repo_owner,repo_name,commit_hash,author,author_email,date,committer_name,committer_email,committer_date,message,filenames,touches_rmd,touches_r,touches_r_or_rmd,is_merge,added,deleted,changed,diff,_touch_r,_touch_rmd,bug_category,category_score
hyunjimoon,SBC,9a544671df74fcff65198267c0a82648ff83f6fe,Martin Modrák,modrak.mar@gmail.com,2025-09-17T11:15:33Z,Martin Modrák,modrak.mar@gmail.com,2025-09-17T11:15:33Z,Fixing vignettes and check_diagnostics,R/results.R;vignettes/SBC.Rmd;vignettes/bayes_factor.Rmd;vignettes/brms.Rmd;vignettes/discrete_vars.Rmd,True,True,True,False,10,7,17,"---FILE: R/results.R---
@@ -1352,7 +1352,7 @@ check_all_SBC_diagnostics <- function(results) {
   msg_unknown <- dplyr::filter(msg, is.na(type))
   purrr::walk(msg_unknown$message, function(m) { cat("" - [???] "", m, ""\n"") })
 
-  all_ok <- all(msg$ok)
+  all_ok <- !any(msg$type == ""bad"")
 
   if(!all_ok) {
     message(""Not all diagnostics are OK.\nYou can learn more by inspecting $default_diagnostics, "",
@@ -1405,7 +1405,9 @@ print.SBC_results_summary <- function(x) {
 
   cat(paste0("" - "", status_string, "" "", messages_indent, collapse = ""\n""))
 
-  if(!all(x$messages$ok)) {
+  all_ok <- !any(x$messages$type == ""bad"")
+
+  if(!all_ok) {
     message(""Not all diagnostics are OK.\nYou can learn more by inspecting $default_diagnostics, "",
             ""$backend_diagnostics \nand/or investigating $outputs/$messages/$warnings for detailed output from the backend."")
   }

---FILE: vignettes/SBC.Rmd---
@@ -264,7 +264,7 @@ In practice, caching is not necessary but is often useful.
 We can now inspect the results to see if there were any errors and check individual stats:
 
 ```{r}
-results$stats
+dplyr::select(results$stats, sim_id:ess_tail) # Hiding some less useful statistics for clarity
 ```
 
 ### Plots

---FILE: vignettes/bayes_factor.Rmd---
@@ -33,7 +33,7 @@ BF_{i,j}\frac{\text{Pr}(\mathcal{M}_i)}{\text{Pr}(\mathcal{M}_j)}
 $$
 
 This means, we can run SBC for this larger model! The results also naturally
-generlize to multiple models.
+generalize to multiple models.
 
 Additionally, we may also employ diagnostics specific for binary variables,
 like testing if the predictions are _calibrated_, e.g. that whenever posterior
@@ -44,7 +44,7 @@ posterior model probability is equal to the prior model probability.
 ## Setting up
 
 Let's setup the environment (`bridgesampling` currently works only with `rstan`,
-so we cannot use `cmdstanr` as do in other vignettes):
+so we cannot use `cmdstanr` as we do in other vignettes):
 
 ```{r setup, message=FALSE,warning=FALSE, results=""hide""}
 library(SBC)

---FILE: vignettes/brms.Rmd---
@@ -100,7 +100,7 @@ generator)
 ```{r}
 backend <- SBC_backend_brms_from_generator(generator, chains = 1, thin = 1,
                             warmup = 500, iter = 1500,               
-                            inits = 0.1)
+                            init = 0.1)
 
 # More verbose alternative that results in exactly the same backend:
 # backend <- SBC_backend_brms(y ~ x, template_data = template_data, prior = priors, warmup = 500, iter = 1000, chains = 1, thin = 1

---FILE: vignettes/discrete_vars.Rmd---
@@ -154,7 +154,8 @@ In practice, caching is not necessary but is often useful.
 We can quickly note that the statistics for the `s` parameter are extreme - many ranks of 0 and _extreme_ z-scores, including -Infinity. Seing just one or two such fits should be enough to convince us that there is something fundamentally wrong.
 
 ```{r}
-dplyr::filter(results_1$stats, variable == ""s"") 
+stats_s <- dplyr::filter(results_1$stats, variable == ""s"") 
+dplyr::select(stats_s, sim_id:ess_tail) # Hiding some less useful statistics for clarity
 ```
 
 ",True,True,Implementation / Logic,6
hyunjimoon,SBC,c79e406da8647f36bc69c990371d7c74ffe2c0d2,Martin Modrák,modrak.mar@gmail.com,2025-09-16T14:39:42Z,Martin Modrák,modrak.mar@gmail.com,2025-09-16T14:39:42Z,More fixes and updates,NAMESPACE;R/backend-bridgesampling.R;R/backend-cmdstanr.R;R/backend-stan-shared.R;R/diagnostics.R;R/results.R;vignettes/bayes_factor.Rmd;vignettes/computational_algorithm1.Rmd;vignettes/discrete_vars.Rmd;vignettes/implementing_backends.Rmd,True,True,True,False,299,103,402,"---FILE: NAMESPACE---
@@ -138,7 +138,6 @@ export(SBC_fit_to_draws_matrix)
 export(SBC_generator_brms)
 export(SBC_generator_custom)
 export(SBC_generator_function)
-export(SBC_nuts_diagnostic_types.CmdStanVB)
 export(SBC_posterior_cdf)
 export(SBC_print_example_model)
 export(SBC_results)

---FILE: R/backend-bridgesampling.R---
@@ -50,20 +50,48 @@ SBC_fit_to_bridge_sampler.SBC_backend_brms <- function(backend, fit, generated,
   bridgesampling::bridge_sampler(fit, ...)
 }
 
+hypothesis_output_prefix <- function(i) {
+  paste0(""[[H"",i,""]]: "")
+}
+
+hypothesis_output_prefix_bridge <- function(i) {
+  paste0(""[[H"",i,"" bridge]]: "")
+}
+
 
 #' @export
 SBC_fit.SBC_backend_bridgesampling <- function(backend, generated, cores) {
-  fit0 <- SBC_fit(backend$backend_H0, generated, cores)
-  bridge_H0 <- do.call(""SBC_fit_to_bridge_sampler"", c(list(backend$backend_H0, fit0, generated), backend$bridgesampling_args))
+  fit_single <- function(backend_H, i) {
+    # Prefix all outputs with relevant markers for post-processing
+    fit_with_outputs <-
+      prefix_captured(
+        capture_all_outputs(SBC_fit(backend_H, generated, cores)),
+        hypothesis_output_prefix(i)
+      )
+
+    reemit_captured(fit_with_outputs)
+    fit <- fit_with_outputs$res
 
-  fit1 <- SBC_fit(backend$backend_H1, generated, cores)
-  bridge_H1 <- do.call(""SBC_fit_to_bridge_sampler"", c(list(backend$backend_H1, fit1, generated), backend$bridgesampling_args))
+
+    bridge_with_outputs <-
+      prefix_captured(
+        capture_all_outputs(
+          do.call(""SBC_fit_to_bridge_sampler"", c(list(backend_H, fit, generated), backend$bridgesampling_args))
+        ),
+        hypothesis_output_prefix_bridge(i)
+      )
+
+    list(fit = fit_with_outputs$res, bridge = bridge_with_outputs$res)
+  }
+
+  fit_bridge_0 <- fit_single(backend$backend_H0, 0)
+  fit_bridge_1 <- fit_single(backend$backend_H1, 1)
 
   structure(list(
-    fit0 = fit0,
-    fit1 = fit1,
-    bridge_H0 = bridge_H0,
-    bridge_H1 = bridge_H1,
+    fit0 = fit_bridge_0$fit,
+    fit1 = fit_bridge_1$fit,
+    bridge_H0 = fit_bridge_0$bridge,
+    bridge_H1 = fit_bridge_1$bridge,
     model_var = backend$model_var,
     prior_prob1 = backend$prior_prob1
   ), class = ""SBC_fit_bridgesampling"")
@@ -123,12 +151,25 @@ SBC_posterior_cdf.SBC_fit_bridgesampling <- function(fit, variables) {
 
 #' @export
 SBC_fit_to_diagnostics.SBC_fit_bridgesampling <- function(fit, fit_output, fit_messages, fit_warnings) {
-  diags0 <- SBC_fit_to_diagnostics(fit$fit0, fit_output, fit_messages, fit_warnings)
-  diags1 <- SBC_fit_to_diagnostics(fit$fit1, fit_output, fit_messages, fit_warnings)
 
-  warning(""TODO: convergence failures"")
-  # ""209 of the 30000 log_prob() evaluations on the proposal draws produced -Inf/Inf.""
+  get_prefixed_lines <- function(prefix, lines) {
+    if(is.null(lines)) {
+      character()
+    } else {
+      with_prefix <- lines[startsWith(lines, prefix)]
+      prefix_removed <- substring(with_prefix, first = length(prefix) + 1)
+      prefix_removed
+    }
+  }
 
+  diags0 <- SBC_fit_to_diagnostics(fit$fit0,
+                                   get_prefixed_lines(hypothesis_output_prefix(0), fit_output),
+                                   get_prefixed_lines(hypothesis_output_prefix(0), fit_messages),
+                                   get_prefixed_lines(hypothesis_output_prefix(0), fit_warnings))
+  diags1 <- SBC_fit_to_diagnostics(fit$fit1,
+                                   get_prefixed_lines(hypothesis_output_prefix(1), fit_output),
+                                   get_prefixed_lines(hypothesis_output_prefix(1), fit_messages),
+                                   get_prefixed_lines(hypothesis_output_prefix(1), fit_warnings))
 
   prob1 <- SBC_fit_bridgesampling_to_prob1(fit)
   log_prob1 <- SBC_fit_bridgesampling_to_prob1(fit, log.p = TRUE)
@@ -148,9 +189,39 @@ SBC_fit_to_diagnostics.SBC_fit_bridgesampling <- function(fit, fit_output, fit_m
       }
     }
   }
-  percentage_error0 <- get_percentage_error(fit$bridge_H0)
-  percentage_error1 <- get_percentage_error(fit$bridge_H1)
-  diags_bs <- data.frame(prob_H1 = prob1, bs_error_H0 = percentage_error0, bs_error_H1 = percentage_error1, log_prob_H1 = log_prob1)
+
+  get_bridge_diagnostics <- function(bridge, i) {
+    bridge_warnings <- get_prefixed_lines(hypothesis_output_prefix_bridge(i), fit_warnings)
+
+    # Example warning:
+    # ""209 of the 30000 log_prob() evaluations on the proposal draws produced -Inf/Inf.""
+    inf_proposal_lines <- grepl(""evaluations.*proposal.*Inf"", bridge_warnings)
+    if(any(inf_proposal_lines)) {
+      if(sum(inf_proposal_lines) > 1) {
+        warning(""Multiple lines with infinite proposals warning."")
+      }
+      inf_proposal_text <- (bridge_warnings[inf_proposal_lines])[1]
+      n_inf_proposals <- as.integer(sub(""\\D*(\\d+).*"", ""\\1"", inf_proposal_text))
+      if(n_inf_proposals <= 0) {
+        warning(""Problems parsing infinite proposals warnings"")
+      }
+    } else {
+      n_inf_proposals <- 0
+    }
+    diags <- data.frame(
+      bs_error = get_percentage_error(bridge),
+      n_inf_proposals = n_inf_proposals,
+      logml_maxiter = any(grepl(""logml.*maxiter"", bridge_warnings)) #logml could not be estimated within maxiter
+    )
+    names(diags) <- paste0(names(diags), ""_H"", i)
+    diags
+  }
+
+  diags_bs <- cbind(
+    data.frame(prob_H1 = prob1, log_prob_H1 = log_prob1),
+    get_bridge_diagnostics(fit$bridge_H0, 0),
+    get_bridge_diagnostics(fit$bridge_H1, 1)
+  )
 
   if(!is.null(diags0)) {
     names(diags0) <- paste0(names(diags0), ""_H0"")
@@ -183,7 +254,12 @@ If not, please file an issue at https://github.com/hyunjimoon/SBC/issues/
     get_submodel_diags <- function(i) {
       bs_specific_diags <- list()
       bs_specific_diags[[paste0(""bs_error_H"", i)]] <-
-        numeric_diagnostic(paste0(""relative error of marginal likelihood for H"", i), report = ""max"", error_above = 5)
+        numeric_diagnostic(paste0(""relative error of marginal likelihood for H"", i), report = ""max"", error_above = 5, unit = ""%"")
+      bs_specific_diags[[paste0(""n_inf_proposals_H"", i)]] <-
+        count_diagnostic(paste0(""H"", i, "": log_prob() evaluations on the proposal draws produced -Inf/Inf""), error_above = 0, error_only = TRUE)
+      bs_specific_diags[[paste0(""logml_maxiter_H"", i)]] <-
+        logical_diagnostic(ok_value = FALSE, true_label = paste0(""H"", i, "": logml could not be estimated within maxiter""),
+                           error_only = TRUE)
 
       H_diags_selected <-
           dplyr::select(diags, tidyselect::ends_with(paste0(""_H"",i)) & !tidyselect::all_of(c(""prob_H1"", ""log_prob_H1"", names(bs_specific_diags))))
@@ -227,7 +303,14 @@ rbind.SBC_bridgesampling_diagnostics <- function(...) {
   args <- list(...)
 
   # Working around the special dispatch for rbind
-  args_class_removed <- purrr::map(args, \(x) { class(x) <- setdiff(class(x), ""SBC_bridgesampling_diagnostics""); x })
+  args_class_removed <- purrr::map(args, \(x) {
+    if(is.null(x)) {
+      NULL
+    } else {
+      class(x) <- setdiff(class(x), ""SBC_bridgesampling_diagnostics"")
+      x
+    }
+  })
   res <- do.call(rbind, args_class_removed)
   class(res) <- c(""SBC_bridgesampling_diagnostics"", class(res))
 

---FILE: R/backend-cmdstanr.R---
@@ -199,7 +199,3 @@ SBC_fit_to_diagnostics.CmdStanVB <- function(fit, fit_output, fit_messages, fit_
   res
 }
 
-#' @export
-SBC_nuts_diagnostic_types.CmdStanVB <- function(backend) {
-  SBC_ADVI_diagnostics_types()
-}

---FILE: R/backend-stan-shared.R---
@@ -59,7 +59,7 @@ get_expected_max_rhat <- function(n_vars, prob = 0.99, approx_sd = 0.005) {
 #' @export
 diagnostic_types.SBC_ADVI_diagnostics <- function(diags) {
   list(
-    elbo_converged = logical_diagnostic(""ELBO converged"", error_value = FALSE),
+    elbo_converged = logical_diagnostic(ok_value = TRUE, true_label = ""ELBO converged"", false_label = ""ELBO not converged""),
     n_rejects = count_diagnostic(""some steps rejected"", error_above = 0),
     time = numeric_diagnostic(""time"", report = ""max"")
   )

---FILE: R/diagnostics.R---
@@ -5,14 +5,15 @@ get_diagnostic_messages_single <- function(diagnostic, values) {
 
 #' @export
 numeric_diagnostic <- function(label, report = NULL, error_above = Inf, error_below = -Inf, allow_na = FALSE, label_short = NULL,
-                                   hint = """", digits = 2) {
+                                   hint = """", digits = 2, unit = """") {
   if(is.null(label_short)) {
     label_short <- label
   }
 
   structure(list(label = label, report = report, error_above = error_above,
-                 error_below = error_below,
-                 label_short = label_short, hint = hint, digits = digits),
+                 error_below = error_below, allow_na = allow_na,
+                 label_short = label_short, hint = hint, digits = digits,
+                 unit = unit),
             class = ""SBC_numeric_diagnostic"")
 }
 
@@ -21,22 +22,25 @@ numeric_diagnostic <- function(label, report = NULL, error_above = Inf, error_be
 get_diagnostic_messages_single.SBC_numeric_diagnostic <- function(diagnostic, values) {
   stopifnot(is.numeric(values) || is.integer(values))
 
-
-  if(is.finite(diagnostic$error_above)) {
-    if(is.finite(diagnostic$error_below)) {
+  unit <- diagnostic$unit
+  if(is.finite(diagnostic$error_below)) {
+    if(is.finite(diagnostic$error_above)) {
       stop(""Not implemented yet"")
     } else {
-      threshold_summary = paste0(""< "", diagnostic$error_above)
+      threshold_summary_error <- paste0(""< "", diagnostic$error_below, unit)
+      threshold_summary_ok <- paste0("">= "", diagnostic$error_below, unit)
     }
   } else {
-    if(is.finite(diagnostic$error_below)) {
-      threshold_summary = paste0(""> "", diagnostic$error_below)
+    if(is.finite(diagnostic$error_above)) {
+      threshold_summary_error <- paste0(""> "", diagnostic$error_above, unit)
+      threshold_summary_ok <- paste0(""<= "", diagnostic$error_above, unit)
     } else {
-      threshold_summary = NULL
+      threshold_summary_error <- NULL
+      threshold_summary_ok <- NULL
     }
   }
 
-  if(is.null(threshold_summary)) {
+  if(is.null(threshold_summary_ok)) {
     label_for_report <- diagnostic$label
   } else {
     label_for_report <- diagnostic$label_short
@@ -45,11 +49,11 @@ get_diagnostic_messages_single.SBC_numeric_diagnostic <- function(diagnostic, va
   if(is.null(diagnostic$report)) {
     report <- """"
   } else if(diagnostic$report == ""max"") {
-    report <- paste0(""Maximum "", label_for_report, "" was "", round(max(values), digits = diagnostic$digits), "". "")
+    report <- paste0(""Maximum "", label_for_report, "" was "", round(max(values, na.rm = TRUE), digits = diagnostic$digits), unit, "". "")
   } else if(diagnostic$report == ""min"") {
-    report <- paste0(""Minimum "", label_for_report, "" was "", round(min(values), digits = diagnostic$digits), "". "")
+    report <- paste0(""Minimum "", label_for_report, "" was "", round(min(values, na.rm = TRUE), digits = diagnostic$digits), unit, "". "")
   } else if(diagnostic$report == ""quantiles"") {
-    quantiles <- round(quantile(values, probs = c(0.05, 0.5, 0.95)), digits = diagnostic$digits)
+    quantiles <- paste0(round(quantile(values, probs = c(0.05, 0.5, 0.95), na.rm = TRUE), digits = diagnostic$digits), unit)
     report <- paste0(label_for_report, "" Q.05 = "", quantiles[1],"", median = "", quantiles[2], "", Q.95 = "", quantiles[3], "". "")
   } else {
     stop(paste0(""Unrecognized 'report' value: "", report))
@@ -60,29 +64,44 @@ get_diagnostic_messages_single.SBC_numeric_diagnostic <- function(diagnostic, va
     !any(values > diagnostic$error_above, na.rm = TRUE) &&
     !any(values < diagnostic$error_below, na.rm = TRUE)
 
-  if(is.null(threshold_summary)) {
-    msg <- data.frame(ok = TRUE, message = report)
+  n_na <- sum(is.na(values))
+
+  if(is.null(threshold_summary_ok)) {
+    if(!diagnostic$allow_na && n_na > 0) {
+      msg <- data.frame(type = ""bad"", message = paste0(n_na, "" ("", round(100 * n_na / length(values)), ""%) fits had NA "", label, report))
+    } else {
+      msg <- data.frame(type = ""info"", message = report)
+    }
   } else {
+    if(!diagnostic$allow_na && n_na > 0) {
+      ok <- FALSE
+      threshold_summary_error <- paste0(threshold_summary_error, "" or NA"")
+    }
+
     if(ok) {
-      msg <- data.frame(ok = TRUE, message = paste0(""All fits had "", diagnostic$label, "" "", threshold_summary, "". "", report))
+      msg <- data.frame(type = ""ok"", message = paste0(""All fits had "", diagnostic$label, "" "", threshold_summary_ok, "". "", report))
     } else {
       n_wrong <- sum(values > diagnostic$error_above | values < diagnostic$error_below, na.rm = TRUE)
-      msg <- data.frame(ok = FALSE, message = paste0( n_wrong, "" ("", round(100 * n_wrong / length(values)), ""%) fits had "", diagnostic$label, "" "", threshold_summary, "". "", report, diagnostic$hint))
+      msg <- data.frame(type = ""bad"",
+                        message = paste0( n_wrong, "" ("", round(100 * n_wrong / length(values)), ""%) fits had "",
+                                          diagnostic$label, "" "", threshold_summary_error, "". "", report, diagnostic$hint))
     }
   }
   msg
 }
 
 
 #' @export
-count_diagnostic <- function(label, error_above = 0, label_short = NULL, hint = """") {
+count_diagnostic <- function(label, error_above = 0, label_short = NULL, hint = """",
+                             error_only = FALSE) {
   if(is.null(label_short)) {
     label_short <- label
   }
   structure(list(label = label,
                  error_above = error_above,
                  label_short = label_short,
-                 hint = hint),
+                 hint = hint,
+                 error_only = error_only),
             class = ""SBC_count_diagnostic"")
 }
 
@@ -97,8 +116,10 @@ get_diagnostic_messages_single.SBC_count_diagnostic <- function(diagnostic, valu
 
   if (diagnostic$error_above == Inf) {
     ok_message <- report
+    ok_type <- ""info""
     threshold_summary <- ""some ""
   } else {
+    ok_type <- ""ok""
     if (diagnostic$error_above == 0) {
       threshold_summary <- """"
       ok_message <- paste0( ""No fits had "",
@@ -113,36 +134,56 @@ get_diagnostic_messages_single.SBC_count_diagnostic <- function(diagnostic, valu
 
   if(any_above_thresh) {
     n_above <- sum(values > diagnostic$error_above, na.rm = TRUE)
-    msg <- data.frame(ok = FALSE,
+    msg <- data.frame(type = ""bad"",
                       message = paste0( n_above, "" ("", round(100 * n_above / length(values)), ""%) fits had "",
                                         threshold_summary, diagnostic$label, "". "", report, diagnostic$hint))
+  } else if(diagnostic$error_only) {
+    msg <- data.frame(type = character(),
+                      message = character())
   } else {
-    msg <- data.frame(ok = TRUE,
+    msg <- data.frame(type = ok_type,
                       message = ok_message)
   }
 
   msg
 }
 
 #' @export
-logical_diagnostic <- function(error_label, error_value, hint = """") {
-  structure(list(error_label = error_label,
-                 error_value = error_value,
+logical_diagnostic <- function(ok_value, true_label,
+                               false_label = paste0(""not "", true_label),
+                               hint = """", error_only = FALSE) {
+  stopifnot(!is.na(ok_value))
+  structure(list(true_label = true_label,
+                 false_label = false_label,
+                 ok_value = ok_value,
+                 error_only = error_only,
                  hint = hint),
             class = ""SBC_logical_diagnostic"")
 }
 
 #' @export
 get_diagnostic_messages_single.SBC_logical_diagnostic <- function(diagnostic, values) {
   stopifnot(is.logical(values))
-  ok_vec <- (values != diagnostic$error_value)
-  if(all(ok_vec)) {
-    msg <- data.frame(ok = TRUE, message = paste0(""No fits "", diagnostic$error_label,"".""))
+  ok_vec_no_nas <- tidyr::replace_na(values, !diagnostic$ok_value) == diagnostic$ok_value
+
+  if(all(ok_vec_no_nas)) {
+    if(diagnostic$error_only) {
+       data.frame(type = character(), message = character())
+    } else if(diagnostic$ok_value) {
+      data.frame(type = ""ok"", message = paste0(""All fits "", diagnostic$true_label,"".""))
+    } else {
+      data.frame(type = ""ok"", message = paste0(""No fits "", diagnostic$true_label,"".""))
+    }
   } else {
-    n_fail <- sum(!ok_vec)
-    msg <- data.frame(ok = FALSE,
+    n_fail <- sum(!ok_vec_no_nas)
+    if(diagnostic$ok_value) {
+      fail_label <- diagnostic$false_label
+    } else {
+      fail_label <- diagnostic$true_label
+    }
+    data.frame(type = ""bad"",
                       message = paste0( n_fail, "" ("", round(100 * n_fail / length(values)), ""%) fits "",
-                                        diagnostic$error_label,"". "", diagnostic$hint))
+                                        fail_label,"". "", diagnostic$hint))
   }
 }
 
@@ -172,12 +213,12 @@ get_diagnostic_messages_single.SBC_default_diagnostic <- function(diagnostic, va
   if(is.logical(values)) {
     n_true <- sum(values, na.rm = TRUE)
     n_na <- sum(is.na(values))
-    data.frame(ok = NA, message =
+    data.frame(type = NA, message =
                  paste0(diagnostic$col_name, "": "", n_true, "" ("", round(100 * n_true / length(values)), ""%) true, "",
                         n_na, "" ("", round(100 * n_na / length(values)), ""%) NA, ""))
   } else if(is.numeric(values) || is.integer(values)) {
     n_na <- sum(is.na(values))
-    data.frame(ok = NA, message =
+    data.frame(type = NA, message =
                  paste0(diagnostic$col_name, "": min = "", round(min(values, na.rm = TRUE), digits = 3), "", max = "", round(max(values, na.rm = TRUE, digits = 3)), "", "",
                         n_na, "" ("", round(100 * n_na / length(values)), ""%) NA, ""))
 
@@ -188,7 +229,7 @@ get_diagnostic_messages_single.SBC_default_diagnostic <- function(diagnostic, va
     } else {
       tab_str <- paste0(length(tab), "" values. Most common: "", names(tab)[1], "" - "", tab[1], "" ("", round(100 * tab[1] / length(values)), ""%)"")
     }
-    data.frame(ok = NA,
+    data.frame(type = NA,
                message = paste0(diagnostic$col_name, "": "", tab_str))
   }
 }
@@ -201,7 +242,7 @@ skip_diagnostic <- function() {
 
 #' @export
 get_diagnostic_messages_single.SBC_skip_diagnostic <- function(diagnostic, values) {
-  data.frame(ok = logical(), message = character())
+  data.frame(type = character(), message = character())
 }
 
 
@@ -222,5 +263,8 @@ get_all_diagnostic_messages <- function(diags, types) {
   types_used <- c(types[shared_names], types_default)
 
   msgs <- purrr::map2_dfr(types_used, diags_used, get_diagnostic_messages_single)
+  if(!all(is.na(msgs$type) | (msgs$type %in% c(""info"", ""ok"", ""bad"")))) {
+    warning(""Urecognized message types"")
+  }
   msgs
 }

---FILE: R/results.R---
@@ -756,6 +756,23 @@ reemit_captured <- function(captured) {
   }
 }
 
+# Add a given prefix to all captured content
+prefix_captured <- function(captured, prefix) {
+  process_single <- function(x) {
+    if(is.null(x)) {
+      NULL
+    } else {
+      paste0(prefix, x)
+    }
+
+  }
+
+  list(result = captured$res,
+       messages = process_single(captured$messages),
+       warnings = process_single(captured$warnings),
+       output = process_single(captured$output))
+}
+
 # See `compute_SBC` for docs for the function arguments
 compute_SBC_single <- function(vars_and_generated, backend, cores,
                                keep_fit, thin_ranks,
@@ -1169,8 +1186,8 @@ SBC_results_base_diagnostics <- function(results) {
 
 SBC_results_base_diagnostic_types <- function() {
   list(
-    has_error = logical_diagnostic(""produced error"", TRUE, hint = ""Inspect $errors for the full messages.""),
-    has_warning = logical_diagnostic(""gave warning"", TRUE, hint = ""Inspect $warnings for the full messages."")
+    has_error = logical_diagnostic(ok_value = FALSE, true_label = ""produced error"", hint = ""Inspect $errors for the full messages.""),
+    has_warning = logical_diagnostic(ok_value = FALSE, true_label = ""gave warning"", hint = ""Inspect $warnings for the full messages."")
   )
 }
 
@@ -1215,44 +1232,77 @@ compute_default_diagnostics <- function(stats) {
 }
 
 #'@export
-default_diagnostics_types <- function() {
-  possibly_constant_hint <- paste0(""This likely means all posterior draws were equal for some variable.\n"",
-                          ""If this is expected, mark the variable `possibly_constant_var_attribute()` to suppress this message."")
-  c(
-    list(
-      n_has_na = count_diagnostic(""some NAs in variables/samples"",
-                                  error_above = 0,
-                                      hint = ""If this is expected, mark the variable with `na_valid_var_attribute()` to suppress this message.""),
+default_diagnostics_types <- function(results) {
+  def_diags <- results$default_diagnostics
+  unique_ess_bulk <- unique(def_diags$min_ess_bulk)
+  unique_ess_tail <- unique(def_diags$min_ess_tail)
+
+  iid_draws <- all(def_diags$max_rhat == 1) && length(unique_ess_bulk) == 1 &&
+    length(unique_ess_tail) == 1 && identical(unique_ess_bulk, unique_ess_tail)
+
+  always_on_diags <- list(
+    n_has_na = count_diagnostic(
+      ""NAs in some variables/samples"",
+      label_short = ""variables with NAs"",
+      error_above = 0, error_only = TRUE,
+      hint = ""If this is expected, mark the variable with `na_valid_var_attribute()` to suppress this message.""
+    )
+  )
+
+  if(iid_draws) {
+    mixing_diags <- list(n_na_rhat = skip_diagnostic(),
+                         n_na_ess_bulk = skip_diagnostic(),
+                         n_na_ess_tail = skip_diagnostic(),
+                         max_rhat = skip_diagnostic(),
+                         min_ess_bulk = skip_diagnostic(),
+                         min_ess_tail = skip_diagnostic(),
+                         min_ess_to_rank = skip_diagnostic())
+  } else {
+    possibly_constant_hint <- paste0(""This likely means all posterior draws were equal for some variable.\n"",
+                                     ""If this is expected, mark the variable `possibly_constant_var_attribute()` to suppress this message."")
+
+    mixing_diags <- list(
       n_na_rhat = count_diagnostic(""NA Rhat"",
-                                   error_above = 0,
+                                   error_above = 0, error_only = TRUE,
                                    hint = possibly_constant_hint),
       n_na_ess_bulk = count_diagnostic(""NA ess_bulk"",
-                                       error_above = 0,
+                                       error_above = 0, error_only = TRUE,
                                        hint = possibly_constant_hint),
-      n_na_ess_tail = count_diagnostic(""NA ess_tail"",
+      n_na_ess_tail = count_diagnostic(""NA ess_tail"", error_only = TRUE,
                                        error_above = 0),
       max_rhat = numeric_diagnostic(""maximum Rhat"", label_short = ""Rhat"", report = ""max"", error_above = 1.01, allow_na = TRUE, digits = 3),
       min_ess_bulk = numeric_diagnostic(""bulk ESS"", report = ""min"", allow_na = TRUE, digits = 0),
       min_ess_tail = numeric_diagnostic(""tail ESS"", report = ""min"", allow_na = TRUE, digits = 0),
       min_ess_to_rank = numeric_diagnostic(""tail ESS / maximum rank"", report = ""min"", allow_na = TRUE, error_below = 0.5,
-                                               hint = ""This potentially skews the rank statistics.\n If the fits look good otherwise, increasing `thin_ranks` (via recompute_SBC_statistics) \nor number of posterior draws (by refitting) might help."")
+                                           hint = ""This potentially skews the rank statistics.\n If the fits look good otherwise, increasing `thin_ranks` (via recompute_SBC_statistics) \nor number of posterior draws (by refitting) might help."")
     )
+
+  }
+
+  c(
+    always_on_diags,
+    mixing_diags
   )
 }
 
 
 #' @export
 SBC_results_diagnostics <- function(results) {
   base <- SBC_results_base_diagnostics(results)
-  stopifnot(identical(base$sim_id, results$default_diagnostics$sim_id))
-  default_mod <- dplyr::select(results$default_diagnostics,
-                               -sim_id, -n_vars)
 
-  diags <- cbind(base, default_mod)
   if(!is.null(results$backend_diagnostics)) {
     stopifnot(identical(base$sim_id, results$backend_diagnostics$sim_id))
-    diags <- cbind(diags, dplyr::select(results$backend_diagnostics, -sim_id))
+    diags <- cbind(base, dplyr::select(results$backend_diagnostics, -sim_id))
+  } else {
+    diags <- base
   }
+
+  stopifnot(identical(base$sim_id, results$default_diagnostics$sim_id))
+  default_mod <- dplyr::select(results$default_diagnostics,
+                               -sim_id, -n_vars)
+
+  diags <- cbind(diags, default_mod)
+
   diags
 }
 
@@ -1266,7 +1316,7 @@ SBC_results_diagnostic_messages <- function(results) {
   default_diags_mod <- dplyr::select(results$default_diagnostics, -n_vars)
   default_messages <- get_all_diagnostic_messages(
     default_diags_mod,
-    default_diagnostics_types()
+    default_diagnostics_types(results)
   )
 
   if(!is.null(results$backend_diagnostics)) {
@@ -1278,21 +1328,28 @@ SBC_results_diagnostic_messages <- function(results) {
 
 
   rbind(base_messages,
-        default_messages,
-        backend_messages)
+        backend_messages,
+        default_messages
+        )
 }
 
 
-#' @rdname check_all_SBC_diagnostics
+#' Check diagnostics for an SBC results object.
+#'
+#' Produces a message for each failed check.
 #' @export
 #' @return TRUE if all checks are OK, FALSE otherwise.
 check_all_SBC_diagnostics <- function(results) {
   msg <- SBC_results_diagnostic_messages(results)
-  msg_problems <- dplyr::filter(msg, !ok)
+
+  msg$message <- gsub(""\n"", ""\n   "", msg$message, fixed = TRUE)
+
+
+  msg_problems <- dplyr::filter(msg, type == ""bad"")
 
   purrr::walk(msg_problems$message, function(m) { message("" - "", m, appendLF = TRUE) })
 
-  msg_unknown <- dplyr::filter(msg, is.na(ok))
+  msg_unknown <- dplyr::filter(msg, is.na(type))
   purrr::walk(msg_unknown$message, function(m) { cat("" - [???] "", m, ""\n"") })
 
   all_ok <- all(msg$ok)
@@ -1328,18 +1385,25 @@ print.SBC_results_summary <- function(x) {
 
   if(requireNamespace(""crayon"", quietly = TRUE)) {
     status_string <- dplyr::case_when(
-      is.na(x$messages$ok) ~ crayon::yellow(""[???]""),
-      x$messages$ok ~ crayon::green(""[OK]""),
-      TRUE ~ crayon::red(""[BAD]"")
+      is.na(x$messages$type) ~ crayon::yellow(""[???]""),
+      x$messages$type == ""info"" ~ ""[INFO]"",
+      x$messages$type == ""ok"" ~ crayon::green(""[OK]""),
+      x$messages$type == ""bad"" ~ crayon::red(""[BAD]""),
+      TRUE ~ crayon::red(paste0(""["", x$messages$type, ""]""))
     )
   } else {
     status_string <- dplyr::case_when(
-      is.na(x$messages$ok) ~ ""[???]"",
-      x$messages$ok ~ ""[OK]"",
-      TRUE ~ ""[BAD]""
+      is.na(x$messages$type) ~ ""[???]"",
+      x$messages$type == ""info"" ~ ""[INFO]"",
+      x$messages$type == ""ok"" ~ ""[OK]"",
+      x$messages$type == ""bad"" ~ ""[BAD]"",
+      TRUE ~ paste0(""["", x$messages$type, ""]"")
     )
   }
-  cat(paste0("" - "", status_string, "" "", x$messages$message, collapse = ""\n""))
+
+  messages_indent <- gsub(""\n"", ""\n   "", x$messages$message, fixed = TRUE)
+
+  cat(paste0("" - "", status_string, "" "", messages_indent, collapse = ""\n""))
 
   if(!all(x$messages$ok)) {
     message(""Not all diagnostics are OK.\nYou can learn more by inspecting $default_diagnostics, "",

---FILE: vignettes/bayes_factor.Rmd---
@@ -1,12 +1,12 @@
 ---
-title: ""SBC for bayes factors (with rstan and bridgesampling)""
+title: ""SBC for Bayes factors (with rstan and bridgesampling)""
 author: ""Martin Modrák""
 date: ""`r Sys.Date()`""
 output: 
   rmarkdown::html_vignette:
     toc: yes
 vignette: >
-  %\VignetteIndexEntry{SBC for bayes factors (with rstan and bridgesampling)}
+  %\VignetteIndexEntry{SBC for Bayes factors (with rstan and bridgesampling)}
   %\VignetteEngine{knitr::rmarkdown}
   \usepackage[utf8]{inputenc}
 ---
@@ -234,7 +234,9 @@ numbers are taken straight from `bridgesampling` documentation).
 One more trick we showcase is that we can cache individual model fits, if
 we wrap a backend with `SBC_backend_cached()`. Since we will reuse the same
 H0 model later, we will do this here just for the H0 model. Obviously everything
-will also work without caching.
+will also work without caching. For H1, some datasets cause divergences,
+and we are lazy to fully fix that issue, so we instead increase `adapt_delta` and
+`max_treedepth` (effectively avoiding the problem by using more compute).
 
 ```{r}
 iter <- 15500
@@ -245,14 +247,18 @@ backend_turtles_bad <- SBC_backend_bridgesampling(
     fit_cache_dir,
     SBC_backend_rstan_sample(m_H0, iter = iter, warmup = warmup, init = init)
     ),
-  SBC_backend_rstan_sample(m_H1_bad, iter = iter, warmup = warmup, init = init)
+  SBC_backend_rstan_sample(m_H1_bad, iter = iter, warmup = warmup, init = init,
+                           control = list(adapt_delta = 0.99, max_treedepth = 12))
 )
 res_turtles_bad <- compute_SBC(ds_turtles, backend_turtles_bad, 
                            keep_fits = FALSE,
                            cache_mode = ""results"",
                            cache_location = file.path(cache_dir, ""turtles_bad.rds""))
 ```
 
+We have a small number of fits with small number of divergences, which we will
+ignore for now.
+
 Lets look at the default SBC diagnostics. Note that the plot by default
 combines all parameters that are present in at least a single model. 
 It then uses the implied BMA supermodel to get draws of the parameters (when
@@ -366,7 +372,7 @@ good test quantities) be detected by SBC.
 [Tsukamura and Okada (2024)](https://doi.org/10.1007/s00407-022-00298-3) have noted
 that many published Stan models do not include proper normalization for bounded
 parameters and all of those models could thus produce incorrect Bayes factors
-if used with `bridgesampling`, so this is a compuational problem
+if used with `bridgesampling`, so this is a computational problem
 one can expect to actually see in the wild.
 
 ## Correct model
@@ -389,14 +395,16 @@ backend_turtles <- SBC_backend_bridgesampling(
     fit_cache_dir,
     SBC_backend_rstan_sample(m_H0, iter = iter, warmup = warmup, init = init)
     ),
-  SBC_backend_rstan_sample(m_H1, iter = iter, warmup = warmup, init = init)
+  SBC_backend_rstan_sample(m_H1, iter = iter, warmup = warmup, init = init, 
+                           control = list(adapt_delta = 0.99, max_treedepth = 12))
 )
 res_turtles <- compute_SBC(ds_turtles, backend_turtles, 
                            keep_fits = FALSE,
                            cache_mode = ""results"",
                            cache_location = file.path(cache_dir, ""turtles.rds""))
 ```
 
+we got a small number of divergences, which we will ignore here
 
 
 ```{r ecdf-ok}

---FILE: vignettes/computational_algorithm1.Rmd---
@@ -144,7 +144,7 @@ res_poisson <-
     cache_mode = ""results"", cache_location = file.path(cache_dir, ""poisson""))
 ```
 
-Even with the quite high precision afforded by 1000 simulations, the ECDF diff plot and the ranks show no problems - the model is quite well calibrated, although the wavy shape of the ECDF suggest a minor overconfidence of the approximation:
+Even with the quite high precision afforded by 1000 simulations, the ECDF diff plot and the ranks show no problems - the model is quite well calibrated, although the wavy shape of the ECDF suggest a potential minor overconfidence of the approximation:
 
 ```{r ecdf_rank_poisson}
 plot_ecdf_diff(res_poisson)

---FILE: vignettes/discrete_vars.Rmd---
@@ -109,7 +109,8 @@ generate_single_sim_1 <- function(T, r_e, r_l) {
       y = y
     ),
     # Letting SBC know that the s parameter can potentially
-    # be drawn as all constants 
+    # be drawn as all draws identical (if s is well informed by data)
+    # and this should not trigger warnings
     var_attributes = var_attributes(
       s = possibly_constant_var_attribute()
     )

---FILE: vignettes/implementing_backends.Rmd---
@@ -262,15 +262,16 @@ this should return a named list where each element describes a single diagnostic
 ```{r}
 diagnostic_types.SBC_glm_diagnostics <- function(x) {
   list(
-    probs_0_1 = logical_diagnostic(error_label = ""had 0/1 probabilities"", error_value = TRUE),
-    converged = logical_diagnostic(error_label = ""had convergence problems"", error_value = FALSE)
+    probs_0_1 = logical_diagnostic(ok_value = FALSE, true_label = ""had 0/1 probabilities""),
+    converged = logical_diagnostic(ok_value = TRUE, true_label = ""converged"", false_label = ""did not converge"")
   )
 }
 ```
 
-You typically want to the predefined functions like `logical_diagnostic()`, 
-`numeric_diagnostic()` and `count_diagnostic()` for most typical diagnostic
-values.
+You typically want to use the predefined functions like `logical_diagnostic()`, 
+`numeric_diagnostic()` and `count_diagnostic()` for your diagnostic
+values, but you can in principle declare your own reporting method (see
+the source for the current methods for examples).
 
 ```{r}
 #TODO implement CDFs once there more use for them",True,True,Documentation / Formatting,6
hyunjimoon,SBC,573b108841e4ceaf26e71f38edb489dd3fe77179,Martin Modrák,modrak.mar@gmail.com,2025-09-15T09:45:05Z,Martin Modrák,modrak.mar@gmail.com,2025-09-15T09:45:05Z,"Fixing problems in diagnostics, mostly working",NAMESPACE;R/backend-bridgesampling.R;R/backend-rstan.R;R/backend-stan-shared.R;R/diagnostics.R;R/results.R;man/rbind.SBC_bridgesampling_diagnostics.Rd;man/select.SBC_bridgesampling_diagnostics.Rd;tests/testthat/test-bridgesampling.R;vignettes/implementing_backends.Rmd,True,True,True,False,236,78,314,"---FILE: NAMESPACE---
@@ -63,6 +63,7 @@ S3method(SBC_fit_to_draws_matrix,default)
 S3method(SBC_posterior_cdf,SBC_fit_bridgesampling)
 S3method(SBC_posterior_cdf,SBC_fit_extractBF_comparison)
 S3method(SBC_posterior_cdf,default)
+S3method(base::rbind,SBC_bridgesampling_diagnostics)
 S3method(brms_response_sequence,bform)
 S3method(brms_response_sequence,brmsfit)
 S3method(brms_response_sequence,brmsterms)
@@ -76,13 +77,15 @@ S3method(diagnostic_types,SBC_RStanOptimizing_diagnostics)
 S3method(diagnostic_types,SBC_bridgesampling_diagnostics)
 S3method(diagnostic_types,SBC_nuts_diagnostics)
 S3method(diagnostic_types,default)
+S3method(dplyr::select,SBC_bridgesampling_diagnostics)
 S3method(generate_datasets,SBC_generator_brms)
 S3method(generate_datasets,SBC_generator_custom)
 S3method(generate_datasets,SBC_generator_function)
 S3method(get_diagnostic_messages_single,SBC_count_diagnostic)
 S3method(get_diagnostic_messages_single,SBC_default_diagnostic)
 S3method(get_diagnostic_messages_single,SBC_logical_diagnostic)
 S3method(get_diagnostic_messages_single,SBC_numeric_diagnostic)
+S3method(get_diagnostic_messages_single,SBC_skip_diagnostic)
 S3method(get_diagnostic_messages_single,SBC_submodel_diagnostic)
 S3method(length,SBC_datasets)
 S3method(length,SBC_results)
@@ -205,6 +208,7 @@ export(possibly_constant_var_attribute)
 export(recompute_SBC_statistics)
 export(recompute_statistics)
 export(remove_attribute_from_stats)
+export(skip_diagnostic)
 export(split_SBC_results_for_bf)
 export(submodel_diagnostic)
 export(submodel_var_attribute)

---FILE: R/backend-bridgesampling.R---
@@ -127,6 +127,8 @@ SBC_fit_to_diagnostics.SBC_fit_bridgesampling <- function(fit, fit_output, fit_m
   diags1 <- SBC_fit_to_diagnostics(fit$fit1, fit_output, fit_messages, fit_warnings)
 
   warning(""TODO: convergence failures"")
+  # ""209 of the 30000 log_prob() evaluations on the proposal draws produced -Inf/Inf.""
+
 
   prob1 <- SBC_fit_bridgesampling_to_prob1(fit)
   log_prob1 <- SBC_fit_bridgesampling_to_prob1(fit, log.p = TRUE)
@@ -181,10 +183,10 @@ If not, please file an issue at https://github.com/hyunjimoon/SBC/issues/
     get_submodel_diags <- function(i) {
       bs_specific_diags <- list()
       bs_specific_diags[[paste0(""bs_error_H"", i)]] <-
-        numeric_diagnostic(paste0(""relative error of marginal likelihood for H"", i), report = ""max"", lower_thresh = 5)
+        numeric_diagnostic(paste0(""relative error of marginal likelihood for H"", i), report = ""max"", error_above = 5)
 
       H_diags_selected <-
-          dplyr::select(diags, tidyselect::ends_with(paste0(""_H"",i)) & !tidyselect::all_of(c(""prob_H1"", names(bs_specific_diags))))
+          dplyr::select(diags, tidyselect::ends_with(paste0(""_H"",i)) & !tidyselect::all_of(c(""prob_H1"", ""log_prob_H1"", names(bs_specific_diags))))
 
       H_diags <- dplyr::rename_with(
         H_diags_selected,
@@ -195,7 +197,7 @@ If not, please file an issue at https://github.com/hyunjimoon/SBC/issues/
       types_sub <- diagnostic_types(H_diags)
       types_mapped <- purrr::map(types_sub,
                                  \(diag) submodel_diagnostic(paste0(""H"", i), diag))
-      names(types_mapped) <- paste0(names(types_sub, ""_H"", i))
+      names(types_mapped) <- paste0(names(types_sub), ""_H"", i)
       c(
         types_mapped,
         bs_specific_diags
@@ -211,12 +213,44 @@ If not, please file an issue at https://github.com/hyunjimoon/SBC/issues/
 
   c(
     list(
-      prob_H1 = numeric_diagnostic(""posterior probability of H1"", report = ""quantiles"")
+      prob_H1 = numeric_diagnostic(""posterior probability of H1"", report = ""quantiles""),
+      log_prob_H1 = skip_diagnostic()
     ),
     submodel_diags
   )
 }
 
+#' Custom rbind implementation maintainig information about submodels
+#' @exportS3Method base::rbind
+rbind.SBC_bridgesampling_diagnostics <- function(...) {
+
+  args <- list(...)
+
+  # Working around the special dispatch for rbind
+  args_class_removed <- purrr::map(args, \(x) { class(x) <- setdiff(class(x), ""SBC_bridgesampling_diagnostics""); x })
+  res <- do.call(rbind, args_class_removed)
+  class(res) <- c(""SBC_bridgesampling_diagnostics"", class(res))
+
+  submodel_classes_list <- purrr::map(args, \(x) attr(x, ""submodel_classes"", exact = TRUE))
+  unique_submodel_classes <- unique(submodel_classes_list)
+  if(length(unique_submodel_classes) > 1) {
+    warning(""Non-unique submodel classes when binding diagnostics"")
+  }
+  submodel_classes <- unique_submodel_classes[[1]]
+  if(!is.null(submodel_classes)) {
+    attr(res, ""submodel_classes"") <- submodel_classes
+  }
+  res
+}
+
+#' Custom select implementation maintainig information about submodels
+#' @exportS3Method dplyr::select
+select.SBC_bridgesampling_diagnostics <- function(diags, ...) {
+  selected <- NextMethod()
+  attr(selected, ""submodel_classes"") <- attr(diags, ""submodel_classes"")
+  selected
+}
+
 #' @export
 SBC_backend_hash_for_cache.SBC_backend_bridgesampling <- function(backend) {
   backend_for_hash <- backend

---FILE: R/backend-rstan.R---
@@ -157,7 +157,7 @@ SBC_fit_to_diagnostics.RStanOptimizingFit <- function(fit, fit_output, fit_messa
 #' @export
 diagnostic_types.SBC_RStanOptimizing_diagnostics <- function(diags) {
   list(
-    n_attempts = count_diagnostic(""attempts to produce usable Hessian"", report = ""max"", lower_thresh = 1),
+    n_attempts = count_diagnostic(""attempts to produce usable Hessian"", error_above = 1),
     time = numeric_diagnostic(""time"", report = ""max"")
   )
 }

---FILE: R/backend-stan-shared.R---
@@ -1,13 +1,18 @@
 #' @export
 diagnostic_types.SBC_nuts_diagnostics <- function(diags) {
-  list(
-    max_chain_time = numeric_diagnostic(""maximum time per chain"", report = ""max"", digits = 0),
-    n_divergent = count_diagnostic(""divergences"", report = ""max"", error_above = 0),
+  types <- list(
+    max_chain_time = numeric_diagnostic(""time per chain"", report = ""max"", digits = 1),
+    n_divergent = count_diagnostic(""divergences"", error_above = 0),
     n_max_treedepth = count_diagnostic(""iterations that saturated max treedepth"", error_above = 0, label_short = ""max treedepths""),
-    n_rejects = count_diagnostic(""steps rejected"", report = ""max"", error_above = 0),
-    min_bfmi = numeric_diagnostic(""E-BFMI"", report = ""min"", error_below = 0.2, digits = 3),
-    n_failed_chains = count_diagnostic(""failed chains"", error_above = 0)
+    n_rejects = count_diagnostic(""steps rejected"", error_above = 0),
+    min_bfmi = numeric_diagnostic(""E-BFMI"", report = ""min"", error_below = 0.2, digits = 3)
   )
+
+  if(""n_failed_chains"" %in% names(diags)) {
+    types$n_failed_chains <- count_diagnostic(""failed chains"", error_above = 0)
+  }
+
+  types
 }
 
 
@@ -55,7 +60,7 @@ get_expected_max_rhat <- function(n_vars, prob = 0.99, approx_sd = 0.005) {
 diagnostic_types.SBC_ADVI_diagnostics <- function(diags) {
   list(
     elbo_converged = logical_diagnostic(""ELBO converged"", error_value = FALSE),
-    n_rejects = count_diagnostic(""some steps rejected"", report = ""max"", lower_thresh = 0),
+    n_rejects = count_diagnostic(""some steps rejected"", error_above = 0),
     time = numeric_diagnostic(""time"", report = ""max"")
   )
 }

---FILE: R/diagnostics.R---
@@ -1,3 +1,8 @@
+#' @export
+get_diagnostic_messages_single <- function(diagnostic, values) {
+  UseMethod(""get_diagnostic_messages_single"")
+}
+
 #' @export
 numeric_diagnostic <- function(label, report = NULL, error_above = Inf, error_below = -Inf, allow_na = FALSE, label_short = NULL,
                                    hint = """", digits = 2) {
@@ -11,46 +16,6 @@ numeric_diagnostic <- function(label, report = NULL, error_above = Inf, error_be
             class = ""SBC_numeric_diagnostic"")
 }
 
-#' @export
-count_diagnostic <- function(label, error_above = 0, label_short = NULL, hint = """") {
-  if(is.null(label_short)) {
-    label_short <- label
-  }
-  structure(list(label = label,
-                 error_above = error_above,
-                 label_short = label_short,
-                 hint = hint),
-            class = ""SBC_count_diagnostic"")
-}
-
-
-#' @export
-logical_diagnostic <- function(label, error_value, hint = """") {
-  structure(list(label = label,
-                 error_value = error_value,
-                 hint = hint),
-            class = ""SBC_logical_diagnostic"")
-}
-
-#' @export
-submodel_diagnostic <- function(prefix, diag) {
-  structure(list(prefix = prefix,
-                 diag = diag),
-            class = ""SBC_submodel_diagnostic"")
-}
-
-#' @export
-default_diagnostic <- function(col_name) {
-  structure(list(col_name = col_name),
-            class = ""SBC_default_diagnostic"")
-}
-
-#' @export
-get_diagnostic_messages_single <- function(diagnostic, values) {
-  UseMethod(""get_diagnostic_messages_single"")
-}
-
-
 
 #' @export
 get_diagnostic_messages_single.SBC_numeric_diagnostic <- function(diagnostic, values) {
@@ -83,6 +48,11 @@ get_diagnostic_messages_single.SBC_numeric_diagnostic <- function(diagnostic, va
     report <- paste0(""Maximum "", label_for_report, "" was "", round(max(values), digits = diagnostic$digits), "". "")
   } else if(diagnostic$report == ""min"") {
     report <- paste0(""Minimum "", label_for_report, "" was "", round(min(values), digits = diagnostic$digits), "". "")
+  } else if(diagnostic$report == ""quantiles"") {
+    quantiles <- round(quantile(values, probs = c(0.05, 0.5, 0.95)), digits = diagnostic$digits)
+    report <- paste0(label_for_report, "" Q.05 = "", quantiles[1],"", median = "", quantiles[2], "", Q.95 = "", quantiles[3], "". "")
+  } else {
+    stop(paste0(""Unrecognized 'report' value: "", report))
   }
 
 
@@ -103,68 +73,112 @@ get_diagnostic_messages_single.SBC_numeric_diagnostic <- function(diagnostic, va
   msg
 }
 
+
+#' @export
+count_diagnostic <- function(label, error_above = 0, label_short = NULL, hint = """") {
+  if(is.null(label_short)) {
+    label_short <- label
+  }
+  structure(list(label = label,
+                 error_above = error_above,
+                 label_short = label_short,
+                 hint = hint),
+            class = ""SBC_count_diagnostic"")
+}
+
 #' @export
 get_diagnostic_messages_single.SBC_count_diagnostic <- function(diagnostic, values) {
   stopifnot(is.numeric(values) || is.integer(values))
   stopifnot(all(as.integer(values) == values))
 
   any_above_thresh <- any(values > diagnostic$error_above, na.rm = TRUE)
 
-  if(diagnostic$error_above == 0) {
-    threshold_summary <- ""some""
+  report <- paste0(""Maximum number of "", diagnostic$label_short, "" was "", max(values, na.rm = TRUE), "". "")
+
+  if (diagnostic$error_above == Inf) {
+    ok_message <- report
+    threshold_summary <- ""some ""
   } else {
-    threshold_summary <- paste0(""> "", diagnostic$error_above)
+    if (diagnostic$error_above == 0) {
+      threshold_summary <- """"
+      ok_message <- paste0( ""No fits had "",
+              threshold_summary, diagnostic$label, ""."")
+    } else {
+      threshold_summary <- paste0(""> "", diagnostic$error_above, "" "")
+      ok_message <- paste0( ""No fits had "",
+              threshold_summary, diagnostic$label, "". "", report)
+    }
   }
 
+
   if(any_above_thresh) {
     n_above <- sum(values > diagnostic$error_above, na.rm = TRUE)
     msg <- data.frame(ok = FALSE,
                       message = paste0( n_above, "" ("", round(100 * n_above / length(values)), ""%) fits had "",
-                                        threshold_summary,"" "", diagnostic$label, "". Maximum number of "", diagnostic$label_short, "" was "", max(values, na.rm = TRUE), "". "", diagnostic$hint))
+                                        threshold_summary, diagnostic$label, "". "", report, diagnostic$hint))
   } else {
     msg <- data.frame(ok = TRUE,
-                      message = paste0( ""No fits had "",
-                                        threshold_summary,"" "", diagnostic$label, "".""))
+                      message = ok_message)
   }
 
   msg
 }
 
+#' @export
+logical_diagnostic <- function(error_label, error_value, hint = """") {
+  structure(list(error_label = error_label,
+                 error_value = error_value,
+                 hint = hint),
+            class = ""SBC_logical_diagnostic"")
+}
+
 #' @export
 get_diagnostic_messages_single.SBC_logical_diagnostic <- function(diagnostic, values) {
   stopifnot(is.logical(values))
   ok_vec <- (values != diagnostic$error_value)
   if(all(ok_vec)) {
-    msg <- data.frame(ok = TRUE, message = paste0(""No fits "", diagnostic$label,"".""))
+    msg <- data.frame(ok = TRUE, message = paste0(""No fits "", diagnostic$error_label,"".""))
   } else {
     n_fail <- sum(!ok_vec)
     msg <- data.frame(ok = FALSE,
                       message = paste0( n_fail, "" ("", round(100 * n_fail / length(values)), ""%) fits "",
-                                        diagnostic$label,"". "", diagnostic$hint))
-
+                                        diagnostic$error_label,"". "", diagnostic$hint))
   }
 }
 
+#' @export
+submodel_diagnostic <- function(prefix, diag) {
+  structure(list(prefix = prefix,
+                 diag = diag),
+            class = ""SBC_submodel_diagnostic"")
+}
 
 #' @export
 get_diagnostic_messages_single.SBC_submodel_diagnostic <- function(diagnostic, values) {
   msgs <- get_diagnostic_messages_single(diagnostic$diag, values)
-  msgs$message <- paste0(prefix,"": "", msgs$message)
+  msgs$message <- paste0(diagnostic$prefix,"": "", msgs$message)
   msgs
 }
 
+
+#' @export
+default_diagnostic <- function(col_name) {
+  structure(list(col_name = col_name),
+            class = ""SBC_default_diagnostic"")
+}
+
 #' @export
 get_diagnostic_messages_single.SBC_default_diagnostic <- function(diagnostic, values) {
   if(is.logical(values)) {
     n_true <- sum(values, na.rm = TRUE)
     n_na <- sum(is.na(values))
-    data.frame(ok = TRUE, message =
+    data.frame(ok = NA, message =
                  paste0(diagnostic$col_name, "": "", n_true, "" ("", round(100 * n_true / length(values)), ""%) true, "",
                         n_na, "" ("", round(100 * n_na / length(values)), ""%) NA, ""))
   } else if(is.numeric(values) || is.integer(values)) {
     n_na <- sum(is.na(values))
-    data.frame(ok = TRUE, message =
-                 paste0(diagnostic$col_name, "": min = "", min(values, na.rm = TRUE), "" max = "", max(values, na.rm = TRUE), "", "",
+    data.frame(ok = NA, message =
+                 paste0(diagnostic$col_name, "": min = "", round(min(values, na.rm = TRUE), digits = 3), "", max = "", round(max(values, na.rm = TRUE, digits = 3)), "", "",
                         n_na, "" ("", round(100 * n_na / length(values)), ""%) NA, ""))
 
   } else{
@@ -174,11 +188,23 @@ get_diagnostic_messages_single.SBC_default_diagnostic <- function(diagnostic, va
     } else {
       tab_str <- paste0(length(tab), "" values. Most common: "", names(tab)[1], "" - "", tab[1], "" ("", round(100 * tab[1] / length(values)), ""%)"")
     }
-    data.frame(ok = TRUE,
+    data.frame(ok = NA,
                message = paste0(diagnostic$col_name, "": "", tab_str))
   }
 }
 
+# A diagnostic that is ignored for summaries and messages
+#' @export
+skip_diagnostic <- function() {
+  structure(list(), class = ""SBC_skip_diagnostic"")
+}
+
+#' @export
+get_diagnostic_messages_single.SBC_skip_diagnostic <- function(diagnostic, values) {
+  data.frame(ok = logical(), message = character())
+}
+
+
 #' @export
 get_all_diagnostic_messages <- function(diags, types) {
   shared_names <- intersect(names(diags), names(types))

---FILE: R/results.R---
@@ -1220,12 +1220,17 @@ default_diagnostics_types <- function() {
                           ""If this is expected, mark the variable `possibly_constant_var_attribute()` to suppress this message."")
   c(
     list(
-      n_has_na = count_diagnostic(""had some NAs in variables/samples"",
+      n_has_na = count_diagnostic(""some NAs in variables/samples"",
+                                  error_above = 0,
                                       hint = ""If this is expected, mark the variable with `na_valid_var_attribute()` to suppress this message.""),
-      n_na_rhat = count_diagnostic(""had NA Rhat"",
+      n_na_rhat = count_diagnostic(""NA Rhat"",
+                                   error_above = 0,
+                                   hint = possibly_constant_hint),
+      n_na_ess_bulk = count_diagnostic(""NA ess_bulk"",
+                                       error_above = 0,
                                        hint = possibly_constant_hint),
-      n_na_ess_bulk = count_diagnostic(""had NA ess_bulk"", hint = possibly_constant_hint),
-      n_na_ess_tail = count_diagnostic(""had NA ess_tail""),
+      n_na_ess_tail = count_diagnostic(""NA ess_tail"",
+                                       error_above = 0),
       max_rhat = numeric_diagnostic(""maximum Rhat"", label_short = ""Rhat"", report = ""max"", error_above = 1.01, allow_na = TRUE, digits = 3),
       min_ess_bulk = numeric_diagnostic(""bulk ESS"", report = ""min"", allow_na = TRUE, digits = 0),
       min_ess_tail = numeric_diagnostic(""tail ESS"", report = ""min"", allow_na = TRUE, digits = 0),
@@ -1285,7 +1290,10 @@ check_all_SBC_diagnostics <- function(results) {
   msg <- SBC_results_diagnostic_messages(results)
   msg_problems <- dplyr::filter(msg, !ok)
 
-  purrr::walk(msg_problems$message, function(m) { message("" - "", m, appendLF = FALSE) })
+  purrr::walk(msg_problems$message, function(m) { message("" - "", m, appendLF = TRUE) })
+
+  msg_unknown <- dplyr::filter(msg, is.na(ok))
+  purrr::walk(msg_unknown$message, function(m) { cat("" - [???] "", m, ""\n"") })
 
   all_ok <- all(msg$ok)
 
@@ -1318,7 +1326,20 @@ print.SBC_results <- function(x) {
 print.SBC_results_summary <- function(x) {
   cat(""SBC_results with"", x$n_fits, ""total fits.\n"")
 
-  cat(paste0("" - "", x$messages$message, collapse = ""\n""))
+  if(requireNamespace(""crayon"", quietly = TRUE)) {
+    status_string <- dplyr::case_when(
+      is.na(x$messages$ok) ~ crayon::yellow(""[???]""),
+      x$messages$ok ~ crayon::green(""[OK]""),
+      TRUE ~ crayon::red(""[BAD]"")
+    )
+  } else {
+    status_string <- dplyr::case_when(
+      is.na(x$messages$ok) ~ ""[???]"",
+      x$messages$ok ~ ""[OK]"",
+      TRUE ~ ""[BAD]""
+    )
+  }
+  cat(paste0("" - "", status_string, "" "", x$messages$message, collapse = ""\n""))
 
   if(!all(x$messages$ok)) {
     message(""Not all diagnostics are OK.\nYou can learn more by inspecting $default_diagnostics, "",

---FILE: man/rbind.SBC_bridgesampling_diagnostics.Rd---
@@ -0,0 +1,11 @@
+% Generated by roxygen2: do not edit by hand
+% Please edit documentation in R/backend-bridgesampling.R
+\name{rbind.SBC_bridgesampling_diagnostics}
+\alias{rbind.SBC_bridgesampling_diagnostics}
+\title{Custom rbind implementation maintainig information about submodels}
+\usage{
+\method{rbind}{SBC_bridgesampling_diagnostics}(...)
+}
+\description{
+Custom rbind implementation maintainig information about submodels
+}

---FILE: man/select.SBC_bridgesampling_diagnostics.Rd---
@@ -0,0 +1,11 @@
+% Generated by roxygen2: do not edit by hand
+% Please edit documentation in R/backend-bridgesampling.R
+\name{select.SBC_bridgesampling_diagnostics}
+\alias{select.SBC_bridgesampling_diagnostics}
+\title{Custom select implementation maintainig information about submodels}
+\usage{
+\method{select}{SBC_bridgesampling_diagnostics}(diags, ...)
+}
+\description{
+Custom select implementation maintainig information about submodels
+}

---FILE: tests/testthat/test-bridgesampling.R---
@@ -49,3 +49,39 @@ test_that(""combine_var_attributes_for_bf"", {
     )
   )
 })
+
+
+test_that(""bridgesampling_diagnostics_special_treatment"", {
+  diags1 <- structure(data.frame(sim_id = 1L, prob_H1 = 0.5, test_H0 = 0.1, test_H1 = 0.5), class = c(""SBC_bridgesampling_diagnostics"", ""data.frame""))
+  attr(diags1, ""submodel_classes"") <- list(""H0"" = c(""test_class"", ""data.frame""), ""H1"" = c(""test_class2"", ""data.frame""))
+  diags2 <- structure(data.frame(sim_id = 2L, prob_H1 = 0.3, test_H0 = 0.3, test_H1 = 0.3), class = c(""SBC_bridgesampling_diagnostics"", ""data.frame""))
+  attr(diags2, ""submodel_classes"") <- list(""H0"" = c(""test_class"", ""data.frame""), ""H1"" = c(""test_class2"", ""data.frame""))
+  diags3 <- structure(data.frame(sim_id = 3L, prob_H1 = 0.1, test_H0 = 0.5, test_H1 = 0.1), class = c(""SBC_bridgesampling_diagnostics"", ""data.frame""))
+  attr(diags3, ""submodel_classes"") <- list(""H0"" = c(""test_class"", ""data.frame""), ""H1"" = c(""test_class2"", ""data.frame""))
+
+  diags_bound <- rbind(diags1, diags2, diags3)
+
+  diags_expected <- structure(data.frame(sim_id = 1:3, prob_H1 = c(0.5, 0.3,0.1), test_H0 = c(0.1, 0.3, 0.5), test_H1 = c(0.5, 0.3, 0.1)), class = c(""SBC_bridgesampling_diagnostics"", ""data.frame""))
+  attr(diags_expected, ""submodel_classes"") <- list(""H0"" = c(""test_class"", ""data.frame""), ""H1"" = c(""test_class2"", ""data.frame""))
+
+  expect_identical(diags_bound, diags_expected)
+
+  diags_mismatched <- structure(data.frame(sim_id = 4L, prob_H1 = 1, test_H0 = 1, test_H1 = 1), class = c(""SBC_bridgesampling_diagnostics"", ""data.frame""))
+  attr(diags_mismatched, ""submodel_classes"") <- list(""H0"" = c(""other_class"", ""data.frame""), ""H1"" = c(""test_class2"", ""data.frame""))
+
+  diags_bound_mismatch <- expect_warning(rbind(diags1, diags2, diags3, diags_mismatched), ""Non-unique submodel classes"")
+
+  diags_expected_mismatch <- structure(data.frame(sim_id = 1:4, prob_H1 = c(0.5, 0.3,0.1, 1), test_H0 = c(0.1, 0.3, 0.5, 1), test_H1 = c(0.5, 0.3, 0.1, 1)), class = c(""SBC_bridgesampling_diagnostics"", ""data.frame""))
+  attr(diags_expected_mismatch, ""submodel_classes"") <- list(""H0"" = c(""test_class"", ""data.frame""), ""H1"" = c(""test_class2"", ""data.frame""))
+
+  expect_identical(diags_bound_mismatch, diags_expected_mismatch)
+
+  library(dplyr)
+  diags_selected <- select(diags_bound, -sim_id)
+  diags_selected_expected <- select(as.data.frame(diags_bound), -sim_id)
+  class(diags_selected_expected) <- c(""SBC_bridgesampling_diagnostics"", ""data.frame"")
+  attr(diags_selected_expected, ""submodel_classes"") <- list(""H0"" = c(""test_class"", ""data.frame""), ""H1"" = c(""test_class2"", ""data.frame""))
+
+  expect_identical(diags_selected, diags_selected_expected)
+
+})

---FILE: vignettes/implementing_backends.Rmd---
@@ -233,7 +233,7 @@ For this reason, SBC package will capture all output, warnings and messages
 that the backend produced and our implementation can then inspect and process
 all of the output. This can be achieved by implementing the `SBC_fit_to_diagnostics()`
 generic for our fit object. This method should return a single row `data.frame`
-that contains any diagnostics. 
+that contains any diagnostics.
 This is our implementation for the `glm` class:
 
 
@@ -248,20 +248,30 @@ SBC_fit_to_diagnostics.glm <- function(fit, fit_output, fit_messages, fit_warnin
 }
 ```
 
-If we want to automatically signal problems with the diagnostics, we
-need to let SBC know when a diagnostic is bad. We do this by
-implementing the `diagnostic_types()` generic for our backend ---
+We have added an extra class (`SBC_glm_diagnostics`) to the result to let us
+provide additional functionality for the diagnostics. Otherwise there is no
+way for the `SBC` package to know that for `probs_0_1` problems 
+are signalled by `TRUE` value while for `converged` problems are signalled by
+`FALSE` value.
+
+Specifically, to provide nice reporting and automatically signal problems with 
+the diagnostics, we can implement the `diagnostic_types()` generic for the class
+of the results ---
 this should return a named list where each element describes a single diagnostic:
 
 ```{r}
 diagnostic_types.SBC_glm_diagnostics <- function(x) {
   list(
-    probs_0_1 = logical_diagnostic(""had 0/1 probabilities"", error_value = TRUE),
-    converged = logical_diagnostic(""had convergence problems"", error_value = FALSE)
+    probs_0_1 = logical_diagnostic(error_label = ""had 0/1 probabilities"", error_value = TRUE),
+    converged = logical_diagnostic(error_label = ""had convergence problems"", error_value = FALSE)
   )
 }
 ```
 
+You typically want to the predefined functions like `logical_diagnostic()`, 
+`numeric_diagnostic()` and `count_diagnostic()` for most typical diagnostic
+values.
+
 ```{r}
 #TODO implement CDFs once there more use for them
 ```",True,True,Documentation / Formatting,6
hyunjimoon,SBC,1e4263de47153f43a7a7c31a527a635b8fb00c28,Martin Modrák,modrak.mar@gmail.com,2025-09-10T13:20:51Z,Martin Modrák,modrak.mar@gmail.com,2025-09-10T13:20:51Z,Fix default diagnostics aroung NAs and Infs and handling of the related var_attributes(),R/results.R;R/var_attributes.R;tests/testthat/test-results.R;tests/testthat/test-var_attributes.R,False,True,True,False,135,25,160,"---FILE: R/results.R---
@@ -29,13 +29,23 @@ SBC_results <- function(stats,
 
 
 compute_default_diagnostics <- function(stats) {
+  # Putting default values to make previously cached results valid
   if(is.null(stats$attributes)) {
     stats$attributes <- """"
   }
-  eligible_for_check <- function(value, attributes) {
-    value[!is.na(value)
-          | !attribute_present_stats(possibly_constant_var_attribute(), attributes)
-          ]
+  if(is.null(stats$all_na)) {
+    stats$all_na <- rep(FALSE, nrow(stats))
+  }
+  if(is.null(stats$all_inf)) {
+    stats$all_inf <- rep(FALSE, nrow(stats))
+  }
+
+  eligible_for_check <- function(value, all_inf, all_na, attributes) {
+    exclude_for_possibly_constant <- (is.na(value)
+                       & attribute_present_stats(possibly_constant_var_attribute(), attributes))
+    exclude_for_all_na <- all_na & attribute_present_stats(na_valid_var_attribute(), attributes)
+    exclude_for_all_inf <- all_inf & attribute_present_stats(inf_valid_var_attribute(), attributes)
+    value[(!exclude_for_possibly_constant) & (!exclude_for_all_na) & (!exclude_for_all_inf)]
   }
 
   should_check_na <- function(attributes) {
@@ -45,13 +55,13 @@ compute_default_diagnostics <- function(stats) {
   val <- dplyr::summarise(dplyr::group_by(stats, sim_id),
                    n_vars = dplyr::n(),
                    n_has_na = sum(has_na & should_check_na(attributes)),
-                   n_na_rhat = sum(is.na(eligible_for_check(rhat, attributes))),
-                   n_na_ess_bulk = sum(is.na(eligible_for_check(ess_bulk, attributes))),
-                   n_na_ess_tail = sum(is.na(eligible_for_check(ess_tail, attributes))),
-                   max_rhat = max(c(-Inf, eligible_for_check(rhat, attributes)), na.rm = TRUE),
-                   min_ess_bulk = min(c(Inf, eligible_for_check(ess_bulk, attributes))),
-                   min_ess_tail = min(c(Inf, eligible_for_check(ess_tail, attributes))),
-                   min_ess_to_rank = min(c(Inf, eligible_for_check(ess_tail / max_rank, attributes))),
+                   n_na_rhat = sum(is.na(eligible_for_check(rhat, all_inf, all_na, attributes))),
+                   n_na_ess_bulk = sum(is.na(eligible_for_check(ess_bulk, all_inf, all_na, attributes))),
+                   n_na_ess_tail = sum(is.na(eligible_for_check(ess_tail, all_inf, all_na, attributes))),
+                   max_rhat = max(c(-Inf, eligible_for_check(rhat, all_inf, all_na, attributes)), na.rm = TRUE),
+                   min_ess_bulk = min(c(Inf, eligible_for_check(ess_bulk, all_inf, all_na, attributes))),
+                   min_ess_tail = min(c(Inf, eligible_for_check(ess_tail, all_inf, all_na, attributes))),
+                   min_ess_to_rank = min(c(Inf, eligible_for_check(ess_tail / max_rank, all_inf, all_na, attributes))),
                    .groups = ""drop""
                    )
 
@@ -334,6 +344,14 @@ compute_results <- function(...) {
   compute_SBC(...)
 }
 
+# A simple vector that can serve as stats when those cannot be computed
+dummy_stats <- function() {
+  data.frame(sim_id = integer(0), rhat = numeric(0), ess_bulk = numeric(0),
+             ess_tail = numeric(0), has_na = logical(0),
+             rank = integer(0), simulated_value = numeric(0), max_rank = integer(0),
+             attributes = character(0))
+}
+
 #' Fit datasets and evaluate diagnostics and SBC metrics.
 #'
 #' Performs the main SBC routine given datasets and a backend.
@@ -665,15 +683,13 @@ compute_SBC <- function(datasets, backend,
                 iid_draws = SBC_backend_iid_draws(backend))
   } else {
     # Return dummy stats that let the rest of the code work.
-    stats <- data.frame(sim_id = integer(0), rhat = numeric(0), ess_bulk = numeric(0),
-                        ess_tail = numeric(0), has_na = logical(0),
-                        rank = integer(0), simulated_value = numeric(0), max_rank = integer(0),
-                        attributes = character(0))
+    stats <- dummy_stats()
   }
 
   default_diagnostics <-  tryCatch(
     { compute_default_diagnostics(stats) },
-    error = function(e) { warning(""Error when computing default per-variable diagnostics. "", e); NULL })
+    error = function(e) { warning(""Error when computing default per-variable diagnostics. "", e);
+      compute_default_diagnostics(dummy_stats())})
 
 
   res <- SBC_results(stats = stats, fits = fits, outputs = outputs,
@@ -910,11 +926,19 @@ SBC_statistics_from_single_fit <- function(fit, variables, generated,
   for(i in 1:length(shared_vars)) {
     var <- shared_vars[i]
     var_draws <- fit_matrix[,var]
-    stats$mean[i] <- mean(var_draws, na.rm = na_valid[i])
-    stats$sd[i] <- sd(var_draws, na.rm = na_valid[i])
-    stats$q5[i] <- quantile(var_draws, prob = 0.05, na.rm = na_valid[i])
-    stats$median[i] <- median(var_draws, na.rm = na_valid[i])
-    stats$q95[i] <- quantile(var_draws, prob = 0.95, na.rm = na_valid[i])
+    if(!na_valid[i] & any(is.na(var_draws))) {
+      stats$mean[i] <- NA_real_
+      stats$sd[i] <- NA_real_
+      stats$q5[i] <- NA_real_
+      stats$median[i] <- NA_real_
+      stats$q95[i] <- NA_real_
+    } else {
+      stats$mean[i] <- mean(var_draws, na.rm = TRUE)
+      stats$sd[i] <- sd(var_draws, na.rm = TRUE)
+      stats$q5[i] <- quantile(var_draws, prob = 0.05, na.rm = TRUE)
+      stats$median[i] <- median(var_draws, na.rm = TRUE)
+      stats$q95[i] <- quantile(var_draws, prob = 0.95, na.rm = TRUE)
+    }
 
     if(SBC_backend_iid_draws(backend)) {
       ## iid draws have the bestest diagnostics by construction
@@ -925,11 +949,13 @@ SBC_statistics_from_single_fit <- function(fit, variables, generated,
       draws_for_diags <- var_draws
       if(inf_valid[i]) {
         finite_draws <- draws_for_diags[is.finite(draws_for_diags)]
-        draws_for_diags[draws_for_diags == -Inf] <- min(finite_draws) - 1
-        draws_for_diags[draws_for_diags == +Inf] <- max(finite_draws) + 1
+        if(length(finite_draws) > 0) {
+          draws_for_diags[draws_for_diags == -Inf] <- min(finite_draws) - 1
+          draws_for_diags[draws_for_diags == +Inf] <- max(finite_draws) + 1
+        }
       }
       if(na_valid[i]) {
-        draws_for_diags[is.na(draws_for_diags)] <- median(draws_for_diags)
+        draws_for_diags[is.na(draws_for_diags)] <- median(draws_for_diags, na.rm = TRUE)
       }
       stats$rhat[i] <- posterior::rhat(draws_for_diags)
       stats$ess_bulk[i] <- posterior::ess_bulk(draws_for_diags)
@@ -962,6 +988,8 @@ SBC_statistics_from_single_fit <- function(fit, variables, generated,
   stats$max_rank <- attr(ranks, ""max_rank"")
   stats$z_score <- (stats$simulated_value - stats$mean) / stats$sd
   stats$has_na <- as.logical(apply(fit_thinned, MARGIN = 2, FUN = \(x) any(is.na(x))))
+  stats$all_na <- as.logical(apply(fit_thinned, MARGIN = 2, FUN = \(x) all(is.na(x))))
+  stats$all_inf <- as.logical(apply(fit_thinned, MARGIN = 2, FUN = \(x) all(is.infinite(x))))
 
   variables_dbl <- as.numeric(variables)
   names(variables_dbl) <- posterior::variables(variables)

---FILE: R/var_attributes.R---
@@ -80,7 +80,8 @@ variable_names_to_var_attributes_names <- function(variable_names) {
 #' `inf_valid_var_attribute` means infinity values may appear in the samples
 #' (this is useful e.g. to note that the parameter is actually not present for the
 #' given draw). Setting this
-#' attribute also changes the ESS/Rhat computation to ignore infinities.
+#' attribute also changes the ESS/Rhat computation to ignore infinities. It
+#' is also assume that it is OK if _all_ of the draws are infinity.
 #'
 #' `submodel_var_attribute` signals that the parameter belongs to a submodel
 #' which can be extracted individually

---FILE: tests/testthat/test-results.R---
@@ -256,3 +256,7 @@ test_that(""SBC_statistics_from_single_fit"", {
     expect_equal(unique(res_ensure7$max_rank), 97)
 
 })
+
+test_that(""dummy_stats"", {
+  expect_no_error(compute_default_diagnostics(dummy_stats()))
+})

---FILE: tests/testthat/test-var_attributes.R---
@@ -94,3 +94,80 @@ test_that(""remove_attribute_from_stats"", {
   expect_identical(remove_attribute_from_stats(""ab(44)"", ""a,b,cab,ab(44)""), ""a,b,cab"")
   expect_identical(remove_attribute_from_stats(""ab(44)"", ""a,b,cab,ab(21)""), ""a,b,cab,ab(21)"")
 })
+
+
+test_that(""compute_default_diagnostics_and_attributes"", {
+  example_fit <- posterior::draws_matrix(only_inf = rep(Inf, 300),
+                                         one_inf = c(Inf, rnorm(299)),
+                                         only_NA = rep(NA, 300),
+                                         one_NA = c(NA, rnorm(299)))
+
+  variables <- posterior::draws_matrix(only_inf = Inf,
+                                       one_inf = 0,
+                                       only_NA = NA,
+                                       one_NA = 0)
+
+
+  stats_no_attr <-
+    SBC_statistics_from_single_fit(example_fit, variables = variables,
+                                 generated = list(),
+                                 thin_ranks = 1,
+                                 ensure_num_ranks_divisor = 1,
+                                 dquants = NULL,
+                                 backend = NULL
+                                 )
+
+  expect_identical(is.na(stats_no_attr$q5), c(F, F, T, T))
+  expect_identical(is.na(stats_no_attr$rhat), c(T, F, T, T))
+  expect_identical(is.na(stats_no_attr$ess_bulk), c(T, F, T, T))
+  expect_identical(is.na(stats_no_attr$ess_tail), c(T, T, T, T))
+
+  expect_identical(stats_no_attr$has_na, c(F, F, T, T))
+  expect_identical(stats_no_attr$all_inf, c(T, F, F, F))
+
+  stats_attr <-
+    SBC_statistics_from_single_fit(example_fit, variables = variables,
+                                 generated = list(),
+                                 thin_ranks = 1,
+                                 ensure_num_ranks_divisor = 1,
+                                 dquants = NULL,
+                                 backend = NULL,
+                                 var_attributes = var_attributes(
+                                   only_inf = inf_valid_var_attribute(),
+                                   one_inf = inf_valid_var_attribute(),
+                                   only_NA = na_valid_var_attribute(),
+                                   one_NA = na_valid_var_attribute())
+  )
+
+
+  expect_identical(is.na(stats_attr$q5), c(F, F, T, F))
+  expect_identical(is.na(stats_attr$rhat), c(T, F, T, F))
+  expect_identical(is.na(stats_attr$ess_bulk), c(T, F, T, F))
+  expect_identical(is.na(stats_attr$ess_tail), c(T, F, T, F))
+
+  expect_identical(stats_attr$has_na, c(F, F, T, T))
+  expect_identical(stats_attr$all_inf, c(T, F, F, F))
+
+
+  stats_no_attr$sim_id <- 1
+  diag_no_attr <- compute_default_diagnostics(stats_no_attr)
+  expect_equal(diag_no_attr$n_has_na, 2)
+  expect_equal(diag_no_attr$n_na_rhat, 3)
+  expect_equal(diag_no_attr$n_na_ess_bulk, 3)
+  expect_equal(diag_no_attr$n_na_ess_tail, 4)
+  expect_true(is.na(diag_no_attr$min_ess_bulk))
+  expect_true(is.na(diag_no_attr$min_ess_tail))
+  expect_true(is.na(diag_no_attr$min_ess_to_rank))
+
+  stats_attr$sim_id <- 1
+  diag_attr <- compute_default_diagnostics(stats_attr)
+  expect_equal(diag_attr$n_has_na, 0)
+  expect_equal(diag_attr$n_na_rhat, 0)
+  expect_equal(diag_attr$n_na_ess_bulk, 0)
+  expect_equal(diag_attr$n_na_ess_tail, 0)
+  expect_false(is.na(diag_attr$min_ess_bulk))
+  expect_false(is.na(diag_attr$min_ess_tail))
+  expect_false(is.na(diag_attr$min_ess_to_rank))
+
+
+})",True,False,Implementation / Logic,6
hyunjimoon,SBC,bfc46cca3ff9875f28025c4b603a6428a2b9d377,Martin Modrák,modrak.mar@gmail.com,2025-09-09T08:57:42Z,Martin Modrák,modrak.mar@gmail.com,2025-09-09T08:57:42Z,Fixed misreporting warnings in summary of SBC_results,R/results.R,False,True,True,False,2,2,4,"---FILE: R/results.R---
@@ -1261,7 +1261,7 @@ summary.SBC_results <- function(x) {
   summ <- list(
     n_fits = length(x$fits),
     n_errors = sum(!purrr::map_lgl(x$errors, is.null)),
-    n_warnings = sum(purrr::map_lgl(x$messages, ~ !is.null(.x) && any(x$type == ""warning""))),
+    n_warnings = sum(!purrr::map_lgl(x$warnings, is.null)),
 
     # ifelse required for backwards compatibility with caches from 0.3 or below
     n_has_na = if(""n_has_na"" %in% names(x$default_diagnostics)) { sum(x$default_diagnostics$n_has_na > 0) }  else {  0 },
@@ -1306,7 +1306,7 @@ get_diagnostic_messages.SBC_results_summary <- function(x) {
   i <- i + 1
 
   if(x$n_warnings > 0) {
-    msg <- paste0(x$n_warnings, "" ("", round(100 * x$n_warnings / x$n_fits), ""%) fits gave warnings. Inspect $messages to see them."")
+    msg <- paste0(x$n_warnings, "" ("", round(100 * x$n_warnings / x$n_fits), ""%) fits gave warnings. Inspect $warnings to see them."")
     message_list[[i]] <- data.frame(ok = TRUE, message = msg)
   } else {
     message_list[[i]] <- data.frame(ok = TRUE, message = ""No fits gave warnings."")",True,False,Implementation / Logic,6
hyunjimoon,SBC,72f3ebede5e2e3b053c84d48b0bfa6ec64e9bdef,Martin Modrák,modrak.mar@gmail.com,2025-09-04T11:42:18Z,Martin Modrák,modrak.mar@gmail.com,2025-09-04T11:42:18Z,Fix bin calculation bug,R/binary-calibration.R,False,True,True,False,1,1,2,"---FILE: R/binary-calibration.R---
@@ -76,7 +76,7 @@ binary_calibration_from_bp <- function(bp, type = c(""reliabilitydiag"", ""calibrat
 
   max_sims <- max(dplyr::tally(bp_grouped)$n)
   attr(res, ""bp"") <- bp
-  attr(res, ""bins"") <- max(2, min(100, max_sims / 10))
+  attr(res, ""bins"") <- max(2, min(100, ceiling(max_sims / 10)))
   return(res)
 }
 ",True,False,Implementation / Logic,3
hyunjimoon,SBC,895561d9cd7df394027f6207391a6ce02eb237a0,Martin Modrák,modrak.mar@gmail.com,2025-08-10T17:10:47Z,Martin Modrák,modrak.mar@gmail.com,2025-08-10T17:10:47Z,"Better error messages, bugfixes",R/backend-bridgesampling.R;R/binary-calibration.R;R/datasets.R,False,True,True,False,52,19,71,"---FILE: R/backend-bridgesampling.R---
@@ -22,7 +22,7 @@ SBC_backend_bridgesampling <- function(backend_H0, backend_H1, model_var = ""mode
 #'
 #' @param backend the underlying backend
 #' @param fit corresponding to the backend
-#' @param generated
+#' @param generated the generated data used to fit the underlying model
 #' @param ... passed to [bridgesampling::bridge_sampler()].
 #' @returns an object of class `bridge` or `bridge_list`.
 #' @seealso [bridgesampling::bridge_sampler()]
@@ -76,6 +76,11 @@ SBC_fit_bridgesampling_to_prob1 <- function(fit, log.p = FALSE) {
   } else {
     log_bf_01 <- bf_res$bf
   }
+  if(is.na(log_bf_01)) {
+    print(fit$bridge_H0)
+    print(fit$bridge_H1)
+    stop(""Bayes factor is NA."")
+  }
   prior_log <- log(fit$prior_prob1) - log1p( -fit$prior_prob1)
   prob1 <- plogis(-log_bf_01 + prior_log, log.p = log.p)
   return(prob1)

---FILE: R/binary-calibration.R---
@@ -43,16 +43,22 @@ binary_probabilities_from_stats <- function(stats) {
 #' it needs to be a `data.frame` with columns `variable`, `prob` and `simulated_value`.
 #' @param type the type of calibration uncertainty bands to compute, see details.
 #' @param alpha the level associated with the confidence intervals reports
+#' @param region.position for `type =""reliabilitydiag""` we may choose whether
+#' the uncertainty interval surrounds the estimate (`region.position = ""estimate""`)
+#' or the null distribution (`region.position = ""diagonal""`)
 #' @param ... additional arguments passed to
 #'  [reliabilitydiag::reliabilitydiag()] or [calibrationband::calibration_bands()]
 #'
 #' @details
-#' When `type = ""reliabilitydiag""`, the intervals are for the null distribution
-#' assuming perfect calibration using [reliabilitydiag::reliabilitydiag()].
+#' When `type = ""reliabilitydiag""`, the intervals are based on
+#' [reliabilitydiag::reliabilitydiag()] and depending on `region.position`
+#' can be centered on the null distribution of perfect calibration or on the
+#' estimated calibration.
 #' When `type = ""calibrationband""` the intervals
-#' are around the observed calibration using [calibrationband::calibration_bands()]
+#' are around the estimated calibration using [calibrationband::calibration_bands()]
 #' --- in our experience the `calibrationband`
-#' method has less sensitivity to detect miscalibration.
+#' method has less sensitivity to detect miscalibration, but they require
+#' somewhat weaker assumptions.
 #'
 #' @returns `binary_calibration_from_bp` returns a `data.frame` with columns `variable`, `prob`, `estimate`, `low` and `high`,
 #' for each variable, it contains an estimate + confidence interval across a range
@@ -63,18 +69,18 @@ binary_probabilities_from_stats <- function(stats) {
 #'
 #' @rdname binary_calibration
 #' @export
-binary_calibration_from_bp <- function(bp, type = c(""reliabilitydiag"", ""calibrationband""), alpha = 0.05, ...) {
+binary_calibration_from_bp <- function(bp, type = c(""reliabilitydiag"", ""calibrationband""), alpha = 0.05, ..., region.position = NULL) {
 
   bp_grouped <- dplyr::group_by(bp, variable)
-  res <- dplyr::reframe(bp_grouped, binary_calibration_base(prob, simulated_value, type = type, uncertainty_prob = 1 - alpha, ...))
+  res <- dplyr::reframe(bp_grouped, binary_calibration_base(prob, simulated_value, type = type, uncertainty_prob = 1 - alpha, region.position = region.position, ...))
 
   max_sims <- max(dplyr::tally(bp_grouped)$n)
   attr(res, ""bp"") <- bp
-  attr(res, ""bins"") <- min(100, max_sims / 10)
+  attr(res, ""bins"") <- max(2, min(100, max_sims / 10))
   return(res)
 }
 
-binary_calibration_base <- function(prob, outcome, uncertainty_prob = 0.95, type = c(""reliabilitydiag"", ""calibrationband""), ...) {
+binary_calibration_base <- function(prob, outcome, uncertainty_prob = 0.95, type = c(""reliabilitydiag"", ""calibrationband""), ..., region.position = NULL) {
   stopifnot(is.numeric(prob))
   stopifnot((is.numeric(outcome) || is.logical(outcome) || is.integer(outcome)))
   outcome <- as.numeric(outcome)
@@ -89,22 +95,40 @@ binary_calibration_base <- function(prob, outcome, uncertainty_prob = 0.95, type
 
   type <- match.arg(type)
   if(type == ""reliabilitydiag"") {
+    list_args <- list(...)
+    if(is.null(region.position)) {
+      region.position <- ""diagonal""
+    }
+
+
     require_package_version(""reliabilitydiag"", ""0.2.1"", ""to compute binary calibration with the type 'reliabilitydiag'."")
     rel_diag <- reliabilitydiag::reliabilitydiag(
       x = prob,
       y = outcome,
       region.level = uncertainty_prob,
+      region.position = region.position,
       ...
     )
     res <- data.frame(prob = rel_diag$x$regions$x, low = rel_diag$x$regions$lower, high = rel_diag$x$regions$upper)
     res$estimate <- approx(x = c(rel_diag$x$bins$x_min, rel_diag$x$bins$x_max),
                            y = rep(rel_diag$x$bins$CEP_pav, times = 2),
                            xout = res$prob)$y
-    res$interval_type = ""null""
+
+    if(region.position == ""diagonal"") {
+      res$interval_type = ""null""
+    } else if(region.position == ""estimate"") {
+      res$interval_type = ""estimate""
+    } else {
+      stop(""unrecognized region.position"")
+    }
 
     return(res)
   } else if(type == ""calibrationband"") {
     require_package_version(""calibrationband"", ""0.2"", ""to compute binary calibration with the type 'calibrationband'."")
+
+    if(!is.null(region.position) && region.position != ""estimate"") {
+      stop(""calibrationband only supports region.position = 'estimate'"")
+    }
     # Need to remove extreme indices because they cause crashes in the package
     extreme_indices <- prob < 1e-10 | prob > 1 - 1e-10
     extreme_indices_mismatch <- extreme_indices & round(prob) != outcome
@@ -130,7 +154,7 @@ binary_calibration_base <- function(prob, outcome, uncertainty_prob = 0.95, type
     estimate_isoy <- c(0, data_estimate_raw$isoy, 1)
 
     res$estimate <- approx(estimate_x, estimate_isoy, xout = res$prob, ties = ""mean"")$y
-    res$interval_type = ""observed""
+    res$interval_type = ""estimate""
 
     return(res)
   } else {
@@ -155,7 +179,7 @@ calibration_prob_hist_geom <- function(calib_df) {
 #' be overlaid with the calibration curve.
 #' @rdname binary_calibration
 #' @export
-plot_binary_calibration_diff <- function(x, type = c(""reliabilitydiag"", ""calibrationband""), alpha = 0.05, ..., prob_histogram = TRUE) {
+plot_binary_calibration_diff <- function(x, type = c(""reliabilitydiag"", ""calibrationband""), alpha = 0.05, ..., region.position = NULL, prob_histogram = TRUE) {
    UseMethod(""plot_binary_calibration_diff"", x)
 }
 
@@ -170,8 +194,8 @@ plot_binary_calibration_diff.SBC_results <- function(res, ...) {
 
 #' @rdname binary_calibration
 #' @export
-plot_binary_calibration_diff.data.frame <- function(bp, type = c(""reliabilitydiag"", ""calibrationband""), alpha = 0.05, ..., prob_histogram = TRUE) {
-  calib_df <- binary_calibration_from_bp(bp, type = type, alpha = alpha, ...)
+plot_binary_calibration_diff.data.frame <- function(bp, type = c(""reliabilitydiag"", ""calibrationband""), alpha = 0.05, ..., region.position = NULL, prob_histogram = TRUE) {
+  calib_df <- binary_calibration_from_bp(bp, type = type, alpha = alpha, region.position = region.position, ...)
 
   if(prob_histogram) {
     hist_geom <- calibration_prob_hist_geom(calib_df)
@@ -183,7 +207,7 @@ plot_binary_calibration_diff.data.frame <- function(bp, type = c(""reliabilitydia
     hist_geom +
     geom_segment(x = 0, y = 0, xend = 1, yend = 0, color = ""skyblue1"", size = 2) +
     geom_ribbon(aes(fill = interval_type), alpha = 0.33) +
-    scale_fill_manual(values = c(""null"" = ""skyblue1"", ""observed"" = ""black""), guide = ""none"") +
+    scale_fill_manual(values = c(""null"" = ""skyblue1"", ""estimate"" = ""black""), guide = ""none"") +
     geom_line() + facet_wrap(~variable)
 }
 
@@ -192,7 +216,7 @@ plot_binary_calibration_diff.data.frame <- function(bp, type = c(""reliabilitydia
 #' be overlaid with the calibration curve.
 #' @rdname binary_calibration
 #' @export
-plot_binary_calibration <- function(x, type = c(""reliabilitydiag"", ""calibrationband""), alpha = 0.05, ..., prob_histogram = TRUE) {
+plot_binary_calibration <- function(x, type = c(""reliabilitydiag"", ""calibrationband""), alpha = 0.05, ..., region.position = NULL, prob_histogram = TRUE) {
   UseMethod(""plot_binary_calibration"", x)
 }
 
@@ -207,8 +231,8 @@ plot_binary_calibration.SBC_results <- function(res, ...) {
 
 #' @rdname binary_calibration
 #' @export
-plot_binary_calibration.data.frame <- function(bp, type = c(""reliabilitydiag"", ""calibrationband""), ..., prob_histogram = TRUE) {
-  calib_df <- binary_calibration_from_bp(bp, type = type, ...)
+plot_binary_calibration.data.frame <- function(bp, type = c(""reliabilitydiag"", ""calibrationband""), ..., region.position = NULL, prob_histogram = TRUE) {
+  calib_df <- binary_calibration_from_bp(bp, type = type, ..., region.position = region.position)
 
   if(prob_histogram) {
     hist_geom <- calibration_prob_hist_geom(calib_df)
@@ -221,6 +245,6 @@ plot_binary_calibration.data.frame <- function(bp, type = c(""reliabilitydiag"", ""
     hist_geom +
     geom_segment(x = 0, y = 0, xend = 1, yend = 1, color = ""skyblue1"", size = 2) +
     geom_ribbon(aes(fill = interval_type), alpha = 0.33) +
-    scale_fill_manual(values = c(""null"" = ""skyblue1"", ""observed"" = ""black""), guide = ""none"") +
+    scale_fill_manual(values = c(""null"" = ""skyblue1"", ""estimate"" = ""black""), guide = ""none"") +
     geom_line() + facet_wrap(~variable) + coord_fixed()
 }

---FILE: R/datasets.R---
@@ -90,6 +90,10 @@ length.SBC_datasets <- function(x) {
 #' @export
 `[.SBC_datasets` <- function(x, indices) {
   validate_SBC_datasets(x)
+  if(is.logical(indices)) {
+    stopifnot(length(indices) == length(x))
+    indices <- which(indices)
+  }
   res <- new_SBC_datasets(posterior::subset_draws(x$variables, draw = indices, unique = FALSE),
                    x$generated[indices],
                    var_attributes = x$var_attributes)",True,False,Implementation / Logic,6
hyunjimoon,SBC,ce8cc5df3ec932f785df55de96772f8fd6c5db54,Martin Modrák,modrak.mar@gmail.com,2025-08-08T19:00:59Z,Martin Modrák,modrak.mar@gmail.com,2025-08-08T19:00:59Z,Fixed bug in brms + rstan,R/brms-helpers.R,False,True,True,False,1,1,2,"---FILE: R/brms-helpers.R---
@@ -116,9 +116,9 @@ variational_backend_from_stanmodel <- function(stanmodel, args) {
 
 brmsfit_from_stanfit <- function(fit, brmsargs) {
   fit_brms <- do.call(brms::brm, combine_args(brmsargs, list(empty = TRUE)))
-  variables <- fit$metadata()$stan_variables
   exclude <- brms:::exclude_pars(fit_brms)
   if(inherits(fit, ""CmdStanFit"")) {
+    variables <- fit$metadata()$stan_variables
     fit_brms$fit <- brms::read_csv_as_stanfit(fit$output_files(),
       variables = variables, exclude = exclude, algorithm = fit_brms$algorithm)
     if(inherits(fit, ""CmdStanVB"")) {",True,False,Implementation / Logic,3
hyunjimoon,SBC,188b309178be81cc6a035e91d0eb0cf088f23536,Martin Modrák,modrak.mar@gmail.com,2025-08-08T14:50:11Z,Martin Modrák,modrak.mar@gmail.com,2025-08-08T14:50:11Z,Fix themes,R/backend-function.R;examples/backend-function-example.R;vignettes/SBC.Rmd,True,True,True,False,7,2,9,"---FILE: R/backend-function.R---
@@ -1,7 +1,7 @@
 #' A backend that just calls a function.
 #'
 #' If the function returns a `draws_matrix` object, no other
-#' work is necessary to make it work with SBC.
+#' work is necessary to make it work with SBC. Useful for quick tests.
 #'
 #' @param func the function that will be called in [SBC_fit()]
 #' @param generated_arg name of the argument of `func` that will receive the

---FILE: examples/backend-function-example.R---
@@ -4,6 +4,9 @@
 # See https://math.stackexchange.com/a/5085538/423833 for derivation that it
 # is generalized gamma distribution. Here we test this is correct.
 
+library(ggplot2)
+theme_set(theme_minimal())
+
 N_sims <- 100
 df <- 5
 z <- rnorm(N_sims)

---FILE: vignettes/SBC.Rmd---
@@ -129,7 +129,8 @@ In this vignette we will demonstrate how the interface is used with a simple poi
 setup and configure our environment.
 
 ```{r setup, message=FALSE,warning=FALSE, results=""hide""}
-library(SBC);
+library(SBC)
+library(ggplot2)
 
 use_cmdstanr <- getOption(""SBC.vignettes_cmdstanr"", TRUE) # Set to false to use rstan instead
 
@@ -161,6 +162,7 @@ if(!dir.exists(cache_dir)) {
   dir.create(cache_dir)
 }
 
+theme_set(theme_minimal())
 ```
 
 ```{r enable progressr, eval = FALSE}",True,True,Documentation / Formatting,6
hyunjimoon,SBC,7d717ca718f8aa0adf039f3155552635c0398955,Martin Modrák,modrak.mar@gmail.com,2025-08-08T14:22:45Z,Martin Modrák,modrak.mar@gmail.com,2025-08-08T14:22:45Z,"Extend docs, fix bugs",R/backend-bridgesampling.R;R/bayes_factors.R;R/binary-calibration-tests.R;R/binary-calibration.R;R/results.R;_pkgdown.yml;vignettes/bayes_factor.Rmd;vignettes/discrete_vars.Rmd,True,True,True,False,88,28,116,"---FILE: R/backend-bridgesampling.R---
@@ -14,7 +14,17 @@ SBC_backend_bridgesampling <- function(backend_H0, backend_H1, model_var = ""mode
 }
 
 #' Convert a fit for a given backend into a bridge sampler object.
+#'
+#' @description
+#' Users should typically not call this method and instead let
+#' [SBC_backend_bridgesampling()] to call it for them.
+#'
+#'
+#' @param backend the underlying backend
+#' @param fit corresponding to the backend
+#' @param generated
 #' @param ... passed to [bridgesampling::bridge_sampler()].
+#' @returns an object of class `bridge` or `bridge_list`.
 #' @seealso [bridgesampling::bridge_sampler()]
 #' @export
 SBC_fit_to_bridge_sampler <- function(backend, fit, generated, ...) {

---FILE: R/bayes_factors.R---
@@ -97,6 +97,16 @@ combine_var_attributes_for_bf <- function(dm0, dm1, var_attr0, var_attr1, model_
   )
 }
 
+#' Combine two datasets to check Bayes factor computation.
+#'
+#' @description
+#' Merge two datasets of the same length, each generated by a different model. The ""true"" model
+#' will be chosen randomly for each dataset.
+#'
+#' @details The merged dataset will keep track of all parameters and later allow
+#' splitting results with [`split_SBC_results_for_bf()`], to this, a number of
+#' submodel-specific variables will be stored, but makred as
+#' [`hidden_var_attribute()`] to not clutter default visualisations.
 #' @export
 SBC_datasets_for_bf <- function(datasets_H0, datasets_H1, prob_H1 = 0.5, model_var = ""model"") {
   validate_SBC_datasets(datasets_H0)

---FILE: R/binary-calibration-tests.R---
@@ -204,8 +204,9 @@ gaffke_p <- function(probs, mu = 0.5, alpha = 0.05, B = 10000, alternative = c(""
 #' assumptions. The test has been proven valid only for special cases but
 #' no counterexample is known despite some efforts in the literature to find
 #' some. The test also provides way more power (and tighter confidence intervals)
-#' than other non-parametric tests --- in fact its power converges
-#' quite quickly to that of the t-test.
+#' than other non-parametric tests for bounded means - in fact its power converges
+#' quite quickly to that of the t-test, which is known to be optimal
+#' in the large data limit.
 #'
 #' In SBC the test is useful for testing the data-averaged posterior
 #' for binary variables.

---FILE: R/binary-calibration.R---
@@ -142,7 +142,7 @@ binary_calibration_base <- function(prob, outcome, uncertainty_prob = 0.95, type
 calibration_prob_hist_geom <- function(calib_df) {
   geom_histogram(
     data = attr(calib_df, ""bp""),
-    aes(x = prob, y = stat(count / sum(count))),
+    aes(x = prob, y = after_stat(count / sum(count))),
     inherit.aes = FALSE,
     bins = attr(calib_df, ""bins""),
     boundary = 0,

---FILE: R/results.R---
@@ -66,7 +66,9 @@ validate_SBC_results <- function(x) {
     stop(""SBC_results object has to have a 'stats' field of type data.frame"")
   }
 
-  # Ensure backwards compatibility
+  # Ensure backwards compatibility of results (important to keep caches
+  # valid and intact)
+  # From 0.3
   if(""dataset_id"" %in% names(x$stats)) {
     x$stats <- dplyr::rename(x$stats, sim_id = dataset_id)
   }
@@ -75,6 +77,21 @@ validate_SBC_results <- function(x) {
     x$stats <- dplyr::rename(x$stats, variable = parameter)
   }
 
+  # From 0.4
+  if(!(""has_na"" %in% names(x$stats))) {
+    x$stats$has_na <- FALSE
+  }
+
+  if(!(""attributes"" %in% names(x$stats))) {
+    x$stats$attributes <- NA_character_
+  }
+
+  if(""mad"" %in% names(x$stats)) {
+    x$stats <- dplyr::select(x$stats, -mad)
+  }
+
+
+  # Check validity
   if(!is.list(x$fits)) {
     stop(""SBC_results object has to have a 'fits' field of type list"")
   }
@@ -88,10 +105,18 @@ validate_SBC_results <- function(x) {
   }
 
   # Ensure backwards compatibility
+  # From 0.3
   if(""parameter"" %in% names(x$default_diagnostics)) {
     x$stats <- dplyr::rename(x$stats, variable = parameter)
   }
 
+  # From 0.4
+  new_default_diagnostics <- c(""n_has_na"", ""n_na_rhat"", ""n_na_ess_bulk"", ""n_na_ess_tail"")
+  for(nd in new_default_diagnostics) {
+    if(!(nd %in% names(x$default_diagnostics))) {
+      x$default_diagnostics[[nd]] <- 0
+    }
+  }
 
   if(!is.list(x$errors)) {
     stop(""SBC_results object has to have an 'errors' field of type list"")
@@ -179,7 +204,7 @@ validate_SBC_results <- function(x) {
 bind_results <- function(...) {
   args <- list(...)
 
-  purrr::walk(args, validate_SBC_results)
+  args <- purrr::map(args, validate_SBC_results)
 
 
   stats_list <- purrr::map(args, function(x) x$stats)

---FILE: _pkgdown.yml---
@@ -72,6 +72,7 @@ articles:
       - brms
       - discrete_vars
       - rejection_sampling
+      - bayes_factor
 
 reference:
 - title: Datasets
@@ -80,11 +81,13 @@ reference:
   - contains(""dataset"")
   - starts_with(""SBC_generator_"")
   - calculate_prior_sd
+  - contains(""attribute"")
 - title: Backends
   desc: Represent various inference engines you can use with SBC.
 - contents:
   - starts_with(""SBC_backend"")
   - starts_with(""SBC_fit"")
+  - starts_with(""SBC_posterior_cdf"")
 - title: Computation & results
   desc: Functions related to running the SBC computation and handling the results.
 - contents:
@@ -100,13 +103,18 @@ reference:
   - contains(""diagnostic"")
   - default_chunk_size
   - default_cores_per_fit
+  - binary_probabilities_from_stats
+  - cached_fit_filename
+  - get_stats_for_submodel
 - title: Plotting & Summarising
   desc: Plotting and summarising results
 - contents:
   - contains(""plot"")
   - guess_rank_hist_bins
   - empirical_coverage
   - starts_with(""combine_"")
+  - starts_with(""gaffke_"")
+  - ends_with(""resampling_test"")
 - title: Examples
   desc: Functions to let you easily test the pacakge
 - contents:

---FILE: vignettes/bayes_factor.Rmd---
@@ -23,7 +23,7 @@ y &\sim \pi_\text{obs}^i(\theta_i)
 \end{aligned}
 $$
 
-The same model is also implied whenver we do Bayesian model averaging (BMA).
+The same model is also implied whenever we do Bayesian model averaging (BMA).
 The Bayes factor is fully determined by the posterior distribution of the model index
 $i$ in this larger model:
 
@@ -52,9 +52,7 @@ library(ggplot2)
 library(bridgesampling)
 library(dplyr)
 library(tidyr)
-library(calibrationband)
 
-use_cmdstanr <- FALSE
 library(rstan)
 rstan_options(auto_write = TRUE)
 
@@ -227,7 +225,7 @@ ds_turtles <- SBC_datasets_for_bf(ds_turtles_m0, ds_turtles_m1)
 
 Let us now build a `bridgesampling` backend --- this will take backends
 based on the individual models as arguments. The backend in question
-need to implement the `SBC_fit_to_bridge_sampler` S3 method. Out of the
+need to implement the `SBC_fit_to_bridge_sampler()` S3 method. Out of the
 box, this is supported by `SBC_backend_rstan_sample()` and `SBC_backend_brms()`.
 Note that we keep
 a pretty high number of iterations as `bridgesampling` needs that (the specific
@@ -258,31 +256,35 @@ res_turtles_bad <- compute_SBC(ds_turtles, backend_turtles_bad,
 Lets look at the default SBC diagnostics. Note that the plot by default
 combines all parameters that are present in at least a single model. 
 It then uses the implied BMA supermodel to get draws of the parameters (when
-a parameter is not present in the model, all its draws are assumed to be lower
-than all possible real numbers when the parameter is present), i.e. the
-corresponding plot combines the correctness of the model index with the
+a parameter is not present in the model, all its draws are assumed to be `-Inf`).
+This means that any SBC diagnostics for model parameters combines the 
+correctness of the model index (and hence Bayes factor) with the
 correctness of the individual model posteriors.
 
 For clarity, we combine all the random effects in a 
 single panel:
 
-```{r}
+```{r ecdf-bad}
 plot_ecdf_diff(res_turtles_bad, combine_variables = combine_array_elements)
 ```
 
-OK, this is not great, but also not completely terrible. 
+OK, this is not great, but not completely conclusive --- given the number
+of variables, some ECDFs being borderline outside the expected range is possible
+even when the model works as expected. If we had no better tools, it would make 
+sense to run more simulations at this point. But we do have better tools.
+
 How about binary prediction calibration? Let's look at 
 calibration plot (the default type relies on `reliabilitydiag::reliabilitydiag()`
 and especially with smaller number of simulations, using `region.method = ""resampling""`
 is more reliable than the default approximation for the uncertainty region).
 The histogram at the bottom shows the distribution of observed posterior
 model probabilities.
 
-```{r}
+```{r calib-bad}
 plot_binary_calibration(res_turtles_bad, region.method = ""resampling"")
 ```
 
-Thats very clearly bad (the observed calibration is the black line, while the blue area is a 
+That is very clearly bad (the observed calibration is the black line, while the blue area is a 
 confidence region assuming the probabilities are calibrated, we get miscalibration in multiple regions). We may also run a formal miscalibration test --- we first extract
 the binary probabilities and then pass them to the test:
 
@@ -306,14 +308,14 @@ brier_resampling_test(bp_bad$prob, bp_bad$simulated_value)
 
 Finally, we may also look at the data-averaged posterior. If we believe we made
 enough simulations for the 
-central limit theorem has already kicked in, the highest sensitivity is
+central limit theorem to kick in, the highest sensitivity is
 achieved by one sample t-test (we simulated with prior model probability = 0.5):
 
 ```{r}
 t.test(bp_bad$prob, mu = 0.5)
 ```
 
-Also very bad. In the cases where we are wary of the CLT, we may also run the Gaffke test,
+Also very bad. In the cases where we are not sure the CLT holds (small number of simulations + ""ugly"" distribution of posterior model probabilities), we may also run the Gaffke test,
 which makes no assumptions about the distribution of posterior model probabilities
 beyond them being bounded between 0 and 1:
 
@@ -333,10 +335,11 @@ using `SBC_datasets_for_bf` to generate the datasets, is that we can use the
 same simulations to also do SBC for individual models (this and other
 special handling is achieved internally via setting `var_attributes()`):
 
-```{r}
+```{r ecdf-bad-split}
 stats_split_bad <- split_SBC_results_for_bf(res_turtles_bad)
-plot_ecdf_diff(stats_split_bad$stats_H0)
-plot_ecdf_diff(stats_split_bad$stats_H1, combine_variables = combine_array_elements)
+plot_ecdf_diff(stats_split_bad$stats_H0) + ggtitle(""M0"")
+plot_ecdf_diff(stats_split_bad$stats_H1, 
+               combine_variables = combine_array_elements) + ggtitle(""M1"")  
 ```
 
 Those don't look bad (though we don't have a ton of simulation for each to be
@@ -361,9 +364,10 @@ or binary prediction calibration, but will (with enough simulation and
 good test quantities) be detected by SBC.
 
 [Tsukamura and Okada (2024)](https://doi.org/10.1007/s00407-022-00298-3) have noted
-that many Stan models do not include proper normalization for bounded
+that many published Stan models do not include proper normalization for bounded
 parameters and all of those models could thus produce incorrect Bayes factors
-if used with `bridgesampling`.
+if used with `bridgesampling`, so this is a compuational problem
+one can expect to actually see in the wild.
 
 ## Correct model
 
@@ -395,7 +399,7 @@ res_turtles <- compute_SBC(ds_turtles, backend_turtles,
 
 
 
-```{r}
+```{r ecdf-ok}
 plot_ecdf_diff(res_turtles, combine_variables = combine_array_elements)
 ```
 
@@ -405,7 +409,7 @@ is in fact correct and `bridgesampling` works for this problem)
 
 Similarly, binary prediction calibration also looks almost good
 
-```{r}
+```{r calib-ok}
 plot_binary_calibration(res_turtles, region.method = ""resampling"")
 ```
 
@@ -427,4 +431,6 @@ t.test(bp$prob, mu = 0.5)
 gaffke_test(bp$prob, mu = 0.5)
 ```
 
-So no problems here.
+So no problems here, up to the resolution available with `r N_sims` simulations.
+In practice, we would recommend running more simulations for thorough checks,
+but this is just an example that should compute in reasonable time.

---FILE: vignettes/discrete_vars.Rmd---
@@ -110,7 +110,7 @@ generate_single_sim_1 <- function(T, r_e, r_l) {
     ),
     # Letting SBC know that the s parameter can potentially
     # be drawn as all constants 
-    var_attributes = list(
+    var_attributes = var_attributes(
       s = possibly_constant_var_attribute()
     )
   )
@@ -207,7 +207,7 @@ generate_single_sim_2 <- function(T, r_e, r_l) {
     ),
     # Letting SBC know that the s parameter can potentially
     # be drawn as all constants 
-    var_attributes = list(
+    var_attributes = var_attributes(
       s = possibly_constant_var_attribute()
     )
   )",True,True,Documentation / Formatting,7
hyunjimoon,SBC,cde1ed2a4928ca040774da972efb11a5da145245,Luna Fazio,bmfaziol@gmail.com,2025-04-14T13:41:19Z,Luna Fazio,bmfaziol@gmail.com,2025-04-14T13:41:19Z,fix variable name,R/generator-brms.R,False,True,True,False,1,1,2,"---FILE: R/generator-brms.R---
@@ -91,7 +91,7 @@ generate_datasets.SBC_generator_brms <- function(generator, n_sims, n_datasets =
       min_ess <- min(c(Inf, summ$ess_bulk), na.rm = TRUE)
       if(min_ess < n_sims / 2) {
         message(""Warning: Bulk effective sample size for some parameters is less than half the number of simulations.\n"",
-                ""The lowest ESS_bulk/n_sims is "", round(min_ess / n_sims, 2),"" for "", summ$parameter[which.min(summ$ess_bulk)],
+                ""The lowest ESS_bulk/n_sims is "", round(min_ess / n_sims, 2),"" for "", summ$variable[which.min(summ$ess_bulk)],
                 ""\nConsider increased thinning  (via 'thin' argument) ."")
       }
 ",True,False,Implementation / Logic,6
hyunjimoon,SBC,c77ef2e5594a44c0d0c8268338bea9023308a9c9,Martin Modrák,modrak.mar@gmail.com,2025-02-17T10:09:38Z,Martin Modrák,modrak.mar@gmail.com,2025-02-17T10:09:38Z,Fix bug in binding multiple SBC_results,R/results.R;tests/testthat/test-results.R,False,True,True,False,18,12,30,"---FILE: R/results.R---
@@ -193,7 +193,7 @@ bind_results <- function(...) {
 
   # Ensure unique sim_ids
   max_ids <- as.numeric(purrr::map(stats_list, function(x) max(x$sim_id)))
-  shifts <- c(0, max_ids[1:(length(max_ids)) - 1]) # Shift of IDs per dataset
+  shifts <- cumsum(c(0, max_ids[1:(length(max_ids) - 1)])) # Shift of IDs per dataset
 
   shift_sim_id <- function(x, shift) {
     if(is.null(x)) {

---FILE: tests/testthat/test-results.R---
@@ -73,14 +73,14 @@ test_that(""capture_all_outputs"", {
 })
 
 test_that(""subset_bind"", {
-    res <- SBC_results(stats = data.frame(sim_id = rep(1:3, each = 4), s = 1:12),
-                       fits = list(""A"", NULL, ""C""),
-                       outputs = list(c(""A1"",""A2""), c(), c(""C1"", ""C4"")),
-                       warnings = list(c(), ""XXXX"", ""asdfdaf""),
-                       messages = list(""aaaa"", ""ddddd"", NA_character_),
-                       errors = list(NULL, ""customerror"", NULL),
-                       default_diagnostics = data.frame(sim_id = 1:3, qq = rnorm(3)),
-                       backend_diagnostics = data.frame(sim_id = 1:3, rr = rnorm(3))
+    res <- SBC_results(stats = data.frame(sim_id = rep(1:5, each = 4), s = 1:20),
+                       fits = list(""A"", NULL, ""C"", ""D"", ""E""),
+                       outputs = list(c(""A1"",""A2""), c(), c(""C1"", ""C4""), c(""D1"", ""D2"", ""D3""), c(""E1"")),
+                       warnings = list(c(), ""XXXX"", ""asdfdaf"", c(), c()),
+                       messages = list(""aaaa"", ""ddddd"", NA_character_, c(""WD1"", ""WD2""), c(""WE1"", ""WE2"", ""WE3"") ),
+                       errors = list(NULL, ""customerror"", NULL, NULL, NULL),
+                       default_diagnostics = data.frame(sim_id = 1:5, qq = rnorm(5)),
+                       backend_diagnostics = data.frame(sim_id = 1:5, rr = rnorm(5))
                        )
 
     remove_sim_id_names <- function(x) {
@@ -92,12 +92,17 @@ test_that(""subset_bind"", {
         x
     }
 
-    expect_equal(res, remove_sim_id_names(bind_results(res[1], res[2:3])))
-    expect_equal(res, remove_sim_id_names(bind_results(res[1:2], res[3])))
+    expect_equal(remove_sim_id_names(res[1:3]), remove_sim_id_names(bind_results(res[1], res[2:3])))
+    expect_equal(remove_sim_id_names(res[1:3]), remove_sim_id_names(bind_results(res[1:2], res[3])))
+    expect_equal(remove_sim_id_names(res[1:3]), remove_sim_id_names(bind_results(res[1], res[2], res[3])))
     expect_equal(remove_sim_id_names(res[3:1]), remove_sim_id_names(bind_results(res[3:2], res[1])))
     expect_equal(remove_sim_id_names(res[2]), remove_sim_id_names(((res[2:3])[1])))
 
-    # The same, but with some NULLs
+    expect_equal(res, remove_sim_id_names(bind_results(res[1], res[2:3], res[4:5])))
+    expect_equal(res, remove_sim_id_names(bind_results(res[1:2], res[3:4], res[5])))
+    expect_equal(remove_sim_id_names(res[5:1]), remove_sim_id_names(bind_results(res[5:4],res[3:2], res[1])))
+
+    # Shorter, but with some NULLs
     res2 <- SBC_results(stats = data.frame(sim_id = rep(1:3, each = 4), s = 1:12),
                        fits = list(""A"", NULL, ""C""),
                        outputs = rep(list(NULL), 3),
@@ -110,6 +115,7 @@ test_that(""subset_bind"", {
 
     expect_equal(res2, remove_sim_id_names(bind_results(res2[1], res2[2:3])))
     expect_equal(res2, remove_sim_id_names(bind_results(res2[1:2], res2[3])))
+    expect_equal(res2, remove_sim_id_names(bind_results(res2[1], res2[2], res2[3])))
     expect_equal(remove_sim_id_names(res2[3:1]), remove_sim_id_names(bind_results(res2[3:2], res2[1])))
     expect_equal(remove_sim_id_names(res2[2]), remove_sim_id_names(((res2[2:3])[1])))
 ",True,False,Implementation / Logic,6
hyunjimoon,SBC,353f13e47ebdb24f2df6895f4963778f591a9cb1,Martin Modrák,modrak.mar@gmail.com,2025-02-14T20:45:05Z,Martin Modrák,modrak.mar@gmail.com,2025-02-14T20:45:05Z,Fixing vignettes and docs,_pkgdown.yml;vignettes/implementing_backends.Rmd;vignettes/rejection_sampling.Rmd;vignettes/small_model_workflow.Rmd;vignettes/small_model_workflow/.gitignore,True,False,True,False,7,2,9,"---FILE: _pkgdown.yml---
@@ -1,7 +1,6 @@
 url: https://hyunjimoon.github.io/SBC/
 
 template:
-  bootstrap: 5
   params:
     bootswatch: cosmo
 

---FILE: vignettes/implementing_backends.Rmd---
@@ -36,6 +36,7 @@ if(!dir.exists(cache_dir)) {
   dir.create(cache_dir)
 }
 
+future::plan(future::sequential)
 theme_set(theme_minimal())
 ```
 

---FILE: vignettes/rejection_sampling.Rmd---
@@ -58,7 +58,7 @@ So let's see if that also happens in practice. Let's setup our environment:
 
 ```{r setup, message=FALSE,warning=FALSE, results=""hide""}
 library(SBC)
-
+library(ggplot2)
 use_cmdstanr <- getOption(""SBC.vignettes_cmdstanr"", TRUE) # Set to false to use rstan instead
 
 if(use_cmdstanr) {

---FILE: vignettes/small_model_workflow.Rmd---
@@ -70,6 +70,7 @@ Let's setup and get our hands dirty:
 
 ```{r setup, message=FALSE,warning=FALSE, results=""hide""}
 library(SBC)
+library(ggplot2)
 
 use_cmdstanr <- getOption(""SBC.vignettes_cmdstanr"", TRUE) # Set to false to use rstan instead
 

---FILE: vignettes/small_model_workflow/.gitignore---
@@ -0,0 +1,4 @@
+*
+!*.*
+!*/
+*.rds",False,True,Documentation / Formatting,7
hyunjimoon,SBC,c31095a5251ab67929e5fbbfb8d3e32f8151b70d,Martin Modrák,modrak.mar@gmail.com,2025-02-14T17:18:51Z,Martin Modrák,modrak.mar@gmail.com,2025-02-14T17:18:51Z,Fixed bugs in brms backend,R/backend-brms.R;R/generator-brms.R;SBC.Rproj;docs/articles/brms.html;docs/articles/brms_files/figure-html/results_func2_fullrank_plots-1.png;docs/articles/brms_files/figure-html/results_func2_fullrank_plots-2.png;docs/articles/brms_files/figure-html/results_func2_meanfield_plots-1.png;docs/articles/brms_files/figure-html/results_func2_meanfield_plots-2.png;docs/articles/brms_files/figure-html/results_func2_plots-1.png;docs/articles/brms_files/figure-html/results_func2_plots-2.png;docs/articles/brms_files/figure-html/results_func_plots-1.png;docs/articles/brms_files/figure-html/results_func_plots-2.png;docs/articles/brms_files/figure-html/results_plots-1.png;docs/articles/brms_files/figure-html/results_plots-2.png;vignettes/bad_parametrization.Rmd,True,True,True,False,152,74,226,"---FILE: R/backend-brms.R---
@@ -6,7 +6,7 @@ new_SBC_backend_brms <- function(compiled_model,
 ) {
   require_brms_version(""brms backend"")
 
-  if(args$algorithm == ""sampling"") {
+  if(is.null(args$algorithm) || args$algorithm == ""sampling"") {
     arg_names_for_stan <- c(""chains"", ""inits"", ""init"", ""iter"", ""warmup"", ""thin"")
   } else if(args$algorithm %in% c(""meanfield"", ""fullrank"")) {
     arg_names_for_stan <- c(""inits"", ""init"") # possibly more valid args
@@ -22,7 +22,7 @@ new_SBC_backend_brms <- function(compiled_model,
       args_for_stan[[orig]] <- NULL
     }
   }
-  if(args$algorithm == ""sampling"") {
+  if(is.null(args$algorithm) || args$algorithm == ""sampling"") {
     stan_backend <- sampling_backend_from_stanmodel(compiled_model, args_for_stan)
   } else if(args$algorithm %in% c(""meanfield"", ""fullrank"")) {
     args_for_stan$algorithm <- args$algorithm
@@ -37,7 +37,7 @@ validate_SBC_backend_brms_args <- function(args) {
     stop(""Algorithms other than sampling, meanfield and fullrank not supported yet. Comment on https://github.com/hyunjimoon/SBC/issues/91 to express your interest."")
   }
 
-  if(args$algorithm %in% c(""meanfield"", ""fullrank"")) {
+  if(!is.null(args$algorithm) && args$algorithm %in% c(""meanfield"", ""fullrank"")) {
     backend <- args$backend
     if(is.null(backend)) {
       backend <- getOption(""brms.backend"", ""rstan"")

---FILE: R/generator-brms.R---
@@ -24,11 +24,13 @@ SBC_generator_brms <- function(formula, data, ...,  generate_lp = TRUE,
 
   args <- list(...)
 
-  if(!is.null(args$algorithm) && !(args$algorithm %in% c(""sampling"", ""meanfield"", ""fullrank""))) {
-    stop(""Algorithms other than sampling and meanfield not supported yet"")
-  }
-  if(args$algorithm %in% c(""meanfield"", ""fullrank"")) {
-    warning(""Variational inference is not recommended for generating datasets as it is unlikely to produce correct results."")
+  if(!is.null(args$algorithm)) {
+    if(!(args$algorithm %in% c(""sampling"", ""meanfield"", ""fullrank""))) {
+      stop(""Algorithms other than sampling and meanfield not supported yet"")
+    }
+    if(args$algorithm %in% c(""meanfield"", ""fullrank"")) {
+      warning(""Variational inference is not recommended for generating datasets as it is unlikely to produce correct results."")
+    }
   }
 
   compiled_model <- stanmodel_for_brms(formula = formula, data = data, out_stan_file = out_stan_file, ...)

---FILE: SBC.Rproj---
@@ -1,4 +1,5 @@
 Version: 1.0
+ProjectId: b108152d-9d8f-49b0-99a1-3ae87744434c
 
 RestoreWorkspace: No
 SaveWorkspace: No

---FILE: docs/articles/brms.html---
@@ -6,20 +6,19 @@
 <meta http-equiv=""X-UA-Compatible"" content=""IE=edge"">
 <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
 <title>SBC for brms models • SBC</title>
-<!-- jquery --><script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"" integrity=""sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="" crossorigin=""anonymous""></script><!-- Bootstrap --><link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"">
+<!-- jquery --><script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js"" integrity=""sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g=="" crossorigin=""anonymous"" referrerpolicy=""no-referrer""></script><!-- Bootstrap --><link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"">
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js"" integrity=""sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4="" crossorigin=""anonymous""></script><!-- bootstrap-toc --><link rel=""stylesheet"" href=""../bootstrap-toc.css"">
 <script src=""../bootstrap-toc.js""></script><!-- Font Awesome icons --><link rel=""stylesheet"" href=""https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css"" integrity=""sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk="" crossorigin=""anonymous"">
 <link rel=""stylesheet"" href=""https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css"" integrity=""sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw="" crossorigin=""anonymous"">
 <!-- clipboard.js --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><!-- headroom.js --><script src=""https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js"" integrity=""sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js"" integrity=""sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4="" crossorigin=""anonymous""></script><!-- pkgdown --><link href=""../pkgdown.css"" rel=""stylesheet"">
 <script src=""../pkgdown.js""></script><meta property=""og:title"" content=""SBC for brms models"">
-<meta property=""og:description"" content=""SBC"">
 <!-- mathjax --><script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script><!--[if lt IE 9]>
 <script src=""https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js""></script>
 <script src=""https://oss.maxcdn.com/respond/1.4.2/respond.min.js""></script>
 <![endif]--><script defer data-domain=""hyunjimoon.github.io"" src=""https://plausible.io/js/script.js""></script>
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
-    
+
 
     <div class=""container template-article"">
       <header><div class=""navbar navbar-default navbar-fixed-top"" role=""navigation"">
@@ -51,7 +50,7 @@
 <li class=""dropdown"">
   <a href=""#"" class=""dropdown-toggle"" data-toggle=""dropdown"" role=""button"" data-bs-toggle=""dropdown"" aria-expanded=""false"">
     Other Packages
-     
+
     <span class=""caret""></span>
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
@@ -95,19 +94,19 @@
 <li>
   <a href=""https://twitter.com/mcmc_stan"" class=""external-link"">
     <span class=""fa fa-twitter""></span>
-     
+
   </a>
 </li>
 <li>
   <a href=""https://github.com/hyunjimoon/SBC"" class=""external-link"">
     <span class=""fa fa-github""></span>
-     
+
   </a>
 </li>
 <li>
   <a href=""http://discourse.mc-stan.org/"" class=""external-link"">
     <span class=""fa fa-users""></span>
-     
+
   </a>
 </li>
       </ul>
@@ -118,7 +117,7 @@
 </div>
 <!--/.navbar -->
 
-      
+
 
       </header><div class=""row"">
   <div class=""col-md-9 contents"">
@@ -127,7 +126,7 @@ <h1 data-toc-skip>SBC for brms models</h1>
                         <h4 data-toc-skip class=""author"">Martin
 Modrák</h4>
             
-            <h4 data-toc-skip class=""date"">2024-03-14</h4>
+            <h4 data-toc-skip class=""date"">2025-02-14</h4>
       
       <small class=""dont-index"">Source: <a href=""https://github.com/hyunjimoon/SBC/blob/HEAD/vignettes/brms.Rmd"" class=""external-link""><code>vignettes/brms.Rmd</code></a></small>
       <div class=""hidden name""><code>brms.Rmd</code></div>
@@ -169,7 +168,9 @@ <h4 data-toc-skip class=""date"">2024-03-14</h4>
 <span><span class=""op"">}</span></span>
 <span><span class=""kw"">if</span><span class=""op"">(</span><span class=""op"">!</span><span class=""fu""><a href=""https://rdrr.io/r/base/files2.html"" class=""external-link"">dir.exists</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span><span class=""op"">)</span><span class=""op"">)</span> <span class=""op"">{</span></span>
 <span>  <span class=""fu""><a href=""https://rdrr.io/r/base/files2.html"" class=""external-link"">dir.create</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span><span class=""op"">)</span></span>
-<span><span class=""op"">}</span></span></code></pre></div>
+<span><span class=""op"">}</span></span>
+<span></span>
+<span><span class=""fu""><a href=""https://ggplot2.tidyverse.org/reference/theme_get.html"" class=""external-link"">theme_set</a></span><span class=""op"">(</span><span class=""fu""><a href=""https://ggplot2.tidyverse.org/reference/ggtheme.html"" class=""external-link"">theme_minimal</a></span><span class=""op"">(</span><span class=""op"">)</span><span class=""op"">)</span></span></code></pre></div>
 <div class=""section level2"">
 <h2 id=""generating-data-using-brms"">Generating data using <code>brms</code><a class=""anchor"" aria-label=""anchor"" href=""#generating-data-using-brms""></a>
 </h2>
@@ -193,9 +194,9 @@ <h2 id=""generating-data-using-brms"">Generating data using <code>brms</code><a cl
 <span><span class=""co""># of the correct data type</span></span>
 <span><span class=""fu""><a href=""https://rdrr.io/r/base/Random.html"" class=""external-link"">set.seed</a></span><span class=""op"">(</span><span class=""fl"">213452</span><span class=""op"">)</span></span>
 <span><span class=""va"">template_data</span> <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/data.frame.html"" class=""external-link"">data.frame</a></span><span class=""op"">(</span>y <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/rep.html"" class=""external-link"">rep</a></span><span class=""op"">(</span><span class=""fl"">0</span>, <span class=""fl"">15</span><span class=""op"">)</span>, x <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Normal.html"" class=""external-link"">rnorm</a></span><span class=""op"">(</span><span class=""fl"">15</span><span class=""op"">)</span><span class=""op"">)</span></span>
-<span><span class=""va"">priors</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://paul-buerkner.github.io/brms/reference/set_prior.html"" class=""external-link"">prior</a></span><span class=""op"">(</span><span class=""fu"">normal</span><span class=""op"">(</span><span class=""fl"">0</span>,<span class=""fl"">1</span><span class=""op"">)</span>, class <span class=""op"">=</span> <span class=""st"">""b""</span><span class=""op"">)</span> <span class=""op"">+</span></span>
-<span>  <span class=""fu""><a href=""https://paul-buerkner.github.io/brms/reference/set_prior.html"" class=""external-link"">prior</a></span><span class=""op"">(</span><span class=""fu"">normal</span><span class=""op"">(</span><span class=""fl"">0</span>,<span class=""fl"">1</span><span class=""op"">)</span>, class <span class=""op"">=</span> <span class=""st"">""Intercept""</span><span class=""op"">)</span> <span class=""op"">+</span></span>
-<span>  <span class=""fu""><a href=""https://paul-buerkner.github.io/brms/reference/set_prior.html"" class=""external-link"">prior</a></span><span class=""op"">(</span><span class=""fu"">normal</span><span class=""op"">(</span><span class=""fl"">0</span>,<span class=""fl"">1</span><span class=""op"">)</span>, class <span class=""op"">=</span> <span class=""st"">""sigma""</span><span class=""op"">)</span></span>
+<span><span class=""va"">priors</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://paulbuerkner.com/brms/reference/set_prior.html"" class=""external-link"">prior</a></span><span class=""op"">(</span><span class=""fu"">normal</span><span class=""op"">(</span><span class=""fl"">0</span>,<span class=""fl"">1</span><span class=""op"">)</span>, class <span class=""op"">=</span> <span class=""st"">""b""</span><span class=""op"">)</span> <span class=""op"">+</span></span>
+<span>  <span class=""fu""><a href=""https://paulbuerkner.com/brms/reference/set_prior.html"" class=""external-link"">prior</a></span><span class=""op"">(</span><span class=""fu"">normal</span><span class=""op"">(</span><span class=""fl"">0</span>,<span class=""fl"">1</span><span class=""op"">)</span>, class <span class=""op"">=</span> <span class=""st"">""Intercept""</span><span class=""op"">)</span> <span class=""op"">+</span></span>
+<span>  <span class=""fu""><a href=""https://paulbuerkner.com/brms/reference/set_prior.html"" class=""external-link"">prior</a></span><span class=""op"">(</span><span class=""fu"">normal</span><span class=""op"">(</span><span class=""fl"">0</span>,<span class=""fl"">1</span><span class=""op"">)</span>, class <span class=""op"">=</span> <span class=""st"">""sigma""</span><span class=""op"">)</span></span>
 <span><span class=""va"">generator</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/SBC_generator_brms.html"">SBC_generator_brms</a></span><span class=""op"">(</span><span class=""va"">y</span> <span class=""op"">~</span> <span class=""va"">x</span>, data <span class=""op"">=</span> <span class=""va"">template_data</span>, prior <span class=""op"">=</span> <span class=""va"">priors</span>, </span>
 <span>                                thin <span class=""op"">=</span> <span class=""fl"">50</span>, warmup <span class=""op"">=</span> <span class=""fl"">10000</span>, refresh <span class=""op"">=</span> <span class=""fl"">2000</span>,</span>
 <span>                                out_stan_file <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/file.path.html"" class=""external-link"">file.path</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span>, <span class=""st"">""brms_linreg1.stan""</span><span class=""op"">)</span></span>
@@ -217,11 +218,22 @@ <h2 id=""generating-data-using-brms"">Generating data using <code>brms</code><a cl
 <span><span class=""co"">## Chain 1 Iteration: 15000 / 15000 [100%]  (Sampling) </span></span>
 <span><span class=""co"">## Chain 1 finished in 0.1 seconds.</span></span></code></pre>
 <pre><code><span><span class=""co"">## Warning: Some rhats are &gt; 1.01 indicating the prior was not explored well.</span></span>
-<span><span class=""co"">## The highest rhat is 1.05 for lp__</span></span>
+<span><span class=""co"">## The highest rhat is 1.02 for lprior</span></span>
 <span><span class=""co"">## Consider adding warmup iterations (via 'warmup' argument).</span></span></code></pre>
+<pre><code><span><span class=""co"">## Loading required package: rstan</span></span></code></pre>
+<pre><code><span><span class=""co"">## Loading required package: StanHeaders</span></span></code></pre>
+<pre><code><span><span class=""co"">## </span></span>
+<span><span class=""co"">## rstan version 2.32.6 (Stan version 2.32.2)</span></span></code></pre>
+<pre><code><span><span class=""co"">## For execution on a local, multicore CPU with excess RAM we recommend calling</span></span>
+<span><span class=""co"">## options(mc.cores = parallel::detectCores()).</span></span>
+<span><span class=""co"">## To avoid recompilation of unchanged Stan programs, we recommend calling</span></span>
+<span><span class=""co"">## rstan_options(auto_write = TRUE)</span></span>
+<span><span class=""co"">## For within-chain threading using `reduce_sum()` or `map_rect()` Stan functions,</span></span>
+<span><span class=""co"">## change `threads_per_chain` option:</span></span>
+<span><span class=""co"">## rstan_options(threads_per_chain = 1)</span></span></code></pre>
 <p>Now we’ll build a backend matching the generator (and reuse the
 compiled model from the generator)</p>
-<div class=""sourceCode"" id=""cb6""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb10""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""va"">backend</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/SBC_backend_brms_from_generator.html"">SBC_backend_brms_from_generator</a></span><span class=""op"">(</span><span class=""va"">generator</span>, chains <span class=""op"">=</span> <span class=""fl"">1</span>, thin <span class=""op"">=</span> <span class=""fl"">1</span>,</span>
 <span>                            warmup <span class=""op"">=</span> <span class=""fl"">500</span>, iter <span class=""op"">=</span> <span class=""fl"">1500</span>,               </span>
 <span>                            inits <span class=""op"">=</span> <span class=""fl"">0.1</span><span class=""op"">)</span></span>
@@ -230,13 +242,13 @@ <h2 id=""generating-data-using-brms"">Generating data using <code>brms</code><a cl
 <span><span class=""co""># backend &lt;- SBC_backend_brms(y ~ x, template_data = template_data, prior = priors, warmup = 500, iter = 1000, chains = 1, thin = 1</span></span>
 <span><span class=""co"">#                            init = 0.1)</span></span></code></pre></div>
 <p>Compute the actual results</p>
-<div class=""sourceCode"" id=""cb7""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb11""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""va"">results</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_SBC.html"">compute_SBC</a></span><span class=""op"">(</span><span class=""va"">datasets</span>, <span class=""va"">backend</span>,</span>
 <span>                    cache_mode <span class=""op"">=</span> <span class=""st"">""results""</span>, </span>
 <span>                    cache_location <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/file.path.html"" class=""external-link"">file.path</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span>, <span class=""st"">""first""</span><span class=""op"">)</span><span class=""op"">)</span></span></code></pre></div>
 <pre><code><span><span class=""co"">## Results loaded from cache file 'first'</span></span></code></pre>
-<pre><code><span><span class=""co"">##  - 10 (10%) fits had at least one Rhat &gt; 1.01. Largest Rhat was 1.024.</span></span></code></pre>
-<pre><code><span><span class=""co"">##  - 46 (46%) fits had some steps rejected. Maximum number of rejections was 1.</span></span></code></pre>
+<pre><code><span><span class=""co"">##  - 19 (19%) fits had at least one Rhat &gt; 1.01. Largest Rhat was 1.027.</span></span></code></pre>
+<pre><code><span><span class=""co"">##  - 55 (55%) fits had some steps rejected. Maximum number of rejections was 1.</span></span></code></pre>
 <pre><code><span><span class=""co"">## Not all diagnostics are OK.</span></span>
 <span><span class=""co"">## You can learn more by inspecting $default_diagnostics, $backend_diagnostics </span></span>
 <span><span class=""co"">## and/or investigating $outputs/$messages/$warnings for detailed output from the backend.</span></span></code></pre>
@@ -245,10 +257,10 @@ <h2 id=""generating-data-using-brms"">Generating data using <code>brms</code><a cl
 noise in Rhat computation).</p>
 <p>So we can inspect the rank plots. There are no big problems at this
 resolution.</p>
-<div class=""sourceCode"" id=""cb12""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb16""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""fu""><a href=""../reference/plot_rank_hist.html"">plot_rank_hist</a></span><span class=""op"">(</span><span class=""va"">results</span><span class=""op"">)</span></span></code></pre></div>
 <p><img src=""brms_files/figure-html/results_plots-1.png"" width=""700""></p>
-<div class=""sourceCode"" id=""cb13""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb17""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""fu""><a href=""../reference/ECDF-plots.html"">plot_ecdf_diff</a></span><span class=""op"">(</span><span class=""va"">results</span><span class=""op"">)</span></span></code></pre></div>
 <p><img src=""brms_files/figure-html/results_plots-2.png"" width=""700""></p>
 </div>
@@ -269,7 +281,7 @@ <h2 id=""using-custom-generator-code"">Using custom generator code<a class=""anchor
 <p>The data can be generated using the following code - note that we
 need to be careful to match the parameter names as <code>brms</code>
 uses them. You can call <code>parnames</code> on a fit to see them.</p>
-<div class=""sourceCode"" id=""cb14""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb18""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""va"">one_sim_generator</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">N</span>, <span class=""va"">K</span><span class=""op"">)</span> <span class=""op"">{</span></span>
 <span>  <span class=""co""># N - number of datapoints, K number of groups for the varying intercept</span></span>
 <span>  <span class=""fu""><a href=""https://rdrr.io/r/base/stopifnot.html"" class=""external-link"">stopifnot</a></span><span class=""op"">(</span><span class=""fl"">3</span> <span class=""op"">*</span> <span class=""va"">K</span> <span class=""op"">&lt;=</span> <span class=""va"">N</span><span class=""op"">)</span></span>
@@ -309,54 +321,54 @@ <h2 id=""using-custom-generator-code"">Using custom generator code<a class=""anchor
 given parameters as a derived quantity that we’ll also monitor (see the
 <a href=""https://hyunjimoon.github.io/SBC/articles/limits_of_SBC.html""><code>limits_of_SBC</code></a>
 vignette for discussion on why this is useful).</p>
-<div class=""sourceCode"" id=""cb15""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb19""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""va"">log_lik_dq_func</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/derived_quantities.html"">derived_quantities</a></span><span class=""op"">(</span></span>
 <span>  log_lik <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/sum.html"" class=""external-link"">sum</a></span><span class=""op"">(</span><span class=""fu""><a href=""https://rdrr.io/r/stats/Normal.html"" class=""external-link"">dnorm</a></span><span class=""op"">(</span><span class=""va"">y</span>, <span class=""va"">b_Intercept</span> <span class=""op"">+</span> <span class=""va"">x</span> <span class=""op"">*</span> <span class=""va"">b_x</span> <span class=""op"">+</span> <span class=""va"">r_group</span><span class=""op"">[</span><span class=""va"">group</span><span class=""op"">]</span>, <span class=""va"">sigma</span>, log <span class=""op"">=</span> <span class=""cn"">TRUE</span><span class=""op"">)</span><span class=""op"">)</span></span>
-<span>  <span class=""co""># Testing CRPS, probably not worth it</span></span>
-<span>  <span class=""co"">#, CRPS = mean(scoringRules::crps_norm(y, b_Intercept + x * b_x + r_group[group], sigma))</span></span>
 <span>  <span class=""op"">)</span></span></code></pre></div>
-<div class=""sourceCode"" id=""cb16""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb20""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""fu""><a href=""https://rdrr.io/r/base/Random.html"" class=""external-link"">set.seed</a></span><span class=""op"">(</span><span class=""fl"">12239755</span><span class=""op"">)</span></span>
 <span><span class=""va"">datasets_func</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/generate_datasets.html"">generate_datasets</a></span><span class=""op"">(</span><span class=""va"">n_sims_generator</span>, <span class=""fl"">100</span><span class=""op"">)</span></span></code></pre></div>
 <p>This is then our <code>brms</code> backend - note that
-<code>brms</code> requires us to provide a dataset that it will use to
-build the model (e.g. to see how many levels of various varying
-intercepts to include):</p>
-<div class=""sourceCode"" id=""cb17""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span><span class=""va"">priors_func</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://paul-buerkner.github.io/brms/reference/set_prior.html"" class=""external-link"">prior</a></span><span class=""op"">(</span><span class=""fu"">normal</span><span class=""op"">(</span><span class=""fl"">0</span>,<span class=""fl"">1</span><span class=""op"">)</span>, class <span class=""op"">=</span> <span class=""st"">""b""</span><span class=""op"">)</span> <span class=""op"">+</span></span>
-<span>  <span class=""fu""><a href=""https://paul-buerkner.github.io/brms/reference/set_prior.html"" class=""external-link"">prior</a></span><span class=""op"">(</span><span class=""fu"">normal</span><span class=""op"">(</span><span class=""fl"">5</span>,<span class=""fl"">1</span><span class=""op"">)</span>, class <span class=""op"">=</span> <span class=""st"">""Intercept""</span><span class=""op"">)</span> <span class=""op"">+</span></span>
-<span>  <span class=""fu""><a href=""https://paul-buerkner.github.io/brms/reference/set_prior.html"" class=""external-link"">prior</a></span><span class=""op"">(</span><span class=""fu"">normal</span><span class=""op"">(</span><span class=""fl"">0</span>,<span class=""fl"">5</span><span class=""op"">)</span>, class <span class=""op"">=</span> <span class=""st"">""sigma""</span><span class=""op"">)</span> <span class=""op"">+</span></span>
-<span>  <span class=""fu""><a href=""https://paul-buerkner.github.io/brms/reference/set_prior.html"" class=""external-link"">prior</a></span><span class=""op"">(</span><span class=""fu"">normal</span><span class=""op"">(</span><span class=""fl"">0</span>,<span class=""fl"">0.75</span><span class=""op"">)</span>, class <span class=""op"">=</span> <span class=""st"">""sd""</span><span class=""op"">)</span></span>
+<code>brms</code> requires us to provide a dataset
+(<code>template_data</code>) that it will use to build the model
+(e.g. to see how many levels of various varying intercepts to
+include):</p>
+<div class=""sourceCode"" id=""cb21""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">priors_func</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://paulbuerkner.com/brms/reference/set_prior.html"" class=""external-link"">prior</a></span><span class=""op"">(</span><span class=""fu"">normal</span><span class=""op"">(</span><span class=""fl"">0</span>,<span class=""fl"">1</span><span class=""op"">)</span>, class <span class=""op"">=</span> <span class=""st"">""b""</span><span class=""op"">)</span> <span class=""op"">+</span></span>
+<span>  <span class=""fu""><a href=""https://paulbuerkner.com/brms/reference/set_prior.html"" class=""external-link"">prior</a></span><span class=""op"">(</span><span class=""fu"">normal</span><span class=""op"">(</span><span class=""fl"">5</span>,<span class=""fl"">1</span><span class=""op"">)</span>, class <span class=""op"">=</span> <span class=""st"">""Intercept""</span><span class=""op"">)</span> <span class=""op"">+</span></span>
+<span>  <span class=""fu""><a href=""https://paulbuerkner.com/brms/reference/set_prior.html"" class=""external-link"">prior</a></span><span class=""op"">(</span><span class=""fu"">normal</span><span class=""op"">(</span><span class=""fl"">0</span>,<span class=""fl"">5</span><span class=""op"">)</span>, class <span class=""op"">=</span> <span class=""st"">""sigma""</span><span class=""op"">)</span> <span class=""op"">+</span></span>
+<span>  <span class=""fu""><a href=""https://paulbuerkner.com/brms/reference/set_prior.html"" class=""external-link"">prior</a></span><span class=""op"">(</span><span class=""fu"">normal</span><span class=""op"">(</span><span class=""fl"">0</span>,<span class=""fl"">0.75</span><span class=""op"">)</span>, class <span class=""op"">=</span> <span class=""st"">""sd""</span><span class=""op"">)</span></span>
 <span></span>
 <span></span>
 <span><span class=""va"">backend_func</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/SBC_backend_brms.html"">SBC_backend_brms</a></span><span class=""op"">(</span><span class=""va"">y</span> <span class=""op"">~</span> <span class=""va"">x</span> <span class=""op"">+</span> <span class=""op"">(</span><span class=""fl"">1</span> <span class=""op"">|</span> <span class=""va"">group</span><span class=""op"">)</span>,  </span>
 <span>                      prior <span class=""op"">=</span> <span class=""va"">priors_func</span>, chains <span class=""op"">=</span> <span class=""fl"">1</span>,</span>
 <span>                      template_data <span class=""op"">=</span> <span class=""va"">datasets_func</span><span class=""op"">$</span><span class=""va"">generated</span><span class=""op"">[[</span><span class=""fl"">1</span><span class=""op"">]</span><span class=""op"">]</span>,</span>
+<span>                      control <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/list.html"" class=""external-link"">list</a></span><span class=""op"">(</span>adapt_delta <span class=""op"">=</span> <span class=""fl"">0.95</span><span class=""op"">)</span>,</span>
 <span>                      out_stan_file <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/file.path.html"" class=""external-link"">file.path</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span>, <span class=""st"">""brms_linreg2.stan""</span><span class=""op"">)</span><span class=""op"">)</span></span></code></pre></div>
 <p>So we can happily compute:</p>
-<div class=""sourceCode"" id=""cb18""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb22""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""va"">results_func</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_SBC.html"">compute_SBC</a></span><span class=""op"">(</span><span class=""va"">datasets_func</span>, <span class=""va"">backend_func</span>, </span>
 <span>                                dquants <span class=""op"">=</span> <span class=""va"">log_lik_dq_func</span>, </span>
 <span>                    cache_mode <span class=""op"">=</span> <span class=""st"">""results""</span>, </span>
 <span>                    cache_location <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/file.path.html"" class=""external-link"">file.path</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span>, <span class=""st"">""func""</span><span class=""op"">)</span><span class=""op"">)</span></span></code></pre></div>
 <pre><code><span><span class=""co"">## Results loaded from cache file 'func'</span></span></code></pre>
-<pre><code><span><span class=""co"">##  - 31 (31%) fits had at least one Rhat &gt; 1.01. Largest Rhat was 1.098.</span></span></code></pre>
+<pre><code><span><span class=""co"">##  - 33 (33%) fits had at least one Rhat &gt; 1.01. Largest Rhat was 1.513.</span></span></code></pre>
 <pre><code><span><span class=""co"">##  - 5 (5%) fits had tail ESS undefined or less than half of the maximum rank, potentially skewing </span></span>
-<span><span class=""co"">## the rank statistics. The lowest tail ESS was 13.</span></span>
+<span><span class=""co"">## the rank statistics. The lowest tail ESS was NA.</span></span>
 <span><span class=""co"">##  If the fits look good otherwise, increasing `thin_ranks` (via recompute_SBC_statistics) </span></span>
 <span><span class=""co"">## or number of posterior draws (by refitting) might help.</span></span></code></pre>
-<pre><code><span><span class=""co"">##  - 51 (51%) fits had divergent transitions. Maximum number of divergences was 115.</span></span></code></pre>
-<pre><code><span><span class=""co"">##  - 2 (2%) fits had iterations that saturated max treedepth. Maximum number of max treedepth was 455.</span></span></code></pre>
-<pre><code><span><span class=""co"">##  - 84 (84%) fits had some steps rejected. Maximum number of rejections was 7.</span></span></code></pre>
+<pre><code><span><span class=""co"">##  - 38 (38%) fits had divergent transitions. Maximum number of divergences was 563.</span></span></code></pre>
+<pre><code><span><span class=""co"">##  - 3 (3%) fits had iterations that saturated max treedepth. Maximum number of max treedepth was 451.</span></span></code></pre>
+<pre><code><span><span class=""co"">##  - 82 (82%) fits had some steps rejected. Maximum number of rejections was 7.</span></span></code></pre>
 <pre><code><span><span class=""co"">## Not all diagnostics are OK.</span></span>
 <span><span class=""co"">## You can learn more by inspecting $default_diagnostics, $backend_diagnostics </span></span>
 <span><span class=""co"">## and/or investigating $outputs/$messages/$warnings for detailed output from the backend.</span></span></code></pre>
 <p>So that’s not looking good! Divergent transitions, Rhat problems… And
 the rank plots also show problems:</p>
-<div class=""sourceCode"" id=""cb26""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb30""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""fu""><a href=""../reference/plot_rank_hist.html"">plot_rank_hist</a></span><span class=""op"">(</span><span class=""va"">results_func</span><span class=""op"">)</span></span></code></pre></div>
 <p><img src=""brms_files/figure-html/results_func_plots-1.png"" width=""700""></p>
-<div class=""sourceCode"" id=""cb27""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb31""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""fu""><a href=""../reference/ECDF-plots.html"">plot_ecdf_diff</a></span><span class=""op"">(</span><span class=""va"">results_func</span><span class=""op"">)</span></span></code></pre></div>
 <p><img src=""brms_files/figure-html/results_func_plots-2.png"" width=""700""></p>
 <p>It looks like there is a problem affecting at least the
@@ -373,51 +385,113 @@ <h2 id=""using-custom-generator-code"">Using custom generator code<a class=""anchor
 <p>Maybe we don’t want <code>brms</code> to do this — using
 <code>0 + Intercept</code> syntax avoids the centering, so we build a
 new backend that should match our simulator better</p>
-<div class=""sourceCode"" id=""cb28""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb32""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""co""># Using 0 + Intercept also changes how we need to specify priors</span></span>
-<span><span class=""va"">priors_func2</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://paul-buerkner.github.io/brms/reference/set_prior.html"" class=""external-link"">prior</a></span><span class=""op"">(</span><span class=""fu"">normal</span><span class=""op"">(</span><span class=""fl"">0</span>,<span class=""fl"">1</span><span class=""op"">)</span>, class <span class=""op"">=</span> <span class=""st"">""b""</span><span class=""op"">)</span> <span class=""op"">+</span></span>
-<span>  <span class=""fu""><a href=""https://paul-buerkner.github.io/brms/reference/set_prior.html"" class=""external-link"">prior</a></span><span class=""op"">(</span><span class=""fu"">normal</span><span class=""op"">(</span><span class=""fl"">5</span>,<span class=""fl"">1</span><span class=""op"">)</span>, class <span class=""op"">=</span> <span class=""st"">""b""</span>, coef <span class=""op"">=</span> <span class=""st"">""Intercept""</span><span class=""op"">)</span> <span class=""op"">+</span></span>
-<span>  <span class=""fu""><a href=""https://paul-buerkner.github.io/brms/reference/set_prior.html"" class=""external-link"">prior</a></span><span class=""op"">(</span><span class=""fu"">normal</span><span class=""op"">(</span><span class=""fl"">0</span>,<span class=""fl"">5</span><span class=""op"">)</span>, class <span class=""op"">=</span> <span class=""st"">""sigma""</span><span class=""op"">)</span> <span class=""op"">+</span></span>
-<span>  <span class=""fu""><a href=""https://paul-buerkner.github.io/brms/reference/set_prior.html"" class=""external-link"">prior</a></span><span class=""op"">(</span><span class=""fu"">normal</span><span class=""op"">(</span><span class=""fl"">0</span>,<span class=""fl"">0.75</span><span class=""op"">)</span>, class <span class=""op"">=</span> <span class=""st"">""sd""</span><span class=""op"">)</span></span>
+<span><span class=""va"">priors_func2</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://paulbuerkner.com/brms/reference/set_prior.html"" class=""external-link"">prior</a></span><span class=""op"">(</span><span class=""fu"">normal</span><span class=""op"">(</span><span class=""fl"">0</span>,<span class=""fl"">1</span><span class=""op"">)</span>, class <span class=""op"">=</span> <span class=""st"">""b""</span><span class=""op"">)</span> <span class=""op"">+</span></span>
+<span>  <span class=""fu""><a href=""https://paulbuerkner.com/brms/reference/set_prior.html"" class=""external-link"">prior</a></span><span class=""op"">(</span><span class=""fu"">normal</span><span class=""op"">(</span><span class=""fl"">5</span>,<span class=""fl"">1</span><span class=""op"">)</span>, class <span class=""op"">=</span> <span class=""st"">""b""</span>, coef <span class=""op"">=</span> <span class=""st"">""Intercept""</span><span class=""op"">)</span> <span class=""op"">+</span></span>
+<span>  <span class=""fu""><a href=""https://paulbuerkner.com/brms/reference/set_prior.html"" class=""external-link"">prior</a></span><span class=""op"">(</span><span class=""fu"">normal</span><span class=""op"">(</span><span class=""fl"">0</span>,<span class=""fl"">5</span><span class=""op"">)</span>, class <span class=""op"">=</span> <span class=""st"">""sigma""</span><span class=""op"">)</span> <span class=""op"">+</span></span>
+<span>  <span class=""fu""><a href=""https://paulbuerkner.com/brms/reference/set_prior.html"" class=""external-link"">prior</a></span><span class=""op"">(</span><span class=""fu"">normal</span><span class=""op"">(</span><span class=""fl"">0</span>,<span class=""fl"">0.75</span><span class=""op"">)</span>, class <span class=""op"">=</span> <span class=""st"">""sd""</span><span class=""op"">)</span></span>
 <span></span>
 <span></span>
 <span><span class=""va"">backend_func2</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/SBC_backend_brms.html"">SBC_backend_brms</a></span><span class=""op"">(</span><span class=""va"">y</span> <span class=""op"">~</span> <span class=""fl"">0</span> <span class=""op"">+</span> <span class=""va"">Intercept</span> <span class=""op"">+</span> <span class=""va"">x</span> <span class=""op"">+</span> <span class=""op"">(</span><span class=""fl"">1</span> <span class=""op"">|</span> <span class=""va"">group</span><span class=""op"">)</span>,  </span>
-<span>                            prior <span class=""op"">=</span> <span class=""va"">priors_func2</span>, warmup <span class=""op"">=</span> <span class=""fl"">1000</span>, iter <span class=""op"">=</span> <span class=""fl"">2000</span>, chains <span class=""op"">=</span> <span class=""fl"">1</span>,</span>
+<span>                            prior <span class=""op"">=</span> <span class=""va"">priors_func2</span>, warmup <span class=""op"">=</span> <span class=""fl"">1000</span>, iter <span class=""op"">=</span> <span class=""fl"">2000</span>, chains <span class=""op"">=</span> <span class=""fl"">2</span>,</span>
 <span>                            template_data <span class=""op"">=</span> <span class=""va"">datasets_func</span><span class=""op"">$</span><span class=""va"">generated</span><span class=""op"">[[</span><span class=""fl"">1</span><span class=""op"">]</span><span class=""op"">]</span>,</span>
+<span>                            control <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/list.html"" class=""external-link"">list</a></span><span class=""op"">(</span>adapt_delta <span class=""op"">=</span> <span class=""fl"">0.95</span><span class=""op"">)</span>,</span>
 <span>                            out_stan_file <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/file.path.html"" class=""external-link"">file.path</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span>, <span class=""st"">""brms_linreg3.stan""</span><span class=""op"">)</span><span class=""op"">)</span></span></code></pre></div>
 <p>Let’s fit the same simulations with the new backend.</p>
-<div class=""sourceCode"" id=""cb29""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb33""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""va"">results_func2</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_SBC.html"">compute_SBC</a></span><span class=""op"">(</span><span class=""va"">datasets_func</span>, <span class=""va"">backend_func2</span>, </span>
 <span>                                 dquants <span class=""op"">=</span> <span class=""va"">log_lik_dq_func</span>, </span>
 <span>                    cache_mode <span class=""op"">=</span> <span class=""st"">""results""</span>, </span>
 <span>                    cache_location <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/file.path.html"" class=""external-link"">file.path</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span>, <span class=""st"">""func2""</span><span class=""op"">)</span><span class=""op"">)</span></span></code></pre></div>
 <pre><code><span><span class=""co"">## Results loaded from cache file 'func2'</span></span></code></pre>
-<pre><code><span><span class=""co"">##  - 19 (19%) fits had at least one Rhat &gt; 1.01. Largest Rhat was 1.042.</span></span></code></pre>
-<pre><code><span><span class=""co"">##  - 4 (4%) fits had divergent transitions. Maximum number of divergences was 2.</span></span></code></pre>
-<pre><code><span><span class=""co"">##  - 1 (1%) fits had iterations that saturated max treedepth. Maximum number of max treedepth was 521.</span></span></code></pre>
-<pre><code><span><span class=""co"">##  - 85 (85%) fits had some steps rejected. Maximum number of rejections was 8.</span></span></code></pre>
+<pre><code><span><span class=""co"">##  - 3 (3%) fits had at least one Rhat &gt; 1.01. Largest Rhat was 1.022.</span></span></code></pre>
+<pre><code><span><span class=""co"">##  - 11 (11%) fits had divergent transitions. Maximum number of divergences was 16.</span></span></code></pre>
+<pre><code><span><span class=""co"">##  - 1 (1%) fits had iterations that saturated max treedepth. Maximum number of max treedepth was 1087.</span></span></code></pre>
+<pre><code><span><span class=""co"">##  - 99 (99%) fits had some steps rejected. Maximum number of rejections was 13.</span></span></code></pre>
 <pre><code><span><span class=""co"">## Not all diagnostics are OK.</span></span>
 <span><span class=""co"">## You can learn more by inspecting $default_diagnostics, $backend_diagnostics </span></span>
 <span><span class=""co"">## and/or investigating $outputs/$messages/$warnings for detailed output from the backend.</span></span></code></pre>
-<p>We see that this still results in some problematic fits, but the
-proportion got lower. At this point I am honestly unsure what is the
-issue, but the rank plots look mostly OK:</p>
-<div class=""sourceCode"" id=""cb36""><pre class=""downlit sourceCode r"">
+<p>We see that this still results in a small number of mildly
+problematic fits, which is enough for our purposes (likely ramping up
+<code>adapt_delta</code> even higher would help). The rank plots look
+mostly OK:</p>
+<div class=""sourceCode"" id=""cb40""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""fu""><a href=""../reference/plot_rank_hist.html"">plot_rank_hist</a></span><span class=""op"">(</span><span class=""va"">results_func2</span><span class=""op"">)</span></span></code></pre></div>
 <p><img src=""brms_files/figure-html/results_func2_plots-1.png"" width=""700""></p>
-<div class=""sourceCode"" id=""cb37""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb41""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""fu""><a href=""../reference/ECDF-plots.html"">plot_ecdf_diff</a></span><span class=""op"">(</span><span class=""va"">results_func2</span><span class=""op"">)</span></span></code></pre></div>
 <p><img src=""brms_files/figure-html/results_func2_plots-2.png"" width=""700""></p>
-<p>I promise to update this vignette once I figure out the source of the
-problems.</p>
+</div>
+<div class=""section level2"">
+<h2 id=""using-variational-inference-with-brms"">Using variational inference with <code>brms</code><a class=""anchor"" aria-label=""anchor"" href=""#using-variational-inference-with-brms""></a>
+</h2>
+<p>Currently variational inference is supported only for
+<code>cmdstanr</code> brms backend, so this part will be skipped with
+<code>rstan</code> backend. We simply pass
+<code>algorithm = ""meanfield""</code> when building the SBC backend:</p>
+<div class=""sourceCode"" id=""cb42""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">backend_func2_meanfield</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/SBC_backend_brms.html"">SBC_backend_brms</a></span><span class=""op"">(</span><span class=""va"">y</span> <span class=""op"">~</span> <span class=""fl"">0</span> <span class=""op"">+</span> <span class=""va"">Intercept</span> <span class=""op"">+</span> <span class=""va"">x</span> <span class=""op"">+</span> <span class=""op"">(</span><span class=""fl"">1</span> <span class=""op"">|</span> <span class=""va"">group</span><span class=""op"">)</span>,  </span>
+<span>                            prior <span class=""op"">=</span> <span class=""va"">priors_func2</span>, warmup <span class=""op"">=</span> <span class=""fl"">1000</span>, iter <span class=""op"">=</span> <span class=""fl"">2000</span>, chains <span class=""op"">=</span> <span class=""fl"">2</span>,</span>
+<span>                            template_data <span class=""op"">=</span> <span class=""va"">datasets_func</span><span class=""op"">$</span><span class=""va"">generated</span><span class=""op"">[[</span><span class=""fl"">1</span><span class=""op"">]</span><span class=""op"">]</span>,</span>
+<span>                            algorithm <span class=""op"">=</span> <span class=""st"">""meanfield""</span>,</span>
+<span>                            out_stan_file <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/file.path.html"" class=""external-link"">file.path</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span>, <span class=""st"">""brms_linreg3.stan""</span><span class=""op"">)</span><span class=""op"">)</span></span></code></pre></div>
+<p>And we run SBC:</p>
+<div class=""sourceCode"" id=""cb43""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">results_func2_meanfield</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_SBC.html"">compute_SBC</a></span><span class=""op"">(</span><span class=""va"">datasets_func</span>, <span class=""va"">backend_func2_meanfield</span>, </span>
+<span>                                 dquants <span class=""op"">=</span> <span class=""va"">log_lik_dq_func</span>, </span>
+<span>                    cache_mode <span class=""op"">=</span> <span class=""st"">""results""</span>, </span>
+<span>                    cache_location <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/file.path.html"" class=""external-link"">file.path</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span>, <span class=""st"">""func2_meanfield""</span><span class=""op"">)</span><span class=""op"">)</span></span></code></pre></div>
+<pre><code><span><span class=""co"">## Results loaded from cache file 'func2_meanfield'</span></span></code></pre>
+<pre><code><span><span class=""co"">##  - 1 (1%) fits resulted in an error.</span></span></code></pre>
+<pre><code><span><span class=""co"">##  - 12 (12%) of fits did not converge.</span></span></code></pre>
+<pre><code><span><span class=""co"">## Not all diagnostics are OK.</span></span>
+<span><span class=""co"">## You can learn more by inspecting $default_diagnostics, $backend_diagnostics </span></span>
+<span><span class=""co"">## and/or investigating $outputs/$messages/$warnings for detailed output from the backend.</span></span></code></pre>
+<p>We see a lot of warnings and when we inspect the diagnostic plots, we
+see that meanfield variational inference doesn’t really work for this
+model.</p>
+<div class=""sourceCode"" id=""cb48""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""fu""><a href=""../reference/plot_rank_hist.html"">plot_rank_hist</a></span><span class=""op"">(</span><span class=""va"">results_func2_meanfield</span><span class=""op"">)</span></span></code></pre></div>
+<p><img src=""brms_files/figure-html/results_func2_meanfield_plots-1.png"" width=""700""></p>
+<div class=""sourceCode"" id=""cb49""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""fu""><a href=""../reference/ECDF-plots.html"">plot_ecdf_diff</a></span><span class=""op"">(</span><span class=""va"">results_func2_meanfield</span><span class=""op"">)</span></span></code></pre></div>
+<p><img src=""brms_files/figure-html/results_func2_meanfield_plots-2.png"" width=""700""></p>
+<p>What about fullrank variational inference? Let’s try</p>
+<div class=""sourceCode"" id=""cb50""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">backend_func2_fullrank</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/SBC_backend_brms.html"">SBC_backend_brms</a></span><span class=""op"">(</span><span class=""va"">y</span> <span class=""op"">~</span> <span class=""fl"">0</span> <span class=""op"">+</span> <span class=""va"">Intercept</span> <span class=""op"">+</span> <span class=""va"">x</span> <span class=""op"">+</span> <span class=""op"">(</span><span class=""fl"">1</span> <span class=""op"">|</span> <span class=""va"">group</span><span class=""op"">)</span>,  </span>
+<span>                            prior <span class=""op"">=</span> <span class=""va"">priors_func2</span>, warmup <span class=""op"">=</span> <span class=""fl"">1000</span>, iter <span class=""op"">=</span> <span class=""fl"">2000</span>, chains <span class=""op"">=</span> <span class=""fl"">2</span>,</span>
+<span>                            template_data <span class=""op"">=</span> <span class=""va"">datasets_func</span><span class=""op"">$</span><span class=""va"">generated</span><span class=""op"">[[</span><span class=""fl"">1</span><span class=""op"">]</span><span class=""op"">]</span>,</span>
+<span>                            algorithm <span class=""op"">=</span> <span class=""st"">""fullrank""</span>,</span>
+<span>                            out_stan_file <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/file.path.html"" class=""external-link"">file.path</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span>, <span class=""st"">""brms_linreg3.stan""</span><span class=""op"">)</span><span class=""op"">)</span></span>
+<span></span>
+<span><span class=""va"">results_func2_fullrank</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_SBC.html"">compute_SBC</a></span><span class=""op"">(</span><span class=""va"">datasets_func</span>, <span class=""va"">backend_func2_fullrank</span>, </span>
+<span>                                 dquants <span class=""op"">=</span> <span class=""va"">log_lik_dq_func</span>, </span>
+<span>                    cache_mode <span class=""op"">=</span> <span class=""st"">""results""</span>, </span>
+<span>                    cache_location <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/file.path.html"" class=""external-link"">file.path</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span>, <span class=""st"">""func2_fullrank""</span><span class=""op"">)</span><span class=""op"">)</span></span></code></pre></div>
+<pre><code><span><span class=""co"">## Results loaded from cache file 'func2_fullrank'</span></span></code></pre>
+<pre><code><span><span class=""co"">##  - 16 (16%) of fits did not converge.</span></span></code></pre>
+<pre><code><span><span class=""co"">## Not all diagnostics are OK.</span></span>
+<span><span class=""co"">## You can learn more by inspecting $default_diagnostics, $backend_diagnostics </span></span>
+<span><span class=""co"">## and/or investigating $outputs/$messages/$warnings for detailed output from the backend.</span></span></code></pre>
+<p>We once again see a lot of warnings and when we inspect the
+diagnostic plots, we see that fullrank variational inference is also not
+well suited here.</p>
+<div class=""sourceCode"" id=""cb54""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""fu""><a href=""../reference/plot_rank_hist.html"">plot_rank_hist</a></span><span class=""op"">(</span><span class=""va"">results_func2_fullrank</span><span class=""op"">)</span></span></code></pre></div>
+<p><img src=""brms_files/figure-html/results_func2_fullrank_plots-1.png"" width=""700""></p>
+<div class=""sourceCode"" id=""cb55""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""fu""><a href=""../reference/ECDF-plots.html"">plot_ecdf_diff</a></span><span class=""op"">(</span><span class=""va"">results_func2_fullrank</span><span class=""op"">)</span></span></code></pre></div>
+<p><img src=""brms_files/figure-html/results_func2_fullrank_plots-2.png"" width=""700""></p>
+<p>This is not so surprising as we know that Stan’s variational
+inference just isn’t very good. See also the <a href=""https://hyunjimoon.github.io/SBC/articles/computational_algorithm1.html"">ADVI
+vignette for plain Stan models</a>.</p>
 </div>
   </div>
 
   <div class=""col-md-3 hidden-xs hidden-sm"" id=""pkgdown-sidebar"">
 
-        <nav id=""toc"" data-toggle=""toc""><h2 data-toc-skip>Contents</h2>
-    </nav>
-</div>
+      </div>
 
 </div>
 
@@ -426,7 +500,7 @@ <h2 id=""using-custom-generator-code"">Using custom generator code<a class=""anchor
       <footer><div class=""copyright"">
   <p></p>
 <p>Developed by Shinyoung Kim, Angie.H Moon, Martin Modrák, Teemu Säilynoja.</p>
-<p>Site built with <a href=""https://pkgdown.r-lib.org/"" class=""external-link"">pkgdown</a> 2.0.7.</p>
+<p>Site built with <a href=""https://pkgdown.r-lib.org/"" class=""external-link"">pkgdown</a> 2.1.1.</p>
 </div>
 
 <div class=""pkgdown"">
@@ -438,10 +512,10 @@ <h2 id=""using-custom-generator-code"">Using custom generator code<a class=""anchor
       </footer>
 </div>
 
-  
 
 
-  
+
+
 
   </body>
 </html>

---FILE: vignettes/bad_parametrization.Rmd---
@@ -18,7 +18,8 @@ presented at SBC StanConnect. Feel free to head to the tutorial website to get a
 Let's setup the environment:
 
 ```{r setup, message=FALSE,warning=FALSE, results=""hide""}
-library(SBC); 
+library(SBC)
+library(ggplot2)
 use_cmdstanr <- getOption(""SBC.vignettes_cmdstanr"", TRUE) # Set to false to use rstan instead
 
 if(use_cmdstanr) {",True,True,Documentation / Formatting,6
hyunjimoon,SBC,8ec34f3128fb169d20628ec14daf42abf08cba82,Martin Modrák,modrak.mar@gmail.com,2024-12-09T08:44:18Z,Martin Modrák,modrak.mar@gmail.com,2024-12-09T08:44:18Z,Fixed failing tests,R/datasets.R;R/var_attributes.R;tests/testthat/test-bridgesampling.R;tests/testthat/test-datasets.R,False,True,True,False,20,18,38,"---FILE: R/datasets.R---
@@ -6,10 +6,12 @@ new_SBC_datasets <- function(variables, generated, var_attributes = NULL, parame
     }
   }
 
-  structure(list(variables = variables,
+  unvalidated <- structure(list(variables = variables,
                  generated = generated,
                  var_attributes = var_attributes),
             class = ""SBC_datasets"")
+
+  return(validate_SBC_datasets(unvalidated))
 }
 
 #' @export
@@ -73,9 +75,8 @@ SBC_datasets <- function(variables, generated, var_attributes = NULL, parameters
       variables <- parameters
     }
   }
-  x <-  new_SBC_datasets(variables, generated, var_attributes)
-  validate_SBC_datasets(x)
-  x
+  x <- new_SBC_datasets(variables, generated, var_attributes)
+  return(x)
 }
 
 #' @export
@@ -89,9 +90,10 @@ length.SBC_datasets <- function(x) {
 #' @export
 `[.SBC_datasets` <- function(x, indices) {
   validate_SBC_datasets(x)
-  new_SBC_datasets(posterior::subset_draws(x$variables, draw = indices, unique = FALSE),
+  res <- new_SBC_datasets(posterior::subset_draws(x$variables, draw = indices, unique = FALSE),
                    x$generated[indices],
                    var_attributes = x$var_attributes)
+  return(res)
 }
 
 #' Combine multiple datasets together.

---FILE: R/var_attributes.R---
@@ -26,7 +26,7 @@ validate_var_attributes <- function(var_attr) {
   }
 
   if(!is.list(var_attr) || !inherits(var_attr, ""var_attributes"")) {
-    stop(""`var_attributes` must be a list"")
+    stop(""`var_attributes` must either be NULL or a list inheriting from the `var_attributes` class"")
   }
 
   if(is.null(names(var_attr)) || any(names(var_attr) == """")) {

---FILE: tests/testthat/test-bridgesampling.R---
@@ -7,8 +7,8 @@ test_that(""combine_draws_matrix_for_bf"", {
   target <- posterior::draws_matrix(
     model_test = model_draws,
     a = c(1,20,3,40),
-    b = c(5, NA, 7, NA),
-    c = c(NA, 60, NA, 80),
+    b = c(5, -Inf, 7, -Inf),
+    c = c(-Inf, 60, -Inf, 80),
     .m0.a = dm0[,""a""],
     .m0.b = dm0[,""b""],
     .m1.a = dm1[,""a""],
@@ -19,8 +19,8 @@ test_that(""combine_draws_matrix_for_bf"", {
   target_NA_raw <- posterior::draws_matrix(
     model_test = model_draws,
     a = c(1,20,3,40),
-    b = c(5, NA, 7, NA),
-    c = c(NA, 60, NA, 80),
+    b = c(5, -Inf, 7, -Inf),
+    c = c(-Inf, 60, -Inf, 80),
     .m0.a = c(1,NA,3,NA),
     .m0.b = c(5, NA, 7,NA),
     .m1.a = c(NA, 20, NA, 40),
@@ -38,13 +38,13 @@ test_that(""combine_var_attributes_for_bf"", {
   expect_identical(
     combine_var_attributes_for_bf(dm0, dm1, var_attr0, var_attr1, model = ""mmm""),
     var_attributes(
-      .m0.a = c(hidden_var_attribute(), na_valid_var_attribute(), binary_var_attribute()),
-      .m0.b = c(hidden_var_attribute(), na_valid_var_attribute()),
-      .m1.a = c(hidden_var_attribute(), na_valid_var_attribute()),
-      .m1.c = c(hidden_var_attribute(), na_valid_var_attribute(), possibly_constant_var_attribute(), hidden_var_attribute()),
+      .m0.a = c(hidden_var_attribute(), submodel_var_attribute(0), binary_var_attribute()),
+      .m0.b = c(hidden_var_attribute(), submodel_var_attribute(0)),
+      .m1.a = c(hidden_var_attribute(), submodel_var_attribute(1)),
+      .m1.c = c(hidden_var_attribute(), submodel_var_attribute(1), possibly_constant_var_attribute(), hidden_var_attribute()),
       a = binary_var_attribute(),
-      b = na_lowest_var_attribute(),
-      c = c(na_lowest_var_attribute(), possibly_constant_var_attribute(), hidden_var_attribute()),
+      b = inf_valid_var_attribute(),
+      c = c(inf_valid_var_attribute(), possibly_constant_var_attribute(), hidden_var_attribute()),
       mmm = c(binary_var_attribute(), possibly_constant_var_attribute())
     )
   )

---FILE: tests/testthat/test-datasets.R---
@@ -73,7 +73,7 @@ test_that(""Generating datasets via functions - exceptions"", {
 })
 
 test_that(""subsetting datasets"", {
-  my_var_attributes <- list(
+  my_var_attributes <- var_attributes(
     mu = hidden_var_attribute()
   )
   list_function <- function(N) {
@@ -102,7 +102,7 @@ test_that(""subsetting datasets"", {
 })
 
 test_that(""binding datasets"", {
-  my_var_attributes <- list(
+  my_var_attributes <- var_attributes(
     mu = hidden_var_attribute()
   )
   list_function <- function(N) {",True,False,Implementation / Logic,6
hyunjimoon,SBC,c4f832cb54e44a088cc937f377aefa3177f7de42,martinmodrak,modrak.mar@gmail.com,2024-08-06T09:50:47Z,martinmodrak,modrak.mar@gmail.com,2024-08-06T09:50:47Z,"Fixed reading of CmdStan output for brms, update vignette",R/brms-helpers.R;R/util.R;vignettes/brms.Rmd,True,True,True,False,9,12,21,"---FILE: R/brms-helpers.R---
@@ -104,7 +104,7 @@ sampling_backend_from_stanmodel <- function(stanmodel, args) {
 brmsfit_from_stanfit <- function(fit, brmsargs) {
   fit_brms <- do.call(brms::brm, combine_args(brmsargs, list(empty = TRUE)))
   if(inherits(fit, ""CmdStanMCMC"")) {
-    fit_brms$fit <- rstan::read_stan_csv(fit$output_files())
+    fit_brms$fit <- brms::read_csv_as_stanfit(fit$output_files())
   } else {
     fit_brms$fit <- fit
   }

---FILE: R/util.R---
@@ -37,7 +37,7 @@ require_package_version <- function(package, version, purpose) {
 }
 
 require_brms_version <- function(purpose) {
-  require_package_version(""brms"", ""2.16.1"", purpose)
+  require_package_version(""brms"", ""2.21.0"", purpose)
 }
 
 require_cmdstanr_version <- function(purpose) {

---FILE: vignettes/brms.Rmd---
@@ -183,8 +183,6 @@ vignette for discussion on why this is useful).
 ```{r}
 log_lik_dq_func <- derived_quantities(
   log_lik = sum(dnorm(y, b_Intercept + x * b_x + r_group[group], sigma, log = TRUE))
-  # Testing CRPS, probably not worth it
-  #, CRPS = mean(scoringRules::crps_norm(y, b_Intercept + x * b_x + r_group[group], sigma))
   )
 
 ```
@@ -196,7 +194,7 @@ datasets_func <- generate_datasets(n_sims_generator, 100)
 ```
 
 This is then our `brms` backend - note that `brms` requires us to provide a
-dataset that it will use to build the model (e.g. to see how many levels of 
+dataset (`template_data`) that it will use to build the model (e.g. to see how many levels of 
 various varying intercepts to include):
 
 ```{r}
@@ -209,6 +207,7 @@ priors_func <- prior(normal(0,1), class = ""b"") +
 backend_func <- SBC_backend_brms(y ~ x + (1 | group),  
                       prior = priors_func, chains = 1,
                       template_data = datasets_func$generated[[1]],
+                      control = list(adapt_delta = 0.95),
                       out_stan_file = file.path(cache_dir, ""brms_linreg2.stan""))
 
 ```
@@ -250,8 +249,9 @@ priors_func2 <- prior(normal(0,1), class = ""b"") +
 
 
 backend_func2 <- SBC_backend_brms(y ~ 0 + Intercept + x + (1 | group),  
-                            prior = priors_func2, warmup = 1000, iter = 2000, chains = 1,
+                            prior = priors_func2, warmup = 1000, iter = 2000, chains = 2,
                             template_data = datasets_func$generated[[1]],
+                            control = list(adapt_delta = 0.95),
                             out_stan_file = file.path(cache_dir, ""brms_linreg3.stan""))
 
 
@@ -266,14 +266,11 @@ results_func2 <- compute_SBC(datasets_func, backend_func2,
                     cache_location = file.path(cache_dir, ""func2""))
 ```
 
-We see that this still results in some problematic fits,
-but the proportion got lower. At this point I am honestly unsure
-what is the issue, but the rank plots look mostly OK:
+We see that this still results in a small number of mildly problematic fits, 
+which is enough for our purposes (likely ramping up `adapt_delta` even higher 
+would help). The rank plots look mostly OK:
 
 ```{r results_func2_plots}
 plot_rank_hist(results_func2)
 plot_ecdf_diff(results_func2)
 ```
-
-
-I promise to update this vignette once I figure out the source of the problems.",True,True,Documentation / Formatting,4
hyunjimoon,SBC,fe586dcb99a917aba3ad385ed0f2cf66d514a922,martinmodrak,modrak.mar@gmail.com,2024-07-29T16:51:17Z,martinmodrak,modrak.mar@gmail.com,2024-07-29T16:51:17Z,Fixed bad number of draws in brms generator,R/generator-brms.R,False,True,True,False,1,1,2,"---FILE: R/generator-brms.R---
@@ -174,7 +174,7 @@ brms_full_ppred <- function(fit, newdata = NULL, draws = NULL, validate_all = FA
   if(is.null(newdata)) newdata <- fit$data
   n <- nrow(newdata)
   # 2.3. if no draws set, range from 1 to all iters (check draws < iters)
-  if(is.null(draws)) draws <- seq_len(sum(fit$fit@sim$n_save))
+	if(is.null(draws)) draws <- seq_len(posterior::ndraws(fit))
   # 2.4. create list to hold data
   pp_data <- list()
 ",True,False,Implementation / Logic,6
hyunjimoon,SBC,218da2628d5146aca3b8c2f43e0d2886b2406b5a,martinmodrak,modrak.mar@gmail.com,2024-06-25T09:32:52Z,martinmodrak,modrak.mar@gmail.com,2024-06-25T09:32:52Z,Fix namespace in bridgesampling,R/backend-bridgesampling.R,False,True,True,False,1,1,2,"---FILE: R/backend-bridgesampling.R---
@@ -126,7 +126,7 @@ SBC_fit_to_diagnostics.SBC_fit_bridgesampling <- function(fit, fit_output, fit_m
   get_percentage_error <- function(bridge) {
     errm <- bridgesampling::error_measures(bridge)
     if(inherits(bridge, ""bridge_list"")) {
-      base <- logml(bridge)
+      base <- bridgesampling::logml(bridge)
       perc_raw <- errm$IQR / base
       return(perc_raw * 100)
     } else {",True,False,Implementation / Logic,3
hyunjimoon,SBC,b4755750f2ac54f3fcc04a973ca84ae8e637ec2a,martinmodrak,modrak.mar@gmail.com,2024-06-16T16:18:15Z,martinmodrak,modrak.mar@gmail.com,2024-06-16T16:18:15Z,Fix bridgesampling backend for brms,R/backend-bridgesampling.R,False,True,True,False,1,1,2,"---FILE: R/backend-bridgesampling.R---
@@ -32,7 +32,7 @@ SBC_fit_to_bridge_sampler.SBC_backend_rstan_sample <- function(backend, fit, gen
 }
 
 #' @export
-SBC_fit_to_bridge_sampler.SBC_backend_brms <- function(backend, fit, ...) {
+SBC_fit_to_bridge_sampler.SBC_backend_brms <- function(backend, fit, generated, ...) {
   bridgesampling::bridge_sampler(fit, ...)
 }
 ",True,False,Documentation / Formatting,3
hyunjimoon,SBC,c40911cfeddb9de5a2aeb1a69da116024900069e,martinmodrak,modrak.mar@gmail.com,2024-04-12T19:58:32Z,martinmodrak,modrak.mar@gmail.com,2024-04-12T19:58:32Z,Fixed limit bug in calculate,R/calculate.R,False,True,True,False,1,1,2,"---FILE: R/calculate.R---
@@ -29,7 +29,7 @@ adjust_gamma_optimize <- function(N, K, conf_level=0.95) {
 
     # pre-compute quantiles and use symmetry for increased efficiency.
     x2_lower <- qbinom(gamma / 2, N, z2)
-    x2_upper <- c(N - rev(x2_lower)[2:K], 1)
+    x2_upper <- c(N - rev(x2_lower)[2:K], N)
 
     # Compute the total probability of trajectories inside the confidence
     # intervals. Initialize the set and corresponding probasbilities known",True,False,Implementation / Logic,3
hyunjimoon,SBC,bec104d4e530d24e176269e7c85fe68edf63dbb3,Luna Fazio,boris.fazio@outlook.com,2024-03-12T14:04:37Z,Luna Fazio,boris.fazio@outlook.com,2024-03-12T14:04:37Z,more informative error message,R/plot.R,False,True,True,False,2,2,4,"---FILE: R/plot.R---
@@ -469,8 +469,8 @@ data_for_ecdf_plots.matrix <- function(x,
     if(!is.list(combine) | is.null(names(combine))) {
       stop(""`combine` must be a named list"")
     }
-    if(is.null(combine_alpha)) {
-      stop(""`combine_alpha` must be specified"")
+    if(!is.function(combine_alpha)) {
+      stop(""`combine_alpha` must be a function"")
     }
     if(!identical(unique(table(unlist(combine))), 1L)) {
       stop(""Duplicated variable names are not allowed in `combine`"")",True,False,Implementation / Logic,6
hyunjimoon,SBC,22e70a52bb00f1c191273b919c2ca0eac2c19fbf,Martin Modrák,modrak.mar@gmail.com,2023-01-30T16:08:10Z,Martin Modrák,modrak.mar@gmail.com,2023-01-30T16:08:10Z,Fixed plot legend in non-default themes,R/plot.R,False,True,True,False,8,8,16,"---FILE: R/plot.R---
@@ -184,14 +184,14 @@ plot_ecdf <- function(x,
   )
 
   # construct figure
-  ggplot(ecdf_df) +
+  ggplot(ecdf_df, aes(color = type, fill = type)) +
     geom_ribbon(
       data = limits_df_trans,
-      aes(x = x, ymax = ymax, ymin = ymin, color = type, fill = type),
+      aes(x = x, ymax = ymax, ymin = ymin),
       alpha = alpha,
       size = size) +
     geom_step(
-      aes(x = z, y = ecdf, color = type)
+      aes(x = z, y = ecdf)
     ) +
     scale_y_continuous(breaks = c(0, 0.5, 1)) +
     scale_color_manual(
@@ -207,7 +207,7 @@ plot_ecdf <- function(x,
     scale_fill_manual(
       name = """",
       values = c(""theoretical CDF"" = ""skyblue"",
-                 ""sample ECDF"" = NA),
+                 ""sample ECDF"" = ""transparent""),
       labels = c(
         ""theoretical CDF"" = expression(italic(""theoretical CDF"")),
         ""sample ECDF"" = expression(italic(""sample ECDF""))
@@ -253,14 +253,14 @@ plot_ecdf_diff <- function(x,
     ymin = limits_df$lower / N - c(rep(z[1:K], each = 2), 1),
     type = ""theoretical CDF""
   )
-  ggplot(ecdf_df) +
+  ggplot(ecdf_df, aes(color = type, fill = type)) +
     geom_ribbon(
       data = limits_df_trans,
-      aes(x = x, ymax = ymax, ymin = ymin, color = type, fill = type),
+      aes(x = x, ymax = ymax, ymin = ymin),
       alpha = alpha,
       size = size) +
     geom_step(
-      aes(x = z, y = z_diff, color = type)
+      aes(x = z, y = z_diff)
     ) +
     scale_color_manual(
       name = """",
@@ -275,7 +275,7 @@ plot_ecdf_diff <- function(x,
     scale_fill_manual(
       name = """",
       values = c(""theoretical CDF"" = ""skyblue"",
-                 ""sample ECDF"" = NA),
+                 ""sample ECDF"" = ""transparent""),
       labels = c(
         ""theoretical CDF"" = expression(italic(""theoretical CDF"")),
         ""sample ECDF"" = expression(italic(""sample ECDF""))",True,False,Implementation / Logic,6
hyunjimoon,SBC,2e7a0af3014aa34e97734fa5036a345a06ae059f,martinmodrak,modrak.mar@gmail.com,2023-01-28T20:46:35Z,martinmodrak,modrak.mar@gmail.com,2023-01-28T20:46:35Z,Fixed #77,R/datasets.R,False,True,True,False,6,2,8,"---FILE: R/datasets.R---
@@ -317,13 +317,17 @@ generate_datasets.SBC_generator_brms <- function(generator, n_sims, n_datasets =
       # Change once https://github.com/stan-dev/cmdstanr/issues/205
       # is resolved
       summ <- prior_fit$summary() # Can trigger warnings for treedepth/divergent ...
-      max_rhat <- max(summ$rhat)
+      if(any(is.na(summ$rhat)) || any(is.na(summ$ess_bulk))) {
+        message(""Some rhats / bulk effective sample sizes are NA.\n"",
+                ""This is not a problem if you have constant elements in your model or you generated very few datasets and/or used little thinning."")
+      }
+      max_rhat <- max(c(-Inf, summ$rhat), na.rm = TRUE)
       if(max_rhat > 1.01) {
         message(""Warning: Some rhats are > 1.01 indicating the prior was not explored well.\n"",
                 ""The highest rhat is "", round(max_rhat, 2),"" for "", summ$variable[which.max(summ$rhat)],
                 ""\nConsider adding warmup iterations (via 'warmup' argument)."")
       }
-      min_ess <- min(summ$ess_bulk)
+      min_ess <- min(c(Inf, summ$ess_bulk), na.rm = TRUE)
       if(min_ess < n_sims / 2) {
         message(""Warning: Bulk effective sample size for some parameters is less than half the number of simulations.\n"",
                 ""The lowest ESS_bulk/n_sims is "", round(min_ess / n_sims, 2),"" for "", summ$parameter[which.min(summ$ess_bulk)],",True,False,Implementation / Logic,6
hyunjimoon,SBC,1c5638d008f46968d3c964c6283326002a6905b8,Martin Modrák,modrak.mar@gmail.com,2022-07-27T16:48:56Z,Martin Modrák,modrak.mar@gmail.com,2022-07-27T16:48:56Z,Speedup/fix in dataset preparations for parallel processing,R/datasets.R;R/results.R,False,True,True,False,2,2,4,"---FILE: R/datasets.R---
@@ -417,6 +417,7 @@ generate_datasets.SBC_generator_brms <- function(generator, n_sims, n_datasets =
 draws_rvars_to_standata <- function(x) {
   res <- list()
   for(i in 1:posterior::ndraws(x)) {
+    # TODO use direct indexing - subset_draws is unnecessarily slow
     res[[i]] <- draws_rvars_to_standata_single(posterior::subset_draws(x, draw = i))
   }
   res

---FILE: R/results.R---
@@ -466,8 +466,7 @@ compute_SBC <- function(datasets, backend,
   vars_and_generated_list <- list()
   for(i in 1:length(datasets)) {
     vars_and_generated_list[[i]] <- list(
-      variables = posterior::subset_draws(datasets$variables,
-                                           draw = i),
+      variables = datasets$variables[i,],
       generated = datasets$generated[[i]]
     )
   }",True,False,Implementation / Logic,6
hyunjimoon,SBC,656fd3f33d48e6da5d7a4f98414443fbac50b40a,Martin Modrák,modrak.mar@gmail.com,2022-07-25T10:56:55Z,Martin Modrák,modrak.mar@gmail.com,2022-07-25T10:56:55Z,Fixed a bug in globals merging,R/results.R,False,True,True,False,2,3,5,"---FILE: R/results.R---
@@ -462,15 +462,14 @@ compute_SBC <- function(datasets, backend,
     future.globals <- globals
   } else {
     gq_globals <- attr(gen_quants, ""globals"")
-    if(length(globals) > 0 && length(gq_globals > 0)) {
+    if(length(globals) > 0 && length(gq_globals)  > 0) {
       if(is.list(gq_globals) && !is.list(globals)) {
         stop(SBC_error(""Not implemented: Currently, when globals in generated quantites are a list, globals argument has to be also a list  (not a character vector).""))
       } else if(!is.list(gq_globals) && is.list(globals)) {
         stop(SBC_error(""Not implemented: Currently, when globals is a list, globals in generated quantites have to be also a list (not a character vector).""))
       }
       future.globals <- c(globals, gq_globals)
-    }
-    if(length(gq_globals) > 0) {
+    } else if(length(gq_globals) > 0) {
       future.globals <- gq_globals
     } else {
       future.globals <- globals",True,False,Implementation / Logic,6
hyunjimoon,SBC,9ded19466121b6eb41dc9896fb0013ddd7ddbbfe,martinmodrak,modrak.mar@gmail.com,2022-07-07T13:02:10Z,martinmodrak,modrak.mar@gmail.com,2022-07-07T13:02:10Z,Fixed a bug in bind_results when NULLs are present,R/results.R;tests/testthat/test-results.R,False,True,True,False,33,6,39,"---FILE: R/results.R---
@@ -62,7 +62,7 @@ validate_SBC_results <- function(x) {
   }
 
   if(!is.data.frame(x$default_diagnostics)) {
-    stop(""If the SBC_results object has a 'default_diagnostics' field, it has to inherit from data.frame"")
+    stop(""The SBC_results needs a 'default_diagnostics' field, and it has to inherit from data.frame"")
   }
 
   # Ensure backwards compatibility
@@ -183,10 +183,17 @@ bind_results <- function(...) {
 
   # Combines multiple data frame objects and then sorts by sim_id
   bind_and_rearrange_df <- function(df_list) {
-    dplyr::arrange(
-      do.call(rbind, df_list),
-      sim_id
-    )
+    null_dfs <- purrr::map_lgl(df_list, is.null)
+    if(all(null_dfs)) {
+      NULL
+    } else if(any(null_dfs)) {
+      stop(""Binding results where NULL and non-NULL components are mixed is not yet supported."")
+    } else {
+      dplyr::arrange(
+        do.call(rbind, df_list),
+        sim_id
+      )
+    }
   }
 
   # Apply the shifts of IDs to individual stats/diagnostics data frames

---FILE: tests/testthat/test-results.R---
@@ -72,14 +72,34 @@ test_that(""subset_bind"", {
     remove_sim_id_names <- function(x) {
         names(x$stats$sim_id) <- NULL
         names(x$default_diagnostics$sim_id) <- NULL
-        names(x$backend_diagnostics$sim_id) <- NULL
+        if(!is.null(x$backend_diagnostics)) {
+          names(x$backend_diagnostics$sim_id) <- NULL
+        }
         x
     }
 
     expect_equal(res, remove_sim_id_names(bind_results(res[1], res[2:3])))
     expect_equal(res, remove_sim_id_names(bind_results(res[1:2], res[3])))
     expect_equal(remove_sim_id_names(res[3:1]), remove_sim_id_names(bind_results(res[3:2], res[1])))
     expect_equal(remove_sim_id_names(res[2]), remove_sim_id_names(((res[2:3])[1])))
+
+    # The same, but with some NULLs
+    res2 <- SBC_results(stats = data.frame(sim_id = rep(1:3, each = 4), s = 1:12),
+                       fits = list(""A"", NULL, ""C""),
+                       outputs = rep(list(NULL), 3),
+                       warnings = rep(list(NULL), 3),
+                       messages = rep(list(NULL), 3),
+                       errors = rep(list(NULL), 3),
+                       default_diagnostics = data.frame(sim_id = 1:3, qq = rnorm(3)),
+                       backend_diagnostics = NULL
+    )
+
+    expect_equal(res2, remove_sim_id_names(bind_results(res2[1], res2[2:3])))
+    expect_equal(res2, remove_sim_id_names(bind_results(res2[1:2], res2[3])))
+    expect_equal(remove_sim_id_names(res2[3:1]), remove_sim_id_names(bind_results(res2[3:2], res2[1])))
+    expect_equal(remove_sim_id_names(res2[2]), remove_sim_id_names(((res2[2:3])[1])))
+
+
 })
 
 test_that(""calculate_ranks_draws_matrix works"", {",True,False,Implementation / Logic,6
hyunjimoon,SBC,8d4cd01ed55a260353f7602d444e978f5e808f21,Martin Modrák,modrak.mar@gmail.com,2022-07-01T10:59:51Z,Martin Modrák,modrak.mar@gmail.com,2022-07-01T10:59:51Z,Fix typo in adjust_gamma_simulate,R/calculate.R,False,True,True,False,1,1,2,"---FILE: R/calculate.R---
@@ -81,7 +81,7 @@ adjust_gamma_simulate <-function(N, L, K, conf_level=0.95, M=5000) {
       scaled_ecdf <- colSums(outer(u, z, ""<=""))
       gamma[m] <- 2 * min(
         pbinom(scaled_ecdf, N, z),
-        pbinom(scaled_ecdfs - 1, N, z, lower.tail = FALSE)
+        pbinom(scaled_ecdf - 1, N, z, lower.tail = FALSE)
       )
     }
   }",True,False,Implementation / Logic,3
hyunjimoon,SBC,8da96956b33fcf62f2797d003e59f4eebcd95e50,Martin Modrák,modrak.mar@gmail.com,2022-06-09T19:25:50Z,Martin Modrák,modrak.mar@gmail.com,2022-06-09T19:25:50Z,"Fix a bug in computation of coverage, less memory",R/calculate.R;tests/testthat/test-empirical-coverage.R,False,True,True,False,62,26,88,"---FILE: R/calculate.R---
@@ -217,31 +217,45 @@ empirical_coverage <- function(stats, width, prob = 0.95, interval_type = ""centr
     }
   }
 
-  long <- tidyr::crossing(stats, data.frame(width = width))
+  # Some juggling to reduce memory footprint
+  stats_trimmed <- dplyr::select(stats, variable, rank, max_rank)
+
+  variable_was_character <- is.character(stats_trimmed$variable)
+  if(variable_was_character) {
+    stats_trimmed <- dplyr::mutate(stats_trimmed, variable = factor(variable))
+  }
+
+
+  long <- dplyr::full_join(stats_trimmed, data.frame(width = width), by = character())
   long <- dplyr::mutate(long,
-                       n_ranks_covered = round((max_rank + 1) * width),
-                       low_rank = get_low_rank(max_rank, n_ranks_covered),
-                       high_rank = low_rank + n_ranks_covered - 1,
-                       width_represented =  (high_rank - low_rank + 1) / (max_rank + 1),
-                       is_covered = rank >= low_rank & rank <= high_rank)
-
-   summ <- dplyr::summarise(
-     dplyr::group_by(long, variable, width),
-     post_alpha = sum(is_covered) + 1,
-     post_beta = dplyr::n() - sum(is_covered) + 1,
-     width_represented = unique(width_represented),
-     # Special handling if width_represented is either 0 or 1 as in such case,
-     # the result can never be different from 0 / 1 and so the CI should collapse to a point
-     representable = width_represented > 0 & width_represented < 1,
-     ci_low =  dplyr::if_else(representable,
-                              qbeta(0.5 - prob / 2, post_alpha, post_beta),
-                              width_represented),
-     estimate = sum(is_covered) / dplyr::n(),
-     ci_high = dplyr::if_else(representable,
-                              qbeta(0.5 + prob / 2, post_alpha, post_beta),
-                              width_represented),
-     .groups = ""drop""
-   )
-
-   dplyr::select(summ, -post_alpha, -post_beta, -representable)
+                        n_ranks_covered = round((max_rank + 1) * width),
+                        low_rank = get_low_rank(max_rank, n_ranks_covered),
+                        high_rank = low_rank + n_ranks_covered - 1,
+                        width_represented =  (high_rank - low_rank + 1) / (max_rank + 1),
+                        is_covered = rank >= low_rank & rank <= high_rank)
+
+  summ <- dplyr::summarise(
+    dplyr::group_by(long, variable, width),
+    post_alpha = sum(is_covered) + 1,
+    post_beta = dplyr::n() - sum(is_covered) + 1,
+    width_represented = unique(width_represented),
+    # Special handling if width_represented is either 0 or 1 as in such case,
+    # the result can never be different from 0 / 1 and so the CI should collapse to a point
+    representable = width_represented > 0 & width_represented < 1,
+    ci_low =  dplyr::if_else(representable,
+                             qbeta(0.5 - prob / 2, post_alpha, post_beta),
+                             width_represented),
+    estimate = mean(is_covered),
+    ci_high = dplyr::if_else(representable,
+                             qbeta(0.5 + prob / 2, post_alpha, post_beta),
+                             width_represented),
+    .groups = ""drop""
+  )
+
+  if(variable_was_character) {
+    summ <- dplyr::mutate(summ, variable = as.character(variable))
+  }
+
+
+  dplyr::select(summ, -post_alpha, -post_beta, -representable)
 }

---FILE: tests/testthat/test-empirical-coverage.R---
@@ -0,0 +1,22 @@
+test_that(""empirical coverage and merging"", {
+  stats_rnd <- tidyr::crossing(variable = LETTERS[1:5], max_rank = 100, sim_id = 1:100)
+  stats_rnd <- dplyr::mutate(stats_rnd, rank = sample(0:100, size = dplyr::n(), replace = TRUE, prob = c(1:50,seq(200, 40, length.out = 51))))
+  #widths_to_test <- c(0.3,0.6,0.9)
+  widths_to_test <- c(0.3)
+  per_var <- empirical_coverage(stats_rnd, width = widths_to_test)
+  stats_merged <- dplyr::mutate(stats_rnd, variable = ""Merged"")
+  merged <- empirical_coverage(stats_merged, width = widths_to_test)
+
+  per_var_merged <- dplyr::summarise(
+    dplyr::group_by(per_var, width),
+    estimate_mean = mean(estimate),
+    min_ci_low = min(ci_low),
+    max_ci_high = max(ci_high)
+  )
+
+  expect_equal(merged$estimate, per_var_merged$estimate_mean)
+  for(i in length(widths_to_test)) {
+    expect_gt(merged$ci_low[i], per_var_merged$min_ci_low[i])
+    expect_lt(merged$ci_high[i], per_var_merged$max_ci_high[i])
+  }
+})",True,False,Implementation / Logic,6
hyunjimoon,SBC,bbdf9beb048fbf584796f0644038b6eb1a3e3825,Martin Modrák,modrak.mar@gmail.com,2022-06-03T13:54:05Z,Martin Modrák,modrak.mar@gmail.com,2022-06-03T13:54:05Z,Fixed subsetting results,R/results.R,False,True,True,False,4,3,7,"---FILE: R/results.R---
@@ -230,10 +230,11 @@ length.SBC_results <- function(x) {
   subset_run_df <- function(df) {
     if(is.null(df)) {
       NULL
+    } else {
+      filtered <- dplyr::filter(df, sim_id %in% indices_to_keep)
+      remapped <- dplyr::mutate(filtered, sim_id = index_map[as.character(sim_id)])
+      dplyr::arrange(remapped, sim_id)
     }
-    filtered <- dplyr::filter(df, sim_id %in% indices_to_keep)
-    remapped <- dplyr::mutate(filtered, sim_id = index_map[as.character(sim_id)])
-    dplyr::arrange(remapped, sim_id)
   }
 
   SBC_results(stats = subset_run_df(x$stats),",True,False,Implementation / Logic,6
hyunjimoon,SBC,939359b9914d029ba1f7f24cd33cb2114b6789ef,Martin Modrák,modrak.mar@gmail.com,2022-03-25T08:55:57Z,Martin Modrák,modrak.mar@gmail.com,2022-03-25T08:55:57Z,Fixed bug in gen quants,R/results.R,False,True,True,False,9,2,11,"---FILE: R/results.R---
@@ -882,9 +882,16 @@ compute_gen_quants <- function(draws, generated, gen_quants) {
   draws_rv <- posterior::as_draws_rvars(draws)
 
   draws_env <- list2env(draws_rv)
-  generated_env <- list2env(generated, parent = draws_env)
+  if(!is.null(generated)) {
+    if(!is.list(generated)) {
+      stop(""compute_gen_quants assumes that generated is a list, but this is not the case"")
+    }
+    generated_env <- list2env(generated, parent = draws_env)
 
-  data_mask <- rlang::new_data_mask(bottom = generated_env, top = draws_env)
+    data_mask <- rlang::new_data_mask(bottom = generated_env, top = draws_env)
+  } else {
+    data_mask <- rlang::new_data_mask(bottom = draws_env)
+  }
 
   eval_func <- function(gq) {
     # Wrap the expression in `rdo` which will mostly do what we need",True,False,Implementation / Logic,6
hyunjimoon,SBC,3b230e3b7f31d02def8bc50ade57107aea862e74,martinmodrak,modrak.mar@gmail.com,2022-01-26T21:35:47Z,martinmodrak,modrak.mar@gmail.com,2022-01-26T21:35:47Z,Fixed backwards incompatibility in ECDF plots,R/plot.R,False,True,True,False,13,0,13,"---FILE: R/plot.R---
@@ -322,6 +322,19 @@ data_for_ecdf_plots.data.frame <- function(x, variables = NULL,
     }
   }
 
+  if(""dataset_id"" %in% names(x)) {
+    if(!(""sim_id"" %in% names(x))) {
+      warning(""The x parameter contains a `dataset_id` column, which is deprecated, use `sim_id` instead."")
+      x$sim_id <- x$dataset_id
+    }
+  }
+
+
+  if(!all(c(""variable"", ""rank"", ""sim_id"") %in% names(x))) {
+    stop(SBC_error(""SBC_invalid_argument_error"",
+                   ""The stats data.frame needs a 'variable', 'rank' and 'sim_id' columns""))
+  }
+
   stats <- x
   if(!is.null(variables)) {
     stats <- dplyr::filter(stats, variable %in% variables)",True,False,Implementation / Logic,6
hyunjimoon,SBC,c67bec852cba516c659d8eeb81960c8987c4304c,martinmodrak,modrak.mar@gmail.com,2022-01-26T20:19:13Z,martinmodrak,modrak.mar@gmail.com,2022-01-26T20:19:13Z,"Detect silent errors, detect and recover from bad Hessian",R/backends.R;R/results.R;man/SBC_backend_rstan_optimizing.Rd;tests/testthat/test-results.R;vignettes/computational_algorithm1.Rmd,True,True,True,False,126,35,161,"---FILE: R/backends.R---
@@ -167,9 +167,16 @@ SBC_backend_hash_for_cache.SBC_backend_rstan_sample <- function(backend) {
 #' @param ... other arguments passed to `optimizing` (number of iterations, ...).
 #'   Argument `data` cannot be set this way as they need to be
 #'   controlled by the package.
+#' @param n_retries_hessian the number of times the backend is allow to retry optimization
+#' (with different seeed) to produce a usable Hessian that can produce draws. In some cases,
+#' the Hessian may be numerically unstable and not be positive definite.
 #' @export
-SBC_backend_rstan_optimizing <- function(model, ...) {
+SBC_backend_rstan_optimizing <- function(model, ..., n_retries_hessian = 1) {
   stopifnot(inherits(model, ""stanmodel""))
+  n_retries_hessian <- as.integer(n_retries_hessian)
+  stopifnot(length(n_retries_hessian) == 1)
+  stopifnot(n_retries_hessian > 0)
+
   args <- list(...)
   unacceptable_params <- c(""data"", ""hessian"")
   if(any(names(args) %in% unacceptable_params)) {
@@ -181,26 +188,42 @@ SBC_backend_rstan_optimizing <- function(model, ...) {
   args$hessian <- TRUE
   if(is.null(args$draws)) {
     args$draws <- 1000
+  } else if(args$draws <= 1) {
+    stop(""Cannot use optimizing backend with less than 2 draws"")
   }
-  structure(list(model = model, args = args), class = ""SBC_backend_rstan_optimizing"")
+  structure(list(model = model, args = args, n_retries_hessian = n_retries_hessian), class = ""SBC_backend_rstan_optimizing"")
 }
 
 
 #' @export
 SBC_fit.SBC_backend_rstan_optimizing <- function(backend, generated, cores) {
-  start <- proc.time()
-  fit <- do.call(rstan::optimizing,
-                 combine_args(list(object = backend$model,
-                                   data = generated),
-                              backend$args)
-  )
-  end <- proc.time()
+  for(attempt in 1:backend$n_retries_hessian) {
+    start <- proc.time()
+    fit <- do.call(rstan::optimizing,
+                   combine_args(list(object = backend$model,
+                                     data = generated),
+                                backend$args)
+    )
+    end <- proc.time()
+    fit$time <- (end - start)[""elapsed""]
+
+    if(fit$return_code != 0) {
+      stop(""Optimizing was not succesful"")
+    }
+    # This signals production of draws was OK
+    if(nrow(fit$theta_tilde) > 1) {
+      break;
+    }
+  }
+
+  fit$n_attempts <- attempt
 
-  if(fit$return_code != 0) {
-    stop(""Optimizing was not succesful"")
+  if(nrow(fit$theta_tilde) == 1) {
+    stop(""Optimizing did not return draws.\n"",
+    ""This is most likely due to numerical problems with the Hessian, check model output.\n"",
+    ""You may also consider increasing `n_retries_hessian`"")
   }
 
-  fit$time <- (end - start)[""elapsed""]
 
   structure(fit, class = ""RStanOptimizingFit"")
 }
@@ -224,7 +247,8 @@ SBC_backend_iid_samples.SBC_backend_rstan_optimizing <- function(backend) {
 #' @export
 SBC_fit_to_diagnostics.RStanOptimizingFit <- function(fit, fit_output, fit_messages, fit_warnings) {
   res <- data.frame(
-    time = fit$time
+    time = fit$time,
+    n_attempts = fit$n_attempts
   )
 
   class(res) <- c(""SBC_RStanOptimizing_diagnostics"", class(res))
@@ -234,7 +258,9 @@ SBC_fit_to_diagnostics.RStanOptimizingFit <- function(fit, fit_output, fit_messa
 #' @export
 summary.SBC_RStanOptimizing_diagnostics <- function(x) {
   summ <- list(
-    max_time = max(x$time)
+    n_fits = nrow(x),
+    max_time = max(x$time),
+    n_multiple_attempts = sum(x$n_attempts > 1)
   )
 
   structure(summ, class = ""SBC_RStanOptimizing_diagnostics_summary"")
@@ -249,7 +275,12 @@ get_diagnostic_messages.SBC_RStanOptimizing_diagnostics <- function(x) {
 #' @export
 get_diagnostic_messages.SBC_RStanOptimizing_diagnostics_summary <- function(x) {
   SBC_diagnostic_messages(
-    data.frame(ok = TRUE, message = paste0(""Maximum time was "", x$max_time, "" sec.""))
+    rbind(
+      data.frame(ok = TRUE, message = paste0(""Maximum time was "", x$max_time, "" sec."")),
+      data.frame(ok = x$n_multiple_attempts == 0,
+               message = paste0( x$n_multiple_attempts, "" ("", round(100 * x$n_multiple_attempts / x$n_fits),
+                                 ""%) of fits required multiple attempts to produce usable Hessian.""))
+    )
   )
 }
 
@@ -517,16 +548,7 @@ SBC_fit.SBC_backend_cmdstan_variational <- function(backend, generated, cores) {
     }
   }
 
-  #Re-emit outputs, warnings, messages
-  for(i in 1:length(fit_outputs)) {
-    cat(fit_outputs[[i]]$output, sep = ""\n"")
-    for(m in 1:length(fit_outputs[[i]]$messages)) {
-      message(fit_outputs[[i]]$messages[m])
-    }
-    for(w in 1:length(fit_outputs[[i]]$warnings)) {
-      warning(fit_outputs[[i]]$warnings[w])
-    }
-  }
+  reemit_captured(fit_outputs[[i]])
 
   if(all(fit$return_codes() != 0)) {
     stop(""Variational inference did not finish succesfully"")

---FILE: R/results.R---
@@ -478,7 +478,7 @@ compute_results <- function(datasets, backend,
   backend_diagnostics <- do.call(rbind, backend_diagnostics_list)
 
   if(!is.null(stats)) {
-    check_stats(stats, datasets, thin_ranks)
+    check_stats(stats, datasets, thin_ranks, SBC_backend_iid_samples(backend))
   } else {
     # Return dummy stats that let the rest of the code work.
     stats <- data.frame(dataset_id = integer(0), rhat = numeric(0), ess_bulk = numeric(0),
@@ -555,19 +555,36 @@ capture_all_outputs <- function(expr) {
     logs <<- new_l
   }
   output <- capture.output({
-    res <- withCallingHandlers(
+    previous_try_outfile <- getOption(""try.outFile"")
+    options(try.outFile = stdout())
+    res <- tryCatch(
+      withCallingHandlers(
       expr,
       warning=function(w) {
         add_log(""warning"", conditionMessage(w))
         invokeRestart(""muffleWarning"")
       }, message = function(m) {
         add_log(""message"", conditionMessage(m))
         invokeRestart(""muffleMessage"")
+      }),
+      finally = {
+        options(try.outFile = previous_try_outfile)
       })
   }, type = ""output"")
   list(result = res, messages = do.call(c, logs$message), warnings = do.call(c, logs$warning), output = output)
 }
 
+# Re-emit what was captured with capture_all_outputs
+reemit_captured <- function(captured) {
+  cat(captured$output, sep = ""\n"")
+  for(m in 1:length(captured$messages)) {
+    message(captured$messages[m], appendLF = FALSE)
+  }
+  for(w in 1:length(captured$warnings)) {
+    warning(captured$warnings[w])
+  }
+}
+
 
 compute_results_single <- function(params_and_generated, backend, cores,
                                    keep_fit, thin_ranks, gen_quants) {
@@ -693,17 +710,22 @@ statistics_from_single_fit <- function(fit, parameters, generated,
 }
 
 # check that the computed stats data frame hs problems
-check_stats <- function(stats, datasets, thin_ranks) {
+check_stats <- function(stats, datasets, thin_ranks, iid_samples) {
   unique_max_ranks <- unique(stats$max_rank)
   if(length(unique_max_ranks) != 1) {
     warning(""Differening max_rank across fits"")
   }
 
   if(min(unique_max_ranks) < 50) {
+    if(iid_samples) {
+      message_end = "" (the backend produces i.i.d. samples so thin_ranks = 1 is the most sensible).""
+    } else {
+      message_end = "".""
+    }
     warning(""Ranks were computed from fewer than 50 samples, the SBC checks will have low "",
             ""precision.\nYou may need to increase the number of samples from the backend and make sure that "",
             ""the combination of thinning in the backend and `thin_ranks` is sensible.\n"",
-            ""Currently thin_ranks = "", thin_ranks, ""."")
+            ""Currently thin_ranks = "", thin_ranks, message_end)
 
   }
 
@@ -812,7 +834,7 @@ recompute_statistics <- function(old_results, datasets, backend,
   }
 
   new_stats <- do.call(rbind, new_stats_list)
-  check_stats(new_stats, datasets, thin_ranks)
+  check_stats(new_stats, datasets, thin_ranks, SBC_backend_iid_samples(backend))
 
   new_results$stats <- new_stats
 

---FILE: man/SBC_backend_rstan_optimizing.Rd---
@@ -4,14 +4,18 @@
 \alias{SBC_backend_rstan_optimizing}
 \title{SBC backend using the \code{optimizing} method from \code{rstan}.}
 \usage{
-SBC_backend_rstan_optimizing(model, ...)
+SBC_backend_rstan_optimizing(model, ..., n_retries_hessian = 1)
 }
 \arguments{
 \item{model}{a \code{stanmodel} object (created via \code{rstan::stan_model})}
 
 \item{...}{other arguments passed to \code{optimizing} (number of iterations, ...).
 Argument \code{data} cannot be set this way as they need to be
 controlled by the package.}
+
+\item{n_retries_hessian}{the number of times the backend is allow to retry optimization
+(with different seeed) to produce a usable Hessian that can produce draws. In some cases,
+the Hessian may be numerically unstable and not be positive definite.}
 }
 \description{
 SBC backend using the \code{optimizing} method from \code{rstan}.

---FILE: tests/testthat/test-results.R---
@@ -1,18 +1,61 @@
 test_that(""capture_all_outputs"", {
     expect_identical(
         capture_all_outputs({
-            cat(""Test"")
+            cat(""Test\n"")
             warning(""W"")
             message(""M"", appendLF = FALSE)
             warning(""W2"")
             message(""M2"", appendLF = FALSE)
             message(""M3"", appendLF = FALSE)
+
+            # A special case - silent error
+            try(stop(""Error""))
+
             14
-            }),
+        }),
         list(result = 14,
              messages = c(""M"", ""M2"", ""M3""),
              warnings = c(""W"", ""W2""),
-             output = ""Test""))
+             output = c('Test', 'Error in try(stop(""Error"")) : Error')))
+
+    # Nested capture.output
+
+    expect_identical(
+        capture_all_outputs({
+            captured <- capture_all_outputs({
+                cat(""Test\n"")
+                warning(""W"")
+                message(""M"", appendLF = FALSE)
+
+                # A special case - silent error
+                try(stop(""Error""))
+
+                28
+
+            })
+            cat(""BEFORE\n"")
+            message(""M_BEFORE"", appendLF = FALSE)
+            warning(""W_BEFORE"")
+            try(stop(""E_BEFORE""))
+            reemit_captured(captured)
+            try(stop(""E_AFTER""))
+            warning(""W_AFTER"")
+            message(""M_AFTER"", appendLF = FALSE)
+            cat(""AFTER\n"")
+            13
+        }),
+        list(result = 13,
+             messages = c(""M_BEFORE"", ""M"", ""M_AFTER""),
+             warnings = c(""W_BEFORE"", ""W"", ""W_AFTER""),
+             output = c('BEFORE',
+                        'Error in try(stop(""E_BEFORE"")) : E_BEFORE',
+                        'Test',
+                        'Error in try(stop(""Error"")) : Error',
+                        'Error in try(stop(""E_AFTER"")) : E_AFTER',
+                        'AFTER'
+                        ))
+
+    )
 })
 
 test_that(""subset_bind"", {

---FILE: vignettes/computational_algorithm1.Rmd---
@@ -495,7 +495,7 @@ model_HMM_rstan <- stan_model(""stan/hmm_poisson.stan"")
 
 res_hmm_optimizing <- compute_results(
   ds_hmm_all, 
-  SBC_backend_rstan_optimizing(model_HMM_rstan),
+  SBC_backend_rstan_optimizing(model_HMM_rstan, n_retries_hessian = 3),
   cache_mode = ""results"", cache_location = file.path(cache_dir, ""hmm_optimizing""))
 ```
 ",True,True,Documentation / Formatting,6
hyunjimoon,SBC,575263dd57ef42bba10af85d1737ee1819dcfc18,martinmodrak,modrak.mar@gmail.com,2022-01-24T17:10:57Z,martinmodrak,modrak.mar@gmail.com,2022-01-24T17:10:57Z,"Updated vignettes to match


Fix associated bugs/issues",R/datasets.R;_pkgdown.yml;vignettes/bad_parametrization.Rmd;vignettes/basic_usage.Rmd;vignettes/brms.Rmd;vignettes/computational_algorithm1.Rmd;vignettes/discrete_vars.Rmd;vignettes/implementing_backends.Rmd;vignettes/indexing.Rmd;vignettes/limits_of_SBC.Rmd;vignettes/rejection_sampling.Rmd;vignettes/small_model_workflow.Rmd;vignettes/stan/discrete_vars1.stan,True,True,True,False,236,238,474,"---FILE: R/datasets.R---
@@ -320,7 +320,7 @@ generate_datasets.SBC_generator_brms <- function(generator, n_sims, n_datasets =
       max_rhat <- max(summ$rhat)
       if(max_rhat > 1.01) {
         message(""Warning: Some rhats are > 1.01 indicating the prior was not explored well.\n"",
-                ""The highest rhat is "", round(max_rhat, 2),"" for "", summ$parameter[which.max(summ$rhat)],
+                ""The highest rhat is "", round(max_rhat, 2),"" for "", summ$variable[which.max(summ$rhat)],
                 ""\nConsider adding warmup iterations (via 'warmup' argument)."")
       }
       min_ess <- min(summ$ess_bulk)

---FILE: _pkgdown.yml---
@@ -66,7 +66,7 @@ articles:
       - computational_algorithm1
       - implementing_backends
       - brms
-      - discrete_params
+      - discrete_vars
       - rejection_sampling
 
 reference:

---FILE: vignettes/bad_parametrization.Rmd---
@@ -40,9 +40,9 @@ options(mc.cores = parallel::detectCores())
 
 # Setup caching of results
 if(use_cmdstanr) {
-  cache_dir <- ""./bad_parametrization_SBC_cache""
+  cache_dir <- ""./_bad_parametrization_SBC_cache""
 } else {
-  cache_dir <- ""./bad_parametrization_rstan_SBC_cache""
+  cache_dir <- ""./_bad_parametrization_rstan_SBC_cache""
 }
 if(!dir.exists(cache_dir)) {
   dir.create(cache_dir)
@@ -81,16 +81,16 @@ Build a generator to create simulated datasets.
 
 ```{r}
 set.seed(21448857)
-n_datasets <- 10
+n_sims <- 10
 
-single_dataset_gamma <- function(N) {
+single_sim_gamma <- function(N) {
   shape <- rlnorm(n = 1, meanlog =  0, sdlog = 1)
   scale <- rlnorm(n = 1, meanlog = 0, sdlog = 1.5)
   
   y <- rgamma(N, shape = shape, scale = scale)
   
   list(
-    parameters = list(
+    variables = list(
       shape = shape,
       scale = scale),
     generated = list(
@@ -100,24 +100,24 @@ single_dataset_gamma <- function(N) {
 }
 
 
-generator_gamma <- SBC_generator_function(single_dataset_gamma, N = 40)
+generator_gamma <- SBC_generator_function(single_sim_gamma, N = 40)
 datasets_gamma <- generate_datasets(
   generator_gamma, 
-  n_datasets)
+  n_sims)
 
 ```
 
 
 ```{r}
-results_gamma <- compute_results(datasets_gamma, backend_gamma, 
+results_gamma <- compute_SBC(datasets_gamma, backend_gamma, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""model1""))
 ```
 
 Here we also use the caching feature to avoid recomputing the fits when recompiling this vignette. 
 In practice, caching is not necessary but is often useful.
 
-10 simulations are enough to see something is wrong with the model. The problem is best seen on an `ecdf_diff` plot - we even see the issue is primarily with the `scale` parameter!
+10 simulations are enough to see something is wrong with the model. The problem is best seen on an `ecdf_diff` plot - we even see the issue is primarily with the `scale` variable!
 
 ```{r results1_ecdf_diff}
 plot_ecdf_diff(results_gamma)
@@ -156,7 +156,7 @@ if(use_cmdstanr) {
 
 
 ```{r}
-results_gamma2 <- compute_results(datasets_gamma, backend_gamma_2, 
+results_gamma2 <- compute_SBC(datasets_gamma, backend_gamma_2, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""model2""))
 ```

---FILE: vignettes/basic_usage.Rmd---
@@ -26,7 +26,7 @@ The rough sketch of SBC is that we simulate some datasets and then for each simu
    - Where rank is defined as the number of draws < simulated value
 
 It can be shown that if model matched the generator and algorithm works correctly,
-then for each parameter, the ranks obtained in SBC should be uniformly distributed between $0$ and $S$.
+then for each variable, the ranks obtained in SBC should be uniformly distributed between $0$ and $S$.
 This corresponds quite directly to claims like 
 ""the posterior 84% credible interval should contain the simulated value in 84% of simulations"",
 the rank uniformity represents this claim for all interval widths at once. The theory of SBC is fully
@@ -110,16 +110,16 @@ To avoid confusion the package and the docs tries to consistently give the same
 
 
 To perform SBC, one needs to first generate simulated datasets and then fit the
-model to those datasets. The `SBC_datasets` object holds the simulated prior and data draws. 
+model to those simulations. The `SBC_datasets` object holds the simulated prior and data draws. 
 `SBC_datasets` objects can be created directly by the user, but it is often easier to use one
-of provided _Generator_ implementations that let you e.g. wrap a function  that returns the variables and simulated data for a single dataset or use a `brms` specification to generate
+of provided _Generator_ implementations that let you e.g. wrap a function  that returns the variables and observed data for a single simulation or use a `brms` specification to generate
 draws corresponding to a given `brms` model. 
 
 The other big part of the process is a  _backend_.
 The SBC package uses a backend object to actually fit the model to the simulated data and generate posterior draws. In short, backend bundles together the algorithm in which inference is run (`cmdstanr`, `rstan`, `brms`, `jags`, etc.), the model, and additional platform-specific inference parameters which are necessary to run inference for the model-platform combination (e.g. number of iterations, initial values, ...). 
 In other words backend is a function that takes data as its only input and provides posterior draws.
 
-Once we have a backend and an `SBC_datasets` instance, we can call `compute_results` 
+Once we have a backend and an `SBC_datasets` instance, we can call `compute_SBC` 
 to actually perform the SBC. The resulting object can then be passed to various plotting 
 and summarising functions to let us easily learn if our model works as expected. 
 
@@ -153,9 +153,9 @@ options(SBC.min_chunk_size = 5)
 
 # Setup caching of results
 if(use_cmdstanr) {
-  cache_dir <- ""./basic_usage_SBC_cache""
+  cache_dir <- ""./_basic_usage_SBC_cache""
 } else {
-  cache_dir <- ""./basic_usage_rstan_SBC_cache""
+  cache_dir <- ""./_basic_usage_rstan_SBC_cache""
 }
 if(!dir.exists(cache_dir)) {
   dir.create(cache_dir)
@@ -191,7 +191,7 @@ poisson_generator_single <- function(N){  # N is the number of data points we ar
   lambda <- rgamma(n = 1, shape = 15, rate = 5)
   y <- rpois(n = N, lambda = lambda)
   list(
-    parameters = list(
+    variables = list(
       lambda = lambda
     ),
     generated = list(
@@ -204,18 +204,18 @@ poisson_generator_single <- function(N){  # N is the number of data points we ar
 
 As you can see, the generator returns a named list containing random draws from the prior and generated data realized from the prior draws - the data are already in the format expected by Stan.
 
-### Create `SBC_Datasets` from generator
+### Create `SBC_datasets` from generator
 
 `SBC` provides helper functions `SBC_generator_function` and `generate_datasets` which takes a generator function and calls it repeatedly to create a valid `SBC_datasets` object. 
 
 ```{r}
 set.seed(54882235)
-n_datasets <- 100  # Number of SBC iterations to run
+n_sims <- 100  # Number of SBC iterations to run
 
 poisson_generator <- SBC_generator_function(poisson_generator_single, N = 40)
 poisson_dataset <- generate_datasets(
   poisson_generator, 
-  n_datasets)
+  n_sims)
 ```
 
 
@@ -239,10 +239,10 @@ if(use_cmdstanr) {
 
 ### Computing Ranks
 
-we can then use `compute_results` to fit our datasets with the backend:
+we can then use `compute_SBC` to fit our simulations with the backend:
 
 ```{r, results=FALSE}
-results <- compute_results(poisson_dataset, poisson_backend, 
+results <- compute_SBC(poisson_dataset, poisson_backend, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""results""))
 ```

---FILE: vignettes/brms.Rmd---
@@ -39,9 +39,9 @@ options(SBC.min_chunk_size = 5)
 
 # Setup caching of results
 if(use_cmdstanr) {
-  cache_dir <- ""./brms_SBC_cache""
+  cache_dir <- ""./_brms_SBC_cache""
 } else { 
-  cache_dir <- ""./brms_rstan_SBC_cache""
+  cache_dir <- ""./_brms_rstan_SBC_cache""
 }
 if(!dir.exists(cache_dir)) {
   dir.create(cache_dir)
@@ -59,7 +59,7 @@ cannot be found as it will most likely affect the generator and the backend in t
 Still this can be useful for validating `brms` itself - we'll get to validation
 with custom generators in a while. For now, we'll build a generator using `brms` directly.
 
-Generating datasets with this generator requires us to compile a Stan model 
+Generating simulations with this generator requires us to compile a Stan model 
 and may thus take a while. Also the exploration is often problematic, so 
 to avoid problems, we take a lot of draws and thin the resulting draws heavily.
 
@@ -97,15 +97,15 @@ backend <- SBC_backend_brms_from_generator(generator, chains = 1, thin = 1,
                             inits = 0.1)
 
 # More verbose alternative that results in exactly the same backend:
-# backend <- SBC_backend_brms(y ~ x, template_dataset = template_data, prior = priors, warmup = 500, iter = 1000, chains = 1, thin = 1
+# backend <- SBC_backend_brms(y ~ x, template_data = template_data, prior = priors, warmup = 500, iter = 1000, chains = 1, thin = 1
 #                            init = 0.1)
 ```
 
 
 Compute the actual results
 
 ```{r}
-results <- compute_results(datasets, backend,
+results <- compute_SBC(datasets, backend,
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""first""))
 ```
@@ -128,7 +128,7 @@ Let's take a bit more complex model - with a single varying intercept.
 This time we will not use the `brms` model to also simulate from prior, but 
 simulate using an R function. This way, we get to learn if `brms` does what we think it does!
 
-Custom generator code also allows us to have different covariate values for each dataset, potentially improving sensitivity
+Custom generator code also allows us to have different covariate values for each simulation, potentially improving sensitivity
 if we want to check the model for a range of potential covariate values.
 If on the other hand we are interested in a specific dataset, it might make
 more sense to use the predictors as seen in  the dataset in all simulations to focus
@@ -142,7 +142,7 @@ need to be careful to match the parameter names as `brms` uses them. You
 can call `parnames` on a fit to see them.
 
 ```{r}
-one_dataset_generator <- function(N, K) {
+one_sim_generator <- function(N, K) {
   # N - number of datapoints, K number of groups for the varying intercept
   stopifnot(3 * K <= N)
   x <- rnorm(N) + 5
@@ -165,7 +165,7 @@ one_dataset_generator <- function(N, K) {
   y <- rnorm(N, predictor, sigma)
   
   list(
-    parameters = list(
+    variables = list(
       b_Intercept = b_Intercept,
       b_x = b_x,
       sd_group__Intercept = sd_group__Intercept,
@@ -176,7 +176,7 @@ one_dataset_generator <- function(N, K) {
   )
 }
 
-n_dataset_generator <- SBC_generator_function(one_dataset_generator, N = 18, K = 5)
+n_sims_generator <- SBC_generator_function(one_sim_generator, N = 18, K = 5)
 ```
 
 For increased sensitivity, we also add the log likelihood of the data given parameters
@@ -192,7 +192,7 @@ log_lik_gq_func <- generated_quantities(
 
 ```{r}
 set.seed(12239755)
-datasets_func <- generate_datasets(n_dataset_generator, 100)
+datasets_func <- generate_datasets(n_sims_generator, 100)
 ```
 
 This is then our `brms` backend - note that `brms` requires us to provide a
@@ -208,13 +208,13 @@ priors_func <- prior(normal(0,1), class = ""b"") +
 
 backend_func <- SBC_backend_brms(y ~ x + (1 | group),  
                             prior = priors_func, chains = 1,
-                            template_dataset = datasets_func$generated[[1]])
+                            template_data = datasets_func$generated[[1]])
 
 ```
 So we can happily compute:
 
 ```{r}
-results_func <- compute_results(datasets_func, backend_func, 
+results_func <- compute_SBC(datasets_func, backend_func, 
                                 gen_quants = log_lik_gq_func, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""func""))
@@ -229,12 +229,12 @@ plot_rank_hist(results_func)
 plot_ecdf_diff(results_func)
 ```
 
-It looks like there is a problem affecting at least the `b_Intercept` and `sigma` parameters.
+It looks like there is a problem affecting at least the `b_Intercept` and `sigma` variables.
 We may also notice that the `log_lik` (log likelihood derived from all the parameters) is copying
-the behaviour of the worst behaving parameter. This tends to be the case in many models, so in models with lots of parameters, it can be useful to add such a term as they make noticing problems easier. 
+the behaviour of the worst behaving variable. This tends to be the case in many models, so in models with lots of variables, it can be useful to add such a term as they make noticing problems easier. 
 
 What happened is that `brms` by default centers all the predictors, which changes the
-numerical values of the intercept (but not other terms). The interaction with the prior than probably also affects the other parameters.
+numerical values of the intercept (but not other terms). The interaction with the prior than probably also affects the other variables.
 
 Maybe we don't want `brms` to do this --- using `0 + Intercept` syntax avoids the centering,
 so we build a new backend that should match our simulator better
@@ -250,15 +250,15 @@ priors_func2 <- prior(normal(0,1), class = ""b"") +
 
 backend_func2 <- SBC_backend_brms(y ~ 0 + Intercept + x + (1 | group),  
                             prior = priors_func2, warmup = 1000, iter = 2000, chains = 1,
-                            template_dataset = datasets_func$generated[[1]])
+                            template_data = datasets_func$generated[[1]])
 
 
 ```
 
-Let's fit the same datasets with the new backend.
+Let's fit the same simulations with the new backend.
 
 ```{r}
-results_func2 <- compute_results(datasets_func, backend_func2, 
+results_func2 <- compute_SBC(datasets_func, backend_func2, 
                                  gen_quants = log_lik_gq_func, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""func2""))

---FILE: vignettes/computational_algorithm1.Rmd---
@@ -21,7 +21,7 @@ penalizing tendencies of convergence metric, and slow convergence of the
 optimization process. We'll discuss 3 examples: 
 
 - In Example I a simple Poisson model is shown that is
-well handled by default ADVI if the size of the data is small, but becomes miscalibrated with larger datasets. It also turns out that for such a simple model using `optimizing` leads to very good results.
+well handled by default ADVI if the size of the data is small, but becomes miscalibrated when larger amount of observations is available. It also turns out that for such a simple model using `optimizing` leads to very good results.
 
 - In Example II we discuss a Hidden Markov Model where the approximation by ADVI is imperfect but not very wrong. We also show how the (mis)calibration responds to changing parameters of the ADVI implementation and that `optimizing` performs worse than ADVI.
 
@@ -73,7 +73,7 @@ options(SBC.min_chunk_size = 5)
 
 
 # Setup caching of results
-cache_dir <- ""./approximate_computation_SBC_cache""
+cache_dir <- ""./_approximate_computation_SBC_cache""
 if(!dir.exists(cache_dir)) {
   dir.create(cache_dir)
 }
@@ -98,7 +98,7 @@ poisson_generator_single <- function(N){
   lambda <- rgamma(n = 1, shape = 15, rate = 5)
   y <- rpois(n = N, lambda = lambda)
   list(
-    parameters = list(
+    variables = list(
       lambda = lambda
     ),
     generated = list(
@@ -130,9 +130,9 @@ Since the model runs quickly and is simple, we start with 1000 simulations.
 set.seed(46522641)
 ds_poisson <- generate_datasets(
   SBC_generator_function(poisson_generator_single, N = 20), 
-  n_datasets = 1000)
+  n_sims = 1000)
 res_poisson <- 
-  compute_results(
+  compute_SBC(
     ds_poisson, backend_poisson, keep_fits = FALSE,
     cache_mode = ""results"", cache_location = file.path(cache_dir, ""poisson""))
 ```
@@ -160,9 +160,9 @@ One would expect that the normal approximation implemented in ADVI becomes bette
 set.seed(23546224)
 ds_poisson_100 <- generate_datasets(
   SBC_generator_function(poisson_generator_single, N = 100), 
-  n_datasets = 1000)
+  n_sims = 1000)
 res_poisson_100 <- 
-  compute_results(ds_poisson_100, backend_poisson, keep_fits = FALSE,
+  compute_SBC(ds_poisson_100, backend_poisson, keep_fits = FALSE,
                   cache_mode = ""results"", cache_location = file.path(cache_dir, ""poisson_100""))
 ```
 
@@ -198,7 +198,7 @@ and use it to fit the same datasets - first to the one with `N = 20`.
 
 ```{r}
 res_poisson_optimizing <- 
-  compute_results(ds_poisson, backend_poisson_optimizing, keep_fits = FALSE,
+  compute_SBC(ds_poisson, backend_poisson_optimizing, keep_fits = FALSE,
     cache_mode = ""results"", cache_location = file.path(cache_dir, ""poisson_opt""))
 ```
 
@@ -213,7 +213,7 @@ Similarly, we can fit the `N = 100` datasets.
 
 ```{r}
 res_poisson_optimizing_100 <- 
-  compute_results(ds_poisson_100, backend_poisson_optimizing, keep_fits = FALSE,
+  compute_SBC(ds_poisson_100, backend_poisson_optimizing, keep_fits = FALSE,
     cache_mode = ""results"", cache_location = file.path(cache_dir, ""poisson_opt_100""))
 ```
 
@@ -286,7 +286,7 @@ generator_HMM <- function(N) {
   y <- rpois(N, mu[states])
   
   list(
-    parameters = list(
+    variables = list(
       mu_background = mu_background,
       mu_signal = mu_signal,
       # rdirichlet returns matrices, convert to 1D vectors
@@ -326,8 +326,8 @@ And we compute results
 
 ```{r}
 set.seed(642354822)
-ds_hmm <- generate_datasets(SBC_generator_function(generator_HMM, N = 100), n_datasets = 100)
-res_hmm <- compute_results(ds_hmm, backend_HMM,
+ds_hmm <- generate_datasets(SBC_generator_function(generator_HMM, N = 100), n_sims = 100)
+res_hmm <- compute_SBC(ds_hmm, backend_HMM,
                            cache_mode = ""results"", cache_location = file.path(cache_dir, ""hmm""))
 ```
 
@@ -348,19 +348,19 @@ To make sure this is not a fluke we add 400 more simulations.
 
 ```{r}
 set.seed(2254355)
-ds_hmm_2 <- generate_datasets(SBC_generator_function(generator_HMM, N = 100), n_datasets = 400)
+ds_hmm_2 <- generate_datasets(SBC_generator_function(generator_HMM, N = 100), n_sims = 400)
 ```
 
 ```{r}
 res_hmm_2 <- bind_results(
   res_hmm,
-  compute_results(ds_hmm_2,backend_HMM,
+  compute_SBC(ds_hmm_2,backend_HMM,
                   cache_mode = ""results"",
                   cache_location = file.path(cache_dir, ""hmm2""))
 )
 ```
 
-This confirms the problems with `mu_signal`. additionally, we see that `mu_background` and the `rho` parameters also show some irregularities.
+This confirms the problems with `mu_signal`. additionally, we see that `mu_background` and the `rho` variables also show some irregularities.
 
 ```{r hmm_2_ecdf_ranks}
 plot_ecdf_diff(res_hmm_2)
@@ -401,7 +401,7 @@ We may try if the situation improves with full-rank ADVI - let's run it for the
 
 ```{r}
 ds_hmm_all <- bind_datasets(ds_hmm, ds_hmm_2)
-res_hmm_fullrank <- compute_results(
+res_hmm_fullrank <- compute_SBC(
   ds_hmm_all, 
   SBC_backend_cmdstan_variational(model_HMM, algorithm = ""fullrank"", n_retries_init = 3),
   cache_mode = ""results"", cache_location = file.path(cache_dir, ""hmm_fullrank""))
@@ -417,7 +417,7 @@ plot_rank_hist(res_hmm_fullrank)
 Interestingly, the rank plot for `mu_signal` shows a ""frowning"" shape, meaning the
 mean-field approximation is slightly underconfident here.
 
-This is nicely demonstrated by looking at the central interval coverage - now the coverage of `mu_signal` is _larger_ than it should be, so the model is underconfident (i.e. more conservative), while the coverages for other parameters track the nominal values quite closely.
+This is nicely demonstrated by looking at the central interval coverage - now the coverage of `mu_signal` is _larger_ than it should be, so the model is underconfident (i.e. more conservative), while the coverages for other variables track the nominal values quite closely.
 
 ```{r hmm_fullrank_coverage}
 plot_coverage(res_hmm_fullrank)
@@ -444,7 +444,7 @@ optimization convergence. Here we'll use the default mean-field
 algorithm, but decrease the `tol_rel_obj` (the default value is 0.01). So let's try that.
 
 ```{r}
-res_hmm_lowtol <- compute_results(
+res_hmm_lowtol <- compute_SBC(
   ds_hmm_all, 
   SBC_backend_cmdstan_variational(model_HMM, tol_rel_obj = 0.001, n_retries_init = 3),
   cache_mode = ""results"", cache_location = file.path(cache_dir, ""hmm_lowtol""))
@@ -493,19 +493,16 @@ SBC:::require_package_version(""rstan"", ""2.26"", ""The models in the following sect
 
 model_HMM_rstan <- stan_model(""stan/hmm_poisson.stan"")
 
-res_hmm_optimizing <- compute_results(
+res_hmm_optimizing <- compute_SBC(
   ds_hmm_all, 
   SBC_backend_rstan_optimizing(model_HMM_rstan),
   cache_mode = ""results"", cache_location = file.path(cache_dir, ""hmm_optimizing""))
 ```
 
 
-
-
-
-We see that while for some parameters (`mu_signal`, the transition probabilities `t[]`), the Laplace approximation is reasonably well calibrated, it is very
+We see that while for some variables (`mu_signal`, the transition probabilities `t[]`), the Laplace approximation is reasonably well calibrated, it is very
 badly calibrated with respect to the initial states `rho` and also for `mu_background`, where there is substantial bias. So if we were only interested in
-a subset of the parameters, the optimizing fit could still be on OK choice.
+a subset of the variables, the optimizing fit could still be on OK choice.
 
 ```{r hmm_optimizing_ecdf_ranks}
 plot_ecdf_diff(res_hmm_optimizing)
@@ -519,7 +516,7 @@ To summarise, the HMM model turns out to pose minor problems for ADVI that can b
 Another relevant question is how much speed we gained. To have a comparison, we run full MCMC with Stan for the same datasets.
 
 ```{r}
-res_hmm_sample <- compute_results(
+res_hmm_sample <- compute_SBC(
   ds_hmm[1:50], 
   SBC_backend_cmdstan_sample(model_HMM),
   keep_fits = FALSE,
@@ -618,7 +615,7 @@ generator_HMM_ordered <- function(N) {
   y <- rpois(N, mu[states])
   
   list(
-    parameters = list(
+    variables = list(
       log_mu = log_mu,
       # rdirichlet returns matrices, convert to 1D vectors
       t1 = as.numeric(t1),
@@ -634,7 +631,7 @@ generator_HMM_ordered <- function(N) {
 ```
 
 
-So let us build a default variational backend and fit it to just 20 datasets.
+So let us build a default variational backend and fit it to just 20 simulations.
 
 ```{r}
 model_HMM_ordered <- cmdstan_model(""stan/hmm_poisson_ordered.stan"")
@@ -646,15 +643,15 @@ backend_HMM_ordered <- SBC_backend_cmdstan_variational(model_HMM_ordered, n_retr
 set.seed(12333654)
 ds_hmm_ordered <- generate_datasets(
   SBC_generator_function(generator_HMM_ordered, N = 100), 
-  n_datasets = 20)
+  n_sims = 20)
 
 res_hmm_ordered <- 
-  compute_results(ds_hmm_ordered, backend_HMM_ordered,
+  compute_SBC(ds_hmm_ordered, backend_HMM_ordered,
                   cache_mode = ""results"", cache_location = file.path(cache_dir, ""hmm_ordered""))
 ```
 
 
-Immediately we see that the `log_mu[1]` parameter is heavily miscalibrated.
+Immediately we see that the `log_mu[1]` variable is heavily miscalibrated.
 
 ```{r hmm_ordered_ecdf_ranks}
 plot_ecdf_diff(res_hmm_ordered)
@@ -675,7 +672,7 @@ backend_HMM_ordered_fullrank <-
                                   algorithm = ""fullrank"", n_retries_init = 3)
 
 res_hmm_ordered_fullrank <- 
-  compute_results(ds_hmm_ordered, backend_HMM_ordered,
+  compute_SBC(ds_hmm_ordered, backend_HMM_ordered,
                   cache_mode = ""results"", cache_location = file.path(cache_dir, ""hmm_ordered_fullrank""))
 ```
 
@@ -692,7 +689,7 @@ To have a complete overview we may also try the optimizing fit:
 ```{r}
 model_HMM_ordered_rstan <- stan_model(""stan/hmm_poisson_ordered.stan"")
 
-res_hmm_ordered_optimizing <- compute_results(
+res_hmm_ordered_optimizing <- compute_SBC(
   ds_hmm_ordered, 
   SBC_backend_rstan_optimizing(model_HMM_ordered_rstan),
   cache_mode = ""results"", cache_location = file.path(cache_dir, ""hmm_ordered_optimizing""))

---FILE: vignettes/discrete_vars.Rmd---
@@ -39,9 +39,9 @@ options(SBC.min_chunk_size = 5)
 
 # Setup caching of results
 if(use_cmdstanr) {
-  cache_dir <- ""./discrete_params_SBC_cache""
+  cache_dir <- ""./_discrete_vars_SBC_cache""
 } else {
-  cache_dir <- ""./discrete_params_rstan_SBC_cache""
+  cache_dir <- ""./_discrete_vars_rstan_SBC_cache""
 }
 if(!dir.exists(cache_dir)) {
   dir.create(cache_dir)
@@ -53,23 +53,23 @@ We take the changepoint model from:
 https://mc-stan.org/docs/2_26/stan-users-guide/change-point-section.html
 
 ```{r, comment = """"}
-cat(readLines(""stan/discrete_params1.stan""), sep = ""\n"")
+cat(readLines(""stan/discrete_vars1.stan""), sep = ""\n"")
 ```
 
 ```{r}
 if(use_cmdstanr) {
-  model_1 <- cmdstan_model(""stan/discrete_params1.stan"")
+  model_1 <- cmdstan_model(""stan/discrete_vars1.stan"")
   backend_1 <- SBC_backend_cmdstan_sample(model_1)
 } else {
-  model_1 <- stan_model(""stan/discrete_params1.stan"")
+  model_1 <- stan_model(""stan/discrete_vars1.stan"")
   backend_1 <- SBC_backend_rstan_sample(model_1)
 }
 ```
 
 Now, let's generate data from the model.
 
 ```{r}
-generate_single_dataset_1 <- function(T, r_e, r_l) {
+generate_single_sim_1 <- function(T, r_e, r_l) {
   e <- rexp(1, r_e)
   l <- rexp(1, r_l)
   s <- sample.int(T, size = 1)
@@ -85,7 +85,7 @@ generate_single_dataset_1 <- function(T, r_e, r_l) {
   }
   
   list(
-    parameters = list(
+    variables = list(
       e = e, l = l, s = s
     ), generated = list(
       T = T,
@@ -96,7 +96,7 @@ generate_single_dataset_1 <- function(T, r_e, r_l) {
   )
 }
 
-generator_1 <- SBC_generator_function(generate_single_dataset_1, T = 5, r_e = 0.5, r_l = 0.1)
+generator_1 <- SBC_generator_function(generate_single_sim_1, T = 5, r_e = 0.5, r_l = 0.1)
 ```
 
 
@@ -107,7 +107,7 @@ datasets_1 <- generate_datasets(generator_1, 30)
 ```
 
 ```{r}
-results_1 <- compute_results(datasets_1, backend_1, 
+results_1 <- compute_SBC(datasets_1, backend_1, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""model1""))
 ```
@@ -148,7 +148,7 @@ But back to the model - what happened? What is wrong with it? After some inspect
 
 
 ```{r}
-generate_single_dataset_2 <- function(T, r_e, r_l) {
+generate_single_sim_2 <- function(T, r_e, r_l) {
   e <- rexp(1, r_e)
   l <- rexp(1, r_l)
   s <- sample.int(T, size = 1)
@@ -164,7 +164,7 @@ generate_single_dataset_2 <- function(T, r_e, r_l) {
   }
   
   list(
-    parameters = list(
+    variables = list(
       e = e, l = l, s = s
     ), generated = list(
       T = T,
@@ -175,7 +175,7 @@ generate_single_dataset_2 <- function(T, r_e, r_l) {
   )
 }
 
-generator_2 <- SBC_generator_function(generate_single_dataset_2, T = 5, r_e = 0.5, r_l = 0.1)
+generator_2 <- SBC_generator_function(generate_single_sim_2, T = 5, r_e = 0.5, r_l = 0.1)
 ```
 
 And we can recompute:
@@ -184,7 +184,7 @@ And we can recompute:
 ```{r}
 set.seed(5846502)
 datasets_2 <- generate_datasets(generator_2, 30)
-results_2 <- compute_results(datasets_2, backend_1, 
+results_2 <- compute_SBC(datasets_2, backend_1, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""model2""))
 ```
@@ -200,7 +200,7 @@ Looks good, so let us add some more simulations to make sure the model behaves w
 ```{r}
 set.seed(54321488)
 datasets_3 <- generate_datasets(generator_2, 100)
-results_3 <- compute_results(datasets_3, backend_1, 
+results_3 <- compute_SBC(datasets_3, backend_1, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""model3""))
 

---FILE: vignettes/implementing_backends.Rmd---
@@ -31,7 +31,7 @@ library(formula.tools)
 library(MASS)
 
 # Setup caching of results
-cache_dir <- ""./implementing_backends_SBC_cache""
+cache_dir <- ""./_implementing_backends_SBC_cache""
 if(!dir.exists(cache_dir)) {
   dir.create(cache_dir)
 }
@@ -47,7 +47,7 @@ run the given statistical method.
 
 For practical reasons, the SBC package actually splits that function into two steps: first,
 there is an S3 generic [`SBC_fit()`](https://hyunjimoon.github.io/SBC/reference/SBC_fit.html),
-that takes a backend object, dataset and the number of cores it is allowed to use
+that takes a backend object, observed data and the number of cores it is allowed to use
 and produces an arbitrary object representing the fit. Additionally,
 there is an `SBC_fit_to_draws_matrix()` S3 generic that takes in the resulting fit
 and returns posterior draws in the `posterior::draws_matrix` format. 
@@ -67,7 +67,7 @@ of the backend. Here, we'll just capture all the arguments (which we will later
 SBC_backend_glm <- function(...) {
     args = list(...)
     if(any(names(args) == ""data"")) {
-      stop(paste0(""Parameter 'data' cannot be provided when defining a backend"",
+      stop(paste0(""Argument 'data' cannot be provided when defining a backend"",
                   "" as it needs to be set by the SBC package""))
     }
   
@@ -79,7 +79,7 @@ So e.g. `SBC_backend_glm(y ~ x, family = ""poisson"")` would create a valid
 backend representing a simple Poisson regression.
 
 Now we create an implementation of `SBC_fit` for the newly created class.
-We take the generated dataset (`generated` parameter) and pass it - along
+We take the generated data (`generated` argument) and pass it - along
 with all the arguments we stored in the constructor - to `glm` via `do.call`. 
 We ignore the `cores` argument as we don't have multicore support.
 
@@ -134,8 +134,8 @@ generator_single_poisson <- function(N) {
   y <- rpois(N, exp(mus))
   
   list(
-    parameters = list(
-      # Naming the parameters in the same way glm will name coefs
+    variables = list(
+      # Naming the variables in the same way glm will name coefs
       `(Intercept)` = log_intercept,
       x = beta
     ),
@@ -145,14 +145,14 @@ generator_single_poisson <- function(N) {
 
 set.seed(354662)
 datasets_poisson <- generate_datasets(SBC_generator_function(generator_single_poisson, N = 100), 
-                              n_datasets = 100)
+                              n_sims = 100)
 ```
 
 Then we'll construct a matching backend and compute the results.
 
 ```{r}
 backend_poisson <- SBC_backend_glm(y ~ x, family = ""poisson"")
-res_poisson <- compute_results(datasets_poisson, 
+res_poisson <- compute_SBC(datasets_poisson, 
                                backend_poisson, 
                                thin_ranks = 1,
                                cache_mode = ""results"", 
@@ -170,11 +170,11 @@ plot_rank_hist(res_poisson)
 plot_ecdf_diff(res_poisson)
 ```
 
-This is not unexpected - we've used a large dataset and a simple model, so
+This is not unexpected - we've used a large number of observations and a simple model, so
 choice of prior should have negligible impact on the posterior and the normal
 approximation is very close to the exact Bayesian solution. 
 
-We can see that both model parameters are recovered almost exactly in almost all 
+We can see that both variables are recovered almost exactly in almost all 
 fits:
 
 ```{r poisson_sim_estimated}
@@ -191,7 +191,7 @@ comfortable to use. Let's walk through the options and se and how they can be im
 Since (unlike MCMC methods) the `glm` approximation does 
 not produce autocorrelated draws, we can implement `SBC_backend_iid_draws`
 to return `TRUE`. The SBC package will then by default use `thin_ranks = 1`
-argument to `compute_results` and will not assess convergence/autocorrelation via the
+argument to `compute_SBC` and will not assess convergence/autocorrelation via the
 R-hat and ESS diagnostics.
 
 ```{r}
@@ -321,11 +321,11 @@ If you are implementing the backend to become part of the SBC package, nothing
 more is needed for paralellization to work. 
 If however you are just building an ad-hoc backend that lives
 in your global environment, you will also need to pass the three functions 
-to the `globals` argument of `compute_results` which will make them available on 
+to the `globals` argument of `compute_SBC` which will make them available on 
 all workers i.e. use:
 
 ```
-compute_results(..., globals = c(""SBC_fit.SBC_backend_glm"", 
+compute_SBC(..., globals = c(""SBC_fit.SBC_backend_glm"", 
                                  ""SBC_fit_to_draws_matrix.glm"",
                                  ""SBC_backend_iid_draws.SBC_backend_glm""))
 
@@ -355,23 +355,23 @@ by running only the approximate method (a lot of times) and look at SBC results.
 This may still be faster than running a single fully Bayesian fit. Additionally,
 fitting with an approximate algorithm can be useful to run 
 approximate power calculations where it lets us cheaply fit a lot of
-simulated datasets to e.g. understand how
+simulations to e.g. understand how
 the width of our posterior intervals changes with sample size
 and at the same time we learn, whether the approximation 
 is problematic in some way.
 
-For the sake of example, let's assume we've already gathered a dataset that
+For the sake of example, let's assume we've already gathered data that
 we want to analyze with Bayesian logistic regression. So our data generating
 process will use the observed covariate values but simulate new coefficients
 and outcome data. Below is a simple implementation with normal priors
 on the intercept and predictors. Note that we do some [rejection
 sampling](https://hyunjimoon.github.io/SBC/articles/rejection_sampling.html) 
-here to avoid using datasets where the generated response
+here to avoid using simulations where the generated response
 is the same or almost the same for all rows.
 
 ```{r}
 generator_single_logistic <- function(formula, 
-                                      dataset, 
+                                      template_data, 
                                       intercept_prior_loc = 0,
                                       intercept_prior_width = 2,
                                       predictor_prior_loc = 0,
@@ -381,7 +381,7 @@ generator_single_logistic <- function(formula,
     stop(""The formula has to have just a single response"")
   }
   
-  X <- model.matrix(formula, dataset)
+  X <- model.matrix(formula, template_data)
   
   repeat {
     coefs <- rnorm(ncol(X), predictor_prior_loc, sd = predictor_prior_width)
@@ -398,18 +398,18 @@ generator_single_logistic <- function(formula,
     }
   }
 
-  dataset_mod <- dataset
-  dataset_mod[[response_name]] <- y
+  data_mod <- template_data
+  data_mod[[response_name]] <- y
 
   list(
-    parameters = as.list(coefs),
-    generated = dataset_mod
+    variables = as.list(coefs),
+    generated = data_mod
   ) 
 }
 ```
 
 
-We are going to use the `indo_rct` dataset from the `medicaldata` package. The 
+We are going to use the `indo_rct` dataset from the `medicaldata` package as a template. The 
 dataset contains the results of a randomized, placebo-controlled, 
 prospective 2-arm trial of indomethacin 100 mg PR once vs. placebo to prevent post-ERCP Pancreatitis in 602 patients. You can inspect the [codebook](https://htmlpreview.github.io/?https://github.com/higgi13425/medicaldata/blob/master/man/codebooks/indo_rct_codebook.html) as well as the [published paper](https://www.nejm.org/doi/full/10.1056/NEJMoa1111103)
 online. The citation for the paper is:
@@ -427,15 +427,15 @@ set.seed(6524243)
 datasets_indo_simple <- generate_datasets(SBC_generator_function(
   generator_single_logistic, 
   formula = formula_indo_simple,
-  dataset = medicaldata::indo_rct),
-  n_datasets = 500) 
+  template_data = medicaldata::indo_rct),
+  n_sims = 500) 
 
 backend_indo_simple <- SBC_backend_glm(formula = formula_indo_simple, family = ""binomial"") 
 ```
 
 
 ```{r}
-res_indo_simple <- compute_results(datasets_indo_simple, backend_indo_simple,
+res_indo_simple <- compute_SBC(datasets_indo_simple, backend_indo_simple,
                                    cache_mode = ""results"", 
                                    cache_location = file.path(cache_dir,""indo_simple""))
 ```
@@ -474,15 +474,16 @@ plot_sim_estimated(res_indo_simple)
 ```
 
 There is a simulation where the posterior uncertainty is very large.
-This corresponds to dataset where the outcome is the same for all
+This corresponds to observed data where the outcome is the same for all
 rows where the treatment was used:
 
 ```{r}
-biggest_sd_dataset <- res_indo_simple$stats$sim_id[
+biggest_sd_sim <- res_indo_simple$stats$sim_id[
   which.max(res_indo_simple$stats$sd)]
-table(datasets_indo_simple$generated[[biggest_sd_dataset]][c(""outcome"", ""rx"")])
+table(datasets_indo_simple$generated[[biggest_sd_sim]][c(""outcome"", ""rx"")])
 ```
-Filtering the extreme datasets out,  we see that most commonly, we
+
+Filtering the extreme simulations out,  we see that most commonly, we
 get a decently precise estimate.
 
 ```{r indo_simple_sim_est}
@@ -517,8 +518,8 @@ formula_indo_complex <- outcome ~ rx + site + gender + age + risk
 datasets_indo_complex <- generate_datasets(SBC_generator_function(
   generator_single_logistic, 
   formula = formula_indo_complex,
-  dataset = indo_rct_complex),
-  n_datasets = 500) 
+  template_data = indo_rct_complex),
+  n_sims = 500) 
 
 backend_indo_complex <- SBC_backend_glm(formula = formula_indo_complex, family = ""binomial"") 
 ```
@@ -527,7 +528,7 @@ backend_indo_complex <- SBC_backend_glm(formula = formula_indo_complex, family =
 Now we are ready to run SBC:
 
 ```{r}
-res_indo_complex <- compute_results(datasets_indo_complex, backend_indo_complex,
+res_indo_complex <- compute_SBC(datasets_indo_complex, backend_indo_complex,
                                    cache_mode = ""results"", 
                                    cache_location = file.path(cache_dir,""indo_complex""))
 ```
@@ -569,21 +570,21 @@ set.seed(1685554)
 datasets_indo_complex_narrow <- generate_datasets(SBC_generator_function(
   generator_single_logistic, 
   formula = formula_indo_complex,
-  dataset = indo_rct_complex,
+  template_data = indo_rct_complex,
   intercept_prior_loc = 3,
   intercept_prior_width = 0.5,
   predictor_prior_loc = c(-2, 2),
   predictor_prior_width = 0.5),
-  n_datasets = 500) 
+  n_sims = 500) 
 ```
 
 ```{r}
-res_indo_complex_narrow <- compute_results(datasets_indo_complex_narrow, backend_indo_complex,
+res_indo_complex_narrow <- compute_SBC(datasets_indo_complex_narrow, backend_indo_complex,
                                    cache_mode = ""results"", 
                                    cache_location = file.path(cache_dir,""indo_complex_narrow""))
 ```
 
-This is enough to make basically all the parameters poorly calibrated:
+This is enough to make basically all the variables poorly calibrated:
 
 ```{r indo_complex_narrow_ranks}
 plot_rank_hist(res_indo_complex_narrow)
@@ -601,16 +602,16 @@ set.seed(3289542)
 datasets_indo_simple_narrow <- generate_datasets(SBC_generator_function(
   generator_single_logistic, 
   formula = formula_indo_simple,
-  dataset = medicaldata::indo_rct,
+  template_data = medicaldata::indo_rct,
   intercept_prior_loc = 3,
   intercept_prior_width = 0.5,
   predictor_prior_loc = c(-2, 2),
   predictor_prior_width = 0.5),
-  n_datasets = 500) 
+  n_sims = 500) 
 ```
 
 ```{r}
-res_indo_simple_narrow <- compute_results(datasets_indo_simple_narrow, backend_indo_simple,
+res_indo_simple_narrow <- compute_SBC(datasets_indo_simple_narrow, backend_indo_simple,
                                    cache_mode = ""results"", 
                                    cache_location = file.path(cache_dir,""indo_simple_narrow""))
 ```

---FILE: vignettes/indexing.Rmd---
@@ -31,9 +31,9 @@ if(use_cmdstanr) {
 
 # Setup caching of results
 if(use_cmdstanr) {
-  cache_dir <- ""./indexing_SBC_cache""
+  cache_dir <- ""./_indexing_SBC_cache""
 } else {
-  cache_dir <- ""./indexing_rstan_SBC_cache""
+  cache_dir <- ""./_indexing_rstan_SBC_cache""
 }
 if(!dir.exists(cache_dir)) {
   dir.create(cache_dir)
@@ -91,7 +91,7 @@ worry about performance here.
 
 ```{r}
 
-single_dataset_regression <- function(N, K) {
+single_sim_regression <- function(N, K) {
   x <- matrix(rnorm(n = N * K, mean = 0, sd = 1), nrow = N, ncol = K)
   alpha <- rnorm(n = 1, mean = 0, sd = 1)
   beta <- rnorm(n = K, mean = 0, sd = 1)
@@ -107,7 +107,7 @@ single_dataset_regression <- function(N, K) {
   }
   
   list(
-    parameters = list(
+    variables = list(
       alpha = alpha,
       beta = beta,
       sigma = sigma),
@@ -120,26 +120,26 @@ single_dataset_regression <- function(N, K) {
 }
 ```
 
-We'll start with just 10 datasets to get a quick computation - this will still
+We'll start with just 10 simulations to get a quick computation - this will still
 let us see big problems (but not subtle issues)
 
 ```{r}
 set.seed(5666024)
 datasets_regression <- generate_datasets(
-  SBC_generator_function(single_dataset_regression, N = 100, K = 2), 10)
+  SBC_generator_function(single_sim_regression, N = 100, K = 2), 10)
 ```
 
 
 Now we can use all of the backends to fit the generated datasets.
 
 ```{r}
-results_regression_1 <- compute_results(datasets_regression, backend_regression_1, 
+results_regression_1 <- compute_SBC(datasets_regression, backend_regression_1, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""regression1""))
-results_regression_2 <- compute_results(datasets_regression, backend_regression_2, 
+results_regression_2 <- compute_SBC(datasets_regression, backend_regression_2, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""regression2""))
-results_regression_3 <- compute_results(datasets_regression, backend_regression_3, 
+results_regression_3 <- compute_SBC(datasets_regression, backend_regression_3, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""regression3""))
 ```
@@ -165,7 +165,7 @@ plot_rank_hist(results_regression_2)
 
 But the second model is actually not looking good.  In fact there is an indexing bug. The problem is the line
 `mu[i] += beta[j] * x[j, j];` which should have `x[i, j]` instead. We see that this 
-propagates most strongly to the `sigma` parameter (reusing the same `x` element leads to more similar predictions for each row, so `sigma` needs to be inflated to accommodate this)
+propagates most strongly to the `sigma` variable (reusing the same `x` element leads to more similar predictions for each row, so `sigma` needs to be inflated to accommodate this)
 
 
 ```{r plots_regression3}

---FILE: vignettes/limits_of_SBC.Rmd---
@@ -41,9 +41,9 @@ options(SBC.min_chunk_size = 5)
 
 # Setup caching of results
 if(use_cmdstanr) {
-  cache_dir <- ""./limits_SBC_cache""
+  cache_dir <- ""./_limits_SBC_cache""
 } else {
-  cache_dir <- ""./limits_rstan_SBC_cache""  
+  cache_dir <- ""./_limits_rstan_SBC_cache""  
 }
 if(!dir.exists(cache_dir)) {
   dir.create(cache_dir)
@@ -103,32 +103,32 @@ if(use_cmdstanr) {
 }
 ```
 
-And here we simulate from a student's t distribution. We scale the distribution so that the `sigma` parameter
+And here we simulate from a student's t distribution. We scale the distribution so that `sigma`
 is the standard deviation of the distribution.
 
 ```{r}
-single_dataset_minor <- function(N) {
+single_sim_minor <- function(N) {
   mu <- rnorm(n = 1, mean = 0, sd = 1)
   sigma <- abs(rnorm(n = 1, mean = 0, sd = 1))
   nu <- 5
   student_scale <- sigma / sqrt(nu / (nu - 2))
   y <- mu + student_scale * rt(N, df = nu)
   
   list(
-    parameters = list(mu = mu, sigma = sigma),
+    variables = list(mu = mu, sigma = sigma),
     generated = list(N = N, y = y)
   )
 }
 
 set.seed(51336848)
-generator_minor <- SBC_generator_function(single_dataset_minor, N = 10)
-datasets_minor <- generate_datasets(generator_minor, n_datasets = 200)
+generator_minor <- SBC_generator_function(single_sim_minor, N = 10)
+datasets_minor <- generate_datasets(generator_minor, n_sims = 200)
 ```
 
-Can we see something by looking at the results of just the first 10 datasets? (note that `SBC_datasets` objects support subsetting).
+Can we see something by looking at the results of just the first 10 simulations? (note that `SBC_datasets` objects support subsetting).
 
 ```{r}
-results_minor_10 <- compute_results(datasets_minor[1:10], backend_minor, 
+results_minor_10 <- compute_SBC(datasets_minor[1:10], backend_minor, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""minor_10""))
 ```
@@ -140,19 +140,19 @@ plot_rank_hist(results_minor_10)
 plot_ecdf_diff(results_minor_10)
 ```
 
-Will we have better luck with 100 datasets? (Note that we can use `bind_results` to combine multiple results,
-letting us start small, but not throw away the computation spent for the initial SBC runs)
+Will we have better luck with 100 simulations? (Note that we can use `bind_results` to combine multiple results,
+letting us start small, but not throw away the computation spent for the initial simulations)
 
 ```{r}
 results_minor_100 <- bind_results(
   results_minor_10,
-  compute_results(datasets_minor[11:100], backend_minor, 
+  compute_SBC(datasets_minor[11:100], backend_minor, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""minor_90""))
 )
 ```
 
-Here we see something suspicios with the `sigma` parameter, but it is not very convincing.
+Here we see something suspicios with the `sigma` variable, but it is not very convincing.
 
 ```{r results_minor_100_plots}
 plot_rank_hist(results_minor_100)
@@ -164,7 +164,7 @@ So let's do additional 100 SBC steps
 ```{r}
 results_minor_200 <- bind_results(
   results_minor_100,
-  compute_results(datasets_minor[101:200], backend_minor, 
+  compute_SBC(datasets_minor[101:200], backend_minor, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""minor_next_100""))
 )
@@ -220,19 +220,19 @@ SBC will not notice if you completely omit likelihood from your Stan model!
 Here we have a generator for a very simple model with gaussian likelihood:
 
 ```{r}
-single_dataset_missing <- function(N) {
+single_sim_missing <- function(N) {
   mu <- rnorm(n = 1, mean = 0, sd = 1)
   y <- rnorm(n = N, mean = mu, sd = 1)
   
   list(
-    parameters = list(mu = mu),
+    variables = list(mu = mu),
     generated = list(N = N, y = y)
   )
 }
 
 set.seed(25746223)
-generator_missing <- SBC_generator_function(single_dataset_missing, N = 10)
-datasets_missing <- generate_datasets(generator_missing, n_datasets = 200)
+generator_missing <- SBC_generator_function(single_sim_missing, N = 10)
+datasets_missing <- generate_datasets(generator_missing, n_sims = 200)
 ```
 
 
@@ -263,10 +263,10 @@ if(use_cmdstanr) {
 ```
 
 
-Now we'll compute the results for 200 simulated datasets:
+Now we'll compute the results for 200 simulations:
 
 ```{r}
-results_missing <- compute_results(datasets_missing, backend_missing, 
+results_missing <- compute_SBC(datasets_missing, backend_missing, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""missing""))
 ```
@@ -283,7 +283,7 @@ It's just nothing out of the ordinary.
 But we are not completely helpless: 
 This specific type of problem can be noticed by prior/posterior contraction plot. 
 In this plot we compare the prior and posterior standard deviation to get a measure
-of how much more we know about the parameter after fitting the model.
+of how much more we know about the variable after fitting the model.
 For this model, we can
 get the prior sd directly, but one can also use a (preferably large) `SBC_datasets` object
 to estimate it empirically for more complex models.
@@ -306,7 +306,7 @@ plot_sim_estimated(results_missing, alpha = 0.5)
 
 There is however even more powerful method - and that is to include the likelihood in the SBC.
 This is most easily done by adding a ""generated quantity"" to the SBC results - this is a function
-that is evaluated within the context of the parameters AND data. 
+that is evaluated within the context of the variables AND data. 
 And it can be added without recomputing the fits!
 
 ```{r}
@@ -317,7 +317,7 @@ normal_lpdf <- function(y, mu, sigma) {
 log_lik_gq <- generated_quantities(log_lik = normal_lpdf(y, mu, 1), 
                                    .globals = ""normal_lpdf"" )
 
-results_missing_gq <- recompute_statistics(
+results_missing_gq <- recompute_SBC_statistics(
   results_missing, datasets_missing, 
   backend = backend_missing, gen_quants = log_lik_gq)
 ```
@@ -355,24 +355,24 @@ if(use_cmdstanr) {
 
 ```
 
-Let us use this model for the same dataset.
+Let us use this model for the same set of simulations.
 
 ```{r}
-results_missing_2 <- compute_results(datasets_missing, backend_missing_2, gen_quants = log_lik_gq, 
+results_missing_2 <- compute_SBC(datasets_missing, backend_missing_2, gen_quants = log_lik_gq, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""missing_2""))
 ```
 
 The contraction plot would not show anything suspicious - we get decent contraction
 
 ```{r results_missing_2_contraction}
-plot_contraction(results_missing_2, prior_sd, parameters = ""mu"")
+plot_contraction(results_missing_2, prior_sd, variables = ""mu"")
 ```
 
 Similarly, our posterior estimates now cluster around the true values.
 
 ```{r results_missing_2_sim_estimated}
-plot_sim_estimated(results_missing_2, parameters = ""mu"", alpha = 0.5)
+plot_sim_estimated(results_missing_2, variables = ""mu"", alpha = 0.5)
 ```
 
 

---FILE: vignettes/rejection_sampling.Rmd---
@@ -1,20 +1,20 @@
 ---
-title: Rejection sampling in dataset generation
+title: Rejection sampling in simulations
 author: ""Martin Modrák""
 date: ""`r Sys.Date()`""
 output: 
   rmarkdown::html_vignette:
     toc: yes
 vignette: >
-  %\VignetteIndexEntry{Rejection sampling in dataset generation}
+  %\VignetteIndexEntry{Rejection sampling in simulations}
   %\VignetteEngine{knitr::rmarkdown}
   \usepackage[utf8]{inputenc}
 ---
 
-In some cases, one may want to exclude extreme datasets from SBC (e.g. because
-those datasets create divergences). It is best to use
+In some cases, one may want to exclude extreme simulations from SBC (e.g. because
+those simulations create divergences). It is best to use
 prior predictive checks to examine your priors and change them
-to avoid the extreme datasets. In some cases, this may however be impractical/impossible to 
+to avoid extremes in the simulated data. In some cases, this may however be impractical/impossible to 
 do via prior choice - one example are regression coefficients, where
 once we have many predictors, any independent prior that is not very strict
 will lead to unrealistic predictions. Joint priors are needed in such case, but
@@ -23,25 +23,25 @@ those are not well understood and easy to use. See
 for more context.
 
 An alternative is to use _rejection sampling_ i.e. we repeatedly generate a 
-dataset and only accept it as a dataset when it passes a certain condition we impose
+simulation and only accept it when it passes a certain condition we impose
 (e.g. that no observed count is larger than $10^8$).
-But does rejection sampling when generating datasets affect the validity of SBC?
+But does rejection sampling when generating simulations affect the validity of SBC?
 
 Thanks to forum user Niko Huurre who derived the necessary math
 at [Stan Discourse discussion of the topic](https://discourse.mc-stan.org/t/using-narrower-priors-for-sbc/21709/6?u=martinmodrak)
 we know exactly when it is OK. Briefly: for algorithms
 that only need to know the posterior density up to a constant (which includes Stan
 and many others),
 it is OK as long as the rejection criterion only
-uses observed data and not the unobserved parameters.
+uses observed data and not the unobserved variables.
 
 We'll first walk through the math and then show examples of both OK and problematic
 rejection sampling.
 
 
 ## The math
 
-Let $f\left(y\right)$ be the probability that the simulated dataset $y$ is rejected (usually a 0-1 function if you have a clear idea what a ""bad"" dataset looks like, but could be probabilistic if you're relying on finicky diagnostics). The important numbers are the probability of rejection for parameter $\theta$
+Let $f\left(y\right)$ be the probability that the simulated data $y$ is rejected (usually a 0-1 function if you have a clear idea what a ""bad"" dataset looks like, but could be probabilistic if you're relying on finicky diagnostics). The important numbers are the probability of rejection for variable $\theta$
 
 $$
 L\left(\theta\right)=\int f\left(y\right)\pi\left(y|\theta\right)\mathrm{d}y
@@ -53,7 +53,7 @@ $$
 R=\iint f\left(y\right)\pi\left(y|\theta\right)\pi\left(\theta\right)\mathrm{d}y\mathrm{d}\theta=\int L\left(\theta\right)\pi\left(\theta\right)\mathrm{d}\theta
 $$
 
-Rejecting the parameter draw when it generates a “bad” dataset effectively distorts the prior
+Rejecting the variable draw when it generates “bad” data effectively distorts the prior
 
 $$
 \pi\left(\theta\right)\to\frac{L\left(\theta\right)}{R}\pi\left(\theta\right)
@@ -77,7 +77,7 @@ $$
 \pi(\theta | y) \propto \frac{L(\theta)}{R} \pi(y | \theta) \frac{f(y)}{L(\theta)} \pi(\theta) = \frac{f(y)}{R} \pi(y | \theta) \pi(\theta)
 $$
 
-And since $\frac{f(y)}{R}$ is a constant for any given dataset (and hence the fit), 
+And since $\frac{f(y)}{R}$ is a constant for any given simulation (and hence the fit), 
 the overall posterior for Stan (and most other MCMC algorithms) is the same, 
 because Stan only needs the posterior density up to a constant. 
 So whether we take rejection into account or not, the model will match the generating process. 
@@ -110,9 +110,9 @@ options(SBC.min_chunk_size = 10)
 
 # Setup caching of results
 if(use_cmdstanr) {
-  cache_dir <- ""./rejection_sampling_SBC_cache""
+  cache_dir <- ""./_rejection_sampling_SBC_cache""
 } else {
-  cache_dir <- ""./rejection_sampling_rstan_SBC_cache""
+  cache_dir <- ""./_rejection_sampling_rstan_SBC_cache""
 }
 if(!dir.exists(cache_dir)) {
   dir.create(cache_dir)
@@ -145,7 +145,7 @@ N <- 10
 generator <- SBC_generator_function(function() {
    mu <- rnorm(1, 0, 2)
    list(
-     parameters = list(mu = mu),
+     variables = list(mu = mu),
      generated = list(N = N, y = rnorm(N, mu, 1))
    )
 })
@@ -159,7 +159,7 @@ datasets <- generate_datasets(generator, 1000)
 ```
 
 ```{r}
-results <- compute_results(datasets, backend, keep_fits = FALSE, 
+results <- compute_SBC(datasets, backend, keep_fits = FALSE, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""no_rejections""))
 ```
@@ -171,20 +171,20 @@ plot_rank_hist(results)
 
 Indeed, all looks good.
 
-### Rejection based on parameter values
+### Rejection based on unobserved variables
 
-Now let us modify the generator to reject based on parameter values. 
+Now let us modify the generator to reject based on values of an unobserved variable. 
 
 ```{r}
-generator_reject_param <- SBC_generator_function(function() {
+generator_reject_unobserved <- SBC_generator_function(function() {
    repeat {
     mu <- rnorm(1, 0, 2)
     if(mu > 3) {
       break
     }
    }
    list(
-     parameters = list(mu = mu),
+     variables = list(mu = mu),
      generated = list(N = N, y = rnorm(N, mu, 1))
    )
 })
@@ -194,18 +194,18 @@ We don't even need to run very many fits to see the problem.
 
 ```{r}
 set.seed(21455)
-datasets_reject_param <- generate_datasets(generator_reject_param, 200)
+datasets_reject_unobserved <- generate_datasets(generator_reject_unobserved, 200)
 ```
 
 ```{r}
-results_reject_param <- compute_results(datasets_reject_param, backend, keep_fits = FALSE, 
+results_reject_unobserved <- compute_SBC(datasets_reject_unobserved, backend, keep_fits = FALSE, 
                     cache_mode = ""results"", 
-                    cache_location = file.path(cache_dir, ""reject_param""))
+                    cache_location = file.path(cache_dir, ""reject_unobserved""))
 ```
 
-```{r reject_param_plots}
-plot_ecdf_diff(results_reject_param)
-plot_rank_hist(results_reject_param)
+```{r reject_unobserved_plots}
+plot_ecdf_diff(results_reject_unobserved)
+plot_rank_hist(results_reject_unobserved)
 ```
 
 Indeed, we see a clear failure.
@@ -214,7 +214,7 @@ Indeed, we see a clear failure.
 
 But what if we reject based on the values of data? This should in theory result in just
 a constant change in posterior density and not affect SBC. (SBC will however then check only the 
-non-rejected parts of the data space). We will do a relatively aggressive rejection scheme (reject more than 50% of datasets).
+non-rejected parts of the data space). We will do a relatively aggressive rejection scheme (reject more than 50% of simulations).
 
 ```{r}
 generator_reject_y <- SBC_generator_function(function() {
@@ -226,7 +226,7 @@ generator_reject_y <- SBC_generator_function(function() {
     }
    }
    list(
-     parameters = list(mu = mu),
+     variables = list(mu = mu),
      generated = list(N = N, y = y)
    )
 })
@@ -238,7 +238,7 @@ datasets_reject_y <- generate_datasets(generator_reject_y, 1000)
 ```
 
 ```{r}
-results_reject_y <- compute_results(datasets_reject_y, backend, keep_fits = FALSE, 
+results_reject_y <- compute_SBC(datasets_reject_y, backend, keep_fits = FALSE, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""reject_y""))
 ```
@@ -252,9 +252,9 @@ We see that even with quite heavy rejection based on y, SBC to a high resolution
 
 ## Take home message
 
-If our priors can sometimes generate datasets that are unrealistic, but we are unable to 
+If our priors can sometimes result in simulated data that is unrealistic, but we are unable to 
 specify a better prior directly (e.g. because we would need to define some sort of joint prior),
-we can use rejection sampling to prune unrealistic datasets as long as we only filter by the observed
-data and don't directly use any unobserved parameter values. Notably, filtering based on divergences or other
+we can use rejection sampling to prune unrealistic simulations as long as we only filter by the observed
+data and don't directly use any unobserved variable values. Notably, filtering based on divergences or other
 fitting issues is also just a function of data and thus permissible. The resulting SBC will however provide guarantees
-only for datasets that would not be rejected by the same criteria.
+only for data that would not be rejected by the same criteria.

---FILE: vignettes/small_model_workflow.Rmd---
@@ -90,9 +90,9 @@ options(SBC.min_chunk_size = 5)
 
 # Setup caching of results
 if(use_cmdstanr) {
-  cache_dir <- ""./small_model_worklow_SBC_cache""
+  cache_dir <- ""./_small_model_worklow_SBC_cache""
 } else {
-  cache_dir <- ""./small_model_worklow_rstan_SBC_cache""
+  cache_dir <- ""./_small_model_worklow_rstan_SBC_cache""
 }
 if(!dir.exists(cache_dir)) {
   dir.create(cache_dir)
@@ -142,7 +142,7 @@ generator_func_first <- function(N) {
   }
   
   list(
-    parameters = list(
+    variables = list(
       mu1 = mu1,
       mu2 = mu2,
       theta = theta
@@ -157,15 +157,15 @@ generator_func_first <- function(N) {
 generator_first <- SBC_generator_function(generator_func_first, N = 50)
 ```
 
-Let's start with just a single dataset:
+Let's start with just a single simulation:
 
 ```{r}
 set.seed(68455554)
 datasets_first <- generate_datasets(generator_first, 1)
 ```
 
 ```{r}
-results_first <- compute_results(datasets_first, backend_first, 
+results_first <- compute_SBC(datasets_first, backend_first, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""mixture_first""))
 ```
@@ -205,10 +205,10 @@ if(use_cmdstanr) {
 }
 ```
 
-So let's try once again with the same single dataset:
+So let's try once again with the same single simulation:
 
 ```{r}
-results_fixed_log_mix <- compute_results(datasets_first, backend_fixed_log_mix, 
+results_fixed_log_mix <- compute_SBC(datasets_first, backend_fixed_log_mix, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""mixture_fixed_log_mix""))
 ```
@@ -219,15 +219,15 @@ No warnings this time. We look at the stats:
 results_fixed_log_mix$stats
 ```
 
-We see nothing obviously wrong, the posterior means are relatively close to simulated values (as summarised by the z-scores) - no parameter is clearly ridiculously misfit. So let's run a few more iterations.
+We see nothing obviously wrong, the posterior means are relatively close to simulated values (as summarised by the z-scores) - no variable is clearly ridiculously misfit. So let's run a few more iterations.
 
 ```{r}
 set.seed(8314566)
 datasets_first_10 <- generate_datasets(generator_first, 10)
 ```
 
 ```{r}
-results_fixed_log_mix_2 <- compute_results(datasets_first_10, backend_fixed_log_mix, 
+results_fixed_log_mix_2 <- compute_SBC(datasets_first_10, backend_fixed_log_mix, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""mixture_fixed_log_mix_2""))
 ```
@@ -289,7 +289,7 @@ generator_func_ordered <- function(N) {
   }
   
   list(
-    parameters = list(
+    variables = list(
       mu = mu,
       theta = theta
     ),
@@ -303,7 +303,7 @@ generator_func_ordered <- function(N) {
 generator_ordered <- SBC_generator_function(generator_func_ordered, N = 50)
 ```
 
-We are kind of confident (and the model fits quickly), so we'll already start with 10 datasets.
+We are kind of confident (and the model fits quickly), so we'll already start with 10 simulations.
 
 ```{r}
 set.seed(3785432)
@@ -312,12 +312,12 @@ datasets_ordered_10 <- generate_datasets(generator_ordered, 10)
 
 
 ```{r}
-results_fixed_ordered <- compute_results(datasets_ordered_10, backend_fixed_ordered, 
+results_fixed_ordered <- compute_SBC(datasets_ordered_10, backend_fixed_ordered, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""mixture_fixed_ordered""))
 ```
 
-Now some fits still produce problematic Rhats or divergent transitions, let's browse the `$backend_diagnostics` (which contain Stan-specific diagnostic values) to see which datasets are causing problems:
+Now some fits still produce problematic Rhats or divergent transitions, let's browse the `$backend_diagnostics` (which contain Stan-specific diagnostic values) to see which simulations are causing problems:
 
 ```{r}
 results_fixed_ordered$backend_diagnostics
@@ -342,13 +342,13 @@ Why does that happen? The key to the answer is in the simulated values for the c
 subset_draws(datasets_ordered_10$variables, draw = problematic_fit_id)
 ```
 
-We were unlucky enough to simulate a dataset where both components have almost the same mean and thus we are actually looking at a dataset that is not really a mixture. Mixture models can misbehave badly in such cases (see once again the [case study by Mike Betancourt](https://betanalpha.github.io/assets/case_studies/identifying_mixture_models.html#5_singular_components_and_computational_issues) for a bit more detailed dive into this particular problem).
+We were unlucky enough to simulate data where both components have almost the same mean and thus we are actually looking at data that is not really a mixture. Mixture models can misbehave badly in such cases (see once again the [case study by Mike Betancourt](https://betanalpha.github.io/assets/case_studies/identifying_mixture_models.html#5_singular_components_and_computational_issues) for a bit more detailed dive into this particular problem).
 
 ### Fixing degenerate components?
 
 What to do about this? Fixing the model to handle such cases gracefully is hard. But the problem is basically our prior - we want to express that (since we are fitting a two component model), we don't expect the means to be too similar. So if we can change our simulation to avoid this, we'll be able to proceed with SBC. If such a pattern appeared in real data, we would still have a problem, but we would notice thanks to the diagnostics.
 
-This can definitely be done. But another way is to just ignore the datasets that had divergences for SBC calculations. It turns out that if we remove datasets in a way that only depends on the observed data (and not on unobserved parameters), the SBC identity is preserved and we can use SBC without modifications. The resulting check is however telling us something only for datasets that were not rejected. In this case this is not a big issue: if a fit had divergent transitions, we would not trust it anyway, so removing fits with divergent transitions is not such a big deal.
+This can definitely be done. But another way is to just ignore the simulations that had divergences for SBC calculations. It turns out that if we remove simulations in a way that only depends on the observed data (and not on unobserved variables), the SBC identity is preserved and we can use SBC without modifications. The resulting check is however telling us something only for data that were not rejected. In this case this is not a big issue: if a fit had divergent transitions, we would not trust it anyway, so removing fits with divergent transitions is not such a big deal.
 
 For more details see the [`rejection_sampling`](https://hyunjimoon.github.io/SBC/articles/rejection_sampling.html) vignette.
 
@@ -411,7 +411,7 @@ You generally don't want to do this unless you are really short on memory, as it
 ```{r}
 set.seed(54987622)
 datasets_ordered_100 <- generate_datasets(generator_ordered, 100)
-results_fixed_ordered_100 <- compute_results(datasets_ordered_100, backend_fixed_ordered, 
+results_fixed_ordered_100 <- compute_SBC(datasets_ordered_100, backend_fixed_ordered, 
                     keep_fits = FALSE, cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""mixture_fixed_ordered_100""))
 ```
@@ -503,7 +503,7 @@ generator_func_beta_first <- function(N_obs, N_predictors) {
   }
     
   list(
-    parameters = list(
+    variables = list(
       beta = beta
     ),
     generated = list(
@@ -518,11 +518,11 @@ generator_func_beta_first <- function(N_obs, N_predictors) {
 generator_beta_first <- SBC_generator_function(generator_func_beta_first, N_obs = 50, N_predictors = 3)
 ```
 
-One thing to note is that we add a rejection sampling step - we repeatedly generate datasets,
+One thing to note is that we add a rejection sampling step - we repeatedly generate simulations,
 until we find one without `y` values very close to 1. Those can be problematic as they
-can be rounded to 1 when the data for Stan is written to disk. And exact 1 is impossible with the Beta likelihood and the model will fail. Rejecting the dataset due to this criterion is quite rare and in fact, it does not threaten the validity of the SBC procedure (at least to the extent our real data also don't contain such extreme values) - for more details see the [`rejection_sampling`](https://hyunjimoon.github.io/SBC/articles/rejection_sampling.html) vignette.
+can be rounded to 1 when the data for Stan is written to disk. And exact 1 is impossible with the Beta likelihood and the model will fail. Rejecting the simulation due to this criterion is quite rare and in fact, it does not threaten the validity of the SBC procedure (at least to the extent our real data also don't contain such extreme values) - for more details see the [`rejection_sampling`](https://hyunjimoon.github.io/SBC/articles/rejection_sampling.html) vignette.
 
-We'll start with 10 datasets once again.
+We'll start with 10 simulations once again.
 
 ```{r}
 set.seed(3325488)
@@ -532,7 +532,7 @@ datasets_beta_first <- generate_datasets(generator_beta_first, 10)
 
 
 ```{r}
-results_beta_first_10 <- compute_results(datasets_beta_first, backend_beta_first, 
+results_beta_first_10 <- compute_SBC(datasets_beta_first, backend_beta_first, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""beta_first_10""))
 ```
@@ -580,7 +580,7 @@ predictor values for the first shape parameter are allowed to vary quite a bit a
 
 ### Parametrizing the beta distribution via mean
 
-The simplest way to resolve the issue with the correlations is to explicitly parametrize the beta distribution by its mean ($0 < \mu < 1$). The more common parametrization than adds a precision parameter ($\phi > 0$), so we then have $y \sim \mathrm{Beta}(\mu \phi, (1 - \mu) \phi)$
+The simplest way to resolve the issue with the correlations is to explicitly parametrize the beta distribution by its mean ($0 < \mu < 1$). The more common parametrization then adds a precision parameter ($\phi > 0$), so we then have $y \sim \mathrm{Beta}(\mu \phi, (1 - \mu) \phi)$
 
 This also makes much more sense for the bigger task - combining with the mixture submodel, as we really want to predict just a single probability. So we'll rewrite our predictors to predict only the logit of the mean (as in logistic regression) and keep the precision as a constant between observations. We could definitely also decide whether to keep the full flexibility and allow predictors for precision, we just don't do it here.
 
@@ -628,7 +628,7 @@ generator_func_beta_precision <- function(N_obs, N_predictors) {
   }
     
   list(
-    parameters = list(
+    variables = list(
       beta = beta,
       phi = phi
     ),
@@ -646,7 +646,7 @@ generator_beta_precision <-
 ```
 
 
-Starting with 10 datasets:
+Starting with 10 simulations:
 
 ```{r}
 set.seed(46988234)
@@ -656,7 +656,7 @@ datasets_beta_precision_10 <- generate_datasets(generator_beta_precision, 10)
 
 
 ```{r}
-results_beta_precision_10 <- compute_results(datasets_beta_precision_10, backend_beta_precision, 
+results_beta_precision_10 <- compute_SBC(datasets_beta_precision_10, backend_beta_precision, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""beta_precision_10""))
 ```
@@ -673,7 +673,7 @@ So we'll run 90 more iterations and combine them with the previous results:
 ```{r}
 set.seed(2136468)
 datasets_beta_precision_90 <- generate_datasets(generator_beta_precision, 90)
-results_beta_precision_90 <- compute_results(
+results_beta_precision_90 <- compute_SBC(
   datasets_beta_precision_90, backend_beta_precision,
   keep_fits = FALSE, cache_mode = ""results"", 
   cache_location = file.path(cache_dir, ""beta_precision_90""))
@@ -694,7 +694,7 @@ plot_rank_hist(results_beta_precision_100)
 plot_ecdf_diff(results_beta_precision_100)
 ```
 
-The plots don't look terrible, but the `beta[2]` and especially the `phi` parameter show slight problems.
+The plots don't look terrible, but the `beta[2]` and especially the `phi` variable show slight problems.
 
 So we look back at our model code and note that we forgot to put any prior on `phi`!
 Mismatches in priors between the model and the simulator are unfortunately often not very well visible for SBC and can require a lot of simulations to discover (see the [`limits_of_SBC`](https://hyunjimoon.github.io/SBC/articles/limits_of_SBC.html) vignette for more detailed discussion)
@@ -719,11 +719,11 @@ if(use_cmdstanr) {
 }
 ```
 
-And recompute for all 100 datasets at once (as we don't expect adding prior to introduce huge problems).
+And recompute for all 100 simulations at once (as we don't expect adding prior to introduce huge problems).
 
 ```{r}
 results_beta_precision_fixed_prior <- 
-  compute_results(datasets_beta_precision_100, backend_beta_precision_fixed_prior, 
+  compute_SBC(datasets_beta_precision_100, backend_beta_precision_fixed_prior, 
                     keep_fits = FALSE, cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""beta_precision_fixed_prior""))
 ```
@@ -733,7 +733,7 @@ plot_rank_hist(results_beta_precision_fixed_prior)
 plot_ecdf_diff(results_beta_precision_fixed_prior)
 ```
 
-Diagnostic plots are looking good! So we add 100 more datasets:
+Diagnostic plots are looking good! So we add 100 more simulations:
 
 
 ```{r}
@@ -742,7 +742,7 @@ datasets_beta_precision_100b <- generate_datasets(generator_beta_precision, 100)
 results_beta_precision_fixed_prior_200 <-
   bind_results(
     results_beta_precision_fixed_prior,
-    compute_results(datasets_beta_precision_100b, backend_beta_precision_fixed_prior, 
+    compute_SBC(datasets_beta_precision_100b, backend_beta_precision_fixed_prior, 
                     keep_fits = FALSE, cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""beta_precision_fixed_prior_2"")))
 ```
@@ -812,7 +812,7 @@ generator_func_combined <- function(N_obs, N_predictors) {
 
 
   list(
-    parameters = list(
+    variables = list(
       beta = beta,
       mu = mu
     ),
@@ -836,7 +836,7 @@ dataset_combined <- generate_datasets(generator_combined, 200)
 ```
 
 ```{r}
-results_combined <- compute_results(dataset_combined, backend_combined, 
+results_combined <- compute_SBC(dataset_combined, backend_combined, 
                     keep_fits = FALSE, cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""combined""))
 ```
@@ -855,9 +855,9 @@ As done previously, we could just exclude the fits that had divergences, but jus
 
 The general idea is that although we might not want to/be able to express our prior belief about the model (here that the two mixture components are distinct) by priors on model parameters, we still may be able to express our prior belief about the data itself.
 
-And it turns out that if we remove datasets that don't meet a certain condition imposed on the observed data, the implied prior on parameters becomes an additive constant and we can use exactly the same model to fit only the non-rejected datasets. Note that this does not hold if we rejected datasets based on their parameter values - for more details see the [`rejection_sampling`](https://hyunjimoon.github.io/SBC/articles/rejection_sampling.html) vignette.
+And it turns out that if we remove simulations that don't meet a certain condition imposed on the observed data, the implied prior on parameters becomes an additive constant and we can use exactly the same model to fit only the non-rejected simulations. Note that this does not hold if we rejected simulations based on some unobserved variables - for more details see the [`rejection_sampling`](https://hyunjimoon.github.io/SBC/articles/rejection_sampling.html) vignette.
 
-The main advantage is that if we can do this, we can avoid wasting computation on fitting datasets that would likely produce divergences anyway. The downside is that it means we no longer have a guarantee the model works for non-rejected datasets, so we need to check if the data we want to analyze would not be rejected by our criterion.
+The main advantage is that if we can do this, we can avoid wasting computation on fitting data that would likely produce divergences anyway. The downside is that it means we no longer have a guarantee the model works for non-rejected data, so we need to check if the data we want to analyze would not be rejected by our criterion.
 
 How to build such a criterion here? We'll note that for Poisson-distributed variables the ratio of mean to variance (a.k.a the Fano factor) is always 1. So if the components are too similar, the data should resemble a Poisson distribution and have Fano factor of 1, while if the components are distinct the Fano factor will be larger. 
 
@@ -876,7 +876,7 @@ All the divergence are for low fano factors - this is the histogram of Fano fact
 hist(fanos[results_combined$backend_diagnostics$n_divergent > 0])
 ```
 
-So what we'll do is that we'll reject any dataset with Fano factor < 1.5. In practice a simple way to implement this is to wrap our generator code in a loop and break from the loop only when the generated dataset meets our criteria (i.e. is not rejected). This is our code:
+So what we'll do is that we'll reject any simulation where the observed data have Fano factor < 1.5. In practice a simple way to implement this is to wrap our generator code in a loop and break from the loop only when the generated data meet our criteria (i.e. is not rejected). This is our code:
 
 ```{r}
 generator_func_combined_reject <- function(N_obs, N_predictors) {
@@ -916,7 +916,7 @@ generator_func_combined_reject <- function(N_obs, N_predictors) {
   }
     
   list(
-    parameters = list(
+    variables = list(
       beta = beta,
       mu = mu
     ),
@@ -933,7 +933,7 @@ generator_combined_reject <-
   SBC_generator_function(generator_func_combined_reject, N_obs = 50, N_predictors = 3)
 ```
 
-We'll once again fit our model to 200 datasets:
+We'll once again fit our model to 200 simulations:
 
 ```{r}
 set.seed(44685226)
@@ -943,7 +943,7 @@ dataset_combined_reject <- generate_datasets(generator_combined_reject, 200)
 
 
 ```{r}
-results_combined_reject <- compute_results(dataset_combined_reject, backend_combined, 
+results_combined_reject <- compute_SBC(dataset_combined_reject, backend_combined, 
                     keep_fits = FALSE, cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""combined_reject""))
 ```
@@ -961,7 +961,7 @@ And our coverage is pretty tight:
 plot_coverage(results_combined_reject)
 ```
 
-Below we show the uncertainty for two parameters and some widths of central posterior intervals numerically:
+Below we show the uncertainty for two variables and some widths of central posterior intervals numerically:
 
 ```{r results_combined_reject_coverage}
 stats_subset <- results_combined_reject$stats[
@@ -977,7 +977,7 @@ set.seed(1395367854)
 dataset_combined_reject_more <- generate_datasets(generator_combined_reject, 300) 
 results_combined_reject_more <- bind_results(
   results_combined_reject,
-  compute_results(dataset_combined_reject_more, backend_combined, 
+  compute_SBC(dataset_combined_reject_more, backend_combined, 
                     keep_fits = FALSE, cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""combined_reject_more""))
 )",True,True,Rendering / Conversion,6
hyunjimoon,SBC,c16b5c124a69e97a4e65289f54a83a9fdb641b9b,Hyunji Moon,30194633+hyunjimoon@users.noreply.github.com,2021-12-31T12:21:45Z,GitHub,noreply@github.com,2021-12-31T12:21:45Z,typo fix,vignettes/computational_algorithm1.Rmd,True,False,True,False,43,42,85,"---FILE: vignettes/computational_algorithm1.Rmd---
@@ -10,22 +10,22 @@ vignette: >
   %\VignetteEngine{knitr::rmarkdown}
   \usepackage[utf8]{inputenc}
 ---
-the fact that KL divergence under-penalizes approximation with
-too-light tails,
+
+
 
 # Summary 
-Computational algorithm such as variational inference (VI) can fail due to the
+Computational algorithms such as variational inference (VI) can fail due to the
 inability of the approximation family to capture the true posterior, under/over
 penalizing tendencies of convergence metric, and slow convergence of the
 optimization process. We show two examples where VI is discouraged due to speed
 (Zero-inflated Poisson) and accuracy (HMM) reasons. The trade-off is illustrated
-by adjusting convergence-related parameter such as tolerance: longer run
-achieves improved accurcy which sometimes becomes even slower than HMC. However,
+by adjusting convergence-related parameters such as tolerance: longer run
+achieves improved accuracy which sometimes becomes even slower than HMC. However,
 when the fit between posterior and approximation family, convergence metric and
 its process are checked so that efficiency is gained without sacrificing
 accuracy too much, VI can be applied. On top of its role as ""the test""
-computational algorithm should pass, SBC provide informative inferential results
-which directly affects workflow decisions.
+computational algorithms should pass, SBC provides informative inferential results
+which directly affect workflow decisions.
 
 
 # Introduction
@@ -35,13 +35,13 @@ prior, and likelihood) and the user's goal, deterministic approximation
 algorithms can be an aid. To be specific, if the joint posterior is well-formed
 enough for reliable approximation (symmetric for ADVI which has normal
 approximation family) or the user only needs point estimate (i.e. specification
-upto distribution-level is not needed) users can consider the deterministic
+up to distribution-level is not needed) users can consider the deterministic
 alternatives for their inference tool such as ADVI supported by Stan. Note that
 Pathfinder (Zhang, 2021) which blends deterministic algorithm's efficiency and
-stochastic algorithm's accuracy in a timely manner is under-development. SBC
+stochastic algorithm's accuracy in a timely manner is under development. SBC
 provides one standard to test whether ADVI works well for your model without
 ever needing to run full HMC for your model. To show a few examples, let's start
-by setting up our environment.
+by setting up our environment. For brevity, computational algorithm is shortened as computation.
 
 ```{r setup, message=FALSE,warning=FALSE, results=""hide""}
 library(SBC); 
@@ -62,7 +62,7 @@ library(future)
 plan(multisession)
 
 # The fits are very fast,
-# so we force a minimum chunk size to reduce overhead of
+# so we force a minimum chunk size to reduce the overhead of
 # paralellization and decrease computation time.
 options(SBC.min_chunk_size = 5)
 
@@ -78,20 +78,20 @@ if(!dir.exists(cache_dir)) {
 
 # Example I - Poisson mixture
 
-In this example, we have collected a set of counts of particles emmitted by 
+In this example, we have collected a set of counts of particles emitted by 
 a specimen in a relatively large number of experimental runs. We however noticed 
 that there is a suspiciously large number of low counts. Inspecting the 
-equipment, it turns out that the experiment was not setup properly and
+equipment, it turns out that the experiment was not set up properly and
 in some of the runs, our detector could only register background noise.
-We however don't know which runs were errorneous. 
+We however don't know which runs were erroneous. 
 
 This naturally calls for a mixture model, where we assume that a proportion 
 (`p_signal`) of experiments
 contains both background noise and the signal of interest and the rest
-contains just the background. For simplicity we assume a Poisson distribution
+contains just the background. For simplicity, we assume a Poisson distribution
 for the counts. 
 We also assume that in our hypothetical example, the expected background noise
-is well understood, which let's us to put a narrow prior on the amount of 
+is well understood, which lets us to put a narrow prior on the amount of 
 particles we would expect to detect just from the background.
 
 So here's our model:
@@ -129,7 +129,7 @@ generator_contamination <- function(N) {
 
 ## Default ADVI (small problems)
 
-We'll start with the Stan's ADVI with all default parameters, i.e. a meanfield
+We'll start with Stan's ADVI with all default parameters, i.e. a mean-field
 variational approximation. 
 We compile the model and create a variational SBC backend.
 
@@ -146,7 +146,7 @@ Since we are feeling confident that our model is implemented correctly (and the
 If you are developing a new model, it might be useful to start with fewer simulations, as discussed in the 
 [small model workflow vignette](https://hyunjimoon.github.io/SBC/articles/small_model_workflow.html).
 
-Throughout the vignette we'll also use caching for the results.
+Throughout the vignette, we'll also use caching for the results.
 
 ```{r}
 set.seed(46522641)
@@ -162,7 +162,7 @@ plot_ecdf_diff(res_contamination)
 plot_rank_hist(res_contamination)
 ```
 
-We'll also look at how well are we able to estimate the various paremeters by
+We'll also look at how well are we able to estimate the various parameters by
 plotting the estimated values + uncertainty intervals against the ""true"" simulated
 values. We have a lot of data and both the `mu_signal` and `p_signal` are well
 constrained by the data. Unsurprisingly we learn a bit less about `mu_background`,
@@ -192,7 +192,7 @@ For example for the 90% central, the 90% interval for `mu_signal` could actually
 contain between `r scales::percent(coverage_contamination$ci_low[2])` and 
 `scales::percent(coverage_contamination$ci_high[2])` of true values.
 
-So we ran 900 more simulation and combine them with the previous results.
+So we ran 900 more simulations and combine them with the previous results.
 
 
 ```{r}
@@ -218,16 +218,16 @@ plot_ecdf_diff(res_contamination_2)
 plot_rank_hist(res_contamination_2)
 ```
 
-The increased resolution of total of 1000 simulations shows that the variational
-approximation to the posterior is underdispersed for `mu_signal` (the true parameter is too often
+The increased resolution of a total of 1000 simulations shows that the variational
+approximation to the posterior is under dispersed for `mu_signal` (the true parameter is too often
 in the extreme tails of the posterior) and - to a lesser extent - also for `p_signal`,
 where we see an overabundance of true values larger than all of the posterior samples,
 but not too many low ranks.
 
-Note that when user is aiming for point estimate of either mean or certain
-quantile, VI posterior can be used to produce a good point estimate even when it
+Note that when the user is aiming for a point estimate of either mean or certain
+quantile, a summary of VI posterior provides a good point estimate even when it
 is far from the true posterior. VSBC, an extended diagnostic that concentrates
-on bias in mariginal quantity, is developed (Yao et. al., 2018). Other
+on bias in marginal quantity, is developed (Yao et. al., 2018). Other
 diagnostic such as PSIS-based which is associated with specific data and test
 quantity, is less flexible for target-testing.
 
@@ -249,17 +249,17 @@ coverage_contamination_2
 The 90% central credible interval for `mu_background` likely
 contains less than `r scales::percent(coverage_contamination$ci_high[2])` of true values.
 
-So for a crude result the default ADVI setup we just tested is not terrible: we don't
+So for a crude result, the default ADVI setup we just tested is not terrible: we don't
 expect to see a strong bias and the model will be somewhat overconfident, but
 not catastrophically so.
 
-## Fullrank approximation (smaller problems)
+## Full-rank approximation (smaller problems)
 
-We may also try the more flexible fullrank variational approximation.
+We may also try the more flexible full-rank variational approximation.
 
-So in the next we build a fullrank variational backend and compute SBC
+So we next build a full-rank variational backend and compute SBC
 for the same 1000 datasets we used earlier. This is primarily for brevity -
-in actual practice you would probably want to start with fewer datasets to
+in actual practice, you would probably want to start with fewer datasets to
 discover big problems quickly.
 
 ```{r}
@@ -270,9 +270,9 @@ res_contamination_fullrank <- compute_results(
   cache_mode = ""results"",
   cache_location = file.path(cache_dir, ""contamination_fullrank""))
 ```
-The ECDF and rank plots actually look a bit better than with the meanfield approximation.
+The ECDF and rank plots actually look a bit better than with the mean-field approximation.
 Interestingly, the rank plots show a bit of a ""frowning"" shape, meaning the
-meanfield approximation is slightly underconfident for `p_signal` and a bit also
+mean-field approximation is slightly underconfident for `p_signal` and a bit also
 for `mu_background`. For `mu_signal`, the model is both slightly underconfident 
 in the bulk of the posterior, but still has overly light tails and is overconfident
 for the extreme quantiles.
@@ -293,8 +293,8 @@ plot_coverage(res_contamination_fullrank)
 ## Meanfield + lower tolerance (even better)
 
 In some cases, it might also help to reduce the tolerance (`tol_rel_obj`) of the
-algorithm. This is a restriction on evidence lower bound (ELBO) and make
-optimization convergence tighter. Here we'll use the default meanfield
+algorithm. This is a restriction on evidence lower bound (ELBO) for tighter
+optimization convergence. Here we'll use the default mean-field
 algorithm, but decrease the `tol_rel_obj` (the default value is 0.01).
 
 ```{r}
@@ -386,7 +386,7 @@ observing background only vs. signal in individual data points is not independen
 and we want to model how the experimental setup switches between these two states over
 time. We add additional structure to the model to account for this autocorrelation.
 
-One possible choice for such structure are hidden Markov models (HMMs) where
+One possible choice for such structure is hidden Markov models (HMMs) where
 we assume the probability of transitioning from one state to another is identical
 across all time points. The [case study for HMMs](https://mc-stan.org/users/documentation/case-studies/hmm-example.html)
 has a more thorough discussion and also shows how to code those in Stan.
@@ -470,7 +470,7 @@ plot_coverage(res_hmm)
 ```
 
 
-We may also try fullrank - let's run it for the same 20 datasets.
+We may also try full-rank - let's run it for the same 20 datasets.
 
 ```{r}
 res_hmm_fullrank <- compute_results(
@@ -492,7 +492,7 @@ plot_ecdf_diff(res_hmm_fullrank)
 plot_rank_hist(res_hmm_fullrank)
 ```
 
-And we may also try meanfield but with lower tolerance
+And we may also try mean-field but with lower tolerance
 
 ```{r}
 res_hmm_lowtol <- compute_results(
@@ -554,11 +554,12 @@ are likely useless.
 
 
 # Next step: Evolving computation and diagnostic.
-In another vigenette, we will focus on hopeful aspects of approximate
-computation. Principles behind evolving computation and diagnostic are discussed
-which can give insight to computation designers aiming to pass SBC. For
-illustration, when and how VI can be used is discussed which include customized
-SBC and first or second order fixes.
+In computational_algorithm2, we will focus on hopeful aspects of approximate
+computation. The adversarial relation between computation and diagnostic is
+introduced based on which mutual evolvement happens. This can give insight to
+computational algorithm designers aiming to pass SBC. For illustration, when and
+how VI can be used is discussed which include customized SBC (e.g. VSBC) and first or
+second-order correction.
 
 # References
 - Zhang et. al. (2021) Pathfinder: Parallel quasi-Newton variational inference https://arxiv.org/abs/2108.03782",False,True,Rendering / Conversion,6
hyunjimoon,SBC,766c650de97a13d31fb3177cf96471acd50b95eb,martinmodrak,modrak.mar@gmail.com,2021-12-27T22:01:54Z,martinmodrak,modrak.mar@gmail.com,2021-12-27T22:01:54Z,Fixed bug in combining GQs,R/results.R,False,True,True,False,14,1,15,"---FILE: R/results.R---
@@ -371,7 +371,20 @@ compute_results <- function(datasets, backend,
   if(is.null(gen_quants)) {
     future.globals <- globals
   } else {
-    future.globals <- c(globals, attr(gen_quants, ""globals""))
+    gq_globals <- attr(gen_quants, ""globals"")
+    if(length(globals) > 0 && length(gq_globals > 0)) {
+      if(is.list(gq_globals) && !is.list(globals)) {
+        stop(SBC_error(""Not implemented: Currently, when globals in generated quantites are a list, globals argument has to be also a list  (not a character vector).""))
+      } else if(!is.list(gq_globals) && is.list(globals)) {
+        stop(SBC_error(""Not implemented: Currently, when globals is a list, globals in generated quantites have to be also a list (not a character vector).""))
+      }
+      future.globals <- c(globals, gq_globals)
+    }
+    if(length(gq_globals) > 0) {
+      future.globals <- gq_globals
+    } else {
+      future.globals <- globals
+    }
   }
 
   results_raw <- future.apply::future_lapply(",True,False,Implementation / Logic,6
hyunjimoon,SBC,a820885c70cc1bad4ba0b5370130f491a4d3998a,martinmodrak,modrak.mar@gmail.com,2021-12-17T22:29:57Z,martinmodrak,modrak.mar@gmail.com,2021-12-17T22:29:57Z,"Final example for ADVI vignette, fixes to backend.",R/backends.R;R/plot.R;vignettes/approximate_computation.Rmd;vignettes/stan/contaminated_poisson.stan;vignettes/stan/hmm_contaminated_poisson.stan,True,True,True,False,281,21,302,"---FILE: R/backends.R---
@@ -355,14 +355,16 @@ SBC_fit_to_diagnostics.CmdStanMCMC <- function(fit, fit_output, fit_messages, fi
 #' Backend based on variational approximation via `cmdstanr`.
 #'
 #' @param model an object of class `CmdStanModel` (as created by `cmdstanr::cmdstan_model`)
-#' @param n_retries_dropped number of times to retry the variational fit if the algorithm
-#' has too many dropped evaluations
-#' (see https://discourse.mc-stan.org/t/advi-too-many-dropped-evaluations-even-for-well-behaved-models/24338)
+#' @param n_retries_init number of times to retry the variational fit if the algorithm
+#' has trouble initializing (e.g. too many dropped evaluations
+#' (see https://discourse.mc-stan.org/t/advi-too-many-dropped-evaluations-even-for-well-behaved-models/24338),
+#' or ""cannot compute ELBO using the initial variational distribution"")
 #' @param ... other arguments passed to the `$variational()` method of the model.
 #' The `data` argument cannot be set this way as they need to be controlled by the SBC
 #'   package.
 #' @export
-SBC_backend_cmdstan_variational <- function(model, ..., n_retries_dropped = 1) {
+SBC_backend_cmdstan_variational <- function(model, ...,
+                                            n_retries_init = 1) {
   require_cmdstanr_version(""cmdstan backend"")
 
   stopifnot(inherits(model, ""CmdStanModel""))
@@ -377,7 +379,7 @@ SBC_backend_cmdstan_variational <- function(model, ..., n_retries_dropped = 1) {
                 ""by the SBC package""))
   }
 
-  structure(list(model = model, n_retries_dropped = n_retries_dropped, args = args), class = ""SBC_backend_cmdstan_variational"")
+  structure(list(model = model, n_retries_init = n_retries_init, args = args), class = ""SBC_backend_cmdstan_variational"")
 }
 
 stan_variational_elbo_converged <- function(fit_output) {
@@ -387,30 +389,42 @@ stan_variational_elbo_converged <- function(fit_output) {
 #' @export
 SBC_fit.SBC_backend_cmdstan_variational <- function(backend, generated, cores) {
   fit_outputs <- list()
-  for(i in 1:backend$n_retries_dropped) {
+  for(i in 1:backend$n_retries_init) {
     # Need to do my own output capturing as the calling code
     # also captures output and interferes with CmdStanVB$output()
-    fit_outputs[[i]] <- capture.output({
+    fit_outputs[[i]] <- capture_all_outputs({
       if(i > 1) {
         cat(""==== SBC backend retrying ===== \n"")
       }
       fit <- do.call(backend$model$variational,
                      combine_args(backend$args,
                                   list(
                                     data = generated)))
-    }, type = ""output"")
-
-    # Only retry if the error is ""too many dropped evaluations""
-    if(fit$return_codes() != 0 && any(grepl(""dropped evaluations.*maximum"", fit_outputs[[i]]))) {
+    })
+
+    # Only retry if the error is ""too many dropped evaluations"" or
+    # Cannot compute initial ELBO
+    if(fit$return_codes() != 0 &&
+       (any(grepl(""dropped evaluations.*maximum"", fit_outputs[[i]]$messages))
+        || any(grepl(""Cannot compute ELBO.*initial"", fit_outputs[[i]]$messages))
+        )
+       ) {
       next
     } else {
       break
     }
   }
 
-
-  all_output <- do.call(c, args = fit_outputs)
-  cat(all_output, sep = ""\n"")
+  #Re-emit outputs, warnings, messages
+  for(i in 1:length(fit_outputs)) {
+    cat(fit_outputs[[i]]$output, sep = ""\n"")
+    for(m in 1:length(fit_outputs[[i]]$messages)) {
+      message(fit_outputs[[i]]$messages[m])
+    }
+    for(w in 1:length(fit_outputs[[i]]$warnings)) {
+      warning(fit_outputs[[i]]$warnings[w])
+    }
+  }
 
   if(all(fit$return_codes() != 0)) {
     stop(""Variational inference did not finish succesfully"")
@@ -422,7 +436,7 @@ SBC_fit.SBC_backend_cmdstan_variational <- function(backend, generated, cores) {
 
 #' @export
 SBC_backend_hash_for_cache.SBC_backend_cmdstan_variational <- function(backend) {
-  rlang::hash(list(model = backend$model$code(), n_retries_dropped = backend$n_retries_dropped, args = backend$args))
+  rlang::hash(list(model = backend$model$code(), n_retries_init = backend$n_retries_init, args = backend$args))
 }
 
 

---FILE: R/plot.R---
@@ -411,22 +411,22 @@ plot_contraction.data.frame <- function(x, prior_sd, parameters = NULL, scale =
 #' @export
 plot_sim_estimated <- function(x, parameters = NULL, estimate = ""mean"",
                                uncertainty = c(""q5"", ""q95""),
-                               alpha = 0.8) {
+                               alpha = NULL) {
   UseMethod(""plot_sim_estimated"")
 }
 
 #' @export
 plot_sim_estimated.SBC_results <- function(x, parameters = NULL, estimate = ""mean"",
                                            uncertainty = c(""q5"", ""q95""),
-                                           alpha = 0.8) {
+                                           alpha = NULL) {
   plot_sim_estimated(x$stats, parameters = parameters, estimate = estimate,
                      uncertainty = uncertainty, alpha = alpha)
 }
 
 #' @export
 plot_sim_estimated.data.frame <- function(x, parameters = NULL, estimate = ""mean"",
                                           uncertainty = c(""q5"", ""q95""),
-                                          alpha = 0.8) {
+                                          alpha = NULL) {
   if(!all(c(""parameter"", estimate, uncertainty) %in% names(x))) {
     stop(""The data.frame needs a 'parameter' and '"", estimate, ""' columns"")
   }
@@ -435,6 +435,13 @@ plot_sim_estimated.data.frame <- function(x, parameters = NULL, estimate = ""mean
     x <- dplyr::filter(x, parameter %in% parameters)
   }
 
+  if(is.null(alpha)) {
+    n_points <- dplyr::summarise(dplyr::group_by(x, parameter), count = dplyr::n())
+    max_points <- max(n_points$count)
+    alpha_guess <- 1 / ((max_points * 0.06) + 1)
+    alpha <-  max(0.05, alpha_guess)
+  }
+
   x$estimate__ <- x[[estimate]]
 
   if(!is.null(uncertainty)) {

---FILE: vignettes/approximate_computation.Rmd---
@@ -26,8 +26,8 @@ options(mc.cores = parallel::detectCores())
 
 # Parallel processing
 
-# library(future)
-# plan(multisession)
+library(future)
+plan(multisession)
 
 # The fits are very fast,
 # so we force a minimum chunk size to reduce overhead of
@@ -52,6 +52,175 @@ HMC for your model.
 # 2. Comparing HMC and ADVI 
 Simple model with location and scale parameter for normal distirbution is used and coded into generator and backend (stan file).
 
+
+```{r}
+generator_contamination <- function(N) {
+  mu_background <- rlnorm(1, -2, 0.2)
+  mu_signal <- rlnorm(1, 2, 1)
+
+  p_signal <- rbeta(1, 2, 2)
+
+  mu <- c(mu_background, mu_background + mu_signal)
+  y <- rpois(N, ifelse(runif(N) < p_signal, mu_background + mu_signal, mu_background))
+  
+  list(
+    parameters = list(
+      mu_signal = mu_signal,
+      mu_background = mu_background,
+      p_signal = p_signal
+    ),
+    generated = list(
+      N = N,
+      y = y
+    )
+  )
+}
+
+
+model_contamination <- cmdstan_model(""stan/contaminated_poisson.stan"")
+backend_contamination <- SBC_backend_cmdstan_variational(model_contamination, n_retries_init = 3)
+
+```
+
+```{r}
+set.seed(46522641)
+ds_contamination <- generate_datasets(SBC_generator_function(generator_contamination, N = 100), n_datasets = 100)
+res_contamination <- compute_results(ds_contamination, backend_contamination, cache_mode = ""results"", cache_location = file.path(cache_dir, ""contamination""))
+```
+
+```{r}
+plot_ecdf_diff(res_contamination)
+plot_rank_hist(res_contamination)
+plot_sim_estimated(res_contamination)
+```
+
+```{r}
+set.seed(12365455)
+ds_contamination_2 <- generate_datasets(SBC_generator_function(generator_contamination, N = 100), n_datasets = 900)
+res_contamination_2 <- bind_results(
+  res_contamination,
+  compute_results(ds_contamination_2, backend_contamination, cache_mode = ""results"", cache_location = file.path(cache_dir, ""contamination_2""))
+)
+  
+```
+
+
+```{r}
+plot_ecdf_diff(res_contamination_2)
+plot_rank_hist(res_contamination_2)
+plot_sim_estimated(res_contamination_2, alpha = 0.2)
+```
+
+
+```{r}
+plot_coverage(res_contamination_2)
+```
+
+```{r}
+res_contamination_fullrank <- compute_results(bind_datasets(ds_contamination, ds_contamination_2), SBC_backend_cmdstan_variational(model_contamination, n_retries_init = 3, algorithm = ""fullrank""),
+                                              cache_mode = ""results"",
+                                              cache_location = file.path(cache_dir, ""contamination_fullrank""))
+```
+
+```{r}
+plot_ecdf_diff(res_contamination_fullrank)
+plot_rank_hist(res_contamination_fullrank)
+plot_sim_estimated(res_contamination_fullrank)
+```
+
+```{r}
+plot_coverage(res_contamination_fullrank)
+```
+
+
+```{r}
+res_contamination_mcmc <- compute_results(bind_datasets(ds_contamination, ds_contamination_2), SBC_backend_cmdstan_sample(model_contamination, chains = 2),
+                                          keep_fits = FALSE,
+                                          cache_mode = ""results"",
+                                          cache_location = file.path(cache_dir, ""contamination_mcmc""))
+```
+
+```{r}
+plot_ecdf_diff(res_contamination_mcmc)
+plot_rank_hist(res_contamination_mcmc)
+plot_sim_estimated(res_contamination_mcmc)
+```
+
+
+https://mc-stan.org/users/documentation/case-studies/hmm-example.html
+
+Simplified to two states and slightly tighter prior on transition probs
+
+```{r}
+generator_HMM <- function(N) {
+  # You can simulate i.i.d. ordered vector just by sorting
+  mu_background <- rlnorm(1, -2, 0.2)
+  mu_signal <- rlnorm(1, 2, 1)
+
+  # Draw the transition probabilities
+  t1 <- MCMCpack::rdirichlet(1, c(3, 3))
+  t2 <- MCMCpack::rdirichlet(1, c(3, 3))
+
+  states = rep(NA_integer_, N)
+  # Draw from initial state distribution
+  rho <- MCMCpack::rdirichlet(1, c(1, 10))
+
+  states[1] = sample(1:2, size = 1, prob = rho)
+  for(n in 2:length(states)) {
+    if(states[n - 1] == 1)
+      states[n] = sample(c(1, 2), size = 1, prob = t1)
+    else if(states[n - 1] == 2)
+      states[n] = sample(c(1, 2), size = 1, prob = t2)
+  }  
+  
+  mu <- c(mu_background, mu_background + mu_signal)
+  y <- rpois(N, mu[states])
+  
+  list(
+    parameters = list(
+      mu_signal = mu_signal,
+      mu_background = mu_background,
+      # rdirichlet returns matrices, convert to 1D vectors
+      t1 = as.numeric(t1),
+      t2 = as.numeric(t2),
+      rho = as.numeric(rho)
+    ),
+    generated = list(
+      N = N,
+      y = y
+    )
+  )
+}
+
+
+model_HMM <- cmdstan_model(""stan/hmm_contaminated_poisson.stan"")
+backend_HMM <- SBC_backend_cmdstan_variational(model_HMM, n_retries_init = 3)
+
+```
+
+```{r}
+set.seed(2165498)
+ds_hmm <- generate_datasets(SBC_generator_function(generator_HMM, N = 100), n_datasets = 20)
+res_hmm <- compute_results(ds_hmm, backend_HMM,
+                           cache_mode = ""results"", cache_location = file.path(cache_dir, ""hmm""))
+```
+
+```{r}
+plot_ecdf_diff(res_hmm)
+plot_rank_hist(res_hmm)
+plot_sim_estimated(res_hmm)
+```
+```{r}
+res_mcmc <- compute_results(ds, SBC_backend_cmdstan_sample(model_HMM, chains = 2))
+```
+
+```{r}
+plot_ecdf_diff(res_mcmc)
+plot_rank_hist(res_mcmc)
+plot_sim_estimated(res_mcmc)
+```
+
+
 ```{R generator and backend}
 generator <- function(hyperparam, param, predictor = NULL){
   # hyperparamter
@@ -117,7 +286,7 @@ s_thin_ranks = 10
 v_thin_ranks = 1
 chains = 4
 backend_tn <- SBC_backend_cmdstan_sample(mod_two_norm, chains = chains, iter_sampling = M * s_thin_ranks / chains)
-backend_tn_vb <- SBC_backend_cmdstan_variational(mod_two_norm, grad_samples = 200, init = 0.5, n_retries_dropped = 3)
+backend_tn_vb <- SBC_backend_cmdstan_variational(mod_two_norm, grad_samples = 200, init = 0.5, n_retries_init = 3)
 prior_width = 1
 datasets_tn <- generator(
   hyperparam = list(prior_width = prior_width, N = N),

---FILE: vignettes/stan/contaminated_poisson.stan---
@@ -0,0 +1,25 @@
+data {
+  int N; // Number of observations
+  array[N] int y;
+}
+parameters {
+  // Parameters of measurement model
+  real<lower=0> mu_signal;
+  real<lower=0> mu_background;
+
+  real<lower=0, upper=1> p_signal;
+}
+
+model {
+
+  for (n in 1 : N) {
+    target += log_mix(p_signal ,
+      poisson_lpmf(y[n] | mu_background + mu_signal),
+      poisson_lpmf(y[n] | mu_background));
+  }
+
+  mu_background ~ lognormal(-2, 0.2);
+  mu_signal ~ lognormal(2, 1);
+
+  p_signal ~ beta(2, 2);
+}

---FILE: vignettes/stan/hmm_contaminated_poisson.stan---
@@ -0,0 +1,45 @@
+data {
+  int N; // Number of observations
+  array[N] int y;
+}
+parameters {
+  // Parameters of measurement model
+  real<lower=0> mu_signal;
+  real<lower=0> mu_background;
+
+  // Initial state
+  simplex[2] rho;
+
+  // Rows of the transition matrix
+  simplex[2] t1;
+  simplex[2] t2;
+}
+
+model {
+
+  matrix[2, 2] Gamma;
+  matrix[2, N] log_omega;
+
+  // Build the transition matrix
+  Gamma[1, : ] = t1';
+  Gamma[2, : ] = t2';
+
+  // Compute the log likelihoods in each possible state
+  for (n in 1 : N) {
+    // The observation model could change with n, or vary in a number of
+    //  different ways (which is why log_omega is passed in as an argument)
+    log_omega[1, n] = poisson_log_lpmf(y[n] | mu_background);
+    log_omega[2, n] = poisson_log_lpmf(y[n] | mu_background + mu_signal);
+  }
+
+  mu_background ~ lognormal(-2, 0.2);
+  mu_signal ~ lognormal(2, 1);
+
+  // Initial state - we're quite sure we started with the source working
+  rho ~ dirichlet([1, 10]);
+
+  t1 ~ dirichlet([3, 3]);
+  t2 ~ dirichlet([3, 3]);
+
+  target += hmm_marginal(log_omega, Gamma, rho);
+}",True,True,Documentation / Formatting,7
hyunjimoon,SBC,a373e5ed685bb7fda8e4552b497527d4e4986aad,martinmodrak,modrak.mar@gmail.com,2021-12-14T10:36:14Z,martinmodrak,modrak.mar@gmail.com,2021-12-14T10:36:14Z,Fixed typo bug in diagnostics,R/results.R,False,True,True,False,1,1,2,"---FILE: R/results.R---
@@ -583,7 +583,7 @@ compute_results_single <- function(params_and_generated, backend, cores,
           backend = backend)
 
         res$backend_diagnostics <- SBC::SBC_fit_to_diagnostics(
-          fit, res$outuput, res$messages, res$warnings)
+          fit, res$output, res$messages, res$warnings)
         NULL
       }, error = identity)
     })",True,False,Implementation / Logic,6
hyunjimoon,SBC,1dd755295d12104f1e4c5409548f97401fa8d02b,martinmodrak,modrak.mar@gmail.com,2021-09-23T17:46:36Z,martinmodrak,modrak.mar@gmail.com,2021-09-23T17:46:36Z,Fixed bug in CIs  for rank_hist plot,R/plot.R,False,True,True,False,2,3,5,"---FILE: R/plot.R---
@@ -48,9 +48,8 @@ plot_rank_hist.data.frame <- function(x, parameters = NULL, bins = NULL, prob =
 
   # Bins can differ by size (at most by 1). Build a CI that is conservative,
   # i.e. includes lower quantile of smalelr bins and higher quantile of larger bins
-  larger_bin_size <- ceiling((max_rank / bins))
-  smaller_bin_size <- floor((max_rank / bins))
-  CI = qbinom(c(0.5 * (1 - prob),0.5,0.5 * (1 + prob)), size=n_simulations,prob  =  larger_bin_size / max_rank)
+  larger_bin_size <- ceiling(((max_rank + 1) / bins))
+  smaller_bin_size <- floor(((max_rank + 1) / bins))
   ci_lower = qbinom(0.5 * (1 - prob), size=n_simulations,prob  =  smaller_bin_size / max_rank)
   ci_mean = qbinom(0.5, size=n_simulations,prob  =  1 / bins)
   ci_upper = qbinom(0.5 * (1 + prob), size=n_simulations,prob  =  larger_bin_size / max_rank)",True,False,Implementation / Logic,6
hyunjimoon,SBC,fbd472962614a65cdad90a5828e8e9d24397ced0,martinmodrak,modrak.mar@gmail.com,2021-09-18T16:01:47Z,martinmodrak,modrak.mar@gmail.com,2021-09-18T16:01:47Z,Two forgotten fixes to vignettes,vignettes/rejection_sampling.Rmd;vignettes/small_model_workflow.Rmd,True,False,True,False,4,3,7,"---FILE: vignettes/rejection_sampling.Rmd---
@@ -30,7 +30,8 @@ But does rejection sampling when generating datasets affect the validity of SBC?
 Thanks to forum user Niko Huurre who derived the necessary math
 at [Stan Discourse discussion of the topic](https://discourse.mc-stan.org/t/using-narrower-priors-for-sbc/21709/6?u=martinmodrak)
 we know exactly when it is OK. Briefly: for algorithms
-that only need to know the posterior density up to a constant,
+that only need to know the posterior density up to a constant (which includes Stan
+and many others),
 it is OK as long as the rejection criterion only
 uses observed data and not the unobserved parameters.
 

---FILE: vignettes/small_model_workflow.Rmd---
@@ -800,7 +800,7 @@ plot(fanos, results_combined$backend_diagnostics$n_divergent)
 
 All the divergence are for low fano factors - this is the histogram of Fano factor for diverging fits:
 
-```{r}
+```{r fanos_divergent}
 hist(fanos[results_combined$backend_diagnostics$n_divergent > 0])
 ```
 
@@ -885,7 +885,7 @@ plot_ecdf_diff(results_combined_reject)
 
 And our coverage is pretty tight:
 
-```{r}
+```{r combined_reject_coverage}
 plot_coverage(results_combined_reject)
 ```
 ",False,True,Rendering / Conversion,3
hyunjimoon,SBC,acfd50fab2193ff96463d5af6bcae7c20d2951c1,martinmodrak,modrak.mar@gmail.com,2021-09-18T15:47:08Z,martinmodrak,modrak.mar@gmail.com,2021-09-18T15:47:08Z,"Extending basic_usage vignette, fixing problems in other vignettes",R/plot.R;README.md;man/plot_contraction.Rd;vignettes/bad_parametrization.Rmd;vignettes/basic_usage.Rmd;vignettes/brms.Rmd;vignettes/discrete_params.Rmd;vignettes/indexing.Rmd;vignettes/limits_of_SBC.Rmd;vignettes/rejection_sampling.Rmd;vignettes/small_model_workflow.Rmd,True,True,True,False,368,91,459,"---FILE: R/plot.R---
@@ -333,6 +333,9 @@ data_for_ecdf_plots.matrix <- function(x,
 
 #' Prior/posterior contraction plot.
 #'
+#' The rationale for this plot and its interpretaion is explained in
+#' Mike Betancourt's
+#' [Towards A Principled Bayesian Workflow](https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html#132_A_Bayesian_Eye_Chart).
 #'
 #' @param x object containing results (a data.frame or [SBC_results()] object).
 #' @param prior_sd a named vector of prior standard deviations for your parameters.

---FILE: README.md---
@@ -27,7 +27,7 @@ plot_rank_hist(results)
 For detailed usage, please refer to the included vignettes.
 
 ### Compatibility
-Currently `SBC` supports `cmdstan`, `rstan`, and `brms` models out of the box. However, adding Backends for other platforms is supported through the `api` interface.
+Currently `SBC` supports `cmdstan`, `rstan`, and `brms` models out of the box. However, adding Backends for other platforms is supported.
 
 ## Installation
 To install the development version of SBC, run

---FILE: man/plot_contraction.Rd---
@@ -25,5 +25,7 @@ or \code{""var""} for variance.}
 a ggplot2 plot object
 }
 \description{
-Prior/posterior contraction plot.
+The rationale for this plot and its interpretaion is explained in
+Mike Betancourt's
+\href{https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html#132_A_Bayesian_Eye_Chart}{Towards A Principled Bayesian Workflow}.
 }

---FILE: vignettes/bad_parametrization.Rmd---
@@ -134,9 +134,6 @@ cat(readLines(""stan/bad_parametrization2.stan""), sep = ""\n"")
 ```
 
 ```{r}
-stan_code_2 <- ""
-""
-
 if(use_cmdstanr) {
   model_gamma_2 <- cmdstan_model(""stan/bad_parametrization2.stan"")
 

---FILE: vignettes/basic_usage.Rmd---
@@ -9,28 +9,107 @@ vignette: >
   %\VignetteEncoding{UTF-8}
 ---
 
-# SBC
-
-## Introduction
-SBC aims to extend `rstan::sbc()` to include support for new Simulation Based Calibration algorithms without the user having to hassle with
-sampling or standardizing input/output. It provides utility functions which can ease sampling prior/posterior predictive distributions, along with
-generic SBC plots, experimental features such as bootstrap/jacknife sampling, and integral probability metric based tests. 
-
-This vignette will demonstrate how the basic package interface can be used to generate multiple SBC samples to calculate ranks.
+## What is SBC?
+
+SBC stands for ""simulation-based calibration"" and it is a tool
+to validate statistical models and/or algorithms fitting those models. 
+In SBC we are given a statistical model, 
+a method to generate samples from the prior predictive distribution 
+(i.e. generate simulated datasets that match the model's priors + likelihood) 
+and an algorithm that fits the model to data.
+
+The rough sketch of SBC is that we simulate some datasets and then for each dataset:
+
+1. Fit the model and obtain $S$ independent samples from the posterior.
+2. For each parameter, take the rank of the simulated parameter value within the
+   posterior samples
+   - Where rank is defined as the number of samples < simulated value
+
+It can be shown that if model matched the generator and algorithm works correctly,
+then for each parameter, the ranks obtained in SBC should be uniformly distributed between $0$ and $S$.
+This corresponds quite directly to claims like 
+""the posterior 84% credible interval should contain the simulated value in 84% of simulations"",
+the rank uniformity represents this claim for all interval widths at once. The theory of SBC is fully
+described in [Talts et al.](https://arxiv.org/abs/1804.06788)
+
+This opens two principal use-cases of SBC:
+
+a) We have an algorithm that we trust is correct and a generator and and we want to check 
+  that we correctly implemented our Bayesian model
+b) We have a generator and a model we trust and we want to check
+  whether a given algorithm correctly computes the posterior.
+
+In any case, a failure of SBC only tells us that at least one of the three 
+pillars of our inference (generator/model/algorithm) is mismatched to others.
+
+In the context of larger Bayesian workflow 
+(as discussed e.g. in [Bayesian Workflow](https://arxiv.org/abs/2011.01808) by Gelman et al. 
+or [Towards A Principled Bayesian Workflow](https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html) by Betancourt), SBC can be used to validate the implementation of a model/algorithm,
+which is just one of many things to check if one needs a robust analysis.
+In particular, SBC does not use any real data and thus cannot tell you anything
+about potential mismatch between your model and the actual data you plan to analyze.
+
+This vignette will demonstrate how the basic package interface can be used to 
+run simulations, calculate ranks and investigate calibration.
+
+## Aims of the package
+
+The SBC package aims to provide a richer and more usable alternative to `rstan::sbc()`.
+The main design goals is to make it easy to incorporate SBC in your everyday modelling
+workflow. To this end:
+
+- No changes to your model are needed to test it with SBC.
+- Once you have your model and code to simulate data ready, it is easy to gradually move from 1 simulation to check
+  your model does not crash to 1000 simulations that can resolve even small inaccuracies.
+
+We intentionally do not focus on mechanisms that would let you automatically 
+construct a simulator just from your model: if we did that, any bugs in your
+model would automatically carry over to the simulator and the SBC would only
+check that the algorithm works. Instead we believe it is good practice to
+implement the simulator in the most easy way possible while altering aspects
+of the implementation that should not matter (e.g. for loops vs. matrix multiplication).
+The best solution would be to have one person write the simulator and a different
+person the model (though that would often be impractical).
+This way you get two independent pieces of code that should correspond to the same data
+generating process and it becomes less likely that there is the same mistake in both 
+versions. A mistake that is in just one version can then be (at least in principle) 
+caught by SBC. 
+
+This is actually a well known pattern in software safety: 
+ critical components in airplanes are required to have two completely 
+ independent implementations of the same software 
+(or even hardware) and the system checks that both produce the same output for the same input.
+Similarly, pharmaceutical
+companies analyzing drug trials are  required to have the data analysis 
+pipeline written by two separate teams and the results of both must match 
+(this is not required for academic trials - who would need
+safety there, right?). The main reason this method is used relatively rarely is that
+implementing the same thing twice is costly. But statistical models are usually relatively small
+pieces of code and the added cost of the second implementation (the generator)
+thus tends to very small. 
 
 ## Overview of the Architecture
 
-The package is largely split into two components, `SBC_datasets` and `Backend` objects. `SBC_datasets` objects hold the simulated prior and data samples, which are then used during SBC to fit the model. Instead of directly creating a dataset object, users may define a `Generator` function that returns the parameters and simulated data for a single iteration. `SBC` can take the function and generate a dataset object for you through repeated calls of the `Generator`. Please refer to here for detailed specifications of `SBC_datasets` and `Generator` functions.
-
 ![Overview of the package structure](overview_wide.png)
 
-Once the `SBC_datasets` is prepared and loaded with the true prior and simulated data samples, `SBC` uses a `Backend` object to actually fit the model to the simulated data and generate posterior samples. In short, `Backend` bunches together the desired platform in which inference is ran(`cmdstanr`, `rstan`, `brms`, `pymc`, etc.), the model, and additional platform-specific inference parameters which are necessary to run inference for the model-platform combination (e.g. number of iterations, initial values, ...).
 
-Once the `SBC_datasets` and `Backend` objects are set up, running SBC and viewing results becomes as simple as a few function calls, greatly reducing the hassle with having to deal with extracting posterior draws and calculating results. Additionally, the results are stored in `posterior::rvars` format, which allows for easy manipulation and rapid calculation of additional metrics of interest.
+To perform SBC, one needs to first generate simulated datasets and then fit the
+model to those datasets. The `SBC_datasets` object holds the simulated prior and data samples. 
+`SBC_datasets` objects can be created directly by the user, but it is often easier to use one
+of provided _Generator_ implementations that let you e.g. wrap a function  that returns the parameters and simulated data for a single dataset or use a `brms` specification to generate
+samples corresponding to a given `brms` model. 
+
+The other big part of the process is a  _backend_.
+The SBC package uses a backend object to actually fit the model to the simulated data and generate posterior samples. In short, backend bunches together the algorithm in which inference is ran (`cmdstanr`, `rstan`, `brms`, `jags`, etc.), the model, and additional platform-specific inference parameters which are necessary to run inference for the model-platform combination (e.g. number of iterations, initial values, ...). 
+In other words backend is a function that takes data as its only input and provides posterior samples.
+
+Once we have a backend and an `SBC_datasets` instance, we can call `compute_results` 
+to actually perform the SBC. The resulting object can then be passed to various plotting 
+and summarising functions to let us easily learn if our model works as expected. 
 
 ## Simple Poisson Regression
 
-In this vignette we will demonstrate how the interface is used with a simple poisson regression model. First we'll
+In this vignette we will demonstrate how the interface is used with a simple poisson model. First we'll
 setup and configure our environment.
 
 ```{r setup, message=FALSE,warning=FALSE, results=""hide""}
@@ -65,7 +144,7 @@ if(!dir.exists(cache_dir)) {
 
 ### Model Setup
 
-We will be running SBC against a model that defines `y ~ Poisson(lambda)`, where `lambda ~ Gamma(15, 5)`. We will be using `cmdstanr` as the backend with the following model code:
+We will be running SBC against a model that defines `y ~ Poisson(lambda)`, where `lambda ~ Gamma(15, 5)`. We will use the following Stan model:
 
 ```{r, comment = """"}
 cat(readLines(""stan/poisson.stan""), sep = ""\n"")
@@ -82,7 +161,7 @@ if(use_cmdstanr) {
 
 ### Generator
 
-Once we have defined the model, we can create a Generator function which will generate prior and data samples:
+Once we have defined the model, we can create a generator function which will generate prior and data samples:
 
 ```{r}
 # A generator function should return a named list containing elements ""parameters"" and ""generated""
@@ -102,11 +181,11 @@ poisson_generator_single <- function(N){  # N is the number of data points we ar
 }
 ```
 
-As you can see, the `Generator` returns a named list containing randomly samples from the prior and generated data realized from the prior samples.
+As you can see, the generator returns a named list containing random samples from the prior and generated data realized from the prior samples - the data are already in the format expected by Stan.
 
-### Create `SBC_Datasets` from Generator
+### Create `SBC_Datasets` from generator
 
-`SBC` provides helper functions `SBC_generator_function` and `generate_datasets` which takes a Generator function and creates a benign `SBC_datasets' object. 
+`SBC` provides helper functions `SBC_generator_function` and `generate_datasets` which takes a generator function and calls it repeatedly to create a valid `SBC_datasets` object. 
 
 ```{r}
 set.seed(54882235)
@@ -119,13 +198,13 @@ poisson_dataset <- generate_datasets(
 ```
 
 
-### Defining `Backend`
+### Defining backend
 
-Once we have the model compiled we'll create a `Backend` object from the model. `SBC` includes pre-defined `Backend` objects for HMC sampling with `cmdstan` and `rstan`. In addition, it also provides generator function and Backend for `brms` based models. 
+Once we have the model compiled we'll create a backend object from the model. `SBC` includes pre-defined backend objects for HMC sampling with `cmdstan` and `rstan`. In addition, it also provides generator function and backend for `brms` based models. 
 
-Note that you can create your own `Backend` if you wish to use a different sampling/optimization platform, such as variational inference or JAGS. For further information on `Backend` specifications, please refer to here.
+Note that you can create your own backend if you wish to use a different sampling/optimization platform, such as variational inference or JAGS. 
 
-Here we'll just use the pre-defined cmdstan Backend, in which we pass our compiled model and any additional arguments we would like to pass over to `cmdstanr::sampling`:
+Here we'll just use the pre-defined cmdstan backend, in which we pass our compiled model and any additional arguments we would like to pass over to the sampling method:
 
 ```{r}
 if(use_cmdstanr) {
@@ -138,6 +217,7 @@ if(use_cmdstanr) {
 ```
 
 ### Computing Ranks
+
 we can then use `compute_results` to fit our datasets with the backend:
 
 ```{r, results=FALSE}
@@ -158,6 +238,7 @@ results$stats
 ```
 
 ### Plots
+
 And finally, we can plot the rank distribution to check if the ranks are uniformly distributed. We can check the rank histogram and ECDF plots:
 
 ```{r rank_hist}
@@ -172,4 +253,47 @@ plot_ecdf(results)
 plot_ecdf_diff(results)
 ```
 
-Since our simulator and model do match, we see that the plots don't show any violation.
+Since our simulator and model do match and Stan works well, we see that the plots don't show any violation.
+
+
+## Is SBC frequentist?
+
+A bit of philosophy at the end - SBC is designed to test Bayesian models and/or algorithms,
+but it fits very well with standard frequentist ideas (and there is no shame about this).
+In fact, SBC can be understood as a very pure form of hypothesis testing as the
+""null hypothesis"" that the ranks are uniformly distributed is completely well specified,
+can (beyond numerical error) actually hold exactly and we are conducting
+the test against a hypothesis of interest. SBC thus lets us follow a 
+simple naive-Popperian way of thinking: we try hard to disprove a hypothesis 
+(that our model + algorithm + generator is correct) and when we fail to disprove
+it, we can consider the hypothesis corroborated to the extent our test was severe.
+This is unlike many scientific applications of hypothesis testing where 
+people use a rejection of the null hypothesis
+ as evidence for alternative (which is usually not warranted).
+ 
+We currently can't provide a good theoretical understanding of the severity
+of a given SBC test, but obviously the more iterations and the narrower the confidence
+bands of the `ecdf` and `ecdf_diff` plots, the more severe the test.
+One can also use `empirical_coverage()` and `plot_coverage()` functions to investigate
+the extent of miscalibration that we cannot rule out given our results so far.
+
+Alternatively, one can somewhat sidestep the discussions about
+philosophy of statistics and understand SBC as a probabilistic unit test for your model.
+In this view, SBC tests a certain identity that we expect to hold if our
+system is implemented correctly, similarly
+how one could test an implementation of an arithmetical system by 
+comparing the results of computing $(x + y)^2$ and $x^2 + 2xy + y^2$ -
+any mismatch means the test failed.
+
+
+## Where to go next?
+
+You may want to explore short examples showing how SBC can be used to diagnose
+[bad parametrization](https://hyunjimoon.github.io/SBC/articles/bad_parametrization.html)
+or [indexing bugs](https://hyunjimoon.github.io/SBC/articles/indexing.html) or
+you may want to read through a longer example of what we consider best
+practice in [model-building workflow](https://hyunjimoon.github.io/SBC/articles/small_model_workflow.html).
+
+Alternatively, you might be interested in the [limits of SBC](https://hyunjimoon.github.io/SBC/articles/limits_of_SBC.html) 
+--- the types of problems that are hard / impossible to catch with SBC and
+what can we do to guard against those.

---FILE: vignettes/brms.Rmd---
@@ -11,6 +11,8 @@ vignette: >
   \usepackage[utf8]{inputenc}
 ---
 
+This vignette shows how the SBC package supports `brms` models. 
+
 ```{r setup, message=FALSE,warning=FALSE, results=""hide""}
 library(SBC)
 library(brms)
@@ -35,7 +37,17 @@ if(!dir.exists(cache_dir)) {
 
 ```
 
-Build a generator using brms and its `sample_prior = ""only""` feature.
+The `brms` package has a built-in feature to simulate from 
+prior corresponding to the model via the `sample_prior = ""only""` option. 
+This is a bit less useful in model validation
+as bug in `brms` (or any mismatch between what `brms` does and what we _think_ it does)
+cannot be found as it will most likely affect the generator and the backend in the same way.
+Still this can be useful for validating `brms` itself - we'll get to validation
+with custom generators in a while. For now, we'll build a generator using `brms` directly.
+
+Generating datasets with this generator requires us to compile a Stan model 
+and may thus take a while. Also the exploration is often problematic, so 
+to avoid problems, we take a lot of samples and thin the resulting samples heavily.
 
 ```{r}
 # We need a ""template dataset"" to let brms build the model.
@@ -62,8 +74,10 @@ set.seed(22133548)
 datasets <- generate_datasets(generator, 100)
 ```
 
+Now we'll build a backend matching the generator (and reuse the compiled model from the
+generator)
+
 ```{r}
-# Reuse the compiled model and other info from the generator
 backend <- SBC_backend_brms_from_generator(generator, chains = 1, thin = 1,
                             init = 0.1)
 
@@ -81,7 +95,10 @@ results <- compute_results(datasets, backend, thin_ranks = 10,
                     cache_location = file.path(cache_dir, ""first""))
 ```
 
-And show ecdf_diff plot - there are no big problems at this resolution.
+There are some problems, that we currently choose to ignore (the highest Rhat is barely above
+the 1.01 threshold, so it is probably just noise in Rhat computation).
+
+So we can inspect the rank plots. There are no big problems at this resolution.
 
 ```{r results_plots}
 plot_rank_hist(results)
@@ -97,11 +114,13 @@ This time we will not use the `brms` model to also simulate from prior, but
 simulate using an R function.
 
 This  allows us to have different covariate values for each dataset, potentially improving sensitivity.
+Additionally, we get to learn if `brms` does what we think it does!
 
 Let's take a Gaussian model with a single varying intercept.
 
-
-The data can be generated using the following code:
+The data can be generated using the following code - note that we
+need to be careful to match the parameter names as `brms` uses them. You
+can call `parnames` on a fit to see them.
 
 ```{r}
 one_dataset_generator <- function(N, K) {
@@ -138,11 +157,12 @@ one_dataset_generator <- function(N, K) {
   )
 }
 
-n_dataset_generator <- SBC_generator_function(one_dataset_generator, N = 25, K = 3)
+n_dataset_generator <- SBC_generator_function(one_dataset_generator, N = 18, K = 5)
 ```
 
 For increased sensitivity, we also add the log likelihood of the data given parameters
-as a generated quantity that we'll also monitor.
+as a generated quantity that we'll also monitor (see the [`limits_of_SBC`](https://hyunjimoon.github.io/SBC/articles/limits_of_SBC.html) 
+vignette for discussion on why this is useful).
 
 ```{r}
 log_lik_gq_func <- generated_quantities(
@@ -156,6 +176,10 @@ set.seed(12239755)
 datasets_func <- generate_datasets(n_dataset_generator, 100)
 ```
 
+This is then our `brms` backend - note that `brms` requires us to provide a sample
+dataset that it will use to build the model (e.g. to see how many levels of 
+various varying intercepts to include):
+
 ```{r}
 priors_func <- prior(normal(0,1), class = ""b"") +
   prior(normal(5,1), class = ""Intercept"") +
@@ -168,7 +192,7 @@ backend_func <- SBC_backend_brms(y ~ x + (1 | group),
                             template_dataset = datasets_func$generated[[1]])
 
 ```
-
+So we can happily compute:
 
 ```{r}
 results_func <- compute_results(datasets_func, backend_func, thin_ranks = 10, 
@@ -177,6 +201,8 @@ results_func <- compute_results(datasets_func, backend_func, thin_ranks = 10,
                     cache_location = file.path(cache_dir, ""func""))
 ```
 
+So that's not looking good! Divergent transitions, Rhat problems... And the
+rank plots also show problems:
 
 
 ```{r results_func_plots}
@@ -186,12 +212,13 @@ plot_ecdf_diff(results_func)
 
 It looks like there is a problem affecting at least the `b_Intercept` and `sigma` parameters.
 We may also notice that the `log_lik` (log likelihood derived from all the parameters) is copying
-the behaviour of the worst behaving parameter. This tends to be the case in many models, so in models with lots of parameters, it can be useful to add such a term as they make noticing problems easier. There also other advantages as discussed in the `limits_of_SBC` vignette.
+the behaviour of the worst behaving parameter. This tends to be the case in many models, so in models with lots of parameters, it can be useful to add such a term as they make noticing problems easier. 
 
 What happened is that `brms` by default centers all the predictors, which changes the
 numerical values of the intercept (but not other terms). The interaction with the prior than probably also affects the other parameters.
 
-Maybe we don't want `brms` to do this --- using `0 + Intercept` syntax avoids the centering. 
+Maybe we don't want `brms` to do this --- using `0 + Intercept` syntax avoids the centering,
+so we build a new backend that should match our simulator better
 
 
 ```{r}
@@ -218,15 +245,14 @@ results_func2 <- compute_results(datasets_func, backend_func2, thin_ranks = 10,
                     cache_location = file.path(cache_dir, ""func2""))
 ```
 
-We see that this results in mostly non-problematic univariate checks.
-
-TODO: Figure out the source of divergences and check if they create the mismatch for some of the parameters.
+We see that this still results in some problematic fits,
+but the proportion got lower. At this point I am honestly unsure
+what is the issue, but the rank plots look mostly OK:
 
 ```{r results_func2_plots}
 plot_rank_hist(results_func2)
 plot_ecdf_diff(results_func2)
 ```
 
 
-
-
+I promise to update this vignette once I figure out the source of the problems.

---FILE: vignettes/discrete_params.Rmd---
@@ -44,7 +44,7 @@ if(!dir.exists(cache_dir)) {
 
 ```
 
-Model from:
+We take the changepoint model from:
 https://mc-stan.org/docs/2_26/stan-users-guide/change-point-section.html
 
 ```{r, comment = """"}
@@ -110,7 +110,7 @@ results_1 <- compute_results(datasets_1, backend_1,
 Here we also use the caching feature to avoid recomputing the fits when recompiling this vignette. 
 In practice, caching is not necessary but is often useful.
 
-TODO the diagnostics are false positives, because Rhat and ESS don't work very well for discrete parameters.
+TODO the diagnostic failures are false positives, because Rhat and ESS don't work very well for discrete parameters.
 We need to figure out how to handle this better.
 
 We can quickly note that the statistics for the `s` parameter are extreme - many ranks of 0 and _extreme_ z-scores, including -Infinity. Seing just one or two such fits should be enough to convince us that there is something fundamentally wrong.
@@ -129,7 +129,17 @@ plot_ecdf_diff(results_1)
 plot_rank_hist(results_1)
 ```
 
-So what happened? After some inspection, you may notice that the simulator does not match the model - the model takes the early rate (`e`) for points `t < s` while the simulator takes `e` for points `t <=  s`, so there is effectively a shift by one time point between the simulator and the model. So let's assume that we beleive that the Stan model is in fact right. We therfore updated the simulator to match the model:
+An important note: you may wonder, how we got such a wiggly line for the `s` parameter - doesn't it
+have just 5 possible values? Shouldn't therefore the ECDF be one big staircase? 
+In fact the package does a little trick to make discrete parameters comparable to
+continuous - the rank of a discrete parameter is chosen uniformly randomly across
+all possible ranks (i.e. posterior draws that have exactly equal value). This 
+means that if the model is well behaved, ranks for the discrete parameter will
+be uniformly distributed across the whole range of possible ranks and we can
+use exactly the same diagnostics for a discrete parameter as we do for the 
+continuous ones.
+
+But back to the model - what happened? What is wrong with it? After some inspection, you may notice that the simulator does not match the model - the model takes the early rate (`e`) for points `t < s` while the simulator takes `e` for points `t <=  s`, so there is effectively a shift by one time point between the simulator and the model. So let's assume that we beleive that the Stan model is in fact right. We therefore updated the simulator to match the model:
 
 
 ```{r}
@@ -163,6 +173,7 @@ generate_single_dataset_2 <- function(T, r_e, r_l) {
 generator_2 <- SBC_generator_function(generate_single_dataset_2, T = 5, r_e = 0.5, r_l = 0.1)
 ```
 
+And we can recompute:
 
 
 ```{r}
@@ -179,7 +190,7 @@ plot_ecdf_diff(results_2)
 ```
 
 
-Looks good, so let us add some more SBC steps to make sure the model behaves well.
+Looks good, so let us add some more simulations to make sure the model behaves well.
 
 ```{r}
 set.seed(54321488)

---FILE: vignettes/indexing.Rmd---
@@ -120,7 +120,8 @@ let us see big problems (but not subtle issues)
 
 ```{r}
 set.seed(5666024)
-datasets_regression <- generate_datasets(SBC_generator_function(single_dataset_regression, N = 100, K = 2), 10)
+datasets_regression <- generate_datasets(
+  SBC_generator_function(single_dataset_regression, N = 100, K = 2), 10)
 ```
 
 

---FILE: vignettes/limits_of_SBC.Rmd---
@@ -12,6 +12,10 @@ vignette: >
 ---
 
 Here, we'll walk through some problems that are hard/impossible to diagnose with SBC.
+As usual the focus is on problems with models, assuming our inference algorithm 
+is correct. But for each of those problems, one can imagine a corresponding
+failure in an algorithm --- although some of those failures are quite unlikely for
+actual algorithms.
 
 ```{r setup, message=FALSE,warning=FALSE, results=""hide""}
 library(SBC)
@@ -45,7 +49,7 @@ if(!dir.exists(cache_dir)) {
 
 # SBC and minor changes to model
 
-SBC requires _a lot_ of iterations to discover problems that are subtle.
+SBC requires _a lot_ of iterations to discover problems (either with model or the algorithm) that are subtle.
 
 To demonstrate this, we will fit a simple model with a normal likelihood, but use Student's t distribution with 5 degrees of freedom to generate the data.
 
@@ -208,6 +212,8 @@ TODO
 
 SBC will not notice if you completely omit likelihood from your Stan model!
 
+Here we have a generator for a very simple model with gaussian likelihood:
+
 ```{r}
 single_dataset_missing <- function(N) {
   mu <- rnorm(n = 1, mean = 0, sd = 1)
@@ -225,6 +231,9 @@ datasets_missing <- generate_datasets(generator_missing, n_datasets = 200)
 ```
 
 
+And here is a model that just completely ignores the data, but has the 
+right prior:
+
 ```{r, comment = """"}
 cat(readLines(""stan/missing_likelihood.stan""), sep = ""\n"")
 ```
@@ -249,19 +258,28 @@ if(use_cmdstanr) {
 ```
 
 
+Now we'll compute the results for 200 simulated datasets:
+
 ```{r}
 results_missing <- compute_results(datasets_missing, backend_missing, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""missing""))
 ```
 
+And here are our rank plots:
+
 ```{r results_missing_plots}
 plot_rank_hist(results_missing)
 plot_ecdf_diff(results_missing)
 ```
 
+It's just nothing out of the ordinary.
 
-Can be noticed by prior/posterior contraction plot. For this model, we can
+But we are not completely helpless: 
+This specific type of problem can be noticed by prior/posterior contraction plot. 
+In this plot we compare the prior and posterior standard deviation to get a measure
+of how much more we know about the parameter after fitting the model.
+For this model, we can
 get the prior sd directly, but one can also use a (preferably large) `SBC_datasets` object
 to estimate it empirically for more complex models.
 
@@ -283,7 +301,8 @@ plot_sim_estimated(results_missing, alpha = 0.5)
 
 There is however even more powerful method - and that is to include the likelihood in the SBC.
 This is most easily done by adding a ""generated quantity"" to the SBC results - this is a function
-that is evaluated within the context of the parameters AND data.
+that is evaluated within the context of the parameters AND data. 
+And it can be added without recomputing the fits!
 
 ```{r}
 normal_lpdf <- function(y, mu, sigma) {
@@ -296,6 +315,7 @@ results_missing_gq <- recompute_statistics(results_missing, datasets_missing,
                                              gen_quants = log_lik_gq)
 ```
 
+The rank plots for the `log_lik` quantity immediately shows a severe problem:
 
 ```{r results_missing_gq_plots}
 plot_ecdf_diff(results_missing_gq)
@@ -306,7 +326,8 @@ plot_rank_hist(results_missing_gq)
 # Partially missing likelihood
 
 A more complicated case is when the likelihood is only slightly wrong (and missing something) - e.g. due to an indexing error.
-Turns out missing just one data point needs a lot of steps, so we'll miss a half of them in our likelihood.
+Turns out missing just one data point needs a lot of simulations to see, so we'll write a
+model that ignores a full half of the data points.
 
 ```{r, comment = """"}
 cat(readLines(""stan/partially_missing_likelihood.stan""), sep = ""\n"")
@@ -327,6 +348,8 @@ if(use_cmdstanr) {
 
 ```
 
+Let us use this model for the same dataset.
+
 ```{r}
 results_missing_2 <- compute_results(datasets_missing, backend_missing_2, gen_quants = log_lik_gq, 
                     cache_mode = ""results"", 
@@ -353,5 +376,5 @@ plot_ecdf_diff(results_missing_2)
 plot_rank_hist(results_missing_2)
 ```
 
-We could definitely find even smaller deviations than omitting half the data points, that would however require more SBC steps.
-This boils down to the earlier discussion on small changes to the model - omitting a few data points does not change the posterior very much and thus is harder to detect by SBC - but it is possible.
+We could definitely find even smaller deviations than omitting half the data points, that would however require more simulations for the SBC.
+This boils down to the earlier discussion on small changes to the model - omitting a few data points does not change the posterior very much in this case (as the model is simple and is already quite well informed by just a few data points) and thus it is harder to detect this problem by SBC - but it is possible.

---FILE: vignettes/rejection_sampling.Rmd---
@@ -11,23 +11,93 @@ vignette: >
   \usepackage[utf8]{inputenc}
 ---
 
-How does rejection sampling when generating datasets affect the validity of SBC?
+In some cases, one may want to exclude extreme datasets from SBC (e.g. because
+those datasets create divergences). It is best to use
+prior predictive checks to examine your priors and change them
+to avoid the extreme datasets. In some cases, this may however be impractical/impossible to 
+do via prior choice - one example are regression coefficients, where
+once we have many predictors, any independent prior that is not very strict
+will lead to unrealistic predictions. Joint priors are needed in such case, but
+those are not well understood and easy to use. See 
+[Paul Bürkner's talk on SBC StanConnect](https://www.youtube.com/watch?v=SbgAMkN18dA&t=2340s)
+for more context.
 
-TODO: copy math and ideas from
-https://discourse.mc-stan.org/t/using-narrower-priors-for-sbc/21709/6?u=martinmodrak
+An alternative is to use _rejection sampling_ i.e. we repeatedly generate a 
+dataset and only accept it as a dataset when it passes a certain condition we impose
+(e.g. that no observed count is larger than $10^8$).
+But does rejection sampling when generating datasets affect the validity of SBC?
 
+Thanks to forum user Niko Huurre who derived the necessary math
+at [Stan Discourse discussion of the topic](https://discourse.mc-stan.org/t/using-narrower-priors-for-sbc/21709/6?u=martinmodrak)
+we know exactly when it is OK. Briefly: for algorithms
+that only need to know the posterior density up to a constant,
+it is OK as long as the rejection criterion only
+uses observed data and not the unobserved parameters.
+
+We'll first walk through the math and then show examples of both OK and problematic
+rejection sampling.
+
+
+## The math
+
+Let $f\left(y\right)$ be the probability that the simulated dataset $y$ is rejected (usually a 0-1 function if you have a clear idea what a ""bad"" dataset looks like, but could be probabilistic if you're relying on finicky diagnostics). The important numbers are the probability of rejection for parameter $\theta$
+
+$$
+L\left(\theta\right)=\int f\left(y\right)\pi\left(y|\theta\right)\mathrm{d}y
+$$
+
+and the total rate of rejections from the prior
+
+$$
+R=\iint f\left(y\right)\pi\left(y|\theta\right)\pi\left(\theta\right)\mathrm{d}y\mathrm{d}\theta=\int L\left(\theta\right)\pi\left(\theta\right)\mathrm{d}\theta
+$$
+
+Rejecting the parameter draw when it generates a “bad” dataset effectively distorts the prior
+
+$$
+\pi\left(\theta\right)\to\frac{L\left(\theta\right)}{R}\pi\left(\theta\right)
+$$
+
+and of course rejections change the generating distribution
+
+$$
+\pi\left(y|\theta\right)\to\frac{f\left(y\right)}{L\left(\theta\right)}\pi\left(y|\theta\right)
+$$
+
+but crucially these changes cancel out when computing the posterior. Before rejections we have:
+
+$$
+\pi(\theta | y) \propto \pi(y | \theta) \pi(\theta)
+$$
+
+After rejections we have
+
+$$
+\pi(\theta | y) \propto \frac{L(\theta)}{R} \pi(y | \theta) \frac{f(y)}{L(\theta)} \pi(\theta) = \frac{f(y)}{R} \pi(y | \theta) \pi(\theta)
+$$
+
+And since $\frac{f(y)}{R}$ is a constant for any given dataset (and hence the fit), 
+the overall posterior for Stan (and most other MCMC algorithms) is the same, 
+because Stan only needs the posterior density up to a constant. 
+So whether we take rejection into account or not, the model will match the generating process. 
+However, if $f$ also depended on $\theta$, it would no longer contribute a constant
+and we'll get a mismatch between the generator and model.
+
+## Practical examples
+
+So let's see if that also happens in practice. Let's setup our environment:
 
 ```{r setup, message=FALSE,warning=FALSE, results=""hide""}
 library(SBC)
 
-# use_cmdstanr <- TRUE # Set to false to use rstan instead
-# 
-# if(use_cmdstanr) {
-#   library(cmdstanr)
-# } else {
-#   library(rstan)
-# }
-library(cmdstanr)
+use_cmdstanr <- TRUE # Set to false to use rstan instead
+
+if(use_cmdstanr) {
+  library(cmdstanr)
+} else {
+  library(rstan)
+}
+
 library(bayesplot)
 library(posterior)
 
@@ -53,10 +123,14 @@ cat(readLines(""stan/rejection_sampling.stan""), sep = ""\n"")
 ```
 
 ```{r}
-backend <- SBC_backend_cmdstan_sample(cmdstan_model(""stan/rejection_sampling.stan""), iter_warmup = 800, iter_sampling = 800)
+if(use_cmdstanr) {
+  backend <- SBC_backend_cmdstan_sample(cmdstan_model(""stan/rejection_sampling.stan""), iter_warmup = 800, iter_sampling = 800)
+} else {
+  backend <- SBC_backend_rstan_sample(stan_model(""stan/rejection_sampling.stan""), iter = 1600, warmup = 800)
+}
 ```
 
-# No rejections
+### No rejections
 
 First, we'll use a generator that matches the model exactly.
 
@@ -91,7 +165,7 @@ plot_rank_hist(results)
 
 Indeed, all looks good.
 
-# Rejection based on parameter values
+### Rejection based on parameter values
 
 Now let us modify the generator to reject based on parameter values. 
 
@@ -130,7 +204,7 @@ plot_rank_hist(results_reject_param)
 
 Indeed, we see a clear failure.
 
-# Rejecting based on data
+### Rejecting based on data
 
 But what if we reject based on the values of data? This should in theory result in just
 a constant change in posterior density and not affect SBC. (SBC will however then check only the 
@@ -170,7 +244,7 @@ plot_ecdf_diff(results_reject_y)
 
 We see that even with quite heavy rejection based on y, SBC to a high resolution passes.
 
-# Take home message
+## Take home message
 
 If our priors can sometimes generate datasets that are unrealistic, but we are unable to 
 specify a better prior directly (e.g. because we would need to define some sort of joint prior),

---FILE: vignettes/small_model_workflow.Rmd---
@@ -1,12 +1,12 @@
 ---
-title: ""Building a small model""
+title: ""Small model implementation workflow""
 author: ""Martin Modrák""
 date: ""`r Sys.Date()`""
 output: 
   rmarkdown::html_vignette:
     toc: yes
 vignette: >
-  %\VignetteIndexEntry{Building a small model}
+  %\VignetteIndexEntry{Small model implementation workflow}
   %\VignetteEngine{knitr::rmarkdown}
   \usepackage[utf8]{inputenc}
 ---
@@ -26,7 +26,7 @@ The workflow described here focuses on small models.
 Once running ~100 fits of the model becomes too costly, there are additional tricks and considerations
 that we hope to delve into in a ""Building a complex model"" vignette (which currently doesn't exist).
 Still many of the approaches here also apply to complex models (especially starting small and building each component separately), and with proper separation of the model into components,
-one can validate big chunks of Stan code while still working with small models.
+one can validate big chunks of Stan code while working with small models only.
 
 We expect the reader to be familiar with basics of the package. If not,
 check out the [""basic_usage"" vignette](https://hyunjimoon.github.io/SBC/articles/basic_usage.html).
@@ -35,7 +35,7 @@ check out the [""basic_usage"" vignette](https://hyunjimoon.github.io/SBC/articles
 
 The example we'll investigate is building a two-component Poisson mixture,
 where the mixing ratio is allowed to vary with some predictors while the means
-of the components are the same for all observations.  
+of the components are the same for all observations.
 A somewhat contrived real world situation where this could be a useful model:
 there are two sub-species of an animal that are hard to observe directly, but leave
 droppings (poop) behind, that we can find. Further, we know the subspecies differ in the 
@@ -59,7 +59,8 @@ It is good practice to start small and implement and validate each of those
 components separately and then put them together and validate the bigger model.
 This makes is substantially easier to locate bugs. 
 You'll notice that the process ends up involving a lot of steps, 
-but the fact is that we still ignore all the completely invalid models (typos, compile errors, dimension mismatches, ...). Developing models you
+but the fact is that we still ignore all the completely invalid models I
+created while writing this vignette (typos, compile errors, dimension mismatches, ...). Developing models you
 can trust is hard work. More experienced users can definitely make bigger steps at once,
 but we strongly discourage anyone from writing a big model in one go. 
 My experience is that whenever I try to do this, the model breaks, is impossible
@@ -162,7 +163,6 @@ results_first <- compute_results(datasets_first, backend_first,
 Oh, we have convergence problems, let us examine the pairs plots
 
 ```{r mixture_first_convergence}
-results_first$stats
 mcmc_pairs(results_first$fits[[1]]$draws())
 ```
 
@@ -185,21 +185,21 @@ model_fixed_log_mix <- cmdstan_model(""small_model_workflow/mixture_fixed_log_mix
 backend_fixed_log_mix <- SBC_backend_cmdstan_sample(model_fixed_log_mix)
 ```
 
-So let's try once again with just the same single dataset:
+So let's try once again with the same single dataset:
 
 ```{r}
 results_fixed_log_mix <- compute_results(datasets_first, backend_fixed_log_mix, 
                     cache_mode = ""results"", 
                     cache_location = file.path(cache_dir, ""mixture_fixed_log_mix""))
 ```
 
-We look at the statistics:
+No warnings this time. We look at the stats:
 
 ```{r}
 results_fixed_log_mix$stats
 ```
 
-We see nothing obviously wrong, no parameter is clearly ridiculously misfit no diagnostic problems, so let's run a few more iterations.
+We see nothing obviously wrong, the posterior means are relatively close to simulated values (as summarised by the z-scores) - no parameter is clearly ridiculously misfit. So let's run a few more iterations.
 
 ```{r}
 set.seed(8314566)
@@ -225,7 +225,7 @@ Let's examine a single pairs plot:
 mcmc_pairs(results_fixed_log_mix_2$fits[[1]]$draws())
 ```
 
-We clearly see two modes in the posterior. And upon reflection, it is not a lot surprising why: swapping `mu1` with `mu2` while also changing `theta` for `1 - theta` gives _exactly_ the same likelihood - because the ordering does not matter. A more detailed explanation of this type of problem is at https://betanalpha.github.io/assets/case_studies/identifying_mixture_models.html
+We clearly see two modes in the posterior. And upon reflection, we can see why: swapping `mu1` with `mu2` while also changing `theta` for `1 - theta` gives _exactly_ the same likelihood - because the ordering does not matter. A more detailed explanation of this type of problem is at https://betanalpha.github.io/assets/case_studies/identifying_mixture_models.html
 
 ### Fixing ordering
 
@@ -294,7 +294,7 @@ Now some fits still produce problematic Rhats or divergent transitions, let's br
 results_fixed_ordered$backend_diagnostics
 ```
 
-There are fits with high R-hats and low ESS. Let's look at the pairs plot for one of those:
+One of the fits has quite a lot of divergent transitions. Let's look at the pairs plot for the model:
 
 ```{r mixture_fixed_ordered_pairs}
 problematic_fit_id <- 2
@@ -343,19 +343,31 @@ plot_rank_hist(results_fixed_ordered_subset)
 plot_ecdf_diff(results_fixed_ordered_subset)
 ```
 
-Since we now have only `r length(results_fixed_ordered_subset)` simulations, it is not surprising that we are still left with a huge uncertainty about the actual coverage of our posterior intervals - we can see that in a plot (showing observed coverage of central posterior intervals of varying width):
+Since we now have only `r length(results_fixed_ordered_subset)` simulations, it is not surprising that we are still left with a huge uncertainty about the actual coverage of our posterior intervals - we can see that in a plot (showing observed coverage of central posterior intervals of varying width and the associated uncertainty):
 
 ```{r mixture_fixed_ordered_subset_coverage}
 plot_coverage(results_fixed_ordered_subset)
 ```
+
 Or investigate numerically.
 
 ```{r}
-empirical_coverage(results_fixed_ordered_subset$stats, width = c(0.5,0.9,0.95))
+coverage <- empirical_coverage(results_fixed_ordered_subset$stats, width = c(0.5,0.9,0.95))
+coverage
+```
+
+```{r, echo=FALSE}
+theta_90_coverage_string <- paste0(round(100 * as.numeric(
+  coverage[coverage$parameter == ""theta"" & coverage$width == 0.9, c(""ci_low"",""ci_high"")])),
+  ""%"",
+  collapse = "" - "")
 ```
 
+
 We can clearly see that while there are no terrible errors, a quite big miscalibration is still
-consistent with the SBC results so far.
+consistent with the SBC results so far, for example the 90% posterior interval for `theta`
+could (as far as we know) contain `r theta_90_coverage_string` of the true values.
+That's not very reassuring.
 
 
 So we can run for more iterations - to reduce memory consumption, we set `keep_fits = FALSE`.
@@ -413,7 +425,7 @@ Let's move to the beta regression component of our model. After spending a bunch
 implementing this, I realized, that maybe treating this as a logistic regression component would have been wiser (and sufficient). But I am gonna keep it in - it just demonstrates that a real workflow can be messy and let's us show some additional classes of problems and how they manifest in SBC.
 
 
-Checking the wiki page for Beta distribution, we notice that it has two parameters, both bounded to be positive. So our first attempt at beta regression just creates two linear predictors - one for each parameter of the distribution, exponentiates to make them positive and we have a model:
+Checking the wiki page for Beta distribution, we notice that it has two parameters, both bounded to be positive. So our first attempt at beta regression just creates two linear predictors - one for each parameter of the distribution. We then exponentiate the predictors to make them positive and we have a model:
 
 ```{r, comment = """"}
 cat(readLines(""small_model_workflow/beta_first.stan""), sep = ""\n"")
@@ -620,6 +632,7 @@ datasets_beta_precision_100 <- bind_datasets(datasets_beta_precision_10, dataset
 plot_rank_hist(results_beta_precision_100)
 plot_ecdf_diff(results_beta_precision_100)
 ```
+
 The plots don't look terrible, but the `beta[2]` and especially the `phi` parameter show slight problems.
 
 So we look back at our model code and note that we forgot to put any prior on `phi`!
@@ -678,6 +691,7 @@ is in quite tight agreement with theory:
 ```{r results_beta_precision_fixed_prior_200_coverage}
 plot_coverage(results_beta_precision_fixed_prior_200)
 ```
+
 So for now we are also happy about the beta regression component.
 
 ## Putting it together
@@ -769,7 +783,7 @@ As done previously, we could just exclude the fits that had divergences, but jus
 
 The general idea is that although we might not want to/be able to express our prior belief about the model (here that the two mixture components are distinct) by priors on model parameters, we still may be able to express our prior belief about the data itself.
 
-And it turns out that if we remove datasets that don't meet a certain condition imposed on the observed data, the implied prior on parameters becomes an additive constant and we can use exactly the same model to fit only the non-rejected datasets. Note that this does not hold if the we rejected datasets based on their parameter values - for more details see the [`rejection_sampling`](https://hyunjimoon.github.io/SBC/articles/rejection_sampling.html) vignette.
+And it turns out that if we remove datasets that don't meet a certain condition imposed on the observed data, the implied prior on parameters becomes an additive constant and we can use exactly the same model to fit only the non-rejected datasets. Note that this does not hold if we rejected datasets based on their parameter values - for more details see the [`rejection_sampling`](https://hyunjimoon.github.io/SBC/articles/rejection_sampling.html) vignette.
 
 The main advantage is that if we can do this, we can avoid wasting computation on fitting datasets that would likely produce divergences anyway. The downside is that it means we no longer have a guarantee the model works for non-rejected datasets, so we need to check if the data we want to analyze would not be rejected by our criterion.
 
@@ -783,11 +797,13 @@ fanos <- vapply(dataset_combined$generated,
                 FUN.VALUE = 0)
 plot(fanos, results_combined$backend_diagnostics$n_divergent)
 ```
+
 All the divergence are for low fano factors - this is the histogram of Fano factor for diverging fits:
 
 ```{r}
 hist(fanos[results_combined$backend_diagnostics$n_divergent > 0])
 ```
+
 So what we'll do is that we'll reject any dataset with Fano factor < 1.5. In practice a simple way to implement this is to wrap our generator code in a loop and break from the loop only when the generated dataset meets our criteria (i.e. is not rejected). This is our code:
 
 ```{r}
@@ -872,7 +888,8 @@ And our coverage is pretty tight:
 ```{r}
 plot_coverage(results_combined_reject)
 ```
-Here is the uncertainty shown numerically for two parameters and some widths of central posterior intervals:
+
+Below we show the uncertainty for two parameters and some widths of central posterior intervals numerically:
 
 ```{r results_combined_reject_coverage}
 stats_subset <- results_combined_reject$stats[
@@ -914,7 +931,7 @@ empirical_coverage(stats_subset, c(0.25,0.5,0.9,0.95))
 
 This actually shows a limitation of the coverage results - for `mu[2]` the approximate CI for coverage excludes exact calibration for a bunch of intervals, but above we see that the more trustworthy `plot_ecdf_diff` is not showing a problem (although there is some tendency towards slight underdispersion).
 
-Still, this might warrant further investigation if small discrepancies in `mu` are considered important, if we are interested only in the `beta` coefficients, we can stay assured that their calibration is pretty good. We give you our word that we ran additional simulations and the discrepance disappears.
+Still, this might warrant further investigation if small discrepancies in `mu` are considered important, if we are interested only in the `beta` coefficients, we can stay assured that their calibration is pretty good. We give you our word that we ran additional simulations and the discrepancy disappears.
 
 Finally, we can also use this simulation exercise to understand what would we be likely to learn from an experiment matching the simulations (50 observations, 3 predictors) and plot the true values against estimated mean + 90% posterior credible interval:
 
@@ -923,7 +940,7 @@ plot_sim_estimated(results_combined_reject_more, alpha = 0.2)
 ```
 
 We see that we get very precise information about `mu` and a decent picture about all `beta` elements, but the reamining uncertainty is large. We could for example compute the probability
-that the posterior 90% interval for `beta[1]` excludes zero, i.e. that we learn something about the sign of `beta[1]` and it is close to 50%:
+that the posterior 90% interval for `beta[1]` excludes zero, i.e. that we learn something about the sign of `beta[1]`: 
 
 ```{r}
 stats_beta1 <- 
@@ -932,8 +949,7 @@ stats_beta1 <-
 
 mean(sign(stats_beta1$q5) == sign(stats_beta1$q95))
 ```
-
-Depending on your aims, this might be a reason to plan for a larger sample size!
+Turns out the probability is only around 50%. Depending on your aims, this might be a reason to plan for a larger sample size!
 
 ## Take home message
 ",True,True,Documentation / Formatting,7
hyunjimoon,SBC,e1c1b9b14c9064c98d025b912446e2a08b019fc0,martinmodrak,modrak.mar@gmail.com,2021-09-18T09:23:28Z,martinmodrak,modrak.mar@gmail.com,2021-09-18T09:23:28Z,Fixed hashing of brms backend,NAMESPACE;R/backends.R;R/results.R;man/empirical_coverage.Rd;vignettes/basic_usage.Rmd;vignettes/brms.Rmd;vignettes/small_model_workflow.Rmd,True,True,True,False,43,9,52,"---FILE: NAMESPACE---
@@ -2,6 +2,7 @@
 
 S3method(""["",SBC_datasets)
 S3method(""["",SBC_results)
+S3method(SBC_backend_hash_for_cache,SBC_backend_brms)
 S3method(SBC_backend_hash_for_cache,SBC_backend_cmdstan_sample)
 S3method(SBC_backend_hash_for_cache,SBC_backend_rstan_sample)
 S3method(SBC_backend_hash_for_cache,default)

---FILE: R/backends.R---
@@ -401,10 +401,12 @@ SBC_backend_brms_from_generator <- function(generator, ...) {
   validate_SBC_backend_brms_args(list(...))
 
   args <- combine_args(generator$args, list(...))
+  args$data <- NULL
+  args$cores <- NULL
+  args$empty <- NULL
+
+  validate_SBC_backend_brms_args(args)
 
-  if(!is.null(args$algorithm) && args$algorithm != ""sampling"") {
-    stop(""Algorithms other than sampling not supported yet"")
-  }
 
   new_SBC_backend_brms(generator$compiled_model, args)
 }
@@ -432,3 +434,12 @@ SBC_fit_to_draws_matrix.brmsfit <- function(fit) {
 SBC_fit_to_diagnostics.brmsfit <- function(fit, fit_output, fit_messages, fit_warnings) {
   SBC_fit_to_diagnostics(fit$fit, fit_output, fit_messages, fit_warnings)
 }
+
+#' @export
+SBC_backend_hash_for_cache.SBC_backend_brms <- function(backend) {
+  object_for_hash <- list(args = backend$args,
+                          model_hash =
+                            SBC_backend_hash_for_cache(backend$stan_backend))
+  rlang::hash(object_for_hash)
+}
+

---FILE: R/results.R---
@@ -856,8 +856,8 @@ check_all_SBC_diagnostics.default <- function(x) {
 check_all_SBC_diagnostics.SBC_results <- function(x) {
   res <- NextMethod()
   if(!res) {
-    message(""Not all diagnostics are OK. You can learn more by inspecting $default_diagnostics, "",
-    ""$backend_diagnostics and/or investigating $outputs/$messages/$warnings for detailed output from the backend."")
+    message(""Not all diagnostics are OK.\nYou can learn more by inspecting $default_diagnostics, "",
+            ""$backend_diagnostics \nand/or investigating $outputs/$messages/$warnings for detailed output from the backend."")
   }
   res
 }
@@ -924,8 +924,8 @@ get_diagnostics_messages.SBC_results_summary <- function(x) {
 
   if(x$n_low_ess_to_rank > 0) {
     msg <- paste0(x$n_low_ess_to_rank, "" ("", round(100 * x$n_low_ess_to_rank / x$n_fits), ""%) fits had tail ESS undefined or less than "",
-                  ""half of the maximum rank, potentially skewing the rank statistics. The lowest tail ESS was "", round(x$min_min_ess_tail),
-                  "".\n If the fits look good otherwise, increasing `thin_ranks` (via recompute_statistcs) or number of posterior samples (by refitting) might help."")
+                  ""half of the maximum rank, potentially skewing \nthe rank statistics. The lowest tail ESS was "", round(x$min_min_ess_tail),
+                  "".\n If the fits look good otherwise, increasing `thin_ranks` (via recompute_statistics) \nor number of posterior samples (by refitting) might help."")
     message_list[[i]] <- data.frame(ok = FALSE, message = msg)
   } else {
     message_list[[i]] <- data.frame(ok = TRUE, message = ""All fits had tail ESS > half of the maximum rank."")
@@ -951,8 +951,8 @@ print.SBC_results_summary <- function(x) {
   print(msg)
 
   if(!all(msg$ok)) {
-    message(""Not all diagnostics are OK. You can learn more by inspecting $default_diagnostics, "",
-            ""$backend_diagnostics and/or investigating $outputs/$messages/$warnings for detailed output from the backend."")
+    message(""Not all diagnostics are OK.\nYou can learn more by inspecting $default_diagnostics, "",
+            ""$backend_diagnostics \nand/or investigating $outputs/$messages/$warnings for detailed output from the backend."")
   }
 
 

---FILE: man/empirical_coverage.Rd---
@@ -44,3 +44,6 @@ intervals should always be accompanied by checks with \code{\link[=plot_ecdf]{pl
 or by using \code{type = ""leftmost""}, because if all leftmost credible intervals are well calibrated,
 then all intervals are well calibrated.
 }
+\seealso{
+\code{\link[=plot_coverage]{plot_coverage()}}
+}

---FILE: vignettes/basic_usage.Rmd---
@@ -109,6 +109,7 @@ As you can see, the `Generator` returns a named list containing randomly samples
 `SBC` provides helper functions `SBC_generator_function` and `generate_datasets` which takes a Generator function and creates a benign `SBC_datasets' object. 
 
 ```{r}
+set.seed(54882235)
 n_datasets <- 100  # Number of SBC iterations to run
 
 poisson_generator <- SBC_generator_function(poisson_generator_single, N = 40)

---FILE: vignettes/brms.Rmd---
@@ -42,6 +42,7 @@ Build a generator using brms and its `sample_prior = ""only""` feature.
 # The predictor (x) values will be used for data generation,
 # the response (y) values will be ignored, but need to be present and 
 # of the correct data type
+set.seed(213452)
 template_data = data.frame(y = rep(0, 15), x = rnorm(15))
 priors <- prior(normal(0,1), class = ""b"") +
   prior(normal(0,1), class = ""Intercept"") +

---FILE: vignettes/small_model_workflow.Rmd---
@@ -921,6 +921,7 @@ Finally, we can also use this simulation exercise to understand what would we be
 ```{r sim_estimated_final}
 plot_sim_estimated(results_combined_reject_more, alpha = 0.2)
 ```
+
 We see that we get very precise information about `mu` and a decent picture about all `beta` elements, but the reamining uncertainty is large. We could for example compute the probability
 that the posterior 90% interval for `beta[1]` excludes zero, i.e. that we learn something about the sign of `beta[1]` and it is close to 50%:
 
@@ -931,8 +932,24 @@ stats_beta1 <-
 
 mean(sign(stats_beta1$q5) == sign(stats_beta1$q95))
 ```
+
 Depending on your aims, this might be a reason to plan for a larger sample size!
 
+## Take home message
+
+There are couple lessons I hope this exercise showed: First, building models 
+you can trust is hard work and it is very easy to make mistakes. Despite the
+models presented here being relatively simple, diagnosing the problems in them
+was not straightforward and required non-trivial background knowledge. For this
+reason, moving in small steps during model development is crucial and can save
+you time as diagnosing the same problems in a 300-line Stan model with 50 parameters 
+can be  basically impossible.
+
+We also hope we convinced you that the SBC package lets you get high-quality 
+information from your simulation efforts and not only diagnose problems but also 
+get some sort of assurance in the end that your model is at least pretty
+close to your simulator.
+
 And that's it for this vignette, thanks for staying until the end and hope the workflow ideas will be useful for you!
 
 ",True,True,Documentation / Formatting,6
hyunjimoon,SBC,4478df2dae698bf8a1cc55e9729511357cb7b837,martinmodrak,cerny.m@gmail.com,2021-09-17T10:53:36Z,martinmodrak,cerny.m@gmail.com,2021-09-17T10:53:36Z,"Docs, fixes, usage of calibration plots",R/calculate.R;R/plot.R;R/results.R;man/ECDF-plots.Rd;man/SBC_results.Rd;man/compute_results.Rd;man/observed_coverage.Rd;man/plot_coverage.Rd;vignettes/limits_of_SBC.Rmd;vignettes/small_model_workflow.Rmd,True,True,True,False,212,51,263,"---FILE: R/calculate.R---
@@ -154,37 +154,82 @@ ranks_to_empirical_pit <- function(ranks, n_posterior_samples){
   (1 + ranks) / (1 + n_posterior_samples)
 }
 
-
+#' Compute observed coverage of posterior credible intervals.
+#'
+#' Uses ranks to compute coverage and surrounding uncertainty of posterior credible intervals.
+#' The uncertainty is only approximate (treating coverage for each interval as a set of independent
+#' Bernoulli trials, while in fact they are not independent), so for making claims on presence/
+#' absence of detectable discrepancies we strongly recommend using [plot_ecdf()] or [plot_ecdf_diff()].
+#' The uncertainty about the coverage can however be useful for guiding decisions on whether
+#' more SBC steps should be performed (i.e. whether we can rule out that the coverage of
+#' the given backend differs too much for our purposes from the optimal value).
+#'
+#' Note that while coverage of central posterior intervals (with the default `type = ""central""`)
+#' is often of the biggest practical interest, perfect calibration of central intervals
+#' still leaves space for substantial problems with the model (e.g. if the posterior 25% - 50% intervals
+#' contain 50% of the true values and the posterior 50% - 75% interval never contains the true value,
+#' the central 50% interval still has the ideal 50% coverage), so investigating central
+#' intervals should always be accompanied by checks with [plot_ecdf()] or [plot_ecdf_diff()]
+#' or by using `type = ""leftmost""`, because if all leftmost credible intervals are well calibrated,
+#' then all intervals are well calibrated.
+#'
+#' @param stats a data.frame of rank statistics (e.g. as returned in the `$stats` component of [SBC_results]),
+#'   at minimum should have at least `parameter`, `rank` and `max_rank` columns)
+#' @param width a vector of values between 0 and 1 representing widths of credible intervals for
+#'   which we compute coverage.
+#' @param prob determines width of the uncertainty interval around the observed coverage
+#' @param inteval_type `""central""` to show coverage of central credible intervals
+#'   or `""leftmost""` to show coverage of leftmost credible intervals (i.e. the observed CDF).
+#' @return A `data.frame` with columns `parameter`, `width` (width of the interval as given
+#'   in the `width` parameter), `width_represented` the closest width that can be represented by
+#'   the ranks in the input (any discrepancy needs to be judged against this rather than `width`),
+#'   `estimate` - observed coverage for the interval, `ci_low`, `ci_high` the uncertainty
+#'   interval around `estimate` (width of the interval is given by the `prob` argument).
 #' @export
-observed_coverage <- function(stats, coverage, ci_width = 0.95) {
+observed_coverage <- function(stats, width, prob = 0.95, interval_type = ""central"") {
   if(!all(c(""parameter"", ""rank"", ""max_rank"") %in% names(stats))) {
     stop(SBC_error(""SBC_invalid_argument_error"",
                    ""The stats data.frame needs a 'parameter', 'rank' and 'max_rank' columns""))
   }
 
-  long <- tidyr::crossing(stats, data.frame(coverage = coverage))
+  stopifnot(is.numeric(width))
+  stopifnot(all(width >= 0) && all(width <= 1))
+
+  stopifnot(interval_type %in% c(""central"", ""leftmost""))
+
+  get_low_rank <- function(max_rank, n_ranks_covered) {
+    if(interval_type == ""central"") {
+      round(max_rank / 2 - n_ranks_covered / 2)
+    } else if(interval_type == ""leftmost"") {
+      rep(0, max(length(n_ranks_covered), length(max_rank)))
+    } else {
+      stop(""Invalid interval_type"")
+    }
+  }
+
+  long <- tidyr::crossing(stats, data.frame(width = width))
   long <- dplyr::mutate(long,
-                       n_ranks_covered = round((max_rank + 1) * coverage),
-                       low_rank = round(max_rank / 2 - n_ranks_covered / 2),
+                       n_ranks_covered = round((max_rank + 1) * width),
+                       low_rank = get_low_rank(max_rank, n_ranks_covered),
                        high_rank = low_rank + n_ranks_covered - 1,
-                       coverage_represented =  (high_rank - low_rank + 1) / (max_rank + 1),
+                       width_represented =  (high_rank - low_rank + 1) / (max_rank + 1),
                        is_covered = rank >= low_rank & rank <= high_rank)
 
    summ <- dplyr::summarise(
-     dplyr::group_by(long, parameter, coverage),
+     dplyr::group_by(long, parameter, width),
      post_alpha = sum(is_covered) + 1,
      post_beta = dplyr::n() - sum(is_covered) + 1,
-     coverage_represented = unique(coverage_represented),
-     # Special handling if coverage_represented is either 0 or 1 as in such case,
+     width_represented = unique(width_represented),
+     # Special handling if width_represented is either 0 or 1 as in such case,
      # the result can never be different from 0 / 1 and so the CI should collapse to a point
-     representable = coverage_represented > 0 & coverage_represented < 1,
+     representable = width_represented > 0 & width_represented < 1,
      ci_low =  dplyr::if_else(representable,
-                              qbeta(0.5 - ci_width / 2, post_alpha, post_beta),
-                              coverage_represented),
+                              qbeta(0.5 - prob / 2, post_alpha, post_beta),
+                              width_represented),
      estimate = sum(is_covered) / dplyr::n(),
      ci_high = dplyr::if_else(representable,
-                              qbeta(0.5 + ci_width / 2, post_alpha, post_beta),
-                              coverage_represented),
+                              qbeta(0.5 + prob / 2, post_alpha, post_beta),
+                              width_represented),
      .groups = ""drop""
    )
 

---FILE: R/plot.R---
@@ -108,6 +108,7 @@ guess_bins <- function(max_rank, N) {
 #' @param ... additional arguments passed to [data_for_ecdf_plots()].
 #' Most notably, if `x` is matrix, a `max_rank` parameter needs to be given.
 #' @import ggplot2
+#' @seealso [plot_coverage()]
 plot_ecdf <- function(x,
                       parameters = NULL,
                       K = NULL,
@@ -461,22 +462,30 @@ plot_sim_estimated.data.frame <- function(x, parameters = NULL, estimate = ""mean
 
 #' Plot the observed coverage and its uncertainty
 #'
+#' Please refer to [observed_coverage()] for details on computation
+#' and limitations of this plot as well as details on the arguments.
+#'
 #' @param x object containing results (a data.frame or [SBC_results()] object).
 #' @param parameters parameters to show in the plot or `NULL` to show all
 #' @param prob the with of the uncertainty interval to be shown
 #' @return a ggplot2 plot object
 #' @export
-plot_coverage <- function(x, parameters = NULL, prob = 0.95 ) {
+plot_coverage <- function(x, parameters = NULL, prob = 0.95,
+                          interval_type = ""central"") {
   UseMethod(""plot_coverage"")
 }
 
+#' @rdname plot_coverage
 #' @export
-plot_coverage.SBC_results <- function(x, parameters = NULL, prob = 0.95) {
-  plot_coverage(x$stats, parameters = parameters, prob = prob)
+plot_coverage.SBC_results <- function(x, parameters = NULL, prob = 0.95,
+                                      interval_type = ""central"") {
+  plot_coverage(x$stats, parameters = parameters, prob = prob, interval_type = interval_type)
 }
 
+#' @rdname plot_coverage
 #' @export
-plot_coverage.data.frame <- function(x, parameters = NULL, prob = 0.95) {
+plot_coverage.data.frame <- function(x, parameters = NULL, prob = 0.95,
+                                     interval_type = ""central"") {
   if(!all(c(""parameter"", ""rank"", ""max_rank"") %in% names(x))) {
     stop(SBC_error(""SBC_invalid_argument_error"",
                    ""The stats data.frame needs a 'parameter', 'rank' and 'max_rank' columns""))
@@ -487,15 +496,16 @@ plot_coverage.data.frame <- function(x, parameters = NULL, prob = 0.95) {
   }
 
   max_max_rank <- max(x$max_rank)
-  coverage <- observed_coverage(x, (0:max_max_rank) / (max_max_rank + 1), ci_width = prob)
+  coverage <- observed_coverage(x, (0:max_max_rank) / (max_max_rank + 1), prob = prob,
+                                interval_type = interval_type)
 
-  ggplot2::ggplot(coverage, aes(x = coverage_represented, y = estimate,
+  ggplot2::ggplot(coverage, aes(x = width_represented, y = estimate,
                                 ymin = ci_low, ymax = ci_high)) +
     geom_ribbon(fill = ""black"", alpha = 0.33) +
     geom_segment(x = 0, y = 0, xend = 1, yend = 1, color = ""skyblue1"", size = 2) +
     #geom_abline(intercept = 0, slope = 1, color = ""skyblue1"", size = 2) +
     geom_line() +
-    scale_x_continuous(""Central interval coverage"") +
+    scale_x_continuous(paste0(interval_type, "" interval width"")) +
     scale_y_continuous(""Observed coverage"") +
     facet_wrap(~parameter)
 

---FILE: R/results.R---
@@ -1,3 +1,13 @@
+#' SBC_results objects.
+#'
+#'
+#' The `SBC_results` contains the following fields:
+#'   - `$stats` statistics for all parameters and fits (one row per parameter-fit combination)
+#'   - `$fits`  the raw fits (unless `keep_fits = FALSE`) or `NULL` if the fit failed
+#'   - `$errors` error messages that caused fit failures
+#'   - `$outputs`, `$messages`, `$warnings` the outputs/messages/warnings written by fits
+#'   - `$default_diagnostics` a data frame of default convergence/correctness diagnostics (one row per fit)
+#'   - `$backend_diagnostics` a data frame of backend-specific diagnostics (one row per fit)
 #' @export
 SBC_results <- function(stats,
                         fits,
@@ -217,15 +227,15 @@ length.SBC_results <- function(x) {
 #'
 #' @param datasets an object of class `SBC_datasets`
 #' @param backend the model + sampling algorithm. The built-in backends can be constructed
-#'   using `SBC_backend_cmdstan_sample()`, `SBC_backend_cmdstan_variational()`, `SBC_backend_rstan_sample()` and `SBC_backend_brms()`.
-#'   (more to come: issue 31, 38, 39). The backend is an S3 class supporting at least the `SBC_fit`,
-#'   `SBC_fit_to_draws_matrix` methods.
+#'   using [SBC_backend_cmdstan_sample()], [SBC_backend_cmdstan_variational()], [SBC_backend_rstan_sample()] and [SBC_backend_brms()].
+#'   (more to come: issue 31, 38, 39). The backend is an S3 class supporting at least the [SBC_fit()],
+#'   [SBC_fit_to_draws_matrix()] methods.
 #' @param cores_per_fit how many cores should the backend be allowed to use for a single fit?
 #'    Defaults to the maximum number that does not produce more parallel chains
-#'    than you have cores. See `default_cores_per_fit()`.
+#'    than you have cores. See [default_cores_per_fit()].
 #' @param keep_fits boolean, when `FALSE` full fits are discarded from memory -
 #'    reduces memory consumption and increases speed (when processing in parallel), but
-#'    prevents you from inspecting the fits and using `recompute_statistics()`.
+#'    prevents you from inspecting the fits and using [recompute_statistics()].
 #'    We recommend to set to `TRUE` in early phases of workflow, when you run just a few fits.
 #'    Once the model is stable and you want to run a lot of iterations, we recommend setting
 #'    to `FALSE` (even for quite a simple model, 1000 fits can easily exhaust 32GB of RAM).
@@ -239,14 +249,8 @@ length.SBC_results <- function(x) {
 #'    enough that a single batch takes at least several seconds, i.e. for small models,
 #'    you can often reduce computation time noticeably by increasing this value.
 #'    You can use `options(SBC.min_chunk_size = value)` to set a minimum chunk size globally.
-#'    See documentation of `future.chunk.size` argument for `future.apply::future_lapply()` for more details.
-#' @return An object of class `SBC_results` that holds:
-#'   - `$stats` statistics for all parameters and fits (one row per parameter-fit combination)
-#'   - `$fits`  the raw fits (unless `keep_fits = FALSE`) or `NULL` if the fit failed
-#'   - `$errors` error messages that caused fit failures
-#'   - `$outputs`, `$messages`, `$warnings` the outputs/messages/warnings written by fits
-#'   - `$default_diagnostics` a data frame of default convergence/correctness diagnostics (one row per fit)
-#'   - `$backend_diagnostics` a data frame of backend-specific diagnostics (one row per fit)
+#'    See documentation of `future.chunk.size` argument for [future.apply::future_lapply()] for more details.
+#' @return An object of class [SBC_results()].
 #'
 #' @export
 compute_results <- function(datasets, backend,

---FILE: man/ECDF-plots.Rd---
@@ -54,3 +54,6 @@ See the methods for \code{\link[=data_for_ecdf_plots]{data_for_ecdf_plots()}} fo
 \details{
 \href{https://arxiv.org/abs/1903.08008}{arxiv::1903.08008} by A. Vehtari et al.
 }
+\seealso{
+\code{\link[=plot_coverage]{plot_coverage()}}
+}

---FILE: man/SBC_results.Rd---
@@ -0,0 +1,28 @@
+% Generated by roxygen2: do not edit by hand
+% Please edit documentation in R/results.R
+\name{SBC_results}
+\alias{SBC_results}
+\title{SBC_results objects.}
+\usage{
+SBC_results(
+  stats,
+  fits,
+  backend_diagnostics,
+  default_diagnostics,
+  outputs,
+  messages,
+  warnings,
+  errors
+)
+}
+\description{
+The \code{SBC_results} contains the following fields:
+\itemize{
+\item \verb{$stats} statistics for all parameters and fits (one row per parameter-fit combination)
+\item \verb{$fits}  the raw fits (unless \code{keep_fits = FALSE}) or \code{NULL} if the fit failed
+\item \verb{$errors} error messages that caused fit failures
+\item \verb{$outputs}, \verb{$messages}, \verb{$warnings} the outputs/messages/warnings written by fits
+\item \verb{$default_diagnostics} a data frame of default convergence/correctness diagnostics (one row per fit)
+\item \verb{$backend_diagnostics} a data frame of backend-specific diagnostics (one row per fit)
+}
+}

---FILE: man/compute_results.Rd---
@@ -18,17 +18,17 @@ compute_results(
 \item{datasets}{an object of class \code{SBC_datasets}}
 
 \item{backend}{the model + sampling algorithm. The built-in backends can be constructed
-using \code{SBC_backend_cmdstan_sample()}, \code{SBC_backend_cmdstan_variational()}, \code{SBC_backend_rstan_sample()} and \code{SBC_backend_brms()}.
-(more to come: issue 31, 38, 39). The backend is an S3 class supporting at least the \code{SBC_fit},
-\code{SBC_fit_to_draws_matrix} methods.}
+using \code{\link[=SBC_backend_cmdstan_sample]{SBC_backend_cmdstan_sample()}}, \code{\link[=SBC_backend_cmdstan_variational]{SBC_backend_cmdstan_variational()}}, \code{\link[=SBC_backend_rstan_sample]{SBC_backend_rstan_sample()}} and \code{\link[=SBC_backend_brms]{SBC_backend_brms()}}.
+(more to come: issue 31, 38, 39). The backend is an S3 class supporting at least the \code{\link[=SBC_fit]{SBC_fit()}},
+\code{\link[=SBC_fit_to_draws_matrix]{SBC_fit_to_draws_matrix()}} methods.}
 
 \item{cores_per_fit}{how many cores should the backend be allowed to use for a single fit?
 Defaults to the maximum number that does not produce more parallel chains
-than you have cores. See \code{default_cores_per_fit()}.}
+than you have cores. See \code{\link[=default_cores_per_fit]{default_cores_per_fit()}}.}
 
 \item{keep_fits}{boolean, when \code{FALSE} full fits are discarded from memory -
 reduces memory consumption and increases speed (when processing in parallel), but
-prevents you from inspecting the fits and using \code{recompute_statistics()}.
+prevents you from inspecting the fits and using \code{\link[=recompute_statistics]{recompute_statistics()}}.
 We recommend to set to \code{TRUE} in early phases of workflow, when you run just a few fits.
 Once the model is stable and you want to run a lot of iterations, we recommend setting
 to \code{FALSE} (even for quite a simple model, 1000 fits can easily exhaust 32GB of RAM).}
@@ -44,18 +44,10 @@ the work may be distributed less equally across workers. We recommend setting th
 enough that a single batch takes at least several seconds, i.e. for small models,
 you can often reduce computation time noticeably by increasing this value.
 You can use \code{options(SBC.min_chunk_size = value)} to set a minimum chunk size globally.
-See documentation of \code{future.chunk.size} argument for \code{future.apply::future_lapply()} for more details.}
+See documentation of \code{future.chunk.size} argument for \code{\link[future.apply:future_lapply]{future.apply::future_lapply()}} for more details.}
 }
 \value{
-An object of class \code{SBC_results} that holds:
-\itemize{
-\item \verb{$stats} statistics for all parameters and fits (one row per parameter-fit combination)
-\item \verb{$fits}  the raw fits (unless \code{keep_fits = FALSE}) or \code{NULL} if the fit failed
-\item \verb{$errors} error messages that caused fit failures
-\item \verb{$outputs}, \verb{$messages}, \verb{$warnings} the outputs/messages/warnings written by fits
-\item \verb{$default_diagnostics} a data frame of default convergence/correctness diagnostics (one row per fit)
-\item \verb{$backend_diagnostics} a data frame of backend-specific diagnostics (one row per fit)
-}
+An object of class \code{\link[=SBC_results]{SBC_results()}}.
 }
 \description{
 Parallel processing is supported via the \code{future} package, for most uses, it is most sensible

---FILE: man/observed_coverage.Rd---
@@ -0,0 +1,46 @@
+% Generated by roxygen2: do not edit by hand
+% Please edit documentation in R/calculate.R
+\name{observed_coverage}
+\alias{observed_coverage}
+\title{Compute observed coverage of posterior credible intervals.}
+\usage{
+observed_coverage(stats, width, prob = 0.95, interval_type = ""central"")
+}
+\arguments{
+\item{stats}{a data.frame of rank statistics (e.g. as returned in the \verb{$stats} component of \link{SBC_results}),
+at minimum should have at least \code{parameter}, \code{rank} and \code{max_rank} columns)}
+
+\item{width}{a vector of values between 0 and 1 representing widths of credible intervals for
+which we compute coverage.}
+
+\item{prob}{determines width of the uncertainty interval around the observed coverage}
+
+\item{inteval_type}{\code{""central""} to show coverage of central credible intervals
+or \code{""leftmost""} to show coverage of leftmost credible intervals (i.e. the observed CDF).}
+}
+\value{
+A \code{data.frame} with columns \code{parameter}, \code{width} (width of the interval as given
+in the \code{width} parameter), \code{width_represented} the closest width that can be represented by
+the ranks in the input (any discrepancy needs to be judged against this rather than \code{width}),
+\code{estimate} - observed coverage for the interval, \code{ci_low}, \code{ci_high} the uncertainty
+interval around \code{estimate} (width of the interval is given by the \code{prob} argument).
+}
+\description{
+Uses ranks to compute coverage and surrounding uncertainty of posterior credible intervals.
+The uncertainty is only approximate (treating coverage for each interval as a set of independent
+Bernoulli trials, while in fact they are not independent), so for making claims on presence/
+absence of detectable discrepancies we strongly recommend using \code{\link[=plot_ecdf]{plot_ecdf()}} or \code{\link[=plot_ecdf_diff]{plot_ecdf_diff()}}.
+The uncertainty about the coverage can however be useful for guiding decisions on whether
+more SBC steps should be performed (i.e. whether we can rule out that the coverage of
+the given backend differs too much for our purposes from the optimal value).
+}
+\details{
+Note that while coverage of central posterior intervals (with the default \code{type = ""central""})
+is often of the biggest practical interest, perfect calibration of central intervals
+still leaves space for substantial problems with the model (e.g. if the posterior 25\% - 50\% intervals
+contain 50\% of the true values and the posterior 50\% - 75\% interval never contains the true value,
+the central 50\% interval still has the ideal 50\% coverage), so investigating central
+intervals should always be accompanied by checks with \code{\link[=plot_ecdf]{plot_ecdf()}} or \code{\link[=plot_ecdf_diff]{plot_ecdf_diff()}}
+or by using \code{type = ""leftmost""}, because if all leftmost credible intervals are well calibrated,
+then all intervals are well calibrated.
+}

---FILE: man/plot_coverage.Rd---
@@ -2,9 +2,15 @@
 % Please edit documentation in R/plot.R
 \name{plot_coverage}
 \alias{plot_coverage}
+\alias{plot_coverage.SBC_results}
+\alias{plot_coverage.data.frame}
 \title{Plot the observed coverage and its uncertainty}
 \usage{
-plot_coverage(x, parameters = NULL, prob = 0.95)
+plot_coverage(x, parameters = NULL, prob = 0.95, interval_type = ""central"")
+
+\method{plot_coverage}{SBC_results}(x, parameters = NULL, prob = 0.95, interval_type = ""central"")
+
+\method{plot_coverage}{data.frame}(x, parameters = NULL, prob = 0.95, interval_type = ""central"")
 }
 \arguments{
 \item{x}{object containing results (a data.frame or \code{\link[=SBC_results]{SBC_results()}} object).}
@@ -17,5 +23,6 @@ plot_coverage(x, parameters = NULL, prob = 0.95)
 a ggplot2 plot object
 }
 \description{
-Plot the observed coverage and its uncertainty
+Please refer to \code{\link[=observed_coverage]{observed_coverage()}} for details on computation
+and limitations of this plot as well as details on the arguments.
 }

---FILE: vignettes/limits_of_SBC.Rmd---
@@ -176,11 +176,25 @@ But it is also the case that the estimates are not completely meaningless (as th
 ```{r}
 plot_sim_estimated(results_minor_200, alpha = 0.5)
 ```
+Another way to investigate this is the coverage plot, showing the attained coverage of various central credible intervals. 
 
 ```{r}
 plot_coverage(results_minor_200)
 ```
 
+Or we can even directly inspect some intervals of interest:
+
+```{r}
+coverage <- observed_coverage(results_minor_200$stats, width = c(0.5,0.9,0.95))
+coverage
+
+sigma_90_coverage_string <- paste0(round(100 * as.numeric(
+  coverage[coverage$parameter == ""sigma"" & coverage$width == 0.9, c(""ci_low"",""ci_high"")])),
+  ""%"",
+  collapse = "" - "")
+```
+
+where we see that for example for the 90% central credible interval of `sigma` we would expect the actual coverage to be  `r sigma_90_coverage_string`.
 
 # Prior mismatch
 

---FILE: vignettes/small_model_workflow.Rmd---
@@ -238,11 +238,23 @@ This gives us no obvious problems.
 plot_ecdf_diff(results_fixed_ordered_subset)
 ```
 
+But we are still left with a huge uncertainty about the actual coverage of our posterior 
+intervals - we can see that in a plot:
+
 ```{r}
 plot_coverage(results_fixed_ordered_subset)
+```
+
 
+Or investigate numerically.
+
+```{r}
+observed_coverage(results_fixed_ordered_subset$stats, width = c(0.5,0.9,0.95))
 ```
 
+We can clearly see that while there are no terrible errors, a quite big miscalibration is still
+consistent with the SBC results so far.
+
 
 So we can run for more iterations:
 ",True,True,Documentation / Formatting,7
hyunjimoon,SBC,e36375e0780b015e974cbd33e4810d6a43bde96a,martinmodrak,modrak.mar@gmail.com,2021-09-15T19:34:01Z,martinmodrak,modrak.mar@gmail.com,2021-09-15T19:34:01Z,"Fixes, adding caching to vignettes pt1",.gitignore;R/backends.R;R/results.R;docs/articles/small_model_workflow.html;tests/testthat/test-integration.R;vignettes/rejection_sampling.Rmd;vignettes/small_model_workflow.Rmd,True,True,True,False,328,193,521,"---FILE: .gitignore---
@@ -5,3 +5,5 @@ Meta
 
 *.nb.html
 *.exe
+
+*_SBC_cache

---FILE: R/backends.R---
@@ -101,7 +101,7 @@ SBC_fit_to_diagnostics.stanfit <- function(fit, fit_output, fit_messages, fit_wa
 
 #' @export
 SBC_backend_hash_for_cache.SBC_backend_rstan_sample <- function(backend) {
-  rlang::hash(backend$model@model_code)
+  rlang::hash(list(model = backend$model@model_code, args = backend$args))
 }
 
 #' @export
@@ -281,7 +281,7 @@ SBC_fit.SBC_backend_cmdstan_sample <- function(backend, generated, cores) {
 
 #' @export
 SBC_backend_hash_for_cache.SBC_backend_cmdstan_sample <- function(backend) {
-  rlang::hash(backend$model$code())
+  rlang::hash(list(model = backend$model$code(), args = backend$args))
 }
 
 

---FILE: R/results.R---
@@ -240,10 +240,10 @@ length.SBC_results <- function(x) {
 #'    you can often reduce computation time noticeably by increasing this value.
 #'    You can use `options(SBC.min_chunk_size = value)` to set a minimum chunk size globally.
 #'    See documentation of `future.chunk.size` argument for `future.apply::future_lapply()` for more details.
-#' @param cache_type Type of caching of results, currently the only supported modes are
+#' @param cache_mode Type of caching of results, currently the only supported modes are
 #'    `""none""` (do not cache) and `""results""` where the whole results object is stored
 #'    and recomputed only when the hash of the backend or dataset changes.
-#' @param cache_location The filesystem location of cache. For `cache_type = ""results""`
+#' @param cache_location The filesystem location of cache. For `cache_mode = ""results""`
 #'    this should be a name of a single file. If the file name does not end with
 #'    `.rds`, this extension is appended.
 #' @return An object of class `SBC_results` that holds:
@@ -292,9 +292,9 @@ compute_results <- function(datasets, backend,
            %in% names(results_from_cache))) {
         warning(""Cache file exists but is in invalid format. Will recompute."")
       } else if(results_from_cache$backend_hash != backend_hash) {
-        warning(""Cache file exists but the backend hash differs. Will recompute."")
+        message(""Cache file exists but the backend hash differs. Will recompute."")
       } else if(results_from_cache$data_hash != data_hash) {
-        warning(""Cache file exists but the datasets hash differs. Will recompute."")
+        message(""Cache file exists but the datasets hash differs. Will recompute."")
       } else {
         result <- tryCatch(validate_SBC_results(results_from_cache$result),
                            error = function(e) { NULL })
@@ -303,16 +303,18 @@ compute_results <- function(datasets, backend,
         } else if(results_from_cache$thin_ranks != thin_ranks ||
                   !identical(results_from_cache$gen_quants, gen_quants))  {
           if(!results_from_cache$keep_fits) {
-            warning(""Cache file exists, but was computed with different thin_ranks/gen_quants and keep_fits == FALSE. Will recompute."")
+            message(""Cache file exists, but was computed with different thin_ranks/gen_quants and keep_fits == FALSE. Will recompute."")
           } else {
             message(paste0(""Results loaded from cache file '"", cache_basename,
                            ""' but it was computed with different thin_ranks/gen_quants.\n"",
-                           ""Calling recompute_statistics""))
+                           ""Calling recompute_statistics.""))
             return(recompute_statistics(old_results = result, datasets = datasets,
                                         thin_ranks = thin_ranks, gen_quants = gen_quants))
           }
         } else {
           message(paste0(""Results loaded from cache file '"", cache_basename, ""'""))
+          check_all_SBC_diagnostics(result)
+
           return(result)
         }
       }

---FILE: docs/articles/small_model_workflow.html---
@@ -134,8 +134,8 @@ <h1 data-toc-skip>Small model workflow</h1>
 <div class=""sourceCode"" id=""cb1""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""kw""><a href=""https://rdrr.io/r/base/library.html"">library</a></span><span class=""op"">(</span><span class=""va"">SBC</span><span class=""op"">)</span>
 
-<span class=""co""># use_cmdstanr &lt;- TRUE # Set to false to use rstan instead</span>
-<span class=""co""># </span>
+<span class=""va"">use_cmdstanr</span> <span class=""op"">&lt;-</span> <span class=""cn"">TRUE</span> <span class=""co""># Set to false to use rstan instead</span>
+
 <span class=""co""># if(use_cmdstanr) {</span>
 <span class=""co"">#   library(cmdstanr)</span>
 <span class=""co""># } else {</span>
@@ -148,18 +148,40 @@ <h1 data-toc-skip>Small model workflow</h1>
 <span class=""kw""><a href=""https://rdrr.io/r/base/library.html"">library</a></span><span class=""op"">(</span><span class=""va""><a href=""https://github.com/HenrikBengtsson/future"">future</a></span><span class=""op"">)</span>
 <span class=""fu""><a href=""https://rdrr.io/pkg/future/man/plan.html"">plan</a></span><span class=""op"">(</span><span class=""va"">multisession</span><span class=""op"">)</span> 
 
-<span class=""fu""><a href=""https://rdrr.io/r/base/options.html"">options</a></span><span class=""op"">(</span>SBC.min_chunk_size <span class=""op"">=</span> <span class=""fl"">5</span><span class=""op"">)</span></code></pre></div>
+<span class=""fu""><a href=""https://rdrr.io/r/base/options.html"">options</a></span><span class=""op"">(</span>SBC.min_chunk_size <span class=""op"">=</span> <span class=""fl"">5</span><span class=""op"">)</span>
+
+<span class=""co""># Setup caching of results</span>
+<span class=""va"">cache_dir</span> <span class=""op"">&lt;-</span> <span class=""st"">""./small_model_worklow_SBC_cache""</span>
+<span class=""kw"">if</span><span class=""op"">(</span><span class=""op"">!</span><span class=""fu""><a href=""https://rdrr.io/r/base/files2.html"">dir.exists</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span><span class=""op"">)</span><span class=""op"">)</span> <span class=""op"">{</span>
+  <span class=""fu""><a href=""https://rdrr.io/r/base/files2.html"">dir.create</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span><span class=""op"">)</span>
+<span class=""op"">}</span></code></pre></div>
 <ul>
 <li>Mixture with predictors for ratios</li>
 </ul>
 <p>A lot of steps, but I still ignore all the completely invalid models (typos, compile errors, dimension mismatches, …)</p>
 <div id=""mixture-component"" class=""section level2"">
 <h2 class=""hasAnchor"">
 <a href=""#mixture-component"" class=""anchor""></a>Mixture component</h2>
-<div class=""sourceCode"" id=""cb2""><pre class=""downlit sourceCode r"">
+<pre><code>data {
+  int&lt;lower=0&gt; N;
+  int y[N];
+}
+
+parameters {
+  real mu1;
+  real mu2;
+  real&lt;lower=0, upper=1&gt; theta;
+}
+
+model {
+  target += log_mix(theta, poisson_log_lpmf(y | mu1), poisson_log_lpmf(y | mu2));
+  target += normal_lpdf(mu1 | 3, 1);
+  target += normal_lpdf(mu2 | 3, 1);
+}</code></pre>
+<div class=""sourceCode"" id=""cb3""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">model_first</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://mc-stan.org/cmdstanr/reference/cmdstan_model.html"">cmdstan_model</a></span><span class=""op"">(</span><span class=""st"">""small_model_workflow/mixture_first.stan""</span><span class=""op"">)</span>
 <span class=""va"">backend_first</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/SBC_backend_cmdstan_sample.html"">SBC_backend_cmdstan_sample</a></span><span class=""op"">(</span><span class=""va"">model_first</span><span class=""op"">)</span> </code></pre></div>
-<div class=""sourceCode"" id=""cb3""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb4""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">generator_func_first</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">N</span><span class=""op"">)</span> <span class=""op"">{</span>
   <span class=""va"">mu1</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Normal.html"">rnorm</a></span><span class=""op"">(</span><span class=""fl"">1</span>, <span class=""fl"">3</span>, <span class=""fl"">1</span><span class=""op"">)</span>
   <span class=""va"">mu2</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Normal.html"">rnorm</a></span><span class=""op"">(</span><span class=""fl"">1</span>, <span class=""fl"">3</span>, <span class=""fl"">1</span><span class=""op"">)</span>
@@ -188,18 +210,16 @@ <h2 class=""hasAnchor"">
 <span class=""op"">}</span>
 
 <span class=""va"">generator_first</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/SBC_generator_function.html"">SBC_generator_function</a></span><span class=""op"">(</span><span class=""va"">generator_func_first</span>, N <span class=""op"">=</span> <span class=""fl"">50</span><span class=""op"">)</span></code></pre></div>
-<div class=""sourceCode"" id=""cb4""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb5""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/r/base/Random.html"">set.seed</a></span><span class=""op"">(</span><span class=""fl"">68455554</span><span class=""op"">)</span>
 <span class=""va"">datasets_first</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/generate_datasets.html"">generate_datasets</a></span><span class=""op"">(</span><span class=""va"">generator_first</span>, <span class=""fl"">1</span><span class=""op"">)</span></code></pre></div>
-<div class=""sourceCode"" id=""cb5""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span class=""va"">results_first</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">datasets_first</span>, <span class=""va"">backend_first</span><span class=""op"">)</span></code></pre></div>
-<pre><code>##  - 1 (100%) fits had at least one Rhat &gt; 1.01. Largest Rhat was 1.52.</code></pre>
-<pre><code>##  - 1 (100%) fits had tail ESS undefined or less than half of the maximum rank, potentially skewing the rank statistics. The lowest tail ESS was NA.
-##  If the fits look good otherwise, increasing `thin_ranks` (via recompute_statistcs) or number of posterior samples (by refitting) might help.</code></pre>
-<pre><code>##  - 1 (100%) fits had divergent transitions. Maximum number of divergences was 9.</code></pre>
-<pre><code>## Not all diagnostics are OK. You can learn more by inspecting $default_diagnostics, $backend_diagnostics and/or investigating $outputs/$messages/$warnings for detailed output from the backend.</code></pre>
+<div class=""sourceCode"" id=""cb6""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""va"">results_first</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">datasets_first</span>, <span class=""va"">backend_first</span>, 
+                    cache_mode <span class=""op"">=</span> <span class=""st"">""results""</span>, 
+                    cache_location <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/file.path.html"">file.path</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span>, <span class=""st"">""mixture_first""</span><span class=""op"">)</span><span class=""op"">)</span></code></pre></div>
+<pre><code>## Results loaded from cache file 'mixture_first'</code></pre>
 <p>We have convergence problems, let us examine the pairs plots</p>
-<div class=""sourceCode"" id=""cb10""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb8""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">results_first</span><span class=""op"">$</span><span class=""va"">stats</span></code></pre></div>
 <pre><code>## # A tibble: 3 x 15
 ##   parameter simulated_value  rank z_score  mean median    sd    mad     q5   q95
@@ -209,58 +229,63 @@ <h2 class=""hasAnchor"">
 ## 3 theta              0.0528    14  -1.87  0.579  0.621 0.282 0.335  0.0773 0.966
 ## # ... with 5 more variables: rhat &lt;dbl&gt;, ess_bulk &lt;dbl&gt;, ess_tail &lt;dbl&gt;,
 ## #   max_rank &lt;int&gt;, dataset_id &lt;int&gt;</code></pre>
-<div class=""sourceCode"" id=""cb12""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb10""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://mc-stan.org/bayesplot/reference/MCMC-scatterplots.html"">mcmc_pairs</a></span><span class=""op"">(</span><span class=""va"">results_first</span><span class=""op"">$</span><span class=""va"">fits</span><span class=""op"">[[</span><span class=""fl"">1</span><span class=""op"">]</span><span class=""op"">]</span><span class=""op"">$</span><span class=""fu"">draws</span><span class=""op"">(</span><span class=""op"">)</span><span class=""op"">)</span></code></pre></div>
-<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-5-1.png"" width=""700""></p>
+<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-6-1.png"" width=""700""></p>
 <p>One thing that stands out is that either <code>mu1</code> is tightly determined and <code>mu2</code> is allowed the full prior range or the other way around. We also don’t learn anything about theta.</p>
 <p>This might be puzzling but relates to bad usage of <code>log_mix</code> (TODO explain)</p>
 <div id=""fixing-mixture"" class=""section level3"">
 <h3 class=""hasAnchor"">
 <a href=""#fixing-mixture"" class=""anchor""></a>Fixing mixture</h3>
-<div class=""sourceCode"" id=""cb13""><pre class=""downlit sourceCode r"">
+<p>data { int&lt;lower=0&gt; N; int y[N]; }</p>
+<p>parameters { real mu1; real mu2; real&lt;lower=0, upper=1&gt; theta; }</p>
+<p>model { for(n in 1:N) { target += log_mix(theta, poisson_log_lpmf(y[n] | mu1), poisson_log_lpmf(y[n] | mu2)); } target += normal_lpdf(mu1 | 3, 1); target += normal_lpdf(mu2 | 3, 1); }</p>
+<div class=""sourceCode"" id=""cb11""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">model_fixed_log_mix</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://mc-stan.org/cmdstanr/reference/cmdstan_model.html"">cmdstan_model</a></span><span class=""op"">(</span><span class=""st"">""small_model_workflow/mixture_fixed_log_mix.stan""</span><span class=""op"">)</span>
 <span class=""va"">backend_fixed_log_mix</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/SBC_backend_cmdstan_sample.html"">SBC_backend_cmdstan_sample</a></span><span class=""op"">(</span><span class=""va"">model_fixed_log_mix</span><span class=""op"">)</span></code></pre></div>
-<div class=""sourceCode"" id=""cb14""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span class=""va"">results_fixed_log_mix</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">datasets_first</span>, <span class=""va"">backend_fixed_log_mix</span><span class=""op"">)</span></code></pre></div>
+<div class=""sourceCode"" id=""cb12""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""va"">results_fixed_log_mix</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">datasets_first</span>, <span class=""va"">backend_fixed_log_mix</span>, 
+                    cache_mode <span class=""op"">=</span> <span class=""st"">""results""</span>, 
+                    cache_location <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/file.path.html"">file.path</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span>, <span class=""st"">""mixture_fixed_log_mix""</span><span class=""op"">)</span><span class=""op"">)</span></code></pre></div>
+<pre><code>## Results loaded from cache file 'mixture_fixed_log_mix'</code></pre>
 <p>We see nothing obviously wrong, let’s run a few more iterations.</p>
-<div class=""sourceCode"" id=""cb15""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb14""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">results_fixed_log_mix</span><span class=""op"">$</span><span class=""va"">stats</span></code></pre></div>
 <pre><code>## # A tibble: 3 x 15
-##   parameter simulated_value  rank z_score   mean median     sd    mad      q5
-##   &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
-## 1 mu1                3.13     392   2.09  2.56   2.58   0.269  0.261  2.10   
-## 2 mu2                4.27     307   0.823 4.26   4.26   0.0171 0.0172 4.23   
-## 3 theta              0.0528   308   0.581 0.0380 0.0331 0.0255 0.0228 0.00688
-## # ... with 6 more variables: q95 &lt;dbl&gt;, rhat &lt;dbl&gt;, ess_bulk &lt;dbl&gt;,
-## #   ess_tail &lt;dbl&gt;, max_rank &lt;int&gt;, dataset_id &lt;int&gt;</code></pre>
-<div class=""sourceCode"" id=""cb17""><pre class=""downlit sourceCode r"">
+##   parameter simulated_value  rank z_score  mean median     sd    mad    q5   q95
+##   &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
+## 1 mu1                3.13       0  -64.9  4.25   4.26  0.0174 0.0172 4.23  4.28 
+## 2 mu2                4.27     400    6.23 2.56   2.58  0.274  0.270  2.08  2.99 
+## 3 theta              0.0528     0  -33.9  0.961  0.967 0.0268 0.0239 0.909 0.993
+## # ... with 5 more variables: rhat &lt;dbl&gt;, ess_bulk &lt;dbl&gt;, ess_tail &lt;dbl&gt;,
+## #   max_rank &lt;int&gt;, dataset_id &lt;int&gt;</code></pre>
+<div class=""sourceCode"" id=""cb16""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/r/base/Random.html"">set.seed</a></span><span class=""op"">(</span><span class=""fl"">8314566</span><span class=""op"">)</span>
 <span class=""va"">datasets_first_10</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/generate_datasets.html"">generate_datasets</a></span><span class=""op"">(</span><span class=""va"">generator_first</span>, <span class=""fl"">10</span><span class=""op"">)</span></code></pre></div>
-<div class=""sourceCode"" id=""cb18""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span class=""va"">results_fixed_log_mix_2</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">datasets_first_10</span>, <span class=""va"">backend_fixed_log_mix</span><span class=""op"">)</span></code></pre></div>
-<pre><code>##  - 10 (100%) fits had at least one Rhat &gt; 1.01. Largest Rhat was 1.736.</code></pre>
-<pre><code>##  - 9 (90%) fits had tail ESS undefined or less than half of the maximum rank, potentially skewing the rank statistics. The lowest tail ESS was NA.
-##  If the fits look good otherwise, increasing `thin_ranks` (via recompute_statistcs) or number of posterior samples (by refitting) might help.</code></pre>
-<pre><code>## Not all diagnostics are OK. You can learn more by inspecting $default_diagnostics, $backend_diagnostics and/or investigating $outputs/$messages/$warnings for detailed output from the backend.</code></pre>
+<div class=""sourceCode"" id=""cb17""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""va"">results_fixed_log_mix_2</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">datasets_first_10</span>, <span class=""va"">backend_fixed_log_mix</span>, 
+                    cache_mode <span class=""op"">=</span> <span class=""st"">""results""</span>, 
+                    cache_location <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/file.path.html"">file.path</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span>, <span class=""st"">""mixture_fixed_log_mix_2""</span><span class=""op"">)</span><span class=""op"">)</span></code></pre></div>
+<pre><code>## Results loaded from cache file 'mixture_fixed_log_mix_2'</code></pre>
 <p>So there are some problems.</p>
-<div class=""sourceCode"" id=""cb22""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb19""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/r/graphics/hist.html"">hist</a></span><span class=""op"">(</span><span class=""va"">results_fixed_log_mix_2</span><span class=""op"">$</span><span class=""va"">stats</span><span class=""op"">$</span><span class=""va"">rhat</span><span class=""op"">)</span></code></pre></div>
-<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-11-1.png"" width=""700""></p>
+<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-13-1.png"" width=""700""></p>
 <p>Let’s examine a single pairs plot:</p>
-<div class=""sourceCode"" id=""cb23""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb20""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://mc-stan.org/bayesplot/reference/MCMC-scatterplots.html"">mcmc_pairs</a></span><span class=""op"">(</span><span class=""va"">results_fixed_log_mix_2</span><span class=""op"">$</span><span class=""va"">fits</span><span class=""op"">[[</span><span class=""fl"">1</span><span class=""op"">]</span><span class=""op"">]</span><span class=""op"">$</span><span class=""fu"">draws</span><span class=""op"">(</span><span class=""op"">)</span><span class=""op"">)</span></code></pre></div>
-<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-12-1.png"" width=""700""></p>
+<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-14-1.png"" width=""700""></p>
 <p>We clearly see two modes. And upon reflection, it is not a lot surprising why: swapping <code>mu1</code> with <code>mu2</code> while also changing <code>theta</code> for <code>1 - theta</code> gives <em>exactly</em> the same likelihood - because the ordering does not matter. A more detailed explanation of this type of problem is at <a href=""https://betanalpha.github.io/assets/case_studies/identifying_mixture_models.html"" class=""uri"">https://betanalpha.github.io/assets/case_studies/identifying_mixture_models.html</a></p>
 </div>
 <div id=""fixing-ordering"" class=""section level3"">
 <h3 class=""hasAnchor"">
 <a href=""#fixing-ordering"" class=""anchor""></a>Fixing ordering</h3>
 <p>We can easily fix the ordering of the <code>mu</code>s by using the <code>ordered</code> built-in type.</p>
-<div class=""sourceCode"" id=""cb24""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb21""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">model_fixed_ordered</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://mc-stan.org/cmdstanr/reference/cmdstan_model.html"">cmdstan_model</a></span><span class=""op"">(</span><span class=""st"">""small_model_workflow/mixture_fixed_ordered.stan""</span><span class=""op"">)</span>
 <span class=""va"">backend_fixed_ordered</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/SBC_backend_cmdstan_sample.html"">SBC_backend_cmdstan_sample</a></span><span class=""op"">(</span><span class=""va"">model_fixed_ordered</span><span class=""op"">)</span> </code></pre></div>
 <p>We also need to update the generator to match the new names and ordering constant:</p>
-<div class=""sourceCode"" id=""cb25""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb22""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">generator_func_ordered</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">N</span><span class=""op"">)</span> <span class=""op"">{</span>
   <span class=""co""># If the priors for all components of an ordered vector are the same</span>
   <span class=""co""># then just sorting the result of a generator is enough to create</span>
@@ -291,17 +316,15 @@ <h3 class=""hasAnchor"">
 
 <span class=""va"">generator_ordered</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/SBC_generator_function.html"">SBC_generator_function</a></span><span class=""op"">(</span><span class=""va"">generator_func_ordered</span>, N <span class=""op"">=</span> <span class=""fl"">50</span><span class=""op"">)</span></code></pre></div>
 <p>We are kind of confident (and the model fits quickly), so we’ll already start with 10 datasets.</p>
-<div class=""sourceCode"" id=""cb26""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb23""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/r/base/Random.html"">set.seed</a></span><span class=""op"">(</span><span class=""fl"">3785432</span><span class=""op"">)</span>
 <span class=""va"">datasets_ordered_10</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/generate_datasets.html"">generate_datasets</a></span><span class=""op"">(</span><span class=""va"">generator_ordered</span>, <span class=""fl"">10</span><span class=""op"">)</span></code></pre></div>
-<div class=""sourceCode"" id=""cb27""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span class=""va"">results_fixed_ordered</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">datasets_ordered_10</span>, <span class=""va"">backend_fixed_ordered</span><span class=""op"">)</span></code></pre></div>
-<pre><code>##  - 2 (20%) fits had at least one Rhat &gt; 1.01. Largest Rhat was 1.207.</code></pre>
-<pre><code>##  - 2 (20%) fits had tail ESS undefined or less than half of the maximum rank, potentially skewing the rank statistics. The lowest tail ESS was NA.
-##  If the fits look good otherwise, increasing `thin_ranks` (via recompute_statistcs) or number of posterior samples (by refitting) might help.</code></pre>
-<pre><code>##  - 2 (20%) fits had divergent transitions. Maximum number of divergences was 145.</code></pre>
-<pre><code>## Not all diagnostics are OK. You can learn more by inspecting $default_diagnostics, $backend_diagnostics and/or investigating $outputs/$messages/$warnings for detailed output from the backend.</code></pre>
-<div class=""sourceCode"" id=""cb32""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb24""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""va"">results_fixed_ordered</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">datasets_ordered_10</span>, <span class=""va"">backend_fixed_ordered</span>, 
+                    cache_mode <span class=""op"">=</span> <span class=""st"">""results""</span>, 
+                    cache_location <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/file.path.html"">file.path</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span>, <span class=""st"">""mixture_fixed_ordered""</span><span class=""op"">)</span><span class=""op"">)</span></code></pre></div>
+<pre><code>## Results loaded from cache file 'mixture_fixed_ordered'</code></pre>
+<div class=""sourceCode"" id=""cb26""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">results_fixed_ordered</span><span class=""op"">$</span><span class=""va"">stats</span></code></pre></div>
 <pre><code>## # A tibble: 30 x 15
 ##    parameter simulated_value  rank z_score  mean median     sd    mad     q5
@@ -319,13 +342,13 @@ <h3 class=""hasAnchor"">
 ## # ... with 20 more rows, and 6 more variables: q95 &lt;dbl&gt;, rhat &lt;dbl&gt;,
 ## #   ess_bulk &lt;dbl&gt;, ess_tail &lt;dbl&gt;, max_rank &lt;int&gt;, dataset_id &lt;int&gt;</code></pre>
 <p>There are fits with high R-hats and low ESS. Let’s look at the pairs plot:</p>
-<div class=""sourceCode"" id=""cb34""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb28""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">problematic_fit_id</span> <span class=""op"">&lt;-</span> <span class=""fl"">2</span>
 <span class=""va"">problematic_fit</span> <span class=""op"">&lt;-</span> <span class=""va"">results_fixed_ordered</span><span class=""op"">$</span><span class=""va"">fits</span><span class=""op"">[[</span><span class=""va"">problematic_fit_id</span><span class=""op"">]</span><span class=""op"">]</span>
 <span class=""fu""><a href=""https://mc-stan.org/bayesplot/reference/MCMC-scatterplots.html"">mcmc_pairs</a></span><span class=""op"">(</span><span class=""va"">problematic_fit</span><span class=""op"">$</span><span class=""fu"">draws</span><span class=""op"">(</span><span class=""op"">)</span>, np <span class=""op"">=</span> <span class=""fu""><a href=""https://mc-stan.org/bayesplot/reference/bayesplot-extractors.html"">nuts_params</a></span><span class=""op"">(</span><span class=""va"">problematic_fit</span><span class=""op"">)</span><span class=""op"">)</span></code></pre></div>
-<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-18-1.png"" width=""700""></p>
+<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-20-1.png"" width=""700""></p>
 <p>There is a lot of ugly stuff going on. Notably, one can notice that the posterior of theta is bimodal, preferring either almost 0 or almost 1 - and when that happens, the mean of one of the components is almost unconstrained. Why does that happen? The key to the answer is in the simulated values for the component means:</p>
-<div class=""sourceCode"" id=""cb35""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb29""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://mc-stan.org/posterior/reference/subset_draws.html"">subset_draws</a></span><span class=""op"">(</span><span class=""va"">datasets_ordered_10</span><span class=""op"">$</span><span class=""va"">parameters</span>, draw <span class=""op"">=</span> <span class=""va"">problematic_fit_id</span><span class=""op"">)</span></code></pre></div>
 <pre><code>## # A draws_matrix: 1 iterations, 1 chains, and 3 variables
 ##     variable
@@ -340,7 +363,7 @@ <h3 class=""hasAnchor"">
 <p>This can definitely be done. But another way is to just ignore the datasets that had divergences for SBC calculations. It turns out that if we remove datasets in a way that only depends on the observed data (and not on unobserved parameters), the SBC identity is preserved and we can use SBC without modifications. The resulting check is however telling us something only for datasets that were not rejected. In this case this is not a big issue: if a fit had divergent transitions, we would not trust it anyway, so removing fits with divergent transitions is not such a big deal.</p>
 <p>For more details see the <code>rejection_sampling</code> vignette.</p>
 <p>So let us subset the results:</p>
-<div class=""sourceCode"" id=""cb37""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb31""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">dataset_ids_to_keep</span> <span class=""op"">&lt;-</span> <span class=""va"">results_fixed_ordered</span><span class=""op"">$</span><span class=""va"">backend_diagnostics</span><span class=""op"">$</span><span class=""va"">dataset_id</span><span class=""op"">[</span><span class=""va"">results_fixed_ordered</span><span class=""op"">$</span><span class=""va"">backend_diagnostics</span><span class=""op"">$</span><span class=""va"">n_divergent</span> <span class=""op"">==</span> <span class=""fl"">0</span><span class=""op"">]</span>
 
 <span class=""co""># Equivalent tidy version if you prefer</span>
@@ -361,22 +384,20 @@ <h3 class=""hasAnchor"">
 ##  - No fits had divergent transitions.
 ##  - No fits had iterations that saturated max treedepth.
 ##  - No fits had steps rejected.
-##  - Maximum time per chain was 3.476 sec.</code></pre>
+##  - Maximum time per chain was 3.865 sec.</code></pre>
 <p>This gives us no obvious problems.</p>
-<div class=""sourceCode"" id=""cb39""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb33""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""../reference/plot_ecdf.html"">plot_ecdf_diff</a></span><span class=""op"">(</span><span class=""va"">results_fixed_ordered_subset</span><span class=""op"">)</span></code></pre></div>
-<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-21-1.png"" width=""700""> So we can run for more iterations:</p>
-<div class=""sourceCode"" id=""cb40""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span class=""va"">datasets_ordered_100</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/generate_datasets.html"">generate_datasets</a></span><span class=""op"">(</span><span class=""va"">generator_ordered</span>, <span class=""fl"">100</span><span class=""op"">)</span>
-<span class=""va"">results_fixed_ordered_100</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">datasets_ordered_100</span>, <span class=""va"">backend_fixed_ordered</span><span class=""op"">)</span></code></pre></div>
-<pre><code>##  - 22 (22%) fits had at least one Rhat &gt; 1.01. Largest Rhat was 1.317.</code></pre>
-<pre><code>##  - 19 (19%) fits had tail ESS undefined or less than half of the maximum rank, potentially skewing the rank statistics. The lowest tail ESS was NA.
-##  If the fits look good otherwise, increasing `thin_ranks` (via recompute_statistcs) or number of posterior samples (by refitting) might help.</code></pre>
-<pre><code>##  - 26 (26%) fits had divergent transitions. Maximum number of divergences was 238.</code></pre>
-<pre><code>##  - 4 (4%) fits had some steps rejected. Maximum number of rejections was 1.</code></pre>
-<pre><code>## Not all diagnostics are OK. You can learn more by inspecting $default_diagnostics, $backend_diagnostics and/or investigating $outputs/$messages/$warnings for detailed output from the backend.</code></pre>
+<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-23-1.png"" width=""700""> So we can run for more iterations:</p>
+<div class=""sourceCode"" id=""cb34""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/r/base/Random.html"">set.seed</a></span><span class=""op"">(</span><span class=""fl"">54987622</span><span class=""op"">)</span>
+<span class=""va"">datasets_ordered_100</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/generate_datasets.html"">generate_datasets</a></span><span class=""op"">(</span><span class=""va"">generator_ordered</span>, <span class=""fl"">100</span><span class=""op"">)</span>
+<span class=""va"">results_fixed_ordered_100</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">datasets_ordered_100</span>, <span class=""va"">backend_fixed_ordered</span>, 
+                    cache_mode <span class=""op"">=</span> <span class=""st"">""results""</span>, 
+                    cache_location <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/file.path.html"">file.path</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span>, <span class=""st"">""mixture_fixed_ordered_100""</span><span class=""op"">)</span><span class=""op"">)</span></code></pre></div>
+<pre><code>## Results loaded from cache file 'mixture_fixed_ordered_100'</code></pre>
 <p>Once again we subset to keep only non-divergent fits</p>
-<div class=""sourceCode"" id=""cb46""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb36""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">dataset_ids_to_keep</span> <span class=""op"">&lt;-</span> <span class=""va"">results_fixed_ordered_100</span><span class=""op"">$</span><span class=""va"">backend_diagnostics</span><span class=""op"">$</span><span class=""va"">dataset_id</span><span class=""op"">[</span><span class=""va"">results_fixed_ordered_100</span><span class=""op"">$</span><span class=""va"">backend_diagnostics</span><span class=""op"">$</span><span class=""va"">n_divergent</span> <span class=""op"">==</span> <span class=""fl"">0</span><span class=""op"">]</span>
 
 <span class=""co""># Equivalent tidy version</span>
@@ -387,24 +408,22 @@ <h3 class=""hasAnchor"">
 
 <span class=""va"">results_fixed_ordered_100_subset</span> <span class=""op"">&lt;-</span> <span class=""va"">results_fixed_ordered_100</span><span class=""op"">[</span><span class=""va"">dataset_ids_to_keep</span><span class=""op"">]</span>
 <span class=""fu""><a href=""https://mc-stan.org/cmdstanr/reference/fit-method-summary.html"">summary</a></span><span class=""op"">(</span><span class=""va"">results_fixed_ordered_100_subset</span><span class=""op"">)</span></code></pre></div>
-<pre><code>## SBC_results with 74 total fits.
+<pre><code>## SBC_results with 72 total fits.
 ##  - No fits had errors.
 ##  - No fits gave warnings.
-##  - 1 (1%) fits had at least one Rhat &gt; 1.01. Largest Rhat was 1.014.
-##  - 1 (1%) fits had tail ESS undefined or less than half of the maximum rank, potentially skewing the rank statistics. The lowest tail ESS was 171.
-##  If the fits look good otherwise, increasing `thin_ranks` (via recompute_statistcs) or number of posterior samples (by refitting) might help.
-##  - The lowest bulk ESS was 363
+##  - No fits had Rhat &gt; 1.01.
+##  - All fits had tail ESS &gt; half of the maximum rank.
+##  - The lowest bulk ESS was 507
 ##  - No fits had failed chains.
 ##  - No fits had divergent transitions.
 ##  - No fits had iterations that saturated max treedepth.
-##  - 4 (5%) fits had some steps rejected. Maximum number of rejections was 1.
-##  - Maximum time per chain was 4.82 sec.</code></pre>
-<pre><code>## Not all diagnostics are OK. You can learn more by inspecting $default_diagnostics, $backend_diagnostics and/or investigating $outputs/$messages/$warnings for detailed output from the backend.</code></pre>
+##  - No fits had steps rejected.
+##  - Maximum time per chain was 4.842 sec.</code></pre>
 <p>And combine with the previous fits to not waste our computational effort.</p>
-<div class=""sourceCode"" id=""cb49""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb38""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">results_fixed_ordered_combined</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/bind_results.html"">bind_results</a></span><span class=""op"">(</span><span class=""va"">results_fixed_ordered_subset</span>, <span class=""va"">results_fixed_ordered_100_subset</span><span class=""op"">)</span>
 <span class=""fu""><a href=""../reference/plot_ecdf.html"">plot_ecdf_diff</a></span><span class=""op"">(</span><span class=""va"">results_fixed_ordered_combined</span><span class=""op"">)</span></code></pre></div>
-<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-24-1.png"" width=""700""></p>
+<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-26-1.png"" width=""700""></p>
 <p>Seems fairly well within the expected bounds. We could definitely run more iterations if we wanted to have a more strict check, but for now, we are happy.</p>
 <p>Note: it turns out that extending the model to more components becomes somewhat tricky as the model can become sensitive to initialization and the problem of data that can be explained by fewer components than the model has becomes more prevalent.</p>
 </div>
@@ -413,10 +432,10 @@ <h3 class=""hasAnchor"">
 <h2 class=""hasAnchor"">
 <a href=""#beta-regression-component"" class=""anchor""></a>Beta regression component</h2>
 <p>Maybe treating this as a logistic regression component would have been wiser. But since I actually realized that only after spending some time with the beta regression task, I am gonna keep it in - it just demonstrates that a real workflow can be messy.</p>
-<div class=""sourceCode"" id=""cb50""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb39""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">model_beta_first</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://mc-stan.org/cmdstanr/reference/cmdstan_model.html"">cmdstan_model</a></span><span class=""op"">(</span><span class=""st"">""small_model_workflow/beta_first.stan""</span><span class=""op"">)</span>
 <span class=""va"">backend_beta_first</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/SBC_backend_cmdstan_sample.html"">SBC_backend_cmdstan_sample</a></span><span class=""op"">(</span><span class=""va"">model_beta_first</span><span class=""op"">)</span> </code></pre></div>
-<div class=""sourceCode"" id=""cb51""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb40""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">generator_func_beta_first</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">N_obs</span>, <span class=""va"">N_predictors</span><span class=""op"">)</span> <span class=""op"">{</span>
   <span class=""kw"">repeat</span> <span class=""op"">{</span>
     <span class=""va"">beta</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/matrix.html"">matrix</a></span><span class=""op"">(</span><span class=""fu""><a href=""https://rdrr.io/r/stats/Normal.html"">rnorm</a></span><span class=""op"">(</span><span class=""va"">N_predictors</span> <span class=""op"">*</span> <span class=""fl"">2</span>, <span class=""fl"">0</span>, <span class=""fl"">1</span><span class=""op"">)</span>, nrow <span class=""op"">=</span> <span class=""fl"">2</span>, ncol <span class=""op"">=</span> <span class=""va"">N_predictors</span><span class=""op"">)</span>
@@ -454,38 +473,38 @@ <h2 class=""hasAnchor"">
 <span class=""op"">}</span>
 
 <span class=""va"">generator_beta_first</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/SBC_generator_function.html"">SBC_generator_function</a></span><span class=""op"">(</span><span class=""va"">generator_func_beta_first</span>, N_obs <span class=""op"">=</span> <span class=""fl"">50</span>, N_predictors <span class=""op"">=</span> <span class=""fl"">3</span><span class=""op"">)</span></code></pre></div>
-<div class=""sourceCode"" id=""cb52""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb41""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/r/base/Random.html"">set.seed</a></span><span class=""op"">(</span><span class=""fl"">3325488</span><span class=""op"">)</span>
 <span class=""va"">datasets_beta_first</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/generate_datasets.html"">generate_datasets</a></span><span class=""op"">(</span><span class=""va"">generator_beta_first</span>, <span class=""fl"">10</span><span class=""op"">)</span></code></pre></div>
-<div class=""sourceCode"" id=""cb53""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span class=""va"">results_beta_first_10</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">datasets_beta_first</span>, <span class=""va"">backend_beta_first</span><span class=""op"">)</span></code></pre></div>
-<pre><code>##  - 1 (10%) fits had divergent transitions. Maximum number of divergences was 6.</code></pre>
-<pre><code>##  - 10 (100%) fits had some steps rejected. Maximum number of rejections was 22.</code></pre>
-<pre><code>## Not all diagnostics are OK. You can learn more by inspecting $default_diagnostics, $backend_diagnostics and/or investigating $outputs/$messages/$warnings for detailed output from the backend.</code></pre>
-<div class=""sourceCode"" id=""cb57""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb42""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""va"">results_beta_first_10</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">datasets_beta_first</span>, <span class=""va"">backend_beta_first</span>, 
+                    cache_mode <span class=""op"">=</span> <span class=""st"">""results""</span>, 
+                    cache_location <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/file.path.html"">file.path</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span>, <span class=""st"">""beta_first_10""</span><span class=""op"">)</span><span class=""op"">)</span></code></pre></div>
+<pre><code>## Results loaded from cache file 'beta_first_10'</code></pre>
+<div class=""sourceCode"" id=""cb44""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""../reference/plot_ecdf.html"">plot_ecdf_diff</a></span><span class=""op"">(</span><span class=""va"">results_beta_first_10</span><span class=""op"">)</span></code></pre></div>
-<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-29-1.png"" width=""700""></p>
-<div class=""sourceCode"" id=""cb58""><pre class=""downlit sourceCode r"">
+<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-31-1.png"" width=""700""></p>
+<div class=""sourceCode"" id=""cb45""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://mc-stan.org/bayesplot/reference/MCMC-scatterplots.html"">mcmc_pairs</a></span><span class=""op"">(</span><span class=""va"">results_beta_first_10</span><span class=""op"">$</span><span class=""va"">fits</span><span class=""op"">[[</span><span class=""fl"">3</span><span class=""op"">]</span><span class=""op"">]</span><span class=""op"">$</span><span class=""fu"">draws</span><span class=""op"">(</span><span class=""op"">)</span><span class=""op"">)</span></code></pre></div>
-<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-30-1.png"" width=""700""></p>
+<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-32-1.png"" width=""700""></p>
 <p>This is a very ugly plot, but we see some correlations between the corresponding beta, let’s have a closer look.</p>
-<div class=""sourceCode"" id=""cb59""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb46""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""kw"">for</span><span class=""op"">(</span><span class=""va"">i</span> <span class=""kw"">in</span> <span class=""fl"">1</span><span class=""op"">:</span><span class=""fl"">5</span><span class=""op"">)</span> <span class=""op"">{</span>
   <span class=""va"">fit</span> <span class=""op"">&lt;-</span> <span class=""va"">results_beta_first_10</span><span class=""op"">$</span><span class=""va"">fits</span><span class=""op"">[[</span><span class=""va"">i</span><span class=""op"">]</span><span class=""op"">]</span>
   <span class=""fu""><a href=""https://rdrr.io/r/base/print.html"">print</a></span><span class=""op"">(</span><span class=""fu""><a href=""https://mc-stan.org/bayesplot/reference/MCMC-scatterplots.html"">mcmc_pairs</a></span><span class=""op"">(</span><span class=""va"">fit</span><span class=""op"">$</span><span class=""fu"">draws</span><span class=""op"">(</span><span class=""op"">)</span>, pars <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/c.html"">c</a></span><span class=""op"">(</span><span class=""st"">""beta[1,1]""</span>, <span class=""st"">""beta[2,1]""</span>,<span class=""st"">""beta[1,2]""</span>, <span class=""st"">""beta[2,2]""</span><span class=""op"">)</span>, np <span class=""op"">=</span> <span class=""fu""><a href=""https://mc-stan.org/bayesplot/reference/bayesplot-extractors.html"">nuts_params</a></span><span class=""op"">(</span><span class=""va"">fit</span><span class=""op"">)</span><span class=""op"">)</span><span class=""op"">)</span>
 <span class=""op"">}</span></code></pre></div>
-<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-31-1.png"" width=""700""><img src=""small_model_workflow_files/figure-html/unnamed-chunk-31-2.png"" width=""700""><img src=""small_model_workflow_files/figure-html/unnamed-chunk-31-3.png"" width=""700""><img src=""small_model_workflow_files/figure-html/unnamed-chunk-31-4.png"" width=""700""><img src=""small_model_workflow_files/figure-html/unnamed-chunk-31-5.png"" width=""700""></p>
+<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-33-1.png"" width=""700""><img src=""small_model_workflow_files/figure-html/unnamed-chunk-33-2.png"" width=""700""><img src=""small_model_workflow_files/figure-html/unnamed-chunk-33-3.png"" width=""700""><img src=""small_model_workflow_files/figure-html/unnamed-chunk-33-4.png"" width=""700""><img src=""small_model_workflow_files/figure-html/unnamed-chunk-33-5.png"" width=""700""></p>
 <p>Turns out the correlations are in all fits, althoug sometimes they are relatively weak and the sampler is able to handle the posterior, it is potentially troubling. The main issue is that we plan to integrate this model with other components and problems that can be tolerated in a single component might interact with other components and become problematic.</p>
 <p>We can even understand the reason for the positive correlation - it is because mean of beta distribution is <span class=""math inline"">\(\frac{\alpha}{\alpha + \beta}\)</span>…</p>
 <p>We can also decide whether to keep the full flexibility and allow predictors for precision.</p>
 <div id=""parametrizing-the-beta-distribution-via-mean"" class=""section level3"">
 <h3 class=""hasAnchor"">
 <a href=""#parametrizing-the-beta-distribution-via-mean"" class=""anchor""></a>Parametrizing the beta distribution via mean</h3>
 <p>This also makes much more sense for the bigger task - combining with the mixture component.</p>
-<div class=""sourceCode"" id=""cb60""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb47""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">model_beta_precision</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://mc-stan.org/cmdstanr/reference/cmdstan_model.html"">cmdstan_model</a></span><span class=""op"">(</span><span class=""st"">""small_model_workflow/beta_precision.stan""</span><span class=""op"">)</span>
 <span class=""va"">backend_beta_precision</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/SBC_backend_cmdstan_sample.html"">SBC_backend_cmdstan_sample</a></span><span class=""op"">(</span><span class=""va"">model_beta_precision</span><span class=""op"">)</span> </code></pre></div>
-<div class=""sourceCode"" id=""cb61""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb48""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">generator_func_beta_precision</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">N_obs</span>, <span class=""va"">N_predictors</span><span class=""op"">)</span> <span class=""op"">{</span>
   <span class=""kw"">repeat</span> <span class=""op"">{</span>
     <span class=""va"">beta</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Normal.html"">rnorm</a></span><span class=""op"">(</span><span class=""va"">N_predictors</span>, <span class=""fl"">0</span>, <span class=""fl"">1</span><span class=""op"">)</span>
@@ -524,64 +543,71 @@ <h3 class=""hasAnchor"">
 <span class=""op"">}</span>
 
 <span class=""va"">generator_beta_precision</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/SBC_generator_function.html"">SBC_generator_function</a></span><span class=""op"">(</span><span class=""va"">generator_func_beta_precision</span>, N_obs <span class=""op"">=</span> <span class=""fl"">50</span>, N_predictors <span class=""op"">=</span> <span class=""fl"">3</span><span class=""op"">)</span></code></pre></div>
-<div class=""sourceCode"" id=""cb62""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb49""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/r/base/Random.html"">set.seed</a></span><span class=""op"">(</span><span class=""fl"">46988234</span><span class=""op"">)</span>
 <span class=""va"">datasets_beta_precision_10</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/generate_datasets.html"">generate_datasets</a></span><span class=""op"">(</span><span class=""va"">generator_beta_precision</span>, <span class=""fl"">10</span><span class=""op"">)</span></code></pre></div>
-<div class=""sourceCode"" id=""cb63""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span class=""va"">results_beta_precision_10</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">datasets_beta_precision_10</span>, <span class=""va"">backend_beta_precision</span><span class=""op"">)</span></code></pre></div>
-<pre><code>##  - 10 (100%) fits had some steps rejected. Maximum number of rejections was 15.</code></pre>
-<pre><code>## Not all diagnostics are OK. You can learn more by inspecting $default_diagnostics, $backend_diagnostics and/or investigating $outputs/$messages/$warnings for detailed output from the backend.</code></pre>
-<div class=""sourceCode"" id=""cb66""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb50""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""va"">results_beta_precision_10</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">datasets_beta_precision_10</span>, <span class=""va"">backend_beta_precision</span>, 
+                    cache_mode <span class=""op"">=</span> <span class=""st"">""results""</span>, 
+                    cache_location <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/file.path.html"">file.path</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span>, <span class=""st"">""beta_precision_10""</span><span class=""op"">)</span><span class=""op"">)</span></code></pre></div>
+<pre><code>## Results loaded from cache file 'beta_precision_10'</code></pre>
+<div class=""sourceCode"" id=""cb52""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""../reference/plot_ecdf.html"">plot_ecdf_diff</a></span><span class=""op"">(</span><span class=""va"">results_beta_precision_10</span><span class=""op"">)</span></code></pre></div>
-<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-36-1.png"" width=""700""></p>
-<div class=""sourceCode"" id=""cb67""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span class=""va"">datasets_beta_precision_90</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/generate_datasets.html"">generate_datasets</a></span><span class=""op"">(</span><span class=""va"">generator_beta_precision</span>, <span class=""fl"">90</span><span class=""op"">)</span>
+<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-38-1.png"" width=""700""></p>
+<div class=""sourceCode"" id=""cb53""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/r/base/Random.html"">set.seed</a></span><span class=""op"">(</span><span class=""fl"">2136468</span><span class=""op"">)</span>
+<span class=""va"">datasets_beta_precision_90</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/generate_datasets.html"">generate_datasets</a></span><span class=""op"">(</span><span class=""va"">generator_beta_precision</span>, <span class=""fl"">90</span><span class=""op"">)</span>
 <span class=""va"">results_beta_precision_100</span> <span class=""op"">&lt;-</span>
   <span class=""fu""><a href=""../reference/bind_results.html"">bind_results</a></span><span class=""op"">(</span>
     <span class=""va"">results_beta_precision_10</span>,
-    <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">datasets_beta_precision_90</span>, <span class=""va"">backend_beta_precision</span><span class=""op"">)</span><span class=""op"">)</span></code></pre></div>
-<pre><code>##  - 90 (100%) fits had some steps rejected. Maximum number of rejections was 22.</code></pre>
-<pre><code>## Not all diagnostics are OK. You can learn more by inspecting $default_diagnostics, $backend_diagnostics and/or investigating $outputs/$messages/$warnings for detailed output from the backend.</code></pre>
-<div class=""sourceCode"" id=""cb70""><pre class=""downlit sourceCode r"">
+    <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">datasets_beta_precision_90</span>, <span class=""va"">backend_beta_precision</span>, 
+                    cache_mode <span class=""op"">=</span> <span class=""st"">""results""</span>, 
+                    cache_location <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/file.path.html"">file.path</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span>, <span class=""st"">""beta_precision_90""</span><span class=""op"">)</span><span class=""op"">)</span><span class=""op"">)</span></code></pre></div>
+<pre><code>## Results loaded from cache file 'beta_precision_90'</code></pre>
+<div class=""sourceCode"" id=""cb55""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">datasets_beta_precision_100</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/bind_datasets.html"">bind_datasets</a></span><span class=""op"">(</span><span class=""va"">datasets_beta_precision_10</span>, <span class=""va"">datasets_beta_precision_90</span><span class=""op"">)</span>
 <span class=""fu""><a href=""../reference/plot_ecdf.html"">plot_ecdf_diff</a></span><span class=""op"">(</span><span class=""va"">results_beta_precision_100</span><span class=""op"">)</span></code></pre></div>
-<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-37-1.png"" width=""700""></p>
+<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-39-1.png"" width=""700""></p>
 <p>Missing prior!</p>
 <p>This type of problem is often not very well visible from SBC (see the <code>limits_of_SBC</code> vignette for more detailed discussion)</p>
 </div>
 <div id=""adding-missing-prior"" class=""section level3"">
 <h3 class=""hasAnchor"">
 <a href=""#adding-missing-prior"" class=""anchor""></a>Adding missing prior</h3>
-<div class=""sourceCode"" id=""cb71""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb56""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">model_beta_precision_fixed_prior</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://mc-stan.org/cmdstanr/reference/cmdstan_model.html"">cmdstan_model</a></span><span class=""op"">(</span><span class=""st"">""small_model_workflow/beta_precision_fixed_prior.stan""</span><span class=""op"">)</span>
 <span class=""va"">backend_beta_precision_fixed_prior</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/SBC_backend_cmdstan_sample.html"">SBC_backend_cmdstan_sample</a></span><span class=""op"">(</span><span class=""va"">model_beta_precision_fixed_prior</span><span class=""op"">)</span> </code></pre></div>
-<div class=""sourceCode"" id=""cb72""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span class=""va"">results_beta_precision_fixed_prior</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">datasets_beta_precision_100</span>, <span class=""va"">backend_beta_precision_fixed_prior</span><span class=""op"">)</span></code></pre></div>
-<pre><code>##  - 100 (100%) fits had some steps rejected. Maximum number of rejections was 17.</code></pre>
-<pre><code>## Not all diagnostics are OK. You can learn more by inspecting $default_diagnostics, $backend_diagnostics and/or investigating $outputs/$messages/$warnings for detailed output from the backend.</code></pre>
-<div class=""sourceCode"" id=""cb75""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb57""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""va"">results_beta_precision_fixed_prior</span> <span class=""op"">&lt;-</span> 
+  <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">datasets_beta_precision_100</span>, <span class=""va"">backend_beta_precision_fixed_prior</span>, 
+                    cache_mode <span class=""op"">=</span> <span class=""st"">""results""</span>, 
+                    cache_location <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/file.path.html"">file.path</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span>, <span class=""st"">""beta_precision_fixed_prior""</span><span class=""op"">)</span><span class=""op"">)</span></code></pre></div>
+<pre><code>## Results loaded from cache file 'beta_precision_fixed_prior'</code></pre>
+<div class=""sourceCode"" id=""cb59""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""../reference/plot_ecdf.html"">plot_ecdf_diff</a></span><span class=""op"">(</span><span class=""va"">results_beta_precision_fixed_prior</span><span class=""op"">)</span></code></pre></div>
-<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-39-1.png"" width=""700""></p>
-<div class=""sourceCode"" id=""cb76""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span class=""va"">datasets_beta_precision_100b</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/generate_datasets.html"">generate_datasets</a></span><span class=""op"">(</span><span class=""va"">generator_beta_precision</span>, <span class=""fl"">100</span><span class=""op"">)</span>
+<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-41-1.png"" width=""700""></p>
+<div class=""sourceCode"" id=""cb60""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/r/base/Random.html"">set.seed</a></span><span class=""op"">(</span><span class=""fl"">1233845</span><span class=""op"">)</span>
+<span class=""va"">datasets_beta_precision_100b</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/generate_datasets.html"">generate_datasets</a></span><span class=""op"">(</span><span class=""va"">generator_beta_precision</span>, <span class=""fl"">100</span><span class=""op"">)</span>
 <span class=""va"">results_beta_precision_fixed_prior_200</span> <span class=""op"">&lt;-</span>
   <span class=""fu""><a href=""../reference/bind_results.html"">bind_results</a></span><span class=""op"">(</span>
     <span class=""va"">results_beta_precision_fixed_prior</span>,
-    <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">datasets_beta_precision_100b</span>, <span class=""va"">backend_beta_precision_fixed_prior</span><span class=""op"">)</span><span class=""op"">)</span></code></pre></div>
-<pre><code>##  - 100 (100%) fits had some steps rejected. Maximum number of rejections was 17.</code></pre>
-<pre><code>## Not all diagnostics are OK. You can learn more by inspecting $default_diagnostics, $backend_diagnostics and/or investigating $outputs/$messages/$warnings for detailed output from the backend.</code></pre>
-<div class=""sourceCode"" id=""cb79""><pre class=""downlit sourceCode r"">
+    <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">datasets_beta_precision_100b</span>, <span class=""va"">backend_beta_precision_fixed_prior</span>, 
+                    cache_mode <span class=""op"">=</span> <span class=""st"">""results""</span>, 
+                    cache_location <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/file.path.html"">file.path</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span>, <span class=""st"">""beta_precision_fixed_prior_2""</span><span class=""op"">)</span><span class=""op"">)</span><span class=""op"">)</span></code></pre></div>
+<pre><code>## Results loaded from cache file 'beta_precision_fixed_prior_2'</code></pre>
+<div class=""sourceCode"" id=""cb62""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""../reference/plot_ecdf.html"">plot_ecdf_diff</a></span><span class=""op"">(</span><span class=""va"">results_beta_precision_fixed_prior_200</span><span class=""op"">)</span></code></pre></div>
-<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-40-1.png"" width=""700""></p>
+<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-42-1.png"" width=""700""></p>
 </div>
 </div>
 <div id=""putting-it-together"" class=""section level2"">
 <h2 class=""hasAnchor"">
 <a href=""#putting-it-together"" class=""anchor""></a>Putting it together</h2>
-<div class=""sourceCode"" id=""cb80""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb63""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">model_combined</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://mc-stan.org/cmdstanr/reference/cmdstan_model.html"">cmdstan_model</a></span><span class=""op"">(</span><span class=""st"">""small_model_workflow/combined_first.stan""</span><span class=""op"">)</span>
 <span class=""va"">backend_combined</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/SBC_backend_cmdstan_sample.html"">SBC_backend_cmdstan_sample</a></span><span class=""op"">(</span><span class=""va"">model_combined</span><span class=""op"">)</span></code></pre></div>
-<div class=""sourceCode"" id=""cb81""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb64""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">generator_func_combined</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">N_obs</span>, <span class=""va"">N_predictors</span><span class=""op"">)</span> <span class=""op"">{</span>
   <span class=""co""># If the priors for all components of an ordered vector are the same</span>
   <span class=""co""># then just sorting the result of a generator is enough to create</span>
@@ -626,31 +652,28 @@ <h2 class=""hasAnchor"">
 <span class=""op"">}</span>
 
 <span class=""va"">generator_combined</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/SBC_generator_function.html"">SBC_generator_function</a></span><span class=""op"">(</span><span class=""va"">generator_func_combined</span>, N_obs <span class=""op"">=</span> <span class=""fl"">50</span>, N_predictors <span class=""op"">=</span> <span class=""fl"">3</span><span class=""op"">)</span></code></pre></div>
-<div class=""sourceCode"" id=""cb82""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb65""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/r/base/Random.html"">set.seed</a></span><span class=""op"">(</span><span class=""fl"">5749955</span><span class=""op"">)</span>
 <span class=""va"">dataset_combined</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/generate_datasets.html"">generate_datasets</a></span><span class=""op"">(</span><span class=""va"">generator_combined</span>, <span class=""fl"">200</span><span class=""op"">)</span></code></pre></div>
-<div class=""sourceCode"" id=""cb83""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span class=""va"">results_combined</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">dataset_combined</span>, <span class=""va"">backend_combined</span><span class=""op"">)</span></code></pre></div>
-<pre><code>##  - 7 (4%) fits had at least one Rhat &gt; 1.01. Largest Rhat was 1.05.</code></pre>
-<pre><code>##  - 8 (4%) fits had tail ESS undefined or less than half of the maximum rank, potentially skewing the rank statistics. The lowest tail ESS was NA.
-##  If the fits look good otherwise, increasing `thin_ranks` (via recompute_statistcs) or number of posterior samples (by refitting) might help.</code></pre>
-<pre><code>##  - 20 (10%) fits had divergent transitions. Maximum number of divergences was 66.</code></pre>
-<pre><code>##  - 2 (1%) fits had some steps rejected. Maximum number of rejections was 2.</code></pre>
-<pre><code>## Not all diagnostics are OK. You can learn more by inspecting $default_diagnostics, $backend_diagnostics and/or investigating $outputs/$messages/$warnings for detailed output from the backend.</code></pre>
-<div class=""sourceCode"" id=""cb89""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb66""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""va"">results_combined</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">dataset_combined</span>, <span class=""va"">backend_combined</span>, 
+                    cache_mode <span class=""op"">=</span> <span class=""st"">""results""</span>, 
+                    cache_location <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/file.path.html"">file.path</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span>, <span class=""st"">""combined""</span><span class=""op"">)</span><span class=""op"">)</span></code></pre></div>
+<pre><code>## Results loaded from cache file 'combined'</code></pre>
+<div class=""sourceCode"" id=""cb68""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""../reference/plot_ecdf.html"">plot_ecdf_diff</a></span><span class=""op"">(</span><span class=""va"">results_combined</span><span class=""op"">)</span></code></pre></div>
-<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-45-1.png"" width=""700""></p>
+<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-47-1.png"" width=""700""></p>
 <div id=""adding-rejection-sampling"" class=""section level3"">
 <h3 class=""hasAnchor"">
 <a href=""#adding-rejection-sampling"" class=""anchor""></a>Adding rejection sampling</h3>
-<div class=""sourceCode"" id=""cb90""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb69""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">fanos</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/lapply.html"">vapply</a></span><span class=""op"">(</span><span class=""va"">dataset_combined</span><span class=""op"">$</span><span class=""va"">generated</span>, <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">dataset</span><span class=""op"">)</span> <span class=""op"">{</span> <span class=""fu""><a href=""https://mc-stan.org/posterior/reference/rvar-summaries-over-draws.html"">var</a></span><span class=""op"">(</span><span class=""va"">dataset</span><span class=""op"">$</span><span class=""va"">y</span><span class=""op"">)</span> <span class=""op"">/</span> <span class=""fu""><a href=""https://rdrr.io/r/base/mean.html"">mean</a></span><span class=""op"">(</span><span class=""va"">dataset</span><span class=""op"">$</span><span class=""va"">y</span><span class=""op"">)</span> <span class=""op"">}</span>, FUN.VALUE <span class=""op"">=</span> <span class=""fl"">0</span><span class=""op"">)</span>
 <span class=""fu""><a href=""https://rdrr.io/r/graphics/plot.default.html"">plot</a></span><span class=""op"">(</span><span class=""va"">fanos</span>, <span class=""va"">results_combined</span><span class=""op"">$</span><span class=""va"">backend_diagnostics</span><span class=""op"">$</span><span class=""va"">n_divergent</span><span class=""op"">)</span></code></pre></div>
-<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-46-1.png"" width=""700""></p>
-<div class=""sourceCode"" id=""cb91""><pre class=""downlit sourceCode r"">
+<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-48-1.png"" width=""700""></p>
+<div class=""sourceCode"" id=""cb70""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/r/graphics/hist.html"">hist</a></span><span class=""op"">(</span><span class=""va"">fanos</span><span class=""op"">[</span><span class=""va"">results_combined</span><span class=""op"">$</span><span class=""va"">backend_diagnostics</span><span class=""op"">$</span><span class=""va"">n_divergent</span> <span class=""op"">&gt;</span> <span class=""fl"">0</span><span class=""op"">]</span><span class=""op"">)</span></code></pre></div>
-<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-46-2.png"" width=""700""></p>
-<div class=""sourceCode"" id=""cb92""><pre class=""downlit sourceCode r"">
+<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-48-2.png"" width=""700""></p>
+<div class=""sourceCode"" id=""cb71""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">generator_func_combined_reject</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">N_obs</span>, <span class=""va"">N_predictors</span><span class=""op"">)</span> <span class=""op"">{</span>
   <span class=""kw"">if</span><span class=""op"">(</span><span class=""va"">N_obs</span> <span class=""op"">&lt;</span> <span class=""fl"">5</span><span class=""op"">)</span> <span class=""op"">{</span>
     <span class=""kw""><a href=""https://rdrr.io/r/base/stop.html"">stop</a></span><span class=""op"">(</span><span class=""st"">""Too low N_obs for this simulator""</span><span class=""op"">)</span>
@@ -702,32 +725,30 @@ <h3 class=""hasAnchor"">
 <span class=""op"">}</span>
 
 <span class=""va"">generator_combined_reject</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/SBC_generator_function.html"">SBC_generator_function</a></span><span class=""op"">(</span><span class=""va"">generator_func_combined_reject</span>, N_obs <span class=""op"">=</span> <span class=""fl"">50</span>, N_predictors <span class=""op"">=</span> <span class=""fl"">3</span><span class=""op"">)</span></code></pre></div>
-<div class=""sourceCode"" id=""cb93""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb72""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/r/base/Random.html"">set.seed</a></span><span class=""op"">(</span><span class=""fl"">44685226</span><span class=""op"">)</span>
 <span class=""va"">dataset_combined_reject</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/generate_datasets.html"">generate_datasets</a></span><span class=""op"">(</span><span class=""va"">generator_combined_reject</span>, <span class=""fl"">200</span><span class=""op"">)</span></code></pre></div>
-<div class=""sourceCode"" id=""cb94""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span class=""va"">results_combined_reject</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">dataset_combined_reject</span>, <span class=""va"">backend_combined</span><span class=""op"">)</span></code></pre></div>
-<pre><code>##  - 1 (0%) fits had some steps rejected. Maximum number of rejections was 2.</code></pre>
-<pre><code>## Not all diagnostics are OK. You can learn more by inspecting $default_diagnostics, $backend_diagnostics and/or investigating $outputs/$messages/$warnings for detailed output from the backend.</code></pre>
-<div class=""sourceCode"" id=""cb97""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb73""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""va"">results_combined_reject</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">dataset_combined_reject</span>, <span class=""va"">backend_combined</span>, 
+                    cache_mode <span class=""op"">=</span> <span class=""st"">""results""</span>, 
+                    cache_location <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/file.path.html"">file.path</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span>, <span class=""st"">""combined_reject""</span><span class=""op"">)</span><span class=""op"">)</span></code></pre></div>
+<pre><code>## Results loaded from cache file 'combined_reject'</code></pre>
+<div class=""sourceCode"" id=""cb75""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""../reference/plot_ecdf.html"">plot_ecdf_diff</a></span><span class=""op"">(</span><span class=""va"">results_combined_reject</span><span class=""op"">)</span></code></pre></div>
-<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-50-1.png"" width=""700""></p>
-<div class=""sourceCode"" id=""cb98""><pre class=""downlit sourceCode r"">
+<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-52-1.png"" width=""700""></p>
+<div class=""sourceCode"" id=""cb76""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/r/base/Random.html"">set.seed</a></span><span class=""op"">(</span><span class=""fl"">1395367854</span><span class=""op"">)</span>
 <span class=""va"">dataset_combined_reject_more</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/generate_datasets.html"">generate_datasets</a></span><span class=""op"">(</span><span class=""va"">generator_combined_reject</span>, <span class=""fl"">300</span><span class=""op"">)</span> 
 <span class=""va"">results_combined_reject_more</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""../reference/bind_results.html"">bind_results</a></span><span class=""op"">(</span>
   <span class=""va"">results_combined_reject</span>,
-  <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">dataset_combined_reject_more</span>, <span class=""va"">backend_combined</span><span class=""op"">)</span>
+  <span class=""fu""><a href=""../reference/compute_results.html"">compute_results</a></span><span class=""op"">(</span><span class=""va"">dataset_combined_reject_more</span>, <span class=""va"">backend_combined</span>, 
+                    cache_mode <span class=""op"">=</span> <span class=""st"">""results""</span>, 
+                    cache_location <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/file.path.html"">file.path</a></span><span class=""op"">(</span><span class=""va"">cache_dir</span>, <span class=""st"">""combined_reject_more""</span><span class=""op"">)</span><span class=""op"">)</span>
 <span class=""op"">)</span></code></pre></div>
-<pre><code>##  - 2 (1%) fits had at least one Rhat &gt; 1.01. Largest Rhat was 1.093.</code></pre>
-<pre><code>##  - 2 (1%) fits had tail ESS undefined or less than half of the maximum rank, potentially skewing the rank statistics. The lowest tail ESS was NA.
-##  If the fits look good otherwise, increasing `thin_ranks` (via recompute_statistcs) or number of posterior samples (by refitting) might help.</code></pre>
-<pre><code>##  - 2 (1%) fits had divergent transitions. Maximum number of divergences was 119.</code></pre>
-<pre><code>##  - 3 (1%) fits had some steps rejected. Maximum number of rejections was 2.</code></pre>
-<pre><code>## Not all diagnostics are OK. You can learn more by inspecting $default_diagnostics, $backend_diagnostics and/or investigating $outputs/$messages/$warnings for detailed output from the backend.</code></pre>
-<div class=""sourceCode"" id=""cb104""><pre class=""downlit sourceCode r"">
+<pre><code>## Results loaded from cache file 'combined_reject_more'</code></pre>
+<div class=""sourceCode"" id=""cb78""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""../reference/plot_ecdf.html"">plot_ecdf_diff</a></span><span class=""op"">(</span><span class=""va"">results_combined_reject_more</span><span class=""op"">)</span></code></pre></div>
-<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-51-1.png"" width=""700""></p>
+<p><img src=""small_model_workflow_files/figure-html/unnamed-chunk-53-1.png"" width=""700""></p>
 </div>
 </div>
   </div>

---FILE: tests/testthat/test-integration.R---
@@ -64,7 +64,7 @@ test_that(""Result caching"", {
   # Change datasets
   datasets_changed <- datasets
   datasets_changed[[3]] <- ""a""
-  expect_warning(
+  expect_message(
     compute_results(datasets_changed, backend, thin_ranks = 1, cache_mode = ""results"", cache_location = cache_file),
     ""datasets.*differ.*recompute""
     )
@@ -78,7 +78,7 @@ test_that(""Result caching"", {
   # Change backend
   backend_changed <- backend
   backend_changed$result[5, ""a""] <- 0
-  expect_warning(
+  expect_message(
     compute_results(datasets_changed, backend_changed, thin_ranks = 1, cache_mode = ""results"", cache_location = cache_file),
     ""backend.*differ.*recompute""
   )

---FILE: vignettes/rejection_sampling.Rmd---
@@ -36,6 +36,12 @@ plan(multisession)
 
 options(SBC.min_chunk_size = 10)
 
+# Setup caching of results
+cache_dir <- ""./rejection_sampling_SBC_cache""
+if(!dir.exists(cache_dir)) {
+  dir.create(cache_dir)
+}
+
 ```
 
 
@@ -85,7 +91,9 @@ datasets <- generate_datasets(generator, 1000)
 ```
 
 ```{r}
-results <- compute_results(datasets, backend, keep_fits = FALSE)
+results <- compute_results(datasets, backend, keep_fits = FALSE, 
+                    cache_mode = ""results"", 
+                    cache_location = file.path(cache_dir, ""no_rejections""))
 ```
 
 ```{r}
@@ -122,7 +130,9 @@ datasets_reject_param <- generate_datasets(generator_reject_param, 200)
 ```
 
 ```{r}
-results_reject_param <- compute_results(datasets_reject_param, backend, keep_fits = FALSE)
+results_reject_param <- compute_results(datasets_reject_param, backend, keep_fits = FALSE, 
+                    cache_mode = ""results"", 
+                    cache_location = file.path(cache_dir, ""reject_param""))
 ```
 
 ```{r}
@@ -160,7 +170,9 @@ datasets_reject_y <- generate_datasets(generator_reject_y, 1000)
 ```
 
 ```{r}
-results_reject_y <- compute_results(datasets_reject_y, backend, keep_fits = FALSE)
+results_reject_y <- compute_results(datasets_reject_y, backend, keep_fits = FALSE, 
+                    cache_mode = ""results"", 
+                    cache_location = file.path(cache_dir, ""reject_y""))
 ```
 
 ```{r}

---FILE: vignettes/small_model_workflow.Rmd---
@@ -1,21 +1,74 @@
 ---
-title: ""Small model workflow""
-output: html_notebook
+title: ""Building a small model""
+author: ""Martin Modrák""
+date: ""`r Sys.Date()`""
+output: 
+  rmarkdown::html_vignette:
+    toc: yes
+vignette: >
+  %\VignetteIndexEntry{Building a small model}
+  %\VignetteEngine{knitr::rmarkdown}
+  \usepackage[utf8]{inputenc}
 ---
 
-Workflow for small models - the texts are still somewhat incomplete.
-
-""Small"" means that the model is fast to fit and we don't have to worry about computation too much.
+Here we describe a complete process to iteratively build and validate the _implementation_ 
+of a non-trivial, but still relatively small model. 
+This is not a full [Bayesian Workflow](https://arxiv.org/abs/2011.01808), instead
+the process described here can be thought of as a subroutine in the full workflow:
+here we take a relatively precise description of a model as input and try to produce
+a Stan program that implements this model. Once we have a Stan program we trust, 
+it is still necessary to validate its fit to actual data and other properties,
+which may trigger a need to change the model. At this point you may want to
+go back to simulations and make sure the modified model is implemented correctly.
+
+The workflow described here focuses on small models. 
+""Small"" means that the model is relatively fast to fit and we don't have to worry about computation too much.
 Once running ~100 fits of the model becomes too costly, there are additional tricks and considerations
-that we hope to delve into in a ""Complex model workflow"" vignette (which currently doesn't exist).
-
+that we hope to delve into in a ""Building a complex model"" vignette (which currently doesn't exist).
 Still many of the approaches here also apply to complex models (especially starting small and building each component separately)
 
+We expect the reader to be familiar with basics of the package. If not,
+check out the ""basic_usage"" vignette.
+
+## Our goal
+
+The example we'll investigate is building a two-component Poisson mixture,
+where the mixing ratio is allowed to vary with some predictors while the means
+of the components are the same for all observations.  
+A somewhat contrived real world situation where this could arise would be that
+we observe the number of daily calls to a support team from a factory, where we know 
+that the only determinant of the number of calls is whether manager A or manager
+B is in charge that day in the factory. We don't directly observe which manager is 
+in charge, but observe some covariates that we expect to predict the presence of either
+manager.
+
+## Big picture
+
+This model naturally decomposes into two components: 
+
+1) the mixture component where the mixing ratio is the same
+for all variables
+
+2) a beta regression where we take covariates and make a prediction of a probability,
+assuming we (noisily) observe the probability.
+
+It is good practice to start small and implement and validate each of those 
+components separately and then put them together and validate the bigger model.
+This makes is substantially easier to locate bugs. 
+You'll notice that the process ends up involving a lot of steps, 
+but the fact is that we still ignore all the completely invalid models (typos, compile errors, dimension mismatches, ...). Developing models you
+can trust is hard work. More experienced users can definitely make bigger steps at once,
+but we strongly discourage anyone from writing a big model in one go. 
+My experience is that whenever I try to do this, the model breaks, is impossible
+to debug and then I end up breaking it down anyway.
+
+Let's setup and get our hands dirty:
+
 ```{r setup, message=FALSE,warning=FALSE, results=""hide""}
 library(SBC)
 
-# use_cmdstanr <- TRUE # Set to false to use rstan instead
-# 
+use_cmdstanr <- TRUE # Set to false to use rstan instead
+
 # if(use_cmdstanr) {
 #   library(cmdstanr)
 # } else {
@@ -30,13 +83,21 @@ plan(multisession)
 
 options(SBC.min_chunk_size = 5)
 
+# Setup caching of results
+cache_dir <- ""./small_model_worklow_SBC_cache""
+if(!dir.exists(cache_dir)) {
+  dir.create(cache_dir)
+}
+
 ```
 
-- Mixture with predictors for ratios
+## Mixture component
+
 
-A lot of steps, but I still ignore all the completely invalid models (typos, compile errors, dimension mismatches, ...)
+```{r, echo = FALSE, comment = """"}
+cat(readLines(""small_model_workflow/mixture_first.stan""), sep = ""\n"")
+```
 
-## Mixture component
 
 ```{r}
 model_first <- cmdstan_model(""small_model_workflow/mixture_first.stan"")
@@ -80,7 +141,9 @@ datasets_first <- generate_datasets(generator_first, 1)
 ```
 
 ```{r}
-results_first <- compute_results(datasets_first, backend_first)
+results_first <- compute_results(datasets_first, backend_first, 
+                    cache_mode = ""results"", 
+                    cache_location = file.path(cache_dir, ""mixture_first""))
 ```
 
 We have convergence problems, let us examine the pairs plots
@@ -96,28 +159,39 @@ This might be puzzling but relates to bad usage of `log_mix` (TODO explain)
 
 ### Fixing mixture
 
+```{r, echo = FALSE, comment = """", results ='asis'}
+cat(readLines(""small_model_workflow/mixture_fixed_log_mix.stan""), sep = ""\n"")
+```
+
 ```{r}
 model_fixed_log_mix <- cmdstan_model(""small_model_workflow/mixture_fixed_log_mix.stan"")
 backend_fixed_log_mix <- SBC_backend_cmdstan_sample(model_fixed_log_mix)
 ```
 
 ```{r}
-results_fixed_log_mix <- compute_results(datasets_first, backend_fixed_log_mix)
+results_fixed_log_mix <- compute_results(datasets_first, backend_fixed_log_mix, 
+                    cache_mode = ""results"", 
+                    cache_location = file.path(cache_dir, ""mixture_fixed_log_mix""))
 ```
 
 We see nothing obviously wrong, let's run a few more iterations.
 
 ```{r}
 results_fixed_log_mix$stats
 ```
+
+
 ```{r}
 set.seed(8314566)
 datasets_first_10 <- generate_datasets(generator_first, 10)
 ```
 
 ```{r}
-results_fixed_log_mix_2 <- compute_results(datasets_first_10, backend_fixed_log_mix)
+results_fixed_log_mix_2 <- compute_results(datasets_first_10, backend_fixed_log_mix, 
+                    cache_mode = ""results"", 
+                    cache_location = file.path(cache_dir, ""mixture_fixed_log_mix_2""))
 ```
+
 So there are some problems.
 
 ```{r}
@@ -184,7 +258,9 @@ datasets_ordered_10 <- generate_datasets(generator_ordered, 10)
 
 
 ```{r}
-results_fixed_ordered <- compute_results(datasets_ordered_10, backend_fixed_ordered)
+results_fixed_ordered <- compute_results(datasets_ordered_10, backend_fixed_ordered, 
+                    cache_mode = ""results"", 
+                    cache_location = file.path(cache_dir, ""mixture_fixed_ordered""))
 ```
 
 
@@ -239,8 +315,11 @@ plot_ecdf_diff(results_fixed_ordered_subset)
 So we can run for more iterations:
 
 ```{r}
+set.seed(54987622)
 datasets_ordered_100 <- generate_datasets(generator_ordered, 100)
-results_fixed_ordered_100 <- compute_results(datasets_ordered_100, backend_fixed_ordered)
+results_fixed_ordered_100 <- compute_results(datasets_ordered_100, backend_fixed_ordered, 
+                    cache_mode = ""results"", 
+                    cache_location = file.path(cache_dir, ""mixture_fixed_ordered_100""))
 ```
 
 Once again we subset to keep only non-divergent fits
@@ -329,7 +408,9 @@ datasets_beta_first <- generate_datasets(generator_beta_first, 10)
 
 
 ```{r}
-results_beta_first_10 <- compute_results(datasets_beta_first, backend_beta_first)
+results_beta_first_10 <- compute_results(datasets_beta_first, backend_beta_first, 
+                    cache_mode = ""results"", 
+                    cache_location = file.path(cache_dir, ""beta_first_10""))
 ```
 ```{r}
 plot_ecdf_diff(results_beta_first_10)
@@ -416,19 +497,24 @@ datasets_beta_precision_10 <- generate_datasets(generator_beta_precision, 10)
 
 
 ```{r}
-results_beta_precision_10 <- compute_results(datasets_beta_precision_10, backend_beta_precision)
+results_beta_precision_10 <- compute_results(datasets_beta_precision_10, backend_beta_precision, 
+                    cache_mode = ""results"", 
+                    cache_location = file.path(cache_dir, ""beta_precision_10""))
 ```
 
 ```{r}
 plot_ecdf_diff(results_beta_precision_10)
 ```
 
 ```{r}
+set.seed(2136468)
 datasets_beta_precision_90 <- generate_datasets(generator_beta_precision, 90)
 results_beta_precision_100 <-
   bind_results(
     results_beta_precision_10,
-    compute_results(datasets_beta_precision_90, backend_beta_precision))
+    compute_results(datasets_beta_precision_90, backend_beta_precision, 
+                    cache_mode = ""results"", 
+                    cache_location = file.path(cache_dir, ""beta_precision_90"")))
 
 datasets_beta_precision_100 <- bind_datasets(datasets_beta_precision_10, datasets_beta_precision_90)
 plot_ecdf_diff(results_beta_precision_100)
@@ -447,17 +533,23 @@ backend_beta_precision_fixed_prior <- SBC_backend_cmdstan_sample(model_beta_prec
 
 ```
 ```{r}
-results_beta_precision_fixed_prior <- compute_results(datasets_beta_precision_100, backend_beta_precision_fixed_prior)
+results_beta_precision_fixed_prior <- 
+  compute_results(datasets_beta_precision_100, backend_beta_precision_fixed_prior, 
+                    cache_mode = ""results"", 
+                    cache_location = file.path(cache_dir, ""beta_precision_fixed_prior""))
 
 plot_ecdf_diff(results_beta_precision_fixed_prior)
 ```
 
 ```{r}
+set.seed(1233845)
 datasets_beta_precision_100b <- generate_datasets(generator_beta_precision, 100)
 results_beta_precision_fixed_prior_200 <-
   bind_results(
     results_beta_precision_fixed_prior,
-    compute_results(datasets_beta_precision_100b, backend_beta_precision_fixed_prior))
+    compute_results(datasets_beta_precision_100b, backend_beta_precision_fixed_prior, 
+                    cache_mode = ""results"", 
+                    cache_location = file.path(cache_dir, ""beta_precision_fixed_prior_2"")))
 
 plot_ecdf_diff(results_beta_precision_fixed_prior_200)
 
@@ -526,7 +618,9 @@ dataset_combined <- generate_datasets(generator_combined, 200)
 ```
 
 ```{r}
-results_combined <- compute_results(dataset_combined, backend_combined)
+results_combined <- compute_results(dataset_combined, backend_combined, 
+                    cache_mode = ""results"", 
+                    cache_location = file.path(cache_dir, ""combined""))
 ```
 
 ```{r}
@@ -604,7 +698,9 @@ dataset_combined_reject <- generate_datasets(generator_combined_reject, 200)
 
 
 ```{r}
-results_combined_reject <- compute_results(dataset_combined_reject, backend_combined)
+results_combined_reject <- compute_results(dataset_combined_reject, backend_combined, 
+                    cache_mode = ""results"", 
+                    cache_location = file.path(cache_dir, ""combined_reject""))
 ```
 
 ```{r}
@@ -617,7 +713,9 @@ set.seed(1395367854)
 dataset_combined_reject_more <- generate_datasets(generator_combined_reject, 300) 
 results_combined_reject_more <- bind_results(
   results_combined_reject,
-  compute_results(dataset_combined_reject_more, backend_combined)
+  compute_results(dataset_combined_reject_more, backend_combined, 
+                    cache_mode = ""results"", 
+                    cache_location = file.path(cache_dir, ""combined_reject_more""))
 )
 
 plot_ecdf_diff(results_combined_reject_more)",True,True,Rendering / Conversion,6
hyunjimoon,SBC,95921fbaa5ae343d44a8c99a6f3ed41349a21446,martinmodrak,modrak.mar@gmail.com,2021-09-15T15:31:39Z,martinmodrak,modrak.mar@gmail.com,2021-09-15T15:31:39Z,Fix test failure,tests/testthat/test-results.R,False,True,True,False,4,4,8,"---FILE: tests/testthat/test-results.R---
@@ -94,10 +94,10 @@ test_that(""calculate_sds_draws_matrix"", {
 
 test_that(""statistics_from_single_fit"", {
     params <- posterior::as_draws_matrix(
-        posterior::as_draws_rvars(list(
-            mu = 4,
-            tau = 4,
-            theta = seq(3.5, 6.5, length.out = 8))))
+        posterior::draws_rvars(
+            mu = posterior::rvar(4) ,
+            tau = posterior::rvar(4),
+            theta = posterior::rvar(array(seq(3.5, 6.5, length.out = 8), dim = c(1,8)))))
 
     # Can't really check correctness, only
     # testing that no error is thrown and structure is OK",True,False,Implementation / Logic,3
hyunjimoon,SBC,57fe9745583d3e62de2b04d0d9e6128867564aff,martinmodrak,modrak.mar@gmail.com,2021-09-11T20:29:01Z,martinmodrak,modrak.mar@gmail.com,2021-09-11T20:29:01Z,"Fixed bugs in naming datasets, require brms 2.16.1 +",R/backends.R;R/datasets.R;R/util.R;tests/testthat/test-datasets.R,False,True,True,False,42,12,54,"---FILE: R/backends.R---
@@ -228,15 +228,7 @@ print.SBC_nuts_diagnostics_summary <- function(x) {
 #'   package.
 #' @export
 SBC_backend_cmdstan_sample <- function(model, ...) {
-  if(!requireNamespace(""cmdstanr"", quietly = TRUE)) {
-    stop(""Using cmdstan backend requires the 'cmdstanr' package"")
-  }
-  # Cannot use `versionCheck` of `requireNamespace` as that doesn't work when
-  # the package is already loaded. Note that `packageVersion` and `package_version`
-  # are completely different methods
-  if(packageVersion(""cmdstanr"") < package_version(""0.4.0"")) {
-    stop(""SBC requires cmdstanr version >= 0.4.0, please update your cmdstanr."")
-  }
+  require_cmdstanr_version(""cmdstan backend"")
 
   stopifnot(inherits(model, ""CmdStanModel""))
   if(length(model$exe_file()) == 0) {
@@ -297,6 +289,8 @@ SBC_fit_to_diagnostics.CmdStanMCMC <- function(fit, fit_output, fit_messages, fi
 #'   package.
 #' @export
 SBC_backend_cmdstan_variational <- function(model, ...) {
+  require_cmdstanr_version(""cmdstan backend"")
+
   stopifnot(inherits(model, ""CmdStanModel""))
   if(length(model$exe_file()) == 0) {
     stop(""The model has to be already compiled, call $compile() first."")
@@ -331,10 +325,12 @@ SBC_fit_to_draws_matrix.CmdStanVB <- function(fit) {
 
 }
 
+
 # For internal use, creates brms backend.
 new_SBC_backend_brms <- function(compiled_model,
   args
 ) {
+  require_brms_version(""brms backend"")
 
   arg_names_for_stan <- c(""chains"", ""inits"", ""iter"", ""warmup"", ""thin"")
   args_for_stan <- args[intersect(names(args), arg_names_for_stan)]

---FILE: R/datasets.R---
@@ -135,11 +135,21 @@ generate_datasets.SBC_generator_function <- function(generator, n_datasets) {
       }
     }
 
+    guess_dimnames <- function(x) {
+      if(!is.null(dimnames(x))) {
+        dimnames(x)
+      } else if(!is.null(names(x))) {
+        list(names(x))
+      } else {
+        NULL
+      }
+    }
+
     params_rvars <-
       do.call(
       posterior::draws_rvars,
       purrr::map(generator_output$parameters,
-                 ~ posterior::rvar(array(.x, dim = c(1, guess_dims(.x))))
+                 ~ posterior::rvar(array(.x, dim = c(1, guess_dims(.x))), dimnames = guess_dimnames(.x))
                  )
       )
     parameters_list[[iter]] <- posterior::as_draws_matrix(params_rvars)
@@ -208,6 +218,8 @@ generate_datasets.SBC_generator_custom <- function(generator, n_datasets) {
 #' but improves sensitivity of the SBC process.
 #' @export
 SBC_generator_brms <- function(..., generate_lp = TRUE) {
+  require_brms_version(""brms generator"")
+
   model_data <- brms::make_standata(..., sample_prior = ""only"")
   class(model_data) <- NULL
 
@@ -318,7 +330,7 @@ generate_datasets.SBC_generator_brms <- function(generator, n_datasets) {
 
     ## Compute the likelihoods (observation model)
     if(generator$generate_lp) {
-      ll <- log_lik(prior_fit_brms, newdata = new_dataset, subset = i, cores = 1)
+      ll <- log_lik(prior_fit_brms, newdata = new_dataset, draw_ids = i, cores = 1)
       log_likelihoods[i] <- sum(ll)
     }
   }

---FILE: R/util.R---
@@ -22,3 +22,24 @@ SBC_error <- function(subclass, message, call = sys.call(-1), ...) {
     ...
   )
 }
+
+
+require_package_version <- function(package, version, purpose) {
+  if(!requireNamespace(package, quietly = TRUE)) {
+    stop(paste0(""Using "", purpose, "" requires the '"", package, ""' package""))
+  }
+  # Cannot use `versionCheck` of `requireNamespace` as that doesn't work when
+  # the package is already loaded. Note that `packageVersion` and `package_version`
+  # are completely different methods
+  if(packageVersion(package) < package_version(version)) {
+    stop(paste0(""SBC requires "", package, "" version >= "", version, "", please update to use SBC.""))
+  }
+}
+
+require_brms_version <- function(purpose) {
+  require_package_version(""brms"", ""2.16.1"", purpose)
+}
+
+require_cmdstanr_version <- function(purpose) {
+  require_package_version(""cmdstanr"", ""0.4.0"", purpose)
+}

---FILE: tests/testthat/test-datasets.R---
@@ -5,6 +5,7 @@ test_that(""Generating datasets via functions"", {
     beta <- matrix(1:6, nrow = 3, ncol = 2)
     gamma <- array(1:12, dim = c(2,3,2))
     delta <- rnorm(3)
+    names(delta) <- LETTERS[1:3]
     y1 <- rnorm(N, mu, sigma)
     y2 <- rnorm(2 * N, mu + 5, sigma)
     list(parameters = list(mu = mu, sigma = sigma, beta = beta, gamma = gamma, delta = delta),
@@ -20,7 +21,7 @@ test_that(""Generating datasets via functions"", {
   beta_vars <- paste0(""beta["", rep(1:3, times = 2), "","", rep(1:2, each = 3), ""]"")
   gamma_vars <- paste0(""gamma["", rep(1:2, times = 6), "","", rep(rep(1:3, each = 2), times = 2),
                        "","", rep(1:2, each = 6), ""]"")
-  delta_vars <- paste0(""delta["",1:3,""]"")
+  delta_vars <- paste0(""delta["",LETTERS[1:3],""]"")
   expect_identical(posterior::variables(res$parameters), c(""mu"", ""sigma"", beta_vars, gamma_vars, delta_vars))
   expect_identical(names(res$generated[[1]]), c(""y1"", ""y2""))
 ",True,False,Implementation / Logic,6
hyunjimoon,SBC,8546fe5c61fc188ae621b40b3fcf57c49474a035,hyunjimoon,mhj1667@gmail.com,2021-09-07T09:27:51Z,hyunjimoon,mhj1667@gmail.com,2021-09-07T09:27:51Z,"Revert ""address variational backend issue 35""

This reverts commit 5d5b3410e580f19e7eaa119ba9974f517b303e00.",NAMESPACE;R/.Rapp.history;R/backends.R;R/results.R;man/SBC_backend_cmdstan_optimize.Rd;man/compute_results.Rd,False,True,True,False,68,8,76,"---FILE: NAMESPACE---
@@ -3,6 +3,7 @@
 S3method(""["",SBC_datasets)
 S3method(""["",SBC_results)
 S3method(SBC_fit,SBC_backend_brms)
+S3method(SBC_fit,SBC_backend_cmdstan_optimize)
 S3method(SBC_fit,SBC_backend_cmdstan_sample)
 S3method(SBC_fit,SBC_backend_cmdstan_variational)
 S3method(SBC_fit,SBC_backend_rstan_sample)
@@ -11,6 +12,7 @@ S3method(SBC_fit_to_diagnostics,brmsfit)
 S3method(SBC_fit_to_diagnostics,default)
 S3method(SBC_fit_to_diagnostics,stanfit)
 S3method(SBC_fit_to_draws_matrix,CmdStanMCMC)
+S3method(SBC_fit_to_draws_matrix,CmdStanMLE)
 S3method(SBC_fit_to_draws_matrix,CmdStanVB)
 S3method(SBC_fit_to_draws_matrix,brmsfit)
 S3method(SBC_fit_to_draws_matrix,default)
@@ -35,6 +37,7 @@ S3method(summary,SBC_nuts_diagnostics)
 S3method(summary,SBC_results)
 export(SBC_backend_brms)
 export(SBC_backend_brms_from_generator)
+export(SBC_backend_cmdstan_optimize)
 export(SBC_backend_cmdstan_sample)
 export(SBC_backend_cmdstan_variational)
 export(SBC_backend_rstan_sample)

---FILE: R/backends.R---
@@ -280,7 +280,7 @@ SBC_backend_cmdstan_variational <- function(model, ...) {
     stop(""The model has to be already compiled, call $compile() first."")
   }
   args <- list(...)
-  unacceptable_params <- c(""data"")
+  unacceptable_params <- c(""data"", ""parallel_chains "", ""cores"", ""num_cores"")
   if(any(names(args) %in% unacceptable_params)) {
     stop(paste0(""Parameters "", paste0(""'"", unacceptable_params, ""'"", collapse = "", ""),
                 "" cannot be provided when defining a backend as they need to be set "",
@@ -297,7 +297,7 @@ SBC_fit.SBC_backend_cmdstan_variational <- function(backend, generated, cores) {
                                 data = generated)))
 
   if(all(fit$return_codes() != 0)) {
-    stop(""Variational inference did not finish succesfully"")
+    stop(""No chains finished succesfully"")
   }
 
   fit
@@ -309,6 +309,45 @@ SBC_fit_to_draws_matrix.CmdStanVB <- function(fit) {
 
 }
 
+#' Backend based on optimize approximation via `cmdstanr`.
+#'
+#' @param model an object of class `CmdStanModel` (as created by `cmdstanr::cmdstan_model`)
+#' @param ... other arguments passed to the `$optimize()` method of the model. The `data` and
+#'   `parallel_chains` arguments cannot be set this way as they need to be controlled by the SBC
+#'   package.
+#' @export
+SBC_backend_cmdstan_optimize <- function(model, ...) {
+  stop(""The optimize method is currently not supported."")
+  stopifnot(inherits(model, ""CmdStanModel""))
+  if(length(model$exe_file()) == 0) {
+    stop(""The model has to be already compiled, call $compile() first."")
+  }
+  args <- list(...)
+  unacceptable_params <- c(""data"")
+  if(any(names(args) %in% unacceptable_params)) {
+    stop(paste0(""Parameters "", paste0(""'"", unacceptable_params, ""'"", collapse = "", ""),
+                "" cannot be provided when defining a backend as they need to be set "",
+                ""by the SBC package""))
+  }
+  structure(list(model = model, args = args), class = ""SBC_backend_cmdstan_optimize"")
+}
+#' @export
+SBC_fit.SBC_backend_cmdstan_optimize <- function(backend, generated, cores) {
+  fit <- do.call(backend$model$optimize,
+                 combine_args(backend$args,
+                              list(data = generated)))
+
+   if(all(fit$return_codes() != 0)) {
+     stop(""Point optimization failed!"")
+   }
+
+   fit
+}
+#' @export
+SBC_fit_to_draws_matrix.CmdStanMLE <- function(fit) {
+  fit$draws(format = ""draws_matrix"")
+}
+
 # For internal use, creates brms backend.
 new_SBC_backend_brms <- function(compiled_model,
   args

---FILE: R/results.R---
@@ -212,13 +212,13 @@ length.SBC_results <- function(x) {
 #'
 #' Parallel processing is supported via the `future` package, for most uses, it is most sensible
 #'  to just call `plan(multisession)` once in your R session and  all
-#'  cores your computer will be used. For more details refer to the documentation
+#'  cores your computer has will be used. For more details refer to the documentation
 #'  of the `future` package.
 #'
 #' @param datasets an object of class `SBC_datasets`
 #' @param backend the model + sampling algorithm. The built-in backends can be constructed
-#'   using `SBC_backend_cmdstan_sample()`, `SBC_backend_cmdstan_variational()`, `SBC_backend_rstan_sample()` and `SBC_backend_brms()`.
-#'   (more to come: issue 31, 38, 39). The backend is an S3 class supporting at least the `SBC_fit`,
+#'   using `SBC_backend_cmdstan_sample()`, `SBC_backend_cmdstan_variational()`,`SBC_backend_cmdstan_optimize()`, `SBC_backend_rstan_sample()` and `SBC_backend_brms()`.
+#'   (more to come). The backend is an S3 class supporting at least the `SBC_fit`,
 #'   `SBC_fit_to_draws_matrix` methods.
 #' @param cores_per_fit how many cores should the backend be allowed to use for a single fit?
 #'    Defaults to the maximum number that does not produce more parallel chains

---FILE: man/SBC_backend_cmdstan_optimize.Rd---
@@ -0,0 +1,18 @@
+% Generated by roxygen2: do not edit by hand
+% Please edit documentation in R/backends.R
+\name{SBC_backend_cmdstan_optimize}
+\alias{SBC_backend_cmdstan_optimize}
+\title{Backend based on optimize approximation via \code{cmdstanr}.}
+\usage{
+SBC_backend_cmdstan_optimize(model, ...)
+}
+\arguments{
+\item{model}{an object of class \code{CmdStanModel} (as created by \code{cmdstanr::cmdstan_model})}
+
+\item{...}{other arguments passed to the \verb{$optimize()} method of the model. The \code{data} and
+\code{parallel_chains} arguments cannot be set this way as they need to be controlled by the SBC
+package.}
+}
+\description{
+Backend based on optimize approximation via \code{cmdstanr}.
+}

---FILE: man/compute_results.Rd---
@@ -18,8 +18,8 @@ compute_results(
 \item{datasets}{an object of class \code{SBC_datasets}}
 
 \item{backend}{the model + sampling algorithm. The built-in backends can be constructed
-using \code{SBC_backend_cmdstan_sample()}, \code{SBC_backend_cmdstan_variational()}, \code{SBC_backend_rstan_sample()} and \code{SBC_backend_brms()}.
-(more to come: issue 31, 38, 39). The backend is an S3 class supporting at least the \code{SBC_fit},
+using \code{SBC_backend_cmdstan_sample()}, \code{SBC_backend_cmdstan_variational()},\code{SBC_backend_cmdstan_optimize()}, \code{SBC_backend_rstan_sample()} and \code{SBC_backend_brms()}.
+(more to come). The backend is an S3 class supporting at least the \code{SBC_fit},
 \code{SBC_fit_to_draws_matrix} methods.}
 
 \item{cores_per_fit}{how many cores should the backend be allowed to use for a single fit?
@@ -60,6 +60,6 @@ An object of class \code{SBC_results} that holds:
 \description{
 Parallel processing is supported via the \code{future} package, for most uses, it is most sensible
 to just call \code{plan(multisession)} once in your R session and  all
-cores your computer will be used. For more details refer to the documentation
+cores your computer has will be used. For more details refer to the documentation
 of the \code{future} package.
 }",True,False,Documentation / Formatting,6
hyunjimoon,SBC,5d5b3410e580f19e7eaa119ba9974f517b303e00,hyunjimoon,mhj1667@gmail.com,2021-09-07T09:27:05Z,hyunjimoon,mhj1667@gmail.com,2021-09-07T09:27:05Z,address variational backend issue 35,NAMESPACE;R/.Rapp.history;R/backends.R;R/results.R;man/SBC_backend_cmdstan_optimize.Rd;man/compute_results.Rd,False,True,True,False,8,68,76,"---FILE: NAMESPACE---
@@ -3,7 +3,6 @@
 S3method(""["",SBC_datasets)
 S3method(""["",SBC_results)
 S3method(SBC_fit,SBC_backend_brms)
-S3method(SBC_fit,SBC_backend_cmdstan_optimize)
 S3method(SBC_fit,SBC_backend_cmdstan_sample)
 S3method(SBC_fit,SBC_backend_cmdstan_variational)
 S3method(SBC_fit,SBC_backend_rstan_sample)
@@ -12,7 +11,6 @@ S3method(SBC_fit_to_diagnostics,brmsfit)
 S3method(SBC_fit_to_diagnostics,default)
 S3method(SBC_fit_to_diagnostics,stanfit)
 S3method(SBC_fit_to_draws_matrix,CmdStanMCMC)
-S3method(SBC_fit_to_draws_matrix,CmdStanMLE)
 S3method(SBC_fit_to_draws_matrix,CmdStanVB)
 S3method(SBC_fit_to_draws_matrix,brmsfit)
 S3method(SBC_fit_to_draws_matrix,default)
@@ -37,7 +35,6 @@ S3method(summary,SBC_nuts_diagnostics)
 S3method(summary,SBC_results)
 export(SBC_backend_brms)
 export(SBC_backend_brms_from_generator)
-export(SBC_backend_cmdstan_optimize)
 export(SBC_backend_cmdstan_sample)
 export(SBC_backend_cmdstan_variational)
 export(SBC_backend_rstan_sample)

---FILE: R/backends.R---
@@ -280,7 +280,7 @@ SBC_backend_cmdstan_variational <- function(model, ...) {
     stop(""The model has to be already compiled, call $compile() first."")
   }
   args <- list(...)
-  unacceptable_params <- c(""data"", ""parallel_chains "", ""cores"", ""num_cores"")
+  unacceptable_params <- c(""data"")
   if(any(names(args) %in% unacceptable_params)) {
     stop(paste0(""Parameters "", paste0(""'"", unacceptable_params, ""'"", collapse = "", ""),
                 "" cannot be provided when defining a backend as they need to be set "",
@@ -297,7 +297,7 @@ SBC_fit.SBC_backend_cmdstan_variational <- function(backend, generated, cores) {
                                 data = generated)))
 
   if(all(fit$return_codes() != 0)) {
-    stop(""No chains finished succesfully"")
+    stop(""Variational inference did not finish succesfully"")
   }
 
   fit
@@ -309,45 +309,6 @@ SBC_fit_to_draws_matrix.CmdStanVB <- function(fit) {
 
 }
 
-#' Backend based on optimize approximation via `cmdstanr`.
-#'
-#' @param model an object of class `CmdStanModel` (as created by `cmdstanr::cmdstan_model`)
-#' @param ... other arguments passed to the `$optimize()` method of the model. The `data` and
-#'   `parallel_chains` arguments cannot be set this way as they need to be controlled by the SBC
-#'   package.
-#' @export
-SBC_backend_cmdstan_optimize <- function(model, ...) {
-  stop(""The optimize method is currently not supported."")
-  stopifnot(inherits(model, ""CmdStanModel""))
-  if(length(model$exe_file()) == 0) {
-    stop(""The model has to be already compiled, call $compile() first."")
-  }
-  args <- list(...)
-  unacceptable_params <- c(""data"")
-  if(any(names(args) %in% unacceptable_params)) {
-    stop(paste0(""Parameters "", paste0(""'"", unacceptable_params, ""'"", collapse = "", ""),
-                "" cannot be provided when defining a backend as they need to be set "",
-                ""by the SBC package""))
-  }
-  structure(list(model = model, args = args), class = ""SBC_backend_cmdstan_optimize"")
-}
-#' @export
-SBC_fit.SBC_backend_cmdstan_optimize <- function(backend, generated, cores) {
-  fit <- do.call(backend$model$optimize,
-                 combine_args(backend$args,
-                              list(data = generated)))
-
-   if(all(fit$return_codes() != 0)) {
-     stop(""Point optimization failed!"")
-   }
-
-   fit
-}
-#' @export
-SBC_fit_to_draws_matrix.CmdStanMLE <- function(fit) {
-  fit$draws(format = ""draws_matrix"")
-}
-
 # For internal use, creates brms backend.
 new_SBC_backend_brms <- function(compiled_model,
   args

---FILE: R/results.R---
@@ -212,13 +212,13 @@ length.SBC_results <- function(x) {
 #'
 #' Parallel processing is supported via the `future` package, for most uses, it is most sensible
 #'  to just call `plan(multisession)` once in your R session and  all
-#'  cores your computer has will be used. For more details refer to the documentation
+#'  cores your computer will be used. For more details refer to the documentation
 #'  of the `future` package.
 #'
 #' @param datasets an object of class `SBC_datasets`
 #' @param backend the model + sampling algorithm. The built-in backends can be constructed
-#'   using `SBC_backend_cmdstan_sample()`, `SBC_backend_cmdstan_variational()`,`SBC_backend_cmdstan_optimize()`, `SBC_backend_rstan_sample()` and `SBC_backend_brms()`.
-#'   (more to come). The backend is an S3 class supporting at least the `SBC_fit`,
+#'   using `SBC_backend_cmdstan_sample()`, `SBC_backend_cmdstan_variational()`, `SBC_backend_rstan_sample()` and `SBC_backend_brms()`.
+#'   (more to come: issue 31, 38, 39). The backend is an S3 class supporting at least the `SBC_fit`,
 #'   `SBC_fit_to_draws_matrix` methods.
 #' @param cores_per_fit how many cores should the backend be allowed to use for a single fit?
 #'    Defaults to the maximum number that does not produce more parallel chains

---FILE: man/SBC_backend_cmdstan_optimize.Rd---
@@ -1,18 +0,0 @@
-% Generated by roxygen2: do not edit by hand
-% Please edit documentation in R/backends.R
-\name{SBC_backend_cmdstan_optimize}
-\alias{SBC_backend_cmdstan_optimize}
-\title{Backend based on optimize approximation via \code{cmdstanr}.}
-\usage{
-SBC_backend_cmdstan_optimize(model, ...)
-}
-\arguments{
-\item{model}{an object of class \code{CmdStanModel} (as created by \code{cmdstanr::cmdstan_model})}
-
-\item{...}{other arguments passed to the \verb{$optimize()} method of the model. The \code{data} and
-\code{parallel_chains} arguments cannot be set this way as they need to be controlled by the SBC
-package.}
-}
-\description{
-Backend based on optimize approximation via \code{cmdstanr}.
-}

---FILE: man/compute_results.Rd---
@@ -18,8 +18,8 @@ compute_results(
 \item{datasets}{an object of class \code{SBC_datasets}}
 
 \item{backend}{the model + sampling algorithm. The built-in backends can be constructed
-using \code{SBC_backend_cmdstan_sample()}, \code{SBC_backend_cmdstan_variational()},\code{SBC_backend_cmdstan_optimize()}, \code{SBC_backend_rstan_sample()} and \code{SBC_backend_brms()}.
-(more to come). The backend is an S3 class supporting at least the \code{SBC_fit},
+using \code{SBC_backend_cmdstan_sample()}, \code{SBC_backend_cmdstan_variational()}, \code{SBC_backend_rstan_sample()} and \code{SBC_backend_brms()}.
+(more to come: issue 31, 38, 39). The backend is an S3 class supporting at least the \code{SBC_fit},
 \code{SBC_fit_to_draws_matrix} methods.}
 
 \item{cores_per_fit}{how many cores should the backend be allowed to use for a single fit?
@@ -60,6 +60,6 @@ An object of class \code{SBC_results} that holds:
 \description{
 Parallel processing is supported via the \code{future} package, for most uses, it is most sensible
 to just call \code{plan(multisession)} once in your R session and  all
-cores your computer has will be used. For more details refer to the documentation
+cores your computer will be used. For more details refer to the documentation
 of the \code{future} package.
 }",True,False,Documentation / Formatting,6
hyunjimoon,SBC,841c692cac45f6aa980de73ca1090e7b2b092eaf,martinmodrak,modrak.mar@gmail.com,2021-09-07T06:16:58Z,martinmodrak,modrak.mar@gmail.com,2021-09-07T06:16:58Z,Fixed a bug with SBC_generator_function and matrices + tests,R/datasets.R;R/results.R;R/util.R;tests/testthat/test-datasets.R,False,True,True,False,67,7,74,"---FILE: R/datasets.R---
@@ -56,7 +56,7 @@ length.SBC_datasets <- function(x) {
 #' @export
 `[.SBC_datasets` <- function(x, indices) {
   validate_SBC_datasets(x)
-  new_SBC_datasets(posterior::subset_draws(x$parameters, draw = indices),
+  new_SBC_datasets(posterior::subset_draws(x$parameters, draw = indices, unique = FALSE),
                    x$generated[indices])
 }
 
@@ -109,15 +109,28 @@ generate_datasets.SBC_generator_function <- function(generator, n_datasets) {
     if(!is.list(generator_output) ||
        is.null(generator_output$parameters) ||
        is.null(generator_output$generated)) {
-      stop(""The generating function has to return a list with elements `parameters`
-      (that can be converted to `draws_rvars`) `generated`"")
+      stop(SBC_error(""SBC_datasets_error"",
+      ""The generating function has to return a list with elements `parameters`
+      (that can be converted to `draws_rvars`) `generated`""))
+    }
+
+    parnames <- names(generator_output$parameters)
+    if(is.null(parnames) || any(is.na(parnames)) ||
+       any(parnames == """") || length(unique(parnames)) != length(parnames)) {
+      stop(SBC_error(""SBC_datasets_error"", ""All elements of $parameters must have a unique name""))
     }
     # TODO add a validate_input generic that would let backends impose additional checks
     # on generated data.
 
     # Directly converting to draws_matrix does not preserve arrays
-    parameters_list[[iter]] <- posterior::as_draws_matrix(
-      posterior::as_draws_rvars(generator_output$parameters))
+    params_rvars <-
+      do.call(
+      posterior::draws_rvars,
+      purrr::map(generator_output$parameters,
+                 ~ posterior::rvar(array(.x, dim = c(1, dim(.x))))
+                 )
+      )
+    parameters_list[[iter]] <- posterior::as_draws_matrix(params_rvars)
     if(posterior::ndraws(parameters_list[[iter]]) != 1) {
       stop(""The `parameters` element of the generated data must contain only
       a single draw"")

---FILE: R/results.R---
@@ -452,6 +452,9 @@ compute_results_single <- function(params_and_generated, backend, cores,
   parameters <- params_and_generated$parameters
   generated <- params_and_generated$generated
 
+  # Note: explicitly referencing functions from the SBC package is needed
+  # here as the function might be run in a separate R session that does not
+  # have SBC imported.
   result_with_output <- SBC:::capture_all_outputs({
     res <- tryCatch({
       fit <- SBC_fit(backend, generated, cores = cores)

---FILE: R/util.R---
@@ -13,3 +13,12 @@ combine_args <- function(args1, args2) {
     c(args1, args2[!(names(args2) %in% shared)])
   }
 }
+
+
+SBC_error <- function(subclass, message, call = sys.call(-1), ...) {
+  structure(
+    class = c(subclass, ""error"", ""condition""),
+    list(message = message, call = call),
+    ...
+  )
+}

---FILE: tests/testthat/test-datasets.R---
@@ -2,9 +2,11 @@ test_that(""Generating datasets via functions"", {
   list_function <- function(N) {
     mu <- rnorm(1)
     sigma <- abs(rnorm(1))
+    beta <- matrix(1:6, nrow = 3, ncol = 2)
+    gamma <- array(1:12, dim = c(2,3,2))
     y1 <- rnorm(N, mu, sigma)
     y2 <- rnorm(2 * N, mu + 5, sigma)
-    list(parameters = list(mu = mu, sigma = sigma),
+    list(parameters = list(mu = mu, sigma = sigma, beta = beta, gamma = gamma),
          generated = list(y1 = y1, y2 = y2))
   }
 
@@ -14,7 +16,10 @@ test_that(""Generating datasets via functions"", {
 
   expect_true(length(res) == 7)
 
-  expect_identical(posterior::variables(res$parameters), c(""mu"", ""sigma""))
+  beta_vars <- paste0(""beta["", rep(1:3, times = 2), "","", rep(1:2, each = 3), ""]"")
+  gamma_vars <- paste0(""gamma["", rep(1:2, times = 6), "","", rep(rep(1:3, each = 2), times = 2),
+                       "","", rep(1:2, each = 6), ""]"")
+  expect_identical(posterior::variables(res$parameters), c(""mu"", ""sigma"", beta_vars, gamma_vars))
   expect_identical(names(res$generated[[1]]), c(""y1"", ""y2""))
 
   expect_equal(posterior::ndraws(res$parameters), 7)
@@ -34,6 +39,36 @@ test_that(""Generating datasets via functions"", {
 
 })
 
+test_that(""Generating datasets via functions - exceptions"", {
+  missing_gen_function <- function() {
+    list(parameters = list(mu = 1),
+         not_generated = 1)
+  }
+
+  expect_error(generate_datasets(
+    SBC_generator_function(missing_gen_function),
+    n_datasets = 1), class = ""SBC_datasets_error"")
+
+  missing_par_function <- function() {
+    list(not_parameters = list(mu = 1),
+         generated = 1)
+  }
+
+  expect_error(generate_datasets(
+    SBC_generator_function(missing_par_function),
+    n_datasets = 1), class = ""SBC_datasets_error"")
+
+
+  missing_names_function <- function() {
+    list(parameters = list(mu = 1, 5),
+         generated = 1)
+  }
+
+  expect_error(generate_datasets(
+    SBC_generator_function(missing_names_function),
+    n_datasets = 1), class = ""SBC_datasets_error"")
+})
+
 test_that(""subsetting datasets"", {
   list_function <- function(N) {
     mu <- rnorm(1)",True,False,Implementation / Logic,6
hyunjimoon,SBC,01cde91b50a63954e238aae7d6c5632bc2acee9e,martinmodrak,cerny.m@gmail.com,2021-09-01T16:25:34Z,martinmodrak,cerny.m@gmail.com,2021-09-01T16:25:34Z,Diagnostics and workaround for issue #29,NAMESPACE;R/backends.R;R/plot.R,False,True,True,False,7,4,11,"---FILE: NAMESPACE---
@@ -31,8 +31,6 @@ S3method(print,SBC_nuts_diagnostics_summary)
 S3method(print,SBC_results_summary)
 S3method(summary,SBC_nuts_diagnostics)
 S3method(summary,SBC_results)
-export(""#'"")
-export(""@export"")
 export(SBC_backend_brms)
 export(SBC_backend_brms_from_generator)
 export(SBC_backend_cmdstan_sample)
@@ -64,6 +62,7 @@ export(generate_datasets)
 export(generated_quantities)
 export(get_diagnostics_messages)
 export(max_diff)
+export(plot_contraction)
 export(plot_ecdf)
 export(plot_ecdf_diff)
 export(plot_rank_hist)

---FILE: R/backends.R---
@@ -94,7 +94,11 @@ summary.SBC_nuts_diagnostics <- function(diagnostics) {
   }
 
   if(!is.null(diagnostics$n_failed_chains)) {
-    summ$has_failed_chains = sum(diagnostics$n_failed_chains > 0)
+    if(any(is.na(diagnostics$n_failed_chains))) {
+      problematic_fit_ids <- paste0(which(is.na(diagnostics$n_failed_chains)), collapse = "", "")
+      warning(""Fits for datasets "", problematic_fit_ids, "" had NA for n_failed_chains."")
+    }
+    summ$has_failed_chains = sum(is.na(diagnostics$n_failed_chains) | diagnostics$n_failed_chains > 0)
   }
 
   structure(summ, class = ""SBC_nuts_diagnostics_summary"")

---FILE: R/plot.R---
@@ -343,7 +343,7 @@ data_for_ecdf_plots.matrix <- function(x,
 #' or `""var""` for variance.
 #' @param alpha the alpha for the points
 #' @return a ggplot2 plot object
-#' @export#' @export
+#' @export
 plot_contraction <- function(x, prior_sd, parameters = NULL, scale = ""sd"", alpha = 0.8) {
   UseMethod(""plot_contraction"")
 }",True,False,Dependency / Package,6
hyunjimoon,SBC,db0014b21aa5d9a9a7aad4f1ed8f9228bd62173e,martinmodrak,modrak.mar@gmail.com,2021-08-23T11:24:42Z,martinmodrak,modrak.mar@gmail.com,2021-08-23T11:24:42Z,Fixed a bug in plot_ecdf / plot_ecdf_diff for matrix arguments,R/plot.R,False,True,True,False,10,0,10,"---FILE: R/plot.R---
@@ -90,6 +90,8 @@ guess_bins <- function(max_rank, N) {
 #' Plot the ECDF-based plots.
 #'
 #'
+#' See the methods for [data_for_ecdf_plots()] for available data formats.
+#'
 #' \href{https://arxiv.org/abs/1903.08008}{arxiv::1903.08008} by A. Vehtari et al.
 #' @export
 #' @rdname ECDF-plots
@@ -103,6 +105,8 @@ guess_bins <- function(max_rank, N) {
 #'   the granularity of the plot and can significantly speed up the computation
 #'   of the simultaneous confidence bands. Defaults to the smaller of number of
 #'   ranks per parameter and the maximum rank.
+#' @param ... additional arguments passed to [data_for_ecdf_plots()].
+#' Most notably, if `x` is matrix, a `max_rank` parameter needs to be given.
 #' @import ggplot2
 plot_ecdf <- function(x,
                       parameters = NULL,
@@ -297,6 +301,7 @@ data_for_ecdf_plots.SBCWorkflow <- function(
 
 data_for_ecdf_plots.matrix <- function(x,
                                                max_rank,
+                                       parameters = NULL,
                                                  prob = 0.95,
                                                  gamma = NULL,
                                                  K = NULL,
@@ -306,6 +311,11 @@ data_for_ecdf_plots.matrix <- function(x,
   if(any(!is.finite(ranks_matrix))) {
     stop(""Ranks may only contain finite values"")
   }
+
+  if(!is.null(parameters)) {
+    ranks_matrix <- ranks_matrix[, parameters]
+  }
+
   pit <- ranks_to_empirical_pit(ranks_matrix, max_rank)
   N <- nrow(pit)
   if (is.null(K)) {",True,False,Implementation / Logic,6
hyunjimoon,SBC,fb48c26261dd85052503d380b8c906e328ebc997,martinmodrak,modrak.mar@gmail.com,2021-08-19T23:03:44Z,martinmodrak,modrak.mar@gmail.com,2021-08-19T23:03:44Z,Fixing bugs in error reporting and vignettes,R/results.R;vignettes/brms.Rmd;vignettes/small_model_workflow.Rmd,True,True,True,False,43,41,84,"---FILE: R/results.R---
@@ -300,34 +300,41 @@ compute_results <- function(datasets, backend,
   n_errors <- 0
   max_errors_to_show <- 5
   for(i in 1:length(datasets)) {
+    if(!is.null(results_raw[[i]]$fit)) {
+      fits[[i]] <- results_raw[[i]]$fit
+    }
     if(is.null(results_raw[[i]]$error)) {
-      if(!is.null(results_raw[[i]]$fit)) {
-        fits[[i]] <- results_raw[[i]]$fit
-      }
       stats_list[[i]] <- results_raw[[i]]$stats
       stats_list[[i]]$dataset_id <- i
       backend_diagnostics_list[[i]] <- results_raw[[i]]$backend_diagnostics
       backend_diagnostics_list[[i]]$dataset_id <- i
     }
     else {
       if(n_errors < max_errors_to_show) {
-        message(""Dataset "", i, "" resulted in error when fitting.\n"")
-        message(results_raw[[i]]$error, ""\n"")
-        if(!is.null(results_raw[[i]]$warnings)) {
-          message("" --- Warnings for fit "", i, "" ----"")
-          message(paste0(results_raw[[i]]$warnings, collapse = ""\n""))
-        }
-        if(!is.null(results_raw[[i]]$messages)) {
-          message("" --- Messages for fit "", i, "" ----"")
-          message(paste0(results_raw[[i]]$messages, collapse = ""\n""))
-        }
-        if(is.null(results_raw[[i]]$output)) {
-          message("" --- Nothing in stdout ---"")
+        if(is.null(results_raw[[i]]$fit)) {
+          message(""Dataset "", i, "" resulted in error when fitting.\n"")
+          message(results_raw[[i]]$error, ""\n"")
+          if(!is.null(results_raw[[i]]$warnings)) {
+            message("" --- Warnings for fit "", i, "" ----"")
+            message(paste0(results_raw[[i]]$warnings, collapse = ""\n""))
+          }
+          if(!is.null(results_raw[[i]]$messages)) {
+            message("" --- Messages for fit "", i, "" ----"")
+            message(paste0(results_raw[[i]]$messages, collapse = ""\n""))
+          }
+          if(is.null(results_raw[[i]]$output)) {
+            message("" --- Nothing in stdout ---"")
+          } else {
+            message("" ---- Model output ----"")
+            cat(paste0(results_raw[[i]]$output, collapse = ""\n""))
+          }
+          message(""\n ---- End of output for dataset "", i, "" -----"")
         } else {
-          message("" ---- Model output ----"")
-          cat(paste0(results_raw[[i]]$output, collapse = ""\n""))
+          message(""Dataset "", i, "" resulted in error when post-processing the fit.\n"",
+                  ""Calling `recompute_statistics` after you've found and fixed the problem could "",
+                  ""let you move further without refitting"")
+          message(results_raw[[i]]$error, ""\n"")
         }
-        message(""\n ---- End of output for dataset "", i, "" -----"")
 
       } else if(n_errors == max_errors_to_show) {
         message(""Too many datasets produced errors. Further error messages not shown.\n"")
@@ -461,7 +468,7 @@ compute_results_single <- function(params_and_generated, backend, cores,
     error_stats <- tryCatch( {
       res$stats <- SBC::statistics_from_single_fit(res$fit, parameters = parameters, thin_ranks = thin_ranks,
                                                    generated = generated, gen_quants = gen_quants)
-      res$backend_diagnostics <-SBC::SBC_fit_to_diagnostics(fit, res$outuput, res$messages, res$warnings)
+      res$backend_diagnostics <- SBC::SBC_fit_to_diagnostics(fit, res$outuput, res$messages, res$warnings)
       NULL
     }, error = identity)
     if(!is.null(error_stats)) {
@@ -623,13 +630,10 @@ recompute_statistics <- function(old_results, datasets, thin_ranks = 10, gen_qua
 
   new_results <- old_results
   missing_fits <- purrr::map_lgl(old_results$fits, is.null)
-  errors <- ! purrr::map_lgl(old_results$errors, is.null)
-  if(all(errors)) {
-    stop(""All fits resulted in an error, cannot recompute"")
-  }
-  else if(all(missing_fits)) {
-    stop(""No raw fits preserved, cannot recompute. Maybe the results were computed with keep_fits = FALSE?"")
-  } else if(any(missing_fits & !errors)) {
+  if(all(missing_fits)) {
+    stop(""No raw fits preserved, cannot recompute. "",
+         ""Either all datasets produced errors or the results were computed with keep_fits = FALSE"")
+  } else if(any(missing_fits)) {
     warning(""Some raw fits not available. Those fits will be ignored when recomputing statistics"")
   }
 

---FILE: vignettes/brms.Rmd---
@@ -49,7 +49,7 @@ datasets <- generate_datasets(generator, 100)
 
 ```{r}
 # Reuse the compiled model and other info from the generator
-backend <- SBC_backend_brms_from_generator(generator, warmup = 500, iter = 1000, chains = 1, thin = 1,
+backend <- SBC_backend_brms_from_generator(generator, chains = 1, thin = 1,
                             init = 0.1)
 
 # More verbose alternative that results in exactly the same backend:
@@ -88,15 +88,13 @@ The data can be generated using the following code:
 ```{r}
 one_dataset_generator <- function(N, K) {
   # N - number of datapoints, K number of groups for the varying intercept
-  stopifnot(K <= N)
-  x <- rnorm(N) + 10
-  
-  group <- sample(1:K, size = K, replace = TRUE)
-  # Ensure all groups are actually present
-  if(length(unique(group)) < K) {
-    group[1:K] <- 1:K
-  }
+  stopifnot(3 * K <= N)
+  x <- rnorm(N) + 5
   
+  group <- sample(1:K, size = N, replace = TRUE)
+  # Ensure all groups are actually present at least twice
+  group[1:(3*K)] <- rep(1:K, each = 3)
+
   b_Intercept <- rnorm(1, 5, 1)   
   b_x <- rnorm(1, 0, 1)
   
@@ -122,7 +120,7 @@ one_dataset_generator <- function(N, K) {
   )
 }
 
-n_dataset_generator <- SBC_generator_function(one_dataset_generator, N = 12, K = 3)
+n_dataset_generator <- SBC_generator_function(one_dataset_generator, N = 25, K = 3)
 ```
 
 For increased sensitivity, we also add the log likelihood of the data given parameters
@@ -183,7 +181,7 @@ priors_func2 <- prior(normal(0,1), class = ""b"") +
 
 
 backend_func2 <- SBC_backend_brms(y ~ 0 + Intercept + x + (1 | group),  
-                            prior = priors_func2, warmup = 500, iter = 1000, chains = 1,
+                            prior = priors_func2, warmup = 1000, iter = 2000, chains = 1,
                             template_dataset = datasets_func$generated[[1]])
 
 

---FILE: vignettes/small_model_workflow.Rmd---
@@ -29,7 +29,7 @@ options(SBC.min_chunk_size = 5)
 ## Mixture component
 
 ```{r}
-model_first <- cmdstan_model(""simple_workflow/mixture_first.stan"")
+model_first <- cmdstan_model(""small_model_workflow/mixture_first.stan"")
 backend_first <- SBC_backend_cmdstan_sample(model_first) 
 ```
 
@@ -87,7 +87,7 @@ This might be puzzling but relates to bad usage of `log_mix` (TODO explain)
 ### Fixing mixture
 
 ```{r}
-model_fixed_log_mix <- cmdstan_model(""simple_workflow/mixture_fixed_log_mix.stan"")
+model_fixed_log_mix <- cmdstan_model(""small_model_workflow/mixture_fixed_log_mix.stan"")
 backend_fixed_log_mix <- SBC_backend_cmdstan_sample(model_fixed_log_mix)
 ```
 
@@ -128,7 +128,7 @@ We clearly see two modes. And upon reflection, it is not a lot surprising why: s
 We can easily fix the ordering of the `mu`s by using the `ordered` built-in type.
 
 ```{r}
-model_fixed_ordered <- cmdstan_model(""simple_workflow/mixture_fixed_ordered.stan"")
+model_fixed_ordered <- cmdstan_model(""small_model_workflow/mixture_fixed_ordered.stan"")
 backend_fixed_ordered <- SBC_backend_cmdstan_sample(model_fixed_ordered) 
 ```
 We also need to update the generator to match the new names and ordering constant:
@@ -262,7 +262,7 @@ Note: it turns out that extending the model to more components becomes somewhat
 ## Beta regression component
 
 ```{r}
-model_beta_first <- cmdstan_model(""simple_workflow/beta_first.stan"")
+model_beta_first <- cmdstan_model(""small_model_workflow/beta_first.stan"")
 backend_beta_first <- SBC_backend_cmdstan_sample(model_beta_first) 
 
 ```",True,True,Implementation / Logic,6
hyunjimoon,SBC,6f515e5dc4142593c5cf6a8e7a36716e0c4574bb,martinmodrak,modrak.mar@gmail.com,2021-08-19T07:44:01Z,martinmodrak,modrak.mar@gmail.com,2021-08-19T07:44:01Z,"Fixes to plots, typos",R/plot.R;vignettes/rejection_sampling.Rmd,True,True,True,False,12,5,17,"---FILE: R/plot.R---
@@ -19,6 +19,9 @@ plot_rank_hist.data.frame <- function(x, parameters = NULL, bins = NULL, prob =
     stop(""Differing number of SBC steps per parameter not supported."")
   }
 
+  if(is.null(max_rank)) {
+    stop(""max_rank either has to be supplied explicitly or be a column in the data"")
+  }
   max_rank <- unique(max_rank)
   if(length(max_rank) > 1) {
     stop(""Differing max_rank across parameters is not supported yet."")
@@ -60,6 +63,7 @@ plot_rank_hist.data.frame <- function(x, parameters = NULL, bins = NULL, prob =
           geom_segment(aes(x=0,y=ci_mean,xend=max_rank,yend=ci_mean),colour=""grey25"") +
           geom_polygon(data=data.frame(x= CI_polygon_x,y= CI_polygon_y),aes(x=x,y=y),fill=""skyblue"",color=""skyblue1"",alpha=0.33) +
           geom_histogram(breaks =  seq(0, max_rank, length.out = bins + 1), closed = ""left"" ,fill=""#808080"",colour=""black"") +
+          scale_y_continuous(""count"") +
           facet_wrap(~parameter, scales = ""free_y"")
 
 }
@@ -106,11 +110,11 @@ plot_ecdf <- function(x,
                       gamma = NULL,
                       prob = 0.95,
                       size = 1,
-                      alpha = 0.33) {
+                      alpha = 0.33, ...) {
 
   ecdf_data <-
     data_for_ecdf_plots(x, parameters = parameters,
-                        prob = prob, K = K, gamma = gamma)
+                        prob = prob, K = K, gamma = gamma, ...)
 
   N <- ecdf_data$N
   K <- ecdf_data$K
@@ -169,10 +173,10 @@ plot_ecdf_diff <- function(x,
                            gamma = NULL,
                            prob = 0.95,
                            size = 1,
-                           alpha = 0.33) {
+                           alpha = 0.33, ...) {
   ecdf_data <-
     data_for_ecdf_plots(x, parameters = parameters,
-                        prob = prob, K = K, gamma = gamma)
+                        prob = prob, K = K, gamma = gamma, ...)
 
   N <- ecdf_data$N
   K <- ecdf_data$K
@@ -250,6 +254,9 @@ data_for_ecdf_plots.data.frame <- function(x, parameters = NULL,
     stats <- dplyr::filter(stats, parameter %in% parameters)
   }
 
+  if(is.null(max_rank)) {
+    stop(""max_rank either has to be supplied explicitly or be a column in the data"")
+  }
   max_rank <- unique(max_rank)
   if(length(max_rank) > 1) {
     stop(""Differing max_rank across parameters is not supported yet."")

---FILE: vignettes/rejection_sampling.Rmd---
@@ -141,4 +141,4 @@ results_reject_y <- compute_results(datasets_reject_y, backend)
 plot_ecdf_diff(results_reject_y)
 ```
 
-We see that even with quite heavy rejection based on y, SBC to a high resolution.
+We see that even with quite heavy rejection based on y, SBC to a high resolution passes.",True,True,Implementation / Logic,6
hyunjimoon,SBC,e916c41f9006b6cb7c2fe2ba987305367e88f3e9,martinmodrak,modrak.mar@gmail.com,2021-08-15T18:56:03Z,martinmodrak,modrak.mar@gmail.com,2021-08-15T18:56:03Z,"More work on workflow example, fixing bugs",R/backends.R;R/results.R;tests/testthat/test-results.R;vignettes/simple_workflow.Rmd;vignettes/simple_workflow/dirichlet_first.stan;vignettes/simple_workflow/mixture_final.stan,True,True,True,False,269,33,302,"---FILE: R/backends.R---
@@ -17,16 +17,16 @@ SBC_fit_to_draws_matrix.default <- function(fit) {
 #'
 #' @param fit The fit returned by `SBC_fit`
 #' @param fit_output a character string capturing what the backend wrote to stdout
-#' @param fit_messages a `data.frame` with columns `type` (type of message as signalled by R,
-#'    currently either ""message"" or ""warning"") and `message` (the actual text of the message).
+#' @param fit_messages a character vector of messages the backend raised
+#' @param fit_warnings a character vector of warnings the backend raised
 #' @return an object that includes diagnostics or NULL, if no diagnostics available.
 #' @export
-SBC_fit_to_diagnostics <- function(fit, fit_output, fit_messages) {
+SBC_fit_to_diagnostics <- function(fit, fit_output, fit_messages, fit_warnings) {
   UseMethod(""SBC_fit_to_diagnostics"")
 }
 
 #' @export
-SBC_fit_to_diagnostics.default <- function(fit, fit_output, fit_messages) {
+SBC_fit_to_diagnostics.default <- function(fit, fit_output, fit_messages, fit_warnings) {
   NULL
 }
 
@@ -59,13 +59,13 @@ SBC_fit.rstan_sample_SBC_backend <- function(backend, generated, cores) {
 }
 
 #' @export
-SBC_fit_to_diagnostics.stanfit <- function(fit, fit_output, fit_messages) {
+SBC_fit_to_diagnostics.stanfit <- function(fit, fit_output, fit_messages, fit_warnings) {
   res <- data.frame(
     max_chain_time = max(rowSums(rstan::get_elapsed_time(fit))),
     n_divergent = rstan::get_num_divergent(fit),
     n_max_treedepth = rstan::get_num_max_treedepth(fit),
     min_bfmi = min(rstan::get_bfmi(fit)),
-    n_rejects = sum(grepl(""reject"", fit_messages$message))
+    n_rejects = sum(grepl(""reject"", fit_messages)) + sum(grepl(""reject"", fit_warnings))
   )
 
   class(res) <- c(""SBC_nuts_diagnostics"", class(res))
@@ -213,11 +213,17 @@ cmdstan_sample_SBC_backend <- function(model, ...) {
 
 #' @export
 SBC_fit.cmdstan_sample_SBC_backend <- function(backend, generated, cores) {
-  do.call(backend$model$sample,
+  fit <- do.call(backend$model$sample,
           combine_args(backend$args,
             list(
               data = generated,
               parallel_chains = cores)))
+
+  if(all(fit$return_codes() != 0)) {
+    stop(""No chains finished succesfully"")
+  }
+
+  fit
 }
 
 
@@ -229,13 +235,13 @@ SBC_fit_to_draws_matrix.CmdStanMCMC <- function(fit) {
 
 
 #' @export
-SBC_fit_to_diagnostics.CmdStanMCMC <- function(fit, fit_output, fit_messages) {
+SBC_fit_to_diagnostics.CmdStanMCMC <- function(fit, fit_output, fit_messages, fit_warnings) {
   res <- data.frame(
     max_chain_time = max(fit$time()$chains[,""total""]),
     n_failed_chains = fit$num_chains() - sum(fit$return_codes() == 0),
     n_divergent = sum(fit$sampler_diagnostics()[, , ""divergent__""]),
     n_max_treedepth =  sum(fit$sampler_diagnostics()[, , ""treedepth__""] == fit$metadata()$max_treedepth),
-    n_rejects = sum(grepl(""reject"", fit_messages$message))
+    n_rejects = sum(grepl(""reject"", fit_messages)) + sum(grepl(""reject"", fit_warnings))
     #
   ) # TODO: add min_bfmi once https://github.com/stan-dev/cmdstanr/pull/500/ is merged
   class(res) <- c(""SBC_nuts_diagnostics"", class(res))

---FILE: R/results.R---
@@ -5,10 +5,11 @@ SBC_results <- function(stats,
                         default_diagnostics,
                         outputs,
                         messages,
+                        warnings,
                         errors) {
   validate_SBC_results(
     structure(list(stats = stats, fits = fits, backend_diagnostics = backend_diagnostics,
-                   outputs = outputs, messages = messages,
+                   outputs = outputs, messages = messages, warnings = warnings,
                    default_diagnostics = default_diagnostics, errors = errors), class = ""SBC_results"")
   )
 }
@@ -53,7 +54,7 @@ validate_SBC_results <- function(x) {
     }
 
 
-    if(min(x$stats$run_id) < 1 || max(x$stats$run_id > length(x$fits))) {
+    if(min(x$stats$run_id) < 1 || max(x$stats$run_id) > length(x$fits)) {
       stop(""stats$run_id values must be between 1 and number of fits"")
     }
   }
@@ -65,11 +66,17 @@ validate_SBC_results <- function(x) {
   }
 
   if(!is.null(x$messages)) {
-    if(!is.list(x$messages) || length(x$messages) != length(x$messages)) {
+    if(!is.list(x$messages) || length(x$messages) != length(x$fits)) {
       stop(""messages can only be a list of the same length as fits"")
     }
   }
 
+  if(!is.null(x$warnings)) {
+    if(!is.list(x$warnings) || length(x$warnings) != length(x$fits)) {
+      stop(""warnings can only be a list of the same length as fits"")
+    }
+  }
+
   if(!is.null(x$backend_diagnostics) && nrow(x$backend_diagnostics) > 0) {
     if(!is.numeric(x$backend_diagnostics$run_id)) {
       stop(""The run_id column of 'backend_diagnostics' needs to be a number."")
@@ -115,6 +122,7 @@ bind_results <- function(...) {
   default_diagnostics_list <- purrr::map(args, function(x) x$default_diagnostics)
   errors_list <- purrr::map(args, function(x) x$errors)
   messages_list <- purrr::map(args, function(x) x$messages)
+  warnings_list <- purrr::map(args, function(x) x$warnings)
   outputs_list <- purrr::map(args, function(x) x$outputs)
 
   # Ensure unique run_ids
@@ -129,16 +137,24 @@ bind_results <- function(...) {
     }
   }
 
+  bind_and_rearrange_df <- function(df_list) {
+    dplyr::arrange(
+      do.call(rbind, df_list),
+      run_id
+    )
+  }
+
   stats_list <- purrr::map2(stats_list, shifts, shift_run_id)
   backend_diagnostics_list <- purrr::map2(backend_diagnostics_list, shifts, shift_run_id)
   default_diagnostics_list <- purrr::map2(default_diagnostics_list, shifts, shift_run_id)
 
-  SBC_results(stats = do.call(rbind, stats_list),
+  SBC_results(stats = bind_and_rearrange_df(stats_list),
               fits = do.call(c, fits_list),
-              backend_diagnostics = do.call(rbind, backend_diagnostics_list),
-              default_diagnostics = do.call(rbind, default_diagnostics_list),
+              backend_diagnostics = bind_and_rearrange_df(backend_diagnostics_list),
+              default_diagnostics = bind_and_rearrange_df(default_diagnostics_list),
               errors =  do.call(c, errors_list),
               messages = do.call(c, messages_list),
+              warnings = do.call(c, warnings_list),
               outputs = do.call(c, outputs_list)
   )
 }
@@ -166,7 +182,7 @@ length.SBC_results <- function(x) {
     }
     filtered <- dplyr::filter(df, run_id %in% indices_to_keep)
     remapped <- dplyr::mutate(filtered, run_id = index_map[as.character(run_id)])
-    remapped
+    dplyr::arrange(remapped, run_id)
   }
 
   SBC_results(stats = subset_run_df(x$stats),
@@ -175,6 +191,7 @@ length.SBC_results <- function(x) {
               default_diagnostics = subset_run_df(x$default_diagnostics),
               outputs = x$output[indices],
               messages = x$messages[indices],
+              warnings = x$warnings[indices],
               errors = x$errors[indices])
 }
 
@@ -192,7 +209,7 @@ compute_results <- function(datasets, backend,
   for(i in 1:length(datasets)) {
     params_and_generated_list[[i]] <- list(
       parameters = posterior::subset_draws(datasets$parameters,
-                                      draw = i),
+                                           draw = i),
       generated = datasets$generated[[i]]
     )
   }
@@ -209,25 +226,44 @@ compute_results <- function(datasets, backend,
   fits <- rep(list(NULL), length(datasets))
   outputs <- rep(list(NULL), length(datasets))
   messages <- rep(list(NULL), length(datasets))
+  warnings <- rep(list(NULL), length(datasets))
   errors <- rep(list(NULL), length(datasets))
   stats_list <- list()
   backend_diagnostics_list <- list()
   n_errors <- 0
   max_errors_to_show <- 5
   for(i in 1:length(datasets)) {
     if(is.null(results_raw[[i]]$error)) {
-      fits[[i]] <- results_raw[[i]]$fit
+      if(!is.null(results_raw[[i]]$fit)) {
+        fits[[i]] <- results_raw[[i]]$fit
+      }
       stats_list[[i]] <- results_raw[[i]]$stats
       stats_list[[i]]$run_id <- i
       backend_diagnostics_list[[i]] <- results_raw[[i]]$backend_diagnostics
       backend_diagnostics_list[[i]]$run_id <- i
     }
     else {
       if(n_errors < max_errors_to_show) {
-        warning(""Dataset "", i, "" resulted in error when fitting.\n"")
+        message(""Dataset "", i, "" resulted in error when fitting.\n"")
         message(results_raw[[i]]$error, ""\n"")
+        if(!is.null(results_raw[[i]]$warnings)) {
+          message("" --- Warnings for fit "", i, "" ----"")
+          message(paste0(results_raw[[i]]$warnings, collapse = ""\n""))
+        }
+        if(!is.null(results_raw[[i]]$messages)) {
+          message("" --- Messages for fit "", i, "" ----"")
+          message(paste0(results_raw[[i]]$messages, collapse = ""\n""))
+        }
+        if(is.null(results_raw[[i]]$output)) {
+          message("" --- Nothing in stdout ---"")
+        } else {
+          message("" ---- Model output ----"")
+          cat(paste0(results_raw[[i]]$output, collapse = ""\n""))
+        }
+        message(""\n ---- End of output for dataset "", i, "" -----"")
+
       } else if(n_errors == max_errors_to_show) {
-        warning(""Too many datasets produced errors. Further error messages not shown.\n"")
+        message(""Too many datasets produced errors. Further error messages not shown.\n"")
       }
       n_errors <- n_errors + 1
       errors[[i]] <- results_raw[[i]]$error
@@ -238,6 +274,9 @@ compute_results <- function(datasets, backend,
     if(!is.null(results_raw[[i]]$messages)) {
       messages[[i]] <- results_raw[[i]]$messages
     }
+    if(!is.null(results_raw[[i]]$warnings)) {
+      warnings[[i]] <- results_raw[[i]]$warnings
+    }
   }
 
   if(n_errors == length(datasets)) {
@@ -290,6 +329,7 @@ compute_results <- function(datasets, backend,
 
   res <- SBC_results(stats = stats, fits = fits, outputs = outputs,
                      messages = messages,
+                     warnings = warnings,
                      backend_diagnostics = backend_diagnostics,
                      default_diagnostics = default_diagnostics,
                      errors = errors)
@@ -324,11 +364,10 @@ default_chunk_size <- function(n_fits, n_workers = future::nbrOfWorkers()) {
 # Capturing output.
 # Based on https://www.r-bloggers.com/2020/10/capture-message-warnings-and-errors-from-a-r-function/
 capture_all_outputs <- function(expr) {
-  logs <- list()
+  logs <- list(message = list(), warning = list())
   add_log <- function(type, message) {
     new_l <- logs
-    new_log <- data.frame(type = type, message =  message)
-    new_l[[length(new_l) + 1]]  <- new_log
+    new_l[[type]][[length(new_l[[type]]) + 1]]  <- message
     logs <<- new_l
   }
   output <- capture.output({
@@ -342,7 +381,7 @@ capture_all_outputs <- function(expr) {
         invokeRestart(""muffleMessage"")
       })
   }, type = ""output"")
-  list(result = res, messages = do.call(rbind, logs), output = output)
+  list(result = res, messages = do.call(c, logs$message), warnings = do.call(c, logs$warning), output = output)
 }
 
 
@@ -367,8 +406,12 @@ compute_results_single <- function(params_and_generated, backend, cores,
   if(is.null(res$error)) {
     error_stats <- tryCatch( {
       res$stats <- SBC::statistics_from_single_fit(res$fit, parameters = parameters, thin_ranks = thin_ranks)
-      res$backend_diagnostics <-SBC::SBC_fit_to_diagnostics(fit, res$outuput, res$messages)
+      res$backend_diagnostics <-SBC::SBC_fit_to_diagnostics(fit, res$outuput, res$messages, res$warnings)
+      NULL
     }, error = identity)
+    if(!is.null(error_stats)) {
+      res$error <- error_stats
+    }
   } else {
     res$stats <- NULL
     res$backend_diagnostics <- NULL
@@ -520,11 +563,11 @@ summary.SBC_results <- function(x) {
     n_errors = sum(!purrr::map_lgl(x$errors, is.null)),
     n_warnings = sum(purrr::map_lgl(x$messages, ~ !is.null(.x) && any(x$type == ""warning""))),
     n_high_rhat = sum(x$default_diagnostics$max_rhat > 1.01),
-    max_max_rhat = max(x$default_diagnostics$max_rhat),
+    max_max_rhat = max(c(-Inf, x$default_diagnostics$max_rhat)),
     n_low_ess_to_rank = sum(is.na(x$default_diagnostics$min_ess_to_rank) | x$default_diagnostics$min_ess_to_rank < 0.5),
-    min_min_ess_bulk = min(x$default_diagnostics$min_ess_bulk),
-    min_min_ess_tail = min(x$default_diagnostics$min_ess_tail)
-    )
+    min_min_ess_bulk = min(c(Inf, x$default_diagnostics$min_ess_bulk)),
+    min_min_ess_tail = min(c(Inf, x$default_diagnostics$min_ess_tail))
+  )
   if(!is.null(x$backend_diagnostics)) {
     summ$backend_diagnostics <- summary(x$backend_diagnostics)
   } else {

---FILE: tests/testthat/test-results.R---
@@ -3,15 +3,42 @@ test_that(""capture_all_outputs"", {
         capture_all_outputs({
             cat(""Test"")
             warning(""W"")
-            message(""M"")
+            message(""M"", appendLF = FALSE)
+            warning(""W2"")
+            message(""M2"", appendLF = FALSE)
+            message(""M3"", appendLF = FALSE)
             14
             }),
         list(result = 14,
-             messages = data.frame(type = c(""warning"", ""message""),
-                                   message = c(""W"", ""M\n"")),
+             messages = c(""M"", ""M2"", ""M3""),
+             warnings = c(""W"", ""W2""),
              output = ""Test""))
 })
 
+test_that(""subset_bind"", {
+    res <- SBC_results(stats = data.frame(run_id = rep(1:3, each = 4), s = 1:12),
+                       fits = list(""A"", NULL, ""C""),
+                       outputs = list(c(""A1"",""A2""), c(), c(""C1"", ""C4"")),
+                       warnings = list(c(), ""XXXX"", ""asdfdaf""),
+                       messages = list(""aaaa"", ""ddddd"", NA_character_),
+                       errors = list(NULL, ""customerror"", NULL),
+                       default_diagnostics = data.frame(run_id = 1:3, qq = rnorm(3)),
+                       backend_diagnostics = data.frame(run_id = 1:3, rr = rnorm(3))
+                       )
+
+    remove_run_id_names <- function(x) {
+        names(x$stats$run_id) <- NULL
+        names(x$default_diagnostics$run_id) <- NULL
+        names(x$backend_diagnostics$run_id) <- NULL
+        x
+    }
+
+    expect_equal(res, remove_run_id_names(bind_results(res[1], res[2:3])))
+    expect_equal(res, remove_run_id_names(bind_results(res[1:2], res[3])))
+    expect_equal(remove_run_id_names(res[3:1]), remove_run_id_names(bind_results(res[3:2], res[1])))
+    expect_equal(remove_run_id_names(res[2]), remove_run_id_names(((res[2:3])[1])))
+})
+
 test_that(""calculate_ranks_draws_matrix works"", {
 
     dm <- matrix(NA_real_, nrow = 10, ncol = 4)

---FILE: vignettes/simple_workflow.Rmd---
@@ -252,10 +252,124 @@ plot_ecdf_diff(results_fixed_ordered_combined)
 ```
 Seems fairly well within the expected bounds. We could definitely run more iterations if we wanted to have a more strict check, but for now, we are happy.
 
+### Extending to more components
+
+To avoid high chances of components with very similar means, we'll make the prior for `mu` much wider. At the same time we concentrate the prior on `theta` to avoid having components with too low probability (and thus not present in the data)
+
+```{r}
+model_final <- cmdstan_model(""simple_workflow/mixture_final.stan"")
+backend_final <- cmdstan_sample_SBC_backend(model_final, chains = 2)
+```
+
+```{r}
+generator_func_final <- function(N, N_components) {
+  # If the priors for all components of an ordered vector are the same
+  # then just sorting the result of a generator is enough to create
+  # a valid sample from the ordered vector
+  mu <- sort(rnorm(N_components, 5, 2.5)) 
+  # Converting via as.numeric to keep only one dimension
+  theta <- as.numeric(MCMCpack::rdirichlet(1, rep(3, N_components)))
+  
+  y <- numeric(N)
+  for(n in 1:N) {
+    comp <- sample.int(N_components, size = 1, prob = theta)
+    y[n] <- rpois(1, exp(mu[comp]))
+  }
+  
+  list(
+    parameters = list(
+      mu = mu,
+      theta = theta
+    ),
+    generated = list(
+      N = N,
+      N_components = N_components,
+      y = y
+    )
+  )
+}
+
+generator_final <- function_SBC_generator(generator_func_final, N = 100, N_components = 3)
+```
+
+Quickly test a few datasets to make sure we didn't do any big error (I actually did when writing this :-))
+
+```{r}
+set.seed(223345864)
+datasets_final_10 <- generate_datasets(generator_final, 10) 
+results_final_10 <- compute_results(datasets_final_10, backend_final)
+```
+```{r}
+bayesplot::mcmc_pairs(results_final_10$fits[[1]]$draws(), np = nuts_params(results_final_10$fits[[1]]))
+```
+
+
+This time we don't save the fits to save memory.
+
+```{r}
+set.seed(54622625)
+datasets_final_200 <- generate_datasets(generator_final, 200) 
+results_final_200 <- compute_results(datasets_final, backend_final, keep_fits = FALSE)
+```
+
+```{r}
+results_final <- bind_results(results_final_10, results_final_200)
+results_final_subset <- results_final[results_final$backend_diagnostics$n_divergent == 0]
+summary(results_final_subset)
+```
+
+
 ## Dirichlet regression component
 
+```{r}
+model_dir_first <- cmdstan_model(""simple_workflow/dirichlet_first.stan"")
+backend_dir_first <- cmdstan_sample_SBC_backend(model_dir_first) 
+
+```
+
+
+```{r}
+generator_func_dir_first <- function(N_obs, N_components, N_predictors) {
+  beta <- matrix(rnorm(N_predictors * N_components, 0, 2), nrow = N_components, ncol = N_predictors)
+  precision <- rlnorm(1, 2, 1)
+  
+  x <- matrix(rnorm(N_predictors * N_obs, 0, 1), nrow = N_predictors, ncol = N_obs)
+  x[1, ] <- 1 # Intercept
+
+  y <- matrix(NA_real, nrow = N_components, ncol = N_obs)
+    
+  for(n in 1:N_obs) {
+    linpred <- rep(0, N_components)
+    for(c in 1:N_components) {
+      for(p in 1:N_predictors) {
+        linpred[c] <- linpred[c] + x[p, n] * beta[c, p]
+      }
+    }
+    mu_vec <- exp(linpred) / sum(exp(linpred))
+    y[,n] <- MCMCpack::rdirichlet(1, precision * mu_vec)
+  }
+    
+  list(
+    parameters = list(
+      beta = beta,
+      precision = precision
+    ),
+    generated = list(
+      N_obs = N_obs,
+      N_components = N_components,
+      N_predictors = N_predictors,
+      y = y,
+      x = x
+    )
+  )
+}
+
+generator_first <- function_SBC_generator(generator_func_first, N = 50)
+```
+
+
 - Non-identifiability: predictors for all
-- Off-by-one: not informed parameter
+- Off-by-one: not informed parameter (posterior shrinkage)
 - Forgotten prior for intercept?
 
 ## Putting it together

---FILE: vignettes/simple_workflow/dirichlet_first.stan---
@@ -0,0 +1,23 @@
+data {
+  int<lower=0> N_obs;
+  int<lower=2> N_components;
+  matrix<lower=0, upper=1>[N_components, N_obs] y;
+
+  int<lower=1> N_predictors;
+  matrix[N_predictors, N_obs] x;
+}
+
+parameters {
+  matrix[N_components, N_predictors] beta;
+  real<lower=0> precision;
+}
+
+model {
+  matrix[N_components, N_obs] linpred = beta * x;
+  for(n in 1:N_obs) {
+    target += dirichlet_lpdf(y[, n] | precision * softmax(linpred[,n]));
+  }
+
+  target += lognormal_lpdf(precision | 2, 1);
+  target += normal_lpdf(to_vector(beta) | 0, 2);
+}

---FILE: vignettes/simple_workflow/mixture_final.stan---
@@ -0,0 +1,23 @@
+data {
+  int<lower=0> N;
+  int<lower=2> N_components;
+  int y[N];
+}
+
+parameters {
+  ordered[N_components] mu;
+  simplex[N_components] theta;
+}
+
+model {
+  for(n in 1:N) {
+    vector[N_components] component_lp;
+    for(c in 1:N_components) {
+      component_lp[c] = poisson_log_lpmf(y[n] | mu[c]);
+    }
+    target += log_sum_exp(theta .* component_lp);
+  }
+  target += normal_lpdf(mu | 5, 2.5);
+  target += dirichlet_lpdf(theta | rep_vector(3, N_components));
+}
+",True,True,Documentation / Formatting,6
hyunjimoon,SBC,1d49c587632176a2f0eb2f749462114cb031b074,martinmodrak,cerny.m@gmail.com,2021-08-12T15:18:06Z,martinmodrak,cerny.m@gmail.com,2021-08-12T15:18:06Z,Fixes to result approx to max rhat,R/backends.R;R/results.R,False,True,True,False,53,6,59,"---FILE: R/backends.R---
@@ -99,6 +99,41 @@ get_diagnostics_messages.SBC_nuts_diagnostics <- function(x) {
   get_diagnostics_messages(summary(x))
 }
 
+# Use the Generalized extreme value distribution
+# to get a quantile of maximum of `n_vars` random values
+# distributed as N(1, 0.005).
+# Following https://en.wikipedia.org/wiki/Generalized_extreme_value_distribution#Example_for_Normally_distributed_variables
+# The approximation looks good for n_vars >= 10
+# for smaller, we just plug in a log function with appropriate scale
+# See https://math.stackexchange.com/questions/89030/expectation-of-the-maximum-of-gaussian-random-variables
+# for a discussion on why log
+get_expected_max_rhat <- function(n_vars, prob = 0.99) {
+  stopifnot(is.numeric(n_vars))
+  stopifnot(all(n_vars >= 1))
+
+  # Maximum of n_vars standardized normals
+  gumbel_approx <- function(n) {
+    # Gumbel params
+    mu_n <- qnorm(1 - 1/n)
+    sigma_n <- qnorm(1 - (1 / n) * exp(-1)) - mu_n
+
+    # Inverse CDF of gumbel with xi = 0
+    mu_n - (sigma_n * log(-log(prob)))
+  }
+
+
+  linear_bound <- 10
+  approx_at_bound <- gumbel_approx(linear_bound)
+  value_at_1 <- qnorm(prob)
+  linear_scale <- (approx_at_bound - value_at_1 ) / log(linear_bound)
+
+  std_val_max <- dplyr::if_else(n_vars < linear_bound,
+    value_at_1 + linear_scale * log(n_vars),
+    gumbel_approx(n_vars)
+  )
+  1 + std_val_max * 0.005
+}
+
 get_diagnostics_messages.SBC_nuts_diagnostics_summary <- function(x) {
   message_list <- list()
   i <- 1
@@ -147,6 +182,9 @@ get_diagnostics_messages.SBC_nuts_diagnostics_summary <- function(x) {
   }
   i <- i + 1
 
+  message_list[[i]] <- data.frame(ok = TRUE, message = paste0(""Maximum time per chain was "", x$max_chain_time, "" sec.""))
+  i <- i + 1
+
   SBC_diagnostic_messages(do.call(rbind, message_list))
 }
 

---FILE: R/results.R---
@@ -19,8 +19,9 @@ compute_param_diagnostics <- function(stats) {
   dplyr::summarise(dplyr::group_by(stats, run_id),
                    n_params = dplyr::n(),
                    max_rhat = max(c(-Inf, rhat)),
-                   min_ess = min(c(Inf, ess_bulk)),
-                   min_ess_to_rank = min(c(Inf, ess_bulk / max_rank)))
+                   min_ess_bulk = min(c(Inf, ess_bulk)),
+                   min_ess_tail = min(c(Inf, ess_tail)),
+                   min_ess_to_rank = min(c(Inf, ess_tail / max_rank)))
 }
 
 #' @export
@@ -234,7 +235,9 @@ compute_results <- function(datasets, backend,
 
     }
   } else {
+    # Return dummy stats that let the rest of the code work.
     stats <- data.frame(run_id = integer(0), rhat = numeric(0), ess_bulk = numeric(0),
+                        ess_tail = numeric(0),
                         rank = integer(0), simulated_value = numeric(0), max_rank = integer(0))
   }
 
@@ -470,7 +473,9 @@ summary.SBC_results <- function(x) {
     n_high_rhat = sum(x$param_diagnostics$max_rhat > 1.01),
     max_max_rhat = max(x$param_diagnostics$max_rhat),
     n_low_ess_to_rank = sum(x$param_diagnostics$min_ess_to_rank < 0.5),
-    min_min_ess = min(x$param_diagnostics$min_ess))
+    min_min_ess_bulk = min(x$param_diagnostics$min_ess_bulk),
+    min_min_ess_tail = min(x$param_diagnostics$min_ess_tail)
+    )
   if(!is.null(x$fit_diagnostics)) {
     summ$fit_diagnostics <- summary(x$fit_diagnostics)
   } else {
@@ -513,14 +518,18 @@ get_diagnostics_messages.SBC_results_summary <- function(x) {
   i <- i + 1
 
   if(x$n_low_ess_to_rank > 0) {
-    msg <- paste0(x$n_low_ess_to_rank, "" ("", round(100 * x$n_low_ess_to_rank / x$n_fits), ""%) fits had bulk ESS < "",
-                  ""half of the maximum rank, potentially skewing the rank statistics. The lowest ESS was "", round(x$min_min_ess), "".\n   Consider increasing `thin_ranks` or number of posterior samples and recomputing."")
+    msg <- paste0(x$n_low_ess_to_rank, "" ("", round(100 * x$n_low_ess_to_rank / x$n_fits), ""%) fits had tail ESS < "",
+                  ""half of the maximum rank, potentially skewing the rank statistics. The lowest tail ESS was "", round(x$min_min_ess_tail),
+                  "".\n   Consider increasing `thin_ranks` or number of posterior samples and recomputing."")
     message_list[[i]] <- data.frame(ok = FALSE, message = msg)
   } else {
-    message_list[[i]] <- data.frame(ok = TRUE, message = ""All fits had bulk ESS > half of the maximum rank."")
+    message_list[[i]] <- data.frame(ok = TRUE, message = ""All fits had tail ESS > half of the maximum rank."")
   }
   i <- i + 1
 
+  message_list[[i]] <- data.frame(ok = TRUE, message = paste0(""The lowest bulk ESS was "", round(x$min_min_ess_bulk)))
+  i <-  i + 1
+
   if(!is.null(x$fit_diagnostics)) {
     message_list[[i]] <- get_diagnostics_messages(x$fit_diagnostics)
     i <- i + 1",True,False,Implementation / Logic,6
hyunjimoon,SBC,d1f470d0b6fda1ecda101c41a657d47346c9661b,martinmodrak,cerny.m@gmail.com,2021-08-12T14:15:49Z,martinmodrak,cerny.m@gmail.com,2021-08-12T14:15:49Z,Fixes in diagnostics,R/backends.R;R/results.R;vignettes/brms.Rmd,True,True,True,False,12,13,25,"---FILE: R/backends.R---
@@ -79,8 +79,8 @@ summary.SBC_nuts_diagnostics <- function(diagnostics) {
     max_chain_time = max(diagnostics$max_chain_time),
     has_divergent = sum(diagnostics$n_divergent > 0),
     has_treedepth = sum(diagnostics$n_max_treedepth > 0),
-    has_rejects = sum(diagnostis$n_rejects > 0),
-    max_rejects = max(diagnostis$n_rejects)
+    has_rejects = sum(diagnostics$n_rejects > 0),
+    max_rejects = max(diagnostics$n_rejects)
   )
 
   if(!is.null(diagnostics$min_bfmi)) {
@@ -121,7 +121,7 @@ get_diagnostics_messages.SBC_nuts_diagnostics_summary <- function(x) {
   i <- i + 1
 
   if(x$has_treedepth > 0) {
-    msg <- paste0(x$has_treedepth, "" ("", round(100 * x$has_treedepth / x$n_fits), ""%) fits had iterations that saturated max treedepth.\n"")
+    msg <- paste0(x$has_treedepth, "" ("", round(100 * x$has_treedepth / x$n_fits), ""%) fits had iterations that saturated max treedepth."")
     message_list[[i]] <- data.frame(ok = FALSE, message = msg)
   } else {
     message_list[[i]] <- data.frame(ok = TRUE, message = ""No fits had iterations that saturated max treedepth."")
@@ -139,7 +139,7 @@ get_diagnostics_messages.SBC_nuts_diagnostics_summary <- function(x) {
   }
 
   if(x$has_rejects > 0) {
-    msg <- paste0(x$has_rejects, "" ("", round(100 * x$has_rejects / x$n_fits), ""%) fits had some steps"",
+    msg <- paste0(x$has_rejects, "" ("", round(100 * x$has_rejects / x$n_fits), ""%) fits had some steps "",
                   ""rejected. Maximum number of rejections was "", x$max_rejects, ""."")
     message_list[[i]] <- data.frame(ok = FALSE, message = msg)
   } else {

---FILE: R/results.R---
@@ -466,7 +466,7 @@ summary.SBC_results <- function(x) {
   summ <- list(
     n_fits = length(x$fits),
     n_errors = sum(!purrr::map_lgl(x$errors, is.null)),
-    n_warnings = sum(!purrr::map_lgl(x$messages, ~ !is.null(.x) && any(x$type == ""warning""))),
+    n_warnings = sum(purrr::map_lgl(x$messages, ~ !is.null(.x) && any(x$type == ""warning""))),
     n_high_rhat = sum(x$param_diagnostics$max_rhat > 1.01),
     max_max_rhat = max(x$param_diagnostics$max_rhat),
     n_low_ess_to_rank = sum(x$param_diagnostics$min_ess_to_rank < 0.5),

---FILE: vignettes/brms.Rmd---
@@ -40,9 +40,7 @@ generator <- brms_SBC_generator(y ~ x, data = template_data, prior = priors,
                                 )
 ```
 
-```{r}
-system.time(generate_datasets(generator, 10))
-```
+
 
 ```{r}
 set.seed(22133548)
@@ -130,7 +128,7 @@ n_dataset_generator <- function_SBC_generator(one_dataset_generator, N = 12, K =
 
 ```{r}
 set.seed(12239755)
-datasets <- generate_datasets(n_dataset_generator, 100)
+datasets_func <- generate_datasets(n_dataset_generator, 100)
 ```
 
 ```{r}
@@ -142,13 +140,13 @@ priors_func <- prior(normal(0,1), class = ""b"") +
 
 backend_func <- brms_SBC_backend(y ~ x + (1 | group),  
                             prior = priors_func, chains = 1,
-                            template_dataset = datasets$generated[[1]])
+                            template_dataset = datasets_func$generated[[1]])
 
 ```
 
 
 ```{r}
-results_func <- compute_results(datasets, backend_func, thin_ranks = 10)
+results_func <- compute_results(datasets_func, backend_func, thin_ranks = 10)
 ```
 
 
@@ -175,14 +173,15 @@ priors_func2 <- prior(normal(0,1), class = ""b"") +
 
 backend_func2 <- brms_SBC_backend(y ~ 0 + Intercept + x + (1 | group),  
                             prior = priors_func2, warmup = 500, iter = 1000, chains = 1,
-                            template_dataset = datasets$generated[[1]])
+                            template_dataset = datasets_func$generated[[1]])
 
 
 ```
+
 Let's fit the same datasets with the new backend.
 
 ```{r}
-results_func2 <- compute_results(datasets, backend_func2, thin_ranks = 10)
+results_func2 <- compute_results(datasets_func, backend_func2, thin_ranks = 10)
 ```
 
 We see that this results in non-problematic univariate checks.",True,True,Implementation / Logic,6
hyunjimoon,SBC,9051c7f2966e7960d0c0dac89cc8a11223fc58bb,martinmodrak,cerny.m@gmail.com,2021-08-12T14:08:57Z,martinmodrak,cerny.m@gmail.com,2021-08-12T14:08:57Z,Fixed default K value in ECDF plots.,R/plot.R,False,True,True,False,1,1,2,"---FILE: R/plot.R---
@@ -259,7 +259,7 @@ data_for_ecdf_plots.matrix <- function(x,
   pit <- ranks_to_empirical_pit(ranks_matrix, max_rank)
   N <- nrow(pit)
   if (is.null(K)) {
-    K <- N
+    K <- max_rank + 1
   }
   if (is.null(gamma)) {
     gamma <- adjust_gamma(",True,False,Implementation / Logic,6
hyunjimoon,SBC,3bea1e9096ad41bcb11a9c01816aeb9d96741038,martinmodrak,cerny.m@gmail.com,2021-08-09T08:50:49Z,martinmodrak,cerny.m@gmail.com,2021-08-09T08:50:49Z,"More docs and checks, fixed a bug in `brms.Rmd`",NAMESPACE;R/datasets.R;R/results.R;man/custom_SBC_generator.Rd;man/function_SBC_generator.Rd;vignettes/brms.Rmd,True,True,True,False,113,12,125,"---FILE: NAMESPACE---
@@ -16,6 +16,7 @@ export(SBC_datasets)
 export(SBC_fit)
 export(SBC_fit_to_draws_matrix)
 export(SBC_results)
+export(bind_results)
 export(brms_SBC_backend)
 export(brms_SBC_backend_from_generator)
 export(brms_SBC_generator)
@@ -26,6 +27,7 @@ export(cmdstan_sample_SBC_backend)
 export(compute_results)
 export(custom_SBC_generator)
 export(data_for_ecdf_plots)
+export(default_chunk_size)
 export(default_cores_per_fit)
 export(dist_summary)
 export(function_SBC_generator)
@@ -37,6 +39,7 @@ export(rank_summary)
 export(rstan_sample_SBC_backend)
 export(statistics_from_single_fit)
 export(validate_SBC_datasets)
+export(validate_SBC_results)
 import(ggplot2)
 importFrom(stats,chisq.test)
 importFrom(stats,integrate)

---FILE: R/datasets.R---
@@ -91,10 +91,22 @@ generate_datasets.function_SBC_generator <- function(generator, n_datasets) {
   generated <- list()
   for(iter in 1:n_datasets){
     generator_output <- do.call(generator$f, generator$args)
-    #TODO check valid output
+    if(!is.list(generator_output) ||
+       is.null(generator_output$parameters) ||
+       is.null(generator_output$generated)) {
+      stop(""The generating function has to return a list with elements `parameters`
+      (that can be converted to `draws_rvars`) `generated`"")
+    }
+    # TODO add a validate_input generic that would let backends impose additional checks
+    # on generated data.
+
     # Directly converting to draws_matrix does not preserve arrays
     parameters_list[[iter]] <- posterior::as_draws_matrix(
       posterior::as_draws_rvars(generator_output$parameters))
+    if(posterior::ndraws(parameters_list[[iter]]) != 1) {
+      stop(""The `parameters` element of the generated data must contain only
+      a single draw"")
+    }
     generated[[iter]] <- generator_output$generated
   }
 
@@ -105,6 +117,30 @@ generate_datasets.function_SBC_generator <- function(generator, n_datasets) {
 
 #' Wrap a function the creates a complete dataset.
 #'
+#' This creates a very thin wrapper around the function and can store additional
+#' arguments, but does not do anything more..
+#'
+#' Running:
+#'
+#' ```r
+#' gen <- custom_SBC_generator(f, <<some other args>>)
+#' datasets <- generate_datasets(gen, n_datasets = my_n_datasets)
+#' ```
+#'
+#' is equivalent to just running
+#'
+#' ```r
+#' datasets <- f(<<some other args>>, n_datasets = my_n_datasets)
+#' ```
+#'
+#' So whenever you control the code calling `generate_datasets`,
+#' it usually makes more sense to just create an `SBC_datasets`
+#' object directly and avoid using `custom_SBC_generator` and `generate_datasets` at all.
+#' `custom_SBC_generator` can however be useful, when a code you
+#' do not control calls `generate_datasets` for you and the
+#' built-in generators do not provide you with enough flexibility.
+#'
+#'
 #' @param f function accepting at least an `n_datasets` argument and returning
 #' and `SBC_datasets` object
 #' @param ... Additional arguments passed to `f`
@@ -116,8 +152,9 @@ custom_SBC_generator <- function(f, ...) {
 
 #'@export
 generate_datasets.custom_SBC_generator <- function(generator, n_datasets) {
-  # TODO: check correct output
-  do.call(generator$f, combine_args(generator$args, list(n_datasets = n_datasets)))
+  res <- do.call(generator$f, combine_args(generator$args, list(n_datasets = n_datasets)))
+  res <- validate_SBC_datasets(res)
+  res
 }
 
 #' Create a brms generator.

---FILE: R/results.R---
@@ -121,9 +121,20 @@ compute_results <- function(datasets, backend,
 
   stats <- do.call(rbind, stats_list)
 
-  if(length(unique(stats$max_rank)) != 1) {
+  unique_max_ranks <- unique(stats$max_rank)
+  if(length(unique_max_ranks) != 1) {
     warning(""Differening max_rank across fits"")
   }
+
+  if(min(unique_max_ranks) < 50) {
+    warning(""Ranks were computed from fewer than 50 samples, the SBC diagnostics will have low "",
+            ""precision.\nYou may need to increase the number of samples from the backend and make sure that "",
+            ""the combination of thinning in the backend and `thin_ranks` is sensible.\n"",
+            ""Currently thin_ranks = "", thin_ranks, ""."")
+
+  }
+
+
   all_vars <- dplyr::summarise(
     dplyr::group_by(stats, run_id),
     all_vars = paste0(variable, collapse = "",""), .groups = ""drop"")

---FILE: man/custom_SBC_generator.Rd---
@@ -0,0 +1,33 @@
+% Generated by roxygen2: do not edit by hand
+% Please edit documentation in R/datasets.R
+\name{custom_SBC_generator}
+\alias{custom_SBC_generator}
+\title{Wrap a function the creates a complete dataset.}
+\usage{
+custom_SBC_generator(f, ...)
+}
+\arguments{
+\item{f}{function accepting at least an \code{n_datasets} argument and returning
+and \code{SBC_datasets} object}
+
+\item{...}{Additional arguments passed to \code{f}}
+}
+\description{
+This creates a very thin wrapper around the function.
+Running:
+}
+\details{
+\if{html}{\out{<div class=""r"">}}\preformatted{gen <- custom_SBC_generator(f, <<some other args>>)
+datasets <- generate_datasets(gen, n_datasets = my_n_datasets)
+}\if{html}{\out{</div>}}
+
+is equivalent to just running\if{html}{\out{<div class=""r"">}}\preformatted{datasets <- f(<<some other args>>, n_datasets = my_n_datasets)
+}\if{html}{\out{</div>}}
+
+So whenever you control the code calling \code{generate_datasets},
+it usually makes more sense to just create an \code{SBC_datasets}
+object directly and avoid using \code{custom_SBC_generator} and \code{generate_datasets} at all.
+\code{custom_SBC_generator} can however be useful, when a code you
+do not control calls \code{generate_datasets} for you and any of the
+buil-in generators does not provide you with enough flexibility.
+}

---FILE: man/function_SBC_generator.Rd---
@@ -0,0 +1,18 @@
+% Generated by roxygen2: do not edit by hand
+% Please edit documentation in R/datasets.R
+\name{function_SBC_generator}
+\alias{function_SBC_generator}
+\title{Generate datasets via a function that creates a single dataset.}
+\usage{
+function_SBC_generator(f, ...)
+}
+\arguments{
+\item{f}{function returning a list with elements \code{parameters}
+(prior draws, a list or anything that can be converted to \code{draws_rvars}) and
+\code{generated} (observed dataset, ready to be passed to backend)}
+
+\item{...}{Additional arguments passed to \code{f}}
+}
+\description{
+Generate datasets via a function that creates a single dataset.
+}

---FILE: vignettes/brms.Rmd---
@@ -7,7 +7,7 @@ output: html_notebook
 library(SBC)
 library(brms)
 library(ggplot2)
-options(brms.backend = ""cmdstanr"") 
+options(brms.backend = ""cmdstanr"")
 # options(brms.backend = ""rstan"") # Uncomment to use rstan instead
 
 # Using parallel processing
@@ -32,20 +32,21 @@ template_data = data.frame(y = rep(0, 15), x = rnorm(15))
 priors <- prior(normal(0,1), class = ""b"") +
   prior(normal(0,1), class = ""Intercept"") +
   prior(normal(0,1), class = ""sigma"")
-generator <- brms_SBC_generator(y ~ x, data = template_data, prior = priors, thin = 50 )
+generator <- brms_SBC_generator(y ~ x, data = template_data, prior = priors, thin = 50, warmup = 10000 )
 ```
 
 ```{r}
+set.seed(22133548)
 datasets <- generate_datasets(generator, 100)
 ```
 
 ```{r}
 # Reuse the compiled model and other info from the generator
-backend <- brms_SBC_backend_from_generator(generator, warmup = 500, iter = 1000, chains = 1,
+backend <- brms_SBC_backend_from_generator(generator, warmup = 500, iter = 1000, chains = 1, thin = 1,
                             init = 0.1)
 
 # More verbose alternative that results in exactly the same backend:
-# backend <- brms_SBC_backend(y ~ x, template_dataset = template_data, prior = priors, warmup = 500, iter = 1000, chains = 1,
+# backend <- brms_SBC_backend(y ~ x, template_dataset = template_data, prior = priors, warmup = 500, iter = 1000, chains = 1, thin = 1
 #                            init = 0.1)
 ```
 
@@ -132,8 +133,7 @@ priors_func <- prior(normal(0,1), class = ""b"") +
 
 backend_func <- brms_SBC_backend(y ~ x + (1 | group),  
                             prior = priors_func, chains = 1,
-                            template_dataset = datasets$generated[[1]],
-                            generator = n_dataset_generator)
+                            template_dataset = datasets$generated[[1]])
 
 ```
 
@@ -166,8 +166,7 @@ priors_func2 <- prior(normal(0,1), class = ""b"") +
 
 backend_func2 <- brms_SBC_backend(y ~ 0 + Intercept + x + (1 | group),  
                             prior = priors_func2, warmup = 500, iter = 1000, chains = 1,
-                            template_dataset = datasets$generated[[1]],
-                            generator = generator_func)
+                            template_dataset = datasets$generated[[1]])
 
 
 ```",True,True,Documentation / Formatting,7
hyunjimoon,SBC,5de38d4cceb244681c34b84e2e10f20aaacbe96b,martinmodrak,cerny.m@gmail.com,2021-08-02T13:13:22Z,martinmodrak,cerny.m@gmail.com,2021-08-02T13:13:22Z,"rstan support, fixes + more examples for brms",NAMESPACE;R/backends.R;R/brms-helpers.R;R/datasets.R;R/results.R;R/util.R;man/brms_SBC_backend.Rd;man/combine_args.Rd;tests/testthat/test-datasets.R;tests/testthat/test-utils.R;vignettes/bad_parametrization.Rmd;vignettes/brms.Rmd,True,True,True,False,378,102,480,"---FILE: NAMESPACE---
@@ -2,9 +2,13 @@
 
 S3method(""["",SBC_datasets)
 S3method(SBC_fit,brms_SBC_backend)
+S3method(SBC_fit,cmdstan_sample_SBC_backend)
+S3method(SBC_fit,rstan_sample_SBC_backend)
+S3method(SBC_fit_to_draws_matrix,CmdStanMCMC)
+S3method(SBC_fit_to_draws_matrix,default)
 S3method(generate_datasets,brms_SBC_generator)
+S3method(generate_datasets,custom_SBC_generator)
 S3method(generate_datasets,function_SBC_generator)
-S3method(generate_datasets,list_function_SBC_generator)
 S3method(length,SBC_datasets)
 S3method(plot_ecdf_diff,SBCWorkflow)
 S3method(plot_ecdf_diff,SBC_results)
@@ -21,14 +25,15 @@ export(calculate_rank_rvars)
 export(calculate_ranks_draws_matrix)
 export(cmdstan_sample_SBC_backend)
 export(compute_results)
+export(custom_SBC_generator)
 export(dist_summary)
 export(function_SBC_generator)
 export(generate_datasets)
-export(list_function_SBC_generator)
 export(plot_ecdf)
 export(plot_ecdf_diff)
 export(plot_hist)
 export(rank_summary)
+export(rstan_sample_SBC_backend)
 export(validate_SBC_datasets)
 import(ggplot2)
 importFrom(stats,chisq.test)

---FILE: R/backends.R---
@@ -3,42 +3,81 @@ SBC_fit <- function(backend, generated, cores) {
   UseMethod(""SBC_fit"")
 }
 
+#' @export
+SBC_fit_to_draws_matrix <- function(fit) {
+  UseMethod(""SBC_fit_to_draws_matrix"")
+}
+
+#' @export
+SBC_fit_to_draws_matrix.default <- function(fit) {
+  posterior::as_draws_matrix(fit)
+}
+
+#' @export
+rstan_sample_SBC_backend <- function(model, ...) {
+  stopifnot(inherits(model, ""stanmodel""))
+  args <- list(...)
+  unacceptable_params <- c(""data"", ""cores"")
+  if(any(names(args) %in% unacceptable_params)) {
+    stop(paste0(""Parameters "", paste0(""'"", unacceptable_params, ""'"", collapse = "", ""),
+                "" cannot be provided when defining a backend as they need to be set "",
+                ""by the SBC package""))
+  }
+  if(is.null(args$refresh)) {
+    args$refresh <- 0
+  }
+  structure(list(model = model, args = args), class = ""rstan_sample_SBC_backend"")
+}
+
+
+#' @export
+SBC_fit.rstan_sample_SBC_backend <- function(backend, generated, cores) {
+  do.call(rstan::sampling,
+          combine_args(list(object = backend$model,
+                 data = generated,
+                 cores = cores),
+            backend$args
+            ))
+}
+
 #' @export
 cmdstan_sample_SBC_backend <- function(model, ...) {
   stopifnot(inherits(model, ""CmdStanModel""))
-  #TODO: check data, cores not in args
-  structure(list(model = model, args = list(...)), class = ""cmdstan_sample_SBC_backend"")
+  if(length(model$exe_file()) == 0) {
+    stop(""The model has to be already compiled, call $compile() first."")
+  }
+  args <- list(...)
+  unacceptable_params <- c(""data"", ""parallel_chains "", ""cores"", ""num_cores"")
+  if(any(names(args) %in% unacceptable_params)) {
+    stop(paste0(""Parameters "", paste0(""'"", unacceptable_params, ""'"", collapse = "", ""),
+                "" cannot be provided when defining a backend as they need to be set "",
+                ""by the SBC package""))
+  }
+  if(is.null(args$refresh)) {
+    args$refresh <- 0
+  }
+  structure(list(model = model, args = args), class = ""cmdstan_sample_SBC_backend"")
 }
 
 #TODO add SBC_diagnostics generic to extract divergences etc.
 
+#' @export
 SBC_fit.cmdstan_sample_SBC_backend <- function(backend, generated, cores) {
   do.call(backend$model$sample,
-          c(list(refresh = 0),
-            backend$args,
+          combine_args(backend$args,
             list(
               data = generated,
               parallel_chains = cores)))
 }
 
-#' @export
-SBC_fit_to_draws_matrix <- function(fit) {
-  UseMethod(""SBC_fit_to_draws_matrix"")
-}
 
-SBC_fit_to_draws_matrix.default <- function(fit) {
-  posterior::as_draws_matrix(fit)
-}
 
+#' @export
 SBC_fit_to_draws_matrix.CmdStanMCMC <- function(fit) {
   fit$draws(format = ""draws_matrix"")
 }
 
 
-SBC_fit_to_draws_matrix.brmsfit <- function(fit) {
-  posterior::as_draws_matrix(fit$fit)
-}
-
 new_brms_SBC_backend <- function(compiled_model,
   args
 ) {
@@ -50,17 +89,29 @@ new_brms_SBC_backend <- function(compiled_model,
   structure(list(stan_backend = stan_backend, args = args), class = ""brms_SBC_backend"")
 }
 
+validate_brms_SBC_backend_args <- function(args) {
+  if(!is.null(args$algorithm) && args$algorithm != ""sampling"") {
+    stop(""Algorithms other than sampling not supported yet"")
+  }
+
+  unacceptable_params <- c(""data"", ""cores"", ""empty"")
+  if(any(names(args) %in% unacceptable_params)) {
+    stop(paste0(""Parameters "", paste0(""'"", unacceptable_params, ""'"", collapse = "", ""),
+                "" cannot be provided when defining a backend as they need to be set "",
+                ""by the SBC package""))
+  }
+}
+
 #' Build a brms backend.
 #'
 #' @param ... arguments passed to `brm`.
+#' @param template_dataset a representative dataset that can be used to generate code.
 #' @export
-brms_SBC_backend <- function(...) {
+brms_SBC_backend <- function(..., template_dataset) {
   args = list(...)
-  if(!is.null(args$algorithm) && args$algorithm != ""sampling"") {
-    stop(""Algorithms other than sampling not supported yet"")
-  }
+  validate_brms_SBC_backend_args(args)
 
-  stanmodel <- stanmodel_for_brms(...)
+  stanmodel <- stanmodel_for_brms(data = template_dataset, ...)
 
   new_brms_SBC_backend(stanmodel, args)
 }
@@ -69,7 +120,9 @@ brms_SBC_backend <- function(...) {
 #' @export
 brms_SBC_backend_from_generator <- function(generator, ...) {
   stopifnot(inherits(generator, ""brms_SBC_generator""))
-  args <- c(generator$args, list(...))
+  validate_brms_SBC_backend_args(list(...))
+
+  args <- combine_args(generator$args, list(...))
 
   if(!is.null(args$algorithm) && args$algorithm != ""sampling"") {
     stop(""Algorithms other than sampling not supported yet"")
@@ -91,3 +144,8 @@ SBC_fit.brms_SBC_backend <- function(backend, generated, cores) {
   brmsfit <- brmsfit_from_stanfit(stanfit, args_with_data)
   brmsfit
 }
+
+SBC_fit_to_draws_matrix.brmsfit <- function(fit) {
+  posterior::as_draws_matrix(fit$fit)
+}
+

---FILE: R/brms-helpers.R---
@@ -14,51 +14,64 @@ stanmodel_for_brms <- function(...) {
   }
   if(backend == ""cmdstanr"") {
     compiled_model <- cmdstanr::cmdstan_model(cmdstanr::write_stan_file(model_code))
+  } else if(backend == ""rstan"") {
+    compiled_model <- rstan::stan_model(model_code = model_code)
   } else {
-    stop(""Only cmdstanr backend currently supported"")
+    stop(""Unsupported backend: "", backend)
+
   }
 
   compiled_model
 }
 
-sampling_backend_from_stanmodel <- function(stanmodel, args) {
-
-  if(inherits(stanmodel, ""CmdStanModel"")) {
-    ignored_args <- c(""cores"", ""data"")
-    translated_args <- list()
-    for(old in names(args)) {
-      if(old == ""control"") {
-        if(!is.null(args$control$adapt_delta)) {
-          translated_args$adapt_delta = args$control$adapt_delta
-        }
-        if(!is.null(args$control$max_treedepth)) {
-          translated_args$max_depth = args$control$max_treedepth
-        }
-      } else if(old == ""iter"") {
-        if(is.null(args$warmup)) {
-          translated_args$iter_warmup = args$iter / 2
-          translated_args$iter_sampling = args$iter/ 2
-        } else {
-          translated_args$iter_warmup = args$warmup
-          translated_args$iter_sampling = args$iter - args$warmup
-        }
-      } else if(old == ""warmup"") {
-        if(is.null(args$iter)) {
-          translated_args$iter_warmup = args$warmup
-        } #If iter is present, warmup will be handled when handling iter
-      } else if(!(old %in% ignored_args)) {
+translate_rstan_args_to_cmdstan <- function(args, include_unrecognized = TRUE) {
+  ignored_args <- c(""cores"", ""data"")
+  recognized_but_unchanged <- c(""thin"", ""refresh"")
+  translated_args <- list()
+  for(old in names(args)) {
+    if(old == ""control"") {
+      if(!is.null(args$control$adapt_delta)) {
+        translated_args$adapt_delta = args$control$adapt_delta
+      }
+      if(!is.null(args$control$max_treedepth)) {
+        translated_args$max_depth = args$control$max_treedepth
+      }
+    } else if(old == ""iter"") {
+      if(is.null(args$warmup)) {
+        translated_args$iter_warmup = args$iter / 2
+        translated_args$iter_sampling = args$iter/ 2
+      } else {
+        translated_args$iter_warmup = args$warmup
+        translated_args$iter_sampling = args$iter - args$warmup
+      }
+    } else if(old == ""warmup"") {
+      if(is.null(args$iter)) {
+        translated_args$iter_warmup = args$warmup
+      } #If iter is present, warmup will be handled when handling iter
+    } else if(!(old %in% ignored_args)) {
+      if(include_unrecognized || old %in% recognized_but_unchanged) {
         translated_args[[old]] = args[[old]]
       }
     }
+  }
+  translated_args
+}
+
+sampling_backend_from_stanmodel <- function(stanmodel, args) {
 
-    do.call(cmdstan_sample_SBC_backend, c(list(model = stanmodel), translated_args))
-  } else if(inherits(stanomodel, ""stanmodel"")) {
-    stop(""rstan backend not supported yet"")
+  if(inherits(stanmodel, ""CmdStanModel"")) {
+    translated_args <- translate_rstan_args_to_cmdstan(args)
+
+    do.call(cmdstan_sample_SBC_backend, combine_args(translated_args, list(model = stanmodel)))
+  } else if(inherits(stanmodel, ""stanmodel"")) {
+    do.call(rstan_sample_SBC_backend, combine_args(args,list(model = stanmodel)))
+  } else {
+    stop(""stanmodel does not inherit from `stanmodel` or `CmdStanModel`"")
   }
 }
 
 brmsfit_from_stanfit <- function(fit, brmsargs) {
-  fit_brms <- do.call(brms::brm, c(list(empty = TRUE), brmsargs))
+  fit_brms <- do.call(brms::brm, combine_args(brmsargs, list(empty = TRUE)))
   if(inherits(fit, ""CmdStanMCMC"")) {
     fit_brms$fit <- rstan::read_stan_csv(fit$output_files())
   } else {

---FILE: R/datasets.R---
@@ -61,13 +61,13 @@ generate_datasets <- function(generator, n_datasets) {
 }
 
 #'@export
-list_function_SBC_generator <- function(f, ...) {
+function_SBC_generator <- function(f, ...) {
   stopifnot(is.function(f))
-  structure(list(f = f, args = list(...)), class = ""list_function_SBC_generator"")
+  structure(list(f = f, args = list(...)), class = ""function_SBC_generator"")
 }
 
 #'@export
-generate_datasets.list_function_SBC_generator <- function(generator, n_datasets) {
+generate_datasets.function_SBC_generator <- function(generator, n_datasets) {
   parameters_list <- list()
   generated <- list()
   for(iter in 1:n_datasets){
@@ -85,15 +85,15 @@ generate_datasets.list_function_SBC_generator <- function(generator, n_datasets)
 }
 
 #'@export
-function_SBC_generator <- function(f, ...) {
+custom_SBC_generator <- function(f, ...) {
   stopifnot(is.function(f))
-  structure(list(f = f, args = list(...)), class = ""function_SBC_generator"")
+  structure(list(f = f, args = list(...)), class = ""custom_SBC_generator"")
 }
 
 #'@export
-generate_datasets.function_SBC_generator <- function(generator, n_datasets) {
+generate_datasets.custom_SBC_generator <- function(generator, n_datasets) {
   # TODO: check correct output
-  do.call(generator$f, c(list(n_datasets = n_datasets), generator$args))
+  do.call(generator$f, combine_args(generator$args, list(n_datasets = n_datasets)))
 }
 
 #' Create a brms generator.
@@ -130,10 +130,66 @@ brms_SBC_generator <- function(..., generate_lp = TRUE) {
 
 #' @export
 generate_datasets.brms_SBC_generator <- function(generator, n_datasets) {
-  #TODO pass args for chains, .... to sampling
-  prior_fit <- generator$compiled_model$sample(data = generator$model_data,
-                        iter_warmup = 1000, iter_sampling = n_datasets,
-                        chains = 1)
+  #TODO pass args for control, warmup, .... to sampling
+  if(inherits(generator$compiled_model, ""CmdStanModel"")) {
+      args_for_fitting <- translate_rstan_args_to_cmdstan(generator$args, include_unrecognized = FALSE)
+      args_for_fitting$data <- generator$model_data
+
+      if(is.null(args_for_fitting$chains)) {
+        args_for_fitting$chains <- 1
+      }
+      if(is.null(args_for_fitting$thin)) {
+        args_for_fitting$thin <- 1
+      }
+
+
+      args_for_fitting$iter_sampling <- ceiling(n_datasets / args_for_fitting$chains) * args_for_fitting$thin
+
+      args_for_fitting
+      prior_fit <- do.call(generator$compiled_model$sample,
+                           args_for_fitting)
+
+
+      # Change once https://github.com/stan-dev/cmdstanr/issues/205
+      # is resolved
+      summ <- prior_fit$summary() # Can trigger warnings for treedepth/divergent ...
+      max_rhat <- max(summ$rhat)
+      if(max_rhat > 1.01) {
+        message(""Warning: Some rhats are > 1.01 indicating the prior was not explored well.\n"",
+                ""The highest rhat is "", round(max_rhat, 2),"" for "", summ$variable[which.max(summ$rhat)],
+                ""\nConsider adding warmup iterations (via 'warmup' argument)."")
+      }
+      min_ess <- min(summ$ess_bulk)
+      if(min_ess < n_datasets / 2) {
+        message(""Warning: Bulk effective sample size for some parameters is less than half the number of datasets.\n"",
+                ""The lowest ESS_bulk/n_datasets is "", round(min_ess / n_datasets, 2),"" for "", summ$variable[which.min(summ$ess_bulk)],
+                ""\nConsider increased thinning  (via 'thin' argument) ."")
+      }
+
+  } else if (inherits(generator$compiled_model, ""stanmodel"")) {
+    args_to_pass <- c(""thin"", ""warmup"", ""control"", ""refresh"")
+    args_for_fitting <- c(
+      list(object = generator$compiled_model,
+           data = generator$model_data,
+           chains = 1
+      ),
+      generator$args[intersect(args_to_pass, names(generator$args))]
+    )
+
+    if(is.null(args_for_fitting$warmup)) {
+      args_for_fitting$warmup <- 1000
+    }
+    if(is.null(args_for_fitting$chains)) {
+      args_for_fitting$chains <- 1
+    }
+
+    args_for_fitting$iter <- ceiling(n_datasets / args_for_fitting$chains) * args_for_fitting$thin
+
+    prior_fit <- do.call(rstan::sampling, args_for_fitting)
+
+  } else {
+    stop(""Invalid generator$compiled_model"")
+  }
 
   prior_fit_brms <- brmsfit_from_stanfit(prior_fit, generator$args)
 

---FILE: R/results.R---
@@ -12,7 +12,6 @@ compute_results <- function(datasets, backend, cores = getOption(""mc.cores"", 1),
   warned_vars <- FALSE
   for(i in 1:length(datasets)) {
     fits[[i]] <- SBC_fit(backend, datasets$generated[[i]], cores = cores)
-    # TODO consider just using as_draws and not insist on a specific format until needed
     fit_matrix <- SBC_fit_to_draws_matrix(fits[[i]])
     missing_vars <- setdiff(posterior::variables(datasets$parameters), posterior::variables(fit_matrix))
     if(length(missing_vars) > 0 && !warned_vars) {

---FILE: R/util.R---
@@ -300,3 +300,19 @@ access_element_by_index <- function(data, index_list){
     return(cbind(unlist(index_list)))
   }
 }
+
+
+#' Combine two named lists and overwrite elements with the same name
+#' using the value from args2
+combine_args <- function(args1, args2) {
+  if(is.null(names(args1)) || is.null(names(args2))) {
+    c(args1, args2)
+  } else {
+    shared <- intersect(names(args1), names(args2))
+    shared <- setdiff(shared, """")
+    for(s in shared) {
+      args1[[s]] <- args2[[s]]
+    }
+    c(args1, args2[!(names(args2) %in% shared)])
+  }
+}

---FILE: man/brms_SBC_backend.Rd---
@@ -4,10 +4,12 @@
 \alias{brms_SBC_backend}
 \title{Build a brms backend.}
 \usage{
-brms_SBC_backend(...)
+brms_SBC_backend(..., template_dataset)
 }
 \arguments{
 \item{...}{arguments passed to \code{brm}.}
+
+\item{template_dataset}{a representative dataset that can be used to generate code.}
 }
 \description{
 Build a brms backend.

---FILE: man/combine_args.Rd---
@@ -0,0 +1,13 @@
+% Generated by roxygen2: do not edit by hand
+% Please edit documentation in R/util.R
+\name{combine_args}
+\alias{combine_args}
+\title{Combine two named lists and overwrite elements with the same name
+using the value from args2}
+\usage{
+combine_args(args1, args2)
+}
+\description{
+Combine two named lists and overwrite elements with the same name
+using the value from args2
+}

---FILE: tests/testthat/test-datasets.R---
@@ -9,7 +9,7 @@ test_that(""Generating datasets via functions"", {
   }
 
   res <- generate_datasets(
-    list_function_SBC_generator(list_function, N = 10),
+    function_SBC_generator(list_function, N = 10),
     n_datasets = 7)
 
   expect_true(length(res) == 7)
@@ -23,11 +23,11 @@ test_that(""Generating datasets via functions"", {
       res[base_indices[rep(1:length(base_indices), length.out = n_datasets)]]
     }
 
-  res_direct1 <- generate_datasets(function_SBC_generator(direct_func),  n_datasets = 7)
+  res_direct1 <- generate_datasets(custom_SBC_generator(direct_func),  n_datasets = 7)
 
   expect_equal(res, res_direct1, check.attributes = FALSE)
 
-  res_direct2 <- generate_datasets(function_SBC_generator(direct_func, base_indices = 1:3),
+  res_direct2 <- generate_datasets(custom_SBC_generator(direct_func, base_indices = 1:3),
   n_datasets = 5)
 
   expect_identical(res[c(1,2,3,1,2)], res_direct2)
@@ -45,7 +45,7 @@ test_that(""subsetting datasets"", {
   }
 
   res <- generate_datasets(
-    list_function_SBC_generator(list_function, N = 10),
+    function_SBC_generator(list_function, N = 10),
     n_datasets = 7)
 
   res_subs <- res[3:5]

---FILE: tests/testthat/test-utils.R---
@@ -0,0 +1,22 @@
+test_that(""combine_args"", {
+  expect_identical(combine_args(list(a = 1, b = 2, c = 3),
+                                list(b = ""no"", d = 4)),
+                   list(a = 1, b = ""no"", c = 3, d = 4))
+
+  expect_identical(combine_args(list(1, 2),
+                                list(c = 3, d = 4)),
+                   list(1, 2, c = 3, d = 4))
+
+  expect_identical(combine_args(list(1, b = 2),
+                                list(c = 3, d = 4)),
+                   list(1, b = 2, c = 3, d = 4))
+
+  expect_identical(combine_args(list(1, b = 2, c = 3),
+                                list(13, b = ""ugh"", e = 5)),
+                   list(1, b = ""ugh"", c = 3, 13, e = 5))
+
+  expect_identical(combine_args(list(a = 1, b = 2, c = 3),
+                                list(c = ""ugh"", a = ""no"")),
+                   list(a = ""no"", b = 2, c = ""ugh""))
+
+})

---FILE: vignettes/bad_parametrization.Rmd---
@@ -4,7 +4,15 @@ output: html_notebook
 ---
 
 ```{r setup, include = FALSE}
-library(SBC); library(cmdstanr)
+library(SBC); 
+use_cmdstanr <- TRUE # Set to false to use rstan instead
+
+if(use_cmdstanr) {
+  library(cmdstanr)
+} else {
+  library(rstan)
+}
+
 ```
 
 
@@ -33,14 +41,20 @@ model {
   scale ~ lognormal(0, 1.5);
 }
 ""
+iter_warmup <- 500
+iter_sampling <- 500
 
-model_1 <- cmdstan_model(write_stan_file(stan_code_1))
-
+if(use_cmdstanr) {
+  model_1 <- cmdstan_model(write_stan_file(stan_code_1))
 
+  sbc_backend_1 <- cmdstan_sample_SBC_backend(
+    model_1, iter_warmup = iter_warmup, iter_sampling = iter_sampling, chains = 2)
+} else {
+  model_1 <- stan_model(model_code = stan_code_1)
 
-sbc_backend_1 <- cmdstan_sample_SBC_backend(model_1, 
-                                            iter_warmup = 500, iter_sampling = 200, chains = 1)
-
+  sbc_backend_1 <- rstan_sample_SBC_backend(
+    model_1, iter = iter_sampling + iter_warmup, warmup = iter_warmup, chains = 2)
+}
 
 ```
 
@@ -72,7 +86,7 @@ generator_func <- function(N) {
 
 N <- 40
 datasets <- generate_datasets(
-  list_function_SBC_generator(generator_func, N = N), 
+  function_SBC_generator(generator_func, N = N), 
   n_datasets)
 
 ```
@@ -113,10 +127,17 @@ model {
 }
 ""
 
-model_2 <- cmdstan_model(write_stan_file(stan_code_2))
+if(use_cmdstanr) {
+  model_2 <- cmdstan_model(write_stan_file(stan_code_2))
 
-sbc_backend_2 <- cmdstan_sample_SBC_backend(model_2, 
-                                            iter_warmup = 500, iter_sampling = 200, chains = 1)
+  sbc_backend_2 <- cmdstan_sample_SBC_backend(
+    model_2, iter_warmup = iter_warmup, iter_sampling = iter_sampling, chains = 2)
+} else {
+  model_2 <- stan_model(model_code = stan_code_2)
+
+  sbc_backend_2 <- rstan_sample_SBC_backend(
+    model_2, iter = iter_sampling + iter_warmup, warmup = iter_warmup, chains = 2)
+}
 
 
 ```
@@ -126,7 +147,7 @@ sbc_backend_2 <- cmdstan_sample_SBC_backend(model_2,
 results2 <- compute_results(datasets, sbc_backend_2)
 ```
 
-No obvious problems here, but obviously if we wanted to be sure, we should have ran a lot more simulations.
+No obvious problems here, but if we wanted to be sure, we should have ran a lot more simulations.
 
 ```{r}
 plot_hist(results2$ranks, par = ""shape"")

---FILE: vignettes/brms.Rmd---
@@ -3,11 +3,12 @@ title: ""SBC for brms models""
 output: html_notebook
 ---
 
-```{r}
+```{r setup}
 library(SBC)
 library(brms)
 library(ggplot2)
 options(brms.backend = ""cmdstanr"")
+#options(brms.backend = ""rstan"") # Uncomment to use rstan
 ```
 
 ```{r}
@@ -29,7 +30,7 @@ backend <- brms_SBC_backend_from_generator(generator, warmup = 500, iter = 1000,
                             init = 0.1)
 
 # More verbose alternative:
-#backend <- brms_SBC_backend(y ~ x, data = data, prior = priors, warmup = 500, iter = 1000, chains = 1,
+#backend <- brms_SBC_backend(y ~ x, template_dataset = data, prior = priors, warmup = 500, iter = 1000, chains = 1,
 #                            init = 0.1)
 ```
 
@@ -43,41 +44,111 @@ for(p in colnames(results$ranks)) {
 }
 ```
 
-## A failing model
+## Using custom simulation code
+
+
+Also allows to have different covariate values for each dataset, potentially improving sensitivity.
+
+Let's take a Gaussian model with a single varying intercept.
 
 ```{r}
-data_fail = data.frame(y = rep(0, 15), x = rnorm(15), id = 1:15, id2 = 1:15)
-priors_fail <- prior(normal(0,1), class = ""b"") +
-  prior(normal(0,10), class = ""Intercept"") +
-  prior(normal(0,10), class = ""sigma"") +
-  prior(normal(0,10), class = ""sd"")
+generate_single_dataset <- function(N, K) {
+  stopifnot(K <= N)
+  x <- rnorm(N) + 10
+  
+  group <- sample(1:K, size = K, replace = TRUE)
+  # Ensure all groups are actually present
+  if(length(unique(group)) < K) {
+    group[1:K] <- 1:K
+  }
+  
+  b_Intercept <- rnorm(1, 5, 1)   
+  b_x <- rnorm(1, 0, 1)
+  
+  sd_group__Intercept <- abs(rnorm(1, 0, 0.75))
+  r_group <- matrix(rnorm(K, 0, sd_group__Intercept), 
+                 nrow = K, ncol = 1,
+                 dimnames = list(1:K, ""Intercept""))
+  
+  sigma <- abs(rnorm(1, 0, 3))
+  
+  predictor <- b_Intercept + x * b_x + r_group[group]
+  y <- rnorm(N, predictor, sigma)
+  
+  list(
+    parameters = list(
+      b_Intercept = b_Intercept,
+      b_x = b_x,
+      sd_group__Intercept = sd_group__Intercept,
+      r_group = r_group,
+      sigma = sigma
+    ),
+    generated = data.frame(y = y, x = x, group = group)
+  )
+}
+
+generator_func <- function_SBC_generator(generate_single_dataset, N = 12, K = 3)
+```
 
 
-generator_fail <- brms_SBC_generator(y ~ x + (1 | id)  + (1 | id2), data = data_fail, prior = priors_fail)
+```{r}
+set.seed(12239755)
+datasets_func <- generate_datasets(generator_func, 100)
 ```
 
 ```{r}
-datasets_fail <- generate_datasets(generator_fail, 40)
+priors_func <- prior(normal(0,1), class = ""b"") +
+  prior(normal(5,1), class = ""Intercept"") +
+  prior(normal(0,5), class = ""sigma"") +
+  prior(normal(0,0.75), class = ""sd"")
+
+
+backend_func <- brms_SBC_backend(y ~ x + (1 | group),  
+                            prior = priors_func, chains = 1,
+                            template_dataset = datasets$generated[[1]],
+                            generator = generator_func)
+
 ```
 
 ```{r}
-# Reuse the compiled model and other info from the generator
-backend_fail <- brms_SBC_backend_from_generator(generator_fail, warmup = 500, iter = 1000, chains = 1,
-                            init = 0.1)
+results_func <- compute_results(datasets_func, backend_func, thin_ranks = 10)
+```
+
+```{r}
+for(p in colnames(results_func$ranks)) {
+  print(plot_ecdf_diff(results_func, p) + ggtitle(p))
+}
+```
+
+What happened is that `brms` by default centers all the predictors, which changes the
+numerical values of the intercept (but not other terms) using `0 + Intercept` syntax avoids this. 
+
+
+```{r}
+priors_func2 <- prior(normal(0,1), class = ""b"") +
+  prior(normal(5,1), class = ""b"", coef = ""Intercept"") +
+  prior(normal(0,5), class = ""sigma"") +
+  prior(normal(0,0.75), class = ""sd"")
+
+
+backend_func2 <- brms_SBC_backend(y ~ 0 + Intercept + x + (1 | group),  
+                            prior = priors_func2, warmup = 500, iter = 1000, chains = 1,
+                            template_dataset = datasets_func$generated[[1]],
+                            generator = generator_func)
+
 
-# More verbose alternative:
-#backend <- brms_SBC_backend(y ~ x, data = data, prior = priors, warmup = 500, iter = 1000, chains = 1,
-#                            init = 0.1)
 ```
 
 ```{r}
-results_fail <- compute_results(datasets_fail, backend_fail, thin_ranks = 5)
+results_func2 <- compute_results(datasets_func, backend_func2, thin_ranks = 10)
 ```
 
-We see a problem with `sigma`. Notably the problem is also visible when looking at `lp__` (which we would expect to often manifest problems if at least one of the parameters has problems)
+We see that this results in non-problematic univariate checks.
 
 ```{r}
-for(p in c(""sigma"", ""lp__"")) {
-  print(plot_ecdf_diff(results_fail, p) + ggtitle(p))
+for(p in colnames(results_func2$ranks)) {
+  print(plot_ecdf_diff(results_func2, p) + ggtitle(p))
 }
 ```
+
+",True,True,Rendering / Conversion,6
hyunjimoon,SBC,a5f1ef1e9c70531950874c9a111875051eccc8c5,hyunjimoon,mhj1667@gmail.com,2021-07-20T09:19:50Z,hyunjimoon,mhj1667@gmail.com,2021-07-20T09:19:50Z,bug fix,R/workflow.R,False,True,True,False,126,127,253,"---FILE: R/workflow.R---
@@ -5,142 +5,141 @@ BRMSFIT_MODEL_CLASS_NAME <- ""brmsfit""
 #' R6 class representing a fluid SBC workflow, boasting a highly customizable pipeline and supports intermediate updates
 #' @export
 SBCWorkflow <- R6::R6Class(""SBCWorkflow"",
-  public = list(
-    #' @field cmdstan_model A CmdStanModel object used for SBC
-    #' @field brms_model_fit A brmsfit object used for SBC
-    #' @field sim_function If using CmdStanModel, a simulator function, which should return simulated prior and data samples for SBC. Please refer \code{SBCWorkflow$initialize()} for details.
-    #' @field calculated_ranks A named list of vectors which contained calculated ranks, or NULL if not calculated.
-    #' @field prior_samples A posterior::draws_rvars of dimension(n_iterations=1, n_chains=n_sbc_iterations, n_variables=n_variables) which stores prior samples
-    #' @field simulated_y A posterior::draws_rvars of dimension(n_iterations=n_simulated_y, n_chains=n_sbc_iterations, n_variables=1), which stores simulated y as ""y""
-    #' @field posterior_samples A posterior::draws_Rvars of dimension(n_iterations=n_posterior_samples, n_chains=n_sbc_iterations, n_variables=n_variables), which stores fitted posterior samples
-    #' @field thin_factor Non-negative integer representing posterior thinning interval
-    cmdstan_model = NULL,
-    brms_model_fit = NULL,
-    sim_function = NULL,
-    calculated_ranks = NULL,
-    prior_samples = NULL,  #  written on simulate
-    simulated_y = NULL,  #  written on simulate
-    posterior_samples = NULL, # written on fit_model
-    thin_factor = NULL, # type is integer. written on initialize and fit_model
+ public = list(
+   #' @field cmdstan_model A CmdStanModel object used for SBC
+   #' @field brms_model_fit A brmsfit object used for SBC
+   #' @field sim_function If using CmdStanModel, a simulator function, which should return simulated prior and data samples for SBC. Please refer \code{SBCWorkflow$initialize()} for details.
+   #' @field calculated_ranks A named list of vectors which contained calculated ranks, or NULL if not calculated.
+   #' @field prior_samples A posterior::draws_rvars of dimension(n_iterations=1, n_chains=n_sbc_iterations, n_variables=n_variables) which stores prior samples
+   #' @field simulated_y A posterior::draws_rvars of dimension(n_iterations=n_simulated_y, n_chains=n_sbc_iterations, n_variables=1), which stores simulated y as ""y""
+   #' @field posterior_samples A posterior::draws_Rvars of dimension(n_iterations=n_posterior_samples, n_chains=n_sbc_iterations, n_variables=n_variables), which stores fitted posterior samples
+   #' @field thin_factor Non-negative integer representing posterior thinning interval
+   cmdstan_model = NULL,
+   brms_model_fit = NULL,
+   sim_function = NULL,
+   calculated_ranks = NULL,
+   prior_samples = NULL,  #  written on simulate
+   simulated_y = NULL,  #  written on simulate
+   posterior_samples = NULL, # written on fit_model
+   thin_factor = NULL, # type is integer. written on initialize and fit_model
 
-    #' R6 Initializer for SBCWorkflow
-    #'
-    #' @param model_obj A CmdStanModel or brmsfit object to use for fitting data.
-    #' @param sim_function If using CmdStanModel, a simulator function. The function must return a
-    #'   named list with elements \code{parameters} and \code{generated}.
-    #'   Parameters should be a named list containing prior samplers for
-    #'   parameters. Generated must be a 1 dimensional vector containing
-    #'   simulated y data generated from the \code{parameters} samples.
-    #'
-    #' @return None
-    initialize = function(model_obj, sim_function){
-      if(!is.na(match(CMDSTAN_MODEL_CLASS_NAME, class(model_obj)))){
-        if(missing(sim_function)){
-          stop(""If a cmdstan model is given, sim_function must also be supplied."")
-        }
-        self$cmdstan_model <- model_obj
-        self$sim_function <- sim_function
-      }
-      else if(!is.na(match(BRMSFIT_MODEL_CLASS_NAME, class(model_obj)))){
-        if(!missing(sim_function)){
-          warning(""A brm model has been supplied, but sim_function was also included in arguments. It will be ignored."")
-        }
-        self$brms_model_fit <- model_obj
-      }
-      else{
-        stop(paste(""The specified model object is neither a"", CMDSTAN_MODEL_CLASS_NAME, ""or a"", BRMSFIT_MODEL_CLASS_NAME, "". Please recheck your model object.""))
-      }
-    },
+   #' R6 Initializer for SBCWorkflow
+   #'
+   #' @param model_obj A CmdStanModel or brmsfit object to use for fitting data.
+   #' @param sim_function If using CmdStanModel, a simulator function. The function must return a
+   #'   named list with elements \code{parameters} and \code{generated}.
+   #'   Parameters should be a named list containing prior samplers for
+   #'   parameters. Generated must be a 1 dimensional vector containing
+   #'   simulated y data generated from the \code{parameters} samples.
+   #'
+   #' @return None
+   initialize = function(model_obj, sim_function){
+     if(!is.na(match(CMDSTAN_MODEL_CLASS_NAME, class(model_obj)))){
+       if(missing(sim_function)){
+         stop(""If a cmdstan model is given, sim_function must also be supplied."")
+       }
+       self$cmdstan_model <- model_obj
+       self$sim_function <- sim_function
+     }
+     else if(!is.na(match(BRMSFIT_MODEL_CLASS_NAME, class(model_obj)))){
+       if(!missing(sim_function)){
+         warning(""A brm model has been supplied, but sim_function was also included in arguments. It will be ignored."")
+       }
+       self$brms_model_fit <- model_obj
+     }
+     else{
+       stop(paste(""The specified model object is neither a"", CMDSTAN_MODEL_CLASS_NAME, ""or a"", BRMSFIT_MODEL_CLASS_NAME, "". Please recheck your model object.""))
+     }
+   },
 
-    #' Sample \eqn{\tilde{\theta} \sim P(\theta)} and \eqn{\tilde{y} \sim P(\tilde{y}) | \tilde{\theta} using \code{sim_function}
-    #'
-    #' @param n_sbc_iterations Number of prior sample sets to generate. Equates to number of SBC iterations
-    #' @param ... Additional arguments to be passed to \code{sim_function}
-    simulate = function(n_sbc_iterations, ...){  # number of simulation draws should be at least 1000
-      if(!is.null(self$brms_model_fit)){
-        #prior_sampler <- update(self$model_obj, sample_prior=""only"", chains=1, iter=n * 2, warmup = n)
-      }
-      else if(!is.null(self$cmdstan_model)){
-        self$prior_samples <- draws_rvars_list[[""parameters""]]
-        self$simulated_y <- draws_rvars_list[[""generated""]]
-      }
-      else{
-        stop(""No valid model specified for the workflow. Please check that your model is a valid brmsfit or a CmdStanModel object."")
-      }
-    },
+   #' Sample \eqn{\tilde{\theta} \sim P(\theta)} and \eqn{\tilde{y} \sim P(\tilde{y}) | \tilde{\theta} using \code{sim_function}
+   #'
+   #' @param n_sbc_iterations Number of prior sample sets to generate. Equates to number of SBC iterations
+   #' @param ... Additional arguments to be passed to \code{sim_function}
    simulate = function(n_sbc_iterations, param = TRUE,  ...){  # number of simulation draws should be at least 1000
+     if(!is.null(self$brms_model_fit)){
+       #prior_sampler <- update(self$model_obj, sample_prior=""only"", chains=1, iter=n * 2, warmup = n)
+     }
+     else if(!is.null(self$cmdstan_model)){
        draws_rvars_list <- do.call(generator_to_draws_rvars, list(self$sim_function, n_sbc_iterations, param = param, ...))
+       self$prior_samples <- draws_rvars_list[[""parameters""]]
+       self$simulated_y <- draws_rvars_list[[""generated""]]
+     }
+     else{
+       stop(""No valid model specified for the workflow. Please check that your model is a valid brmsfit or a CmdStanModel object."")
+     }
+   },
 
-    #' Sample \eqn{\widehat{\theta} \sim P(\widehat{\theta} | \tilde{y})} using the stan model.
-    #'
-    #' @param sample_iterations Number of sampling iterations. Equates to number of posterior samples
-    #' @param warmup_iterations Number of warmup iteratioins.
-    #' @param data List specifying data to be passed to the model. Note that \code{y} will be replaced with simulated \code{y} samples.
-    #' @param thin_factor Non-negative integer in which thinning should be applied. 1 equates to no thinning being done.
-    #'
-    #' @return A list of named lists containing posterior samples for each parameter.
-    fit_model = function(sample_iterations, warmup_iterations, data=list(), thin_factor=3){
-      self$thin_factor <- thin_factor
-      if(is.null(self$simulated_y)){
-        stop(""There are no simulated data available. Please run SBCWorkflow$simulate() first "")
-      }
-      # if(posterior::nchains(self$prior_samples) != posterior::nchains(self$simulated_y)){
-      #   stop(""The number of simulated prior and data do not match. Please rerun SBCWorkflow$simulate() and if using CmdStan, make sure your generator is well formed."")
-      # }
+   #' Sample \eqn{\widehat{\theta} \sim P(\widehat{\theta} | \tilde{y})} using the stan model.
+   #'
+   #' @param sample_iterations Number of sampling iterations. Equates to number of posterior samples
+   #' @param warmup_iterations Number of warmup iteratioins.
+   #' @param data List specifying data to be passed to the model. Note that \code{y} will be replaced with simulated \code{y} samples.
+   #' @param thin_factor Non-negative integer in which thinning should be applied. 1 equates to no thinning being done.
+   #'
+   #' @return A list of named lists containing posterior samples for each parameter.
+   fit_model = function(sample_iterations, warmup_iterations, data=list(), thin_factor=3){
+     self$thin_factor <- thin_factor
+     if(is.null(self$simulated_y)){
+       stop(""There are no simulated data available. Please run SBCWorkflow$simulate() first "")
+     }
+     # if(posterior::nchains(self$prior_samples) != posterior::nchains(self$simulated_y)){
+     #   stop(""The number of simulated prior and data do not match. Please rerun SBCWorkflow$simulate() and if using CmdStan, make sure your generator is well formed."")
+     # }
 
 
-      if(!is.null(self$brms_model_fit)){
-        #brms
-      }
-      else if(!is.null(self$cmdstan_model)){
-        sbc_iterations <- posterior::nchains(self$prior_samples)
-        posterior_draws_rvars <- cmdstan_fits_to_draws_rvars(self$cmdstan_model, sbc_iterations, data, self$simulated_y, iter_sampling=sample_iterations * thin_factor, iter_warmup = warmup_iterations, chains=1, thin=thin_factor)
-        self$posterior_samples <- posterior_draws_rvars
-      }
+     if(!is.null(self$brms_model_fit)){
+       #brms
+     }
+     else if(!is.null(self$cmdstan_model)){
+       sbc_iterations <- posterior::nchains(self$prior_samples)
+       posterior_draws_rvars <- cmdstan_fits_to_draws_rvars(self$cmdstan_model, sbc_iterations, data, self$simulated_y, iter_sampling=sample_iterations * thin_factor, iter_warmup = warmup_iterations, chains=1, thin=thin_factor)
+       self$posterior_samples <- posterior_draws_rvars
+     }
 
-      posterior_draws_rvars
-    },
+     posterior_draws_rvars
+   },
 
-    #' Calculate rank statistics for a given parameter name
-    #'
-    #' @param param list of parameter names to calculate. If not given, calculate for all available parameters.
-    #'
-    calculate_rank = function(param=NULL){
-      if(is.null(self$posterior_samples)){
-        stop(""There are no posterior samples available. Please run SBCWorkflow$fit_model() first."")
-      }
-      if(is.null(param)){
-        param <- posterior::variables(prior)
-      }
-      calculate_rank_draws_rvars(self$prior_samples, self$posterior_samples)
+   #' Calculate rank statistics for a given parameter name
+   #'
+   #' @param param list of parameter names to calculate. If not given, calculate for all available parameters.
+   #'
+   calculate_rank = function(param=NULL){
+     if(is.null(self$posterior_samples)){
+       stop(""There are no posterior samples available. Please run SBCWorkflow$fit_model() first."")
+     }
+     if(is.null(param)){
+       param <- posterior::variables(prior)
+     }
+     calculate_rank_draws_rvars(self$prior_samples, self$posterior_samples)
 
-      # ranks <- array(rep(0, n_iters * n_params), dim=c(n_iters, n_params))
-      # dimnames(ranks)[2] <- list(names(decomposed_prior))
-      #
-      # for(i in 1:n_iters){
-      #   prior <- self$prior_samples[[i]]
-      #   decomposed_prior <- decompose_structure_to_par_list(prior)
-      #
-      #   for(j in 1:n_params){
-      #     regex_res <- gregexpr(""(?<=\\[)(.+)(?=\\])"", param[[j]], perl = TRUE)[[1]]
-      #     capture_start <- attr(regex_res, ""capture.start"")
-      #     capture_length <- attr(regex_res, ""capture.length"")
-      #     if(capture_start != -1){
-      #       index <- as.integer(unlist(substr(param[[j]], capture_start, capture_start + capture_length - 1)))
-      #       ranks[i, param[[j]]] <- sum(self$posterior_samples[[i]][[param[[j]]]] < access_element_by_index(self$prior_samples[[i]][[base_param_names[[j]]]], index))
-      #     }
-      #     else{
-      #       t1 <- self$posterior_samples[[i]][[param[[j]]]]
-      #       t2 <- self$prior_samples[[i]][[param[[j]]]]
-      #       #ranks[i, param[[j]]] <- sum(self$posterior_samples[[i]][[param[[j]]]] < self$prior_samples[[i]][[param[[j]]]])
-      #       ranks[i, param[[j]]] <- sum(t1 < t2)
-      #     }
-      #   }
-      # }
-      # return(ranks)
-    },
-    add_steps = function(N){
+     # ranks <- array(rep(0, n_iters * n_params), dim=c(n_iters, n_params))
+     # dimnames(ranks)[2] <- list(names(decomposed_prior))
+     #
+     # for(i in 1:n_iters){
+     #   prior <- self$prior_samples[[i]]
+     #   decomposed_prior <- decompose_structure_to_par_list(prior)
+     #
+     #   for(j in 1:n_params){
+     #     regex_res <- gregexpr(""(?<=\\[)(.+)(?=\\])"", param[[j]], perl = TRUE)[[1]]
+     #     capture_start <- attr(regex_res, ""capture.start"")
+     #     capture_length <- attr(regex_res, ""capture.length"")
+     #     if(capture_start != -1){
+     #       index <- as.integer(unlist(substr(param[[j]], capture_start, capture_start + capture_length - 1)))
+     #       ranks[i, param[[j]]] <- sum(self$posterior_samples[[i]][[param[[j]]]] < access_element_by_index(self$prior_samples[[i]][[base_param_names[[j]]]], index))
+     #     }
+     #     else{
+     #       t1 <- self$posterior_samples[[i]][[param[[j]]]]
+     #       t2 <- self$prior_samples[[i]][[param[[j]]]]
+     #       #ranks[i, param[[j]]] <- sum(self$posterior_samples[[i]][[param[[j]]]] < self$prior_samples[[i]][[param[[j]]]])
+     #       ranks[i, param[[j]]] <- sum(t1 < t2)
+     #     }
+     #   }
+     # }
+     # return(ranks)
+   },
+   add_steps = function(N){
 
-    }
-  )
+   }
+ )
 )",True,False,Implementation / Logic,6
hyunjimoon,SBC,714e06ecc71eb3b5012e0fbcce5a1f469eb1371c,martinmodrak,modrak.mar@gmail.com,2021-05-12T09:24:46Z,martinmodrak,modrak.mar@gmail.com,2021-05-12T09:24:46Z,"Example with discrete parameters

Fix to calculate_rank to handle ties.",R/calculate.R;vignettes/ModelDiagnose.Rmd;vignettes/discrete_params.Rmd,True,True,True,False,158,3,161,"---FILE: R/calculate.R---
@@ -66,8 +66,11 @@ calculate_rank <- function(prior, posterior, thin){
   dimnames(ranks)[2] <- list(par_names)
   for(i in 1:n_iter){
     for(j in 1:n_pars){
-      ranks[i, par_names[j]] <- sum(posterior[, par_names[j], i][thinner] < prior[i, par_names[j]])
+      post_samples <- posterior[, par_names[j], i][thinner]
+      prior_samples <- prior[i, par_names[j]]
+      ranks[i, par_names[j]] <- sum(post_samples < prior_samples) +
+        purrr::rdunif(1, a = 0, b = sum(post_samples == prior_samples))
     }
   }
   return(ranks)
-}
\ No newline at end of file
+}

---FILE: vignettes/ModelDiagnose.Rmd---
@@ -90,7 +90,7 @@ We'll be sampling a total of `n_datasets` individual samples of the parameter `l
 theta_prior <- sbc_obj$sample_theta_tilde_stan(list(""lambda""), n_datasets, data = data)
 
 # or alternatively, use the hyperpriors list:
-# theta_prior <- sbc_obj$sample_theta_tilde(list(""lambda), n_datasets, hyperpriors)
+theta_prior <- sbc_obj$sample_theta_tilde(list(""lambda""), n_datasets, hyperpriors)
 ```
 
 ### Example model - posterior predictive sampling

---FILE: vignettes/discrete_params.Rmd---
@@ -0,0 +1,152 @@
+---
+title: ""SBC with discrete parameters""
+output: html_notebook
+---
+
+```{r setup, include = FALSE}
+library(SBC); library(cmdstanr)
+```
+
+Model from:
+https://mc-stan.org/docs/2_26/stan-users-guide/change-point-section.html
+
+
+```{r}
+stan_code_1 <- ""
+data {
+  real<lower=0> r_e;
+  real<lower=0> r_l;
+
+  int<lower=1> T;
+  int<lower=0> y[T];
+}
+transformed data {
+  real log_unif;
+  log_unif = -log(T);
+}
+parameters {
+  real<lower=0> e;
+  real<lower=0> l;
+}
+transformed parameters {
+  vector[T] lp;
+  lp = rep_vector(log_unif, T);
+  for (s in 1:T)
+    for (t in 1:T)
+      lp[s] = lp[s] + poisson_lpmf(y[t] | t < s ? e : l);
+}
+model {
+  e ~ exponential(r_e);
+  l ~ exponential(r_l);
+  target += log_sum_exp(lp);
+}
+
+generated quantities {
+  int<lower=1,upper=T> s;
+  s = categorical_logit_rng(lp);
+}
+""
+
+model_1 <- cmdstan_model(write_stan_file(stan_code_1))
+
+
+
+sbc_obj_1 <- SBCModel$new(name = ""change_point"", stan_model = model_1)
+
+
+```
+
+```{r}
+set.seed(5846502)
+n_datasets <- 30
+thin <- 4
+
+T <- 5
+r_e <- 0.5
+r_l <- 0.1
+
+hyperpriors <- list(""e"" = function(){rexp(1, r_e)},
+                    ""l"" = function() { rexp(1, r_l)},
+                    ""s"" = function() { purrr::rdunif(1, a = 1, b = T)}
+                    )
+
+theta_prior <- sbc_obj_1$sample_theta_tilde(list(""e"", ""l"", ""s""), n_datasets, hyperpriors)
+
+sampled_y <- array(NA_real_, dim = c(n_datasets, T))
+for(n in 1:n_datasets) {
+  for(t in 1:T) {
+    if(t <= theta_prior$s[n]) {
+      rate <- theta_prior$e[n]
+    } else {
+      rate <- theta_prior$l[n]
+    }
+    sampled_y[n, t] <- rpois(1, rate) 
+  }
+}
+
+
+```
+
+```{r}
+data <- list(T=T, r_e = r_e, r_l = r_l)
+
+theta_post <- sbc_obj_1$sample_theta_bar_y(sampled_y, data=data, pars=list(""e"", ""l"", ""s""), fit_iter = 400)
+```
+
+Let's look at the plots
+
+```{r}
+rank <- calculate_rank(theta_prior, theta_post, thin = thin) 
+plot_hist(rank, ""e"")
+plot_hist(rank, ""l"")
+plot_hist(rank, ""s"")
+plot_ecdf(rank, ""e"")
+plot_ecdf(rank, ""l"")
+plot_ecdf(rank, ""s"")
+```
+We'll note that the discrete `s` parameter looks problematic. Did we get our marginalization wrong? After some inspection, you may notice that the simulator does not match the model - the model takes the early rate (`e`) for points `t < s` while the simulator takes `e` for points `t <=  s`, so there is effectively a shift by one time point between the simulator and the model. So let's assume that we belive that the model is in fact right, so we updated the simulator to match the model:
+
+```{r}
+set.seed(5846502)
+
+hyperpriors <- list(""e"" = function(){rexp(1, r_e)},
+                    ""l"" = function() { rexp(1, r_l)},
+                    ""s"" = function() { purrr::rdunif(1, a = 1, b = T)}
+                    )
+
+theta_prior <- sbc_obj_1$sample_theta_tilde(list(""e"", ""l"", ""s""), n_datasets, hyperpriors)
+
+sampled_y <- array(NA_real_, dim = c(n_datasets, T))
+for(n in 1:n_datasets) {
+  for(t in 1:T) {
+    if(t < theta_prior$s[n]) {
+      rate <- theta_prior$e[n]
+    } else {
+      rate <- theta_prior$l[n]
+    }
+    sampled_y[n, t] <- rpois(1, rate) 
+  }
+}
+
+
+```
+
+And rerun SBC.
+
+```{r}
+data <- list(T=T, r_e = r_e, r_l = r_l)
+
+theta_post <- sbc_obj_1$sample_theta_bar_y(sampled_y, data=data, pars=list(""e"", ""l"", ""s""), fit_iter = 400)
+```
+
+
+```{r}
+rank <- calculate_rank(theta_prior, theta_post, thin = thin) 
+plot_hist(rank, ""e"")
+plot_hist(rank, ""l"")
+plot_hist(rank, ""s"")
+plot_ecdf(rank, ""e"")
+plot_ecdf(rank, ""l"")
+plot_ecdf(rank, ""s"")
+```
+Now - as far as this amount of iterations can see, the model is good and we get good behaviour for both the continuous and the discrete parameters.",True,True,Documentation / Formatting,6
hyunjimoon,SBC,e9d3ca92d73a0923df23cc54482b7e0259a276c9,martinmodrak,modrak.mar@gmail.com,2021-05-12T09:24:08Z,martinmodrak,modrak.mar@gmail.com,2021-05-12T09:24:08Z,Quick fix for mismatches between matrix and list formats,R/calculate.R,False,True,True,False,30,0,30,"---FILE: R/calculate.R---
@@ -12,6 +12,36 @@
 #' @export
 calculate_rank <- function(prior, posterior, thin){
 
+  # Just a hacky conversion from the list representation to make code work right now
+  if(is.list(prior)) {
+    total_vars <- 0
+    for(i in 1:length(prior)) {
+      if(length(dim(prior[[i]])) != 2) {
+        stop(""Multidimensional not supported"")
+      }
+      total_vars <- total_vars + dim(prior[[i]])[2]
+    }
+    prior_matrix <- matrix(nrow = dim(prior[[1]])[1], ncol = total_vars)
+    var_names <- array(NA_character_, total_vars)
+    next_index <- 1
+    for(i in 1:length(prior)) {
+      n_elems <- (dim(prior[[i]])[2])
+      if(n_elems == 1) {
+        prior_matrix[, next_index] <- prior[[i]][,1]
+        var_names[next_index] <- names(prior)[i]
+        next_index <- next_index + 1
+      } else {
+        for(k in 1:n_elems) {
+          prior_matrix[, next_index] <- prior[[i]][, k]
+          var_names[next_index] <- paste0(names(prior)[i], ""["",k,""]"")
+          next_index <- next_index + 1
+        }
+      }
+    }
+    colnames(prior_matrix) <- var_names
+    prior <- prior_matrix
+  }
+
   prior_dims = dim(prior)
   posterior_dims = dim(posterior)
 ",True,False,Implementation / Logic,6
hyunjimoon,SBC,dd596715097d3a774d552147a087cf97063729ea,martinmodrak,modrak.mar@gmail.com,2021-05-12T08:19:27Z,martinmodrak,modrak.mar@gmail.com,2021-05-12T08:19:27Z,"Fixed bugs in excercises, changed to gamma in bad parametrization",vignettes/bad_parametrization.Rmd;vignettes/indexing.Rmd,True,False,True,False,73,74,147,"---FILE: vignettes/bad_parametrization.Rmd---
@@ -12,111 +12,113 @@ Premise: we mistakenly assume that Stan does parametrize the normal distribution
 via mean and precision (like JAGS or INLA do). Since we want to put prior on the 
 standard deviation (as is suggested on the prior choice wiki), we take standard deviation as the parameter and transform to precision $\tau = \frac{1}{\sigma^2}$.
 
+
+TODO maybe start with prior predictive check to tune priors?
+
 ```{r}
-stan_code_prec <- ""
+stan_code_1 <- ""
 data {
   int N;
-  vector[N] y;
+  vector<lower=0>[N] y;
 }
 
 parameters {
-  real mu;
-  real<lower = 0> sigma;
+  real<lower = 0> shape;
+  real<lower = 0> scale;  
 }
 
 model {
-  y ~ normal(mu, 1 / square(sigma));
-  mu ~ normal(0, 5);
-  sigma ~ normal(0, 2);
+  y ~ gamma(shape, scale);
+  shape ~ lognormal(0, 1);
+  scale ~ lognormal(0, 1.5);
 }
 ""
 
-model_prec <- cmdstan_model(write_stan_file(stan_code_prec))
+model_1 <- cmdstan_model(write_stan_file(stan_code_1))
 
 
 
-sbc_obj_prec <- SBCModel$new(name = ""prec"", stan_model = model_prec)
+sbc_obj_1 <- SBCModel$new(name = ""scale"", stan_model = model_1)
 
 
 ```
 
 ```{r}
+set.seed(2258334)
 n_datasets <- 10
 thin <- 4
-hyperpriors <- list(""mu"" = function(){rnorm(1, mean = 0, sd = 5)},
-                    ""sigma"" = function() { abs(rnorm(1, mean = 0, sd = 2))})
+hyperpriors <- list(""shape"" = function(){rlnorm(1, meanlog =  0, sdlog = 1)},
+                    ""scale"" = function() { rlnorm(1, meanlog = 0, sdlog = 1.5)})
 
-theta_prior <- sbc_obj_prec$sample_theta_tilde(list(""mu"", ""sigma""), n_datasets, hyperpriors)
+theta_prior <- sbc_obj_1$sample_theta_tilde(list(""shape"", ""scale""), n_datasets, hyperpriors)
 
-N <- 30
+N <- 40
 sampled_y <- array(NA_real_, dim = c(n_datasets, N))
 for(n in 1:n_datasets) {
-  sampled_y[n, ] <- rnorm(N, theta_prior$mu[n], theta_prior$sigma[n]) 
+  sampled_y[n, ] <- rgamma(N, shape = theta_prior[n, ""shape""], scale = theta_prior[n, ""scale""]) 
+}
+
+if(any(sampled_y == 0)) {
+  warning(""Generated zero, replacing with small values"")
+  sampled_y[sampled_y == 0] <- .Machine$double.eps
 }
 ```
 
 ```{r}
 data <- list(N=N)
 
-theta_post <- sbc_obj_prec$sample_theta_bar_y(sampled_y, data=data, pars=list(""mu"", ""sigma""), fit_iter = 200)
+theta_post <- sbc_obj_1$sample_theta_bar_y(sampled_y, data=data, pars=list(""shape"", ""scale""), fit_iter = 200)
 ```
 10 simulations are enough to see something is wrong with the model. We even see the issue is primarily with the `sigma` parameter!
 
 ```{r}
-xx <- matrix(nrow = n_datasets, ncol = 2)
-xx[,1] = theta_prior$mu
-xx[,2] = theta_prior$sigma
-colnames(xx) <- c(""mu"", ""sigma"")
-rank <- calculate_rank(xx, theta_post, thin = thin)  # thinning factor of 3
-plot_hist(rank, ""mu"")
-plot_hist(rank, ""sigma"")
-plot_ecdf(rank, ""mu"")
-plot_ecdf(rank, ""sigma"")
+rank <- calculate_rank(theta_prior, theta_post, thin = thin)  # thinning factor of 3
+plot_hist(rank, ""shape"")
+plot_hist(rank, ""scale"")
+plot_ecdf(rank, ""shape"")
+plot_ecdf(rank, ""scale"")
 ```
 
-We realize our mistake and fix the model
+So we see that the simulation does not match the model. In practice, the problem may lie with the simulation, with the model or both. Here, we'll assume that the simulation is correct - we really wanted to work with scale and fix the model to match. I.e. we still represent scale in our model, but invert it to get rate before using Stan's `gamma` distribution:
+
 
 ```{r}
-stan_code_sd <- ""
+stan_code_2 <- ""
 data {
   int N;
-  vector[N] y;
+  vector<lower=0>[N] y;
 }
 
 parameters {
-  real mu;
-  real<lower = 0> sigma;
+  real<lower = 0> shape;
+  real<lower = 0> scale;  
 }
 
 model {
-  y ~ normal(mu, sigma);
-  mu ~ normal(0, 5);
-  sigma ~ normal(0, 2);
+  y ~ gamma(shape, inv(scale));
+  shape ~ lognormal(0, 1);
+  scale ~ lognormal(0, 1.5);
 }
 ""
 
-model_sd <- cmdstan_model(write_stan_file(stan_code_sd))
-sbc_obj_sd <- SBCModel$new(name = ""sd"", stan_model = model_sd)
+model_2 <- cmdstan_model(write_stan_file(stan_code_2))
+sbc_obj_2 <- SBCModel$new(name = ""sd"", stan_model = model_2)
 
 ```
 
 
 ```{r}
-theta_post_sd <- sbc_obj_sd$sample_theta_bar_y(sampled_y, data=data, pars=list(""mu"", ""sigma""), fit_iter = 200)
+theta_post_2 <- sbc_obj_2$sample_theta_bar_y(sampled_y, data=data, pars=list(""shape"", ""scale""), fit_iter = 200)
 ```
 
 No obvious problems here, but obviously if we wanted to be sure, we should have ran a lot more simulations.
 
 ```{r}
-xx <- matrix(nrow = n_datasets, ncol = 2)
-xx[,1] = theta_prior$mu
-xx[,2] = theta_prior$sigma
-colnames(xx) <- c(""mu"", ""sigma"")
-rank <- calculate_rank(xx, theta_post_sd, thin = thin)  
-plot_hist(rank, ""mu"")
-plot_hist(rank, ""sigma"")
-plot_ecdf(rank, ""mu"")
-plot_ecdf(rank, ""sigma"")
+rank <- calculate_rank(theta_prior, theta_post_2, thin = thin)  
+plot_hist(rank, ""shape"")
+plot_hist(rank, ""scale"")
+plot_ecdf(rank, ""shape"")
+plot_ecdf(rank, ""scale"")
 ```
 ```
 

---FILE: vignettes/indexing.Rmd---
@@ -108,36 +108,45 @@ K <- 2
 x <- matrix(rnorm(N * K), nrow = N, ncol = K)
 
 thin <- 4
-hyperpriors <- list(""alpha"" = function(){rnorm(1, mean = 0, sd = 5)},
-                    ""beta"" = function(){rnorm(K, mean = 0, sd = 1)},
-                    ""sigma"" = function() { abs(rnorm(1, mean = 0, sd = 2))})
+# hyperpriors <- list(""alpha"" = function(){rnorm(1, mean = 0, sd = 5)},
+#                     ""beta"" = function(){rnorm(K, mean = 0, sd = 1)},
+#                     ""sigma"" = function() { abs(rnorm(1, mean = 0, sd = 2))})
+# 
+# theta_prior <- sbc_obj_1$sample_theta_tilde(list(""alpha"", ""beta"", ""sigma""), n_datasets, hyperpriors)
+theta_prior <- matrix(nrow = n_datasets, ncol = K + 2)
+colnames(theta_prior) <- c(""alpha"", paste0(""beta["", 1:K, ""]""), ""sigma"")
+theta_prior[,""alpha""] <- rnorm(n_datasets, mean = 0, sd = 5)
+for(k in 1:K) {
+  theta_prior[, paste0(""beta["", k, ""]"")] <- rnorm(n_datasets, mean = 0, sd = 1)
+}
+theta_prior[,""sigma""] <- abs(rnorm(n_datasets, mean = 0, sd = 2))
+
 
-theta_prior <- sbc_obj_1$sample_theta_tilde(list(""alpha"", ""beta"", ""sigma""), n_datasets, hyperpriors)
 
 sampled_y <- array(NA_real_, dim = c(n_datasets, N))
-for(n in 1:n_datasets) {
-  sampled_y[n, ] <- rnorm(N, theta_prior$alpha[n] + x %*% theta_prior$beta[n,], theta_prior$sigma[n]) 
+for(d in 1:n_datasets) {
+  for(n in 1:N) {
+    mu <- theta_prior[d, ""alpha""]
+    for(k in 1:K) {
+      mu <- mu + x[n,k] * theta_prior[d, paste0(""beta["", k, ""]"")]
+    }
+    sampled_y[d, n] <- rnorm(1, mu, theta_prior[d, ""sigma""]) 
+  }
 }
 ```
 
 ```{r}
 data <- list(N=N, K = K, x = x)
 
-theta_post_1 <- sbc_obj_1$sample_theta_bar_y(sampled_y, data=data, pars=list(""alpha"", ""beta"", ""sigma""), fit_iter = 400)
+theta_post_1 <- sbc_obj_1$sample_theta_bar_y(sampled_y, data=data, pars=colnames(theta_prior), fit_iter = 400)
 
-theta_post_2 <- sbc_obj_2$sample_theta_bar_y(sampled_y, data=data, pars=list(""alpha"", ""beta"", ""sigma""), fit_iter = 400)
+theta_post_2 <- sbc_obj_2$sample_theta_bar_y(sampled_y, data=data, pars=colnames(theta_prior), fit_iter = 400)
 
-theta_post_3 <- sbc_obj_3$sample_theta_bar_y(sampled_y, data=data, pars=list(""alpha"", ""beta"", ""sigma""), fit_iter = 400)
+theta_post_3 <- sbc_obj_3$sample_theta_bar_y(sampled_y, data=data, pars=colnames(theta_prior), fit_iter = 400)
 ```
 
 ```{r}
-xx <- matrix(nrow = n_datasets, ncol = 4)
-xx[,1] = theta_prior$alpha
-xx[,2] = theta_prior$beta[,1]
-xx[,3] = theta_prior$beta[,2]
-xx[,4] = theta_prior$sigma
-colnames(xx) <- c(""alpha"", ""beta[1]"", ""beta[2]"", ""sigma"")
-rank_1 <- calculate_rank(xx, theta_post_1, thin = thin)  
+rank_1 <- calculate_rank(theta_prior, theta_post_1, thin = thin)  
 plot_hist(rank_1, ""alpha"")
 plot_hist(rank_1, ""beta[1]"")
 plot_hist(rank_1, ""beta[2]"")
@@ -155,13 +164,7 @@ but we tested the model for you and it is OK (although the implementation is not
 
 
 ```{r}
-xx <- matrix(nrow = n_datasets, ncol = 4)
-xx[,1] = theta_prior$alpha
-xx[,2] = theta_prior$beta[,1]
-xx[,3] = theta_prior$beta[,2]
-xx[,4] = theta_prior$sigma
-colnames(xx) <- c(""alpha"", ""beta[1]"", ""beta[2]"", ""sigma"")
-rank_2 <- calculate_rank(xx, theta_post_2, thin = thin)  
+rank_2 <- calculate_rank(theta_prior, theta_post_2, thin = thin)  
 plot_hist(rank_2, ""alpha"")
 plot_hist(rank_2, ""beta[1]"")
 plot_hist(rank_2, ""beta[2]"")
@@ -180,13 +183,7 @@ propagates most strongly to the `sigma` parameter (reusing the same `x` element
 
 
 ```{r}
-xx <- matrix(nrow = n_datasets, ncol = 4)
-xx[,1] = theta_prior$alpha
-xx[,2] = theta_prior$beta[,1]
-xx[,3] = theta_prior$beta[,2]
-xx[,4] = theta_prior$sigma
-colnames(xx) <- c(""alpha"", ""beta[1]"", ""beta[2]"", ""sigma"")
-rank_3 <- calculate_rank(xx, theta_post_3, thin = thin)  
+rank_3 <- calculate_rank(theta_prior, theta_post_3, thin = thin)  
 plot_hist(rank_3, ""alpha"")
 plot_hist(rank_3, ""beta[1]"")
 plot_hist(rank_3, ""beta[2]"")",False,True,Implementation / Logic,6
hyunjimoon,SBC,e15ce43a44d3aac49828732d6ae32dc12d2489f6,martinmodrak,modrak.mar@gmail.com,2021-05-10T10:07:06Z,martinmodrak,modrak.mar@gmail.com,2021-05-10T10:07:06Z,Drafts of examples of using SBC to find bugs in models,vignettes/bad_parametrization.Rmd;vignettes/indexing.Rmd,True,False,True,False,325,0,325,"---FILE: vignettes/bad_parametrization.Rmd---
@@ -0,0 +1,122 @@
+---
+title: ""Discovering bad parametrization with SBC""
+output: html_notebook
+---
+
+```{r setup, include = FALSE}
+library(SBC); library(cmdstanr)
+```
+
+
+Premise: we mistakenly assume that Stan does parametrize the normal distribution
+via mean and precision (like JAGS or INLA do). Since we want to put prior on the 
+standard deviation (as is suggested on the prior choice wiki), we take standard deviation as the parameter and transform to precision $\tau = \frac{1}{\sigma^2}$.
+
+```{r}
+stan_code_prec <- ""
+data {
+  int N;
+  vector[N] y;
+}
+
+parameters {
+  real mu;
+  real<lower = 0> sigma;
+}
+
+model {
+  y ~ normal(mu, 1 / square(sigma));
+  mu ~ normal(0, 5);
+  sigma ~ normal(0, 2);
+}
+""
+
+model_prec <- cmdstan_model(write_stan_file(stan_code_prec))
+
+
+
+sbc_obj_prec <- SBCModel$new(name = ""prec"", stan_model = model_prec)
+
+
+```
+
+```{r}
+n_datasets <- 10
+thin <- 4
+hyperpriors <- list(""mu"" = function(){rnorm(1, mean = 0, sd = 5)},
+                    ""sigma"" = function() { abs(rnorm(1, mean = 0, sd = 2))})
+
+theta_prior <- sbc_obj_prec$sample_theta_tilde(list(""mu"", ""sigma""), n_datasets, hyperpriors)
+
+N <- 30
+sampled_y <- array(NA_real_, dim = c(n_datasets, N))
+for(n in 1:n_datasets) {
+  sampled_y[n, ] <- rnorm(N, theta_prior$mu[n], theta_prior$sigma[n]) 
+}
+```
+
+```{r}
+data <- list(N=N)
+
+theta_post <- sbc_obj_prec$sample_theta_bar_y(sampled_y, data=data, pars=list(""mu"", ""sigma""), fit_iter = 200)
+```
+10 simulations are enough to see something is wrong with the model. We even see the issue is primarily with the `sigma` parameter!
+
+```{r}
+xx <- matrix(nrow = n_datasets, ncol = 2)
+xx[,1] = theta_prior$mu
+xx[,2] = theta_prior$sigma
+colnames(xx) <- c(""mu"", ""sigma"")
+rank <- calculate_rank(xx, theta_post, thin = thin)  # thinning factor of 3
+plot_hist(rank, ""mu"")
+plot_hist(rank, ""sigma"")
+plot_ecdf(rank, ""mu"")
+plot_ecdf(rank, ""sigma"")
+```
+
+We realize our mistake and fix the model
+
+```{r}
+stan_code_sd <- ""
+data {
+  int N;
+  vector[N] y;
+}
+
+parameters {
+  real mu;
+  real<lower = 0> sigma;
+}
+
+model {
+  y ~ normal(mu, sigma);
+  mu ~ normal(0, 5);
+  sigma ~ normal(0, 2);
+}
+""
+
+model_sd <- cmdstan_model(write_stan_file(stan_code_sd))
+sbc_obj_sd <- SBCModel$new(name = ""sd"", stan_model = model_sd)
+
+```
+
+
+```{r}
+theta_post_sd <- sbc_obj_sd$sample_theta_bar_y(sampled_y, data=data, pars=list(""mu"", ""sigma""), fit_iter = 200)
+```
+
+No obvious problems here, but obviously if we wanted to be sure, we should have ran a lot more simulations.
+
+```{r}
+xx <- matrix(nrow = n_datasets, ncol = 2)
+xx[,1] = theta_prior$mu
+xx[,2] = theta_prior$sigma
+colnames(xx) <- c(""mu"", ""sigma"")
+rank <- calculate_rank(xx, theta_post_sd, thin = thin)  
+plot_hist(rank, ""mu"")
+plot_hist(rank, ""sigma"")
+plot_ecdf(rank, ""mu"")
+plot_ecdf(rank, ""sigma"")
+```
+```
+

---FILE: vignettes/indexing.Rmd---
@@ -0,0 +1,203 @@
+---
+title: ""Discovering indexing errors with SBC""
+output: html_notebook
+---
+
+```{r setup, include = FALSE}
+library(SBC); library(cmdstanr)
+```
+
+Below are three different Stan codes for implementing a simple linear regression. Not all of them are correct - can you see which one is wrong?
+
+```{r}
+stan_code_1 <- ""
+data {
+  int<lower=0> N;   // number of data items
+  int<lower=0> K;   // number of predictors
+  matrix[N, K] x;   // predictor matrix
+  vector[N] y;      // outcome vector
+}
+parameters {
+  real alpha;           // intercept
+  vector[K] beta;       // coefficients for predictors
+  real<lower=0> sigma;  // error scale
+}
+model {
+  vector[N] mu = rep_vector(alpha, N);
+  for(i in 1:K) {
+    for(j in 1:N) {
+      mu[j] += beta[i] * x[j, i];
+    }
+  }
+  y ~ normal(mu, sigma);  // likelihood
+  alpha ~ normal(0, 5);
+  beta ~ normal(0, 1);
+  sigma ~ normal(0, 2);
+}
+""
+
+stan_code_2 <- ""
+data {
+  int<lower=0> N;   // number of data items
+  int<lower=0> K;   // number of predictors
+  matrix[N, K] x;   // predictor matrix
+  vector[N] y;      // outcome vector
+}
+parameters {
+  real alpha;           // intercept
+  vector[K] beta;       // coefficients for predictors
+  real<lower=0> sigma;  // error scale
+}
+model {
+  vector[N] mu;
+  for(i in 1:N) {
+    mu[i] = alpha;
+    for(j in 1:K) {
+      mu[i] += beta[j] * x[j, j];
+    }
+  }
+  y ~ normal(mu, sigma);  // likelihood
+  alpha ~ normal(0, 5);
+  beta ~ normal(0, 1);
+  sigma ~ normal(0, 2);
+}
+""
+
+stan_code_3 <- ""
+data {
+  int<lower=0> N;   // number of data items
+  int<lower=0> K;   // number of predictors
+  matrix[N, K] x;   // predictor matrix
+  vector[N] y;      // outcome vector
+}
+parameters {
+  real alpha;           // intercept
+  vector[K] beta;       // coefficients for predictors
+  real<lower=0> sigma;  // error scale
+}
+model {
+  y ~ normal(transpose(beta) * transpose(x) + alpha, sigma);  // likelihood
+  alpha ~ normal(0, 5);
+  beta ~ normal(0, 1);
+  sigma ~ normal(0, 2);
+}
+""
+
+
+stan_model_1 <- cmdstan_model(write_stan_file(stan_code_1))
+stan_model_2 <- cmdstan_model(write_stan_file(stan_code_2))
+stan_model_3 <- cmdstan_model(write_stan_file(stan_code_3))
+
+
+
+sbc_obj_1 <- SBCModel$new(name = ""linreg_1"", stan_model = stan_model_1)
+sbc_obj_2 <- SBCModel$new(name = ""linreg_2"", stan_model = stan_model_2)
+sbc_obj_3 <- SBCModel$new(name = ""linreg_3"", stan_model = stan_model_3)
+
+
+```
+If you can, good for you! If not, don't worry, SBC can help you spot coding problems, so let's simulate
+data and test all three models against simulated data.
+
+```{r}
+set.seed(5666024)
+n_datasets <- 10
+N <- 100
+K <- 2
+
+x <- matrix(rnorm(N * K), nrow = N, ncol = K)
+
+thin <- 4
+hyperpriors <- list(""alpha"" = function(){rnorm(1, mean = 0, sd = 5)},
+                    ""beta"" = function(){rnorm(K, mean = 0, sd = 1)},
+                    ""sigma"" = function() { abs(rnorm(1, mean = 0, sd = 2))})
+
+theta_prior <- sbc_obj_1$sample_theta_tilde(list(""alpha"", ""beta"", ""sigma""), n_datasets, hyperpriors)
+
+sampled_y <- array(NA_real_, dim = c(n_datasets, N))
+for(n in 1:n_datasets) {
+  sampled_y[n, ] <- rnorm(N, theta_prior$alpha[n] + x %*% theta_prior$beta[n,], theta_prior$sigma[n]) 
+}
+```
+
+```{r}
+data <- list(N=N, K = K, x = x)
+
+theta_post_1 <- sbc_obj_1$sample_theta_bar_y(sampled_y, data=data, pars=list(""alpha"", ""beta"", ""sigma""), fit_iter = 400)
+
+theta_post_2 <- sbc_obj_2$sample_theta_bar_y(sampled_y, data=data, pars=list(""alpha"", ""beta"", ""sigma""), fit_iter = 400)
+
+theta_post_3 <- sbc_obj_3$sample_theta_bar_y(sampled_y, data=data, pars=list(""alpha"", ""beta"", ""sigma""), fit_iter = 400)
+```
+
+```{r}
+xx <- matrix(nrow = n_datasets, ncol = 4)
+xx[,1] = theta_prior$alpha
+xx[,2] = theta_prior$beta[,1]
+xx[,3] = theta_prior$beta[,2]
+xx[,4] = theta_prior$sigma
+colnames(xx) <- c(""alpha"", ""beta[1]"", ""beta[2]"", ""sigma"")
+rank_1 <- calculate_rank(xx, theta_post_1, thin = thin)  
+plot_hist(rank_1, ""alpha"")
+plot_hist(rank_1, ""beta[1]"")
+plot_hist(rank_1, ""beta[2]"")
+plot_hist(rank_1, ""sigma"")
+
+plot_ecdf(rank_1, ""alpha"")
+plot_ecdf(rank_1, ""beta[1]"")
+plot_ecdf(rank_1, ""beta[2]"")
+plot_ecdf(rank_1, ""sigma"")
+
+```
+
+As far as a quick SBC can see the first code is OK. You could verify further with more iterations
+but we tested the model for you and it is OK (although the implementation is not the best one).
+
+
+```{r}
+xx <- matrix(nrow = n_datasets, ncol = 4)
+xx[,1] = theta_prior$alpha
+xx[,2] = theta_prior$beta[,1]
+xx[,3] = theta_prior$beta[,2]
+xx[,4] = theta_prior$sigma
+colnames(xx) <- c(""alpha"", ""beta[1]"", ""beta[2]"", ""sigma"")
+rank_2 <- calculate_rank(xx, theta_post_2, thin = thin)  
+plot_hist(rank_2, ""alpha"")
+plot_hist(rank_2, ""beta[1]"")
+plot_hist(rank_2, ""beta[2]"")
+plot_hist(rank_2, ""sigma"")
+
+plot_ecdf(rank_2, ""alpha"")
+plot_ecdf(rank_2, ""beta[1]"")
+plot_ecdf(rank_2, ""beta[2]"")
+plot_ecdf(rank_2, ""sigma"")
+
+```
+
+But the second model is actually not looking good.     In fact the problem is the line
+`mu[i] += beta[j] * x[j, j];` which should have `x[i, j]` instead. We see that this 
+propagates most strongly to the `sigma` parameter (reusing the same `x` element leads to more similar predictions for each row, so `sigma` needs to be inflated to accommodate this)
+
+
+```{r}
+xx <- matrix(nrow = n_datasets, ncol = 4)
+xx[,1] = theta_prior$alpha
+xx[,2] = theta_prior$beta[,1]
+xx[,3] = theta_prior$beta[,2]
+xx[,4] = theta_prior$sigma
+colnames(xx) <- c(""alpha"", ""beta[1]"", ""beta[2]"", ""sigma"")
+rank_3 <- calculate_rank(xx, theta_post_3, thin = thin)  
+plot_hist(rank_3, ""alpha"")
+plot_hist(rank_3, ""beta[1]"")
+plot_hist(rank_3, ""beta[2]"")
+plot_hist(rank_3, ""sigma"")
+
+plot_ecdf(rank_3, ""alpha"")
+plot_ecdf(rank_3, ""beta[1]"")
+plot_ecdf(rank_3, ""beta[2]"")
+plot_ecdf(rank_3, ""sigma"")
+
+```
+
+
+And the third ",False,True,Documentation / Formatting,6
hyunjimoon,SBC,836f79452aed6ee2d0b99a23d35070844d9b47ef,Dashadower,tttllshin@gmail.com,2020-12-31T09:09:23Z,Dashadower,tttllshin@gmail.com,2020-12-31T09:09:23Z,"Change some functions' names, fix bug with rstan's y_bar_theta sampling",NAMESPACE;R/calculate.R;R/plot.R;R/print.R;R/sample.R;man/calculate_rank.Rd;man/plot_ecdf.Rd;man/plot_hist.Rd;man/print_summary.Rd;vignettes/ModelDiagnose.Rmd,True,True,True,False,26,29,55,"---FILE: NAMESPACE---
@@ -1,10 +1,10 @@
 # Generated by roxygen2: do not edit by hand
 
-S3method(plot,ecdf)
-S3method(plot,hist)
-S3method(print,summary)
 export(SBCModel)
-export(calculate.rank)
+export(calculate_rank)
+export(plot_ecdf)
+export(plot_hist)
+export(print_summary)
 import(ggplot2)
 importFrom(stats,chisq.test)
 importFrom(stats,integrate)

---FILE: R/calculate.R---
@@ -9,7 +9,7 @@
 #' posterior array dimensions: (n_iter, n_pars, n_sample)
 #' @return array of dimensions(n_iter, n_pars)
 #' @export
-calculate.rank <- function(prior, posterior, thin){
+calculate_rank <- function(prior, posterior, thin){
 
   prior_dims = dim(prior)
   posterior_dims = dim(posterior)

---FILE: R/plot.R---
@@ -3,11 +3,10 @@
 #'
 #' @param ranks array of dimension(n_iter, n_pars) where n_iter=number of posterior draw iterations, n_pars the number of parameters of interest
 #' @param par names of parameter to plot
-#' @param thin integer in which thinning was applied
 #' @param bins number of histogram bins to plot default is 20
 #' @import ggplot2
 #' @export
-plot.hist <- function(ranks, par, bins=20){
+plot_hist <- function(ranks, par, bins=20){
   CI = stats::qbinom(c(0.05,0.5,0.95), size=dim(ranks)[1], prob = 1/(bins))
   ggplot() + aes(ranks[, par]) + geom_histogram(bins=bins) +
     geom_hline(yintercept = CI, color=""black"", linetype=""dashed"") +
@@ -21,7 +20,7 @@ plot.hist <- function(ranks, par, bins=20){
 #' @param par names of parameter to plot
 #' @import ggplot2
 #' @export
-plot.ecdf <- function(ranks, par){
+plot_ecdf <- function(ranks, par){
 
   S <- dim(ranks)[1]
   r.scale <- rank(ranks[, par], ties.method=""average"")

---FILE: R/print.R---
@@ -7,7 +7,7 @@
 #' @param bins number of bins to use for summary
 #' @importFrom stats chisq.test integrate
 #' @export
-print.summary <- function(ranks, par, thin, bins = 20){
+print_summary <- function(ranks, par, thin, bins = 20){
   pval <- function(bin_count){
     return(chisq.test(bin_count)$p.value)
   }

---FILE: R/sample.R---
@@ -100,7 +100,7 @@ SBCModel <- R6::R6Class(""SBCModel"",
           # sample for rstan
           model_fit <- rstan::sampling(self$stan_model, data=data,
                                        pars=as.vector(c(dimnames(theta_arr)[[2]], y_var)), chains=1, algorithm=""Fixed_param"",
-                                       init=list(theta_slice), cores=1, show_messages=FALSE, refresh=0)
+                                       init=list(theta_slice), iter=2, warmup=1, cores=1, show_messages=FALSE, refresh=0)
 
           sample_summary <- rstan::summary(model_fit)$summary
           samples <- lapply(1:y_count, function(x) sample_summary[paste0(y_var, ""["", x, ""]""), ""50%""])

---FILE: man/calculate_rank.Rd---
@@ -1,10 +1,10 @@
 % Generated by roxygen2: do not edit by hand
 % Please edit documentation in R/calculate.R
-\name{calculate.rank}
-\alias{calculate.rank}
+\name{calculate_rank}
+\alias{calculate_rank}
 \title{Given prior and posterior samples, generate rank count for each bin.}
 \usage{
-calculate.rank(prior, posterior, thin)
+calculate_rank(prior, posterior, thin)
 }
 \arguments{
 \item{prior}{A named array of dimensions(n_iter, n_pars) where n_iter=number of SBC draws, n_pars the number of parameters. Names should be applied as parameter names.}

---FILE: man/plot_ecdf.Rd---
@@ -1,11 +1,11 @@
 % Generated by roxygen2: do not edit by hand
 % Please edit documentation in R/plot.R
-\name{plot.ecdf}
-\alias{plot.ecdf}
+\name{plot_ecdf}
+\alias{plot_ecdf}
 \title{Plot ECDF given rank array ""ranks""
 \href{https://arxiv.org/abs/1903.08008}{arxiv::1903.08008} by A. Vehtari et al.}
 \usage{
-\method{plot}{ecdf}(ranks, par)
+plot_ecdf(ranks, par)
 }
 \arguments{
 \item{ranks}{array of dimension(n_iter, n_pars) where n_iter=number of posterior draw iterations, n_pars the number of parameters of interest}

---FILE: man/plot_hist.Rd---
@@ -1,18 +1,16 @@
 % Generated by roxygen2: do not edit by hand
 % Please edit documentation in R/plot.R
-\name{plot.hist}
-\alias{plot.hist}
+\name{plot_hist}
+\alias{plot_hist}
 \title{Plot Rank Histogram given rank array ""ranks""}
 \usage{
-\method{plot}{hist}(ranks, par, thin, bins = 20)
+plot_hist(ranks, par, bins = 20)
 }
 \arguments{
 \item{ranks}{array of dimension(n_iter, n_pars) where n_iter=number of posterior draw iterations, n_pars the number of parameters of interest}
 
 \item{par}{names of parameter to plot}
 
-\item{thin}{integer in which thinning was applied}
-
 \item{bins}{number of histogram bins to plot default is 20}
 }
 \description{

---FILE: man/print_summary.Rd---
@@ -1,10 +1,10 @@
 % Generated by roxygen2: do not edit by hand
 % Please edit documentation in R/print.R
-\name{print.summary}
-\alias{print.summary}
+\name{print_summary}
+\alias{print_summary}
 \title{Summarize Ranks on different distance maeasure metrics}
 \usage{
-\method{print}{summary}(ranks, par, thin, bins = 20)
+print_summary(ranks, par, thin, bins = 20)
 }
 \arguments{
 \item{ranks}{array of dimension(n_iter, n_pars) where n_iter=number of posterior draw iterations, n_pars the number of parameters of interest}

---FILE: vignettes/ModelDiagnose.Rmd---
@@ -53,9 +53,9 @@ theta_prior <- sbc_obj$sample_theta_tilde(list(""lambda""), n_datasets)
 sampled_y <- sbc_obj$sample_y_tilde(theta_prior, y_count = n_datasets, data=data) # dummy data for y) 
 # retrieve parameters by refitting on simulated y data
 theta_post <- sbc_obj$sample_theta_bar_y(sampled_y, data=data, pars=list(""lambda""), fit_iter = n_samples * thin)
-rank <- calculate.rank(theta_prior, theta_post, thin = thin)
-plot.hist(rank, ""lambda"")
-plot.ecdf(rank, ""lambda"")
+rank <- calculate_rank(theta_prior, theta_post, thin = thin)
+plot_hist(rank, ""lambda"")
+plot_ecdf(rank, ""lambda"")
 # plot.ecdf.diff? 
 ```
 
@@ -66,8 +66,8 @@ For faster computation, bootstrap could be used to decrease the number of refitt
 bootstrap_y <- sbc_obj$sample_bootstrap_y_tilde(sampled_y[1, ], 10)
 post <- rstan_sbc_obj$sample_theta_bar_y(rstan_bootstrap_y, pars=list(""lambda"", ""lp__""), data=list(N=25))
 calculate.rank(rstan_theta_arr, rstan_post, thin = 3)
-plot.hist(rank, ""lambda"")
-plot.ecdf(rank, ""lambda"")
+plot_hist(rank, ""lambda"")
+plot_ecdf(rank, ""lambda"")
 ```
 
 cmdstanr is also supported and by replacing the above functions with the equivalents introduced [here](https://github.com/hyunjimoon/SBC/blob/master/tests/testthat/test-SBCModel.R).",True,True,Documentation / Formatting,6
hyunjimoon,SBC,e5a2dd5f4b005888bca1a1cabe81d2202c7d9b3a,Dashadower,tttllshin@gmail.com,2020-12-02T15:29:08Z,Dashadower,tttllshin@gmail.com,2020-12-02T15:29:08Z,sbc_vanilla finished. Results verified with simple tests. Still need better input validation and error catching for sampling.R,src/sample.R;src/sbc_array.R;test/sbc_array_pois.stan;test/test_sample.R,False,True,True,False,79,13,92,"---FILE: src/sample.R---
@@ -1,8 +1,10 @@
 library(R6)
+library(posterior)
 
-RSTAN_MODEL_CLASS_NAME <- ""stanmodel""  # sucks that R doesn't have 
+RSTAN_MODEL_CLASS_NAME <- ""stanmodel""  # r preprocessor macro equivalent someday?
 CMDSTAN_MODEL_CLASS_NAME <- ""CmdStanModel""
 
+
 SBCModel <- R6Class(""SBCModel"", list(
   # @field name: Some string to identify your SBCModel
   # @field stan_model: A CmdStanModel or a stanmodel
@@ -27,6 +29,9 @@ SBCModel <- R6Class(""SBCModel"", list(
     else if(RSTAN_MODEL_CLASS_NAME %in% class(stan_model)){
       self$model_type <- RSTAN_MODEL_CLASS_NAME
     }
+    else{
+      stop(paste(""Could not identify stan_model with unknown class type"", class(stan_model)))
+    }
     self$stan_model <- stan_model
     self$hyperpriors <- hyperpriors
   },
@@ -50,12 +55,12 @@ SBCModel <- R6Class(""SBCModel"", list(
     # sample $\tilde{y} ~ p(\tilde{y} | \tilde{\theta})$, or y_tilde ~ P(y_tilde | theta_tilde)
     # The stan model must specify P(y | theta) within the generated quantities block
     #
-    # @param theta_arr: Array of sampled theta_tilde values, which is outputted from self$sample_theta_tilde()
+    # @param theta_arr: Array of sampled theta_tilde values (n_iters, n_pars), which is outputted from self$sample_theta_tilde()
     # @param y_count: number of y_tilde samples being generated within generated quantities
     # @param y_var: y_tilde variable name. Will be retrieved from model as so: y_var[n] (1<=n<=y_count)
     # @param data: data list to pass to the stan model, in most cases is irrelevant since sampling will be done with fixed params
     #
-    # returns: array of length (n_iters, y_count) of sampled y
+    # returns: array of dimension (n_iters, y_count) of sampled y
     stopifnot(length(dim(theta_arr)) == 2)
 
     n_iters = dim(theta_arr)[1]
@@ -87,6 +92,52 @@ SBCModel <- R6Class(""SBCModel"", list(
     rm(model_fit, sample_summary, samples)  # cleanup
     return(sample_arr)
   },
-  approx_theta_bar_y = function(y_sample_arr){
+  approx_theta_bar_y = function(y_sample_arr, data=list(), pars=list(), fit_iter=200){
+    # sample $\theta ~ p(\theta | \tilde{y})$, or theta ~ P(theta | y_tilde)
+    # The stan model must have \theta defined as parameters
+    #
+    # @param y_sample_arr: array of dimension (n_iters, y_count) of sampled y. Same as output of self$sample_y_tilde()
+    # @param data: list of additional data to pass to the stan model. Note that ""y"" will be overwritten with draws from y_sample_arr.
+    # @param pars: list of parameters of interest.
+    # @param fit_iter: number of model iterations.
+    #
+    # returns: array of dimension (n_iters, n_pars, fit_iter) of posterior parameter draws
+    stopifnot(length(pars) > 0)
+
+    n_iters = dim(theta_arr)[1]
+    draw_arr <- array(dim=c(n_iters, length(pars), fit_iter))
+    if(typeof(pars) == ""list""){
+      pars <- unlist(pars)
+    }
+
+    for(iter_index in 1:n_iters){
+      data[[""y""]] <- y_sample_arr[iter_index, ]  # insert ""y"" with sample slice vector
+
+      if(self$model_type == CMDSTAN_MODEL_CLASS_NAME){
+        model_fit <- self$stan_model$sample(data=data, iter_warmup=fit_iter, iter_sampling=fit_iter, chains=1,
+                                            save_warmup=FALSE, refresh=0, thin=NULL)
+        
+        draw_arr[iter_index, , ] <- aperm(model_fit$draws(variables=pars)[, 1, ])  # arrays are filled row first, so we permutate once
+        # https://github.com/stan-dev/cmdstanr/issues/346
+        # currently throws an error if you try to retrieve only a single numeric variable, just add lp until fix is released
+      }
+
+      else if(self$model_type == RSTAN_MODEL_CLASS_NAME){
+        model_fit <- rstan::sampling(self$stan_model, data=data, pars=pars, chains=1, iter=fit_iter*2, warmup=fit_iter,
+                                     refresh=0)
+        
+        draw_arr[iter_index, , ] <- aperm(posterior::as_draws_array(rstan::extract(model_fit, pars=pars, permuted=FALSE, inc_warmup=FALSE)))
+      }
+    }
+    if(dim(draw_arr)[2] != length(pars)){
+      warning(""Couldn't rename array dimnames with corresponding parameters.
+              This probably means a sequential parameter is included, and SBC can't verify the identities of parameter samples.
+              If you would like to use SBC plotting features, you need to manually define dimnames for each parameter in dimension 2"")
+    }
+    else{
+      dimnames(draw_arr)[[2]] <- pars  # TODO: handle sequential parameters
+    }
+    rm(model_fit)
+    return(draw_arr)
   }
 ))
\ No newline at end of file

---FILE: src/sbc_array.R---
@@ -34,8 +34,7 @@ sbc.rank <- function(SBCData.object, thin){
   # return array dimensions: (n_iter, n_pars)
   prior_dims = dim(SBCData.object@prior)
   posterior_dims = dim(SBCData.object@posterior)
-  print(prior_dims)
-  print(posterior_dims)
+
   if (prior_dims[1] != posterior_dims[1] || prior_dims[2] != posterior_dims[2]){
     stop(""Dimension mismatch error!\n dim(SBCData.object@prior)[1] == dim(SBCData.object@posterior)[1] && dim(SBCData.object@prior)[2] == dim(SBCData.object@posterior)[2] must be satisfied"")
   }

---FILE: test/sbc_array_pois.stan---
@@ -15,4 +15,4 @@ generated quantities{
     y_rep[i] = poisson_rng(lambda); 
   }
   
-}
\ No newline at end of file
+}

---FILE: test/test_sample.R---
@@ -1,5 +1,5 @@
 library(cmdstanr)
-#library(rstan)
+library(rstan)
 library(posterior)
 set.seed(20201111)
 source(file.path(getwd(),""src/sample.R""))
@@ -9,15 +9,31 @@ model_path <- file.path(getwd(), ""test/sbc_array_pois.stan"")
 cmdstan_model <- cmdstan_model(model_path)
 
 cmdstan_sbc_obj <- SBCModel$new(""poisson_cmdstan"", cmdstan_model, list(""lambda""=function(){as.integer(rgamma(1, shape=15, rate=5))}))#, ""sigma""=function(){rexp(1)}))
-theta_arr <- cmdstan_sbc_obj$sample_theta_tilde(list(""lambda""), 10)
-
-cmdstan_sbc_obj$sample_y_tilde(theta_arr, 25, data=list(N=25, y=as.vector(1:25)))
+theta_arr <- cmdstan_sbc_obj$sample_theta_tilde(list(""lambda""), 1)
 
+sampled_y <- cmdstan_sbc_obj$sample_y_tilde(theta_arr, 25, data=list(N=25, y=as.vector(1:25)))
 
+post <- cmdstan_sbc_obj$approx_theta_bar_y(sampled_y, pars=list(""lambda"", ""lp__""), data=list(N=25))
+print(dim(post))
+print(theta_arr[1, ""lambda""])
+print(mean(post[, ""lambda"", ]))
 ###########################
 # check rstan
 rstan_model <- stan_model(model_path)
 
 rstan_sbc_obj <- SBCModel$new(""poisson_rstan"", rstan_model, list(""lambda""=function(){as.integer(rgamma(1, shape=15, rate=5))}))#, ""sigma""=function(){rexp(1)}))
-theta_arr <- rstan_sbc_obj$sample_theta_tilde(list(""lambda""), 10)
-rstan_sbc_obj$sample_y_tilde(theta_arr, 25, data=list(N=25, y=as.vector(1:25)))
+theta_arr <- rstan_sbc_obj$sample_theta_tilde(list(""lambda""), 100)
+sampled_y <- rstan_sbc_obj$sample_y_tilde(theta_arr, 25, data=list(N=25, y=as.vector(1:25)))
+sampled_y <- round(sampled_y)  # rstan returns double values(float components are ignoreable, < 1e-4)
+post_samples <- rstan_sbc_obj$approx_theta_bar_y(sampled_y, pars=list(""lambda""), data=list(N=25))
+print(dim(post_samples))
+print(theta_arr[1, ""lambda""])
+print(mean(post_samples[, ""lambda"", ]))
+
+################################
+source(file.path(getwd(),""src/sbc_array.R""))
+sbc.obj <- new(""SBCData"", prior=theta_arr, posterior=post_samples, model.name=""poisson"")
+rank <- sbc.rank(sbc.obj, 3)
+sbc.plot.hist(rank, ""lambda"", 3)
+sbc.plot.ecdf(rank, ""lambda"")
+sbc.plot.ecdf.diff(rank, ""lambda"")  # this plot not looking good :(",True,False,Implementation / Logic,6
