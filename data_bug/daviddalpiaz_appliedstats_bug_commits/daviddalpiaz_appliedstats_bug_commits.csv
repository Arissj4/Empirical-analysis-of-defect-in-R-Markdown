repo_owner,repo_name,commit_hash,author_name,author_email,author_date,committer_name,committer_email,committer_date,message,filenames,touches_rmd,touches_r,touches_r_or_rmd,is_merge,added,deleted,changed,diff
daviddalpiaz,appliedstats,77498cf0dc37f48264ecf84c951ad0e8fd168873,David Dalpiaz,9003346+daviddalpiaz@users.noreply.github.com,2024-11-18T15:04:51Z,David Dalpiaz,9003346+daviddalpiaz@users.noreply.github.com,2024-11-18T15:04:51Z,fix broken link,logistic.Rmd,True,False,True,False,1,1,2,"---FILE: logistic.Rmd---
@@ -1113,7 +1113,7 @@ get_spec(conf_mat_90)
 
 While this is far fewer false positives, is it acceptable though? Still probably not. Also, don't forget, this would actually be a terrible spam detector today since this is based on data from a very different era of the internet, for a very specific set of people. Spam has changed a lot since the 90s! (Ironically, machine learning is probably partially to blame.)
 
-This chapter has provided a rather quick introduction to classification, and thus, machine learning. For a more complete coverage of machine learning, [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/){target=""_blank""} is a highly recommended resource. Additionally, [`R` for Statistical Learning](https://daviddalpiaz.github.io/r4sl/){target=""_blank""} has been written as a supplement which provides additional detail on how to perform these methods using `R`. The [classification](https://daviddalpiaz.github.io/r4sl/classification-overview.html){target=""_blank""} and [logistic regression](https://daviddalpiaz.github.io/r4sl/logistic-regression.html){target=""_blank""} chapters might be useful.
+This chapter has provided a rather quick introduction to classification, and thus, machine learning. For a more complete coverage of machine learning, [An Introduction to Statistical Learning](https://www.statlearning.com/){target=""_blank""} is a highly recommended resource. Additionally, [`R` for Statistical Learning](https://daviddalpiaz.github.io/r4sl/){target=""_blank""} has been written as a supplement which provides additional detail on how to perform these methods using `R`. The [classification](https://daviddalpiaz.github.io/r4sl/classification-overview.html){target=""_blank""} and [logistic regression](https://daviddalpiaz.github.io/r4sl/logistic-regression.html){target=""_blank""} chapters might be useful.
 
 We should note that the code to perform classification using logistic regression is presented in a way that illustrates the concepts to the reader. In practice, you may prefer to use a more general machine learning pipeline such as [`caret`](http://topepo.github.io/caret/index.html){target=""_blank""} in `R`. This will streamline processes for creating predictions and generating evaluation metrics.
 "
daviddalpiaz,appliedstats,abb5cda728b01eb841a499b78f37f15818f60417,Ossama Sybesma,ossama_sybesma@hotmail.com,2024-01-07T15:49:26Z,GitHub,noreply@github.com,2024-01-07T15:49:26Z,"chore: Fix numbers in logistic.Rmd

The false positive in the code output is 127, instead 137 has been written down.

The same mistake has been made for the false negative 157, instead 161 is being used.

Fixed the numbers so the story adds up.",logistic.Rmd,True,False,True,False,2,2,4,"---FILE: logistic.Rmd---
@@ -1006,7 +1006,7 @@ table(spam_tst$type) / nrow(spam_tst)
 
 First, note that to be a reasonable classifier, it needs to outperform the obvious classifier of simply classifying all observations to the majority class. In this case, classifying everything as non-spam for a test misclassification rate of `r as.numeric((table(spam_tst$type) / nrow(spam_tst))[2])`
 
-Next, we can see that using the classifier created from `fit_additive`, only a total of $137 + 161 = 298$ from the total of 3601 emails in the test set are misclassified. Overall, the accuracy in the test set it
+Next, we can see that using the classifier created from `fit_additive`, only a total of $127 + 157 = 284$ from the total of 3601 emails in the test set are misclassified. Overall, the accuracy in the test set it
 
 ```{r}
 mean(spam_tst_pred == spam_tst$type)
@@ -1020,7 +1020,7 @@ mean(spam_tst_pred != spam_tst$type)
 
 This seems like a decent classifier...
 
-However, are all errors created equal? In this case, absolutely not. The 137 non-spam emails that were marked as spam (false positives) are a problem. We can't allow important information, say, a job offer, to miss our inbox and get sent to the spam folder. On the other hand, the 161 spam email that would make it to an inbox (false negatives) are easily dealt with, just delete them.
+However, are all errors created equal? In this case, absolutely not. The 127 non-spam emails that were marked as spam (false positives) are a problem. We can't allow important information, say, a job offer, to miss our inbox and get sent to the spam folder. On the other hand, the 157 spam email that would make it to an inbox (false negatives) are easily dealt with, just delete them.
 
 Instead of simply evaluating a classifier based on its misclassification rate (or accuracy), we'll define two additional metrics, sensitivity and specificity. Note that these are simply two of many more metrics that can be considered. The [Wikipedia page for sensitivity and specificity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity){target=""_blank""} details a large number of metrics that can be derived from a confusion matrix.
 "
daviddalpiaz,appliedstats,b99ebcc9be6f5712bedfecebf80b1d2741bb1051,Ossama Sybesma,ossama_sybesma@hotmail.com,2024-01-07T13:51:07Z,GitHub,noreply@github.com,2024-01-07T13:51:07Z,"chore: Fixed another typo in logistic.Rmd

""proportion of correction classifications"" to ""proportion of correct classifications""",logistic.Rmd,True,False,True,False,1,1,2,"---FILE: logistic.Rmd---
@@ -909,7 +909,7 @@ In reality, we didn't actually suppress it, but instead changed `maxit` to `75`,
 
 ### Evaluating Classifiers
 
-The metric we'll be most interested in for evaluating the overall performance of a classifier is the **misclassification rate**. (Sometimes, instead accuracy is reported, which is instead the proportion of correction classifications, so both metrics serve the same purpose.)
+The metric we'll be most interested in for evaluating the overall performance of a classifier is the **misclassification rate**. (Sometimes, instead accuracy is reported, which is instead the proportion of correct classifications, so both metrics serve the same purpose.)
 
 $$
 \text{Misclass}(\hat{C}, \text{Data}) = \frac{1}{n}\sum_{i = 1}^{n}I(y_i \neq \hat{C}({\bf x_i}))"
daviddalpiaz,appliedstats,8e24cefbf24ea5d0411e01bee55d03e9caea80d6,Ossama Sybesma,ossama_sybesma@hotmail.com,2024-01-06T18:50:35Z,GitHub,noreply@github.com,2024-01-06T18:50:35Z,"fix: Typo in logistic.Rmd

Changed Fist to First in the sentence: ""Fist, we’ll use the predict() function to obtain ^η(x) for this observation.""",logistic.Rmd,True,False,True,False,1,1,2,"---FILE: logistic.Rmd---
@@ -702,7 +702,7 @@ new_obs = data.frame(
 )
 ```
 
-Fist, we'll use the `predict()` function to obtain $\hat{\eta}({\bf x})$ for this observation.
+First, we'll use the `predict()` function to obtain $\hat{\eta}({\bf x})$ for this observation.
 
 ```{r}
 eta_hat = predict(chd_mod_selected, new_obs, se.fit = TRUE, type = ""link"")"
daviddalpiaz,appliedstats,b9363110b21850b9fa093e32b13fcc2743bfaf9e,daviddalpiaz,dalpiaz2@illinois.edu,2022-10-21T19:55:01Z,daviddalpiaz,dalpiaz2@illinois.edu,2022-10-21T19:55:01Z,master -> main to fix actions?,.github/workflows/bookdown.yaml,False,False,False,False,3,3,6,"---FILE: .github/workflows/bookdown.yaml---
@@ -17,13 +17,13 @@ jobs:
 
       # Deploy with master... Let's see what goes wrong! 
       - name: Setup R
-        uses: r-lib/actions/setup-r@master
+        uses: r-lib/actions/setup-r@main
 
       - name: Install tinytex
-        uses: r-lib/actions/setup-tinytex@master
+        uses: r-lib/actions/setup-tinytex@main
 
       - name: Setup pandoc
-        uses: r-lib/actions/setup-pandoc@master
+        uses: r-lib/actions/setup-pandoc@main
         
       - name: Install XQuartz on macOS
         if: runner.os == 'macOS'"
daviddalpiaz,appliedstats,614fe952a31928d1b19a6055fbfe9eec979cb0fa,chadyuu,yutaro.nishiyama.07@gmail.com,2022-07-30T07:06:02Z,chadyuu,yutaro.nishiyama.07@gmail.com,2022-08-01T03:56:50Z,fix typo in the equation,logistic.Rmd,True,False,True,False,1,1,2,"---FILE: logistic.Rmd---
@@ -155,7 +155,7 @@ $$
 With $n$ observations, we write the model indexed with $i$ to note that it is being applied to each observation. 
 
 $$
-\log\left(\frac{p({\bf x_i})}{1 - p({\bf x_i)})}\right) = \beta_0 + \beta_1 x_{i1} + \cdots + \beta_{p-1} x_{i(p-1)}
+\log\left(\frac{p({\bf x_i})}{1 - p({\bf x_i})}\right) = \beta_0 + \beta_1 x_{i1} + \cdots + \beta_{p-1} x_{i(p-1)}
 $$
 
 We can apply the inverse logit transformation to obtain $P[Y_i = 1 \mid {\bf X_i} = {\bf x_i}]$ for each observation. Since these are probabilities, it's good that we used a function that returns values between $0$ and $1$."
daviddalpiaz,appliedstats,c900a79c07c3d7b4ba4b66a15a29ba4853b66a94,chadyuu,yutaro.nishiyama.07@gmail.com,2022-07-14T01:28:37Z,chadyuu,yutaro.nishiyama.07@gmail.com,2022-07-14T01:28:37Z,added predict function for logistic regression,logistic.Rmd,True,False,True,False,6,0,6,"---FILE: logistic.Rmd---
@@ -303,6 +303,12 @@ Making predictions with an object of type  `glm` is slightly different than maki
 
 That is, `type = ""link""` will get you the log odds, while `type = ""response""` will return the estimated mean, in this case, $P[Y = 1 \mid {\bf X} = {\bf x}]$ for each observation.
 
+```{r}
+predict(fit_glm, data.frame(x = 1.2)) # type = ""link"" as default
+predict(fit_glm, data.frame(x = 1.2), type = ""link"")
+predict(fit_glm, data.frame(x = 1.2), type = ""response"")
+```
+
 ```{r}
 plot(y ~ x, data = example_data, 
      pch = 20, ylab = ""Estimated Probability"", "
daviddalpiaz,appliedstats,abfbf1800fe76f411501f530b10df2d6473c319f,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-27T04:58:52Z,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-27T04:58:52Z,fix typo in chapter16,selection.Rmd,True,False,True,False,1,1,2,"---FILE: selection.Rmd---
@@ -239,7 +239,7 @@ lines(xplot, predict(fit_big_removed, newdata = data.frame(x = xplot)),
       col = ""darkorange"", lwd = 2, lty = 2)
 ```
 
-We see that on average, the solid blue line for the quadratic model has similar errors as before. It has changed very slightly. However, the dashed orange line for the large model, has a huge error at the point that was removed and is much different from the previous fit.
+We see that on average, the solid blue line for the quadratic model has similar errors as before. It has changed very slightly. However, the dashed orange line for the large model, has a huge error at the point that was removed and is much different than the previous fit.
 
 This is the purpose of cross-validation. By assessing how the model fits points that were not used to perform the regression, we get an idea of how well the model will work for future observations. It assesses how well the model works in general, not simply on the observed data.
 "
daviddalpiaz,appliedstats,0cdf94ebae0025c31b0c81363e01027728d590c6,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-27T04:55:20Z,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-27T04:55:20Z,fix typo in chapter13,diagnostics.Rmd,True,False,True,False,1,1,2,"---FILE: diagnostics.Rmd---
@@ -296,7 +296,7 @@ hist(resid(fit_3),
      breaks = 20)
 ```
 
-Above are histograms for each of the three regressions we have been considering. Notice that the first, for `fit_1` appears very normal. The third, for `fit_3`, appears to be very non-normal. However `fit_2` is not as clear. It does have a rough bell shape, however, it also has a very sharp peak. For this reason we will usually use more powerful tools such as **Q-Q plots** and the **Shapiro-Wilk test** for assessing the normality of errors.
+Above are histograms for each of the three regression models we have been considering. Notice that the first, for `fit_1` appears very normal. The third, for `fit_3`, appears to be very non-normal. However `fit_2` is not as clear. It does have a rough bell shape, however, it also has a very sharp peak. For this reason we will usually use more powerful tools such as **Q-Q plots** and the **Shapiro-Wilk test** for assessing the normality of errors.
 
 ### Q-Q Plots
 "
daviddalpiaz,appliedstats,8e1a0b0eb97c3a11485eccbd2181d05b3a56b385,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-27T04:53:49Z,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-27T04:53:49Z,fix typo in chapter12,anova.Rmd,True,False,True,False,2,2,4,"---FILE: anova.Rmd---
@@ -171,7 +171,7 @@ where the mean of each group is given by
 
 Here $\alpha_i$ measures the effect of group $i$. It is the difference between the overall mean and the mean of group $i$.
 
-Essentially, the assumptions here are the same as the two sample cases, however now, we simply have more groups.
+Essentially, the assumptions here are the same as the two-sample case, however now, we simply have more groups.
 
 Much like the two-sample case, we would again like to test if the means of the groups are equal.
 
@@ -690,7 +690,7 @@ levels(rats$poison)
 levels(rats$treat)
 ```
 
-Here, 48 rats were randomly assigned both one of three poisons and one of four possible treatments. The experimenters then measure their survival time in tens of hours. A total of 12 groups, each with 4 replicates.
+Here, 48 rats were randomly assigned both one of three poisons and one of four possible treatments. The experimenters then measured their survival time in tens of hours. A total of 12 groups, each with 4 replicates.
 
 Before running any tests, we should first look at the data. We will create **interaction plots**, which will help us visualize the effect of one factor, as we move through the levels of another factor.
 "
daviddalpiaz,appliedstats,db49f87653964c953ac6e070686a46db3ea2e9af,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-12T04:59:42Z,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-13T06:05:01Z,fix typo chapter18,beyond.Rmd,True,False,True,False,6,6,12,"---FILE: beyond.Rmd---
@@ -14,11 +14,11 @@ So you've completed STAT 420, where do you go from here? Now that you understand
 
 ## RStudio
 
-RStudio has recently released version 1.0! This is exciting for a number of reason, especially the release of [`R` Notebooks](http://rmarkdown.rstudio.com/r_notebooks.html){target=""_blank""}. `R` Notebooks combine the RMarkdown you have already learned with the ability to work interactively.
+RStudio has recently released version 1.0! This is exciting for a number of reasons, especially the release of [`R` Notebooks](http://rmarkdown.rstudio.com/r_notebooks.html){target=""_blank""}. `R` Notebooks combine the RMarkdown you have already learned with the ability to work interactively.
 
 ## Tidy Data
 
-In this textbook, much of the data we have seen has been nice and tidy. It was rectangular where each row is an observation and each column is a variable. This is not always the case! Many packages have been developed to deal with data, and force it into a nice format, which is called [tidy data](http://vita.had.co.nz/papers/tidy-data.pdf){target=""_blank""}, that we can then use for modeling. Often during analysis, this is where a large portion of your time will be spent.
+In this textbook, much of the data we have seen has been nice and tidy. It was rectangular where each row was an observation and each column was a variable. This is not always the case! Many packages have been developed to deal with data, and force it into a nice format, which is called [tidy data](http://vita.had.co.nz/papers/tidy-data.pdf){target=""_blank""}, that we can then use for modeling. Often during analysis, this is where a large portion of your time will be spent.
 
 The `R` community has started to call this collection of packages the [Tidyverse](http://tidyverse.org/){target=""_blank""}. It was once called the Hadleyverse, as [Hadley Wickham](http://hadley.nz/){target=""_blank""} has authored so many of the packages. Hadley is writing a book called [`R` for Data Science](http://r4ds.had.co.nz/){target=""_blank""} which describes the use of many of these packages. (And also how to use some to make the modeling process better!) This book is a great starting point for diving deeper into the `R` community. The two main packages are [`dplyr`](https://cran.r-project.org/web/packages/dplyr/vignettes/dplyr.html){target=""_blank""} and [`tidyr`](https://blog.rstudio.org/2014/07/22/introducing-tidyr/){target=""_blank""} both of which are used internally in RStudio.
 
@@ -30,21 +30,21 @@ Use of the [`manipulate` package](https://support.rstudio.com/hc/en-us/articles/
 
 ## Web Applications
 
-RStudio has made it incredible easy to create data products through the use of [Shiny](https://shiny.rstudio.com/){target=""_blank""}, which allows for the creation of web applications with `R`. RStudio maintains an ever-growing [tutorial](http://shiny.rstudio.com/tutorial/){target=""_blank""} and [gallery](https://shiny.rstudio.com/gallery/){target=""_blank""} of examples.
+RStudio has made it incredibly easy to create data products through the use of [Shiny](https://shiny.rstudio.com/){target=""_blank""}, which allows for the creation of web applications with `R`. RStudio maintains an ever-growing [tutorial](http://shiny.rstudio.com/tutorial/){target=""_blank""} and [gallery](https://shiny.rstudio.com/gallery/){target=""_blank""} of examples.
 
 ## Experimental Design
 
-In the ANOVA chapter, we briefly discussed experimental design. This topic could easily be its own class, and is currently an area of revitalized interest with the rise of [A/B testing.](https://en.wikipedia.org/wiki/A/B_testing){target=""_blank""} Two more classic statistical references include *Statistics for Experimenters* by Box, Hunter, and Hunter as well as *Design and Analysis of Experiments* by Douglas Montgomery. There are several `R` packages for design of experiments, list in the [CRAN Task View](https://cran.r-project.org/web/views/ExperimentalDesign.html){target=""_blank""}.
+In the ANOVA chapter, we briefly discussed experimental design. This topic could easily be its own class, and is currently an area of revitalized interest with the rise of [A/B testing.](https://en.wikipedia.org/wiki/A/B_testing){target=""_blank""} Two more classic statistical references include *Statistics for Experimenters* by Box, Hunter, and Hunter as well as *Design and Analysis of Experiments* by Douglas Montgomery. There are several `R` packages for design of experiments, listed in the [CRAN Task View](https://cran.r-project.org/web/views/ExperimentalDesign.html){target=""_blank""}.
 
 ## Machine Learning
 
 Using models for prediction is the key focus of machine learning. There are many methods, each with its own package, however `R` has a wonderful package called [`caret`, *Classification And REgression Training*,](http://topepo.github.io/caret/index.html){target=""_blank""} which provides a unified interface to training these models. It also contains various utilities for data processing and visualization that are useful for predictive modeling. 
 
-*Applied Predictive Modeling* by Max Kuhn, the author of the `caret` package is a good general resource for predictive modeling, which obviously utilizes `R`. [*An Introduction to Statistical Learning*](http://www-bcf.usc.edu/~gareth/ISL/){target=""_blank""} by James, Witten, Hastie, and Tibshirani is a gentle introduction to machine learning from a statistical perspective which uses `R` and picks up right where this courses stops. This is based on the often referenced [*The Elements of Statistical Learning*](https://web.stanford.edu/~hastie/Papers/ESLII.pdf){target=""_blank""} by Hastie, Tibshirani, and Friedman. Both are freely available online.
+*Applied Predictive Modeling* by Max Kuhn, the author of the `caret` package, is a good general resource for predictive modeling, which obviously utilizes `R`. [*An Introduction to Statistical Learning*](http://www-bcf.usc.edu/~gareth/ISL/){target=""_blank""} by James, Witten, Hastie, and Tibshirani is a gentle introduction to machine learning from a statistical perspective which uses `R` and picks up right where this course stops. This is based on the often referenced [*The Elements of Statistical Learning*](https://web.stanford.edu/~hastie/Papers/ESLII.pdf){target=""_blank""} by Hastie, Tibshirani, and Friedman. Both are freely available online.
 
 ### Deep Learning
 
-While, it probably isn't the best tool for the job, `R` now has the ability to [train deep neural networks via TensorFlow](https://rstudio.github.io/tensorflow/){target=""_blank""}.
+While it probably isn't the best tool for the job, `R` now has the ability to [train deep neural networks via TensorFlow](https://rstudio.github.io/tensorflow/){target=""_blank""}.
 
 ## Time Series
 "
daviddalpiaz,appliedstats,57a4c7a30b5b0c15e3245ec56d0c0c626f088e4d,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-12T04:51:38Z,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-13T06:05:01Z,fix typo chapter17,logistic.Rmd,True,False,True,False,13,13,26,"---FILE: logistic.Rmd---
@@ -101,9 +101,9 @@ $$
 \log\left(\frac{p({\bf x})}{1 - p({\bf x})}\right) = \beta_0 + \beta_1 x_1 + \ldots  + \beta_{p - 1} x_{p - 1}
 $$
 
-Immediately we notice some similarities to ordinary linear regression, in particular, the right hand side. This is our usual linear combination of the predictors. We have our usual $p - 1$ predictors for a total of $p$ $\beta$ parameters. (Note, many more machine learning focused texts will use $p$ as the number of predictors. This is an arbitrary choice, but you should be aware of it.)
+Immediately we notice some similarities to ordinary linear regression, in particular, the right-hand side. This is our usual linear combination of the predictors. We have our usual $p - 1$ predictors for a total of $p$ $\beta$ parameters. (Note, many more machine learning focused texts will use $p$ as the number of predictors. This is an arbitrary choice, but you should be aware of it.)
 
-The left hand side is called the **log odds**, which is the log of the odds. The odds are the probability for a positive event $(Y = 1)$ divided by the probability of a negative event $(Y = 0)$. So when the odds are $1$, the two events have equal probability. Odds greater than $1$ favor a positive event. The opposite is true when the odds are less than $1$.
+The left-hand side is called the **log odds**, which is the log of the odds. The odds are the probability for a positive event $(Y = 1)$ divided by the probability of a negative event $(Y = 0)$. So when the odds are $1$, the two events have equal probability. Odds greater than $1$ favor a positive event. The opposite is true when the odds are less than $1$.
 
 $$
 \frac{p({\bf x})}{1 - p({\bf x})} = \frac{P[Y = 1 \mid {\bf X} = {\bf x}]}{P[Y = 0 \mid {\bf X} = {\bf x}]}
@@ -123,7 +123,7 @@ $$
 
 Note that for $x \in (-\infty, \infty))$, this function outputs values between 0 and 1.
 
-Students often ask, where is the error term? The answer is that its something that is specific to the normal model. First notice that the model with the error term,
+Students often ask, where is the error term? The answer is that it's something that is specific to the normal model. First notice that the model with the error term,
 
 $$
 Y = \beta_0 + \beta_1x_1 + \ldots + \beta_qx_q + \epsilon, \ \ \epsilon \sim N(0, \sigma^2)
@@ -265,7 +265,7 @@ example_data = sim_logistic_data()
 head(example_data)
 ```
 
-After simulating a dataset, we'll then fit both ordinary linear regression and logistic regression. Notice that currently the responses variable `y` is a numeric variable that only takes values `0` and `1`. Later we'll see that we can also fit logistic regression when the response is a factor variable with only two levels. (Generally, having a factor response is preferred, but having a dummy response allows use to make the comparison to using ordinary linear regression.)
+After simulating a dataset, we'll then fit both ordinary linear regression and logistic regression. Notice that currently the responses variable `y` is a numeric variable that only takes values `0` and `1`. Later we'll see that we can also fit logistic regression when the response is a factor variable with only two levels. (Generally, having a factor response is preferred, but having a dummy response allows us to make the comparison to using ordinary linear regression.)
 
 ```{r}
 # ordinary linear regression
@@ -766,7 +766,7 @@ You may have realized this before we actually explicitly wrote it down!
 
 You have probably noticed that the output from `summary()` is also very similar to that of ordinary linear regression. One difference, is the ""deviance"" being reported. The `Null deviance` is the deviance for the null model, that is, a model with no predictors. The `Residual deviance` is the deviance for the model that was fit.
 
-[**Deviance**](https://en.wikipedia.org/wiki/Deviance_(statistics)){target=""_blank""} compares the model to a saturated model. (Without repeated observations, a saturated model is a model that fits perfectly, using a parameter for each observation.) Essentially, deviance is a generalized *residual sum of squares* for GLMs. Like RSS, deviance decreased as the model complexity increases.
+[**Deviance**](https://en.wikipedia.org/wiki/Deviance_(statistics)){target=""_blank""} compares the model to a saturated model. (Without repeated observations, a saturated model is a model that fits perfectly, using a parameter for each observation.) Essentially, deviance is a generalized *residual sum of squares* for GLMs. Like RSS, deviance decreases as the model complexity increases.
 
 ```{r}
 deviance(chd_mod_ldl)
@@ -839,7 +839,7 @@ data(""spam"")
 tibble::as.tibble(spam)
 ```
 
-This dataset, created in the late 1990s at Hewlett-Packard Labs, contains 4601 emails, of which 1813 are considered spam. The remaining are not spam. (Which for simplicity, we might call, ham.) Additional details can be obtained by using `?spam` of by visiting the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/spambase){target=""_blank""}. 
+This dataset, created in the late 1990s at Hewlett-Packard Labs, contains 4601 emails, of which 1813 are considered spam. The remaining are not spam. (Which for simplicity, we might call, ham.) Additional details can be obtained by using `?spam` or by visiting the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/spambase){target=""_blank""}. 
 
 The response variable, `type`, is a **factor** with levels that label each email as `spam` or `nonspam`. When fitting models, `nonspam` will be the reference level, $Y = 0$, as it comes first alphabetically.
 
@@ -848,7 +848,7 @@ is.factor(spam$type)
 levels(spam$type)
 ```
 
-Many of the predictors (often called features in machine learning) are engineered based on the emails. For example, `charDollar` is the number of times an email contains the `$` character. Some variables are highly specific to this dataset, for example `george` and `num650`. (The name and area code for one of the researchers whose emails were used.) We should keep in mind that this dataset was created based on emails send to academic type researcher in the 1990s. Any results we derive probably won't generalize to modern emails for the general public.
+Many of the predictors (often called features in machine learning) are engineered based on the emails. For example, `charDollar` is the number of times an email contains the `$` character. Some variables are highly specific to this dataset, for example `george` and `num650`. (The name and area code for one of the researchers whose emails were used.) We should keep in mind that this dataset was created based on emails sent to academic type researchers in the 1990s. Any results we derive probably won't generalize to modern emails for the general public.
 
 To get started, we'll first test-train split the data.
 
@@ -925,7 +925,7 @@ Because of this, training data isn't useful for evaluating, as it would suggest
 
 To overcome this, we'll use cross-validation as we did with ordinary linear regression, but this time we'll cross-validate the misclassification rate. To do so, we'll use the `cv.glm()` function from the `boot` library. It takes arguments for the data (in this case training), a model fit via `glm()`, and `K`, the number of folds. See `?cv.glm` for details.
 
-Previously, for cross-validating RMSE in ordinary linear regression, we used LOOCV. We certainly could do that here. However, with logistic regression, we no longer have the clever trick that would allow use to obtain a LOOCV metric without needing to fit the model $n$ times. So instead, we'll use 5-fold cross-validation. (5 and 10 fold are the most common in practice.) Instead of leaving a single observation out repeatedly, we'll leave out a fifth of the data.
+Previously, for cross-validating RMSE in ordinary linear regression, we used LOOCV. We certainly could do that here. However, with logistic regression, we no longer have the clever trick that would allow us to obtain a LOOCV metric without needing to fit the model $n$ times. So instead, we'll use 5-fold cross-validation. (5 and 10 fold are the most common in practice.) Instead of leaving a single observation out repeatedly, we'll leave out a fifth of the data.
 
 Essentially we'll repeat the following process 5 times:
 
@@ -994,7 +994,7 @@ table(spam_tst$type) / nrow(spam_tst)
 
 First, note that to be a reasonable classifier, it needs to outperform the obvious classifier of simply classifying all observations to the majority class. In this case, classifying everything as non-spam for a test misclassification rate of `r as.numeric((table(spam_tst$type) / nrow(spam_tst))[2])`
 
-Next, we can see that using the classifier create from `fit_additive`, only a total of $137 + 161 = 298$ from the total of 3601 email in the test set are misclassified. Overall, the accuracy in the test set it
+Next, we can see that using the classifier created from `fit_additive`, only a total of $137 + 161 = 298$ from the total of 3601 emails in the test set are misclassified. Overall, the accuracy in the test set it
 
 ```{r}
 mean(spam_tst_pred == spam_tst$type)
@@ -1008,9 +1008,9 @@ mean(spam_tst_pred != spam_tst$type)
 
 This seems like a decent classifier...
 
-However, are all errors created equal? In this case, absolutely not. The 137 non-spam emails that were marked as spam (false positives) are a problem. We can't allow important information, say, a job offer, miss our inbox and get sent to the spam folder. On the other hand, the 161 spam email that would make it to an inbox (false negatives) are easily dealt with, just delete them.
+However, are all errors created equal? In this case, absolutely not. The 137 non-spam emails that were marked as spam (false positives) are a problem. We can't allow important information, say, a job offer, to miss our inbox and get sent to the spam folder. On the other hand, the 161 spam email that would make it to an inbox (false negatives) are easily dealt with, just delete them.
 
-Instead of simply evaluating a classifier based on its misclassification rate (or accuracy), we'll define two additional metrics, sensitivity and specificity. Note that these are simply two of many more metrics that can be considered. The [Wikipedia page for sensitivity and specificity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity){target=""_blank""} details a large number of metrics that can be derived form a confusion matrix.
+Instead of simply evaluating a classifier based on its misclassification rate (or accuracy), we'll define two additional metrics, sensitivity and specificity. Note that these are simply two of many more metrics that can be considered. The [Wikipedia page for sensitivity and specificity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity){target=""_blank""} details a large number of metrics that can be derived from a confusion matrix.
 
 **Sensitivity** is essentially the true positive rate. So when sensitivity is high, the number of false negatives is low.
 
@@ -1099,11 +1099,11 @@ get_sens(conf_mat_90)
 get_spec(conf_mat_90)
 ```
 
-While this is far fewer false positives, is it acceptable though? Still probably not. Also, don't forget, this would actually be a terrible spam detector today since this is based on data from a very different era of the internet, for a very specific set of people. Spam has changed a lot since 90s! (Ironically, machine learning is probably partially to blame.)
+While this is far fewer false positives, is it acceptable though? Still probably not. Also, don't forget, this would actually be a terrible spam detector today since this is based on data from a very different era of the internet, for a very specific set of people. Spam has changed a lot since the 90s! (Ironically, machine learning is probably partially to blame.)
 
 This chapter has provided a rather quick introduction to classification, and thus, machine learning. For a more complete coverage of machine learning, [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/){target=""_blank""} is a highly recommended resource. Additionally, [`R` for Statistical Learning](https://daviddalpiaz.github.io/r4sl/){target=""_blank""} has been written as a supplement which provides additional detail on how to perform these methods using `R`. The [classification](https://daviddalpiaz.github.io/r4sl/classification-overview.html){target=""_blank""} and [logistic regression](https://daviddalpiaz.github.io/r4sl/logistic-regression.html){target=""_blank""} chapters might be useful.
 
-We should note that the code to perform classification using logistic regression is presented in a way that illustrates the concepts to the reader. In practice, you may to prefer to use a more general machine learning pipeline such as [`caret`](http://topepo.github.io/caret/index.html){target=""_blank""} in `R`. This will streamline processes for creating predictions and generating evaluation metrics.
+We should note that the code to perform classification using logistic regression is presented in a way that illustrates the concepts to the reader. In practice, you may prefer to use a more general machine learning pipeline such as [`caret`](http://topepo.github.io/caret/index.html){target=""_blank""} in `R`. This will streamline processes for creating predictions and generating evaluation metrics.
 
 ## `R` Markdown
 "
daviddalpiaz,appliedstats,ad608e3b8e5a30b19d67fa6fe649b0339a20ed58,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-12T04:32:55Z,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-13T06:04:54Z,fix typo chapter16,selection.Rmd,True,False,True,False,17,17,34,"---FILE: selection.Rmd---
@@ -14,15 +14,15 @@ After reading this chapter you will be able to:
 - Use variable selection procedures to find a good model from a set of possible models.
 - Understand the two uses of models: explanation and prediction.
 
-Last chapter we saw how correlation between predictor variables can have undesirable effects on models. We used variance inflation factors to assess the severity of the collinearity issues caused by these correlations. We also saw how fitting a smaller model, leaving out some of the correlated predictors, results in a model which no longer suffers from collinearity issues. But how should we chose this smaller model?
+Last chapter we saw how correlation between predictor variables can have undesirable effects on models. We used variance inflation factors to assess the severity of the collinearity issues caused by these correlations. We also saw how fitting a smaller model, leaving out some of the correlated predictors, results in a model which no longer suffers from collinearity issues. But how should we choose this smaller model?
 
 This chapter, we will discuss several *criteria* and *procedures* for choosing a ""good"" model from among a choice of many.
 
 ## Quality Criterion
 
-So far, we have seen criteria such as $R^2$ and $\text{RMSE}$ for assessing quality of fit. However, both of these have a fatal flaw. By increasing the size of a model, that is adding predictors, that can at worst not improve. It is impossible to add a predictor to a model and make $R^2$ or $\text{RMSE}$ worse. That means, if we were to use either of these to chose between models, we would *always* simply choose the larger model. Eventually we would simply be fitting to noise.
+So far, we have seen criteria such as $R^2$ and $\text{RMSE}$ for assessing quality of fit. However, both of these have a fatal flaw. By increasing the size of a model, that is adding predictors, that can at worst not improve. It is impossible to add a predictor to a model and make $R^2$ or $\text{RMSE}$ worse. That means, if we were to use either of these to choose between models, we would *always* simply choose the larger model. Eventually we would simply be fitting to noise.
 
-This suggests that we need a quality criteria that takes into account the size of the model, since our preference is for small models that still fit well. We are willing to sacrifice a small amount of ""goodness-of-fit"" for obtaining a smaller model. (Here we use ""goodness-of-fit"" to simply mean how far the data is from the model, the smaller the errors the better. Often in statistics, goodness-of-fit can have a more precise meaning.) We will look at three criteria that do this explicitly: $\text{AIC}$, $\text{BIC}$, and Adjusted $R^2$. We will also look at one, Cross-Validated $\text{RMSE}$, which implicitly considers the size of the model.
+This suggests that we need a quality criterion that takes into account the size of the model, since our preference is for small models that still fit well. We are willing to sacrifice a small amount of ""goodness-of-fit"" for obtaining a smaller model. (Here we use ""goodness-of-fit"" to simply mean how far the data is from the model, the smaller the errors the better. Often in statistics, goodness-of-fit can have a more precise meaning.) We will look at three criteria that do this explicitly: $\text{AIC}$, $\text{BIC}$, and Adjusted $R^2$. We will also look at one, Cross-Validated $\text{RMSE}$, which implicitly considers the size of the model.
 
 ### Akaike Information Criterion
 
@@ -50,7 +50,7 @@ The likelihood portion of $\text{AIC}$ is given by
 -2 \log L(\boldsymbol{\hat{\beta}}, \hat{\sigma}^2) = n + n \log(2\pi) + n \log\left(\frac{\text{RSS}}{n}\right).
 \]
 
-For the sake of comparing models, the only term here that will change is $n \log\left(\frac{\text{RSS}}{n}\right)$, which is function of $\text{RSS}$. The 
+For the sake of comparing models, the only term here that will change is $n \log\left(\frac{\text{RSS}}{n}\right)$, which is a function of $\text{RSS}$. The 
 
 \[
 n + n \log(2\pi)
@@ -96,7 +96,7 @@ whereas for $\text{BIC}$, the penalty is
 
 So, for any dataset where $log(n) > 2$ the $\text{BIC}$ penalty will be larger than the $\text{AIC}$ penalty, thus $\text{BIC}$ will likely prefer a smaller model.  
 
-Note that, sometimes the penalty is considered a general expression of the form
+Note that sometimes the penalty is considered a general expression of the form
 
 \[
 k \cdot p.
@@ -239,9 +239,9 @@ lines(xplot, predict(fit_big_removed, newdata = data.frame(x = xplot)),
       col = ""darkorange"", lwd = 2, lty = 2)
 ```
 
-We see that on average, the solid blue line for the quadratic model has similar errors as before. It has changed very slightly. However, the dashed orange line for the large model, has a huge error at the point that was removed and is much different that the previous fit.
+We see that on average, the solid blue line for the quadratic model has similar errors as before. It has changed very slightly. However, the dashed orange line for the large model, has a huge error at the point that was removed and is much different from the previous fit.
 
-This is the purpose of cross-validation. By assessing how the model fits points that were not used to perform the regression, we get an idea of how well the model will work for future observations. It assess how well the model works in general, not simply on the observed data.
+This is the purpose of cross-validation. By assessing how the model fits points that were not used to perform the regression, we get an idea of how well the model will work for future observations. It assesses how well the model works in general, not simply on the observed data.
 
 ## Selection Procedures
 
@@ -265,15 +265,15 @@ If we had 10 or more predictors, we would already be considering over 1000 model
 
 ### Backward Search
 
-Backward selection procedures start with all possible predictors in the model, then considers how deleting a single predictor will effect a chosen metric. Let's try this on the `seatpos` data. We will use the `step()` function in `R` which by default uses $\text{AIC}$ as its metric of choice.
+Backward selection procedures start with all possible predictors in the model, then consider how deleting a single predictor will affect a chosen metric. Let's try this on the `seatpos` data. We will use the `step()` function in `R` which by default uses $\text{AIC}$ as its metric of choice.
 
 ```{r}
 hipcenter_mod_back_aic = step(hipcenter_mod, direction = ""backward"")
 ```
 
 We start with the model `hipcenter ~ .`, which is otherwise known as `hipcenter ~ Age + Weight + HtShoes + Ht + Seated + Arm + Thigh + Leg`. `R` will then repeatedly attempt to delete a predictor until it stops, or reaches the model `hipcenter ~ 1`, which contains no predictors.
 
-At each ""step"", `R` reports the current model, its $\text{AIC}$, and the possible steps with their $\text{RSS}$ and more importantly $\text{AIC}$.
+At each ""step,"" `R` reports the current model, its $\text{AIC}$, and the possible steps with their $\text{RSS}$ and more importantly $\text{AIC}$.
 
 In this example, at the first step, the current model is `hipcenter ~ Age + Weight + HtShoes + Ht + Seated + Arm + Thigh + Leg` which has an AIC of `283.62`. Note that when `R` is calculating this value, it is using `extractAIC()`, which uses the expression
 
@@ -290,7 +290,7 @@ n = length(resid(hipcenter_mod))
 n * log(mean(resid(hipcenter_mod) ^ 2)) + 2 * p
 ```
 
-Returning to the first step, `R` then gives us a row which shows the effect of deleting each of the current predictors. The `-` signs at the beginning of each row indicates we are considering removing a predictor. There is also a row with `<none>` which is a row for keeping the current model. Notice that this row has the smallest $\text{RSS}$, as it is the largest model.
+Returning to the first step, `R` then gives us a row which shows the effect of deleting each of the current predictors. The `-` signs at the beginning of each row indicate we are considering removing a predictor. There is also a row with `<none>` which is a row for keeping the current model. Notice that this row has the smallest $\text{RSS}$, as it is the largest model.
 
 We see that every row above `<none>` has a smaller $\text{AIC}$ than the row for `<none>` with the one at the top, `Ht`, giving the lowest $\text{AIC}$. Thus we remove `Ht` from the model, and continue the process.
 
@@ -589,7 +589,7 @@ We'll try backwards search with both $\text{AIC}$ and $\text{BIC}$ to attempt to
 autompg_mod_back_aic = step(autompg_big_mod, direction = ""backward"", trace = 0)
 ```
 
-Notice that we used `trace = 0` in the function call. This suppress the output for each step, and simply stores the chosen model. This is useful, as this code would otherwise create a large amount of output. If we had viewed the output, which you can try on your own by removing `trace = 0`, we would see that `R` only considers the `cyl` variable as a single variable, despite the fact that it is coded using two dummy variables. So removing `cyl` would actually remove two parameters from the resulting model.
+Notice that we used `trace = 0` in the function call. This suppresses the output for each step, and simply stores the chosen model. This is useful, as this code would otherwise create a large amount of output. If we had viewed the output, which you can try on your own by removing `trace = 0`, we would see that `R` only considers the `cyl` variable as a single variable, despite the fact that it is coded using two dummy variables. So removing `cyl` would actually remove two parameters from the resulting model.
 
 You should also notice that `R` respects hierarchy when attempting to remove variables. That is, for example, `R` will not consider removing `hp` if `hp:disp` or `I(hp ^ 2)` are currently in the model.
 
@@ -638,25 +638,25 @@ Notice this is a somewhat ""large"" model, which uses `r length(coef(autompg_mod_b
 
 ### Explanation
 
-Suppose we would like to use this model for explanation. Perhaps we are a car manufacturer trying to engineer a fuel efficient vehicle. If this is the case, we are interested in both what predictor variables are useful for explaining the car's fuel efficiency, as well as how those variables effect fuel efficiency. By understanding this relationship, we can use this knowledge to our advantage when designing a car.
+Suppose we would like to use this model for explanation. Perhaps we are a car manufacturer trying to engineer a fuel efficient vehicle. If this is the case, we are interested in both what predictor variables are useful for explaining the car's fuel efficiency, as well as how those variables affect fuel efficiency. By understanding this relationship, we can use this knowledge to our advantage when designing a car.
 
-To explain a relationship, we are interested in keeping models as small as possible, since smaller models are easy to interpret. The fewer predictors the less considerations we need to make in our design process. Also the fewer interactions and polynomial terms, the easier it is to interpret any one parameter, since the parameter interpretations are conditional on which parameters are in the model.
+To explain a relationship, we are interested in keeping models as small as possible, since smaller models are easy to interpret. The fewer predictors the fewer considerations we need to make in our design process. Also the fewer interactions and polynomial terms, the easier it is to interpret any one parameter, since the parameter interpretations are conditional on which parameters are in the model.
 
 Note that *linear* models are rather interpretable to begin with. Later in your data analysis careers, you will see more complicated models that may fit data better, but are much harder, if not impossible to interpret. These models aren't very useful for explaining a relationship.
 
-To find small and interpretable models, we would use selection criterion that *explicitly* penalize larger models, such as AIC and BIC. In this case we still obtained a somewhat large model, but much smaller than the model we used to start the selection process.
+To find small and interpretable models, we would use selection criteria that *explicitly* penalize larger models, such as AIC and BIC. In this case we still obtained a somewhat large model, but much smaller than the model we used to start the selection process.
 
 #### Correlation and Causation
 
 A word of caution when using a model to *explain* a relationship. There are two terms often used to describe a relationship between two variables: *causation* and *correlation*. [Correlation](https://xkcd.com/552/){target=""_blank""} is often also referred to as association.
 
-Just because two variable are correlated does not necessarily mean that one causes the other. For example, considering modeling `mpg` as only a function of `hp`.
+Just because two variables are correlated does not necessarily mean that one causes the other. For example, considering modeling `mpg` as only a function of `hp`.
 
 ```{r}
 plot(mpg ~ hp, data = autompg, col = ""dodgerblue"", pch = 20, cex = 1.5)
 ```
 
-Does an increase in horsepower cause a drop in fuel efficiency? Or, perhaps the causality is reversed and an increase in fuel efficiency cause a decrease in horsepower. Or, perhaps there is a third variable that explains both!
+Does an increase in horsepower cause a drop in fuel efficiency? Or, perhaps the causality is reversed and an increase in fuel efficiency causes a decrease in horsepower. Or, perhaps there is a third variable that explains both!
 
 The issue here is that we have **observational** data. With observational data, we can only detect associations. To speak with confidence about causality, we would need to run **experiments**.
 
@@ -666,7 +666,7 @@ This is a concept that you should encounter often in your statistics education.
 
 Suppose now instead of the manufacturer who would like to build a car, we are a consumer who wishes to purchase a new car. However this particular car is so new, it has not been rigorously tested, so we are unsure of what fuel efficiency to expect. (And, as skeptics, we don't trust what the manufacturer is telling us.)
 
-In this case, we would like to use the model to help *predict* the fuel efficiency of this car based on its attributes, which are the predictors of the model. The smaller the errors the model makes, the more confident we are in its prediction. Thus, to find models for prediction, we would use selection criterion that *implicitly* penalize larger models, such as LOOCV $\text{RMSE}$. So long as the model does not over-fit, we do not actually care how large the model becomes. Explaining the relationship between the variables is not our goal here, we simply want to know what kind of fuel efficiency we should expect!
+In this case, we would like to use the model to help *predict* the fuel efficiency of this car based on its attributes, which are the predictors of the model. The smaller the errors the model makes, the more confident we are in its prediction. Thus, to find models for prediction, we would use selection criteria that *implicitly* penalize larger models, such as LOOCV $\text{RMSE}$. So long as the model does not over-fit, we do not actually care how large the model becomes. Explaining the relationship between the variables is not our goal here, we simply want to know what kind of fuel efficiency we should expect!
 
 If we **only** care about prediction, we don't need to worry about correlation vs causation, and we don't need to worry about model assumptions. 
 "
daviddalpiaz,appliedstats,a860746f1d7ac6f37c34f9fd3b47f547295c125d,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-12T04:08:15Z,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-13T06:04:00Z,fix typo chapter15,collinearity.Rmd,True,False,True,False,3,3,6,"---FILE: collinearity.Rmd---
@@ -61,7 +61,7 @@ fit2 = lm(y ~ x1 + x3, data = exact_collin_data)
 fit3 = lm(y ~ x2 + x3, data = exact_collin_data)
 ```
 
-We see that the fitted values for each of the three models are exactly the same. This is a result of $x_3$ containing all of the information from $x_1$ and $x_2$. As long as one of $x_1$ or $x_2$ are included in the model, $x_3$ can be used to recover the information from the variable not included.
+We see that the fitted values for each of the three models are exactly the same. This is a result of $x_3$ containing all of the information from $x_1$ and $x_2$. As long as one of $x_1$ or $x_2$ is included in the model, $x_3$ can be used to recover the information from the variable not included.
 
 ```{r}
 all.equal(fitted(fit1), fitted(fit2))
@@ -92,7 +92,7 @@ round(cor(seatpos), 2)
 
 After loading the `faraway` package, we do some quick checks of correlation between the predictors. Visually, we can do this with the `pairs()` function, which plots all possible scatterplots between pairs of variables in the dataset.
 
-We can also do this numerically with the `cor()` function, which when applied to a dataset, returns all pairwise correlations. Notice this is a symmetric matrix. Recall that correlation measures strength and direction of the linear relationship between to variables. The correlation between `Ht` and `HtShoes` is extremely high. So high, that rounded to two decimal places, it appears to be 1!
+We can also do this numerically with the `cor()` function, which when applied to a dataset, returns all pairwise correlations. Notice this is a symmetric matrix. Recall that correlation measures strength and direction of the linear relationship between two variables. The correlation between `Ht` and `HtShoes` is extremely high. So high, that rounded to two decimal places, it appears to be 1!
 
 Unlike exact collinearity, here we can still fit a model with all of the predictors, but what effect does this have?
 
@@ -225,7 +225,7 @@ Here the variable added plot shows almost no linear relationship. This tells us
 
 Had there been a strong linear relationship here, thus a large partial correlation coefficient, it would likely have been useful to add the additional predictor to the model.
 
-This trade off is mostly true in general. As a model gets more predictors, errors will get smaller and its *prediction* will be better, but it will be harder to interpret. This is why, if we are interested in *explaining* the relationship between the predictors and the response, we often want a model that fits well, but with a small number of predictors with little correlation.
+This trade-off is mostly true in general. As a model gets more predictors, errors will get smaller and its *prediction* will be better, but it will be harder to interpret. This is why, if we are interested in *explaining* the relationship between the predictors and the response, we often want a model that fits well, but with a small number of predictors with little correlation.
 
 Next chapter we will learn about methods to find models that both fit well, but also have a small number of predictors. We will also discuss *overfitting*. Although, adding additional predictors will always make errors smaller, sometimes we will be ""fitting the noise"" and such a model will not generalize to additional observations well.
 "
daviddalpiaz,appliedstats,e7690835fc6d6cf01ca633d0eb27c1bc52da131c,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-12T03:41:19Z,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-13T06:03:55Z,fix typo chapter14,transformations.Rmd,True,False,True,False,4,4,8,"---FILE: transformations.Rmd---
@@ -104,7 +104,7 @@ In order to correct for this, we would like to find some function of $Y$, $g(Y)$
   \text{Var}[g(Y) \mid X = x] = c
 \]
 
-where $c$ is a constant that does not depend on the mean, $\text{E}[Y \mid X = x]$. A transformation that accomplishes this is called a **variance stabilizaing transformation.**
+where $c$ is a constant that does not depend on the mean, $\text{E}[Y \mid X = x]$. A transformation that accomplishes this is called a **variance stabilizing transformation.**
 
 A common variance stabilizing transformation (VST) when we see increasing variance in a fitted versus residuals plot is $\log(Y)$. Also, if the values of a variable range over more than one order of magnitude and the variable is *strictly positive*, then replacing the variable by its logarithm is likely to be helpful.
 
@@ -264,7 +264,7 @@ plot(fitted(savings_model), resid(savings_model), col = ""dodgerblue"",
 abline(h = 0, lty = 2, col = ""darkorange"", lwd = 2)
 ```
 
-Looking at a fitted versus residuals plot verifies that there likely are not any issue with the assumptions of this model, which Breusch-Pagan and Shapiro-Wilk tests verify.
+Looking at a fitted versus residuals plot verifies that there likely are not any issues with the assumptions of this model, which Breusch-Pagan and Shapiro-Wilk tests verify.
 
 ```{r, message = FALSE, warning = FALSE}
 library(lmtest)
@@ -310,7 +310,7 @@ abline(h = 0, lty = 2, col = ""darkorange"", lwd = 2)
 
 The resulting fitted versus residuals plot looks much better!
 
-Lastly, we return to the `initech` data, and the `initech_fit` model we had used earlier. Recall, that this was the untransformed model, that we used a $\log$ transform to fix.
+Lastly, we return to the `initech` data, and the `initech_fit` model we had used earlier. Recall that this was the untransformed model, that we used a $\log$ transform to fix.
 
 ```{r}
 boxcox(initech_fit)
@@ -661,7 +661,7 @@ plot(fitted(fit6), resid(fit6), xlab = ""Fitted"", ylab = ""Residuals"",
   abline(h = 0, col = ""darkorange"", lwd = 2)
 ```
 
-Again the sixth order term is significant with the other terms in the model and here we see less pattern in the residuals plot. Let's now test for which of the previous two models we prefer. We will test
+Again the sixth order term is significant with the other terms in the model and here we see less pattern in the residuals plot. Let's now test which of the previous two models we prefer. We will test
 
 \[
 H_0: \beta_5 = \beta_6 = 0."
daviddalpiaz,appliedstats,2c7380d9bad2ee2a2cd91760fee37310051cdb0e,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-12T03:31:16Z,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-13T06:02:53Z,fix typo chapter13,diagnostics.Rmd,True,False,True,False,12,12,24,"---FILE: diagnostics.Rmd---
@@ -67,7 +67,7 @@ We then used this fact to define
 
 which we used to perform hypothesis testing.
 
-So far we have looked at various metrics such as RMSE, RSE and $R^2$ to determine how well our model fit our data. Each of these in some way considers the expression
+So far we have looked at various metrics such as RMSE, RSE, and $R^2$ to determine how well our model fits our data. Each of these in some way considers the expression
 
 \[
 \sum_{i = 1}^n (y_i - \hat{y}_i)^2.
@@ -232,7 +232,7 @@ This time on the fitted versus residuals plot, for any fitted value, the spread
 
 Constant variance is often called **homoscedasticity**. Conversely, non-constant variance is called **heteroscedasticity**. We've seen how we can use a fitted versus residuals plot to look for these attributes.
 
-While a fitted versus residuals plot can give us an idea about homoscedasticity, sometimes we would prefer a more formal test. There are many tests for constant variance, but here we will present one, the [**Breusch-Pagan Test**](https://en.wikipedia.org/wiki/Breusch%E2%80%93Pagan_test){target=""_blank""}. The exact details of the test will omitted here, but importantly the null and alternative can be considered to be,
+While a fitted versus residuals plot can give us an idea about homoscedasticity, sometimes we would prefer a more formal test. There are many tests for constant variance, but here we will present one, the [**Breusch-Pagan Test**](https://en.wikipedia.org/wiki/Breusch%E2%80%93Pagan_test){target=""_blank""}. The exact details of the test will be omitted here, but importantly the null and alternative can be considered to be,
 
 - $H_0$: Homoscedasticity. The errors have constant variance about the true model.
 - $H_1$: Heteroscedasticity.  The errors have non-constant variance about the true model.
@@ -296,7 +296,7 @@ hist(resid(fit_3),
      breaks = 20)
 ```
 
-Above are histograms for each of the three regression we have been considering. Notice that the first, for `fit_1` appears very normal. The third, for `fit_3`, appears to be very non-normal. However `fit_2` is not as clear. It does have a rough bell shape, however, it also has a very sharp peak. For this reason we will usually use more powerful tools such as **Q-Q plots** and the **Shapiro-Wilk test** for assessing the normality of errors.
+Above are histograms for each of the three regressions we have been considering. Notice that the first, for `fit_1` appears very normal. The third, for `fit_3`, appears to be very non-normal. However `fit_2` is not as clear. It does have a rough bell shape, however, it also has a very sharp peak. For this reason we will usually use more powerful tools such as **Q-Q plots** and the **Shapiro-Wilk test** for assessing the normality of errors.
 
 ### Q-Q Plots
 
@@ -375,7 +375,7 @@ qq_plot(rt(25, df = 4))
 qq_plot(rt(100, df = 4))
 ```
 
-Recall, that as the degrees of freedom for a $t$ distribution become larger, the distribution becomes more and more similar to a normal. Here, using 4 degrees of freedom, we have a distribution that is somewhat normal, it is symmetrical and roughly bell-shaped, however it has ""fat tails."" This presents itself clearly in the third panel. While many of the points are close to the line, at the edges, there are large discrepancies. This indicates that the values are too small (negative) or too large (positive) compared to what we would expect for a normal distribution. So for the sample size of `100`, we would conclude that that normality assumption is violated. (If these were residuals of a model.) For sample sizes of `10` and `25` we may be suspicious, but not entirely confident. Reading Q-Q plots, is a bit of an art, not completely a science.
+Recall that as the degrees of freedom for a $t$ distribution become larger, the distribution becomes more and more similar to a normal. Here, using 4 degrees of freedom, we have a distribution that is somewhat normal, it is symmetrical and roughly bell-shaped, however it has ""fat tails."" This presents itself clearly in the third panel. While many of the points are close to the line, at the edges, there are large discrepancies. This indicates that the values are too small (negative) or too large (positive) compared to what we would expect for a normal distribution. So for the sample size of `100`, we would conclude that the normality assumption is violated. (If these were residuals of a model.) For sample sizes of `10` and `25` we may be suspicious, but not entirely confident. Reading Q-Q plots, is a bit of an art, not completely a science.
 
 Next, we simulate data from an exponential distribution.
 
@@ -389,7 +389,7 @@ qq_plot(rexp(100))
 
 This is a distribution that is not very similar to a normal, so in all three cases, we see points that are far from the lines, so we would think that the normality assumption is violated.
 
-For a better understanding of which Q-Q plots are ""good,"" repeat the simulations above a number of times (without setting the seed) and pay attention to the differences between those that are simulated from normal, and those that are not. Also consider different samples sizes and distribution parameters.
+For a better understanding of which Q-Q plots are ""good,"" repeat the simulations above a number of times (without setting the seed) and pay attention to the differences between those that are simulated from normal, and those that are not. Also consider different sample sizes and distribution parameters.
 
 Returning to our three regressions, recall,
 
@@ -436,7 +436,7 @@ For details, see: [Wikipedia: Shapiro–Wilk test.](https://en.wikipedia.org/wik
 
 In the above examples, we see we fail to reject for the data sampled from normal, and reject on the non-normal data, for any reasonable $\alpha$.
 
-Returning again to `fit_1`, `fit_2` and `fit_3`, we see the result of running `shapiro.test()` on the residuals of each, returns a result for each that matches for decisions based on the Q-Q plots.
+Returning again to `fit_1`, `fit_2`, and `fit_3`, we see the result of running `shapiro.test()` on the residuals of each, returns a result for each that matches decisions based on the Q-Q plots.
 
 ```{r}
 shapiro.test(resid(fit_1))
@@ -558,7 +558,7 @@ H = X \left(X^\top X\right)^{-1} X^\top
 
 which we will refer to as the *hat matrix*. The hat matrix is used to project onto the subspace spanned by the columns of $X$. It is also simply known as a projection matrix.
 
-The hat matrix, is a matrix that takes the original $y$ values, and adds a hat!
+The hat matrix is a matrix that takes the original $y$ values, and adds a hat!
 
 \[
 \hat{y} = H y
@@ -574,7 +574,7 @@ where $h_i$ is the leverage for the $i$th observation.
 
 Large values of $h_i$ indicate extreme values in $X$, which may influence regression. Note that leverages only depend on $X$.
 
-Here, $p$ the number of $\beta$s  is also the trace (and rank) of the hat matrix.
+Here, $p$, the number of $\beta$s, is also the trace (and rank) of the hat matrix.
 
 \[
 \sum_{i = 1}^n h_i = p
@@ -704,7 +704,7 @@ We see that in the second and third plots, the added point is a point of high le
 
 ### Outliers
 
-Outliers are points which do not fit the model well. They may or may not have a large affect on the model. To identify outliers, we will look for observations with large residuals.
+Outliers are points which do not fit the model well. They may or may not have a large effect on the model. To identify outliers, we will look for observations with large residuals.
 
 Note,
 
@@ -802,7 +802,7 @@ cooks.distance(model_2)[11] > 4 / length(cooks.distance(model_2))
 cooks.distance(model_3)[11] > 4 / length(cooks.distance(model_3))
 ```
 
-And, as expected, the added point in the third plot, with high leverage and a large residual is considered influential!
+And, as expected, the added point in the third plot, with high leverage and a large residual, is considered influential!
 
 ## Data Analysis Examples
 
@@ -876,14 +876,14 @@ mpg_hp_add_fix = lm(mpg ~ hp + am,
 coef(mpg_hp_add_fix)
 ```
 
-It seems there isn't much of a change in the coefficients as a results of removing the supposed influential points. Notice we did not create a new dataset to accomplish this. We instead used the `subset` argument to `lm()`. Think about what the code `cd_mpg_hp_add <= 4 / length(cd_mpg_hp_add)` does here.
+It seems there isn't much of a change in the coefficients as a result of removing the supposed influential points. Notice we did not create a new dataset to accomplish this. We instead used the `subset` argument to `lm()`. Think about what the code `cd_mpg_hp_add <= 4 / length(cd_mpg_hp_add)` does here.
 
 ```{r, fig.height = 8, fig.width = 8}
 par(mfrow = c(2, 2))
 plot(mpg_hp_add)
 ```
 
-Notice that, calling `plot()` on a variable which stores an object created by `lm()` outputs four diagnostic plots by default. Use `?plot.lm` to learn more. The first two should already be familiar.
+Notice that calling `plot()` on a variable which stores an object created by `lm()` outputs four diagnostic plots by default. Use `?plot.lm` to learn more. The first two should already be familiar.
 
 ### Suspect Diagnostics
 "
daviddalpiaz,appliedstats,7e94649d52771ce61d1387fcbf7db99d9833056c,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-12T03:08:18Z,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-13T06:02:48Z,fix typo chapter12,anova.Rmd,True,False,True,False,11,11,22,"---FILE: anova.Rmd---
@@ -35,7 +35,7 @@ The biggest difference between an observational study and an experiment is *how*
 
 In an experiment, the predictors, which are controlled by the experimenter, are called **factors**. The possible values of these factors are called **levels**. Subjects are *randomly* assigned to a level of each of the factors.
 
-The design of experiments could be a course by itself. The Wikipedia article on [design of experiments](https://en.wikipedia.org/wiki/Design_of_experiments){target=""_blank""} gives a good overview. Originally, most of the methodology was developed for agricultural applications by [R. A. Fisher](https://en.wikipedia.org/wiki/Ronald_Fisher){target=""_blank""}, but are still in use today, now in a wide variety of application areas. Notably, these methods have seen a resurgence as a part of ""A/B Testing.""
+The design of experiments could be a course by itself. The Wikipedia article on [design of experiments](https://en.wikipedia.org/wiki/Design_of_experiments){target=""_blank""} gives a good overview. Originally, most of the methodology was developed for agricultural applications by [R. A. Fisher](https://en.wikipedia.org/wiki/Ronald_Fisher){target=""_blank""}, but is still in use today, now in a wide variety of application areas. Notably, these methods have seen a resurgence as a part of ""A/B Testing.""
 
 <!-- TODO: In the future, discuss the Morrow Plots: http://cropsci.illinois.edu/research/morrow -->
 
@@ -92,7 +92,7 @@ melatonin = data.frame(
 )
 ```
 
-As an example, suppose we are interested in the effect of [melatotin](https://en.wikipedia.org/wiki/Melatonin){target=""_blank""} on sleep duration. A researcher obtains a random sample of 20 adult males. Of these subjects, 10 are randomly chosen for the control group, which will receive a placebo. The remaining 10 will be given 5mg of melatonin before bed. The sleep duration in hours of each subject is then measured. The researcher chooses a significance level of $\alpha = 0.10$. Was sleep duration affected by the melatonin?
+As an example, suppose we are interested in the effect of [melatonin](https://en.wikipedia.org/wiki/Melatonin){target=""_blank""} on sleep duration. A researcher obtains a random sample of 20 adult males. Of these subjects, 10 are randomly chosen for the control group, which will receive a placebo. The remaining 10 will be given 5mg of melatonin before bed. The sleep duration in hours of each subject is then measured. The researcher chooses a significance level of $\alpha = 0.10$. Was sleep duration affected by the melatonin?
 
 ```{r}
 melatonin
@@ -171,15 +171,15 @@ where the mean of each group is given by
 
 Here $\alpha_i$ measures the effect of group $i$. It is the difference between the overall mean and the mean of group $i$.
 
-Essentially, the assumptions here are the same as the two sample case, however now, we simply have more groups.
+Essentially, the assumptions here are the same as the two sample cases, however now, we simply have more groups.
 
 Much like the two-sample case, we would again like to test if the means of the groups are equal.
 
 \[
 H_0: \mu_1 = \mu_2 = \ldots \mu_g \quad \text{vs} \quad H_1: \text{ Not all } \mu_i \text{ are equal.}
 \]
 
-Notice that the alternative simply indicates the some of the means are not equal, not specifically which are not equal. More on that later.
+Notice that the alternative simply indicates that some of the means are not equal, not specifically which are not equal. More on that later.
 
 Alternatively, we could write
 
@@ -306,7 +306,7 @@ The left panel shows the three normal distributions we are sampling from. The ti
 
 Here the sample means vary a lot around the overall sample mean, which is the solid grey line on the right panel. Within the groups there is variability, but it is still obvious that the sample means are very different.
 
-As a result, we we obtain a *large* test statistic, thus *small* p-value. 
+As a result, we obtain a *large* test statistic, thus *small* p-value. 
 
 - $F = `r p1$f`$
 - $\text{p-value} = `r p1$p`$
@@ -321,7 +321,7 @@ p2 = plot_anova(n = 20, mu_a =  0, mu_b = 0, mu_c = 0, sigma = 1)
 
 Here the sample means vary only a tiny bit around the overall sample mean. Within the groups there is variability, this time much larger than the variability of the sample means.
 
-As a result, we we obtain a *small* test statistic, thus *large* p-value. 
+As a result, we obtain a *small* test statistic, thus *large* p-value. 
 
 - $F = `r p2$f`$
 - $\text{p-value} = `r p2$p`$
@@ -477,8 +477,8 @@ A number of things can affect the power of a test:
 
 - **Effect size**. It is easier to detect larger effects.
 - **Noise level** $\sigma$. The less noise, the easier it is to detect signal (effect). We don't have much ability to control this, except maybe to measure more accurately.
-- **Significance level** $\alpha$. Lower significance level makes rejecting more difficult. (But also allows for less false positives.)
-- **Sample size**. Large samples means easier to detect effects.
+- **Significance level** $\alpha$. Lower significance level makes rejecting more difficult. (But also allows for fewer false positives.)
+- **Sample size**. Large samples mean easier to detect effects.
 - **Balanced design**. An equal number of observations per group leads to higher power.
 
 The following simulations look at the effect of significance level, effect size, and noise level on the power of an ANOVA $F$-test. Homework will look into sample size and balance.
@@ -519,7 +519,7 @@ Also note that we are using the argument `p.adj = ""none""`. What is this? An adju
 
 The adjustment is an attempt to correct for the [multiple testing problem](https://en.wikipedia.org/wiki/Multiple_comparisons_problem){target=""_blank""}. (See also: [Relevant XKCD](https://xkcd.com/882/){target=""_blank""}. ) Imagine that you knew ahead of time that you were going to perform 100 $t$-tests. Suppose you wish to do this with a false positive rate of $\alpha = 0.05$. If we use this significance level for each test, for 100 tests, we then expect 5 false positives. That means, with 100 tests, we're almost guaranteed to have at least one error.
 
-What we'd really like, is for the [family-wise error rate](https://en.wikipedia.org/wiki/Family-wise_error_rate){target=""_blank""} to be 0.05. If we consider the 100 tests to be a single ""experiment"" the FWER is the rate of one or more false positives for in the full experiment (100 tests). Consider it an error rate for an entire procedure, instead of a single test.
+What we'd really like is for the [family-wise error rate](https://en.wikipedia.org/wiki/Family-wise_error_rate){target=""_blank""} to be 0.05. If we consider the 100 tests to be a single ""experiment"" the FWER is the rate of one or more false positives for in the full experiment (100 tests). Consider it an error rate for an entire procedure, instead of a single test.
 
 With this in mind, one of the simplest adjustments we can make, is to increase the p-values for each test, depending on the number of tests. In particular the Bonferroni correction simply multiplies by the number of tests.
 
@@ -531,7 +531,7 @@ With this in mind, one of the simplest adjustments we can make, is to increase t
 with(coagulation, pairwise.t.test(coag, diet, p.adj = ""bonferroni""))
 ```
 
-We see that these p-values are much higher than the unadjusted p-values, thus, we are less likely to reject each tests. As a result, the FWER is 0.05, instead of an error rate of 0.05 for each test.
+We see that these p-values are much higher than the unadjusted p-values, thus, we are less likely to reject each test. As a result, the FWER is 0.05, instead of an error rate of 0.05 for each test.
 
 We can simulate the 100 test scenario to illustrate this point.
 
@@ -690,7 +690,7 @@ levels(rats$poison)
 levels(rats$treat)
 ```
 
-Here, 48 rats were randomly assigned both one of three poisons and one of four possible treatments. The experimenters then measures their survival time in tens of hours. A total of 12 groups, each with 4 replicates.
+Here, 48 rats were randomly assigned both one of three poisons and one of four possible treatments. The experimenters then measure their survival time in tens of hours. A total of 12 groups, each with 4 replicates.
 
 Before running any tests, we should first look at the data. We will create **interaction plots**, which will help us visualize the effect of one factor, as we move through the levels of another factor.
 "
daviddalpiaz,appliedstats,23e75088832eb165bd96ab34d7546db2b61dd578,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-12T02:44:29Z,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-13T05:59:55Z,fix typo chapter11,cat-int.Rmd,True,False,True,False,11,11,22,"---FILE: cat-int.Rmd---
@@ -19,7 +19,7 @@ So far in each of our analyses, we have only used numeric variables as predictor
 
 ## Dummy Variables
 
-For this chapter, we will briefly use the built in dataset `mtcars` before returning to our `autompg` dataset that we created in the last chapter. The `mtcars` dataset is somewhat smaller, so we'll quickly take a look at the entire dataset.
+For this chapter, we will briefly use the built-in dataset `mtcars` before returning to our `autompg` dataset that we created in the last chapter. The `mtcars` dataset is somewhat smaller, so we'll quickly take a look at the entire dataset.
 
 ```{r}
 mtcars
@@ -84,7 +84,7 @@ x_2 =
   \end{cases}.
 \]
 
-In this case, we call $x_2$ a **dummy variable**. A dummy variable is somewhat unfortunately named, as it is in no way ""dumb"". In fact, it is actually somewhat clever. A dummy variable is a numerical variable that is used in a regression analysis to ""code"" for a binary categorical variable. Let's see how this works.
+In this case, we call $x_2$ a **dummy variable**. A dummy variable is somewhat unfortunately named, as it is in no way ""dumb."" In fact, it is actually somewhat clever. A dummy variable is a numerical variable that is used in a regression analysis to ""code"" for a binary categorical variable. Let's see how this works.
 
 First, note that `am` is already a dummy variable, since it uses the values `0` and `1` to represent automatic and manual transmissions. Often, a variable like `am` would store the character values `auto` and `man` and we would either have to convert these to `0` and `1`, or, as we will see later, `R` will take care of creating dummy variables for us.
 
@@ -171,7 +171,7 @@ Recapping some interpretations:
 - $\hat{\beta}_0 + \hat{\beta}_2 = `r coef(mpg_hp_add)[1] + coef(mpg_hp_add)[3]`$ is the estimated average `mpg` for a car with a manual transmission and **0** `hp`.
 
 - $\hat{\beta}_2 = `r coef(mpg_hp_add)[3]`$ is the estimated **difference** in average `mpg` for cars with manual transmissions as compared to those with automatic transmission, for **any** `hp`.
-- $\hat{\beta}_1 = `r coef(mpg_hp_add)[2]`$ is the estimated change in average `mpg` for an increase in one `hp`, for **either** transmission types.
+- $\hat{\beta}_1 = `r coef(mpg_hp_add)[2]`$ is the estimated change in average `mpg` for an increase in one `hp`, for **either** transmission type.
 
 We should take special notice of those last two. In the model,
 
@@ -333,7 +333,7 @@ H_0: \beta_3 = 0.
 
 In this case, testing for $\beta_3 = 0$ is testing for two lines with parallel slopes versus two lines with possibly different slopes. The `disp:domestic` line in the `summary()` output uses a $t$-test to perform the test.
 
-We could also use an ANOVA $F$-test. The additive model, without interaction is our null model, and the interaction model is the alternative.
+We could also use an ANOVA $F$-test. The additive model without interaction is our null model, and the interaction model is the alternative.
 
 ```{r}
 anova(mpg_disp_add, mpg_disp_int)
@@ -493,7 +493,7 @@ where
 
 - $Y$ is `mpg`, the fuel efficiency in miles per gallon,
 - $x_1$ is `disp`, the displacement in cubic inches,
-- $x_2$ is `domestic` a dummy variable where `1` indicates a domestic car.
+- $x_2$ is `domestic`, a dummy variable where `1` indicates a domestic car.
 
 ```{r}
 (mod_dummy = lm(mpg ~ disp * domestic, data = autompg))
@@ -513,9 +513,9 @@ Now let's try to do the same, but using our new factor variable.
 (mod_factor = lm(mpg ~ disp * origin, data = autompg))
 ```
 
-It seems that it doesn't produce the same results. Right away we notice that the intercept is different, as is the the coefficient in front of `disp`. We also notice that the remaining two coefficients are of the same magnitude as their respective counterparts using the domestic variable, but with a different sign. Why is this happening?
+It seems that it doesn't produce the same results. Right away we notice that the intercept is different, as is the coefficient in front of `disp`. We also notice that the remaining two coefficients are of the same magnitude as their respective counterparts using the domestic variable, but with a different sign. Why is this happening?
 
-It turns out, that by using a factor variable, `R` is automatically creating a dummy variable for us. However, it is not the dummy variable that we had originally used ourselves.
+It turns out that by using a factor variable, `R` is automatically creating a dummy variable for us. However, it is not the dummy variable that we had originally used ourselves.
 
 `R` is fitting the model
 
@@ -552,7 +552,7 @@ levels(autompg$cyl)
 
 Here the `cyl` variable has three possible levels: `4`, `6`, and `8`. You may wonder, why not simply use `cyl` as a numerical variable? You certainly could. 
 
-However, that would force the difference in average `mpg` between `4` and `6` cylinders to be the same as the difference in average mpg between `6` and `8` cylinders. That usually make senses for a continuous variable, but not for a discrete variable with so few possible values. In the case of this variable, there is no such thing as a 7-cylinder engine or a 6.23-cylinder engine in personal vehicles. For these reasons, we will simply consider `cyl` to be categorical. This is a decision that will commonly need to be made with ordinal variables. Often, with a large number of categories, the decision to treat them as numerical variables is appropriate because, otherwise, a large number of dummy variables are then needed to represent these variables.
+However, that would force the difference in average `mpg` between `4` and `6` cylinders to be the same as the difference in average mpg between `6` and `8` cylinders. That usually makes sense for a continuous variable, but not for a discrete variable with so few possible values. In the case of this variable, there is no such thing as a 7-cylinder engine or a 6.23-cylinder engine in personal vehicles. For these reasons, we will simply consider `cyl` to be categorical. This is a decision that will commonly need to be made with ordinal variables. Often, with a large number of categories, the decision to treat them as numerical variables is appropriate because, otherwise, a large number of dummy variables are then needed to represent these variables.
 
 Let's define three dummy variables related to the `cyl` factor variable.
 
@@ -596,7 +596,7 @@ where
 
 - $Y$ is `mpg`, the fuel efficiency in miles per gallon,
 - $x$ is `disp`, the displacement in cubic inches,
-- $v_2$ and $v_3$ are the dummy variables define above.
+- $v_2$ and $v_3$ are the dummy variables defined above.
 
 Why doesn't `R` use $v_1$? Essentially because it doesn't need to. To create three lines, it only needs two dummy variables since it is using a reference level, which in this case is a 4 cylinder car. The three ""sub models"" are then:
 
@@ -764,7 +764,7 @@ What is happening here? Notice that `R` is essentially ignoring `v3`, but why? W
 \boldsymbol{1} = v_1 + v_2 + v_3
 \]
 
-which means that $\boldsymbol{1}$, $v_1$, $v_2$, and $v_3$ are linearly dependent. This would make the $X^\top X$ matrix singular, but we need to be able to invert it to solve the normal equations and obtain $\hat{\beta}.$ With the intercept, `v1`, and `v2`, `R` can make the necessary ""three intercepts"". So, in this case `v3` is the reference level.
+which means that $\boldsymbol{1}$, $v_1$, $v_2$, and $v_3$ are linearly dependent. This would make the $X^\top X$ matrix singular, but we need to be able to invert it to solve the normal equations and obtain $\hat{\beta}.$ With the intercept, `v1`, and `v2`, `R` can make the necessary ""three intercepts."" So, in this case `v3` is the reference level.
 
 If we remove the intercept, then we can directly obtain all ""three intercepts"" without a reference level.
 
@@ -919,7 +919,7 @@ mean(resid(big_model) ^ 2)
 mean(resid(two_way_int_mod) ^ 2)
 ```
 
-However, it is not much smaller. We could even say that, the difference is insignificant. This is an idea we will return to later in greater detail.
+However, it is not much smaller. We could even say that the difference is insignificant. This is an idea we will return to later in greater detail.
 
 Now that we have chosen the model without the three-way interaction, can we go further? Do we need the two-way interactions? Let's test
 "
daviddalpiaz,appliedstats,428ca2f0ffee11fed013b4cd0c58f9e57294c320,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-12T02:23:39Z,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-12T02:23:39Z,fix typo chapter10,model-building.Rmd,True,False,True,False,9,9,18,"---FILE: model-building.Rmd---
@@ -113,7 +113,7 @@ A **family** of models is a broader grouping of many possible *forms* of a model
 
 For example, there are several families of *non-parametric* regression. Smoothing is a broad family of models. As are regression trees. 
 
-In linear regression, we specified models with parameters, $\beta_j$ and fit the model by finding the best values of these parameters. This is a *parametric* approach. A non-parametric approach skips the step of specifying a model with parameters, and are often described as more of an algorithm. Non-parametric models are often used in machine learning.
+In linear regression, we specified models with parameters, $\beta_j$ and fit the model by finding the best values of these parameters. This is a *parametric* approach. A non-parametric approach skips the step of specifying a model with parameters, and is often described as more of an algorithm. Non-parametric models are often used in machine learning.
 
 ```{r, echo=FALSE, fig.height=6, fig.width=12}
 set.seed(42)
@@ -193,17 +193,17 @@ for the assumed **family** and **form**. Fitting a model only gives us the best
 
 ## Explanation versus Prediction
 
-What is the purpose of fitting a model to data? Usually it is to accomplish one of two goals. We can use a model to **explain** the relationship between the response and the predictors. Models can also be used to **predict** the response based on the predictors. Often, a good model will do both, but we'll discuss both goals separately since the process of finding models for explaining and predicting have some differences. 
+What is the purpose of fitting a model to data? Usually it is to accomplish one of two goals. We can use a model to **explain** the relationship between the response and the predictors. Models can also be used to **predict** the response based on the predictors. Often, a good model will do both, but we'll discuss both goals separately since the processes of finding models for explaining and predicting have some differences. 
 
 For our purposes, since we are only considering linear models, searching for a good model is essentially searching for a good **form** of a model.
 
 ### Explanation
 
 If the goal of a model is to explain the relationship between the response and the predictors, we are looking for a model that is **small** and **interpretable**, but still fits the data well. When discussing linear models, the **size** of a model is essentially the number of $\beta$ parameters used.
 
-Suppose we would like to find a model that explains fuel efficiency (`mpg`) based on a car's attributes (`wt`, `year`, `cyl`, `disp`, `hp`, `acc`). Perhaps we are a car manufacturer trying to engineer a fuel efficient vehicle. If this is the case, we are interested in both which predictor variables are useful for explaining the car's fuel efficiency, as well as how those variables effect fuel efficiency. By understanding this relationship, we can use this knowledge to our advantage when designing a car.
+Suppose we would like to find a model that explains fuel efficiency (`mpg`) based on a car's attributes (`wt`, `year`, `cyl`, `disp`, `hp`, `acc`). Perhaps we are a car manufacturer trying to engineer a fuel-efficient vehicle. If this is the case, we are interested in both which predictor variables are useful for explaining the car's fuel efficiency, as well as how those variables affect fuel efficiency. By understanding this relationship, we can use this knowledge to our advantage when designing a car.
 
-To explain a relationship, we are interested in keeping models as small as possible, since smaller models are easy to interpret. The fewer predictors the less considerations we need to make in our design process. 
+To explain a relationship, we are interested in keeping models as small as possible, since smaller models are easy to interpret. The fewer predictors the fewer considerations we need to make in our design process. 
 
 Note that *linear* models of any size are rather interpretable to begin with. Later in your data analysis careers, you will see more complicated models that may fit data better, but are much harder, if not impossible to interpret. These models aren't nearly as useful for explaining a relationship. This is another reason to always attempt a linear model. If it fits as well as more complicated methods, it will be the easiest to understand.
 
@@ -219,7 +219,7 @@ Our additional assumption is about the error term.
 \epsilon \sim N(0, \sigma^2)
 \]
 
-This assumption, that the errors are normally distributed with some common variance is the key to all of the inference we have done so far. We will discuss this in great detail later.
+This assumption that the errors are normally distributed with some common variance is the key to all of the inference we have done so far. We will discuss this in great detail later.
 
 So with our inference tools (ANOVA and $t$-test) we have two potential strategies. Start with a very small model (no predictors) and attempt to add predictors. Or, start with a big model (all predictors) and attempt to remove predictors.
 
@@ -247,7 +247,7 @@ Just because two variables are correlated does not necessarily mean that one cau
 plot(mpg ~ hp, data = autompg, col = ""dodgerblue"", pch = 20, cex = 1.5)
 ```
 
-Does an increase in horsepower cause a drop in fuel efficiency? Or, perhaps the causality is reversed and an increase in fuel efficiency cause a decrease in horsepower. Or, perhaps there is a third variable that explains both!
+Does an increase in horsepower cause a drop in fuel efficiency? Or, perhaps the causality is reversed and an increase in fuel efficiency causes a decrease in horsepower. Or, perhaps there is a third variable that explains both!
 
 The issue here is that we have **observational** data. With observational data, we can only detect *associations*. To speak with confidence about *causality*, we would need to run **experiments**. Often, this decision is made for us, before we ever see data, so we can only modify our interpretation.
 
@@ -276,11 +276,11 @@ Suppose instead of the manufacturer who would like to build a car, we are a cons
 
 #### Test-Train Split
 
-The trouble with using RMSE to identify how well a model fits data, is that RMSE is **always** (equal or) lower for a larger model. This would suggest that we should always use the largest model possible when looking for a model that predicts well. The problem with this is the potential to **overfit** to the data. So, we want a model that fits well, but does not overfit. To understand overfitting, we need to think about applying a model to seen and unseen data.
+The trouble with using RMSE to identify how well a model fits data is that RMSE is **always** (equal or) lower for a larger model. This would suggest that we should always use the largest model possible when looking for a model that predicts well. The problem with this is the potential to **overfit** to the data. So, we want a model that fits well, but does not overfit. To understand overfitting, we need to think about applying a model to seen and unseen data.
 
 Suppose we fit a model using all data available and we evaluate RMSE on this fitted model and all of the seen data. We will call this data the **training** data, and this RMSE the **train** RMSE.
 
-Now, suppose we magically encounter some additional data. To truly asses how well the model predicts, we should evaluate how well our models predicts the response of this data. We will call this data the  **test** data and this RMSE the **test** RMSE.
+Now, suppose we magically encounter some additional data. To truly assess how well the model predicts, we should evaluate how well our model predicts the response of this data. We will call this data the  **test** data and this RMSE the **test** RMSE.
 
 - Train RMSE: model fit on seen data, evaluated on **seen** data
 - Test RMSE: model fit on seen data, evaluated on **unseen** data
@@ -351,7 +351,7 @@ The left panel shows the data that was used to fit the two models. Clearly the ""
 | Simple  | `r round(rmse(sim_data$response, predict(sim_fit_1)), 2)` | `r round(rmse(sim_data_new$response, predict(sim_fit_1, sim_data_new)), 2)` |
 | Complex | `r round(rmse(sim_data$response, predict(sim_fit_2)), 2)` | `r round(rmse(sim_data_new$response, predict(sim_fit_2, sim_data_new)), 2)` |
 
-The more ""complex"", wiggly, model fits the training data much better as it has a much lower train RMSE. However, we see that the ""simple"" model fits the test data much better, with a much lower test RMSE. This means that the complex model has *overfit* the data, and we prefer the simple model. When choosing a model for prediction, we prefer a model that predicts unseen data.
+The more ""complex,"" wiggly, model fits the training data much better as it has a much lower train RMSE. However, we see that the ""simple"" model fits the test data much better, with a much lower test RMSE. This means that the complex model has *overfit* to the data, and we prefer the simple model. When choosing a model for prediction, we prefer a model that predicts unseen data.
 
 In practice, you can't simply generate more data to evaluate your models. Instead we split existing data into data used to fit the model (train) and data used to evaluate the model (test). Never fit a model with test data.
 "
daviddalpiaz,appliedstats,fc92663897f5839306cd912103742ae3c361d23a,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-12T01:58:15Z,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-12T01:58:15Z,fix typo chapter9,mlr.Rmd,True,False,True,False,4,4,8,"---FILE: mlr.Rmd---
@@ -133,13 +133,13 @@ coef(mpg_model)
 \hat{y} = `r coef(mpg_model)[1]` + `r coef(mpg_model)[2]` x_1 + `r coef(mpg_model)[3]` x_2
 \]
 
-Here we have once again fit our model using `lm()`, however we have introduced a new syntactical element. The formula `mpg ~ wt + year` now reads: ""model the response variable `mpg` as a linear function of `wt` and `year`"". That is, it will estimate an intercept, as well as slope coefficients for `wt` and `year`. We then extract these as we have done before using `coef()`.
+Here we have once again fit our model using `lm()`, however we have introduced a new syntactical element. The formula `mpg ~ wt + year` now reads: ""model the response variable `mpg` as a linear function of `wt` and `year`."" That is, it will estimate an intercept, as well as slope coefficients for `wt` and `year`. We then extract these as we have done before using `coef()`.
 
 In the multiple linear regression setting, some of the interpretations of the coefficients change slightly.
 
 Here, $\hat{\beta}_0 = `r coef(mpg_model)[1]`$ is our estimate for $\beta_0$, the mean miles per gallon for a car that weighs 0 pounds and was built in 1900. We see our estimate here is negative, which is a physical impossibility. However, this isn't unexpected, as we shouldn't expect our model to be accurate for cars from 1900 which weigh 0 pounds. (Because they never existed!) This isn't much of a change from SLR. That is, $\beta_0$ is still simply the mean when all of the predictors are 0.
 
-The interpretation of the coefficients in front of our predictors are slightly different than before. For example $\hat{\beta}_1 = `r coef(mpg_model)[2]`$ is our estimate for $\beta_1$, the average change in miles per gallon for an increase in weight ($x_{1}$) of one-pound **for a car of a certain model year**, that is, for a fixed value of $x_{2}$. Note that this coefficient is actually the same for any given value of $x_{2}$. Later, we will look at models that allow for a different change in mean response for different values of $x_{2}$. Also note that this estimate is negative, which we would expect since, in general, fuel efficiency decreases for larger vehicles. Recall that in the multiple linear regression setting, this interpretation is dependent on a fixed value for $x_{2}$, that is, ""for a car of a certain model year."" It is possible that the indirect relationship between fuel efficiency and weight does not hold when an additional factor, say year, is included, and thus we could have the sign of our coefficient flipped.
+The interpretation of the coefficients in front of our predictors is slightly different than before. For example $\hat{\beta}_1 = `r coef(mpg_model)[2]`$ is our estimate for $\beta_1$, the average change in miles per gallon for an increase in weight ($x_{1}$) of one-pound **for a car of a certain model year**, that is, for a fixed value of $x_{2}$. Note that this coefficient is actually the same for any given value of $x_{2}$. Later, we will look at models that allow for a different change in mean response for different values of $x_{2}$. Also note that this estimate is negative, which we would expect since, in general, fuel efficiency decreases for larger vehicles. Recall that in the multiple linear regression setting, this interpretation is dependent on a fixed value for $x_{2}$, that is, ""for a car of a certain model year."" It is possible that the indirect relationship between fuel efficiency and weight does not hold when an additional factor, say year, is included, and thus we could have the sign of our coefficient flipped.
 
 Lastly, $\hat{\beta}_2 = `r coef(mpg_model)[3]`$ is our estimate for $\beta_2$, the average change in miles per gallon for a one-year increase in model year ($x_{2}$) for a car of a certain weight, that is, for a fixed value of $x_{1}$. It is not surprising that the estimate is positive. We expect that as time passes and the years march on, technology would improve so that a car of a specific weight would get better mileage now as compared to their predecessors. And yet, the coefficient could have been negative because we are also including weight as variable, and not strictly as a fixed value. 
 
@@ -219,7 +219,7 @@ Just as before, we can estimate $\beta$ by minimizing,
 f(\beta_0, \beta_1, \beta_2, \cdots, \beta_{p-1}) = \sum_{i = 1}^{n}(y_i - (\beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_{p-1} x_{i(p-1)}))^2,
 \]
 
-which would require taking $p$ derivatives, which result in following **normal equations**.
+which would require taking $p$ derivatives, which result in the following **normal equations**.
 
 \[
 \begin{bmatrix}
@@ -701,7 +701,7 @@ That is,
 \text{SST} = \text{SSE} + \text{SSReg}.
 \]
 
-This means that, we can still calculate $R^2$ in the same manner as before, which `R` continues to do automatically.
+This means that we can still calculate $R^2$ in the same manner as before, which `R` continues to do automatically.
 
 ```{r}
 summary(mpg_model)$r.squared"
daviddalpiaz,appliedstats,b905d2a7de66b8643a867cc86dbb30bc70e36cca,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-12T01:02:51Z,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-12T01:37:14Z,fix typo chapter8,slr-inf.Rmd,True,False,True,False,6,6,12,"---FILE: slr-inf.Rmd---
@@ -71,7 +71,7 @@ S_{xy}= \sum_{i = 1}^{n}(x_i - \bar{x})(y_i - \bar{y}) = \sum_{i = 1}^{n}(x_i -
 
 This may be a surprising equivalence. (Maybe try to prove it.) However, it will be useful for illustrating concepts in this chapter.
 
-Note that, $\hat{\beta}_1$ is a **sample statistic** when calculated with observed data as written above, as is $\hat{\beta}_0$.   
+Note that $\hat{\beta}_1$ is a **sample statistic** when calculated with observed data as written above, as is $\hat{\beta}_0$.   
 
 However, in this chapter it will often be convenient to use both $\hat{\beta}_1$ and $\hat{\beta}_0$ as **random variables**, that is, we have not yet observed the values for each $Y_i$. When this is the case, we will use a slightly different notation, substituting in capital $Y_i$ for lower case $y_i$.
 
@@ -82,13 +82,13 @@ However, in this chapter it will often be convenient to use both $\hat{\beta}_1$
 \end{aligned}
 \]
 
-Last chapter we argued that these estimates of unknown model parameters $\beta_0$ and $\beta_1$ were good because we obtained them by minimizing errors. We will now discuss the Gauss–Markov theorem which takes this idea further, showing that these estimates are actually the ""best"" estimates, from a certain point of view.
+Last chapter we argued that these estimates of unknown model parameters $\beta_0$ and $\beta_1$ were good because we obtained them by minimizing errors. We will now discuss the Gauss–Markov theorem, which takes this idea further, showing that these estimates are actually the ""best"" estimates, from a certain point of view.
 
 ## Gauss–Markov Theorem
 
 The **Gauss–Markov theorem** tells us that when estimating the parameters of the simple linear regression model $\beta_0$ and $\beta_1$, the $\hat{\beta}_0$ and $\hat{\beta}_1$ which we derived are the **best linear unbiased estimates**, or *BLUE* for short. (The actual conditions for the Gauss–Markov theorem are more relaxed than the SLR model.)
 
-We will now discuss *linear*, *unbiased*, and *best* as is relates to these estimates.
+We will now discuss *linear*, *unbiased*, and *best* as they relate to these estimates.
 
 #### Linear {-}
 
@@ -150,7 +150,7 @@ So now, the natural question is, what are the variances of $\hat{\beta}_0$ and $
 \end{aligned}
 \]
 
-These quantify the variability of the estimates due to random chance during sampling. Are these ""the best""? Are these variances as small as we can possibility get? You'll just have to take our word for it that they are because showing that this is true is beyond the scope of this course.
+These quantify the variability of the estimates due to random chance during sampling. Are these ""the best""? Are these variances as small as we can possibly get? You'll just have to take our word for it that they are because showing that this is true is beyond the scope of this course.
 
 ## Sampling Distributions
 
@@ -489,11 +489,11 @@ where $t_{\alpha/2, n - 2}$ is the critical value such that $P(t_{n-2} > t_{\alp
 
 ## Hypothesis Tests
 
-> ""We may speak of this hypothesis as the '[null hypothesis](https://xkcd.com/892/){target=""_blank""}', and it should be noted that the null hypothesis is never proved or established, but is possibly disproved, in the course of experimentation.""
+> ""We may speak of this hypothesis as the '[null hypothesis](https://xkcd.com/892/){target=""_blank""},' and it should be noted that the null hypothesis is never proved or established, but is possibly disproved, in the course of experimentation.""
 >
 > --- **Ronald Aylmer Fisher**
 
-Recall that a test statistic ($\text{TS}$) for testing means often take the form:
+Recall that a test statistic ($\text{TS}$) for testing means often takes the form:
 
 \[
 \text{TS} = \frac{\text{EST} - \text{HYP}}{\text{SE}}"
daviddalpiaz,appliedstats,f714f43d56e7451532babb9ba39f190c52692de2,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-12T00:35:07Z,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-12T00:35:07Z,fix typo chapter7,slr.Rmd,True,False,True,False,12,12,24,"---FILE: slr.Rmd---
@@ -19,7 +19,7 @@ After reading this chapter you will be able to:
 
 ## Modeling
 
-Let's consider a simple example of how the speed of a car affects its stopping distance, that is, how far it travels before it comes to a stop. To examine this relationship, we will use the `cars` dataset which, is a default `R` dataset. Thus, we don't need to load a package first; it is immediately available.
+Let's consider a simple example of how the speed of a car affects its stopping distance, that is, how far it travels before it comes to a stop. To examine this relationship, we will use the `cars` dataset, which is a default `R` dataset. Thus, we don't need to load a package first; it is immediately available.
 
 To get a first look at the data you can use the `View()` function inside RStudio.
 
@@ -112,7 +112,7 @@ plot(dist ~ speed, data = cars,
 lines(x, predict(overfit_model, data.frame(speed = x)), lwd = 2, col = ""darkorange"")
 ```
 
-Lastly, we could try to model the data with a well chosen line rather than one of the two extremes previously attempted. The line on the plot below seems to summarize the relationship between stopping distance and speed quite well. As speed increases, the distance required to come to a stop increases. There is still some variation about this line, but it seems to capture the overall trend.
+Lastly, we could try to model the data with a well-chosen line rather than one of the two extremes previously attempted. The line on the plot below seems to summarize the relationship between stopping distance and speed quite well. As speed increases, the distance required to come to a stop increases. There is still some variation about this line, but it seems to capture the overall trend.
 
 ```{r goodfit_plot, echo = FALSE}
 stop_dist_model = lm(dist ~ speed, data = cars)
@@ -191,7 +191,7 @@ As a side note, we will often refer to simple linear regression as **SLR**. Some
 - **Linear** tells us that our model for $Y$ is a linear combination of the predictors $X$. (In this case just the one.) Right now, this always results in a model that is a line, but later we will see how this is not always the case.
 - **Regression** simply means that we are attempting to measure the relationship between a response variable and (one or more) predictor variables. In the case of SLR, both the response and the predictor are *numeric* variables. 
 
-So SLR models $Y$ as a linear function of $X$, but how do we actually define a good line? There are an infinite number of lines we could use, so we will attempt to find one with ""small errors."" That is a line with as many points as close to it as possible. The questions now becomes, how do we find such a line? There are many approaches we could take.
+So SLR models $Y$ as a linear function of $X$, but how do we actually define a good line? There are an infinite number of lines we could use, so we will attempt to find one with ""small errors."" That is a line with as many points as close to it as possible. The question now becomes, how do we find such a line? There are many approaches we could take.
 
 We could find the line that has the smallest maximum distance from any of the points to the line. That is,
 
@@ -233,7 +233,7 @@ $$
 \end{aligned}
 $$
 
-We then set each of the partial derivatives equal to zero and solving the resulting system of equations.
+We then set each of the partial derivatives equal to zero and solve the resulting system of equations.
 
 $$
 \begin{aligned}
@@ -280,7 +280,7 @@ $$
 
 Traditionally we would now calculate $\hat{\beta}_0$ and $\hat{\beta}_1$ by hand for the `cars` dataset. However because we are living in the 21st century and are intelligent (or lazy or efficient, depending on your perspective), we will utilize `R` to do the number crunching for us.
 
-To keep some notation consistent with above mathematics, we will store the response variable as `y` and the predictor variable as `x`.
+To keep some notation consistent with the above mathematics, we will store the response variable as `y` and the predictor variable as `x`.
 
 ```{r}
 x = cars$speed
@@ -490,15 +490,15 @@ $$
 \sum_{i=1}^{n}(y_i - \bar{y})^2 = \sum_{i=1}^{n}(y_i - \hat{y}_i)^2 + \sum_{i=1}^{n}(\hat{y}_i - \bar{y})^2.
 $$
 
-This should be somewhat alarming or amazing. How is this true? For now we will leave this questions unanswered. (Think about this, and maybe try to prove it.) We will now define three of the quantities seen in this equation. 
+This should be somewhat alarming or amazing. How is this true? For now we will leave this question unanswered. (Think about this, and maybe try to prove it.) We will now define three of the quantities seen in this equation. 
 
 #### Sum of Squares Total {-}
 
 $$
 \text{SST} = \sum_{i=1}^{n}(y_i - \bar{y})^2
 $$
 
-The quantity ""Sum of Squares Total,"" or $\text{SST}$, represents the **total variation** of the observed $y$ values. This should be a familiar looking expression. Note that,
+The quantity ""Sum of Squares Total,"" or $\text{SST}$, represents the **total variation** of the observed $y$ values. This should be a familiar-looking expression. Note that,
 
 $$
 s ^ 2 = \frac{1}{n - 1}\sum_{i=1}^{n}(y_i - \bar{y})^2 = \frac{1}{n - 1} \text{SST}.
@@ -543,7 +543,7 @@ We can use `R` to verify that this matches our previous calculation of $s_e^2$.
 s2_e == SSE / (n - 2)
 ```
 
-These three measures also do not have an important practical interpretation individually. But together, they're about to reveal a new statistic to help measure the strength of a SLR model.
+These three measures also do not have an important practical interpretation individually. But together, they're about to reveal a new statistic to help measure the strength of an SLR model.
 
 ###  Coefficient of Determination
 
@@ -668,7 +668,7 @@ We'll continue using the `cars` data, and essentially use the `lm()` function to
 stop_dist_model = lm(dist ~ speed, data = cars)
 ```
 
-This line of code fits our very first linear model. The syntax should look somewhat familiar. We use the `dist ~ speed` syntax to tell `R` we would like to model the response variable `dist` as a linear function of the predictor variable `speed`. In general, you should think of the syntax as `response ~ predictor`. The `data = cars` argument then tells `R` that that `dist` and `speed` variables are from the dataset `cars`. We then store this result in a variable `stop_dist_model`.
+This line of code fits our very first linear model. The syntax should look somewhat familiar. We use the `dist ~ speed` syntax to tell `R` we would like to model the response variable `dist` as a linear function of the predictor variable `speed`. In general, you should think of the syntax as `response ~ predictor`. The `data = cars` argument then tells `R` that the `dist` and `speed` variables are from the dataset `cars`. We then store this result in a variable `stop_dist_model`.
 
 The variable `stop_dist_model` now contains a wealth of information, and we will now see how to extract and use that information. The first thing we will do is simply output whatever is stored immediately in the variable `stop_dist_model`.
 
@@ -747,7 +747,7 @@ $$
 s_e = \text{RSE} = \sqrt{\frac{1}{n - 2}\sum_{i = 1}^n e_i^2}
 $$
 
-Often it is useful to talk about $s_e$ (or RSE) instead of $s_e^2$ because of their units. The units of $s_e$ in the `cars` example is feet, while the units of $s_e^2$ is feet-squared.
+Often it is useful to talk about $s_e$ (or RSE) instead of $s_e^2$ because of their units. The unit of $s_e$ in the `cars` example is feet, while the unit of $s_e^2$ is feet-squared.
 
 Another useful function, which we will use almost as often as `lm()` is the `predict()` function.
 
@@ -936,7 +936,7 @@ x_vals = seq(from = 0, to = 10, length.out = num_obs)
 # x_vals = runif(num_obs, 0, 10)
 ```
 
-We then generate the $y$ values according the specified functional relationship.
+We then generate the $y$ values according to the specified functional relationship.
 
 ```{r}
 y_vals = beta_0 + beta_1 * x_vals + epsilon
@@ -956,7 +956,7 @@ plot(y_vals ~ x_vals)
 abline(sim_fit)
 ```
 
-We should say here, that we're being sort of lazy, and not the good kinda of lazy that could be considered efficient. Any time you simulate data, you should consider doing two things: writing a function, and storing the data in a data frame.
+We should say here, that we're being sort of lazy, and not the good kind of lazy that could be considered efficient. Any time you simulate data, you should consider doing two things: writing a function, and storing the data in a data frame.
 
 The function below, `sim_slr()`, can be used for the same task as above, but is much more flexible. Notice that we provide `x` to the function, instead of generating `x` inside the function. In the SLR model, the $x_i$ are considered known values. That is, they are not random, so we do not assume a distribution for the $x_i$. Because of this, we will repeatedly use the same `x` values across all simulations.
 "
daviddalpiaz,appliedstats,81ac93f48a54f55296489b94b26e9514a0bfee32,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-10T06:24:37Z,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-10T06:27:14Z,fix typo chapter5,prob-and-stat.Rmd,True,False,True,False,3,3,6,"---FILE: prob-and-stat.Rmd---
@@ -73,7 +73,7 @@ Also note that, when using the `dname` functions with discrete distributions, th
 A prerequisite for STAT 420 is an understanding of the basics of hypothesis testing. Recall the basic structure of hypothesis tests:
 
 - An overall model and related assumptions are made. (The most common being observations following a normal distribution.)
-- The **null** ($H_{0}$) and **alternative** ($H_{1}$ or $H_{A}$) hypothesis are specified. Usually the null specifies a particular value of a parameter.
+- The **null** ($H_{0}$) and **alternative** ($H_{1}$ or $H_{A}$) hypotheses are specified. Usually the null specifies a particular value of a parameter.
 - With given data, the **value** of the *test statistic* is calculated.
 - Under the general assumptions, as well as assuming the null hypothesis is true, the **distribution** of the *test statistic* is known.
 - Given the distribution and value of the test statistic, as well as the form of the alternative hypothesis, we can calculate a **p-value** of the test.
@@ -105,7 +105,7 @@ where $t_{\alpha/2, n-1}$ is the critical value such that $P\left(t>t_{\alpha/2,
 
 ### One Sample t-Test: Example
 
-Suppose a grocery store sells ""16 ounce"" boxes of *Captain Crisp* cereal. A random sample of 9 boxes was taken and weighed. The weight in ounces are stored in the data frame `capt_crisp`.
+Suppose a grocery store sells ""16 ounce"" boxes of *Captain Crisp* cereal. A random sample of 9 boxes was taken and weighed. The weight in ounces is stored in the data frame `capt_crisp`.
 
 ```{r}
 capt_crisp = data.frame(weight = c(15.5, 16.2, 16.1, 15.8, 15.6, 16.0, 15.8, 15.9, 16.2))
@@ -387,7 +387,7 @@ Our strategy will be to repeatedly:
 
 - Generate a sample of 25 random observations from $N(\mu_1 = 6,\sigma^2 = 4)$. Call the mean of this sample $\bar{x}_{1s}$.
 - Generate a sample of 25 random observations from $N(\mu_1 = 5,\sigma^2 = 4)$. Call the mean of this sample $\bar{x}_{2s}$.
-- Calculate the differences of the means, $d_s = \bar{x}_{1s} - \bar{x}_{2s}$.
+- Calculate the differences in the means, $d_s = \bar{x}_{1s} - \bar{x}_{2s}$.
 
 We will repeat the process a large number of times. Then we will use the distribution of the simulated observations of $d_s$ as an estimate for the true distribution of $D$.
 "
daviddalpiaz,appliedstats,60684b8ee66e28aa94c1073cc60dbe80481c9839,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-10T06:11:57Z,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-10T06:11:57Z,fix typo chapter4,data-summary.Rmd,True,False,True,False,7,7,14,"---FILE: data-summary.Rmd---
@@ -2,7 +2,7 @@
 
 ## Summary Statistics
 
-`R` has built in functions for a large number of summary statistics. For numeric variables, we can summarize data with the center and spread. We'll again look at the `mpg` dataset from the `ggplot2` package.
+`R` has built-in functions for a large number of summary statistics. For numeric variables, we can summarize data with the center and spread. We'll again look at the `mpg` dataset from the `ggplot2` package.
 
 ```{r, message = FALSE, warning = FALSE}
 library(ggplot2)
@@ -37,7 +37,7 @@ table(mpg$drv) / nrow(mpg)
 
 ## Plotting
 
-Now that we have some data to work with, and we have learned about the data at the most basic level, our next tasks is to visualize the data. Often, a proper visualization can illuminate features of the data that can inform further analysis.
+Now that we have some data to work with, and we have learned about the data at the most basic level, our next task is to visualize the data. Often, a proper visualization can illuminate features of the data that can inform further analysis.
 
 We will look at four methods of visualizing data that we will use throughout the course:
 
@@ -77,11 +77,11 @@ barplot(table(mpg$drv))
 
 ```{r}
 barplot(table(mpg$drv),
-        xlab   = ""Drivetrain (f = FWD, r = RWD, 4 = 4WD)"",
-        ylab   = ""Frequency"",
-        main   = ""Drivetrains"",
-        col    = ""dodgerblue"",
-        border = ""darkorange"")
+     xlab   = ""Drivetrain (f = FWD, r = RWD, 4 = 4WD)"",
+     ylab   = ""Frequency"",
+     main   = ""Drivetrains"",
+     col    = ""dodgerblue"",
+     border = ""darkorange"")
 ```
 
 ### Boxplots"
daviddalpiaz,appliedstats,bff2f561ee43efd44d5b0b739bb9fde8a13046d8,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-10T06:01:41Z,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-10T06:01:41Z,fix typo chapter3,data-and-programming.Rmd,True,False,True,False,10,10,20,"---FILE: data-and-programming.Rmd---
@@ -32,13 +32,13 @@
 
 Many operations in `R` make heavy use of **vectors**. Vectors in `R` are indexed starting at `1`. That is what the `[1]` in the output is indicating, that the first element of the row being displayed is the first element of the vector. Larger vectors will start additional rows with `[*]` where `*` is the index of the first element of the row.
 
-Possibly the most common way to create a vector in `R` is using the `c()` function, which is short for ""combine."""" As the name suggests, it combines a list of elements separated by commas. 
+Possibly the most common way to create a vector in `R` is using the `c()` function, which is short for ""combine."" As the name suggests, it combines a list of elements separated by commas. 
 
 ```{r}
 c(1, 3, 5, 7, 8, 9)
 ```
 
-Here `R` simply outputs this vector. If we would like to store this vector in a **variable** we can do so with the **assignment** operator `=`. In this case the variable `x` now holds the vector we just created, and we can access the vector by typing `x`.
+Here `R` simply outputs this vector. If we would like to store this vector in a **variable**, we can do so with the **assignment** operator `=`. In this case the variable `x` now holds the vector we just created, and we can access the vector by typing `x`.
 
 ```{r}
 x = c(1, 3, 5, 7, 8, 9)
@@ -154,7 +154,7 @@ x[z]
 
 ### Vectorization
 
-One of the biggest strengths of `R` is its use of vectorized operations. (Frequently the lack of understanding of this concept leads of a belief that `R` is *slow*. `R` is not the fastest language, but it has a reputation for being slower than it really is.)
+One of the biggest strengths of `R` is its use of vectorized operations. (Frequently the lack of understanding of this concept leads to a belief that `R` is *slow*. `R` is not the fastest language, but it has a reputation for being slower than it really is.)
 
 ```{r}
 x = 1:10
@@ -422,7 +422,7 @@ c(is.vector(a_vec), is.vector(b_vec))
 c(is.matrix(a_vec), is.matrix(b_vec))
 ```
 
-When this is the case, the `%*%` operator is used to calculate the **dot product**, also know as the **inner product** of the two vectors.
+When this is the case, the `%*%` operator is used to calculate the **dot product**, also known as the **inner product** of the two vectors.
 
 The dot product of vectors $\boldsymbol{a} = \lbrack a_1, a_2, \cdots a_n \rbrack$ and $\boldsymbol{b} = \lbrack b_1, b_2, \cdots b_n \rbrack$ is defined to be
 
@@ -449,7 +449,7 @@ If we use the `%*%` operator on matrices, `%*%` again performs the expected matr
 as.matrix(a_vec) %*% b_vec
 ```
 
-At face value this is a $3 \times 1$ matrix, multiplied by a $3 \times 1$ matrix. However, when `b_vec` is automatically coerced to be a matrix, `R` decided to make it a ""row vector"", a $1 \times 3$ matrix, so that the multiplication has conformable dimensions.
+At face value this is a $3 \times 1$ matrix, multiplied by a $3 \times 1$ matrix. However, when `b_vec` is automatically coerced to be a matrix, `R` decided to make it a ""row vector,"" a $1 \times 3$ matrix, so that the multiplication has conformable dimensions.
 
 If we had coerced both, then `R` would produce an error.
 
@@ -566,13 +566,13 @@ ncol(example_data)
 dim(example_data)
 ```
 
-The `data.frame()` function above is one way to create a data frame. We can also import data from various file types in into `R`, as well as use data stored in packages.
+The `data.frame()` function above is one way to create a data frame. We can also import data from various file types into `R`, as well as use data stored in packages.
 
 ```{r, echo = FALSE}
 write.csv(example_data, ""data/example-data.csv"", row.names = FALSE)
 ```
 
-[The example data above can also be found here as a .csv file.](data/example-data.csv) To read this data into `R`, we would use the `read_csv()` function from the `readr` package. Note that `R` has a built in function `read.csv()` that operates very similarly. The `readr` function `read_csv()` has a number of advantages. For example, it is much faster reading larger data. [It also uses the `tibble` package to read the data as a tibble.](https://cran.r-project.org/web/packages/tibble/vignettes/tibble.html){target=""_blank""}
+[The example data above can also be found here as a .csv file.](data/example-data.csv) To read this data into `R`, we would use the `read_csv()` function from the `readr` package. Note that `R` has a built-in function `read.csv()` that operates very similarly. The `readr` function `read_csv()` has a number of advantages. For example, it is much faster reading larger data. [It also uses the `tibble` package to read the data as a tibble.](https://cran.r-project.org/web/packages/tibble/vignettes/tibble.html){target=""_blank""}
 
 ```{r, message = FALSE, warning = FALSE}
 library(readr)
@@ -765,10 +765,10 @@ We can also write our own functions in `R`. For example, we often like to ""stand
 \frac{x - \bar{x}}{s}
 \]
 
-In `R` we would write a function to do this. When writing a function, there are three thing you must do.
+In `R` we would write a function to do this. When writing a function, there are three things you must do.
 
 - Give the function a name. Preferably something that is short, but descriptive.
-- Specify the arguments using `function()`
+- Specify the arguments using `function()`.
 - Write the body of the function within curly braces, `{}`.
 
 ```{r}
@@ -854,7 +854,7 @@ get_var(test_sample, biased = FALSE)
 var(test_sample)
 ```
 
-We see the function is working as expected, and when returning the unbiased estimate it matches `R`'s built in function `var()`. Finally, let's examine the biased estimate of $\sigma^2$.
+We see the function is working as expected, and when returning the unbiased estimate it matches `R`'s built-in function `var()`. Finally, let's examine the biased estimate of $\sigma^2$.
 
 ```{r}
 get_var(test_sample, biased = TRUE)"
daviddalpiaz,appliedstats,c654b10729494108d6b63d00fdf74d402fb8e3d2,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-10T05:25:53Z,chadyuu,yutaro.nishiyama.07@gmail.com,2022-06-10T05:25:53Z,fix typo,r-intro.Rmd,True,False,True,False,3,3,6,"---FILE: r-intro.Rmd---
@@ -9,7 +9,7 @@
 - [RStudio, an excellent IDE for working with `R`.](http://www.rstudio.com/){target=""_blank""}
     - Note, you must have `R` installed to use RStudio. RStudio is simply an interface used to interact with `R`.
 
-The popularity of `R` is on the rise, and everyday it becomes a better tool for statistical analysis. It even generated this book! (A skill you will learn in this course.) There are many good resources for learning `R`. 
+The popularity of `R` is on the rise, and every day it becomes a better tool for statistical analysis. It even generated this book! (A skill you will learn in this course.) There are many good resources for learning `R`. 
 
 The following few chapters will serve as a whirlwind introduction to `R`. They are by no means meant to be a complete reference for the `R` language, but simply an introduction to the basics that we will need along the way. Several of the more important topics will be re-stressed as they are actually needed for analyses.
 
@@ -24,7 +24,7 @@ RStudio has a large number of useful keyboard shortcuts. A list of these can be
 
 The RStudio team has developed [a number of ""cheatsheets""](https://www.rstudio.com/resources/cheatsheets/){target=""_blank""} for working with both `R` and RStudio. [This particular cheatsheet for ""Base"" `R`](https://github.com/rstudio/cheatsheets/blob/main/base-r.pdf){target=""_blank""} will summarize many of the concepts in this document. (""Base"" `R` is a name used to differentiate the practice of using built-in `R` functions, as opposed to using functions from outside packages, in particular, those from the [`tidyverse`](https://www.tidyverse.org/){target=""_blank""}. More on this later.)
 
-When programming, it is often a good practice to follow a style guide. (Where do spaces go? Tabs or spaces? Underscores or CamelCase when naming variables?) No style guide is ""correct"" but it helps to be aware of what others do. The more important thing is to be consistent within your own code.
+When programming, it is often a good practice to follow a style guide. (Where do spaces go? Tabs or spaces? Underscores or CamelCase when naming variables?) No style guide is ""correct,"" but it helps to be aware of what others do. The more important thing is to be consistent within your own code.
 
 - [Hadley Wickham Style Guide](http://adv-r.had.co.nz/Style.html){target=""_blank""} from [Advanced `R`](http://adv-r.had.co.nz/){target=""_blank""}
 - [Google Style Guide](https://google.github.io/styleguide/Rguide.xml){target=""_blank""}
@@ -35,7 +35,7 @@ For this course, our main deviation from these two guides is the use of `=` in p
 
 To get started, we'll use `R` like a simple calculator.
 
-#### Addition, Subtraction, Multiplication and Division {-}
+#### Addition, Subtraction, Multiplication, and Division {-}
 
 | Math          | `R`     | Result    |
 |---------------|---------|-----------|"
daviddalpiaz,appliedstats,fbd495267a7748f6ea25500c222a1fc7a0bec31e,chadyuu,yutaro.nishiyama.07@gmail.com,2022-05-11T06:49:39Z,GitHub,noreply@github.com,2022-05-11T06:49:39Z,Fix a typo: 'at' in place of 'a' in Chapter 14,transformations.Rmd,True,False,True,False,1,1,2,"---FILE: transformations.Rmd---
@@ -570,7 +570,7 @@ Our goal then, is to fit a model to this data in order to be able to predict fue
 econ = read.csv(""data/fuel_econ.csv"")
 ```
 
-In this example, we will be frequently looking a the fitted versus residuals plot, so we *should* write a function to make our life easier, but this is left as an exercise for homework.
+In this example, we will be frequently looking at the fitted versus residuals plot, so we *should* write a function to make our life easier, but this is left as an exercise for homework.
 
 We will also be adding fitted curves to scatterplots repeatedly, so smartly we will write a function to do so.
 "
daviddalpiaz,appliedstats,1edf57403d4aaa41b5c049ba01b4eb0e3ac422a3,Salman Yousaf,37085288+salmany@users.noreply.github.com,2022-01-21T00:50:11Z,GitHub,noreply@github.com,2022-01-21T00:50:11Z,"Fix Typo: 'exist' in place of 'exists'

Line 69: 'Note that scalars do not exists in `R`.'
Should be:
'Note that scalars do not exist in `R`.'
('exist' instead of 'exists')",data-and-programming.Rmd,True,False,True,False,1,1,2,"---FILE: data-and-programming.Rmd---
@@ -66,7 +66,7 @@ Frequently you may wish to create a vector based on a sequence of numbers. The q
 
 Here we see `R` labeling the rows after the first since this is a large vector. Also, we see that by putting parentheses around the assignment, `R` both stores the vector in a variable called `y` and automatically outputs `y` to the console.
 
-Note that scalars do not exists in `R`. They are simply vectors of length `1`.
+Note that scalars do not exist in `R`. They are simply vectors of length `1`.
 
 ```{r}
 2"
daviddalpiaz,appliedstats,970dcaae9ad1a0a2dada030baaa5449dae2932d0,Lowell Tyner,lowell.tyner@gmail.com,2021-07-20T15:27:20Z,Lowell Tyner,lowell.tyner@gmail.com,2021-07-20T15:27:20Z,Fixes very minor typo in the Model Building chapter,model-building.Rmd,True,False,True,False,1,1,2,"---FILE: model-building.Rmd---
@@ -364,7 +364,7 @@ When using model to,
 - **explain**; we prefer *small* and *interpretable* models.
 - **predict**; we prefer models that make the smallest errors possible, without *overfitting*.
 
-Linear models can accomplish both these goals. Later, we will see that often a linear model that accomplish one of these goals, usually accomplishes the other.
+Linear models can accomplish both these goals. Later, we will see that often a linear model that accomplishes one of these goals, usually accomplishes the other.
 
 ## `R` Markdown
 "
daviddalpiaz,appliedstats,4e3f832b05729f40fd566e520bc3827cd645239e,Iván Valdés,iv@nvald.es,2021-07-10T23:46:36Z,GitHub,noreply@github.com,2021-07-10T23:46:36Z,"Update transformations.Rmd

Fix minimal code style issues in R code",transformations.Rmd,True,False,True,False,8,8,16,"---FILE: transformations.Rmd---
@@ -575,10 +575,10 @@ In this example, we will be frequently looking a the fitted versus residuals plo
 We will also be adding fitted curves to scatterplots repeatedly, so smartly we will write a function to do so.
 
 ```{r}
-plot_econ_curve = function(model){
+plot_econ_curve = function(model) {
   plot(mpg ~ mph, data = econ, xlab = ""Speed (Miles per Hour)"", 
        ylab = ""Fuel Efficiency (Miles per Gallon)"", col = ""dodgerblue"", 
-       pch = 20, cex =2)
+       pch = 20, cex = 2)
   xplot = seq(10, 75, by = 0.1)
   lines(xplot, predict(model, newdata = data.frame(mph = xplot)),
         col = ""darkorange"", lwd = 2, lty = 1)
@@ -595,7 +595,7 @@ fit1 = lm(mpg ~ mph, data = econ)
 par(mfrow = c(1, 2))
 plot_econ_curve(fit1)
 plot(fitted(fit1), resid(fit1), xlab = ""Fitted"", ylab = ""Residuals"", 
-     col = ""dodgerblue"", pch = 20, cex =2)
+     col = ""dodgerblue"", pch = 20, cex = 2)
   abline(h = 0, col = ""darkorange"", lwd = 2)
 ```
 
@@ -612,7 +612,7 @@ summary(fit2)
 par(mfrow = c(1, 2))
 plot_econ_curve(fit2)
 plot(fitted(fit2), resid(fit2), xlab = ""Fitted"", ylab = ""Residuals"", 
-     col = ""dodgerblue"", pch = 20, cex =2)
+     col = ""dodgerblue"", pch = 20, cex = 2)
   abline(h = 0, col = ""darkorange"", lwd = 2)
 ```
 
@@ -627,7 +627,7 @@ summary(fit3)
 par(mfrow = c(1, 2))
 plot_econ_curve(fit3)
 plot(fitted(fit3), resid(fit3), xlab = ""Fitted"", ylab = ""Residuals"", 
-     col = ""dodgerblue"", pch = 20, cex =2)
+     col = ""dodgerblue"", pch = 20, cex = 2)
   abline(h = 0, col = ""darkorange"", lwd = 2)
 ```
 
@@ -642,7 +642,7 @@ summary(fit4)
 par(mfrow = c(1, 2))
 plot_econ_curve(fit4)
 plot(fitted(fit4), resid(fit4), xlab = ""Fitted"", ylab = ""Residuals"", 
-     col = ""dodgerblue"", pch = 20, cex =2)
+     col = ""dodgerblue"", pch = 20, cex = 2)
   abline(h = 0, col = ""darkorange"", lwd = 2)
 ```
 
@@ -657,7 +657,7 @@ summary(fit6)
 par(mfrow = c(1, 2))
 plot_econ_curve(fit6)
 plot(fitted(fit6), resid(fit6), xlab = ""Fitted"", ylab = ""Residuals"", 
-     col = ""dodgerblue"", pch = 20, cex =2)
+     col = ""dodgerblue"", pch = 20, cex = 2)
   abline(h = 0, col = ""darkorange"", lwd = 2)
 ```
 
@@ -683,7 +683,7 @@ summary(fit8)
 par(mfrow = c(1, 2))
 plot_econ_curve(fit8)
 plot(fitted(fit8), resid(fit8), xlab = ""Fitted"", ylab = ""Residuals"", 
-     col = ""dodgerblue"", pch = 20, cex =2)
+     col = ""dodgerblue"", pch = 20, cex = 2)
   abline(h = 0, col = ""darkorange"", lwd = 2)
 ```
 "
daviddalpiaz,appliedstats,7d92b2f57eefe3b8310b11706616b2c02cd55589,Tony Mu,tonymuwork@gmail.com,2021-07-05T02:22:54Z,GitHub,noreply@github.com,2021-07-05T02:22:54Z,fix a comma placement,cat-int.Rmd,True,False,True,False,1,1,2,"---FILE: cat-int.Rmd---
@@ -638,7 +638,7 @@ On this plot, we have
 
 The odd result here is that we're estimating that 8 cylinder cars have better fuel efficiency than 6 cylinder cars at **any** displacement! The dotted blue line is always above the dashed grey line. That doesn't seem right. Maybe for very large displacement engines that could be true, but that seems wrong for medium to low displacement.
 
-To attempt to fix this, we will try using an interaction model, that is, instead of simply three intercepts and one slope, we will allow for three slopes. Again, we'll let `R` take the wheel, (no pun intended) then figure out what model it has applied.
+To attempt to fix this, we will try using an interaction model, that is, instead of simply three intercepts and one slope, we will allow for three slopes. Again, we'll let `R` take the wheel (no pun intended), then figure out what model it has applied.
 
 ```{r}
 (mpg_disp_int_cyl = lm(mpg ~ disp * cyl, data = autompg))"
daviddalpiaz,appliedstats,2bcaf3d8656b95769b5e0846c587da5acc3a6aad,Iván Valdés,iv@nvald.es,2021-07-02T00:04:20Z,GitHub,noreply@github.com,2021-07-02T00:04:20Z,Fix typo in Chapter 11,cat-int.Rmd,True,False,True,False,1,1,2,"---FILE: cat-int.Rmd---
@@ -206,7 +206,7 @@ rownames(autompg) = paste(autompg$cyl, ""cylinder"", autompg$year, autompg$name)
 autompg = subset(autompg, select = c(""mpg"", ""cyl"", ""disp"", ""hp"", ""wt"", ""acc"", ""year"", ""origin""))
 # change horsepower from character to numeric
 autompg$hp = as.numeric(autompg$hp)
-# create a dummary variable for foreign vs domestic cars. domestic = 1.
+# create a dummy variable for foreign vs domestic cars. domestic = 1.
 autompg$domestic = as.numeric(autompg$origin == 1)
 # remove 3 and 5 cylinder cars (which are very rare.)
 autompg = autompg[autompg$cyl != 5,]"
daviddalpiaz,appliedstats,9f1dbb04a10da481fcca3f1349412bc4b6b4f4a2,daviddalpiaz,dalpiaz2@illinois.edu,2020-10-30T00:10:51Z,daviddalpiaz,dalpiaz2@illinois.edu,2020-10-30T00:10:51Z,fix oddly rendered styling,index.Rmd,True,False,True,False,2,3,5,"---FILE: index.Rmd---
@@ -1,5 +1,5 @@
 --- 
-title: ""Applied Statistics with `R`""
+title: ""Applied Statistics with R""
 date: ""`r Sys.Date()`""
 github-repo: daviddalpiaz/appliedstats
 url: 'https\://daviddalpiaz.github.io/appliedstats/'
@@ -16,7 +16,7 @@ description: """"
 
 # Introduction
 
-Welcome to Applied Statistics with `R`!
+Welcome to Applied Statistics with R!
 
 ## About This Book
 
@@ -95,4 +95,3 @@ Your name could be here! Suggest an edit! Correct a typo! If you submit a correc
 ## License
 
 ![This work is licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-nc-sa/4.0/).](images/cc.png)
-"
daviddalpiaz,appliedstats,9005ca98110e73ba8e4c08af0c20d5effcfeedf1,nbalepur,55101514+nbalepur@users.noreply.github.com,2020-10-27T19:04:52Z,GitHub,noreply@github.com,2020-10-27T19:04:52Z,Fixed typo in anova.Rmd,anova.Rmd,True,False,True,False,1,1,2,"---FILE: anova.Rmd---
@@ -450,7 +450,7 @@ We'd like to design our experiment so that we have a good chance of detecting an
 We'd like the ANOVA test to have high **power** for an alternative hypothesis with a minimum desired effect size.
 
 \[
-\text{Power } = P(\text{Rejct } H_0 \mid H_0 \text{ False})
+\text{Power } = P(\text{Reject } H_0 \mid H_0 \text{ False})
 \]
 
 That is, for a true difference of means that we deem interesting, we want the test to reject with high probability."
daviddalpiaz,appliedstats,af4c093ac07d025de78a12242d512cc5ed87c776,daviddalpiaz,dalpiaz2@illinois.edu,2020-09-01T16:43:16Z,daviddalpiaz,dalpiaz2@illinois.edu,2020-09-01T16:43:16Z,fix typo,logistic.Rmd,True,False,True,False,1,1,2,"---FILE: logistic.Rmd---
@@ -101,7 +101,7 @@ $$
 \log\left(\frac{p({\bf x})}{1 - p({\bf x})}\right) = \beta_0 + \beta_1 x_1 + \ldots  + \beta_{p - 1} x_{p - 1}
 $$
 
-Immediately we notice some similarities to ordinary linear regression, in particular, the right hand side. This is our usual linear combination of the predictors. We have our usual $p - 1$ predictors for a total of $p$ $\beta$ parameters. (Note, many more machine learning focused texts will use $p$ as the number of parameters. This is an arbitrary choice, but you should be aware of it.)
+Immediately we notice some similarities to ordinary linear regression, in particular, the right hand side. This is our usual linear combination of the predictors. We have our usual $p - 1$ predictors for a total of $p$ $\beta$ parameters. (Note, many more machine learning focused texts will use $p$ as the number of predictors. This is an arbitrary choice, but you should be aware of it.)
 
 The left hand side is called the **log odds**, which is the log of the odds. The odds are the probability for a positive event $(Y = 1)$ divided by the probability of a negative event $(Y = 0)$. So when the odds are $1$, the two events have equal probability. Odds greater than $1$ favor a positive event. The opposite is true when the odds are less than $1$.
 "
daviddalpiaz,appliedstats,e47b5cf355efc4acd826819db2bc784c4680e184,daviddalpiaz,dalpiaz2@illinois.edu,2020-08-15T02:52:08Z,daviddalpiaz,dalpiaz2@illinois.edu,2020-08-15T02:52:08Z,fix more broom issues,anova.Rmd,True,False,True,False,2,1,3,"---FILE: anova.Rmd---
@@ -268,7 +268,8 @@ plot_anova = function(n = 20, mu_a = 0, mu_b = 0, mu_c = 0, sigma = 1) {
   segments(x0 = 1.6, x1 = 2.4, y0 = mean(response[group == ""B""]), y1 = mean(response[group == ""B""]), lwd = 2, lty = 2, col = ""darkorange"")
   segments(x0 = 2.6, x1 = 3.4, y0 = mean(response[group == ""C""]), y1 = mean(response[group == ""C""]), lwd = 2, lty = 2, col = ""black"")
 
-  aov_results = aov(response ~ group)
+  # use lm instead of aov for ease of use with broom::glance
+  aov_results = lm(response ~ group) 
   f_stat = glance(aov_results)$statistic
   p_val  = glance(aov_results)$p.value
   list(f = f_stat, p = p_val)"
daviddalpiaz,appliedstats,1ebe5793619bf2319a8cebef0e8b70e6e105f33a,Albert Lin,linyingkui@gmail.com,2020-08-03T02:08:05Z,GitHub,noreply@github.com,2020-08-03T02:08:05Z,"Fix a typo in logistic.md

Change *residual sum of squared* to *residual sum of squares*",logistic.Rmd,True,False,True,False,1,1,2,"---FILE: logistic.Rmd---
@@ -766,7 +766,7 @@ You may have realized this before we actually explicitly wrote it down!
 
 You have probably noticed that the output from `summary()` is also very similar to that of ordinary linear regression. One difference, is the ""deviance"" being reported. The `Null deviance` is the deviance for the null model, that is, a model with no predictors. The `Residual deviance` is the deviance for the model that was fit.
 
-[**Deviance**](https://en.wikipedia.org/wiki/Deviance_(statistics)){target=""_blank""} compares the model to a saturated model. (Without repeated observations, a saturated model is a model that fits perfectly, using a parameter for each observation.) Essentially, deviance is a generalized *residual sum of squared* for GLMs. Like RSS, deviance decreased as the model complexity increases.
+[**Deviance**](https://en.wikipedia.org/wiki/Deviance_(statistics)){target=""_blank""} compares the model to a saturated model. (Without repeated observations, a saturated model is a model that fits perfectly, using a parameter for each observation.) Essentially, deviance is a generalized *residual sum of squares* for GLMs. Like RSS, deviance decreased as the model complexity increases.
 
 ```{r}
 deviance(chd_mod_ldl)"
daviddalpiaz,appliedstats,e5ce868d1b4105b40288fcc323b4e2d34230744f,daviddalpiaz,dalpiaz2@illinois.edu,2020-06-16T03:23:15Z,daviddalpiaz,dalpiaz2@illinois.edu,2020-06-16T03:23:15Z,better typo fix,slr.Rmd,True,False,True,False,1,1,2,"---FILE: slr.Rmd---
@@ -928,7 +928,7 @@ set.seed(1)
 epsilon = rnorm(n = num_obs, mean = 0, sd = sigma)
 ```
 
-Now, since the $x_i$ values in SLR are considered fixed and known, we simply specify 21 values. Another common practice is to generate them from a uniform distribution, and then use them for the remainder of the analysis.
+Now, since the $x_i$ values in SLR are considered fixed and known, we simply specify `r num_obs` values. Another common practice is to generate them from a uniform distribution, and then use them for the remainder of the analysis.
 
 ```{r}
 x_vals = seq(from = 0, to = 10, length.out = num_obs)"
daviddalpiaz,appliedstats,b1023c73b8dac1a2f56d37a21c1bfffc8db1e841,daviddalpiaz,dalpiaz2@illinois.edu,2020-06-15T16:47:39Z,daviddalpiaz,dalpiaz2@illinois.edu,2020-06-15T16:47:39Z,fixed,slr.Rmd,True,False,True,False,1,1,2,"---FILE: slr.Rmd---
@@ -928,7 +928,7 @@ set.seed(1)
 epsilon = rnorm(n = num_obs, mean = 0, sd = sigma)
 ```
 
-Now, since the $x_i$ values in SLR are considered fixed and known, we simply specify 20 values. Another common practice is to generate them from a uniform distribution, and then use them for the remainder of the analysis.
+Now, since the $x_i$ values in SLR are considered fixed and known, we simply specify 21 values. Another common practice is to generate them from a uniform distribution, and then use them for the remainder of the analysis.
 
 ```{r}
 x_vals = seq(from = 0, to = 10, length.out = num_obs)"
daviddalpiaz,appliedstats,262ce77eb3ef3d57edd0982aae727c32fbad8290,daviddalpiaz,dalpiaz2@illinois.edu,2020-05-20T02:41:41Z,daviddalpiaz,dalpiaz2@illinois.edu,2020-05-20T02:41:41Z,fix typo,index.Rmd;r-intro.Rmd,True,False,True,False,2,1,3,"---FILE: index.Rmd---
@@ -86,6 +86,7 @@ Your name could be here! Suggest an edit! Correct a typo! If you submit a correc
 - [Tony Ma](https://www.linkedin.com/in/tony-ma-b978143a/){target=""_blank""}
 - [Radu Manolescu](https://www.linkedin.com/in/radumanolescu1/){target=""_blank""}
 - [Dileep Pasumarthi](https://www.linkedin.com/in/dileep-pasumarthi-75a53345/){target=""_blank""}
+- Sihun Wang
 
 ## License
 

---FILE: r-intro.Rmd---
@@ -24,7 +24,7 @@ RStudio has a large number of useful keyboard shortcuts. A list of these can be
 
 The RStudio team has developed [a number of ""cheatsheets""](https://www.rstudio.com/resources/cheatsheets/){target=""_blank""} for working with both `R` and RStudio. [This particular cheatsheet for ""Base"" `R`](http://www.rstudio.com/wp-content/uploads/2016/05/base-r.pdf){target=""_blank""} will summarize many of the concepts in this document. (""Base"" `R` is a name used to differentiate the practice of using built-in `R` functions, as opposed to using functions from outside packages, in particular, those from the [`tidyverse`](https://www.tidyverse.org/){target=""_blank""}. More on this later.)
 
-When programming, it is often a good practice to follow a style guide. (Where do spaces go? Tabs or spaces? Underscores or CamelCase when naming variables?) No style guide is ""correct"" but it helps to be aware of what others do. The more import thing is to be consistent within your own code.
+When programming, it is often a good practice to follow a style guide. (Where do spaces go? Tabs or spaces? Underscores or CamelCase when naming variables?) No style guide is ""correct"" but it helps to be aware of what others do. The more important thing is to be consistent within your own code.
 
 - [Hadley Wickham Style Guide](http://adv-r.had.co.nz/Style.html){target=""_blank""} from [Advanced `R`](http://adv-r.had.co.nz/){target=""_blank""}
 - [Google Style Guide](https://google.github.io/styleguide/Rguide.xml){target=""_blank""}"
daviddalpiaz,appliedstats,e1eca1aa7c2f8e89925c1652a5acc3bfdb85fec0,daviddalpiaz,dalpiaz2@illinois.edu,2020-04-01T01:26:05Z,daviddalpiaz,dalpiaz2@illinois.edu,2020-04-01T01:26:05Z,fix additional indicies,anova.Rmd,True,False,True,False,3,3,6,"---FILE: anova.Rmd---
@@ -154,7 +154,7 @@ Here,
 Then the total sample size is
 
 \[
-N = \sum_{i = i}^{g} n_i
+N = \sum_{i = 1}^{g} n_i
 \]
 
 Observations from group $i$ follow a normal distribution
@@ -204,13 +204,13 @@ SST = \sum_{i = 1}^{g} \sum_{j = 1}^{n_i} (y_{ij} - \bar{y})^2
 The variation **between** groups looks at how far the individual sample means are from the overall sample mean.
 
 \[
-SSB = \sum_{i = 1}^{g} \sum_{j = 1}^{n_i} (\bar{y}_i - \bar{y})^2 = \sum_{i = i}^{g} n_i (\bar{y}_i - \bar{y})^2
+SSB = \sum_{i = 1}^{g} \sum_{j = 1}^{n_i} (\bar{y}_i - \bar{y})^2 = \sum_{i = 1}^{g} n_i (\bar{y}_i - \bar{y})^2
 \]
 
 Lastly, the **within** group variation measures how far observations are from the sample mean of its group.
 
 \[
-SSW = \sum_{i = 1}^{g} \sum_{j = 1}^{n_i} (y_{ij} - \bar{y}_i)^2 = \sum_{i = i}^{g} (n_i - 1) s_{i}^{2}
+SSW = \sum_{i = 1}^{g} \sum_{j = 1}^{n_i} (y_{ij} - \bar{y}_i)^2 = \sum_{i = 1}^{g} (n_i - 1) s_{i}^{2}
 \]
 
 This could also be thought of as the error sum of squares, where $y_{ij}$ is an observation and $\bar{y}_i$ is its fitted (predicted) value from the model. "
daviddalpiaz,appliedstats,fa2dd894329f25b62dc1774fa42f783d19d39274,pvsdileep,pvsdileep@gmail.com,2019-07-04T23:37:26Z,GitHub,noreply@github.com,2019-07-04T23:37:26Z,"Typo in Ch - 13 Model Diagnostics

I am a current Stat 420 student. Fixing a typo.",diagnostics.Rmd,True,False,True,False,1,1,2,"---FILE: diagnostics.Rmd---
@@ -375,7 +375,7 @@ qq_plot(rt(25, df = 4))
 qq_plot(rt(100, df = 4))
 ```
 
-Recall, that as the degrees of freedom for a $t$ distribution become larger, the distribution becomes more and more similar to a normal. Here, using 4 degrees of freedom, we have a distribution that is somewhat normal, it is symmetrical and roughly bell-shaped, however it has ""fat tails."" This presents itself clearly in the third panel. While many of the points are close to the line, at the edges, there are large discrepancies. This indicates that the values are to small (negative) or too large (positive) compared to what we would expect for a normal distribution. So for the sample size of `100`, we would conclude that that normality assumption is violated. (If these were residuals of a model.) For sample sizes of `10` and `25` we may be suspicious, but not entirely confident. Reading Q-Q plots, is a bit of an art, not completely a science.
+Recall, that as the degrees of freedom for a $t$ distribution become larger, the distribution becomes more and more similar to a normal. Here, using 4 degrees of freedom, we have a distribution that is somewhat normal, it is symmetrical and roughly bell-shaped, however it has ""fat tails."" This presents itself clearly in the third panel. While many of the points are close to the line, at the edges, there are large discrepancies. This indicates that the values are too small (negative) or too large (positive) compared to what we would expect for a normal distribution. So for the sample size of `100`, we would conclude that that normality assumption is violated. (If these were residuals of a model.) For sample sizes of `10` and `25` we may be suspicious, but not entirely confident. Reading Q-Q plots, is a bit of an art, not completely a science.
 
 Next, we simulate data from an exponential distribution.
 "
daviddalpiaz,appliedstats,49135515d27e2cd6955246c90fb37438464c14bf,ksezgin80,48252013+ksezgin80@users.noreply.github.com,2019-06-07T03:30:57Z,GitHub,noreply@github.com,2019-06-07T03:30:57Z,"Update model-building.Rmd

Fix typo",model-building.Rmd,True,False,True,False,1,1,2,"---FILE: model-building.Rmd---
@@ -249,7 +249,7 @@ plot(mpg ~ hp, data = autompg, col = ""dodgerblue"", pch = 20, cex = 1.5)
 
 Does an increase in horsepower cause a drop in fuel efficiency? Or, perhaps the causality is reversed and an increase in fuel efficiency cause a decrease in horsepower. Or, perhaps there is a third variable that explains both!
 
-The issue here is that we have **observational** data. With observational data, we can only detect *associations*. To speak with confidence about *causality*, we would need to run **experiments**. Often, this is decision is made for us, before we ever see data, so we can only modify our interpretation.
+The issue here is that we have **observational** data. With observational data, we can only detect *associations*. To speak with confidence about *causality*, we would need to run **experiments**. Often, this decision is made for us, before we ever see data, so we can only modify our interpretation.
 
 This is a concept that you should encounter often in your statistics education. For some further reading, and some related fallacies, see: [Wikipedia: Correlation does not imply causation](https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation){target=""_blank""}.
 "
daviddalpiaz,appliedstats,99fefb17a11f00755bcffcd13199b6cbf1e9c8b5,Tony Ma,tonymazn@gmail.com,2019-06-01T01:45:27Z,GitHub,noreply@github.com,2019-06-01T01:45:27Z,Fix typo,slr-inf.Rmd,True,False,True,False,1,1,2,"---FILE: slr-inf.Rmd---
@@ -726,7 +726,7 @@ c(beta_1_hat - crit * beta_1_hat_se, beta_1_hat + crit * beta_1_hat_se)
 
 In addition to confidence intervals for $\beta_0$ and $\beta_1$, there are two other common interval estimates used with regression. The first is called a **confidence interval for the mean response**. Often, we would like an interval estimate for the mean, $E[Y \mid X = x]$ for a particular value of $x$.
 
-In this situation we use $\hat{y}(x)$ as our estimate of $E[Y \mid X = x]$. We modify our notation slightly to make it clear that the the predicted value is a function of the $x$ value.
+In this situation we use $\hat{y}(x)$ as our estimate of $E[Y \mid X = x]$. We modify our notation slightly to make it clear that the predicted value is a function of the $x$ value.
 
 \[
 \hat{y}(x) = \hat{\beta}_0 + \hat{\beta}_1 x"
daviddalpiaz,appliedstats,220328efe855c912be63408ff03b88f1c13060e0,kyleholgate,kyle.holgate@gmail.com,2019-05-10T18:09:55Z,GitHub,noreply@github.com,2019-05-10T18:09:55Z,"Update data-and-programming.Rmd

fix a small grammatical typo",data-and-programming.Rmd,True,False,True,False,1,1,2,"---FILE: data-and-programming.Rmd---
@@ -516,7 +516,7 @@ ex_list = list(
 
 Lists can be subset using two syntaxes, the `$` operator, and square brackets `[]`. The `$` operator returns a named **element** of a list. The `[]` syntax returns a **list**, while the `[[]]` returns an **element** of a list.
 
-- `ex_list[1]` returns a list contain the first element.
+- `ex_list[1]` returns a list containing the first element.
 - `ex_list[[1]]` returns the first element of the list, in this case, a vector.
 
 ```{r}"
daviddalpiaz,appliedstats,06844f783bb1eda949f4903b6491d366663125f7,Elmar Langholz,elan@microsoft.com,2018-08-02T03:54:22Z,Elmar Langholz,elan@microsoft.com,2018-08-02T03:54:22Z,Fix typo: polynimials -> polynomials,transformations.Rmd,True,False,True,False,1,1,2,"---FILE: transformations.Rmd---
@@ -708,7 +708,7 @@ coef(fit6)
 coef(fit6_alt)
 ```
 
-This is because `poly()` uses *orthogonal polynimials*, which solves an issue we will discuss in the next chapter. 
+This is because `poly()` uses *orthogonal polynomials*, which solves an issue we will discuss in the next chapter. 
 
 ```{r}
 summary(fit6)"
daviddalpiaz,appliedstats,335a072d9eef48d373a3564e79726a0410b49263,Junyoung Kim,34694853+junkim327@users.noreply.github.com,2018-07-24T23:51:15Z,GitHub,noreply@github.com,2018-07-24T23:51:15Z,fix some tex commands,logistic.Rmd,True,False,True,False,2,2,4,"---FILE: logistic.Rmd---
@@ -560,7 +560,7 @@ The predictors are various measurements for each individual, many related to hea
 We'll begin by attempting to model the probability of coronary heart disease based on low density lipoprotein cholesterol. That is, we will fit the model
 
 $$
-\log\left(\frac{P[\texttt{chd} = 1]}{1 - P[\texttt{chd} = 1]}\right) = \beta_0 + \beta_{\texttt{ldl}} \texttt{ldl}
+\log\left(\frac{P[\texttt{chd} = 1]}{1 - P[\texttt{chd} = 1]}\right) = \beta_0 + \beta_{\texttt{ldl}} x_{\texttt{ldl}}
 $$
 
 ```{r}
@@ -660,7 +660,7 @@ $$
 Then we can create an approximate $(1 - \alpha)\%$ confidence intervals for $\eta({\bf x})$ using
 
 $$
-\hat{\eta}({\bf x}) \pm z_{\alpha/2} \cdot \text{SE}[\hat{\eta}({\bf x})]] 
+\hat{\eta}({\bf x}) \pm z_{\alpha/2} \cdot \text{SE}[\hat{\eta}({\bf x})]
 $$
 
 where $z_{\alpha/2}$ is the critical value such that $P(Z > z_{\alpha/2}) = \alpha/2$."
daviddalpiaz,appliedstats,6028e9bbe67306cfb7142d9278447258a738a49a,Elmar Langholz,elan@microsoft.com,2018-07-13T03:01:42Z,Elmar Langholz,elan@microsoft.com,2018-07-13T03:01:42Z,Fix logistic link of deviance to wikipedia,logistic.Rmd,True,False,True,False,1,1,2,"---FILE: logistic.Rmd---
@@ -763,7 +763,7 @@ You may have realized this before we actually explicitly wrote it down!
 
 You have probably noticed that the output from `summary()` is also very similar to that of ordinary linear regression. One difference, is the ""deviance"" being reported. The `Null deviance` is the deviance for the null model, that is, a model with no predictors. The `Residual deviance` is the deviance for the mode that was fit.
 
-[**Deviance**](https://en.wikipedia.org/wiki/Deviance_(statistics){target=""_blank""}) compares the model to a saturated model. (Without repeated observations, a saturated model is a model that fits perfectly, using a parameter for each observation.) Essentially, deviance is a generalized *residual sum of squared* for GLMs. Like RSS, deviance decreased as the model complexity increases.
+[**Deviance**](https://en.wikipedia.org/wiki/Deviance_(statistics)){target=""_blank""} compares the model to a saturated model. (Without repeated observations, a saturated model is a model that fits perfectly, using a parameter for each observation.) Essentially, deviance is a generalized *residual sum of squared* for GLMs. Like RSS, deviance decreased as the model complexity increases.
 
 ```{r}
 deviance(chd_mod_ldl)"
daviddalpiaz,appliedstats,4bc0270864c8b1bf32d1b6d0760f205444367730,Thai Duy Cuong Nguyen,dr.dcnguyen@gmail.com,2018-07-10T21:16:05Z,GitHub,noreply@github.com,2018-07-10T21:16:05Z,"Fixed typos

Fixed typos in explanations of Sensitivity and Specificity.",logistic.Rmd,True,False,True,False,2,2,4,"---FILE: logistic.Rmd---
@@ -1009,7 +1009,7 @@ However, are all errors created equal? In this case, absolutely note. The 137 no
 
 Instead of simply evaluating a classifier based on its misclassification rate (or accuracy), we'll define two additional metrics, sensitivity and specificity. Note that this are simply two of many more metrics that can be considered. The [Wikipedia page for sensitivity and specificity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity){target=""_blank""} details a large number of metrics that can be derived form a confusion matrix.
 
-**Sensitivity** is essentially the true positive rate. So when sensitivity if high, the number of false negatives is low.
+**Sensitivity** is essentially the true positive rate. So when sensitivity is high, the number of false negatives is low.
 
 $$
 \text{Sens} = \text{True Positive Rate} = \frac{\text{TP}}{\text{P}} = \frac{\text{TP}}{\text{TP + FN}}
@@ -1023,7 +1023,7 @@ get_sens = function(conf_mat) {
 }
 ```
 
-**Specificity** is essentially the true negative rate. So when Specificity if high, the number of false positives is low.
+**Specificity** is essentially the true negative rate. So when specificity is high, the number of false positives is low.
 
 $$
 \text{Spec} = \text{True Negative Rate} = \frac{\text{TN}}{\text{N}} = \frac{\text{TN}}{\text{TN + FP}}"
daviddalpiaz,appliedstats,14178d9d0a1cff516817528cf8196226a9d6095f,Duy Cuong Nguyen,dr.dcnguyen@gmail.com,2018-06-23T21:53:08Z,GitHub,noreply@github.com,2018-06-23T21:53:08Z,"Update r-intro.Rmd

Fixed typo in link description to cheatsheet for Base `R`.",r-intro.Rmd,True,False,True,False,1,1,2,"---FILE: r-intro.Rmd---
@@ -22,7 +22,7 @@ RStudio has a large number of useful keyboard shortcuts. A list of these can be
 - On Windows: `Alt` + `Shift` + `K`
 - On Mac:  `Option` + `Shift` + `K`
 
-The RStudio team has developed [a number of ""cheatsheets""](https://www.rstudio.com/resources/cheatsheets/){target=""_blank""} for working with both `R` and RStudio. [This particular cheatseet for Base `R`](http://www.rstudio.com/wp-content/uploads/2016/05/base-r.pdf){target=""_blank""} will summarize many of the concepts in this document.
+The RStudio team has developed [a number of ""cheatsheets""](https://www.rstudio.com/resources/cheatsheets/){target=""_blank""} for working with both `R` and RStudio. [This particular cheatsheet for Base `R`](http://www.rstudio.com/wp-content/uploads/2016/05/base-r.pdf){target=""_blank""} will summarize many of the concepts in this document.
 
 When programming, it is often a good practice to follow a style guide. (Where do spaces go? Tabs or spaces? Underscores or CamelCase when naming variables?) No style guide is ""correct"" but it helps to be aware of what others do. The more import thing is to be consistent within your own code.
 "
daviddalpiaz,appliedstats,014e092e3baae390ba937fa7a27e0d041386143f,Duy Cuong Nguyen,dr.dcnguyen@gmail.com,2018-06-23T21:51:49Z,GitHub,noreply@github.com,2018-06-23T21:51:49Z,"Update slr.Rmd

Fixed typo in LINE acronym expansion.",slr.Rmd,True,False,True,False,1,1,2,"---FILE: slr.Rmd---
@@ -179,7 +179,7 @@ This is visually displayed in the image below. We see that for any value $x$, th
 Often, we directly talk about the assumptions that this model makes. They can be cleverly shortened to **LINE**.  
 
 - **L**inear. The relationship between $Y$ and $x$ is linear, of the form $\beta_0 + \beta_1 x$.
-- **I**ndepedent. The errors $\epsilon$ are independent.
+- **I**ndependent. The errors $\epsilon$ are independent.
 - **N**ormal. The errors, $\epsilon$ are normally distributed. That is the ""error"" around the line follows a normal distribution.
 - **E**qual Variance. At each value of $x$, the variance of $Y$ is the same, $\sigma^2$.
 "
daviddalpiaz,appliedstats,139dd80e6394d7d7462206ffbe0ae8121f67e002,daviddalpiaz,dalpiaz2@illinois.edu,2018-06-18T17:42:43Z,daviddalpiaz,dalpiaz2@illinois.edu,2018-06-18T17:42:43Z,fix typo,logistic.Rmd,True,False,True,False,2,2,4,"---FILE: logistic.Rmd---
@@ -724,7 +724,7 @@ Without really thinking about it, we've been using our previous knowledge of `R`
 Let's add an interaction between LDL and family history for the model we selected.
 
 ```{r}
-chd_mod_interaction = glm(chd ~ tobacco + ldl + famhist + typea + age + ldl:famhist, 
+chd_mod_interaction = glm(chd ~ alcohol + ldl + famhist + typea + age + ldl:famhist, 
                           data = SAheart, family = binomial)
 summary(chd_mod_interaction)
 ```
@@ -736,7 +736,7 @@ Based on the $z$-test seen in the above summary, this interaction is significant
 Let's take the previous model, and now add a polynomial term.
 
 ```{r}
-chd_mod_int_quad = glm(chd ~ tobacco + ldl + famhist + typea + age + ldl:famhist + I(ldl^2),
+chd_mod_int_quad = glm(chd ~ alcohol + ldl + famhist + typea + age + ldl:famhist + I(ldl^2),
                        data = SAheart, family = binomial)
 summary(chd_mod_int_quad)
 ```"
daviddalpiaz,appliedstats,32d858c0366f3b942b611d6ec6c44e688cc28b90,Elmar Langholz,elan@microsoft.com,2018-06-15T21:07:12Z,Elmar Langholz,elan@microsoft.com,2018-06-15T21:07:12Z,Fix model-building.Rmd typos,model-building.Rmd,True,False,True,False,3,3,6,"---FILE: model-building.Rmd---
@@ -189,7 +189,7 @@ This is our best guess for the function $f$ in
 y = f(x_1, x_2, x_3, \ldots, x_{p-1}) + \epsilon
 \]
 
-for the assumed **family** and **form**. Fitting a model only gives us the best fit for the family and form that we specify. So the natural question is; how to we choose the correct family and form? We'll focus on *form* since we are focusing on the *family* of linear models.
+for the assumed **family** and **form**. Fitting a model only gives us the best fit for the family and form that we specify. So the natural question is; how do we choose the correct family and form? We'll focus on *form* since we are focusing on the *family* of linear models.
 
 ## Explanation versus Prediction
 
@@ -219,7 +219,7 @@ Our additional assumption is about the error term.
 \epsilon \sim N(0, \sigma^2)
 \]
 
-This assumption, that the errors are normally distributed with some common variance is the key to all of the inference we have done so far. We will discuss this is great detail later.
+This assumption, that the errors are normally distributed with some common variance is the key to all of the inference we have done so far. We will discuss this in great detail later.
 
 So with our inference tools (ANOVA and $t$-test) we have two potential strategies. Start with a very small model (no predictors) and attempt to add predictors. Or, start with a big model (all predictors) and attempt to remove predictors.
 
@@ -282,7 +282,7 @@ Suppose we fit a model using all data available and we evaluate RMSE on this fit
 
 Now, suppose we magically encounter some additional additional data. To truly asses how well the model predicts, we should evaluate how well our models predicts the response of this data. We will call this data the  **test** data and this RMSE the **test** RMSE.
 
-- Train RMSE: model fit on seen data, evaluated on seen data
+- Train RMSE: model fit on seen data, evaluated on **seen** data
 - Test RMSE: model fit on seen data, evaluated on **unseen** data
 
 Below, we simulate some data and fit two models. We will call the solid blue line the ""simple"" model. The dashed orange line will be called the ""complex"" model, which was fit with methods we do not yet know."
daviddalpiaz,appliedstats,a0d82529dd78fed7d492b9e40c9041431a85ce84,daviddalpiaz,dalpiaz2@illinois.edu,2018-06-11T14:39:24Z,daviddalpiaz,dalpiaz2@illinois.edu,2018-06-11T14:39:24Z,fix typo,logistic.Rmd,True,False,True,False,1,1,2,"---FILE: logistic.Rmd---
@@ -1023,7 +1023,7 @@ get_sens = function(conf_mat) {
 }
 ```
 
-**Specificity** is essentially the true negative rate. So when sensitivity if high, the number of false positives is low.
+**Specificity** is essentially the true negative rate. So when Specificity if high, the number of false positives is low.
 
 $$
 \text{Spec} = \text{True Negative Rate} = \frac{\text{TN}}{\text{N}} = \frac{\text{TN}}{\text{TN + FP}}"
daviddalpiaz,appliedstats,f4ec2ef048e7093d32a09a9757189d8dcc8d6047,daviddalpiaz,dalpiaz2@illinois.edu,2018-06-07T01:12:23Z,daviddalpiaz,dalpiaz2@illinois.edu,2018-06-07T01:12:23Z,Adding some details to logistic. Fixing some typos.,logistic.Rmd,True,False,True,False,55,8,63,"---FILE: logistic.Rmd---
@@ -144,7 +144,7 @@ $$
 
 So even though we introduced ordinary linear regression first, in some ways, logistic regression is actually simpler.
 
-Note that appling the inverse logit transformation allow us to obtain an expression for $p({\bf x})$.
+Note that applying the inverse logit transformation allow us to obtain an expression for $p({\bf x})$.
 
 $$
 p({\bf x}) = P[Y = 1 \mid {\bf X} = {\bf x}] = \frac{e^{\beta_0 + \beta_1 x_{1} + \cdots + \beta_{p-1} x_{(p-1)}}}{1 + e^{\beta_0 + \beta_1 x_{1} + \cdots + \beta_{p-1} x_{(p-1)}}}
@@ -519,7 +519,7 @@ $$
 H_0: \beta_q = \beta_{q+1} = \cdots = \beta_{p - 1} = 0.
 $$
 
-This implies that the reduced modesl is nested inside the full model.
+This implies that the reduced model is nested inside the full model.
 
 We then define a test statistic, $D$,
 
@@ -633,13 +633,25 @@ anova(chd_mod_selected, chd_mod_additive, test = ""LRT"")
 
 Here it seems that we would prefer the selected model.
 
+### Confidence Intervals
+
 We can create confidence intervals for the $\beta$ parameters using the `confint()` function as we did with ordinary linear regression.
 
 ```{r}
 confint(chd_mod_selected, level = 0.99)
 ```
 
-Confidence intervals for the mean response require some additional thought. With a large enough sample, we have
+Note that we could create intervals by rearranging the results of the Wald test to obtain the Wald confidence interval. This would be given by
+
+$$
+\hat{\beta}_j \pm z_{\alpha/2} \cdot \text{SE}[\hat{\beta}_j].
+$$
+
+However, `R` is using a slightly different approach based on a concept called the profile likelihood. (The details of which we will omit.) Ultimately the intervals reported will be similar, but the method used by `R` is more common in practice, probably at least partially because it is the default approach in `R`. Check to see how intervals using the formula above compare to those from the output of `confint()`. (Or, note that using `confint.default()` will return the results of calculating the Wald confidence interval.)
+
+### Confidence Intervals for Mean Response
+
+Confidence intervals for the mean response require some additional thought. With a ""large enough"" sample, we have
 
 $$
 \frac{\hat{\eta}({\bf x}) - \eta({\bf x})}{\text{SE}[\hat{\eta}({\bf x})]} \overset{\text{approx}}{\sim} N(0, 1)
@@ -682,7 +694,7 @@ eta_hat = predict(chd_mod_selected, new_obs, se.fit = TRUE, type = ""link"")
 eta_hat
 ```
 
-By setting `se.fit = TRUE`, `R` also computes $\text{SE}[\hat{\eta}({\bf x})]$.
+By setting `se.fit = TRUE`, `R` also computes $\text{SE}[\hat{\eta}({\bf x})]$. Note that we used `type = ""link""`, but this is actually a default value. We added it here to stress that the output from `predict()` will be the value of the link function.
 
 ```{r}
 z_crit = round(qnorm(0.975), 2)
@@ -703,6 +715,12 @@ boot::inv.logit(eta_hat$fit + c(-1, 1) * z_crit * eta_hat$se.fit)
 
 Notice, as we would expect, the bounds of this interval are both between 0 and 1. Also, since both bounds of the interval for $\eta({\bf x})$ are positive, both bounds of the interval for $p({\bf x})$ are greater than 0.5.
 
+### Formula Syntax
+
+Without really thinking about it, we've been using our previous knowledge of `R`'s model formula syntax to fit logistic regression. 
+
+#### Interactions
+
 Let's add an interaction between LDL and family history for the model we selected.
 
 ```{r}
@@ -711,20 +729,49 @@ chd_mod_interaction = glm(chd ~ tobacco + ldl + famhist + typea + age + ldl:famh
 summary(chd_mod_interaction)
 ```
 
-Based on the $z$-test seen in the above summary, this interaction is significant. The effect of LDL on probability of CHD is different depending on family history.
+Based on the $z$-test seen in the above summary, this interaction is significant. The effect of LDL on the probability of CHD is different depending on family history.
+
+#### Polynomial Terms
+
+Let's take the previous model, and now add a polynomial term.
+
+```{r}
+chd_mod_int_quad = glm(chd ~ tobacco + ldl + famhist + typea + age + ldl:famhist + I(ldl^2),
+                       data = SAheart, family = binomial)
+summary(chd_mod_int_quad)
+```
+
+Unsurprisingly, since this additional transformed variable wasn't intelligently chosen, it is not significant. However, this does allow us to stress the fact that the syntax notation that we had been using with `lm()` works basically exactly the same for `glm()`, however now we understand that this is specifying the linear combination of predictions, $\eta({\bf x})$.
+
+That is, the above fits the model
+
+$$
+\log\left(\frac{p({\bf x})}{1 - p({\bf x})}\right) = 
+\beta_0 +
+\beta_{1}x_{\texttt{alcohol}} +
+\beta_{2}x_{\texttt{ldl}} +
+\beta_{3}x_{\texttt{famhist}} +
+\beta_{4}x_{\texttt{typea}} +
+\beta_{5}x_{\texttt{age}} +
+\beta_{6}x_{\texttt{ldl}}x_{\texttt{famhist}} +
+\beta_{7}x_{\texttt{ldl}}^2
+$$
+
+You may have realized this before we actually explicitly wrote it down!
+
+### Deviance
 
-You have probably noticed that the output from `summary()` is very similar to that of ordinary linear regression. One difference, is the ""deviance"" being reported. The `Null deviance` is the deviance for the null model, that is, a model with no predictors. The `Residual deviance` is the deviance for the mode that was fit.
+You have probably noticed that the output from `summary()` is also very similar to that of ordinary linear regression. One difference, is the ""deviance"" being reported. The `Null deviance` is the deviance for the null model, that is, a model with no predictors. The `Residual deviance` is the deviance for the mode that was fit.
 
 [**Deviance**](https://en.wikipedia.org/wiki/Deviance_(statistics){target=""_blank""}) compares the model to a saturated model. (Without repeated observations, a saturated model is a model that fits perfectly, using a parameter for each observation.) Essentially, deviance is a generalized *residual sum of squared* for GLMs. Like RSS, deviance decreased as the model complexity increases.
 
 ```{r}
 deviance(chd_mod_ldl)
 deviance(chd_mod_selected)
 deviance(chd_mod_additive)
-deviance(chd_mod_interaction)
 ```
 
-Note that the first three models above are nested, and we see that deviance does decrease as the model size becomes larger. So while a lower deviance is better, if the model becomes too big, it may be overfitting. Note that `R` also outputs AIC in the summary, which will penalize according to model size, to prevent overfitting.
+Note that these are nested, and we see that deviance does decrease as the model size becomes larger. So while a lower deviance is better, if the model becomes too big, it may be overfitting. Note that `R` also outputs AIC in the summary, which will penalize according to model size, to prevent overfitting.
 
 ## Classification
 "
daviddalpiaz,appliedstats,77fc10dd6555384d176b5dde4539628c656f2696,daviddalpiaz,dalpiaz2@illinois.edu,2018-05-31T18:01:41Z,daviddalpiaz,dalpiaz2@illinois.edu,2018-05-31T18:01:41Z,fix typo,index.Rmd;slr.Rmd,True,False,True,False,2,1,3,"---FILE: index.Rmd---
@@ -88,6 +88,7 @@ Your name could be here! Suggest an edit! Correct a typo! If you submit a correc
 - [Jeff Gerlach](https://github.com/jeffgerlach){target=""_blank""}
 - [Brandon Ching](https://github.com/linuxdream){target=""_blank""}
 - [Ray Fix](https://github.com/rayfix){target=""_blank""}
+- [Tyler Kim](https://github.com/tyler-thetyrant/){target=""_blank""}
 
 ## License
 

---FILE: slr.Rmd---
@@ -174,7 +174,7 @@ $$
 
 This is visually displayed in the image below. We see that for any value $x$, the expected value of $Y$ is $\beta_0 + \beta_1 x$. At each value of $x$, $Y$ has the same variance $\sigma^2$.
 
-![Simple Linear Regression Model [Introductory Statistics (Shafer and Zhang), UC David Stat Wiki](http://statwiki.ucdavis.edu/Textbook_Maps/General_Statistics/Map%3A_Introductory_Statistics_(Shafer_and_Zhang)/10%3A_Correlation_and_Regression/10.3_Modelling_Linear_Relationships_with_Randomness_Present){target=""_blank""}](images/model.jpg)
+![Simple Linear Regression Model [Introductory Statistics (Shafer and Zhang), UC Davis Stat Wiki](http://statwiki.ucdavis.edu/Textbook_Maps/General_Statistics/Map%3A_Introductory_Statistics_(Shafer_and_Zhang)/10%3A_Correlation_and_Regression/10.3_Modelling_Linear_Relationships_with_Randomness_Present){target=""_blank""}](images/model.jpg)
 
 Often, we directly talk about the assumptions that this model makes. They can be cleverly shortened to **LINE**.  
 "
daviddalpiaz,appliedstats,414c2866d9bccf518eec3fd2ca3673be53736f58,daviddalpiaz,dalpiaz2@illinois.edu,2018-05-26T00:57:13Z,daviddalpiaz,dalpiaz2@illinois.edu,2018-05-26T00:57:13Z,fix parameter vs statistic issue,slr.Rmd,True,False,True,False,1,1,2,"---FILE: slr.Rmd---
@@ -306,7 +306,7 @@ c(beta_0_hat, beta_1_hat)
 
 What do these values tell us about our dataset?
 
-The slope *parameter* $\beta_1$ tells us that for an increase in speed of one mile per hour, the **mean** stopping distance increases by $\beta_1$. It is important to specify that we are talking about the mean. Recall that $\beta_0 + \beta_1 x$ is the estimated mean of $Y$, in this case stopping distance, for a particular value of $x$. (In this case speed.) So $\beta_1$ tells us how the mean of $Y$ is affected by a change in $x$.
+The slope *parameter* $\beta_1$ tells us that for an increase in speed of one mile per hour, the **mean** stopping distance increases by $\beta_1$. It is important to specify that we are talking about the mean. Recall that $\beta_0 + \beta_1 x$ is the mean of $Y$, in this case stopping distance, for a particular value of $x$. (In this case speed.) So $\beta_1$ tells us how the mean of $Y$ is affected by a change in $x$.
 
 Similarly, the *estimate* $\hat{\beta}_1 = `r round(beta_1_hat, 2)`$ tells us that for an increase in speed of one mile per hour, the **estimated** *mean* stopping distance increases by $`r round(beta_1_hat, 2)`$ feet. Here we should be sure to specify we are discussing an estimated quantity. Recall that $\hat{y}$ is the estimated mean of $Y$, so $\hat{\beta}_1$ tells us how the estimated mean of $Y$ is affected by changing $x$. 
 "
daviddalpiaz,appliedstats,1c54b668777129939c3968f61830f43a8a0bd46a,daviddalpiaz,dalpiaz2@illinois.edu,2018-05-24T17:05:23Z,daviddalpiaz,dalpiaz2@illinois.edu,2018-05-24T17:05:23Z,KM already identifying issues!,_bookdown.yml;data-and-programming.Rmd;deployment/_build.sh,True,False,True,False,4,3,7,"---FILE: _bookdown.yml---
@@ -1,5 +1,6 @@
 book_filename: ""applied_statistics""
 chapter_name: ""Chapter ""
+new_session: yes
 
 rmd_files: [
   ""index.Rmd"",

---FILE: data-and-programming.Rmd---
@@ -599,7 +599,7 @@ Alternatively, we could use the ""Import Dataset"" feature in RStudio which can be
 
 Earlier we looked at installing packages, in particular the `ggplot2` package. (A package for visualization. While not necessary for this course, it is quickly growing in popularity.) 
 
-```{r, eval = FALSE}
+```{r, message = FALSE, warning = FALSE}
 library(ggplot2)
 ```
 

---FILE: deployment/_build.sh---
@@ -1,4 +1,4 @@
 #!/usr/bin/env Rscript
 
-bookdown::render_book(""index.Rmd"", ""bookdown::gitbook"", new_session = TRUE)
-bookdown::render_book(""index.Rmd"", ""bookdown::pdf_book"", new_session = TRUE)
+bookdown::render_book(""index.Rmd"", ""bookdown::gitbook"")
+bookdown::render_book(""index.Rmd"", ""bookdown::pdf_book"")"
daviddalpiaz,appliedstats,63089a513e61db906a29d781b4d04db9f93045af,Ray Fix,rayfix@gmail.com,2018-05-24T06:33:26Z,Ray Fix,rayfix@gmail.com,2018-05-24T06:33:26Z,"Fixes #12 Add {target=""_blank""} to external links.

Transformation done using:
perl -0777 -pi -e 's/\[([^\]]*)\]\((http[^\)]*)\)/[$1]($2){target=""_blank""}/g' *.Rmd",anova.Rmd;beyond.Rmd;data-and-programming.Rmd;diagnostics.Rmd;index.Rmd;logistic.Rmd;mlr.Rmd;model_building.Rmd;r-intro.Rmd;r-resources.Rmd;selection.Rmd;slr-inf.Rmd;slr.Rmd;transformations.Rmd,True,False,True,False,90,91,181,"---FILE: anova.Rmd---
@@ -35,7 +35,7 @@ The biggest difference between an observational study and an experiment is *how*
 
 In an experiment, the predictors, which are controlled by the experimenter, are called **factors**. The possible values of these factors are called **levels**. Subjects are *randomly* assigned to a level of each of the factors.
 
-The design of experiments could be a course by itself. The Wikipedia article on [design of experiments](https://en.wikipedia.org/wiki/Design_of_experiments) gives a good overview. Originally, most of the methodology was developed for agricultural applications by [R. A. Fisher](https://en.wikipedia.org/wiki/Ronald_Fisher), but are still in use today, now in a wide variety of application areas. Notably, these methods have seen a resurgence as a part of ""A/B Testing.""
+The design of experiments could be a course by itself. The Wikipedia article on [design of experiments](https://en.wikipedia.org/wiki/Design_of_experiments){target=""_blank""} gives a good overview. Originally, most of the methodology was developed for agricultural applications by [R. A. Fisher](https://en.wikipedia.org/wiki/Ronald_Fisher){target=""_blank""}, but are still in use today, now in a wide variety of application areas. Notably, these methods have seen a resurgence as a part of ""A/B Testing.""
 
 <!-- TODO: In the future, discuss the Morrow Plots: http://cropsci.illinois.edu/research/morrow -->
 
@@ -92,7 +92,7 @@ melatonin = data.frame(
 )
 ```
 
-As an example, suppose we are interested in the effect of [melatotin](https://en.wikipedia.org/wiki/Melatonin) on sleep duration. A researcher obtains a random sample of 20 adult males. Of these subjects, 10 are randomly chosen for the control group, which will receive a placebo. The remaining 10 will be given 5mg of melatonin before bed. The sleep duration in hours of each subject is then measured. The researcher chooses a significance level of $\alpha = 0.10$. Was sleep duration affected by the melatonin?
+As an example, suppose we are interested in the effect of [melatotin](https://en.wikipedia.org/wiki/Melatonin){target=""_blank""} on sleep duration. A researcher obtains a random sample of 20 adult males. Of these subjects, 10 are randomly chosen for the control group, which will receive a placebo. The remaining 10 will be given 5mg of melatonin before bed. The sleep duration in hours of each subject is then measured. The researcher chooses a significance level of $\alpha = 0.10$. Was sleep duration affected by the melatonin?
 
 ```{r}
 melatonin
@@ -496,9 +496,9 @@ Notice the `pairwise.t.test()` function does not have a `data` argument. To avoi
 
 Also note that we are using the argument `p.adj = ""none""`. What is this? An adjustment (in this case not an adjustment) to the p-value of each test. Why would we need to do this?
 
-The adjustment is an attempt to correct for the [multiple testing problem](https://en.wikipedia.org/wiki/Multiple_comparisons_problem). (See also: [Relevant XKCD](https://xkcd.com/882/). ) Imagine that you knew ahead of time that you were going to perform 100 $t$-tests. Suppose you wish to do this with a false positive rate of $\alpha = 0.05$. If we use this significance level for each test, for 100 tests, we then expect 5 false positives. That means, with 100 tests, we're almost guaranteed to have at least one error.
+The adjustment is an attempt to correct for the [multiple testing problem](https://en.wikipedia.org/wiki/Multiple_comparisons_problem){target=""_blank""}. (See also: [Relevant XKCD](https://xkcd.com/882/){target=""_blank""}. ) Imagine that you knew ahead of time that you were going to perform 100 $t$-tests. Suppose you wish to do this with a false positive rate of $\alpha = 0.05$. If we use this significance level for each test, for 100 tests, we then expect 5 false positives. That means, with 100 tests, we're almost guaranteed to have at least one error.
 
-What we'd really like, is for the [family-wise error rate](https://en.wikipedia.org/wiki/Family-wise_error_rate) to be 0.05. If we consider the 100 tests to be a single ""experiment"" the FWER is the rate of one or more false positives for in the full experiment (100 tests). Consider it an error rate for an entire procedure, instead of a single test.
+What we'd really like, is for the [family-wise error rate](https://en.wikipedia.org/wiki/Family-wise_error_rate){target=""_blank""} to be 0.05. If we consider the 100 tests to be a single ""experiment"" the FWER is the rate of one or more false positives for in the full experiment (100 tests). Consider it an error rate for an entire procedure, instead of a single test.
 
 With this in mind, one of the simplest adjustments we can make, is to increase the p-values for each test, depending on the number of tests. In particular the Bonferroni correction simply multiplies by the number of tests.
 
@@ -539,7 +539,7 @@ mean(replicate(1000, any(replicate(100, get_p_val()) < 0.05)))
 mean(replicate(1000, any(p.adjust(replicate(100, get_p_val()), ""bonferroni"") < 0.05)))
 ```
 
-For the specific case of testing all two-way mean differences after an ANOVA test, there are [a number of potential methods](https://en.wikipedia.org/wiki/Post_hoc_analysis) for making an adjustment of this type. The pros and cons of the potential methods are beyond the scope of this course. We choose a method for its ease of use, and to a lesser extent, its developer.
+For the specific case of testing all two-way mean differences after an ANOVA test, there are [a number of potential methods](https://en.wikipedia.org/wiki/Post_hoc_analysis){target=""_blank""} for making an adjustment of this type. The pros and cons of the potential methods are beyond the scope of this course. We choose a method for its ease of use, and to a lesser extent, its developer.
 
 Tukey's Honest Significance difference can be applied directly to an object which was created using `aov()`. It will adjust the p-values of the pairwise comparisons of the means to control the FWER, in this case, for 0.05. Notice it also gives confidence intervals for the difference of the means.
 
@@ -555,7 +555,7 @@ Also, nicely, we can easily produce a plot of these confidence intervals.
 plot(TukeyHSD(coag_aov, conf.level = 0.95))
 ```
 
-The creator of this method, [John Tukey](https://en.wikipedia.org/wiki/John_Tukey), is an important figure in the history of data science. He essentially [predicted the rise of data science over 50 years ago](https://projecteuclid.org/euclid.aoms/1177704711). For some retrospective thoughts on those 50 years, see [this paper from David Donoho](http://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf).
+The creator of this method, [John Tukey](https://en.wikipedia.org/wiki/John_Tukey){target=""_blank""}, is an important figure in the history of data science. He essentially [predicted the rise of data science over 50 years ago](https://projecteuclid.org/euclid.aoms/1177704711){target=""_blank""}. For some retrospective thoughts on those 50 years, see [this paper from David Donoho](http://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf){target=""_blank""}.
 
 ## Two-Way ANOVA
 

---FILE: beyond.Rmd---
@@ -14,68 +14,68 @@ So you've completed STAT 420, where do you go from here? Now that you understand
 
 ## RStudio
 
-RStudio has recently released version 1.0! This is exciting for a number of reason, especially the release of [`R` Notebooks](http://rmarkdown.rstudio.com/r_notebooks.html). `R` Notebooks combine the RMarkdown you have already learned with the ability to work interactively.
+RStudio has recently released version 1.0! This is exciting for a number of reason, especially the release of [`R` Notebooks](http://rmarkdown.rstudio.com/r_notebooks.html){target=""_blank""}. `R` Notebooks combine the RMarkdown you have already learned with the ability to work interactively.
 
 ## Tidy Data
 
-In this textbook, much of the data we have seen has been nice and tidy. It was rectangular where each row is an observation and each column is a variable. This is not always the case! Many packages have been developed to deal with data, and force it into a nice format, which is called [tidy data](http://vita.had.co.nz/papers/tidy-data.pdf), that we can then use for modeling. Often during analysis, this is where a large portion of your time will be spent.
+In this textbook, much of the data we have seen has been nice and tidy. It was rectangular where each row is an observation and each column is a variable. This is not always the case! Many packages have been developed to deal with data, and force it into a nice format, which is called [tidy data](http://vita.had.co.nz/papers/tidy-data.pdf){target=""_blank""}, that we can then use for modeling. Often during analysis, this is where a large portion of your time will be spent.
 
-The `R` community has started to call this collection of packages the [Tidyverse](http://tidyverse.org/). It was once called the Hadleyverse, as [Hadley Wickham](http://hadley.nz/) has authored so many of the packages. Hadley is writing a book called [`R` for Data Science](http://r4ds.had.co.nz/) which describes the use of many of these packages. (And also how to use some to make the modeling process better!) This book is a great starting point for diving deeper into the `R` community. The two main packages are [`dplyr`](https://cran.r-project.org/web/packages/dplyr/vignettes/dplyr.html) and [`tidyr`](https://blog.rstudio.org/2014/07/22/introducing-tidyr/) both of which are used internally in RStudio.
+The `R` community has started to call this collection of packages the [Tidyverse](http://tidyverse.org/){target=""_blank""}. It was once called the Hadleyverse, as [Hadley Wickham](http://hadley.nz/){target=""_blank""} has authored so many of the packages. Hadley is writing a book called [`R` for Data Science](http://r4ds.had.co.nz/){target=""_blank""} which describes the use of many of these packages. (And also how to use some to make the modeling process better!) This book is a great starting point for diving deeper into the `R` community. The two main packages are [`dplyr`](https://cran.r-project.org/web/packages/dplyr/vignettes/dplyr.html){target=""_blank""} and [`tidyr`](https://blog.rstudio.org/2014/07/22/introducing-tidyr/){target=""_blank""} both of which are used internally in RStudio.
 
 ## Visualization
 
-In this course, we have mostly used the base plotting methods in `R`. When working with tidy data, many users prefer to use the [`ggplot2`](http://ggplot2.org/) package, also developed by Hadley Wickham. RStudio provides a rather detailed [""cheat sheet""](https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf) for working with `ggplot2`. The community maintains a [graph gallery](http://www.r-graph-gallery.com/portfolio/ggplot2-package/) of examples.
+In this course, we have mostly used the base plotting methods in `R`. When working with tidy data, many users prefer to use the [`ggplot2`](http://ggplot2.org/){target=""_blank""} package, also developed by Hadley Wickham. RStudio provides a rather detailed [""cheat sheet""](https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf){target=""_blank""} for working with `ggplot2`. The community maintains a [graph gallery](http://www.r-graph-gallery.com/portfolio/ggplot2-package/){target=""_blank""} of examples.
 
-Use of the [`manipulate` package](https://support.rstudio.com/hc/en-us/articles/200551906-Interactive-Plotting-with-Manipulate) with RStudio gives the ability to quickly change a static graphic to become interactive.
+Use of the [`manipulate` package](https://support.rstudio.com/hc/en-us/articles/200551906-Interactive-Plotting-with-Manipulate){target=""_blank""} with RStudio gives the ability to quickly change a static graphic to become interactive.
 
 ## Web Applications
 
-RStudio has made it incredible easy to create data products through the use of [Shiny](https://shiny.rstudio.com/), which allows for the creation of web applications with `R`. RStudio maintains an ever-growing [tutorial](http://shiny.rstudio.com/tutorial/) and [gallery](https://shiny.rstudio.com/gallery/) of examples.
+RStudio has made it incredible easy to create data products through the use of [Shiny](https://shiny.rstudio.com/){target=""_blank""}, which allows for the creation of web applications with `R`. RStudio maintains an ever-growing [tutorial](http://shiny.rstudio.com/tutorial/){target=""_blank""} and [gallery](https://shiny.rstudio.com/gallery/){target=""_blank""} of examples.
 
 ## Experimental Design
 
-In the ANOVA chapter, we briefly discussed experimental design. This topic could easily be its own class, and is currently an area of revitalized interest with the rise of [A/B testing.](https://en.wikipedia.org/wiki/A/B_testing) Two more classic statistical references include *Statistics for Experimenters* by Box, Hunter, and Hunter as well as *Design and Analysis of Experiments* by Douglas Montgomery. There are several `R` packages for design of experiments, list in the [CRAN Task View](https://cran.r-project.org/web/views/ExperimentalDesign.html).
+In the ANOVA chapter, we briefly discussed experimental design. This topic could easily be its own class, and is currently an area of revitalized interest with the rise of [A/B testing.](https://en.wikipedia.org/wiki/A/B_testing){target=""_blank""} Two more classic statistical references include *Statistics for Experimenters* by Box, Hunter, and Hunter as well as *Design and Analysis of Experiments* by Douglas Montgomery. There are several `R` packages for design of experiments, list in the [CRAN Task View](https://cran.r-project.org/web/views/ExperimentalDesign.html){target=""_blank""}.
 
 ## Machine Learning
 
-Using models for prediction is the key focus of machine learning. There are many methods, each with its own package, however `R` has a wonderful package called [`caret`, *Classification And REgression Training*,](http://topepo.github.io/caret/index.html) which provides a unified interface to training these models. It also contains various utilities for data processing and visualization that are useful for predictive modeling. 
+Using models for prediction is the key focus of machine learning. There are many methods, each with its own package, however `R` has a wonderful package called [`caret`, *Classification And REgression Training*,](http://topepo.github.io/caret/index.html){target=""_blank""} which provides a unified interface to training these models. It also contains various utilities for data processing and visualization that are useful for predictive modeling. 
 
-*Applied Predictive Modeling* by Max Kuhn, the author of the `caret` package is a good general resource for predictive modeling, which obviously utilizes `R`. [*An Introduction to Statistical Learning*](http://www-bcf.usc.edu/~gareth/ISL/) by James, Witten, Hastie, and Tibshirani is a gentle introduction to machine learning from a statistical perspective which uses `R` and picks up right where this courses stops. This is based on the often referenced [*The Elements of Statistical Learning*](https://web.stanford.edu/~hastie/Papers/ESLII.pdf) by Hastie, Tibshirani, and Friedman. Both are freely available online.
+*Applied Predictive Modeling* by Max Kuhn, the author of the `caret` package is a good general resource for predictive modeling, which obviously utilizes `R`. [*An Introduction to Statistical Learning*](http://www-bcf.usc.edu/~gareth/ISL/){target=""_blank""} by James, Witten, Hastie, and Tibshirani is a gentle introduction to machine learning from a statistical perspective which uses `R` and picks up right where this courses stops. This is based on the often referenced [*The Elements of Statistical Learning*](https://web.stanford.edu/~hastie/Papers/ESLII.pdf){target=""_blank""} by Hastie, Tibshirani, and Friedman. Both are freely available online.
 
 ### Deep Learning
 
-While, it probably isn't the best tool for the job, `R` now has the ability to [train deep neural networks via TensorFlow](https://rstudio.github.io/tensorflow/).
+While, it probably isn't the best tool for the job, `R` now has the ability to [train deep neural networks via TensorFlow](https://rstudio.github.io/tensorflow/){target=""_blank""}.
 
 ## Time Series
 
 In this class we have only considered independent data. What if data is dependent? Time Series is the area of statistics which deals with this issue, and could easily span multiple courses.
 
 Two books that are used in STAT 429 at the University of Illinois, both free:
 
-- [*Time Series Analysis and Its Applications: With R Examples*](http://www.stat.pitt.edu/stoffer/tsa4/) by Shumway and Stoffer
-- [A Tour of Time Series Analysis with R](http://tts.smac-group.com/) by Balamuta, Guerrier, Molinari, and Xu. This book is currently under development at UIUC.
+- [*Time Series Analysis and Its Applications: With R Examples*](http://www.stat.pitt.edu/stoffer/tsa4/){target=""_blank""} by Shumway and Stoffer
+- [A Tour of Time Series Analysis with R](http://tts.smac-group.com/){target=""_blank""} by Balamuta, Guerrier, Molinari, and Xu. This book is currently under development at UIUC.
 
 Some tutorials:
 
-- [Little Book of R for Time Series](https://a-little-book-of-r-for-time-series.readthedocs.io/en/latest/)
-- [Quick `R`: Time Series and Forecasting](http://www.statmethods.net/advstats/timeseries.html)
-- [TSA: Start to Finish Examples](http://rpubs.com/ryankelly/ts6)
+- [Little Book of R for Time Series](https://a-little-book-of-r-for-time-series.readthedocs.io/en/latest/){target=""_blank""}
+- [Quick `R`: Time Series and Forecasting](http://www.statmethods.net/advstats/timeseries.html){target=""_blank""}
+- [TSA: Start to Finish Examples](http://rpubs.com/ryankelly/ts6){target=""_blank""}
 
-When performing time series analysis in `R` you should be aware of the [many packages](https://cran.r-project.org/web/views/TimeSeries.html) that are useful for analysis. It should be hard to avoid the [`forecast`](https://github.com/robjhyndman/forecast) and [`zoo`](https://cran.r-project.org/web/packages/zoo/zoo.pdf) packages. Often the most difficult part will be dealing with time and date data. Make sure you are utilizing one of the many packages that help with this.
+When performing time series analysis in `R` you should be aware of the [many packages](https://cran.r-project.org/web/views/TimeSeries.html){target=""_blank""} that are useful for analysis. It should be hard to avoid the [`forecast`](https://github.com/robjhyndman/forecast){target=""_blank""} and [`zoo`](https://cran.r-project.org/web/packages/zoo/zoo.pdf){target=""_blank""} packages. Often the most difficult part will be dealing with time and date data. Make sure you are utilizing one of the many packages that help with this.
 
 ## Bayesianism
 
 In this class, we have worked within the frequentist view of statistics. There is an entire alternative universe of Bayesian statistics.
 
-[*Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan*](https://sites.google.com/site/doingbayesiandataanalysis/) by John Kruschke is a great introduction to the topic. It introduces the world of [probabilistic programming](https://www.cs.cornell.edu/Courses/cs4110/2016fa/lectures/lecture33.html), in particular [Stan](http://mc-stan.org/), which can be used in both `R` and Python.
+[*Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan*](https://sites.google.com/site/doingbayesiandataanalysis/){target=""_blank""} by John Kruschke is a great introduction to the topic. It introduces the world of [probabilistic programming](https://www.cs.cornell.edu/Courses/cs4110/2016fa/lectures/lecture33.html){target=""_blank""}, in particular [Stan](http://mc-stan.org/){target=""_blank""}, which can be used in both `R` and Python.
 
 ## High Performance Computing
 
-Often `R` will be called a ""slow"" language, for two reasons. One, because many do not understand `R`. Two, because sometimes it really is. Luckily, it is easy to extend `R` via the [`Rcpp` package](http://www.rcpp.org/) to allow for faster code. Many modern `R` packages utilize `Rcpp` to achieve better performance.
+Often `R` will be called a ""slow"" language, for two reasons. One, because many do not understand `R`. Two, because sometimes it really is. Luckily, it is easy to extend `R` via the [`Rcpp` package](http://www.rcpp.org/){target=""_blank""} to allow for faster code. Many modern `R` packages utilize `Rcpp` to achieve better performance.
 
 ## Further `R` Resources
 
-Also, don't forget that previously in this book we have outlined a large number of [`R` resources](http://daviddalpiaz.github.io/appliedstats/introduction-to-r.html#r-resources). Now that you've gotten started with `R` many of these will be much more useful.
+Also, don't forget that previously in this book we have outlined a large number of [`R` resources](http://daviddalpiaz.github.io/appliedstats/introduction-to-r.html#r-resources){target=""_blank""}. Now that you've gotten started with `R` many of these will be much more useful.
 
 If any of these topics interest you, and you would like more information, please don't hesitate to start a discussion on the forums!
 

---FILE: data-and-programming.Rmd---
@@ -45,9 +45,9 @@ x = c(1, 3, 5, 7, 8, 9)
 x
 ```
 
-As an aside, there is a long history of the assignment operator in `R`, partially due to the keys available on the [keyboards of the creators of the `S` language.](https://twitter.com/kwbroman/status/747829864091127809) (Which preceded `R`.) For simplicity we will use `=`, but know that often you will see `<-` as the assignment operator. 
+As an aside, there is a long history of the assignment operator in `R`, partially due to the keys available on the [keyboards of the creators of the `S` language.](https://twitter.com/kwbroman/status/747829864091127809){target=""_blank""} (Which preceded `R`.) For simplicity we will use `=`, but know that often you will see `<-` as the assignment operator. 
 
-The pros and cons of these two are well beyond the scope of this book, but know that for our purposes you will have no issue if you simply use `=`. If you are interested in the weird cases where the difference matters, check out [The R Inferno](http://www.burns-stat.com/documents/books/the-r-inferno/).
+The pros and cons of these two are well beyond the scope of this book, but know that for our purposes you will have no issue if you simply use `=`. If you are interested in the weird cases where the difference matters, check out [The R Inferno](http://www.burns-stat.com/documents/books/the-r-inferno/){target=""_blank""}.
 
 If you wish to use `<-`, you will still need to use `=`, however only for argument passing. Some users like to keep assignment (`<-`) and argument passing (`=`) separate. No matter what you choose, the more important thing is that you **stay consistent**. Also, if working on a larger collaborative project, you should use whatever style is already in place.
 
@@ -572,7 +572,7 @@ The `data.frame()` function above is one way to create a data frame. We can also
 write.csv(example_data, ""data/example-data.csv"", row.names = FALSE)
 ```
 
-[The example data above can also be found here as a .csv file.](data/example-data.csv) To read this data into `R`, we would use the `read_csv()` function from the `readr` package. Note that `R` has a built in function `read.csv()` that operates very similarly. The `readr` function `read_csv()` has a number of advantages. For example, it is much faster reading larger data. [It also uses the `tibble` package to read the data as a tibble.](https://cran.r-project.org/web/packages/tibble/vignettes/tibble.html)
+[The example data above can also be found here as a .csv file.](data/example-data.csv) To read this data into `R`, we would use the `read_csv()` function from the `readr` package. Note that `R` has a built in function `read.csv()` that operates very similarly. The `readr` function `read_csv()` has a number of advantages. For example, it is much faster reading larger data. [It also uses the `tibble` package to read the data as a tibble.](https://cran.r-project.org/web/packages/tibble/vignettes/tibble.html){target=""_blank""}
 
 ```{r, message = FALSE, warning = FALSE}
 library(readr)

---FILE: diagnostics.Rmd---
@@ -228,7 +228,7 @@ This time on the fitted versus residuals plot, for any fitted value, the spread
 
 Constant variance is often called **homoscedasticity**. Conversely, non-constant variance is called **heteroscedasticity**. We've seen how we can use a fitted versus residuals plot to look for these attributes.
 
-While a fitted versus residuals plot can give us an idea about homoscedasticity, sometimes we would prefer a more formal test. There are many tests for constant variance, but here we will present one, the [**Breusch-Pagan Test**](https://en.wikipedia.org/wiki/Breusch%E2%80%93Pagan_test). The exact details of the test will omitted here, but importantly the null and alternative can be considered to be,
+While a fitted versus residuals plot can give us an idea about homoscedasticity, sometimes we would prefer a more formal test. There are many tests for constant variance, but here we will present one, the [**Breusch-Pagan Test**](https://en.wikipedia.org/wiki/Breusch%E2%80%93Pagan_test){target=""_blank""}. The exact details of the test will omitted here, but importantly the null and alternative can be considered to be,
 
 - $H_0$: Homoscedasticity. The errors have constant variance about the true model.
 - $H_1$: Heteroscedasticity.  The errors have non-constant variance about the true model.
@@ -309,7 +309,7 @@ In short, if the points of the plot do not closely follow a straight line, this
 
 The calculations required to create the plot vary depending on the implementation, but essentially the $y$-axis is the sorted data (observed, or sample quantiles), and the $x$-axis is the values we would expect if the data did come from a normal distribution (theoretical quantiles).
 
-The [Wikipedia page for Normal probability plots](http://en.wikipedia.org/wiki/Normal_probability_plot) gives details on how this is implemented in `R` if you are interested.
+The [Wikipedia page for Normal probability plots](http://en.wikipedia.org/wiki/Normal_probability_plot){target=""_blank""} gives details on how this is implemented in `R` if you are interested.
 
 Also, to get a better idea of how Q-Q plots work, here is a quick function which creates a Q-Q plot:
 
@@ -428,7 +428,7 @@ shapiro.test(rexp(25))
 
 This gives us the value of the test statistic and its p-value. The null hypothesis assumes the data were sampled from a normal distribution, thus a small p-value indicates we believe there is only a small probability the data could have been sampled from a normal distribution.
 
-For details, see: [Wikipedia: Shapiro–Wilk test.](https://en.wikipedia.org/wiki/Shapiro-Wilk_test)
+For details, see: [Wikipedia: Shapiro–Wilk test.](https://en.wikipedia.org/wiki/Shapiro-Wilk_test){target=""_blank""}
 
 In the above examples, we see we fail to reject for the data sampled from normal, and reject on the non-normal data, for any reasonable $\alpha$.
 
@@ -450,7 +450,7 @@ shapiro.test(resid(fit_3))
 
 In addition to checking the assumptions of regression, we also look for any ""unusual observations"" in the data. Often a small number of data points can have an extremely large influence on a regression, sometimes so much so that the regression assumptions are violated as a result of these points.
 
-The following three plots are inspired by an example from [Linear Models with R](http://www.maths.bath.ac.uk/~jjf23/LMR/).
+The following three plots are inspired by an example from [Linear Models with R](http://www.maths.bath.ac.uk/~jjf23/LMR/){target=""_blank""}.
 
 ```{r unusual_obs_plot, fig.height = 5, fig.width = 15}
 par(mfrow = c(1, 3))

---FILE: index.Rmd---
@@ -1,6 +1,5 @@
 --- 
 title: ""Applied Statistics with `R`""
-author: ""[David Dalpiaz](https://daviddalpiaz.com/)""
 date: ""`r Sys.Date()`""
 github-repo: daviddalpiaz/appliedstats
 url: 'https\://daviddalpiaz.github.io/appliedstats/'
@@ -36,9 +35,9 @@ Welcome to Applied Statistics with `R`!
 
 This book was originally (and currently) designed for use with STAT 420, Methods of Applied Statistics, at the University of Illinois at Urbana-Champaign. It may certainly be used elsewhere, but any references to ""this course"" in this book specifically refer to STAT 420.
 
-This book is under active development. When possible, it would be best to always access the text online to be sure you are using the most up-to-date version. Also, the html version provides additional features such as changing text size, font, and colors. If you are in need of a local copy, a [**pdf version** is continuously maintained](http://daviddalpiaz.github.io/appliedstats/applied_statistics.pdf).
+This book is under active development. When possible, it would be best to always access the text online to be sure you are using the most up-to-date version. Also, the html version provides additional features such as changing text size, font, and colors. If you are in need of a local copy, a [**pdf version** is continuously maintained](http://daviddalpiaz.github.io/appliedstats/applied_statistics.pdf){target=""_blank""}.
 
-Since this book is under active development you may encounter errors ranging from typos, to broken code, to poorly explained topics. If you do, please let us know! Simply send an email and we will make the changes as soon as possible. (`dalpiaz2 AT illinois DOT edu`) Or, if you know RMarkdown and are familiar with GitHub, [make a pull request and fix an issue yourself!](https://github.com/daviddalpiaz/appliedstats) This process is partially automated by the edit button in the top-left corner of the html version. If your suggestion or fix becomes part of the book, you will be added to the list at the end of this chapter. We'll also link to your GitHub account, or personal website upon request.
+Since this book is under active development you may encounter errors ranging from typos, to broken code, to poorly explained topics. If you do, please let us know! Simply send an email and we will make the changes as soon as possible. (`dalpiaz2 AT illinois DOT edu`) Or, if you know RMarkdown and are familiar with GitHub, [make a pull request and fix an issue yourself!](https://github.com/daviddalpiaz/appliedstats){target=""_blank""} This process is partially automated by the edit button in the top-left corner of the html version. If your suggestion or fix becomes part of the book, you will be added to the list at the end of this chapter. We'll also link to your GitHub account, or personal website upon request.
 
 This text uses MathJax to render mathematical notation for the web. Occasionally, but rarely, a JavaScript error will prevent MathJax from rendering correctly. In this case, you will see the ""code"" instead of the expected mathematical equations. From experience, this is almost always fixed by simply refreshing the page. You'll also notice that if you right-click any equation you can obtain the MathML Code (for copying into Microsoft Word) or the TeX command used to generate the equation.
 
@@ -72,25 +71,25 @@ Material in this book was heavily influenced by:
 
 - Alex Stepanov
     - Longtime instructor of STAT 420 at the University of Illinois at Urbana-Champaign. The author of this book actually took Alex's STAT 420 class many years ago! Alex provided or inspired many of the examples in the text.
-- [David Unger](http://publish.illinois.edu/dunger/)
+- [David Unger](http://publish.illinois.edu/dunger/){target=""_blank""}
     - Another STAT 420 instructor at the University of Illinois at Urbana-Champaign. Co-taught with the author during the summer of 2016 while this book was first being developed. Provided endless hours of copy editing and countless suggestions.
-- [James Balamuta](http://www.thecoatlessprofessor.com/)
-    - Current graduate student at the University of Illinois at Urbana-Champaign. Provided the initial push to write this book by introducing the author to the [`bookdown`](https://bookdown.org/yihui/bookdown/) package in `R`. Also a frequent contributor via GitHub.
+- [James Balamuta](http://www.thecoatlessprofessor.com/){target=""_blank""}
+    - Current graduate student at the University of Illinois at Urbana-Champaign. Provided the initial push to write this book by introducing the author to the [`bookdown`](https://bookdown.org/yihui/bookdown/){target=""_blank""} package in `R`. Also a frequent contributor via GitHub.
 
 Your name could be here! Suggest an edit! Correct a typo! If you submit a correction and would like to be listed below, please provide your name as you would like it to appear, as well as a link to a GitHub, LinkedIn, or personal website.
 
-- [Daniel McQuillan](https://github.com/dmcquillan314)
-- [Mason Rubenstein](https://github.com/mruben09)
-- [Yuhang Wang](https://github.com/yuhangwang)
+- [Daniel McQuillan](https://github.com/dmcquillan314){target=""_blank""}
+- [Mason Rubenstein](https://github.com/mruben09){target=""_blank""}
+- [Yuhang Wang](https://github.com/yuhangwang){target=""_blank""}
 - Zhao Liu
-- [Jinfeng Xiao](https://github.com/JinfengXiao)
-- [Somu Palaniappan](https://www.linkedin.com/in/somupalaniappan)
-- [Michael Hung-Yiu Chan](https://www.linkedin.com/in/michaelchan2newyork)
-- [Eloise Rosen](https://github.com/EloiseRosen)
-- [Kiomars Nassiri](https://www.linkedin.com/in/kiomars-nassiri-kahnamooee/)
-- [Jeff Gerlach](https://github.com/jeffgerlach)
-- [Brandon Ching](https://github.com/linuxdream)
-- [Ray Fix](https://github.com/rayfix)
+- [Jinfeng Xiao](https://github.com/JinfengXiao){target=""_blank""}
+- [Somu Palaniappan](https://www.linkedin.com/in/somupalaniappan){target=""_blank""}
+- [Michael Hung-Yiu Chan](https://www.linkedin.com/in/michaelchan2newyork){target=""_blank""}
+- [Eloise Rosen](https://github.com/EloiseRosen){target=""_blank""}
+- [Kiomars Nassiri](https://www.linkedin.com/in/kiomars-nassiri-kahnamooee/){target=""_blank""}
+- [Jeff Gerlach](https://github.com/jeffgerlach){target=""_blank""}
+- [Brandon Ching](https://github.com/linuxdream){target=""_blank""}
+- [Ray Fix](https://github.com/rayfix){target=""_blank""}
 
 ## License
 

---FILE: logistic.Rmd---
@@ -23,7 +23,7 @@ Now we'll allow for two modifications of this situation, which will let us use l
 
 In *general*, a generalized linear model has three parts:
 
-- A **distribution** of the response conditioned on the predictors. (Technically this distribution needs to be from the [exponential family](https://en.wikipedia.org/wiki/Exponential_family) of distributions.)
+- A **distribution** of the response conditioned on the predictors. (Technically this distribution needs to be from the [exponential family](https://en.wikipedia.org/wiki/Exponential_family){target=""_blank""} of distributions.)
 - A **linear combination** of the $p - 1$ predictors, $\beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots  + \beta_{p - 1} x_{p - 1}$, which we write as $\eta({\bf x})$. That is,  
 
 $$\eta({\bf x}) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots  + \beta_{p - 1} x_{p - 1}$$
@@ -97,13 +97,13 @@ $$
 \frac{p({\bf x})}{1 - p({\bf x})} = \frac{P[Y = 1 \mid {\bf X} = {\bf x}]}{P[Y = 0 \mid {\bf X} = {\bf x}]}
 $$
 
-Essentially, the log odds are the [logit](https://en.wikipedia.org/wiki/Logit) transform applied to $p({\bf x})$.
+Essentially, the log odds are the [logit](https://en.wikipedia.org/wiki/Logit){target=""_blank""} transform applied to $p({\bf x})$.
 
 $$
 \text{logit}(x) = \log\left(\frac{x}{1 - x}\right)
 $$
 
-It will also be useful to define the inverse logit, otherwise known as the ""logistic"" or [sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function) function.
+It will also be useful to define the inverse logit, otherwise known as the ""logistic"" or [sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function){target=""_blank""} function.
 
 $$
 \text{logit}^{-1}(x) = \frac{e^x}{1 + e^{x}} = \frac{1}{1 + e^{-x}}
@@ -198,7 +198,7 @@ This, and similar numeric issues related to estimated probabilities near 0 or 1,
 message(""Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred"")
 ```
 
-When this happens, the model is still ""fit,"" but there are consequences, namely, the estimated coefficients are highly suspect. This is an issue when then trying to interpret the model. When this happens, the model will often still be useful for creating a classifier, which will be discussed later. However, it is still subject to the usual evaluations for classifiers to determine how well it is performing. For details, see [Modern Applied Statistics with S-PLUS, Chapter 7](https://link.springer.com/content/pdf/10.1007/978-1-4757-2719-7_7.pdf).
+When this happens, the model is still ""fit,"" but there are consequences, namely, the estimated coefficients are highly suspect. This is an issue when then trying to interpret the model. When this happens, the model will often still be useful for creating a classifier, which will be discussed later. However, it is still subject to the usual evaluations for classifiers to determine how well it is performing. For details, see [Modern Applied Statistics with S-PLUS, Chapter 7](https://link.springer.com/content/pdf/10.1007/978-1-4757-2719-7_7.pdf){target=""_blank""}.
 
 ### Simulation Examples
 
@@ -683,7 +683,7 @@ Based on the $z$-test seen in the above summary, this interaction is significant
 
 You have probably noticed that the output from `summary()` is very similar to that of ordinary linear regression. One difference, is the ""deviance"" being reported. The `Null deviance` is the deviance for the null model, that is, a model with no predictors. The `Residual deviance` is the deviance for the mode that was fit.
 
-[**Deviance**](https://en.wikipedia.org/wiki/Deviance_(statistics)) compares the model to a saturated model. (Without repeated observations, a saturated model is a model that fits perfectly, using a parameter for each observation.) Essentially, deviance is a generalized *residual sum of squared* for GLMs. Like RSS, deviance decreased as the model complexity increases.
+[**Deviance**](https://en.wikipedia.org/wiki/Deviance_(statistics){target=""_blank""}) compares the model to a saturated model. (Without repeated observations, a saturated model is a model that fits perfectly, using a parameter for each observation.) Essentially, deviance is a generalized *residual sum of squared* for GLMs. Like RSS, deviance decreased as the model complexity increases.
 
 ```{r}
 deviance(chd_mod_ldl)
@@ -747,7 +747,7 @@ data(""spam"")
 tibble::as.tibble(spam)
 ```
 
-This dataset, created in the late 1990s at Hewlett-Packard Labs, contains 4601 emails, of which 1813 are considered spam. The remaining are not spam. (Which for simplicity, we might call, ham.) Additional details can be obtained by using `?spam` of by visiting the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/spambase). 
+This dataset, created in the late 1990s at Hewlett-Packard Labs, contains 4601 emails, of which 1813 are considered spam. The remaining are not spam. (Which for simplicity, we might call, ham.) Additional details can be obtained by using `?spam` of by visiting the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/spambase){target=""_blank""}. 
 
 The response variable, `type`, is a **factor** with levels that label each email as `spam` or `nonspam`. When fitting models, `nonspam` will be the reference level, $Y = 0$, as it comes first alphabetically.
 
@@ -910,7 +910,7 @@ This seems like a decent classifier...
 
 However, are all errors created equal? In this case, absolutely note. The 137 non-spam emails that were marked as spam (false positives) are a problem. We can't allow important information, say, a job offer, miss our inbox and get sent to the spam folder. On the other hand, the 161 spam email that would make it to an inbox (false negatives) are easily dealt with, just delete them.
 
-Instead of simply evaluating a classifier based on its misclassification rate (or accuracy), we'll define two additional metrics, sensitivity and specificity. Note that this are simply two of many more metrics that can be considered. The [Wikipedia page for sensitivity_and_specificity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity) details a large number of metrics that can be derived form a confusion matrix.
+Instead of simply evaluating a classifier based on its misclassification rate (or accuracy), we'll define two additional metrics, sensitivity and specificity. Note that this are simply two of many more metrics that can be considered. The [Wikipedia page for sensitivity_and_specificity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity){target=""_blank""} details a large number of metrics that can be derived form a confusion matrix.
 
 **Sensitivity** is essentially the true positive rate. So when sensitivity if high, the number of false negatives is low.
 
@@ -997,6 +997,6 @@ get_spec(conf_mat_90)
 
 While this is far fewer false positives, is it acceptable though? Still probably not. Also, don't forget, this would actually be a terrible spam detector today since this is based on data from a very different era of the internet, for a very specific set of people. Spam has changed a lot since 90s! (Ironically, machine learning is probably partially to blame.)
 
-This chapter has provided a rather quick introduction to classification, and thus, machine learning. For a more complete coverage of machine learning, [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/) is a highly recommended resource. Additionally, [`R` for Statistical Learning](https://daviddalpiaz.github.io/r4sl/) has been written as a supplement which provides additional detail on how to perform these methods using `R`. The [classification](https://daviddalpiaz.github.io/r4sl/classification-overview.html) and [logistic regression](https://daviddalpiaz.github.io/r4sl/logistic-regression.html) chapters might be useful.
+This chapter has provided a rather quick introduction to classification, and thus, machine learning. For a more complete coverage of machine learning, [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/){target=""_blank""} is a highly recommended resource. Additionally, [`R` for Statistical Learning](https://daviddalpiaz.github.io/r4sl/){target=""_blank""} has been written as a supplement which provides additional detail on how to perform these methods using `R`. The [classification](https://daviddalpiaz.github.io/r4sl/classification-overview.html){target=""_blank""} and [logistic regression](https://daviddalpiaz.github.io/r4sl/logistic-regression.html){target=""_blank""} chapters might be useful.
 
-We should note that the code to perform classification using logistic regression is presented in a way that illustrates the concepts to the reader. In practice, you may to prefer to use a more general machine learning pipeline such as [`caret`](http://topepo.github.io/caret/index.html) in `R`. This will streamline processes for creating predictions and generating evaluation metrics.
+We should note that the code to perform classification using logistic regression is presented in a way that illustrates the concepts to the reader. In practice, you may to prefer to use a more general machine learning pipeline such as [`caret`](http://topepo.github.io/caret/index.html){target=""_blank""} in `R`. This will streamline processes for creating predictions and generating evaluation metrics.

---FILE: mlr.Rmd---
@@ -51,7 +51,7 @@ write.csv(autompg, ""data/autompg.csv"")
 ```
 
 
-We will once again discuss a dataset with information about cars. [This dataset](http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data), which can be found at the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Auto+MPG) contains a response variable `mpg` which stores the city fuel efficiency of cars, as well as several predictor variables for the attributes of the vehicles. We load the data, and perform some basic tidying before moving on to analysis.
+We will once again discuss a dataset with information about cars. [This dataset](http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data){target=""_blank""}, which can be found at the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Auto+MPG){target=""_blank""} contains a response variable `mpg` which stores the city fuel efficiency of cars, as well as several predictor variables for the attributes of the vehicles. We load the data, and perform some basic tidying before moving on to analysis.
 
 For now we will focus on using two variables, `wt` and `year`, as predictor variables. That is, we would like to model the fuel efficiency (`mpg`) of a car as a function of its weight (`wt`) and model year (`year`). To do so, we will define the following linear model,
 

---FILE: model_building.Rmd---
@@ -235,7 +235,7 @@ autompg = subset(autompg, select = c(""mpg"", ""cyl"", ""disp"", ""hp"", ""wt"", ""acc"", ""y
 autompg$hp = as.numeric(autompg$hp)
 ```
 
-A word of caution when using a model to *explain* a relationship. There are two terms often used to describe a relationship between two variables: *causation* and *correlation*. [Correlation](https://xkcd.com/552/) is often also referred to as association.
+A word of caution when using a model to *explain* a relationship. There are two terms often used to describe a relationship between two variables: *causation* and *correlation*. [Correlation](https://xkcd.com/552/){target=""_blank""} is often also referred to as association.
 
 Just because two variables are correlated does not necessarily mean that one causes the other. For example, consider modeling `mpg` as only a function of `hp`.
 
@@ -247,7 +247,7 @@ Does an increase in horsepower cause a drop in fuel efficiency? Or, perhaps the
 
 The issue here is that we have **observational** data. With observational data, we can only detect *associations*. To speak with confidence about *causality*, we would need to run **experiments**. Often, this is decision is made for us, before we ever see data, so we can only modify our interpretation.
 
-This is a concept that you should encounter often in your statistics education. For some further reading, and some related fallacies, see: [Wikipedia: Correlation does not imply causation](https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation).
+This is a concept that you should encounter often in your statistics education. For some further reading, and some related fallacies, see: [Wikipedia: Correlation does not imply causation](https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation){target=""_blank""}.
 
 We'll discuss this further when we discuss experimental design and traditional ANOVA techniques. (All of which has recently been re-branded as A/B testing.)
 

---FILE: r-intro.Rmd---
@@ -4,9 +4,9 @@
 
 `R` is both a programming language and software environment for statistical computing, which is *free* and *open-source*. To get started, you will need to install two pieces of software:
 
-- [`R`, the actual programming language.](http://cran.r-project.org/)
+- [`R`, the actual programming language.](http://cran.r-project.org/){target=""_blank""}
     - Chose your operating system, and select the most recent version, `r paste0(version$major, ""."" ,version$minor)`.
-- [RStudio, an excellent IDE for working with `R`.](http://www.rstudio.com/)
+- [RStudio, an excellent IDE for working with `R`.](http://www.rstudio.com/){target=""_blank""}
     - Note, you must have `R` installed to use RStudio. RStudio is simply an interface used to interact with `R`.
 
 The popularity of `R` is on the rise, and everyday it becomes a better tool for statistical analysis. It even generated this book! (A skill you will learn in this course.) There are many good resources for learning `R`. 
@@ -22,12 +22,12 @@ RStudio has a large number of useful keyboard shortcuts. A list of these can be
 - On Windows: `Alt` + `Shift` + `K`
 - On Mac:  `Option` + `Shift` + `K`
 
-The RStudio team has developed [a number of ""cheatsheets""](https://www.rstudio.com/resources/cheatsheets/) for working with both `R` and RStudio. [This particular cheatseet for Base `R`](http://www.rstudio.com/wp-content/uploads/2016/05/base-r.pdf) will summarize many of the concepts in this document.
+The RStudio team has developed [a number of ""cheatsheets""](https://www.rstudio.com/resources/cheatsheets/){target=""_blank""} for working with both `R` and RStudio. [This particular cheatseet for Base `R`](http://www.rstudio.com/wp-content/uploads/2016/05/base-r.pdf){target=""_blank""} will summarize many of the concepts in this document.
 
 When programming, it is often a good practice to follow a style guide. (Where do spaces go? Tabs or spaces? Underscores or CamelCase when naming variables?) No style guide is ""correct"" but it helps to be aware of what others do. The more import thing is to be consistent within your own code.
 
-- [Hadley Wickham Style Guide](http://adv-r.had.co.nz/Style.html) from [Advanced `R`](http://adv-r.had.co.nz/)
-- [Google Style Guide](https://google.github.io/styleguide/Rguide.xml)
+- [Hadley Wickham Style Guide](http://adv-r.had.co.nz/Style.html){target=""_blank""} from [Advanced `R`](http://adv-r.had.co.nz/){target=""_blank""}
+- [Google Style Guide](https://google.github.io/styleguide/Rguide.xml){target=""_blank""}
 
 For this course, our main deviation from these two guides is the use of `=` in place of `<-`. (More on that later.)
 
@@ -89,7 +89,7 @@ In using `R` as a calculator, we have seen a number of functions: `sqrt()`, `exp
 ?lm
 ```
 
-Frequently one of the most difficult things to do when learning `R` is asking for help. First, you need to decide to ask for help, then you need to know *how* to ask for help. Your very first line of defense should be to Google your error message or a short description of your issue. (The ability to solve problems using this method is quickly becoming an extremely valuable skill.) If that fails, and it eventually will, you should ask for help. There are a number of things you should include when emailing an instructor, or posting to a help website such as [Stack Exchange](http://stats.stackexchange.com/).
+Frequently one of the most difficult things to do when learning `R` is asking for help. First, you need to decide to ask for help, then you need to know *how* to ask for help. Your very first line of defense should be to Google your error message or a short description of your issue. (The ability to solve problems using this method is quickly becoming an extremely valuable skill.) If that fails, and it eventually will, you should ask for help. There are a number of things you should include when emailing an instructor, or posting to a help website such as [Stack Exchange](http://stats.stackexchange.com/){target=""_blank""}.
 
 - Describe what you expect the code to do.
 - State the end goal you are trying to achieve. (Sometimes what you expect the code to do, is not what you want to actually do.)

---FILE: r-resources.Rmd---
@@ -4,50 +4,50 @@ So far, we have seen a lot of `R`, and a lot of `R` quickly. Again, the precedin
 
 ## Beginner Tutorials and References
 
-- [Try `R`](http://tryr.codeschool.com/) from Code School.
+- [Try `R`](http://tryr.codeschool.com/){target=""_blank""} from Code School.
     - An interactive introduction to the basics of `R`. Useful for getting up to speed on `R`'s syntax.
-- [Quick-R](http://www.statmethods.net/) by Robert Kabacoff.
+- [Quick-R](http://www.statmethods.net/){target=""_blank""} by Robert Kabacoff.
     - A good reference for `R` basics.
-- [`R` Tutorial](http://www.r-tutor.com/) by Chi Yau.
+- [`R` Tutorial](http://www.r-tutor.com/){target=""_blank""} by Chi Yau.
     - A combination reference and tutorial for `R` basics.
-- [`R` Programming for Data Science](https://bookdown.org/rdpeng/rprogdatascience/) by Roger Peng
+- [`R` Programming for Data Science](https://bookdown.org/rdpeng/rprogdatascience/){target=""_blank""} by Roger Peng
     - A great text for `R` programming beginners. Discusses `R` from the ground up, highlighting programming details we might not discuss.
 
 ## Intermediate References
 
-- [`R` for Data Science](http://r4ds.had.co.nz/) by Hadley Wickham and Garrett Grolemund.
-    - Similar to Advanced `R`, but focuses more on data analysis, while still introducing programming concepts. Especially useful for working in the [tidyverse](http://tidyverse.org/). 
-- [The Art of `R` Programming](https://www.nostarch.com/artofr.htm) by Norman Matloff.
-    - Gentle introduction to the programming side of `R`. (Whereas we will focus more on the data analysis side.) A [free electronic version](http://vufind.carli.illinois.edu/vf-uiu/Record/uiu_6955421) is available through the Illinois library.
+- [`R` for Data Science](http://r4ds.had.co.nz/){target=""_blank""} by Hadley Wickham and Garrett Grolemund.
+    - Similar to Advanced `R`, but focuses more on data analysis, while still introducing programming concepts. Especially useful for working in the [tidyverse](http://tidyverse.org/){target=""_blank""}. 
+- [The Art of `R` Programming](https://www.nostarch.com/artofr.htm){target=""_blank""} by Norman Matloff.
+    - Gentle introduction to the programming side of `R`. (Whereas we will focus more on the data analysis side.) A [free electronic version](http://vufind.carli.illinois.edu/vf-uiu/Record/uiu_6955421){target=""_blank""} is available through the Illinois library.
 
 ## Advanced References
 
-- [Advanced `R`](http://adv-r.had.co.nz/) by Hadley Wickham.
+- [Advanced `R`](http://adv-r.had.co.nz/){target=""_blank""} by Hadley Wickham.
     - From the author of several extremely popular `R` packages. Good follow-up to The Art of `R` Programming. (And more up-to-date material.)
-- [The `R` Inferno](http://www.burns-stat.com/documents/books/the-r-inferno/) by Patrick Burns.
+- [The `R` Inferno](http://www.burns-stat.com/documents/books/the-r-inferno/){target=""_blank""} by Patrick Burns.
     - Likens learning the tricks of `R` to descending through the levels of hell. Very advanced material, but may be important if `R` becomes a part of your everyday toolkit.
-- [Efficient `R` Programming](https://csgillespie.github.io/efficientR/) by Colin Gillespie and Robin Lovelace
+- [Efficient `R` Programming](https://csgillespie.github.io/efficientR/){target=""_blank""} by Colin Gillespie and Robin Lovelace
     - Discusses both efficient `R` programs, as well as programming in `R` efficiently.
 
 ## Quick Comparisons to Other Languages
 
 Those who are familiar with other languages may find the following ""cheatsheets"" helpful for transitioning to `R`.
 
-- [MATLAB, NumPy, Julia](http://hyperpolyglot.org/numerical-analysis2#polynomials)
-- [Stata](http://dss.princeton.edu/training/RStata.pdf)
+- [MATLAB, NumPy, Julia](http://hyperpolyglot.org/numerical-analysis2#polynomials){target=""_blank""}
+- [Stata](http://dss.princeton.edu/training/RStata.pdf){target=""_blank""}
 - [SAS]() - Look for a resource still! Suggestions welcome.
 
 ## RStudio and RMarkdown Videos
 
 The following video playlists were made as an introduction to `R`, RStudio, and RMarkdown for STAT 420 at UIUC. If you are currently using this text for a Coursera course, you can also find updated videos there. 
 
-- [`R` and RStudio](https://www.youtube.com/playlist?list=PLBgxzZMu3GpMjYhX7jLm5B9gEV7AOOJ5w)
-- [Data in `R`](https://www.youtube.com/playlist?list=PLBgxzZMu3GpPojVSoriMTWQCUno_3hjNi)
-- [RMarkdown](https://www.youtube.com/playlist?list=PLBgxzZMu3GpNgd07DwmS-2odHtMO6MWGH)
+- [`R` and RStudio](https://www.youtube.com/playlist?list=PLBgxzZMu3GpMjYhX7jLm5B9gEV7AOOJ5w){target=""_blank""}
+- [Data in `R`](https://www.youtube.com/playlist?list=PLBgxzZMu3GpPojVSoriMTWQCUno_3hjNi){target=""_blank""}
+- [RMarkdown](https://www.youtube.com/playlist?list=PLBgxzZMu3GpNgd07DwmS-2odHtMO6MWGH){target=""_blank""}
 
 Note that RStudio and RMarkdown are constantly receiving excellent support and updates, so these videos may already contain some outdated information.
 
-[RStudio](http://rmarkdown.rstudio.com/) provides their own [tutorial for RMarkdown](http://rmarkdown.rstudio.com/lesson-1.html). They also have an excellent [RStudio ""cheatsheets""](https://www.rstudio.com/wp-content/uploads/2016/01/rstudio-IDE-cheatsheet.pdf) which visually identifies many of the features available in the IDE.
+[RStudio](http://rmarkdown.rstudio.com/){target=""_blank""} provides their own [tutorial for RMarkdown](http://rmarkdown.rstudio.com/lesson-1.html){target=""_blank""}. They also have an excellent [RStudio ""cheatsheets""](https://www.rstudio.com/wp-content/uploads/2016/01/rstudio-IDE-cheatsheet.pdf){target=""_blank""} which visually identifies many of the features available in the IDE.
 
 ## RMarkdown Template
 

---FILE: selection.Rmd---
@@ -644,7 +644,7 @@ To find small and interpretable models, we would use selection criterion that *e
 
 #### Correlation and Causation
 
-A word of caution when using a model to *explain* a relationship. There are two terms often used to describe a relationship between two variables: *causation* and *correlation*. [Correlation](https://xkcd.com/552/) is often also referred to as association.
+A word of caution when using a model to *explain* a relationship. There are two terms often used to describe a relationship between two variables: *causation* and *correlation*. [Correlation](https://xkcd.com/552/){target=""_blank""} is often also referred to as association.
 
 Just because two variable are correlated does not necessarily mean that one causes the other. For example, considering modeling `mpg` as only a function of `hp`.
 
@@ -656,7 +656,7 @@ Does an increase in horsepower cause a drop in fuel efficiency? Or, perhaps the
 
 The issue here is that we have **observational** data. With observational data, we can only detect associations. To speak with confidence about causality, we would need to run **experiments**.
 
-This is a concept that you should encounter often in your statistics education. For some further reading, and some related fallacies, see: [Wikipedia: Correlation does not imply causation](https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation).
+This is a concept that you should encounter often in your statistics education. For some further reading, and some related fallacies, see: [Wikipedia: Correlation does not imply causation](https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation){target=""_blank""}.
 
 ### Prediction
 

---FILE: slr-inf.Rmd---
@@ -485,7 +485,7 @@ where $t_{\alpha/2, n - 2}$ is the critical value such that $P(t_{n-2} > t_{\alp
 
 ## Hypothesis Tests
 
-> ""We may speak of this hypothesis as the '[null hypothesis](https://xkcd.com/892/)', and it should be noted that the null hypothesis is never proved or established, but is possibly disproved, in the course of experimentation.""
+> ""We may speak of this hypothesis as the '[null hypothesis](https://xkcd.com/892/){target=""_blank""}', and it should be noted that the null hypothesis is never proved or established, but is possibly disproved, in the course of experimentation.""
 >
 > --- **Ronald Aylmer Fisher**
 

---FILE: slr.Rmd---
@@ -170,7 +170,7 @@ $$
 
 This is visually displayed in the image below. We see that for any value $x$, the expected value of $Y$ is $\beta_0 + \beta_1 x$. At each value of $x$, $Y$ has the same variance $\sigma^2$.
 
-![Simple Linear Regression Model [Introductory Statistics (Shafer and Zhang), UC David Stat Wiki](http://statwiki.ucdavis.edu/Textbook_Maps/General_Statistics/Map%3A_Introductory_Statistics_(Shafer_and_Zhang)/10%3A_Correlation_and_Regression/10.3_Modelling_Linear_Relationships_with_Randomness_Present)](images/model.jpg)
+![Simple Linear Regression Model [Introductory Statistics (Shafer and Zhang), UC David Stat Wiki](http://statwiki.ucdavis.edu/Textbook_Maps/General_Statistics/Map%3A_Introductory_Statistics_(Shafer_and_Zhang){target=""_blank""}/10%3A_Correlation_and_Regression/10.3_Modelling_Linear_Relationships_with_Randomness_Present)](images/model.jpg)
 
 Often, we directly talk about the assumptions that this model makes. They can be cleverly shortened to **LINE**.  
 
@@ -359,7 +359,7 @@ $$
 beta_0_hat + beta_1_hat * 21
 ```
 
-Lastly, we can make a prediction for the stopping distance of a car traveling at 50 miles per hour. This is considered [**extrapolation**](https://xkcd.com/605/) as 50 is not an observed value of $x$ and is outside data range. We should be less confident in predictions of this type.
+Lastly, we can make a prediction for the stopping distance of a car traveling at 50 miles per hour. This is considered [**extrapolation**](https://xkcd.com/605/){target=""_blank""} as 50 is not an observed value of $x$ and is outside data range. We should be less confident in predictions of this type.
 
 ```{r}
 range(cars$speed)
@@ -1003,7 +1003,7 @@ legend(""topright"", c(""Estimate"", ""Truth""), lty = c(1, 2), lwd = 2,
 
 ## History
 
-For some brief background on the history of linear regression, see [""Galton, Pearson, and the Peas: A Brief History of Linear Regression for Statistics Instructors""](http://www.amstat.org/publications/jse/v9n3/stanton.html) from the [Journal of Statistics Education](http://www.amstat.org/publications/jse/) as well as the [Wikipedia page on the history of regression analysis](https://en.wikipedia.org/wiki/Regression_analysis#History) and lastly the article for [regression to the mean](https://en.wikipedia.org/wiki/Regression_toward_the_mean) which details the origins of the term ""regression.""
+For some brief background on the history of linear regression, see [""Galton, Pearson, and the Peas: A Brief History of Linear Regression for Statistics Instructors""](http://www.amstat.org/publications/jse/v9n3/stanton.html){target=""_blank""} from the [Journal of Statistics Education](http://www.amstat.org/publications/jse/){target=""_blank""} as well as the [Wikipedia page on the history of regression analysis](https://en.wikipedia.org/wiki/Regression_analysis#History){target=""_blank""} and lastly the article for [regression to the mean](https://en.wikipedia.org/wiki/Regression_toward_the_mean){target=""_blank""} which details the origins of the term ""regression.""
 
 
 ## RMarkdown

---FILE: transformations.Rmd---
@@ -518,7 +518,7 @@ lines(xplot, predict(mark_mod_poly3, newdata = data.frame(advert = xplot)),
       col = ""red"", lty = 3, lwd = 3)
 ```
 
-The previous plot was made using base graphics in `R`. The next plot was made using the package [`ggplot2`](http://ggplot2.org/), an increasingly popular plotting method in `R`.
+The previous plot was made using base graphics in `R`. The next plot was made using the package [`ggplot2`](http://ggplot2.org/){target=""_blank""}, an increasingly popular plotting method in `R`.
 
 ```{r}
 library(ggplot2)"
daviddalpiaz,appliedstats,ab6fac78e0f101f6a091ebc3bc979b37e7846294,Ray Fix,rayfix@gmail.com,2018-05-23T13:45:12Z,Ray Fix,rayfix@gmail.com,2018-05-23T13:45:12Z,Fixes #43 Build leaving behind example-data.csv,data/example-data.csv;data/example_data.csv,False,False,False,False,11,11,22,"---FILE: data/example-data.csv---
@@ -0,0 +1,11 @@
+""x"",""y"",""z""
+1,""Hello"",TRUE
+3,""Hello"",FALSE
+5,""Hello"",TRUE
+7,""Hello"",FALSE
+9,""Hello"",TRUE
+1,""Hello"",FALSE
+3,""Hello"",TRUE
+5,""Hello"",FALSE
+7,""Hello"",TRUE
+9,""Goodbye"",FALSE

---FILE: data/example_data.csv---
@@ -1,11 +0,0 @@
-""x"",""y"",""z""
-1,""Hello"",""TRUE""
-3,""Hello"",""FALSE""
-5,""Hello"",""TRUE""
-7,""Hello"",""FALSE""
-9,""Hello"",""TRUE""
-1,""Hello"",""FALSE""
-3,""Hello"",""TRUE""
-5,""Hello"",""FALSE""
-7,""Hello"",""TRUE""
-9,""Hello"",""FALSE"""
daviddalpiaz,appliedstats,34d8d5f63ae7b353c333de188253823562ce74c3,"Brandon Ching, PhD",bdching@gmail.com,2018-05-22T17:26:53Z,GitHub,noreply@github.com,2018-05-22T17:26:53Z,"Typo fix ""must contains"" to ""must contain""",data-and-programming.Rmd,True,False,True,False,1,1,2,"---FILE: data-and-programming.Rmd---
@@ -51,7 +51,7 @@ The pros and cons of these two are well beyond the scope of this book, but know
 
 If you wish to use `<-`, you will still need to use `=`, however only for argument passing. Some users like to keep assignment (`<-`) and argument passing (`=`) separate. No matter what you choose, the more important thing is that you **stay consistent**. Also, if working on a larger collaborative project, you should use whatever style is already in place.
 
-Because vectors must contains elements that are all the same type, `R` will automatically coerce to a single type when attempting to create a vector that combines multiple types.
+Because vectors must contain elements that are all the same type, `R` will automatically coerce to a single type when attempting to create a vector that combines multiple types.
 
 ```{r}
 c(42, ""Statistics"", TRUE)"
daviddalpiaz,appliedstats,f1d766faa5c281becc2eae5c86d498b093d8e99e,daviddalpiaz,dalpiaz2@illinois.edu,2018-05-18T15:29:08Z,daviddalpiaz,dalpiaz2@illinois.edu,2018-05-18T15:29:08Z,fix pandoc issue?,DESCRIPTION;_output.yml,True,False,True,False,2,2,4,"---FILE: DESCRIPTION---
@@ -1,5 +1,5 @@
 Package: appliedstats
-Title: Applied Statistics
+Title: Applied Statistics with `R`
 Version: 0.0.1
 Authors@R: c(
   person(""David"", ""Dalpiaz"" , ""dalpiaz2@illinois.edu"", c(""aut"", ""cre""))

---FILE: _output.yml---
@@ -17,7 +17,7 @@ bookdown::pdf_book:
   dev: ""cairo_pdf""
   latex_engine: xelatex
   citation_package: natbib
-  pandoc_args: --chapters
+  pandoc_args: --top-level-division=chapter
   toc_depth: 3
   toc_unnumbered: no
   toc_appendix: yes"
daviddalpiaz,appliedstats,1c710aade3f9291ea91c14573ed8f985675235fc,Jeff Gerlach,13844570+jeffgerlach@users.noreply.github.com,2018-05-16T03:48:32Z,GitHub,noreply@github.com,2018-05-16T03:48:32Z,"Fix minor typo in chapter 5

could also be ""we need to calculate the area""",prob-and-stat.Rmd,True,False,True,False,1,1,2,"---FILE: prob-and-stat.Rmd---
@@ -137,7 +137,7 @@ t
 
 Under the null hypothesis, the test statistic has a $t$ distribution with $n - 1$ degrees of freedom, in this case `r n - 1`.
 
-To complete the test, we need to obtain the p-value of the test. Since this is a one-sided test with a less-than alternative, we need to area to the left of `r t` for a $t$ distribution with `r n - 1` degrees of freedom. That is,
+To complete the test, we need to obtain the p-value of the test. Since this is a one-sided test with a less-than alternative, we need the area to the left of `r t` for a $t$ distribution with `r n - 1` degrees of freedom. That is,
 
 \[
 P(t_{`r n - 1`} < `r t`)"
daviddalpiaz,appliedstats,180b7e4147042e8ff77e64bf4b3e405ead15de0d,Jeff Gerlach,13844570+jeffgerlach@users.noreply.github.com,2018-05-16T02:15:14Z,GitHub,noreply@github.com,2018-05-16T02:15:14Z,"Update data-summary.Rmd

one more small typo fix in chapter 4",data-summary.Rmd,True,False,True,False,1,1,2,"---FILE: data-summary.Rmd---
@@ -100,7 +100,7 @@ However, more often we will use boxplots to compare a numerical variable for dif
 boxplot(hwy ~ drv, data = mpg)
 ```
 
-Here used the `boxplot()` command to create side-by-side boxplots. However, since we are now dealing with two variables, the syntax has changed. The `R` syntax `hwy ~ drv, data = mpg` reads ""Plot the `hwy` variable against the `drv` variable using the dataset `mpg`."" We see the use of a `~` (which specifies a formula) and also a `data = ` argument. This will be a syntax that is common to many functions we will use in this course. 
+Here we used the `boxplot()` command to create side-by-side boxplots. However, since we are now dealing with two variables, the syntax has changed. The `R` syntax `hwy ~ drv, data = mpg` reads ""Plot the `hwy` variable against the `drv` variable using the dataset `mpg`."" We see the use of a `~` (which specifies a formula) and also a `data = ` argument. This will be a syntax that is common to many functions we will use in this course. 
 
 ```{r}
 boxplot(hwy ~ drv, data = mpg,"
daviddalpiaz,appliedstats,13ffbbec5e4f3ee60f7b9494b418948b8372c05f,Jeff Gerlach,13844570+jeffgerlach@users.noreply.github.com,2018-05-15T22:59:33Z,GitHub,noreply@github.com,2018-05-15T22:59:33Z,"Update data-and-programming.Rmd

Small typo fixes",data-and-programming.Rmd,True,False,True,False,2,2,4,"---FILE: data-and-programming.Rmd---
@@ -617,7 +617,7 @@ To look at the data, we have two useful commands: `head()` and `str()`.
 head(mpg, n = 10)
 ```
 
-The function `head()` will display the first `n` observations of the data frame. The `head()` function was more useful before tibbles. Notice that `mpg` is a tibble already, so the output from `head()` indicates there are only `10` observations. Note that this applies to `head(mpg, n = 10)` and not `mpg` itself. Also note that tibbles print a limited number of rows and columns by default. The last line of the printed output indicates with rows and columns were omitted.
+The function `head()` will display the first `n` observations of the data frame. The `head()` function was more useful before tibbles. Notice that `mpg` is a tibble already, so the output from `head()` indicates there are only `10` observations. Note that this applies to `head(mpg, n = 10)` and not `mpg` itself. Also note that tibbles print a limited number of rows and columns by default. The last line of the printed output indicates which rows and columns were omitted.
 
 ```{r}
 mpg
@@ -780,7 +780,7 @@ standardize = function(x) {
 }
 ```
 
-Here the name of the function is `standardize`, and the function has a single argument `x` which is used in the body of function. Note that the output of the final line of the body is what is returned by the function. In this case the function returns the vector stored in the variable `results`.
+Here the name of the function is `standardize`, and the function has a single argument `x` which is used in the body of function. Note that the output of the final line of the body is what is returned by the function. In this case the function returns the vector stored in the variable `result`.
 
 To test our function, we will take a random sample of size `n = 10` from a normal distribution with a mean of `2` and a standard deviation of `5`.
 "
daviddalpiaz,appliedstats,0c635c25bbe64c029ac18928022fea5fc2cf4d6c,Carson Zhang,cxzhang4@illinois.edu,2017-10-28T16:39:09Z,Carson Zhang,cxzhang4@illinois.edu,2017-10-28T16:39:09Z,changed 'significance of the regression test' to 'significance of regression test',mlr.Rmd,True,False,True,False,2,2,4,"---FILE: mlr.Rmd---
@@ -782,7 +782,7 @@ First, notice that `R` does not display the results in the same manner as the ta
 summary(mpg_model)
 ```
 
-Notice that the value reported in the row for `F-statistic` is indeed the $F$ test statistic for the significance of the regression test, and additionally it reports the two relevant degrees of freedom.
+Notice that the value reported in the row for `F-statistic` is indeed the $F$ test statistic for the significance of regression test, and additionally it reports the two relevant degrees of freedom.
 
 Also, note that none of the individual $t$-tests are equivalent to the $F$-test as they were in SLR. This equivalence only holds for SLR because the individual test for $\beta_1$ is the same as testing for all non-intercept parameters, since there is only one.
 
@@ -805,7 +805,7 @@ length(resid(null_mpg_model)) - length(coef(null_mpg_model))
 
 ## Nested Models
 
-The significance of the regression test is actually a special case of testing what we will call **nested models**. More generally we can compare two models, where one model is ""nested"" inside the other, meaning one model contains a subset of the predictors from only the larger model.
+The significance of regression test is actually a special case of testing what we will call **nested models**. More generally we can compare two models, where one model is ""nested"" inside the other, meaning one model contains a subset of the predictors from only the larger model.
 
 Consider the following full model,
 "
daviddalpiaz,appliedstats,2d7a34a4807981657df1a1ecd4ef6fe74f9dd1ea,Carson Zhang,cxzhang4@illinois.edu,2017-10-28T16:26:06Z,Carson Zhang,cxzhang4@illinois.edu,2017-10-28T16:26:06Z,Fixed 'asses' typo,diagnostics.Rmd,True,False,True,False,16,16,32,"---FILE: diagnostics.Rmd---
@@ -173,7 +173,7 @@ plot(fitted(fit_1), resid(fit_1), col = ""grey"", pch = 20,
 abline(h = 0, col = ""darkorange"", lwd = 2)
 ```
 
-We should look for two things in this plot. 
+We should look for two things in this plot.
 
 - At any fitted value, the mean of the residuals should be roughly 0. If this is the case, the *linearity* assumption is valid. For this reason, we generally add a horizontal line at $y = 0$ to emphasize this point.
 - At every fitted value, the spread of the residuals should be roughly the same. If this is the case, the *constant variance* assumption is valid.
@@ -393,7 +393,7 @@ Returning to our three regressions, recall,
 - `fit_2` violated the constant variance assumption, but not linearity,
 - `fit_3` violated linearity, but not constant variance.
 
-We'll now create a Q-Q plot for each to asses normality of errors.
+We'll now create a Q-Q plot for each to assess normality of errors.
 
 ```{r}
 qqnorm(resid(fit_1), main = ""Normal Q-Q Plot, fit_1"", col = ""darkgrey"")
@@ -455,32 +455,32 @@ The following three plots are inspired by an example from [Linear Models with R]
 ```{r unusual_obs_plot, fig.height = 5, fig.width = 15}
 par(mfrow = c(1, 3))
 set.seed(42)
-ex_data  = data.frame(x = 1:10, 
+ex_data  = data.frame(x = 1:10,
                       y = 10:1 + rnorm(n = 10))
 ex_model = lm(y ~ x, data = ex_data)
 
 # low leverage, large residual, small influence
 point_1 = c(5.4, 11)
 ex_data_1 = rbind(ex_data, point_1)
 model_1 = lm(y ~ x, data = ex_data_1)
-plot(y ~ x, data = ex_data_1, cex = 2, pch = 20, col = ""grey"", 
+plot(y ~ x, data = ex_data_1, cex = 2, pch = 20, col = ""grey"",
      main = ""Low Leverage, Large Residual, Small Influence"")
 points(x = point_1[1], y = point_1[2], pch = 1, cex = 4, col = ""black"", lwd = 2)
 abline(ex_model, col = ""dodgerblue"", lwd = 2)
 abline(model_1, lty = 2, col = ""darkorange"", lwd = 2)
-legend(""bottomleft"", c(""Original Data"", ""Added Point""), 
+legend(""bottomleft"", c(""Original Data"", ""Added Point""),
        lty = c(1, 2), col = c(""dodgerblue"", ""darkorange""))
 
 # high leverage, small residual, small influence
 point_2 = c(18, -5.7)
 ex_data_2 = rbind(ex_data, point_2)
 model_2 = lm(y ~ x, data = ex_data_2)
-plot(y ~ x, data = ex_data_2, cex = 2, pch = 20, col = ""grey"", 
+plot(y ~ x, data = ex_data_2, cex = 2, pch = 20, col = ""grey"",
      main = ""High Leverage, Small Residual, Small Influence"")
 points(x = point_2[1], y = point_2[2], pch = 1, cex = 4, col = ""black"", lwd = 2)
 abline(ex_model, col = ""dodgerblue"", lwd = 2)
 abline(model_2, lty = 2, col = ""darkorange"", lwd = 2)
-legend(""bottomleft"", c(""Original Data"", ""Added Point""), 
+legend(""bottomleft"", c(""Original Data"", ""Added Point""),
        lty = c(1, 2), col = c(""dodgerblue"", ""darkorange""))
 
 # high leverage, large residual, large influence
@@ -492,7 +492,7 @@ plot(y ~ x, data = ex_data_3, cex = 2, pch = 20, col = ""grey"", ylim = c(-3, 12),
 points(x = point_3[1], y = point_3[2], pch = 1, cex = 4, col = ""black"", lwd = 2)
 abline(ex_model, col = ""dodgerblue"", lwd = 2)
 abline(model_3, lty = 2, col = ""darkorange"", lwd = 2)
-legend(""bottomleft"", c(""Original Data"", ""Added Point""), 
+legend(""bottomleft"", c(""Original Data"", ""Added Point""),
        lty = c(1, 2), col = c(""dodgerblue"", ""darkorange""))
 ```
 
@@ -582,7 +582,7 @@ What is a value of $h_i$ that would be considered large? There is no exact answe
 h_i > 2 \bar{h}
 \]
 
-we say that observation $i$ has large leverage. Here, 
+we say that observation $i$ has large leverage. Here,
 
 \[
 \bar{h} = \frac{\sum_{i = 1}^n h_i}{n} = \frac{p}{n}.
@@ -768,9 +768,9 @@ A common measure of influence is **Cook's Distance**, which is defined as
   D_i = \frac{1}{p}r_i^2\frac{h_i}{1-{h_i}}.
 \]
 
-Notice that this is a function of both *leverage* and *standardized residuals*. 
+Notice that this is a function of both *leverage* and *standardized residuals*.
 
-A Cook's Distance is often considered large if 
+A Cook's Distance is often considered large if
 
 \[
 D_i > \frac{4}{n}
@@ -814,7 +814,7 @@ mpg_hp_add = lm(mpg ~ hp + am, data = mtcars)
 
 ```{r}
 plot(fitted(mpg_hp_add), resid(mpg_hp_add), col = ""grey"", pch = 20,
-     xlab = ""Fitted"", ylab = ""Residual"", 
+     xlab = ""Fitted"", ylab = ""Residual"",
      main = ""mtcars: Fitted versus Residuals"")
 abline(h = 0, col = ""darkorange"", lwd = 2)
 ```
@@ -866,8 +866,8 @@ coef(mpg_hp_add)
 Since the diagnostics looked good, there isn't much need to worry about these two points, but let's see how much the coefficients change if we remove them.
 
 ```{r}
-mpg_hp_add_fix = lm(mpg ~ hp + am, 
-                    data = mtcars, 
+mpg_hp_add_fix = lm(mpg ~ hp + am,
+                    data = mtcars,
                     subset = cd_mpg_hp_add <= 4 / length(cd_mpg_hp_add))
 coef(mpg_hp_add_fix)
 ```
@@ -939,8 +939,8 @@ sum(big_mod_cd > 4 / length(big_mod_cd))
 Here, we find `r sum(big_mod_cd > 4 / length(big_mod_cd))`, so perhaps removing them will help!
 
 ```{r}
-big_model_fix = lm(mpg ~ disp * hp * domestic, 
-                   data = autompg, 
+big_model_fix = lm(mpg ~ disp * hp * domestic,
+                   data = autompg,
                    subset = big_mod_cd < 4 / length(big_mod_cd))
 qqnorm(resid(big_model_fix), col = ""grey"")
 qqline(resid(big_model_fix), col = ""dodgerblue"", lwd = 2)"
daviddalpiaz,appliedstats,008107e20ab3c2184a5ece150eb14872827a17e1,daviddalpiaz,dalpiaz2@illinois.edu,2017-09-17T21:16:54Z,daviddalpiaz,dalpiaz2@illinois.edu,2017-09-17T21:16:54Z,fix tables?,logistic.Rmd,True,False,True,False,4,4,8,"---FILE: logistic.Rmd---
@@ -36,8 +36,8 @@ $$
 
 The following table summarizes three examples of a generalized linear model:
 
-|                                                 | Ordinary Linear Regression     | Poisson Regression                       | Logistic Regression                                                    |
-|-------------------------------------------------|--------------------------------|------------------------------------------|------------------------------------------------------------------------|
+|            | Ordinary Linear Regression | Poisson Regression | Logistic Regression |
+|------------|----------------------------|--------------------|---------------------|
 | **Distribution of ** $Y \mid {\bf X} = {\bf x}$ | $N(\mu({\bf x}), \sigma^2)$    | $\text{Pois}(\lambda({\bf x}))$          | $\text{Bern}(p({\bf x}))$                                              |
 | **Distribution Name**                           | Normal                         | Poisson                                  | Bernoulli (Binomial)                                                   |
 | $\text{E}[Y \mid {\bf X} = {\bf x}]$            | $\mu({\bf x})$                 | $\lambda({\bf x})$                       | $p({\bf x})$                                                           |
@@ -274,8 +274,8 @@ fit_glm = glm(y ~ x, data = example_data, family = binomial(link = ""logit""))
 
 Making predictions with an object of type  `glm` is slightly different than making predictions after fitting with `lm()`. In the case of logistic regression, with `family = binomial`, we have:
 
-| `type`             | Returned                                                                               |
-|--------------------|----------------------------------------------------------------------------------------|
+| `type`| Returned |
+|------ |----------|
 | `""link""` [default] | $\hat{\eta}({\bf x}) = \log\left(\frac{\hat{p}({\bf x})}{1 - \hat{p}({\bf x})}\right)$ |
 | `""response""`       | $\hat{p}({\bf x})$                                                                     |
 "
daviddalpiaz,appliedstats,e8a113553f66630f08aaaa868983aa2315800eb8,David Dalpiaz,dalpiaz2@illinois.edu,2017-06-23T21:32:40Z,David Dalpiaz,dalpiaz2@illinois.edu,2017-06-23T21:32:40Z,fixes,selection.Rmd,True,False,True,False,2,2,4,"---FILE: selection.Rmd---
@@ -283,7 +283,7 @@ which we quickly verify.
 extractAIC(hipcenter_mod) # returns both p and AIC
 n = length(resid(hipcenter_mod))
 (p = length(coef(hipcenter_mod)))
-n * log(mean(resid(hipcenter_mod) ^ 2)) + 2 * 9
+n * log(mean(resid(hipcenter_mod) ^ 2)) + 2 * p
 ```
 
 Returning to the first step, `R` then gives us a row which shows the effect of deleting each of the current predictors. The `-` signs at the beginning of each row indicates we are considering removing a predictor. There is also a row with `<none>` which is a row for keeping the current model. Notice that this row has the smallest $\text{RSS}$, as it is the largest model.
@@ -379,7 +379,7 @@ Here we perform stepwise search using $\text{AIC}$ as our metric. We start with
 ```{r}
 hipcenter_mod_both_aic = step(
   hipcenter_mod_start, 
-  scopre = hipcenter ~ Age + Weight + HtShoes + Ht + Seated + Arm + Thigh + Leg, 
+  scope = hipcenter ~ Age + Weight + HtShoes + Ht + Seated + Arm + Thigh + Leg, 
   direction = ""both"")
 ```
 "
daviddalpiaz,appliedstats,a1af897b73ad631d81e35dd272c91278d129c093,David Dalpiaz,dalpiaz2@illinois.edu,2017-05-24T19:46:40Z,David Dalpiaz,dalpiaz2@illinois.edu,2017-05-24T19:46:40Z,fix typo,cat_int.Rmd,True,False,True,False,1,1,2,"---FILE: cat_int.Rmd---
@@ -523,7 +523,7 @@ where
 
 - $Y$ is `mpg`, the fuel efficiency in miles per gallon,
 - $x_1$ is `disp`, the displacement in cubic inches,
-- $x_2$ **is a dummy variable create by `R`.** It uses `1` to represent a **foreign car**.
+- $x_2$ **is a dummy variable created by `R`.** It uses `1` to represent a **foreign car**.
 
 So now,
 "
daviddalpiaz,appliedstats,965b46efbfa3df75f429c212449c48fcdbc94f6b,David Dalpiaz,dalpiaz2@illinois.edu,2017-05-23T20:53:25Z,David Dalpiaz,dalpiaz2@illinois.edu,2017-05-23T20:53:25Z,more color word errors,cat_int.Rmd,True,False,True,False,1,1,2,"---FILE: cat_int.Rmd---
@@ -624,7 +624,7 @@ On this plot, we have
 - 6 Cylinder: grey dots, dashed grey line.
 - 8 Cylinder: blue dots, dotted blue line.
 
-The odd result here is that we're estimating that 8 cylinder cars have better fuel efficiency than 6 cylinder cars at **any** displacement! The dotted blue line is always above the dashed red line. That doesn't seem right. Maybe for very large displacement engines that could be true, but that seems wrong for medium to low displacement.
+The odd result here is that we're estimating that 8 cylinder cars have better fuel efficiency than 6 cylinder cars at **any** displacement! The dotted blue line is always above the dashed grey line. That doesn't seem right. Maybe for very large displacement engines that could be true, but that seems wrong for medium to low displacement.
 
 To attempt to fix this, we will try using an interaction model, that is, instead of simply three intercepts and one slope, we will allow for three slopes. Again, we'll let `R` take the wheel, (no pun intended) then figure out what model it has applied.
 "
daviddalpiaz,appliedstats,e71095551333d78f5b6c82056a1a91dadd55f146,David Dalpiaz,dalpiaz2@illinois.edu,2017-05-23T15:51:28Z,David Dalpiaz,dalpiaz2@illinois.edu,2017-05-23T15:51:28Z,fix old colors,cat_int.Rmd;devel/cat_int.Rmd;devel/cat_int.html,True,False,True,False,4,2002,2006,"---FILE: cat_int.Rmd---
@@ -620,11 +620,11 @@ legend(""topright"", c(""4 Cylinder"", ""6 Cylinder"", ""8 Cylinder""),
 
 On this plot, we have
 
-- 4 Cylinder: black dots, solid black line.
-- 6 Cylinder: red dots, dashed red line.
-- 8 Cylinder: green dots, dotted green line.
+- 4 Cylinder: orange dots, solid orange line.
+- 6 Cylinder: grey dots, dashed grey line.
+- 8 Cylinder: blue dots, dotted blue line.
 
-The odd result here is that we're estimating that 8 cylinder cars have better fuel efficiency than 6 cylinder cars at **any** displacement! The dotted green line is always above the dashed red line. That doesn't seem right. Maybe for very large displacement engines that could be true, but that seems wrong for medium to low displacement.
+The odd result here is that we're estimating that 8 cylinder cars have better fuel efficiency than 6 cylinder cars at **any** displacement! The dotted blue line is always above the dashed red line. That doesn't seem right. Maybe for very large displacement engines that could be true, but that seems wrong for medium to low displacement.
 
 To attempt to fix this, we will try using an interaction model, that is, instead of simply three intercepts and one slope, we will allow for three slopes. Again, we'll let `R` take the wheel, (no pun intended) then figure out what model it has applied.
 

---FILE: devel/cat_int.Rmd---
@@ -1,934 +0,0 @@
-# Categorical Predictors and Interactions
-
-> ""The greatest value of a picture is when it forces us to notice what we never expected to see.""
->
-> --- **John Tukey**
-
-After reading this chapter you will be able to:
-
-- Include and interpret categorical variables in a linear regression model by way of dummy variables.
-- Understand the implications of using a model with a categorical variable in two ways: levels serving as unique predictors versus levels serving as a comparison to a baseline.
-- Construct and interpret linear regression models with interaction terms.
-- Identify categorical variables in a data set and convert them into factor variables, if necessary, using R.
-
-So far in each of our analyses, we have only used numeric variables as predictors. We have also only used *additive models*, meaning the effect any predictor had on the response was not dependent on the other predictors. In this chapter, we will remove both of these restrictions. We will fit models with categorical predictors, and use models that allow predictors to *interact*. The mathematics of multiple regression will remain largely unchanging, however, we will pay close attention to interpretation, as well as some difference in `R` usage.
-
-## Dummy Variables
-
-For this chapter, we will briefly use the built in dataset `mtcars` before returning to our `autompg` dataset that we created in the last chapter. The `mtcars` dataset is somewhat smaller, so we'll quickly take a look at the entire dataset.
-
-```{r}
-mtcars
-```
-
-We will be interested in three of the variables: `mpg `, `hp`, and `am`.
-
-- `mpg`: fuel efficiency, in miles per gallon.
-- `hp`: horsepower, in foot-pounds per second.
-- `am`: transmission. Automatic or manual.
-
-As we often do, we will start by plotting the data. We are interested in `mpg` as the response variable, and `hp` as a predictor.
-
-```{r}
-plot(mpg ~ hp, data = mtcars, cex = 2)
-```
-
-Since we are also interested in the transmission type, we could also label the points accordingly.
-
-```{r}
-plot(mpg ~ hp, data = mtcars, col = am + 1, pch = am + 1, cex = 2)
-legend(""topright"", c(""Automatic"", ""Manual""), col = c(1, 2), pch = c(1, 2))
-```
-
-We used a common `R` ""trick"" when plotting this data. The `am` variable takes two possible values; `0` for automatic transmission, and `1` for manual transmissions. `R` can use numbers to represent colors, however the color for `0` is white. So we take the `am` vector and add `1` to it. Then observations with automatic transmissions are now represented by `1`, which is black in `R`, and manual transmission are represented by `2`, which is red in `R`. (Note, we are only adding `1` inside the call to `plot()`, we are not actually modifying the values stored in `am`.)
-
-We now fit the SLR model
-
-\[
-Y = \beta_0 + \beta_1 x_1 + \epsilon,
-\]
-
-where $Y$ is `mpg` and $x_1$ is `hp`. For notational brevity, we drop the index $i$ for observations.
-
-```{r}
-mpg_hp_slr = lm(mpg ~ hp, data = mtcars)
-```
-
-We then re-plot the data and add the fitted line to the plot.
-
-```{r}
-plot(mpg ~ hp, data = mtcars, col = am + 1, pch = am + 1, cex = 2)
-abline(mpg_hp_slr, lwd = 3, col = ""grey"")
-legend(""topright"", c(""Automatic"", ""Manual""), col = c(1, 2), pch = c(1, 2))
-```
-
-We should notice a pattern here. The red, manual observations largely fall above the line, while the black, automatic observations are mostly below the line. This means our model underestimates the fuel efficiency of manual transmissions, and overestimates the fuel efficiency of automatic transmissions. To correct for this, we will add a predictor to our model, namely, `am` as $x_2$.
-
-Our new model is
-
-\[
-Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \epsilon,
-\]
-
-where $x_1$ and $Y$ remain the same, but now
-
-\[
-x_2 =
-  \begin{cases}
-   1 & \text{manual transmission} \\
-   0       & \text{automatic transmission}
-  \end{cases}.
-\]
-
-In this case, we call $x_2$ a **dummy variable**. A dummy variable is somewhat unfortunately named, as it is in no way ""dumb"". In fact, it is actually somewhat clever. A dummy variable is a numerical variable that is used in a regression analysis to ""code"" for a binary categorical variable. Let's see how this works.
-
-First, note that `am` is already a dummy variable, since it uses the values `0` and `1` to represent automatic and manual transmissions. Often, a variable like `am` would store the character values `auto` and `man` and we would either have to convert these to `0` and `1`, or, as we will see later, `R` will take care of creating dummy variables for us.
-
-So, to fit the above model, we do so like any other multiple regression model we have seen before.
-
-```{r}
-mpg_hp_add = lm(mpg ~ hp + am, data = mtcars)
-```
-
-Briefly checking the output, we see that `R` has estimated the three $\beta$ parameters.
-
-```{r}
-mpg_hp_add
-```
-
-Since $x_2$ can only take values `0` and `1`, we can effectively write two different models, one for manual and one for automatic transmissions.
-
-For automatic transmissions, that is $x_2 = 0$, we have,
-
-\[
-Y = \beta_0 + \beta_1 x_1 + \epsilon.
-\]
-
-Then for manual transmissions, that is $x_2 = 1$, we have,
-
-\[
-Y = (\beta_0 + \beta_2) + \beta_1 x_1 + \epsilon.
-\]
-
-Notice that these models share the same slope, $\beta_1$, but have different intercepts, differing by $\beta_2$. So the change in `mpg` is the same for both models, but on average `mpg` differs by $\beta_2$ between the two transmission types.
-
-We'll now calculate the estimated slope and intercept of these two models so that we can add them to a plot. Note that:
-
-- $\hat{\beta}_0$ = `coef(mpg_hp_add)[1]` = `r coef(mpg_hp_add)[1]`
-- $\hat{\beta}_1$ = `coef(mpg_hp_add)[2]` = `r coef(mpg_hp_add)[2]`
-- $\hat{\beta}_2$ = `coef(mpg_hp_add)[3]` = `r coef(mpg_hp_add)[3]`
-
-We can then combine these to calculate the estimated slope and intercepts.
-
-```{r}
-int_auto = coef(mpg_hp_add)[1]
-int_manu = coef(mpg_hp_add)[1] + coef(mpg_hp_add)[3]
-
-slope_auto = coef(mpg_hp_add)[2]
-slope_manu = coef(mpg_hp_add)[2]
-```
-
-Re-plotting the data, we use these slopes and intercepts to add the ""two"" fitted models to the plot.
-
-```{r}
-plot(mpg ~ hp, data = mtcars, col = am + 1, pch = am + 1, cex = 2)
-abline(int_auto, slope_auto, col = 1, lty = 1, lwd = 2) # add line for auto
-abline(int_manu, slope_manu, col = 2, lty = 2, lwd = 2) # add line for manual
-legend(""topright"", c(""Automatic"", ""Manual""), col = c(1, 2), pch = c(1, 2))
-```
-
-We notice right away that the points are no longer systematically incorrect. The red, manual observations vary about the red line in no particular pattern without underestimating the observations as before. The black, automatic points vary about the black line, also without an obvious pattern.
-
-They say a picture is worth a thousand words, but as a statistician, sometimes a picture is worth an entire analysis. The above picture makes it plainly obvious that $\beta_2$ is significant, but let's verify mathematically. Essentially we would like to test:
-
-\[
-H_0: \beta_2 = 0 \quad \text{vs} \quad H_1: \beta_2 \neq 0.
-\]
-
-This is nothing new. Again, the math is the same as the multiple regression analyses we have seen before. We could perform either a $t$ or $F$ test here. The only difference is a slight change in interpretation. We could think of this as testing a model with a single line ($H_0$) against a model that allows two lines ($H_1$).
-
-To obtain the test statistic and p-value for the $t$-test, we would use
-
-```{r}
-summary(mpg_hp_add)$coefficients[""am"",]
-```
-
-To do the same for the $F$ test, we would use
-
-```{r}
-anova(mpg_hp_slr, mpg_hp_add)
-```
-
-Notice that these are indeed testing the same thing, as the p-values are exactly equal. (And the $F$ test statistic is the $t$ test statistic squared.)
-
-Recapping some interpretations:
-
-- $\hat{\beta}_0 = `r coef(mpg_hp_add)[1]`$ is the estimated average `mpg` for a car with an automatic transmission and **0** `hp`.
-- $\hat{\beta}_0 + \hat{\beta}_2 = `r coef(mpg_hp_add)[1] + coef(mpg_hp_add)[3]`$ is the estimated average `mpg` for a car with a manual transmission and **0** `hp`.
-
-- $\hat{\beta}_2 = `r coef(mpg_hp_add)[3]`$ is the estimated **difference** in average `mpg` for cars with manual transmissions as compared to those with automatic transmission, for **any** `hp`.
-- $\hat{\beta}_1 = `r coef(mpg_hp_add)[2]`$ is the estimated change in average `mpg` for an increase in one `hp`, for **either** transmission types.
-
-We should take special notice of those last two. In the model,
-
-\[
-Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \epsilon,
-\]
-
-we see $\beta_1$ is the average change in $Y$ for an increase in $x_1$, *no matter* the value of $x_2$. Also, $\beta_2$ is always the difference in the average of $Y$ for *any* value of $x_1$. These are two restrictions we won't always want, so we need a way to specify a more flexible model.
-
-Here we restricted ourselves to a single numerical predictor $x_1$ and one dummy variable $x_2$. However, the concept of a dummy variable can be used with larger multiple regression models. We only use a single numerical predictor here for ease of visualization since we can think of the ""two lines"" interpretation. But in general, we can think of a dummy variable as creating ""two models,"" one for each category of a binary categorical variable.
-
-## Interactions
-
-To remove the ""same slope"" restriction, we will now discuss **interaction**. To illustrate this concept, we will return to the `autompg` dataset we created in the last chapter, with a few more modifications.
-
-```{r}
-# read data frame from the web
-autompg = read.table(
-  ""http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data"",
-  quote = ""\"""",
-  comment.char = """",
-  stringsAsFactors = FALSE)
-# give the dataframe headers
-colnames(autompg) = c(""mpg"", ""cyl"", ""disp"", ""hp"", ""wt"", ""acc"", ""year"", ""origin"", ""name"")
-# remove missing data, which is stored as ""?""
-autompg = subset(autompg, autompg$hp != ""?"")
-# remove the plymouth reliant, as it causes some issues
-autompg = subset(autompg, autompg$name != ""plymouth reliant"")
-# give the dataset row names, based on the engine, year and name
-rownames(autompg) = paste(autompg$cyl, ""cylinder"", autompg$year, autompg$name)
-# remove the variable for name
-autompg = subset(autompg, select = c(""mpg"", ""cyl"", ""disp"", ""hp"", ""wt"", ""acc"", ""year"", ""origin""))
-# change horsepower from character to numeric
-autompg$hp = as.numeric(autompg$hp)
-# create a dummary variable for foreign vs domestic cars. domestic = 1.
-autompg$domestic = as.numeric(autompg$origin == 1)
-# remove 3 and 5 cylinder cars (which are very rare.)
-autompg = autompg[autompg$cyl != 5,]
-autompg = autompg[autompg$cyl != 3,]
-# the following line would verify the remaining cylinder possibilities are 4, 6, 8
-#unique(autompg$cyl)
-# change cyl to a factor variable
-autompg$cyl = as.factor(autompg$cyl)
-```
-
-```{r}
-str(autompg)
-```
-
-We've removed cars with `3` and `5` cylinders , as well as created a new variable `domestic` which indicates whether or not a car was built in the United States. Removing the `3` and `5` cylinders is simply for ease of demonstration later in the chapter and would not be done in practice. The new variable `domestic` takes the value `1` if the car was built in the United States, and `0` otherwise, which we will refer to as ""foreign."" (We are arbitrarily using the United States as the reference point here.) We have also made `cyl` and `origin` into factor variables, which we will discuss later.
-
-We'll now be concerned with three variables: `mpg`, `disp`, and `domestic`. We will use `mpg` as the response. We can fit a model,
-
-\[
-Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \epsilon,
-\]
-
-where 
-
-- $Y$ is `mpg`, the fuel efficiency in miles per gallon,
-- $x_1$ is `disp`, the displacement in cubic inches,
-- $x_2$ is `domestic` as described above, which is a dummy variable.
-
-We will fit this model, extract the slope and intercept for the ""two lines,"" plot the data and add the lines.
-
-```{r}
-mpg_disp_add = lm(mpg ~ disp + domestic, data = autompg)
-
-int_for = coef(mpg_disp_add)[1]
-int_dom = coef(mpg_disp_add)[1] + coef(mpg_disp_add)[3]
-
-slope_for = coef(mpg_disp_add)[2]
-slope_dom = coef(mpg_disp_add)[2]
-
-plot(mpg ~ disp, data = autompg, col = domestic + 1, pch = domestic + 1)
-abline(int_for, slope_for, col = 1, lty = 1, lwd = 2) # add line for foreign cars
-abline(int_dom, slope_dom, col = 2, lty = 2, lwd = 2) # add line for domestic cars
-legend(""topright"", c(""Foreign"", ""Domestic""), pch = c(1, 2), col = c(1, 2))
-```
-
-This is a model that allows for two *parallel* lines, meaning the `mpg` can be different on average between foreign and domestic cars of the same engine displacement, but the change in average `mpg` for an increase in displacement is the same for both. We can see this model isn't doing very well here. The red line fits the red points fairly well, but the black line isn't doing very well for the black points, it should clearly have a more negative slope. Essentially, we would like a model that allows for two different slopes.
-
-Consider the following model,
-
-\[
-Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2 + \epsilon,
-\]
-
-where $x_1$, $x_2$, and $Y$ are the same as before, but we have added a new **interaction** term $x_1 x_2$ which multiplies $x_1$ and $x_2$, so we also have an additional $\beta$ parameter $\beta_3$.
-
-This model essentially creates two slopes and two intercepts, $\beta_2$ being the difference in intercepts and $\beta_3$ being the difference in slopes. To see this, we will break down the model into the two ""sub-models"" for foreign and domestic cars.
-
-For foreign cars, that is $x_2 = 0$, we have
-
-\[
-Y = \beta_0 + \beta_1 x_1 + \epsilon.
-\]
-
-For domestic cars, that is $x_2 = 1$, we have
-
-\[
-Y = (\beta_0 + \beta_2) + (\beta_1 + \beta_3) x_1 + \epsilon.
-\]
-
-These two models have both different slopes and intercepts. 
-
-- $\beta_0$ is the average `mpg` for a foreign car with **0** `disp`.
-- $\beta_1$ is the change in average `mpg` for an increase of one `disp`, for **foreign** cars.
-- $\beta_0 + \beta_2$ is the average `mpg` for a domestic car with **0** `disp`.
-- $\beta_1 + \beta_3$ is the change in average `mpg` for an increase of one `disp`, for **domestic** cars.
-
-How do we fit this model in `R`? There are a number of ways.
-
-One method would be to simply create a new variable, then fit a model like any other.
-
-```{r, eval = FALSE}
-autompg$x3 = autompg$disp * autompg$domestic # THIS CODE NOT RUN!
-do_not_do_this = lm(mpg ~ disp + domestic + x3, data = autompg) # THIS CODE NOT RUN!
-```
-
-You should only do this as a last resort. We greatly prefer not to have to modify our data simply to fit a model. Instead, we can tell `R` we would like to use the existing data with an interaction term, which it will create automatically when we use the `:` operator.
-
-```{r}
-mpg_disp_int = lm(mpg ~ disp + domestic + disp:domestic, data = autompg)
-```
-
-An alternative method, which will fit the exact same model as above would be to use the `*` operator. This method automatically creates the interaction term, as well as any ""lower order terms,"" which in this case are the first order terms for `disp` and `domestic`
-
-```{r}
-mpg_disp_int2 = lm(mpg ~ disp * domestic, data = autompg)
-```
-
-We can quickly verify that these are doing the same thing.
-
-```{r}
-coef(mpg_disp_int)
-coef(mpg_disp_int2)
-```
-
-We see that both the variables, and their coefficient estimates are indeed the same for both models.
-
-```{r}
-summary(mpg_disp_int)
-```
-
-We see that using `summary()` gives the usual output for a multiple regression model. We pay close attention to the row for `disp:domestic` which tests,
-
-\[
-H_0: \beta_3 = 0.
-\]
-
-In this case, testing for $\beta_3 = 0$ is testing for two lines with parallel slopes versus two lines with possibly different slopes. The `disp:domestic` line in the `summary()` output uses a $t$-test to perform the test.
-
-We could also use an ANOVA $F$-test. The additive model, without interaction is our null model, and the interaction model is the alternative.
-
-```{r}
-anova(mpg_disp_add, mpg_disp_int)
-```
-
-Again we see this test has the same p-value as the $t$-test. Also the p-value is extremely low, so between the two, we choose the interaction model.
-
-```{r}
-int_for = coef(mpg_disp_int)[1]
-int_dom = coef(mpg_disp_int)[1] + coef(mpg_disp_int)[3]
-
-slope_for = coef(mpg_disp_int)[2]
-slope_dom = coef(mpg_disp_int)[2] + coef(mpg_disp_int)[4]
-```
-
-Here we again calculate the slope and intercepts for the two lines for use in plotting.
-
-```{r}
-plot(mpg ~ disp, data = autompg, col = domestic + 1, pch = domestic + 1)
-abline(int_for, slope_for, col = 1, lty = 1, lwd = 2) # line for foreign cars
-abline(int_dom, slope_dom, col = 2, lty = 2, lwd = 2) # line for domestic cars
-legend(""topright"", c(""Foreign"", ""Domestic""), pch = c(1, 2), col = c(1, 2))
-```
-
-We see that these lines fit the data much better, which matches the result of our tests.
-
-So far we have only seen interaction between a categorical variable (`domestic`) and a numerical variable (`disp`). While this is easy to visualize, since it allows for different slopes for two lines, it is not the only type of interaction we can use in a model. We can also consider interactions between two numerical variables.
-
-Consider the model,
-
-\[
-Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2 + \epsilon,
-\]
-
-where
-
-- $Y$ is `mpg`, the fuel efficiency in miles per gallon,
-- $x_1$ is `disp`, the displacement in cubic inches,
-- $x_2$ is `hp`, the horsepower, in foot-pounds per second.
-
-How does `mpg` change based on `disp` in this model? We can rearrange some terms to see how.
-
-\[
-Y = \beta_0 + (\beta_1 + \beta_3 x_2) x_1 + \beta_2 x_2 + \epsilon
-\]
-
-So, for a one unit increase in $x_1$ (`disp`), the mean of $Y$ (`mpg`) increases $\beta_1 + \beta_3 x_2$, which is a different value depending on the value of $x_2$ (`hp`)! 
-
-Since we're now working in three dimensions, this model can't be easily justified via visualizations like the previous example. Instead, we will have to rely on a test.
-
-```{r}
-mpg_disp_add_hp = lm(mpg ~ disp + hp, data = autompg)
-mpg_disp_int_hp = lm(mpg ~ disp * hp, data = autompg)
-summary(mpg_disp_int_hp)
-```
-
-Using `summary()` we focus on the row for `disp:hp` which tests,
-
-\[
-H_0: \beta_3 = 0.
-\]
-
-Again, we see a very low p-value so we reject the null (additive model) in favor of the interaction model. Again, there is an equivalent $F$-test.
-
-```{r}
-anova(mpg_disp_add_hp, mpg_disp_int_hp)
-```
-
-We can take a closer look at the coefficients of our fitted interaction model.
-
-```{r}
-coef(mpg_disp_int_hp)
-```
-
-- $\hat{\beta}_0 = `r coef(mpg_disp_int_hp)[1]`$ is the estimated average `mpg` for a car with 0 `disp` and 0 `hp`.
-- $\hat{\beta}_1 = `r coef(mpg_disp_int_hp)[2]`$ is the estimated change in average `mpg` for an increase in 1 `disp`, **for a car with 0 `hp`**.
-- $\hat{\beta}_2 = `r coef(mpg_disp_int_hp)[3]`$ is the estimated change in average `mpg` for an increase in 1 `hp`, **for a car with 0 `disp`**.
-- $\hat{\beta}_3 = `r coef(mpg_disp_int_hp)[4]`$ is an estimate of the modification to the change in average `mpg` for an increase in `disp`, for a car of a certain `hp` (or vice versa).
-
-That last coefficient needs further explanation. Recall the rearrangement we made earlier
-
-\[
-Y = \beta_0 + (\beta_1 + \beta_3 x_2) x_1 + \beta_2 x_2 + \epsilon.
-\]
-
-So, our estimate for $\beta_1 + \beta_3 x_2$, is $\hat{\beta}_1 + \hat{\beta}_3 x_2$, which in this case is
-
-\[
-`r coef(mpg_disp_int_hp)[2]` + `r coef(mpg_disp_int_hp)[4]` x_2.
-\]
-
-This says that, for an increase of one `disp` we see an estimated change in average `mpg` of $`r coef(mpg_disp_int_hp)[2]` + `r coef(mpg_disp_int_hp)[4]` x_2$. So how `disp` and `mpg` are related, depends on the `hp` of the car.
-
-So for a car with 50 `hp`, the estimated change in average `mpg` for an increase of one `disp` is
-
-\[
-`r coef(mpg_disp_int_hp)[2]` + `r coef(mpg_disp_int_hp)[4]` \cdot 50 = `r coef(mpg_disp_int_hp)[2] + coef(mpg_disp_int_hp)[4] * 50`
-\]
-
-And for a car with 350 `hp`, the estimated change in average `mpg` for an increase of one `disp` is
-
-\[
-`r coef(mpg_disp_int_hp)[2]` + `r coef(mpg_disp_int_hp)[4]` \cdot 350 = `r coef(mpg_disp_int_hp)[2] + coef(mpg_disp_int_hp)[4] * 350`
-\]
-
-Notice the sign changed!
-
-## Factor Variables
-
-So far in this chapter, we have limited our use of categorical variables to binary categorical variables. Specifically, we have limited ourselves to dummy variables which take a value of `0` or `1` and represent a categorical variable numerically.
-
-We will now discuss **factor** variables, which is a special way that `R` deals with categorical variables. With factor variables, a human user can simply think about the categories of a variable, and `R` will take care of the necessary dummy variables without any 0/1 assignment being done by the user.
-
-```{r}
-is.factor(autompg$domestic)
-```
-
-Earlier when we used the `domestic` variable, it was **not** a factor variable. It was simply a numerical variable that only took two possible values, `1` for domestic, and `0` for foreign. Let's create a new variable `origin` that stores the same information, but in a different way.
-
-```{r}
-autompg$origin[autompg$domestic == 1] = ""domestic""
-autompg$origin[autompg$domestic == 0] = ""foreign""
-head(autompg$origin)
-```
-
-Now the `origin` variable stores `""domestic""` for domestic cars and `""foreign""` for foreign cars.
-
-```{r}
-is.factor(autompg$origin)
-```
-
-However, this is simply a vector of character values. A vector of car models is a character variable in `R`. A vector of Vehicle Identification Numbers (VINs) is a character variable as well. But those don't represent a short list of levels that might influence a response variable. We will want to **coerce** this origin variable to be something more: a factor variable.
-
-```{r}
-autompg$origin = as.factor(autompg$origin)
-```
-
-Now when we check the structure of the `autompg` dataset, we see that `origin` is a factor variable.
-
-```{r}
-str(autompg)
-```
-
-Factor variables have **levels** which are the possible values (categories) that the variable may take, in this case foreign or domestic.
-
-```{r}
-levels(autompg$origin)
-```
-
-Recall that previously we have fit the model
-
-\[
-Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2 + \epsilon,
-\]
-
-where 
-
-- $Y$ is `mpg`, the fuel efficiency in miles per gallon,
-- $x_1$ is `disp`, the displacement in cubic inches,
-- $x_2$ is `domestic` a dummy variable where `1` indicates a domestic car.
-
-```{r}
-(mod_dummy = lm(mpg ~ disp * domestic, data = autompg))
-```
-
-So here we see that
-
-\[
-\hat{\beta}_0 + \hat{\beta}_2 = `r coef(mod_dummy)[1]` + `r coef(mod_dummy)[3]` = `r coef(mod_dummy)[1] + coef(mod_dummy)[3]`
-\]
-
-is the estimated average `mpg` for a **domestic** car with 0 `disp`.
-
-Now let's try to do the same, but using our new factor variable.
-
-```{r}
-(mod_factor = lm(mpg ~ disp * origin, data = autompg))
-```
-
-It seems that it doesn't produce the same results. Right away we notice that the intercept is different, as is the the coefficient in front of `disp`. We also notice that the remaining two coefficients are of the same magnitude as their respective counterparts using the domestic variable, but with a different sign. Why is this happening?
-
-It turns out, that by using a factor variable, `R` is automatically creating a dummy variable for us. However, it is not the dummy variable that we had originally used ourselves.
-
-`R` is fitting the model
-
-\[
-Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2 + \epsilon,
-\]
-
-where 
-
-- $Y$ is `mpg`, the fuel efficiency in miles per gallon,
-- $x_1$ is `disp`, the displacement in cubic inches,
-- $x_2$ **is a dummy variable create by `R`.** It uses `1` to represent a **foreign car**.
-
-So now,
-
-\[
-\hat{\beta}_0 = `r coef(mod_factor)[1]`
-\]
-
-is the estimated average `mpg` for a **domestic** car with 0 `disp`, which is indeed the same as before.
-
-When `R` created $x_2$, the dummy variable, it used domestic cars as the **reference** level, that is the default value of the factor variable. So when the dummy variable is `0`, the model represents this reference level, which is domestic. (`R` makes this choice because domestic comes before foreign alphabetically.)
-
-So the two models have different estimated coefficients, but due to the different model representations, they are actually the same model.
-
-### Factors with More Than Two Levels
-
-Let's now consider a factor variable with more than two levels. In this dataset, `cyl` is an example.
-
-```{r}
-is.factor(autompg$cyl)
-levels(autompg$cyl)
-```
-
-Here the `cyl` variable has three possible levels: `4`, `6`, and `8`. You may wonder, why not simply use `cyl` as a numerical variable? You certainly could. 
-
-However, that would force the difference in average `mpg` between `4` and `6` cylinders to be the same as the difference in average mpg between `6` and `8` cylinders. That usually make senses for a continuous variable, but not for a discrete variable with so few possible values. In the case of this variable, there is no such thing as a 7-cylinder engine or a 6.23-cylinder engine in personal vehicles. For these reasons, we will simply consider `cyl` to be categorical. This is a decision that will commonly need to be made with ordinal variables. Often, with a large number of categories, the decision to treat them as numerical variables is appropriate because a large number of dummy variables are then needed to represent these variables.
-
-Let's define three dummy variables related to the `cyl` factor variable.
-
-\[
-v_1 =
-  \begin{cases}
-   1 & \text{4 cylinder} \\
-   0       & \text{not 4 cylinder}
-  \end{cases}
-\]
-
-\[
-v_2 =
-  \begin{cases}
-   1 & \text{6 cylinder} \\
-   0       & \text{not 6 cylinder}
-  \end{cases}
-\]
-
-\[
-v_3 =
-  \begin{cases}
-   1 & \text{8 cylinder} \\
-   0       & \text{not 8 cylinder}
-  \end{cases}
-\]
-
-Now, let's fit an additive model in `R`, using `mpg` as the response, and `disp` and `cyl` as predictors. This should be a model that uses ""three regression lines"" to model `mpg`, one for each of the possible `cyl` levels. They will all have the same slope (since it is an additive model), but each will have its own intercept.
-
-```{r}
-(mpg_disp_add_cyl = lm(mpg ~ disp + cyl, data = autompg))
-```
-
-The question is, what is the model that `R` has fit here? It has chosen to use the model
-
-\[
-Y = \beta_0 + \beta_1 x + \beta_2 v_2 + \beta_3 v_3 + \epsilon,
-\]
-
-where
-
-- $Y$ is `mpg`, the fuel efficiency in miles per gallon,
-- $x$ is `disp`, the displacement in cubic inches,
-- $v_2$ and $v_3$ are the dummy variables define above.
-
-Why doesn't `R` use $v_1$? Essentially because it doesn't need to. To create three lines, it only needs two dummy variables since it is using a reference level, which in this case is a 4 cylinder car. The three ""sub models"" are then:
-
-- 4 Cylinder: $Y = \beta_0 + \beta_1 x + \epsilon$
-- 6 Cylinder: $Y = (\beta_0 + \beta_2) + \beta_1 x + \epsilon$
-- 8 Cylinder: $Y = (\beta_0 + \beta_3) + \beta_1 x + \epsilon$
-
-Notice that they all have the same slope. However, using the two dummy variables, we achieve the three intercepts.
-
-- $\beta_0$ is the average `mpg` for a 4 cylinder car with 0 `disp`.
-- $\beta_0 + \beta_2$ is the average `mpg` for a 6 cylinder car with 0 `disp`.
-- $\beta_0 + \beta_3$ is the average `mpg` for a 8 cylinder car with 0 `disp`.
-
-So because 4 cylinder is the reference level, $\beta_0$ is specific to 4 cylinders, but $\beta_2$ and $\beta_3$ are used to represent quantities relative to 4 cylinders.
-
-As we have done before, we can extract these intercepts and slopes for the three lines, and plot them accordingly.
-
-```{r}
-int_4cyl = coef(mpg_disp_add_cyl)[1]
-int_6cyl = coef(mpg_disp_add_cyl)[1] + coef(mpg_disp_add_cyl)[3]
-int_8cyl = coef(mpg_disp_add_cyl)[1] + coef(mpg_disp_add_cyl)[4]
-
-slope_all_cyl = coef(mpg_disp_add_cyl)[2]
-
-plot_colors = c(""Darkorange"", ""Darkgrey"", ""Dodgerblue"")
-plot(mpg ~ disp, data = autompg, col = plot_colors[cyl], pch = as.numeric(cyl))
-abline(int_4cyl, slope_all_cyl, col = plot_colors[1], lty = 1, lwd = 2)
-abline(int_6cyl, slope_all_cyl, col = plot_colors[2], lty = 2, lwd = 2)
-abline(int_8cyl, slope_all_cyl, col = plot_colors[3], lty = 3, lwd = 2)
-legend(""topright"", c(""4 Cylinder"", ""6 Cylinder"", ""8 Cylinder""),
-       col = plot_colors, lty = c(1, 2, 3), pch = c(1, 2, 3))
-```
-
-On this plot, we have
-
-- 4 Cylinder: black dots, solid black line.
-- 6 Cylinder: red dots, dashed red line.
-- 8 Cylinder: green dots, dotted green line.
-
-The odd result here is that we're estimating that 8 cylinder cars have better fuel efficiency than 6 cylinder cars at **any** displacement! The dotted green line is always above the dashed red line. That doesn't seem right. Maybe for very large displacement engines that could be true, but that seems wrong for medium to low displacement.
-
-To attempt to fix this, we will try using an interaction model, that is, instead of simply three intercepts and one slope, we will allow for three slopes. Again, we'll let `R` take the wheel, (no pun intended) then figure out what model it has applied.
-
-```{r}
-(mpg_disp_int_cyl = lm(mpg ~ disp * cyl, data = autompg))
-# could also use mpg ~ disp + cyl + disp:cyl
-```
-
-`R` has again chosen to use 4 cylinder cars as the reference level, but this also now has an effect on the interaction terms. `R` has fit the model.
-
-\[
-Y = \beta_0 + \beta_1 x + \beta_2 v_2 + \beta_3 v_3 + \gamma_2 x v_2 + \gamma_3 x v_3 + \epsilon
-\]
-
-We're using $\gamma$ like a $\beta$ parameter for simplicity, so that, for example $\beta_2$ and $\gamma_2$ are both associated with $v_2$.
-
-Now, the three ""sub models"" are:
-
-- 4 Cylinder: $Y = \beta_0 + \beta_1 x + \epsilon$.
-- 6 Cylinder: $Y = (\beta_0 + \beta_2) + (\beta_1 + \gamma_2) x + \epsilon$.
-- 8 Cylinder: $Y = (\beta_0 + \beta_3) + (\beta_1 + \gamma_3) x + \epsilon$.
-
-Interpreting some parameters and coefficients then:
-
-- $(\beta_0 + \beta_2)$ is the average `mpg` of a 6 cylinder car with 0 `disp`
-- $(\hat{\beta}_1 + \hat{\gamma}_3) = `r coef(mpg_disp_int_cyl)[2]` + `r coef(mpg_disp_int_cyl)[6]` = `r coef(mpg_disp_int_cyl)[2] + coef(mpg_disp_int_cyl)[6]`$ is the estimated change in average `mpg` for an increase of one `disp`, for an 8 cylinder car.
-
-So, as we have seen before $\beta_2$ and $\beta_3$ change the intercepts for 6 and 8 cylinder cars relative to the reference level of $\beta_0$ for 4 cylinder cars.
-
-Now, similarly $\gamma_2$ and $\gamma_3$ change the slopes for 6 and 8 cylinder cars relative to the reference level of $\beta_1$ for 4 cylinder cars.
-
-Once again, we extract the coefficients and plot the results.
-
-```{r}
-int_4cyl = coef(mpg_disp_int_cyl)[1]
-int_6cyl = coef(mpg_disp_int_cyl)[1] + coef(mpg_disp_int_cyl)[3]
-int_8cyl = coef(mpg_disp_int_cyl)[1] + coef(mpg_disp_int_cyl)[4]
-
-slope_4cyl = coef(mpg_disp_int_cyl)[2]
-slope_6cyl = coef(mpg_disp_int_cyl)[2] + coef(mpg_disp_int_cyl)[5]
-slope_8cyl = coef(mpg_disp_int_cyl)[2] + coef(mpg_disp_int_cyl)[6]
-
-plot_colors = c(""Darkorange"", ""Darkgrey"", ""Dodgerblue"")
-plot(mpg ~ disp, data = autompg, col = plot_colors[cyl], pch = as.numeric(cyl))
-abline(int_4cyl, slope_4cyl, col = plot_colors[1], lty = 1, lwd = 2)
-abline(int_6cyl, slope_6cyl, col = plot_colors[2], lty = 2, lwd = 2)
-abline(int_8cyl, slope_8cyl, col = plot_colors[3], lty = 3, lwd = 2)
-legend(""topright"", c(""4 Cylinder"", ""6 Cylinder"", ""8 Cylinder""),
-       col = plot_colors, lty = c(1, 2, 3), pch = c(1, 2, 3))
-```
-
-This looks much better! We can see that for medium displacement cars, 6 cylinder cars now perform better than 8 cylinder cars, which seems much more reasonable than before.
-
-To completely justify the interaction model (i.e., a unique slope for each `cyl` level) compared to the additive model (single slope), we can perform an $F$-test. Notice first, that there is no $t$-test that will be able to do this since the difference between the two models is not a single parameter.
-
-We will test,
-
-\[
-H_0: \gamma_2 = \gamma_3 = 0
-\]
-
-which represents the parallel regression lines we saw before,
-
-\[
-Y = \beta_0 + \beta_1 x + \beta_2 v_2 + \beta_3 v_3 + \epsilon.
-\]
-
-Again, this is a difference of two parameters, thus no $t$-test will be useful.
-
-```{r}
-anova(mpg_disp_add_cyl, mpg_disp_int_cyl)
-```
-
-As expected, we see a very low p-value, and thus reject the null. We prefer the interaction model over the additive model.
-
-Recapping a bit:
-
-- Null Model: $Y = \beta_0 + \beta_1 x + \beta_2 v_2 + \beta_3 v_3 + \epsilon$
-    - Number of parameters: $q = 4$
-- Full Model: $Y = \beta_0 + \beta_1 x + \beta_2 v_2 + \beta_3 v_3 + \gamma_2 x v_2 + \gamma_3 x v_3 + \epsilon$
-    - Number of parameters: $p = 6$
-    
-    
-```{r}
-length(coef(mpg_disp_int_cyl)) - length(coef(mpg_disp_add_cyl))
-```
-
-We see there is a difference of two parameters, which is also displayed in the resulting ANOVA table from `R`. Notice that the following two values also appear on the ANOVA table.
-
-```{r}
-nrow(autompg) - length(coef(mpg_disp_int_cyl))
-nrow(autompg) - length(coef(mpg_disp_add_cyl))
-```
-
-## Parameterization
-
-So far we have been simply letting `R` decide how to create the dummy variables, and thus `R` has been deciding the parameterization of the models. To illustrate the ability to use alternative parameterizations, we will recreate the data, but directly creating the dummy variables ourselves.
-
-```{r}
-new_param_data = data.frame(
-  y = autompg$mpg,
-  x = autompg$disp,
-  v1 = 1 * as.numeric(autompg$cyl == 4),
-  v2 = 1 * as.numeric(autompg$cyl == 6),
-  v3 = 1 * as.numeric(autompg$cyl == 8))
-
-head(new_param_data, 20)
-```
-
-Now,
-
-- `y` is `mpg`
-- `x` is `disp`, the displacement in cubic inches,
-- `v1`, `v2`, and `v3` are dummy variables as defined above.
-
-First let's try to fit an additive model using `x` as well as the three dummy variables.
-
-```{r}
-lm(y ~ x + v1 + v2 + v3, data = new_param_data)
-```
-
-What is happening here? Notice that `R` is essentially ignoring `v3`, but why? Well, because `R` uses an intercept, it cannot also use `v3`. This is because
-
-\[
-\boldsymbol{1} = v_1 + v_2 + v_3
-\]
-
-which means that $\boldsymbol{1}$, $v_1$, $v_2$, and $v_3$ are linearly dependent. This would make the $X^\top X$ matrix singular, but we need to be able to invert it to solve the normal equations and obtain $\hat{\beta}.$ With the intercept, `v1`, and `v2`, `R` can make the necessary ""three intercepts"". So, in this case `v3` is the reference level.
-
-If we remove the intercept, then we can directly obtain all ""three intercepts"" without a reference level.
-
-```{r}
-lm(y ~ 0 + x + v1 + v2 + v3, data = new_param_data)
-```
-
-Here, we are fitting the model
-
-\[
-Y = \mu_1 v_1 + \mu_2 v_2 + \mu_3 v_3 + \beta x +\epsilon.
-\]
-
-Thus we have:
-
-- 4 Cylinder: $Y = \mu_1 + \beta x + \epsilon$
-- 6 Cylinder: $Y = \mu_2 + \beta x + \epsilon$
-- 8 Cylinder: $Y = \mu_3 + \beta x + \epsilon$
-
-We could also do something similar with the interaction model, and give each line an intercept and slope, without the need for a reference level.
-
-```{r}
-lm(y ~ 0 + v1 + v2 + v3 + x:v1 + x:v2 + x:v3, data = new_param_data)
-```
-
-\[
-Y = \mu_1 v_1 + \mu_2 v_2 + \mu_3 v_3 + \beta_1 x v_1 + \beta_2 x v_2 + \beta_3 x v_3 +\epsilon
-\]
-
-- 4 Cylinder: $Y = \mu_1 + \beta_1 x + \epsilon$
-- 6 Cylinder: $Y = \mu_2 + \beta_2 x + \epsilon$
-- 8 Cylinder: $Y = \mu_3 + \beta_3 x + \epsilon$
-
-Using the original data, we have (at least) three equivalent ways to specify the interaction model with `R`.
-
-```{r}
-lm(mpg ~ disp * cyl, data = autompg)
-lm(mpg ~ 0 + cyl + disp : cyl, data = autompg)
-lm(mpg ~ 0 + disp + cyl + disp : cyl, data = autompg)
-```
-
-They all fit the same model, importantly each using six parameters, but the coefficients mean slightly different things in each. However, once they are interpreted as slopes and intercepts for the ""three lines"" they will have the same result.
-
-Use `?all.equal` to learn about the `all.equal()` function, and think about how the following code verifies that the residuals of the two models are the same.
-
-```{r}
-all.equal(fitted(lm(mpg ~ disp * cyl, data = autompg)), 
-          fitted(lm(mpg ~ 0 + cyl + disp : cyl, data = autompg)))
-```
-
-## Building Larger Models
-
-Now that we have seen how to incorporate categorical predictors as well as interaction terms, we can start to build much larger, much more flexible models which can potentially fit data better.
-
-Let's define a ""big"" model,
-
-\[
-Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_1 x_2 + \beta_5 x_1 x_3 + \beta_6 x_2 x_3 + \beta_7 x_1 x_2 x_3 + \epsilon.
-\]
-
-Here,
-
-- $Y$ is `mpg`.
-- $x_1$ is `disp`.
-- $x_2$ is `hp`.
-- $x_3$ is `domestic`, which is a dummy variable we defined, where `1` is a domestic vehicle.
-
-First thing to note here, we have included a new term $x_1 x_2 x_3$ which is a three-way interaction. Interaction terms can be larger and larger, up to the number of predictors in the model. 
-
-Since we are using the three-way interaction term, we also use all possible two-way interactions, as well as each of the first order (**main effect**) terms. This is the concept of a **hierarchy**. Any time a ""higher-order"" term is in a model, the related ""lower-order"" terms should also be included. Mathematically their inclusion or exclusion is sometimes irrelevant, but from an interpretation standpoint, it is best to follow the hierarchy rules.
-
-Let's do some rearrangement to obtain a ""coefficient"" in front of $x_1$.
-
-\[
-Y = \beta_0 + \beta_2 x_2 + \beta_3 x_3 + \beta_6 x_2 x_3 + (\beta_1 + \beta_4 x_2 + \beta_5 x_3 + \beta_7 x_2 x_3)x_1 + \epsilon.
-\]
-
-Specifically, the ""coefficient"" in front of $x_1$ is
-
-\[
-(\beta_1 + \beta_4 x_2 + \beta_5 x_3 + \beta_7 x_2 x_3).
-\]
-
-Let's discuss this ""coefficient"" to help us understand the idea of the *flexibility* of a model. Recall that,
-
-- $\beta_1$ is the coefficient for a first order term,
-- $\beta_4$ and $\beta_5$ are coefficients for two-way interactions,
-- $\beta_7$ is the coefficient for the three-way interaction.
-
-If the two and three way interactions were not in the model, the whole ""coefficient"" would simply be 
-
-\[
-\beta_1. 
-\]
-
-Thus, no matter the values of $x_2$ and $x_3$, $\beta_1$ would determine the relationship between $x_1$ (`disp`) and $Y$ (`mpg`).
-
-With the addition of the two-way interactions, now the ""coefficient"" would be
-
-\[
-(\beta_1 + \beta_4 x_2 + \beta_5 x_3).
-\]
-
-Now, changing $x_1$ (`disp`) has a different effect on $Y$ (`mpg`), depending on the values of $x_2$ and $x_3$.
-
-Lastly, adding the three-way interaction gives the whole ""coefficient""
-
-\[
-(\beta_1 + \beta_4 x_2 + \beta_5 x_3 + \beta_7 x_2 x_3)
-\]
-
-which is even more flexible. Now changing $x_1$ (`disp`) has a different effect on $Y$ (`mpg`), depending on the values of $x_2$ and $x_3$, but in a more flexible way which we can see with some more rearrangement. Now the ""coefficient"" in front of $x_3$ in this ""coefficient"" is dependent on $x_2$. 
-
-\[
-(\beta_1 + \beta_4 x_2 + (\beta_5 + \beta_7 x_2) x_3)
-\]
-
-It is so flexible, it is becoming hard to interpret!
-
-Let's fit this three-way interaction model in `R`.
-
-```{r}
-big_model = lm(mpg ~ disp * hp * domestic, data = autompg)
-summary(big_model)
-```
-
-Do we actually need this large of a model? Let's first test for the necessity of the three-way interaction term. That is,
-
-\[
-H_0: \beta_7 = 0.
-\]
-
-So,
-
-- Full Model: $Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_1 x_2 + \beta_5 x_1 x_3 + \beta_6 x_2 x_3 + \beta_7 x_1 x_2 x_3 + \epsilon$
-- Null Model: $Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_1 x_2 + \beta_5 x_1 x_3 + \beta_6 x_2 x_3 + \epsilon$
-
-We fit the null model in `R` as `two_way_int_mod`, then use `anova()` to perform an $F$-test as usual.
-
-```{r}
-two_way_int_mod = lm(mpg ~ disp * hp + disp * domestic + hp * domestic, data = autompg)
-#two_way_int_mod = lm(mpg ~ (disp + hp + domestic) ^ 2, data = autompg)
-anova(two_way_int_mod, big_model)
-```
-
-We see the p-value is somewhat large, so we would fail to reject. We prefer the smaller, less flexible, null model, without the three-way interaction.
-
-A quick note here: the full model does still ""fit better."" Notice that it has a smaller RMSE than the null model, which means the full model makes smaller (squared) errors on average.
-
-```{r}
-mean(resid(big_model) ^ 2)
-mean(resid(two_way_int_mod) ^ 2)
-```
-
-However, it is not much smaller. We could even say that, the difference is insignificant. This is an idea we will return to later in greater detail.
-
-Now that we have chosen the model without the three-way interaction, can we go further? Do we need the two-way interactions? Let's test
-
-\[
-H_0: \beta_4 = \beta_5 = \beta_6 = 0.
-\]
-
-Remember we already chose $\beta_7 = 0$, so,
-
-- Full Model: $Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_1 x_2 + \beta_5 x_1 x_3 + \beta_6 x_2 x_3 + \epsilon$
-- Null Model: $Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \epsilon$
-
-We fit the null model in `R` as `additive_mod`, then use `anova()` to perform an $F$-test as usual.
-
-```{r}
-additive_mod = lm(mpg ~ disp + hp + domestic, data = autompg)
-anova(additive_mod, two_way_int_mod)
-```
-
-Here the p-value is small, so we reject the null, and we prefer the full (alternative) model. Of the models we have considered, our final preference is for
-
-\[
-Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_1 x_2 + \beta_5 x_1 x_3 + \beta_6 x_2 x_3 + \epsilon.
-\]"
daviddalpiaz,appliedstats,49b828640f39afede5910c5382b9ef5d0be7b72e,David Dalpiaz,dalpiaz2@illinois.edu,2017-05-12T17:08:07Z,David Dalpiaz,dalpiaz2@illinois.edu,2017-05-12T17:08:07Z,fixing some TODOs,data-and-programming.Rmd;data-summary.Rmd,True,False,True,False,27,40,67,"---FILE: data-and-programming.Rmd---
@@ -51,7 +51,7 @@ The pros and cons of these two are well beyond the scope of this book, but know
 
 If you wish to use `<-`, you will still need to use `=`, however only for argument passing. Some users like to keep assignment (`<-`) and argument passing (`=`) separate. No matter what you choose, the more important thing is that you **stay consistent**. Also, if working on a larger collaborative project, you should use whatever style is already in place.
 
-- TODO: coercion
+Because vectors must contains elements that are all the same type, `R` will automatically coerce to a single type when attempting to create a vector that combines multiple types.
 
 ```{r}
 c(42, ""Statistics"", TRUE)
@@ -64,8 +64,6 @@ Frequently you may wish to create a vector based on a sequence of numbers. The q
 (y = 1:100)
 ```
 
-- TODO: style note
-
 Here we see `R` labeling the rows after the first since this is a large vector. Also, we see that by putting parentheses around the assignment, `R` both stores the vector in a variable called `y` and automatically outputs `y` to the console.
 
 Note that scalars do not exists in `R`. They are simply vectors of length `1`.
@@ -184,9 +182,6 @@ We see that when a function like `log()` is called on a vector `x`, a vector is
 | `x | y`  | `x` or `y`                       | `(3 > 42) | TRUE`      | `r (3 > 42) | TRUE`      |
 | `x & y`  | `x` and `y`                      | `(3 < 4) & ( 42 > 13)` | `r (3 < 4) & ( 42 > 13)` |
 
-
-- TODO: add narrative, split chunks
-
 In `R`, logical operators are vectorized. 
 
 ```{r}
@@ -219,6 +214,7 @@ sum(x > 3)
 as.numeric(x > 3)
 ```
 
+Here we see that using the `sum()` function on a vector of logical `TRUE` and `FALSE` values that is the result of `x > 3` results in a numeric result. `R` is first automatically coercing the logical to numeric where `TRUE` is `1` and `FALSE` is `0`. This coercion from logical to numeric happens for most mathematical operations.
 
 ```{r}
 which(x > 3)
@@ -325,8 +321,6 @@ X[2, c(1, 3)]
 
 Matrices can also be created by combining vectors as columns, using `cbind`, or combining vectors as rows, using `rbind`.
 
-- TODO: some subsetting returns vectors.
-
 ```{r}
 x = 1:9
 rev(x)
@@ -341,7 +335,7 @@ rbind(x, rev(x), rep(1, 9))
 cbind(col_1 = x, col_2 = rev(x), col_3 = rep(1, 9))
 ```
 
-- TODO: named columns
+When using `rbind` and `cbind` you can specify ""argument"" names that will be used as column names.
 
 `R` can then be used to perform matrix calculations.
 
@@ -374,7 +368,7 @@ Z
 solve(Z)
 ```
 
-- TODO: explain
+To verify that `solve(Z)` returns the inverse, we multiply it by `Z`. We would expect this to return the identity matrix, however we see that this is not the case due to some computational issues. However, `R` also has the `all.equal()` function which checks for equality, with some small tolerance which accounts for some computational issues. The `identical()` function is used to check for exact equality.
 
 ```{r}
 solve(Z) %*% Z
@@ -505,7 +499,7 @@ all.equal(crossprod(C_mat, C_mat), t(C_mat) %*% C_mat)
 
 ### Lists
 
-- TODO: explain list stuff below:
+A list is a one-dimensional heterogeneous data structure. So it is indexed like a vector with a single integer value, but each element can contain an element of any type.
 
 ```{r}
 # creation
@@ -520,6 +514,11 @@ ex_list = list(
 )
 ```
 
+Lists can be subset using two syntaxes, the `$` operator, and square brackets `[]`. The `$` operator returns a named **element** of a list. The `[]` syntax returns a **list**, while the `[[]]` returns an **element** of a list.
+
+- `ex_list[1]` returns a list contain the first element.
+- `ex_list[[1]]` returns the first element of the list, in this case, a vector.
+
 ```{r}
 # subsetting
 ex_list$e
@@ -535,7 +534,6 @@ ex_list$d
 ex_list$d(arg = 1)
 ```
 
-
 ### Data Frames
 
 We have previously seen vectors and matrices for storing data as we introduced `R`. We will now introduce a **data frame** which will be the most common way that we store and interact with data in this course.
@@ -552,7 +550,7 @@ Unlike a matrix, which can be thought of as a vector rearranged into rows and co
 example_data
 ```
 
-- TODO: explain below
+Unlike a list which has more flexibility, the elements of a data frame must all be vectors, and have the same length.
 
 ```{r}
 example_data$x
@@ -566,7 +564,6 @@ str(example_data)
 nrow(example_data)
 ncol(example_data)
 dim(example_data)
-
 ```
 
 The `data.frame()` function above is one way to create a data frame. We can also import data from various file types in into `R`, as well as use data stored in packages.
@@ -686,9 +683,7 @@ mpg %>% filter(hwy > 35) %>% select(manufacturer, model, year)
 
 All three approaches produce the same results. Which you use will be largely based on a given situation as well as user preference.
 
-- TODO: general data.frame subsetting
-
-- TODO: difference between data.frame (more like matrix) and tibble (more like list) subsetting
+When subsetting a data frame, be aware of what is being returned, as sometimes it may be a vector instead of a data frame. Also note that there are differences between subsetting a data frame and a tibble. A data frame operates more like a matrix where it is possible to reduce the subset to a vector. A tibble operates more like a list where it always subsets to another tibble.
 
 ## Programming Basics
 

---FILE: data-summary.Rmd---
@@ -2,41 +2,35 @@
 
 ## Summary Statistics
 
-`R` has built in functions for a large number of summary statistics.
-
-```{r}
-(y = 1:100)
-```
-
-TODO: change to mpg$cty, discuss what the results mean
+`R` has built in functions for a large number of summary statistics. For numeric variables, we can summarize data with the center and spread.
 
 ### Central Tendency {-}
 
 | Measure | `R`         | Result        |
 |---------|-------------|---------------|
-| Mean    | `mean(y)`   | `r mean(y)`   |
-| Median  | `median(y)` | `r median(y)` |
+| Mean    | `mean(mpg$cty)`   | `r mean(mpg$cty)`   |
+| Median  | `median(mpg$cty)` | `r median(mpg$cty)` |
 
 ### Spread {-}
 
-| Measure            | `R`        | Result       |
-|--------------------|------------|--------------|
-| Variance           | `var(y)`   | `r var(y)`   |
-| Standard Deviation | `sd(y)`    | `r sd(y)`    |
-| IQR                | `IQR(y)`   | `r IQR(y)`   |
-| Minimum            | `min(y)`   | `r min(y)`   |
-| Maximum            | `max(y)`   | `r max(y)`   |
-| Range              | `range(y)` | `r range(y)` |
+| Measure            | `R`              | Result             |
+|--------------------|------------------|--------------------|
+| Variance           | `var(mpg$cty)`   | `r var(mpg$cty)`   |
+| Standard Deviation | `sd(mpg$cty)`    | `r sd(mpg$cty)`    |
+| IQR                | `IQR(mpg$cty)`   | `r IQR(mpg$cty)`   |
+| Minimum            | `min(mpg$cty)`   | `r min(mpg$cty)`   |
+| Maximum            | `max(mpg$cty)`   | `r max(mpg$cty)`   |
+| Range              | `range(mpg$cty)` | `r range(mpg$cty)` |
 
-- TODO: categorical summary
+### Categorical {-}
+
+For categorical variables, counts and percentages can be used for summary.
 
 ```{r}
 table(mpg$drv)
 table(mpg$drv) / nrow(mpg)
 ```
 
-TODO: discuss relationships found in the data, look at the data.
-
 ## Plotting
 
 Now that we have some data to work with, and we have learned about the data at the most basic level, our next tasks is to visualize the data. Often, a proper visualization can illuminate features of the data that can inform further analysis.
@@ -48,8 +42,6 @@ We will look at four methods of visualizing data that we will use throughout the
 - Boxplots
 - Scatterplots
 
-TODO: discuss relationships found in the data
-
 ### Histograms
 
 When visualizing a single numerical variable, a **histogram** will be our go-to tool, which can be created in `R` using the `hist()` function.
@@ -73,7 +65,7 @@ Importantly, you should always be sure to label your axes and give the plot a ti
 
 ### Barplots
 
-TODO: narrative
+Somewhat similar to a histogram, a barplot can provide a visual summary of a categorical variable, or a numeric variable with a finite number of values, like a ranking from 1 to 10.
 
 ```{r}
 barplot(table(mpg$drv))"
daviddalpiaz,appliedstats,23051f270a89bf5daf855915ffd4060fd011b112,David Dalpiaz,dalpiaz2@illinois.edu,2017-04-22T15:30:33Z,David Dalpiaz,dalpiaz2@illinois.edu,2017-04-22T15:30:33Z,fix typos,mlr.Rmd,True,False,True,False,2,3,5,"---FILE: mlr.Rmd---
@@ -655,14 +655,13 @@ Here we use $\hat{y}(x_0)$ to estimate $Y_0$, a new observation of $Y$ at the pr
 \[
 \begin{aligned}
 \hat{y}(x_0) &= x_{0}^\top\hat{\beta} \\
-&= \hat{\beta}_0 + \hat{\beta}_1 x_{01} + \hat{\beta}_2 x_{02} + \cdots + \hat{\beta}_{p-1}
+&= \hat{\beta}_0 + \hat{\beta}_1 x_{01} + \hat{\beta}_2 x_{02} + \cdots + \hat{\beta}_{p-1} x_{0(p-1)}
 \end{aligned}
 \]
 
 \[
 \begin{aligned}
-\text{E}[\hat{y}(x_0)] &= Y_0 \\
-&= x_{0}^\top\beta \\
+\text{E}[\hat{y}(x_0)] &= x_{0}^\top\beta \\
 &= \beta_0 + \beta_1 x_{01} + \beta_2 x_{02} + \cdots + \beta_{p-1} x_{0(p-1)}
 \end{aligned}
 \]"
daviddalpiaz,appliedstats,7fdbdf74fb34deeae92726ffb38c7c4e796d767c,David Dalpiaz,dalpiaz2@illinois.edu,2017-04-19T14:35:14Z,David Dalpiaz,dalpiaz2@illinois.edu,2017-04-19T14:35:14Z,fix missing color issue,plots.Rmd,True,False,True,False,23,27,50,"---FILE: plots.Rmd---
@@ -169,6 +169,15 @@ y.pred = matrix(predict(fit, newdata = x1x2),
 # fitted points for droplines to surface
 fitpoints = predict(fit)
 
+library(""plot3D"")
+
+
+
+
+minlim = min(fitpoints, y.pred, y) - 0.1
+maxlim = max(fitpoints, y.pred, y) + 0.1
+
+bothlim = c(minlim, maxlim)
 ```
 
 
@@ -177,56 +186,43 @@ fitpoints = predict(fit)
 ```{r, fig.height = 15, fig.width = 15}
 par(mfrow = c(1, 3))
 
-scatter3D(x1, x2, y, pch = 20, cex = 2, col = gg.col(1000), lighting = TRUE, colkey = FALSE, pch = 20,
-          xlim = c(0, 10), 
-          ylim = c(0, 10),
-          theta = 0, phi = 45, ticktype = ""detailed"", zlim = c(min(y.pred), max(y.pred)), clim = c(min(y.pred), max(y.pred)),
+scatter3D(x1, x2, y, pch = 20, cex = 2, col = gg.col(1000), colkey = FALSE, pch = 20,
+          theta = 0, phi = 45, zlim = c(min(y.pred), max(y.pred)), clim = bothlim,
           xlab = ""x1"", ylab = ""x2"", zlab = ""y"",
           # surf = list(x = x1.pred, y = x2.pred, z = y.pred, facets = NA, fit = fitpoints), 
           main = """")
 
-scatter3D(x1, x2, y, pch = 20, cex = 2, col = gg.col(1000), lighting = TRUE, colkey = FALSE,
-          xlim = c(0, 10), 
-          ylim = c(0, 10),
-          theta = 45, phi = 15, ticktype = ""detailed"", zlim = c(min(y.pred), max(y.pred)), clim = c(min(y.pred), max(y.pred)),
+scatter3D(x1, x2, y, pch = 20, cex = 2, col = gg.col(1000), colkey = FALSE,
+          theta = 45, phi = 15, zlim = c(min(y.pred), max(y.pred)), clim = bothlim,
           xlab = ""x1"", ylab = ""x2"", zlab = ""y"",
           # surf = list(x = x1.pred, y = x2.pred, z = y.pred, facets = NA, fit = fitpoints), 
           main = """")
 
-scatter3D(x1, x2, y, pch = 20, cex = 2, col = gg.col(1000), lighting = TRUE, colkey = FALSE,
-          xlim = c(0, 10), 
-          ylim = c(0, 10),
-          theta = 90, phi = 0, ticktype = ""detailed"", zlim = c(min(y.pred), max(y.pred)), clim = c(min(y.pred), max(y.pred)),
+scatter3D(x1, x2, y, pch = 20, cex = 2, col = gg.col(1000), colkey = FALSE,
+          theta = 90, phi = 0, zlim = c(min(y.pred), max(y.pred)), clim = bothlim,
           xlab = ""x1"", ylab = ""x2"", zlab = ""y"",
           # surf = list(x = x1.pred, y = x2.pred, z = y.pred, facets = NA, fit = fitpoints), 
           main = """")
-
 ```
 
 
 ```{r, fig.height = 15, fig.width = 15}
 par(mfrow = c(1, 3))
 
-scatter3D(x1, x2, y, pch = 20, cex = 2, col = gg.col(1000), lighting = TRUE, colkey = FALSE, pch = 20,
-                    xlim = c(0, 10), 
-          ylim = c(0, 10),
-          theta = 0, phi = 45, ticktype = ""detailed"", zlim = c(min(y.pred), max(y.pred)), clim = c(min(y.pred), max(y.pred)),
+scatter3D(x1, x2, y, pch = 20, cex = 2, col = gg.col(1000), colkey = FALSE, pch = 20,
+          theta = 0, phi = 45, zlim = c(min(y.pred), max(y.pred)), clim = bothlim,
           xlab = ""x1"", ylab = ""x2"", zlab = ""y"",
           surf = list(x = x1.pred, y = x2.pred, z = y.pred, facets = NA, fit = fitpoints),
           main = """")
 
-scatter3D(x1, x2, y, pch = 20, cex = 2, col = gg.col(1000), lighting = TRUE, colkey = FALSE,
-                    xlim = c(0, 10), 
-          ylim = c(0, 10),
-          theta = 45, phi = 15, ticktype = ""detailed"", zlim = c(min(y.pred), max(y.pred)), clim = c(min(y.pred), max(y.pred)),
+scatter3D(x1, x2, y, pch = 20, cex = 2, col = gg.col(1000), colkey = FALSE,
+          theta = 45, phi = 15, zlim = c(min(y.pred), max(y.pred)), clim = bothlim,
           xlab = ""x1"", ylab = ""x2"", zlab = ""y"",
           surf = list(x = x1.pred, y = x2.pred, z = y.pred, facets = NA, fit = fitpoints),
           main = """")
 
-scatter3D(x1, x2, y, pch = 20, cex = 2, col = gg.col(1000), lighting = TRUE, colkey = FALSE,
-                    xlim = c(0, 10), 
-          ylim = c(0, 10),
-          theta = 90, phi = 0, ticktype = ""detailed"", zlim = c(min(y.pred), max(y.pred)), clim = c(min(y.pred), max(y.pred)),
+scatter3D(x1, x2, y, pch = 20, cex = 2, col = gg.col(1000), colkey = FALSE,
+          theta = 90, phi = 0, zlim = c(min(y.pred), max(y.pred)), clim = bothlim,
           xlab = ""x1"", ylab = ""x2"", zlab = ""y"",
           surf = list(x = x1.pred, y = x2.pred, z = y.pred, facets = NA, fit = fitpoints),
           main = """")
@@ -235,9 +231,9 @@ scatter3D(x1, x2, y, pch = 20, cex = 2, col = gg.col(1000), lighting = TRUE, col
 
 
 
-```{r, fig.height = 20, fig.width = 20}
+```{r, fig.height = 10, fig.width = 10}
 scatter3D(x1, x2, y, pch = 20, cex = 2, col = gg.col(1000), lighting = TRUE, colkey = FALSE,
-          theta = 90, phi = -15, ticktype = ""detailed"", zlim = c(min(y.pred), max(y.pred)), clim = c(min(y.pred), max(y.pred)),
+          theta = 95, phi = -10, zlim = c(min(y.pred), max(y.pred)), clim = bothlim,
           xlab = ""x1"", ylab = ""x2"", zlab = ""y"",
           surf = list(x = x1.pred, y = x2.pred, z = y.pred, facets = NA, fit = fitpoints),
           main = """")"
daviddalpiaz,appliedstats,60c696c0c8e619ee0e2ece1024e294fc9a1ed336,David Dalpiaz,dalpiaz2@illinois.edu,2017-04-04T18:25:38Z,David Dalpiaz,dalpiaz2@illinois.edu,2017-04-04T18:25:38Z,fix formula,slr-inf.Rmd,True,False,True,False,1,1,2,"---FILE: slr-inf.Rmd---
@@ -426,7 +426,7 @@ Then we use the classic trick of ""multiply by 1"" and some rearranging to arrive
 &= \frac{\hat{\beta}_1 - \beta_1}{s_e / \sqrt{S_{xx}}} \cdot \frac{\sigma / \sqrt{S_{xx}}}{\sigma / \sqrt{S_{xx}}} \\
 &= \frac{\hat{\beta}_1 - \beta_1}{\sigma / \sqrt{S_{xx}}} \cdot \frac{\sigma / \sqrt{S_{xx}}}{s_e / \sqrt{S_{xx}}} \\
 &= \frac{\hat{\beta}_1 - \beta_1}{\sigma / \sqrt{S_{xx}}} \bigg/ \sqrt{\frac{s_e^2}{\sigma^2}} \\
-&= \frac{\hat{\beta}_1 - \beta_1}{\text{SD}[\hat{\beta}_1]} \bigg/ \sqrt{\frac{\frac{(n - s)s_e^2}{\sigma^2}}{n - 2}}
+&= \frac{\hat{\beta}_1 - \beta_1}{\text{SD}[\hat{\beta}_1]} \bigg/ \sqrt{\frac{\frac{(n - 2)s_e^2}{\sigma^2}}{n - 2}}
 \sim \frac{Z}{\sqrt{\frac{\chi_{n-2}^2}{n-2}}}
 \sim t_{n-2}
 \end{aligned}"
daviddalpiaz,appliedstats,91981b583a324c67cc33e396c6c195aa19058dd6,David Dalpiaz,dalpiaz2@illinois.edu,2017-03-20T20:59:59Z,David Dalpiaz,dalpiaz2@illinois.edu,2017-03-20T20:59:59Z,add image and fix notation,images/model2.jpg;slr.Rmd,True,False,True,False,1,1,2,"---FILE: slr.Rmd---
@@ -790,7 +790,7 @@ $$
 Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
 $$
 
-where $e_i \sim N(0, \sigma^2)$.
+where $\epsilon_i \sim N(0, \sigma^2)$.
 
 Then we can find the mean and variance of each $Y_i$.
 "
daviddalpiaz,appliedstats,a406aba9455db84b6f507915c1c2ccb51a4f84ce,David Dalpiaz,dalpiaz2@illinois.edu,2017-02-08T17:05:11Z,David Dalpiaz,dalpiaz2@illinois.edu,2017-02-08T17:05:11Z,typo fix,slr.Rmd,True,False,True,False,1,1,2,"---FILE: slr.Rmd---
@@ -666,7 +666,7 @@ The ""thing"" that is returned by the `lm()` function is actually an object of cla
 names(stop_dist_model)
 ```
 
-When can then use this information to, for example, access the residuals using the `$` operator.
+We can then use this information to, for example, access the residuals using the `$` operator.
 
 ```{r}
 stop_dist_model$residuals"
daviddalpiaz,appliedstats,2185ec6e9a7e0fd1e8af98743769cb402640c26b,daviddalpiaz,dalpiaz2@illinois.edu,2016-12-01T03:52:11Z,daviddalpiaz,dalpiaz2@illinois.edu,2016-12-01T03:52:11Z,typo and wording fix,beyond.Rmd,True,False,True,False,1,1,2,"---FILE: beyond.Rmd---
@@ -77,4 +77,4 @@ Often `R` will be called a ""slow"" language, for two reasons. One, because many d
 
 Also, don't forget that previously in this book we have outlined a large number of [`R` resources](http://daviddalpiaz.github.io/appliedstats/introduction-to-r.html#r-resources). Now that you've gotten started with `R` many of these will be much more useful.
 
-If any of these topics interest you, and you would like more information, to hesitate to start a discussion on the fourms!
+If any of these topics interest you, and you would like more information, please don't hesitate to start a discussion on the forums!"
daviddalpiaz,appliedstats,07a1133089baa08c5a6632bbc6b27b780dc48e5a,David Dalpiaz,dalpiaz2@illinois.edu,2016-11-30T21:52:31Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-11-30T21:52:31Z,fix Rcpp,beyond.Rmd,True,False,True,False,1,1,2,"---FILE: beyond.Rmd---
@@ -71,7 +71,7 @@ In this class, we have worked within the frequentist view of statistics. There i
 
 ## High Performance Computing
 
-Often `R` will be called a ""slow"" language, for two reasons. One, because many do not understand `R`. Two, because sometimes it really is. Luckily, it is easy to extend `R` via the [`RCpp` package](http://www.rcpp.org/) to allow for faster code. Many modern `R` packages utilize `Rcpp` to achieve better performance.
+Often `R` will be called a ""slow"" language, for two reasons. One, because many do not understand `R`. Two, because sometimes it really is. Luckily, it is easy to extend `R` via the [`Rcpp` package](http://www.rcpp.org/) to allow for faster code. Many modern `R` packages utilize `Rcpp` to achieve better performance.
 
 ## Further `R` Resources
 "
daviddalpiaz,appliedstats,b60e8a5f4d9580ecb9601ba56de1bc2d6eb03093,David Dalpiaz,dalpiaz2@illinois.edu,2016-11-21T20:36:20Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-11-21T20:36:20Z,typo fix,selection.Rmd,True,False,True,False,1,1,2,"---FILE: selection.Rmd---
@@ -561,7 +561,7 @@ We'll use the `pairs()` plot to determine which variables may benefit from a qua
 So now, we'll fit this rather large model. We'll use a log-transformed response. Notice that `log(mpg) ~ . ^ 2` will automatically consider all first-order terms, as well as all two-way interactions. We use `I(var_name ^ 2)` to add quadratic terms for some variables. This generally works better than using `poly()` when performing variable selection.
 
 ```{r}
-autompg_big_mod = lm(log(mpg) ~ . ^ 2 + I(disp ^ 2) + I(disp ^ 2) + I(hp ^ 2) + I(wt ^ 2) + I(acc ^ 2), data = autompg)
+autompg_big_mod = lm(log(mpg) ~ . ^ 2 + I(disp ^ 2) + I(hp ^ 2) + I(wt ^ 2) + I(acc ^ 2), data = autompg)
 ```
 
 We think it is rather unlikely that we truly need all of these terms. There are quite a few!"
daviddalpiaz,appliedstats,882a5d3e37f2e3dbf52630a332bc6c61c75f5348,David Dalpiaz,dalpiaz2@illinois.edu,2016-10-23T15:43:51Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-10-23T15:43:51Z,fix line endings,appliedstats.Rproj,False,False,False,False,2,0,2,"---FILE: appliedstats.Rproj---
@@ -12,6 +12,8 @@ Encoding: UTF-8
 RnwWeave: Sweave
 LaTeX: pdfLaTeX
 
+LineEndingConversion: Posix
+
 BuildType: Package
 PackageUseDevtools: Yes
 PackageInstallArgs: --no-multiarch --with-keep.source"
daviddalpiaz,appliedstats,68d7da61f4aeeddd92d925071f026fb831b7b659,David Dalpiaz,dalpiaz2@illinois.edu,2016-10-22T16:35:09Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-10-22T16:35:09Z,typo fix,anova.Rmd,True,False,True,False,1,1,2,"---FILE: anova.Rmd---
@@ -155,7 +155,7 @@ Here,
 Then the total sample size is
 
 \[
-N = \sum_{i = i}^{I} n_i
+N = \sum_{i = i}^{g} n_i
 \]
 
 Observations from group $i$ follow a normal distribution"
daviddalpiaz,appliedstats,10fefd85c78befadb5aa03880d87ad0acd8fa672,David Dalpiaz,dalpiaz2@illinois.edu,2016-10-13T15:29:05Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-10-13T15:29:05Z,fix typo,r-intro.Rmd,True,False,True,False,1,1,2,"---FILE: r-intro.Rmd---
@@ -1039,7 +1039,7 @@ var(test_sample)
 We see the function is working as expected, and when returning the unbiased estimate it matches `R`'s built in function `var()`. Finally, let's examine the biased estimate of $\sigma^2$.
 
 ```{r}
-get_sd(test_sample, biased = TRUE)
+get_var(test_sample, biased = TRUE)
 ```
 
 ## Hypothesis Tests in `R`"
daviddalpiaz,appliedstats,44a1698cb24222c013b976cee5cc87d00b8aba88,David Dalpiaz,dalpiaz2@illinois.edu,2016-09-25T18:03:20Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-09-25T18:03:20Z,"align -> aligned, fix TeX error",model_building.Rmd,True,False,True,False,6,6,12,"---FILE: model_building.Rmd---
@@ -21,10 +21,10 @@ We can think of this as
 We *could* consider all sorts of complicated functions for $f$. You will likely encounter several ways of doing this in future machine learning courses. So far in this course we have focused on (multiple) linear regression. That is
 
 \[
-\begin{align}
+\begin{aligned}
 y &= f(x_1, x_2, x_3, \ldots, x_{p-1}) + \epsilon \\
   &= \beta_0 + \beta_1 x_{1} + \beta_2 x_{2} + \cdots + \beta_{p-1} x_{p-1} + \epsilon
-\end{align}
+\end{aligned}
 \]
 
 In the big picture of possible models that we could fit to this data, this is a rather restrictive model. What do we mean by a restrictive model?
@@ -86,19 +86,19 @@ y = f(x_1, x_2, x_3, \ldots, x_{p-1}) + \epsilon = \beta_0 + \beta_2 x_{2} + \ep
 Often, we'll use multiple predictors in our model. Very often, we will at least try a model with all possible predictors.
 
 \[
-\begin{align}
+\begin{aligned}
 y &= f(x_1, x_2, x_3, \ldots, x_{p-1}) + \epsilon \\
   &= \beta_0 + \beta_1 x_{1} + \beta_2 x_{2} + \cdots + \beta_{p-1} x_{p-1} + \epsilon
-\end{align}
+\end{aligned}
 \]
 
 We could also use some, but not all of the predictors.
 
 \[
-\begin{align}
+\begin{aligned}
 y &= f(x_1, x_2, x_3, \ldots, x_{p-1}) + \epsilon \\ 
   &= \beta_0 + \beta_1 x_{1} + \beta_3 x_{3} + \beta_5 x_{5} + \epsilon
-\end{align}
+\end{aligned}
 \]
 
 These forms are **restrictive** in two senses. First, they only allow for linear relationships between the response and the predictors. This seems like an obvious restriction of linear models, but in fact, we will soon see how to use linear models for *non-linear* relationships. (It will involve transforming variables.) Second, how one variable affects the response is the same for **any** values of the other predictors. Soon we will see how to create models where the effect of $x_{1}$ can be different for different values of $x_{2}$. We will discuss the concept of *interaction*."
daviddalpiaz,appliedstats,a049f92635008c410ad78b8c764226995abdf272,David Dalpiaz,dalpiaz2@illinois.edu,2016-09-24T19:17:25Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-09-24T19:17:25Z,typo fix,09-selection.Rmd,True,False,True,False,1,1,2,"---FILE: 09-selection.Rmd---
@@ -644,7 +644,7 @@ plot(mpg ~ hp, data = autompg, col = ""dodgerblue"", pch = 20, cex = 1.5)
 
 Does an increase in horsepower cause a drop in fuel efficiency? Or, perhaps the causality is reversed and an increase in fuel efficiency cause a decrease in horsepower. Or, perhaps there is a third variable that explains both!
 
-The issue here is the we have **observational** data. With observational data, we can only detect associations. To speak with confidence about causality, we would nee to run **experiments**.
+The issue here is that we have **observational** data. With observational data, we can only detect associations. To speak with confidence about causality, we would need to run **experiments**.
 
 This is a concept that you should encounter often in your statistics education. For some further reading, and some related fallacies, see: [Wikipedia: Correlation does not imply causation](https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation).
 "
daviddalpiaz,appliedstats,0247e697e5370b618f2c77643af1ceb2fc8844c4,David Dalpiaz,dalpiaz2@illinois.edu,2016-09-24T15:46:50Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-09-24T15:46:50Z,typo fix and attribution,04-mlr.Rmd;index.Rmd,True,False,True,False,3,3,6,"---FILE: 04-mlr.Rmd---
@@ -716,7 +716,7 @@ H_1: \text{At least one of } \beta_j \neq 0, j = 1, 2, \cdots, (p-1)
 We could then say that the full model, or ""model under the alternative hypothesis"" is
 
 \[
-Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{i(p-1)} + \epsilon_i
+Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_{(p-1)} x_{i(p-1)} + \epsilon_i
 \]
 
 This is a model where the regression is significant. At least one of the predictors has a significant linear relationship with the response. We will denote the fitted values of this model as $\hat{y}_{1i}$. The ANOVA table is then nearly identical to the ANOVA table from SLR, with two exceptions in the degrees of freedom column.
@@ -790,7 +790,7 @@ The significance of the regression test is actually a special case of testing wh
 Consider the following full model,
 
 \[
-Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{i(p-1)} + \epsilon_i
+Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_{(p-1)} x_{i(p-1)} + \epsilon_i
 \]
 
 This model has $p - 1$ predictors, for a total of $p$ $\beta$-parameters. We will denote the fitted values of this model as $\hat{y}_{1i}$.

---FILE: index.Rmd---
@@ -77,7 +77,7 @@ Material in this book was heavily influenced by:
 
 Additional corrections or suggestions provided by:
 
-[Daniel McQuillan](https://github.com/dmcquillan314), [Mason Rubenstein](https://github.com/mruben09), [Yuhang Wang](https://github.com/yuhangwang), Zhao Liu, [Jinfeng Xiao](https://github.com/JinfengXiao)
+[Daniel McQuillan](https://github.com/dmcquillan314), [Mason Rubenstein](https://github.com/mruben09), [Yuhang Wang](https://github.com/yuhangwang), Zhao Liu, [Jinfeng Xiao](https://github.com/JinfengXiao), [Somu Palaniappan](https://www.linkedin.com/in/somupalaniappan)
 
 ## License
 "
daviddalpiaz,appliedstats,b04df90322fe629e032c1a9d44576421173b269f,David Dalpiaz,dalpiaz2@illinois.edu,2016-08-04T20:49:21Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-08-04T20:49:21Z,hat fix,08-collinearity.Rmd,True,False,True,False,4,4,8,"---FILE: 08-collinearity.Rmd---
@@ -314,13 +314,13 @@ hist(beta_hat_bad[, 2],
      col = ""darkorange"",
      border = ""dodgerblue"",
      main = expression(""Histogram of "" *hat(beta)[1]* "" with Collinearity""),
-     xlab = expression(beta[1])
+     xlab = expression(hat(beta)[1])
 )
 hist(beta_hat_good[, 2],
      col = ""darkorange"",
      border = ""dodgerblue"",
      main = expression(""Histogram of "" *hat(beta)[1]* "" without Collinearity""),
-     xlab = expression(beta[1])
+     xlab = expression(hat(beta)[1])
 )
 ```
 
@@ -344,13 +344,13 @@ hist(beta_hat_bad[, 3],
      col = ""darkorange"",
      border = ""dodgerblue"",
      main = expression(""Histogram of "" *hat(beta)[2]* "" with Collinearity""),
-     xlab = expression(beta[2])
+     xlab = expression(hat(beta)[2])
 )
 hist(beta_hat_good[, 3],
      col = ""darkorange"",
      border = ""dodgerblue"",
      main = expression(""Histogram of "" *hat(beta)[2]* "" without Collinearity""),
-     xlab = expression(beta[2])
+     xlab = expression(hat(beta)[2])
 )
 ```
 "
daviddalpiaz,appliedstats,d299dcdc94e1ad5ea02f71a99d77ccb6b47f0e59,David Dalpiaz,dalpiaz2@illinois.edu,2016-07-18T21:38:51Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-07-18T21:38:51Z,typo fix,06-diagnostics.Rmd,True,False,True,False,1,1,2,"---FILE: 06-diagnostics.Rmd---
@@ -906,7 +906,7 @@ qqline(resid(big_model), col = ""darkorange"", lwd = 2)
 shapiro.test(resid(big_model))
 ```
 
-Here both the Q-Q plot, and the Shapiro-Wilk test suggests that the normality assumption is violated.
+Here both the Q-Q plot, and the Shapiro-Wilk test suggest that the normality assumption is violated.
 
 ```{r}
 big_mod_cd = cooks.distance(big_model)"
daviddalpiaz,appliedstats,d4a82cc9729e35712c96f3e3ea0ad9101a0baff0,David Dalpiaz,dalpiaz2@illinois.edu,2016-07-12T17:43:26Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-07-12T17:43:26Z,typo fix,05-cat_int.Rmd,True,False,True,False,1,1,2,"---FILE: 05-cat_int.Rmd---
@@ -189,7 +189,7 @@ autompg = subset(autompg, autompg$hp != ""?"")
 autompg = subset(autompg, autompg$name != ""plymouth reliant"")
 # give the dataset row names, based on the engine, year and name
 rownames(autompg) = paste(autompg$cyl, ""cylinder"", autompg$year, autompg$name)
-# remove the variable for name, as will as origin
+# remove the variable for name
 autompg = subset(autompg, select = c(""mpg"", ""cyl"", ""disp"", ""hp"", ""wt"", ""acc"", ""year"", ""origin""))
 # change horsepower from character to numeric
 autompg$hp = as.numeric(autompg$hp)"
daviddalpiaz,appliedstats,49e894591754ba3e7df54df12e41b63ed8cb2c15,David Dalpiaz,dalpiaz2@illinois.edu,2016-07-11T15:46:53Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-07-11T15:46:53Z,typo fix,05-cat_int.Rmd,True,False,True,False,1,1,2,"---FILE: 05-cat_int.Rmd---
@@ -290,7 +290,7 @@ An alternative method, which will fit the exact same model as above would be to
 mpg_disp_int2 = lm(mpg ~ disp * domestic, data = autompg)
 ```
 
-We can quickly verify that these are the doing the same thing.
+We can quickly verify that these are doing the same thing.
 
 ```{r}
 coef(mpg_disp_int)"
daviddalpiaz,appliedstats,069291561f11f727eecfb1e318ad89d4a0dbd258,daviddalpiaz,dalpiaz2@illinois.edu,2016-07-07T02:58:48Z,daviddalpiaz,dalpiaz2@illinois.edu,2016-07-07T02:58:48Z,fix R2 typo,02-slr.Rmd,True,False,True,False,2,2,4,"---FILE: 02-slr.Rmd---
@@ -527,9 +527,9 @@ These three measures also do not have an important practical interpretation indi
 The **coefficient of determination**, $R^2$, is defined as
 
 \[
-R^2 = \frac{\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}{\sum_{i=1}^{n}(y_i - \bar{y})^2} =
+R^2 = \frac{\sum_{i=1}^{n}(\hat{y}_i - \bar{y})^2}{\sum_{i=1}^{n}(y_i - \bar{y})^2} =
 \frac{SSReg}{SST} = 
-1 - \frac{\sum_{i=1}^{n}(\hat{y}_i - \bar{y})^2}{\sum_{i=1}^{n}(y_i - \bar{y})^2} = 
+1 - \frac{\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}{\sum_{i=1}^{n}(y_i - \bar{y})^2} = 
 1 - \frac{\sum_{i = 1}^{n}e_i^2}{\sum_{i=1}^{n}(y_i - \bar{y})^2} = 1 - \frac{SSE}{SST}
 \]
 "
daviddalpiaz,appliedstats,77982a085ba3e91d6f2277e6ffd66eb6b3848b91,daviddalpiaz,dalpiaz2@illinois.edu,2016-07-05T21:41:18Z,daviddalpiaz,dalpiaz2@illinois.edu,2016-07-05T21:41:18Z,fix normal eqs,04-mlr.Rmd,True,False,True,False,1,1,2,"---FILE: 04-mlr.Rmd---
@@ -105,7 +105,7 @@ After doing so, we will once again obtain the **normal equations.**
 
 \[
 \begin{aligned}
-\beta_0 + \beta_1 \sum_{i = 1}^{n} x_{i1} + \beta_2 \sum_{i = 1}^{n} x_{i2} &= \sum_{i = 1}^{n} y_i  \\
+n \beta_0 + \beta_1 \sum_{i = 1}^{n} x_{i1} + \beta_2 \sum_{i = 1}^{n} x_{i2} &= \sum_{i = 1}^{n} y_i  \\
 \beta_0 \sum_{i = 1}^{n} x_{i1} + \beta_1 \sum_{i = 1}^{n} x_{i1}^2 + \beta_2 \sum_{i = 1}^{n} x_{i1}x_{i2} &= \sum_{i = 1}^{n} x_{i1}y_i \\
 \beta_0 \sum_{i = 1}^{n} x_{i2} + \beta_1 \sum_{i = 1}^{n} x_{i1}x_{i2} + \beta_2 \sum_{i = 1}^{n} x_{i2}^2 &= \sum_{i = 1}^{n} x_{i2}y_i
 \end{aligned}"
daviddalpiaz,appliedstats,427591df9cb6012681ffaf787ea0b35225ae25fe,Dan McQuillan,d.mcquillan314@gmail.com,2016-07-03T16:05:18Z,GitHub,noreply@github.com,2016-07-03T16:05:18Z,Fix grammatical error,04-mlr.Rmd,True,False,True,False,1,1,2,"---FILE: 04-mlr.Rmd---
@@ -787,7 +787,7 @@ length(resid(null_mpg_model)) - length(coef(null_mpg_model))
 
 The significance of the regression test is actually a special case of testing what we will call **nested models**. More generally we can compare two models, where one model is ""nested"" inside the other, meaning one model contains a subset of the predictors from only the larger model.
 
-Consider the following the full model,
+Consider the following full model,
 
 \[
 Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{i(p-1)} + \epsilon_i"
daviddalpiaz,appliedstats,032c9c20a52c780be85e9886e38e50a65b1ecd97,daviddalpiaz,dalpiaz2@illinois.edu,2016-06-28T13:47:33Z,daviddalpiaz,dalpiaz2@illinois.edu,2016-06-28T13:47:33Z,table width fix,03-slr-inf.Rmd,True,False,True,False,5,5,10,"---FILE: 03-slr-inf.Rmd---
@@ -821,11 +821,11 @@ SST = SSReg + SSE.
 
 To develop the $F$ test, we will arrange this information in an **ANOVA** table,
 
-| Source     | Sum of Squares  | Degrees of Freedom | Mean Square     | $F$         |
-|------------|-----------------|--------------------|-----------------|-------------|
-| Regression | $\sum_{i=1}^{n}(\hat{y}_i - \bar{y})^2$ | $1$                | $SSReg / 1$     | $MSReg / MSE$ |
-| Error      | $\sum_{i=1}^{n}(y_i - \hat{y}_i)^2$ | $n - 2$            | $SSE / (n - 2)$ |             |
-| Total      | $\sum_{i=1}^{n}(y_i - \bar{y})^2$       | $n - 1$            |                 |             |
+| Source     | Sum of Squares  | Degrees of Freedom | Mean Square | $F$ |
+|------------|-----------------|------------|-----------|-----------|
+| Regression | $\sum_{i=1}^{n}(\hat{y}_i - \bar{y})^2$ | $1$ | $SSReg / 1$     | $MSReg / MSE$ |
+| Error      | $\sum_{i=1}^{n}(y_i - \hat{y}_i)^2$     | $n - 2$ | $SSE / (n - 2)$ |             |
+| Total      | $\sum_{i=1}^{n}(y_i - \bar{y})^2$       | $n - 1$ |                 |             |
 
 ANOVA, or Analysis of Variance will be a concept we return to often in this course. For now, we will focus on the results of the table, which is the $F$ statistic,
 "
daviddalpiaz,appliedstats,5a632f8841dc65dc4c9435ebe07f0ae14366ba27,daviddalpiaz,dalpiaz2@illinois.edu,2016-06-25T15:10:04Z,daviddalpiaz,dalpiaz2@illinois.edu,2016-06-25T15:10:04Z,typo fixes,03-slr-inf.Rmd,True,False,True,False,5,5,10,"---FILE: 03-slr-inf.Rmd---
@@ -388,7 +388,7 @@ SE[\hat{\beta}_1] = \frac{s_e}{\sqrt{S_{xx}}}
 Now if we divide by the standard error, instead of the standard deviation, we obtain the following results which will allow us to make confidence intervals and perform hypothesis testing.
 
 \[
-\frac{\hat{\beta}_1 - \beta_1}{SE[\hat{\beta}_0]} \sim t_{n-2}
+\frac{\hat{\beta}_0 - \beta_0}{SE[\hat{\beta}_0]} \sim t_{n-2}
 \]
 
 \[
@@ -404,10 +404,10 @@ To see this, first note that,
 Then we use the classic trick of ""multiply by 1"" and some rearranging to arrive at
 
 \[
-\frac{\hat{\beta}_1 - \beta_1}{SE[\hat{\beta}_1]} = \frac{\hat{\beta}_1 - \beta_1}{s_e / S_{xx}}
-= \frac{\hat{\beta}_1 - \beta_1}{s_e / S_{xx}} \cdot \frac{\sigma / S_{xx}}{\sigma / S_{xx}}
-= \frac{\hat{\beta}_1 - \beta_1}{\sigma / S_{xx}} \cdot \frac{\sigma / S_{xx}}{s_e / S_{xx}}
-= \frac{\hat{\beta}_1 - \beta_1}{\sigma / S_{xx}} \bigg/ \sqrt{\frac{s_e^2}{\sigma^2}}
+\frac{\hat{\beta}_1 - \beta_1}{SE[\hat{\beta}_1]} = \frac{\hat{\beta}_1 - \beta_1}{s_e / \sqrt{S_{xx}}}
+= \frac{\hat{\beta}_1 - \beta_1}{s_e / \sqrt{S_{xx}}} \cdot \frac{\sigma / \sqrt{S_{xx}}}{\sigma / \sqrt{S_{xx}}}
+= \frac{\hat{\beta}_1 - \beta_1}{\sigma / \sqrt{S_{xx}}} \cdot \frac{\sigma / \sqrt{S_{xx}}}{s_e / \sqrt{S_{xx}}}
+= \frac{\hat{\beta}_1 - \beta_1}{\sigma / \sqrt{S_{xx}}} \bigg/ \sqrt{\frac{s_e^2}{\sigma^2}}
 \sim \frac{Z}{\sqrt{\frac{\chi_{n-2}^2}{n-2}}}
 \sim t_{n-2}
 \]"
daviddalpiaz,appliedstats,cf95f34ad45d22bb9acccac8a8dfc30c5b4dd683,daviddalpiaz,dalpiaz2@illinois.edu,2016-06-25T04:48:09Z,daviddalpiaz,dalpiaz2@illinois.edu,2016-06-25T04:48:09Z,fix TeX error,03-slr-inf.Rmd,True,False,True,False,1,1,2,"---FILE: 03-slr-inf.Rmd---
@@ -373,7 +373,7 @@ and
 SD[\hat{\beta}_1] = \frac{\sigma}{\sqrt{S_{xx}}}.
 \]
 
-Since we don't know $\sigma$ in practice, we will have to estimate it using $s_e$, which we plug into our existing expression for the standard deviations of our estimates. We choose $s_e$ instead of $\hat{\signa}$ because, as you've seen recently, we prize unbiased estimators over biased ones.
+Since we don't know $\sigma$ in practice, we will have to estimate it using $s_e$, which we plug into our existing expression for the standard deviations of our estimates. We choose $s_e$ instead of $\hat{\sigma}$ because, as you've seen recently, we prize unbiased estimators over biased ones.
 
 These two new expressions are called **standard errors** which are the *estimated* standard deviations of the sampling distributions.
 "
daviddalpiaz,appliedstats,74c1b415aa01e8bda7a90ed92d411a27d8a27c72,daviddalpiaz,dalpiaz2@illinois.edu,2016-06-25T04:47:15Z,daviddalpiaz,dalpiaz2@illinois.edu,2016-06-25T04:47:15Z,"index fix, .R update",03-slr-inf.Rmd;applied_statistics.R,True,False,True,False,185,2,187,"---FILE: 03-slr-inf.Rmd---
@@ -80,7 +80,7 @@ However, in this chapter it will often be convenient to use both $\hat{\beta}_1$
 
 Last chapter we argued that these estimates of unknown model parameters $\beta_0$ and $\beta_1$ were good because we obtained them by minimizing errors. We will now discuss the Gauss–Markov theorem which takes this idea further, showing that these estimates are actually the ""best"" estimates, from a certain point of view.
 
-### Gauss–Markov Theorem
+## Gauss–Markov Theorem
 
 The **Gauss–Markov theorem** tells us that when estimating the parameters of the simple linear regression model $\beta_0$ and $\beta_1$, the $\hat{\beta}_0$ and $\hat{\beta}_1$ which we derived are the **best linear unbiased estiamtes**, or *BLUE* for short. (The actual conditions for the Gauss–Markov theorem are more relaxed than the SLR model.)
 

---FILE: applied_statistics.R---
@@ -1,7 +1,7 @@
 ## ----setup, echo = FALSE, message = FALSE, warning = FALSE--------------------
 require(knitr)
 read_chunk('r_book.R')
-options(scipen = 8, digits = 4, width = 80)
+options(scipen = 8, width = 80)
 knit_hooks$set(purl = hook_purl)
 opts_template$set(nopurl = list(purl = FALSE))
 opts_template$set(dopurl = list(purl = TRUE))
@@ -892,3 +892,186 @@ plot(response ~ predictor, data = sim_data,
      col  = ""dodgerblue"")
 abline(sim_fit, lwd = 3, col = ""darkorange"")
 
+## -----------------------------------------------------------------------------
+stop_dist_model = lm(dist ~ speed, data = cars)
+summary(stop_dist_model)
+
+## -----------------------------------------------------------------------------
+plot(dist ~ speed, data = cars,
+     xlab = ""Speed (in Miles Per Hour)"",
+     ylab = ""Stopping Distance (in Feet)"",
+     main = ""Stopping Distance vs Speed"",
+     pch  = 20,
+     cex  = 2,
+     col  = ""dodgerblue"")
+abline(stop_dist_model, lwd = 5, col = ""darkorange"")
+
+## -----------------------------------------------------------------------------
+set.seed(42)
+sample_size = 100 # this is n
+x = seq(-1, 1, length = sample_size)
+Sxx = sum((x - mean(x)) ^ 2)
+
+## -----------------------------------------------------------------------------
+beta_0 = 3
+beta_1 = 6
+sigma  = 2
+
+## -----------------------------------------------------------------------------
+(var_beta_1_hat = sigma ^ 2 / Sxx)
+(var_beta_0_hat = sigma ^ 2 * (1 / sample_size + mean(x) ^ 2 / Sxx))
+
+## -----------------------------------------------------------------------------
+num_samples = 10000
+beta_0_hats = rep(0, num_samples)
+beta_1_hats = rep(0, num_samples)
+
+for(i in 1:num_samples) {
+  eps = rnorm(sample_size, mean = 0, sd = sigma)
+  y   = beta_0 + beta_1 * x + eps
+  
+  sim_model = lm(y ~ x)
+  
+  beta_0_hats[i] = coef(sim_model)[1]
+  beta_1_hats[i] = coef(sim_model)[2]
+}
+
+## -----------------------------------------------------------------------------
+mean(beta_1_hats) # empirical mean
+beta_1            # true mean
+var(beta_1_hats)  # empirical variance
+var_beta_1_hat    # true variance
+
+## -----------------------------------------------------------------------------
+# note need to use prob = TRUE
+hist(beta_1_hats, prob = TRUE, breaks = 20, 
+     xlab = expression(hat(beta)[1]), main = """", border = ""dodgerblue"")
+curve(dnorm(x, mean = beta_1, sd = sqrt(var_beta_1_hat)), 
+      col = ""darkorange"", add = TRUE, lwd = 3)
+
+## -----------------------------------------------------------------------------
+mean(beta_0_hats) # empirical mean
+beta_0            # true mean
+var(beta_0_hats)  # empirical variance
+var_beta_0_hat    # true variance
+
+## -----------------------------------------------------------------------------
+hist(beta_0_hats, prob = TRUE, breaks = 20, 
+     xlab = expression(hat(beta)[0]), main = """", border = ""dodgerblue"")
+curve(dnorm(x, mean = beta_0, sd = sqrt(var_beta_0_hat)),
+      col = ""darkorange"", add = TRUE, lwd = 3)
+
+## -----------------------------------------------------------------------------
+par(mar = c(5, 5, 1, 1)) # adjusted plot margins, otherwise the ""hat"" does not display
+plot(cumsum(beta_1_hats) / (1:length(beta_1_hats)), type = ""l"", ylim = c(5.95, 6.05),
+     xlab = ""Number of Simulations"",
+     ylab = expression(""Empirical Mean of "" ~ hat(beta)[1]),
+     col  = ""dodgerblue"")
+abline(h = 6, col = ""darkorange"", lwd = 2)
+
+par(mar = c(5, 5, 1, 1)) # adjusted plot margins, otherwise the ""hat"" does not display
+plot(cumsum(beta_0_hats) / (1:length(beta_0_hats)), type = ""l"", ylim = c(2.95, 3.05),
+     xlab = ""Number of Simulations"",
+     ylab = expression(""Empirical Mean of "" ~ hat(beta)[0]),
+     col  = ""dodgerblue"")
+abline(h = 3, col = ""darkorange"", lwd = 2)
+
+## -----------------------------------------------------------------------------
+stop_dist_model = lm(dist ~ speed, data = cars)
+summary(stop_dist_model)
+
+## -----------------------------------------------------------------------------
+names(summary(stop_dist_model))
+summary(stop_dist_model)$coefficients
+
+## -----------------------------------------------------------------------------
+summary(stop_dist_model)$coefficients[2,]
+
+## -----------------------------------------------------------------------------
+summary(stop_dist_model)$coefficients[1,]
+
+## -----------------------------------------------------------------------------
+stop_dist_model_test_info = summary(stop_dist_model)$coefficients
+
+beta_0_hat      = stop_dist_model_test_info[1,1] # Estimate
+beta_0_hat_se   = stop_dist_model_test_info[1,2] # Std. Error
+beta_0_hat_t    = stop_dist_model_test_info[1,3] # t value
+beta_0_hat_pval = stop_dist_model_test_info[1,4] # Pr(>|t|)
+
+beta_1_hat      = stop_dist_model_test_info[2,1] # Estimate
+beta_1_hat_se   = stop_dist_model_test_info[2,2] # Std. Error
+beta_1_hat_t    = stop_dist_model_test_info[2,3] # t value
+beta_1_hat_pval = stop_dist_model_test_info[2,4] # Pr(>|t|)
+
+## -----------------------------------------------------------------------------
+(beta_1_hat - 0) / beta_1_hat_se
+beta_1_hat_t
+
+## -----------------------------------------------------------------------------
+2 * pt(abs(beta_1_hat_t), df = length(resid(stop_dist_model)) - 2, lower.tail = FALSE)
+beta_1_hat_pval
+
+## ---- echo = FALSE------------------------------------------------------------
+set.seed(42)
+x = seq(-1, 1, 0.01)
+y = 5 + 4 * x ^ 2 + rnorm(length(x), 0, 0.5)
+plot(x, y)
+abline(lm(y ~ x))
+#summary(lm(y ~ x))$coef[2,4]
+
+## -----------------------------------------------------------------------------
+confint(stop_dist_model, level = 0.99)
+
+## ---- eval = FALSE------------------------------------------------------------
+#  confint(stop_dist_model, level = 0.99)[1,]
+#  confint(stop_dist_model, level = 0.99)[1,1]
+#  confint(stop_dist_model, level = 0.99)[1,2]
+#  confint(stop_dist_model, parm = ""(Intercept)"", level = 0.99)
+#  confint(stop_dist_model, level = 0.99)[2,]
+#  confint(stop_dist_model, level = 0.99)[2,1]
+#  confint(stop_dist_model, level = 0.99)[2,2]
+#  confint(stop_dist_model, parm = ""speed"", level = 0.99)
+
+## -----------------------------------------------------------------------------
+new_speeds = data.frame(speed = c(5, 21))
+predict(stop_dist_model, newdata = new_speeds, 
+        interval = c(""confidence""), level = 0.99)
+
+## -----------------------------------------------------------------------------
+predict(stop_dist_model, newdata = new_speeds, 
+        interval = c(""prediction""), level = 0.99)
+
+## -----------------------------------------------------------------------------
+speed_grid = seq(min(cars$speed), max(cars$speed), by = 0.01)
+dist_ci_band = predict(stop_dist_model, 
+                           newdata = data.frame(speed = speed_grid), 
+                           interval = ""confidence"", level = 0.99)
+dist_pi_band = predict(stop_dist_model, 
+                           newdata = data.frame(speed = speed_grid), 
+                           interval = ""prediction"", level = 0.99) 
+
+plot(dist ~ speed, data = cars,
+     xlab = ""Speed (in Miles Per Hour)"",
+     ylab = ""Stopping Distance (in Feet)"",
+     main = ""Stopping Distance vs Speed"",
+     pch  = 20,
+     cex  = 2,
+     col  = ""dodgerblue"",
+     ylim = c(-50, 140))
+abline(stop_dist_model, lwd = 5, col = ""darkorange"")
+
+lines(speed_grid, dist_ci_band[,""lwr""], col = ""red"", lwd = 3, lty = 2)
+lines(speed_grid, dist_ci_band[,""upr""], col = ""red"", lwd = 3, lty = 2)
+lines(speed_grid, dist_pi_band[,""lwr""], col = ""green"", lwd = 3, lty = 3)
+lines(speed_grid, dist_pi_band[,""upr""], col = ""green"", lwd = 3, lty = 3)
+points(mean(cars$speed), mean(cars$dist), pch = ""+"", cex = 3)
+
+## -----------------------------------------------------------------------------
+summary(stop_dist_model)
+
+## -----------------------------------------------------------------------------
+anova(stop_dist_model)
+
+## -----------------------------------------------------------------------------
+anova(lm(dist ~ 1, data = cars), lm(dist ~ speed, data = cars))
+"
daviddalpiaz,appliedstats,552de3405598b13ddb8304a0654173b435c88581,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-23T21:22:40Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-23T21:22:40Z,mle derivative fix,02-slr.Rmd;index.Rmd,True,False,True,False,4,3,7,"---FILE: 02-slr.Rmd---
@@ -810,8 +810,8 @@ Note that we use $\log$ to mean the natural logarithm. We now take a partial der
 
 \[
 \begin{aligned}
-\frac{\partial \log L(\beta_0, \beta_1, \sigma^2)}{\partial \beta_0} &= -\frac{2}{\sigma^2} \sum_{i = 1}^{n} (y_i - \beta_0 - \beta_1 x_i)\\
-\frac{\partial \log L(\beta_0, \beta_1, \sigma^2)}{\partial \beta_1} &= -\frac{2}{\sigma^2} \sum_{i = 1}^{n}(x_i)(y_i - \beta_0 - \beta_1 x_i) \\
+\frac{\partial \log L(\beta_0, \beta_1, \sigma^2)}{\partial \beta_0} &= \frac{1}{\sigma^2} \sum_{i = 1}^{n} (y_i - \beta_0 - \beta_1 x_i)\\
+\frac{\partial \log L(\beta_0, \beta_1, \sigma^2)}{\partial \beta_1} &= \frac{1}{\sigma^2} \sum_{i = 1}^{n}(x_i)(y_i - \beta_0 - \beta_1 x_i) \\
 \frac{\partial \log L(\beta_0, \beta_1, \sigma^2)}{\partial \sigma^2} &= -\frac{n}{2 \sigma^2} + \frac{1}{2(\sigma^2)^2} \sum_{i = 1}^{n} (y_i - \beta_0 - \beta_1 x_i)^2
 \end{aligned}
 \]
@@ -856,7 +856,7 @@ In practice you will almost never have a true model, and you will use data to at
 For this example, we will simulate `n = 20` observations from the model
 
 \[
-y_i = 5 + 2 x + \epsilon_i.
+y_i = 5 + 2 x_i + \epsilon_i.
 \]
 
 That is $\beta_0 = 5$, $\beta_1 = 2$, and let $\epsilon_i \sim N(\mu = 0, \sigma^2 = 1)$.

---FILE: index.Rmd---
@@ -76,6 +76,7 @@ Additional corrections or suggestions provided by:
 
 - [Daniel McQuillan](https://github.com/dmcquillan314)
 - [Mason Rubenstein](https://github.com/mruben09)
+- [Yuhang Wang](https://github.com/yuhangwang)
 
 ## License
 "
daviddalpiaz,appliedstats,691246d8cfc6a07f3e92b4fb4c29aab7c70ac76b,daviddalpiaz,dalpiaz2@illinois.edu,2016-06-21T02:14:28Z,daviddalpiaz,dalpiaz2@illinois.edu,2016-06-21T02:14:28Z,type fix and attribution,02-slr.Rmd;index.Rmd,True,False,True,False,2,1,3,"---FILE: 02-slr.Rmd---
@@ -851,7 +851,7 @@ In the next chapter, we will discuss in detail the difference between these two
 
 We return again to more examples of simulation. This will be a common theme! 
 
-In practice you will almost never have a true model, and you will use data to attempt to recover information about the unknown true model. With simulation, we decide the true model and simulate data from the it. Then we apply a method to the data, in this case least squares. Now, since we know the true model, we can asses how well it did.
+In practice you will almost never have a true model, and you will use data to attempt to recover information about the unknown true model. With simulation, we decide the true model and simulate data from the it. Then we apply a method to the data, in this case least squares. Now, since we know the true model, we can assess how well it did.
 
 For this example, we will simulate `n = 20` observations from the model
 

---FILE: index.Rmd---
@@ -75,6 +75,7 @@ Material in this book was heavily influenced by:
 Additional corrections or suggestions provided by:
 
 - [Daniel McQuillan](https://github.com/dmcquillan314)
+- [Mason Rubenstein](https://github.com/mruben09)
 
 ## License
 "
daviddalpiaz,appliedstats,69b020c0b307f46ee5c19ab488d4c5644941ca3b,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-18T20:30:23Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-18T20:30:23Z,fixed indexing,02-slr.Rmd,True,False,True,False,3,3,6,"---FILE: 02-slr.Rmd---
@@ -469,7 +469,7 @@ If we square then sum both sides of the equation above, we can obtain the follow
 
 This should be somewhat alarming or amazing. How is this true? For now we will leave this questions unanswered. (Think about this, and maybe try to prove it.) We will now define three of the quantities seen in this equation. 
 
-#### Sum of Squares Total
+#### Sum of Squares Total {-}
 
 \[
 SST = \sum_{i=1}^{n}(y_i - \bar{y})^2
@@ -481,15 +481,15 @@ The quantity ""Sum of Squares Total,"" or $SST$, represents the **total variation*
 s ^ 2 = \frac{1}{n - 1}\sum_{i=1}^{n}(y_i - \bar{y})^2 = \frac{1}{n - 1} SST.
 \]
 
-#### Sum of Squares Regression
+#### Sum of Squares Regression {-}
 
 \[
 SSReg = \sum_{i=1}^{n}(\hat{y}_i - \bar{y})^2
 \]
 
 The quantity ""Sum of Squares Regression,"" $SSReg$, represents the **explained variation** of the observed $y$ values.
 
-#### Sum of Squares Error
+#### Sum of Squares Error {-}
 
 \[
 SSE = RSS = \sum_{i=1}^{n}(y_i - \hat{y}_i)^2"
daviddalpiaz,appliedstats,83eb7f3ff205d1e46d5546f452ad8f81fbda1442,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-17T19:30:16Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-17T19:30:16Z,Fixed broken image reference.,02-slr.Rmd,True,False,True,False,1,1,2,"---FILE: 02-slr.Rmd---
@@ -156,7 +156,7 @@ Var[Y_i] = \sigma^2.
 
 This is visually displayed in the image below. We see that for any value $x$, the expected value of $Y$ is $\beta_0 + \beta_1 x$. At each value of $x$, $Y$ has the same variance $\sigma^2$.
 
-![Simple Linear Regression Model [UC David Stat Wiki](http://statwiki.ucdavis.edu/Textbook_Maps/General_Statistics/Map%3A_Introductory_Statistics_(Shafer_and_Zhang)/10%3A_Correlation_and_Regression/10.3_Modelling_Linear_Relationships_with_Randomness_Present)](../images/model.jpg)
+![Simple Linear Regression Model [UC David Stat Wiki](http://statwiki.ucdavis.edu/Textbook_Maps/General_Statistics/Map%3A_Introductory_Statistics_(Shafer_and_Zhang)/10%3A_Correlation_and_Regression/10.3_Modelling_Linear_Relationships_with_Randomness_Present)](images/model.jpg)
 
 Often, we directly talk about the assumptions that this model makes. They can be cleverly shortened to **LINE**.  
 "
daviddalpiaz,appliedstats,f412403b97ee657a1213f9e2c361f8258bbc0bb5,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-16T17:32:31Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-16T17:32:31Z,"fixed missing "".""",01-r-intro.Rmd,True,False,True,False,1,1,2,"---FILE: 01-r-intro.Rmd---
@@ -37,7 +37,7 @@ The popularity of `R` is on the rise, and everyday it becomes a better tool for
     - Gentle introduction to the programming side of `R`. (Whereas we will focus more on the data analysis side.) A [free electronic version](http://vufind.carli.illinois.edu/vf-uiu/Record/uiu_6955421) is available through the Illinois library.
 - [Advanced `R`](http://adv-r.had.co.nz/) by Hadley Wickham.
     - From the author of several extremely popular `R` packages. Good follow-up to The Art of `R` Programming. (And more up-to-date material.)
-- [`R` for Data Science](http://r4ds.had.co.nz/) by Hadley Wickham and Garrett Grolemund
+- [`R` for Data Science](http://r4ds.had.co.nz/) by Hadley Wickham and Garrett Grolemund.
     - Similar to Advanced `R`, but focuses more on data analysis, while still introducing programming concepts. At the time of writing, currently under development.
 - [The R Inferno](http://www.burns-stat.com/documents/books/the-r-inferno/) by Patrick Burns.
     - Likens learning the tricks of `R` to descending through the levels of hell. Very advanced material, but may be important if `R` becomes a part of your everyday toolkit."
daviddalpiaz,appliedstats,4a777481ae9120ad078d39149f0d61f8a8434d36,daviddalpiaz,dalpiaz2@illinois.edu,2016-06-14T03:44:12Z,daviddalpiaz,dalpiaz2@illinois.edu,2016-06-14T03:44:12Z,fixed pooled sd notation.,01-r-intro.Rmd,True,False,True,False,1,1,2,"---FILE: 01-r-intro.Rmd---
@@ -1117,7 +1117,7 @@ s_y   = sd(y)
 We can then calculate the pooled standard deviation.
 
 \[
-s_{p}^{2} = \sqrt{\frac{(n-1)s_{x}^{2}+(m-1)s_{y}^{2}}{n+m-2}}
+s_{p} = \sqrt{\frac{(n-1)s_{x}^{2}+(m-1)s_{y}^{2}}{n+m-2}}
 \]
 
 ```{r}"
daviddalpiaz,appliedstats,ef0d683c6c121436e67e0b47f057321d7a98ef11,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-13T03:25:49Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-13T03:25:49Z,fixed dash.,01-r-intro.Rmd,True,False,True,False,1,1,2,"---FILE: 01-r-intro.Rmd---
@@ -42,7 +42,7 @@ The popularity of `R` is on the rise, and everyday it becomes a better tool for
 - [The R Inferno](http://www.burns-stat.com/documents/books/the-r-inferno/) by Patrick Burns.
     - Likens learning the tricks of `R` to descending through the levels of hell. Very advanced material, but may be important if `R` becomes a part of your everyday toolkit.
 
-RStudio has a large number of useful keyboard shortcuts. A list of these can be found using a keyboard shortcut - the keyboard shortcut to rule them all:
+RStudio has a large number of useful keyboard shortcuts. A list of these can be found using a keyboard shortcut -- the keyboard shortcut to rule them all:
 
 - On Windows: `Alt` + `Shift` + `K`
 - On Mac:  `Option` + `Shift` + `K`"
daviddalpiaz,appliedstats,2b7b68903925eb101f0e1b5211b48ec7334b35ff,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-11T22:17:33Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-11T22:17:33Z,fixed purl output,applied_statistics.R,False,True,True,False,559,0,559,"---FILE: applied_statistics.R---
@@ -27,3 +27,562 @@ a = 3
 b = 4
 sqrt(a ^ 2 + b ^ 2)
 
+## -----------------------------------------------------------------------------
+3 + 2
+3 - 2
+3 * 2
+3 / 2
+
+## -----------------------------------------------------------------------------
+3 ^ 2
+2 ^ (-3)
+100 ^ (1 / 2)
+sqrt(1 / 2)
+exp(1)
+
+## -----------------------------------------------------------------------------
+pi
+exp(1)
+
+## -----------------------------------------------------------------------------
+log(10)           # natural log
+log10(1000)       # base 10 log
+log2(8)           # base 2 log
+log(16, base = 4) # base 4 log
+
+## -----------------------------------------------------------------------------
+sin(pi / 2)
+cos(0)
+
+## ---- eval = FALSE------------------------------------------------------------
+#  ?log
+#  ?sin
+#  ?paste
+#  ?lm
+
+## ---- eval = FALSE------------------------------------------------------------
+#  install.packages(""ggplot2"")
+
+## ---- eval = FALSE------------------------------------------------------------
+#  library(ggplot2)
+
+## -----------------------------------------------------------------------------
+c(1, 3, 5, 7, 8, 9)
+
+## -----------------------------------------------------------------------------
+x = c(1, 3, 5, 7, 8, 9)
+x
+
+## -----------------------------------------------------------------------------
+(y = 1:100)
+
+## -----------------------------------------------------------------------------
+x
+x[1]
+x[3]
+
+## -----------------------------------------------------------------------------
+x[-2]
+
+## -----------------------------------------------------------------------------
+x[1:3]
+x[c(1,3,4)]
+
+## -----------------------------------------------------------------------------
+x = 1:10
+x + 1
+2 * x
+2 ^ x
+sqrt(x)
+log(x)
+
+## -----------------------------------------------------------------------------
+vec_1 = 1:10
+vec_2 = 1:1000
+vec_3 = 42
+
+## -----------------------------------------------------------------------------
+length(vec_1)
+length(vec_2)
+length(vec_3)
+
+## -----------------------------------------------------------------------------
+seq(from = 1.5, to = 4.2, by = 0.1)
+
+## -----------------------------------------------------------------------------
+seq(1.5, 4.2, 0.1)
+
+## -----------------------------------------------------------------------------
+rep(""A"", times = 10)
+
+## -----------------------------------------------------------------------------
+rep(x, times = 3)
+
+## -----------------------------------------------------------------------------
+c(x, rep(seq(1, 9, 2), 3), c(1, 2, 3), 42, 2:4)
+
+## -----------------------------------------------------------------------------
+y
+
+## -----------------------------------------------------------------------------
+mean(y)
+median(y)
+
+## -----------------------------------------------------------------------------
+var(y)
+sd(y)
+IQR(y)
+min(y)
+max(y)
+range(y)
+
+## -----------------------------------------------------------------------------
+x = 1:9
+x
+X = matrix(x, nrow = 3, ncol = 3)
+X
+
+## -----------------------------------------------------------------------------
+Y = matrix(x, nrow = 3, ncol = 3, byrow = TRUE)
+Y
+
+## -----------------------------------------------------------------------------
+Z = matrix(0, 2, 4)
+Z
+
+## -----------------------------------------------------------------------------
+X
+X[1, 2]
+
+## -----------------------------------------------------------------------------
+X[1, ]
+X[, 2]
+
+## -----------------------------------------------------------------------------
+X[2, c(1, 3)]
+
+## -----------------------------------------------------------------------------
+x = 1:9
+rev(x)
+rep(1, 9)
+
+## -----------------------------------------------------------------------------
+cbind(x, rev(x), rep(1, 9))
+
+## -----------------------------------------------------------------------------
+rbind(x, rev(x), rep(1, 9))
+
+## -----------------------------------------------------------------------------
+x = 1:9
+y = 9:1
+X = matrix(x, 3, 3)
+Y = matrix(y, 3, 3)
+X
+Y
+
+## -----------------------------------------------------------------------------
+X + Y
+X - Y
+X * Y
+X / Y
+
+## -----------------------------------------------------------------------------
+X %*% Y
+t(X)
+
+## -----------------------------------------------------------------------------
+Z = matrix(c(9, 2, -3, 2, 4, -2, -3, -2, 16), 3, byrow = TRUE)
+Z
+solve(Z)
+
+## -----------------------------------------------------------------------------
+X = matrix(1:6, 2, 3)
+X
+dim(X)
+rowSums(X)
+colSums(X)
+rowMeans(X)
+colMeans(X)
+
+## -----------------------------------------------------------------------------
+diag(Z)
+
+## -----------------------------------------------------------------------------
+diag(1:5)
+
+## -----------------------------------------------------------------------------
+diag(5)
+
+## -----------------------------------------------------------------------------
+example_data = data.frame(x = c(1, 3, 5, 7, 9, 1, 3, 5, 7, 9),
+                          y = rep(""Hello"", 10),
+                          z = rep(c(""TRUE"", ""FALSE""), 5))
+
+## -----------------------------------------------------------------------------
+example_data
+
+## ---- echo = FALSE------------------------------------------------------------
+write.csv(example_data, ""data/example_data.csv"", row.names = FALSE)
+
+## ---- eval = FALSE------------------------------------------------------------
+#  example_data_from_csv = read.csv(""data/example_data.csv"")
+
+## ---- eval = FALSE------------------------------------------------------------
+#  library(ggplot2)
+
+## -----------------------------------------------------------------------------
+head(mpg, n = 10)
+
+## -----------------------------------------------------------------------------
+str(mpg)
+
+## ---- eval = FALSE------------------------------------------------------------
+#  ?mpg
+
+## -----------------------------------------------------------------------------
+names(mpg)
+
+## -----------------------------------------------------------------------------
+mpg$year
+mpg$hwy
+
+## -----------------------------------------------------------------------------
+dim(mpg)
+nrow(mpg)
+ncol(mpg)
+
+## -----------------------------------------------------------------------------
+mpg[mpg$hwy > 35, c(""manufacturer"", ""model"", ""year"")]
+
+## ---- eval = FALSE------------------------------------------------------------
+#  subset(mpg, subset = hwy > 35, select = c(""manufacturer"", ""model"", ""year""))
+
+## ---- eval = FALSE------------------------------------------------------------
+#  library(dplyr)
+#  mpg %>% filter(hwy > 35) %>% select(manufacturer, model, year)
+
+## -----------------------------------------------------------------------------
+hist(mpg$cty)
+
+## -----------------------------------------------------------------------------
+hist(mpg$cty,
+     xlab   = ""Miles Per Gallon (City)"",
+     main   = ""Histogram of MPG (City)"",
+     breaks = 12,
+     col    = ""dodgerblue"",
+     border = ""darkorange"")
+
+## -----------------------------------------------------------------------------
+unique(mpg$drv)
+
+## -----------------------------------------------------------------------------
+boxplot(mpg$hwy)
+
+## -----------------------------------------------------------------------------
+boxplot(hwy ~ drv, data = mpg)
+
+## -----------------------------------------------------------------------------
+boxplot(hwy ~ drv, data = mpg,
+     xlab   = ""Drivetrain (f = FWD, r = RWD, 4 = 4WD)"",
+     ylab   = ""Miles Per Gallon (Highway)"",
+     main   = ""MPG (Highway) vs Drivetrain"",
+     pch    = 20,
+     cex    = 2,
+     col    = ""darkorange"",
+     border = ""dodgerblue"")
+
+## -----------------------------------------------------------------------------
+plot(hwy ~ displ, data = mpg)
+
+## -----------------------------------------------------------------------------
+plot(hwy ~ displ, data = mpg,
+     xlab = ""Engine Displacement (in Liters)"",
+     ylab = ""Miles Per Gallon (Highway)"",
+     main = ""MPG (Highway) vs Engine Displacement"",
+     pch  = 20,
+     cex  = 2,
+     col  = ""dodgerblue"")
+
+## -----------------------------------------------------------------------------
+dnorm(x = 3, mean = 2, sd = 5)
+
+## -----------------------------------------------------------------------------
+pnorm(q = 3, mean = 2, sd = 5)
+
+## -----------------------------------------------------------------------------
+qnorm(p = 0.975, mean = 2, sd = 5)
+
+## -----------------------------------------------------------------------------
+rnorm(n = 10, mean = 2, sd = 5)
+
+## -----------------------------------------------------------------------------
+dbinom(x = 6, size = 10, prob = 0.75)
+
+## -----------------------------------------------------------------------------
+heights = c(110, 120, 115, 136, 205, 156, 175)
+weights = c(64, 67, 62, 60, 77, 70, 66)
+
+## -----------------------------------------------------------------------------
+heights < 121
+heights < 121 | heights == 156
+
+## -----------------------------------------------------------------------------
+heights > 150
+heights[heights > 150]
+weights[heights > 150]
+
+## -----------------------------------------------------------------------------
+a = 1:10
+b = 2:4
+a < b
+
+## -----------------------------------------------------------------------------
+a > 5
+
+## -----------------------------------------------------------------------------
+5 + (a > 5)
+
+## -----------------------------------------------------------------------------
+sum(a > 5)
+
+## ---- eval = FALSE------------------------------------------------------------
+#  if (...) {
+#    some R code
+#  } else {
+#    more R code
+#  }
+
+## -----------------------------------------------------------------------------
+x = 1
+y = 3
+if (x > y) {
+  z = x * y
+  print(""x is larger than y"")
+} else {
+  z = x + 5 * y
+  print(""x is less than or equal to y"")
+}
+
+z
+
+## -----------------------------------------------------------------------------
+ifelse(4 > 3, 1, 0)
+
+## -----------------------------------------------------------------------------
+fib = c(1, 1, 2, 3, 5, 8, 13, 21)
+ifelse(fib > 6, ""Foo"", ""Bar"")
+
+## -----------------------------------------------------------------------------
+x = 11:15
+for (i in 1:5) {
+  x[i] = x[i] * 2
+}
+
+x
+
+## -----------------------------------------------------------------------------
+x = 11:15
+x = x * 2
+x
+
+## ---- eval = FALSE------------------------------------------------------------
+#  function_name(arg1 = 10, arg2 = 20)
+
+## -----------------------------------------------------------------------------
+standardize = function(x) {
+  m = mean(x)
+  std = sd(x)
+  result = (x - m) / std
+  result
+}
+
+## -----------------------------------------------------------------------------
+(test_sample = rnorm(n = 10, mean = 2, sd = 5))
+standardize(x = test_sample)
+
+## -----------------------------------------------------------------------------
+standardize = function(x) {
+  (x - mean(x)) / sd(x)
+}
+
+## -----------------------------------------------------------------------------
+power_of_num = function(num, power = 2) {
+  num ^ power
+}
+
+## -----------------------------------------------------------------------------
+power_of_num(10)
+power_of_num(10, 2)
+power_of_num(num = 10, power = 2)
+power_of_num(power = 2, num = 10)
+
+
+## -----------------------------------------------------------------------------
+power_of_num(2, 10)
+
+## ---- eval = FALSE------------------------------------------------------------
+#  power_of_num(power = 5)
+
+## -----------------------------------------------------------------------------
+get_sd = function(x, biased = FALSE) {
+  n = length(x) - 1 * !biased
+  sqrt((1 / n) * sum((x - mean(x)) ^ 2))
+}
+
+## -----------------------------------------------------------------------------
+get_sd(test_sample)
+get_sd(test_sample, biased = FALSE)
+sd(test_sample)
+
+## -----------------------------------------------------------------------------
+get_sd(test_sample, biased = TRUE)
+
+## -----------------------------------------------------------------------------
+capt_crisp = data.frame(weight = c(15.5, 16.2, 16.1, 15.8, 15.6, 16.0, 15.8, 15.9, 16.2))
+
+## -----------------------------------------------------------------------------
+x_bar = mean(capt_crisp$weight)
+s     = sd(capt_crisp$weight)
+mu_0  = 16
+n     = 9
+
+## -----------------------------------------------------------------------------
+t = (x_bar - mu_0) / (s / sqrt(n))
+t
+
+## -----------------------------------------------------------------------------
+pt(t, df = n - 1)
+
+## -----------------------------------------------------------------------------
+t.test(x = capt_crisp$weight, mu = 16, alternative = c(""less""), conf.level = 0.95)
+
+## -----------------------------------------------------------------------------
+capt_test_results = t.test(capt_crisp$weight, mu = 16,
+                           alternative = c(""two.sided""), conf.level = 0.95)
+
+## -----------------------------------------------------------------------------
+names(capt_test_results)
+
+## -----------------------------------------------------------------------------
+capt_test_results$conf.int
+
+## -----------------------------------------------------------------------------
+qt(0.975, df = 8)
+
+## -----------------------------------------------------------------------------
+c(mean(capt_crisp$weight) - qt(0.975, df = 8) * sd(capt_crisp$weight) / sqrt(9),
+  mean(capt_crisp$weight) + qt(0.975, df = 8) * sd(capt_crisp$weight) / sqrt(9))
+
+## -----------------------------------------------------------------------------
+x = c(70, 82, 78, 74, 94, 82)
+n = length(x)
+
+## -----------------------------------------------------------------------------
+y = c(64, 72, 60, 76, 72, 80, 84, 68)
+m = length(y)
+
+## -----------------------------------------------------------------------------
+x_bar = mean(x)
+s_x   = sd(x)
+y_bar = mean(y)
+s_y   = sd(y)
+
+## -----------------------------------------------------------------------------
+s_p = sqrt(((n - 1) * s_x ^ 2 + (m - 1) * s_y ^ 2) / (n + m - 2))
+
+## -----------------------------------------------------------------------------
+t = ((x_bar - y_bar) - 0) / (s_p * sqrt(1 / n + 1 / m))
+t
+
+## -----------------------------------------------------------------------------
+1 - pt(t, df = n + m - 2)
+
+## -----------------------------------------------------------------------------
+t.test(x, y, alternative = c(""greater""), var.equal = TRUE)
+
+## -----------------------------------------------------------------------------
+t_test_data = data.frame(values = c(x, y),
+                         group  = c(rep(""A"", length(x)), rep(""B"", length(y))))
+
+## -----------------------------------------------------------------------------
+t_test_data
+
+## -----------------------------------------------------------------------------
+t.test(values ~ group, data = t_test_data,
+       alternative = c(""greater""), var.equal = TRUE)
+
+## -----------------------------------------------------------------------------
+pnorm(2, mean = 1, sd = sqrt(0.32)) - pnorm(0, mean = 1, sd = sqrt(0.32))
+
+## -----------------------------------------------------------------------------
+set.seed(42)
+num_samples = 10000
+differences = rep(0, num_samples)
+
+## -----------------------------------------------------------------------------
+for (s in 1:num_samples) {
+  x1 = rnorm(n = 25, mean = 6, sd = 2)
+  x2 = rnorm(n = 25, mean = 5, sd = 2)
+  differences[s] = mean(x1) - mean(x2)
+}
+
+## -----------------------------------------------------------------------------
+mean(0 < differences & differences < 2)
+
+## -----------------------------------------------------------------------------
+hist(differences, breaks = 20, 
+     main   = ""Empirical Distribution of D"",
+     xlab   = ""Simulated Values of D"",
+     col    = ""dodgerblue"",
+     border = ""darkorange"")
+
+## -----------------------------------------------------------------------------
+mean(differences)
+var(differences)
+
+## -----------------------------------------------------------------------------
+set.seed(42)
+diffs = replicate(10000, mean(rnorm(25, 6, 2)) - mean(rnorm(25, 5, 2)))
+
+## -----------------------------------------------------------------------------
+mean(differences == diffs)
+
+## -----------------------------------------------------------------------------
+set.seed(1337)
+mu          = 10
+sample_size = 50
+samples     = 100000
+x_bars      = rep(0, samples)
+
+## -----------------------------------------------------------------------------
+for(i in 1:samples){
+  x_bars[i] = mean(rpois(sample_size, lambda = mu))
+}
+
+## -----------------------------------------------------------------------------
+x_bar_hist = hist(x_bars, breaks = 50, 
+                  main = ""Histogram of Sample Means"",
+                  xlab = ""Sample Means"")
+
+## -----------------------------------------------------------------------------
+c(mean(x_bars), mu)
+
+## -----------------------------------------------------------------------------
+c(var(x_bars), mu / sample_size)
+
+## -----------------------------------------------------------------------------
+c(sd(x_bars), sqrt(mu) / sqrt(sample_size))
+
+## -----------------------------------------------------------------------------
+mean(x_bars > mu - 2 * sqrt(mu) / sqrt(sample_size) &
+     x_bars < mu + 2 * sqrt(mu) / sqrt(sample_size))
+
+## -----------------------------------------------------------------------------
+shading = ifelse(x_bar_hist$breaks > mu - 2 * sqrt(mu) / sqrt(sample_size) & 
+                   x_bar_hist$breaks < mu + 2 * sqrt(mu) / sqrt(sample_size),
+                  ""darkorange"", ""dodgerblue"")
+
+x_bar_hist = hist(x_bars, breaks = 50, col = shading,
+                  main = ""Histogram of Sample Means, Two Standard Deviations"",
+                  xlab = ""Sample Means"")
+"
daviddalpiaz,appliedstats,c629888715baf34543c863944978d58b35dcfbba,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-11T22:05:15Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-11T22:05:15Z,fixed email.,index.Rmd,True,False,True,False,1,1,2,"---FILE: index.Rmd---
@@ -38,7 +38,7 @@ This book was originally (and currently) designed for use with STAT 420, Methods
 
 This book is under active development. When possible, it would be best to always access the text online to be sure you are using the most up-to-date version. (Also, the html version provides additional features such as changing text size, font, and colors.) If you are in need of a local copy, a [**pdf version** is continuously maintained](http://daviddalpiaz.github.io/appliedstats/applied_statistics.pdf).
 
-Since this book is under active development you may encounter errors ranging from typos to broken code to poorly explained topics. If you do, please let us know! Simply send an email and we'll make the changes ASAP. (<dalpiaz2@illinois.edu>) Or, if you know RMarkdown and are familiar with GitHub, [make a pull request and fix an issue yourself!](https://github.com/daviddalpiaz/appliedstats) (This process is partially automated by the edit button in the top-left corner of the html version.)
+Since this book is under active development you may encounter errors ranging from typos to broken code to poorly explained topics. If you do, please let us know! Simply send an email and we'll make the changes ASAP. (`dalpiaz2 AT illinois DOT edu`) Or, if you know RMarkdown and are familiar with GitHub, [make a pull request and fix an issue yourself!](https://github.com/daviddalpiaz/appliedstats) (This process is partially automated by the edit button in the top-left corner of the html version.)
 
 This text uses MathJax to render mathematical notation for the web. Occasionally, but rarely, a JavaScript error will prevent MathJax from rendering correctly. (In which case, will see the ""code"" instead of the expected mathematical equations.) From experience, this is almost always fixed by simply refreshing the page. You'll also notice that if you right-click any equation you can obtain the MathML Code (for copying into Microsoft Word) or the TeX command used to generate the equation.
 "
daviddalpiaz,appliedstats,3a011e64c8131bd40ae02adae9770951870fe9ae,daviddalpiaz,dalpiaz2@illinois.edu,2016-06-11T02:40:07Z,daviddalpiaz,dalpiaz2@illinois.edu,2016-06-11T02:40:07Z,many dunger suggestions and fixes,01-r-intro.Rmd,True,False,True,False,48,34,82,"---FILE: 01-r-intro.Rmd---
@@ -129,37 +129,40 @@ If you follow these steps, you will get your issue resolved much quicker, and po
 
 `R` comes with a number of built-in functions and datasets, but one of the main strengths of `R` as an open-source project is its package system. Packages add additional functions and data. Frequently if you want to do something in `R`, and it isn't available by default, there is a good chance that there is a package that will fulfill your needs.
 
-To install a package, use the `install.packages()` function.
+To install a package, use the `install.packages()` function. Think of this as buying a recipe book from the store, bringing it home, and putting it on your shelf.
 
 ```{r, eval = FALSE}
 install.packages(""ggplot2"")
 ```
 
-Once a package is installed, it must be loaded into your current `R` session before being used.
+Once a package is installed, it must be loaded into your current `R` session before being used. Think of this as taking the book off of the shelf and opening it up to read.
 
 ```{r, eval = FALSE}
 library(ggplot2)
 ```
 
+Once you close `R`, all the packages are closed and put back on the imaginary shelf. The next time you open `R`, you do not have to install the package again, but you do have to load any packages you intend to use by invoking `library()`.
+
+
 ### Data Types
 
 `R` has a number of basic data *types*.
 
 - Numeric
     - Also known as Double. The default type when dealing with numbers.
-    - Examples: `1`, `1.0`, `42.5`.
+    - Examples: `1`, `1.0`, `42.5`
 - Integer
-    - Examples: `1`, `2`, `42`
+    - Examples: `1L`, `2L`, `42L`
 - Complex
     - Example: `4 + 2i`
 - Logical
-    - Two possible values: `TRUE` and `FALSE`.
+    - Two possible values: `TRUE` and `FALSE`
     - You can also use `T` and `F`, but this is *not* recommended.
     - `NA` is also considered logical.
 - Character
     - Examples: `""a""`, `""Statistics""`, `""1 plus 2.""`
 
-`R` also has a number of basic data *structures*. Data structures can be either homogeneous (contain only a single data type) or heterogeneous. (Contain more than one data type.)
+`R` also has a number of basic data *structures*. A data structure is either homogeneous (all elements are of the same data type) or heterogeneous (elements can be of more than one data type).
 
 | Dimension | **Homogeneous** | **Heterogeneous** |
 |-----------|-----------------|-------------------|
@@ -171,7 +174,7 @@ library(ggplot2)
 
 Many operations in `R` make heavy use of **vectors**. Vectors in `R` are indexed starting at `1`. That is what the `[1]` in the output is indicating, that the first element of the row being displayed is the first element of the vector. Larger vectors will start additional rows with `[*]` where `*` is the index of the first element of the row.
 
-Possibly the most common way to create a vector in `R` is using the `c()` function, which is short for combine. As the name suggests, it combines a list of numbers separated by commas. 
+Possibly the most common way to create a vector in `R` is using the `c()` function, which is short for ""combine."""" As the name suggests, it combines a list of numbers separated by commas. 
 
 ```{r}
 c(1, 3, 5, 7, 8, 9)
@@ -217,13 +220,10 @@ x[c(1,3,4)]
 
 Lastly we see that we can subset based on a vector of indices.
 
-```{r}
-x = 1:10
-```
-
 One of the biggest strengths of `R` is its use of vectorized operations. (Frequently the lack of understanding of this concept leads of a belief that `R` is *slow*. `R` is not the fastest language, but it has a reputation for being slower than it really is.)
 
 ```{r}
+x = 1:10
 x + 1
 2 * x
 2 ^ x
@@ -255,7 +255,7 @@ If we want to create a sequence that isn't limited to integers and increasing by
 seq(from = 1.5, to = 4.2, by = 0.1)
 ```
 
-We will discuss functions later, but note here that `from`, `to` and `by` are optional.
+We will discuss functions in detail later, but note here that the input labels `from`, `to`, and `by` are optional.
 
 ```{r}
 seq(1.5, 4.2, 0.1)
@@ -264,7 +264,7 @@ seq(1.5, 4.2, 0.1)
 Another common operation to create a vector is `rep()`, which can repeat a single value a number of times.
 
 ```{r}
-rep(0.5, times = 10)
+rep(""A"", times = 10)
 ```
 
 Or, `rep()` can be used to repeat a vector a number of times.
@@ -294,14 +294,14 @@ c(x, rep(seq(1, 9, 2), 3), c(1, 2, 3), 42, 2:4)
 y
 ```
 
-- Central Tendency
+#### Central Tendency {-}
 
 ```{r}
 mean(y)
 median(y)
 ```
 
-- Spread
+#### Spread {-}
 
 ```{r}
 var(y)
@@ -314,7 +314,7 @@ range(y)
 
 ### Matrices
 
-`R` can also be used for **matrix** calculations. Matrices have rows and columns containing a single data type. (And unlike a data frame, which we will see later, the order is important.)
+`R` can also be used for **matrix** calculations. Matrices have rows and columns containing a single data type. In a matrix, the order of rows and columns is important. (This is not true of *data frames*, which we will see later.)
 
 Matrices can be created using the `matrix` function. 
 
@@ -325,6 +325,8 @@ X = matrix(x, nrow = 3, ncol = 3)
 X
 ```
 
+Note here that we are using two different variables: lower case `x`, which stores a vector and capital `X`, which stores a matrix. (Following the usual mathematical convention.) We can do this because `R` is case sensitive.
+
 By default the `matrix` function reorders a vector into columns, but we can also tell `R` to use rows instead.
 
 ```{r}
@@ -359,7 +361,7 @@ We can also use vectors to subset more than one row or column at a time. Here we
 X[2, c(1, 3)]
 ```
 
-Matrices can also be created by combining vectors as columns, using `cbind` or combining vectors as rows using `rbind`.
+Matrices can also be created by combining vectors as columns, using `cbind`, or combining vectors as rows, using `rbind`.
 
 ```{r}
 x = 1:9
@@ -393,7 +395,7 @@ X * Y
 X / Y
 ```
 
-Note that `X * Y` is not matrix multiplication. It is element by element multiplication. (Same for `X / Y`). Instead, matrix multiplication uses `%*%`. `t()` gives the transpose of a matrix, and `solve()` returns the inverse of a matrix.
+Note that `X * Y` is not matrix multiplication. It is element by element multiplication. (Same for `X / Y`). Instead, matrix multiplication uses `%*%`. Other matrix functions include `t()` which gives the transpose of a matrix and `solve()` which returns the inverse of a square matrix if it is invertible.
 
 ```{r}
 X %*% Y
@@ -466,15 +468,19 @@ example_data_from_csv = read.csv(""data/example_data.csv"")
 
 This particular line of code assumes that the file `example_data.csv` exists in a folder called `data` in your current working directory.
 
-Alternatively, we could use the ""Import Dataset"" feature in RStudio which can be found in the environment window. This process will automatically generate the code to import a file. The resulting code will be shown in the console window.
+Alternatively, we could use the ""Import Dataset"" feature in RStudio which can be found in the environment window. (By default, the top-right pane of RStudio.) 
 
 ![RStudio Import Screen](images/import.png)
 
+Once completed, this process will automatically generate the code to import a file. The resulting code will be shown in the console window.
+
+Earlier we looked at installing packages, in particular the `ggplot2` package. (A package for visualization. While not necessary for this course, it is quickly growing in popularity.) 
+
 ```{r, eval = FALSE}
 library(ggplot2)
 ```
 
-Earlier we looked at installing packages, in particular the `ggplot2` package. (A package for visualization. While not necessary for this course, it is quickly growing in popularity.) Inside the `ggplot2` package is a dataset called `mpg`. By loading the package using the `library()` function, we can now access `mpg`.
+Inside the `ggplot2` package is a dataset called `mpg`. By loading the package using the `library()` function, we can now access `mpg`.
 
 When using data from inside a package, there are three things we would generally like to do:
 
@@ -488,13 +494,13 @@ To look at the data, we have two useful commands: `head()` and `str()`.
 head(mpg, n = 10)
 ```
 
-`head()` will display the first `n` observations of the data frame.
+The function `head()` will display the first `n` observations of the data frame.
 
 ```{r}
 str(mpg)
 ```
 
-`str()` will display the ""structure"" of the data frame. It will display the number of **observations** and **variables**, list the variables, give the type of each variable, and show some elements of each variable.
+The function `str()` will display the ""structure"" of the data frame. It will display the number of **observations** and **variables**, list the variables, give the type of each variable, and show some elements of each variable.
 
 It is important to note that while matrices have rows and columns, data frames instead have observations and variables. When displayed in the console or viewer, each row is an observation and each column is a variable. However generally speaking, their order does not matter, it is simply a side-effect of how the data was entered or stored.
 
@@ -527,7 +533,9 @@ nrow(mpg)
 ncol(mpg)
 ```
 
-Subsetting data frames can work much like subsetting matrices using square brackets, `[,]`. Here, we find fuel efficient vehicles and only display `manufacturer`, `model` and `year`.
+Here `nrow()` is also the number of observations, which in most cases is the *sample size*.
+
+Subsetting data frames can work much like subsetting matrices using square brackets, `[,]`. Here, we find fuel efficient vehicles earning over 35 miles per gallon and only display `manufacturer`, `model` and `year`.
 
 ```{r}
 mpg[mpg$hwy > 35, c(""manufacturer"", ""model"", ""year"")]
@@ -577,23 +585,29 @@ hist(mpg$cty,
      border = ""darkorange"")
 ```
 
-Importantly, you should always be sure to label your axes and give the plot a title. `breaks` is an argument specific to `hist()` which controls how many bars `R` will use for the histogram. By default `R` will attempt to intelligently guess a good number of `breaks`, but as we can see here, it is sometimes useful to modify this yourself.
+Importantly, you should always be sure to label your axes and give the plot a title. The argument `breaks` is specific to `hist()`. Entering an integer will give a suggestion to `R` for how many bars to use for the histogram. By default `R` will attempt to intelligently guess a good number of `breaks`, but as we can see here, it is sometimes useful to modify this yourself.
 
 #### Boxplots
 
-To visualize the relationship between a numerical and categorical variable we will use a **boxplot**. In the `mpg` dataset, the `drv` variable takes a small, finite number of values. A car can only be front wheel drive, rear wheel drive, or 4 wheel drive. (FWD, RWD, or 4WD.)
+To visualize the relationship between a numerical and categorical variable, we will use a **boxplot**. In the `mpg` dataset, the `drv` variable takes a small, finite number of values. A car can only be front wheel drive, 4 wheel drive, or rear wheel drive.
 
 ```{r}
 unique(mpg$drv)
 ```
 
+First note that we can use a single boxplot as an alternative to a histogram for visualizing a single numerical variable. To do so in `R`, we use the `boxplot()` function.
+
 ```{r}
-boxplot(hwy ~ drv, data = mpg)
+boxplot(mpg$hwy)
 ```
 
-Here used the `boxplot()` command to create the boxplot. However, since we are now dealing with two variables, the syntax has changed, and we see the use of a `~` and also a `data = ` argument. This will be a syntax that is common to many functions we will use in this course.
+However, more often we will use boxplots to compare a numerical variable for different values of a categorical variable.
+
+```{r}
+boxplot(hwy ~ drv, data = mpg)
+```
 
-The `R` syntax `hwy ~ drv, data = mpg` reads ""Plot the `hwy` variable against the `drv` variable using the dataset `mpg`.""
+Here used the `boxplot()` command to create side-by-side boxplots. However, since we are now dealing with two variables, the syntax has changed. The `R` syntax `hwy ~ drv, data = mpg` reads ""Plot the `hwy` variable against the `drv` variable using the dataset `mpg`."" We see the use of a `~` (which specifies a formula) and also a `data = ` argument. This will be a syntax that is common to many functions we will use in this course. 
 
 ```{r}
 boxplot(hwy ~ drv, data = mpg,
@@ -610,7 +624,7 @@ Again, `boxplot()` has a number of additional arguments which have the ability t
 
 #### Scatterplots
 
-Lastly, to visualize the relationship between two numerical variables we will use a **scatterplot**. This can be done with the `plot()` function and the `~` syntax we just used with a boxplot. (`plot()` can also be used more generally, see the documentation for details.)
+Lastly, to visualize the relationship between two numeric variables we will use a **scatterplot**. This can be done with the `plot()` function and the `~` syntax we just used with a boxplot. (The function `plot()` can also be used more generally; see the documentation for details.)
 
 ```{r}
 plot(hwy ~ displ, data = mpg)
@@ -633,9 +647,9 @@ When working with different statistical distributions, we often want to make pro
 We typically want to know one of four things:
 
 * The density (pdf) at a particular value.
-* The distribution (cdf)at a particular value.
-* The quantile corresponding to a particular probability.
-* A random draw from a particular distribution.
+* The distribution (cdf) at a particular value.
+* The quantile value corresponding to a particular probability.
+* A random draw of values from a particular distribution.
 
 This used to be done with statistical tables printed in the back of textbooks. Now, `R` has functions for obtaining density, distribution, quantile and random values.
 
@@ -648,7 +662,7 @@ The general naming structure of the relevant `R` functions is:
 
 Note that `name` represents the name of the given distribution.
 
-For example, consider a random variable $X$ which is $N(\mu = 2, \sigma^2 = 25)$. (Note, we are parameterizing using the the variance $\sigma^2$. `R` however uses the standard deviation.)
+For example, consider a random variable $X$ which is $N(\mu = 2, \sigma^2 = 25)$. (Note, we are parameterizing using the variance $\sigma^2$. `R` however uses the standard deviation.)
 
 To calculate the value of the pdf at `x = 3`, that is, the height of the curve at `x = 3`, use:
 
@@ -690,7 +704,7 @@ Where `*` can be `d`, `p`, `q`, and `r`. Each distribution will have its own set
 dbinom(x = 6, size = 10, prob = 0.75)
 ```
 
-Also note that, when using the `dname` functions with discrete distributions, they are the pmf of the distribution. For example, the above command is $P(Y = 5)$ if $Y \sim b(n = 10, p = 0.75)$. (The probability of flipping an unfair coin `10` times and seeing `6` heads, if the probability of heads is `0.75`.)
+Also note that, when using the `dname` functions with discrete distributions, they are the pmf of the distribution. For example, the above command is $P(Y = 6)$ if $Y \sim b(n = 10, p = 0.75)$. (The probability of flipping an unfair coin `10` times and seeing `6` heads, if the probability of heads is `0.75`.)
 
 ## Programming Basics
 "
daviddalpiaz,appliedstats,29dab9c20a0c1422d61b4fec902af9a41b499321,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-10T19:09:45Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-10T19:09:45Z,removed external image link causing build error,images/cc.png;index.Rmd,True,False,True,False,1,1,2,"---FILE: index.Rmd---
@@ -72,6 +72,6 @@ sqrt(a ^ 2 + b ^ 2)
 
 ## License
 
-![](https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png)
+![](images/cc.png)
 
 This work is licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-nc-sa/4.0/)."
daviddalpiaz,appliedstats,b6b3caa71d17840a33011d33c4735c093a1e7e8f,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-10T18:58:09Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-10T18:58:09Z,fixed license,applied_statistics.R;index.Rmd,True,True,True,False,2,563,565,"---FILE: applied_statistics.R---
@@ -27,564 +27,3 @@ a = 3
 b = 4
 sqrt(a ^ 2 + b ^ 2)
 
-## -----------------------------------------------------------------------------
-3 + 2
-3 - 2
-3 * 2
-3 / 2
-
-## -----------------------------------------------------------------------------
-3 ^ 2
-2 ^ (-3)
-100 ^ (1 / 2)
-sqrt(1 / 2)
-exp(1)
-
-## -----------------------------------------------------------------------------
-pi
-exp(1)
-
-## -----------------------------------------------------------------------------
-log(10)           # natural log
-log10(1000)       # base 10 log
-log2(8)           # base 2 log
-log(16, base = 4) # base 4 log
-
-## -----------------------------------------------------------------------------
-sin(pi / 2)
-cos(0)
-
-## ---- eval = FALSE------------------------------------------------------------
-#  ?log
-#  ?sin
-#  ?paste
-#  ?lm
-
-## ---- eval = FALSE------------------------------------------------------------
-#  install.packages(""ggplot2"")
-
-## ---- eval = FALSE------------------------------------------------------------
-#  library(ggplot2)
-
-## -----------------------------------------------------------------------------
-c(1, 3, 5, 7, 8, 9)
-
-## -----------------------------------------------------------------------------
-x = c(1, 3, 5, 7, 8, 9)
-x
-
-## -----------------------------------------------------------------------------
-(y = 1:100)
-
-## -----------------------------------------------------------------------------
-x
-x[1]
-x[3]
-
-## -----------------------------------------------------------------------------
-x[-2]
-
-## -----------------------------------------------------------------------------
-x[1:3]
-x[c(1,3,4)]
-
-## -----------------------------------------------------------------------------
-x = 1:10
-
-## -----------------------------------------------------------------------------
-x + 1
-2 * x
-2 ^ x
-sqrt(x)
-log(x)
-
-## -----------------------------------------------------------------------------
-vec_1 = 1:10
-vec_2 = 1:1000
-vec_3 = 42
-
-## -----------------------------------------------------------------------------
-length(vec_1)
-length(vec_2)
-length(vec_3)
-
-## -----------------------------------------------------------------------------
-seq(from = 1.5, to = 4.2, by = 0.1)
-
-## -----------------------------------------------------------------------------
-seq(1.5, 4.2, 0.1)
-
-## -----------------------------------------------------------------------------
-rep(0.5, times = 10)
-
-## -----------------------------------------------------------------------------
-rep(x, times = 3)
-
-## -----------------------------------------------------------------------------
-c(x, rep(seq(1, 9, 2), 3), c(1, 2, 3), 42, 2:4)
-
-## -----------------------------------------------------------------------------
-y
-
-## -----------------------------------------------------------------------------
-mean(y)
-median(y)
-
-## -----------------------------------------------------------------------------
-var(y)
-sd(y)
-IQR(y)
-min(y)
-max(y)
-range(y)
-
-## -----------------------------------------------------------------------------
-x = 1:9
-x
-X = matrix(x, nrow = 3, ncol = 3)
-X
-
-## -----------------------------------------------------------------------------
-Y = matrix(x, nrow = 3, ncol = 3, byrow = TRUE)
-Y
-
-## -----------------------------------------------------------------------------
-Z = matrix(0, 2, 4)
-Z
-
-## -----------------------------------------------------------------------------
-X
-X[1, 2]
-
-## -----------------------------------------------------------------------------
-X[1, ]
-X[, 2]
-
-## -----------------------------------------------------------------------------
-X[2, c(1, 3)]
-
-## -----------------------------------------------------------------------------
-x = 1:9
-rev(x)
-rep(1, 9)
-
-## -----------------------------------------------------------------------------
-cbind(x, rev(x), rep(1, 9))
-
-## -----------------------------------------------------------------------------
-rbind(x, rev(x), rep(1, 9))
-
-## -----------------------------------------------------------------------------
-x = 1:9
-y = 9:1
-X = matrix(x, 3, 3)
-Y = matrix(y, 3, 3)
-X
-Y
-
-## -----------------------------------------------------------------------------
-X + Y
-X - Y
-X * Y
-X / Y
-
-## -----------------------------------------------------------------------------
-X %*% Y
-t(X)
-
-## -----------------------------------------------------------------------------
-Z = matrix(c(9, 2, -3, 2, 4, -2, -3, -2, 16), 3, byrow = TRUE)
-Z
-solve(Z)
-
-## -----------------------------------------------------------------------------
-X = matrix(1:6, 2, 3)
-X
-dim(X)
-rowSums(X)
-colSums(X)
-rowMeans(X)
-colMeans(X)
-
-## -----------------------------------------------------------------------------
-diag(Z)
-
-## -----------------------------------------------------------------------------
-diag(1:5)
-
-## -----------------------------------------------------------------------------
-diag(5)
-
-## -----------------------------------------------------------------------------
-example_data = data.frame(x = c(1, 3, 5, 7, 9, 1, 3, 5, 7, 9),
-                          y = rep(""Hello"", 10),
-                          z = rep(c(""TRUE"", ""FALSE""), 5))
-
-## -----------------------------------------------------------------------------
-example_data
-
-## ---- echo = FALSE------------------------------------------------------------
-write.csv(example_data, ""data/example_data.csv"", row.names = FALSE)
-
-## ---- eval = FALSE------------------------------------------------------------
-#  example_data_from_csv = read.csv(""data/example_data.csv"")
-
-## ---- eval = FALSE------------------------------------------------------------
-#  library(ggplot2)
-
-## -----------------------------------------------------------------------------
-head(mpg, n = 10)
-
-## -----------------------------------------------------------------------------
-str(mpg)
-
-## ---- eval = FALSE------------------------------------------------------------
-#  ?mpg
-
-## -----------------------------------------------------------------------------
-names(mpg)
-
-## -----------------------------------------------------------------------------
-mpg$year
-mpg$hwy
-
-## -----------------------------------------------------------------------------
-dim(mpg)
-nrow(mpg)
-ncol(mpg)
-
-## -----------------------------------------------------------------------------
-mpg[mpg$hwy > 35, c(""manufacturer"", ""model"", ""year"")]
-
-## ---- eval = FALSE------------------------------------------------------------
-#  subset(mpg, subset = hwy > 35, select = c(""manufacturer"", ""model"", ""year""))
-
-## ---- eval = FALSE------------------------------------------------------------
-#  library(dplyr)
-#  mpg %>% filter(hwy > 35) %>% select(manufacturer, model, year)
-
-## -----------------------------------------------------------------------------
-hist(mpg$cty)
-
-## -----------------------------------------------------------------------------
-hist(mpg$cty,
-     xlab   = ""Miles Per Gallon (City)"",
-     main   = ""Histogram of MPG (City)"",
-     breaks = 12,
-     col    = ""dodgerblue"",
-     border = ""darkorange"")
-
-## -----------------------------------------------------------------------------
-unique(mpg$drv)
-
-## -----------------------------------------------------------------------------
-boxplot(hwy ~ drv, data = mpg)
-
-## -----------------------------------------------------------------------------
-boxplot(hwy ~ drv, data = mpg,
-     xlab   = ""Drivetrain (f = FWD, r = RWD, 4 = 4WD)"",
-     ylab   = ""Miles Per Gallon (Highway)"",
-     main   = ""MPG (Highway) vs Drivetrain"",
-     pch    = 20,
-     cex    = 2,
-     col    = ""darkorange"",
-     border = ""dodgerblue"")
-
-## -----------------------------------------------------------------------------
-plot(hwy ~ displ, data = mpg)
-
-## -----------------------------------------------------------------------------
-plot(hwy ~ displ, data = mpg,
-     xlab = ""Engine Displacement (in Liters)"",
-     ylab = ""Miles Per Gallon (Highway)"",
-     main = ""MPG (Highway) vs Engine Displacement"",
-     pch  = 20,
-     cex  = 2,
-     col  = ""dodgerblue"")
-
-## -----------------------------------------------------------------------------
-dnorm(x = 3, mean = 2, sd = 5)
-
-## -----------------------------------------------------------------------------
-pnorm(q = 3, mean = 2, sd = 5)
-
-## -----------------------------------------------------------------------------
-qnorm(p = 0.975, mean = 2, sd = 5)
-
-## -----------------------------------------------------------------------------
-rnorm(n = 10, mean = 2, sd = 5)
-
-## -----------------------------------------------------------------------------
-dbinom(x = 6, size = 10, prob = 0.75)
-
-## -----------------------------------------------------------------------------
-heights = c(110, 120, 115, 136, 205, 156, 175)
-weights = c(64, 67, 62, 60, 77, 70, 66)
-
-## -----------------------------------------------------------------------------
-heights < 121
-heights < 121 | heights == 156
-
-## -----------------------------------------------------------------------------
-heights > 150
-heights[heights > 150]
-weights[heights > 150]
-
-## -----------------------------------------------------------------------------
-a = 1:10
-b = 2:4
-a < b
-
-## -----------------------------------------------------------------------------
-a > 5
-
-## -----------------------------------------------------------------------------
-1 * (a > 5)
-
-## -----------------------------------------------------------------------------
-sum(1 * (a > 5))
-
-## -----------------------------------------------------------------------------
-sum(a > 5)
-
-## ---- eval = FALSE------------------------------------------------------------
-#  if (...) {
-#    some R code
-#  } else {
-#    more R code
-#  }
-
-## -----------------------------------------------------------------------------
-x = 1
-y = 3
-if (x > y) {
-  z = x * y
-  print(""x is larger than y"")
-} else {
-  z = x + 5 * y
-  print(""x is less than or equal to y"")
-}
-
-z
-
-## -----------------------------------------------------------------------------
-ifelse(4 > 3, 1, 0)
-
-## -----------------------------------------------------------------------------
-fib = c(1, 1, 2, 3, 5, 8, 13, 21)
-ifelse(fib > 6, ""Foo"", ""Bar"")
-
-## -----------------------------------------------------------------------------
-x = 11:15
-for (i in 1:5) {
-  x[i] = x[i] * 2
-}
-
-x
-
-## -----------------------------------------------------------------------------
-x = 11:15
-x = x * 2
-x
-
-## ---- eval = FALSE------------------------------------------------------------
-#  function_name(arg1 = 10, arg2 = 20)
-
-## -----------------------------------------------------------------------------
-standardize = function(x) {
-  m = mean(x)
-  std = sd(x)
-  result = (x - m) / std
-  result
-}
-
-## -----------------------------------------------------------------------------
-(test_sample = rnorm(n = 10, mean = 2, sd = 5))
-standardize(x = test_sample)
-
-## -----------------------------------------------------------------------------
-standardize = function(x) {
-  (x - mean(x)) / sd(x)
-}
-
-## -----------------------------------------------------------------------------
-power_of_num = function(num, power = 2) {
-  num ^ power
-}
-
-## -----------------------------------------------------------------------------
-power_of_num(10)
-power_of_num(10, 2)
-power_of_num(num = 10, power = 2)
-power_of_num(power = 2, num = 10)
-
-
-## -----------------------------------------------------------------------------
-power_of_num(2, 10)
-
-## ---- eval = FALSE------------------------------------------------------------
-#  power_of_num(power = 5)
-
-## -----------------------------------------------------------------------------
-get_sd = function(x, biased = FALSE) {
-  n = length(x) - 1 * !biased
-  sqrt((1 / n) * sum((x - mean(x)) ^ 2))
-}
-
-## -----------------------------------------------------------------------------
-get_sd(test_sample)
-get_sd(test_sample, biased = FALSE)
-sd(test_sample)
-
-## -----------------------------------------------------------------------------
-get_sd(test_sample, biased = TRUE)
-
-## -----------------------------------------------------------------------------
-capt_crisp = data.frame(weight = c(15.5, 16.2, 16.1, 15.8, 15.6, 16.0, 15.8, 15.9, 16.2))
-
-## -----------------------------------------------------------------------------
-x_bar = mean(capt_crisp$weight)
-s     = sd(capt_crisp$weight)
-mu_0  = 16
-n     = 9
-
-## -----------------------------------------------------------------------------
-t = (x_bar - mu_0) / (s / sqrt(n))
-t
-
-## -----------------------------------------------------------------------------
-pt(t, df = n - 1)
-
-## -----------------------------------------------------------------------------
-t.test(x = capt_crisp$weight, mu = 16, alternative = c(""less""), conf.level = 0.95)
-
-## -----------------------------------------------------------------------------
-capt_test_results = t.test(capt_crisp$weight, mu = 16,
-                           alternative = c(""two.sided""), conf.level = 0.95)
-
-## -----------------------------------------------------------------------------
-names(capt_test_results)
-
-## -----------------------------------------------------------------------------
-capt_test_results$conf.int
-
-## -----------------------------------------------------------------------------
-qt(0.975, df = 8)
-
-## -----------------------------------------------------------------------------
-c(mean(capt_crisp$weight) - qt(0.975, df = 8) * sd(capt_crisp$weight) / sqrt(9),
-  mean(capt_crisp$weight) + qt(0.975, df = 8) * sd(capt_crisp$weight) / sqrt(9))
-
-## -----------------------------------------------------------------------------
-x = c(70, 82, 78, 74, 94, 82)
-n = length(x)
-
-## -----------------------------------------------------------------------------
-y = c(64, 72, 60, 76, 72, 80, 84, 68)
-m = length(y)
-
-## -----------------------------------------------------------------------------
-x_bar = mean(x)
-s_x   = sd(x)
-y_bar = mean(y)
-s_y   = sd(y)
-
-## -----------------------------------------------------------------------------
-s_p = sqrt(((n - 1) * s_x ^ 2 + (m - 1) * s_y ^ 2) / (n + m - 2))
-
-## -----------------------------------------------------------------------------
-t = ((x_bar - y_bar) - 0) / (s_p * sqrt(1 / n + 1 / m))
-t
-
-## -----------------------------------------------------------------------------
-1 - pt(t, df = n + m - 2)
-
-## -----------------------------------------------------------------------------
-t.test(x, y, alternative = c(""greater""), var.equal = TRUE)
-
-## -----------------------------------------------------------------------------
-t_test_data = data.frame(values = c(x, y),
-                         group  = c(rep(""A"", length(x)), rep(""B"", length(y))))
-
-## -----------------------------------------------------------------------------
-t_test_data
-
-## -----------------------------------------------------------------------------
-t.test(values ~ group, data = t_test_data,
-       alternative = c(""greater""), var.equal = TRUE)
-
-## -----------------------------------------------------------------------------
-pnorm(2, mean = 1, sd = sqrt(0.32)) - pnorm(0, mean = 1, sd = sqrt(0.32))
-
-## -----------------------------------------------------------------------------
-set.seed(42)
-num_samples = 10000
-differences = rep(0, num_samples)
-
-## -----------------------------------------------------------------------------
-for (s in 1:num_samples) {
-  x1 = rnorm(n = 25, mean = 6, sd = 2)
-  x2 = rnorm(n = 25, mean = 5, sd = 2)
-  differences[s] = mean(x1) - mean(x2)
-}
-
-## -----------------------------------------------------------------------------
-mean(0 < differences & differences < 2)
-
-## -----------------------------------------------------------------------------
-hist(differences, breaks = 20, 
-     main   = ""Empirical Distribution of D"",
-     xlab   = ""Simulated Values of D"",
-     col    = ""dodgerblue"",
-     border = ""darkorange"")
-
-## -----------------------------------------------------------------------------
-mean(differences)
-var(differences)
-
-## -----------------------------------------------------------------------------
-set.seed(42)
-diffs = replicate(10000, mean(rnorm(25, 6, 2)) - mean(rnorm(25, 5, 2)))
-
-## -----------------------------------------------------------------------------
-mean(differences == diffs)
-
-## -----------------------------------------------------------------------------
-set.seed(1337)
-mu          = 10
-sample_size = 50
-samples     = 100000
-x_bars      = rep(0, samples)
-
-## -----------------------------------------------------------------------------
-for(i in 1:samples){
-  x_bars[i] = mean(rpois(sample_size, lambda = mu))
-}
-
-## -----------------------------------------------------------------------------
-x_bar_hist = hist(x_bars, breaks = 50, 
-                  main = ""Histogram of Sample Means"",
-                  xlab = ""Sample Means"")
-
-## -----------------------------------------------------------------------------
-c(mean(x_bars), mu)
-
-## -----------------------------------------------------------------------------
-c(var(x_bars), var(mu) / sample_size)
-
-## -----------------------------------------------------------------------------
-c(sd(x_bars), sqrt(mu) / sqrt(sample_size))
-
-## -----------------------------------------------------------------------------
-mean(x_bars > mu - 2 * sqrt(mu) / sqrt(sample_size) &
-     x_bars < mu + 2 * sqrt(mu) / sqrt(sample_size))
-
-## -----------------------------------------------------------------------------
-shading = ifelse(x_bar_hist$breaks > mu - 2 * sqrt(mu) / sqrt(sample_size) & 
-                   x_bar_hist$breaks < mu + 2 * sqrt(mu) / sqrt(sample_size),
-                  ""darkorange"", ""dodgerblue"")
-
-x_bar_hist = hist(x_bars, breaks = 50, col = shading,
-                  main = ""Histogram of Sample Means, Two Standard Deviations"",
-                  xlab = ""Sample Means"")
-

---FILE: index.Rmd---
@@ -72,6 +72,6 @@ sqrt(a ^ 2 + b ^ 2)
 
 ## License
 
-This work is licensed under a <a rel=""license"" href=""http://creativecommons.org/licenses/by-nc-sa/4.0/"">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.<br />
+![](https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png)
 
-<center><a rel=""license"" href=""http://creativecommons.org/licenses/by-nc-sa/4.0/""><img alt=""Creative Commons License"" style=""border-width:0"" src=""https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"" /></a></center>
+This work is licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-nc-sa/4.0/)."
daviddalpiaz,appliedstats,e5ba9bc8118c2037f6e10750834b44a95d87b9b6,daviddalpiaz,dalpiaz2@illinois.edu,2016-06-10T03:51:00Z,daviddalpiaz,dalpiaz2@illinois.edu,2016-06-10T03:51:00Z,"small fixes: wording, citl link preferences, subsubsubheader usage.",01-r-intro.Rmd;applied_statistics.R,True,False,True,False,625,9,634,"---FILE: 01-r-intro.Rmd---
@@ -18,11 +18,12 @@ After reading this chapter you will be able to:
 
 `R` is both a programming language and software environment for statistical computing, which is *free* and *open-source*. To get started, you will need to install two pieces of software:
 
-- `R`, the actual programming language, which can be installed from <http://cran.r-project.org/>
-    - Chose your operating system, and select the most recent version. (As of writing, 3.3.0.)
-- RStudio, an excellent IDE for working with `R`, which can be obtained from <http://www.rstudio.com/> (Note, you must have `R` installed to use RStudio. RStudio is simply a way to interact with `R`.)
+- [`R`, the actual programming language.](http://cran.r-project.org/)
+    - Chose your operating system, and select the most recent version, `r paste0(version$major, ""."" ,version$minor)`.
+- [RStudio, an excellent IDE for working with `R`.](http://www.rstudio.com/)
+    - Note, you must have `R` installed to use RStudio. RStudio is simply an interface used to interact with `R`.
 
-`R`'s popularity is on the rise, and everyday it becomes a better tool for statistical analysis. It even generated this book! (A skill you will learn in this course.) There are many good resources for learning `R`. They are not necessary for this course, but you may find them useful if you would like a deeper understanding of `R`:
+The popularity of `R` is on the rise, and everyday it becomes a better tool for statistical analysis. It even generated this book! (A skill you will learn in this course.) There are many good resources for learning `R`. They are not necessary for this course, but you may find them useful if you would like a deeper understanding of `R`:
 
 - [Try R](http://tryr.codeschool.com/) from Code School.
     - An interactive introduction to the basics of `R`. Could be very useful for getting up to speed on `R`'s syntax.
@@ -61,7 +62,7 @@ For this course, our main deviation from these two guides is the use of `=` in p
 
 To get started, we'll use `R` like a simple calculator. Note, in `R` the `#` symbol is used for comments. In this book, lines which begin with two such symbols, `##`, indicate output.
 
-**Addition, Subtraction, Multiplication and Division:**
+#### Addition, Subtraction, Multiplication and Division {-}
 
 ```{r}
 3 + 2
@@ -70,7 +71,7 @@ To get started, we'll use `R` like a simple calculator. Note, in `R` the `#` sym
 3 / 2
 ```
 
-**Exponents:**
+#### Exponents  {-}
 
 ```{r}
 3 ^ 2
@@ -80,14 +81,14 @@ sqrt(1 / 2)
 exp(1)
 ```
 
-**Mathematical Constants:**
+#### Mathematical Constants  {-}
 
 ```{r}
 pi
 exp(1)
 ```
 
-**Logarithms:**
+#### Logarithms  {-}
 
 ```{r}
 log(10)           # natural log
@@ -96,7 +97,7 @@ log2(8)           # base 2 log
 log(16, base = 4) # base 4 log
 ```
 
-**Trigonometry:**
+#### Trigonometry  {-}
 
 ```{r}
 sin(pi / 2)

---FILE: applied_statistics.R---
@@ -27,3 +27,618 @@ a = 3
 b = 4
 sqrt(a ^ 2 + b ^ 2)
 
+## -----------------------------------------------------------------------------
+3 + 2
+3 - 2
+3 * 2
+3 / 2
+
+## -----------------------------------------------------------------------------
+3 ^ 2
+2 ^ (-3)
+100 ^ (1 / 2)
+sqrt(1 / 2)
+exp(1)
+
+## -----------------------------------------------------------------------------
+pi
+exp(1)
+
+## -----------------------------------------------------------------------------
+log(10)           # natural log
+log10(1000)       # base 10 log
+log2(8)           # base 2 log
+log(16, base = 4) # base 4 log
+
+## -----------------------------------------------------------------------------
+sin(pi / 2)
+cos(0)
+
+## ---- eval = FALSE------------------------------------------------------------
+#  ?log
+#  ?sin
+#  ?paste
+#  ?lm
+
+## ---- eval = FALSE------------------------------------------------------------
+#  install.packages(""ggplot2"")
+
+## ---- eval = FALSE------------------------------------------------------------
+#  library(ggplot2)
+
+## -----------------------------------------------------------------------------
+c(1, 3, 5, 7, 8, 9)
+
+## -----------------------------------------------------------------------------
+x = c(1, 3, 5, 7, 8, 9)
+x
+
+## -----------------------------------------------------------------------------
+(y = 1:100)
+
+## -----------------------------------------------------------------------------
+x
+x[1]
+x[3]
+
+## -----------------------------------------------------------------------------
+x[-2]
+
+## -----------------------------------------------------------------------------
+x[1:3]
+x[c(1,3,4)]
+
+## -----------------------------------------------------------------------------
+x = 1:10
+
+## -----------------------------------------------------------------------------
+x + 1
+2 * x
+2 ^ x
+sqrt(x)
+log(x)
+
+## -----------------------------------------------------------------------------
+vec_1 = 1:10
+vec_2 = 1:1000
+vec_3 = 42
+
+## -----------------------------------------------------------------------------
+length(vec_1)
+length(vec_2)
+length(vec_3)
+
+## -----------------------------------------------------------------------------
+seq(from = 1.5, to = 4.2, by = 0.1)
+
+## -----------------------------------------------------------------------------
+seq(1.5, 4.2, 0.1)
+
+## -----------------------------------------------------------------------------
+rep(0.5, times = 10)
+
+## -----------------------------------------------------------------------------
+rep(x, times = 3)
+
+## -----------------------------------------------------------------------------
+c(x, rep(seq(1, 9, 2), 3), c(1, 2, 3), 42, 2:4)
+
+## -----------------------------------------------------------------------------
+y
+
+## -----------------------------------------------------------------------------
+mean(y)
+median(y)
+
+## -----------------------------------------------------------------------------
+var(y)
+sd(y)
+IQR(y)
+min(y)
+max(y)
+range(y)
+
+## -----------------------------------------------------------------------------
+x = 1:9
+x
+X = matrix(x, nrow = 3, ncol = 3)
+X
+
+## -----------------------------------------------------------------------------
+Y = matrix(x, nrow = 3, ncol = 3, byrow = TRUE)
+Y
+
+## -----------------------------------------------------------------------------
+Z = matrix(0, 2, 4)
+Z
+
+## -----------------------------------------------------------------------------
+X
+X[1, 2]
+
+## -----------------------------------------------------------------------------
+X[1, ]
+X[, 2]
+
+## -----------------------------------------------------------------------------
+X[2, c(1, 3)]
+
+## -----------------------------------------------------------------------------
+x = 1:9
+rev(x)
+rep(1, 9)
+
+## -----------------------------------------------------------------------------
+cbind(x, rev(x), rep(1, 9))
+
+## -----------------------------------------------------------------------------
+rbind(x, rev(x), rep(1, 9))
+
+## -----------------------------------------------------------------------------
+x = 1:9
+y = 9:1
+X = matrix(x, 3, 3)
+Y = matrix(y, 3, 3)
+X
+Y
+
+## -----------------------------------------------------------------------------
+X + Y
+X - Y
+X * Y
+X / Y
+
+## -----------------------------------------------------------------------------
+X %*% Y
+t(X)
+
+## -----------------------------------------------------------------------------
+Z = matrix(c(9, 2, -3, 2, 4, -2, -3, -2, 16), 3, byrow = TRUE)
+Z
+solve(Z)
+
+## -----------------------------------------------------------------------------
+X = matrix(1:6, 2, 3)
+X
+dim(X)
+rowSums(X)
+colSums(X)
+rowMeans(X)
+colMeans(X)
+
+## -----------------------------------------------------------------------------
+diag(Z)
+
+## -----------------------------------------------------------------------------
+diag(1:5)
+
+## -----------------------------------------------------------------------------
+diag(5)
+
+## -----------------------------------------------------------------------------
+example_data = data.frame(x = c(1, 3, 5, 7, 9, 1, 3, 5, 7, 9),
+                          y = rep(""Hello"", 10),
+                          z = rep(c(""TRUE"", ""FALSE""), 5))
+
+## -----------------------------------------------------------------------------
+example_data
+
+## ---- echo = FALSE------------------------------------------------------------
+write.csv(example_data, ""data/example_data.csv"", row.names = FALSE)
+
+## ---- eval = FALSE------------------------------------------------------------
+#  example_data_from_csv = read.csv(""data/example_data.csv"")
+
+## ---- eval = FALSE------------------------------------------------------------
+#  library(ggplot2)
+
+## -----------------------------------------------------------------------------
+head(mpg, n = 10)
+
+## -----------------------------------------------------------------------------
+str(mpg)
+
+## ---- eval = FALSE------------------------------------------------------------
+#  ?mpg
+
+## -----------------------------------------------------------------------------
+names(mpg)
+
+## -----------------------------------------------------------------------------
+mpg$year
+mpg$hwy
+
+## -----------------------------------------------------------------------------
+dim(mpg)
+nrow(mpg)
+ncol(mpg)
+
+## -----------------------------------------------------------------------------
+mpg[mpg$hwy > 35, c(""manufacturer"", ""model"", ""year"")]
+
+## ---- eval = FALSE------------------------------------------------------------
+#  subset(mpg, subset = hwy > 35, select = c(""manufacturer"", ""model"", ""year""))
+
+## ---- eval = FALSE------------------------------------------------------------
+#  library(dplyr)
+#  mpg %>% filter(hwy > 35) %>% select(manufacturer, model, year)
+
+## -----------------------------------------------------------------------------
+hist(mpg$cty)
+
+## -----------------------------------------------------------------------------
+hist(mpg$cty,
+     xlab   = ""Miles Per Gallon (City)"",
+     main   = ""Histogram of MPG (City)"",
+     breaks = 12,
+     col    = ""dodgerblue"",
+     border = ""darkorange"")
+
+## -----------------------------------------------------------------------------
+unique(mpg$drv)
+
+## -----------------------------------------------------------------------------
+boxplot(hwy ~ drv, data = mpg)
+
+## -----------------------------------------------------------------------------
+boxplot(hwy ~ drv, data = mpg,
+     xlab   = ""Drivetrain (f = FWD, r = RWD, 4 = 4WD)"",
+     ylab   = ""Miles Per Gallon (Highway)"",
+     main   = ""MPG (Highway) vs Drivetrain"",
+     pch    = 20,
+     cex    = 2,
+     col    = ""darkorange"",
+     border = ""dodgerblue"")
+
+## -----------------------------------------------------------------------------
+plot(hwy ~ displ, data = mpg)
+
+## -----------------------------------------------------------------------------
+plot(hwy ~ displ, data = mpg,
+     xlab = ""Engine Displacement (in Liters)"",
+     ylab = ""Miles Per Gallon (Highway)"",
+     main = ""MPG (Highway) vs Engine Displacement"",
+     pch  = 20,
+     cex  = 2,
+     col  = ""dodgerblue"")
+
+## -----------------------------------------------------------------------------
+dnorm(x = 3, mean = 2, sd = 5)
+
+## -----------------------------------------------------------------------------
+pnorm(q = 3, mean = 2, sd = 5)
+
+## -----------------------------------------------------------------------------
+qnorm(p = 0.975, mean = 2, sd = 5)
+
+## -----------------------------------------------------------------------------
+rnorm(n = 10, mean = 2, sd = 5)
+
+## -----------------------------------------------------------------------------
+dbinom(x = 6, size = 10, prob = 0.75)
+
+## -----------------------------------------------------------------------------
+heights = c(110, 120, 115, 136, 205, 156, 175)
+weights = c(64, 67, 62, 60, 77, 70, 66)
+
+## -----------------------------------------------------------------------------
+heights < 121
+heights < 121 | heights == 156
+
+## -----------------------------------------------------------------------------
+heights > 150
+heights[heights > 150]
+weights[heights > 150]
+
+## -----------------------------------------------------------------------------
+a = 1:10
+b = 2:4
+a < b
+
+## -----------------------------------------------------------------------------
+a > 5
+
+## -----------------------------------------------------------------------------
+1 * (a > 5)
+
+## -----------------------------------------------------------------------------
+sum(1 * (a > 5))
+
+## -----------------------------------------------------------------------------
+sum(a > 5)
+
+## ---- eval = FALSE------------------------------------------------------------
+#  if (...) {
+#    some R code
+#  } else {
+#    more R code
+#  }
+
+## -----------------------------------------------------------------------------
+x = 1
+y = 3
+if (x > y) {
+  z = x * y
+  print(""x is larger than y"")
+} else {
+  z = x + 5 * y
+  print(""x is less than or equal to y"")
+}
+
+z
+
+## -----------------------------------------------------------------------------
+ifelse(4 > 3, 1, 0)
+
+## -----------------------------------------------------------------------------
+fib = c(1, 1, 2, 3, 5, 8, 13, 21)
+ifelse(fib > 6, ""Foo"", ""Bar"")
+
+## -----------------------------------------------------------------------------
+x = 11:15
+for (i in 1:5) {
+  x[i] = x[i] * 2
+}
+
+x
+
+## -----------------------------------------------------------------------------
+x = 11:15
+x = x * 2
+x
+
+## ---- eval = FALSE------------------------------------------------------------
+#  function_name(arg1 = 10, arg2 = 20)
+
+## -----------------------------------------------------------------------------
+standardize = function(x) {
+  m = mean(x)
+  std = sd(x)
+  result = (x - m) / std
+  result
+}
+
+## -----------------------------------------------------------------------------
+(test_sample = rnorm(n = 10, mean = 2, sd = 5))
+standardize(x = test_sample)
+
+## -----------------------------------------------------------------------------
+standardize = function(x) {
+  (x - mean(x)) / sd(x)
+}
+
+## -----------------------------------------------------------------------------
+power_of_num = function(num, power = 2) {
+  num ^ power
+}
+
+## -----------------------------------------------------------------------------
+power_of_num(10)
+power_of_num(10, 2)
+power_of_num(num = 10, power = 2)
+power_of_num(power = 2, num = 10)
+
+
+## -----------------------------------------------------------------------------
+power_of_num(2, 10)
+
+## ---- eval = FALSE------------------------------------------------------------
+#  power_of_num(power = 5)
+
+## -----------------------------------------------------------------------------
+get_sd = function(x, biased = FALSE) {
+  n = length(x) - 1 * !biased
+  sqrt((1 / n) * sum((x - mean(x)) ^ 2))
+}
+
+## -----------------------------------------------------------------------------
+get_sd(test_sample)
+get_sd(test_sample, biased = FALSE)
+sd(test_sample)
+
+## -----------------------------------------------------------------------------
+get_sd(test_sample, biased = TRUE)
+
+## -----------------------------------------------------------------------------
+capt_crisp = data.frame(weight = c(15.5, 16.2, 16.1, 15.8, 15.6, 16.0, 15.8, 15.9, 16.2))
+
+## -----------------------------------------------------------------------------
+x_bar = mean(capt_crisp$weight)
+s     = sd(capt_crisp$weight)
+mu_0  = 16
+n     = 9
+
+## -----------------------------------------------------------------------------
+t = (x_bar - mu_0) / (s / sqrt(n))
+t
+
+## -----------------------------------------------------------------------------
+pt(t, df = n - 1)
+
+## -----------------------------------------------------------------------------
+t.test(x = capt_crisp$weight, mu = 16, alternative = c(""less""), conf.level = 0.95)
+
+## -----------------------------------------------------------------------------
+capt_test_results = t.test(capt_crisp$weight, mu = 16,
+                           alternative = c(""two.sided""), conf.level = 0.95)
+
+## -----------------------------------------------------------------------------
+names(capt_test_results)
+
+## -----------------------------------------------------------------------------
+capt_test_results$conf.int
+
+## -----------------------------------------------------------------------------
+qt(0.975, df = 8)
+
+## -----------------------------------------------------------------------------
+c(mean(capt_crisp$weight) - qt(0.975, df = 8) * sd(capt_crisp$weight) / sqrt(9),
+  mean(capt_crisp$weight) + qt(0.975, df = 8) * sd(capt_crisp$weight) / sqrt(9))
+
+## -----------------------------------------------------------------------------
+x = c(70, 82, 78, 74, 94, 82)
+n = length(x)
+
+## -----------------------------------------------------------------------------
+y = c(64, 72, 60, 76, 72, 80, 84, 68)
+m = length(y)
+
+## -----------------------------------------------------------------------------
+x_bar = mean(x)
+s_x   = sd(x)
+y_bar = mean(y)
+s_y   = sd(y)
+
+## -----------------------------------------------------------------------------
+s_p = sqrt(((n - 1) * s_x ^ 2 + (m - 1) * s_y ^ 2) / (n + m - 2))
+
+## -----------------------------------------------------------------------------
+t = ((x_bar - y_bar) - 0) / (s_p * sqrt(1 / n + 1 / m))
+t
+
+## -----------------------------------------------------------------------------
+1 - pt(t, df = n + m - 2)
+
+## -----------------------------------------------------------------------------
+t.test(x, y, alternative = c(""greater""), var.equal = TRUE)
+
+## -----------------------------------------------------------------------------
+t_test_data = data.frame(values = c(x, y),
+                         group  = c(rep(""A"", length(x)), rep(""B"", length(y))))
+
+## -----------------------------------------------------------------------------
+t_test_data
+
+## -----------------------------------------------------------------------------
+t.test(values ~ group, data = t_test_data,
+       alternative = c(""greater""), var.equal = TRUE)
+
+## -----------------------------------------------------------------------------
+pnorm(2, mean = 1, sd = sqrt(0.32)) - pnorm(0, mean = 1, sd = sqrt(0.32))
+
+## -----------------------------------------------------------------------------
+set.seed(42)
+num_samples = 10000
+differences = rep(0, num_samples)
+
+## -----------------------------------------------------------------------------
+for (s in 1:num_samples) {
+  x1 = rnorm(n = 25, mean = 6, sd = 2)
+  x2 = rnorm(n = 25, mean = 5, sd = 2)
+  differences[s] = mean(x1) - mean(x2)
+}
+
+## -----------------------------------------------------------------------------
+mean(0 < differences & differences < 2)
+
+## -----------------------------------------------------------------------------
+hist(differences, breaks = 20, 
+     main   = ""Empirical Distribution of D"",
+     xlab   = ""Simulated Values of D"",
+     col    = ""dodgerblue"",
+     border = ""darkorange"")
+
+## -----------------------------------------------------------------------------
+mean(differences)
+var(differences)
+
+## -----------------------------------------------------------------------------
+set.seed(42)
+diffs = replicate(10000, mean(rnorm(25, 6, 2)) - mean(rnorm(25, 5, 2)))
+
+## -----------------------------------------------------------------------------
+mean(differences == diffs)
+
+## -----------------------------------------------------------------------------
+set.seed(1337)
+mu          = 10
+sample_size = 50
+samples     = 100000
+x_bars      = rep(0, samples)
+
+## -----------------------------------------------------------------------------
+for(i in 1:samples){
+  x_bars[i] = mean(rpois(sample_size, lambda = mu))
+}
+
+## -----------------------------------------------------------------------------
+x_bar_hist = hist(x_bars, breaks = 50, 
+                  main = ""Histogram of Sample Means"",
+                  xlab = ""Sample Means"")
+
+## -----------------------------------------------------------------------------
+c(mean(x_bars), mu)
+
+## -----------------------------------------------------------------------------
+c(sd(x_bars), sqrt(mu) / sqrt(sample_size))
+
+## -----------------------------------------------------------------------------
+mean(x_bars > mu - 2 * sqrt(mu) / sqrt(sample_size) &
+     x_bars < mu + 2 * sqrt(mu) / sqrt(sample_size))
+
+## -----------------------------------------------------------------------------
+shading = ifelse(x_bar_hist$breaks > mu - 2 * sqrt(mu) / sqrt(sample_size) & 
+                   x_bar_hist$breaks < mu + 2 * sqrt(mu) / sqrt(sample_size),
+                  ""darkorange"", ""dodgerblue"")
+
+x_bar_hist = hist(x_bars, breaks = 50, col = shading,
+                  main = ""Histogram of Sample Means, Two Standard Deviations"",
+                  xlab = ""Sample Means"")
+
+## -----------------------------------------------------------------------------
+momma_leona = data.frame(students = c(2, 6, 8, 8, 12, 16, 20, 20, 22, 26), 
+                          sales = c(58, 105, 88, 118, 117, 137, 157, 169, 149, 202))
+
+## -----------------------------------------------------------------------------
+names(momma_leona)
+
+## -----------------------------------------------------------------------------
+momma_leona$sales
+momma_leona$students
+
+## -----------------------------------------------------------------------------
+dim(momma_leona)
+nrow(momma_leona)
+ncol(momma_leona)
+
+## -----------------------------------------------------------------------------
+str(momma_leona)
+
+## ---- echo = FALSE------------------------------------------------------------
+write.csv(momma_leona, ""data/momma_leona.csv"", row.names = FALSE)
+
+## -----------------------------------------------------------------------------
+plot(momma_leona$students, momma_leona$sales)
+
+## -----------------------------------------------------------------------------
+plot(momma_leona$students, momma_leona$sales,
+     xlab = ""Students (in 1000s)"",
+     ylab = ""Sales (in $1000s)"",
+     main = ""Quarterly Sales vs Student Population"",
+     pch  = 20,
+     cex  = 2,
+     col  = ""dodgerblue"")
+
+## -----------------------------------------------------------------------------
+momma_leona_model = lm(sales ~ students, data = momma_leona)
+
+## -----------------------------------------------------------------------------
+plot(momma_leona$students, momma_leona$sales,
+     xlab = ""Students (in 1000s)"",
+     ylab = ""Sales (in $1000s)"",
+     main = ""Quarterly Sales vs Student Population"",
+     pch  = 20,
+     cex  = 2,
+     col  = ""dodgerblue"")
+abline(momma_leona_model, lwd = 2, col = ""darkorange"")
+
+## -----------------------------------------------------------------------------
+plot(sales ~ students, data = momma_leona,
+     xlab = ""Students (in 1000s)"",
+     ylab = ""Sales (in $1000s)"",
+     main = ""Quarterly Sales vs Student Population"",
+     pch  = 20,
+     cex  = 2,
+     col  = ""dodgerblue"")
+abline(momma_leona_model, lwd = 2, col = ""darkorange"")
+"
daviddalpiaz,appliedstats,1c6c6ff8b911fb057214c735344f3b821c91a364,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-09T22:20:55Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-09T22:20:55Z,fixed link formatting,01-r-intro.Rmd,True,False,True,False,2,2,4,"---FILE: 01-r-intro.Rmd---
@@ -33,7 +33,7 @@ After reading this chapter you will be able to:
 - [R Markdown](http://rmarkdown.rstudio.com/) from RStudio.
     - Reference materials for RMarkdown.
 - [The Art of `R` Programming](https://www.nostarch.com/artofr.htm) by Norman Matloff.
-    - Gentle introduction to the programming side of `R`. (Whereas we will focus more on the data analysis side.) A free electronic version is available through the [Illinois library](http://vufind.carli.illinois.edu/vf-uiu/Record/uiu_6955421).
+    - Gentle introduction to the programming side of `R`. (Whereas we will focus more on the data analysis side.) A [free electronic version](http://vufind.carli.illinois.edu/vf-uiu/Record/uiu_6955421) is available through the Illinois library.
 - [Advanced `R`](http://adv-r.had.co.nz/) by Hadley Wickham.
     - From the author of several extremely popular `R` packages. Good follow-up to The Art of `R` Programming. (And more up-to-date material.)
 - [`R` for Data Science](http://r4ds.had.co.nz/) by Hadley Wickham and Garrett Grolemund
@@ -46,7 +46,7 @@ RStudio has a large number of useful keyboard shortcuts. A list of these can be
 - On Windows: `Alt` + `Shift` + `K`
 - On Mac:  `Option` + `Shift` + `K`
 
-The RStudio team has developed a number of ""cheatsheets"" for working with both `R` and RStudio which can be found [here](https://www.rstudio.com/resources/cheatsheets/) or from the help menu inside of RStudio. [This one for Base `R` in particular](http://www.rstudio.com/wp-content/uploads/2016/05/base-r.pdf) will summarize many of the concepts in this document.
+The RStudio team has developed [a number of ""cheatsheets""](https://www.rstudio.com/resources/cheatsheets/) for working with both `R` and RStudio. [This particular cheatseet for Base `R`](http://www.rstudio.com/wp-content/uploads/2016/05/base-r.pdf) will summarize many of the concepts in this document.
 
 When programming, it is often a good practice to follow a style guide. (Where do spaces go? Tabs or spaces? Underscores or CamelCase when naming variables?) No style guide is ""correct"" but it helps to be aware of what others do. The more import thing is to be consistent within your own code.
 "
daviddalpiaz,appliedstats,b5e0dcce51302ed9e534cd7729dfaf2b7eac0c4e,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-07T22:03:28Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-07T22:03:28Z,Title fix. Content updates.,01-r-intro.Rmd;index.Rmd,True,False,True,False,181,141,322,"---FILE: 01-r-intro.Rmd---
@@ -36,7 +36,7 @@ RStudio has a large number of useful keyboard shortcuts. A list of these can be
 
 The RStudio team has developed a number of ""cheatsheets"" for working with both `R` and RStudio which can be found [here](https://www.rstudio.com/resources/cheatsheets/) or from the help menu inside of RStudio. [This one for Base `R` in particular](http://www.rstudio.com/wp-content/uploads/2016/05/base-r.pdf) will summarize many of the concepts in this document.
 
-When programming, it is often a good practice to follow a style guide. (Where do spaces go? Tabs of spaces? Underscores of CamelCase when naming variables?) No style guide is ""correct"" but it helps to be aware of what some others do. The more import thing is to be consistent with yourself.
+When programming, it is often a good practice to follow a style guide. (Where do spaces go? Tabs or spaces? Underscores or CamelCase when naming variables?) No style guide is ""correct"" but it helps to be aware of what some others do. The more import thing is to be consistent with yourself.
 
 - [Hadley Wickham Style Guide](http://adv-r.had.co.nz/Style.html) from [Advanced `R`](http://adv-r.had.co.nz/)
 - [Google Style Guide](https://google.github.io/styleguide/Rguide.xml)
@@ -102,7 +102,7 @@ In using `R` as a calculator, we have seen a number of functions. `sqrt()`, `exp
 ?lm
 ```
 
-Frequently one of the most difficult things to do when learning `R` is asking for help. First, you need to decide to ask for help, then you need to know *how* to ask for help. Your very first line of defense should be to Google your error message or a short description of your issue. (The ability to solve problems using this method is quickly becoming an extremely valuable skill.) If that fails, and it eventually will, you should ask for help. There are a number of things you should include when emailing an instructor, or posting to a help website such as <http://stats.stackexchange.com/>.
+Frequently one of the most difficult things to do when learning `R` is asking for help. First, you need to decide to ask for help, then you need to know *how* to ask for help. Your very first line of defense should be to Google your error message or a short description of your issue. (The ability to solve problems using this method is quickly becoming an extremely valuable skill.) If that fails, and it eventually will, you should ask for help. There are a number of things you should include when emailing an instructor, or posting to a help website such as [Stack Exchange](http://stats.stackexchange.com/).
 
 - Describe what you expect the code to do.
 - State the end goal you are trying to achieve. (Sometimes what you expect the code to do, is not what you want to actually do.)
@@ -122,7 +122,7 @@ To install a package, use the `install.packages()` function.
 install.packages(""ggplot2"")
 ```
 
-Once a package is install, it must be loaded in your current `R` session before being used.
+Once a package is installed, it must be loaded into your current `R` session before being used.
 
 ```{r, eval = FALSE}
 library(ggplot2)
@@ -220,12 +220,15 @@ log(x)
 
 We see that when a function like `log()` is called on a vector `x`, a vector is returned which has applied the function to each element of the vector  `x`.
 
-The length of a vector can be obtained with the `length()` function.
-
 ```{r}
 vec_1 = 1:10
 vec_2 = 1:1000
 vec_3 = 42
+```
+
+The length of a vector can be obtained with the `length()` function.
+
+```{r}
 length(vec_1)
 length(vec_2)
 length(vec_3)
@@ -402,7 +405,7 @@ rowMeans(X)
 colMeans(X)
 ```
 
-The `diag()` function can be used in a number of way. We can extract the diagonal of a matrix.
+The `diag()` function can be used in a number of ways. We can extract the diagonal of a matrix.
 
 ```{r}
 diag(Z)
@@ -448,6 +451,8 @@ write.csv(example_data, ""data/example_data.csv"", row.names = FALSE)
 example_data_from_csv = read.csv(""data/example_data.csv"")
 ```
 
+TODO: Note about header and sep and wd and folder struct. rproj?
+
 Alternatively, we could use the ""Import Dataset"" feature in RStudio which can be found in the environment window. This process will automatically generate the code to import a file. The resulting code will be shown in the console window.
 
 ```{r, eval = FALSE}
@@ -486,7 +491,7 @@ To understand more about the data set, we use the `?` operator to pull up the do
 ?mpg
 ```
 
-`R` has a number of functions for quickly working with and extract basic information from data frames. To quickly obtain a vector of the variable names, we use the `names()` function.
+`R` has a number of functions for quickly working with and extracting basic information from data frames. To quickly obtain a vector of the variable names, we use the `names()` function.
 
 ```{r}
 names(mpg)
@@ -507,6 +512,8 @@ nrow(mpg)
 ncol(mpg)
 ```
 
+TODO: subsetting. dpylr?
+
 ### Plotting
 
 Now that we have some data to work with, and we have learned about the data at the most basic level, our next tasks is to visualize the data. Often, a proper visualization can illuminate features of the data that can inform further analysis.
@@ -529,8 +536,8 @@ The histogram function has a number of parameters which can be changed to make o
 
 ```{r}
 hist(mpg$cty,
-     xlab   = ""City Miles Per Gallon"",
-     main   = ""Histogram of City MPG"",
+     xlab   = ""Miles Per Gallon (City)"",
+     main   = ""Histogram of MPG (City)"",
      breaks = 12,
      col    = ""dodgerblue"",
      border = ""darkorange"")
@@ -557,8 +564,8 @@ The `R` syntax `hwy ~ drv, data = mpg` reads ""Plot the `hwy` variable against th
 ```{r}
 boxplot(hwy ~ drv, data = mpg,
      xlab   = ""Drivetrain (f = FWD, r = RWD, 4 = 4WD)"",
-     ylab   = ""Highway Miles Per Gallon"",
-     main   = ""Highway MPG vs Engine Displacement"",
+     ylab   = ""Miles Per Gallon (Highway)"",
+     main   = ""MPG (Highway) vs Drivetrain"",
      pch    = 20,
      cex    = 2,
      col    = ""darkorange"",
@@ -578,8 +585,8 @@ plot(hwy ~ displ, data = mpg)
 ```{r}
 plot(hwy ~ displ, data = mpg,
      xlab = ""Engine Displacement (in Liters)"",
-     ylab = ""Highway Miles Per Gallon"",
-     main = ""Highway MPG vs Engine Displacement"",
+     ylab = ""Miles Per Gallon (Highway)"",
+     main = ""MPG (Highway) vs Engine Displacement"",
      pch  = 20,
      cex  = 2,
      col  = ""dodgerblue"")
@@ -591,18 +598,18 @@ When working with different statistical distributions, we often want to make pro
 
 We typically want to know one of four things:
 
-* The density (pdf) value at a particular value of `x`.
-* The distribution (cdf) value at a particular value of `x`.
-* The quantile `x` value corresponding to a particular probability.
-* A random value from a particular distribution.
+* The density (pdf) at a particular value.
+* The distribution (cdf)at a particular value.
+* The quantile corresponding to a particular probability.
+* A random draw from a particular distribution.
 
-This used to be done with statistical tables printed in the back of textbooks. Now, R has functions for obtaining density, distribution, quantile and random values.
+This used to be done with statistical tables printed in the back of textbooks. Now, `R` has functions for obtaining density, distribution, quantile and random values.
 
-The general naming structure of the relevant R functions is:
+The general naming structure of the relevant `R` functions is:
 
-* `dname` calculates density (pdf) value at input `x`.
-* `pname` calculates distribution (cdf) value at input `x`.
-* `qname` calculates the quantile `x` value at input probability.
+* `dname` calculates density (pdf) at input `x`.
+* `pname` calculates distribution (cdf) at input `x`.
+* `qname` calculates the quantile at an input probability.
 * `rname` generates a random draw from a particular distribution.
 
 Note that `name` represents the name of the given distribution.
@@ -674,14 +681,14 @@ heights = c(110, 120, 115, 136, 205, 156, 175)
 weights = c(64, 67, 62, 60, 77, 70, 66)
 ```
 
-First, using the `<` operator, when can which `heights` are less than `121`. Further, we could also find which `heights` are less than `121` or exactly equal to `156.`
+First, using the `<` operator, when can find which `heights` are less than `121`. Further, we could also find which `heights` are less than `121` or exactly equal to `156.`
 
 ```{r}
 heights < 121
 heights < 121 | heights == 156
 ```
 
-Often, a vector of logical values is useful for subsetting a vector. For example we can find the `heights` that are larger than `150`. We can then use the resulting vector to subset the `heights` vector, thus actually returning the `heights` that are above `150`, instead of a vector of which values are about `150`. Here we also obtain the `weights` corresponding to `heights` above `150`.
+Often, a vector of logical values is useful for subsetting a vector. For example we can find the `heights` that are larger than `150`. We can then use the resulting vector to subset the `heights` vector, thus actually returning the `heights` that are above `150`, instead of a vector of which values are above `150`. Here we also obtain the `weights` corresponding to `heights` above `150`.
 
 ```{r}
 heights > 150
@@ -699,7 +706,7 @@ a < b
 
 What happened here? `R` still performed the operation, but it also gives us a warning. (To perform the operation automatically made `b` longer by repeating `b` as needed.)
 
-The one exception to this behavior is comparing to a vector length `1`. `R` does not warning us in this case, as comparing each value of a vector to a single value is a common operation that is usually reasonable to perform.
+The one exception to this behavior is comparing to a vector of length `1`. `R` does not warn us in this case, as comparing each value of a vector to a single value is a common operation that is usually reasonable to perform.
 
 ```{r}
 a > 5
@@ -711,7 +718,7 @@ Often we will want to convert `TRUE` and `FALSE` values to `1` and `0`. To do th
 1 * (a > 5)
 ```
 
-If we then sum the resulting vector, we have essentially count the number of elements of `a` that are larger than `5.`
+If we then sum the resulting vector, we have essentially counted the number of elements of `a` that are larger than `5.`
 
 ```{r}
 sum(1 * (a > 5))
@@ -782,8 +789,7 @@ x
 So far we have been using functions, but haven't actually discussed some of their details.
 
 TODO: use
-TODO: arguments
-TODO: defaults (order?)
+TODO: arguments, defaults (order?)
 
 Lastly, we can write our own functions in `R`. For example, we often like to ""standardize"" variables, that is, subtracting the sample mean, and dividing by the sample standard deviation,
 
@@ -793,6 +799,8 @@ Lastly, we can write our own functions in `R`. For example, we often like to ""st
 
 In `R` we would write a function to do this.
 
+TODO: syntax (argument, {}, return)
+
 ```{r}
 standardize = function(x) {
   m = mean(x)
@@ -802,55 +810,73 @@ standardize = function(x) {
 }
 ```
 
+To test our function, we will take a random sample of size `n = 10` from a normal distribution with a mean of `2` and a standard deviation of `5`.
+
+TODO: set.seed()
+
 ```{r}
-(x = rnorm(10, mean = 2, sd = 5))
-standardize(x)
+set.seed(42)
+(test_sample = rnorm(10, mean = 2, sd = 5))
+standardize(x = test_sample)
+```
+
+```{r}
+result = standardize(x = test_sample)
+mean(result)
+sd(result)
 ```
 
-This function could be written much more succinctly, simply performing all the operations on one line and immediately return the result, without storing any of the intermediate results.
+This function could be written much more succinctly, simply performing all the operations on one line and immediately returning the result, without storing any of the intermediate results.
 
 ```{r}
 standardize = function(x) {
   (x - mean(x)) / sd(x)
 }
 ```
 
-TODO: function with arguments, control flow, if based return, how return works. compare these two?
+To illustrate a function with a default argument, we will write a function that calculates sample standard deviation two ways.
+
+By default is will calculate the unbiased estimate of $\sigma$, which we will call $s$.
 
 \[
 s = \sqrt{\frac{1}{n - 1}\sum_{i=1}^{n}(x - \bar{x})^2}
 \]
 
+It will also have the ability to return the biased estimate (base on maximum likilhood) which we will call $\hat{\sigma}$.
+
 \[
 \hat{\sigma} = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(x - \bar{x})^2}
 \]
 
 ```{r}
 get_sd = function(x, biased = FALSE) {
-  n = length(x) - 1 * biased
+  n = length(x) - 1 * !biased
   sqrt((1 / n) * sum((x - mean(x)) ^ 2))
 }
 ```
 
-TODO: explain 1 * biased
+```{r}
+get_sd(test_sample)
+get_sd(test_sample, biased = FALSE)
+sd(test_sample)
+get_sd(test_sample, biased = TRUE)
+```
 
 ## Hypothesis Tests in `R`
 
-TODO: make all data data frames
-
 ### One Sample t-Test: Review
 
 Suppose $x_{i} \sim \mathrm{N}(\mu,\sigma^{2})$ and we want to test $H_{0}: \mu = \mu_{0}$ versus $H_{1}: \mu \neq \mu_{0}.$
 
 Assuming $\sigma$ is unknown, we use the one-sample Student's $t$ test statistic:
 
 \[
-t = \displaystyle\frac{\bar{x}-\mu_{0}}{s/\sqrt{n}}\sim t_{n-1}
+t = \displaystyle\frac{\bar{x}-\mu_{0}}{s/\sqrt{n}} \sim t_{n-1}
 \]
 
-where $\bar{x} = \displaystyle\frac{\sum_{i=1}^{n}x_{i}}{n}$ and $s = \sqrt{\displaystyle\frac{\sum_{i=1}^{n}(x_{i}-\bar{x})^{2}}{n-1}}$
+where $\bar{x} = \displaystyle\frac{\sum_{i=1}^{n}x_{i}}{n}$ and $s = \sqrt{\displaystyle\frac{1}{n - 1}\sum_{i=1}^{n}(x - \bar{x})^2}$
 
-A $100(1 - \alpha)$\% CI for $\mu$ is given by
+A $100(1 - \alpha)$\% confidence interval for $\mu$ is given by
 
 \[
 \bar{x} \pm t_{n-1}^{(\alpha/2)}\frac{s}{\sqrt{n}}
@@ -860,79 +886,98 @@ where $t_{n-1}^{(\alpha/2)}$ is the critical value such that $P\left(t>t_{n-1}^{
 
 ### One Sample t-Test: Example
 
-TODO: change data to a data frame? or at least a vector
+Suppose a store sells ""16 ounce"" boxes of *Captain Crisp* cereal. A random sample of 9 boxes was taken and weighed. The weight in ounces are stored in the data frame `capt_crisp`.
+
+```{r}
+capt_crisp = data.frame(weight = c(15.5, 16.2, 16.1, 15.8, 15.6, 16.0, 15.8, 15.9, 16.2))
+```
+
+The company that makes *Captain Crisp* cereal claims that the average weight of a box is at least 16 ounces. We will assume the weight of cereal in a box is normally distributed and use a 0.05 level of significance to test the company's claim.
 
-A store sells ""16 ounce"" boxes of *Captain Crisp* cereal. A random sample of 9 boxes was taken and weighed. The results were
+To test $H_{0}: \mu \geq 16$ versus $H_{1}: \mu < 16$, the test statistic is
 
 \[
-15.5 \quad 16.2  \quad 16.1  \quad 15.8  \quad 15.6  \quad 16.0  \quad 15.8  \quad 15.9  \quad 16.2
+t = \displaystyle\frac{\bar{x}-\mu_{0}}{s/\sqrt{n}}
 \]
 
-ounces. Assume the weight of cereal in a box is normally distributed.
+The sample mean $\bar{x}$ and the sample standard deviation $s$ can be easily computed using `R`. We also create variables for the hypothesized mean and the sample size.
 
-**a)** Compute the sample mean $\bar{x}$ and the sample standard deviation $s$.
+```{r}
+x_bar = mean(capt_crisp$weight)
+s     = sd(capt_crisp$weight)
+mu_0  = 16
+n     = 9
+```
 
-\[
-\begin{split}
-\bar{x} &= \frac{1}{n}\sum_{i=1}^{n}x_{i}=(1/9)(15.5+\cdots+16.2) = (1/9)(143.1)=\textbf{15.9}\\
-s^{2} &=\frac{1}{n-1}\sum_{i=1}^{n}(x_{i}-\bar{x})^{2}=\frac{1}{n-1}\left[\sum_{i=1}^{n}x_{i}^{2} - n \bar{x}^{2}\right]\\
-&= (1/8)\left[2275.79 - 9(15.9^2)\right] = (1/8)(0.5) = 0.0625\\
-s &= \sqrt{0.0625} = \textbf{0.25}
-\end{split}
-\]
+We can then easily compute the test statistic.
 
 ```{r}
-x = c(15.5, 16.2, 16.1, 15.8, 15.6, 16.0, 15.8, 15.9, 16.2)
-mean(x)
-sd(x)
+t = (x_bar - mu_0) / (s / sqrt(n))
+t
 ```
 
-**b)** Construct a $95\%$ confidence interval for the overall average weight of boxes of *Captain Crisp* cereal.
+Under the null hypothesis, the test statistic has a $t$ distribution with n - 1 degrees of freedom, in this case `r n - 1`.
 
-$t_{n-1}^{(\alpha/2)}=t_{8}^{(0.025)}=2.306$, so the 95\% CI for the average weight of a cereal box is: 
+To complete the test, we need to obtain the p-value of the test. Since this is a one-sided test with a less-than alternative, we need to area to the left of `r t` for a $t$ distribution with `r n - 1` degrees of freedom. That is,
 
 \[
-\begin{split}
-15.9 \pm 2.306\sqrt{\frac{0.0625}{9}} & = [15.708, 16.092]
-\end{split}
+P(t_{`r n - 1`} < `r t`)
 \]
 
-Or, in R:
+```{r}
+pt(t, df = n - 1)
+```
+
+We now have the p-value of our test, which is greater than our significance level (0.05) so we fail to reject the null hypothesis.
+
+Alternatively, this entire process could have been completed using one line of `R` code.
 
 ```{r}
-t.test(x, alternative = c(""two.sided""), conf.level = 0.95)
+t.test(capt_crisp$weight, mu = 16, alternative = c(""less""), conf.level = 0.95)
 ```
 
-Or if we only wanted to display the interval:
+We supply `R` with the data, the hyopthesized value of $\mu$, the alternative and the confidence level. `R` then returns a wealth of information including:
+
+- The value of the test statistic.
+- The degrees of freedom of distribution under the null hyopthesis.
+- The p-value of the test.
+- The confidence interval which corresponds to the test.
+- An estimate of $\mu$.
+
+Since the test was one-sided, `R` returned a one-sided confidence interval. If instead we wanted a two-sided interval for the mean weight of boxes of *Captain Crisp* cereal we could modify our code.
 
 ```{r}
-t.test(x, alternative = c(""two.sided""), conf.level = 0.95)$conf.int
+capt_test_results = t.test(capt_crisp$weight, mu = 16,
+                           alternative = c(""two.sided""), conf.level = 0.95)
 ```
 
-Or, we could calculate it ""by hand"" in `R`.
+This time we have stored the results. By doing so, we can directly access portions of the ouput from `t.test()`. To see what information is availible we use the `names()` function.
 
 ```{r}
-qt(0.975, 8)
-c(mean(x) - qt(0.975, 8) * sd(x) / sqrt(9),
-  mean(x) + qt(0.975, 8) * sd(x) / sqrt(9))
+names(capt_test_results)
 ```
 
-**c)** The company that makes *Captain Crisp* cereal claims that the average weight of its box is at least 16 ounces. Use a 0.05 level of significance to test the company's claim. What is the p-value of this test?
+We are insteaded in a confidence interval.
 
-To test $H_{0}: \mu \geq 16$ versus $H_{1}: \mu < 16$, the test statistic is
+```{r}
+capt_test_results$conf.int
+```
 
-\[
-\begin{split}
-T=\frac{15.9-16}{\sqrt{0.0625/9}}=-1.2
-\end{split}
-\]
+Let's check this interval ""by hand."" The one piece of information we are missing is the critical value,  $t_{n-1}^{(\alpha/2)} = t_{8}^{(0.025)}$, which can be calculated in `R` using the `qt()` function.
+
+```{r}
+qt(0.975, df = 8)
+```
 
-We know that $T\sim t_{8}$, so the rejection reject is $T < -t_{n-1}^{(\alpha)}=-t_{8}^{(0.05)}= -1.860.$
+So, the 95\% CI for the mean weight of a cereal box is calculated by pluggin into the forumula,
 
-Therefore, we **do NOT reject the null hypothesis** at the $\alpha=.05$ level. We could have also bounded the p-value of the test using the $t$ table.
+\[
+\bar{x} \pm t_{n-1}^{(\alpha/2)}\frac{s}{\sqrt{n}}
+\]
 
 ```{r}
-t.test(x, mu = 16, alternative = c(""less""), conf.level = 0.95)
+c(mean(capt_crisp$weight) - qt(0.975, df = 8) * sd(capt_crisp$weight) / sqrt(9),
+  mean(capt_crisp$weight) + qt(0.975, df = 8) * sd(capt_crisp$weight) / sqrt(9))
 ```
 
 ### Two Sample t-Test: Review
@@ -944,7 +989,7 @@ Want to test $H_{0}: \mu_{x}-\mu_{y} = \mu_{0}$ versus $H_{1}: \mu_{x}-\mu_{y} \
 Assuming $\sigma$ is unknown, use the two-sample Student's $t$ test statistic:
 
 \[
-T=\frac{(\bar{x}-\bar{y})-\mu_{0}}{s_{p}\sqrt{\frac{1}{n}+\frac{1}{m}}}\sim t_{n+m-2}
+t = \frac{(\bar{x}-\bar{y})-\mu_{0}}{s_{p}\sqrt{\frac{1}{n}+\frac{1}{m}}}\sim t_{n+m-2}
 \]
 
 where $\displaystyle\bar{x}=\frac{\sum_{i=1}^{n}x_{i}}{n}$, $\displaystyle\bar{y}=\frac{\sum_{i=1}^{m}y_{i}}{m}$, and $s_p^2 = \displaystyle\frac{(n-1)s_1^2+(m-1)s_2^2}{n+m-2}$
@@ -961,78 +1006,82 @@ where $t_{n+m-2}^{(\alpha/2)}$ is critical $t_{n+m-2}$ value such that $P\left(T
 
 Assume that the distributions of $X$ and $Y$ are $\mathrm{N}(\mu_{1},\sigma^{2})$ and $\mathrm{N}(\mu_{2},\sigma^{2})$, respectively. Given the $n = 6$ observations of $X$,
 
-\[
-70, \qquad 82, \qquad 78, \qquad 74, \qquad 94, \qquad 82 
-\]
+```{r}
+x = c(70, 82, 78, 74, 94, 82)
+n = length(x)
+```
 
 and the $m = 8$ observations of $Y$,
 
-\[
-64, \qquad 72, \qquad 60, \qquad 76, \qquad 72, \qquad 80, \qquad 84, \qquad 68
-\]
+```{r}
+y = c(64, 72, 60, 76, 72, 80, 84, 68)
+m = length(y)
+```
 
-find the p-value for the test $H_{0}: \mu_{1} = \mu_{2}$ versus $H_{1}: \mu_{1} > \mu_{2}$.
+we will test $H_{0}: \mu_{1} = \mu_{2}$ versus $H_{1}: \mu_{1} > \mu_{2}$.
 
-First, note that the sample means and variances are given by
+First, note that we can calculate the sample means and standard deviations.
 
-\[
-\begin{split}
-\bar{x} &= (1/6)\textstyle\sum_{i=1}^{6}x_{i}=(1/6)480=80\\
-\bar{y} &= (1/8)\textstyle\sum_{i=1}^{8}y_{i}=(1/8)576=72\\
-s_{x}^{2} &= (1/5)\textstyle\sum_{i=1}^{6}(x_{i}-\bar{x})^{2}=(1/5)344=68.8\\
-s_{y}^{2} &= (1/7)\textstyle\sum_{i=1}^{8}(y_{i}-\bar{y})^{2}=(1/7)448=64\\
-\end{split}
-\]
+```{r}
+x_bar = mean(x)
+s_x   = sd(x)
+y_bar = mean(y)
+s_y   = sd(y)
+```
 
-which implies that the pooled variance estimate is given by
+We can then calculate the pooled standard deviation.
 
 \[
-\begin{split}
-s_{p}^{2} &= \frac{(n-1)s_{x}^{2}+(m-1)s_{y}^{2}}{n+m-2}\\
-&= \frac{344+448}{12}\\
-&=66
-\end{split}
+s_{p}^{2} = \sqrt{\frac{(n-1)s_{x}^{2}+(m-1)s_{y}^{2}}{n+m-2}}
 \]
 
+```{r}
+s_p = sqrt(((n - 1) * s_x ^ 2 + (m - 1) * s_y ^ 2) / (n + m - 2))
+```
 
 Thus, the relevant $t$ test statistic is given by
 
 \[
-\begin{split}
-T &= \frac{(\bar{x}-\bar{y})-\mu_{0}}{s_{p}\sqrt{\frac{1}{n}+\frac{1}{m}}}\\
-&= \frac{(80-72)-0}{\sqrt{66}\sqrt{\frac{1}{6}+\frac{1}{8}}}\\
-&= 1.82337
-\end{split}
+t = \frac{(\bar{x}-\bar{y})-\mu_{0}}{s_{p}\sqrt{\frac{1}{n}+\frac{1}{m}}}
 \]
 
-Note that $T\sim t_{12}$, so 
-
-\[
-0.025 < p-value < 0.05
-\]
+```{r}
+t = ((x_bar - y_bar) - 0) / (s_p * sqrt(1 / n + 1 / m))
+t
+```
 
-since 
+Note that $t \sim t_{n + m - 2} = t_{`r n + m - 2`}$, so we can calculate the p-value, which is
 
 \[
-t_{12}^{(0.025)} = 1.782< 1.82337 < t_{12}^{(0.05)} = 2.179.
+P(t_{`r n + m - 2`} > `r t`)
 \]
 
+```{r}
+1 - pt(t, df = n + m - 2)
+```
+
+But, then again, we could have simply performed this test in one line of `R`.
 
 ```{r}
-x = c(70, 82, 78, 74, 94, 82)
-y = c(64, 72, 60, 76, 72, 80, 84, 68)
 t.test(x, y, alternative = c(""greater""), var.equal = TRUE)
 ```
 
+Recall that a two-sample $t$-test can be done with or without an equal variance assumption. Here `var.equal = TRUE` tells `R` we would like to perform the test under the equal variance assumption.
+
+TODO: store in df and use formula?
 
-Or, performing the calculations `by hand' in `R`:
 ```{r}
-sPooled2 = ((6 - 1) * var(x) + (8 - 1) * var(y)) / (6 + 8 - 2)
-sPooled2
+t_test_data = data.frame(values = c(x, y),
+                         group  = c(rep(""A"", length(x)), rep(""B"", length(y))))
+```
 
-test_stat = (mean(x) - mean(y)) / sqrt(sPooled2 * (1 / 6 + 1 / 8))
-test_stat
-1 - pt(test_stat, 6 + 8 - 2)
+```{r}
+t_test_data
+```
+
+```{r}
+t.test(values ~ group, data = t_test_data,
+       alternative = c(""greater""), var.equal = TRUE)
 ```
 
 ## Simulation
@@ -1098,31 +1147,24 @@ Which can then be calculated using `R` without a need to first standardize, or u
 pnorm(2, mean = 1, sd = sqrt(0.32)) - pnorm(0, mean = 1, sd = sqrt(0.32))
 ```
 
-An alternative approach, would be to **simulate** observations of $D$ then use the **empirical distribution** to calculate the probability.
+An alternative approach, would be to **simulate** a large number of observations of $D$ then use the **empirical distribution** to calculate the probability.
 
-TODO: split chunks and add narration
 TODO: discuss rname functions. (or earlier?)
 
 Generate $s = 10000$ samples for each of group 1 and group 2. For each of the  $10000$  samples,  compute $d_s = \bar{x}_{1s} - \bar{x}_{2s}$. 
 
-Make a histogram for the $10000$ values of  $d$. 
-
-What is the proportion of values of  $d$  (among the 10000 values of  $d$  generated) that are between 0 and 2?
+What is the proportion of values of $d$ (among the 10000 values of $d$ generated) that are between 0 and 2?
 
 ```{r}
 set.seed(42)
-mu1         = 6
-mu2         = 5
-std         = 2
-sample_size = 25
-samples     = 10000
-differences = rep(0, samples)
+num_samples = 10000
+differences = rep(0, num_samples)
 ```
 
 ```{r}
-for (i in 1:samples) {
-  x1 = rnorm(sample_size, mu1, std)
-  x2 = rnorm(sample_size, mu2, std)
+for (i in 1:num_samples) {
+  x1 = rnorm(25, mean = 6, sd = 2)
+  x2 = rnorm(25, mean = 5, sd = 2)
   differences[i] = mean(x1) - mean(x2)
 }
 ```
@@ -1133,17 +1175,15 @@ mean(0 < differences & differences < 2)
 
 ```{r}
 hist(differences, breaks = 20, 
-     main = ""Empirical Distribution of D"",
+     main   = ""Empirical Distribution of D"",
      xlab   = ""Simulated Values of D"",
      col    = ""dodgerblue"",
      border = ""darkorange"")
 ```
 
 ### Distribution of a Sample Mean
 
-TODO: Move in front of paired?
-TODO: split chunks and add narration
-TODO: set.seed
+For another example of simulation, we will simulate observations from a Poisson distribution, and examine the emperical distribution of these observatoins.
 
 ```{r}
 set.seed(42)
@@ -1175,7 +1215,7 @@ c(sd(x_bars), sqrt(mu) / sqrt(sample_size))
 
 ```{r}
 mean(x_bars > mu - 2 * sqrt(mu) / sqrt(sample_size) &
-       x_bars < mu + 2 * sqrt(mu) / sqrt(sample_size))
+     x_bars < mu + 2 * sqrt(mu) / sqrt(sample_size))
 ```
 
 ```{r}

---FILE: index.Rmd---
@@ -1,5 +1,5 @@
 --- 
-title: ""Applied Statistics""
+title: ""Applied Statistics with `R`""
 author: ""David Dalpiaz""
 date: ""`r Sys.Date()`""
 knit: ""bookdown::render_book"""
daviddalpiaz,appliedstats,f0bd8dce1255be17594e5c090c990a980d77e199,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-07T14:59:10Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-07T14:59:10Z,Removed purl in attempt to fix travis build fail.,index.Rmd,True,False,True,False,3,3,6,"---FILE: index.Rmd---
@@ -17,9 +17,9 @@ github-repo: daviddalpiaz/appliedstats
 require(knitr)
 read_chunk('r_book.R')
 options(scipen = 8, width = 65)
-knit_hooks$set(purl = hook_purl)
-opts_template$set(nopurl = list(purl = FALSE))
-opts_template$set(dopurl = list(purl = TRUE))
+# knit_hooks$set(purl = hook_purl)
+# opts_template$set(nopurl = list(purl = FALSE))
+# opts_template$set(dopurl = list(purl = TRUE))
 ```
 
 ```{r load_packages, message=FALSE,echo=FALSE, warning=FALSE}"
daviddalpiaz,appliedstats,11c37e07ece2b8ecebc3d585630dbd79637cb1d4,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-06T20:40:25Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-06T20:40:25Z,Contet. (Mostly plotting.) Fixes. Data.,01-r-intro.Rmd;course/todo.Rmd;data/example_data.csv,True,False,True,False,174,63,237,"---FILE: 01-r-intro.Rmd---
@@ -29,13 +29,17 @@
 
 RStudio has a large number of useful keyboard shortcuts. A list of these can be found using a keyboard shortcut, the keyboard shortcut to rule them all:
 
-- On Windows: `Option` + `Shift` + `K`
-- On Mac:  `Alt` + `Shift` + `K`
+- On Windows: `Alt` + `Shift` + `K`
+- On Mac:  `Option` + `Shift` + `K`
 
 The RStudio team has developed a number of ""cheatsheets"" for working with both `R` and RStudio which can be found [here](https://www.rstudio.com/resources/cheatsheets/) or from the help menu inside of RStudio. [This one for Base `R` in particular](http://www.rstudio.com/wp-content/uploads/2016/05/base-r.pdf) will summarize many of the concepts in this document.
 
-http://adv-r.had.co.nz/Style.html
-https://google.github.io/styleguide/Rguide.xml
+When programing, it is often a good practice to follow a style guide. (Where do spaces go? Tabs of spaces? Underscores of CamelCase when naming variables?) No style guide is ""correct"" but it helps to be aware of what some others do. The more import thing is to be consistent with yourself.
+
+- [Hadley Wickham Style Guide](http://adv-r.had.co.nz/Style.html) from [Advanced `R`](http://adv-r.had.co.nz/)
+- [Google Style Guide](https://google.github.io/styleguide/Rguide.xml)
+
+For this course, our main deviation from these two guides is the use of `=` in place of `<-`. (More on that later.)
 
 ## `R` Basics
 
@@ -89,37 +93,37 @@ cos(0)
 
 In using `R` as a calculator, we have seen a number of functions. `sqrt()`, `exp()`, `log()` and `sin()` are all `R` functions. To get documentation about a function in `R`, simply put a question mark in front of the function name and RStudio will display the documentation, for example: 
 
-```{r, eval = F}
+```{r, eval = FALSE}
 ?log
 ?sin
 ?paste
 ?lm
 ```
 
-Frequently one of the most difficult things to do when learning `R` is asking for help. First, you need to decide to ask for help, then you need to know *how* to ask for help. Your very first line of defense should be to Google your error message or a short description of your issue. (The ability to solve problems using this method is quickly becoming an extremely valuable skill.) If that fails, and it eventually will, you should ask for help. There are a number of things you should include when emailing an instructor, or posting to a help website such as http://stats.stackexchange.com/.
+Frequently one of the most difficult things to do when learning `R` is asking for help. First, you need to decide to ask for help, then you need to know *how* to ask for help. Your very first line of defense should be to Google your error message or a short description of your issue. (The ability to solve problems using this method is quickly becoming an extremely valuable skill.) If that fails, and it eventually will, you should ask for help. There are a number of things you should include when emailing an instructor, or posting to a help website such as <http://stats.stackexchange.com/>.
 
 - Describe what you expect the code to do.
 - State the end goal you are trying to achieve. (Sometimes what you expect the code to do, is not what you want to actually do.)
 - Provide the full text of any errors you have received.
 - Provide enough code to recreate the error. Often for the purpose of this course, you could simply email your entire `.R` or `.Rmd` file.
 - Sometimes it is also helpful to include a screenshot of your entire RStudio window when the error occurs.
 
-If you follow these steps, you will get your issue resolved much quicker, and possibly learn more in the process. Do not be discouraged by running into errors and difficulties when learning `R`. (Or any technicaly skill.) It is simply part of the learning process.
+If you follow these steps, you will get your issue resolved much quicker, and possibly learn more in the process. Do not be discouraged by running into errors and difficulties when learning `R`. (Or any technical skill.) It is simply part of the learning process.
 
 ### Installing Packages
 
-`R` comes with a number of built-in functions and datasets, but one of the main strengths of `R` as an open-source project is its package system. Packages add additional functions and data. Frequently if you want to do something in `R`, and it isn't availible by default, there is a good chance that there is a package that will fufill your needs.
+`R` comes with a number of built-in functions and datasets, but one of the main strengths of `R` as an open-source project is its package system. Packages add additional functions and data. Frequently if you want to do something in `R`, and it isn't available by default, there is a good chance that there is a package that will fulfill your needs.
 
 To install a package, use the `install.packages()` function.
 
 ```{r, eval = FALSE}
-install.packages(""UsingR"")
+install.packages(""ggplot2"")
 ```
 
 Once a package is install, it must be loaded in your current `R` session before being used.
 
 ```{r, eval = FALSE}
-library(UsingR)
+library(ggplot2)
 ```
 
 ### Data Types
@@ -148,11 +152,9 @@ library(UsingR)
 | 2         | Matrix          | Data Frame        |
 | 3+        | Array           |                   |
 
-We will discuss both vectors and matrices in this chapter. Discussion of lists and data frames will be saved for the following chapter when we encounter them during data analysis.
-
 ### Vectors
 
-Many operations in `R` make heavy use of vectors. Vectors in `R` are indexed starting at `1`. That is what the `[1]` in the output is indicating, that the first element of the row being displayed is the first element of the vector. Larger vectors will start additional rows with `[*]` where `*` is the index of the first element of the row.
+Many operations in `R` make heavy use of **vectors**. Vectors in `R` are indexed starting at `1`. That is what the `[1]` in the output is indicating, that the first element of the row being displayed is the first element of the vector. Larger vectors will start additional rows with `[*]` where `*` is the index of the first element of the row.
 
 Possibly the most common way to create a vector in `R` is using the `c()` function, which is short for combine. As the name suggests, it combines a list of numbers separated by commas. 
 
@@ -177,20 +179,36 @@ Frequently you may wish to create a vector based on a sequence of numbers. The q
 
 Here we see `R` labeling the rows after the first since this is a large vector. Also, we see that by putting parentheses around the assignment, `R` both stores the vector in a variable called `y` and automatically outputs `y` to the console.
 
-TODO: Accessing elements, subset, indexed at 1
+To subset a vector, we use square brackets, `[]`. 
 
 ```{r}
 x
+x[1]
 x[3]
-x[1:3]
+```
+
+We see that `x[1]` returns the first element, and `x[3]` returns the third element.
+
+```{r}
 x[-2]
+```
+
+We can also exclude certain indexes, in this case the second element.
+
+```{r}
+x[1:3]
 x[c(1,3,4)]
 ```
 
-One of the biggest strengths of `R` is its use of vectorized operations. (Frequently the lack of understanding of this concept leads of a belief that `R` is *slow*. `R` is not the fastest language, but it has a reputation for being slower than it really is.)
+Lastly we see that we can subset based on a vector of indicies.
 
 ```{r}
 x = 1:10
+```
+
+One of the biggest strengths of `R` is its use of vectorized operations. (Frequently the lack of understanding of this concept leads of a belief that `R` is *slow*. `R` is not the fastest language, but it has a reputation for being slower than it really is.)
+
+```{r}
 x + 1
 2 * x
 2 ^ x
@@ -204,50 +222,69 @@ The length of a vector can be obtained with the `length()` function.
 
 ```{r}
 vec_1 = 1:10
-vec_2 = seq(2, 4, by = 0.01)
+vec_2 = 1:1000
 vec_3 = 42
 length(vec_1)
 length(vec_2)
 length(vec_3)
 ```
 
-Note that there scalars do not exists in `R`. They are simply vectors of lenght `1`.
+Note that scalars do not exists in `R`. They are simply vectors of length `1`.
 
 If we want to create a sequence that isn't limited to integers and increasing by 1 at a time, we can use the `seq()` function.
 
 ```{r}
 seq(from = 1.5, to = 4.2, by = 0.1)
 ```
 
+We will discuss functions later, but note here that `from`, `to` and `by` are optional.
+
 ```{r}
 seq(1.5, 4.2, 0.1)
 ```
 
-TODO: add `rep`
+Another common operation to create a vector is `rep()`, which can repeat a single value a number of times.
 
 ```{r}
 rep(0.5, times = 10)
 ```
 
+Or, `rep()` can be used to repeat a vector a number of times.
+
 ```{r}
-rep(x, 3)
+rep(x, times = 3)
 ```
 
+We have now seen four different ways to create vectors:
+
+- `c()`
+- `:`
+- `seq()`
+- `rep()`
+
+So far we have mostly used them in isolation, but they are often used together.
+
 ```{r}
-c(x, rep(seq(1, 9, 2), 3), c(1, 2, 3), 42)
+c(x, rep(seq(1, 9, 2), 3), c(1, 2, 3), 42, 2:4)
 ```
 
 ### Summary Statistics
 
+`R` has built in functions for a large number of summary statistics.
+
 ```{r}
 y
 ```
 
+- Central Tendancy
+
 ```{r}
 mean(y)
 median(y)
 ```
 
+- Spread
+
 ```{r}
 var(y)
 sd(y)
@@ -268,12 +305,24 @@ By default the `matrix` function reorders a vector into columns, but we can also
 ```{r}
 x = 1:9
 x
+```
+
+```{r}
 X = matrix(x, nrow = 3, ncol = 3)
 X
+```
+
+```{r}
 Y = matrix(x, nrow = 3, ncol = 3, byrow = TRUE)
 Y
+```
+
+```{r}
 Z = matrix(0, 2, 4)
 Z
+```
+
+```{r}
 X
 X[1, 2]
 X[1, ]
@@ -287,7 +336,13 @@ Matrices can also be created by combining vectors as columns, using `cbind` or c
 x = 1:9
 rev(x)
 rep(1, 9)
+```
+
+```{r}
 cbind(x, rev(x), rep(1, 9))
+```
+
+```{r}
 rbind(x, rev(x), rep(1, 9))
 ```
 
@@ -302,8 +357,6 @@ X
 Y
 ```
 
-TODO: byrow
-
 ```{r}
 X + Y
 X - Y
@@ -316,97 +369,142 @@ Note that `X * Y` is not matrix multiplication. It is element by element multipl
 ```{r}
 X %*% Y
 t(X)
+```
+
+```{r}
 Z = matrix(c(9, 2, -3, 2, 4, -2, -3, -2, 16), 3, byrow = T)
 Z
 solve(Z)
+```
+
+```{r}
 X = matrix(1:6, 2, 3)
 X
 dim(X)
 rowSums(X)
 colSums(X)
 rowMeans(X)
 colMeans(X)
+```
+
+```{r}
 diag(Z)
 diag(1:5)
 diag(5)
 ```
 
 ### Data Frames
 
-TODO: get data???
-TODO: basic idea
-TODO: make with R
-TODO: import from .csv
-TODO: from package
+We have previously seen vectors and matrices for storing data as we introduced `R`. We will now introduce a **data frame** which will be the most common way that we store and interact with data in this course.
 
 ```{r}
-pizza = data.frame(students = c(2, 6, 8, 8, 12, 16, 20, 20, 22, 26), 
-                          sales = c(58, 105, 88, 118, 117, 137, 157, 169, 149, 202))
+example_data = data.frame(x = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10),
+                          y = c(2, 4, 6, 8, 2, 4, 6, 8, 2, 10),
+                          z = c(1, 1, 1, 1, 1, 3, 3, 3, 3, 42))
 ```
 
-We have previously seen vectors and matrices for storing data as we introduced `R`. We will now introduce a **data frame** which will be the most common way that we store and interact with data in this course.
-
 list of vectors
 observations and variables
 order ""doesn't matter"" (unlike a matrix)
 
 ```{r}
-names(pizza)
+names(example_data)
 ```
 
 ```{r}
-pizza$sales
-pizza$students
+example_data$x
+example_data$z
 ```
 
 ```{r}
-dim(pizza)
-nrow(pizza)
-ncol(pizza)
+dim(example_data)
+nrow(example_data)
+ncol(example_data)
 ```
 
-```{r}
-str(pizza)
+```{r, echo = FALSE}
+write.csv(example_data, ""data/example_data.csv"", row.names = FALSE)
 ```
 
-```{r, echo = FALSE}
-write.csv(pizza, ""data/pizza.csv"", row.names = FALSE)
+[data is csv here](data/example_data.csv)
+
+```{r, eval = FALSE}
+example_data_from_csv = read.csv(""data/example_data.csv"")
+```
+
+TODO: import into R/RStudio (screenshot of button?)
+
+```{r, eval = FALSE}
+library(ggplot2)
 ```
 
-[data is csv here](data/pizza.csv)
+```{r}
+head(mpg, n = 10)
+```
 
-TODO: import into R/RStudio  
 
 ```{r}
-plot(pizza$students, pizza$sales)
+str(mpg)
 ```
 
 ### Plotting
 
-TODO: hist
-TODO: plot (scatter) (y ~ x formula)
-TODO: boxplot
+TODO: look at the data. pictures are your friend.
+
+#### Histograms
 
 ```{r}
-plot(pizza$students, pizza$sales,
-     xlab = ""Students (in 1000s)"",
-     ylab = ""Sales (in $1000s)"",
-     main = ""Quarterly Sales vs Student Population"",
+hist(mpg$cty)
+```
+
+```{r}
+hist(mpg$cty,
+     xlab   = ""City Miles Per Gallon"",
+     main   = ""Histogram of City MPG"",
+     breaks = 12,
+     col    = ""dodgerblue"",
+     border = ""darkorange"")
+```
+
+#### Boxplots
+
+```{r}
+unique(mpg$drv)
+```
+
+```{r}
+boxplot(hwy ~ drv, data = mpg)
+```
+
+```{r}
+boxplot(hwy ~ drv, data = mpg,
+     xlab = ""Drivetrain (f = FWD, r = RWD, 4 = 4WD)"",
+     ylab = ""Highway Miles Per Gallon"",
+     main = ""Highway MPG vs Engine Displacement"",
      pch  = 20,
      cex  = 2,
-     col  = ""dodgerblue"")
+     col  = ""darkorange"",
+     border = ""dodgerblue"")
+```
+
+#### Scatterplots
+
+```{r}
+plot(mpg$displ, mpg$hwy)
 ```
 
 ```{r}
-plot(sales ~ students, data = pizza,
-     xlab = ""Students (in 1000s)"",
-     ylab = ""Sales (in $1000s)"",
-     main = ""Quarterly Sales vs Student Population"",
+plot(hwy ~ displ, data = mpg,
+     xlab = ""Engine Displacement (in Liters)"",
+     ylab = ""Highway Miles Per Gallon"",
+     main = ""Highway MPG vs Engine Displacement"",
      pch  = 20,
      cex  = 2,
      col  = ""dodgerblue"")
 ```
 
+TODO: Discuss formula.
+
 ### Distributions
 
 When working with different statistical distributions, we often want to make probabilistic statements based on the distribution.
@@ -515,7 +613,7 @@ What happened here? `R` still performed the operation, but it also gives us a wa
 
 TODO: add comparison to ""scalar""
 
-TODO: which.max()
+TODO: which.max(). MAYBE.
 
 ### Control Flow
 
@@ -583,7 +681,9 @@ standardize = function(x) {
   result = (x - m) / std
   result
 }
-  
+```
+
+```{r}
 x = rnorm(10, 2, 25)
 standardize(x)
 ```
@@ -615,6 +715,8 @@ TODO: explain 1 * biased
 
 ## Hypothesis Tests in `R`
 
+TODO: make all data data frames
+
 ### One Sample t-Test: Review
 
 Suppose $x_{i} \sim \mathrm{N}(\mu,\sigma^{2})$ and we want to test $H_{0}: \mu = \mu_{0}$ versus $H_{1}: \mu \neq \mu_{0}.$
@@ -818,7 +920,7 @@ test_stat
 
 ## Simulation
 
-TODO: genearl comments on simulations
+TODO: general comments on simulations
 
 ### Paired Differences
 
@@ -889,9 +991,6 @@ for (i in 1:samples) {
 mean(0 < differences & differences < 2)
 
 hist(differences, breaks = 20, main = ""Empirical Distribution of Differences"")
-
-qqnorm(differences)
-qqline(differences)
 ```
 
 ### Distribution of a Sample Mean

---FILE: course/todo.Rmd---
@@ -74,5 +74,6 @@ Extending Linear Models
 
 ## Misc Notes
 
+- Post Alex's hypothesis testing review?
 - Week 7 is light, and Week 8 is unneeded for undergrads, which gives time to work on projects.
 - Project should be released by Week 5.

---FILE: data/example_data.csv---
@@ -0,0 +1,11 @@
+""x"",""y"",""z""
+1,2,1
+2,4,1
+3,6,1
+4,8,1
+5,2,1
+6,4,3
+7,6,3
+8,8,3
+9,2,3
+10,10,42"
daviddalpiaz,appliedstats,30092723dac353966c3ef76da0891bfa4e3cb72e,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-05T15:26:18Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-05T15:26:18Z,data folder. small fixes. files names.,01-r-intro.Rmd;02-slr.rmd;data/momma_leona.csv;index.Rmd,True,False,True,False,49,6,55,"---FILE: 01-r-intro.Rmd---
@@ -161,6 +161,8 @@ log(x)
 
 We see that when a function like `log()` is called on a vector `x`, a vector is returned which has applied the function to each element of the vector  `x`.
 
+TODO: Basic stat functions. Mean. SD. Etc.
+
 ## Matrix Calculations
 
 `R` can also be used for matrix calculations. Matrices can be created using the `matrix` function. 
@@ -242,8 +244,6 @@ When working with different statistical distributions, we often want to make pro
 # add pictures for d, p, q, r
 ```
 
-
-
 We typically want to know one of four things:
 
 * The density (pdf) value at a particular value of `x`.

---FILE: 02-slr.rmd---
@@ -3,7 +3,6 @@
 > ""All models are wrong, but some are useful.""\
         - **George E. P. Box**
 
-
 ## Motivating Example
 
 Suppose you are the owner of the *Momma Leona’s Pizza*, a restaurant chain located near several college campuses. You currently own 10 stores and have data on the size of the student population as well as quarterly sales for each. Your data is summarized in the table below.
@@ -27,11 +26,32 @@ Here,
 - Student Population, $x_i$, in 1000s
 - Quarterly Sales, $y_i$, in $1000s
 
+```{r}
+momma_leona <- data.frame(students = c(2, 6, 8, 8, 12, 16, 20, 20, 22, 26), 
+                          sales = c(58, 105, 88, 118, 117, 137, 157, 169, 149, 202))
+
+```
+
+```{r, echo = FALSE}
+write.csv(momma_leona, ""data/momma_leona.csv"", row.names = FALSE)
+```
+
+
+
+[data is csv here](data/momma_leona.csv)
+
+
+```{r}
+plot(momma_leona$students, momma_leona$sales)
+```
 
 How can you use this data to 
 
 - Explain relationship
+    - Significant?
+    - Which *variables* (word?) are most important? (Say, a variable for public/private)
 - Predict
+    - 
 
 One tool will do both, LINEAR REGRESSION
 
@@ -47,8 +67,20 @@ y = f(x) + \epsilon
 y = \beta_0 + \beta_1 x + \epsilon
 \]
 
+Unexplained:
+
+- missing variables
+- measurement error
+
 ##  What is the Best Line?
 
+goldilocks
+
+- Underfitting (Just using y_bar)
+- Just right (SLR)
+- Overfitting (Connect the dots)
+
+
 TODO: picture with lines. one for overall mean. one for LS?
 
 \[

---FILE: data/momma_leona.csv---
@@ -0,0 +1,11 @@
+""students"",""sales""
+2,58
+6,105
+8,88
+8,118
+12,117
+16,137
+20,157
+20,169
+22,149
+26,202

---FILE: index.Rmd---
@@ -33,11 +33,11 @@ Welcome to Applied Statistics with `R`!
 
 This book was originally (and currently) designed for use with STAT 420, Methods of Applied Statistics, at the University of Illinois at Urbana-Champaign. It may certainly be used elsewhere, but you may find references to ""this course"" which is STAT 420.
 
-This book is under active development. When possible, it would be best to always access the text online to be sure you are using the most up-to-date version. (Also the html version provides the most features such as changing text size, font, and colors.) If you are in need of a local copy, a pdf version is continuously updated as well at http://daviddalpiaz.github.io/appliedstats/applied_statistics.pdf
+This book is under active development. When possible, it would be best to always access the text online to be sure you are using the most up-to-date version. (Also the html version provides the most features such as changing text size, font, and colors.) If you are in need of a local copy, a pdf version is continuously maintained at <http://daviddalpiaz.github.io/appliedstats/applied_statistics.pdf>.
 
-Since this book is under active development you may encounter errors ranging from typos to broken code to poorly explained topics. If you do, please let us know! Simply send an email and we'll make the changes ASAP. Or if you know RMarkdown and are familiar with GitHub, [make a pull request and fix an issue yourself!](https://github.com/daviddalpiaz/appliedstats)
+Since this book is under active development you may encounter errors ranging from typos to broken code to poorly explained topics. If you do, please let us know! Simply send an email and we'll make the changes ASAP. Or, if you know RMarkdown and are familiar with GitHub, [make a pull request and fix an issue yourself!](https://github.com/daviddalpiaz/appliedstats)
 
-This text uses MathJax to render mathematical notation for the web. Occasionally but rarely a JavaScript error will prevent MathJax from rendering correctly. (And you will see the code to produce the text instead.) From experience, this is almost always fixed by simply refreshing the page. You'll also notice that if you right-click any equation you can obtain the MathML Code (for copying into Microsoft Word) or the TeX command used to generate the equation.
+This text uses MathJax to render mathematical notation for the web. Occasionally but rarely a JavaScript error will prevent MathJax from rendering correctly. (And you will see the ""code"" instead of the expected mathematical equations.) From experience, this is almost always fixed by simply refreshing the page. You'll also notice that if you right-click any equation you can obtain the MathML Code (for copying into Microsoft Word) or the TeX command used to generate the equation.
 
 \[
 a^2 + b^2 = c^2"
daviddalpiaz,appliedstats,ab236931a5b4dc007342f05394d625fb54e3af3d,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-04T21:06:28Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-04T21:06:28Z,remove $\LateX$ to fix failing build?,index.Rmd,True,False,True,False,1,1,2,"---FILE: index.Rmd---
@@ -37,7 +37,7 @@ This book is under active development. When possible, it would be best to always
 
 Since this book is under active development you may encounter errors ranging from typos to broken code to poorly explained topics. If you do, please let us know! Simply send an email and we'll make the changes ASAP. Or if you know RMarkdown and are familiar with GitHub, [make a pull request and fix an issue yourself!](https://github.com/daviddalpiaz/appliedstats)
 
-This text uses MathJax to render mathematical notation for the web. Occasionally but rarely a JavaScript error will prevent MathJax from rendering correctly. (And you will see the code to produce the text instead.) From experience, this is almost always fixed by simply refreshing the page. You'll also notice that if you right-click any equation you can obtain the MathML Code (for copying into Microsoft Word) or the $\LaTeX$ command used to generate the equation.
+This text uses MathJax to render mathematical notation for the web. Occasionally but rarely a JavaScript error will prevent MathJax from rendering correctly. (And you will see the code to produce the text instead.) From experience, this is almost always fixed by simply refreshing the page. You'll also notice that if you right-click any equation you can obtain the MathML Code (for copying into Microsoft Word) or the TeX command used to generate the equation.
 
 \[
 a^2 + b^2 = c^2"
daviddalpiaz,appliedstats,775ad5d218d3591e20efa40d32d30984b2827906,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-04T16:18:14Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-04T16:18:14Z,Moved/merged introduction into preface. Fixed resulting shift in chapters.,01-introduction.Rmd;01-r-intro.Rmd;02-slr.rmd;03-slr-inf.Rmd;index.Rmd,True,False,True,False,4,7,11,"---FILE: 01-introduction.Rmd---
@@ -1,5 +0,0 @@
-# Introduction
-
-## About This Book
-
-## Conventions

---FILE: index.Rmd---
@@ -25,6 +25,8 @@ options(scipen = 8, width=65)
 ```{r misc_func, echo=FALSE}
 ```
 
-# Preface
+# Introduction
 
-Fill me in later
\ No newline at end of file
+## About This Book
+
+## Conventions"
daviddalpiaz,appliedstats,bd0475fe766b88448f39887ee6d09f8c50dbd013,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-04T16:03:57Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-04T16:03:57Z,Fixed github repo.,03-slr.rmd;index.Rmd,True,False,True,False,5,3,8,"---FILE: 03-slr.rmd---
@@ -24,8 +24,8 @@ Suppose you are the owner of the *Momma Leona’s Pizza*, a restaurant chain loc
 Here,
 
 - Restaurant, $i$
-- Student Population,<br> $x_i$, in 1000s
-- Quarterly Sales,<br> $y_i$, in $1000s
+- Student Population, $x_i$, in 1000s
+- Quarterly Sales, $y_i$, in $1000s
 
 
 How can you use this data to 
@@ -58,3 +58,5 @@ historical, easy math
 \[
 \sum_{i=1}^{n}(y_i - \bar{y})^2 = \sum_{i=1}^{n}(y_i - \hat{y}_i)^2 + \sum_{i=1}^{n}(\hat{y}_i - \bar{y})^2
 \]
+
+Decomposing variation.

---FILE: index.Rmd---
@@ -10,7 +10,7 @@ link-citations: yes
 site: bookdown::bookdown_site
 description: """"
 url: 'https\://daviddalpiaz.github.io/appliedstats/'
-github-repo: coatless/appliedstats
+github-repo: daviddalpiaz/appliedstats
 ---
 
 ```{r setup, echo=FALSE, message=FALSE, warning=FALSE}"
daviddalpiaz,appliedstats,955316e154620486919ee4c1635556abbab16731,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-04T15:48:11Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-04T15:48:11Z,"Rearrange chapters.
Fixed typos.
Changed assignment operator from <- to =.",01-introduction.Rmd;01-world.Rmd;02-r-intro.Rmd;04-slr-inf.Rmd,True,False,True,False,62,62,124,"---FILE: 01-introduction.Rmd---
@@ -0,0 +1,3 @@
+# Introduction
+
+## About This Book

---FILE: 01-world.Rmd---
@@ -1,3 +0,0 @@
-# The World of Applied Statistics
-
-## Subheader
\ No newline at end of file

---FILE: 02-r-intro.Rmd---
@@ -101,22 +101,22 @@ TODO: make a vector
 TODO: assignment
 
 ```{r}
-x <- c(1, 3, 5, 7, 8, 9)
+x = c(1, 3, 5, 7, 8, 9)
 x
 ```
 
 TODO: vector sequence
 
 ```{r}
-y <- 1:20
+y = 1:20
 y
 ```
 
 TODO: fine control sequence
 TODO: directly output
 
 ```{r}
-(z <- seq(1, 2, 0.1))
+(z = seq(1, 2, 0.1))
 ```
 
 TODO: add `rep`
@@ -135,7 +135,7 @@ x[-2]
 One of the biggest strengths of `R` is its use of vectorized operations. (Frequently the lack of understanding of this concept leads of a belief that `R` is *slow*. `R` isn't the fastest language, but it has a reputation for being slower than it really is.)
 
 ```{r}
-x <- 1:10
+x = 1:10
 x + 1
 2 * x
 2 ^ x
@@ -154,13 +154,13 @@ TODO: matrix all same ""data"""" type. ""order matters"". has rows and columns
 By default the `matrix` function reorders a vector into columns, but we can also tell `R` to use rows instead.
 
 ```{r}
-x <- 1:9
+x = 1:9
 x
-X <- matrix(x, nrow = 3, ncol = 3)
+X = matrix(x, nrow = 3, ncol = 3)
 X
-Y <- matrix(x, nrow = 3, ncol = 3, byrow = TRUE)
+Y = matrix(x, nrow = 3, ncol = 3, byrow = TRUE)
 Y
-Z <- matrix(0, 2, 4)
+Z = matrix(0, 2, 4)
 Z
 X
 X[1, 2]
@@ -172,7 +172,7 @@ X[2, c(1, 3)]
 Matrices can also be created by combining vectors as columns, using `cbind` or combining vectors as rows using `rbind`.
 
 ```{r}
-x <- 1:9
+x = 1:9
 rev(x)
 rep(1, 9)
 cbind(x, rev(x), rep(1, 9))
@@ -182,10 +182,10 @@ rbind(x, rev(x), rep(1, 9))
 `R` can then be used to perform matrix calculations.
 
 ```{r}
-x <- 1:9
-y <- 9:1
-X <- matrix(x, 3, 3)
-Y <- matrix(y, 3, 3)
+x = 1:9
+y = 9:1
+X = matrix(x, 3, 3)
+Y = matrix(y, 3, 3)
 X
 Y
 ```
@@ -202,10 +202,10 @@ Note that `X * Y` is not matrix multiplication. It is element by element multipl
 ```{r}
 X %*% Y
 t(X)
-Z <- matrix(c(9, 2, -3, 2, 4, -2, -3, -2, 16), 3, byrow = T)
+Z = matrix(c(9, 2, -3, 2, 4, -2, -3, -2, 16), 3, byrow = T)
 Z
 solve(Z)
-X <- matrix(1:6, 2, 3)
+X = matrix(1:6, 2, 3)
 X
 dim(X)
 rowSums(X)
@@ -298,8 +298,8 @@ Operator | Summary
 In `R`, logical operators are vectorized.
 
 ```{r}
-heights <- c(110, 120, 115, 136, 205, 156, 175)
-weights <- c(64, 67, 62, 60, 77, 70, 66)
+heights = c(110, 120, 115, 136, 205, 156, 175)
+weights = c(64, 67, 62, 60, 77, 70, 66)
 heights < 121 | heights == 156
 weights[heights > 150]
 ```
@@ -317,13 +317,13 @@ if (...) {
 For example,
 
 ```{r}
-x <- 1
-y <- 3
+x = 1
+y = 3
 if (x > y) {
-  z <- x * y
+  z = x * y
   print(""x is larger than y"")
 } else {
-  z <- x + 5 * y
+  z = x + 5 * y
   print(""x is less than or equal to y"")
 }
 
@@ -335,9 +335,9 @@ TODO: ifelse
 Now a `for` loop example,
 
 ```{r}
-x <- 11:15
+x = 11:15
 for (i in 1:5) {
-  x[i] <- x[i] + 1
+  x[i] = x[i] + 1
 }
 
 x
@@ -346,22 +346,22 @@ x
 Note that this `for` loop is very normal in many programming languages, but not in `R`. In `R` we would not use a loop, instead we would simply use a vectorized operation:
 
 ```{r}
-x <- 11:15
-x <- x + 1
+x = 11:15
+x = x + 1
 x
 ```
 
 
 Lastly, we can write our own functions in `R`. For example,
 ```{r}
-standardize <- function(x) {
-  m <- mean(x)
-  std <- sd(x)
-  result <- (x - m) / std
+standardize = function(x) {
+  m = mean(x)
+  std = sd(x)
+  result = (x - m) / std
   result
 }
   
-x <- rnorm(10, 2, 25)
+x = rnorm(10, 2, 25)
 standardize(x)
 ```
 \
@@ -370,12 +370,12 @@ standardize(x)
 TODO: function with arguments, control flow, if based return, how return works
 
 ```{r}
-get_sd <- function(y, biased = FALSE) {
-  n <- length(y)
+get_sd = function(y, biased = FALSE) {
+  n = length(y)
   if (biased) {
-    std <- sqrt((1 / n) * sum((y - mean(y)) ^ 2))
+    std = sqrt((1 / n) * sum((y - mean(y)) ^ 2))
   } else {
-    std <- sqrt((1 / (n - 1)) * sum((y - mean(y)) ^ 2))
+    std = sqrt((1 / (n - 1)) * sum((y - mean(y)) ^ 2))
   }
   std
 }
@@ -447,7 +447,7 @@ s &= \sqrt{0.0625} = \textbf{0.25}
 \]
 
 ```{r}
-x <- c(15.5, 16.2, 16.1, 15.8, 15.6, 16.0, 15.8, 15.9, 16.2)
+x = c(15.5, 16.2, 16.1, 15.8, 15.6, 16.0, 15.8, 15.9, 16.2)
 mean(x)
 sd(x)
 ```
@@ -469,7 +469,7 @@ t.test(x, alternative = c(""two.sided""), conf.level = 0.95)
 
 Or if we only wanted to display the interval:
 ```{r}
-tt <- t.test(x, alternative = c(""two.sided""), conf.level = 0.95)
+tt = t.test(x, alternative = c(""two.sided""), conf.level = 0.95)
 tt$conf.int
 ```
 
@@ -585,18 +585,18 @@ t_{12}^{(0.025)} = 1.782< 1.82337 < t_{12}^{(0.05)} = 2.179.
 
 
 ```{r}
-x <- c(70, 82, 78, 74, 94, 82)
-y <- c(64, 72, 60, 76, 72, 80, 84, 68)
+x = c(70, 82, 78, 74, 94, 82)
+y = c(64, 72, 60, 76, 72, 80, 84, 68)
 t.test(x, y, alternative = c(""greater""), var.equal = TRUE)
 ```
 
 
 Or, performing the calculations `by hand' in `R`:
 ```{r}
-sPooled2 <- ((6 - 1) * var(x) + (8 - 1) * var(y)) / (6 + 8 - 2)
+sPooled2 = ((6 - 1) * var(x) + (8 - 1) * var(y)) / (6 + 8 - 2)
 sPooled2
 
-test_stat <- (mean(x) - mean(y)) / sqrt(sPooled2 * (1 / 6 + 1 / 8))
+test_stat = (mean(x) - mean(y)) / sqrt(sPooled2 * (1 / 6 + 1 / 8))
 test_stat
 1 - pt(test_stat, 6 + 8 - 2)
 ```
@@ -643,7 +643,7 @@ P(0 < D < 2) = P ( – 1.77 < Z < 1.77 )  =  0.9616  - 0.0384  =  0.9232.
 \]
 
 ```{r}
-z <- 1 / sqrt(0.32)
+z = 1 / sqrt(0.32)
 pnorm(z) - pnorm(-z)
 ```
 
@@ -655,21 +655,21 @@ Generate  $S = 1000$ datasets for each of group 1 and group 2. For each of the
 
 ```{r}
 set.seed(42)
-sampleSize <- 25
-mu1 <- 6
-mu2 <- 5
-std <- 2
+sampleSize = 25
+mu1 = 6
+mu2 = 5
+std = 2
 
-samples <- 1000
-count <- 0
-differences <- c(1:samples)
+samples = 1000
+count = 0
+differences = c(1:samples)
 
 for (i in 1:samples) {
-  x1 <- rnorm(sampleSize, mu1, std)
-  x2 <- rnorm(sampleSize, mu2, std)
-  differences[i] <- mean(x1) - mean(x2)
+  x1 = rnorm(sampleSize, mu1, std)
+  x2 = rnorm(sampleSize, mu2, std)
+  differences[i] = mean(x1) - mean(x2)
   if ((differences[i] > 0) & (differences[i] < 2)) {
-  count <- count + 1
+  count = count + 1
   }
 }
 
@@ -685,13 +685,13 @@ qqline(differences)
 ### Distribution of $\bar{x}$
 
 ```{r}
-sampleSize <- 50
-mu <- 10
-samples <- 100000
-xBar <- rep(0, samples)
+sampleSize = 50
+mu = 10
+samples = 100000
+xBar = rep(0, samples)
 
 for(i in 1:samples){
-  xBar[i] <- mean(rpois(sampleSize, lambda = mu))
+  xBar[i] = mean(rpois(sampleSize, lambda = mu))
 }
 
 hist(xBar, breaks = 50)
@@ -702,7 +702,7 @@ c(sd(xBar), sqrt(mu) / sqrt(sampleSize))
 mean(xBar > mu - 2 * sqrt(mu) / sqrt(sampleSize) &
        xBar < mu + 2 * sqrt(mu) / sqrt(sampleSize))
 
-histgm <- hist(xBar, breaks = 50, plot = FALSE)
+histgm = hist(xBar, breaks = 50, plot = FALSE)
 plot(
   histgm,
   col = ifelse(

---FILE: 04-slr-inf.Rmd---
@@ -1 +1 @@
-# Inference for Simple Linear Regressino
+# Inference for Simple Linear Regression"
daviddalpiaz,appliedstats,0a0d8c8a530948f503459d04f531853573d1a757,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-03T22:46:55Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-03T22:46:55Z,Attempt to fix header depth.,02-r-intro.Rmd;03-slr.rmd;04-slr-inf.Rmd,True,False,True,False,5,14,19,"---FILE: 02-r-intro.Rmd---
@@ -1,4 +1,4 @@
-## Introduction
+# Introduction
 
 `R` is both a programming language and software environment for statistical computing, which is *free* and *open-source*. To get started, you will need to install two pieces of software:
 
@@ -713,4 +713,3 @@ plot(
   )
 )
 ```
-

---FILE: 03-slr.rmd---
@@ -1,12 +1,4 @@
-<style type=""text/css"">
-.table {
-
-    width: 60%;
-    margin-left:15%; 
-    margin-right:15%;
-    
-}
-</style>
+# Simple Linear Regression
 
 > ""All models are wrong, but some are useful.""\
         - **George E. P. Box**
@@ -16,7 +8,7 @@
 
 Suppose you are the owner of the *Momma Leona’s Pizza*, a restaurant chain located near several college campuses. You currently own 10 stores and have data on the size of the student population as well as quarterly sales for each. Your data is summarized in the table below.
 
-| Restaurant, $i$ | Student Population, $x_i$, in 1000s | Quarterly Sales, $y_i$, in $1000s |
+| Restaurant, $i$ | Student Population,<br> $x_i$, in 1000s | Quarterly Sales,<br> $y_i$, in $1000s |
 |-----------------|-------------------------------------|-----------------------------------|
 | 1               | 2                                   | 58                                |
 | 2               | 6                                   | 105                               |
@@ -58,4 +50,4 @@ historical, easy math
 
 \[
 \sum_{i=1}^{n}(y_i - \bar{y})^2 = \sum_{i=1}^{n}(y_i - \hat{y}_i)^2 + \sum_{i=1}^{n}(\hat{y}_i - \bar{y})^2
-\]
\ No newline at end of file
+\]

---FILE: 04-slr-inf.Rmd---
@@ -1 +1 @@
-# Another Chapter
\ No newline at end of file
+# Inference for Simple Linear Regressino"
daviddalpiaz,appliedstats,76fd9c8d3ab97bc3c77a78ca7971f3e1940d412a,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-03T22:43:14Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-03T22:43:14Z,Attempt to fix table widths.,03-slr.rmd,True,False,True,False,10,0,10,"---FILE: 03-slr.rmd---
@@ -1,3 +1,13 @@
+<style type=""text/css"">
+.table {
+
+    width: 60%;
+    margin-left:15%; 
+    margin-right:15%;
+    
+}
+</style>
+
 > ""All models are wrong, but some are useful.""\
         - **George E. P. Box**
 "
daviddalpiaz,appliedstats,bfe22b8512722d64e4ad89cb8f7264d0396b0c51,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-03T22:37:11Z,David Dalpiaz,dalpiaz2@illinois.edu,2016-06-03T22:37:11Z,Fixed chapter levels.,.Rbuildignore;02-r-intro.Rmd;03-slr.rmd,True,False,True,False,29,93,122,"---FILE: .Rbuildignore---
@@ -2,3 +2,5 @@
 ^\.DS_Store$
 ^\.Rbuildignore$
 ^\.gitignore$
+^.*\.Rproj$
+^\.Rproj\.user$

---FILE: 02-r-intro.Rmd---
@@ -78,7 +78,7 @@ sin(pi / 2)
 cos(0)
 ```
 
-# Getting Help
+## Getting Help
 
 In using `R` as a calculator, we have seen a number of functions. `sqrt()`, `exp()`, `log()` and `sin()` are all `R` functions. To get documentation about a function in `R`, simply put a question mark in front of the function name and RStudio will display the documentation, for example: 
 
@@ -91,7 +91,7 @@ In using `R` as a calculator, we have seen a number of functions. `sqrt()`, `exp
 
 TODO: how to ask for help
 
-# Vectors
+## Vectors
 
 Many operations in `R` make heavy use of vectors. Note that vectors in `R` are indexed starting at 1.
 
@@ -145,7 +145,7 @@ log(x)
 
 We see that when a function like `log()` is called on a vector `x`, a vector is returned which has applied the function to each element of the vector  `x`.
 
-# Matrix Calculations
+## Matrix Calculations
 
 `R` can also be used for matrix calculations. Matrices can be created using the `matrix` function. 
 
@@ -217,7 +217,7 @@ diag(1:5)
 diag(5)
 ```
 
-# Distributions
+## Distributions
 
 When working with different statistical distributions, we often want to make probabilistic statements based on the distribution.
 
@@ -279,9 +279,9 @@ Command  | Distribution
 
 Where `*` can be `d`, `p`, `q`, and `r`.
 
-# Programming Basics
+## Programming Basics
 
-## Logical Operators
+### Logical Operators
 
 Operator | Summary
 ------------- | -------------
@@ -385,27 +385,20 @@ get_sd <- function(y, biased = FALSE) {
 
 TODO: Potentially save this for the SLR document, since it is already somewhat there.
 
-# Data Frames
+## Data Frames
 
 TODO: data frames. have observations and variables
 
-# Importing Data
+## Importing Data
 
 TODO: read() or RStudio
 
-# Scatter Plots
-
-
-# Hypothesis Tests in `R`
-\
-\
+## Scatter Plots
 
 
+## Hypothesis Tests in `R`
 
-
-
-## One Sample $t$ Test: Review
-\
+### One Sample $t$ Test: Review
 
 Suppose $x_{i} \sim \mathrm{N}(\mu,\sigma^{2})$ and we want to test $H_{0}: \mu = \mu_{0}$ versus $H_{1}: \mu \neq \mu_{0}.$
 
@@ -424,19 +417,8 @@ A $100(1-\alpha)$\% CI for $\mu$ is given by
 \]
 
 where $t_{n-1}^{(\alpha/2)}$ is the critical value such that $P\left(T>t_{n-1}^{(\alpha/2)}\right)=\alpha/2$ for $n-1$ degrees of freedom.
-\
-\
-
-
-
-
-
 
-
-
-
-## One Sample $t$ Test: Example
-\
+### One Sample $t$ Test: Example
 
 ```{r, eval = FALSE, echo = FALSE}
 # this example needs to be cleaned up
@@ -453,11 +435,7 @@ was taken and weighed. The results were
 
 ounces. Assume the weight of cereal in a box is normally distributed.
 
-\
-\
 **a)** Compute the sample mean $\bar{x}$ and the sample standard deviation $s$.
-\
-\
 
 \[
 \begin{split}
@@ -474,11 +452,7 @@ mean(x)
 sd(x)
 ```
 
-\
-\
 **b)** Construct a $95\%$ confidence interval for the overall average weight of boxes of \textit{Captain Crisp} cereal.
-\
-\
 
 $t_{n-1}^{(\alpha/2)}=t_{8}^{(0.025)}=2.306$, so the 95\% CI for the average weight of a cereal box is: 
 
@@ -506,11 +480,7 @@ c(mean(x) - qt(0.975, 8) * sd(x) / sqrt(9),
   mean(x) + qt(0.975, 8) * sd(x) / sqrt(9))
 ```
 
-\
-\
 **c)** The company that makes *Captain Crisp* cereal claims that the average weight of its box is at least 16 ounces. Use a 0.05 level of significance to test the company's claim. What is the p-value of this test?
-\
-\
 
 To test $H_{0}: \mu \geq 16$ versus $H_{1}: \mu < 16$, the test statistic is
 
@@ -527,18 +497,8 @@ Therefore, we **do NOT reject the null hypothesis** at the $\alpha=.05$ level. W
 ```{r}
 t.test(x, mu = 16, alternative = c(""less""), conf.level = 0.95)
 ```
-\
-\
-
-
 
-
-
-
-
-## Two Sample $t$ Test: Review
-\
-\
+### Two Sample $t$ Test: Review
 
 Suppose $x_{i}\sim\mathrm{N}(\mu_{x},\sigma^{2})$ and $y_{i}\sim\mathrm{N}(\mu_{y},\sigma^{2}).$ 
 
@@ -559,17 +519,8 @@ A $100(1-\alpha)$\% CI for $\mu_{x}-\mu_{y}$ is given by
 \]
 
 where $t_{n+m-2}^{(\alpha/2)}$ is critical $t_{n+m-2}$ value such that $P\left(T>t_{n+m-2}^{(\alpha/2)}\right)=\alpha/2$.
-\
-\
-
-
-
-
-
-
 
-
-## Two Sample $t$ Test: Example
+### Two Sample $t$ Test: Example
 \
 
 Assume that the distributions of $X$ and $Y$ are $\mathrm{N}(\mu_{1},\sigma^{2})$ and $\mathrm{N}(\mu_{2},\sigma^{2})$, respectively. Given the $n = 6$ observations of $X$,
@@ -654,14 +605,9 @@ test_stat
 
 
 
-# Simulation in `R`
-\
-\
-
-
-
+## Simulation in `R`
 
-## Paired Differences
+### Paired Differences
 
 Consider the model:
 
@@ -736,7 +682,7 @@ qqnorm(differences)
 qqline(differences)
 ```
 
-## Distribution of $\bar{x}$
+### Distribution of $\bar{x}$
 
 ```{r}
 sampleSize <- 50

---FILE: 03-slr.rmd---
@@ -1,20 +1,8 @@
----
-title: ""Simple Linear Regression""
-author: ""STAT 420""
-date: 'University of Illinois'
-output:
-  html_document:
-    theme: readable
-    toc: yes
-    toc_float: yes
-header-includes: \usepackage{amsmath}
----
-
 > ""All models are wrong, but some are useful.""\
         - **George E. P. Box**
 
 
-# Motivating Example
+## Motivating Example
 
 Suppose you are the owner of the *Momma Leona’s Pizza*, a restaurant chain located near several college campuses. You currently own 10 stores and have data on the size of the student population as well as quarterly sales for each. Your data is summarized in the table below.
 
@@ -38,25 +26,25 @@ How can you use this data to
 
 One tool will do both, LINEAR REGRESSION
 
-# WH___ ?s
+##  WH___ ?s
 
-# Model
+##  Model
 
-# What is the Best Line?
+##  What is the Best Line?
 
 historical, easy math
 
-# Least Squares Approach
+##  Least Squares Approach
 
-# MLE Approach
+##  MLE Approach
 
-# Example
+##  Example
 
-# `R`
+##  `R`
 
-# Decomposition
+##  Decomposition
 
-# $R^2$
+##  $R^2$
 
 \[
 \sum_{i=1}^{n}(y_i - \bar{y})^2 = \sum_{i=1}^{n}(y_i - \hat{y}_i)^2 + \sum_{i=1}^{n}(\hat{y}_i - \bar{y})^2"
