repo_owner,repo_name,commit_hash,author,author_email,date,committer_name,committer_email,committer_date,message,filenames,touches_rmd,touches_r,touches_r_or_rmd,is_merge,added,deleted,changed,diff,_touch_r,_touch_rmd,bug_category,category_score
tidyverse,datascience-box,58ad92a7bbcddd4855bf19cb6b9304a9dae24a81,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2024-08-15T21:37:28Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2024-08-15T21:37:28Z,Fix filename,course-materials/_metadata.yml,False,False,False,False,0,0,0,,False,False,Data / Input Handling,3
tidyverse,datascience-box,5d1845fa4eaf8fac118d80632348eae8684a093d,Mine Cetinkaya-Rundel,cetinkaya.mine@gmail.com,2024-07-24T03:02:38Z,GitHub,noreply@github.com,2024-07-24T03:02:38Z,Fix broken formatting,course-materials/_slides/u2-d11-data-classes/u2-d11-data-classes.Rmd,True,False,True,False,173,77,250,"---FILE: course-materials/_slides/u2-d11-data-classes/u2-d11-data-classes.Rmd---
@@ -1,46 +1,26 @@
----
-title: ""Data classes""
-subtitle: ""<br><br> Data Science in a Box""
-author: ""[datasciencebox.org](https://datasciencebox.org/)""
-output:
-  xaringan::moon_reader:
-    css: [""../xaringan-themer.css"", ""../slides.css""]
-    lib_dir: libs
-    nature:
-      ratio: ""16:9""
-      highlightLines: true
-      highlightStyle: solarized-light
-      countIncrementalSlides: false
----
-
-```{r child = ""../setup.Rmd""}
-```
-
-```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
-library(tidyverse)
-library(DT)
-library(scales)
-```
-
 class: middle
 
 # Data classes
 
-------------------------------------------------------------------------
+---
 
 ## Data classes
 
 We talked about *types* so far, next we'll introduce the concept of *classes*
 
--   Vectors are like Lego building blocks
+- Vectors are like Lego building blocks
 
-| \- We stick them together to build more complicated constructs, e.g. *representations of data*                                                                                                                                                                  |
-|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
-| \- The **class** attribute relates to the S3 class of an object which determines its behaviour - You don't need to worry about what S3 classes really mean, but you can read more about it [here](https://adv-r.hadley.nz/s3.html#s3-classes) if you're curious |
+--
+- We stick them together to build more complicated constructs, e.g. *representations of data*
 
--   Examples: factors, dates, and data frames
+--
+- The **class** attribute relates to the S3 class of an object which determines its behaviour
+  - You don't need to worry about what S3 classes really mean, but you can read more about it [here](https://adv-r.hadley.nz/s3.html#s3-classes) if you're curious
 
-------------------------------------------------------------------------
+--
+- Examples: factors, dates, and data frames
+  
+---
 
 ## Factors
 
@@ -53,9 +33,19 @@ x
 
 --
 
-.pull-left\[\] .pull-right\[\]
+.pull-left[
+```{r}
+typeof(x)
+```
+]
+.pull-right[
+```{r}
+class(x)
+```
+]
 
-------------------------------------------------------------------------
+
+---
 
 ## More on factors
 
@@ -66,7 +56,7 @@ glimpse(x)
 as.integer(x)
 ```
 
-------------------------------------------------------------------------
+---
 
 ## Dates
 
@@ -77,7 +67,7 @@ typeof(y)
 class(y)
 ```
 
-------------------------------------------------------------------------
+---
 
 ## More on dates
 
@@ -88,7 +78,7 @@ as.integer(y)
 as.integer(y) / 365 # roughly 50 yrs
 ```
 
-------------------------------------------------------------------------
+---
 
 ## Data frames
 
@@ -99,9 +89,18 @@ df <- data.frame(x = 1:2, y = 3:4)
 df
 ```
 
-.pull-left\[\] .pull-right\[\]
+.pull-left[
+```{r}
+typeof(df)
+```
+]
+.pull-right[
+```{r}
+class(df)
+```
+]
 
-------------------------------------------------------------------------
+---
 
 ## Lists
 
@@ -116,12 +115,12 @@ l <- list(
 l
 ```
 
-------------------------------------------------------------------------
+---
 
 ## Lists and data frames
 
--   A data frame is a special list containing vectors of equal length
--   When we use the `pull()` function, we extract a vector from the data frame
+- A data frame is a special list containing vectors of equal length
+- When we use the `pull()` function, we extract a vector from the data frame
 
 ```{r}
 df
@@ -130,13 +129,14 @@ df %>%
   pull(y)
 ```
 
-------------------------------------------------------------------------
+
+---
 
 class: middle
 
 # Working with factors
 
-------------------------------------------------------------------------
+---
 
 ```{r include=FALSE}
 cat_lovers <- read_csv(""data/cat-lovers.csv"")
@@ -148,7 +148,7 @@ cat_lovers <- read_csv(""data/cat-lovers.csv"")
 glimpse(cat_lovers)
 ```
 
-------------------------------------------------------------------------
+---
 
 ## But coerce when plotting
 
@@ -157,7 +157,7 @@ ggplot(cat_lovers, mapping = aes(x = handedness)) +
   geom_bar()
 ```
 
-------------------------------------------------------------------------
+---
 
 ## Use forcats to manipulate factors
 
@@ -168,18 +168,36 @@ cat_lovers %>%
   geom_bar()
 ```
 
-------------------------------------------------------------------------
+---
 
 ## Come for the functionality
 
-.pull-left\[ ... stay for the logo\] .pull-right\[\]
+.pull-left[
+... stay for the logo
+]
+.pull-right[
+```{r echo=FALSE, out.width=""70%""}
+knitr::include_graphics(""img/forcats-part-of-tidyverse.png"")
+```
+]
 
-.pull-left-wide\[ - Factors are useful when you have true categorical data and you want to override the ordering of character vectors to improve display - They are also useful in modeling scenarios - The **forcats** package provides a suite of useful tools that solve common problems with factors\]
+.pull-left-wide[
+- Factors are useful when you have true categorical data and you want to override the ordering of character vectors to improve display
+- They are also useful in modeling scenarios
+- The **forcats** package provides a suite of useful tools that solve common problems with factors
+]
 
-------------------------------------------------------------------------
+---
 
-.small\[ .your-turn\[ \### .hand\[Your turn!\]
-\]\]
+.small[
+.your-turn[
+### .hand[Your turn!]
+
+- [RStudio Cloud](http://rstd.io/dsbox-cloud) > `AE 05 - Hotels + Data types` > `hotels-forcats.Rmd` > knit
+- Recreate the x-axis of the following plot. 
+- **Stertch goal:** Recreate the y-axis.
+]
+]
 
 ```{r echo=FALSE, out.width=""90%"", fig.asp=0.4}
 if (!file.exists(""data/hotels"")) {
@@ -208,80 +226,158 @@ hotels %>%
   scale_x_discrete(guide = guide_axis(check.overlap = TRUE))
 ```
 
-------------------------------------------------------------------------
+---
 
 class: middle
 
 # Working with dates
 
-------------------------------------------------------------------------
+---
 
 ## Make a date
 
-.pull-left\[\] .pull-right\[ - **lubridate** is the tidyverse-friendly package that makes dealing with dates a little easier - It's not one of the *core* tidyverse packages, hence it's installed with `install.packages(""tidyverse)` but it's not loaded with it, and needs to be explicitly loaded with `library(lubridate)`\]
+.pull-left[
+```{r echo=FALSE, out.width=""65%"", fig.align=""center""}
+knitr::include_graphics(""img/lubridate-not-part-of-tidyverse.png"")
+```
+]
+.pull-right[
+- **lubridate** is the tidyverse-friendly package that makes dealing with dates a little easier
+- It's not one of the *core* tidyverse packages, hence it's installed with `install.packages(""tidyverse)` but it's not loaded with it, and needs to be explicitly loaded with `library(lubridate)`
+]
 
-------------------------------------------------------------------------
+---
 
 class: middle
 
-.hand\[.light-blue\[ we're just going to scratch the surface of working with dates in R here...\]\]
+.hand[.light-blue[
+we're just going to scratch the surface of working with dates in R here...
+]]
 
-------------------------------------------------------------------------
+---
 
-.question\[ Calculate and visualise the number of bookings on any given arrival date.\]
+.question[
+Calculate and visualise the number of bookings on any given arrival date.
+]
 
 ```{r}
 hotels %>%
   select(starts_with(""arrival_""))
 ```
 
-------------------------------------------------------------------------
+---
 
 ## Step 1. Construct dates
 
-.midi\[\]
+.midi[
+```{r output.lines=7}
+library(glue)
 
-------------------------------------------------------------------------
+hotels %>%
+  mutate(
+    arrival_date = glue(""{arrival_date_year} {arrival_date_month} {arrival_date_day_of_month}"") #<<
+    ) %>% 
+  relocate(arrival_date)
+```
+]
+
+---
 
 ## Step 2. Count bookings per date
 
-.midi\[\]
+.midi[
+```{r}
+hotels %>%
+  mutate(arrival_date = glue(""{arrival_date_year} {arrival_date_month} {arrival_date_day_of_month}"")) %>%
+  count(arrival_date)
+```
+]
 
-------------------------------------------------------------------------
+---
 
 ## Step 3. Visualise bookings per date
 
-.midi\[\]
+.midi[
+```{r out.width=""80%"", fig.asp = 0.4}
+hotels %>%
+  mutate(arrival_date = glue(""{arrival_date_year} {arrival_date_month} {arrival_date_day_of_month}"")) %>%
+  count(arrival_date) %>%
+  ggplot(aes(x = arrival_date, y = n, group = 1)) +
+  geom_line()
+```
+]
 
-------------------------------------------------------------------------
+---
 
-.hand\[zooming in a bit...\]
+.hand[zooming in a bit...]
 
-.question\[ Why does the plot start with August when we know our data start in July?
-And why does 10 August come after 1 August?\]
+.question[
+Why does the plot start with August when we know our data start in July? And why does 10 August come after 1 August?
+]
 
-.midi\[\]
+.midi[
+```{r out.width=""80%"", echo=FALSE, fig.asp = 0.4}
+hotels %>%
+  mutate(arrival_date = glue(""{arrival_date_year} {arrival_date_month} {arrival_date_day_of_month}"")) %>%
+  count(arrival_date) %>%
+  slice(1:7) %>%
+  ggplot(aes(x = arrival_date, y = n, group = 1)) +
+  geom_line()
+```
+]
 
-------------------------------------------------------------------------
+---
 
 ## Step 1. *REVISED* Construct dates ""as dates""
 
-.midi\[\]
+.midi[
+```{r output.lines=7}
+library(lubridate)
 
-------------------------------------------------------------------------
+hotels %>%
+  mutate(
+    arrival_date = ymd(glue(""{arrival_date_year} {arrival_date_month} {arrival_date_day_of_month}"")) #<<
+    ) %>% 
+  relocate(arrival_date)
+```
+]
+
+---
 
 ## Step 2. Count bookings per date
 
-.midi\[\]
+.midi[
+```{r}
+hotels %>%
+  mutate(arrival_date = ymd(glue(""{arrival_date_year} {arrival_date_month} {arrival_date_day_of_month}""))) %>% 
+  count(arrival_date)
+```
+]
 
-------------------------------------------------------------------------
+---
 
 ## Step 3a. Visualise bookings per date
 
-.midi\[\]
+.midi[
+```{r out.width=""80%"", fig.asp = 0.4}
+hotels %>%
+  mutate(arrival_date = ymd(glue(""{arrival_date_year} {arrival_date_month} {arrival_date_day_of_month}""))) %>% 
+  count(arrival_date) %>%
+  ggplot(aes(x = arrival_date, y = n, group = 1)) +
+  geom_line()
+```
+]
 
-------------------------------------------------------------------------
+---
 
 ## Step 3b. Visualise using a smooth curve
 
-.midi\[\]
+.midi[
+```{r out.width=""80%"", fig.asp = 0.4, message = FALSE}
+hotels %>%
+  mutate(arrival_date = ymd(glue(""{arrival_date_year} {arrival_date_month} {arrival_date_day_of_month}""))) %>% 
+  count(arrival_date) %>%
+  ggplot(aes(x = arrival_date, y = n, group = 1)) +
+  geom_smooth() #<<
+```
+]",False,True,Documentation / Formatting,6
tidyverse,datascience-box,7052ff77aaa4f6841660bdf441143840515fbbb3,dhodge180,dhodge180@yahoo.com,2024-07-18T16:10:21Z,GitHub,noreply@github.com,2024-07-18T16:10:21Z,Fixed Data Detective link. Also updated geom_segment to use linewidth not size in Catalan plots (else it gave -deprecated- warnings) (#153),course-materials/_slides/u3-d01-misrepresentation/u3-d01-misrepresentation.Rmd,True,False,True,False,4,4,8,"---FILE: course-materials/_slides/u3-d01-misrepresentation/u3-d01-misrepresentation.Rmd---
@@ -153,12 +153,12 @@ knitr::include_graphics(""img/ga-dph-declining-bars.jpg"")
 ## Graph detective
 
 .center[
-<iframe width=""900"" height=""450"" src=""https://livefreeordichotomize.com/2020/05/17/graph-detective/"" frameborder=""0""></iframe>  
+<iframe width=""900"" height=""450"" src=""https://livefreeordichotomize.com/posts/2020-05-17-graph-detective/"" frameborder=""0""></iframe>  
 ]
 
 .footnote[
 .midi[
-Lucy D'Agostino McGowan. [Graph detective](https://livefreeordichotomize.com/2020/05/17/graph-detective/). Live Free or Dichotomize. 17 May 2020.
+Lucy D'Agostino McGowan. [Graph detective](https://livefreeordichotomize.com/posts/2020-05-17-graph-detective/). Live Free or Dichotomize. 17 May 2020.
 ]
 ]
 
@@ -255,7 +255,7 @@ ggplot(catalan, aes(y = fct_rev(response), x = rate, color = response, group = r
   geom_point() +
   geom_segment(aes(x = 0, xend = rate, 
                    y = fct_rev(response), yend = fct_rev(response)),
-               size = 1) +
+               linewidth = 1) +
   scale_color_manual(values = c(""#5C8AA9"", ""#9D303A"", ""gray"")) +
   scale_x_continuous(labels = label_percent(scale = 1)) +
   guides(color = ""none"") +
@@ -285,7 +285,7 @@ catalan <- catalan %>%
 ggplot(catalan, aes(y = fct_rev(response), x = rate, color = response, group = response)) +
   geom_segment(aes(x = low, xend = high, 
                    y = fct_rev(response), yend = fct_rev(response)),
-               size = 0.8, color = ""black"") +
+               linewidth = 0.8, color = ""black"") +
   geom_point(size = 3) +
   scale_color_manual(values = c(""#5C8AA9"", ""#9D303A"", ""gray"")) +
   scale_x_continuous(labels = label_percent(scale = 1)) +",False,True,Documentation / Formatting,4
tidyverse,datascience-box,29930ed9926eb58c65bab52c015ce3813f0a335d,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2023-12-12T04:15:28Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2023-12-12T04:15:34Z,Fix syntax,course-materials/hw-instructions/hw-01/hw-01-pet-names.Rmd;course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.Rmd;course-materials/hw-instructions/hw-03/hw-03-accidents.Rmd;course-materials/hw-instructions/hw-04/hw-04-college-majors.Rmd;course-materials/hw-instructions/hw-05/hw-05-legos.Rmd;course-materials/hw-instructions/hw-06/hw-06-money-in-politics.Rmd;course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.Rmd;course-materials/hw-instructions/hw-08/hw-08-exploring-gss.Rmd;course-materials/hw-instructions/hw-09/hw-09-modeling-gss.Rmd;course-materials/hw-instructions/hw-10/hw-10-wrap-up.Rmd;course-materials/lab-instructions/lab-01/lab-01-hello-r.Rmd;course-materials/lab-instructions/lab-02/lab-02-plastic-waste.Rmd;course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.Rmd;course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.Rmd;course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.Rmd;course-materials/lab-instructions/lab-06/lab-06-sad-plots.Rmd;course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.Rmd;course-materials/lab-instructions/lab-08/lab-08-uoe-art.Rmd;course-materials/lab-instructions/lab-09/lab-09-better-viz.Rmd;course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.Rmd;course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.Rmd;course-materials/lab-instructions/lab-12/lab-12-inference-smoking.Rmd;course-materials/lab-instructions/lab-13/lab-13-work-on-projects.Rmd;course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.Rmd,True,False,True,False,28,27,55,"---FILE: course-materials/hw-instructions/hw-01/hw-01-pet-names.Rmd---
@@ -6,7 +6,7 @@ output:
     css: ../hw.css
     tufte_variant: ""envisioned""
     highlight: pygments
-link-citations: yes
+link-citations: true
 ---
 
 ```{r include = FALSE}
@@ -181,10 +181,11 @@ knitr::include_graphics(""img/ready-to-push.png"")
 
 This will prompt a dialogue box where you first need to enter your user name, and then your password.
 This might feel cumbersome.
-Bear with me... I *will* teach you how to save your password so you don't have to enter it every time.
+Bear with me...
+I *will* teach you how to save your password so you don't have to enter it every time.
 But for this one assignment you'll have to manually enter each time you push in order to gain some experience with it.
 
-**Thought exercise:** Which of the above steps (updating the YAML, committing, and pushing) needs to talk to GitHub?[^hw-01-pet-names-1]
+**Thought exercise:** Which of the above steps (updating the YAML, committing, and pushing) needs to talk to GitHub?[^1]
 
 # Packages
 
@@ -349,4 +350,4 @@ ggplot(comb_name_props, aes(x = cat_prop, y = dog_prop)) +
 
 üß∂ ‚úÖ ‚¨ÜÔ∏è *Now is a good time to commit and push your changes to GitHub with an appropriate commit message. Commit and push all changed files so that your Git pane is cleared up afterwards. Make sure that your last push to the repo comes before the deadline. You should confirm that what you committed and pushed are indeed in your repo that we will see by visiting your repo on GitHub.*
 
-[^hw-01-pet-names-1]: Only pushing requires talking to GitHub, this is why you're asked for your password at that point.
+[^1]: Only pushing requires talking to GitHub, this is why you're asked for your password at that point.

---FILE: course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.Rmd---
@@ -5,7 +5,7 @@ output:
     css: ../hw.css
     tufte_variant: ""envisioned""
     highlight: pygments
-link-citations: yes
+link-citations: true
 ---
 
 ```{r include = FALSE}

---FILE: course-materials/hw-instructions/hw-03/hw-03-accidents.Rmd---
@@ -5,7 +5,7 @@ output:
     css: ../hw.css
     tufte_variant: ""envisioned""
     highlight: pygments
-link-citations: yes
+link-citations: true
 ---
 
 ```{r include = FALSE}

---FILE: course-materials/hw-instructions/hw-04/hw-04-college-majors.Rmd---
@@ -5,7 +5,7 @@ output:
     css: ../hw.css
     tufte_variant: ""envisioned""
     highlight: pygments
-link-citations: yes
+link-citations: true
 ---
 
 ```{r include = FALSE}

---FILE: course-materials/hw-instructions/hw-05/hw-05-legos.Rmd---
@@ -5,7 +5,7 @@ output:
     css: ../hw.css
     tufte_variant: ""envisioned""
     highlight: pygments
-link-citations: yes
+link-citations: true
 ---
 
 ```{r include = FALSE}

---FILE: course-materials/hw-instructions/hw-06/hw-06-money-in-politics.Rmd---
@@ -5,7 +5,7 @@ output:
     css: ../hw.css
     tufte_variant: ""envisioned""
     highlight: pygments
-link-citations: yes
+link-citations: true
 ---
 
 ```{r include = FALSE}

---FILE: course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.Rmd---
@@ -5,7 +5,7 @@ output:
     css: ../hw.css
     tufte_variant: ""envisioned""
     highlight: pygments
-link-citations: yes
+link-citations: true
 ---
 
 ```{r include = FALSE}

---FILE: course-materials/hw-instructions/hw-08/hw-08-exploring-gss.Rmd---
@@ -5,7 +5,7 @@ output:
     css: ../hw.css
     tufte_variant: ""envisioned""
     highlight: pygments
-link-citations: yes
+link-citations: true
 ---
 
 ```{r include = FALSE}

---FILE: course-materials/hw-instructions/hw-09/hw-09-modeling-gss.Rmd---
@@ -5,7 +5,7 @@ output:
     css: ../hw.css
     tufte_variant: ""envisioned""
     highlight: pygments
-link-citations: yes
+link-citations: true
 ---
 
 ```{r include = FALSE}

---FILE: course-materials/hw-instructions/hw-10/hw-10-wrap-up.Rmd---
@@ -5,7 +5,7 @@ output:
     css: ../hw.css
     tufte_variant: ""envisioned""
     highlight: pygments
-link-citations: yes
+link-citations: true
 ---
 
 ```{r include = FALSE}

---FILE: course-materials/lab-instructions/lab-01/lab-01-hello-r.Rmd---
@@ -5,7 +5,7 @@ output:
     css: ../lab.css
     tufte_variant: ""envisioned""
     highlight: pygments
-link-citations: yes
+link-citations: true
 ---
 
 ```{marginfigure}

---FILE: course-materials/lab-instructions/lab-02/lab-02-plastic-waste.Rmd---
@@ -5,7 +5,7 @@ output:
     tufte_variant: ""envisioned""
     highlight: pygments
     css: ../lab.css
-link-citations: yes
+link-citations: true
 ---
 
 ```{r include = FALSE}

---FILE: course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.Rmd---
@@ -5,7 +5,7 @@ output:
     css: ../lab.css
     tufte_variant: ""envisioned""
     highlight: pygments
-link-citations: yes
+link-citations: true
 ---
 
 ```{r setup, include = FALSE}

---FILE: course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.Rmd---
@@ -6,7 +6,7 @@ output:
     tufte_variant: ""envisioned""
     highlight: pygments
     css: ../lab.css
-link-citations: yes
+link-citations: true
 ---
 
 ```{r include = FALSE}

---FILE: course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.Rmd---
@@ -6,7 +6,7 @@ output:
     tufte_variant: ""envisioned""
     highlight: pygments
     css: ../lab.css
-link-citations: yes
+link-citations: true
 ---
 
 ```{r fig.margin = TRUE, echo = FALSE}

---FILE: course-materials/lab-instructions/lab-06/lab-06-sad-plots.Rmd---
@@ -5,7 +5,7 @@ output:
     css: ../lab.css
     tufte_variant: ""envisioned""
     highlight: pygments
-link-citations: yes
+link-citations: true
 ---
 
 ```{r setup, include=FALSE}

---FILE: course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.Rmd---
@@ -6,7 +6,7 @@ output:
     tufte_variant: ""envisioned""
     highlight: pygments
     css: ../lab.css
-link-citations: yes
+link-citations: true
 ---
 
 ```{r setup, include=FALSE}

---FILE: course-materials/lab-instructions/lab-08/lab-08-uoe-art.Rmd---
@@ -5,7 +5,7 @@ output:
     css: ../lab.css
     tufte_variant: ""envisioned""
     highlight: pygments
-link-citations: yes
+link-citations: true
 ---
 
 ```{r setup, include=FALSE}

---FILE: course-materials/lab-instructions/lab-09/lab-09-better-viz.Rmd---
@@ -5,7 +5,7 @@ output:
     tufte_variant: ""envisioned""
     highlight: pygments
     css: ../lab.css
-link-citations: yes
+link-citations: true
 ---
 
 In this lab our goal is to reconstruct and improve a data visualisation on COVID and mask wearing.

---FILE: course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.Rmd---
@@ -6,7 +6,7 @@ output:
     tufte_variant: ""envisioned""
     highlight: pygments
     css: ../lab.css
-link-citations: yes
+link-citations: true
 ---
 
 ```{r include=FALSE}

---FILE: course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.Rmd---
@@ -6,7 +6,7 @@ output:
     tufte_variant: ""envisioned""
     highlight: pygments
     css: ../lab.css
-link-citations: yes
+link-citations: true
 ---
 
 ```{r include=FALSE}

---FILE: course-materials/lab-instructions/lab-12/lab-12-inference-smoking.Rmd---
@@ -6,7 +6,7 @@ output:
     tufte_variant: ""envisioned""
     highlight: pygments
     css: ../lab.css
-link-citations: yes
+link-citations: true
 ---
 
 ```{r include=FALSE}

---FILE: course-materials/lab-instructions/lab-13/lab-13-work-on-projects.Rmd---
@@ -6,7 +6,7 @@ output:
     tufte_variant: ""envisioned""
     highlight: pygments
     toc: yes
-link-citations: yes
+link-citations: true
 ---
 
 This week you'll be working on your projects.

---FILE: course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.Rmd---
@@ -6,7 +6,7 @@ output:
     tufte_variant: ""envisioned""
     highlight: pygments
     toc: yes
-link-citations: yes
+link-citations: true
 ---
 
 ```{r setup, include=FALSE}",False,True,Rendering / Conversion,3
tidyverse,datascience-box,1a265f3b8baaa25a9d6dfa3961018c13f3cc5634,Gleb Ebert,5892266+gl-eb@users.noreply.github.com,2023-10-06T14:33:35Z,GitHub,noreply@github.com,2023-10-06T14:33:35Z,Fix link to tidyverse design principles (#151),01-design-principles.qmd,True,False,True,False,1,1,2,"---FILE: 01-design-principles.qmd---
@@ -77,7 +77,7 @@ So, in this course, instead of teaching students the basics of regular expressio
 ## Leverage the ecosystem
 
 The course materials make heavy use of the tidyverse for data visualization and data wrangling.
-However, until recently, there was a gap in the R ecosystem for doing basic statistical inference using a syntax that follows [tidyverse design principles](https://principles.tidyverse.org/).
+However, until recently, there was a gap in the R ecosystem for doing basic statistical inference using a syntax that follows [tidyverse design principles](https://design.tidyverse.org/).
 This prompted the developments of [**infer**](http://infer.netlify.com), a package for performing statistical inference using an expressive statistical grammar that coheres with the tidyverse design framework.
 Using infer to introduce statistical inference makes the transition from the first to the second unit of the course much smoother, and the development of the package as a collaboration between like-minded educators is a great example of leveraging an existing ecosystem to provide a smoother learning experience for students.
 ",False,True,Documentation / Formatting,4
tidyverse,datascience-box,41c98cd528f92f993f0a5416efd72fedc733cc75,mine-cetinkaya-rundel,cetinkaya.mine@gmail.com,2023-02-21T15:43:13Z,mine-cetinkaya-rundel,cetinkaya.mine@gmail.com,2023-02-21T15:43:13Z,Moar syntax error stuff,course-materials/_slides/u2-d12-data-import/u2-d12-data-import.Rmd;course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.qmd;course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.Rmd;course-materials/hw-instructions/hw-06/scripts/scrape-pac.R;course-materials/starters/hw/hw-06-money-in-politics/scrape-pac.R,True,False,True,False,166,162,328,"---FILE: course-materials/_slides/u2-d12-data-import/u2-d12-data-import.Rmd---
@@ -138,10 +138,12 @@ names(edibnb_badnames)
 
 ... but R doesn't allow spaces in variable names
 
-```{r error=TRUE}
+````r
 ggplot(edibnb_badnames, aes(x = Number of bathrooms, y = Price)) +
   geom_point()
-```
+````
+
+TO DO: Add error: true
 
 ---
 

---FILE: course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.qmd---
@@ -129,7 +129,9 @@ set.seed(1122)
 
 #### Old model
 
-```{r}
+TO DO: See what `___` is.
+
+````r
 #| label: old-model
 #| error: true
 
@@ -155,4 +157,4 @@ office_fit_old <- office_wflow_old %>%
 tidy(office_fit_old)
 
 ___
-```
+````

---FILE: course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.Rmd---
@@ -99,11 +99,11 @@ You can find descriptions of each of the variables in the help file for the data
 
 3.  Create a faceted histogram where each facet represents a neighbourhood and displays the distribution of Airbnb prices in that neighbourhood. Think critically about whether it makes more sense to stack the facets on top of each other in a column, lay them out in a row, or wrap them around. Along with your visualisation, include your reasoning for the layout you chose for your facets.
 
-```{r}
+````r
 ggplot(data = ___, mapping = aes(x = ___)) +
   geom_histogram(binwidth = ___) +
   facet_wrap(~___)
-```
+````
 
 Let's de-construct this code:
 

---FILE: course-materials/hw-instructions/hw-06/scripts/scrape-pac.R---
@@ -1,78 +1,78 @@
-# load packages ----------------------------------------------------------------
-
-library(tidyverse)
-library(rvest)
-library(here) 
-
-# function: scrape_pac ---------------------------------------------------------
-
-scrape_pac <- function(url) {
-  
-  # read the page
-  page <- ___(___)
-  
-  # exract the table
-  pac <-  page %>%
-    # select node .DataTable (identified using the SelectorGadget)
-    html_node("".DataTable-Partial"") %>%
-    # parse table at node td into a data frame
-    #   table has a head and empty cells should be filled with NAs
-    html_table(""td"", header = ___, fill = ___) %>%
-    # convert to a tibble
-    as_tibble()
-  
-  # rename variables
-  pac <- pac %>%
-    # rename columns
-    rename(
-      name = ___ ,
-      country_parent = ___,
-      total = ___,
-      dems = ___,
-      repubs = ___
-    )
-  
-  # fix name
-  pac <- pac %>%
-    # remove extraneous whitespaces from the name column
-    mutate(name = ___)
-  
-  # add year
-  pac <- pac %>%
-    # extract last 4 characters of the URL and save as year
-    mutate(year = ___)
-  
-  # return data frame
-  pac
-  
-}
-
-# test function ----------------------------------------------------------------
-
-url_2022 <- ""___""
-pac_2022 <- scrape_pac(___)
-
-url_2020 <- ""___""
-pac_2020 <- scrape_pac(___)
-
-url_2000 <- ""___""
-pac_2000 <- scrape_pac(___)
-
-# list of urls -----------------------------------------------------------------
-
-# first part of url
-root <- ""https://www.opensecrets.org/political-action-committees-pacs/foreign-connected-pacs/""
-
-# second part of url (election years as a sequence)
-year <- seq(from = ___, to = ___, by = ___)
-
-# construct urls by pasting first and second parts together
-urls <- paste0(___, ___)
-
-# map the scrape_pac function over list of urls --------------------------------
-
-pac_all <- ___(___, ___)
-
-# write data -------------------------------------------------------------------
-
-write_csv(___, file = here::here(""data/pac-all.csv""))
\ No newline at end of file
+## load packages ----------------------------------------------------------------
+#
+#library(tidyverse)
+#library(rvest)
+#library(here) 
+#
+## function: scrape_pac ---------------------------------------------------------
+#
+#scrape_pac <- function(url) {
+#  
+#  # read the page
+#  page <- ___(___)
+#  
+#  # exract the table
+#  pac <-  page %>%
+#    # select node .DataTable (identified using the SelectorGadget)
+#    html_node("".DataTable-Partial"") %>%
+#    # parse table at node td into a data frame
+#    #   table has a head and empty cells should be filled with NAs
+#    html_table(""td"", header = ___, fill = ___) %>%
+#    # convert to a tibble
+#    as_tibble()
+#  
+#  # rename variables
+#  pac <- pac %>%
+#    # rename columns
+#    rename(
+#      name = ___ ,
+#      country_parent = ___,
+#      total = ___,
+#      dems = ___,
+#      repubs = ___
+#    )
+#  
+#  # fix name
+#  pac <- pac %>%
+#    # remove extraneous whitespaces from the name column
+#    mutate(name = ___)
+#  
+#  # add year
+#  pac <- pac %>%
+#    # extract last 4 characters of the URL and save as year
+#    mutate(year = ___)
+#  
+#  # return data frame
+#  pac
+#  
+#}
+#
+## test function ----------------------------------------------------------------
+#
+#url_2022 <- ""___""
+#pac_2022 <- scrape_pac(___)
+#
+#url_2020 <- ""___""
+#pac_2020 <- scrape_pac(___)
+#
+#url_2000 <- ""___""
+#pac_2000 <- scrape_pac(___)
+#
+## list of urls -----------------------------------------------------------------
+#
+## first part of url
+#root <- ""https://www.opensecrets.org/political-action-committees-pacs/foreign-connected-pacs/""
+#
+## second part of url (election years as a sequence)
+#year <- seq(from = ___, to = ___, by = ___)
+#
+## construct urls by pasting first and second parts together
+#urls <- paste0(___, ___)
+#
+## map the scrape_pac function over list of urls --------------------------------
+#
+#pac_all <- ___(___, ___)
+#
+## write data -------------------------------------------------------------------
+#
+#write_csv(___, file = here::here(""data/pac-all.csv""))
\ No newline at end of file

---FILE: course-materials/starters/hw/hw-06-money-in-politics/scrape-pac.R---
@@ -1,78 +1,78 @@
-# load packages ----------------------------------------------------------------
-
-library(tidyverse)
-library(rvest)
-library(here) 
-
-# function: scrape_pac ---------------------------------------------------------
-
-scrape_pac <- function(url) {
-  
-  # read the page
-  page <- ___(___)
-  
-  # exract the table
-  pac <-  page %>%
-    # select node .DataTable (identified using the SelectorGadget)
-    html_node("".DataTable"") %>%
-    # parse table at node td into a data frame
-    #   table has a head and empty cells should be filled with NAs
-    html_table(""td"", header = ___, fill = ___) %>%
-    # convert to a tibble
-    as_tibble()
-  
-  # rename variables
-  pac <- pac %>%
-    # rename columns
-    rename(
-      name = ___ ,
-      country_parent = ___,
-      total = ___,
-      dems = ___,
-      repubs = ___
-    )
-  
-  # fix name
-  pac <- pac %>%
-    # remove extraneous whitespaces from the name column
-    mutate(name = ___)
-  
-  # add year
-  pac <- pac %>%
-    # extract last 4 characters of the URL and save as year
-    mutate(year = ___)
-  
-  # return data frame
-  pac
-  
-}
-
-# test function ----------------------------------------------------------------
-
-url_2022 <- ""___""
-pac_2022 <- scrape_pac(___)
-
-url_2020 <- ""___""
-pac_2020 <- scrape_pac(___)
-
-url_2000 <- ""___""
-pac_2000 <- scrape_pac(___)
-
-# list of urls -----------------------------------------------------------------
-
-# first part of url
-root <- ""https://www.opensecrets.org/political-action-committees-pacs/foreign-connected-pacs/""
-
-# second part of url (election years as a sequence)
-year <- seq(from = ___, to = ___, by = ___)
-
-# construct urls by pasting first and second parts together
-urls <- paste0(___, ___)
-
-# map the scrape_pac function over list of urls --------------------------------
-
-pac_all <- ___(___, ___)
-
-# write data -------------------------------------------------------------------
-
-write_csv(___, file = here::here(""data/pac-all.csv""))
\ No newline at end of file
+## load packages ----------------------------------------------------------------
+#
+#library(tidyverse)
+#library(rvest)
+#library(here) 
+#
+## function: scrape_pac ---------------------------------------------------------
+#
+#scrape_pac <- function(url) {
+#  
+#  # read the page
+#  page <- ___(___)
+#  
+#  # exract the table
+#  pac <-  page %>%
+#    # select node .DataTable (identified using the SelectorGadget)
+#    html_node("".DataTable"") %>%
+#    # parse table at node td into a data frame
+#    #   table has a head and empty cells should be filled with NAs
+#    html_table(""td"", header = ___, fill = ___) %>%
+#    # convert to a tibble
+#    as_tibble()
+#  
+#  # rename variables
+#  pac <- pac %>%
+#    # rename columns
+#    rename(
+#      name = ___ ,
+#      country_parent = ___,
+#      total = ___,
+#      dems = ___,
+#      repubs = ___
+#    )
+#  
+#  # fix name
+#  pac <- pac %>%
+#    # remove extraneous whitespaces from the name column
+#    mutate(name = ___)
+#  
+#  # add year
+#  pac <- pac %>%
+#    # extract last 4 characters of the URL and save as year
+#    mutate(year = ___)
+#  
+#  # return data frame
+#  pac
+#  
+#}
+#
+## test function ----------------------------------------------------------------
+#
+#url_2022 <- ""___""
+#pac_2022 <- scrape_pac(___)
+#
+#url_2020 <- ""___""
+#pac_2020 <- scrape_pac(___)
+#
+#url_2000 <- ""___""
+#pac_2000 <- scrape_pac(___)
+#
+## list of urls -----------------------------------------------------------------
+#
+## first part of url
+#root <- ""https://www.opensecrets.org/political-action-committees-pacs/foreign-connected-pacs/""
+#
+## second part of url (election years as a sequence)
+#year <- seq(from = ___, to = ___, by = ___)
+#
+## construct urls by pasting first and second parts together
+#urls <- paste0(___, ___)
+#
+## map the scrape_pac function over list of urls --------------------------------
+#
+#pac_all <- ___(___, ___)
+#
+## write data -------------------------------------------------------------------
+#
+#write_csv(___, file = here::here(""data/pac-all.csv""))
\ No newline at end of file",True,True,Implementation / Logic,6
tidyverse,datascience-box,b52111268928359a4ad11fa96a192f1a323f11ac,mine-cetinkaya-rundel,cetinkaya.mine@gmail.com,2023-02-21T15:30:39Z,mine-cetinkaya-rundel,cetinkaya.mine@gmail.com,2023-02-21T15:30:39Z,Comment stuff out for syntax errors,course-materials/_slides/u2-d01-data-viz/u2-d01-data-viz.Rmd;course-materials/_slides/u2-d02-ggplot2/u2-d02-ggplot2.Rmd;course-materials/_slides/u2-d21-functions/u2-d21-functions.Rmd;course-materials/_slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.Rmd;course-materials/application-exercises/ae-08-imdb-webscraping/01-imdb-250movies.R;course-materials/application-exercises/ae-08-imdb-webscraping/02-imdb-tvshows.R;course-materials/application-exercises/ae-08-imdb-webscraping/04-imdb-tvshows-complete.R;course-materials/starters/lab/lab-08-uoe-art/lab-08.Rmd;course-materials/starters/lab/lab-08-uoe-art/scripts/01-scrape-page-one.R;course-materials/starters/lab/lab-08-uoe-art/scripts/02-scrape-page-function.R;course-materials/starters/lab/lab-08-uoe-art/scripts/03-scrape-page-many.R,True,False,True,False,258,256,514,"---FILE: course-materials/_slides/u2-d01-data-viz/u2-d01-data-viz.Rmd---
@@ -223,12 +223,12 @@ ggplot(data = starwars, mapping = aes(x = height, y = mass)) +
 - Plots are constructed in layers
 - Structure of the code for plots can be summarized as
 
-```{r eval = FALSE}
+````r
 ggplot(data = [dataset], 
        mapping = aes(x = [x-variable], y = [y-variable])) +
    geom_xxx() +
    other options
-```
+````
 
 - The ggplot2 package comes with the tidyverse
 

---FILE: course-materials/_slides/u2-d02-ggplot2/u2-d02-ggplot2.Rmd---
@@ -38,13 +38,13 @@ knitr::include_graphics(""img/ggplot2-part-of-tidyverse.png"")
 - **ggplot2** is tidyverse's data visualization package 
 - Structure of the code for plots can be summarized as
 
-```{r eval = FALSE}
+````r
 ggplot(data = [dataset], 
        mapping = aes(x = [x-variable], 
                      y = [y-variable])) +
    geom_xxx() +
    other options
-```
+````
 ]
 
 ---

---FILE: course-materials/_slides/u2-d21-functions/u2-d21-functions.Rmd---
@@ -538,11 +538,11 @@ class: middle
 .pull-left-wide[
 - They take input(s) defined in the function definition
 
-```{r eval=FALSE}
+````r
 function([inputs separated by commas]){
   # what to do with those inputs
 }
-```
+````
 
 - By default they return the last value computed in the function
 

---FILE: course-materials/_slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.Rmd---
@@ -643,15 +643,15 @@ yawn %>%
 - Calculate the sample statistic of interest (difference in propotions)
     - Since the explanatory variable is categorical, specify the order in which the subtraction should occur for the calculation of the sample statistic, $(\hat{p}_{treatment} - \hat{p}_{control})$.
     
-```{r eval=FALSE}
+````r
 {{null_dist <- yawn %>% }}
   specify(response = outcome, explanatory = group, 
           success = ""yawn"") %>%
   hypothesize(null = ""independence"") %>%
   generate(100, type = ""permute"") %>%
   calculate(stat = ""diff in props"", 
             order = c(""treatment"", ""control""))
-```
+````
 ]
 
 ---

---FILE: course-materials/application-exercises/ae-08-imdb-webscraping/01-imdb-250movies.R---
@@ -7,37 +7,37 @@ library(rvest)
 
 # Read html page ---------------------------------------------------------------
 
-page <- read_html(""___"")
+#page <- read_html(""___"")
 
 # Titles -----------------------------------------------------------------------
 
-titles <- page %>%
-  html_nodes(""___"") %>%
-  html_text()
+#titles <- page %>%
+#  html_nodes(""___"") %>%
+#  html_text()
 
 # Years-------------------------------------------------------------------------
 
-years <- page %>%
-  html_nodes(""___"") %>%
-  html_text() %>%
-  str_remove(""___"") %>%
-  str_remove(""___"") %>%
-  as.numeric()
+#years <- page %>%
+#  html_nodes(""___"") %>%
+#  html_text() %>%
+#  str_remove(""___"") %>%
+#  str_remove(""___"") %>%
+#  as.numeric()
 
 # Scores -----------------------------------------------------------------------
 
-ratings <- page %>%
-  html_nodes(""___"") %>%
-  ___ %>%
-  ___
+#ratings <- page %>%
+#  html_nodes(""___"") %>%
+#  ___ %>%
+#  ___
 
 # Put it all in a data frame ---------------------------------------------------
 
-imdb_top_250 <- tibble(
-  title = ___,
-  rating = ___,
-  year = ___
-)
+#imdb_top_250 <- tibble(
+#  title = ___,
+#  rating = ___,
+#  year = ___
+#)
 
 # Add rank ---------------------------------------------------------------------
 

---FILE: course-materials/application-exercises/ae-08-imdb-webscraping/02-imdb-tvshows.R---
@@ -1,63 +1,63 @@
 ## Scrape the list of most populat TV shows from https://www.imdb.com/chart/tvmeter
 
-# load packages ----------------------------------------------------------------
-
-library(tidyverse)
-library(rvest)
-
-# read in http://www.imdb.com/chart/tvmeter ------------------------------------
-
-page <- read_html(""___"")
-
-# years ------------------------------------------------------------------------
-
-years <- page %>%
-  html_nodes(""___"") %>%
-  html_text() %>%
-  ___
-
-# scores -----------------------------------------------------------------------
-
-scores <- page %>%
-  ___
-
-# names ------------------------------------------------------------------------
-
-names <- ___
-
-# tvshows dataframe ------------------------------------------------------------
-
-tvshows <- tibble(
-  rank = 1:100,
-  ___,
-  ___,
-  ___,
-  ___
-)
-
-# add new variables ------------------------------------------------------------
-
-tvshows <- tvshows %>%
-  mutate(
-    genre = NA,
-    runtime = NA,
-    n_episode = NA,
-  )
-
-# add new info for first show --------------------------------------------------
-
-tvshows$genre[1] <- ""__""
-tvshows$runtime[1] <- ___
-tvshows$n_episode[1] <- ___
-
-# add new info for second show --------------------------------------------------
-
-tvshows$genre[2] <- ""__""
-tvshows$runtime[2] <- ___
-tvshows$n_episode[2] <- ___
-
-# add new info for third show --------------------------------------------------
-
-tvshows$genre[3] <- ""__""
-tvshows$runtime[3] <- ___
-tvshows$n_episode[3] <- ___
+## load packages ----------------------------------------------------------------
+#
+#library(tidyverse)
+#library(rvest)
+#
+## read in http://www.imdb.com/chart/tvmeter ------------------------------------
+#
+#page <- read_html(""___"")
+#
+## years ------------------------------------------------------------------------
+#
+#years <- page %>%
+#  html_nodes(""___"") %>%
+#  html_text() %>%
+#  ___
+#
+## scores -----------------------------------------------------------------------
+#
+#scores <- page %>%
+#  ___
+#
+## names ------------------------------------------------------------------------
+#
+#names <- ___
+#
+## tvshows dataframe ------------------------------------------------------------
+#
+#tvshows <- tibble(
+#  rank = 1:100,
+#  ___,
+#  ___,
+#  ___,
+#  ___
+#)
+#
+## add new variables ------------------------------------------------------------
+#
+#tvshows <- tvshows %>%
+#  mutate(
+#    genre = NA,
+#    runtime = NA,
+#    n_episode = NA,
+#  )
+#
+## add new info for first show --------------------------------------------------
+#
+#tvshows$genre[1] <- ""__""
+#tvshows$runtime[1] <- ___
+#tvshows$n_episode[1] <- ___
+#
+## add new info for second show --------------------------------------------------
+#
+#tvshows$genre[2] <- ""__""
+#tvshows$runtime[2] <- ___
+#tvshows$n_episode[2] <- ___
+#
+## add new info for third show --------------------------------------------------
+#
+#tvshows$genre[3] <- ""__""
+#tvshows$runtime[3] <- ___
+#tvshows$n_episode[3] <- ___

---FILE: course-materials/application-exercises/ae-08-imdb-webscraping/04-imdb-tvshows-complete.R---
@@ -2,73 +2,73 @@
 
 # load packages ----------------------------------------------------------------
 
-library(tidyverse)
-library(rvest)
-
-# read in http://www.imdb.com/chart/tvmeter ------------------------------------
-
-page <- read_html(""https://www.imdb.com/chart/tvmeter"")
-
-# years ------------------------------------------------------------------------
-
-years <- page %>%
-  html_nodes(""a+ .secondaryInfo"") %>%
-  html_text() %>%
-  str_remove(""\\("") %>%
-  str_remove(""\\)"") %>%
-  as.numeric()
-
-# scores -----------------------------------------------------------------------
-
-scores <- page %>%
-  html_nodes("".imdbRating"") %>%
-  html_text() %>%
-  as.numeric()
-
-# names ------------------------------------------------------------------------
-
-names <- page %>%
-  html_nodes("".titleColumn"") %>%
-  html_text() %>%
-  str_remove_all(""\n"") %>%
-  str_squish()
-
-# tvshows dataframe ------------------------------------------------------------
-
-tvshows <- tibble(
-  rank = 1:100,
-  name = names,
-  year = years,
-  score = scores
-)
-
-tvshows <- tvshows %>%
-  separate(col = name, into = c(""name"", ""other_info""), sep = "" \\("", extra = ""merge"") %>%
-  select(-other_info)
-
-# add new variables ------------------------------------------------------------
-
-tvshows <- tvshows %>%
-  mutate(
-    genre = NA,
-    runtime = NA,
-    n_episode = NA,
-  )
-
-# add new info for first show --------------------------------------------------
-
-tvshows$genre[1] <- ""Drama, Horror, Mystery""
-tvshows$runtime[1] <- 494
-tvshows$n_episode[1] <- 9
-
-# add new info for second show --------------------------------------------------
-
-tvshows$genre[2] <- ""Action, Comedy, Crime""
-tvshows$runtime[2] <- 60
-tvshows$n_episode[2] <- 17
-
-# add new info for third show --------------------------------------------------
-
-tvshows$genre[3] <- ""__""
-tvshows$runtime[3] <- ___
-tvshows$n_episode[3] <- ___
+#library(tidyverse)
+#library(rvest)
+#
+## read in http://www.imdb.com/chart/tvmeter ------------------------------------
+#
+#page <- read_html(""https://www.imdb.com/chart/tvmeter"")
+#
+## years ------------------------------------------------------------------------
+#
+#years <- page %>%
+#  html_nodes(""a+ .secondaryInfo"") %>%
+#  html_text() %>%
+#  str_remove(""\\("") %>%
+#  str_remove(""\\)"") %>%
+#  as.numeric()
+#
+## scores -----------------------------------------------------------------------
+#
+#scores <- page %>%
+#  html_nodes("".imdbRating"") %>%
+#  html_text() %>%
+#  as.numeric()
+#
+## names ------------------------------------------------------------------------
+#
+#names <- page %>%
+#  html_nodes("".titleColumn"") %>%
+#  html_text() %>%
+#  str_remove_all(""\n"") %>%
+#  str_squish()
+#
+## tvshows dataframe ------------------------------------------------------------
+#
+#tvshows <- tibble(
+#  rank = 1:100,
+#  name = names,
+#  year = years,
+#  score = scores
+#)
+#
+#tvshows <- tvshows %>%
+#  separate(col = name, into = c(""name"", ""other_info""), sep = "" \\("", extra = ""merge"") %>%
+#  select(-other_info)
+#
+## add new variables ------------------------------------------------------------
+#
+#tvshows <- tvshows %>%
+#  mutate(
+#    genre = NA,
+#    runtime = NA,
+#    n_episode = NA,
+#  )
+#
+## add new info for first show --------------------------------------------------
+#
+#tvshows$genre[1] <- ""Drama, Horror, Mystery""
+#tvshows$runtime[1] <- 494
+#tvshows$n_episode[1] <- 9
+#
+## add new info for second show --------------------------------------------------
+#
+#tvshows$genre[2] <- ""Action, Comedy, Crime""
+#tvshows$runtime[2] <- 60
+#tvshows$n_episode[2] <- 17
+#
+## add new info for third show --------------------------------------------------
+#
+#tvshows$genre[3] <- ""__""
+#tvshows$runtime[3] <- ___
+#tvshows$n_episode[3] <- ___

---FILE: course-materials/starters/lab/lab-08-uoe-art/lab-08.Rmd---
@@ -19,12 +19,14 @@ uoe_art <- read_csv(""data/uoe-art.csv"")
 
 ### Exercise 9
 
-```{r separate-title-date, error = TRUE}
+````r
 uoe_art <- uoe_art %>%
   separate(title, into = c(""title"", ""date""), sep = ""\\("") %>%
   mutate(year = str_remove(date, ""\\)"") %>% as.numeric()) %>%
   select(title, artist, year, ___)
-```
+````
+
+TO DO: Add error true
 
 ### Exercise 10
 

---FILE: course-materials/starters/lab/lab-08-uoe-art/scripts/01-scrape-page-one.R---
@@ -1,54 +1,54 @@
 # load packages ----------------------------------------------------------------
 
-library(tidyverse)
-library(rvest)
-
-# set url ----------------------------------------------------------------------
-
-first_url <- ""https://collections.ed.ac.uk/art/search/*:*/Collection:%22edinburgh+college+of+art%7C%7C%7CEdinburgh+College+of+Art%22?offset=0""
-
-# read first page --------------------------------------------------------------
-
-page <- read_html(first_url)
-
-# scrape titles ----------------------------------------------------------------
-
-titles <- page %>%
-  html_nodes("".iteminfo"") %>%
-  html_node(""h3 a"") %>%
-  html_text() %>%
-  ___()
-
-# scrape links -----------------------------------------------------------------
-
-links <- page %>%
-  html_nodes("".iteminfo"") %>%
-  html_node(""h3 a"") %>%
-  html_attr(""href"") %>%
-  str_replace(""\\."", ""___"")
-
-# scrape artists ---------------------------------------------------------------
-
-artists <- page %>%
-  html_nodes("".iteminfo"") %>%
-  html_node("".artist"") %>%
-  ___
-
-# put together in a data frame -------------------------------------------------
-
-first_ten <- tibble(
-  title = ___,
-  artist = ___,
-  link = ___
-)
-
-# scrape second ten paintings --------------------------------------------------
-
-second_url <- ""___""
-
-page <- read_html(second_url)
-...
-
-second_ten <- tibble(
-  ...
-)
\ No newline at end of file
+#library(tidyverse)
+#library(rvest)
+#
+## set url ----------------------------------------------------------------------
+#
+#first_url <- ""https://collections.ed.ac.uk/art/search/*:*/Collection:%22edinburgh+college+of+art%7C%7C%7CEdinburgh+College+of+Art%22?offset=0""
+#
+## read first page --------------------------------------------------------------
+#
+#page <- read_html(first_url)
+#
+## scrape titles ----------------------------------------------------------------
+#
+#titles <- page %>%
+#  html_nodes("".iteminfo"") %>%
+#  html_node(""h3 a"") %>%
+#  html_text() %>%
+#  ___()
+#
+## scrape links -----------------------------------------------------------------
+#
+#links <- page %>%
+#  html_nodes("".iteminfo"") %>%
+#  html_node(""h3 a"") %>%
+#  html_attr(""href"") %>%
+#  str_replace(""\\."", ""___"")
+#
+## scrape artists ---------------------------------------------------------------
+#
+#artists <- page %>%
+#  html_nodes("".iteminfo"") %>%
+#  html_node("".artist"") %>%
+#  ___
+#
+## put together in a data frame -------------------------------------------------
+#
+#first_ten <- tibble(
+#  title = ___,
+#  artist = ___,
+#  link = ___
+#)
+#
+## scrape second ten paintings --------------------------------------------------
+#
+#second_url <- ""___""
+#
+#page <- read_html(second_url)
+#...
+#
+#second_ten <- tibble(
+#  ...
+#)
\ No newline at end of file

---FILE: course-materials/starters/lab/lab-08-uoe-art/scripts/02-scrape-page-function.R---
@@ -1,27 +1,27 @@
 # load packages ----------------------------------------------------------------
 
-library(tidyverse)
-library(rvest)
-
-# function: scrape_page --------------------------------------------------------
-
-___ <- function(url){
-  
-  # read page
-  page <- read_html(url)
-  
-  # scrape titles
-  titles <- ___
-  
-  # scrape links
-  links <- ___
-  
-  # scrape artists 
-  artists <- ___
-  
-  # create and return tibble
-  tibble(
-    ___
-  )
-  
-}
+#library(tidyverse)
+#library(rvest)
+#
+## function: scrape_page --------------------------------------------------------
+#
+#___ <- function(url){
+#  
+#  # read page
+#  page <- read_html(url)
+#  
+#  # scrape titles
+#  titles <- ___
+#  
+#  # scrape links
+#  links <- ___
+#  
+#  # scrape artists 
+#  artists <- ___
+#  
+#  # create and return tibble
+#  tibble(
+#    ___
+#  )
+#  
+#}

---FILE: course-materials/starters/lab/lab-08-uoe-art/scripts/03-scrape-page-many.R---
@@ -1,19 +1,19 @@
-# load packages ----------------------------------------------------------------
-
-library(tidyverse)
-library(rvest)
-library(glue)
-
-# list of urls to be scraped ---------------------------------------------------
-
-root <- ""https://collections.ed.ac.uk/art/search/*:*/Collection:%22edinburgh+college+of+art%7C%7C%7CEdinburgh+College+of+Art%22?offset=""
-numbers <- seq(from = ___, to = ___, by = ___)
-urls <- glue(""{___}{___}"")
-
-# map over all urls and output a data frame ------------------------------------
-
-___ <- map_dfr(___, ___)
-
-# write out data frame ---------------------------------------------------------
-
-write_csv(uoe_art, path = ""data/uoe-art.csv"")
+## load packages ----------------------------------------------------------------
+#
+#library(tidyverse)
+#library(rvest)
+#library(glue)
+#
+## list of urls to be scraped ---------------------------------------------------
+#
+#root <- ""https://collections.ed.ac.uk/art/search/*:*/Collection:%22edinburgh+college+of+art%7C%7C%7CEdinburgh+College+of+Art%22?offset=""
+#numbers <- seq(from = ___, to = ___, by = ___)
+#urls <- glue(""{___}{___}"")
+#
+## map over all urls and output a data frame ------------------------------------
+#
+#___ <- map_dfr(___, ___)
+#
+## write out data frame ---------------------------------------------------------
+#
+#write_csv(uoe_art, path = ""data/uoe-art.csv"")",True,True,Implementation / Logic,6
tidyverse,datascience-box,2f426c6e41006a68b9e51f7c9cd2d8805416d62e,Mine Cetinkaya-Rundel,cetinkaya.mine@gmail.com,2023-02-07T05:38:29Z,GitHub,noreply@github.com,2023-02-07T05:38:29Z,"Fix link, closes #143",02-interactive-tutorials.qmd,True,False,True,False,1,1,2,"---FILE: 02-interactive-tutorials.qmd---
@@ -39,7 +39,7 @@ The goal of this tutorial is not to conduct a thorough analysis of Airbnb listin
 -   Calculate summary statistics with `summarise()`.
 -   Arrange output of dplyr chains with `arrange()`.
 
-[\[Tutorial\]](https://minecr.shinyapps.io/dsbox-03-collegegrads/) [\[Source\]](https://github.com/rstudio-education/dsbox/tree/master/inst/tutorials/03-collegegrads)
+[\[Tutorial\]](https://minecr.shinyapps.io/dsbox-03-collegemajors/) [\[Source\]](https://github.com/rstudio-education/dsbox/tree/main/inst/tutorials/03-collegemajors)
 :::
 
 ::: tutorial",False,True,Rendering / Conversion,3
tidyverse,datascience-box,a8d853efdd89c42d9a40e10216db226b52676c06,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2022-08-09T22:09:43Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2022-08-09T22:09:43Z,Fix link to slides,02-ethics.qmd;02-exploring-data.qmd;02-hello-world.qmd;02-looking-further.qmd;02-making-rigorous-conclusions.qmd,True,False,True,False,46,46,92,"---FILE: 02-ethics.qmd---
@@ -15,7 +15,7 @@ Course lectures are supplemented with ""guest lectures"" from domain experts.
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u3-d01-misrepresentation)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u3-d01-misrepresentation)
 :::
 
 ::: video
@@ -39,7 +39,7 @@ Course lectures are supplemented with ""guest lectures"" from domain experts.
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u3-d02-privacy)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u3-d02-privacy)
 :::
 
 ::: video
@@ -63,7 +63,7 @@ Course lectures are supplemented with ""guest lectures"" from domain experts.
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u3-d03-algorithmic-bias)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u3-d03-algorithmic-bias)
 :::
 
 ::: video

---FILE: 02-exploring-data.qmd---
@@ -24,7 +24,7 @@ You can join the workspace and play around with the application exercises.
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d01-data-viz)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u2-d01-data-viz)
 :::
 
 ::: video
@@ -40,7 +40,7 @@ You can join the workspace and play around with the application exercises.
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d02-ggplot2)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u2-d02-ggplot2)
 :::
 
 ::: video
@@ -60,7 +60,7 @@ R4DS :: [Chp 3 - Data visualization](https://r4ds.had.co.nz/data-visualisation.h
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d03-viz-num)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u2-d03-viz-num)
 :::
 
 ::: video
@@ -80,7 +80,7 @@ IMS :: [Chp 4 - Exploring numerical data](https://openintro-ims.netlify.app/expl
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d04-viz-cat)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u2-d04-viz-cat)
 :::
 
 ::: video
@@ -114,7 +114,7 @@ IMS :: [Chp 5 - Exploring categorical data](https://openintro-ims.netlify.app/ex
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d05-tidy-data)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u2-d05-tidy-data)
 :::
 
 ::: video
@@ -134,7 +134,7 @@ JSS :: [Tidy data](https://www.jstatsoft.org/article/view/v059i10)
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d06-grammar-wrangle)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u2-d06-grammar-wrangle)
 :::
 
 ::: video
@@ -150,7 +150,7 @@ JSS :: [Tidy data](https://www.jstatsoft.org/article/view/v059i10)
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d07-single-df)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u2-d07-single-df)
 :::
 
 ::: video
@@ -170,7 +170,7 @@ R4DS :: [Chp 5 - Data transformation](https://r4ds.had.co.nz/transform.html)
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d08-multi-df)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u2-d08-multi-df)
 :::
 
 ::: video
@@ -190,7 +190,7 @@ R4DS :: [Chp 13 - Relational data](https://r4ds.had.co.nz/relational-data.html)
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d09-tidying)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u2-d09-tidying)
 :::
 
 ::: video
@@ -224,7 +224,7 @@ R4DS :: [Chp 12 - Tidy data](https://r4ds.had.co.nz/tidy-data.html)
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d10-data-types)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u2-d10-data-types)
 :::
 
 ::: video
@@ -240,7 +240,7 @@ R4DS :: [Chp 12 - Tidy data](https://r4ds.had.co.nz/tidy-data.html)
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d11-data-classes)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u2-d11-data-classes)
 :::
 
 ::: video
@@ -260,7 +260,7 @@ R4DS :: [Chp 15 - Factors](https://r4ds.had.co.nz/factors.html)
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d12-data-import)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u2-d12-data-import)
 :::
 
 ::: video
@@ -280,7 +280,7 @@ R4DS :: [Chp 11 - Data import](https://r4ds.had.co.nz/data-import.html)
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d13-data-recode)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u2-d13-data-recode)
 :::
 
 ::: video
@@ -334,7 +334,7 @@ R4DS :: [Sec 16.1 - 16.3 - Dates and times](https://r4ds.had.co.nz/dates-and-tim
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d14-effective-dataviz)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u2-d14-effective-dataviz)
 :::
 
 ::: video
@@ -366,7 +366,7 @@ IMS :: [Chp 6 - Applications: Explore](https://openintro-ims.netlify.app/explore
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d15-studies-confounding)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u2-d15-studies-confounding)
 :::
 
 ::: video
@@ -386,7 +386,7 @@ IMS :: [Chp 2 - Study design](https://openintro-ims.netlify.app/data-design.html
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d16-simpsons-paradox)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u2-d16-simpsons-paradox)
 :::
 
 ::: video
@@ -402,7 +402,7 @@ IMS :: [Chp 2 - Study design](https://openintro-ims.netlify.app/data-design.html
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d17-doing-data-science)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u2-d17-doing-data-science)
 :::
 
 ::: video
@@ -424,7 +424,7 @@ R4DS :: [Chp 7 - Exploratory data analysis](https://r4ds.had.co.nz/exploratory-d
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d18-web-scrape)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u2-d18-web-scrape)
 :::
 
 ::: video
@@ -440,7 +440,7 @@ R4DS :: [Chp 7 - Exploratory data analysis](https://r4ds.had.co.nz/exploratory-d
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d19-top-250-imdb)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u2-d19-top-250-imdb)
 :::
 
 ::: video
@@ -456,7 +456,7 @@ R4DS :: [Chp 7 - Exploratory data analysis](https://r4ds.had.co.nz/exploratory-d
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d20-considerations)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u2-d20-considerations)
 :::
 
 ::: video
@@ -484,7 +484,7 @@ R4DS :: [Chp 7 - Exploratory data analysis](https://r4ds.had.co.nz/exploratory-d
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d21-functions)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u2-d21-functions)
 :::
 
 ::: video
@@ -504,7 +504,7 @@ R4DS :: [Chp 19 - Functions](https://r4ds.had.co.nz/functions.html)
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d22-iteration)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u2-d22-iteration)
 :::
 
 ::: video

---FILE: 02-hello-world.qmd---
@@ -31,7 +31,7 @@ You can join the workspace and play around with the sample application exercises
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u1-d01-welcome)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u1-d01-welcome)
 :::
 
 ::: video
@@ -67,7 +67,7 @@ You can join the workspace and play around with the sample application exercises
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u1-d02-toolkit-r)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u1-d02-toolkit-r)
 :::
 
 ::: video
@@ -96,7 +96,7 @@ You can join the workspace and play around with the sample application exercises
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u1-d03-toolkit-git)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u1-d03-toolkit-git)
 :::
 
 ::: video

---FILE: 02-looking-further.qmd---
@@ -16,7 +16,7 @@ Note that the slides in this unit are a bit more sparse than the others, and muc
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u5-d01-text-analysis)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u5-d01-text-analysis)
 :::
 
 ::: video
@@ -32,7 +32,7 @@ Note that the slides in this unit are a bit more sparse than the others, and muc
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u5-d02-comparing-texts)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u5-d02-comparing-texts)
 :::
 
 ::: video
@@ -48,7 +48,7 @@ Note that the slides in this unit are a bit more sparse than the others, and muc
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u5-d03-interactive-web-app)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u5-d03-interactive-web-app)
 :::
 
 ::: video
@@ -64,7 +64,7 @@ Note that the slides in this unit are a bit more sparse than the others, and muc
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u5-d04-machine-learning)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u5-d04-machine-learning)
 :::
 
 ::: video
@@ -96,7 +96,7 @@ Note that the slides in this unit are a bit more sparse than the others, and muc
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u5-d07-bayes-inf)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u5-d07-bayes-inf)
 :::
 :::
 

---FILE: 02-making-rigorous-conclusions.qmd---
@@ -23,7 +23,7 @@ You can join the workspace and play around with the sample application exercises
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d01-language-of-models)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u4-d01-language-of-models)
 :::
 
 ::: video
@@ -39,7 +39,7 @@ You can join the workspace and play around with the sample application exercises
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d02-fitting-interpreting-models)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u4-d02-fitting-interpreting-models)
 :::
 
 ::: video
@@ -59,7 +59,7 @@ IMS :: [Chp 7 - Linear regression with a single predictor](https://openintro-ims
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d03-modeling-nonlinear-relationships)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u4-d03-modeling-nonlinear-relationships)
 :::
 
 ::: video
@@ -75,7 +75,7 @@ IMS :: [Chp 7 - Linear regression with a single predictor](https://openintro-ims
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d04-model-multiple-predictors)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u4-d04-model-multiple-predictors)
 :::
 
 ::: video
@@ -95,7 +95,7 @@ IMS :: [Chp 8 - Linear regression with multiple predictors](https://openintro-im
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d05-more-model-multiple-predictors)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u4-d05-more-model-multiple-predictors)
 :::
 
 ::: video
@@ -113,7 +113,7 @@ IMS :: [Chp 8 - Linear regression with multiple predictors](https://openintro-im
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d06-logistic-reg)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u4-d06-logistic-reg)
 :::
 
 ::: video
@@ -133,7 +133,7 @@ IMS :: [Chp 9 - Logistic regression](https://openintro-ims.netlify.app/model-log
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d07-prediction-overfitting)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u4-d07-prediction-overfitting)
 :::
 
 ::: video
@@ -153,7 +153,7 @@ tidymodels :: [Build a model](https://www.tidymodels.org/start/models/)
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d08-feature-engineering)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u4-d08-feature-engineering)
 :::
 
 ::: video
@@ -175,7 +175,7 @@ tidymodels :: [Preprocess your data with recipes](https://www.tidymodels.org/sta
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d09-cross-validation)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u4-d09-cross-validation)
 :::
 
 ::: video
@@ -221,7 +221,7 @@ tidymodels :: [Evaluate your model with resampling](https://www.tidymodels.org/s
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d10-quantify-uncertainty)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u4-d10-quantify-uncertainty)
 :::
 
 ::: video
@@ -237,7 +237,7 @@ tidymodels :: [Evaluate your model with resampling](https://www.tidymodels.org/s
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d11-bootstrap)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u4-d11-bootstrap)
 :::
 
 ::: video
@@ -257,7 +257,7 @@ IMS :: [Chp 12 - Confidence intervals with bootstrapping](https://openintro-ims.
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d12-hypothesis-testing)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u4-d12-hypothesis-testing)
 :::
 
 ::: reading
@@ -273,7 +273,7 @@ IMS :: [Chp 12 - Confidence intervals with bootstrapping](https://openintro-ims.
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d13-inference-overview)
+[Source](https://github.com/rstudio-education/datascience-box/tree/main/course-materials/_slides/u4-d13-inference-overview)
 :::
 :::
 ",False,True,Documentation / Formatting,4
tidyverse,datascience-box,bfa48628c4bd41e42b476259ee7792fb2442e66e,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2022-06-22T18:06:46Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2022-06-22T18:06:46Z,"Fix link to merge conflict activity, closes #137",03-version-control.qmd,True,False,True,False,1,1,2,"---FILE: 03-version-control.qmd---
@@ -29,7 +29,7 @@ Students often develop elaborate workflows to avoid these types of issues but th
 
 It is super important to encourage students to **commit early and often** to reduce the size of each change.
 Finally, in the early stages of learning git it is useful to engineer situations in which students encounter problems while they are in the classroom so that the professor and teaching assistants are present to troubleshoot and walk them through the process in person.
-A sample activity for resolving merge conflicts is provided in the course materials [here](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-06/lab-06-ugly-charts.html).
+A sample activity for resolving merge conflicts is provided in the course materials [here](https://datasciencebox.org/course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#merge-conflict-activity).
 
 ## GitHub
 ",False,True,Rendering / Conversion,3
tidyverse,datascience-box,ea5c77055e6eeb61b2bb7d24207194ddcc597eec,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2022-06-17T12:52:48Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2022-06-17T12:52:48Z,fix typo,design.qmd,True,False,True,False,1,1,2,"---FILE: design.qmd---
@@ -3,5 +3,5 @@ title: ""Course design""
 editor: visual
 ---
 
-Want some resources for learning more about teaching with Data Science in a Box or need a 10 or 15-week term schedule?
+Want some resources for learning more about teaching with Data Science in a Box or need a 11 or 15-week term schedule?
 You've come to the right place.",False,True,Documentation / Formatting,4
tidyverse,datascience-box,439693e301fb75efd630184589267fa6032addde,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2022-06-17T06:06:59Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2022-06-17T06:06:59Z,Fix links,02-ethics.qmd;02-exams.qmd;02-exploring-data.qmd;02-looking-further.qmd;02-making-rigorous-conclusions.qmd,True,False,True,False,26,26,52,"---FILE: 02-ethics.qmd---
@@ -111,7 +111,7 @@ Course lectures are supplemented with ""guest lectures"" from domain experts.
 Improving data visualisations to better convey the right message
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-09/lab-09-better-viz.html)
+[Instructions](https://datasciencebox.org/course-materials/lab-instructions/lab-09/lab-09-better-viz.html)
 :::
 
 ::: source

---FILE: 02-exams.qmd---
@@ -10,11 +10,11 @@ But they might give you some idea about how to structure take home exams, how to
 ::: exam
 **Exam 1**
 
-[\[Instructions\]](https://rstudio-education.github.io/datascience-box/course-materials/exams/exam-01/) [\[Source\]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/exams/exam-01)
+[\[Instructions\]](https://datasciencebox.org/course-materials/exams/exam-01/) [\[Source\]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/exams/exam-01)
 :::
 
 ::: exam
 **Exam 2**
 
-[\[Instructions\]](https://rstudio-education.github.io/datascience-box/course-materials/exams/exam-02/) [\[Source\]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/exams/exam-02)
+[\[Instructions\]](https://datasciencebox.org/course-materials/exams/exam-02/) [\[Source\]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/exams/exam-02)
 :::

---FILE: 02-exploring-data.qmd---
@@ -524,7 +524,7 @@ R4DS :: [Chp 20 - Iteration](https://r4ds.had.co.nz/iteration.html)
 Introduction to R, R Markdown, Git, and GitHub
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-01/lab-01-hello-r.html)
+[Instructions](https://datasciencebox.org/course-materials/lab-instructions/lab-01/lab-01-hello-r.html)
 :::
 
 ::: source
@@ -542,7 +542,7 @@ Introduction to R, R Markdown, Git, and GitHub
 Introduction to working with data in R with the tidyverse
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html)
+[Instructions](https://datasciencebox.org/course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html)
 :::
 
 ::: source
@@ -560,7 +560,7 @@ Introduction to working with data in R with the tidyverse
 Data wrangling and tidying
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html)
+[Instructions](https://datasciencebox.org/course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html)
 :::
 
 ::: source
@@ -578,7 +578,7 @@ Data wrangling and tidying
 Visualizing spatial data
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html)
+[Instructions](https://datasciencebox.org/course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html)
 :::
 
 ::: source
@@ -596,7 +596,7 @@ Visualizing spatial data
 Wrangling spatial data
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html)
+[Instructions](https://datasciencebox.org/course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html)
 :::
 
 ::: source
@@ -614,7 +614,7 @@ Wrangling spatial data
 Critiquing and improving data visualisations
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-06/lab-06-sad-plots.html)
+[Instructions](https://datasciencebox.org/course-materials/lab-instructions/lab-06/lab-06-sad-plots.html)
 :::
 
 ::: source
@@ -632,7 +632,7 @@ Critiquing and improving data visualisations
 Data visualisation, confounding, multivariable relationships
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.html)
+[Instructions](https://datasciencebox.org/course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.html)
 :::
 
 ::: source
@@ -650,7 +650,7 @@ Data visualisation, confounding, multivariable relationships
 Web scraping, function, iteration
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-08/lab-08-uoe-art.html)
+[Instructions](https://datasciencebox.org/course-materials/lab-instructions/lab-08/lab-08-uoe-art.html)
 :::
 
 ::: source
@@ -670,7 +670,7 @@ Web scraping, function, iteration
 Introduction to working with data in R with the tidyverse
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-01/hw-01-pet-names.html)
+[Instructions](https://datasciencebox.org/course-materials/hw-instructions/hw-01/hw-01-pet-names.html)
 :::
 
 ::: source
@@ -688,7 +688,7 @@ Introduction to working with data in R with the tidyverse
 Data visualisation with the tidyverse
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html)
+[Instructions](https://datasciencebox.org/course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html)
 :::
 
 ::: source
@@ -706,7 +706,7 @@ Data visualisation with the tidyverse
 Data wrangling, tidying, and visualization
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-03/hw-03-accidents.html)
+[Instructions](https://datasciencebox.org/course-materials/hw-instructions/hw-03/hw-03-accidents.html)
 :::
 
 ::: source
@@ -724,7 +724,7 @@ Data wrangling, tidying, and visualization
 More data wrangling, summarizing, and visualization
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-04/hw-04-college-majors.html)
+[Instructions](https://datasciencebox.org/course-materials/hw-instructions/hw-04/hw-04-college-majors.html)
 :::
 
 ::: source
@@ -742,7 +742,7 @@ More data wrangling, summarizing, and visualization
 More data wrangling, summarizing, and visualization
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-05/hw-05-legos.html)
+[Instructions](https://datasciencebox.org/course-materials/hw-instructions/hw-05/hw-05-legos.html)
 :::
 
 ::: source
@@ -760,7 +760,7 @@ More data wrangling, summarizing, and visualization
 Web scraping, functions, and iteration
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html)
+[Instructions](https://datasciencebox.org/course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html)
 :::
 
 ::: source

---FILE: 02-looking-further.qmd---
@@ -108,7 +108,7 @@ Note that the slides in this unit are a bit more sparse than the others, and muc
 Fitting and interpreting simple linear regression models
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-13/lab-13-work-on-projects.html)
+[Instructions](https://datasciencebox.org/course-materials/lab-instructions/lab-13/lab-13-work-on-projects.html)
 :::
 
 ::: source
@@ -122,7 +122,7 @@ Fitting and interpreting simple linear regression models
 Fitting and interpreting simple linear regression models
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html)
+[Instructions](https://datasciencebox.org/course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html)
 :::
 
 ::: source
@@ -138,7 +138,7 @@ Fitting and interpreting simple linear regression models
 Model validation and inference
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-10/hw-10-wrap-up.html)
+[Instructions](https://datasciencebox.org/course-materials/hw-instructions/hw-10/hw-10-wrap-up.html)
 :::
 
 ::: source

---FILE: 02-making-rigorous-conclusions.qmd---
@@ -285,7 +285,7 @@ IMS :: [Chp 12 - Confidence intervals with bootstrapping](https://openintro-ims.
 Fitting and interpreting simple linear regression models
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html)
+[Instructions](https://datasciencebox.org/course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html)
 :::
 
 ::: source
@@ -303,7 +303,7 @@ Fitting and interpreting simple linear regression models
 Fitting and interpreting multiple linear regression models
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html)
+[Instructions](https://datasciencebox.org/course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html)
 :::
 
 ::: source
@@ -321,7 +321,7 @@ Fitting and interpreting multiple linear regression models
 Constructing confidence intervals, conducting hypothesis tests, and interpreting results in context of the data
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html)
+[Instructions](https://datasciencebox.org/course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html)
 :::
 
 ::: source
@@ -341,7 +341,7 @@ Constructing confidence intervals, conducting hypothesis tests, and interpreting
 Exploratory data analysis and fitting and interpreting models
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html)
+[Instructions](https://datasciencebox.org/course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html)
 :::
 
 ::: source
@@ -359,7 +359,7 @@ Exploratory data analysis and fitting and interpreting models
 Fitting and interpreting models
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html)
+[Instructions](https://datasciencebox.org/course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html)
 :::
 
 ::: source
@@ -377,7 +377,7 @@ Fitting and interpreting models
 Model validation and inference
 
 ::: instructions
-[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html)
+[Instructions](https://datasciencebox.org/course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html)
 :::
 
 ::: source",False,True,Rendering / Conversion,3
tidyverse,datascience-box,d1ff0d31572288be3d60221d2460d841d2e8b173,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2022-06-17T06:03:52Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2022-06-17T06:03:52Z,Fix broken links,02-project.qmd,True,False,True,False,3,3,6,"---FILE: 02-project.qmd---
@@ -3,8 +3,8 @@ title: ""Project""
 ---
 
 The following is a sample project assignment for this curriculum.
-You can find the source code for this assignment write up [here](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/project).
-I've also provided [sample evaluation forms](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/project/evaluation-forms) to be used by the teaching team and students as well as a [sample repo structure](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/project/repo-structure) for the project.
+You can find the source code for this assignment write up [here](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/project-instructions).
+I've also provided [sample evaluation forms](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/project-instructions/evaluation-forms) to be used by the teaching team and students as well as a [sample repo structure](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/project-instructions/repo-structure) for the project.
 
 ------------------------------------------------------------------------
 
@@ -137,7 +137,7 @@ The presentation line-up will be generated randomly.
 The grading scheme for the presentation is as follows:
 
 | Total                                                                                                                                                                                                          | 50 pts |
-|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------|
+|-------------------------------------------------------------|-----------|
 | Time management: Did the team divide the time well amongst themselves or got cut off going over time?                                                                                                          | 4 pts  |
 | Content: Is the research question well designed and is the data being used relevant to the research question?                                                                                                  | 5 pts  |
 | Professionalism: How well did the team present? Does the presentation appear to be well practiced? Did everyone get a chance to say something meaningful about the project?                                    | 5 pts  |",False,True,Rendering / Conversion,3
tidyverse,datascience-box,c20da4ac61883c0b37fb9f677b329ef0a11b92b2,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2022-06-17T06:00:50Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2022-06-17T06:00:50Z,Fix links to AEs,02-exploring-data.qmd;02-hello-world.qmd;02-making-rigorous-conclusions.qmd,True,False,True,False,12,12,24,"---FILE: 02-exploring-data.qmd---
@@ -96,7 +96,7 @@ IMS :: [Chp 5 - Exploring categorical data](https://openintro-ims.netlify.app/ex
 **StarWars + Dataviz**
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-03-starwars-dataviz/starwars.Rmd)
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-03-starwars-dataviz/starwars.qmd)
 :::
 
 ::: video
@@ -206,7 +206,7 @@ R4DS :: [Chp 12 - Tidy data](https://r4ds.had.co.nz/tidy-data.html)
 **Hotels + Data wrangling**
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.Rmd)
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.qmd)
 :::
 
 ::: video
@@ -296,11 +296,11 @@ R4DS :: [Sec 16.1 - 16.3 - Dates and times](https://r4ds.had.co.nz/dates-and-tim
 **Hotels + Data types**
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-05-hotels-datatypes/hotels-forcats.Rmd)
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-05-hotels-datatypes/hotels-forcats.qmd)
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-05-hotels-datatypes/type-coercion.Rmd)
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-05-hotels-datatypes/type-coercion.qmd)
 :::
 
 ::: video
@@ -312,11 +312,11 @@ R4DS :: [Sec 16.1 - 16.3 - Dates and times](https://r4ds.had.co.nz/dates-and-tim
 **Nobels + Sales + Data import**
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-06-nobels-sales-dataimport/nobels-csv.Rmd)
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-06-nobels-sales-dataimport/nobels-csv.qmd)
 :::
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-06-nobels-sales-dataimport/sales-excel.Rmd)
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-06-nobels-sales-dataimport/sales-excel.qmd)
 :::
 
 ::: video
@@ -350,7 +350,7 @@ IMS :: [Chp 6 - Applications: Explore](https://openintro-ims.netlify.app/explore
 **Brexit + Telling stories with dataviz**
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-07-brexit-story-dataviz/brexit.Rmd)
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-07-brexit-story-dataviz/brexit.qmd)
 :::
 
 ::: video

---FILE: 02-hello-world.qmd---
@@ -45,7 +45,7 @@ You can join the workspace and play around with the sample application exercises
 > **Option 1 - UN Votes**
 >
 > ::: source
-> [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-01a-un-votes/unvotes.Rmd)
+> [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-01a-un-votes/unvotes.qmd)
 > :::
 >
 > ::: video
@@ -55,7 +55,7 @@ You can join the workspace and play around with the sample application exercises
 > **Option 2 - COVID-19**
 >
 > ::: source
-> [Source](https://github.com/rstudio-education/datascience-box/blob/master/course-materials/application-exercises/ae-01b-covid/covid.Rmd)
+> [Source](https://github.com/rstudio-education/datascience-box/blob/master/course-materials/application-exercises/ae-01b-covid/covid.qmd)
 > :::
 :::
 
@@ -84,7 +84,7 @@ You can join the workspace and play around with the sample application exercises
 **Bechdel + R Markdown**
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.Rmd)
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.qmd)
 :::
 :::
 

---FILE: 02-making-rigorous-conclusions.qmd---
@@ -191,7 +191,7 @@ tidymodels :: [Evaluate your model with resampling](https://www.tidymodels.org/s
 **The Office + Feature engineering, Pt. 1**
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.Rmd)
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.qmd)
 :::
 
 ::: video
@@ -203,7 +203,7 @@ tidymodels :: [Evaluate your model with resampling](https://www.tidymodels.org/s
 **The Office + Cross validation, Pt. 2**
 
 ::: source
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.Rmd)
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.qmd)
 :::
 
 ::: video",False,True,Rendering / Conversion,3
tidyverse,datascience-box,e16e14192ffcbc7d6c27d35ba6625bd7e04dbc56,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2022-06-17T05:55:02Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2022-06-17T05:55:02Z,Fix links to slides,02-ethics.qmd;02-exploring-data.qmd;02-hello-world.qmd;02-looking-further.qmd;02-making-rigorous-conclusions.qmd,True,False,True,False,48,48,96,"---FILE: 02-ethics.qmd---
@@ -11,7 +11,7 @@ Course lectures are supplemented with ""guest lectures"" from domain experts.
 **Unit 3 - Deck 1: Misrepresentation**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u3-d01-misrepresentation/u3-d01-misrepresentation.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u3-d01-misrepresentation/u3-d01-misrepresentation.html#1)
 :::
 
 ::: source
@@ -35,7 +35,7 @@ Course lectures are supplemented with ""guest lectures"" from domain experts.
 **Unit 3 - Deck 2: Data privacy**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u3-d02-privacy/u3-d02-privacy.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u3-d02-privacy/u3-d02-privacy.html#1)
 :::
 
 ::: source
@@ -59,7 +59,7 @@ Course lectures are supplemented with ""guest lectures"" from domain experts.
 **Unit 3 - Deck 3: Algorithmic bias**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#1)
 :::
 
 ::: source

---FILE: 02-exploring-data.qmd---
@@ -20,7 +20,7 @@ You can join the workspace and play around with the application exercises.
 **Unit 2 - Deck 1: Data and visualisation**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d01-data-viz/u2-d01-data-viz.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u2-d01-data-viz/u2-d01-data-viz.html#1)
 :::
 
 ::: source
@@ -36,7 +36,7 @@ You can join the workspace and play around with the application exercises.
 **Unit 2 - Deck 2: Visualising data with ggplot2**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d02-ggplot2/u2-d02-ggplot2.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u2-d02-ggplot2/u2-d02-ggplot2.html#1)
 :::
 
 ::: source
@@ -56,7 +56,7 @@ R4DS :: [Chp 3 - Data visualization](https://r4ds.had.co.nz/data-visualisation.h
 **Unit 2 - Deck 3: Visualising numerical data**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d03-viz-num/u2-d03-viz-num.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u2-d03-viz-num/u2-d03-viz-num.html#1)
 :::
 
 ::: source
@@ -76,7 +76,7 @@ IMS :: [Chp 4 - Exploring numerical data](https://openintro-ims.netlify.app/expl
 **Unit 2 - Deck 4: Visualising categorical data**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d04-viz-cat/u2-d04-viz-cat.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u2-d04-viz-cat/u2-d04-viz-cat.html#1)
 :::
 
 ::: source
@@ -110,7 +110,7 @@ IMS :: [Chp 5 - Exploring categorical data](https://openintro-ims.netlify.app/ex
 **Unit 2 - Deck 5: Tidy data**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d05-tidy-data/u2-d05-tidy-data.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u2-d05-tidy-data/u2-d05-tidy-data.html#1)
 :::
 
 ::: source
@@ -130,7 +130,7 @@ JSS :: [Tidy data](https://www.jstatsoft.org/article/view/v059i10)
 **Unit 2 - Deck 6: Grammar of data wrangling**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#1)
 :::
 
 ::: source
@@ -146,7 +146,7 @@ JSS :: [Tidy data](https://www.jstatsoft.org/article/view/v059i10)
 **Unit 2 - Deck 7: Working with a single data frame**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d07-single-df/u2-d07-single-df.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u2-d07-single-df/u2-d07-single-df.html#1)
 :::
 
 ::: source
@@ -166,7 +166,7 @@ R4DS :: [Chp 5 - Data transformation](https://r4ds.had.co.nz/transform.html)
 **Unit 2 - Deck 8: Working with multiple data frames**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d08-multi-df/u2-d08-multi-df.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u2-d08-multi-df/u2-d08-multi-df.html#1)
 :::
 
 ::: source
@@ -186,7 +186,7 @@ R4DS :: [Chp 13 - Relational data](https://r4ds.had.co.nz/relational-data.html)
 **Unit 2 - Deck 9: Tidying data**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d09-tidying/u2-d09-tidying.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u2-d09-tidying/u2-d09-tidying.html#1)
 :::
 
 ::: source
@@ -220,7 +220,7 @@ R4DS :: [Chp 12 - Tidy data](https://r4ds.had.co.nz/tidy-data.html)
 **Unit 2 - Deck 10: Data types**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d10-data-types/u2-d10-data-types.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u2-d10-data-types/u2-d10-data-types.html#1)
 :::
 
 ::: source
@@ -236,7 +236,7 @@ R4DS :: [Chp 12 - Tidy data](https://r4ds.had.co.nz/tidy-data.html)
 **Unit 2 - Deck 11: Data classes**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d11-data-classes/u2-d11-data-classes.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u2-d11-data-classes/u2-d11-data-classes.html#1)
 :::
 
 ::: source
@@ -256,7 +256,7 @@ R4DS :: [Chp 15 - Factors](https://r4ds.had.co.nz/factors.html)
 **Unit 2 - Deck 12: Importing data**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d12-data-import/u2-d12-data-import.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u2-d12-data-import/u2-d12-data-import.html#1)
 :::
 
 ::: source
@@ -276,7 +276,7 @@ R4DS :: [Chp 11 - Data import](https://r4ds.had.co.nz/data-import.html)
 **Unit 2 - Deck 13: Recoding data**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d13-data-recode/u2-d13-data-recode.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u2-d13-data-recode/u2-d13-data-recode.html#1)
 :::
 
 ::: source
@@ -330,7 +330,7 @@ R4DS :: [Sec 16.1 - 16.3 - Dates and times](https://r4ds.had.co.nz/dates-and-tim
 **Unit 2 - Deck 14: Tips for effective data visualization**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#1)
 :::
 
 ::: source
@@ -362,7 +362,7 @@ IMS :: [Chp 6 - Applications: Explore](https://openintro-ims.netlify.app/explore
 **Unit 2 - Deck 15: Scientific studies and confounding**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html#1)
 :::
 
 ::: source
@@ -382,7 +382,7 @@ IMS :: [Chp 2 - Study design](https://openintro-ims.netlify.app/data-design.html
 **Unit 2 - Deck 16: Simpson's paradox**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#1)
 :::
 
 ::: source
@@ -398,7 +398,7 @@ IMS :: [Chp 2 - Study design](https://openintro-ims.netlify.app/data-design.html
 **Unit 2 - Deck 17: Doing data science**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#1)
 :::
 
 ::: source
@@ -420,7 +420,7 @@ R4DS :: [Chp 7 - Exploratory data analysis](https://r4ds.had.co.nz/exploratory-d
 **Unit 2 - Deck 18: Web scraping**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d18-web-scrape/u2-d18-web-scrape.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u2-d18-web-scrape/u2-d18-web-scrape.html#1)
 :::
 
 ::: source
@@ -436,7 +436,7 @@ R4DS :: [Chp 7 - Exploratory data analysis](https://r4ds.had.co.nz/exploratory-d
 **Unit 2 - Deck 19: Scraping top 250 movies on IMDB**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#1)
 :::
 
 ::: source
@@ -452,7 +452,7 @@ R4DS :: [Chp 7 - Exploratory data analysis](https://r4ds.had.co.nz/exploratory-d
 **Unit 2 - Deck 20: Web scraping considerations**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d20-considerations/u2-d20-considerations.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u2-d20-considerations/u2-d20-considerations.html#1)
 :::
 
 ::: source
@@ -480,7 +480,7 @@ R4DS :: [Chp 7 - Exploratory data analysis](https://r4ds.had.co.nz/exploratory-d
 **Unit 2 - Deck 21: Functions**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d21-functions/u2-d21-functions.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u2-d21-functions/u2-d21-functions.html#1)
 :::
 
 ::: source
@@ -500,7 +500,7 @@ R4DS :: [Chp 19 - Functions](https://r4ds.had.co.nz/functions.html)
 **Unit 2 - Deck 22: Iteration**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d22-iteration/u2-d22-iteration.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u2-d22-iteration/u2-d22-iteration.html#1)
 :::
 
 ::: source

---FILE: 02-hello-world.qmd---
@@ -27,7 +27,7 @@ You can join the workspace and play around with the sample application exercises
 **Unit 1 - Deck 1: Welcome**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u1-d01-welcome/u1-d01-welcome.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u1-d01-welcome/u1-d01-welcome.html#1)
 :::
 
 ::: source
@@ -63,7 +63,7 @@ You can join the workspace and play around with the sample application exercises
 **Unit 1 - Deck 2: Meet the toolkit - Programming**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#1)
 :::
 
 ::: source
@@ -92,7 +92,7 @@ You can join the workspace and play around with the sample application exercises
 **Unit 1 - Deck 3: Meet the toolkit - Version control and collaboration**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html#1)
 :::
 
 ::: source

---FILE: 02-looking-further.qmd---
@@ -12,7 +12,7 @@ Note that the slides in this unit are a bit more sparse than the others, and muc
 **Unit 5 - Deck 1: Text analysis**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u5-d01-text-analysis/u5-d01-text-analysis.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u5-d01-text-analysis/u5-d01-text-analysis.html#1)
 :::
 
 ::: source
@@ -28,7 +28,7 @@ Note that the slides in this unit are a bit more sparse than the others, and muc
 **Unit 5 - Deck 2: Comparing texts**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u5-d02-comparing-texts/u5-d02-comparing-texts.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u5-d02-comparing-texts/u5-d02-comparing-texts.html#1)
 :::
 
 ::: source
@@ -44,7 +44,7 @@ Note that the slides in this unit are a bit more sparse than the others, and muc
 **Unit 5 - Deck 3: Interactive web apps**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u5-d03-interactive-web-app/u5-d03-interactive-web-app.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u5-d03-interactive-web-app/u5-d03-interactive-web-app.html#1)
 :::
 
 ::: source
@@ -60,7 +60,7 @@ Note that the slides in this unit are a bit more sparse than the others, and muc
 **Unit 5 - Deck 4: Machine learning**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u5-d04-machine-learning/u5-d04-machine-learning.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u5-d04-machine-learning/u5-d04-machine-learning.html#1)
 :::
 
 ::: source
@@ -76,23 +76,23 @@ Note that the slides in this unit are a bit more sparse than the others, and muc
 **Unit 5 - Deck 5: Interactive data visualisation**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u5-d05-shiny-1/u5-d05-shiny-1.pdf)
+[Slides](https://datasciencebox.org/course-materials/_slides/u5-d05-shiny-1/u5-d05-shiny-1.pdf)
 :::
 :::
 
 ::: slide-deck
 **Unit 5 - Deck 6: Interactive data visualisation and reporting**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u5-d05-shiny-2/u5-d05-shiny-2.pdf)
+[Slides](https://datasciencebox.org/course-materials/_slides/u5-d05-shiny-2/u5-d05-shiny-2.pdf)
 :::
 :::
 
 ::: slide-deck
 **Unit 5 - Deck 7: Bayesian inference**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#1)
 :::
 
 ::: source

---FILE: 02-making-rigorous-conclusions.qmd---
@@ -19,7 +19,7 @@ You can join the workspace and play around with the sample application exercises
 **Unit 4 - Deck 1: The language of models**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d01-language-of-models/u4-d01-language-of-models.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u4-d01-language-of-models/u4-d01-language-of-models.html#1)
 :::
 
 ::: source
@@ -35,7 +35,7 @@ You can join the workspace and play around with the sample application exercises
 **Unit 4 - Deck 2: Fitting and interpreting models**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#1)
 :::
 
 ::: source
@@ -55,7 +55,7 @@ IMS :: [Chp 7 - Linear regression with a single predictor](https://openintro-ims
 **Unit 4 - Deck 3: Modelling nonlinear relationships**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#1)
 :::
 
 ::: source
@@ -71,7 +71,7 @@ IMS :: [Chp 7 - Linear regression with a single predictor](https://openintro-ims
 **Unit 4 - Deck 4: Models with multiple predictors**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html#1)
 :::
 
 ::: source
@@ -91,7 +91,7 @@ IMS :: [Chp 8 - Linear regression with multiple predictors](https://openintro-im
 **Unit 4 - Deck 5: More models with multiple predictors**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#1)
 :::
 
 ::: source
@@ -109,7 +109,7 @@ IMS :: [Chp 8 - Linear regression with multiple predictors](https://openintro-im
 **Unit 4 - Deck 6: Logistic regression**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#1)
 :::
 
 ::: source
@@ -129,7 +129,7 @@ IMS :: [Chp 9 - Logistic regression](https://openintro-ims.netlify.app/model-log
 **Unit 4 - Deck 7: Prediction and overfitting**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#1)
 :::
 
 ::: source
@@ -149,7 +149,7 @@ tidymodels :: [Build a model](https://www.tidymodels.org/start/models/)
 **Unit 4 - Deck 8: Feature engineering**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#1)
 :::
 
 ::: source
@@ -171,7 +171,7 @@ tidymodels :: [Preprocess your data with recipes](https://www.tidymodels.org/sta
 **Unit 4 - Deck 9: Cross validation**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d09-cross-validation/u4-d09-cross-validation.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u4-d09-cross-validation/u4-d09-cross-validation.html#1)
 :::
 
 ::: source
@@ -217,7 +217,7 @@ tidymodels :: [Evaluate your model with resampling](https://www.tidymodels.org/s
 **Unit 4 - Deck 10: Quantifying uncertainty**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#1)
 :::
 
 ::: source
@@ -233,7 +233,7 @@ tidymodels :: [Evaluate your model with resampling](https://www.tidymodels.org/s
 **Unit 4 - Deck 11: Bootstrapping**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d11-bootstrap/u4-d11-bootstrap.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u4-d11-bootstrap/u4-d11-bootstrap.html#1)
 :::
 
 ::: source
@@ -253,7 +253,7 @@ IMS :: [Chp 12 - Confidence intervals with bootstrapping](https://openintro-ims.
 **Unit 4 - Deck 12: Hypothesis testing**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#1)
 :::
 
 ::: source
@@ -269,7 +269,7 @@ IMS :: [Chp 12 - Confidence intervals with bootstrapping](https://openintro-ims.
 **Unit 4 - Deck 13: Inference overview**
 
 ::: slides
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d13-inference-overview/u4-d13-inference-overview.html#1)
+[Slides](https://datasciencebox.org/course-materials/_slides/u4-d13-inference-overview/u4-d13-inference-overview.html#1)
 :::
 
 ::: source",False,True,Rendering / Conversion,3
tidyverse,datascience-box,a53863d1f17858f763134c1e544d2ebf44310854,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2022-06-17T01:52:06Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2022-06-17T01:52:06Z,Fix indentation,.github/workflows/build-page.yaml,False,False,False,False,4,2,6,"---FILE: .github/workflows/build-page.yaml---
@@ -1,10 +1,12 @@
 on:
   push:
     branches: main
+    paths-ignore: 
+      - '_course-materials/**'
   pull_request:
     branches: main
-  paths-ignore: 
-    - '_course-materials/**'  
+    paths-ignore: 
+      - '_course-materials/**'
   # to be able to trigger a manual build
   workflow_dispatch:
   schedule:",False,False,Data / Input Handling,3
tidyverse,datascience-box,f796a52642652461f8679700a3ad2ee2bd56b27a,Mine Cetinkaya-Rundel,cetinkaya.mine@gmail.com,2022-06-17T01:45:48Z,GitHub,noreply@github.com,2022-06-17T01:45:48Z,"Convert bookdown to Quarto webpage (#136)

* Visual editor

* YAML style chunk options

* Convert to Quarto

* Don't need this

* For quarto

* Fix page titles, explicitly load knitr

* Using quarto instead

* Not used

* Don't need

* Convert to qmd

* Not used

* Change build type

* Move

* Add twitter card

* Load fontawesome with a kit instead

* Organize all style things in one folder

* Fix paths

* Rename course materials folder

* Update R and pkgs

* Make Quarto action

* omit R things...

* Fix up action",.Rbuildignore;.github/workflows/build-book.yaml;.github/workflows/build-page.yaml;.gitignore;.renvignore;01-community.qmd;01-design-principles.qmd;01-overview.qmd;01-tech-stack.qmd;01-topics.qmd;02-ethics.qmd;02-exams.qmd;02-exploring-data.qmd;02-hello-world.qmd;02-interactive-tutorials.qmd;02-looking-further.qmd;02-making-rigorous-conclusions.qmd;02-project.qmd;03-access-r.qmd;03-alternative-setups.qmd;03-discussion.qmd;03-sharing.qmd;03-version-control.qmd;04-pedagogy.qmd;04-schedule.qmd;_bookdown.yml;_common.R;_course-materials/application-exercises/README.md;_course-materials/application-exercises/ae-01a-un-votes/unvotes.Rmd;_course-materials/application-exercises/ae-01b-covid/covid.Rmd;_course-materials/application-exercises/ae-01b-covid/covid_files/figure-gfm/list-countries-1.png;_course-materials/application-exercises/ae-01b-covid/covid_files/figure-gfm/visualise-1.png;_course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.Rmd;_course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel_files/figure-gfm/unnamed-chunk-6-1.png;_course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel_files/figure-gfm/unnamed-chunk-8-1.png;_course-materials/application-exercises/ae-03-starwars-dataviz/starwars.Rmd;_course-materials/application-exercises/ae-03-starwars-dataviz/starwars_files/figure-gfm/scatterplot-1.png;_course-materials/application-exercises/ae-03-starwars-dataviz/starwars_files/figure-gfm/scatterplot-labels-1.png;_course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.Rmd;_course-materials/application-exercises/ae-05-hotels-datatypes/hotels-forcats.Rmd;_course-materials/application-exercises/ae-05-hotels-datatypes/hotels-forcats_files/figure-gfm/plot-1.png;_course-materials/application-exercises/ae-05-hotels-datatypes/type-coercion.Rmd;_course-materials/application-exercises/ae-06-nobels-sales-dataimport/data-raw/nobel.csv;_course-materials/application-exercises/ae-06-nobels-sales-dataimport/data-raw/sales.xlsx;_course-materials/application-exercises/ae-06-nobels-sales-dataimport/images/sales-1.png;_course-materials/application-exercises/ae-06-nobels-sales-dataimport/images/sales-2.png;_course-materials/application-exercises/ae-06-nobels-sales-dataimport/nobels-csv.Rmd;_course-materials/application-exercises/ae-06-nobels-sales-dataimport/sales-excel.Rmd;_course-materials/application-exercises/ae-07-brexit-story-dataviz/brexit.Rmd;_course-materials/application-exercises/ae-07-brexit-story-dataviz/brexit_files/figure-gfm/unnamed-chunk-2-1.png;_course-materials/application-exercises/ae-07-brexit-story-dataviz/brexit_files/figure-gfm/unnamed-chunk-3-1.png;_course-materials/application-exercises/ae-07-brexit-story-dataviz/data/brexit.csv;_course-materials/application-exercises/ae-08-imdb-webscraping/01-imdb-250movies.R;_course-materials/application-exercises/ae-08-imdb-webscraping/02-imdb-tvshows.R;_course-materials/application-exercises/ae-08-imdb-webscraping/03-imdb-250movies-complete.R;_course-materials/application-exercises/ae-08-imdb-webscraping/04-imdb-tvshows-complete.R;_course-materials/application-exercises/ae-09-feat-eng-cv/theoffice-solution.Rmd;_course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.Rmd;_course-materials/exams/exam-01/README.md;_course-materials/exams/exam-01/exam-01.Rmd;_course-materials/exams/exam-01/exam-01.html;_course-materials/exams/exam-01/exam-01.md;_course-materials/exams/exam-01/img/plot-to-recreate.png;_course-materials/exams/exam-02/README.md;_course-materials/exams/exam-02/exam-02.Rmd;_course-materials/exams/exam-02/exam-02.html;_course-materials/exams/exam-02/exam-02.md;_course-materials/hw-instructions/hw-01/hw-01-pet-names.Rmd;_course-materials/hw-instructions/hw-01/hw-01-pet-names.html;_course-materials/hw-instructions/hw-01/img/clone-repo-link.png;_course-materials/hw-instructions/hw-01/img/course-workspace.png;_course-materials/hw-instructions/hw-01/img/jovana-askrabic-XYIQXLH_v0o-unsplash.jpg;_course-materials/hw-instructions/hw-01/img/load-packages-chunk.png;_course-materials/hw-instructions/hw-01/img/new-project-from-git.png;_course-materials/hw-instructions/hw-01/img/ready-to-push.png;_course-materials/hw-instructions/hw-01/img/rstudio-anatomy.png;_course-materials/hw-instructions/hw-01/img/rstudio-cloud-space.png;_course-materials/hw-instructions/hw-01/img/update-author-name-commit.png;_course-materials/hw-instructions/hw-01/img/view-data.png;_course-materials/hw-instructions/hw-01/img/yaml-raw-to-rendered.png;_course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.Rmd;_course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html;_course-materials/hw-instructions/hw-02/img/madeleine-kohler-90Qn643Pq9c-unsplash.jpg;_course-materials/hw-instructions/hw-03/hw-03-accidents.Rmd;_course-materials/hw-instructions/hw-03/hw-03-accidents.html;_course-materials/hw-instructions/hw-03/img/accident.jpg;_course-materials/hw-instructions/hw-04/hw-04-college-majors.Rmd;_course-materials/hw-instructions/hw-04/hw-04-college-majors.html;_course-materials/hw-instructions/hw-04/img/graduate.jpg;_course-materials/hw-instructions/hw-05/hw-05-legos.Rmd;_course-materials/hw-instructions/hw-05/hw-05-legos.html;_course-materials/hw-instructions/hw-05/img/daniel-cheung-ZqqlOZyGG7g-unsplash.jpg;_course-materials/hw-instructions/hw-06/data/pac-all.csv;_course-materials/hw-instructions/hw-06/hw-06-money-in-politics.Rmd;_course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html;_course-materials/hw-instructions/hw-06/img/functionalize.png;_course-materials/hw-instructions/hw-06/img/opensecrets.png;_course-materials/hw-instructions/hw-06/img/pac_2020.png;_course-materials/hw-instructions/hw-06/img/sharon-mccutcheon-rItGZ4vquWk-unsplash.jpg;_course-materials/hw-instructions/hw-06/scripts/scrape-pac.R;_course-materials/hw-instructions/hw-07/data/bikeshare-day.csv;_course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.Rmd;_course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html;_course-materials/hw-instructions/hw-07/img/viktor-kern-UdGEXZtlx-E-unsplash.jpg;_course-materials/hw-instructions/hw-08/hw-08-exploring-gss.Rmd;_course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html;_course-materials/hw-instructions/hw-08/img/mauro-mora-31-pOduwZGE-unsplash.jpg;_course-materials/hw-instructions/hw-09/hw-09-modeling-gss.Rmd;_course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html;_course-materials/hw-instructions/hw-09/img/mauro-mora-31-pOduwZGE-unsplash.jpg;_course-materials/hw-instructions/hw-10/hw-10-wrap-up.Rmd;_course-materials/hw-instructions/hw-10/hw-10-wrap-up.html;_course-materials/hw-instructions/hw-10/img/kari-shea-VfWkdMue5Jc-unsplash.jpg;_course-materials/hw-instructions/hw.css;_course-materials/lab-instructions/README.md;_course-materials/lab-instructions/lab-01/img/clone-repo-link.png;_course-materials/lab-instructions/lab-01/img/fig-resize-global.png;_course-materials/lab-instructions/lab-01/img/fig-resize-local.png;_course-materials/lab-instructions/lab-01/img/github-auth-1.png;_course-materials/lab-instructions/lab-01/img/github-auth-2.png;_course-materials/lab-instructions/lab-01/img/github-auth-3.png;_course-materials/lab-instructions/lab-01/img/github-auth-4.png;_course-materials/lab-instructions/lab-01/img/github-auth-5.png;_course-materials/lab-instructions/lab-01/img/github-auth-6.png;_course-materials/lab-instructions/lab-01/img/new-project-from-gh.png;_course-materials/lab-instructions/lab-01/img/paste-gh-repo-url.png;_course-materials/lab-instructions/lab-01/img/theme-highlight.png;_course-materials/lab-instructions/lab-01/img/update-author-name-commit.png;_course-materials/lab-instructions/lab-01/img/yaml-raw-to-rendered.png;_course-materials/lab-instructions/lab-01/lab-01-hello-r.Rmd;_course-materials/lab-instructions/lab-01/lab-01-hello-r.html;_course-materials/lab-instructions/lab-02/data/plastic-waste.csv;_course-materials/lab-instructions/lab-02/data/raw-data/coast_vs_waste.csv;_course-materials/lab-instructions/lab-02/data/raw-data/country-and-continent-codes-list-csv_csv.csv;_course-materials/lab-instructions/lab-02/data/raw-data/data-cleanup.R;_course-materials/lab-instructions/lab-02/data/raw-data/mismanaged_vs_gdp.csv;_course-materials/lab-instructions/lab-02/data/raw-data/waste-vs-gdp.csv;_course-materials/lab-instructions/lab-02/img/repo-begin.png;_course-materials/lab-instructions/lab-02/img/repo-end.png;_course-materials/lab-instructions/lab-02/lab-02-plastic-waste.Rmd;_course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html;_course-materials/lab-instructions/lab-03/data/nobel.csv;_course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.Rmd;_course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html;_course-materials/lab-instructions/lab-04/data/states.csv;_course-materials/lab-instructions/lab-04/img/mitch-hedgeberg-lqd.jpg;_course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.Rmd;_course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html;_course-materials/lab-instructions/lab-05/img/dennys-laquinta-sketches/dennys-laquinta-sketches.001.png;_course-materials/lab-instructions/lab-05/img/dennys-laquinta-sketches/dennys-laquinta-sketches.002.png;_course-materials/lab-instructions/lab-05/img/dennys-laquinta-sketches/dennys-laquinta-sketches.003.png;_course-materials/lab-instructions/lab-05/img/dennys-laquinta-sketches/dennys-laquinta-sketches.004.png;_course-materials/lab-instructions/lab-05/img/mitch-hedgeberg-lqd.jpg;_course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.Rmd;_course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html;_course-materials/lab-instructions/lab-06/data/fisheries.csv;_course-materials/lab-instructions/lab-06/data/instructional-staff.csv;_course-materials/lab-instructions/lab-06/img/fisheries.png;_course-materials/lab-instructions/lab-06/img/staff-employment.png;_course-materials/lab-instructions/lab-06/img/tidyr-longer-wider.gif;_course-materials/lab-instructions/lab-06/lab-06-sad-plots.Rmd;_course-materials/lab-instructions/lab-06/lab-06-sad-plots.html;_course-materials/lab-instructions/lab-07/img/whickham.png;_course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.Rmd;_course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.html;_course-materials/lab-instructions/lab-08/img/h3a.png;_course-materials/lab-instructions/lab-08/img/iteminfo-h3a.gif;_course-materials/lab-instructions/lab-08/img/iteminfo.png;_course-materials/lab-instructions/lab-08/img/selectorgadget.png;_course-materials/lab-instructions/lab-08/lab-08-uoe-art.Rmd;_course-materials/lab-instructions/lab-08/lab-08-uoe-art.html;_course-materials/lab-instructions/lab-09/img/masks-v-nomasks.png;_course-materials/lab-instructions/lab-09/lab-09-better-viz.Rmd;_course-materials/lab-instructions/lab-09/lab-09-better-viz.html;_course-materials/lab-instructions/lab-10/img/data-upload.png;_course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.Rmd;_course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html;_course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.Rmd;_course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html;_course-materials/lab-instructions/lab-12/lab-12-inference-smoking.Rmd;_course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html;_course-materials/lab-instructions/lab-13/lab-13-work-on-projects.Rmd;_course-materials/lab-instructions/lab-13/lab-13-work-on-projects.html;_course-materials/lab-instructions/lab-14/img/practice-issue-assign.png;_course-materials/lab-instructions/lab-14/img/practice-issue-check.png;_course-materials/lab-instructions/lab-14/img/practice-issue-close.png;_course-materials/lab-instructions/lab-14/img/practice-issue-commit.png;_course-materials/lab-instructions/lab-14/img/practice-issue-create.png;_course-materials/lab-instructions/lab-14/img/practice-issue-number.png;_course-materials/lab-instructions/lab-14/img/practice-issue-progress.png;_course-materials/lab-instructions/lab-14/img/project-description.png;_course-materials/lab-instructions/lab-14/img/styler-1.png;_course-materials/lab-instructions/lab-14/img/styler-2.png;_course-materials/lab-instructions/lab-14/img/theme-diff.png;_course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.Rmd;_course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html;_course-materials/lab-instructions/lab.css;_course-materials/project-instructions/evaluation-forms/instructor-eval.pdf;_course-materials/project-instructions/evaluation-forms/peer-eval.pdf;_course-materials/project-instructions/img/laptop-3190194_1920.jpg;_course-materials/project-instructions/project.Rmd;_course-materials/project-instructions/project.css;_course-materials/project-instructions/project.html;_course-materials/project-instructions/repo-structure/README.Rmd;_course-materials/project-instructions/repo-structure/README.html;_course-materials/project-instructions/repo-structure/README.md;_course-materials/project-instructions/repo-structure/_config.yml;_course-materials/project-instructions/repo-structure/data/README.md;_course-materials/project-instructions/repo-structure/extra/README.md;_course-materials/project-instructions/repo-structure/presentation/img/confetti.jpg;_course-materials/project-instructions/repo-structure/presentation/libs/header-attrs-2.4.4/header-attrs.js;_course-materials/project-instructions/repo-structure/presentation/libs/header-attrs-2.5.3/header-attrs.js;_course-materials/project-instructions/repo-structure/presentation/libs/remark-css-0.0.1/default-fonts.css;_course-materials/project-instructions/repo-structure/presentation/libs/remark-css-0.0.1/default.css;_course-materials/project-instructions/repo-structure/presentation/presentation.Rmd;_course-materials/project-instructions/repo-structure/presentation/presentation.html;_course-materials/project-instructions/repo-structure/presentation/presentation_files/figure-html/cars-1.png;_course-materials/project-instructions/repo-structure/presentation/presentation_files/figure-html/plot-iris-1.png;_course-materials/project-instructions/repo-structure/presentation/presentation_files/figure-html/unnamed-chunk-1-1.png;_course-materials/project-instructions/repo-structure/presentation/presentation_files/figure-html/unnamed-chunk-2-1.png;_course-materials/project-instructions/repo-structure/presentation/xaringan-themer.css;_course-materials/project-instructions/repo-structure/proposal/proposal.Rmd;_course-materials/project-instructions/repo-structure/proposal/proposal.md;_course-materials/render-materials.R;_course-materials/slides/README.md;_course-materials/slides/dsbox-hex.png;_course-materials/slides/setup.Rmd;_course-materials/slides/slides.css;_course-materials/slides/u1-d01-welcome/img/code-examples.jpeg;_course-materials/slides/u1-d01-welcome/img/covid.jpeg;_course-materials/slides/u1-d01-welcome/img/data-science-cycle/data-science-cycle.001.png;_course-materials/slides/u1-d01-welcome/img/data-science-cycle/data-science-cycle.002.png;_course-materials/slides/u1-d01-welcome/img/data-science-cycle/data-science-cycle.003.png;_course-materials/slides/u1-d01-welcome/img/data-science-cycle/data-science-cycle.004.png;_course-materials/slides/u1-d01-welcome/img/data-science-cycle/data-science-cycle.005.png;_course-materials/slides/u1-d01-welcome/img/data-science-cycle/data-science-cycle.006.png;_course-materials/slides/u1-d01-welcome/img/data-science-cycle/data-science-cycle.007.png;_course-materials/slides/u1-d01-welcome/img/data-science-cycle/data-science-cycle.008.png;_course-materials/slides/u1-d01-welcome/img/data-science-cycle/data-science-cycle.009.png;_course-materials/slides/u1-d01-welcome/img/excel.png;_course-materials/slides/u1-d01-welcome/img/gender-pronouns.jpeg;_course-materials/slides/u1-d01-welcome/img/google-trend-index.png;_course-materials/slides/u1-d01-welcome/img/r.png;_course-materials/slides/u1-d01-welcome/img/rstudio.png;_course-materials/slides/u1-d01-welcome/img/trump-tweets.jpeg;_course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-01.jpeg;_course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-02.jpeg;_course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-03.jpeg;_course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-04.jpeg;_course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-05.jpeg;_course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-06.jpeg;_course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-07.jpeg;_course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-08.jpeg;_course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-09.jpeg;_course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-10.jpeg;_course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-11.jpeg;_course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-12.jpeg;_course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-13.jpeg;_course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-14.jpeg;_course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-15.png;_course-materials/slides/u1-d01-welcome/img/unvotes/unvotes.gif;_course-materials/slides/u1-d01-welcome/libs/font-awesome/css/all.css;_course-materials/slides/u1-d01-welcome/libs/font-awesome/css/v4-shims.css;_course-materials/slides/u1-d01-welcome/libs/font-awesome/webfonts/fa-brands-400.eot;_course-materials/slides/u1-d01-welcome/libs/font-awesome/webfonts/fa-brands-400.svg;_course-materials/slides/u1-d01-welcome/libs/font-awesome/webfonts/fa-brands-400.ttf;_course-materials/slides/u1-d01-welcome/libs/font-awesome/webfonts/fa-brands-400.woff;_course-materials/slides/u1-d01-welcome/libs/font-awesome/webfonts/fa-brands-400.woff2;_course-materials/slides/u1-d01-welcome/libs/font-awesome/webfonts/fa-regular-400.eot;_course-materials/slides/u1-d01-welcome/libs/font-awesome/webfonts/fa-regular-400.svg;_course-materials/slides/u1-d01-welcome/libs/font-awesome/webfonts/fa-regular-400.ttf;_course-materials/slides/u1-d01-welcome/libs/font-awesome/webfonts/fa-regular-400.woff;_course-materials/slides/u1-d01-welcome/libs/font-awesome/webfonts/fa-regular-400.woff2;_course-materials/slides/u1-d01-welcome/libs/font-awesome/webfonts/fa-solid-900.eot;_course-materials/slides/u1-d01-welcome/libs/font-awesome/webfonts/fa-solid-900.svg;_course-materials/slides/u1-d01-welcome/libs/font-awesome/webfonts/fa-solid-900.ttf;_course-materials/slides/u1-d01-welcome/libs/font-awesome/webfonts/fa-solid-900.woff;_course-materials/slides/u1-d01-welcome/libs/font-awesome/webfonts/fa-solid-900.woff2;_course-materials/slides/u1-d01-welcome/libs/header-attrs/header-attrs.js;_course-materials/slides/u1-d01-welcome/libs/panelset/panelset.css;_course-materials/slides/u1-d01-welcome/libs/panelset/panelset.js;_course-materials/slides/u1-d01-welcome/u1-d01-welcome.Rmd;_course-materials/slides/u1-d01-welcome/u1-d01-welcome.html;_course-materials/slides/u1-d02-toolkit-r/img/hex-australia.png;_course-materials/slides/u1-d02-toolkit-r/img/md-cheatsheet.png;_course-materials/slides/u1-d02-toolkit-r/img/r-logo.png;_course-materials/slides/u1-d02-toolkit-r/img/rmarkdown.png;_course-materials/slides/u1-d02-toolkit-r/img/rmd-cheatsheet.png;_course-materials/slides/u1-d02-toolkit-r/img/rstudio-logo.png;_course-materials/slides/u1-d02-toolkit-r/img/tidyverse.png;_course-materials/slides/u1-d02-toolkit-r/img/tour-r-rstudio.png;_course-materials/slides/u1-d02-toolkit-r/img/tour-rmarkdown.png;_course-materials/slides/u1-d02-toolkit-r/libs/font-awesome/css/all.css;_course-materials/slides/u1-d02-toolkit-r/libs/font-awesome/css/v4-shims.css;_course-materials/slides/u1-d02-toolkit-r/libs/font-awesome/webfonts/fa-brands-400.eot;_course-materials/slides/u1-d02-toolkit-r/libs/font-awesome/webfonts/fa-brands-400.svg;_course-materials/slides/u1-d02-toolkit-r/libs/font-awesome/webfonts/fa-brands-400.ttf;_course-materials/slides/u1-d02-toolkit-r/libs/font-awesome/webfonts/fa-brands-400.woff;_course-materials/slides/u1-d02-toolkit-r/libs/font-awesome/webfonts/fa-brands-400.woff2;_course-materials/slides/u1-d02-toolkit-r/libs/font-awesome/webfonts/fa-regular-400.eot,True,False,True,False,696,773,1469,"---FILE: .Rbuildignore---
@@ -1,3 +0,0 @@
-^renv$
-^renv\.lock$
-^\.github$

---FILE: .github/workflows/build-book.yaml---
@@ -1,67 +0,0 @@
-on:
-  push:
-    branches:
-      - main
-    paths-ignore: 
-    - 'course-materials/**'  
-
-
-name: Build book
-
-jobs:
-  build:
-    runs-on: macOS-latest
-    env:
-      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}
-    steps:
-      - name: Checkout repo
-        uses: actions/checkout@v2
-
-      - name: Setup pandoc
-        uses: r-lib/actions/setup-pandoc@v2
-
-      - name: Setup R
-        uses: r-lib/actions/setup-r@v2
-        with:
-          use-public-rspm: true
-
-      - name: Cache Renv packages
-        uses: actions/cache@v1
-        with:
-          path: $HOME/.local/share/renv
-          key: r-${{ hashFiles('renv.lock') }}
-          restore-keys: r-
-
-      - name: Cache bookdown results
-        uses: actions/cache@v2
-        with:
-          path: _bookdown_files
-          key: bookdown-${{ hashFiles('**/*Rmd') }}
-          restore-keys: bookdown-
-
-      - name: Install packages
-        run: |
-          R -e 'install.packages(""renv"")'
-          R -e 'renv::restore()'
-
-      - name: Build site
-        run: |
-         install.packages(""bslib"")
-         install.packages(""xml2"")
-         install.packages(""downlit"")
-         bookdown::render_book(""index.Rmd"", quiet = TRUE)
-        shell: Rscript {0}
-        
-      - name: Install npm
-        uses: actions/setup-node@v3
-        with:
-          node-version: 14
-    
-      - name: Deploy to Netlify
-        # NETLIFY_AUTH_TOKEN and NETLIFY_SITE_ID added in the repo's secrets
-        env:
-          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}
-          NETLIFY_SITE_ID: ${{ secrets.NETLIFY_SITE_ID }}
-        run: |
-          npm install netlify-cli -g
-          netlify deploy --prod --dir _book

---FILE: .github/workflows/build-page.yaml---
@@ -0,0 +1,62 @@
+on:
+  push:
+    branches: main
+  pull_request:
+    branches: main
+  paths-ignore: 
+    - '_course-materials/**'  
+  # to be able to trigger a manual build
+  workflow_dispatch:
+  schedule:
+    # run every day at 11 PM
+    - cron: '0 23 * * *'
+
+name: Render and deploy webpage to Netlify
+
+env:
+  isExtPR: ${{ github.event.pull_request.head.repo.fork == true }}
+  RUST_BACKTRACE: 1
+
+jobs:
+  build-deploy:
+    runs-on: ubuntu-latest
+    env:
+      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}
+    steps:
+      - uses: actions/checkout@v2
+
+      - name: Install Quarto
+        uses: quarto-dev/quarto-actions/install-quarto@v1
+
+      - name: Setup R
+        uses: r-lib/actions/setup-r@v2
+        with:
+          use-public-rspm: true
+
+      - name: Set up renv
+        uses: r-lib/actions/setup-renv@v2
+        with:
+          cache-version: 2
+
+      - name: Render book to all format
+        # Add any command line argument needed
+        run: |
+          quarto render
+
+      - name: Deploy to Netlify
+        if: contains(env.isExtPR, 'false')
+        id: netlify-deploy
+        uses: nwtgck/actions-netlify@v1
+        with:
+          # The folder the action should deploy. Adapt if you changed in Quarto config
+          publish-dir: './_site'
+          production-branch: main
+          github-token: ${{ secrets.GITHUB_TOKEN }}
+          deploy-message:
+            'Deploy from GHA: ${{ github.event.pull_request.title || github.event.head_commit.message }} (${{ github.sha }})'
+          enable-pull-request-comment: false #  Comment on pull request
+          enable-commit-comment: false # Comment on GitHub commit
+        env:
+          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}
+          NETLIFY_SITE_ID: ${{ secrets.NETLIFY_SITE_ID }}
+        timeout-minutes: 1
\ No newline at end of file

---FILE: .gitignore---
@@ -8,3 +8,8 @@ render*.rds
 *.key
 *.docx
 .Rapp.history
+
+/.quarto/
+.Rdata
+.httr-oauth
+.DS_Store

---FILE: .renvignore---
@@ -1,7 +1,7 @@
-course-materials/**.R
-course-materials/**.Rmd
-course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.Rmd
-course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.Rmd
+_course-materials/**.R
+_course-materials/**.Rmd
+_course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.Rmd
+_course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.Rmd
 course-materials/slides/u2-d12-data-import/u2-d12-data-import.Rmd
-course-materials/starters/lab/lab-08-uoe-art/lab-08.Rmd
-course-materials/hw-instructions/hw-06/scripts/scrape-pac.R
+_course-materials/starters/lab/lab-08-uoe-art/lab-08.Rmd
+_course-materials/hw-instructions/hw-06/scripts/scrape-pac.R

---FILE: 01-community.qmd---
@@ -5,7 +5,7 @@ Do you have questions?
 Is something you need missing?
 Want to exchange ideas with others teaching similar courses?
 
-We now have a `dsbox` Slack channel, you can join [here](https://join.slack.com/t/dsboxworkspace/shared_invite/zt-vvjh8ovb-dCy31PATijOrdaz9oVGvVQ).[^community-1]
+We now have a `dsbox` Slack channel, you can join [here](https://join.slack.com/t/dsboxworkspace/shared_invite/zt-vvjh8ovb-dCy31PATijOrdaz9oVGvVQ).[^01-community-1]
 The Slack channel is a place for discussion on using these or similar materials in data science courses.
 Please make sure to review the [Code of Conduct](https://contributor-covenant.org/version/2/0/CODE_OF_CONDUCT.html) before joining.
 
@@ -15,4 +15,4 @@ Additionally, we would love to hear from you if you are using these resources.
 Please take just a few minutes to fill out [this Google form](https://forms.gle/AjqXStdFq42TTV9LA).
 All fields are optional, but the more information you provide, the more data we will have to assess the reach and impact of this project.
 
-[^community-1]: If the link has expired, please email me at [cetinkaya.mine\@gmail.com](mailto:cetinkaya.mine@gmail.com){.email} to request a new one.
+[^01-community-1]: If the link has expired, please email me at [cetinkaya.mine\@gmail.com](mailto:cetinkaya.mine@gmail.com){.email} to request a new one.

---FILE: 01-design-principles.qmd---
@@ -1,4 +1,6 @@
-# Design principles {#design-principles}
+---
+title: ""Design principles""
+---
 
 This course is designed with five principles in mind:
 
@@ -13,8 +15,15 @@ This course is designed with five principles in mind:
 Assuming you like chocolate and strawberries, which of the following images is more likely to make you want to learn to bake a cake?
 I'm guessing the answer is the image on the left: the cake.
 
-```{r cake-ingredients, fig.align=""center"", echo=FALSE}
-include_graphics(path = ""images/design-cake-ingredients.png"")
+```{r}
+#| labe: cake-ingredients
+#| fig-align: center
+#| echo: false
+#| fig-alt: |
+#|   Two pictures side-by-side. The first shows ingredients. The second shows 
+#|   a baked cake.
+
+knitr::include_graphics(path = ""images/design-cake-ingredients.png"")
 ```
 
 The teaching philosophy of this course builds on this same idea.
@@ -23,8 +32,15 @@ Specifically, instead of starting with data structures and functions, we start d
 And not just a toy example, but a complex, multivariate data visualization.
 Of course, we don't want students feeling like...
 
-```{r owl, fig.align=""center"", echo=FALSE}
-include_graphics(path = ""images/design-owl.jpg"")
+```{r}
+#| label: owl
+#| fig-align: center
+#| echo: false
+#| fig-alt: |
+#|   Illustration titled ""How to draw an owl"". Step 1 is just two circles. 
+#|   Step 2 is a complete owl.
+
+knitr::include_graphics(path = ""images/design-owl.jpg"")
 ```
 
 The course starts out slow and emphasizes iteration.

---FILE: 01-overview.qmd---
@@ -1,6 +1,6 @@
-# (PART) Hello \#dsbox! {.unnumbered}
-
-# Overview {#overview}
+---
+title: ""Overview""
+---
 
 Hello!
 And welcome!

---FILE: 01-tech-stack.qmd---
@@ -1,4 +1,6 @@
-# Tech stack {#tech-stack}
+---
+title: ""Tech stack""
+---
 
 This course teaches computing and statistics to undergraduates with no background in either.
 Managing such a course with students from varied backgrounds doing non-trivial computational work is a big technical challenge.
@@ -7,12 +9,12 @@ This page briefly describes the toolkit choices, and the Infrastructure part pro
 While the recommended tech stack for the entirety of course development is tall, only a few of the technologies are student facing:
 
 -   RStudio Cloud: [RStudio Cloud](https://rstudio.cloud/) is a managed cloud instance of the RStudio IDE. We recommend having students access RStudio via RStudio Cloud as opposed to using a local installation.
-    See Section \@ref(access-r) for more on this.
+    See [Accessing R](03-access-r.html) for more on this.
 
 -   GitHub: The use of [GitHub](https://github.com/) also goes a long way to help students visualize and understand the git process which also aids in student buy-in.
     The web interface allows students to easily view diffs (file changes over time) in files they are collaborating on, keep track of commit histories, and search both the current state as well as the entire history of the code base.
     Within the classroom GitHub can be thought of as an advanced and flexible learning management system (compared to traditional tools like Blackboard or Sakai).
-    See Section \@ref(version-control) for more on this.
+    See [Version Control](03-version-control.html) for more on this.
 
 -   Piazza: [Piazza](http://piazza.com/) is an easy to use and free Q&A platform that your students might very well be already familiar with from other classes.
     It is also possible that it's already integrated into your learning management system if you're teaching in a university setting.

---FILE: 01-topics.qmd---
@@ -1,8 +1,18 @@
-# Topics {#topics}
+---
+title: ""Topics""
+---
 
 The course content is organized in three units:
 
-```{r topic-flow, fig.align=""center"", echo=FALSE, fig.asp=0.3, out.width=""100%""}
+```{r}
+#| label: topic-flow
+#| fig-align: center
+#| echo: false
+#| fig-asp: 0.3
+#| out-width: ""100%""
+#| fig-alt: |
+#|   Workflow diagram showing five course units described in the following text.
+
 library(DiagrammeR)
 
 hello_border <- ""#333333""

---FILE: 02-ethics.qmd---
@@ -1,122 +1,124 @@
-# Data science ethics {#ethics}
+---
+title: ""Data science ethics""
+---
 
 This unit touches on data science ethics, specifically on issues of misrepresentation of data and results, data privacy, and algorithmic bias.
 Course lectures are supplemented with ""guest lectures"" from domain experts.
 
 ## Slides, videos, and application exercises
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 3 - Deck 1: Misrepresentation**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u3-d01-misrepresentation/u3-d01-misrepresentation.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u3-d01-misrepresentation)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/C_-rTKfswUI)
 :::
 :::
 
-::: {.guest-lecture}
+::: guest-lecture
 **Alberto Cairo - How charts lie**
 
-::: {.video}
+::: video
 [Video](https://youtu.be/Low28hx4wyk)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 3 - Deck 2: Data privacy**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u3-d02-privacy/u3-d02-privacy.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u3-d02-privacy)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/c4fvdoNbcSw)
 :::
 :::
 
-::: {.guest-lecture}
+::: guest-lecture
 **The Guardian - Cambridge Analytica whistleblower**
 
-::: {.video}
+::: video
 [Video](https://youtu.be/FXdYSQ6nu-M)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 3 - Deck 3: Algorithmic bias**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u3-d03-algorithmic-bias)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/E2eD72pwtps)
 :::
 :::
 
-::: {.guest-lecture}
+::: guest-lecture
 **Joy Buolamwini - How I'm fighting bias in algorithms**
 
-::: {.video}
+::: video
 [Video](https://youtu.be/UG_X_7g63rY)
 :::
 :::
 
-::: {.guest-lecture}
+::: guest-lecture
 **Cathy O'Neil - Weapons of Math Destruction**
 
-::: {.video}
+::: video
 [Video](https://youtu.be/TQHs8SA1qpk)
 :::
 :::
 
-::: {.guest-lecture}
+::: guest-lecture
 **Safiya Umoja Noble - Imagining a Future Free from the Algorithms of Oppression**
 
-::: {.video}
+::: video
 [Video](https://youtu.be/tNi_U1Bb1S0)
 :::
 :::
 
-::: {.guest-lecture}
+::: guest-lecture
 **Kristian Lum - What's An Algorithm Got To Do With It**
 
-::: {.video}
+::: video
 [Video](https://youtu.be/5zxDwA99soA)
 :::
 :::
 
 ## Labs
 
-::: {.lab}
+::: lab
 **Lab 9: Conveying the right message through visualisation**
 
 Improving data visualisations to better convey the right message
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-09/lab-09-better-viz.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-09)
 :::
 
-::: {.starter}
+::: starter
 [Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-09-better-viz)
 :::
 :::

---FILE: 02-exams.qmd---
@@ -1,18 +1,20 @@
-# Exams {#exams}
+---
+title: ""Exams""
+---
 
 I don't think the best assessment method for this curriculum is an exam, but sometimes a take home exam can be an incredible motivator for students without stifling their creativity.
 I've provided two sample take home exams.
 You probably wouldn't want to use them verbatim as exams, since they're now publicly available.
 But they might give you some idea about how to structure take home exams, how to write directions to reduce issues around plagiarism while still encouraging students to search for resources, etc.
 
-::: {.exam}
+::: exam
 **Exam 1**
 
-[[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/exams/exam-01/) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/exams/exam-01)
+[\[Instructions\]](https://rstudio-education.github.io/datascience-box/course-materials/exams/exam-01/) [\[Source\]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/exams/exam-01)
 :::
 
-::: {.exam}
+::: exam
 **Exam 2**
 
-[[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/exams/exam-02/) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/exams/exam-02)
+[\[Instructions\]](https://rstudio-education.github.io/datascience-box/course-materials/exams/exam-02/) [\[Source\]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/exams/exam-02)
 :::

---FILE: 02-exploring-data.qmd---
@@ -1,11 +1,13 @@
-# Exploring data {#exploring-data}
+---
+title: ""Exploring data""
+---
 
 This unit focuses on data visualization and data wrangling.
 Specifically we cover fundamentals of data and data visualization, confounding variables, and Simpson's paradox as well as the concept of tidy data, data import, data cleaning, and data curation.
 We end the unit with web scraping and introduce the idea of iteration in preparation for the next unit.
 Also in this unit students are introduced to the toolkit: R, RStudio, R Markdown, Git, and GitHub.
 
-::: {.rstudio-cloud}
+::: rstudio-cloud
 The RStudio Cloud workspace for Data Science Course in a Box project is [here](https://rstudio.cloud/spaces/1655/join?access_code=5rdjusfIYF5iI0Gum2vNsBDLdtdnIEELBkf2EivK).
 You can join the workspace and play around with the application exercises.
 :::
@@ -14,758 +16,758 @@ You can join the workspace and play around with the application exercises.
 
 ### Visualising data
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 2 - Deck 1: Data and visualisation**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d01-data-viz/u2-d01-data-viz.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d01-data-viz)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/FddF4b_GuTI)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 2 - Deck 2: Visualising data with ggplot2**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d02-ggplot2/u2-d02-ggplot2.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d02-ggplot2)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/s2NF2J36ljE)
 :::
 
-::: {.reading}
+::: reading
 R4DS :: [Chp 3 - Data visualization](https://r4ds.had.co.nz/data-visualisation.html)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 2 - Deck 3: Visualising numerical data**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d03-viz-num/u2-d03-viz-num.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d03-viz-num)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/waBabVTI8ec)
 :::
 
-::: {.reading}
+::: reading
 IMS :: [Chp 4 - Exploring numerical data](https://openintro-ims.netlify.app/explore-numerical.html)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 2 - Deck 4: Visualising categorical data**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d04-viz-cat/u2-d04-viz-cat.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d04-viz-cat)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/21h3rEO8k2E)
 :::
 
-::: {.reading}
+::: reading
 IMS :: [Chp 5 - Exploring categorical data](https://openintro-ims.netlify.app/explore-categorical.html)
 :::
 :::
 
-::: {.application-exercise}
+::: application-exercise
 **StarWars + Dataviz**
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-03-starwars-dataviz/starwars.Rmd)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/3UaLPtCKkXQ)
 :::
 :::
 
 ### Wrangling and tidying data
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 2 - Deck 5: Tidy data**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d05-tidy-data/u2-d05-tidy-data.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d05-tidy-data)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/Ux85eR3h9hw)
 :::
 
-::: {.reading}
+::: reading
 JSS :: [Tidy data](https://www.jstatsoft.org/article/view/v059i10)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 2 - Deck 6: Grammar of data wrangling**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d06-grammar-wrangle)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/ZCaYBES_VEk)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 2 - Deck 7: Working with a single data frame**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d07-single-df/u2-d07-single-df.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d07-single-df)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/0229Uq2hkJo)
 :::
 
-::: {.reading}
+::: reading
 R4DS :: [Chp 5 - Data transformation](https://r4ds.had.co.nz/transform.html)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 2 - Deck 8: Working with multiple data frames**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d08-multi-df/u2-d08-multi-df.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d08-multi-df)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/VdV5ABsaf5Y)
 :::
 
-::: {.reading}
+::: reading
 R4DS :: [Chp 13 - Relational data](https://r4ds.had.co.nz/relational-data.html)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 2 - Deck 9: Tidying data**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d09-tidying/u2-d09-tidying.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d09-tidying)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/x3KM5uxaFdI)
 :::
 
-::: {.reading}
+::: reading
 R4DS :: [Chp 12 - Tidy data](https://r4ds.had.co.nz/tidy-data.html)
 :::
 :::
 
-::: {.application-exercise}
+::: application-exercise
 **Hotels + Data wrangling**
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.Rmd)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/BXlOd4EYQrI)
 :::
 :::
 
 ### Importing and recoding data
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 2 - Deck 10: Data types**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d10-data-types/u2-d10-data-types.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d10-data-types)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/WsxLbtWbEfc)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 2 - Deck 11: Data classes**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d11-data-classes/u2-d11-data-classes.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d11-data-classes)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/dozvSVQcqqg)
 :::
 
-::: {.reading}
+::: reading
 R4DS :: [Chp 15 - Factors](https://r4ds.had.co.nz/factors.html)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 2 - Deck 12: Importing data**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d12-data-import/u2-d12-data-import.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d12-data-import)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/tIMaRYiuEFA)
 :::
 
-::: {.reading}
+::: reading
 R4DS :: [Chp 11 - Data import](https://r4ds.had.co.nz/data-import.html)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 2 - Deck 13: Recoding data**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d13-data-recode/u2-d13-data-recode.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d13-data-recode)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/O8qxV3N4D5Q)
 :::
 
-::: {.reading}
+::: reading
 R4DS :: [Sec 16.1 - 16.3 - Dates and times](https://r4ds.had.co.nz/dates-and-times.html)
 :::
 :::
 
-::: {.application-exercise}
+::: application-exercise
 **Hotels + Data types**
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-05-hotels-datatypes/hotels-forcats.Rmd)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-05-hotels-datatypes/type-coercion.Rmd)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/sByadx_cgDc)
 :::
 :::
 
-::: {.application-exercise}
+::: application-exercise
 **Nobels + Sales + Data import**
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-06-nobels-sales-dataimport/nobels-csv.Rmd)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-06-nobels-sales-dataimport/sales-excel.Rmd)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/2vA6qizYnM8)
 :::
 :::
 
 ### Communicating data science results effectively
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 2 - Deck 14: Tips for effective data visualization**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d14-effective-dataviz)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/ZrifrBvFWgg)
 :::
 
-::: {.reading}
+::: reading
 IMS :: [Chp 6 - Applications: Explore](https://openintro-ims.netlify.app/explore-applications.html)
 :::
 :::
 
-::: {.application-exercise}
+::: application-exercise
 **Brexit + Telling stories with dataviz**
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-07-brexit-story-dataviz/brexit.Rmd)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/aPqnkcn13kQ)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 2 - Deck 15: Scientific studies and confounding**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d15-studies-confounding)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/WnMzTBrZDcc)
 :::
 
-::: {.reading}
+::: reading
 IMS :: [Chp 2 - Study design](https://openintro-ims.netlify.app/data-design.html)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 2 - Deck 16: Simpson's paradox**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d16-simpsons-paradox)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/sdas62v0iJU)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 2 - Deck 17: Doing data science**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d17-doing-data-science)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/b9lSW0kyqBg)
 :::
 
-::: {.reading}
+::: reading
 R4DS :: [Chp 7 - Exploratory data analysis](https://r4ds.had.co.nz/exploratory-data-analysis.html)
 :::
 :::
 
 ### Web scraping and programming
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 2 - Deck 18: Web scraping**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d18-web-scrape/u2-d18-web-scrape.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d18-web-scrape)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/99Hkmfb2i80)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 2 - Deck 19: Scraping top 250 movies on IMDB**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d19-top-250-imdb)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/YmKULNLsDsU)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 2 - Deck 20: Web scraping considerations**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d20-considerations/u2-d20-considerations.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d20-considerations)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/LONRJHMvSyU)
 :::
 :::
 
-::: {.application-exercise}
+::: application-exercise
 **IMDB + Web scraping**
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-08-imdb-webscraping)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/PetWV5g1Xsc)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 2 - Deck 21: Functions**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d21-functions/u2-d21-functions.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d21-functions)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/6KWlPhPMluE)
 :::
 
-::: {.reading}
+::: reading
 R4DS :: [Chp 19 - Functions](https://r4ds.had.co.nz/functions.html)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 2 - Deck 22: Iteration**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d22-iteration/u2-d22-iteration.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d22-iteration)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/x3UMny1fQhc)
 :::
 
-::: {.reading}
+::: reading
 R4DS :: [Chp 20 - Iteration](https://r4ds.had.co.nz/iteration.html)
 :::
 :::
 
 ## Labs
 
-::: {.lab}
+::: lab
 **Lab 1: Hello R**
 
 Introduction to R, R Markdown, Git, and GitHub
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-01/lab-01-hello-r.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-01)
 :::
 
-::: {.starter}
+::: starter
 [Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-01-hello-r)
 :::
 :::
 
-::: {.lab}
+::: lab
 **Lab 2: Plastic waste**
 
 Introduction to working with data in R with the tidyverse
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-02)
 :::
 
-::: {.starter}
+::: starter
 [Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-02-plastic-waste)
 :::
 :::
 
-::: {.lab}
+::: lab
 **Lab 3: Nobel laureates**
 
 Data wrangling and tidying
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-03)
 :::
 
-::: {.starter}
+::: starter
 [Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-03-nobel-laureates)
 :::
 :::
 
-::: {.lab}
+::: lab
 **Lab 4: La Quinta is Spanish for 'next to Denny's', Pt. 1**
 
 Visualizing spatial data
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-04)
 :::
 
-::: {.starter}
+::: starter
 [Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-04-viz-sp-data)
 :::
 :::
 
-::: {.lab}
+::: lab
 **Lab 5: La Quinta is Spanish for 'next to Denny's', Pt. 2**
 
 Wrangling spatial data
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-05)
 :::
 
-::: {.starter}
+::: starter
 [Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-05-wrangle-sp-data)
 :::
 :::
 
-::: {.lab}
+::: lab
 **Lab 6: Sad plots**
 
 Critiquing and improving data visualisations
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-06/lab-06-sad-plots.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-06)
 :::
 
-::: {.starter}
+::: starter
 [Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-06-sad-plots)
 :::
 :::
 
-::: {.lab}
+::: lab
 **Lab 7: Simpson's paradox**
 
 Data visualisation, confounding, multivariable relationships
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-07)
 :::
 
-::: {.starter}
+::: starter
 [Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-07-simpsons-paradox)
 :::
 :::
 
-::: {.lab}
+::: lab
 **Lab 8: University of Edinburgh Art Collection**
 
 Web scraping, function, iteration
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-08/lab-08-uoe-art.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-08)
 :::
 
-::: {.starter}
+::: starter
 [Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-08-uoe-art)
 :::
 :::
 
 ## Homework assignments
 
-::: {.homework}
+::: homework
 **HW 1: Pet names**
 
 Introduction to working with data in R with the tidyverse
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-01/hw-01-pet-names.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-01)
 :::
 
-::: {.starter}
+::: starter
 [Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/hw/hw-01-pet-names)
 :::
 :::
 
-::: {.homework}
+::: homework
 **HW 2: Edinburgh Airbnb rentals**
 
 Data visualisation with the tidyverse
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-02)
 :::
 
-::: {.starter}
+::: starter
 [Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/hw/hw-02-airbnb-edi)
 :::
 :::
 
-::: {.homework}
+::: homework
 **HW 3: Road traffic accidents**
 
 Data wrangling, tidying, and visualization
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-03/hw-03-accidents.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-03)
 :::
 
-::: {.starter}
+::: starter
 [Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/hw/hw-03-accidents)
 :::
 :::
 
-::: {.homework}
+::: homework
 **HW 4: What should I major in?**
 
 More data wrangling, summarizing, and visualization
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-04/hw-04-college-majors.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-04)
 :::
 
-::: {.starter}
+::: starter
 [Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/hw/hw-04-college-majors)
 :::
 :::
 
-::: {.homework}
+::: homework
 **HW 5: Legos**
 
 More data wrangling, summarizing, and visualization
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-05/hw-05-legos.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-05)
 :::
 
-::: {.starter}
+::: starter
 [Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/hw/hw-05-legos)
 :::
 :::
 
-::: {.homework}
+::: homework
 **HW 6: Money in politics**
 
 Web scraping, functions, and iteration
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-06)
 :::
 
-::: {.starter}
+::: starter
 [Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/hw/hw-06-money-in-politics)
 :::
 :::

---FILE: 02-hello-world.qmd---
@@ -1,6 +1,6 @@
-# (PART) Course content {.unnumbered}
-
-# Hello world {#hello-world}
+---
+title: ""Hello world""
+---
 
 I recommend starting the class off right, devoting more of the class time to introducing the course content instead of the course policies.
 And get students doing something with data as quickly as possible!

---FILE: 02-interactive-tutorials.qmd---
@@ -1,92 +1,94 @@
-# Interactive tutorials {#interactive-tutorials}
+---
+title: ""Interactive tutorials""
+---
 
 The following interactive tutorials have been built with [**learnr**](https://rstudio.github.io/learnr/publishing.html) and [**gradethis**](https://rstudio-education.github.io/gradethis/).
-They're available on shinyapps.io (linked) as well as distributed with the [**dsbox**](https://rstudio-education.github.io/dsbox/tutorials/index.html) package.[^interactive-tutorials-1]
+They're available on shinyapps.io (linked) as well as distributed with the [**dsbox**](https://rstudio-education.github.io/dsbox/tutorials/index.html) package.[^1]
 With the dsbox package installed, you can also run these tutorials in the Tutorials pane of your RStudio window.
 This might be preferable for courses with high enrollment where students need to access the tutorials at the same time.
 
-[^interactive-tutorials-1]: The dsbox package is not yet on CRAN, until then you will need to install from GitHub with `devtools::install_github(""rstudio-education/dsbox"")`.
-
 Note that many of these include examples and questions from the homework assignments listed earlier.
 You can think of these as interactive, auto-feedback versions of the simpler questions in the homework assignments.
 If using both the tutorials and the homework assignments in your teaching, I recommend modifying the homework assignments to remove the redundant questions (they will usually be the earlier, shorter, simpler questions) and making the homework assignment shorter.
 Students will ultimately get exposed to the same material, but get auto-feedback in the tutorials and human feedback on the homework assignments.
 
 If you would like to learn about making your own tutorials with learnr, I strongly recommend reviewing the video and materials from the following 1.5 hour workshop: [Building interactive tutorials in R](https://mine-cetinkaya-rundel.github.io/teach-r-online/).
 
-::: {.tutorial}
+::: tutorial
 **Tutorial 1: Airbnb listings in Edinburgh**
 
 The goal of this tutorial is not to conduct a thorough analysis of Airbnb listings in Edinburgh, but instead to give you a chance to practice your data visualisation and interpretation skills.
 
-[[Tutorial]](https://minecr.shinyapps.io/dsbox-01-edibnb/) [[Source]](https://github.com/rstudio-education/dsbox/tree/master/inst/tutorials/01-basics)
+[\[Tutorial\]](https://minecr.shinyapps.io/dsbox-01-edibnb/) [\[Source\]](https://github.com/rstudio-education/dsbox/tree/master/inst/tutorials/01-basics)
 :::
 
-::: {.tutorial}
+::: tutorial
 **Tutorial 2: Road Traffic Accidents**
 
 -   Continue practising data visualization skills with ggplot2.
 -   Filter data for certain attributes with `filter()`.
 -   Create new variables based on existing variables in the data with `mutate()`.
 
-[[Tutorial]](https://minecr.shinyapps.io/dsbox-02-accidents/) [[Source]](https://github.com/rstudio-education/dsbox/tree/master/inst/tutorials/02-accidents)
+[\[Tutorial\]](https://minecr.shinyapps.io/dsbox-02-accidents/) [\[Source\]](https://github.com/rstudio-education/dsbox/tree/master/inst/tutorials/02-accidents)
 :::
 
-::: {.tutorial}
+::: tutorial
 **Tutorial 3: What should I major in?**
 
 -   Continue practising data tidying and visualisation.
 -   Calculate summary statistics with `summarise()`.
 -   Arrange output of dplyr chains with `arrange()`.
 
-[[Tutorial]](https://minecr.shinyapps.io/dsbox-03-collegegrads/) [[Source]](https://github.com/rstudio-education/dsbox/tree/master/inst/tutorials/03-collegegrads)
+[\[Tutorial\]](https://minecr.shinyapps.io/dsbox-03-collegegrads/) [\[Source\]](https://github.com/rstudio-education/dsbox/tree/master/inst/tutorials/03-collegegrads)
 :::
 
-::: {.tutorial}
+::: tutorial
 **Tutorial 4: Lego sales**
 
 -   Practice the analysis skills you have learned so far.
 -   Develop a question you can answer with the data.
 -   Deepen your understanding of building and interpreting visualisations.
 
-[[Tutorial]](https://minecr.shinyapps.io/dsbox-04-legosales/) [[Source]](https://github.com/rstudio-education/dsbox/tree/master/inst/tutorials/04-legosales)
+[\[Tutorial\]](https://minecr.shinyapps.io/dsbox-04-legosales/) [\[Source\]](https://github.com/rstudio-education/dsbox/tree/master/inst/tutorials/04-legosales)
 :::
 
-::: {.tutorial}
+::: tutorial
 **Tutorial 5: Money in US politics**
 
 -   Get started with scraping data from the web.
 -   Continue to build on your data cleaning and visualisation skills.
 
-[[Tutorial]](https://minecr.shinyapps.io/dsbox-05-moneyinpolitics/) [[Source]](https://github.com/rstudio-education/dsbox/tree/master/inst/tutorials/05-moneyinpolitics)
+[\[Tutorial\]](https://minecr.shinyapps.io/dsbox-05-moneyinpolitics/) [\[Source\]](https://github.com/rstudio-education/dsbox/tree/master/inst/tutorials/05-moneyinpolitics)
 :::
 
-::: {.tutorial}
+::: tutorial
 **Tutorial 6: Bike Rentals in D.C.**
 
 -   Continue to hone your data wrangling skills.
 -   Practice modelling and interpreting model results and performance.
 -   Conduct backwards selection for finding the ""best"" model.
 
-[[Tutorial]](https://minecr.shinyapps.io/dsbox-06-dcbikeshare/) [[Source]](https://github.com/rstudio-education/dsbox/tree/master/inst/tutorials/06-dcbikeshare)
+[\[Tutorial\]](https://minecr.shinyapps.io/dsbox-06-dcbikeshare/) [\[Source\]](https://github.com/rstudio-education/dsbox/tree/master/inst/tutorials/06-dcbikeshare)
 :::
 
-::: {.tutorial}
+::: tutorial
 **Tutorial 7: Exploring the General Social Survey**
 
 -   Work on your data manipulation skills.
 -   Fit linear models with multiple predictors.
 -   Interpret regression output.
 
-[[Tutorial]](https://minecr.shinyapps.io/dsbox-07-exploregss/) [[Source]](https://github.com/rstudio-education/dsbox/tree/master/inst/tutorials/07-exploregss)
+[\[Tutorial\]](https://minecr.shinyapps.io/dsbox-07-exploregss/) [\[Source\]](https://github.com/rstudio-education/dsbox/tree/master/inst/tutorials/07-exploregss)
 :::
 
-::: {.tutorial}
+::: tutorial
 **Tutorial 8: Bootstrapping the General Social Survey**
 
 -   Continue to hone your data wrangling skills.
 -   Use bootstrapping to construct confidence intervals.
 -   Interpret of confidence intervals in context of the data.
 
-[[Tutorial]](https://minecr.shinyapps.io/dsbox-08-bootstrapgss/) [[Source]](https://github.com/rstudio-education/dsbox/tree/master/inst/tutorials/08-bootstrapgss)
+[\[Tutorial\]](https://minecr.shinyapps.io/dsbox-08-bootstrapgss/) [\[Source\]](https://github.com/rstudio-education/dsbox/tree/master/inst/tutorials/08-bootstrapgss)
 :::
+
+[^1]: The dsbox package is not yet on CRAN, until then you will need to install from GitHub with `devtools::install_github(""rstudio-education/dsbox"")`.

---FILE: 02-looking-further.qmd---
@@ -1,149 +1,151 @@
-# Looking further {#looking-forward}
+---
+title: ""Looking further""
+---
 
 In the last unit we present a series of modules such as interactive reporting and visualization with Shiny, text analysis, machine learning, and Bayesian inference.
 These are independent modules that educators can choose to include in their introductory data science curriculum depending on how much time they have left in the semester.
 Note that the slides in this unit are a bit more sparse than the others, and much of the content is delivered as live coding sessions.
 
 ## Slides, videos, and application exercises
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 5 - Deck 1: Text analysis**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u5-d01-text-analysis/u5-d01-text-analysis.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u5-d01-text-analysis)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/_YqEHZccujc)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 5 - Deck 2: Comparing texts**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u5-d02-comparing-texts/u5-d02-comparing-texts.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u5-d02-comparing-texts)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/Q79feeFbsxM)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 5 - Deck 3: Interactive web apps**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u5-d03-interactive-web-app/u5-d03-interactive-web-app.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u5-d03-interactive-web-app)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/gXBEOFWrxsk)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 5 - Deck 4: Machine learning**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u5-d04-machine-learning/u5-d04-machine-learning.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u5-d04-machine-learning)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/IP5skNjwo7A)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 5 - Deck 5: Interactive data visualisation**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u5-d05-shiny-1/u5-d05-shiny-1.pdf)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 5 - Deck 6: Interactive data visualisation and reporting**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u5-d05-shiny-2/u5-d05-shiny-2.pdf)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 5 - Deck 7: Bayesian inference**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u5-d07-bayes-inf)
 :::
 :::
 
 ## Labs
 
-::: {.lab}
+::: lab
 **Lab 13: Working on projects**
 
 Fitting and interpreting simple linear regression models
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-13/lab-13-work-on-projects.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-13)
 :::
 :::
 
-::: {.lab}
+::: lab
 **Lab 14: Collaboration on GitHub**
 
 Fitting and interpreting simple linear regression models
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-14)
 :::
 :::
 
 ## Homework assignments
 
-::: {.homework}
+::: homework
 **HW 10: Wrapping up**
 
 Model validation and inference
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-10/hw-10-wrap-up.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-10)
 :::
 
-::: {.starter}
+::: starter
 [Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/hw/hw-10-wrap-up)
 :::
 :::

---FILE: 02-making-rigorous-conclusions.qmd---
@@ -1,10 +1,12 @@
-# Making rigorous conclusions {#making-rigorous-conclusions}
+---
+title: ""Making rigorous conclusions""
+---
 
 In this part we introduce modelling and statistical inference for making data-based conclusions.
 We discuss building, interpreting, and selecting models, visualizing interaction effects, and prediction and model validation.
 Statistical inference is introduced from a simulation based perspective, and the Central Limit Theorem is discussed very briefly to lay the foundation for future coursework in statistics.
 
-::: {.rstudio-cloud}
+::: rstudio-cloud
 The RStudio Cloud workspace for Data Science Course in a Box project is [here](https://rstudio.cloud/spaces/1655/join?access_code=5rdjusfIYF5iI0Gum2vNsBDLdtdnIEELBkf2EivK).
 You can join the workspace and play around with the sample application exercises.
 :::
@@ -13,376 +15,376 @@ You can join the workspace and play around with the sample application exercises
 
 ### Modelling data
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 4 - Deck 1: The language of models**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d01-language-of-models/u4-d01-language-of-models.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d01-language-of-models)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/MWkkvDopBKc)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 4 - Deck 2: Fitting and interpreting models**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d02-fitting-interpreting-models)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/69U92Q3pwnA)
 :::
 
-::: {.reading}
+::: reading
 IMS :: [Chp 7 - Linear regression with a single predictor](https://openintro-ims.netlify.app/model-slr.html)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 4 - Deck 3: Modelling nonlinear relationships**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d03-modeling-nonlinear-relationships)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/j4MZ6ZdHnHg)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 4 - Deck 4: Models with multiple predictors**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d04-model-multiple-predictors)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/mjkNabD4oi4)
 :::
 
-::: {.reading}
+::: reading
 IMS :: [Chp 8 - Linear regression with multiple predictors](https://openintro-ims.netlify.app/model-mlr.html)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 4 - Deck 5: More models with multiple predictors**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d05-more-model-multiple-predictors)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/nJAYRnLPb10)
 :::
 :::
 
 ### Classification and model building
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 4 - Deck 6: Logistic regression**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d06-logistic-reg)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/AidXFYSYfJg)
 :::
 
-::: {.reading}
+::: reading
 IMS :: [Chp 9 - Logistic regression](https://openintro-ims.netlify.app/model-logistic.html)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 4 - Deck 7: Prediction and overfitting**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d07-prediction-overfitting)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/Qd4lu_Lmwi0)
 :::
 
-::: {.reading}
+::: reading
 tidymodels :: [Build a model](https://www.tidymodels.org/start/models/)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 4 - Deck 8: Feature engineering**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d08-feature-engineering)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/wZt9ab4jBZ4)
 :::
 
-::: {.reading}
+::: reading
 tidymodels :: [Preprocess your data with recipes](https://www.tidymodels.org/start/recipes/)
 :::
 :::
 
 ### Model validation
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 4 - Deck 9: Cross validation**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d09-cross-validation/u4-d09-cross-validation.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d09-cross-validation)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/L1KfIISmUT4)
 :::
 
-::: {.reading}
+::: reading
 tidymodels :: [Evaluate your model with resampling](https://www.tidymodels.org/start/resampling/)
 :::
 :::
 
-::: {.application-exercise}
+::: application-exercise
 **The Office + Feature engineering, Pt. 1**
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.Rmd)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/qsUYstdN4LQ)
 :::
 :::
 
-::: {.application-exercise}
+::: application-exercise
 **The Office + Cross validation, Pt. 2**
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.Rmd)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/WstIr94Fdjc)
 :::
 :::
 
 ### Uncertainty quantification
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 4 - Deck 10: Quantifying uncertainty**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d10-quantify-uncertainty)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/LYpKrtZmQtI)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 4 - Deck 11: Bootstrapping**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d11-bootstrap/u4-d11-bootstrap.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d11-bootstrap)
 :::
 
-::: {.video}
+::: video
 [Video](https://youtu.be/bdqpI3iVOso)
 :::
 
-::: {.reading}
+::: reading
 IMS :: [Chp 12 - Confidence intervals with bootstrapping](https://openintro-ims.netlify.app/foundations-bootstrapping.html)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 4 - Deck 12: Hypothesis testing**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d12-hypothesis-testing)
 :::
 
-::: {.reading}
+::: reading
 [IMS :: Chp 11 - Hypothesis testing with randomization](https://openintro-ims.netlify.app/foundations-randomization.html)
 :::
 :::
 
-::: {.slide-deck}
+::: slide-deck
 **Unit 4 - Deck 13: Inference overview**
 
-::: {.slides}
+::: slides
 [Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d13-inference-overview/u4-d13-inference-overview.html#1)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d13-inference-overview)
 :::
 :::
 
 ## Labs
 
-::: {.lab}
+::: lab
 **Lab 10: Grading the professor, Pt. 1**
 
 Fitting and interpreting simple linear regression models
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-10)
 :::
 
-::: {.starter}
+::: starter
 [Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-10-slr-course-evals)
 :::
 :::
 
-::: {.lab}
+::: lab
 **Lab 11: Grading the professor, Pt. 2**
 
 Fitting and interpreting multiple linear regression models
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-11)
 :::
 
-::: {.starter}
+::: starter
 [Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-11-mlr-course-evals)
 :::
 :::
 
-::: {.lab}
+::: lab
 **Lab 12: Smoking while pregnant**
 
 Constructing confidence intervals, conducting hypothesis tests, and interpreting results in context of the data
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-12)
 :::
 
-::: {.starter}
+::: starter
 [Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-12-inference-smoking)
 :::
 :::
 
 ## Homework assignments
 
-::: {.homework}
+::: homework
 **HW 7: Bike rentals in DC**
 
 Exploratory data analysis and fitting and interpreting models
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-07)
 :::
 
-::: {.starter}
+::: starter
 [Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/hw/hw-07-bike-rentals-dc)
 :::
 :::
 
-::: {.homework}
+::: homework
 **HW 8: Exploring the GSS**
 
 Fitting and interpreting models
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-08)
 :::
 
-::: {.starter}
+::: starter
 [Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/hw/hw-08-exploring-gss)
 :::
 :::
 
-::: {.homework}
+::: homework
 **HW 9: Modelling the GSS**
 
 Model validation and inference
 
-::: {.instructions}
+::: instructions
 [Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html)
 :::
 
-::: {.source}
+::: source
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-09)
 :::
 
-::: {.starter}
+::: starter
 [Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/hw/hw-09-modeling-gss)
 :::
 :::

---FILE: 02-project.qmd---
@@ -1,4 +1,6 @@
-# Project {#project}
+---
+title: ""Project""
+---
 
 The following is a sample project assignment for this curriculum.
 You can find the source code for this assignment write up [here](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/project).
@@ -68,9 +70,9 @@ But you might find something interesting there:
 
 ### Deliverables
 
-1.  Proposal - due [ENTER DUE DATE]
-2.  Presentation - due [ENTER DUE DATE]
-3.  Executive summary - due [ENTER DUE DATE]
+1.  Proposal - due \[ENTER DUE DATE\]
+2.  Presentation - due \[ENTER DUE DATE\]
+3.  Executive summary - due \[ENTER DUE DATE\]
 
 #### Proposal
 
@@ -107,17 +109,12 @@ The grading scheme for the project proposal is as follows.
 Note that after you receive feedback for your proposal you can improve it based on the feedback and re-submit it.
 If you re-submit, your final score for the proposal will be the average of two scores you receive (first and second submission).
 
-+-----------------------------------------------------------+----------+
-| Total                                                     | 10 pts   |
-+===========================================================+==========+
-| Data                                                      | 3 pts    |
-+-----------------------------------------------------------+----------+
-| Proposal                                                  | 5 pts    |
-+-----------------------------------------------------------+----------+
-| Workflow, organization, code quality                      | 1 pt     |
-+-----------------------------------------------------------+----------+
-| Teamwork                                                  | 1 pt     |
-+-----------------------------------------------------------+----------+
+| Total                                | 10 pts |
+|--------------------------------------|--------|
+| Data                                 | 3 pts  |
+| Proposal                             | 5 pts  |
+| Workflow, organization, code quality | 1 pt   |
+| Teamwork                             | 1 pt   |
 
 #### Presentation
 
@@ -139,23 +136,15 @@ The presentation line-up will be generated randomly.
 
 The grading scheme for the presentation is as follows:
 
-+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
 | Total                                                                                                                                                                                                          | 50 pts |
-+================================================================================================================================================================================================================+========+
+|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------|
 | Time management: Did the team divide the time well amongst themselves or got cut off going over time?                                                                                                          | 4 pts  |
-+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
 | Content: Is the research question well designed and is the data being used relevant to the research question?                                                                                                  | 5 pts  |
-+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
 | Professionalism: How well did the team present? Does the presentation appear to be well practiced? Did everyone get a chance to say something meaningful about the project?                                    | 5 pts  |
-+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
 | Teamwork: Did the team present a unified story, or did it seem like independent pieces of work patched together?                                                                                               | 6 pts  |
-+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
 | Content: Did the team use appropriate statistical procedures and interpretations of results accurately?                                                                                                        | 10 pts |
-+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
 | Creativity and Critical Thought: Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project? | 10 pts |
-+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
 | Slides: Are the slides well organized, readable, not full of text, featuring figures with legible labels, legends, etc.?                                                                                       | 10 pts |
-+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
 
 #### Executive summary
 
@@ -200,21 +189,14 @@ Style and format does count for this assignment, so please take the time to make
 
 ### Marking
 
-+----------------------------------------------------------+-----------+
-| Total                                                    | 100 pts   |
-+==========================================================+===========+
-| Proposal                                                 | 10 pts    |
-+----------------------------------------------------------+-----------+
-| Presentation                                             | 50 pts    |
-+----------------------------------------------------------+-----------+
-| Executive summary                                        | 15 pts    |
-+----------------------------------------------------------+-----------+
-| Reproducibility and organization                         | 10 pts    |
-+----------------------------------------------------------+-----------+
-| Team peer evaluation                                     | 10 pts    |
-+----------------------------------------------------------+-----------+
-| Classmates' evaluation                                   | 5 pts     |
-+----------------------------------------------------------+-----------+
+| Total                            | 100 pts |
+|----------------------------------|---------|
+| Proposal                         | 10 pts  |
+| Presentation                     | 50 pts  |
+| Executive summary                | 15 pts  |
+| Reproducibility and organization | 10 pts  |
+| Team peer evaluation             | 10 pts  |
+| Classmates' evaluation           | 5 pts   |
 
 #### Criteria
 

---FILE: 03-access-r.qmd---
@@ -1,6 +1,6 @@
-# (PART) Infrastructure {.unnumbered}
-
-# Accessing R {#access-r}
+---
+title: ""Accessing R""
+---
 
 One of the design principles of this course is ""cherish day one"" -- get students from nothing to their first meaningful data visualization within the first 10 minutes of the course.
 Achieving this is possible, but requires careful consideration of the computing infrastructure.
@@ -13,12 +13,12 @@ Additionally, since it is a full fledged IDE, it also features integrated help,
 [RStudio Cloud](https://rstudio.cloud/) is a managed cloud instance of the RStudio IDE. We recommend having students access RStudio via RStudio Cloud as opposed to using a local installation.
 The main reason for this choice is reducing friction at first exposure to R.
 Local installation can be difficult to manage, both for the student and the instructor, and can shift the focus away from data science learning at the beginning of the course.
-We discuss in further detail the reasons for avoiding local installation at the beginning of the course in Section \@ref(design-principles).[^access-r-1]
+We discuss in further detail the reasons for avoiding local installation at the beginning of the course in [Design Principles](01-design-principles.html).[^1]
 
 When you create an account on RStudio Cloud, you get a workspace of your own, and the projects you create here can be public or private.
 You can also add a new workspace and control its permissions, and the projects you create here can also be public or private.
 
-::: {.rstudio-cloud}
+::: rstudio-cloud
 The RStudio Cloud workspace for Data Science Course in a Box project is [here](https://rstudio.cloud/spaces/1655/join?access_code=5rdjusfIYF5iI0Gum2vNsBDLdtdnIEELBkf2EivK).
 You can join the workspace and play around with the application exercises.
 :::
@@ -29,8 +29,13 @@ Once a workspace is set up, instructors can invite students to the workspace via
 Workspaces allow for various permission levels which can be assigned to students, teaching assistants, and instructors.
 Then, each assignment/project in the course maps to an RStudio Cloud project.
 
-```{r rscloud-bigpicture, fig.align=""center"", echo=FALSE, fig.cap=""RStudio Cloud classroom structure""}
-include_graphics(path = ""images/rscloud-bigpicture.png"")
+```{r}
+#| label: rscloud-bigpicture
+#| fig-align: center
+#| echo: false
+#| fig-cap: ""RStudio Cloud classroom structure""
+
+knitr::include_graphics(path = ""images/rscloud-bigpicture.png"")
 ```
 
 ## Setting up your course in RStudio Cloud
@@ -42,33 +47,38 @@ You can update the information once the space is created, however you can't chan
 For the name,\
 I recommend using something along the lines of Course number - Semester.
 
-```{r rscloud-new-workspace, fig.align=""center"", echo=FALSE, fig.cap=""Creating a new workspace on RStudio Cloud""}
-include_graphics(path = ""images/rscloud-new-workspace.png"")
+```{r}
+#| label: rscloud-new-workspace
+#| fig-align: center
+#| echo: false
+#| fig-cap: ""Creating a new workspace on RStudio Cloud""
+
+knitr::include_graphics(path = ""images/rscloud-new-workspace.png"")
 ```
 
 Next step is to invite members to the workspace.
 You can do this by sending invitations or using a sharing link.
 I recommend using the latter approach for efficiency.
 Once all of your students are in the course (or once drop/add period ends) you can change the settings so that additional members cannot join throughout the semester using the sharing link, and can only be added via an invitation from the instructor.
 
-```{r rscloud-workspace-permissions, fig.align=""center"", echo=FALSE, fig.cap=""Setting workspace permissions""}
-include_graphics(path = ""images/rscloud-workspace-permissions.png"")
+```{r}
+#| label: rscloud-workspace-permissions
+#| fig-align: center
+#| echo: false
+#| fig-cap: ""Setting workspace permissions""
+
+knitr::include_graphics(path = ""images/rscloud-workspace-permissions.png"")
 ```
 
 As highlighted in the figure above, when a workspace is set to accept members via a shared link, the owner can also set a default permission level for those entering the workspace via the sharing link.
 Suggested permission levels and suggestions for mapping to course roles are as follows.
 
-+--------------------+--------------------------------------------------+--------------------+
 | RStudio Cloud role | Permissions                                      | Course role        |
-+====================+==================================================+====================+
+|------------------|------------------------------------|------------------|
 | Admin              | Manage users, view, edit and manage all projects | Instructor         |
-+--------------------+--------------------------------------------------+--------------------+
 | Moderator          | View, edit and manage all projects               | Teaching Assistant |
-+--------------------+--------------------------------------------------+--------------------+
 | Contributor        | Create, edit and manage their own projects       | Student            |
-+--------------------+--------------------------------------------------+--------------------+
 | Viewer             | View projects shared with everyone               | Auditor, Visitor   |
-+--------------------+--------------------------------------------------+--------------------+
 
 This set of permissions will allow instructors full access including management of users.
 Teaching assistants will be able to peek into student projects, which can be very useful when helping troubleshoot.
@@ -85,8 +95,13 @@ A project in RStudio Cloud is equivalent to an RStudio project.
 If you are an RStudio user, but you don't use projects, I highly recommend considering switching your workflow to include projects.
 You can learn more about them [here](http://r4ds.had.co.nz/workflow-projects.html#rstudio-projects).
 
-```{r rscloud-new-project, fig.align=""center"", echo=FALSE, fig.cap=""A new project in RStudio Cloud is a new project in the RStudio IDE""}
-include_graphics(path = ""images/rscloud-new-project.png"")
+```{r}
+#| label: rscloud-new-project
+#| fig-align: center
+#| echo: false
+#| fig-cap: ""A new project in RStudio Cloud is a new project in the RStudio IDE""
+
+knitr::include_graphics(path = ""images/rscloud-new-project.png"")
 ```
 
 ### Access
@@ -100,8 +115,13 @@ This default has two advantages:
 When your project is ready to be shared with the students in your course, you can adjust the access level by clicking on the gear icon to reveal the settings menu.
 You should also check the ""Make this project an assignment"" box so that when a student starts their assignment RStudio Cloud automatically makes a copy of the project for them.
 
-```{r rscloud-project-permissions, fig.align=""center"", echo=FALSE, fig.cap=""Setting project permissions within a workspace""}
-include_graphics(path = ""images/rscloud-project-permissions.png"")
+```{r}
+#| label: rscloud-project-permissions
+#| fig-align: center
+#| echo: false
+#| fig-cap: ""Setting project permissions within a workspace""
+
+knitr::include_graphics(path = ""images/rscloud-project-permissions.png"")
 ```
 
 ## Base project template
@@ -111,8 +131,13 @@ You can use this by defining a base project template for the space.
 Simply create a new project and add any packages or files you want projects created in the space to start with.
 After creating your project, select it on the Settings page as the base project template.
 
-```{r rscloud-base-template, fig.align=""center"", echo=FALSE, fig.cap=""Selecting a base project template""}
-include_graphics(path = ""images/rscloud-base-template.png"")
+```{r}
+#| label: rscloud-base-template
+#| fig-align: center
+#| echo: false
+#| fig-cap: ""Selecting a base project template""
+
+knitr::include_graphics(path = ""images/rscloud-base-template.png"")
 ```
 
 Note that a project must be shared with everyone in the space in order to be used as a template; only projects which are viewable by everyone in the space will appear in the templates list.
@@ -125,13 +150,18 @@ Therefore updating the base project will not break projects already created with
 
 It is possible to create (clone) a new project in RStudio Cloud from a GitHub repository, just like in the RStudio IDE.
 
-```{r rscloud-git-project, fig.align=""center"", echo=FALSE, fig.cap=""Creating a new project from GitHub repository""}
-include_graphics(path = ""images/rscloud-git-project.png"")
+```{r}
+#| label: rscloud-git-project
+#| fig-align: center
+#| echo: false
+#| fig-cap: ""Creating a new project from GitHub repository""
+
+knitr::include_graphics(path = ""images/rscloud-git-project.png"")
 ```
 
 If you have a base project template set up for your workspace, this new project created from GitHub will also have the packages installed in the base project template.
 
-For more on using Git and GitHub in the classroom, see Section \@ref(version-control).
+For more on using Git and GitHub in the classroom, see [Version Control](03-version-control.html).
 
 ## Troubleshooting
 
@@ -166,7 +196,7 @@ To see this all in action and learn more, watch the following RStudio Cloud webi
 -   [Teaching R online with RStudio Cloud](https://resources.rstudio.com/webinars/rstudio-cloud-in-the-classroom) (March 2020)
 -   [RStudio Cloud in the Classroom](https://resources.rstudio.com/webinars/rstudio-cloud-in-the-classroom)
 
-[^access-r-1]: Note that as of August 2020 RStudio Cloud offers paid tiers as well, and you will likely need a paid subscription to teach with RStudio Cloud (unless you're teaching a short, small course).
+[^1]: Note that as of August 2020 RStudio Cloud offers paid tiers as well, and you will likely need a paid subscription to teach with RStudio Cloud (unless you're teaching a short, small course).
     Depending on your institution's IT infrastructure and your class size, RStudio Cloud may or may not be the most economically feasible solution for your teaching needs.
-    See Section \@ref(alternative-setups) for suggestions for other setups for providing server access to RStudio for your students.
-    Note that these alternatives generally require system infrastructure expertiose or IT professional time.
+    See [Alternative Setups](03-alternative-setups.html) for suggestions for other setups for providing server access to RStudio for your students.
+    Note that these alternatives generally require system infrastructure expertise or IT professional time.

---FILE: 03-alternative-setups.qmd---
@@ -1,4 +1,6 @@
-# Alternative setups {#alternative-setups}
+---
+title: ""Alternative setups""
+---
 
 In this section we describe alternative setups for your course.
 
@@ -19,8 +21,13 @@ The figure below is a sketch of the architecture of the centralized RStudio serv
 This works well for upper division and graduate level courses as most students are directly affiliated with the department.
 Students taking courses who are not affiliated with the department are issued temporary visitor accounts which expire at the end of the semester.
 
-```{r alt-centralized-server, fig.align=""center"", echo=FALSE, fig.cap=""Centralized RStudio server""}
-include_graphics(path = ""images/alt-centralized-server.png"")
+```{r}
+#| label: alt-centralized-server
+#| fig-align: center
+#| echo: false
+#| fig-cap: ""Centralized RStudio server""
+
+knitr::include_graphics(path = ""images/alt-centralized-server.png"")
 ```
 
 More modest configurations can be more than adequate (e.g., a mid-to-high end desktop) for the vast majority of use cases, however care should be given when working with larger datasets in a shared environment.
@@ -36,8 +43,13 @@ For example, advanced courses can include homework assignments where students ne
 A second approach to running RStudio server involves the construction and hosting of a farm of individualized Docker container instances.
 A sketch of the architecture of the Docker containers is in the figure below, which shows that students authenticate via university login which redirects them to a personal RStudio instance running in a Docker container on either a local or cloud based server.
 
-```{r alt-docker, fig.align=""center"", echo=FALSE, fig.cap=""Dockerized RStudio server""}
-include_graphics(path = ""images/alt-docker.png"")
+```{r}
+#| label: alt-docker
+#| fig-align: center
+#| echo: false
+#| fig-cap: ""Dockerized RStudio server""
+
+knitr::include_graphics(path = ""images/alt-docker.png"")
 ```
 
 Docker is a popular and rapidly evolving containerization tool suite that allows users to automate the deployment of software in a repeatable and self-contained way.

---FILE: 03-discussion.qmd---
@@ -1,4 +1,6 @@
-# Discussion {#discussion}
+---
+title: ""Discussion""
+---
 
 My recommended tool for course discussion is [Piazza](http://piazza.com/).
 

---FILE: 03-sharing.qmd---
@@ -1,4 +1,6 @@
-# Sharing {#sharing}
+---
+title: ""Sharing""
+---
 
 A nifty tool for building your course website is blogdown.
 

---FILE: 03-version-control.qmd---
@@ -1,4 +1,6 @@
-# Version control {#version-control}
+---
+title: ""Version control""
+---
 
 One of the defining principles behind how this course teaches computing is that everything the instructor and the students produce should be reproducible -- how you get a result is just as important as the result itself.
 Implicit in the idea of reproducibility is collaboration, the code you produce is documentation of the process and it is critical to share it (even if only with yourself in the future).
@@ -8,7 +10,7 @@ This is best accomplished with a distributed version control system like Git
 This course adopts a top down approach to teaching Git -- students are *required* to use it for *all* assignments.
 These type of tools tend to suffer from delayed gratification as when they are first introduced students view them as a clunky addition to their workflow and it is not until weeks or even months later that they experience the value first hand.
 
-If this section doesn't convince you that you should be using Git and GitHub in your data science course, Chapter \@ref(alternative-setups) describes how to leverage RStudio Cloud features for assignment dissemination, collection, and providing feedback.
+If this section doesn't convince you that you should be using Git and GitHub in your data science course, [Alternative Setups](03-alternative-setups.html) describes how to leverage RStudio Cloud features for assignment dissemination, collection, and providing feedback.
 You can also use your own institution's learning management system for this purpose as well.
 
 ## Git
@@ -54,7 +56,7 @@ In order to comply with Family Educational Rights and Privacy Act (FERPA) requir
 
 Setup and management for larger classes can be challenging due to the sheer number of components, however most actions can be scripted via the GitHub API which can dramatically reduce the course administrative workload.
 Two solutions to this problem are (1) GitHub Classroom and (2) ghclass.
-Use of ghclass, an R package for GitHub classroom tools is detailed below, and use of GitHub classroom is described in Chapter \@ref(alternative-setups).
+Use of ghclass, an R package for GitHub classroom tools is detailed below, and use of GitHub classroom is described in [Alternative Setups](03-alternative-setups.html).
 
 ## ghclass
 

---FILE: 04-pedagogy.qmd---
@@ -1,6 +1,6 @@
-# (PART) Pedagogy {.unnumbered}
-
-# Pedagogy {#pedagogy}
+---
+title: ""Pedagogy""
+---
 
 ## Course design
 
@@ -10,12 +10,12 @@ The following resources describe the pedagogy used in designing and teaching a c
 > A fresh look at introductory data science, *Journal of Statistics Education*.
 > [doi.org/10.1080/10691898.2020.1804497](https://doi.org/10.1080/10691898.2020.1804497).
 
-> Talk: The art and science of teaching data science [[Slides]](https://speakerdeck.com/minecr/the-art-and-science-of-teaching-data-science-university-of-glasgow)
+> Talk: The art and science of teaching data science [\[Slides\]](https://speakerdeck.com/minecr/the-art-and-science-of-teaching-data-science-university-of-glasgow)
 
-> Talk: Data Science in a Box [[Slides]](https://speakerdeck.com/minecr/data-science-in-a-box) [[Video]](https://www.youtube.com/watch?v=tYGLYdeFJMc)
+> Talk: Data Science in a Box [\[Slides\]](https://speakerdeck.com/minecr/data-science-in-a-box) [\[Video\]](https://www.youtube.com/watch?v=tYGLYdeFJMc)
 
 > Talk: Let them eat cake (first)!
-> [[Slides]](https://speakerdeck.com/minecr/let-them-eat-cake-first) [[Video]](https://www.youtube.com/embed/RsVOrpXAPXo?start=1009)
+> [\[Slides\]](https://speakerdeck.com/minecr/let-them-eat-cake-first) [\[Video\]](https://www.youtube.com/embed/RsVOrpXAPXo?start=1009)
 
 ## Teaching the tidyverse
 

---FILE: 04-schedule.qmd---
@@ -1,4 +1,6 @@
-# Schedule {#schedule}
+---
+title: ""Schedule""
+---
 
 There are a lot of materials in Data Science Course in a Box, which allows instructors to pick and choose what they want depending on the length of the course they're teaching, their audience, and the curriculum within which the course is placed.
 The following are two options for course schedules, one for a 11-week course and the other for a 15-week course.
@@ -165,180 +167,92 @@ The following are two options for course schedules, one for a 11-week course and
 
 ## 15-week schedule
 
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| Unit  | Week   | Title                                               | Type                        |
-+=======+========+=====================================================+=============================+
-| 1     | 1      | Welcome to data science!                            | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 1     | 1      | Meet the toolkit: Programming                       | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 1     | 1      | Meet the toolkit: Version control & collaboration   | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 1     | 1      | Hello R                                             | Lab                         |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 1     | 1      | Pet names                                           | Homework                    |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **2** | **2**  | **Data and visualisation**                          | **Lecture**                 |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **2** | **2**  | **Visualising data with ggplot2**                   | **Lecture**                 |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **2** | **2**  | **Visualising numerical data**                      | **Lecture**                 |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **2** | **2**  | **Visualising categorical data**                    | **Lecture**                 |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **2** | **2**  | **StarWars + Dataviz**                              | **Application exercise**    |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **2** | **2**  | **Plastic waste**                                   | **Lab**                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **2** | **2**  | **Airbnb listings in Edinburgh**                    | **Homework**                |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 2     | 3      | Tidy data                                           | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 2     | 3      | Grammar of data wrangling                           | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 2     | 3      | Working with a single data frame                    | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 2     | 3      | Working with multiple data frames                   | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 2     | 3      | Tidying data                                        | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 2     | 3      | Hotels + Data wrangling                             | Application exercise        |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 2     | 3      | Nobel laureates                                     | Lab                         |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 2     | 3      | Road traffic accidents                              | Homework                    |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **2** | **4**  | **Data types**                                      | **Lecture**                 |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **2** | **4**  | **Data classes**                                    | **Lecture**                 |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **2** | **4**  | **Recoding data**                                   | **Lecture**                 |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **2** | **4**  | **Hotels + Data types**                             | **Application exercise**    |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **2** | **4**  | **La Quinta is Spanish for next to Denny's, Pt. 1** | **Lab**                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **2** | **4**  | **College majors**                                  | **Homework**                |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 2     | 5      | Importing data                                      | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 2     | 5      | Nobels + Sales + Data import                        | Application exercise        |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 2     | 5      | Tips for effective data visualization               | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 2     | 5      | Brexit + Telling stories with dataviz               | Application exercise        |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 2     | 5      | Take a sad plot and make it better                  | Lab                         |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 2     | 5      | La Quinta is Spanish for next to Denny's, Pt. 2     | Homework                    |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **2** | **6**  | **Scientific studies and confounding**              | **Lecture**                 |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **2** | **6**  | **Simpson's paradox**                               | **Lecture**                 |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **2** | **6**  | **Doing data science**                              | **Lecture**                 |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **2** | **6**  | **Simpson's paradox**                               | **Lab**                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **2** | **6**  | **Legos**                                           | **Homework**                |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 2     | 7      | Web scraping                                        | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 2     | 7      | Scraping top 250 movies on IMDB                     | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 2     | 7      | Web scraping considerations                         | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 2     | 7      | IMDB + Web scraping                                 | Application exercise        |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 2     | 7      | Work on projects                                    | Lab                         |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 2     | 7      | Work on projects                                    | Homework                    |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **2** | **8**  | **Functions**                                       | **Lecture**                 |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **2** | **8**  | **Iteration**                                       | **Lecture**                 |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **2** | **8**  | **University of Edinburgh Art Collection**          | **Lab**                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **2** | **8**  | **Money in politics**                               | **Homework**                |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 3     | 9      | Misrepresentation                                   | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 3     | 9      | Data privacy                                        | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 3     | 9      | Algorithmic bias                                    | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 3     | 9      | Conveying the right message through visualisation   | Lab                         |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 3     | 9      | Project proposals                                   | Project                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 3     | 9      | Peer review of project proposals                    | Homework                    |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **4** | **10** | **Fitting and interpreting models**                 | **Lecture**                 |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **4** | **10** | **Modelling nonlinear relationships**               | **Lecture**                 |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **4** | **10** | **Models with multiple predictors**                 | **Lecture**                 |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **4** | **10** | **More models with multiple predictors**            | **Lecture**                 |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **4** | **10** | **Grading the professor, Pt 1**                     | **Lab**                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **4** | **10** | **Bike rentals in DC**                              | **Homework**                |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 4     | 11     | Logistic regression                                 | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 4     | 11     | Prediction and overfitting                          | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 4     | 11     | Feature engineering                                 | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 4     | 11     | Grading the professor, Pt. 1                        | Lab                         |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 4     | 11     | Exploring the GSS                                   | Homework                    |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **4** | **12** | **Cross validation**                                | **Lecture**                 |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **4** | **12** | **The Office, Part 1**                              | **Application exercise**    |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **4** | **12** | **The Office, Part 2**                              | **Application exercise**    |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **4** | **12** | **Bootstrapping**                                   | **Lecture**                 |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **4** | **12** | **Work on projects**                                | **Lab**                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **4** | **12** | **Grading the professor, Pt. 2**                    | **Homework**                |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 4     | 13     | Quantifying uncertainty                             | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 4     | 13     | Bootstrapping                                       | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 4     | 13     | Hypothesis testing                                  | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 4     | 13     | Inference overview                                  | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 4     | 13     | Smoking during pregnancy                            | Lab                         |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 4     | 13     | Modelling the GSS                                   | Homework                    |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **5** | **14** | **Text analysis**                                   | **Lecture**                 |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **5** | **14** | **Comparing texts**                                 | **Lecture**                 |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **5** | **14** | **Interactive web apps**                            | **Lecture**                 |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **5** | **14** | **Machine learning**                                | **Lecture**                 |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **5** | **14** | **Collaborating on GitHub**                         | **Lab**                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| **5** | **14** | **Wrap up**                                         | **Homework**                |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 5     | 15     | Bayesian inference                                  | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 5     | 15     | Building interactive web apps, Pt. 1                | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 5     | 15     | Building interactive web apps, Pt. 1                | Lecture                     |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 5     | 15     | Project presentations                               | Lab                         |
-+-------+--------+-----------------------------------------------------+-----------------------------+
-| 5     | 15     | N/A                                                 | Homework                    |
-+-------+--------+-----------------------------------------------------+-----------------------------+
+| Unit  | Week   | Title                                               | Type                     |
+|-------|--------|-----------------------------------------------------|--------------------------|
+| 1     | 1      | Welcome to data science!                            | Lecture                  |
+| 1     | 1      | Meet the toolkit: Programming                       | Lecture                  |
+| 1     | 1      | Meet the toolkit: Version control & collaboration   | Lecture                  |
+| 1     | 1      | Hello R                                             | Lab                      |
+| 1     | 1      | Pet names                                           | Homework                 |
+| **2** | **2**  | **Data and visualisation**                          | **Lecture**              |
+| **2** | **2**  | **Visualising data with ggplot2**                   | **Lecture**              |
+| **2** | **2**  | **Visualising numerical data**                      | **Lecture**              |
+| **2** | **2**  | **Visualising categorical data**                    | **Lecture**              |
+| **2** | **2**  | **StarWars + Dataviz**                              | **Application exercise** |
+| **2** | **2**  | **Plastic waste**                                   | **Lab**                  |
+| **2** | **2**  | **Airbnb listings in Edinburgh**                    | **Homework**             |
+| 2     | 3      | Tidy data                                           | Lecture                  |
+| 2     | 3      | Grammar of data wrangling                           | Lecture                  |
+| 2     | 3      | Working with a single data frame                    | Lecture                  |
+| 2     | 3      | Working with multiple data frames                   | Lecture                  |
+| 2     | 3      | Tidying data                                        | Lecture                  |
+| 2     | 3      | Hotels + Data wrangling                             | Application exercise     |
+| 2     | 3      | Nobel laureates                                     | Lab                      |
+| 2     | 3      | Road traffic accidents                              | Homework                 |
+| **2** | **4**  | **Data types**                                      | **Lecture**              |
+| **2** | **4**  | **Data classes**                                    | **Lecture**              |
+| **2** | **4**  | **Recoding data**                                   | **Lecture**              |
+| **2** | **4**  | **Hotels + Data types**                             | **Application exercise** |
+| **2** | **4**  | **La Quinta is Spanish for next to Denny's, Pt. 1** | **Lab**                  |
+| **2** | **4**  | **College majors**                                  | **Homework**             |
+| 2     | 5      | Importing data                                      | Lecture                  |
+| 2     | 5      | Nobels + Sales + Data import                        | Application exercise     |
+| 2     | 5      | Tips for effective data visualization               | Lecture                  |
+| 2     | 5      | Brexit + Telling stories with dataviz               | Application exercise     |
+| 2     | 5      | Take a sad plot and make it better                  | Lab                      |
+| 2     | 5      | La Quinta is Spanish for next to Denny's, Pt. 2     | Homework                 |
+| **2** | **6**  | **Scientific studies and confounding**              | **Lecture**              |
+| **2** | **6**  | **Simpson's paradox**                               | **Lecture**              |
+| **2** | **6**  | **Doing data science**                              | **Lecture**              |
+| **2** | **6**  | **Simpson's paradox**                               | **Lab**                  |
+| **2** | **6**  | **Legos**                                           | **Homework**             |
+| 2     | 7      | Web scraping                                        | Lecture                  |
+| 2     | 7      | Scraping top 250 movies on IMDB                     | Lecture                  |
+| 2     | 7      | Web scraping considerations                         | Lecture                  |
+| 2     | 7      | IMDB + Web scraping                                 | Application exercise     |
+| 2     | 7      | Work on projects                                    | Lab                      |
+| 2     | 7      | Work on projects                                    | Homework                 |
+| **2** | **8**  | **Functions**                                       | **Lecture**              |
+| **2** | **8**  | **Iteration**                                       | **Lecture**              |
+| **2** | **8**  | **University of Edinburgh Art Collection**          | **Lab**                  |
+| **2** | **8**  | **Money in politics**                               | **Homework**             |
+| 3     | 9      | Misrepresentation                                   | Lecture                  |
+| 3     | 9      | Data privacy                                        | Lecture                  |
+| 3     | 9      | Algorithmic bias                                    | Lecture                  |
+| 3     | 9      | Conveying the right message through visualisation   | Lab                      |
+| 3     | 9      | Project proposals                                   | Project                  |
+| 3     | 9      | Peer review of project proposals                    | Homework                 |
+| **4** | **10** | **Fitting and interpreting models**                 | **Lecture**              |
+| **4** | **10** | **Modelling nonlinear relationships**               | **Lecture**              |
+| **4** | **10** | **Models with multiple predictors**                 | **Lecture**              |
+| **4** | **10** | **More models with multiple predictors**            | **Lecture**              |
+| **4** | **10** | **Grading the professor, Pt 1**                     | **Lab**                  |
+| **4** | **10** | **Bike rentals in DC**                              | **Homework**             |
+| 4     | 11     | Logistic regression                                 | Lecture                  |
+| 4     | 11     | Prediction and overfitting                          | Lecture                  |
+| 4     | 11     | Feature engineering                                 | Lecture                  |
+| 4     | 11     | Grading the professor, Pt. 1                        | Lab                      |
+| 4     | 11     | Exploring the GSS                                   | Homework                 |
+| **4** | **12** | **Cross validation**                                | **Lecture**              |
+| **4** | **12** | **The Office, Part 1**                              | **Application exercise** |
+| **4** | **12** | **The Office, Part 2**                              | **Application exercise** |
+| **4** | **12** | **Bootstrapping**                                   | **Lecture**              |
+| **4** | **12** | **Work on projects**                                | **Lab**                  |
+| **4** | **12** | **Grading the professor, Pt. 2**                    | **Homework**             |
+| 4     | 13     | Quantifying uncertainty                             | Lecture                  |
+| 4     | 13     | Bootstrapping                                       | Lecture                  |
+| 4     | 13     | Hypothesis testing                                  | Lecture                  |
+| 4     | 13     | Inference overview                                  | Lecture                  |
+| 4     | 13     | Smoking during pregnancy                            | Lab                      |
+| 4     | 13     | Modelling the GSS                                   | Homework                 |
+| **5** | **14** | **Text analysis**                                   | **Lecture**              |
+| **5** | **14** | **Comparing texts**                                 | **Lecture**              |
+| **5** | **14** | **Interactive web apps**                            | **Lecture**              |
+| **5** | **14** | **Machine learning**                                | **Lecture**              |
+| **5** | **14** | **Collaborating on GitHub**                         | **Lab**                  |
+| **5** | **14** | **Wrap up**                                         | **Homework**             |
+| 5     | 15     | Bayesian inference                                  | Lecture                  |
+| 5     | 15     | Building interactive web apps, Pt. 1                | Lecture                  |
+| 5     | 15     | Building interactive web apps, Pt. 1                | Lecture                  |
+| 5     | 15     | Project presentations                               | Lab                      |
+| 5     | 15     | N/A                                                 | Homework                 |

---FILE: _bookdown.yml---
@@ -1,36 +0,0 @@
-book_filename: ""datasciencebox""
-delete_merged_file: true
-language:
-  ui:
-    chapter_name: ""Chapter ""
-
-rmd_files: [
-  ""index.Rmd"",
-  
-  ""01-overview.Rmd"",
-  ""01-design-principles.Rmd"",
-  ""01-topics.Rmd"",
-  ""01-tech-stack.Rmd"",
-  ""01-community.Rmd"",
-  
-  ""02-hello-world.Rmd"",
-  ""02-exploring-data.Rmd"",
-  ""02-ethics.Rmd"",
-  ""02-making-rigorous-conclusions.Rmd"",
-  ""02-looking-further.Rmd"",
-  ""02-interactive-tutorials.Rmd"",
-  ""02-project.Rmd"",
-  ""02-exams.Rmd"",
-
-  ""03-access-r.Rmd"",
-  ""03-version-control.Rmd"",
-  ""03-discussion.Rmd"",
-  ""03-sharing.Rmd"",
-  ""03-alternative-setups.Rmd"",
-  
-  ""04-pedagogy.Rmd"",
-  ""04-schedule.Rmd""
-  ]
-
-new_session: yes
-before_chapter_script: ""_common.R""

---FILE: _common.R---
@@ -1,22 +0,0 @@
-set.seed(1015)
-
-options(
-  digits = 3,
-  dplyr.print_min = 6,
-  dplyr.print_max = 6
-)
-
-knitr::opts_chunk$set(
-  comment = ""#>"",
-  collapse = TRUE,
-  cache = TRUE,
-  out.width = ""70%"",
-  fig.align = ""center"",
-  fig.width = 6,
-  fig.asp = 0.618, # 1 / phi
-  fig.show = ""hold""
-)
-
-suppressMessages(
-  library(knitr)
-)",True,True,Rendering / Conversion,7
tidyverse,datascience-box,c7b90cd76c29d09e5a94400258d778d7e7a78438,Tyler George,82473808+stats-tgeorge@users.noreply.github.com,2022-06-14T03:41:49Z,GitHub,noreply@github.com,2022-06-14T03:41:49Z,"HW6 Fixes (#135)

* HW6 Fixes

* reformat

* k

Co-authored-by: Mine √áetinkaya-Rundel <cetinkaya.mine@gmail.com>",course-materials/hw-instructions/hw-06/data/pac-all.csv;course-materials/hw-instructions/hw-06/hw-06-money-in-politics.Rmd;course-materials/hw-instructions/hw-06/scripts/scrape-pac.R;course-materials/starters/hw/hw-06-money-in-politics/scrape-pac.R,True,False,True,False,752,504,1256,"---FILE: course-materials/hw-instructions/hw-06/hw-06-money-in-politics.Rmd---
@@ -29,7 +29,7 @@ They are also of interest to citizens who want to stay informed of how much mone
 In the United States, *""only American citizens (and immigrants with green cards) can contribute to federal politics, but the American divisions of foreign companies can form political action committees (PACs) and collect contributions from their American employees.""*[^hw-06-money-in-politics-1]
 
 In this assignment we will scrape and work with data foreign connected PACs that donate to US political campaigns.
-First, we will get data foreign connected PAC contributions in the 2020 election cycle.
+First, we will get data foreign connected PAC contributions in the 2022 election cycle.
 Then, you will use a similar approach to get data such contributions from previous years so that we can examine trends over time.
 
 In order to complete this assignment you will need a Chrome browser with the [Selector Gadget extension](http://selectorgadget.com/) installed.
@@ -88,7 +88,7 @@ Since that means repeating a task many times, let's first write a function that
 Confirm it works on a few others.
 Then iterate it over pages for all years.
 
-::: {.box}
+::: box
 Complete the following set of steps in the `scrape-pac.R` file in the `scripts` folder of your repository.
 This file already contains some starter code to help you out.
 :::
@@ -101,7 +101,7 @@ This file already contains some starter code to help you out.
     -   clean up the `Country of Origin/Parent Company` variable with `str_squish()`.
     -   add a new column to the data frame for `year`. We will want this information when we ultimately have data from all years, so this is a good time to keep track of it. Our function doesn't take a year argument, but the year is embedded in the URL, so we can extract it out of there, and add it as a new column. Use the `str_sub()` function to extract the last 4 characters from the URL. You will probably want to look at the help for this function to figure out how to specify ""last 4 characters"".
 
--   Define the URLs for 2020, 2018, and 1998 contributions.
+-   Define the URLs for 2022, 2020, and 2000 contributions.
     Then, test your function using these URLs as inputs.
     Does the function seem to do what you expected it to do?
 
@@ -115,7 +115,7 @@ This file already contains some starter code to help you out.
 
 <div>
 
-Complete the following set of steps in the `hw-05.Rmd` file in your repository.
+Complete the following set of steps in the `hw-06.Rmd` file in your repository.
 
 </div>
 

---FILE: course-materials/hw-instructions/hw-06/scripts/scrape-pac.R---
@@ -14,7 +14,7 @@ scrape_pac <- function(url) {
   # exract the table
   pac <-  page %>%
     # select node .DataTable (identified using the SelectorGadget)
-    html_node("".DataTable"") %>%
+    html_node("".DataTable-Partial"") %>%
     # parse table at node td into a data frame
     #   table has a head and empty cells should be filled with NAs
     html_table(""td"", header = ___, fill = ___) %>%
@@ -49,19 +49,19 @@ scrape_pac <- function(url) {
 
 # test function ----------------------------------------------------------------
 
+url_2022 <- ""___""
+pac_2022 <- scrape_pac(___)
+
 url_2020 <- ""___""
 pac_2020 <- scrape_pac(___)
 
-url_2018 <- ""___""
-pac_2018 <- scrape_pac(___)
-
-url_1998 <- ""___""
-pac_1998 <- scrape_pac(___)
+url_2000 <- ""___""
+pac_2000 <- scrape_pac(___)
 
 # list of urls -----------------------------------------------------------------
 
 # first part of url
-root <- ""https://www.opensecrets.org/political-action-committees-pacs/foreign-connected-pacs?cycle=""
+root <- ""https://www.opensecrets.org/political-action-committees-pacs/foreign-connected-pacs/""
 
 # second part of url (election years as a sequence)
 year <- seq(from = ___, to = ___, by = ___)
@@ -75,4 +75,4 @@ pac_all <- ___(___, ___)
 
 # write data -------------------------------------------------------------------
 
-write_csv(___, file = here::here(""data/pac-all.csv""))
+write_csv(___, file = here::here(""data/pac-all.csv""))
\ No newline at end of file

---FILE: course-materials/starters/hw/hw-06-money-in-politics/scrape-pac.R---
@@ -49,19 +49,19 @@ scrape_pac <- function(url) {
 
 # test function ----------------------------------------------------------------
 
+url_2022 <- ""___""
+pac_2022 <- scrape_pac(___)
+
 url_2020 <- ""___""
 pac_2020 <- scrape_pac(___)
 
-url_2018 <- ""___""
-pac_2018 <- scrape_pac(___)
-
-url_1998 <- ""___""
-pac_1998 <- scrape_pac(___)
+url_2000 <- ""___""
+pac_2000 <- scrape_pac(___)
 
 # list of urls -----------------------------------------------------------------
 
 # first part of url
-root <- ""https://www.opensecrets.org/political-action-committees-pacs/foreign-connected-pacs?cycle=""
+root <- ""https://www.opensecrets.org/political-action-committees-pacs/foreign-connected-pacs/""
 
 # second part of url (election years as a sequence)
 year <- seq(from = ___, to = ___, by = ___)
@@ -75,4 +75,4 @@ pac_all <- ___(___, ___)
 
 # write data -------------------------------------------------------------------
 
-write_csv(___, file = here::here(""data/pac-all.csv""))
+write_csv(___, file = here::here(""data/pac-all.csv""))
\ No newline at end of file",True,True,Implementation / Logic,6
tidyverse,datascience-box,97dacb1041165ce95a82b80cb4870d29a046d6b1,Debbie Yuster,dyuster@ramapo.edu,2021-11-08T01:09:32Z,GitHub,noreply@github.com,2021-11-08T01:09:32Z,"Fix typos (#129)

Corrected model name for consistency + fixed minor typo",course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.Rmd,True,False,True,False,2,2,4,"---FILE: course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.Rmd---
@@ -69,7 +69,7 @@ You can also find this information [here](https://www.openintro.org/data/index.p
 
 ## Multiple linear regression
 
-3.  Fit a linear model (one you have fit before): `score_bty_gender_fit`, predicting average professor evaluation `score` based on average beauty rating (`bty_avg`) and `gender`.
+3.  Fit a linear model (one you have fit before): `score_bty_gen_fit`, predicting average professor evaluation `score` based on average beauty rating (`bty_avg`) and `gender`.
     Write the linear model, and note the $R^2$ and the adjusted $R^2$.
 
 4.  Interpret the slopes and intercept of `score_bty_gen_fit` in context of the data.
@@ -83,7 +83,7 @@ You can also find this information [here](https://www.openintro.org/data/index.p
 8.  How does the relationship between beauty and evaluation score vary between male and female professors?
 
 9.  How do the adjusted $R^2$ values of `score_bty_gen_fit` and `score_bty_fit` compare?
-    What does this tell us about how useful `gender` is in explaining the variability in evaluation scores when we already have information on the beuaty score of the professor.
+    What does this tell us about how useful `gender` is in explaining the variability in evaluation scores when we already have information on the beauty score of the professor.
 
 10. Compare the slopes of `bty_avg` under the two models (`score_bty_fit` and `score_bty_gen_fit`).
     Has the addition of `gender` to the model changed the parameter estimate (slope) for `bty_avg`?",False,True,Implementation / Logic,6
tidyverse,datascience-box,eb39ba26572c07c0919a61660c03bdc34312d639,Kenneth C. Arnold,kenneth.arnold@gmail.com,2021-10-28T00:53:18Z,GitHub,noreply@github.com,2021-10-28T00:53:18Z,"Lab06: Incorrect column was converted to numeric (#128)

The corresponding slides are correct.

(This is a drive-by correction; this lab also needs to remove the `read_csv`s.",course-materials/lab-instructions/lab-06/lab-06-sad-plots.Rmd,True,False,True,False,1,1,2,"---FILE: course-materials/lab-instructions/lab-06/lab-06-sad-plots.Rmd---
@@ -106,7 +106,7 @@ pivot_longer(data, cols, names_to = ""name"")
 ```{r}
 staff_long <- staff %>%
   pivot_longer(cols = -faculty_type, names_to = ""year"") %>%
-  mutate(value = as.numeric(value))
+  mutate(year = as.numeric(year))
 ```
 
 Let's take a look at what the new longer data frame looks like.",False,True,Rendering / Conversion,3
tidyverse,datascience-box,1c0685d60ffbfaf6669e07972e6cb31cafe7c6fc,Debbie Yuster,dyuster@ramapo.edu,2021-09-30T14:35:01Z,GitHub,noreply@github.com,2021-09-30T14:35:01Z,Typo fixes (#127),course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.Rmd,True,False,True,False,12,13,25,"---FILE: course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.Rmd---
@@ -67,7 +67,6 @@ library(dsbox)
 The datasets we'll use are called `dennys` and `laquinta` from the **dsbox** package.
 Note that these data were scraped from [here](https://locations.dennys.com/) and [here](https://www.lq.com/en/findandbook/hotel-listings.html), respectively.
 
-The datasets we'll use are called `dennys` and `laquinta` from the **dsbox** package.
 Since the datasets are distributed with the package, we don't need to load them separately; they become available to us when we load the package.
 You can find out more about the datasets by inspecting their documentation, which you can access by running `?dennys` and `?laquinta` in the Console or using the Help menu in RStudio to search for `dennys` or `laquinta`.
 You can also find this information [here](https://rstudio-education.github.io/dsbox/reference/dennys.html) and [here](https://rstudio-education.github.io/dsbox/reference/laquinta.html).
@@ -105,7 +104,7 @@ We would like to limit our analysis to Denny's and La Quinta locations in the Un
     Don't worry about whether you know how to implement this, just brainstorm some ideas.
     Write down at least one as your answer, but you're welcomed to write down a few options too.
 
-We will determine whether or not the establishment has a location outside the US using the `state` variable in the `dn` and `lq` datasets.
+We will determine whether or not the establishment has a location outside the US using the `state` variable in the `dennys` and `laquinta` datasets.
 We know exactly which states are in the US, and we have this information in the `states` dataframe we loaded.
 
 5.  Find the Denny's locations that are outside the US, if any. To do so, filter the Denny's locations for observations where `state` is not in `states$abbreviation`. The code for this is given below. Note that the `%in%` operator matches the states listed in the `state` variable to those listed in `states$abbreviation`. The `!` operator means **not**. Are there any Denny's locations outside the US?
@@ -115,18 +114,18 @@ We know exactly which states are in the US, and we have this information in the
 ```
 
 ```{r}
-dn %>%
+dennys %>%
   filter(!(state %in% states$abbreviation))
 ```
 
-6.  Add a country variable to the Denny's dataset and set all observations equal to `""United States""`. Remember, you can use the `mutate` function for adding a variable. Make sure to save the result of this as `dn` again so that the stored data frame contains the new variable going forward.
+6.  Add a country variable to the Denny's dataset and set all observations equal to `""United States""`. Remember, you can use the `mutate` function for adding a variable. Make sure to save the result of this as `dennys` again so that the stored data frame contains the new variable going forward.
 
 ```{marginfigure}
 We don't need to tell R how many times to repeat the character string ""United States"" to fill in the data for all observations, R takes care of that automatically.
 ```
 
 ```{r}
-dn %>%
+dennys %>%
   mutate(country = ""United States"")
 ```
 
@@ -140,7 +139,7 @@ dn %>%
     Here is some starter code to get you going:
 
 ```{r eval = FALSE}
-lq %>%
+laquinta %>%
   mutate(country = case_when(
     state %in% state.abb     ~ ""United States"",
     state %in% c(""ON"", ""BC"") ~ ""Canada"",
@@ -156,22 +155,22 @@ All Denny's locations are in the United States, so we don't need to worry about
 However we do need to filter the La Quinta dataset for locations in United States.
 
 ```{r}
-lq <- lq %>%
+laquinta <- laquinta %>%
   filter(country == ""United States"")
 ```
 
 9.  Which states have the most and fewest Denny's locations? What about La Quinta? Is this surprising? Why or why not?
 
 Next, let's calculate which states have the most Denny's locations *per thousand square miles*.
-This requires *joinining* information from the frequency tables you created in Exercise 8 with information from the `states` data frame.
+This requires *joining* information from the frequency tables you created in Exercise 8 with information from the `states` data frame.
 
 First, we count how many observations are in each state, which will give us a data frame with two variables: `state` and `n`.
 Then, we join this data frame with the `states` data frame.
 However note that the variables in the `states` data frame that has the two-letter abbreviations is called `abbreviation`.
 So when we're joining the two data frames we specify that the `state` variable from the Denny's data should be matched `by` the `abbreviation` variable from the `states` data:
 
 ```{r}
-dn %>%
+dennys %>%
   count(state) %>%
   inner_join(states, by = c(""state"" = ""abbreviation""))
 ```
@@ -183,19 +182,19 @@ In the next exercise you will need to build on this pipe.
 
 Next, we put the two datasets together into a single data frame.
 However before we do so, we need to add an identifier variable.
-We'll call this `establishment` and set the value to `""Denny's""` and `""La Quinta""` for the `dn` and `lq` data frames, respectively.
+We'll call this `establishment` and set the value to `""Denny's""` and `""La Quinta""` for the `dennys` and `laquinta` data frames, respectively.
 
 ```{r}
-dn <- dn %>%
+dennys <- dennys %>%
   mutate(establishment = ""Denny's"")
-lq <- lq %>%
+laquinta <- laquinta %>%
   mutate(establishment = ""La Quinta"")
 ```
 
 Since the two data frames have the same columns, we can easily bind them with the `bind_rows` function:
 
 ```{r}
-dn_lq <- bind_rows(dn, lq)
+dn_lq <- bind_rows(dennys, laquinta)
 ```
 
 We can plot the locations of the two establishments using a scatter plot, and color the points by the establishment type.",False,True,Documentation / Formatting,4
tidyverse,datascience-box,6dcdc06782d63743bb7e5b5c6bbf29d80286c527,Debbie Yuster,dyuster@ramapo.edu,2021-09-09T12:34:13Z,GitHub,noreply@github.com,2021-09-09T12:34:13Z,Fix typo (#125),course-materials/starters/hw/hw-01-pet-names/hw-01.Rmd,True,False,True,False,1,1,2,"---FILE: course-materials/starters/hw/hw-01-pet-names/hw-01.Rmd---
@@ -45,4 +45,4 @@ Remove this text, and add your answer for Exercise 5 here.
 
 ### Exercise 6
 
-Remove this text, and add your answer for Exercise 5 here.
+Remove this text, and add your answer for Exercise 6 here.",False,True,Documentation / Formatting,4
tidyverse,datascience-box,1edfac57b766cba5029b10a0a260838cc752db33,Debbie Yuster,dyuster@ramapo.edu,2021-09-09T12:33:48Z,GitHub,noreply@github.com,2021-09-09T12:33:48Z,"Fix minor typos in HW 01 Pet names (#124)

* Fix typo

* Fix typos",course-materials/hw-instructions/hw-01/hw-01-pet-names.Rmd,True,False,True,False,5,5,10,"---FILE: course-materials/hw-instructions/hw-01/hw-01-pet-names.Rmd---
@@ -1,6 +1,6 @@
 ---
 title: ""HW 01 - Pet names""
-subtitle: ""Mett the toolkit""
+subtitle: ""Meet the toolkit""
 output: 
   tufte::tufte_html:
     css: ../hw.css
@@ -151,7 +151,7 @@ knitr::include_graphics(""img/yaml-raw-to-rendered.png"")
 
 Then Go to the **Git pane** in your RStudio.
 
-You should see that your Rmd (R Markdown) file and its output, your md file (Markdown), file are listed there as recently changed files.
+You should see that your Rmd (R Markdown) file and its output, your md file (Markdown), are listed there as recently changed files.
 
 Next, click on **Diff**.
 This will pop open a new window that shows you the **diff**erence between the last committed state of the document and its current state that includes your changes.
@@ -202,7 +202,7 @@ You should also load these packages in your Console, which you can do by sending
 knitr::include_graphics(""img/load-packages-chunk.png"")
 ```
 
-Note that these packages are also get loaded in your R Markdown environment when you **Knit** your R Markdown document.
+Note that these packages also get loaded in your R Markdown environment when you **Knit** your R Markdown document.
 
 # Data
 
@@ -233,12 +233,12 @@ You can find out more about the dataset by inspecting its documentation (which c
 
 2.  Again, according to the data dictionary, how many variables do we have for each pet?
 
-üß∂ ‚úÖ ‚¨ÜÔ∏è *Write your answer in your R Markdown document under Exercise 1, knit the document, commit your changes with a commit message that says ""Completed Exercise 2"", and push. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+üß∂ ‚úÖ ‚¨ÜÔ∏è *Write your answer in your R Markdown document under Exercise 2, knit the document, commit your changes with a commit message that says ""Completed Exercise 2"", and push. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
 
 3.  What are the three most common pet names in Seattle? To do this you will need to count the frequencies of each pet name and display the results in descending order of frequency so that you can easily see the top three most popular names. The following code does exactly that.
 
 ```{marginfigure}
-The two lines of code can be read as ""Start with the seattlepets data frame, and then count the animal_names, and display the results sorted in descending order. The ""and then"" in the previous sentence maps to %>%, the pipe operator, which takes what comes before it and plugs it in as the first argument of the function that comes after it.
+The two lines of code can be read as ""Start with the seattlepets data frame, and then count the animal_names, and display the results sorted in descending order. The 'and then' in the previous sentence maps to %>%, the pipe operator, which takes what comes before it and plugs it in as the first argument of the function that comes after it.""
 ```
 
 ```{r}",False,True,Documentation / Formatting,7
tidyverse,datascience-box,b040ef09c77a65e23801ffc0d1732aa809144443,Debbie Yuster,dyuster@ramapo.edu,2021-08-27T02:28:40Z,GitHub,noreply@github.com,2021-08-27T02:28:40Z,Fix link for IMS reading (#123),02-hello-world.Rmd,True,False,True,False,1,1,2,"---FILE: 02-hello-world.Rmd---
@@ -76,7 +76,7 @@ You can join the workspace and play around with the sample application exercises
 
 ::: {.reading}
 -   R4DS :: [Chp 2 - Introduction](https://r4ds.had.co.nz/explore-intro.html)
--   IMS :: [Sec 1.1 & 1.2 - Case study & Data basics](https://openintro-ims.netlify.app/getting-started-with-data.html#basic-stents-strokes)
+-   IMS :: [Sec 1.1 & 1.2 - Case study & Data basics](https://openintro-ims.netlify.app/data-hello.html)
 :::
 :::
 ",False,True,Documentation / Formatting,4
tidyverse,datascience-box,cf5c07f84338cc9ac9da2925b7959228cbb95bdc,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2021-08-20T01:49:13Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2021-08-20T01:49:13Z,Fix IMS links,02-exploring-data.Rmd;02-hello-world.Rmd;02-making-rigorous-conclusions.Rmd,True,False,True,False,10,12,22,"---FILE: 02-exploring-data.Rmd---
@@ -66,7 +66,7 @@ R4DS :: [Chp 3 - Data visualization](https://r4ds.had.co.nz/data-visualisation.h
 :::
 
 ::: {.reading}
-IMS :: [Sec 2.1 - Exploring numerical data](https://openintro-ims.netlify.app/summarizing-visualizing-data.html#numerical-data)
+IMS :: [Chp 4 - Exploring numerical data](https://openintro-ims.netlify.app/explore-numerical.html)
 :::
 :::
 
@@ -86,7 +86,7 @@ IMS :: [Sec 2.1 - Exploring numerical data](https://openintro-ims.netlify.app/su
 :::
 
 ::: {.reading}
-IMS :: [Sec 2.2 - Exploring categorical data](https://openintro-ims.netlify.app/summarizing-visualizing-data.html#categorical-data)
+IMS :: [Chp 5 - Exploring categorical data](https://openintro-ims.netlify.app/explore-categorical.html)
 :::
 :::
 
@@ -340,7 +340,7 @@ R4DS :: [Sec 16.1 - 16.3 - Dates and times](https://r4ds.had.co.nz/dates-and-tim
 :::
 
 ::: {.reading}
-IMS :: [Sec 2.3 - Effective data visualisation](https://openintro-ims.netlify.app/summarizing-visualizing-data.html#effective-data-visualization)
+IMS :: [Chp 6 - Applications: Explore](https://openintro-ims.netlify.app/explore-applications.html)
 :::
 :::
 
@@ -372,8 +372,7 @@ IMS :: [Sec 2.3 - Effective data visualisation](https://openintro-ims.netlify.ap
 :::
 
 ::: {.reading}
--   IMS :: [Sec 1.3 - Sampling principles and strategies](https://openintro-ims.netlify.app/getting-started-with-data.html#sampling-principles-strategies)
--   IMS :: [Sec 1.4 - Experiments](https://openintro-ims.netlify.app/getting-started-with-data.html#experiments)
+IMS :: [Chp 2 - Study design](https://openintro-ims.netlify.app/data-design.html)
 :::
 :::
 
@@ -440,7 +439,6 @@ R4DS :: [Chp 7 - Exploratory data analysis](https://r4ds.had.co.nz/exploratory-d
 
 ::: {.source}
 [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d19-top-250-imdb)
-
 :::
 
 ::: {.video}

---FILE: 02-hello-world.Rmd---
@@ -76,7 +76,7 @@ You can join the workspace and play around with the sample application exercises
 
 ::: {.reading}
 -   R4DS :: [Chp 2 - Introduction](https://r4ds.had.co.nz/explore-intro.html)
--   IMS :: [Sec 1.1 & 1.2 - Case study & Data basics](https://openintro-ims.netlify.app/getting-started-with-data.html#basic-stents-strokes)
+-   IMS :: [Chp 1 - Hello data](https://openintro-ims.netlify.app/data-hello.html)
 :::
 :::
 

---FILE: 02-making-rigorous-conclusions.Rmd---
@@ -45,7 +45,7 @@ You can join the workspace and play around with the sample application exercises
 :::
 
 ::: {.reading}
-IMS :: [Chp 3 - Introduction to linear models](https://openintro-ims.netlify.app/intro-linear-models.html)
+IMS :: [Chp 7 - Linear regression with a single predictor](https://openintro-ims.netlify.app/model-slr.html)
 :::
 :::
 
@@ -81,7 +81,7 @@ IMS :: [Chp 3 - Introduction to linear models](https://openintro-ims.netlify.app
 :::
 
 ::: {.reading}
-IMS :: [Sec 4.1 - Regression with multiple predictors](https://openintro-ims.netlify.app/multi-logistic-models.html#regression-multiple-predictors)
+IMS :: [Chp 8 - Linear regression with multiple predictors](https://openintro-ims.netlify.app/model-mlr.html)
 :::
 :::
 
@@ -119,7 +119,7 @@ IMS :: [Sec 4.1 - Regression with multiple predictors](https://openintro-ims.net
 :::
 
 ::: {.reading}
-IMS :: [Sec 4.5 - Logistic regression](https://openintro-ims.netlify.app/multi-logistic-models.html#logistic-regression)
+IMS :: [Chp 9 - Logistic regression](https://openintro-ims.netlify.app/model-logistic.html)
 :::
 :::
 
@@ -243,7 +243,7 @@ tidymodels :: [Evaluate your model with resampling](https://www.tidymodels.org/s
 :::
 
 ::: {.reading}
-IMS :: [Sec 5.2 - Bootstrap confidence intervals](https://openintro-ims.netlify.app/intro-stat-inference.html#boot-ci)
+IMS :: [Chp 12 - Confidence intervals with bootstrapping](https://openintro-ims.netlify.app/foundations-bootstrapping.html)
 :::
 :::
 
@@ -259,7 +259,7 @@ IMS :: [Sec 5.2 - Bootstrap confidence intervals](https://openintro-ims.netlify.
 :::
 
 ::: {.reading}
-[IMS :: Sec 5.1 - Randomization tests](https://openintro-ims.netlify.app/intro-stat-inference.html#inf-rand)
+[IMS :: Chp 11 - Hypothesis testing with randomization](https://openintro-ims.netlify.app/foundations-randomization.html)
 :::
 :::
 ",False,True,Rendering / Conversion,3
tidyverse,datascience-box,c9783eeca948ac707fe1c7f43dba16019d503f8a,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2021-08-20T01:42:28Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2021-08-20T01:42:28Z,Fix edit link,_output.yml,True,False,True,False,1,1,2,"---FILE: _output.yml---
@@ -14,5 +14,5 @@ bookdown::gitbook:
       after: |
         <li><a href=""https://github.com/rstudio/bookdown"" target=""blank"">Published with bookdown</a></li>
     edit:
-      link: https://github.com/openintrostat/ims/edit/master/%s
+      link: https://github.com/rstudio-education/datascience-box/edit/master/%s
       text: ""Edit""",False,True,Rendering / Conversion,3
tidyverse,datascience-box,9698599e2fdfcba47af78833eff60a2d702c04fc,Botond Barabas,bboti86@gmail.com,2021-05-18T00:00:59Z,GitHub,noreply@github.com,2021-05-18T00:00:59Z,"Fixed the code (#118)

Scores have been saved into the scores variable but the tibble was build from a ratings variable which does not exist",course-materials/application-exercises/ae-08-imdb-webscraping/03-imdb-250movies-complete.R,False,True,True,False,1,1,2,"---FILE: course-materials/application-exercises/ae-08-imdb-webscraping/03-imdb-250movies-complete.R---
@@ -35,7 +35,7 @@ scores <- page %>%
 
 imdb_top_250 <- tibble(
   title = titles,
-  rating = ratings,
+  rating = scores,
   year = years
 )
 ",True,False,Implementation / Logic,3
tidyverse,datascience-box,93db83494e60604816fd51b327e3c23a1813d1a0,Naomi Alterman,ohnoleo@gmail.com,2021-04-26T21:01:49Z,GitHub,noreply@github.com,2021-04-26T21:01:49Z,"Fix mismatched lecture video link (#117)

Co-authored-by: nacl <uhohnaomi@gmail.com>",02-ethics.Rmd,True,False,True,False,1,1,2,"---FILE: 02-ethics.Rmd---
@@ -65,7 +65,7 @@ Course lectures are supplemented with ""guest lectures"" from domain experts.
 :::
 
 ::: {.video}
-[Video](https://youtu.be/c4fvdoNbcSw)
+[Video](https://youtu.be/E2eD72pwtps)
 :::
 :::
 ",False,True,Documentation / Formatting,4
tidyverse,datascience-box,3e4e966e32f45887d2031570481427827af04cc5,Vincent Cannataro,cannatarov@emmanuel.edu,2021-02-22T23:10:30Z,GitHub,noreply@github.com,2021-02-22T23:10:30Z,fixed html widget issue (#111),course-materials/slides/u2-d10-data-types/u2-d10-data-types.Rmd;course-materials/slides/u2-d11-text-analysis/u2-d11-text-analysis.Rmd;course-materials/slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.Rmd,True,False,True,False,3,0,3,"---FILE: course-materials/slides/u2-d10-data-types/u2-d10-data-types.Rmd---
@@ -86,6 +86,7 @@ glimpse(cat_lovers)
 
 .small[
 ```{r echo=FALSE}
+options(htmltools.preserve.raw = FALSE)
 cat_lovers %>%
   datatable()
 ```

---FILE: course-materials/slides/u2-d11-text-analysis/u2-d11-text-analysis.Rmd---
@@ -296,6 +296,7 @@ sheeran <- artist_albums %>%
 
 .small[
 ```{r echo=FALSE}
+options(htmltools.preserve.raw = FALSE)
 sheeran %>%
   distinct(album, track_title) %>%
   datatable(options = list(dom = ""p""))

---FILE: course-materials/slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.Rmd---
@@ -428,6 +428,7 @@ imdb_top_250
 ---
 
 ```{r echo=FALSE}
+options(htmltools.preserve.raw = FALSE)
 imdb_top_250 %>% datatable(options(list(dom = ""p"", pageLength = 8)), height = 400)
 ```
 ",False,True,Rendering / Conversion,4
tidyverse,datascience-box,71f62634867428d4795ae76813cb3dc7f5d49017,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2021-02-15T10:06:50Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2021-02-15T10:06:50Z,Fix between chapter links,03-version-control.Rmd,True,False,True,False,2,2,4,"---FILE: 03-version-control.Rmd---
@@ -8,7 +8,7 @@ This is best accomplished with a distributed version control system like Git
 This course adopts a top down approach to teaching Git -- students are *required* to use it for *all* assignments.
 These type of tools tend to suffer from delayed gratification as when they are first introduced students view them as a clunky addition to their workflow and it is not until weeks or even months later that they experience the value first hand.
 
-If this section doesn't convince you that you should be using Git and GitHub in your data science course, the section on [alternative setups][alternative_setups] describes how to leverage RStudio Cloud features for assignment dissemination, collection, and providing feedback.
+If this section doesn't convince you that you should be using Git and GitHub in your data science course, Chapter \@ref(alternative-setups) describes how to leverage RStudio Cloud features for assignment dissemination, collection, and providing feedback.
 You can also use your own institution's learning management system for this purpose as well.
 
 ## Git
@@ -54,7 +54,7 @@ In order to comply with Family Educational Rights and Privacy Act (FERPA) requir
 
 Setup and management for larger classes can be challenging due to the sheer number of components, however most actions can be scripted via the GitHub API which can dramatically reduce the course administrative workload.
 Two solutions to this problem are (1) GitHub Classroom and (2) ghclass.
-Use of ghclass, an R package for GitHub classroom tools is detailed below, and use of GitHub classroom is described in the [alternative setups][alternative_setups] section.
+Use of ghclass, an R package for GitHub classroom tools is detailed below, and use of GitHub classroom is described in Chapter \@ref(alternative-setups).
 
 ## ghclass
 ",False,True,Rendering / Conversion,3
tidyverse,datascience-box,1f9cdf4b4e0fdeddcc06152444f8bc0438239019,Silvia Canel√≥n,49913337+spcanelon@users.noreply.github.com,2021-01-13T10:04:10Z,GitHub,noreply@github.com,2021-01-13T10:04:10Z,"Fix links for slides and source in Deck 19 (#108)

Current links point to Deck 18 material instead of Deck 19",02-exploring-data.Rmd,True,False,True,False,3,2,5,"---FILE: 02-exploring-data.Rmd---
@@ -435,11 +435,12 @@ R4DS :: [Chp 7 - Exploratory data analysis](https://r4ds.had.co.nz/exploratory-d
 **Unit 2 - Deck 19: Scraping top 250 movies on IMDB**
 
 ::: {.slides}
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d18-web-scrape/u2-d18-web-scrape.html#1)
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#1)
 :::
 
 ::: {.source}
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d18-web-scrape)
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d19-top-250-imdb)
+
 :::
 
 ::: {.video}",False,True,Rendering / Conversion,3
tidyverse,datascience-box,8e5e9f38c2a6dde7afe93ab4a3ccfe9c43bf6fc4,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2021-01-07T21:42:35Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2021-01-07T21:42:35Z,Fix typo,index.Rmd,True,False,True,False,1,1,2,"---FILE: index.Rmd---
@@ -38,7 +38,7 @@ By contributing to this project, you agree to abide by its terms.
 
 ## License {.unnumbered}
 
-<a rel=""license"" href=""https://creativecommons.org/licenses/by-sa/4.0/""><img src=""https://licensebuttons.net/l/by-sa/4.0/88x31.png"" alt=""Creative Commons License"" style=""border-width:0""/></a><br />This online work is licensed under a <a rel=""license"" href=""https://creativecommons.org/licenses/by-sa/4.0/"">Creative Commons Attribution-ShareAlike 4.0 Internationale</a>.
+<a rel=""license"" href=""https://creativecommons.org/licenses/by-sa/4.0/""><img src=""https://licensebuttons.net/l/by-sa/4.0/88x31.png"" alt=""Creative Commons License"" style=""border-width:0""/></a><br />This online work is licensed under a <a rel=""license"" href=""https://creativecommons.org/licenses/by-sa/4.0/"">Creative Commons Attribution-ShareAlike 4.0 International</a>.
 Visit [here](https://github.com/rstudio-education/datascience-box/blob/master/LICENSE.md) for more information about the license.
 
 ## Acknowledements {.unnumbered}",False,True,Implementation / Logic,6
tidyverse,datascience-box,aeb8987ead8189fd9846304eef68303c02752a45,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-12-28T17:28:59Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-12-28T17:28:59Z,Fix links to AEs,02-exploring-data.Rmd;02-hello-world.Rmd;02-making-rigorous-conclusions.Rmd,True,False,True,False,18,10,28,"---FILE: 02-exploring-data.Rmd---
@@ -94,7 +94,7 @@ IMS :: [Sec 2.2 - Exploring categorical data](https://openintro-ims.netlify.app/
 **StarWars + Dataviz**
 
 ::: {.source}
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-03-starwars-dataviz/ae-03-starwars-dataviz.Rmd)
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-03-starwars-dataviz/starwars.Rmd)
 :::
 
 ::: {.video}
@@ -204,7 +204,7 @@ R4DS :: [Chp 12 - Tidy data](https://r4ds.had.co.nz/tidy-data.html)
 **Hotels + Data wrangling**
 
 ::: {.source}
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-04-hotels-datawrangling/ae-04-hotels-datawrangling.Rmd)
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.Rmd)
 :::
 
 ::: {.video}
@@ -294,7 +294,11 @@ R4DS :: [Sec 16.1 - 16.3 - Dates and times](https://r4ds.had.co.nz/dates-and-tim
 **Hotels + Data types**
 
 ::: {.source}
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-05-hotels-datatypes/ae-05-hotels-datatypes.Rmd)
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-05-hotels-datatypes/hotels-forcats.Rmd)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-05-hotels-datatypes/type-coercion.Rmd)
 :::
 
 ::: {.video}
@@ -306,7 +310,11 @@ R4DS :: [Sec 16.1 - 16.3 - Dates and times](https://r4ds.had.co.nz/dates-and-tim
 **Nobels + Sales + Data import**
 
 ::: {.source}
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-06-nobels-sales-dataimport/ae-06-nobels-sales-dataimport.Rmd)
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-06-nobels-sales-dataimport/nobels-csv.Rmd)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-06-nobels-sales-dataimport/sales-excel.Rmd)
 :::
 
 ::: {.video}
@@ -340,7 +348,7 @@ IMS :: [Sec 2.3 - Effective data visualisation](https://openintro-ims.netlify.ap
 **Brexit + Telling stories with dataviz**
 
 ::: {.source}
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-07-brexit-story-dataviz/ae-07-brexit-story-dataviz.Rmd)
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-07-brexit-story-dataviz/brexit.Rmd)
 :::
 
 ::: {.video}
@@ -459,7 +467,7 @@ R4DS :: [Chp 7 - Exploratory data analysis](https://r4ds.had.co.nz/exploratory-d
 **IMDB + Web scraping**
 
 ::: {.source}
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-08-imdb-webscraping/ae-08-imdb-webscraping.Rmd)
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-08-imdb-webscraping)
 :::
 
 ::: {.video}

---FILE: 02-hello-world.Rmd---
@@ -45,7 +45,7 @@ You can join the workspace and play around with the sample application exercises
 > **Option 1 - UN Votes**
 >
 > ::: {.source}
-> [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-01a-un-votes/ae-01a-un-votes.Rmd)
+> [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-01a-un-votes/unvotes.Rmd)
 > :::
 >
 > ::: {.video}
@@ -84,7 +84,7 @@ You can join the workspace and play around with the sample application exercises
 **Bechdel + R Markdown**
 
 ::: {.source}
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-02-bechdel-rmarkdown/ae-02-bechdel-rmarkdown.Rmd)
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.Rmd)
 :::
 :::
 

---FILE: 02-making-rigorous-conclusions.Rmd---
@@ -189,7 +189,7 @@ tidymodels :: [Evaluate your model with resampling](https://www.tidymodels.org/s
 **The Office + Feature engineering, Pt. 1**
 
 ::: {.source}
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-09-feat-eng-cv/ae-09-feat-eng-cv.Rmd)
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.Rmd)
 :::
 
 ::: {.video}
@@ -201,7 +201,7 @@ tidymodels :: [Evaluate your model with resampling](https://www.tidymodels.org/s
 **The Office + Cross validation, Pt. 2**
 
 ::: {.source}
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-09-feat-eng-cv/ae-09-feat-eng-cv.Rmd)
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.Rmd)
 :::
 
 ::: {.video}",False,True,Rendering / Conversion,3
tidyverse,datascience-box,9a0ddaaa017a292b9281ddab208502e35f7e3603,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-12-28T15:39:07Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-12-28T15:39:07Z,Fix underscores to dashes,02-hello-world.Rmd,True,False,True,False,2,2,4,"---FILE: 02-hello-world.Rmd---
@@ -27,11 +27,11 @@ You can join the workspace and play around with the sample application exercises
 **Unit 1 - Deck 1: Welcome**
 
 ::: {.slides}
-[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u1_d01-welcome/u1_d01-welcome.html#1)
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u1-d01-welcome/u1-d01-welcome.html#1)
 :::
 
 ::: {.source}
-[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u1_d01-welcome)
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u1-d01-welcome)
 :::
 
 ::: {.video}",False,True,Rendering / Conversion,3
tidyverse,datascience-box,03ff98c50b61a931d5d9e945b3c8bb6f4a3509f7,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-12-24T20:54:21Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-12-24T20:54:21Z,Fix link to repo,_output.yml,True,False,True,False,1,1,2,"---FILE: _output.yml---
@@ -2,7 +2,7 @@ bookdown::bs4_book:
   css: [css/dsbox.css, css/fontawesome/css/all.css]
   theme:
     primary: ""#1E5C65""
-  repo: https://github.com/rstudio-education/datasciencebox/
+  repo: https://github.com/rstudio-education/datascience-box/
 
 bookdown::gitbook:
   css: [css/style.css, css/dsbox.css, css/fontawesome/css/all.css]",False,True,Rendering / Conversion,3
tidyverse,datascience-box,709242f5aa13cd5c9a5f212bf171cfb730cfac2c,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-12-24T13:38:22Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-12-24T13:38:22Z,Fix action,.github/workflows/build-book.yaml;index.Rmd,True,False,True,False,1,3,4,"---FILE: .github/workflows/build-book.yaml---
@@ -48,8 +48,6 @@ jobs:
          bookdown::render_book(""index.Rmd"", quiet = TRUE)
         shell: Rscript {0}
         
-        run: Rscript -e ''
-
       - name: Install npm
         uses: actions/setup-node@v1
 

---FILE: index.Rmd---
@@ -4,10 +4,10 @@ title: ""Data Science in a Box""
 author: ""Mine √áetinkaya-Rundel""
 description: ""Data Science in a Box contains the materials required to teach (or learn from) the course described above, all of which are freely-available and open-source.""
 date: ""`r Sys.Date()`""
-url: 'https\://datasciencebox.org/'
 github-repo: rstudio-education/datasciencebox
 twitter-handle: minebocek
 cover-image: dsbox.png
+url: 'https\://datasciencebox.org/'
 site: bookdown::bookdown_site
 documentclass: book
 link-citations: yes",False,True,Rendering / Conversion,6
tidyverse,datascience-box,038b9c3fc32e9e537985c1a75271c1e41b446df5,Mine Cetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-12-23T22:59:46Z,GitHub,noreply@github.com,2020-12-23T22:59:46Z,"Version 2 - post Fall 2020 update (#105)

* Update topic flow for 4 units

* Split topic flow into 5 units and update diagram

* Welcome -> hello world

* Fix colors

* Update content for v2

* Add new chapter

* Visual editor update

* Add fontawesome css

* Add new divs for slide decks

* New slide style and setup

* AE update and output change

* New Unit 1 slides

* Remove old slides

* Update all remaining AEs

* Remove html output and rerender

* Ignore word documents

* Update project instructions and repo structure

* Update project instructions and repo structure

* Don't need this here

* Update css

* Tables with viz editor

* Move meet the toolkit to Unit 1

* Add missing AE

* Change border color of AEs

* New dataviz and wrangle materials

* Update labs, mostly simplify instructions

* Update lab CSS

* Remove old explore data slides

* New explore data slides

* Explore data materials, except HW

* Update and streamline HW 1-5

* Update formatting

* Line breaks for visual editor

* This is not here anymore...

* New assignment

* Fall 2020 update of HW assignments

* Rename folder

* Remove exercise on backwards selection

* Tables

* Ok...

* Rename folder

* ignore .Rapp.history

* Updated 11-week schedule

* Update and streamline HW instructions, hopefully for the last time

* Last pass at HW starters, hopefully...

* Updated and streamlined lab instructions

* References at the end

* Rename a couple assignments

* Rename file

* Update starters for all labs

* Add 15-week schedule

* Correct lecture title

* Add ethics unit

* Guest lecture + assignment divs

* Fix title

* Fix divs for assignments

* Something is happening with these tables

* Modeling and inference unit materials

* Rename unit

* Now the lines are back

* Updated Unit 5 materials and landing page

* Update with new data

* Add README with RStudio Cloud link

* Streamline how RStudio Cloud is displayed on course materials

* Don't need a separate videos link

* Specifically call out videos

* Add more files to renvignore

* Omit files with fill in the blanks in them

* More packages...

* Align project descriptions

* Update a few references

* Update RStudio cloud info and some screenshots

* Update discussions discussion...",.gitignore;.renvignore;01-topics.Rmd;02-ethics.Rmd;02-exploring-data.Rmd;02-hello-world.Rmd;02-looking-forward.Rmd;02-looking-further.Rmd;02-making-rigorous-conclusions.Rmd;02-project.Rmd;02-videos.Rmd;03-access-r.Rmd;03-discussion.Rmd;03-version-control.Rmd;04-pedagogy.Rmd;04-schedule.Rmd;_bookdown.yml;_output.yml;course-materials/application-exercises/README.md;course-materials/application-exercises/ae-01a-un-votes/unvotes.Rmd;course-materials/application-exercises/ae-01a-un-votes/unvotes.html;course-materials/application-exercises/ae-01a-un-votes/unvotes.md;course-materials/application-exercises/ae-01a-un-votes/unvotes_files/figure-gfm/list-countries-1.png;course-materials/application-exercises/ae-01a-un-votes/unvotes_files/figure-gfm/plot-yearly-yes-issue-1.png;course-materials/application-exercises/ae-01b-covid/covid.Rmd;course-materials/application-exercises/ae-01b-covid/covid.html;course-materials/application-exercises/ae-01b-covid/covid.md;course-materials/application-exercises/ae-01b-covid/covid_files/figure-gfm/list-countries-1.png;course-materials/application-exercises/ae-01b-covid/covid_files/figure-gfm/visualise-1.png;course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.Rmd;course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.html;course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.md;course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel_files/figure-gfm/unnamed-chunk-6-1.png;course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel_files/figure-gfm/unnamed-chunk-8-1.png;course-materials/application-exercises/ae-03-starwars-dataviz/starwars.Rmd;course-materials/application-exercises/ae-03-starwars-dataviz/starwars.html;course-materials/application-exercises/ae-03-starwars-dataviz/starwars.md;course-materials/application-exercises/ae-03-starwars-dataviz/starwars_files/figure-gfm/scatterplot-1.png;course-materials/application-exercises/ae-03-starwars-dataviz/starwars_files/figure-gfm/scatterplot-labels-1.png;course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.Rmd;course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.html;course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.md;course-materials/application-exercises/ae-05-fisheries-datajoins/data/continents.csv;course-materials/application-exercises/ae-05-fisheries-datajoins/data/fisheries.csv;course-materials/application-exercises/ae-05-fisheries-datajoins/fisheries.Rmd;course-materials/application-exercises/ae-05-fisheries-datajoins/fisheries.html;course-materials/application-exercises/ae-05-hotels-datatypes/hotels-forcats.Rmd;course-materials/application-exercises/ae-05-hotels-datatypes/hotels-forcats.md;course-materials/application-exercises/ae-05-hotels-datatypes/hotels-forcats_files/figure-gfm/plot-1.png;course-materials/application-exercises/ae-05-hotels-datatypes/type-coercion.Rmd;course-materials/application-exercises/ae-05-hotels-datatypes/type-coercion.md;course-materials/application-exercises/ae-06-hotels-datatypes/hotels-forcats.Rmd;course-materials/application-exercises/ae-06-hotels-datatypes/hotels-forcats.html;course-materials/application-exercises/ae-06-hotels-datatypes/type-coercion.Rmd;course-materials/application-exercises/ae-06-hotels-datatypes/type-coercion.html;course-materials/application-exercises/ae-06-nobels-sales-dataimport/data-raw/nobel.csv;course-materials/application-exercises/ae-06-nobels-sales-dataimport/data-raw/sales.xlsx;course-materials/application-exercises/ae-06-nobels-sales-dataimport/images/sales-1.png;course-materials/application-exercises/ae-06-nobels-sales-dataimport/images/sales-2.png;course-materials/application-exercises/ae-06-nobels-sales-dataimport/nobels-csv.Rmd;course-materials/application-exercises/ae-06-nobels-sales-dataimport/nobels-csv.md;course-materials/application-exercises/ae-06-nobels-sales-dataimport/sales-excel.Rmd;course-materials/application-exercises/ae-06-nobels-sales-dataimport/sales-excel.md;course-materials/application-exercises/ae-07-brexit-story-dataviz/brexit.Rmd;course-materials/application-exercises/ae-07-brexit-story-dataviz/brexit.md;course-materials/application-exercises/ae-07-brexit-story-dataviz/brexit_files/figure-gfm/unnamed-chunk-2-1.png;course-materials/application-exercises/ae-07-brexit-story-dataviz/brexit_files/figure-gfm/unnamed-chunk-3-1.png;course-materials/application-exercises/ae-07-brexit-story-dataviz/data/brexit.csv;course-materials/application-exercises/ae-07-nobels-sales-dataimport/food-excel.Rmd;course-materials/application-exercises/ae-07-nobels-sales-dataimport/food-excel.html;course-materials/application-exercises/ae-07-nobels-sales-dataimport/nobels-csv.html;course-materials/application-exercises/ae-07-nobels-sales-dataimport/sales-excel.Rmd;course-materials/application-exercises/ae-07-nobels-sales-dataimport/sales-excel.html;course-materials/application-exercises/ae-08-imdb-webscraping/01-imdb-250movies.R;course-materials/application-exercises/ae-08-imdb-webscraping/02-imdb-tvshows.R;course-materials/application-exercises/ae-08-imdb-webscraping/03-imdb-250movies-complete.R;course-materials/application-exercises/ae-08-imdb-webscraping/04-imdb-tvshows-complete.R;course-materials/application-exercises/ae-09-feat-eng-cv/theoffice-solution.Rmd;course-materials/application-exercises/ae-09-feat-eng-cv/theoffice-solution.md;course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.Rmd;course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.md;course-materials/application-exercises/ae-09-uoeart-functions/01-individual-pieces.R;course-materials/application-exercises/ae-09-uoeart-functions/02-functionalize.R;course-materials/application-exercises/ae-09-uoeart-functions/03-iterate.R;course-materials/application-exercises/ae-09-uoeart-functions/data/uoe-art.csv;course-materials/exams/exam-01/exam-01.html;course-materials/exams/exam-01/exam-01.md;course-materials/exams/exam-02/exam-02.html;course-materials/exams/exam-02/exam-02.md;course-materials/hw-instructions/hw-01/hw-01-airbnb-edi.Rmd;course-materials/hw-instructions/hw-01/hw-01-airbnb-edi.html;course-materials/hw-instructions/hw-01/hw-01-pet-names.Rmd;course-materials/hw-instructions/hw-01/hw-01-pet-names.html;course-materials/hw-instructions/hw-01/img/clone-repo-link.png;course-materials/hw-instructions/hw-01/img/course-workspace.png;course-materials/hw-instructions/hw-01/img/jovana-askrabic-XYIQXLH_v0o-unsplash.jpg;course-materials/hw-instructions/hw-01/img/load-packages-chunk.png;course-materials/hw-instructions/hw-01/img/new-project-from-git.png;course-materials/hw-instructions/hw-01/img/ready-to-push.png;course-materials/hw-instructions/hw-01/img/rstudio-anatomy.png;course-materials/hw-instructions/hw-01/img/rstudio-cloud-space.png;course-materials/hw-instructions/hw-01/img/update-author-name-commit.png;course-materials/hw-instructions/hw-01/img/view-data.png;course-materials/hw-instructions/hw-01/img/yaml-raw-to-rendered.png;course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.Rmd;course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html;course-materials/hw-instructions/hw-02/hw-02-bike-crash.Rmd;course-materials/hw-instructions/hw-02/hw-02-bike-crash.html;course-materials/hw-instructions/hw-02/img/bike.jpg;course-materials/hw-instructions/hw-02/img/madeleine-kohler-90Qn643Pq9c-unsplash.jpg;course-materials/hw-instructions/hw-03/hw-03-accidents.Rmd;course-materials/hw-instructions/hw-03/hw-03-accidents.html;course-materials/hw-instructions/hw-03/hw-03-college-majors.Rmd;course-materials/hw-instructions/hw-03/hw-03-college-majors.html;course-materials/hw-instructions/hw-03/img/accident.jpg;course-materials/hw-instructions/hw-04/hw-04-college-majors.Rmd;course-materials/hw-instructions/hw-04/hw-04-college-majors.html;course-materials/hw-instructions/hw-04/hw-04-legos-instructors.Rmd;course-materials/hw-instructions/hw-04/hw-04-legos-instructors.html;course-materials/hw-instructions/hw-04/img/graduate.jpg;course-materials/hw-instructions/hw-04/img/instructors.png;course-materials/hw-instructions/hw-05/data/pac-1998.csv;course-materials/hw-instructions/hw-05/data/pac-2018.csv;course-materials/hw-instructions/hw-05/data/pac-2020-fn.csv;course-materials/hw-instructions/hw-05/data/pac-2020.csv;course-materials/hw-instructions/hw-05/data/pac-all-clean.csv;course-materials/hw-instructions/hw-05/hw-05-legos.Rmd;course-materials/hw-instructions/hw-05/hw-05-legos.html;course-materials/hw-instructions/hw-05/hw-05-money-in-politics.Rmd;course-materials/hw-instructions/hw-05/hw-05-money-in-politics.html;course-materials/hw-instructions/hw-05/img/daniel-cheung-ZqqlOZyGG7g-unsplash.jpg;course-materials/hw-instructions/hw-05/scripts/01-scrape-pac-2020.R;course-materials/hw-instructions/hw-05/scripts/02-scrape-pac-function.R;course-materials/hw-instructions/hw-05/scripts/03-scrape-pac-all.R;course-materials/hw-instructions/hw-06/data/pac-all.csv;course-materials/hw-instructions/hw-06/hw-06-bike-rentals-dc.Rmd;course-materials/hw-instructions/hw-06/hw-06-bike-rentals-dc.html;course-materials/hw-instructions/hw-06/hw-06-money-in-politics.Rmd;course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html;course-materials/hw-instructions/hw-06/img/functionalize.png;course-materials/hw-instructions/hw-06/img/opensecrets.png;course-materials/hw-instructions/hw-06/img/pac_2020.png;course-materials/hw-instructions/hw-06/img/sharon-mccutcheon-rItGZ4vquWk-unsplash.jpg;course-materials/hw-instructions/hw-06/img/viktor-kern-UdGEXZtlx-E-unsplash.jpg;course-materials/hw-instructions/hw-06/scripts/scrape-pac.R;course-materials/hw-instructions/hw-07/data/bikeshare-day.csv;course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.Rmd;course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html;course-materials/hw-instructions/hw-07/hw-07-exploring-gss.Rmd;course-materials/hw-instructions/hw-07/hw-07-exploring-gss.html;course-materials/hw-instructions/hw-07/img/benny-jackson-222664-unsplash.jpg;course-materials/hw-instructions/hw-07/img/viktor-kern-UdGEXZtlx-E-unsplash.jpg;course-materials/hw-instructions/hw-08/hw-08-exploring-gss.Rmd;course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html;course-materials/hw-instructions/hw-08/hw-08-wrap-up.Rmd;course-materials/hw-instructions/hw-08/hw-08-wrap-up.html;course-materials/hw-instructions/hw-08/img/mauro-mora-31-pOduwZGE-unsplash.jpg;course-materials/hw-instructions/hw-09/hw-09-modeling-gss.Rmd;course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html;course-materials/hw-instructions/hw-09/img/mauro-mora-31-pOduwZGE-unsplash.jpg;course-materials/hw-instructions/hw-10/hw-10-wrap-up.Rmd;course-materials/hw-instructions/hw-10/hw-10-wrap-up.html;course-materials/hw-instructions/hw-10/img/kari-shea-VfWkdMue5Jc-unsplash.jpg;course-materials/lab-instructions/lab-01/img/github-auth-1.png;course-materials/lab-instructions/lab-01/img/github-auth-2.png;course-materials/lab-instructions/lab-01/img/github-auth-3.png;course-materials/lab-instructions/lab-01/img/github-auth-4.png;course-materials/lab-instructions/lab-01/img/github-auth-5.png;course-materials/lab-instructions/lab-01/img/github-auth-6.png;course-materials/lab-instructions/lab-01/img/untitled-project.png;course-materials/lab-instructions/lab-01/lab-01-hello-r.Rmd;course-materials/lab-instructions/lab-01/lab-01-hello-r.html;course-materials/lab-instructions/lab-02/img/repo-begin.png;course-materials/lab-instructions/lab-02/img/repo-end.png;course-materials/lab-instructions/lab-02/lab-02-plastic-waste.Rmd;course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html;course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.Rmd;course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html;course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.Rmd;course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html;course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.Rmd;course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html;course-materials/lab-instructions/lab-06/lab-06-sad-plots.Rmd;course-materials/lab-instructions/lab-06/lab-06-sad-plots.html;course-materials/lab-instructions/lab-06/lab-06-ugly-charts.Rmd;course-materials/lab-instructions/lab-06/lab-06-ugly-charts.html;course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.Rmd;course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.html;course-materials/lab-instructions/lab-08/lab-08-uoe-art.Rmd;course-materials/lab-instructions/lab-08/lab-08-uoe-art.html;course-materials/lab-instructions/lab-09/img/masks-v-nomasks.png;course-materials/lab-instructions/lab-09/lab-09-better-viz.Rmd;course-materials/lab-instructions/lab-09/lab-09-better-viz.html;course-materials/lab-instructions/lab-09/lab-09-modelling-course-evals.Rmd;course-materials/lab-instructions/lab-09/lab-09-modelling-course-evals.html;course-materials/lab-instructions/lab-10/img/data-upload.png;course-materials/lab-instructions/lab-10/lab-10-mlr-course-evals.Rmd;course-materials/lab-instructions/lab-10/lab-10-mlr-course-evals.html;course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.Rmd;course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html;course-materials/lab-instructions/lab-11/lab-11-inference-smoking.Rmd;course-materials/lab-instructions/lab-11/lab-11-inference-smoking.html;course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.Rmd;course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html;course-materials/lab-instructions/lab-12/lab-12-inference-smoking.Rmd;course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html;course-materials/lab-instructions/lab-12/lab-12-work-on-projects.Rmd;course-materials/lab-instructions/lab-12/lab-12-work-on-projects.html;course-materials/lab-instructions/lab-13/lab-13-collaborating-on-github.Rmd;course-materials/lab-instructions/lab-13/lab-13-collaborating-on-github.html;course-materials/lab-instructions/lab-13/lab-13-work-on-projects.Rmd;course-materials/lab-instructions/lab-13/lab-13-work-on-projects.html;course-materials/lab-instructions/lab-14/img/practice-issue-assign.png;course-materials/lab-instructions/lab-14/img/practice-issue-check.png;course-materials/lab-instructions/lab-14/img/practice-issue-close.png;course-materials/lab-instructions/lab-14/img/practice-issue-commit.png;course-materials/lab-instructions/lab-14/img/practice-issue-create.png;course-materials/lab-instructions/lab-14/img/practice-issue-number.png;course-materials/lab-instructions/lab-14/img/practice-issue-progress.png;course-materials/lab-instructions/lab-14/img/project-description.png;course-materials/lab-instructions/lab-14/img/styler-1.png;course-materials/lab-instructions/lab-14/img/styler-2.png;course-materials/lab-instructions/lab-14/img/theme-diff.png;course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.Rmd;course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html;course-materials/lab-instructions/lab.css;course-materials/project-instructions/evaluation-forms/instructor-eval.pdf;course-materials/project-instructions/evaluation-forms/peer-eval.pdf;course-materials/project-instructions/img/laptop-3190194_1920.jpg;course-materials/project-instructions/project.Rmd;course-materials/project-instructions/project.css;course-materials/project-instructions/project.html;course-materials/project-instructions/repo-structure/README.Rmd;course-materials/project-instructions/repo-structure/README.md;course-materials/project-instructions/repo-structure/_config.yml;course-materials/project-instructions/repo-structure/data/README.md;course-materials/project-instructions/repo-structure/extra/README.md;course-materials/project-instructions/repo-structure/presentation/img/confetti.jpg;course-materials/project-instructions/repo-structure/presentation/libs/header-attrs-2.4.4/header-attrs.js;course-materials/project-instructions/repo-structure/presentation/libs/header-attrs-2.5.3/header-attrs.js;course-materials/project-instructions/repo-structure/presentation/libs/remark-css-0.0.1/default-fonts.css;course-materials/project-instructions/repo-structure/presentation/libs/remark-css-0.0.1/default.css;course-materials/project-instructions/repo-structure/presentation/presentation.Rmd;course-materials/project-instructions/repo-structure/presentation/presentation.html;course-materials/project-instructions/repo-structure/presentation/presentation_files/figure-html/cars-1.png;course-materials/project-instructions/repo-structure/presentation/presentation_files/figure-html/plot-iris-1.png;course-materials/project-instructions/repo-structure/presentation/presentation_files/figure-html/unnamed-chunk-1-1.png;course-materials/project-instructions/repo-structure/presentation/presentation_files/figure-html/unnamed-chunk-2-1.png;course-materials/project-instructions/repo-structure/presentation/xaringan-themer.css;course-materials/project-instructions/repo-structure/proposal/proposal.Rmd;course-materials/project-instructions/repo-structure/proposal/proposal.md;course-materials/project/evaluation-forms/instructor-eval.pdf;course-materials/project/evaluation-forms/peer-eval.pdf;course-materials/project/project.Rmd;course-materials/project/project.html;course-materials/project/repo-structure/project/project.Rmd;course-materials/project/repo-structure/proposal/proposal.Rmd;course-materials/slides/img/demo.png;course-materials/slides/setup.Rmd;course-materials/slides/slides.css;course-materials/slides/u1-d01-welcome/img/code-examples.jpeg;course-materials/slides/u1-d01-welcome/img/covid.jpeg;course-materials/slides/u1-d01-welcome/img/data-science-cycle/data-science-cycle.001.png;course-materials/slides/u1-d01-welcome/img/data-science-cycle/data-science-cycle.002.png;course-materials/slides/u1-d01-welcome/img/data-science-cycle/data-science-cycle.003.png;course-materials/slides/u1-d01-welcome/img/data-science-cycle/data-science-cycle.004.png;course-materials/slides/u1-d01-welcome/img/data-science-cycle/data-science-cycle.005.png;course-materials/slides/u1-d01-welcome/img/data-science-cycle/data-science-cycle.006.png;course-materials/slides/u1-d01-welcome/img/data-science-cycle/data-science-cycle.007.png;course-materials/slides/u1-d01-welcome/img/data-science-cycle/data-science-cycle.008.png;course-materials/slides/u1-d01-welcome/img/data-science-cycle/data-science-cycle.009.png;course-materials/slides/u1-d01-welcome/img/excel.png;course-materials/slides/u1-d01-welcome/img/gender-pronouns.jpeg;course-materials/slides/u1-d01-welcome/img/google-trend-index.png;course-materials/slides/u1-d01-welcome/img/r.png;course-materials/slides/u1-d01-welcome/img/rstudio.png;course-materials/slides/u1-d01-welcome/img/trump-tweets.jpeg;course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-01.jpeg;course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-02.jpeg;course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-03.jpeg;course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-04.jpeg;course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-05.jpeg;course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-06.jpeg;course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-07.jpeg;course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-08.jpeg;course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-09.jpeg;course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-10.jpeg;course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-11.jpeg;course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-12.jpeg;course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-13.jpeg;course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-14.jpeg;course-materials/slides/u1-d01-welcome/img/unvotes/unvotes-15.png;course-materials/slides/u1-d01-welcome/img/unvotes/unvotes.gif;course-materials/slides/u1-d01-welcome/libs/font-awesome/css/all.css;course-materials/slides/u1-d01-welcome/libs/font-awesome/css/v4-shims.css;course-materials/slides/u1-d01-welcome/libs/font-awesome/webfonts/fa-brands-400.eot;course-materials/slides/u1-d01-welcome/libs/font-awesome/webfonts/fa-brands-400.svg;course-materials/slides/u1-d01-welcome/libs/font-awesome/webfonts/fa-brands-400.ttf;course-materials/slides/u1-d01-welcome/libs/font-awesome/webfonts/fa-brands-400.woff;course-materials/slides/u1-d01-welcome/libs/font-awesome/webfonts/fa-brands-400.woff2,True,False,True,False,18295,50599,68894,"---FILE: .gitignore---
@@ -5,3 +5,5 @@ _book
 _bookdown_files
 *.rds
 *.key
+*.docx
+.Rapp.history

---FILE: .renvignore---
@@ -1 +1,5 @@
-course-materials/**.R
\ No newline at end of file
+course-materials/**.R
+course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.Rmd
+course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.Rmd
+course-materials/slides/u2-d12-data-import/u2-d12-data-import.Rmd
+course-materials/starters/lab/lab-08-uoe-art/lab-08.Rmd

---FILE: 01-topics.Rmd---
@@ -5,75 +5,197 @@ The course content is organized in three units:
 ```{r topic-flow, fig.align=""center"", echo=FALSE}
 library(DiagrammeR)
 
+hello_border <- ""#333333""
+hello_fill   <- ""#d8d8d8""
+explore_border <- ""#57707a""
+explore_fill   <- ""#A7D5E8""
+ethics_border  <- ""#6e8796""
+ethics_fill    <- ""#b3dcf5""
+rigor_border   <- ""#1E5C65""
+rigor_fill     <- ""#b3edf5""
+further_border <- ""#FFD748""
+further_fill   <- ""#faebb4""
+
 topic_flow <- create_graph() %>%
+  # Hello world ----
+  add_node(
+    label = ""Hello\nworld"",
+    node_aes = node_aes(
+      x = 2, y = 2,
+      shape = ""hexagon"", fixedsize = TRUE, height = 1, width = 1.1,
+      fontsize = 12, fontcolor = ""black"",
+      color = hello_border, penwidth = 2, fillcolor = hello_fill
+    )
+  ) %>%
   # Exploring data ----
-  add_node(label = ""Exploring\ndata"", 
-           node_aes = node_aes(x = 2, y = 2,
-                               shape = ""square"", fixedsize = TRUE, height = 1, 
-                               fontname = ""helvetica"", fontsize = 12, fontcolor = ""black"",
-                               color = ""#364E4F"", penwidth = 2, fillcolor = ""#BCECED"")) %>%
-  add_node(label = ""Visualize"", 
-           node_aes = node_aes(x = 2, y = 3, 
-                               fontsize = 10, width = 0.75,
-                               color = ""#BCECED"", penwidth = 2, fillcolor = ""white"")) %>%
-  add_node(label = ""Wrangle"", 
-           node_aes = node_aes(x = 3, y = 1, 
-                               fontsize = 10, width = 0.75,
-                               color = ""#BCECED"", penwidth = 2, fillcolor = ""white"")) %>%
-  add_node(label = ""Import"", 
-           node_aes = node_aes(x = 1, y = 1, 
-                               fontsize = 10, width = 0.75,
-                               color = ""#BCECED"", penwidth = 2, fillcolor = ""white"")) %>%
+  add_node(
+    label = ""Exploring\ndata"",
+    node_aes = node_aes(
+      x = 4, y = 2,
+      shape = ""hexagon"", fixedsize = TRUE, height = 1, width = 1.1,
+      fontname = ""helvetica"", fontsize = 12, fontcolor = ""black"",
+      color = explore_border, penwidth = 2, fillcolor = explore_fill
+    )
+  ) %>%
+  add_edge(
+    from = ""Hello\nworld"", to = ""Exploring\ndata"",
+    edge_aes = edge_aes(arrowhead = ""normal"")
+  ) %>%
+  add_edge(
+    from = ""Exploring\ndata"", to = ""Hello\nworld"",
+    edge_aes = edge_aes(arrowhead = ""normal"")
+  ) %>%
+  add_node(
+    label = ""Visualize"",
+    node_aes = node_aes(
+      x = 4, y = 3,
+      fontsize = 10, width = 0.75,
+      color = explore_fill, penwidth = 2, fillcolor = ""white""
+    )
+  ) %>%
+  add_node(
+    label = ""Wrangle"",
+    node_aes = node_aes(
+      x = 5, y = 1,
+      fontsize = 10, width = 0.75,
+      color = explore_fill, penwidth = 2, fillcolor = ""white""
+    )
+  ) %>%
+  add_node(
+    label = ""Import"",
+    node_aes = node_aes(
+      x = 3, y = 1,
+      fontsize = 10, width = 0.75,
+      color = explore_fill, penwidth = 2, fillcolor = ""white""
+    )
+  ) %>%
   add_edge(from = ""Visualize"", to = ""Exploring\ndata"", edge_aes = edge_aes(arrowhead = ""none"")) %>%
   add_edge(from = ""Wrangle"", to = ""Exploring\ndata"", edge_aes = edge_aes(arrowhead = ""none"")) %>%
   add_edge(from = ""Import"", to = ""Exploring\ndata"", edge_aes = edge_aes(arrowhead = ""none"")) %>%
+  # Data science ethics ----
+  add_node(
+    label = ""Data\nscience\nethics"",
+    node_aes = node_aes(
+      x = 6, y = 2,
+      shape = ""hexagon"", fixedsize = TRUE, height = 1, width = 1.1,
+      fontsize = 12, fontcolor = ""black"",
+      color = ethics_border, penwidth = 2, fillcolor = ethics_fill
+    )
+  ) %>%
+  add_edge(
+    from = ""Exploring\ndata"", to = ""Data\nscience\nethics"",
+    edge_aes = edge_aes(arrowhead = ""normal"")
+  ) %>%
+  add_edge(
+    from = ""Data\nscience\nethics"", to = ""Exploring\ndata"",
+    edge_aes = edge_aes(arrowhead = ""normal"")
+  ) %>%
+  add_node(
+    label = ""Misrepre-\nsentation"",
+    node_aes = node_aes(
+      x = 5, y = 3,
+      fontsize = 10, width = 0.75,
+      color = ethics_fill, penwidth = 2, fillcolor = ""white""
+    )
+  ) %>%
+  add_node(
+    label = ""Data\nprivacy"",
+    node_aes = node_aes(
+      x = 7, y = 3,
+      fontsize = 10, width = 0.75,
+      color = ethics_fill, penwidth = 2, fillcolor = ""white""
+    )
+  ) %>%
+  add_node(
+    label = ""Algorithmic\nbias"",
+    node_aes = node_aes(
+      x = 6, y = 1,
+      fontsize = 10, width = 0.75,
+      color = ethics_fill, penwidth = 2, fillcolor = ""white""
+    )
+  ) %>%
+  add_edge(from = ""Misrepre-\nsentation"", to = ""Data\nscience\nethics"", edge_aes = edge_aes(arrowhead = ""none"")) %>%
+  add_edge(from = ""Data\nprivacy"", to = ""Data\nscience\nethics"", edge_aes = edge_aes(arrowhead = ""none"")) %>%
+  add_edge(from = ""Algorithmic\nbias"", to = ""Data\nscience\nethics"", edge_aes = edge_aes(arrowhead = ""none"")) %>%
   # Making rigorous conclusions ----
-  add_node(label = ""Making\nrigorous\nconclusions"", 
-           node_aes = node_aes(x = 5, y = 2,
-                               shape = ""square"", fixedsize = TRUE, height = 1, 
-                               fontsize = 12, fontcolor = ""black"",
-                               color = ""#5581B0"", penwidth = 2, fillcolor = ""#B6D7E4"")) %>%
-  add_edge(from = ""Exploring\ndata"", to = ""Making\nrigorous\nconclusions"",
-           edge_aes = edge_aes(arrowhead = ""normal"")) %>%
-  add_edge(from = ""Making\nrigorous\nconclusions"", to = ""Exploring\ndata"",
-           edge_aes = edge_aes(arrowhead = ""normal"")) %>%
-  add_node(label = ""Model"", 
-           node_aes = node_aes(x = 4, y = 3, 
-                               fontsize = 10, width = 0.75,
-                               color = ""#B6D7E4"", penwidth = 2, fillcolor = ""white"")) %>%
-  add_node(label = ""Predict"", 
-           node_aes = node_aes(x = 6, y = 3, 
-                               fontsize = 10, width = 0.75,
-                               color = ""#B6D7E4"", penwidth = 2, fillcolor = ""white"")) %>%
-  add_node(label = ""Infer"", 
-           node_aes = node_aes(x = 5, y = 1, 
-                               fontsize = 10, width = 0.75,
-                               color = ""#B6D7E4"", penwidth = 2, fillcolor = ""white"")) %>%
-  add_edge(from = ""Model"", to = ""Making\nrigorous\nconclusions"", edge_aes = edge_aes(arrowhead = ""none"")) %>%
-  add_edge(from = ""Predict"", to = ""Making\nrigorous\nconclusions"", edge_aes = edge_aes(arrowhead = ""none"")) %>%
-  add_edge(from = ""Infer"", to = ""Making\nrigorous\nconclusions"", edge_aes = edge_aes(arrowhead = ""none"")) %>%
+  add_node(
+    label = ""Making\nrigorous\nconclu-\nsions"",
+    node_aes = node_aes(
+      x = 8, y = 2,
+      shape = ""hexagon"", fixedsize = TRUE, height = 1, width = 1.1,
+      fontsize = 12, fontcolor = ""black"",
+      color = rigor_border, penwidth = 2, fillcolor = rigor_fill
+    )
+  ) %>%
+  add_edge(
+    from = ""Data\nscience\nethics"", to = ""Making\nrigorous\nconclu-\nsions"",
+    edge_aes = edge_aes(arrowhead = ""normal"")
+  ) %>%
+  add_edge(
+    from = ""Making\nrigorous\nconclu-\nsions"", to = ""Data\nscience\nethics"",
+    edge_aes = edge_aes(arrowhead = ""normal"")
+  ) %>%
+  add_node(
+    label = ""Model"",
+    node_aes = node_aes(
+      x = 8, y = 3,
+      fontsize = 10, width = 0.75,
+      color = rigor_fill, penwidth = 2, fillcolor = ""white""
+    )
+  ) %>%
+  add_node(
+    label = ""Predict"",
+    node_aes = node_aes(
+      x = 9, y = 1,
+      fontsize = 10, width = 0.75,
+      color = rigor_fill, penwidth = 2, fillcolor = ""white""
+    )
+  ) %>%
+  add_node(
+    label = ""Infer"",
+    node_aes = node_aes(
+      x = 7, y = 1,
+      fontsize = 10, width = 0.75,
+      color = rigor_fill, penwidth = 2, fillcolor = ""white""
+    )
+  ) %>%
+  add_edge(from = ""Model"", to = ""Making\nrigorous\nconclu-\nsions"", edge_aes = edge_aes(arrowhead = ""none"")) %>%
+  add_edge(from = ""Predict"", to = ""Making\nrigorous\nconclu-\nsions"", edge_aes = edge_aes(arrowhead = ""none"")) %>%
+  add_edge(from = ""Infer"", to = ""Making\nrigorous\nconclu-\nsions"", edge_aes = edge_aes(arrowhead = ""none"")) %>%
   # Looking further ----
-  add_node(label = ""Looking\nfurther"", 
-           node_aes = node_aes(x = 8, y = 2,
-                               shape = ""square"", fixedsize = TRUE, height = 1, 
-                               fontname = ""helvetica"", fontsize = 12, fontcolor = ""black"",
-                               color = ""#737F7E"", penwidth = 2, fillcolor = ""#F9F9F9"")) %>%
-  add_edge(from = ""Making\nrigorous\nconclusions"", to = ""Looking\nfurther"",
-           edge_aes = edge_aes(arrowhead = ""normal"")) %>%
-  add_edge(to = ""Making\nrigorous\nconclusions"", from = ""Looking\nfurther"",
-           edge_aes = edge_aes(arrowhead = ""normal""))
+  add_node(
+    label = ""Looking\nfurther"",
+    node_aes = node_aes(
+      x = 10, y = 2,
+      shape = ""hexagon"", fixedsize = TRUE, height = 1, width = 1.1,
+      fontname = ""helvetica"", fontsize = 12, fontcolor = ""black"",
+      color = further_border, penwidth = 2, fillcolor = further_fill
+    )
+  ) %>%
+  add_edge(
+    from = ""Making\nrigorous\nconclu-\nsions"", to = ""Looking\nfurther"",
+    edge_aes = edge_aes(arrowhead = ""normal"")
+  ) %>%
+  add_edge(
+    to = ""Making\nrigorous\nconclu-\nsions"", from = ""Looking\nfurther"",
+    edge_aes = edge_aes(arrowhead = ""normal"")
+  )
 
 render_graph(topic_flow)
 ```
 
-**Unit 1 - Exploring data:** This unit focuses on data visualization and data wrangling.
+**Unit 1 - Hello world:** This unit is an introduction to the content, pedagogy, and toolkit of the course.
+
+**Unit 2 - Exploring data:** This unit focuses on data visualization and data wrangling.
 Specifically we cover fundamentals of data and data visualization, confounding variables, and Simpson's paradox as well as the concept of tidy data, data import, data cleaning, and data curation.
 We end the unit with web scraping and introduce the idea of iteration in preparation for the next unit.
 Also in this unit students are introduced to the toolkit: R, RStudio, R Markdown, Git, and GitHub.
 
-**Unit 2 - Making rigorous conclusions:** In this part we introduce modelling and statistical inference for making data-based conclusions.
+**Unit 3 - Data science ethics:** In this unit we discuss misrepresentation of findings, particularly in data visualisations, breaches of data privacy, and algorithmic bias.
+
+**Unit 4 - Making rigorous conclusions:** In this unit we introduce modelling and statistical inference for making data-based conclusions.
 We discuss building, interpreting, and selecting models, visualizing interaction effects, and prediction and model validation.
 Statistical inference is introduced from a simulation based perspective, and the Central Limit Theorem is discussed very briefly to lay the foundation for future coursework in statistics.
 
-**Unit 3 - Looking forward:** In the last unit we present a series of modules such as interactive reporting and visualization with Shiny, text analysis, and Bayesian inference.
+**Unit 5 - Looking forward:** In the last unit we present a series of modules such as interactive reporting and visualization with Shiny, text analysis, and Bayesian inference.
 These are independent modules that educators can choose to include in their introductory data science curriculum depending on how much time they have left in the semester.

---FILE: 02-ethics.Rmd---
@@ -0,0 +1,122 @@
+# Data science ethics {#ethics}
+
+This unit touches on data science ethics, specifically on issues of misrepresentation of data and results, data privacy, and algorithmic bias.
+Course lectures are supplemented with ""guest lectures"" from domain experts.
+
+## Slides, videos, and application exercises
+
+::: {.slide-deck}
+**Unit 3 - Deck 1: Misrepresentation**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u3-d01-misrepresentation/u3-d01-misrepresentation.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u3-d01-misrepresentation)
+:::
+
+::: {.video}
+[Video](https://youtu.be/C_-rTKfswUI)
+:::
+:::
+
+::: {.guest-lecture}
+**Alberto Cairo - How charts lie**
+
+::: {.video}
+[Video](https://youtu.be/Low28hx4wyk)
+:::
+:::
+
+::: {.slide-deck}
+**Unit 3 - Deck 2: Data privacy**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u3-d02-privacy/u3-d02-privacy.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u3-d02-privacy)
+:::
+
+::: {.video}
+[Video](https://youtu.be/c4fvdoNbcSw)
+:::
+:::
+
+::: {.guest-lecture}
+**The Guardian - Cambridge Analytica whistleblower**
+
+::: {.video}
+[Video](https://youtu.be/FXdYSQ6nu-M)
+:::
+:::
+
+::: {.slide-deck}
+**Unit 3 - Deck 3: Algorithmic bias**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u3-d03-algorithmic-bias)
+:::
+
+::: {.video}
+[Video](https://youtu.be/c4fvdoNbcSw)
+:::
+:::
+
+::: {.guest-lecture}
+**Joy Buolamwini - How I'm fighting bias in algorithms**
+
+::: {.video}
+[Video](https://youtu.be/UG_X_7g63rY)
+:::
+:::
+
+::: {.guest-lecture}
+**Cathy O'Neil - Weapons of Math Destruction**
+
+::: {.video}
+[Video](https://youtu.be/TQHs8SA1qpk)
+:::
+:::
+
+::: {.guest-lecture}
+**Safiya Umoja Noble - Imagining a Future Free from the Algorithms of Oppression**
+
+::: {.video}
+[Video](https://youtu.be/tNi_U1Bb1S0)
+:::
+:::
+
+::: {.guest-lecture}
+**Kristian Lum - What's An Algorithm Got To Do With It**
+
+::: {.video}
+[Video](https://youtu.be/5zxDwA99soA)
+:::
+:::
+
+## Labs
+
+::: {.lab}
+**Lab 9: Conveying the right message through visualisation**
+
+Improving data visualisations to better convey the right message
+
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-09/lab-09-better-viz.html)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-09)
+:::
+
+::: {.starter}
+[Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-09-better-viz)
+:::
+:::

---FILE: 02-exploring-data.Rmd---
@@ -10,166 +10,500 @@ The RStudio Cloud workspace for Data Science Course in a Box project is [here](h
 You can join the workspace and play around with the application exercises.
 :::
 
-## Slides & application exercises
+## Slides, videos, and application exercises
+
+### Visualising data
 
 ::: {.slide-deck}
-**Unit 1 - Deck 2: Meet the toolkit**
+**Unit 2 - Deck 1: Data and visualisation**
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u1_d02-meet-the-toolkit/u1_d02-meet-the-toolkit.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u1_d02-meet-the-toolkit)
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d01-data-viz/u2-d01-data-viz.html#1)
+:::
 
-::: {.application-exercise}
-[Bechdel + R Markdown](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-02-bechdel-rmarkdown)
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d01-data-viz)
 :::
 
-::: {.reading}
--   [R4DS :: Chp 2 - Introduction](https://r4ds.had.co.nz/explore-intro.html)
--   [IMS :: Sec 1.1 & 1.2 - Case study & Data basics](https://openintro-ims.netlify.app/getting-started-with-data.html#basic-stents-strokes)
+::: {.video}
+[Video](https://youtu.be/FddF4b_GuTI)
 :::
 :::
 
 ::: {.slide-deck}
-**Unit 1 - Deck 3: Data and visualization**
+**Unit 2 - Deck 2: Visualising data with ggplot2**
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u1_d03-data-viz-1/u1_d03-data-viz-1.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u1_d03-data-viz-1)
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d02-ggplot2/u2-d02-ggplot2.html#1)
+:::
 
-::: {.application-exercise}
-[Star Wars + Data visualisation](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-03-starwars-dataviz)
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d02-ggplot2)
+:::
+
+::: {.video}
+[Video](https://youtu.be/s2NF2J36ljE)
 :::
 
 ::: {.reading}
-[R4DS :: Chp 3 - Data visualization](https://r4ds.had.co.nz/data-visualisation.html)
+R4DS :: [Chp 3 - Data visualization](https://r4ds.had.co.nz/data-visualisation.html)
 :::
 :::
 
 ::: {.slide-deck}
-**Unit 1 - Deck 4: Building plots for various data types**
+**Unit 2 - Deck 3: Visualising numerical data**
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u1_d04-data-viz-2/u1_d04-data-viz-2.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u1_d04-data-viz-2)
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d03-viz-num/u2-d03-viz-num.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d03-viz-num)
+:::
+
+::: {.video}
+[Video](https://youtu.be/waBabVTI8ec)
+:::
 
 ::: {.reading}
-[IMS :: Chp 2 - Summarizing and visualizing data](https://openintro-ims.netlify.app/summarizing-visualizing-data.html)
+IMS :: [Sec 2.1 - Exploring numerical data](https://openintro-ims.netlify.app/summarizing-visualizing-data.html#numerical-data)
 :::
 :::
 
 ::: {.slide-deck}
-**Unit 1 - Deck 5: Tidy data and data wrangling**
+**Unit 2 - Deck 4: Visualising categorical data**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d04-viz-cat/u2-d04-viz-cat.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d04-viz-cat)
+:::
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u1_d05-data-wrangle/u1_d05-data-wrangle.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u1_d05-data-wrangle)
+::: {.video}
+[Video](https://youtu.be/21h3rEO8k2E)
+:::
+
+::: {.reading}
+IMS :: [Sec 2.2 - Exploring categorical data](https://openintro-ims.netlify.app/summarizing-visualizing-data.html#categorical-data)
+:::
+:::
 
 ::: {.application-exercise}
-[Hotels + Data wrangling](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-04-hotels-datawrangling)
+**StarWars + Dataviz**
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-03-starwars-dataviz/ae-03-starwars-dataviz.Rmd)
+:::
+
+::: {.video}
+[Video](https://youtu.be/3UaLPtCKkXQ)
+:::
+:::
+
+### Wrangling and tidying data
+
+::: {.slide-deck}
+**Unit 2 - Deck 5: Tidy data**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d05-tidy-data/u2-d05-tidy-data.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d05-tidy-data)
+:::
+
+::: {.video}
+[Video](https://youtu.be/Ux85eR3h9hw)
 :::
 
 ::: {.reading}
-[R4DS :: Chp 5 - Data transformation](https://r4ds.had.co.nz/transform.html)
+JSS :: [Tidy data](https://www.jstatsoft.org/article/view/v059i10)
 :::
 :::
 
 ::: {.slide-deck}
-**Unit 1 - Deck 6: Joining data from multiple sources**
+**Unit 2 - Deck 6: Grammar of data wrangling**
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u1_d06-data-join/u1_d06-data-join.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u1_d06-data-join)
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#1)
+:::
 
-::: {.application-exercise}
-[Fisheries + Data joins](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-05-fisheries-datajoins)
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d06-grammar-wrangle)
+:::
+
+::: {.video}
+[Video](https://youtu.be/ZCaYBES_VEk)
+:::
+:::
+
+::: {.slide-deck}
+**Unit 2 - Deck 7: Working with a single data frame**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d07-single-df/u2-d07-single-df.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d07-single-df)
+:::
+
+::: {.video}
+[Video](https://youtu.be/0229Uq2hkJo)
 :::
 
 ::: {.reading}
-[R4DS :: Chp 13 - Relational data](https://r4ds.had.co.nz/relational-data.html)
+R4DS :: [Chp 5 - Data transformation](https://r4ds.had.co.nz/transform.html)
 :::
 :::
 
 ::: {.slide-deck}
-**Unit 1 - Deck 7: Data tidying and reshaping**
+**Unit 2 - Deck 8: Working with multiple data frames**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d08-multi-df/u2-d08-multi-df.html#1)
+:::
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u1_d07-tidy-data)
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d08-multi-df)
+:::
+
+::: {.video}
+[Video](https://youtu.be/VdV5ABsaf5Y)
+:::
 
 ::: {.reading}
-[R4DS :: Chp 12 - Tidy data](https://r4ds.had.co.nz/tidy-data.html)
+R4DS :: [Chp 13 - Relational data](https://r4ds.had.co.nz/relational-data.html)
 :::
 :::
 
 ::: {.slide-deck}
-**Unit 1 - Deck 8: Data types and recoding**
+**Unit 2 - Deck 9: Tidying data**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d09-tidying/u2-d09-tidying.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d09-tidying)
+:::
+
+::: {.video}
+[Video](https://youtu.be/x3KM5uxaFdI)
+:::
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u1_d08-data-types/u1_d08-data-types.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u1_d08-data-types)
+::: {.reading}
+R4DS :: [Chp 12 - Tidy data](https://r4ds.had.co.nz/tidy-data.html)
+:::
+:::
 
 ::: {.application-exercise}
-[Hotels + Data types](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-06-hotels-datatypes)
+**Hotels + Data wrangling**
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-04-hotels-datawrangling/ae-04-hotels-datawrangling.Rmd)
+:::
+
+::: {.video}
+[Video](https://youtu.be/BXlOd4EYQrI)
+:::
+:::
+
+### Importing and recoding data
+
+::: {.slide-deck}
+**Unit 2 - Deck 10: Data types**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d10-data-types/u2-d10-data-types.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d10-data-types)
+:::
+
+::: {.video}
+[Video](https://youtu.be/WsxLbtWbEfc)
+:::
+:::
+
+::: {.slide-deck}
+**Unit 2 - Deck 11: Data classes**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d11-data-classes/u2-d11-data-classes.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d11-data-classes)
+:::
+
+::: {.video}
+[Video](https://youtu.be/dozvSVQcqqg)
 :::
 
 ::: {.reading}
--   [R4DS :: Chp 20.2 - Vector basics](https://r4ds.had.co.nz/vectors.html#vector-basics)
--   [R4DS :: Chp 20.3 - Important types of atomic vector](https://r4ds.had.co.nz/vectors.html#important-types-of-atomic-vector)
--   [R4DS :: Chp 15 - Factors](https://r4ds.had.co.nz/factors.html)
--   [R4DS :: Chp 16.2 - Creating date/times](https://r4ds.had.co.nz/dates-and-times.html#creating-datetimes)
--   [R4DS :: Chp 16.3 - Date-time components](https://r4ds.had.co.nz/dates-and-times.html#date-time-components)
+R4DS :: [Chp 15 - Factors](https://r4ds.had.co.nz/factors.html)
 :::
 :::
 
 ::: {.slide-deck}
-**Unit 1 - Deck 9: Importing data**
+**Unit 2 - Deck 12: Importing data**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d12-data-import/u2-d12-data-import.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d12-data-import)
+:::
+
+::: {.video}
+[Video](https://youtu.be/tIMaRYiuEFA)
+:::
+
+::: {.reading}
+R4DS :: [Chp 11 - Data import](https://r4ds.had.co.nz/data-import.html)
+:::
+:::
+
+::: {.slide-deck}
+**Unit 2 - Deck 13: Recoding data**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d13-data-recode/u2-d13-data-recode.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d13-data-recode)
+:::
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u1_d09-import-data/u1_d09-import-data.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u1_d09-import-data)
+::: {.video}
+[Video](https://youtu.be/O8qxV3N4D5Q)
+:::
+
+::: {.reading}
+R4DS :: [Sec 16.1 - 16.3 - Dates and times](https://r4ds.had.co.nz/dates-and-times.html)
+:::
+:::
 
 ::: {.application-exercise}
-[Nobels & Sales + Data import](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-07-nobels-sales-dataimport)
+**Hotels + Data types**
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-05-hotels-datatypes/ae-05-hotels-datatypes.Rmd)
+:::
+
+::: {.video}
+[Video](https://youtu.be/sByadx_cgDc)
+:::
+:::
+
+::: {.application-exercise}
+**Nobels + Sales + Data import**
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-06-nobels-sales-dataimport/ae-06-nobels-sales-dataimport.Rmd)
+:::
+
+::: {.video}
+[Video](https://youtu.be/2vA6qizYnM8)
+:::
+:::
+
+### Communicating data science results effectively
+
+::: {.slide-deck}
+**Unit 2 - Deck 14: Tips for effective data visualization**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d14-effective-dataviz)
+:::
+
+::: {.video}
+[Video](https://youtu.be/ZrifrBvFWgg)
 :::
 
 ::: {.reading}
-[R4DS :: Chp 11 - Data import](https://r4ds.had.co.nz/data-import.html)
+IMS :: [Sec 2.3 - Effective data visualisation](https://openintro-ims.netlify.app/summarizing-visualizing-data.html#effective-data-visualization)
+:::
+:::
+
+::: {.application-exercise}
+**Brexit + Telling stories with dataviz**
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-07-brexit-story-dataviz/ae-07-brexit-story-dataviz.Rmd)
+:::
+
+::: {.video}
+[Video](https://youtu.be/aPqnkcn13kQ)
 :::
 :::
 
 ::: {.slide-deck}
-**Unit 1 - Deck 10: Tips for effective data visualization**
+**Unit 2 - Deck 15: Scientific studies and confounding**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html#1)
+:::
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u1_d10-effective-dataviz/u1_d10-effective-dataviz.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u1_d10-effective-dataviz)
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d15-studies-confounding)
+:::
+
+::: {.video}
+[Video](https://youtu.be/WnMzTBrZDcc)
+:::
 
 ::: {.reading}
-[IMS :: Sec 2.3 - Effective data visualization](https://openintro-ims.netlify.app/summarizing-visualizing-data.html#effective-data-visualization)
+-   IMS :: [Sec 1.3 - Sampling principles and strategies](https://openintro-ims.netlify.app/getting-started-with-data.html#sampling-principles-strategies)
+-   IMS :: [Sec 1.4 - Experiments](https://openintro-ims.netlify.app/getting-started-with-data.html#experiments)
 :::
 :::
 
 ::: {.slide-deck}
-**Unit 1 - Deck 11: Scientific studies and confounding**
+**Unit 2 - Deck 16: Simpson's paradox**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d16-simpsons-paradox)
+:::
+
+::: {.video}
+[Video](https://youtu.be/sdas62v0iJU)
+:::
+:::
+
+::: {.slide-deck}
+**Unit 2 - Deck 17: Doing data science**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d17-doing-data-science)
+:::
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u1_d11-studies-confounding/u1_d11-studies-confounding.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u1_d11-studies-confounding)
+::: {.video}
+[Video](https://youtu.be/b9lSW0kyqBg)
+:::
 
 ::: {.reading}
--   [IMS :: Sec 1.3 - Sampling principles and strategies](https://openintro-ims.netlify.app/getting-started-with-data.html#sampling-principles-strategies)
--   [IMS :: Sec 1.4 - Experiments](https://openintro-ims.netlify.app/getting-started-with-data.html#experiments)
+R4DS :: [Chp 7 - Exploratory data analysis](https://r4ds.had.co.nz/exploratory-data-analysis.html)
 :::
 :::
 
+### Web scraping and programming
+
 ::: {.slide-deck}
-**Unit 1 - Deck 12: Communicating data science results effectively**
+**Unit 2 - Deck 18: Web scraping**
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u1_d12-effective-communication/u1_d12-effective-communication.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u1_d12-effective-communication)
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d18-web-scrape/u2-d18-web-scrape.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d18-web-scrape)
+:::
+
+::: {.video}
+[Video](https://youtu.be/99Hkmfb2i80)
+:::
 :::
 
 ::: {.slide-deck}
-**Unit 1 - Deck 13: Web scraping**
+**Unit 2 - Deck 19: Scraping top 250 movies on IMDB**
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u1_d13-webscraping/u1_d13-webscraping.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u1_d13-webscraping)
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d18-web-scrape/u2-d18-web-scrape.html#1)
+:::
 
-::: {.application-exercise}
-[IMDB + Web scraping](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-08-imdb-webscraping)
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d18-web-scrape)
+:::
+
+::: {.video}
+[Video](https://youtu.be/YmKULNLsDsU)
 :::
 :::
 
 ::: {.slide-deck}
-**Unit 1 - Deck 14: Functions and iteration**
+**Unit 2 - Deck 20: Web scraping considerations**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d20-considerations/u2-d20-considerations.html#1)
+:::
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u1_d14-functions-iteration/u1_d14-functions-iteration.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u1_d14-functions-iteration)
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d20-considerations)
+:::
+
+::: {.video}
+[Video](https://youtu.be/LONRJHMvSyU)
+:::
+:::
 
 ::: {.application-exercise}
-[University of Edinburgh Art + Functions](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-09-uoeart-functions)
+**IMDB + Web scraping**
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-08-imdb-webscraping/ae-08-imdb-webscraping.Rmd)
+:::
+
+::: {.video}
+[Video](https://youtu.be/PetWV5g1Xsc)
+:::
+:::
+
+::: {.slide-deck}
+**Unit 2 - Deck 21: Functions**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d21-functions/u2-d21-functions.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d21-functions)
+:::
+
+::: {.video}
+[Video](https://youtu.be/6KWlPhPMluE)
 :::
 
 ::: {.reading}
--   [R4DS :: Chp 19 - Functions](https://r4ds.had.co.nz/functions.html)
--   [R4DS :: Sec 21.5 - The map functions](https://r4ds.had.co.nz/iteration.html#the-map-functions)
+R4DS :: [Chp 19 - Functions](https://r4ds.had.co.nz/functions.html)
+:::
+:::
+
+::: {.slide-deck}
+**Unit 2 - Deck 22: Iteration**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2-d22-iteration/u2-d22-iteration.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2-d22-iteration)
+:::
+
+::: {.video}
+[Video](https://youtu.be/x3UMny1fQhc)
+:::
+
+::: {.reading}
+R4DS :: [Chp 20 - Iteration](https://r4ds.had.co.nz/iteration.html)
 :::
 :::
 
@@ -180,103 +514,251 @@ You can join the workspace and play around with the application exercises.
 
 Introduction to R, R Markdown, Git, and GitHub
 
-[[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-01/lab-01-hello-r.html) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-01) [[Starter]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/labs/lab-01-hello-r)
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-01/lab-01-hello-r.html)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-01)
+:::
+
+::: {.starter}
+[Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-01-hello-r)
+:::
 :::
 
 ::: {.lab}
 **Lab 2: Plastic waste**
 
 Introduction to working with data in R with the tidyverse
 
-[[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-02) [[Starter]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/labs/lab-02-plastic-waste)
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-02)
+:::
+
+::: {.starter}
+[Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-02-plastic-waste)
+:::
 :::
 
 ::: {.lab}
 **Lab 3: Nobel laureates**
 
 Data wrangling and tidying
 
-[[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-03) [[Starter]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/labs/lab-03-nobel-laureates)
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-03)
+:::
+
+::: {.starter}
+[Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-03-nobel-laureates)
+:::
 :::
 
 ::: {.lab}
 **Lab 4: La Quinta is Spanish for 'next to Denny's', Pt. 1**
 
 Visualizing spatial data
 
-[[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-04)
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-04)
+:::
+
+::: {.starter}
+[Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-04-viz-sp-data)
+:::
 :::
 
 ::: {.lab}
 **Lab 5: La Quinta is Spanish for 'next to Denny's', Pt. 2**
 
 Wrangling spatial data
 
-[[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-05)
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-05)
+:::
+
+::: {.starter}
+[Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-05-wrangle-sp-data)
+:::
 :::
 
 ::: {.lab}
-**Lab 6: Ugly charts**
+**Lab 6: Sad plots**
 
 Critiquing and improving data visualisations
 
-[[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-06/lab-06-ugly-charts.html) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-06) [[Starter]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/labs/lab-06-ugly-charts)
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-06/lab-06-sad-plots.html)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-06)
+:::
+
+::: {.starter}
+[Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-06-sad-plots)
+:::
 :::
 
 ::: {.lab}
 **Lab 7: Simpson's paradox**
 
 Data visualisation, confounding, multivariable relationships
 
-[[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.html) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-07) [[Starter]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/labs/lab-07-simpsons-paradox)
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.html)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-07)
+:::
+
+::: {.starter}
+[Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-07-simpsons-paradox)
+:::
 :::
 
 ::: {.lab}
 **Lab 8: University of Edinburgh Art Collection**
 
 Web scraping, function, iteration
 
-[[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-08/lab-08-uoe-art.html) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-08) [[Starter]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/labs/lab-08-uoe-art)
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-08/lab-08-uoe-art.html)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-08)
+:::
+
+::: {.starter}
+[Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-08-uoe-art)
+:::
 :::
 
 ## Homework assignments
 
 ::: {.homework}
-**HW 1: Edinburgh Airbnb rentals**
+**HW 1: Pet names**
 
 Introduction to working with data in R with the tidyverse
 
-[[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-01/hw-01-airbnb-edi.html) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-01) [[Starter]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/assignments/hw-01-airbnb-edi)
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-01/hw-01-pet-names.html)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-01)
+:::
+
+::: {.starter}
+[Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/hw/hw-01-pet-names)
+:::
 :::
 
 ::: {.homework}
-**HW 2: North Carolina bike crashes**
+**HW 2: Edinburgh Airbnb rentals**
+
+Data visualisation with the tidyverse
+
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-02)
+:::
+
+::: {.starter}
+[Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/hw/hw-02-airbnb-edi)
+:::
+:::
+
+::: {.homework}
+**HW 3: Road traffic accidents**
 
 Data wrangling, tidying, and visualization
 
-[[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-02/hw-02-bike-crash.html) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-02) [[Starter]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/assignments/hw-02-bike-crash)
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-03/hw-03-accidents.html)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-03)
+:::
+
+::: {.starter}
+[Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/hw/hw-03-accidents)
+:::
 :::
 
 ::: {.homework}
-**HW 3: What should I major in?**
+**HW 4: What should I major in?**
+
+More data wrangling, summarizing, and visualization
+
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-04/hw-04-college-majors.html)
+:::
 
-Data wrangling, summarizing, and visualization
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-04)
+:::
 
-[[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-03/hw-03-college-majors.html) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-03) [[Starter]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/assignments/hw-03-college-majors)
+::: {.starter}
+[Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/hw/hw-04-college-majors)
+:::
 :::
 
 ::: {.homework}
-**HW 4: Legos and instructors**
+**HW 5: Legos**
+
+More data wrangling, summarizing, and visualization
+
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-05/hw-05-legos.html)
+:::
 
-Data wrangling, summarizing, and visualization
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-05)
+:::
 
-[[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-04/hw-04-legos-instructors.html) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-04) [[Starter]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/assignments/hw-04-legos-instructors)
+::: {.starter}
+[Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/hw/hw-05-legos)
+:::
 :::
 
 ::: {.homework}
-**HW 5: Money in politics**
+**HW 6: Money in politics**
 
 Web scraping, functions, and iteration
 
-[[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-05/hw-05-money-in-politics.html) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-05) [[Starter]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/assignments/hw-05-money-in-politics)
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-06)
+:::
+
+::: {.starter}
+[Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/hw/hw-06-money-in-politics)
+:::
 :::

---FILE: 02-hello-world.Rmd---
@@ -9,33 +9,97 @@ The application exercise in this lecture is one way of achieving this goal.
 Slides for Day One of class are provided below.
 
 Note that getting students computing on Day One in class requires that they come to class equipped with a laptop or that you're holding your course online or in a computer lab.
+If teaching online, this is resolved automatically, of course.
 They do not need to do any preparation ahead of time, just need internet access.
 As outlined in the slides, give them a link to your RStudio Cloud workspace and get them started working on the application exercise you put together for them.
-
-<iframe width=""560"" height=""315"" style=""border:1px solid #80D4E6; margin-top:10px; margin-bottom:10px;"" src=""https://rstudio-education.github.io/datascience-box/course-materials/slides/u1_d01-welcome/u1_d01-welcome.html#1"" frameborder=""0"">
-
-</iframe>
-
-You can view the slides in full screen as well as access their source code.
-Along with the slides for this lesson, I'm providing two options for such an activity.
+There are two options for a day one application exercise.
 Note that one of them uses COVID-19 data and depending on where, when, and to whom you're teaching, working with these data might not be the most pleasant experience for all students.
 Please make sure to consider this before using this activity.
 
+::: {.rstudio-cloud}
+The RStudio Cloud workspace for Data Science Course in a Box project is [here](https://rstudio.cloud/spaces/1655/join?access_code=5rdjusfIYF5iI0Gum2vNsBDLdtdnIEELBkf2EivK).
+You can join the workspace and play around with the sample application exercises.
+:::
+
+## Slides, videos, and application exercises
+
 ::: {.slide-deck}
 **Unit 1 - Deck 1: Welcome**
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u1_d01-welcome/u1_d01-welcome.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u1_d01-welcome)
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u1_d01-welcome/u1_d01-welcome.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u1_d01-welcome)
+:::
+
+::: {.video}
+[Video](https://youtu.be/OJ1xR0ObhIw)
+:::
+:::
 
 ::: {.application-exercise}
-[Option 1 - UN Votes](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-01a-un-votes)
+**First dataviz**
+
+> **Option 1 - UN Votes**
+>
+> ::: {.source}
+> [Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-01a-un-votes/ae-01a-un-votes.Rmd)
+> :::
+>
+> ::: {.video}
+> [Video](https://youtu.be/r-uTBEclM1E)
+> :::
+
+> **Option 2 - COVID-19**
+>
+> ::: {.source}
+> [Source](https://github.com/rstudio-education/datascience-box/blob/master/course-materials/application-exercises/ae-01b-covid/covid.Rmd)
+> :::
+:::
+
+::: {.slide-deck}
+**Unit 1 - Deck 2: Meet the toolkit - Programming**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u1-d02-toolkit-r)
+:::
+
+::: {.video}
+[Video](https://youtu.be/mTAZLFcpnLI)
+:::
+
+::: {.reading}
+-   R4DS :: [Chp 2 - Introduction](https://r4ds.had.co.nz/explore-intro.html)
+-   IMS :: [Sec 1.1 & 1.2 - Case study & Data basics](https://openintro-ims.netlify.app/getting-started-with-data.html#basic-stents-strokes)
+:::
 :::
 
 ::: {.application-exercise}
-[Option 2 - COVID-19](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-01b-covid)
+**Bechdel + R Markdown**
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-02-bechdel-rmarkdown/ae-02-bechdel-rmarkdown.Rmd)
 :::
 :::
 
-::: {.rstudio-cloud}
-The RStudio Cloud workspace for Data Science Course in a Box project is [here](https://rstudio.cloud/spaces/1655/join?access_code=5rdjusfIYF5iI0Gum2vNsBDLdtdnIEELBkf2EivK).
-You can join the workspace and play around with sample application exercises.
+::: {.slide-deck}
+**Unit 1 - Deck 3: Meet the toolkit - Version control and collaboration**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u1-d03-toolkit-git)
+:::
+
+::: {.video}
+[Video](https://youtu.be/124DQasLyNQ)
+:::
 :::

---FILE: 02-looking-forward.Rmd---
@@ -1,84 +0,0 @@
-# Looking forward {#looking-forward}
-
-In the last unit we present a series of modules such as interactive reporting and visualization with Shiny, text analysis, and Bayesian inference.
-These are independent modules that educators can choose to include in their introductory data science curriculum depending on how much time they have left in the semester.
-
-## Slides & application exercises
-
-::: {.slide-deck}
-**Unit 3 - Deck 1: Data science ethics**
-
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u3_d01-ethics/u3_d01-ethics.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u3_d01-ethics)
-
-::: {.reading}
-[Modern Data Science with R :: Chp 6 - Professional Ethics](https://mdsr-book.github.io/excerpts/mdsr-ethics.pdf)
-:::
-:::
-
-::: {.slide-deck}
-**Unit 3 - Deck 2: Interactive data visualization**
-
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u3_d02-shiny-1/u3_d2-shiny-1.pdf) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u3_d02-shiny-1)
-
-::: {.reading}
-[Mastering Shiny :: Chp 2 - Your first Shiny app](https://mastering-shiny.org/basic-app.html)
-:::
-:::
-
-::: {.slide-deck}
-**Unit 3 - Deck 3: Interactive data visualization and reporting**
-
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u3_d03-shiny-2/u3_d3-shiny-2.pdf) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u3_d03-shiny-2)
-
-::: {.reading}
--   [Mastering Shiny :: Chp 3 - Basic UI](https://mastering-shiny.org/basic-ui.html)
-
--   [Mastering Shiny :: Chp 4 - Basic reactivity](https://mastering-shiny.org/basic-reactivity.html)
-:::
-:::
-
-::: {.slide-deck}
-**Unit 3 - Deck 4: Bayesian inference**
-
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u3_d04-bayes-inf/u3_d04-bayes-inf.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u3_d04-bayes-inf)
-:::
-
-::: {.slide-deck}
-**Unit 3 - Deck 5: Text analysis**
-
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u3_d05-text-analysis/u3_d05-text-analysis.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u3_d05-text-analysis)
-
-::: {.reading}
--   [Tidy Text Mining :: Chp 1 - The tidy text format](https://www.tidytextmining.com/tidytext.html)
-
--   [Tidy Text Mining :: Chp 2 - Sentiment analysis with tidy data](https://www.tidytextmining.com/sentiment.html)
-:::
-:::
-
-## Labs
-
-::: {.lab}
-**Lab 12: Working on projects**
-
-Workflows for data science projects
-
-[[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-12/lab-12-work-on-projects.html) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-12)
-:::
-
-::: {.lab}
-**Lab 13: Collaborating on GitHub**
-
-Workflows for data science projects, closing issues with commits, gh-pages
-
-[[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-13/lab-13-collaborating-on-github.html) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-13)
-:::
-
-## Homework assignments
-
-::: {.homework}
-**HW 8: Wrapping up**
-
-Pick a package and do something with it, make an ugly plot!
-
-[[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-08/hw-08-wrap-up.html) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-08) [[Starter]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/assignments/hw-08-wrap-up)
-:::

---FILE: 02-looking-further.Rmd---
@@ -0,0 +1,149 @@
+# Looking further {#looking-forward}
+
+In the last unit we present a series of modules such as interactive reporting and visualization with Shiny, text analysis, machine learning, and Bayesian inference.
+These are independent modules that educators can choose to include in their introductory data science curriculum depending on how much time they have left in the semester.
+Note that the slides in this unit are a bit more sparse than the others, and much of the content is delivered as live coding sessions.
+
+## Slides, videos, and application exercises
+
+::: {.slide-deck}
+**Unit 5 - Deck 1: Text analysis**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u5-d01-text-analysis/u5-d01-text-analysis.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u5-d01-text-analysis)
+:::
+
+::: {.video}
+[Video](https://youtu.be/_YqEHZccujc)
+:::
+:::
+
+::: {.slide-deck}
+**Unit 5 - Deck 2: Comparing texts**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u5-d02-comparing-texts/u5-d02-comparing-texts.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u5-d02-comparing-texts)
+:::
+
+::: {.video}
+[Video](https://youtu.be/Q79feeFbsxM)
+:::
+:::
+
+::: {.slide-deck}
+**Unit 5 - Deck 3: Interactive web apps**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u5-d03-interactive-web-app/u5-d03-interactive-web-app.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u5-d03-interactive-web-app)
+:::
+
+::: {.video}
+[Video](https://youtu.be/gXBEOFWrxsk)
+:::
+:::
+
+::: {.slide-deck}
+**Unit 5 - Deck 4: Machine learning**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u5-d04-machine-learning/u5-d04-machine-learning.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u5-d04-machine-learning)
+:::
+
+::: {.video}
+[Video](https://youtu.be/IP5skNjwo7A)
+:::
+:::
+
+::: {.slide-deck}
+**Unit 5 - Deck 5: Interactive data visualisation**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u5-d05-shiny-1/u5-d05-shiny-1.pdf)
+:::
+:::
+
+::: {.slide-deck}
+**Unit 5 - Deck 6: Interactive data visualisation and reporting**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u5-d05-shiny-2/u5-d05-shiny-2.pdf)
+:::
+:::
+
+::: {.slide-deck}
+**Unit 5 - Deck 7: Bayesian inference**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u5-d07-bayes-inf)
+:::
+:::
+
+## Labs
+
+::: {.lab}
+**Lab 13: Working on projects**
+
+Fitting and interpreting simple linear regression models
+
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-13/lab-13-work-on-projects.html)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-13)
+:::
+:::
+
+::: {.lab}
+**Lab 14: Collaboration on GitHub**
+
+Fitting and interpreting simple linear regression models
+
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-14)
+:::
+:::
+
+## Homework assignments
+
+::: {.homework}
+**HW 10: Wrapping up**
+
+Model validation and inference
+
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-10/hw-10-wrap-up.html)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-10)
+:::
+
+::: {.starter}
+[Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/hw/hw-10-wrap-up)
+:::
+:::

---FILE: 02-making-rigorous-conclusions.Rmd---
@@ -4,142 +4,385 @@ In this part we introduce modelling and statistical inference for making data-ba
 We discuss building, interpreting, and selecting models, visualizing interaction effects, and prediction and model validation.
 Statistical inference is introduced from a simulation based perspective, and the Central Limit Theorem is discussed very briefly to lay the foundation for future coursework in statistics.
 
-## Slides & application exercises
+::: {.rstudio-cloud}
+The RStudio Cloud workspace for Data Science Course in a Box project is [here](https://rstudio.cloud/spaces/1655/join?access_code=5rdjusfIYF5iI0Gum2vNsBDLdtdnIEELBkf2EivK).
+You can join the workspace and play around with the sample application exercises.
+:::
+
+## Slides, videos, and application exercises
+
+### Modelling data
 
 ::: {.slide-deck}
-**Unit 2 - Deck 1: The language of models**
+**Unit 4 - Deck 1: The language of models**
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d01-language-of-models/u2_d01-language-of-models.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d01-language-of-models)
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d01-language-of-models/u4-d01-language-of-models.html#1)
+:::
 
-::: {.reading}
-[IMS :: Sec 3.1 - Fitting a line, residuals, and correlation](https://openintro-ims.netlify.app/intro-linear-models.html#fit-line-res-cor)
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d01-language-of-models)
+:::
+
+::: {.video}
+[Video](https://youtu.be/MWkkvDopBKc)
 :::
 :::
 
 ::: {.slide-deck}
-**Unit 2 - Deck 2: Linear models with a single predictor**
+**Unit 4 - Deck 2: Fitting and interpreting models**
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d02-linear-model-single-predictor/u2_d02-linear-model-single-predictor.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d02-linear-model-single-predictor)
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d02-fitting-interpreting-models)
+:::
+
+::: {.video}
+[Video](https://youtu.be/69U92Q3pwnA)
+:::
 
 ::: {.reading}
-[IMS :: Sec 3.2 - Least squares regression](https://openintro-ims.netlify.app/intro-linear-models.html#least-squares-regression)
+IMS :: [Chp 3 - Introduction to linear models](https://openintro-ims.netlify.app/intro-linear-models.html)
 :::
 :::
 
 ::: {.slide-deck}
-**Unit 2 - Deck 3: Modeling non-linear relationships**
+**Unit 4 - Deck 3: Modelling nonlinear relationships**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d03-modeling-nonlinear-relationships)
+:::
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d03-modeling-non-linear-relationships/u2_d03-modeling-non-linear-relationships.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d03-modeling-non-linear-relationships)
+::: {.video}
+[Video](https://youtu.be/j4MZ6ZdHnHg)
+:::
 :::
 
 ::: {.slide-deck}
-**Unit 2 - Deck 4: Linear models with multiple predictors**
+**Unit 4 - Deck 4: Models with multiple predictors**
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d04-linear-model-multiple-predictors)
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d04-model-multiple-predictors)
+:::
+
+::: {.video}
+[Video](https://youtu.be/mjkNabD4oi4)
+:::
 
 ::: {.reading}
-[IMS :: Sec 4.1 - Regression with multiple predictors](https://openintro-ims.netlify.app/multi-logistic-models.html#regression-multiple-predictors)
+IMS :: [Sec 4.1 - Regression with multiple predictors](https://openintro-ims.netlify.app/multi-logistic-models.html#regression-multiple-predictors)
+:::
+:::
+
+::: {.slide-deck}
+**Unit 4 - Deck 5: More models with multiple predictors**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d05-more-model-multiple-predictors)
+:::
+
+::: {.video}
+[Video](https://youtu.be/nJAYRnLPb10)
 :::
 :::
 
+### Classification and model building
+
 ::: {.slide-deck}
-**Unit 2 - Deck 5: Model selection**
+**Unit 4 - Deck 6: Logistic regression**
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d05-model-selection/u2_d05-model-selection.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d05-model-selection)
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d06-logistic-reg)
+:::
+
+::: {.video}
+[Video](https://youtu.be/AidXFYSYfJg)
+:::
 
 ::: {.reading}
-[IMS :: Sec 4.2 - Model selection](https://openintro-ims.netlify.app/multi-logistic-models.html#model-selection)
+IMS :: [Sec 4.5 - Logistic regression](https://openintro-ims.netlify.app/multi-logistic-models.html#logistic-regression)
 :::
 :::
 
 ::: {.slide-deck}
-**Unit 2 - Deck 6: Model validation**
+**Unit 4 - Deck 7: Prediction and overfitting**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d07-prediction-overfitting)
+:::
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d06-model-validation/u2_d06-model-validation.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d06-model-validation)
+::: {.video}
+[Video](https://youtu.be/Qd4lu_Lmwi0)
+:::
+
+::: {.reading}
+tidymodels :: [Build a model](https://www.tidymodels.org/start/models/)
+:::
 :::
 
 ::: {.slide-deck}
-**Unit 2 - Deck 7: Logistic regression and classification**
+**Unit 4 - Deck 8: Feature engineering**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d08-feature-engineering)
+:::
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d07-logistic-regression/u2_d07-logistic-regression.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d07-logistic-regression)
+::: {.video}
+[Video](https://youtu.be/wZt9ab4jBZ4)
+:::
 
 ::: {.reading}
-[IMS :: Sec 4.5 - Logistic regression](https://openintro-ims.netlify.app/multi-logistic-models.html#logistic-regression)
+tidymodels :: [Preprocess your data with recipes](https://www.tidymodels.org/start/recipes/)
 :::
 :::
 
+### Model validation
+
 ::: {.slide-deck}
-**Unit 2 - Deck 8: Quantifying uncertainty**
+**Unit 4 - Deck 9: Cross validation**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d09-cross-validation/u4-d09-cross-validation.html#1)
+:::
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d08-quantifying-uncertainty/u2_d08-quantifying-uncertainty.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d08-quantifying-uncertainty)
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d09-cross-validation)
+:::
+
+::: {.video}
+[Video](https://youtu.be/L1KfIISmUT4)
+:::
 
 ::: {.reading}
-[IMS :: Sec 5.2 - Bootstrap confidence intervals](https://openintro-ims.netlify.app/intro-stat-inference.html#boot-ci)
+tidymodels :: [Evaluate your model with resampling](https://www.tidymodels.org/start/resampling/)
+:::
+:::
+
+::: {.application-exercise}
+**The Office + Feature engineering, Pt. 1**
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-09-feat-eng-cv/ae-09-feat-eng-cv.Rmd)
+:::
+
+::: {.video}
+[Video](https://youtu.be/qsUYstdN4LQ)
+:::
+:::
+
+::: {.application-exercise}
+**The Office + Cross validation, Pt. 2**
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/application-exercises/ae-09-feat-eng-cv/ae-09-feat-eng-cv.Rmd)
+:::
+
+::: {.video}
+[Video](https://youtu.be/WstIr94Fdjc)
+:::
+:::
+
+### Uncertainty quantification
+
+::: {.slide-deck}
+**Unit 4 - Deck 10: Quantifying uncertainty**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d10-quantify-uncertainty)
+:::
+
+::: {.video}
+[Video](https://youtu.be/LYpKrtZmQtI)
 :::
 :::
 
 ::: {.slide-deck}
-**Unit 2 - Deck 9: Hypothesis testing with randomization**
+**Unit 4 - Deck 11: Bootstrapping**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d11-bootstrap/u4-d11-bootstrap.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d11-bootstrap)
+:::
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d09-hypothesis-testing/u2_d09-hypothesis-testing.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d09-hypothesis-testing)
+::: {.video}
+[Video](https://youtu.be/bdqpI3iVOso)
+:::
 
 ::: {.reading}
-[IMS :: Sec 5.1 - Randomization tests](https://openintro-ims.netlify.app/intro-stat-inference.html#inf-rand)
+IMS :: [Sec 5.2 - Bootstrap confidence intervals](https://openintro-ims.netlify.app/intro-stat-inference.html#boot-ci)
 :::
 :::
 
 ::: {.slide-deck}
-**Unit 2 - Deck 10: Inference overview**
+**Unit 4 - Deck 12: Hypothesis testing**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#1)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d12-hypothesis-testing)
+:::
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d10-inference-overview/u2_d10-inference-overview.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d10-inference-overview)
+::: {.reading}
+[IMS :: Sec 5.1 - Randomization tests](https://openintro-ims.netlify.app/intro-stat-inference.html#inf-rand)
+:::
 :::
 
 ::: {.slide-deck}
-**Unit 2 - Deck 11: Simulation based inference review**
+**Unit 4 - Deck 13: Inference overview**
+
+::: {.slides}
+[Slides](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d13-inference-overview/u4-d13-inference-overview.html#1)
+:::
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d11-sim-inf-review/u2_d11-sim-inf-review.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d11-sim-inf-review)
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u4-d13-inference-overview)
+:::
 :::
 
 ## Labs
 
 ::: {.lab}
-**Lab 9: Grading the professor, Pt. 1**
+**Lab 10: Grading the professor, Pt. 1**
+
+Fitting and interpreting simple linear regression models
+
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html)
+:::
 
-Simple linear regression, prediction
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-10)
+:::
 
-[[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-09/lab-09-modelling-course-evals.html) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-09) [[Starter]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/labs/lab-09-model-course-evals)
+::: {.starter}
+[Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-10-slr-course-evals)
+:::
 :::
 
 ::: {.lab}
-**Lab 10: Grading the professor, Pt. 2**
+**Lab 11: Grading the professor, Pt. 2**
+
+Fitting and interpreting multiple linear regression models
+
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html)
+:::
 
-Simple and multiple linear regression, model selection
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-11)
+:::
 
-[[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-10/lab-10-mlr-course-evals.html) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-10)
+::: {.starter}
+[Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-11-mlr-course-evals)
+:::
 :::
 
 ::: {.lab}
-**Lab 11: So what if you smoke when pregnant?**
+**Lab 12: Smoking while pregnant**
+
+Constructing confidence intervals, conducting hypothesis tests, and interpreting results in context of the data
 
-Inference with bootstrap intervals and randomization testing
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-12)
+:::
 
-[[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/lab-instructions/lab-11/lab-11-inference-smoking.html) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/lab-instructions/lab-11)
+::: {.starter}
+[Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/lab/lab-12-inference-smoking)
+:::
 :::
 
 ## Homework assignments
 
 ::: {.homework}
-**HW 6: Bike rentals in DC**
+**HW 7: Bike rentals in DC**
+
+Exploratory data analysis and fitting and interpreting models
+
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-07)
+:::
+
+::: {.starter}
+[Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/hw/hw-07-bike-rentals-dc)
+:::
+:::
+
+::: {.homework}
+**HW 8: Exploring the GSS**
+
+Fitting and interpreting models
+
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html)
+:::
 
-Modeling and visualization
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-08)
+:::
 
-[[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-06/hw-06-bike-rentals-dc.html) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-06) [[Starter]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/assignments/hw-06-bike-rentals-dc)
+::: {.starter}
+[Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/hw/hw-08-exploring-gss)
+:::
 :::
 
 ::: {.homework}
-**HW 7: Exploring the General Social Survey**
+**HW 9: Modelling the GSS**
+
+Model validation and inference
 
-Inference with bootstrap intervals and randomization testing
+::: {.instructions}
+[Instructions](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html)
+:::
+
+::: {.source}
+[Source](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-09)
+:::
 
-[[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/hw-instructions/hw-07/hw-07-exploring-gss.html) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/hw-instructions/hw-07) [[Starter]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/assignments/hw-07-exploring-gss)
+::: {.starter}
+[Starter](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/starters/hw/hw-09-modeling-gss)
+:::
 :::

---FILE: 02-project.Rmd---
@@ -14,173 +14,213 @@ Pick a dataset, any dataset...
 That is your final project in a nutshell.
 More details below.
 
-PS: Please don't make pie charts for your project.
-
 ## May be too long, but please do read
 
 The final project for this class will consist of analysis on a dataset of your own choosing.
 The dataset may already exist, or you may collect your own data using a survey or by conducting an experiment.
 You can choose the data based on your interests or based on work in other courses or research projects.
 The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like) and apply them to a novel dataset in a meaningful way.
 
-### Data
+The goal is not to do an exhaustive data analysis i.e., do not calculate every statistic and procedure you have learned for every variable, but rather let me know that you are proficient at asking meaningful questions and answering them with results of data analysis, that you are proficient in using R, and that you are proficient at interpreting and presenting the results.
+Focus on methods that help you begin to answer your research questions.
+You do not have to apply every statistical procedure we learned (and you can use techniques we haven't officially covered in class, if you're feeling adventurous).
+Also, critique your own methods and provide suggestions for improving your analysis.
+Issues pertaining to the reliability and validity of your data, and appropriateness of the statistical analysis should be discussed here.
+
+The project is very open ended.
+You should create some kind of compelling visualization(s) of this data in R.
+There is no limit on what tools or packages you may use, but sticking to packages we learned in class (`tidyverse`) is required.
+You do not need to visualize all of the data at once.
+A single high quality visualization will receive a much higher grade than a large number of poor quality visualizations.
+Also pay attention to your presentation.
+Neatness, coherency, and clarity will count.
+All analyses must be done in RStudio, using R.
+
+## Data
 
 In order for you to have the greatest chance of success with this project it is important that you choose a manageable dataset.
 This means that the data should be readily accessible and large enough that multiple relationships can be explored.
 As such, your dataset must have at least 50 observations and between 10 to 20 variables (exceptions can be made but you must speak with me first).
 The dataset's variables should include categorical variables, discrete numerical variables, and continuous numerical variables.
 
-All analyses must be done in RStudio.
-If you are using a dataset that comes in a format that we haven't encountered in class, make sure that you are able to load it into RStudio as this can be tricky depending on the source.
+If you are using a dataset that comes in a format that we haven't encountered in class, make sure that you are able to load it into R as this can be tricky depending on the source.
 If you are having trouble ask for help before it is too late.
 
-*Reusing datasets from class:* Do not reuse datasets used in examples / homework in the class.
+**Note on reusing datasets from class:** Do not reuse datasets used in examples, homework assignments, or labs in the class.
+
+Below are a list of data repositories that might be of interest to browse.
+You're not limited to these resources, and in fact you're encouraged to venture beyond them.
+But you might find something interesting there:
+
+-   [TidyTuesday](https://github.com/rfordatascience/tidytuesday)
+-   [NHS Scotland Open Data](https://www.opendata.nhs.scot/)
+-   [Edinburgh Open Data](https://edinburghopendata.info/)
+-   [Open access to Scotland's official statistics](https://statistics.gov.scot/home)
+-   [Bikeshare data portal](https://www.bikeshare.com/data/)
+-   [UK Gov Data](https://data.gov.uk/)
+-   [Kaggle datasets](https://www.kaggle.com/datasets)
+-   [OpenIntro datasets](http://openintrostat.github.io/openintro/)
+-   [Awesome public datasets](https://github.com/awesomedata/awesome-public-datasets)
+-   [Youth Risk Behavior Surveillance System (YRBSS)](https://chronicdata.cdc.gov/Youth-Risk-Behaviors/DASH-Youth-Risk-Behavior-Surveillance-System-YRBSS/q6p7-56au)
+-   [PRISM Data Archive Project](https://www.icpsr.umich.edu/icpsrweb/content/ICPSR/fenway.html)
+-   [Harvard Dataverse](https://dataverse.harvard.edu/)
+-   If you know of others, let me know, and we'll add here...
+
+### Deliverables
+
+1.  Proposal - due [ENTER DUE DATE]
+2.  Presentation - due [ENTER DUE DATE]
+3.  Executive summary - due [ENTER DUE DATE]
 
-### Project proposal
+#### Proposal
 
 This is a draft of the introduction section of your project as well as a data analysis plan and your dataset.
-Each section should be no more than 1 page (excluding figures).
-You can check a print preview to confirm length.
-Your write up and all typesetting must be done with using R Markdown.
 
--   **Section 1 - Introduction:**
+-   **Section 1 - Introduction:** The introduction should introduce your general
 
-The introduction should introduce your general research question and your data (where it came from, how it was collected, what are the cases, what are the variables, etc.).
+    research question and your data (where it came from, how it was collected,
 
--   **Section 2 - Data analysis plan:**
+    what are the cases, what are the variables, etc.).
 
-The data analysis plan should include:
+-   **Section 2 - Data:** Place your data in the \`/data\` folder, and add dimensions and codebook to the README in that folder.
+    Then print out the output of and codebook to the README in that folder.
+    Then print out the output of `glimpse()` or `skim()` of your data frame.
 
--   The outcome (dependent, response, Y) and predictor (independent, explanatory, X) variables you will use to answer your question.
+-   **Section 3 - Data analysis plan:**
 
--   The comparison groups you will use, if applicable.
+    -   The outcome (response, Y) and predictor (explanatory, X) variables you will use to answer your question.
 
--   Very preliminary exploratory data analysis, including some summary statistics and visualizations, along with some explanation on how they help you learn more about your data.
-    (You can add to these later as you work on your project..)
+    -   The comparison groups you will use, if applicable.
 
--   The statistical method(s) that you believe will be useful in answering your question(s).
-    (You can update these later as you work on your project.)
+    -   Very preliminary exploratory data analysis, including some summary statistics and visualizations, along with some explanation on how they help you learn more about your data.
+        (You can add to these later as you work on your project.)
 
--   What results from these specific statistical methods are needed to support your hypothesized answer?
+    -   The method(s) that you believe will be useful in answering your question(s).
+        (You can update these later as you work on your project.)
 
--   **Section 3 - Data:**
+    -   What results from these specific statistical methods are needed to support your hypothesized answer?
 
-Place your data in the `/data` folder, and add dimensions and codebook to the README in this folder.
-Then print out the output of `glimpse` of your data frame.
+Each section should be no more than 1 page (excluding figures).
+You can check a print preview to confirm length.
 
--   **Grading**
+The grading scheme for the project proposal is as follows.
+Note that after you receive feedback for your proposal you can improve it based on the feedback and re-submit it.
+If you re-submit, your final score for the proposal will be the average of two scores you receive (first and second submission).
+
++-----------------------------------------------------------+----------+
+| Total                                                     | 10 pts   |
++===========================================================+==========+
+| Data                                                      | 3 pts    |
++-----------------------------------------------------------+----------+
+| Proposal                                                  | 5 pts    |
++-----------------------------------------------------------+----------+
+| Workflow, organization, code quality                      | 1 pt     |
++-----------------------------------------------------------+----------+
+| Teamwork                                                  | 1 pt     |
++-----------------------------------------------------------+----------+
 
-+-------------------------------+--------+
-| Total                         | 20 pts |
-+===============================+========+
-| Introduction                  | 6 pts  |
-+-------------------------------+--------+
-| Data analysis plan            | 10 pts |
-+-------------------------------+--------+
-| Data                          | 2 pts  |
-+-------------------------------+--------+
-| Organization and code quality | 2 pts  |
-+-------------------------------+--------+
+#### Presentation
 
-### Project
+5 minutes maximum, and each team member should say something substantial.
+You can either present live during your workshop or pre-record and submit your video to be played during the workshop.
 
-#### Write up
+Prepare a slide deck using the template in your repo.
+This template uses a package called `xaringan`, and allows you to make presentation slides using R Markdown syntax.
+There isn't a limit to how many slides you can use, just a time limit (5 minutes total).
+Each team member should get a chance to speak during the presentation.
+Your presentation should not just be an account of everything you tried (""then we did this, then we did this, etc.""), instead it should convey what choices you made, and why, and what you found.
 
-After providing the description of your dataset and research question in the introduction use the remainder of your write up to showcase how you have arrived at an answer / answers to your question using any techniques we have learned in this class (and some beyond, if you're feeling adventerous).
-The goal is not to do an exhaustive data analysis i.e., do not calculate every statistic and procedure you have learned for every variable, but rather let me know that you are proficient at asking meaningful questions and answering them with results of data analysis, that you are proficient in using R, and that you are proficient at interpreting and presenting the results.
-Focus on methods that help you begin to answer your research questions.
-You do not have to apply every statistical procedure we learned.
-Also pay attention to your presentation.
-Neatness, coherency, and clarity will count.
+Before you finalize your presentation, make sure your chunks are turned off with `echo = FALSE`.
 
-Your write up must also include a one to two page conclusion and discussion.
-This will require a summary of what you have learned about your research question along with statistical arguments supporting your conclusions.
-Also critique your own methods and provide suggestions for improving your analysis.
-Issues pertaining to the reliability and validity of your data, and appropriateness of the statistical analysis should be discussed here.
-A paragraph on what you would do differently if you were able to start over with the project or what you would do next if you were going to continue work on the project should also be included.
+Presentations will take place during the last workshop of the semester.
+You can choose to do your presentation live or pre-record it.
+During your workshop you will watch presentations from other teams in your workshop and provide feedback in the form of peer evaluations.
+The presentation line-up will be generated randomly.
 
-The project is very open ended.
-You should create some kind of compelling visualization(s) of this data in R.
-There is no limit on what tools or packages you may use, but sticking to packages we learned in class (`tidyverse`) is required.
-You do not need to visualize all of the data at once.
-A single high quality visualization will receive a much higher grade than a large number of poor quality visualizations.
+The grading scheme for the presentation is as follows:
 
-Before you finalize your write up, make sure your chunks are turned off with `echo = FALSE`.
++----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
+| Total                                                                                                                                                                                                          | 50 pts |
++================================================================================================================================================================================================================+========+
+| Time management: Did the team divide the time well amongst themselves or got cut off going over time?                                                                                                          | 4 pts  |
++----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
+| Content: Is the research question well designed and is the data being used relevant to the research question?                                                                                                  | 5 pts  |
++----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
+| Professionalism: How well did the team present? Does the presentation appear to be well practiced? Did everyone get a chance to say something meaningful about the project?                                    | 5 pts  |
++----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
+| Teamwork: Did the team present a unified story, or did it seem like independent pieces of work patched together?                                                                                               | 6 pts  |
++----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
+| Content: Did the team use appropriate statistical procedures and interpretations of results accurately?                                                                                                        | 10 pts |
++----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
+| Creativity and Critical Thought: Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project? | 10 pts |
++----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
+| Slides: Are the slides well organized, readable, not full of text, featuring figures with legible labels, legends, etc.?                                                                                       | 10 pts |
++----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
 
-You can add sections as you see fit to the template in your project repo.
-Make sure you have a section called Introduction at the beginning and a section called Conclusion at the end.
-The rest is up to you!
+#### Executive summary
 
-#### Presentation
+Along with your presentation slides, we want you to provide a brief summary of your project in the README of your repository.
 
-6 minutes maximum, and each team member should say something substantial.
+This executive summary should provide information on the dataset you're using, your research question(s), your methodology, and your findings.
 
-You can use any software you like for your final presentation, including R Markdown to create your slides.
-There isn't a limit to how many slides you can use, just a time limit (6 minutes total).
-Each team member should get a chance to speak during the presentation.
-Your presentation should not just be an account of everything you tried (""then we did this, then we did this, etc.""), instead it should convey what choices you made, and why, and what you found.
+The executive summary is worth 15 points and will be evaluated based on whether it follows guidance and whether it's concise but detailed enough.
 
-#### Delivarables
+#### Repo organization
 
-Your submission should include
+The following folders and files in your project repository:
 
--   RMarkdown file (formated to clearly present all of your code and results)
--   HTML file
--   md file (viewable on GitHub, with all figures)
--   Dataset(s) (in csv or RData format, in a `/data` folder)
--   Presentation (if using Keynote/PowerPoint/Google Slides, export to PDF and put in repo, in a `/presentation` folder)
+-   `presentation.Rmd` + `presentation.html`: Your presentation slides
+-   `README.Rmd` + `README.md`: Your write-up
+-   `/data`: Your dataset in CSV or RDS format and your data dictionary
+-   `/proposal`: Your project proposal
 
-Style and format does count for this assignment, so please take the time to make sure everything looks good and your data and code are properly formated.
+Style and format does count for this assignment, so please take the time to make sure everything looks good and your data and code are properly formatted.
 
 ### Tips
 
--   You're working in the same repo as your teammates now, so merge conflics will happen, issues will arise, and that's fine!
-    Commit and push often, and ask questions when stuck.
+-   You're working in the same repo as your teammates now, so merge conflicts will happen, issues will arise, and that's fine Commit and push often, and ask questions when stuck.
 
--   Review the grading guidelines below and ask questions if any of the expectations are unclear.
+-   Review the marking guidelines below and ask questions if any of the expectations are unclear.
 
 -   Make sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).
 
 -   Set aside time to work together and apart (physically).
 
--   When you're done, review the .md document on GitHub to make sure you're happy with the final state of your work.
+-   When you're done, review the documents on GitHub to make sure you're happy with the final state of your work.
     Then go get some rest!
 
--   Code: In your write up your code should be hidden (`echo = FALSE`) so that your document is neat and easy to read.
-    However your document should include all your code such that if I re-knit your Rmd file I should be able to obtain the results you presented.
-    **Exception:** If you want to highlight something specific about a piece of code, you're welcomed to show that portion.
+-   Code: In your presentation your code should be hidden (`echo = FALSE`) so that your document is neat and easy to read.
+    However your document should include all your code such that if I re-knit your R Markdown file I should be able to obtain the results you presented.
+
+    -   Exception: If you want to highlight something specific about a piece of code, you're welcomed to show that portion.
 
 -   Teamwork: You are to complete the assignment as a team.
-    All team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized.
+    All team members are expected to contribute equally to the completion of this assignment and team evaluations will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized.
     While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works.
 
-### Grading
-
-+--------------------------------+---------+
-| Total                          | 100 pts |
-+================================+=========+
-| Proposal                       | 20 pts  |
-+--------------------------------+---------+
-| Presentation                   | 25 pts  |
-+--------------------------------+---------+
-| Write up                       | 30 pts  |
-+--------------------------------+---------+
-| Classmates' scores             | 5 pts   |
-+--------------------------------+---------+
-| Team peer evaluation           | 10 pts  |
-+--------------------------------+---------+
-| Repo and document organization | 10 pts  |
-+--------------------------------+---------+
-
-**Team peer evaluation:** You will be asked to fill out a survey where you rate the contribution and teamwork of each team member out of 10 points.
-You will additionally report a contribution percentage for each team member.
-Filling out the survey is a prerequisite for getting credit on the team member evaluation.
-If you are suggesting that an individual did less than 20% of the work, please provide some explanation.
-If any individual gets an average peer score indicating that they did less than 10% of the work, this person will receive half the grade of the rest of the group.
-
-Grading of the project will take into account the following:
-
--   Content - What is the quality of research and/or policy question and relevancy of data to thosequestions?
+### Marking
+
++----------------------------------------------------------+-----------+
+| Total                                                    | 100 pts   |
++==========================================================+===========+
+| Proposal                                                 | 10 pts    |
++----------------------------------------------------------+-----------+
+| Presentation                                             | 50 pts    |
++----------------------------------------------------------+-----------+
+| Executive summary                                        | 15 pts    |
++----------------------------------------------------------+-----------+
+| Reproducibility and organization                         | 10 pts    |
++----------------------------------------------------------+-----------+
+| Team peer evaluation                                     | 10 pts    |
++----------------------------------------------------------+-----------+
+| Classmates' evaluation                                   | 5 pts     |
++----------------------------------------------------------+-----------+
+
+#### Criteria
+
+Your project will be assessed on the following criteria:
+
+-   Content - What is the quality of research and/or policy question and relevancy of data to those questions?
 -   Correctness - Are statistical procedures carried out and explained correctly?
 -   Writing and Presentation - What is the quality of the statistical presentation, writing, and explanations?
 -   Creativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?
@@ -193,7 +233,9 @@ A general breakdown of scoring is as follows:
 -   60%-69% - Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.
 -   Below 60% - Student is not making a sufficient effort.
 
-**Late penalty:**
+#### Team peer evaluation
 
--   Late, but within 24 hours of due date/time: -20% (only applies to written portion, there is no option to do your presentation later)
--   Any later: no credit
+You will be asked to fill out a survey where you rate the contribution and teamwork of each team member out of 10 points.
+You will additionally report a contribution percentage for each team member.
+Filling out the survey is a prerequisite for getting credit on the team member evaluation.If you are suggesting that an individual did less than 20% of the work, please provide some explanation.
+If any individual gets an average peer score indicating that they did less than 10% of the work, this person will receive half the grade of the rest of the group.

---FILE: 02-videos.Rmd---
@@ -1,3 +0,0 @@
-# Videos {#videos}
-
-Unfortunately there is not much here yet, but just like everyone else, I will be making videos for my course in Fall 2020 and will be linking them here as I make them.

---FILE: 03-access-r.Rmd---
@@ -4,7 +4,7 @@
 
 One of the design principles of this course is ""cherish day one"" -- get students from nothing to their first meaningful data visualization within the first 10 minutes of the course.
 Achieving this is possible, but requires careful consideration of the computing infrastructure.
-This section outlines how one can set up their course to run on RStudio Cloud, use GitHub for not only version control and collaboration but also the learning management system for the course, build their course materials with packages from the \*down universe (rmarkdown, blogdown, xaringan, etc.), and use Slack for course communication.
+This section outlines how one can set up their course to run on RStudio Cloud, use GitHub for not only version control and collaboration but also as the learning management system for the course, and build their course materials with packages from the `*down` universe (**rmarkdown**, **blogdown**, **xaringan**, etc.).
 Lastly, the alternative setups section describes other approaches to setting up the computing infrastructure that can be just as efficient and effective as the ones described in the main choices for the course, and discusses pros and cons.
 
 The RStudio IDE includes a viewable environment, a file browser, data viewer, and a plotting pane, which makes it less intimidating than the bare R shell.
@@ -13,7 +13,7 @@ Additionally, since it is a full fledged IDE, it also features integrated help,
 [RStudio Cloud](https://rstudio.cloud/) is a managed cloud instance of the RStudio IDE. We recommend having students access RStudio via RStudio Cloud as opposed to using a local installation.
 The main reason for this choice is reducing friction at first exposure to R.
 Local installation can be difficult to manage, both for the student and the instructor, and can shift the focus away from data science learning at the beginning of the course.
-In the pedagogical decisions section, we discuss in further detail the reasons for avoiding local installation at the beginning of the course and discuss when to introduce it later on in the course.
+We discuss in further detail the reasons for avoiding local installation at the beginning of the course in Section \@ref(design-principles).[^access-r-1]
 
 When you create an account on RStudio Cloud, you get a workspace of your own, and the projects you create here can be public or private.
 You can also add a new workspace and control its permissions, and the projects you create here can also be public or private.
@@ -98,32 +98,12 @@ This default has two advantages:
 2.  It means when a student creates a project in the workspace it's not, by default, visible to other students.
 
 When your project is ready to be shared with the students in your course, you can adjust the access level by clicking on the gear icon to reveal the settings menu.
+You should also check the ""Make this project an assignment"" box so that when a student starts their assignment RStudio Cloud automatically makes a copy of the project for them.
 
 ```{r rscloud-project-permissions, fig.align=""center"", echo=FALSE, fig.cap=""Setting project permissions within a workspace""}
 include_graphics(path = ""images/rscloud-project-permissions.png"")
 ```
 
-### Copying
-
-When a student clicks on your shared project, they are notified that this is a temporary copy (with red blinking text), and are given the option to make their own permanent copy of the project.
-This is the first thing a student should do when they start working on a project.
-
-When a student makes a copy of a project, a new project where they are the owner and that is only visible to them (and the admins and moderators of the space) is created.
-This copy contains all documents included in the original project and has all the packages installed (but not loaded) as well.
-
-```{r rscloud-project-copy, fig.align=""center"", echo=FALSE, fig.cap=""Making a copy of a project""}
-include_graphics(path = ""images/rscloud-project-copy.png"")
-```
-
-You will see in the above screenshot that the user (on the right) is not the admin of the course.
-This screenshot was taken when logged into the demo workspace as a student (contributor).
-I strongly recommend that instructors make a second account for themselves on RStudio Cloud and add that user as a contributor to the workspace to be able to see what your students see when they log in.
-It's a great way to test out functionality and resolve unexpected issues your students might encounter, before they encounter them.
-I recommend using an incognito browser window for the student account so that you can stay logged in both as a student and as the instructor at the same time and test the student view as you develop content as an instructor.
-
-One huge advantage of your students working in RStudio Cloud is that you as the instructor, and anyone with an admin and moderator role, can peek into student projects.
-While it is important for your students to learn to ask questions in a way that does not depend on someone else being able to see their work directly (and for this I strongly recommend teaching students to make [reprexes](https://www.tidyverse.org/help/#reprex)), it is sometimes, especially early on, nice to be able to peek into a student's project.
-
 ## Base project template
 
 If you consistently use a particular set of packages and/or need a particular set of documents to be included in each project, the base project template functionality will come in very handy.
@@ -137,6 +117,10 @@ include_graphics(path = ""images/rscloud-base-template.png"")
 
 Note that a project must be shared with everyone in the space in order to be used as a template; only projects which are viewable by everyone in the space will appear in the templates list.
 
+You can update your base project as many times as you want throughout the semester.
+The base template is applied prospectively -- it only effects projects created after the template has been set.
+Therefore updating the base project will not break projects already created with the previous version of a base project.
+
 ## Git integration
 
 It is possible to create (clone) a new project in RStudio Cloud from a GitHub repository, just like in the RStudio IDE.
@@ -147,24 +131,32 @@ include_graphics(path = ""images/rscloud-git-project.png"")
 
 If you have a base project template set up for your workspace, this new project created from GitHub will also have the packages installed in the base project template.
 
-For more on using Git and GitHub in the classroom, see [here][version\_control].
+For more on using Git and GitHub in the classroom, see Section \@ref(version-control).
+
+## Troubleshooting
+
+I strongly recommend that you make a second account for themselves on RStudio Cloud and add that user as a contributor to the workspace to be able to see what your students see when they log in.
+It's a great way to test out functionality and resolve unexpected issues your students might encounter, before they encounter them.
+I recommend using an incognito browser window for the student account so that you can stay logged in both as a student and as the instructor at the same time and test the student view as you develop content as an instructor.
+
+One huge advantage of your students working in RStudio Cloud is that you as the instructor, and anyone with an admin and moderator role, can peek into student projects.
+While it is important for your students to learn to ask questions in a way that does not depend on someone else being able to see their work directly (and for this I strongly recommend teaching students to make [reprexes](https://www.tidyverse.org/help/#reprex)), it is sometimes, especially early on, nice to be able to peek into a student's project.
 
 ## Limits
 
-### Memory
+### Memory & CPU
 
-Each project on RStudio Cloud is allocated 1 GB of RAM.
-While this is a pretty generous limit, actions like joining large tables or fitting complicated models could exceed the limit.
+Each project on RStudio Cloud is allocated 1 GB of RAM and 1 CPU by default.
+While this is a pretty generous limit, actions like joining very large tables or fitting complicated models could exceed the limit.
 
 I recommend testing out the any work you assign, especially those using large datasets, in order to avoid unexpected hiccups due to out of memory issues.
 One challenge is that you might have no control over what issues students might run into if they are working on an open ended project using a dataset of their own choice.
 In these circumstances it's helpful to keep in the back of your mind that one way an out of memory issue can present itself is with the RStudio Cloud project crashing.
 
-### Users / projects
+### Other limits
 
-Another limit that you will most likely hit when setting up your course on RStudio Cloud is that each account is allocated one private space, with up to three members and five projects.
-Once you hit this limit RStudio Cloud will prompt you to submit a request to the RStudio Cloud team for more capacity.
-Rest assured that this request will be approved.
+For most up to date information on limits on free RStudio Cloud accounts, as well as any other technical details, see the [RStudio Cloud Guide](https://rstudio.cloud/learn/guide#limits).
+This document gets updated as changes are made to the user interface and/or the backend of RStudio Cloud and should be assumed to be more current than the information outlined here.
 
 ## Learn more
 
@@ -173,3 +165,8 @@ To see this all in action and learn more, watch the following RStudio Cloud webi
 -   [Teaching R online with RStudio Cloud](https://mine-cetinkaya-rundel.github.io/teach-r-online/) (July 2020)
 -   [Teaching R online with RStudio Cloud](https://resources.rstudio.com/webinars/rstudio-cloud-in-the-classroom) (March 2020)
 -   [RStudio Cloud in the Classroom](https://resources.rstudio.com/webinars/rstudio-cloud-in-the-classroom)
+
+[^access-r-1]: Note that as of August 2020 RStudio Cloud offers paid tiers as well, and you will likely need a paid subscription to teach with RStudio Cloud (unless you're teaching a short, small course).
+    Depending on your institution's IT infrastructure and your class size, RStudio Cloud may or may not be the most economically feasible solution for your teaching needs.
+    See Section \@ref(alternative-setups) for suggestions for other setups for providing server access to RStudio for your students.
+    Note that these alternatives generally require system infrastructure expertiose or IT professional time.

---FILE: 03-discussion.Rmd---
@@ -1,10 +1,11 @@
 # Discussion {#discussion}
 
-Our recommended tool for course discussion is [Piazza](http://piazza.com/).
+My recommended tool for course discussion is [Piazza](http://piazza.com/).
 
-We have, in the past, used Slack for course communication as well.
+I have, in the past, used Slack for course communication as well.
 Slack has the advantage of being real-life feeling as well as being the communication tool of choice for many data science teams.
-However it doesn't work well for class discussion as threading and searchability are poor.
-Additionally, the instructor does not have the option to edit student questions, which is frustrating if they have not formatted their code appropriately.
+However it doesn't work well for lasting class discussions as threading and searchability are poor.
+Additionally, the instructor does not have the option to edit student questions, which can be frustrating if they have not formatted their code appropriately.
+Similar tools like Discord and MS Teams have similar advantages when it comes to real-life discussions and similar disadvantages when it comes to threading and searchability.
 
-Other options are GitHub issues and Gitter, especially for courses using version control.
+Other options are GitHub issues and GitHub Discussions, especially for courses using version control.

---FILE: 03-version-control.Rmd---
@@ -69,7 +69,7 @@ If you would like to learn more about teaching with version control, I recommend
 
 > Beckman, M. D., √áetinkaya-Rundel, M., Horton, N. J., Rundel, C. W., Sullivan, A. J., & Tackett, M.
 > (2020).
-> Implementing version control with Git as a learning objective in statistics courses.
-> [arxiv.org/abs/2001.01988](https://arxiv.org/abs/2001.01988)
+> Implementing version control with Git and GitHub as a learning objective in statistics and data science courses.
+> [doi.org/10.1080/10691898.2020.1848485](https://doi.org/10.1080/10691898.2020.1848485)
 
 If you would like to learn more about using version control with R, I strongly recommend [Happy Git with R](https://happygitwithr.com/).

---FILE: 04-pedagogy.Rmd---
@@ -6,7 +6,8 @@
 
 The following resources describe the pedagogy used in designing and teaching a course with the materials provided in this resources.
 
-> Mine √áetinkaya-Rundel & Victoria Ellison (In press), A fresh look at introductory data science, *Journal of Statistics Education*.
+> Mine √áetinkaya-Rundel & Victoria Ellison.
+> A fresh look at introductory data science, *Journal of Statistics Education*.
 > [doi.org/10.1080/10691898.2020.1804497](https://doi.org/10.1080/10691898.2020.1804497).
 
 > Talk: The art and science of teaching data science [[Slides]](https://speakerdeck.com/minecr/the-art-and-science-of-teaching-data-science-university-of-glasgow)

---FILE: 04-schedule.Rmd---
@@ -5,228 +5,340 @@ The following are two options for course schedules, one for a 11-week course and
 
 ## 11-week schedule
 
-+-------+--------+-------------------------------------------------------+--------------+
-| Unit  | Week   | Title                                                 | Type         |
-+=======+========+=======================================================+==============+
-| 1     | 1      | Welcome to data science!                              | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 1      | Meet the toolkit                                      | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 1      | Hello R                                               | Lab          |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 1      | Edinburgh Airbnb rentals                              | Homework     |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **2**  | **Data and visualization**                            | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **2**  | **Building plots for various data types**             | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **2**  | **Plastic waste**                                     | **Lab**      |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **2**  | **North Carolina bike crashes**                       | **Homework** |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 3      | Tidy data and data wrangling                          | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 3      | Joining data from multiple sources                    | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 3      | Data tidying and reshaping                            | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 3      | Nobel laureates                                       | Lab          |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 3      | What should I major in?                               | Homework     |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **4**  | **Data types and recoding**                           | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **4**  | **Importing data**                                    | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **4**  | **La Quinta is Spanish for 'next to Denny's', Pt. 1** | **Lab**      |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **4**  | **La Quinta is Spanish for 'next to Denny's', Pt. 2** | **Homework** |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 5      | Tips for effective data visualization                 | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 5      | Scientific studies and confounding                    | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 5      | Communicating data science results effectively        | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 5      | Ugly charts + Merge conflict                          | Lab          |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 5      | Legos and instructors                                 | Homework     |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **6**  | **Web scraping**                                      | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **6**  | **Functions and iteration**                           | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **6**  | **University of Edinburgh Art Collection**            | **Lab**      |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **6**  | **Money in politics**                                 | **Homework** |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **6**  | **Project proposal**                                  |              |
-+-------+--------+-------------------------------------------------------+--------------+
-| 2     | 7      | The language of models                                | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 2     | 7      | Linear models with a single predictor                 | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 2     | 7      | Grading the professor, Pt. 1                          | Lab          |
-+-------+--------+-------------------------------------------------------+--------------+
-| 2     | 7      | Project proposal peer review                          | Homework     |
-+-------+--------+-------------------------------------------------------+--------------+
-| **2** | **8**  | **Modeling non-linear relationships**                 | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **2** | **8**  | **Linear models with multiple predictors**            | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **2** | **8**  | **Grading the professor, Pt. 2**                      | **Lab**      |
-+-------+--------+-------------------------------------------------------+--------------+
-| **2** | **8**  | **Bike rentals in DC**                                | **Homework** |
-+-------+--------+-------------------------------------------------------+--------------+
-| 2     | 9      | Model selection                                       | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 2     | 9      | Model validation                                      | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 2     | 9      | Working on projects                                   | Lab          |
-+-------+--------+-------------------------------------------------------+--------------+
-| 2     | 9      | Work on projects                                      | Homework     |
-+-------+--------+-------------------------------------------------------+--------------+
-| **2** | **10** | **Logistic regression and classification**            | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **2** | **10** | **Quantifying uncertainty**                           | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **2** | **10** | **Collaborating on GitHub**                           | **Lab**      |
-+-------+--------+-------------------------------------------------------+--------------+
-| **2** | **10** | **Wrapping up**                                       | **Homework** |
-+-------+--------+-------------------------------------------------------+--------------+
-| 3     | 11     | Data science ethics                                   | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 3     | 11     | Text analysis                                         | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 3     | 11     | Project presentations & write up                      |              |
-+-------+--------+-------------------------------------------------------+--------------+
++-------+--------+---------------------------------------------------------------+--------------------------+
+| Unit  | Week   | Title                                                         | Type                     |
++=======+========+===============================================================+==========================+
+| 1     | 1      | Welcome to data science!                                      | Lecture                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 1     | 1      | Meet the toolkit: Programming                                 | Lecture                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 1     | 1      | Meet the toolkit: Version control & collaboration             | Lecture                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 1     | 1      | Hello R                                                       | Lab                      |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 1     | 1      | Pet names                                                     | Homework                 |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **2** | **2**  | **Data and visualisation**                                    | **Lecture**              |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **2** | **2**  | **Visualising data with ggplot2**                             | **Lecture**              |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **2** | **2**  | **Visualising numerical data**                                | **Lecture**              |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **2** | **2**  | **Visualising categorical data**                              | **Lecture**              |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **2** | **2**  | **StarWars + Dataviz**                                        | **Application exercise** |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **2** | **2**  | **Plastic waste**                                             | **Lab**                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **2** | **2**  | **Airbnb listings in Edinburgh**                              | **Homework**             |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 2     | 3      | Tidy data                                                     | Lecture                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 2     | 3      | Grammar of data wrangling                                     | Lecture                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 2     | 3      | Working with a single data frame                              | Lecture                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 2     | 3      | Working with multiple data frames                             | Lecture                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 2     | 3      | Tidying data                                                  | Lecture                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 2     | 3      | Hotels + Data wrangling                                       | Application exercise     |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 2     | 3      | Nobel laureates                                               | Lab                      |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 2     | 3      | Road traffic accidents                                        | Homework                 |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **2** | **4**  | **Data types**                                                | **Lecture**              |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **2** | **4**  | **Data classes**                                              | **Lecture**              |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **2** | **4**  | **Importing data**                                            | **Lecture**              |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **2** | **4**  | **Recoding data**                                             | **Lecture**              |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **2** | **4**  | **Hotels + Data types**                                       | **Application exercise** |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **2** | **4**  | **Nobels + Sales + Data import**                              | **Application exercise** |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **2** | **4**  | **Option 1: La Quinta is Spanish for next to Denny's, Pt. 1** | **Lab**                  |
+|       |        |                                                               |                          |
+|       |        | **Option 2: La Quinta is Spanish for next to Denny's, Pt. 2** |                          |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **2** | **4**  | **College majors**                                            | **Homework**             |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 2     | 5      | Tips for effective data visualization                         | Lecture                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 2     | 5      | Brexit + Telling stories with dataviz                         | Application exercise     |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 2     | 5      | Scientific studies and confounding                            | Lecture                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 2     | 5      | Simpson's paradox                                             | Lecture                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 2     | 5      | Doing data science                                            | Lecture                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 2     | 5      | Option 1: Take a sad plot and make it better                  | Lab                      |
+|       |        |                                                               |                          |
+|       |        | Option 2: Simpson's paradox                                   |                          |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 2     | 5      | Legos                                                         | Homework                 |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **2** | **6**  | **Web scraping**                                              | **Lecture**              |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **2** | **6**  | **Scraping top 250 movies on IMDB**                           | **Lecture**              |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **2** | **6**  | **Web scraping considerations**                               | **Lecture**              |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **2** | **6**  | **IMDB + Web scraping**                                       | **Application exercise** |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **2** | **6**  | **Functions**                                                 | **Lecture**              |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **2** | **6**  | **Iteration**                                                 | **Lecture**              |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **2** | **6**  | **University of Edinburgh Art Collection**                    | **Lab**                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **2** | **6**  | **Money in politics**                                         | **Homework**             |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 3     | 7      | Misrepresentation                                             | Lecture                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 3     | 7      | Data privacy                                                  | Lecture                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 3     | 7      | Algorithmic bias                                              | Lecture                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 3     | 7      | Conveying the right message through visualisation             | Lab                      |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 3     | 7      | Project proposals                                             | Project                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **4** | **8**  | **Fitting and interpreting models**                           | **Lecture**              |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **4** | **8**  | **Modelling nonlinear relationships**                         | **Lecture**              |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **4** | **8**  | **Models with multiple predictors**                           | **Lecture**              |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **4** | **8**  | **More models with multiple predictors**                      | **Lecture**              |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **4** | **8**  | **Grading the professor, Pt 1**                               | **Lab**                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **4** | **8**  | **Option 1: Bike rentals in DC**                              | **Homework**             |
+|       |        |                                                               |                          |
+|       |        | **Option 2: Peer review of project proposals**                |                          |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 4     | 9      | Logistic regression                                           | Lecture                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 4     | 9      | Prediction and overfitting                                    | Lecture                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 4     | 9      | Feature engineering                                           | Lecture                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 4     | 9      | Grading the professor, Pt 1                                   | Lab                      |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 4     | 9      | Exploring the GSS                                             | Homework                 |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **4** | **10** | **Cross validation**                                          | **Lecture**              |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **4** | **10** | **The Office, Part 1**                                        | **Application exercise** |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **4** | **10** | **The Office, Part 2**                                        | **Application exercise** |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **4** | **10** | **Quantifying uncertainty**                                   | **Lecture**              |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **4** | **10** | **Bootstrapping**                                             | **Lecture**              |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **4** | **10** | **Option 1: Smoking during pregnancy**                        | **Lab**                  |
+|       |        |                                                               |                          |
+|       |        | **Option 2: Work on projects**                                |                          |
+|       |        |                                                               |                          |
+|       |        | **Option 3: Collaboration on GitHub**                         |                          |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| **4** | **10** | **Modelling the GSS**                                         | **Homework**             |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 5     | 11     | Text analysis                                                 | Lecture                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 5     | 11     | Comparing texts                                               | Lecture                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 5     | 11     | Interactive web apps                                          | Lecture                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 5     | 11     | Machine learning                                              | Lecture                  |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 5     | 11     | Project presentations                                         | Lab                      |
++-------+--------+---------------------------------------------------------------+--------------------------+
+| 5     | 11     | Wrap up                                                       | Homework                 |
++-------+--------+---------------------------------------------------------------+--------------------------+
 
 ## 15-week schedule
 
-+-------+--------+-------------------------------------------------------+--------------+
-| Unit  | Week   | Title                                                 | Type         |
-+=======+========+=======================================================+==============+
-| 1     | 1      | Welcome to data science!                              | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 1      | Meet the toolkit                                      | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 1      | Hello R                                               | Lab          |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 1      | Edinburgh Airbnb rentals                              | Homework     |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **2**  | **Data and visualization**                            | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **2**  | **Building plots for various data types**             | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **2**  | **Plastic waste**                                     | **Lab**      |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **2**  | **North Carolina bike crashes**                       | **Homework** |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 3      | Tidy data and data wrangling                          | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 3      | Joining data from multiple sources                    | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 3      | Nobel laureates                                       | Lab          |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 3      | What should I major in?                               | Homework     |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **4**  | **Data tidying and reshaping**                        | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **4**  | **Data types and recoding**                           | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **4**  | **La Quinta is Spanish for 'next to Denny's', Pt. 1** | **Lab**      |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **4**  | **La Quinta is Spanish for 'next to Denny's', Pt. 2** | **Homework** |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 5      | Tips for effective data visualization                 | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 5      | Scientific studies and confounding                    | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 5      | Communicating data science results effectively        | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 5      | Ugly charts                                           | Lab          |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 5      | Legos and instructors                                 | Homework     |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **6**  | **Importing data**                                    | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **6**  | **Web scraping**                                      | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **6**  | **Work on projects**                                  | **Lab**      |
-+-------+--------+-------------------------------------------------------+--------------+
-| **1** | **6**  | **Project proposal**                                  | **Homework** |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 7      | Functions and iteration                               | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 7      | Exploring data review[^schedule-1]                    | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 7      | University of Edinburgh Art Collection                | Lab          |
-+-------+--------+-------------------------------------------------------+--------------+
-| 1     | 7      | Peer review of project proposals                      | Homework     |
-+-------+--------+-------------------------------------------------------+--------------+
-| **2** | **8**  | **The language of models**                            | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **2** | **8**  | **Linear models with a single predictor**             | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **2** | **8**  | **Work on projects**                                  | **Lab**      |
-+-------+--------+-------------------------------------------------------+--------------+
-| **2** | **8**  | **Money in politics**                                 | **Homework** |
-+-------+--------+-------------------------------------------------------+--------------+
-| 2     | 9      | Modeling non-linear relationships                     | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 2     | 9      | Linear models with multiple predictors                | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 2     | 9      | Grading the professor, Pt. 1                          | Lab          |
-+-------+--------+-------------------------------------------------------+--------------+
-| 2     | 9      | Bike rentals in DC                                    | Homework     |
-+-------+--------+-------------------------------------------------------+--------------+
-| **2** | **10** | **Model selection**                                   | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **2** | **10** | **Model validation**                                  | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **2** | **10** | **Grading the professor, Pt. 2**                      | **Lab**      |
-+-------+--------+-------------------------------------------------------+--------------+
-| **2** | **10** | ***[Not available]***                                 | **Homework** |
-+-------+--------+-------------------------------------------------------+--------------+
-| 2     | 11     | Logistic regression and classification                | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 2     | 11     | Quantifying uncertainty                               | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 2     | 11     | *[Not available]*                                     | Lab          |
-+-------+--------+-------------------------------------------------------+--------------+
-| 2     | 11     | *[Not available]*                                     | Homework     |
-+-------+--------+-------------------------------------------------------+--------------+
-| **2** | **12** | **Hypothesis testing with randomization**             | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **2** | **12** | **Inference overview**                                | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **2** | **12** | **So what if you smoke when pregnant?**               | **Lab**      |
-+-------+--------+-------------------------------------------------------+--------------+
-| **2** | **12** | **Exploring the General Social Survey**               | **Homework** |
-+-------+--------+-------------------------------------------------------+--------------+
-| 2     | 13     | Simulation based inference review                     | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 3     | 13     | Data science ethics                                   | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 3     | 13     | Working on projects                                   | Lab          |
-+-------+--------+-------------------------------------------------------+--------------+
-| 3     | 13     | Wrapping up                                           | Homework     |
-+-------+--------+-------------------------------------------------------+--------------+
-| **3** | **14** | **Interactive data visualization**                    | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **3** | **14** | **Interactive data visualization and reporting**      | **Lecture**  |
-+-------+--------+-------------------------------------------------------+--------------+
-| **3** | **14** | **Collaborating on GitHub**                           | **Lab**      |
-+-------+--------+-------------------------------------------------------+--------------+
-| **3** | **14** | **Work on projects**                                  | **Homework** |
-+-------+--------+-------------------------------------------------------+--------------+
-| 3     | 15     | Bayesian inference                                    | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 3     | 15     | Text analysis                                         | Lecture      |
-+-------+--------+-------------------------------------------------------+--------------+
-| 3     | 15     | Work on projects                                      | Lab          |
-+-------+--------+-------------------------------------------------------+--------------+
-| 3     | 15     | Project presentations & write up                      |              |
-+-------+--------+-------------------------------------------------------+--------------+
-
-[^schedule-1]: Slides not included in Data Science Course in a Box.
++-------+--------+-----------------------------------------------------+-----------------------------+
+| Unit  | Week   | Title                                               | Type                        |
++=======+========+=====================================================+=============================+
+| 1     | 1      | Welcome to data science!                            | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 1     | 1      | Meet the toolkit: Programming                       | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 1     | 1      | Meet the toolkit: Version control & collaboration   | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 1     | 1      | Hello R                                             | Lab                         |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 1     | 1      | Pet names                                           | Homework                    |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **2** | **2**  | **Data and visualisation**                          | **Lecture**                 |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **2** | **2**  | **Visualising data with ggplot2**                   | **Lecture**                 |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **2** | **2**  | **Visualising numerical data**                      | **Lecture**                 |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **2** | **2**  | **Visualising categorical data**                    | **Lecture**                 |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **2** | **2**  | **StarWars + Dataviz**                              | **Application exercise**    |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **2** | **2**  | **Plastic waste**                                   | **Lab**                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **2** | **2**  | **Airbnb listings in Edinburgh**                    | **Homework**                |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 2     | 3      | Tidy data                                           | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 2     | 3      | Grammar of data wrangling                           | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 2     | 3      | Working with a single data frame                    | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 2     | 3      | Working with multiple data frames                   | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 2     | 3      | Tidying data                                        | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 2     | 3      | Hotels + Data wrangling                             | Application exercise        |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 2     | 3      | Nobel laureates                                     | Lab                         |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 2     | 3      | Road traffic accidents                              | Homework                    |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **2** | **4**  | **Data types**                                      | **Lecture**                 |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **2** | **4**  | **Data classes**                                    | **Lecture**                 |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **2** | **4**  | **Recoding data**                                   | **Lecture**                 |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **2** | **4**  | **Hotels + Data types**                             | **Application exercise**    |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **2** | **4**  | **La Quinta is Spanish for next to Denny's, Pt. 1** | **Lab**                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **2** | **4**  | **College majors**                                  | **Homework**                |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 2     | 5      | Importing data                                      | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 2     | 5      | Nobels + Sales + Data import                        | Application exercise        |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 2     | 5      | Tips for effective data visualization               | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 2     | 5      | Brexit + Telling stories with dataviz               | Application exercise        |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 2     | 5      | Take a sad plot and make it better                  | Lab                         |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 2     | 5      | La Quinta is Spanish for next to Denny's, Pt. 2     | Homework                    |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **2** | **6**  | **Scientific studies and confounding**              | **Lecture**                 |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **2** | **6**  | **Simpson's paradox**                               | **Lecture**                 |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **2** | **6**  | **Doing data science**                              | **Lecture**                 |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **2** | **6**  | **Simpson's paradox**                               | **Lab**                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **2** | **6**  | **Legos**                                           | **Homework**                |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 2     | 7      | Web scraping                                        | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 2     | 7      | Scraping top 250 movies on IMDB                     | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 2     | 7      | Web scraping considerations                         | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 2     | 7      | IMDB + Web scraping                                 | Application exercise        |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 2     | 7      | Work on projects                                    | Lab                         |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 2     | 7      | Work on projects                                    | Homework                    |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **2** | **8**  | **Functions**                                       | **Lecture**                 |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **2** | **8**  | **Iteration**                                       | **Lecture**                 |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **2** | **8**  | **University of Edinburgh Art Collection**          | **Lab**                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **2** | **8**  | **Money in politics**                               | **Homework**                |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 3     | 9      | Misrepresentation                                   | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 3     | 9      | Data privacy                                        | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 3     | 9      | Algorithmic bias                                    | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 3     | 9      | Conveying the right message through visualisation   | Lab                         |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 3     | 9      | Project proposals                                   | Project                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 3     | 9      | Peer review of project proposals                    | Homework                    |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **4** | **10** | **Fitting and interpreting models**                 | **Lecture**                 |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **4** | **10** | **Modelling nonlinear relationships**               | **Lecture**                 |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **4** | **10** | **Models with multiple predictors**                 | **Lecture**                 |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **4** | **10** | **More models with multiple predictors**            | **Lecture**                 |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **4** | **10** | **Grading the professor, Pt 1**                     | **Lab**                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **4** | **10** | **Bike rentals in DC**                              | **Homework**                |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 4     | 11     | Logistic regression                                 | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 4     | 11     | Prediction and overfitting                          | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 4     | 11     | Feature engineering                                 | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 4     | 11     | Grading the professor, Pt. 1                        | Lab                         |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 4     | 11     | Exploring the GSS                                   | Homework                    |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **4** | **12** | **Cross validation**                                | **Lecture**                 |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **4** | **12** | **The Office, Part 1**                              | **Application exercise**    |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **4** | **12** | **The Office, Part 2**                              | **Application exercise**    |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **4** | **12** | **Bootstrapping**                                   | **Lecture**                 |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **4** | **12** | **Work on projects**                                | **Lab**                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **4** | **12** | **Grading the professor, Pt. 2**                    | **Homework**                |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 4     | 13     | Quantifying uncertainty                             | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 4     | 13     | Bootstrapping                                       | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 4     | 13     | Hypothesis testing                                  | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 4     | 13     | Inference overview                                  | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 4     | 13     | Smoking during pregnancy                            | Lab                         |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 4     | 13     | Modelling the GSS                                   | Homework                    |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **5** | **14** | **Text analysis**                                   | **Lecture**                 |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **5** | **14** | **Comparing texts**                                 | **Lecture**                 |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **5** | **14** | **Interactive web apps**                            | **Lecture**                 |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **5** | **14** | **Machine learning**                                | **Lecture**                 |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **5** | **14** | **Collaborating on GitHub**                         | **Lab**                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| **5** | **14** | **Wrap up**                                         | **Homework**                |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 5     | 15     | Bayesian inference                                  | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 5     | 15     | Building interactive web apps, Pt. 1                | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 5     | 15     | Building interactive web apps, Pt. 1                | Lecture                     |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 5     | 15     | Project presentations                               | Lab                         |
++-------+--------+-----------------------------------------------------+-----------------------------+
+| 5     | 15     | N/A                                                 | Homework                    |
++-------+--------+-----------------------------------------------------+-----------------------------+

---FILE: _bookdown.yml---
@@ -15,11 +15,11 @@ rmd_files: [
   
   ""02-hello-world.Rmd"",
   ""02-exploring-data.Rmd"",
+  ""02-ethics.Rmd"",
   ""02-making-rigorous-conclusions.Rmd"",
-  ""02-looking-forward.Rmd"",
+  ""02-looking-further.Rmd"",
   ""02-interactive-tutorials.Rmd"",
   ""02-project.Rmd"",
-  ""02-videos.Rmd"",
   ""02-exams.Rmd"",
 
   ""03-access-r.Rmd"",

---FILE: _output.yml---
@@ -1,5 +1,5 @@
 bookdown::gitbook:
-  css: [css/style.css, css/dsbox.css]
+  css: [css/style.css, css/dsbox.css, css/fontawesome/css/all.css]
   config:
     toc:
       collapse: section

---FILE: course-materials/application-exercises/README.md---
@@ -0,0 +1,3 @@
+# README
+
+You can try out the application exercises on RStudio Cloud. To join the RStudio Cloud workspace for Data Science course in a Box, click [here](https://rstudio.cloud/spaces/1655/join?access_code=5rdjusfIYF5iI0Gum2vNsBDLdtdnIEELBkf2EivK).

---FILE: course-materials/application-exercises/ae-01a-un-votes/unvotes.Rmd---
@@ -1,25 +1,17 @@
 ---
 title: ""UN Votes""
 author: ""Mine √áetinkaya-Rundel""
-date: ""`r Sys.Date()`""
-output: 
-  html_document: 
-    toc: yes
-    toc_float: yes
+output: github_document
 ---
 
 ## Introduction
 
-How do various countries vote in the United Nations General Assembly, how have 
-their voting patterns evolved throughout time, and how similarly or differently 
-do they view certain issues? Answering these questions (at a high level) is the 
-focus of this analysis.
+How do various countries vote in the United Nations General Assembly, how have their voting patterns evolved throughout time, and how similarly or differently do they view certain issues?
+Answering these questions (at a high level) is the focus of this analysis.
 
 ### Packages
 
-We will use the __tidyverse__, __lubridate__, and __scales__ packages for the 
-data wrangling and visualization, and the __DT__ package for interactive display 
-of tabular output.
+We will use the **tidyverse**, **lubridate**, and **scales** packages for the data wrangling and visualization, and the **DT** package for interactive display of tabular output.
 
 ```{r load-packages, warning=FALSE, message=FALSE}
 library(tidyverse)
@@ -30,25 +22,19 @@ library(DT)
 
 ### Data
 
-The data we're using originally come from the **unvotes** package, but it's been 
-modified a bit (by joining the various data frames provided in the package) to 
-help you get started with the analysis.
+The data we're using originally come from the **unvotes** package, but it's been modified a bit (by joining the various data frames provided in the package) to help you get started with the analysis.
 
 ```{r load-data}
 unvotes <- read_rds(""data/unvotes.rds"")
 ```
 
+## UN voting patterns
 
-## UN voting patterns {#voting}
+Let's create a data visualization that displays how the voting record of the UK & NI changed over time on a variety of issues, and compares it to two other countries: US and Turkey.
 
-Let's  create a data visualization that displays how the voting record of the 
-UK & NI changed over time on a variety of issues, and compares it 
-to two other countries: US and Turkey.
-
-We can easily change which countries are being plotted by changing which 
-countries the code above `filter`s for. Note that the country name should be 
-spelled and capitalized exactly the same way as it appears in the data. See 
-the [Appendix](#appendix) for a list of the countries in the data.
+We can easily change which countries are being plotted by changing which countries the code above `filter`s for.
+Note that the country name should be spelled and capitalized exactly the same way as it appears in the data.
+See the [Appendix](#appendix) for a list of the countries in the data.
 
 ```{r plot-yearly-yes-issue, fig.width=10, fig.height=6, message=FALSE}
 unvotes %>%
@@ -70,19 +56,13 @@ unvotes %>%
   )
 ```
 
+## References
 
-## References {#references}
-
-1. David Robinson (2017). [unvotes](https://CRAN.R-project.org/package=unvotes): 
-   United Nations General Assembly Voting Data. R package version 0.2.0.
-1. Erik Voeten ""Data and Analyses of Voting in the UN General Assembly"" 
-   Routledge Handbook of International Organization, edited by Bob Reinalda 
-   (published May 27, 2013).
-1. Much of the analysis has been modeled on the examples presented in the 
-   [unvotes package vignette](https://cran.r-project.org/web/packages/unvotes/vignettes/unvotes.html).
-
+1.  David Robinson (2017). [unvotes](https://CRAN.R-project.org/package=unvotes): United Nations General Assembly Voting Data. R package version 0.2.0.
+2.  Erik Voeten ""Data and Analyses of Voting in the UN General Assembly"" Routledge Handbook of International Organization, edited by Bob Reinalda (published May 27, 2013).
+3.  Much of the analysis has been modeled on the examples presented in the [unvotes package vignette](https://cran.r-project.org/web/packages/unvotes/vignettes/unvotes.html).
 
-## Appendix {#appendix}
+## Appendix
 
 Below is a list of countries in the dataset:
 

---FILE: course-materials/application-exercises/ae-01a-un-votes/unvotes.md---
@@ -0,0 +1,85 @@
+UN Votes
+================
+Mine √áetinkaya-Rundel
+
+## Introduction
+
+How do various countries vote in the United Nations General Assembly,
+how have their voting patterns evolved throughout time, and how
+similarly or differently do they view certain issues? Answering these
+questions (at a high level) is the focus of this analysis.
+
+### Packages
+
+We will use the **tidyverse**, **lubridate**, and **scales** packages
+for the data wrangling and visualization, and the **DT** package for
+interactive display of tabular output.
+
+``` r
+library(tidyverse)
+library(lubridate)
+library(scales)
+library(DT)
+```
+
+### Data
+
+The data we‚Äôre using originally come from the **unvotes** package, but
+it‚Äôs been modified a bit (by joining the various data frames provided in
+the package) to help you get started with the analysis.
+
+``` r
+unvotes <- read_rds(""data/unvotes.rds"")
+```
+
+## UN voting patterns
+
+Let‚Äôs create a data visualization that displays how the voting record of
+the UK & NI changed over time on a variety of issues, and compares it to
+two other countries: US and Turkey.
+
+We can easily change which countries are being plotted by changing which
+countries the code above `filter`s for. Note that the country name
+should be spelled and capitalized exactly the same way as it appears in
+the data. See the [Appendix](#appendix) for a list of the countries in
+the data.
+
+``` r
+unvotes %>%
+  filter(country %in% c(""UK & NI"", ""US"", ""Turkey"")) %>%
+  mutate(year = year(date)) %>%
+  group_by(country, year, issue) %>%
+  summarize(percent_yes = mean(vote == ""yes"")) %>%
+  ggplot(mapping = aes(x = year, y = percent_yes, color = country)) +
+  geom_point(alpha = 0.4) +
+  geom_smooth(method = ""loess"", se = FALSE) +
+  facet_wrap(~issue) +
+  scale_y_continuous(labels = percent) +
+  labs(
+    title = ""Percentage of 'Yes' votes in the UN General Assembly"",
+    subtitle = ""1946 to 2015"",
+    y = ""% Yes"",
+    x = ""Year"",
+    color = ""Country""
+  )
+```
+
+![](unvotes_files/figure-gfm/plot-yearly-yes-issue-1.png)<!-- -->
+
+## References
+
+1.  David Robinson (2017).
+    [unvotes](https://CRAN.R-project.org/package=unvotes): United
+    Nations General Assembly Voting Data. R package version 0.2.0.
+2.  Erik Voeten ‚ÄúData and Analyses of Voting in the UN General Assembly‚Äù
+    Routledge Handbook of International Organization, edited by Bob
+    Reinalda (published May 27, 2013).
+3.  Much of the analysis has been modeled on the examples presented in
+    the [unvotes package
+    vignette](https://cran.r-project.org/web/packages/unvotes/vignettes/unvotes.html).
+
+## Appendix
+
+Below is a list of countries in the dataset:
+
+![](unvotes_files/figure-gfm/list-countries-1.png)<!-- -->

---FILE: course-materials/application-exercises/ae-01b-covid/covid.Rmd---
@@ -1,26 +1,26 @@
 ---
 title: ""Cumulative deaths from COVID-19""
 author: ""Mine √áetinkaya-Rundel""
-date: ""`r Sys.Date()`""
-output: 
-  html_document: 
-    toc: yes
-    toc_float: yes
+output: github_document
 ---
 
 ## Introduction
 
-Countries around the world are responding to an outbreak of respiratory illness caused by a novel coronavirus, COVID-19. The outbreak first started in Wuhan, China, but cases have been identified in a growing number of other locations internationally, including the United States. In this report we explore how the trajectory of the cumulative deaths in a number of countries.
+Countries around the world are responding to an outbreak of respiratory illness caused by a novel coronavirus, COVID-19.
+The outbreak first started in Wuhan, China, but cases have been identified in a growing number of other locations internationally, including the United States.
+In this report we explore how the trajectory of the cumulative deaths in a number of countries.
 
-The data come from the **coronavirus** package, which pulls data from the Johns Hopkins University Center for Systems Science and Engineering (JHU CCSE) Coronavirus repository. The coronavirus package provides a tidy format dataset of the 2019 Novel Coronavirus COVID-19 (2019-nCoV) epidemic. The package is available on GitHub [here](https://github.com/RamiKrispin/coronavirus) and is updated daily.
+The data come from the **coronavirus** package, which pulls data from the Johns Hopkins University Center for Systems Science and Engineering (JHU CCSE) Coronavirus repository.
+The coronavirus package provides a tidy format dataset of the 2019 Novel Coronavirus COVID-19 (2019-nCoV) epidemic.
+The package is available on GitHub [here](https://github.com/RamiKrispin/coronavirus) and is updated daily.
 
 For our analysis, in addition to the coronavirus package, we will use the following packages for data wrangling and visualisation.
 
-- **tidyverse** for data wrangling and visualization
-- **lubridate** package for handling dates
-- **glue** package for constructing text strings
-- **scales** package for formatting axis labels
-- **ggrepel** package for pretty printing of country labels
+-   **tidyverse** for data wrangling and visualization
+-   **lubridate** package for handling dates
+-   **glue** package for constructing text strings
+-   **scales** package for formatting axis labels
+-   **ggrepel** package for pretty printing of country labels
 
 We will make use of the **DT** package for interactive display of tabular output in the Appendix.
 
@@ -36,7 +36,11 @@ library(DT)
 
 ## Data prep
 
-The data frame called `coronavirus` in the coronavirus package provides a daily summary of the Coronavirus (COVID-19) cases by country. Each row in the data frame represents a country (or, where relevant, state/province). A full list of the countries in the data frame is provided in the [Appendix]. Note that the data provided in this package provides daily number of deaths, confirmed cases, and recovered cases. For this report, we will focus on the deaths. 
+The data frame called `coronavirus` in the coronavirus package provides a daily summary of the Coronavirus (COVID-19) cases by country.
+Each row in the data frame represents a country (or, where relevant, state/province).
+A full list of the countries in the data frame is provided in the [Appendix].
+Note that the data provided in this package provides daily number of deaths, confirmed cases, and recovered cases.
+For this report, we will focus on the deaths.
 
 We will start by making our selection for the countries we want to explore.
 
@@ -50,7 +54,8 @@ countries <- c(
 )
 ```
 
-In the following code chunk we filter the data frame for deaths in the countries we specified above and calculate cumulative number of deaths. We will only visualise data since 10th confirmed death. 
+In the following code chunk we filter the data frame for deaths in the countries we specified above and calculate cumulative number of deaths.
+We will only visualise data since 10th confirmed death.
 
 ```{r prep-country-data}
 country_data <- coronavirus %>%
@@ -99,7 +104,8 @@ These data are as of `r as_of_date_formatted`.
 
 ## Visualisation
 
-The following visualisation shows the number of cumulative cases vs. days elapsed since the 10th confirmed death in each country. The time span plotted for each country varies since some countries started seeing (and reporting) deaths from COVID-19 much later than others.
+The following visualisation shows the number of cumulative cases vs. days elapsed since the 10th confirmed death in each country.
+The time span plotted for each country varies since some countries started seeing (and reporting) deaths from COVID-19 much later than others.
 
 ```{r visualise, warning=FALSE}
 ggplot(data = country_data,

---FILE: course-materials/application-exercises/ae-01b-covid/covid.md---
@@ -0,0 +1,161 @@
+Cumulative deaths from COVID-19
+================
+Mine √áetinkaya-Rundel
+
+## Introduction
+
+Countries around the world are responding to an outbreak of respiratory
+illness caused by a novel coronavirus, COVID-19. The outbreak first
+started in Wuhan, China, but cases have been identified in a growing
+number of other locations internationally, including the United States.
+In this report we explore how the trajectory of the cumulative deaths in
+a number of countries.
+
+The data come from the **coronavirus** package, which pulls data from
+the Johns Hopkins University Center for Systems Science and Engineering
+(JHU CCSE) Coronavirus repository. The coronavirus package provides a
+tidy format dataset of the 2019 Novel Coronavirus COVID-19 (2019-nCoV)
+epidemic. The package is available on GitHub
+[here](https://github.com/RamiKrispin/coronavirus) and is updated daily.
+
+For our analysis, in addition to the coronavirus package, we will use
+the following packages for data wrangling and visualisation.
+
+-   **tidyverse** for data wrangling and visualization
+-   **lubridate** package for handling dates
+-   **glue** package for constructing text strings
+-   **scales** package for formatting axis labels
+-   **ggrepel** package for pretty printing of country labels
+
+We will make use of the **DT** package for interactive display of
+tabular output in the Appendix.
+
+``` r
+library(coronavirus) # devtools::install_github(""RamiKrispin/coronavirus"")
+library(tidyverse)
+library(lubridate)
+library(glue)
+library(scales)
+library(ggrepel)
+library(DT)
+```
+
+## Data prep
+
+The data frame called `coronavirus` in the coronavirus package provides
+a daily summary of the Coronavirus (COVID-19) cases by country. Each row
+in the data frame represents a country (or, where relevant,
+state/province). A full list of the countries in the data frame is
+provided in the [Appendix](#appendix). Note that the data provided in
+this package provides daily number of deaths, confirmed cases, and
+recovered cases. For this report, we will focus on the deaths.
+
+We will start by making our selection for the countries we want to
+explore.
+
+``` r
+countries <- c(
+  ""China"",
+  ""France"",
+  ""United Kingdom"",
+  ""US"",
+  ""Turkey""
+)
+```
+
+In the following code chunk we filter the data frame for deaths in the
+countries we specified above and calculate cumulative number of deaths.
+We will only visualise data since 10th confirmed death.
+
+``` r
+country_data <- coronavirus %>%
+  # filter for deaths in countries of interest
+  filter(
+    type == ""death"",
+    country %in% countries
+  ) %>%
+  # fix county labels for pretty plotting
+  mutate(
+    country = case_when(
+      country == ""United Kingdom"" ~ ""UK"",
+      TRUE ~ country
+    )
+  ) %>%
+  # calculate number of total cases for each country and date
+  group_by(country, date) %>%
+  summarise(tot_cases = sum(cases)) %>%
+  # arrange by date in ascending order
+  arrange(date) %>%
+  # record daily cumulative cases as cumulative_cases
+  mutate(cumulative_cases = cumsum(tot_cases)) %>%
+  # only use days since the 10th confirmed death
+  filter(cumulative_cases > 9) %>%
+  # record days elapsed, end date, and end label
+  mutate(
+    days_elapsed = as.numeric(date - min(date)),
+    end_date     = if_else(date == max(date), TRUE, FALSE),
+    end_label    = if_else(end_date, country, NULL)
+  ) %>%
+  # ungroup
+  ungroup()
+```
+
+    ## `summarise()` regrouping output by 'country' (override with `.groups` argument)
+
+We also need to take a note of the ‚Äúas of date‚Äù for the data so that we
+can properly label our visualisation.
+
+``` r
+as_of_date <- country_data %>% 
+  summarise(max(date)) %>% 
+  pull()
+
+as_of_date_formatted <- glue(""{wday(as_of_date, label = TRUE)}, {month(as_of_date, label = TRUE)} {day(as_of_date)}, {year(as_of_date)}"")
+```
+
+These data are as of Tue, Dec 22, 2020.
+
+## Visualisation
+
+The following visualisation shows the number of cumulative cases
+vs.¬†days elapsed since the 10th confirmed death in each country. The
+time span plotted for each country varies since some countries started
+seeing (and reporting) deaths from COVID-19 much later than others.
+
+``` r
+ggplot(data = country_data,
+       mapping = aes(x = days_elapsed, 
+                     y = cumulative_cases, 
+                     color = country, 
+                     label = end_label)) +
+  # represent cumulative cases with lines
+  geom_line(size = 0.7, alpha = 0.8) +
+  # add points to line endings
+  geom_point(data = country_data %>% filter(end_date)) +
+  # add country labels, nudged above the lines
+  geom_label_repel(nudge_y = 1, direction = ""y"", hjust = 1) + 
+  # turn off legend
+  guides(color = FALSE) +
+  # use pretty colors
+  scale_color_viridis_d() +
+  # better formatting for y-axis
+  scale_y_continuous(labels = label_comma()) +
+  # use minimal theme
+  theme_minimal() +
+  # customize labels
+  labs(
+    x = ""Days since 10th confirmed death"",
+    y = ""Cumulative number of deaths"",
+    title = ""Cumulative deaths from COVID-19, selected countries"",
+    subtitle = glue(""Data as of"", as_of_date_formatted, .sep = "" ""),
+    caption = ""Source: github.com/RamiKrispin/coronavirus""
+  )
+```
+
+![](covid_files/figure-gfm/visualise-1.png)<!-- -->
+
+## Appendix
+
+A list of countries in the `coronavirus` data frame is provided below.
+
+![](covid_files/figure-gfm/list-countries-1.png)<!-- -->

---FILE: course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.Rmd---
@@ -1,14 +1,11 @@
 ---
 title: ""Bechdel""
 author: ""Mine √áetinkaya-Rundel""
-date: ""`r Sys.Date()`""
-output: 
-  html_document: 
-    fig_height: 4
-    fig_width: 9
+output: github_document
 ---
 
-In this mini analysis we work with the data used in the FiveThirtyEight story titled [""The Dollar-And-Cents Case Against Hollywood‚Äôs Exclusion of Women""](https://fivethirtyeight.com/features/the-dollar-and-cents-case-against-hollywoods-exclusion-of-women/).
+In this mini analysis we work with the data used in the FiveThirtyEight story titled [""The Dollar-And-Cents Case Against Hollywood's Exclusion of Women""](https://fivethirtyeight.com/features/the-dollar-and-cents-case-against-hollywoods-exclusion-of-women/).
+Your task is to fill in the blanks denoted by `___`.
 
 ## Data and packages
 
@@ -19,80 +16,97 @@ library(fivethirtyeight)
 library(tidyverse)
 ```
 
-The dataset contains information on `r nrow(bechdel)` movies released between `r min(bechdel$year)` and `r max(bechdel$year)`. However we'll focus our analysis on movies released between 1990 and 2013.
+The dataset contains information on `r nrow(bechdel)` movies released between `r min(bechdel$year)` and `r max(bechdel$year)`.
+However we'll focus our analysis on movies released between 1990 and 2013.
 
 ```{r}
 bechdel90_13 <- bechdel %>% 
   filter(between(year, 1990, 2013))
 ```
 
-There are ---- such movies.
+There are `___` such movies.
 
 The financial variables we'll focus on are the following:
 
-- `budget_2013`: Budget in 2013 inflation adjusted dollars
-- `domgross_2013`: Domestic gross (US) in 2013 inflation adjusted dollars
-- `intgross_2013`: Total International (i.e., worldwide) gross in 2013 inflation adjusted dollars
+-   `budget_2013`: Budget in 2013 inflation adjusted dollars
+-   `domgross_2013`: Domestic gross (US) in 2013 inflation adjusted dollars
+-   `intgross_2013`: Total International (i.e., worldwide) gross in 2013 inflation adjusted dollars
 
-And we'll also use the `binary` and `test_clean` variables for grouping.
+And we'll also use the `binary` and `clean_test` variables for **grouping**.
 
 ## Analysis
 
-Let's take a look at how median budget and gross vary by whether the movie passed the Bechdel test.
+Let's take a look at how median budget and gross vary by whether the movie passed the Bechdel test, which is stored in the `binary` variable.
 
-```{r}
+```{r message = FALSE}
 bechdel90_13 %>%
   group_by(binary) %>%
   summarise(med_budget = median(budget_2013),
             med_domgross = median(domgross_2013, na.rm = TRUE),
             med_intgross = median(intgross_2013, na.rm = TRUE))
 ```
 
-Next, let's take a look at how median budget and gross vary by a more detailed indicator of the Bechdel test result (`ok` = passes test, `dubious`, `men` = women only talk about men, `notalk` = women don't talk to each other, `nowomen` = fewer than two women).
+Next, let's take a look at how median budget and gross vary by a more detailed indicator of the Bechdel test result.
+This information is stored in the `clean_test` variable, which takes on the following values:
 
-```{r}
+-   `ok` = passes test
+-   `dubious`
+-   `men` = women only talk about men
+-   `notalk` = women don't talk to each other
+-   `nowomen` = fewer than two women
+
+```{r message = FALSE}
 bechdel90_13 %>%
-  # ____ %>%
+  #group_by(___) %>%
   summarise(med_budget = median(budget_2013),
             med_domgross = median(domgross_2013, na.rm = TRUE),
             med_intgross = median(intgross_2013, na.rm = TRUE))
 ```
 
-In order to evaluate how return on investment varies among movies that pass and fail the Bechdel test, we'l  first create a new variable called `roi` as the ratio of the gross to budget.
+In order to evaluate how return on investment varies among movies that pass and fail the Bechdel test, we'll first create a new variable called `roi` as the ratio of the gross to budget.
 
 ```{r}
 bechdel90_13 <- bechdel90_13 %>%
-  mutate(roi = intgross_2013 / domgross_2013)
+  mutate(roi = (intgross_2013 + domgross_2013) / budget_2013)
 ```
 
 Let's see which movies have the highest return on investment.
 
 ```{r}
 bechdel90_13 %>%
   arrange(desc(roi)) %>% 
-  select(title, clean_test, binary, roi, budget_2013, intgross_2013)
+  select(title, roi, year)
 ```
 
 Below is a visualization of the return on investment by test result, however it's difficult to see the distributions due to a few extreme observations.
 
-```{r}
-ggplot(data = bechdel90_13, mapping = aes(x = clean_test, y = roi, color = binary)) +
+```{r warning = FALSE}
+ggplot(data = bechdel90_13, 
+       mapping = aes(x = clean_test, y = roi, color = binary)) +
   geom_boxplot() +
   labs(title = ""Return on investment vs. Bechdel test result"",
        x = ""Detailed Bechdel result"",
        y = ""___"",
        color = ""Binary Bechdel result"")
 ```
 
-Zooming in on the movies with `roi < 10` provides a better view of how the medians across the categories compare:
+What are those movies with *very* high returns on investment?
 
 ```{r}
+bechdel90_13 %>%
+  filter(roi > 400) %>%
+  select(title, budget_2013, domgross_2013, year)
+```
+
+Zooming in on the movies with `roi < ___` provides a better view of how the medians across the categories compare:
+
+```{r warning = FALSE}
 ggplot(data = bechdel90_13, mapping = aes(x = clean_test, y = roi, color = binary)) +
   geom_boxplot() +
-  ylim(0, 10) +
   labs(title = ""Return on investment vs. Bechdel test result"",
-       subtitle = ""___"",
+       subtitle = ""___"", # Something about zooming in to a certain level
        x = ""Detailed Bechdel result"",
        y = ""Return on investment"",
-       color = ""Binary Bechdel result"")
+       color = ""Binary Bechdel result"") +
+  coord_cartesian(ylim = c(0, 15))
 ```

---FILE: course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.md---
@@ -0,0 +1,162 @@
+Bechdel
+================
+Mine √áetinkaya-Rundel
+
+In this mini analysis we work with the data used in the FiveThirtyEight
+story titled [‚ÄúThe Dollar-And-Cents Case Against Hollywood‚Äôs Exclusion
+of
+Women‚Äù](https://fivethirtyeight.com/features/the-dollar-and-cents-case-against-hollywoods-exclusion-of-women/).
+Your task is to fill in the blanks denoted by `___`.
+
+## Data and packages
+
+We start with loading the packages we‚Äôll use.
+
+``` r
+library(fivethirtyeight)
+library(tidyverse)
+```
+
+The dataset contains information on 1794 movies released between 1970
+and 2013. However we‚Äôll focus our analysis on movies released between
+1990 and 2013.
+
+``` r
+bechdel90_13 <- bechdel %>% 
+  filter(between(year, 1990, 2013))
+```
+
+There are `___` such movies.
+
+The financial variables we‚Äôll focus on are the following:
+
+-   `budget_2013`: Budget in 2013 inflation adjusted dollars
+-   `domgross_2013`: Domestic gross (US) in 2013 inflation adjusted
+    dollars
+-   `intgross_2013`: Total International (i.e., worldwide) gross in 2013
+    inflation adjusted dollars
+
+And we‚Äôll also use the `binary` and `clean_test` variables for
+**grouping**.
+
+## Analysis
+
+Let‚Äôs take a look at how median budget and gross vary by whether the
+movie passed the Bechdel test, which is stored in the `binary` variable.
+
+``` r
+bechdel90_13 %>%
+  group_by(binary) %>%
+  summarise(med_budget = median(budget_2013),
+            med_domgross = median(domgross_2013, na.rm = TRUE),
+            med_intgross = median(intgross_2013, na.rm = TRUE))
+```
+
+    ## # A tibble: 2 x 4
+    ##   binary med_budget med_domgross med_intgross
+    ##   <chr>       <dbl>        <dbl>        <dbl>
+    ## 1 FAIL    48385984.    57318606.    104475669
+    ## 2 PASS    31070724     45330446.     80124349
+
+Next, let‚Äôs take a look at how median budget and gross vary by a more
+detailed indicator of the Bechdel test result. This information is
+stored in the `clean_test` variable, which takes on the following
+values:
+
+-   `ok` = passes test
+-   `dubious`
+-   `men` = women only talk about men
+-   `notalk` = women don‚Äôt talk to each other
+-   `nowomen` = fewer than two women
+
+``` r
+bechdel90_13 %>%
+  #group_by(___) %>%
+  summarise(med_budget = median(budget_2013),
+            med_domgross = median(domgross_2013, na.rm = TRUE),
+            med_intgross = median(intgross_2013, na.rm = TRUE))
+```
+
+    ## # A tibble: 1 x 3
+    ##   med_budget med_domgross med_intgross
+    ##        <int>        <dbl>        <dbl>
+    ## 1   37878971     52270207     93523336
+
+In order to evaluate how return on investment varies among movies that
+pass and fail the Bechdel test, we‚Äôll first create a new variable called
+`roi` as the ratio of the gross to budget.
+
+``` r
+bechdel90_13 <- bechdel90_13 %>%
+  mutate(roi = (intgross_2013 + domgross_2013) / budget_2013)
+```
+
+Let‚Äôs see which movies have the highest return on investment.
+
+``` r
+bechdel90_13 %>%
+  arrange(desc(roi)) %>% 
+  select(title, roi, year)
+```
+
+    ## # A tibble: 1,615 x 3
+    ##    title                     roi  year
+    ##    <chr>                   <dbl> <int>
+    ##  1 Paranormal Activity      671.  2007
+    ##  2 The Blair Witch Project  648.  1999
+    ##  3 El Mariachi              583.  1992
+    ##  4 Clerks.                  258.  1994
+    ##  5 In the Company of Men    231.  1997
+    ##  6 Napoleon Dynamite        227.  2004
+    ##  7 Once                     190.  2006
+    ##  8 The Devil Inside         155.  2012
+    ##  9 Primer                   142.  2004
+    ## 10 Fireproof                134.  2008
+    ## # ‚Ä¶ with 1,605 more rows
+
+Below is a visualization of the return on investment by test result,
+however it‚Äôs difficult to see the distributions due to a few extreme
+observations.
+
+``` r
+ggplot(data = bechdel90_13, 
+       mapping = aes(x = clean_test, y = roi, color = binary)) +
+  geom_boxplot() +
+  labs(title = ""Return on investment vs. Bechdel test result"",
+       x = ""Detailed Bechdel result"",
+       y = ""___"",
+       color = ""Binary Bechdel result"")
+```
+
+![](bechdel_files/figure-gfm/unnamed-chunk-6-1.png)<!-- -->
+
+What are those movies with *very* high returns on investment?
+
+``` r
+bechdel90_13 %>%
+  filter(roi > 400) %>%
+  select(title, budget_2013, domgross_2013, year)
+```
+
+    ## # A tibble: 3 x 4
+    ##   title                   budget_2013 domgross_2013  year
+    ##   <chr>                         <int>         <dbl> <int>
+    ## 1 Paranormal Activity          505595     121251476  2007
+    ## 2 The Blair Witch Project      839077     196538593  1999
+    ## 3 El Mariachi                   11622       3388636  1992
+
+Zooming in on the movies with `roi < ___` provides a better view of how
+the medians across the categories compare:
+
+``` r
+ggplot(data = bechdel90_13, mapping = aes(x = clean_test, y = roi, color = binary)) +
+  geom_boxplot() +
+  labs(title = ""Return on investment vs. Bechdel test result"",
+       subtitle = ""___"", # Something about zooming in to a certain level
+       x = ""Detailed Bechdel result"",
+       y = ""Return on investment"",
+       color = ""Binary Bechdel result"") +
+  coord_cartesian(ylim = c(0, 15))
+```
+
+![](bechdel_files/figure-gfm/unnamed-chunk-8-1.png)<!-- -->

---FILE: course-materials/application-exercises/ae-03-starwars-dataviz/starwars.Rmd---
@@ -1,25 +1,72 @@
 ---
 title: ""Visualizing Starwars characters""
 author: ""Mine √áetinkaya-Rundel""
-date: ""`r Sys.Date()`""
-output: 
-  html_document: 
-    fig_height: 4
-    fig_width: 9
+output: github_document
 ---
 
 ```{r load-packages, include=FALSE}
 library(tidyverse)
 ```
 
+### Glimpse at the starwars data frame.
+
+```{r glimpse-starwars}
+glimpse(starwars)
+```
+
 ### Modify the following plot to change the color of all points to `""pink""`.
 
-```{r starwars-plot}
-ggplot(data = starwars, 
-       mapping = aes(x = height, y = mass, color = gender, size = birth_year)) +
+```{r scatterplot}
+ggplot(starwars, 
+       aes(x = height, y = mass, color = gender, size = birth_year)) +
+  geom_point(color = ""#30509C"")
+```
+
+### Add labels for title, x and y axes, and size of points. Uncomment to see the effect.
+
+```{r scatterplot-labels}
+ggplot(starwars, 
+       aes(x = height, y = mass, color = gender, size = birth_year)) +
   geom_point(color = ""#30509C"") +
-  labs(size = ""Birth year"", x = ""Height"", y = ""Mass"")
+  labs(
+    #title = ""___"",
+    #x = ""___"", 
+    #y = ""___"",
+    #___
+    )
 ```
 
-### Stretch goal: Add labels for title, x and y axes, and size of points.
+### Pick a single categorical variable from the data set and make a bar plot of its distribution.
+
+(A little bit of starter code is provided below, and the code chunk is set to not be evaluated with `eval = FALSE` because the current code in there is not valid code and hence the document wouldn't knit. Once you replace the code with valid code, set the chunk option to `eval = TRUE`, or remove the `eval` option altogether since it's set to `TRUE` by default.)
 
+```{r barplot, eval = FALSE}
+ggplot(starwars, aes(___)) +
+  geom___
+```
+
+### Pick a single numerical variable and make a histogram of it.
+
+(This time no starter code is provided, you're on your own!)
+
+```{r histogram}
+
+```
+
+### Pick a numerical variable and a categorical variable and make a visualisation (you pick the type!) to visualise the relationship between the two variables. Along with your code and output, provide an interpretation of the visualisation.
+
+```{r num-cat}
+
+```
+
+### Pick two categorical variables and make a visualisation to visualise the relationship between the two variables. Along with your code and output, provide an interpretation of the visualisation.
+
+```{r cat-cat}
+
+```
+
+### Pick two numerical variables and two categorical variables and make a visualisation that incorportes all of them and provide an interpretation with your answer.
+
+```{r multi}
+
+```

---FILE: course-materials/application-exercises/ae-03-starwars-dataviz/starwars.md---
@@ -0,0 +1,80 @@
+Visualizing Starwars characters
+================
+Mine √áetinkaya-Rundel
+
+### Glimpse at the starwars data frame.
+
+``` r
+glimpse(starwars)
+```
+
+    ## Rows: 87
+    ## Columns: 14
+    ## $ name       <chr> ""Luke Skywalker"", ""C-3PO"", ""R2-D2"", ""Darth Vader"", ""Leia O‚Ä¶
+    ## $ height     <int> 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188, 180, ‚Ä¶
+    ## $ mass       <dbl> 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 84.0, 77‚Ä¶
+    ## $ hair_color <chr> ""blond"", NA, NA, ""none"", ""brown"", ""brown, grey"", ""brown"", ‚Ä¶
+    ## $ skin_color <chr> ""fair"", ""gold"", ""white, blue"", ""white"", ""light"", ""light"", ‚Ä¶
+    ## $ eye_color  <chr> ""blue"", ""yellow"", ""red"", ""yellow"", ""brown"", ""blue"", ""blue""‚Ä¶
+    ## $ birth_year <dbl> 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0, 57.0,‚Ä¶
+    ## $ sex        <chr> ""male"", ""none"", ""none"", ""male"", ""female"", ""male"", ""female""‚Ä¶
+    ## $ gender     <chr> ""masculine"", ""masculine"", ""masculine"", ""masculine"", ""femin‚Ä¶
+    ## $ homeworld  <chr> ""Tatooine"", ""Tatooine"", ""Naboo"", ""Tatooine"", ""Alderaan"", ""‚Ä¶
+    ## $ species    <chr> ""Human"", ""Droid"", ""Droid"", ""Human"", ""Human"", ""Human"", ""Hum‚Ä¶
+    ## $ films      <list> [<""The Empire Strikes Back"", ""Revenge of the Sith"", ""Retu‚Ä¶
+    ## $ vehicles   <list> [<""Snowspeeder"", ""Imperial Speeder Bike"">, <>, <>, <>, ""I‚Ä¶
+    ## $ starships  <list> [<""X-wing"", ""Imperial shuttle"">, <>, <>, ""TIE Advanced x1‚Ä¶
+
+### Modify the following plot to change the color of all points to `""pink""`.
+
+``` r
+ggplot(starwars, 
+       aes(x = height, y = mass, color = gender, size = birth_year)) +
+  geom_point(color = ""#30509C"")
+```
+
+    ## Warning: Removed 51 rows containing missing values (geom_point).
+
+![](starwars_files/figure-gfm/scatterplot-1.png)<!-- -->
+
+### Add labels for title, x and y axes, and size of points. Uncomment to see the effect.
+
+``` r
+ggplot(starwars, 
+       aes(x = height, y = mass, color = gender, size = birth_year)) +
+  geom_point(color = ""#30509C"") +
+  labs(
+    #title = ""___"",
+    #x = ""___"", 
+    #y = ""___"",
+    #___
+    )
+```
+
+    ## Warning: Removed 51 rows containing missing values (geom_point).
+
+![](starwars_files/figure-gfm/scatterplot-labels-1.png)<!-- -->
+
+### Pick a single categorical variable from the data set and make a bar plot of its distribution.
+
+(A little bit of starter code is provided below, and the code chunk is
+set to not be evaluated with `eval = FALSE` because the current code in
+there is not valid code and hence the document wouldn‚Äôt knit. Once you
+replace the code with valid code, set the chunk option to `eval = TRUE`,
+or remove the `eval` option altogether since it‚Äôs set to `TRUE` by
+default.)
+
+``` r
+ggplot(starwars, aes(___)) +
+  geom___
+```
+
+### Pick a single numerical variable and make a histogram of it.
+
+(This time no starter code is provided, you‚Äôre on your own!)
+
+### Pick a numerical variable and a categorical variable and make a visualisation (you pick the type!) to visualise the relationship between the two variables. Along with your code and output, provide an interpretation of the visualisation.
+
+### Pick two categorical variables and make a visualisation to visualise the relationship between the two variables. Along with your code and output, provide an interpretation of the visualisation.
+
+### Pick two numerical variables and two categorical variables and make a visualisation that incorportes all of them and provide an interpretation with your answer.

---FILE: course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.Rmd---
@@ -1,11 +1,7 @@
 ---
 title: ""Hotel bookings - data wrangling""
 author: ""Mine √áetinkaya-Rundel""
-date: ""`r Sys.Date()`""
-output: 
-  html_document: 
-    toc: yes
-    toc_float: yes
+output: github_document
 ---
 
 ```{r load-pkg, message = FALSE}
@@ -18,32 +14,29 @@ library(skimr)
 hotels <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv"")
 ```
 
-
 ## Exercises
 
-### Exercise 1. 
+### Exercise 1.
 
-Warm up! Take a look at an overview of the data with the `skim()` function.
+Warm up!
+Take a look at an overview of the data with the `skim()` function.
 
-**Note:** I already gave you the answer to this exercise. You just need to 
-knit the document and view the output. A definition of all variables is given 
-in the [Data dictionary] section at the end, though you don't need to familiarize 
-yourself with all variables in order to work through these exercises.
+**Note:** I already gave you the answer to this exercise.
+You just need to knit the document and view the output.
+A definition of all variables is given in the [Data dictionary] section at the end, though you don't need to familiarize yourself with all variables in order to work through these exercises.
 
 ```{r hotels-skim}
 skim(hotels)
 ```
 
-
 ### Exercise 2.
 
-Are people traveling on a whim? Let's see... 
+Are people traveling on a whim?
+Let's see...
 
-Fill in the blanks for filtering for hotel bookings where the guest is **not** 
-from the US (`country` code `""USA""`) and the `lead_time` is less than 1 day.
+Fill in the blanks for filtering for hotel bookings where the guest is **not** from the US (`country` code `""USA""`) and the `lead_time` is less than 1 day.
 
-**Note:** You will need to set `eval=TRUE` when you have an answer you want to 
-try out.
+**Note:** You will need to set `eval=TRUE` when you have an answer you want to try out.
 
 ```{r travel-whim, eval=FALSE}
 hotels %>%
@@ -57,13 +50,12 @@ hotels %>%
 
 How many bookings involve at least 1 child **or** baby?
 
-In the following chunk, replace 
+In the following chunk, replace
 
-- `[AT LEAST]` with the logical operator for ""at least"" (in two places)
-- `[OR]` with the logical operator for ""or""
+-   `[AT LEAST]` with the logical operator for ""at least"" (in two places)
+-   `[OR]` with the logical operator for ""or""
 
-**Note:** You will need to set `eval=TRUE` when you have an answer you want to 
-try out.
+**Note:** You will need to set `eval=TRUE` when you have an answer you want to try out.
 
 ```{r some-children, eval=FALSE}
 hotels %>%
@@ -74,11 +66,10 @@ hotels %>%
 
 ### Exercise 4.
 
-Do you think it's more likely to find bookings with children or babies in city 
-hotels or resort hotels? Test your intuition. Using `filter()` determine the 
-number of bookings in resort hotels that have more than 1 child **or** baby 
-in the room? Then, do the same for city hotels, and compare the numbers of 
-rows in the resulting filtered data frames.
+Do you think it's more likely to find bookings with children or babies in city hotels or resort hotels?
+Test your intuition.
+Using `filter()` determine the number of bookings in resort hotels that have more than 1 child **or** baby in the room?
+Then, do the same for city hotels, and compare the numbers of rows in the resulting filtered data frames.
 
 ```{r resort-children}
 # add code here
@@ -92,15 +83,14 @@ rows in the resulting filtered data frames.
 
 ### Exercise 5.
 
-Create a frequency table of the number of `adults` in a booking. Display the 
-results in descending order so the most common observation is on top. What is 
-the most common number of adults in bookings in this dataset? Are there any 
-surprising results?
+Create a frequency table of the number of `adults` in a booking.
+Display the results in descending order so the most common observation is on top.
+What is the most common number of adults in bookings in this dataset?
+Are there any surprising results?
 
-**Note:** Don't forget to label your R chunk as well (where it says `label-me-1`). 
-Your label should be short, informative, and shouldn't include spaces. It also 
-shouldn't repeat a previous label, otherwise R Markdown will give you an 
-error about repeated R chunk labels.
+**Note:** Don't forget to label your R chunk as well (where it says `label-me-1`).
+Your label should be short, informative, and shouldn't include spaces.
+It also shouldn't repeat a previous label, otherwise R Markdown will give you an error about repeated R chunk labels.
 
 ```{r label-me-1}
 # add code here
@@ -109,11 +99,10 @@ error about repeated R chunk labels.
 
 ### Exercise 6.
 
-Repeat Exercise 5, once for canceled bookings (`is_canceled` coded as 1) and 
-once for not canceled bookings (`is_canceled` coded as 0). What does this 
-reveal about the surprising results you spotted in the previous exercise?
+Repeat Exercise 5, once for canceled bookings (`is_canceled` coded as 1) and once for not canceled bookings (`is_canceled` coded as 0).
+What does this reveal about the surprising results you spotted in the previous exercise?
 
-**Note:** Don't forget to label your R chunk as well (where it says `label-me-2`). 
+**Note:** Don't forget to label your R chunk as well (where it says `label-me-2`).
 
 ```{r label-me-2}
 # add code here
@@ -122,9 +111,8 @@ reveal about the surprising results you spotted in the previous exercise?
 
 ### Exercise 7.
 
-Calculate minimum, mean, median, and maximum average daily rate (`adr`) grouped 
-by `hotel` type so that you can get these statistics separately for resort and 
-city hotels. Which type of hotel is higher, on average? 
+Calculate minimum, mean, median, and maximum average daily rate (`adr`) grouped by `hotel` type so that you can get these statistics separately for resort and city hotels.
+Which type of hotel is higher, on average?
 
 ```{r label-me-3}
 # add code here
@@ -133,59 +121,54 @@ city hotels. Which type of hotel is higher, on average?
 
 ### Exercise 8.
 
-We observe two unusual values in the summary statistics above -- a negative 
-minimum, and a very high maximum). What types of hotels are these? Locate 
-these observations in the dataset and find out the arrival date (year and 
-month) as well as how many people (adults, children, and babies) stayed in 
-the room. You can investigate the data in the viewer to locate these values, but 
-preferably you should identify them in a reproducible way with some code. 
+We observe two unusual values in the summary statistics above -- a negative minimum, and a very high maximum).
+What types of hotels are these?
+Locate these observations in the dataset and find out the arrival date (year and month) as well as how many people (adults, children, and babies) stayed in the room.
+You can investigate the data in the viewer to locate these values, but preferably you should identify them in a reproducible way with some code.
 
-**Hint:** For example, you can `filter` for the given `adr` amounts and 
-`select` the relevant columns.
+**Hint:** For example, you can `filter` for the given `adr` amounts and `select` the relevant columns.
 
 ```{r label-me-4}
 # add code here
 # pay attention to correctness and code style
 ```
 
-
 ## Data dictionary
 
-Below is the full data dictionary. Note that it is long (there are lots of 
-variables in the data), but we will be using a limited set of the variables 
-for our analysis.
-
-|variable                       |class     |description |
-|:------------------------------|:---------|:-----------|
-|hotel                          |character | Hotel (H1 = Resort Hotel or H2 = City Hotel) |
-|is_canceled                    |double    | Value indicating if the booking was canceled (1) or not (0) |
-|lead_time                      |double    | Number of days that elapsed between the entering date of the booking into the PMS and the arrival date |
-|arrival_date_year              |double    | Year of arrival date|
-|arrival_date_month             |character | Month of arrival date|
-|arrival_date_week_number       |double    | Week number of year for arrival date|
-|arrival_date_day_of_month      |double    | Day of arrival date|
-|stays_in_weekend_nights        |double    | Number of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel |
-|stays_in_week_nights           |double    |  Number of week nights (Monday to Friday) the guest stayed or booked to stay at the hotel|
-|adults                         |double    | Number of adults|
-|children                       |double    | Number of children|
-|babies                         |double    |Number of babies |
-|meal                           |character | Type of meal booked. Categories are presented in standard hospitality meal packages: <br> Undefined/SC ‚Äì no meal package;<br>BB ‚Äì Bed & Breakfast; <br> HB ‚Äì Half board (breakfast and one other meal ‚Äì usually dinner); <br> FB ‚Äì Full board (breakfast, lunch and dinner) |
-|country                        |character | Country of origin. Categories are represented in the ISO 3155‚Äì3:2013 format |
-|market_segment                 |character | Market segment designation. In categories, the term ‚ÄúTA‚Äù means ‚ÄúTravel Agents‚Äù and ‚ÄúTO‚Äù means ‚ÄúTour Operators‚Äù |
-|distribution_channel           |character | Booking distribution channel. The term ‚ÄúTA‚Äù means ‚ÄúTravel Agents‚Äù and ‚ÄúTO‚Äù means ‚ÄúTour Operators‚Äù |
-|is_repeated_guest              |double    | Value indicating if the booking name was from a repeated guest (1) or not (0) |
-|previous_cancellations         |double    | Number of previous bookings that were cancelled by the customer prior to the current booking |
-|previous_bookings_not_canceled |double    | Number of previous bookings not cancelled by the customer prior to the current booking |
-|reserved_room_type             |character | Code of room type reserved. Code is presented instead of designation for anonymity reasons |
-|assigned_room_type             |character | Code for the type of room assigned to the booking. Sometimes the assigned room type differs from the reserved room type due to hotel operation reasons (e.g. overbooking) or by customer request. Code is presented instead of designation for anonymity reasons |
-|booking_changes                |double    | Number of changes/amendments made to the booking from the moment the booking was entered on the PMS until the moment of check-in or cancellation|
-|deposit_type                   |character | Indication on if the customer made a deposit to guarantee the booking. This variable can assume three categories:<br>No Deposit ‚Äì no deposit was made;<br>Non Refund ‚Äì a deposit was made in the value of the total stay cost;<br>Refundable ‚Äì a deposit was made with a value under the total cost of stay. |
-|agent                          |character | ID of the travel agency that made the booking |
-|company                        |character | ID of the company/entity that made the booking or responsible for paying the booking. ID is presented instead of designation for anonymity reasons |
-|days_in_waiting_list           |double    | Number of days the booking was in the waiting list before it was confirmed to the customer |
-|customer_type                  |character | Type of booking, assuming one of four categories:<br>Contract - when the booking has an allotment or other type of contract associated to it;<br>Group ‚Äì when the booking is associated to a group;<br>Transient ‚Äì when the booking is not part of a group or contract, and is not associated to other transient booking;<br>Transient-party ‚Äì when the booking is transient, but is associated to at least other transient booking|
-|adr                            |double    | Average Daily Rate as defined by dividing the sum of all lodging transactions by the total number of staying nights |
-|required_car_parking_spaces    |double    | Number of car parking spaces required by the customer |
-|total_of_special_requests      |double    | Number of special requests made by the customer (e.g. twin bed or high floor)|
-|reservation_status             |character | Reservation last status, assuming one of three categories:<br>Canceled ‚Äì booking was canceled by the customer;<br>Check-Out ‚Äì customer has checked in but already departed;<br>No-Show ‚Äì customer did not check-in and did inform the hotel of the reason why |
-|reservation_status_date        |double    | Date at which the last status was set. This variable can be used in conjunction with the ReservationStatus to understand when was the booking canceled or when did the customer checked-out of the hotel|
+Below is the full data dictionary.
+Note that it is long (there are lots of variables in the data), but we will be using a limited set of the variables for our analysis.
+
+| variable                       | class     | description                                                                                                                                                                                                                                                                                                                                                                                                                         |
+|:-------------------------------|:----------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
+| hotel                          | character | Hotel (H1 = Resort Hotel or H2 = City Hotel)                                                                                                                                                                                                                                                                                                                                                                                        |
+| is_canceled                    | double    | Value indicating if the booking was canceled (1) or not (0)                                                                                                                                                                                                                                                                                                                                                                         |
+| lead_time                      | double    | Number of days that elapsed between the entering date of the booking into the PMS and the arrival date                                                                                                                                                                                                                                                                                                                              |
+| arrival_date_year              | double    | Year of arrival date                                                                                                                                                                                                                                                                                                                                                                                                                |
+| arrival_date_month             | character | Month of arrival date                                                                                                                                                                                                                                                                                                                                                                                                               |
+| arrival_date_week_number       | double    | Week number of year for arrival date                                                                                                                                                                                                                                                                                                                                                                                                |
+| arrival_date_day_of_month      | double    | Day of arrival date                                                                                                                                                                                                                                                                                                                                                                                                                 |
+| stays_in_weekend_nights        | double    | Number of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel                                                                                                                                                                                                                                                                                                                                       |
+| stays_in_week_nights           | double    | Number of week nights (Monday to Friday) the guest stayed or booked to stay at the hotel                                                                                                                                                                                                                                                                                                                                            |
+| adults                         | double    | Number of adults                                                                                                                                                                                                                                                                                                                                                                                                                    |
+| children                       | double    | Number of children                                                                                                                                                                                                                                                                                                                                                                                                                  |
+| babies                         | double    | Number of babies                                                                                                                                                                                                                                                                                                                                                                                                                    |
+| meal                           | character | Type of meal booked. Categories are presented in standard hospitality meal packages: <br> Undefined/SC ‚Äì no meal package;<br>BB ‚Äì Bed & Breakfast; <br> HB ‚Äì Half board (breakfast and one other meal ‚Äì usually dinner); <br> FB ‚Äì Full board (breakfast, lunch and dinner)                                                                                                                                                         |
+| country                        | character | Country of origin. Categories are represented in the ISO 3155‚Äì3:2013 format                                                                                                                                                                                                                                                                                                                                                         |
+| market_segment                 | character | Market segment designation. In categories, the term ""TA"" means ""Travel Agents"" and ""TO"" means ""Tour Operators""                                                                                                                                                                                                                                                                                                                      |
+| distribution_channel           | character | Booking distribution channel. The term ""TA"" means ""Travel Agents"" and ""TO"" means ""Tour Operators""                                                                                                                                                                                                                                                                                                                                   |
+| is_repeated_guest              | double    | Value indicating if the booking name was from a repeated guest (1) or not (0)                                                                                                                                                                                                                                                                                                                                                       |
+| previous_cancellations         | double    | Number of previous bookings that were cancelled by the customer prior to the current booking                                                                                                                                                                                                                                                                                                                                        |
+| previous_bookings_not_canceled | double    | Number of previous bookings not cancelled by the customer prior to the current booking                                                                                                                                                                                                                                                                                                                                              |
+| reserved_room_type             | character | Code of room type reserved. Code is presented instead of designation for anonymity reasons                                                                                                                                                                                                                                                                                                                                          |
+| assigned_room_type             | character | Code for the type of room assigned to the booking. Sometimes the assigned room type differs from the reserved room type due to hotel operation reasons (e.g. overbooking) or by customer request. Code is presented instead of designation for anonymity reasons                                                                                                                                                                    |
+| booking_changes                | double    | Number of changes/amendments made to the booking from the moment the booking was entered on the PMS until the moment of check-in or cancellation                                                                                                                                                                                                                                                                                    |
+| deposit_type                   | character | Indication on if the customer made a deposit to guarantee the booking. This variable can assume three categories:<br>No Deposit ‚Äì no deposit was made;<br>Non Refund ‚Äì a deposit was made in the value of the total stay cost;<br>Refundable ‚Äì a deposit was made with a value under the total cost of stay.                                                                                                                        |
+| agent                          | character | ID of the travel agency that made the booking                                                                                                                                                                                                                                                                                                                                                                                       |
+| company                        | character | ID of the company/entity that made the booking or responsible for paying the booking. ID is presented instead of designation for anonymity reasons                                                                                                                                                                                                                                                                                  |
+| days_in_waiting_list           | double    | Number of days the booking was in the waiting list before it was confirmed to the customer                                                                                                                                                                                                                                                                                                                                          |
+| customer_type                  | character | Type of booking, assuming one of four categories:<br>Contract - when the booking has an allotment or other type of contract associated to it;<br>Group ‚Äì when the booking is associated to a group;<br>Transient ‚Äì when the booking is not part of a group or contract, and is not associated to other transient booking;<br>Transient-party ‚Äì when the booking is transient, but is associated to at least other transient booking |
+| adr                            | double    | Average Daily Rate as defined by dividing the sum of all lodging transactions by the total number of staying nights                                                                                                                                                                                                                                                                                                                 |
+| required_car_parking_spaces    | double    | Number of car parking spaces required by the customer                                                                                                                                                                                                                                                                                                                                                                               |
+| total_of_special_requests      | double    | Number of special requests made by the customer (e.g. twin bed or high floor)                                                                                                                                                                                                                                                                                                                                                       |
+| reservation_status             | character | Reservation last status, assuming one of three categories:<br>Canceled ‚Äì booking was canceled by the customer;<br>Check-Out ‚Äì customer has checked in but already departed;<br>No-Show ‚Äì customer did not check-in and did inform the hotel of the reason why                                                                                                                                                                       |
+| reservation_status_date        | double    | Date at which the last status was set. This variable can be used in conjunction with the ReservationStatus to understand when was the booking canceled or when did the customer checked-out of the hotel                                                                                                                                                                                                                            |

---FILE: course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.md---
@@ -0,0 +1,251 @@
+Hotel bookings - data wrangling
+================
+Mine √áetinkaya-Rundel
+
+``` r
+library(tidyverse)
+library(skimr)
+```
+
+``` r
+# From TidyTuesday: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-11/readme.md
+hotels <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv"")
+```
+
+## Exercises
+
+### Exercise 1.
+
+Warm up! Take a look at an overview of the data with the `skim()`
+function.
+
+**Note:** I already gave you the answer to this exercise. You just need
+to knit the document and view the output. A definition of all variables
+is given in the [Data dictionary](#data-dictionary) section at the end,
+though you don‚Äôt need to familiarize yourself with all variables in
+order to work through these exercises.
+
+``` r
+skim(hotels)
+```
+
+|                                                  |        |
+|:-------------------------------------------------|:-------|
+| Name                                             | hotels |
+| Number of rows                                   | 119390 |
+| Number of columns                                | 32     |
+| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |        |
+| Column type frequency:                           |        |
+| character                                        | 13     |
+| Date                                             | 1      |
+| numeric                                          | 18     |
+| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |        |
+| Group variables                                  | None   |
+
+Data summary
+
+**Variable type: character**
+
+| skim\_variable        | n\_missing | complete\_rate | min | max | empty | n\_unique | whitespace |
+|:----------------------|-----------:|---------------:|----:|----:|------:|----------:|-----------:|
+| hotel                 |          0 |              1 |  10 |  12 |     0 |         2 |          0 |
+| arrival\_date\_month  |          0 |              1 |   3 |   9 |     0 |        12 |          0 |
+| meal                  |          0 |              1 |   2 |   9 |     0 |         5 |          0 |
+| country               |          0 |              1 |   2 |   4 |     0 |       178 |          0 |
+| market\_segment       |          0 |              1 |   6 |  13 |     0 |         8 |          0 |
+| distribution\_channel |          0 |              1 |   3 |   9 |     0 |         5 |          0 |
+| reserved\_room\_type  |          0 |              1 |   1 |   1 |     0 |        10 |          0 |
+| assigned\_room\_type  |          0 |              1 |   1 |   1 |     0 |        12 |          0 |
+| deposit\_type         |          0 |              1 |  10 |  10 |     0 |         3 |          0 |
+| agent                 |          0 |              1 |   1 |   4 |     0 |       334 |          0 |
+| company               |          0 |              1 |   1 |   4 |     0 |       353 |          0 |
+| customer\_type        |          0 |              1 |   5 |  15 |     0 |         4 |          0 |
+| reservation\_status   |          0 |              1 |   7 |   9 |     0 |         3 |          0 |
+
+**Variable type: Date**
+
+| skim\_variable            | n\_missing | complete\_rate | min        | max        | median     | n\_unique |
+|:--------------------------|-----------:|---------------:|:-----------|:-----------|:-----------|----------:|
+| reservation\_status\_date |          0 |              1 | 2014-10-17 | 2017-09-14 | 2016-08-07 |       926 |
+
+**Variable type: numeric**
+
+| skim\_variable                    | n\_missing | complete\_rate |    mean |     sd |      p0 |     p25 |     p50 |  p75 | p100 | hist  |
+|:----------------------------------|-----------:|---------------:|--------:|-------:|--------:|--------:|--------:|-----:|-----:|:------|
+| is\_canceled                      |          0 |              1 |    0.37 |   0.48 |    0.00 |    0.00 |    0.00 |    1 |    1 | ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÖ |
+| lead\_time                        |          0 |              1 |  104.01 | 106.86 |    0.00 |   18.00 |   69.00 |  160 |  737 | ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ |
+| arrival\_date\_year               |          0 |              1 | 2016.16 |   0.71 | 2015.00 | 2016.00 | 2016.00 | 2017 | 2017 | ‚ñÉ‚ñÅ‚ñá‚ñÅ‚ñÜ |
+| arrival\_date\_week\_number       |          0 |              1 |   27.17 |  13.61 |    1.00 |   16.00 |   28.00 |   38 |   53 | ‚ñÖ‚ñá‚ñá‚ñá‚ñÖ |
+| arrival\_date\_day\_of\_month     |          0 |              1 |   15.80 |   8.78 |    1.00 |    8.00 |   16.00 |   23 |   31 | ‚ñá‚ñá‚ñá‚ñá‚ñÜ |
+| stays\_in\_weekend\_nights        |          0 |              1 |    0.93 |   1.00 |    0.00 |    0.00 |    1.00 |    2 |   19 | ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ |
+| stays\_in\_week\_nights           |          0 |              1 |    2.50 |   1.91 |    0.00 |    1.00 |    2.00 |    3 |   50 | ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ |
+| adults                            |          0 |              1 |    1.86 |   0.58 |    0.00 |    2.00 |    2.00 |    2 |   55 | ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ |
+| children                          |          4 |              1 |    0.10 |   0.40 |    0.00 |    0.00 |    0.00 |    0 |   10 | ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ |
+| babies                            |          0 |              1 |    0.01 |   0.10 |    0.00 |    0.00 |    0.00 |    0 |   10 | ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ |
+| is\_repeated\_guest               |          0 |              1 |    0.03 |   0.18 |    0.00 |    0.00 |    0.00 |    0 |    1 | ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ |
+| previous\_cancellations           |          0 |              1 |    0.09 |   0.84 |    0.00 |    0.00 |    0.00 |    0 |   26 | ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ |
+| previous\_bookings\_not\_canceled |          0 |              1 |    0.14 |   1.50 |    0.00 |    0.00 |    0.00 |    0 |   72 | ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ |
+| booking\_changes                  |          0 |              1 |    0.22 |   0.65 |    0.00 |    0.00 |    0.00 |    0 |   21 | ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ |
+| days\_in\_waiting\_list           |          0 |              1 |    2.32 |  17.59 |    0.00 |    0.00 |    0.00 |    0 |  391 | ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ |
+| adr                               |          0 |              1 |  101.83 |  50.54 |   -6.38 |   69.29 |   94.58 |  126 | 5400 | ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ |
+| required\_car\_parking\_spaces    |          0 |              1 |    0.06 |   0.25 |    0.00 |    0.00 |    0.00 |    0 |    8 | ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ |
+| total\_of\_special\_requests      |          0 |              1 |    0.57 |   0.79 |    0.00 |    0.00 |    0.00 |    1 |    5 | ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ |
+
+### Exercise 2.
+
+Are people traveling on a whim? Let‚Äôs see‚Ä¶
+
+Fill in the blanks for filtering for hotel bookings where the guest is
+**not** from the US (`country` code `""USA""`) and the `lead_time` is less
+than 1 day.
+
+**Note:** You will need to set `eval=TRUE` when you have an answer you
+want to try out.
+
+``` r
+hotels %>%
+  filter(
+    country ____ ""USA"", 
+    lead_time ____ ____
+    )
+```
+
+### Exercise 3.
+
+How many bookings involve at least 1 child **or** baby?
+
+In the following chunk, replace
+
+-   `[AT LEAST]` with the logical operator for ‚Äúat least‚Äù (in two
+    places)
+-   `[OR]` with the logical operator for ‚Äúor‚Äù
+
+**Note:** You will need to set `eval=TRUE` when you have an answer you
+want to try out.
+
+``` r
+hotels %>%
+  filter(
+    children [AT LEAST] 1 [OR] babies [AT LEAST] 1
+    )
+```
+
+### Exercise 4.
+
+Do you think it‚Äôs more likely to find bookings with children or babies
+in city hotels or resort hotels? Test your intuition. Using `filter()`
+determine the number of bookings in resort hotels that have more than 1
+child **or** baby in the room? Then, do the same for city hotels, and
+compare the numbers of rows in the resulting filtered data frames.
+
+``` r
+# add code here
+# pay attention to correctness and code style
+```
+
+``` r
+# add code here
+# pay attention to correctness and code style
+```
+
+### Exercise 5.
+
+Create a frequency table of the number of `adults` in a booking. Display
+the results in descending order so the most common observation is on
+top. What is the most common number of adults in bookings in this
+dataset? Are there any surprising results?
+
+**Note:** Don‚Äôt forget to label your R chunk as well (where it says
+`label-me-1`). Your label should be short, informative, and shouldn‚Äôt
+include spaces. It also shouldn‚Äôt repeat a previous label, otherwise R
+Markdown will give you an error about repeated R chunk labels.
+
+``` r
+# add code here
+# pay attention to correctness and code style
+```
+
+### Exercise 6.
+
+Repeat Exercise 5, once for canceled bookings (`is_canceled` coded as 1)
+and once for not canceled bookings (`is_canceled` coded as 0). What does
+this reveal about the surprising results you spotted in the previous
+exercise?
+
+**Note:** Don‚Äôt forget to label your R chunk as well (where it says
+`label-me-2`).
+
+``` r
+# add code here
+# pay attention to correctness and code style
+```
+
+### Exercise 7.
+
+Calculate minimum, mean, median, and maximum average daily rate (`adr`)
+grouped by `hotel` type so that you can get these statistics separately
+for resort and city hotels. Which type of hotel is higher, on average?
+
+``` r
+# add code here
+# pay attention to correctness and code style
+```
+
+### Exercise 8.
+
+We observe two unusual values in the summary statistics above ‚Äì a
+negative minimum, and a very high maximum). What types of hotels are
+these? Locate these observations in the dataset and find out the arrival
+date (year and month) as well as how many people (adults, children, and
+babies) stayed in the room. You can investigate the data in the viewer
+to locate these values, but preferably you should identify them in a
+reproducible way with some code.
+
+**Hint:** For example, you can `filter` for the given `adr` amounts and
+`select` the relevant columns.
+
+``` r
+# add code here
+# pay attention to correctness and code style
+```
+
+## Data dictionary
+
+Below is the full data dictionary. Note that it is long (there are lots
+of variables in the data), but we will be using a limited set of the
+variables for our analysis.
+
+| variable                          | class     | description                                                                                                                                                                                                                                                                                                                                                                                                                         |
+|:----------------------------------|:----------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
+| hotel                             | character | Hotel (H1 = Resort Hotel or H2 = City Hotel)                                                                                                                                                                                                                                                                                                                                                                                        |
+| is\_canceled                      | double    | Value indicating if the booking was canceled (1) or not (0)                                                                                                                                                                                                                                                                                                                                                                         |
+| lead\_time                        | double    | Number of days that elapsed between the entering date of the booking into the PMS and the arrival date                                                                                                                                                                                                                                                                                                                              |
+| arrival\_date\_year               | double    | Year of arrival date                                                                                                                                                                                                                                                                                                                                                                                                                |
+| arrival\_date\_month              | character | Month of arrival date                                                                                                                                                                                                                                                                                                                                                                                                               |
+| arrival\_date\_week\_number       | double    | Week number of year for arrival date                                                                                                                                                                                                                                                                                                                                                                                                |
+| arrival\_date\_day\_of\_month     | double    | Day of arrival date                                                                                                                                                                                                                                                                                                                                                                                                                 |
+| stays\_in\_weekend\_nights        | double    | Number of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel                                                                                                                                                                                                                                                                                                                                       |
+| stays\_in\_week\_nights           | double    | Number of week nights (Monday to Friday) the guest stayed or booked to stay at the hotel                                                                                                                                                                                                                                                                                                                                            |
+| adults                            | double    | Number of adults                                                                                                                                                                                                                                                                                                                                                                                                                    |
+| children                          | double    | Number of children                                                                                                                                                                                                                                                                                                                                                                                                                  |
+| babies                            | double    | Number of babies                                                                                                                                                                                                                                                                                                                                                                                                                    |
+| meal                              | character | Type of meal booked. Categories are presented in standard hospitality meal packages: <br> Undefined/SC ‚Äì no meal package;<br>BB ‚Äì Bed & Breakfast; <br> HB ‚Äì Half board (breakfast and one other meal ‚Äì usually dinner); <br> FB ‚Äì Full board (breakfast, lunch and dinner)                                                                                                                                                         |
+| country                           | character | Country of origin. Categories are represented in the ISO 3155‚Äì3:2013 format                                                                                                                                                                                                                                                                                                                                                         |
+| market\_segment                   | character | Market segment designation. In categories, the term ‚ÄúTA‚Äù means ‚ÄúTravel Agents‚Äù and ‚ÄúTO‚Äù means ‚ÄúTour Operators‚Äù                                                                                                                                                                                                                                                                                                                      |
+| distribution\_channel             | character | Booking distribution channel. The term ‚ÄúTA‚Äù means ‚ÄúTravel Agents‚Äù and ‚ÄúTO‚Äù means ‚ÄúTour Operators‚Äù                                                                                                                                                                                                                                                                                                                                   |
+| is\_repeated\_guest               | double    | Value indicating if the booking name was from a repeated guest (1) or not (0)                                                                                                                                                                                                                                                                                                                                                       |
+| previous\_cancellations           | double    | Number of previous bookings that were cancelled by the customer prior to the current booking                                                                                                                                                                                                                                                                                                                                        |
+| previous\_bookings\_not\_canceled | double    | Number of previous bookings not cancelled by the customer prior to the current booking                                                                                                                                                                                                                                                                                                                                              |
+| reserved\_room\_type              | character | Code of room type reserved. Code is presented instead of designation for anonymity reasons                                                                                                                                                                                                                                                                                                                                          |
+| assigned\_room\_type              | character | Code for the type of room assigned to the booking. Sometimes the assigned room type differs from the reserved room type due to hotel operation reasons (e.g.¬†overbooking) or by customer request. Code is presented instead of designation for anonymity reasons                                                                                                                                                                    |
+| booking\_changes                  | double    | Number of changes/amendments made to the booking from the moment the booking was entered on the PMS until the moment of check-in or cancellation                                                                                                                                                                                                                                                                                    |
+| deposit\_type                     | character | Indication on if the customer made a deposit to guarantee the booking. This variable can assume three categories:<br>No Deposit ‚Äì no deposit was made;<br>Non Refund ‚Äì a deposit was made in the value of the total stay cost;<br>Refundable ‚Äì a deposit was made with a value under the total cost of stay.                                                                                                                        |
+| agent                             | character | ID of the travel agency that made the booking                                                                                                                                                                                                                                                                                                                                                                                       |
+| company                           | character | ID of the company/entity that made the booking or responsible for paying the booking. ID is presented instead of designation for anonymity reasons                                                                                                                                                                                                                                                                                  |
+| days\_in\_waiting\_list           | double    | Number of days the booking was in the waiting list before it was confirmed to the customer                                                                                                                                                                                                                                                                                                                                          |
+| customer\_type                    | character | Type of booking, assuming one of four categories:<br>Contract - when the booking has an allotment or other type of contract associated to it;<br>Group ‚Äì when the booking is associated to a group;<br>Transient ‚Äì when the booking is not part of a group or contract, and is not associated to other transient booking;<br>Transient-party ‚Äì when the booking is transient, but is associated to at least other transient booking |
+| adr                               | double    | Average Daily Rate as defined by dividing the sum of all lodging transactions by the total number of staying nights                                                                                                                                                                                                                                                                                                                 |
+| required\_car\_parking\_spaces    | double    | Number of car parking spaces required by the customer                                                                                                                                                                                                                                                                                                                                                                               |
+| total\_of\_special\_requests      | double    | Number of special requests made by the customer (e.g.¬†twin bed or high floor)                                                                                                                                                                                                                                                                                                                                                       |
+| reservation\_status               | character | Reservation last status, assuming one of three categories:<br>Canceled ‚Äì booking was canceled by the customer;<br>Check-Out ‚Äì customer has checked in but already departed;<br>No-Show ‚Äì customer did not check-in and did inform the hotel of the reason why                                                                                                                                                                       |
+| reservation\_status\_date         | double    | Date at which the last status was set. This variable can be used in conjunction with the ReservationStatus to understand when was the booking canceled or when did the customer checked-out of the hotel                                                                                                                                                                                                                            |

---FILE: course-materials/application-exercises/ae-05-fisheries-datajoins/data/continents.csv---
@@ -1,246 +0,0 @@
-country,continent
-Afghanistan,Asia
-√Öland Islands,Europe
-Albania,Europe
-Algeria,Africa
-American Samoa,Oceania
-Andorra,Europe
-Angola,Africa
-Anguilla,Americas
-Antigua & Barbuda,Americas
-Argentina,Americas
-Armenia,Asia
-Aruba,Americas
-Australia,Oceania
-Austria,Europe
-Azerbaijan,Asia
-Bahamas,Americas
-Bahrain,Asia
-Bangladesh,Asia
-Barbados,Americas
-Belarus,Europe
-Belgium,Europe
-Belize,Americas
-Benin,Africa
-Bermuda,Americas
-Bhutan,Asia
-Bolivia,Americas
-Caribbean Netherlands,Americas
-Bosnia & Herzegovina,Europe
-Botswana,Africa
-Brazil,Americas
-Brunei,Asia
-Bulgaria,Europe
-Burkina Faso,Africa
-Burundi,Africa
-Cape Verde,Africa
-Cambodia,Asia
-Cameroon,Africa
-Canada,Americas
-Cayman Islands,Americas
-Central African Republic,Africa
-Chad,Africa
-Chile,Americas
-China,Asia
-Christmas Island,Oceania
-Colombia,Americas
-Comoros,Africa
-Congo - Brazzaville,Africa
-Cook Islands,Oceania
-Costa Rica,Americas
-C√¥te d‚ÄôIvoire,Africa
-Croatia,Europe
-Cuba,Americas
-Cura√ßao,Americas
-Cyprus,Asia
-Czechia,Europe
-North Korea,Asia
-Congo - Kinshasa,Africa
-Denmark,Europe
-Djibouti,Africa
-Dominica,Americas
-Dominican Republic,Americas
-Ecuador,Americas
-Egypt,Africa
-El Salvador,Americas
-Equatorial Guinea,Africa
-Eritrea,Africa
-Estonia,Europe
-Ethiopia,Africa
-Falkland Islands,Americas
-Faroe Islands,Europe
-Fiji,Oceania
-Finland,Europe
-France,Europe
-French Guiana,Americas
-French Polynesia,Oceania
-Gabon,Africa
-Gambia,Africa
-Georgia,Asia
-Germany,Europe
-Ghana,Africa
-Gibraltar,Europe
-Greece,Europe
-Greenland,Americas
-Grenada,Americas
-Guadeloupe,Americas
-Guam,Oceania
-Guatemala,Americas
-Guernsey,Europe
-Guinea,Africa
-Guinea-Bissau,Africa
-Guyana,Americas
-Haiti,Americas
-Vatican City,Europe
-Honduras,Americas
-Hong Kong SAR China,Asia
-Hungary,Europe
-Iceland,Europe
-India,Asia
-Indonesia,Asia
-Iran,Asia
-Iraq,Asia
-Ireland,Europe
-Isle of Man,Europe
-Israel,Asia
-Italy,Europe
-Jamaica,Americas
-Japan,Asia
-Jersey,Europe
-Jordan,Asia
-Kazakhstan,Asia
-Kenya,Africa
-Kiribati,Oceania
-Kuwait,Asia
-Kyrgyzstan,Asia
-Laos,Asia
-Latvia,Europe
-Lebanon,Asia
-Lesotho,Africa
-Liberia,Africa
-Libya,Africa
-Liechtenstein,Europe
-Lithuania,Europe
-Luxembourg,Europe
-Macau SAR China,Asia
-Madagascar,Africa
-Malawi,Africa
-Malaysia,Asia
-Maldives,Asia
-Mali,Africa
-Malta,Europe
-Marshall Islands,Oceania
-Martinique,Americas
-Mauritania,Africa
-Mauritius,Africa
-Mayotte,Africa
-Mexico,Americas
-Micronesia (Federated States of),Oceania
-Monaco,Europe
-Mongolia,Asia
-Montenegro,Europe
-Montserrat,Americas
-Morocco,Africa
-Mozambique,Africa
-Myanmar (Burma),Asia
-Namibia,Africa
-Nauru,Oceania
-Nepal,Asia
-Netherlands,Europe
-Netherlands Antilles,Americas
-New Caledonia,Oceania
-New Zealand,Oceania
-Nicaragua,Americas
-Niger,Africa
-Nigeria,Africa
-Niue,Oceania
-Norfolk Island,Oceania
-Northern Mariana Islands,Oceania
-Norway,Europe
-Oman,Asia
-Pakistan,Asia
-Palau,Oceania
-Palestinian Territories,Asia
-Panama,Americas
-Papua New Guinea,Oceania
-Paraguay,Americas
-Peru,Americas
-Philippines,Asia
-Pitcairn Islands,Oceania
-Poland,Europe
-Portugal,Europe
-Puerto Rico,Americas
-Qatar,Asia
-South Korea,Asia
-Moldova,Europe
-R√©union,Africa
-Romania,Europe
-Russia,Europe
-Rwanda,Africa
-St. Barth√©lemy,Americas
-St. Helena,Africa
-St. Kitts & Nevis,Americas
-St. Lucia,Americas
-Saint Martin (French part),Americas
-St. Pierre & Miquelon,Americas
-St. Vincent & Grenadines,Americas
-Samoa,Oceania
-San Marino,Europe
-S√£o Tom√© & Pr√≠ncipe,Africa
-Saudi Arabia,Asia
-Senegal,Africa
-Serbia,Europe
-Seychelles,Africa
-Sierra Leone,Africa
-Singapore,Asia
-Sint Maarten,Americas
-Slovakia,Europe
-Slovenia,Europe
-Solomon Islands,Oceania
-Somalia,Africa
-Somaliland,Africa
-South Africa,Africa
-South Sudan,Africa
-Spain,Europe
-Sri Lanka,Asia
-Sudan,Africa
-Suriname,Americas
-Svalbard & Jan Mayen,Europe
-Swaziland,Africa
-Sweden,Europe
-Switzerland,Europe
-Syria,Asia
-Taiwan,Asia
-Tajikistan,Asia
-Thailand,Asia
-Macedonia,Europe
-Timor-Leste,Asia
-Togo,Africa
-Tokelau,Oceania
-Tonga,Oceania
-Trinidad & Tobago,Americas
-Tunisia,Africa
-Turkey,Asia
-Turkmenistan,Asia
-Turks & Caicos Islands,Americas
-Tuvalu,Oceania
-Uganda,Africa
-Ukraine,Europe
-United Arab Emirates,Asia
-United Arab Republic,Asia
-United Kingdom,Europe
-Tanzania,Africa
-United States,Americas
-Uruguay,Americas
-Uzbekistan,Asia
-Vanuatu,Oceania
-Venezuela,Americas
-Vietnam,Asia
-Republic of Vietnam,Asia
-British Virgin Islands,Americas
-U.S. Virgin Islands,Americas
-Wallis & Futuna,Oceania
-Western Sahara,Africa
-Yemen,Asia
-Zambia,Africa
-Zimbabwe,Africa

---FILE: course-materials/application-exercises/ae-05-fisheries-datajoins/data/fisheries.csv---
@@ -1,217 +0,0 @@
-Ôªøcountry,capture,aquaculture,total
-Afghanistan,1000,1200,2200
-Albania,7886,950,8836
-Algeria,95000,1361,96361
-American Samoa,3047,20,3067
-Andorra,0,0,0
-Angola,486490,655,487145
-Antigua and Barbuda,3000,10,3010
-Argentina,755226,3673,758899
-Armenia,3758,16381,20139
-Aruba,142,0,142
-Australia,174629,96847,271476
-Austria,350,3483,3833
-Azerbaijan,676,640,1316
-Bahamas,11625,8,11633
-Bahrain,15000,6,15006
-Bangladesh,1674770,2203554,3878324
-Barbados,1735,26,1761
-Belarus,686,11199,11885
-Belgium,26970,44,27014
-Belize,91432,953,92385
-Benin,49806,3080,52886
-Bermuda,410,0,410
-Bhutan,7,150,157
-Bolivia,7000,3000,10000
-Bosnia and Herzegovina,305,4564,4869
-Botswana,38,15,53
-Brazil,705000,581230,1286230
-British Virgin Islands,1200,0,1200
-Brunei,13292,948,14240
-Bulgaria,8614,15762,24376
-Burkina Faso,22070,470,22540
-Burundi,21805,1330,23135
-Cambodia,629950,172500,802450
-Cameroon,233190,2315,235505
-Canada,874727,200765,1075492
-Cape Verde,19900,0,19900
-Cayman Islands,125,0,125
-Central African Republic,29000,190,29190
-Chad,110000,94,110094
-Chile,1829238,1050117,2879355
-China,17800000,63700000,81500000
-Colombia,86344,96970,183314
-Comoros,16407,0,16407
-Costa Rica,14750,22421,37171
-Croatia,72312,15805,88117
-Cuba,23574,29185,52759
-Cura√ßao,35534,0,35534
-Cyprus,1507,6625,8132
-Czech Republic,3507,20952,24459
-Democratic Republic of the Congo,237372,3161,240533
-Denmark,670344,36337,706681
-Djibouti,2220,0,2220
-Dominica,770,6,776
-Dominican Republic,14640,2285,16925
-Ecuador,715495,451090,1166585
-Egypt,335614,1370660,1706274
-El Salvador,54084,7956,62040
-Equatorial Guinea,8000,15,8015
-Eritrea,4300,0,4300
-Estonia,75931,868,76799
-Eswatini,65,100,165
-Ethiopia,45500,95,45595
-Faroe Islands,568435,83300,651735
-Federated States of Micronesia,88397,0,88397
-Fiji,44663,754,45417
-Finland,192065,14412,206477
-France,561173,166640,727813
-France,90,0,90
-French Polynesia,13754,1343,15097
-Gabon,31000,45,31045
-Gambia,58261,5,58266
-Georgia,30078,670,30748
-Germany,271185,41721,312906
-Ghana,327457,52480,379937
-Gibraltar,1,0,1
-Greece,76362,123410,199772
-Greenland,273175,0,273175
-Grenada,2550,0,2550
-Guam,1391,110,1501
-Guatemala,19011,26268,45279
-Guinea,128000,250,128250
-Guinea-Bissau,6700,0,6700
-Guyana,42142,337,42479
-Haiti,16510,1220,17730
-Honduras,10600,53100,63700
-Hong Kong,142775,4258,147033
-Hungary,5048,16248,21296
-Iceland,1085176,15129,1100305
-India,5082332,5703002,10785334
-Indonesia,6584419,16600000,23184419
-Iran,695407,398129,1093536
-Iraq,28000,28835,56835
-Ireland,259845,40244,300089
-Isle of Man,7040,0,7040
-Israel,1758,18914,20672
-Italy,198130,157109,355239
-Ivory Coast,67500,4701,72201
-Jamaica,16800,620,17420
-Japan,3275263,1067994,4343257
-Jersey and Guernsey,2985,1499,4484
-Jordan,873,885,1758
-Kazakhstan,41335,1878,43213
-Kenya,171391,15360,186751
-Kiribati,172822,3652,176474
-Kuwait,5493,196,5689
-Kyrgyzstan,89,1931,2020
-Laos,70915,109835,180750
-Latvia,114806,788,115594
-Lebanon,4291,1015,5306
-Lesotho,52,1050,1102
-Liberia,14700,40,14740
-Libya,30002,10,30012
-Liechtenstein,0,0,0
-Lithuania,106945,4393,111338
-Luxembourg,0,0,0
-Macao,1500,0,1500
-Madagascar,142333,25998,168331
-Malawi,152852,7646,160498
-Malaysia,1584371,407887,1992258
-Maldives,129191,0,129191
-Mali,102486,4194,106680
-Malta,2420,6073,8493
-Marshall Islands,64795,5,64800
-Mauritania,609754,0,609754
-Mauritius,18062,1021,19083
-Mexico,1524467,221328,1745795
-Moldova,50,16011,16061
-Monaco,1,0,1
-Mongolia,15,0,15
-Montenegro,1595,929,2524
-Morocco,1454105,1142,1455247
-Mozambique,299591,1180,300771
-Myanmar,2072390,1017644,3090034
-Namibia,503878,591,504469
-Nauru,530,0,530
-Nepal,21500,49043,70543
-Netherlands,370274,62940,433214
-New Caledonia,3815,1587,5402
-New Zealand,424791,109016,533807
-Nicaragua,45500,22530,68030
-Niger,34592,300,34892
-Nigeria,734731,306727,1041458
-North Korea,209000,554100,763100
-North Macedonia,306,986,1292
-Northern Mariana Islands,950,42,992
-Norway,2203360,1326216,3529576
-Oman,279606,103,279709
-Pakistan,513156,156430,669586
-Palau,818,23,841
-Palestine,3306,280,3586
-Panama,144450,8808,153258
-Papua New Guinea,309245,6200,315445
-Paraguay,17000,8500,25500
-Peru,3811802,100187,3911989
-Philippines,2027992,2200914,4228906
-Poland,218115,38300,256415
-Portugal,186950,9787,196737
-Puerto Rico,1901,20,1921
-Qatar,14516,10,14526
-Republic of the Congo,86748,177,86925
-Romania,12728,12574,25302
-Russia,4773413,173840,4947253
-Rwanda,25013,580,25593
-Saint Kitts and Nevis,65734,1,65735
-Saint Lucia,2097,32,2129
-Saint Vincent and the Grenadines,23077,0,23077
-Samoa,8801,10,8811
-San Marino,0,0,0
-S√£o Tom√© and Pr√≠ncipe,11750,0,11750
-Saudi Arabia,68082,39920,108002
-Senegal,474162,2079,476241
-Serbia,2067,6878,8945
-Seychelles,127128,0,127128
-Sierra Leone,202100,75,202175
-Singapore,1234,6112,7346
-Sint Maarten,253,0,253
-Slovakia,1866,2169,4035
-Slovenia,311,1844,2155
-Solomon Islands,66445,10582,77027
-Somalia,30000,0,30000
-South Africa,622070,7994,630064
-South Korea,1395951,1859220,3255171
-South Sudan,35000,20,35020
-Spain,915137,283831,1198968
-Sri Lanka,521637,30974,552611
-Sudan,33002,4500,37502
-Suriname,47013,102,47115
-Sweden,208783,15747,224530
-Switzerland,1851,1733,3584
-Syria,4500,3500,8000
-Tajikistan,1100,450,1550
-Tanzania,370966,12547,383513
-Thailand,1530583,962571,2493154
-Timor-Leste,3200,1560,4760
-Togo,31891,98,31989
-Tonga,1697,3,1700
-Trinidad and Tobago,13027,11,13038
-Tunisia,115064,16165,131229
-Turkey,335326,250331,585657
-Turkmenistan,15000,30,15030
-Turks and Caicos Islands,2780,0,2780
-Tuvalu,7684,3,7687
-Uganda,389244,118051,507295
-Ukraine,75743,21425,97168
-United Arab Emirates,73000,1241,74241
-United Kingdom,702405,194492,896897
-United States,4931017,444369,5375386
-Uruguay,51500,70,51570
-US Virgin Islands,551,8,559
-Uzbekistan,27267,38055,65322
-Vanuatu,44002,16,44018
-Venezuela,284175,25998,310173
-Vietnam,2785940,3634531,6420471
-Yemen,154450,0,154450
-Zambia,83918,30285,114203
-Zimbabwe,15711,10085,25796
\ No newline at end of file

---FILE: course-materials/application-exercises/ae-05-fisheries-datajoins/fisheries.Rmd---
@@ -1,80 +0,0 @@
----
-title: ""Fisheries""
-author: ""Mine √áetinkaya-Rundel""
-date: ""`r Sys.Date()`""
-output: 
-  html_document: 
-    toc: yes
-    toc_float: yes
----
-
-```{r setup, include=FALSE}
-library(tidyverse)
-fisheries <- read_csv(""data/fisheries.csv"")
-continents <- read_csv(""data/continents.csv"")
-```
-
-The code below brings you to the point in the slides where we left off...
-
-```{r catch-up}
-fisheries <- fisheries %>%
-  filter(total > 100000) %>%
-  left_join(continents) %>%
-  mutate(
-    continent = case_when(
-      country == ""Democratic Republic of the Congo"" ~ ""Africa"",
-      country == ""Hong Kong""                        ~ ""Asia"",
-      country == ""Myanmar""                          ~ ""Asia"",
-      TRUE                                          ~ continent
-      ),
-    aquaculture_perc = aquaculture / total
-    )
-```
-
-**Note:** In each of these exercises you will need to set `eval=TRUE` when you're 
-ready to run the code for that exercise.
-
-### Exercise 1.
-
-Calculate the mean aquaculture percentage (we'll call it `mean_ap` for short) 
-for continents in the fisheries data using the `summarise()` function in dplyr. 
-Note that the function for calculating the mean is `mean()` in R.
-
-```{r fisheries-mean, eval=FALSE}
-fisheries %>%                  # start with the fisheries data frame
-  ___ %>%                      # group by continent
-  ___(mean_ap = ___)           # calculate mean aquaculture
-```
-
-### Exercise 2.
-
-Now expand your calculations to also calculate the minimum and maximum 
-aquaculture percentage for continents in the fisheries data. Note that the 
-functions for calculating minimum and maximum in R are `min()` and `max()`
-respectively.
-
-```{r fisheries-summary, eval=FALSE}
-fisheries %>%                  # start with the fisheries data frame
-  # and the rest of the code goes here         
-```
-
-### Exercise 3.
-
-Create a new data frame called `fisheries_summary_continent` that calculates 
-minimum, mean, and maximum aquaculture percentage for each continent in the 
-fisheries data. 
-
-```{r fisheries-summary-continent, eval=FALSE}
-fisheries_summary_continent <- fisheries %>%
-  # you can reuse code from Exercise 2 here                        
-```
-
-### Exercise 4.
-
-Take the `fisheries_summary_continent` data frame and order the results in descending 
-order of mean aquaculture percentage.
-
-```{r fisheries-summary-continent-sorted, eval=FALSE}
-fisheries_summary_continent %>%      # start with the fisheries_summary_continent data frame
-  ___                                # order in descending order of mean_ap
-```

---FILE: course-materials/application-exercises/ae-05-hotels-datatypes/hotels-forcats.Rmd---
@@ -0,0 +1,43 @@
+---
+title: ""Hotel bookings - factors""
+author: ""Mine √áetinkaya-Rundel""
+output: github_document
+---
+
+```{r load-pkg, message = FALSE}
+library(tidyverse)
+library(skimr)
+```
+
+```{r load-data, message = FALSE}
+# From TidyTuesday: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-11/readme.md
+hotels <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv"")
+```
+
+First, knit the document and view the following visualisation.
+How are the months ordered?
+What would be a better order?
+Then, reorder the months on the x-axis (levels of `arrival_date_month`) in a way that makes more sense.
+You will want to use a function from the **forcats** package, see <https://forcats.tidyverse.org/reference/index.html> for inspiration and help.
+
+**Stretch goal:** If you finish the above task before time is up, change the y-axis label so the values are shown with dollar signs, e.g. $80 instead of 80.
+You will want to use a function from the **scales** package, see <https://scales.r-lib.org/reference/index.html> for inspiration and help.
+
+```{r plot, fig.width=10}
+hotels %>%
+  group_by(hotel, arrival_date_month) %>%   # group by hotel type and arrival month
+  summarise(mean_adr = mean(adr)) %>%       # calculate mean adr for each group
+  ggplot(aes(
+    x = arrival_date_month,                 # x-axis = arrival_date_month
+    y = mean_adr,                           # y-axis = mean_adr calculated above
+    group = hotel,                          # group lines by hotel type
+    color = hotel)                          # and color by hotel type
+    ) +
+  geom_line() +                             # use lines to represent data
+  theme_minimal() +                         # use a minimal theme
+  labs(x = ""Arrival month"",                 # customize labels
+       y = ""Mean ADR (average daily rate)"",
+       title = ""Comparison of resort and city hotel prices across months"",
+       subtitle = ""Resort hotel prices soar in the summer while ciry hotel prices remain relatively constant throughout the year"",
+       color = ""Hotel type"")
+```

---FILE: course-materials/application-exercises/ae-05-hotels-datatypes/hotels-forcats.md---
@@ -0,0 +1,49 @@
+Hotel bookings - factors
+================
+Mine √áetinkaya-Rundel
+
+``` r
+library(tidyverse)
+library(skimr)
+```
+
+``` r
+# From TidyTuesday: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-11/readme.md
+hotels <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv"")
+```
+
+First, knit the document and view the following visualisation. How are
+the months ordered? What would be a better order? Then, reorder the
+months on the x-axis (levels of `arrival_date_month`) in a way that
+makes more sense. You will want to use a function from the **forcats**
+package, see <https://forcats.tidyverse.org/reference/index.html> for
+inspiration and help.
+
+**Stretch goal:** If you finish the above task before time is up, change
+the y-axis label so the values are shown with dollar signs, e.g.¬†$80
+instead of 80. You will want to use a function from the **scales**
+package, see <https://scales.r-lib.org/reference/index.html> for
+inspiration and help.
+
+``` r
+hotels %>%
+  group_by(hotel, arrival_date_month) %>%   # group by hotel type and arrival month
+  summarise(mean_adr = mean(adr)) %>%       # calculate mean adr for each group
+  ggplot(aes(
+    x = arrival_date_month,                 # x-axis = arrival_date_month
+    y = mean_adr,                           # y-axis = mean_adr calculated above
+    group = hotel,                          # group lines by hotel type
+    color = hotel)                          # and color by hotel type
+    ) +
+  geom_line() +                             # use lines to represent data
+  theme_minimal() +                         # use a minimal theme
+  labs(x = ""Arrival month"",                 # customize labels
+       y = ""Mean ADR (average daily rate)"",
+       title = ""Comparison of resort and city hotel prices across months"",
+       subtitle = ""Resort hotel prices soar in the summer while ciry hotel prices remain relatively constant throughout the year"",
+       color = ""Hotel type"")
+```
+
+    ## `summarise()` regrouping output by 'hotel' (override with `.groups` argument)
+
+![](hotels-forcats_files/figure-gfm/plot-1.png)<!-- -->

---FILE: course-materials/application-exercises/ae-05-hotels-datatypes/type-coercion.Rmd---
@@ -0,0 +1,83 @@
+---
+title: ""Type coercion""
+author: ""Mine √áetinkaya-Rundel""
+output: github_document
+---
+
+-   `c(1, 1L, ""C"")`
+
+```{r}
+c(1, 1L, ""C"")
+```
+
+```{r}
+1
+1L
+""C""
+```
+
+```{r}
+#typeof(c(1, 1L, ""C""))
+```
+
+-   `c(1L / 0, ""A"")`
+
+```{r}
+c(1L / 0, ""A"")
+```
+
+```{r}
+typeof(1L)
+typeof(0)
+typeof(1L/0)
+typeof(""A"")
+```
+
+```{r}
+#typeof(c(1L / 0, ""A""))
+```
+
+-   `c(1:3, 5)`
+
+```{r}
+c(1:3, 5)
+```
+
+```{r}
+typeof(1:3)
+typeof(5)
+```
+
+```{r}
+#typeof(c(1:3, 5))
+```
+
+-   `c(3, ""3+"")`
+
+```{r}
+c(3, ""3+"")
+```
+
+```{r}
+typeof(3)
+typeof(""3+"")
+```
+
+```{r}
+#typeof(c(3, ""3+""))
+```
+
+-   `c(NA, TRUE)`
+
+```{r}
+c(NA, TRUE)
+```
+
+```{r}
+typeof(NA)
+typeof(TRUE)
+```
+
+```{r}
+#typeof(c(NA, TRUE))
+```

---FILE: course-materials/application-exercises/ae-05-hotels-datatypes/type-coercion.md---
@@ -0,0 +1,141 @@
+Type coercion
+================
+Mine √áetinkaya-Rundel
+
+-   `c(1, 1L, ""C"")`
+
+``` r
+c(1, 1L, ""C"")
+```
+
+    ## [1] ""1"" ""1"" ""C""
+
+``` r
+1
+```
+
+    ## [1] 1
+
+``` r
+1L
+```
+
+    ## [1] 1
+
+``` r
+""C""
+```
+
+    ## [1] ""C""
+
+``` r
+#typeof(c(1, 1L, ""C""))
+```
+
+-   `c(1L / 0, ""A"")`
+
+``` r
+c(1L / 0, ""A"")
+```
+
+    ## [1] ""Inf"" ""A""
+
+``` r
+typeof(1L)
+```
+
+    ## [1] ""integer""
+
+``` r
+typeof(0)
+```
+
+    ## [1] ""double""
+
+``` r
+typeof(1L/0)
+```
+
+    ## [1] ""double""
+
+``` r
+typeof(""A"")
+```
+
+    ## [1] ""character""
+
+``` r
+#typeof(c(1L / 0, ""A""))
+```
+
+-   `c(1:3, 5)`
+
+``` r
+c(1:3, 5)
+```
+
+    ## [1] 1 2 3 5
+
+``` r
+typeof(1:3)
+```
+
+    ## [1] ""integer""
+
+``` r
+typeof(5)
+```
+
+    ## [1] ""double""
+
+``` r
+#typeof(c(1:3, 5))
+```
+
+-   `c(3, ""3+"")`
+
+``` r
+c(3, ""3+"")
+```
+
+    ## [1] ""3""  ""3+""
+
+``` r
+typeof(3)
+```
+
+    ## [1] ""double""
+
+``` r
+typeof(""3+"")
+```
+
+    ## [1] ""character""
+
+``` r
+#typeof(c(3, ""3+""))
+```
+
+-   `c(NA, TRUE)`
+
+``` r
+c(NA, TRUE)
+```
+
+    ## [1]   NA TRUE
+
+``` r
+typeof(NA)
+```
+
+    ## [1] ""logical""
+
+``` r
+typeof(TRUE)
+```
+
+    ## [1] ""logical""
+
+``` r
+#typeof(c(NA, TRUE))
+```

---FILE: course-materials/application-exercises/ae-06-hotels-datatypes/hotels-forcats.Rmd---
@@ -1,42 +0,0 @@
----
-title: ""Hotel bookings - factors""
-author: ""Mine √áetinkaya-Rundel""
-date: ""`r Sys.Date()`""
-output: 
-  html_document: 
-    toc: yes
-    toc_float: yes
----
-
-```{r load-pkg, message = FALSE}
-library(tidyverse)
-library(skimr)
-```
-
-```{r load-data, message = FALSE}
-# From TidyTuesday: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-11/readme.md
-hotels <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv"")
-```
-
-First, knit the document and view the following visualisation. How are the months ordered? What would be a better order? Then, reorder the months on the x-axis (levels of `arrival_date_month`) in a way that makes more sense. You will want to use a function from the **forcats** package, see https://forcats.tidyverse.org/reference/index.html for inspiration and help.
-
-**Stretch goal:** If you finish the above task before time is up, change the y-axis label so the values are shown with dollar signs, e.g. $80 instead of 80. You will want to use a function from the **scales** package, see https://scales.r-lib.org/reference/index.html for inspiration and help.
-
-```{r plot, fig.width=10}
-hotels %>%
-  group_by(hotel, arrival_date_month) %>%   # group by hotel type and arrival month
-  summarise(mean_adr = mean(adr)) %>%       # calculate mean adr for each group
-  ggplot(aes(
-    x = arrival_date_month,                 # x-axis = arrival_date_month
-    y = mean_adr,                           # y-axis = mean_adr calculated above
-    group = hotel,                          # group lines by hotel type
-    color = hotel)                          # and color by hotel type
-    ) +
-  geom_line() +                             # use lines to represent data
-  theme_minimal() +                         # use a minimal theme
-  labs(x = ""Arrival month"",                 # customize labels
-       y = ""Mean ADR (average daily rate)"",
-       title = ""Comparison of resort and city hotel prices across months"",
-       subtitle = ""Resort hotel prices soar in the summer while ciry hotel prices remain relatively constant throughout the year"",
-       color = ""Hotel type"")
-```

---FILE: course-materials/application-exercises/ae-06-hotels-datatypes/type-coercion.Rmd---
@@ -1,85 +0,0 @@
----
-title: ""Type coercion""
-author: ""Mine √áetinkaya-Rundel""
-date: ""`r Sys.Date()`""
-output: 
-  html_document: 
-    toc: yes
-    toc_float: yes
----
-
--   `c(1, 1L, ""C"")`
-```{r}
-c(1, 1L, ""C"")
-```
-
-```{r}
-1
-1L
-""C""
-```
-
-```{r}
-typeof(c(1, 1L, ""C""))
-```
-
--   `c(1L / 0, ""A"")`
-
-```{r}
-c(1L / 0, ""A"")
-```
-
-```{r}
-typeof(1L)
-typeof(0)
-typeof(1L/0)
-typeof(""A"")
-```
-
-```{r}
-typeof(c(1L / 0, ""A""))
-```
-
--   `c(1:3, 5)`
-
-```{r}
-c(1:3, 5)
-```
-
-```{r}
-typeof(1:3)
-typeof(5)
-```
-
-```{r}
-typeof(c(1:3, 5))
-```
-
--   `c(3, ""3+"")`
-
-```{r}
-c(3, ""3+"")
-```
-
-```{r}
-typeof(3)
-typeof(""3+"")
-```
-
-```{r}
-typeof(c(3, ""3+""))
-```
--   `c(NA, TRUE)`
-
-```{r}
-c(NA, TRUE)
-```
-
-```{r}
-typeof(NA)
-typeof(TRUE)
-```
-
-```{r}
-typeof(c(NA, TRUE))
-```

---FILE: course-materials/application-exercises/ae-06-nobels-sales-dataimport/nobels-csv.Rmd---
@@ -1,11 +1,7 @@
 ---
 title: ""Nobel winners""
 author: ""Mine √áetinkaya-Rundel""
-date: ""`r Sys.Date()`""
-output: 
-  html_document: 
-    toc: yes
-    toc_float: yes
+output: github_document
 ---
 
 ```{r load-packages, message=FALSE}
@@ -35,4 +31,3 @@ And finally write out the data:
 ```{r label-me3}
 # add code for writing out the two data frames here
 ```
-

---FILE: course-materials/application-exercises/ae-06-nobels-sales-dataimport/nobels-csv.md---
@@ -0,0 +1,31 @@
+Nobel winners
+================
+Mine √áetinkaya-Rundel
+
+``` r
+library(tidyverse)
+```
+
+Let‚Äôs first load the data:
+
+``` r
+nobel <- ___(___)
+```
+
+Then let‚Äôs split the data into two:
+
+``` r
+# stem laureates
+___ <- nobel %>%
+  filter(___)
+
+# non-steam laureates
+___ <- nobel %>%
+  filter(___)
+```
+
+And finally write out the data:
+
+``` r
+# add code for writing out the two data frames here
+```

---FILE: course-materials/application-exercises/ae-06-nobels-sales-dataimport/sales-excel.Rmd---
@@ -0,0 +1,30 @@
+---
+title: ""Sales""
+author: ""Mine √áetinkaya-Rundel""
+output: github_document
+---
+
+```{r load-packages, message=FALSE}
+library(tidyverse)
+library(readxl)
+```
+
+-   Read in the Excel file called `sales.xlsx` from the `data-raw/` folder such that it looks like the following.
+
+```{r echo=FALSE, out.width=""20%""}
+knitr::include_graphics(""images/sales-1.png"")
+```
+
+```{r}
+
+```
+
+-   **Stretch goal:** Manipulate the sales data such such that it looks like the following.
+
+```{r echo=FALSE, out.width=""25%""}
+knitr::include_graphics(""images/sales-2.png"")
+```
+
+```{r}
+
+```

---FILE: course-materials/application-exercises/ae-06-nobels-sales-dataimport/sales-excel.md---
@@ -0,0 +1,18 @@
+Sales
+================
+Mine √áetinkaya-Rundel
+
+``` r
+library(tidyverse)
+library(readxl)
+```
+
+-   Read in the Excel file called `sales.xlsx` from the `data-raw/`
+    folder such that it looks like the following.
+
+<img src=""images/sales-1.png"" width=""20%"" />
+
+-   **Stretch goal:** Manipulate the sales data such such that it looks
+    like the following.
+
+<img src=""images/sales-2.png"" width=""25%"" />

---FILE: course-materials/application-exercises/ae-07-brexit-story-dataviz/brexit.Rmd---
@@ -0,0 +1,99 @@
+---
+title: ""Brexit""
+author: ""Mine √áetinkaya-Rundel""
+output: github_document
+---
+
+```{r load-packages, message = FALSE, echo = FALSE}
+library(tidyverse)
+```
+
+In September 2019, YouGov survey asked 1,639 GB adults the following question:
+
+> In hindsight, do you think Britain was right/wrong to vote to leave EU?
+>
+> -   Right to leave  
+> -   Wrong to leave  
+> -   Don't know
+
+The data from the survey are in `data/brexit.csv`.
+
+```{r message = FALSE}
+brexit <- read_csv(""data/brexit.csv"")
+```
+
+In the course video we made the following visualisation.
+
+```{r}
+brexit <- brexit %>%
+  mutate(
+    region = fct_relevel(region, ""london"", ""rest_of_south"", ""midlands_wales"", ""north"", ""scot""),
+    region = fct_recode(region, London = ""london"", `Rest of South` = ""rest_of_south"", `Midlands / Wales` = ""midlands_wales"", North = ""north"", Scotland = ""scot"")
+  )
+
+ggplot(brexit, aes(y = opinion, fill = opinion)) +
+  geom_bar() +
+  facet_wrap(~region, nrow = 1, labeller = label_wrap_gen(width = 12)) +
+  guides(fill = FALSE) +
+  labs(
+    title = ""Was Britain right/wrong to vote to leave EU?"",
+    subtitle = ""YouGov Survey Results, 2-3 September 2019"",
+    caption = ""Source: bit.ly/2lCJZVg"",
+    x = NULL, y = NULL
+  ) +
+  scale_fill_manual(values = c(
+    ""Wrong"" = ""#ef8a62"",
+    ""Right"" = ""#67a9cf"",
+    ""Don't know"" = ""gray""
+  )) +
+  theme_minimal()
+```
+
+In this application exercise we tell different stories with the same data.
+
+### Exercise 1 - Free scales
+
+Add `scales = ""free_x""` as an argument to the `facet_wrap()` function.
+How does the visualisation change?
+How is the story this visualisation telling different than the story the original plot tells?
+
+```{r}
+ggplot(brexit, aes(y = opinion, fill = opinion)) +
+  geom_bar() +
+  facet_wrap(~region,
+    nrow = 1, labeller = label_wrap_gen(width = 12),
+    # ___
+  ) +
+  guides(fill = FALSE) +
+  labs(
+    title = ""Was Britain right/wrong to vote to leave EU?"",
+    subtitle = ""YouGov Survey Results, 2-3 September 2019"",
+    caption = ""Source: bit.ly/2lCJZVg"",
+    x = NULL, y = NULL
+  ) +
+  scale_fill_manual(values = c(
+    ""Wrong"" = ""#ef8a62"",
+    ""Right"" = ""#67a9cf"",
+    ""Don't know"" = ""gray""
+  )) +
+  theme_minimal()
+```
+
+### Exercise 2 - Comparing proportions across facets
+
+First, calculate the proportion of wrong, right, and don't know answers in each category and then plot these proportions (rather than the counts) and then improve axis labeling.
+How is the story this visualisation telling different than the story the original plot tells?
+**Hint:** You'll need the **scales** package to improve axis labeling, which means you'll need to load it on top of the document as well.
+
+```{r}
+# code goes here
+```
+
+### Exercise 3 - Comparing proportions across bars
+
+Recreate the same visualisation from the previous exercise, this time dodging the bars for opinion proportions for each region, rather than faceting by region and then improve the legend.
+How is the story this visualisation telling different than the story the previous plot tells?
+
+```{r}
+# code goes here
+```

---FILE: course-materials/application-exercises/ae-07-brexit-story-dataviz/brexit.md---
@@ -0,0 +1,105 @@
+Brexit
+================
+Mine √áetinkaya-Rundel
+
+In September 2019, YouGov survey asked 1,639 GB adults the following
+question:
+
+> In hindsight, do you think Britain was right/wrong to vote to leave
+> EU?
+>
+> -   Right to leave  
+> -   Wrong to leave  
+> -   Don‚Äôt know
+
+The data from the survey are in `data/brexit.csv`.
+
+``` r
+brexit <- read_csv(""data/brexit.csv"")
+```
+
+In the course video we made the following visualisation.
+
+``` r
+brexit <- brexit %>%
+  mutate(
+    region = fct_relevel(region, ""london"", ""rest_of_south"", ""midlands_wales"", ""north"", ""scot""),
+    region = fct_recode(region, London = ""london"", `Rest of South` = ""rest_of_south"", `Midlands / Wales` = ""midlands_wales"", North = ""north"", Scotland = ""scot"")
+  )
+
+ggplot(brexit, aes(y = opinion, fill = opinion)) +
+  geom_bar() +
+  facet_wrap(~region, nrow = 1, labeller = label_wrap_gen(width = 12)) +
+  guides(fill = FALSE) +
+  labs(
+    title = ""Was Britain right/wrong to vote to leave EU?"",
+    subtitle = ""YouGov Survey Results, 2-3 September 2019"",
+    caption = ""Source: bit.ly/2lCJZVg"",
+    x = NULL, y = NULL
+  ) +
+  scale_fill_manual(values = c(
+    ""Wrong"" = ""#ef8a62"",
+    ""Right"" = ""#67a9cf"",
+    ""Don't know"" = ""gray""
+  )) +
+  theme_minimal()
+```
+
+![](brexit_files/figure-gfm/unnamed-chunk-2-1.png)<!-- -->
+
+In this application exercise we tell different stories with the same
+data.
+
+### Exercise 1 - Free scales
+
+Add `scales = ""free_x""` as an argument to the `facet_wrap()` function.
+How does the visualisation change? How is the story this visualisation
+telling different than the story the original plot tells?
+
+``` r
+ggplot(brexit, aes(y = opinion, fill = opinion)) +
+  geom_bar() +
+  facet_wrap(~region,
+    nrow = 1, labeller = label_wrap_gen(width = 12),
+    # ___
+  ) +
+  guides(fill = FALSE) +
+  labs(
+    title = ""Was Britain right/wrong to vote to leave EU?"",
+    subtitle = ""YouGov Survey Results, 2-3 September 2019"",
+    caption = ""Source: bit.ly/2lCJZVg"",
+    x = NULL, y = NULL
+  ) +
+  scale_fill_manual(values = c(
+    ""Wrong"" = ""#ef8a62"",
+    ""Right"" = ""#67a9cf"",
+    ""Don't know"" = ""gray""
+  )) +
+  theme_minimal()
+```
+
+![](brexit_files/figure-gfm/unnamed-chunk-3-1.png)<!-- -->
+
+### Exercise 2 - Comparing proportions across facets
+
+First, calculate the proportion of wrong, right, and don‚Äôt know answers
+in each category and then plot these proportions (rather than the
+counts) and then improve axis labeling. How is the story this
+visualisation telling different than the story the original plot tells?
+**Hint:** You‚Äôll need the **scales** package to improve axis labeling,
+which means you‚Äôll need to load it on top of the document as well.
+
+``` r
+# code goes here
+```
+
+### Exercise 3 - Comparing proportions across bars
+
+Recreate the same visualisation from the previous exercise, this time
+dodging the bars for opinion proportions for each region, rather than
+faceting by region and then improve the legend. How is the story this
+visualisation telling different than the story the previous plot tells?
+
+``` r
+# code goes here
+```

---FILE: course-materials/application-exercises/ae-07-brexit-story-dataviz/data/brexit.csv---
@@ -0,0 +1,1640 @@
+opinion,region
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,london
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,rest_of_south
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,midlands_wales
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,north
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Right,scot
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,london
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,rest_of_south
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,midlands_wales
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,north
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Wrong,scot
+Don't know,london
+Don't know,london
+Don't know,london
+Don't know,london
+Don't know,london
+Don't know,london
+Don't know,london
+Don't know,london
+Don't know,london
+Don't know,london
+Don't know,london
+Don't know,london
+Don't know,london
+Don't know,london
+Don't know,london
+Don't know,london
+Don't know,london
+Don't know,london
+Don't know,london
+Don't know,london
+Don't know,london
+Don't know,london
+Don't know,london
+Don't know,london
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,rest_of_south
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,midlands_wales
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,north
+Don't know,scot
+Don't know,scot
+Don't know,scot
+Don't know,scot
+Don't know,scot
+Don't know,scot
+Don't know,scot
+Don't know,scot
+Don't know,scot
+Don't know,scot

---FILE: course-materials/application-exercises/ae-07-nobels-sales-dataimport/food-excel.Rmd---
@@ -1,80 +0,0 @@
----
-title: ""Favourite foods""
-author: ""Mine √áetinkaya-Rundel""
-date: ""`r Sys.Date()`""
-output: 
-  html_document: 
-    toc: yes
-    toc_float: yes
----
-
-```{r load-packages, message=FALSE}
-library(tidyverse)
-library(readxl)
-```
-
-## Exercise 1
-
-* Read in the Excel file called `favourite-food.xlsx` from the `data-raw/` folder.
-
-```{r label-me1, eval=FALSE}
-fav_food <- read_excel(___)
-fav_food
-```
-
-* Clean up `NA`s and make sure you're happy with variable types.
-
-```{r label-me2, eval=FALSE}
-fav_food <- read_excel(___, ___)
-fav_food 
-```
-
-* Convert SES (socio economic status) to a factor variables with levels in the 
-following order: `Low`, `Middle`, `High`.
-
-```{r label-me3}
-# add code here
-```
-
-* Write out the resulting data frame to `favourite-food.csv` in the `data/` folder.
-
-```{r label-me4}
-# add code here
-```
-
-* Finally, read `favourite-food.csv` back in from the `data/` folder and 
-observe the variable types. Are they as you left them?
-
-```{r label-me5}
-# add code here
-```
-
-## Exercise 2
-
-* Read in the Excel file called `favourite-food.xlsx` from the `data-raw/` folder, 
-taking care of `NA`s and variable types.
-
-```{r label-me6, eval=FALSE}
-fav_food <- read_excel(___, ___)
-fav_food 
-```
-
-* Convert SES (socio economic status) to a factor variables with levels in the 
-following order: `Low`, `Middle`, `High`.
-
-```{r label-me7}
-# add code here
-```
-
-* Write out the resulting data frame to `favourite-food.rds` in the `data/` folder.
-
-```{r label-me8}
-# add code here
-```
-
-* Read `favourite-food.rds` back in from the `data/` folder and observe the 
-variable types. Are they as you left them?
-
-```{r label-me9}
-# add code here
-```

---FILE: course-materials/application-exercises/ae-07-nobels-sales-dataimport/sales-excel.Rmd---
@@ -1,34 +0,0 @@
----
-title: ""Sales""
-author: ""Mine √áetinkaya-Rundel""
-date: ""`r Sys.Date()`""
-output: html_document
----
-
-```{r load-packages, message=FALSE}
-library(tidyverse)
-library(readxl)
-```
-
-* Read in the Excel file called `sales.xlsx` from the `data-raw/` folder 
-such that it looks like the following.
-
-```{r echo=FALSE}
-knitr::include_graphics(""images/sales-1.png"")
-```
-
-```{r}
-
-```
-
-* **Stretch goal:** Manipulate the sales data such such that it looks like the 
-following.
-
-```{r echo=FALSE}
-knitr::include_graphics(""images/sales-2.png"")
-```
-
-```{r}
-
-```
-

---FILE: course-materials/application-exercises/ae-08-imdb-webscraping/01-imdb-250movies.R---
@@ -1,32 +1,46 @@
+## Scrape the list of top 250 movies from https://www.imdb.com/chart/top
+
 # Load packages ---------------------------------------------------------------
+
 library(tidyverse)
 library(rvest)
 
 # Read html page ---------------------------------------------------------------
-page <- read_html(""https://www.imdb.com/chart/top"")
+
+page <- read_html(""___"")
 
 # Titles -----------------------------------------------------------------------
+
 titles <- page %>%
-  html_nodes("".titleColumn a"") %>%
+  html_nodes(""___"") %>%
   html_text()
 
 # Years-------------------------------------------------------------------------
+
 years <- page %>%
-  html_nodes("".secondaryInfo"") %>%
+  html_nodes(""___"") %>%
   html_text() %>%
-  str_remove(""\\("") %>%
-  str_remove(""\\)"") %>%
+  str_remove(""___"") %>%
+  str_remove(""___"") %>%
   as.numeric()
 
 # Scores -----------------------------------------------------------------------
-scores <- page %>%
-  html_nodes(""#main strong"") %>%
-  html_text() %>%
-  as.numeric()
+
+ratings <- page %>%
+  html_nodes(""___"") %>%
+  ___ %>%
+  ___
 
 # Put it all in a data frame ---------------------------------------------------
-top250 <- tibble(
-  title = titles,
-  score = scores,
-  year = years
+
+imdb_top_250 <- tibble(
+  title = ___,
+  rating = ___,
+  year = ___
 )
+
+# Add rank ---------------------------------------------------------------------
+
+imdb_top_250 <- imdb_top_250 %>%
+  mutate(rank = 1:nrow(imdb_top_250)) %>%
+  relocate(rank)

---FILE: course-materials/application-exercises/ae-08-imdb-webscraping/02-imdb-tvshows.R---
@@ -1,24 +1,32 @@
+## Scrape the list of most populat TV shows from https://www.imdb.com/chart/tvmeter
+
 # load packages ----------------------------------------------------------------
+
 library(tidyverse)
 library(rvest)
 
 # read in http://www.imdb.com/chart/tvmeter ------------------------------------
+
 page <- read_html(""___"")
 
 # years ------------------------------------------------------------------------
+
 years <- page %>%
   html_nodes(""___"") %>%
   html_text() %>%
   ___
 
 # scores -----------------------------------------------------------------------
+
 scores <- page %>%
   ___
 
 # names ------------------------------------------------------------------------
+
 names <- ___
 
 # tvshows dataframe ------------------------------------------------------------
+
 tvshows <- tibble(
   rank = 1:100,
   ___,
@@ -28,28 +36,28 @@ tvshows <- tibble(
 )
 
 # add new variables ------------------------------------------------------------
+
 tvshows <- tvshows %>%
   mutate(
     genre = NA,
     runtime = NA,
     n_episode = NA,
-    keywords = NA
   )
 
 # add new info for first show --------------------------------------------------
+
 tvshows$genre[1] <- ""__""
-tvshows$runtime[1] <- ""___""
-tvshows$n_episode[1] <- ""___""
-tvshows$keywords[[1]] <- c(""___"", ""___"", ""___"", ""___"", ""___"")
+tvshows$runtime[1] <- ___
+tvshows$n_episode[1] <- ___
 
 # add new info for second show --------------------------------------------------
+
 tvshows$genre[2] <- ""__""
-tvshows$runtime[2] <- ""___""
-tvshows$n_episode[2] <- ""___""
-tvshows$keywords[[2]] <- c(""___"", ""___"", ""___"", ""___"", ""___"")
+tvshows$runtime[2] <- ___
+tvshows$n_episode[2] <- ___
 
 # add new info for third show --------------------------------------------------
+
 tvshows$genre[3] <- ""__""
-tvshows$runtime[3] <- ""___""
-tvshows$n_episode[3] <- ""___""
-tvshows$keywords[[3]] <- c(""___"", ""___"", ""___"", ""___"", ""___"")
+tvshows$runtime[3] <- ___
+tvshows$n_episode[3] <- ___

---FILE: course-materials/application-exercises/ae-08-imdb-webscraping/03-imdb-250movies-complete.R---
@@ -1,32 +1,46 @@
+## Scrape the list of top 250 movies from https://www.imdb.com/chart/top
+
 # Load packages ---------------------------------------------------------------
+
 library(tidyverse)
 library(rvest)
 
-# Read html page --------------------------------------------------------------
-page <- read_html(""http://www.imdb.com/chart/top"")
+# Read html page ---------------------------------------------------------------
+
+page <- read_html(""https://www.imdb.com/chart/top"")
+
+# Titles -----------------------------------------------------------------------
 
-# Titles ----------------------------------------------------------------------
 titles <- page %>%
   html_nodes("".titleColumn a"") %>%
   html_text()
 
-# Years -----------------------------------------------------------------------
+# Years-------------------------------------------------------------------------
+
 years <- page %>%
   html_nodes("".secondaryInfo"") %>%
   html_text() %>%
-  str_remove(""\\("") %>% # remove (
-  str_remove(""\\)"") %>% # remove )
+  str_remove(""\\("") %>%
+  str_remove(""\\)"") %>%
   as.numeric()
 
-# Scores ----------------------------------------------------------------------
+# Scores -----------------------------------------------------------------------
+
 scores <- page %>%
-  html_nodes(""#main strong"") %>%
+  html_nodes(""strong"") %>%
   html_text() %>%
   as.numeric()
 
-# Create data frame -----------------------------------------------------------
+# Put it all in a data frame ---------------------------------------------------
+
 imdb_top_250 <- tibble(
-  title = titles, 
-  year = years, 
-  score = scores
+  title = titles,
+  rating = ratings,
+  year = years
 )
+
+# Add rank ---------------------------------------------------------------------
+
+imdb_top_250 <- imdb_top_250 %>%
+  mutate(rank = 1:nrow(imdb_top_250)) %>%
+  relocate(rank)

---FILE: course-materials/application-exercises/ae-08-imdb-webscraping/04-imdb-tvshows-complete.R---
@@ -1,11 +1,16 @@
+## Scrape the list of most popular TV shows from https://www.imdb.com/chart/tvmeter
+
 # load packages ----------------------------------------------------------------
+
 library(tidyverse)
 library(rvest)
 
 # read in http://www.imdb.com/chart/tvmeter ------------------------------------
-page <- read_html(""http://www.imdb.com/chart/tvmeter"")
+
+page <- read_html(""https://www.imdb.com/chart/tvmeter"")
 
 # years ------------------------------------------------------------------------
+
 years <- page %>%
   html_nodes(""a+ .secondaryInfo"") %>%
   html_text() %>%
@@ -14,52 +19,56 @@ years <- page %>%
   as.numeric()
 
 # scores -----------------------------------------------------------------------
+
 scores <- page %>%
   html_nodes("".imdbRating"") %>%
   html_text() %>%
-  str_replace_all(""\n"", """") %>%
-  str_trim() %>%
   as.numeric()
 
 # names ------------------------------------------------------------------------
+
 names <- page %>%
   html_nodes("".titleColumn"") %>%
   html_text() %>%
-  str_trim() %>%
-  str_extract(""^(.+?)\\n"") %>%
-  str_remove(""\n"")
+  str_remove_all(""\n"") %>%
+  str_squish()
 
 # tvshows dataframe ------------------------------------------------------------
+
 tvshows <- tibble(
   rank = 1:100,
   name = names,
   year = years,
   score = scores
 )
 
+tvshows <- tvshows %>%
+  separate(col = name, into = c(""name"", ""other_info""), sep = "" \\("", extra = ""merge"") %>%
+  select(-other_info)
+
 # add new variables ------------------------------------------------------------
+
 tvshows <- tvshows %>%
   mutate(
     genre = NA,
     runtime = NA,
     n_episode = NA,
-    keywords = NA
   )
 
 # add new info for first show --------------------------------------------------
-tvshows$genre[1] <- ""__""
-tvshows$runtime[1] <- ""___""
-tvshows$n_episode[1] <- ""___""
-tvshows$keywords[[1]] <- c(""___"", ""___"", ""___"", ""___"", ""___"")
+
+tvshows$genre[1] <- ""Drama, Horror, Mystery""
+tvshows$runtime[1] <- 494
+tvshows$n_episode[1] <- 9
 
 # add new info for second show --------------------------------------------------
-tvshows$genre[2] <- ""__""
-tvshows$runtime[2] <- ""___""
-tvshows$n_episode[2] <- ""___""
-tvshows$keywords[[2]] <- c(""___"", ""___"", ""___"", ""___"", ""___"")
+
+tvshows$genre[2] <- ""Action, Comedy, Crime""
+tvshows$runtime[2] <- 60
+tvshows$n_episode[2] <- 17
 
 # add new info for third show --------------------------------------------------
+
 tvshows$genre[3] <- ""__""
-tvshows$runtime[3] <- ""___""
-tvshows$n_episode[3] <- ""___""
-tvshows$keywords[[3]] <- c(""___"", ""___"", ""___"", ""___"", ""___"")
+tvshows$runtime[3] <- ___
+tvshows$n_episode[3] <- ___

---FILE: course-materials/application-exercises/ae-09-feat-eng-cv/theoffice-solution.Rmd---
@@ -0,0 +1,197 @@
+---
+title: ""The Office""
+author: ""Mine √áetinkaya-Rundel""
+output: github_document
+---
+
+```{r load-packages, message = FALSE}
+library(tidyverse)
+library(tidymodels)
+library(schrute)
+library(lubridate)
+```
+
+Use `theoffice` data from the [**schrute**](https://bradlindblad.github.io/schrute/) package to predict IMDB scores for episodes of The Office.
+
+```{r}
+glimpse(theoffice)
+```
+
+Fix `air_date` for later use.
+
+```{r}
+theoffice <- theoffice %>%
+  mutate(air_date = ymd(as.character(air_date)))
+```
+
+We will
+
+-   engineer features based on episode scripts
+-   train a model
+-   perform cross validation
+-   make predictions
+
+Note: The episodes listed in `theoffice` don't match the ones listed in the data we used in the [cross validation lesson](https://ids-s1-20.github.io/slides/week-10/w10-d02-cross-validation/w10-d02-cross-validation.html).
+
+```{r}
+theoffice %>%
+  distinct(season, episode)
+```
+
+### Exercise 1 - Calculate the percentage of lines spoken by Jim, Pam, Michael, and Dwight for each episode of The Office.
+
+```{r lines}
+office_lines <- theoffice %>%
+  group_by(season, episode) %>%
+  mutate(
+    n_lines = n(),
+    lines_jim = sum(character == ""Jim"") / n_lines,
+    lines_pam = sum(character == ""Pam"") / n_lines,
+    lines_michael = sum(character == ""Michael"") / n_lines,
+    lines_dwight = sum(character == ""Dwight"") / n_lines,
+  ) %>%
+  ungroup() %>%
+  select(season, episode, episode_name, contains(""lines_"")) %>%
+  distinct(season, episode, episode_name, .keep_all = TRUE)
+```
+
+### Exercise 2 - Identify episodes that touch on Halloween, Valentine's Day, and Christmas.
+
+```{r special-episodes}
+theoffice <- theoffice %>%
+  mutate(text = tolower(text))
+
+halloween_episodes <- theoffice %>%
+  filter(str_detect(text, ""halloween"")) %>% 
+  count(episode_name) %>%
+  filter(n > 1) %>%
+  mutate(halloween = 1) %>%
+  select(-n)
+
+valentine_episodes <- theoffice %>%
+  filter(str_detect(text, ""valentine"")) %>% 
+  count(episode_name) %>%
+  filter(n > 1) %>%
+  mutate(valentine = 1) %>%
+  select(-n)
+
+christmas_episodes <- theoffice %>%
+  filter(str_detect(text, ""christmas"")) %>% 
+  count(episode_name) %>%
+  filter(n > 1) %>%
+  mutate(christmas = 1) %>%
+  select(-n)
+```
+
+### Exercise 3 - Put together a modeling dataset that includes features you've engineered. Also add an indicator variable called `michael` which takes the value `1` if Michael Scott (Steve Carrell) was there, and `0` if not. Note: Michael Scott (Steve Carrell) left the show at the end of Season 7.
+
+```{r office-df}
+office_df <- theoffice %>%
+  select(season, episode, episode_name, imdb_rating, total_votes, air_date) %>%
+  distinct(season, episode, .keep_all = TRUE) %>%
+  left_join(halloween_episodes, by = ""episode_name"") %>% 
+  left_join(valentine_episodes, by = ""episode_name"") %>% 
+  left_join(christmas_episodes, by = ""episode_name"") %>% 
+  replace_na(list(halloween = 0, valentine = 0, christmas = 0)) %>%
+  mutate(michael = if_else(season > 7, 0, 1)) %>%
+  mutate(across(halloween:michael, as.factor)) %>%
+  left_join(office_lines, by = c(""season"", ""episode"", ""episode_name""))
+```
+
+### Exercise 4 - Split the data into training (75%) and testing (25%).
+
+```{r split}
+set.seed(1122)
+office_split <- initial_split(office_df)
+office_train <- training(office_split)
+office_test <- testing(office_split)
+```
+
+### Exercise 5 - Specify a linear regression model.
+
+```{r model}
+office_mod <- linear_reg() %>%
+  set_engine(""lm"")
+```
+
+### Exercise 6 - Create a recipe that updates the role of `episode_name` to not be a predictor, removes `air_date` as a predictor, and removes all zero variance predictors.
+
+```{r recipe}
+office_rec <- recipe(imdb_rating ~ ., data = office_train) %>%
+  update_role(episode_name, new_role = ""id"") %>%
+  step_rm(air_date) %>%
+  step_dummy(all_nominal(), -episode_name) %>%
+  step_zv(all_predictors())
+```
+
+### Exercise 7 - Build a workflow for fitting the model specified earlier and using the recipe you developed to preprocess the data.
+
+```{r workflow}
+office_wflow <- workflow() %>%
+  add_model(office_mod) %>%
+  add_recipe(office_rec)
+```
+
+### Exercise 8 - Fit the model to training data and interpret a couple of the slope coefficients.
+
+```{r fit}
+office_fit <- office_wflow %>%
+  fit(data = office_train)
+
+tidy(office_fit)
+```
+
+### Exercise 9 - Perform 5-fold cross validation and view model performance metrics.
+
+```{r cv, message=FALSE, error = TRUE}
+set.seed(345)
+folds <- vfold_cv(office_train, v = 5)
+folds
+
+set.seed(456)
+office_fit_rs <- office_wflow %>%
+  fit_resamples(folds)
+
+collect_metrics(office_fit_rs)
+```
+
+### Exercise 10 - Use your model to make predictions for the testing data and calculate the RMSE. Also use the model developed in the [cross validation lesson](https://ids-s1-20.github.io/slides/week-10/w10-d02-cross-validation/w10-d02-cross-validation.html) to make predictions for the testing data and calculate the RMSE as well. Which model did a better job in predicting IMDB scores for the testing data?
+
+#### New model
+
+```{r new-model}
+office_test_pred <- predict(office_fit, new_data = office_test) %>%
+  bind_cols(office_test %>% select(imdb_rating, episode_name))
+
+rmse(office_test_pred, truth = imdb_rating, estimate = .pred)
+```
+
+#### Old model
+
+```{r old-model, error = TRUE}
+office_mod_old <- linear_reg() %>%
+  set_engine(""lm"")
+
+office_rec_old <- recipe(imdb_rating ~ season + episode + total_votes + air_date, data = office_train) %>%
+  # extract month of air_date
+  step_date(air_date, features = ""month"") %>%
+  step_rm(air_date) %>%
+  # make dummy variables of month 
+  step_dummy(contains(""month"")) %>%
+  # remove zero variance predictors
+  step_zv(all_predictors())
+
+office_wflow_old <- workflow() %>%
+  add_model(office_mod_old) %>%
+  add_recipe(office_rec_old)
+
+office_fit_old <- office_wflow_old %>%
+  fit(data = office_train)
+
+tidy(office_fit_old)
+
+office_test_pred_old <- predict(office_fit_old, new_data = office_test) %>%
+  bind_cols(office_test %>% select(imdb_rating, episode_name))
+
+rmse(office_test_pred_old, truth = imdb_rating, estimate = .pred)
+```

---FILE: course-materials/application-exercises/ae-09-feat-eng-cv/theoffice-solution.md---
@@ -0,0 +1,291 @@
+The Office
+================
+Mine √áetinkaya-Rundel
+
+``` r
+library(tidyverse)
+library(tidymodels)
+library(schrute)
+library(lubridate)
+```
+
+Use `theoffice` data from the
+[**schrute**](https://bradlindblad.github.io/schrute/) package to
+predict IMDB scores for episodes of The Office.
+
+``` r
+glimpse(theoffice)
+```
+
+    ## Rows: 55,130
+    ## Columns: 12
+    ## $ index            <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1‚Ä¶
+    ## $ season           <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶
+    ## $ episode          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶
+    ## $ episode_name     <chr> ""Pilot"", ""Pilot"", ""Pilot"", ""Pilot"", ""Pilot"", ""Pilot""‚Ä¶
+    ## $ director         <chr> ""Ken Kwapis"", ""Ken Kwapis"", ""Ken Kwapis"", ""Ken Kwapi‚Ä¶
+    ## $ writer           <chr> ""Ricky Gervais;Stephen Merchant;Greg Daniels"", ""Rick‚Ä¶
+    ## $ character        <chr> ""Michael"", ""Jim"", ""Michael"", ""Jim"", ""Michael"", ""Mich‚Ä¶
+    ## $ text             <chr> ""All right Jim. Your quarterlies look very good. How‚Ä¶
+    ## $ text_w_direction <chr> ""All right Jim. Your quarterlies look very good. How‚Ä¶
+    ## $ imdb_rating      <dbl> 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.‚Ä¶
+    ## $ total_votes      <int> 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706‚Ä¶
+    ## $ air_date         <fct> 2005-03-24, 2005-03-24, 2005-03-24, 2005-03-24, 2005‚Ä¶
+
+Fix `air_date` for later use.
+
+``` r
+theoffice <- theoffice %>%
+  mutate(air_date = ymd(as.character(air_date)))
+```
+
+We will
+
+-   engineer features based on episode scripts
+-   train a model
+-   perform cross validation
+-   make predictions
+
+Note: The episodes listed in `theoffice` don‚Äôt match the ones listed in
+the data we used in the [cross validation
+lesson](https://ids-s1-20.github.io/slides/week-10/w10-d02-cross-validation/w10-d02-cross-validation.html).
+
+``` r
+theoffice %>%
+  distinct(season, episode)
+```
+
+    ## # A tibble: 186 x 2
+    ##    season episode
+    ##     <int>   <int>
+    ##  1      1       1
+    ##  2      1       2
+    ##  3      1       3
+    ##  4      1       4
+    ##  5      1       5
+    ##  6      1       6
+    ##  7      2       1
+    ##  8      2       2
+    ##  9      2       3
+    ## 10      2       4
+    ## # ‚Ä¶ with 176 more rows
+
+### Exercise 1 - Calculate the percentage of lines spoken by Jim, Pam, Michael, and Dwight for each episode of The Office.
+
+``` r
+office_lines <- theoffice %>%
+  group_by(season, episode) %>%
+  mutate(
+    n_lines = n(),
+    lines_jim = sum(character == ""Jim"") / n_lines,
+    lines_pam = sum(character == ""Pam"") / n_lines,
+    lines_michael = sum(character == ""Michael"") / n_lines,
+    lines_dwight = sum(character == ""Dwight"") / n_lines,
+  ) %>%
+  ungroup() %>%
+  select(season, episode, episode_name, contains(""lines_"")) %>%
+  distinct(season, episode, episode_name, .keep_all = TRUE)
+```
+
+### Exercise 2 - Identify episodes that touch on Halloween, Valentine‚Äôs Day, and Christmas.
+
+``` r
+theoffice <- theoffice %>%
+  mutate(text = tolower(text))
+
+halloween_episodes <- theoffice %>%
+  filter(str_detect(text, ""halloween"")) %>% 
+  count(episode_name) %>%
+  filter(n > 1) %>%
+  mutate(halloween = 1) %>%
+  select(-n)
+
+valentine_episodes <- theoffice %>%
+  filter(str_detect(text, ""valentine"")) %>% 
+  count(episode_name) %>%
+  filter(n > 1) %>%
+  mutate(valentine = 1) %>%
+  select(-n)
+
+christmas_episodes <- theoffice %>%
+  filter(str_detect(text, ""christmas"")) %>% 
+  count(episode_name) %>%
+  filter(n > 1) %>%
+  mutate(christmas = 1) %>%
+  select(-n)
+```
+
+### Exercise 3 - Put together a modeling dataset that includes features you‚Äôve engineered. Also add an indicator variable called `michael` which takes the value `1` if Michael Scott (Steve Carrell) was there, and `0` if not. Note: Michael Scott (Steve Carrell) left the show at the end of Season 7.
+
+``` r
+office_df <- theoffice %>%
+  select(season, episode, episode_name, imdb_rating, total_votes, air_date) %>%
+  distinct(season, episode, .keep_all = TRUE) %>%
+  left_join(halloween_episodes, by = ""episode_name"") %>% 
+  left_join(valentine_episodes, by = ""episode_name"") %>% 
+  left_join(christmas_episodes, by = ""episode_name"") %>% 
+  replace_na(list(halloween = 0, valentine = 0, christmas = 0)) %>%
+  mutate(michael = if_else(season > 7, 0, 1)) %>%
+  mutate(across(halloween:michael, as.factor)) %>%
+  left_join(office_lines, by = c(""season"", ""episode"", ""episode_name""))
+```
+
+### Exercise 4 - Split the data into training (75%) and testing (25%).
+
+``` r
+set.seed(1122)
+office_split <- initial_split(office_df)
+office_train <- training(office_split)
+office_test <- testing(office_split)
+```
+
+### Exercise 5 - Specify a linear regression model.
+
+``` r
+office_mod <- linear_reg() %>%
+  set_engine(""lm"")
+```
+
+### Exercise 6 - Create a recipe that updates the role of `episode_name` to not be a predictor, removes `air_date` as a predictor, and removes all zero variance predictors.
+
+``` r
+office_rec <- recipe(imdb_rating ~ ., data = office_train) %>%
+  update_role(episode_name, new_role = ""id"") %>%
+  step_rm(air_date) %>%
+  step_dummy(all_nominal(), -episode_name) %>%
+  step_zv(all_predictors())
+```
+
+### Exercise 7 - Build a workflow for fitting the model specified earlier and using the recipe you developed to preprocess the data.
+
+``` r
+office_wflow <- workflow() %>%
+  add_model(office_mod) %>%
+  add_recipe(office_rec)
+```
+
+### Exercise 8 - Fit the model to training data and interpret a couple of the slope coefficients.
+
+``` r
+office_fit <- office_wflow %>%
+  fit(data = office_train)
+
+tidy(office_fit)
+```
+
+    ## # A tibble: 12 x 5
+    ##    term           estimate std.error statistic  p.value
+    ##    <chr>             <dbl>     <dbl>     <dbl>    <dbl>
+    ##  1 (Intercept)    6.39     0.323      19.8     9.73e-41
+    ##  2 season         0.0423   0.0240      1.76    8.03e- 2
+    ##  3 episode        0.0118   0.00427     2.77    6.47e- 3
+    ##  4 total_votes    0.000512 0.0000625   8.19    2.32e-13
+    ##  5 lines_jim      0.629    0.664       0.946   3.46e- 1
+    ##  6 lines_pam     -0.00587  0.717      -0.00818 9.93e- 1
+    ##  7 lines_michael -0.743    0.623      -1.19    2.35e- 1
+    ##  8 lines_dwight   0.348    0.545       0.639   5.24e- 1
+    ##  9 halloween_X1  -0.183    0.180      -1.01    3.12e- 1
+    ## 10 valentine_X1  -0.120    0.158      -0.759   4.49e- 1
+    ## 11 christmas_X1   0.246    0.137       1.79    7.56e- 2
+    ## 12 michael_X1     0.598    0.166       3.61    4.43e- 4
+
+### Exercise 9 - Perform 5-fold cross validation and view model performance metrics.
+
+``` r
+set.seed(345)
+folds <- vfold_cv(office_train, v = 5)
+folds
+```
+
+    ## #  5-fold cross-validation 
+    ## # A tibble: 5 x 2
+    ##   splits           id   
+    ##   <list>           <chr>
+    ## 1 <split [112/28]> Fold1
+    ## 2 <split [112/28]> Fold2
+    ## 3 <split [112/28]> Fold3
+    ## 4 <split [112/28]> Fold4
+    ## 5 <split [112/28]> Fold5
+
+``` r
+set.seed(456)
+office_fit_rs <- office_wflow %>%
+  fit_resamples(folds)
+
+collect_metrics(office_fit_rs)
+```
+
+    ## # A tibble: 2 x 6
+    ##   .metric .estimator  mean     n std_err .config             
+    ##   <chr>   <chr>      <dbl> <int>   <dbl> <chr>               
+    ## 1 rmse    standard   0.362     5  0.0226 Preprocessor1_Model1
+    ## 2 rsq     standard   0.553     5  0.0782 Preprocessor1_Model1
+
+### Exercise 10 - Use your model to make predictions for the testing data and calculate the RMSE. Also use the model developed in the [cross validation lesson](https://ids-s1-20.github.io/slides/week-10/w10-d02-cross-validation/w10-d02-cross-validation.html) to make predictions for the testing data and calculate the RMSE as well. Which model did a better job in predicting IMDB scores for the testing data?
+
+#### New model
+
+``` r
+office_test_pred <- predict(office_fit, new_data = office_test) %>%
+  bind_cols(office_test %>% select(imdb_rating, episode_name))
+
+rmse(office_test_pred, truth = imdb_rating, estimate = .pred)
+```
+
+    ## # A tibble: 1 x 3
+    ##   .metric .estimator .estimate
+    ##   <chr>   <chr>          <dbl>
+    ## 1 rmse    standard       0.444
+
+#### Old model
+
+``` r
+office_mod_old <- linear_reg() %>%
+  set_engine(""lm"")
+
+office_rec_old <- recipe(imdb_rating ~ season + episode + total_votes + air_date, data = office_train) %>%
+  # extract month of air_date
+  step_date(air_date, features = ""month"") %>%
+  step_rm(air_date) %>%
+  # make dummy variables of month 
+  step_dummy(contains(""month"")) %>%
+  # remove zero variance predictors
+  step_zv(all_predictors())
+
+office_wflow_old <- workflow() %>%
+  add_model(office_mod_old) %>%
+  add_recipe(office_rec_old)
+
+office_fit_old <- office_wflow_old %>%
+  fit(data = office_train)
+
+tidy(office_fit_old)
+```
+
+    ## # A tibble: 12 x 5
+    ##    term                estimate std.error statistic  p.value
+    ##    <chr>                  <dbl>     <dbl>     <dbl>    <dbl>
+    ##  1 (Intercept)         6.50     0.234        27.7   5.68e-56
+    ##  2 season             -0.0240   0.0156       -1.54  1.27e- 1
+    ##  3 episode             0.0524   0.00841       6.23  6.12e- 9
+    ##  4 total_votes         0.000538 0.0000585     9.19  8.92e-16
+    ##  5 air_date_month_Feb -0.0927   0.119        -0.778 4.38e- 1
+    ##  6 air_date_month_Mar -0.249    0.133        -1.87  6.36e- 2
+    ##  7 air_date_month_Apr -0.238    0.124        -1.92  5.70e- 2
+    ##  8 air_date_month_May -0.192    0.154        -1.25  2.14e- 1
+    ##  9 air_date_month_Sep  0.660    0.161         4.11  7.02e- 5
+    ## 10 air_date_month_Oct  0.463    0.128         3.62  4.27e- 4
+    ## 11 air_date_month_Nov  0.368    0.122         3.00  3.20e- 3
+    ## 12 air_date_month_Dec  0.368    0.145         2.54  1.23e- 2
+
+``` r
+office_test_pred_old <- predict(office_fit_old, new_data = office_test) %>%
+  bind_cols(office_test %>% select(imdb_rating, episode_name))
+
+rmse(office_test_pred_old, truth = imdb_rating, estimate = .pred)
+```
+
+    ## # A tibble: 1 x 3
+    ##   .metric .estimator .estimate
+    ##   <chr>   <chr>          <dbl>
+    ## 1 rmse    standard       0.498

---FILE: course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.Rmd---
@@ -0,0 +1,137 @@
+---
+title: ""The Office""
+author: ""Mine √áetinkaya-Rundel""
+output: github_document
+---
+
+```{r load-packages, message = FALSE}
+library(tidyverse)
+library(tidymodels)
+library(schrute)
+library(lubridate)
+```
+
+Use `theoffice` data from the [**schrute**](https://bradlindblad.github.io/schrute/) package to predict IMDB scores for episodes of The Office.
+
+```{r}
+glimpse(theoffice)
+```
+
+Fix `air_date` for later use.
+
+```{r}
+theoffice <- theoffice %>%
+  mutate(air_date = ymd(as.character(air_date)))
+```
+
+We will
+
+-   engineer features based on episode scripts
+-   train a model
+-   perform cross validation
+-   make predictions
+
+Note: The episodes listed in `theoffice` don't match the ones listed in the data we used in the [cross validation lesson](https://ids-s1-20.github.io/slides/week-10/w10-d02-cross-validation/w10-d02-cross-validation.html).
+
+```{r}
+theoffice %>%
+  distinct(season, episode)
+```
+
+### Exercise 1 - Calculate the percentage of lines spoken by Jim, Pam, Michael, and Dwight for each episode of The Office.
+
+```{r lines}
+
+```
+
+### Exercise 2 - Identify episodes that touch on Halloween, Valentine's Day, and Christmas.
+
+```{r special-episodes}
+
+```
+
+### Exercise 3 - Put together a modeling dataset that includes features you've engineered. Also add an indicator variable called `michael` which takes the value `1` if Michael Scott (Steve Carrell) was there, and `0` if not. Note: Michael Scott (Steve Carrell) left the show at the end of Season 7.
+
+```{r office-df}
+
+```
+
+### Exercise 4 - Split the data into training (75%) and testing (25%).
+
+```{r split}
+set.seed(1122)
+
+```
+
+### Exercise 5 - Specify a linear regression model.
+
+```{r model}
+
+```
+
+### Exercise 6 - Create a recipe that updates the role of `episode_name` to not be a predictor, removes `air_date` as a predictor, uses `season` as a factor, and removes all zero variance predictors.
+
+```{r recipe}
+
+```
+
+### Exercise 7 - Build a workflow for fitting the model specified earlier and using the recipe you developed to preprocess the data.
+
+```{r workflow}
+
+```
+
+### Exercise 8 - Fit the model to training data and interpret a couple of the slope coefficients.
+
+```{r fit}
+
+```
+
+### Exercise 9 - Perform 5-fold cross validation and view model performance metrics.
+
+```{r cv, message=FALSE, error = TRUE}
+set.seed(345)
+folds <- vfold_cv(___, v = ___)
+folds
+
+set.seed(456)
+office_fit_rs <- ___ %>%
+  ___(___)
+
+___(office_fit_rs)
+```
+
+### Exercise 10 - Use your model to make predictions for the testing data and calculate the RMSE. Also use the model developed in the [cross validation lesson](https://ids-s1-20.github.io/slides/week-10/w10-d02-cross-validation/w10-d02-cross-validation.html) to make predictions for the testing data and calculate the RMSE as well. Which model did a better job in predicting IMDB scores for the testing data?
+
+#### New model
+
+```{r new-model}
+
+```
+
+#### Old model
+
+```{r old-model, error = TRUE}
+office_mod_old <- linear_reg() %>%
+  set_engine(""lm"")
+
+office_rec_old <- recipe(imdb_rating ~ season + episode + total_votes + air_date, data = office_train) %>%
+  # extract month of air_date
+  step_date(air_date, features = ""month"") %>%
+  step_rm(air_date) %>%
+  # make dummy variables of month 
+  step_dummy(contains(""month"")) %>%
+  # remove zero variance predictors
+  step_zv(all_predictors())
+
+office_wflow_old <- workflow() %>%
+  add_model(office_mod_old) %>%
+  add_recipe(office_rec_old)
+
+office_fit_old <- office_wflow_old %>%
+  fit(data = office_train)
+
+tidy(office_fit_old)
+
+___
+```

---FILE: course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.md---
@@ -0,0 +1,146 @@
+The Office
+================
+Mine √áetinkaya-Rundel
+
+``` r
+library(tidyverse)
+library(tidymodels)
+library(schrute)
+library(lubridate)
+```
+
+Use `theoffice` data from the
+[**schrute**](https://bradlindblad.github.io/schrute/) package to
+predict IMDB scores for episodes of The Office.
+
+``` r
+glimpse(theoffice)
+```
+
+    ## Rows: 55,130
+    ## Columns: 12
+    ## $ index            <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1‚Ä¶
+    ## $ season           <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶
+    ## $ episode          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶
+    ## $ episode_name     <chr> ""Pilot"", ""Pilot"", ""Pilot"", ""Pilot"", ""Pilot"", ""Pilot""‚Ä¶
+    ## $ director         <chr> ""Ken Kwapis"", ""Ken Kwapis"", ""Ken Kwapis"", ""Ken Kwapi‚Ä¶
+    ## $ writer           <chr> ""Ricky Gervais;Stephen Merchant;Greg Daniels"", ""Rick‚Ä¶
+    ## $ character        <chr> ""Michael"", ""Jim"", ""Michael"", ""Jim"", ""Michael"", ""Mich‚Ä¶
+    ## $ text             <chr> ""All right Jim. Your quarterlies look very good. How‚Ä¶
+    ## $ text_w_direction <chr> ""All right Jim. Your quarterlies look very good. How‚Ä¶
+    ## $ imdb_rating      <dbl> 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.‚Ä¶
+    ## $ total_votes      <int> 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706‚Ä¶
+    ## $ air_date         <fct> 2005-03-24, 2005-03-24, 2005-03-24, 2005-03-24, 2005‚Ä¶
+
+Fix `air_date` for later use.
+
+``` r
+theoffice <- theoffice %>%
+  mutate(air_date = ymd(as.character(air_date)))
+```
+
+We will
+
+-   engineer features based on episode scripts
+-   train a model
+-   perform cross validation
+-   make predictions
+
+Note: The episodes listed in `theoffice` don‚Äôt match the ones listed in
+the data we used in the [cross validation
+lesson](https://ids-s1-20.github.io/slides/week-10/w10-d02-cross-validation/w10-d02-cross-validation.html).
+
+``` r
+theoffice %>%
+  distinct(season, episode)
+```
+
+    ## # A tibble: 186 x 2
+    ##    season episode
+    ##     <int>   <int>
+    ##  1      1       1
+    ##  2      1       2
+    ##  3      1       3
+    ##  4      1       4
+    ##  5      1       5
+    ##  6      1       6
+    ##  7      2       1
+    ##  8      2       2
+    ##  9      2       3
+    ## 10      2       4
+    ## # ‚Ä¶ with 176 more rows
+
+### Exercise 1 - Calculate the percentage of lines spoken by Jim, Pam, Michael, and Dwight for each episode of The Office.
+
+### Exercise 2 - Identify episodes that touch on Halloween, Valentine‚Äôs Day, and Christmas.
+
+### Exercise 3 - Put together a modeling dataset that includes features you‚Äôve engineered. Also add an indicator variable called `michael` which takes the value `1` if Michael Scott (Steve Carrell) was there, and `0` if not. Note: Michael Scott (Steve Carrell) left the show at the end of Season 7.
+
+### Exercise 4 - Split the data into training (75%) and testing (25%).
+
+``` r
+set.seed(1122)
+```
+
+### Exercise 5 - Specify a linear regression model.
+
+### Exercise 6 - Create a recipe that updates the role of `episode_name` to not be a predictor, removes `air_date` as a predictor, uses `season` as a factor, and removes all zero variance predictors.
+
+### Exercise 7 - Build a workflow for fitting the model specified earlier and using the recipe you developed to preprocess the data.
+
+### Exercise 8 - Fit the model to training data and interpret a couple of the slope coefficients.
+
+### Exercise 9 - Perform 5-fold cross validation and view model performance metrics.
+
+``` r
+set.seed(345)
+folds <- vfold_cv(___, v = ___)
+folds
+
+set.seed(456)
+office_fit_rs <- ___ %>%
+  ___(___)
+
+___(office_fit_rs)
+```
+
+    ## Error: <text>:2:19: unexpected input
+    ## 1: set.seed(345)
+    ## 2: folds <- vfold_cv(_
+    ##                      ^
+
+### Exercise 10 - Use your model to make predictions for the testing data and calculate the RMSE. Also use the model developed in the [cross validation lesson](https://ids-s1-20.github.io/slides/week-10/w10-d02-cross-validation/w10-d02-cross-validation.html) to make predictions for the testing data and calculate the RMSE as well. Which model did a better job in predicting IMDB scores for the testing data?
+
+#### New model
+
+#### Old model
+
+``` r
+office_mod_old <- linear_reg() %>%
+  set_engine(""lm"")
+
+office_rec_old <- recipe(imdb_rating ~ season + episode + total_votes + air_date, data = office_train) %>%
+  # extract month of air_date
+  step_date(air_date, features = ""month"") %>%
+  step_rm(air_date) %>%
+  # make dummy variables of month 
+  step_dummy(contains(""month"")) %>%
+  # remove zero variance predictors
+  step_zv(all_predictors())
+
+office_wflow_old <- workflow() %>%
+  add_model(office_mod_old) %>%
+  add_recipe(office_rec_old)
+
+office_fit_old <- office_wflow_old %>%
+  fit(data = office_train)
+
+tidy(office_fit_old)
+
+___
+```
+
+    ## Error: <text>:22:1: unexpected input
+    ## 21: 
+    ## 22: _
+    ##     ^

---FILE: course-materials/application-exercises/ae-09-uoeart-functions/01-individual-pieces.R---
@@ -1,44 +0,0 @@
-# load packages ----------------------------------------------------------------
-
-library(tidyverse)
-library(rvest)
-
-# first url --------------------------------------------------------------------
-
-## set url ----
-first_info_url <- ""https://collections.ed.ac.uk/art/record/22024?highlight=*:*""
-
-## read page at url ----
-page <- read_html(first_info_url)
-
-## scrape headers ----
-headers <- page %>%
-  html_nodes(""th"") %>%
-  html_text()
-
-## scrape values ----
-values <- page %>%
-  html_nodes(""td"") %>%
-  html_text() %>%
-  str_squish()
-
-## put together in a tibble and add link to help keep track ----
-tibble(headers, values) %>%
-  pivot_wider(names_from = headers, values_from = values) %>%
-  add_column(link = first_info_url)
-
-
-# second url --------------------------------------------------------------------
-
-## set url ----
-second_info_url <- ""___""
-
-___
-
-
-# third url --------------------------------------------------------------------
-
-## set url ----
-third_info_url <- ""___""
-
-___
\ No newline at end of file

---FILE: course-materials/application-exercises/ae-09-uoeart-functions/02-functionalize.R---
@@ -1,39 +0,0 @@
-# load packages ----------------------------------------------------------------
-
-library(tidyverse)
-library(rvest)
-
-# function: scrape_art_info() --------------------------------------------------
-
-scrape_art_info <- function(x){
-
-  # read page at url ----
-  page <- read_html(x)
-  
-  # scrape headers ----
-  headers <- page %>%
-    html_nodes(""th"") %>%
-    html_text()
-  
-  # scrape values ----
-  values <- page %>%
-    html_nodes(""td"") %>%
-    html_text() %>%
-    str_squish()
-  
-  # put together in a tibble and add link to help keep track ----
-  tibble(headers, values) %>%
-    pivot_wider(names_from = headers, values_from = values) %>%
-    add_column(link = x)
-  
-}
-
-# load data to get links -------------------------------------------------------
-
-uoe_art <- read_csv(""data/uoe_art.csv"")
-
-# apply function ---------------------------------------------------------------
-
-scrape_art_info(uoe_art$link[1])
-scrape_art_info(___)
-scrape_art_info(___)

---FILE: course-materials/application-exercises/ae-09-uoeart-functions/03-iterate.R---
@@ -1,11 +0,0 @@
-# load packages ----------------------------------------------------------------
-
-library(tidyverse)
-library(rvest)
-
-# iterate ----------------------------------------------------------------------
-
-# the following line is commented out as running it will take a while
-# get ready to be patient if you want to run it
-
-#map_dfr(uoe_art$link, scrape_art_info)

---FILE: course-materials/exams/exam-01/exam-01.html---
@@ -1,630 +0,0 @@
-<!DOCTYPE html>
-
-<html xmlns=""http://www.w3.org/1999/xhtml"">
-
-<head>
-
-<meta charset=""utf-8"">
-<meta http-equiv=""Content-Type"" content=""text/html; charset=utf-8"" />
-<meta name=""generator"" content=""pandoc"" />
-<meta name=""viewport"" content=""width=device-width, initial-scale=1"">
-
-<style type=""text/css"">
-@font-face {
-font-family: octicons-link;
-src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
-}
-body {
--webkit-text-size-adjust: 100%;
-text-size-adjust: 100%;
-color: #333;
-font-family: ""Helvetica Neue"", Helvetica, ""Segoe UI"", Arial, freesans, sans-serif, ""Apple Color Emoji"", ""Segoe UI Emoji"", ""Segoe UI Symbol"";
-font-size: 16px;
-line-height: 1.6;
-word-wrap: break-word;
-}
-a {
-background-color: transparent;
-}
-a:active,
-a:hover {
-outline: 0;
-}
-strong {
-font-weight: bold;
-}
-h1 {
-font-size: 2em;
-margin: 0.67em 0;
-}
-img {
-border: 0;
-}
-hr {
-box-sizing: content-box;
-height: 0;
-}
-pre {
-overflow: auto;
-}
-code,
-kbd,
-pre {
-font-family: monospace, monospace;
-font-size: 1em;
-}
-input {
-color: inherit;
-font: inherit;
-margin: 0;
-}
-html input[disabled] {
-cursor: default;
-}
-input {
-line-height: normal;
-}
-input[type=""checkbox""] {
-box-sizing: border-box;
-padding: 0;
-}
-table {
-border-collapse: collapse;
-border-spacing: 0;
-}
-td,
-th {
-padding: 0;
-}
-* {
-box-sizing: border-box;
-}
-input {
-font: 13px / 1.4 Helvetica, arial, nimbussansl, liberationsans, freesans, clean, sans-serif, ""Apple Color Emoji"", ""Segoe UI Emoji"", ""Segoe UI Symbol"";
-}
-a {
-color: #4078c0;
-text-decoration: none;
-}
-a:hover,
-a:active {
-text-decoration: underline;
-}
-hr {
-height: 0;
-margin: 15px 0;
-overflow: hidden;
-background: transparent;
-border: 0;
-border-bottom: 1px solid #ddd;
-}
-hr:before {
-display: table;
-content: """";
-}
-hr:after {
-display: table;
-clear: both;
-content: """";
-}
-h1,
-h2,
-h3,
-h4,
-h5,
-h6 {
-margin-top: 15px;
-margin-bottom: 15px;
-line-height: 1.1;
-}
-h1 {
-font-size: 30px;
-}
-h2 {
-font-size: 21px;
-}
-h3 {
-font-size: 16px;
-}
-h4 {
-font-size: 14px;
-}
-h5 {
-font-size: 12px;
-}
-h6 {
-font-size: 11px;
-}
-blockquote {
-margin: 0;
-}
-ul,
-ol {
-padding: 0;
-margin-top: 0;
-margin-bottom: 0;
-}
-ol ol,
-ul ol {
-list-style-type: lower-roman;
-}
-ul ul ol,
-ul ol ol,
-ol ul ol,
-ol ol ol {
-list-style-type: lower-alpha;
-}
-dd {
-margin-left: 0;
-}
-code {
-font-family: Consolas, ""Liberation Mono"", Menlo, Courier, monospace;
-font-size: 12px;
-}
-pre {
-margin-top: 0;
-margin-bottom: 0;
-font: 12px Consolas, ""Liberation Mono"", Menlo, Courier, monospace;
-}
-.select::-ms-expand {
-opacity: 0;
-}
-.octicon {
-font: normal normal normal 16px/1 octicons-link;
-display: inline-block;
-text-decoration: none;
-text-rendering: auto;
--webkit-font-smoothing: antialiased;
--moz-osx-font-smoothing: grayscale;
--webkit-user-select: none;
--moz-user-select: none;
--ms-user-select: none;
-user-select: none;
-}
-.octicon-link:before {
-content: '\f05c';
-}
-.markdown-body:before {
-display: table;
-content: """";
-}
-.markdown-body:after {
-display: table;
-clear: both;
-content: """";
-}
-.markdown-body>*:first-child {
-margin-top: 0 !important;
-}
-.markdown-body>*:last-child {
-margin-bottom: 0 !important;
-}
-a:not([href]) {
-color: inherit;
-text-decoration: none;
-}
-.anchor {
-display: inline-block;
-padding-right: 2px;
-margin-left: -18px;
-}
-.anchor:focus {
-outline: none;
-}
-h1,
-h2,
-h3,
-h4,
-h5,
-h6 {
-margin-top: 1em;
-margin-bottom: 16px;
-font-weight: bold;
-line-height: 1.4;
-}
-h1 .octicon-link,
-h2 .octicon-link,
-h3 .octicon-link,
-h4 .octicon-link,
-h5 .octicon-link,
-h6 .octicon-link {
-color: #000;
-vertical-align: middle;
-visibility: hidden;
-}
-h1:hover .anchor,
-h2:hover .anchor,
-h3:hover .anchor,
-h4:hover .anchor,
-h5:hover .anchor,
-h6:hover .anchor {
-text-decoration: none;
-}
-h1:hover .anchor .octicon-link,
-h2:hover .anchor .octicon-link,
-h3:hover .anchor .octicon-link,
-h4:hover .anchor .octicon-link,
-h5:hover .anchor .octicon-link,
-h6:hover .anchor .octicon-link {
-visibility: visible;
-}
-h1 {
-padding-bottom: 0.3em;
-font-size: 2.25em;
-line-height: 1.2;
-border-bottom: 1px solid #eee;
-}
-h1 .anchor {
-line-height: 1;
-}
-h2 {
-padding-bottom: 0.3em;
-font-size: 1.75em;
-line-height: 1.225;
-border-bottom: 1px solid #eee;
-}
-h2 .anchor {
-line-height: 1;
-}
-h3 {
-font-size: 1.5em;
-line-height: 1.43;
-}
-h3 .anchor {
-line-height: 1.2;
-}
-h4 {
-font-size: 1.25em;
-}
-h4 .anchor {
-line-height: 1.2;
-}
-h5 {
-font-size: 1em;
-}
-h5 .anchor {
-line-height: 1.1;
-}
-h6 {
-font-size: 1em;
-color: #777;
-}
-h6 .anchor {
-line-height: 1.1;
-}
-p,
-blockquote,
-ul,
-ol,
-dl,
-table,
-pre {
-margin-top: 0;
-margin-bottom: 16px;
-}
-hr {
-height: 4px;
-padding: 0;
-margin: 16px 0;
-background-color: #e7e7e7;
-border: 0 none;
-}
-ul,
-ol {
-padding-left: 2em;
-}
-ul ul,
-ul ol,
-ol ol,
-ol ul {
-margin-top: 0;
-margin-bottom: 0;
-}
-li>p {
-margin-top: 16px;
-}
-dl {
-padding: 0;
-}
-dl dt {
-padding: 0;
-margin-top: 16px;
-font-size: 1em;
-font-style: italic;
-font-weight: bold;
-}
-dl dd {
-padding: 0 16px;
-margin-bottom: 16px;
-}
-blockquote {
-padding: 0 15px;
-color: #777;
-border-left: 4px solid #ddd;
-}
-blockquote>:first-child {
-margin-top: 0;
-}
-blockquote>:last-child {
-margin-bottom: 0;
-}
-table {
-display: block;
-width: 100%;
-overflow: auto;
-word-break: normal;
-word-break: keep-all;
-}
-table th {
-font-weight: bold;
-}
-table th,
-table td {
-padding: 6px 13px;
-border: 1px solid #ddd;
-}
-table tr {
-background-color: #fff;
-border-top: 1px solid #ccc;
-}
-table tr:nth-child(2n) {
-background-color: #f8f8f8;
-}
-img {
-max-width: 100%;
-box-sizing: content-box;
-background-color: #fff;
-}
-code {
-padding: 0;
-padding-top: 0.2em;
-padding-bottom: 0.2em;
-margin: 0;
-font-size: 85%;
-background-color: rgba(0,0,0,0.04);
-border-radius: 3px;
-}
-code:before,
-code:after {
-letter-spacing: -0.2em;
-content: ""\00a0"";
-}
-pre>code {
-padding: 0;
-margin: 0;
-font-size: 100%;
-word-break: normal;
-white-space: pre;
-background: transparent;
-border: 0;
-}
-.highlight {
-margin-bottom: 16px;
-}
-.highlight pre,
-pre {
-padding: 16px;
-overflow: auto;
-font-size: 85%;
-line-height: 1.45;
-background-color: #f7f7f7;
-border-radius: 3px;
-}
-.highlight pre {
-margin-bottom: 0;
-word-break: normal;
-}
-pre {
-word-wrap: normal;
-}
-pre code {
-display: inline;
-max-width: initial;
-padding: 0;
-margin: 0;
-overflow: initial;
-line-height: inherit;
-word-wrap: normal;
-background-color: transparent;
-border: 0;
-}
-pre code:before,
-pre code:after {
-content: normal;
-}
-kbd {
-display: inline-block;
-padding: 3px 5px;
-font-size: 11px;
-line-height: 10px;
-color: #555;
-vertical-align: middle;
-background-color: #fcfcfc;
-border: solid 1px #ccc;
-border-bottom-color: #bbb;
-border-radius: 3px;
-box-shadow: inset 0 -1px 0 #bbb;
-}
-.pl-c {
-color: #969896;
-}
-.pl-c1,
-.pl-s .pl-v {
-color: #0086b3;
-}
-.pl-e,
-.pl-en {
-color: #795da3;
-}
-.pl-s .pl-s1,
-.pl-smi {
-color: #333;
-}
-.pl-ent {
-color: #63a35c;
-}
-.pl-k {
-color: #a71d5d;
-}
-.pl-pds,
-.pl-s,
-.pl-s .pl-pse .pl-s1,
-.pl-sr,
-.pl-sr .pl-cce,
-.pl-sr .pl-sra,
-.pl-sr .pl-sre {
-color: #183691;
-}
-.pl-v {
-color: #ed6a43;
-}
-.pl-id {
-color: #b52a1d;
-}
-.pl-ii {
-background-color: #b52a1d;
-color: #f8f8f8;
-}
-.pl-sr .pl-cce {
-color: #63a35c;
-font-weight: bold;
-}
-.pl-ml {
-color: #693a17;
-}
-.pl-mh,
-.pl-mh .pl-en,
-.pl-ms {
-color: #1d3e81;
-font-weight: bold;
-}
-.pl-mq {
-color: #008080;
-}
-.pl-mi {
-color: #333;
-font-style: italic;
-}
-.pl-mb {
-color: #333;
-font-weight: bold;
-}
-.pl-md {
-background-color: #ffecec;
-color: #bd2c00;
-}
-.pl-mi1 {
-background-color: #eaffea;
-color: #55a532;
-}
-.pl-mdr {
-color: #795da3;
-font-weight: bold;
-}
-.pl-mo {
-color: #1d3e81;
-}
-kbd {
-display: inline-block;
-padding: 3px 5px;
-font: 11px Consolas, ""Liberation Mono"", Menlo, Courier, monospace;
-line-height: 10px;
-color: #555;
-vertical-align: middle;
-background-color: #fcfcfc;
-border: solid 1px #ccc;
-border-bottom-color: #bbb;
-border-radius: 3px;
-box-shadow: inset 0 -1px 0 #bbb;
-}
-.task-list-item {
-list-style-type: none;
-}
-.task-list-item+.task-list-item {
-margin-top: 3px;
-}
-.task-list-item input {
-margin: 0 0.35em 0.25em -1.6em;
-vertical-align: middle;
-}
-:checked+.radio-label {
-z-index: 1;
-position: relative;
-border-color: #4078c0;
-}
-.sourceLine {
-display: inline-block;
-}
-code .kw { color: #000000; }
-code .dt { color: #ed6a43; }
-code .dv { color: #009999; }
-code .bn { color: #009999; }
-code .fl { color: #009999; }
-code .ch { color: #009999; }
-code .st { color: #183691; }
-code .co { color: #969896; }
-code .ot { color: #0086b3; }
-code .al { color: #a61717; }
-code .fu { color: #63a35c; }
-code .er { color: #a61717; background-color: #e3d2d2; }
-code .wa { color: #000000; }
-code .cn { color: #008080; }
-code .sc { color: #008080; }
-code .vs { color: #183691; }
-code .ss { color: #183691; }
-code .im { color: #000000; }
-code .va {color: #008080; }
-code .cf { color: #000000; }
-code .op { color: #000000; }
-code .bu { color: #000000; }
-code .ex { color: #000000; }
-code .pp { color: #999999; }
-code .at { color: #008080; }
-code .do { color: #969896; }
-code .an { color: #008080; }
-code .cv { color: #008080; }
-code .in { color: #008080; }
-</style>
-<style>
-body {
-  box-sizing: border-box;
-  min-width: 200px;
-  max-width: 980px;
-  margin: 0 auto;
-  padding: 45px;
-  padding-top: 0px;
-}
-</style>
-
-</head>
-
-<body>
-
-<h1 id=""sample-take-home-exam---student-template"">SAMPLE TAKE HOME EXAM - STUDENT TEMPLATE</h1>
-<p>[ENTER NAME HERE] Due: [DUE DATE HERE]</p>
-<h2 id=""academic-honesty-statement"">Academic Honesty Statement</h2>
-<p>I, ____________, hereby state that I have not communicated with or gained information in any way from my classmates or anyone other than the Professor or TA during this exam, and that all work is my own.</p>
-<h2 id=""load-packages"">Load packages</h2>
-<pre><code># load required packages here</code></pre>
-<h2 id=""questions"">Questions</h2>
-<h3 id=""question-1"">Question 1</h3>
-<p>[Enter code and narrative here.]</p>
-<h3 id=""question-2"">Question 2</h3>
-<p>[Enter code and narrative here.]</p>
-<h3 id=""question-3"">Question 3</h3>
-<p>[Enter code and narrative here.]</p>
-<h3 id=""question-4"">Question 4</h3>
-<p>[Enter code and narrative here.]</p>
-<h3 id=""question-5"">Question 5</h3>
-<p>[Enter code and narrative here.]</p>
-<h3 id=""question-6"">Question 6</h3>
-<p>[Enter code and narrative here.]</p>
-<h3 id=""question-7"">Question 7</h3>
-<p>[Enter code and narrative here.]</p>
-<h3 id=""question-8"">Question 8</h3>
-<p>[Enter code and narrative here.]</p>
-<h3 id=""extra-credit"">Extra Credit</h3>
-<p>[Enter code and narrative here.]</p>
-
-</body>
-</html>

---FILE: course-materials/exams/exam-01/exam-01.md---
@@ -3,20 +3,19 @@ SAMPLE TAKE HOME EXAM - STUDENT TEMPLATE
 \[ENTER NAME HERE\]
 Due: \[DUE DATE HERE\]
 
-Academic Honesty Statement
---------------------------
+## Academic Honesty Statement
 
 I, \_\_\_\_\_\_\_\_\_\_\_\_, hereby state that I have not communicated
 with or gained information in any way from my classmates or anyone other
 than the Professor or TA during this exam, and that all work is my own.
 
-Load packages
--------------
+## Load packages
 
-    # load required packages here
+``` r
+# load required packages here
+```
 
-Questions
----------
+## Questions
 
 ### Question 1
 

---FILE: course-materials/exams/exam-02/exam-02.html---
@@ -1,622 +0,0 @@
-<!DOCTYPE html>
-
-<html xmlns=""http://www.w3.org/1999/xhtml"">
-
-<head>
-
-<meta charset=""utf-8"">
-<meta http-equiv=""Content-Type"" content=""text/html; charset=utf-8"" />
-<meta name=""generator"" content=""pandoc"" />
-<meta name=""viewport"" content=""width=device-width, initial-scale=1"">
-
-<style type=""text/css"">
-@font-face {
-font-family: octicons-link;
-src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
-}
-body {
--webkit-text-size-adjust: 100%;
-text-size-adjust: 100%;
-color: #333;
-font-family: ""Helvetica Neue"", Helvetica, ""Segoe UI"", Arial, freesans, sans-serif, ""Apple Color Emoji"", ""Segoe UI Emoji"", ""Segoe UI Symbol"";
-font-size: 16px;
-line-height: 1.6;
-word-wrap: break-word;
-}
-a {
-background-color: transparent;
-}
-a:active,
-a:hover {
-outline: 0;
-}
-strong {
-font-weight: bold;
-}
-h1 {
-font-size: 2em;
-margin: 0.67em 0;
-}
-img {
-border: 0;
-}
-hr {
-box-sizing: content-box;
-height: 0;
-}
-pre {
-overflow: auto;
-}
-code,
-kbd,
-pre {
-font-family: monospace, monospace;
-font-size: 1em;
-}
-input {
-color: inherit;
-font: inherit;
-margin: 0;
-}
-html input[disabled] {
-cursor: default;
-}
-input {
-line-height: normal;
-}
-input[type=""checkbox""] {
-box-sizing: border-box;
-padding: 0;
-}
-table {
-border-collapse: collapse;
-border-spacing: 0;
-}
-td,
-th {
-padding: 0;
-}
-* {
-box-sizing: border-box;
-}
-input {
-font: 13px / 1.4 Helvetica, arial, nimbussansl, liberationsans, freesans, clean, sans-serif, ""Apple Color Emoji"", ""Segoe UI Emoji"", ""Segoe UI Symbol"";
-}
-a {
-color: #4078c0;
-text-decoration: none;
-}
-a:hover,
-a:active {
-text-decoration: underline;
-}
-hr {
-height: 0;
-margin: 15px 0;
-overflow: hidden;
-background: transparent;
-border: 0;
-border-bottom: 1px solid #ddd;
-}
-hr:before {
-display: table;
-content: """";
-}
-hr:after {
-display: table;
-clear: both;
-content: """";
-}
-h1,
-h2,
-h3,
-h4,
-h5,
-h6 {
-margin-top: 15px;
-margin-bottom: 15px;
-line-height: 1.1;
-}
-h1 {
-font-size: 30px;
-}
-h2 {
-font-size: 21px;
-}
-h3 {
-font-size: 16px;
-}
-h4 {
-font-size: 14px;
-}
-h5 {
-font-size: 12px;
-}
-h6 {
-font-size: 11px;
-}
-blockquote {
-margin: 0;
-}
-ul,
-ol {
-padding: 0;
-margin-top: 0;
-margin-bottom: 0;
-}
-ol ol,
-ul ol {
-list-style-type: lower-roman;
-}
-ul ul ol,
-ul ol ol,
-ol ul ol,
-ol ol ol {
-list-style-type: lower-alpha;
-}
-dd {
-margin-left: 0;
-}
-code {
-font-family: Consolas, ""Liberation Mono"", Menlo, Courier, monospace;
-font-size: 12px;
-}
-pre {
-margin-top: 0;
-margin-bottom: 0;
-font: 12px Consolas, ""Liberation Mono"", Menlo, Courier, monospace;
-}
-.select::-ms-expand {
-opacity: 0;
-}
-.octicon {
-font: normal normal normal 16px/1 octicons-link;
-display: inline-block;
-text-decoration: none;
-text-rendering: auto;
--webkit-font-smoothing: antialiased;
--moz-osx-font-smoothing: grayscale;
--webkit-user-select: none;
--moz-user-select: none;
--ms-user-select: none;
-user-select: none;
-}
-.octicon-link:before {
-content: '\f05c';
-}
-.markdown-body:before {
-display: table;
-content: """";
-}
-.markdown-body:after {
-display: table;
-clear: both;
-content: """";
-}
-.markdown-body>*:first-child {
-margin-top: 0 !important;
-}
-.markdown-body>*:last-child {
-margin-bottom: 0 !important;
-}
-a:not([href]) {
-color: inherit;
-text-decoration: none;
-}
-.anchor {
-display: inline-block;
-padding-right: 2px;
-margin-left: -18px;
-}
-.anchor:focus {
-outline: none;
-}
-h1,
-h2,
-h3,
-h4,
-h5,
-h6 {
-margin-top: 1em;
-margin-bottom: 16px;
-font-weight: bold;
-line-height: 1.4;
-}
-h1 .octicon-link,
-h2 .octicon-link,
-h3 .octicon-link,
-h4 .octicon-link,
-h5 .octicon-link,
-h6 .octicon-link {
-color: #000;
-vertical-align: middle;
-visibility: hidden;
-}
-h1:hover .anchor,
-h2:hover .anchor,
-h3:hover .anchor,
-h4:hover .anchor,
-h5:hover .anchor,
-h6:hover .anchor {
-text-decoration: none;
-}
-h1:hover .anchor .octicon-link,
-h2:hover .anchor .octicon-link,
-h3:hover .anchor .octicon-link,
-h4:hover .anchor .octicon-link,
-h5:hover .anchor .octicon-link,
-h6:hover .anchor .octicon-link {
-visibility: visible;
-}
-h1 {
-padding-bottom: 0.3em;
-font-size: 2.25em;
-line-height: 1.2;
-border-bottom: 1px solid #eee;
-}
-h1 .anchor {
-line-height: 1;
-}
-h2 {
-padding-bottom: 0.3em;
-font-size: 1.75em;
-line-height: 1.225;
-border-bottom: 1px solid #eee;
-}
-h2 .anchor {
-line-height: 1;
-}
-h3 {
-font-size: 1.5em;
-line-height: 1.43;
-}
-h3 .anchor {
-line-height: 1.2;
-}
-h4 {
-font-size: 1.25em;
-}
-h4 .anchor {
-line-height: 1.2;
-}
-h5 {
-font-size: 1em;
-}
-h5 .anchor {
-line-height: 1.1;
-}
-h6 {
-font-size: 1em;
-color: #777;
-}
-h6 .anchor {
-line-height: 1.1;
-}
-p,
-blockquote,
-ul,
-ol,
-dl,
-table,
-pre {
-margin-top: 0;
-margin-bottom: 16px;
-}
-hr {
-height: 4px;
-padding: 0;
-margin: 16px 0;
-background-color: #e7e7e7;
-border: 0 none;
-}
-ul,
-ol {
-padding-left: 2em;
-}
-ul ul,
-ul ol,
-ol ol,
-ol ul {
-margin-top: 0;
-margin-bottom: 0;
-}
-li>p {
-margin-top: 16px;
-}
-dl {
-padding: 0;
-}
-dl dt {
-padding: 0;
-margin-top: 16px;
-font-size: 1em;
-font-style: italic;
-font-weight: bold;
-}
-dl dd {
-padding: 0 16px;
-margin-bottom: 16px;
-}
-blockquote {
-padding: 0 15px;
-color: #777;
-border-left: 4px solid #ddd;
-}
-blockquote>:first-child {
-margin-top: 0;
-}
-blockquote>:last-child {
-margin-bottom: 0;
-}
-table {
-display: block;
-width: 100%;
-overflow: auto;
-word-break: normal;
-word-break: keep-all;
-}
-table th {
-font-weight: bold;
-}
-table th,
-table td {
-padding: 6px 13px;
-border: 1px solid #ddd;
-}
-table tr {
-background-color: #fff;
-border-top: 1px solid #ccc;
-}
-table tr:nth-child(2n) {
-background-color: #f8f8f8;
-}
-img {
-max-width: 100%;
-box-sizing: content-box;
-background-color: #fff;
-}
-code {
-padding: 0;
-padding-top: 0.2em;
-padding-bottom: 0.2em;
-margin: 0;
-font-size: 85%;
-background-color: rgba(0,0,0,0.04);
-border-radius: 3px;
-}
-code:before,
-code:after {
-letter-spacing: -0.2em;
-content: ""\00a0"";
-}
-pre>code {
-padding: 0;
-margin: 0;
-font-size: 100%;
-word-break: normal;
-white-space: pre;
-background: transparent;
-border: 0;
-}
-.highlight {
-margin-bottom: 16px;
-}
-.highlight pre,
-pre {
-padding: 16px;
-overflow: auto;
-font-size: 85%;
-line-height: 1.45;
-background-color: #f7f7f7;
-border-radius: 3px;
-}
-.highlight pre {
-margin-bottom: 0;
-word-break: normal;
-}
-pre {
-word-wrap: normal;
-}
-pre code {
-display: inline;
-max-width: initial;
-padding: 0;
-margin: 0;
-overflow: initial;
-line-height: inherit;
-word-wrap: normal;
-background-color: transparent;
-border: 0;
-}
-pre code:before,
-pre code:after {
-content: normal;
-}
-kbd {
-display: inline-block;
-padding: 3px 5px;
-font-size: 11px;
-line-height: 10px;
-color: #555;
-vertical-align: middle;
-background-color: #fcfcfc;
-border: solid 1px #ccc;
-border-bottom-color: #bbb;
-border-radius: 3px;
-box-shadow: inset 0 -1px 0 #bbb;
-}
-.pl-c {
-color: #969896;
-}
-.pl-c1,
-.pl-s .pl-v {
-color: #0086b3;
-}
-.pl-e,
-.pl-en {
-color: #795da3;
-}
-.pl-s .pl-s1,
-.pl-smi {
-color: #333;
-}
-.pl-ent {
-color: #63a35c;
-}
-.pl-k {
-color: #a71d5d;
-}
-.pl-pds,
-.pl-s,
-.pl-s .pl-pse .pl-s1,
-.pl-sr,
-.pl-sr .pl-cce,
-.pl-sr .pl-sra,
-.pl-sr .pl-sre {
-color: #183691;
-}
-.pl-v {
-color: #ed6a43;
-}
-.pl-id {
-color: #b52a1d;
-}
-.pl-ii {
-background-color: #b52a1d;
-color: #f8f8f8;
-}
-.pl-sr .pl-cce {
-color: #63a35c;
-font-weight: bold;
-}
-.pl-ml {
-color: #693a17;
-}
-.pl-mh,
-.pl-mh .pl-en,
-.pl-ms {
-color: #1d3e81;
-font-weight: bold;
-}
-.pl-mq {
-color: #008080;
-}
-.pl-mi {
-color: #333;
-font-style: italic;
-}
-.pl-mb {
-color: #333;
-font-weight: bold;
-}
-.pl-md {
-background-color: #ffecec;
-color: #bd2c00;
-}
-.pl-mi1 {
-background-color: #eaffea;
-color: #55a532;
-}
-.pl-mdr {
-color: #795da3;
-font-weight: bold;
-}
-.pl-mo {
-color: #1d3e81;
-}
-kbd {
-display: inline-block;
-padding: 3px 5px;
-font: 11px Consolas, ""Liberation Mono"", Menlo, Courier, monospace;
-line-height: 10px;
-color: #555;
-vertical-align: middle;
-background-color: #fcfcfc;
-border: solid 1px #ccc;
-border-bottom-color: #bbb;
-border-radius: 3px;
-box-shadow: inset 0 -1px 0 #bbb;
-}
-.task-list-item {
-list-style-type: none;
-}
-.task-list-item+.task-list-item {
-margin-top: 3px;
-}
-.task-list-item input {
-margin: 0 0.35em 0.25em -1.6em;
-vertical-align: middle;
-}
-:checked+.radio-label {
-z-index: 1;
-position: relative;
-border-color: #4078c0;
-}
-.sourceLine {
-display: inline-block;
-}
-code .kw { color: #000000; }
-code .dt { color: #ed6a43; }
-code .dv { color: #009999; }
-code .bn { color: #009999; }
-code .fl { color: #009999; }
-code .ch { color: #009999; }
-code .st { color: #183691; }
-code .co { color: #969896; }
-code .ot { color: #0086b3; }
-code .al { color: #a61717; }
-code .fu { color: #63a35c; }
-code .er { color: #a61717; background-color: #e3d2d2; }
-code .wa { color: #000000; }
-code .cn { color: #008080; }
-code .sc { color: #008080; }
-code .vs { color: #183691; }
-code .ss { color: #183691; }
-code .im { color: #000000; }
-code .va {color: #008080; }
-code .cf { color: #000000; }
-code .op { color: #000000; }
-code .bu { color: #000000; }
-code .ex { color: #000000; }
-code .pp { color: #999999; }
-code .at { color: #008080; }
-code .do { color: #969896; }
-code .an { color: #008080; }
-code .cv { color: #008080; }
-code .in { color: #008080; }
-</style>
-<style>
-body {
-  box-sizing: border-box;
-  min-width: 200px;
-  max-width: 980px;
-  margin: 0 auto;
-  padding: 45px;
-  padding-top: 0px;
-}
-</style>
-
-</head>
-
-<body>
-
-<h1 id=""sample-take-home-exam---student-template"">SAMPLE TAKE HOME EXAM - STUDENT TEMPLATE</h1>
-<p>[ENTER NAME HERE] Due: [DUE DATE HERE]</p>
-<h2 id=""academic-honesty-statement"">Academic Honesty Statement</h2>
-<p>I, ____________, hereby state that I have not communicated with or gained information in any way from my classmates or anyone other than the Professor or TA during this exam, and that all work is my own.</p>
-<h2 id=""load-packages"">Load packages</h2>
-<pre><code># load required packages here</code></pre>
-<h2 id=""questions"">Questions</h2>
-<h3 id=""question-1"">Question 1</h3>
-<p>[Enter code and/or narrative here.]</p>
-<h3 id=""question-2"">Question 2</h3>
-<p>[Enter code and/or narrative here.]</p>
-<h3 id=""question-3"">Question 3</h3>
-<p>[Enter code and/or narrative here.]</p>
-<p>‚Ä¶</p>
-<p>[Add headers for subsequent questions as needed.]</p>
-<h3 id=""extra-credit"">Extra Credit</h3>
-<p>[Enter code and narrative here.]</p>
-
-</body>
-</html>

---FILE: course-materials/exams/exam-02/exam-02.md---
@@ -3,20 +3,19 @@ SAMPLE TAKE HOME EXAM - STUDENT TEMPLATE
 \[ENTER NAME HERE\]
 Due: \[DUE DATE HERE\]
 
-Academic Honesty Statement
---------------------------
+## Academic Honesty Statement
 
 I, \_\_\_\_\_\_\_\_\_\_\_\_, hereby state that I have not communicated
 with or gained information in any way from my classmates or anyone other
 than the Professor or TA during this exam, and that all work is my own.
 
-Load packages
--------------
+## Load packages
 
-    # load required packages here
+``` r
+# load required packages here
+```
 
-Questions
----------
+## Questions
 
 ### Question 1
 

---FILE: course-materials/hw-instructions/hw-01/hw-01-airbnb-edi.Rmd---
@@ -1,98 +0,0 @@
----
-title: ""HW 01 - Airbnb listings in Edinburgh""
-output: 
-  tufte::tufte_html:
-    css: ../hw.css
-    tufte_variant: ""envisioned""
-    highlight: pygments
-link-citations: yes
----
-
-```{r grassmarket, fig.margin = TRUE, echo = FALSE, fig.width=3, fig.cap=""Photo by Madeleine Kohler on Unsplash""}
-knitr::include_graphics(""img/madeleine-kohler-90Qn643Pq9c-unsplash.jpg"")
-```
-
-Recent development in Edinburgh regarding the growth of Airbnb and its impact on the housing market means a better understanding of the Airbnb listings is needed.
-Using data provided by Airbnb, we can explore how Airbnb availability and prices vary by neighbourhood.
-
-The data come from the [Kaggle database](https://www.kaggle.com/thoroc/edinburgh-inside-airbnb/version/2).
-It's been modified to better serve the goals of this exploration.
-
-## Learning goals
-
-The goal of this assignment is not to conduct a thorough analysis of Airbnb listings in Edinburgh, but instead to give you another chance to practice your workflow, data visualization, and interpretation skills.
-
-## Getting help
-
-If you have any questions about the assignment, please post them on Piazza!
-
-## Getting started
-
-```{marginfigure}
-**IMPORTANT:** If there is no GitHub repo created for you for this assignment, it means I didn't have your GitHub username as of when I assigned the homework. Please let me know your GitHub username asap, and I can create your repo.
-```
-
-Go to the course GitHub organization and locate your HW 1 repo, which should be named `hw-01-airbnb-edi-YOUR_GITHUB_USERNAME`.
-Grab the URL of the repo, and clone it in RStudio.
-Refer to Lab 01 if you would like to see step-by-step instructions for cloning a repo into an RStudio project.
-
-First, open the R Markdown document `hw-01-airbnb-edi.Rmd` and Knit it.
-Make sure it compiles without errors.
-The output will be in the file markdown `.md` file with the same name.
-
-## Packages
-
-We'll use the **tidyverse** package for this analysis, and the data is in the **dsbox** package.
-Run the following code in the Console to load these packages.
-
-```{r load-packages, message=FALSE}
-library(tidyverse)
-library(dsbox)
-```
-
-## Data
-
-1.  The dataset you'll be using is called `edibnb`. Run `View(edibnb)` in your Console to view the data in the data viewer. What does each row in the dataset represent?
-
-```{marginfigure}
-**Hint:** The Markdown Quick Reference sheet has an example of inline R code that might be helpful. You can access it from the Help menu in RStudio.
-```
-
-2.  How many observations (rows) does the dataset have? Instead of hard coding the number in your answer, use inline code.
-
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *Now is a good time to commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
-
-Each column represents a variable.
-We can get a list of the variables in the data frame using the `names()` function.
-
-```{r}
-names(edibnb)
-```
-
-You can find descriptions of each of the variables in the help file for the dataset, which you can access by running `?edibnb` in your Console.
-
-```{marginfigure}
-**Note:** The plot will give a warning about some observations with non-finite values for price being removed. Don't worry about the warning, it simply means that 199 listings in the data didn't have prices available, so they can't be plotted.
-```
-
-3.  Create a faceted histogram where each facet represents a neighborhood and displays the distribution of Airbnb prices in that neighborhood. Sample code is provided below, but you will need to fill in the blanks.
-
-```{r eval=FALSE}
-ggplot(data = ___, mapping = aes(x = ___)) +
-  geom_histogram(binwidth = ___) +
-  facet_wrap(~___)
-```
-
-Let's deconstruct this code:
-
--   `ggplot()` is the function we are using to build our plot, in layers.
--   In the first layer we always define the data frame as the first argument. Then, we define the mappings between the variables in the dataset and the **aes**thetics of the plot (e.g. x and y coordinates, colors, etc.).
--   In the next layer we represent the data with **geom**etric shapes, in this case with a histogram. You should decide what makes a reasonable bin width for the histogram by trying out a few options.
--   In the final layer we facet the data by neighbourhood.
-
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *Commit and push your changes again.*
-
-4 Create a similar visualization, this time showing the distribution of review scores (`review_scores_rating`) across neighborhoods.
-In your answer, include a brief interpretation of how Airbnb guests rate properties in general and how the neighborhoods compare to each other in terms of their ratings.
-
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *Commit and push your changes again.*

---FILE: course-materials/hw-instructions/hw-01/hw-01-pet-names.Rmd---
@@ -0,0 +1,352 @@
+---
+title: ""HW 01 - Pet names""
+subtitle: ""Mett the toolkit""
+output: 
+  tufte::tufte_html:
+    css: ../hw.css
+    tufte_variant: ""envisioned""
+    highlight: pygments
+link-citations: yes
+---
+
+```{r include = FALSE}
+knitr::opts_chunk$set(
+  eval = FALSE,
+  out.width = ""80%"",
+  fig.asp = 0.618,
+  fig.width = 10
+)
+library(tidyverse)
+library(openintro)
+library(ggrepel)
+```
+
+```{r photo, fig.margin = TRUE, echo = FALSE, fig.width = 3, fig.cap = ""Photo by Jovana Askrabic on Unsplash"", eval = TRUE}
+knitr::include_graphics(""img/jovana-askrabic-XYIQXLH_v0o-unsplash.jpg"")
+```
+
+The goal of this assignment is to introduce you to R, RStudio, Git, and GitHub, which you'll be using throughout the course both to learn the data science concepts discussed in the course and to analyze real data and come to informed conclusions.
+
+# Getting started
+
+## Prerequisites {data-link=""Prerequisites""}
+
+This assignment assumes that you have reviewed the lectures titled ""Meet the toolkit: Programming"" and ""Meet the toolkit: version control and collaboration"".
+If you haven't yet done so, please pause and complete the following before continuing.
+
+## Terminology
+
+We've already thrown around a few new terms, so let's define them before we proceed.
+
+-   **R:** Name of the programming language we will be using throughout the course.
+
+-   **RStudio:** An integrated development environment for R.
+    In other words, a convenient interface for writing and running R code.
+
+-   **Git:** A version control system.
+
+-   **GitHub:** A web platform for hosting version controlled files and facilitating collaboration among users.
+
+-   **Repository:** A Git repository contains all of your project's files and stores each file's revision history.
+    It's common to refer to a repository as a repo.
+
+    -   In this course, each assignment you work on will be contained in a Git repo.
+    -   For individual assignments, only you will have access to the repo. For team assignments, all team members will have access to a single repo where they work collaboratively.
+    -   All repos associated with this course are housed in the course GitHub organization. The organization is set up such that students can only see repos they have access to, but the course staff can see all of them.
+
+## Starting slow
+
+As the course progresses, you are encouraged to explore beyond what the assignments dictate; a willingness to experiment will make you a much better programmer!
+Before we get to that stage, however, you need to build some basic fluency in R.
+First, we will explore the fundamental building blocks of all of these tools.
+
+Before you can get started with the analysis, you need to make sure you:
+
+-   have a GitHub account
+
+-   are a member of the course GitHub organization
+
+-   are a member of the course RStudio Cloud space
+
+If you failed to confirm any of these, it means you have not yet completed the prerequisites for this assignment.
+Please go back to [Prerequisites] and complete them before continuing the assignment.
+
+# Workflow
+
+```{marginfigure}
+**IMPORTANT:** If there is no GitHub repo created for you for this assignment, it means I didn't have your GitHub username as of when I assigned the homework. Please let me know your GitHub username asap, and I can create your repo.
+```
+
+For each assignment in this course you will start with a GitHub repo that I created for you and that contains the starter documents you will build upon when working on your assignment.
+The first step is always to bring these files into RStudio so that you can edit them, run them, view your results, and interpret them.
+This action is called **cloning**.
+
+Then you will work in RStudio on the data analysis, making **commits** along the way (snapshots of your changes) and finally **push** all your work back to GitHub.
+
+The next few steps will walk you through the process of getting information of the repo to be cloned, cloning your repo in a new RStudio Cloud project, and getting started with the analysis.
+
+### Step 1. Get URL of repo to be cloned
+
+```{r clone-repo-link, fig.margin = TRUE, echo = FALSE, eval = TRUE}
+knitr::include_graphics(""img/clone-repo-link.png"")
+```
+
+On GitHub, click on the green **Code** button, select **HTTPS** (this might already be selected by default, and if it is, you'll see the text *Use Git or checkout with SVN using the web URL* jas in the image on the right).
+Click on the clipboard icon üìã to copy the repo URL.
+
+### Step 2. Go to RStudio Cloud
+
+Go to [rstudio.cloud](https://rstudio.cloud/ ""RStudio Cloud"") and then **navigate to the course workspace** via the left sidebar.
+It's very important that you do this for two reasons:
+
+-   It's only when you're in the course workspace that you'll be able to benefit from R packages I've pre-installed for you so that your project can be configured correctly.
+-   It's only when you're in the course workspace that your usage of RStudio Cloud won't count towards the free usage limits.
+
+```{r course-workspace, fig.margin = TRUE, echo = FALSE, eval = TRUE}
+knitr::include_graphics(""img/course-workspace.png"")
+```
+
+Before you proceed, confirm that you are in the course workspace by checking out what's on your top bar in RStudio Cloud.
+
+### Step 3. Clone the repo
+
+In RStudio, click on the **down arrow** next to New Project and then choose **New Project from Git Repository**.
+
+In the pop-up window, **paste the URL** you copied from GitHub, make sure the box for **Add packages from the base project** is checked (it should be, by default) and then click **OK**.
+
+```{r new-project-from-git, echo = FALSE, eval = TRUE, fig.align = ""left""}
+knitr::include_graphics(""img/new-project-from-git.png"")
+```
+
+# Hello RStudio!
+
+RStudio is comprised of four panes.
+
+```{r rstudio-anatomy, fig.fullwidth=TRUE, echo = FALSE, eval = TRUE}
+knitr::include_graphics(""img/rstudio-anatomy.png"")
+```
+
+-   On the bottom left is the Console, this is where you can write code that will be evaluated. Try typing `2 + 2` here and hit enter, what do you get?
+-   On the bottom right is the Files pane, as well as other panes that will come handy as we start our analysis.
+-   If you click on a file, it will open in the editor, on the top left pane.
+-   Finally, the top right pane shows your Environment. If you define a variable it would show up there. Try typing `x <- 2` in the Console and hit enter, what do you get in the **Environment** pane? Importantly, this pane is also where the **Git** interface lives. We will be using that regularly throughout this assignment.
+
+# Warm up
+
+Before we introduce the data, let's warm up with some simple exercises.
+
+```{marginfigure}
+The top portion of your R Markdown file (between the three dashed lines) is called **YAML**. It stands for ""YAML Ain't Markup Language"". It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.
+```
+
+## Step 1. Update the YAML
+
+Open the R Markdown (Rmd) file in your project, change the author name to your name, and knit the document.
+
+```{r yaml-raw-to-rendered, echo = FALSE, eval = TRUE, fig.align = ""center""}
+knitr::include_graphics(""img/yaml-raw-to-rendered.png"")
+```
+
+## Step 2: Commit
+
+Then Go to the **Git pane** in your RStudio.
+
+You should see that your Rmd (R Markdown) file and its output, your md file (Markdown), file are listed there as recently changed files.
+
+Next, click on **Diff**.
+This will pop open a new window that shows you the **diff**erence between the last committed state of the document and its current state that includes your changes.
+If you're happy with these changes, click on the checkboxes of all files in the list, and type *""Update author name""* in the **Commit message** box and hit **Commit**.
+
+```{r update-author-name-commit, echo = FALSE, eval = TRUE, fig.align = ""left""}
+knitr::include_graphics(""img/update-author-name-commit.png"")
+```
+
+You don't have to commit after every change, this would get quite cumbersome.
+You should consider committing states that are *meaningful to you* for inspection, comparison, or restoration.
+In the first few assignments we will tell you exactly when to commit and in some cases, what commit message to use.
+As the semester progresses we will let you make these decisions.
+
+## Step 3. Push
+
+Now that you have made an update and committed this change, it's time to push these changes to the web!
+Or more specifically, to your repo on GitHub.
+Why?
+So that others can see your changes.
+And by others, we mean the course teaching team (your repos in this course are private to you and us, only).
+In order to push your changes to GitHub, click on **Push**.
+
+```{r ready-to-push, fig.margin = TRUE, echo = FALSE, eval = TRUE}
+knitr::include_graphics(""img/ready-to-push.png"")
+```
+
+This will prompt a dialogue box where you first need to enter your user name, and then your password.
+This might feel cumbersome.
+Bear with me... I *will* teach you how to save your password so you don't have to enter it every time.
+But for this one assignment you'll have to manually enter each time you push in order to gain some experience with it.
+
+**Thought exercise:** Which of the above steps (updating the YAML, committing, and pushing) needs to talk to GitHub?[^hw-01-pet-names-1]
+
+# Packages
+
+R is an open-source language, and developers contribute functionality to R via packages.
+In this assignment we will use the following packages:
+
+-   **tidyverse**: a collection of packages for doing data analysis in a ""tidy"" way
+-   **openintro**: a package that contains the datasets from OpenIntro resources
+
+We use the `library()` function to load packages.
+In your R Markdown document you should see an R chunk labelled `load-packages` which has the necessary code for loading both packages.
+You should also load these packages in your Console, which you can do by sending the code to your Console by clicking on the **Run Current Chunk** icon (green arrow pointing right icon).
+
+```{r load-packages-chunk, echo = FALSE, eval = TRUE, fig.align = ""left""}
+knitr::include_graphics(""img/load-packages-chunk.png"")
+```
+
+Note that these packages are also get loaded in your R Markdown environment when you **Knit** your R Markdown document.
+
+# Data
+
+The city of [Seattle, WA](https://en.wikipedia.org/wiki/Seattle) has an open data portal that includes pets registered in the city.
+For each registered pet, we have information on the pet's name and species.
+The data used in this exercise can be found in the **openintro** package, and it's called `seattlepets`.
+Since the dataset is distributed with the package, we don't need to load it separately; it becomes available to us when we load the package.
+
+You can view the dataset as a spreadsheet using the `View()` function.
+Note that you should not put this function in your R Markdown document, but instead type it directly in the Console, as it pops open a new window (and the concept of popping open a window in a static document doesn't really make sense...).
+When you run this in the console, you'll see the following **data viewer** window pop up.
+
+```{r view-data}
+View(seattlepets)
+```
+
+```{r data.viewer, echo = FALSE, eval = TRUE, fig.align = ""left""}
+knitr::include_graphics(""img/view-data.png"")
+```
+
+You can find out more about the dataset by inspecting its documentation (which contains a **data dictionary**, name of each variable and its description), which you can access by running `?seattlepets` in the Console or using the Help menu in RStudio to search for `seattlepets`.
+
+# Exercises
+
+1.  According to the data dictionary, how many pets are included in this dataset?
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è *Write your answer in your R Markdown document under Exercise 1, knit the document, commit your changes with a commit message that says ""Completed Exercise 1"", and push. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+2.  Again, according to the data dictionary, how many variables do we have for each pet?
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è *Write your answer in your R Markdown document under Exercise 1, knit the document, commit your changes with a commit message that says ""Completed Exercise 2"", and push. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+3.  What are the three most common pet names in Seattle? To do this you will need to count the frequencies of each pet name and display the results in descending order of frequency so that you can easily see the top three most popular names. The following code does exactly that.
+
+```{marginfigure}
+The two lines of code can be read as ""Start with the seattlepets data frame, and then count the animal_names, and display the results sorted in descending order. The ""and then"" in the previous sentence maps to %>%, the pipe operator, which takes what comes before it and plugs it in as the first argument of the function that comes after it.
+```
+
+```{r}
+seattlepets %>%
+  count(animal_name, sort = TRUE)
+```
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è *Write your answer in your R Markdown document under Exercise 3. In this exercise you will not only provide a written answer but also include some code and output. You should insert the code in the code chunk provided for you, knit the document to see the output, and then write your narrative for the answer based on the output of this function, and knit again to see your narrative, code, and output in the resulting document. Then, commit your changes with a commit message that says ""Completed Exercise 3"", and push. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+Let's also look to see what the most common pet names are for various species.
+For this we need to first `group_by()` the `species`, and then do the same counting we did before.
+
+```{marginfigure}
+Looks like many of those NAs were cats. Poor unnamed kitties‚Ä¶
+```
+
+```{r species-names, eval=TRUE}
+seattlepets %>% 
+  group_by(species) %>%
+  count(animal_name, sort = TRUE)
+```
+
+But this output isn't exactly what we wanted.
+We wanted to know the most common cat and dog names, but there are barely any cats present in this output!
+This is because there are more dogs than cats in the dataset overall.
+We can confirm this by counting the various species in the data.
+
+```{marginfigure}
+6 pigs in the city? Ok‚Ä¶ But we'll continue with cats and dogs.
+```
+
+```{r species, eval=TRUE}
+seattlepets %>%
+  count(species, sort = TRUE)
+```
+
+Let's search for the top 5 cat and dog names.
+To do this, we can use the `slice_max()` function.
+The first argument in the function is the variable we want to select the highest values of, which is `n`.
+The second argument is the number of rows to select, which is `n = 5` for the top 5.
+It may be a bit confusing that both of these are `n`, but this is because we already have a variable called `n` in the data frame.
+
+```{r species-names-top5, eval=TRUE}
+seattlepets %>% 
+  group_by(species) %>%
+  count(animal_name, sort = TRUE) %>% 
+  slice_max(n, n = 5)
+```
+
+1.  Based on the previous output we can easily identify the most common cat and dog names in Seattle, but the output is sorted by `n` (the frequencies) as opposed to being organized by the `species`. Build on the pipeline to arrange the results so that they're arranged by `species` first, and then `n`. This means you will need to add one more step to the pipeline, and you have two options: `arrange(species, n)` or `arrange(n, species)`. You should try both and decide which one organizes the output by species and then ranks the names in order of frequency for each species.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è *Write your answer in your R Markdown document under Exercise 4. In this exercise you're asked to complete the code provided for you. You should insert the code in the code chunk provided for you, knit the document to see the output, and then write your narrative for the answer based on the output of this function, and knit again to see your narrative, code, and output in the resulting document. Then, commit your changes with a commit message that says ""Completed Exercise 4"", and push. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+The following visualization plots the proportion of dogs with a given name versus the proportion of cats with the same name.
+The 20 most common cat and dog names are displayed.
+The diagonal line on the plot is the $x = y$ line; if a name appeared on this line, the name's popularity would be exactly the same for dogs and cats.
+
+```{r eval = TRUE, echo = FALSE, fig.fullwidth = TRUE}
+# data prep
+name_props <- seattlepets %>% 
+  filter(
+    !is.na(animal_name),
+    species %in% c(""Dog"", ""Cat"")
+    ) %>%
+  group_by(species) %>% 
+  count(animal_name, sort = TRUE) %>%
+  mutate(prop = n / sum(n))
+    
+cat_name_props <- name_props %>%
+  filter(species == ""Cat"") %>%
+  rename(cat_prop = prop) %>%
+  slice(1:30)
+
+dog_name_props <- name_props %>%
+  filter(species == ""Dog"") %>%
+  rename(dog_prop = prop) %>%
+  slice(1:30)
+    
+comb_name_props <- inner_join(cat_name_props, dog_name_props, 
+                              by = ""animal_name"") %>%
+  ungroup() %>%
+  select(animal_name, cat_prop, dog_prop)
+    
+# create viz
+ggplot(comb_name_props, aes(x = cat_prop, y = dog_prop)) +
+  geom_abline(intercept = 0, 
+              color = COL[""lgray"",""full""], 
+              alpha = 0.8, 
+              size = 1.5) +
+  geom_text_repel(aes(label = animal_name), 
+                  segment.color = COL[""gray"",""full""], 
+                  seed = 291252, max.iter = 10000) +
+  geom_point(color = COL[""blue"",""full""], alpha = 0.8) +
+  theme_minimal() +
+  labs(x = ""Proportion of cats"", y = ""Proportion of dogs"") +
+  xlim(0.002, 0.01) +
+  ylim(0.002, 0.01) +
+  ggimage::geom_emoji(
+      image = ""1f436"", aes(x = 0.003, y = 0.009), size = 0.1
+      ) +
+  ggimage::geom_emoji(
+      image = ""1f431"", aes(x = 0.009, y = 0.003), size = 0.1
+      )
+```
+
+1.  What names are more common for cats than dogs? The ones above the line or the ones below the line?
+2.  Is the relationship between the two variables (proportion of cats with a given name and proportion of dogs with a given name) positive or negative? What does this mean in context of the data?
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è *Now is a good time to commit and push your changes to GitHub with an appropriate commit message. Commit and push all changed files so that your Git pane is cleared up afterwards. Make sure that your last push to the repo comes before the deadline. You should confirm that what you committed and pushed are indeed in your repo that we will see by visiting your repo on GitHub.*
+
+[^hw-01-pet-names-1]: Only pushing requires talking to GitHub, this is why you're asked for your password at that point.

---FILE: course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.Rmd---
@@ -0,0 +1,120 @@
+---
+title: ""HW 02 - Airbnb listings in Edinburgh""
+output: 
+  tufte::tufte_html:
+    css: ../hw.css
+    tufte_variant: ""envisioned""
+    highlight: pygments
+link-citations: yes
+---
+
+```{r include = FALSE}
+knitr::opts_chunk$set(
+  eval = FALSE,
+  out.width = ""80%"",
+  fig.asp = 0.618,
+  fig.width = 6
+)
+```
+
+```{r photo, fig.margin = TRUE, echo = FALSE, fig.width = 3, fig.cap = ""Photo by Madeleine Kohler on Unsplash"", eval = TRUE}
+knitr::include_graphics(""img/madeleine-kohler-90Qn643Pq9c-unsplash.jpg"")
+```
+
+Once upon a time, people travelled all over the world, and some stayed in hotels and others chose to stay in other people's houses that they booked through Airbnb.
+Recent developments in Edinburgh regarding the growth of Airbnb and its impact on the housing market means a better understanding of the Airbnb listings is needed.
+Using data provided by Airbnb, we can explore how Airbnb availability and prices vary by neighbourhood.
+
+# Getting started
+
+```{marginfigure}
+**IMPORTANT:** If there is no GitHub repo created for you for this assignment, it means I didn't have your GitHub username as of when I assigned the homework. Please let me know your GitHub username asap, and I can create your repo.
+```
+
+Go to the course GitHub organization and locate your homework repo, which should be named `hw-02-airbnb-edi-YOUR_GITHUB_USERNAME`.
+Grab the URL of the repo, and clone it in RStudio.
+First, open the R Markdown document `hw-02.Rmd` and Knit it.
+Make sure it compiles without errors.
+The output will be in the file markdown `.md` file with the same name.
+
+## Warm up
+
+Before we introduce the data, let's warm up with some simple exercises.
+
+-   Update the YAML, changing the author name to your name, and **knit** the document.
+-   Commit your changes with a meaningful commit message.
+-   Push your changes to GitHub.
+-   Go to your repo on GitHub and confirm that your changes are visible in your Rmd **and** md files. If anything is missing, commit and push again.
+
+## Packages
+
+We'll use the **tidyverse** package for much of the data wrangling and visualisation and the data lives in the **dsbox** package.
+These packages are already installed for you.
+You can load them by running the following in your Console:
+
+```{r load-packages, message = FALSE}
+library(tidyverse)
+library(dsbox)
+```
+
+## Data
+
+The data can be found in the **dsbox** package, and it's called `edibnb`.
+Since the dataset is distributed with the package, we don't need to load it separately; it becomes available to us when we load the package.
+
+You can view the dataset as a spreadsheet using the `View()` function.
+Note that you should not put this function in your R Markdown document, but instead type it directly in the Console, as it pops open a new window (and the concept of popping open a window in a static document doesn't really make sense...).
+When you run this in the console, you'll see the following **data viewer** window pop up.
+
+```{r view-data}
+View(edibnb)
+```
+
+You can find out more about the dataset by inspecting its documentation, which you can access by running `?edibnb` in the Console or using the Help menu in RStudio to search for `edibnb`.
+You can also find this information [here](https://rstudio-education.github.io/dsbox/reference/edibnb.html).
+
+# Exercises
+
+```{marginfigure}
+**Hint:** The Markdown Quick Reference sheet has an example of inline R code that might be helpful. You can access it from the Help menu in RStudio.
+```
+
+1.  How many observations (rows) does the dataset have? Instead of hard coding the number in your answer, use inline code.
+2.  Run `View(edibnb)` in your Console to view the data in the data viewer. What does each row in the dataset represent?
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è *Knit,* *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+Each column represents a variable.
+We can get a list of the variables in the data frame using the `names()` function.
+
+```{r}
+names(edibnb)
+```
+
+You can find descriptions of each of the variables in the help file for the dataset, which you can access by running `?edibnb` in your Console.
+
+```{marginfigure}
+**Note:** The plot will give a warning about some observations with non-finite values for price being removed. Don't worry about the warning, it simply means that 199 listings in the data didn't have prices available, so they can't be plotted.
+```
+
+3.  Create a faceted histogram where each facet represents a neighbourhood and displays the distribution of Airbnb prices in that neighbourhood. Think critically about whether it makes more sense to stack the facets on top of each other in a column, lay them out in a row, or wrap them around. Along with your visualisation, include your reasoning for the layout you chose for your facets.
+
+```{r}
+ggplot(data = ___, mapping = aes(x = ___)) +
+  geom_histogram(binwidth = ___) +
+  facet_wrap(~___)
+```
+
+Let's de-construct this code:
+
+-   `ggplot()` is the function we are using to build our plot, in layers.
+-   In the first layer we always define the data frame as the first argument. Then, we define the mappings between the variables in the dataset and the **aes**thetics of the plot (e.g. x and y coordinates, colours, etc.).
+-   In the next layer we represent the data with **geom**etric shapes, in this case with a histogram. You should decide what makes a reasonable bin width for the histogram by trying out a few options.
+-   In the final layer we facet the data by neighbourhood.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+4.  Use a single pipeline to identity the neighbourhoods with the top five median listing prices. Then, in another pipeline filter the data for these five neighbourhoods and make ridge plots of the distributions of listing prices in these five neighbourhoods. In a third pipeline calculate the minimum, mean, median, standard deviation, IQR, and maximum listing price in each of these neighbourhoods. Use the visualisation and the summary statistics to describe the distribution of listing prices in the neighbourhoods. (Your answer will include three pipelines, one of which ends in a visualisation, and a narrative.)
+5.  Create a visualization that will help you compare the distribution of review scores (`review_scores_rating`) across neighbourhoods. You get to decide what type of visualisation to create and there is more than one correct answer! In your answer, include a brief interpretation of how Airbnb guests rate properties in general and how the neighbourhoods compare to each other in terms of their ratings.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you're happy with the final state of your work.*

---FILE: course-materials/hw-instructions/hw-02/hw-02-bike-crash.Rmd---
@@ -1,116 +0,0 @@
----
-title: ""HW 02 - Bike crashes""
-output: 
-  tufte::tufte_html:
-    css: ../hw.css
-    tufte_variant: ""envisioned""
-    highlight: pygments
-link-citations: yes
----
-
-```{r grassmarket, fig.margin = TRUE, echo = FALSE, fig.width=3, fig.cap=""Photo by Andhika Soreng on Unsplash""}
-knitr::include_graphics(""img/bike.jpg"")
-```
-
-Biking is the environmentally friendly way to commute, and a fun activity for kids, but bike crashes are no joke!
-
-The data for this assignment comes from [Durham Open Data](https://live-durhamnc.opendata.arcgis.com/).
-The data contains bike crashes between 2007 and 2014.
-
-## Learning goals
-
-The goal of this assignment is to keep you practicing your data visualization skills while also adding on tasks for data manipulation like filtering and transforming.
-
-## Getting started
-
-```{marginfigure}
-**IMPORTANT:** If there is no GitHub repo created for you for this assignment, it means I didn't have your GitHub username as of when I assigned the homework. Please let me know your GitHub username asap, and I can create your repo.
-```
-
-Go to the course GitHub organization and locate your HW 2 repo, which should be named `hw-02-bike-crash-YOUR_GITHUB_USERNAME`.
-Grab the URL of the repo, and clone it in RStudio.
-Refer to Lab 01 if you would like to see step-by-step instructions for cloning a repo into an RStudio project.
-
-First, open the R Markdown document `hw-02-bike-crash.Rmd` and Knit it.
-Make sure it compiles without errors.
-The output will be in the file markdown `.md` file with the same name.
-
-## Packages
-
-We'll use the **tidyverse** package for the analysis, as usual and the data lives in the **dsbox** package.
-These packages are already installed for you, so you load it as usual by running the following in your Console:
-
-```{r load-packages, message=FALSE}
-library(tidyverse)
-library(dsbox)
-```
-
-## Data
-
-The data is called `ncbikecrash`.
-You can find descriptions of each of the variables in the help file for the dataset, which you can access by running `?ncbikecrash` in your Console.
-
-1.  Run `View(ncbikecrash)` in your Console to view the data in the data viewer. What does each row in the dataset represent?
-
-```{marginfigure}
-**Hint:** The Markdown Quick Reference sheet has an example of inline R code that might be helpful. You can access it from the Help menu in RStudio. Last week you used `nrow()` to find the number of rows. Use `ncol()` for the number of columns.
-```
-
-2.  How many bike crashes were recorded in NC between 2007 and 2014? How many variables are recorded on these crashes? Use inline R code when answering this question.
-
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *Now is a good time to commit and push your changes to GitHub with an appropriate commit message (e.g. ""Dimensions of data""). Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
-
-3.  How many bike crashes occurred in residential development areas where the driver was between 0 and 19 years old?
-
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *This is again a good time to commit and push your changes to GitHub with an appropriate commit message (e.g. ""Filter for residential and young driver""). Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
-
-```{marginfigure}
-**Hint:** See the help for the `count()` function, specifically the 
-`sort` argument for reporting the frequency table in descending order of counts, 
-i.e. highest on top.
-```
-
-4.  Create a frequency table of the estimated speed of the car (`driver_est_speed`) involved in the crash. What is the most common estimated speed range in the dataset?
-
-Don't forget to label your R chunk as well (where it says `label-me-1`).
-Your label should be short, informative, and shouldn't include spaces.
-It also shouldn't repeat a previous label, otherwise R Markdown will give you an error about repeated R chunk labels.
-
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *Commit and push your changes again with an appropriate commit message (e.g. ""Most common estimated speed""). Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
-
-5.  Recreate the following plot, and describe in context of the data what it shows.
-
-Don't forget to label your R chunk as well (where it says `label-me-2`).
-Your label should be short, informative, shouldn't include spaces, and shouldn't repeat a previous label.
-
-Play around with the `fig.height` and `fig.width` options in the R chunk definitions until you're satisfied with the dimensions of the figure.
-
-```{marginfigure}
-**Hint:** To match the colors, you can use `scale_fill_viridis_d()`.
-```
-
-```{r fig.width=7, fig.height=3, echo=FALSE}
-ggplot(ncbikecrash, aes(x = crash_alcohol, fill = crash_severity)) +
-  geom_bar(position = ""fill"") +
-  coord_flip() +
-  labs(y = ""Proportion"", x = ""Did the crash involve alcohol?"",
-       fill = ""Crash severity"", 
-       title = ""Involvement of alcohol and severity of bike crashes"") +
-  scale_fill_viridis_d()
-```
-
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *This is a another good place to pause, commit changes with the commit message like ""Recreated crash severity and alcohol figure"". Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
-
-```{marginfigure}
-**Hint:** Instead of changing the legend, change how the data are represented in the `crash_severity` variable with `mutate()`.
-```
-
-6.  Recreate the same figure, but this time change the labels of the crash severity variable such that text like `A:`, `B:`, etc. doesn't show up.
-
-For this question you'll need to add an R chunk, label it, and define preferences for the figure's height and width.
-
-```{marginfigure}
-Not sure how to use emojis on your computer? Maybe a classmate can help? Or you can ask on Piazza or student hours!
-```
-
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *Yay, you're done! Commit all remaining changes, use the commit message ""Recreated figure with cleaner labels, done with HW 2! `r emo::ji(""muscle"")`"", and push. Before you wrap up the assignment, make sure all documents are updated on your GitHub repo.*

---FILE: course-materials/hw-instructions/hw-03/hw-03-accidents.Rmd---
@@ -0,0 +1,103 @@
+---
+title: ""HW 03 - Road traffic accidents""
+output: 
+  tufte::tufte_html:
+    css: ../hw.css
+    tufte_variant: ""envisioned""
+    highlight: pygments
+link-citations: yes
+---
+
+```{r include = FALSE}
+knitr::opts_chunk$set(
+  eval = FALSE,
+  out.width = ""80%"",
+  fig.asp = 0.618,
+  fig.width = 10,
+  dpi = 300
+)
+```
+
+```{r photo, fig.margin = TRUE, echo = FALSE, fig.width = 3, fig.cap = ""Photo by Clark Van Der Beken on Unsplash"", eval = TRUE}
+knitr::include_graphics(""img/accident.jpg"")
+```
+
+In this assignment we'll look at traffic accidents in Edinburgh.
+The data are made available [online](https://data.gov.uk/dataset/cb7ae6f0-4be6-4935-9277-47e5ce24a11f/road-safety-data/datafile/36f1658e-b709-47e7-9f56-cca7aefeb8fe/preview) by the UK Government.
+It covers all recorded accidents in Edinburgh in 2018 and some of the variables were modified for the purposes of this assignment.
+
+# Getting started
+
+```{marginfigure}
+**IMPORTANT:** If there is no GitHub repo created for you for this assignment, it means I didn't have your GitHub username as of when I assigned the homework. Please let me know your GitHub username asap, and I can create your repo.
+```
+
+Go to the course GitHub organization and locate your homework repo, which should be named `hw-03-accidents-YOUR_GITHUB_USERNAME`.
+Grab the URL of the repo, and clone it in RStudio.
+First, open the R Markdown document `hw-03.Rmd` and Knit it.
+Make sure it compiles without errors.
+The output will be in the file markdown `.md` file with the same name.
+
+## Warm up
+
+Before we introduce the data, let's warm up with some simple exercises.
+
+-   Update the YAML, changing the author name to your name, and **knit** the document.
+-   Commit your changes with a meaningful commit message.
+-   Push your changes to GitHub.
+-   Go to your repo on GitHub and confirm that your changes are visible in your Rmd **and** md files. If anything is missing, commit and push again.
+
+## Packages
+
+We'll use the **tidyverse** package for much of the data wrangling and visualisation and the data lives in the **dsbox** package.
+These packages are already installed for you.
+You can load them by running the following in your Console:
+
+```{r load-packages, message = FALSE, eval = TRUE}
+library(tidyverse)
+library(dsbox)
+```
+
+## Data
+
+The data can be found in the **dsbox** package, and it's called `accidents`.
+Since the dataset is distributed with the package, we don't need to load it separately; it becomes available to us when we load the package.
+You can find out more about the dataset by inspecting its documentation, which you can access by running `?accidents` in the Console or using the Help menu in RStudio to search for `accidents`.
+You can also find this information [here](https://rstudio-education.github.io/dsbox/reference/accidents.html).
+
+# Exercises
+
+1.  How many observations (rows) does the dataset have? Instead of hard coding the number in your answer, use inline code.
+
+```{marginfigure}
+**Tired of typing your password?** Chances are your browser has already saved your password, but if not, you can ask Git to save (cache) your password for a period of time, where you indicate the period of time in seconds. For example, if you want it to cache your password for 1 hour, that would be 3,600 seconds. To do so, run the following *in the Console*: `usethis::use_git_config(credential.helper = ""cache --timeout=3600"")`. If you want to cache it for a longer time, you can adjust the number of seconds in the code.
+```
+
+1.  Run `View(accidents)` in your Console to view the data in the data viewer. What does each row in the dataset represent?
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+3.  Recreate the following plot, and describe in context of the data. In your answer, don't forget to label your R chunk as well (where it says `label-me-1`). Your label should be short, informative, shouldn't include spaces, and shouldn't shouldn't repeat a previous label.
+
+```{r eval = TRUE, echo = FALSE, fig.fullwidth = TRUE}
+accidents %>%
+  mutate(day_of_week_type = if_else(day_of_week %in% c(""Saturday"", ""Sunday""), ""Weekend"", ""Weekday"")) %>%
+  ggplot(aes(x = time, fill = severity)) +
+  geom_density(alpha = 0.5) +
+  facet_wrap(~day_of_week_type, ncol = 1) +
+  theme_minimal() +
+  scale_fill_viridis_d() +
+  labs(
+    title = ""Number of accidents throughout the day"",
+    subtitle = ""By day of week and severity"",
+    x = ""Time of day"",
+    y = ""Density"",
+    fill = ""Severity""
+  )
+```
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+4.  Create another data visualisation based on these data and interpret it. You can choose any variables and any type of visualisation you like, but it must have at least three variables, e.g. a scatterplot of x vs. y isn't enough, but if points are coloured by z, that's fine. In your answer, don't forget to label your R chunk as well (where it says `label-me-2`).
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you're happy with the final state of your work.*

---FILE: course-materials/hw-instructions/hw-03/hw-03-college-majors.Rmd---
@@ -1,292 +0,0 @@
----
-title: ""HW 03 - What should I major in?""
-output: 
-  tufte::tufte_html:
-    css: ../hw.css
-    tufte_variant: ""envisioned""
-    highlight: pygments
-link-citations: yes
----
-
-```{r grassmarket, fig.margin = TRUE, echo = FALSE, fig.width=3, fig.cap=""Photo by Marleena Garris on Unsplash""}
-knitr::include_graphics(""img/graduate.jpg"")
-```
-
-The first step in the process of turning information into knowledge process is to summarize and describe the raw information - the data.
-In this assignment we explore data on college majors and earnings, specifically the data begind the FiveThirtyEight story [""The Economic Guide To Picking A College Major""](https://fivethirtyeight.com/features/the-economic-guide-to-picking-a-college-major/).
-
-These data originally come from the American Community Survey (ACS) 2010-2012 Public Use Microdata Series.
-While this is outside the scope of this assignment, if you are curious about howraw data from the ACS were cleaned and prepared, see [the code](https://github.com/fivethirtyeight/data/blob/master/college-majors/college-majors-rscript.R) FiveThirtyEight authors used.
-
-We should also note that there are many considerations that go into picking a major.
-Earnings potential and employment prospects are two of them, and they are important, but they don't tell the whole story.
-Keep this in mind as you analyze the data.
-
-# Packages
-
-In this assignment we will work with the `tidyverse` as usual.
-In addition, we'll use the `scales` package for formatting numerical values, and the `fivethirtyeight` package for data.
-`tidyverse` and `scales` packages are already installed for you, so you can load them with the following:
-
-```{r message=FALSE}
-library(tidyverse)
-library(scales)
-```
-
-You'll first need to install the `fivethirtyeight` package by running the following in the console once:
-
-```{r eval=FALSE}
-install.packages(""fivethirtyeight"")
-```
-
-and then you can load it as usual with:
-
-```{r message=FALSE}
-library(fivethirtyeight)
-```
-
-Note that these packages are also loaded in your R Markdown document.
-
-# The data
-
-The data frame we will be working with today is called `college_recent_grads` and it's in the `fivethirtyeight` package.
-
-To find out more about the dataset, type the following in your Console: `?college_recent_grads`.
-A question mark before the name of an object will always bring up its help file.
-This command must be ran in the Console.
-
-`college_recent_grads` is a tidy **data frame**, with each row representing an **observation** and each column representing a **variable**.
-
-To view the data, click on the name of the data frame in the Environment tab.
-
-You can also take a quick peek at your data frame and view its dimensions with the `glimpse` function.
-
-```{r glimpse}
-glimpse(college_recent_grads)
-```
-
-The description of the variables, i.e. the **codebook**, is given below.
-
-| Header                         | Description                                                                |
-|:-------------------------------|:---------------------------------------------------------------------------|
-| `rank`                         | Rank by median earnings                                                    |
-| `major_code`                   | Major code, FO1DP in ACS PUMS                                              |
-| `major`                        | Major description                                                          |
-| `major_category`               | Category of major from Carnevale et al                                     |
-| `total`                        | Total number of people with major                                          |
-| `sample_size`                  | Sample size (unweighted) of full-time, year-round ONLY (used for earnings) |
-| `men`                          | Male graduates                                                             |
-| `women`                        | Female graduates                                                           |
-| `sharewomen`                   | Women as share of total                                                    |
-| `employed`                     | Number employed (ESR == 1 or 2)                                            |
-| `employed_full_time`           | Employed 35 hours or more                                                  |
-| `employed_part_time`           | Employed less than 35 hours                                                |
-| `employed_full_time_yearround` | Employed at least 50 weeks (WKW == 1) and at least 35 hours (WKHP \>= 35)  |
-| `unemployed`                   | Number unemployed (ESR == 3)                                               |
-| `unemployment_rate`            | Unemployed / (Unemployed + Employed)                                       |
-| `median`                       | Median earnings of full-time, year-round workers                           |
-| `p25th`                        | 25th percentile of earnigns                                                |
-| `p75th`                        | 75th percentile of earnings                                                |
-| `college_jobs`                 | Number with job requiring a college degree                                 |
-| `non_college_jobs`             | Number with job not requiring a college degree                             |
-| `low_wage_jobs`                | Number in low-wage service jobs                                            |
-
-The `college_recent_grads` data frame is a trove of information.
-Let's think about some questions we might want to answer with these data:
-
--   Which major has the lowest unemployment rate?
--   Which major has the highest percentage of women?
--   How do the distributions of median income compare across major categories?
--   Do women tend to choose majors with lower or higher earnings?
-
-In the next section we aim to answer these questions.
-
-# Data wrangling and visualization
-
-## Which major has the lowest unemployment rate?
-
-In order to answer this question all we need to do is sort the data.
-We use the `arrange` function to do this, and sort it by the `unemployment_rate` variable.
-By default `arrange` sorts in ascending order, which is what we want here -- we're interested in the major with the *lowest* unemployment rate.
-
-```{r lowest-unemp}
-college_recent_grads %>%
-  arrange(unemployment_rate)
-```
-
-This gives us what we wanted, but not in an ideal form.
-First, the name of the major barely fits on the page.
-Second, some of the variables are not that useful (e.g. `major_code`, `major_category`) and some we might want front and center are not easily viewed (e.g. `unemployment_rate`).
-
-We can use the `select` function to choose which variables to display, and in which order:
-
-```{marginfigure}
-Note how easily we expanded our code with adding another step to our pipeline,
-with the pipe operator: `%>%`.
-```
-
-```{r lowest-unemp-select}
-college_recent_grads %>%
-  arrange(unemployment_rate) %>%
-  select(rank, major, unemployment_rate)
-```
-
-Ok, this is looking better, but do we really need to display all those decimal places in the unemployment variable?
-Not really!
-
-We can use the `percent()` function to clean up the display a bit.
-
-```{r}
-college_recent_grads %>%
-  arrange(unemployment_rate) %>%
-  select(rank, major, unemployment_rate) %>%
-  mutate(unemployment_rate = percent(unemployment_rate))
-```
-
-## Which major has the highest percentage of women?
-
-To answer such a question we need to arrange the data in descending order.
-For example, if earlier we were interested in the major with the highest unemployment rate, we would use the following:
-
-```{marginfigure}
-The `desc` function specifies that we want `unemployment_rate` in descending order.
-```
-
-```{r}
-college_recent_grads %>%
-  arrange(desc(unemployment_rate)) %>%
-  select(rank, major, unemployment_rate)
-```
-
-1.  Using what you've learned so far, arrange the data in descending order with respect to proportion of women in a major, and display only the major, the total number of people with major, and proportion of women. Show only the top 3 majors by adding `top_n(3)` at the end of the pipeline.
-
-## How do the distributions of median income compare across major categories?
-
-```{marginfigure}
-A percentile is a measure used in statistics indicating the value below which a given percentage of observations in a group of observations fall. For example, the 20th percentile is the value below which 20% of the observations may be found. (Source: [Wikipedia](https://en.wikipedia.org/wiki/Percentile)
-```
-
-There are three types of incomes reported in this data frame: `p25th`, `median`, and `p75th`.
-These correspond to the 25th, 50th, and 75th percentiles of the income distribution of sampled individuals for a given major.
-
-2.  Why do we often choose the median, rather than the mean, to describe the typical income of a group of people?
-
-The question we want to answer ""How do the distributions of median income compare across major categories?"".
-We need to do a few things to answer this question: First, we need to group the data by `major_category`.
-Then, we need a way to summarize the distributions of median income within these groups.
-This decision will depend on the shapes of these distributions.
-So first, we need to visualize the data.
-
-We use the `ggplot()` function to do this.
-The first argument is the data frame, and the next argument gives the mapping of the variables of the data to the `aes`thetic elements of the plot.
-
-Let's start simple and take a look at the distribution of all median incomes, without considering the major categories.
-
-```{r fig,height=2}
-ggplot(data = college_recent_grads, mapping = aes(x = median)) +
-  geom_histogram()
-```
-
-Along with the plot, we get a message:
-
-    `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
-
-This is telling us that we might want to reconsider the binwidth we chose for our histogram -- or more accurately, the binwidth we didn't specify.
-It's good practice to always think in the context of the data and try out a few binwidths before settling on a binwidth.
-You might ask yourself: ""What would be a meaningful difference in median incomes?"" \$1 is obviously too little, \$10000 might be too high.
-
-3.  Try binwidths of \$1000 and \$5000 and choose one. Explain your reasoning for your choice. Note that the binwidth is an argument for the `geom_histogram` function. So to specify a binwidth of \$1000, you would use `geom_histogram(binwidth = 1000)`.
-
-We can also calculate summary statistics for this distribution using the `summarise` function:
-
-```{r}
-college_recent_grads %>%
-  summarise(min = min(median), max = max(median),
-            mean = mean(median), med = median(median),
-            sd = sd(median), 
-            q1 = quantile(median, probs = 0.25),
-            q3 = quantile(median, probs = 0.75))
-```
-
-4.  Based on the shape of the histogram you created in the previous exercise, determine which of these summary statistics is useful for describing the distribution.
-    Write up your description (remember shape, center, spread, any unusual observations) and include the summary statistic output as well.
-
-5.  Plot the distribution of `median` income using a histogram, faceted by `major_category`.
-    Use the `binwidth` you chose in the earlier exercise.
-
-Now that we've seen the shapes of the distributions of median incomes for each major category, we should have a better idea for which summary statistic to use to quantify the typical median income.
-
-6.  Which major category has the highest typical (you'll need to decide what this means) median income? Use the partial code below, filling it in with the appropriate statistic and function. Also note that we are looking for the highest statistic, so make sure to arrange in the correct direction.
-
-```{r eval=FALSE}
-college_recent_grads %>%
-  group_by(major_category) %>%
-  summarise(___ = ___(median)) %>%
-  arrange(___)
-```
-
-7.  Which major category is the least popular in this sample? To answer this question we use a new function called `count`, which first groups the data and then counts the number of observations in each category (see below). Add to the pipeline appropriately to arrange the results so that the major with the lowest observations is on top.
-
-```{r}
-college_recent_grads %>%
-  count(major_category)
-```
-
-## All STEM fields aren't the same
-
-One of the sections of the [FiveThirtyEight story](https://fivethirtyeight.com/features/the-economic-guide-to-picking-a-college-major/) is ""All STEM fields aren't the same"".
-Let's see if this is true.
-
-First, let's create a new vector called `stem_categories` that lists the major categories that are considered STEM fields.
-
-```{r}
-stem_categories <- c(""Biology & Life Science"",
-                     ""Computers & Mathematics"",
-                     ""Engineering"",
-                     ""Physical Sciences"")
-```
-
-Then, we can use this to create a new variable in our data frame indicating whether a major is STEM or not.
-
-```{r}
-college_recent_grads <- college_recent_grads %>%
-  mutate(major_type = ifelse(major_category %in% stem_categories, ""stem"", ""not stem""))
-```
-
-Let's unpack this: with `mutate` we create a new variable called `major_type`, which is defined as `""stem""` if the `major_category` is in the nector called `stem_categories` we created earlier, and as `""not stem""` otherwise.
-
-`%in%` is a **logical operator**.
-Other logical operators that are commonly used are
-
-| Operator            | Operation                |
-|:--------------------|:-------------------------|
-| `x < y`             | less than                |
-| `x > y`             | greater than             |
-| `x <= y`            | less than or equal to    |
-| `x >= y`            | greater than or equal to |
-| `x != y`            | not equal to             |
-| `x == y`            | equal to                 |
-| `x %in% y`          | contains                 |
-| <code>x \| y</code> | or                       |
-| `x & y`             | and                      |
-| `!x`                | not                      |
-
-We can use the logical operators to also `filter` our data for STEM majors whose median earnings is less than median for all majors's median earnings, which we found to be \$36,000 earlier.
-
-```{r}
-college_recent_grads %>%
-  filter(
-    major_type == ""stem"",
-    median < 36000
-  )
-```
-
-8.  Which STEM majors have median salaries equal to or less than the median for all majors's median earnings? Your output should only show the major name and median, 25th percentile, and 75th percentile earning for that major as and should be sorted such that the major with the highest median earning is on top.
-
-## What types of majors do women tend to major in?
-
-9.  Create a scatterplot of median income vs. proportion of women in that major, colored by whether the major is in a STEM field or not. Describe the association between these three variables.
-
-## Further exploration
-
-10. Ask a question of interest to you, and answer it using summary statistic(s) and/or visualization(s).

---FILE: course-materials/hw-instructions/hw-04/hw-04-college-majors.Rmd---
@@ -0,0 +1,281 @@
+---
+title: ""HW 04 - What should I major in?""
+output: 
+  tufte::tufte_html:
+    css: ../hw.css
+    tufte_variant: ""envisioned""
+    highlight: pygments
+link-citations: yes
+---
+
+```{r include = FALSE}
+knitr::opts_chunk$set(
+  eval = FALSE,
+  out.width = ""80%"",
+  fig.asp = 0.618,
+  fig.width = 10,
+  dpi = 300
+)
+```
+
+```{r photo, fig.margin = TRUE, echo = FALSE, fig.width = 3, fig.cap = ""Photo by Marleena Garris on Unsplash"", eval = TRUE}
+knitr::include_graphics(""img/graduate.jpg"")
+```
+
+The first step in the process of turning information into knowledge process is to summarize and describe the raw information - the data.
+In this assignment we explore data on college majors and earnings, specifically the data begin the FiveThirtyEight story [""The Economic Guide To Picking A College Major""](https://fivethirtyeight.com/features/the-economic-guide-to-picking-a-college-major/).
+
+These data originally come from the American Community Survey (ACS) 2010-2012 Public Use Microdata Series.
+While this is outside the scope of this assignment, if you are curious about how raw data from the ACS were cleaned and prepared, see [the code](https://github.com/fivethirtyeight/data/blob/master/college-majors/college-majors-rscript.R) FiveThirtyEight authors used.
+
+We should also note that there are many considerations that go into picking a major.
+Earnings potential and employment prospects are two of them, and they are important, but they don't tell the whole story.
+Keep this in mind as you analyze the data.
+
+# Getting started
+
+Go to the course GitHub organization and locate your homework repo, which should be named `hw-04-college-majors-YOUR_GITHUB_USERNAME`.
+Grab the URL of the repo, and clone it in RStudio.
+First, open the R Markdown document `hw-04.Rmd` and Knit it.
+Make sure it compiles without errors.
+The output will be in the file markdown `.md` file with the same name.
+
+## Warm up
+
+Before we introduce the data, let's warm up with some simple exercises.
+
+-   Update the YAML, changing the author name to your name, and **knit** the document.
+-   Commit your changes with a meaningful commit message.
+-   Push your changes to GitHub.
+-   Go to your repo on GitHub and confirm that your changes are visible in your Rmd **and** md files. If anything is missing, commit and push again.
+
+## Packages
+
+We'll use the **tidyverse** package for much of the data wrangling and visualisation, the **scales** package for better formatting of labels on visualisations, and the data lives in the **fivethirtyeight** package.
+These packages are already installed for you.
+You can load them by running the following in your Console:
+
+```{r load-packages, message = FALSE, eval = TRUE}
+library(tidyverse)
+library(scales)
+library(fivethirtyeight)
+```
+
+## Data
+
+The data can be found in the **fivethirtyeight** package, and it's called `college_recent_grads`.
+Since the dataset is distributed with the package, we don't need to load it separately; it becomes available to us when we load the package.
+You can find out more about the dataset by inspecting its documentation, which you can access by running `?college_recent_grads` in the Console or using the Help menu in RStudio to search for `college_recent_grads`.
+You can also find this information [here](https://fivethirtyeight-r.netlify.app/reference/college_recent_grads.html).
+
+You can also take a quick peek at your data frame and view its dimensions with the `glimpse` function.
+
+```{r glimpse}
+glimpse(college_recent_grads)
+```
+
+The `college_recent_grads` data frame is a trove of information.
+Let's think about some questions we might want to answer with these data:
+
+-   Which major has the lowest unemployment rate?
+-   Which major has the highest percentage of women?
+-   How do the distributions of median income compare across major categories?
+-   Do women tend to choose majors with lower or higher earnings?
+
+In the next section we aim to answer these questions.
+
+# Exercises
+
+## Which major has the lowest unemployment rate?
+
+In order to answer this question all we need to do is sort the data.
+We use the `arrange` function to do this, and sort it by the `unemployment_rate` variable.
+By default `arrange` sorts in ascending order, which is what we want here -- we're interested in the major with the *lowest* unemployment rate.
+
+```{r lowest-unemp}
+college_recent_grads %>%
+  arrange(unemployment_rate)
+```
+
+This gives us what we wanted, but not in an ideal form.
+First, the name of the major barely fits on the page.
+Second, some of the variables are not that useful (e.g. `major_code`, `major_category`) and some we might want front and center are not easily viewed (e.g. `unemployment_rate`).
+
+We can use the `select` function to choose which variables to display, and in which order:
+
+```{marginfigure}
+Note how easily we expanded our code with adding another step to our pipeline,
+with the pipe operator: `%>%`.
+```
+
+```{r lowest-unemp-select}
+college_recent_grads %>%
+  arrange(unemployment_rate) %>%
+  select(rank, major, unemployment_rate)
+```
+
+Ok, this is looking better, but do we really need to display all those decimal places in the unemployment variable?
+Not really!
+
+We can use the `percent()` function to clean up the display a bit.
+
+```{r}
+college_recent_grads %>%
+  arrange(unemployment_rate) %>%
+  select(rank, major, unemployment_rate) %>%
+  mutate(unemployment_rate = percent(unemployment_rate))
+```
+
+## Which major has the highest percentage of women?
+
+To answer such a question we need to arrange the data in descending order.
+For example, if earlier we were interested in the major with the highest unemployment rate, we would use the following:
+
+```{marginfigure}
+The `desc` function specifies that we want `unemployment_rate` in descending order.
+```
+
+```{r}
+college_recent_grads %>%
+  arrange(desc(unemployment_rate)) %>%
+  select(rank, major, unemployment_rate)
+```
+
+1.  Using what you've learned so far, arrange the data in descending order with respect to proportion of women in a major, and display only the major, the total number of people with major, and proportion of women. Show only the top 3 majors by adding `top_n(3)` at the end of the pipeline.
+
+## How do the distributions of median income compare across major categories?
+
+```{marginfigure}
+A percentile is a measure used in statistics indicating the value below which a given percentage of observations in a group of observations fall. For example, the 20th percentile is the value below which 20% of the observations may be found. (Source: [Wikipedia](https://en.wikipedia.org/wiki/Percentile)
+```
+
+There are three types of incomes reported in this data frame: `p25th`, `median`, and `p75th`.
+These correspond to the 25th, 50th, and 75th percentiles of the income distribution of sampled individuals for a given major.
+
+2.  Why do we often choose the median, rather than the mean, to describe the typical income of a group of people?
+
+The question we want to answer ""How do the distributions of median income compare across major categories?"".
+We need to do a few things to answer this question: First, we need to group the data by `major_category`.
+Then, we need a way to summarize the distributions of median income within these groups.
+This decision will depend on the shapes of these distributions.
+So first, we need to visualize the data.
+
+We use the `ggplot()` function to do this.
+The first argument is the data frame, and the next argument gives the mapping of the variables of the data to the `aes`thetic elements of the plot.
+
+Let's start simple and take a look at the distribution of all median incomes, without considering the major categories.
+
+```{r fig,height=2}
+ggplot(data = college_recent_grads, mapping = aes(x = median)) +
+  geom_histogram()
+```
+
+Along with the plot, we get a message:
+
+    `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
+
+This is telling us that we might want to reconsider the binwidth we chose for our histogram -- or more accurately, the binwidth we didn't specify.
+It's good practice to always think in the context of the data and try out a few binwidths before settling on a binwidth.
+You might ask yourself: ""What would be a meaningful difference in median incomes?"" \$1 is obviously too little, \$10000 might be too high.
+
+3.  Try binwidths of \$1000 and \$5000 and choose one. Explain your reasoning for your choice. Note that the binwidth is an argument for the `geom_histogram` function. So to specify a binwidth of \$1000, you would use `geom_histogram(binwidth = 1000)`.
+
+We can also calculate summary statistics for this distribution using the `summarise` function:
+
+```{r}
+college_recent_grads %>%
+  summarise(min = min(median), max = max(median),
+            mean = mean(median), med = median(median),
+            sd = sd(median), 
+            q1 = quantile(median, probs = 0.25),
+            q3 = quantile(median, probs = 0.75))
+```
+
+4.  Based on the shape of the histogram you created in the previous exercise, determine which of these summary statistics is useful for describing the distribution.
+    Write up your description (remember shape, center, spread, any unusual observations) and include the summary statistic output as well.
+
+5.  Plot the distribution of `median` income using a histogram, faceted by `major_category`.
+    Use the `binwidth` you chose in the earlier exercise.
+
+Now that we've seen the shapes of the distributions of median incomes for each major category, we should have a better idea for which summary statistic to use to quantify the typical median income.
+
+6.  Which major category has the highest typical (you'll need to decide what this means) median income? Use the partial code below, filling it in with the appropriate statistic and function. Also note that we are looking for the highest statistic, so make sure to arrange in the correct direction.
+
+```{r eval=FALSE}
+college_recent_grads %>%
+  group_by(major_category) %>%
+  summarise(___ = ___(median)) %>%
+  arrange(___)
+```
+
+7.  Which major category is the least popular in this sample? To answer this question we use a new function called `count`, which first groups the data and then counts the number of observations in each category (see below). Add to the pipeline appropriately to arrange the results so that the major with the lowest observations is on top.
+
+```{r}
+college_recent_grads %>%
+  count(major_category)
+```
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+## All STEM fields aren't the same
+
+One of the sections of the [FiveThirtyEight story](https://fivethirtyeight.com/features/the-economic-guide-to-picking-a-college-major/) is ""All STEM fields aren't the same"".
+Let's see if this is true.
+
+First, let's create a new vector called `stem_categories` that lists the major categories that are considered STEM fields.
+
+```{r}
+stem_categories <- c(""Biology & Life Science"",
+                     ""Computers & Mathematics"",
+                     ""Engineering"",
+                     ""Physical Sciences"")
+```
+
+Then, we can use this to create a new variable in our data frame indicating whether a major is STEM or not.
+
+```{r}
+college_recent_grads <- college_recent_grads %>%
+  mutate(major_type = ifelse(major_category %in% stem_categories, ""stem"", ""not stem""))
+```
+
+Let's unpack this: with `mutate` we create a new variable called `major_type`, which is defined as `""stem""` if the `major_category` is in the vector called `stem_categories` we created earlier, and as `""not stem""` otherwise.
+
+`%in%` is a **logical operator**.
+Other logical operators that are commonly used are
+
+| Operator            | Operation                |
+|:--------------------|:-------------------------|
+| `x < y`             | less than                |
+| `x > y`             | greater than             |
+| `x <= y`            | less than or equal to    |
+| `x >= y`            | greater than or equal to |
+| `x != y`            | not equal to             |
+| `x == y`            | equal to                 |
+| `x %in% y`          | contains                 |
+| <code>x \| y</code> | or                       |
+| `x & y`             | and                      |
+| `!x`                | not                      |
+
+We can use the logical operators to also `filter` our data for STEM majors whose median earnings is less than median for all majors' median earnings, which we found to be \$36,000 earlier.
+
+```{r}
+college_recent_grads %>%
+  filter(
+    major_type == ""stem"",
+    median < 36000
+  )
+```
+
+8.  Which STEM majors have median salaries equal to or less than the median for all majors' median earnings? Your output should only show the major name and median, 25th percentile, and 75th percentile earning for that major as and should be sorted such that the major with the highest median earning is on top.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+## What types of majors do women tend to major in?
+
+9.  Create a scatterplot of median income vs. proportion of women in that major, coloured by whether the major is in a STEM field or not. Describe the association between these three variables.
+
+## Further exploration
+
+10. Ask a question of interest to you, and answer it using summary statistic(s) and/or visualization(s).
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you're happy with the final state of your work.*

---FILE: course-materials/hw-instructions/hw-04/hw-04-legos-instructors.Rmd---
@@ -1,82 +0,0 @@
----
-title: ""HW 04 - Legos and instructors""
-output: 
-  tufte::tufte_html:
-    css: ../hw.css
-    tufte_variant: ""envisioned""
-    highlight: pygments
-link-citations: yes
----
-
-```{r grassmarket, fig.margin = TRUE, echo = FALSE, fig.width=3, fig.cap=""Photo by Daniel Cheung on Unsplash""}
-knitr::include_graphics(""img/daniel-cheung-ZqqlOZyGG7g-unsplash.jpg"")
-```
-
-This week we'll do some data gymnastics to refresh and review what we learned over the past few weeks.
-
-# Packages
-
-In this assignment we will work with the `tidyverse` as usual ans the **dsbox** package for the data.
-
-```{r load-package, eval=FALSE}
-library(tidyverse)
-library(dsbox)
-```
-
-## Lego sales
-
-We have (simulated) data from lego sales in 2018 for a sample of customers who bought legos in the US.  The dataset is called `lego_sales`. You can find descriptions of each of the variables in the help file for the dataset, which you can access by running `?lego_sales` in your Console.
-
-Answer the following questions using pipelines. For each question, state your answer in a sentence, e.g. ""The first three common names of purchasers are ..."".
-
-1. What are the three most common first names of purchasers?
-
-2. What are the three most common themes of lego sets purchased?
-
-3. Among the most common theme of lego sets purchased, what is the most common 
-subtheme?
-
-```{marginfigure}
-*Hint:* Use the `case_when()` function.
-```
-
-4. Create a new variable called `age_group` and group the ages into the 
-following categories: ""18 and under"", ""19 - 25"", ""26 - 35"", ""36 - 50"", ""51 and over"".
-
-```{marginfigure}
-*Hint:* You will need to consider quantity of purchases.
-```
-
-5. Which age group has purchased the highest number of lego sets. 
-
-```{marginfigure}
-*Hint:* You will need to consider quantity of purchases as well as price of 
-lego sets.
-```
-
-6. Which age group has spent the most money on legos?
-
-7. Come up with a question you want to answer using these data, and write it down. 
-Then, create a data visualization that answers the question, and explain how 
-your visualization answers the question.
-
-## Instructional staff employment trends
-
-The next dataset is about instructional staff employee hiring trends between 1975 and 2011. 
-The dataset is called `instructors`. You can find descriptions of each of the variables in the help file for the dataset, which you can access by running `?instructors` in your Console.
-
-The American Association of University Professors (AAUP) is a nonprofit membership association of faculty and other academic professionals. [This report](https://www.aaup.org/sites/default/files/files/AAUP_Report_InstrStaff-75-11_apr2013.pdf) compiled by the AAUP shows trends in instructional staff employees between 1975 and 2011, and contains an image very similar to the one given below.
-
-```{r instructors, echo = FALSE, fig.width=7}
-knitr::include_graphics(""img/instructors.png"")
-```
-
-During the lab you had a chance to discuss with your teammates how you 
-would improve upon this visualization if the main objective was to communicate 
-that the proportion of part-time faculty have gone up over time compared to 
-other instructional staff types.
-
-8. Implement the improvements and provide your improved visualization as part 
-of your answer. Also write a few sentences about why you chose to make these 
-improvements and how they address the main goal stated above. Feel free to reuse 
-any code from the lab.

---FILE: course-materials/hw-instructions/hw-05/data/pac-1998.csv---
@@ -1,99 +0,0 @@
-name,country_parent,total,dems,repubs,year
-ABB Daimler-Benz Transportation,Germany/Daimler-Benz AG,""$15,775"",""$10,775"",""$5,000"",1998
-ABB Group,Switzerland/Asea Brown Boveri,""$48,500"",""$19,750"",""$28,750"",1998
-AE Staley Manufacturing (Tate & Lyle),UK/Tate & Lyle,""$30,500"",""$3,500"",""$27,000"",1998
-AEGON USA (AEGON USA),Netherlands/Aegon NV,""$41,700"",""$10,100"",""$31,600"",1998
-Alcatel USA,France/Alcatel,""$31,000"",""$8,500"",""$22,500"",1998
-Allied Domecq Spirits & Wine,UK/Allied Domecq,""$39,500"",""$11,000"",""$28,500"",1998
-APL Ltd,Singapore/Neptune Orient Lines,""$41,983"",""$18,060"",""$23,923"",1998
-Aqua-Chem Inc,France/Lyonnaise des Eaux-Dumez Group,""$11,800"",""$1,200"",""$10,600"",1998
-Ares-Serono Inc,Switzerland/Serono SA,""$6,357"",""$5,857"",$500,1998
-Bacardi Corp,UK/Bacardi Ltd,$0,$0,$0,1998
-Bacardi-Martini USA,UK/Bacardi Ltd,""$8,500"",""$3,500"",""$5,000"",1998
-BASF Corp,Germany/BASF Group,$0,$0,$0,1998
-Bayer Corp,Germany/Bayer AG,""$186,500"",""$50,250"",""$136,250"",1998
-Bear Creek Corp (Shaklee Corp),Japan/Yamanouchi Pharmaceutical,""$5,000"",""$2,500"",""$2,500"",1998
-BHP Copper (Broken Hill Proprietary),Australia/Broken Hill Proprietary,""$7,450"",""$1,000"",""$6,450"",1998
-BHP Minerals International (Broken Hill Proprietary),Australia/Broken Hill Proprietary,""$10,250"",""$4,500"",""$5,750"",1998
-BHP Petroleum Americas (Broken Hill Proprietary),Australia/Broken Hill Proprietary,""$2,600"",""$2,500"",$100,1998
-Blue Circle America,UK/Blue Circle Industries,""$31,850"",""$2,250"",""$29,600"",1998
-BOC Group,UK/BOC Group,$0,$0,$0,1998
-BP America,UK/British Petroleum Co,""$122,361"",""$31,250"",""$91,111"",1998
-Brown & Williamson Tobacco,UK/BAT Industries,""$350,821"",""$90,000"",""$260,821"",1998
-Budd Co,Germany/Thyssen,""$16,600"",""$1,500"",""$15,100"",1998
-Ciba Specialty Chemicals,Switzerland/Ciba Specialty Chemicals Holding Inc,""$15,000"",""$2,000"",""$13,000"",1998
-CIBC Oppenheimer,Canada/Canadian Imperial Bank of Commerce,$0,$0,$0,1998
-Credit Suisse First Boston,Switzerland/Credit Suisse Group,""$188,750"",""$90,500"",""$98,250"",1998
-DaimlerChrysler (DaimlerChrysler),Germany/DaimlerChrysler AG,""$493,386"",""$192,936"",""$300,450"",1998
-""Donaldson, Lufkin & Jenrette (Equitable Companies)"",France/AXA Group SA,""$3,000"",""$1,000"",""$2,000"",1998
-Electrocom Automation Inc,Germany/Daimler-Benz,""$1,800"",$0,""$1,800"",1998
-Elf Atochem North America,France/Elf Aquitaine,""$26,600"",""$6,700"",""$19,900"",1998
-Equitable Companies (Equitable Companies),France/AXA Group SA,""$124,500"",""$60,500"",""$64,000"",1998
-Equitable of Iowa Companies (ING Americas),Netherlands/ING Group,""$6,900"",""$1,000"",""$5,900"",1998
-Essroc Corp,Italy/Italcementi Group,""$1,000"",""$1,000"",$0,1998
-Farmers Group (Zurich Financial Services),Switzerland/Zurich Financial Services,""$22,175"",""$2,000"",""$20,175"",1998
-Fina Inc,Belgium/Petrofina,""$11,050"",""$5,000"",""$6,050"",1998
-First Maryland Bancorp,Ireland/Allied Irish Banks,""$8,800"",""$4,475"",""$4,325"",1998
-Food Lion,Belgium/Delhaize Group,""$39,416"",""$12,707"",""$26,709"",1998
-Fortis Inc,Belgium/Fortis AG,$500,$0,$500,1998
-Fox Inc (News Corporation),Australia/News Corp,""$25,134"",""$10,134"",""$15,000"",1998
-GEC-Marconi Electronic Systems (Marconi North America),UK/General Electric Co PLC,""$27,600"",""$10,600"",""$17,000"",1998
-Genentech Inc (Roche Group),Switzerland/Roche Group,""$96,704"",""$53,704"",""$43,000"",1998
-Glaxo Wellcome Inc,UK/Glaxo Wellcome,""$406,001"",""$110,825"",""$295,176"",1998
-Grand Trunk Western-Illinois Central RR,Canada/Canadian National Railway,""$11,475"",""$5,225"",""$6,250"",1998
-Great-West Life & Annuity Insurance,Canada/Power Financial Corp,""$47,950"",""$3,000"",""$44,950"",1998
-Gulfstream Aerospace,Germany/DaimlerChrysler AG,""$27,000"",""$10,500"",""$16,500"",1998
-Heublein Inc,UK/Diageo PLC,""$28,800"",""$11,300"",""$17,500"",1998
-Hill & Knowlton (WPP Group),UK/WPP Group,""$54,575"",""$26,325"",""$28,250"",1998
-Hoechst Celanese Corp (Hoechst Corp),Germany/Hoechst AG,""$74,500"",""$29,500"",""$45,000"",1998
-Hoechst Marion Roussel (Hoechst Corp),Germany/Hoechst AG,""$44,256"",""$12,000"",""$32,256"",1998
-Hoffmann-La Roche (Roche Group),Switzerland/Roche Group,""$95,049"",""$31,499"",""$63,550"",1998
-Holnam Inc,Switzerland/Holderbank Financiere Glaris,""$47,062"",""$13,778"",""$33,284"",1998
-HSBC Americas,UK/HSBC Holdings,""$10,930"",""$6,700"",""$4,230"",1998
-ICI Americas Inc,UK/Imperial Chemical Industries,""$4,750"",""$2,000"",""$2,750"",1998
-Jackson National Life Insurance,UK/Prudential Corp PLC,""$46,300"",""$17,100"",""$29,200"",1998
-Joseph E Seagram & Sons (Joseph E Seagram & Sons),Canada/Seagram Co,""$136,190"",""$56,012"",""$80,178"",1998
-Kennecott Holdings,UK/Rio Tinto PLC,""$33,500"",""$8,000"",""$25,500"",1998
-LaFarge Corp,France/Lafarge SA,""$24,750"",""$10,200"",""$14,550"",1998
-LaSalle National Corp,Netherlands/ABN Amro Holding,""$19,500"",""$8,500"",""$11,000"",1998
-Learjet Inc,Canada/Bombardier Inc,""$3,500"",$0,""$3,500"",1998
-Lehigh Portland Cement,Germany/Heidelberger Zement,$0,$0,$0,1998
-Life Insurance Co of Georgia (ING Americas),Netherlands/ING Group,""$26,000"",""$7,000"",""$19,000"",1998
-Loral Space & Communications,UK/Loral Space & Communications,""$127,750"",""$85,750"",""$42,000"",1998
-Marconi North America (Marconi North America),UK/General Electric Co PLC,""$290,750"",""$103,200"",""$187,550"",1998
-Massachusetts Financial Services,Canada/Sun Life Financial Services,""$25,000"",""$8,500"",""$16,500"",1998
-Master Builders Inc (Novartis Corp),Switzerland/Sandoz,""$2,500"",$500,""$2,000"",1998
-Nestle USA (Nestle SA),Switzerland/Nestle,""$58,000"",""$15,000"",""$43,000"",1998
-News America Publishing (News Corporation),Australia/News Corp,""$48,000"",""$14,000"",""$34,000"",1998
-Northern Telecom,Canada/BCE Inc,""$92,379"",""$46,266"",""$46,113"",1998
-Novartis Corp (Novartis Corp),Switzerland/Novartis AG,""-$1,250"",$0,""-$1,250"",1998
-Novartis Corp (Novartis AG),Switzerland/Novartis AG,""$157,013"",""$44,500"",""$112,513"",1998
-Organon Inc,Netherlands/Akzo Nobel,$0,$0,$0,1998
-Pasteur Merieux Connaught (Rhone-Poulenc Rorer Inc),France/Rhone-Poulenc,""$88,500"",""$43,000"",""$45,500"",1998
-Perrier Group of America (Nestle SA),Switzerland/Nestle,""$10,750"",""$4,250"",""$6,500"",1998
-Peter Pan Seafoods,Japan/Nichiro Corp,""$2,100"",-$250,""$2,350"",1998
-Philips Electronics North America,Netherlands/Philips Electronics,""$59,325"",""$11,650"",""$47,675"",1998
-Pillsbury Co,UK/Diageo PLC,""$16,600"",""$3,500"",""$13,100"",1998
-Pinkerton Tobacco,Sweden/Swedish Match AB,""$48,250"",""$17,250"",""$31,000"",1998
-Princess Cruises,UK/Peninsular & Oriental Steam Navigation,""$53,250"",""$17,500"",""$35,750"",1998
-Providian Corp (AEGON USA),Netherlands/Aegon NV,""$32,900"",$200,""$32,700"",1998
-Racal-Datacom,UK/Platinum Equity Holdings,$0,$0,$0,1998
-Rhone-Poulenc Rorer Inc (Rhone-Poulenc Rorer Inc),France/Rhone-Poulenc,""$33,500"",""$16,000"",""$17,500"",1998
-Rhone-Poulenc Rorer Inc (Rhone-Poulenc Rorer Inc),France/Rhone-Poulenc,""$42,750"",""$6,000"",""$36,750"",1998
-Rolls-Royce North America (Rolls-Royce PLC),UK/Rolls Royce,""$55,159"",""$13,898"",""$41,261"",1998
-SBC Warburg Dillon Read,Switzerland/UBS AG,$0,$0,$0,1998
-""Schroder, Wertheim & Co"",UK/Schroders PLC,$0,$0,$0,1998
-Security Life of Denver (ING Americas),Netherlands/ING Group,""$22,400"",""$5,000"",""$17,400"",1998
-Shaklee Corp (Shaklee Corp),Japan/Yamanouchi Pharmaceutical,""$13,500"",""$4,000"",""$9,500"",1998
-Shell Oil,Netherlands/Royal Dutch-Shell Group,""$113,500"",""$27,500"",""$86,000"",1998
-SmithKline Beecham,UK/SmithKline Beecham,""$138,750"",""$51,250"",""$87,500"",1998
-Sony Pictures Entertainment (Sony Corp of America),Japan/Sony Corp,""$108,500"",""$47,750"",""$60,750"",1998
-Syntex (USA) Inc,Switzerland/Roche Holdings,""$12,666"",""$11,666"",""$1,000"",1998
-Tate & Lyle North American Sugars (Tate & Lyle),UK/Tate & Lyle,""$9,900"",""$9,800"",$100,1998
-UnionBanCal Corp,Japan/Bank of Tokyo,""$10,500"",""$4,500"",""$6,000"",1998
-Universal Studios (Joseph E Seagram & Sons),Canada/Seagram Co,""$210,100"",""$90,500"",""$119,600"",1998
-US Surgical Corp,Ireland/Tyco International,""$65,550"",""$23,050"",""$42,500"",1998
-Wexler Group (WPP Group),UK/WPP Group,""$112,098"",""$47,498"",""$64,600"",1998
-Zeneca Inc (Zeneca Inc),UK/Zeneca Group PLC,$0,$0,$0,1998
-Zeneca Inc (Zeneca Inc),UK/Zeneca Group PLC,""$125,077"",""$33,827"",""$91,250"",1998
-Zurich Insurance (Zurich Financial Services),Switzerland/Zurich Financial Services,""$55,050"",""$15,550"",""$39,500"",1998

---FILE: course-materials/hw-instructions/hw-05/data/pac-2018.csv---
@@ -1,243 +0,0 @@
-name,country_parent,total,dems,repubs,year
-7-Eleven,Japan/Seven & I Holdings,""$5,500"",""$1,000"",""$4,500"",2018
-ABB Group (ABB Group),Switzerland/Asea Brown Boveri,""$10,500"",""$4,000"",""$6,500"",2018
-Accenture (Accenture),Ireland/Accenture plc,""$177,000"",""$80,500"",""$96,500"",2018
-Advance America Cash Advance Centers (Grupo Salinas),Mexico/Grupo Salinas,""$89,000"",""$9,000"",""$80,000"",2018
-Air Liquide America,France/L'Air Liquide SA,""$49,512"",""$7,000"",""$42,512"",2018
-Airbus Group,Netherlands/Airbus Group,""$191,500"",""$65,500"",""$126,000"",2018
-Alkermes Inc,Ireland/Alkermes Plc,""$165,000"",""$65,500"",""$99,500"",2018
-Allergan PLC (Allergan PLC),Ireland/Allergan PLC,""$157,500"",""$26,000"",""$131,500"",2018
-Allianz of America (Allianz),Germany/Allianz AG Holding,""$89,750"",""$29,950"",""$59,800"",2018
-AMC Theatres (AMC Theatres),China/Wanda Group,""$6,479"",$0,""$6,479"",2018
-AMG Vanadium,Netherlands/AMG Advanced Metallurgical Group,""$2,000"",$0,""$2,000"",2018
-Anheuser-Busch (Anheuser-Busch InBev),Belgium/Anheuser-Busch InBev,""$495,000"",""$241,000"",""$254,000"",2018
-AON Corp (AON plc),UK/AON PLC,""$117,700"",""$42,000"",""$75,700"",2018
-APL Ltd (CMA CGM),France/CMA CGM SA,""$7,500"",""$2,000"",""$5,500"",2018
-APL Maritime (CMA CGM),France/CMA CGM SA,""$12,500"",""$6,000"",""$5,500"",2018
-Aptiv PLC,UK/Delphi Automotive,""$5,000"",""$2,000"",""$3,000"",2018
-Arcadis US (Arcadis NV),Netherlands/Arcadis NV,$250,$250,$0,2018
-ArcelorMittal USA,Luxembourg/ArcelorMittal,""$54,500"",""$25,500"",""$29,000"",2018
-Arch Capital Group (US),UK/Arch Capital Group,""$11,500"",""$4,000"",""$7,500"",2018
-Arkema Inc,France/Arkema,""$58,500"",""$26,000"",""$32,500"",2018
-Ash Grove (CRH Plc),Ireland/CRH PLC,""$44,500"",$0,""$44,500"",2018
-Ashta Chemicals,Mexico/Bigshire Mexico,$0,$0,$0,2018
-Ashton Woods Corp,Canada/Great Gulf Group,""$2,500"",$0,""$2,500"",2018
-Assured Guaranty Municipal Corp (Assured Guaranty US Holdings),UK/Assured Guaranty Ltd,""$2,700"",$0,""$2,700"",2018
-Astellas US,Japan/Astellas Pharma,""$185,700"",""$75,000"",""$110,700"",2018
-AstraZeneca Pharmaceuticals (AstraZeneca PLC),UK/AstraZeneca PLC,""$358,500"",""$136,500"",""$222,000"",2018
-Atkins North America,UK/WS Atkins PLC,""$9,000"",$0,""$9,000"",2018
-Austal USA,Australia/Austal,""$45,600"",""$11,100"",""$34,500"",2018
-Avangrid Inc (Iberdrola SA),Spain/Iberdrola SA,""$109,500"",""$65,000"",""$41,000"",2018
-AXA Equitable Life Insurance (AXA),France/AXA,""$121,500"",""$39,500"",""$82,000"",2018
-Bacardi USA,UK/Bacardi Ltd,""$46,000"",""$20,500"",""$24,500"",2018
-BAE Systems (BAE Systems),UK/BAE Systems,""$611,500"",""$229,000"",""$378,500"",2018
-Barclays Group US,UK/Barclays plc,""$208,238"",""$80,500"",""$124,738"",2018
-Barrick Goldstrike Mines,Canada/Barrick Gold Corp,""$63,000"",""$31,000"",""$32,000"",2018
-BASF Corp,Germany/BASF SE,""$641,375"",""$304,125"",""$337,250"",2018
-Bayer Corp (Bayer AG),Germany/Bayer AG,""$277,000"",""$85,500"",""$191,500"",2018
-BBVA Compass,Spain/Banco Bilbao Vizcaya Argentaria,""$253,500"",""$71,500"",""$182,000"",2018
-Beam Suntory (Suntory Holdings),Japan/Suntory Holdings,""$29,070"",""$4,000"",""$25,070"",2018
-BMO Financial Corp (Bank of Montreal),Canada/Bank of Montreal,""$106,984"",""$42,500"",""$64,484"",2018
-BMO Financial Corp (Bank of Montreal),Canada/Bank of Montreal,$0,$0,$0,2018
-Boehringer Ingelheim Corp,Germany/CH Boehringer Sohn,""$123,500"",""$61,500"",""$62,000"",2018
-Bombardier Transportation USA (Bombardier Inc),Canada/Bombardier Inc,""$40,500"",""$20,500"",""$20,000"",2018
-BP,UK/BP PLC,""$359,000"",""$122,500"",""$236,500"",2018
-Bridgestone Americas,Japan/Bridgestone Corp,""$28,000"",""$6,000"",""$22,000"",2018
-Bumble Bee Foods,UK/Lion Capital,""$8,000"",""$2,000"",""$6,000"",2018
-""Burson, Cohn & Wolfe (WPP Group)"",UK/WPP Group,""$41,250"",""$16,750"",""$24,000"",2018
-Buzzi Unicem USA (Buzzi Unicem SpA),Italy/Buzzi Unicem SpA,$0,$0,$0,2018
-CalPortland Co,Japan/Taiheiyo Cement Co,""$103,500"",""$6,000"",""$97,500"",2018
-Cardtronics Inc,UK/Cardtronics Plc,""$2,500"",$0,""$2,500"",2018
-Carmeuse Lime,Netherlands/Carmeuse Holding SA,$0,$0,$0,2018
-Case New Holland,Netherlands/CNH Global,""$92,000"",""$8,000"",""$84,000"",2018
-CEMEX Inc,Mexico/CEMEX SA de CV,""$288,500"",""$48,000"",""$240,500"",2018
-CGI Technologies & Solutions,Canada/Groupe CGI,""$44,500"",""$20,500"",""$24,000"",2018
-Chicago Bridge & Iron (McDermott International),Panama/McDermott International,""$92,500"",""$24,500"",""$68,000"",2018
-Chubb Group of Insurance Companies,Switzerland/Chubb Ltd,""$205,000"",""$79,000"",""$126,000"",2018
-CIBC Bancorp,Canada/Canadian Imperial Bank of Commerce,""$2,000"",$0,""$2,000"",2018
-Cirrus Aircraft Corp,China/China Aviation Industry General Aircraft,""$6,000"",""$2,000"",""$4,000"",2018
-CMOC Mining USA (China Molybdenum Co),China/China Molybdenum Co,""$1,500"",$0,""$1,500"",2018
-Cobham Management Services,UK/Cobham PLC,""$176,500"",""$57,500"",""$119,000"",2018
-Commonwealth-Altadis (Imperial Brands),UK/Imperial Tobacco Group,$0,$0,$0,2018
-Continental Automotive Systems (Continental AG),Germany/Continental AG,""$125,000"",""$50,500"",""$74,500"",2018
-Covestro LLC (Covestro AG),Germany/Covestro AG,""$35,000"",""$9,500"",""$25,500"",2018
-Credit Suisse Securities,Switzerland/Credit Suisse Group,""$364,000"",""$187,500"",""$176,500"",2018
-CRH Americas (CRH PLC),Ireland/CRH PLC,""$475,250"",""$150,000"",""$325,250"",2018
-CSL Behring,Australia/CSL Ltd,""$83,500"",""$23,000"",""$60,500"",2018
-Daiichi Sankyo Inc,Japan/Daiichi Sanyko,""$76,500"",""$30,000"",""$46,500"",2018
-Daimler Trucks North America (Daimler AG),Germany/Daimler AG,""$4,000"",""$2,000"",""$2,000"",2018
-Delhaize America,Belgium/Ahold Delhaize,""$20,750"",""$6,250"",""$12,000"",2018
-Deutsche Bank Securities,Germany/Deutsche Bank AG,""$16,500"",""$5,000"",""$11,500"",2018
-DHL (Deutsche Post AG),Germany/Deutsche Post AG,$0,$0,$0,2018
-Diageo North America (Diageo PLC),UK/Diageo PLC,""$58,585"",""$33,321"",""$25,264"",2018
-Direct Energy Inc,UK/Centrica Plc,""$33,500"",""$9,000"",""$24,500"",2018
-Eaton Corp (Eaton Corp),Ireland/Eaton Plc,""$58,000"",""$9,000"",""$49,000"",2018
-EDF Renewables (EDF Group),France/EDF Group,""$34,000"",""$11,500"",""$22,500"",2018
-EDP Renewables NA,Portugal/EDP Renovaveis,""$21,500"",""$8,500"",""$11,500"",2018
-Eisai Inc,Japan/Eisai Co Ltd,""$29,000"",""$13,000"",""$16,000"",2018
-Elbit Systems of America,Israel/Elbit Systems Ltd,""$79,500"",""$13,500"",""$66,000"",2018
-Elekta Inc (Elekta AB),Sweden/Elekta AB,""$48,000"",""$23,500"",""$24,500"",2018
-Embraer Aircraft Holdings,Brazil/Embraer-Empresa Brasileira de Aeronautic,""$40,000"",""$8,500"",""$31,500"",2018
-EMD Serono Inc,Germany/Merck KGaA,""$169,000"",""$84,000"",""$85,000"",2018
-Enbridge Inc,Canada/Enbridge Inc,""$122,200"",""$21,500"",""$94,200"",2018
-EnCana Oil & Gas USA,Canada/EnCana Corp,""$24,500"",""$7,000"",""$17,500"",2018
-Endo Pharmaceuticals,Ireland/Endo International,""$89,500"",""$27,000"",""$62,500"",2018
-ENGIE North America,France/ENGIE,""$4,500"",""$1,000"",""$2,500"",2018
-Ericsson Inc,Sweden/Telefonaktiebolaget LM Ericsson,""$12,500"",""$2,000"",""$10,500"",2018
-Experian,UK/Experian plc,""$554,500"",""$189,000"",""$365,500"",2018
-Farmers Group (Zurich Insurance Group),Switzerland/Zurich Financial Services AG,""$356,200"",""$103,000"",""$253,200"",2018
-First Hawaiian Bank (BNP Paribas),France/BNP Paribas,""$1,000"",""$1,000"",$0,2018
-Florida East Coast Industries (SoftBank Corp),Japan/SoftBank Corp,""$79,000"",""$20,500"",""$58,500"",2018
-Florida East Coast Railway (Grupo Mexico),Mexico/Grupo Mexico,""$8,780"",""$3,640"",""$5,140"",2018
-FMC Technologies,UK/TechnipFMC plc,""-$3,000"",$0,""-$3,000"",2018
-Framatome (EDF Group),France/EDF Group,""$50,500"",""$20,000"",""$30,500"",2018
-Fresenius Medical Care North America,Germany/Fresenius Medical Care,""$323,000"",""$149,000"",""$174,000"",2018
-G4S Secure Solutions,UK/G4S plc,""$15,000"",""$5,000"",""$10,000"",2018
-Garmin International (Garmin Ltd),Switzerland/Garmin Ltd,""$37,400"",""$10,500"",""$26,900"",2018
-GE Appliances,China/Haier Group,""$24,000"",""$4,500"",""$19,500"",2018
-Genentech Inc (Roche Holdings),Switzerland/Roche Holdings,""$573,000"",""$232,000"",""$341,000"",2018
-General Cigar Co,Sweden/Scandinavian Tobacco Group,$0,$0,$0,2018
-Gerdau Ameristeel Corp,Brazil/Gerdau,""$8,500"",""$5,000"",""$3,500"",2018
-Glanbia Foods,Ireland/Glanbia PLC,$750,$0,$750,2018
-GlaxoSmithKline,UK/GlaxoSmithKline,""$322,750"",""$138,500"",""$184,250"",2018
-Glover Park Group (WPP Group),UK/WPP Group,""$143,200"",""$94,700"",""$48,000"",2018
-Grand Trunk Western-Illinois Central RR,Canada/Canadian National Railway,""$12,500"",$0,""$12,500"",2018
-Great-West Life & Annuity Insurance (Power Financial Corp),Canada/Power Financial Corp,""$1,500"",$0,""$1,500"",2018
-Greyhound Lines,UK/FirstGroup PLC,""$17,500"",""$8,500"",""$9,000"",2018
-Headwaters Inc,Australia/Boral Ltd,""$14,507"",$1,""$14,506"",2018
-Heineken USA,Netherlands/L'Arche Green NV,""$47,750"",""$21,250"",""$26,500"",2018
-Herbalife Nutrition,UK/Herbalife Ltd,""$149,219"",""$67,519"",""$81,700"",2018
-Hoffmann-La Roche (Roche Holdings),Switzerland/Roche Holdings,""$55,500"",""$16,500"",""$39,000"",2018
-Horizon Pharma USA,Ireland/Horizon Pharma PLC,""$81,200"",""$42,700"",""$38,500"",2018
-HSBC North America (HSBC Holdings),UK/HSBC Holdings,""$164,000"",""$76,500"",""$87,500"",2018
-HSBC North America (HSBC Holdings),UK/HSBC Holdings,""$1,000"",$0,""$1,000"",2018
-IDEMIA Identity & Security (IDEMIA),France/Safran SA,""$30,456"",""$7,500"",""$22,956"",2018
-Infineon Technologies,Germany/Infineon Technologies AG,""$2,000"",""$1,000"",""$1,000"",2018
-Ingersoll-Rand,Ireland/Ingersoll Rand Co,""$33,500"",""$13,100"",""$20,400"",2018
-Intelsat Holdings (Serafina SA),Luxembourg/Intelsat SA,""$45,500"",""$17,500"",""$28,000"",2018
-Intergraph Corp,Sweden/Hexagon AB,""$2,500"",$0,""$2,500"",2018
-International Game Technology,Italy/B&D Holding Di Marco Drago e C Sapa,""$65,500"",""$29,000"",""$36,500"",2018
-ITG Brands (Imperial Brands),UK/Imperial Brands,""$179,000"",""$28,000"",""$151,000"",2018
-Jackson National Life Insurance (Prudential PLC),UK/Prudential PLC,""$264,489"",""$66,500"",""$197,989"",2018
-Jackson National Life Insurance (Prudential PLC),UK/Prudential PLC,""$12,000"",""$5,000"",""$7,000"",2018
-JBS USA,Brazil/JBS SA,""$46,000"",""$2,000"",""$44,000"",2018
-John Hancock Life Insurance,Canada/Manulife Financial,""$118,200"",""$62,000"",""$55,200"",2018
-Johnson Controls (Johnson Controls International),Ireland/Johnson Controls International,""$240,500"",""$121,000"",""$117,500"",2018
-Johnson Controls (Johnson Controls International),Ireland/Johnson Controls International,""$1,000"",$0,""$1,000"",2018
-Kawasaki Heavy Industries,Japan/Kawasaki Heavy Industries,$500,$0,$500,2018
-Komatsu Mining,Japan/Komatsu Ltd,""$17,760"",""$1,000"",""$16,760"",2018
-LafargeHolcim (LafargeHolcim),Switzerland/LaFargeHolcim,""$106,000"",""$29,000"",""$77,000"",2018
-Lanxess Corp,Germany/Lanxess Corp,$250,$0,$250,2018
-Lehigh Hanson,Germany/HeidelbergCement AG,""$159,000"",""$13,500"",""$145,500"",2018
-Leonardo DRS,Italy/Finmeccanica SpA,""$198,500"",""$60,000"",""$138,500"",2018
-Lincare Holdings (Linde AG),Germany/Linde AG,""$3,000"",""$1,000"",""$2,000"",2018
-Linde North America (Linde AG),Germany/Linde AG,""$109,000"",""$43,500"",""$65,500"",2018
-Livanova Inc,UK/Livanova Plc,$0,$0,$0,2018
-Louis Dreyfus Co,Netherlands/Louis Dreyfus Holding B.V.,""$13,000"",$0,""$13,000"",2018
-LSEG US,UK/London Stock Exchange Group,""$16,500"",""$8,000"",""$8,500"",2018
-Lundbeck Inc,Denmark/H Lundbeck A/S,""$71,500"",""$33,500"",""$38,000"",2018
-M-E Companies,Canada/IBI Group,$0,$0,$0,2018
-Maersk Inc (AP Moller-Maersk),Denmark/AP M√∏ller-M√¶rsk,""$56,000"",""$25,500"",""$29,500"",2018
-Magna US,Canada/Magna International,$0,$0,$0,2018
-Magnolia LNG,Australia/LNG Limited,""$4,500"",$0,""$4,500"",2018
-Mallinckrodt Pharmaceuticals,UK/Mallinckrodt Plc,""$265,000"",""$105,000"",""$160,000"",2018
-Marinette Marine,Italy/Fincantieri-Cantieri Navali Italiani SpA,""$19,500"",""$6,000"",""$13,500"",2018
-Massachusetts Financial Services (Sun Life Financial),Canada/Sun Life Financial Services,""$23,246"",""$10,246"",""$13,000"",2018
-Maxar Technologies (Maxar Technologies),Canada/Maxar Technologies,""$113,500"",""$34,500"",""$76,500"",2018
-Maxar Technologies Holdings (Maxar Technologies),Canada/Maxar Tecxhnologies,""$7,000"",""$4,000"",""$3,000"",2018
-MBDA Inc,UK/MBDA,""$6,000"",$0,""$6,000"",2018
-Medimmune Inc (AstraZeneca PLC),UK/AstraZeneca PLC,$0,$0,$0,2018
-Medtronic Inc,Ireland/Medtronic Plc,""$293,000"",""$133,000"",""$159,000"",2018
-MillerCoors LLC (Anheuser-Busch InBev),Belgium/Anheuser-Busch InBev,""$163,000"",""$62,000"",""$101,000"",2018
-Miraca Life Sciences,Japan/Miraca Holdings,$0,$0,$0,2018
-Mitsubishi Hitachi Power Systems,Japan/Mitsubishi Hitachi Power Systems,""$23,400"",$0,""$23,400"",2018
-Monsanto Co (Bayer AG),Germany/Bayer AG,""$349,500"",""$114,500"",""$235,000"",2018
-Mr Cooper Group (SoftBank Corp),Japan/SoftBank Corp,""$32,760"",""$11,000"",""$21,760"",2018
-Munich American Reassurance,Germany/Munich Re Group,$0,$0,$0,2018
-Mylan Inc,Netherlands/Mylan NV,""$83,000"",""$33,500"",""$49,500"",2018
-Nammo Talley Inc,Norway/Nammo AS,""$19,500"",""$4,500"",""$15,000"",2018
-National Cement Co,France/Vicat Group,""$1,000"",$0,""$1,000"",2018
-National Grid USA (National Grid plc),UK/National Grid plc,""$63,000"",""$47,000"",""$16,000"",2018
-Natixis Investment Managers,France/Groupe BPCE,""$18,500"",""$10,500"",""$8,000"",2018
-Nestle Purina PetCare (Nestle SA),Switzerland/Nestle,""$23,750"",""$9,750"",""$14,000"",2018
-Nomura Holding America,Japan/Nomura Holdings,""$113,500"",""$48,000"",""$65,500"",2018
-NOVA Chemicals,United Arab Emirates/International Petroleum Investment Co,$0,$0,$0,2018
-Novartis Corp (Novartis AG),Switzerland/Novartis AG,""$293,000"",""$166,000"",""$127,000"",2018
-Novo Nordisk,Denmark/Novo Nordisk A/S,""$405,938"",""$188,000"",""$217,938"",2018
-Novocure Inc,UK/Novocure,""$52,200"",""$6,700"",""$45,500"",2018
-Nutrien Ltd,Canada/Nutrien Ltd,""$8,000"",$0,""$8,000"",2018
-Orano USA (Orano Group),France/Orano Group,""$11,000"",""$2,500"",""$8,500"",2018
-Otsuka America (Otsuka Pharmaceutical),Japan/Otsuka Pharmaceutical,""$83,000"",""$45,000"",""$38,000"",2018
-Patheon Pharmaceuticals,Netherlands/Patheon NV,""$10,574"",$0,""$10,574"",2018
-Permobil Inc (Investor AB),Sweden/Investor AB,""$8,500"",""$1,000"",""$7,500"",2018
-Pernod Ricard USA,France/Pernod Ricard SA,""$23,700"",""$3,000"",""$20,700"",2018
-Peter Pan Seafoods,Japan/Maruha Nichiro Holdings,""$1,500"",$0,""$1,500"",2018
-Pharmavite LLC (Otsuka Pharmaceutical),Japan/Otsuka Pharmaceutical,""$81,000"",""$41,000"",""$40,000"",2018
-Philips Electronics North America (Philips),Netherlands/Philips Electronics,""$66,000"",""$33,000"",""$33,000"",2018
-Protective Life Corp (Dai-Ichi Life),Japan/Dai-Ichi Life,""$64,500"",""$17,700"",""$46,800"",2018
-Putnam Investments (Power Financial Corp),Canada/Power Financial Corp,""$8,941"",$0,""$8,941"",2018
-RBC Bank (Royal Bank of Canada),Canada/Royal Bank of Canada,""$59,500"",""$35,000"",""$24,500"",2018
-Recurrent Energy,Canada/Canadian Solar,""$2,000"",""$1,000"",""$1,000"",2018
-RELX Inc,UK/RELX Group,""$207,600"",""$98,500"",""$109,100"",2018
-Renewable Energy Systems Americas,UK/Renewable Energy Systems,""$15,051"",""$1,000"",""$13,551"",2018
-Resolute Forest Products,Canada/Resolute Forest Products,""$80,700"",""$12,200"",""$67,500"",2018
-Reynolds American (British American Tobacco),UK/British American Tobacco plc,""$385,000"",""$34,000"",""$351,000"",2018
-Rio Tinto America,UK/Rio Tinto Group,""$12,500"",""$4,500"",""$8,000"",2018
-Roho Group (Investor AB),Sweden/Investor AB,$500,$500,$0,2018
-Rolls-Royce North America (Rolls-Royce PLC),UK/Rolls-Royce PLC,""$303,500"",""$78,500"",""$225,000"",2018
-Safelite Group,Belgium/D'Ieteren SA,""$5,700"",""$1,000"",""$4,700"",2018
-Samsung Electronics America,South Korea/Samsung Group,""$143,000"",""$72,500"",""$70,500"",2018
-Sanofi US (Sanofi),France/Sanofi,""$443,200"",""$208,700"",""$234,500"",2018
-Santander Bank (Banco Santander),Spain/Banco Santander,""$24,500"",""$9,500"",""$15,000"",2018
-SAP America,Germany/SAP Aktiengesellschaft,""$59,000"",""$40,000"",""$19,000"",2018
-Schaeffler Group USA,Germany/Schaeffler Group,""$2,500"",$0,""$2,500"",2018
-Securitas Security Services USA,Sweden/Securitas AB,$0,$0,$0,2018
-Serco Inc,UK/Serco Group,""$107,500"",""$40,500"",""$67,000"",2018
-Shell Oil,Netherlands/Royal Dutch-Shell Group,""$23,000"",""$3,500"",""$19,500"",2018
-Shire Holdings US (Shire PLC),Ireland/Shire Plc,""$84,000"",""$47,000"",""$37,000"",2018
-Siemens Corp,Germany/Siemens AG,""$189,250"",""$76,000"",""$113,250"",2018
-Smith & Nephew,UK/Smith & Nephew Plc,""$81,000"",""$36,000"",""$45,000"",2018
-Smithfield Foods,China/WH Group,""$61,000"",""$21,000"",""$40,000"",2018
-Smiths Detection (Smiths Group),UK/Smiths Group PLC,$0,$0,$0,2018
-Smiths Group Services Corp (Smiths Group),UK/Smiths Group PLC,""$134,700"",""$36,500"",""$98,200"",2018
-Sodexo Inc,France/Sodexo,""-$1,000"",$0,""-$1,000"",2018
-Solvay America,Belgium/Solvay SA,""$19,200"",""$8,000"",""$11,200"",2018
-Sony Pictures Entertainment (Sony Corp),Japan/Sony Corp,""$164,000"",""$85,000"",""$79,000"",2018
-Sprint Corp (SoftBank Corp),Japan/Softbank Corp,""$184,000"",""$73,500"",""$110,500"",2018
-SSAB Americas,Sweden/SSAB AB,""$13,600"",""$4,500"",""$9,100"",2018
-Standard Insurance Co,Japan/Meiji Yasuda Life Insurance,""$10,000"",""$1,000"",""$7,500"",2018
-Steris Corp,UK/Steris PLC,""$51,000"",""$16,500"",""$34,500"",2018
-SUEZ Water,France/SUEZ Environnement,""$11,000"",""$10,000"",""$1,000"",2018
-Sun Life Financial (Sun Life Financial),Canada/Sun Life Financial,""$23,600"",""$8,900"",""$12,000"",2018
-Sunovion Pharmaceuticals (Sumitomo Chemical),Japan/Sumitomo Chemical,""$50,500"",""$26,000"",""$24,500"",2018
-Sunpower Corp,France/Total SA,""$7,000"",""$2,000"",""$5,000"",2018
-Swedish Match North America (Swedish Match AB),Sweden/Swedish Match AB,""$13,500"",""$2,500"",""$11,000"",2018
-Swiss Re America,Switzerland/Swiss Re,""$48,000"",""$19,000"",""$29,000"",2018
-Syngenta Corp,China/ChemChina,""$125,200"",""$47,500"",""$77,700"",2018
-T-Mobile USA,Germany/Deutsche Telekom AG,""$694,500"",""$314,000"",""$374,500"",2018
-Takeda Pharmaceuticals USA (Takeda Pharmaceutical Co),Japan/Takeda Pharmaceutical Co,""$143,500"",""$77,500"",""$66,000"",2018
-Tate & Lyle Americas (Tate & Lyle),UK/Tate & Lyle,""$26,900"",""$7,000"",""$19,900"",2018
-TD Bank USA,Canada/Toronto-Dominion Bank,""$197,500"",""$91,500"",""$101,000"",2018
-TE Connectivity,Switzerland/TE Connectivity,""$94,000"",""$34,000"",""$60,000"",2018
-Terumo BCT,Japan/Terumo Corp,$0,$0,$0,2018
-Teva Pharmaceuticals USA,Israel/Teva Pharmaceutical Industries,""$45,500"",""$17,000"",""$28,500"",2018
-Toyota Motor North America,Japan/Toyota Motor Corp,""$874,999"",""$378,000"",""$496,999"",2018
-TransAmerica,Netherlands/Aegon NV,""$458,500"",""$226,500"",""$230,000"",2018
-Transcanada USA Services (Transcanada Corp),Canada/TransCanada Corp,""$149,500"",""$51,500"",""$94,500"",2018
-Travelport Inc,UK/Travelport Ltd,""$1,000"",$0,""$1,000"",2018
-UBS Americas,Switzerland/UBS AG,""$1,404,750"",""$650,750"",""$744,000"",2018
-UCB Inc (UCB SA),Belgium/UCB SA,""$50,500"",""$7,500"",""$43,000"",2018
-Ultra Electronics USA,UK/Ultra Electronics,""$59,000"",""$15,000"",""$44,000"",2018
-UnionBanCal Corp,Japan/Bank of Tokyo,""$5,000"",""$5,000"",$0,2018
-Universal Music Group (Vivendi),France/Vivendi,""$114,494"",""$64,494"",""$50,000"",2018
-Valent USA (Sumitomo Chemical),Japan/Sumitomo Chemical,""$16,000"",""$5,500"",""$10,500"",2018
-VNA Holding (AB Volvo),Sweden/AB Volvo,""$16,000"",""$8,000"",""$8,000"",2018
-VT Halter Marine,Singapore/ST Engineering,""$12,500"",$0,""$12,500"",2018
-Washington Gas Light Co (AltaGas Ltd),Canada/AltaGas Ltd,""$21,000"",""$13,000"",""$8,000"",2018
-Westfield Corp (Unibail-Rodamco-Westfield),Australia/Westfield Group of Australia,""$4,000"",""$1,500"",""$2,500"",2018
-Westinghouse Electric,Canada/Brookfield Business Partners,""$68,500"",""$25,000"",""$43,500"",2018
-Wexler & Walker Public Policy Assoc (WPP Group),UK/WPP Group,""$45,000"",""$15,500"",""$29,500"",2018
-WSP worldwide,Canada/WSP Global,""$151,724"",""$86,650"",""$65,074"",2018
-XL America,Ireland/XL Group PLC,$0,$0,$0,2018
-ZF TRW Automotive (ZF Friedrichshafen AG),Germany/ZF Friedrichshafen AG,""$30,000"",""$14,000"",""$16,000"",2018
-Zurich Insurance (Zurich Insurance Group),Switzerland/Zurich Financial Services AG,""$173,000"",""$92,500"",""$80,500"",2018

---FILE: course-materials/hw-instructions/hw-05/data/pac-2020-fn.csv---
@@ -1,216 +0,0 @@
-name,country_parent,total,dems,repubs,year
-ABB Group (ABB Group),Switzerland/Asea Brown Boveri,""$1,000"",""$1,000"",$0,2020
-Accenture (Accenture),Ireland/Accenture plc,""$75,500"",""$46,000"",""$29,500"",2020
-Advance America Cash Advance Centers (Grupo Salinas),Mexico/Grupo Salinas,""$3,000"",""$1,000"",""$2,000"",2020
-Air Liquide America,France/L'Air Liquide SA,""$11,500"",""$5,000"",""$6,500"",2020
-Airbus Group,Netherlands/Airbus Group,""$79,000"",""$26,500"",""$52,500"",2020
-Alkermes Inc,Ireland/Alkermes Plc,""$40,250"",""$11,250"",""$29,000"",2020
-Allergan PLC (Allergan PLC),Ireland/Allergan PLC,""$98,500"",""$6,000"",""$92,500"",2020
-Allianz of America (Allianz),Germany/Allianz AG Holding,""$34,500"",""$16,100"",""$18,400"",2020
-Anheuser-Busch (Anheuser-Busch InBev),Belgium/Anheuser-Busch InBev,""$218,500"",""$109,000"",""$109,500"",2020
-AON Corp (AON plc),UK/AON PLC,""$29,500"",""$14,000"",""$15,500"",2020
-APL Maritime (CMA CGM),France/CMA CGM SA,""$14,000"",""$8,500"",""$5,500"",2020
-Arcadis US (Arcadis NV),Netherlands/Arcadis NV,$0,$0,$0,2020
-ArcelorMittal USA,Luxembourg/ArcelorMittal,""$21,500"",""$4,000"",""$17,500"",2020
-Arch Capital Group (US),UK/Arch Capital Group,""$7,000"",""$3,500"",""$3,500"",2020
-Arkema Inc,France/Arkema,""$43,500"",""$17,000"",""$26,500"",2020
-Ash Grove (CRH Plc),Ireland/CRH PLC,$0,$0,$0,2020
-Ashton Woods Corp,Canada/Great Gulf Group,$0,$0,$0,2020
-Assured Guaranty Municipal Corp (Assured Guaranty US Holdings),UK/Assured Guaranty Ltd,""$67,500"",""$38,100"",""$29,400"",2020
-Astellas US,Japan/Astellas Pharma,""$40,000"",""$29,000"",""$11,000"",2020
-AstraZeneca Pharmaceuticals (AstraZeneca PLC),UK/AstraZeneca PLC,""$115,500"",""$53,500"",""$62,000"",2020
-Atkins North America,UK/WS Atkins PLC,""$9,700"",$0,""$9,700"",2020
-Austal USA,Australia/Austal,""$6,200"",""$2,700"",""$3,500"",2020
-Avangrid Inc (Iberdrola SA),Spain/Iberdrola SA,""$27,000"",""$10,500"",""$14,000"",2020
-AXA Equitable Life Insurance (AXA),France/AXA,""$41,000"",""$13,500"",""$27,500"",2020
-Bacardi USA,UK/Bacardi Ltd,""$11,500"",""$4,500"",""$6,000"",2020
-BAE Systems (BAE Systems),UK/BAE Systems,""$301,000"",""$147,000"",""$154,000"",2020
-Barclays Group US,UK/Barclays plc,""$18,000"",""$8,000"",""$10,000"",2020
-Barrick Goldstrike Mines,Canada/Barrick Gold Corp,""$11,000"",""$6,500"",""$4,500"",2020
-BASF Corp,Germany/BASF SE,""$126,500"",""$57,500"",""$69,000"",2020
-Bayer Corp (Bayer AG),Germany/Bayer AG,""$103,000"",""$41,500"",""$61,500"",2020
-Bayer CropScience (Bayer AG),Germany/Bayer AG,""-$4,500"",""-$4,500"",$0,2020
-BBVA USA,Spain/Banco Bilbao Vizcaya Argentaria,""$154,500"",""$44,000"",""$110,500"",2020
-Beam Suntory (Suntory Holdings),Japan/Suntory Holdings,""$14,331"",""$9,500"",""$4,831"",2020
-BMO Financial Corp (Bank of Montreal),Canada/Bank of Montreal,$0,$0,$0,2020
-BMO Financial Corp (Bank of Montreal),Canada/Bank of Montreal,""$80,300"",""$37,800"",""$42,500"",2020
-Boehringer Ingelheim Corp,Germany/CH Boehringer Sohn,""$48,500"",""$23,000"",""$25,500"",2020
-Bombardier Transportation USA (Bombardier Inc),Canada/Bombardier Inc,""$27,500"",""$17,500"",""$10,000"",2020
-BP,UK/BP PLC,""$104,500"",""$28,000"",""$76,500"",2020
-Bridgestone Americas,Japan/Bridgestone Corp,""$7,500"",""$2,500"",""$5,000"",2020
-Bumble Bee Foods,UK/Lion Capital,""$1,000"",""$1,000"",$0,2020
-""Burson, Cohn & Wolfe (WPP Group)"",UK/WPP Group,""$21,000"",""$8,500"",""$12,500"",2020
-Buzzi Unicem USA (Buzzi Unicem SpA),Italy/Buzzi Unicem SpA,$500,$0,$500,2020
-CalPortland Co,Japan/Taiheiyo Cement Co,""$30,000"",""$10,000"",""$20,000"",2020
-Cardtronics Inc,UK/Cardtronics Plc,$0,$0,$0,2020
-Carmeuse Lime,Netherlands/Carmeuse Holding SA,$0,$0,$0,2020
-Case New Holland,Netherlands/CNH Global,""$36,500"",""$1,500"",""$35,000"",2020
-CEMEX Inc,Mexico/CEMEX SA de CV,""$56,000"",""$23,500"",""$32,500"",2020
-CGI Technologies & Solutions,Canada/Groupe CGI,""$12,500"",""$7,500"",""$5,000"",2020
-Chicago Bridge & Iron (McDermott International),Panama/McDermott International,""$5,470"",$470,""$5,000"",2020
-Chubb Group of Insurance Companies,Switzerland/Chubb Ltd,""$76,000"",""$28,500"",""$47,500"",2020
-CIBC Bancorp,Canada/Canadian Imperial Bank of Commerce,""$3,000"",""$2,000"",""$1,000"",2020
-Cirrus Aircraft Corp,China/China Aviation Industry General Aircraft,""$1,500"",""$1,500"",$0,2020
-Cobham Management Services,UK/Cobham PLC,""$64,000"",""$13,500"",""$50,500"",2020
-Continental Automotive Systems (Continental AG),Germany/Continental AG,""$17,500"",""$8,500"",""$9,000"",2020
-Covestro LLC (Covestro AG),Germany/Covestro AG,""$17,500"",""$2,000"",""$15,500"",2020
-Credit Suisse Securities,Switzerland/Credit Suisse Group,""$22,000"",""$6,000"",""$16,000"",2020
-CRH Americas (CRH PLC),Ireland/CRH PLC,""$236,500"",""$56,500"",""$180,000"",2020
-CSL Behring,Australia/CSL Ltd,""$30,000"",""$13,500"",""$16,500"",2020
-Daimler Trucks North America (Daimler AG),Germany/Daimler AG,""$2,500"",$0,""$2,500"",2020
-Delhaize America,Belgium/Ahold Delhaize,""$3,500"",""$1,000"",""$2,500"",2020
-Deutsche Bank Securities,Germany/Deutsche Bank AG,$0,$0,$0,2020
-Diageo North America (Diageo PLC),UK/Diageo PLC,""$20,108"",""$11,060"",""$9,048"",2020
-Direct Energy Inc,UK/Centrica Plc,$0,$0,$0,2020
-Eaton Corp (Eaton Corp),Ireland/Eaton Plc,""$13,000"",""$4,500"",""$8,500"",2020
-EDF Renewables (EDF Group),France/EDF Group,""$8,000"",""$4,500"",""$3,500"",2020
-EDP Renewables NA,Portugal/EDP Renovaveis,""$9,000"",""$4,000"",""$5,000"",2020
-Eisai Inc,Japan/Eisai Co Ltd,""$2,500"",""$2,500"",$0,2020
-Elbit Systems of America,Israel/Elbit Systems Ltd,""$34,600"",""$6,600"",""$28,000"",2020
-Elekta Inc (Elekta AB),Sweden/Elekta AB,""$27,500"",""$12,000"",""$15,500"",2020
-Embraer Aircraft Holdings,Brazil/Embraer-Empresa Brasileira de Aeronautic,""$18,000"",""$5,000"",""$13,000"",2020
-EMD Serono Inc,Germany/Merck KGaA,""$53,500"",""$28,500"",""$25,000"",2020
-Enbridge Inc,Canada/Enbridge Inc,""$12,500"",""$4,500"",""$8,000"",2020
-EnCana Oil & Gas USA (EnCana Corp),Canada/EnCana Corp,""$19,500"",""$5,000"",""$14,500"",2020
-Endo Pharmaceuticals,Ireland/Endo International,$0,$0,$0,2020
-ENGIE North America,France/ENGIE,$0,$0,$0,2020
-Ericsson Inc,Sweden/Telefonaktiebolaget LM Ericsson,""$10,500"",""$5,000"",""$5,500"",2020
-Experian,UK/Experian plc,""$264,500"",""$119,500"",""$145,000"",2020
-Farmers Group (Zurich Insurance Group),Switzerland/Zurich Financial Services AG,""$83,500"",""$32,500"",""$51,000"",2020
-First Hawaiian Bank (BNP Paribas),France/BNP Paribas,$0,$0,$0,2020
-Florida East Coast Industries (SoftBank Corp),Japan/SoftBank Corp,""$34,000"",""$13,500"",""$20,500"",2020
-Florida East Coast Railway (Grupo Mexico),Mexico/Grupo Mexico,$500,$500,$0,2020
-Framatome (EDF Group),France/EDF Group,""$16,000"",""$14,000"",""$2,000"",2020
-Fresenius Medical Care North America,Germany/Fresenius Medical Care,""$169,500"",""$93,500"",""$76,000"",2020
-G4S Secure Solutions,UK/G4S plc,$0,$0,$0,2020
-Garmin International (Garmin Ltd),Switzerland/Garmin Ltd,""$7,000"",$0,""$7,000"",2020
-GE Appliances,China/Haier Group,""$8,500"",""$5,000"",""$3,500"",2020
-Genentech Inc (Roche Holdings),Switzerland/Roche Holdings,""$215,000"",""$97,500"",""$117,500"",2020
-General Cigar Co,Sweden/Scandinavian Tobacco Group,$0,$0,$0,2020
-Gerdau Ameristeel Corp,Brazil/Gerdau,""$2,000"",$0,""$2,000"",2020
-Glanbia Foods,Ireland/Glanbia PLC,$0,$0,$0,2020
-GlaxoSmithKline,UK/GlaxoSmithKline,""$76,000"",""$30,000"",""$46,000"",2020
-Glover Park Group (WPP Group),UK/WPP Group,""$58,700"",""$43,200"",""$15,500"",2020
-Grand Trunk Western-Illinois Central RR,Canada/Canadian National Railway,""$4,000"",$0,""$4,000"",2020
-Great-West Life & Annuity Insurance (Power Financial Corp),Canada/Power Financial Corp,$0,$0,$0,2020
-Greyhound Lines,UK/FirstGroup PLC,""$7,500"",""$6,500"",""$1,000"",2020
-Headwaters Inc,Australia/Boral Ltd,""$10,000"",$0,""$10,000"",2020
-Heineken USA,Netherlands/L'Arche Green NV,""$20,500"",""$11,500"",""$9,000"",2020
-Herbalife Nutrition,UK/Herbalife Ltd,""$49,000"",""$32,000"",""$17,000"",2020
-Horizon Therapeutics,Ireland/Horizon Pharma PLC,""$31,000"",""$7,500"",""$23,500"",2020
-HSBC North America (HSBC Holdings),UK/HSBC Holdings,""$60,000"",""$7,500"",""$52,500"",2020
-HSBC North America (HSBC Holdings),UK/HSBC Holdings,""$1,000"",$0,""$1,000"",2020
-IBI Group Engineering Services,Canada/IBI Group,$0,$0,$0,2020
-IDEMIA Identity & Security (IDEMIA),France/Safran SA,""$6,000"",""$2,500"",""$3,500"",2020
-Infineon Technologies,Germany/Infineon Technologies AG,""$7,500"",""$5,500"",""$2,000"",2020
-Ingersoll-Rand,Ireland/Ingersoll Rand Co,""$2,000"",$0,""$2,000"",2020
-Intelsat Holdings (Serafina SA),Luxembourg/Intelsat SA,""$1,500"",$0,""$1,500"",2020
-International Game Technology,Italy/B&D Holding Di Marco Drago e C Sapa,""$16,000"",""$10,000"",""$6,000"",2020
-ITG Brands,UK/Imperial Brands,$0,$0,$0,2020
-Jackson National Life Insurance (Prudential PLC),UK/Prudential PLC,""$40,000"",""$3,500"",""$36,500"",2020
-Jackson National Life Insurance (Prudential PLC),UK/Prudential PLC,""$98,000"",""$33,000"",""$65,000"",2020
-JBS USA,Brazil/JBS SA,""$16,000"",""$2,000"",""$14,000"",2020
-John Hancock Life Insurance,Canada/Manulife Financial,""$47,900"",""$28,500"",""$19,400"",2020
-Johnson Controls (Johnson Controls International),Ireland/Johnson Controls International,""$139,900"",""$68,900"",""$71,000"",2020
-Komatsu Mining,Japan/Komatsu Ltd,""$16,500"",$0,""$16,500"",2020
-LafargeHolcim (LafargeHolcim),Switzerland/LaFargeHolcim,""$30,000"",""$3,500"",""$26,500"",2020
-Lanxess Corp,Germany/Lanxess Corp,""$1,000"",$500,$500,2020
-Lehigh Hanson,Germany/HeidelbergCement AG,""$38,500"",""$7,500"",""$31,000"",2020
-Leonardo DRS,Italy/Finmeccanica SpA,""$46,000"",""$23,000"",""$23,000"",2020
-Lincare Holdings (Linde plc),UK/Linde plc,""$4,500"",$0,""$4,500"",2020
-Linde North America (Linde plc),UK/Linde plc,$0,$0,$0,2020
-Linde plc (Linde plc),UK/Linde Plc,""$7,000"",""$6,000"",""$1,000"",2020
-Livanova Inc,UK/Livanova Plc,""$1,000"",$0,""$1,000"",2020
-Louis Dreyfus Co,Netherlands/Louis Dreyfus Holding B.V.,$0,$0,$0,2020
-LSEG US,UK/London Stock Exchange Group,""$18,000"",""$8,500"",""$9,500"",2020
-Lundbeck Inc,Denmark/H Lundbeck A/S,""$36,500"",""$18,500"",""$18,000"",2020
-Maersk Inc (AP Moller-Maersk),Denmark/AP M√∏ller-M√¶rsk,""$18,500"",""$11,500"",""$7,000"",2020
-Magnolia LNG,Australia/LNG Limited,$0,$0,$0,2020
-Mallinckrodt Pharmaceuticals,UK/Mallinckrodt Plc,""$31,000"",""$10,000"",""$21,000"",2020
-Marinette Marine,Italy/Fincantieri-Cantieri Navali Italiani SpA,""$9,500"",""$3,500"",""$6,000"",2020
-Massachusetts Financial Services (Sun Life Financial),Canada/Sun Life Financial Services,""$2,500"",$0,""$2,500"",2020
-Maxar Technologies (Maxar Technologies),Canada/Maxar Technologies,""$30,000"",""$9,000"",""$21,000"",2020
-MBDA Inc,UK/MBDA,$0,$0,$0,2020
-Medtronic Inc,Ireland/Medtronic Plc,""$97,500"",""$47,500"",""$50,000"",2020
-Messer North America,Germany/Messer Group,$0,$0,$0,2020
-MillerCoors LLC (Anheuser-Busch InBev),Belgium/Anheuser-Busch InBev,""$28,000"",""$10,500"",""$17,500"",2020
-Mitsubishi Hitachi Power Systems,Japan/Mitsubishi Hitachi Power Systems,""$1,000"",$0,""$1,000"",2020
-Mr Cooper Group (SoftBank Corp),Japan/SoftBank Corp,""$8,000"",""$2,000"",""$6,000"",2020
-Munich American Reassurance,Germany/Munich Re Group,""$5,000"",""$5,000"",$0,2020
-Mylan Inc,Netherlands/Mylan NV,""$109,500"",""$55,500"",""$54,000"",2020
-Nammo Talley Inc,Norway/Nammo AS,""$3,500"",""$1,000"",""$2,500"",2020
-National Grid USA (National Grid plc),UK/National Grid plc,""$12,800"",""$9,800"",""$3,000"",2020
-Natixis Investment Managers,France/Groupe BPCE,""$4,011"",""$1,000"",""$3,011"",2020
-Nestle Purina PetCare (Nestle SA),Switzerland/Nestle,""$2,000"",$0,""$2,000"",2020
-Nomura Holding America,Japan/Nomura Holdings,""$32,000"",""$22,500"",""$9,500"",2020
-NOVA Chemicals,United Arab Emirates/International Petroleum Investment Co,$0,$0,$0,2020
-Novartis Corp (Novartis AG),Switzerland/Novartis AG,""$131,500"",""$58,500"",""$73,000"",2020
-Novo Nordisk,Denmark/Novo Nordisk A/S,""$120,013"",""$60,927"",""$59,086"",2020
-Novocure Inc,UK/Novocure,""$26,800"",$0,""$26,800"",2020
-Nutrien Ag Solutions,Canada/Nutrien Ltd,""$8,500"",""$1,000"",""$7,500"",2020
-Orano USA (Orano Group),France/Orano Group,""$1,500"",$0,""$1,500"",2020
-Otsuka America (Otsuka Pharmaceutical),Japan/Otsuka Pharmaceutical,""$2,500"",$500,""$2,000"",2020
-Pernod Ricard USA,France/Pernod Ricard SA,""$2,000"",$0,""$2,000"",2020
-Peter Pan Seafoods,Japan/Maruha Nichiro Holdings,$0,$0,$0,2020
-Pharmavite LLC (Otsuka Pharmaceutical),Japan/Otsuka Pharmaceutical,""$24,000"",""$11,000"",""$13,000"",2020
-Philips Electronics North America (Philips),Netherlands/Philips Electronics,""$32,000"",""$17,000"",""$15,000"",2020
-Protective Life Corp (Dai-Ichi Life),Japan/Dai-Ichi Life,""$57,300"",""$10,000"",""$47,300"",2020
-Putnam Investments (Power Financial Corp),Canada/Power Financial Corp,""$5,237"",$0,""$5,237"",2020
-RBC Bank (Royal Bank of Canada),Canada/Royal Bank of Canada,""$11,000"",""$6,000"",""$5,000"",2020
-Recurrent Energy,Canada/Canadian Solar,$0,$0,$0,2020
-RELX Inc,UK/RELX Group,""$128,000"",""$50,000"",""$78,000"",2020
-Resolute Forest Products,Canada/Resolute Forest Products,""$20,500"",""$2,000"",""$18,500"",2020
-Reynolds American (British American Tobacco),UK/British American Tobacco plc,""$96,000"",""$31,000"",""$65,000"",2020
-Rio Tinto America,UK/Rio Tinto Group,""$3,500"",$0,""$3,500"",2020
-Roche Diagnostics (Roche Holdings),Switzerland/Roche Holdings,""$31,000"",""$10,500"",""$20,500"",2020
-Rolls-Royce North America (Rolls-Royce PLC),UK/Rolls-Royce PLC,""$114,500"",""$38,000"",""$76,500"",2020
-Safelite Group,Belgium/D'Ieteren SA,""-$3,000"",$0,""-$3,000"",2020
-Samsung Electronics America,South Korea/Samsung Group,""$63,500"",""$33,500"",""$30,000"",2020
-Sanofi US (Sanofi),France/Sanofi,""$128,500"",""$69,000"",""$59,500"",2020
-Santander Bank (Banco Santander),Spain/Banco Santander,""$45,500"",""$22,000"",""$23,500"",2020
-SAP America,Germany/SAP Aktiengesellschaft,""$6,000"",""$6,000"",$0,2020
-Securitas Security Services USA,Sweden/Securitas AB,$0,$0,$0,2020
-Serco Inc,UK/Serco Group,""$23,500"",""$13,500"",""$10,000"",2020
-Shell Oil,Netherlands/Royal Dutch-Shell Group,""$4,000"",$0,""$4,000"",2020
-Shire Holdings US (Takeda Pharmaceutical Co),Japan/Takeda Pharmaceutical Co,""-$12,500"",""-$1,500"",""-$11,000"",2020
-Siemens Corp,Germany/Siemens AG,""$39,500"",""$20,500"",""$19,000"",2020
-Smith & Nephew,UK/Smith & Nephew Plc,""$34,500"",""$14,000"",""$20,500"",2020
-Smithfield Foods,China/WH Group,""$20,000"",""$3,500"",""$16,500"",2020
-Smiths Group Services Corp (Smiths Group),UK/Smiths Group PLC,""$26,000"",""$13,500"",""$12,500"",2020
-Sodexo Inc,France/Sodexo,""$3,000"",$0,""$3,000"",2020
-Solvay America,Belgium/Solvay SA,""$20,000"",""$8,500"",""$11,500"",2020
-Sony Pictures Entertainment (Sony Corp),Japan/Sony Corp,""$67,000"",""$45,500"",""$21,500"",2020
-Sprint Corp (SoftBank Corp),Japan/Softbank Corp,""$87,000"",""$39,500"",""$47,500"",2020
-SSAB Americas,Sweden/SSAB AB,""$7,500"",$500,""$7,000"",2020
-Standard Insurance Co,Japan/Meiji Yasuda Life Insurance,$0,$0,$0,2020
-Steris Corp,UK/Steris PLC,""$5,750"",""$5,500"",$250,2020
-SUEZ Water,France/SUEZ Environnement,""$2,500"",""$1,500"",""$1,000"",2020
-Sun Life Financial (Sun Life Financial),Canada/Sun Life Financial,""$39,000"",""$27,500"",""$9,000"",2020
-Sunovion Pharmaceuticals (Sumitomo Chemical),Japan/Sumitomo Chemical,""$38,000"",""$18,000"",""$20,000"",2020
-Sunpower Corp,France/Total SA,""$4,500"",""$4,500"",$0,2020
-Swedish Match North America (Swedish Match AB),Sweden/Swedish Match AB,""$1,000"",$0,""$1,000"",2020
-Swiss Re America,Switzerland/Swiss Re,""$61,000"",""$38,500"",""$22,500"",2020
-Syngenta Corp,China/ChemChina,""$23,500"",""$8,500"",""$15,000"",2020
-T-Mobile USA,Germany/Deutsche Telekom AG,""$365,500"",""$185,000"",""$179,500"",2020
-Takeda Pharmaceuticals USA (Takeda Pharmaceutical Co),Japan/Takeda Pharmaceutical Co,""$24,500"",""$11,500"",""$13,000"",2020
-Tate & Lyle Americas (Tate & Lyle),UK/Tate & Lyle,""$5,000"",""$1,000"",""$4,000"",2020
-TD Bank USA,Canada/Toronto-Dominion Bank,""$55,700"",""$19,700"",""$36,000"",2020
-TE Connectivity,Switzerland/TE Connectivity,""$22,000"",""$6,000"",""$16,000"",2020
-Teva Pharmaceuticals USA,Israel/Teva Pharmaceutical Industries,""$10,500"",""$6,500"",""$4,000"",2020
-Toyota Motor North America,Japan/Toyota Motor Corp,""$391,100"",""$186,000"",""$205,100"",2020
-TransAmerica,Netherlands/Aegon NV,""$242,500"",""$120,000"",""$122,500"",2020
-Transcanada USA Services (Transcanada Corp),Canada/TransCanada Corp,""$57,500"",""$16,500"",""$41,000"",2020
-Travelport Inc,UK/Travelport Ltd,$0,$0,$0,2020
-UBS Americas,Switzerland/UBS AG,""$607,500"",""$239,500"",""$368,000"",2020
-UCB Inc (UCB SA),Belgium/UCB SA,""$2,500"",""$1,500"",""$1,000"",2020
-Ultra Electronics USA,UK/Ultra Electronics,""$15,000"",""$5,000"",""$10,000"",2020
-Universal Music Group (Vivendi),France/Vivendi,""$48,500"",""$25,500"",""$23,000"",2020
-Valent USA (Sumitomo Chemical),Japan/Sumitomo Chemical,""$6,500"",""$3,500"",""$3,000"",2020
-VNA Holding (AB Volvo),Sweden/AB Volvo,""$16,000"",""$4,000"",""$12,000"",2020
-VT Halter Marine,Singapore/ST Engineering,""$5,200"",$0,""$5,200"",2020
-Washington Gas Light Co (AltaGas Ltd),Canada/AltaGas Ltd,""$6,500"",""$6,500"",$0,2020
-Westinghouse Electric,Canada/Brookfield Business Partners,""$15,500"",""$3,500"",""$12,000"",2020
-Wexler & Walker Public Policy Assoc (WPP Group),UK/WPP Group,$0,$0,$0,2020
-WSP worldwide,Canada/WSP Global,""$49,750"",""$39,250"",""$10,500"",2020
-ZF TRW Automotive (ZF Friedrichshafen AG),Germany/ZF Friedrichshafen AG,$0,$0,$0,2020
-Zurich Insurance (Zurich Insurance Group),Switzerland/Zurich Financial Services AG,""$84,000"",""$56,000"",""$28,000"",2020

---FILE: course-materials/hw-instructions/hw-05/data/pac-2020.csv---
@@ -1,216 +0,0 @@
-name,country_parent,total,dems,repubs
-ABB Group (ABB Group),Switzerland/Asea Brown Boveri,""$1,000"",""$1,000"",$0
-Accenture (Accenture),Ireland/Accenture plc,""$75,500"",""$46,000"",""$29,500""
-Advance America Cash Advance Centers (Grupo Salinas),Mexico/Grupo Salinas,""$3,000"",""$1,000"",""$2,000""
-Air Liquide America,France/L'Air Liquide SA,""$11,500"",""$5,000"",""$6,500""
-Airbus Group,Netherlands/Airbus Group,""$79,000"",""$26,500"",""$52,500""
-Alkermes Inc,Ireland/Alkermes Plc,""$40,250"",""$11,250"",""$29,000""
-Allergan PLC (Allergan PLC),Ireland/Allergan PLC,""$98,500"",""$6,000"",""$92,500""
-Allianz of America (Allianz),Germany/Allianz AG Holding,""$34,500"",""$16,100"",""$18,400""
-Anheuser-Busch (Anheuser-Busch InBev),Belgium/Anheuser-Busch InBev,""$218,500"",""$109,000"",""$109,500""
-AON Corp (AON plc),UK/AON PLC,""$29,500"",""$14,000"",""$15,500""
-APL Maritime (CMA CGM),France/CMA CGM SA,""$14,000"",""$8,500"",""$5,500""
-Arcadis US (Arcadis NV),Netherlands/Arcadis NV,$0,$0,$0
-ArcelorMittal USA,Luxembourg/ArcelorMittal,""$21,500"",""$4,000"",""$17,500""
-Arch Capital Group (US),UK/Arch Capital Group,""$7,000"",""$3,500"",""$3,500""
-Arkema Inc,France/Arkema,""$43,500"",""$17,000"",""$26,500""
-Ash Grove (CRH Plc),Ireland/CRH PLC,$0,$0,$0
-Ashton Woods Corp,Canada/Great Gulf Group,$0,$0,$0
-Assured Guaranty Municipal Corp (Assured Guaranty US Holdings),UK/Assured Guaranty Ltd,""$67,500"",""$38,100"",""$29,400""
-Astellas US,Japan/Astellas Pharma,""$40,000"",""$29,000"",""$11,000""
-AstraZeneca Pharmaceuticals (AstraZeneca PLC),UK/AstraZeneca PLC,""$115,500"",""$53,500"",""$62,000""
-Atkins North America,UK/WS Atkins PLC,""$9,700"",$0,""$9,700""
-Austal USA,Australia/Austal,""$6,200"",""$2,700"",""$3,500""
-Avangrid Inc (Iberdrola SA),Spain/Iberdrola SA,""$27,000"",""$10,500"",""$14,000""
-AXA Equitable Life Insurance (AXA),France/AXA,""$41,000"",""$13,500"",""$27,500""
-Bacardi USA,UK/Bacardi Ltd,""$11,500"",""$4,500"",""$6,000""
-BAE Systems (BAE Systems),UK/BAE Systems,""$301,000"",""$147,000"",""$154,000""
-Barclays Group US,UK/Barclays plc,""$18,000"",""$8,000"",""$10,000""
-Barrick Goldstrike Mines,Canada/Barrick Gold Corp,""$11,000"",""$6,500"",""$4,500""
-BASF Corp,Germany/BASF SE,""$126,500"",""$57,500"",""$69,000""
-Bayer Corp (Bayer AG),Germany/Bayer AG,""$103,000"",""$41,500"",""$61,500""
-Bayer CropScience (Bayer AG),Germany/Bayer AG,""-$4,500"",""-$4,500"",$0
-BBVA USA,Spain/Banco Bilbao Vizcaya Argentaria,""$154,500"",""$44,000"",""$110,500""
-Beam Suntory (Suntory Holdings),Japan/Suntory Holdings,""$14,331"",""$9,500"",""$4,831""
-BMO Financial Corp (Bank of Montreal),Canada/Bank of Montreal,""$80,300"",""$37,800"",""$42,500""
-BMO Financial Corp (Bank of Montreal),Canada/Bank of Montreal,$0,$0,$0
-Boehringer Ingelheim Corp,Germany/CH Boehringer Sohn,""$48,500"",""$23,000"",""$25,500""
-Bombardier Transportation USA (Bombardier Inc),Canada/Bombardier Inc,""$27,500"",""$17,500"",""$10,000""
-BP,UK/BP PLC,""$104,500"",""$28,000"",""$76,500""
-Bridgestone Americas,Japan/Bridgestone Corp,""$7,500"",""$2,500"",""$5,000""
-Bumble Bee Foods,UK/Lion Capital,""$1,000"",""$1,000"",$0
-""Burson, Cohn & Wolfe (WPP Group)"",UK/WPP Group,""$21,000"",""$8,500"",""$12,500""
-Buzzi Unicem USA (Buzzi Unicem SpA),Italy/Buzzi Unicem SpA,$500,$0,$500
-CalPortland Co,Japan/Taiheiyo Cement Co,""$30,000"",""$10,000"",""$20,000""
-Cardtronics Inc,UK/Cardtronics Plc,$0,$0,$0
-Carmeuse Lime,Netherlands/Carmeuse Holding SA,$0,$0,$0
-Case New Holland,Netherlands/CNH Global,""$36,500"",""$1,500"",""$35,000""
-CEMEX Inc,Mexico/CEMEX SA de CV,""$56,000"",""$23,500"",""$32,500""
-CGI Technologies & Solutions,Canada/Groupe CGI,""$12,500"",""$7,500"",""$5,000""
-Chicago Bridge & Iron (McDermott International),Panama/McDermott International,""$5,470"",$470,""$5,000""
-Chubb Group of Insurance Companies,Switzerland/Chubb Ltd,""$76,000"",""$28,500"",""$47,500""
-CIBC Bancorp,Canada/Canadian Imperial Bank of Commerce,""$3,000"",""$2,000"",""$1,000""
-Cirrus Aircraft Corp,China/China Aviation Industry General Aircraft,""$1,500"",""$1,500"",$0
-Cobham Management Services,UK/Cobham PLC,""$64,000"",""$13,500"",""$50,500""
-Continental Automotive Systems (Continental AG),Germany/Continental AG,""$17,500"",""$8,500"",""$9,000""
-Covestro LLC (Covestro AG),Germany/Covestro AG,""$17,500"",""$2,000"",""$15,500""
-Credit Suisse Securities,Switzerland/Credit Suisse Group,""$22,000"",""$6,000"",""$16,000""
-CRH Americas (CRH PLC),Ireland/CRH PLC,""$236,500"",""$56,500"",""$180,000""
-CSL Behring,Australia/CSL Ltd,""$30,000"",""$13,500"",""$16,500""
-Daimler Trucks North America (Daimler AG),Germany/Daimler AG,""$2,500"",$0,""$2,500""
-Delhaize America,Belgium/Ahold Delhaize,""$3,500"",""$1,000"",""$2,500""
-Deutsche Bank Securities,Germany/Deutsche Bank AG,$0,$0,$0
-Diageo North America (Diageo PLC),UK/Diageo PLC,""$20,108"",""$11,060"",""$9,048""
-Direct Energy Inc,UK/Centrica Plc,$0,$0,$0
-Eaton Corp (Eaton Corp),Ireland/Eaton Plc,""$13,000"",""$4,500"",""$8,500""
-EDF Renewables (EDF Group),France/EDF Group,""$8,000"",""$4,500"",""$3,500""
-EDP Renewables NA,Portugal/EDP Renovaveis,""$9,000"",""$4,000"",""$5,000""
-Eisai Inc,Japan/Eisai Co Ltd,""$2,500"",""$2,500"",$0
-Elbit Systems of America,Israel/Elbit Systems Ltd,""$34,600"",""$6,600"",""$28,000""
-Elekta Inc (Elekta AB),Sweden/Elekta AB,""$27,500"",""$12,000"",""$15,500""
-Embraer Aircraft Holdings,Brazil/Embraer-Empresa Brasileira de Aeronautic,""$18,000"",""$5,000"",""$13,000""
-EMD Serono Inc,Germany/Merck KGaA,""$53,500"",""$28,500"",""$25,000""
-Enbridge Inc,Canada/Enbridge Inc,""$12,500"",""$4,500"",""$8,000""
-EnCana Oil & Gas USA (EnCana Corp),Canada/EnCana Corp,""$19,500"",""$5,000"",""$14,500""
-Endo Pharmaceuticals,Ireland/Endo International,$0,$0,$0
-ENGIE North America,France/ENGIE,$0,$0,$0
-Ericsson Inc,Sweden/Telefonaktiebolaget LM Ericsson,""$10,500"",""$5,000"",""$5,500""
-Experian,UK/Experian plc,""$264,500"",""$119,500"",""$145,000""
-Farmers Group (Zurich Insurance Group),Switzerland/Zurich Financial Services AG,""$83,500"",""$32,500"",""$51,000""
-First Hawaiian Bank (BNP Paribas),France/BNP Paribas,$0,$0,$0
-Florida East Coast Industries (SoftBank Corp),Japan/SoftBank Corp,""$34,000"",""$13,500"",""$20,500""
-Florida East Coast Railway (Grupo Mexico),Mexico/Grupo Mexico,$500,$500,$0
-Framatome (EDF Group),France/EDF Group,""$16,000"",""$14,000"",""$2,000""
-Fresenius Medical Care North America,Germany/Fresenius Medical Care,""$169,500"",""$93,500"",""$76,000""
-G4S Secure Solutions,UK/G4S plc,$0,$0,$0
-Garmin International (Garmin Ltd),Switzerland/Garmin Ltd,""$7,000"",$0,""$7,000""
-GE Appliances,China/Haier Group,""$8,500"",""$5,000"",""$3,500""
-Genentech Inc (Roche Holdings),Switzerland/Roche Holdings,""$215,000"",""$97,500"",""$117,500""
-General Cigar Co,Sweden/Scandinavian Tobacco Group,$0,$0,$0
-Gerdau Ameristeel Corp,Brazil/Gerdau,""$2,000"",$0,""$2,000""
-Glanbia Foods,Ireland/Glanbia PLC,$0,$0,$0
-GlaxoSmithKline,UK/GlaxoSmithKline,""$76,000"",""$30,000"",""$46,000""
-Glover Park Group (WPP Group),UK/WPP Group,""$58,700"",""$43,200"",""$15,500""
-Grand Trunk Western-Illinois Central RR,Canada/Canadian National Railway,""$4,000"",$0,""$4,000""
-Great-West Life & Annuity Insurance (Power Financial Corp),Canada/Power Financial Corp,$0,$0,$0
-Greyhound Lines,UK/FirstGroup PLC,""$7,500"",""$6,500"",""$1,000""
-Headwaters Inc,Australia/Boral Ltd,""$10,000"",$0,""$10,000""
-Heineken USA,Netherlands/L'Arche Green NV,""$20,500"",""$11,500"",""$9,000""
-Herbalife Nutrition,UK/Herbalife Ltd,""$49,000"",""$32,000"",""$17,000""
-Horizon Therapeutics,Ireland/Horizon Pharma PLC,""$31,000"",""$7,500"",""$23,500""
-HSBC North America (HSBC Holdings),UK/HSBC Holdings,""$1,000"",$0,""$1,000""
-HSBC North America (HSBC Holdings),UK/HSBC Holdings,""$60,000"",""$7,500"",""$52,500""
-IBI Group Engineering Services,Canada/IBI Group,$0,$0,$0
-IDEMIA Identity & Security (IDEMIA),France/Safran SA,""$6,000"",""$2,500"",""$3,500""
-Infineon Technologies,Germany/Infineon Technologies AG,""$7,500"",""$5,500"",""$2,000""
-Ingersoll-Rand,Ireland/Ingersoll Rand Co,""$2,000"",$0,""$2,000""
-Intelsat Holdings (Serafina SA),Luxembourg/Intelsat SA,""$1,500"",$0,""$1,500""
-International Game Technology,Italy/B&D Holding Di Marco Drago e C Sapa,""$16,000"",""$10,000"",""$6,000""
-ITG Brands,UK/Imperial Brands,$0,$0,$0
-Jackson National Life Insurance (Prudential PLC),UK/Prudential PLC,""$40,000"",""$3,500"",""$36,500""
-Jackson National Life Insurance (Prudential PLC),UK/Prudential PLC,""$98,000"",""$33,000"",""$65,000""
-JBS USA,Brazil/JBS SA,""$16,000"",""$2,000"",""$14,000""
-John Hancock Life Insurance,Canada/Manulife Financial,""$47,900"",""$28,500"",""$19,400""
-Johnson Controls (Johnson Controls International),Ireland/Johnson Controls International,""$139,900"",""$68,900"",""$71,000""
-Komatsu Mining,Japan/Komatsu Ltd,""$16,500"",$0,""$16,500""
-LafargeHolcim (LafargeHolcim),Switzerland/LaFargeHolcim,""$30,000"",""$3,500"",""$26,500""
-Lanxess Corp,Germany/Lanxess Corp,""$1,000"",$500,$500
-Lehigh Hanson,Germany/HeidelbergCement AG,""$38,500"",""$7,500"",""$31,000""
-Leonardo DRS,Italy/Finmeccanica SpA,""$46,000"",""$23,000"",""$23,000""
-Lincare Holdings (Linde plc),UK/Linde plc,""$4,500"",$0,""$4,500""
-Linde North America (Linde plc),UK/Linde plc,$0,$0,$0
-Linde plc (Linde plc),UK/Linde Plc,""$7,000"",""$6,000"",""$1,000""
-Livanova Inc,UK/Livanova Plc,""$1,000"",$0,""$1,000""
-Louis Dreyfus Co,Netherlands/Louis Dreyfus Holding B.V.,$0,$0,$0
-LSEG US,UK/London Stock Exchange Group,""$18,000"",""$8,500"",""$9,500""
-Lundbeck Inc,Denmark/H Lundbeck A/S,""$36,500"",""$18,500"",""$18,000""
-Maersk Inc (AP Moller-Maersk),Denmark/AP M√∏ller-M√¶rsk,""$18,500"",""$11,500"",""$7,000""
-Magnolia LNG,Australia/LNG Limited,$0,$0,$0
-Mallinckrodt Pharmaceuticals,UK/Mallinckrodt Plc,""$31,000"",""$10,000"",""$21,000""
-Marinette Marine,Italy/Fincantieri-Cantieri Navali Italiani SpA,""$9,500"",""$3,500"",""$6,000""
-Massachusetts Financial Services (Sun Life Financial),Canada/Sun Life Financial Services,""$2,500"",$0,""$2,500""
-Maxar Technologies (Maxar Technologies),Canada/Maxar Technologies,""$30,000"",""$9,000"",""$21,000""
-MBDA Inc,UK/MBDA,$0,$0,$0
-Medtronic Inc,Ireland/Medtronic Plc,""$97,500"",""$47,500"",""$50,000""
-Messer North America,Germany/Messer Group,$0,$0,$0
-MillerCoors LLC (Anheuser-Busch InBev),Belgium/Anheuser-Busch InBev,""$28,000"",""$10,500"",""$17,500""
-Mitsubishi Hitachi Power Systems,Japan/Mitsubishi Hitachi Power Systems,""$1,000"",$0,""$1,000""
-Mr Cooper Group (SoftBank Corp),Japan/SoftBank Corp,""$8,000"",""$2,000"",""$6,000""
-Munich American Reassurance,Germany/Munich Re Group,""$5,000"",""$5,000"",$0
-Mylan Inc,Netherlands/Mylan NV,""$109,500"",""$55,500"",""$54,000""
-Nammo Talley Inc,Norway/Nammo AS,""$3,500"",""$1,000"",""$2,500""
-National Grid USA (National Grid plc),UK/National Grid plc,""$12,800"",""$9,800"",""$3,000""
-Natixis Investment Managers,France/Groupe BPCE,""$4,011"",""$1,000"",""$3,011""
-Nestle Purina PetCare (Nestle SA),Switzerland/Nestle,""$2,000"",$0,""$2,000""
-Nomura Holding America,Japan/Nomura Holdings,""$32,000"",""$22,500"",""$9,500""
-NOVA Chemicals,United Arab Emirates/International Petroleum Investment Co,$0,$0,$0
-Novartis Corp (Novartis AG),Switzerland/Novartis AG,""$131,500"",""$58,500"",""$73,000""
-Novo Nordisk,Denmark/Novo Nordisk A/S,""$120,013"",""$60,927"",""$59,086""
-Novocure Inc,UK/Novocure,""$26,800"",$0,""$26,800""
-Nutrien Ag Solutions,Canada/Nutrien Ltd,""$8,500"",""$1,000"",""$7,500""
-Orano USA (Orano Group),France/Orano Group,""$1,500"",$0,""$1,500""
-Otsuka America (Otsuka Pharmaceutical),Japan/Otsuka Pharmaceutical,""$2,500"",$500,""$2,000""
-Pernod Ricard USA,France/Pernod Ricard SA,""$2,000"",$0,""$2,000""
-Peter Pan Seafoods,Japan/Maruha Nichiro Holdings,$0,$0,$0
-Pharmavite LLC (Otsuka Pharmaceutical),Japan/Otsuka Pharmaceutical,""$24,000"",""$11,000"",""$13,000""
-Philips Electronics North America (Philips),Netherlands/Philips Electronics,""$32,000"",""$17,000"",""$15,000""
-Protective Life Corp (Dai-Ichi Life),Japan/Dai-Ichi Life,""$57,300"",""$10,000"",""$47,300""
-Putnam Investments (Power Financial Corp),Canada/Power Financial Corp,""$5,237"",$0,""$5,237""
-RBC Bank (Royal Bank of Canada),Canada/Royal Bank of Canada,""$11,000"",""$6,000"",""$5,000""
-Recurrent Energy,Canada/Canadian Solar,$0,$0,$0
-RELX Inc,UK/RELX Group,""$128,000"",""$50,000"",""$78,000""
-Resolute Forest Products,Canada/Resolute Forest Products,""$20,500"",""$2,000"",""$18,500""
-Reynolds American (British American Tobacco),UK/British American Tobacco plc,""$96,000"",""$31,000"",""$65,000""
-Rio Tinto America,UK/Rio Tinto Group,""$3,500"",$0,""$3,500""
-Roche Diagnostics (Roche Holdings),Switzerland/Roche Holdings,""$31,000"",""$10,500"",""$20,500""
-Rolls-Royce North America (Rolls-Royce PLC),UK/Rolls-Royce PLC,""$114,500"",""$38,000"",""$76,500""
-Safelite Group,Belgium/D'Ieteren SA,""-$3,000"",$0,""-$3,000""
-Samsung Electronics America,South Korea/Samsung Group,""$63,500"",""$33,500"",""$30,000""
-Sanofi US (Sanofi),France/Sanofi,""$128,500"",""$69,000"",""$59,500""
-Santander Bank (Banco Santander),Spain/Banco Santander,""$45,500"",""$22,000"",""$23,500""
-SAP America,Germany/SAP Aktiengesellschaft,""$6,000"",""$6,000"",$0
-Securitas Security Services USA,Sweden/Securitas AB,$0,$0,$0
-Serco Inc,UK/Serco Group,""$23,500"",""$13,500"",""$10,000""
-Shell Oil,Netherlands/Royal Dutch-Shell Group,""$4,000"",$0,""$4,000""
-Shire Holdings US (Takeda Pharmaceutical Co),Japan/Takeda Pharmaceutical Co,""-$12,500"",""-$1,500"",""-$11,000""
-Siemens Corp,Germany/Siemens AG,""$39,500"",""$20,500"",""$19,000""
-Smith & Nephew,UK/Smith & Nephew Plc,""$34,500"",""$14,000"",""$20,500""
-Smithfield Foods,China/WH Group,""$20,000"",""$3,500"",""$16,500""
-Smiths Group Services Corp (Smiths Group),UK/Smiths Group PLC,""$26,000"",""$13,500"",""$12,500""
-Sodexo Inc,France/Sodexo,""$3,000"",$0,""$3,000""
-Solvay America,Belgium/Solvay SA,""$20,000"",""$8,500"",""$11,500""
-Sony Pictures Entertainment (Sony Corp),Japan/Sony Corp,""$67,000"",""$45,500"",""$21,500""
-Sprint Corp (SoftBank Corp),Japan/Softbank Corp,""$87,000"",""$39,500"",""$47,500""
-SSAB Americas,Sweden/SSAB AB,""$7,500"",$500,""$7,000""
-Standard Insurance Co,Japan/Meiji Yasuda Life Insurance,$0,$0,$0
-Steris Corp,UK/Steris PLC,""$5,750"",""$5,500"",$250
-SUEZ Water,France/SUEZ Environnement,""$2,500"",""$1,500"",""$1,000""
-Sun Life Financial (Sun Life Financial),Canada/Sun Life Financial,""$39,000"",""$27,500"",""$9,000""
-Sunovion Pharmaceuticals (Sumitomo Chemical),Japan/Sumitomo Chemical,""$38,000"",""$18,000"",""$20,000""
-Sunpower Corp,France/Total SA,""$4,500"",""$4,500"",$0
-Swedish Match North America (Swedish Match AB),Sweden/Swedish Match AB,""$1,000"",$0,""$1,000""
-Swiss Re America,Switzerland/Swiss Re,""$61,000"",""$38,500"",""$22,500""
-Syngenta Corp,China/ChemChina,""$23,500"",""$8,500"",""$15,000""
-T-Mobile USA,Germany/Deutsche Telekom AG,""$365,500"",""$185,000"",""$179,500""
-Takeda Pharmaceuticals USA (Takeda Pharmaceutical Co),Japan/Takeda Pharmaceutical Co,""$24,500"",""$11,500"",""$13,000""
-Tate & Lyle Americas (Tate & Lyle),UK/Tate & Lyle,""$5,000"",""$1,000"",""$4,000""
-TD Bank USA,Canada/Toronto-Dominion Bank,""$55,700"",""$19,700"",""$36,000""
-TE Connectivity,Switzerland/TE Connectivity,""$22,000"",""$6,000"",""$16,000""
-Teva Pharmaceuticals USA,Israel/Teva Pharmaceutical Industries,""$10,500"",""$6,500"",""$4,000""
-Toyota Motor North America,Japan/Toyota Motor Corp,""$391,100"",""$186,000"",""$205,100""
-TransAmerica,Netherlands/Aegon NV,""$242,500"",""$120,000"",""$122,500""
-Transcanada USA Services (Transcanada Corp),Canada/TransCanada Corp,""$57,500"",""$16,500"",""$41,000""
-Travelport Inc,UK/Travelport Ltd,$0,$0,$0
-UBS Americas,Switzerland/UBS AG,""$607,500"",""$239,500"",""$368,000""
-UCB Inc (UCB SA),Belgium/UCB SA,""$2,500"",""$1,500"",""$1,000""
-Ultra Electronics USA,UK/Ultra Electronics,""$15,000"",""$5,000"",""$10,000""
-Universal Music Group (Vivendi),France/Vivendi,""$48,500"",""$25,500"",""$23,000""
-Valent USA (Sumitomo Chemical),Japan/Sumitomo Chemical,""$6,500"",""$3,500"",""$3,000""
-VNA Holding (AB Volvo),Sweden/AB Volvo,""$16,000"",""$4,000"",""$12,000""
-VT Halter Marine,Singapore/ST Engineering,""$5,200"",$0,""$5,200""
-Washington Gas Light Co (AltaGas Ltd),Canada/AltaGas Ltd,""$6,500"",""$6,500"",$0
-Westinghouse Electric,Canada/Brookfield Business Partners,""$15,500"",""$3,500"",""$12,000""
-Wexler & Walker Public Policy Assoc (WPP Group),UK/WPP Group,$0,$0,$0
-WSP worldwide,Canada/WSP Global,""$49,750"",""$39,250"",""$10,500""
-ZF TRW Automotive (ZF Friedrichshafen AG),Germany/ZF Friedrichshafen AG,$0,$0,$0
-Zurich Insurance (Zurich Insurance Group),Switzerland/Zurich Financial Services AG,""$84,000"",""$56,000"",""$28,000""

---FILE: course-materials/hw-instructions/hw-05/hw-05-legos.Rmd---
@@ -0,0 +1,102 @@
+---
+title: ""HW 05 - Legos""
+output: 
+  tufte::tufte_html:
+    css: ../hw.css
+    tufte_variant: ""envisioned""
+    highlight: pygments
+link-citations: yes
+---
+
+```{r include = FALSE}
+knitr::opts_chunk$set(
+  eval = FALSE,
+  out.width = ""80%"",
+  fig.asp = 0.618,
+  fig.width = 10,
+  dpi = 300
+)
+```
+
+```{r photo, fig.margin = TRUE, echo = FALSE, fig.width = 3, fig.cap = ""Photo by Daniel Cheung on Unsplash"", eval = TRUE}
+knitr::include_graphics(""img/daniel-cheung-ZqqlOZyGG7g-unsplash.jpg"")
+```
+
+This week we'll do some data gymnastics to refresh and review what we learned over the past few weeks using (simulated) data from Lego sales in 2018 for a sample of customers who bought Legos in the US.
+
+# Getting started
+
+Go to the course GitHub organization and locate your homework repo, clone it in RStudio and open the R Markdown document.
+Knit the document to make sure it compiles without errors.
+
+## Warm up
+
+Before we introduce the data, let's warm up with some simple exercises.
+Update the YAML of your R Markdown file with your information, knit, commit, and push your changes.
+Make sure to commit with a meaningful commit message.
+Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd **and** md files.
+If anything is missing, commit and push again.
+
+## Packages
+
+We'll use the **tidyverse** package for much of the data wrangling and visualisation and the data lives in the **dsbox** package.
+These packages are already installed for you.
+You can load them by running the following in your Console:
+
+```{r load-packages, message = FALSE, eval = TRUE}
+library(tidyverse)
+library(dsbox)
+```
+
+## Data
+
+The data can be found in the **dsbox** package, and it's called `lego_sales`.
+Since the dataset is distributed with the package, we don't need to load it separately; it becomes available to us when we load the package.
+You can find out more about the dataset by inspecting its documentation, which you can access by running `?lego_sales` in the Console or using the Help menu in RStudio to search for `lego_sales`.
+You can also find this information [here](https://rstudio-education.github.io/dsbox/reference/lego_sales.html).
+
+# Exercises
+
+Answer the following questions using pipelines.
+For each question, state your answer in a sentence, e.g. ""In this sample, the first three common names of purchasers are ..."".
+Note that the answers to all questions are within the context of this particular sample of sales, i.e. you shouldn't make inferences about the population of all Lego sales based on this sample.
+
+1.  What are the three most common first names of purchasers?
+
+2.  What are the three most common themes of Lego sets purchased?
+
+3.  Among the most common theme of Lego sets purchased, what is the most common subtheme?
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+```{marginfigure}
+**Hint:** Use the `case_when()` function.
+```
+
+4.  Create a new variable called `age_group` and group the ages into the following categories: ""18 and under"", ""19 - 25"", ""26 - 35"", ""36 - 50"", ""51 and over"".
+
+```{marginfigure}
+**Hint:** You will need to consider quantity of purchases.
+```
+
+5.  Which age group has purchased the highest number of Lego sets.
+
+```{marginfigure}
+**Hint:** You will need to consider quantity of purchases as well as price of lego sets.
+```
+
+6.  Which age group has spent the most money on Legos?
+
+```{marginfigure}
+**Hint:** The [`str_sub()`](https://stringr.tidyverse.org/reference/str_sub.html) function will be helpful here!
+```
+
+7.  Which Lego theme has made the most money for Lego?
+
+8.  Which area code has spent the most money on Legos?
+    In the US the area code is the first 3 digits of a phone number.
+
+9.  Come up with a question you want to answer using these data, and write it down.
+    Then, create a data visualization that answers the question, and explain how your visualization answers the question.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you're happy with the final state of your work.*

---FILE: course-materials/hw-instructions/hw-05/hw-05-money-in-politics.Rmd---
@@ -1,391 +0,0 @@
----
-title: ""HW 05 - Money in US politics""
-output: 
-  tufte::tufte_html:
-    css: ../hw.css
-    tufte_variant: ""envisioned""
-    highlight: pygments
-link-citations: yes
----
-
-```{r include=FALSE}
-library(DT)
-```
-
-```{r photo, fig.margin = TRUE, echo = FALSE, fig.width=3, fig.cap=""Photo by Sharon McCutcheon on Unsplash""}
-knitr::include_graphics(""img/sharon-mccutcheon-rItGZ4vquWk-unsplash.jpg"")
-```
-
-Every election cycle brings its own brand of excitement -- and lots of money. 
-Political donations are of particular interest to political scientists and 
-other researchers studying politics and voting patterns. They are also of 
-interest to citizens who want to stay informed of how much money their candidates 
-raise and where that money comes from.
-
-In the United States, _""only American citizens (and immigrants with green cards) 
-can contribute to federal politics, but the American divisions of foreign 
-companies can form political action committees (PACs) and collect contributions 
-from their American employees.""_^[Source: [Open Secrets - Foreign Connected PACs](https://www.opensecrets.org/political-action-committees-pacs/foreign-connected-pacs).] 
-
-In this assignment we will scrape and work with data foreign connected PACs that 
-donate to US political campaigns. First, we will get data foreign connected PAC 
-contributions in the 2020 election cycle. Then, you will use a similar approach 
-to get data such contributions from previous years so that we can examine trends 
-over time.
-
-In order to complete this assignment you will need a Chrome browser with the 
-[Selector Gadget extension](http://selectorgadget.com/) installed.
-
-# Packages
-
-In this assignment we will work with the following packaes. They should already 
-be installed in your project, and you can load them with the following:
-
-```{r load-packages, eval=TRUE, message=FALSE}
-library(tidyverse)
-library(robotstxt)
-library(rvest)
-library(scales)
-```
-
-# Data collection via web scraping
-
-```{r opensecrets, eval=TRUE, echo=FALSE, fig.margin = TRUE}
-knitr::include_graphics(""img/opensecrets.png"")
-```
-
-The data come from [OpenSecrets.org](https://www.opensecrets.org), a _""website tracking the influence of money on U.S. politics, and how that money affects policy and citizens' lives""_. 
-This website is hosted by The Center for Responsive Politics, which is a nonpartisan, 
-independent nonprofit that _""tracks money in U.S. politics and its effect on elections and public policy.""_^[Source: [Open Secrets - About](https://www.opensecrets.org/about/).]
-
-Before getting started, let's check that a bot has permissions to access pages 
-on this domain.
-
-```{r paths-allowed, eval=TRUE, warning=FALSE, message=FALSE}
-paths_allowed(""https://www.opensecrets.org"")
-```
-
-## 2020 Foreign-connected PAC contributions
-
-```{r nc_races, eval=TRUE, echo=FALSE, out.width=""60%""}
-knitr::include_graphics(""img/pac_2020.png"")
-```
-
-The goal of this exercise is scrape the data from a page that looks like the 
-the page shown above, and save it as a data frame that looks like the 
-data frame shown below.
-
-```{r read-nc-page, echo=FALSE, message=FALSE, eval=TRUE}
-pac_2020 <- read_csv(""data/pac-2020.csv"")
-datatable(pac_2020, width=""60%"")
-```
-
-Since the data are already formatted as a table, we can use the `html_table()`
-function to extract it out of the page. Note that this function has some useful 
-arguments like `header` (to indicate whether the first row of the table 
-should be used as header) and `fill` (to indicate whether rows with fewer than 
-the maximum number of columns shuld be filled with `NA`).
-
-<div class=""box"">
-Complete the following set of steps in the `01-scrape-pac-2020.R` file in the 
-`scripts` folder of your repository. This file already contains some starter 
-code to help you out.
-</div>
-
-- Fill in the blanks to scrape the table from the webpage, and confirm that 
-the resulting data frame, `pac_2020`, has 215 observations and 5 variables.
-
-```{marginfigure}
-**Hint:** Take a look at the help for the `rename()` function to determine 
-whether these new variable names need to be quoted or not.
-```
-
-- The names of the variables in the `pac_2020` data frame are somewhat ill-formed.
-Rename the variables to the following: `name`, `country_parent`, `total`, 
-`dems`, `repubs`. Note that `dems` is short for Democrats and `repubs` is short 
-for Republicans, the two major parties in the US. Once you make the change 
-view the data frame in the data viewer to see how things look.
-
-- The `name` variable looks pretty messy. There is lots of white space between 
-the name and the affliate in parantheses. But remember, we have a string 
-manipulation function that removes pesky white spaces: `str_squish()`. Fix up 
-the `name` variable using this function. Confirm that your data frame looks like 
-the data shown above.
-
-- Write the data frame out to a csv file called `pac-2020.csv` in the 
-`data` folder.
-
-```{marginfigure}
-**Hint:** You already know what these numbers should be!
-```
-
-1. In your R Markdown document, load `pac-2020.csv` and report its number of 
-observations and variables using inline code.
-
-## Functionalize!
-
-You can probably guess where we're headed: we'll ultimately scrape data for 
-contributions in all election years Open Secrets has data for. Since that means 
-repeating a task many times, let's first write a function that works on the 
-first page. Confirm it works on a few others. Then iterate it over pages for 
-all years.
-
-<div class=""box"">
-Complete the following set of steps in the `02-scrape-pac-function.R` file in the 
-`scripts` folder of your repository. This file already contains some starter 
-code to help you out.
-</div>
-
-- Write a function called `scrape_pac()` that scrapes information from the 
-Open Secrets webpage for foreign-conntected PAC contributions in a given year. 
-This function should have one input: the URL of the webpage and should return 
-a data frame. You should be able to reuse code you developed for scraping 
-2020 data here.
-
-- Enhance your function with one more feature: adding a new column to the data 
-frame for `year`. We will want this information when we ultimately have data 
-from all years, so this is a good time to keep track of it. Our function doesn't 
-take a year argument, but the year is embedded in the URL, so we can extract it 
-out of there, and add it as a new column. Use the `str_sub()` function to extract 
-the last 4 characters from the URL. You will probably want to look at the help 
-for this function to figure out how to specify ""last 4 characters"".
-
-- Define the URLs for 2020, 2018, and 1998 contributions. Then, test your 
-function using these URLs as inputs. Does the function seem to do what you 
-expected it to do?
-
-- Write the data frames for 2020, 2018, and 1998 to csv files called 
-`pac-2020-fn.csv` (to avoid overwriting the earlier file), `pac-2018.csv`, 
-and `pac-1998.csv`, respectively, in the `data` folder.
-
-2. In your R Markdown file, load these three data frames and report each of 
-their numbers of observations and variables using inline code.
-
-## Foreign-connected PAC contributions for all years
-
-Our final task in data scraping is to map the `scrape_pac()` function over a 
-list of all URLs of web pages containing information on foreign-connected 
-PAC contributions for each year.
-
-Go back to the URLs you defined in the previous exercise, what pattern emerges? 
-They each have the following form:
-
-```{r eval=FALSE}
-url_2020 <- ""...cycle=2020""
-url_2018 <- ""...cycle=2018""
-url_1998 <- ""...cycle=1998""
-```
-
-<div class=""box"">
-Complete the following set of steps in the `03-scrape-pac-all.R` file in the 
-`scripts` folder of your repository. This file already contains some starter 
-code to help you out.
-</div>
-
-- Construct a vector called `urls` that contains the URLs for each webpage that 
-contains information on foreign-connected PAC contributions for a given year.
-
-- Map the `scrape_pac()` function over `urls` in a way that will result in a 
-data frame called `pac_all`.
-
-- Write the data frame to a csv file called `pac-all.csv` in the `data` folder. 
-
-3. In your R Markdown file, load `pac-all.csv` and report its number of 
-observations and variables using inline code.
-
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *If you haven't yet done so, now is definitely a good time to commit and push your changes to GitHub with an appropriate commit message (e.g. ""Data scraping complete""). Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
-
-# Data cleaning
-
-In this section we clean the `pac_all` data frame to prepare it for analysis and 
-visualization. We have two goals in data cleaning:
-
-- Separate the `country_parent` into two such that country and parent company appear in different columns for country-level analysis.
-
-- Convert contribution amounts in `total`, `dems`, and `repubs` from character 
-strings to numeric values.
-
-Exercises 4 and 5 walk you through how to make these fixes to the data.
-
-4. Use the `separate()` function to separate `country_parent` into `country` 
-and `parent` columns. Note that country and parent company names are separated 
-by `\` (which will need to be specified in your function) and also note that 
-there are some entries where the `\` sign appears twice and in these cases we 
-want to only split the value at the first occurrence of `\`. This can be 
-accomplished by setting the `extra` argument in to `""merge""` so that the cell 
-is split into only 2 segments, e.g. we want `""Denmark/Novo Nordisk A/S""` to 
-be split into `""Denmark""` and `""Novo Nordisk A/S""`. (See help for `separate()` 
-for more on this.)
-
-5. Remove the character strings including `$` and `,` signs in the `total`, `dems`,
-and `repubs` columns and convert these columns to numeric. Few hints to help 
-you out: 
-  - Function for removing character strings is `str_remove()`. 
-  - The `$` character is a special character so it will need to be escaped.
-  - Some contribution amounts are in the millions (e.g. Anheuser-Busch contributed a total of $1,510,897 in 2008). In this case we need to remove all occurences of `,`, which we can do by using `str_remove_all()` instead of `str_remove()`.
-
-# Data visualization
-
-```{r include=FALSE}
-pac_all <- read_csv(""data/pac-all-clean.csv"")
-```
-
-6. Create a line plot of total contributions from all foreign-connected PACs 
-in the UK and Canada over the years. Once you have made the plot, write a brief 
-interpretation of what the graph reveals. Make sure to comment on the dip at 2020. 
-Few hints to help you out:
-  - Filter for only `Canada` and `UK`
-  - Calculate sum of total contributions from PACs for each year for each country
-  by using a sequence of `group_by()` then `summarise()`.
-  - Make a plot of total contributions (y-axis) by year (x-axis) where two lines 
-  identified by different colors represent each of Canada and UK.
-  
-Next, we will walk you through creating the following visualization for 
-contributions from UK-connected PACs to Democratic and Republican parties.
-
-```{r echo=FALSE, fig.width=7, fig.height=4, fig.retina=3}
-pac_all %>%
-  filter(
-    country == ""UK"",
-    year < 2020
-    ) %>%
-  group_by(year) %>%
-  summarise(
-    Democrat = sum(dems),
-    Republican = sum(repubs)
-  ) %>%
-  pivot_longer(cols = c(Democrat, Republican), names_to = ""party"", values_to = ""amount"") %>%
-  ggplot(aes(x = year)) +
-  geom_line(aes(y = amount, group = party, color = party)) +
-  labs(title = ""UK PACs"")
-```
-
-First, we need to filter the data for UK contributions as well as years only 
-up to 2018:
-
-```{r}
-pac_all %>%
-  filter(
-    country == ""UK"",
-    year < 2020
-    ) 
-```
-
-Next, we need to calculate total contributions to Democratic and Republican 
-parties from all UK-connected PACs each year. This requires a `group_by()` and 
-`summarise()` step:
-
-```{r}
-pac_all %>%
-  filter(
-    country == ""UK"",
-    year < 2020
-    ) %>%
-  group_by(year) %>%
-  summarise(
-    Democrat = sum(dems),
-    Republican = sum(repubs)
-  )
-```
-
-This results in a 11x3 tibble (11 years, and a column each for year, 
-total contributions in that year to the Democratic party, and total 
-contributions in that year to the Republican party). Ultimately we want to 
-color the lines by party though, and this requires our data to be formatted 
-a little differently:
-
-```{r echo=FALSE}
-pac_all %>%
-  filter(
-    country == ""UK"",
-    year < 2020
-    ) %>%
-  group_by(year) %>%
-  summarise(
-    Democrat = sum(dems),
-    Republican = sum(repubs)
-  ) %>%
-  pivot_longer(cols = c(Democrat, Republican), names_to = ""party"", values_to = ""amount"") 
-```
-
-Note that now we have two rows per year, one for contributions to the 
-Democratic party and the other for the Republican. The contribution 
-amounts are not stored in a new column called `amount` and the party 
-information is no longer spread across two columns, but appears in a single
-column called `party`. We can achieve this by pivoting our data to be longer 
-(going from 11 to 22 rows):
-
-```{r eval=FALSE}
-pac_all %>%
-  filter(
-    country == ""UK"",
-    year < 2020
-    ) %>%
-  group_by(year) %>%
-  summarise(
-    Democrat = sum(dems),
-    Republican = sum(repubs)
-  ) %>%
-  pivot_longer(cols = c(Democrat, Republican), names_to = ""party"", values_to = ""amount"") 
-```
-
-And finally we are ready to visualize!
-
-```{r echo=FALSE, fig.width=7, fig.height=4, fig.retina=3}
-pac_all %>%
-  filter(
-    country == ""UK"",
-    year < 2020
-    ) %>%
-  group_by(year) %>%
-  summarise(
-    Democrat = sum(dems),
-    Republican = sum(repubs)
-  ) %>%
-  pivot_longer(
-    cols = c(Democrat, Republican), 
-    names_to = ""party"", 
-    values_to = ""amount""
-    ) %>%
-  ggplot(aes(x = year)) +
-  geom_line(aes(y = amount, group = party, color = party))
-```
-
-7. In this exercise we ask you to build on the plot we constructed above to 
-make it a little more visually applealing. The desired outcome is shown below, 
-and it's your job to get from where we left things off above to this outcome 
-by adding more layers to your plot. **Hint:** You will need to make use of 
-some functions from the **scales** package for axis labels as well as from **ggplot2**. Remember, if you can't figure out certain bits, you can always 
-ask on Piazza!
-
-```{r echo=FALSE, fig.width=7, fig.height=4, fig.retina=3}
-pac_all %>%
-  filter(
-    country == ""UK"",
-    year < 2020
-    ) %>%
-  group_by(year) %>%
-  summarise(
-    Democrat = sum(dems),
-    Republican = sum(repubs)
-  ) %>%
-  pivot_longer(
-    cols = c(Democrat, Republican), 
-    names_to = ""party"", 
-    values_to = ""amount""
-    ) %>%
-  ggplot(aes(x = year)) +
-  geom_line(aes(y = amount, group = party, color = party)) +
-  scale_color_manual(values = c(""blue"", ""red"")) +
-  scale_y_continuous(labels = dollar_format(scale = 0.000001, suffix = ""M"")) +
-  labs(
-    x = ""Year"",
-    y = ""Amount"",
-    color = ""Party"",
-    title = ""Contribution to US politics from UK-Connected PACs"",
-    subtitle = ""By party, over time""
-  ) +
-  theme_minimal()
-```
-
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *Now is definitely a good time to knit your document, and commit and push your changes to GitHub with an appropriate commit message (e.g. ""Data visualization complete""). Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
\ No newline at end of file

---FILE: course-materials/hw-instructions/hw-05/scripts/01-scrape-pac-2020.R---
@@ -1,41 +0,0 @@
-# 01-scrape-pac-2020.R: scrape information for 2020 contributions
-
-# load packages ----------------------------------------------------------------
-
-library(tidyverse)
-library(rvest)
-
-# define url -------------------------------------------------------------------
-
-url_2020 <- ""https://www.opensecrets.org/political-action-committees-pacs/foreign-connected-pacs?cycle=2020""
-
-# read the page ----------------------------------------------------------------
-
-page <- ___(url_2020)
-
-# exract the table -------------------------------------------------------------
-
-pac_2020 <- ___ %>%
-  html_node("".DataTable"") %>%
-  html_table(""___"", header = ___, fill = ___) %>%
-  as_tibble()
-
-# rename variables -------------------------------------------------------------
-
-pac_2020 <- pac_2020 %>%
-  rename(
-    ___ = `PAC Name (Affiliate)` ,
-    ___ = `Country of Origin/Parent Company`,
-    ___ = Total,
-    ___ = Dems,
-    ___ = Repubs
-  )
-
-# fix name ---------------------------------------------------------------------
-
-pac_2020 <- pac_2020 %>%
-  ___
-
-# write data -------------------------------------------------------------------
-
-write_csv(pac_2020, path = ""data/pac-2020.csv"")
\ No newline at end of file

---FILE: course-materials/hw-instructions/hw-05/scripts/02-scrape-pac-function.R---
@@ -1,48 +0,0 @@
-# 02-scrape-pac-function.R: function to scrape information for all contributions
-
-# load packages ----------------------------------------------------------------
-
-library(tidyverse)
-library(rvest)
-
-# function: scrape_pac ---------------------------------------------------------
-
-scrape_pac <- function(url) {
-  
-  # read the page
-  ___
-  
-  # extract the table
-  pac <- ___
-  
-  # rename variables
-  ___
-  
-  # fix name
-  ___
-  
-  # add year
-  pac <- pac %>%
-    mutate(year = str_sub(___))
-  
-  # return data frame
-  pac
-  
-}
-
-# test function ----------------------------------------------------------------
-
-url_2020 <- ""___""
-pac_2020_fn <- scrape_pac(url_2020)
-
-url_2018 <- ""___""
-pac_2018 <- scrape_pac(url_2018)
-
-url_1998 <- ""___""
-pac_1998 <- scrape_pac(url_1998)
-
-# write files -------------------------------------------------------------------
-
-write_csv(pac_2020_fn, ""data/pac-2020-fn.csv"")
-write_csv(pac_2018, ""data/pac-2018.csv"")
-write_csv(pac_1998, ""data/pac-1998.csv"")

---FILE: course-materials/hw-instructions/hw-05/scripts/03-scrape-pac-all.R---
@@ -1,20 +0,0 @@
-# 03-scrape-pac-all.R: map scrape_pac() over all years
-
-# load packages ----------------------------------------------------------------
-
-library(tidyverse)
-library(rvest)
-
-# list of urls -----------------------------------------------------------------
-
-root <- ""https://www.opensecrets.org/political-action-committees-pacs/foreign-connected-pacs?cycle=""
-year <- seq(from = ___, to = ___, by = ___)
-urls <- paste0(root, ___)
-
-# map --------------------------------------------------------------------------
-
-pac_all <- map_dfr(urls, scrape_pac)
-
-# write data -------------------------------------------------------------------
-
-write_csv(pac_all, path = ""data/pac-all.csv"")

---FILE: course-materials/hw-instructions/hw-06/hw-06-bike-rentals-dc.Rmd---
@@ -1,131 +0,0 @@
----
-title: ""HW 06 - Bike rentals in DC""
-output: 
-  tufte::tufte_html:
-    css: ../hw.css
-    tufte_variant: ""envisioned""
-    highlight: pygments
-link-citations: yes
----
-
-```{r photo, fig.margin = TRUE, echo = FALSE, fig.width=3, fig.cap=""Photo by Viktor Kern on Unsplash""}
-knitr::include_graphics(""img/viktor-kern-UdGEXZtlx-E-unsplash.jpg"")
-```
-
-Bike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return back has become automatic. Through these systems, user is able to easily rent a bike from a particular position and return back at another position. Currently, there are about over 500 bike-sharing programs around the world which is composed of over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues. 
-
-Apart from interesting real world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for the research. Opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position is explicitly recorded in these systems. This feature turns bike sharing system into a virtual sensor network that can be used for sensing mobility in the city. Hence, it is expected that most of important events in the city could be detected via monitoring these data.
-
-Source: [UCI Machine Learning Repository - Bike Sharing Dataset](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)
-
-# Packages
-
-In this assignment we will work with the following packages. They should already 
-be installed in your project, and you can load them with the following:
-
-```{r load-packages, eval=TRUE, message=FALSE}
-library(tidyverse)
-library(dsbox)
-```
-
-# Data
-
-The data include daily bike rental counts (by members and casual users) of Capital Bikeshare in Washington, DC in 2011 and 2012 as well as weather information on these days.
-
-The original data sources are http://capitalbikeshare.com/system-data and http://www.freemeteo.com.
-
-The dataset is called `dcbikeshare`. You can find descriptions of each of the variables in the help file for the dataset, which you can access by running `?dcbikeshare` in your Console.
-
-# Exercises
-
-## Data wrangling
-
-1. Recode the `season` variable to be a factor with meaningful level names as 
-outlined in the codebook, with spring as the baseline level.
-
-2. Recode the binary variables `holiday` and `workingday` to be factors with 
-levels no (0) and yes (1), with no as the baseline level.
-
-3. Recode the `yr` variable to be a factor with levels 2011 and 2012, with 2011 
-as the baseline level.
-
-4. Recode the `weathersit` variable as 1 - clear, 2 - mist, 3 - light precipitation, 
-and 4 - heavy precipitation, with clear as the baseline.
-
-5. Calculate raw temperature, feeling temperature, humidity, and windspeed as 
-their values given in the dataset multiplied by the maximum raw values stated 
-in the codebook for each variable. Instead of writing over the existing variables, 
-create new ones with concise but informative names.
-
-6. Check that the sum of `casual` and `registered` adds up to `cnt` for each record.
-**Hint:** One way of doing this is to create a new column that takes on the value 
-`TRUE` if they add up and `FALSE` if not, and then checking if all values in 
-that column are `TRUE`s. But this is only one way, you might come up with another.
-
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *Now is a good time to knit your document, and commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
-
-## Exploratory data analysis
-
-7. Recreate the following visualization, and interpret it in context of the data. 
-*Hint: You will need to use one of the variables you created above. The temperature plotted is the feeling temperature.*
-
-```{r fig.width=9, echo=FALSE}
-dcbikeshare %>%
-  mutate(atemp_raw = atemp * 50) %>%
-  ggplot(mapping = aes(x = dteday, y = cnt, color = atemp_raw)) +
-    geom_point(alpha = 0.7) +
-    labs(
-      title = ""Bike rentals in DC, 2011 and 2012"",
-      subtitle = ""Warmer temperatures associated with more bike rentals"",
-      x = ""Date"",
-      y = ""Bike renrals"",
-      color = ""Temperature (C)""
-    ) +
-  theme_minimal()
-```
-
-8. Create a visualization displaying the relationship between bike rentals and 
-season. Interpret the plot in context of the data.
-
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *Now is a good time to knit your document, and commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
-
-## Modelling
-
-9. Fit a linear model predicting total daily bike rentals from daily temperature. 
-Write the linear model, interpret the slope and the intercept in context of the 
-data, and determine and interpret the $R^2$.
-
-10. Fit another linear model predicting total daily bike rentals from daily 
-feeling temperature. Write the linear model, interpret the slope and the intercept 
-in context of the data, and determine and interpret the $R^2$. Is temperature or 
-feeling temperature a better predictor of bike rentals? Explain your reasoning.
-
-11. Fit a model predicting total daily bike rentals from season, year, whether 
-the day is holiday or not, whether the day is a workingday or not, the weather 
-category, temperature, feeling temperature, humidity, and windspeed, as well as 
-the interaction between feeling temperature and holiday. Record adjusted $R^2$ 
-of the model.
-
-12. Write the linear models for holidays and non-holidays. Is the slope of 
-temperature the same or different for these two models? How about the slope 
-for feeling temperature? Why or why not?
-
-13. Interpret the slopes of season and feeling temperature. If the slopes are 
-different for holidays and non-holidays, make sure to interpret both. If the 
-variable has multiple levels, make sure you interpret all of the slope coefficients 
-associated with it.
-
-14. Interpret the intercept. If the intercept is different for holidays and 
-non-holidays, make sure to interpret both.
-
-15. According to this model, assuming everything else is the same, in which 
-season does the model predict total daily bike rentals to be highest and 
-which to be the lowest?
-
-16. Perform the first step of backward selection by fitting a series of models, 
-each with one explanatory variable removed from the model you fit in the previous 
-exercise. Record adjusted $R^2$s of each of these models. Which model of these 
-models, if any, gives the highest improvement over the model in the previous 
-exercise?
-
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *Now is definitely a good time to knit your document, and commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards, and review the .md document on GitHub to make sure you're happy with the final state of your work. Then go get some rest!*

---FILE: course-materials/hw-instructions/hw-06/hw-06-money-in-politics.Rmd---
@@ -0,0 +1,218 @@
+---
+title: ""HW 06 - Money in US politics""
+output: 
+  tufte::tufte_html:
+    css: ../hw.css
+    tufte_variant: ""envisioned""
+    highlight: pygments
+link-citations: yes
+---
+
+```{r include = FALSE}
+knitr::opts_chunk$set(
+  eval = FALSE,
+  out.width = ""80%"",
+  fig.asp = 0.618,
+  fig.width = 10,
+  dpi = 300
+)
+```
+
+```{r photo, fig.margin = TRUE, echo = FALSE, fig.width = 3, fig.cap = ""Photo by Sharon McCutcheon on Unsplash"", eval = TRUE}
+knitr::include_graphics(""img/sharon-mccutcheon-rItGZ4vquWk-unsplash.jpg"")
+```
+
+Every election cycle brings its own brand of excitement -- and lots of money.
+Political donations are of particular interest to political scientists and other researchers studying politics and voting patterns.
+They are also of interest to citizens who want to stay informed of how much money their candidates raise and where that money comes from.
+
+In the United States, *""only American citizens (and immigrants with green cards) can contribute to federal politics, but the American divisions of foreign companies can form political action committees (PACs) and collect contributions from their American employees.""*[^hw-06-money-in-politics-1]
+
+In this assignment we will scrape and work with data foreign connected PACs that donate to US political campaigns.
+First, we will get data foreign connected PAC contributions in the 2020 election cycle.
+Then, you will use a similar approach to get data such contributions from previous years so that we can examine trends over time.
+
+In order to complete this assignment you will need a Chrome browser with the [Selector Gadget extension](http://selectorgadget.com/) installed.
+
+# Getting started
+
+Go to the course GitHub organization and locate your homework repo, clone it in RStudio and open the R Markdown document.
+Knit the document to make sure it compiles without errors.
+
+## Warm up
+
+Before we introduce the data, let's warm up with some simple exercises.
+Update the YAML of your R Markdown file with your information, knit, commit, and push your changes.
+Make sure to commit with a meaningful commit message.
+Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd **and** md files.
+If anything is missing, commit and push again.
+
+## Packages
+
+We'll use the **tidyverse** package for much of the data wrangling and visualisation, the **robotstxt** package to check if we're allowed to scrape the data, the **rvest** package for data scraping, and the **scales** package for better formatting of labels on visualisations.
+These packages are already installed for you.
+You can load them by running the following in your Console:
+
+```{r load-packages, message = FALSE, eval = TRUE}
+library(tidyverse)
+library(robotstxt)
+library(rvest)
+library(scales)
+```
+
+## Data
+
+This assignment does not come with any prepared datasets.
+Instead you'll be scraping the data!
+
+# Exercises
+
+## Data collection via web scraping
+
+```{r opensecrets, eval=TRUE, echo=FALSE, fig.margin = TRUE}
+knitr::include_graphics(""img/opensecrets.png"")
+```
+
+The data come from [OpenSecrets.org](https://www.opensecrets.org), a *""website tracking the influence of money on U.S. politics, and how that money affects policy and citizens' lives""*.
+This website is hosted by The Center for Responsive Politics, which is a nonpartisan, independent nonprofit that *""tracks money in U.S. politics and its effect on elections and public policy.""*[^hw-06-money-in-politics-2]
+
+Before getting started, let's check that a bot has permissions to access pages on this domain.
+
+```{r paths-allowed, eval = TRUE, warning = FALSE, message = FALSE}
+library(robotstxt)
+paths_allowed(""https://www.opensecrets.org"")
+```
+
+Our goal is to scrape data for contributions in all election years Open Secrets has data for.
+Since that means repeating a task many times, let's first write a function that works on the first page.
+Confirm it works on a few others.
+Then iterate it over pages for all years.
+
+::: {.box}
+Complete the following set of steps in the `scrape-pac.R` file in the `scripts` folder of your repository.
+This file already contains some starter code to help you out.
+:::
+
+-   Write a function called `scrape_pac()` that scrapes information from the Open Secrets webpage for foreign-connected PAC contributions in a given year.
+    This function should
+
+    -   have one input: the URL of the webpage and should return a data frame.
+    -   rename variables scraped, using `snake_case` naming.
+    -   clean up the `Country of Origin/Parent Company` variable with `str_squish()`.
+    -   add a new column to the data frame for `year`. We will want this information when we ultimately have data from all years, so this is a good time to keep track of it. Our function doesn't take a year argument, but the year is embedded in the URL, so we can extract it out of there, and add it as a new column. Use the `str_sub()` function to extract the last 4 characters from the URL. You will probably want to look at the help for this function to figure out how to specify ""last 4 characters"".
+
+-   Define the URLs for 2020, 2018, and 1998 contributions.
+    Then, test your function using these URLs as inputs.
+    Does the function seem to do what you expected it to do?
+
+-   Construct a vector called `urls` that contains the URLs for each webpage that contains information on foreign-connected PAC contributions for a given year.
+
+-   Map the `scrape_pac()` function over `urls` in a way that will result in a data frame called `pac_all`.
+
+-   Write the data frame to a csv file called `pac-all.csv` in the `data` folder.
+
+*‚úÖ‚¨ÜÔ∏è If you haven't yet done so, now is definitely a good time to commit and push your changes to GitHub with an appropriate commit message (e.g. ""Data scraping complete""). Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+<div>
+
+Complete the following set of steps in the `hw-05.Rmd` file in your repository.
+
+</div>
+
+1.  In your R Markdown file, load `pac-all.csv` and report its number of observations and variables using inline code.
+
+## Data cleaning
+
+In this section we clean the `pac_all` data frame to prepare it for analysis and visualization.
+We have two goals in data cleaning:
+
+-   Separate the `country_parent` into two such that country and parent company appear in different columns for country-level analysis.
+
+-   Convert contribution amounts in `total`, `dems`, and `repubs` from character strings to numeric values.
+
+The following exercises walk you through how to make these fixes to the data.
+
+2.  Use the `separate()` function to separate `country_parent` into `country` and `parent` columns.
+    Note that country and parent company names are separated by `\` (which will need to be specified in your function) and also note that there are some entries where the `\` sign appears twice and in these cases we want to only split the value at the first occurrence of `\`.
+    This can be accomplished by setting the `extra` argument in to `""merge""` so that the cell is split into only 2 segments, e.g. we want `""Denmark/Novo Nordisk A/S""` to be split into `""Denmark""` and `""Novo Nordisk A/S""`.
+    (See help for `separate()` for more on this.) End your code chunk by printing out the top 10 rows of your data frame (if you just type the data frame name it should automatically do this for you).
+
+3.  Remove the character strings including `$` and `,` signs in the `total`, `dems`,and `repubs` columns and convert these columns to numeric.
+    End your code chunk by printing out the top 10 rows of your data frame (if you just type the data frame name it should automatically do this for you).
+    A couple hints to help you out:
+
+    -   The `$` character is a special character so it will need to be escaped.
+
+    -   Some contribution amounts are in the millions (e.g. Anheuser-Busch contributed a total of \$1,510,897 in 2008).
+        In this case we need to remove all occurrences of `,`, which we can do by using `str_remove_all()` instead of `str_remove()`.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è *Now is a good time to knit your document, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+## Data visualization and interpretation
+
+4.  Create a line plot of total contributions from all foreign-connected PACs in the Canada and Mexico over the years.
+    Once you have made the plot, write a brief interpretation of what the graph reveals.
+    Few hints to help you out:
+
+    -   Filter for only `Canada` and `Mexico`.
+    -   Calculate sum of total contributions from PACs for each year for each country by using a sequence of `group_by()` then `summarise()`.
+    -   Make a plot of total contributions (y-axis) by year (x-axis) where two lines identified by different colours represent each of Canada and Mexico.
+
+```{marginfigure}
+**Note:** The figure you create might look slightly different than this one if the data on the website has been updated recently.
+```
+
+4.  Recreate the following visualisation. Once you have made the plot, write a brief interpretation of what the graph reveals. Note that these are only UK contributions. You will need to make use of functions from the **scales** package for axis labels as well as from **ggplot2**.
+
+```{r eval = TRUE, echo = FALSE, message = FALSE, fig.fullwidth = TRUE, fig.asp = 0.5}
+pac_all <- read_csv(""data/pac-all.csv"")
+
+parse_currency <- function(x){
+  x %>%
+    # remove dollar sign
+    str_remove(""\\$"") %>%
+    # remove all occurences of commas
+    str_remove_all("","") %>%
+    # convert to numeric
+    as.numeric()
+}
+
+# plot
+pac_all %>%
+  separate(country_parent, into = c(""country"", ""parent""), sep = ""/"", extra = ""merge"") %>%
+  mutate(
+    total = parse_currency(total),
+    dems = parse_currency(dems),
+    repubs = parse_currency(repubs)
+  ) %>%
+  filter(country == ""UK"") %>%
+  group_by(year) %>%
+  summarise(
+    Democrat = sum(dems),
+    Republican = sum(repubs),
+    .groups = ""drop""
+  ) %>%
+  pivot_longer(
+    cols = c(Democrat, Republican),
+    names_to = ""party"",
+    values_to = ""amount""
+  ) %>%
+  ggplot(aes(x = year)) +
+  geom_line(aes(y = amount, group = party, color = party), size = 1) +
+  scale_color_manual(values = c(""blue"", ""red"")) +
+  scale_y_continuous(labels = dollar_format(scale = 0.000001, suffix = ""M"")) +
+  labs(
+    x = ""Year"",
+    y = ""Amount"",
+    color = ""Party"",
+    title = ""Contribution to US politics from UK-Connected PACs"",
+    subtitle = ""By party, over time""
+  ) +
+  theme_minimal()
+```
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you're happy with the final state of your work.*
+
+[^hw-06-money-in-politics-1]: Source: [Open Secrets - Foreign Connected PACs](https://www.opensecrets.org/political-action-committees-pacs/foreign-connected-pacs).
+
+[^hw-06-money-in-politics-2]: Source: [Open Secrets - About](https://www.opensecrets.org/about/).

---FILE: course-materials/hw-instructions/hw-06/scripts/scrape-pac.R---
@@ -0,0 +1,78 @@
+# load packages ----------------------------------------------------------------
+
+library(tidyverse)
+library(rvest)
+library(here) 
+
+# function: scrape_pac ---------------------------------------------------------
+
+scrape_pac <- function(url) {
+  
+  # read the page
+  page <- ___(___)
+  
+  # exract the table
+  pac <-  page %>%
+    # select node .DataTable (identified using the SelectorGadget)
+    html_node("".DataTable"") %>%
+    # parse table at node td into a data frame
+    #   table has a head and empty cells should be filled with NAs
+    html_table(""td"", header = ___, fill = ___) %>%
+    # convert to a tibble
+    as_tibble()
+  
+  # rename variables
+  pac <- pac %>%
+    # rename columns
+    rename(
+      name = ___ ,
+      country_parent = ___,
+      total = ___,
+      dems = ___,
+      repubs = ___
+    )
+  
+  # fix name
+  pac <- pac %>%
+    # remove extraneous whitespaces from the name column
+    mutate(name = ___)
+  
+  # add year
+  pac <- pac %>%
+    # extract last 4 characters of the URL and save as year
+    mutate(year = ___)
+  
+  # return data frame
+  pac
+  
+}
+
+# test function ----------------------------------------------------------------
+
+url_2020 <- ""___""
+pac_2020 <- scrape_pac(___)
+
+url_2018 <- ""___""
+pac_2018 <- scrape_pac(___)
+
+url_1998 <- ""___""
+pac_1998 <- scrape_pac(___)
+
+# list of urls -----------------------------------------------------------------
+
+# first part of url
+root <- ""https://www.opensecrets.org/political-action-committees-pacs/foreign-connected-pacs?cycle=""
+
+# second part of url (election years as a sequence)
+year <- seq(from = ___, to = ___, by = ___)
+
+# construct urls by pasting first and second parts together
+urls <- paste0(___, ___)
+
+# map the scrape_pac function over list of urls --------------------------------
+
+pac_all <- ___(___, ___)
+
+# write data -------------------------------------------------------------------
+
+write_csv(___, file = here::here(""data/pac-all.csv""))

---FILE: course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.Rmd---
@@ -0,0 +1,142 @@
+---
+title: ""HW 07 - Bike rentals in DC""
+output: 
+  tufte::tufte_html:
+    css: ../hw.css
+    tufte_variant: ""envisioned""
+    highlight: pygments
+link-citations: yes
+---
+
+```{r include = FALSE}
+knitr::opts_chunk$set(
+  eval = FALSE,
+  out.width = ""80%"",
+  fig.asp = 0.618,
+  fig.width = 10,
+  dpi = 300
+)
+```
+
+```{r photo, fig.margin = TRUE, echo = FALSE, fig.width = 3, fig.cap = ""Photo by Viktor Kern on Unsplash"", eval = TRUE}
+knitr::include_graphics(""img/viktor-kern-UdGEXZtlx-E-unsplash.jpg"")
+```
+
+Bike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return back has become automatic.
+Through these systems, user is able to easily rent a bike from a particular position and return back at another position.
+Currently, there are about over 500 bike-sharing programs around the world which is composed of over 500 thousands bicycles.
+Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues.
+
+Apart from interesting real world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for the research.
+Opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position is explicitly recorded in these systems.
+This feature turns bike sharing system into a virtual sensor network that can be used for sensing mobility in the city.
+Hence, it is expected that most of important events in the city could be detected via monitoring these data.
+
+Source: [UCI Machine Learning Repository - Bike Sharing Dataset](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)
+
+# Getting started
+
+Go to the course GitHub organization and locate your homework repo, clone it in RStudio and open the R Markdown document.
+Knit the document to make sure it compiles without errors.
+
+## Warm up
+
+Before we introduce the data, let's warm up with some simple exercises.
+Update the YAML of your R Markdown file with your information, knit, commit, and push your changes.
+Make sure to commit with a meaningful commit message.
+Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd **and** md files.
+If anything is missing, commit and push again.
+
+## Packages
+
+We'll use the **tidyverse** package for much of the data wrangling and visualisation and the data lives in the **dsbox** package.
+These packages are already installed for you.
+You can load them by running the following in your Console:
+
+```{r load-packages, message = FALSE, eval = TRUE}
+library(tidyverse)
+library(dsbox)
+```
+
+## Data
+
+The data can be found in the **dsbox** package, and it's called `dcbikeshare`.
+Since the dataset is distributed with the package, we don't need to load it separately; it becomes available to us when we load the package.
+You can find out more about the dataset by inspecting its documentation, which you can access by running `?dcbikeshare` in the Console or using the Help menu in RStudio to search for `dcbikeshare`.
+You can also find this information [here](https://rstudio-education.github.io/dsbox/reference/dcbikeshare.html).
+
+The data include daily bike rental counts (by members and casual users) of Capital Bikeshare in Washington, DC in 2011 and 2012 as well as weather information on these days.
+The original data sources are <http://capitalbikeshare.com/system-data> and <http://www.freemeteo.com>.
+
+# Exercises
+
+## Data wrangling
+
+1.  Recode the `season` variable to be a factor with meaningful level names as outlined in the codebook, with spring as the baseline level.
+
+2.  Recode the binary variables `holiday` and `workingday` to be factors with levels no (0) and yes (1), with no as the baseline level.
+
+3.  Recode the `yr` variable to be a factor with levels 2011 and 2012, with 2011 as the baseline level.
+
+4.  Recode the `weathersit` variable as 1 - clear, 2 - mist, 3 - light precipitation, and 4 - heavy precipitation, with clear as the baseline.
+
+5.  Calculate raw temperature, feeling temperature, humidity, and windspeed as their values given in the dataset multiplied by the maximum raw values stated in the codebook for each variable.
+    Instead of writing over the existing variables, create new ones with concise but informative names.
+
+6.  Check that the sum of `casual` and `registered` adds up to `cnt` for each record.
+    **Hint:** One way of doing this is to create a new column that takes on the value `TRUE` if they add up and `FALSE` if not, and then checking if all values in that column are `TRUE`s.
+    But this is only one way, you might come up with another.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+## Exploratory data analysis
+
+7.  Recreate the following visualization, and interpret it in context of the data. **Hint:** You will need to use one of the variables you created above. The temperature plotted is the feeling temperature.
+
+```{r fig.width=9, echo=FALSE}
+dcbikeshare %>%
+  mutate(atemp_raw = atemp * 50) %>%
+  ggplot(mapping = aes(x = dteday, y = cnt, color = atemp_raw)) +
+    geom_point(alpha = 0.7) +
+    labs(
+      title = ""Bike rentals in DC, 2011 and 2012"",
+      subtitle = ""Warmer temperatures associated with more bike rentals"",
+      x = ""Date"",
+      y = ""Bike renrals"",
+      color = ""Temperature (C)""
+    ) +
+  theme_minimal()
+```
+
+8.  Create a visualization displaying the relationship between bike rentals and season. Interpret the plot in context of the data.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+## Modelling
+
+9.  Fit a linear model predicting total daily bike rentals from daily temperature.
+    Write the linear model, interpret the slope and the intercept in context of the data, and determine and interpret the $R^2$.
+
+10. Fit another linear model predicting total daily bike rentals from daily feeling temperature.
+    Write the linear model, interpret the slope and the intercept in context of the data, and determine and interpret the $R^2$.
+    Is temperature or feeling temperature a better predictor of bike rentals?
+    Explain your reasoning.
+
+11. Fit a model predicting total daily bike rentals from season, year, whether the day is holiday or not, whether the day is a workingday or not, the weather category, temperature, feeling temperature, humidity, and windspeed, as well as the interaction between feeling temperature and holiday.
+    Record adjusted $R^2$ of the model.
+
+12. Write the linear models for holidays and non-holidays.
+    Is the slope of temperature the same or different for these two models?
+    How about the slope for feeling temperature?
+    Why or why not?
+
+13. Interpret the slopes of season and feeling temperature.
+    If the slopes are different for holidays and non-holidays, make sure to interpret both.
+    If the variable has multiple levels, make sure you interpret all of the slope coefficients associated with it.
+
+14. Interpret the intercept.
+    If the intercept is different for holidays and non-holidays, make sure to interpret both.
+
+15. According to this model, assuming everything else is the same, in which season does the model predict total daily bike rentals to be highest and which to be the lowest?
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you're happy with the final state of your work.*

---FILE: course-materials/hw-instructions/hw-07/hw-07-exploring-gss.Rmd---
@@ -1,143 +0,0 @@
----
-title: ""HW 09 - Exploring the GSS""
-output: 
-  tufte::tufte_html:
-    css: ../hw.css
-    tufte_variant: ""envisioned""
-    highlight: pygments
-link-citations: yes
----
-
-```{r photo, fig.margin = TRUE, echo = FALSE, fig.width=3, fig.cap=""Photo by Benny Jackson on Unsplash""}
-knitr::include_graphics(""img/benny-jackson-222664-unsplash.jpg"")
-```
-
-The GSS gathers data on contemporary American society in order to monitor and 
-explain trends and constants in attitudes, behaviors, and attributes. Hundreds 
-of trends have been tracked since 1972. In addition, since the GSS adopted 
-questions from earlier surveys, trends can be followed for up to 70 years.
-
-The GSS contains a standard core of demographic, behavioral, and attitudinal 
-questions, plus topics of special interest. Among the topics covered are civil 
-liberties, crime and violence, intergroup tolerance, morality, national spending 
-priorities, psychological well-being, social mobility, and stress and traumatic 
-events.
-
-In this assignment we analyze data from the 2016 GSS, using it to estimate values 
-of population parameters of interest about US adults.[^1]
-
-# Packages
-
-In this assignment we will work with the following packages. They should already 
-be installed in your project, and you can load them with the following:
-
-```{r load-packages, eval=TRUE, message=FALSE}
-library(tidyverse)
-library(dsbox)
-```
-
-# Data
-
-As we mentioned above, we will work with the 2016 GSS data. The dataset is called `gss`. You can find descriptions of each of the variables in the help file for the dataset, which you can access by running `?gss` in your Console.
-
-# Exercises
-
-## Part 1: Harrassment at work
-
-In 2016, the GSS added a new question on harrassment at work. The question is 
-phrased as the following.
-
->*Over the past five years, have you been harassed by your superiors or co-workers at your job, for example, have you experienced any bullying, physical or psychological abuse?*
-
-Answers to this question are stored in the `harass5` variable in our dataset.
-
-1. What are the possible responses to this question and how many respondents 
-chose each of these answers?
-
-2. What percent of the respondents for whom this question is applicable  
-(i.e. excluding `NA`s and `Does not apply`s) have been harassed by their superiors 
-or co-workers at their job.
-
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *Now is a good time to knit your document, and commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
-
-## Part 2: Time spent on email
-
-The 2016 GSS also asked respondents how many hours and minutes they spend on 
-email weekly. The responses to these questions are recorded in the `emailhr` and 
-`emailmin` variables. For example, if the response is 2.5 hrs, this would be 
-recorded as `emailhr = 2` and `emailmin = 30`.
-
-3. Create a new variable called `email` that combines these two variables to 
-reports the number of minutes the respondents spend on email weekly.
-
-4. Visualize the distribution of this new variable. Find the mean and the median 
-number of minutes respondents spend on email weekly. Is the mean or the median a 
-better measure of the typical amoung of time Americans spend on email weekly? Why?
-
-5. Create another new variable, `snap_insta` that is coded as ""Yes"" if the 
-respondent reported using any of Snapchat (`snapchat`) or Instagram (`instagrm`), 
-and ""No"" if not. If the recorded value was `NA` for both of these questions, 
-the value in your new variable should also be `NA`.
-
-6. Calculate the percentage of Yes's for `snap_insta` among those who answered 
-the question, i.e. excluding `NA`s.
-
-7. What are the possible responses to the question *Last week were you working full time, part time, going to school, keeping house, or what?* and how many respondents 
-chose each of these answers? Note that this information is stored in the `wrkstat` 
-variable.
-
-8. Fit a model predicting `email` (number of minutes per week spent on email) 
-from `educ` (number of years of education), `wrkstat`, and `snap_insta`. 
-Interpret the slopes for each of these variables.
-
-9. Create a predicted values vs. residuals plot for this model. Are there any 
-issues with the model? If yes, describe them.
-
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *Now is a good time to knit your document, and commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
-
-## Part 3: Political views and science research
-
-The 2016 GSS also asked respondents whether they think of themselves as liberal 
-or conservative (`polviews`) and whether they think science research is necessary 
-and should be supported by the federal government (`advfront`).
-
-- The question on science research is worded as follows:
-
->Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government.
-
-And possible responses to this question are Strongly agree, Agree, Disagree, 
-Strongly disagree, Dont know, No answer, Not applicable.
-
-- The question on political views is worded as follows:
-
-> We hear a lot of talk these days about liberals and conservatives. I'm going to show you a seven-point scale on which the political views that people might hold are arranged from extremely liberal--point 1--to extremely conservative--point 7. Where would you place yourself on this scale?
-
-```{marginfigure}
-Note that the levels of this variables are spelled inconsistently: ""Extremely liberal"" vs. ""Extrmly conservative"". Since this is the spelling that shows up in the data, you need to make sure this is how you spell the levels in your code.
-```
-
-And possible responses to this question are Extremely liberal, Liberal, Slightly 
-liberal, Moderate, Slghtly conservative, Conservative, Extrmly conservative. 
-Responses that were originally Don't know, No answer and Not applicable are 
-already mapped to `NA`s upon data import.
-
-10. In a new variable, recode `advfront` such that Strongly Agree and Agree are 
-mapped to `""Yes""`, and Disagree and Strongly disagree are mapped to `""No""`. The 
-remaining levels can be left as is. Don't overwrite the existing `advfront`, 
-instead pick a different, informative name for your new variable.
-
-11. In a new variable, recode `polviews` such that Extremely liberal, Liberal, 
-and Slightly liberal, are mapped to `""Liberal""`, and Slghtly conservative, 
-Conservative, and Extrmly conservative disagree are mapped to `""Conservative""`. 
-The remaining levels can be left as is. Make sure that the levels are 
-in a reasonable order. Don't overwrite the existing `polviews`, 
-instead pick a different, informative name for your new variable.
-
-12. Create a visualization that displays the relationship between these two 
-new variables and interpret it.
-
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *Now is definitely a good time to knit your document, and commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards, and review the .md document on GitHub to make sure you're happy with the final state of your work. Then go get some rest!*
-
-[^1]: Smith, Tom W, Peter Marsden, Michael Hout, and Jibum Kim. General Social Surveys, 1972-2016 [machine-readable data file] /Principal Investigator, Tom W. Smith; Co-Principal Investigator, Peter V. Marsden; Co-Principal Investigator, Michael Hout; Sponsored by National Science Foundation. -NORC ed.- Chicago: NORC at the University of Chicago [producer and distributor]. Data accessed from the GSS Data Explorer website at gssdataexplorer.norc.org.
-[^2]: [GitHub Help - Working with large files](https://help.github.com/articles/working-with-large-files/)
-

---FILE: course-materials/hw-instructions/hw-08/hw-08-exploring-gss.Rmd---
@@ -0,0 +1,152 @@
+---
+title: ""HW 08 - Exploring the GSS""
+output: 
+  tufte::tufte_html:
+    css: ../hw.css
+    tufte_variant: ""envisioned""
+    highlight: pygments
+link-citations: yes
+---
+
+```{r include = FALSE}
+knitr::opts_chunk$set(
+  eval = FALSE,
+  out.width = ""80%"",
+  fig.asp = 0.618,
+  fig.width = 10,
+  dpi = 300
+)
+```
+
+```{r photo, fig.margin = TRUE, echo = FALSE, fig.width = 3, fig.cap = ""Photo by Mauro Mora on Unsplash"", eval = TRUE}
+knitr::include_graphics(""img/mauro-mora-31-pOduwZGE-unsplash.jpg"")
+```
+
+The GSS gathers data on contemporary American society in order to monitor and explain trends and constants in attitudes, behaviours, and attributes.
+Hundreds of trends have been tracked since 1972.
+In addition, since the GSS adopted questions from earlier surveys, trends can be followed for up to 70 years.
+
+The GSS contains a standard core of demographic, behavioural, and attitudinal questions, plus topics of special interest.
+Among the topics covered are civil liberties, crime and violence, intergroup tolerance, morality, national spending priorities, psychological well-being, social mobility, and stress and traumatic events.
+
+In this assignment we analyze data from the 2016 GSS, using it to estimate values of population parameters of interest about US adults.[^hw-08-exploring-gss-1]
+
+# Getting started
+
+Go to the course GitHub organization and locate your homework repo, clone it in RStudio and open the R Markdown document.
+Knit the document to make sure it compiles without errors.
+
+## Warm up
+
+Before we introduce the data, let's warm up with some simple exercises.
+Update the YAML of your R Markdown file with your information, knit, commit, and push your changes.
+Make sure to commit with a meaningful commit message.
+Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd **and** md files.
+If anything is missing, commit and push again.
+
+## Packages
+
+We'll use the **tidyverse** package for much of the data wrangling and visualisation and the data lives in the **dsbox** package.
+These packages are already installed for you.
+You can load them by running the following in your Console:
+
+```{r load-packages, message = FALSE, eval = TRUE}
+library(tidyverse)
+library(dsbox)
+```
+
+## Data
+
+The data can be found in the **dsbox** package, and it's called `gss16`.
+Since the dataset is distributed with the package, we don't need to load it separately; it becomes available to us when we load the package.
+You can find out more about the dataset by inspecting its documentation, which you can access by running `?gss16` in the Console or using the Help menu in RStudio to search for `gss16`.
+You can also find this information [here](https://rstudio-education.github.io/dsbox/reference/gss16.html).
+
+# Exercises
+
+## Part 1: Harassment at work
+
+In 2016, the GSS added a new question on harassment at work.
+The question is phrased as the following.
+
+> *Over the past five years, have you been harassed by your superiors or co-workers at your job, for example, have you experienced any bullying, physical or psychological abuse?*
+
+Answers to this question are stored in the `harass5` variable in our dataset.
+
+1.  What are the possible responses to this question and how many respondents chose each of these answers?
+
+2.  What percent of the respondents for whom this question is applicable\
+    (i.e. excluding `NA`s and `Does not apply`s) have been harassed by their superiors or co-workers at their job.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+## Part 2: Time spent on email
+
+The 2016 GSS also asked respondents how many hours and minutes they spend on email weekly.
+The responses to these questions are recorded in the `emailhr` and `emailmin` variables.
+For example, if the response is 2.5 hrs, this would be recorded as `emailhr = 2` and `emailmin = 30`.
+
+3.  Create a new variable called `email` that combines these two variables to reports the number of minutes the respondents spend on email weekly.
+
+4.  Visualize the distribution of this new variable.
+    Find the mean and the median number of minutes respondents spend on email weekly.
+    Is the mean or the median a better measure of the typical among of time Americans spend on email weekly?
+    Why?
+
+5.  Create another new variable, `snap_insta` that is coded as ""Yes"" if the respondent reported using any of Snapchat (`snapchat`) or Instagram (`instagrm`), and ""No"" if not.
+    If the recorded value was `NA` for both of these questions, the value in your new variable should also be `NA`.
+
+6.  Calculate the percentage of Yes's for `snap_insta` among those who answered the question, i.e. excluding `NA`s.
+
+7.  What are the possible responses to the question *Last week were you working full time, part time, going to school, keeping house, or what?* and how many respondents chose each of these answers?
+    Note that this information is stored in the `wrkstat` variable.
+
+8.  Fit a model predicting `email` (number of minutes per week spent on email) from `educ` (number of years of education), `wrkstat`, and `snap_insta`.
+    Interpret the slopes for each of these variables.
+
+9.  Create a predicted values vs. residuals plot for this model.
+    Are there any issues with the model?
+    If yes, describe them.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+## Part 3: Political views and science research
+
+The 2016 GSS also asked respondents whether they think of themselves as liberal or conservative (`polviews`) and whether they think science research is necessary and should be supported by the federal government (`advfront`).
+
+-   The question on science research is worded as follows:
+
+> Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government.
+
+And possible responses to this question are Strongly agree, Agree, Disagree, Strongly disagree, Don't know, No answer, Not applicable.
+
+-   The question on political views is worded as follows:
+
+> We hear a lot of talk these days about liberals and conservatives.
+> I'm going to show you a seven-point scale on which the political views that people might hold are arranged from extremely liberal--point 1--to extremely conservative--point 7.
+> Where would you place yourself on this scale?
+
+```{marginfigure}
+**Note:** The levels of this variables are spelled inconsistently: ""Extremely liberal"" vs. ""Extrmly conservative"". Since this is the spelling that shows up in the data, you need to make sure this is how you spell the levels in your code.
+```
+
+And possible responses to this question are Extremely liberal, Liberal, Slightly liberal, Moderate, Slghtly conservative, Conservative, Extrmly conservative.
+Responses that were originally Don't know, No answer and Not applicable are already mapped to `NA`s upon data import.
+
+10. In a new variable, recode `advfront` such that Strongly Agree and Agree are mapped to `""Yes""`, and Disagree and Strongly disagree are mapped to `""No""`.
+    The remaining levels can be left as is.
+    Don't overwrite the existing `advfront`, instead pick a different, informative name for your new variable.
+
+11. In a new variable, recode `polviews` such that Extremely liberal, Liberal, and Slightly liberal, are mapped to `""Liberal""`, and Slghtly conservative, Conservative, and Extrmly conservative disagree are mapped to `""Conservative""`.
+    The remaining levels can be left as is.
+    Make sure that the levels are in a reasonable order.
+    Don't overwrite the existing `polviews`, instead pick a different, informative name for your new variable.
+
+12. Create a visualization that displays the relationship between these two new variables and interpret it.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you're happy with the final state of your work.*
+
+[^hw-08-exploring-gss-1]: Smith, Tom W, Peter Marsden, Michael Hout, and Jibum Kim.
+    General Social Surveys, 1972-2016 [machine-readable data file] /Principal Investigator, Tom W. Smith; Co-Principal Investigator, Peter V. Marsden; Co-Principal Investigator, Michael Hout; Sponsored by National Science Foundation.
+    -NORC ed.- Chicago: NORC at the University of Chicago [producer and distributor].
+    Data accessed from the GSS Data Explorer website at gssdataexplorer.norc.org.

---FILE: course-materials/hw-instructions/hw-08/hw-08-wrap-up.Rmd---
@@ -1,196 +0,0 @@
----
-title: ""HW 08 - Wrap up!""
-output: 
-  tufte::tufte_html:
-    css: ../hw.css
-    tufte_variant: ""envisioned""
-    highlight: pygments
-link-citations: yes
----
-
-```{r photo, fig.margin = TRUE, echo = FALSE, fig.width=3, fig.cap=""Photo by Kari Shea on Unsplash""}
-knitr::include_graphics(""img/kari-shea-VfWkdMue5Jc-unsplash.jpg"")
-```
-
-```{r include=FALSE}
-library(tidyverse)
-```
-
-It's almost time to wrap up the course! In this three part assignment you get to 
-practice what we learned this week, try something new, and get creative!
-
-# Getting started
-
-By now you should be familiar with instructions for getting started with a 
-new assignment in RStudio Cloud and setting up your git configuration. If not, 
-you can refer to one of the earlier assignments.
-
-# Part 1 - Bootstrapping the GSS
-
-In this part we continue our exploration of the 2016 GSS dataset from last week. 
-Remember that this dataset can be found in the **dsbox** package, and is called `gss`.
-Also remember that the GSS asked respondents how many hours and minutes they spend on 
-email weekly. The responses to these questions are recorded in the `emailhr` and 
-`emailmin` variables. For example, if the response is 2.5 hrs, this would be 
-recorded as `emailhr = 2` and `emailmin = 30`.
-
-```{marginfigure}
-Yes, this exercise is a repeat of what you did last week!
-```
-
-1. Create a new variable called `email` that combines these two variables to 
-reports the number of minutes the respondents spend on email weekly.
-
-2. Filter the data for only those who have non `NA` entries for `email`. Do not 
-overwrite the data frame (you'll need the full data later). Instead save the 
-resulting data frame with a new name.
-
-3. Describe how bootstrapping can be used to estimate the mean amount of time 
-all Americans spend on email weekly.
-
-In the following questions you will use the `infer` package to construct intervals 
-rather than writing for loops.
-
-4. Calculate a 95% bootstrap confidence interval for the mean amount of time 
-Americans spend on email weekly. Interpret this interval in context of the data, 
-reporting its endpoints in ""humanized"" units (e.g. instead of 108 minutes, report 
-1 hr and 8 minutes). If you get a result that seems a bit odd, discuss why you think 
-this might be the case.
-
-5. Would you expect a 99% confidence interval to be wider or narrower than the 
-interval you calculated above? Explain your reasoning.
-
-6. Using the bootstrap distribution from the previous Exercise 4, calculate a 99%
-bootstrap confidence interval for the mean amount of time Americans spend on email 
-weekly. Once again, use humanized units.
-
-7. And finally, construct and interpret a 90% confidence interval for the median 
-amount of time Americans spend on email weekly. Once again, use humanized units.
-
-8. What does the ""90%"" mean in your interpretation of the above interval?
-
-# Part 2 - You gotta pick a package or two
-
-But really, one is enough. Pick a package from the list below, and use it to do 
-something. If you want to use a package not on this list, that's also ok, but 
-run it by me first by posting a question about it on Pizza (so that I can confirm 
-it's not one we introduced in the class so far, the goal is to work with a new package).
-
-```{marginfigure}
-Remember, you install the package in the Console, not in your R Markdown document 
-since you don't want to keep reinstalling it every time you knit the document.
-```
-
-Your task is to install the package you pick. Depending on where the package comes from, how you install the package differs:
-    - If the package is on CRAN (Comprehensive R Archive Network), you can install it with `install.packages`. 
-    - If the package is only on Github (most likely because it is still under development), you need to use the `install_github` function. See above for details.
-
-Then, load the package. Regardless of how you installed the package you can load it with the `library` function.
-
-Finally, do something with the package. It doesn't have to be complicated. In fact, keep it simple. The goal is to try to read and understand the package documentation to be able to carry out a simple task.
-
-9. Which package are you using? State the name of the package, whether it was on CRAN or GitHub, and include the code for loading it.
-
-10. What are you doing with the package? Give me a brief narrative including code and output.
-
-## Packages on CRAN
-
-These packages can be installed with:
-
-```{r eval=FALSE}
-install.packages(""PACKAGENAME"")
-```
-
-The package manuals are linked below, however developers of the packages might have additional information on the GitHub repo of the package.
-
-- cowsay:
-	- Allows printing of character strings as messages/warnings/etc. with ASCII animals, including cats, cows, frogs, chickens, ghosts, and more.
-	- https://cran.r-project.org/web/packages/cowsay/vignettes/cowsay_tutorial.html
-- babynames:
-	- US Baby Names 1880-2015
-	- https://cran.r-project.org/web/packages/babynames/babynames.pdf
-- Lahman:
-	- Provides the tables from the 'Sean Lahman Baseball Database' as a set of R data.frames. It uses the data on pitching, hitting and fielding performance and other tables from 1871 through 2015, as recorded in the 2016 version of the database. 
-	- https://cran.r-project.org/web/packages/Lahman/Lahman.pdf
-- praise:
-	- https://cran.r-project.org/web/packages/praise/praise.pdf
-	- Build friendly R packages that praise their users if they have done something good, or they just need it to feel better.	
-- ggimage:
-	- Supports image files and graphic objects to be visualized in 'ggplot2' graphic system.
-	- https://cran.r-project.org/web/packages/ggimage/vignettes/ggimage.html
-- suncalc:
-	- R interface to 'suncalc.js' library, part of the 'SunCalc.net' project <http://suncalc.net>, for calculating sun position, sunlight phases (times for sunrise, sunset, dusk, etc.), moon position and lunar phase for the given location and time.
-	- https://cran.r-project.org/web/packages/suncalc/suncalc.pdf
-- ttbbeer
-	- An R data package of beer statistics from U.S. Department of the Treasury, Alcohol and Tobacco Tax and Trade Bureau (TTB)
-	- https://cran.r-project.org/web/packages/ttbbeer/ttbbeer.pdf
-
-## Packages on GitHub only
-
-These packages can be installed with:
-
-```{r eval=FALSE}
-library(devtools)
-install_github(""USERNAME/PACKAGENAME"")
-```
-
-`USERNAME` refers to the user name of the developer of the package. For example, for the first package listed below, `USERNAME` is `hadley` and `PACKAGENAME` is `emo`.
-
-The package manuals are linked below, however developers of the packages might have additional information on the GitHub repo of the package.
-
-- emo: 
-	- The goal of emo(ji) is to make it very easy to insert emoji into RMarkdown documents 
-	- https://github.com/hadley/emo
-- gganimate:
-	- Create easy animations with ggplot2 
-	- https://github.com/dgrtwo/gganimate
-- ggkeyboard:
-  - Plot a Keyboard Using ""ggplot2""
-  - https://github.com/sharlagelfand/ggkeyboard
-- emokid:
-	- For those times when you're having trouble expressing how you feel about your broken code.
-	- https://github.com/itsrainingdata/emokid
-- prenoms:
-	- First names given to babies in metropolitan France between 1900 and 2015.
-	- https://github.com/ThinkR-open/prenoms
-- dadjoke:
-	- The goal of dadjoke is to make you laugh in spite of yourself.
-	- https://github.com/jhollist/dadjoke/
-- cooking:
-	- Chopping, peeling, frying, and cooking various ingredients, and combining them to a delicious ragout. Also includes buying them from a local supermarket.
-	- https://github.com/krlmlr/cooking
-- kandinsky
-	- Turn any dataset into a Kandinsky paintingy
-	- https://github.com/gsimchoni/kandinsky
-- emoGG
-	- Use emoji in your ggplot2 plots.
-	- https://github.com/dill/emoGG
-- lego
-	- This R data package contains information about every Lego set manufactured from 1970 to 2015, a total of 6172 sets. 
-	- https://github.com/seankross/lego
-- bingo
-	- Generate Bingo cards
-	- https://github.com/jennybc/bingo
-- CatterPlots
-	- Plots with Cats 
-	- https://github.com/Gibbsdavidl/CatterPlots
-- BRRR
-  - BRRR extends the beepr package to include a number of rap adlibs
-  - https://github.com/brooke-watson/BRRR
-  
-  
-# Part 3 - Mirror, mirror on the wall, who's the ugliest of them all?
-
-Here is a simple plot using the `mpg` dataset, which contains information on fuel economy of cars. We're plotting highway miles per gallon vs. city miles per gallon, colored by whether the car is 
-front-wheel drive, rear wheel drive, or four-wheel drive.
-
-```{r}
-ggplot(data = mpg, aes(x = cty, y = hwy, color = drv)) +
-  geom_point()
-```
-
-```{marginfigure}
-I realize that ""ugly"" is subjective, so we're mostly looking to see if you can figure out how to change the look of a plot using help files of functions you haven't learned before.
-```
-
-11. Make this plot as ugly as possible by changing colors, background color, fonts, or anything else you can think of. You will probably want to play around with [theme options](https://ggplot2.tidyverse.org/reference/theme.html), but you can do more. You can also search online for other themes. fonts, etc. that you want to tweak.
\ No newline at end of file

---FILE: course-materials/hw-instructions/hw-09/hw-09-modeling-gss.Rmd---
@@ -0,0 +1,187 @@
+---
+title: ""HW 09 - Modeling the GSS""
+output: 
+  tufte::tufte_html:
+    css: ../hw.css
+    tufte_variant: ""envisioned""
+    highlight: pygments
+link-citations: yes
+---
+
+```{r include = FALSE}
+knitr::opts_chunk$set(
+  eval = FALSE,
+  out.width = ""80%"",
+  fig.asp = 0.618,
+  fig.width = 10,
+  dpi = 300
+)
+```
+
+```{r photo, fig.margin = TRUE, echo = FALSE, fig.width = 3, fig.cap = ""Photo Mauro Mora on Unsplash"", eval = TRUE}
+knitr::include_graphics(""img/mauro-mora-31-pOduwZGE-unsplash.jpg"")
+```
+
+In this assignment we continue our exploration of the 2016 GSS dataset from the previous homework.
+
+# Getting started
+
+Go to the course GitHub organization and locate your homework repo, clone it in RStudio and open the R Markdown document.
+Knit the document to make sure it compiles without errors.
+
+## Warm up
+
+Before we introduce the data, let's warm up with some simple exercises.
+Update the YAML of your R Markdown file with your information, knit, commit, and push your changes.
+Make sure to commit with a meaningful commit message.
+Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd **and** md files.
+If anything is missing, commit and push again.
+
+## Packages
+
+We'll use the **tidyverse** package for much of the data wrangling and visualisation, the **tidymodels** package for modeling and inference, and the data lives in the **dsbox** package.
+These packages are already installed for you.
+You can load them by running the following in your Console:
+
+```{r load-packages, message = FALSE, eval = TRUE}
+library(tidyverse)
+library(tidymodels)
+library(dsbox)
+```
+
+## Data
+
+The data can be found in the **dsbox** package, and it's called `gss16`.
+Since the dataset is distributed with the package, we don't need to load it separately; it becomes available to us when we load the package.
+You can find out more about the dataset by inspecting its documentation, which you can access by running `?gss16` in the Console or using the Help menu in RStudio to search for `gss16`.
+You can also find this information [here](https://rstudio-education.github.io/dsbox/reference/gss16.html).
+
+# Exercises
+
+## Scientific research
+
+In this section we're going to build a model to predict whether someone agrees or doesn't agree with the following statement:
+
+> Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government.
+
+The responses to the question on the GSS about this statement are in the `advfront` variable.
+
+```{marginfigure}
+It's important that you don't recode the NAs, just the remaining levels.
+```
+
+1.  Re-level the `advfront` variable such that it has two levels: `Strongly agree` and ""`Agree""` combined into a new level called `agree` and the remaining levels (except `NA`s) combined into ""`Not agree""`. Then, re-order the levels in the following order: `""Agree""` and `""Not agree""`. Finally, `count()` how many times each new level appears in the `advfront` variable.
+
+```{marginfigure}
+You can do this in various ways. One option is to use the `str_detect()` function to detect the existence of words like liberal or conservative. Note that these sometimes show up with lowercase first letters and sometimes with upper case first letters. To detect either in the `str_detect()` function, you can use ""[Ll]iberal"" and ""[Cc]onservative"". But feel free to solve the problem however you like, this is just one option!
+```
+
+2.  Combine the levels of the `polviews` variable such that levels that have the word ""liberal"" in them are lumped into a level called `""Liberal""` and those that have the word conservative in them are lumped into a level called `""Conservative""`. Then, re-order the levels in the following order: `""Conservative""` , `""Moderate""`, and `""Liberal""`. Finally, `count()` how many times each new level appears in the `polviews` variable.
+3.  Create a new data frame called `gss16_advfront` that includes the variables `advfront`, `educ`, `polviews`, and `wrkstat`. Then, use the `drop_na()` function to remove rows that contain `NA`s from this new data frame. Sample code is provided below.
+
+```{r eval=FALSE}
+gss16_advfront <- gss16 %>%
+  select(___, ___, ___, ___) %>%
+  drop_na()
+```
+
+4.  Split the data into training (75%) and testing (25%) data sets. Make sure to set a seed before you do the `initial_split()`. Call the training data `gss16_train` and the testing data `gss16_test`. Sample code is provided below. Use these specific names to make it easier to follow the rest of the instructions.
+
+```{r eval=FALSE}
+set.seed(___)
+gss16_split <- initial_split(gss16_advfront)
+gss16_train <- training(gss16_split)
+gss16_test  <- testing(gss16_split)
+```
+
+5.  Create a recipe with the following steps for predicting `advfront` from `polviews`, `wrkstat`, and `educ`.
+    Name this recipe `gss16_rec_1`.
+    (We'll create one more recipe later, that's why we're naming this recipe `_1`.) Sample code is provided below.
+
+    -   `step_other()` to pool values that occur less than 10% of the time (`threshold = 0.10`) in the `wrkstat` variable into `""Other""`.
+
+    -   `step_dummy()` to create dummy variables for `all_nominal()` variables that are predictors, i.e. `all_predictors()`
+
+```{r eval=FALSE}
+gss16_rec_1 <- recipe(___ ~ ___, data = ___) %>%
+  step_other(wrkstat, threshold = ___, other = ""Other"") %>%
+  step_dummy(all_nominal(), -all_outcomes())
+```
+
+6.  Specify a logistic regression model using `""glm""` as the engine. Name this specification `gss16_spec`. Sample code is provided below.
+
+```{r eval=FALSE}
+gss16_spec <- ___() %>%
+  set_engine(""___"")
+```
+
+7.  Build a workflow that uses the recipe you defined (`gss16_rec`) and the model you specified (`gss16_spec`). Name this workflow `gss16_wflow_1`. Sample code is provided below.
+
+```{r eval=FALSE}
+gss16_wflow_1 <- workflow() %>%
+  add_model(___) %>%
+  add_recipe(___)
+```
+
+8.  Perform 5-fold cross validation.
+    specifically,
+
+    -   split the training data into 5 folds (don't forget to set a seed first!),
+
+    -   apply the workflow you defined earlier to the folds with `fit_resamples()`, and
+
+    -   `collect_metrics()` and comment on the consistency of metrics across folds (you can get the area under the ROC curve and the accuracy for each fold by setting `summarize = FALSE` in `collect_metrics()`)
+
+    -   report the average area under the ROC curve and the accuracy for all cross validation folds `collect_metrics()`
+
+```{r eval=FALSE}
+set.seed(___)
+gss16_folds <- vfold_cv(___, v = ___)
+
+gss16_fit_rs_1 <- gss16_wflow_1 %>%
+  fit_resamples(___)
+
+collect_metrics(___, summarize = FALSE)
+collect_metrics(___)
+```
+
+9.  Now, try a different, simpler model: predict `advfront` from only `polviews` and `educ`.
+    Specifically,
+
+    -   update the recipe to reflect this simpler model specification (and name it `gss16_rec_2`),
+    -   redefine the workflow with the new recipe (and name this new workflow `gss16_wflow_2`),
+    -   perform cross validation, and
+    -   report the average area under the ROC curve and the accuracy for all cross validation folds `collect_metrics()`.
+
+10. Comment on which model performs better (one including `wrkstat`, model 1, or the one excluding `wrkstat`, model 2) on the training data based on area under the ROC curve.
+
+11. Fit both models to the testing data, plot the ROC curves for the predictions for both models, and calculate the areas under the ROC curve.
+    Does your answer to the previous exercise hold for the testing data as well?
+    Explain your reasoning.
+    Note: If you haven't yet done so, you'll need to first train your workflows on the training data with the following, and then use these fit objects to calculate predictions for the test data.
+
+```{r eval=FALSE}
+gss16_fit_1 <- gss16_wflow_1 %>%
+  fit(gss16_train)
+
+gss16_fit_2 <- gss16_wflow_2 %>%
+  fit(gss16_train)
+```
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+## Harassment at work
+
+In 2016, the GSS added a new question on harassment at work.
+The question is phrased as the following.
+
+> Over the past five years, have you been harassed by your superiors or co-workers at your job, for example, have you experienced any bullying, physical or psychological abuse?
+
+Answers to this question are stored in the `harass5` variable in our dataset.
+
+12. Create a subset of the data that only contains `Yes` and `No` answers for the harassment question. How many responses chose each of these answers?
+13. Describe how bootstrapping can be used to estimate the proportion of Americans who have been harassed by their superiors or co-workers at their job.
+14. Calculate a 95% bootstrap confidence interval for the proportion of Americans who have been harassed by their superiors or co-workers at their job. Interpret this interval in context of the data.
+15. Would you expect a 90% confidence interval to be wider or narrower than the interval you calculated above? Explain your reasoning.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you're happy with the final state of your work.*

---FILE: course-materials/hw-instructions/hw-10/hw-10-wrap-up.Rmd---
@@ -0,0 +1,201 @@
+---
+title: ""HW 10 - Wrap up!""
+output: 
+  tufte::tufte_html:
+    css: ../hw.css
+    tufte_variant: ""envisioned""
+    highlight: pygments
+link-citations: yes
+---
+
+```{r include = FALSE}
+knitr::opts_chunk$set(
+  eval = FALSE,
+  out.width = ""80%"",
+  fig.asp = 0.618,
+  fig.width = 10,
+  dpi = 300
+)
+```
+
+```{r photo, fig.margin = TRUE, echo = FALSE, fig.width = 3, fig.cap = ""Photo by Kari Shea on Unsplash"", eval = TRUE}
+knitr::include_graphics(""img/kari-shea-VfWkdMue5Jc-unsplash.jpg"")
+```
+
+It's almost time to wrap up the course!
+In this three part assignment you get to practice what we learned this week, try something new, and get creative!
+
+# Getting started
+
+Go to the course GitHub organization and locate your homework repo, clone it in RStudio and open the R Markdown document.
+Knit the document to make sure it compiles without errors.
+
+## Warm up
+
+Before we introduce the data, let's warm up with some simple exercises.
+Update the YAML of your R Markdown file with your information, knit, commit, and push your changes.
+Make sure to commit with a meaningful commit message.
+Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd **and** md files.
+If anything is missing, commit and push again.
+
+## Packages
+
+We'll use the **tidyverse** package for the first part of this assignment.
+For the second part you get to choose which package to use.
+
+```{r load-packages, message = FALSE, eval = TRUE}
+library(tidyverse)
+```
+
+# Exercises
+
+## Part 1 - Mirror, mirror on the wall, who's the ugliest of them all?
+
+Here is a simple plot using the `mpg` dataset, which contains information on fuel economy of cars.
+We're plotting highway miles per gallon vs. city miles per gallon, coloured by whether the car is front-wheel drive, rear wheel drive, or four-wheel drive.
+
+```{r}
+ggplot(data = mpg, aes(x = cty, y = hwy, color = drv)) +
+  geom_point()
+```
+
+```{marginfigure}
+I realize that ""ugly"" is subjective, so we're mostly looking to see if you can figure out how to change the look of a plot using help files of functions you haven't learned before.
+```
+
+1.  Make this plot as ugly as possible by changing colours, background color, fonts, or anything else you can think of. You will probably want to play around with [theme options](https://ggplot2.tidyverse.org/reference/theme.html), but you can do more. You can also search online for other themes, fonts, etc. that you want to tweak. Try to make it as ugly as possible, the sky is the limit!
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+## Part 2 - You gotta pick a package or two
+
+But really, one is enough.
+Pick a package from the list below, and use it to do something.
+If you want to use a package not on this list, that's also ok, but it needs to be a package we haven't used in class.
+If you start with a package and are struggling to get it to work, ask for help on Piazza or just move to another one.
+
+```{marginfigure}
+**Remember:** You *install* the package in the Console, not in the R Markdown document since you don't want to keep reinstalling it every time you knit the document.
+```
+
+Your task is to install the package you pick.
+Depending on where the package comes from, how you install the package differs:
+
+-   If the package is on CRAN (Comprehensive R Archive Network), you can install it with `install.packages`.
+-   If the package is only on Github (most likely because it is still under development), you need to use the `install_github` function.
+
+Then, load the package.
+Regardless of how you installed the package you can load it with the `library` function.
+
+Finally, do something with the package.
+It doesn't have to be complicated.
+In fact, **keep it simple**.
+The goal is for you to read and understand the package documentation to carry out a simple task.
+
+```{marginfigure}
+**Note:** For the output generated by some of these packages to show up properly, you might need to change the output of your R Markdown document from `github_document` to `html_document` in the YAML of your R Markdown document.
+```
+
+2.  Which package are you using? State the name of the package, whether it was on CRAN or GitHub, and include the code for loading it. Also include a one sentence description of what the package does.Then, do something with the package and provide a brief narrative including code and output. Also comment on difficulties you had, if any, figuring out how to use the package.
+
+### Packages on CRAN
+
+These packages can be installed with:
+
+```{r eval=FALSE}
+install.packages(""PACKAGENAME"")
+```
+
++-----------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
+| Package                                                                                       | Description                                                                                                                                                                                                                                                                                                                              |
++===============================================================================================+==========================================================================================================================================================================================================================================================================================================================================+
+| [cowsay](https://cran.r-project.org/web/packages/cowsay/vignettes/cowsay_tutorial.html)       | Allows printing of character strings as messages/warnings/etc. with ASCII animals, including cats, cows, frogs, chickens, ghosts, and more                                                                                                                                                                                               |
++-----------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [babynames](http://hadley.github.io/babynames/)                                               | US Baby Names 1880-2015                                                                                                                                                                                                                                                                                                                  |
++-----------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [dragracer](https://cran.r-project.org/web/packages/dragracer/vignettes/dragracer-intro.html) | These are data sets for the hit TV show, RuPaul's Drag Race. Data right now include episode-level data, contestant-level data, and episode-contestant-level data                                                                                                                                                                         |
++-----------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [datapasta](https://milesmcbain.github.io/datapasta/)                                         | RStudio addins and R functions that make copy-pasting vectors and tables to text painless                                                                                                                                                                                                                                                |
++-----------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [DiagrammeR](https://rich-iannone.github.io/DiagrammeR/)                                      | Graph/Network Visualization                                                                                                                                                                                                                                                                                                              |
++-----------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [janeaustenr](https://github.com/juliasilge/janeaustenr)                                      | Full texts for Jane Austen's 6 completed novels, ready for text analysis. These novels are ""Sense and Sensibility"", ""Pride and Prejudice"", ""Mansfield Park"", ""Emma"", ""Northanger Abbey"", and ""Persuasion""                                                                                                                                |
++-----------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [ggimage](https://cran.r-project.org/web/packages/ggimage/vignettes/ggimage.html)             | Supports image files and graphic objects to be visualized in 'ggplot2' graphic system                                                                                                                                                                                                                                                    |
++-----------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [gganimate](https://github.com/dgrtwo/gganimate)                                              | Create easy animations with ggplot2                                                                                                                                                                                                                                                                                                      |
++-----------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [gt](https://gt.rstudio.com/)                                                                 | Easily Create Presentation-Ready Display Tables                                                                                                                                                                                                                                                                                          |
++-----------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [leaflet](https://rstudio.github.io/leaflet/)                                                 | Create Interactive Web Maps with the JavaScript 'Leaflet' Library                                                                                                                                                                                                                                                                        |
++-----------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [praise](https://cran.r-project.org/web/packages/praise/praise.pdf)                           | Build friendly R packages that praise their users if they have done something good, or they just need it to feel better                                                                                                                                                                                                                  |
++-----------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [plotly](https://plotly-r.com/)                                                               | Create interactive web graphics from ggplot2 graphs and/or a custom interface to the JavaScript library plotly.js inspired by the grammar of graphics                                                                                                                                                                                    |
++-----------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [suncalc](https://cran.r-project.org/web/packages/suncalc/suncalc.pdf)                        | R interface to `suncalc.js` library, part of the [SunCalc.net project](http://suncalc.net), for calculating sun position, sunlight phases (times for sunrise, sunset, dusk, etc.), moon position and lunar phase for the given location and time                                                                                         |
++-----------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [schrute](https://bradlindblad.github.io/schrute/)                                            | The complete scripts from the American version of the Office television show in tibble format                                                                                                                                                                                                                                            |
++-----------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [statebins](https://cran.r-project.org/web/packages/statebins/statebins.pdf)                  | The cartogram heatmaps generated by the included methods are an alternative to choropleth maps for the United States and are based on work by the Washington Post graphics department in their report on [""The states most threatened by trade""](http://www.washingtonpost.com/wp-srv/special/business/states-most-threatened-by-trade/) |
++-----------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [ttbbeer](https://cran.r-project.org/web/packages/ttbbeer/ttbbeer.pdf)                        | An R data package of beer statistics from U.S. Department of the Treasury, Alcohol and Tobacco Tax and Trade Bureau (TTB)                                                                                                                                                                                                                |
++-----------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [ukbabynames](https://cran.r-project.org/web/packages/ukbabynames/ukbabynames.pdf)            | Full listing of UK baby names occurring more than three times per year between 1996 and 2015, and rankings of baby name popularity by decade from 1904 to 1994                                                                                                                                                                           |
++-----------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
+
+### Packages on GitHub only
+
+These packages can be installed with:
+
+```{r eval=FALSE}
+library(devtools)
+install_github(""USERNAME/PACKAGENAME"")
+```
+
+`USERNAME` refers to the user name of the developer of the package.
+For example, for the first package listed below, `USERNAME` is `hadley` and `PACKAGENAME` is `emo`.
+
++------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
+| Package                                                    | Description                                                                                                                                              |
++============================================================+==========================================================================================================================================================+
+| [bingo](https://github.com/jennybc/bingo)                  | Generate Bingo cards                                                                                                                                     |
++------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [BRRR](https://github.com/brooke-watson/BRRR)              | BRRR extends the beepr package to include a number of rap adlibs                                                                                         |
++------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [CatterPlots](https://github.com/Gibbsdavidl/CatterPlots)  | Plots with Cats                                                                                                                                          |
++------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [cooking](https://github.com/krlmlr/cooking)               | Chopping, peeling, frying, and cooking various ingredients, and combining them to a delicious ragout. Also includes buying them from a local supermarket |
++------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [dadjoke](https://github.com/jhollist/dadjoke/)            | The goal of dadjoke is to make you laugh in spite of yourself                                                                                            |
++------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [emo](https://github.com/hadley/emo)                       | The goal of emo(ji) is to make it very easy to insert emoji into RMarkdown documents                                                                     |
++------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [emoGG](https://github.com/dill/emoGG)                     | Use Emoji in ggplot2                                                                                                                                     |
++------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [emokid](https://github.com/itsrainingdata/emokid)         | For those times when you're having trouble expressing how you feel about your broken code                                                                |
++------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [flametree](https://flametree.djnavarro.net/)              | The goal of flametree is to make pretty pictures                                                                                                         |
++------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [ggbarf](https://github.com/karawoo/ggbarf)                | Make isotype bars using the vomit emoji                                                                                                                  |
++------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [ggCyberPunk](https://github.com/delabj/ggCyberPunk)       | Create Cyberpunk area and line plots                                                                                                                     |
++------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [ggiraph](https://davidgohel.github.io/ggiraph/index.html) | Create interactive ggplot2 graphics using htmlwidgets                                                                                                    |
++------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [ggkeyboard](https://github.com/sharlagelfand/ggkeyboard)  | Plot a Keyboard Using ggplot2                                                                                                                            |
++------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [jasmines](https://jasmines.djnavarro.net/)                | Make generative art                                                                                                                                      |
++------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [kandinsky](https://github.com/gsimchoni/kandinsky)        | Turn any dataset into a Kandinsky painting                                                                                                               |
++------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [lego](https://github.com/seankross/lego)                  | This R data package contains information about every Lego set manufactured from 1970 to 2015, a total of 6172 sets                                       |
++------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [linkinpark](https://github.com/delabj/linkinpark)         | Data package that contains a few different datasets about the band                                                                                       |
++------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [prenoms](https://github.com/ThinkR-open/prenoms)          | First names given to babies in metropolitan France between 1900 and 2015                                                                                 |
++------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
+| [raybonsai](http://www.raybonsai.com/)                     | Generate 3D procedural trees in R, rendered with rayrender! Procedural generation code based on the flametree package by Danielle Navarro.               |
++------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you're happy with the final state of your work.*

---FILE: course-materials/lab-instructions/lab-01/lab-01-hello-r.Rmd---
@@ -18,117 +18,92 @@ The main goal of this lab is to introduce you to R and RStudio, which we will be
 git is a version control system (like ""Track Changes"" features from Microsoft Word on steroids) and GitHub is the home for your Git-based projects on the internet (like DropBox but much, much better).
 ```
 
-An additional goal is to introduce you to git and GitHub, which is the collaboration and version control system that we will be using throughout the course.
+An additional goal is to introduce you to Git and GitHub, which is the collaboration and version control system that we will be using throughout the course.
 
 As the labs progress, you are encouraged to explore beyond what the labs dictate; a willingness to experiment will make you a much better programmer.
 Before we get to that stage, however, you need to build some basic fluency in R.
 Today we begin with the fundamental building blocks of R and RStudio: the interface, reading in data, and basic commands.
 
 And to make versioning simpler, this is a solo lab.
 Additionally, we want to make sure everyone gets a significant amount of time at the steering wheel.
-Next week you'll learn about collaborating on GitHub and produce a single lab report for your team.
+In future labs you'll learn about collaborating on GitHub and produce a single lab report for your team.
 
-## Getting started
+# Connecting GitHub and RStudio Cloud
 
-Each of your assignments will begin with the following steps.
-You saw these once in class yesterday, they're outlined in detail here again.
-Going forward each lab will start with a ""Getting started"" section but details will be a bit more sparse than this.
-You can always refer back to this lab for a detailed list of the steps involved for getting started with an assignment.
+You should have already received an invitation to join the GitHub organization for this course.
+You need to accept the invitation before moving on to the next step.
 
-The following screencast also walks you through these steps:
+To connect your RStudio and GitHub accounts by following the steps below:
 
-::: {style=""position:relative;height:0;padding-bottom:40%""}
-<iframe width=""600"" height=""320"" src=""https://www.youtube.com/embed/8Ta_SJq3MrU"" frameborder=""0"" allow=""autoplay; encrypted-media"" allowfullscreen>
+-   Click on your name on the top right corner to open the right menu.
+-   Then, click on Authentication.
 
-</iframe>
-:::
-
--   Click on the assignment link that you should have received in your email to create your GitHub repository (which we'll refer to as ""repo"" going forward) for the assignment. This repo contains a template you can build on to complete your assignment.
-
-```{r clone-repo-link, fig.margin = TRUE, echo = FALSE, fig.width=3}
-knitr::include_graphics(""img/clone-repo-link.png"")
+```{r github-auth-1, echo = FALSE}
+knitr::include_graphics(""img/github-auth-1.png"")
 ```
 
--   On GitHub, click on the green **Clone or download** button, select **Use HTTPS** (this might already be selected by default, and if it is, you'll see the text **Clone with HTTPS** as in the image below). Click on the clipboard icon to copy the repo URL.
+-   In the Authentication window, check the box for *Enabled*.
 
-```{r new-project-from-gh, fig.margin = TRUE, echo = FALSE, fig.width=3}
-knitr::include_graphics(""img/new-project-from-gh.png"")
+```{r github-auth-2, echo = FALSE}
+knitr::include_graphics(""img/github-auth-2.png"")
 ```
 
--   Go to RStudio Cloud and into the course workspace. Create a **New Project from Git Repo**. You will need to click on the down arrow next to the **New Project** button to see this option.
+-   In the next window, click on the green box that says ""Authorize rstudio"".
 
-```{r paste-gh-repo-url, fig.margin = TRUE, echo = FALSE, fig.width=5}
-knitr::include_graphics(""img/paste-gh-repo-url.png"")
+```{r github-auth-3, echo = FALSE}
+knitr::include_graphics(""img/github-auth-3.png"")
 ```
 
--   Copy and paste the URL of your assignment repo into the dialog box:
+-   Back in the Authentication window, check the box for *Private repo access also enabled*, and once again, on the green box that says ""Authorize rstudio"" in the next window. At this point you should also make sure that the course organization shows up for you under *Organization access*. If it does not, this means you have not yet accepted the GitHub invitation to join the course, and you should go back and do that.
 
--   Hit OK, and you're good to go!
+```{r github-auth-4, echo = FALSE}
+knitr::include_graphics(""img/github-auth-4.png"")
+```
 
-### Packages
+-   Once you're done, both of these boxes should be checked.
 
-In this lab we will work with two packages: `datasauRus` which contains the dataset, and `tidyverse` which is a collection of packages for doing data analysis in a ""tidy"" way.
+```{r github-auth-5, echo = FALSE}
+knitr::include_graphics(""img/github-auth-5.png"")
+```
 
-Install these packages by running the following in the console.
+-   To confirm that you've successfully linked up your GitHub and RStudio Cloud accounts, [GitHub settings \> Applications](https://github.com/settings/applications). You should see RStudio listed as an authorized app under *Authorized OAuth Apps*. If you don't this is a good time to ask a question.
 
-```{r eval = FALSE}
-install.packages(""tidyverse"")
-install.packages(""datasauRus"")
+```{r github-auth-6, echo = FALSE}
+knitr::include_graphics(""img/github-auth-6.png"")
 ```
 
-Now that the necessary packages are installed, you should be able to Knit your document and see the results.
+# Getting started
 
-If you'd like to run your code in the Console as well you'll also need to load the packages there.
-To do so, run the following in the console.
+Each of your assignments will begin with the following steps.
+You saw these once in class yesterday, they're outlined in detail here again.
+Going forward each lab will start with a ""Getting started"" section but details will be a bit more sparse than this.
+You can always refer back to this lab for a detailed list of the steps involved for getting started with an assignment.
 
-```{r message=FALSE}
-library(tidyverse) 
-library(datasauRus)
-```
+-   Click on the assignment link that you should have received in your email to create your GitHub repository (which we'll refer to as ""repo"" going forward) for the assignment. This repo contains a template you can build on to complete your assignment.
 
-Note that the packages are also loaded with the same commands in your R Markdown document.
+```{r clone-repo-link, fig.margin = TRUE, echo = FALSE, fig.width=3}
+knitr::include_graphics(""img/clone-repo-link.png"")
+```
 
-### Housekeeping
+-   On GitHub, click on the green **Clone or download** button, select **Use HTTPS** (this might already be selected by default, and if it is, you'll see the text **Clone with HTTPS** as in the image below). Click on the clipboard icon to copy the repo URL.
 
-```{marginfigure}
-Your email address is the address tied to your GitHub account and your name should be first and last name.
+```{r new-project-from-gh, fig.margin = TRUE, echo = FALSE, fig.width=3}
+knitr::include_graphics(""img/new-project-from-gh.png"")
 ```
 
-Before we can get started we need to take care of some required housekeeping.
-Specifically, we need to configure your git so that RStudio can communicate with GitHub.
-This requires two pieces of information: your email address and your name.
-
-To do so, run the following:
+-   Go to RStudio Cloud and into the course workspace. Create a **New Project from Git Repo**. You will need to click on the down arrow next to the **New Project** button to see this option.
 
-```{r eval=FALSE}
-usethis::use_git_config(user.name = ""your name"", user.email = ""your email"")
+```{r paste-gh-repo-url, fig.margin = TRUE, echo = FALSE, fig.width=5}
+knitr::include_graphics(""img/paste-gh-repo-url.png"")
 ```
 
-For example, for me this looks like:
+-   Copy and paste the URL of your assignment repo into the dialog box:
 
-```{r eval=FALSE}
-usethis::use_git_config(user.name = ""Mine Cetinkaya-Rundel"", user.email = ""cetinkaya.mine@gmail.com"")
-```
+-   Hit OK, and you're good to go!
 
 ## Warm up
 
 Before we introduce the data, let's warm up with some simple exercises.
-The following video is an overview of some of these warm-up exercises.
-
-::: {style=""position:relative;height:0;padding-bottom:40%""}
-<iframe width=""600"" height=""320"" src=""https://www.youtube.com/embed/XE8h8jIyu04"" frameborder=""0"" allow=""autoplay; encrypted-media"" allowfullscreen>
-
-</iframe>
-:::
-
-### Project name
-
-Currently your project is called *Untitled Project*.
-Update the name of your project to be ""Lab 01 - Hello R"".
-
-```{r untitled-project, fig.fullwidth=TRUE, echo = FALSE}
-knitr::include_graphics(""img/untitled-project.png"")
-```
 
 ```{marginfigure}
 The top portion of your R Markdown file (between the three dashed lines) is called YAML. It stands for ""YAML Ain't Markup Language"". It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.
@@ -174,12 +149,20 @@ This might feel cumbersome.
 Bear with me... We *will* teach you how to save your password so you don't have to enter it every time.
 But for this one assignment you'll have to manually enter each time you push in order to gain some experience with it.
 
-### Thought exercise
+## Packages
+
+In this lab we will work with two packages: **datasauRus** which contains the dataset we'll be using and **tidyverse** which is a collection of packages for doing data analysis in a ""tidy"" way.
+These packages are already installed for you.
+You can load the packages by running the following in the Console.
 
-For which of the above steps (changing project name, making updates to the document, committing, and pushing changes) do you need to have an internet connection?
-Discuss with your classmates.
+```{r message=FALSE}
+library(tidyverse) 
+library(datasauRus)
+```
 
-## The data
+Note that the packages are also loaded with the same commands in your R Markdown document.
+
+## Data
 
 ```{marginfigure}
 If it's confusing that the data frame is called `datasaurus_dozen` when it contains 13 datasets, you're not alone! Have you heard of a [baker's dozen](https://en.wikipedia.org/wiki/Dozen#Baker's_dozen)?
@@ -193,9 +176,9 @@ To find out more about the dataset, type the following in your Console: `?datasa
 A question mark before the name of an object will always bring up its help file.
 This command must be ran in the Console.
 
-## Exercises
+# Exercises
 
-1.  Based on the help file, how many rows and how many columns does the `datasaurus_dozen` file have? What are the variables included in the data frame? Add your responses to your lab report. When you're done, commit your changes with the commit message ""Added answer for Ex 1"", and push.
+1.  Based on the help file, how many rows and how many columns does the `datasaurus_dozen` file have? What are the variables included in the data frame? Add your responses to your lab report.
 
 Let's take a look at what these datasets are.
 To do so we can make a *frequency table* of the dataset variable:
@@ -214,6 +197,8 @@ The original Datasaurus (`dino`) was created by Alberto Cairo in [this great blo
 The other Dozen were generated using simulated annealing and the process is described in the paper *Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics* through Simulated Annealing by Justin Matejka and George Fitzmaurice.
 In the paper, the authors simulate a variety of datasets that have the same summary statistics as the Datasaurus but have very different distributions.
 
+üß∂ ‚úÖ ‚¨ÜÔ∏è *Knit, commit, and push your changes to GitHub with the commit message ""Added answer for Ex 1"". Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
 2.  Plot `y` vs. `x` for the `dino` dataset. Then, calculate the correlation coefficient between `x` and `y` for this dataset.
 
 Below is the code you will need to complete this exercise.
@@ -268,21 +253,21 @@ dino_data %>%
   summarize(r = cor(x, y))
 ```
 
-*This is a good place to pause, commit changes with the commit message ""Added answer for Ex 2"", and push.*
+üß∂ ‚úÖ ‚¨ÜÔ∏è *Knit, commit, and push your changes to GitHub with the commit message ""Added answer for Ex 2"". Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
 
 3.  Plot `y` vs. `x` for the `star` dataset. You can (and should) reuse code we introduced above, just replace the dataset name with the desired dataset. Then, calculate the correlation coefficient between `x` and `y` for this dataset. How does this value compare to the `r` of `dino`?
 
-*This is another good place to pause, commit changes with the commit message ""Added answer for Ex 3"", and push.*
+üß∂ ‚úÖ ‚¨ÜÔ∏è *This is another good place to pause, knit, commit changes with the commit message ""Added answer for Ex 3"", and push. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
 
 4.  Plot `y` vs. `x` for the `circle` dataset. You can (and should) reuse code we introduced above, just replace the dataset name with the desired dataset. Then, calculate the correlation coefficient between `x` and `y` for this dataset. How does this value compare to the `r` of `dino`?
 
-*You should pause again, commit changes with the commit message ""Added answer for Ex 4"", and push.*
+üß∂ ‚úÖ ‚¨ÜÔ∏è *You should pause again, commit changes with the commit message ""Added answer for Ex 4"", and push. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
 
 ```{marginfigure}
 Facet by the dataset variable, placing the plots in a 3 column grid, and don't add a legend.
 ```
 
-5. Finally, let's plot all datasets at once. In order to do this we will make use of facetting.
+5.  Finally, let's plot all datasets at once. In order to do this we will make use of faceting.
 
 ```{r all-viz, eval=FALSE, fig.fullwidth=TRUE}
 ggplot(datasaurus_dozen, aes(x = x, y = y, color = dataset))+
@@ -340,4 +325,4 @@ Play around with these until you're happy with the look.
 Not sure how to use emojis on your computer? Maybe a teammate can help? Or you can ask your TA as well!
 ```
 
-*Yay, you're done! Commit all remaining changes, use the commit message ""Done with Lab 1! `r emo::ji(""muscle"")`"", and push. Before you wrap up the assignment, make sure all documents are updated on your GitHub repo.*
+üß∂ ‚úÖ ‚¨ÜÔ∏è *Yay, you're done! Commit all remaining changes, use the commit message ""Done with Lab 1!* üí™*"", and push. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards. Before you wrap up the assignment, make sure all documents are updated on your GitHub repo.*

---FILE: course-materials/lab-instructions/lab-02/lab-02-plastic-waste.Rmd---
@@ -8,44 +8,39 @@ output:
 link-citations: yes
 ---
 
-```{r include=FALSE}
+```{r include = FALSE}
 knitr::opts_chunk$set(eval = FALSE)
 ```
 
-```{marginfigure}
-**A note on expectations: ** For each exercise and on your own question you 
-answer include any relevant output (tables, summary statistics, plots) in your 
-answer. Doing this is easy! Just place any relevant R code in a code chunk, 
-and hit Knit HTML.
-```
-
 Plastic pollution is a major and growing problem, negatively affecting oceans and wildlife health.
 [Our World in Data](https://ourworldindata.org/plastic-pollution) has a lot of great data at various levels including globally, per country, and over time.
 For this lab we focus on data from 2010.
 
-Additionally, National Geographic recently ran a data visualization communication contest on plastic waste as seen [here](https://www.nationalgeographic.org/funding-opportunities/innovation-challenges/plastic/dataviz/).
+Additionally, National Geographic ran a data visualization communication contest on plastic waste as seen [here](https://www.nationalgeographic.org/funding-opportunities/innovation-challenges/plastic/dataviz/).
 
-Learning goals for this lab are:
+# Learning goals
 
--   Visualize numerical and categorical data.
--   Recreate visualizations.
--   Get more practice using with Git and GitHub.
+-   Visualising numerical and categorical data and interpreting visualisations
+-   Recreating visualizations
+-   Getting more practice using with R, RStudio, Git, and GitHub
 
-## Getting started
+# Getting started
 
-```{marginfigure}
-**IMPORTANT:** If there is no GitHub repo created for you for this assignment, it means I didn't have your GitHub username as of when I assigned the homework. Please let me know your GitHub username asap, and I can create your repo.
+Go to the course GitHub organization and locate your assignment repo, which should be named `lab-02-plastic-waste-YOUR_GITHUB_USERNAME`.
+If you're in the right place, it should look like the following.
+
+```{r echo=FALSE, eval=TRUE}
+knitr::include_graphics(""img/repo-begin.png"")
 ```
 
-Go to the course GitHub organization and locate your Lab 02 repo, which should be named `lab-02-plastic-waste-YOUR_GITHUB_USERNAME`.
 Grab the URL of the repo, and clone it in RStudio.
-Refer to Lab 01 if you would like to see step-by-step instructions for cloning a repo into an RStudio project.
+Refer to [HW 00](https://ids-s1-20.github.io/homework/hw-00/hw-00-pet-names.html) if you would like to see step-by-step instructions for cloning a repo into an RStudio project.
 
-First, open the R Markdown document `lab-02-plastic-waste.Rmd` and Knit it.
+First, open the R Markdown document `lab-02.Rmd` and Knit it.
 Make sure it compiles without errors.
 The output will be in the file markdown `.md` file with the same name.
 
-### Packages
+## Packages
 
 We'll use the **tidyverse** package for this analysis.
 Run the following code in the Console to load this package.
@@ -54,29 +49,7 @@ Run the following code in the Console to load this package.
 library(tidyverse)
 ```
 
-### Housekeeping
-
-```{marginfigure}
-Your email address is the address tied to your GitHub account and your name should be first and last name.
-```
-
-Before we can get started we need to take care of some required housekeeping.
-Specifically, we need to configure your git so that RStudio can communicate with GitHub.
-This requires two pieces of information: your email address and your name.
-
-To do so, run the following:
-
-```{r eval=FALSE}
-usethis::use_git_config(user.name = ""your name"", user.email = ""your email"")
-```
-
-For example, for me this looks like:
-
-```{r eval=FALSE}
-usethis::use_git_config(user.name = ""Mine Cetinkaya-Rundel"", user.email = ""cetinkaya.mine@gmail.com"")
-```
-
-## The data
+## Data
 
 The dataset for this assignment can be found as a csv file in the `data` folder of your repository.
 You can read it in using the following.
@@ -98,7 +71,18 @@ The variable descriptions are as follows:
 -   `coastal_pop`: Number of individuals living on/near coast
 -   `total_pop`: Total population according to Gapminder
 
-## Exercises
+# Warm up
+
+-   Recall that RStudio is divided into four panes. Without looking, can you name them all and briefly describe their purpose?
+-   Verify that the dataset has loaded into the Environment. How many observations are in the dataset? Clicking on the dataset in the Environment will allow you to inspect it more carefully. Alternatively, you can type `View(plastic_waste)` into the Console to do this.
+
+```{marginfigure}
+**Hint:** If you're not sure, run the command `?NA` which will lead you to the documentation.
+```
+
+-   Have a quick look at the data and notice that there are cells taking the value `NA` -- what does this mean?
+
+# Exercises
 
 Let's start by taking a look at the distribution of plastic waste per capita in 2010.
 
@@ -121,7 +105,7 @@ You might consider doing some research on Trinidad and Tobago to see why plastic
 1.  Plot, using histograms, the distribution of plastic waste per capita faceted by continent. What can you say about how the continents compare to each other in terms of their plastic waste per capita?
 
 ```{marginfigure}
-From this point onwards the plots / output of the code won't be printed in the lab, but you can run the code and view the results yourself.
+**NOTE:** From this point onwards the plots and the output of the code are not displayed in the lab instructions, but you can and should the code and view the results yourself.
 ```
 
 Another way of visualizing numerical data is using density plots.
@@ -131,7 +115,7 @@ ggplot(data = plastic_waste, aes(x = plastic_waste_per_cap)) +
   geom_density()
 ```
 
-And compare distributions across continents by coloring density curves by continent.
+And compare distributions across continents by colouring density curves by continent.
 
 ```{r plastic_waste_per_cap-dens-color}
 ggplot(data = plastic_waste, 
@@ -140,7 +124,7 @@ ggplot(data = plastic_waste,
   geom_density()
 ```
 
-The resulting plot may be a little difficult to read, so let's also fill the curves in with colors as well.
+The resulting plot may be a little difficult to read, so let's also fill the curves in with colours as well.
 
 ```{r plastic_waste_per_cap-dens-color-fill}
 ggplot(data = plastic_waste, 
@@ -150,7 +134,7 @@ ggplot(data = plastic_waste,
   geom_density()
 ```
 
-The overlapping colors make it difficult to tell what's happening with the distributions in continents plotted first, and hence coverred by continents plotted over them.
+The overlapping colours make it difficult to tell what's happening with the distributions in continents plotted first, and hence covered by continents plotted over them.
 We can change the transparency level of the fill color to help with this.
 The `alpha` argument takes values between 0 and 1: 0 is completely transparent and 1 is completely opaque.
 There is no way to tell what value will work best, so you just need to try a few.
@@ -169,7 +153,7 @@ This still doesn't look great...
 
 2.  Describe why we defined the `color` and `fill` of the curves by mapping aesthetics of the plot but we defined the `alpha` level as a characteristic of the plotting geom.
 
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *Now is a good time to commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+üß∂ ‚úÖ ‚¨ÜÔ∏è *Now is a good time to knit your document and commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
 
 And yet another way to visualize this relationship is using side-by-side box plots.
 
@@ -180,28 +164,37 @@ ggplot(data = plastic_waste,
   geom_boxplot()
 ```
 
-1.  Learn something new: violin plots! Read about them at <http://ggplot2.tidyverse.org/reference/geom_violin.html>, and convert your side-by-side box plots from the previous task to violin plots. What do the violin plots reveal that box plots do not? What features are apparent in the box plots but not in the violin plots?
+1.  Convert your side-by-side box plots from the previous task to [violin plots](http://ggplot2.tidyverse.org/reference/geom_violin.html). What do the violin plots reveal that box plots do not? What features are apparent in the box plots but not in the violin plots?
 
 ```{marginfigure}
-Remember that we use `geom_point()` to make scatterplots.
+**Remember:** We use `geom_point()` to make scatterplots.
 ```
 
 1.  Visualize the relationship between plastic waste per capita and mismanaged plastic waste per capita using a scatterplot.
     Describe the relationship.
 
-2.  Color the points in the scatterplot by continent.
+2.  Colour the points in the scatterplot by continent.
     Does there seem to be any clear distinctions between continents with respect to how plastic waste per capita and mismanaged plastic waste per capita are associated?
 
 3.  Visualize the relationship between plastic waste per capita and total population as well as plastic waste per capita and coastal population.
+    You will need to make two separate plots.
     Do either of these pairs of variables appear to be more strongly linearly associated?
 
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *Now is another good time to commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+üß∂ ‚úÖ ‚¨ÜÔ∏è *Now is another good time to knit your document and commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+# Wrapping up
+
+We don't expect you to complete all of the exercises within the hour reserved for the live workshop.
+Ideally, you should have got to this point.
+If you still have some time left, move on to the remaining exercises below.
+If not, you should find a time to meet with your team and complete them after the workshop.
+If you haven't had time to finish the exercises above, please ask for help before you leave!
 
 ```{marginfigure}
-Hint: The x-axis is a calculated variable. One country with plastic waste per capita over 3 kg/day has been filtered out. And the colors are from the viridis color palette. Take a look at the functions starting with `scale_color_viridis_*`.
+**Hint:** The x-axis is a calculated variable. One country with plastic waste per capita over 3 kg/day has been filtered out. And the data are not only represented with points on the plot but also a smooth curve. The term ""smooth"" should help you [pick which geom to use](https://ggplot2.tidyverse.org/reference/index.html#section-geoms).
 ```
 
-1  Recreate the following plot, and interpret what you see in context of the data.
+1.  Recreate the following plot, and interpret what you see in context of the data.
 
 ```{r echo=FALSE, message=FALSE, eval=TRUE, warning=FALSE}
 plastic_waste %>% 
@@ -219,4 +212,10 @@ plastic_waste %>%
     theme_minimal()
 ```
 
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *Commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you're happy with the final state of your work.*
+
+Once you're done, check to make sure your latest changes are on GitHub and that you have a green indicator for the automated check for your R Markdown document knitting.
+
+```{r echo=FALSE, eval=TRUE}
+knitr::include_graphics(""img/repo-end.png"")
+```

---FILE: course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.Rmd---
@@ -8,8 +8,8 @@ output:
 link-citations: yes
 ---
 
-```{r setup, include=FALSE}
-knitr::opts_chunk$set(eval = FALSE)
+```{r setup, include = FALSE}
+knitr::opts_chunk$set(eval = TRUE)
 ```
 
 In January 2017, Buzzfeed published an article on why Nobel laureates show immigration is so important for American science.
@@ -18,46 +18,151 @@ In the article they show that while most living Nobel laureates in the sciences
 This is one reason why scientific leaders say that immigration is vital for progress.
 In this lab we will work with the data from this article to recreate some of their visualizations as well as explore new questions.
 
-The learning goals of this lab are:
+# Learning goals
 
--   Manipulate and transform data to prepare it for visualization.
--   Recreate visualizations.
--   Summarise data.
--   Get more practice working as a team.
+-   Collaborating on GitHub and resolving merge conflicts
+-   Replicating published results
+-   Data wrangling and visualisation
 
-## Workflow
+# Lab prep
 
-This is the first week you're working in teams.
-You have a team repository that each member of the team has access to.
-You can all push to this repository, but **for this week only** we will keep things simple and ask that the **team lead for the week is the only one who pushes** while others work on together with them.
+You have two tasks you should complete before the lab:
 
-Starting next week we'll show you how you can all collectively work in a repo, the (mini) chaos that might result in (called a merge conflict), and how to resolve it.
+-   **Task 1:** Read the Buzzfeed article titled [*These Nobel Prize Winners Show Why Immigration Is So Important For American Science*](https://www.buzzfeednews.com/article/peteraldhous/immigration-and-science)*.* We will replicate this analysis in the workshop so it's crucial that you're familiar with it ahead of time.
+-   **Task 2:** Read about merge conflicts below. The merge conflict exercise we'll start with during the lab will assume that you have this background information.
 
-## Getting started
+## Merges and merge conflicts
 
-Go to the course GitHub organization and locate your Lab 03 repo, which should be named `lab-03-nobel-winners-YOUR_TEAMNAME`.
-Grab the URL of the repo, and clone it in RStudio.
-Refer to Lab 01 if you would like to see step-by-step instructions for cloning a repo into an RStudio project.
+This is the second week you're working in teams, so we're going to make things a little more interesting and let all of you make changes and push those changes to your team repository.
+Sometimes things will go swimmingly, and sometimes you'll run into merge conflicts.
+So our first task today is to walk you through a merge conflict!
+
+-   Pushing to a repo replaces the code on GitHub with the code you have on your computer.
+-   If a collaborator has made a change to your repo on GitHub that you haven't incorporated into your local work, GitHub will stop you from pushing to the repo because this could overwrite your collaborator's work!
+-   So you need to explicitly ""merge"" your collaborator's work before you can push.
+-   If your and your collaborator's changes are in different files or in different parts of the same file, git merges the work for you automatically when you \*pull\*.
+-   If you both changed the same part of a file, git will produce a \*\*merge conflict\*\* because it doesn't know how which change you want to keep and which change you want to overwrite.
+
+Git will put conflict markers in your code that look like:
+
+    <<<<<<< HEAD 
+
+    See also: [dplyr documentation](https://dplyr.tidyverse.org/)   
+
+    ======= 
+
+    See also [ggplot2 documentation](https://ggplot2.tidyverse.org/)  
+
+    >>>>>>> some1alpha2numeric3string4
+
+The `===`s separate *your* changes (top) from *their* changes (bottom).
+
+Note that on top you see the word `HEAD`, which indicates that these are your changes.
+
+And at the bottom you see `some1alpha2numeric3string4` (well, it probably looks more like `28e7b2ceb39972085a0860892062810fb812a08f`).
+
+This is the **hash** (a unique identifier) of the commit your collaborator made with the conflicting change.
+
+Your job is to *reconcile* the changes: edit the file so that it incorporates the best of both versions and delete the `<<<`, `===`, and `>>>` lines.
+Then you can stage and commit the result.
+
+# Merge conflict activity
+
+## Setup
+
+-   Clone the repo and open the .Rmd file.
+-   Assign the numbers 1, 2, 3, and 4 to each of the team members. If your team has fewer than 4 people, some people will need to have multiple numbers. If your team has more than 4 people, some people will need to share some numbers.
+
+## Let's cause a merge conflict!
+
+Our goal is to see two different types of merges: first we'll see a type of merge that git can't figure out on its own how to do on its own (a **merge conflict**) and requires human intervention, then another type of where that git can figure out how to do without human intervention.
+
+Doing this will require some tight choreography, so pay attention!
+
+Take turns in completing the exercise, only one member at a time.
+**Others should just watch, not doing anything on their own projects (this includes not even pulling changes!)** until they are instructed to.
+If you feel like you won't be able to resist the urge to touch your computer when it's not your turn, we recommend putting your hands in your pockets or sitting on them!
+
+**Before starting**: everyone should have the repo cloned and know which role number(s) they are.
+
+**Role 1:**
+
+-   Change the team name to your actual team name.
+-   Knit, commit, push.
+
+üõë Make sure the previous role has finished before moving on to the next step.
+
+**Role 2:**
 
-First, open the R Markdown document `lab-03-nobel-winners.Rmd` and Knit it.
+-   Change the team name to some other word.
+-   Knit, commit, push. You should get an error.
+-   Pull. Take a look at the document with the merge conflict.
+-   Clear the merge conflict by editing the document to choose the correct/preferred change.
+-   Knit.
+-   **Click the Stage checkbox** for all files in your Git tab. Make sure they all have check marks, not filled-in boxes.
+-   Commit and push.
+
+üõë Make sure the previous role has finished before moving on to the next step.
+
+**Role 3:**
+
+-   Change the a label of the first code chunk
+-   Knit, commit, push. You should get an error.
+-   Pull. No merge conflicts should occur, but you should see a message about merging.
+-   Now push.
+
+üõë Make sure the previous role has finished before moving on to the next step.
+
+**Role 4:**
+
+-   Change the label of the first code chunk to something other than previous role did.
+-   Knit, commit, push. You should get an error.
+-   Pull. Take a look at the document with the merge conflict. Clear the merge conflict by choosing the correct/preferred change. Commit, and push.
+
+üõë Make sure the previous role has finished before moving on to the next step.
+
+**Everyone:** Pull, and observe the changes in your document.
+
+## Tips for collaborating via GitHub
+
+-   Always pull first before you start working.
+-   Resolve a merge conflict (commit and push) *before* continuing your work. Never do new work while resolving a merge conflict.
+-   Knit, commit, and push often to minimize merge conflicts and/or to make merge conflicts easier to resolve.
+-   If you find yourself in a situation that is difficult to resolve, ask questions ASAP. Don't let it linger and get bigger.
+
+# Getting started
+
+Go to the course GitHub organization and locate your lab repo, which should be named `lab-03-nobel-laureates-YOUR_GITHUB_USERNAME`.
+Grab the URL of the repo, and clone it in RStudio.
+First, open the R Markdown document `lab-03.Rmd` and Knit it.
 Make sure it compiles without errors.
 The output will be in the file markdown `.md` file with the same name.
 
-### Packages
+## Warm up
 
-We'll use the **tidyverse** package for this analysis.
-Run the following code in the Console to load this package.
+Before we introduce the data, let's warm up with some simple exercises.
 
-```{r load-packages, message=FALSE, eval=TRUE}
+-   Update the YAML, changing the author name to your name, and **knit** the document.
+-   Commit your changes with a meaningful commit message.
+-   Push your changes to GitHub.
+-   Go to your repo on GitHub and confirm that your changes are visible in your Rmd **and** md files. If anything is missing, commit and push again.
+
+## Packages
+
+We'll use the **tidyverse** package for much of the data wrangling.
+This package is already installed for you.
+You can load them by running the following in your Console:
+
+```{r load-packages, message = FALSE}
 library(tidyverse)
 ```
 
-## The data
+## Data
 
-The dataset for this assignment can be found as a csv file in the `data` folder of your repository.
+The dataset for this assignment can be found as a CSv (comma separated values) file in the `data` folder of your repository.
 You can read it in using the following.
 
-```{r load-data, message=FALSE, eval=TRUE}
+```{r load-data, message = FALSE}
 nobel <- read_csv(""data/nobel.csv"")
 ```
 
@@ -84,8 +189,8 @@ The variable descriptions are as follows:
 -   `share`: Number of other winners award is shared with
 -   `motivation`: Motivation for recognition
 
-In a few cases the name of the city/country changed after laureate was given (e.g. in 1975 Bosnia and Herzegovina was part of the Socialist Federative Republic of Yugoslavia).
-In these cases the variables below reflect a different name than their counterparts without the suffix `_original`.
+In a few cases the name of the city/country changed after laureate was given (e.g. in 1975 Bosnia and Herzegovina was called the Socialist Federative Republic of Yugoslavia).
+In these cases the variables below reflect a different name than their counterparts without the suffix \`\_original\`.
 
 -   `born_country_original`: Original country where laureate was born
 -   `born_city_original`: Original city where laureate was born
@@ -94,11 +199,16 @@ In these cases the variables below reflect a different name than their counterpa
 -   `city_original`: Original city where laureate lived at the time of winning the award
 -   `country_original`: Original country where laureate lived at the time of winning the award
 
-## Exercises
+# Exercises
 
-### Get to know your data
+Take turns answering the exercises.
+Make sure each team member gets to commit to the repo by the time you submit your work.
+And make sure that the person taking the lead for an exercise is sharing their screen.
+You don't have to switch at each exercise, you can find your a cadence that works for your team and stick to it.
 
-1.  How many observations and how many variables are in the dataset? Use inline code to answer this question.
+## Get to know your data
+
+1.  How many observations and how many variables are in the dataset? Use inline code to answer this question. What does each row represent?
 
 There are some observations in this dataset that we will exclude from our analysis to match the Buzzfeed results.
 
@@ -108,11 +218,20 @@ There are some observations in this dataset that we will exclude from our analys
 -   laureates who are people as opposed to organizations (organizations are denoted with `""org""` as their `gender`)
 -   laureates who are still alive (their `died_date` is `NA`)
 
-Confirm that once you have filtered for these characteristics you are left with a data frame with 228 observations.
+```{r echo=FALSE}
+nobel_living <- nobel %>%
+  filter(
+    !is.na(country),
+    gender != ""org"",
+    is.na(died_date)
+  )
+```
+
+Confirm that once you have filtered for these characteristics you are left with a data frame with `r nrow(nobel_living)` observations, once again using inline code.
 
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *Commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
 
-### Most living Nobel laureates were based in the US when they won their prizes
+## Most living Nobel laureates were based in the US when they won their prizes
 
 ... says the Buzzfeed article.
 Let's see if that's true.
@@ -146,45 +265,48 @@ nobel_living_science <- nobel_living %>%
 For the next exercise work with the `nobel_living_science` data frame you created above.
 This means you'll need to define this data frame in your R Markdown document, even though the next exercise doesn't explicitly ask you to do so.
 
-3.  Create a faceted bar plot visualizing the relationship between the category of prize and whether the laureate was in the US when they won the nobel prize. Note: Your visualization should be faceted by category. For each facet you should have two bars, one for winners in the US and one for Other. Flip the coordinates so the bars are horizontal, not vertical. Interpret your visualization, and say a few words about whether the Buzzfeed headline is supported by the data.
+3.  Create a faceted bar plot visualizing the relationship between the category of prize and whether the laureate was in the US when they won the nobel prize.
+    Interpret your visualization, and say a few words about whether the Buzzfeed headline is supported by the data.
+
+    -   Your visualization should be faceted by category.
+    -   For each facet you should have two bars, one for winners in the US and one for Other.
+    -   Flip the coordinates so the bars are horizontal, not vertical.
 
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *Commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.d*
 
-### But of those US-based Nobel laureates, many were born in other countries
+## But of those US-based Nobel laureates, many were born in other countries
 
 ```{marginfigure}
 **Hint:** You should be able to ~~cheat~~ borrow from code you used earlier to create the `country_us` variable.
 ```
 
 4.  Create a new variable called `born_country_us` that has the value `""USA""` if the laureate is born in the US, and `""Other""` otherwise.
+    How many of the winners are born in the US?
 
 5.  Add a second variable to your visualization from Exercise 3 based on whether the laureate was born in the US or not.
-    Your final visualization should contain a facet for each category, within each facet a bar for whether they won the award in the US or not, and within each bar whether they were born in the US or not.
     Based on your visualization, do the data appear to support Buzzfeed's claim?
     Explain your reasoning in 1-2 sentences.
 
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *Commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+    -   Your final visualization should contain a facet for each category.
+    -   Within each facet, there should be a bar for whether the laureate won the award in the US or not.
+    -   Each bar should have segments for whether the laureate was born in the US or not.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
 
-### Here's where those immigrant Nobelists were born
+## Here's where those immigrant Nobelists were born
 
 ```{marginfigure}
 Note that your bar plot won't exactly match the one from the Buzzfeed article. This is likely because the data has been updated since the article was published.
 ```
 
-6. In a single pipeline, filter for laureates who won their prize in the US, but were born outside of the US, and then create a frequency table (with the `count()`) function for their birth country, `born_country`, and arrange the resulting data frame in descending order of number of observations for each country.
-
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *Commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
-
-## Wrapping up
-
-Go back through your write up to make sure you're following coding style guidelines we discussed in class.
-Make any edits as needed.
+6.  In a single pipeline, filter for laureates who won their prize in the US, but were born outside of the US, and then create a frequency table (with the `count()` function) for their birth country (`born_country`) and arrange the resulting data frame in descending order of number of observations for each country. Which country is the most common?
 
-Also, make sure all of your R chunks are properly labeled, and your figures are reasonably sized.
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you're happy with the final state of your work.*
 
-Once the team leader for the week pushes their final changes, others should also clone the team repo (or if you've already done so, *pull* on the Git pane) and knit the R Markdown document to confirm that they can reproduce the report.
+Now go back through your write up to make sure you've answered all questions and all of your R chunks are properly labelled.
+Once you decide as a team that you're done with this lab, all members of the team should pull the changes and knit the R Markdown document to confirm that they can reproduce the report.
 
-## Interested in how Buzzfeed made their visualizations?
+# Interested in how Buzzfeed made their visualizations?
 
 The plots in the Buzzfeed article are called waffle plots.
 You can find the code used for making these plots in Buzzfeed's GitHub repo (yes, they have one!) [here](https://buzzfeednews.github.io/2017-01-immigration-and-science/).

---FILE: course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.Rmd---
@@ -1,5 +1,5 @@
 ---
-title: ""Lab 04 - La Quinta is Spanish for 'next to Denny's', Pt. 1""
+title: ""Lab 04 - La Quinta is Spanish for next to Denny's, Pt. 1""
 subtitle: ""Visualizing spatial data""
 output: 
   tufte::tufte_html:
@@ -9,19 +9,12 @@ output:
 link-citations: yes
 ---
 
-```{r include=FALSE}
-library(tufte)
-library(knitr)
-options(
-  htmltools.dir.version = FALSE, # for blogdown
-  show.signif.stars = FALSE,     # for regression output
-  digits = 2
-  )
+```{r include = FALSE}
 knitr::opts_chunk$set(eval = FALSE)
 ```
 
-```{r fig.margin=TRUE, eval=TRUE, echo=FALSE}
-include_graphics(""img/mitch-hedgeberg-lqd.jpg"")
+```{r fig.margin = TRUE, echo = FALSE}
+knitr::include_graphics(""img/mitch-hedgeberg-lqd.jpg"")
 ```
 
 Have you ever taken a road trip in the US and thought to yourself ""I wonder what La Quinta means"".
@@ -39,51 +32,47 @@ In this lab we focus on visualization and analysis of these data.
 However note that the data scraping was also done in R, and we we will discuss web scraping using R later in the course.
 But for now we focus on the data that has already been scraped and tidied for you.
 
-## Getting started
+# Learning goals
 
-### Packages
+-   Visualising spatial data
+-   Joining data frames
 
-In this lab we will use the **tidyverse** and **dsbox** packages.
+# Getting started
 
-```{r eval = TRUE, message = FALSE}
-library(tidyverse) 
-library(dsbox) 
-```
-
-## Housekeeping
-
-### Project name
+Go to the course GitHub organization and locate your homework repo, clone it in RStudio and open the R Markdown document.
+Knit the document to make sure it compiles without errors.
 
-Currently your project is called *Untitled Project*.
-Update the name of your project to be ""Lab 03 - Visualizing spatial data"".
-
-### Warm up
-
-**Pick one team member to complete the steps in this section while the others contribute to the discussion but do not actually touch the files on their computer.**
+## Warm up
 
 Before we introduce the data, let's warm up with some simple exercises.
 
-### YAML
-
-Open the R Markdown (Rmd) file in your project, change the author name to your **team** name, and knit the document.
-
-### Commiting and pushing changes
+-   Update the YAML, changing the author name to your name, and **knit** the document.
+-   Commit your changes with a meaningful commit message.
+-   Push your changes to GitHub.
+-   Go to your repo on GitHub and confirm that your changes are visible in your Rmd **and** md files. If anything is missing, commit and push again.
 
--   Go to the **Git** pane in your RStudio.
--   View the **Diff** and confirm that you are happy with the changes.
--   Add a commit message like ""Update team name"" in the **Commit message** box and hit **Commit**.
--   Click on **Push**. This will prompt a dialogue box where you first need to enter your user name, and then your password.
+## Packages
 
-### Pulling changes
+We'll use the **tidyverse** package for much of the data wrangling and visualisation and the data lives in the **dsbox** package.
+These packages are already installed for you.
+You can load them by running the following in your Console:
 
-Now, the remaining team members who have not been concurrently making these changes on their projects should click on the **Pull** button in their Git pane and observe that the changes are now reflected on their projects as well.
+```{r message = FALSE}
+library(tidyverse) 
+library(dsbox) 
+```
 
-## The data
+## Data
 
 The datasets we'll use are called `dennys` and `laquinta` from the **dsbox** package.
 Note that these data were scraped from [here](https://locations.dennys.com/) and [here](https://www.lq.com/en/findandbook/hotel-listings.html), respectively.
 
-To help with our analysis we will also use a dataset on US states:
+The datasets we'll use are called `dennys` and `laquinta` from the **dsbox** package.
+Since the datasets are distributed with the package, we don't need to load them separately; they become available to us when we load the package.
+You can find out more about the datasets by inspecting their documentation, which you can access by running `?dennys` and `?laquinta` in the Console or using the Help menu in RStudio to search for `dennys` or `laquinta`.
+You can also find this information [here](https://rstudio-education.github.io/dsbox/reference/dennys.html) and [here](https://rstudio-education.github.io/dsbox/reference/laquinta.html).
+
+To help with our analysis we will also use a dataset on US states, which is located in your repository's `data` folder.
 
 ```{r}
 states <- read_csv(""data/states.csv"")
@@ -92,7 +81,7 @@ states <- read_csv(""data/states.csv"")
 Each observation in this dataset represents a state, including DC.
 Along with the name of the state we have the two-letter abbreviation and we have the geographic area of the state (in square miles).
 
-## Exercises
+# Exercises
 
 1.  What are the dimensions of the Denny's dataset?
     (Hint: Use inline R code and functions like `nrow` and `ncol` to compose your answer.) What does each row in the dataset represent?
@@ -102,6 +91,8 @@ Along with the name of the state we have the two-letter abbreviation and we have
     What does each row in the dataset represent?
     What are the variables?
 
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
 We would like to limit our analysis to Denny's and La Quinta locations in the United States.
 
 3.  Take a look at the websites that the data come from (linked above).
@@ -148,7 +139,7 @@ dn %>%
     You'll need to refer to your notes from Exercise 7 about which country the non-US locations are in.
     Here is some starter code to get you going:
 
-```{r eval=FALSE}
+```{r eval = FALSE}
 lq %>%
   mutate(country = case_when(
     state %in% state.abb     ~ ""United States"",
@@ -158,7 +149,9 @@ lq %>%
   ))
 ```
 
-`r newthought('Going forward')` we will work with the data from the United States only.
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+Going forward we will work with the data from the United States only.
 All Denny's locations are in the United States, so we don't need to worry about them.
 However we do need to filter the La Quinta dataset for locations in United States.
 
@@ -170,7 +163,7 @@ lq <- lq %>%
 9.  Which states have the most and fewest Denny's locations? What about La Quinta? Is this surprising? Why or why not?
 
 Next, let's calculate which states have the most Denny's locations *per thousand square miles*.
-This requires *join*ining information from the frequency tables you created in Exercise 8 with information from the `states` data frame.
+This requires *joinining* information from the frequency tables you created in Exercise 8 with information from the `states` data frame.
 
 First, we count how many observations are in each state, which will give us a data frame with two variables: `state` and `n`.
 Then, we join this data frame with the `states` data frame.
@@ -227,3 +220,5 @@ You can also choose different themes to change the overall look of your plots, s
 
 That's it for now!
 In the next lab we will take a more quantitative approach to answering these questions.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you're happy with the final state of your work.*

---FILE: course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.Rmd---
@@ -1,5 +1,5 @@
 ---
-title: ""Lab 05 - La Quinta is Spanish for *next to Denny's*, Pt. 2""
+title: ""Lab 05 - La Quinta is Spanish for next to Denny's, Pt. 2""
 subtitle: ""Wrangling spatial data""
 output: 
   tufte::tufte_html:
@@ -9,103 +9,62 @@ output:
 link-citations: yes
 ---
 
-```{r include=FALSE}
-library(tufte)
-library(knitr)
-options(
-  htmltools.dir.version = FALSE, # for blogdown
-  show.signif.stars = FALSE,     # for regression output
-  digits = 2
-  )
-knitr::opts_chunk$set(eval = FALSE)
-```
-
-```{r fig.margin=TRUE, eval=TRUE, echo=FALSE}
-include_graphics(""img/mitch-hedgeberg-lqd.jpg"")
+```{r fig.margin = TRUE, echo = FALSE}
+knitr::include_graphics(""img/mitch-hedgeberg-lqd.jpg"")
 ```
 
 In this lab we revisit the Denny's and La Quinta Inn and Suites data we visualized in the previous lab.
 
-## Getting started
+# Learning goals
 
--   Go to the course organization on GitHub.
+-   Working with spatial data
+-   Writing and using a custom function
 
--   Find your lab repo.
+# Getting started
 
--   In the repo, click on the green **Clone or download** button, select **Use HTTPS** (this might already be selected by default, and if it is, you'll see the text **Clone with HTTPS** as in the image below).
-    Click on the clipboard icon to copy the repo URL.
+Go to the course GitHub organization and locate your homework repo, clone it in RStudio and open the R Markdown document.
+Knit the document to make sure it compiles without errors.
 
--   Go to RStudio Cloud and into the course workspace.
-    Create a **New Project from Git Repo**.
-    You will need to click on the down arrow next to the **New Project** button to see this option.
-
--   Copy and paste the URL of your assignment repo into the dialog box:
+## Warm up
 
--   Hit OK, and you're good to go!
+Before we introduce the data, let's warm up with some simple exercises.
+Update the YAML of your R Markdown file with your information, knit, commit, and push your changes.
+Make sure to commit with a meaningful commit message.
+Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd **and** md files.
+If anything is missing, commit and push again.
 
-### Packages
+## Packages
 
-In this lab we will use the **tidyverse** and **dsbox** packages.
+We'll use the **tidyverse** package for much of the data wrangling and visualisation and the data lives in the **dsbox** package.
+These packages are already installed for you.
+You can load them by running the following in your Console:
 
-```{r eval = FALSE}
+```{r message = FALSE}
 library(tidyverse) 
 library(dsbox) 
 ```
 
-### Housekeeping
+## Data
 
-#### Password caching
+Remember that the datasets we'll use are called `dennys` and `laquinta` from the **dsbox** package.
+Since the datasets are distributed with the package, we don't need to load them separately; they become available to us when we load the package.
+You can find out more about the datasets by inspecting their documentation, which you can access by running `?dennys` and `?laquinta` in the Console or using the Help menu in RStudio to search for `dennys` or `laquinta`.
+You can also find this information [here](https://rstudio-education.github.io/dsbox/reference/dennys.html) and [here](https://rstudio-education.github.io/dsbox/reference/laquinta.html).
 
-If you would like your git password cached for a week for this project, type the following in the Terminal:
-
-```{bash eval=FALSE}
-git config --global credential.helper 'cache --timeout 604800'
-```
-
-#### Project name
-
-Currently your project is called *Untitled Project*.
-Update the name of your project to be ""Lab 04 - Wrangling spatial data"".
-
-## Warm up
-
-**Pick one team member to complete the steps in this section while the others contribute to the discussion but do not actually touch the files on their computer.**
-
-Before we introduce the data, let's warm up with some simple exercises.
-
-### YAML
-
-Open the R Markdown (Rmd) file in your project, change the author name to your **team** name, and knit the document.
-
-### Commiting and pushing changes:
-
--   Go to the **Git** pane in your RStudio.
--   View the **Diff** and confirm that you are happy with the changes.
--   Add a commit message like ""Update team name"" in the **Commit message** box and hit **Commit**.
--   Click on **Push**. This will prompt a dialogue box where you first need to enter your user name, and then your password.
-
-### Pulling changes
-
-Now, the remaining team members who have not been concurrently making these changes on their projects should click on the **Pull** button in their Git pane and observe that the changes are now reflected on their projects as well.
-
-## The data
-
-The datasets we'll use are called `dennys` and `laquinta` from the **dsbox** package.
-
-## Exercises
+# Exercises
 
 1.  Filter the Denny's dataframe for Alaska (AK) and save the result as `dn_ak`. How many Denny's locations are there in Alaska?
 
 ```{r}
-dn_ak <- dn %>%
+dn_ak <- dennys %>%
   filter(state == ""AK"")
 nrow(dn_ak)
 ```
 
 2.  Filter the La Quinta dataframe for Alaska (AK) and save the result as `lq_ak`. How many La Quinta locations are there in Alaska?
 
 ```{r}
-lq_ak <- lq %>%
+lq_ak <- laquinta %>%
   filter(state == ""AK"")
 nrow(lq_ak)
 ```
@@ -177,6 +136,8 @@ These varibles are renamed to include `.x` and `.y` because the two data frames
 
 Now that we have the data in the format we wanted, all that is left is to calculate the distances between the pairs.
 
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
 5.  What function from the tidyverse do we use the add a new variable to a data frame while keeping the existing variables?
 
 One way of calculating the distance between any two points on the earth is to use the Haversine distance formula.
@@ -213,14 +174,15 @@ This function takes five arguments:
 7.  Calculate the minimum distance between a Denny's and La Quinta for each Denny's location.
     To do so we group by Denny's locations and calculate a new variable that stores the information for the minimum distance.
 
-```{r}
+```{r eval = FALSE}
 dn_lq_ak_mindist <- dn_lq_ak %>%
   group_by(address.x) %>%
   summarise(closest = min(distance))
 ```
 
-8.  Describe the distribution of the distances Denny's and the nearest La Quinta locations in Alaska.
-    Also include an appripriate visualization and relevant summary statistics.
+8.  Describe the distribution of the distances Denny's and the nearest La Quinta locations in Alaska. Also include an appripriate visualization and relevant summary statistics.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
 
 9.  Repeat the same analysis for North Carolina: (i) filter Denny's and La Quinta Data Frames for NC, (ii) join these data frames to get a completelist of all possible pairings, (iii) calculate the distances between all possible pairings of Denny's and La Quinta in NC, (iv) find the minimum distance between each Denny's and La Quinta location, (v) visualize and describe the distribution of these shortest distances using appropriate summary statistics.
 
@@ -230,3 +192,5 @@ dn_lq_ak_mindist <- dn_lq_ak %>%
 
 12. Among the states you examined, where is Mitch Hedberg's joke most likely to hold true?
     Explain your reasoning.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you're happy with the final state of your work.*

---FILE: course-materials/lab-instructions/lab-06/lab-06-sad-plots.Rmd---
@@ -0,0 +1,189 @@
+---
+title: ""Lab 06 - Take a sad plot and make it better""
+output: 
+  tufte::tufte_html:
+    css: ../lab.css
+    tufte_variant: ""envisioned""
+    highlight: pygments
+link-citations: yes
+---
+
+```{r setup, include=FALSE}
+knitr::opts_chunk$set(eval = TRUE)
+```
+
+Given below are two data visualizations that violate many data visualization best practices.
+Improve these visualizations using R and the tips for effective visualizations that we introduced in class.
+You should produce one visualization per dataset.
+Your visualization should be accompanied by a brief paragraph describing the choices you made in your improvement, specifically discussing what you didn't like in the original plots and why, and how you addressed them in the visualization you created.
+
+On the due date you will give a brief presentation describing one of your improved visualizations and the reasoning for the choices you made.
+
+# Learning goals
+
+-   Telling a story with data
+-   Data visualization best practices
+-   Reshaping data
+
+# Getting started
+
+Go to the course GitHub organization and locate your homework repo, clone it in RStudio and open the R Markdown document.
+Knit the document to make sure it compiles without errors.
+
+## Warm up
+
+Before we introduce the data, let's warm up with some simple exercises.
+Update the YAML of your R Markdown file with your information, knit, commit, and push your changes.
+Make sure to commit with a meaningful commit message.
+Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd **and** md files.
+If anything is missing, commit and push again.
+
+## Packages
+
+We'll use the **tidyverse** package for much of the data wrangling and visualisation and the data lives in the **dsbox** package.
+These packages are already installed for you.
+You can load them by running the following in your Console:
+
+```{r eval = TRUE, message = FALSE}
+library(tidyverse) 
+library(dsbox) 
+```
+
+## Data
+
+The datasets we'll use are called `instructors` and `fisheries` from the **dsbox** package.
+Since the datasets are distributed with the package, we don't need to load them separately; they become available to us when we load the package.
+You can find out more about the datasets by inspecting their documentation, which you can access by running `?instructors` and `?fisheries` in the Console or using the Help menu in RStudio to search for `instructors` or `fisheries`.
+You can also find this information [here](https://rstudio-education.github.io/dsbox/reference/instructors.html) and [here](https://rstudio-education.github.io/dsbox/reference/fisheries.html).
+
+# Exercises
+
+## Instructional staff employment trends
+
+The American Association of University Professors (AAUP) is a nonprofit membership association of faculty and other academic professionals.
+[This report](https://www.aaup.org/sites/default/files/files/AAUP_Report_InstrStaff-75-11_apr2013.pdf) compiled by the AAUP shows trends in instructional staff employees between 1975 and 2011, and contains an image very similar to the one given below.
+
+```{r echo=FALSE, fig.fullwidth = TRUE}
+knitr::include_graphics(""img/staff-employment.png"")
+```
+
+Let's start by loading the data used to create this plot.
+
+```{r load-data-staff, message = FALSE}
+staff <- read_csv(""data/instructional-staff.csv"")
+```
+
+Each row in this dataset represents a faculty type, and the columns are the years for which we have data.
+The values are percentage of hires of that type of faculty for each year.
+
+```{r echo = FALSE}
+staff
+```
+
+In order to recreate this visualization we need to first reshape the data to have one variable for faculty type and one variable for year.
+In other words, we will convert the data from wide format to long format.
+
+But before we do so, a thought exercise: *How many rows will the long-format data have?* It will have a row for each combination of year and faculty type.
+If there are 5 faculty types and 11 years of data, how many rows will we have?
+
+We do the wide to long conversion using a new function: `pivot_longer()`.
+The animation below show how this function works, as well as its counterpart `pivot_wider()`.
+
+```{r echo = FALSE}
+knitr::include_graphics(""img/tidyr-longer-wider.gif"")
+```
+
+The function has the following arguments:
+
+```{r eval = FALSE}
+pivot_longer(data, cols, names_to = ""name"")
+```
+
+-   The first argument is `data` as usual.
+-   The second argument, `cols`, is where you specify which columns to pivot into longer format -- in this case all columns except for the `faculty_type`
+-   The third argument, `names_to`, is a string specifying the name of the column to create from the data stored in the column names of data -- in this case `year`
+
+```{r}
+staff_long <- staff %>%
+  pivot_longer(cols = -faculty_type, names_to = ""year"") %>%
+  mutate(value = as.numeric(value))
+```
+
+Let's take a look at what the new longer data frame looks like.
+
+```{r}
+staff_long
+```
+
+And now let's plot is as a line plot.
+A possible approach for creating a line plot where we color the lines by faculty type is the following:
+
+```{r fig.width = 10, fig.fullwidth = TRUE}
+staff_long %>%
+  ggplot(aes(x = year, y = value, color = faculty_type)) +
+  geom_line()
+```
+
+But note that this results in a message as well as an unexpected plot.
+The message is saying that there is only one observation for each faculty type year combination.
+We can fix this using the `group` aesthetic following.
+
+```{r fig.width = 10, fig.fullwidth = TRUE}
+staff_long %>%
+  ggplot(aes(x = year, y = value, group = faculty_type, color = faculty_type)) +
+  geom_line()
+```
+
+1.  Include the line plot you made above in your report and make sure the figure width is large enough to make it legible.
+    Also fix the title, axis labels, and legend label.
+
+2.  Suppose the objective of this plot was to show that the proportion of part-time faculty have gone up over time compared to other instructional staff types.
+    What changes would you propose making to this plot to tell this story and why.
+
+3.  Implement the changes you proposed in the previous exercise.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+## Fisheries
+
+Fisheries and Aquaculture Department of the Food and Agriculture Organization of the United Nations collects data on fisheries production of countries.
+[This Wikipedia page](https://en.wikipedia.org/wiki/Fishing_industry_by_country) lists fishery production of countries for 2016.
+For each country tonnage from capture and aquaculture are listed.
+Note that countries whose total harvest was less than 100,000 tons are not included in the visualization.
+
+A researcher shared with you the following visualization they created based on these data.
+üò≥
+
+```{r echo=FALSE, fig.fullwidth = TRUE}
+knitr::include_graphics(""img/fisheries.png"")
+```
+
+4.  Can you help them make improve it? First, brainstorm how you would improve it. Then create the improved visualization and write up the changes/decisions you made as bullet points. It's ok if some of your improvements are aspirational, i.e. you don't know how to implement it, but you think it's a good idea.
+
+Load the data.
+
+```{r load-data-fisheries, eval = FALSE}
+fisheries <- read_csv(""data/fisheries.csv"")
+```
+
+5.  Create a new data visualisation for these data that implements the improvements you proposed in the previous exercise (or many of them as you can).
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you're happy with the final state of your work.*
+
+# Wrapping up
+
+Go back through your write up to make sure you're following coding style guidelines we discussed in class.
+Make any edits as needed.
+
+Also, make sure all of your R chunks are properly labelled, and your figures are reasonably sized.
+
+Once the team leader for the week pushes their final changes, others should *pull* the changes and knit the R Markdown document to confirm that they can reproduce the report.
+
+# More ugly charts
+
+Want to see more ugly charts?
+
+-   [Flowing Data - Ugly Charts](https://flowingdata.com/category/visualization/ugly-visualization/)
+-   [Reddit - Data is ugly](https://www.reddit.com/r/dataisugly/)
+-   [Missed Opportunities and Graphical Failures](http://www.datavis.ca/gallery/missed.php)
+-   [(Mostly Bad) Graphics and Tables](http://users.stat.umn.edu/~rend0020/Teaching/STAT8801-resources/graphics/index.html)

---FILE: course-materials/lab-instructions/lab-06/lab-06-ugly-charts.Rmd---
@@ -1,280 +0,0 @@
----
-title: ""Lab 06 - Ugly chartss""
-output: 
-  tufte::tufte_html:
-    css: ../lab.css
-    tufte_variant: ""envisioned""
-    highlight: pygments
-link-citations: yes
----
-
-```{r setup, include=FALSE}
-knitr::opts_chunk$set(eval = TRUE)
-```
-
-Given below are two data visualizations that violate many data visualization best practices.
-Improve these visualizations using R and the tips for effective visualizations that we introduced in class.
-You should produce one visualization per dataset.
-Your visualization should be accompanied by a brief paragraph describing the choices you made in your improvement, specifically discussing what you didn't like in the original plots and why, and how you addressed them in the visualization you created.
-
-On the due date you will give a brief presentation describing one of your improved visualizations and the reasoning for the choices you made.
-
-The learning goals for this lab are:
-
--   Telling a story with data
--   Data visualization best practices
--   Reshaping data
-
-## Getting started
-
-Go to the course GitHub organization and locate your lab repo.
-Grab the URL of the repo, and clone it in RStudio.
-Refer to Lab 01 if you would like to see step-by-step instructions for cloning a repo into an RStudio project.
-
-First, open the R Markdown document and Knit it.
-Make sure it compiles without errors.
-The output will be in the file markdown `.md` file with the same name.
-
-### Housekeeping
-
-```{marginfigure}
-Your email address is the address tied to your GitHub account and your name should be first and last name.
-```
-
-Before we can get started we need to take care of some required housekeeping.
-Specifically, we need to do some configuration so that RStudio can communicate with GitHub.
-This requires two pieces of information: your email address and your name.
-
-Run the following (but update it for your name and email!) in the Console to configure git:
-
-```{r git-config, eval=FALSE}
-library(usethis)
-use_git_config(user.name = ""Your Name"", 
-               user.email = ""your.email@address.com"")
-```
-
-### Workflow
-
-This is the second week you're working in teams, so we're going to make things a little more interesting and let all of you make changes and push those changes to your team repository.
-Sometimes things will go swimmingly, and sometimes you'll run into merge conflicts.
-So our first task today is to walk you through a merge conflict!
-
-## Merges and merge conflicts
-
--   Pushing to a repo replaces the code on GitHub with the code you have on your computer.
--   If a collaborator has made a change to your repo on GitHub that you haven't incorporated into your local work, GitHub will stop you from pushing to the repo because this could overwrite your collaborator's work!
--   So you need to explicitly ""merge"" your collaborator's work before you can push.
--   If your and your collaborator's changes are in different files or in different parts of the same file, git merges the work for you automatically when you *pull*.
--   If you both changed the same part of a file, git will produce a **merge conflict** because it doesn't know how which change you want to keep and which change you want to overwrite.
-
-Git will put conflict markers in your code that look like:
-
-    <<<<<<< HEAD 
-    See also: [dplyr documentation](https://dplyr.tidyverse.org/)   
-    ======= 
-    See also [ggplot2 documentation](https://ggplot2.tidyverse.org/)  
-    >>>>>>> some1alpha2numeric3string4
-
-The `===`s separate *your* changes (top) from *their* changes (bottom).
-Note that on top you see the word `HEAD`, which indicates that these are your changes.
-And at the bottom you see `some1alpha2numeric3string4` (well, it probably looks more like `28e7b2ceb39972085a0860892062810fb812a08f`).
-This is the *hash* (a unique identifier) of the commit your collaborator made with the conflicting change.
-
-Your job is to *reconcile* the changes: edit the file so that it incorporates the best of both versions and delete the `<<<`, `===`, and `>>>` lines.
-Then Stage and Commit the result.
-
-### Setup
-
--   Clone the repo and open the .Rmd file.
--   Assign the numbers 1, 2, 3, and 4 to each of the team members. If your team has fewer than 4 people, some people will need to have multiple numbers. If your team has more than 4 people, some people will need to share some numbers.
-
-### Let's cause a merge conflict!
-
-Our goal is to see two different types of merges: first we'll see a type of merge that git can't figure out on its own how to do on its own (a **merge conflict**) and requires human intervention, then another type of where that git can figure out how to do without human intervention.
-
-Doing this will require some tight choreography, so pay attention!
-
-Take turns in completing the exercise, only one member at a time.
-**Others should just watch, not doing anything on their own projects (this includes not even pulling changes!)** until they are instructed to.
-If you feel like you won't be able to resist the urge to touch your computer when it's not your turn, we recommend putting your hands in your pockets or sitting on them!
-
-**Before starting**: everyone should have the repo cloned and know which role number(s) they are.
-
-**Role 1:**
-
--   Change the team name to your actual team name.
--   Knit, commit, push.
-
-üõë Wait for instructions before moving on to the next step.
-
-**Role 2:**
-
--   Change the team name to some other word.
--   Knit, commit, push. You should get an error.
--   Pull. Take a look at the document with the merge conflict.
--   Clear the merge conflict by editing the document to choose the correct/preferred change.
--   Knit.
--   **Click the Stage checkbox** for all files in your Git tab. Make sure they all have check marks, not filled-in boxes.
--   Commit and push.
-
-üõë Wait for instructions before moving on to the next step.
-
-**Role 3:**
-
--   Add a label to the first code chunk
--   Knit, commit, push. You should get an error.
--   Pull. No merge conflicts should occur, but you should see a message about merging.
--   Now push.
-
-üõë Wait for instructions before moving on to the next step.
-
-**Role 4:**
-
--   Add a different label to the first code chunk.
--   Knit, commit, push. You should get an error.
--   Pull. Take a look at the document with the merge conflict. Clear the merge conflict by choosing the correct/preferred change. Commit, and push.
-
-üõë Wait for instructions before moving on to the next step.
-
-**Everyone:** Pull, and observe the changes in your document.
-
-### Tips for collaborating via GitHub
-
--   Always pull first before you start working.
--   Resolve a merge conflict (commit and push) *before* continuing your work. Never do new work while resolving a merge conflict.
--   Knit, commit, and push often to minimize merge conflicts and/or to make merge conflicts easier to resolve.
--   If you find yourself in a situation that is difficult to resolve, ask questions ASAP. Don't let it linger and get bigger.
-
-## Packages
-
-Run the following code in the Console to load this package.
-
-```{r load-packages, message=FALSE, eval=TRUE}
-library(tidyverse)
-```
-
-## Take a sad plot and make it better
-
-### Instructional staff employment trends
-
-The American Association of University Professors (AAUP) is a nonprofit membership association of faculty and other academic professionals.
-[This report](https://www.aaup.org/sites/default/files/files/AAUP_Report_InstrStaff-75-11_apr2013.pdf) compiled by the AAUP shows trends in instructional staff employees between 1975 and 2011, and contains an image very similar to the one given below.
-
-```{r echo=FALSE, fig.fullwidth=TRUE}
-knitr::include_graphics(""img/staff-employment.png"")
-```
-
-Let's start by loading the data used to create this plot.
-
-```{r load-data-staff, message=FALSE, eval=TRUE}
-staff <- read_csv(""data/instructional-staff.csv"")
-```
-
-Each row in this dataset represents a faculty type, and the columns are the years for which we have data.
-The values are percentage of hires of that type of faculty for each year.
-
-```{r echo=FALSE}
-staff
-```
-
-In order to recreate this visualization we need to first reshape the data to have one variable for faculty type and one variable for year.
-In other words, we will convert the data from wide format to long format.
-
-But before we do so, a thought exercise: *How many rows will the long-format data have?* It will have a row for each combination of year and faculty type.
-If there are 5 faculty types and 11 years of data, how many rows will we have?
-
-We do the wide to long conversion using a new function: `pivot_longer()`.
-The animation below show how this function works, as well as its counterpart `pivot_wider()`.
-
-```{r echo=FALSE}
-knitr::include_graphics(""img/tidyr-longer-wider.gif"")
-```
-
-The function has the following arguments:
-
-```{r eval=FALSE}
-pivot_longer(data, cols, names_to = ""name"")
-```
-
--   The first argument is `data` as usual.
--   The second argument, `cols`, is where you specify which columns to pivot into longer format -- in this case all columns except for the `faculty_type`
--   The third argument, `names_to`, is a string specifying the name of the column to create from the data stored in the column names of data -- in this case `year`
-
-```{r}
-staff_long <- staff %>%
-  pivot_longer(cols = -faculty_type, names_to = ""year"") %>%
-  mutate(value = as.numeric(value))
-```
-
-Let's take a look at what the new longer data frame looks like.
-
-```{r}
-staff_long
-```
-
-And now let's plot is as a line plot.
-A possible approach for creating a line plot where we color the lines by faculty type is the following:
-
-```{r eval=TRUE, fig.width=10}
-staff_long %>%
-  ggplot(aes(x = year, y = value, color = faculty_type)) +
-  geom_line()
-```
-
-But note that this results in a message as well as an unexpected plot.
-The message is saying that there is only one observation for each faculty type year combination.
-We can fix this using the `group` aesthetic following.
-
-```{r eval=FALSE, fig.width=10}
-staff_long %>%
-  ggplot(aes(x = year, y = value, group = faculty_type, color = faculty_type)) +
-  geom_line()
-```
-
-1.  Include the line plot you made above in your report and make sure the figure width is large enough to make it legible.
-    Also fix the title, axis labels, and legend label.
-
-2.  Suppose the objective of this plot was to show that the proportion of part-time faculty have gone up over time compared to other instructional staff types.
-    What changes would you propose making to this plot to tell this story.
-    (You don't need to implement these changes now, you will get to do that as part of this week's homework. But work as a team to come up with ideas and list them as bullet points. The more precise you are, the easier your homework will be.)
-
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *Commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
-
-### Fisheries
-
-Fisheries and Aquaculture Department of the Food and Agriculture Organization of the United Nations collects data on fisheries production of countries.
-[This Wikipedia page](https://en.wikipedia.org/wiki/Fishing_industry_by_country) lists fishery production of countries for 2016.
-For each country tonnage from capture and aquaculture are listed.
-Note that countries whose total harvest was less than 100,000 tons are not included in the visualization.
-
-A researcher shared with you the following visualization they created based on these data `r emo::ji(""flushed"")`.
-
-```{r echo=FALSE, fig.fullwidth=TRUE}
-knitr::include_graphics(""img/fisheries.png"")
-```
-
-3.  Can you help them make improve it? First, brainstorm how you would improve it. Then create the improved visualization and write up the changes/decisions you made as bullet points. It's ok if some of your improvements are aspirational, i.e. you don't know how to implement it, but you think it's a good idea. Ask a tutor for help, but also keep an eye on the time. Implement what you can and leave note identifying the aspirational improvements.
-
-```{r load-data-fisheries, eval=FALSE}
-fisheries <- read_csv(""data/fisheries.csv"")
-```
-
-`r emo::ji(""white_check_mark"")` `r emo::ji(""arrow_up"")` *Commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
-
-## Wrapping up
-
-Go back through your write up to make sure you're following coding style guidelines we discussed in class.
-Make any edits as needed.
-
-Also, make sure all of your R chunks are properly labeled, and your figures are reasonably sized.
-
-Once the team leader for the week pushes their final changes, others should *pull* the changes and knit the R Markdown document to confirm that they can reproduce the report.
-
-## More ugly charts
-
-Want to see more ugly charts?
-
--   [Flowing Data - Ugly Charts](https://flowingdata.com/category/visualization/ugly-visualization/)
--   [Reddit - Data is ugly](https://www.reddit.com/r/dataisugly/)
--   [Missed Opportunities and Graphical Failures](http://www.datavis.ca/gallery/missed.php)
--   [(Mostly Bad) Graphics and Tables](http://users.stat.umn.edu/~rend0020/Teaching/STAT8801-resources/graphics/index.html)

---FILE: course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.Rmd---
@@ -9,91 +9,85 @@ output:
 link-citations: yes
 ---
 
-```{r include=FALSE}
-library(tufte)
-library(knitr)
-options(
-  htmltools.dir.version = FALSE, # for blogdown
-  show.signif.stars = FALSE,     # for regression output
-  digits = 2
-  )
+```{r setup, include=FALSE}
 knitr::opts_chunk$set(eval = FALSE)
 ```
 
-## Getting started
-
-```{r fig.margin=TRUE, eval=TRUE, echo=FALSE}
-include_graphics(""img/whickham.png"")
+```{r fig.margin = TRUE, eval = TRUE, echo = FALSE}
+knitr::include_graphics(""img/whickham.png"")
 ```
 
 A study of conducted in Whickham, England recorded participants' age, smoking status at baseline, and then 20 years later recorded their health outcome.
+In this lab we analyse the relationships between these variables, first two at a time, and then controlling for the third.
 
-### Packages
+# Learning goals
 
-In this lab we will work with the `tidyverse` and `mosaicData` packages.
+-   Visualising relationships between variables
+-   Discovering Simpson's paradox via visualisations
 
-This is the first time we're using the `mosaicData` package, you need to make 
-sure to install it first by running `install.packages(""mosaicData"")` in the 
-console.
+# Getting started
 
-```{r}
-library(tidyverse) 
-library(mosaicData) 
-```
+Go to the course GitHub organization and locate your homework repo, clone it in RStudio and open the R Markdown document.
+Knit the document to make sure it compiles without errors.
+
+## Warm up
 
-Note that these packages are also loaded in your R Markdown document.
+Before we introduce the data, let's warm up with some simple exercises.
+Update the YAML of your R Markdown file with your information, knit, commit, and push your changes.
+Make sure to commit with a meaningful commit message.
+Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd **and** md files.
+If anything is missing, commit and push again.
 
-## The data
+## Packages
 
-The data is in the `mosaicData` package. You can load it with
+We'll use the **tidyverse** package for much of the data wrangling and visualisation and the data lives in the **mosaicData** package.
+These packages are already installed for you.
+You can load them by running the following in your Console:
 
-```{r load-data}
-data(Whickham)
+```{r eval = TRUE, message = FALSE}
+library(tidyverse) 
+library(mosaicData) 
 ```
 
-Take a peek at the codebook with
+## Data
 
-```{r eval=FALSE}
-?Whickham
-```
+The dataset we'll use is called Whickham from the **mosaicData** package.
+You can find out more about the dataset by inspecting their documentation, which you can access by running `?Whickham` in the Console or using the Help menu in RStudio to search for `Whickham`.
 
-## Exercises
+# Exercises
 
-1. What type of study do you think these data comne from: observational 
-   or experiment? Why?
+1.  What type of study do you think these data come from: observational or experiment?
+    Why?
 
-2. How many observations are in this dataset? What does each observation 
-   represent?
+2.  How many observations are in this dataset?
+    What does each observation represent?
 
-3. How many variables are in this dataset? What type of variable is each? 
-   Display each variable using an appropriate visualization.
+3.  How many variables are in this dataset?
+    What type of variable is each?
+    Display each variable using an appropriate visualization.
 
-4. What would you expect the relationship between smoking status and 
-   health outcome to be?
+4.  What would you expect the relationship between smoking status and health outcome to be?
 
-5. Create a visualization depicting the relationship between smoking status 
-   and health outcome. Briefly describe the relationship, and evaluate whether 
-   this meets your expectations. Additionally, calculate the relevant
-   conditional probabilities to help your narrative. Here is some code to 
-   get you started:
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+5.  Create a visualization depicting the relationship between smoking status and health outcome. Briefly describe the relationship, and evaluate whether this meets your expectations. Additionally, calculate the relevant conditional probabilities to help your narrative. Here is some code to get you started:
 
 ```{r}
 Whickham %>%
   count(smoker, outcome)
 ```
 
-6. Create a new variable called `age_cat` using the following scheme:
+6.  Create a new variable called `age_cat` using the following scheme:
 
-- `age <= 44 ~ ""18-44""`
-- `age > 44 & age <= 64 ~ ""45-64""`
-- `age > 64 ~ ""65+""`
+-   `age <= 44 ~ ""18-44""`
+-   `age > 44 & age <= 64 ~ ""45-64""`
+-   `age > 64 ~ ""65+""`
 
-7. Re-create the visualization depicting the relationship between smoking 
-status and health outcome, faceted by `age_cat`. What changed? What might 
-explain this change? Extend the contingency table from earlier by 
-breaking it down by age category and use it to help your narrative.
+7.  Re-create the visualization depicting the relationship between smoking status and health outcome, faceted by `age_cat`. What changed? What might explain this change? Extend the contingency table from earlier by breaking it down by age category and use it to help your narrative.
 
 ```{r}
 Whickham %>%
   count(smoker, age_cat, outcome)
 ```
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you're happy with the final state of your work.*

---FILE: course-materials/lab-instructions/lab-08/lab-08-uoe-art.Rmd---
@@ -15,62 +15,51 @@ library(rvest)
 library(tidyverse)
 ```
 
-The University of Edinburgh Art Collection _""supports the world-leading research and teaching that happens within the University. Comprised of an astonishing range of objects and ideas spanning two millennia and a multitude of artistic forms, the collection reflects not only the long and rich trajectory of the University, but also major national and international shifts in art history.""_^[Source: https://collections.ed.ac.uk/art/about].
+The University of Edinburgh Art Collection *""supports the world-leading research and teaching that happens within the University. Comprised of an astonishing range of objects and ideas spanning two millennia and a multitude of artistic forms, the collection reflects not only the long and rich trajectory of the University, but also major national and international shifts in art history.""*[^lab-08-uoe-art-1].
 
 ```{marginfigure}
-See the sidebar [here](https://collections.ed.ac.uk/art) and note that there are 
-2909 pieces in the art collection we're collecting data on.
+See the sidebar [here](https://collections.ed.ac.uk/art) and note that there are 2970 pieces in the art collection we're collecting data on. Note that more pieces may have been added or some pieces may have been removed between when this lab was written and when you're working on it.
 ```
 
-In this lab we'll scrape data on all art pieces in the [Edinburgh College 
-of Art collection](https://collections.ed.ac.uk/art/search/*:*/Collection:%22edinburgh+college+of+art%7C%7C%7CEdinburgh+College+of+Art%22).
+In this lab we'll scrape data on all art pieces in the [Edinburgh College of Art collection](https://collections.ed.ac.uk/art/search/*:*/Collection:%22edinburgh+college+of+art%7C%7C%7CEdinburgh+College+of+Art%22).
 
-The earning goals of this lab are:
+# Learning goals
 
-- Web scraping from a single page
-- Writing functions
-- Iteration
-- Writing data
+-   Working with R scripts
+-   Web scraping from a single page
+-   Writing functions
+-   Iteration by mapping functions
+-   Writing data out
 
-Before getting started, let's check that a bot has permissions to access pages on this domain.
+# Lab prep
 
-```{r paths-allowed, warning=FALSE}
-paths_allowed(""https://collections.ed.ac.uk/art)"")
+```{r selectorgadget, fig.margin = TRUE, echo = FALSE}
+knitr::include_graphics(""img/selectorgadget.png"")
 ```
 
-## Getting started
+-   Download and install the SelectorGadget for your browser.
+    Once you do, you should now be able to access SelectorGadget by clicking on the icon next to the search bar in your Chrome or Firefox browser.
 
-Go to the course GitHub organization and locate your lab repo, which should be named `lab-08-uoe-art-YOUR_TEAMNAME`. Grab the URL of the repo, and clone it in RStudio Cloud.
+    -   See [here](https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb) for Chrome (recommended)
+    -   See [here](https://addons.mozilla.org/en-US/firefox/addon/chropath-for-firefox) for Firefox
 
-```{marginfigure}
-Your email address is the address tied to your GitHub account and your name 
-should be first and last name.
-```
-
-Run the following (but update it for your name and email!) in the Console to 
-configure Git:
-
-```{r git-config, eval=FALSE}
-library(usethis)
-use_git_config(user.name = ""Your Name"", 
-               user.email = ""your.email@address.com"")
-``` 
+-   Read the following on working with R Markdown documents vs. R scripts.
 
 ## R scripts vs. R Markdown documents
 
 Today we will be using both R scripts and R Markdown documents:
 
-- `.R`: R scripts are plain text files containing **only** code and brief comments,
-  - We'll use R scripts in the web scraping stage and ultimately save the scraped 
-  data as a csv.
-- `.Rmd`: R Markdown documents are plain text files containing.
-  - We'll use an R Markdown document in the web analysis stage, where we start 
-  off by reading in the csv file we wrote out in the scraping stage.
-  
-Here is the organization of your repo, and the corresponding section in the 
-lab that each file will be used for:
+-   `.R`: R scripts are plain text files containing **only** code and brief comments,
 
-```
+    -   We'll use R scripts in the web scraping stage and ultimately save the scraped data as a csv.
+
+-   `.Rmd`: R Markdown documents are plain text files containing.
+
+    -   We'll use an R Markdown document in the web analysis stage, where we start off by reading in the csv file we wrote out in the scraping stage.
+
+Here is the organization of your repo, and the corresponding section in the lab that each file will be used for:
+
+```{=plain}
 |-data
 |  |- README.md
 |-lab-06-uoe-art.Rmd              # analysis
@@ -81,41 +70,58 @@ lab that each file will be used for:
 |  |- 02-scrape-page-function.R   # functions
 |  |- 03-scrape-page-many.R       # iteration
 ```
-  
-## SelectorGadget
-
-For this lab, please use Google Chrome as your web browser. If you are using the 
-one of the computers in the computer lab, you can access Google Chrome by 
-searching for it in the search bar at the bottom left of your home screen. Then, 
-go to the [SelectorGadget extension page](https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb?hl=en) on the Chrome Web Store and click on ""Add to Chrome"" (big blue 
-button). A pop up window will ask _Add ""SelectorGadget""?_, click ""Add extension"". 
-Another pop up window will asl whether you want to get your extensions on all 
-your computer. If you want this, you can turn on sync, but you don't need to 
-for the purpose of this lab.
+# Getting started
 
-```{r selectorgadget, fig.margin = TRUE, echo = FALSE}
-knitr::include_graphics(""img/selectorgadget.png"")
+Go to the course GitHub organization and locate your homework repo, clone it in RStudio and open the R Markdown document.
+Knit the document to make sure it compiles without errors.
+
+## Warm up
+
+Let's warm up with some simple exercises.
+Update the YAML of your R Markdown file with your information, knit, commit, and push your changes.
+Make sure to commit with a meaningful commit message.
+Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd **and** md files.
+If anything is missing, commit and push again.
+
+## Packages
+
+We'll use the **tidyverse** package for much of the data wrangling and visualisation, the **robotstxt** package to check if we're allowed to scrape the data, the **rvest** package for data scraping.
+These packages are already installed for you.
+You can load them by running the following in your Console:
+
+```{r eval = TRUE, message = FALSE}
+library(tidyverse) 
+library(robotstxt)
+library(rvest)
 ```
 
-You should now be able to access SelectorGadget by clicking on the icon next to 
-the search bar in the Chrome browser.
+## Data
 
-### Scraping a single page
+This assignment does not come with any prepared datasets.
+Instead you'll be scraping the data!
+But before doing so, let's check that a bot has permissions to access pages on this domain.
+
+```{r paths-allowed, warning=FALSE}
+paths_allowed(""https://collections.ed.ac.uk/art)"")
+```
+
+# Exercises
+
+## Scraping a single page
 
 ```{marginfigure}
 **Tip:** To run the code you can highlight or put your cursor next to the lines of code you want to run and hit Command+Enter.
 ```
 
-<div class=""box"">
+::: {.box}
 Work in `scripts/01-scrape-page-one.R`.
-</div>
+:::
 
-We will start off by scraping data on the first 10 pieces in the collection from 
-[here](https://collections.ed.ac.uk/art/search/*:*/Collection:%22edinburgh+college+of+art%7C%7C%7CEdinburgh+College+of+Art%22?offset=0).
+We will start off by scraping data on the first 10 pieces in the collection from [here](https://collections.ed.ac.uk/art/search/*:*/Collection:%22edinburgh+college+of+art%7C%7C%7CEdinburgh+College+of+Art%22?offset=0).
 
-First, we define a new object called `first_url`, which is the link above. Then, 
-we read the page at this url with the `read_html()` function from the **rvest** 
-package. The code for this is already provided in `01-scrape-page-one.R`.
+First, we define a new object called `first_url`, which is the link above.
+Then, we read the page at this url with the `read_html()` function from the **rvest** package.
+The code for this is already provided in `01-scrape-page-one.R`.
 
 ```{r}
 # set url
@@ -125,13 +131,12 @@ first_url <- ""https://collections.ed.ac.uk/art/search/*:*/Collection:%22edinburg
 page <- read_html(first_url)
 ```
 
-For the ten pieces on this page we will extract `title`, `artist`, and `link` 
-information, and put these three variables in a data frame.
+For the ten pieces on this page we will extract `title`, `artist`, and `link` information, and put these three variables in a data frame.
 
 ### Titles
 
-Let's start with titles. We make use of the SelectorGadget to identify the 
-tags for the relevant nodes:
+Let's start with titles.
+We make use of the SelectorGadget to identify the tags for the relevant nodes:
 
 ```{r iteminfo-h3a, fig.margin = TRUE, echo = FALSE}
 knitr::include_graphics(""img/iteminfo-h3a.gif"")
@@ -152,10 +157,10 @@ page %>%
   html_text()
 ```
 
-And get rid of all the spurious whitespace in the text with `str_squish()`:
+And get rid of all the spurious white space in the text with `str_squish()`, which reduces repeated whitespace inside a string.
 
 ```{marginfigure}
-Take a look at the help docs for `str_squish()` (with `?str_squish`) to 
+Take a look at the help for `str_squish()` to find out more about how it works and how it's different from `str_trim()`.
 ```
 
 ```{r}
@@ -178,21 +183,17 @@ titles <- page %>%
 
 ### Links
 
-The same nodes that contain the text for the titles also contains information 
-on the links to individual art piece pages for each title. We can extract this 
-information using a new function from the rvest package, `html_attr()`, which 
-extracts attributes.
+The same nodes that contain the text for the titles also contains information on the links to individual art piece pages for each title.
+We can extract this information using a new function from the rvest package, `html_attr()`, which extracts attributes.
 
-A mini HTML lesson! The following is how we define hyperlinked text in HTML:
+A mini HTML lesson!
+The following is how we define hyperlinked text in HTML:
 
-```
-<a href=""https://www.google.com"">Seach on Google</a>
-```
+    <a href=""https://www.google.com"">Seach on Google</a>
 
 And this is how the text would look like on a webpage: [Seach on Google](https://www.google.com).
 
-Here the text is `Seach on Google` and the `href` attribute contains the url 
-of the website you'd go to if you click on the hyperlinked text: `https://www.google.com`.
+Here the text is `Seach on Google` and the `href` attribute contains the url of the website you'd go to if you click on the hyperlinked text: `https://www.google.com`.
 
 The moral of the story is: the link is stored in the `href` attribute.
 
@@ -203,44 +204,39 @@ page %>%
   html_attr(""href"")             # but get href attribute instead of text
 ```
 
-These don't really look like urls as we know then though. They're relative 
-links.
+These don't really look like URLs as we know then though.
+They're relative links.
 
 ```{marginfigure}
-See the help for `str_replace()` to find out how it works. Remember that the 
-first argument is passed in from the pipeline, so you just need to define the 
-`pattern` and `replacement` arguments.
+See the help for `str_replace()` to find out how it works. Remember that the first argument is passed in from the pipeline, so you just need to define the `pattern` and `replacement` arguments.
 ```
 
-1. Click on one of art piece titles in your browser and take note of the url 
-of the webpage it takes you to. How does that url compare to what we scraped 
-above? How is it different? Using `str_replace()`, fix the URLs.
+1.  Click on one of art piece titles in your browser and take note of the url of the webpage it takes you to. Think about how that url compares to what we scraped above? How is it different? Using `str_replace()`, fix the URLs. You'll note something special happening in the `pattern` to replace. We want to replace the `.`, but we have it as `\\.`. This is because the period `.` is a special character and so we need to escape it first with backslashes, `\\`s.
 
 ### Artists
 
-2. Fill in the blanks to scrape artist names.
+2.  Fill in the blanks to scrape artist names.
 
 ### Put it altogether
 
-3. Fill in the blanks to organize everything in a tibble.
+3.  Fill in the blanks to organize everything in a tibble.
 
 ### Scrape the next page
 
-4. Click on the next page, and grab its url. Fill in the blank in 
-to define a new object: `second_url`. Copy-paste code from top of the R script 
-to scrape the new set of art pieces, and save the resulting data frame as 
-`second_ten`.
+4.  Click on the next page, and grab its url. Fill in the blank in to define a new object: `second_url`. Copy-paste code from top of the R script to scrape the new set of art pieces, and save the resulting data frame as `second_ten`.
+
+‚úÖ ‚¨ÜÔ∏è If you haven't done so recently, c*ommit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
 
 ## Functions
 
-<div class=""box"">
+::: {.box}
 Work in `scripts/02-scrape-page-function.R`.
-</div>
+:::
 
 You've been using R functions, now it's time to write your own!
 
-Let's start simple. Here is a function that takes in an argument `x`, and adds 2 
-to it.
+Let's start simple.
+Here is a function that takes in an argument `x`, and adds 2 to it.
 
 ```{r}
 add_two <- function(x){
@@ -278,148 +274,122 @@ function_name <- function(url){
 }
 ```
 
-5. Fill in the blanks using code you already developed in the previous exercises. 
-Name the function `scrape_page`. 
+5.  Fill in the blanks using code you already developed in the previous exercises. Name the function `scrape_page`.
 
-6. Test out your new function by running the following in the console. Does the 
-output look right? Discuss with teammaates whether you're getting the same results 
-as before.
+Test out your new function by running the following in the console.
+Does the output look right?
+Discuss with teammates whether you're getting the same results as before.
 
 ```{r eval=FALSE}
 scrape_page(first_url)
 scrape_page(second_url)
 ```
 
+‚úÖ ‚¨ÜÔ∏è If you haven't done so recently, c*ommit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
 ## Iteration
 
-<div class=""box"">
+::: {.box}
 Work in `scripts/03-scrape-page-many.R`.
-</div>
+:::
 
-We went from manually scraping individual pages to writing a function to do 
-the same. Next, we will work on making our workflow a little more efficient 
-by using R to iterate over all pages that contain information on the art collection. 
+We went from manually scraping individual pages to writing a function to do the same.
+Next, we will work on making our workflow a little more efficient by using R to iterate over all pages that contain information on the art collection.
 
 ```{marginfigure}
-**Reminder:** The collection has 2909 pieces in total.
+**Reminder:** The collection has 2970 pieces in total.
 ```
 
-That means we give develop a list of URLs (of pages that each have 10 art pieces), 
-and write some code that applies the `scrape_page()` function to each page, and 
-combines the resulting data frames from each page into a single data frame with 
-2909 rows and 3 columns.
+That means we give develop a list of URLs (of pages that each have 10 art pieces), and write some code that applies the `scrape_page()` function to each page, and combines the resulting data frames from each page into a single data frame with 2970 rows and 3 columns.
 
 ### List of URLs
 
-Click through the first few of the pages in the art collection and observe their 
-URLs to confirm the following pattern:
+Click through the first few of the pages in the art collection and observe their URLs to confirm the following pattern:
 
-```
-[sometext]offset=0     # Pieces 1-10
-[sometext]offset=10    # Pieces 11-20
-[sometext]offset=20    # Pieces 21-30
-[sometext]offset=30    # Pieces 31-40
-...
-[sometext]offset=2900  # Pieces 2900-2909
-```
+    [sometext]offset=0     # Pieces 1-10
+    [sometext]offset=10    # Pieces 11-20
+    [sometext]offset=20    # Pieces 21-30
+    [sometext]offset=30    # Pieces 31-40
+    ...
+    [sometext]offset=2960  # Pieces 2961-2970
 
-We can construct these URLs in R by pasting together two pieces: (1) a common 
-(`root`) text for the beginning of the URL, and (2) numbers starting at 0, increasing 
-by 10, all the way up to 2900. Two new functions are helpful for accomplishing 
-this: `paste0()` for pasting two pieces of text and `seq()` for generating a 
-sequence of numbers.
+We can construct these URLs in R by pasting together two pieces: (1) a common (`root`) text for the beginning of the URL, and (2) numbers starting at 0, increasing by 10, all the way up to 2970.
+Two new functions are helpful for accomplishing this: `glue()` for pasting two pieces of text and `seq()` for generating a sequence of numbers.
 
-7. Fill in the blanks to construct the list of URLs. 
+6.  Fill in the blanks to construct the list of URLs.
 
 ### Mapping
 
-Finally, we're ready to iterate over the list of URLs we constructed. We will do 
-this by **map**ping the function we developed over the list of URLs. There are 
-a series of mapping functions in R (which we'll learn about in more detail 
-tomorrow), and they each take the following form:
+Finally, we're ready to iterate over the list of URLs we constructed.
+We will do this by **map**ping the function we developed over the list of URLs.
+There are a series of mapping functions in R (which we'll learn about in more detail tomorrow), and they each take the following form:
 
-```
-map([x], [function to apply to each element of x])
-```
+    map([x], [function to apply to each element of x])
 
-In our case `x` is the list of URLs we constructed and the function to apply 
-to each element of `x` is the function we developed earlier, `scrape_page`.
+In our case `x` is the list of URLs we constructed and the function to apply to each element of `x` is the function we developed earlier, `scrape_page`.
 And as a result we want a data frame, so we use `map_dfr` function:
 
 ```{r eval=FALSE}
 map_dfr(urls, scrape_page)
 ```
 
-8. Fill in the blanks to scrape all pages, and to create a new data frame called 
-`uoe_art`.
+7.  Fill in the blanks to scrape all pages, and to create a new data frame called `uoe_art`.
 
 ### Write out data
 
-9. Finally write out the data frame you constructed into the `data` folder so 
-that you can use it in the analysis section.
+8.  Finally write out the data frame you constructed into the `data` folder so that you can use it in the analysis section.
+
+::: {.marker}
+Aim to make it to this point during the workshop.
+:::
+
+‚úÖ ‚¨ÜÔ∏è If you haven't done so recently, c*ommit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
 
 ## Analysis
 
-<div class=""box"">
-Work in `lab-06-uoe-art.Rmd` for the rest of the lab.
-</div>
+::: {.box}
+Work in `lab-08.Rmd` for the rest of the lab.
+:::
 
 Now that we have a tidy dataset that we can analyze, let's do that!
 
-We'll start with some data cleaning, to clean up the dates that appear at the 
-end of some title text in parentheses. Some of these are years, others are 
-more specific dates, some art pieces have no date information whatsoever, and 
-others have some non-date information in parentheses. This should be interesting 
-to clean up!
+We'll start with some data cleaning, to clean up the dates that appear at the end of some title text in parentheses.
+Some of these are years, others are more specific dates, some art pieces have no date information whatsoever, and others have some non-date information in parentheses.
+This should be interesting to clean up!
 
-First thing we'll try is to separate the `title` column into two: one for the 
-actual `title` and the other for the `date` if it exists. In human speak, we 
-need to 
+First thing we'll try is to separate the `title` column into two: one for the actual `title` and the other for the `date` if it exists.
+In human speak, we need to
 
-> ""separate the `title` column at the first occurence of `(` and put the contents on one side of the `(` into a column called `title` and the contents on the other side into a column called `date`""
+> ""separate the `title` column at the first occurrence of `(` and put the contents on one side of the `(` into a column called `title` and the contents on the other side into a column called `date`""
 
 Luckily, there's a function that does just this: `separate()`!
 
-And once we have completed separating the single `title` column into `title` 
-and `date`, we need to do further cleanup in the `date` column to get rid of 
-extraneous `)`s with `str_remove()`, capture year information, and save the data 
-as a numeric variable.
+And once we have completed separating the single `title` column into `title` and `date`, we need to do further clean-up in the `date` column to get rid of extraneous `)`s with `str_remove()`, capture year information, and save the data as a numeric variable.
 
 ```{marginfigure}
-**Hint:** Remember escaping special characters from yesterday's lecture? You'll 
-need to use that trick again.
+**Hint:** Remember escaping special characters from yesterday's lecture? You'll need to use that trick again.
 ```
 
-10. Fill in the blanks in to implement the data wrangling we described above. 
-Note that this will result in some warnings when you run the code, and that's OK! 
-Read the warnings, and explain what they mean, and why we are ok with leaving 
-them in given that our objective is to just capture `year` where it's convenient 
-to do so.
-
-11. Print out a summary of the dataframe using the `skim()` function. How many 
-pieces have artist info missing? How many have year info missing?
-
-12. Make a histogram of years. Use a reasonable binwidth. Do you see anything 
-out of the ordinary?
+9.  Fill in the blanks in to implement the data wrangling we described above. Note that this will result in some warnings when you run the code, and that's OK! Read the warnings, and explain what they mean, and why we are ok with leaving them in given that our objective is to just capture `year` where it's convenient to do so.
+10. Print out a summary of the data frame using the `skim()` function. How many pieces have artist info missing? How many have year info missing?
+11. Make a histogram of years. Use a reasonable binwidth. Do you see anything out of the ordinary?
 
 ```{marginfigure}
-**Hint:** You'll want to use `mutate()` and `if_else()` or `case_when()` to 
-implement the correction.
+**Hint:** You'll want to use `mutate()` and `if_else()` or `case_when()` to implement the correction.
 ```
 
-13. Find which piece has the out of the ordinary year and go to its page on the 
-art collection website to find the correct year for it. Can you tell why our code 
-didn't capture the correct year information? Correct the error in the data frame 
-and visualize the data again.
+12. Find which piece has the out of the ordinary year and go to its page on the art collection website to find the correct year for it. Can you tell why our code didn't capture the correct year information? Correct the error in the data frame and visualize the data again.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è *If you haven't done so recently, knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
 
-14. Who is the most commonly featured artist in the collection? Do you know them? 
-Any guess as to why the university has so many pieces from them?
+13. Who is the most commonly featured artist in the collection? Do you know them? Any guess as to why the university has so many pieces from them?
 
 ```{marginfigure}
-**Hint:** You'll want to use a combination of `filter()` and `str_detect()`. 
-You will want to read the help for `str_detect()` at a minimum, and consider 
-how you might capture titles where the word appears as ""child"" and ""Child"".
+**Hint:** `str_subset()` can be helful here. You should consider how you might capture titles where the word appears as ""child"" and ""Child"".
 ```
 
-15. Final question! How many art pieces have the word ""child"" in their title? See 
-if you can figure it out, and ask for help if not.
+14. Final question! How many art pieces have the word ""child"" in their title? Try to figure it out, and ask for help if you're stuck.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you're happy with the final state of your work.*
+
+[^lab-08-uoe-art-1]: Source: <https://collections.ed.ac.uk/art/about>

---FILE: course-materials/lab-instructions/lab-09/lab-09-better-viz.Rmd---
@@ -0,0 +1,88 @@
+---
+title: ""Lab 09 - Conveying the right message through visualisation""
+output: 
+  tufte::tufte_html:
+    tufte_variant: ""envisioned""
+    highlight: pygments
+    css: ../lab.css
+link-citations: yes
+---
+
+In this lab our goal is to reconstruct and improve a data visualisation on COVID and mask wearing.
+
+# Learning goals
+
+-   Critiquing visualisations that misrepresent data
+-   Improving data visualisations to better convey the right message
+
+# Getting started
+
+Go to the course GitHub organization and locate your homework repo, clone it in RStudio and open the R Markdown document.
+Knit the document to make sure it compiles without errors.
+
+## Warm up
+
+Let's warm up with some simple exercises.
+Update the YAML of your R Markdown file with your information, knit, commit, and push your changes.
+Make sure to commit with a meaningful commit message.
+Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd **and** md files.
+If anything is missing, commit and push again.
+
+## Packages
+
+We'll use the **tidyverse** package for much of the data wrangling and visualisation.
+This package is already installed for you.
+You can load it by running the following in your Console:
+
+```{r load-packages, message = FALSE}
+library(tidyverse)
+```
+
+## Data
+
+In this lab you'll construct the dataset!
+
+# Exercises
+
+The following visualisation was shared [on Twitter](https://twitter.com/JonBoeckenstedt/status/1291602888376999936) as ""extraordinary misleading"".
+
+```{r fig.fullwidth = TRUE, echo = FALSE}
+knitr::include_graphics(""img/masks-v-nomasks.png"")
+```
+
+Before you join the workshop, think about what is misleading about this visualisation and how you might go about fixing it.
+Take some notes and bring your notes to the workshop to share with your teammates.
+
+1.  Create a data frame that can be used to re-construct this visualisation. You may need to guess some of the numbers, that's ok. You should first think about how many rows and columns you'll need and what you want to call your variables. Then, you can use the `tribble()` function for this. For example, if you wanted to construct the following data frame
+
+```{r tribble, echo = FALSE}
+df <- tribble(
+  ~date, ~count,
+  ""1/1/2020"", 15,
+  ""2/1/2020"", 20,
+  ""3/1/2020"", 22,
+)
+```
+
+```{r}
+df
+```
+
+you can write
+
+```{r ref.label=""tribble"", eval = FALSE}
+```
+
+```{marginfigure}
+Since the exercises for this week are short it's possible not every team member will get to commit and push **during** the workshop. However each team member should review what was created, fix typos, make edits for better presentation, etc. either during or after the workshop, and before the deadline.
+```
+
+2.  Make a visualisation that more accurately (and honestly) tells the story.
+
+3.  What message is more clear in your visualisation than it was in the original visualisation?
+
+4.  What, if any, useful information do these data and your visualisation tell us about mask wearing and COVID?
+    It'll be difficult to set aside what you already know about mask wearing, but you should try to focus only on what this visualisation tells.
+    Feel free to also comment on whether that lines up with what you know about mask wearing.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you're happy with the final state of your work.*

---FILE: course-materials/lab-instructions/lab-09/lab-09-modelling-course-evals.Rmd---
@@ -1,145 +0,0 @@
----
-title: ""Lab 06 - Professor attractiveness and course evaluations, Pt 1""
-subtitle: ""Modelling with a single predictor""
-output: 
-  tufte::tufte_html:
-    tufte_variant: ""envisioned""
-    highlight: pygments
-    css: ../lab.css
-link-citations: yes
----
-
-```{r include=FALSE}
-library(tufte)
-library(knitr)
-options(
-  htmltools.dir.version = FALSE, # for blogdown
-  show.signif.stars = FALSE,     # for regression output
-  digits = 2
-  )
-knitr::opts_chunk$set(eval = FALSE)
-```
-
-## Getting started
-
-Many college courses conclude by giving students the opportunity to evaluate the course and the instructor anonymously. However, the use of these student evaluations as an indicator of course quality and teaching effectiveness is often criticized because these measures may reflect the influence of non-teaching related characteristics, such as the physical appearance of the instructor. The article titled, ""Beauty in the classroom: instructors‚Äô pulchritude and putative pedagogical productivity"" (Hamermesh and Parker, 2005) found that instructors who are viewed to be better looking receive higher instructional ratings. (Daniel S. Hamermesh, Amy Parker, Beauty in the classroom: instructors pulchritude and putative pedagogical productivity, Economics of Education Review, Volume 24, Issue 4, August 2005, Pages 369-376, ISSN 0272-7757, 10.1016/j.econedurev.2004.07.013. http://www.sciencedirect.com/science/article/pii/S0272775704001165.)
-
-For this assignment you will analyze the data from this study in order to learn what goes into a positive professor evaluation.
-
-The data were gathered from end of semester student evaluations for a large sample of professors from the University of Texas at Austin. In addition, six students rated the professors‚Äô physical appearance. (This is a slightly modified version of the original data set that was released as part of the replication data for Data Analysis Using Regression and Multilevel/Hierarchical Models (Gelman and Hill, 2007).) The result is a data frame where each row contains a different course and columns represent variables about the courses and professors.
-
-### Packages
-
-In this lab we will work with the **tidyverse**, **openintro**, and **broom** packages.
-
-```{r eval = FALSE}
-library(tidyverse) 
-library(broom)
-library(openintro)
-```
-
-### Housekeeping
-
-#### Git configuration / password caching
-
-Configure your Git user name and email. If you cannot remember the instructions, refer to an earlier lab. Also remember that you can cache your password for a limited amount of time.
-
-#### Project name
-
-Update the name of your project to match the lab's title.
-
-## Warm up
-
-**Pick one team member to complete the steps in this section while the others contribute to the discussion but do not actually touch the files on their computer.**
-
-Before we introduce the data, let's warm up with some simple exercises.
-
-### YAML
-
-Open the R Markdown (Rmd) file in your project, change the author name to your **team** name, and knit the document.
-
-### Commiting and pushing changes
-
-- Go to the **Git** pane in your RStudio. 
-- View the **Diff** and confirm that you are happy with the changes.
-- Add a commit message like ""Update team name"" in the **Commit message** box and hit **Commit**.
-- Click on **Push**. This will prompt a dialogue box where you first need to enter your user name, and then your password.
-
-### Pulling changes
-
-Now, the remaining team members who have not been concurrently making these changes on their projects should click on the **Pull** button in their Git pane and observe that the changes are now reflected on their projects as well.
-
-## The data
-
-The dataset we'll be using is called `evals` from the **openintro** package. Take a peek at the codebook with `?evals`.
-
-## Exercises
-
-### Part 1: Exploratory Data Analysis
-
-1.  Visualize the distribution of `score`. Is the distribution skewed? What does 
-    that tell you about how students rate courses? Is this what you expected to 
-    see? Why, or why not? Include any summary statistics and visualizations
-    you use in your response.
-
-2.  Visualize and describe the relationship between `score` and the new variable you 
-    created, `bty_avg`.
-    
-```{marginfigure}
-**Hint:** See the help page for the function at http://ggplot2.tidyverse.org/reference/index.html.
-```
-    
-3.  Replot the scatterplot from Exercise 3, but this time use  
-    `geom_jitter()`? What does ""jitter"" mean? 
-    What was misleading about the initial scatterplot?
-
-### Part 2: Linear regression with a numerical predictor
-
-```{marginfigure}
-Linear model is in the form $\hat{y} = b_0 + b_1 x$.
-```
-
-4.  Let's see if the apparent trend in the plot is something more than
-    natural variation. Fit a linear model called `m_bty` to predict average
-    professor evaluation `score` by average beauty rating (`bty_avg`). Based on the 
-    regression output, write the linear model.
-    
-5.  Replot your visualization from Exercise 3, and add the regression line to this plot
-    in orange color. Turn off the shading for the uncertainty of the line.
-    
-6.  Interpret the slope of the linear model in context of the data.
-
-7.  Interpret the intercept of the linear model in context of the data. Comment on whether 
-    or not the intercept makes sense in this context.
-    
-8.  Determine the $R^2$ of the model and interpret it in context of the data.
-
-### Part 3: Linear regression with a categorical predictor
-
-9.  Fit a new linear model called `m_gen` to predict average professor evaluation `score` 
-    based on `gender` of the professor. Based on the regression output, write the linear 
-    model and interpret the slope and intercept in context of the data.
-    
-10. What is the equation of the line corresponding to male professors? What is it for 
-    female professors?
-    
-11. Fit a new linear model called `m_rank` to predict average professor evaluation `score` 
-    based on `rank` of the professor. Based on the regression output, write the linear 
-    model and interpret the slopes and intercept in context of the data.
-
-12. Create a new variable called `rank_relevel` where `""tenure track""` is the baseline level. 
-
-13. Fit a new linear model called `m_rank_relevel` to predict average professor evaluation 
-    `score` based on `rank_relevel` of the professor. This is the new (releveled) variable 
-    you created in Exercise 13. Based on the regression output, write the linear 
-    model and interpret the slopes and intercept in context of the data. Also determine and 
-    interpret the $R^2$ of the model.
-    
-14. Create another new variable called `tenure_eligible` that labels `""teaching""` faculty as 
-    `""no""` and labels `""tenure track""` and `""tenured""` faculty as `""yes""`.
-  
-15. Fit a new linear model called `m_tenure_eligible` to predict average professor evaluation 
-    `score` based on `tenure_eligible`ness of the professor. This is the new (regrouped) variable 
-    you created in Exercise 15. Based on the regression output, write the linear 
-    model and interpret the slopes and intercept in context of the data. Also determine and 
-    interpret the $R^2$ of the model.

---FILE: course-materials/lab-instructions/lab-10/lab-10-mlr-course-evals.Rmd---
@@ -1,147 +0,0 @@
----
-title: ""Lab 07 - Professor attractiveness and course evaluations, Pt. 2""
-subtitle: ""Modelling with multiple predictors""
-output: 
-  tufte::tufte_html:
-    tufte_variant: ""envisioned""
-    highlight: pygments
-    css: ../lab.css
-link-citations: yes
----
-
-```{r include=FALSE}
-library(tufte)
-library(knitr)
-options(
-  htmltools.dir.version = FALSE, # for blogdown
-  show.signif.stars = FALSE,     # for regression output
-  digits = 2
-  )
-knitr::opts_chunk$set(eval = FALSE)
-```
-
-In this lab we revisit the professor evaluations data we modeled in the previous lab. In the last lab we modeled evaluation scores using a single predictor at a time. However this time we use multiple predictors to model evaluation scores.
-
-If you don't remember the data, review the previous lab's introduction before continuing to the exercises.
-
-## Getting started
-
-### Packages
-
-In this lab we will work with the **tidyverse**, **openintro**, and **broom** packages.
-
-```{r eval = FALSE}
-library(tidyverse) 
-library(broom)
-library(openintro)
-```
-
-### Housekeeping
-
-#### Git configuration / password caching
-
-Configure your Git user name and email. If you cannot remember the instructions, refer to an earlier lab. Also remember that you can cache your password for a limited amount of time.
-
-#### Project name
-
-Update the name of your project to match the lab's title.
-
-## Warm up
-
-**Pick one team member to complete the steps in this section while the others contribute to the discussion but do not actually touch the files on their computer.**
-
-Before we introduce the data, let's warm up with some simple exercises.
-
-### YAML
-
-Open the R Markdown (Rmd) file in your project, change the author name to your **team** name, and knit the document.
-
-### Commiting and pushing changes
-
-- Go to the **Git** pane in your RStudio. 
-- View the **Diff** and confirm that you are happy with the changes.
-- Add a commit message like ""Update team name"" in the **Commit message** box and hit **Commit**.
-- Click on **Push**. This will prompt a dialogue box where you first need to enter your user name, and then your password.
-
-### Pulling changes
-
-Now, the remaining team members who have not been concurrently making these changes on their projects should click on the **Pull** button in their Git pane and observe that the changes are now reflected on their projects as well.
-
-## The data
-
-The dataset we'll be using is called `evals` from the **openintro** package. Take a peek at the codebook with `?evals`.
-
-## Exercises
-
-1. Load the data by including the appropriate code in your R Markdown file.
-
-### Part 1: Simple linear regression
-
-2. Fit a linear model (one you have fit before): `m_bty`, predicting average
-   professor evaluation `score` based on average beauty rating (`bty_avg`) only. Write the 
-   linear model, and note the $R^2$ and the adjusted $R^2$.
-
-### Part 2: Multiple linear regression
-
-2. Fit a linear model (one you have fit before): `m_bty_gen`, predicting average
-   professor evaluation `score` based on average beauty rating (`bty_avg`) and `gender`. 
-   Write the linear model, and note the $R^2$ and the adjusted $R^2$.
-   
-3. Interpret the slope and intercept of `m_bty_gen` in context of the data.
-
-4. What percent of the variability in `score` is explained by the model `m_bty_gen`.
-
-5.  What is the equation of the line corresponding to *just* male professors?
-    
-6.  For two professors who received the same beauty rating, which gender tends 
-    to have the higher course evaluation score?
-    
-7. How does the relationship between beauty and evaluation score
-    vary between male and female professors?
-    
-8. How do the adjusted $R^2$ values of `m_bty_gen` and `m_bty` compare? What does this tell us 
-   about how useful `gender` is in explaining the variability in evaluation scores when we 
-   already have information on the beaty score of the professor.
-
-9. Compare the slopes of `bty_avg` under the two models (`m_bty` and `m_bty_gen`). Has the 
-   addition of `gender` to the model changed the parameter estimate (slope) for `bty_avg`?
-    
-10. Create a new model called `m_bty_rank` with `gender` removed and `rank` 
-    added in. Write the equation of the linear model and interpret the slopes and intercept 
-    in context of the data. 
-
-### Part 3: The search for the best model
-
-Going forward, only consider the following variables as potential predictors: `rank`, 
-`ethnicity`, `gender`, `language`, `age`, `cls_perc_eval`, `cls_did_eval`, `cls_students`, 
-`cls_level`, `cls_profs`, `cls_credits`, `bty_avg`.
-
-11. Which variable, on its own, would you expect to be the worst predictor of 
-    evaluation scores? Why? *Hint:* Think about which variable would you 
-    expect to not have any association with the professor's score.
-
-12. Check your suspicions from the previous exercise. Include the model output
-    for that variable in your response.
-    
-13. Suppose you wanted to fit a full model with the variables listed above. If 
-    you are already going to include `cls_perc_eval` and `cls_students`, which variable 
-    should you not include as an additional predictor? Why?
-
-14. Fit a full model with all predictors listed above (except for the one you decided to 
-    exclude) in the previous question.
-
-15. Using backward-selection with adjusted R-squared as the selection 
-    criterion, determine the *best* model. You do not need to show all 
-    steps in your answer, just the output for the final model. Also, 
-    write out the linear model for predicting score based on the final 
-    model you settle on.
-
-16. Interpret the slopes of one numerical and one categorical predictor based on your final model.
-
-17. Based on your final model, describe the characteristics of a professor and 
-    course at University of Texas at Austin that would be associated with a high
-    evaluation score.
-
-18. Would you be comfortable generalizing your conclusions to apply to professors
-    generally (at any university)? Why or why not?
-    
\ No newline at end of file

---FILE: course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.Rmd---
@@ -0,0 +1,133 @@
+---
+title: ""Lab 10 - Grading the professor, Pt. 1""
+subtitle: ""Modelling with a single predictor""
+output: 
+  tufte::tufte_html:
+    tufte_variant: ""envisioned""
+    highlight: pygments
+    css: ../lab.css
+link-citations: yes
+---
+
+```{r include=FALSE}
+knitr::opts_chunk$set(eval = FALSE)
+```
+
+Many college courses conclude by giving students the opportunity to evaluate the course and the instructor anonymously.
+However, the use of these student evaluations as an indicator of course quality and teaching effectiveness is often criticized because these measures may reflect the influence of non-teaching related characteristics, such as the physical appearance of the instructor.
+The article titled, ""Beauty in the classroom: instructors' pulchritude and putative pedagogical productivity"" (Hamermesh and Parker, 2005) found that instructors who are viewed to be better looking receive higher instructional ratings.
+(Daniel S. Hamermesh, Amy Parker, Beauty in the classroom: instructors pulchritude and putative pedagogical productivity, Economics of Education Review, Volume 24, Issue 4, August 2005, Pages 369-376, ISSN 0272-7757, 10.1016/j.econedurev.2004.07.013. <http://www.sciencedirect.com/science/article/pii/S0272775704001165>.)
+
+In this lab you will analyze the data from this study in order to learn what goes into a positive professor evaluation.
+
+The data were gathered from end of semester student evaluations for a large sample of professors from the University of Texas at Austin.
+In addition, six students rated the professors' physical appearance.
+(This is a slightly modified version of the original data set that was released as part of the replication data for Data Analysis Using Regression and Multilevel/Hierarchical Models (Gelman and Hill, 2007).) The result is a data frame where each row contains a different course and columns represent variables about the courses and professors.
+
+# Learning goals
+
+-   Fitting a linear regression with a single numerical and categorical predictor
+-   Interpreting regression output in context of the data
+-   Comparing models
+
+# Getting started
+
+Go to the course GitHub organization and locate your homework repo, clone it in RStudio and open the R Markdown document.
+Knit the document to make sure it compiles without errors.
+
+## Warm up
+
+Let's warm up with some simple exercises.
+Update the YAML of your R Markdown file with your information, knit, commit, and push your changes.
+Make sure to commit with a meaningful commit message.
+Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd **and** md files.
+If anything is missing, commit and push again.
+
+## Packages
+
+We'll use the **tidyverse** package for much of the data wrangling and visualisation, the **tidymodels** package for modeling and inference, and the data lives in the **dsbox** package.
+These packages are already installed for you.
+You can load them by running the following in your Console:
+
+```{r}
+library(tidyverse) 
+library(tidymodels)
+library(openintro)
+```
+
+## Data
+
+The data can be found in the **dsbox** package, and it's called `evals`.
+Since the dataset is distributed with the package, we don't need to load it separately; it becomes available to us when we load the package.
+You can find out more about the dataset by inspecting its documentation, which you can access by running `?evals` in the Console or using the Help menu in RStudio to search for `evals`.
+You can also find this information [here](https://rstudio-education.github.io/dsbox/reference/evals.html).
+
+# Exercises
+
+## Exploratory Data Analysis
+
+1.  Visualize the distribution of `score`.
+    Is the distribution skewed?
+    What does that tell you about how students rate courses?
+    Is this what you expected to see?
+    Why, or why not?
+    Include any summary statistics and visualizations you use in your response.
+
+2.  Visualize and describe the relationship between `score` and `bty_avg`.
+
+```{marginfigure}
+**Hint:** See the help page for the function at http://ggplot2.tidyverse.org/reference/index.html.
+```
+
+3.  Recreate the scatterplot from Exercise 3, but this time use\
+    `geom_jitter()`? What does ""jitter"" mean? What was misleading about the initial scatterplot?
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è *If you haven't done so recently, knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+## Linear regression with a numerical predictor
+
+```{marginfigure}
+Linear model is in the form $\hat{y} = b_0 + b_1 x$.
+```
+
+4.  Let's see if the apparent trend in the plot is something more than natural variation.
+    Fit a linear model called `score_bty_fit` to predict average professor evaluation `score` by average beauty rating (`bty_avg`).
+    Based on the regression output, write the linear model.
+
+5.  Recreate the scatterplot from Exercise 3, and add the regression line to this plot in orange colour, with shading for the uncertainty of the line turned off.
+
+6.  Interpret the slope of the linear model in context of the data.
+
+7.  Interpret the intercept of the linear model in context of the data.
+    Comment on whether or not the intercept makes sense in this context.
+
+8.  Determine the $R^2$ of the model and interpret it in context of the data.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è *If you haven't done so recently, knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+## Linear regression with a categorical predictor
+
+9.  Fit a new linear model called `score_bty_gender` to predict average professor evaluation `score` based on `gender` of the professor.
+    Based on the regression output, write the linear model and interpret the slope and intercept in context of the data.
+
+10. What is the equation of the line corresponding to male professors?
+    What is it for female professors?
+
+11. Fit a new linear model called `score_bty_rank` to predict average professor evaluation `score` based on `rank` of the professor.
+    Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data.
+
+12. Create a new variable called `rank_relevel` where `""tenure track""` is the baseline level.
+
+13. Fit a new linear model called `score_bty_rank_relevel` to predict average professor evaluation `score` based on `rank_relevel` of the professor.
+    This is the new (releveled) variable you created in Exercise 13.
+    Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data.
+    Also determine and interpret the $R^2$ of the model.
+
+14. Create another new variable called `tenure_eligible` that labels `""teaching""` faculty as `""no""` and labels `""tenure track""` and `""tenured""` faculty as `""yes""`.
+
+15. Fit a new linear model called `score_bty_tenure_eligible` to predict average professor evaluation `score` based on `tenure_eligible`ness of the professor.
+    This is the new (regrouped) variable you created in the previous exercise.
+    Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data.
+    Also determine and interpret the $R^2$ of the model.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you're happy with the final state of your work.*

---FILE: course-materials/lab-instructions/lab-11/lab-11-inference-smoking.Rmd---
@@ -1,186 +0,0 @@
----
-title: ""Lab 11 - So what if you smoke when pregnant?""
-subtitle: ""Simulation based inference""
-output: 
-  tufte::tufte_html:
-    tufte_variant: ""envisioned""
-    highlight: pygments
-    css: ../lab.css
-link-citations: yes
----
-
-```{r include=FALSE}
-library(tufte)
-library(knitr)
-options(
-  htmltools.dir.version = FALSE, # for blogdown
-  show.signif.stars = FALSE,     # for regression output
-  digits = 2
-  )
-knitr::opts_chunk$set(eval = TRUE)
-```
-
-In 2004, the state of North Carolina released a large data set containing 
-information on births recorded in this state. This data set is useful to 
-researchers studying the relation between habits and practices of expectant 
-mothers and the birth of their children. We will work with a random sample of 
-observations from this data set.
-
-## Getting started
-
-### Packages
-
-In this lab we will work with the **tidyverse**, **infer**, and **openintro** packages. We can install and load them with the following:
-
-```{r load-packages, message=FALSE}
-library(tidyverse) 
-library(infer)
-library(openintro)
-```
-
-## Housekeeping
-
-### Git configuration / password caching
-
-Configure your Git user name and email. If you cannot remember the instructions, refer to an earlier lab. Also remember that you can cache your password for a limited amount of time.
-
-### Project name
-
-Update the name of your project to match the lab's title.
-
-## Warm up
-
-**Pick one team member to complete the steps in this section while the others contribute to the discussion but do not actually touch the files on their computer.**
-
-Before we introduce the data, let's warm up with some simple exercises.
-
-### YAML
-
-Open the R Markdown (Rmd) file in your project, change the author name to your **team** name, and knit the document.
-
-### Commiting and pushing changes
-
-- Go to the **Git** pane in your RStudio. 
-- View the **Diff** and confirm that you are happy with the changes.
-- Add a commit message like ""Update team name"" in the **Commit message** box and hit **Commit**.
-- Click on **Push**. This will prompt a dialogue box where you first need to enter your user name, and then your password.
-
-### Pulling changes
-
-Now, the remaining team members who have not been concurrently making these changes on their projects should click on the **Pull** button in their Git pane and observe that the changes are now reflected on their projects as well.
-
-## Set a seed!
-
-In this lab we'll be generating random samples. The last thing you want is those samples to change every time you knit your document. So, you should set a seed. There's an R chunk in your R Markdown file set aside for this. Locate it and add a seed. Make sure all members in a team are using the same seed so that you don't get merge conflicts and your results match up for the narratives.
-
-## The data
-
-Load the `ncbirths` data from the `openintro` package:
-
-```{r load-data}
-data(ncbirths)
-```
-
-We have observations on 13 different variables, some categorical and some 
-numerical. The meaning of each variable is as follows.
-
-variable         | description
----------------- | ---------------------------------------------
-`fage`           | father's age in years.
-`mage`           | mother's age in years.
-`mature`         | maturity status of mother.
-`weeks`          | length of pregnancy in weeks.
-`premie`         | whether the birth was classified as premature (premie) or full-term.
-`visits`         | number of hospital visits during pregnancy.
-`marital`        | whether mother is `married` or `not married` at birth.
-`gained`         | weight gained by mother during pregnancy in pounds.
-`weight`         | weight of the baby at birth in pounds.
-`lowbirthweight` | whether baby was classified as low birthweight (`low`) or not (`not low`).
-`gender`         | gender of the baby, `female` or `male`.
-`habit`          | status of the mother as a `nonsmoker` or a `smoker`.
-`whitemom`       | whether mom is `white` or `not white`.
-
-## Exercises
-
-1.  What are the cases in this data set? How many cases are there in our sample?
-
-The first step in the analysis of a new dataset is getting acquanted with the data.
-Make summaries of the variables in your dataset, determine  which variables are 
-categorical and which are numerical. For numerical variables, are there outliers? 
-If you aren't sure or want to take a closer look at the data, make a graph.
-
-### Baby weights
-
-```{marginfigure}
-Wen, Shi Wu, Michael S. Kramer, and Robert H. Usher. ""Comparison of birth weight distributions between Chinese and Caucasian infants."" American Journal of Epidemiology 141.12 (1995): 1177-1187.
-````
-
-A 1995 study suggestes that average weight of Caucasian babies born in the US is 3,369 grams (7.43 pounds). In this dataset we only have information on mother's race, so we will make the simplifying assumption that babies of Caucasian mothers are also Caucasian, i.e. `whitemom = ""white""`. 
-
-We want to evaluate whether the average weight of Caucasian babies has changed since 1995.
-
-Our null hypothesis should state ""there is nothing going on"", i.e. no change since 1995: $H_0: \mu = 7.43~pounds$.
-
-Our alternative hypothesis should reflect the research question, i.e. some change since 1995. Since the research question doesn't state a direction for the change, we use a two sided alternative hypothesis: $H_A: \mu \ne 7.43~pounds$.
-
-3. Create a filtered data frame called `ncbirths_white` that contain data only from white mothers. Then, calculate the mean of the weights of their babies.
-
-4. Are the conditions necessary for conducting simulation based inference satisfied? Explain your reasoning.
-
-Let's discuss how this test would work. Our goal is to simulate a null distribution of sample means that is centered at the null value of 7.43 pounds. In order to do so, we 
-
-- take a bootstrap sample of from the original sample,
-- calculate this bootstrap sample's mean,
-- repeat these two steps a large number of times to create a bootstrap distribution of means centered at the observed sample mean,
-- shift this distribution to be centered at the null value by substracting / adding X to all boostrap mean (X = difference between mean of bootstrap distribution and null value), and
-- calculate the p-value as the proportion of bootstrap samples that yielded a sample mean at least as extreme as the observed sample mean.
-
-5. Run the appropriate hypothesis test, visualize the null distribution, calculate the p-value, and interpret the results in context of the data and the hypothesis test.
-
-### Baby weight vs. smoking
-
-Consider the possible relationship between a mother's smoking habit and the 
-weight of her baby. Plotting the data is a useful first step because it helps 
-us quickly visualize trends, identify strong associations, and develop research
-questions.
-
-6.  Make side-by-side boxplots displaying the relationship between `habit` and 
-`weight`. What does the plot highlight about the relationship between these 
-two variables?
-
-7. Before moving forward, save a version of the dataset omitting observations where there are NAs for `habit`. You can call this version `ncbirths_habitgiven`.
-
-The box plots show how the medians of the two distributions compare, but we can
-also compare the means of the distributions using the following to 
-first group the data by the `habit` variable, and then calculate the mean
-`weight` in these groups using.
-
-```{r habit-means, eval=FALSE}
-ncbirths_habitgiven %>%
-  group_by(habit) %>%
-  summarise(mean_weight = mean(weight))
-```
-
-There is an observed difference, but is this difference statistically 
-significant? In order to answer this question we will conduct a hypothesis test
-.
-
-7. Write the hypotheses for testing if the average weights of babies born to 
-smoking and non-smoking mothers are different.
-
-8. Are the conditions necessary for conducting simulation based inference satisfied? Explain your reasoning.
-
-9. Run the appropriate hypothesis test, calculate the p-value, and interpret the results in context of the data and the hypothesis test.
-
-10. Construct a 95% confidence interval for the difference between the average weights of babies born to smoking and non-smoking mothers.
-
-### Baby weight vs. mother's age
- 
-In this portion of the analysis we focus on two variables. The first one is `maturemom`.
-
-11. First, a non-inference task: Determine the age cutoff for younger and mature 
-mothers. Use a method of your choice, and explain how your method works.
-
-The other variable of interest is `lowbirthweight`.
-
-12. Conduct a hypothesis test evaluating whether the proportion of low birth weight babies is higher for mature mothers. State the hypotheses, verify the conditions, run the test and calculate the p-value, and state your conclusion in context of the research question. Use $\alpha = 0.05$. If you find a significant difference, costruct a confidence interval, at the equivalent level to the hypothesis test, for the difference between the proportions of low birth weight babies between mature and younger moms, and interpret this interval in context of the data.

---FILE: course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.Rmd---
@@ -0,0 +1,94 @@
+---
+title: ""Lab 11 - Grading the professor, Pt. 2""
+subtitle: ""Modelling with multiple predictors""
+output: 
+  tufte::tufte_html:
+    tufte_variant: ""envisioned""
+    highlight: pygments
+    css: ../lab.css
+link-citations: yes
+---
+
+```{r include=FALSE}
+knitr::opts_chunk$set(eval = FALSE)
+```
+
+In this lab we revisit the professor evaluations data we modelled in the previous lab.
+In the last lab we modelled evaluation scores using a single predictor at a time.
+This time we will use multiple predictors to model evaluation scores.
+
+For context, review the previous lab's introduction before continuing on to the exercises.
+
+# Learning goals
+
+-   Fitting a linear regression with multiple predictors
+-   Interpreting regression output in context of the data
+-   Comparing models
+
+# Getting started
+
+Go to the course GitHub organization and locate your homework repo, clone it in RStudio and open the R Markdown document.
+Knit the document to make sure it compiles without errors.
+
+## Warm up
+
+Let's warm up with some simple exercises.
+Update the YAML of your R Markdown file with your information, knit, commit, and push your changes.
+Make sure to commit with a meaningful commit message.
+Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd **and** md files.
+If anything is missing, commit and push again.
+
+## Packages
+
+We'll use the **tidyverse** package for much of the data wrangling and visualisation, the **tidymodels** package for modeling and inference, and the data lives in the **dsbox** package.
+These packages are already installed for you.
+You can load them by running the following in your Console:
+
+```{r}
+library(tidyverse) 
+library(tidymodels)
+library(openintro)
+```
+
+## Data
+
+The data can be found in the **dsbox** package, and it's called `evals`.
+Since the dataset is distributed with the package, we don't need to load it separately; it becomes available to us when we load the package.
+You can find out more about the dataset by inspecting its documentation, which you can access by running `?evals` in the Console or using the Help menu in RStudio to search for `evals`.
+You can also find this information [here](https://rstudio-education.github.io/dsbox/reference/evals.html).
+
+# Exercises
+
+1.  Load the data by including the appropriate code in your R Markdown file.
+
+## Simple linear regression
+
+2.  Fit a linear model (one you have fit before): `score_bty_fit`, predicting average professor evaluation `score` based on average beauty rating (`bty_avg`) only. Write the linear model, and note the $R^2$ and the adjusted $R^2$.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è *If you haven't done so recently, knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*
+
+## Multiple linear regression
+
+3.  Fit a linear model (one you have fit before): `score_bty_gender_fit`, predicting average professor evaluation `score` based on average beauty rating (`bty_avg`) and `gender`.
+    Write the linear model, and note the $R^2$ and the adjusted $R^2$.
+
+4.  Interpret the slopes and intercept of `score_bty_gen_fit` in context of the data.
+
+5.  What percent of the variability in `score` is explained by the model `score_bty_gen_fit`.
+
+6.  What is the equation of the line corresponding to *just* male professors?
+
+7.  For two professors who received the same beauty rating, which gender tends to have the higher course evaluation score?
+
+8.  How does the relationship between beauty and evaluation score vary between male and female professors?
+
+9.  How do the adjusted $R^2$ values of `score_bty_gen_fit` and `score_bty_fit` compare?
+    What does this tell us about how useful `gender` is in explaining the variability in evaluation scores when we already have information on the beuaty score of the professor.
+
+10. Compare the slopes of `bty_avg` under the two models (`score_bty_fit` and `score_bty_gen_fit`).
+    Has the addition of `gender` to the model changed the parameter estimate (slope) for `bty_avg`?
+
+11. Create a new model called `score_bty_rank_fit` with `gender` removed and `rank` added in.
+    Write the equation of the linear model and interpret the slopes and intercept in context of the data.
+
+üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you're happy with the final state of your work.*

---FILE: course-materials/lab-instructions/lab-12/lab-12-inference-smoking.Rmd---
@@ -0,0 +1,149 @@
+---
+title: ""Lab 12 - Smoking during pregnacy""
+subtitle: ""Simulation based inference""
+output: 
+  tufte::tufte_html:
+    tufte_variant: ""envisioned""
+    highlight: pygments
+    css: ../lab.css
+link-citations: yes
+---
+
+```{r include=FALSE}
+knitr::opts_chunk$set(eval = FALSE)
+```
+
+In 2004, the state of North Carolina released a large data set containing information on births recorded in this state.
+This data set is useful to researchers studying the relation between habits and practices of expectant mothers and the birth of their children.
+We will work with a random sample of observations from this data set.
+
+# Learning goals
+
+-   Constructing confidence intervals
+-   Conducting hypothesis tests
+-   Interpreting confidence intervals and results of hypothesis tests in context of the data
+
+# Getting started
+
+Go to the course GitHub organization and locate your homework repo, clone it in RStudio and open the R Markdown document.
+Knit the document to make sure it compiles without errors.
+
+## Warm up
+
+Let's warm up with some simple exercises.
+Update the YAML of your R Markdown file with your information, knit, commit, and push your changes.
+Make sure to commit with a meaningful commit message.
+Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd **and** md files.
+If anything is missing, commit and push again.
+
+## Packages
+
+We'll use the **tidyverse** package for much of the data wrangling and visualisation, the **tidymodels** package for inference, and the data lives in the **dsbox** package.
+These packages are already installed for you.
+You can load them by running the following in your Console:
+
+```{r}
+library(tidyverse) 
+library(tidymodels)
+library(openintro)
+```
+
+## Data
+
+The data can be found in the **dsbox** package, and it's called `ncbirths`.
+Since the dataset is distributed with the package, we don't need to load it separately; it becomes available to us when we load the package.
+You can find out more about the dataset by inspecting its documentation, which you can access by running `?ncbirths` in the Console or using the Help menu in RStudio to search for `ncbirths`.
+You can also find this information [here](https://rstudio-education.github.io/dsbox/reference/ncbirths.html).
+
+# Set a seed!
+
+In this lab we'll be generating random samples.
+The last thing you want is those samples to change every time you knit your document.
+So, you should set a seed.
+There's an R chunk in your R Markdown file set aside for this.
+Locate it and add a seed.
+Make sure all members in a team are using the same seed so that you don't get merge conflicts and your results match up for the narratives.
+
+# Exercises
+
+1.  What are the cases in this data set? How many cases are there in our sample?
+
+The first step in the analysis of a new dataset is getting acquainted with the data.
+Make summaries of the variables in your dataset, determine which variables are categorical and which are numerical.
+For numerical variables, are there outliers?
+If you aren't sure or want to take a closer look at the data, make a graph.
+
+## Baby weights
+
+A 1995 study suggests that average weight of Caucasian babies born in the US is 3,369 grams (7.43 pounds).[^lab-12-inference-smoking-1]
+In this dataset we only have information on mother's race, so we will make the simplifying assumption that babies of Caucasian mothers are also Caucasian, i.e. `whitemom = ""white""`.
+
+We want to evaluate whether the average weight of Caucasian babies has changed since 1995.
+
+Our null hypothesis should state ""there is nothing going on"", i.e. no change since 1995: $H_0: \mu = 7.43~pounds$.
+
+Our alternative hypothesis should reflect the research question, i.e. some change since 1995.
+Since the research question doesn't state a direction for the change, we use a two sided alternative hypothesis: $H_A: \mu \ne 7.43~pounds$.
+
+3.  Create a filtered data frame called `ncbirths_white` that contain data only from white mothers.
+    Then, calculate the mean of the weights of their babies.
+
+4.  Are the conditions necessary for conducting simulation based inference satisfied?
+    Explain your reasoning.
+
+Let's discuss how this test would work.
+Our goal is to simulate a null distribution of sample means that is centred at the null value of 7.43 pounds.
+In order to do so, we
+
+-   take a bootstrap sample of from the original sample,
+-   calculate this bootstrap sample's mean,
+-   repeat these two steps a large number of times to create a bootstrap distribution of means centred at the observed sample mean,
+-   shift this distribution to be centred at the null value by subtracting / adding X to all bootstrap mean (X = difference between mean of bootstrap distribution and null value), and
+-   calculate the p-value as the proportion of bootstrap samples that yielded a sample mean at least as extreme as the observed sample mean.
+
+5.  Run the appropriate hypothesis test, visualize the null distribution, calculate the p-value, and interpret the results in context of the data and the hypothesis test.
+
+## Baby weight vs. smoking
+
+Consider the possible relationship between a mother's smoking habit and the weight of her baby.
+Plotting the data is a useful first step because it helps us quickly visualize trends, identify strong associations, and develop research questions.
+
+6.  Make side-by-side boxplots displaying the relationship between `habit` and `weight`.
+    What does the plot highlight about the relationship between these two variables?
+
+7.  Before moving forward, save a version of the dataset omitting observations where there are NAs for `habit`.
+    You can call this version `ncbirths_habitgiven`.
+
+The box plots show how the medians of the two distributions compare, but we can also compare the means of the distributions using the following to first group the data by the `habit` variable, and then calculate the mean `weight` in these groups using.
+
+```{r habit-means, eval=FALSE}
+ncbirths_habitgiven %>%
+  group_by(habit) %>%
+  summarise(mean_weight = mean(weight))
+```
+
+There is an observed difference, but is this difference statistically significant?
+In order to answer this question we will conduct a hypothesis test .
+
+7.  Write the hypotheses for testing if the average weights of babies born to smoking and non-smoking mothers are different.
+
+8.  Are the conditions necessary for conducting simulation based inference satisfied?
+    Explain your reasoning.
+
+9.  Run the appropriate hypothesis test, calculate the p-value, and interpret the results in context of the data and the hypothesis test.
+
+10. Construct a 95% confidence interval for the difference between the average weights of babies born to smoking and non-smoking mothers.
+
+## Baby weight vs. mother's age
+
+In this portion of the analysis we focus on two variables.
+The first one is `maturemom`.
+
+11. First, a non-inference task: Determine the age cutoff for younger and mature mothers. Use a method of your choice, and explain how your method works.
+
+The other variable of interest is `lowbirthweight`.
+
+12. Conduct a hypothesis test evaluating whether the proportion of low birth weight babies is higher for mature mothers. State the hypotheses, verify the conditions, run the test and calculate the p-value, and state your conclusion in context of the research question. Use $\alpha = 0.05$. If you find a significant difference, construct a confidence interval, at the equivalent level to the hypothesis test, for the difference between the proportions of low birth weight babies between mature and younger mothers, and interpret this interval in context of the data.
+
+[^lab-12-inference-smoking-1]: Wen, Shi Wu, Michael S. Kramer, and Robert H. Usher.
+    ""Comparison of birth weight distributions between Chinese and Caucasian infants."" American Journal of Epidemiology 141.12 (1995): 1177-1187.

---FILE: course-materials/lab-instructions/lab-12/lab-12-work-on-projects.Rmd---
@@ -1,40 +0,0 @@
----
-title: ""Lab 12 - Work on projects""
-output: 
-  tufte::tufte_html:
-    css: ../lab.css
-    tufte_variant: ""envisioned""
-    highlight: pygments
-    toc: yes
-link-citations: yes
----
-
-```{r setup, include=FALSE}
-knitr::opts_chunk$set(eval = TRUE)
-```
-
-This week you'll be working on your projects. Here are a few to do items to get 
-you started. Once you complete these, use the rest of the time to, well, 
-work on your project!
-
-- Remind yourself of the project assignment
-- Go to the course organization on GitHub and clone your project repo titled `project-TEAM_NAME`
-- Add your project title and team name to the `README.Rmd` file in the repo and commit and push your changes. Observe that these are updated in the README of the repo.
-- Open the `presentation.Rmd` file, knit the document, and review the presentation format. This is where your presentation will go. Update the YAML with your  project title, team name, etc. and commit and push your changes.
-- Go to your project repo on GitHub, click on **Settings** on the top right corner, and scroll down to the section titled **GiHub Pages**. Under **Source**, select `master branch`. This will give you a URL where the website for your project will be automatically built from the content in your README. This might take a few minutes. Click on the link to confirm that the website has been built.
-  - (Optional) Once the website it build, you can change its theme using the **Theme Chooser**.
-  - Also, once the website is built, you'll need to pull changes to your project in RStudio.
-  - Take a look at your rendered project website. Click on the link in the presentation section and you should be able to view the rendered slides. This is the link we will use to project your slides during the presentations.
-  - On your repo you should see a text on top *No description, website, or topics provided.*. Next to it there's an **Edit** button. Add a short description as well as the URL of your project website here.
-  - **Note:** This website is public, but your repository will remain private,unless... you as a team decide you would like to feature your repos in your personal GitHub profiles. If so, I will help you convert your repo to a public repo at the end of the semester. I will not add any marks to your repos so that your public work won't contain your score for the project. 
-- Add your dataset to the `data` folder and add your codebook to the README inthat folder.
-  - If in your proposal you were advised to update your codebook, make sure to make those updates.
-  - If you had R scripts you used to scrape your data, add them to this folder as well.
-- Add the content from your proposal to the `proposal.Rmd` file in the `proposal` folder. Knit the document to make sure everything works and commit and push your proposal to your project repo.
-  - **Important:** Your data now lives in a folder called `data` that is *not* inside your proposal folder. So you need to specify the path to your data with `""../data/name_of_datafile""` in your `read_csv()` (or similar) function.
-  - You don't need to make further updates to your proposal at this point, even if your plans for the project change slightly.
-- Load your data in your `presentation.Rmd`, knit, and make sure everything works. Commit and push your updated proposal to your project repo.
-  - **Important:** Same note as above! Your data now lives in a folder called `data` that is *not* inside your presentation folder. So you need to specify the path to your data with `""../data/name_of_datafile""` in your `read_csv()` (or similar) function.
-- Now that all the logistical details are done, start working on your project.
-  - Open issues for things you want to accomplish. Assign them to specific team member(s) if you like. And as you complete the tasks, close the issues. You can also use the issues for discussion on the specific tasks.
-- **Strongly recommended:** Get a hold of a tutor and run your ideas by them.

---FILE: course-materials/lab-instructions/lab-13/lab-13-collaborating-on-github.Rmd---
@@ -1,192 +0,0 @@
----
-title: ""Lab 13 - Collaborating on GitHub""
-output: 
-  tufte::tufte_html:
-    css: ../lab.css
-    tufte_variant: ""envisioned""
-    highlight: pygments
-    toc: yes
-link-citations: yes
----
-
-```{r setup, include=FALSE}
-knitr::opts_chunk$set(eval = TRUE)
-```
-
-This week you'll continue working on your projects. The first half of the workshop is structured, and you can use the second half to make progress on your projects.
-
-## GitHub issues
-
-Issues are a great way to keep track of tasks, enhancements, and bugs for your 
-projects. They‚Äôre kind of like email‚Äîexcept they can be shared and discussed 
-with the rest of your team. You can use issues as to-do lists as well as a place 
-for brainstorming / discussing ideas.
-
-### Opening an issue
-
-1. Go to your project repo and open a new issue titled ""Practice issue"". 
-2. Add the following text to the issue:
-
-```
-This is not a real issue. This is just some placeholder text.
-
-And the following is a bulleted to-do list:
-- [ ] Do this
-- [ ] Then that
-- [ ] And finally this
-```
-
-3. Hit preview to make sure the issue looks like the following:
-
-```{r echo=FALSE}
-knitr::include_graphics(""img/practice-issue-create.png"")
-```
-
-4. Submit the issue.
-5. Then, assign the issue to one or few members of the team.
-
-```{r echo=FALSE}
-knitr::include_graphics(""img/practice-issue-assign.png"")
-```
-
-### Working on the issue
-
-As you work on the issue you can check the boxes.
-
-```{r echo=FALSE}
-knitr::include_graphics(""img/practice-issue-check.png"")
-```
-
-Note that this will also show progress on the issue on the issue dashboard.
-
-```{r echo=FALSE}
-knitr::include_graphics(""img/practice-issue-progress.png"")
-```
-
-6. Check some of the boxes on your practice issue and confirm that you can 
-see the progress result on the issue dashboard.
-
-### Closing the issue
-
-Once you're done with an issue, you should close it. You can do this in one of 
-two ways: on GitHub by clicking on Close issue or via a commit that directly 
-addresses the issue. We'll practice the second one. If you preface your commits
-with ‚ÄúFixes‚Äù, ‚ÄúFixed‚Äù, ‚ÄúFix‚Äù, ‚ÄúCloses‚Äù, ‚ÄúClosed‚Äù, or ‚ÄúClose‚Äù, the issue will be 
-closed when you push the changes to your repo.
-
-7. Take a note of the issue number, which will show up next to the 
-issue title.
-
-```{r echo=FALSE}
-knitr::include_graphics(""img/practice-issue-number.png"")
-```
-
-8. Go to your project on RStudio and make a change. This can be something 
-silly like adding a new line to the issue README. Then commit this change. 
-In your commit message, use one of the special words listed above and 
-reference the issue. For example, if the change I made was to add a new line 
-to the README I would say something like the following:
-
-```
-Add a new line to the README, closes #2
-```
-
-```{r echo=FALSE}
-knitr::include_graphics(""img/practice-issue-commit.png"")
-```
-
-9. Push your changes and observe that the issue is now closed on GitHub. 
-Click on the referenced commit to confirm that it was your last commit that 
-closed the issue.
-
-```{r echo=FALSE}
-knitr::include_graphics(""img/practice-issue-commit.png"")
-```
-
-## Project progress
-
-Now back to your project...
-
-10. **Crafting your to-do list:** Discuss your plan for your project as a team, 
-and open **at least n issues**, where n is the number of students in your team. 
-Not every issue needs to have a checklist, but you might want to include 
-checklists in some of them to remind yourselves the exact steps you discussed 
-to tackle the issue. Then assign **at least one** issue to each team member. 
-
-11. **Customizing your website theme:** We attempted this last week, and failed 
-due to permission issues. Let's try it one more time! Browse the possible 
-GitHub themes' demo pages at the following links.
-
-  - [architect](https://pages-themes.github.io/architect)
-  - [cayman](https://pages-themes.github.io/cayman)
-  - [dinky](https://pages-themes.github.io/dinky)
-  - [hacker](https://pages-themes.github.io/hacker)
-  - [leap-day](https://pages-themes.github.io/leap-day)
-  - [merlot](https://pages-themes.github.io/merlot)
-  - [midnight](https://pages-themes.github.io/midnight)
-  - [minimal](https://pages-themes.github.io/minimal)
-  - [modernist](https://pages-themes.github.io/modernist)
-  - [slate](https://pages-themes.github.io/slate)
-  - [tactile](https://pages-themes.github.io/tactile)
-  - [time machine](https://pages-themes.github.io/time machine)
-
-Once you decide which theme you prefer (and it's perfectly fine if it's the 
-default theme you had to begin with), go to the `_config.yml` file in your repo 
-on RStudio and edit the theme name in the `_config.yml` file. For example, if 
-you were going from `cayman` to `hacker`, your diff would look like the 
-following. Once you commit and push this change, give it a couple minutes 
-for the website to rebuild, and confirm that the theme was changed.
-
-```{r echo=FALSE}
-knitr::include_graphics(""img/practice-issue-commit.png"")
-```
-
-```{marginfigure}
-**Note:** This is an extremely important step as this is the link I will use 
-on the day of your presentation. There will not be time to make push 
-updates once your presentation session starts.
-```
-
-12. **Updating your project description:** If you have not yet done so, 
-add a brief description, link to your project website, and topics to your 
-project repo.
-
-```{r echo=FALSE}
-knitr::include_graphics(""img/project-description.png"")
-```
-
-13. **Citing your data:** Now is the time to fix up those citations! In your 
-project README there is a link to a resource for properly citing data. Develop 
-a citation for your dataset and add it under the data section using this guidance. If you have questions, ask a tutor for help!
-
-14. **Confirming presentation format:** Go to the website for your repo and 
-click on the link that should take you to your presentation. Confirm that your 
-latest changes to the presentation are reflected at this link (which means you 
-must have pushed the resulting HTML file along with the Rmd file where you 
-wrote your presentation).
-
-15. **Confirming schedules:** Go to the schedule for presentations and 
-confirm that all team members can make it at the beginning of the hour you're 
-assigned to present in. Also note that we will not be meeting in the computer 
-lab. 
-  - Some of you who have an ILA workshop before this class have been assigned 
-  to the first hour due to the sheer number of such students with conflicts. 
-  I have checked in with the ILA course organizer and have been told that next 
-  week's workshop is revision, and the presentations in IDS should take priority. 
-  So please make sure to leave your workshop by 11:30 at the latest to get to 
-  King's Buildings in time for the presentations.
-  - Order within each hour will be announced on the day of the presentations, so 
-  you should all be ready to go at the beginning of the hour.
-  
-16. **Tidying up your coding style:** Go to the pull requests tab and take a 
-look at the code styling suggestions. Implement them in the relevant files. 
-Styling suggestions are generated daily at 13:30, so if you do more work today, 
-there may be more suggestions tomorrow. Make sure to check these before you 
-finalize work on your repo.
-
-```{r echo=FALSE}
-knitr::include_graphics(""img/styler-1.png"")
-knitr::include_graphics(""img/styler-2.png"")
-```
-
-17. **Strongly recommended:** Get a hold of a tutor and run your ideas by them.

---FILE: course-materials/lab-instructions/lab-13/lab-13-work-on-projects.Rmd---
@@ -0,0 +1,57 @@
+---
+title: ""Lab 13 - Work on projects""
+output: 
+  tufte::tufte_html:
+    css: ../lab.css
+    tufte_variant: ""envisioned""
+    highlight: pygments
+    toc: yes
+link-citations: yes
+---
+
+This week you'll be working on your projects.
+Here are a few to do items to get you started.
+Once you complete these, use the rest of the time to, well, work on your project!
+
+-   Remind yourself of the project assignment
+
+-   Go to the course organization on GitHub and clone your project repo titled `project-TEAM_NAME`
+
+-   Add your project title and team name to the `README.Rmd` file in the repo and commit and push your changes.
+    Observe that these are updated in the README of the repo.
+
+-   Open the `presentation.Rmd` file, knit the document, and review the presentation format.
+    This is where your presentation will go.
+    Update the YAML with your project title, team name, etc. and commit and push your changes.
+
+-   Go to your project repo on GitHub, click on **Settings** on the top right corner, and scroll down to the section titled **GiHub Pages**.
+    Under **Source**, select `main` branch and the `root` folder.
+    This will give you a URL where the website for your project will be automatically built from the content in your README.
+    This might take a few minutes.
+
+    -   Once the website is built, pull changes to your project in RStudio.
+    -   Take a look at your rendered project website. Click on the link in the presentation section and you should be able to view the rendered slides. This is the link we will use to project your slides during the presentations.
+    -   On your repo you should see a text on top *No description, website, or topics provided.*. Next to it there's an **Edit** button. Add a short description as well as the URL of your project website here.
+    -   **Note:** This website is public, but your repository will remain private,unless... you as a team decide you would like to feature your repos in your personal GitHub profiles. If so, I will help you convert your repo to a public repo at the end of the semester. I will not add any marks to your repos so that your public work won't contain your score for the project.
+
+-   Add your dataset to the `data` folder and add your codebook to the README in that folder.
+
+    -   If in your proposal you were advised to update your codebook, make sure to make those updates.
+    -   If you had R scripts you used to scrape your data, add them to this folder as well.
+
+-   Add the content from your proposal to the `proposal.Rmd` file in the `proposal` folder.
+    Knit the document to make sure everything works and commit and push your proposal to your project repo.
+
+    -   **Important:** Your data now lives in a folder called `data` that is *not* inside your proposal folder. So you need to specify the path to your data with `""../data/name_of_datafile""` in your `read_csv()` (or similar) function.
+    -   You don't need to make further updates to your proposal at this point, even if your plans for the project change slightly.
+
+-   Load your data in your `presentation.Rmd`, knit, and make sure everything works.
+    Commit and push your updated proposal to your project repo.
+
+    -   **Important:** Same note as above! Your data now lives in a folder called `data` that is *not* inside your presentation folder. So you need to specify the path to your data with `""../data/name_of_datafile""` in your `read_csv()` (or similar) function.
+
+-   Now that all the logistical details are done, start working on your project.
+
+    -   Open issues for things you want to accomplish. Assign them to specific team member(s) if you like. And as you complete the tasks, close the issues. You can also use the issues for discussion on the specific tasks.
+
+-   **Strongly recommended:** Get a hold of the instructor or a TA and run your ideas by them.

---FILE: course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.Rmd---
@@ -0,0 +1,132 @@
+---
+title: ""Lab 14 - Collaborating on GitHub""
+output: 
+  tufte::tufte_html:
+    css: ../lab.css
+    tufte_variant: ""envisioned""
+    highlight: pygments
+    toc: yes
+link-citations: yes
+---
+
+```{r setup, include=FALSE}
+knitr::opts_chunk$set(echo = FALSE)
+```
+
+This week you'll continue working on your projects.
+The first half of the workshop is structured, and you can use the second half to make progress on your projects.
+
+# GitHub issues
+
+Issues are a great way to keep track of tasks, enhancements, and bugs for your projects.
+They're kind of like email---except they can be shared and discussed with the rest of your team.
+You can use issues as to-do lists as well as a place for brainstorming / discussing ideas.
+
+## Opening an issue
+
+1.  Go to your project repo and open a new issue titled ""Practice issue"".
+2.  Add the following text to the issue:
+
+<!-- -->
+
+    This is not a real issue. This is just some placeholder text.
+
+    And the following is a bulleted to-do list:
+    - [ ] Do this
+    - [ ] Then that
+    - [ ] And finally this
+
+3.  Hit preview to make sure the issue looks like the following:
+
+```{r}
+knitr::include_graphics(""img/practice-issue-create.png"")
+```
+
+4.  Submit the issue.
+5.  Then, assign the issue to one or few members of the team.
+
+```{r}
+knitr::include_graphics(""img/practice-issue-assign.png"")
+```
+
+## Working on the issue
+
+As you work on the issue you can check the boxes.
+
+```{r}
+knitr::include_graphics(""img/practice-issue-check.png"")
+```
+
+Note that this will also show progress on the issue on the issue dashboard.
+
+```{r}
+knitr::include_graphics(""img/practice-issue-progress.png"")
+```
+
+6.  Check some of the boxes on your practice issue and confirm that you can see the progress result on the issue dashboard.
+
+## Closing the issue
+
+Once you're done with an issue, you should close it.
+You can do this in one of two ways: on GitHub by clicking on Close issue or via a commit that directly addresses the issue.
+We'll practice the second one.
+If you preface your commits with ""Fixes"", ""Fixed"", ""Fix"", ""Closes"", ""Closed"", or ""Close"", the issue will be closed when you push the changes to your repo.
+
+7.  Take a note of the issue number, which will show up next to the issue title.
+
+```{r}
+knitr::include_graphics(""img/practice-issue-number.png"")
+```
+
+8.  Go to your project on RStudio and make a change. This can be something silly like adding a new line to the issue README. Then commit this change. In your commit message, use one of the special words listed above and reference the issue. For example, if the change I made was to add a new line to the README I would say something like the following:
+
+<!-- -->
+
+    Add a new line to the README, closes #2
+
+```{r}
+knitr::include_graphics(""img/practice-issue-commit.png"")
+```
+
+9.  Push your changes and observe that the issue is now closed on GitHub. Click on the referenced commit to confirm that it was your last commit that closed the issue.
+
+```{r}
+knitr::include_graphics(""img/practice-issue-commit.png"")
+```
+
+# Project progress
+
+Now back to your project...
+
+10. **Crafting your to-do list:** Discuss your plan for your project as a team, and open **at least n issues**, where n is the number of students in your team.
+    Not every issue needs to have a checklist, but you might want to include checklists in some of them to remind yourselves the exact steps you discussed to tackle the issue.
+    Then assign **at least one** issue to each team member.
+
+11. **Customizing your website theme:** (Optional) Edit the `_config.yml` document to change the theme of your project website.
+    Your options are [architect](https://pages-themes.github.io/architect), [cayman](https://pages-themes.github.io/cayman), [dinky](https://pages-themes.github.io/dinky), [hacker](https://pages-themes.github.io/hacker), [leap-day](https://pages-themes.github.io/leap-day), [merlot](https://pages-themes.github.io/merlot), [midnight](https://pages-themes.github.io/midnight), [minima](https://pages-themes.github.io/minima), [minimal](https://pages-themes.github.io/minimal), [modernist](https://pages-themes.github.io/modernist), [slate](https://pages-themes.github.io/slate), [tactile](https://pages-themes.github.io/tactile), and [time-machine](https://pages-themes.github.io/time-machine).
+    Suppose you want the `architect` theme, you'd add `theme: architect` to the `_config.yml` document, save, commit, and push.
+
+```{r}
+knitr::include_graphics(""img/project-description.png"")
+```
+
+12. **Updating your project description:** If you have not yet done so, add a brief description, link to your project website, and topics to your project repo.
+
+13. **Citing your data:** Now is the time to fix up those citations!
+    In your project README there is a link to a resource for properly citing data.
+    Develop a citation for your dataset and add it under the data section using this guidance.
+    If you have questions, ask a tutor for help!
+
+14. **Confirming presentation format:** Go to the website for your repo and click on the link that should take you to your presentation.
+    Confirm that your latest changes to the presentation are reflected at this link (which means you must have pushed the resulting HTML file along with the Rmd file where you wrote your presentation).
+
+15. **Tidying up your coding style:** Go to the pull requests tab and take a look at the code styling suggestions.
+    Implement them in the relevant files.
+    Make sure to check these before you finalize work on your repo.
+
+```{r}
+knitr::include_graphics(""img/styler-1.png"")
+knitr::include_graphics(""img/styler-2.png"")
+```
+
+16. **Strongly recommended:** Get a hold of a tutor and run your ideas by them.

---FILE: course-materials/lab-instructions/lab.css---
@@ -5,42 +5,52 @@
 
 @charset ""UTF-8"";
 
-/* Tufte CSS styles */
-
-html {
-	font-size: 14px;
+/* colors */
+:root {
+  --dark-blue: #002b36;
+  --light-blue: #A7D5E8;
+  --green: #8fada7;
+  --gray: #A7A7A7;
+  --pink: #E9AFA3;
+  --yellow: #e9d968;
+  --beige: #fdf6e3;
+  --green-faint: #8fada750;
+  --light-blue-faint: #A7D5E850;
+  --pink-faint: #E9AFA350;
 }
 
+/* Tufte CSS styles */
+
 body {
 	font-family: 'Source Sans Pro', sans-serif;
 	font-weight: 300;
-	background-color: #fefefe;
+	background-color: #ffffff;
 	color: #222;
 	counter-reset: li;
 }
 
 h1.title {
 	font-weight: 700;
 	font-family: 'Source Sans Pro', sans-serif;
-	color: #6CA0DC;
+	color: var(--green);
 }
 
 h1 {
 	font-style: normal;
 	font-family: 'Source Sans Pro', sans-serif;
-	color: #6CA0DC;
+	color: var(--green);
 }
 
 h2 {
 	font-style: normal;
 	font-family: 'Source Sans Pro', sans-serif;
 	font-weight: 400;
-	color: #6CA0DC;
+	color: var(--green);
 }
 
 h3.subtitle {
 	font-style: normal;
-	color: #6CA0DC;
+	color: var(--green);
 }
 
 h4 {
@@ -75,30 +85,39 @@ strong {
 	font-family: ""Source Sans Pro"";
 }
 
+.marginnote code,
+.sidenote code {
+	font-size: 1rem;
+}
+
 /* Code formatting */
 
 @media screen and (max-width: 760px) {
 	pre {
 		width: 100%;
 		font-size: 16px;
+     	overflow-x: auto;
 	}
 }
 
 code {
 	font-family: 'Source Code Pro', Consolas, ""Liberation Mono"", Menlo, Courier, monospace;
-	font-size: 15px;
 	line-height: 1.6;
 }
 
-.marginnote code,
-.sidenote code {
-	font-size: 1rem;
-}
-
 pre {
-	width: 100%;
-	font-size: 16px;
+	background-color: #FFFFFF;
+	border-color: #CCCCCC;
+	border-style: solid;
+	border-width: 1px;
+    border-radius: 4px;
 	overflow-x: auto;
+ 	padding: 1em;
+}
+
+pre.r {
+	background-color: #F5F5F5;
+	border-color: #CCCCCC
 }
 
 /* Exercise counter */
@@ -117,7 +136,7 @@ ol>li {
 	padding-top: 10px;
 	padding-bottom: 10px;
 	padding-right: 0;
-	padding-left: 90px;
+	padding-left: 120px;
 }
 
 ol>li:before {
@@ -126,11 +145,29 @@ ol>li:before {
 	/* Increment the counter by 1 */
 	counter-increment: li;
 	position: absolute;
-	color: #6CA0DC;
+	color: var(--green);
 	left: -0.5px;
 	font-weight: bold;
 }
 
 ol ol {
 	counter-reset: subitem;
 }
+
+ul ul {
+  width: 100%;
+}
+
+.box {
+	background-color: #a3c586;
+	border-color: #CCCCCC;
+	color: #FFFFFF;
+	border-style: solid;
+	border-width: 1px;
+    border-radius: 4px;
+	overflow-x: auto;
+	margin-top: 1em;
+	margin-bottom: 1em;
+	width: 55%;
+	text-align: center;
+}

---FILE: course-materials/project-instructions/project.Rmd---
@@ -0,0 +1,255 @@
+---
+title: ""Showcase your inner data scientist""
+output: 
+  html_document: 
+    css: project.css
+    theme: yeti
+    toc: true
+    toc_float: true
+    fig_caption: true
+---
+
+::: {style=""float:right;position: relative; margin-left: 20px""}
+```{r setup, echo=FALSE, fig.align=""right""}
+knitr::include_graphics(""img/laptop-3190194_1920.jpg"")
+```
+:::
+
+# TL;DR
+
+Pick a dataset, any dataset...
+
+...and do something with it.
+That is your final project in a nutshell.
+More details below.
+
+# May be too long, but please do read
+
+The final project for this class will consist of analysis on a dataset of your own choosing.
+The dataset may already exist, or you may collect your own data using a survey or by conducting an experiment.
+You can choose the data based on your interests or based on work in other courses or research projects.
+The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like) and apply them to a novel dataset in a meaningful way.
+
+The goal is not to do an exhaustive data analysis i.e., do not calculate every statistic and procedure you have learned for every variable, but rather let me know that you are proficient at asking meaningful questions and answering them with results of data analysis, that you are proficient in using R, and that you are proficient at interpreting and presenting the results.
+Focus on methods that help you begin to answer your research questions.
+You do not have to apply every statistical procedure we learned (and you can use techniques we haven't officially covered in class, if you're feeling adventurous).
+Also, critique your own methods and provide suggestions for improving your analysis.
+Issues pertaining to the reliability and validity of your data, and appropriateness of the statistical analysis should be discussed here.
+
+The project is very open ended.
+You should create some kind of compelling visualization(s) of this data in R.
+There is no limit on what tools or packages you may use, but sticking to packages we learned in class (`tidyverse`) is required.
+You do not need to visualize all of the data at once.
+A single high quality visualization will receive a much higher grade than a large number of poor quality visualizations.
+Also pay attention to your presentation.
+Neatness, coherency, and clarity will count.
+All analyses must be done in RStudio, using R.
+
+## Data
+
+In order for you to have the greatest chance of success with this project it is important that you choose a manageable dataset.
+This means that the data should be readily accessible and large enough that multiple relationships can be explored.
+As such, your dataset must have at least 50 observations and between 10 to 20 variables (exceptions can be made but you must speak with me first).
+The dataset's variables should include categorical variables, discrete numerical variables, and continuous numerical variables.
+
+If you are using a dataset that comes in a format that we haven't encountered in class, make sure that you are able to load it into R as this can be tricky depending on the source.
+If you are having trouble ask for help before it is too late.
+
+**Note on reusing datasets from class:** Do not reuse datasets used in examples, homework assignments, or labs in the class.
+
+Below are a list of data repositories that might be of interest to browse.
+You're not limited to these resources, and in fact you're encouraged to venture beyond them.
+But you might find something interesting there:
+
+-   [TidyTuesday](https://github.com/rfordatascience/tidytuesday)
+-   [NHS Scotland Open Data](https://www.opendata.nhs.scot/)
+-   [Edinburgh Open Data](https://edinburghopendata.info/)
+-   [Open access to Scotland's official statistics](https://statistics.gov.scot/home)
+-   [Bikeshare data portal](https://www.bikeshare.com/data/)
+-   [UK Gov Data](https://data.gov.uk/)
+-   [Kaggle datasets](https://www.kaggle.com/datasets)
+-   [OpenIntro datasets](http://openintrostat.github.io/openintro/)
+-   [Awesome public datasets](https://github.com/awesomedata/awesome-public-datasets)
+-   [Youth Risk Behavior Surveillance System (YRBSS)](https://chronicdata.cdc.gov/Youth-Risk-Behaviors/DASH-Youth-Risk-Behavior-Surveillance-System-YRBSS/q6p7-56au)
+-   [PRISM Data Archive Project](https://www.icpsr.umich.edu/icpsrweb/content/ICPSR/fenway.html)
+-   [Harvard Dataverse](https://dataverse.harvard.edu/)
+-   If you know of others, let me know, and we'll add here...
+
+## Deliverables
+
+1.  Proposal - due [ENTER DUE DATE]
+2.  Presentation - due [ENTER DUE DATE]
+3.  Executive summary - due [ENTER DUE DATE]
+
+### Proposal
+
+This is a draft of the introduction section of your project as well as a data analysis plan and your dataset.
+
+-   **Section 1 - Introduction:** The introduction should introduce your general
+
+    research question and your data (where it came from, how it was collected,
+
+    what are the cases, what are the variables, etc.).
+
+-   **Section 2 - Data:** Place your data in the \`/data\` folder, and add dimensions and codebook to the README in that folder.
+    Then print out the output of and codebook to the README in that folder.
+    Then print out the output of `glimpse()` or `skim()` of your data frame.
+
+-   **Section 3 - Data analysis plan:**
+
+    -   The outcome (response, Y) and predictor (explanatory, X) variables you will use to answer your question.
+
+    -   The comparison groups you will use, if applicable.
+
+    -   Very preliminary exploratory data analysis, including some summary statistics and visualizations, along with some explanation on how they help you learn more about your data.
+        (You can add to these later as you work on your project.)
+
+    -   The method(s) that you believe will be useful in answering your question(s).
+        (You can update these later as you work on your project.)
+
+    -   What results from these specific statistical methods are needed to support your hypothesized answer?
+
+Each section should be no more than 1 page (excluding figures).
+You can check a print preview to confirm length.
+
+The grading scheme for the project proposal is as follows.
+Note that after you receive feedback for your proposal you can improve it based on the feedback and re-submit it.
+If you re-submit, your final score for the proposal will be the average of two scores you receive (first and second submission).
+
++-----------------------------------------------------------+----------+
+| Total                                                     | 10 pts   |
++===========================================================+==========+
+| Data                                                      | 3 pts    |
++-----------------------------------------------------------+----------+
+| Proposal                                                  | 5 pts    |
++-----------------------------------------------------------+----------+
+| Workflow, organization, code quality                      | 1 pt     |
++-----------------------------------------------------------+----------+
+| Teamwork                                                  | 1 pt     |
++-----------------------------------------------------------+----------+
+
+### Presentation
+
+5 minutes maximum, and each team member should say something substantial.
+You can either present live during your workshop or pre-record and submit your video to be played during the workshop.
+
+Prepare a slide deck using the template in your repo.
+This template uses a package called `xaringan`, and allows you to make presentation slides using R Markdown syntax.
+There isn't a limit to how many slides you can use, just a time limit (5 minutes total).
+Each team member should get a chance to speak during the presentation.
+Your presentation should not just be an account of everything you tried (""then we did this, then we did this, etc.""), instead it should convey what choices you made, and why, and what you found.
+
+Before you finalize your presentation, make sure your chunks are turned off with `echo = FALSE`.
+
+Presentations will take place during the last workshop of the semester.
+You can choose to do your presentation live or pre-record it.
+During your workshop you will watch presentations from other teams in your workshop and provide feedback in the form of peer evaluations.
+The presentation line-up will be generated randomly.
+
+The grading scheme for the presentation is as follows:
+
++----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
+| Total                                                                                                                                                                                                          | 50 pts |
++================================================================================================================================================================================================================+========+
+| Time management: Did the team divide the time well amongst themselves or got cut off going over time?                                                                                                          | 4 pts  |
++----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
+| Content: Is the research question well designed and is the data being used relevant to the research question?                                                                                                  | 5 pts  |
++----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
+| Professionalism: How well did the team present? Does the presentation appear to be well practiced? Did everyone get a chance to say something meaningful about the project?                                    | 5 pts  |
++----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
+| Teamwork: Did the team present a unified story, or did it seem like independent pieces of work patched together?                                                                                               | 6 pts  |
++----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
+| Content: Did the team use appropriate statistical procedures and interpretations of results accurately?                                                                                                        | 10 pts |
++----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
+| Creativity and Critical Thought: Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project? | 10 pts |
++----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
+| Slides: Are the slides well organized, readable, not full of text, featuring figures with legible labels, legends, etc.?                                                                                       | 10 pts |
++----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+
+
+### Executive summary
+
+Along with your presentation slides, we want you to provide a brief summary of your project in the README of your repository.
+
+This executive summary should provide information on the dataset you're using, your research question(s), your methodology, and your findings.
+
+The executive summary is worth 15 points and will be evaluated based on whether it follows guidance and whether it's concise but detailed enough.
+
+### Repo organization
+
+The following folders and files in your project repository:
+
+-   `presentation.Rmd` + `presentation.html`: Your presentation slides
+-   `README.Rmd` + `README.md`: Your write-up
+-   `/data`: Your dataset in CSV or RDS format and your data dictionary
+-   `/proposal`: Your project proposal
+
+Style and format does count for this assignment, so please take the time to make sure everything looks good and your data and code are properly formatted.
+
+## Tips
+
+-   You're working in the same repo as your teammates now, so merge conflicts will happen, issues will arise, and that's fine Commit and push often, and ask questions when stuck.
+
+-   Review the marking guidelines below and ask questions if any of the expectations are unclear.
+
+-   Make sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).
+
+-   Set aside time to work together and apart (physically).
+
+-   When you're done, review the documents on GitHub to make sure you're happy with the final state of your work.
+    Then go get some rest!
+
+-   Code: In your presentation your code should be hidden (`echo = FALSE`) so that your document is neat and easy to read.
+    However your document should include all your code such that if I re-knit your R Markdown file I should be able to obtain the results you presented.
+
+    -   Exception: If you want to highlight something specific about a piece of code, you're welcomed to show that portion.
+
+-   Teamwork: You are to complete the assignment as a team.
+    All team members are expected to contribute equally to the completion of this assignment and team evaluations will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized.
+    While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works.
+
+## Marking
+
++----------------------------------------------------------+-----------+
+| Total                                                    | 100 pts   |
++==========================================================+===========+
+| Proposal                                                 | 10 pts    |
++----------------------------------------------------------+-----------+
+| Presentation                                             | 50 pts    |
++----------------------------------------------------------+-----------+
+| Executive summary                                        | 15 pts    |
++----------------------------------------------------------+-----------+
+| Reproducibility and organization                         | 10 pts    |
++----------------------------------------------------------+-----------+
+| Team peer evaluation                                     | 10 pts    |
++----------------------------------------------------------+-----------+
+| Classmates' evaluation                                   | 5 pts     |
++----------------------------------------------------------+-----------+
+
+### Criteria
+
+Your project will be assessed on the following criteria:
+
+-   Content - What is the quality of research and/or policy question and relevancy of data to those questions?
+-   Correctness - Are statistical procedures carried out and explained correctly?
+-   Writing and Presentation - What is the quality of the statistical presentation, writing, and explanations?
+-   Creativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?
+
+A general breakdown of scoring is as follows:
+
+-   90%-100% - Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.
+-   80%-89% - Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.
+-   70%-79% - Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.
+-   60%-69% - Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.
+-   Below 60% - Student is not making a sufficient effort.
+
+### Team peer evaluation
+
+You will be asked to fill out a survey where you rate the contribution and teamwork of each team member out of 10 points.
+You will additionally report a contribution percentage for each team member.
+Filling out the survey is a prerequisite for getting credit on the team member evaluation.If you are suggesting that an individual did less than 20% of the work, please provide some explanation.
+If any individual gets an average peer score indicating that they did less than 10% of the work, this person will receive half the grade of the rest of the group.
+
+### Late work policy
+
+-   There is no late submission / make up for the presentation. You must be in class on the day of the presentation to get credit for it *or* pre-record and submit your presentation by 9am in the morning of the presentations.
+-   The late work policy for the write-up is 5% of the maximum obtainable mark per calendar day up to seven calendar days after the deadline. If you intend to submit work late for the project, you must notify the course organizer before the original deadline as well as as soon as the completed work is submitted on GitHub.

---FILE: course-materials/project-instructions/repo-structure/README.Rmd---
@@ -0,0 +1,39 @@
+---
+title: Project title
+author: by Team name
+output: github_document
+---
+
+## Summary
+
+Write-up of your project and findings go here. 
+Think of this as the text of your presentation. 
+The length should be roughly 5 minutes when read out loud.
+Although pacing varies, a 5-minute speech is roughly 750 words. 
+To use the word count addin, select the text you want to count the words of (probably this is the 
+Summary section of this document, go to Addins, and select the `Word count` addin).
+This addin counts words using two different algorithms, but the results should be similar and as long as you're in the ballpark of 750 words, you're good! 
+The addin will ignore code chunks and only count the words in prose.
+
+You can also load your data here and present any analysis results / plots, but I strongly urge you to keep that to a minimum (maybe only the most important graphic, if you have one you can choose). 
+And make sure to hide your code with  `echo = FALSE` unless the point you are trying to make is about the code itself.
+Your results with proper output and graphics go in your presentation, this space is for a brief summary of your project.
+
+```{r load-data, echo = FALSE}
+# load data here, if you like
+```
+
+## Presentation
+
+Our presentation can be found [here](presentation/presentation.html).
+
+## Data 
+
+Include a citation for your data here. 
+See http://libraryguides.vu.edu.au/c.php?g=386501&p=4347840 for guidance on proper citation for datasets. 
+If you got your data off the web, make sure to note the retrieval date.
+
+## References
+
+List any references here. You should, at a minimum, list your data source.
+

---FILE: course-materials/project-instructions/repo-structure/README.md---
@@ -0,0 +1,39 @@
+Project title
+================
+by Team name
+
+## Summary
+
+Write-up of your project and findings go here. Think of this as the text
+of your presentation. The length should be roughly 5 minutes when read
+out loud. Although pacing varies, a 5-minute speech is roughly 750
+words. To use the word count addin, select the text you want to count
+the words of (probably this is the Summary section of this document, go
+to Addins, and select the `Word count` addin). This addin counts words
+using two different algorithms, but the results should be similar and as
+long as you‚Äôre in the ballpark of 750 words, you‚Äôre good! The addin will
+ignore code chunks and only count the words in prose.
+
+You can also load your data here and present any analysis results /
+plots, but I strongly urge you to keep that to a minimum (maybe only the
+most important graphic, if you have one you can choose). And make sure
+to hide your code with `echo = FALSE` unless the point you are trying to
+make is about the code itself. Your results with proper output and
+graphics go in your presentation, this space is for a brief summary of
+your project.
+
+## Presentation
+
+Our presentation can be found [here](presentation/presentation.html).
+
+## Data
+
+Include a citation for your data here. See
+<http://libraryguides.vu.edu.au/c.php?g=386501&p=4347840> for guidance
+on proper citation for datasets. If you got your data off the web, make
+sure to note the retrieval date.
+
+## References
+
+List any references here. You should, at a minimum, list your data
+source.

---FILE: course-materials/project-instructions/repo-structure/_config.yml---
@@ -0,0 +1 @@
+theme: jekyll-theme-hacker

---FILE: course-materials/project-instructions/repo-structure/data/README.md---
@@ -0,0 +1,13 @@
+# data
+
+Place data file(s) in this folder.
+
+Then, include codebooks (variables, and their descriptions) for your data file(s)
+using the following format.
+
+## name of data file
+
+- `variable1`: Description of variable 1
+- `variable2`: Description of variable 2
+- `variable3`: Description of variable 3
+- ...

---FILE: course-materials/project-instructions/repo-structure/extra/README.md---
@@ -0,0 +1,3 @@
+# extra
+
+Any extra documents you might have go here. This might include Rmd files you're using to develop your project, any notes, or anything else. The contents of this folder will **not** be marked, it's just a convenient place to store documents and collaborate with teammates without cluttering the rest of your repo.

---FILE: course-materials/project-instructions/repo-structure/presentation/libs/remark-css-0.0.1/default-fonts.css---
@@ -0,0 +1,10 @@
+@import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
+@import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
+@import url(https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700);
+
+body { font-family: 'Droid Serif', 'Palatino Linotype', 'Book Antiqua', Palatino, 'Microsoft YaHei', 'Songti SC', serif; }
+h1, h2, h3 {
+  font-family: 'Yanone Kaffeesatz';
+  font-weight: normal;
+}
+.remark-code, .remark-inline-code { font-family: 'Source Code Pro', 'Lucida Console', Monaco, monospace; }

---FILE: course-materials/project-instructions/repo-structure/presentation/libs/remark-css-0.0.1/default.css---
@@ -0,0 +1,72 @@
+a, a > code {
+  color: rgb(249, 38, 114);
+  text-decoration: none;
+}
+.footnote {
+  position: absolute;
+  bottom: 3em;
+  padding-right: 4em;
+  font-size: 90%;
+}
+.remark-code-line-highlighted     { background-color: #ffff88; }
+
+.inverse {
+  background-color: #272822;
+  color: #d6d6d6;
+  text-shadow: 0 0 20px #333;
+}
+.inverse h1, .inverse h2, .inverse h3 {
+  color: #f3f3f3;
+}
+/* Two-column layout */
+.left-column {
+  color: #777;
+  width: 20%;
+  height: 92%;
+  float: left;
+}
+.left-column h2:last-of-type, .left-column h3:last-child {
+  color: #000;
+}
+.right-column {
+  width: 75%;
+  float: right;
+  padding-top: 1em;
+}
+.pull-left {
+  float: left;
+  width: 47%;
+}
+.pull-right {
+  float: right;
+  width: 47%;
+}
+.pull-right + * {
+  clear: both;
+}
+img, video, iframe {
+  max-width: 100%;
+}
+blockquote {
+  border-left: solid 5px lightgray;
+  padding-left: 1em;
+}
+.remark-slide table {
+  margin: auto;
+  border-top: 1px solid #666;
+  border-bottom: 1px solid #666;
+}
+.remark-slide table thead th { border-bottom: 1px solid #ddd; }
+th, td { padding: 5px; }
+.remark-slide thead, .remark-slide tfoot, .remark-slide tr:nth-child(even) { background: #eee }
+
+@page { margin: 0; }
+@media print {
+  .remark-slide-scaler {
+    width: 100% !important;
+    height: 100% !important;
+    transform: scale(1) !important;
+    top: 0 !important;
+    left: 0 !important;
+  }
+}

---FILE: course-materials/project-instructions/repo-structure/presentation/presentation.Rmd---
@@ -0,0 +1,203 @@
+---
+title: ""Presentation title""
+subtitle: ""Presentation subtitle (if any)""
+author: ""Team name <br> Names of team members""
+institute: ""University of Edinburgh""
+date: ""`r Sys.Date()`""
+output:
+  xaringan::moon_reader:
+    css: xaringan-themer.css
+    lib_dir: libs
+    nature:
+      ratio: ""16:9""
+      highlightStyle: github
+      highlightLines: true
+      countIncrementalSlides: false
+---
+
+```{r load-packages, include = FALSE}
+# Add any additional packages you need to this chunk
+library(tidyverse)
+library(tidymodels)
+library(palmerpenguins)
+library(knitr)
+library(xaringanthemer)
+```
+
+```{r setup, include=FALSE}
+# For better figure resolution
+knitr::opts_chunk$set(fig.retina = 3, dpi = 300, fig.width = 6, fig.asp = 0.618, out.width = ""80%"")
+```
+
+```{r load-data, include=FALSE}
+# Load your data here
+```
+
+```{r}
+style_xaringan(
+  title_slide_background_image = ""img/confetti.jpg""
+)
+```
+
+
+class: center, middle
+
+## A statement of the overall goal / research question
+
+---
+
+class: inverse, center, middle
+
+# Section title
+
+---
+
+# Hello World
+
+- Click the `Knit` button to compile your presentation
+
+- Make sure to commit and push all resulting files to your GitHub repo
+
+---
+
+class: inverse, middle, center
+
+# Using xaringan
+
+---
+
+# xaringan
+
+- The presentation is created using the `xaringan` package
+
+- Use `---` to separate slides and `--` for incremental builds
+
+--
+
+- Like this
+
+---
+
+# Layouts
+
+You can use plain text
+
+- or bullet points
+
+.pull-left[
+or text in two columns $^*$
+]
+.pull-right[
+- like
+- this
+]
+
+.footnote[
+[*] And add footnotes
+]
+
+---
+
+# Code
+
+```{r boring-regression}
+# a boring regression
+model <- lm(dist ~ speed, data = cars)
+tidy(model)
+glance(model)
+```
+
+---
+
+# Plots
+
+```{r recode-species, echo = FALSE}
+# In this chunk I'm doing a bunch of analysis that I don't want to present 
+# in my slides. But I need the resulting data frame for a plot I want to present.
+iris_modified <- iris %>%
+  mutate(Species = fct_other(Species, keep = ""setosa""))
+```
+
+```{r plot-iris, echo = FALSE}
+# Code hidden with echo = FALSE
+# Uses modified iris dataset from previous chunk
+# Play around with height and width until you're happy with the look
+ggplot(data = iris_modified, mapping = aes(x = Sepal.Width, y = Sepal.Length, color = Species)) +
+  geom_point() + 
+  theme_minimal() # theme options: https://ggplot2.tidyverse.org/reference/ggtheme.html
+```
+
+---
+
+## Plot and text
+
+.pull-left[
+- Some text
+- goes here
+]
+.pull-right[
+```{r warning=FALSE, out.width=""100%"", fig.width=4, echo=FALSE}
+# see how I changed out.width and fig.width from defaults
+# to make the figure bigger
+ggplot(penguins, aes(x = bill_length_mm, y = species, color = species)) +
+  geom_boxplot() +
+  theme_minimal()
+```
+]
+
+---
+
+# Tables
+
+If you want to generate a table, make sure it is in the HTML format (instead of Markdown or other formats), e.g.,
+
+```{r iris-table, echo = FALSE}
+kable(head(iris), format = ""html"")
+```
+
+---
+
+# Images
+
+```{r castle, echo = FALSE, out.width = ""60%"", fig.align = ""center"", fig.cap = ""Image credit: Photo by J√∂rg Angeli on Unsplash.""}
+include_graphics(""https://images.unsplash.com/photo-1535448033526-c0e85c9e6968?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1650&q=80"")
+```
+
+Or you can also include a full page image. See next slide.
+
+---
+
+background-image: url(https://images.unsplash.com/photo-1535448033526-c0e85c9e6968?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1650&q=80)
+
+---
+
+# Math Expressions
+
+You can write LaTeX math expressions inside a pair of dollar signs, e.g. &#36;\alpha+\beta$ renders $\alpha+\beta$. You can use the display style with double dollar signs:
+
+```
+$$\bar{X}=\frac{1}{n}\sum_{i=1}^nX_i$$
+```
+
+$$\bar{X}=\frac{1}{n}\sum_{i=1}^nX_i$$
+
+Limitations:
+
+1. The source code of a LaTeX math expression must be in one line, unless it is inside a pair of double dollar signs, in which case the starting `$$` must appear in the very beginning of a line, followed immediately by a non-space character, and the ending `$$` must be at the end of a line, led by a non-space character;
+
+1. There should not be spaces after the opening `$` or before the closing `$`.
+
+1. Math does not work on the title slide (see [#61](https://github.com/yihui/xaringan/issues/61) for a workaround).
+
+---
+
+# Feeling adventurous?
+
+- Want to find out more about `xaringan`? See https://slides.yihui.name/xaringan/#1.
+
+- You are welcomed to use the default styling of the slides. In fact, that's what I expect majority of you will do. You will differentiate yourself with the content of your presentation.
+
+- But some of you might want to play around with slide styling. The 
+`xaringanthemer` provides some solutions for this that: https://pkg.garrickadenbuie.com/xaringanthemer.
+
+- And if you want more bells and whistles, there is also `xaringanExtra`: https://pkg.garrickadenbuie.com/xaringanExtra.

---FILE: course-materials/project-instructions/repo-structure/presentation/presentation.html---
@@ -0,0 +1,377 @@
+<!DOCTYPE html>
+<html lang="""" xml:lang="""">
+  <head>
+    <title>Presentation title</title>
+    <meta charset=""utf-8"" />
+    <meta name=""author"" content=""Team name   Names of team members"" />
+    <meta name=""date"" content=""2020-11-24"" />
+    <script src=""libs/header-attrs-2.5.3/header-attrs.js""></script>
+    <link rel=""stylesheet"" href=""xaringan-themer.css"" type=""text/css"" />
+  </head>
+  <body>
+    <textarea id=""source"">
+class: center, middle, inverse, title-slide
+
+# Presentation title
+## Presentation subtitle (if any)
+### Team name <br> Names of team members
+### University of Edinburgh
+### 2020-11-24
+
+---
+
+
+
+
+
+
+
+
+
+```r
+style_xaringan(
+  title_slide_background_image = ""img/confetti.jpg""
+)
+```
+
+
+class: center, middle
+
+## A statement of the overall goal / research question
+
+---
+
+class: inverse, center, middle
+
+# Section title
+
+---
+
+# Hello World
+
+- Click the `Knit` button to compile your presentation
+
+- Make sure to commit and push all resulting files to your GitHub repo
+
+---
+
+class: inverse, middle, center
+
+# Using xaringan
+
+---
+
+# xaringan
+
+- The presentation is created using the `xaringan` package
+
+- Use `---` to separate slides and `--` for incremental builds
+
+--
+
+- Like this
+
+---
+
+# Layouts
+
+You can use plain text
+
+- or bullet points
+
+.pull-left[
+or text in two columns `\(^*\)`
+]
+.pull-right[
+- like
+- this
+]
+
+.footnote[
+[*] And add footnotes
+]
+
+---
+
+# Code
+
+
+```r
+# a boring regression
+model &lt;- lm(dist ~ speed, data = cars)
+tidy(model)
+```
+
+```
+## # A tibble: 2 x 5
+##   term        estimate std.error statistic  p.value
+##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
+## 1 (Intercept)   -17.6      6.76      -2.60 1.23e- 2
+## 2 speed           3.93     0.416      9.46 1.49e-12
+```
+
+```r
+glance(model)
+```
+
+```
+## # A tibble: 1 x 12
+##   r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC
+##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
+## 1     0.651         0.644  15.4      89.6 1.49e-12     1  -207.  419.  425.
+## # ‚Ä¶ with 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;
+```
+
+---
+
+# Plots
+
+
+
+&lt;img src=""presentation_files/figure-html/plot-iris-1.png"" width=""80%"" /&gt;
+
+---
+
+## Plot and text
+
+.pull-left[
+- Some text
+- goes here
+]
+.pull-right[
+&lt;img src=""presentation_files/figure-html/unnamed-chunk-2-1.png"" width=""100%"" /&gt;
+]
+
+---
+
+# Tables
+
+If you want to generate a table, make sure it is in the HTML format (instead of Markdown or other formats), e.g.,
+
+&lt;table&gt;
+ &lt;thead&gt;
+  &lt;tr&gt;
+   &lt;th style=""text-align:right;""&gt; Sepal.Length &lt;/th&gt;
+   &lt;th style=""text-align:right;""&gt; Sepal.Width &lt;/th&gt;
+   &lt;th style=""text-align:right;""&gt; Petal.Length &lt;/th&gt;
+   &lt;th style=""text-align:right;""&gt; Petal.Width &lt;/th&gt;
+   &lt;th style=""text-align:left;""&gt; Species &lt;/th&gt;
+  &lt;/tr&gt;
+ &lt;/thead&gt;
+&lt;tbody&gt;
+  &lt;tr&gt;
+   &lt;td style=""text-align:right;""&gt; 5.1 &lt;/td&gt;
+   &lt;td style=""text-align:right;""&gt; 3.5 &lt;/td&gt;
+   &lt;td style=""text-align:right;""&gt; 1.4 &lt;/td&gt;
+   &lt;td style=""text-align:right;""&gt; 0.2 &lt;/td&gt;
+   &lt;td style=""text-align:left;""&gt; setosa &lt;/td&gt;
+  &lt;/tr&gt;
+  &lt;tr&gt;
+   &lt;td style=""text-align:right;""&gt; 4.9 &lt;/td&gt;
+   &lt;td style=""text-align:right;""&gt; 3.0 &lt;/td&gt;
+   &lt;td style=""text-align:right;""&gt; 1.4 &lt;/td&gt;
+   &lt;td style=""text-align:right;""&gt; 0.2 &lt;/td&gt;
+   &lt;td style=""text-align:left;""&gt; setosa &lt;/td&gt;
+  &lt;/tr&gt;
+  &lt;tr&gt;
+   &lt;td style=""text-align:right;""&gt; 4.7 &lt;/td&gt;
+   &lt;td style=""text-align:right;""&gt; 3.2 &lt;/td&gt;
+   &lt;td style=""text-align:right;""&gt; 1.3 &lt;/td&gt;
+   &lt;td style=""text-align:right;""&gt; 0.2 &lt;/td&gt;
+   &lt;td style=""text-align:left;""&gt; setosa &lt;/td&gt;
+  &lt;/tr&gt;
+  &lt;tr&gt;
+   &lt;td style=""text-align:right;""&gt; 4.6 &lt;/td&gt;
+   &lt;td style=""text-align:right;""&gt; 3.1 &lt;/td&gt;
+   &lt;td style=""text-align:right;""&gt; 1.5 &lt;/td&gt;
+   &lt;td style=""text-align:right;""&gt; 0.2 &lt;/td&gt;
+   &lt;td style=""text-align:left;""&gt; setosa &lt;/td&gt;
+  &lt;/tr&gt;
+  &lt;tr&gt;
+   &lt;td style=""text-align:right;""&gt; 5.0 &lt;/td&gt;
+   &lt;td style=""text-align:right;""&gt; 3.6 &lt;/td&gt;
+   &lt;td style=""text-align:right;""&gt; 1.4 &lt;/td&gt;
+   &lt;td style=""text-align:right;""&gt; 0.2 &lt;/td&gt;
+   &lt;td style=""text-align:left;""&gt; setosa &lt;/td&gt;
+  &lt;/tr&gt;
+  &lt;tr&gt;
+   &lt;td style=""text-align:right;""&gt; 5.4 &lt;/td&gt;
+   &lt;td style=""text-align:right;""&gt; 3.9 &lt;/td&gt;
+   &lt;td style=""text-align:right;""&gt; 1.7 &lt;/td&gt;
+   &lt;td style=""text-align:right;""&gt; 0.4 &lt;/td&gt;
+   &lt;td style=""text-align:left;""&gt; setosa &lt;/td&gt;
+  &lt;/tr&gt;
+&lt;/tbody&gt;
+&lt;/table&gt;
+
+---
+
+# Images
+
+&lt;div class=""figure"" style=""text-align: center""&gt;
+&lt;img src=""https://images.unsplash.com/photo-1535448033526-c0e85c9e6968?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=1650&amp;q=80"" alt=""Image credit: Photo by J√∂rg Angeli on Unsplash."" width=""60%"" /&gt;
+&lt;p class=""caption""&gt;Image credit: Photo by J√∂rg Angeli on Unsplash.&lt;/p&gt;
+&lt;/div&gt;
+
+Or you can also include a full page image. See next slide.
+
+---
+
+background-image: url(https://images.unsplash.com/photo-1535448033526-c0e85c9e6968?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=1650&amp;q=80)
+
+---
+
+# Math Expressions
+
+You can write LaTeX math expressions inside a pair of dollar signs, e.g. &amp;#36;\alpha+\beta$ renders `\(\alpha+\beta\)`. You can use the display style with double dollar signs:
+
+```
+$$\bar{X}=\frac{1}{n}\sum_{i=1}^nX_i$$
+```
+
+`$$\bar{X}=\frac{1}{n}\sum_{i=1}^nX_i$$`
+
+Limitations:
+
+1. The source code of a LaTeX math expression must be in one line, unless it is inside a pair of double dollar signs, in which case the starting `$$` must appear in the very beginning of a line, followed immediately by a non-space character, and the ending `$$` must be at the end of a line, led by a non-space character;
+
+1. There should not be spaces after the opening `$` or before the closing `$`.
+
+1. Math does not work on the title slide (see [#61](https://github.com/yihui/xaringan/issues/61) for a workaround).
+
+---
+
+# Feeling adventurous?
+
+- Want to find out more about `xaringan`? See https://slides.yihui.name/xaringan/#1.
+
+- You are welcomed to use the default styling of the slides. In fact, that's what I expect majority of you will do. You will differentiate yourself with the content of your presentation.
+
+- But some of you might want to play around with slide styling. The 
+`xaringanthemer` provides some solutions for this that: https://pkg.garrickadenbuie.com/xaringanthemer.
+
+- And if you want more bells and whistles, there is also `xaringanExtra`: https://pkg.garrickadenbuie.com/xaringanExtra.
+    </textarea>
+<style data-target=""print-only"">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
+<script src=""https://remarkjs.com/downloads/remark-latest.min.js""></script>
+<script>var slideshow = remark.create({
+""ratio"": ""16:9"",
+""highlightStyle"": ""github"",
+""highlightLines"": true,
+""countIncrementalSlides"": false
+});
+if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
+  window.dispatchEvent(new Event('resize'));
+});
+(function(d) {
+  var s = d.createElement(""style""), r = d.querySelector("".remark-slide-scaler"");
+  if (!r) return;
+  s.type = ""text/css""; s.innerHTML = ""@page {size: "" + r.style.width + "" "" + r.style.height +""; }"";
+  d.head.appendChild(s);
+})(document);
+
+(function(d) {
+  var el = d.getElementsByClassName(""remark-slides-area"");
+  if (!el) return;
+  var slide, slides = slideshow.getSlides(), els = el[0].children;
+  for (var i = 1; i < slides.length; i++) {
+    slide = slides[i];
+    if (slide.properties.continued === ""true"" || slide.properties.count === ""false"") {
+      els[i - 1].className += ' has-continuation';
+    }
+  }
+  var s = d.createElement(""style"");
+  s.type = ""text/css""; s.innerHTML = ""@media print { .has-continuation { display: none; } }"";
+  d.head.appendChild(s);
+})(document);
+// delete the temporary CSS (for displaying all slides initially) when the user
+// starts to view slides
+(function() {
+  var deleted = false;
+  slideshow.on('beforeShowSlide', function(slide) {
+    if (deleted) return;
+    var sheets = document.styleSheets, node;
+    for (var i = 0; i < sheets.length; i++) {
+      node = sheets[i].ownerNode;
+      if (node.dataset[""target""] !== ""print-only"") continue;
+      node.parentNode.removeChild(node);
+    }
+    deleted = true;
+  });
+})();
+(function() {
+  ""use strict""
+  // Replace <script> tags in slides area to make them executable
+  var scripts = document.querySelectorAll(
+    '.remark-slides-area .remark-slide-container script'
+  );
+  if (!scripts.length) return;
+  for (var i = 0; i < scripts.length; i++) {
+    var s = document.createElement('script');
+    var code = document.createTextNode(scripts[i].textContent);
+    s.appendChild(code);
+    var scriptAttrs = scripts[i].attributes;
+    for (var j = 0; j < scriptAttrs.length; j++) {
+      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
+    }
+    scripts[i].parentElement.replaceChild(s, scripts[i]);
+  }
+})();
+(function() {
+  var links = document.getElementsByTagName('a');
+  for (var i = 0; i < links.length; i++) {
+    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
+      links[i].target = '_blank';
+    }
+  }
+})();
+// adds .remark-code-has-line-highlighted class to <pre> parent elements
+// of code chunks containing highlighted lines with class .remark-code-line-highlighted
+(function(d) {
+  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
+  const preParents = [];
+  const findPreParent = function(line, p = 0) {
+    if (p > 1) return null; // traverse up no further than grandparent
+    const el = line.parentElement;
+    return el.tagName === ""PRE"" ? el : findPreParent(el, ++p);
+  };
+
+  for (let line of hlines) {
+    let pre = findPreParent(line);
+    if (pre && !preParents.includes(pre)) preParents.push(pre);
+  }
+  preParents.forEach(p => p.classList.add(""remark-code-has-line-highlighted""));
+})(document);</script>
+
+<script>
+slideshow._releaseMath = function(el) {
+  var i, text, code, codes = el.getElementsByTagName('code');
+  for (i = 0; i < codes.length;) {
+    code = codes[i];
+    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
+      text = code.textContent;
+      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
+          /^\$\$(.|\s)+\$\$$/.test(text) ||
+          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
+        code.outerHTML = code.innerHTML;  // remove <code></code>
+        continue;
+      }
+    }
+    i++;
+  }
+};
+slideshow._releaseMath(document);
+</script>
+<!-- dynamically load mathjax for compatibility with self-contained -->
+<script>
+(function () {
+  var script = document.createElement('script');
+  script.type = 'text/javascript';
+  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
+  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
+    script.src  = script.src.replace(/^https?:/, '');
+  document.getElementsByTagName('head')[0].appendChild(script);
+})();
+</script>
+  </body>
+</html>

---FILE: course-materials/project-instructions/repo-structure/presentation/xaringan-themer.css---
@@ -0,0 +1,233 @@
+/* -------------------------------------------------------
+ *
+ *     !! This file was generated by xaringanthemer !!
+ *
+ *  Changes made to this file directly will be overwritten
+ *  if you used xaringanthemer in your xaringan slides Rmd
+ *
+ *  Issues or likes?
+ *    - https://github.com/gadenbuie/xaringanthemer
+ *    - https://www.garrickadenbuie.com
+ *
+ *  Need help? Try:
+ *    - vignette(package = ""xaringanthemer"")
+ *    - ?xaringanthemer::style_xaringan
+ *    - xaringan wiki: https://github.com/yihui/xaringan/wiki
+ *    - remarkjs wiki: https://github.com/gnab/remark/wiki
+ *
+ *  Version: 0.3.0
+ *
+ * ------------------------------------------------------- */
+@import url(https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i&display=swap);
+@import url(https://fonts.googleapis.com/css?family=Cabin:600,600i&display=swap);
+@import url(https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700&display=swap);
+
+
+:root {
+  /* Fonts */
+  --text-font-family: 'Noto Sans';
+  --text-font-is-google: 1;
+  --text-font-family-fallback: -apple-system, BlinkMacSystemFont, avenir next, avenir, helvetica neue, helvetica, Ubuntu, roboto, noto, segoe ui, arial;
+  --text-font-base: sans-serif;
+  --header-font-family: Cabin;
+  --header-font-is-google: 1;
+  --code-font-family: 'Source Code Pro';
+  --code-font-is-google: 1;
+  --base-font-size: 20px;
+  --text-font-size: 1rem;
+  --code-font-size: 0.9rem;
+  --code-inline-font-size: 1em;
+  --header-h1-font-size: 2.75rem;
+  --header-h2-font-size: 2.25rem;
+  --header-h3-font-size: 1.75rem;
+
+  /* Colors */
+  --text-color: #000;
+  --header-color: #000;
+  --background-color: #FFF;
+  --link-color: rgb(249, 38, 114);
+  --code-highlight-color: rgba(255,255,0,0.5);
+  --inverse-text-color: #d6d6d6;
+  --inverse-background-color: #272822;
+  --inverse-header-color: #f3f3f3;
+  --title-slide-background-color: #272822;
+  --title-slide-text-color: #d6d6d6;
+  --header-background-color: #000;
+  --header-background-text-color: #FFF;
+}
+
+html {
+  font-size: var(--base-font-size);
+}
+
+body {
+  font-family: var(--text-font-family), var(--text-font-family-fallback), var(--text-font-base);
+  font-weight: normal;
+  color: var(--text-color);
+}
+h1, h2, h3 {
+  font-family: var(--header-font-family);
+  font-weight: 600;
+  color: var(--header-color);
+}
+.remark-slide-content {
+  background-color: var(--background-color);
+  font-size: 1rem;
+  padding: 16px 64px 16px 64px;
+  width: 100%;
+  height: 100%;
+}
+.remark-slide-content h1 {
+  font-size: var(--header-h1-font-size);
+}
+.remark-slide-content h2 {
+  font-size: var(--header-h2-font-size);
+}
+.remark-slide-content h3 {
+  font-size: var(--header-h3-font-size);
+}
+.remark-code, .remark-inline-code {
+  font-family: var(--code-font-family), Menlo, Consolas, Monaco, Liberation Mono, Lucida Console, monospace;
+}
+.remark-code {
+  font-size: var(--code-font-size);
+}
+.remark-inline-code {
+  font-size: var(--code-inline-font-size);
+  color: #000;
+}
+.remark-slide-number {
+  color: #272822;
+  opacity: 1;
+  font-size: 0.9em;
+}
+a, a > code {
+  color: var(--link-color);
+  text-decoration: none;
+}
+.footnote {
+  position: absolute;
+  bottom: 60px;
+  padding-right: 4em;
+  font-size: 0.9em;
+}
+.remark-code-line-highlighted {
+  background-color: var(--code-highlight-color);
+}
+.inverse {
+  background-color: var(--inverse-background-color);
+  color: var(--inverse-text-color);
+  
+}
+.inverse h1, .inverse h2, .inverse h3 {
+  color: var(--inverse-header-color);
+}
+.title-slide, .title-slide h1, .title-slide h2, .title-slide h3 {
+  color: var(--title-slide-text-color);
+}
+.title-slide {
+  background-color: var(--title-slide-background-color);
+  background-image: url(""img/confetti.jpg"");
+  background-size: cover;
+}
+.title-slide .remark-slide-number {
+  display: none;
+}
+/* Two-column layout */
+.left-column {
+  width: 20%;
+  height: 92%;
+  float: left;
+}
+.left-column h2, .left-column h3 {
+  color: #777;
+}
+.left-column h2:last-of-type, .left-column h3:last-child {
+  color: #000;
+}
+.right-column {
+  width: 75%;
+  float: right;
+  padding-top: 1em;
+}
+.pull-left {
+  float: left;
+  width: 47%;
+}
+.pull-right {
+  float: right;
+  width: 47%;
+}
+.pull-right ~ * {
+  clear: both;
+}
+img, video, iframe {
+  max-width: 100%;
+}
+blockquote {
+  border-left: solid 5px lightgray;
+  padding-left: 1em;
+}
+.remark-slide table {
+  margin: auto;
+  border-top: 1px solid #666;
+  border-bottom: 1px solid #666;
+}
+.remark-slide table thead th {
+  border-bottom: 1px solid #ddd;
+}
+th, td {
+  padding: 5px;
+}
+.remark-slide thead, .remark-slide tfoot, .remark-slide tr:nth-child(even) {
+  background: #eee;
+}
+table.dataTable tbody {
+  background-color: var(--background-color);
+  color: var(--text-color);
+}
+table.dataTable.display tbody tr.odd {
+  background-color: var(--background-color);
+}
+table.dataTable.display tbody tr.even {
+  background-color: #eee;
+}
+table.dataTable.hover tbody tr:hover, table.dataTable.display tbody tr:hover {
+  background-color: rgba(255, 255, 255, 0.5);
+}
+.dataTables_wrapper .dataTables_length, .dataTables_wrapper .dataTables_filter, .dataTables_wrapper .dataTables_info, .dataTables_wrapper .dataTables_processing, .dataTables_wrapper .dataTables_paginate {
+  color: var(--text-color);
+}
+.dataTables_wrapper .dataTables_paginate .paginate_button {
+  color: var(--text-color) !important;
+}
+
+/* Slide Header Background for h1 elements */
+.remark-slide-content.header_background > h1 {
+  display: block;
+  position: absolute;
+  top: 0;
+  left: 0;
+  width: 100%;
+  background: var(--header-background-color);
+  color: var(--header-background-text-color);
+  padding: 2rem 64px 1.5rem 64px;
+  margin-top: 0;
+  box-sizing: border-box;
+}
+.remark-slide-content.header_background {
+  padding-top: 7rem;
+}
+
+@page { margin: 0; }
+@media print {
+  .remark-slide-scaler {
+    width: 100% !important;
+    height: 100% !important;
+    transform: scale(1) !important;
+    top: 0 !important;
+    left: 0 !important;
+  }
+}
+
+

---FILE: course-materials/project-instructions/repo-structure/proposal/proposal.Rmd---
@@ -0,0 +1,23 @@
+---
+title: ""Project proposal""
+author: ""Team name""
+output: github_document
+---
+
+```{r load-packages, message = FALSE}
+library(tidyverse)
+library(broom)
+```
+
+## 1. Introduction
+
+
+
+## 2. Data
+
+
+
+## 3. Data analysis plan
+
+
+

---FILE: course-materials/project-instructions/repo-structure/proposal/proposal.md---
@@ -0,0 +1,14 @@
+Project proposal
+================
+Team name
+
+``` r
+library(tidyverse)
+library(broom)
+```
+
+## 1\. Introduction
+
+## 2\. Data
+
+## 3\. Data analysis plan

---FILE: course-materials/project/project.Rmd---
@@ -1,192 +0,0 @@
----
-title: ""Showcase your inner data scientist""
-output: 
-  html_document: 
-    css: hw.css
-    theme: yeti
-    toc: true
-    toc_float: true
-    fig_caption: true
----
-
-::: {style=""float:right;position: relative; margin-left: 20px""}
-```{r setup, echo=FALSE, fig.align=""right""}
-knitr::include_graphics(""img/laptop-3190194_1920.jpg"")
-```
-:::
-
-# TL;DR
-
-Pick a dataset, any dataset...
-
-...and do something with it.
-That is your final project in a nutshell.
-More details below.
-
-PS: Please don't make pie charts for your project.
-
-# May be too long, but please do read
-
-The final project for this class will consist of analysis on a dataset of your own choosing.
-The dataset may already exist, or you may collect your own data using a survey or by conducting an experiment.
-You can choose the data based on your interests or based on work in other courses or research projects.
-The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like) and apply them to a novel dataset in a meaningful way.
-
-## Data
-
-In order for you to have the greatest chance of success with this project it is important that you choose a manageable dataset.
-This means that the data should be readily accessible and large enough that multiple relationships can be explored.
-As such, your dataset must have at least 50 observations and between 10 to 20 variables (exceptions can be made but you must speak with me first).
-The dataset's variables should include categorical variables, discrete numerical variables, and continuous numerical variables.
-
-All analyses must be done in RStudio.
-If you are using a dataset that comes in a format that we haven't encountered in class, make sure that you are able to load it into RStudio as this can be tricky depending on the source.
-If you are having trouble ask for help before it is too late.
-
-*Reusing datasets from class:* Do not reuse datasets used in examples / homework in the class.
-
-## Components
-
-### Project proposal
-
-This is a draft of the introduction section of your project as well as a data analysis plan and your dataset.
-Each section should be no more than 1 page (excluding figures).
-You can check a print preview to confirm length.
-Your write up and all typesetting must be done with using R Markdown.
-
-#### Section 1 - Introduction:
-
-The introduction should introduce your general research question and your data (where it came from, how it was collected, what are the cases, what are the variables, etc.).
-
-#### Section 2 - Data analysis plan:
-
-The data analysis plan should include:
-
--   The outcome (dependent, response, Y) and predictor (independent, explanatory, X) variables you will use to answer your question.
--   The comparison groups you will use, if applicable.
--   Very preliminary exploratory data analysis, including some summary statistics and visualizations, along with some explanation on how they help you learn more about your data. (You can add to these later as you work on your project..)
--   The statistical method(s) that you believe will be useful in answering your question(s). (You can update these later as you work on your project.)
--   What results from these specific statistical methods are needed to support your hypothesized answer?
-
-#### Section 3 - Data:
-
-Place your data in the `/data` folder, and add dimensions and codebook to the README in this folder.
-Then print out the output of `glimpse` of your data frame.
-
-#### Grading
-
-| Total                         | 20 pts |
-|-------------------------------|--------|
-| Introduction                  | 6 pts  |
-| Data analysis plan            | 10 pts |
-| Data                          | 2 pts  |
-| Organization and code quality | 2 pts  |
-
-### Project
-
-#### Write up
-
-After providing the description of your dataset and research question in the introduction use the remainder of your write up to showcase how you have arrived at an answer / answers to your question using any techniques we have learned in this class (and some beyond, if you're feeling adventerous).
-The goal is not to do an exhaustive data analysis i.e., do not calculate every statistic and procedure you have learned for every variable, but rather let me know that you are proficient at asking meaningful questions and answering them with results of data analysis, that you are proficient in using R, and that you are proficient at interpreting and presenting the results.
-Focus on methods that help you begin to answer your research questions.
-You do not have to apply every statistical procedure we learned.
-Also pay attention to your presentation.
-Neatness, coherency, and clarity will count.
-
-Your write up must also include a one to two page conclusion and discussion.
-This will require a summary of what you have learned about your research question along with statistical arguments supporting your conclusions.
-Also critique your own methods and provide suggestions for improving your analysis.
-Issues pertaining to the reliability and validity of your data, and appropriateness of the statistical analysis should be discussed here.
-A paragraph on what you would do differently if you were able to start over with the project or what you would do next if you were going to continue work on the project should also be included.
-
-The project is very open ended.
-You should create some kind of compelling visualization(s) of this data in R.
-There is no limit on what tools or packages you may use, but sticking to packages we learned in class (`tidyverse`) is required.
-You do not need to visualize all of the data at once.
-A single high quality visualization will receive a much higher grade than a large number of poor quality visualizations.
-
-Before you finalize your write up, make sure your chunks are turned off with `echo = FALSE`.
-
-You can add sections as you see fit to the template in your project repo.
-Make sure you have a section called Introduction at the beginning and a section called Conclusion at the end.
-The rest is up to you!
-
-#### Presentation
-
-6 minutes maximum, and each team member should say something substantial.
-
-You can use any software you like for your final presentation, including R Markdown to create your slides.
-There isn't a limit to how many slides you can use, just a time limit (6 minutes total).
-Each team member should get a chance to speak during the presentation.
-Your presentation should not just be an account of everything you tried (""then we did this, then we did this, etc.""), instead it should convey what choices you made, and why, and what you found.
-
-#### Delivarables
-
-Your submission should include
-
--   RMarkdown file (formated to clearly present all of your code and results)
--   HTML file
--   md file (viewable on GitHub, with all figures)
--   Dataset(s) (in csv or RData format, in a `/data` folder)
--   Presentation (if using Keynote/PowerPoint/Google Slides, export to PDF and put in repo, in a `/presentation` folder)
-
-Style and format does count for this assignment, so please take the time to make sure everything looks good and your data and code are properly formated.
-
-## Tips
-
--   You're working in the same repo as your teammates now, so merge conflics will happen, issues will arise, and that's fine!
-    Commit and push often, and ask questions when stuck.
-
--   Review the grading guidelines below and ask questions if any of the expectations are unclear.
-
--   Make sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).
-
--   Set aside time to work together and apart (physically).
-
--   When you're done, review the .md document on GitHub to make sure you're happy with the final state of your work.
-    Then go get some rest!
-
--   Code: In your write up your code should be hidden (`echo = FALSE`) so that your document is neat and easy to read.
-    However your document should include all your code such that if I re-knit your Rmd file I should be able to obtain the results you presented.
-    **Exception:** If you want to highlight something specific about a piece of code, you're welcomed to show that portion.
-
--   Teamwork: You are to complete the assignment as a team.
-    All team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized.
-    While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works.
-
-## Grading
-
-| Total                          | 100 pts |
-|--------------------------------|---------|
-| Proposal                       | 20 pts  |
-| Presentation                   | 25 pts  |
-| Write up                       | 30 pts  |
-| Classmates' scores             | 5 pts   |
-| Team peer evaluation           | 10 pts  |
-| Repo and document organization | 10 pts  |
-
-**Team peer evaluation:** You will be asked to fill out a survey where you rate the contribution and teamwork of each team member out of 10 points.
-You will additionally report a contribution percentage for each team member.
-Filling out the survey is a prerequisite for getting credit on the team member evaluation.
-If you are suggesting that an individual did less than 20% of the work, please provide some explanation.
-If any individual gets an average peer score indicating that they did less than 10% of the work, this person will receive half the grade of the rest of the group.
-
-Grading of the project will take into account the following:
-
--   Content - What is the quality of research and/or policy question and relevancy of data to thosequestions?
--   Correctness - Are statistical procedures carried out and explained correctly?
--   Writing and Presentation - What is the quality of the statistical presentation, writing, and explanations?
--   Creativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?
-
-A general breakdown of scoring is as follows:
-
--   90%-100% - Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.
--   80%-89% - Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.
--   70%-79% - Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.
--   60%-69% - Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.
--   Below 60% - Student is not making a sufficient effort.
-
-**Late penalty:**
-
--   Late, but within 24 hours of due date/time: -20% (only applies to written portion, there is no option to do your presentation later)
--   Any later: no credit

---FILE: course-materials/project/repo-structure/project/project.Rmd---
@@ -1,14 +0,0 @@
----
-title: ""PROJECT TITLE""
-author: ""NAME HERE""
-date: ""TODAY'S DATE""
-output: github_document
----
-
-```{r setup, include=FALSE}
-knitr::opts_chunk$set(echo = FALSE)
-```
-
-Your project goes here! Before you submit, make sure your chunks are turned off with `echo = FALSE`. 
-
-You can add sections as you see fit. Make sure you have a section called Introduction at the beginning and a section called Conclusion at the end. The rest is up to you!

---FILE: course-materials/project/repo-structure/proposal/proposal.Rmd---
@@ -1,12 +0,0 @@
----
-title: ""PROJECT TITLE""
-author: ""NAME HERE""
-date: ""TODAY'S DATE""
-output: github_document
----
-
-## Section 1. Introduction
-
-## Section 2. Data analysis plan
-
-## Section 3. Data

---FILE: course-materials/slides/setup.Rmd---
@@ -4,17 +4,19 @@ options(
   htmltools.dir.version = FALSE,
   dplyr.print_min = 6, 
   dplyr.print_max = 6,
-  width = 100
+  tibble.width = 65,
+  width = 65
   )
 # figure height, width, dpi
-# figure height, width, dpi
 knitr::opts_chunk$set(echo = TRUE, 
-                      fig.width = 6, 
-                      fig.asp = 0.5,
-                      out.width = ""100%"",
+                      fig.width = 8, 
+                      fig.asp = 0.618,
+                      out.width = ""60%"",
                       fig.align = ""center"",
                       dpi = 300,
                       message = FALSE)
+# ggplot2
+ggplot2::theme_set(ggplot2::theme_gray(base_size = 16))
 # set seed
 set.seed(1234)
 # fontawesome
@@ -28,14 +30,38 @@ library(countdown)
 # conflicted
 library(conflicted)
 conflict_prefer(""filter"", ""dplyr"")
+# xaringanExtra
+library(xaringanExtra)
+xaringanExtra::use_panelset()
+# output number of lines
+hook_output <- knitr::knit_hooks$get(""output"")
+knitr::knit_hooks$set(output = function(x, options) {
+  lines <- options$output.lines
+  if (is.null(lines)) {
+    return(hook_output(x, options))  # pass to default hook
+  }
+  x <- unlist(strsplit(x, ""\n""))
+  more <- ""...""
+  if (length(lines)==1) {        # first n lines
+    if (length(x) > lines) {
+      # truncate the output, but add ....
+      x <- c(head(x, lines), more)
+    }
+  } else {
+    x <- c(more, x[lines], more)
+  }
+  # paste these lines together
+  x <- paste(c(x, """"), collapse = ""\n"")
+  hook_output(x, options)
+})
 ```
 
 layout: true
   
 <div class=""my-footer"">
 <span>
-<a href=""https://datasciencebox.org"" target=""_blank"">datasciencebox.org</a>
+<a href=""https://introds.org"" target=""_blank"">introds.org</a>
 </span>
 </div> 
 
----
\ No newline at end of file
+---",True,True,Documentation / Formatting,7
tidyverse,datascience-box,c402fe8595177fbe977ea5d5f4ad08d3c70debfe,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-12-18T10:21:43Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-12-18T10:21:43Z,Fix,.github/workflows/render-rmd.yaml,False,False,False,False,4,2,6,"---FILE: .github/workflows/render-rmd.yaml---
@@ -32,8 +32,10 @@ jobs:
         run: |
           x = system(""git diff-tree --no-commit-id --name-only -r HEAD"", intern=TRUE, wait=TRUE)
           print(x)
-          print(str(x))
-          print(""hello"")
+          x = x[grepl(""course-materials/.*/\\.[Rr]md"", x)]
+          print(x)
+          lapply(x, rmarkdown::render)
+          
         shell: Rscript {0}
     
       - name: Commit results",False,False,Rendering / Conversion,3
tidyverse,datascience-box,67b1765c5f282da66fcc5d6863baaa12e8a01492,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-12-18T10:16:40Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-12-18T10:16:40Z,Fix,.github/workflows/render-rmd.yaml,False,False,False,False,6,6,12,"---FILE: .github/workflows/render-rmd.yaml---
@@ -21,18 +21,18 @@ jobs:
     
       - uses: r-lib/actions/setup-pandoc@v1
     
-      - name: Render Rmarkdown files
+      - name: Install Packages
         run: |
-         install.packages(c(""rmarkdown"", ""tidyverse"", ""renv"", ""remotes""))
+         #install.packages(c(""rmarkdown"", ""tidyverse"", ""renv"", ""remotes""))
+         install.packages(c(""rmarkdown"", ""remotes""))
          remotes::install_github(""rundel/checklist"")
         shell: Rscript {0}
     
       - name: Render Rmarkdown files
         run: |
-          Rscript -e 'cat(system(""git diff-tree --no-commit-id --name-only -r HEAD"", intern=TRUE, wait=TRUE))'
-    
-      - name: Render Rmarkdown files
-        run: |
+          x = system(""git diff-tree --no-commit-id --name-only -r HEAD"", intern=TRUE, wait=TRUE)
+          print(x)
+          print(str(x))
           print(""hello"")
         shell: Rscript {0}
     ",False,False,Rendering / Conversion,3
tidyverse,datascience-box,120ff4eeaef6284460c4d4240d472731a14a2d28,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-12-18T10:07:53Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-12-18T10:07:53Z,Fix again,.github/workflows/render-rmd.yaml,False,False,False,False,9,4,13,"---FILE: .github/workflows/render-rmd.yaml---
@@ -21,16 +21,21 @@ jobs:
     
       - uses: r-lib/actions/setup-pandoc@v1
     
-      - name: Install packages
+      - name: Render Rmarkdown files
         run: |
-          R -e 'install.packages(c(""rmarkdown"", ""tidyverse"", ""renv"", ""remotes""))'
-          R -e 'remotes::install_github(""rundel/checklist"")'
+         install.packages(c(""rmarkdown"", ""tidyverse"", ""renv"", ""remotes""))
+         remotes::install_github(""rundel/checklist"")
+        shell: Rscript {0}
     
       - name: Render Rmarkdown files
         run: |
-          RMD_PATH=($(git diff-tree --no-commit-id --name-only -r HEAD | grep '^course-materials/.*\\.[rR]md$'))
           Rscript -e 'cat(system(""git diff-tree --no-commit-id --name-only -r HEAD"", intern=TRUE, wait=TRUE))'
     
+      - name: Render Rmarkdown files
+        run: |
+          print(""hello"")
+        shell: Rscript {0}
+    
       - name: Commit results
         run: |
           git config --local user.email ""actions@github.com""",False,False,Rendering / Conversion,3
tidyverse,datascience-box,f5ec636693b3d1ed9163e9204e8115b2418e4e8d,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-12-18T10:03:46Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-12-18T10:03:46Z,fix test,course-materials/hw-instructions/hw-01/hw-01-airbnb-edi.Rmd,True,False,True,False,0,1,1,"---FILE: course-materials/hw-instructions/hw-01/hw-01-airbnb-edi.Rmd---
@@ -13,7 +13,6 @@ knitr::include_graphics(""img/madeleine-kohler-90Qn643Pq9c-unsplash.jpg"")
 ```
 
 Recent development in Edinburgh regarding the growth of Airbnb and its impact on the housing market means a better understanding of the Airbnb listings is needed.
-
 Using data provided by Airbnb, we can explore how Airbnb availability and prices vary by neighborhood.
 
 The data come from the [Kaggle database](https://www.kaggle.com/thoroc/edinburgh-inside-airbnb/version/2).",False,True,Rendering / Conversion,3
tidyverse,datascience-box,044faeffd9eecf9f3dd612e21e5577ecb3236bc1,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-12-18T10:03:34Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-12-18T10:03:34Z,Fix,.github/workflows/render-rmd.yaml,False,False,False,False,1,1,2,"---FILE: .github/workflows/render-rmd.yaml---
@@ -23,7 +23,7 @@ jobs:
     
       - name: Install packages
         run: |
-          R -e 'install.packages(c(""rmarkdown"", ""tidyverse"", ""renv"", ""remotes"")'
+          R -e 'install.packages(c(""rmarkdown"", ""tidyverse"", ""renv"", ""remotes""))'
           R -e 'remotes::install_github(""rundel/checklist"")'
     
       - name: Render Rmarkdown files",False,False,Data / Input Handling,3
tidyverse,datascience-box,e81223f4c4da8cf722bc56f534dc19a47378dc26,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-12-18T10:00:06Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-12-18T10:00:06Z,Fix,.github/workflows/render-rmd.yaml,False,False,False,False,3,4,7,"---FILE: .github/workflows/render-rmd.yaml---
@@ -23,14 +23,13 @@ jobs:
     
       - name: Install packages
         run: |
-          R -e 'install.packages(""renv"")'
-          R -e 'renv::restore()'
+          R -e 'install.packages(c(""rmarkdown"", ""tidyverse"", ""renv"", ""remotes"")'
+          R -e 'remotes::install_github(""rundel/checklist"")'
     
       - name: Render Rmarkdown files
         run: |
           RMD_PATH=($(git diff-tree --no-commit-id --name-only -r HEAD | grep '^course-materials/.*\\.[rR]md$'))
-          Rscript -e 'cat(""HERE:"", Sys.getenv(""RMD_PATH""))'
-          Rscript -e 'for (file in commandArgs(TRUE)) rmarkdown::render(file)' ${RMD_PATH[*]}
+          Rscript -e 'cat(system(""git diff-tree --no-commit-id --name-only -r HEAD"", intern=TRUE, wait=TRUE))'
     
       - name: Commit results
         run: |",False,False,Rendering / Conversion,3
tidyverse,datascience-box,a5a0efec44a0d03127a6d2d3fef752935210be5f,Debbie Yuster,dyuster@ramapo.edu,2020-11-05T12:54:24Z,GitHub,noreply@github.com,2020-11-05T12:54:24Z,Typo fixes (including LaTeX typesetting fixes) (#97),course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors.Rmd,True,False,True,False,12,12,24,"---FILE: course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors.Rmd---
@@ -73,7 +73,7 @@ tidy(m_wi_hgt)
 
 <br>
 
-$$\widehat{log_price} = 4.77 + 0.0269~width - 0.0133~height$$
+$$\widehat{log\_price} = 4.77 + 0.0269~width - 0.0133~height$$
 
 ---
 
@@ -302,7 +302,7 @@ ggplot() +
               mapping = aes(x = volume, y = .fitted, color = cover)) +
   theme_minimal() +
   labs(title = ""Main effects, parallel slopes"", 
-       subtitle = ""weigmainht-hat = volume + cover"")
+       subtitle = ""weight-hat = volume + cover"")
 ```
 
 
@@ -347,7 +347,7 @@ to the model.
 ... a (more) objective measure for model selection
 
 - Adjusted $R^2$ doesn't increase if the new variable does not provide any new 
-informaton or is completely unrelated, as it applies a penalty for number of 
+information or is completely unrelated, as it applies a penalty for number of 
 variables included in the model.
 - This makes adjusted $R^2$ a preferable metric for model selection in multiple
 regression models.
@@ -438,21 +438,21 @@ tidy(m_main)
 
 --
 
-$$ \widehat{log_price} = 4.88 + 0.000265~surface + 0.137~artistliving $$
+$$ \widehat{log\_price} = 4.88 + 0.000265~surface + 0.137~artistliving $$
 
 ---
 
 ## Solving the model
 
 - Non-living artist: Plug in 0 for `artistliving`
 
-$\widehat{log_price} = 4.88 + 0.000265~surface + 0.137 \times 0$  
+$\widehat{log\_price} = 4.88 + 0.000265~surface + 0.137 \times 0$  
 $= 4.88 + 0.000265~surface$
 
 --
 - Living artist: Plug in 1 for `artistliving`
 
-$\widehat{log_price} = 4.88 + 0.000265~surface + 0.137 \times 1$   
+$\widehat{log\_price} = 4.88 + 0.000265~surface + 0.137 \times 1$   
 $= 5.017 + 0.000265~surface$
 
 ---
@@ -520,7 +520,7 @@ ggplot(data = m_pr_aug, mapping = aes(y = log_price, x = Surface, color = artist
 
 ---
 
-## What went ~wrong~ diferently?
+## What went ~wrong~ differently?
 
 - The way we specified our model only lets `artistliving` affect the intercept.
 - Model implicitly assumes that paintings with living and deceased artists have the *same slope* and only allows for *different intercepts*.  
@@ -574,26 +574,26 @@ tidy(m_int)
 ```
 ]
 
-$$ \widehat{log_price} = 4.91 + 0.00021~surface - 0.126~artistliving $$
+$$ \widehat{log\_price} = 4.91 + 0.00021~surface - 0.126~artistliving $$
 $$+ ~ 0.00048~surface \times artistliving $$
 
 ---
 
 ## Interpretation of interaction effects
 
 - Rate of change in price as the surface area of the painting increases does 
-vary between paintings by living and non-living artists (different slopes), 
+vary between paintings by living and non-living artists (different slopes) 
 - Some paintings by living artists are more expensive than paintings by
 non-living artists, and some are not (different intercept).
 
 .small[
 .pull-left[
 - Non-living artist: 
-$\widehat{log_price} = 4.91 + 0.00021~surface$
+$\widehat{log\_price} = 4.91 + 0.00021~surface$
 $- 0.126 \times 0 + 0.00048~surface \times 0$
 $= 4.91 + 0.00021~surface$
-- Living artist: 
-$\widehat{log_price} = 4.91 + 0.00021~surface$
+- Living artist:  
+$\widehat{log\_price} = 4.91 + 0.00021~surface$
 $- 0.126 \times 1 + 0.00048~surface \times 1$
 $= 4.91 + 0.00021~surface$
 $- 0.126 + 0.00048~surface$",False,True,Documentation / Formatting,4
tidyverse,datascience-box,f7e6431ad11c39728c2316adc7380f7ba96e4976,Debbie Yuster,dyuster@ramapo.edu,2020-10-29T14:16:24Z,GitHub,noreply@github.com,2020-10-29T14:16:24Z,"Fix minor typos (#96)

* Fix minor typos

* Update course-materials/slides/u2_d02-linear-model-single-predictor/u2_d02-linear-model-single-predictor.Rmd

* Update course-materials/slides/u2_d02-linear-model-single-predictor/u2_d02-linear-model-single-predictor.Rmd

Co-authored-by: Mine Cetinkaya-Rundel <cetinkaya.mine@gmail.com>",course-materials/slides/u2_d02-linear-model-single-predictor/u2_d02-linear-model-single-predictor.Rmd,True,False,True,False,4,4,8,"---FILE: course-materials/slides/u2_d02-linear-model-single-predictor/u2_d02-linear-model-single-predictor.Rmd---
@@ -372,11 +372,11 @@ model.
 
 ---
 
-## Height vs. lanscape features
+## Height vs. landscape features
 
 .question[
 Which of the following is the correct interpretation of $R^2$ of the model 
-below.
+below?
 ]
 
 .small[
@@ -424,7 +424,7 @@ class: middle
 
 ## Not-so-tidy regression output
 
-- You might come accross these in your googling adventures, but we'll try to stay away from them
+- You might come across these in your googling adventures, but we'll try to stay away from them
 - Not because they are wrong, but because they don't result in tidy data frames as results.
 
 ---
@@ -464,7 +464,7 @@ What makes a data frame tidy?
 
 ## Tidy regression output
 
-Achieved with functions from the broom package:
+Achieved with functions from the **broom** package:
 
 - `tidy`: Constructs a data frame that summarizes the model's statistical findings: coefficient estimates, *standard errors, test statistics, p-values*.
 - `glance`: Constructs a concise one-row summary of the model. This typically contains values such as $R^2$, adjusted $R^2$, *and residual standard error that are computed once for the entire model*.",False,True,Rendering / Conversion,3
tidyverse,datascience-box,3858809dd18e803645e2bbc63b5d63e6ddf93587,Debbie Yuster,dyuster@ramapo.edu,2020-10-23T00:16:17Z,GitHub,noreply@github.com,2020-10-23T00:16:17Z,Small changes/typo fixes (#95),course-materials/slides/u1_d14-functions-iteration/u1_d14-functions-iteration.Rmd,True,False,True,False,6,6,12,"---FILE: course-materials/slides/u1_d14-functions-iteration/u1_d14-functions-iteration.Rmd---
@@ -133,7 +133,7 @@ additional data on each art piece in the Edinburgh College of Art Collection?
 
 ## Why functions?
 
-- Automate common tasks in a power powerful and general way than copy-and-pasting:
+- Automate common tasks in a more powerful and general way than copy-and-pasting:
     - You can give a function an evocative name that makes your code easier to understand.
     - As requirements change, you only need to update code in one place, instead of many.
     - You eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).
@@ -237,7 +237,7 @@ scrape_art_info <-
 ## Turn your code into a function
 
 - Pick a short but evocative **name**, preferably a verb.
-- List inputs, or **arguments**, to the function inside `function`. If we had more the call would look like `function(x, y, z)`.
+- List inputs, or **arguments**, to the function inside `function`. If we had more arguments the call would look like `function(x, y, z)`.
 
 <br>
 
@@ -257,7 +257,7 @@ scrape_art_info <- function(x){
 
 - Pick a short but informative **name**, preferably a verb.
 - List inputs, or **arguments**, to the function inside `function`. If we had more the call would look like `function(x, y, z)`.
-- Place the **code** you have developed in body of the function, a `{` block that immediately follows `function(...)`.
+- Place the **code** you have developed in body of the function, a `{}` block that immediately follows `function(...)`.
 
 ```{r eval=FALSE}
 scrape_art_info <- function(x){
@@ -441,7 +441,7 @@ scrape_art_info(uoe_art$link[3])
 ```
 ]
 - What else do we need to do?
-  - Run the `scrape_art_info()` function to all 2909 links
+  - Run the `scrape_art_info()` function on all 2909 links
   - Combine the resulting data frames from each run into one giant data frame with 2909 rows
   
 ---
@@ -454,7 +454,7 @@ You now have a function that will scrape the relevant info on art pieces given t
 
 --
 
-From the data frame you constucted in lab yesterday: `uoe_art$link`
+From the data frame you constructed in lab yesterday: `uoe_art$link`
 
 ---
 
@@ -517,7 +517,7 @@ Functions for looping over an object and returning a value (of a specific type):
 
 * `map()` - returns a list
 * `map_lgl()` - returns a logical vector
-* `map_int()` - returns a integer vector
+* `map_int()` - returns an integer vector
 * `map_dbl()` - returns a double vector
 * `map_chr()` - returns a character vector
 * `map_df()` / `map_dfr()` - returns a data frame by row binding",False,True,Documentation / Formatting,4
tidyverse,datascience-box,c96b279b475489da1d8a1ae393c4289cdf92a983,Debbie Yuster,dyuster@ramapo.edu,2020-10-11T21:43:13Z,GitHub,noreply@github.com,2020-10-11T21:43:13Z,One minor typo + one important plot fix (#93),course-materials/slides/u1_d10-effective-dataviz/u1_d10-effective-dataviz.Rmd,True,False,True,False,2,2,4,"---FILE: course-materials/slides/u1_d10-effective-dataviz/u1_d10-effective-dataviz.Rmd---
@@ -151,7 +151,7 @@ ggplot(data = brexit, aes(x = opinion)) +
 
 ## Order by frequency
 
-`fct_infreq`: Reorder factors levels by frequency
+`fct_infreq`: Reorder factors' levels by frequency
 
 ```{r out.width=""75%""}
 ggplot(data = brexit, aes(x = fct_infreq(opinion))) +
@@ -184,7 +184,7 @@ ggplot(data = brexit, aes(x = region)) +
 `fct_relevel`: Reorder factor levels using a custom order
 
 .midi[
-```{r eval=FALSE}
+```{r eval=TRUE}
 brexit <- brexit %>%
   mutate(
     region = fct_relevel(",False,True,Documentation / Formatting,4
tidyverse,datascience-box,4baa9159c3aa4984bff2fc06dae4776abf8f4057,Kenneth C. Arnold,kenneth.arnold@gmail.com,2020-09-30T07:06:21Z,GitHub,noreply@github.com,2020-09-30T07:06:21Z,"Minor fixes to lab 06 (#90)

* Fix some typos

* Clarify a thought exercise

* Fix a typo in my correction.",course-materials/lab-instructions/lab-06/lab-06-ugly-charts.Rmd,True,False,True,False,7,7,14,"---FILE: course-materials/lab-instructions/lab-06/lab-06-ugly-charts.Rmd---
@@ -101,7 +101,7 @@ and 2011, and contains an image very similar to the one given below.
 knitr::include_graphics(""img/staff-employment.png"")
 ```
 
-Let's start by loadong the data used to create this plot.
+Let's start by loading the data used to create this plot.
 
 ```{r load-data-staff, message=FALSE, eval=TRUE}
 staff <- read_csv(""data/instructional-staff.csv"")
@@ -116,13 +116,13 @@ staff
 ```
 
 In order to recreate this visualization we need to first reshape the data to have one variable for faculty type and one variable for year. In other words, 
-we will convert the data from the long format to wide format. 
+we will convert the data from wide format to long format. 
 
-But before we do so, a thought exercise: If the long data will have a row for 
-each year/faculty type combination, and there are 5 faculty types and 11 
-years of data, how many rows will the data have?
+But before we do so, a thought exercise: *How many rows will the long-format data have?*
+It will have a row for each combination of year and faculty type.
+If there are 5 faculty types and 11 years of data, how many rows will we have?
 
-We do the wide to long converstion using a new function: `pivot_longer()`. 
+We do the wide to long conversion using a new function: `pivot_longer()`. 
 The animation below show how this function works, as well as its counterpart 
 `pivot_wider()`.
 
@@ -163,7 +163,7 @@ staff_long %>%
   geom_line()
 ```
 
-But note that this resuls in a message as well as an unexpected plot. The 
+But note that this results in a message as well as an unexpected plot. The 
 message is saying that there is only one observation for each faculty type 
 year combination. We can fix this using the `group` aesthetic following.
 ",False,True,Implementation / Logic,6
tidyverse,datascience-box,963331e5cb11e6b83a5e83015176d79522c1bce2,Debbie Yuster,dyuster@ramapo.edu,2020-09-28T22:39:36Z,GitHub,noreply@github.com,2020-09-28T22:39:36Z,Slide fixes (#88),course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data.Rmd,True,False,True,False,5,5,10,"---FILE: course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data.Rmd---
@@ -77,7 +77,7 @@ staff
 
 In order to recreate this visualization we need to first reshape the data to have 
 one variable for faculty type and one variable for year. In other words, 
-we will convert the data from the long format to wide format. 
+we will convert the data from the wide format to long format. 
 
 But before we do so... 
 
@@ -533,9 +533,9 @@ ggplot(rel_inc_long, aes(y = religion, x = frequency)) +
 
 ```{r out.width=""75%""}
 rel_inc_long <- rel_inc_long %>%
-  mutate(religion = fct_rev(religion))
+  mutate(religion = fct_rev(religion)) #<<
 
-ggplot(rel_inc_long, aes(y = religion, x = frequency)) + #<<
+ggplot(rel_inc_long, aes(y = religion, x = frequency)) + 
   geom_col()
 ```
 
@@ -666,8 +666,8 @@ ggplot(rel_inc_long, aes(y = religion, x = frequency, fill = income)) +
   theme_minimal() +
   theme(
     legend.position = ""bottom"", 
-    legend.key.size = unit(0.3, ""cm""), #<<
-    legend.box.margin = margin(t = 0, r = 0, b = 0, l = 0, unit = ""pt"") #<<
+    legend.key.size = unit(0.3, ""cm""), 
+    legend.box.margin = margin(t = 0, r = 0, b = 0, l = 0, unit = ""pt"") 
     ) +
   guides(fill = guide_legend(nrow = 2, byrow = TRUE)) +
   labs(",False,True,Rendering / Conversion,3
tidyverse,datascience-box,18655e0eb5a069f3ed3a01b0fbc277920490a3e6,Debbie Yuster,dyuster@ramapo.edu,2020-09-25T20:41:22Z,GitHub,noreply@github.com,2020-09-25T20:41:22Z,"Fix slide typos (#85)

* Added missing word

* Slide fixes

* Fix typo",course-materials/slides/u1_d05-data-wrangle/u1_d05-data-wrangle.Rmd,True,False,True,False,6,6,12,"---FILE: course-materials/slides/u1_d05-data-wrangle/u1_d05-data-wrangle.Rmd---
@@ -230,7 +230,7 @@ select(.data = hotels, lead_time)
 - Start with the function (a verb): `select()`
 - First argument is `.data` (the data frame we're working with) = `hotels`
 - Second argument is variable we want to select: `lead_time`
-- The result is a data frame with 119,300 and 1 column: --dplyr functions always 
+- The result is a data frame with 119,300 rows and 1 column: --dplyr functions always 
 expect a data frame and always yield a data frame.
 ]
 
@@ -391,7 +391,7 @@ knitr::include_graphics(""img/magrittr.jpg"")
 
 ## How does a pipe work?
 
-- You can think about the following sequence of actions - find key, 
+- You can think about the following sequence of actions - find keys, 
 unlock car, start car, drive to work, park.
 
 --
@@ -704,7 +704,7 @@ operator    | definition                   || operator     | definition
 
 .your-turn[
 
-Time to actually play around with the Star Wars dataset!
+Time to actually play around with the Hotels dataset!
 
 - Go to RStudio Cloud ([rstd.io/dsbox-cloud](http://rstd.io/dsbox-cloud)) and start `AE 04 - Hotels + Data wrangling`.
 - Open the R Markdown document and complete Exercises 1 - 4.
@@ -815,7 +815,7 @@ hotels %>%
 
 .your-turn[
 
-Time to actually play around with the Star Wars dataset!
+Time to actually play around with the Hotels dataset!
 
 - Go to RStudio Cloud ([rstd.io/dsbox-cloud](http://rstd.io/dsbox-cloud)) and start `AE 04 - Hotels + Data wrangling`.
 - Open the R Markdown document and complete Exercises 5 and 6.
@@ -897,7 +897,7 @@ hotels %>%
 
 .tip[
 `summarise()` changes the data frame entirely, it collapses rows down to a single 
-summary statistics, and removes all columns that are irrelevant to the calculation.
+summary statistic, and removes all columns that are irrelevant to the calculation.
 ]
 
 ---
@@ -974,7 +974,7 @@ hotels %>%
 
 .your-turn[
 
-Time to actually play around with the Star Wars dataset!
+Time to actually play around with the Hotels dataset!
 
 - Go to RStudio Cloud ([rstd.io/dsbox-cloud](http://rstd.io/dsbox-cloud)) and start `AE 04 - Hotels + Data wrangling`.
 - Open the R Markdown document and complete Exercises 7 and 8.",False,True,Implementation / Logic,6
tidyverse,datascience-box,ff9ba1fc55e7b0c6009cf8942666fe04e395bb8c,Debbie Yuster,dyuster@ramapo.edu,2020-09-14T08:59:53Z,GitHub,noreply@github.com,2020-09-14T08:59:53Z,"Minor slide fixes (#84)

* Fix minor typo

* Fixed Anscombe's quartet slide

(I think this is what it's supposed to be, not 100% sure)",course-materials/slides/u1_d03-data-viz-1/u1_d03-data-viz-1.Rmd,True,False,True,False,3,2,5,"---FILE: course-materials/slides/u1_d03-data-viz-1/u1_d03-data-viz-1.Rmd---
@@ -339,7 +339,7 @@ ggplot(data = starwars, mapping = aes(x = height, y = mass, color = gender)) +
 
 ## Aesthetics summary
 
-- Continuous variable are measured on a continuous scale
+- Continuous variables are measured on a continuous scale
 - Discrete variables are measured (or often counted) on a discrete scale
 
 aesthetics | discrete                 | continuous                              
@@ -468,9 +468,10 @@ ggplot(datasaurus_dozen, aes(x = x, y = y, color = dataset))+
 ```
 
 ---
+
 ## Anscombe's quartet
 
-```{r quartet-for-show, eval=FALSE}
+```{r quartet-for-show, eval=FALSE, echo=FALSE}
 library(Tmisc)
 quartet
 ```",False,True,Documentation / Formatting,4
tidyverse,datascience-box,31bb0c9633fa950544310eb6eb647e2cfabf8ce9,Debbie Yuster,dyuster@ramapo.edu,2020-09-11T22:48:10Z,GitHub,noreply@github.com,2020-09-11T22:48:10Z,"Rename u1_d03-data-viz.Rmd to u1_d03-data-viz-1.Rmd (#82)

Fixing filename to be consistent with in-pointing links and other Data Viz slide deck name",course-materials/slides/u1_d03-data-viz-1/u1_d03-data-viz-1.Rmd,True,False,True,False,0,0,0,,False,True,Rendering / Conversion,3
tidyverse,datascience-box,872a2c63688f6edf0bd174e502488ee426c10ca9,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-09-09T00:07:03Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-09-09T00:07:03Z,Fix links to u2 decks,02-making-rigorous-conclusions.Rmd,True,False,True,False,9,9,18,"---FILE: 02-making-rigorous-conclusions.Rmd---
@@ -9,7 +9,7 @@ Statistical inference is introduced from a simulation based perspective, and the
 ::: {.slide-deck}
 **Unit 2 - Deck 1: The language of models**
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d1-language-of-models/u2_d1-language-of-models.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d1-language-of-models)
+[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d01-language-of-models/u2_d01-language-of-models.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d01-language-of-models)
 
 ::: {.reading}
 [IMS :: Sec 3.1 - Fitting a line, residuals, and correlation](https://openintro-ims.netlify.app/intro-linear-models.html#fit-line-res-cor)
@@ -19,7 +19,7 @@ Statistical inference is introduced from a simulation based perspective, and the
 ::: {.slide-deck}
 **Unit 2 - Deck 2: Linear models with a single predictor**
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d2-linear-model-single-predictor/u2_d2-linear-model-single-predictor.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d2-linear-model-single-predictor)
+[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d02-linear-model-single-predictor/u2_d02-linear-model-single-predictor.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d02-linear-model-single-predictor)
 
 ::: {.reading}
 [IMS :: Sec 3.2 - Least squares regression](https://openintro-ims.netlify.app/intro-linear-models.html#least-squares-regression)
@@ -29,13 +29,13 @@ Statistical inference is introduced from a simulation based perspective, and the
 ::: {.slide-deck}
 **Unit 2 - Deck 3: Modeling non-linear relationships**
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d3-modeling-non-linear-relationships/u2_d3-modeling-non-linear-relationships.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d3-modeling-non-linear-relationships)
+[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d03-modeling-non-linear-relationships/u2_d03-modeling-non-linear-relationships.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d03-modeling-non-linear-relationships)
 :::
 
 ::: {.slide-deck}
 **Unit 2 - Deck 4: Linear models with multiple predictors**
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d4-linear-model-multiple-predictors/u2_d4-linear-model-multiple-predictors.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d4-linear-model-multiple-predictors)
+[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d04-linear-model-multiple-predictors)
 
 ::: {.reading}
 [IMS :: Sec 4.1 - Regression with multiple predictors](https://openintro-ims.netlify.app/multi-logistic-models.html#regression-multiple-predictors)
@@ -45,7 +45,7 @@ Statistical inference is introduced from a simulation based perspective, and the
 ::: {.slide-deck}
 **Unit 2 - Deck 5: Model selection**
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d5-model-selection/u2_d5-model-selection.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d5-model-selection)
+[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d05-model-selection/u2_d05-model-selection.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d05-model-selection)
 
 ::: {.reading}
 [IMS :: Sec 4.2 - Model selection](https://openintro-ims.netlify.app/multi-logistic-models.html#model-selection)
@@ -55,13 +55,13 @@ Statistical inference is introduced from a simulation based perspective, and the
 ::: {.slide-deck}
 **Unit 2 - Deck 6: Model validation**
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d6-model-validation/u2_d6-model-validation.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d6-model-validation)
+[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d06-model-validation/u2_d06-model-validation.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d06-model-validation)
 :::
 
 ::: {.slide-deck}
 **Unit 2 - Deck 7: Logistic regression and classification**
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d7-logistic-regression/u2_d7-logistic-regression.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d7-logistic-regression)
+[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d07-logistic-regression/u2_d07-logistic-regression.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d07-logistic-regression)
 
 ::: {.reading}
 [IMS :: Sec 4.5 - Logistic regression](https://openintro-ims.netlify.app/multi-logistic-models.html#logistic-regression)
@@ -71,7 +71,7 @@ Statistical inference is introduced from a simulation based perspective, and the
 ::: {.slide-deck}
 **Unit 2 - Deck 8: Quantifying uncertainty**
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d8-quantifying-uncertainty/u2_d8-quantifying-uncertainty.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d8-quantifying-uncertainty)
+[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d08-quantifying-uncertainty/u2_d08-quantifying-uncertainty.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d08-quantifying-uncertainty)
 
 ::: {.reading}
 [IMS :: Sec 5.2 - Bootstrap confidence intervals](https://openintro-ims.netlify.app/intro-stat-inference.html#boot-ci)
@@ -81,7 +81,7 @@ Statistical inference is introduced from a simulation based perspective, and the
 ::: {.slide-deck}
 **Unit 2 - Deck 9: Hypothesis testing with randomization**
 
-[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d9-hypothesis-testing/u2_d9-hypothesis-testing.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d9-hypothesis-testing)
+[[Slides]](https://rstudio-education.github.io/datascience-box/course-materials/slides/u2_d09-hypothesis-testing/u2_d09-hypothesis-testing.html#1) [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/slides/u2_d09-hypothesis-testing)
 
 ::: {.reading}
 [IMS :: Sec 5.1 - Randomization tests](https://openintro-ims.netlify.app/intro-stat-inference.html#inf-rand)",False,True,Rendering / Conversion,3
tidyverse,datascience-box,dcbddb4f7c7061aa1ee4a5509fa525abeabbfbd1,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-09-09T00:03:38Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-09-09T00:03:38Z,"Fix figure and text sizing, closes #77 and #79",course-materials/slides/u1_d02-meet-the-toolkit/u1_d02-meet-the-toolkit.Rmd;course-materials/slides/u1_d02-meet-the-toolkit/u1_d02-meet-the-toolkit.html;course-materials/slides/u1_d03-data-viz-1/u1_d03-data-viz.Rmd;course-materials/slides/u1_d03-data-viz-1/u1_d03-data-viz.html;course-materials/slides/u1_d04-data-viz-2/u1_d04-data-viz-2.Rmd;course-materials/slides/u1_d04-data-viz-2/u1_d04-data-viz-2.html;course-materials/slides/u1_d05-data-wrangle/u1_d05-data-wrangle.Rmd;course-materials/slides/u1_d05-data-wrangle/u1_d05-data-wrangle.html;course-materials/slides/u1_d05-data-wrangle/u1_d05-data-wrangle_files/figure-html/unnamed-chunk-25-1.png;course-materials/slides/u1_d06-data-join/u1_d06-data-join.Rmd;course-materials/slides/u1_d06-data-join/u1_d06-data-join.html;course-materials/slides/u1_d06-data-join/u1_d06-data-join_files/figure-html/unnamed-chunk-40-1.png;course-materials/slides/u1_d06-data-join/u1_d06-data-join_files/figure-html/unnamed-chunk-41-1.png;course-materials/slides/u1_d06-data-join/u1_d06-data-join_files/figure-html/unnamed-chunk-48-1.png;course-materials/slides/u1_d06-data-join/u1_d06-data-join_files/figure-html/unnamed-chunk-53-1.png;course-materials/slides/u1_d06-data-join/u1_d06-data-join_files/figure-html/unnamed-chunk-54-1.png;course-materials/slides/u1_d06-data-join/u1_d06-data-join_files/figure-html/unnamed-chunk-56-1.png;course-materials/slides/u1_d06-data-join/u1_d06-data-join_files/figure-html/unnamed-chunk-58-1.png;course-materials/slides/u1_d06-data-join/u1_d06-data-join_files/figure-html/unnamed-chunk-60-1.png;course-materials/slides/u1_d06-data-join/u1_d06-data-join_files/figure-html/unnamed-chunk-61-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data.Rmd;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data.html;course-materials/slides/u1_d08-data-types/u1_d08-data-types.Rmd;course-materials/slides/u1_d08-data-types/u1_d08-data-types.html;course-materials/slides/u1_d09-import-data/u1_d09-import-data.Rmd;course-materials/slides/u1_d11-studies-confounding/u1_d11-studies-confounding.Rmd;course-materials/slides/u1_d11-studies-confounding/u1_d11-studies-confounding.html;course-materials/slides/u1_d11-studies-confounding/u1_d11-studies-confounding_files/figure-html/unnamed-chunk-11-1.png;course-materials/slides/u1_d11-studies-confounding/u1_d11-studies-confounding_files/figure-html/unnamed-chunk-13-1.png;course-materials/slides/u1_d11-studies-confounding/u1_d11-studies-confounding_files/figure-html/unnamed-chunk-17-1.png;course-materials/slides/u1_d11-studies-confounding/u1_d11-studies-confounding_files/figure-html/unnamed-chunk-18-1.png;course-materials/slides/u1_d11-studies-confounding/u1_d11-studies-confounding_files/figure-html/unnamed-chunk-21-1.png;course-materials/slides/u1_d11-studies-confounding/u1_d11-studies-confounding_files/figure-html/unnamed-chunk-22-1.png;course-materials/slides/u1_d11-studies-confounding/u1_d11-studies-confounding_files/figure-html/unnamed-chunk-23-1.png;course-materials/slides/u1_d11-studies-confounding/u1_d11-studies-confounding_files/figure-html/unnamed-chunk-24-1.png;course-materials/slides/u1_d11-studies-confounding/u1_d11-studies-confounding_files/figure-html/unnamed-chunk-25-1.png;course-materials/slides/u1_d11-studies-confounding/u1_d11-studies-confounding_files/figure-html/unnamed-chunk-7-1.png;course-materials/slides/u1_d11-studies-confounding/u1_d11-studies-confounding_files/figure-html/unnamed-chunk-9-1.png;course-materials/slides/u1_d12-effective-communication/u1_d12-effective-communication.Rmd;course-materials/slides/u1_d12-effective-communication/u1_d12-effective-communication.html;course-materials/slides/u1_d12-effective-communication/u1_d12-effective-communication_files/figure-html/unnamed-chunk-11-1.png;course-materials/slides/u1_d12-effective-communication/u1_d12-effective-communication_files/figure-html/unnamed-chunk-12-1.png;course-materials/slides/u1_d12-effective-communication/u1_d12-effective-communication_files/figure-html/unnamed-chunk-13-1.png;course-materials/slides/u1_d13-webscraping/u1_d13-webscraping.Rmd;course-materials/slides/u1_d13-webscraping/u1_d13-webscraping.html;course-materials/slides/u1_d13-webscraping/u1_d13-webscraping_files/figure-html/unnamed-chunk-14-1.png;course-materials/slides/u1_d14-functions-iteration/u1_d14-functions-iteration.Rmd;course-materials/slides/u1_d14-functions-iteration/u1_d14-functions-iteration.html;course-materials/slides/u2_d01-language-of-models/data/paris-paintings.csv;course-materials/slides/u2_d01-language-of-models/img/auction-catalogue.png;course-materials/slides/u2_d01-language-of-models/img/auction-trend-paris.png;course-materials/slides/u2_d01-language-of-models/img/auction-video.png;course-materials/slides/u2_d01-language-of-models/img/broom-part-of-tidyverse.png;course-materials/slides/u2_d01-language-of-models/img/cell_phones.png;course-materials/slides/u2_d01-language-of-models/img/depart-pour-la-chasse.png;course-materials/slides/u2_d01-language-of-models/img/hex-forcats.png;course-materials/slides/u2_d01-language-of-models/img/hilary-coe-cronheim.png;course-materials/slides/u2_d01-language-of-models/img/old-auction.png;course-materials/slides/u2_d01-language-of-models/img/painting1.png;course-materials/slides/u2_d01-language-of-models/img/painting2.png;course-materials/slides/u2_d01-language-of-models/img/painting3.png;course-materials/slides/u2_d01-language-of-models/img/sandra-van-ginhoven.png;course-materials/slides/u2_d01-language-of-models/libs/font-awesome/css/all.css;course-materials/slides/u2_d01-language-of-models/libs/font-awesome/css/v4-shims.css;course-materials/slides/u2_d01-language-of-models/libs/font-awesome/webfonts/fa-brands-400.eot;course-materials/slides/u2_d01-language-of-models/libs/font-awesome/webfonts/fa-brands-400.svg;course-materials/slides/u2_d01-language-of-models/libs/font-awesome/webfonts/fa-brands-400.ttf;course-materials/slides/u2_d01-language-of-models/libs/font-awesome/webfonts/fa-brands-400.woff;course-materials/slides/u2_d01-language-of-models/libs/font-awesome/webfonts/fa-brands-400.woff2;course-materials/slides/u2_d01-language-of-models/libs/font-awesome/webfonts/fa-regular-400.eot;course-materials/slides/u2_d01-language-of-models/libs/font-awesome/webfonts/fa-regular-400.svg;course-materials/slides/u2_d01-language-of-models/libs/font-awesome/webfonts/fa-regular-400.ttf;course-materials/slides/u2_d01-language-of-models/libs/font-awesome/webfonts/fa-regular-400.woff;course-materials/slides/u2_d01-language-of-models/libs/font-awesome/webfonts/fa-regular-400.woff2;course-materials/slides/u2_d01-language-of-models/libs/font-awesome/webfonts/fa-solid-900.eot;course-materials/slides/u2_d01-language-of-models/libs/font-awesome/webfonts/fa-solid-900.svg;course-materials/slides/u2_d01-language-of-models/libs/font-awesome/webfonts/fa-solid-900.ttf;course-materials/slides/u2_d01-language-of-models/libs/font-awesome/webfonts/fa-solid-900.woff;course-materials/slides/u2_d01-language-of-models/libs/font-awesome/webfonts/fa-solid-900.woff2;course-materials/slides/u2_d01-language-of-models/libs/header-attrs/header-attrs.js;course-materials/slides/u2_d01-language-of-models/u2_d01-language-of-models.Rmd;course-materials/slides/u2_d01-language-of-models/u2_d01-language-of-models.html;course-materials/slides/u2_d01-language-of-models/u2_d01-language-of-models_files/figure-html/extrapolation-1.png;course-materials/slides/u2_d01-language-of-models/u2_d01-language-of-models_files/figure-html/height-dist-1.png;course-materials/slides/u2_d01-language-of-models/u2_d01-language-of-models_files/figure-html/height-width-gam-smooth-1.png;course-materials/slides/u2_d01-language-of-models/u2_d01-language-of-models_files/figure-html/height-width-landscape-1.png;course-materials/slides/u2_d01-language-of-models/u2_d01-language-of-models_files/figure-html/height-width-loess-smooth-1.png;course-materials/slides/u2_d01-language-of-models/u2_d01-language-of-models_files/figure-html/height-width-plot-1.png;course-materials/slides/u2_d01-language-of-models/u2_d01-language-of-models_files/figure-html/height-width-plot-alpha-1.png;course-materials/slides/u2_d01-language-of-models/u2_d01-language-of-models_files/figure-html/height-width-plot-code-1.png;course-materials/slides/u2_d01-language-of-models/u2_d01-language-of-models_files/figure-html/height-width-plot-no-se-1.png;course-materials/slides/u2_d01-language-of-models/u2_d01-language-of-models_files/figure-html/height-width-plot-no-se2-1.png;course-materials/slides/u2_d01-language-of-models/u2_d01-language-of-models_files/figure-html/height-width-plot-pink-line-1.png;course-materials/slides/u2_d01-language-of-models/u2_d01-language-of-models_files/figure-html/vis-res-1-1.png;course-materials/slides/u2_d01-language-of-models/u2_d01-language-of-models_files/figure-html/vis-res-2-1.png;course-materials/slides/u2_d01-language-of-models/u2_d01-language-of-models_files/figure-html/vis-res-3-1.png;course-materials/slides/u2_d01-language-of-models/u2_d01-language-of-models_files/figure-html/width-dist-1.png;course-materials/slides/u2_d02-linear-model-single-predictor/data/paris-paintings.csv;course-materials/slides/u2_d02-linear-model-single-predictor/img/cell_phones.png;course-materials/slides/u2_d02-linear-model-single-predictor/libs/font-awesome/css/all.css;course-materials/slides/u2_d02-linear-model-single-predictor/libs/font-awesome/css/v4-shims.css;course-materials/slides/u2_d02-linear-model-single-predictor/libs/font-awesome/webfonts/fa-brands-400.eot;course-materials/slides/u2_d02-linear-model-single-predictor/libs/font-awesome/webfonts/fa-brands-400.svg;course-materials/slides/u2_d02-linear-model-single-predictor/libs/font-awesome/webfonts/fa-brands-400.ttf;course-materials/slides/u2_d02-linear-model-single-predictor/libs/font-awesome/webfonts/fa-brands-400.woff;course-materials/slides/u2_d02-linear-model-single-predictor/libs/font-awesome/webfonts/fa-brands-400.woff2;course-materials/slides/u2_d02-linear-model-single-predictor/libs/font-awesome/webfonts/fa-regular-400.eot;course-materials/slides/u2_d02-linear-model-single-predictor/libs/font-awesome/webfonts/fa-regular-400.svg;course-materials/slides/u2_d02-linear-model-single-predictor/libs/font-awesome/webfonts/fa-regular-400.ttf;course-materials/slides/u2_d02-linear-model-single-predictor/libs/font-awesome/webfonts/fa-regular-400.woff;course-materials/slides/u2_d02-linear-model-single-predictor/libs/font-awesome/webfonts/fa-regular-400.woff2;course-materials/slides/u2_d02-linear-model-single-predictor/libs/font-awesome/webfonts/fa-solid-900.eot;course-materials/slides/u2_d02-linear-model-single-predictor/libs/font-awesome/webfonts/fa-solid-900.svg;course-materials/slides/u2_d02-linear-model-single-predictor/libs/font-awesome/webfonts/fa-solid-900.ttf;course-materials/slides/u2_d02-linear-model-single-predictor/libs/font-awesome/webfonts/fa-solid-900.woff;course-materials/slides/u2_d02-linear-model-single-predictor/libs/font-awesome/webfonts/fa-solid-900.woff2;course-materials/slides/u2_d02-linear-model-single-predictor/libs/header-attrs/header-attrs.js;course-materials/slides/u2_d02-linear-model-single-predictor/u2_d02-linear-model-single-predictor.Rmd;course-materials/slides/u2_d02-linear-model-single-predictor/u2_d02-linear-model-single-predictor.html;course-materials/slides/u2_d02-linear-model-single-predictor/u2_d02-linear-model-single-predictor_files/figure-html/extrapolate-1.png;course-materials/slides/u2_d02-linear-model-single-predictor/u2_d02-linear-model-single-predictor_files/figure-html/unnamed-chunk-20-1.png;course-materials/slides/u2_d02-linear-model-single-predictor/u2_d02-linear-model-single-predictor_files/figure-html/unnamed-chunk-21-1.png;course-materials/slides/u2_d02-linear-model-single-predictor/u2_d02-linear-model-single-predictor_files/figure-html/unnamed-chunk-22-1.png;course-materials/slides/u2_d02-linear-model-single-predictor/u2_d02-linear-model-single-predictor_files/figure-html/unnamed-chunk-23-1.png;course-materials/slides/u2_d02-linear-model-single-predictor/u2_d02-linear-model-single-predictor_files/figure-html/unnamed-chunk-24-1.png;course-materials/slides/u2_d02-linear-model-single-predictor/u2_d02-linear-model-single-predictor_files/figure-html/unnamed-chunk-25-1.png;course-materials/slides/u2_d02-linear-model-single-predictor/u2_d02-linear-model-single-predictor_files/figure-html/unnamed-chunk-26-1.png;course-materials/slides/u2_d04-linear-model-multiple-predictors/data/paris-paintings.csv;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/countdown/countdown.css;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/countdown/countdown.js;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/countdown/smb_stage_clear.mp3;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/font-awesome/css/all.css;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/font-awesome/css/v4-shims.css;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/font-awesome/webfonts/fa-brands-400.eot;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/font-awesome/webfonts/fa-brands-400.svg;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/font-awesome/webfonts/fa-brands-400.ttf;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/font-awesome/webfonts/fa-brands-400.woff;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/font-awesome/webfonts/fa-brands-400.woff2;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/font-awesome/webfonts/fa-regular-400.eot;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/font-awesome/webfonts/fa-regular-400.svg;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/font-awesome/webfonts/fa-regular-400.ttf;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/font-awesome/webfonts/fa-regular-400.woff;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/font-awesome/webfonts/fa-regular-400.woff2;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/font-awesome/webfonts/fa-solid-900.eot;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/font-awesome/webfonts/fa-solid-900.svg;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/font-awesome/webfonts/fa-solid-900.ttf;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/font-awesome/webfonts/fa-solid-900.woff;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/font-awesome/webfonts/fa-solid-900.woff2;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/header-attrs/header-attrs.js;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/htmlwidgets/htmlwidgets.js;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/pymjs/pym.v1.js;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/pymjs/pym.v1.min.js;course-materials/slides/u2_d04-linear-model-multiple-predictors/libs/widgetframe-binding/widgetframe.js;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors.Rmd;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors.html;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_cache/html/__packages;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_cache/html/plotly_05b64af38f5a983ebd27e31daae09532.RData;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_cache/html/plotly_05b64af38f5a983ebd27e31daae09532.rdb;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_cache/html/plotly_05b64af38f5a983ebd27e31daae09532.rdx;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-14-1.png;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-15-1.png;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-16-1.png;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-5-1.png;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-6-1.png;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-7-1.png;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-8-1.png;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-9-1.png;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/viz-interaction-effects-1.png;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/viz-interaction-effects2-1.png;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/viz-main-effects-1.png;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/viz-main-effects3-1.png;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/viz-surf-artistliving-1.png;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/viz-surf-lt-5000-artistliving-1.png;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/viz-surf-lt-5000-artistliving-facet-1.png;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/widgets/plotly_libs/crosstalk/css/crosstalk.css;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/widgets/plotly_libs/crosstalk/js/crosstalk.js;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/widgets/plotly_libs/crosstalk/js/crosstalk.js.map;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/widgets/plotly_libs/crosstalk/js/crosstalk.min.js;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/widgets/plotly_libs/crosstalk/js/crosstalk.min.js.map;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/widgets/plotly_libs/htmlwidgets/htmlwidgets.js;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/widgets/plotly_libs/jquery/jquery-AUTHORS.txt;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/widgets/plotly_libs/jquery/jquery.js;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/widgets/plotly_libs/jquery/jquery.min.js;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/widgets/plotly_libs/jquery/jquery.min.map;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/widgets/plotly_libs/plotly-binding/plotly.js;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/widgets/plotly_libs/plotly-htmlwidgets-css/plotly-htmlwidgets.css;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/widgets/plotly_libs/plotly-main/plotly-latest.min.js;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/widgets/plotly_libs/pymjs/pym.v1.js;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/widgets/plotly_libs/pymjs/pym.v1.min.js;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/widgets/plotly_libs/typedarray/typedarray.min.js;course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/widgets/widget_plotly.html;course-materials/slides/u2_d05-model-selection/libs/font-awesome/css/all.css;course-materials/slides/u2_d05-model-selection/libs/font-awesome/css/v4-shims.css;course-materials/slides/u2_d05-model-selection/libs/font-awesome/webfonts/fa-brands-400.eot;course-materials/slides/u2_d05-model-selection/libs/font-awesome/webfonts/fa-brands-400.svg;course-materials/slides/u2_d05-model-selection/libs/font-awesome/webfonts/fa-brands-400.ttf;course-materials/slides/u2_d05-model-selection/libs/font-awesome/webfonts/fa-brands-400.woff;course-materials/slides/u2_d05-model-selection/libs/font-awesome/webfonts/fa-brands-400.woff2;course-materials/slides/u2_d05-model-selection/libs/font-awesome/webfonts/fa-regular-400.eot;course-materials/slides/u2_d05-model-selection/libs/font-awesome/webfonts/fa-regular-400.svg;course-materials/slides/u2_d05-model-selection/libs/font-awesome/webfonts/fa-regular-400.ttf;course-materials/slides/u2_d05-model-selection/libs/font-awesome/webfonts/fa-regular-400.woff;course-materials/slides/u2_d05-model-selection/libs/font-awesome/webfonts/fa-regular-400.woff2;course-materials/slides/u2_d05-model-selection/libs/font-awesome/webfonts/fa-solid-900.eot;course-materials/slides/u2_d05-model-selection/libs/font-awesome/webfonts/fa-solid-900.svg;course-materials/slides/u2_d05-model-selection/libs/font-awesome/webfonts/fa-solid-900.ttf;course-materials/slides/u2_d05-model-selection/libs/font-awesome/webfonts/fa-solid-900.woff;course-materials/slides/u2_d05-model-selection/libs/font-awesome/webfonts/fa-solid-900.woff2;course-materials/slides/u2_d05-model-selection/libs/header-attrs/header-attrs.js;course-materials/slides/u2_d05-model-selection/u2_d05-model-selection.Rmd;course-materials/slides/u2_d05-model-selection/u2_d05-model-selection.html;course-materials/slides/u2_d05-model-selection/u2_d05-model-selection_cache/html/__packages;course-materials/slides/u2_d05-model-selection/u2_d05-model-selection_cache/html/unnamed-chunk-3_b4b4c7100dfb5fd2513049951ad81536.RData;course-materials/slides/u2_d05-model-selection/u2_d05-model-selection_cache/html/unnamed-chunk-3_b4b4c7100dfb5fd2513049951ad81536.rdb;course-materials/slides/u2_d05-model-selection/u2_d05-model-selection_cache/html/unnamed-chunk-3_b4b4c7100dfb5fd2513049951ad81536.rdx;course-materials/slides/u2_d05-model-selection/u2_d05-model-selection_cache/html/unnamed-chunk-4_90c4a9cb44fbe99410769a961f6fbd08.RData;course-materials/slides/u2_d05-model-selection/u2_d05-model-selection_cache/html/unnamed-chunk-4_90c4a9cb44fbe99410769a961f6fbd08.rdb;course-materials/slides/u2_d05-model-selection/u2_d05-model-selection_cache/html/unnamed-chunk-4_90c4a9cb44fbe99410769a961f6fbd08.rdx;course-materials/slides/u2_d05-model-selection/u2_d05-model-selection_files/figure-html/unnamed-chunk-3-1.png;course-materials/slides/u2_d05-model-selection/u2_d05-model-selection_files/figure-html/unnamed-chunk-4-1.png;course-materials/slides/u2_d06-model-validation/libs/font-awesome/css/all.css;course-materials/slides/u2_d06-model-validation/libs/font-awesome/css/v4-shims.css;course-materials/slides/u2_d06-model-validation/libs/font-awesome/webfonts/fa-brands-400.eot;course-materials/slides/u2_d06-model-validation/libs/font-awesome/webfonts/fa-brands-400.svg;course-materials/slides/u2_d06-model-validation/libs/font-awesome/webfonts/fa-brands-400.ttf;course-materials/slides/u2_d06-model-validation/libs/font-awesome/webfonts/fa-brands-400.woff;course-materials/slides/u2_d06-model-validation/libs/font-awesome/webfonts/fa-brands-400.woff2;course-materials/slides/u2_d06-model-validation/libs/font-awesome/webfonts/fa-regular-400.eot;course-materials/slides/u2_d06-model-validation/libs/font-awesome/webfonts/fa-regular-400.svg;course-materials/slides/u2_d06-model-validation/libs/font-awesome/webfonts/fa-regular-400.ttf;course-materials/slides/u2_d06-model-validation/libs/font-awesome/webfonts/fa-regular-400.woff;course-materials/slides/u2_d06-model-validation/libs/font-awesome/webfonts/fa-regular-400.woff2;course-materials/slides/u2_d06-model-validation/libs/font-awesome/webfonts/fa-solid-900.eot;course-materials/slides/u2_d06-model-validation/libs/font-awesome/webfonts/fa-solid-900.svg;course-materials/slides/u2_d06-model-validation/libs/font-awesome/webfonts/fa-solid-900.ttf;course-materials/slides/u2_d06-model-validation/libs/font-awesome/webfonts/fa-solid-900.woff;course-materials/slides/u2_d06-model-validation/libs/font-awesome/webfonts/fa-solid-900.woff2;course-materials/slides/u2_d06-model-validation/libs/header-attrs/header-attrs.js;course-materials/slides/u2_d06-model-validation/u2_d06-model-validation.Rmd;course-materials/slides/u2_d06-model-validation/u2_d06-model-validation.html;course-materials/slides/u2_d06-model-validation/u2_d06-model-validation_files/figure-html/unnamed-chunk-19-1.png;course-materials/slides/u2_d07-logistic-regression/libs/countdown/countdown.css;course-materials/slides/u2_d07-logistic-regression/libs/countdown/countdown.js;course-materials/slides/u2_d07-logistic-regression/libs/countdown/smb_stage_clear.mp3;course-materials/slides/u2_d07-logistic-regression/libs/font-awesome/css/all.css;course-materials/slides/u2_d07-logistic-regression/libs/font-awesome/css/v4-shims.css;course-materials/slides/u2_d07-logistic-regression/libs/font-awesome/webfonts/fa-brands-400.eot;course-materials/slides/u2_d07-logistic-regression/libs/font-awesome/webfonts/fa-brands-400.svg;course-materials/slides/u2_d07-logistic-regression/libs/font-awesome/webfonts/fa-brands-400.ttf;course-materials/slides/u2_d07-logistic-regression/libs/font-awesome/webfonts/fa-brands-400.woff;course-materials/slides/u2_d07-logistic-regression/libs/font-awesome/webfonts/fa-brands-400.woff2;course-materials/slides/u2_d07-logistic-regression/libs/font-awesome/webfonts/fa-regular-400.eot;course-materials/slides/u2_d07-logistic-regression/libs/font-awesome/webfonts/fa-regular-400.svg;course-materials/slides/u2_d07-logistic-regression/libs/font-awesome/webfonts/fa-regular-400.ttf;course-materials/slides/u2_d07-logistic-regression/libs/font-awesome/webfonts/fa-regular-400.woff;course-materials/slides/u2_d07-logistic-regression/libs/font-awesome/webfonts/fa-regular-400.woff2;course-materials/slides/u2_d07-logistic-regression/libs/font-awesome/webfonts/fa-solid-900.eot;course-materials/slides/u2_d07-logistic-regression/libs/font-awesome/webfonts/fa-solid-900.svg;course-materials/slides/u2_d07-logistic-regression/libs/font-awesome/webfonts/fa-solid-900.ttf;course-materials/slides/u2_d07-logistic-regression/libs/font-awesome/webfonts/fa-solid-900.woff;course-materials/slides/u2_d07-logistic-regression/libs/font-awesome/webfonts/fa-solid-900.woff2;course-materials/slides/u2_d07-logistic-regression/libs/header-attrs/header-attrs.js;course-materials/slides/u2_d07-logistic-regression/u2_d07-logistic-regression.Rmd;course-materials/slides/u2_d07-logistic-regression/u2_d07-logistic-regression.html;course-materials/slides/u2_d07-logistic-regression/u2_d07-logistic-regression_files/figure-html/unnamed-chunk-10-1.png;course-materials/slides/u2_d07-logistic-regression/u2_d07-logistic-regression_files/figure-html/unnamed-chunk-11-1.png;course-materials/slides/u2_d07-logistic-regression/u2_d07-logistic-regression_files/figure-html/unnamed-chunk-3-1.png;course-materials/slides/u2_d07-logistic-regression/u2_d07-logistic-regression_files/figure-html/unnamed-chunk-4-1.png;course-materials/slides/u2_d07-logistic-regression/u2_d07-logistic-regression_files/figure-html/unnamed-chunk-5-1.png;course-materials/slides/u2_d07-logistic-regression/u2_d07-logistic-regression_files/figure-html/unnamed-chunk-6-1.png;course-materials/slides/u2_d08-quantifying-uncertainty/data/edi-3br.csv;course-materials/slides/u2_d08-quantifying-uncertainty/img/2019-11-18-bcc-poll-tracker.png;course-materials/slides/u2_d08-quantifying-uncertainty/img/boot.png;course-materials/slides/u2_d08-quantifying-uncertainty/img/bootstrap-by-hand.png;course-materials/slides/u2_d08-quantifying-uncertainty/img/garfield.png;course-materials/slides/u2_d08-quantifying-uncertainty/img/infer-part-of-tidymodels.png;course-materials/slides/u2_d08-quantifying-uncertainty/img/net.png;course-materials/slides/u2_d08-quantifying-uncertainty/img/photo-1571942676516-bcab84649e44.png;course-materials/slides/u2_d08-quantifying-uncertainty/img/rent-bootpop.png;course-materials/slides/u2_d08-quantifying-uncertainty/img/rent-bootsamp.png;course-materials/slides/u2_d08-quantifying-uncertainty/img/spear.png;course-materials/slides/u2_d08-quantifying-uncertainty/libs/font-awesome/css/all.css;course-materials/slides/u2_d08-quantifying-uncertainty/libs/font-awesome/css/v4-shims.css;course-materials/slides/u2_d08-quantifying-uncertainty/libs/font-awesome/webfonts/fa-brands-400.eot;course-materials/slides/u2_d08-quantifying-uncertainty/libs/font-awesome/webfonts/fa-brands-400.svg;course-materials/slides/u2_d08-quantifying-uncertainty/libs/font-awesome/webfonts/fa-brands-400.ttf;course-materials/slides/u2_d08-quantifying-uncertainty/libs/font-awesome/webfonts/fa-brands-400.woff;course-materials/slides/u2_d08-quantifying-uncertainty/libs/font-awesome/webfonts/fa-brands-400.woff2;course-materials/slides/u2_d08-quantifying-uncertainty/libs/font-awesome/webfonts/fa-regular-400.eot;course-materials/slides/u2_d08-quantifying-uncertainty/libs/font-awesome/webfonts/fa-regular-400.svg;course-materials/slides/u2_d08-quantifying-uncertainty/libs/font-awesome/webfonts/fa-regular-400.ttf;course-materials/slides/u2_d08-quantifying-uncertainty/libs/font-awesome/webfonts/fa-regular-400.woff;course-materials/slides/u2_d08-quantifying-uncertainty/libs/font-awesome/webfonts/fa-regular-400.woff2;course-materials/slides/u2_d08-quantifying-uncertainty/libs/font-awesome/webfonts/fa-solid-900.eot;course-materials/slides/u2_d08-quantifying-uncertainty/libs/font-awesome/webfonts/fa-solid-900.svg;course-materials/slides/u2_d08-quantifying-uncertainty/libs/font-awesome/webfonts/fa-solid-900.ttf;course-materials/slides/u2_d08-quantifying-uncertainty/libs/font-awesome/webfonts/fa-solid-900.woff;course-materials/slides/u2_d08-quantifying-uncertainty/libs/font-awesome/webfonts/fa-solid-900.woff2;course-materials/slides/u2_d08-quantifying-uncertainty/libs/header-attrs/header-attrs.js;course-materials/slides/u2_d08-quantifying-uncertainty/u2_d08-quantifying-uncertainty.Rmd,True,False,True,False,469,543,1012,"---FILE: course-materials/slides/u1_d02-meet-the-toolkit/u1_d02-meet-the-toolkit.Rmd---
@@ -298,7 +298,7 @@ knitr::include_graphics(""img/lego-steps-commit-messages.png"")
 
 ## Why do we need version control?
 
-```{r echo=FALSE, fig.align = ""center""}
+```{r echo=FALSE, fig.align = ""center"", out.width=""40%""}
 knitr::include_graphics(""img/phd_comics_vc.gif"")
 ```
 

---FILE: course-materials/slides/u1_d02-meet-the-toolkit/u1_d02-meet-the-toolkit.html---
@@ -134,7 +134,7 @@
 
 A short list (for now):
 
-- Functions are (most often) verbs, followed by what they will be applied to in parantheses:
+- Functions are (most often) verbs, followed by what they will be applied to in parentheses:
 
 
 ```r
@@ -302,7 +302,7 @@
 
 ## Why do we need version control?
 
-&lt;img src=""img/phd_comics_vc.gif"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""img/phd_comics_vc.gif"" width=""40%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -314,7 +314,7 @@
 - There are millions of git commands -- ok, that's an exaggeration, but there are a lot of them -- and very few people know them all. 99% of the time you will use git to add, commit, push, and pull.
 
 --
-- We will be doing Git things and interfacing with GitHub through RStudio, but if you google for help you might come accross methods for doing these things in the command line -- skip that and move on to the next resource unless you feel comfortable trying it out.
+- We will be doing Git things and interfacing with GitHub through RStudio, but if you google for help you might come across methods for doing these things in the command line -- skip that and move on to the next resource unless you feel comfortable trying it out.
 
 --
 - There is a great resource for working with git and R: [happygitwithr.com](http://happygitwithr.com/). Some of the content in there is beyond the scope of this course, but it's a good place to look for help.

---FILE: course-materials/slides/u1_d03-data-viz-1/u1_d03-data-viz.Rmd---
@@ -32,9 +32,9 @@ class: middle
 
 ## What is EDA?
 
--   Exploratory data analysis (EDA) is an approach to analyzing data sets to summarize its main characteristics.
--   Often, this is visual. That's what we're focusing on today.
--   But we might also calculate summary statistics and perform data wrangling/manipulation/transformation at (or before) this stage of the analysis. That's what we'll focus on next.
+- Exploratory data analysis (EDA) is an approach to analyzing data sets to summarize its main characteristics.
+- Often, this is visual. That's what we're focusing on today.
+- But we might also calculate summary statistics and perform data wrangling/manipulation/transformation at (or before) this stage of the analysis. That's what we'll focus on next.
 
 ---
 
@@ -48,20 +48,24 @@ class: middle
 
 > *""The simple graph has brought more information to the data analyst's mind than any other device."" --- John Tukey*
 
--   Data visualization is the creation and study of the visual representation of data.
--   There are many tools for visualizing data (R is one of them), and many approaches/systems within R for making data visualizations (**ggplot2** is one of them, and that's what we're going to use).
+- Data visualization is the creation and study of the visual representation of data.
+- There are many tools for visualizing data (R is one of them), and many approaches/systems within R for making data visualizations (**ggplot2** is one of them, and that's what we're going to use).
 
 ---
 
 ## ggplot2 $\in$ tidyverse
 
 .pull-left[
-
 ```{r echo=FALSE, out.width=""80%""}
 knitr::include_graphics(""img/ggplot2-part-of-tidyverse.png"")
 ```
+] 
+.pull-right[ 
+- **ggplot2** is tidyverse's data visualization package - The `gg` in ""ggplot2"" stands for Grammar of Graphics 
+- It is inspired by the book **Grammar of Graphics** by Leland Wilkinson
+]
 
-] .pull-right[ - **ggplot2** is tidyverse's data visualization package - The `gg` in ""ggplot2"" stands for Grammar of Graphics - It is inspired by the book **Grammar of Graphics** by Leland Wilkinson] ---
+---
 
 ## Grammar of Graphics
 
@@ -84,10 +88,12 @@ ggplot(data = starwars, mapping = aes(x = height, y = mass)) +
 
 ---
 
-.question[ - What are the functions doing the plotting?
+.question[ 
+- What are the functions doing the plotting?
 - What is the dataset being plotted?
 - Which variable is on the x-axis and which variable is on the y-axis?
-- What does the warning mean?]
+- What does the warning mean?
+]
 
 ```{r eval=FALSE}
 ggplot(data = starwars, mapping = aes(x = height, y = mass)) +
@@ -103,7 +109,9 @@ ggplot(data = starwars, mapping = aes(x = height, y = mass)) +
 
 ---
 
-.question[ What does `geom_smooth()` do?]
+.question[
+What does `geom_smooth()` do?
+]
 
 ```{r out.width=""70%"", warning=FALSE, message=FALSE}
 ggplot(data = starwars, mapping = aes(x = height, y = mass)) +
@@ -117,9 +125,9 @@ ggplot(data = starwars, mapping = aes(x = height, y = mass)) +
 
 ## Hello ggplot2!
 
--   `ggplot()` is the main function in ggplot2
--   Plots are constructed in layers
--   Structure of the code for plots can be summarized as
+- `ggplot()` is the main function in ggplot2
+- Plots are constructed in layers
+- Structure of the code for plots can be summarized as
 
 ```{r eval = FALSE}
 ggplot(data = [dataset], 
@@ -128,13 +136,13 @@ ggplot(data = [dataset],
    other options
 ```
 
--   To use ggplot2 functions, first load tidyverse
+- To use ggplot2 functions, first load tidyverse
 
 ```{r}
 library(tidyverse)
 ```
 
--   For help with the ggplot2, see [ggplot2.tidyverse.org](http://ggplot2.tidyverse.org/)
+- For help with the ggplot2, see [ggplot2.tidyverse.org](http://ggplot2.tidyverse.org/)
 
 ---
 
@@ -146,8 +154,8 @@ class: middle
 
 ## Dataset terminology
 
--   Each row is an **observation**
--   Each column is a **variable**
+- Each row is an **observation**
+- Each column is a **variable**
 
 .small[
 
@@ -177,9 +185,11 @@ glimpse(starwars)
 
 ## What's in the Star Wars data?
 
-.question[ How many rows and columns does this dataset have?
+.question[
+How many rows and columns does this dataset have?
 What does each row represent?
-What does each column represent?]
+What does each column represent?
+]
 
 ```{r eval = FALSE}
 ?starwars
@@ -201,13 +211,13 @@ ggplot(data = starwars, mapping = aes(x = height, y = mass)) +
 
 ## What's that warning?
 
--   Not all characters have height and mass information (hence 28 of them not plotted)
+- Not all characters have height and mass information (hence 28 of them not plotted)
 
 <!-- -->
 
     ## Warning: Removed 28 rows containing missing values (geom_point).
 
--   Going forward I'll supress the warning to save room on slides, but it's important to note it
+- Going forward I'll supress the warning to save room on slides, but it's important to note it
 
 ---
 
@@ -228,9 +238,11 @@ ggplot(data = starwars, mapping = aes(x = height, y = mass)) +
 
 ## Mass vs. height
 
-.question[ How would you describe this relationship?
+.question[ 
+How would you describe this relationship?
 What other variables would help us understand data points that don't follow the overall trend?
-Who is the not so tall but really chubby character?]
+Who is the not so tall but really chubby character?
+]
 
 .small[
 
@@ -268,14 +280,12 @@ knitr::include_graphics(""img/jabbaplot.png"")
 
 We can map additional variables to various features of the plot:
 
--   aesthetics
-
-    -   shape
-    -   colour
-    -   size
-    -   alpha (transparency)
-
--   faceting: small multiples displaying different subsets
+- aesthetics
+    - shape
+    - colour
+    - size
+    - alpha (transparency)
+- faceting: small multiples displaying different subsets
 
 ---
 
@@ -289,10 +299,10 @@ class: middle
 
 Visual characteristics of plotting characters that can be **mapped to a specific variable** in the data are
 
--   `color`
--   `size`
--   `shape`
--   `alpha` (transparency)
+- `color`
+- `size`
+- `shape`
+- `alpha` (transparency)
 
 ---
 
@@ -329,20 +339,16 @@ ggplot(data = starwars, mapping = aes(x = height, y = mass, color = gender)) +
 
 ## Aesthetics summary
 
--   Continuous variable are measured on a continuous scale
--   Discrete variables are measured (or often counted) on a discrete scale
+- Continuous variable are measured on a continuous scale
+- Discrete variables are measured (or often counted) on a discrete scale
 
-+------------+--------------------------+-----------------------------------------+
-| aesthetics | discrete                 | continuous                              |
-+============+==========================+=========================================+
-| color      | rainbow of colors        | gradient                                |
-+------------+--------------------------+-----------------------------------------+
-| size       | discrete steps           | linear mapping between radius and value |
-+------------+--------------------------+-----------------------------------------+
-| shape      | different shape for each | shouldn't (and doesn't) work            |
-+------------+--------------------------+-----------------------------------------+
+aesthetics | discrete                 | continuous                              
+-----------|--------------------------|-----------------------------------------
+color      | rainbow of colors        | gradient
+size       | discrete steps           | linear mapping between radius and value 
+shape      | different shape for each | shouldn't (and doesn't) work            
 
--   Use aesthetics for mapping features of a plot to a variable, define the features in the geom for customization **not** mapped to a variable
+- Use aesthetics for mapping features of a plot to a variable, define the features in the geom for customization **not** mapped to a variable
 
 ---
 
@@ -354,8 +360,8 @@ class: middle
 
 ## Faceting
 
--   Smaller plots that display different subsets of the data
--   Useful for exploring conditional relationships and large data
+- Smaller plots that display different subsets of the data
+- Useful for exploring conditional relationships and large data
 
 ---
 
@@ -371,8 +377,10 @@ ggplot(data = starwars, mapping = aes(x = height, y = mass)) +
 
 ## Dive further...
 
-.question[ In the next few slides describe what each plot displays.
-Think about how the code relates to the output.]
+.question[
+In the next few slides describe what each plot displays.
+Think about how the code relates to the output.
+]
 
 --
 
@@ -407,13 +415,11 @@ ggplot(data = starwars, mapping = aes(x = height, y = mass)) +
 
 ## Facet summary
 
--   `facet_grid()`:
-
-    -   2d grid
-    -   `rows ~ cols`
-    -   use `.` for no split
-
--   `facet_wrap()`: 1d ribbon wrapped into 2d
+- `facet_grid()`:
+    - 2d grid
+    - `rows ~ cols`
+    - use `.` for no split
+- `facet_wrap()`: 1d ribbon wrapped into 2d
 
 ---
 
@@ -449,8 +455,10 @@ datasaurus_dozen %>%
 
 ---
 
-.question[ How similar do the relationships between `x` and `y` in the thirteen datasets look?
-How similar are they based on summary stats?]
+.question[
+How similar do the relationships between `x` and `y` in the thirteen datasets look?
+How similar are they based on summary stats?
+]
 
 ```{r datasaurus-plot, echo=FALSE, fig.height=4, fig.width=7}
 ggplot(datasaurus_dozen, aes(x = x, y = y, color = dataset))+
@@ -468,17 +476,14 @@ quartet
 ```
 
 .pull-left[
-
 ```{r quartet-view1, echo=FALSE}
 quartet[1:22,]
 ```
-
-] .pull-right[
-
+] 
+.pull-right[
 ```{r quartet-view2, echo=FALSE}
 quartet[23:44,]
 ```
-
 ]
 
 ---
@@ -511,7 +516,9 @@ ggplot(quartet, aes(x = x, y = y)) +
 
 ## Age at first kiss
 
-.question[ Do you see anything out of the ordinary?]
+.question[ 
+Do you see anything out of the ordinary?
+]
 
 ```{r fig.height=2.5, echo=FALSE, warning=FALSE}
 ggplot(student_survey, aes(x = first_kiss)) +
@@ -523,7 +530,9 @@ ggplot(student_survey, aes(x = first_kiss)) +
 
 ## Facebook visits
 
-.question[ How are people reporting lower vs. higher values of FB visits?]
+.question[ 
+How are people reporting lower vs. higher values of FB visits?
+]
 
 ```{r fig.height=2.5, echo=FALSE, warning=FALSE}
 ggplot(student_survey, aes(x = fb_visits_per_day)) +

---FILE: course-materials/slides/u1_d03-data-viz-1/u1_d03-data-viz.html---
@@ -41,9 +41,9 @@
 
 ## What is EDA?
 
--   Exploratory data analysis (EDA) is an approach to analyzing data sets to summarize its main characteristics.
--   Often, this is visual. That's what we're focusing on today.
--   But we might also calculate summary statistics and perform data wrangling/manipulation/transformation at (or before) this stage of the analysis. That's what we'll focus on next.
+- Exploratory data analysis (EDA) is an approach to analyzing data sets to summarize its main characteristics.
+- Often, this is visual. That's what we're focusing on today.
+- But we might also calculate summary statistics and perform data wrangling/manipulation/transformation at (or before) this stage of the analysis. That's what we'll focus on next.
 
 ---
 
@@ -57,18 +57,22 @@
 
 &gt; *""The simple graph has brought more information to the data analyst's mind than any other device."" --- John Tukey*
 
--   Data visualization is the creation and study of the visual representation of data.
--   There are many tools for visualizing data (R is one of them), and many approaches/systems within R for making data visualizations (**ggplot2** is one of them, and that's what we're going to use).
+- Data visualization is the creation and study of the visual representation of data.
+- There are many tools for visualizing data (R is one of them), and many approaches/systems within R for making data visualizations (**ggplot2** is one of them, and that's what we're going to use).
 
 ---
 
 ## ggplot2 `\(\in\)` tidyverse
 
 .pull-left[
-
 &lt;img src=""img/ggplot2-part-of-tidyverse.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
+] 
+.pull-right[ 
+- **ggplot2** is tidyverse's data visualization package - The `gg` in ""ggplot2"" stands for Grammar of Graphics 
+- It is inspired by the book **Grammar of Graphics** by Leland Wilkinson
+]
 
-] .pull-right[ - **ggplot2** is tidyverse's data visualization package - The `gg` in ""ggplot2"" stands for Grammar of Graphics - It is inspired by the book **Grammar of Graphics** by Leland Wilkinson] ---
+---
 
 ## Grammar of Graphics
 
@@ -96,10 +100,12 @@
 
 ---
 
-.question[ - What are the functions doing the plotting?
+.question[ 
+- What are the functions doing the plotting?
 - What is the dataset being plotted?
 - Which variable is on the x-axis and which variable is on the y-axis?
-- What does the warning mean?]
+- What does the warning mean?
+]
 
 
 ```r
@@ -116,7 +122,9 @@
 
 ---
 
-.question[ What does `geom_smooth()` do?]
+.question[
+What does `geom_smooth()` do?
+]
 
 
 ```r
@@ -133,9 +141,9 @@
 
 ## Hello ggplot2!
 
--   `ggplot()` is the main function in ggplot2
--   Plots are constructed in layers
--   Structure of the code for plots can be summarized as
+- `ggplot()` is the main function in ggplot2
+- Plots are constructed in layers
+- Structure of the code for plots can be summarized as
 
 
 ```r
@@ -145,14 +153,14 @@
    other options
 ```
 
--   To use ggplot2 functions, first load tidyverse
+- To use ggplot2 functions, first load tidyverse
 
 
 ```r
 library(tidyverse)
 ```
 
--   For help with the ggplot2, see [ggplot2.tidyverse.org](http://ggplot2.tidyverse.org/)
+- For help with the ggplot2, see [ggplot2.tidyverse.org](http://ggplot2.tidyverse.org/)
 
 ---
 
@@ -164,8 +172,8 @@
 
 ## Dataset terminology
 
--   Each row is an **observation**
--   Each column is a **variable**
+- Each row is an **observation**
+- Each column is a **variable**
 
 .small[
 
@@ -229,9 +237,11 @@
 
 ## What's in the Star Wars data?
 
-.question[ How many rows and columns does this dataset have?
+.question[
+How many rows and columns does this dataset have?
 What does each row represent?
-What does each column represent?]
+What does each column represent?
+]
 
 
 ```r
@@ -259,13 +269,13 @@
 
 ## What's that warning?
 
--   Not all characters have height and mass information (hence 28 of them not plotted)
+- Not all characters have height and mass information (hence 28 of them not plotted)
 
 &lt;!-- --&gt;
 
     ## Warning: Removed 28 rows containing missing values (geom_point).
 
--   Going forward I'll supress the warning to save room on slides, but it's important to note it
+- Going forward I'll supress the warning to save room on slides, but it's important to note it
 
 ---
 
@@ -289,9 +299,11 @@
 
 ## Mass vs. height
 
-.question[ How would you describe this relationship?
+.question[ 
+How would you describe this relationship?
 What other variables would help us understand data points that don't follow the overall trend?
-Who is the not so tall but really chubby character?]
+Who is the not so tall but really chubby character?
+]
 
 .small[
 
@@ -310,14 +322,12 @@
 
 We can map additional variables to various features of the plot:
 
--   aesthetics
-
-    -   shape
-    -   colour
-    -   size
-    -   alpha (transparency)
-
--   faceting: small multiples displaying different subsets
+- aesthetics
+    - shape
+    - colour
+    - size
+    - alpha (transparency)
+- faceting: small multiples displaying different subsets
 
 ---
 
@@ -331,10 +341,10 @@
 
 Visual characteristics of plotting characters that can be **mapped to a specific variable** in the data are
 
--   `color`
--   `size`
--   `shape`
--   `alpha` (transparency)
+- `color`
+- `size`
+- `shape`
+- `alpha` (transparency)
 
 ---
 
@@ -380,20 +390,16 @@
 
 ## Aesthetics summary
 
--   Continuous variable are measured on a continuous scale
--   Discrete variables are measured (or often counted) on a discrete scale
+- Continuous variable are measured on a continuous scale
+- Discrete variables are measured (or often counted) on a discrete scale
 
-+------------+--------------------------+-----------------------------------------+
-| aesthetics | discrete                 | continuous                              |
-+============+==========================+=========================================+
-| color      | rainbow of colors        | gradient                                |
-+------------+--------------------------+-----------------------------------------+
-| size       | discrete steps           | linear mapping between radius and value |
-+------------+--------------------------+-----------------------------------------+
-| shape      | different shape for each | shouldn't (and doesn't) work            |
-+------------+--------------------------+-----------------------------------------+
+aesthetics | discrete                 | continuous                              
+-----------|--------------------------|-----------------------------------------
+color      | rainbow of colors        | gradient
+size       | discrete steps           | linear mapping between radius and value 
+shape      | different shape for each | shouldn't (and doesn't) work            
 
--   Use aesthetics for mapping features of a plot to a variable, define the features in the geom for customization **not** mapped to a variable
+- Use aesthetics for mapping features of a plot to a variable, define the features in the geom for customization **not** mapped to a variable
 
 ---
 
@@ -405,8 +411,8 @@
 
 ## Faceting
 
--   Smaller plots that display different subsets of the data
--   Useful for exploring conditional relationships and large data
+- Smaller plots that display different subsets of the data
+- Useful for exploring conditional relationships and large data
 
 ---
 
@@ -425,8 +431,10 @@
 
 ## Dive further...
 
-.question[ In the next few slides describe what each plot displays.
-Think about how the code relates to the output.]
+.question[
+In the next few slides describe what each plot displays.
+Think about how the code relates to the output.
+]
 
 --
 
@@ -470,13 +478,11 @@
 
 ## Facet summary
 
--   `facet_grid()`:
-
-    -   2d grid
-    -   `rows ~ cols`
-    -   use `.` for no split
-
--   `facet_wrap()`: 1d ribbon wrapped into 2d
+- `facet_grid()`:
+    - 2d grid
+    - `rows ~ cols`
+    - use `.` for no split
+- `facet_wrap()`: 1d ribbon wrapped into 2d
 
 ---
 
@@ -534,8 +540,10 @@
 
 ---
 
-.question[ How similar do the relationships between `x` and `y` in the thirteen datasets look?
-How similar are they based on summary stats?]
+.question[
+How similar do the relationships between `x` and `y` in the thirteen datasets look?
+How similar are they based on summary stats?
+]
 
 &lt;img src=""u1_d03-data-viz_files/figure-html/datasaurus-plot-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
 
@@ -550,7 +558,6 @@
 
 .pull-left[
 
-
 ```
 ##    set  x     y
 ## 1    I 10  8.04
@@ -576,9 +583,8 @@
 ## 21  II  7  7.26
 ## 22  II  5  4.74
 ```
-
-] .pull-right[
-
+] 
+.pull-right[
 
 ```
 ##    set  x     y
@@ -605,7 +611,6 @@
 ## 43  IV  8  7.91
 ## 44  IV  8  6.89
 ```
-
 ]
 
 ---
@@ -652,15 +657,19 @@
 
 ## Age at first kiss
 
-.question[ Do you see anything out of the ordinary?]
+.question[ 
+Do you see anything out of the ordinary?
+]
 
 &lt;img src=""u1_d03-data-viz_files/figure-html/unnamed-chunk-24-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
 ## Facebook visits
 
-.question[ How are people reporting lower vs. higher values of FB visits?]
+.question[ 
+How are people reporting lower vs. higher values of FB visits?
+]
 
 &lt;img src=""u1_d03-data-viz_files/figure-html/unnamed-chunk-25-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
     </textarea>

---FILE: course-materials/slides/u1_d04-data-viz-2/u1_d04-data-viz-2.Rmd---
@@ -30,16 +30,16 @@ class: middle
 
 ## Number of variables involved
 
--   Univariate data analysis - distribution of single variable
--   Bivariate data analysis - relationship between two variables
--   Multivariate data analysis - relationship between many variables at once, usually focusing on the relationship between two while conditioning for others
+- Univariate data analysis - distribution of single variable
+- Bivariate data analysis - relationship between two variables
+- Multivariate data analysis - relationship between many variables at once, usually focusing on the relationship between two while conditioning for others
 
 ---
 
 ## Types of variables
 
--   **Numerical variables** can be classified as **continuous** or **discrete** based on whether or not the variable can take on an infinite number of values or only non-negative whole numbers, respectively.
--   If the variable is **categorical**, we can determine if it is **ordinal** based on whether or not the levels have a natural ordering.
+- **Numerical variables** can be classified as **continuous** or **discrete** based on whether or not the variable can take on an infinite number of values or only non-negative whole numbers, respectively.
+- If the variable is **categorical**, we can determine if it is **ordinal** based on whether or not the levels have a natural ordering.
 
 ---
 
@@ -51,16 +51,12 @@ class: middle
 
 ## Describing shapes of numerical distributions
 
--   shape:
-
-    -   skewness: right-skewed, left-skewed, symmetric (skew is to the side of the longer tail)
-    -   modality: unimodal, bimodal, multimodal, uniform
-
--   center: mean (`mean`), median (`median`), mode (not always useful)
-
--   spread: range (`range`), standard deviation (`sd`), inter-quartile range (`IQR`)
-
--   unusal observations
+- shape:
+    - skewness: right-skewed, left-skewed, symmetric (skew is to the side of the longer tail)
+    - modality: unimodal, bimodal, multimodal, uniform
+- center: mean (`mean`), median (`median`), mode (not always useful)
+- spread: range (`range`), standard deviation (`sd`), inter-quartile range (`IQR`)
+- unusal observations
 
 ---
 
@@ -165,9 +161,9 @@ ggplot(data = starwars, mapping = aes(x = gender, fill = hair_color2)) +
 
 Time to actually play around with the Star Wars dataset!
 
--   Go to RStudio Cloud ([rstd.io/dsbox-cloud](http://rstd.io/dsbox-cloud)) and start `AE 03 - StarWars + Data visualization`.
--   Open the R Markdown document and complete the exercise (and if time allows, the stretch goal exercise).
--   Once done, place a green sticky on your laptop. If you have questions, place a pink sticky. ]
+- Go to RStudio Cloud ([rstd.io/dsbox-cloud](http://rstd.io/dsbox-cloud)) and start `AE 03 - StarWars + Data visualization`.
+- Open the R Markdown document and complete the exercise (and if time allows, the stretch goal exercise).
+- Once done, place a green sticky on your laptop. If you have questions, place a pink sticky. ]
 
 ---
 

---FILE: course-materials/slides/u1_d04-data-viz-2/u1_d04-data-viz-2.html---
@@ -41,16 +41,16 @@
 
 ## Number of variables involved
 
--   Univariate data analysis - distribution of single variable
--   Bivariate data analysis - relationship between two variables
--   Multivariate data analysis - relationship between many variables at once, usually focusing on the relationship between two while conditioning for others
+- Univariate data analysis - distribution of single variable
+- Bivariate data analysis - relationship between two variables
+- Multivariate data analysis - relationship between many variables at once, usually focusing on the relationship between two while conditioning for others
 
 ---
 
 ## Types of variables
 
--   **Numerical variables** can be classified as **continuous** or **discrete** based on whether or not the variable can take on an infinite number of values or only non-negative whole numbers, respectively.
--   If the variable is **categorical**, we can determine if it is **ordinal** based on whether or not the levels have a natural ordering.
+- **Numerical variables** can be classified as **continuous** or **discrete** based on whether or not the variable can take on an infinite number of values or only non-negative whole numbers, respectively.
+- If the variable is **categorical**, we can determine if it is **ordinal** based on whether or not the levels have a natural ordering.
 
 ---
 
@@ -62,16 +62,12 @@
 
 ## Describing shapes of numerical distributions
 
--   shape:
-
-    -   skewness: right-skewed, left-skewed, symmetric (skew is to the side of the longer tail)
-    -   modality: unimodal, bimodal, multimodal, uniform
-
--   center: mean (`mean`), median (`median`), mode (not always useful)
-
--   spread: range (`range`), standard deviation (`sd`), inter-quartile range (`IQR`)
-
--   unusal observations
+- shape:
+    - skewness: right-skewed, left-skewed, symmetric (skew is to the side of the longer tail)
+    - modality: unimodal, bimodal, multimodal, uniform
+- center: mean (`mean`), median (`median`), mode (not always useful)
+- spread: range (`range`), standard deviation (`sd`), inter-quartile range (`IQR`)
+- unusal observations
 
 ---
 
@@ -205,9 +201,9 @@
 
 Time to actually play around with the Star Wars dataset!
 
--   Go to RStudio Cloud ([rstd.io/dsbox-cloud](http://rstd.io/dsbox-cloud)) and start `AE 03 - StarWars + Data visualization`.
--   Open the R Markdown document and complete the exercise (and if time allows, the stretch goal exercise).
--   Once done, place a green sticky on your laptop. If you have questions, place a pink sticky. ]
+- Go to RStudio Cloud ([rstd.io/dsbox-cloud](http://rstd.io/dsbox-cloud)) and start `AE 03 - StarWars + Data visualization`.
+- Open the R Markdown document and complete the exercise (and if time allows, the stretch goal exercise).
+- Once done, place a green sticky on your laptop. If you have questions, place a pink sticky. ]
 
 ---
 

---FILE: course-materials/slides/u1_d05-data-wrangle/u1_d05-data-wrangle.Rmd---
@@ -474,7 +474,7 @@ ggplot(hotels, aes(x = hotel, fill = deposit_type)) %>%
 
 `r emo::ji(""white_check_mark"")`
 
-```{r fig.width=10, fig.height=2, dpi=300}
+```{r out.width=""40%""}
 ggplot(hotels, aes(x = hotel, fill = deposit_type)) +
   geom_bar()
 ```

---FILE: course-materials/slides/u1_d05-data-wrangle/u1_d05-data-wrangle.html---
@@ -711,7 +711,7 @@
   geom_bar()
 ```
 
-&lt;img src=""u1_d05-data-wrangle_files/figure-html/unnamed-chunk-25-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d05-data-wrangle_files/figure-html/unnamed-chunk-25-1.png"" width=""40%"" style=""display: block; margin: auto;"" /&gt;
 ]
 
 ---

---FILE: course-materials/slides/u1_d06-data-join/u1_d06-data-join.Rmd---
@@ -44,7 +44,7 @@ class: middle
 Fisheries and Aquaculture Department of the Food and Agriculture Organization of 
 the United Nations collects data on fisheries production of countries.
 
-```{r echo=FALSE, out.width=""60%"", fig.align=""center""}
+```{r echo=FALSE, out.width=""60%""}
 include_graphics(""img/fisheries-data.png"")
 ```
 .center[
@@ -122,7 +122,7 @@ improve this visualization? Note that countries whose total harvest was less
 than 100,000 tons are not included in the visualization.
 ]
 
-```{r echo=FALSE, out.width=""60%"", fig.align=""center""}
+```{r echo=FALSE, out.width=""60%""}
 include_graphics(""img/fisheries.png"")
 ```
 
@@ -431,7 +431,7 @@ fisheries_summary <- fisheries %>%
 
 ## Visualize continent summary stats
 
-```{r fig.height=4,fig.width=10}
+```{r out.width=""80%""}
 ggplot(fisheries_summary, aes(x = continent, y = mean_ap)) +
   geom_col()
 ```
@@ -440,7 +440,7 @@ ggplot(fisheries_summary, aes(x = continent, y = mean_ap)) +
 
 ## Improve visualization
 
-```{r fig.height=4,fig.width=10}
+```{r out.width=""80%""}
 ggplot(fisheries_summary, 
        aes(x = fct_reorder(continent, mean_ap), y = mean_ap)) + #<<
   geom_col()
@@ -517,7 +517,7 @@ map_data(""world"")[1:14,]
 
 ## Connect the dots
 
-```{r echo=FALSE, out.width=""50%"", fig.align=""center""}
+```{r echo=FALSE, out.width=""50%""}
 include_graphics(""img/connect-the-dots-australia.png"")
 ```
 
@@ -545,7 +545,7 @@ world_map <- map_data(""world"") %>%
 ## Map the world
 
 .midi[
-```{r fig.height=5, fig.width=12}
+```{r}
 ggplot(world_map, aes(x = long, y = lat, group = group)) +
   geom_polygon(fill = ""gray"") +
   theme_minimal()
@@ -586,7 +586,7 @@ glimpse(fisheries_map)
 ## Mapping fisheries
 
 .midi[
-```{r fig.height=4.5, fig.width=12}
+```{r fig.asp=0.4}
 ggplot(fisheries_map, mapping = aes(x = long, y = lat, group = group)) +
   geom_polygon(aes(fill = capture)) +
   scale_fill_viridis_c() +
@@ -600,7 +600,7 @@ ggplot(fisheries_map, mapping = aes(x = long, y = lat, group = group)) +
 What is misleading about the following map?
 ]
 
-```{r echo=FALSE, fig.height=4.5, fig.width=12, fig.align=""center""}
+```{r echo=FALSE, fig.asp=0.4}
 ggplot(fisheries_map, mapping = aes(x = long, y = lat, group = group)) +
   geom_polygon(aes(fill = capture)) +
   scale_fill_viridis_c() +
@@ -634,7 +634,7 @@ ggplot() +
 
 ---
 
-```{r echo=FALSE, fig.height=6, fig.width=11, fig.align=""center""}
+```{r echo=FALSE, fig.asp=0.8}
 ggplot() +
   geom_polygon(world_map, 
                mapping = aes(x = long, y = lat, group = group), 
@@ -678,7 +678,7 @@ ggplot() +
 
 ---
 
-```{r echo=FALSE, fig.height=6, fig.width=11, fig.align=""center""}
+```{r echo=FALSE, fig.asp=0.8}
 ggplot() +
   geom_polygon(world_map, mapping = aes(x = long, y = lat, group = group), fill = ""lightgray"") +
   geom_polygon(fisheries_map, mapping = aes(x = long, y = lat, group = group, fill = log(capture))) +
@@ -719,7 +719,7 @@ ggplot() +
 
 ---
 
-```{r echo=FALSE, fig.height=6, fig.width=11, fig.align=""center""}
+```{r echo=FALSE, fig.asp=0.8}
 ggplot() +
   geom_polygon(world_map, mapping = aes(x = long, y = lat, group = group), fill = ""lightgray"") +
   geom_polygon(fisheries_map, mapping = aes(x = long, y = lat, group = group, fill = log(aquaculture+1))) +
@@ -737,7 +737,7 @@ ggplot() +
 
 ---
 
-```{r echo=FALSE, fig.height=6, fig.width=11, fig.align=""center""}
+```{r echo=FALSE}
 fisheries_map <- fisheries_map %>%
   mutate(
     aquaculture_perc = aquaculture / total

---FILE: course-materials/slides/u1_d06-data-join/u1_d06-data-join.html---
@@ -163,19 +163,6 @@
   summarise(across(is.numeric, mean))
 ```
 
-```
-## Warning: Predicate functions must be wrapped in `where()`.
-## 
-##   # Bad
-##   data %&gt;% select(is.numeric)
-## 
-##   # Good
-##   data %&gt;% select(where(is.numeric))
-## 
-## ‚Ñπ Please update your code.
-## This message is displayed once per session.
-```
-
 ```
 ## # A tibble: 1 x 3
 ##   capture aquaculture   total
@@ -646,7 +633,7 @@
   geom_col()
 ```
 
-&lt;img src=""u1_d06-data-join_files/figure-html/unnamed-chunk-40-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d06-data-join_files/figure-html/unnamed-chunk-40-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -659,7 +646,7 @@
   geom_col()
 ```
 
-&lt;img src=""u1_d06-data-join_files/figure-html/unnamed-chunk-41-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d06-data-join_files/figure-html/unnamed-chunk-41-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 

---FILE: course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data.Rmd---
@@ -54,7 +54,7 @@ and other academic professionals.
 by the AAUP shows trends in instructional staff employees between 1975 
 and 2011, and contains an image very similar to the one given below.
 
-```{r echo=FALSE,out.width=""70%"",fig.align=""center""}
+```{r echo=FALSE,out.width=""70%""}
 include_graphics(""img/staff-employment.png"")
 ```
 
@@ -90,7 +90,7 @@ and there are 5 faculty types and 11 years of data, how many rows will the data
 
 class: middle
 
-```{r echo=FALSE,out.width=""80%"",fig.align=""center""}
+```{r echo=FALSE,out.width=""80%""}
 include_graphics(""img/pivot.gif"")
 ```
 
@@ -175,7 +175,7 @@ staff_long %>%
 
 ## Some improvement...
 
-```{r out.width=""80%""}
+```{r}
 staff_long %>%
   ggplot(aes(x = percentage, y = year, fill = faculty_type)) +
   geom_col()
@@ -185,7 +185,7 @@ staff_long %>%
 
 ## More improvement
 
-```{r out.width=""80%""}
+```{r}
 staff_long %>%
   ggplot(aes(x = year, y = percentage, group = faculty_type, color = faculty_type)) +
   geom_line()
@@ -418,7 +418,7 @@ class: middle
 
 ---
 
-```{r echo=FALSE, out.width=""85%"", fig.align=""center""}
+```{r echo=FALSE, out.width=""85%""}
 include_graphics(""img/relig-income.png"")
 ```
 
@@ -531,7 +531,7 @@ ggplot(rel_inc_long, aes(y = religion, x = frequency)) +
 
 ## Reverse religion order
 
-```{r out.width=""80%""}
+```{r out.width=""75%""}
 rel_inc_long <- rel_inc_long %>%
   mutate(religion = fct_rev(religion))
 
@@ -565,7 +565,7 @@ rel_inc_long <- rel_inc_long %>%
 
 ## Plot again
 
-```{r}
+```{r out.width=""80%""}
 ggplot(rel_inc_long, aes(y = religion, x = frequency, fill = income)) + 
   geom_col()
 ```

---FILE: course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data.html---
@@ -237,7 +237,7 @@
   geom_col()
 ```
 
-&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-10-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-10-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -250,7 +250,7 @@
   geom_line()
 ```
 
-&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-11-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-11-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -577,7 +577,7 @@
   geom_col()
 ```
 
-&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-30-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-30-1.png"" width=""75%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -615,7 +615,7 @@
   geom_col()
 ```
 
-&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-33-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-33-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 

---FILE: course-materials/slides/u1_d08-data-types/u1_d08-data-types.Rmd---
@@ -55,7 +55,7 @@ cat_lovers %>%
 ```
 
 ```{r echo=FALSE, caption=""Help for mean"", out.width=""80%"", fig.align=""center""}
-include_graphics(""img/mean-help.png"")
+knitr::include_graphics(""img/mean-help.png"")
 ```
 
 ---
@@ -592,7 +592,7 @@ cat_lovers %>%
 ]
 .pull-right[
 ```{r echo=FALSE, out.width=""70%""}
-include_graphics(""img/forcats-part-of-tidyverse.png"")
+knitr::include_graphics(""img/forcats-part-of-tidyverse.png"")
 ```
 ]
 - Factors are useful when you have true categorical data and you want to override the ordering of character vectors to improve display
@@ -643,7 +643,7 @@ class: middle
 
 .pull-left[
 ```{r echo=FALSE, out.width=""70%"", fig.align=""center""}
-include_graphics(""img/lubridate-not-part-of-tidyverse.png"")
+knitr::include_graphics(""img/lubridate-not-part-of-tidyverse.png"")
 ```
 ]
 .pull-right[

---FILE: course-materials/slides/u1_d08-data-types/u1_d08-data-types.html---
@@ -149,8 +149,8 @@
 ## Let's take another look
 
 .small[
-<div id=""htmlwidget-0b2450c22e55e4a5515d"" style=""width:100%;height:auto;"" class=""datatables html-widget""></div>
-<script type=""application/json"" data-for=""htmlwidget-0b2450c22e55e4a5515d"">{""x"":{""filter"":""none"",""data"":[[""1"",""2"",""3"",""4"",""5"",""6"",""7"",""8"",""9"",""10"",""11"",""12"",""13"",""14"",""15"",""16"",""17"",""18"",""19"",""20"",""21"",""22"",""23"",""24"",""25"",""26"",""27"",""28"",""29"",""30"",""31"",""32"",""33"",""34"",""35"",""36"",""37"",""38"",""39"",""40"",""41"",""42"",""43"",""44"",""45"",""46"",""47"",""48"",""49"",""50"",""51"",""52"",""53"",""54"",""55"",""56"",""57"",""58"",""59"",""60""],[""Bernice Warren"",""Woodrow Stone"",""Willie Bass"",""Tyrone Estrada"",""Alex Daniels"",""Jane Bates"",""Latoya Simpson"",""Darin Woods"",""Agnes Cobb"",""Tabitha Grant"",""Perry Cross"",""Wanda Silva"",""Alicia Sims"",""Emily Logan"",""Woodrow Elliott"",""Brent Copeland"",""Pedro Carlson"",""Patsy Luna"",""Brett Robbins"",""Oliver George"",""Calvin Perry"",""Lora Gutierrez"",""Charlotte Sparks"",""Earl Mack"",""Leslie Wade"",""Santiago Barker"",""Jose Bell"",""Lynda Smith"",""Bradford Marshall"",""Irving Miller"",""Caroline Simpson"",""Frances Welch"",""Melba Jenkins"",""Veronica Morales"",""Juanita Cunningham"",""Maurice Howard"",""Teri Pierce"",""Phil Franklin"",""Jan Zimmerman"",""Leslie Price"",""Bessie Patterson"",""Ethel Wolfe"",""Naomi Wright"",""Sadie Frank"",""Lonnie Cannon"",""Tony Garcia"",""Darla Newton"",""Ginger Clark"",""Lionel Campbell"",""Florence Klein"",""Harriet Leonard"",""Terrence Harrington"",""Travis Garner"",""Doug Bass"",""Pat Norris"",""Dawn Young"",""Shari Alvarez"",""Tamara Robinson"",""Megan Morgan"",""Kara Obrien""],[""0"",""0"",""1"",""3"",""3"",""2"",""1"",""1"",""0"",""0"",""0"",""0"",""1"",""3"",""3"",""2"",""1"",""1"",""0"",""0"",""1"",""1"",""0"",""0"",""4"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""1"",""3"",""3"",""2"",""1"",""1.5 - honestly I think one of my cats is half human"",""0"",""0"",""1"",""0"",""1"",""three"",""1"",""1"",""1"",""0"",""0"",""2""],[""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""ambidextrous"",""ambidextrous"",""ambidextrous"",""ambidextrous"",""ambidextrous""]],""container"":""<table class=\""display\"">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>name<\/th>\n      <th>number_of_cats<\/th>\n      <th>handedness<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>"",""options"":{""order"":[],""autoWidth"":false,""orderClasses"":false,""columnDefs"":[{""orderable"":false,""targets"":0}]}},""evals"":[],""jsHooks"":[]}</script>
+<div id=""htmlwidget-8f836166d559454ecd73"" style=""width:100%;height:auto;"" class=""datatables html-widget""></div>
+<script type=""application/json"" data-for=""htmlwidget-8f836166d559454ecd73"">{""x"":{""filter"":""none"",""data"":[[""1"",""2"",""3"",""4"",""5"",""6"",""7"",""8"",""9"",""10"",""11"",""12"",""13"",""14"",""15"",""16"",""17"",""18"",""19"",""20"",""21"",""22"",""23"",""24"",""25"",""26"",""27"",""28"",""29"",""30"",""31"",""32"",""33"",""34"",""35"",""36"",""37"",""38"",""39"",""40"",""41"",""42"",""43"",""44"",""45"",""46"",""47"",""48"",""49"",""50"",""51"",""52"",""53"",""54"",""55"",""56"",""57"",""58"",""59"",""60""],[""Bernice Warren"",""Woodrow Stone"",""Willie Bass"",""Tyrone Estrada"",""Alex Daniels"",""Jane Bates"",""Latoya Simpson"",""Darin Woods"",""Agnes Cobb"",""Tabitha Grant"",""Perry Cross"",""Wanda Silva"",""Alicia Sims"",""Emily Logan"",""Woodrow Elliott"",""Brent Copeland"",""Pedro Carlson"",""Patsy Luna"",""Brett Robbins"",""Oliver George"",""Calvin Perry"",""Lora Gutierrez"",""Charlotte Sparks"",""Earl Mack"",""Leslie Wade"",""Santiago Barker"",""Jose Bell"",""Lynda Smith"",""Bradford Marshall"",""Irving Miller"",""Caroline Simpson"",""Frances Welch"",""Melba Jenkins"",""Veronica Morales"",""Juanita Cunningham"",""Maurice Howard"",""Teri Pierce"",""Phil Franklin"",""Jan Zimmerman"",""Leslie Price"",""Bessie Patterson"",""Ethel Wolfe"",""Naomi Wright"",""Sadie Frank"",""Lonnie Cannon"",""Tony Garcia"",""Darla Newton"",""Ginger Clark"",""Lionel Campbell"",""Florence Klein"",""Harriet Leonard"",""Terrence Harrington"",""Travis Garner"",""Doug Bass"",""Pat Norris"",""Dawn Young"",""Shari Alvarez"",""Tamara Robinson"",""Megan Morgan"",""Kara Obrien""],[""0"",""0"",""1"",""3"",""3"",""2"",""1"",""1"",""0"",""0"",""0"",""0"",""1"",""3"",""3"",""2"",""1"",""1"",""0"",""0"",""1"",""1"",""0"",""0"",""4"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""1"",""3"",""3"",""2"",""1"",""1.5 - honestly I think one of my cats is half human"",""0"",""0"",""1"",""0"",""1"",""three"",""1"",""1"",""1"",""0"",""0"",""2""],[""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""ambidextrous"",""ambidextrous"",""ambidextrous"",""ambidextrous"",""ambidextrous""]],""container"":""<table class=\""display\"">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>name<\/th>\n      <th>number_of_cats<\/th>\n      <th>handedness<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>"",""options"":{""order"":[],""autoWidth"":false,""orderClasses"":false,""columnDefs"":[{""orderable"":false,""targets"":0}]}},""evals"":[],""jsHooks"":[]}</script>
 ]
 
 ---

---FILE: course-materials/slides/u1_d09-import-data/u1_d09-import-data.Rmd---
@@ -342,7 +342,7 @@ sales
 ## vroom vroom!!
 
 .pull-left[
-```{r echo=FALSE, out.width=""80%"", fig.align=""center""}
+```{r echo=FALSE, out.width=""80%""}
 knitr::include_graphics(""img/vroom.png"")
 ```
 ]

---FILE: course-materials/slides/u1_d11-studies-confounding/u1_d11-studies-confounding.Rmd---
@@ -94,7 +94,7 @@ Souce: [Study: Cereal Keeps Girls Slim](https://www.cbsnews.com/news/study-cerea
 
 ## Correlation != causation
 
-```{r echo=FALSE, out.height=""50%"", out.width=""80%"", fig.align=""center""}
+```{r echo=FALSE, out.height=""50%"", out.width=""80%""}
 knitr::include_graphics(""img/xkcdcorrelation.png"")
 ```
 
@@ -106,7 +106,7 @@ Randall Munroe CC BY-NC 2.5 http://xkcd.com/552/
 
 ## Stu!dies and conclusions
 
-```{r echo=FALSE, out.height=""50%"", out.width=""80%"", fig.align=""center""}
+```{r echo=FALSE, out.height=""50%"", out.width=""80%""}
 knitr::include_graphics(""img/random_sample_assign_grid.png"")
 ```
 
@@ -230,7 +230,7 @@ df %>%
 
 --
 
-```{r echo=FALSE, fig.width=3, fig.height=1.25, fig.align=""center""}
+```{r echo=FALSE, out.width = ""80%""}
 ggplot(data = df) +
   geom_point(aes(x = x, y = y), color = ""darkgray"") +
   theme_minimal()
@@ -248,7 +248,7 @@ df %>%
   column_spec(1, bold = T, border_right = T)
 ```
 
-```{r echo=FALSE, fig.width=3, fig.height=1.25, fig.align=""center"", message=FALSE}
+```{r echo=FALSE, message=FALSE, out.width = ""80%""}
 ggplot(data = df) +
   geom_point(aes(x = x, y = y), color = ""darkgray"") +
   geom_smooth(aes(x = x, y = x), color = ""darkgray"") +
@@ -267,7 +267,7 @@ df %>%
   column_spec(1, bold = T, border_right = T)
 ```
 
-```{r echo=FALSE, fig.width=3, fig.height=1.25, fig.align=""center"", message=FALSE}
+```{r echo=FALSE, message=FALSE, out.width = ""80%""}
 ggplot(data = df) +
   geom_point(aes(x = x, y = y, color = z)) +
   geom_smooth(aes(x = x, y = x), method = ""lm"", color = ""darkgray"") +
@@ -286,7 +286,7 @@ df %>%
   column_spec(1, bold = T, border_right = T)
 ```
 
-```{r echo=FALSE, fig.width=3, fig.height=1.25, fig.align=""center"", message=FALSE}
+```{r echo=FALSE, message=FALSE, out.width = ""80%""}
 ggplot(data = df) +
   geom_point(aes(x = x, y = y, color = z)) +
   geom_smooth(aes(x = x, y = x), method = ""lm"", color = ""darkgray"") +
@@ -325,15 +325,6 @@ ucbadmit
 
 ---
 
-## Skim the data
-
-```{r message=FALSE}
-library(skimr)
-skim(ucbadmit) #<<
-```
-
----
-
 ## Overall gender distribution
 
 .question[
@@ -364,7 +355,7 @@ ucbadmit %>%
 
 ## Overall gender distribution
 
-```{r fig.height=2, fig.width=5}
+```{r out.width = ""80%""}
 ggplot(ucbadmit, mapping = aes(x = gender, fill = admit)) +
   geom_bar(position = ""fill"") + 
   labs(y = """", title = ""Admit by gender"")
@@ -419,7 +410,7 @@ ucbadmit %>%
 
 ## Gender distribution, by department
 
-```{r fig.width=8, fig.height=2.75}
+```{r out.width = ""80%""}
 ggplot(ucbadmit, mapping = aes(x = gender, fill = admit)) +
   geom_bar(position = ""fill"") +
   facet_grid(. ~ dept) +
@@ -432,7 +423,7 @@ ggplot(ucbadmit, mapping = aes(x = gender, fill = admit)) +
 ## Gender distribution, by department
 
 .small[
-```{r fig.width=7, fig.height=3}
+```{r}
 ggplot(ucbadmit, mapping = aes(x = gender, fill = admit)) +
   geom_bar(position = ""fill"") +
   scale_y_continuous(labels = percent) +
@@ -445,15 +436,15 @@ ggplot(ucbadmit, mapping = aes(x = gender, fill = admit)) +
 
 ---
 
-```{r echo=FALSE, fig.height=1.5, fig.width=7}
+```{r echo=FALSE, out.width=""55%""}
 ggplot(ucbadmit, mapping = aes(x = gender, fill = admit)) +
   geom_bar(position = ""fill"") +
   labs(x = """", y = """", fill = """", title = ""Admissions by gender"") +
   coord_flip() +
   scale_y_continuous(labels = percent)
 ```
 
-```{r echo=FALSE, fig.height=2.5, fig.width=7}
+```{r echo=FALSE, out.width=""55%""}
 ggplot(ucbadmit, mapping = aes(x = gender, fill = admit)) +
   geom_bar(position = ""fill"") +
   facet_wrap(. ~ dept) +

---FILE: course-materials/slides/u1_d11-studies-confounding/u1_d11-studies-confounding.html---
@@ -309,7 +309,7 @@
 
 --
 
-&lt;img src=""u1_d11-studies-confounding_files/figure-html/unnamed-chunk-7-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d11-studies-confounding_files/figure-html/unnamed-chunk-7-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -342,7 +342,7 @@
 &lt;/tbody&gt;
 &lt;/table&gt;
 
-&lt;img src=""u1_d11-studies-confounding_files/figure-html/unnamed-chunk-9-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d11-studies-confounding_files/figure-html/unnamed-chunk-9-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -386,7 +386,7 @@
 &lt;/tbody&gt;
 &lt;/table&gt;
 
-&lt;img src=""u1_d11-studies-confounding_files/figure-html/unnamed-chunk-11-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d11-studies-confounding_files/figure-html/unnamed-chunk-11-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -430,7 +430,7 @@
 &lt;/tbody&gt;
 &lt;/table&gt;
 
-&lt;img src=""u1_d11-studies-confounding_files/figure-html/unnamed-chunk-13-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d11-studies-confounding_files/figure-html/unnamed-chunk-13-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -473,104 +473,6 @@
 
 ---
 
-## Skim the data
-
-
-```r
-library(skimr)
-*skim(ucbadmit)
-```
-
-
-&lt;table style='width: auto;'
-        class='table table-condensed'&gt;
-&lt;caption&gt;Data summary&lt;/caption&gt;
- &lt;thead&gt;
-  &lt;tr&gt;
-   &lt;th style=""text-align:left;""&gt;   &lt;/th&gt;
-   &lt;th style=""text-align:left;""&gt;   &lt;/th&gt;
-  &lt;/tr&gt;
- &lt;/thead&gt;
-&lt;tbody&gt;
-  &lt;tr&gt;
-   &lt;td style=""text-align:left;""&gt; Name &lt;/td&gt;
-   &lt;td style=""text-align:left;""&gt; ucbadmit &lt;/td&gt;
-  &lt;/tr&gt;
-  &lt;tr&gt;
-   &lt;td style=""text-align:left;""&gt; Number of rows &lt;/td&gt;
-   &lt;td style=""text-align:left;""&gt; 4526 &lt;/td&gt;
-  &lt;/tr&gt;
-  &lt;tr&gt;
-   &lt;td style=""text-align:left;""&gt; Number of columns &lt;/td&gt;
-   &lt;td style=""text-align:left;""&gt; 3 &lt;/td&gt;
-  &lt;/tr&gt;
-  &lt;tr&gt;
-   &lt;td style=""text-align:left;""&gt; _______________________ &lt;/td&gt;
-   &lt;td style=""text-align:left;""&gt;  &lt;/td&gt;
-  &lt;/tr&gt;
-  &lt;tr&gt;
-   &lt;td style=""text-align:left;""&gt; Column type frequency: &lt;/td&gt;
-   &lt;td style=""text-align:left;""&gt;  &lt;/td&gt;
-  &lt;/tr&gt;
-  &lt;tr&gt;
-   &lt;td style=""text-align:left;""&gt; factor &lt;/td&gt;
-   &lt;td style=""text-align:left;""&gt; 3 &lt;/td&gt;
-  &lt;/tr&gt;
-  &lt;tr&gt;
-   &lt;td style=""text-align:left;""&gt; ________________________ &lt;/td&gt;
-   &lt;td style=""text-align:left;""&gt;  &lt;/td&gt;
-  &lt;/tr&gt;
-  &lt;tr&gt;
-   &lt;td style=""text-align:left;""&gt; Group variables &lt;/td&gt;
-   &lt;td style=""text-align:left;""&gt; None &lt;/td&gt;
-  &lt;/tr&gt;
-&lt;/tbody&gt;
-&lt;/table&gt;
-
-
-**Variable type: factor**
-
-&lt;table&gt;
- &lt;thead&gt;
-  &lt;tr&gt;
-   &lt;th style=""text-align:left;""&gt; skim_variable &lt;/th&gt;
-   &lt;th style=""text-align:right;""&gt; n_missing &lt;/th&gt;
-   &lt;th style=""text-align:right;""&gt; complete_rate &lt;/th&gt;
-   &lt;th style=""text-align:left;""&gt; ordered &lt;/th&gt;
-   &lt;th style=""text-align:right;""&gt; n_unique &lt;/th&gt;
-   &lt;th style=""text-align:left;""&gt; top_counts &lt;/th&gt;
-  &lt;/tr&gt;
- &lt;/thead&gt;
-&lt;tbody&gt;
-  &lt;tr&gt;
-   &lt;td style=""text-align:left;""&gt; admit &lt;/td&gt;
-   &lt;td style=""text-align:right;""&gt; 0 &lt;/td&gt;
-   &lt;td style=""text-align:right;""&gt; 1 &lt;/td&gt;
-   &lt;td style=""text-align:left;""&gt; FALSE &lt;/td&gt;
-   &lt;td style=""text-align:right;""&gt; 2 &lt;/td&gt;
-   &lt;td style=""text-align:left;""&gt; Rej: 2771, Adm: 1755 &lt;/td&gt;
-  &lt;/tr&gt;
-  &lt;tr&gt;
-   &lt;td style=""text-align:left;""&gt; gender &lt;/td&gt;
-   &lt;td style=""text-align:right;""&gt; 0 &lt;/td&gt;
-   &lt;td style=""text-align:right;""&gt; 1 &lt;/td&gt;
-   &lt;td style=""text-align:left;""&gt; FALSE &lt;/td&gt;
-   &lt;td style=""text-align:right;""&gt; 2 &lt;/td&gt;
-   &lt;td style=""text-align:left;""&gt; Mal: 2691, Fem: 1835 &lt;/td&gt;
-  &lt;/tr&gt;
-  &lt;tr&gt;
-   &lt;td style=""text-align:left;""&gt; dept &lt;/td&gt;
-   &lt;td style=""text-align:right;""&gt; 0 &lt;/td&gt;
-   &lt;td style=""text-align:right;""&gt; 1 &lt;/td&gt;
-   &lt;td style=""text-align:left;""&gt; TRUE &lt;/td&gt;
-   &lt;td style=""text-align:right;""&gt; 6 &lt;/td&gt;
-   &lt;td style=""text-align:left;""&gt; A: 933, C: 918, D: 792, F: 714 &lt;/td&gt;
-  &lt;/tr&gt;
-&lt;/tbody&gt;
-&lt;/table&gt;
-
----
-
 ## Overall gender distribution
 
 .question[
@@ -631,7 +533,7 @@
   labs(y = """", title = ""Admit by gender"")
 ```
 
-&lt;img src=""u1_d11-studies-confounding_files/figure-html/unnamed-chunk-18-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d11-studies-confounding_files/figure-html/unnamed-chunk-17-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -731,7 +633,7 @@
        title = ""Admit by gender by department"")
 ```
 
-&lt;img src=""u1_d11-studies-confounding_files/figure-html/unnamed-chunk-22-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d11-studies-confounding_files/figure-html/unnamed-chunk-21-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -749,14 +651,14 @@
   theme(legend.position = ""bottom"")
 ```
 
-&lt;img src=""u1_d11-studies-confounding_files/figure-html/unnamed-chunk-23-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d11-studies-confounding_files/figure-html/unnamed-chunk-22-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
 ]
 
 ---
 
-&lt;img src=""u1_d11-studies-confounding_files/figure-html/unnamed-chunk-24-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d11-studies-confounding_files/figure-html/unnamed-chunk-23-1.png"" width=""55%"" style=""display: block; margin: auto;"" /&gt;
 
-&lt;img src=""u1_d11-studies-confounding_files/figure-html/unnamed-chunk-25-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d11-studies-confounding_files/figure-html/unnamed-chunk-24-1.png"" width=""55%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 

---FILE: course-materials/slides/u1_d12-effective-communication/u1_d12-effective-communication.Rmd---
@@ -151,7 +151,7 @@ If the variable names are malformatted, use `janitor::clean_names()`
 fav_food
 ```
 
-```{r message=FALSE}
+```{r message=FALSE, warning=FALSE}
 library(janitor)
 fav_food %>% clean_names()  
 ```
@@ -227,7 +227,7 @@ knitr::include_graphics(""img/central-park-coords.png"")
 ## Make a plot
 
 .small[
-```{r fig.retina=3, fig.height=2, fig.width=5}
+```{r out.width=""80%""}
 ggplot(squirrels, aes(x = long, y = lat)) +
   geom_point(alpha = 0.2)
 ```
@@ -243,7 +243,7 @@ than inside the park.
 ## Try the easy solution first
 
 .small[
-```{r fig.retina=3, fig.height=2, fig.width=5}
+```{r out.width=""80%""}
 squirrels <- squirrels %>%
   separate(hectare, into = c(""NS"", ""EW""), sep = 2, remove = FALSE) %>%
   mutate(where = if_else(NS %in% c(""01"", ""42"") | EW %in% c(""A"", ""I""), ""perimeter"", ""inside"")) 
@@ -257,7 +257,7 @@ ggplot(squirrels, aes(x = long, y = lat, color = where)) +
 
 ## Then go deeper...
 
-```{r echo=FALSE, fig.retina=3, fig.height=2.75, fig.width=5, message=FALSE}
+```{r echo=FALSE, message=FALSE}
 hectare_counts <- squirrels %>%
   group_by(hectare) %>%
   summarise(n = n()) 

---FILE: course-materials/slides/u1_d12-effective-communication/u1_d12-effective-communication.html---
@@ -1,7 +1,7 @@
 <!DOCTYPE html>
 <html lang="""" xml:lang="""">
   <head>
-    <title>Communicating data science results effectively   üóû</title>
+    <title>Communicating data science results effectively   üì∞</title>
     <meta charset=""utf-8"" />
     <script src=""libs/header-attrs/header-attrs.js""></script>
     <link href=""libs/font-awesome/css/all.css"" rel=""stylesheet"" />
@@ -12,7 +12,7 @@
     <textarea id=""source"">
 class: center, middle, inverse, title-slide
 
-# Communicating data science results effectively <br> üóû
+# Communicating data science results effectively <br> üì∞
 ### 
 
 ---
@@ -180,16 +180,6 @@
 fav_food %&gt;% clean_names()  
 ```
 
-```
-## Warning in stringr::str_replace_all(str = string, pattern = replace): partial argument match of
-## 'str' to 'string'
-```
-
-```
-## Warning in stringr::str_replace(str = transliterated_names, pattern = ""\\A[\\h\\s\\p{Punctuation}\
-## \p{Symbol}\\p{Separator}\\p{Other}]*(.*)$"", : partial argument match of 'str' to 'string'
-```
-
 ```
 ## # A tibble: 5 x 4
 ##   student_id full_name        favourite_food     meal_plan          
@@ -233,7 +223,7 @@
 ```
 
 ```
-## [1] 3023   35
+## [1] 3023   38
 ```
 
 ---
@@ -247,22 +237,22 @@
 ```
 
 ```
-## # A tibble: 6 x 35
-##    long   lat unique_squirrel‚Ä¶ hectare shift date       hectare_squirre‚Ä¶ age   primary_fur_col‚Ä¶
-##   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;   &lt;chr&gt; &lt;date&gt;                &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;           
-## 1 -74.0  40.8 13A-PM-1014-04   13A     PM    2018-10-14                4 &lt;NA&gt;  Gray            
-## 2 -74.0  40.8 15F-PM-1010-06   15F     PM    2018-10-10                6 Adult Gray            
-## 3 -74.0  40.8 19C-PM-1018-02   19C     PM    2018-10-18                2 Adult Gray            
-## 4 -74.0  40.8 21B-AM-1019-04   21B     AM    2018-10-19                4 &lt;NA&gt;  &lt;NA&gt;            
-## 5 -74.0  40.8 23A-AM-1018-02   23A     AM    2018-10-18                2 Juve‚Ä¶ Black           
-## 6 -74.0  40.8 38H-PM-1012-01   38H     PM    2018-10-12                1 Adult Gray            
-## # ‚Ä¶ with 26 more variables: highlight_fur_color &lt;chr&gt;,
+## # A tibble: 6 x 38
+##    long   lat unique_squirrel‚Ä¶ hectare NS    EW    shift date       hectare_squirre‚Ä¶ age  
+##   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;date&gt;                &lt;dbl&gt; &lt;chr&gt;
+## 1 -74.0  40.8 13A-PM-1014-04   13A     13    A     PM    2018-10-14                4 &lt;NA&gt; 
+## 2 -74.0  40.8 15F-PM-1010-06   15F     15    F     PM    2018-10-10                6 Adult
+## 3 -74.0  40.8 19C-PM-1018-02   19C     19    C     PM    2018-10-18                2 Adult
+## 4 -74.0  40.8 21B-AM-1019-04   21B     21    B     AM    2018-10-19                4 &lt;NA&gt; 
+## 5 -74.0  40.8 23A-AM-1018-02   23A     23    A     AM    2018-10-18                2 Juve‚Ä¶
+## 6 -74.0  40.8 38H-PM-1012-01   38H     38    H     PM    2018-10-12                1 Adult
+## # ‚Ä¶ with 28 more variables: primary_fur_color &lt;chr&gt;, highlight_fur_color &lt;chr&gt;,
 ## #   combination_of_primary_and_highlight_color &lt;chr&gt;, color_notes &lt;chr&gt;, location &lt;chr&gt;,
 ## #   above_ground_sighter_measurement &lt;chr&gt;, specific_location &lt;chr&gt;, running &lt;lgl&gt;, chasing &lt;lgl&gt;,
 ## #   climbing &lt;lgl&gt;, eating &lt;lgl&gt;, foraging &lt;lgl&gt;, other_activities &lt;chr&gt;, kuks &lt;lgl&gt;, quaas &lt;lgl&gt;,
 ## #   moans &lt;lgl&gt;, tail_flags &lt;lgl&gt;, tail_twitches &lt;lgl&gt;, approaches &lt;lgl&gt;, indifferent &lt;lgl&gt;,
 ## #   runs_from &lt;lgl&gt;, other_interactions &lt;chr&gt;, zip_codes &lt;dbl&gt;, community_districts &lt;dbl&gt;,
-## #   borough_boundaries &lt;dbl&gt;, city_council_districts &lt;dbl&gt;, police_precincts &lt;dbl&gt;
+## #   borough_boundaries &lt;dbl&gt;, city_council_districts &lt;dbl&gt;, police_precincts &lt;dbl&gt;, where &lt;chr&gt;
 ```
 ]
 
@@ -277,22 +267,22 @@
 ```
 
 ```
-## # A tibble: 6 x 35
-##    long   lat unique_squirrel‚Ä¶ hectare shift date       hectare_squirre‚Ä¶ age   primary_fur_col‚Ä¶
-##   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;   &lt;chr&gt; &lt;date&gt;                &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;           
-## 1 -74.0  40.8 6D-PM-1020-01    06D     PM    2018-10-20                1 Adult Gray            
-## 2 -74.0  40.8 21H-PM-1018-01   21H     PM    2018-10-18                1 Juve‚Ä¶ Gray            
-## 3 -74.0  40.8 31D-PM-1006-02   31D     PM    2018-10-06                2 Adult Gray            
-## 4 -74.0  40.8 37B-AM-1018-04   37B     AM    2018-10-18                4 Adult Gray            
-## 5 -74.0  40.8 21C-PM-1006-01   21C     PM    2018-10-06                1 Adult Gray            
-## 6 -74.0  40.8 7G-PM-1018-04    07G     PM    2018-10-18                4 Adult Gray            
-## # ‚Ä¶ with 26 more variables: highlight_fur_color &lt;chr&gt;,
+## # A tibble: 6 x 38
+##    long   lat unique_squirrel‚Ä¶ hectare NS    EW    shift date       hectare_squirre‚Ä¶ age  
+##   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;date&gt;                &lt;dbl&gt; &lt;chr&gt;
+## 1 -74.0  40.8 6D-PM-1020-01    06D     06    D     PM    2018-10-20                1 Adult
+## 2 -74.0  40.8 21H-PM-1018-01   21H     21    H     PM    2018-10-18                1 Juve‚Ä¶
+## 3 -74.0  40.8 31D-PM-1006-02   31D     31    D     PM    2018-10-06                2 Adult
+## 4 -74.0  40.8 37B-AM-1018-04   37B     37    B     AM    2018-10-18                4 Adult
+## 5 -74.0  40.8 21C-PM-1006-01   21C     21    C     PM    2018-10-06                1 Adult
+## 6 -74.0  40.8 7G-PM-1018-04    07G     07    G     PM    2018-10-18                4 Adult
+## # ‚Ä¶ with 28 more variables: primary_fur_color &lt;chr&gt;, highlight_fur_color &lt;chr&gt;,
 ## #   combination_of_primary_and_highlight_color &lt;chr&gt;, color_notes &lt;chr&gt;, location &lt;chr&gt;,
 ## #   above_ground_sighter_measurement &lt;chr&gt;, specific_location &lt;chr&gt;, running &lt;lgl&gt;, chasing &lt;lgl&gt;,
 ## #   climbing &lt;lgl&gt;, eating &lt;lgl&gt;, foraging &lt;lgl&gt;, other_activities &lt;chr&gt;, kuks &lt;lgl&gt;, quaas &lt;lgl&gt;,
 ## #   moans &lt;lgl&gt;, tail_flags &lt;lgl&gt;, tail_twitches &lt;lgl&gt;, approaches &lt;lgl&gt;, indifferent &lt;lgl&gt;,
 ## #   runs_from &lt;lgl&gt;, other_interactions &lt;chr&gt;, zip_codes &lt;dbl&gt;, community_districts &lt;dbl&gt;,
-## #   borough_boundaries &lt;dbl&gt;, city_council_districts &lt;dbl&gt;, police_precincts &lt;dbl&gt;
+## #   borough_boundaries &lt;dbl&gt;, city_council_districts &lt;dbl&gt;, police_precincts &lt;dbl&gt;, where &lt;chr&gt;
 ```
 ]
 
@@ -822,7 +812,7 @@
   geom_point(alpha = 0.2)
 ```
 
-&lt;img src=""u1_d12-effective-communication_files/figure-html/unnamed-chunk-11-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d12-effective-communication_files/figure-html/unnamed-chunk-11-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 ]
 
 --
@@ -845,7 +835,7 @@
   geom_point(alpha = 0.2)
 ```
 
-&lt;img src=""u1_d12-effective-communication_files/figure-html/unnamed-chunk-12-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d12-effective-communication_files/figure-html/unnamed-chunk-12-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 ]
 
 ---

---FILE: course-materials/slides/u1_d13-webscraping/u1_d13-webscraping.Rmd---
@@ -23,7 +23,7 @@ library(rvest)
 library(DT)
 ```
 
-class: center, middle
+class: middle
 
 # Scraping the web
 
@@ -49,7 +49,7 @@ but it's time-consuming and prone to errors
 
 ---
 
-class: center, middle
+class: middle
 
 # Web Scraping with rvest
 
@@ -145,7 +145,7 @@ up with the appropriate CSS selector for your needs
 
 ---
 
-class: center, middle
+class: middle
 
 # Top 250 movies on IMDB
 
@@ -289,7 +289,7 @@ How would you go about creating this visualization: Visualize the average yearly
 --
 
 .small[
-```{r echo=FALSE, fig.retina=3, fig.height=2}
+```{r echo=FALSE, out.width=""90%""}
 imdb_top_250 %>% 
   group_by(year) %>%
   summarise(avg_score = mean(score)) %>%

---FILE: course-materials/slides/u1_d13-webscraping/u1_d13-webscraping.html---
@@ -42,7 +42,7 @@
 
 
 
-class: center, middle
+class: middle
 
 # Scraping the web
 
@@ -68,7 +68,7 @@
 
 ---
 
-class: center, middle
+class: middle
 
 # Web Scraping with rvest
 
@@ -158,7 +158,7 @@
 
 ---
 
-class: center, middle
+class: middle
 
 # Top 250 movies on IMDB
 
@@ -241,8 +241,8 @@
 
 ---
 
-<div id=""htmlwidget-8f836166d559454ecd73"" style=""width:100%;height:400px;"" class=""datatables html-widget""></div>
-<script type=""application/json"" data-for=""htmlwidget-8f836166d559454ecd73"">{""x"":{""filter"":""none"",""data"":[[""1"",""2"",""3"",""4"",""5"",""6"",""7"",""8"",""9"",""10"",""11"",""12"",""13"",""14"",""15"",""16"",""17"",""18"",""19"",""20"",""21"",""22"",""23"",""24"",""25"",""26"",""27"",""28"",""29"",""30"",""31"",""32"",""33"",""34"",""35"",""36"",""37"",""38"",""39"",""40"",""41"",""42"",""43"",""44"",""45"",""46"",""47"",""48"",""49"",""50"",""51"",""52"",""53"",""54"",""55"",""56"",""57"",""58"",""59"",""60"",""61"",""62"",""63"",""64"",""65"",""66"",""67"",""68"",""69"",""70"",""71"",""72"",""73"",""74"",""75"",""76"",""77"",""78"",""79"",""80"",""81"",""82"",""83"",""84"",""85"",""86"",""87"",""88"",""89"",""90"",""91"",""92"",""93"",""94"",""95"",""96"",""97"",""98"",""99"",""100"",""101"",""102"",""103"",""104"",""105"",""106"",""107"",""108"",""109"",""110"",""111"",""112"",""113"",""114"",""115"",""116"",""117"",""118"",""119"",""120"",""121"",""122"",""123"",""124"",""125"",""126"",""127"",""128"",""129"",""130"",""131"",""132"",""133"",""134"",""135"",""136"",""137"",""138"",""139"",""140"",""141"",""142"",""143"",""144"",""145"",""146"",""147"",""148"",""149"",""150"",""151"",""152"",""153"",""154"",""155"",""156"",""157"",""158"",""159"",""160"",""161"",""162"",""163"",""164"",""165"",""166"",""167"",""168"",""169"",""170"",""171"",""172"",""173"",""174"",""175"",""176"",""177"",""178"",""179"",""180"",""181"",""182"",""183"",""184"",""185"",""186"",""187"",""188"",""189"",""190"",""191"",""192"",""193"",""194"",""195"",""196"",""197"",""198"",""199"",""200"",""201"",""202"",""203"",""204"",""205"",""206"",""207"",""208"",""209"",""210"",""211"",""212"",""213"",""214"",""215"",""216"",""217"",""218"",""219"",""220"",""221"",""222"",""223"",""224"",""225"",""226"",""227"",""228"",""229"",""230"",""231"",""232"",""233"",""234"",""235"",""236"",""237"",""238"",""239"",""240"",""241"",""242"",""243"",""244"",""245"",""246"",""247"",""248"",""249"",""250""],[""The Shawshank Redemption"",""The Godfather"",""The Godfather: Part II"",""The Dark Knight"",""12 Angry Men"",""Schindler's List"",""The Lord of the Rings: The Return of the King"",""Pulp Fiction"",""The Good, the Bad and the Ugly"",""The Lord of the Rings: The Fellowship of the Ring"",""Fight Club"",""Forrest Gump"",""Inception"",""Star Wars: Episode V - The Empire Strikes Back"",""The Lord of the Rings: The Two Towers"",""The Matrix"",""Goodfellas"",""One Flew Over the Cuckoo's Nest"",""Seven Samurai"",""Seven"",""Life Is Beautiful"",""City of God"",""The Silence of the Lambs"",""It's a Wonderful Life"",""Star Wars: Episode IV - A New Hope"",""Saving Private Ryan"",""Spirited Away"",""The Green Mile"",""Parasite"",""Interstellar"",""Leon"",""Hamilton"",""The Usual Suspects"",""Harakiri"",""The Lion King"",""Back to the Future"",""The Pianist"",""Terminator 2: Judgment Day"",""American History X"",""Modern Times"",""Psycho"",""Gladiator"",""City Lights"",""The Departed"",""Untouchable"",""Whiplash"",""The Prestige"",""Grave of the Fireflies"",""Once Upon a Time in the West"",""Casablanca"",""Cinema Paradiso"",""Rear Window"",""Alien"",""Apocalypse Now"",""Memento"",""Raiders of the Lost Ark"",""The Great Dictator"",""Joker"",""Django Unchained"",""The Lives of Others"",""Paths of Glory"",""The Shining"",""WALL¬∑E"",""Avengers: Infinity War"",""Sunset Blvd."",""Spider-Man: Into the Spider-Verse"",""Witness for the Prosecution"",""Princess Mononoke"",""Oldboy"",""Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb"",""The Dark Knight Rises"",""Once Upon a Time in America"",""Aliens"",""Avengers: Endgame"",""Your Name."",""Coco"",""American Beauty"",""Braveheart"",""3 Idiots"",""Das Boot"",""Toy Story"",""High and Low"",""Amadeus"",""Taare Zameen Par"",""Star Wars: Episode VI - Return of the Jedi"",""Inglourious Basterds"",""Reservoir Dogs"",""Good Will Hunting"",""Capernaum"",""2001: A Space Odyssey"",""Requiem for a Dream"",""Vertigo"",""M"",""Dangal"",""1917"",""Eternal Sunshine of the Spotless Mind"",""The Hunt"",""Citizen Kane"",""Full Metal Jacket"",""Bicycle Thieves"",""The Kid"",""A Clockwork Orange"",""North by Northwest"",""Singin' in the Rain"",""Snatch"",""Scarface"",""Taxi Driver"",""Ikiru"",""Lawrence of Arabia"",""Am√©lie"",""Toy Story 3"",""The Sting"",""Metropolis"",""A Separation"",""For a Few Dollars More"",""Incendies"",""The Apartment"",""Double Indemnity"",""Come and See"",""To Kill a Mockingbird"",""Indiana Jones and the Last Crusade"",""Up"",""L.A. Confidential"",""Heat"",""Monty Python and the Holy Grail"",""Die Hard"",""Rashomon"",""Yojimbo"",""Batman Begins"",""Green Book"",""Downfall"",""Children of Heaven"",""Anand"",""Unforgiven"",""Some Like It Hot"",""Ran"",""Howl's Moving Castle"",""A Beautiful Mind"",""All About Eve"",""The Great Escape"",""Casino"",""Pan's Labyrinth"",""The Wolf of Wall Street"",""The Secret in Their Eyes"",""Lock, Stock and Two Smoking Barrels"",""My Neighbour Totoro"",""Raging Bull"",""There Will Be Blood"",""Judgment at Nuremberg"",""The Treasure of the Sierra Madre"",""Three Billboards Outside Ebbing, Missouri"",""Babam ve Oglum"",""Dial M for Murder"",""The Gold Rush"",""Chinatown"",""Shutter Island"",""V for Vendetta"",""No Country for Old Men"",""The Seventh Seal"",""Inside Out"",""Warrior"",""The Elephant Man"",""Trainspotting"",""The Sixth Sense"",""The Thing"",""Jurassic Park"",""Gone with the Wind"",""Wild Strawberries"",""Blade Runner"",""Finding Nemo"",""The Truman Show"",""Room"",""The Bridge on the River Kwai"",""Stalker"",""Kill Bill: Vol. 1"",""Fargo"",""Tokyo Story"",""The Third Man"",""On the Waterfront"",""Memories of Murder"",""Gran Torino"",""The Deer Hunter"",""Wild Tales"",""Klaus"",""Andhadhun"",""In the Name of the Father"",""Mary and Max"",""Gone Girl"",""Hacksaw Ridge"",""The Grand Budapest Hotel"",""The Big Lebowski"",""Before Sunrise"",""Catch Me If You Can"",""The Bandit"",""Persona"",""Le Mans '66"",""To Be or Not to Be"",""Prisoners"",""The General"",""How to Train Your Dragon"",""Sherlock Jr."",""Mr. Smith Goes to Washington"",""12 Years a Slave"",""Barry Lyndon"",""Mad Max: Fury Road"",""Network"",""Stand by Me"",""Million Dollar Baby"",""Cool Hand Luke"",""Ben-Hur"",""Hachi: A Dog's Tale"",""Into the Wild"",""Dead Poets Society"",""The Wages of Fear"",""Platoon"",""Harry Potter and the Deathly Hallows: Part 2"",""Monty Python's Life of Brian"",""Logan"",""Rush"",""Rififi"",""The Handmaiden"",""The 400 Blows"",""The Passion of Joan of Arc"",""Hotel Rwanda"",""Andrei Rublev"",""Spotlight"",""Amores Perros"",""Nausica√§ of the Valley of the Wind"",""Rang De Basanti"",""La Haine"",""Rocky"",""Gangs of Wasseypur"",""Monsters, Inc."",""Rebecca"",""Portrait of a Lady on Fire"",""Before Sunset"",""It Happened One Night"",""In the Mood for Love"",""The Circus"",""Drishyam"",""Paris, Texas"",""The Invisible Guest"",""The Help"",""The Princess Bride"",""The Battle of Algiers"",""The Terminator"",""Neon Genesis Evangelion: The End of Evangelion"",""Three Colours: Red"",""A Wednesday"",""A Silent Voice""],[1994,1972,1974,2008,1957,1993,2003,1994,1966,2001,1999,1994,2010,1980,2002,1999,1990,1975,1954,1995,1997,2002,1991,1946,1977,1998,2001,1999,2019,2014,1994,2020,1995,1962,1994,1985,2002,1991,1998,1936,1960,2000,1931,2006,2011,2014,2006,1988,1968,1942,1988,1954,1979,1979,2000,1981,1940,2019,2012,2006,1957,1980,2008,2018,1950,2018,1957,1997,2003,1964,2012,1984,1986,2019,2016,2017,1999,1995,2009,1981,1995,1963,1984,2007,1983,2009,1992,1997,2018,1968,2000,1958,1931,2016,2019,2004,2012,1941,1987,1948,1921,1971,1959,1952,2000,1983,1976,1952,1962,2001,2010,1973,1927,2011,1965,2010,1960,1944,1985,1962,1989,2009,1997,1995,1975,1988,1950,1961,2005,2018,2004,1997,1971,1992,1959,1985,2004,2001,1950,1963,1995,2006,2013,2009,1998,1988,1980,2007,1961,1948,2017,2005,1954,1925,1974,2010,2005,2007,1957,2015,2011,1980,1996,1999,1982,1993,1939,1957,1982,2003,1998,2015,1957,1979,2003,1996,1953,1949,1954,2003,2008,1978,2014,2019,2018,1993,2009,2014,2016,2014,1998,1995,2002,1996,1966,2019,1942,2013,1926,2010,1924,1939,2013,1975,2015,1976,1986,2004,1967,1959,2009,2007,1989,1953,1986,2011,1979,2017,2013,1955,2016,1959,1928,2004,1966,2015,2000,1984,2006,1995,1976,2012,2001,1940,2019,2004,1934,2000,1928,2015,1984,2016,2011,1987,1966,1984,1997,1994,2008,2016],[9.2,9.1,9,9,8.9,8.9,8.9,8.8,8.8,8.8,8.8,8.8,8.7,8.7,8.7,8.6,8.6,8.6,8.6,8.6,8.6,8.6,8.6,8.6,8.6,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8]],""container"":""<table class=\""display\"">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>title<\/th>\n      <th>year<\/th>\n      <th>score<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>"",""options"":{""columnDefs"":[{""className"":""dt-right"",""targets"":[2,3]},{""orderable"":false,""targets"":0}],""order"":[],""autoWidth"":false,""orderClasses"":false}},""evals"":[],""jsHooks"":[]}</script>
+<div id=""htmlwidget-1b4ff99564eb6e8884a5"" style=""width:100%;height:400px;"" class=""datatables html-widget""></div>
+<script type=""application/json"" data-for=""htmlwidget-1b4ff99564eb6e8884a5"">{""x"":{""filter"":""none"",""data"":[[""1"",""2"",""3"",""4"",""5"",""6"",""7"",""8"",""9"",""10"",""11"",""12"",""13"",""14"",""15"",""16"",""17"",""18"",""19"",""20"",""21"",""22"",""23"",""24"",""25"",""26"",""27"",""28"",""29"",""30"",""31"",""32"",""33"",""34"",""35"",""36"",""37"",""38"",""39"",""40"",""41"",""42"",""43"",""44"",""45"",""46"",""47"",""48"",""49"",""50"",""51"",""52"",""53"",""54"",""55"",""56"",""57"",""58"",""59"",""60"",""61"",""62"",""63"",""64"",""65"",""66"",""67"",""68"",""69"",""70"",""71"",""72"",""73"",""74"",""75"",""76"",""77"",""78"",""79"",""80"",""81"",""82"",""83"",""84"",""85"",""86"",""87"",""88"",""89"",""90"",""91"",""92"",""93"",""94"",""95"",""96"",""97"",""98"",""99"",""100"",""101"",""102"",""103"",""104"",""105"",""106"",""107"",""108"",""109"",""110"",""111"",""112"",""113"",""114"",""115"",""116"",""117"",""118"",""119"",""120"",""121"",""122"",""123"",""124"",""125"",""126"",""127"",""128"",""129"",""130"",""131"",""132"",""133"",""134"",""135"",""136"",""137"",""138"",""139"",""140"",""141"",""142"",""143"",""144"",""145"",""146"",""147"",""148"",""149"",""150"",""151"",""152"",""153"",""154"",""155"",""156"",""157"",""158"",""159"",""160"",""161"",""162"",""163"",""164"",""165"",""166"",""167"",""168"",""169"",""170"",""171"",""172"",""173"",""174"",""175"",""176"",""177"",""178"",""179"",""180"",""181"",""182"",""183"",""184"",""185"",""186"",""187"",""188"",""189"",""190"",""191"",""192"",""193"",""194"",""195"",""196"",""197"",""198"",""199"",""200"",""201"",""202"",""203"",""204"",""205"",""206"",""207"",""208"",""209"",""210"",""211"",""212"",""213"",""214"",""215"",""216"",""217"",""218"",""219"",""220"",""221"",""222"",""223"",""224"",""225"",""226"",""227"",""228"",""229"",""230"",""231"",""232"",""233"",""234"",""235"",""236"",""237"",""238"",""239"",""240"",""241"",""242"",""243"",""244"",""245"",""246"",""247"",""248"",""249"",""250""],[""The Shawshank Redemption"",""The Godfather"",""The Godfather: Part II"",""The Dark Knight"",""12 Angry Men"",""Schindler's List"",""The Lord of the Rings: The Return of the King"",""Pulp Fiction"",""The Good, the Bad and the Ugly"",""The Lord of the Rings: The Fellowship of the Ring"",""Fight Club"",""Forrest Gump"",""Inception"",""Star Wars: Episode V - The Empire Strikes Back"",""The Lord of the Rings: The Two Towers"",""The Matrix"",""Goodfellas"",""One Flew Over the Cuckoo's Nest"",""Seven Samurai"",""Seven"",""Life Is Beautiful"",""City of God"",""The Silence of the Lambs"",""It's a Wonderful Life"",""Star Wars: Episode IV - A New Hope"",""Saving Private Ryan"",""Spirited Away"",""The Green Mile"",""Parasite"",""Interstellar"",""Leon"",""Hamilton"",""The Usual Suspects"",""Harakiri"",""The Lion King"",""Back to the Future"",""The Pianist"",""Terminator 2: Judgment Day"",""American History X"",""Modern Times"",""Psycho"",""Gladiator"",""City Lights"",""The Departed"",""Untouchable"",""Whiplash"",""The Prestige"",""Grave of the Fireflies"",""Once Upon a Time in the West"",""Casablanca"",""Cinema Paradiso"",""Rear Window"",""Alien"",""Apocalypse Now"",""Memento"",""Raiders of the Lost Ark"",""The Great Dictator"",""Joker"",""Django Unchained"",""The Lives of Others"",""Paths of Glory"",""The Shining"",""WALL¬∑E"",""Avengers: Infinity War"",""Sunset Blvd."",""Spider-Man: Into the Spider-Verse"",""Witness for the Prosecution"",""Princess Mononoke"",""Oldboy"",""Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb"",""The Dark Knight Rises"",""Once Upon a Time in America"",""Aliens"",""Avengers: Endgame"",""Your Name."",""Coco"",""American Beauty"",""Braveheart"",""3 Idiots"",""Das Boot"",""Toy Story"",""High and Low"",""Amadeus"",""Taare Zameen Par"",""Star Wars: Episode VI - Return of the Jedi"",""Inglourious Basterds"",""Reservoir Dogs"",""Good Will Hunting"",""Capernaum"",""2001: A Space Odyssey"",""Requiem for a Dream"",""Vertigo"",""M"",""Dangal"",""1917"",""Eternal Sunshine of the Spotless Mind"",""The Hunt"",""Citizen Kane"",""Full Metal Jacket"",""Bicycle Thieves"",""The Kid"",""A Clockwork Orange"",""North by Northwest"",""Singin' in the Rain"",""Snatch"",""Scarface"",""Taxi Driver"",""Ikiru"",""Lawrence of Arabia"",""Am√©lie"",""Toy Story 3"",""The Sting"",""Metropolis"",""A Separation"",""For a Few Dollars More"",""Incendies"",""The Apartment"",""Double Indemnity"",""Come and See"",""To Kill a Mockingbird"",""Indiana Jones and the Last Crusade"",""Up"",""L.A. Confidential"",""Heat"",""Monty Python and the Holy Grail"",""Die Hard"",""Rashomon"",""Yojimbo"",""Batman Begins"",""Green Book"",""Downfall"",""Children of Heaven"",""Anand"",""Unforgiven"",""Some Like It Hot"",""Ran"",""Howl's Moving Castle"",""A Beautiful Mind"",""All About Eve"",""The Great Escape"",""Casino"",""Pan's Labyrinth"",""The Wolf of Wall Street"",""The Secret in Their Eyes"",""Lock, Stock and Two Smoking Barrels"",""My Neighbour Totoro"",""Raging Bull"",""There Will Be Blood"",""Judgment at Nuremberg"",""The Treasure of the Sierra Madre"",""Three Billboards Outside Ebbing, Missouri"",""Babam ve Oglum"",""Dial M for Murder"",""The Gold Rush"",""Chinatown"",""Shutter Island"",""V for Vendetta"",""No Country for Old Men"",""The Seventh Seal"",""Inside Out"",""Warrior"",""The Elephant Man"",""Trainspotting"",""The Sixth Sense"",""The Thing"",""Jurassic Park"",""Gone with the Wind"",""Wild Strawberries"",""Blade Runner"",""Finding Nemo"",""The Truman Show"",""Room"",""The Bridge on the River Kwai"",""Stalker"",""Kill Bill: Vol. 1"",""Fargo"",""Tokyo Story"",""The Third Man"",""On the Waterfront"",""Memories of Murder"",""Gran Torino"",""The Deer Hunter"",""Wild Tales"",""Klaus"",""Andhadhun"",""In the Name of the Father"",""Mary and Max"",""Gone Girl"",""Hacksaw Ridge"",""The Grand Budapest Hotel"",""The Big Lebowski"",""Before Sunrise"",""Catch Me If You Can"",""The Bandit"",""Persona"",""Le Mans '66"",""To Be or Not to Be"",""Prisoners"",""The General"",""How to Train Your Dragon"",""Sherlock Jr."",""Mr. Smith Goes to Washington"",""12 Years a Slave"",""Barry Lyndon"",""Mad Max: Fury Road"",""Network"",""Stand by Me"",""Million Dollar Baby"",""Cool Hand Luke"",""Ben-Hur"",""Hachi: A Dog's Tale"",""Into the Wild"",""Dead Poets Society"",""The Wages of Fear"",""Platoon"",""Harry Potter and the Deathly Hallows: Part 2"",""Monty Python's Life of Brian"",""Logan"",""Rush"",""Rififi"",""The Handmaiden"",""The 400 Blows"",""The Passion of Joan of Arc"",""Hotel Rwanda"",""Andrei Rublev"",""Spotlight"",""Amores Perros"",""Nausica√§ of the Valley of the Wind"",""Rang De Basanti"",""La Haine"",""Rocky"",""Gangs of Wasseypur"",""Monsters, Inc."",""Rebecca"",""Portrait of a Lady on Fire"",""Before Sunset"",""It Happened One Night"",""In the Mood for Love"",""The Circus"",""Drishyam"",""Paris, Texas"",""The Invisible Guest"",""The Help"",""The Princess Bride"",""The Battle of Algiers"",""The Terminator"",""Neon Genesis Evangelion: The End of Evangelion"",""Three Colours: Red"",""A Wednesday"",""A Silent Voice""],[1994,1972,1974,2008,1957,1993,2003,1994,1966,2001,1999,1994,2010,1980,2002,1999,1990,1975,1954,1995,1997,2002,1991,1946,1977,1998,2001,1999,2019,2014,1994,2020,1995,1962,1994,1985,2002,1991,1998,1936,1960,2000,1931,2006,2011,2014,2006,1988,1968,1942,1988,1954,1979,1979,2000,1981,1940,2019,2012,2006,1957,1980,2008,2018,1950,2018,1957,1997,2003,1964,2012,1984,1986,2019,2016,2017,1999,1995,2009,1981,1995,1963,1984,2007,1983,2009,1992,1997,2018,1968,2000,1958,1931,2016,2019,2004,2012,1941,1987,1948,1921,1971,1959,1952,2000,1983,1976,1952,1962,2001,2010,1973,1927,2011,1965,2010,1960,1944,1985,1962,1989,2009,1997,1995,1975,1988,1950,1961,2005,2018,2004,1997,1971,1992,1959,1985,2004,2001,1950,1963,1995,2006,2013,2009,1998,1988,1980,2007,1961,1948,2017,2005,1954,1925,1974,2010,2005,2007,1957,2015,2011,1980,1996,1999,1982,1993,1939,1957,1982,2003,1998,2015,1957,1979,2003,1996,1953,1949,1954,2003,2008,1978,2014,2019,2018,1993,2009,2014,2016,2014,1998,1995,2002,1996,1966,2019,1942,2013,1926,2010,1924,1939,2013,1975,2015,1976,1986,2004,1967,1959,2009,2007,1989,1953,1986,2011,1979,2017,2013,1955,2016,1959,1928,2004,1966,2015,2000,1984,2006,1995,1976,2012,2001,1940,2019,2004,1934,2000,1928,2015,1984,2016,2011,1987,1966,1984,1997,1994,2008,2016],[9.2,9.1,9,9,8.9,8.9,8.9,8.8,8.8,8.8,8.8,8.8,8.7,8.7,8.7,8.6,8.6,8.6,8.6,8.6,8.6,8.6,8.6,8.6,8.6,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8]],""container"":""<table class=\""display\"">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>title<\/th>\n      <th>year<\/th>\n      <th>score<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>"",""options"":{""columnDefs"":[{""className"":""dt-right"",""targets"":[2,3]},{""orderable"":false,""targets"":0}],""order"":[],""autoWidth"":false,""orderClasses"":false}},""evals"":[],""jsHooks"":[]}</script>
 
 ---
 
@@ -274,8 +274,8 @@
 
 ---
 
-<div id=""htmlwidget-0d7db73d03839427d3b7"" style=""width:100%;height:400px;"" class=""datatables html-widget""></div>
-<script type=""application/json"" data-for=""htmlwidget-0d7db73d03839427d3b7"">{""x"":{""filter"":""none"",""data"":[[""1"",""2"",""3"",""4"",""5"",""6"",""7"",""8"",""9"",""10"",""11"",""12"",""13"",""14"",""15"",""16"",""17"",""18"",""19"",""20"",""21"",""22"",""23"",""24"",""25"",""26"",""27"",""28"",""29"",""30"",""31"",""32"",""33"",""34"",""35"",""36"",""37"",""38"",""39"",""40"",""41"",""42"",""43"",""44"",""45"",""46"",""47"",""48"",""49"",""50"",""51"",""52"",""53"",""54"",""55"",""56"",""57"",""58"",""59"",""60"",""61"",""62"",""63"",""64"",""65"",""66"",""67"",""68"",""69"",""70"",""71"",""72"",""73"",""74"",""75"",""76"",""77"",""78"",""79"",""80"",""81"",""82"",""83"",""84"",""85"",""86"",""87"",""88"",""89"",""90"",""91"",""92"",""93"",""94"",""95"",""96"",""97"",""98"",""99"",""100"",""101"",""102"",""103"",""104"",""105"",""106"",""107"",""108"",""109"",""110"",""111"",""112"",""113"",""114"",""115"",""116"",""117"",""118"",""119"",""120"",""121"",""122"",""123"",""124"",""125"",""126"",""127"",""128"",""129"",""130"",""131"",""132"",""133"",""134"",""135"",""136"",""137"",""138"",""139"",""140"",""141"",""142"",""143"",""144"",""145"",""146"",""147"",""148"",""149"",""150"",""151"",""152"",""153"",""154"",""155"",""156"",""157"",""158"",""159"",""160"",""161"",""162"",""163"",""164"",""165"",""166"",""167"",""168"",""169"",""170"",""171"",""172"",""173"",""174"",""175"",""176"",""177"",""178"",""179"",""180"",""181"",""182"",""183"",""184"",""185"",""186"",""187"",""188"",""189"",""190"",""191"",""192"",""193"",""194"",""195"",""196"",""197"",""198"",""199"",""200"",""201"",""202"",""203"",""204"",""205"",""206"",""207"",""208"",""209"",""210"",""211"",""212"",""213"",""214"",""215"",""216"",""217"",""218"",""219"",""220"",""221"",""222"",""223"",""224"",""225"",""226"",""227"",""228"",""229"",""230"",""231"",""232"",""233"",""234"",""235"",""236"",""237"",""238"",""239"",""240"",""241"",""242"",""243"",""244"",""245"",""246"",""247"",""248"",""249"",""250""],[""The Shawshank Redemption"",""The Godfather"",""The Godfather: Part II"",""The Dark Knight"",""12 Angry Men"",""Schindler's List"",""The Lord of the Rings: The Return of the King"",""Pulp Fiction"",""The Good, the Bad and the Ugly"",""The Lord of the Rings: The Fellowship of the Ring"",""Fight Club"",""Forrest Gump"",""Inception"",""Star Wars: Episode V - The Empire Strikes Back"",""The Lord of the Rings: The Two Towers"",""The Matrix"",""Goodfellas"",""One Flew Over the Cuckoo's Nest"",""Seven Samurai"",""Seven"",""Life Is Beautiful"",""City of God"",""The Silence of the Lambs"",""It's a Wonderful Life"",""Star Wars: Episode IV - A New Hope"",""Saving Private Ryan"",""Spirited Away"",""The Green Mile"",""Parasite"",""Interstellar"",""Leon"",""Hamilton"",""The Usual Suspects"",""Harakiri"",""The Lion King"",""Back to the Future"",""The Pianist"",""Terminator 2: Judgment Day"",""American History X"",""Modern Times"",""Psycho"",""Gladiator"",""City Lights"",""The Departed"",""Untouchable"",""Whiplash"",""The Prestige"",""Grave of the Fireflies"",""Once Upon a Time in the West"",""Casablanca"",""Cinema Paradiso"",""Rear Window"",""Alien"",""Apocalypse Now"",""Memento"",""Raiders of the Lost Ark"",""The Great Dictator"",""Joker"",""Django Unchained"",""The Lives of Others"",""Paths of Glory"",""The Shining"",""WALL¬∑E"",""Avengers: Infinity War"",""Sunset Blvd."",""Spider-Man: Into the Spider-Verse"",""Witness for the Prosecution"",""Princess Mononoke"",""Oldboy"",""Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb"",""The Dark Knight Rises"",""Once Upon a Time in America"",""Aliens"",""Avengers: Endgame"",""Your Name."",""Coco"",""American Beauty"",""Braveheart"",""3 Idiots"",""Das Boot"",""Toy Story"",""High and Low"",""Amadeus"",""Taare Zameen Par"",""Star Wars: Episode VI - Return of the Jedi"",""Inglourious Basterds"",""Reservoir Dogs"",""Good Will Hunting"",""Capernaum"",""2001: A Space Odyssey"",""Requiem for a Dream"",""Vertigo"",""M"",""Dangal"",""1917"",""Eternal Sunshine of the Spotless Mind"",""The Hunt"",""Citizen Kane"",""Full Metal Jacket"",""Bicycle Thieves"",""The Kid"",""A Clockwork Orange"",""North by Northwest"",""Singin' in the Rain"",""Snatch"",""Scarface"",""Taxi Driver"",""Ikiru"",""Lawrence of Arabia"",""Am√©lie"",""Toy Story 3"",""The Sting"",""Metropolis"",""A Separation"",""For a Few Dollars More"",""Incendies"",""The Apartment"",""Double Indemnity"",""Come and See"",""To Kill a Mockingbird"",""Indiana Jones and the Last Crusade"",""Up"",""L.A. Confidential"",""Heat"",""Monty Python and the Holy Grail"",""Die Hard"",""Rashomon"",""Yojimbo"",""Batman Begins"",""Green Book"",""Downfall"",""Children of Heaven"",""Anand"",""Unforgiven"",""Some Like It Hot"",""Ran"",""Howl's Moving Castle"",""A Beautiful Mind"",""All About Eve"",""The Great Escape"",""Casino"",""Pan's Labyrinth"",""The Wolf of Wall Street"",""The Secret in Their Eyes"",""Lock, Stock and Two Smoking Barrels"",""My Neighbour Totoro"",""Raging Bull"",""There Will Be Blood"",""Judgment at Nuremberg"",""The Treasure of the Sierra Madre"",""Three Billboards Outside Ebbing, Missouri"",""Babam ve Oglum"",""Dial M for Murder"",""The Gold Rush"",""Chinatown"",""Shutter Island"",""V for Vendetta"",""No Country for Old Men"",""The Seventh Seal"",""Inside Out"",""Warrior"",""The Elephant Man"",""Trainspotting"",""The Sixth Sense"",""The Thing"",""Jurassic Park"",""Gone with the Wind"",""Wild Strawberries"",""Blade Runner"",""Finding Nemo"",""The Truman Show"",""Room"",""The Bridge on the River Kwai"",""Stalker"",""Kill Bill: Vol. 1"",""Fargo"",""Tokyo Story"",""The Third Man"",""On the Waterfront"",""Memories of Murder"",""Gran Torino"",""The Deer Hunter"",""Wild Tales"",""Klaus"",""Andhadhun"",""In the Name of the Father"",""Mary and Max"",""Gone Girl"",""Hacksaw Ridge"",""The Grand Budapest Hotel"",""The Big Lebowski"",""Before Sunrise"",""Catch Me If You Can"",""The Bandit"",""Persona"",""Le Mans '66"",""To Be or Not to Be"",""Prisoners"",""The General"",""How to Train Your Dragon"",""Sherlock Jr."",""Mr. Smith Goes to Washington"",""12 Years a Slave"",""Barry Lyndon"",""Mad Max: Fury Road"",""Network"",""Stand by Me"",""Million Dollar Baby"",""Cool Hand Luke"",""Ben-Hur"",""Hachi: A Dog's Tale"",""Into the Wild"",""Dead Poets Society"",""The Wages of Fear"",""Platoon"",""Harry Potter and the Deathly Hallows: Part 2"",""Monty Python's Life of Brian"",""Logan"",""Rush"",""Rififi"",""The Handmaiden"",""The 400 Blows"",""The Passion of Joan of Arc"",""Hotel Rwanda"",""Andrei Rublev"",""Spotlight"",""Amores Perros"",""Nausica√§ of the Valley of the Wind"",""Rang De Basanti"",""La Haine"",""Rocky"",""Gangs of Wasseypur"",""Monsters, Inc."",""Rebecca"",""Portrait of a Lady on Fire"",""Before Sunset"",""It Happened One Night"",""In the Mood for Love"",""The Circus"",""Drishyam"",""Paris, Texas"",""The Invisible Guest"",""The Help"",""The Princess Bride"",""The Battle of Algiers"",""The Terminator"",""Neon Genesis Evangelion: The End of Evangelion"",""Three Colours: Red"",""A Wednesday"",""A Silent Voice""],[1994,1972,1974,2008,1957,1993,2003,1994,1966,2001,1999,1994,2010,1980,2002,1999,1990,1975,1954,1995,1997,2002,1991,1946,1977,1998,2001,1999,2019,2014,1994,2020,1995,1962,1994,1985,2002,1991,1998,1936,1960,2000,1931,2006,2011,2014,2006,1988,1968,1942,1988,1954,1979,1979,2000,1981,1940,2019,2012,2006,1957,1980,2008,2018,1950,2018,1957,1997,2003,1964,2012,1984,1986,2019,2016,2017,1999,1995,2009,1981,1995,1963,1984,2007,1983,2009,1992,1997,2018,1968,2000,1958,1931,2016,2019,2004,2012,1941,1987,1948,1921,1971,1959,1952,2000,1983,1976,1952,1962,2001,2010,1973,1927,2011,1965,2010,1960,1944,1985,1962,1989,2009,1997,1995,1975,1988,1950,1961,2005,2018,2004,1997,1971,1992,1959,1985,2004,2001,1950,1963,1995,2006,2013,2009,1998,1988,1980,2007,1961,1948,2017,2005,1954,1925,1974,2010,2005,2007,1957,2015,2011,1980,1996,1999,1982,1993,1939,1957,1982,2003,1998,2015,1957,1979,2003,1996,1953,1949,1954,2003,2008,1978,2014,2019,2018,1993,2009,2014,2016,2014,1998,1995,2002,1996,1966,2019,1942,2013,1926,2010,1924,1939,2013,1975,2015,1976,1986,2004,1967,1959,2009,2007,1989,1953,1986,2011,1979,2017,2013,1955,2016,1959,1928,2004,1966,2015,2000,1984,2006,1995,1976,2012,2001,1940,2019,2004,1934,2000,1928,2015,1984,2016,2011,1987,1966,1984,1997,1994,2008,2016],[9.2,9.1,9,9,8.9,8.9,8.9,8.8,8.8,8.8,8.8,8.8,8.7,8.7,8.7,8.6,8.6,8.6,8.6,8.6,8.6,8.6,8.6,8.6,8.6,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250]],""container"":""<table class=\""display\"">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>title<\/th>\n      <th>year<\/th>\n      <th>score<\/th>\n      <th>rank<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>"",""options"":{""dom"":""p"",""pageLength"":8,""columnDefs"":[{""className"":""dt-right"",""targets"":[2,3,4]},{""orderable"":false,""targets"":0}],""order"":[],""autoWidth"":false,""orderClasses"":false,""lengthMenu"":[8,10,25,50,100]}},""evals"":[],""jsHooks"":[]}</script>
+<div id=""htmlwidget-8f836166d559454ecd73"" style=""width:100%;height:400px;"" class=""datatables html-widget""></div>
+<script type=""application/json"" data-for=""htmlwidget-8f836166d559454ecd73"">{""x"":{""filter"":""none"",""data"":[[""1"",""2"",""3"",""4"",""5"",""6"",""7"",""8"",""9"",""10"",""11"",""12"",""13"",""14"",""15"",""16"",""17"",""18"",""19"",""20"",""21"",""22"",""23"",""24"",""25"",""26"",""27"",""28"",""29"",""30"",""31"",""32"",""33"",""34"",""35"",""36"",""37"",""38"",""39"",""40"",""41"",""42"",""43"",""44"",""45"",""46"",""47"",""48"",""49"",""50"",""51"",""52"",""53"",""54"",""55"",""56"",""57"",""58"",""59"",""60"",""61"",""62"",""63"",""64"",""65"",""66"",""67"",""68"",""69"",""70"",""71"",""72"",""73"",""74"",""75"",""76"",""77"",""78"",""79"",""80"",""81"",""82"",""83"",""84"",""85"",""86"",""87"",""88"",""89"",""90"",""91"",""92"",""93"",""94"",""95"",""96"",""97"",""98"",""99"",""100"",""101"",""102"",""103"",""104"",""105"",""106"",""107"",""108"",""109"",""110"",""111"",""112"",""113"",""114"",""115"",""116"",""117"",""118"",""119"",""120"",""121"",""122"",""123"",""124"",""125"",""126"",""127"",""128"",""129"",""130"",""131"",""132"",""133"",""134"",""135"",""136"",""137"",""138"",""139"",""140"",""141"",""142"",""143"",""144"",""145"",""146"",""147"",""148"",""149"",""150"",""151"",""152"",""153"",""154"",""155"",""156"",""157"",""158"",""159"",""160"",""161"",""162"",""163"",""164"",""165"",""166"",""167"",""168"",""169"",""170"",""171"",""172"",""173"",""174"",""175"",""176"",""177"",""178"",""179"",""180"",""181"",""182"",""183"",""184"",""185"",""186"",""187"",""188"",""189"",""190"",""191"",""192"",""193"",""194"",""195"",""196"",""197"",""198"",""199"",""200"",""201"",""202"",""203"",""204"",""205"",""206"",""207"",""208"",""209"",""210"",""211"",""212"",""213"",""214"",""215"",""216"",""217"",""218"",""219"",""220"",""221"",""222"",""223"",""224"",""225"",""226"",""227"",""228"",""229"",""230"",""231"",""232"",""233"",""234"",""235"",""236"",""237"",""238"",""239"",""240"",""241"",""242"",""243"",""244"",""245"",""246"",""247"",""248"",""249"",""250""],[""The Shawshank Redemption"",""The Godfather"",""The Godfather: Part II"",""The Dark Knight"",""12 Angry Men"",""Schindler's List"",""The Lord of the Rings: The Return of the King"",""Pulp Fiction"",""The Good, the Bad and the Ugly"",""The Lord of the Rings: The Fellowship of the Ring"",""Fight Club"",""Forrest Gump"",""Inception"",""Star Wars: Episode V - The Empire Strikes Back"",""The Lord of the Rings: The Two Towers"",""The Matrix"",""Goodfellas"",""One Flew Over the Cuckoo's Nest"",""Seven Samurai"",""Seven"",""Life Is Beautiful"",""City of God"",""The Silence of the Lambs"",""It's a Wonderful Life"",""Star Wars: Episode IV - A New Hope"",""Saving Private Ryan"",""Spirited Away"",""The Green Mile"",""Parasite"",""Interstellar"",""Leon"",""Hamilton"",""The Usual Suspects"",""Harakiri"",""The Lion King"",""Back to the Future"",""The Pianist"",""Terminator 2: Judgment Day"",""American History X"",""Modern Times"",""Psycho"",""Gladiator"",""City Lights"",""The Departed"",""Untouchable"",""Whiplash"",""The Prestige"",""Grave of the Fireflies"",""Once Upon a Time in the West"",""Casablanca"",""Cinema Paradiso"",""Rear Window"",""Alien"",""Apocalypse Now"",""Memento"",""Raiders of the Lost Ark"",""The Great Dictator"",""Joker"",""Django Unchained"",""The Lives of Others"",""Paths of Glory"",""The Shining"",""WALL¬∑E"",""Avengers: Infinity War"",""Sunset Blvd."",""Spider-Man: Into the Spider-Verse"",""Witness for the Prosecution"",""Princess Mononoke"",""Oldboy"",""Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb"",""The Dark Knight Rises"",""Once Upon a Time in America"",""Aliens"",""Avengers: Endgame"",""Your Name."",""Coco"",""American Beauty"",""Braveheart"",""3 Idiots"",""Das Boot"",""Toy Story"",""High and Low"",""Amadeus"",""Taare Zameen Par"",""Star Wars: Episode VI - Return of the Jedi"",""Inglourious Basterds"",""Reservoir Dogs"",""Good Will Hunting"",""Capernaum"",""2001: A Space Odyssey"",""Requiem for a Dream"",""Vertigo"",""M"",""Dangal"",""1917"",""Eternal Sunshine of the Spotless Mind"",""The Hunt"",""Citizen Kane"",""Full Metal Jacket"",""Bicycle Thieves"",""The Kid"",""A Clockwork Orange"",""North by Northwest"",""Singin' in the Rain"",""Snatch"",""Scarface"",""Taxi Driver"",""Ikiru"",""Lawrence of Arabia"",""Am√©lie"",""Toy Story 3"",""The Sting"",""Metropolis"",""A Separation"",""For a Few Dollars More"",""Incendies"",""The Apartment"",""Double Indemnity"",""Come and See"",""To Kill a Mockingbird"",""Indiana Jones and the Last Crusade"",""Up"",""L.A. Confidential"",""Heat"",""Monty Python and the Holy Grail"",""Die Hard"",""Rashomon"",""Yojimbo"",""Batman Begins"",""Green Book"",""Downfall"",""Children of Heaven"",""Anand"",""Unforgiven"",""Some Like It Hot"",""Ran"",""Howl's Moving Castle"",""A Beautiful Mind"",""All About Eve"",""The Great Escape"",""Casino"",""Pan's Labyrinth"",""The Wolf of Wall Street"",""The Secret in Their Eyes"",""Lock, Stock and Two Smoking Barrels"",""My Neighbour Totoro"",""Raging Bull"",""There Will Be Blood"",""Judgment at Nuremberg"",""The Treasure of the Sierra Madre"",""Three Billboards Outside Ebbing, Missouri"",""Babam ve Oglum"",""Dial M for Murder"",""The Gold Rush"",""Chinatown"",""Shutter Island"",""V for Vendetta"",""No Country for Old Men"",""The Seventh Seal"",""Inside Out"",""Warrior"",""The Elephant Man"",""Trainspotting"",""The Sixth Sense"",""The Thing"",""Jurassic Park"",""Gone with the Wind"",""Wild Strawberries"",""Blade Runner"",""Finding Nemo"",""The Truman Show"",""Room"",""The Bridge on the River Kwai"",""Stalker"",""Kill Bill: Vol. 1"",""Fargo"",""Tokyo Story"",""The Third Man"",""On the Waterfront"",""Memories of Murder"",""Gran Torino"",""The Deer Hunter"",""Wild Tales"",""Klaus"",""Andhadhun"",""In the Name of the Father"",""Mary and Max"",""Gone Girl"",""Hacksaw Ridge"",""The Grand Budapest Hotel"",""The Big Lebowski"",""Before Sunrise"",""Catch Me If You Can"",""The Bandit"",""Persona"",""Le Mans '66"",""To Be or Not to Be"",""Prisoners"",""The General"",""How to Train Your Dragon"",""Sherlock Jr."",""Mr. Smith Goes to Washington"",""12 Years a Slave"",""Barry Lyndon"",""Mad Max: Fury Road"",""Network"",""Stand by Me"",""Million Dollar Baby"",""Cool Hand Luke"",""Ben-Hur"",""Hachi: A Dog's Tale"",""Into the Wild"",""Dead Poets Society"",""The Wages of Fear"",""Platoon"",""Harry Potter and the Deathly Hallows: Part 2"",""Monty Python's Life of Brian"",""Logan"",""Rush"",""Rififi"",""The Handmaiden"",""The 400 Blows"",""The Passion of Joan of Arc"",""Hotel Rwanda"",""Andrei Rublev"",""Spotlight"",""Amores Perros"",""Nausica√§ of the Valley of the Wind"",""Rang De Basanti"",""La Haine"",""Rocky"",""Gangs of Wasseypur"",""Monsters, Inc."",""Rebecca"",""Portrait of a Lady on Fire"",""Before Sunset"",""It Happened One Night"",""In the Mood for Love"",""The Circus"",""Drishyam"",""Paris, Texas"",""The Invisible Guest"",""The Help"",""The Princess Bride"",""The Battle of Algiers"",""The Terminator"",""Neon Genesis Evangelion: The End of Evangelion"",""Three Colours: Red"",""A Wednesday"",""A Silent Voice""],[1994,1972,1974,2008,1957,1993,2003,1994,1966,2001,1999,1994,2010,1980,2002,1999,1990,1975,1954,1995,1997,2002,1991,1946,1977,1998,2001,1999,2019,2014,1994,2020,1995,1962,1994,1985,2002,1991,1998,1936,1960,2000,1931,2006,2011,2014,2006,1988,1968,1942,1988,1954,1979,1979,2000,1981,1940,2019,2012,2006,1957,1980,2008,2018,1950,2018,1957,1997,2003,1964,2012,1984,1986,2019,2016,2017,1999,1995,2009,1981,1995,1963,1984,2007,1983,2009,1992,1997,2018,1968,2000,1958,1931,2016,2019,2004,2012,1941,1987,1948,1921,1971,1959,1952,2000,1983,1976,1952,1962,2001,2010,1973,1927,2011,1965,2010,1960,1944,1985,1962,1989,2009,1997,1995,1975,1988,1950,1961,2005,2018,2004,1997,1971,1992,1959,1985,2004,2001,1950,1963,1995,2006,2013,2009,1998,1988,1980,2007,1961,1948,2017,2005,1954,1925,1974,2010,2005,2007,1957,2015,2011,1980,1996,1999,1982,1993,1939,1957,1982,2003,1998,2015,1957,1979,2003,1996,1953,1949,1954,2003,2008,1978,2014,2019,2018,1993,2009,2014,2016,2014,1998,1995,2002,1996,1966,2019,1942,2013,1926,2010,1924,1939,2013,1975,2015,1976,1986,2004,1967,1959,2009,2007,1989,1953,1986,2011,1979,2017,2013,1955,2016,1959,1928,2004,1966,2015,2000,1984,2006,1995,1976,2012,2001,1940,2019,2004,1934,2000,1928,2015,1984,2016,2011,1987,1966,1984,1997,1994,2008,2016],[9.2,9.1,9,9,8.9,8.9,8.9,8.8,8.8,8.8,8.8,8.8,8.7,8.7,8.7,8.6,8.6,8.6,8.6,8.6,8.6,8.6,8.6,8.6,8.6,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250]],""container"":""<table class=\""display\"">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>title<\/th>\n      <th>year<\/th>\n      <th>score<\/th>\n      <th>rank<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>"",""options"":{""dom"":""p"",""pageLength"":8,""columnDefs"":[{""className"":""dt-right"",""targets"":[2,3,4]},{""orderable"":false,""targets"":0}],""order"":[],""autoWidth"":false,""orderClasses"":false,""lengthMenu"":[8,10,25,50,100]}},""evals"":[],""jsHooks"":[]}</script>
 
 ---
 
@@ -347,7 +347,7 @@
 --
 
 .small[
-&lt;img src=""u1_d13-webscraping_files/figure-html/unnamed-chunk-14-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d13-webscraping_files/figure-html/unnamed-chunk-14-1.png"" width=""90%"" style=""display: block; margin: auto;"" /&gt;
 ]
 
 ---

---FILE: course-materials/slides/u1_d14-functions-iteration/u1_d14-functions-iteration.Rmd---
@@ -110,7 +110,7 @@ class: middle
 
 --
 
-```{r echo=FALSE, out.width=""70%"", fig.align=""center""}
+```{r echo=FALSE, out.width=""70%""}
 knitr::include_graphics(""img/funct-all-things.png"")
 ```
 

---FILE: course-materials/slides/u2_d01-language-of-models/u2_d01-language-of-models.Rmd---
@@ -70,7 +70,7 @@ PhD students in the Duke Art, Law, and Markets Initiative in 2013
 
 ## Auctions today
 
-```{r out.width=""90%"", fig.align=""center"", echo=FALSE}
+```{r out.width=""90%"", echo=FALSE}
 knitr::include_graphics(""img/auction-video.png"")
 ```
 
@@ -82,7 +82,7 @@ https://www.youtube.com/watch?v=apaE1Q7r4so
 
 ## Auctions back in the day
 
-```{r out.width=""80%"", fig.align=""center"", echo=FALSE}
+```{r out.width=""80%"", echo=FALSE}
 knitr::include_graphics(""img/old-auction.png"")
 ```
 
@@ -92,15 +92,15 @@ Pierre-Antoine de Machy, Public Sale at the H√¥tel Bullion, Mus√©e Carnavalet, P
 
 ## Paris auction market
 
-```{r out.width=""75%"", fig.align=""center"", echo=FALSE}
+```{r out.width=""75%"", echo=FALSE}
 knitr::include_graphics(""img/auction-trend-paris.png"")
 ```
 
 ---
 
 ## Depart pour la chasse
 
-```{r out.width=""75%"", fig.align=""center"", echo=FALSE}
+```{r out.width=""75%"", echo=FALSE}
 knitr::include_graphics(""img/depart-pour-la-chasse.png"")
 ```
 
@@ -109,7 +109,7 @@ knitr::include_graphics(""img/depart-pour-la-chasse.png"")
 ## Auction catalog text
 
 .pull-left[
-```{r out.width=""70%"", fig.align=""center"", echo=FALSE}
+```{r out.width=""70%"", echo=FALSE}
 knitr::include_graphics(""img/auction-catalogue.png"")
 ```
 ]
@@ -121,7 +121,7 @@ Two paintings very rich in composition, of a beautiful execution, and whose meri
 
 ---
 
-```{r out.width=""80%"", fig.align=""center"", echo=FALSE}
+```{r out.width=""80%"", echo=FALSE}
 knitr::include_graphics(""img/painting1.png"")
 knitr::include_graphics(""img/painting2.png"")
 knitr::include_graphics(""img/painting3.png"")
@@ -150,7 +150,7 @@ class: middle
 Describe the distribution of heights of paintings.
 ]
 
-```{r height-dist, fig.height=2, fig.width=5, echo=FALSE, warning=FALSE}
+```{r height-dist, out.width=""80%"", echo=FALSE, warning=FALSE}
 ggplot(data = pp, aes(x = Height_in)) +
   geom_histogram(bins = 30) +
   labs(x = ""Height, in inches"", y = """")
@@ -164,7 +164,7 @@ ggplot(data = pp, aes(x = Height_in)) +
 Describe the distribution of widths of paintings.
 ]
 
-```{r width-dist, fig.height=2, fig.width=5, echo=FALSE, warning=FALSE}
+```{r width-dist, out.width=""80%"", echo=FALSE, warning=FALSE}
 ggplot(data = pp, aes(x = Width_in)) +
   geom_histogram(bins = 30) +
   labs(x = ""Width, in inches"", y = """")
@@ -192,7 +192,7 @@ and one or more inputs.
 Describe the relationship between height and width of paintings.
 ]
 
-```{r height-width-plot, warning = FALSE, echo=FALSE, fig.height=2.4, fig.width=5}
+```{r height-width-plot, warning = FALSE, echo=FALSE, out.width=""80%""}
 ggplot(data = pp, aes(x = Width_in, y = Height_in)) +
   geom_point() +
   geom_smooth(method = ""lm"") +
@@ -207,7 +207,7 @@ ggplot(data = pp, aes(x = Width_in, y = Height_in)) +
 ## Visualizing the linear model
 
 .small[
-```{r height-width-plot-code, warning = FALSE, fig.height=2.3, fig.width=5}
+```{r height-width-plot-code, warning = FALSE, out.width=""80%""}
 ggplot(data = pp, aes(x = Width_in, y = Height_in)) +
   geom_point() +
   geom_smooth(method = ""lm"") # lm for linear model
@@ -219,7 +219,7 @@ ggplot(data = pp, aes(x = Width_in, y = Height_in)) +
 ## ... without the measure of uncertainty
 
 .small[
-```{r height-width-plot-no-se, warning = FALSE, fig.height=2.2, fig.width=5}
+```{r height-width-plot-no-se, warning = FALSE, out.width=""80%""}
 ggplot(data = pp, aes(x = Width_in, y = Height_in)) +
   geom_point() +
   geom_smooth(method = ""lm"", se = FALSE)
@@ -231,7 +231,7 @@ ggplot(data = pp, aes(x = Width_in, y = Height_in)) +
 ## ... with different cosmetic choices
 
 .small[
-```{r height-width-plot-pink-line, warning = FALSE, fig.height=2.15, fig.width=5}
+```{r height-width-plot-pink-line, warning = FALSE, out.width=""80%""}
 ggplot(data = pp, aes(x = Width_in, y = Height_in)) +
   geom_point() +
   geom_smooth(method = ""lm"", se = FALSE, 
@@ -245,7 +245,7 @@ ggplot(data = pp, aes(x = Width_in, y = Height_in)) +
 ## Other smoothing methods: gam
 
 .small[
-```{r height-width-gam-smooth, warning = FALSE, fig.height=2.2, fig.width=5}
+```{r height-width-gam-smooth, warning = FALSE, out.width=""80%""}
 ggplot(data = pp, aes(x = Width_in, y = Height_in)) +
   geom_point() +
   geom_smooth(method = ""gam"")
@@ -257,7 +257,7 @@ ggplot(data = pp, aes(x = Width_in, y = Height_in)) +
 ## Other smoothing methods: loess
 
 .small[
-```{r height-width-loess-smooth, warning = FALSE, fig.height=2.2, fig.width=5}
+```{r height-width-loess-smooth, warning = FALSE, out.width=""80%""}
 ggplot(data = pp, aes(x = Width_in, y = Height_in)) +
   geom_point() +
   geom_smooth(method = ""loess"")
@@ -289,7 +289,7 @@ What does a negative residual mean? Which paintings on the plot have have
 negative residuals, those below or above the line?
 ]
 
-```{r height-width-plot-no-se2, warning = FALSE, echo=FALSE, fig.height=2.3, fig.width=5}
+```{r height-width-plot-no-se2, warning = FALSE, echo=FALSE, out.width=""80%""}
 m_ht_wt <- lm(Height_in ~ Width_in, data = pp)
 m_ht_wt_tidy <- tidy(m_ht_wt) 
 m_ht_wt_aug <- augment(m_ht_wt)
@@ -313,7 +313,7 @@ ggplot(data = m_ht_wt_aug) +
 The plot below displays the relationship between height and width of paintings. The only difference from the previous plots is that it uses a smaller alpha value, making the points somewhat transparent. What feature is apparent in this plot that was not (as) apparent in the previous plots? What might be the reason for this feature?
 ]
 
-```{r height-width-plot-alpha, warning = FALSE, echo=FALSE, fig.height=2.1, fig.width=5}
+```{r height-width-plot-alpha, warning = FALSE, echo=FALSE, out.width=""80%""}
 ggplot(data = pp, aes(x = Width_in, y = Height_in)) +
   geom_point(alpha = 0.2) +
   labs(
@@ -350,7 +350,7 @@ How, if at all, the relatonship between width and height of paintings vary by
 whether or not they have any landscape elements?
 ]
 .small[
-```{r height-width-landscape, warning = FALSE, fig.height=2.2, echo=FALSE}
+```{r height-width-landscape, warning = FALSE, out.width=""80%"", echo=FALSE}
 ggplot(data = pp, aes(x = Width_in, y = Height_in, color = factor(landsALL))) +
   geom_point(alpha = 0.4) +
   geom_smooth(method = ""lm"", se = FALSE) +
@@ -375,7 +375,7 @@ ggplot(data = pp, aes(x = Width_in, y = Height_in,
 ## Extending regression lines
 
 .small[
-```{r extrapolation, warning = FALSE, fig.height=2}
+```{r extrapolation, warning = FALSE, out.width=""80%""}
 ggplot(data = pp, aes(x = Width_in, y = Height_in, color = factor(landsALL))) +
   geom_point(alpha = 0.4) +
   geom_smooth(method = ""lm"", se = FALSE, fullrange = TRUE) +

---FILE: course-materials/slides/u2_d01-language-of-models/u2_d01-language-of-models.html---
@@ -173,7 +173,7 @@
 Describe the distribution of heights of paintings.
 ]
 
-&lt;img src=""u2_d1-language-of-models_files/figure-html/height-dist-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d01-language-of-models_files/figure-html/height-dist-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -183,7 +183,7 @@
 Describe the distribution of widths of paintings.
 ]
 
-&lt;img src=""u2_d1-language-of-models_files/figure-html/width-dist-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d01-language-of-models_files/figure-html/width-dist-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -207,7 +207,7 @@
 Describe the relationship between height and width of paintings.
 ]
 
-&lt;img src=""u2_d1-language-of-models_files/figure-html/height-width-plot-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d01-language-of-models_files/figure-html/height-width-plot-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -221,7 +221,7 @@
   geom_smooth(method = ""lm"") # lm for linear model
 ```
 
-&lt;img src=""u2_d1-language-of-models_files/figure-html/height-width-plot-code-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d01-language-of-models_files/figure-html/height-width-plot-code-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 ]
 
 ---
@@ -236,7 +236,7 @@
   geom_smooth(method = ""lm"", se = FALSE)
 ```
 
-&lt;img src=""u2_d1-language-of-models_files/figure-html/height-width-plot-no-se-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d01-language-of-models_files/figure-html/height-width-plot-no-se-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 ]
 
 ---
@@ -253,7 +253,7 @@
               col = ""pink"", lty = 2,    lwd = 3)
 ```
 
-&lt;img src=""u2_d1-language-of-models_files/figure-html/height-width-plot-pink-line-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d01-language-of-models_files/figure-html/height-width-plot-pink-line-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 ]
 
 ---
@@ -268,7 +268,7 @@
   geom_smooth(method = ""gam"")
 ```
 
-&lt;img src=""u2_d1-language-of-models_files/figure-html/height-width-gam-smooth-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d01-language-of-models_files/figure-html/height-width-gam-smooth-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 ]
 
 ---
@@ -283,7 +283,7 @@
   geom_smooth(method = ""loess"")
 ```
 
-&lt;img src=""u2_d1-language-of-models_files/figure-html/height-width-loess-smooth-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d01-language-of-models_files/figure-html/height-width-loess-smooth-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 ]
 
 ---
@@ -311,15 +311,15 @@
 negative residuals, those below or above the line?
 ]
 
-&lt;img src=""u2_d1-language-of-models_files/figure-html/height-width-plot-no-se2-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d01-language-of-models_files/figure-html/height-width-plot-no-se2-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
 .question[
 The plot below displays the relationship between height and width of paintings. The only difference from the previous plots is that it uses a smaller alpha value, making the points somewhat transparent. What feature is apparent in this plot that was not (as) apparent in the previous plots? What might be the reason for this feature?
 ]
 
-&lt;img src=""u2_d1-language-of-models_files/figure-html/height-width-plot-alpha-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d01-language-of-models_files/figure-html/height-width-plot-alpha-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -349,7 +349,7 @@
 whether or not they have any landscape elements?
 ]
 .small[
-&lt;img src=""u2_d1-language-of-models_files/figure-html/height-width-landscape-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d01-language-of-models_files/figure-html/height-width-landscape-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 ]
 
 ---
@@ -378,7 +378,7 @@
   labs(color = ""landscape"")
 ```
 
-&lt;img src=""u2_d1-language-of-models_files/figure-html/extrapolation-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d01-language-of-models_files/figure-html/extrapolation-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 ]
 
 ---
@@ -503,19 +503,19 @@
 
 ## Visualizing residuals
 
-&lt;img src=""u2_d1-language-of-models_files/figure-html/vis-res-1-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d01-language-of-models_files/figure-html/vis-res-1-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
 ## Visualizing residuals (cont.)
 
-&lt;img src=""u2_d1-language-of-models_files/figure-html/vis-res-2-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d01-language-of-models_files/figure-html/vis-res-2-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
 ## Visualizing residuals (cont.)
 
-&lt;img src=""u2_d1-language-of-models_files/figure-html/vis-res-3-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d01-language-of-models_files/figure-html/vis-res-3-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 

---FILE: course-materials/slides/u2_d02-linear-model-single-predictor/u2_d02-linear-model-single-predictor.Rmd---
@@ -251,7 +251,7 @@ Remember this when interpreting model coefficients
 
 <br>
 
-```{r echo=FALSE, out.width=""100%""}
+```{r echo=FALSE}
 knitr::include_graphics(""img/cell_phones.png"")
 ```
 
@@ -325,7 +325,7 @@ On average, how tall are paintings that are 400 inches wide?
 $$\widehat{Height_{in}} = 3.62 + 0.78~Width_{in}$$
 ]
 
-```{r extrapolate, warning = FALSE, echo=FALSE, fig.height=2, fig.width=5}
+```{r extrapolate, warning = FALSE, echo=FALSE, out.width = ""80%""}
 newdata <- tibble(Width_in = 400)
 newdata <- newdata %>%
   mutate(Height_in = predict(m_ht_wt, newdata = newdata))
@@ -517,7 +517,7 @@ Why might we be interested in these new variables?
 ## Residuals plot
 
 .small[
-```{r fig.height=2, fig.width=5}
+```{r out.width = ""80%""}
 m_ht_wt_aug <- augment(m_ht_wt)
 ggplot(m_ht_wt_aug, mapping = aes(x = .fitted, y = .resid)) +
   geom_point(alpha = 0.5) +
@@ -547,7 +547,7 @@ our explanatory and response variables.
 - Residuals distributed randomly around 0
 - With no visible pattern along the x or y axes
 
-```{r fig.height=2, fig.width=5, echo=FALSE}
+```{r out.width = ""80%"", echo=FALSE}
 set.seed(12346)
 df <- tibble(
   fake_resid = rnorm(1000, mean = 0, sd = 30),
@@ -565,7 +565,7 @@ ggplot(df, mapping = aes(x = fake_predicted, y = fake_resid)) +
 
 ### Fan shapes
 
-```{r fig.height=2, fig.width=5, echo=FALSE}
+```{r out.width = ""80%"", echo=FALSE}
 set.seed(12346)
 df <- tibble(
   fake_resid = c(rnorm(100, mean = 0, sd = 1), 
@@ -591,7 +591,7 @@ ggplot(df, mapping = aes(x = fake_predicted, y = fake_resid)) +
 
 ### Residuals correlated with predicted values
 
-```{r fig.height=2, fig.width=5, echo=FALSE}
+```{r out.width = ""80%"", echo=FALSE}
 set.seed(12346)
 df <- tibble(
   fake_predicted = seq(0.2, 200, 0.2),
@@ -612,7 +612,7 @@ ggplot(df, mapping = aes(x = fake_predicted, y = fake_resid)) +
 
 ### Groups of patterns
 
-```{r fig.height=2, fig.width=5, echo=FALSE}
+```{r out.width = ""80%"", echo=FALSE}
 set.seed(12346)
 df <- tibble(
   fake_predicted = seq(0.2, 200, 0.2),
@@ -630,7 +630,7 @@ ggplot(df, mapping = aes(x = fake_predicted, y = fake_resid)) +
 
 ### Any patterns!
 
-```{r fig.height=2, fig.width=5, echo=FALSE}
+```{r out.width = ""80%"", echo=FALSE}
 set.seed(12346)
 df <- tibble(
   fake_predicted = seq(-100, 100, 0.4),
@@ -650,7 +650,7 @@ whether a linear model is a good fit for modeling the relationship
 between height and width of paintings?
 ]
 
-```{r fig.height=2, fig.width=5, echo=FALSE}
+```{r out.width = ""80%"", echo=FALSE}
 ggplot(m_ht_wt_aug, mapping = aes(x = .fitted, y = .resid)) +
   geom_point(alpha = 0.5) +
   geom_hline(yintercept = 0, color = ""gray"", lty = 2) +

---FILE: course-materials/slides/u2_d02-linear-model-single-predictor/u2_d02-linear-model-single-predictor.html---
@@ -427,7 +427,7 @@
 `$$\widehat{Height_{in}} = 3.62 + 0.78~Width_{in}$$`
 ]
 
-&lt;img src=""u2_d2-linear-model-single-predictor_files/figure-html/extrapolate-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d02-linear-model-single-predictor_files/figure-html/extrapolate-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -701,7 +701,7 @@
   labs(x = ""Predicted height"", y = ""Residuals"")
 ```
 
-&lt;img src=""u2_d2-linear-model-single-predictor_files/figure-html/unnamed-chunk-20-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d02-linear-model-single-predictor_files/figure-html/unnamed-chunk-20-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 ]
 
 ---
@@ -725,39 +725,39 @@
 - Residuals distributed randomly around 0
 - With no visible pattern along the x or y axes
 
-&lt;img src=""u2_d2-linear-model-single-predictor_files/figure-html/unnamed-chunk-21-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d02-linear-model-single-predictor_files/figure-html/unnamed-chunk-21-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
 ## Not looking for...
 
 ### Fan shapes
 
-&lt;img src=""u2_d2-linear-model-single-predictor_files/figure-html/unnamed-chunk-22-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d02-linear-model-single-predictor_files/figure-html/unnamed-chunk-22-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
 ## Not looking for...
 
 ### Residuals correlated with predicted values
 
-&lt;img src=""u2_d2-linear-model-single-predictor_files/figure-html/unnamed-chunk-23-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d02-linear-model-single-predictor_files/figure-html/unnamed-chunk-23-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
 ## Not looking for...
 
 ### Groups of patterns
 
-&lt;img src=""u2_d2-linear-model-single-predictor_files/figure-html/unnamed-chunk-24-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d02-linear-model-single-predictor_files/figure-html/unnamed-chunk-24-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
 ## Not looking for...
 
 ### Any patterns!
 
-&lt;img src=""u2_d2-linear-model-single-predictor_files/figure-html/unnamed-chunk-25-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d02-linear-model-single-predictor_files/figure-html/unnamed-chunk-25-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -767,7 +767,7 @@
 between height and width of paintings?
 ]
 
-&lt;img src=""u2_d2-linear-model-single-predictor_files/figure-html/unnamed-chunk-26-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d02-linear-model-single-predictor_files/figure-html/unnamed-chunk-26-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
     </textarea>
 <style data-target=""print-only"">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
 <script src=""https://remarkjs.com/downloads/remark-latest.min.js""></script>

---FILE: course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors.Rmd---
@@ -24,7 +24,7 @@ library(plotly)
 library(widgetframe)
 ```
 
-class: center, middle
+class: middle
 
 # The linear model with multiple predictors
 
@@ -96,7 +96,7 @@ frameWidget(p, width = ""100%"", height = ""100%"")
 
 ---
 
-class: center, middle
+class: middle
 
 # Exploration: Price, surface area, and living artist
 
@@ -127,7 +127,7 @@ pp %>%
 What is the typical surface area for paintings?
 ]
 
-```{r viz-surf-artistliving, echo=FALSE,warning=FALSE, fig.width=5, fig.height=2}
+```{r viz-surf-artistliving, echo=FALSE,warning=FALSE, out.width=""80%""}
 ggplot(data = pp, 
        mapping = aes(x = Surface, fill = artistliving)) +
   geom_histogram(binwidth = 500) + 
@@ -149,12 +149,12 @@ Less than 1000 square inches (~ 80cm x 80cm). There are very few paintings that
 
 For simplicity let's focus on the paintings with `Surface < 5000`:
 
-```{r surf-lt-5000}
+```{r surf-lt-5000, out.width=""90%""}
 pp_Surf_lt_5000 <- pp %>%
   filter(Surface < 5000)
 ```
 
-```{r viz-surf-lt-5000-artistliving, echo=FALSE, warning=FALSE, fig.width=5, fig.height=1.8}
+```{r viz-surf-lt-5000-artistliving, echo=FALSE, warning=FALSE, out.width=""80%""}
 ggplot(data = pp_Surf_lt_5000, 
        mapping = aes(y = log_price, x = Surface, 
                      color = artistliving)) +
@@ -167,7 +167,7 @@ ggplot(data = pp_Surf_lt_5000,
 
 ## Facet to get a better look
 
-```{r viz-surf-lt-5000-artistliving-facet, echo=FALSE, warning=FALSE, fig.width=5, fig.height=1.8}
+```{r viz-surf-lt-5000-artistliving-facet, echo=FALSE, warning=FALSE, out.width=""80%""}
 ggplot(data = pp_Surf_lt_5000, 
        mapping = aes(y = log_price, x = Surface, 
                      color = artistliving)) +
@@ -199,7 +199,7 @@ explanatory variables.
 
 ---
 
-class: center, middle
+class: middle
 
 # Side-step: Weights of books
 
@@ -237,15 +237,15 @@ The bookshelf of J. H. Maindonald at Australian National University.
 
 ---
 
-```{r}
+```{r out.width=""80%""}
 ggplot(allbacks, aes(x = volume, y = weight, color = cover)) +
   geom_point(alpha = 0.7) +
   theme_minimal()
 ```
 
 ---
 
-```{r echo=FALSE, fig.height = 2, fig.width = 6}
+```{r echo=FALSE, out.width=""55%""}
 m_main <- lm(weight ~ volume + cover, data = allbacks)
 m_main_aug <- augment(m_main)
 
@@ -260,7 +260,7 @@ ggplot() +
 ```
 
 
-```{r echo=FALSE, fig.height = 2, fig.width = 6}
+```{r echo=FALSE, out.width=""55%""}
 m_int <- lm(weight ~ volume + cover + volume*cover, data = allbacks)
 m_int_aug <- augment(m_int)
 
@@ -291,7 +291,7 @@ variable brings something valuable in terms of predictive power to the model.
 Visually, which of the two models is preferable under Occam's razor?
 ]
 
-```{r echo=FALSE, fig.height = 1.7, fig.width = 6}
+```{r echo=FALSE, out.width=""55%""}
 m_main <- lm(weight ~ volume + cover, data = allbacks)
 m_main_aug <- augment(m_main)
 
@@ -302,11 +302,11 @@ ggplot() +
               mapping = aes(x = volume, y = .fitted, color = cover)) +
   theme_minimal() +
   labs(title = ""Main effects, parallel slopes"", 
-       subtitle = ""weight-hat = volume + cover"")
+       subtitle = ""weigmainht-hat = volume + cover"")
 ```
 
 
-```{r echo=FALSE, fig.height = 1.7, fig.width = 6}
+```{r echo=FALSE, out.width=""55%""}
 m_int <- lm(weight ~ volume + cover + volume*cover, data = allbacks)
 m_int_aug <- augment(m_int)
 
@@ -382,7 +382,7 @@ glance(m_int)$adj.r.squared > glance(m_main)$adj.r.squared
 
 ---
 
-class: center, middle
+class: middle
 
 # Back to exploration: Price, surface area, and living artist
 
@@ -396,7 +396,7 @@ class: center, middle
 price **varies** by whether or not the artist is living.
 
 .pull-left[
-```{r viz-main-effects, fig.height=3.8, echo=FALSE}
+```{r viz-main-effects, out.width=""80%"", echo=FALSE}
 m_main <- lm(log_price ~ Surface + artistliving, data = pp_Surf_lt_5000)
 m_main_aug <- augment(m_main)
 ggplot(data = m_main_aug, 
@@ -409,7 +409,7 @@ ggplot(data = m_main_aug,
 ```
 ]
 .pull-right[
-```{r viz-interaction-effects, fig.height=3.8, echo=FALSE}
+```{r viz-interaction-effects, out.width=""80%"", echo=FALSE}
 ggplot(data = pp_Surf_lt_5000,
        mapping = aes(y = log_price, x = Surface, 
                      color = artistliving)) +
@@ -459,7 +459,7 @@ $= 5.017 + 0.000265~surface$
 
 ## Visualizing main effects
 
-```{r fig.height=1.75, echo = FALSE}
+```{r out.width=""60%"", echo = FALSE}
 ggplot(data = m_main_aug, 
        mapping = aes(y = log_price, x = Surface, color = artistliving)) +
   geom_point(alpha = 0.3) +
@@ -498,7 +498,7 @@ Why is our linear regression model different from what we got from `geom_smooth(
 ]
 
 .pull-left[
-```{r echo=FALSE, fig.height=4}
+```{r echo=FALSE, out.width=""80%""}
 ggplot(pp_Surf_lt_5000, aes(x = Surface, y = log_price, color = artistliving)) + 
   geom_point(alpha = 0.3) +
   geom_smooth(method = ""lm"") +
@@ -507,7 +507,7 @@ ggplot(pp_Surf_lt_5000, aes(x = Surface, y = log_price, color = artistliving)) +
 ```
 ]
 .pull-right[
-```{r viz-main-effects3, echo=FALSE, fig.height=4}
+```{r viz-main-effects3, echo=FALSE, out.width=""80%""}
 m_pr <- lm(log_price ~ Surface + artistliving, data = pp_Surf_lt_5000)
 m_pr_aug <- augment(m_pr)
 ggplot(data = m_pr_aug, mapping = aes(y = log_price, x = Surface, color = artistliving)) +
@@ -536,7 +536,7 @@ What seems more appropriate in this case?
 
 ## Interaction: surface * artist living
 
-```{r fig.height=1.75, echo = FALSE}
+```{r out.width=""80%"", echo = FALSE}
 m_int <- lm(log_price ~ Surface * artistliving, data = pp_Surf_lt_5000)
 m_int_aug <- augment(m_int)
 ggplot(data = m_int_aug, 
@@ -600,7 +600,7 @@ $- 0.126 + 0.00048~surface$
 $= 4.784 + 0.00069~surface$
 ]
 .pull-right[
-```{r viz-interaction-effects2, fig.height=3.5, echo = FALSE}
+```{r viz-interaction-effects2, out.width=""80%"", echo = FALSE}
 ggplot(data = pp_Surf_lt_5000,
        aes(y = log_price, x = Surface, color = artistliving)) +
   geom_point(alpha = 0.3) +

---FILE: course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors.html---
@@ -38,7 +38,7 @@
 
 
 
-class: center, middle
+class: middle
 
 # The linear model with multiple predictors
 
@@ -111,12 +111,12 @@
 
 ## Visualizing models with multiple predictors
 
-<div id=""htmlwidget-65b7328530dcdf303887"" style=""width:100%;height:100%;"" class=""widgetframe html-widget""></div>
-<script type=""application/json"" data-for=""htmlwidget-65b7328530dcdf303887"">{""x"":{""url"":""u2_d4-linear-model-multiple-predictors_files/figure-html//widgets/widget_plotly.html"",""options"":{""xdomain"":""*"",""allowfullscreen"":false,""lazyload"":false}},""evals"":[],""jsHooks"":[]}</script>
+<div id=""htmlwidget-8f836166d559454ecd73"" style=""width:100%;height:100%;"" class=""widgetframe html-widget""></div>
+<script type=""application/json"" data-for=""htmlwidget-8f836166d559454ecd73"">{""x"":{""url"":""u2_d04-linear-model-multiple-predictors_files/figure-html//widgets/widget_plotly.html"",""options"":{""xdomain"":""*"",""allowfullscreen"":false,""lazyload"":false}},""evals"":[],""jsHooks"":[]}</script>
 
 ---
 
-class: center, middle
+class: middle
 
 # Exploration: Price, surface area, and living artist
 
@@ -156,7 +156,7 @@
 What is the typical surface area for paintings?
 ]
 
-&lt;img src=""u2_d4-linear-model-multiple-predictors_files/figure-html/viz-surf-artistliving-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d04-linear-model-multiple-predictors_files/figure-html/viz-surf-artistliving-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 --
 
@@ -174,13 +174,13 @@
   filter(Surface &lt; 5000)
 ```
 
-&lt;img src=""u2_d4-linear-model-multiple-predictors_files/figure-html/viz-surf-lt-5000-artistliving-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d04-linear-model-multiple-predictors_files/figure-html/viz-surf-lt-5000-artistliving-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
 ## Facet to get a better look
 
-&lt;img src=""u2_d4-linear-model-multiple-predictors_files/figure-html/viz-surf-lt-5000-artistliving-facet-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d04-linear-model-multiple-predictors_files/figure-html/viz-surf-lt-5000-artistliving-facet-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -204,7 +204,7 @@
 
 ---
 
-class: center, middle
+class: middle
 
 # Side-step: Weights of books
 
@@ -221,7 +221,7 @@
 increases would be different for hardback and paperback books.
 ]
 
-<div class=""countdown"" id=""timer_5f523ae6"" style=""right:0;bottom:0;"" data-warnwhen=""0"">
+<div class=""countdown"" id=""timer_5f581ccd"" style=""right:0;bottom:0;"" data-warnwhen=""0"">
 <code class=""countdown-time""><span class=""countdown-digits minutes"">03</span><span class=""countdown-digits colon"">:</span><span class=""countdown-digits seconds"">00</span></code>
 </div>
 
@@ -263,14 +263,14 @@
   theme_minimal()
 ```
 
-&lt;img src=""u2_d4-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-5-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d04-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-5-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
-&lt;img src=""u2_d4-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-6-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d04-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-6-1.png"" width=""55%"" style=""display: block; margin: auto;"" /&gt;
 
 
-&lt;img src=""u2_d4-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-7-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d04-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-7-1.png"" width=""55%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -289,10 +289,10 @@
 Visually, which of the two models is preferable under Occam's razor?
 ]
 
-&lt;img src=""u2_d4-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-8-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d04-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-8-1.png"" width=""55%"" style=""display: block; margin: auto;"" /&gt;
 
 
-&lt;img src=""u2_d4-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-9-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d04-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-9-1.png"" width=""55%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -404,7 +404,7 @@
 
 ---
 
-class: center, middle
+class: middle
 
 # Back to exploration: Price, surface area, and living artist
 
@@ -418,10 +418,10 @@
 price **varies** by whether or not the artist is living.
 
 .pull-left[
-&lt;img src=""u2_d4-linear-model-multiple-predictors_files/figure-html/viz-main-effects-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d04-linear-model-multiple-predictors_files/figure-html/viz-main-effects-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 ]
 .pull-right[
-&lt;img src=""u2_d4-linear-model-multiple-predictors_files/figure-html/viz-interaction-effects-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d04-linear-model-multiple-predictors_files/figure-html/viz-interaction-effects-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 ]
 
 ---
@@ -473,7 +473,7 @@
 
 ## Visualizing main effects
 
-&lt;img src=""u2_d4-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-14-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d04-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-14-1.png"" width=""60%"" style=""display: block; margin: auto;"" /&gt;
 
 - **Same slope:** Rate of change in price as the surface area increases does 
 not vary between paintings by living and non-living artists.
@@ -515,10 +515,10 @@
 ]
 
 .pull-left[
-&lt;img src=""u2_d4-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-15-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d04-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-15-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 ]
 .pull-right[
-&lt;img src=""u2_d4-linear-model-multiple-predictors_files/figure-html/viz-main-effects3-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d04-linear-model-multiple-predictors_files/figure-html/viz-main-effects3-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 ]
 
 ---
@@ -539,7 +539,7 @@
 
 ## Interaction: surface * artist living
 
-&lt;img src=""u2_d4-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-16-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d04-linear-model-multiple-predictors_files/figure-html/unnamed-chunk-16-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -612,7 +612,7 @@
 `\(= 4.784 + 0.00069~surface\)`
 ]
 .pull-right[
-&lt;img src=""u2_d4-linear-model-multiple-predictors_files/figure-html/viz-interaction-effects2-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d04-linear-model-multiple-predictors_files/figure-html/viz-interaction-effects2-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 ]
 ]
 

---FILE: course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_cache/html/__packages---
@@ -9,6 +9,7 @@ grDevices
 graphics
 stats
 countdown
+conflicted
 tidyverse
 ggplot2
 tibble
@@ -18,8 +19,9 @@ purrr
 dplyr
 stringr
 forcats
+scales
 broom
-knitr
-DT
-emo
-infer
+here
+plotly
+htmlwidgets
+widgetframe

---FILE: course-materials/slides/u2_d04-linear-model-multiple-predictors/u2_d04-linear-model-multiple-predictors_files/figure-html/widgets/widget_plotly.html---
@@ -0,0 +1,27 @@
+<!DOCTYPE html>
+<html>
+<head>
+<meta charset=""utf-8""/>
+<style>body{background-color:white;}</style>
+<script src=""plotly_libs/htmlwidgets/htmlwidgets.js""></script>
+<script src=""plotly_libs/plotly-binding/plotly.js""></script>
+<script src=""plotly_libs/pymjs/pym.v1.min.js""></script>
+<script src=""plotly_libs/typedarray/typedarray.min.js""></script>
+<script src=""plotly_libs/jquery/jquery.min.js""></script>
+<link href=""plotly_libs/crosstalk/css/crosstalk.css"" rel=""stylesheet"" />
+<script src=""plotly_libs/crosstalk/js/crosstalk.min.js""></script>
+<link href=""plotly_libs/plotly-htmlwidgets-css/plotly-htmlwidgets.css"" rel=""stylesheet"" />
+<script src=""plotly_libs/plotly-main/plotly-latest.min.js""></script>
+  <title>plotly</title>
+</head>
+<body>
+<div id=""htmlwidget_container"">
+  <div id=""htmlwidget-1b4ff99564eb6e8884a5"" style=""width:100%;height:100%;"" class=""plotly html-widget""></div>
+  <script>HTMLWidgets.pymChild = new pym.Child();HTMLWidgets.addPostRenderHandler(function(){
+                                setTimeout(function(){HTMLWidgets.pymChild.sendHeight();},100);
+                            });</script>
+</div>
+<script type=""application/json"" data-for=""htmlwidget-1b4ff99564eb6e8884a5"">{""x"":{""visdat"":{""170f3de6492a"":[""function () "",""plotlyVisDat""]},""cur_data"":""170f3de6492a"",""attrs"":{""170f3de6492a"":{""x"":{},""y"":{},""z"":{},""marker"":{""size"":3,""color"":""lightgray"",""alpha"":0.5,""line"":{""color"":""gray"",""width"":2}},""alpha_stroke"":1,""sizes"":[10,100],""spans"":[1,20],""type"":""scatter3d"",""mode"":""markers"",""inherit"":true}},""layout"":{""margin"":{""b"":40,""l"":60,""t"":25,""r"":10},""scene"":{""xaxis"":{""title"":""Width (in)""},""yaxis"":{""title"":""Height (in)""},""zaxis"":{""title"":""log_price""}},""hovermode"":""closest"",""showlegend"":false},""source"":""A"",""config"":{""showSendToCloud"":false,""displayModeBar"":false},""data"":[{""x"":[29.5,14,16,18,18,10,13,13,15,7,7,12,12,12,16,22,22,20,20,44,48,36,36,60,27,27,30,24,54,30,30,36,27,17,24,36,24,29,16,29,22,18,22,22,21,21,20,12,22,22,13,13,17,13.5,36,24,20.5,16,12.5,32.5,41,11,11,26,10.5,18,18,18,55,55,55,12.5,7,15.5,40,48,27,11,6.25,6.25,19.5,19.5,10.5,8,16,8,8,36,10.5,17.5,12,25,31,23,23,34.5,23,23,18,49,49,49,49,24.5,24.5,24.5,24.5,36,36,24,24,36,36,16,16,16,16,29.5,35,16,34,25,10.25,10.25,10.25,10.25,26,16,18,18,18.5,48,27,23,23,6.25,24,20,13.25,12,12,37,29,13,6.5,5,10,12,10,18,12,15,10.5,7,8.5,27,34,15.5,14,9.3,8,9,6,10,18,20.5,8.75,11,14,4,12.5,13,13.5,13.5,13,3,12,12,6.25,14.5,18,11,10.5,72.75,37,20,21,17,14,13.75,16.5,24,16,9,11.5,13.5,24,9,26.5,12,18,13,21,27,13.25,10.25,13,15,10.5,13.25,20.5,31,11.25,9.75,18.25,18.25,24,11,15.25,19.25,18,18,23.5,12,15,12,27,27,26,26,24.5,24.5,35,6.25,6.25,9.5,18,14.75,9.5,9.5,14.5,7,7,18,22,13.5,11.5,25.5,18,10.5,20,20.75,13.75,14,19.75,34,15.5,19,36,37,37,22,32,14,55,55,8.75,27,20.25,17,17,17,17,21.5,12.5,12.5,15,9.5,9.5,12.5,46.5,19.5,18.25,23.25,95,21.5,21.5,22.25,11.25,16,86,14.75,13.6,9.5,5.75,22.75,22.75,10,15.75,9,2.5,2.5,26,20.75,20.75,8,16,40,30,16.75,16.75,16.75,17,19.25,10.25,11,19,30,18.5,38,14.6,16.25,23,12.5,3.5,3.5,3.25,3.58,13,13,10,27,27,70,47,20.5,17.5,18,58,18,12.5,7.5,16,16,19.25,22.5,12.75,12.5,6.75,7,24.5,24.5,24,8,20.5,18,54,39,34.75,14,66,30,11.75,28.25,15.5,7.25,17,12,17.75,7,18.5,18.5,18,12.75,20,18.75,7.5,7,10.25,17.25,7.25,7.25,5.66,47,4.5,4.5,67,29.5,20,20,7.25,12,66,59.5,29.5,29.5,29.5,11.33,44,4.33,4.33,17,23.75,25,25,15,15,14.5,7,7,17.5,13.5,13.75,59,13.5,9.5,17.5,13.25,14,15,15,24,24,29,29,18,16.5,23,23,7,13,6.5,6.5,18,36.75,29.5,14.25,33,33,36,36,49,13,40,22.5,14.75,60,105,22.5,27,12,12,24,42,10,10,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,35,18,18,21,21,11.75,16.25,13.5,15,49,12,27,19,13.25,24,24,17,10,16,17,9.5,4.5,33.5,23.5,23.5,23.5,23.5,21,38,9,27.5,17,37,11.5,24,24,21,20.75,11.25,13.25,28,14,14,19,19,19,19,19,19,24,24,39,23.5,39,43,49.5,11.25,11.25,18.5,26,14.5,14.5,14,16.5,17.5,21.25,21,10.5,49.5,18,16,31.25,31.25,31.25,31.25,9.5,48,14.5,18,11.75,12,6.25,13,6,20.25,20.5,13.5,19,24,13,10,8,7,10,33,23,39,33,26,20,17,6,16,6,33,33,19.5,7,7,7,14,7,10,6,6,13,8,8,5.5,5.5,13,20,31,7.5,7.5,22,17,12,12,24,24,7,7,23,7,10,7,7,20,13,30,30,6,6,43,8,10,10,8,22,10,10,10,13,7,6,6,30,30,35,41,27,20,8,8,27,23,24,20,20,20,27.5,43,27,17,24,24,15,27,8,8,19,9,18,17,15,19,17,17,20,20,20,11,22,47,17,17,17,17,17,17,17,17,17,17,26,12,18,18,20,19,19,22,24,48,50,36,36,48,35,53,50,48,37,37,54,14.5,18,21.5,62,48,48,48,48,48,36,36,44,46,74,74,43,43,43,38,33,38,48,38,37,14,21,21,72,23,96,76,31,31,31,31,31,31,31,31,31,31,31,31,31,31,36,54,54,54,54,54,54,60,47,32,32,63,48,54,27,13,72,5.5,14,14,37,42,27,21.5,34,27,28,24,27,25,30,30,26,36,24,43,39,39,43,31,2,14,14,13,8,38,11,11,54,18,46,54,36,58,70,42,60,22,22,51,51,74,74,42,42,48,48,46,48,68,68,67,24,26,39,34,34,5.5,3,3,44,44,36,33,33,36,36,42,36,36,72,72,72,72,72,72,72,72,66,66,72,54,67,84,46,50,50,8.5,48,48,108,144,228,87,37,54,27,42,22,30,31,18.5,19,35.5,66,40,10.25,10,9.5,5.75,5.75,13.75,9.5,9.5,30.5,18,14.75,14.75,12.5,18,18,25,45,32,7.75,9.5,21,8.75,5.75,7,7,7,25,6.75,33,17.5,17.5,20,20,6.5,20.75,20.75,5,5,29.25,18,18,16.5,13.75,13.5,6.5,5.5,11.75,9.5,8.75,8.75,11.75,11.75,49.5,49.5,49.5,23.25,13,9.75,9.75,9,9,21,21,34.5,27.5,8,8,31,35,11.5,26,35,44.5,20.5,5.5,9,18,18,75,16,20,20.5,20.5,13,13,11.5,14,27,40,16.5,16.5,61,48,34,64,20,30,67,50,13,13,36,29.5,14,42,11,14,14,22,30,38,40,23,26.5,27.5,24,38.5,43,15,6.25,24,38.5,16.5,48,14.5,14.5,36,26,50,50,24,30,27,28.5,28.5,19,39,8.5,8.5,6.5,50.5,27,36,30,16.5,24,24,18,29,9.5,27.5,10,39.5,33,30,30,31,10.5,10.5,37,37,46,17.5,51,18,36,5.5,51,51,24,24,108,59,18.5,14,18.5,18.5,20,30,22.5,20,20,48,21.5,24,24,22.5,22,45,17,17,18.5,18,31,26,26,27,43,12.5,12.5,16.5,13,48,21,5.75,9,9,18,19,14,11.5,26.5,19,19,15.5,37,24,24,19,8,4,2.42,20,13,14.5,17,5.33,5.33,71,34,47,23,41,6,8.5,23,21.75,41,53.25,48,15.5,40.5,31,72,24,24,30,30,16.5,5,34,11.5,17,16.5,25,25,19.5,34.5,36,36,32,19,17,17,18.5,18.5,10.5,10.5,23.5,29,19,21,37.5,33,19,15,24,22.5,22.5,23,19,8.5,12.5,8.5,27,12,49,9.5,13,12,12,11.5,23,41.75,13.5,26,14,10.5,52.5,51,38,57,19.5,16,54,18,27,57,15,15,27,24,18,14.75,10,20.5,63,8.5,27,18,14,18.5,18,9,30,16,16,6.25,14.75,20.5,20.5,41,11.5,8.5,8.5,8.25,5.5,34,7.5,15,18,14,6.25,6.25,5.5,8.5,9.25,16.75,7,20,15.75,20.33,27,14.25,14.25,7,30,30,50,14,23,13,20,20,23,60,13,27,20,18,32,18,18,7,8,7,7,8,8,14,20.5,20.5,46,16,16,16,8,36,46,68,68,68,68,58,43,57,52,9.5,9.5,13,23,12,10,10,13,13,6.5,6.5,22,22.5,15.5,10.5,9.5,8.5,21,40,27,10,10,8,18,24,42,17.5,18,18,15,22,11,23,26,35,35,23,25,25,8.25,8.25,10,10,10,13.5,16,16,13,16.5,13,23.5,23.5,22,11.5,11.5,26.5,26.5,8.25,13.5,30,16,4.5,11,11,11,21,4.75,13,16,6,15,33,24,9.5,15,30,20,9.5,17.75,17.75,17,17,15,24,10.5,12,10,7,6.25,7.5,10,23.5,12.5,16,4.5,4.5,17,46,77,14,17.75,13.5,16,50,12.5,6.75,7.5,26.75,38,18,21,16,55,20,8.5,10.5,33,14,33,36,36,24,36,36,28,19,23,34,13,13,17,5,6,7,3.75,24,16,7.5,7.5,32,5.25,36,18,30,16,15.75,10.25,4,4,10.5,15,7,7,30,24,15.25,18,28,50,9.5,30,30,21,19,13.5,27,29,32,9.5,15,27,15,6,51,51,19.5,10.5,22,48,6,50,10,10,13,10.5,20,7,6,28,28,14,10,12,20,6,16.5,16.5,14,13.75,32,27,45,21,26,33,34,24,24,16,16,59,59,10.5,24,52,24,59,20,48,48,35,18,18,11,13,13,20,13,54,54,8,8,17,17,27,21,21,3.75,7,8.5,8.5,3.5,3.5,24,11.5,5,7,7,26,26,13,12,12,5,16,13,7,15,20,15,12.5,12.5,31,38,12,12,6.25,6.25,17,41,30,4.5,17,24,42,22,27,34,37,37,37,37,20,24,26,12,12,48,27,27,48,13,11.5,25,11.5,50,23,46,38.5,35,15,19,5.416,27,10,8.5,11.5,16.5,27,8.5,16,25.5,14.5,4.5,2,11.5,13,7,3.5,7,6,4.5,15,20,17,17,11,11,7,5,31,15,15,17,13,43,29,29,24,16,20,23,16,18,18,24,24,18,28,7,22,16,21,21,14,10,6,19,12,12,15,25.5,25.5,23.5,23.5,25.5,26,26,18,18,36,26,30,19,40,27,42,12,36,14,21,32,27,15,27,14,39,39,35,26,21,14,20,40,39,39,13,18,28.5,30,29,19,19,22,22,60,33,18,18,8,7.5,7.5,6,14,12,12,14,14,30,21,21,10,17,32,27,43,8,12,12,54,36,16.5,20,20,71,25.5,34,19,14.25,14.25,46.5,45,58,58,10.5,16,13.75,13.75,9.5,9.5,13,13,5.75,5.75,25,20,20,20,20,20,37,37,36,36,16,16,5,5,15,15,46,46,9.5,9.5,6.5,6.5,4.25,4.25,22,42,10.5,10.5,18,16,29,3,3,4.5,6.5,9,9,17,17,7,7,9,9,7.75,10.5,12,12,10,6,6,7,7,5.25,5.5,5.5,11,11,9,9,9.75,9.75,5.5,29,22,9,9,29,8.5,9,34,23.75,23.75,12,12,12.5,12.5,10,10,39,15,14.5,13.5,13.75,7,7,32.75,39,17,13.25,13.25,13.5,17,17,11.5,11.5,9,13.75,13.25,66,28,8,8,8,7,7,6.75,6.75,8,4.5,4.5,4.5,4.5,9.25,9,9,7.75,12,15,72,6,8.25,30.5,11.5,11.5,13.25,8,8,14,19.25,13.5,13.5,17,30.5,10,10,8.25,8.25,12,12,15.5,12.25,8.5,8.5,9.75,9.75,6,6,10,5.25,5.25,16,18,15,8,8,5.5,7.25,13,13,38.5,48,30,36,78,54,19.5,11,11,46,30,13,16.25,16.25,8,11,11,12.5,12.5,13,10,24,21.75,26,10,12,11.75,26,38,15,15,14,15,13.5,6,5,28,16.5,16.5,16.5,16.5,18.5,24,9.16,9,9,6,7.5,7.5,12,4,23,10.75,13,8.5,9,22,22,15.5,15.5,6,6,12,12,5,5,9,36,32,16,27.5,15,15,14.5,44.5,26,26,36,50,16,38.5,61,12,12,18,53,16,16,7.75,26,26,13.5,30,24,36,39,11,72,9,65,31,5,15.5,15,25.25,8,13,10.5,21,8.5,9,72,5.5,5.5,5.5,5.5,12,38,15.75,15.75,72,49,52,34,10.5,20,72,23,23,24,24,19,19,36,36,18.5,11.75,11.75,62,10.5,48,48,27,10,10,9.75,9.75,4.5,3,3,22,9.75,9.75,18,9,42,7,7,9,3.33,14.5,5.25,3,3,7.5,7.5,5.5,5.5,6.25,6.25,6,6,6,9.5,9.5,17.5,8,9,4,3.5,3.5,4.25,36,36,29,19,10.75,10.75,3.25,3.25,13,21.5,17.5,26,7.5,13,9,9,15,22,8,13,12.25,34,13.5,20.5,4.25,13,10.5,11,24,3.75,24,5,4.5,4.75,3,9,66,8.5,8.5,5.25,23,23,30,25.5,7.5,7.5,6,17,12,4.75,4.75,21,11,15,13.5,33,12,10,12,17,19.5,19.5,16,11.5,8,10.5,14,14,14,25,25,7.5,7.5,7.5,7.5,9,4.75,4.75,11,19,19,7.25,7.25,4.5,4.5,7.5,5.5,50,17.5,17.5,15,15,45,30,30,12,3.75,3.75,5,16.5,16.5,6,27,27,34,12,12,24,24,50,55,17,17,21,15.5,22.5,13,11.5,16.5,12.5,22,16,16,12,12,60,44.5,24,13,21.5,14.5,38,9,19,24,65,6.5,6.5,6.5,7.5,22,25.5,24,49,49,18,18,44,14.5,14.5,17.5,17.5,17,12.5,13.5,53,53,10.5,6.5,6,6,114,31,17,29.5,12.75,27,4.25,4.25,6.25,6.25,7,6,6,11.75,15,12,14,77.5,42.5,18,30.5,8,12.5,24,24,12.5,12.5,24,31,23,13,52.5,17,48,15,74,40,31,25,7,14.5,5.5,4.75,9,9,11,21,21,12,9,20,22.5,18,22,10.5,9.75,7,7.5,7.5,25,11,11,9,8.25,12.25,20,11,29.25,30,23,23,9.25,9.25,15,15,13,9,9,13,27.5,17,14.75,47,18,31.5,54,31.5,31.5,75,13,13,11,17,30,16,28,15,10,14.5,10.75,13.75,12.5,32.5,32.5,40,49,22,15,4.75,36,36,11.5,7,55,26.5,10,17,8,4,12.5,12.5,18,20.75,26,13.25,22.5,16,16,16.75,9,7,3,61.5,65,21,15.5,15.5,15.5,15.5,17,9,16,9.5,12.5,11.75,22.75,5.5,5.5,14,19,22,22,16,80,80,9,11.5,51.5,12.75,13,13,13,11,27,26,14,22.5,22.5,18.5,18.5,19.5,19.5,17,20,20,21,31.5,17,10,25,28,8.25,8.25,37,41,6.5,32,20,32,24,27,18,15,15,15,15,15.5,13.5,9.5,9.5,67,56.5,56.5,30,16,16,30,17,17,17,13,13,14,14,12,12,13.25,14.5,18,12,12,19,57,57,57,57,57,57,54,12,15,14,11.5,20.5,30,16,33,23,17,5.25,4,34,34,47,47,36,36,33,14.5,4.5,24,8,8,5,8.5,8.5,6.5,21,26.5,23.25,11.5,11,42.5,19.5,7.5,25,12,9,6.5,22,23,7,6.5,16.5,15,14.5,16,6.5,13,12,16,10.5,12.5,14,23,14,14,23,36,56,18,8.5,10,10,20,20,6.75,6.75,12,12,32,32,23,27,13,40,6.5,6.5,10,16.5,16,16,23,23,14,16,16.5,2.75,2.75,2.75,5.5,30,37,24,24,12,141,38,13,40,39,30,14,33,32,11,11,40,10,48,48,15,36,17,16.5,11,8,11,9.5,18,22,23,24,14.5,18,29,32,32,15,4,44,9,9.25,9.25,20,11,42,10.5,40,36,28,10,22.5,12,60,8.5,18,40,14,37,22,9,12,12,6,10,10,20,8,15,18,24,11,24,11,26,13,12,32,19,13,14,19,16,9.25,14,16,10,14,14,12,12,12.5,46,13,48,48,48,7.5,12,15,21.5,18,50,26,32,12,15,53,25,72,33,46,45,10,9,22,22,18,9,9,24,14,25,27,19,19,10,25,48,32,13,13,9,48,23,23,8,8,26,26,48,27,43,43,18,13,9,22,14.5,18,18,48,35.5,35.5,14,14,10,10,18,14,14,15,15,14,11.5,25,25,12.5,15.75,17.25,14.5,12,4.5,10,14.25,14.25,13.5,8,16.25,16.25,13.5,10.5,12,12,21,21,17.5,14.5,13,10.5,18.5,13,26,19,13,13,9,21.5,14,14,30,18,18,14,13,9,9,24,15,10,14,12.5,13,14.5,19,11,11,24,18,18,26,14,7.5,15,14,24,14,7,7,33,23,23,23,14,7,54,54,21,26,22,24,17,24,16,16,24,14,14,39,15,12.5,12.5,20,11,24,7,7,8,15,16,16,16,12,60,18,6.5,16,42,42,7,15,13,13,42,7,7,10,10,18,12,12,12,9,22,24,27,12,12,18.5,18.5,22,21,21,9,9,7.5,7.5,15,15,15,12,17,16,21,18,30,30,23,16,15,11.5,10,29,29,14,13,16,16,21,26,16,24,15,15,24,21,33,33,21,30,12,27,38,36,26,12,14,14,15,21,21,21,14,14,23,13,30,30,21,12,15,21,17,17,22,15,11,17,66,9,20,12,17,8,21,42,44,40,12,30,47,21.5,18,19,12,35,24.25,60,11.5,9.5,9.5,33,33,35,6,7.5,7.5,19,6,15,16,27.5,75,75,5.5,20,15.5,15.5,25.5,45.5,45.5,25,45,17.5,10.25,44,44,14.25,38,21,18,18,20,20,7.25,8.5,23,8.25,21.5,21.5,27,4.75,6,6,15,39,6.25,15,12,16,29,15.5,10.5,10,19.75,19.75,26.5,3,15,15.25,15.25,10,10,10,25.5,18,18,18,19,19,10.5,13.6,13.6,11,5,11.5,48,48,10,14.5,16,46,31,9.5,9,23,9,14,18,36,20.75,8,13.5,13.5,26,18,9.5,9.25,24,17,24,13,27,24,15.5,25,6,24,26,33,36,36,18,18,10.5,7.5,7.5,38,23,10.5,10.5,19,7,7,5,7.5,15,24,19,48,48,24,4,4,36,22.5,17,8,11.5,11.5,20.5,24,24,16,12,15.5,16,8.5,10,12,12,23,19,16.5,16.5,10.5,14,35,17.5,20,13.5,14.5,14.5,13.5,13,15.5,21,21,21,60,37,33,33,17,27,13,50,36,39.5,32,48,29,9.5,19.5,16,54,54,48,60,72,72,47,47,21.5,24,36,18.5,18,18,14,11.75,19,17,21.5,16.5,30,23,23],""y"":[37,18,13,14,14,7,6,6,15,9,9,16,16,16,20,14,14,15,15,37,36,27,27,44,22,22,42,30,66,38,38,48,33,20,30,48,30,40,22,40,27,22,17,17,16,16,14,14,16,16,9.5,9.5,13,10,20,18.5,15.5,12.5,16,24,27,8.5,8.5,34,16,24,24,24,78,78,78,10.5,9,11,27,36,17,15,8.25,8.25,13,13,7,6.5,12,5.5,5.5,24,14,14,10,16,20.5,19,19,24,30,30,24,31,31,31,31,24,24,24,24,27.5,27.5,15,15,24,24,11,11,11,11,19.5,27,11,22,23,6.5,6.5,6.5,6.5,18,21.5,12,12,11.25,19,18,19,19,5,18,23,18,15,15,47,42,18,9.5,9.5,8,15,13,13,9,12,8,10,6.5,18,19,12,11.5,6.75,6,6.5,4.5,3,12,17,5.75,8,12,5.5,9.5,10,8.5,8.5,11,4,9,9,7.75,12,12,9,13.5,54,31,14.25,27,10,16,11.25,11.25,14.5,20,11.5,15,10.5,16.5,12,15.5,9,24,14,27,33,9.75,14.5,14.5,19.75,13.5,18.75,25,25,14.25,7.75,13.75,13.75,18,14.25,11.25,22.5,21.5,21.5,29,15.5,20,15.5,11,11,31.5,31.5,30,30,27,8,8,13.5,13,15.25,7.5,7.5,10,9,9,24,17,10,17.5,18,21.75,13.75,17,13.5,17,17,13.5,23,12.5,33,25,15,15,28,41.5,18,45,45,12,22.5,12.5,22,22,22,22,27,16,16,20,11.5,11.25,16.5,27.5,25,20.5,14,64,37.5,37.5,17,8.25,12.5,64,11.75,17.5,12,4.5,16.25,16.25,6,11.75,11.25,3.25,3.25,15,15,15,6,10.75,28,24,24,18,18,22.75,12.5,15,19,13,26,14.25,26,11.5,15.5,19,16.75,4.66,4.66,4,2.75,9.5,9.5,6.5,17,17,77,65,25,14,12,41,22,16,9.75,22,22,25.25,26.5,10,14.5,8,7.5,16.5,16.5,31,9.75,24,12.25,42,28.5,17.5,16.25,27,22.5,15,21.75,19,5.25,13,14.5,14.5,8.59,14.25,14.25,14,11,25,15.5,9.59,9,13.5,22.5,9,9,7.25,66,5.75,5.75,36,23.25,16,16,5.75,9,76,53.25,23.5,23.5,23.25,8.5,30,5.75,5.75,19,20,31.75,31.75,11,11,16.25,8,8,20.75,17,17.25,35,11.5,7.5,21,16,16.75,18,18,19,19,15,15,10.5,10.25,29,29,9,7.75,10,10,24,29,23.25,18.5,43,43,26,26,34,16.75,51.25,18,18,78,78,18,57.5,9,9,30,30,13,13,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,27,14.5,14.5,25,25,15.25,12.75,18,19,44,9,22,14,16.5,14,14,20,13,20,20,14,5.5,20,36,36,36,36,25,28,16,23,26.5,58,29,12,12,16.5,27.5,14,18,24,11.25,11.25,24,24,24,24,24,24,19,19,22,20,21.5,30,36.5,14.5,14.5,22,34,12,12,17,19.75,21.5,26,25,14.5,19,22,19.5,17.25,17.25,17.25,17.25,14.5,36,19.75,13,9,15.75,8,11,8,18,13.5,17.5,24,28,16,12,11,9,12,42,28,29,24,32,27,23,8,14,8,45,45,23,9,8,9,18,10,12,3,3,9,6,6,5.5,5.5,10,30,34,10,10,27,23,9.5,9.5,18,18,11,11,18,9,13,9,9,25,11,38,38,7,7,33,11,7,10,6,17,7,7,7,11,8,7,7,24,24,27,34,30,23,11,34,34,15,17,24,24,24,22.5,58,38,22,18,18,12.5,34,6,6,14,12,23,23,22,25,13,13,25,25,23,14,16,27,45,45,45,45,45,45,45,45,45,45,30,15,22,22,27,23,23,14.5,29.5,36.5,37,47,50,36,53,44,34,40,27,27,42,17.5,15,14,46,36,36,37,37,36,16,16,36,40,56,56,33,57,57,27,42,50,72,30,50,18,24,24,60,15,72,105,18,18,18,18,18,18,18,18,18,18,18,18,18,18,48,72,72,72,72,72,72,36,45,56,56,48,72,90,33,17,108,93,17,17,49,58.5,33,17,27,34,24,30,18.5,18,22,22,31,27,19,31,51,51,50,26,18,18,18,18,13.5,30,7,7,42,24,54,52,48,82,46,32,43,17,17,68,68,58,58,54,54,58,58,58,66,50,56,54,30,34,51,27,27,5.5,3.5,3.5,31,31,27,24,24,48,48,24,48,48,48,48,48,48,48,48,48,48,84,72,60,84,48,60,84,24,24,12,60,36,108,108,108,120,48,42,24,54,28,42,26,24.5,24,26,50,48,7.75,6,6.66,4.75,4.75,11,6.25,6.25,42,25,18.5,18.5,15.5,22,22,31,32,25,10,5,15.75,12,7.25,9,9,9,31,11.25,24,13,13,15,15,8.25,16,16,2.33,2.33,32.25,13.5,13.5,18.25,11,18,8,6.75,15,7.5,11,11.25,14.5,14.5,37,37,37,16,17.75,6.75,6.75,6,6,15,15,26.5,34.5,7,7,42,43,13,33,40,29,16,7,12,13.5,13.5,50,11.5,14,18,18,16,16,14.5,12,34,46,8,8,49,38,44,47,25,22,45.5,35,17.5,17.5,63,22,17.5,54.5,8.5,17.5,17.5,27,37,50,25,28,18.5,34,30,50,29.5,19.5,9.5,30,50,13,60,10,10,50,18,35,35,30,37,34,22.75,22.75,15.5,18,6,6,8.75,37,22,46,24,20.5,18.5,30.5,23,35.5,14,34,13.25,40,43,24,24,47,7.5,7.5,30,30,36,15,64,24,41,7,28,28,18,30,110,39,23,16.5,23,23,24,24,27.5,30,30,60,26.5,17.5,17.5,43.5,39,30,14,14,22,21,14,36,36,36,31,16,16,20.5,9.75,36,27,8,5.5,5.5,29,13.5,17.5,15.5,21.25,23,23,20.5,26,15,20.25,14.75,6,2.42,1.33,13,10,18,10,3.66,3.66,40.5,15,65,17,38,7.5,11.5,16,11.25,47,34,33,11,53,18,47,29,29,20.5,20.5,13.5,7.25,18,14.5,10.5,13.5,21,21,15,41,48,29,45,33.5,12,12,14.5,14.5,16,16,19.5,20,16,27,22,22,13.75,12,18,30.5,30.5,23,23,13,10,13.5,52,16,37,13.5,15,24,24,15,29,33,18.5,18,18,16.5,72,81,62,84,24.5,21,41,23.5,36,67,20,20,33.5,34.25,23,17.5,12,16,45,11,22,13.5,11.5,24,24,8,26,10.25,10.25,8.5,10.75,14,14,31,10.25,6,6,6.25,7.5,38,8.25,11.5,14,11,6.75,9.75,8,6.5,6.5,19,9,16,21,18.25,32.25,10,10,9,22,22,36,9,32,17,35,35,32,60,19,19.5,15,24,25,22.5,22.5,9.25,9,5,5,6,6,18,14.5,14.5,51,26,7,7,6.5,36,58,64,64,60,60,42,66,55,52,7,7,8,17,15,7,7,9.5,9.5,5,5,16,14.5,11.5,12.5,13,6,17,28,23,14,14,7,14,32,28,12,12,12,24,28,14,19,22,24,24,18,18,18,6,6,8.5,8.5,8.5,10.5,8,8,9,20,20,14.5,14.5,19.5,8.5,8.5,14.5,14.5,11.33,9.5,21,25.5,6,9,14,9,27,5.75,9,11.25,8,9.5,36,21,12,12.75,21,28.5,7.5,13.5,13.5,12,12,15.25,20,8.5,14,12.25,7.75,7,6,8,17.75,10,11.25,5,5,13,38.5,68,16.5,20.5,16.25,12.5,31,10,8.5,4.75,22.5,45,21,17,13,30,14,9,8.25,43,18,43,43,43,17,26,26,24,14,16,24,9,9,12.75,7,8,9,5.5,43,12.5,6,6,24,48,43,14,21,13,20,12.5,65.5,65.5,14,17,9,8,26,22,17.25,13,24,33,12.5,24,24,25.5,15,9.5,21.5,21,23,7.5,17,22,17,7,49,49,23,11,25,38,8,33,10,10,18,11.5,24,9,5,24,24,12,13,15,24,5,10.25,10.25,12,16.5,42,21.5,34,25,33,33,48,19,19,13,13,44,44,14,32,35,32,39,24,36,36,30,24,24,14,15,15,24,17,38,38,13,13,13.5,13.5,19,27,27,5.5,5,6,6,2.25,2.25,32,14.5,7,8.75,8.75,33,33,10,15,10,7,12.5,9,5,12,17,12,10,10,25,27,9,9,4.5,4.5,12,26,36,5.5,19,29,54,27,20,24,29,29,29,29,24,30,20,15,15,60,15,15,29,10,14,35,14.5,35,19,32.5,31,28.5,22,14.5,4.16,22,12,11,14.5,14,20,11.5,15,20.5,18,5.5,2.75,13.5,10,9,4,9,7,5.5,19,25,14,14,14,9,10,6.5,26,11,11,14,10,33,45,45,30,20,15,29,13,14,14,31,31,22,20,8,28,20,26,26,9,8,8,23,16,16,11,16.5,16.5,15,15,17,23,20,14,14,48,23,39,13,54,32,54,15,39,16,24,42,38,18,33,18,27,27,27,36,28,16,25,48,54,54,9,22,21,21,24,14,14,15.5,15.5,42,20,11,11,10.5,5.5,5.5,7,15,15.5,15.5,12,12,22,15,15,13.5,24,43,20,33,10,14,14,78,48,20,13,22,54,39.5,24,24,10.75,10.75,27.5,41,41,41,13,21,11,11,7,7,9,9,4,4,18,13,13,13,13,13,22,22,18,18,10,10,3,3,12,12,27,27,6.25,6.25,4.5,4.5,3.75,3.75,16,26,7.5,7.5,12,13,20,2.5,2.5,6,8,6,6,14,14,5.5,5.5,7,7,6,7,8,8,7.5,4,4,4.5,4.5,3.75,4.25,4.25,9,9,6.5,6.5,2.25,2.25,3.33,19.5,15,7,7,36,7,12,45,30,30,16,16,17,17,8,8,31,17,11,11,10,9.5,9.5,25,30,20,9.75,9.75,10,25,25,15.75,15.75,12,9,10.25,48,21,5.75,6,6,5,5,4.75,4.75,6.5,6.75,6.75,6.75,6.75,11.25,12,12,9,9.5,13,48,8,10.25,35,14.5,14.5,17,13,13,11,15,16.5,16.5,13.25,22,8,8,10.25,10.25,9.5,14,13,9.25,4.5,4.5,5,5,4.5,4.5,8,4.5,4.5,10.5,13,12,5.75,6,7.25,5.75,16.5,16.5,30,36,26,26,53,36,15,9,9,20,18,10.75,13,13,6.5,8.5,8.5,8.5,8.5,9,8.5,18.25,17,18,7.5,10.25,8,20,30,11,11,11,12,10,8,10.5,22,11.75,11.75,11.75,11.75,16,22,8.16,7,7,8,9.5,9.5,16,5.5,13,13.25,9.25,11.5,11,29,29,18.5,18.5,4.75,4.75,14.5,14.5,9,9,6.75,26.75,24,13.25,18,12,12,15.5,36,20,20,26,37,19.25,30.5,42,16,16,14,45,11,11,11,24,24,10.25,66,34,44,54,8,52,12,84,39.5,8,13,12,22,6,10.5,13,27,6.5,13,48,7.5,7.5,7.5,7.5,9,25,12,12,48,58.5,62,37,13,34,48,17,17,13,13,15,15,48,48,10,5.5,5.5,52,14,36,36,34,15,15,12,12,8.5,3.75,3.75,30,12,12,12,11,54,8.75,8.75,12,3,11,3.75,2.25,2.25,5,5,4.25,4.25,4,4,4,4,4,7.5,7.5,12.33,7.5,8,3.5,2,2,5.5,46,46,21,12,7.5,7.5,2,2,7,16.5,15,14,9.5,10,7.5,7.5,11,18,5.25,6.5,9.25,18,16.5,13,3,16,13.5,15,34,5,30,6.5,7,6.5,4,12,72,10.5,10.5,9,15,15,21,21,5.5,5.5,9,13.5,8.25,5.75,5.75,14,7.5,15,11,23,9.5,13.5,9,24,13,13,23,15,10,18,19,12,12,18,18,10.75,10.75,10.75,10.75,7,7,7,14,14.5,14.5,4.75,4.75,3,3,5.5,7,64,11,11,12.5,12.5,34,21,21,13.5,5,5,6.5,12.5,12.5,4.75,18,18,24,13.42,13.42,17.5,17.5,38,69,11,11,14,10.5,16.5,19,16.5,16.5,15,27,13,13,3,3,42,27,19,11,27.5,18,32,12,24,18,84,8.5,8.5,8.5,9.5,26.5,17,18,37,37,24,24,60,19,19,9.5,9.5,9.25,16.5,17,38,38,8.75,9,4,4,90,42,22,29.5,16,18,3,3,4.5,4.5,6,3.5,3.5,9.25,12,11.5,13,57,44,14,42,10.75,16,20,20,10.25,10.25,25,24.5,28.5,15,42.5,19,38,13,49,30,22,17,6,12,7.75,5.75,6,6,15,15.75,15.75,14.5,10.75,16,17.5,14,26,14,13,9,11.25,11.25,31,13.25,13.25,11,11,9,16,13.25,23,23,17.25,17.25,6.5,6.5,13,13,10.75,12,12,15,19.5,11,11.5,35,14.25,24.5,33,35,35,50,10.5,10.5,9,21.25,33,10.75,20,19,12,18.25,8.5,11,10,41,41,28,38,19,15,5.75,27,27,8,9,41.5,23,12,13.75,9.75,5,16,16,13.5,17,18,11.5,17,17,19,18.75,11,9.25,4.5,60,42.5,18.5,13.5,13.5,11.25,11.25,18.5,7.25,12.5,7.5,11.75,13.5,29,7.25,7.25,17,14.25,29,29,12.75,76,76,12.75,21.5,36.5,19.5,24,17.5,17.5,7.25,19,31,19.25,9,9,9,9,12.5,12.5,23,12,12,25,40.25,20,13,21,49.5,11,11,33,34,8,22,24.5,22,27,34,22.5,19,19,19,19,13.75,9,16,16,36,28,28,24,10,10,24,20,21,21,17,17,16,16,15,15,16,11.5,22,15,15,12,86,86,86,86,86,86,28,13,27,11,14.5,15,36,20.25,25.75,20.5,20.5,7.42,5.5,19,19,25,25,26,26,18,11.5,6,17.5,6,6,6.5,5.75,5.75,8,14,20.5,18.5,13.5,13,33,25,8.75,18,8.5,7.5,8,18,18,4.5,5,12.5,13,12,12,8,16,11.5,20,13.5,16,16,29.5,18,18,19,29,44,22,6.5,7,7,26,26,5.25,5.25,8,8,37,22,15,21,15,30,12,12,13,13,13,13,18,18,16,20,14,3,3,3,4,24,49,18,18,13,27,44,9,28,24,37,19.5,40,42,17.5,17.5,30,12,36,36,24,49,12,23.5,8,6,14,6,14,13,29,18,11.5,24,19,25,24,14,6,30,10,11.5,11.5,23,13.25,32,9,28,25,29,8,16.5,15.5,42,6.5,12,37,10,30,28,11,15,15,4,7,7,24,9,18.5,13,18,12,16,14,33,18,10,14,32,11.5,11.5,15,20,11,11,19,10.5,11,11,8,8,16,42,10.5,36,36,36,10,14,11,18,15.5,38,18,27,14,18,30,26,48,40,30,27,13,12,18,18,24,12.5,12.5,27,17,30,34,23,23,13,42,36,22,16.5,15,13,24.5,18,18,6,6,21.5,21,36,19,30,30,13,17,11,17,18,18,18,36,23,23,12,12,12,12,13,11,11,13,13,11.5,14.5,14,14,7.5,19.5,25,11,14,5.5,11.5,18,18,9,6,16.5,16.5,10,13.5,10,10,13.5,13.5,12,11.5,10,9.5,15.5,11,10,14,10,10,14,18,10.5,10.5,24,20,20,25,17,13,13,18,19,18,19,16,15,11.75,24,14,14,19,21,21,30,12,10,20,12,30,10,9,9,26,17,17,19,12,5,30,30,18,33,18,17,21,18,11,11,18,12,10,16,13,8.5,8.5,17,8,30,10,10,10,11,12,20,20,9,36,13,4.5,12,36,36,5,12,16,16,33,5,5,14,14,14,9,8,8,6,16,16,18,9,9,13.5,13.5,15,8,8,10,10,5.5,5.5,13,18,12,9,18,12,14,15,24,24,17,23,13,12,18,14,14,11,10,20,20,16,18,12,14,12,12,22,27,45,45,26,25,9,36,30,24,20,10,17,17,18,16,14,14,19,18,18,18,24,24,17,9,12,26,21,21,15,19,8,13,37,12,16,15,20,11,34.5,34,45,60,15,22.5,32,24,24,27,16.5,26,18.25,42,15.5,6,6,45,45,27,8,10,10,24,8,11.5,20,19.5,69,69,5,13,10.5,10.5,16.5,27.5,27.5,36,36,23.5,13.5,36,36,19,29,26.5,24,24,26.5,26.5,9.75,11,17,10,14.25,14.25,33,5.5,7,7,11,30,8.5,13.25,15,11.5,39,19.5,14,12.5,7,7,22.25,4,20,10.25,10.25,7.5,7.5,7.5,20,15,9.25,9.25,12,12,14.25,17,17,16,6.5,14.75,32,35,13.25,18,13.5,34,40,12,11.75,16.5,13,19.5,14.5,27,13.5,9.5,16.5,16.5,32,22,12,12.25,31,11,29,17,33,20,20,15,8,36,33,27,27,27,22,22,7,9.5,9.5,30,18,7,7,13,9,9,5.5,9.5,12,19.5,14.5,36,36,19.5,4.75,4.75,30,25,13,10.25,14.5,14.5,26.5,29,29,9,21,20,19,11,26,14.66,14.66,19.5,24,19,19,6.5,18,43,22.5,24,24,18.5,18.5,16,16,11.75,28,27,27,46,47,30,30,12,22.5,16,34,25,26.5,42,36,23.5,12,23.5,11,72,72,36,47,48,48,72,72,18,27,27,22,24,24,19,14.6,24,20,18,13,24,27,27],""z"":[5.88610403145016,1.79175946922805,2.484906649788,1.79175946922805,1.79175946922805,2.19722457733622,2.484906649788,2.484906649788,3.17805383034795,1.79175946922805,1.79175946922805,0.262364264467491,0.262364264467491,0.262364264467491,2.484906649788,4.60517018598809,4.60517018598809,2.484906649788,2.484906649788,2.484906649788,1.79175946922805,2.484906649788,2.484906649788,2.484906649788,5.75257263882563,5.75257263882563,4.07753744390572,3.58351893845611,3.71357206670431,5.6970934865054,5.48063892334199,6.05678401322862,4.78749174278205,4.14313472639153,5.07517381523383,6.21460809842219,4.94875989037817,5.82894561761021,5.01727983681492,5.01063529409626,5.7037824746562,3.87120101090789,4.21950770517611,4.21950770517611,3.17805383034795,3.17805383034795,2.07944154167984,3.63758615972639,3.17805383034795,3.17805383034795,2.19722457733622,2.19722457733622,3.17805383034795,3.58351893845611,2.19722457733622,3.61091791264422,3.58351893845611,3.17805383034795,3.17805383034795,4.97673374242057,3.93182563272433,3.58351893845611,3.58351893845611,4.78749174278205,4.27666611901606,4.9416424226093,4.31748811353631,4.31748811353631,3.40119738166216,3.40119738166216,4.0943445622221,2.484906649788,3.17805383034795,1.09861228866811,5.74300318780948,6.90775527898214,5.74300318780948,5.88610403145016,3.69137633431252,5.01063529409626,6.21860011969173,5.11198778835654,6.38856140554563,5.91350300563827,5.48272008954582,3.2188758248682,3.2188758248682,5.02388052084628,5.4380793089232,5.85793315448346,4.4188406077966,4.27666611901606,4.0943445622221,3.80666248977032,3.80666248977032,6.08677472691231,5.30081424674662,5.30081424674662,6.27664348934164,7.51887862406349,7.51887862406349,8.0179667034936,8.0179667034936,6.90815519900346,6.68473671985608,5.91620206260743,5.91620206260743,6.47866324024282,6.47866324024282,6.04263283368238,6.04263283368238,6.41673228251233,6.41673228251233,6.40522845803084,6.40522845803084,6.5510803350434,6.5510803350434,6.91572344863131,6.90775527898214,6.21480807842486,4.2780540442909,3.18221184049661,2.46809953147162,2.46809953147162,2.46809953147162,2.46809953147162,3.58351893845611,4.9416424226093,3.28091121578765,3.28091121578765,4.09600984154116,2.89591193827178,4.60517018598809,3.91202300542815,3.91202300542815,2.41591377830105,5.39408198853242,5.09497644253001,5.52146091786225,3.62434093297637,3.62434093297637,4.60517018598809,3.49650756146648,4.89034912822175,1.79175946922805,2.484906649788,3.91202300542815,2.89037175789616,2.89037175789616,4.27666611901606,1.79175946922805,1.79175946922805,1.79175946922805,1.79175946922805,3.58351893845611,6.68586094706836,5.01063529409626,5.99146454710798,5.48063892334199,6.25382881157547,5.87211778947542,4.62497281328427,1.79175946922805,4.27666611901606,5.94017125272043,6.68586094706836,4.38202663467388,3.68887945411394,1.79175946922805,4.969813299576,3.2188758248682,3.87120101090789,4.38202663467388,4.38202663467388,5.01063529409626,4.23410650459726,3.58351893845611,3.58351893845611,3.68887945411394,4.56434819146784,3.17805383034795,2.484906649788,4.0943445622221,5.7037824746562,6.21860011969173,6.26530121273771,4.11087386417331,5.29831736654804,5.63478960316925,6.21260609575152,5.70711026474888,3.13549421592915,2.19722457733622,3.61091791264422,2.70805020110221,2.484906649788,2.07944154167984,2.07944154167984,2.19722457733622,1.6094379124341,1.79175946922805,1.6094379124341,1.79175946922805,1.09861228866811,5.19295685089021,3.91202300542815,6.20455776256869,5.99146454710798,2.77258872223978,6.00388706710654,5.9427993751267,7.55013534248843,5.76832099579377,6.43615036836943,5.99396142730657,5.99396142730657,6.36475075685191,6.02102334934953,5.52545293913178,7.78322401633604,6.62007320653036,6.62007320653036,6.85646198459459,5.99396142730657,4.38202663467388,5.605802066296,5.41610040220442,5.41610040220442,3.68887945411394,3.68887945411394,4.86753445045558,4.86753445045558,5.4380793089232,4.49980967033027,4.49980967033027,5.11198778835654,6.21460809842219,5.63478960316925,6.91373735065968,6.91373735065968,5.52146091786225,3.36729582998647,3.36729582998647,5.29831736654804,5.29831736654804,6.10924758276437,5.32787616878958,4.27666611901606,5.99893656194668,4.0943445622221,5.79909265446053,5.30826769740121,4.56434819146784,3.80666248977032,4.52178857704904,5.29831736654804,3.63758615972639,4.12713438504509,1.79175946922805,3.97968165390196,3.97968165390196,6.73933662735717,7.74413662762799,5.01727983681492,6.26435019031701,6.26435019031701,4.60517018598809,6.10924758276437,5.01727983681492,6.10924758276437,6.10924758276437,6.10924758276437,6.10924758276437,6.05208916892442,5.29831736654804,5.29831736654804,5.74300318780948,3.73766961828337,3.89182029811063,5.99146454710798,6.90775527898214,5.74300318780948,5.29831736654804,4.48863636973214,9.39366142910322,5.71042701737487,5.71042701737487,5.54126354515843,4.27666611901606,3.68887945411394,8.69951474821019,5.30330490805908,4.33073334028633,3.87120101090789,5.71042701737487,6.53233429222235,6.53233429222235,7.28000825288419,6.17378610390194,6.59578051396131,5.99146454710798,5.99146454710798,6.39692965521615,5.7037824746562,5.7037824746562,5.71373280550937,3.87120101090789,8.51719319141624,8.24538446812075,6.40522845803084,5.24702407216049,5.24702407216049,6.90775527898214,6.17378610390194,3.68887945411394,5.29831736654804,4.85203026391962,5.42053499927229,6.39859493453521,7.21597500265147,5.19295685089021,4.31748811353631,4.0943445622221,6.74875954749168,5.70544775397526,5.70544775397526,4.34380542185368,5.7037824746562,6.72743172485086,6.72743172485086,6.55250788703459,5.7037824746562,5.7037824746562,6.68461172766793,5.73657229747919,6.24027584517077,7.00306545878646,5.48063892334199,5.99146454710798,8.1318247850072,7.49609734517596,7.35500192110526,6.40522845803084,6.40522845803084,7.05185562295589,6.5510803350434,5.48063892334199,5.01063529409626,3.97029191355212,4.89034912822175,6.94263968083564,6.94263968083564,5.01727983681492,4.38202663467388,7.9373746961633,7.82404601085629,8.88211404420882,8.49699048409872,7.34083555412327,5.03695260241363,6.80239476332431,7.49554194388426,6.44571981938558,7.60090245954208,4.0943445622221,4.78749174278205,8.91058571829013,8.76795190976342,7.90100705199242,6.90875477931522,7.15070145759253,7.15070145759253,6.96602418710611,5.7037824746562,5.4971682252932,3.91202300542815,8.03947991910045,7.78322401633604,7.05703698169789,8.70284253830287,6.5510803350434,6.5510803350434,6.46302945692067,6.47697236288968,3.68887945411394,3.68887945411394,9.72316399840485,8.52931937121408,8.52218073292728,7.83201418050547,5.99146454710798,5.82894561761021,7.61085279039525,8.98869569678571,7.84990867038202,7.84990867038202,7.37775890822787,7.00306545878646,8.49923286603924,3.87120101090789,3.87120101090789,4.969813299576,7.64969262371151,7.2152399787301,7.2152399787301,7.3132203870903,7.3132203870903,6.91869521902047,6.74641212857337,6.74641212857337,8.16337131645991,6.26909628370626,5.30330490805908,9.17055950196434,6.68586094706836,7.7873820264847,7.82404601085629,6.80239476332431,7.82404601085629,7.32974968904151,7.32974968904151,5.41610040220442,5.41610040220442,5.02058562494942,5.02058562494942,4.9416424226093,4.27666611901606,3.40119738166216,3.40119738166216,5.73657229747919,4.27666611901606,6.06610809010375,6.06610809010375,3.97029191355212,4.34380542185368,5.08759633523238,4.49980967033027,6.21660610108486,4.11087386417331,6.80516869020704,6.80516869020704,8.1886891244442,7.31588350450979,6.91274282049318,5.60947179518496,5.62762111369064,5.52744298953979,5.52744298953979,6.47697236288968,4.65396035015752,4.16666522380173,4.16666522380173,4.38202663467388,5.74300318780948,4.84024230816757,4.84024230816757,3.58351893845611,3.58351893845611,3.58351893845611,3.58351893845611,3.58351893845611,3.58351893845611,3.58351893845611,3.58351893845611,3.58351893845611,3.58351893845611,3.58351893845611,3.58351893845611,3.58351893845611,3.58351893845611,3.58351893845611,3.58351893845611,3.58351893845611,3.58351893845611,3.58351893845611,3.58351893845611,6.08677472691231,5.29831736654804,5.29831736654804,6.47774129795256,6.47774129795256,3.87120101090789,6.1779441140506,6.29341927884648,3.61091791264422,6.17378610390194,3.61091791264422,6.90775527898214,4.56434819146784,5.72031177660741,4.38202663467388,4.38202663467388,7.86901937649902,6.96129604591017,6.21460809842219,6.5510803350434,5.16478597392351,3.17805383034795,4.78749174278205,4.31748811353631,4.31748811353631,4.11087386417331,4.11087386417331,4.60517018598809,3.80666248977032,3.40119738166216,8.52118521268578,7.43838353004431,7.78447323573647,7.09007683577609,6.38856140554563,6.38856140554563,5.56452040732269,5.29831736654804,5.39362754635236,5.39362754635236,4.8283137373023,5.42934562895444,5.42934562895444,4.17438726989564,4.17438726989564,4.20469261939097,4.20469261939097,4.24849524204936,4.24849524204936,4.60517018598809,4.60517018598809,5.2257466737132,5.48063892334199,5.8406416573734,8.2725706084249,7.88231491898027,4.0943445622221,4.0943445622221,5.73657229747919,6.59714570188665,4.18205014264121,4.18205014264121,6.45204895443723,5.19849703126583,4.86753445045558,5.50125821054473,5.95064255258773,5.52942908751142,4.86753445045558,5.34710753071747,3.40119738166216,4.65681341913993,4.65681341913993,4.65681341913993,4.65681341913993,3.29583686600433,4.78749174278205,4.36944785246702,4.27666611901606,3.98898404656427,3.63758615972639,3.76120011569356,2.63905732961526,2.89037175789616,2.70805020110221,4.63472898822964,5.07517381523383,2.89037175789616,2.484906649788,1.09861228866811,2.07944154167984,1.79175946922805,2.484906649788,1.38629436111989,2.77258872223978,1.09861228866811,2.19722457733622,3.3322045101752,0,1.79175946922805,1.94591014905531,1.38629436111989,1.38629436111989,1.09861228866811,2.89037175789616,2.89037175789616,0,2.19722457733622,1.6094379124341,1.09861228866811,2.07944154167984,2.07944154167984,4.29045944114839,1.38629436111989,1.38629436111989,1.09861228866811,1.09861228866811,1.09861228866811,1.09861228866811,1.09861228866811,2.39789527279837,2.19722457733622,2.30258509299405,1.25276296849537,1.25276296849537,0,2.19722457733622,3.61091791264422,3.61091791264422,3.17805383034795,3.17805383034795,2.484906649788,2.484906649788,2.70805020110221,2.89037175789616,0.693147180559945,0,0,3.36729582998647,2.39789527279837,3.02042488614436,3.02042488614436,2.484906649788,2.484906649788,2.484906649788,1.09861228866811,1.79175946922805,3.2188758248682,1.79175946922805,2.99573227355399,1.25276296849537,1.25276296849537,2.19722457733622,1.09861228866811,3.63758615972639,2.94443897916644,2.94443897916644,2.19722457733622,2.19722457733622,1.09861228866811,1.09861228866811,3.40119738166216,1.6094379124341,0.405465108108164,2.63905732961526,3.49650756146648,1.94591014905531,2.07944154167984,0.693147180559945,0.693147180559945,0.693147180559945,1.09861228866811,4.69134788222914,3.3322045101752,4.29045944114839,2.19722457733622,2.19722457733622,2.19722457733622,2.484906649788,0.693147180559945,0.693147180559945,1.94591014905531,1.38629436111989,2.484906649788,2.484906649788,1.94591014905531,2.99573227355399,1.94591014905531,1.94591014905531,2.484906649788,2.484906649788,0.405465108108164,1.09861228866811,1.6094379124341,2.19722457733622,1.62924053973028,1.62924053973028,1.62924053973028,1.62924053973028,1.62924053973028,1.62924053973028,1.62924053973028,1.62924053973028,1.62924053973028,1.62924053973028,0,1.09861228866811,1.79175946922805,1.79175946922805,2.70805020110221,1.79175946922805,1.79175946922805,1.09861228866811,1.94591014905531,6.70318811324086,5.52146091786225,5.01727983681492,4.0943445622221,6.39692965521615,4.56434819146784,4.78749174278205,5.29831736654804,5.99146454710798,4.60517018598809,3.87120101090789,4.78749174278205,4.969813299576,3.87120101090789,4.60517018598809,6.39692965521615,6.80239476332431,4.78749174278205,5.48063892334199,5.48063892334199,5.99146454710798,3.87120101090789,3.87120101090789,4.78749174278205,4.27666611901606,6.90775527898214,6.90775527898214,6.90775527898214,4.60517018598809,4.60517018598809,4.60517018598809,5.7037824746562,6.39692965521615,4.9416424226093,5.29831736654804,3.87120101090789,4.56434819146784,2.484906649788,2.484906649788,5.29831736654804,5.7037824746562,4.78749174278205,4.60517018598809,2.30258509299405,2.30258509299405,2.30258509299405,2.30258509299405,2.30258509299405,2.30258509299405,2.30258509299405,2.30258509299405,2.30258509299405,2.30258509299405,2.30258509299405,2.30258509299405,2.30258509299405,2.30258509299405,3.87120101090789,3.3322045101752,3.3322045101752,3.3322045101752,3.3322045101752,3.3322045101752,3.3322045101752,4.27666611901606,4.60517018598809,3.17805383034795,3.17805383034795,3.17805383034795,4.27666611901606,3.17805383034795,3.17805383034795,2.30258509299405,6.80239476332431,5.99146454710798,3.58351893845611,3.58351893845611,4.60517018598809,4.60517018598809,3.87120101090789,5.01063529409626,4.78749174278205,4.78749174278205,3.17805383034795,4.78749174278205,5.29831736654804,3.17805383034795,3.87120101090789,3.87120101090789,4.78749174278205,5.29831736654804,3.40119738166216,5.29831736654804,4.0943445622221,4.0943445622221,6.90775527898214,5.29831736654804,4.27666611901606,3.17805383034795,3.17805383034795,2.484906649788,4.56434819146784,6.90775527898214,2.89037175789616,2.89037175789616,4.60517018598809,4.78749174278205,4.0943445622221,4.60517018598809,4.27666611901606,4.78749174278205,5.29831736654804,3.87120101090789,3.40119738166216,3.91202300542815,3.40119738166216,4.0943445622221,4.0943445622221,4.0943445622221,4.0943445622221,3.68887945411394,3.68887945411394,3.40119738166216,3.40119738166216,3.40119738166216,3.40119738166216,3.40119738166216,3.87120101090789,3.87120101090789,3.87120101090789,3.87120101090789,3.40119738166216,2.70805020110221,2.70805020110221,2.484906649788,1.79175946922805,1.79175946922805,4.27666611901606,4.27666611901606,6.39692965521615,5.7037824746562,5.7037824746562,3.17805383034795,1.79175946922805,2.484906649788,3.17805383034795,2.89037175789616,4.60517018598809,4.60517018598809,4.60517018598809,4.60517018598809,4.60517018598809,4.60517018598809,4.60517018598809,4.60517018598809,4.78749174278205,2.484906649788,6.39692965521615,4.78749174278205,4.43081679884331,4.60517018598809,4.60517018598809,2.19722457733622,2.19722457733622,1.79175946922805,3.40119738166216,3.17805383034795,3.17805383034795,4.60517018598809,3.17805383034795,3.87120101090789,4.27666611901606,3.87120101090789,4.27666611901606,2.484906649788,6.85646198459459,7.7873820264847,7.1066061377273,7.650168700845,8.0774471493312,6.90775527898214,9.77195416257428,7.34213173058472,5.30330490805908,7.12286665859908,6.21860011969173,5.44457987352629,5.44457987352629,6.21460809842219,7.24494154633701,7.24494154633701,9.12695876303713,7.49554194388426,7.09090982207998,7.09090982207998,8.6569551337914,6.62073965107352,6.62073965107352,8.53699581871242,9.79979231619736,8.88875674784872,7.4265490723973,6.77422388635761,9.28730141311231,8.73552518573323,8.54578064826815,8.38974610892351,8.38974610892351,8.38974610892351,8.61250337122056,7.21744343169653,9.58603332175068,7.74066440191724,7.74066440191724,7.82404601085629,7.82404601085629,6.68461172766793,7.46765674039472,7.46765674039472,6.40025744530882,6.40025744530882,9.04782144247841,7.60090245954208,7.60090245954208,8.07558263667172,7.2086003379602,7.9229859587112,8.03915739047324,6.18208490671663,6.10479323241498,7.3132203870903,7.09007683577609,8.69951474821019,6.34212141872115,6.34212141872115,8.00969535774292,8.03915739047324,8.03915739047324,5.7037824746562,5.76832099579377,4.38202663467388,4.38202663467388,4.44265125649032,4.44265125649032,7.97762509878459,7.97762509878459,6.47697236288968,5.25749537202778,6.03068526026126,6.03068526026126,9.90348755253613,9.3943272080892,6.55250788703459,7.3004728142678,7.52294091807237,8.8246778911642,8.1605182474775,7.09340462586877,7.09007683577609,7.60115242829729,7.60115242829729,9.01821087419114,7.43838353004431,8.03915739047324,5.89440283426485,5.89440283426485,6.13122648948314,6.13122648948314,6.75693238924755,5.29831736654804,5.36129216570943,5.01063529409626,3.2188758248682,3.2188758248682,8.1605182474775,8.41183267575841,4.78749174278205,7.90137735379262,4.9416424226093,6.39859493453521,5.63478960316925,5.53733426701854,6.90775527898214,6.90775527898214,8.92930284224307,6.21460809842219,6.0913098820777,6.40025744530882,5.7037824746562,4.8283137373023,4.8283137373023,5.44673737166631,7.09007683577609,6.21660610108486,6.05208916892442,7.32646561384032,6.5792512120101,6.75809450442773,5.01063529409626,6.21660610108486,6.68586094706836,4.78749174278205,4.86753445045558,4.07753744390572,6.69950034016168,3.87120101090789,6.54965074223381,3.89182029811063,3.89182029811063,6.01615715969835,6.95654544315157,6.16436688198544,6.16436688198544,6.11146733950268,6.00635315960173,4.27666611901606,5.52345892052492,5.52345892052492,5.90808293816893,5.01727983681492,5.56068163101553,5.56068163101553,2.70805020110221,9.11052003669397,7.49554194388426,5.99146454710798,6.90875477931522,6.68710860786651,4.60517018598809,5.07517381523383,5.52146091786225,5.52146091786225,4.27666611901606,5.71042701737487,3.17805383034795,7.60090245954208,5.37527840768417,6.23539063760472,6.23539063760472,6.62007320653036,4.60517018598809,4.60517018598809,6.0591231955818,6.0591231955818,5.99146454710798,6.5792512120101,5.7037824746562,5.02388052084628,6.10924758276437,3.73766961828337,7.82424599085896,7.82424599085896,6.21460809842219,4.27666611901606,4.49980967033027,6.68461172766793,5.7037824746562,5.76832099579377,6.64639051484773,6.64639051484773,7.74066440191724,8.46589989702869,6.85646198459459,3.91202300542815,3.91202300542815,6.68461172766793,6.39692965521615,5.19295685089021,5.19295685089021,4.78749174278205,4.49980967033027,5.03695260241363,4.0943445622221,4.0943445622221,4.38202663467388,1.6094379124341,1.79175946922805,5.29831736654804,5.29831736654804,4.70048036579242,4.78749174278205,5.01063529409626,5.01063529409626,4.969813299576,4.0943445622221,5.30330490805908,5.01063529409626,5.99146454710798,5.41610040220442,5.41610040220442,6.80239476332431,5.99146454710798,3.55534806148941,5.52146091786225,5.99146454710798,4.60517018598809,4.60517018598809,4.38202663467388,5.48893772615669,5.7037824746562,6.80350525760834,6.39692965521615,3.87120101090789,5.25749537202778,5.7037824746562,4.56434819146784,4.60517018598809,3.98898404656427,5.01063529409626,3.41772668361337,3.41772668361337,4.99043258677874,3.91202300542815,3.91202300542815,6.05208916892442,3.68887945411394,3.91202300542815,4.8283137373023,4.56434819146784,4.29045944114839,3.73766961828337,4.49980967033027,5.37527840768417,5.63478960316925,4.78749174278205,2.99573227355399,6.17378610390194,5.99021376520633,5.99021376520633,3.23867845216438,3.23867845216438,4.49980967033027,5.79605775076537,5.99146454710798,5.48063892334199,3.40119738166216,3.68887945411394,3.91202300542815,3.91202300542815,4.60517018598809,4.31748811353631,4.18965474202643,4.94875989037817,5.44241771052179,3.49650756146648,3.68887945411394,3.68887945411394,3.87120101090789,3.87120101090789,2.70805020110221,2.70805020110221,3.04452243772342,2.89037175789616,2.89037175789616,3.58351893845611,3.40119738166216,3.40119738166216,4.60517018598809,4.11087386417331,2.94443897916644,4.49980967033027,4.49980967033027,4.60517018598809,4.79579054559674,5.42934562895444,4.84418708645859,5.13579843705026,3.58351893845611,4.81218435537242,5.01063529409626,5.03043792139244,5.12396397940326,4.60517018598809,4.60517018598809,4.49980967033027,4.53259949315326,4.59511985013459,4.60517018598809,4.27666611901606,3.87120101090789,3.61091791264422,5.99146454710798,4.02535169073515,4.11087386417331,5.29831736654804,3.25809653802148,2.07944154167984,5.14749447681345,3.04452243772342,3.76120011569356,4.38202663467388,3.43398720448515,3.43398720448515,4.27666611901606,3.17805383034795,3.89182029811063,3.68887945411394,4.56434819146784,3.87120101090789,4.27666611901606,2.70805020110221,3.63758615972639,3.68887945411394,4.31748811353631,3.17805383034795,3.91202300542815,3.91202300542815,2.70805020110221,4.78749174278205,4.78749174278205,5.52146091786225,5.7037824746562,5.52345892052492,5.52345892052492,6.5510803350434,6.16751649088834,5.52146091786225,5.52146091786225,5.19295685089021,5.01727983681492,7.37775890822787,6.49526555593701,7.00306545878646,6.98378996525813,6.62007320653036,5.07517381523383,5.29831736654804,6.5510803350434,6.05208916892442,4.86753445045558,7.27931883541462,4.86753445045558,5.85793315448346,4.20469261939097,5.57594910314632,4.56434819146784,3.96081316959758,3.96081316959758,4.15888308335967,6.76849321164863,5.52545293913178,6.62007320653036,4.38202663467388,3.55534806148941,4.31748811353631,2.99573227355399,2.99573227355399,3.55534806148941,4.78749174278205,3.68887945411394,3.68887945411394,6.72142570079064,5.52942908751142,6.10924758276437,4.31748811353631,6.39692965521615,6.39692965521615,4.31748811353631,4.13516655674236,4.13516655674236,2.77258872223978,2.77258872223978,3.68887945411394,3.17805383034795,3.17805383034795,4.27666611901606,6.03787091992214,3.48124008933569,3.48124008933569,4.38202663467388,2.70805020110221,5.38449506278909,4.49980967033027,5.59842195899838,5.15329159449778,5.15329159449778,5.48063892334199,4.0943445622221,2.484906649788,4.78749174278205,5.30081424674662,5.30081424674662,3.91202300542815,5.32787616878958,3.98898404656427,2.7408400239252,2.7408400239252,5.48063892334199,5.7037824746562,4.69592454925656,4.69592454925656,4.31748811353631,5.53338948872752,5.48893772615669,3.87120101090789,4.87519732320115,2.19722457733622,3.40119738166216,3.63758615972639,2.70805020110221,3.19867311755068,3.19867311755068,2.19722457733622,5.08140436498446,3.58351893845611,4.45434729625351,4.61512051684126,3.46573590279973,3.46573590279973,3.3322045101752,3.3322045101752,4.38202663467388,2.70805020110221,3.87120101090789,4.31748811353631,4.31748811353631,2.70805020110221,5.32787616878958,5.32787616878958,5.37063802812766,5.37063802812766,4.0943445622221,4.0943445622221,3.78418963391826,4.60517018598809,5.24702407216049,5.24702407216049,4.78749174278205,4.29045944114839,4.38202663467388,3.40119738166216,3.40119738166216,4.36944785246702,5.52146091786225,5.52146091786225,4.60517018598809,4.60517018598809,7.52294091807237,4.04305126783455,6.90775527898214,3.91202300542815,3.40119738166216,6.13122648948314,5.22035582507832,3.91202300542815,5.79605775076537,5.01063529409626,6.39359075395063,3.40119738166216,5.08140436498446,4.78749174278205,5.10594547390058,8.21635833238616,5.35658627467201,5.87211778947542,3.89182029811063,6.39692965521615,5.7037824746562,5.94148617730174,5.94148617730174,6.68461172766793,6.68461172766793,5.01063529409626,5.34710753071747,7.00760061395185,8.10167774745457,6.62140565176413,6.30991827822652,5.19295685089021,5.56068163101553,4.78749174278205,5.7037824746562,7.52294091807237,6.90975328164481,5.5683445037611,5.5683445037611,3.76120011569356,7.45066079621154,5.25749537202778,4.02535169073515,5.72031177660741,6.10924758276437,4.52178857704904,6.80239476332431,5.31811999384422,5.39362754635236,4.38202663467388,4.56434819146784,5.31320597904179,4.78749174278205,3.43398720448515,3.17805383034795,3.68887945411394,3.25809653802148,3.58351893845611,3.58351893845611,5.56068163101553,6.5792512120101,6.60800062529609,6.68461172766793,6.1527326947041,6.19440539110467,6.31264183869356,6.31264183869356,6.21460809842219,6.40025744530882,5.48063892334199,8.69951474821019,6.36647044773144,5.37527840768417,7.14834574390007,3.69386699562498,3.69386699562498,3.69386699562498,4.0943445622221,2.70805020110221,6.04025471127741,5.82894561761021,5.82894561761021,6.13339804299665,3.71357206670431,5.99146454710798,7.46737106691756,7.20785987143248,6.8351845861473,7.01211529430638,6.21660610108486,5.52146091786225,5.52146091786225,8.5173931714189,7.78322401633604,5.77455154554441,5.48063892334199,8.69968140098951,8.0802374162167,8.29379960884682,6.39692965521615,6.90975328164481,4.83628190695148,6.75809450442773,7.82404601085629,7.82404601085629,7.52833176670725,6.68461172766793,4.80402104473326,7.03878354138854,7.09007683577609,6.58617165485467,4.02535169073515,6.7093043402583,8.22951111896446,7.10414409298753,5.30826769740121,5.93753620508243,6.19236248947487,7.52402141520612,6.04025471127741,6.77992190747225,7.74500280351584,4.56434819146784,4.9416424226093,4.65396035015752,4.65396035015752,5.07517381523383,6.43615036836943,6.63463335786169,5.7037824746562,4.86753445045558,6.06378520868761,6.06378520868761,6.90675477864855,6.48616078894409,5.4380793089232,5.48893772615669,4.56434819146784,6.23441072571837,6.23441072571837,6.39692965521615,7.3132203870903,4.61512051684126,7.09007683577609,7.09090982207998,8.27384693278451,5.19295685089021,5.19295685089021,5.7037824746562,6.75285431776417,6.75285431776417,6.80239476332431,6.80239476332431,5.24702407216049,5.24702407216049,6.8351845861473,5.07517381523383,6.39692965521615,5.07517381523383,6.90875477931522,6.73578001424233,8.27512163021651,8.27512163021651,7.7621706071382,5.4402508624367,5.4402508624367,6.5510803350434,5.7037824746562,5.7037824746562,7.27931883541462,6.50428817353665,6.47697236288968,6.47697236288968,5.48063892334199,5.48063892334199,6.59304453414244,6.59304453414244,5.29831736654804,5.19295685089021,5.19295685089021,3.58351893845611,3.66356164612965,5.01063529409626,5.01063529409626,3.17805383034795,3.17805383034795,5.07517381523383,3.40119738166216,4.49980967033027,2.484906649788,2.484906649788,4.44265125649032,4.44265125649032,5.13579843705026,4.38202663467388,3.40119738166216,4.35670882668959,5.16478597392351,4.60517018598809,3.87120101090789,5.19849703126583,5.54517744447956,5.50938833662798,4.61015772749913,4.61015772749913,6.3297209055227,5.39816270151775,2.89037175789616,2.89037175789616,4.14313472639153,4.14313472639153,2.19722457733622,4.27666611901606,4.70048036579242,2.70805020110221,2.89037175789616,3.76120011569356,2.89037175789616,2.56494935746154,2.99573227355399,4.38202663467388,2.89037175789616,2.89037175789616,2.89037175789616,2.89037175789616,2.484906649788,3.68887945411394,2.77258872223978,3.52636052461616,3.52636052461616,6.80239476332431,4.44265125649032,4.44265125649032,4.27666611901606,1.6094379124341,1.79175946922805,5.48479693349065,4.27666611901606,3.43398720448515,3.87120101090789,7.90100705199242,6.95654544315157,6.95654544315157,7.69621263934641,5.50938833662798,6.48004456192665,5.53338948872752,5.35658627467201,6.17378610390194,5.6021188208797,4.78749174278205,5.52545293913178,6.39692965521615,6.80239476332431,5.29831736654804,5.605802066296,3.8286413964891,4.66343909411207,4.00733318523247,4.80402104473326,5.04985600724954,3.40119738166216,3.58351893845611,4.24849524204936,2.89037175789616,4.07753744390572,4.27666611901606,2.52572864430826,2.52572864430826,2.30258509299405,5.34710753071747,2.484906649788,3.68887945411394,4.49980967033027,3.80666248977032,3.80666248977032,3.68887945411394,5.53733426701854,4.27666611901606,4.60517018598809,4.60517018598809,5.86078622346587,4.29045944114839,4.68213122712422,4.34380542185368,3.43398720448515,3.27714473299218,3.27714473299218,3.3322045101752,3.3322045101752,2.484906649788,5.69035945432406,4.26267987704132,4.59511985013459,4.39444915467244,2.30258509299405,2.30258509299405,3.76120011569356,2.7408400239252,4.78749174278205,3.93182563272433,3.3499040872746,3.3499040872746,2.70805020110221,4.9416424226093,4.9416424226093,4.32413265625498,4.32413265625498,5.19849703126583,3.87120101090789,3.63758615972639,2.63905732961526,2.63905732961526,4.27666611901606,4.00733318523247,4.27666611901606,2.63905732961526,7.17011954344963,2.89037175789616,4.69134788222914,2.70805020110221,6.47697236288968,2.484906649788,4.51085950651685,3.17805383034795,4.9416424226093,2.70805020110221,3.66356164612965,2.19722457733622,6.34124074935556,6.34124074935556,6.56667242980324,3.17805383034795,4.38202663467388,3.95124371858143,2.484906649788,4.9416424226093,5.70544775397526,5.70544775397526,4.40671924726425,3.52636052461616,8.69951474821019,8.13153071060425,7.60140233458373,8.10167774745457,8.10167774745457,7.90193254951336,7.90193254951336,5.80211837537706,4.0943445622221,4.74493212836325,4.74493212836325,4.86753445045558,5.29581423632992,5.29581423632992,3.13549421592915,2.07944154167984,8.14627442706066,8.14627442706066,3.55534806148941,3.55534806148941,4.51085950651685,3.66356164612965,3.66356164612965,3.49650756146648,5.94017125272043,3.43398720448515,2.94443897916644,2.19722457733622,1.09861228866811,2.56494935746154,2.56494935746154,4.35670882668959,3.29583686600433,5.89164421182577,3.55534806148941,5.52545293913178,6.90775527898214,9.39266192877014,5.31811999384422,5.25749537202778,5.72031177660741,5.72031177660741,7.46221493976819,5.13579843705026,5.96614673912369,5.96614673912369,7.1708884785125,4.49980967033027,4.0943445622221,4.0943445622221,5.34948565312244,5.34948565312244,4.44265125649032,4.44265125649032,3.17805383034795,3.17805383034795,3.58351893845611,3.29583686600433,3.29583686600433,3.49650756146648,3.49650756146648,3.58351893845611,5.76832099579377,5.76832099579377,6.44571981938558,6.44571981938558,5.19295685089021,5.19295685089021,4.17438726989564,4.17438726989564,3.87120101090789,3.87120101090789,5.4380793089232,5.4380793089232,7.53849499941346,6.38856140554563,5.68866883684615,5.68866883684615,5.48063892334199,5.48063892334199,3.63758615972639,6.40687998606931,6.51693244761084,6.51693244761084,7.31388683163346,7.43897159239586,6.40687998606931,5.44241771052179,5.44241771052179,3.87120101090789,4.86753445045558,4.24849524204936,4.24849524204936,5.48063892334199,5.48063892334199,6.041444479413,6.041444479413,5.51945891519157,5.51945891519157,5.29831736654804,5.39362754635236,7.60090245954208,7.60090245954208,6.68461172766793,5.99146454710798,5.99146454710798,5.31073988654659,5.31073988654659,6.39692965521615,5.88610403145016,5.88610403145016,5.04342511691925,5.04342511691925,5.52146091786225,5.52146091786225,5.52146091786225,5.52146091786225,5.19295685089021,7.24422751560335,5.56068163101553,5.19573077777294,5.19573077777294,6.80239476332431,5.56068163101553,4.29045944114839,9.52515111181622,8.69951474821019,6.52209279817015,7.57609734062311,7.57609734062311,7.3132203870903,7.3132203870903,5.54126354515843,5.54126354515843,8.22951111896446,7.10332206252611,7.31388683163346,6.71538338633468,6.80239476332431,6.00388706710654,6.00388706710654,10.2750511089686,9.30565055178051,8.48052920704465,7.49831587076698,7.49831587076698,7.78530518253986,6.62007320653036,6.62007320653036,6.90775527898214,6.90775527898214,7.05185562295589,6.96129604591017,7.43838353004431,7.60090245954208,6.21460809842219,6.13122648948314,6.42324696353352,6.42324696353352,6.10924758276437,6.10924758276437,5.94017125272043,5.94017125272043,6.33682573114644,5.52146091786225,5.52146091786225,5.52146091786225,5.52146091786225,5.70711026474888,6.1892902904379,6.1892902904379,5.85793315448346,8.36637030168165,8.00636756765025,5.7037824746562,8.69951474821019,7.1777824161952,10.1581297709097,7.15929190479756,7.15929190479756,7.34601020991329,5.20675017302255,5.20675017302255,8.7826296549207,8.68287710705717,8.00720055395414,8.00720055395414,8.04237800517328,8.41183267575841,7.69757534680234,7.69757534680234,7.20042489294496,7.20042489294496,6.98471632011827,6.68586094706836,7.57558465155779,6.98193467715639,6.89264164117209,6.89264164117209,7.30518821539304,7.30518821539304,5.61858762859297,5.61858762859297,5.9427993751267,5.68187763926815,5.68187763926815,5.73657229747919,6.99025650049388,6.52209279817015,6.30078579466324,5.48063892334199,6.66057514983969,5.70711026474888,5.61858762859297,5.61858762859297,8.5173931714189,8.65869275368994,6.21460809842219,9.11943049661634,9.35010231435134,8.66733584984596,8.30770596654951,7.82003798945875,7.82003798945875,7.3132203870903,5.56452040732269,4.86753445045558,6.19440539110467,6.19440539110467,6.68461172766793,6.80239476332431,6.80239476332431,5.427150238391,5.427150238391,7.49554194388426,4.11087386417331,5.29831736654804,8.33351070898294,8.3039999709552,7.49554194388426,8.13153071060425,7.34923082461333,7.09090982207998,9.61447125707121,7.60090245954208,7.60090245954208,6.90875477931522,6.90975328164481,6.28226674689601,7.3132203870903,6.40025744530882,8.39208338037339,6.39692965521615,6.39692965521615,6.39692965521615,6.39692965521615,9.75324588920559,6.90775527898214,7.60090245954208,4.43081679884331,4.43081679884331,7.17930796950403,6.21460809842219,6.21460809842219,8.47657950853094,4.0943445622221,5.24702407216049,4.31748811353631,4.27666611901606,6.19440539110467,5.7037824746562,8.29404964010203,8.29404964010203,8.29404964010203,8.29404964010203,4.78749174278205,4.78749174278205,4.3502779363593,4.3502779363593,3.31418600467253,3.31418600467253,5.26269018890489,7.80791662892641,7.3132203870903,6.44571981938558,6.62007320653036,4.90897164031976,4.90897164031976,5.96614673912369,9.04782144247841,8.69148257651293,8.69148257651293,9.21034037197618,9.20029003612268,8.30647216010058,7.26612877955645,7.60589000105312,6.80516869020704,6.80516869020704,5.04342511691925,6.21860011969173,7.0475172213573,7.0475172213573,5.63835466933375,5.70544775397526,5.70544775397526,5.99645208861902,5.88887795833288,4.04305126783455,7.17011954344963,5.29831736654804,4.60517018598809,5.01063529409626,3.40119738166216,9.42545175159313,8.07558263667172,5.29831736654804,8.00603417874901,8.78032639094661,7.60090245954208,4.969813299576,5.56452040732269,5.52545293913178,4.15888308335967,6.17378610390194,4.53259949315326,7.61134771740362,4.78749174278205,4.78749174278205,4.78749174278205,4.78749174278205,5.01727983681492,5.19295685089021,3.98898404656427,7.09007683577609,7.24494154633701,7.15461535691366,7.09007683577609,7.11476944836646,4.62497281328427,6.06842558824411,7.24422751560335,5.29831736654804,5.99146454710798,5.19295685089021,5.19295685089021,5.17897060891547,5.17897060891547,5.04985600724954,5.04985600724954,6.01615715969835,5.07517381523383,5.07517381523383,7.43838353004431,6.60665018619822,5.99146454710798,5.99146454710798,6.19440539110467,4.86753445045558,4.86753445045558,4.9416424226093,4.9416424226093,4.60517018598809,2.30258509299405,2.30258509299405,4.74493212836325,4.67282883446191,4.67282883446191,3.58351893845611,7.82564473221999,5.01063529409626,4.38202663467388,4.38202663467388,5.21493575760899,4.56434819146784,5.88610403145016,4.60517018598809,3.91202300542815,3.91202300542815,3.71357206670431,3.71357206670431,2.7408400239252,2.7408400239252,2.56494935746154,2.56494935746154,3.96081316959758,3.96081316959758,3.40119738166216,4.31748811353631,4.31748811353631,4.58496747867057,3.17805383034795,2.77258872223978,3.17805383034795,3.76120011569356,3.76120011569356,5.12396397940326,5.32300997913841,4.72738781871234,5.12396397940326,5.48063892334199,4.47163879336357,4.47163879336357,4.0517849478033,4.0517849478033,4.31748811353631,4.31748811353631,5.40267738187228,4.60517018598809,6.39692965521615,4.24849524204936,4.60517018598809,4.60517018598809,3.95124371858143,4.76217393479776,4.56434819146784,4.52178857704904,3.87120101090789,4.9416424226093,4.78749174278205,5.48063892334199,4.60517018598809,2.77258872223978,3.58351893845611,4.38202663467388,5.53338948872752,2.89037175789616,4.43081679884331,3.40119738166216,3.66356164612965,2.484906649788,2.484906649788,3.17805383034795,8.69951474821019,2.35137525716348,2.35137525716348,3.04452243772342,6.25382881157547,5.01063529409626,4.57471097850338,5.68697535633982,5.01063529409626,5.01063529409626,3.58351893845611,3.2188758248682,4.43081679884331,3.58351893845611,3.58351893845611,4.78749174278205,4.07753744390572,6.42971947803914,6.47697236288968,5.01727983681492,3.58351893845611,4.31748811353631,3.40119738166216,5.91350300563827,5.7037824746562,5.7037824746562,3.58351893845611,3.43398720448515,3.17805383034795,4.07753744390572,5.19295685089021,2.56494935746154,2.56494935746154,5.16478597392351,5.16478597392351,2.72785282839839,2.72785282839839,2.72785282839839,2.72785282839839,4.0943445622221,4.38202663467388,4.38202663467388,5.7037824746562,5.20675017302255,5.20675017302255,3.17805383034795,3.17805383034795,2.52572864430826,2.52572864430826,4.43081679884331,5.48063892334199,4.27666611901606,2.99573227355399,2.99573227355399,2.70805020110221,2.70805020110221,5.26269018890489,4.99382817577987,4.99382817577987,6.30991827822652,5.10594547390058,5.10594547390058,6.17378610390194,4.91265488573605,4.91265488573605,4.69134788222914,4.17438726989564,4.17438726989564,5.7037824746562,4.47163879336357,4.47163879336357,5.29581423632992,5.29581423632992,4.56434819146784,4.0943445622221,4.27666611901606,4.27666611901606,4.27666611901606,4.49980967033027,4.36944785246702,3.87120101090789,3.89182029811063,3.68887945411394,7.3132203870903,2.94443897916644,3.2188758248682,3.2188758248682,4.27666611901606,4.27666611901606,5.99146454710798,5.56068163101553,4.65396035015752,4.33073334028633,5.99146454710798,6.80239476332431,8.63052187672324,7.3132203870903,8.1605182474775,8.1886891244442,7.78322401633604,6.10924758276437,6.5510803350434,6.5510803350434,6.361302477573,6.74523634948436,6.85856503479136,7.25134498337221,7.9373746961633,7.9373746961633,7.13489085156588,7.13489085156588,7.00306545878646,7.3132203870903,7.3132203870903,5.7037824746562,5.7037824746562,5.52146091786225,6.46302945692067,7.3125534981026,7.82404601085629,7.82404601085629,6.68586094706836,6.90975328164481,6.39859493453521,6.39859493453521,9.21034037197618,7.49554194388426,7.3132203870903,7.09007683577609,6.21460809842219,8.79709507654906,6.62007320653036,6.62007320653036,6.43855132990697,6.43855132990697,6.78105762593618,6.39692965521615,6.39692965521615,6.89770494312864,6.32793678372919,5.94017125272043,6.81947036411457,8.47657950853094,7.62559507213245,7.64969262371151,9.24956108512946,6.65929391968364,7.55171221535131,7.71890769273299,7.71890769273299,8.60337088765729,8.60337088765729,9.25913053614561,8.85794198480471,9.21034037197618,7.78322401633604,9.21034037197618,7.31986492980897,7.58120982619635,7.09007683577609,7.00306545878646,9.21034037197618,7.09007683577609,8.00636756765025,7.60638738977265,8.48052920704465,7.49554194388426,7.12367278520461,8.49699048409872,8.49699048409872,7.11476944836646,9.14846496825809,8.84505705350085,8.79482492801452,8.13446757027756,8.00969535774292,8.99355158629998,8.63230599851674,8.13153071060425,9.64859530290734,9.10497985631836,8.74830491237962,9.47270463644367,9.47270463644367,9.20833836930551,8.77183540978982,8.77183540978982,8.51719319141624,6.39859493453521,7.24494154633701,7.37713371283395,6.42971947803914,9.39266192877014,8.98719682066197,8.57546209954021,8.57546209954021,8.29404964010203,8.29404964010203,7.82404601085629,7.82404601085629,8.51719319141624,7.97108575350561,7.91571319938212,7.78322401633604,8.68558484267669,7.50659178007084,7.10085190894405,8.63070043220983,8.98719682066197,8.69951474821019,7.34601020991329,6.85646198459459,6.85646198459459,9.22029070282935,6.90775527898214,6.90775527898214,8.764209507142,8.61250337122056,8.51919119407891,7.60090245954208,9.13776967914135,8.9159693113736,8.29404964010203,7.79152281915073,7.95647679803678,7.17011954344963,6.5792512120101,7.18916773842032,7.18916773842032,9.61580548008435,8.03915739047324,8.20111164444276,6.47697236288968,6.13122648948314,7.09423484592476,7.09423484592476,6.80239476332431,8.99961934066053,7.60090245954208,6.80239476332431,7.37775890822787,7.09007683577609,6.29156913955832,6.74817320915767,7.78405700263993,6.32793678372919,8.72469504674049,8.00736706798333,9.90348755253613,8.85366542803745,8.51719319141624,8.51719319141624,8.47637119689598,7.9373746961633,7.37650812632622,7.37775890822787,7.49554194388426,9.47278155656217,8.68287710705717,7.37838371299671,7.69666708152646,7.69666708152646,7.69848278788095,7.69848278788095,8.61431990214696,7.60090245954208,7.9373746961633,6.43133108193348,6.73340189183736,7.14677217945264,9.0825070004663,5.78382518232974,5.78382518232974,8.69951474821019,7.78322401633604,9.10586835037947,9.10586835037947,7.54960916515453,6.21460809842219,6.21460809842219,6.68710860786651,6.21460809842219,9.61580548008435,8.86799089818209,6.8351845861473,7.57584102894671,7.57584102894671,6.3297209055227,5.70711026474888,9.21034037197618,6.63358155655515,6.63358155655515,6.63358155655515,6.63358155655515,6.63358155655515,5.89989735358249,5.89989735358249,6.22851100359118,6.48463523563525,6.48463523563525,8.59415423255237,8.69951474821019,8.00636756765025,7.86326672400957,6.68461172766793,8.8246778911642,6.30991827822652,6.30991827822652,6.39859493453521,8.69951474821019,7.49554194388426,8.69951474821019,8.00703401219341,6.68461172766793,7.07326971745971,8.25322764558177,7.09340462586877,6.4377516497364,6.4377516497364,6.5510803350434,6.5510803350434,6.78332520060396,6.52795791762255,5.4553211153577,6.31082695616273,8.34283980427146,8.35936910622267,8.35936910622267,8.29379960884682,7.60090245954208,7.60090245954208,8.80986280537906,8.1605182474775,7.82404601085629,7.82404601085629,7.24422751560335,7.24422751560335,7.63506231118879,7.63506231118879,7.09423484592476,7.09423484592476,7.13169851046691,7.09090982207998,6.21460809842219,7.07326971745971,7.07326971745971,6.31082695616273,6.80239476332431,6.80239476332431,6.80239476332431,6.80239476332431,6.80239476332431,6.80239476332431,6.68461172766793,5.02388052084628,6.21860011969173,6.48844476405192,6.08677472691231,8.85794198480471,8.34283980427146,6.56526497003536,5.7037824746562,7.40853056689463,6.77992190747225,6.39692965521615,5.79909265446053,5.88610403145016,5.88610403145016,5.10594547390058,5.10594547390058,4.65396035015752,4.65396035015752,6.01615715969835,5.63478960316925,2.89037175789616,8.4144957931779,6.39692965521615,6.39692965521615,7.09007683577609,5.52146091786225,5.52146091786225,5.85793315448346,7.19368581839511,7.9728107841214,7.86326672400957,7.34665516317654,7.01211529430638,8.17723488551019,6.15060276844628,7.71423114484909,6.74641212857337,7.34601020991329,5.94017125272043,5.99645208861902,8.04622910107538,6.74758652682932,5.07517381523383,6.14203740558736,7.17011954344963,4.80402104473326,5.51745289646471,5.51745289646471,6.52209279817015,7.17011954344963,6.07534603108868,5.9427993751267,6.3456363608286,5.99146454710798,6.43294009273918,5.06259503302697,5.47855341685097,5.47855341685097,7.1770187659099,5.78382518232974,7.49498623395053,6.55250788703459,6.39692965521615,5.31320597904179,5.31320597904179,5.7037824746562,5.7037824746562,6.05326494801343,6.05326494801343,2.89037175789616,2.89037175789616,5.88610403145016,4.31748811353631,8.07090608878782,7.24422751560335,6.31173480915291,6.19440539110467,5.59656839034905,5.59656839034905,6.29156913955832,6.0137151560428,4.84811636459848,4.84811636459848,4.60517018598809,4.60517018598809,6.68586094706836,6.39692965521615,4.60517018598809,0.693147180559945,0.693147180559945,0.693147180559945,2.89037175789616,5.24174701505964,4.60517018598809,5.99645208861902,5.99645208861902,5.01063529409626,7.09007683577609,8.21608809863232,4.02535169073515,4.55387689160054,5.08140436498446,4.38202663467388,4.80402104473326,5.91350300563827,4.87519732320115,1.79175946922805,1.79175946922805,4.85981240436167,5.29831736654804,3.91202300542815,3.91202300542815,3.40119738166216,3.55534806148941,5.7268477475872,4.49980967033027,4.24849524204936,4.27666611901606,5.01063529409626,4.56434819146784,5.18738580584075,6.06842558824411,3.25809653802148,4.45434729625351,5.4380793089232,4.60517018598809,5.07517381523383,4.60517018598809,5.07517381523383,4.70953020131233,3.8286413964891,5.01727983681492,4.44265125649032,6.05208916892442,6.05208916892442,5.00394630594546,4.61512051684126,7.9373746961633,4.38202663467388,4.38202663467388,4.27666611901606,6.80350525760834,5.24702407216049,5.52146091786225,4.56434819146784,8.29404964010203,3.49650756146648,5.14166355650266,6.39526159811545,4.88280192258637,3.91202300542815,4.48863636973214,4.78749174278205,6.06378520868761,4.45434729625351,3.73766961828337,7.0475172213573,7.0475172213573,4.33073334028633,6.17378610390194,5.01727983681492,4.48863636973214,5.29831736654804,4.78749174278205,6.19644412779452,4.38202663467388,4.38202663467388,6.21660610108486,6.68586094706836,3.17805383034795,5.12396397940326,4.70048036579242,4.38202663467388,4.35670882668959,3.58351893845611,5.73657229747919,2.99573227355399,5.56068163101553,4.18965474202643,4.60517018598809,4.60517018598809,3.80666248977032,3.80666248977032,5.94017125272043,7.09506437728713,3.68887945411394,8.29404964010203,6.95654544315157,5.73657229747919,3.63758615972639,4.56434819146784,4.45434729625351,6.54965074223381,5.63478960316925,4.86753445045558,4.00733318523247,5.70711026474888,3.98898404656427,2.70805020110221,4.14313472639153,4.27666611901606,7.3132203870903,7.40245152081824,3.76120011569356,3.68887945411394,7.17011954344963,4.57471097850338,6.24416690066374,6.24416690066374,4.79579054559674,3.58351893845611,3.58351893845611,2.07944154167984,3.93182563272433,5.57215403217776,6.25190388316589,4.24849524204936,2.89037175789616,4.43081679884331,3.71357206670431,6.39692965521615,3.58351893845611,4.9416424226093,3.25809653802148,3.8286413964891,7.90100705199242,4.0943445622221,4.0943445622221,4.27666611901606,4.27666611901606,5.7037824746562,4.36944785246702,3.98898404656427,4.0943445622221,3.17805383034795,3.17805383034795,4.12713438504509,2.484906649788,3.98898404656427,3.17805383034795,2.56494935746154,2.35137525716348,2.35137525716348,5.14749447681345,4.28358656186063,4.28358656186063,3.40119738166216,3.40119738166216,4.31079912538551,4.31079912538551,4.24849524204936,3.93182563272433,3.93182563272433,3.58351893845611,3.58351893845611,2.70805020110221,6.08449941307517,3.58351893845611,3.58351893845611,4.56434819146784,3.2188758248682,3.89182029811063,2.70805020110221,5.98896141688986,1.94591014905531,2.89037175789616,3.58351893845611,3.58351893845611,4.27666611901606,3.13549421592915,2.4423470353692,2.4423470353692,3.09104245335832,2.19722457733622,2.56494935746154,2.56494935746154,3.94158180766969,3.94158180766969,4.56434819146784,1.09861228866811,5.29831736654804,4.60517018598809,5.04985600724954,4.54329478227,4.0943445622221,3.61091791264422,3.70130197411249,3.70130197411249,3.40119738166216,6.36302810354046,5.19295685089021,5.19295685089021,5.34710753071747,4.24849524204936,4.24849524204936,4.31748811353631,3.17805383034795,4.00733318523247,4.00733318523247,3.87120101090789,5.96614673912369,3.40119738166216,3.17805383034795,6.23832462503951,5.04342511691925,5.7037824746562,5.01063529409626,3.89182029811063,3.17805383034795,4.78749174278205,3.44998754583159,3.44998754583159,3.2188758248682,4.33073334028633,2.83321334405622,2.89037175789616,1.94591014905531,2.30258509299405,4.60517018598809,3.66356164612965,3.66356164612965,6.39692965521615,4.47163879336357,4.47163879336357,5.7037824746562,4.56434819146784,3.55534806148941,5.06259503302697,5.06259503302697,4.04305126783455,6.47697236288968,5.7037824746562,5.52146091786225,4.47733681447821,4.36944785246702,7.40822749066864,7.40822749066864,5.12989871492307,5.49306144334055,3.87120101090789,5.12989871492307,4.45434729625351,4.32413265625498,4.32413265625498,3.68887945411394,3.2188758248682,4.86753445045558,4.18205014264121,4.18205014264121,3.87120101090789,4.97673374242057,5.76519110278484,4.0943445622221,4.0943445622221,4.78749174278205,6.85646198459459,5.00394630594546,3.63758615972639,3.8286413964891,6.21660610108486,6.21660610108486,2.19722457733622,3.40119738166216,2.91777073208428,2.91777073208428,4.0943445622221,2.2512917986065,2.2512917986065,4.28358656186063,4.28358656186063,4.56434819146784,4.0943445622221,4.78749174278205,4.78749174278205,4.78749174278205,4.56434819146784,4.36944785246702,5.26269018890489,4.18965474202643,4.18965474202643,4.99721227376411,4.99721227376411,3.87120101090789,3.40119738166216,3.40119738166216,2.70805020110221,2.70805020110221,4.83230575857184,4.83230575857184,7.00215595440362,7.3125534981026,5.29330482472449,4.49980967033027,7.20785987143248,6.25766758788264,6.70441435496411,5.29831736654804,3.58351893845611,3.58351893845611,5.19295685089021,5.66988092298052,4.27666611901606,4.69134788222914,3.87120101090789,4.8283137373023,4.8283137373023,4.00733318523247,3.85014760171006,2.67414864942653,2.67414864942653,4.59511985013459,4.59511985013459,4.27666611901606,2.89037175789616,4.33073334028633,1.38629436111989,1.94591014905531,2.30258509299405,4.18965474202643,4.18965474202643,4.04305126783455,3.71357206670431,4.0943445622221,4.969813299576,4.38202663467388,3.87120101090789,3.58351893845611,2.89037175789616,3.52636052461616,3.52636052461616,3.04452243772342,4.04305126783455,4.68213122712422,4.68213122712422,3.36729582998647,4.78749174278205,3.40119738166216,4.68213122712422,3.17805383034795,3.40119738166216,4.30406509320417,3.36729582998647,4.27666611901606,5.04342511691925,3.87120101090789,3.87120101090789,5.85793315448346,3.58351893845611,3.17805383034795,4.27666611901606,3.58351893845611,4.27666611901606,5.01727983681492,5.52146091786225,1.79175946922805,1.09861228866811,1.09861228866811,1.79175946922805,1.09861228866811,1.38629436111989,2.70805020110221,2.77258872223978,3.36729582998647,3.68887945411394,1.09861228866811,1.79175946922805,5.77455154554441,2.56494935746154,4.38202663467388,5.48479693349065,3.91202300542815,3.23867845216438,3.23867845216438,6.10924758276437,6.10924758276437,4.0943445622221,5.70711026474888,2.52572864430826,2.52572864430826,6.10924758276437,4.80402104473326,4.65396035015752,5.01727983681492,5.17614973257383,5.04342511691925,5.04342511691925,3.09104245335832,3.04452243772342,3.17805383034795,3.17805383034795,2.30258509299405,2.19722457733622,2.19722457733622,5.7037824746562,5.99146454710798,3.40119738166216,2.30258509299405,2.52572864430826,2.52572864430826,5.07517381523383,2.30258509299405,0.693147180559945,6.21959563993323,6.21959563993323,1.09861228866811,1.09861228866811,3.87120101090789,3.68887945411394,4.04305126783455,7.39633529380081,4.60517018598809,4.60517018598809,4.07753744390572,6.39692965521615,5.2257466737132,5.2257466737132,4.9416424226093,1.79175946922805,3.17805383034795,6.68461172766793,3.40119738166216,4.27666611901606,2.56494935746154,4.38202663467388,4.78749174278205,4.79579054559674,5.427150238391,5.427150238391,6.7286286130847,6.47697236288968,5.01063529409626,2.07944154167984,2.07944154167984,4.11087386417331,1.87180217690159,1.87180217690159,3.46573590279973,2.63905732961526,4.60517018598809,4.60517018598809,4.38825718442452,4.38825718442452,3.61091791264422,3.19867311755068,3.19867311755068,1.79175946922805,2.70805020110221,3.40119738166216,3.2188758248682,4.83628190695148,4.27666611901606,2.484906649788,3.93182563272433,3.8286413964891,3.66356164612965,2.56494935746154,3.43398720448515,2.77258872223978,3.17805383034795,3.40119738166216,4.20469261939097,5.07517381523383,5.01727983681492,4.39444915467244,3.8286413964891,3.8286413964891,1.79175946922805,2.63905732961526,3.17805383034795,1.09861228866811,4.27666611901606,2.63905732961526,5.04985600724954,3.04452243772342,6.21460809842219,3.98898404656427,3.68887945411394,2.30258509299405,2.484906649788,5.52545293913178,3.68887945411394,5.07517381523383,3.68887945411394,3.68887945411394,3.02042488614436,3.02042488614436,4.11087386417331,2.30258509299405,2.30258509299405,4.99043258677874,3.66356164612965,4.97673374242057,4.97673374242057,4.27666611901606,3.17805383034795,3.17805383034795,3.04452243772342,2.99573227355399,2.484906649788,1.94591014905531,4.39444915467244,3.61091791264422,3.61091791264422,2.56494935746154,4.74493212836325,4.74493212836325,5.48063892334199,1.79175946922805,0.693147180559945,3.66356164612965,3.72569342723665,3.72569342723665,4.39444915467244,5.01396308418893,5.01396308418893,5.48063892334199,1.79175946922805,4.27666611901606,2.19722457733622,3.49650756146648,2.63905732961526,3.17805383034795,3.17805383034795,4.0943445622221,3.93182563272433,5.49921530891493,5.49921530891493,3.87120101090789,3.91202300542815,5.7037824746562,5.4380793089232,4.60517018598809,5.02388052084628,3.41772668361337,3.41772668361337,4.55387689160054,3.68887945411394,1.79175946922805,1.09861228866811,2.07944154167984,2.07944154167984,1.79175946922805,1.09861228866811,5.03043792139244,5.03043792139244,3.98898404656427,1.38629436111989,0.693147180559945,1.94591014905531,3.95124371858143,3.98898404656427,3.87120101090789,2.484906649788,4.0943445622221,2.70805020110221,1.79175946922805,4.0943445622221,5.7037824746562,5.7037824746562,4.86753445045558,5.13579843705026,5.66988092298052,5.19849703126583,5.7037824746562,5.48063892334199,4.0943445622221,2.94443897916644,1.79175946922805,1.09861228866811,5.52146091786225,5.52146091786225,5.01727983681492,3.80666248977032,4.66343909411207,3.40119738166216,2.89037175789616,3.2188758248682,4.38202663467388,1.6094379124341,1.6094379124341],""marker"":{""color"":""lightgray"",""size"":3,""alpha"":0.5,""line"":{""color"":""gray"",""width"":2}},""type"":""scatter3d"",""mode"":""markers"",""error_y"":{""color"":""rgba(31,119,180,1)""},""error_x"":{""color"":""rgba(31,119,180,1)""},""line"":{""color"":""rgba(31,119,180,1)""},""frame"":null}],""highlight"":{""on"":""plotly_click"",""persistent"":false,""dynamic"":false,""selectize"":false,""opacityDim"":0.2,""selected"":{""opacity"":1},""debounce"":0},""shinyEvents"":[""plotly_hover"",""plotly_click"",""plotly_selected"",""plotly_relayout"",""plotly_brushed"",""plotly_brushing"",""plotly_clickannotation"",""plotly_doubleclick"",""plotly_deselect"",""plotly_afterplot"",""plotly_sunburstclick""],""base_url"":""https://plot.ly""},""evals"":[],""jsHooks"":[]}</script>
+<script type=""application/htmlwidget-sizing"" data-for=""htmlwidget-1b4ff99564eb6e8884a5"">{""viewer"":{""width"":""100%"",""height"":""100%"",""padding"":0,""fill"":false},""browser"":{""width"":""100%"",""height"":""100%"",""padding"":0,""fill"":false}}</script>
+</body>
+</html>

---FILE: course-materials/slides/u2_d05-model-selection/u2_d05-model-selection.Rmd---
@@ -72,7 +72,7 @@ glance(full_model)$adj.r.squared
 
 ---
 
-```{r message=FALSE, cache=TRUE, fig.height=3,fig.width=7}
+```{r message=FALSE, cache=TRUE, out.width=""80%""}
 library(GGally)
 evals %>%
   select(score, cls_did_eval, cls_students, cls_perc_eval) %>%
@@ -87,7 +87,7 @@ other two variables (`cls_students` or `cls_perc_eval`) is least likely to
 be effective in increasing the model's predictive power?
 ]
 
-```{r echo=FALSE,message=FALSE, cache=TRUE, fig.height=3,fig.width=7}
+```{r echo=FALSE,message=FALSE, cache=TRUE, out.width=""80%""}
 library(GGally)
 evals %>%
   select(score, cls_did_eval, cls_students, cls_perc_eval) %>%

---FILE: course-materials/slides/u2_d05-model-selection/u2_d05-model-selection.html---
@@ -101,7 +101,7 @@
   ggpairs()
 ```
 
-&lt;img src=""u2_d5-model-selection_files/figure-html/unnamed-chunk-3-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d05-model-selection_files/figure-html/unnamed-chunk-3-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -111,7 +111,7 @@
 be effective in increasing the model's predictive power?
 ]
 
-&lt;img src=""u2_d5-model-selection_files/figure-html/unnamed-chunk-4-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u2_d05-model-selection_files/figure-html/unnamed-chunk-4-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 

---FILE: course-materials/slides/u2_d05-model-selection/u2_d05-model-selection_cache/html/__packages---
@@ -0,0 +1,24 @@
+base
+usethis
+devtools
+testthat
+countdown
+conflicted
+tidyverse
+ggplot2
+tibble
+tidyr
+readr
+purrr
+dplyr
+stringr
+forcats
+broom
+here
+DT
+modelr
+airports
+cherryblossom
+usdata
+openintro
+GGally

---FILE: course-materials/slides/u2_d06-model-validation/u2_d06-model-validation.Rmd---
@@ -30,6 +30,7 @@ class: middle
 
 ---
 
+.small[
 ```{r}
 full_model <- lm(score ~ rank + ethnicity + gender + language + 
                          age + cls_perc_eval + cls_did_eval + 
@@ -38,7 +39,9 @@ full_model <- lm(score ~ rank + ethnicity + gender + language +
 
 selected_model <- step(full_model, direction = ""backward"")
 ```
+]
 
+---
 
 class: middle
 

---FILE: course-materials/slides/u2_d06-model-validation/u2_d06-model-validation.html---
@@ -10,7 +10,7 @@
   </head>
   <body>
     <textarea id=""source"">
-class: middle, inverse, title-slide
+class: center, middle, inverse, title-slide
 
 # Model validation and logistic regression <br> ‚úÖ
 ### 
@@ -39,6 +39,7 @@
 
 ---
 
+.small[
 
 ```r
 full_model &lt;- lm(score ~ rank + ethnicity + gender + language + 
@@ -151,7 +152,9 @@
 ## - bty_avg        1    4.0096 119.13 -614.51
 ## - cls_credits    1    6.1046 121.23 -606.44
 ```
+]
 
+---
 
 class: middle
 
@@ -241,8 +244,7 @@
 ## 4     4     4
 ## 5     5     5
 ## 6     6     1
-## 7     7     2
-## 8     8     3
+## # ‚Ä¶ with 2 more rows
 ```
 ]
 
@@ -481,7 +483,7 @@
 
 ## Putting it altogether
 
-&lt;img src=""u2_d6-model-validation_files/figure-html/unnamed-chunk-19-1.png"" width=""1500"" /&gt;
+&lt;img src=""u2_d06-model-validation_files/figure-html/unnamed-chunk-19-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -536,13 +538,6 @@
                        bty_avg = 2.5)
 ```
 
-```
-## Warning: `data_frame()` is deprecated as of tibble 1.1.0.
-## Please use `tibble()` instead.
-## This warning is displayed once every 8 hours.
-## Call `lifecycle::last_warnings()` to see where this warning was generated.
-```
-
 ---
 
 ## New observation, corrected

---FILE: course-materials/slides/u2_d07-logistic-regression/u2_d07-logistic-regression.Rmd---
@@ -109,7 +109,7 @@ email %>%
 Even if we set not spam to 0 and spam to 1, this isn‚Äôt something we can 
 reasonably fit a linear model to - we need something more.
 
-```{r echo=FALSE, fig.height=2.25}
+```{r echo=FALSE, out.width=""80%""}
 means <- email %>%
   group_by(spam) %>%
   summarise(mean_num_char = mean(num_char)) %>%

---FILE: course-materials/slides/u2_d07-logistic-regression/u2_d07-logistic-regression.html---
@@ -12,7 +12,7 @@
   </head>
   <body>
     <textarea id=""source"">
-class: middle, inverse, title-slide
+class: center, middle, inverse, title-slide
 
 # Logistic regression <br> ‚úåÔ∏è
 ### 
@@ -63,7 +63,7 @@
 
 --
 
-&lt;img src=""u2_d7-logistic-regression_files/figure-html/unnamed-chunk-3-1.png"" width=""1500"" /&gt;
+&lt;img src=""u2_d07-logistic-regression_files/figure-html/unnamed-chunk-3-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -73,7 +73,7 @@
 
 --
 
-&lt;img src=""u2_d7-logistic-regression_files/figure-html/unnamed-chunk-4-1.png"" width=""1500"" /&gt;
+&lt;img src=""u2_d07-logistic-regression_files/figure-html/unnamed-chunk-4-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
 ---
 
 # Modeling spam
@@ -90,12 +90,7 @@
 Even if we set not spam to 0 and spam to 1, this isn‚Äôt something we can 
 reasonably fit a linear model to - we need something more.
 
-
-```
-## `summarise()` ungrouping output (override with `.groups` argument)
-```
-
-&lt;img src=""u2_d7-logistic-regression_files/figure-html/unnamed-chunk-5-1.png"" width=""1500"" /&gt;
+&lt;img src=""u2_d07-logistic-regression_files/figure-html/unnamed-chunk-5-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -161,7 +156,7 @@
 
 ---
 
-&lt;img src=""u2_d7-logistic-regression_files/figure-html/unnamed-chunk-6-1.png"" width=""1500"" /&gt;
+&lt;img src=""u2_d07-logistic-regression_files/figure-html/unnamed-chunk-6-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -257,21 +252,21 @@
 an email with 40000 characters?
 ]
 
-<div class=""countdown"" id=""timer_5f3f1538"" style=""right:0;bottom:0;"" data-warnwhen=""0"">
+<div class=""countdown"" id=""timer_5f58132a"" style=""right:0;bottom:0;"" data-warnwhen=""0"">
 <code class=""countdown-time""><span class=""countdown-digits minutes"">05</span><span class=""countdown-digits colon"">:</span><span class=""countdown-digits seconds"">00</span></code>
 </div>
 
 ---
 
-&lt;img src=""u2_d7-logistic-regression_files/figure-html/unnamed-chunk-10-1.png"" width=""1500"" /&gt;
+&lt;img src=""u2_d07-logistic-regression_files/figure-html/unnamed-chunk-10-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
 .question[
 Would you prefer an email with 2000 characters to be labeled as spam or not? How about 40,000 characters?
 ]
 
-&lt;img src=""u2_d7-logistic-regression_files/figure-html/unnamed-chunk-11-1.png"" width=""1500"" /&gt;
+&lt;img src=""u2_d07-logistic-regression_files/figure-html/unnamed-chunk-11-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -302,7 +297,7 @@
 If you were designing a spam filter, would you want sensitivity and specificity to be high or low? What are the tradeoffs associated with each decision? 
 ]
 
-<div class=""countdown"" id=""timer_5f3f150f"" style=""right:0;bottom:0;"" data-warnwhen=""0"">
+<div class=""countdown"" id=""timer_5f581522"" style=""right:0;bottom:0;"" data-warnwhen=""0"">
 <code class=""countdown-time""><span class=""countdown-digits minutes"">03</span><span class=""countdown-digits colon"">:</span><span class=""countdown-digits seconds"">00</span></code>
 </div>
 

---FILE: course-materials/slides/u2_d08-quantifying-uncertainty/u2_d08-quantifying-uncertainty.Rmd---
@@ -30,7 +30,7 @@ class: middle
 about the underlying population the sample came from.
 - Similar to tasting a spoonful of soup while cooking to make an inference about the entire pot.
 
-```{r echo=FALSE, out.width=650, out.height= 375, fig.align=""center""}
+```{r echo=FALSE, out.width=""60%""}
 knitr::include_graphics(""img/photo-1571942676516-bcab84649e44.png"")
 ```
 
@@ -51,12 +51,12 @@ If you want to catch a fish, do you prefer a spear or a net?
 <br>
 
 .pull-left[
-```{r echo=FALSE, out.width=400, fig.align=""center""}
+```{r echo=FALSE, out.width=""80%""}
 knitr::include_graphics(""img/spear.png"")
 ```
 ]
 .pull-right[
-```{r echo=FALSE, out.width=400, fig.align=""center""}
+```{r echo=FALSE, out.width=""80%""}
 knitr::include_graphics(""img/net.png"")
 ```
 ]
@@ -79,7 +79,7 @@ the parameter.
 
 ---
 
-```{r echo=FALSE, out.width=450, fig.align=""center""}
+```{r echo=FALSE, out.width=450}
 knitr::include_graphics(""img/2019-11-18-bcc-poll-tracker.png"")
 ```
 
@@ -197,7 +197,7 @@ edi_3br
 
 ## Observed sample
 
-```{r message=FALSE, echo=FALSE, fig.height=2.5}
+```{r message=FALSE, echo=FALSE, out.width=""80%""}
 ggplot(data = edi_3br, mapping = aes(x = rent)) +
   geom_histogram(binwidth = 200) +
   labs(title = ""Rent of 3 BR flats in Edinburgh"")
@@ -211,7 +211,7 @@ Sample mean ‚âà ¬£`r edi_3br %>% summarise(med_rent = mean(rent)) %>% pull() %>%
 
 <br>
 
-```{r fig.align=""center"", echo=FALSE, out.width=900}
+```{r echo=FALSE, out.width=""90%""}
 knitr::include_graphics(""img/rent-bootsamp.png"")
 ```
 
@@ -223,7 +223,7 @@ Generated assuming there are more flats like the ones in the observed sample...
 
 <br>
 
-```{r fig.align=""center"", echo=FALSE, out.width=900}
+```{r echo=FALSE, out.width=""90%""}
 knitr::include_graphics(""img/rent-bootpop.png"")
 ```
 
@@ -288,7 +288,7 @@ for (i in 1:100){
 
 ## Bootstrap results
 
-```{r fig.height=2}
+```{r out.width=""60%""}
 ggplot(boot_df, aes(x = stat)) +
   geom_histogram(binwidth = 100)
 ```
@@ -406,7 +406,7 @@ boot_df
 
 ## Visualize the bootstrap distribution
 
-```{r fig.height=2}
+```{r out.width=""80%""}
 ggplot(data = boot_df, mapping = aes(x = stat)) +
   geom_histogram(binwidth = 100) +
   labs(title = ""Bootstrap distribution of means"")
@@ -434,7 +434,7 @@ lower_bound <- boot_df %>% summarize(lower_bound = quantile(stat, 0.025)) %>% pu
 upper_bound <- boot_df %>% summarize(upper_bound = quantile(stat, 0.975)) %>% pull() %>% round()
 ```
 
-```{r echo=FALSE, fig.height=2.5}
+```{r echo=FALSE, out.width=""80%""}
 ggplot(data = boot_df, mapping = aes(x = stat)) +
   geom_histogram(binwidth = 100) +
   geom_vline(xintercept = c(lower_bound, upper_bound), 
@@ -486,7 +486,7 @@ class: middle
 Which line (orange dash/dot, blue dash, green dot) represents which confidence level?
 ]
 
-```{r echo=FALSE, fig.height=2.1}
+```{r echo=FALSE, out.width=""80%""}
 l90 <- boot_df %>% summarize(lower_bound = quantile(stat, 0.05)) %>% round(2) %>% pull()
 u90 <- boot_df %>% summarize(lower_bound = quantile(stat, 0.95)) %>% round(2) %>% pull()
 ",False,True,Visualization / Plotting,7
tidyverse,datascience-box,625774336a212871e85ffe90a33120c19389e94c,Debbie Yuster,dyuster@ramapo.edu,2020-09-08T20:45:04Z,GitHub,noreply@github.com,2020-09-08T20:45:04Z,"Fixed 2 more small typos (#81)

* Fix typos

* Fix typo",course-materials/labs/lab-01/lab-01-hello-r.Rmd,True,False,True,False,2,2,4,"---FILE: course-materials/labs/lab-01/lab-01-hello-r.Rmd---
@@ -198,9 +198,9 @@ ggplot(data = dino_data, mapping = aes(x = x, y = y)) +
 
 If this seems like a lot, it is. And you will learn about the philosophy of building data visualizations in layer in detail next week. For now, follow along with the code that is provided.
 
-For the second part of this exercises, we need to calculate a summary statistic: the correlation coefficient. Correlation coefficient, often referred to as $r$ in statistics, measures the linear association between two variables. You will see that some of the pairs of variables we plot do not have a linear relationship between them. This is exactly why we want to visualize first: visualize to assess the form of the relationship, and calculate $r$ only if relevant. In this case, calculating a correlation coefficient really doesn't make sense since the relationship between `x` and `y` is definitely not linear -- it's dinosaurial!
+For the second part of these exercises, we need to calculate a summary statistic: the correlation coefficient. Correlation coefficient, often referred to as $r$ in statistics, measures the linear association between two variables. You will see that some of the pairs of variables we plot do not have a linear relationship between them. This is exactly why we want to visualize first: visualize to assess the form of the relationship, and calculate $r$ only if relevant. In this case, calculating a correlation coefficient really doesn't make sense since the relationship between `x` and `y` is definitely not linear -- it's dinosaurial!
 
-But, for illustrative purposes, let's calculate correlation coefficient between `x` and `y`.
+But, for illustrative purposes, let's calculate the correlation coefficient between `x` and `y`.
 
 ```{marginfigure}
 Start with `dino_data` and calculate a summary statistic that we will call `r` as the `cor`relation between `x` and `y`.",False,True,Documentation / Formatting,4
tidyverse,datascience-box,8ca56f3a0560f58ae1eecae44f09d56d70fbe565,Debbie Yuster,dyuster@ramapo.edu,2020-09-08T19:56:32Z,GitHub,noreply@github.com,2020-09-08T19:56:32Z,Fix typos (#78),course-materials/slides/u1_d02-meet-the-toolkit/u1_d02-meet-the-toolkit.Rmd,True,False,True,False,2,2,4,"---FILE: course-materials/slides/u1_d02-meet-the-toolkit/u1_d02-meet-the-toolkit.Rmd---
@@ -131,7 +131,7 @@ knitr::include_graphics(""img/engine-dashboard.png"")
 
 A short list (for now):
 
-- Functions are (most often) verbs, followed by what they will be applied to in parantheses:
+- Functions are (most often) verbs, followed by what they will be applied to in parentheses:
 
 ```{r eval=FALSE}
 do_this(to_this)
@@ -312,7 +312,7 @@ knitr::include_graphics(""img/phd_comics_vc.gif"")
 - There are millions of git commands -- ok, that's an exaggeration, but there are a lot of them -- and very few people know them all. 99% of the time you will use git to add, commit, push, and pull.
 
 --
-- We will be doing Git things and interfacing with GitHub through RStudio, but if you google for help you might come accross methods for doing these things in the command line -- skip that and move on to the next resource unless you feel comfortable trying it out.
+- We will be doing Git things and interfacing with GitHub through RStudio, but if you google for help you might come across methods for doing these things in the command line -- skip that and move on to the next resource unless you feel comfortable trying it out.
 
 --
 - There is a great resource for working with git and R: [happygitwithr.com](http://happygitwithr.com/). Some of the content in there is beyond the scope of this course, but it's a good place to look for help.",False,True,Rendering / Conversion,3
tidyverse,datascience-box,ccb24b816045fe0905f433e78694f4bb3d617ab1,Debbie Yuster,dyuster@ramapo.edu,2020-09-08T19:55:37Z,GitHub,noreply@github.com,2020-09-08T19:55:37Z,Fix typos (#80),course-materials/labs/lab-01/lab-01-hello-r.Rmd,True,False,True,False,5,5,10,"---FILE: course-materials/labs/lab-01/lab-01-hello-r.Rmd---
@@ -122,9 +122,9 @@ Open the R Markdown (Rmd) file in your project, change the author name to your n
 knitr::include_graphics(""img/yaml-raw-to-rendered.png"")
 ```
 
-### Commiting changes
+### Committing changes
 
-Then Go to the Git pane in your RStudio.
+Then go to the Git pane in your RStudio.
 
 If you have made changes to your Rmd file, you should see it listed here. Click on it to select it in this list and then click on **Diff**. This shows you the *diff*erence between the last committed state of the document and its current state that includes your changes. If you're happy with these changes, write ""Update author name"" in the **Commit message** box and hit **Commit**.
 
@@ -150,7 +150,7 @@ For which of the above steps (changing project name, making updates to the docum
 If it's confusing that the data frame is called `datasaurus_dozen` when it contains 13 datasets, you're not alone! Have you heard of a [baker's dozen](https://en.wikipedia.org/wiki/Dozen#Baker's_dozen)?
 ```
 
-The data frame we will be working with today is called `datasaurus_dozen` and it's in the `datasauRus` package. Actually, this single data frame contains 13 datasets, designed to show us  why data visualisation is important and how summary statistics alone can be misleading. The different datasets are maked by the `dataset` variable.
+The data frame we will be working with today is called `datasaurus_dozen` and it's in the `datasauRus` package. Actually, this single data frame contains 13 datasets, designed to show us  why data visualisation is important and how summary statistics alone can be misleading. The different datasets are marked by the `dataset` variable.
 
 To find out more about the dataset, type the following in your Console: `?datasaurus_dozen`. A question mark before the name of an object will always bring up its help file. This command must be ran in the Console.
 
@@ -170,7 +170,7 @@ datasaurus_dozen %>%
 Matejka, Justin, and George Fitzmaurice. ""Same stats, different graphs: Generating datasets with varied appearance and identical statistics through simulated annealing."" Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. ACM, 2017.
 ```
 
-The original Datasaurus (`dino`) was created by Alberto Cairo in [this great blog post](http://www.thefunctionalart.com/2016/08/download-datasaurus-never-trust-summary.html). The other Dozen were generated using simulated annealing and the process is described in the paper *Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics* through Simulated Annealing by Justin Matejka and George Fitzmaurice. In the paper, the authors simulate a variety of datasets that the same summary statistics to the Datasaurus but have very different distributions.
+The original Datasaurus (`dino`) was created by Alberto Cairo in [this great blog post](http://www.thefunctionalart.com/2016/08/download-datasaurus-never-trust-summary.html). The other Dozen were generated using simulated annealing and the process is described in the paper *Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics* through Simulated Annealing by Justin Matejka and George Fitzmaurice. In the paper, the authors simulate a variety of datasets that have the same summary statistics as the Datasaurus but have very different distributions.
 
 2. Plot `y` vs. `x` for the `dino` dataset. Then, calculate the correlation coefficient between `x` and `y` for this dataset.
 
@@ -189,7 +189,7 @@ First, the pipe operator: `%>%`, takes what comes before it and sends it as the
 
 Second, the assignment operator: `<-`, assigns the name `dino_data` to the filtered data frame.
 
-Next, we need to visualize these data. We will use the `ggplot` function for this. Its first argument is the data you're visualizing. Next we define the `aes`thetic mappings. In other words, the columns of the data that get mapped to certain aesthetic features of the plot, e.g. the `x` axis will represent the variable called `x` and the `y` axis will represent the variable called `y`. Then, we add another layer to this plot where we define which `geom`etric shapes we want to use to represent each observation in the data. In this case we want these to be points,m hence `geom_point`.
+Next, we need to visualize these data. We will use the `ggplot` function for this. Its first argument is the data you're visualizing. Next we define the `aes`thetic mappings. In other words, the columns of the data that get mapped to certain aesthetic features of the plot, e.g. the `x` axis will represent the variable called `x` and the `y` axis will represent the variable called `y`. Then, we add another layer to this plot where we define which `geom`etric shapes we want to use to represent each observation in the data. In this case we want these to be points, hence `geom_point`.
 
 ```{r fig.fullwidth=TRUE}
 ggplot(data = dino_data, mapping = aes(x = x, y = y)) +",False,True,Implementation / Logic,6
tidyverse,datascience-box,dd3dbfb1d06bfb39a55adc6c6b4c95fadc9e2a26,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-09-04T20:43:44Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-09-04T20:43:44Z,Fix up data types lecture!,course-materials/slides/u1_d08-data-types/u1_d08-data-types.Rmd;course-materials/slides/u1_d08-data-types/u1_d08-data-types.html;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-36-1.png;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-37-1.png;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-38-1.png;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-39-1.png;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-40-1.png;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-41-1.png;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-42-1.png;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-43-1.png;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-44-1.png;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-45-1.png;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-46-1.png;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-47-1.png;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-48-1.png;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-49-1.png;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-50-1.png;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-51-1.png;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-52-1.png;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-53-1.png;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-54-1.png;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-55-1.png;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-56-1.png;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-57-1.png;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-58-1.png;course-materials/slides/u1_d08-data-types/u1_d08-data-types_files/figure-html/unnamed-chunk-59-1.png,True,False,True,False,499,604,1103,"---FILE: course-materials/slides/u1_d08-data-types/u1_d08-data-types.Rmd---
@@ -17,9 +17,7 @@ output:
 
 ```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
 library(tidyverse)
-library(knitr)
 library(DT)
-library(here)
 library(scales)
 ```
 
@@ -163,18 +161,17 @@ class: middle
 
 class: middle
 
-# Data classes and types
+# Data types
 
 ---
 
 ## Data types in R
 
-* **logical**
-* **double**
-* **integer**
-* **character**
-* **lists**
-* and some more, but we won't be focusing on those
+- **logical**
+- **double**
+- **integer**
+- **character**
+- and some more, but we won't be focusing on those
 
 ---
 
@@ -218,134 +215,135 @@ typeof(1:3)
 
 ---
 
-## Lists
+## Concatenation
 
-**Lists** are 1d objects that can contain any combination of R objects
+Vectors can be constructed using the `c()` function.
+
+```{r}
+c(1, 2, 3)
+c(""Hello"", ""World!"")
+c(c(""hi"", ""hello""), c(""bye"", ""jello""))
+```
+
+---
+
+## Converting between types
+
+.hand[with intention...]
 
 .pull-left[
-.midi[
 ```{r}
-mylist <- list(
-  ""A"", 
-  1:4, 
-  c(TRUE, FALSE), 
-  (1:4)/2
-  )
-mylist
+x <- 1:3
+x
+typeof(x)
+y <- as.character(x)
+y
+typeof(y)
 ```
 ]
-]
+--
 .pull-right[
 ```{r}
-str(mylist)
+x <- c(TRUE, FALSE)
+x
+typeof(x)
+y <- as.numeric(x)
+y
+typeof(y)
 ```
 ]
 
 ---
 
-## Named lists
+## Converting between types
+
+.hand[without intention...]
 
-Because of their more complex structure we often want to name the elements of a list (we 
-can also do this with vectors). This can make reading and accessing the list more 
-straight forward.
+R will happily convert between various types without complaint when different types of data are concatenated in a vector, and that's not always a great thing!
 
 .pull-left[
 ```{r}
-myotherlist <- list(
-  A = ""hello"", 
-  B = 1:4, 
-  ""knock knock"" = ""who's there?""
-  )
+c(1, ""Hello"")
+c(FALSE, 3L)
 ```
 ]
 .pull-right[
-.midi[
 ```{r}
-str(myotherlist)
-names(myotherlist)
-myotherlist$B
+c(1.2, 3L)
+c(2L, ""two"")
 ```
 ]
-]
 
 ---
 
-## Concatenation
+## Explicit vs. implicit coercion
 
-Vectors can be constructed using the `c()` function.
+Let's give formal names to what we've seen so far:
 
-```{r}
-c(1, 2, 3)
-c(""Hello"", ""World!"")
-c(1, c(2, c(3)))
-```
+- **Explicit coercion** is when you call a function like `as.logical()`, `as.numeric()`, `as.integer()`, `as.double()`, or `as.character()`.
+- **Implicit coercion** happens when you use a vector in a specific context that expects a certain type of vector. 
 
 ---
 
+.midi[
+.your-turn[
+- [RStudio Cloud](http://rstd.io/dsbox-cloud) > `AE 06 - Hotels + Data types` > open `type-coercion.Rmd` and knit.
+- What is the type of the given vectors? First, guess. Then, try it out in R. 
+If your guess was correct, great! If not, discuss why they have that type.
+]
+]
 
-## Vectors vs. lists
+.small[
+**Example:** Suppose we want to know the type of `c(1, ""a"")`. First, I'd look at: 
 
 .pull-left[
-```{r, error=TRUE}
-x <- c(8,4,7)
-```
-```{r}
-x[1]
-```
 ```{r}
-x[[1]]
+typeof(1)
 ```
 ]
---
 .pull-right[
 ```{r}
-y <- list(8,4,7)
-```
-```{r}
-y[2]
+typeof(""a"")
 ```
+]
+
+and make a guess based on these. Then finally I'd check:
+.pull-left[
 ```{r}
-y[[2]]
+typeof(c(1, ""a""))
 ```
 ]
+]
 
---
+---
 
-<br>
+class: middle
 
-**Note:** When using tidyverse code you'll rarely need to refer to elements using square brackets, but it's good to be aware of this syntax, especially since you might encounter it when searching for help online.
+# Special values
 
 ---
 
-```{r echo=FALSE, caption=""Hadley Wickham's tweet on indexing with salt and pepper shakers"", out.width=""80%"", fig.align=""center""}
-include_graphics(""img/hadley-salt-pepper.png"")
-```
+## Special values
 
----
-
-## Type coercion
+- `NA`: Not available
+- `NaN`: Not a number
+- `Inf`: Positive infinity
+- `-Inf`: Negative infinity
 
-R will happily convert between the various types without complaint.
+--
 
+.pull-left[
 ```{r}
-c(1, ""Hello"")
-c(FALSE, 3L)
-c(1.2, 3L)
+pi / 0
+0 / 0
 ```
-
---
-
-...and that's not alwas a great thing!
-
----
-
-## Missing Values
-
-R uses `NA` to represent missing values in its data structures.
-
+]
+.pull-right[
 ```{r}
-typeof(NA)
+1/0 - 1/0
+1/0 + 1/0
 ```
+]
 
 ---
 
@@ -361,262 +359,201 @@ mean(x, na.rm = TRUE)
 summary(x)
 ```
 
-
 ---
 
-## Other Special Values
+## `NA`s are logical
 
-`NaN` - Not a number
+R uses `NA` to represent missing values in its data structures.
+
+```{r}
+typeof(NA)
+```
 
-`Inf` - Positive infinity
+---
 
-`-Inf` - Negative infinity
+## Mental model for `NA`s
+
+- Unlike `NaN`, `NA`s are genuinely unknown values
+- But that doesn't mean they can't function in a logical way
+- Let's think about why `NA`s are logical...
 
 --
 
+.question[
+Why do the following give different answers?
+]
 .pull-left[
 ```{r}
-pi / 0
-0 / 0
-1/0 + 1/0
+# TRUE or NA
+TRUE | NA
 ```
 ]
 .pull-right[
 ```{r}
-1/0 - 1/0
-NaN / NA
-NaN * NA
+# FALSE or NA
+FALSE | NA
 ```
 ]
 
----
+$\rightarrow$ See next slide for answers...
 
-.midi[
-.your-turn[
-- [RStudio Cloud](http://rstd.io/dsbox-cloud) > `AE 06 - Hotels + Data types` > open `type-coercion.Rmd` and knit.
-- What is the type of the given vectors? First, guess. Then, try it out in R. 
-If your guess was correct, great! If not, discuss why they have that type.
-]
-]
+---
 
-.small[
-**Example:** Suppose we want to know the type of `c(1, ""a"")`. First, I'd look at: 
+- `NA` is unknown, so it could be `TRUE` or `FALSE`
 
 .pull-left[
+.midi[
+- `TRUE` or `TRUE` is `TRUE` and `TRUE` or `FALSE` is also `TRUE`, and since both are `TRUE`
 ```{r}
-typeof(1)
+TRUE | TRUE
+FALSE | TRUE
 ```
 ]
-.pull-right[
-```{r}
-typeof(""a"")
-```
 ]
 
-and make a guess based on these. Then finally I'd check:
-.pull-left[
+.pull-right[
+.midi[
+- `FALSE` or `TRUE` is `TRUE` and `FALSE` or `FALSE` is also `FALSE`, so you you can't tell which should be the right answer
 ```{r}
-typeof(c(1, ""a""))
+FALSE | TRUE
+FALSE | FALSE
 ```
 ]
 ]
 
+- Doesn't make sense for mathematical operations but make sense in the context of missing data
+
 ---
 
 class: middle
 
-# Data ""set""
+# Data classes
 
 ---
 
-## Data ""sets"" in R
-
-- ""set"" is in quotation marks because it is not a formal data class
---
+## Data classes
 
-- A tidy data ""set"" can be one of the following types:
-    + `tibble`
-    + `data.frame`
---
-- We'll often work with `tibble`s:
-    + `readr` package (e.g. `read_csv` function) loads data as a `tibble` by default
-    + `tibble`s are part of the tidyverse, so they work well with other packages we are using
-    + they make minimal assumptions about your data, so are less likely to cause hard to track bugs in your code
+We talked about *types* so far, next we'll introduce the concept of *classes*
 
+- Vectors are like Lego building blocks
+- We stick them together to build more complicated constructs, e.g. *representations of data*
+- The **class** attribute relates to the S3 class of an object which determines its behaviour
+  - You don't need to worry about what S3 classes really mean, but you can read more about it [here](https://adv-r.hadley.nz/s3.html#s3-classes) if you're curious
+- Examples: factors, dates, and data frames
+  
 ---
 
-## Data frames
-
-- A data frame is the most commonly used data structure in R: it is a list of equal length vectors. 
---
-
-- Each vector is treated as a column and elements of the vectors as rows.
---
-
-- A tibble is a type of data frame that makes your life (i.e. data analysis) easier.
-
----
+## Factors
 
-## Constructing data frames
+R uses factors to handle categorical variables, variables that have a fixed and known set of possible values
 
-- Most often a data frame will be constructed by reading in from a file
-- But we can also create them from scratch.
+```{r}
+x <- factor(c(""BS"", ""MS"", ""PhD"", ""MS""))
+x
+```
 
-.midi[
 .pull-left[
 ```{r}
-df <- tibble(
-  x = 1:3, 
-  y = c(""a"", ""b"", ""c"")
-  )
-class(df)
-glimpse(df)
+typeof(x)
 ```
 ]
 .pull-right[
 ```{r}
-df <- tribble(
-  ~x, ~y,
-  1,  ""a"",
-  2,  ""b"",
-  3,  ""c""
-)
-df
+class(x)
 ```
 ]
-]
 
----
 
-## Working with data frames in pipelines
+---
 
-.question[
-How many respondents have below average number of cats?
-]
+## More on factors
 
---
+We can think of factors like character (level labels) and an integer (level numbers) glued together
 
 ```{r}
-mean_cats <- cat_lovers %>%
-  summarise(mean_cats = mean(number_of_cats))
-
-cat_lovers %>%
-  filter(number_of_cats < mean_cats) %>%
-  nrow()
+glimpse(x)
+as.integer(x)
 ```
 
---
-
-.question[
-Do you believe this number? Why, why not?
-]
-
 ---
 
-## A result of a pipeline is always a data frame
+## Dates
 
 ```{r}
-mean_cats
-class(mean_cats)
+y <- as.Date(""2020-01-01"")
+y
+typeof(y)
+class(y)
 ```
 
 ---
 
-## `pull()` can be your new best friend
+## More on dates
 
-But use it sparingly!
+We can think of factors like an integer (the number of days since the origin, 1 Jan 1970) and an integer (the origin) glued together
 
 ```{r}
-mean_cats <- cat_lovers %>%
-  summarise(mean_cats = mean(number_of_cats)) %>%
-  pull() #<<
-mean_cats
-class(mean_cats)
+as.integer(y)
+as.integer(y) / 365 # roughly 50 yrs
 ```
 
+---
+
+## Data frames
+
+We can think of data frames like like vectors of equal length glued together
+
 ```{r}
-cat_lovers %>%
-  filter(number_of_cats < mean_cats) %>%
-  nrow()
+df <- data.frame(x = 1:2, y = 3:4)
+df
 ```
 
---
-
 .pull-left[
 ```{r}
-mean_cats
+typeof(df)
 ```
 ]
 .pull-right[
 ```{r}
-class(mean_cats)
+class(df)
 ```
 ]
 
 ---
 
-## to conlcude discussion on data frames / tibbles...
+## Lists
 
-.pull-left[
-```{r echo=FALSE, out.width=""60%"",fig.align=""center""}
-include_graphics(""img/tibble-part-of-tidyverse.png"")
+Lists are a generic vector container vectors of any type can go in them
+
+```{r}
+l <- list(
+  x = 1:4,
+  y = c(""hi"", ""hello"", ""jello""),
+  z = c(TRUE, FALSE)
+)
+l
 ```
-]
-.pull-right[
-- **tibble** is also the name of the Tidyverse package that implements this data type
-- But you rarely need to directly load this package since `library(tidyverse)` takes care of it
-- And you rarely need to use functions from this package for data wrangling and visualisation, except when you're manually creating your data frames for a short example with `tibble()` or `tribble()`
-]
 
 ---
 
-## Recap
+## Lists and data frames
 
-- Always best to think of data as part of a tibble
-    + This plays nicely with the `tidyverse` as well
-    + Rows are observations, columns are variables
---
-- Be careful about data types / classes
-    + Sometimes `R` makes silly assumptions about your data class 
-        + Using `tibble`s help, but it might not solve all issues
-        + Think about your data in context, e.g. 0/1 variable is most likely a `factor`
-    + If a plot/output is not behaving the way you expect, first
-    investigate the data class
-    + If you are absolutely sure of a data class, overwrite it in your
-    tibble so that you don't need to keep having to keep track of it
-        + `mutate` the variable with the correct class
-        
----
+- A data frame is a special list containing vectors of equal length
+- When we use the `pull()` function, we extract a vector from the data frame
 
-## Two data types worth knowing your way around
+```{r}
+df
 
-- .huge-blue[factors]
+df %>%
+  pull(y)
+```
 
-- .huge-blue[dates]
 
 ---
 
 class: middle
 
-# Factors
-
----
-
-## Factors
-
-Factor objects are how R stores data for categorical variables (fixed numbers of discrete values).
-
-```{r}
-(x = factor(c(""BS"", ""MS"", ""PhD"", ""MS"")))
-```
-
-```{r}
-glimpse(x)
-```
-
-```{r}
-typeof(x)
-```
+# Working with factors
 
 ---
 
@@ -639,7 +576,7 @@ ggplot(cat_lovers, mapping = aes(x = handedness)) +
 
 ## Use forcats to manipulate factors
 
-```{r fig.retina=3, fig.height=2, fig.width=6}
+```{r out.width=""70%""}
 cat_lovers %>%
   mutate(handedness = fct_infreq(handedness)) %>% #<<
   ggplot(mapping = aes(x = handedness)) +
@@ -658,20 +595,20 @@ cat_lovers %>%
 include_graphics(""img/forcats-part-of-tidyverse.png"")
 ```
 ]
-
-- R uses factors to handle categorical variables, variables that have a fixed and known set of possible values
 - Factors are useful when you have true categorical data and you want to override the ordering of character vectors to improve display
 - They are also useful in modeling scenarios
 - The **forcats** package provides a suite of useful tools that solve common problems with factors
 
 ---
 
+.small[
 .your-turn[
-- [RStudio Cloud](http://rstd.io/dsbox-cloud) > start `AE 06 - Hotels + Data types` > open `hotels-forcats.Rmd` and knit.
+- [RStudio Cloud](http://rstd.io/dsbox-cloud) > `AE 06 - Hotels + Data types` > `hotels-forcats.Rmd` > knit
 - Recreate the following. The x-axis first, then, as a stretch goal, the y-axis.
 ]
+]
 
-```{r fig.height=3, fig.width=9, echo=FALSE, message=FALSE, warning=FALSE}
+```{r echo=FALSE, out.width=""100%"", fig.asp=0.4}
 hotels <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv"")
 hotels %>%
   mutate(arrival_date_month = fct_relevel(arrival_date_month, month.name)) %>%
@@ -689,15 +626,16 @@ hotels %>%
   labs(x = ""Arrival month"",                 # customize labels
        y = ""Mean ADR (average daily rate)"",
        title = ""Comparison of resort and city hotel prices across months"",
-       subtitle = ""Resort hotel prices soar in the summer while city hotel prices remain relatively constant throughout the year"",
-       color = ""Hotel type"")
+       subtitle = ""Resort hotel prices soar in the summer while city hotel prices remain\nrelatively constant throughout the year"",
+       color = ""Hotel type"") +
+  scale_x_discrete(guide = guide_axis(check.overlap = TRUE))
 ```
 
 ---
 
 class: middle
 
-# Dates
+# Working with dates
 
 ---
 
@@ -734,7 +672,7 @@ hotels %>%
 
 ---
 
-### Step 1. Put together dates.
+## Step 1. Put together dates.
 
 .midi[
 ```{r}
@@ -750,7 +688,7 @@ hotels %>%
 
 ---
 
-### Step 2. Count number of bookings per date.
+## Step 2. Count number of bookings per date.
 
 .midi[
 ```{r}
@@ -762,16 +700,15 @@ hotels %>%
 
 ---
 
-### Step 3. Visualise number of bookings per date.
+## Step 3. Visualise number of bookings per date.
 
 .midi[
-```{r fig.height=3, fig.width=9}
+```{r out.width=""70%""}
 hotels %>%
   mutate(arrival_date = glue(""{arrival_date_year} {arrival_date_month} {arrival_date_day_of_month}"")) %>%
   count(arrival_date) %>%
   ggplot(aes(x = arrival_date, y = n, group = 1)) +
-  geom_line() +
-  ylim(0, 450)
+  geom_line()
 ```
 ]
 
@@ -784,7 +721,7 @@ Why does the plot start with August when we know our data start in July? And why
 ]
 
 .midi[
-```{r fig.height=3, fig.width=9, echo=FALSE}
+```{r out.width=""70%"", echo=FALSE}
 hotels %>%
   mutate(arrival_date = glue(""{arrival_date_year} {arrival_date_month} {arrival_date_day_of_month}"")) %>%
   count(arrival_date) %>%
@@ -796,7 +733,7 @@ hotels %>%
 
 ---
 
-### Step 1. `REVISED` Put together dates `as dates`.
+## Step 1. `REVISED` Put together dates `as dates`.
 
 .midi[
 ```{r}
@@ -812,7 +749,7 @@ hotels %>%
 
 ---
 
-### Step 2. Count number of bookings per date.
+## Step 2. Count number of bookings per date.
 
 .midi[
 ```{r}
@@ -824,30 +761,28 @@ hotels %>%
 
 ---
 
-### Step 3a. Visualise number of bookings per date.
+## Step 3a. Visualise number of bookings per date.
 
 .midi[
-```{r fig.height=3, fig.width=9}
+```{r out.width=""70%""}
 hotels %>%
   mutate(arrival_date = ymd(glue(""{arrival_date_year} {arrival_date_month} {arrival_date_day_of_month}""))) %>% 
   count(arrival_date) %>%
   ggplot(aes(x = arrival_date, y = n, group = 1)) +
-  geom_line() +
-  ylim(0, 450)
+  geom_line()
 ```
 ]
 
 ---
 
-### Step 3b. Visualise using a smooth curve.
+## Step 3b. Visualise using a smooth curve.
 
 .midi[
-```{r fig.height=3, fig.width=9, message=FALSE}
+```{r out.width=""70%"", message = FALSE}
 hotels %>%
   mutate(arrival_date = ymd(glue(""{arrival_date_year} {arrival_date_month} {arrival_date_day_of_month}""))) %>% 
   count(arrival_date) %>%
   ggplot(aes(x = arrival_date, y = n, group = 1)) +
-  geom_smooth() + #<<
-  ylim(0, 450)
+  geom_smooth() #<<
 ```
 ]

---FILE: course-materials/slides/u1_d08-data-types/u1_d08-data-types.html---
@@ -149,8 +149,8 @@
 ## Let's take another look
 
 .small[
-<div id=""htmlwidget-1b4ff99564eb6e8884a5"" style=""width:100%;height:auto;"" class=""datatables html-widget""></div>
-<script type=""application/json"" data-for=""htmlwidget-1b4ff99564eb6e8884a5"">{""x"":{""filter"":""none"",""data"":[[""1"",""2"",""3"",""4"",""5"",""6"",""7"",""8"",""9"",""10"",""11"",""12"",""13"",""14"",""15"",""16"",""17"",""18"",""19"",""20"",""21"",""22"",""23"",""24"",""25"",""26"",""27"",""28"",""29"",""30"",""31"",""32"",""33"",""34"",""35"",""36"",""37"",""38"",""39"",""40"",""41"",""42"",""43"",""44"",""45"",""46"",""47"",""48"",""49"",""50"",""51"",""52"",""53"",""54"",""55"",""56"",""57"",""58"",""59"",""60""],[""Bernice Warren"",""Woodrow Stone"",""Willie Bass"",""Tyrone Estrada"",""Alex Daniels"",""Jane Bates"",""Latoya Simpson"",""Darin Woods"",""Agnes Cobb"",""Tabitha Grant"",""Perry Cross"",""Wanda Silva"",""Alicia Sims"",""Emily Logan"",""Woodrow Elliott"",""Brent Copeland"",""Pedro Carlson"",""Patsy Luna"",""Brett Robbins"",""Oliver George"",""Calvin Perry"",""Lora Gutierrez"",""Charlotte Sparks"",""Earl Mack"",""Leslie Wade"",""Santiago Barker"",""Jose Bell"",""Lynda Smith"",""Bradford Marshall"",""Irving Miller"",""Caroline Simpson"",""Frances Welch"",""Melba Jenkins"",""Veronica Morales"",""Juanita Cunningham"",""Maurice Howard"",""Teri Pierce"",""Phil Franklin"",""Jan Zimmerman"",""Leslie Price"",""Bessie Patterson"",""Ethel Wolfe"",""Naomi Wright"",""Sadie Frank"",""Lonnie Cannon"",""Tony Garcia"",""Darla Newton"",""Ginger Clark"",""Lionel Campbell"",""Florence Klein"",""Harriet Leonard"",""Terrence Harrington"",""Travis Garner"",""Doug Bass"",""Pat Norris"",""Dawn Young"",""Shari Alvarez"",""Tamara Robinson"",""Megan Morgan"",""Kara Obrien""],[""0"",""0"",""1"",""3"",""3"",""2"",""1"",""1"",""0"",""0"",""0"",""0"",""1"",""3"",""3"",""2"",""1"",""1"",""0"",""0"",""1"",""1"",""0"",""0"",""4"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""1"",""3"",""3"",""2"",""1"",""1.5 - honestly I think one of my cats is half human"",""0"",""0"",""1"",""0"",""1"",""three"",""1"",""1"",""1"",""0"",""0"",""2""],[""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""ambidextrous"",""ambidextrous"",""ambidextrous"",""ambidextrous"",""ambidextrous""]],""container"":""<table class=\""display\"">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>name<\/th>\n      <th>number_of_cats<\/th>\n      <th>handedness<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>"",""options"":{""order"":[],""autoWidth"":false,""orderClasses"":false,""columnDefs"":[{""orderable"":false,""targets"":0}]}},""evals"":[],""jsHooks"":[]}</script>
+<div id=""htmlwidget-0b2450c22e55e4a5515d"" style=""width:100%;height:auto;"" class=""datatables html-widget""></div>
+<script type=""application/json"" data-for=""htmlwidget-0b2450c22e55e4a5515d"">{""x"":{""filter"":""none"",""data"":[[""1"",""2"",""3"",""4"",""5"",""6"",""7"",""8"",""9"",""10"",""11"",""12"",""13"",""14"",""15"",""16"",""17"",""18"",""19"",""20"",""21"",""22"",""23"",""24"",""25"",""26"",""27"",""28"",""29"",""30"",""31"",""32"",""33"",""34"",""35"",""36"",""37"",""38"",""39"",""40"",""41"",""42"",""43"",""44"",""45"",""46"",""47"",""48"",""49"",""50"",""51"",""52"",""53"",""54"",""55"",""56"",""57"",""58"",""59"",""60""],[""Bernice Warren"",""Woodrow Stone"",""Willie Bass"",""Tyrone Estrada"",""Alex Daniels"",""Jane Bates"",""Latoya Simpson"",""Darin Woods"",""Agnes Cobb"",""Tabitha Grant"",""Perry Cross"",""Wanda Silva"",""Alicia Sims"",""Emily Logan"",""Woodrow Elliott"",""Brent Copeland"",""Pedro Carlson"",""Patsy Luna"",""Brett Robbins"",""Oliver George"",""Calvin Perry"",""Lora Gutierrez"",""Charlotte Sparks"",""Earl Mack"",""Leslie Wade"",""Santiago Barker"",""Jose Bell"",""Lynda Smith"",""Bradford Marshall"",""Irving Miller"",""Caroline Simpson"",""Frances Welch"",""Melba Jenkins"",""Veronica Morales"",""Juanita Cunningham"",""Maurice Howard"",""Teri Pierce"",""Phil Franklin"",""Jan Zimmerman"",""Leslie Price"",""Bessie Patterson"",""Ethel Wolfe"",""Naomi Wright"",""Sadie Frank"",""Lonnie Cannon"",""Tony Garcia"",""Darla Newton"",""Ginger Clark"",""Lionel Campbell"",""Florence Klein"",""Harriet Leonard"",""Terrence Harrington"",""Travis Garner"",""Doug Bass"",""Pat Norris"",""Dawn Young"",""Shari Alvarez"",""Tamara Robinson"",""Megan Morgan"",""Kara Obrien""],[""0"",""0"",""1"",""3"",""3"",""2"",""1"",""1"",""0"",""0"",""0"",""0"",""1"",""3"",""3"",""2"",""1"",""1"",""0"",""0"",""1"",""1"",""0"",""0"",""4"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""0"",""1"",""3"",""3"",""2"",""1"",""1.5 - honestly I think one of my cats is half human"",""0"",""0"",""1"",""0"",""1"",""three"",""1"",""1"",""1"",""0"",""0"",""2""],[""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""left"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""right"",""ambidextrous"",""ambidextrous"",""ambidextrous"",""ambidextrous"",""ambidextrous""]],""container"":""<table class=\""display\"">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>name<\/th>\n      <th>number_of_cats<\/th>\n      <th>handedness<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>"",""options"":{""order"":[],""autoWidth"":false,""orderClasses"":false,""columnDefs"":[{""orderable"":false,""targets"":0}]}},""evals"":[],""jsHooks"":[]}</script>
 ]
 
 ---
@@ -251,18 +251,17 @@
 
 class: middle
 
-# Data classes and types
+# Data types
 
 ---
 
 ## Data types in R
 
-* **logical**
-* **double**
-* **integer**
-* **character**
-* **lists**
-* and some more, but we won't be focusing on those
+- **logical**
+- **double**
+- **integer**
+- **character**
+- and some more, but we won't be focusing on those
 
 ---
 
@@ -340,246 +339,270 @@
 
 ---
 
-## Lists
+## Concatenation
 
-**Lists** are 1d objects that can contain any combination of R objects
+Vectors can be constructed using the `c()` function.
 
-.pull-left[
-.midi[
 
 ```r
-mylist &lt;- list(
-  ""A"", 
-  1:4, 
-  c(TRUE, FALSE), 
-  (1:4)/2
-  )
-mylist
+c(1, 2, 3)
 ```
 
 ```
-## [[1]]
-## [1] ""A""
-## 
-## [[2]]
-## [1] 1 2 3 4
-## 
-## [[3]]
-## [1]  TRUE FALSE
-## 
-## [[4]]
-## [1] 0.5 1.0 1.5 2.0
+## [1] 1 2 3
 ```
-]
-]
-.pull-right[
 
 ```r
-str(mylist)
+c(""Hello"", ""World!"")
 ```
 
 ```
-## List of 4
-##  $ : chr ""A""
-##  $ : int [1:4] 1 2 3 4
-##  $ : logi [1:2] TRUE FALSE
-##  $ : num [1:4] 0.5 1 1.5 2
+## [1] ""Hello""  ""World!""
+```
+
+```r
+c(c(""hi"", ""hello""), c(""bye"", ""jello""))
+```
+
+```
+## [1] ""hi""    ""hello"" ""bye""   ""jello""
 ```
-]
 
 ---
 
-## Named lists
+## Converting between types
 
-Because of their more complex structure we often want to name the elements of a list (we 
-can also do this with vectors). This can make reading and accessing the list more 
-straight forward.
+.hand[with intention...]
 
 .pull-left[
 
 ```r
-myotherlist &lt;- list(
-  A = ""hello"", 
-  B = 1:4, 
-  ""knock knock"" = ""who's there?""
-  )
+x &lt;- 1:3
+x
+```
+
+```
+## [1] 1 2 3
 ```
-]
-.pull-right[
-.midi[
 
 ```r
-str(myotherlist)
+typeof(x)
 ```
 
 ```
-## List of 3
-##  $ A          : chr ""hello""
-##  $ B          : int [1:4] 1 2 3 4
-##  $ knock knock: chr ""who's there?""
+## [1] ""integer""
 ```
 
 ```r
-names(myotherlist)
+y &lt;- as.character(x)
+y
 ```
 
 ```
-## [1] ""A""           ""B""           ""knock knock""
+## [1] ""1"" ""2"" ""3""
 ```
 
 ```r
-myotherlist$B
+typeof(y)
 ```
 
 ```
-## [1] 1 2 3 4
+## [1] ""character""
 ```
 ]
-]
-
----
-
-## Concatenation
+--
+.pull-right[
 
-Vectors can be constructed using the `c()` function.
+```r
+x &lt;- c(TRUE, FALSE)
+x
+```
 
+```
+## [1]  TRUE FALSE
+```
 
 ```r
-c(1, 2, 3)
+typeof(x)
 ```
 
 ```
-## [1] 1 2 3
+## [1] ""logical""
 ```
 
 ```r
-c(""Hello"", ""World!"")
+y &lt;- as.numeric(x)
+y
 ```
 
 ```
-## [1] ""Hello""  ""World!""
+## [1] 1 0
 ```
 
 ```r
-c(1, c(2, c(3)))
+typeof(y)
 ```
 
 ```
-## [1] 1 2 3
+## [1] ""double""
 ```
+]
 
 ---
 
+## Converting between types
 
-## Vectors vs. lists
+.hand[without intention...]
 
-.pull-left[
+R will happily convert between various types without complaint when different types of data are concatenated in a vector, and that's not always a great thing!
 
-```r
-x &lt;- c(8,4,7)
-```
+.pull-left[
 
 ```r
-x[1]
+c(1, ""Hello"")
 ```
 
 ```
-## [1] 8
+## [1] ""1""     ""Hello""
 ```
 
 ```r
-x[[1]]
+c(FALSE, 3L)
 ```
 
 ```
-## [1] 8
+## [1] 0 3
 ```
 ]
---
 .pull-right[
 
 ```r
-y &lt;- list(8,4,7)
-```
-
-```r
-y[2]
+c(1.2, 3L)
 ```
 
 ```
-## [[1]]
-## [1] 4
+## [1] 1.2 3.0
 ```
 
 ```r
-y[[2]]
+c(2L, ""two"")
 ```
 
 ```
-## [1] 4
+## [1] ""2""   ""two""
 ```
 ]
 
---
-
-&lt;br&gt;
+---
 
-**Note:** When using tidyverse code you'll rarely need to refer to elements using square brackets, but it's good to be aware of this syntax, especially since you might encounter it when searching for help online.
+## Explicit vs. implicit coercion
 
----
+Let's give formal names to what we've seen so far:
 
-&lt;img src=""img/hadley-salt-pepper.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
+- **Explicit coercion** is when you call a function like `as.logical()`, `as.numeric()`, `as.integer()`, `as.double()`, or `as.character()`.
+- **Implicit coercion** happens when you use a vector in a specific context that expects a certain type of vector. 
 
 ---
 
-## Type coercion
+.midi[
+.your-turn[
+- [RStudio Cloud](http://rstd.io/dsbox-cloud) &gt; `AE 06 - Hotels + Data types` &gt; open `type-coercion.Rmd` and knit.
+- What is the type of the given vectors? First, guess. Then, try it out in R. 
+If your guess was correct, great! If not, discuss why they have that type.
+]
+]
 
-R will happily convert between the various types without complaint.
+.small[
+**Example:** Suppose we want to know the type of `c(1, ""a"")`. First, I'd look at: 
 
+.pull-left[
 
 ```r
-c(1, ""Hello"")
+typeof(1)
 ```
 
 ```
-## [1] ""1""     ""Hello""
+## [1] ""double""
 ```
+]
+.pull-right[
 
 ```r
-c(FALSE, 3L)
+typeof(""a"")
 ```
 
 ```
-## [1] 0 3
+## [1] ""character""
 ```
+]
+
+and make a guess based on these. Then finally I'd check:
+.pull-left[
 
 ```r
-c(1.2, 3L)
+typeof(c(1, ""a""))
 ```
 
 ```
-## [1] 1.2 3.0
+## [1] ""character""
 ```
+]
+]
 
---
+---
 
-...and that's not alwas a great thing!
+class: middle
+
+# Special values
 
 ---
 
-## Missing Values
+## Special values
 
-R uses `NA` to represent missing values in its data structures.
+- `NA`: Not available
+- `NaN`: Not a number
+- `Inf`: Positive infinity
+- `-Inf`: Negative infinity
+
+--
 
+.pull-left[
 
 ```r
-typeof(NA)
+pi / 0
 ```
 
 ```
-## [1] ""logical""
+## [1] Inf
 ```
 
+```r
+0 / 0
+```
+
+```
+## [1] NaN
+```
+]
+.pull-right[
+
+```r
+1/0 - 1/0
+```
+
+```
+## [1] NaN
+```
+
+```r
+1/0 + 1/0
+```
+
+```
+## [1] Inf
+```
+]
+
 ---
 
 ## `NA`s are special ‚ùÑÔ∏ès
@@ -615,401 +638,341 @@
 ##    1.00    1.75    2.50    2.50    3.25    4.00       1
 ```
 
-
 ---
 
-## Other Special Values
-
-`NaN` - Not a number
-
-`Inf` - Positive infinity
+## `NA`s are logical
 
-`-Inf` - Negative infinity
+R uses `NA` to represent missing values in its data structures.
 
---
-
-.pull-left[
 
 ```r
-pi / 0
+typeof(NA)
 ```
 
 ```
-## [1] Inf
-```
-
-```r
-0 / 0
+## [1] ""logical""
 ```
 
-```
-## [1] NaN
-```
+---
 
-```r
-1/0 + 1/0
-```
+## Mental model for `NA`s
 
-```
-## [1] Inf
-```
-]
-.pull-right[
+- Unlike `NaN`, `NA`s are genuinely unknown values
+- But that doesn't mean they can't function in a logical way
+- Let's think about why `NA`s are logical...
 
-```r
-1/0 - 1/0
-```
+--
 
-```
-## [1] NaN
-```
+.question[
+Why do the following give different answers?
+]
+.pull-left[
 
 ```r
-NaN / NA
+# TRUE or NA
+TRUE | NA
 ```
 
 ```
-## [1] NaN
+## [1] TRUE
 ```
+]
+.pull-right[
 
 ```r
-NaN * NA
+# FALSE or NA
+FALSE | NA
 ```
 
 ```
-## [1] NaN
+## [1] NA
 ```
 ]
 
+`\(\rightarrow\)` See next slide for answers...
+
 ---
 
+- `NA` is unknown, so it could be `TRUE` or `FALSE`
+
+.pull-left[
 .midi[
-.your-turn[
-- [RStudio Cloud](http://rstd.io/dsbox-cloud) &gt; `AE 06 - Hotels + Data types` &gt; open `type-coercion.Rmd` and knit.
-- What is the type of the given vectors? First, guess. Then, try it out in R. 
-If your guess was correct, great! If not, discuss why they have that type.
-]
-]
+- `TRUE` or `TRUE` is `TRUE` and `TRUE` or `FALSE` is also `TRUE`, and since both are `TRUE`
 
-.small[
-**Example:** Suppose we want to know the type of `c(1, ""a"")`. First, I'd look at: 
+```r
+TRUE | TRUE
+```
 
-.pull-left[
+```
+## [1] TRUE
+```
 
 ```r
-typeof(1)
+FALSE | TRUE
 ```
 
 ```
-## [1] ""double""
+## [1] TRUE
 ```
 ]
+]
+
 .pull-right[
+.midi[
+- `FALSE` or `TRUE` is `TRUE` and `FALSE` or `FALSE` is also `FALSE`, so you you can't tell which should be the right answer
 
 ```r
-typeof(""a"")
+FALSE | TRUE
 ```
 
 ```
-## [1] ""character""
+## [1] TRUE
 ```
-]
-
-and make a guess based on these. Then finally I'd check:
-.pull-left[
 
 ```r
-typeof(c(1, ""a""))
+FALSE | FALSE
 ```
 
 ```
-## [1] ""character""
+## [1] FALSE
 ```
 ]
 ]
 
----
-
-class: middle
-
-# Data ""set""
+- Doesn't make sense for mathematical operations but make sense in the context of missing data
 
 ---
 
-## Data ""sets"" in R
-
-- ""set"" is in quotation marks because it is not a formal data class
---
+class: middle
 
-- A tidy data ""set"" can be one of the following types:
-    + `tibble`
-    + `data.frame`
---
-- We'll often work with `tibble`s:
-    + `readr` package (e.g. `read_csv` function) loads data as a `tibble` by default
-    + `tibble`s are part of the tidyverse, so they work well with other packages we are using
-    + they make minimal assumptions about your data, so are less likely to cause hard to track bugs in your code
+# Data classes
 
 ---
 
-## Data frames
-
-- A data frame is the most commonly used data structure in R: it is a list of equal length vectors. 
---
-
-- Each vector is treated as a column and elements of the vectors as rows.
---
+## Data classes
 
-- A tibble is a type of data frame that makes your life (i.e. data analysis) easier.
+We talked about *types* so far, next we'll introduce the concept of *classes*
 
+- Vectors are like Lego building blocks
+- We stick them together to build more complicated constructs, e.g. *representations of data*
+- The **class** attribute relates to the S3 class of an object which determines its behaviour
+  - You don't need to worry about what S3 classes really mean, but you can read more about it [here](https://adv-r.hadley.nz/s3.html#s3-classes) if you're curious
+- Examples: factors, dates, and data frames
+  
 ---
 
-## Constructing data frames
+## Factors
 
-- Most often a data frame will be constructed by reading in from a file
-- But we can also create them from scratch.
+R uses factors to handle categorical variables, variables that have a fixed and known set of possible values
 
-.midi[
-.pull-left[
 
 ```r
-df &lt;- tibble(
-  x = 1:3, 
-  y = c(""a"", ""b"", ""c"")
-  )
-class(df)
+x &lt;- factor(c(""BS"", ""MS"", ""PhD"", ""MS""))
+x
 ```
 
 ```
-## [1] ""tbl_df""     ""tbl""        ""data.frame""
+## [1] BS  MS  PhD MS 
+## Levels: BS MS PhD
 ```
 
+.pull-left[
+
 ```r
-glimpse(df)
+typeof(x)
 ```
 
 ```
-## Rows: 3
-## Columns: 2
-## $ x &lt;int&gt; 1, 2, 3
-## $ y &lt;chr&gt; ""a"", ""b"", ""c""
+## [1] ""integer""
 ```
 ]
 .pull-right[
 
 ```r
-df &lt;- tribble(
-  ~x, ~y,
-  1,  ""a"",
-  2,  ""b"",
-  3,  ""c""
-)
-df
+class(x)
 ```
 
 ```
-## # A tibble: 3 x 2
-##       x y    
-##   &lt;dbl&gt; &lt;chr&gt;
-## 1     1 a    
-## 2     2 b    
-## 3     3 c
+## [1] ""factor""
 ```
 ]
-]
 
----
 
-## Working with data frames in pipelines
+---
 
-.question[
-How many respondents have below average number of cats?
-]
+## More on factors
 
---
+We can think of factors like character (level labels) and an integer (level numbers) glued together
 
 
 ```r
-mean_cats &lt;- cat_lovers %&gt;%
-  summarise(mean_cats = mean(number_of_cats))
-
-cat_lovers %&gt;%
-  filter(number_of_cats &lt; mean_cats) %&gt;%
-  nrow()
+glimpse(x)
 ```
 
 ```
-## [1] 60
+##  Factor w/ 3 levels ""BS"",""MS"",""PhD"": 1 2 3 2
 ```
 
---
+```r
+as.integer(x)
+```
 
-.question[
-Do you believe this number? Why, why not?
-]
+```
+## [1] 1 2 3 2
+```
 
 ---
 
-## A result of a pipeline is always a data frame
+## Dates
 
 
 ```r
-mean_cats
+y &lt;- as.Date(""2020-01-01"")
+y
 ```
 
 ```
-## # A tibble: 1 x 1
-##   mean_cats
-##       &lt;dbl&gt;
-## 1     0.833
+## [1] ""2020-01-01""
 ```
 
 ```r
-class(mean_cats)
+typeof(y)
 ```
 
 ```
-## [1] ""tbl_df""     ""tbl""        ""data.frame""
+## [1] ""double""
+```
+
+```r
+class(y)
+```
+
+```
+## [1] ""Date""
 ```
 
 ---
 
-## `pull()` can be your new best friend
+## More on dates
 
-But use it sparingly!
+We can think of factors like an integer (the number of days since the origin, 1 Jan 1970) and an integer (the origin) glued together
 
 
 ```r
-mean_cats &lt;- cat_lovers %&gt;%
-  summarise(mean_cats = mean(number_of_cats)) %&gt;%
-* pull()
-mean_cats
+as.integer(y)
 ```
 
 ```
-## [1] 0.8333333
+## [1] 18262
 ```
 
 ```r
-class(mean_cats)
+as.integer(y) / 365 # roughly 50 yrs
 ```
 
 ```
-## [1] ""numeric""
+## [1] 50.03288
 ```
 
+---
+
+## Data frames
+
+We can think of data frames like like vectors of equal length glued together
+
 
 ```r
-cat_lovers %&gt;%
-  filter(number_of_cats &lt; mean_cats) %&gt;%
-  nrow()
+df &lt;- data.frame(x = 1:2, y = 3:4)
+df
 ```
 
 ```
-## [1] 32
+##   x y
+## 1 1 3
+## 2 2 4
 ```
 
---
-
 .pull-left[
 
 ```r
-mean_cats
+typeof(df)
 ```
 
 ```
-## [1] 0.8333333
+## [1] ""list""
 ```
 ]
 .pull-right[
 
 ```r
-class(mean_cats)
+class(df)
 ```
 
 ```
-## [1] ""numeric""
+## [1] ""data.frame""
 ```
 ]
 
 ---
 
-## to conlcude discussion on data frames / tibbles...
-
-.pull-left[
-&lt;img src=""img/tibble-part-of-tidyverse.png"" width=""60%"" style=""display: block; margin: auto;"" /&gt;
-]
-.pull-right[
-- **tibble** is also the name of the Tidyverse package that implements this data type
-- But you rarely need to directly load this package since `library(tidyverse)` takes care of it
-- And you rarely need to use functions from this package for data wrangling and visualisation, except when you're manually creating your data frames for a short example with `tibble()` or `tribble()`
-]
-
----
-
-## Recap
-
-- Always best to think of data as part of a tibble
-    + This plays nicely with the `tidyverse` as well
-    + Rows are observations, columns are variables
---
-- Be careful about data types / classes
-    + Sometimes `R` makes silly assumptions about your data class 
-        + Using `tibble`s help, but it might not solve all issues
-        + Think about your data in context, e.g. 0/1 variable is most likely a `factor`
-    + If a plot/output is not behaving the way you expect, first
-    investigate the data class
-    + If you are absolutely sure of a data class, overwrite it in your
-    tibble so that you don't need to keep having to keep track of it
-        + `mutate` the variable with the correct class
-        
----
-
-## Two data types worth knowing your way around
-
-- .huge-blue[factors]
+## Lists
 
-- .huge-blue[dates]
+Lists are a generic vector container vectors of any type can go in them
 
----
 
-class: middle
+```r
+l &lt;- list(
+  x = 1:4,
+  y = c(""hi"", ""hello"", ""jello""),
+  z = c(TRUE, FALSE)
+)
+l
+```
 
-# Factors
+```
+## $x
+## [1] 1 2 3 4
+## 
+## $y
+## [1] ""hi""    ""hello"" ""jello""
+## 
+## $z
+## [1]  TRUE FALSE
+```
 
 ---
 
-## Factors
+## Lists and data frames
 
-Factor objects are how R stores data for categorical variables (fixed numbers of discrete values).
+- A data frame is a special list containing vectors of equal length
+- When we use the `pull()` function, we extract a vector from the data frame
 
 
 ```r
-(x = factor(c(""BS"", ""MS"", ""PhD"", ""MS"")))
+df
 ```
 
 ```
-## [1] BS  MS  PhD MS 
-## Levels: BS MS PhD
+##   x y
+## 1 1 3
+## 2 2 4
 ```
 
-
 ```r
-glimpse(x)
+df %&gt;%
+  pull(y)
 ```
 
 ```
-##  Factor w/ 3 levels ""BS"",""MS"",""PhD"": 1 2 3 2
+## [1] 3 4
 ```
 
 
-```r
-typeof(x)
-```
+---
 
-```
-## [1] ""integer""
-```
+class: middle
+
+# Working with factors
 
 ---
 
@@ -1038,7 +1001,7 @@
   geom_bar()
 ```
 
-&lt;img src=""u1_d08-data-types_files/figure-html/unnamed-chunk-51-1.png"" width=""70%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d08-data-types_files/figure-html/unnamed-chunk-46-1.png"" width=""70%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -1052,7 +1015,7 @@
   geom_bar()
 ```
 
-&lt;img src=""u1_d08-data-types_files/figure-html/unnamed-chunk-52-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d08-data-types_files/figure-html/unnamed-chunk-47-1.png"" width=""70%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -1064,26 +1027,26 @@
 .pull-right[
 &lt;img src=""img/forcats-part-of-tidyverse.png"" width=""70%"" style=""display: block; margin: auto;"" /&gt;
 ]
-
-- R uses factors to handle categorical variables, variables that have a fixed and known set of possible values
 - Factors are useful when you have true categorical data and you want to override the ordering of character vectors to improve display
 - They are also useful in modeling scenarios
 - The **forcats** package provides a suite of useful tools that solve common problems with factors
 
 ---
 
+.small[
 .your-turn[
-- [RStudio Cloud](http://rstd.io/dsbox-cloud) &gt; start `AE 06 - Hotels + Data types` &gt; open `hotels-forcats.Rmd` and knit.
+- [RStudio Cloud](http://rstd.io/dsbox-cloud) &gt; `AE 06 - Hotels + Data types` &gt; `hotels-forcats.Rmd` &gt; knit
 - Recreate the following. The x-axis first, then, as a stretch goal, the y-axis.
 ]
+]
 
-&lt;img src=""u1_d08-data-types_files/figure-html/unnamed-chunk-54-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d08-data-types_files/figure-html/unnamed-chunk-49-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
 class: middle
 
-# Dates
+# Working with dates
 
 ---
 
@@ -1132,7 +1095,7 @@
 
 ---
 
-### Step 1. Put together dates.
+## Step 1. Put together dates.
 
 .midi[
 
@@ -1162,7 +1125,7 @@
 
 ---
 
-### Step 2. Count number of bookings per date.
+## Step 2. Count number of bookings per date.
 
 .midi[
 
@@ -1188,7 +1151,7 @@
 
 ---
 
-### Step 3. Visualise number of bookings per date.
+## Step 3. Visualise number of bookings per date.
 
 .midi[
 
@@ -1197,11 +1160,10 @@
   mutate(arrival_date = glue(""{arrival_date_year} {arrival_date_month} {arrival_date_day_of_month}"")) %&gt;%
   count(arrival_date) %&gt;%
   ggplot(aes(x = arrival_date, y = n, group = 1)) +
-  geom_line() +
-  ylim(0, 450)
+  geom_line()
 ```
 
-&lt;img src=""u1_d08-data-types_files/figure-html/unnamed-chunk-59-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d08-data-types_files/figure-html/unnamed-chunk-54-1.png"" width=""70%"" style=""display: block; margin: auto;"" /&gt;
 ]
 
 ---
@@ -1213,12 +1175,12 @@
 ]
 
 .midi[
-&lt;img src=""u1_d08-data-types_files/figure-html/unnamed-chunk-60-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d08-data-types_files/figure-html/unnamed-chunk-55-1.png"" width=""70%"" style=""display: block; margin: auto;"" /&gt;
 ]
 
 ---
 
-### Step 1. `REVISED` Put together dates `as dates`.
+## Step 1. `REVISED` Put together dates `as dates`.
 
 .midi[
 
@@ -1248,7 +1210,7 @@
 
 ---
 
-### Step 2. Count number of bookings per date.
+## Step 2. Count number of bookings per date.
 
 .midi[
 
@@ -1274,7 +1236,7 @@
 
 ---
 
-### Step 3a. Visualise number of bookings per date.
+## Step 3a. Visualise number of bookings per date.
 
 .midi[
 
@@ -1283,16 +1245,15 @@
   mutate(arrival_date = ymd(glue(""{arrival_date_year} {arrival_date_month} {arrival_date_day_of_month}""))) %&gt;% 
   count(arrival_date) %&gt;%
   ggplot(aes(x = arrival_date, y = n, group = 1)) +
-  geom_line() +
-  ylim(0, 450)
+  geom_line()
 ```
 
-&lt;img src=""u1_d08-data-types_files/figure-html/unnamed-chunk-63-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d08-data-types_files/figure-html/unnamed-chunk-58-1.png"" width=""70%"" style=""display: block; margin: auto;"" /&gt;
 ]
 
 ---
 
-### Step 3b. Visualise using a smooth curve.
+## Step 3b. Visualise using a smooth curve.
 
 .midi[
 
@@ -1301,11 +1262,10 @@
   mutate(arrival_date = ymd(glue(""{arrival_date_year} {arrival_date_month} {arrival_date_day_of_month}""))) %&gt;% 
   count(arrival_date) %&gt;%
   ggplot(aes(x = arrival_date, y = n, group = 1)) +
-* geom_smooth() +
-  ylim(0, 450)
+* geom_smooth()
 ```
 
-&lt;img src=""u1_d08-data-types_files/figure-html/unnamed-chunk-64-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+&lt;img src=""u1_d08-data-types_files/figure-html/unnamed-chunk-59-1.png"" width=""70%"" style=""display: block; margin: auto;"" /&gt;
 ]
     </textarea>
 <style data-target=""print-only"">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>",False,True,Visualization / Plotting,6
tidyverse,datascience-box,c30c6e9454614d0cd17684a3d3d72a072ed98862,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-09-03T15:39:08Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-09-03T15:39:08Z,Fix slides,course-materials/slides/u1_d07-tidy-data/libs/animate.css/animate.xaringan.css;course-materials/slides/u1_d07-tidy-data/libs/panelset/panelset.css;course-materials/slides/u1_d07-tidy-data/libs/panelset/panelset.js;course-materials/slides/u1_d07-tidy-data/libs/tachyons/tachyons.min.css;course-materials/slides/u1_d07-tidy-data/libs/tile-view/tile-view.css;course-materials/slides/u1_d07-tidy-data/libs/tile-view/tile-view.js;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data.Rmd;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data.html;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/bottom-legend-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/fix-labels-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/income-relevel-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/legend-adjust-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/unnamed-chunk-10-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/unnamed-chunk-11-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/unnamed-chunk-12-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/unnamed-chunk-13-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/unnamed-chunk-14-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/unnamed-chunk-17-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/unnamed-chunk-19-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/unnamed-chunk-20-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/unnamed-chunk-29-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/unnamed-chunk-30-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/unnamed-chunk-31-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/unnamed-chunk-32-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/unnamed-chunk-33-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/unnamed-chunk-34-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/unnamed-chunk-35-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/unnamed-chunk-36-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/unnamed-chunk-37-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/unnamed-chunk-38-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/unnamed-chunk-39-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/unnamed-chunk-8-1.png;course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data_files/figure-html/unnamed-chunk-9-1.png,True,False,True,False,4522,199,4721,"---FILE: course-materials/slides/u1_d07-tidy-data/libs/panelset/panelset.css---
@@ -0,0 +1,94 @@
+/* prefixed by https://autoprefixer.github.io (PostCSS: v7.0.23, autoprefixer: v9.7.3) */
+
+.panelset {
+  width: 100%;
+  position: relative;
+  --panel-tabs-border-bottom: #ddd;
+  --panel-tab-color: currentColor;
+  --panel-tab-color-active: currentColor;
+  --panel-tab-color-hover: currentColor;
+  --panel-tab-background-color: unset;
+  --panel-tab-background-color-active: unset;
+  --panel-tab-background-color-hover: unset;
+  --panel-tab-border-color-active: currentColor;
+  --panel-tab-border-color-hover: currentColor;
+  --panel-tab-inactive-opacity: 0.5;
+  --panel-tab-font-family: Menlo, Consolas, Monaco, Liberation Mono, Lucida Console, monospace;
+}
+
+.panelset * {
+  box-sizing: border-box;
+}
+
+.panelset .panel-tabs {
+  display: -webkit-box;
+  display: flex;
+  -webkit-box-orient: horizontal;
+  -webkit-box-direction: normal;
+          flex-direction: row;
+  -webkit-box-pack: start;
+          justify-content: start;
+  -webkit-box-align: center;
+          align-items: center;
+  border-bottom: 2px solid var(--panel-tabs-border-bottom);
+  padding: 0;
+}
+
+.panelset .panel-tabs * {
+  -webkit-transition: opacity 0.5s ease;
+  transition: opacity 0.5s ease;
+}
+
+.panelset .panel-tabs .panel-tab {
+  min-height: 50px;
+  display: -webkit-box;
+  display: flex;
+  -webkit-box-pack: center;
+          justify-content: center;
+  -webkit-box-align: center;
+          align-items: center;
+  padding: 0.5em 1em;
+  font-family: var(--panel-tab-font-family);
+  opacity: var(--panel-tab-inactive-opacity);
+  border-top: 2px solid transparent;
+  border-bottom: 2px solid transparent;
+  margin-bottom: -2px;
+  color: var(--panel-tab-color);
+  background-color: var(--panel-tab-background-color);
+  list-style: none;
+}
+
+.panelset .panel-tabs .panel-tab > a {
+  color: currentColor;
+  text-decoration: none;
+}
+
+.panelset .panel-tabs .panel-tab:hover {
+  border-bottom-color: var(--panel-tab-border-color-hover);
+  color: var(--panel-tab-color-hover);
+  background-color: var(--panel-tab-background-color-hover);
+  opacity: 1;
+  cursor: pointer;
+}
+
+.panelset .panel-tabs .panel-tab:focus {
+  outline: none;
+  color: var(--panel-tab-color-hover);
+  border-bottom-color: var(--panel-tab-border-color-hover);
+  background-color: var(--panel-tab-background-color-hover);
+}
+
+.panelset .panel-tabs .panel-tab.panel-tab-active {
+  border-top-color: var(--panel-tab-border-color-active);
+  color: var(--panel-tab-color-active);
+  background-color: var(--panel-tab-background-color-active);
+  opacity: 1;
+}
+
+.panelset .panel {
+  display: none;
+}
+
+.panelset .panel-active {
+  display: block;
+}

---FILE: course-materials/slides/u1_d07-tidy-data/libs/panelset/panelset.js---
@@ -0,0 +1,243 @@
+/* global slideshow */
+(function () {
+  const ready = function (fn) {
+    /* MIT License Copyright (c) 2016 Nuclei */
+    /* https://github.com/nuclei/readyjs */
+    const completed = () => {
+      document.removeEventListener('DOMContentLoaded', completed)
+      window.removeEventListener('load', completed)
+      fn()
+    }
+    if (document.readyState !== 'loading') {
+      setTimeout(fn)
+    } else {
+      document.addEventListener('DOMContentLoaded', completed)
+      window.addEventListener('load', completed)
+    }
+  }
+
+  ready(function () {
+    [...document.querySelectorAll('.panel-name')]
+      .map(el => el.textContent.trim())
+
+    const panelIds = {}
+
+    const uniquePanelId = (name) => {
+      name = encodeURIComponent(name.toLowerCase().replace(/[\s]/g, '-'))
+      if (Object.keys(panelIds).includes(name)) {
+        name += ++panelIds[name]
+      } else {
+        panelIds[name] = 1
+      }
+      return name
+    }
+
+    const processPanelItem = (item) => {
+      const nameDiv = item.querySelector('.panel-name')
+      let name = 'Panel'
+      if (nameDiv) {
+        name = nameDiv.textContent.trim()
+        if (nameDiv.tagName === 'SPAN' && nameDiv.parentNode.tagName === 'P') {
+          item.removeChild(nameDiv.parentNode)
+        } else {
+          item.removeChild(nameDiv)
+        }
+      }
+      return { name, content: item.children, id: uniquePanelId(name) }
+    }
+
+    const getCurrentPanelFromUrl = (panelset) => {
+      const params = new URLSearchParams(window.location.search)
+      return params.get(panelset)
+    }
+
+    const reflowPanelSet = (panels, idx) => {
+      const res = document.createElement('div')
+      res.className = 'panelset'
+      res.id = 'panelset' + (idx > 0 ? idx : '')
+      const panelSelected = getCurrentPanelFromUrl(res.id)
+
+      // create header row
+      const headerRow = document.createElement('ul')
+      headerRow.className = 'panel-tabs'
+      headerRow.setAttribute('role', 'tablist')
+      panels
+        .map((p, idx) => {
+          const panelHeaderItem = document.createElement('li')
+          panelHeaderItem.className = 'panel-tab'
+          panelHeaderItem.setAttribute('role', 'tab')
+          const thisPanelIsActive = panelSelected ? panelSelected === p.id : idx === 0
+          if (thisPanelIsActive) {
+            panelHeaderItem.classList.add('panel-tab-active')
+            panelHeaderItem.setAttribute('aria-selected', true)
+          }
+          panelHeaderItem.tabIndex = 0
+          panelHeaderItem.id = res.id + '_' + p.id // #panelsetid_panelid
+
+          const panelHeaderLink = document.createElement('a')
+          panelHeaderLink.href = '?' + res.id + '=' + p.id + '#' + panelHeaderItem.id
+          panelHeaderLink.setAttribute('onclick', 'return false;')
+          panelHeaderLink.tabIndex = -1 // list item is tabable, not link
+          panelHeaderLink.innerHTML = p.name
+          panelHeaderLink.setAttribute('aria-controls', p.id)
+
+          panelHeaderItem.appendChild(panelHeaderLink)
+          return panelHeaderItem
+        })
+        .forEach(el => headerRow.appendChild(el))
+
+      res.appendChild(headerRow)
+
+      panels
+        .map((p, idx) => {
+          const panelContent = document.createElement('section')
+          panelContent.className = 'panel'
+          panelContent.setAttribute('role', 'tabpanel')
+          const thisPanelIsActive = panelSelected ? panelSelected === p.id : idx === 0
+          panelContent.classList.toggle('panel-active', thisPanelIsActive)
+          panelContent.id = p.id
+          panelContent.setAttribute('aria-labelledby', p.id)
+          Array.from(p.content).forEach(el => panelContent.appendChild(el))
+          return panelContent
+        })
+        .forEach(el => res.appendChild(el))
+
+      return res
+    }
+
+    const updateUrl = (panelset, panel) => {
+      let params = new URLSearchParams(window.location.search)
+      if (panel) {
+        params.set(panelset, panel)
+      } else {
+        params.delete(panelset)
+      }
+      params = params.toString() ? ('?' + params.toString()) : ''
+      const { pathname, hash } = window.location
+      const uri = pathname + params + hash
+      window.history.replaceState(uri, '', uri)
+    }
+
+    const togglePanel = (clicked) => {
+      if (clicked.nodeName.toUpperCase() === 'A') {
+        clicked = clicked.parentElement
+      }
+      if (!clicked.classList.contains('panel-tab')) return
+      if (clicked.classList.contains('panel-tab-active')) return
+
+      const tabs = clicked.parentNode
+        .querySelectorAll('.panel-tab')
+      const panels = clicked.parentNode.parentNode
+        .querySelectorAll('.panel')
+      const panelTabClicked = clicked.children[0].getAttribute('aria-controls')
+      const panelClicked = clicked.parentNode.parentNode.id
+
+      Array.from(tabs)
+        .forEach(t => {
+          t.classList.remove('panel-tab-active')
+          t.removeAttribute('aria-selected')
+        })
+      Array.from(panels)
+        .forEach(p => {
+          const active = p.id === panelTabClicked
+          p.classList.toggle('panel-active', active)
+          // make inactive panels inaccessible by keyboard navigation
+          if (active) {
+            p.removeAttribute('tabIndex')
+            p.removeAttribute('aria-hidden')
+          } else {
+            p.setAttribute('tabIndex', -1)
+            p.setAttribute('aria-hidden', true)
+          }
+        })
+
+      clicked.classList.add('panel-tab-active')
+      clicked.setAttribute('aria-selected', true)
+
+      // update query string
+      updateUrl(panelClicked, panelTabClicked)
+    }
+
+    const initPanelSet = (panelset, idx) => {
+      const panels = Array.from(panelset.querySelectorAll('.panel'))
+      if (!panels.length) return
+
+      const contents = panels.map(processPanelItem)
+      const newPanelSet = reflowPanelSet(contents, idx)
+      panelset.parentNode.insertBefore(newPanelSet, panelset)
+      panelset.parentNode.removeChild(panelset)
+
+      // click and touch events
+      const panelTabs = newPanelSet.querySelector('.panel-tabs');
+      ['click', 'touchend'].forEach(eventType => {
+        panelTabs.addEventListener(eventType, function (ev) {
+          togglePanel(ev.target)
+          ev.stopPropagation()
+        })
+      })
+      panelTabs.addEventListener('touchmove', function (ev) {
+        ev.preventDefault()
+      })
+
+      // key events
+      newPanelSet
+        .querySelector('.panel-tabs')
+        .addEventListener('keydown', (ev) => {
+          const self = ev.currentTarget.querySelector('.panel-tab-active')
+          if (ev.code === 'Space' || ev.code === 'Enter') {
+            togglePanel(ev.target)
+            ev.stopPropagation()
+          } else if (ev.code === 'ArrowLeft' && self.previousSibling) {
+            togglePanel(self.previousSibling)
+            self.previousSibling.focus()
+            ev.stopPropagation()
+          } else if (ev.code === 'ArrowRight' && self.nextSibling) {
+            togglePanel(self.nextSibling)
+            self.nextSibling.focus()
+            ev.stopPropagation()
+          }
+        })
+
+      return panels
+    }
+
+    // initialize panels
+    Array.from(document.querySelectorAll('.panelset')).map(initPanelSet)
+
+    if (typeof slideshow !== 'undefined') {
+      const getVisibleActivePanelInfo = () => {
+        const slidePanels = document.querySelectorAll('.remark-visible .panel-tab-active')
+
+        if (!slidePanels.length) return null
+
+        return slidePanels.map(panel => {
+          return {
+            panel,
+            panelId: panel.children[0].getAttribute('aria-controls'),
+            panelSetId: panel.parentNode.parentNode.id
+          }
+        })
+      }
+
+      slideshow.on('hideSlide', slide => {
+        // clear focus if we had a panel-tab selected
+        document.activeElement.blur()
+
+        // clear search query for panelsets in current slide
+        document.querySelectorAll('.remark-visible .panelset')
+          .forEach(ps => updateUrl(ps.id, null))
+      })
+
+      slideshow.on('afterShowSlide', slide => {
+        const slidePanels = getVisibleActivePanelInfo()
+
+        if (slidePanels) {
+          // only first panel gets focus
+          slidePanels[0].panel.focus()
+          // but still update the url to reflect all active panels
+          slidePanels.forEach(({ panelId, panelSetId }) => updateUrl(panelSetId, panelId))
+        }
+      })
+    }
+  })
+})()

---FILE: course-materials/slides/u1_d07-tidy-data/libs/tachyons/tachyons.min.css---
@@ -0,0 +1,3 @@
+/*! TACHYONS v4.12.0 | http://tachyons.io */
+/*! normalize.css v8.0.0 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}h1{font-size:2em;margin:.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:.35em .75em .625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}[hidden],template{display:none}.border-box,a,article,aside,blockquote,body,code,dd,div,dl,dt,fieldset,figcaption,figure,footer,form,h1,h2,h3,h4,h5,h6,header,html,input[type=email],input[type=number],input[type=password],input[type=tel],input[type=text],input[type=url],legend,li,main,nav,ol,p,pre,section,table,td,textarea,th,tr,ul{box-sizing:border-box}.aspect-ratio{height:0;position:relative}.aspect-ratio--16x9{padding-bottom:56.25%}.aspect-ratio--9x16{padding-bottom:177.77%}.aspect-ratio--4x3{padding-bottom:75%}.aspect-ratio--3x4{padding-bottom:133.33%}.aspect-ratio--6x4{padding-bottom:66.6%}.aspect-ratio--4x6{padding-bottom:150%}.aspect-ratio--8x5{padding-bottom:62.5%}.aspect-ratio--5x8{padding-bottom:160%}.aspect-ratio--7x5{padding-bottom:71.42%}.aspect-ratio--5x7{padding-bottom:140%}.aspect-ratio--1x1{padding-bottom:100%}.aspect-ratio--object{position:absolute;top:0;right:0;bottom:0;left:0;width:100%;height:100%;z-index:100}img{max-width:100%}.cover{background-size:cover!important}.contain{background-size:contain!important}.bg-center{background-position:50%}.bg-center,.bg-top{background-repeat:no-repeat}.bg-top{background-position:top}.bg-right{background-position:100%}.bg-bottom,.bg-right{background-repeat:no-repeat}.bg-bottom{background-position:bottom}.bg-left{background-repeat:no-repeat;background-position:0}.outline{outline:1px solid}.outline-transparent{outline:1px solid transparent}.outline-0{outline:0}.ba{border-style:solid;border-width:1px}.bt{border-top-style:solid;border-top-width:1px}.br{border-right-style:solid;border-right-width:1px}.bb{border-bottom-style:solid;border-bottom-width:1px}.bl{border-left-style:solid;border-left-width:1px}.bn{border-style:none;border-width:0}.b--black{border-color:#000}.b--near-black{border-color:#111}.b--dark-gray{border-color:#333}.b--mid-gray{border-color:#555}.b--gray{border-color:#777}.b--silver{border-color:#999}.b--light-silver{border-color:#aaa}.b--moon-gray{border-color:#ccc}.b--light-gray{border-color:#eee}.b--near-white{border-color:#f4f4f4}.b--white{border-color:#fff}.b--white-90{border-color:hsla(0,0%,100%,.9)}.b--white-80{border-color:hsla(0,0%,100%,.8)}.b--white-70{border-color:hsla(0,0%,100%,.7)}.b--white-60{border-color:hsla(0,0%,100%,.6)}.b--white-50{border-color:hsla(0,0%,100%,.5)}.b--white-40{border-color:hsla(0,0%,100%,.4)}.b--white-30{border-color:hsla(0,0%,100%,.3)}.b--white-20{border-color:hsla(0,0%,100%,.2)}.b--white-10{border-color:hsla(0,0%,100%,.1)}.b--white-05{border-color:hsla(0,0%,100%,.05)}.b--white-025{border-color:hsla(0,0%,100%,.025)}.b--white-0125{border-color:hsla(0,0%,100%,.0125)}.b--black-90{border-color:rgba(0,0,0,.9)}.b--black-80{border-color:rgba(0,0,0,.8)}.b--black-70{border-color:rgba(0,0,0,.7)}.b--black-60{border-color:rgba(0,0,0,.6)}.b--black-50{border-color:rgba(0,0,0,.5)}.b--black-40{border-color:rgba(0,0,0,.4)}.b--black-30{border-color:rgba(0,0,0,.3)}.b--black-20{border-color:rgba(0,0,0,.2)}.b--black-10{border-color:rgba(0,0,0,.1)}.b--black-05{border-color:rgba(0,0,0,.05)}.b--black-025{border-color:rgba(0,0,0,.025)}.b--black-0125{border-color:rgba(0,0,0,.0125)}.b--dark-red{border-color:#e7040f}.b--red{border-color:#ff4136}.b--light-red{border-color:#ff725c}.b--orange{border-color:#ff6300}.b--gold{border-color:#ffb700}.b--yellow{border-color:gold}.b--light-yellow{border-color:#fbf1a9}.b--purple{border-color:#5e2ca5}.b--light-purple{border-color:#a463f2}.b--dark-pink{border-color:#d5008f}.b--hot-pink{border-color:#ff41b4}.b--pink{border-color:#ff80cc}.b--light-pink{border-color:#ffa3d7}.b--dark-green{border-color:#137752}.b--green{border-color:#19a974}.b--light-green{border-color:#9eebcf}.b--navy{border-color:#001b44}.b--dark-blue{border-color:#00449e}.b--blue{border-color:#357edd}.b--light-blue{border-color:#96ccff}.b--lightest-blue{border-color:#cdecff}.b--washed-blue{border-color:#f6fffe}.b--washed-green{border-color:#e8fdf5}.b--washed-yellow{border-color:#fffceb}.b--washed-red{border-color:#ffdfdf}.b--transparent{border-color:transparent}.b--inherit{border-color:inherit}.b--initial{border-color:initial}.b--unset{border-color:unset}.br0{border-radius:0}.br1{border-radius:.125rem}.br2{border-radius:.25rem}.br3{border-radius:.5rem}.br4{border-radius:1rem}.br-100{border-radius:100%}.br-pill{border-radius:9999px}.br--bottom{border-top-left-radius:0;border-top-right-radius:0}.br--top{border-bottom-right-radius:0}.br--right,.br--top{border-bottom-left-radius:0}.br--right{border-top-left-radius:0}.br--left{border-top-right-radius:0;border-bottom-right-radius:0}.br-inherit{border-radius:inherit}.br-initial{border-radius:initial}.br-unset{border-radius:unset}.b--dotted{border-style:dotted}.b--dashed{border-style:dashed}.b--solid{border-style:solid}.b--none{border-style:none}.bw0{border-width:0}.bw1{border-width:.125rem}.bw2{border-width:.25rem}.bw3{border-width:.5rem}.bw4{border-width:1rem}.bw5{border-width:2rem}.bt-0{border-top-width:0}.br-0{border-right-width:0}.bb-0{border-bottom-width:0}.bl-0{border-left-width:0}.shadow-1{box-shadow:0 0 4px 2px rgba(0,0,0,.2)}.shadow-2{box-shadow:0 0 8px 2px rgba(0,0,0,.2)}.shadow-3{box-shadow:2px 2px 4px 2px rgba(0,0,0,.2)}.shadow-4{box-shadow:2px 2px 8px 0 rgba(0,0,0,.2)}.shadow-5{box-shadow:4px 4px 8px 0 rgba(0,0,0,.2)}.pre{overflow-x:auto;overflow-y:hidden;overflow:scroll}.top-0{top:0}.right-0{right:0}.bottom-0{bottom:0}.left-0{left:0}.top-1{top:1rem}.right-1{right:1rem}.bottom-1{bottom:1rem}.left-1{left:1rem}.top-2{top:2rem}.right-2{right:2rem}.bottom-2{bottom:2rem}.left-2{left:2rem}.top--1{top:-1rem}.right--1{right:-1rem}.bottom--1{bottom:-1rem}.left--1{left:-1rem}.top--2{top:-2rem}.right--2{right:-2rem}.bottom--2{bottom:-2rem}.left--2{left:-2rem}.absolute--fill{top:0;right:0;bottom:0;left:0}.cf:after,.cf:before{content:"" "";display:table}.cf:after{clear:both}.cf{*zoom:1}.cl{clear:left}.cr{clear:right}.cb{clear:both}.cn{clear:none}.dn{display:none}.di{display:inline}.db{display:block}.dib{display:inline-block}.dit{display:inline-table}.dt{display:table}.dtc{display:table-cell}.dt-row{display:table-row}.dt-row-group{display:table-row-group}.dt-column{display:table-column}.dt-column-group{display:table-column-group}.dt--fixed{table-layout:fixed;width:100%}.flex{display:flex}.inline-flex{display:inline-flex}.flex-auto{flex:1 1 auto;min-width:0;min-height:0}.flex-none{flex:none}.flex-column{flex-direction:column}.flex-row{flex-direction:row}.flex-wrap{flex-wrap:wrap}.flex-nowrap{flex-wrap:nowrap}.flex-wrap-reverse{flex-wrap:wrap-reverse}.flex-column-reverse{flex-direction:column-reverse}.flex-row-reverse{flex-direction:row-reverse}.items-start{align-items:flex-start}.items-end{align-items:flex-end}.items-center{align-items:center}.items-baseline{align-items:baseline}.items-stretch{align-items:stretch}.self-start{align-self:flex-start}.self-end{align-self:flex-end}.self-center{align-self:center}.self-baseline{align-self:baseline}.self-stretch{align-self:stretch}.justify-start{justify-content:flex-start}.justify-end{justify-content:flex-end}.justify-center{justify-content:center}.justify-between{justify-content:space-between}.justify-around{justify-content:space-around}.content-start{align-content:flex-start}.content-end{align-content:flex-end}.content-center{align-content:center}.content-between{align-content:space-between}.content-around{align-content:space-around}.content-stretch{align-content:stretch}.order-0{order:0}.order-1{order:1}.order-2{order:2}.order-3{order:3}.order-4{order:4}.order-5{order:5}.order-6{order:6}.order-7{order:7}.order-8{order:8}.order-last{order:99999}.flex-grow-0{flex-grow:0}.flex-grow-1{flex-grow:1}.flex-shrink-0{flex-shrink:0}.flex-shrink-1{flex-shrink:1}.fl{float:left}.fl,.fr{_display:inline}.fr{float:right}.fn{float:none}.sans-serif{font-family:-apple-system,BlinkMacSystemFont,avenir next,avenir,helvetica neue,helvetica,ubuntu,roboto,noto,segoe ui,arial,sans-serif}.serif{font-family:georgia,times,serif}.system-sans-serif{font-family:sans-serif}.system-serif{font-family:serif}.code,code{font-family:Consolas,monaco,monospace}.courier{font-family:Courier Next,courier,monospace}.helvetica{font-family:helvetica neue,helvetica,sans-serif}.avenir{font-family:avenir next,avenir,sans-serif}.athelas{font-family:athelas,georgia,serif}.georgia{font-family:georgia,serif}.times{font-family:times,serif}.bodoni{font-family:Bodoni MT,serif}.calisto{font-family:Calisto MT,serif}.garamond{font-family:garamond,serif}.baskerville{font-family:baskerville,serif}.i{font-style:italic}.fs-normal{font-style:normal}.normal{font-weight:400}.b{font-weight:700}.fw1{font-weight:100}.fw2{font-weight:200}.fw3{font-weight:300}.fw4{font-weight:400}.fw5{font-weight:500}.fw6{font-weight:600}.fw7{font-weight:700}.fw8{font-weight:800}.fw9{font-weight:900}.input-reset{-webkit-appearance:none;-moz-appearance:none}.button-reset::-moz-focus-inner,.input-reset::-moz-focus-inner{border:0;padding:0}.h1{height:1rem}.h2{height:2rem}.h3{height:4rem}.h4{height:8rem}.h5{height:16rem}.h-25{height:25%}.h-50{height:50%}.h-75{height:75%}.h-100{height:100%}.min-h-100{min-height:100%}.vh-25{height:25vh}.vh-50{height:50vh}.vh-75{height:75vh}.vh-100{height:100vh}.min-vh-100{min-height:100vh}.h-auto{height:auto}.h-inherit{height:inherit}.tracked{letter-spacing:.1em}.tracked-tight{letter-spacing:-.05em}.tracked-mega{letter-spacing:.25em}.lh-solid{line-height:1}.lh-title{line-height:1.25}.lh-copy{line-height:1.5}.link{text-decoration:none}.link,.link:active,.link:focus,.link:hover,.link:link,.link:visited{transition:color .15s ease-in}.link:focus{outline:1px dotted currentColor}.list{list-style-type:none}.mw-100{max-width:100%}.mw1{max-width:1rem}.mw2{max-width:2rem}.mw3{max-width:4rem}.mw4{max-width:8rem}.mw5{max-width:16rem}.mw6{max-width:32rem}.mw7{max-width:48rem}.mw8{max-width:64rem}.mw9{max-width:96rem}.mw-none{max-width:none}.w1{width:1rem}.w2{width:2rem}.w3{width:4rem}.w4{width:8rem}.w5{width:16rem}.w-10{width:10%}.w-20{width:20%}.w-25{width:25%}.w-30{width:30%}.w-33{width:33%}.w-34{width:34%}.w-40{width:40%}.w-50{width:50%}.w-60{width:60%}.w-70{width:70%}.w-75{width:75%}.w-80{width:80%}.w-90{width:90%}.w-100{width:100%}.w-third{width:33.33333%}.w-two-thirds{width:66.66667%}.w-auto{width:auto}.overflow-visible{overflow:visible}.overflow-hidden{overflow:hidden}.overflow-scroll{overflow:scroll}.overflow-auto{overflow:auto}.overflow-x-visible{overflow-x:visible}.overflow-x-hidden{overflow-x:hidden}.overflow-x-scroll{overflow-x:scroll}.overflow-x-auto{overflow-x:auto}.overflow-y-visible{overflow-y:visible}.overflow-y-hidden{overflow-y:hidden}.overflow-y-scroll{overflow-y:scroll}.overflow-y-auto{overflow-y:auto}.static{position:static}.relative{position:relative}.absolute{position:absolute}.fixed{position:fixed}.o-100{opacity:1}.o-90{opacity:.9}.o-80{opacity:.8}.o-70{opacity:.7}.o-60{opacity:.6}.o-50{opacity:.5}.o-40{opacity:.4}.o-30{opacity:.3}.o-20{opacity:.2}.o-10{opacity:.1}.o-05{opacity:.05}.o-025{opacity:.025}.o-0{opacity:0}.rotate-45{-webkit-transform:rotate(45deg);transform:rotate(45deg)}.rotate-90{-webkit-transform:rotate(90deg);transform:rotate(90deg)}.rotate-135{-webkit-transform:rotate(135deg);transform:rotate(135deg)}.rotate-180{-webkit-transform:rotate(180deg);transform:rotate(180deg)}.rotate-225{-webkit-transform:rotate(225deg);transform:rotate(225deg)}.rotate-270{-webkit-transform:rotate(270deg);transform:rotate(270deg)}.rotate-315{-webkit-transform:rotate(315deg);transform:rotate(315deg)}.black-90{color:rgba(0,0,0,.9)}.black-80{color:rgba(0,0,0,.8)}.black-70{color:rgba(0,0,0,.7)}.black-60{color:rgba(0,0,0,.6)}.black-50{color:rgba(0,0,0,.5)}.black-40{color:rgba(0,0,0,.4)}.black-30{color:rgba(0,0,0,.3)}.black-20{color:rgba(0,0,0,.2)}.black-10{color:rgba(0,0,0,.1)}.black-05{color:rgba(0,0,0,.05)}.white-90{color:hsla(0,0%,100%,.9)}.white-80{color:hsla(0,0%,100%,.8)}.white-70{color:hsla(0,0%,100%,.7)}.white-60{color:hsla(0,0%,100%,.6)}.white-50{color:hsla(0,0%,100%,.5)}.white-40{color:hsla(0,0%,100%,.4)}.white-30{color:hsla(0,0%,100%,.3)}.white-20{color:hsla(0,0%,100%,.2)}.white-10{color:hsla(0,0%,100%,.1)}.black{color:#000}.near-black{color:#111}.dark-gray{color:#333}.mid-gray{color:#555}.gray{color:#777}.silver{color:#999}.light-silver{color:#aaa}.moon-gray{color:#ccc}.light-gray{color:#eee}.near-white{color:#f4f4f4}.white{color:#fff}.dark-red{color:#e7040f}.red{color:#ff4136}.light-red{color:#ff725c}.orange{color:#ff6300}.gold{color:#ffb700}.yellow{color:gold}.light-yellow{color:#fbf1a9}.purple{color:#5e2ca5}.light-purple{color:#a463f2}.dark-pink{color:#d5008f}.hot-pink{color:#ff41b4}.pink{color:#ff80cc}.light-pink{color:#ffa3d7}.dark-green{color:#137752}.green{color:#19a974}.light-green{color:#9eebcf}.navy{color:#001b44}.dark-blue{color:#00449e}.blue{color:#357edd}.light-blue{color:#96ccff}.lightest-blue{color:#cdecff}.washed-blue{color:#f6fffe}.washed-green{color:#e8fdf5}.washed-yellow{color:#fffceb}.washed-red{color:#ffdfdf}.color-inherit{color:inherit}.bg-black-90{background-color:rgba(0,0,0,.9)}.bg-black-80{background-color:rgba(0,0,0,.8)}.bg-black-70{background-color:rgba(0,0,0,.7)}.bg-black-60{background-color:rgba(0,0,0,.6)}.bg-black-50{background-color:rgba(0,0,0,.5)}.bg-black-40{background-color:rgba(0,0,0,.4)}.bg-black-30{background-color:rgba(0,0,0,.3)}.bg-black-20{background-color:rgba(0,0,0,.2)}.bg-black-10{background-color:rgba(0,0,0,.1)}.bg-black-05{background-color:rgba(0,0,0,.05)}.bg-white-90{background-color:hsla(0,0%,100%,.9)}.bg-white-80{background-color:hsla(0,0%,100%,.8)}.bg-white-70{background-color:hsla(0,0%,100%,.7)}.bg-white-60{background-color:hsla(0,0%,100%,.6)}.bg-white-50{background-color:hsla(0,0%,100%,.5)}.bg-white-40{background-color:hsla(0,0%,100%,.4)}.bg-white-30{background-color:hsla(0,0%,100%,.3)}.bg-white-20{background-color:hsla(0,0%,100%,.2)}.bg-white-10{background-color:hsla(0,0%,100%,.1)}.bg-black{background-color:#000}.bg-near-black{background-color:#111}.bg-dark-gray{background-color:#333}.bg-mid-gray{background-color:#555}.bg-gray{background-color:#777}.bg-silver{background-color:#999}.bg-light-silver{background-color:#aaa}.bg-moon-gray{background-color:#ccc}.bg-light-gray{background-color:#eee}.bg-near-white{background-color:#f4f4f4}.bg-white{background-color:#fff}.bg-transparent{background-color:transparent}.bg-dark-red{background-color:#e7040f}.bg-red{background-color:#ff4136}.bg-light-red{background-color:#ff725c}.bg-orange{background-color:#ff6300}.bg-gold{background-color:#ffb700}.bg-yellow{background-color:gold}.bg-light-yellow{background-color:#fbf1a9}.bg-purple{background-color:#5e2ca5}.bg-light-purple{background-color:#a463f2}.bg-dark-pink{background-color:#d5008f}.bg-hot-pink{background-color:#ff41b4}.bg-pink{background-color:#ff80cc}.bg-light-pink{background-color:#ffa3d7}.bg-dark-green{background-color:#137752}.bg-green{background-color:#19a974}.bg-light-green{background-color:#9eebcf}.bg-navy{background-color:#001b44}.bg-dark-blue{background-color:#00449e}.bg-blue{background-color:#357edd}.bg-light-blue{background-color:#96ccff}.bg-lightest-blue{background-color:#cdecff}.bg-washed-blue{background-color:#f6fffe}.bg-washed-green{background-color:#e8fdf5}.bg-washed-yellow{background-color:#fffceb}.bg-washed-red{background-color:#ffdfdf}.bg-inherit{background-color:inherit}.hover-black:focus,.hover-black:hover{color:#000}.hover-near-black:focus,.hover-near-black:hover{color:#111}.hover-dark-gray:focus,.hover-dark-gray:hover{color:#333}.hover-mid-gray:focus,.hover-mid-gray:hover{color:#555}.hover-gray:focus,.hover-gray:hover{color:#777}.hover-silver:focus,.hover-silver:hover{color:#999}.hover-light-silver:focus,.hover-light-silver:hover{color:#aaa}.hover-moon-gray:focus,.hover-moon-gray:hover{color:#ccc}.hover-light-gray:focus,.hover-light-gray:hover{color:#eee}.hover-near-white:focus,.hover-near-white:hover{color:#f4f4f4}.hover-white:focus,.hover-white:hover{color:#fff}.hover-black-90:focus,.hover-black-90:hover{color:rgba(0,0,0,.9)}.hover-black-80:focus,.hover-black-80:hover{color:rgba(0,0,0,.8)}.hover-black-70:focus,.hover-black-70:hover{color:rgba(0,0,0,.7)}.hover-black-60:focus,.hover-black-60:hover{color:rgba(0,0,0,.6)}.hover-black-50:focus,.hover-black-50:hover{color:rgba(0,0,0,.5)}.hover-black-40:focus,.hover-black-40:hover{color:rgba(0,0,0,.4)}.hover-black-30:focus,.hover-black-30:hover{color:rgba(0,0,0,.3)}.hover-black-20:focus,.hover-black-20:hover{color:rgba(0,0,0,.2)}.hover-black-10:focus,.hover-black-10:hover{color:rgba(0,0,0,.1)}.hover-white-90:focus,.hover-white-90:hover{color:hsla(0,0%,100%,.9)}.hover-white-80:focus,.hover-white-80:hover{color:hsla(0,0%,100%,.8)}.hover-white-70:focus,.hover-white-70:hover{color:hsla(0,0%,100%,.7)}.hover-white-60:focus,.hover-white-60:hover{color:hsla(0,0%,100%,.6)}.hover-white-50:focus,.hover-white-50:hover{color:hsla(0,0%,100%,.5)}.hover-white-40:focus,.hover-white-40:hover{color:hsla(0,0%,100%,.4)}.hover-white-30:focus,.hover-white-30:hover{color:hsla(0,0%,100%,.3)}.hover-white-20:focus,.hover-white-20:hover{color:hsla(0,0%,100%,.2)}.hover-white-10:focus,.hover-white-10:hover{color:hsla(0,0%,100%,.1)}.hover-inherit:focus,.hover-inherit:hover{color:inherit}.hover-bg-black:focus,.hover-bg-black:hover{background-color:#000}.hover-bg-near-black:focus,.hover-bg-near-black:hover{background-color:#111}.hover-bg-dark-gray:focus,.hover-bg-dark-gray:hover{background-color:#333}.hover-bg-mid-gray:focus,.hover-bg-mid-gray:hover{background-color:#555}.hover-bg-gray:focus,.hover-bg-gray:hover{background-color:#777}.hover-bg-silver:focus,.hover-bg-silver:hover{background-color:#999}.hover-bg-light-silver:focus,.hover-bg-light-silver:hover{background-color:#aaa}.hover-bg-moon-gray:focus,.hover-bg-moon-gray:hover{background-color:#ccc}.hover-bg-light-gray:focus,.hover-bg-light-gray:hover{background-color:#eee}.hover-bg-near-white:focus,.hover-bg-near-white:hover{background-color:#f4f4f4}.hover-bg-white:focus,.hover-bg-white:hover{background-color:#fff}.hover-bg-transparent:focus,.hover-bg-transparent:hover{background-color:transparent}.hover-bg-black-90:focus,.hover-bg-black-90:hover{background-color:rgba(0,0,0,.9)}.hover-bg-black-80:focus,.hover-bg-black-80:hover{background-color:rgba(0,0,0,.8)}.hover-bg-black-70:focus,.hover-bg-black-70:hover{background-color:rgba(0,0,0,.7)}.hover-bg-black-60:focus,.hover-bg-black-60:hover{background-color:rgba(0,0,0,.6)}.hover-bg-black-50:focus,.hover-bg-black-50:hover{background-color:rgba(0,0,0,.5)}.hover-bg-black-40:focus,.hover-bg-black-40:hover{background-color:rgba(0,0,0,.4)}.hover-bg-black-30:focus,.hover-bg-black-30:hover{background-color:rgba(0,0,0,.3)}.hover-bg-black-20:focus,.hover-bg-black-20:hover{background-color:rgba(0,0,0,.2)}.hover-bg-black-10:focus,.hover-bg-black-10:hover{background-color:rgba(0,0,0,.1)}.hover-bg-white-90:focus,.hover-bg-white-90:hover{background-color:hsla(0,0%,100%,.9)}.hover-bg-white-80:focus,.hover-bg-white-80:hover{background-color:hsla(0,0%,100%,.8)}.hover-bg-white-70:focus,.hover-bg-white-70:hover{background-color:hsla(0,0%,100%,.7)}.hover-bg-white-60:focus,.hover-bg-white-60:hover{background-color:hsla(0,0%,100%,.6)}.hover-bg-white-50:focus,.hover-bg-white-50:hover{background-color:hsla(0,0%,100%,.5)}.hover-bg-white-40:focus,.hover-bg-white-40:hover{background-color:hsla(0,0%,100%,.4)}.hover-bg-white-30:focus,.hover-bg-white-30:hover{background-color:hsla(0,0%,100%,.3)}.hover-bg-white-20:focus,.hover-bg-white-20:hover{background-color:hsla(0,0%,100%,.2)}.hover-bg-white-10:focus,.hover-bg-white-10:hover{background-color:hsla(0,0%,100%,.1)}.hover-dark-red:focus,.hover-dark-red:hover{color:#e7040f}.hover-red:focus,.hover-red:hover{color:#ff4136}.hover-light-red:focus,.hover-light-red:hover{color:#ff725c}.hover-orange:focus,.hover-orange:hover{color:#ff6300}.hover-gold:focus,.hover-gold:hover{color:#ffb700}.hover-yellow:focus,.hover-yellow:hover{color:gold}.hover-light-yellow:focus,.hover-light-yellow:hover{color:#fbf1a9}.hover-purple:focus,.hover-purple:hover{color:#5e2ca5}.hover-light-purple:focus,.hover-light-purple:hover{color:#a463f2}.hover-dark-pink:focus,.hover-dark-pink:hover{color:#d5008f}.hover-hot-pink:focus,.hover-hot-pink:hover{color:#ff41b4}.hover-pink:focus,.hover-pink:hover{color:#ff80cc}.hover-light-pink:focus,.hover-light-pink:hover{color:#ffa3d7}.hover-dark-green:focus,.hover-dark-green:hover{color:#137752}.hover-green:focus,.hover-green:hover{color:#19a974}.hover-light-green:focus,.hover-light-green:hover{color:#9eebcf}.hover-navy:focus,.hover-navy:hover{color:#001b44}.hover-dark-blue:focus,.hover-dark-blue:hover{color:#00449e}.hover-blue:focus,.hover-blue:hover{color:#357edd}.hover-light-blue:focus,.hover-light-blue:hover{color:#96ccff}.hover-lightest-blue:focus,.hover-lightest-blue:hover{color:#cdecff}.hover-washed-blue:focus,.hover-washed-blue:hover{color:#f6fffe}.hover-washed-green:focus,.hover-washed-green:hover{color:#e8fdf5}.hover-washed-yellow:focus,.hover-washed-yellow:hover{color:#fffceb}.hover-washed-red:focus,.hover-washed-red:hover{color:#ffdfdf}.hover-bg-dark-red:focus,.hover-bg-dark-red:hover{background-color:#e7040f}.hover-bg-red:focus,.hover-bg-red:hover{background-color:#ff4136}.hover-bg-light-red:focus,.hover-bg-light-red:hover{background-color:#ff725c}.hover-bg-orange:focus,.hover-bg-orange:hover{background-color:#ff6300}.hover-bg-gold:focus,.hover-bg-gold:hover{background-color:#ffb700}.hover-bg-yellow:focus,.hover-bg-yellow:hover{background-color:gold}.hover-bg-light-yellow:focus,.hover-bg-light-yellow:hover{background-color:#fbf1a9}.hover-bg-purple:focus,.hover-bg-purple:hover{background-color:#5e2ca5}.hover-bg-light-purple:focus,.hover-bg-light-purple:hover{background-color:#a463f2}.hover-bg-dark-pink:focus,.hover-bg-dark-pink:hover{background-color:#d5008f}.hover-bg-hot-pink:focus,.hover-bg-hot-pink:hover{background-color:#ff41b4}.hover-bg-pink:focus,.hover-bg-pink:hover{background-color:#ff80cc}.hover-bg-light-pink:focus,.hover-bg-light-pink:hover{background-color:#ffa3d7}.hover-bg-dark-green:focus,.hover-bg-dark-green:hover{background-color:#137752}.hover-bg-green:focus,.hover-bg-green:hover{background-color:#19a974}.hover-bg-light-green:focus,.hover-bg-light-green:hover{background-color:#9eebcf}.hover-bg-navy:focus,.hover-bg-navy:hover{background-color:#001b44}.hover-bg-dark-blue:focus,.hover-bg-dark-blue:hover{background-color:#00449e}.hover-bg-blue:focus,.hover-bg-blue:hover{background-color:#357edd}.hover-bg-light-blue:focus,.hover-bg-light-blue:hover{background-color:#96ccff}.hover-bg-lightest-blue:focus,.hover-bg-lightest-blue:hover{background-color:#cdecff}.hover-bg-washed-blue:focus,.hover-bg-washed-blue:hover{background-color:#f6fffe}.hover-bg-washed-green:focus,.hover-bg-washed-green:hover{background-color:#e8fdf5}.hover-bg-washed-yellow:focus,.hover-bg-washed-yellow:hover{background-color:#fffceb}.hover-bg-washed-red:focus,.hover-bg-washed-red:hover{background-color:#ffdfdf}.hover-bg-inherit:focus,.hover-bg-inherit:hover{background-color:inherit}.pa0{padding:0}.pa1{padding:.25rem}.pa2{padding:.5rem}.pa3{padding:1rem}.pa4{padding:2rem}.pa5{padding:4rem}.pa6{padding:8rem}.pa7{padding:16rem}.pl0{padding-left:0}.pl1{padding-left:.25rem}.pl2{padding-left:.5rem}.pl3{padding-left:1rem}.pl4{padding-left:2rem}.pl5{padding-left:4rem}.pl6{padding-left:8rem}.pl7{padding-left:16rem}.pr0{padding-right:0}.pr1{padding-right:.25rem}.pr2{padding-right:.5rem}.pr3{padding-right:1rem}.pr4{padding-right:2rem}.pr5{padding-right:4rem}.pr6{padding-right:8rem}.pr7{padding-right:16rem}.pb0{padding-bottom:0}.pb1{padding-bottom:.25rem}.pb2{padding-bottom:.5rem}.pb3{padding-bottom:1rem}.pb4{padding-bottom:2rem}.pb5{padding-bottom:4rem}.pb6{padding-bottom:8rem}.pb7{padding-bottom:16rem}.pt0{padding-top:0}.pt1{padding-top:.25rem}.pt2{padding-top:.5rem}.pt3{padding-top:1rem}.pt4{padding-top:2rem}.pt5{padding-top:4rem}.pt6{padding-top:8rem}.pt7{padding-top:16rem}.pv0{padding-top:0;padding-bottom:0}.pv1{padding-top:.25rem;padding-bottom:.25rem}.pv2{padding-top:.5rem;padding-bottom:.5rem}.pv3{padding-top:1rem;padding-bottom:1rem}.pv4{padding-top:2rem;padding-bottom:2rem}.pv5{padding-top:4rem;padding-bottom:4rem}.pv6{padding-top:8rem;padding-bottom:8rem}.pv7{padding-top:16rem;padding-bottom:16rem}.ph0{padding-left:0;padding-right:0}.ph1{padding-left:.25rem;padding-right:.25rem}.ph2{padding-left:.5rem;padding-right:.5rem}.ph3{padding-left:1rem;padding-right:1rem}.ph4{padding-left:2rem;padding-right:2rem}.ph5{padding-left:4rem;padding-right:4rem}.ph6{padding-left:8rem;padding-right:8rem}.ph7{padding-left:16rem;padding-right:16rem}.ma0{margin:0}.ma1{margin:.25rem}.ma2{margin:.5rem}.ma3{margin:1rem}.ma4{margin:2rem}.ma5{margin:4rem}.ma6{margin:8rem}.ma7{margin:16rem}.ml0{margin-left:0}.ml1{margin-left:.25rem}.ml2{margin-left:.5rem}.ml3{margin-left:1rem}.ml4{margin-left:2rem}.ml5{margin-left:4rem}.ml6{margin-left:8rem}.ml7{margin-left:16rem}.mr0{margin-right:0}.mr1{margin-right:.25rem}.mr2{margin-right:.5rem}.mr3{margin-right:1rem}.mr4{margin-right:2rem}.mr5{margin-right:4rem}.mr6{margin-right:8rem}.mr7{margin-right:16rem}.mb0{margin-bottom:0}.mb1{margin-bottom:.25rem}.mb2{margin-bottom:.5rem}.mb3{margin-bottom:1rem}.mb4{margin-bottom:2rem}.mb5{margin-bottom:4rem}.mb6{margin-bottom:8rem}.mb7{margin-bottom:16rem}.mt0{margin-top:0}.mt1{margin-top:.25rem}.mt2{margin-top:.5rem}.mt3{margin-top:1rem}.mt4{margin-top:2rem}.mt5{margin-top:4rem}.mt6{margin-top:8rem}.mt7{margin-top:16rem}.mv0{margin-top:0;margin-bottom:0}.mv1{margin-top:.25rem;margin-bottom:.25rem}.mv2{margin-top:.5rem;margin-bottom:.5rem}.mv3{margin-top:1rem;margin-bottom:1rem}.mv4{margin-top:2rem;margin-bottom:2rem}.mv5{margin-top:4rem;margin-bottom:4rem}.mv6{margin-top:8rem;margin-bottom:8rem}.mv7{margin-top:16rem;margin-bottom:16rem}.mh0{margin-left:0;margin-right:0}.mh1{margin-left:.25rem;margin-right:.25rem}.mh2{margin-left:.5rem;margin-right:.5rem}.mh3{margin-left:1rem;margin-right:1rem}.mh4{margin-left:2rem;margin-right:2rem}.mh5{margin-left:4rem;margin-right:4rem}.mh6{margin-left:8rem;margin-right:8rem}.mh7{margin-left:16rem;margin-right:16rem}.na1{margin:-.25rem}.na2{margin:-.5rem}.na3{margin:-1rem}.na4{margin:-2rem}.na5{margin:-4rem}.na6{margin:-8rem}.na7{margin:-16rem}.nl1{margin-left:-.25rem}.nl2{margin-left:-.5rem}.nl3{margin-left:-1rem}.nl4{margin-left:-2rem}.nl5{margin-left:-4rem}.nl6{margin-left:-8rem}.nl7{margin-left:-16rem}.nr1{margin-right:-.25rem}.nr2{margin-right:-.5rem}.nr3{margin-right:-1rem}.nr4{margin-right:-2rem}.nr5{margin-right:-4rem}.nr6{margin-right:-8rem}.nr7{margin-right:-16rem}.nb1{margin-bottom:-.25rem}.nb2{margin-bottom:-.5rem}.nb3{margin-bottom:-1rem}.nb4{margin-bottom:-2rem}.nb5{margin-bottom:-4rem}.nb6{margin-bottom:-8rem}.nb7{margin-bottom:-16rem}.nt1{margin-top:-.25rem}.nt2{margin-top:-.5rem}.nt3{margin-top:-1rem}.nt4{margin-top:-2rem}.nt5{margin-top:-4rem}.nt6{margin-top:-8rem}.nt7{margin-top:-16rem}.collapse{border-collapse:collapse;border-spacing:0}.striped--light-silver:nth-child(odd){background-color:#aaa}.striped--moon-gray:nth-child(odd){background-color:#ccc}.striped--light-gray:nth-child(odd){background-color:#eee}.striped--near-white:nth-child(odd){background-color:#f4f4f4}.stripe-light:nth-child(odd){background-color:hsla(0,0%,100%,.1)}.stripe-dark:nth-child(odd){background-color:rgba(0,0,0,.1)}.strike{text-decoration:line-through}.underline{text-decoration:underline}.no-underline{text-decoration:none}.tl{text-align:left}.tr{text-align:right}.tc{text-align:center}.tj{text-align:justify}.ttc{text-transform:capitalize}.ttl{text-transform:lowercase}.ttu{text-transform:uppercase}.ttn{text-transform:none}.f-6,.f-headline{font-size:6rem}.f-5,.f-subheadline{font-size:5rem}.f1{font-size:3rem}.f2{font-size:2.25rem}.f3{font-size:1.5rem}.f4{font-size:1.25rem}.f5{font-size:1rem}.f6{font-size:.875rem}.f7{font-size:.75rem}.measure{max-width:30em}.measure-wide{max-width:34em}.measure-narrow{max-width:20em}.indent{text-indent:1em;margin-top:0;margin-bottom:0}.small-caps{font-variant:small-caps}.truncate{white-space:nowrap;overflow:hidden;text-overflow:ellipsis}.overflow-container{overflow-y:scroll}.center{margin-left:auto}.center,.mr-auto{margin-right:auto}.ml-auto{margin-left:auto}.clip{position:fixed!important;_position:absolute!important;clip:rect(1px 1px 1px 1px);clip:rect(1px,1px,1px,1px)}.ws-normal{white-space:normal}.nowrap{white-space:nowrap}.pre{white-space:pre}.v-base{vertical-align:baseline}.v-mid{vertical-align:middle}.v-top{vertical-align:top}.v-btm{vertical-align:bottom}.dim{opacity:1}.dim,.dim:focus,.dim:hover{transition:opacity .15s ease-in}.dim:focus,.dim:hover{opacity:.5}.dim:active{opacity:.8;transition:opacity .15s ease-out}.glow,.glow:focus,.glow:hover{transition:opacity .15s ease-in}.glow:focus,.glow:hover{opacity:1}.hide-child .child{opacity:0;transition:opacity .15s ease-in}.hide-child:active .child,.hide-child:focus .child,.hide-child:hover .child{opacity:1;transition:opacity .15s ease-in}.underline-hover:focus,.underline-hover:hover{text-decoration:underline}.grow{-moz-osx-font-smoothing:grayscale;-webkit-backface-visibility:hidden;backface-visibility:hidden;-webkit-transform:translateZ(0);transform:translateZ(0);transition:-webkit-transform .25s ease-out;transition:transform .25s ease-out;transition:transform .25s ease-out,-webkit-transform .25s ease-out}.grow:focus,.grow:hover{-webkit-transform:scale(1.05);transform:scale(1.05)}.grow:active{-webkit-transform:scale(.9);transform:scale(.9)}.grow-large{-moz-osx-font-smoothing:grayscale;-webkit-backface-visibility:hidden;backface-visibility:hidden;-webkit-transform:translateZ(0);transform:translateZ(0);transition:-webkit-transform .25s ease-in-out;transition:transform .25s ease-in-out;transition:transform .25s ease-in-out,-webkit-transform .25s ease-in-out}.grow-large:focus,.grow-large:hover{-webkit-transform:scale(1.2);transform:scale(1.2)}.grow-large:active{-webkit-transform:scale(.95);transform:scale(.95)}.pointer:hover,.shadow-hover{cursor:pointer}.shadow-hover{position:relative;transition:all .5s cubic-bezier(.165,.84,.44,1)}.shadow-hover:after{content:"""";box-shadow:0 0 16px 2px rgba(0,0,0,.2);border-radius:inherit;opacity:0;position:absolute;top:0;left:0;width:100%;height:100%;z-index:-1;transition:opacity .5s cubic-bezier(.165,.84,.44,1)}.shadow-hover:focus:after,.shadow-hover:hover:after{opacity:1}.bg-animate,.bg-animate:focus,.bg-animate:hover{transition:background-color .15s ease-in-out}.z-0{z-index:0}.z-1{z-index:1}.z-2{z-index:2}.z-3{z-index:3}.z-4{z-index:4}.z-5{z-index:5}.z-999{z-index:999}.z-9999{z-index:9999}.z-max{z-index:2147483647}.z-inherit{z-index:inherit}.z-initial{z-index:auto}.z-unset{z-index:unset}.nested-copy-line-height ol,.nested-copy-line-height p,.nested-copy-line-height ul{line-height:1.5}.nested-headline-line-height h1,.nested-headline-line-height h2,.nested-headline-line-height h3,.nested-headline-line-height h4,.nested-headline-line-height h5,.nested-headline-line-height h6{line-height:1.25}.nested-list-reset ol,.nested-list-reset ul{padding-left:0;margin-left:0;list-style-type:none}.nested-copy-indent p+p{text-indent:1em;margin-top:0;margin-bottom:0}.nested-copy-separator p+p{margin-top:1.5em}.nested-img img{width:100%;max-width:100%;display:block}.nested-links a{color:#357edd;transition:color .15s ease-in}.nested-links a:focus,.nested-links a:hover{color:#96ccff;transition:color .15s ease-in}.debug *{outline:1px solid gold}.debug-white *{outline:1px solid #fff}.debug-black *{outline:1px solid #000}.debug-grid{background:transparent url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAYAAADED76LAAAAFElEQVR4AWPAC97/9x0eCsAEPgwAVLshdpENIxcAAAAASUVORK5CYII=) repeat 0 0}.debug-grid-16{background:transparent url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAMklEQVR4AWOgCLz/b0epAa6UGuBOqQHOQHLUgFEDnAbcBZ4UGwDOkiCnkIhdgNgNxAYAiYlD+8sEuo8AAAAASUVORK5CYII=) repeat 0 0}.debug-grid-8-solid{background:#fff url(data:image/gif;base64,R0lGODdhCAAIAPEAAADw/wDx/////wAAACwAAAAACAAIAAACDZQvgaeb/lxbAIKA8y0AOw==) repeat 0 0}.debug-grid-16-solid{background:#fff url(data:image/gif;base64,R0lGODdhEAAQAPEAAADw/wDx/xXy/////ywAAAAAEAAQAAACIZyPKckYDQFsb6ZqD85jZ2+BkwiRFKehhqQCQgDHcgwEBQA7) repeat 0 0}@media screen and (min-width:30em){.aspect-ratio-ns{height:0;position:relative}.aspect-ratio--16x9-ns{padding-bottom:56.25%}.aspect-ratio--9x16-ns{padding-bottom:177.77%}.aspect-ratio--4x3-ns{padding-bottom:75%}.aspect-ratio--3x4-ns{padding-bottom:133.33%}.aspect-ratio--6x4-ns{padding-bottom:66.6%}.aspect-ratio--4x6-ns{padding-bottom:150%}.aspect-ratio--8x5-ns{padding-bottom:62.5%}.aspect-ratio--5x8-ns{padding-bottom:160%}.aspect-ratio--7x5-ns{padding-bottom:71.42%}.aspect-ratio--5x7-ns{padding-bottom:140%}.aspect-ratio--1x1-ns{padding-bottom:100%}.aspect-ratio--object-ns{position:absolute;top:0;right:0;bottom:0;left:0;width:100%;height:100%;z-index:100}.cover-ns{background-size:cover!important}.contain-ns{background-size:contain!important}.bg-center-ns{background-position:50%}.bg-center-ns,.bg-top-ns{background-repeat:no-repeat}.bg-top-ns{background-position:top}.bg-right-ns{background-position:100%}.bg-bottom-ns,.bg-right-ns{background-repeat:no-repeat}.bg-bottom-ns{background-position:bottom}.bg-left-ns{background-repeat:no-repeat;background-position:0}.outline-ns{outline:1px solid}.outline-transparent-ns{outline:1px solid transparent}.outline-0-ns{outline:0}.ba-ns{border-style:solid;border-width:1px}.bt-ns{border-top-style:solid;border-top-width:1px}.br-ns{border-right-style:solid;border-right-width:1px}.bb-ns{border-bottom-style:solid;border-bottom-width:1px}.bl-ns{border-left-style:solid;border-left-width:1px}.bn-ns{border-style:none;border-width:0}.br0-ns{border-radius:0}.br1-ns{border-radius:.125rem}.br2-ns{border-radius:.25rem}.br3-ns{border-radius:.5rem}.br4-ns{border-radius:1rem}.br-100-ns{border-radius:100%}.br-pill-ns{border-radius:9999px}.br--bottom-ns{border-top-left-radius:0;border-top-right-radius:0}.br--top-ns{border-bottom-right-radius:0}.br--right-ns,.br--top-ns{border-bottom-left-radius:0}.br--right-ns{border-top-left-radius:0}.br--left-ns{border-top-right-radius:0;border-bottom-right-radius:0}.br-inherit-ns{border-radius:inherit}.br-initial-ns{border-radius:initial}.br-unset-ns{border-radius:unset}.b--dotted-ns{border-style:dotted}.b--dashed-ns{border-style:dashed}.b--solid-ns{border-style:solid}.b--none-ns{border-style:none}.bw0-ns{border-width:0}.bw1-ns{border-width:.125rem}.bw2-ns{border-width:.25rem}.bw3-ns{border-width:.5rem}.bw4-ns{border-width:1rem}.bw5-ns{border-width:2rem}.bt-0-ns{border-top-width:0}.br-0-ns{border-right-width:0}.bb-0-ns{border-bottom-width:0}.bl-0-ns{border-left-width:0}.shadow-1-ns{box-shadow:0 0 4px 2px rgba(0,0,0,.2)}.shadow-2-ns{box-shadow:0 0 8px 2px rgba(0,0,0,.2)}.shadow-3-ns{box-shadow:2px 2px 4px 2px rgba(0,0,0,.2)}.shadow-4-ns{box-shadow:2px 2px 8px 0 rgba(0,0,0,.2)}.shadow-5-ns{box-shadow:4px 4px 8px 0 rgba(0,0,0,.2)}.top-0-ns{top:0}.left-0-ns{left:0}.right-0-ns{right:0}.bottom-0-ns{bottom:0}.top-1-ns{top:1rem}.left-1-ns{left:1rem}.right-1-ns{right:1rem}.bottom-1-ns{bottom:1rem}.top-2-ns{top:2rem}.left-2-ns{left:2rem}.right-2-ns{right:2rem}.bottom-2-ns{bottom:2rem}.top--1-ns{top:-1rem}.right--1-ns{right:-1rem}.bottom--1-ns{bottom:-1rem}.left--1-ns{left:-1rem}.top--2-ns{top:-2rem}.right--2-ns{right:-2rem}.bottom--2-ns{bottom:-2rem}.left--2-ns{left:-2rem}.absolute--fill-ns{top:0;right:0;bottom:0;left:0}.cl-ns{clear:left}.cr-ns{clear:right}.cb-ns{clear:both}.cn-ns{clear:none}.dn-ns{display:none}.di-ns{display:inline}.db-ns{display:block}.dib-ns{display:inline-block}.dit-ns{display:inline-table}.dt-ns{display:table}.dtc-ns{display:table-cell}.dt-row-ns{display:table-row}.dt-row-group-ns{display:table-row-group}.dt-column-ns{display:table-column}.dt-column-group-ns{display:table-column-group}.dt--fixed-ns{table-layout:fixed;width:100%}.flex-ns{display:flex}.inline-flex-ns{display:inline-flex}.flex-auto-ns{flex:1 1 auto;min-width:0;min-height:0}.flex-none-ns{flex:none}.flex-column-ns{flex-direction:column}.flex-row-ns{flex-direction:row}.flex-wrap-ns{flex-wrap:wrap}.flex-nowrap-ns{flex-wrap:nowrap}.flex-wrap-reverse-ns{flex-wrap:wrap-reverse}.flex-column-reverse-ns{flex-direction:column-reverse}.flex-row-reverse-ns{flex-direction:row-reverse}.items-start-ns{align-items:flex-start}.items-end-ns{align-items:flex-end}.items-center-ns{align-items:center}.items-baseline-ns{align-items:baseline}.items-stretch-ns{align-items:stretch}.self-start-ns{align-self:flex-start}.self-end-ns{align-self:flex-end}.self-center-ns{align-self:center}.self-baseline-ns{align-self:baseline}.self-stretch-ns{align-self:stretch}.justify-start-ns{justify-content:flex-start}.justify-end-ns{justify-content:flex-end}.justify-center-ns{justify-content:center}.justify-between-ns{justify-content:space-between}.justify-around-ns{justify-content:space-around}.content-start-ns{align-content:flex-start}.content-end-ns{align-content:flex-end}.content-center-ns{align-content:center}.content-between-ns{align-content:space-between}.content-around-ns{align-content:space-around}.content-stretch-ns{align-content:stretch}.order-0-ns{order:0}.order-1-ns{order:1}.order-2-ns{order:2}.order-3-ns{order:3}.order-4-ns{order:4}.order-5-ns{order:5}.order-6-ns{order:6}.order-7-ns{order:7}.order-8-ns{order:8}.order-last-ns{order:99999}.flex-grow-0-ns{flex-grow:0}.flex-grow-1-ns{flex-grow:1}.flex-shrink-0-ns{flex-shrink:0}.flex-shrink-1-ns{flex-shrink:1}.fl-ns{float:left}.fl-ns,.fr-ns{_display:inline}.fr-ns{float:right}.fn-ns{float:none}.i-ns{font-style:italic}.fs-normal-ns{font-style:normal}.normal-ns{font-weight:400}.b-ns{font-weight:700}.fw1-ns{font-weight:100}.fw2-ns{font-weight:200}.fw3-ns{font-weight:300}.fw4-ns{font-weight:400}.fw5-ns{font-weight:500}.fw6-ns{font-weight:600}.fw7-ns{font-weight:700}.fw8-ns{font-weight:800}.fw9-ns{font-weight:900}.h1-ns{height:1rem}.h2-ns{height:2rem}.h3-ns{height:4rem}.h4-ns{height:8rem}.h5-ns{height:16rem}.h-25-ns{height:25%}.h-50-ns{height:50%}.h-75-ns{height:75%}.h-100-ns{height:100%}.min-h-100-ns{min-height:100%}.vh-25-ns{height:25vh}.vh-50-ns{height:50vh}.vh-75-ns{height:75vh}.vh-100-ns{height:100vh}.min-vh-100-ns{min-height:100vh}.h-auto-ns{height:auto}.h-inherit-ns{height:inherit}.tracked-ns{letter-spacing:.1em}.tracked-tight-ns{letter-spacing:-.05em}.tracked-mega-ns{letter-spacing:.25em}.lh-solid-ns{line-height:1}.lh-title-ns{line-height:1.25}.lh-copy-ns{line-height:1.5}.mw-100-ns{max-width:100%}.mw1-ns{max-width:1rem}.mw2-ns{max-width:2rem}.mw3-ns{max-width:4rem}.mw4-ns{max-width:8rem}.mw5-ns{max-width:16rem}.mw6-ns{max-width:32rem}.mw7-ns{max-width:48rem}.mw8-ns{max-width:64rem}.mw9-ns{max-width:96rem}.mw-none-ns{max-width:none}.w1-ns{width:1rem}.w2-ns{width:2rem}.w3-ns{width:4rem}.w4-ns{width:8rem}.w5-ns{width:16rem}.w-10-ns{width:10%}.w-20-ns{width:20%}.w-25-ns{width:25%}.w-30-ns{width:30%}.w-33-ns{width:33%}.w-34-ns{width:34%}.w-40-ns{width:40%}.w-50-ns{width:50%}.w-60-ns{width:60%}.w-70-ns{width:70%}.w-75-ns{width:75%}.w-80-ns{width:80%}.w-90-ns{width:90%}.w-100-ns{width:100%}.w-third-ns{width:33.33333%}.w-two-thirds-ns{width:66.66667%}.w-auto-ns{width:auto}.overflow-visible-ns{overflow:visible}.overflow-hidden-ns{overflow:hidden}.overflow-scroll-ns{overflow:scroll}.overflow-auto-ns{overflow:auto}.overflow-x-visible-ns{overflow-x:visible}.overflow-x-hidden-ns{overflow-x:hidden}.overflow-x-scroll-ns{overflow-x:scroll}.overflow-x-auto-ns{overflow-x:auto}.overflow-y-visible-ns{overflow-y:visible}.overflow-y-hidden-ns{overflow-y:hidden}.overflow-y-scroll-ns{overflow-y:scroll}.overflow-y-auto-ns{overflow-y:auto}.static-ns{position:static}.relative-ns{position:relative}.absolute-ns{position:absolute}.fixed-ns{position:fixed}.rotate-45-ns{-webkit-transform:rotate(45deg);transform:rotate(45deg)}.rotate-90-ns{-webkit-transform:rotate(90deg);transform:rotate(90deg)}.rotate-135-ns{-webkit-transform:rotate(135deg);transform:rotate(135deg)}.rotate-180-ns{-webkit-transform:rotate(180deg);transform:rotate(180deg)}.rotate-225-ns{-webkit-transform:rotate(225deg);transform:rotate(225deg)}.rotate-270-ns{-webkit-transform:rotate(270deg);transform:rotate(270deg)}.rotate-315-ns{-webkit-transform:rotate(315deg);transform:rotate(315deg)}.pa0-ns{padding:0}.pa1-ns{padding:.25rem}.pa2-ns{padding:.5rem}.pa3-ns{padding:1rem}.pa4-ns{padding:2rem}.pa5-ns{padding:4rem}.pa6-ns{padding:8rem}.pa7-ns{padding:16rem}.pl0-ns{padding-left:0}.pl1-ns{padding-left:.25rem}.pl2-ns{padding-left:.5rem}.pl3-ns{padding-left:1rem}.pl4-ns{padding-left:2rem}.pl5-ns{padding-left:4rem}.pl6-ns{padding-left:8rem}.pl7-ns{padding-left:16rem}.pr0-ns{padding-right:0}.pr1-ns{padding-right:.25rem}.pr2-ns{padding-right:.5rem}.pr3-ns{padding-right:1rem}.pr4-ns{padding-right:2rem}.pr5-ns{padding-right:4rem}.pr6-ns{padding-right:8rem}.pr7-ns{padding-right:16rem}.pb0-ns{padding-bottom:0}.pb1-ns{padding-bottom:.25rem}.pb2-ns{padding-bottom:.5rem}.pb3-ns{padding-bottom:1rem}.pb4-ns{padding-bottom:2rem}.pb5-ns{padding-bottom:4rem}.pb6-ns{padding-bottom:8rem}.pb7-ns{padding-bottom:16rem}.pt0-ns{padding-top:0}.pt1-ns{padding-top:.25rem}.pt2-ns{padding-top:.5rem}.pt3-ns{padding-top:1rem}.pt4-ns{padding-top:2rem}.pt5-ns{padding-top:4rem}.pt6-ns{padding-top:8rem}.pt7-ns{padding-top:16rem}.pv0-ns{padding-top:0;padding-bottom:0}.pv1-ns{padding-top:.25rem;padding-bottom:.25rem}.pv2-ns{padding-top:.5rem;padding-bottom:.5rem}.pv3-ns{padding-top:1rem;padding-bottom:1rem}.pv4-ns{padding-top:2rem;padding-bottom:2rem}.pv5-ns{padding-top:4rem;padding-bottom:4rem}.pv6-ns{padding-top:8rem;padding-bottom:8rem}.pv7-ns{padding-top:16rem;padding-bottom:16rem}.ph0-ns{padding-left:0;padding-right:0}.ph1-ns{padding-left:.25rem;padding-right:.25rem}.ph2-ns{padding-left:.5rem;padding-right:.5rem}.ph3-ns{padding-left:1rem;padding-right:1rem}.ph4-ns{padding-left:2rem;padding-right:2rem}.ph5-ns{padding-left:4rem;padding-right:4rem}.ph6-ns{padding-left:8rem;padding-right:8rem}.ph7-ns{padding-left:16rem;padding-right:16rem}.ma0-ns{margin:0}.ma1-ns{margin:.25rem}.ma2-ns{margin:.5rem}.ma3-ns{margin:1rem}.ma4-ns{margin:2rem}.ma5-ns{margin:4rem}.ma6-ns{margin:8rem}.ma7-ns{margin:16rem}.ml0-ns{margin-left:0}.ml1-ns{margin-left:.25rem}.ml2-ns{margin-left:.5rem}.ml3-ns{margin-left:1rem}.ml4-ns{margin-left:2rem}.ml5-ns{margin-left:4rem}.ml6-ns{margin-left:8rem}.ml7-ns{margin-left:16rem}.mr0-ns{margin-right:0}.mr1-ns{margin-right:.25rem}.mr2-ns{margin-right:.5rem}.mr3-ns{margin-right:1rem}.mr4-ns{margin-right:2rem}.mr5-ns{margin-right:4rem}.mr6-ns{margin-right:8rem}.mr7-ns{margin-right:16rem}.mb0-ns{margin-bottom:0}.mb1-ns{margin-bottom:.25rem}.mb2-ns{margin-bottom:.5rem}.mb3-ns{margin-bottom:1rem}.mb4-ns{margin-bottom:2rem}.mb5-ns{margin-bottom:4rem}.mb6-ns{margin-bottom:8rem}.mb7-ns{margin-bottom:16rem}.mt0-ns{margin-top:0}.mt1-ns{margin-top:.25rem}.mt2-ns{margin-top:.5rem}.mt3-ns{margin-top:1rem}.mt4-ns{margin-top:2rem}.mt5-ns{margin-top:4rem}.mt6-ns{margin-top:8rem}.mt7-ns{margin-top:16rem}.mv0-ns{margin-top:0;margin-bottom:0}.mv1-ns{margin-top:.25rem;margin-bottom:.25rem}.mv2-ns{margin-top:.5rem;margin-bottom:.5rem}.mv3-ns{margin-top:1rem;margin-bottom:1rem}.mv4-ns{margin-top:2rem;margin-bottom:2rem}.mv5-ns{margin-top:4rem;margin-bottom:4rem}.mv6-ns{margin-top:8rem;margin-bottom:8rem}.mv7-ns{margin-top:16rem;margin-bottom:16rem}.mh0-ns{margin-left:0;margin-right:0}.mh1-ns{margin-left:.25rem;margin-right:.25rem}.mh2-ns{margin-left:.5rem;margin-right:.5rem}.mh3-ns{margin-left:1rem;margin-right:1rem}.mh4-ns{margin-left:2rem;margin-right:2rem}.mh5-ns{margin-left:4rem;margin-right:4rem}.mh6-ns{margin-left:8rem;margin-right:8rem}.mh7-ns{margin-left:16rem;margin-right:16rem}.na1-ns{margin:-.25rem}.na2-ns{margin:-.5rem}.na3-ns{margin:-1rem}.na4-ns{margin:-2rem}.na5-ns{margin:-4rem}.na6-ns{margin:-8rem}.na7-ns{margin:-16rem}.nl1-ns{margin-left:-.25rem}.nl2-ns{margin-left:-.5rem}.nl3-ns{margin-left:-1rem}.nl4-ns{margin-left:-2rem}.nl5-ns{margin-left:-4rem}.nl6-ns{margin-left:-8rem}.nl7-ns{margin-left:-16rem}.nr1-ns{margin-right:-.25rem}.nr2-ns{margin-right:-.5rem}.nr3-ns{margin-right:-1rem}.nr4-ns{margin-right:-2rem}.nr5-ns{margin-right:-4rem}.nr6-ns{margin-right:-8rem}.nr7-ns{margin-right:-16rem}.nb1-ns{margin-bottom:-.25rem}.nb2-ns{margin-bottom:-.5rem}.nb3-ns{margin-bottom:-1rem}.nb4-ns{margin-bottom:-2rem}.nb5-ns{margin-bottom:-4rem}.nb6-ns{margin-bottom:-8rem}.nb7-ns{margin-bottom:-16rem}.nt1-ns{margin-top:-.25rem}.nt2-ns{margin-top:-.5rem}.nt3-ns{margin-top:-1rem}.nt4-ns{margin-top:-2rem}.nt5-ns{margin-top:-4rem}.nt6-ns{margin-top:-8rem}.nt7-ns{margin-top:-16rem}.strike-ns{text-decoration:line-through}.underline-ns{text-decoration:underline}.no-underline-ns{text-decoration:none}.tl-ns{text-align:left}.tr-ns{text-align:right}.tc-ns{text-align:center}.tj-ns{text-align:justify}.ttc-ns{text-transform:capitalize}.ttl-ns{text-transform:lowercase}.ttu-ns{text-transform:uppercase}.ttn-ns{text-transform:none}.f-6-ns,.f-headline-ns{font-size:6rem}.f-5-ns,.f-subheadline-ns{font-size:5rem}.f1-ns{font-size:3rem}.f2-ns{font-size:2.25rem}.f3-ns{font-size:1.5rem}.f4-ns{font-size:1.25rem}.f5-ns{font-size:1rem}.f6-ns{font-size:.875rem}.f7-ns{font-size:.75rem}.measure-ns{max-width:30em}.measure-wide-ns{max-width:34em}.measure-narrow-ns{max-width:20em}.indent-ns{text-indent:1em;margin-top:0;margin-bottom:0}.small-caps-ns{font-variant:small-caps}.truncate-ns{white-space:nowrap;overflow:hidden;text-overflow:ellipsis}.center-ns{margin-left:auto}.center-ns,.mr-auto-ns{margin-right:auto}.ml-auto-ns{margin-left:auto}.clip-ns{position:fixed!important;_position:absolute!important;clip:rect(1px 1px 1px 1px);clip:rect(1px,1px,1px,1px)}.ws-normal-ns{white-space:normal}.nowrap-ns{white-space:nowrap}.pre-ns{white-space:pre}.v-base-ns{vertical-align:baseline}.v-mid-ns{vertical-align:middle}.v-top-ns{vertical-align:top}.v-btm-ns{vertical-align:bottom}}@media screen and (min-width:30em) and (max-width:60em){.aspect-ratio-m{height:0;position:relative}.aspect-ratio--16x9-m{padding-bottom:56.25%}.aspect-ratio--9x16-m{padding-bottom:177.77%}.aspect-ratio--4x3-m{padding-bottom:75%}.aspect-ratio--3x4-m{padding-bottom:133.33%}.aspect-ratio--6x4-m{padding-bottom:66.6%}.aspect-ratio--4x6-m{padding-bottom:150%}.aspect-ratio--8x5-m{padding-bottom:62.5%}.aspect-ratio--5x8-m{padding-bottom:160%}.aspect-ratio--7x5-m{padding-bottom:71.42%}.aspect-ratio--5x7-m{padding-bottom:140%}.aspect-ratio--1x1-m{padding-bottom:100%}.aspect-ratio--object-m{position:absolute;top:0;right:0;bottom:0;left:0;width:100%;height:100%;z-index:100}.cover-m{background-size:cover!important}.contain-m{background-size:contain!important}.bg-center-m{background-position:50%}.bg-center-m,.bg-top-m{background-repeat:no-repeat}.bg-top-m{background-position:top}.bg-right-m{background-position:100%}.bg-bottom-m,.bg-right-m{background-repeat:no-repeat}.bg-bottom-m{background-position:bottom}.bg-left-m{background-repeat:no-repeat;background-position:0}.outline-m{outline:1px solid}.outline-transparent-m{outline:1px solid transparent}.outline-0-m{outline:0}.ba-m{border-style:solid;border-width:1px}.bt-m{border-top-style:solid;border-top-width:1px}.br-m{border-right-style:solid;border-right-width:1px}.bb-m{border-bottom-style:solid;border-bottom-width:1px}.bl-m{border-left-style:solid;border-left-width:1px}.bn-m{border-style:none;border-width:0}.br0-m{border-radius:0}.br1-m{border-radius:.125rem}.br2-m{border-radius:.25rem}.br3-m{border-radius:.5rem}.br4-m{border-radius:1rem}.br-100-m{border-radius:100%}.br-pill-m{border-radius:9999px}.br--bottom-m{border-top-left-radius:0;border-top-right-radius:0}.br--top-m{border-bottom-right-radius:0}.br--right-m,.br--top-m{border-bottom-left-radius:0}.br--right-m{border-top-left-radius:0}.br--left-m{border-top-right-radius:0;border-bottom-right-radius:0}.br-inherit-m{border-radius:inherit}.br-initial-m{border-radius:initial}.br-unset-m{border-radius:unset}.b--dotted-m{border-style:dotted}.b--dashed-m{border-style:dashed}.b--solid-m{border-style:solid}.b--none-m{border-style:none}.bw0-m{border-width:0}.bw1-m{border-width:.125rem}.bw2-m{border-width:.25rem}.bw3-m{border-width:.5rem}.bw4-m{border-width:1rem}.bw5-m{border-width:2rem}.bt-0-m{border-top-width:0}.br-0-m{border-right-width:0}.bb-0-m{border-bottom-width:0}.bl-0-m{border-left-width:0}.shadow-1-m{box-shadow:0 0 4px 2px rgba(0,0,0,.2)}.shadow-2-m{box-shadow:0 0 8px 2px rgba(0,0,0,.2)}.shadow-3-m{box-shadow:2px 2px 4px 2px rgba(0,0,0,.2)}.shadow-4-m{box-shadow:2px 2px 8px 0 rgba(0,0,0,.2)}.shadow-5-m{box-shadow:4px 4px 8px 0 rgba(0,0,0,.2)}.top-0-m{top:0}.left-0-m{left:0}.right-0-m{right:0}.bottom-0-m{bottom:0}.top-1-m{top:1rem}.left-1-m{left:1rem}.right-1-m{right:1rem}.bottom-1-m{bottom:1rem}.top-2-m{top:2rem}.left-2-m{left:2rem}.right-2-m{right:2rem}.bottom-2-m{bottom:2rem}.top--1-m{top:-1rem}.right--1-m{right:-1rem}.bottom--1-m{bottom:-1rem}.left--1-m{left:-1rem}.top--2-m{top:-2rem}.right--2-m{right:-2rem}.bottom--2-m{bottom:-2rem}.left--2-m{left:-2rem}.absolute--fill-m{top:0;right:0;bottom:0;left:0}.cl-m{clear:left}.cr-m{clear:right}.cb-m{clear:both}.cn-m{clear:none}.dn-m{display:none}.di-m{display:inline}.db-m{display:block}.dib-m{display:inline-block}.dit-m{display:inline-table}.dt-m{display:table}.dtc-m{display:table-cell}.dt-row-m{display:table-row}.dt-row-group-m{display:table-row-group}.dt-column-m{display:table-column}.dt-column-group-m{display:table-column-group}.dt--fixed-m{table-layout:fixed;width:100%}.flex-m{display:flex}.inline-flex-m{display:inline-flex}.flex-auto-m{flex:1 1 auto;min-width:0;min-height:0}.flex-none-m{flex:none}.flex-column-m{flex-direction:column}.flex-row-m{flex-direction:row}.flex-wrap-m{flex-wrap:wrap}.flex-nowrap-m{flex-wrap:nowrap}.flex-wrap-reverse-m{flex-wrap:wrap-reverse}.flex-column-reverse-m{flex-direction:column-reverse}.flex-row-reverse-m{flex-direction:row-reverse}.items-start-m{align-items:flex-start}.items-end-m{align-items:flex-end}.items-center-m{align-items:center}.items-baseline-m{align-items:baseline}.items-stretch-m{align-items:stretch}.self-start-m{align-self:flex-start}.self-end-m{align-self:flex-end}.self-center-m{align-self:center}.self-baseline-m{align-self:baseline}.self-stretch-m{align-self:stretch}.justify-start-m{justify-content:flex-start}.justify-end-m{justify-content:flex-end}.justify-center-m{justify-content:center}.justify-between-m{justify-content:space-between}.justify-around-m{justify-content:space-around}.content-start-m{align-content:flex-start}.content-end-m{align-content:flex-end}.content-center-m{align-content:center}.content-between-m{align-content:space-between}.content-around-m{align-content:space-around}.content-stretch-m{align-content:stretch}.order-0-m{order:0}.order-1-m{order:1}.order-2-m{order:2}.order-3-m{order:3}.order-4-m{order:4}.order-5-m{order:5}.order-6-m{order:6}.order-7-m{order:7}.order-8-m{order:8}.order-last-m{order:99999}.flex-grow-0-m{flex-grow:0}.flex-grow-1-m{flex-grow:1}.flex-shrink-0-m{flex-shrink:0}.flex-shrink-1-m{flex-shrink:1}.fl-m{float:left}.fl-m,.fr-m{_display:inline}.fr-m{float:right}.fn-m{float:none}.i-m{font-style:italic}.fs-normal-m{font-style:normal}.normal-m{font-weight:400}.b-m{font-weight:700}.fw1-m{font-weight:100}.fw2-m{font-weight:200}.fw3-m{font-weight:300}.fw4-m{font-weight:400}.fw5-m{font-weight:500}.fw6-m{font-weight:600}.fw7-m{font-weight:700}.fw8-m{font-weight:800}.fw9-m{font-weight:900}.h1-m{height:1rem}.h2-m{height:2rem}.h3-m{height:4rem}.h4-m{height:8rem}.h5-m{height:16rem}.h-25-m{height:25%}.h-50-m{height:50%}.h-75-m{height:75%}.h-100-m{height:100%}.min-h-100-m{min-height:100%}.vh-25-m{height:25vh}.vh-50-m{height:50vh}.vh-75-m{height:75vh}.vh-100-m{height:100vh}.min-vh-100-m{min-height:100vh}.h-auto-m{height:auto}.h-inherit-m{height:inherit}.tracked-m{letter-spacing:.1em}.tracked-tight-m{letter-spacing:-.05em}.tracked-mega-m{letter-spacing:.25em}.lh-solid-m{line-height:1}.lh-title-m{line-height:1.25}.lh-copy-m{line-height:1.5}.mw-100-m{max-width:100%}.mw1-m{max-width:1rem}.mw2-m{max-width:2rem}.mw3-m{max-width:4rem}.mw4-m{max-width:8rem}.mw5-m{max-width:16rem}.mw6-m{max-width:32rem}.mw7-m{max-width:48rem}.mw8-m{max-width:64rem}.mw9-m{max-width:96rem}.mw-none-m{max-width:none}.w1-m{width:1rem}.w2-m{width:2rem}.w3-m{width:4rem}.w4-m{width:8rem}.w5-m{width:16rem}.w-10-m{width:10%}.w-20-m{width:20%}.w-25-m{width:25%}.w-30-m{width:30%}.w-33-m{width:33%}.w-34-m{width:34%}.w-40-m{width:40%}.w-50-m{width:50%}.w-60-m{width:60%}.w-70-m{width:70%}.w-75-m{width:75%}.w-80-m{width:80%}.w-90-m{width:90%}.w-100-m{width:100%}.w-third-m{width:33.33333%}.w-two-thirds-m{width:66.66667%}.w-auto-m{width:auto}.overflow-visible-m{overflow:visible}.overflow-hidden-m{overflow:hidden}.overflow-scroll-m{overflow:scroll}.overflow-auto-m{overflow:auto}.overflow-x-visible-m{overflow-x:visible}.overflow-x-hidden-m{overflow-x:hidden}.overflow-x-scroll-m{overflow-x:scroll}.overflow-x-auto-m{overflow-x:auto}.overflow-y-visible-m{overflow-y:visible}.overflow-y-hidden-m{overflow-y:hidden}.overflow-y-scroll-m{overflow-y:scroll}.overflow-y-auto-m{overflow-y:auto}.static-m{position:static}.relative-m{position:relative}.absolute-m{position:absolute}.fixed-m{position:fixed}.rotate-45-m{-webkit-transform:rotate(45deg);transform:rotate(45deg)}.rotate-90-m{-webkit-transform:rotate(90deg);transform:rotate(90deg)}.rotate-135-m{-webkit-transform:rotate(135deg);transform:rotate(135deg)}.rotate-180-m{-webkit-transform:rotate(180deg);transform:rotate(180deg)}.rotate-225-m{-webkit-transform:rotate(225deg);transform:rotate(225deg)}.rotate-270-m{-webkit-transform:rotate(270deg);transform:rotate(270deg)}.rotate-315-m{-webkit-transform:rotate(315deg);transform:rotate(315deg)}.pa0-m{padding:0}.pa1-m{padding:.25rem}.pa2-m{padding:.5rem}.pa3-m{padding:1rem}.pa4-m{padding:2rem}.pa5-m{padding:4rem}.pa6-m{padding:8rem}.pa7-m{padding:16rem}.pl0-m{padding-left:0}.pl1-m{padding-left:.25rem}.pl2-m{padding-left:.5rem}.pl3-m{padding-left:1rem}.pl4-m{padding-left:2rem}.pl5-m{padding-left:4rem}.pl6-m{padding-left:8rem}.pl7-m{padding-left:16rem}.pr0-m{padding-right:0}.pr1-m{padding-right:.25rem}.pr2-m{padding-right:.5rem}.pr3-m{padding-right:1rem}.pr4-m{padding-right:2rem}.pr5-m{padding-right:4rem}.pr6-m{padding-right:8rem}.pr7-m{padding-right:16rem}.pb0-m{padding-bottom:0}.pb1-m{padding-bottom:.25rem}.pb2-m{padding-bottom:.5rem}.pb3-m{padding-bottom:1rem}.pb4-m{padding-bottom:2rem}.pb5-m{padding-bottom:4rem}.pb6-m{padding-bottom:8rem}.pb7-m{padding-bottom:16rem}.pt0-m{padding-top:0}.pt1-m{padding-top:.25rem}.pt2-m{padding-top:.5rem}.pt3-m{padding-top:1rem}.pt4-m{padding-top:2rem}.pt5-m{padding-top:4rem}.pt6-m{padding-top:8rem}.pt7-m{padding-top:16rem}.pv0-m{padding-top:0;padding-bottom:0}.pv1-m{padding-top:.25rem;padding-bottom:.25rem}.pv2-m{padding-top:.5rem;padding-bottom:.5rem}.pv3-m{padding-top:1rem;padding-bottom:1rem}.pv4-m{padding-top:2rem;padding-bottom:2rem}.pv5-m{padding-top:4rem;padding-bottom:4rem}.pv6-m{padding-top:8rem;padding-bottom:8rem}.pv7-m{padding-top:16rem;padding-bottom:16rem}.ph0-m{padding-left:0;padding-right:0}.ph1-m{padding-left:.25rem;padding-right:.25rem}.ph2-m{padding-left:.5rem;padding-right:.5rem}.ph3-m{padding-left:1rem;padding-right:1rem}.ph4-m{padding-left:2rem;padding-right:2rem}.ph5-m{padding-left:4rem;padding-right:4rem}.ph6-m{padding-left:8rem;padding-right:8rem}.ph7-m{padding-left:16rem;padding-right:16rem}.ma0-m{margin:0}.ma1-m{margin:.25rem}.ma2-m{margin:.5rem}.ma3-m{margin:1rem}.ma4-m{margin:2rem}.ma5-m{margin:4rem}.ma6-m{margin:8rem}.ma7-m{margin:16rem}.ml0-m{margin-left:0}.ml1-m{margin-left:.25rem}.ml2-m{margin-left:.5rem}.ml3-m{margin-left:1rem}.ml4-m{margin-left:2rem}.ml5-m{margin-left:4rem}.ml6-m{margin-left:8rem}.ml7-m{margin-left:16rem}.mr0-m{margin-right:0}.mr1-m{margin-right:.25rem}.mr2-m{margin-right:.5rem}.mr3-m{margin-right:1rem}.mr4-m{margin-right:2rem}.mr5-m{margin-right:4rem}.mr6-m{margin-right:8rem}.mr7-m{margin-right:16rem}.mb0-m{margin-bottom:0}.mb1-m{margin-bottom:.25rem}.mb2-m{margin-bottom:.5rem}.mb3-m{margin-bottom:1rem}.mb4-m{margin-bottom:2rem}.mb5-m{margin-bottom:4rem}.mb6-m{margin-bottom:8rem}.mb7-m{margin-bottom:16rem}.mt0-m{margin-top:0}.mt1-m{margin-top:.25rem}.mt2-m{margin-top:.5rem}.mt3-m{margin-top:1rem}.mt4-m{margin-top:2rem}.mt5-m{margin-top:4rem}.mt6-m{margin-top:8rem}.mt7-m{margin-top:16rem}.mv0-m{margin-top:0;margin-bottom:0}.mv1-m{margin-top:.25rem;margin-bottom:.25rem}.mv2-m{margin-top:.5rem;margin-bottom:.5rem}.mv3-m{margin-top:1rem;margin-bottom:1rem}.mv4-m{margin-top:2rem;margin-bottom:2rem}.mv5-m{margin-top:4rem;margin-bottom:4rem}.mv6-m{margin-top:8rem;margin-bottom:8rem}.mv7-m{margin-top:16rem;margin-bottom:16rem}.mh0-m{margin-left:0;margin-right:0}.mh1-m{margin-left:.25rem;margin-right:.25rem}.mh2-m{margin-left:.5rem;margin-right:.5rem}.mh3-m{margin-left:1rem;margin-right:1rem}.mh4-m{margin-left:2rem;margin-right:2rem}.mh5-m{margin-left:4rem;margin-right:4rem}.mh6-m{margin-left:8rem;margin-right:8rem}.mh7-m{margin-left:16rem;margin-right:16rem}.na1-m{margin:-.25rem}.na2-m{margin:-.5rem}.na3-m{margin:-1rem}.na4-m{margin:-2rem}.na5-m{margin:-4rem}.na6-m{margin:-8rem}.na7-m{margin:-16rem}.nl1-m{margin-left:-.25rem}.nl2-m{margin-left:-.5rem}.nl3-m{margin-left:-1rem}.nl4-m{margin-left:-2rem}.nl5-m{margin-left:-4rem}.nl6-m{margin-left:-8rem}.nl7-m{margin-left:-16rem}.nr1-m{margin-right:-.25rem}.nr2-m{margin-right:-.5rem}.nr3-m{margin-right:-1rem}.nr4-m{margin-right:-2rem}.nr5-m{margin-right:-4rem}.nr6-m{margin-right:-8rem}.nr7-m{margin-right:-16rem}.nb1-m{margin-bottom:-.25rem}.nb2-m{margin-bottom:-.5rem}.nb3-m{margin-bottom:-1rem}.nb4-m{margin-bottom:-2rem}.nb5-m{margin-bottom:-4rem}.nb6-m{margin-bottom:-8rem}.nb7-m{margin-bottom:-16rem}.nt1-m{margin-top:-.25rem}.nt2-m{margin-top:-.5rem}.nt3-m{margin-top:-1rem}.nt4-m{margin-top:-2rem}.nt5-m{margin-top:-4rem}.nt6-m{margin-top:-8rem}.nt7-m{margin-top:-16rem}.strike-m{text-decoration:line-through}.underline-m{text-decoration:underline}.no-underline-m{text-decoration:none}.tl-m{text-align:left}.tr-m{text-align:right}.tc-m{text-align:center}.tj-m{text-align:justify}.ttc-m{text-transform:capitalize}.ttl-m{text-transform:lowercase}.ttu-m{text-transform:uppercase}.ttn-m{text-transform:none}.f-6-m,.f-headline-m{font-size:6rem}.f-5-m,.f-subheadline-m{font-size:5rem}.f1-m{font-size:3rem}.f2-m{font-size:2.25rem}.f3-m{font-size:1.5rem}.f4-m{font-size:1.25rem}.f5-m{font-size:1rem}.f6-m{font-size:.875rem}.f7-m{font-size:.75rem}.measure-m{max-width:30em}.measure-wide-m{max-width:34em}.measure-narrow-m{max-width:20em}.indent-m{text-indent:1em;margin-top:0;margin-bottom:0}.small-caps-m{font-variant:small-caps}.truncate-m{white-space:nowrap;overflow:hidden;text-overflow:ellipsis}.center-m{margin-left:auto}.center-m,.mr-auto-m{margin-right:auto}.ml-auto-m{margin-left:auto}.clip-m{position:fixed!important;_position:absolute!important;clip:rect(1px 1px 1px 1px);clip:rect(1px,1px,1px,1px)}.ws-normal-m{white-space:normal}.nowrap-m{white-space:nowrap}.pre-m{white-space:pre}.v-base-m{vertical-align:baseline}.v-mid-m{vertical-align:middle}.v-top-m{vertical-align:top}.v-btm-m{vertical-align:bottom}}@media screen and (min-width:60em){.aspect-ratio-l{height:0;position:relative}.aspect-ratio--16x9-l{padding-bottom:56.25%}.aspect-ratio--9x16-l{padding-bottom:177.77%}.aspect-ratio--4x3-l{padding-bottom:75%}.aspect-ratio--3x4-l{padding-bottom:133.33%}.aspect-ratio--6x4-l{padding-bottom:66.6%}.aspect-ratio--4x6-l{padding-bottom:150%}.aspect-ratio--8x5-l{padding-bottom:62.5%}.aspect-ratio--5x8-l{padding-bottom:160%}.aspect-ratio--7x5-l{padding-bottom:71.42%}.aspect-ratio--5x7-l{padding-bottom:140%}.aspect-ratio--1x1-l{padding-bottom:100%}.aspect-ratio--object-l{position:absolute;top:0;right:0;bottom:0;left:0;width:100%;height:100%;z-index:100}.cover-l{background-size:cover!important}.contain-l{background-size:contain!important}.bg-center-l{background-position:50%}.bg-center-l,.bg-top-l{background-repeat:no-repeat}.bg-top-l{background-position:top}.bg-right-l{background-position:100%}.bg-bottom-l,.bg-right-l{background-repeat:no-repeat}.bg-bottom-l{background-position:bottom}.bg-left-l{background-repeat:no-repeat;background-position:0}.outline-l{outline:1px solid}.outline-transparent-l{outline:1px solid transparent}.outline-0-l{outline:0}.ba-l{border-style:solid;border-width:1px}.bt-l{border-top-style:solid;border-top-width:1px}.br-l{border-right-style:solid;border-right-width:1px}.bb-l{border-bottom-style:solid;border-bottom-width:1px}.bl-l{border-left-style:solid;border-left-width:1px}.bn-l{border-style:none;border-width:0}.br0-l{border-radius:0}.br1-l{border-radius:.125rem}.br2-l{border-radius:.25rem}.br3-l{border-radius:.5rem}.br4-l{border-radius:1rem}.br-100-l{border-radius:100%}.br-pill-l{border-radius:9999px}.br--bottom-l{border-top-left-radius:0;border-top-right-radius:0}.br--top-l{border-bottom-right-radius:0}.br--right-l,.br--top-l{border-bottom-left-radius:0}.br--right-l{border-top-left-radius:0}.br--left-l{border-top-right-radius:0;border-bottom-right-radius:0}.br-inherit-l{border-radius:inherit}.br-initial-l{border-radius:initial}.br-unset-l{border-radius:unset}.b--dotted-l{border-style:dotted}.b--dashed-l{border-style:dashed}.b--solid-l{border-style:solid}.b--none-l{border-style:none}.bw0-l{border-width:0}.bw1-l{border-width:.125rem}.bw2-l{border-width:.25rem}.bw3-l{border-width:.5rem}.bw4-l{border-width:1rem}.bw5-l{border-width:2rem}.bt-0-l{border-top-width:0}.br-0-l{border-right-width:0}.bb-0-l{border-bottom-width:0}.bl-0-l{border-left-width:0}.shadow-1-l{box-shadow:0 0 4px 2px rgba(0,0,0,.2)}.shadow-2-l{box-shadow:0 0 8px 2px rgba(0,0,0,.2)}.shadow-3-l{box-shadow:2px 2px 4px 2px rgba(0,0,0,.2)}.shadow-4-l{box-shadow:2px 2px 8px 0 rgba(0,0,0,.2)}.shadow-5-l{box-shadow:4px 4px 8px 0 rgba(0,0,0,.2)}.top-0-l{top:0}.left-0-l{left:0}.right-0-l{right:0}.bottom-0-l{bottom:0}.top-1-l{top:1rem}.left-1-l{left:1rem}.right-1-l{right:1rem}.bottom-1-l{bottom:1rem}.top-2-l{top:2rem}.left-2-l{left:2rem}.right-2-l{right:2rem}.bottom-2-l{bottom:2rem}.top--1-l{top:-1rem}.right--1-l{right:-1rem}.bottom--1-l{bottom:-1rem}.left--1-l{left:-1rem}.top--2-l{top:-2rem}.right--2-l{right:-2rem}.bottom--2-l{bottom:-2rem}.left--2-l{left:-2rem}.absolute--fill-l{top:0;right:0;bottom:0;left:0}.cl-l{clear:left}.cr-l{clear:right}.cb-l{clear:both}.cn-l{clear:none}.dn-l{display:none}.di-l{display:inline}.db-l{display:block}.dib-l{display:inline-block}.dit-l{display:inline-table}.dt-l{display:table}.dtc-l{display:table-cell}.dt-row-l{display:table-row}.dt-row-group-l{display:table-row-group}.dt-column-l{display:table-column}.dt-column-group-l{display:table-column-group}.dt--fixed-l{table-layout:fixed;width:100%}.flex-l{display:flex}.inline-flex-l{display:inline-flex}.flex-auto-l{flex:1 1 auto;min-width:0;min-height:0}.flex-none-l{flex:none}.flex-column-l{flex-direction:column}.flex-row-l{flex-direction:row}.flex-wrap-l{flex-wrap:wrap}.flex-nowrap-l{flex-wrap:nowrap}.flex-wrap-reverse-l{flex-wrap:wrap-reverse}.flex-column-reverse-l{flex-direction:column-reverse}.flex-row-reverse-l{flex-direction:row-reverse}.items-start-l{align-items:flex-start}.items-end-l{align-items:flex-end}.items-center-l{align-items:center}.items-baseline-l{align-items:baseline}.items-stretch-l{align-items:stretch}.self-start-l{align-self:flex-start}.self-end-l{align-self:flex-end}.self-center-l{align-self:center}.self-baseline-l{align-self:baseline}.self-stretch-l{align-self:stretch}.justify-start-l{justify-content:flex-start}.justify-end-l{justify-content:flex-end}.justify-center-l{justify-content:center}.justify-between-l{justify-content:space-between}.justify-around-l{justify-content:space-around}.content-start-l{align-content:flex-start}.content-end-l{align-content:flex-end}.content-center-l{align-content:center}.content-between-l{align-content:space-between}.content-around-l{align-content:space-around}.content-stretch-l{align-content:stretch}.order-0-l{order:0}.order-1-l{order:1}.order-2-l{order:2}.order-3-l{order:3}.order-4-l{order:4}.order-5-l{order:5}.order-6-l{order:6}.order-7-l{order:7}.order-8-l{order:8}.order-last-l{order:99999}.flex-grow-0-l{flex-grow:0}.flex-grow-1-l{flex-grow:1}.flex-shrink-0-l{flex-shrink:0}.flex-shrink-1-l{flex-shrink:1}.fl-l{float:left}.fl-l,.fr-l{_display:inline}.fr-l{float:right}.fn-l{float:none}.i-l{font-style:italic}.fs-normal-l{font-style:normal}.normal-l{font-weight:400}.b-l{font-weight:700}.fw1-l{font-weight:100}.fw2-l{font-weight:200}.fw3-l{font-weight:300}.fw4-l{font-weight:400}.fw5-l{font-weight:500}.fw6-l{font-weight:600}.fw7-l{font-weight:700}.fw8-l{font-weight:800}.fw9-l{font-weight:900}.h1-l{height:1rem}.h2-l{height:2rem}.h3-l{height:4rem}.h4-l{height:8rem}.h5-l{height:16rem}.h-25-l{height:25%}.h-50-l{height:50%}.h-75-l{height:75%}.h-100-l{height:100%}.min-h-100-l{min-height:100%}.vh-25-l{height:25vh}.vh-50-l{height:50vh}.vh-75-l{height:75vh}.vh-100-l{height:100vh}.min-vh-100-l{min-height:100vh}.h-auto-l{height:auto}.h-inherit-l{height:inherit}.tracked-l{letter-spacing:.1em}.tracked-tight-l{letter-spacing:-.05em}.tracked-mega-l{letter-spacing:.25em}.lh-solid-l{line-height:1}.lh-title-l{line-height:1.25}.lh-copy-l{line-height:1.5}.mw-100-l{max-width:100%}.mw1-l{max-width:1rem}.mw2-l{max-width:2rem}.mw3-l{max-width:4rem}.mw4-l{max-width:8rem}.mw5-l{max-width:16rem}.mw6-l{max-width:32rem}.mw7-l{max-width:48rem}.mw8-l{max-width:64rem}.mw9-l{max-width:96rem}.mw-none-l{max-width:none}.w1-l{width:1rem}.w2-l{width:2rem}.w3-l{width:4rem}.w4-l{width:8rem}.w5-l{width:16rem}.w-10-l{width:10%}.w-20-l{width:20%}.w-25-l{width:25%}.w-30-l{width:30%}.w-33-l{width:33%}.w-34-l{width:34%}.w-40-l{width:40%}.w-50-l{width:50%}.w-60-l{width:60%}.w-70-l{width:70%}.w-75-l{width:75%}.w-80-l{width:80%}.w-90-l{width:90%}.w-100-l{width:100%}.w-third-l{width:33.33333%}.w-two-thirds-l{width:66.66667%}.w-auto-l{width:auto}.overflow-visible-l{overflow:visible}.overflow-hidden-l{overflow:hidden}.overflow-scroll-l{overflow:scroll}.overflow-auto-l{overflow:auto}.overflow-x-visible-l{overflow-x:visible}.overflow-x-hidden-l{overflow-x:hidden}.overflow-x-scroll-l{overflow-x:scroll}.overflow-x-auto-l{overflow-x:auto}.overflow-y-visible-l{overflow-y:visible}.overflow-y-hidden-l{overflow-y:hidden}.overflow-y-scroll-l{overflow-y:scroll}.overflow-y-auto-l{overflow-y:auto}.static-l{position:static}.relative-l{position:relative}.absolute-l{position:absolute}.fixed-l{position:fixed}.rotate-45-l{-webkit-transform:rotate(45deg);transform:rotate(45deg)}.rotate-90-l{-webkit-transform:rotate(90deg);transform:rotate(90deg)}.rotate-135-l{-webkit-transform:rotate(135deg);transform:rotate(135deg)}.rotate-180-l{-webkit-transform:rotate(180deg);transform:rotate(180deg)}.rotate-225-l{-webkit-transform:rotate(225deg);transform:rotate(225deg)}.rotate-270-l{-webkit-transform:rotate(270deg);transform:rotate(270deg)}.rotate-315-l{-webkit-transform:rotate(315deg);transform:rotate(315deg)}.pa0-l{padding:0}.pa1-l{padding:.25rem}.pa2-l{padding:.5rem}.pa3-l{padding:1rem}.pa4-l{padding:2rem}.pa5-l{padding:4rem}.pa6-l{padding:8rem}.pa7-l{padding:16rem}.pl0-l{padding-left:0}.pl1-l{padding-left:.25rem}.pl2-l{padding-left:.5rem}.pl3-l{padding-left:1rem}.pl4-l{padding-left:2rem}.pl5-l{padding-left:4rem}.pl6-l{padding-left:8rem}.pl7-l{padding-left:16rem}.pr0-l{padding-right:0}.pr1-l{padding-right:.25rem}.pr2-l{padding-right:.5rem}.pr3-l{padding-right:1rem}.pr4-l{padding-right:2rem}.pr5-l{padding-right:4rem}.pr6-l{padding-right:8rem}.pr7-l{padding-right:16rem}.pb0-l{padding-bottom:0}.pb1-l{padding-bottom:.25rem}.pb2-l{padding-bottom:.5rem}.pb3-l{padding-bottom:1rem}.pb4-l{padding-bottom:2rem}.pb5-l{padding-bottom:4rem}.pb6-l{padding-bottom:8rem}.pb7-l{padding-bottom:16rem}.pt0-l{padding-top:0}.pt1-l{padding-top:.25rem}.pt2-l{padding-top:.5rem}.pt3-l{padding-top:1rem}.pt4-l{padding-top:2rem}.pt5-l{padding-top:4rem}.pt6-l{padding-top:8rem}.pt7-l{padding-top:16rem}.pv0-l{padding-top:0;padding-bottom:0}.pv1-l{padding-top:.25rem;padding-bottom:.25rem}.pv2-l{padding-top:.5rem;padding-bottom:.5rem}.pv3-l{padding-top:1rem;padding-bottom:1rem}.pv4-l{padding-top:2rem;padding-bottom:2rem}.pv5-l{padding-top:4rem;padding-bottom:4rem}.pv6-l{padding-top:8rem;padding-bottom:8rem}.pv7-l{padding-top:16rem;padding-bottom:16rem}.ph0-l{padding-left:0;padding-right:0}.ph1-l{padding-left:.25rem;padding-right:.25rem}.ph2-l{padding-left:.5rem;padding-right:.5rem}.ph3-l{padding-left:1rem;padding-right:1rem}.ph4-l{padding-left:2rem;padding-right:2rem}.ph5-l{padding-left:4rem;padding-right:4rem}.ph6-l{padding-left:8rem;padding-right:8rem}.ph7-l{padding-left:16rem;padding-right:16rem}.ma0-l{margin:0}.ma1-l{margin:.25rem}.ma2-l{margin:.5rem}.ma3-l{margin:1rem}.ma4-l{margin:2rem}.ma5-l{margin:4rem}.ma6-l{margin:8rem}.ma7-l{margin:16rem}.ml0-l{margin-left:0}.ml1-l{margin-left:.25rem}.ml2-l{margin-left:.5rem}.ml3-l{margin-left:1rem}.ml4-l{margin-left:2rem}.ml5-l{margin-left:4rem}.ml6-l{margin-left:8rem}.ml7-l{margin-left:16rem}.mr0-l{margin-right:0}.mr1-l{margin-right:.25rem}.mr2-l{margin-right:.5rem}.mr3-l{margin-right:1rem}.mr4-l{margin-right:2rem}.mr5-l{margin-right:4rem}.mr6-l{margin-right:8rem}.mr7-l{margin-right:16rem}.mb0-l{margin-bottom:0}.mb1-l{margin-bottom:.25rem}.mb2-l{margin-bottom:.5rem}.mb3-l{margin-bottom:1rem}.mb4-l{margin-bottom:2rem}.mb5-l{margin-bottom:4rem}.mb6-l{margin-bottom:8rem}.mb7-l{margin-bottom:16rem}.mt0-l{margin-top:0}.mt1-l{margin-top:.25rem}.mt2-l{margin-top:.5rem}.mt3-l{margin-top:1rem}.mt4-l{margin-top:2rem}.mt5-l{margin-top:4rem}.mt6-l{margin-top:8rem}.mt7-l{margin-top:16rem}.mv0-l{margin-top:0;margin-bottom:0}.mv1-l{margin-top:.25rem;margin-bottom:.25rem}.mv2-l{margin-top:.5rem;margin-bottom:.5rem}.mv3-l{margin-top:1rem;margin-bottom:1rem}.mv4-l{margin-top:2rem;margin-bottom:2rem}.mv5-l{margin-top:4rem;margin-bottom:4rem}.mv6-l{margin-top:8rem;margin-bottom:8rem}.mv7-l{margin-top:16rem;margin-bottom:16rem}.mh0-l{margin-left:0;margin-right:0}.mh1-l{margin-left:.25rem;margin-right:.25rem}.mh2-l{margin-left:.5rem;margin-right:.5rem}.mh3-l{margin-left:1rem;margin-right:1rem}.mh4-l{margin-left:2rem;margin-right:2rem}.mh5-l{margin-left:4rem;margin-right:4rem}.mh6-l{margin-left:8rem;margin-right:8rem}.mh7-l{margin-left:16rem;margin-right:16rem}.na1-l{margin:-.25rem}.na2-l{margin:-.5rem}.na3-l{margin:-1rem}.na4-l{margin:-2rem}.na5-l{margin:-4rem}.na6-l{margin:-8rem}.na7-l{margin:-16rem}.nl1-l{margin-left:-.25rem}.nl2-l{margin-left:-.5rem}.nl3-l{margin-left:-1rem}.nl4-l{margin-left:-2rem}.nl5-l{margin-left:-4rem}.nl6-l{margin-left:-8rem}.nl7-l{margin-left:-16rem}.nr1-l{margin-right:-.25rem}.nr2-l{margin-right:-.5rem}.nr3-l{margin-right:-1rem}.nr4-l{margin-right:-2rem}.nr5-l{margin-right:-4rem}.nr6-l{margin-right:-8rem}.nr7-l{margin-right:-16rem}.nb1-l{margin-bottom:-.25rem}.nb2-l{margin-bottom:-.5rem}.nb3-l{margin-bottom:-1rem}.nb4-l{margin-bottom:-2rem}.nb5-l{margin-bottom:-4rem}.nb6-l{margin-bottom:-8rem}.nb7-l{margin-bottom:-16rem}.nt1-l{margin-top:-.25rem}.nt2-l{margin-top:-.5rem}.nt3-l{margin-top:-1rem}.nt4-l{margin-top:-2rem}.nt5-l{margin-top:-4rem}.nt6-l{margin-top:-8rem}.nt7-l{margin-top:-16rem}.strike-l{text-decoration:line-through}.underline-l{text-decoration:underline}.no-underline-l{text-decoration:none}.tl-l{text-align:left}.tr-l{text-align:right}.tc-l{text-align:center}.tj-l{text-align:justify}.ttc-l{text-transform:capitalize}.ttl-l{text-transform:lowercase}.ttu-l{text-transform:uppercase}.ttn-l{text-transform:none}.f-6-l,.f-headline-l{font-size:6rem}.f-5-l,.f-subheadline-l{font-size:5rem}.f1-l{font-size:3rem}.f2-l{font-size:2.25rem}.f3-l{font-size:1.5rem}.f4-l{font-size:1.25rem}.f5-l{font-size:1rem}.f6-l{font-size:.875rem}.f7-l{font-size:.75rem}.measure-l{max-width:30em}.measure-wide-l{max-width:34em}.measure-narrow-l{max-width:20em}.indent-l{text-indent:1em;margin-top:0;margin-bottom:0}.small-caps-l{font-variant:small-caps}.truncate-l{white-space:nowrap;overflow:hidden;text-overflow:ellipsis}.center-l{margin-left:auto}.center-l,.mr-auto-l{margin-right:auto}.ml-auto-l{margin-left:auto}.clip-l{position:fixed!important;_position:absolute!important;clip:rect(1px 1px 1px 1px);clip:rect(1px,1px,1px,1px)}.ws-normal-l{white-space:normal}.nowrap-l{white-space:nowrap}.pre-l{white-space:pre}.v-base-l{vertical-align:baseline}.v-mid-l{vertical-align:middle}.v-top-l{vertical-align:top}.v-btm-l{vertical-align:bottom}}
+

---FILE: course-materials/slides/u1_d07-tidy-data/libs/tile-view/tile-view.css---
@@ -0,0 +1,52 @@
+.remark__tile-view * {
+  box-sizing: border-box;
+}
+
+.remark__tile-view {
+  background: lightgray;
+  position: relative;
+  width: 100%;
+  height: 100%;
+  padding: 3em;
+  font-size: 18px;
+  box-sizing: border-box;
+  overflow: scroll;
+}
+
+.remark__tile-view__header {
+  text-align: center;
+}
+
+.remark__tile-view__tiles {
+  display: grid;
+  /* Set column width in JS */
+  /* grid-template-columns: repeat(auto-fill, minmax(300px, 1fr)); */
+  justify-items: center;
+}
+
+.remark__tile-view__tile {
+  position: relative;
+  margin: 0.5em;
+  padding: 0.5em;
+}
+
+.remark__tile-view__slide-container {
+  margin: 0 auto;
+}
+
+.remark__tile-view__tile--current {
+  background: #ffd863;
+  border: 5px solid #ffd863;
+  margin: calc(0.5em - 5px);
+  border-radius: 0;
+}
+
+.remark__tile-view__tile--seen {
+  opacity: 0.5;
+}
+
+.remark__tile-view__tile:hover {
+  /* background: #993d70; */
+  background: #44bc96;
+  opacity: 1;
+}

---FILE: course-materials/slides/u1_d07-tidy-data/libs/tile-view/tile-view.js---
@@ -0,0 +1,189 @@
+/*
+ *  Tile View for remark.js Slides
+ *
+ *  Garrick Aden-Buie
+ *
+ *  Inspired and converted to Vanilla JS from
+ *  https://github.com/StephenHesperus/remark-hook/
+ *
+ *  Include after remarkjs slides are initialized.
+ *
+ */
+
+/* global slideshow */
+(function () {
+  const ready = function (fn) {
+    /* MIT License Copyright (c) 2016 Nuclei */
+    /* https://github.com/nuclei/readyjs */
+    const completed = () => {
+      document.removeEventListener('DOMContentLoaded', completed)
+      window.removeEventListener('load', completed)
+      fn()
+    }
+    if (document.readyState !== 'loading') {
+      setTimeout(fn)
+    } else {
+      document.addEventListener('DOMContentLoaded', completed)
+      window.addEventListener('load', completed)
+    }
+  }
+
+  ready(function () {
+    const launchKey = 79 // keycode for O, used to enable tile view
+
+    // Slides container
+    const remarkSlideShow = document.querySelector('div.remark-slides-area')
+
+    let tileView = document.querySelector('div.remark__tile-view')
+    if (!tileView) {
+      tileView = document.createElement('div')
+      tileView.className = 'remark__tile-view'
+    }
+
+    const toggleElement = el => {
+      el.style.display = el.style.display === 'none' ? '' : 'none'
+    }
+
+    const toggleTileView = function () {
+      toggleElement(tileView)
+      toggleElement(remarkSlideShow)
+
+      if (tileView.style.display === 'none') {
+        // tileView is now hidden, go to current slide
+        slideshow.gotoSlide(tileVars.currentSlideIdx + 1)
+
+        // remove scroll/mousewheel event blocking
+        tileView.removeEventListener('mousewheel', blockEvent)
+        tileView.removeEventListener('DOMMouseScroll', blockEvent)
+        console.log('removing blockScaling')
+        document.removeEventListener('keydown', blockScaling)
+      } else {
+        // store current slide index prior to launching tile-view
+        tileVars.currentSlideIdx = slideshow.getCurrentSlideIndex()
+
+        // set class on seen and current slide and scroll into view
+        const tiles = tileView.querySelectorAll('.remark__tile-view__tile');
+        [...tiles].forEach((tile, idx) => {
+          tile.classList.toggle(
+            'remark__tile-view__tile--seen',
+            idx < tileVars.currentSlideIdx
+          )
+          tile.classList.toggle(
+            'remark__tile-view__tile--current',
+            idx === tileVars.currentSlideIdx
+          )
+        })
+        tiles[tileVars.currentSlideIdx].scrollIntoView({
+          behavior: 'smooth',
+          block: 'center'
+        })
+
+        // block remarkjs from handling scroll events
+        tileView.addEventListener('mousewheel', blockEvent)
+        tileView.addEventListener('DOMMouseScroll', blockEvent)
+        console.log('adding blockScaling')
+        document.addEventListener('keydown', blockScaling)
+      }
+    }
+
+    const createTileView = ({ minSize = 250, title = document.title } = {}) => {
+      // Tile view header
+      const h1 = document.createElement('h1')
+      h1.className = 'remark__tile-view__header'
+      h1.innerHTML = title
+
+      tileView.appendChild(h1)
+      const tiles = document.createElement('div')
+      tiles.className = 'remark__tile-view__tiles'
+      tileView.appendChild(tiles)
+
+      // Clone slideshow
+      const slidesArea = remarkSlideShow.cloneNode(true)
+
+      // Calculate slide scale and tile container size
+      const slideScaler = slidesArea.querySelector('.remark-slide-scaler')
+      const slideWidth = parseFloat(slideScaler.style.width.replace('px', ''))
+      const slideHeight = parseFloat(
+        slideScaler.style.height.replace('px', '')
+      )
+      const scale = minSize / Math.min(slideWidth, slideHeight)
+      let tileWidth = Math.round(slideWidth * scale)
+      let tileHeight = Math.round(slideHeight * scale)
+
+      // convert tileWidth/Height to em relative to base 18px (set in CSS)
+      tileWidth = tileWidth / 18
+      tileHeight = tileHeight / 18
+
+      tiles.style.gridTemplateColumns = `repeat(auto-fill, minmax(${tileWidth}em, 1fr))`
+
+      const slides = slidesArea.querySelectorAll('.remark-slide-container')
+
+      slides.forEach((slide, slideIndex) => {
+        let tile = document.createElement('template')
+        tile.innerHTML = `<div class=""remark__tile-view__tile"">
+            <div class=""remark__tile-view__slide-container"">
+            </div></div>`
+        tile = tile.content.firstChild
+
+        const tileContainer = tile.querySelector(
+          '.remark__tile-view__slide-container'
+        )
+        tileContainer.style.width = `${tileWidth}em`
+        tileContainer.style.height = `${tileHeight}em`
+
+        const thisSlideScaler = slide.querySelector('.remark-slide-scaler')
+        thisSlideScaler.style.top = '0px'
+        thisSlideScaler.style.left = '0px'
+        thisSlideScaler.style.transform = `scale(${scale})`
+        thisSlideScaler.parentElement.classList.add('remark-visible')
+
+        slide.addEventListener('click', () => {
+          tileVars.currentSlideIdx = slideIndex
+          toggleTileView()
+        })
+
+        tileContainer.appendChild(slide)
+        tiles.appendChild(tile)
+      })
+
+      document.body.appendChild(tileView)
+    }
+
+    const tileVars = {}
+    const blockEvent = ev => ev.stopPropagation()
+    const blockScaling = function (ev) {
+      if (ev.controlKey || ev.metaKey) {
+        if (ev.key === '=' || ev.key === '-') {
+          ev.preventDefault()
+          console.log('window scaling is not allowed inside the tile overview')
+        }
+      }
+    }
+
+    document.addEventListener('keydown', ev => {
+      if (ev.keyCode === launchKey) {
+        toggleTileView()
+      }
+    })
+
+    const addTileViewHelpText = () => {
+      const helpTable = document.querySelector(
+        '.remark-help-content table.light-keys'
+      )
+      if (!helpTable) {
+        console.error(
+          'Could not find remark help table, has remark been initialized?'
+        )
+        return
+      }
+      const newRow = document.createElement('tr')
+      newRow.innerHTML += '<td><span class=""key"">o</span></td>'
+      newRow.innerHTML += '<td>Tile View: Overview of Slides</td>'
+      helpTable.append(newRow)
+    }
+
+    createTileView({ minSize: 200 })
+    toggleElement(tileView)
+    addTileViewHelpText()
+  })
+})()

---FILE: course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data.Rmd---
@@ -22,6 +22,10 @@ library(knitr)
 library(skimr)
 library(scales)
 library(patchwork)
+
+# xaringanExtra
+xaringanExtra::use_xaringan_extra()
+xaringanExtra::use_panelset()
 ```
 
 ## A grammar of data tidying
@@ -77,7 +81,7 @@ we will convert the data from the long format to wide format.
 
 But before we do so... 
 
-.discussion[
+.question[
 If the long data will have a row for each year/faculty type combination, 
 and there are 5 faculty types and 11 years of data, how many rows will the data have?
 ]
@@ -95,7 +99,7 @@ include_graphics(""img/pivot.gif"")
 ## `pivot_*()` functions
 
 
-```{r echo=FALSE}
+```{r echo=FALSE, out.width=""50%""}
 include_graphics(""img/tidyr-longer-wider.gif"")
 ```
 
@@ -149,19 +153,19 @@ staff_long
 
 ---
 
-.discussion[
+.question[
 This doesn't look quite right, how would you fix it?
 ]
 
-```{r fig.width=8, fig.height=3}
+```{r out.width=""70%""}
 staff_long %>%
   ggplot(aes(x = percentage, y = year, color = faculty_type)) +
   geom_col(position = ""dodge"")
 ```
 
 ---
 
-```{r fig.width=8, fig.height=3}
+```{r out.width=""80%""}
 staff_long %>%
   ggplot(aes(x = percentage, y = year, fill = faculty_type)) +
   geom_col(position = ""dodge"")
@@ -171,7 +175,7 @@ staff_long %>%
 
 ## Some improvement...
 
-```{r fig.width=8, fig.height=3}
+```{r out.width=""80%""}
 staff_long %>%
   ggplot(aes(x = percentage, y = year, fill = faculty_type)) +
   geom_col()
@@ -181,19 +185,19 @@ staff_long %>%
 
 ## More improvement
 
-```{r fig.width=8, fig.height=3}
+```{r out.width=""80%""}
 staff_long %>%
   ggplot(aes(x = year, y = percentage, group = faculty_type, color = faculty_type)) +
   geom_line()
 ```
 
 ---
 
-.discussion[
+.question[
 What is the difference between these two plots?
 ]
 
-```{r echo=FALSE, fig.width=6, fig.height=3}
+```{r echo=FALSE, out.width=""70%"", fig.asp=0.7}
 p1 <- staff_long %>%
   ggplot(aes(x = year, y = percentage, group = faculty_type, color = faculty_type)) +
   geom_line() +
@@ -211,22 +215,24 @@ p1 + p2 +
 
 ## Make year numeric again!
 
-```{r fig.width=6, fig.height=2}
+.small[
+```{r out.width=""70%""}
 staff_long <- staff_long %>%
   mutate(year = as.numeric(year))
 
 staff_long %>%
   ggplot(aes(x = year, y = percentage, group = faculty_type, color = faculty_type)) +
   geom_line()
 ```
+]
 
 ---
 
-.discussion[
+.question[
 How would you go about creating the following plot?
 ]
 
-```{r echo=FALSE, fig.width=6, fig.height=3}
+```{r echo=FALSE, out.width=""80%""}
 staff_long %>%
   mutate(part_time = if_else(faculty_type == ""Part-Time Faculty"",
                              ""Part-Time Faculty"", 
@@ -439,7 +445,7 @@ rel_inc
 
 ## Rename columns
 
-.small[
+.midi[
 ```{r}
 rel_inc %>%
   rename(
@@ -451,15 +457,15 @@ rel_inc %>%
 
 --
 
-.discussion[
+.question[
 If we want a new variable called `income` with levels such as ""Less than $30,000"", ""$30,000-$49,999"", ... etc. which function should we use?
 ]
 
 ---
 
 ## Pivot longer
 
-.small[
+.midi[
 ```{r}
 rel_inc %>%
   rename(
@@ -478,7 +484,7 @@ rel_inc %>%
 
 ## Calculate frequencies
 
-.small[
+.midi[
 ```{r}
 rel_inc %>%
   rename(
@@ -514,9 +520,9 @@ rel_inc_long <- rel_inc %>%
 
 ---
 
-## Start plotting
+## Religion
 
-```{r fig.height=2}
+```{r out.width=""80%""}
 ggplot(rel_inc_long, aes(y = religion, x = frequency)) +
   geom_col()
 ```
@@ -525,39 +531,78 @@ ggplot(rel_inc_long, aes(y = religion, x = frequency)) +
 
 ## Reverse religion order
 
-```{r fig.height=2}
-ggplot(rel_inc_long, aes(y = fct_rev(religion), x = frequency)) + #<<
+```{r out.width=""80%""}
+rel_inc_long <- rel_inc_long %>%
+  mutate(religion = fct_rev(religion))
+
+ggplot(rel_inc_long, aes(y = religion, x = frequency)) + #<<
   geom_col()
 ```
 
 ---
 
 ## Add income
 
-```{r fig.height=2}
-ggplot(rel_inc_long, aes(y = fct_rev(religion), x = frequency, fill = income)) + #<<
+```{r out.width=""80%""}
+ggplot(rel_inc_long, aes(y = religion, x = frequency, fill = income)) + #<<
   geom_col() 
 ```
 
 ---
 
-## Dodge bars
+## Fix income level ordering
+
+```{r}
+rel_inc_long <- rel_inc_long %>%
+  mutate(
+    income = fct_relevel(income, ""$100,000 or more"", #<<
+                         ""$50,000-$99,999"", ""$30,000-$49,999"", #<<
+                         ""Less than $30,000"") #<<
+    )
+```
+
+---
+
+## Plot again
+
+```{r}
+ggplot(rel_inc_long, aes(y = religion, x = frequency, fill = income)) + 
+  geom_col()
+```
+
+---
+
+## Fill bars
 
 .small[
-```{r fig.height=2}
-ggplot(rel_inc_long, aes(y = fct_rev(religion), x = frequency, fill = income)) +
-  geom_col(position = ""dodge"") #<<
+```{r out.width=""80%""}
+ggplot(rel_inc_long, aes(y = religion, x = frequency, fill = income)) +
+  geom_col(position = ""fill"") #<<
 ```
 ]
 
 ---
 
+## Change colors
+
+.small[
+```{r out.width=""80%""}
+ggplot(rel_inc_long, aes(y = religion, x = frequency, fill = income)) +
+  geom_col(position = ""fill"") +
+  scale_fill_viridis_d() #<<
+```
+]
+
+---
+
+
 ## Change theme
 
 .small[
-```{r fig.height=2}
-ggplot(rel_inc_long, aes(y = fct_rev(religion), x = frequency, fill = income)) +
-  geom_col(position = ""dodge"") +
+```{r out.width=""80%""}
+ggplot(rel_inc_long, aes(y = religion, x = frequency, fill = income)) +
+  geom_col(position = ""fill"") +
+  scale_fill_viridis_d() +
   theme_minimal() #<<
 ```
 ]
@@ -566,57 +611,78 @@ ggplot(rel_inc_long, aes(y = fct_rev(religion), x = frequency, fill = income)) +
 
 ## Move legend to the bottom
 
-.small[
-```{r fig.height=2}
-ggplot(rel_inc_long, aes(y = fct_rev(religion), x = frequency, fill = income)) +
-  geom_col(position = ""dodge"") +
+.midi[
+```{r bottom-legend, fig.show=""hide""}
+ggplot(rel_inc_long, aes(y = religion, x = frequency, fill = income)) +
+  geom_col(position = ""fill"") +
+  scale_fill_viridis_d() +
   theme_minimal() +
   theme(legend.position = ""bottom"") #<<
 ```
 ]
 
 ---
 
-## Prettier colors
+## Move legend to the bottom (plot)
+
+```{r ref.label = ""bottom-legend"", echo=FALSE, out.width=""80%""}
+```
+
+---
+
+## Legend adjustments
 
 .small[
-```{r fig.height=2}
-ggplot(rel_inc_long, aes(y = fct_rev(religion), x = frequency, fill = income)) +
-  geom_col(position = ""dodge"") +
+```{r legend-adjust, fig.show=""hide""}
+ggplot(rel_inc_long, aes(y = religion, x = frequency, fill = income)) +
+  geom_col(position = ""fill"") +
+  scale_fill_viridis_d() +
   theme_minimal() +
-  theme(legend.position = ""bottom"") +
-  scale_fill_viridis_d() #<<
+  theme(
+    legend.position = ""bottom"", 
+    legend.key.size = unit(0.3, ""cm""), #<<
+    legend.box.margin = margin(t = 0, r = 0, b = 0, l = 0, unit = ""pt"") #<<
+    ) +
+  guides(fill = guide_legend(nrow = 2, byrow = TRUE)) #<<
 ```
 ]
 
 ---
 
+## Legend adjustments (plot)
+
+```{r ref.label = ""legend-adjust"", echo=FALSE, out.width=""80%""}
+```
+
+---
+
 ## Fix labels
 
-```{r eval=FALSE}
-ggplot(rel_inc_long, aes(y = fct_rev(religion), x = frequency, fill = income)) +
-  geom_col(position = ""dodge"") +
-  theme_minimal() +
-  theme(legend.position = ""bottom"") +
+.midi[
+```{r fix-labels, fig.show=""hide""}
+ggplot(rel_inc_long, aes(y = religion, x = frequency, fill = income)) +
+  geom_col(position = ""fill"") +
   scale_fill_viridis_d() +
-  labs( #<<
+  theme_minimal() +
+  theme(
+    legend.position = ""bottom"", 
+    legend.key.size = unit(0.3, ""cm""), #<<
+    legend.box.margin = margin(t = 0, r = 0, b = 0, l = 0, unit = ""pt"") #<<
+    ) +
+  guides(fill = guide_legend(nrow = 2, byrow = TRUE)) +
+  labs(
     x = ""Frequency"", y = """", #<<
     title = ""Income distribution by religious group"", #<<
-    caption = ""Source: pewforum.org/religious-landscape-study/income-distribution"" #<<
-    ) #<<
+    subtitle = ""Source: Pew Research Center, Religious Landscape Study"", #<<
+    fill = ""Income""
+    )
 ```
+]
 
 ---
 
-```{r echo=FALSE}
-ggplot(rel_inc_long, aes(y = fct_rev(religion), x = frequency, fill = income)) +
-  geom_col(position = ""dodge"") +
-  theme_minimal() +
-  theme(legend.position = ""bottom"") +
-  scale_fill_viridis_d() +
-  labs( 
-    x = ""Frequency"", y = """", 
-    title = ""Income distribution by religious group"", 
-    caption = ""Source: pewforum.org/religious-landscape-study/income-distribution"" 
-    ) 
+## Fix labels (plot)
+
+```{r ref.label = ""fix-labels"", echo=FALSE, out.width=""80%""}
 ```
+

---FILE: course-materials/slides/u1_d07-tidy-data/u1_d07-tidy-data.html---
@@ -6,6 +6,12 @@
     <script src=""libs/header-attrs/header-attrs.js""></script>
     <link href=""libs/font-awesome/css/all.css"" rel=""stylesheet"" />
     <link href=""libs/font-awesome/css/v4-shims.css"" rel=""stylesheet"" />
+    <link href=""libs/tile-view/tile-view.css"" rel=""stylesheet"" />
+    <script src=""libs/tile-view/tile-view.js""></script>
+    <link href=""libs/animate.css/animate.xaringan.css"" rel=""stylesheet"" />
+    <link href=""libs/tachyons/tachyons.min.css"" rel=""stylesheet"" />
+    <link href=""libs/panelset/panelset.css"" rel=""stylesheet"" />
+    <script src=""libs/panelset/panelset.js""></script>
     <link rel=""stylesheet"" href=""../slides.css"" type=""text/css"" />
   </head>
   <body>
@@ -75,14 +81,13 @@
 
 ```
 ## # A tibble: 5 x 12
-##   faculty_type `1975` `1989` `1993` `1995` `1999` `2001` `2003` `2005` `2007` `2009`
-##   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
-## 1 Full-Time T‚Ä¶   29     27.6   25     24.8   21.8   20.3   19.3   17.8   17.2   16.8
-## 2 Full-Time T‚Ä¶   16.1   11.4   10.2    9.6    8.9    9.2    8.8    8.2    8      7.6
-## 3 Full-Time N‚Ä¶   10.3   14.1   13.6   13.6   15.2   15.5   15     14.8   14.9   15.1
-## 4 Part-Time F‚Ä¶   24     30.4   33.1   33.2   35.5   36     37     39.3   40.5   41.1
-## 5 Graduate St‚Ä¶   20.5   16.5   18.1   18.8   18.7   19     20     19.9   19.5   19.4
-## # ‚Ä¶ with 1 more variable: `2011` &lt;dbl&gt;
+##   faculty_type          `1975` `1989` `1993` `1995` `1999` `2001` `2003` `2005` `2007` `2009` `2011`
+##   &lt;chr&gt;                  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
+## 1 Full-Time Tenured Fa‚Ä¶   29     27.6   25     24.8   21.8   20.3   19.3   17.8   17.2   16.8   16.7
+## 2 Full-Time Tenure-Tra‚Ä¶   16.1   11.4   10.2    9.6    8.9    9.2    8.8    8.2    8      7.6    7.4
+## 3 Full-Time Non-Tenure‚Ä¶   10.3   14.1   13.6   13.6   15.2   15.5   15     14.8   14.9   15.1   15.4
+## 4 Part-Time Faculty       24     30.4   33.1   33.2   35.5   36     37     39.3   40.5   41.1   41.3
+## 5 Graduate Student Emp‚Ä¶   20.5   16.5   18.1   18.8   18.7   19     20     19.9   19.5   19.4   19.3
 ```
 
 ---
@@ -95,7 +100,7 @@
 
 But before we do so... 
 
-.discussion[
+.question[
 If the long data will have a row for each year/faculty type combination, 
 and there are 5 faculty types and 11 years of data, how many rows will the data have?
 ]
@@ -111,7 +116,7 @@
 ## `pivot_*()` functions
 
 
-![](img/tidyr-longer-wider.gif)&lt;!-- --&gt;
+&lt;img src=""img/tidyr-longer-wider.gif"" width=""50%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -150,19 +155,15 @@
 
 ```
 ## # A tibble: 55 x 3
-##    faculty_type              year  percentage
-##    &lt;chr&gt;                     &lt;chr&gt;      &lt;dbl&gt;
-##  1 Full-Time Tenured Faculty 1975        29  
-##  2 Full-Time Tenured Faculty 1989        27.6
-##  3 Full-Time Tenured Faculty 1993        25  
-##  4 Full-Time Tenured Faculty 1995        24.8
-##  5 Full-Time Tenured Faculty 1999        21.8
-##  6 Full-Time Tenured Faculty 2001        20.3
-##  7 Full-Time Tenured Faculty 2003        19.3
-##  8 Full-Time Tenured Faculty 2005        17.8
-##  9 Full-Time Tenured Faculty 2007        17.2
-## 10 Full-Time Tenured Faculty 2009        16.8
-## # ‚Ä¶ with 45 more rows
+##   faculty_type              year  percentage
+##   &lt;chr&gt;                     &lt;chr&gt;      &lt;dbl&gt;
+## 1 Full-Time Tenured Faculty 1975        29  
+## 2 Full-Time Tenured Faculty 1989        27.6
+## 3 Full-Time Tenured Faculty 1993        25  
+## 4 Full-Time Tenured Faculty 1995        24.8
+## 5 Full-Time Tenured Faculty 1999        21.8
+## 6 Full-Time Tenured Faculty 2001        20.3
+## # ‚Ä¶ with 49 more rows
 ```
 
 ---
@@ -183,24 +184,20 @@
 
 ```
 ## # A tibble: 55 x 3
-##    faculty_type              year  percentage
-##    &lt;chr&gt;                     &lt;chr&gt;      &lt;dbl&gt;
-##  1 Full-Time Tenured Faculty 1975        29  
-##  2 Full-Time Tenured Faculty 1989        27.6
-##  3 Full-Time Tenured Faculty 1993        25  
-##  4 Full-Time Tenured Faculty 1995        24.8
-##  5 Full-Time Tenured Faculty 1999        21.8
-##  6 Full-Time Tenured Faculty 2001        20.3
-##  7 Full-Time Tenured Faculty 2003        19.3
-##  8 Full-Time Tenured Faculty 2005        17.8
-##  9 Full-Time Tenured Faculty 2007        17.2
-## 10 Full-Time Tenured Faculty 2009        16.8
-## # ‚Ä¶ with 45 more rows
+##   faculty_type              year  percentage
+##   &lt;chr&gt;                     &lt;chr&gt;      &lt;dbl&gt;
+## 1 Full-Time Tenured Faculty 1975        29  
+## 2 Full-Time Tenured Faculty 1989        27.6
+## 3 Full-Time Tenured Faculty 1993        25  
+## 4 Full-Time Tenured Faculty 1995        24.8
+## 5 Full-Time Tenured Faculty 1999        21.8
+## 6 Full-Time Tenured Faculty 2001        20.3
+## # ‚Ä¶ with 49 more rows
 ```
 
 ---
 
-.discussion[
+.question[
 This doesn't look quite right, how would you fix it?
 ]
 
@@ -211,7 +208,7 @@
   geom_col(position = ""dodge"")
 ```
 
-&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-8-1.png"" width=""2400"" /&gt;
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-8-1.png"" width=""70%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -222,7 +219,7 @@
   geom_col(position = ""dodge"")
 ```
 
-&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-9-1.png"" width=""2400"" /&gt;
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-9-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -235,7 +232,7 @@
   geom_col()
 ```
 
-&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-10-1.png"" width=""2400"" /&gt;
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-10-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -248,20 +245,21 @@
   geom_line()
 ```
 
-&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-11-1.png"" width=""2400"" /&gt;
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-11-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
-.discussion[
+.question[
 What is the difference between these two plots?
 ]
 
-&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-12-1.png"" width=""1800"" /&gt;
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-12-1.png"" width=""70%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
 ## Make year numeric again!
 
+.small[
 
 ```r
 staff_long &lt;- staff_long %&gt;%
@@ -272,15 +270,16 @@
   geom_line()
 ```
 
-&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-13-1.png"" width=""1800"" /&gt;
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-13-1.png"" width=""70%"" style=""display: block; margin: auto;"" /&gt;
+]
 
 ---
 
-.discussion[
+.question[
 How would you go about creating the following plot?
 ]
 
-&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-14-1.png"" width=""1800"" /&gt;
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-14-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -330,7 +329,7 @@
 
 ---
 
-&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-17-1.png"" width=""1500"" /&gt;
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-17-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -358,11 +357,11 @@
 
 ---
 
-&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-19-1.png"" width=""1500"" /&gt;
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-19-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
-&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-20-1.png"" width=""1500"" /&gt;
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-20-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
@@ -416,29 +415,23 @@
 
 ```
 ## # A tibble: 12 x 6
-##    `Religious trad‚Ä¶ `Less than $30,‚Ä¶ `$30,000-$49,99‚Ä¶ `$50,000-$99,99‚Ä¶ `$100,000 or mo‚Ä¶
-##    &lt;chr&gt;                       &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;
-##  1 ""Buddhist""                  0.36              0.18            0.32             0.13 
-##  2 ""Catholic""                  0.36              0.19            0.26             0.19 
-##  3 ""Evangelical Pr‚Ä¶            0.35              0.22            0.28             0.14 
-##  4 ""Hindu""                     0.17              0.13            0.34             0.36 
-##  5 ""Historically B‚Ä¶            0.53              0.22            0.17             0.08 
-##  6 ""Jehovah's Witn‚Ä¶            0.48              0.25            0.22             0.04 
-##  7 ""Jewish""                    0.16              0.15            0.24             0.44 
-##  8 ""Mainline Prote‚Ä¶            0.290             0.2             0.28             0.23 
-##  9 ""Mormon""                    0.27              0.2             0.33             0.2  
-## 10 ""Muslim""                    0.34              0.17            0.290            0.2  
-## 11 ""Orthodox Chris‚Ä¶            0.18              0.17            0.36             0.290
-## 12 ""Unaffiliated (‚Ä¶            0.33              0.2             0.26             0.21 
-## # ‚Ä¶ with 1 more variable: `Sample Size` &lt;dbl&gt;
+##   `Religious trad‚Ä¶ `Less than $30,‚Ä¶ `$30,000-$49,99‚Ä¶ `$50,000-$99,99‚Ä¶ `$100,000 or mo‚Ä¶ `Sample Size`
+##   &lt;chr&gt;                       &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;         &lt;dbl&gt;
+## 1 Buddhist                     0.36             0.18             0.32             0.13           233
+## 2 Catholic                     0.36             0.19             0.26             0.19          6137
+## 3 Evangelical Pro‚Ä¶             0.35             0.22             0.28             0.14          7462
+## 4 Hindu                        0.17             0.13             0.34             0.36           172
+## 5 Historically Bl‚Ä¶             0.53             0.22             0.17             0.08          1704
+## 6 Jehovah's Witne‚Ä¶             0.48             0.25             0.22             0.04           208
+## # ‚Ä¶ with 6 more rows
 ```
 ]
 
 ---
 
 ## Rename columns
 
-.small[
+.midi[
 
 ```r
 rel_inc %&gt;%
@@ -450,34 +443,29 @@
 
 ```
 ## # A tibble: 12 x 6
-##    religion     `Less than $30,0‚Ä¶ `$30,000-$49,99‚Ä¶ `$50,000-$99,99‚Ä¶ `$100,000 or mo‚Ä¶     n
-##    &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt; &lt;dbl&gt;
-##  1 ""Buddhist""               0.36              0.18            0.32             0.13    233
-##  2 ""Catholic""               0.36              0.19            0.26             0.19   6137
-##  3 ""Evangelica‚Ä¶             0.35              0.22            0.28             0.14   7462
-##  4 ""Hindu""                  0.17              0.13            0.34             0.36    172
-##  5 ""Historical‚Ä¶             0.53              0.22            0.17             0.08   1704
-##  6 ""Jehovah's ‚Ä¶             0.48              0.25            0.22             0.04    208
-##  7 ""Jewish""                 0.16              0.15            0.24             0.44    708
-##  8 ""Mainline P‚Ä¶             0.290             0.2             0.28             0.23   5208
-##  9 ""Mormon""                 0.27              0.2             0.33             0.2     594
-## 10 ""Muslim""                 0.34              0.17            0.290            0.2     205
-## 11 ""Orthodox C‚Ä¶             0.18              0.17            0.36             0.290   155
-## 12 ""Unaffiliat‚Ä¶             0.33              0.2             0.26             0.21   6790
+##   religion             `Less than $30,00‚Ä¶ `$30,000-$49,999` `$50,000-$99,99‚Ä¶ `$100,000 or mor‚Ä¶     n
+##   &lt;chr&gt;                             &lt;dbl&gt;             &lt;dbl&gt;            &lt;dbl&gt;             &lt;dbl&gt; &lt;dbl&gt;
+## 1 Buddhist                           0.36              0.18             0.32              0.13   233
+## 2 Catholic                           0.36              0.19             0.26              0.19  6137
+## 3 Evangelical Protest‚Ä¶               0.35              0.22             0.28              0.14  7462
+## 4 Hindu                              0.17              0.13             0.34              0.36   172
+## 5 Historically Black ‚Ä¶               0.53              0.22             0.17              0.08  1704
+## 6 Jehovah's Witness                  0.48              0.25             0.22              0.04   208
+## # ‚Ä¶ with 6 more rows
 ```
 ]
 
 --
 
-.discussion[
+.question[
 If we want a new variable called `income` with levels such as ""Less than $30,000"", ""$30,000-$49,999"", ... etc. which function should we use?
 ]
 
 ---
 
 ## Pivot longer
 
-.small[
+.midi[
 
 ```r
 rel_inc %&gt;%
@@ -494,27 +482,23 @@
 
 ```
 ## # A tibble: 48 x 4
-##    religion                   n income            proportion
-##    &lt;chr&gt;                  &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt;
-##  1 Buddhist                 233 Less than $30,000       0.36
-##  2 Buddhist                 233 $30,000-$49,999         0.18
-##  3 Buddhist                 233 $50,000-$99,999         0.32
-##  4 Buddhist                 233 $100,000 or more        0.13
-##  5 Catholic                6137 Less than $30,000       0.36
-##  6 Catholic                6137 $30,000-$49,999         0.19
-##  7 Catholic                6137 $50,000-$99,999         0.26
-##  8 Catholic                6137 $100,000 or more        0.19
-##  9 Evangelical Protestant  7462 Less than $30,000       0.35
-## 10 Evangelical Protestant  7462 $30,000-$49,999         0.22
-## # ‚Ä¶ with 38 more rows
+##   religion     n income            proportion
+##   &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt;
+## 1 Buddhist   233 Less than $30,000       0.36
+## 2 Buddhist   233 $30,000-$49,999         0.18
+## 3 Buddhist   233 $50,000-$99,999         0.32
+## 4 Buddhist   233 $100,000 or more        0.13
+## 5 Catholic  6137 Less than $30,000       0.36
+## 6 Catholic  6137 $30,000-$49,999         0.19
+## # ‚Ä¶ with 42 more rows
 ```
 ]
 
 ---
 
 ## Calculate frequencies
 
-.small[
+.midi[
 
 ```r
 rel_inc %&gt;%
@@ -532,19 +516,15 @@
 
 ```
 ## # A tibble: 48 x 5
-##    religion                   n income            proportion frequency
-##    &lt;chr&gt;                  &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;
-##  1 Buddhist                 233 Less than $30,000       0.36        84
-##  2 Buddhist                 233 $30,000-$49,999         0.18        42
-##  3 Buddhist                 233 $50,000-$99,999         0.32        75
-##  4 Buddhist                 233 $100,000 or more        0.13        30
-##  5 Catholic                6137 Less than $30,000       0.36      2209
-##  6 Catholic                6137 $30,000-$49,999         0.19      1166
-##  7 Catholic                6137 $50,000-$99,999         0.26      1596
-##  8 Catholic                6137 $100,000 or more        0.19      1166
-##  9 Evangelical Protestant  7462 Less than $30,000       0.35      2612
-## 10 Evangelical Protestant  7462 $30,000-$49,999         0.22      1642
-## # ‚Ä¶ with 38 more rows
+##   religion     n income            proportion frequency
+##   &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;
+## 1 Buddhist   233 Less than $30,000       0.36        84
+## 2 Buddhist   233 $30,000-$49,999         0.18        42
+## 3 Buddhist   233 $50,000-$99,999         0.32        75
+## 4 Buddhist   233 $100,000 or more        0.13        30
+## 5 Catholic  6137 Less than $30,000       0.36      2209
+## 6 Catholic  6137 $30,000-$49,999         0.19      1166
+## # ‚Ä¶ with 42 more rows
 ```
 ]
 
@@ -569,123 +549,194 @@
 
 ---
 
-## Start plotting
+## Religion
 
 
 ```r
 ggplot(rel_inc_long, aes(y = religion, x = frequency)) +
   geom_col()
 ```
 
-&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-29-1.png"" width=""1500"" /&gt;
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-29-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
 ## Reverse religion order
 
 
 ```r
-*ggplot(rel_inc_long, aes(y = fct_rev(religion), x = frequency)) +
+rel_inc_long &lt;- rel_inc_long %&gt;%
+  mutate(religion = fct_rev(religion))
+
+*ggplot(rel_inc_long, aes(y = religion, x = frequency)) +
   geom_col()
 ```
 
-&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-30-1.png"" width=""1500"" /&gt;
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-30-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
 ## Add income
 
 
 ```r
-*ggplot(rel_inc_long, aes(y = fct_rev(religion), x = frequency, fill = income)) +
+*ggplot(rel_inc_long, aes(y = religion, x = frequency, fill = income)) +
   geom_col() 
 ```
 
-&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-31-1.png"" width=""1500"" /&gt;
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-31-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 
 ---
 
-## Dodge bars
+## Fix income level ordering
+
+
+```r
+rel_inc_long &lt;- rel_inc_long %&gt;%
+  mutate(
+*   income = fct_relevel(income, ""$100,000 or more"",
+*                        ""$50,000-$99,999"", ""$30,000-$49,999"",
+*                        ""Less than $30,000"")
+    )
+```
+
+---
+
+## Plot again
+
+
+```r
+ggplot(rel_inc_long, aes(y = religion, x = frequency, fill = income)) + 
+  geom_col()
+```
+
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-33-1.png"" width=""100%"" style=""display: block; margin: auto;"" /&gt;
+
+---
+
+## Fill bars
 
 .small[
 
 ```r
-ggplot(rel_inc_long, aes(y = fct_rev(religion), x = frequency, fill = income)) +
-* geom_col(position = ""dodge"")
+ggplot(rel_inc_long, aes(y = religion, x = frequency, fill = income)) +
+* geom_col(position = ""fill"")
 ```
 
-&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-32-1.png"" width=""1500"" /&gt;
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-34-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 ]
 
 ---
 
+## Change colors
+
+.small[
+
+```r
+ggplot(rel_inc_long, aes(y = religion, x = frequency, fill = income)) +
+  geom_col(position = ""fill"") +
+* scale_fill_viridis_d()
+```
+
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-35-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
+]
+
+---
+
+
 ## Change theme
 
 .small[
 
 ```r
-ggplot(rel_inc_long, aes(y = fct_rev(religion), x = frequency, fill = income)) +
-  geom_col(position = ""dodge"") +
+ggplot(rel_inc_long, aes(y = religion, x = frequency, fill = income)) +
+  geom_col(position = ""fill"") +
+  scale_fill_viridis_d() +
 * theme_minimal()
 ```
 
-&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-33-1.png"" width=""1500"" /&gt;
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-36-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
 ]
 
 ---
 
 ## Move legend to the bottom
 
-.small[
+.midi[
 
 ```r
-ggplot(rel_inc_long, aes(y = fct_rev(religion), x = frequency, fill = income)) +
-  geom_col(position = ""dodge"") +
+ggplot(rel_inc_long, aes(y = religion, x = frequency, fill = income)) +
+  geom_col(position = ""fill"") +
+  scale_fill_viridis_d() +
   theme_minimal() +
 * theme(legend.position = ""bottom"")
 ```
-
-&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-34-1.png"" width=""1500"" /&gt;
 ]
 
 ---
 
-## Prettier colors
+## Move legend to the bottom (plot)
+
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-37-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
+
+---
+
+## Legend adjustments
 
 .small[
 
 ```r
-ggplot(rel_inc_long, aes(y = fct_rev(religion), x = frequency, fill = income)) +
-  geom_col(position = ""dodge"") +
+ggplot(rel_inc_long, aes(y = religion, x = frequency, fill = income)) +
+  geom_col(position = ""fill"") +
+  scale_fill_viridis_d() +
   theme_minimal() +
-  theme(legend.position = ""bottom"") +
-* scale_fill_viridis_d()
+  theme(
+    legend.position = ""bottom"", 
+*   legend.key.size = unit(0.3, ""cm""),
+*   legend.box.margin = margin(t = 0, r = 0, b = 0, l = 0, unit = ""pt"")
+    ) +
+* guides(fill = guide_legend(nrow = 2, byrow = TRUE))
 ```
-
-&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-35-1.png"" width=""1500"" /&gt;
 ]
 
 ---
 
+## Legend adjustments (plot)
+
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-38-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
+
+---
+
 ## Fix labels
 
+.midi[
 
 ```r
-ggplot(rel_inc_long, aes(y = fct_rev(religion), x = frequency, fill = income)) +
-  geom_col(position = ""dodge"") +
-  theme_minimal() +
-  theme(legend.position = ""bottom"") +
+ggplot(rel_inc_long, aes(y = religion, x = frequency, fill = income)) +
+  geom_col(position = ""fill"") +
   scale_fill_viridis_d() +
-* labs(
+  theme_minimal() +
+  theme(
+    legend.position = ""bottom"", 
+*   legend.key.size = unit(0.3, ""cm""),
+*   legend.box.margin = margin(t = 0, r = 0, b = 0, l = 0, unit = ""pt"")
+    ) +
+  guides(fill = guide_legend(nrow = 2, byrow = TRUE)) +
+  labs(
 *   x = ""Frequency"", y = """",
 *   title = ""Income distribution by religious group"",
-*   caption = ""Source: pewforum.org/religious-landscape-study/income-distribution""
-*   )
+*   subtitle = ""Source: Pew Research Center, Religious Landscape Study"",
+    fill = ""Income""
+    )
 ```
+]
 
 ---
 
-&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-37-1.png"" width=""1500"" /&gt;
+## Fix labels (plot)
+
+&lt;img src=""u1_d07-tidy-data_files/figure-html/unnamed-chunk-39-1.png"" width=""80%"" style=""display: block; margin: auto;"" /&gt;
+
     </textarea>
 <style data-target=""print-only"">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
 <script src=""https://remarkjs.com/downloads/remark-latest.min.js""></script>",False,True,Documentation / Formatting,6
tidyverse,datascience-box,f07a8df4d4bb69428a7a88c9b1a98c1a84116931,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-09-03T15:39:03Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-09-03T15:39:03Z,Fix setup,course-materials/slides/setup.Rmd,True,False,True,False,18,10,28,"---FILE: course-materials/slides/setup.Rmd---
@@ -1,26 +1,34 @@
 ```{r setup, include=FALSE}
 # R options
 options(
-  htmltools.dir.version = FALSE, # for blogdown
-  show.signif.stars = FALSE,     # for regression output
-  warn = 1
+  htmltools.dir.version = FALSE,
+  dplyr.print_min = 6, 
+  dplyr.print_max = 6,
+  width = 100
   )
 # figure height, width, dpi
-knitr::opts_chunk$set(fig.height = 2.5, fig.width = 5, dpi = 300, fig.retina=3) 
+# figure height, width, dpi
+knitr::opts_chunk$set(echo = TRUE, 
+                      fig.width = 6, 
+                      fig.asp = 0.5,
+                      out.width = ""100%"",
+                      fig.align = ""center"",
+                      dpi = 300,
+                      warning = FALSE,
+                      message = FALSE)
+# set seed
+set.seed(1234)
 # fontawesome
 htmltools::tagList(rmarkdown::html_dependency_font_awesome())
 # magick
 dev.off <- function(){
   invisible(grDevices::dev.off())
 }
-# code highlighting
-hook_source <- knitr::knit_hooks$get('source')
-knitr::knit_hooks$set(source = function(x, options) {
-  x <- stringr::str_replace(x, ""^[[:blank:]]?([^*].+?)[[:blank:]]*#<<[[:blank:]]*$"", ""*\\1"")
-  hook_source(x, options)
-})
 # countdown
 library(countdown)
+# conflicted
+library(conflicted)
+conflict_prefer(""filter"", ""dplyr"")
 ```
 
 layout: true",False,True,Rendering / Conversion,6
tidyverse,datascience-box,9a69d2de6cc70e37593d7d4d1812d23b92819e3a,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-09-03T12:14:13Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-09-03T12:14:13Z,Fix how links are presented,04-pedagogy.Rmd,True,False,True,False,3,3,6,"---FILE: 04-pedagogy.Rmd---
@@ -9,12 +9,12 @@ The following resources describe the pedagogy used in designing and teaching a c
 > Mine √áetinkaya-Rundel & Victoria Ellison (In press), A fresh look at introductory data science, *Journal of Statistics Education*.
 > [doi.org/10.1080/10691898.2020.1804497](https://doi.org/10.1080/10691898.2020.1804497).
 
-> Talk: The art and science of teaching data science [Slides](https://speakerdeck.com/minecr/the-art-and-science-of-teaching-data-science-university-of-glasgow)
+> Talk: The art and science of teaching data science [[Slides]](https://speakerdeck.com/minecr/the-art-and-science-of-teaching-data-science-university-of-glasgow)
 
-> Talk: Data Science in a Box [Slides](https://speakerdeck.com/minecr/data-science-in-a-box) [Video](https://www.youtube.com/watch?v=tYGLYdeFJMc)
+> Talk: Data Science in a Box [[Slides]](https://speakerdeck.com/minecr/data-science-in-a-box) [[Video]](https://www.youtube.com/watch?v=tYGLYdeFJMc)
 
 > Talk: Let them eat cake (first)!
-> [Slides]<https://speakerdeck.com/minecr/let-them-eat-cake-first>) [Video](https://www.youtube.com/embed/RsVOrpXAPXo?start=1009)
+> [[Slides]](https://speakerdeck.com/minecr/let-them-eat-cake-first) [[Video]](https://www.youtube.com/embed/RsVOrpXAPXo?start=1009)
 
 ## Teaching the tidyverse
 ",False,True,Rendering / Conversion,3
tidyverse,datascience-box,acd783a324d0ea93dc162b7addd915eb1b1043ae,Debbie Yuster,dyuster@ramapo.edu,2020-09-02T13:52:15Z,GitHub,noreply@github.com,2020-09-02T13:52:15Z,Fix typo,course-materials/slides/u1_d01-welcome/u1_d01-welcome.Rmd,True,False,True,False,1,1,2,"---FILE: course-materials/slides/u1_d01-welcome/u1_d01-welcome.Rmd---
@@ -267,7 +267,7 @@ class: center, middle
 ## Tips for asking questions
 
 - First search existing discussion for answers. If the question has already been answered, you're done! If it has already been asked but you're not satisfied with the answer, add to the thread. 
-- Give your question context from course concepts not couse assignments.
+- Give your question context from course concepts not course assignments.
     - Good context: ""I have a question on filtering""
     - Bad context: ""I have a question on HW 1 question 4""
 - Be precise in your description:",False,True,Documentation / Formatting,4
tidyverse,datascience-box,a60528a6242181d3199286f45d1bb0ad3a71ffb2,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-08-24T18:13:24Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-08-24T18:13:24Z,Fix typo,index.Rmd,True,False,True,False,1,1,2,"---FILE: index.Rmd---
@@ -24,6 +24,6 @@ Majority of the materials linked live in the GitHub repo serving this website. Y
 
 ## Acknowledements {-}
 
-Huge thanks to the #rstats education community who have made numerous suggestions for this resource, to Lee Suddaby and Zeno Kujowa for converting the homework assignments to learnr tutorials, and to [M√ºge √áetinkaya](http://muge.fr/) for the hex logo!
+Huge thanks to the #rstats education community who have made numerous suggestions for this resource, to Lee Suddaby and Zeno Kujawa for converting the homework assignments to learnr tutorials, and to [M√ºge √áetinkaya](http://muge.fr/) for the hex logo!
 
 This website is built with [bookdown](https://bookdown.org/), the lovely icons by [icons8](http://icons8.com/), and none of this would be possible without the [tidyverse](https://tidyverse.org/).",False,True,Implementation / Logic,6
tidyverse,datascience-box,d7c8ef43c51bcbceabbaf56748ac823549c2814f,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-08-24T18:02:13Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-08-24T18:02:13Z,Fix link,02-interactive-tutorials.Rmd,True,False,True,False,1,1,2,"---FILE: 02-interactive-tutorials.Rmd---
@@ -1,6 +1,6 @@
 # Interactive tutorials {#interactive-tutorials}
 
-The following interactive tutorials have been built with [**learnr**](https://rstudio.github.io/learnr/publishing.html) and [**gradethis**](https://rstudio-education.github.io/gradethis/). They're available on shinyapps.io (linked) as well as distributed with the [**dsbox**](https://rstudio-education.github.io/dsbox/tutorials/index.html) package.^[The dsbox package is not yet on CRAN, until then you will need to install from GitHub with `devtools::install_github(""rstudio-education/gradethis"")`.] With the dsbox package installed, you can also run these tutorials in the Tutorials pane of your RStudio window. This might be preferable for courses with high enrollment where students need to access the tutorials at the same time. 
+The following interactive tutorials have been built with [**learnr**](https://rstudio.github.io/learnr/publishing.html) and [**gradethis**](https://rstudio-education.github.io/gradethis/). They're available on shinyapps.io (linked) as well as distributed with the [**dsbox**](https://rstudio-education.github.io/dsbox/tutorials/index.html) package.^[The dsbox package is not yet on CRAN, until then you will need to install from GitHub with `devtools::install_github(""rstudio-education/dsbox"")`.] With the dsbox package installed, you can also run these tutorials in the Tutorials pane of your RStudio window. This might be preferable for courses with high enrollment where students need to access the tutorials at the same time. 
 
 Note that many of these include examples and questions from the homework assignments listed earlier. You can think of these as interactive, auto-feedback versions of the simpler questions in the homework assignments. If using both the tutorials and the homework assignments in your teaching, I recommend modifying the homework assignments to remove the redundant questions (they will usually be the earlier, shorter, simpler questions) and making the homework assignment shorter. Students will ultimately get exposed to the same material, but get auto-feedback in the tutorials and human feedback on the homework assignments.
 ",False,True,Implementation / Logic,6
tidyverse,datascience-box,069d93bb2f0ebeb92366e71218aa087bcdf6d351,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-08-21T23:07:33Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-08-21T23:07:33Z,Fix sentence fragment,01-overview.Rmd,True,False,True,False,1,1,2,"---FILE: 01-overview.Rmd---
@@ -72,7 +72,7 @@ session
 - labs: 12 guided hands on exercises for students requiring minimal introduction from the instructor
 - exams: 2 sample take-home exams and keys
 - project: Final project assignment
-- tutorials: 8 interactive learnr tutorials built
+- tutorials: 8 interactive learnr tutorials
 
 **Educator facing materials:**
 ",False,True,Rendering / Conversion,3
tidyverse,datascience-box,caedb3b02b1a1b4ad47f5cae302876edd4926546,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-08-21T23:05:09Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-08-21T23:05:09Z,"Fixed misplaced wording, closes #71",02-exams.Rmd;03-access-r.Rmd,True,False,True,False,3,3,6,"---FILE: 02-exams.Rmd---
@@ -14,4 +14,4 @@ I don't think the best assessment method for this curriculum is an exam, but som
 
 [[Instructions]](https://rstudio-education.github.io/datascience-box/course-materials/exams/exam-02/)
 [[Source]](https://github.com/rstudio-education/datascience-box/tree/master/course-materials/exams/exam-02)
-:::
\ No newline at end of file
+:::

---FILE: 03-access-r.Rmd---
@@ -1,5 +1,7 @@
 # (PART) Infrastructure {-}
 
+# Accessing R {#access-r}
+
 One of the design principles of this course is ""cherish day one"" -- get students 
 from nothing to their first meaningful data visualization within the first 10 minutes 
 of the course. Achieving this is possible, but requires careful consideration of 
@@ -12,8 +14,6 @@ setups section describes other approaches to setting up the computing infrastruc
 that can be just as efficient and effective as the ones described in the main 
 choices for the course, and discusses pros and cons.
 
-# Accessing R {#access-r}
-
 The RStudio IDE includes a viewable environment, a file browser, data viewer, 
 and a plotting pane, which makes it less intimidating than the bare R shell. 
 Additionally, since it is a full fledged IDE, it also features integrated help, ",False,True,Rendering / Conversion,3
tidyverse,datascience-box,3201d634a95fd936635757755e81aa0cba78a005,Debbie Yuster,dyuster@ramapo.edu,2020-08-21T18:42:33Z,GitHub,noreply@github.com,2020-08-21T18:42:33Z,"Fixed minor typos (#72)

* Update 01-tech-stack.Rmd

Fixed typos

* Update 01-community.Rmd

Minor grammar fix

* Update 02-exploring-data.Rmd

Fixed minor typo

* Update hw-01-airbnb-edi.Rmd

Fixed minor typo - should I edit the HTML as well or will it be rerendered from source at some point?

* Update 02-interactive-tutorials.Rmd

Fixed minor typo, changed hr -> hour.

* Update hw-01-airbnb-edi.Rmd

Reverting previous (unnecessary) change

* Update 03-sharing.Rmd

Fixed minor typo",01-community.Rmd;01-tech-stack.Rmd;02-exploring-data.Rmd;02-interactive-tutorials.Rmd;03-sharing.Rmd,True,False,True,False,6,6,12,"---FILE: 01-community.Rmd---
@@ -5,7 +5,7 @@ exchange ideas with others teaching similar courses?
 
 We now have a `dsbox` Slack channel, you can join [here](https://join.slack.com/t/dsboxworkspace/shared_invite/zt-gro0x0hh-x9JzHN0oLQayP2G0g~6Zhg).^[If the link has expired, please email me at [cetinkaya.mine@gmail.com](mailto:cetinkaya.mine@gmail.com) to request a new one.] The Slack channel is a place for discussion on using these or similar materials in data science courses. Please make sure to review the [Code of Conduct](https://contributor-covenant.org/version/2/0/CODE_OF_CONDUCT.html) before joining. 
 
-Other great venues for questions is the [RStudio Community under Teaching](https://community.rstudio.com/c/teaching) 
+Other great venues for questions are the [RStudio Community under Teaching](https://community.rstudio.com/c/teaching) 
 or [#rstats](https://twitter.com/search?q=%23rstats) Twitter.
 
 Additionally, we would love to hear from you if you are using these resources. 

---FILE: 01-tech-stack.Rmd---
@@ -21,4 +21,4 @@ It is also possible that it's already integrated into your learning management s
 Students are discouraged from using email for questions and discussions related to content of the course, only emails about personal matters are allowed. 
 Hence most course communication happens on Piazza. 
 Both public (for announcements and general questions) and private (for team communication) channels are used. 
-Note that not Piazza is not everyone's first choice, a fewoptions for alternatives used in statistics and data science courses can be found [on this Twitter thread](https://twitter.com/minebocek/status/1292499540105404416).
+Note that Piazza is not everyone's first choice, a few options for alternatives used in statistics and data science courses can be found [on this Twitter thread](https://twitter.com/minebocek/status/1292499540105404416).

---FILE: 02-exploring-data.Rmd---
@@ -194,7 +194,7 @@ Visualizing spatial data
 
 
 ::: {.lab}
-**Lab 5: La Quinta is Spanish for 'next to Denny's', Pt. 5** 
+**Lab 5: La Quinta is Spanish for 'next to Denny's', Pt. 2** 
 
 Wrangling spatial data
 

---FILE: 02-interactive-tutorials.Rmd---
@@ -1,10 +1,10 @@
 # Interactive tutorials {#interactive-tutorials}
 
-the following interactive tutorials have been built with [**learnr**](https://rstudio.github.io/learnr/publishing.html) and [**gradethis**](https://rstudio-education.github.io/gradethis/). They're available on shinyapps.io (linked) as well as distributed with the [**dsbox**](https://rstudio-education.github.io/dsbox/tutorials/index.html) package.^[The dsbox package is not yet on CRAN, until then you will need to install from GitHub with `devtools::install_github(""rstudio-education/gradethis"")`.] With the dsbox package installed, you can also run these tutorials in the Tutorials pane of your RStudio window. This might be preferable for courses with high enrollment where students need to access the tutorials at the same time. 
+The following interactive tutorials have been built with [**learnr**](https://rstudio.github.io/learnr/publishing.html) and [**gradethis**](https://rstudio-education.github.io/gradethis/). They're available on shinyapps.io (linked) as well as distributed with the [**dsbox**](https://rstudio-education.github.io/dsbox/tutorials/index.html) package.^[The dsbox package is not yet on CRAN, until then you will need to install from GitHub with `devtools::install_github(""rstudio-education/gradethis"")`.] With the dsbox package installed, you can also run these tutorials in the Tutorials pane of your RStudio window. This might be preferable for courses with high enrollment where students need to access the tutorials at the same time. 
 
 Note that many of these include examples and questions from the homework assignments listed earlier. You can think of these as interactive, auto-feedback versions of the simpler questions in the homework assignments. If using both the tutorials and the homework assignments in your teaching, I recommend modifying the homework assignments to remove the redundant questions (they will usually be the earlier, shorter, simpler questions) and making the homework assignment shorter. Students will ultimately get exposed to the same material, but get auto-feedback in the tutorials and human feedback on the homework assignments.
 
-If you would like to learn about making your own tutorials with learnr, I strongly recommend reviewing the video and materials from the following 1.5 hr workshop: [Building interactive tutorials in R](https://mine-cetinkaya-rundel.github.io/teach-r-online/).
+If you would like to learn about making your own tutorials with learnr, I strongly recommend reviewing the video and materials from the following 1.5 hour workshop: [Building interactive tutorials in R](https://mine-cetinkaya-rundel.github.io/teach-r-online/).
 
 
 ::: {.tutorial}

---FILE: 03-sharing.Rmd---
@@ -2,7 +2,7 @@
 
 A nifty tool for building your course website is blogdown.
 
-Perhaps the most useful aspect of blogdown in this setting is that your slides, assignments, etc. written in R Markdown can be automatically rendered, so you don‚Äôt need to separate knit those documents. 
+Perhaps the most useful aspect of blogdown in this setting is that your slides, assignments, etc. written in R Markdown can be automatically rendered, so you don‚Äôt need to separately knit those documents. 
 
 If you would like to build your course website with blogdown, you can use [this course website](http://introds.org/) as an example, source code [here](https://github.com/ids-s1-19/website).
 ",False,True,Implementation / Logic,6
tidyverse,datascience-box,6a92bcba2decf93c776c4837f9cd61c19ea492dc,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-08-21T15:08:47Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-08-21T15:08:47Z,Fix Muge's dots,index.Rmd,True,False,True,False,1,1,2,"---FILE: index.Rmd---
@@ -24,6 +24,6 @@ Majority of the materials linked live in the GitHub repo serving this website. Y
 
 ## Acknowledements {-}
 
-Huge thanks to the #rstats education community who have made numerous suggestions for this resource, to Lee Suddaby and Zeno Kujowa for converting the homework assignments to learnr tutorials, and to [Muge Cetinkaya](http://muge.fr/) for the hex logo!
+Huge thanks to the #rstats education community who have made numerous suggestions for this resource, to Lee Suddaby and Zeno Kujowa for converting the homework assignments to learnr tutorials, and to [M√ºge √áetinkaya](http://muge.fr/) for the hex logo!
 
 This website is built with [bookdown](https://bookdown.org/), the lovely icons by [icons8](http://icons8.com/), and none of this would be possible without the [tidyverse](https://tidyverse.org/).",False,True,Implementation / Logic,6
tidyverse,datascience-box,2f04d87330166c74cdd099af211937e4793e4d54,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-08-21T13:26:20Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-08-21T13:26:20Z,"Fix links, closes #66",01-tech-stack.Rmd,True,False,True,False,16,27,43,"---FILE: 01-tech-stack.Rmd---
@@ -1,35 +1,24 @@
 # Tech stack {#tech-stack}
 
-This course teaches computing and statistics to undergraduates with no background 
-in either. Managing such a course with students from varied backgrounds doing 
-non-trivial computational work is a big technical challenge. This page briefly 
-describes the toolkit choices, and the [infrastructure](/20-infrastructure) section 
-provides a path forward for educators who are considering using these tools for 
-their own teaching purposes.
+This course teaches computing and statistics to undergraduates with no background in either. 
+Managing such a course with students from varied backgrounds doing non-trivial computational work is a big technical challenge. 
+This page briefly describes the toolkit choices, and the Infrastructure part provides a path forward for educators who are considering using these tools for their own teaching purposes.
 
 While the recommended tech stack for the entirety of course development is tall, 
 only a few of the technologies are student facing:
 
-- RStudio Cloud: [RStudio Cloud](https://rstudio.cloud/) is a managed cloud 
-instance of the RStudio IDE. We recommend having students access RStudio via 
-RStudio Cloud as opposed to using a local installation. 
-[[Read more]](/infrastructure/rscloud/)
+- RStudio Cloud: [RStudio Cloud](https://rstudio.cloud/) is a managed cloud instance of the RStudio IDE. 
+We recommend having students access RStudio via RStudio Cloud as opposed to using a local installation. 
+See Section \@ref(access-r) for more on this.
 
-- GitHub: The use of [GitHub](https://github.com/) also goes a long way to help 
-students visualize and understand the git process which also aids in student 
-buy-in. The web interface allows students to easily view diffs (file changes 
-over time) in files they are collaborating on, keep track of commit histories, 
-and search both the current state as well as the entire history of the code 
-base. Within the classroom GitHub can be thought of as an advanced and flexible 
-learning management system (compared to traditional tools like Blackboard or Sakai). 
-[[Read more]](/infrastructure/github/)
-
-- Piazza: [Piazza](http://piazza.com/) is an easy to use and free Q&A platform 
-that your students might very well be already familiar with from other classes. 
-It is also possible that it's already integrated into your learning management 
-system if you're teaching in a university setting. Students are discouraged from 
-using email for questions and discussions related to content of the course, only 
-emails about personal matters are allowed. Hence most course communication 
-happens on Piazza. Both public (for announcements and general questions) and 
-private (for team communication) channels are used. [[Read more]](/infrastructure/piazza/)
+- GitHub: The use of [GitHub](https://github.com/) also goes a long way to help students visualize and understand the git process which also aids in student buy-in. 
+The web interface allows students to easily view diffs (file changes over time) in files they are collaborating on, keep track of commit histories, and search both the current state as well as the entire history of the code base. 
+Within the classroom GitHub can be thought of as an advanced and flexible learning management system (compared to traditional tools like Blackboard or Sakai). 
+See Section \@ref(version-control) for more on this.
 
+- Piazza: [Piazza](http://piazza.com/) is an easy to use and free Q&A platform that your students might very well be already familiar with from other classes. 
+It is also possible that it's already integrated into your learning management system if you're teaching in a university setting. 
+Students are discouraged from using email for questions and discussions related to content of the course, only emails about personal matters are allowed. 
+Hence most course communication happens on Piazza. 
+Both public (for announcements and general questions) and private (for team communication) channels are used. 
+Note that not Piazza is not everyone's first choice, a fewoptions for alternatives used in statistics and data science courses can be found [on this Twitter thread](https://twitter.com/minebocek/status/1292499540105404416).",False,True,Rendering / Conversion,3
tidyverse,datascience-box,2ba64b72db7a1abdb6991ad589833ec5627d3008,Debbie Yuster,dyuster@ramapo.edu,2020-08-21T02:06:29Z,GitHub,noreply@github.com,2020-08-21T02:06:29Z,"Update 01-tech-stack.Rmd

Fixed typo",01-tech-stack.Rmd,True,False,True,False,1,1,2,"---FILE: 01-tech-stack.Rmd---
@@ -27,7 +27,7 @@ learning management system (compared to traditional tools like Blackboard or Sak
 - Piazza: [Piazza](http://piazza.com/) is an easy to use and free Q&A platform 
 that your students might very well be already familiar with from other classes. 
 It is also possible that it's already integrated into your learning management 
-system if you're teahcing in a university setting. Students are discouraged from 
+system if you're teaching in a university setting. Students are discouraged from 
 using email for questions and discussions related to content of the course, only 
 emails about personal matters are allowed. Hence most course communication 
 happens on Slack. Both public (for announcements and general questions) and ",False,True,Documentation / Formatting,4
tidyverse,datascience-box,1a829818bf9c4330ddfdc9c7a093369cbe7b66ca,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-04-01T10:35:11Z,Mine √áetinkaya-Rundel,cetinkaya.mine@gmail.com,2020-04-01T10:35:11Z,Fix typo,slides/u1_d10-functions-and-automation/u1_d10-functions-and-automation.Rmd,True,False,True,False,1,1,2,"---FILE: slides/u1_d10-functions-and-automation/u1_d10-functions-and-automation.Rmd---
@@ -396,7 +396,7 @@ top_100_shows <- map_df(urls, scrape_show_info)
 - This will hit the `urls` one after another, and grab the info.
 
 --
-- If you get `HTTP Error 429 (Too man requests)` you might want to slow down your hits.
+- If you get `HTTP Error 429 (Too many requests)` you might want to slow down your hits.
 
 --
 - You can add a `Sys.sleep()` call to slow down your function:",False,True,Documentation / Formatting,4
tidyverse,datascience-box,9f4dad4356148aad2edf45505b87d455f71a2edb,Mine Cetinkaya-Rundel,mine@stat.duke.edu,2019-07-09T23:58:28Z,Mine Cetinkaya-Rundel,mine@stat.duke.edu,2019-07-09T23:58:28Z,Typo fix,website/content/infrastructure/rscloud/_index.Rmd;website/content/infrastructure/rscloud/_index.html,True,False,True,False,2,2,4,"---FILE: website/content/infrastructure/rscloud/_index.Rmd---
@@ -75,7 +75,7 @@ Viewer	    | View projects shared with everyone	             | Auditor, Visitor
 
 This set of permissions will allow instructors full access including management 
 of users. Teaching assistants will be able to peek into student projects, which 
-can very useful when helping troubleshoot. Students won't be able to see 
+can be very useful when helping troubleshoot. Students won't be able to see 
 each others' projects. Students auditing your course or visitors, such as 
 colleagues wanting to view/experience your course setup will have limited 
 access.

---FILE: website/content/infrastructure/rscloud/_index.html---
@@ -109,7 +109,7 @@ <h2>Setting up your course in RStudio Cloud</h2>
 </table>
 <p>This set of permissions will allow instructors full access including management
 of users. Teaching assistants will be able to peek into student projects, which
-can very useful when helping troubleshoot. Students won‚Äôt be able to see
+can be very useful when helping troubleshoot. Students won‚Äôt be able to see
 each others‚Äô projects. Students auditing your course or visitors, such as
 colleagues wanting to view/experience your course setup will have limited
 access.</p>",False,True,Documentation / Formatting,4
tidyverse,datascience-box,67e661472955c0151b67ff7c6cbaffbbb3ab9fe1,Mine Cetinkaya-Rundel,mine@stat.duke.edu,2019-07-09T22:01:00Z,Mine Cetinkaya-Rundel,mine@stat.duke.edu,2019-07-09T22:01:00Z,Fix spelling,website/content/content/explore/_index.Rmd,True,False,True,False,2,2,4,"---FILE: website/content/content/explore/_index.Rmd---
@@ -27,7 +27,7 @@ output: blogdown::html_page
 
 ## Labs
 
-- Lab 00 - Logistics: Overview of lab policies; class survey and pretest; create github and RStudio Cloud accounts
+- Lab 00 - Logistics: Overview of lab policies; class survey and pretest; create GitHub and RStudio Cloud accounts
 - Lab 01 - Hello R!: Working with RStudio Cloud, R, R markdown, and version control
 - Lab 02 - Data wrangling and visualization: Summarizing data using ggplot2 and dplyr
 - Lab 03 - Visualizing spatial data: Using spatial data to examine the clustering of Denny's restaurants and La Quinta hotels; importance of visualizing spatial data (John Snow)
@@ -37,5 +37,5 @@ output: blogdown::html_page
 ## Homework assignments
 
 - HW 01 - Ugly Charts: Improving a poor data visualization by using the principles discussed in class
-- HW 02 - Gotta catch 'em all: Visualizing Pok√©mon Go data and interpreting the results
+- HW 02 - Gotta catch 'em all: Visualizing Pokemon Go data and interpreting the results
 ",False,True,Documentation / Formatting,4
tidyverse,datascience-box,d63079dd1eee1191c5e39c22085e9217c3298b12,Mine Cetinkaya-Rundel,mine@stat.duke.edu,2019-07-09T08:30:06Z,Mine Cetinkaya-Rundel,mine@stat.duke.edu,2019-07-09T08:30:06Z,Fix link,website/content/hello/community/_index.html,False,False,False,False,1,1,2,"---FILE: website/content/hello/community/_index.html---
@@ -9,4 +9,4 @@
 <p>Like what‚Äôs in the box? Have questions? Is something you need missing? Want to
 exchange ideas with others teaching similar courses?</p>
 <p>Post on <a href=""https://community.rstudio.com/c/teaching"">RStudio Community under Teaching</a>
-or tweet with [#rstats](<a href=""https://twitter.com/search?q=%23rstats"">https://twitter.com/search?q=%23rstats</a>.</p>
+or tweet with <a href=""https://twitter.com/search?q=%23rstats"">#rstats</a>.</p>",False,False,Documentation / Formatting,1
tidyverse,datascience-box,bc4c7965f908cd6f9241198b32a95d640209adec,Florian Mayer,Florian.Mayer@dbca.wa.gov.au,2018-10-19T02:22:58Z,GitHub,noreply@github.com,2018-10-19T02:22:58Z,"Fix typo in hello/community/index.Rmd

Add a closing bracket to a Markdown link to render the link correctly.",website/content/hello/community/_index.Rmd,True,False,True,False,1,1,2,"---FILE: website/content/hello/community/_index.Rmd---
@@ -8,4 +8,4 @@ Like what's in the box? Have questions? Is something you need missing? Want to
 exchange ideas with others teaching similar courses?
 
 Post on [RStudio Community under Teaching](https://community.rstudio.com/c/teaching) 
-or tweet with [#rstats](https://twitter.com/search?q=%23rstats.
+or tweet with [#rstats](https://twitter.com/search?q=%23rstats).",False,True,Documentation / Formatting,4
tidyverse,datascience-box,f99405cb2840ab5b689d3b686a4296c843482e80,Mine Cetinkaya-Rundel,mine@stat.duke.edu,2018-08-17T16:51:56Z,Mine Cetinkaya-Rundel,mine@stat.duke.edu,2018-08-17T16:51:56Z,Fix brokwn links due to previous edit,website/content/hello/tech-stack/_index.Rmd;website/content/hello/tech-stack/_index.html;website/content/infrastructure/rscloud/_index.Rmd;website/content/infrastructure/rscloud/_index.html,True,False,True,False,13,8,21,"---FILE: website/content/hello/tech-stack/_index.Rmd---
@@ -11,20 +11,24 @@ describes the toolkit choices, and the [infrastructure](/20-infrastructure) sect
 provides a path forward for instructors who are considering using these tools for 
 their own teaching purposes.
 
+While the recommended tech stack is tall, only a few of the technologies are 
+student facing:
+
 - RStudio Cloud: [RStudio Cloud](https://rstudio.cloud/) is a managed cloud 
 instance of the RStudio IDE. We recommend having students access RStudio via 
 RStudio Cloud as opposed to using a local installation. 
-[[Read more]](20-infrastructure/01-rscloud/)
+[[Read more]](infrastructure/rscloud/)
 - GitHub: The use of [GitHub](https://github.com/) also goes a long way to help 
 students visualize and understand the git process which also aids in student 
 buy-in. The web interface allows students to easily view diffs (file changes 
 over time) in files they are collaborating on, keep track of commit histories, 
 and search both the current state as well as the entire history of the code 
 base. Within the classroom GitHub can be thought of as an advanced and flexible 
 learning management system (compared to traditional tools like Blackboard or Sakai).
-[[Read more]](20-infrastructure/02-github/)
+[[Read more]](infrastructure/github/)
 - Slack: [Slack](https://slack.com/) is a versatile communications and 
 collaboration tool. Students are discouraged from using email and, most course 
 communication happens here. Both public (for announcements and general questions) 
 and private (for team communication) channels are used.
-[[Read more]](20-infrastructure/03-slack/)
+[[Read more]](infrastructure/slack/)
+

---FILE: website/content/hello/tech-stack/_index.html---
@@ -7,8 +7,9 @@
 
 
 <p>This course teaches computing and statistics to undergraduates with no background in either. Managing such a course with students from varied backgrounds doing non-trivial computational work is a big technical challenge. This page briefly describes the toolkit choices, and the <a href=""/20-infrastructure"">infrastructure</a> section provides a path forward for instructors who are considering using these tools for their own teaching purposes.</p>
+<p>While the recommended tech stack is tall, only a few of the technologies are student facing:</p>
 <ul>
-<li>RStudio Cloud: <a href=""https://rstudio.cloud/"">RStudio Cloud</a> is a managed cloud instance of the RStudio IDE. We recommend having students access RStudio via RStudio Cloud as opposed to using a local installation. <a href=""20-infrastructure/01-rscloud/"">[Read more]</a></li>
-<li>GitHub: The use of <a href=""https://github.com/"">GitHub</a> also goes a long way to help students visualize and understand the git process which also aids in student buy-in. The web interface allows students to easily view diffs (file changes over time) in files they are collaborating on, keep track of commit histories, and search both the current state as well as the entire history of the code base. Within the classroom GitHub can be thought of as an advanced and flexible learning management system (compared to traditional tools like Blackboard or Sakai). <a href=""20-infrastructure/02-github/"">[Read more]</a></li>
-<li>Slack: <a href=""https://slack.com/"">Slack</a> is a versatile communications and collaboration tool. Students are discouraged from using email and, most course communication happens here. Both public (for announcements and general questions) and private (for team communication) channels are used. <a href=""20-infrastructure/03-slack/"">[Read more]</a></li>
+<li>RStudio Cloud: <a href=""https://rstudio.cloud/"">RStudio Cloud</a> is a managed cloud instance of the RStudio IDE. We recommend having students access RStudio via RStudio Cloud as opposed to using a local installation. <a href=""infrastructure/rscloud/"">[Read more]</a></li>
+<li>GitHub: The use of <a href=""https://github.com/"">GitHub</a> also goes a long way to help students visualize and understand the git process which also aids in student buy-in. The web interface allows students to easily view diffs (file changes over time) in files they are collaborating on, keep track of commit histories, and search both the current state as well as the entire history of the code base. Within the classroom GitHub can be thought of as an advanced and flexible learning management system (compared to traditional tools like Blackboard or Sakai). <a href=""infrastructure/github/"">[Read more]</a></li>
+<li>Slack: <a href=""https://slack.com/"">Slack</a> is a versatile communications and collaboration tool. Students are discouraged from using email and, most course communication happens here. Both public (for announcements and general questions) and private (for team communication) channels are used. <a href=""infrastructure/slack/"">[Read more]</a></li>
 </ul>

---FILE: website/content/infrastructure/rscloud/_index.Rmd---
@@ -169,7 +169,7 @@ If you have a base project template set up for your workspace, this new project
 created from GitHub will also have the packages installed in the base project 
 template.
 
-For more on using Git and GitHub in the classroom, see [here](../02-github/).
+For more on using Git and GitHub in the classroom, see [here](../github/).
 
 ## Limits
 

---FILE: website/content/infrastructure/rscloud/_index.html---
@@ -112,7 +112,7 @@ <h2>Git integration</h2>
 <p class=""caption"">Creating a new project from GitHub repository</p>
 </div>
 <p>If you have a base project template set up for your workspace, this new project created from GitHub will also have the packages installed in the base project template.</p>
-<p>For more on using Git and GitHub in the classroom, see <a href=""../02-github/"">here</a>.</p>
+<p>For more on using Git and GitHub in the classroom, see <a href=""../github/"">here</a>.</p>
 </div>
 <div id=""limits"" class=""section level2"">
 <h2>Limits</h2>",False,True,Rendering / Conversion,3
tidyverse,datascience-box,4e7e4ba77678dfcf529d4b012399be85e8dff19a,Mine Cetinkaya-Rundel,mine@stat.duke.edu,2018-08-15T16:03:45Z,Mine Cetinkaya-Rundel,mine@stat.duke.edu,2018-08-15T16:04:34Z,"Fix broken link, closes #45",website/content/20-infrastructure/01-rscloud/_index.Rmd;website/content/20-infrastructure/01-rscloud/_index.html,True,False,True,False,2,2,4,"---FILE: website/content/20-infrastructure/01-rscloud/_index.Rmd---
@@ -169,7 +169,7 @@ If you have a base project template set up for your workspace, this new project
 created from GitHub will also have the packages installed in the base project 
 template.
 
-For more on using Git and GitHub in the classroom, see [here](here).
+For more on using Git and GitHub in the classroom, see [here](../02-github/).
 
 ## Limits
 

---FILE: website/content/20-infrastructure/01-rscloud/_index.html---
@@ -112,7 +112,7 @@ <h2>Git integration</h2>
 <p class=""caption"">Creating a new project from GitHub repository</p>
 </div>
 <p>If you have a base project template set up for your workspace, this new project created from GitHub will also have the packages installed in the base project template.</p>
-<p>For more on using Git and GitHub in the classroom, see <a href=""here"" class=""uri"">here</a>.</p>
+<p>For more on using Git and GitHub in the classroom, see <a href=""../02-github/"">here</a>.</p>
 </div>
 <div id=""limits"" class=""section level2"">
 <h2>Limits</h2>",False,True,Documentation / Formatting,4
tidyverse,datascience-box,4b9c1c4ce69fd3e45b35faa237d971ea3d03ae37,Seth Russell,magic-lantern@users.noreply.github.com,2018-08-06T18:05:10Z,GitHub,noreply@github.com,2018-08-06T18:05:10Z,Spelling fixes,slides/README.md,False,False,False,False,2,2,4,"---FILE: slides/README.md---
@@ -2,7 +2,7 @@
 
 ## Outline
 
-The course is divided into three parts. Part 1 is on exloratory data analysis, part 2 is making rigorous conclusions via statistical tools like modeling and inference, and part 3 includes four topics (that could easily be swapped with others or taught in any order) that are designed to inspire studends to learn more data science and statistics.
+The course is divided into three parts. Part 1 is on exploratory data analysis, part 2 is making rigorous conclusions via statistical tools like modeling and inference, and part 3 includes four topics (that could easily be swapped with others or taught in any order) that are designed to inspire students to learn more data science and statistics.
 
 ### Part 1: Exploring data
 
@@ -37,7 +37,7 @@ The course is divided into three parts. Part 1 is on exloratory data analysis, p
 
 - p3_d01: Web scraping
 - p3_d02: Functions and automation
-- p3_d03: Interactive vidualizations with Shiny
+- p3_d03: Interactive visualizations with Shiny
 - p3_d04: Bayesian inference
 
 ## Toolkit",False,False,Documentation / Formatting,7
tidyverse,datascience-box,07904103b5ece08ffc522dc896c5e2f0c4390fe6,davidkane9,dave.kane@gmail.com,2018-08-04T12:50:05Z,GitHub,noreply@github.com,2018-08-04T12:50:05Z,typo fix,README.md,False,False,False,False,2,2,4,"---FILE: README.md---
@@ -11,7 +11,7 @@ This repository serves as a ""data science course in a box"" containing all materi
 ## Contents
 
 - `slides`: 26 `xaringan` slide decks, each to be covered roughly in a 75 minute class session
-- `assignments`: 6 homewoek assignments
+- `assignments`: 6 homework assignments
 - `labs`: 10 guided hands on exercises for students requiring minimal introduction from the instructor
 - `exams`: 2 sample take-home exams and keys
 - `project`: Final project assignment
@@ -44,4 +44,4 @@ as well.
 
 ### Tools
 
-- [ghclass](https://rundel.github.io/ghclass/) (WIP)
\ No newline at end of file
+- [ghclass](https://rundel.github.io/ghclass/) (WIP)",False,False,Documentation / Formatting,7
tidyverse,datascience-box,6feb13bf6494b41844a53c522c88d1cec48008f2,Mine Cetinkaya-Rundel,mine@stat.duke.edu,2018-06-12T08:18:35Z,Mine Cetinkaya-Rundel,mine@stat.duke.edu,2018-06-12T08:18:35Z,404 error page formatting,website/themes/hugo-theme-learn/i18n/en.toml;website/themes/hugo-theme-learn/i18n/es.toml;website/themes/hugo-theme-learn/i18n/fr.toml;website/themes/hugo-theme-learn/layouts/404.html,False,False,False,False,5,7,12,"---FILE: website/themes/hugo-theme-learn/i18n/en.toml---
@@ -8,7 +8,7 @@ other = ""Clear History""
 other = ""Attachments""
 
 [title-404]
-other = ""Error""
+other = ""404 Error""
 
 [message-404]
 other = ""Woops. Looks like this page doesn't exist ¬Ø\\_(„ÉÑ)_/¬Ø.""

---FILE: website/themes/hugo-theme-learn/i18n/es.toml---
@@ -8,7 +8,7 @@ other = ""Borrar Historial""
 other = ""Adjuntos""
 
 [title-404]
-other = ""Error""
+other = ""404 Error""
 
 [message-404]
 other = ""Ups. Parece que la p√°gina no existe ¬Ø\\_(„ÉÑ)_/¬Ø.""

---FILE: website/themes/hugo-theme-learn/i18n/fr.toml---
@@ -8,7 +8,7 @@ other = ""Supprimer l'historique""
 other = ""Pi√®ces jointes""
 
 [title-404]
-other = ""Erreur""
+other = ""404 Erreur""
 
 [message-404]
 other = ""Oups. On dirait que cette page n'existe pas ¬Ø\\_(„ÉÑ)_/¬Ø""

---FILE: website/themes/hugo-theme-learn/layouts/404.html---
@@ -44,12 +44,10 @@
       <div id=""chapter"">
         <div id=""body-inner"">
           <h1>{{T ""title-404""}}</h1>
-          <p>
-          </p>
-          <p>{{T ""message-404""}}</p>
           <p></p>
+          <p><img src=""{{ .Site.BaseURL }}/images/milu-404.png"" style=""width:50%;align:center""></img></p>
           <p><a href=""{{.Site.BaseURL}}"">{{T ""Go-to-homepage""}}</a></p>
-          <p><img src=""{{ .Site.BaseURL }}/images/milu-404.jpg"" style=""width:50%""></img></p>
+          </p>
         </div>
       </div>
 ",False,False,Rendering / Conversion,0
tidyverse,datascience-box,81706b6e338e5cf95f1b0c169d01d98729323af2,Mine Cetinkaya-Rundel,mine@stat.duke.edu,2018-05-14T03:27:21Z,Mine Cetinkaya-Rundel,mine@stat.duke.edu,2018-05-14T03:27:21Z,Typo fixes and remove task 3,assignments/hw-01/excel/~$InstructionalStaffEmployTrends.xlsx;assignments/hw-01/hw-01.Rmd,True,False,True,False,2,2,4,"---FILE: assignments/hw-01/hw-01.Rmd---
@@ -49,15 +49,15 @@ The source data can be found in the `fisheries` dataset in the **dsbox** package
 The American Association of University Professors (AAUP) is a nonprofit 
 membership association of faculty and other academic professionals. 
 [This report](https://www.aaup.org/sites/default/files/files/AAUP_Report_InstrStaff-75-11_apr2013.pdf) 
-compiled by the AAUP shows trends in instructions staff employees between 1975 
+compiled by the AAUP shows trends in instructional staff employees between 1975 
 and 2011.
 
 The following plots were produced based off the data given on the Wikipedia 
 page.
 
 ![fisheries-plot](img/inst_staff.png)
 
-The source data can be found in the `inst_staff` dataset in the **dsbox** package.
+The source data can be found in the `instructors` dataset in the **dsbox** package.
 
 ## More ugly charts
 ",False,True,Documentation / Formatting,4
