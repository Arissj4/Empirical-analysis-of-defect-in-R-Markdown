repo_owner,repo_name,commit_hash,author_name,author_email,author_date,committer_name,committer_email,committer_date,message,filenames,touches_rmd,touches_r,touches_r_or_rmd,is_merge,added,deleted,changed,diff
thaum-xyz,ankhmorpork,e4c9366c7d06d7c417fb4a3b0664cf95ee80ed0e,paulfantom,pawel@krupa.net.pl,2025-11-23T21:04:26Z,paulfantom,pawel@krupa.net.pl,2025-11-23T21:04:26Z,paperless: use image with owrkaround for s6 overlay issues,apps/paperless/manifests/backups/cronjob.yaml,False,False,False,False,1,1,2,"---FILE: apps/paperless/manifests/backups/cronjob.yaml---
@@ -63,7 +63,7 @@ spec:
                     name: paperless-secrets
                 - secretRef:
                     name: paperless-db
-              image: ghcr.io/paperless-ngx/paperless-ngx:2.18.4
+              image: ghcr.io/community-tooling/oci-images/paperless-export:1.4.0
               name: backup
               ports: []
               resources: {}"
thaum-xyz,ankhmorpork,0e949d1d799795a4b01d576b364f5742b60b0c17,paulfantom,pawel@krupa.net.pl,2025-11-21T14:11:34Z,paulfantom,pawel@krupa.net.pl,2025-11-21T14:11:34Z,versity: fix namespace setting,apps/versity-test/pvc.yaml,False,False,False,False,1,0,1,"---FILE: apps/versity-test/pvc.yaml---
@@ -19,6 +19,7 @@ apiVersion: v1
 kind: PersistentVolumeClaim
 metadata:
   name: metadata
+  namespace: versity-test
   labels:
     app.kubernetes.io/name: versitygw
     app.kubernetes.io/instance: test"
thaum-xyz,ankhmorpork,0d339d274e7ced08d8ba24143ba5a7ce84ba96aa,paulfantom,pawel@krupa.net.pl,2025-11-21T14:11:03Z,paulfantom,pawel@krupa.net.pl,2025-11-21T14:11:03Z,karakeep: fix ES version,apps/karakeep/manifests/secrets.yaml,False,False,False,False,1,1,2,"---FILE: apps/karakeep/manifests/secrets.yaml---
@@ -1,4 +1,4 @@
-apiVersion: external-secrets.io/v1beta1
+apiVersion: external-secrets.io/v1
 kind: ExternalSecret
 metadata:
   name: karakeep-secrets"
thaum-xyz,ankhmorpork,ebe8fe7ed35829212cb31410aff11c3125c019e6,paulfantom,pawel@krupa.net.pl,2025-11-21T14:04:17Z,paulfantom,pawel@krupa.net.pl,2025-11-21T14:04:17Z,flux-apps: fix versity deployment,base/flux-apps/versity-test.yaml,False,False,False,False,1,1,2,"---FILE: base/flux-apps/versity-test.yaml---
@@ -5,7 +5,7 @@ metadata:
   namespace: flux-apps
 spec:
   interval: 15m0s
-  path: ./apps/verstity-test
+  path: ./apps/versity-test
   prune: true
   sourceRef:
     kind: GitRepository"
thaum-xyz,ankhmorpork,e50c1f4391734e2fa497bcd21c870b4dc34297d1,paulfantom,pawel@krupa.net.pl,2025-10-17T09:36:12Z,paulfantom,pawel@krupa.net.pl,2025-10-17T09:36:12Z,*: fix logs in homer dashboard,apps/photos/values.yaml;apps/stirling-pdf/values.yaml,False,False,False,False,2,2,4,"---FILE: apps/photos/values.yaml---
@@ -68,7 +68,7 @@ server:
       annotations:
         cert-manager.io/cluster-issuer: letsencrypt-prod
         reloader.homer/group: Ankh Cloud
-        reloader.homer/logo: https://immich.app/img/immich-logo.svg
+        reloader.homer/logo: https://raw.githubusercontent.com/loganmarchione/homelab-svg-assets/refs/heads/main/assets/immich.svg
         reloader.homer/name: Immich
         reloader.homer/subtitle: Photo & Video Library
       labels:

---FILE: apps/stirling-pdf/values.yaml---
@@ -9,7 +9,7 @@ ingress:
   annotations:
     cert-manager.io/cluster-issuer: letsencrypt-prod
     reloader.homer/group: Ankh Cloud
-    reloader.homer/logo: https://stirlingpdf.io/favicon.svg
+    reloader.homer/logo: https://stirling.com/app/logo192.png
     reloader.homer/name: Stirling PDF
     reloader.homer/subtitle: PDF manipulation tool
   labels:"
thaum-xyz,ankhmorpork,9cab992bacdd6b2e82c5b46506d6dbc0b405760a,paulfantom,pawel@krupa.net.pl,2025-09-29T15:48:22Z,paulfantom,pawel@krupa.net.pl,2025-09-29T15:48:22Z,paperless: fix es sync issue,apps/paperless/manifests/app/databaseSecret.yaml,False,False,False,False,1,4,5,"---FILE: apps/paperless/manifests/app/databaseSecret.yaml---
@@ -11,9 +11,6 @@ spec:
     - remoteRef:
         key: PAPERLESS_DB_PASS
       secretKey: PAPERLESS_DBPASS
-    - remoteRef:
-        key: PAPERLESS_DB_USER
-      secretKey: PAPERLESS_DBUSER
   refreshInterval: 1h
   secretStoreRef:
     kind: ClusterSecretStore
@@ -28,4 +25,4 @@ spec:
         PAPERLESS_DBPASS: '{{ .PAPERLESS_DBPASS }}'
         PAPERLESS_DBPORT: ""5432""
         PAPERLESS_DBSSLMODE: prefer
-        PAPERLESS_DBUSER: '{{ .PAPERLESS_DBUSER }}'
+        PAPERLESS_DBUSER: paperless"
thaum-xyz,ankhmorpork,68dad16fa48afb7d5547f2c7c40457b09736734b,paulfantom,pawel@krupa.net.pl,2025-09-29T11:04:18Z,paulfantom,pawel@krupa.net.pl,2025-09-29T11:04:18Z,paperless: fix gotenberg config,apps/paperless/manifests/gotenberg/deployment.yaml,False,False,False,False,4,0,4,"---FILE: apps/paperless/manifests/gotenberg/deployment.yaml---
@@ -20,6 +20,10 @@ spec:
       containers:
       - name: gotenberg
         image: docker.io/gotenberg/gotenberg:8.22
+        command:
+        - ""gotenberg""
+        - ""--chromium-disable-javascript=true""
+        - ""--chromium-allow-list=file:///tmp/.*""
         ports:
         - containerPort: 3000
           name: http"
thaum-xyz,ankhmorpork,5391afdccb4d18e6d64415c81a403e538c316232,paulfantom,pawel@krupa.net.pl,2025-09-29T08:39:34Z,paulfantom,pawel@krupa.net.pl,2025-09-29T08:39:34Z,mealie: fix deployment,apps/mealie/manifests/kustomization.yaml,False,False,False,False,0,1,1,"---FILE: apps/mealie/manifests/kustomization.yaml---
@@ -3,6 +3,5 @@ kind: Kustomization
 namespace: mealie
 resources:
   - namespace.yaml
-  - tailscale-ingress.yaml
   - app/
   - db/"
thaum-xyz,ankhmorpork,997421a88f0bcda05928c66bef151d6d19dc601b,paulfantom,pawel@krupa.net.pl,2025-09-27T09:44:51Z,paulfantom,pawel@krupa.net.pl,2025-09-27T09:44:51Z,external-dns: fix fqdn templating,apps/external-dns/values.yaml,False,False,False,False,1,1,2,"---FILE: apps/external-dns/values.yaml---
@@ -16,7 +16,7 @@ serviceMonitor:
 
 extraArgs:
   - --ignore-ingress-tls-spec
-  - --fqdn-template={{.Name}}.{{.Namespace}}.ankhmorpork.thaum.xyz
+  - --fqdn-template={{`{{`}}.Name{{`}}`}}.{{`{{`}}.Namespace{{`}}`}}.ankhmorpork.thaum.xyz
   - --service-type-filter=LoadBalancer
 
 provider:"
thaum-xyz,ankhmorpork,c94299c54531d6ccb04601cc66399fdda93250d5,paulfantom,pawel@krupa.net.pl,2025-03-15T15:15:22Z,paulfantom,pawel@krupa.net.pl,2025-03-15T15:15:22Z,csi-nfs: fix chart name,base/csi-nfs/release.yaml,False,False,False,False,1,1,2,"---FILE: base/csi-nfs/release.yaml---
@@ -7,7 +7,7 @@ metadata:
 spec:
   chart:
     spec:
-      chart: csi-nfs
+      chart: csi-driver-nfs
       version: ""4.9.0""
       sourceRef:
         kind: HelmRepository"
thaum-xyz,ankhmorpork,13a9abb737101d35d5bb17b17350d8a9bf53dd48,paulfantom,pawel@krupa.net.pl,2025-03-15T15:13:14Z,paulfantom,pawel@krupa.net.pl,2025-03-15T15:13:14Z,csi-nfs: fix chart version,base/csi-nfs/release.yaml,False,False,False,False,1,1,2,"---FILE: base/csi-nfs/release.yaml---
@@ -8,7 +8,7 @@ spec:
   chart:
     spec:
       chart: csi-nfs
-      version: ""0.14.1""
+      version: ""4.9.0""
       sourceRef:
         kind: HelmRepository
         name: csi-driver-nfs"
thaum-xyz,ankhmorpork,6b3e086bc13e0d7d17c54c6d74509b4391bd8a20,paulfantom,pawel@krupa.net.pl,2025-03-04T20:04:43Z,paulfantom,pawel@krupa.net.pl,2025-03-04T20:04:43Z,paperless: fix PVC mapping,apps/paperless/manifests/web/pvcConsume.yaml,False,False,False,False,1,0,1,"---FILE: apps/paperless/manifests/web/pvcConsume.yaml---
@@ -14,3 +14,4 @@ spec:
     requests:
       storage: 15Gi
   storageClassName: manual
+  volumeName: consume"
thaum-xyz,ankhmorpork,7371d12e988414209341610eaf799e27e1deb4a3,paulfantom,pawel@krupa.net.pl,2025-02-22T14:04:24Z,paulfantom,pawel@krupa.net.pl,2025-02-22T14:04:24Z,homeassistant: fix postgres storage req,apps/homeassistant/manifests/postgres/cluster.yaml;apps/homeassistant/settings.yaml,False,False,False,False,2,2,4,"---FILE: apps/homeassistant/manifests/postgres/cluster.yaml---
@@ -41,7 +41,7 @@ spec:
       cpu: 130m
       memory: 300Mi
   storage:
-    size: 7Gi
+    size: 14Gi
     storageClass: lvm-thin
   superuserSecret:
     name: postgres-admin

---FILE: apps/homeassistant/settings.yaml---
@@ -79,7 +79,7 @@ postgres:
       cpu: 400m
       memory: 420Mi
   storage:
-    size: 7Gi
+    size: 14Gi
     storageClass: lvm-thin
 esphome:
   version: ""2024.12.4""  # application-version-from-github: esphome/esphome"
thaum-xyz,ankhmorpork,b3234fc68b7d63aee5a34f1d03c571546a1dc86c,paulfantom,pawel@krupa.net.pl,2025-02-08T14:14:50Z,paulfantom,pawel@krupa.net.pl,2025-02-08T14:14:50Z,mealie: fix ingress,apps/mealie/manifests/app/ingress.yaml,False,False,False,False,1,1,2,"---FILE: apps/mealie/manifests/app/ingress.yaml---
@@ -3,13 +3,13 @@ kind: Ingress
 metadata:
   annotations:
     cert-manager.io/cluster-issuer: letsencrypt-prod
-    probe: enabled
     probe-uri: /api/app/about
     reloader.homer/group: Ankh Cloud
     reloader.homer/logo: https://cdn.jsdelivr.net/npm/@loganmarchione/homelab-svg-assets@latest/assets/mealie.svg
     reloader.homer/name: Mealie
     reloader.homer/subtitle: Our recipes
   labels:
+    probe: enabled
     app.kubernetes.io/name: mealie
   name: mealie
 spec:"
thaum-xyz,ankhmorpork,2f749a37e24c890d6b333ad6364db00f857b4670,paulfantom,pawel@krupa.net.pl,2025-02-01T15:20:03Z,paulfantom,pawel@krupa.net.pl,2025-02-01T15:20:03Z,hack: fix perms,hack/lvm-trim.sh,False,False,False,False,0,0,0,
thaum-xyz,ankhmorpork,f46f3e45ebcda6ff35726765fa71af7c14807095,paulfantom,pawel@krupa.net.pl,2025-01-31T18:39:39Z,paulfantom,pawel@krupa.net.pl,2025-01-31T18:39:39Z,changedetection: fix helmrelease syntax,apps/changedetection/release.yaml,False,False,False,False,1,1,2,"---FILE: apps/changedetection/release.yaml---
@@ -32,7 +32,7 @@ spec:
   postRenderers:
     - kustomize:
         patches:
-          target:
+        - target:
             group: networking.k8s.io
             version: v1
             kind: Ingress"
thaum-xyz,ankhmorpork,d048029398f8745b6d9a9fed5ee18d987db002a4,paulfantom,pawel@krupa.net.pl,2025-01-31T18:37:51Z,paulfantom,pawel@krupa.net.pl,2025-01-31T18:37:51Z,longhorn: fix rule?,base/longhorn-system/prometheusrule.yaml,False,False,False,False,1,1,2,"---FILE: base/longhorn-system/prometheusrule.yaml---
@@ -54,7 +54,7 @@ spec:
         severity: warning
     - alert: LonghornVolumeOverprovisioned
       annotations:
-        description: PVC {{$labels.persistentvolumeclaim}} in namespace {{$labels.namespace}} on node {{$labels.node}} is overprovisioned by a factor of {{$value | humanize}}. Run fstrim if possible.
+        description: PVC {{$labels.persistentvolumeclaim}} in namespace {{$labels.namespace}} on node {{$labels.node}} is overprovisioned by a factor of {{$value | humanizePercentage}}. Run fstrim if possible.
         summary: Longhorn volume overprovisioned
       expr: |
         sum by (persistentvolumeclaim, namespace, node) (kubelet_volume_stats_used_bytes)"
thaum-xyz,ankhmorpork,31bd851adbbf9acaa4e69ce8b66617629f5a02eb,paulfantom,pawel@krupa.net.pl,2025-01-31T18:35:33Z,paulfantom,pawel@krupa.net.pl,2025-01-31T18:35:33Z,longhorn: fix rule?,base/longhorn-system/prometheusrule.yaml,False,False,False,False,4,2,6,"---FILE: base/longhorn-system/prometheusrule.yaml---
@@ -5,7 +5,7 @@ metadata:
   namespace: monitoring
 spec:
   groups:
-  - name: longhorn.rules
+  - name: longhorn-test.rules
     rules:
     - alert: LonghornVolumeTrimNeeded
       annotations:
@@ -26,6 +26,8 @@ spec:
       for: 2d
       labels:
         severity: warning
+  - name: longhorn.rules
+    rules:
     - alert: LonghornVolumeActualSpaceUsedWarning
       annotations:
         description: The actual space used by Longhorn volume {{$labels.volume}} on {{$labels.node}} is at {{$value}}% capacity for more than 5 minutes.
@@ -52,7 +54,7 @@ spec:
         severity: warning
     - alert: LonghornVolumeOverprovisioned
       annotations:
-        description: PVC {{$labels.persistentvolumeclaim}} in namespace {{$labels.namespace}} on node {{$labels.node}} is overprovisioned by a factor of {{$value | humanizePercent}}. Run fstrim if possible.
+        description: PVC {{$labels.persistentvolumeclaim}} in namespace {{$labels.namespace}} on node {{$labels.node}} is overprovisioned by a factor of {{$value | humanize}}. Run fstrim if possible.
         summary: Longhorn volume overprovisioned
       expr: |
         sum by (persistentvolumeclaim, namespace, node) (kubelet_volume_stats_used_bytes)"
thaum-xyz,ankhmorpork,ca52254250f253c3e8e8a7d0672261f0c181f2f6,paulfantom,pawel@krupa.net.pl,2025-01-31T18:25:44Z,paulfantom,pawel@krupa.net.pl,2025-01-31T18:25:44Z,longhorn: fix rule?,base/longhorn-system/prometheusrule.yaml,False,False,False,False,2,4,6,"---FILE: base/longhorn-system/prometheusrule.yaml---
@@ -5,7 +5,7 @@ metadata:
   namespace: monitoring
 spec:
   groups:
-  - name: longhorn-test.rules
+  - name: longhorn.rules
     rules:
     - alert: LonghornVolumeTrimNeeded
       annotations:
@@ -22,12 +22,10 @@ spec:
         )
         < 0.5
         AND
-        (kubelet_volume_stats_capacity_bytes - kubelet_volume_stats_available_bytes) > 1024*1024*1024
+        (kubelet_volume_stats_capacity_bytes - kubelet_volume_stats_available_bytes) > 1024 * 1024 * 1024
       for: 2d
       labels:
         severity: warning
-  - name: longhorn.rules
-    rules:
     - alert: LonghornVolumeActualSpaceUsedWarning
       annotations:
         description: The actual space used by Longhorn volume {{$labels.volume}} on {{$labels.node}} is at {{$value}}% capacity for more than 5 minutes."
thaum-xyz,ankhmorpork,356b8ab4ae9d7794ec8308de2dd2777d4dee654e,paulfantom,pawel@krupa.net.pl,2025-01-31T14:40:54Z,paulfantom,pawel@krupa.net.pl,2025-01-31T14:40:54Z,mealie: fix base url,apps/mealie/manifests/app/deployment.yaml,False,False,False,False,1,1,2,"---FILE: apps/mealie/manifests/app/deployment.yaml---
@@ -26,7 +26,7 @@ spec:
         - name: TZ
           value: Europe/Warsaw
         - name: BASE_URL
-          value: https://mealie.ankhmorpork.thaum.xyz
+          value: https://recipes.krupa.net.pl
         - name: DB_ENGINE
           value: postgres
         - name: POSTGRES_SERVER"
thaum-xyz,ankhmorpork,26abbc19b54ef90e1c6b991847e3bf4b335bbdd5,paulfantom,pawel@krupa.net.pl,2025-01-28T18:19:32Z,paulfantom,pawel@krupa.net.pl,2025-01-28T18:19:32Z,traefik: fix typo,base/traefik/private/values.yaml,False,False,False,False,1,1,2,"---FILE: base/traefik/private/values.yaml---
@@ -19,4 +19,4 @@ logs:
   access:
     enabled: true
     format: json
-    filePath: ""/var/log/traefik/access.log
+    filePath: ""/var/log/traefik/access.log"""
thaum-xyz,ankhmorpork,86522c2b79cc0c0b426d6e023c6e44365fdbb743,paulfantom,pawel@krupa.net.pl,2025-01-25T13:10:26Z,paulfantom,pawel@krupa.net.pl,2025-01-25T13:10:26Z,stirling-pdf: fix chart name,apps/stirling-pdf/release.yaml,False,False,False,False,1,1,2,"---FILE: apps/stirling-pdf/release.yaml---
@@ -6,7 +6,7 @@ metadata:
 spec:
   chart:
     spec:
-      chart: stirling-pdf
+      chart: stirling-pdf-chart
       version: ""1.5.0""
       sourceRef:
         kind: HelmRepository"
thaum-xyz,ankhmorpork,d9b747393f7e1df5ac54766068ee98bdc1812f25,paulfantom,pawel@krupa.net.pl,2025-01-24T12:48:35Z,paulfantom,pawel@krupa.net.pl,2025-01-24T12:48:35Z,changedetection: fix flux postRenderer,apps/changedetection/release.yaml,False,False,False,False,10,7,17,"---FILE: apps/changedetection/release.yaml---
@@ -31,10 +31,13 @@ spec:
       name: values
   postRenderers:
     - kustomize:
-        patchesStrategicMerge:
-          - kind: Ingress
-            apiVersion: networking.k8s.io/v1
-            metadata:
-              name: changedetection
-              labels:
-                reloader.homer/enabled: ""true""
+        patches:
+          target:
+            group: networking.k8s.io
+            version: v1
+            kind: Ingress
+            name: changedetection
+          patch: |-
+            - op: add
+              path: /metadata/labels/reloader.homer~1enabled
+              value: ""true"""
thaum-xyz,ankhmorpork,900c95cdda2409dbfc63384d04d20cb1cae1a301,paulfantom,pawel@krupa.net.pl,2025-01-07T18:54:37Z,paulfantom,pawel@krupa.net.pl,2025-01-07T18:54:37Z,fix renovate config,.github/renovate.json,False,False,False,False,4,4,8,"---FILE: .github/renovate.json---
@@ -45,7 +45,7 @@
   ""packageRules"": [
     {
       ""addLabels"": [
-        ""dependensies/ci""
+        ""dependencies/ci""
       ],
       ""groupName"": ""github actions"",
       ""matchFileNames"": [
@@ -55,7 +55,7 @@
     },
     {
       ""addLabels"": [
-        ""dependensies/hosting""
+        ""dependencies/hosting""
       ],
       ""groupName"": ""hosting infrastructure"",
       ""matchFileNames"": [
@@ -64,7 +64,7 @@
     },
     {
       ""addLabels"": [
-        ""dependensies/base""
+        ""dependencies/base""
       ],
       ""groupName"": ""hosting infrastructure"",
       ""matchFileNames"": [
@@ -75,7 +75,7 @@
     },
     {
       ""addLabels"": [
-        ""dependensies/apps""
+        ""dependencies/apps""
       ],
       ""groupName"": ""applications"",
       ""matchFileNames"": ["
thaum-xyz,ankhmorpork,9e4e59457dabe4690f4ebcf0a8ff247f4387d9d5,paulfantom,pawel@krupa.net.pl,2024-12-01T17:07:48Z,paulfantom,pawel@krupa.net.pl,2024-12-01T17:07:48Z,minio: fix alert defs,apps/minio/prometheus-rules.yaml,False,False,False,False,2,2,4,"---FILE: apps/minio/prometheus-rules.yaml---
@@ -14,7 +14,7 @@ spec:
   - name: minio-alerts
     rules:
     - alert: MinioNodesOffline
-      expr: sum(minio_cluster_nodes_offline_total{namespace=""minio""}[5m]) > 0
+      expr: sum(minio_cluster_nodes_offline_total{namespace=""minio""}) > 0
       for: 10m
       labels:
         severity: warning
@@ -23,7 +23,7 @@ spec:
         description: ""Minio cluster {{ $labels.instance }} has {{ $value }} node(s) offline for more than 5 minutes""
 
     - alert: MinioDisksOffline
-      expr: sum(minio_cluster_disk_offline_total{namespace=""minio""}[5m]) > 0
+      expr: sum(minio_cluster_disk_offline_total{namespace=""minio""}) > 0
       for: 10m
       labels:
         severity: warning"
thaum-xyz,ankhmorpork,f5b2703742b51eef47659be450c71b80a68f7570,paulfantom,pawel@krupa.net.pl,2024-12-01T14:16:01Z,paulfantom,pawel@krupa.net.pl,2024-12-01T14:16:01Z,monitoring: fix cluster latency SLO data,apps/monitoring/manifests/pyrra/slo-apiserver-read-cluster-latency.yaml;apps/monitoring/manifests/pyrra/slo-apiserver-read-namespace-latency.yaml,False,False,False,False,2,2,4,"---FILE: apps/monitoring/manifests/pyrra/slo-apiserver-read-cluster-latency.yaml---
@@ -11,7 +11,7 @@ spec:
   indicator:
     latency:
       success:
-        metric: apiserver_request_duration_seconds_bucket{component=""apiserver"",scope=~""cluster|"",verb=~""LIST|GET"",le=""5""}
+        metric: apiserver_request_duration_seconds_bucket{component=""apiserver"",scope=~""cluster|"",verb=~""LIST|GET"",le=""1.5""}
       total:
         metric: apiserver_request_duration_seconds_count{component=""apiserver"",scope=~""cluster|"",verb=~""LIST|GET""}
   target: ""99""

---FILE: apps/monitoring/manifests/pyrra/slo-apiserver-read-namespace-latency.yaml---
@@ -11,7 +11,7 @@ spec:
   indicator:
     latency:
       success:
-        metric: apiserver_request_duration_seconds_bucket{component=""apiserver"",scope=~""namespace|"",verb=~""LIST|GET"",le=""5""}
+        metric: apiserver_request_duration_seconds_bucket{component=""apiserver"",scope=~""namespace|"",verb=~""LIST|GET"",le=""1.5""}
       total:
         metric: apiserver_request_duration_seconds_count{component=""apiserver"",scope=~""namespace|"",verb=~""LIST|GET""}
   target: ""99"""
thaum-xyz,ankhmorpork,b211ecc8a3cac23d8535eead44277876fd3ca8aa,paulfantom,pawel@krupa.net.pl,2024-12-01T14:09:04Z,paulfantom,pawel@krupa.net.pl,2024-12-01T14:09:04Z,minio: fix alert expressions. closes #346,apps/minio/prometheus-rules.yaml,False,False,False,False,6,6,12,"---FILE: apps/minio/prometheus-rules.yaml---
@@ -14,22 +14,22 @@ spec:
   - name: minio-alerts
     rules:
     - alert: MinioNodesOffline
-      expr: avg_over_time(minio_cluster_nodes_offline_total{namespace=""minio""}[5m]) > 0
+      expr: sum(minio_cluster_nodes_offline_total{namespace=""minio""}[5m]) > 0
       for: 10m
       labels:
         severity: warning
       annotations:
         summary: ""Node down in MinIO deployment""
-        description: ""Node(s) in cluster {{ $labels.instance }} offline for more than 5 minutes""
+        description: ""Minio cluster {{ $labels.instance }} has {{ $value }} node(s) offline for more than 5 minutes""
 
     - alert: MinioDisksOffline
-      expr: avg_over_time(minio_cluster_disk_offline_total{namespace=""minio""}[5m]) > 0
+      expr: sum(minio_cluster_disk_offline_total{namespace=""minio""}[5m]) > 0
       for: 10m
       labels:
         severity: warning
       annotations:
         summary: ""Disks down in MinIO deployment""
-        description: ""Disks(s) in cluster {{ $labels.instance }} offline for more than 5 minutes""
+        description: ""Minio cluster {{ $labels.instance }} has {{ $value }} disks offline for more than 5 minutes""
 
     - alert: MinioClusterAlmostOutOfSpace
       expr:  (minio_cluster_capacity_usable_free_bytes:sum / minio_cluster_capacity_usable_total_bytes:sum * 100 < 3)
@@ -47,7 +47,7 @@ spec:
       annotations:
         summary: ""MinIO cluster has less than 5% space left.""
         description: 'MinIO cluster {{ $labels.instance }} has only {{ printf ""%.2f"" $value }}% available space left.'
-    
+
     - alert: MinioClusterSpaceFillingUp
       expr: |
         minio_cluster_capacity_usable_free_bytes:sum
@@ -77,4 +77,4 @@ spec:
         severity: warning
       annotations:
         summary: ""MinIO cluster is predicted to run out of space within the next 24 hours.""
-        description: 'MinIO cluster {{ $labels.instance }} is filling up. Only {{ printf ""%.2f"" $value }}% available space left and is filling up.'
\ No newline at end of file
+        description: 'MinIO cluster {{ $labels.instance }} is filling up. Only {{ printf ""%.2f"" $value }}% available space left and is filling up.'"
thaum-xyz,ankhmorpork,ecc65dd6c2a537f83be0ad2b8d38c84308942af0,paulfantom,pawel@krupa.net.pl,2024-11-30T18:49:52Z,paulfantom,pawel@krupa.net.pl,2024-11-30T18:49:52Z,external-dns: fix port problems with adguard webhook,apps/external-dns/values.yaml,False,False,False,False,1,13,14,"---FILE: apps/external-dns/values.yaml---
@@ -33,20 +33,8 @@ sidecars:
   - name: adguard-webhook
     image: ghcr.io/muhlba91/external-dns-provider-adguard:v8.0.0
     ports:
-      - containerPort: 8888
+      - containerPort: 8080
         name: http
-    livenessProbe:
-      httpGet:
-        path: /healthz
-        port: http
-      initialDelaySeconds: 10
-      timeoutSeconds: 5
-    readinessProbe:
-      httpGet:
-        path: /healthz
-        port: http
-      initialDelaySeconds: 10
-      timeoutSeconds: 5
     env:
       - name: LOG_LEVEL
         value: debug"
thaum-xyz,ankhmorpork,07e1c4c2ad47ac4d2c9b8ceb7a90210818d35fcb,paulfantom,pawel@krupa.net.pl,2024-11-30T18:19:04Z,paulfantom,pawel@krupa.net.pl,2024-11-30T18:19:04Z,multimedia: fix transmission ingress,apps/multimedia/manifests/transmission/ingress.yaml,False,False,False,False,1,1,2,"---FILE: apps/multimedia/manifests/transmission/ingress.yaml---
@@ -8,9 +8,9 @@ metadata:
     reloader.homer/name: Transmission
     reloader.homer/subtitle: Downloader
     reloader.homer/tag: local
+    traefik.http.middlewares.add-foo.addprefix.prefix: ""/transmission/web""
   labels:
     reloader.homer/enabled: ""true""
-    traefik.http.middlewares.add-foo.addprefix.prefix: ""/transmission/web""
   name: downloader
   namespace: multimedia
 spec:"
thaum-xyz,ankhmorpork,566fa0b7f40880093bd5ba61b5395b9c1da48ce2,paulfantom,pawel@krupa.net.pl,2024-11-30T17:32:41Z,paulfantom,pawel@krupa.net.pl,2024-11-30T17:32:41Z,homer: bump reloader version with fixes from https://github.com/paulfantom/homer-reloader/pull/2,apps/homer/manifests/reloader/deployment.yaml,False,False,False,False,1,1,2,"---FILE: apps/homer/manifests/reloader/deployment.yaml---
@@ -28,7 +28,7 @@ spec:
               valueFrom:
                 fieldRef:
                   fieldPath: metadata.namespace
-          image: ghcr.io/paulfantom/homer-reloader:0.0.11 # {""$imagepolicy"": ""homer:reloader""}
+          image: ghcr.io/paulfantom/homer-reloader:0.0.12 # {""$imagepolicy"": ""homer:reloader""}
           name: reloader
           ports:
             - containerPort: 9333"
thaum-xyz,ankhmorpork,d1391da3c1ef74ed53ed50c2d019326db18a8b41,paulfantom,pawel@krupa.net.pl,2024-11-30T13:30:16Z,paulfantom,pawel@krupa.net.pl,2024-11-30T13:30:16Z,changedetection: minor fixes,apps/changedetection/values.yaml,False,False,False,False,2,0,2,"---FILE: apps/changedetection/values.yaml---
@@ -24,6 +24,7 @@ ingress:
 
 env:
   simple:
+    BASE_URL: https://change.ankhmorpork.thaum.xyz
     PLAYWRIGHT_DRIVER_URL: ""ws://playwright:3000/?stealth=1&--disable-web-security=true""
 
 resources:
@@ -37,3 +38,4 @@ resources:
 persistence:
   storageClass: ""longhorn-r2""
   size: 1Gi
+  accessMode: ReadWriteMany"
thaum-xyz,ankhmorpork,f9ba3ad417891f993ee7d18f3aa1934dc4378cc0,paulfantom,pawel@krupa.net.pl,2024-11-29T17:17:20Z,paulfantom,pawel@krupa.net.pl,2024-11-29T17:17:20Z,homeassistant: fix passing payload to awtrix,apps/homeassistant/config/configuration.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,5,5,10,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -295,12 +295,12 @@ rest_command:
   awtrix_notify:
     url: ""http://192.168.2.219/api/notify""
     method: ""post""
-    payload: ""{{ states('input_text.awtrix_custom_payload') }}""
+    payload: ""{{ payload }}""
     content_type: ""application/json""
   awtrix_app:
     url: ""http://192.168.2.219/api/custom""
     method: ""post""
-    payload: ""{{ states('input_text.awtrix_custom_payload') }}""
+    payload: ""{{ payload }}""
     content_type: ""application/json""
 
 cover:

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -298,12 +298,12 @@ data:
       awtrix_notify:
         url: ""http://192.168.2.219/api/notify""
         method: ""post""
-        payload: ""{{ states('input_text.awtrix_custom_payload') }}""
+        payload: ""{{ payload }}""
         content_type: ""application/json""
       awtrix_app:
         url: ""http://192.168.2.219/api/custom""
         method: ""post""
-        payload: ""{{ states('input_text.awtrix_custom_payload') }}""
+        payload: ""{{ payload }}""
         content_type: ""application/json""
 
     cover:

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: 2112b0a1cd63e42240a7d16aeac52a34
+        checksum.config/md5: 7cd1af157058537785f7daa44b436e55
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,4379e179057bd0442bb80650fe6ed8fcb064deb4,paulfantom,pawel@krupa.net.pl,2024-11-23T13:30:35Z,paulfantom,pawel@krupa.net.pl,2024-11-23T13:30:35Z,npd: fix?,base/node-problem-detector/values.yaml,False,False,False,False,1,37,38,"---FILE: base/node-problem-detector/values.yaml---
@@ -24,40 +24,4 @@ settings:
   log_monitors:
     - /config/kernel-monitor.json
     - /config/readonly-monitor.json
-    - /custom-config/health-checker-containerd.json
-
-  custom_monitor_definitions:
-    health-checker-containerd.json: |
-      {
-        ""plugin"": ""custom"",
-        ""pluginConfig"": {
-          ""invoke_interval"": ""10s"",
-          ""timeout"": ""3m"",
-          ""max_output_length"": ""80"",
-          ""concurrency"": ""1""
-        },
-        ""source"": ""health-checker"",
-        ""metricsReporting"": true,
-        ""conditions"": [
-          {
-            ""type"": ""ContainerRuntimeUnhealthy"",
-            ""reason"": ""ContainerRuntimeIsHealthy"",
-            ""message"": ""Container runtime on the node is functioning properly""
-          }
-        ],
-        ""rules"": [
-          {
-            ""type"": ""permanent"",
-            ""condition"": ""ContainerRuntimeUnhealthy"",
-            ""reason"": ""ContainerdUnhealthy"",
-            ""path"": ""/home/kubernetes/bin/health-checker"",
-            ""args"": [
-              ""--component=cri"",
-              ""--enable-repair=true"",
-              ""--cooldown-time=2m"",
-              ""--health-check-timeout=60s""
-            ],
-            ""timeout"": ""3m""
-          }
-        ]
-      }
+    - /config/health-checker-containerd.json"
thaum-xyz,ankhmorpork,3bc30bfe6e689092996ed6857fd03cf98fcd6243,paulfantom,pawel@krupa.net.pl,2024-11-22T14:59:06Z,paulfantom,pawel@krupa.net.pl,2024-11-22T14:59:06Z,npd: fix repo type,base/node-problem-detector/repository.yaml,False,False,False,False,1,1,2,"---FILE: base/node-problem-detector/repository.yaml---
@@ -5,5 +5,5 @@ metadata:
   namespace: node-problem-detector
 spec:
   interval: 5m
-  oci: true
+  type: oci
   url: oci://ghcr.io/deliveryhero/helm-charts"
thaum-xyz,ankhmorpork,85775c2736bc180589a3e2fc62b4538083baa6b2,paulfantom,pawel@krupa.net.pl,2024-11-22T12:43:06Z,paulfantom,pawel@krupa.net.pl,2024-11-22T12:43:21Z,"npd: test a solution to a bug in npd

Signed-off-by: paulfantom <pawel@krupa.net.pl>",base/node-problem-detector/repository.yaml;base/node-problem-detector/values.yaml,False,False,False,False,43,2,45,"---FILE: base/node-problem-detector/repository.yaml---
@@ -5,4 +5,5 @@ metadata:
   namespace: node-problem-detector
 spec:
   interval: 5m
-  url: https://charts.deliveryhero.io/
+  oci: true
+  url: oci://ghcr.io/deliveryhero/helm-charts

---FILE: base/node-problem-detector/values.yaml---
@@ -20,7 +20,47 @@ resources:
     memory: 18Mi
 
 settings:
+  #log_monitors:
+  #  - /config/kernel-monitor.json
+  #  - /config/readonly-monitor.json
+  #  - /config/health-checker-containerd.json
   log_monitors:
     - /config/kernel-monitor.json
     - /config/readonly-monitor.json
-    - /config/health-checker-containerd.json
+    - /custom-config/health-checker-containerd.json
+
+  custom_monitor_definitions:
+    health-checker-containerd.json: |
+      {
+        ""plugin"": ""custom"",
+        ""pluginConfig"": {
+          ""invoke_interval"": ""10s"",
+          ""timeout"": ""3m"",
+          ""max_output_length"": ""80"",
+          ""concurrency"": ""1""
+        },
+        ""source"": ""health-checker"",
+        ""metricsReporting"": true,
+        ""conditions"": [
+          {
+            ""type"": ""ContainerRuntimeUnhealthy"",
+            ""reason"": ""ContainerRuntimeIsHealthy"",
+            ""message"": ""Container runtime on the node is functioning properly""
+          }
+        ],
+        ""rules"": [
+          {
+            ""type"": ""permanent"",
+            ""condition"": ""ContainerRuntimeUnhealthy"",
+            ""reason"": ""ContainerdUnhealthy"",
+            ""path"": ""/home/kubernetes/bin/health-checker"",
+            ""args"": [
+              ""--component=cri"",
+              ""--enable-repair=true"",
+              ""--cooldown-time=2m"",
+              ""--health-check-timeout=60s""
+            ],
+            ""timeout"": ""3m""
+          }
+        ]
+      }"
thaum-xyz,ankhmorpork,b964196789394ab3add91ef16cd82e17f401a933,paulfantom,pawel@krupa.net.pl,2024-11-16T16:41:06Z,paulfantom,pawel@krupa.net.pl,2024-11-16T16:41:06Z,kured: fix days,apps/system-kured/values.yaml,False,False,False,False,4,1,5,"---FILE: apps/system-kured/values.yaml---
@@ -6,7 +6,10 @@ configuration:
   # Abort drain after this time
   drainTimeout: ""2h""
   period: ""2h""
-  rebootDays: ""mo,we,th""
+  rebootDays:
+  - mo
+  - we
+  - th
   startTime: ""07:00:00""
   endTime: ""12:00:00""
   lockReleaseDelay: ""1h"""
thaum-xyz,ankhmorpork,98b3b1df45779d74b475743cee1fbfe72daf1fcf,paulfantom,pawel@krupa.net.pl,2024-11-16T16:40:18Z,paulfantom,pawel@krupa.net.pl,2024-11-16T16:40:18Z,kured: fix chart version,apps/system-kured/release.yaml,False,False,False,False,1,1,2,"---FILE: apps/system-kured/release.yaml---
@@ -7,7 +7,7 @@ spec:
   chart:
     spec:
       chart: kured
-      version: ""15.8.1""
+      version: ""5.5.0""
       sourceRef:
         kind: HelmRepository
         name: kured"
thaum-xyz,ankhmorpork,5e0f6fcbfb8816dcf90f6b215416c8bc309fef08,paulfantom,pawel@krupa.net.pl,2024-11-16T16:20:28Z,paulfantom,pawel@krupa.net.pl,2024-11-16T16:20:28Z,datalake-metrics: fix image name,apps/datalake-metrics/values.yaml,False,False,False,False,1,1,2,"---FILE: apps/datalake-metrics/values.yaml---
@@ -2,7 +2,7 @@
 
 image:
   registry: quay.io
-  repository: thanos
+  repository: thanos/thanos
   tag: v0.36.1
 
 existingObjstoreSecret: thanos-objectstorage"
thaum-xyz,ankhmorpork,c531c3dfdfa68533d2dc151ba7b34f88765eb270,paulfantom,pawel@krupa.net.pl,2024-11-16T16:19:20Z,paulfantom,pawel@krupa.net.pl,2024-11-16T16:19:20Z,datalake-metrics: fix namespace,apps/datalake-metrics/kustomization.yaml,False,False,False,False,1,1,2,"---FILE: apps/datalake-metrics/kustomization.yaml---
@@ -1,6 +1,6 @@
 apiVersion: kustomize.config.k8s.io/v1beta1
 kind: Kustomization
-namespace: minio
+namespace: datalake-metrics
 resources:
   - repository.yaml
   - release.yaml"
thaum-xyz,ankhmorpork,2be07bf75ae3f2a7c0ed5b8f81b297f55e85b021,paulfantom,pawel@krupa.net.pl,2024-11-16T16:18:41Z,paulfantom,pawel@krupa.net.pl,2024-11-16T16:18:41Z,datalake-metrics: fix location,base/flux-apps/datalake-metrics.yaml,False,False,False,False,1,2,3,"---FILE: base/flux-apps/datalake-metrics.yaml---
@@ -5,11 +5,10 @@ metadata:
   namespace: flux-apps
 spec:
   interval: 5m0s
-  path: ./apps/datalake-metrics/manifests
+  path: ./apps/datalake-metrics
   prune: true
   force: true
   suspend: false
   sourceRef:
     kind: GitRepository
     name: ankhmorpork
-"
thaum-xyz,ankhmorpork,f728ec368876ce205780017614aa988540c264ac,paulfantom,pawel@krupa.net.pl,2024-11-16T16:16:59Z,paulfantom,pawel@krupa.net.pl,2024-11-16T16:16:59Z,datalake-metrics: fix SC used by receive,apps/datalake-metrics/values.yaml,False,False,False,False,1,1,2,"---FILE: apps/datalake-metrics/values.yaml---
@@ -136,7 +136,7 @@ receive:
       - thanos-receive-2.thanos-receive-headless.datalake-metrics.svc.cluster.local:10901
 
   persistence:
-    storageClass: lvm
+    storageClass: lvm-thin
     size: 35Gi
 
 #receiveDistributor:"
thaum-xyz,ankhmorpork,60899edf2afbc5a4ddd5db261e0f5e05b6af3cc2,paulfantom,pawel@krupa.net.pl,2024-11-16T15:22:35Z,paulfantom,pawel@krupa.net.pl,2024-11-16T15:22:35Z,datalake-metrics: fix thanos image ref,apps/datalake-metrics/manifests/values.yaml,False,False,False,False,2,2,4,"---FILE: apps/datalake-metrics/manifests/values.yaml---
@@ -7,9 +7,9 @@ data:
   values.yaml: |-
     image:
       registry: quay.io
-      repository: thanos
+      repository: thanos/thanos
       tag: v0.36.1
-  
+
     existingObjstoreSecret: thanos-objectstorage
 
     minio:"
thaum-xyz,ankhmorpork,1cbf7e68af64636cdf7c463988776c71cab98302,paulfantom,pawel@krupa.net.pl,2024-11-12T20:05:01Z,paulfantom,pawel@krupa.net.pl,2024-11-12T20:05:01Z,photos: fix immich metrics gathering,apps/photos/release.yaml;apps/photos/values.yaml,False,False,False,False,1,2,3,"---FILE: apps/photos/release.yaml---
@@ -7,7 +7,7 @@ spec:
   chart:
     spec:
       chart: immich
-      version: ""0.8.2""
+      version: ""0.8.4""
       sourceRef:
         kind: HelmRepository
         name: immich

---FILE: apps/photos/values.yaml---
@@ -18,7 +18,6 @@ env:
         name: postgres-user
         key: password
   DB_DATABASE_NAME: ""immich""
-  IMMICH_METRICS: ""true""  # FIXME: most likely not needed since immich.metrics.enabled is set to true. Left here until chart 0.6.0+ is released
   IMMICH_MACHINE_LEARNING_URL: '{{ printf ""http://%s-machine-learning:3003"" .Release.Name }}'
 
 immich:"
thaum-xyz,ankhmorpork,bc032234ea815b2e4ef41c4569858e63bb66cbc9,paulfantom,pawel@krupa.net.pl,2024-11-12T19:40:55Z,paulfantom,pawel@krupa.net.pl,2024-11-12T19:40:55Z,monitoring: fix typo,apps/monitoring/config.jsonnet;apps/monitoring/manifests/blackboxExporter/ingressProbe.yaml,False,False,False,False,2,2,4,"---FILE: apps/monitoring/config.jsonnet---
@@ -123,7 +123,7 @@
             {
               action: 'replace',
               regex: '(.+);(.+);(.+)',
-              replacement: '${1}://${2}${3}""',
+              replacement: '${1}://${2}${3}',
               separator: ';',
               sourceLabels: [
                 '__meta_kubernetes_ingress_scheme',

---FILE: apps/monitoring/manifests/blackboxExporter/ingressProbe.yaml---
@@ -21,7 +21,7 @@ spec:
       relabelingConfigs:
         - action: replace
           regex: (.+);(.+);(.+)
-          replacement: ${1}://${2}${3}""
+          replacement: ${1}://${2}${3}
           separator: ;
           sourceLabels:
             - __meta_kubernetes_ingress_scheme"
thaum-xyz,ankhmorpork,31b8853a6f3a8efa5568043ac24dcec000b16612,paulfantom,pawel@krupa.net.pl,2024-10-22T12:38:56Z,paulfantom,pawel@krupa.net.pl,2024-10-22T12:38:56Z,paperless: fix permission issues,apps/paperless/jsonnet/main.jsonnet;apps/paperless/manifests/web/cronjob.yaml,False,False,False,False,32,0,32,"---FILE: apps/paperless/jsonnet/main.jsonnet---
@@ -10,6 +10,28 @@ local config = std.parseYaml(configYAML)[0];
 
 local all = {
   web: paperless(config.paperless) + {
+    cronjob+: {
+      spec+: {
+        jobTemplate+: {
+          spec+: {
+            template+: {
+              spec+: {
+                initContainers: [{
+                  // init container to change permissions on the backup directory to 0777 due to bug in longhorn RWX support
+                  command: ['sh', '-c', 'chmod 0777 /mnt/backups'],
+                  image: 'busybox',
+                  name: 'permissions',
+                  volumeMounts: [{
+                    mountPath: '/mnt/backups',
+                    name: 'backups',
+                  }],
+                }],
+              },
+            },
+          },
+        },
+      },
+    },
     database+:: {},
     databaseSecret: externalsecret(
       $.web.database.metadata,

---FILE: apps/paperless/manifests/web/cronjob.yaml---
@@ -59,6 +59,16 @@ spec:
                   name: consume
                 - mountPath: /mnt/backups
                   name: backups
+          initContainers:
+            - command:
+                - sh
+                - -c
+                - chmod 0777 /mnt/backups
+              image: busybox
+              name: permissions
+              volumeMounts:
+                - mountPath: /mnt/backups
+                  name: backups
           restartPolicy: Never
           serviceAccountName: paperless
           volumes:"
thaum-xyz,ankhmorpork,9affc2611dff41f141f20e02d844ab84fd4ab8de,paulfantom,pawel@krupa.net.pl,2024-10-20T14:09:42Z,paulfantom,pawel@krupa.net.pl,2024-10-20T14:09:42Z,promtail: fix typo,apps/promtail/values.yaml,False,False,False,False,1,1,2,"---FILE: apps/promtail/values.yaml---
@@ -26,7 +26,7 @@ extraPorts:
     containerPort: 1514
     protocol: TCP
     service:
-      type: Loadbalancer
+      type: LoadBalancer
       port: 1514
       loadBalancerIP: 192.168.2.82
 "
thaum-xyz,ankhmorpork,3852c935a88b1edbce93b85297a8e8af33ef6d3a,paulfantom,pawel@krupa.net.pl,2024-10-20T14:09:04Z,paulfantom,pawel@krupa.net.pl,2024-10-20T14:09:04Z,promtail: fix indentation,apps/promtail/values.yaml,False,False,False,False,12,11,23,"---FILE: apps/promtail/values.yaml---
@@ -37,14 +37,15 @@ config:
     - url: http://loki-write.datalake-logs.svc:3100/loki/api/v1/push
       external_labels:
         cluster: ankhmorpork
-  extraScrapeConfigs: |
-    - job_name: syslog
-      syslog:
-        listen_address: 0.0.0.0:1514
-        idle_timeout: 60s
-        label_structured_data: yes
-        labels:
-          job: ""syslog""
-      relabel_configs:
-        - source_labels: ['__syslog_message_hostname']
-          target_label: 'host'
+  snippets:
+    extraScrapeConfigs: |
+      - job_name: syslog
+        syslog:
+          listen_address: 0.0.0.0:1514
+          idle_timeout: 60s
+          label_structured_data: yes
+          labels:
+            job: ""syslog""
+        relabel_configs:
+          - source_labels: ['__syslog_message_hostname']
+            target_label: 'host'"
thaum-xyz,ankhmorpork,0f6dfdb9f43a8b203e1cfe5cf22da8a8bc418ba7,paulfantom,pawel@krupa.net.pl,2024-10-15T18:07:00Z,paulfantom,pawel@krupa.net.pl,2024-10-15T18:07:00Z,homeassistant: fix config,apps/homeassistant/config/configuration.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,3,3,6,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -184,7 +184,7 @@ sensor:
 rest:
   - resource: http://192.168.2.3/sql_handle.php?type=status_layout
     scan_interval: 15
-    sensors:
+    sensor:
       - name: ""PDU Amperage""
         unique_id: ""pdu_amperage""
         value_template: ""{{ value.split(',')[0] | float / 10 }}""

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -187,7 +187,7 @@ data:
     rest:
       - resource: http://192.168.2.3/sql_handle.php?type=status_layout
         scan_interval: 15
-        sensors:
+        sensor:
           - name: ""PDU Amperage""
             unique_id: ""pdu_amperage""
             value_template: ""{{ value.split(',')[0] | float / 10 }}""

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: d9102db2e6c2df4106c4a61e7caca582
+        checksum.config/md5: 7b2c73a85568fdd1d3a544670e8796d5
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,8c4bf3f12b6dc0d9e2365cadd81c84f698194528,paulfantom,pawel@krupa.net.pl,2024-10-11T15:21:28Z,paulfantom,pawel@krupa.net.pl,2024-10-11T15:21:28Z,kube-system/cilium: work around issues with schema validation,base/kube-system/manifests/cilium/values.yaml,False,False,False,False,5,5,10,"---FILE: base/kube-system/manifests/cilium/values.yaml---
@@ -35,8 +35,8 @@ prometheus:
   serviceMonitor:
     enabled: true
 
-hubble:
-  metrics:
-    enabled: true
-    serviceMonitor:
-      enabled: false
+#hubble:
+#  metrics:
+#    enabled: true
+#    serviceMonitor:
+#      enabled: false"
thaum-xyz,ankhmorpork,59d142494aa7a9d86876498a652a9db2cdd49998,paulfantom,pawel@krupa.net.pl,2024-10-04T20:27:02Z,paulfantom,pawel@krupa.net.pl,2024-10-04T20:27:02Z,monitoring/goldpinger: fix deployment,apps/monitoring/manifests/goldpinger/clusterrole.yaml;apps/monitoring/manifests/goldpinger/clusterrolebinding.yaml;apps/monitoring/manifests/goldpinger/config.yaml;apps/monitoring/manifests/goldpinger/daemonset.yaml;apps/monitoring/manifests/goldpinger/service.yaml,False,False,False,False,21,47,68,"---FILE: apps/monitoring/manifests/goldpinger/clusterrole.yaml---
@@ -8,4 +8,7 @@ metadata:
 rules:
   - apiGroups: [""""]
     resources: [""pods""]
+    verbs: [""get"", ""list""]
+  - apiGroups: [""""]
+    resources: [""nodes""]
     verbs: [""list""]

---FILE: apps/monitoring/manifests/goldpinger/clusterrolebinding.yaml---
@@ -10,4 +10,4 @@ roleRef:
 subjects:
   - kind: ServiceAccount
     name: goldpinger-serviceaccount
-    namespace: goldpinger
+    namespace: monitoring

---FILE: apps/monitoring/manifests/goldpinger/config.yaml---
@@ -1,30 +0,0 @@
-apiVersion: v1
-kind: ConfigMap
-metadata:
-  name: goldpinger-zap
-  labels:
-    app: goldpinger
-    app.kubernetes.io/name: goldpinger
-data:
-  zap.json: |
-    {
-      ""level"": ""debug"",
-      ""encoding"": ""json"",
-      ""outputPaths"": [
-          ""stdout""
-      ],
-      ""errorOutputPaths"": [
-          ""stderr""
-      ],
-      ""initialFields"": {
-      },
-      ""encoderConfig"": {
-          ""messageKey"": ""message"",
-          ""levelKey"": ""level"",
-          ""levelEncoder"": ""lowercase"",
-          ""timeKey"": ""ts"",
-          ""timeEncoder"": ""ISO8601"",
-          ""callerKey"": ""caller"",
-          ""callerEncoder"": ""Short""
-      }
-    }

---FILE: apps/monitoring/manifests/goldpinger/daemonset.yaml---
@@ -16,9 +16,6 @@ spec:
       app.kubernetes.io/name: goldpinger
   template:
     metadata:
-      annotations:
-        prometheus.io/scrape: 'true'
-        prometheus.io/port: '8080'
       labels:
         app: goldpinger
         app.kubernetes.io/name: goldpinger
@@ -40,21 +37,32 @@ spec:
               valueFrom:
                 fieldRef:
                   fieldPath: spec.nodeName
-            # podIP is used to select a randomized subset of nodes to ping.
             - name: POD_IP
               valueFrom:
                 fieldRef:
                   fieldPath: status.podIP
+            - name: POD_NAME
+              valueFrom:
+                fieldRef:
+                  fieldPath: metadata.name
             - name: LABEL_SELECTOR
               value: ""app.kubernetes.io/name=goldpinger""
+            - name: DISPLAY_NODENAME
+              value: ""true""
+            #- name: HOSTS_TO_RESOLVE
+            #  value: ""www.google.com""
+            - name: REFRESH_INTERVAL
+              value: ""10""
+            - name: HTTP_TARGETS
+              value: ""http://www.google.com""
           image: ""docker.io/bloomberg/goldpinger:3.10.1""
           imagePullPolicy: Always
           securityContext:
             allowPrivilegeEscalation: false
             readOnlyRootFilesystem: true
           resources:
-            limits:
-              memory: 80Mi
+            #limits:
+            #  memory: 80Mi
             requests:
               cpu: 1m
               memory: 40Mi
@@ -64,19 +72,12 @@ spec:
           readinessProbe:
             httpGet:
               path: /healthz
-              port: 8080
+              port: http
             initialDelaySeconds: 20
             periodSeconds: 5
           livenessProbe:
             httpGet:
               path: /healthz
-              port: 8080
+              port: http
             initialDelaySeconds: 20
             periodSeconds: 5
-          volumeMounts:
-            - name: zap
-              mountPath: /config
-      volumes:
-        - name: zap
-          configMap:
-            name: goldpinger-zap

---FILE: apps/monitoring/manifests/goldpinger/service.yaml---
@@ -10,7 +10,7 @@ metadata:
 spec:
   ports:
     - port: 8080
-      targetPort: 8080
+      targetPort: http
       name: http
   selector:
     app: goldpinger"
thaum-xyz,ankhmorpork,17d4d45a63e94b8d9a09f90d52457c853f825643,paulfantom,pawel@krupa.net.pl,2024-10-04T15:10:22Z,paulfantom,pawel@krupa.net.pl,2024-10-04T15:10:22Z,monitoring/goldpinger: fixes,apps/monitoring/manifests/goldpinger/daemonset.yaml,False,False,False,False,3,1,4,"---FILE: apps/monitoring/manifests/goldpinger/daemonset.yaml---
@@ -48,7 +48,9 @@ spec:
               valueFrom:
                 fieldRef:
                   fieldPath: status.podIP
-          image: ""docker.io/bloomberg/goldpinger:v3.10.1""
+            - name: LABEL_SELECTOR
+              value: ""app.kubernetes.io/name=goldpinger""
+          image: ""docker.io/bloomberg/goldpinger:3.10.1""
           imagePullPolicy: Always
           securityContext:
             allowPrivilegeEscalation: false"
thaum-xyz,ankhmorpork,232c24db5283821ad86d822b64986ae6e1733791,paulfantom,pawel@krupa.net.pl,2024-10-04T15:03:36Z,paulfantom,pawel@krupa.net.pl,2024-10-04T15:03:36Z,monitoring/goldpinger: FIX SVC,apps/monitoring/manifests/goldpinger/service.yaml,False,False,False,False,1,1,2,"---FILE: apps/monitoring/manifests/goldpinger/service.yaml---
@@ -10,7 +10,7 @@ metadata:
 spec:
   ports:
     - port: 8080
-      nodePort: 30080
+      targetPort: 8080
       name: http
   selector:
     app: goldpinger"
thaum-xyz,ankhmorpork,f60228925cb145bf94487de22433d9eb99ec760c,paulfantom,pawel@krupa.net.pl,2024-10-04T15:00:54Z,paulfantom,pawel@krupa.net.pl,2024-10-04T15:00:54Z,monitoring: fix goldpinger RBAC,apps/monitoring/manifests/goldpinger/clusterrole.yaml;apps/monitoring/manifests/goldpinger/clusterrolebinding.yaml,False,False,False,False,12,1,13,"---FILE: apps/monitoring/manifests/goldpinger/clusterrole.yaml---
@@ -0,0 +1,11 @@
+kind: ClusterRole
+apiVersion: rbac.authorization.k8s.io/v1
+metadata:
+  name: goldpinger-clusterrole
+  labels:
+    app: goldpinger
+    app.kubernetes.io/name: goldpinger
+rules:
+  - apiGroups: [""""]
+    resources: [""pods""]
+    verbs: [""list""]

---FILE: apps/monitoring/manifests/goldpinger/clusterrolebinding.yaml---
@@ -6,7 +6,7 @@ metadata:
 roleRef:
   apiGroup: rbac.authorization.k8s.io
   kind: ClusterRole
-  name: view
+  name: goldpinger-clusterrole
 subjects:
   - kind: ServiceAccount
     name: goldpinger-serviceaccount"
thaum-xyz,ankhmorpork,5d3c4739d93408efe5898b15907d229456a1ff10,paulfantom,pawel@krupa.net.pl,2024-09-29T18:18:55Z,paulfantom,pawel@krupa.net.pl,2024-09-29T18:23:23Z,"monitoring: fix scrapeconfig

Signed-off-by: paulfantom <pawel@krupa.net.pl>",apps/monitoring/jsonnet/main.jsonnet;apps/monitoring/manifests/kubernetesControlPlane/scrapeConfigKubeletProbes.yaml;apps/monitoring/manifests/kubernetesControlPlane/scrapeConfigKubeletSLIS.yaml,False,False,False,False,2,4,6,"---FILE: apps/monitoring/jsonnet/main.jsonnet---
@@ -645,7 +645,7 @@ local kp =
         spec+: {
           honorLabels: true,
           metricsPath: '/metrics/probes',
-          metricRelabelings: [],
+          metricRelabelings:: [],
           scrapeInterval: '30s',
         },
       },
@@ -656,7 +656,7 @@ local kp =
         spec+: {
           honorLabels: true,
           metricsPath: '/metrics/slis',
-          metricRelabelings: [],
+          metricRelabelings:: [],
           scrapeInterval: '5s',
           scrapeTimeout: '5s',
         },

---FILE: apps/monitoring/manifests/kubernetesControlPlane/scrapeConfigKubeletProbes.yaml---
@@ -15,7 +15,6 @@ spec:
   honorLabels: true
   kubernetesSDConfigs:
     - role: Node
-  metricRelabelings: []
   metricsPath: /metrics/probes
   relabelings:
     - action: replace

---FILE: apps/monitoring/manifests/kubernetesControlPlane/scrapeConfigKubeletSLIS.yaml---
@@ -15,7 +15,6 @@ spec:
   honorLabels: true
   kubernetesSDConfigs:
     - role: Node
-  metricRelabelings: []
   metricsPath: /metrics/slis
   relabelings:
     - action: replace"
thaum-xyz,ankhmorpork,5f6406b0a7654e6dff86cd38188601710a3db811,paulfantom,pawel@krupa.net.pl,2024-09-28T09:30:49Z,paulfantom,pawel@krupa.net.pl,2024-09-28T09:30:49Z,homer: another attempt at fixing trakt logo,apps/homer/manifests/reloader/configmap-template.yaml;apps/homer/manifests/reloader/deployment.yaml,False,False,False,False,2,2,4,"---FILE: apps/homer/manifests/reloader/configmap-template.yaml---
@@ -116,7 +116,7 @@ data:
             url: ""https://qnap.ankhmorpork.thaum.xyz""
           - name: Trakt
             subtitle: ""Movie and TV series tracking""
-            logo: ""https://trakt.tv/assets/branding/logos/icon/pixels/trakt-icon-red-46d9d5748d43ee952be3861646c10e584a6e0cbade5ef6651b6de41b88058175.png""
+            logo: ""https://user-images.githubusercontent.com/67451572/160710031-1c69ffdb-918a-474f-a3cf-257313b4c8d6.png""
             <<: *external
             url: ""https://trakt.tv""
           #- name: Plex

---FILE: apps/homer/manifests/reloader/deployment.yaml---
@@ -14,7 +14,7 @@ spec:
       labels:
         app.kubernetes.io/name: reloader
       annotations:
-        revision.config/number: ""6""
+        revision.config/number: ""7""
     spec:
       containers:
         - args:"
thaum-xyz,ankhmorpork,0e74770cb0e753ba5523765bf1fbc06390513d56,paulfantom,pawel@krupa.net.pl,2024-09-25T21:17:57Z,paulfantom,pawel@krupa.net.pl,2024-09-25T21:17:57Z,jellyfin: fix sec contexts,apps/jellyfin/manifests/release.yaml,False,False,False,False,1,1,2,"---FILE: apps/jellyfin/manifests/release.yaml---
@@ -40,7 +40,7 @@ spec:
               name: jellyfin
             patch: |
               - op: add
-                path: /spec/template/spec/securityContext/privileged
+                path: /spec/template/spec/containers/0/securityContext/privileged
                 value: true
               - op: add
                 path: /spec/template/spec/securityContext/runAsUser"
thaum-xyz,ankhmorpork,b3a33a3899d1c90a31a091bf1de29d86882d392f,paulfantom,pawel@krupa.net.pl,2024-09-25T08:13:05Z,paulfantom,pawel@krupa.net.pl,2024-09-25T08:13:05Z,jellyfin: fix middleware reference,apps/jellyfin/manifests/values.yaml,False,False,False,False,1,1,2,"---FILE: apps/jellyfin/manifests/values.yaml---
@@ -7,7 +7,7 @@ ingress:
   annotations:
     cert-manager.io/cluster-issuer: letsencrypt-dns01
     kubernetes.io/ingress.class: private
-    traefik.ingress.kubernetes.io/router.middlewares: deny-metrics-path@kubernetescrd
+    traefik.ingress.kubernetes.io/router.middlewares: jellyfin-deny-metrics-path@kubernetescrd
   hosts:
     - jellyfin.ankhmorpork.thaum.xyz
   tls:"
thaum-xyz,ankhmorpork,ef2cd90e2f2b4b0ab49ccdac8c2a47669419390e,paulfantom,pawel@krupa.net.pl,2024-09-24T17:55:02Z,paulfantom,pawel@krupa.net.pl,2024-09-24T17:55:02Z,jellyfin: fix stupid helm chart variable name,apps/jellyfin/manifests/values.yaml,False,False,False,False,1,1,2,"---FILE: apps/jellyfin/manifests/values.yaml---
@@ -26,7 +26,7 @@ persistence:
   extraExistingClaimMounts:
     - name: media-tv
       mountPath: /media/tv
-      claimName: media-tv
+      existingClaim: media-tv
       readOnly: true
     #- name: media-movies
     #  mountPath: /media/movies"
thaum-xyz,ankhmorpork,aa0f601348bdda103ce2ffc2e7d8c4c22dca9456,paulfantom,pawel@krupa.net.pl,2024-09-24T17:49:04Z,paulfantom,pawel@krupa.net.pl,2024-09-24T17:49:04Z,jellyfin: fix media pvc,apps/jellyfin/manifests/pvc-media-tv.yaml,False,False,False,False,1,1,2,"---FILE: apps/jellyfin/manifests/pvc-media-tv.yaml---
@@ -5,7 +5,7 @@ metadata:
   namespace: jellyfin
 spec:
   accessModes:
-    - ReadWriteOnce
+    - ReadWriteMany
   resources:
     requests:
       storage: 4000Gi"
thaum-xyz,ankhmorpork,7d38017edb45a4392584d7c64c49a071a0f7addc,paulfantom,pawel@krupa.net.pl,2024-09-24T17:44:40Z,paulfantom,pawel@krupa.net.pl,2024-09-24T17:44:40Z,multimedia: fix PV access modes,apps/multimedia/jsonnet/utils.libsonnet;apps/multimedia/manifests/shared/pv-books.yaml;apps/multimedia/manifests/shared/pv-movies.yaml;apps/multimedia/manifests/shared/pv-tv.yaml;apps/multimedia/manifests/shared/pvc-books.yaml;apps/multimedia/manifests/shared/pvc-movies.yaml;apps/multimedia/manifests/shared/pvc-tv.yaml,False,False,False,False,8,8,16,"---FILE: apps/multimedia/jsonnet/utils.libsonnet---
@@ -5,7 +5,7 @@
       kind: 'PersistentVolume',
       metadata: metadata,
       spec: {
-        accessModes: ['ReadWriteOnce'],
+        accessModes: ['ReadWriteMany'],
         capacity: {
           storage: capacity,
         },
@@ -24,7 +24,7 @@
       kind: 'PersistentVolumeClaim',
       metadata: metadata,
       spec: {
-        accessModes: ['ReadWriteOnce'],
+        accessModes: ['ReadWriteMany'],
         resources: {
           requests: {
             storage: capacity,

---FILE: apps/multimedia/manifests/shared/pv-books.yaml---
@@ -5,7 +5,7 @@ metadata:
   namespace: multimedia
 spec:
   accessModes:
-    - ReadWriteOnce
+    - ReadWriteMany
   capacity:
     storage: 4000Gi
   nfs:

---FILE: apps/multimedia/manifests/shared/pv-movies.yaml---
@@ -5,7 +5,7 @@ metadata:
   namespace: multimedia
 spec:
   accessModes:
-    - ReadWriteOnce
+    - ReadWriteMany
   capacity:
     storage: 4000Gi
   nfs:

---FILE: apps/multimedia/manifests/shared/pv-tv.yaml---
@@ -5,7 +5,7 @@ metadata:
   namespace: multimedia
 spec:
   accessModes:
-    - ReadWriteOnce
+    - ReadWriteMany
   capacity:
     storage: 4000Gi
   nfs:

---FILE: apps/multimedia/manifests/shared/pvc-books.yaml---
@@ -5,7 +5,7 @@ metadata:
   namespace: multimedia
 spec:
   accessModes:
-    - ReadWriteOnce
+    - ReadWriteMany
   resources:
     requests:
       storage: 4000Gi

---FILE: apps/multimedia/manifests/shared/pvc-movies.yaml---
@@ -5,7 +5,7 @@ metadata:
   namespace: multimedia
 spec:
   accessModes:
-    - ReadWriteOnce
+    - ReadWriteMany
   resources:
     requests:
       storage: 4000Gi

---FILE: apps/multimedia/manifests/shared/pvc-tv.yaml---
@@ -5,7 +5,7 @@ metadata:
   namespace: multimedia
 spec:
   accessModes:
-    - ReadWriteOnce
+    - ReadWriteMany
   resources:
     requests:
       storage: 4000Gi"
thaum-xyz,ankhmorpork,25c9dbd47527f0c778ccf01c55b1b4b0d6163a79,paulfantom,pawel@krupa.net.pl,2024-05-18T15:33:02Z,paulfantom,pawel@krupa.net.pl,2024-05-18T15:33:02Z,apps/paperless: post incident fixes,apps/paperless/manifests/postgres/cluster.yaml;apps/paperless/manifests/web/cronjob.yaml;apps/paperless/settings.yaml;lib/jsonnet/apps/paperless.libsonnet,False,False,False,False,8,8,16,"---FILE: apps/paperless/manifests/postgres/cluster.yaml---
@@ -41,7 +41,7 @@ spec:
       cpu: 50m
       memory: 200Mi
   storage:
-    size: 4Gi
+    size: 6Gi
     storageClass: lvm-thin
   superuserSecret:
     name: postgres-admin

---FILE: apps/paperless/manifests/web/cronjob.yaml---
@@ -56,10 +56,10 @@ spec:
           volumes:
             - name: data
               persistentVolumeClaim:
-                claimName: data
+                claimName: paperless-data
             - name: media
               persistentVolumeClaim:
-                claimName: media
+                claimName: paperless-media
             - name: consume
               persistentVolumeClaim:
                 claimName: consume

---FILE: apps/paperless/settings.yaml---
@@ -104,7 +104,7 @@ postgres:
       cpu: 200m
       memory: 800Mi
   storage:
-    size: 4Gi
+    size: 6Gi
     storageClass: ""lvm-thin""
 
 broker:

---FILE: lib/jsonnet/apps/paperless.libsonnet---
@@ -375,25 +375,25 @@ function(params) {
                 {
                   name: 'data',
                   persistentVolumeClaim: {
-                    claimName: 'data',
+                    claimName: $.pvcData.metadata.name,
                   },
                 },
                 {
                   name: 'media',
                   persistentVolumeClaim: {
-                    claimName: 'media',
+                    claimName: $.pvcMedia.metadata.name,
                   },
                 },
                 {
                   name: 'consume',
                   persistentVolumeClaim: {
-                    claimName: 'consume',
+                    claimName: $.pvcConsume.metadata.name,
                   },
                 },
                 {
                   name: 'backups',
                   persistentVolumeClaim: {
-                    claimName: 'backups',
+                    claimName: $.pvcBackups.metadata.name,
                   },
                 },
               ],"
thaum-xyz,ankhmorpork,f69e48f942dcd354c2bed53c6ee9b086cb7634c0,paulfantom,pawel@krupa.net.pl,2024-05-06T09:44:34Z,paulfantom,pawel@krupa.net.pl,2024-05-06T09:44:34Z,apps/multimedia: fix readarr db backup schedule,apps/multimedia/manifests/readarrdb/backup.yaml;apps/multimedia/settings.yaml,False,False,False,False,2,2,4,"---FILE: apps/multimedia/manifests/readarrdb/backup.yaml---
@@ -9,5 +9,5 @@ spec:
   backupOwnerReference: self
   cluster:
     name: postgres-readarr
-  schedule: 0 17 33 * * *
+  schedule: 0 17 23 * * *
   suspend: false

---FILE: apps/multimedia/settings.yaml---
@@ -293,7 +293,7 @@ readarr:
       adminPassRef: READARR_DB_ADMIN_PASS
     externalSecretStoreName: *externalSecretStoreName
     backup:
-      schedule: ""0 17 33 * * *""
+      schedule: ""0 17 23 * * *""
       retentionPolicy: 7d
       suspend: false
       destinationPath: ""s3://postgres/multimedia/readarr"""
thaum-xyz,ankhmorpork,4d09f6512e87a22e288bfc5e93ee537f6f95e092,paulfantom,pawel@krupa.net.pl,2024-05-06T09:22:26Z,paulfantom,pawel@krupa.net.pl,2024-05-06T09:22:26Z,apps/monitoring: fix pushover notification title,apps/monitoring/manifests/alertmanager/configTemplate.yaml;apps/monitoring/raw/alertmanager-config.yaml.gtpl,False,False,False,False,4,4,8,"---FILE: apps/monitoring/manifests/alertmanager/configTemplate.yaml---
@@ -103,9 +103,9 @@ data:
         priority: '{{ `{{ if eq .Status ""firing"" }}` }}0{{ `{{ else }}` }}-1{{ `{{ end }}` }}'
         title: |
           {{ `{{- if .CommonAnnotations.summary -}}` }}
-            {{ .CommonAnnotations.summary }}
+            {{ `{{- .CommonAnnotations.summary -}}` }}
           {{ `{{- else -}}` }}
-            {{ .CommonLabels.alertname }}
+            {{ `{{- .CommonLabels.alertname -}}` }}
           {{ `{{- end }}` }}
         message: >-
           {{ `{{- if .CommonAnnotations.message }}` }}

---FILE: apps/monitoring/raw/alertmanager-config.yaml.gtpl---
@@ -100,9 +100,9 @@ receivers:
     priority: '{{ `{{ if eq .Status ""firing"" }}` }}0{{ `{{ else }}` }}-1{{ `{{ end }}` }}'
     title: |
       {{ `{{- if .CommonAnnotations.summary -}}` }}
-        {{ .CommonAnnotations.summary }}
+        {{ `{{- .CommonAnnotations.summary -}}` }}
       {{ `{{- else -}}` }}
-        {{ .CommonLabels.alertname }}
+        {{ `{{- .CommonLabels.alertname -}}` }}
       {{ `{{- end }}` }}
     message: >-
       {{ `{{- if .CommonAnnotations.message }}` }}"
thaum-xyz,ankhmorpork,f9aee694e76eacace03e34902e0d88ef4ccf6112,paulfantom,pawel@krupa.net.pl,2024-05-06T08:47:06Z,paulfantom,pawel@krupa.net.pl,2024-05-06T08:47:06Z,apps/monitoring: fix issue with incorrect whitespace handling in go template,apps/monitoring/manifests/alertmanager/configTemplate.yaml;apps/monitoring/raw/alertmanager-config.yaml.gtpl,False,False,False,False,2,2,4,"---FILE: apps/monitoring/manifests/alertmanager/configTemplate.yaml---
@@ -98,7 +98,7 @@ data:
         token: {{ .pushover_token }}  {{/* This is a reference to a secret stored in doppler */}}
         retry: 10m
         device: McAir
-        priority: {{ `{{- if eq .Status ""firing"" -}}` }}0{{ `{{- else -}}` }}-1{{ `{{- end }}` }}
+        priority: {{ `{{ if eq .Status ""firing"" }}` }}0{{ `{{ else }}` }}-1{{ `{{ end }}` }}
         ttl: 2h
         title: |
           {{ `{{- if eq .Status ""firing"" -}}` }}

---FILE: apps/monitoring/raw/alertmanager-config.yaml.gtpl---
@@ -95,7 +95,7 @@ receivers:
     token: {{ .pushover_token }}  {{/* This is a reference to a secret stored in doppler */}}
     retry: 10m
     device: McAir
-    priority: {{ `{{- if eq .Status ""firing"" -}}` }}0{{ `{{- else -}}` }}-1{{ `{{- end }}` }}
+    priority: {{ `{{ if eq .Status ""firing"" }}` }}0{{ `{{ else }}` }}-1{{ `{{ end }}` }}
     ttl: 2h
     title: |
       {{ `{{- if eq .Status ""firing"" -}}` }}"
thaum-xyz,ankhmorpork,e1e93fedeb885d908aeb2ab70b0667b7fd800f4d,paulfantom,pawel@krupa.net.pl,2024-05-06T08:39:10Z,paulfantom,pawel@krupa.net.pl,2024-05-06T08:39:10Z,apps/monitoring: fix issue with double golang templating,apps/monitoring/manifests/alertmanager/configTemplate.yaml;apps/monitoring/raw/alertmanager-config.yaml.gtpl,False,False,False,False,2,4,6,"---FILE: apps/monitoring/manifests/alertmanager/configTemplate.yaml---
@@ -98,8 +98,7 @@ data:
         token: {{ .pushover_token }}  {{/* This is a reference to a secret stored in doppler */}}
         retry: 10m
         device: McAir
-        priority: |
-          {{ if eq .Status ""firing"" }}0{{ else }}-1{{ end }}
+        priority: {{ `{{- if eq .Status ""firing"" -}}` }}0{{ `{{- else -}}` }}-1{{ `{{- end }}` }}
         ttl: 2h
         title: |
           {{ `{{- if eq .Status ""firing"" -}}` }}

---FILE: apps/monitoring/raw/alertmanager-config.yaml.gtpl---
@@ -95,8 +95,7 @@ receivers:
     token: {{ .pushover_token }}  {{/* This is a reference to a secret stored in doppler */}}
     retry: 10m
     device: McAir
-    priority: |
-      {{ if eq .Status ""firing"" }}0{{ else }}-1{{ end }}
+    priority: {{ `{{- if eq .Status ""firing"" -}}` }}0{{ `{{- else -}}` }}-1{{ `{{- end }}` }}
     ttl: 2h
     title: |
       {{ `{{- if eq .Status ""firing"" -}}` }}"
thaum-xyz,ankhmorpork,174d0e290761bd7c9e35785003a0a7b69c875762,paulfantom,pawel@krupa.net.pl,2024-05-06T08:34:36Z,paulfantom,pawel@krupa.net.pl,2024-05-06T08:34:36Z,apps/monitoring: alternative fix setting notification priority for pushover,apps/monitoring/manifests/alertmanager/configTemplate.yaml;apps/monitoring/raw/alertmanager-config.yaml.gtpl,False,False,False,False,4,2,6,"---FILE: apps/monitoring/manifests/alertmanager/configTemplate.yaml---
@@ -98,7 +98,8 @@ data:
         token: {{ .pushover_token }}  {{/* This is a reference to a secret stored in doppler */}}
         retry: 10m
         device: McAir
-        priority: ""{{ `{{ if eq .Status ""firing"" }}0{{ else }}-1{{ end }}` }}""
+        priority: |
+          {{ if eq .Status ""firing"" }}0{{ else }}-1{{ end }}
         ttl: 2h
         title: |
           {{ `{{- if eq .Status ""firing"" -}}` }}

---FILE: apps/monitoring/raw/alertmanager-config.yaml.gtpl---
@@ -95,7 +95,8 @@ receivers:
     token: {{ .pushover_token }}  {{/* This is a reference to a secret stored in doppler */}}
     retry: 10m
     device: McAir
-    priority: ""{{ `{{ if eq .Status ""firing"" }}0{{ else }}-1{{ end }}` }}""
+    priority: |
+      {{ if eq .Status ""firing"" }}0{{ else }}-1{{ end }}
     ttl: 2h
     title: |
       {{ `{{- if eq .Status ""firing"" -}}` }}"
thaum-xyz,ankhmorpork,849bba8341b733a3bb7f7e6982af4d724b65483e,paulfantom,pawel@krupa.net.pl,2024-05-06T08:29:07Z,paulfantom,pawel@krupa.net.pl,2024-05-06T08:29:07Z,apps/monitoring: fix setting notification priority for pushover,apps/monitoring/manifests/alertmanager/configTemplate.yaml;apps/monitoring/raw/alertmanager-config.yaml.gtpl,False,False,False,False,2,2,4,"---FILE: apps/monitoring/manifests/alertmanager/configTemplate.yaml---
@@ -98,7 +98,7 @@ data:
         token: {{ .pushover_token }}  {{/* This is a reference to a secret stored in doppler */}}
         retry: 10m
         device: McAir
-        priority: {{ if eq .Status ""firing"" }}0{{ else }}-1{{ end }}
+        priority: ""{{ `{{ if eq .Status ""firing"" }}0{{ else }}-1{{ end }}` }}""
         ttl: 2h
         title: |
           {{ `{{- if eq .Status ""firing"" -}}` }}

---FILE: apps/monitoring/raw/alertmanager-config.yaml.gtpl---
@@ -95,7 +95,7 @@ receivers:
     token: {{ .pushover_token }}  {{/* This is a reference to a secret stored in doppler */}}
     retry: 10m
     device: McAir
-    priority: {{ if eq .Status ""firing"" }}0{{ else }}-1{{ end }}
+    priority: ""{{ `{{ if eq .Status ""firing"" }}0{{ else }}-1{{ end }}` }}""
     ttl: 2h
     title: |
       {{ `{{- if eq .Status ""firing"" -}}` }}"
thaum-xyz,ankhmorpork,fb6938a7c8d9de8951f62a8f4e681e24583dc309,paulfantom,pawel@krupa.net.pl,2024-04-15T17:12:55Z,paulfantom,pawel@krupa.net.pl,2024-04-15T17:12:55Z,apps/photos: fix PVC access mode incompatibility,apps/photos/library-pv.yaml,False,False,False,False,1,1,2,"---FILE: apps/photos/library-pv.yaml---
@@ -5,7 +5,7 @@ metadata:
   name: immich-library
 spec:
   accessModes:
-    - ReadWriteOnce
+    - ReadWriteMany
   capacity:
     storage: 500Gi
   nfs:"
thaum-xyz,ankhmorpork,8cd74bc02c8df45fe377225ed56b501395e2c953,paulfantom,pawel@krupa.net.pl,2024-04-11T19:21:14Z,paulfantom,pawel@krupa.net.pl,2024-04-11T19:21:14Z,apps/homeassistant: fix tandoor template,apps/homeassistant/config/configuration.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,17,17,34,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -192,22 +192,22 @@ rest:
         unique_id: ""meal_today_breakfast""
         value_template: >
           {% set data = value_json | selectattr('meal_type.order', 'eq', 0) | first | default({}) -%}
-          {{ data.title if data.title is defined else data.recipe_name | default() }}
+          {{ data.title if data.title is defined and data.title != """" else data.recipe_name | default() }}
       - name: ""Today's Lunch""
         unique_id: ""meal_today_lunch""
         value_template: >
           {% set data = value_json | selectattr('meal_type.order', 'eq', 1) | first | default({}) -%}
-          {{ data.title if data.title is defined else data.recipe_name | default() }}
+          {{ data.title if data.title is defined and data.title != """" else data.recipe_name | default() }}
       - name: ""Today's Snack""
         unique_id: ""meal_today_snack""
         value_template: >
           {% set data = value_json | selectattr('meal_type.order', 'eq', 2) | first | default({}) -%}
-          {{ data.title if data.title is defined else data.recipe_name | default() }}
+          {{ data.title if data.title is defined and data.title != """" else data.recipe_name | default() }}
       - name: ""Today's Dinner""
         unique_id: ""meal_today_dinner""
         value_template: >
           {% set data = value_json | selectattr('meal_type.order', 'eq', 3) | first | default({}) -%}
-          {{ data.title if data.title is defined else data.recipe_name | default() }}
+          {{ data.title if data.title is defined and data.title != """" else data.recipe_name | default() }}
         json_attributes_path: ""$.[?(@.meal_type.order==3)].recipe""
         json_attributes:
           - image
@@ -228,22 +228,22 @@ rest:
         unique_id: ""meal_tomorrow_breakfast""
         value_template: >
           {% set data = value_json | selectattr('meal_type.order', 'eq', 0) | first | default({}) -%}
-          {{ data.title if data.title is defined else data.recipe_name | default() }}
+          {{ data.title if data.title is defined and data.title != """" else data.recipe_name | default() }}
       - name: ""Tomorrow's Lunch""
         unique_id: ""meal_tomorrow_lunch""
         value_template: >
           {% set data = value_json | selectattr('meal_type.order', 'eq', 1) | first | default({}) -%}
-          {{ data.title if data.title is defined else data.recipe_name | default() }}
+          {{ data.title if data.title is defined and data.title != """" else data.recipe_name | default() }}
       - name: ""Tomorrow's Snack""
         unique_id: ""meal_tomorrow_snack""
         value_template: >
           {% set data = value_json | selectattr('meal_type.order', 'eq', 2) | first | default({}) -%}
-          {{ data.title if data.title is defined else data.recipe_name | default() }}
+          {{ data.title if data.title is defined and data.title != """" else data.recipe_name | default() }}
       - name: ""Tomorrow's Dinner""
         unique_id: ""meal_tomorrow_dinner""
         value_template: >
           {% set data = value_json | selectattr('meal_type.order', 'eq', 3) | first | default({}) -%}
-          {{ data.title if data.title is defined else data.recipe_name | default() }}
+          {{ data.title if data.title is defined and data.title != """" else data.recipe_name | default() }}
         json_attributes_path: ""$.[?(@.meal_type.order==3)].recipe""
         json_attributes:
           - image

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -195,22 +195,22 @@ data:
             unique_id: ""meal_today_breakfast""
             value_template: >
               {% set data = value_json | selectattr('meal_type.order', 'eq', 0) | first | default({}) -%}
-              {{ data.title if data.title is defined else data.recipe_name | default() }}
+              {{ data.title if data.title is defined and data.title != """" else data.recipe_name | default() }}
           - name: ""Today's Lunch""
             unique_id: ""meal_today_lunch""
             value_template: >
               {% set data = value_json | selectattr('meal_type.order', 'eq', 1) | first | default({}) -%}
-              {{ data.title if data.title is defined else data.recipe_name | default() }}
+              {{ data.title if data.title is defined and data.title != """" else data.recipe_name | default() }}
           - name: ""Today's Snack""
             unique_id: ""meal_today_snack""
             value_template: >
               {% set data = value_json | selectattr('meal_type.order', 'eq', 2) | first | default({}) -%}
-              {{ data.title if data.title is defined else data.recipe_name | default() }}
+              {{ data.title if data.title is defined and data.title != """" else data.recipe_name | default() }}
           - name: ""Today's Dinner""
             unique_id: ""meal_today_dinner""
             value_template: >
               {% set data = value_json | selectattr('meal_type.order', 'eq', 3) | first | default({}) -%}
-              {{ data.title if data.title is defined else data.recipe_name | default() }}
+              {{ data.title if data.title is defined and data.title != """" else data.recipe_name | default() }}
             json_attributes_path: ""$.[?(@.meal_type.order==3)].recipe""
             json_attributes:
               - image
@@ -231,22 +231,22 @@ data:
             unique_id: ""meal_tomorrow_breakfast""
             value_template: >
               {% set data = value_json | selectattr('meal_type.order', 'eq', 0) | first | default({}) -%}
-              {{ data.title if data.title is defined else data.recipe_name | default() }}
+              {{ data.title if data.title is defined and data.title != """" else data.recipe_name | default() }}
           - name: ""Tomorrow's Lunch""
             unique_id: ""meal_tomorrow_lunch""
             value_template: >
               {% set data = value_json | selectattr('meal_type.order', 'eq', 1) | first | default({}) -%}
-              {{ data.title if data.title is defined else data.recipe_name | default() }}
+              {{ data.title if data.title is defined and data.title != """" else data.recipe_name | default() }}
           - name: ""Tomorrow's Snack""
             unique_id: ""meal_tomorrow_snack""
             value_template: >
               {% set data = value_json | selectattr('meal_type.order', 'eq', 2) | first | default({}) -%}
-              {{ data.title if data.title is defined else data.recipe_name | default() }}
+              {{ data.title if data.title is defined and data.title != """" else data.recipe_name | default() }}
           - name: ""Tomorrow's Dinner""
             unique_id: ""meal_tomorrow_dinner""
             value_template: >
               {% set data = value_json | selectattr('meal_type.order', 'eq', 3) | first | default({}) -%}
-              {{ data.title if data.title is defined else data.recipe_name | default() }}
+              {{ data.title if data.title is defined and data.title != """" else data.recipe_name | default() }}
             json_attributes_path: ""$.[?(@.meal_type.order==3)].recipe""
             json_attributes:
               - image

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: 59b7f87d25e76215f94ed54b534e6129
+        checksum.config/md5: c3bca31ac8e65e1c51357dafe7eabf15
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,ead3d5934239ec41c36108808a79a11f7102802f,paulfantom,pawel@krupa.net.pl,2024-04-11T15:25:19Z,paulfantom,pawel@krupa.net.pl,2024-04-11T15:25:19Z,apps/shlink: fix DB uri,apps/shlink/manifests/shlink/deployment.yaml,False,False,False,False,1,1,2,"---FILE: apps/shlink/manifests/shlink/deployment.yaml---
@@ -55,7 +55,7 @@ spec:
           - name: DB_DRIVER
             value: postgres
           - name: DB_HOST
-            value: postgres
+            value: postgres-rw
           - name: DB_NAME
             value: shlink
           - name: DB_USER"
thaum-xyz,ankhmorpork,0c86c6f2ee1fcd6b00e92912acaf861955240fb2,paulfantom,pawel@krupa.net.pl,2024-04-11T14:40:40Z,paulfantom,pawel@krupa.net.pl,2024-04-11T14:40:40Z,apps/kube-image-keeper: do not cache images for cnpg due to https://github.com/cloudnative-pg/cloudnative-pg/issues/3231,apps/kube-image-keeper/values.yaml,False,False,False,False,4,0,4,"---FILE: apps/kube-image-keeper/values.yaml---
@@ -6,6 +6,10 @@ controllers:
   replicas: 1
   podMonitor:
     create: true
+  webhook:
+    ignoredImages:
+    - ghcr.io/cloudnative-pg/*
+    - ghcr.io/tensorchord/cloudnative*
 
 proxy:
   podMonitor:"
thaum-xyz,ankhmorpork,5740ccb86aced0db392269e7c54c86d28ddda6e3,paulfantom,pawel@krupa.net.pl,2024-04-11T06:56:52Z,paulfantom,pawel@krupa.net.pl,2024-04-11T06:56:52Z,apps/shlink: fix shlink deployment,apps/shlink/manifests/shlink/deployment.yaml,False,False,False,False,5,5,10,"---FILE: apps/shlink/manifests/shlink/deployment.yaml---
@@ -65,11 +65,11 @@ spec:
                 key: password
           #- name: REDIS_SERVERS
           #  value: redis://redis:6379
-          - name: WEB_WORKER_NUM
-            valueFrom:
-              resourceFieldRef:
-                resource: limits.cpu
-                divisor: 100m
+          #- name: WEB_WORKER_NUM
+          #  valueFrom:
+          #    resourceFieldRef:
+          #      resource: limits.cpu
+          #      divisor: 100m
           resources:
             limits:
               cpu: 200m"
thaum-xyz,ankhmorpork,3dd72be030677477df6995721f7af65fa251b860,paulfantom,pawel@krupa.net.pl,2024-04-04T09:22:43Z,paulfantom,pawel@krupa.net.pl,2024-04-04T09:22:43Z,apps/adguard: fix hostAlias,apps/adguard/manifests/deployment.yaml,False,False,False,False,5,5,10,"---FILE: apps/adguard/manifests/deployment.yaml---
@@ -44,15 +44,15 @@ spec:
             requests:
               cpu: 5m
               memory: 18Mi
-          hostAliases:
-            - ip: ""192.168.2.4""
-              hostnames:
-                - adguard
-                - dns.ankhmorpork.thaum.xyz
           volumeMounts:
             - mountPath: /etc/json_exporter/
               name: adguard
               readOnly: true
+      hostAliases:
+        - ip: ""192.168.2.4""
+          hostnames:
+            - adguard
+            - dns.ankhmorpork.thaum.xyz
       serviceAccountName: adguard
       volumes:
         - name: adguard"
thaum-xyz,ankhmorpork,5ab34f9fda3a05d427da482c62e10088873dbf13,paulfantom,pawel@krupa.net.pl,2024-03-29T13:23:14Z,paulfantom,pawel@krupa.net.pl,2024-03-29T13:23:14Z,multimedia: fix creation of readarr cache db,apps/multimedia/manifests/readarrdb/cluster.yaml,False,False,False,False,2,2,4,"---FILE: apps/multimedia/manifests/readarrdb/cluster.yaml---
@@ -18,8 +18,8 @@ spec:
       postInitSQL:
         - CREATE DATABASE logs;
         - ALTER DATABASE logs OWNER TO readarr;
-        - CREATE DATABASE readarr-cache;
-        - ALTER DATABASE readarr-cache OWNER TO readarr;
+        - CREATE DATABASE ""readarr-cache"";
+        - ALTER DATABASE ""readarr-cache"" OWNER TO readarr;
       secret:
         name: postgres-readarr-user
   instances: 2"
thaum-xyz,ankhmorpork,1ca79659c54305d422a254a705677787ff6caa4a,paulfantom,pawel@krupa.net.pl,2024-03-25T16:51:33Z,paulfantom,pawel@krupa.net.pl,2024-03-25T16:51:33Z,multimedia: fix placement of radarr postgres secret,apps/multimedia/manifests/radarr/pg-credentialsAdmin.yaml,False,False,False,False,1,1,2,"---FILE: apps/multimedia/manifests/radarr/pg-credentialsAdmin.yaml---
@@ -4,7 +4,7 @@ metadata:
   labels:
     app.kubernetes.io/name: postgres
   name: postgres-radarr-admin
-  namespace: homeassistant
+  namespace: multimedia
 spec:
   data:
     - remoteRef:"
thaum-xyz,ankhmorpork,064e5e40833596d3deaeaf60cbea1401a72583cd,paulfantom,pawel@krupa.net.pl,2024-03-24T13:11:34Z,paulfantom,pawel@krupa.net.pl,2024-03-24T13:11:34Z,homer: fix tags,apps/homer/manifests/reloader/configmap-template.yaml,False,False,False,False,2,0,2,"---FILE: apps/homer/manifests/reloader/configmap-template.yaml---
@@ -94,10 +94,12 @@ data:
           - name: Storage Unit
             subtitle: Tracking content stored remotely
             logo: ""https://upload.wikimedia.org/wikipedia/commons/thumb/3/30/Google_Sheets_logo_%282014-2020%29.svg/562px-Google_Sheets_logo_%282014-2020%29.svg.png""
+            <<: *external
             url: ""https://docs.google.com/spreadsheets/d/1-aFb40yjIjdcJNJ3Ngvbw9HWo5r1eGugZBWqSPcU-HU""
           - name: Pantry
             subtitle: Tracking pantry content
             logo: ""https://upload.wikimedia.org/wikipedia/commons/thumb/3/30/Google_Sheets_logo_%282014-2020%29.svg/562px-Google_Sheets_logo_%282014-2020%29.svg.png""
+            <<: *external
             url: ""https://docs.google.com/spreadsheets/d/13JSCTEgDHP26carFuHO5j5mfqvI5UBNAu_B9ED3vWbQ""
           - name: Image Compressor
             subtitle: ""Compress images online"""
thaum-xyz,ankhmorpork,6881fb1dfb297ed1b536a8a421d8d2ed18c2cb69,paulfantom,pawel@krupa.net.pl,2024-03-23T11:57:20Z,paulfantom,pawel@krupa.net.pl,2024-03-23T11:57:20Z,*: fix postgres affinity,apps/homeassistant/manifests/postgres/cluster.yaml;apps/paperless/manifests/postgres/cluster.yaml;apps/tandoor/manifests/postgres/cluster.yaml;lib/jsonnet/apps/cloudnative-pg-cluster.libsonnet,False,False,False,False,12,52,64,"---FILE: apps/homeassistant/manifests/postgres/cluster.yaml---
@@ -7,17 +7,9 @@ metadata:
   namespace: homeassistant
 spec:
   affinity:
-    podAntiAffinity:
-      preferredDuringSchedulingIgnoredDuringExecution:
-        - podAffinityTerm:
-            labelSelector:
-              matchExpressions:
-                - key: app.kubernetes.io/name
-                  operator: In
-                  values:
-                    - postgres
-            topologyKey: kubernetes.io/hostname
-          weight: 100
+    enablePodAntiAffinity: true
+    podAntiAffinityType: required
+    topologyKey: kubernetes.io/hostname
   backup:
     barmanObjectStore:
       destinationPath: s3://postgres/homeassistant

---FILE: apps/paperless/manifests/postgres/cluster.yaml---
@@ -7,17 +7,9 @@ metadata:
   namespace: paperless
 spec:
   affinity:
-    podAntiAffinity:
-      preferredDuringSchedulingIgnoredDuringExecution:
-        - podAffinityTerm:
-            labelSelector:
-              matchExpressions:
-                - key: app.kubernetes.io/name
-                  operator: In
-                  values:
-                    - postgres
-            topologyKey: kubernetes.io/hostname
-          weight: 100
+    enablePodAntiAffinity: true
+    podAntiAffinityType: required
+    topologyKey: kubernetes.io/hostname
   backup:
     barmanObjectStore:
       destinationPath: s3://postgres/paperless

---FILE: apps/tandoor/manifests/postgres/cluster.yaml---
@@ -7,17 +7,9 @@ metadata:
   namespace: tandoor
 spec:
   affinity:
-    podAntiAffinity:
-      preferredDuringSchedulingIgnoredDuringExecution:
-        - podAffinityTerm:
-            labelSelector:
-              matchExpressions:
-                - key: app.kubernetes.io/name
-                  operator: In
-                  values:
-                    - postgres
-            topologyKey: kubernetes.io/hostname
-          weight: 100
+    enablePodAntiAffinity: true
+    podAntiAffinityType: required
+    topologyKey: kubernetes.io/hostname
   backup:
     barmanObjectStore:
       destinationPath: s3://postgres/tandoor

---FILE: lib/jsonnet/apps/cloudnative-pg-cluster.libsonnet---
@@ -15,25 +15,9 @@ local defaults = {
   },
   instances: 2,
   affinity: {
-    podAntiAffinity: {
-      preferredDuringSchedulingIgnoredDuringExecution: [
-        {
-          weight: 100,
-          podAffinityTerm: {
-            topologyKey: 'kubernetes.io/hostname',
-            labelSelector: {
-              matchExpressions: [
-                {
-                  key: 'app.kubernetes.io/name',
-                  operator: 'In',
-                  values: ['postgres'],
-                },
-              ],
-            },
-          },
-        },
-      ],
-    },
+    enablePodAntiAffinity: true,
+    topologyKey: 'kubernetes.io/hostname',
+    podAntiAffinityType: 'required',
   },
   db: {
     name: 'postgres',"
thaum-xyz,ankhmorpork,f14cbf3ad2ed24a8eda04a57ae22084838b3b087,paulfantom,pawel@krupa.net.pl,2024-03-22T08:00:25Z,paulfantom,pawel@krupa.net.pl,2024-03-22T08:00:25Z,topolvm: monitoring fixes and alerts,base/topolvm/kustomization.yaml;base/topolvm/prometheusrules.yaml;base/topolvm/values.yaml,False,False,False,False,32,5,37,"---FILE: base/topolvm/kustomization.yaml---
@@ -5,6 +5,7 @@ resources:
   - repository.yaml
   - namespace.yaml
   - release.yaml
+  - prometheusrules.yaml
 configMapGenerator:
   - name: values
     files:

---FILE: base/topolvm/prometheusrules.yaml---
@@ -0,0 +1,26 @@
+---
+apiVersion: monitoring.coreos.com/v1
+kind: PrometheusRule
+metadata:
+  name: topolvm-rules
+  namespace: topolvm-system
+spec:
+  groups:
+  - name: topolvm.rules
+    rules:
+    - alert: TopoLVMThinPoolDataUsedHigh
+      annotations:
+        description: The data in LVM thin pool connected to device class {{$labels.device_class}} on node {{$labels.node}} reached {{$value}} occupancy level. If it reaches 100% the LogicalVolumes in that pool can start misbehaving.
+        summary: LVM thin pool data usage is high.
+      expr: topolvm_thinpool_data_percent > 90
+      for: 5m
+      labels:
+        severity: warning
+    - alert: TopoLVMThinPoolDataUsedHigh
+      annotations:
+        description: The data in LVM thin pool connected to device class {{$labels.device_class}} on node {{$labels.node}} reached {{$value}} occupancy level. If it reaches 100% the LogicalVolumes in that pool can start misbehaving.
+        summary: LVM thin pool data usage is high.
+      expr: topolvm_thinpool_data_percent > 95
+      for: 5m
+      labels:
+        severity: critical

---FILE: base/topolvm/values.yaml---
@@ -29,11 +29,11 @@ node:
   prometheus:
     podMonitor:
       enabled: true
-      relabelings:
-      - action: replace
-        sourceLabels:
-        - __meta_kubernetes_pod_node_name
-        targetLabel: node
+      #relabelings:
+      #- action: replace
+      #  sourceLabels:
+      #  - __meta_kubernetes_pod_node_name
+      #  targetLabel: node
   priorityClassName: system-node-critical
 
 controller:"
thaum-xyz,ankhmorpork,a77fc4f1a68a32ed40c99f04eac927b0b28c8f08,paulfantom,pawel@krupa.net.pl,2024-03-19T11:59:44Z,paulfantom,pawel@krupa.net.pl,2024-03-19T11:59:44Z,apps/immich: fix JSON patch op,apps/immich/release.yaml,False,False,False,False,1,1,2,"---FILE: apps/immich/release.yaml---
@@ -37,5 +37,5 @@ spec:
               kind: Deployment
               name: immich-server
             patch: |-
-              - op: delete
+              - op: remove
                 path: /spec/template/spec/containers/0/livenessProbe"
thaum-xyz,ankhmorpork,2b40699a69d7cf5a00a945c6972a6c1ed7c1b6d7,paulfantom,pawel@krupa.net.pl,2024-03-14T16:19:34Z,paulfantom,pawel@krupa.net.pl,2024-03-14T16:19:34Z,apps/external-dns: fix schema,apps/external-dns/release.yaml,False,False,False,False,1,1,2,"---FILE: apps/external-dns/release.yaml---
@@ -6,7 +6,7 @@ metadata:
 spec:
   chart:
     spec:
-      name: external-dns
+      chart: external-dns
       version: ""6.36.1""
       sourceRef:
         kind: HelmRepository"
thaum-xyz,ankhmorpork,4680777ff31fdef4bf5ad973a74390b3db12848c,paulfantom,pawel@krupa.net.pl,2024-03-12T07:50:07Z,paulfantom,pawel@krupa.net.pl,2024-03-12T07:50:07Z,apps/homer: downgrade to circumvent https://github.com/bastienwirtz/homer/issues/753,apps/homer/manifests/homer/deployment.yaml;apps/homer/manifests/homer/ingress.yaml;apps/homer/manifests/homer/service.yaml;apps/homer/manifests/homer/serviceAccount.yaml;apps/homer/settings.yaml,False,False,False,False,8,8,16,"---FILE: apps/homer/manifests/homer/deployment.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: server
     app.kubernetes.io/name: homer
     app.kubernetes.io/part-of: homer
-    app.kubernetes.io/version: 24.02.1
+    app.kubernetes.io/version: 23.10.1
   name: homer
   namespace: homer
 spec:
@@ -23,7 +23,7 @@ spec:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homer
         app.kubernetes.io/part-of: homer
-        app.kubernetes.io/version: 24.02.1
+        app.kubernetes.io/version: 23.10.1
     spec:
       affinity:
         podAntiAffinity:
@@ -38,7 +38,7 @@ spec:
                 topologyKey: kubernetes.io/hostname
               weight: 100
       containers:
-        - image: b4bz/homer:v24.02.1
+        - image: ghcr.io/bastienwirtz/homer:v23.10.1
           imagePullPolicy: IfNotPresent
           name: homer
           ports:

---FILE: apps/homer/manifests/homer/ingress.yaml---
@@ -7,7 +7,7 @@ metadata:
     app.kubernetes.io/component: server
     app.kubernetes.io/name: homer
     app.kubernetes.io/part-of: homer
-    app.kubernetes.io/version: 24.02.1
+    app.kubernetes.io/version: 23.10.1
     probe: enabled
   name: homer
   namespace: homer

---FILE: apps/homer/manifests/homer/service.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: server
     app.kubernetes.io/name: homer
     app.kubernetes.io/part-of: homer
-    app.kubernetes.io/version: 24.02.1
+    app.kubernetes.io/version: 23.10.1
   name: homer
   namespace: homer
 spec:

---FILE: apps/homer/manifests/homer/serviceAccount.yaml---
@@ -6,6 +6,6 @@ metadata:
     app.kubernetes.io/component: server
     app.kubernetes.io/name: homer
     app.kubernetes.io/part-of: homer
-    app.kubernetes.io/version: 24.02.1
+    app.kubernetes.io/version: 23.10.1
   name: homer
   namespace: homer

---FILE: apps/homer/settings.yaml---
@@ -1,7 +1,7 @@
 ---
 homer:
-  version: ""24.02.1""  # application-version-from-github: bastienwirtz/homer
-  image: ""b4bz/homer:v24.02.1""  # application-image-from-github: bastienwirtz/homer
+  version: ""23.10.1""  # application-version-from-github: bastienwirtz/homer
+  image: ""ghcr.io/bastienwirtz/homer:v23.10.1""  # application-image-from-github: bastienwirtz/homer
   namespace: ""homer""
   replicas: 2
   domain: ""ankhmorpork.thaum.xyz"""
thaum-xyz,ankhmorpork,bbc1e2eecb3a840f3516d37988e2be87d135e10e,paulfantom,pawel@krupa.net.pl,2024-03-11T20:27:13Z,paulfantom,pawel@krupa.net.pl,2024-03-11T20:27:13Z,immich: fix pvc name,apps/immich/values.yaml,False,False,False,False,1,1,2,"---FILE: apps/immich/values.yaml---
@@ -18,7 +18,7 @@ env:
 immich:
   persistence:
     library:
-      existingClaim: immich-library-pvc
+      existingClaim: immich-library
 
 postgresql:
   # Postgres is provided by cnpg"
thaum-xyz,ankhmorpork,c1f3be89490a0ddf70ab07d21011cb8070ed7031,paulfantom,pawel@krupa.net.pl,2024-02-26T22:05:19Z,paulfantom,pawel@krupa.net.pl,2024-02-26T22:05:19Z,apps/minio: fix servicemonitor regex,apps/minio/values.yaml,False,False,False,False,2,2,4,"---FILE: apps/minio/values.yaml---
@@ -54,7 +54,7 @@ metrics:
         regex: 'minio_cluster_.*'
         action: drop
       - sourceLabels: [server]
-        regex: '([a-z-0-1]+).([a-z-0-1]+).*'
+        regex: '([a-z-0-9]+).([a-z-0-9]+).*'
         replacement: ""${1}.${2}""
         targetLabel: server
     relabelConfigsCluster:
@@ -64,7 +64,7 @@ metrics:
         regex: 'minio_audit_.*|minio_inter_node_traffic_.*|minio_notify_current_send_in_progress|minio_s3_requests_.*|minio_software_.*'
         action: drop
       - sourceLabels: [server]
-        regex: '([a-z-0-1]+).([a-z-0-1]+).*'
+        regex: '([a-z-0-9]+).([a-z-0-9]+).*'
         replacement: ""${1}.${2}""
         targetLabel: server
       # Replace server label as it unnecesarily differentiates cluster-level metrics"
thaum-xyz,ankhmorpork,ebe54fa4fca157944fde116bcde5d709e8cc28d2,paulfantom,pawel@krupa.net.pl,2024-02-26T20:32:12Z,paulfantom,pawel@krupa.net.pl,2024-02-26T20:32:12Z,metal: fix lvm script creation,metal/01_system.yml;metal/group_vars/all.yml;metal/inventory,False,False,False,False,10,9,19,"---FILE: metal/01_system.yml---
@@ -96,14 +96,14 @@
   - name: Download textfile collector scripts
     get_url:
       url: ""{{ item.url }}""
-      dest: ""/usr/local/bin/{{ item.file }}""
+      dest: ""{{ item.exec }}""
       mode: 0755
     loop: ""{{ node_exporter_scripts }}""
   - name: Set cronjob for textfile scripts
     cron:
       cron_file: ""/etc/cron.d/metrics""
       user: root
       name: ""{{ item.name }}""
-      minute: ""*/10""
-      job: ""/usr/local/bin/{{ item.file }} | sponge /var/lib/node_exporter/{{ item.name }}.prom""
+      minute: ""*/5""
+      job: ""{{ item.exec }} {{ item.params | default('') }} | sponge /var/lib/node_exporter/{{ item.name }}.prom""
     loop: ""{{ node_exporter_scripts }}""

---FILE: metal/group_vars/all.yml---
@@ -19,11 +19,12 @@ systemd_exporter_unit_blacklist: '.*.mount|user-runtime-dir@0.service'
 
 node_exporter_scripts:
   - name: apt
-    file: apt_info.py
+    exec: /usr/local/bin/apt_info.py
     url: ""https://raw.githubusercontent.com/prometheus-community/node-exporter-textfile-collector-scripts/master/apt_info.py""
   - name: smartmon
-    file: smartmon.sh
+    exec: /usr/local/bin/smartmon.sh
     url: ""https://raw.githubusercontent.com/prometheus-community/node-exporter-textfile-collector-scripts/master/smartmon.sh""
   - name: lvm
-    file: lvm.sh
+    exec: /usr/local/bin/lvm.sh
     url: ""https://raw.githubusercontent.com/prometheus-community/node-exporter-textfile-collector-scripts/master/lvm-prom-collector""
+    params: ""-a""

---FILE: metal/inventory---
@@ -8,18 +8,18 @@ master02 ansible_host=192.168.2.32
 master03  ansible_host=192.168.2.33
 
 metal01  ansible_host=192.168.2.40
-metal02  ansible_host=192.168.2.41
+#metal02  ansible_host=192.168.2.41
 
 [nvidia]
 metal01
-metal02
+#metal02
 
 [k3s_control_plane]
 master0[1:3]
 
 [k3s_nodes]
 metal01
-metal02
+#metal02
 
 [k3s:children]
 k3s_control_plane"
thaum-xyz,ankhmorpork,7c8736cd12c0106ed04c0cbc2cd660305bc54fdb,paulfantom,pawel@krupa.net.pl,2024-02-24T10:55:26Z,paulfantom,pawel@krupa.net.pl,2024-02-24T10:55:26Z,apps/monitoring: fix logo on portal site,apps/monitoring/jsonnet/main.jsonnet;apps/monitoring/manifests/alertmanager/ingress.yaml;apps/monitoring/manifests/prometheus/ingress.yaml,False,False,False,False,3,3,6,"---FILE: apps/monitoring/jsonnet/main.jsonnet---
@@ -43,7 +43,7 @@ local ingress(metadata, domain, service) = {
       'cert-manager.io/cluster-issuer': 'letsencrypt-prod',
       'traefik.ingress.kubernetes.io/router.middlewares': 'auth-traefik-forward-auth@kubernetescrd',
       'reloader.homer/group': 'Administration',
-      'reloader.homer/logo': 'https://github.com/cncf/artwork/blob/master/projects/prometheus/icon/color/prometheus-icon-color.png',  // Default to prometheus logo
+      'reloader.homer/logo': 'https://github.com/cncf/artwork/blob/main/projects/prometheus/icon/color/prometheus-icon-color.png?raw=true',  // Default to prometheus logo
       'reloader.homer/name': $.metadata.name,
       'probe-uri': '/-/healthy',
     },

---FILE: apps/monitoring/manifests/alertmanager/ingress.yaml---
@@ -6,7 +6,7 @@ metadata:
     ignore-check.kube-linter.io/dangling-service: Check is incompatible with prometheus-operator CRDs
     probe-uri: /-/healthy
     reloader.homer/group: Administration
-    reloader.homer/logo: https://github.com/cncf/artwork/blob/master/projects/prometheus/icon/color/prometheus-icon-color.png
+    reloader.homer/logo: https://github.com/cncf/artwork/blob/main/projects/prometheus/icon/color/prometheus-icon-color.png?raw=true
     reloader.homer/name: alertmanager
     traefik.ingress.kubernetes.io/router.middlewares: auth-traefik-forward-auth@kubernetescrd
     traefik.ingress.kubernetes.io/service.sticky.cookie: ""true""

---FILE: apps/monitoring/manifests/prometheus/ingress.yaml---
@@ -6,7 +6,7 @@ metadata:
     ignore-check.kube-linter.io/dangling-service: Check is incompatible with prometheus-operator CRDs
     probe-uri: /-/healthy
     reloader.homer/group: Administration
-    reloader.homer/logo: https://github.com/cncf/artwork/blob/master/projects/prometheus/icon/color/prometheus-icon-color.png
+    reloader.homer/logo: https://github.com/cncf/artwork/blob/main/projects/prometheus/icon/color/prometheus-icon-color.png?raw=true
     reloader.homer/name: prometheus-k8s
     traefik.ingress.kubernetes.io/router.middlewares: auth-traefik-forward-auth@kubernetescrd
     traefik.ingress.kubernetes.io/service.sticky.cookie: ""true"""
thaum-xyz,ankhmorpork,87ac526ef82eafa5621fa80ead4837041159d6a4,paulfantom,pawel@krupa.net.pl,2024-02-19T20:23:01Z,paulfantom,pawel@krupa.net.pl,2024-02-19T20:23:01Z,apps/homeassistant: fix parsing data from tandoor,apps/homeassistant/config/configuration.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,17,17,34,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -193,22 +193,22 @@ rest:
         unique_id: ""meal_today_breakfast""
         value_template: >
           {% set data = value_json | selectattr('meal_type.order', 'eq', 0) | first | default({}) -%}
-          {{ data.title if data.title else data.recipe_name | default() }}
+          {{ data.title if data.title is defined else data.recipe_name | default() }}
       - name: ""Today's Lunch""
         unique_id: ""meal_today_lunch""
         value_template: >
           {% set data = value_json | selectattr('meal_type.order', 'eq', 1) | first | default({}) -%}
-          {{ data.title if data.title else data.recipe_name | default() }}
+          {{ data.title if data.title is defined else data.recipe_name | default() }}
       - name: ""Today's Snack""
         unique_id: ""meal_today_snack""
         value_template: >
           {% set data = value_json | selectattr('meal_type.order', 'eq', 2) | first | default({}) -%}
-          {{ data.title if data.title else data.recipe_name | default() }}
+          {{ data.title if data.title is defined else data.recipe_name | default() }}
       - name: ""Today's Dinner""
         unique_id: ""meal_today_dinner""
         value_template: >
           {% set data = value_json | selectattr('meal_type.order', 'eq', 3) | first | default({}) -%}
-          {{ data.title if data.title else data.recipe_name | default() }}
+          {{ data.title if data.title is defined else data.recipe_name | default() }}
         json_attributes_path: ""$.[?(@.meal_type.order==3)].recipe""
         json_attributes:
           - image
@@ -229,22 +229,22 @@ rest:
         unique_id: ""meal_tomorrow_breakfast""
         value_template: >
           {% set data = value_json | selectattr('meal_type.order', 'eq', 0) | first | default({}) -%}
-          {{ data.title if data.title else data.recipe_name | default() }}
+          {{ data.title if data.title is defined else data.recipe_name | default() }}
       - name: ""Tomorrow's Lunch""
         unique_id: ""meal_tomorrow_lunch""
         value_template: >
           {% set data = value_json | selectattr('meal_type.order', 'eq', 1) | first | default({}) -%}
-          {{ data.title if data.title else data.recipe_name | default() }}
+          {{ data.title if data.title is defined else data.recipe_name | default() }}
       - name: ""Tomorrow's Snack""
         unique_id: ""meal_tomorrow_snack""
         value_template: >
           {% set data = value_json | selectattr('meal_type.order', 'eq', 2) | first | default({}) -%}
-          {{ data.title if data.title else data.recipe_name | default() }}
+          {{ data.title if data.title is defined else data.recipe_name | default() }}
       - name: ""Tomorrow's Dinner""
         unique_id: ""meal_tomorrow_dinner""
         value_template: >
           {% set data = value_json | selectattr('meal_type.order', 'eq', 3) | first | default({}) -%}
-          {{ data.title if data.title else data.recipe_name | default() }}
+          {{ data.title if data.title is defined else data.recipe_name | default() }}
         json_attributes_path: ""$.[?(@.meal_type.order==3)].recipe""
         json_attributes:
           - image

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -196,22 +196,22 @@ data:
             unique_id: ""meal_today_breakfast""
             value_template: >
               {% set data = value_json | selectattr('meal_type.order', 'eq', 0) | first | default({}) -%}
-              {{ data.title if data.title else data.recipe_name | default() }}
+              {{ data.title if data.title is defined else data.recipe_name | default() }}
           - name: ""Today's Lunch""
             unique_id: ""meal_today_lunch""
             value_template: >
               {% set data = value_json | selectattr('meal_type.order', 'eq', 1) | first | default({}) -%}
-              {{ data.title if data.title else data.recipe_name | default() }}
+              {{ data.title if data.title is defined else data.recipe_name | default() }}
           - name: ""Today's Snack""
             unique_id: ""meal_today_snack""
             value_template: >
               {% set data = value_json | selectattr('meal_type.order', 'eq', 2) | first | default({}) -%}
-              {{ data.title if data.title else data.recipe_name | default() }}
+              {{ data.title if data.title is defined else data.recipe_name | default() }}
           - name: ""Today's Dinner""
             unique_id: ""meal_today_dinner""
             value_template: >
               {% set data = value_json | selectattr('meal_type.order', 'eq', 3) | first | default({}) -%}
-              {{ data.title if data.title else data.recipe_name | default() }}
+              {{ data.title if data.title is defined else data.recipe_name | default() }}
             json_attributes_path: ""$.[?(@.meal_type.order==3)].recipe""
             json_attributes:
               - image
@@ -232,22 +232,22 @@ data:
             unique_id: ""meal_tomorrow_breakfast""
             value_template: >
               {% set data = value_json | selectattr('meal_type.order', 'eq', 0) | first | default({}) -%}
-              {{ data.title if data.title else data.recipe_name | default() }}
+              {{ data.title if data.title is defined else data.recipe_name | default() }}
           - name: ""Tomorrow's Lunch""
             unique_id: ""meal_tomorrow_lunch""
             value_template: >
               {% set data = value_json | selectattr('meal_type.order', 'eq', 1) | first | default({}) -%}
-              {{ data.title if data.title else data.recipe_name | default() }}
+              {{ data.title if data.title is defined else data.recipe_name | default() }}
           - name: ""Tomorrow's Snack""
             unique_id: ""meal_tomorrow_snack""
             value_template: >
               {% set data = value_json | selectattr('meal_type.order', 'eq', 2) | first | default({}) -%}
-              {{ data.title if data.title else data.recipe_name | default() }}
+              {{ data.title if data.title is defined else data.recipe_name | default() }}
           - name: ""Tomorrow's Dinner""
             unique_id: ""meal_tomorrow_dinner""
             value_template: >
               {% set data = value_json | selectattr('meal_type.order', 'eq', 3) | first | default({}) -%}
-              {{ data.title if data.title else data.recipe_name | default() }}
+              {{ data.title if data.title is defined else data.recipe_name | default() }}
             json_attributes_path: ""$.[?(@.meal_type.order==3)].recipe""
             json_attributes:
               - image

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: 3a874a41cc7988c98e85c486dfbbbd8b
+        checksum.config/md5: 34720d79d3564ae9baca60518cef9e5f
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,fd952afbd5853f7facbb243605f1d79891c2f4c2,paulfantom,pawel@krupa.net.pl,2024-02-10T15:40:37Z,paulfantom,pawel@krupa.net.pl,2024-02-10T15:40:37Z,base/kube-system: fix intel gpu NFD rules,base/kube-system/manifests/device-plugins/intel-gpu-nfd.yaml,False,False,False,False,109,192,301,"---FILE: base/kube-system/manifests/device-plugins/intel-gpu-nfd.yaml---
@@ -1,197 +1,114 @@
 apiVersion: nfd.k8s-sigs.io/v1alpha1
 kind: NodeFeatureRule
 metadata:
-  name: intel-gpu-platform-labeling
+  name: intel-dp-devices
 spec:
   rules:
-  - extendedResources:
-      gpu.intel.com/millicores: ""@local.label.gpu.intel.com/millicores""
-      gpu.intel.com/memory.max: ""@local.label.gpu.intel.com/memory.max""
-      gpu.intel.com/tiles: ""@local.label.gpu.intel.com/tiles""
-    matchFeatures:
-      - feature: local.label
-        matchExpressions:
-          gpu.intel.com/millicores: {op: Exists}
-          gpu.intel.com/memory.max: {op: Exists}
-          gpu.intel.com/tiles: {op: Exists}
-    name: intel.gpu.fractionalresources
-  # generic rule for older and upcoming devices
-  - labelsTemplate: |
-      {{ range .pci.device }}gpu.intel.com/device-id.{{ .class }}-{{ .device }}.present=true
-      {{ end }}
-    matchFeatures:
-      - feature: pci.device
-        matchExpressions:
-          class:
-            op: In
-            value:
-            - ""0300""
-            - ""0380""
-          vendor:
-            op: In
-            value:
-            - ""8086""
-    name: intel.gpu.generic.deviceid
-  - labelsTemplate: gpu.intel.com/device-id.0300-{{ (index .pci.device 0).device }}.count={{ len .pci.device }}
-    matchFeatures:
-      - feature: pci.device
-        matchExpressions:
-          class:
-            op: In
-            value:
-            - ""0300""
-          vendor:
-            op: In
-            value:
-            - ""8086""
-    name: intel.gpu.generic.count.300
-  - labelsTemplate: gpu.intel.com/device-id.0380-{{ (index .pci.device 0).device }}.count={{ len .pci.device }}
-    matchFeatures:
-      - feature: pci.device
-        matchExpressions:
-          class:
-            op: In
-            value:
-            - ""0380""
-          vendor:
-            op: In
-            value:
-            - ""8086""
-    name: intel.gpu.generic.count.380
-  - labels:
-      gpu.intel.com/product: ""Max_1100""
-    labelsTemplate: ""gpu.intel.com/device.count={{ len .pci.device }}""
-    matchFeatures:
-    - feature: pci.device
-      matchExpressions:
-        class:
-          op: In
-          value:
-          - ""0380""
-        vendor:
-          op: In
-          value:
-          - ""8086""
-        device:
-          op: In
-          value:
-          - ""0bda""
-    name: intel.gpu.max.1100
-  - labels:
-      gpu.intel.com/product: ""Max_1550""
-    labelsTemplate: ""gpu.intel.com/device.count={{ len .pci.device }}""
-    matchFeatures:
-    - feature: pci.device
-      matchExpressions:
-        class:
-          op: In
-          value:
-          - ""0380""
-        vendor:
-          op: In
-          value:
-          - ""8086""
-        device:
-          op: In
-          value:
-          - ""0bd5""
-    name: intel.gpu.max.1550
-  - labels:
-      gpu.intel.com/family: ""Max_Series""
-    matchFeatures:
-    - feature: pci.device
-      matchExpressions:
-        class:
-          op: In
-          value:
-          - ""0380""
-        vendor:
-          op: In
-          value:
-          - ""8086""
-        device:
-          op: In
-          value:
-          - ""0bda""
-          - ""0bd5""
-          - ""0bd9""
-          - ""0bdb""
-          - ""0bd7""
-          - ""0bd6""
-          - ""0bd0""
-    name: intel.gpu.max.series
-  - labels:
-      gpu.intel.com/family: ""Flex_Series""
-      gpu.intel.com/product: ""Flex_170""
-    labelsTemplate: ""gpu.intel.com/device.count={{ len .pci.device }}""
-    matchFeatures:
-    - feature: pci.device
-      matchExpressions:
-        class:
-          op: In
-          value:
-          - ""0380""
-        vendor:
-          op: In
-          value:
-          - ""8086""
-        device:
-          op: In
-          value:
-          - ""56c0""
-    name: intel.gpu.flex.170
-  - labels:
-      gpu.intel.com/family: ""Flex_Series""
-      gpu.intel.com/product: ""Flex_140""
-    labelsTemplate: ""gpu.intel.com/device.count={{ len .pci.device }}""
-    matchFeatures:
-    - feature: pci.device
-      matchExpressions:
-        class:
-          op: In
-          value:
-          - ""0380""
-        vendor:
-          op: In
-          value:
-          - ""8086""
-        device:
-          op: In
-          value:
-          - ""56c1""
-    name: intel.gpu.flex.140
-  - labels:
-      gpu.intel.com/family: ""A_Series""
-    matchFeatures:
-    - feature: pci.device
-      matchExpressions:
-        class:
-          op: In
-          value:
-          - ""0300""
-        vendor:
-          op: In
-          value:
-          - ""8086""
-        device:
-          op: In
-          value:
-          - ""56a6""
-          - ""56a5""
-          - ""56a1""
-          - ""56a0""
-          - ""5694""
-          - ""5693""
-          - ""5692""
-          - ""5691""
-          - ""5690""
-          - ""56b3""
-          - ""56b2""
-          - ""56a4""
-          - ""56a3""
-          - ""5697""
-          - ""5696""
-          - ""5695""
-          - ""56b1""
-          - ""56b0""
-    name: intel.gpu.a.series
+    - name: ""intel.dlb""
+      labels:
+        ""intel.feature.node.kubernetes.io/dlb"": ""true""
+      matchFeatures:
+        - feature: pci.device
+          matchExpressions:
+            vendor: {op: In, value: [""8086""]}
+            device: {op: In, value: [""2710""]}
+            class: {op: In, value: [""0b40""]}
+        - feature: kernel.loadedmodule
+          matchExpressions:
+            dlb2: {op: Exists}
+
+    - name: ""intel.dsa""
+      labels:
+        ""intel.feature.node.kubernetes.io/dsa"": ""true""
+      matchFeatures:
+        - feature: pci.device
+          matchExpressions:
+            vendor: {op: In, value: [""8086""]}
+            device: {op: In, value: [""0b25""]}
+            class: {op: In, value: [""0880""]}
+        - feature: kernel.loadedmodule
+          matchExpressions:
+            idxd: {op: Exists}
+
+    - name: ""intel.fpga-arria10""
+      labels:
+        ""intel.feature.node.kubernetes.io/fpga-arria10"": ""true""
+      matchFeatures:
+        - feature: pci.device
+          matchExpressions:
+            vendor: {op: In, value: [""8086""]}
+            device: {op: In, value: [""09c4""]}
+            class: {op: In, value: [""1200""]}
+      matchAny:
+        - matchFeatures:
+            - feature: kernel.loadedmodule
+              matchExpressions:
+                dfl_pci: {op: Exists}
+        - matchFeatures:
+            - feature: kernel.loadedmodule
+              matchExpressions:
+                intel_fpga_pci: {op: Exists}
+
+    - name: ""intel.gpu""
+      labels:
+        ""intel.feature.node.kubernetes.io/gpu"": ""true""
+      matchFeatures:
+        - feature: pci.device
+          matchExpressions:
+            vendor: {op: In, value: [""8086""]}
+            class: {op: In, value: [""0300"", ""0380""]}
+        - feature: kernel.loadedmodule
+          matchExpressions:
+            i915: {op: Exists}
+
+    - name: ""intel.iaa""
+      labels:
+        ""intel.feature.node.kubernetes.io/iaa"": ""true""
+      matchFeatures:
+        - feature: pci.device
+          matchExpressions:
+            vendor: {op: In, value: [""8086""]}
+            device: {op: In, value: [""0cfe""]}
+            class: {op: In, value: [""0880""]}
+        - feature: kernel.loadedmodule
+          matchExpressions:
+            idxd: {op: Exists}
+
+    - name: ""intel.qat""
+      labels:
+        ""intel.feature.node.kubernetes.io/qat"": ""true""
+      matchFeatures:
+        - feature: pci.device
+          matchExpressions:
+            vendor: {op: In, value: [""8086""]}
+            device: {op: In, value: [""37c8"", ""4940"", ""4942"", ""4944""]}
+            class: {op: In, value: [""0b40""]}
+        - feature: kernel.loadedmodule
+          matchExpressions:
+            intel_qat: {op: Exists}
+      matchAny:
+        - matchFeatures:
+          - feature: kernel.loadedmodule
+            matchExpressions:
+              vfio_pci: {op: Exists}
+        - matchFeatures:
+          - feature: kernel.enabledmodule
+            matchExpressions:
+              vfio-pci: {op: Exists}
+
+    - name: ""intel.sgx""
+      labels:
+        ""intel.feature.node.kubernetes.io/sgx"": ""true""
+      extendedResources:
+        sgx.intel.com/epc: ""@cpu.security.sgx.epc""
+      matchFeatures:
+        - feature: cpu.cpuid
+          matchExpressions:
+            SGX: {op: Exists}
+            SGXLC: {op: Exists}
+        - feature: cpu.security
+          matchExpressions:
+            sgx.enabled: {op: IsTrue}
+        - feature: kernel.config
+          matchExpressions:
+            X86_SGX: {op: Exists}"
thaum-xyz,ankhmorpork,9e25b5e86c772707c728090918cdf6398ca0887a,paulfantom,pawel@krupa.net.pl,2024-02-08T19:21:28Z,paulfantom,pawel@krupa.net.pl,2024-02-08T19:21:28Z,apps/homeassistant: fix configuration templates for other sensor,apps/homeassistant/config/configuration.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,11,11,22,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -192,24 +192,24 @@ rest:
       - name: ""Today's Breakfast""
         unique_id: ""meal_today_breakfast""
         value_template: >
-          {% set data = value_json | selectattr('meal_type.order', 'eq', 'Breakfast') | first -%}
+          {% set data = value_json | selectattr('meal_type.order', 'eq', 0) | first | default({}) -%}
           {{ data.title if data.title else data.recipe_name | default() }}
       - name: ""Today's Lunch""
         unique_id: ""meal_today_lunch""
         value_template: >
-          {% set data = value_json | selectattr('meal_type.order', 'eq', 'Lunch') | first -%}
+          {% set data = value_json | selectattr('meal_type.order', 'eq', 1) | first | default({}) -%}
           {{ data.title if data.title else data.recipe_name | default() }}
       - name: ""Today's Snack""
         unique_id: ""meal_today_snack""
         value_template: >
-          {% set data = value_json | selectattr('meal_type.order', 'eq', 'Snack') | first -%}
+          {% set data = value_json | selectattr('meal_type.order', 'eq', 2) | first | default({}) -%}
           {{ data.title if data.title else data.recipe_name | default() }}
       - name: ""Today's Dinner""
         unique_id: ""meal_today_dinner""
         value_template: >
-          {% set data = value_json | selectattr('meal_type.order', 'eq', 'Dinner') | first -%}
+          {% set data = value_json | selectattr('meal_type.order', 'eq', 3) | first | default({}) -%}
           {{ data.title if data.title else data.recipe_name | default() }}
-        json_attributes_path: ""$.[?(@.meal_type_name=='Dinnert')].recipe""
+        json_attributes_path: ""$.[?(@.meal_type.order==3)].recipe""
         json_attributes:
           - image
           - id

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -195,24 +195,24 @@ data:
           - name: ""Today's Breakfast""
             unique_id: ""meal_today_breakfast""
             value_template: >
-              {% set data = value_json | selectattr('meal_type.order', 'eq', 'Breakfast') | first -%}
+              {% set data = value_json | selectattr('meal_type.order', 'eq', 0) | first | default({}) -%}
               {{ data.title if data.title else data.recipe_name | default() }}
           - name: ""Today's Lunch""
             unique_id: ""meal_today_lunch""
             value_template: >
-              {% set data = value_json | selectattr('meal_type.order', 'eq', 'Lunch') | first -%}
+              {% set data = value_json | selectattr('meal_type.order', 'eq', 1) | first | default({}) -%}
               {{ data.title if data.title else data.recipe_name | default() }}
           - name: ""Today's Snack""
             unique_id: ""meal_today_snack""
             value_template: >
-              {% set data = value_json | selectattr('meal_type.order', 'eq', 'Snack') | first -%}
+              {% set data = value_json | selectattr('meal_type.order', 'eq', 2) | first | default({}) -%}
               {{ data.title if data.title else data.recipe_name | default() }}
           - name: ""Today's Dinner""
             unique_id: ""meal_today_dinner""
             value_template: >
-              {% set data = value_json | selectattr('meal_type.order', 'eq', 'Dinner') | first -%}
+              {% set data = value_json | selectattr('meal_type.order', 'eq', 3) | first | default({}) -%}
               {{ data.title if data.title else data.recipe_name | default() }}
-            json_attributes_path: ""$.[?(@.meal_type_name=='Dinnert')].recipe""
+            json_attributes_path: ""$.[?(@.meal_type.order==3)].recipe""
             json_attributes:
               - image
               - id

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: c136068740521a1090ce8491b3b3e924
+        checksum.config/md5: 3a874a41cc7988c98e85c486dfbbbd8b
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,63677dd15a991b2eada0f37ef24fb8b0298d05af,paulfantom,pawel@krupa.net.pl,2024-02-08T19:18:05Z,paulfantom,pawel@krupa.net.pl,2024-02-08T19:18:05Z,apps/homeassistant: fix configuration templates again,apps/homeassistant/config/configuration.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,11,11,22,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -228,22 +228,22 @@ rest:
       - name: ""Tomorrow's Breakfast""
         unique_id: ""meal_tomorrow_breakfast""
         value_template: >
-          {% set data = value_json | selectattr('meal_type.order', 'eq', 0) | first -%}
+          {% set data = value_json | selectattr('meal_type.order', 'eq', 0) | first | default({}) -%}
           {{ data.title if data.title else data.recipe_name | default() }}
       - name: ""Tomorrow's Lunch""
         unique_id: ""meal_tomorrow_lunch""
         value_template: >
-          {% set data = value_json | selectattr('meal_type.order', 'eq', 1) | first -%}
+          {% set data = value_json | selectattr('meal_type.order', 'eq', 1) | first | default({}) -%}
           {{ data.title if data.title else data.recipe_name | default() }}
       - name: ""Tomorrow's Snack""
         unique_id: ""meal_tomorrow_snack""
         value_template: >
-          {% set data = value_json | selectattr('meal_type.order', 'eq', 2) | first -%}
+          {% set data = value_json | selectattr('meal_type.order', 'eq', 2) | first | default({}) -%}
           {{ data.title if data.title else data.recipe_name | default() }}
       - name: ""Tomorrow's Dinner""
         unique_id: ""meal_tomorrow_dinner""
         value_template: >
-          {% set data = value_json | selectattr('meal_type.order', 'eq', 3) | first -%}
+          {% set data = value_json | selectattr('meal_type.order', 'eq', 3) | first | default({}) -%}
           {{ data.title if data.title else data.recipe_name | default() }}
         json_attributes_path: ""$.[?(@.meal_type.order==3)].recipe""
         json_attributes:
@@ -325,7 +325,7 @@ switch:
       projector:
         friendly_name: ""Projector""
         unique_id: projector_benq
-        icon: ""mdi:projector""
+        icon_template: ""mdi:projector""
         turn_on:
         - service: remote.send_command
           data:

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -231,22 +231,22 @@ data:
           - name: ""Tomorrow's Breakfast""
             unique_id: ""meal_tomorrow_breakfast""
             value_template: >
-              {% set data = value_json | selectattr('meal_type.order', 'eq', 0) | first -%}
+              {% set data = value_json | selectattr('meal_type.order', 'eq', 0) | first | default({}) -%}
               {{ data.title if data.title else data.recipe_name | default() }}
           - name: ""Tomorrow's Lunch""
             unique_id: ""meal_tomorrow_lunch""
             value_template: >
-              {% set data = value_json | selectattr('meal_type.order', 'eq', 1) | first -%}
+              {% set data = value_json | selectattr('meal_type.order', 'eq', 1) | first | default({}) -%}
               {{ data.title if data.title else data.recipe_name | default() }}
           - name: ""Tomorrow's Snack""
             unique_id: ""meal_tomorrow_snack""
             value_template: >
-              {% set data = value_json | selectattr('meal_type.order', 'eq', 2) | first -%}
+              {% set data = value_json | selectattr('meal_type.order', 'eq', 2) | first | default({}) -%}
               {{ data.title if data.title else data.recipe_name | default() }}
           - name: ""Tomorrow's Dinner""
             unique_id: ""meal_tomorrow_dinner""
             value_template: >
-              {% set data = value_json | selectattr('meal_type.order', 'eq', 3) | first -%}
+              {% set data = value_json | selectattr('meal_type.order', 'eq', 3) | first | default({}) -%}
               {{ data.title if data.title else data.recipe_name | default() }}
             json_attributes_path: ""$.[?(@.meal_type.order==3)].recipe""
             json_attributes:
@@ -328,7 +328,7 @@ data:
           projector:
             friendly_name: ""Projector""
             unique_id: projector_benq
-            icon: ""mdi:projector""
+            icon_template: ""mdi:projector""
             turn_on:
             - service: remote.send_command
               data:

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: 8482f637b941f81318c00b3773294e9c
+        checksum.config/md5: c136068740521a1090ce8491b3b3e924
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,d44c4f46ad4504ac401b98a0a835be3ff575f1b7,paulfantom,pawel@krupa.net.pl,2024-02-08T19:10:31Z,paulfantom,pawel@krupa.net.pl,2024-02-08T19:10:31Z,apps/homeassistant: fix configuration templates,apps/homeassistant/config/configuration.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,23,31,54,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -192,22 +192,22 @@ rest:
       - name: ""Today's Breakfast""
         unique_id: ""meal_today_breakfast""
         value_template: >
-          {% set data = value_json | selectattr('meal_type_name', 'eq', 'Breakfast') | first -%}
+          {% set data = value_json | selectattr('meal_type.order', 'eq', 'Breakfast') | first -%}
           {{ data.title if data.title else data.recipe_name | default() }}
       - name: ""Today's Lunch""
         unique_id: ""meal_today_lunch""
         value_template: >
-          {% set data = value_json | selectattr('meal_type_name', 'eq', 'Lunch') | first -%}
+          {% set data = value_json | selectattr('meal_type.order', 'eq', 'Lunch') | first -%}
           {{ data.title if data.title else data.recipe_name | default() }}
       - name: ""Today's Snack""
         unique_id: ""meal_today_snack""
         value_template: >
-          {% set data = value_json | selectattr('meal_type_name', 'eq', 'Snack') | first -%}
+          {% set data = value_json | selectattr('meal_type.order', 'eq', 'Snack') | first -%}
           {{ data.title if data.title else data.recipe_name | default() }}
       - name: ""Today's Dinner""
         unique_id: ""meal_today_dinner""
         value_template: >
-          {% set data = value_json | selectattr('meal_type_name', 'eq', 'Dinner') | first -%}
+          {% set data = value_json | selectattr('meal_type.order', 'eq', 'Dinner') | first -%}
           {{ data.title if data.title else data.recipe_name | default() }}
         json_attributes_path: ""$.[?(@.meal_type_name=='Dinnert')].recipe""
         json_attributes:
@@ -228,24 +228,24 @@ rest:
       - name: ""Tomorrow's Breakfast""
         unique_id: ""meal_tomorrow_breakfast""
         value_template: >
-          {% set data = value_json | selectattr('meal_type_name', 'eq', 'Breakfast') | first -%}
+          {% set data = value_json | selectattr('meal_type.order', 'eq', 0) | first -%}
           {{ data.title if data.title else data.recipe_name | default() }}
       - name: ""Tomorrow's Lunch""
         unique_id: ""meal_tomorrow_lunch""
         value_template: >
-          {% set data = value_json | selectattr('meal_type_name', 'eq', 'Lunch') | first -%}
+          {% set data = value_json | selectattr('meal_type.order', 'eq', 1) | first -%}
           {{ data.title if data.title else data.recipe_name | default() }}
       - name: ""Tomorrow's Snack""
         unique_id: ""meal_tomorrow_snack""
         value_template: >
-          {% set data = value_json | selectattr('meal_type_name', 'eq', 'Snack') | first -%}
+          {% set data = value_json | selectattr('meal_type.order', 'eq', 2) | first -%}
           {{ data.title if data.title else data.recipe_name | default() }}
       - name: ""Tomorrow's Dinner""
         unique_id: ""meal_tomorrow_dinner""
         value_template: >
-          {% set data = value_json | selectattr('meal_type_name', 'eq', 'Dinner') | first -%}
+          {% set data = value_json | selectattr('meal_type.order', 'eq', 3) | first -%}
           {{ data.title if data.title else data.recipe_name | default() }}
-        json_attributes_path: ""$.[?(@.meal_type_name=='Dinnert')].recipe""
+        json_attributes_path: ""$.[?(@.meal_type.order==3)].recipe""
         json_attributes:
           - image
           - id
@@ -325,6 +325,7 @@ switch:
       projector:
         friendly_name: ""Projector""
         unique_id: projector_benq
+        icon: ""mdi:projector""
         turn_on:
         - service: remote.send_command
           data:
@@ -343,12 +344,7 @@ switch:
             hold_secs: 0
           target:
             entity_id: remote.broadlink
-        icon_template: >
-          {% if this.state == 'on' %}
-            mdi:projector
-          {% else %}
-            mdi:projector-off
-          {% endif %}
+
   - platform: wake_on_lan
     name: pawel-pc
     host: ""192.168.2.51""

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -195,22 +195,22 @@ data:
           - name: ""Today's Breakfast""
             unique_id: ""meal_today_breakfast""
             value_template: >
-              {% set data = value_json | selectattr('meal_type_name', 'eq', 'Breakfast') | first -%}
+              {% set data = value_json | selectattr('meal_type.order', 'eq', 'Breakfast') | first -%}
               {{ data.title if data.title else data.recipe_name | default() }}
           - name: ""Today's Lunch""
             unique_id: ""meal_today_lunch""
             value_template: >
-              {% set data = value_json | selectattr('meal_type_name', 'eq', 'Lunch') | first -%}
+              {% set data = value_json | selectattr('meal_type.order', 'eq', 'Lunch') | first -%}
               {{ data.title if data.title else data.recipe_name | default() }}
           - name: ""Today's Snack""
             unique_id: ""meal_today_snack""
             value_template: >
-              {% set data = value_json | selectattr('meal_type_name', 'eq', 'Snack') | first -%}
+              {% set data = value_json | selectattr('meal_type.order', 'eq', 'Snack') | first -%}
               {{ data.title if data.title else data.recipe_name | default() }}
           - name: ""Today's Dinner""
             unique_id: ""meal_today_dinner""
             value_template: >
-              {% set data = value_json | selectattr('meal_type_name', 'eq', 'Dinner') | first -%}
+              {% set data = value_json | selectattr('meal_type.order', 'eq', 'Dinner') | first -%}
               {{ data.title if data.title else data.recipe_name | default() }}
             json_attributes_path: ""$.[?(@.meal_type_name=='Dinnert')].recipe""
             json_attributes:
@@ -231,24 +231,24 @@ data:
           - name: ""Tomorrow's Breakfast""
             unique_id: ""meal_tomorrow_breakfast""
             value_template: >
-              {% set data = value_json | selectattr('meal_type_name', 'eq', 'Breakfast') | first -%}
+              {% set data = value_json | selectattr('meal_type.order', 'eq', 0) | first -%}
               {{ data.title if data.title else data.recipe_name | default() }}
           - name: ""Tomorrow's Lunch""
             unique_id: ""meal_tomorrow_lunch""
             value_template: >
-              {% set data = value_json | selectattr('meal_type_name', 'eq', 'Lunch') | first -%}
+              {% set data = value_json | selectattr('meal_type.order', 'eq', 1) | first -%}
               {{ data.title if data.title else data.recipe_name | default() }}
           - name: ""Tomorrow's Snack""
             unique_id: ""meal_tomorrow_snack""
             value_template: >
-              {% set data = value_json | selectattr('meal_type_name', 'eq', 'Snack') | first -%}
+              {% set data = value_json | selectattr('meal_type.order', 'eq', 2) | first -%}
               {{ data.title if data.title else data.recipe_name | default() }}
           - name: ""Tomorrow's Dinner""
             unique_id: ""meal_tomorrow_dinner""
             value_template: >
-              {% set data = value_json | selectattr('meal_type_name', 'eq', 'Dinner') | first -%}
+              {% set data = value_json | selectattr('meal_type.order', 'eq', 3) | first -%}
               {{ data.title if data.title else data.recipe_name | default() }}
-            json_attributes_path: ""$.[?(@.meal_type_name=='Dinnert')].recipe""
+            json_attributes_path: ""$.[?(@.meal_type.order==3)].recipe""
             json_attributes:
               - image
               - id
@@ -328,6 +328,7 @@ data:
           projector:
             friendly_name: ""Projector""
             unique_id: projector_benq
+            icon: ""mdi:projector""
             turn_on:
             - service: remote.send_command
               data:
@@ -346,12 +347,7 @@ data:
                 hold_secs: 0
               target:
                 entity_id: remote.broadlink
-            icon_template: >
-              {% if this.state == 'on' %}
-                mdi:projector
-              {% else %}
-                mdi:projector-off
-              {% endif %}
+
       - platform: wake_on_lan
         name: pawel-pc
         host: ""192.168.2.51""

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: 976cf41e1e1d35435e67f5c743ffa7a5
+        checksum.config/md5: 8482f637b941f81318c00b3773294e9c
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,b6be84e4f0edd0093a384ea01d02f4398801b2be,paulfantom,pawel@krupa.net.pl,2024-02-05T20:23:33Z,paulfantom,pawel@krupa.net.pl,2024-02-05T20:23:33Z,apps/multimedia: fix alert rule,apps/multimedia/jsonnet/arr.libsonnet;apps/multimedia/manifests/prowlarr/prometheusRule.yaml,False,False,False,False,2,2,4,"---FILE: apps/multimedia/jsonnet/arr.libsonnet---
@@ -178,7 +178,7 @@ function(params) {
           annotations: {
             summary: 'One of Prowlarr Indexers stopped working properly',
             description: |||
-              Prowalarr reports problems with indexer - {{ labels.message }}.
+              Prowalarr reports problems with indexer - {{ $labels.message }}.
               For more infromation check {{ $labels.wikiurl }}.
             |||,
           },

---FILE: apps/multimedia/manifests/prowlarr/prometheusRule.yaml---
@@ -45,7 +45,7 @@ spec:
         - alert: ProwlarIndexerUnhealthy
           annotations:
             description: |
-              Prowalarr reports problems with indexer - {{ labels.message }}.
+              Prowalarr reports problems with indexer - {{ $labels.message }}.
               For more infromation check {{ $labels.wikiurl }}.
             summary: One of Prowlarr Indexers stopped working properly
           expr: max_over_time(prowlarr_system_health_issues{job=""prowlarr"",source=""IndexerLongTermStatusCheck""}[1h]) == 1"
thaum-xyz,ankhmorpork,4a51c3ea9ddcb43b03cd92eca6078e0fa9a95d91,paulfantom,pawel@krupa.net.pl,2024-02-05T19:59:08Z,paulfantom,pawel@krupa.net.pl,2024-02-05T19:59:08Z,apps/datalake-metrics: fix container image tag,apps/datalake-metrics/manifests/compact/statefulSet.yaml;apps/datalake-metrics/manifests/query/deployment.yaml;apps/datalake-metrics/manifests/receiveIngestor/ingestor-default-statefulSet.yaml;apps/datalake-metrics/manifests/receiveRouter/deployment.yaml;apps/datalake-metrics/manifests/store/statefulSet.yaml;apps/datalake-metrics/settings.yaml,False,False,False,False,6,6,12,"---FILE: apps/datalake-metrics/manifests/compact/statefulSet.yaml---
@@ -67,7 +67,7 @@ spec:
               valueFrom:
                 fieldRef:
                   fieldPath: status.hostIP
-          image: quay.io/thanos/thanos:0.34.0
+          image: quay.io/thanos/thanos:v0.34.0
           imagePullPolicy: IfNotPresent
           livenessProbe:
             failureThreshold: 4

---FILE: apps/datalake-metrics/manifests/query/deployment.yaml---
@@ -55,7 +55,7 @@ spec:
               valueFrom:
                 fieldRef:
                   fieldPath: status.hostIP
-          image: quay.io/thanos/thanos:0.34.0
+          image: quay.io/thanos/thanos:v0.34.0
           imagePullPolicy: IfNotPresent
           livenessProbe:
             failureThreshold: 4

---FILE: apps/datalake-metrics/manifests/receiveIngestor/ingestor-default-statefulSet.yaml---
@@ -96,7 +96,7 @@ spec:
                 secretKeyRef:
                   key: thanos.yaml
                   name: thanos-objectstorage
-          image: quay.io/thanos/thanos:0.34.0
+          image: quay.io/thanos/thanos:v0.34.0
           imagePullPolicy: IfNotPresent
           livenessProbe:
             failureThreshold: 8

---FILE: apps/datalake-metrics/manifests/receiveRouter/deployment.yaml---
@@ -49,7 +49,7 @@ spec:
               valueFrom:
                 fieldRef:
                   fieldPath: status.hostIP
-          image: quay.io/thanos/thanos:0.34.0
+          image: quay.io/thanos/thanos:v0.34.0
           imagePullPolicy: IfNotPresent
           livenessProbe:
             failureThreshold: 8

---FILE: apps/datalake-metrics/manifests/store/statefulSet.yaml---
@@ -66,7 +66,7 @@ spec:
               valueFrom:
                 fieldRef:
                   fieldPath: status.podIP
-          image: quay.io/thanos/thanos:0.34.0
+          image: quay.io/thanos/thanos:v0.34.0
           imagePullPolicy: IfNotPresent
           livenessProbe:
             failureThreshold: 8

---FILE: apps/datalake-metrics/settings.yaml---
@@ -1,6 +1,6 @@
 ---
 version: '0.34.0'  # application-version-from-github: thanos-io/thanos
-image: ""quay.io/thanos/thanos:0.34.0""  # application-image-from-github: thanos-io/thanos
+image: ""quay.io/thanos/thanos:v0.34.0""  # application-image-from-github: thanos-io/thanos
 namespace: ""datalake-metrics""
 imagePullPolicy: 'IfNotPresent'
 hashringConfigMapName: 'hashring-config'"
thaum-xyz,ankhmorpork,bc60d1eee5c0688d00678dba8f1d915a57f13934,Pawe Krupa,pawel@krupa.net.pl,2024-02-02T16:03:54Z,GitHub,noreply@github.com,2024-02-02T16:03:54Z,fix projector turn off,apps/homeassistant/config/configuration.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml,False,False,False,False,2,22,24,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -333,26 +333,16 @@ switch:
             num_repeats: 1
           target:
             entity_id: remote.broadlink
-        - delay:
-            hours: 0
-            minutes: 0
-            seconds: 15
-            milliseconds: 0
         turn_off:
         - service: remote.send_command
           data:
             device: projector
             command: ""off""
             num_repeats: 2
-            delay_secs: 1
+            delay_secs: 2
             hold_secs: 0
           target:
             entity_id: remote.broadlink
-        - delay:
-            hours: 0
-            minutes: 0
-            seconds: 60
-            milliseconds: 0
         icon_template: >
           {% if this.state == 'on' %}
             mdi:projector

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -336,26 +336,16 @@ data:
                 num_repeats: 1
               target:
                 entity_id: remote.broadlink
-            - delay:
-                hours: 0
-                minutes: 0
-                seconds: 15
-                milliseconds: 0
             turn_off:
             - service: remote.send_command
               data:
                 device: projector
                 command: ""off""
                 num_repeats: 2
-                delay_secs: 60
+                delay_secs: 2
                 hold_secs: 0
               target:
                 entity_id: remote.broadlink
-            - delay:
-                hours: 0
-                minutes: 0
-                seconds: 60
-                milliseconds: 0
             icon_template: >
               {% if this.state == 'on' %}
                 mdi:projector"
thaum-xyz,ankhmorpork,bee03434d7e267e001501950bf8fc75bcd6a99c9,Pawe Krupa,pawel@krupa.net.pl,2024-02-02T15:53:04Z,GitHub,noreply@github.com,2024-02-02T15:53:04Z,fix projector turn on,apps/homeassistant/config/configuration.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml,False,False,False,False,5,3,8,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -328,8 +328,9 @@ switch:
         turn_on:
         - service: remote.send_command
           data:
-            device: Projector
+            device: projector
             command: ""on""
+            num_repeats: 1
           target:
             entity_id: remote.broadlink
         - delay:
@@ -340,7 +341,7 @@ switch:
         turn_off:
         - service: remote.send_command
           data:
-            device: Projector
+            device: projector
             command: ""off""
             num_repeats: 2
             delay_secs: 1

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -333,6 +333,7 @@ data:
               data:
                 device: projector
                 command: ""on""
+                num_repeats: 1
               target:
                 entity_id: remote.broadlink
             - delay:
@@ -346,7 +347,7 @@ data:
                 device: projector
                 command: ""off""
                 num_repeats: 2
-                delay_secs: 1
+                delay_secs: 60
                 hold_secs: 0
               target:
                 entity_id: remote.broadlink"
thaum-xyz,ankhmorpork,a38877adb752f946bf7fec6946b11339c0e2159c,paulfantom,pawel@krupa.net.pl,2023-12-05T19:22:28Z,paulfantom,pawel@krupa.net.pl,2023-12-05T19:22:28Z,apps/multimedia: attempt to manually fix sqlite in prowlarr,apps/multimedia/manifests/prowlarr/statefulset.yaml,False,False,False,False,10,0,10,"---FILE: apps/multimedia/manifests/prowlarr/statefulset.yaml---
@@ -26,6 +26,16 @@ spec:
         app.kubernetes.io/part-of: prowlarr
         app.kubernetes.io/version: 1.7.4.3769-ls30
     spec:
+      initContainers:
+        - name: sqlite-fixer
+          image: alpine:3.14.2
+          command:
+            - /bin/sh
+            - -c
+            - sleep 999999999
+          volumeMounts:
+            - mountPath: /config
+              name: config
       containers:
         - env:
             - name: TZ"
thaum-xyz,ankhmorpork,6dca38a542acd5aea6a4fc671dd5516767a4baaf,paulfantom,pawel@krupa.net.pl,2023-11-26T14:22:28Z,paulfantom,pawel@krupa.net.pl,2023-11-26T14:22:28Z,base/traefik: fix port redirection syntax,base/traefik/values.yaml,False,False,False,False,2,1,3,"---FILE: base/traefik/values.yaml---
@@ -47,7 +47,8 @@ service:
 
 ports:
   web:
-    redirectTo: websecure
+    redirectTo:
+      port: websecure
 
 metrics:
   prometheus:"
thaum-xyz,ankhmorpork,527b09ec4342a0605273bb8f641dd59cd7b29657,paulfantom,pawel@krupa.net.pl,2023-11-01T22:41:49Z,paulfantom,pawel@krupa.net.pl,2023-11-01T22:41:49Z,apps/multimedia: fix plex STS,apps/multimedia/jsonnet/plex.libsonnet;apps/multimedia/manifests/plex/statefulset.yaml,False,False,False,False,18,18,36,"---FILE: apps/multimedia/jsonnet/plex.libsonnet---
@@ -289,7 +289,6 @@ function(params) {
       selector: {
         matchLabels: $._config.selectorLabels,
       },
-      serviceAccountName: $.serviceAccount.metadata.name,
       serviceName: $._metadata.name,
       template: {
         metadata: {
@@ -299,6 +298,7 @@ function(params) {
           labels: $._config.selectorLabels,
         },
         spec: {
+          serviceAccountName: $.serviceAccount.metadata.name,
           containers: [p, e],
           hostname: $._config.hostname,
           nodeSelector: {
@@ -338,13 +338,13 @@ function(params) {
             },
           ],
         },
-        volumeClaimTemplates: [{
-          metadata: {
-            name: 'library',
-          },
-          spec: $._config.storage.library.pvcSpec,
-        }],
       },
+      volumeClaimTemplates: [{
+        metadata: {
+          name: 'library',
+        },
+        spec: $._config.storage.library.pvcSpec,
+      }],
     },
   },
 }

---FILE: apps/multimedia/manifests/plex/statefulset.yaml---
@@ -15,7 +15,6 @@ spec:
       app.kubernetes.io/component: server
       app.kubernetes.io/name: plex
       app.kubernetes.io/part-of: plex
-  serviceAccountName: plex
   serviceName: plex
   template:
     metadata:
@@ -101,6 +100,7 @@ spec:
         kubernetes.io/arch: amd64
         kubernetes.io/os: linux
       runtimeClassName: nvidia
+      serviceAccountName: plex
       volumes:
       - emptyDir: {}
         name: transcode
@@ -117,13 +117,13 @@ spec:
       - name: tv
         persistentVolumeClaim:
           claimName: tv
-    volumeClaimTemplates:
-    - metadata:
-        name: library
-      spec:
-        accessModes:
-        - ReadWriteOnce
-        resources:
-          requests:
-            storage: 45Gi
-        storageClassName: lvm-secondary
+  volumeClaimTemplates:
+  - metadata:
+      name: library
+    spec:
+      accessModes:
+      - ReadWriteOnce
+      resources:
+        requests:
+          storage: 45Gi
+      storageClassName: lvm-secondary"
thaum-xyz,ankhmorpork,e22ef1254371f15cc123893ba342fe50149d52fc,paulfantom,pawel@krupa.net.pl,2023-10-21T18:06:31Z,paulfantom,pawel@krupa.net.pl,2023-10-21T18:06:31Z,apps/opencost: fix thanos port,apps/opencost/values.yaml,False,False,False,False,4,3,7,"---FILE: apps/opencost/values.yaml---
@@ -25,6 +25,7 @@ opencost:
       internal:
         serviceName: thanos-query
         namespaceName: datalake-metrics
+        port: 9090
 
   ui:
     enabled: true
@@ -48,6 +49,6 @@ opencost:
       spotRAM: 0.000892
       GPU: 0.95
       storage: 0.25
-      zoneNetworkEgress: 0.01
-      regionNetworkEgress: 0.01
-      internetNetworkEgress: 0.12
+      zoneNetworkEgress: 0
+      regionNetworkEgress: 0
+      internetNetworkEgress: 0"
thaum-xyz,ankhmorpork,fcfe6e643b04cfc85c1f6a944deb39666d075a48,paulfantom,pawel@krupa.net.pl,2023-10-16T17:16:43Z,paulfantom,pawel@krupa.net.pl,2023-10-16T17:16:43Z,apps/homeassistant: fix existing recipes sensor,apps/homeassistant/config/configuration.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,15,13,28,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -186,7 +186,8 @@ sensor:
       from_date: >
         {{ now().strftime(""%Y-%m-%d"") }}
       to_date: >
-        {{ (now().date() + timedelta(days=1)).strftime(""%Y-%m-%d"") }}
+        {{ now().strftime(""%Y-%m-%d"") }}
+#        {{ (now().date() + timedelta(days=1)).strftime(""%Y-%m-%d"") }}
     value_template: >
       {% if value_json is none or value_json == [] %}
         No meal plan found
@@ -221,6 +222,11 @@ rest:
         value_template: >
           {% set data = value_json | selectattr('meal_type_name', 'eq', 'Lunch') | first -%}
           {{ data.title if data.title else data.recipe_name | default() }}
+      - name: ""Today's Snack""
+        unique_id: ""meal_today_snack""
+        value_template: >
+          {% set data = value_json | selectattr('meal_type_name', 'eq', 'Snack') | first -%}
+          {{ data.title if data.title else data.recipe_name | default() }}
       - name: ""Today's Dinner""
         unique_id: ""meal_today_dinner""
         value_template: >
@@ -231,11 +237,6 @@ rest:
           - image
           - id
           - name
-      - name: ""Today's Snack""
-        unique_id: ""meal_today_snack""
-        value_template: >
-          {% set data = value_json | selectattr('meal_type_name', 'eq', 'Snack') | first -%}
-          {{ data.title if data.title else data.recipe_name | default() }}
 
   #- name: we_wash_w1
   #  platform: imap_email_content

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -189,7 +189,8 @@ data:
           from_date: >
             {{ now().strftime(""%Y-%m-%d"") }}
           to_date: >
-            {{ (now().date() + timedelta(days=1)).strftime(""%Y-%m-%d"") }}
+            {{ now().strftime(""%Y-%m-%d"") }}
+    #        {{ (now().date() + timedelta(days=1)).strftime(""%Y-%m-%d"") }}
         value_template: >
           {% if value_json is none or value_json == [] %}
             No meal plan found
@@ -224,6 +225,11 @@ data:
             value_template: >
               {% set data = value_json | selectattr('meal_type_name', 'eq', 'Lunch') | first -%}
               {{ data.title if data.title else data.recipe_name | default() }}
+          - name: ""Today's Snack""
+            unique_id: ""meal_today_snack""
+            value_template: >
+              {% set data = value_json | selectattr('meal_type_name', 'eq', 'Snack') | first -%}
+              {{ data.title if data.title else data.recipe_name | default() }}
           - name: ""Today's Dinner""
             unique_id: ""meal_today_dinner""
             value_template: >
@@ -234,11 +240,6 @@ data:
               - image
               - id
               - name
-          - name: ""Today's Snack""
-            unique_id: ""meal_today_snack""
-            value_template: >
-              {% set data = value_json | selectattr('meal_type_name', 'eq', 'Snack') | first -%}
-              {{ data.title if data.title else data.recipe_name | default() }}
 
       #- name: we_wash_w1
       #  platform: imap_email_content

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: c1f296e4b5b0e0dbbd0fbd7d40eb2dc0
+        checksum.config/md5: 04e3e5c08a9eaa39e8c97afc9f17c7af
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,71f45332610cf7d95b0cb4176f6531323a161011,paulfantom,pawel@krupa.net.pl,2023-10-14T09:02:51Z,paulfantom,pawel@krupa.net.pl,2023-10-14T09:02:51Z,base/metallb-system: fix L2 advertisement,base/metallb-system/custom/l2advert.yaml,False,False,False,False,1,1,2,"---FILE: base/metallb-system/custom/l2advert.yaml---
@@ -5,4 +5,4 @@ metadata:
   namespace: metallb-system
 spec:
   ipAddressPools:
-  - main-pool
+  - default"
thaum-xyz,ankhmorpork,bcb595515ef07a8622611142b8959811aa3938b1,paulfantom,pawel@krupa.net.pl,2023-10-14T08:36:27Z,paulfantom,pawel@krupa.net.pl,2023-10-14T08:36:27Z,base/metallb-system: fix nodeSelector labels,base/metallb-system/values.yaml,False,False,False,False,0,1,1,"---FILE: base/metallb-system/values.yaml---
@@ -18,7 +18,6 @@ prometheus:
 speaker:
   priorityClassName: system-node-critical
   nodeSelector:
-    kubernetes.io/os: linux
     network.infra/type: fast
 
 controller:"
thaum-xyz,ankhmorpork,92cbef903431c4ed72b78085f8f7cf0d95fc5935,paulfantom,pawel@krupa.net.pl,2023-09-02T15:26:47Z,paulfantom,pawel@krupa.net.pl,2023-09-02T15:50:41Z,"apps/cats: fix path routing

Signed-off-by: paulfantom <pawel@krupa.net.pl>",apps/cats/manifests/ingress.yaml;apps/cats/manifests/middleware-path-replace.yaml,False,False,False,False,9,0,9,"---FILE: apps/cats/manifests/ingress.yaml---
@@ -8,6 +8,7 @@ metadata:
     reloader.homer/name: Random Cat
     reloader.homer/subtitle: Cat as a Service
     nginx.ingress.kubernetes.io/app-root: /random
+    traefik.ingress.kubernetes.io/router.middlewares: cats-path-replace@kubernetescrd
   labels:
     app.kubernetes.io/name: cats
     # probe: enabled

---FILE: apps/cats/manifests/middleware-path-replace.yaml---
@@ -0,0 +1,8 @@
+apiVersion: traefik.io/v1alpha1
+kind: Middleware
+metadata:
+  name: path-replace
+  namespace: cats
+spec:
+  replacePath:
+    path: /random"
thaum-xyz,ankhmorpork,3be4e966a0327a901112b3a0987f4f5f4488c0de,paulfantom,pawel@krupa.net.pl,2023-08-22T20:49:19Z,paulfantom,pawel@krupa.net.pl,2023-08-22T20:49:19Z,apps/paperless: fix readiness probe for cronjob,apps/paperless/manifests/web/cronjob.yaml;lib/jsonnet/apps/paperless.libsonnet,False,False,False,False,1,2,3,"---FILE: apps/paperless/manifests/web/cronjob.yaml---
@@ -39,7 +39,6 @@ spec:
             image: ghcr.io/paperless-ngx/paperless-ngx:1.15.1
             name: backup
             ports: []
-            readinessProbe: {}
             resources: {}
             securityContext:
               privileged: false

---FILE: lib/jsonnet/apps/paperless.libsonnet---
@@ -361,7 +361,7 @@ function(params) {
                 name: ""backup"",
                 ports: [],
                 resources: {},
-                readinessProbe: {},
+                readinessProbe:: {},
                 volumeMounts+: [
                   {
                     mountPath: '/mnt/backups',"
thaum-xyz,ankhmorpork,1047c5a7045261be557a0440d94975bd71573aa3,paulfantom,pawel@krupa.net.pl,2023-08-19T10:01:06Z,paulfantom,pawel@krupa.net.pl,2023-08-19T10:01:06Z,apps/dns: fix grafana dns address,apps/dns/Corefile;apps/dns/manifests/config.yaml;apps/dns/manifests/deployment.yaml,False,False,False,False,3,3,6,"---FILE: apps/dns/Corefile---
@@ -24,7 +24,7 @@
     192.168.2.92 longhorn.ankhmorpork.thaum.xyz
     192.168.2.92 minio.ankhmorpork.thaum.xyz
     192.168.2.92 alertmanager.ankhmorpork.thaum.xyz
-    192.168.2.91 grafana.ankhmorpork.thaum.xyz
+    192.168.2.92 grafana.ankhmorpork.thaum.xyz
     192.168.2.92 prometheus.ankhmorpork.thaum.xyz
     192.168.2.92 pyrra.ankhmorpork.thaum.xyz
     192.168.2.92 papers.krupa.net.pl

---FILE: apps/dns/manifests/config.yaml---
@@ -27,7 +27,7 @@ data:
         192.168.2.92 longhorn.ankhmorpork.thaum.xyz
         192.168.2.92 minio.ankhmorpork.thaum.xyz
         192.168.2.92 alertmanager.ankhmorpork.thaum.xyz
-        192.168.2.91 grafana.ankhmorpork.thaum.xyz
+        192.168.2.92 grafana.ankhmorpork.thaum.xyz
         192.168.2.92 prometheus.ankhmorpork.thaum.xyz
         192.168.2.92 pyrra.ankhmorpork.thaum.xyz
         192.168.2.92 papers.krupa.net.pl

---FILE: apps/dns/manifests/deployment.yaml---
@@ -20,7 +20,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.corefile/md5: 07509b4387196674790389e54fa3bdb3
+        checksum.corefile/md5: 2104596e9531d1e69c4542a4c384e719
         checksum.envs/md5: 7b94015a8cc4f90d59a98d7e0a1ebe61
         parca.dev/scrape: ""true""
       labels:"
thaum-xyz,ankhmorpork,20f4d15be239e2a7d54551c669bb3c65dcefbb27,paulfantom,pawel@krupa.net.pl,2023-08-17T14:59:30Z,paulfantom,pawel@krupa.net.pl,2023-08-17T14:59:30Z,apps/datalake-metrics: fix auth secret,apps/datalake-metrics/jsonnet/main.jsonnet;apps/datalake-metrics/manifests/custom/thanosReceiveIngressAuth.yaml,False,False,False,False,2,2,4,"---FILE: apps/datalake-metrics/jsonnet/main.jsonnet---
@@ -120,7 +120,7 @@ local all = {
       },
       'doppler-auth-api',
       {
-        auth: settings.ingressAuthHTPasswdRef,
+        users: settings.ingressAuthHTPasswdRef,
       }
     ),
     middlewareAuth: {

---FILE: apps/datalake-metrics/manifests/custom/thanosReceiveIngressAuth.yaml---
@@ -7,7 +7,7 @@ spec:
   data:
   - remoteRef:
       key: THANOS_INGRESS_HTPASSWD
-    secretKey: auth
+    secretKey: users
   refreshInterval: 1h
   secretStoreRef:
     kind: ClusterSecretStore"
thaum-xyz,ankhmorpork,233ef496331d82b2d6d73ebe372a531fa8a974fc,paulfantom,pawel@krupa.net.pl,2023-07-23T11:53:35Z,paulfantom,pawel@krupa.net.pl,2023-07-23T11:53:35Z,fix version upgrades,Makefile;apps/auth/Makefile;apps/auth/manifests/creds.yaml;apps/auth/manifests/deployment.yaml,False,False,False,False,3,4,7,"---FILE: Makefile---
@@ -10,7 +10,6 @@ DIRS=\
 	apps/homeassistant \
 	apps/homer \
 	apps/monitoring \
-	apps/portal \
 	apps/unifi
 
 MAKEFILES=$(shell find . -name ""Makefile"" -not -path ""*/vendor/*"" -not -path ""./Makefile"")

---FILE: apps/auth/Makefile---
@@ -4,6 +4,7 @@ include ../../Makefile.common
 LATEST=$(shell curl https://raw.githubusercontent.com/paulfantom/dockerfiles/master/oauth2-proxy/VERSION 2>/dev/null)
 CURRENT=$(shell grep version settings.yaml | cut -d':' -f2 | xargs)
 version-update:
-	sed -i ""s/$(CURRENT)/$(LATEST)/g"" settings.yaml
+	sed -Ei.bak ""s/$(CURRENT)/$(LATEST)/g"" settings.yaml
+	rm *.bak
 	@echo ""oauth2-proxy/oauth2-proxy from $(CURRENT) to $(LATEST)"" >> ""$(shell git rev-parse --show-toplevel)/.version-changelog""
 	if ! git diff-index --quiet HEAD .; then $(MAKE) generate; fi

---FILE: apps/auth/manifests/creds.yaml---
@@ -1,7 +1,6 @@
 apiVersion: external-secrets.io/v1beta1
 kind: ExternalSecret
 metadata:
-  creationTimestamp: null
   name: oauth-creds
   namespace: auth
 spec:

---FILE: apps/auth/manifests/deployment.yaml---
@@ -18,7 +18,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: 007ff63e879594d08ce5cc308a2ed137
+        checksum.config/md5: 161ad26695f89ead5240d6014be54f7f
       labels:
         app.kubernetes.io/component: proxy
         app.kubernetes.io/name: oauth2-proxy"
thaum-xyz,ankhmorpork,dc0860db2d4f14b1ea395bd4281c68badfedaadc,paulfantom,pawel@krupa.net.pl,2023-06-22T09:09:44Z,paulfantom,pawel@krupa.net.pl,2023-06-22T09:09:44Z,apps/proxy-ghcr-io: fix keys in s3 creds secret,apps/proxy-ghcr-io/s3credentials.yaml;apps/proxy-ghcr-io/values.yaml,False,False,False,False,3,2,5,"---FILE: apps/proxy-ghcr-io/s3credentials.yaml---
@@ -15,5 +15,5 @@ spec:
     name: s3-credentials
     template:
       data:
-        secretKey: '{{ .secretKey }}'
-        accessKey: docker-cache
+        s3SecretKey: '{{ .secretKey }}'
+        s3AccessKey: docker-cache

---FILE: apps/proxy-ghcr-io/values.yaml---
@@ -1,4 +1,5 @@
 # Config reference: https://artifacthub.io/packages/helm/twuni/docker-registry
+# Chart repository: https://github.com/twuni/docker-registry.helm
 
 proxy:
   enabled: true"
thaum-xyz,ankhmorpork,ab3e13b121a2eb8e34643fcde58db7c4e9535a52,paulfantom,pawel@krupa.net.pl,2023-06-20T21:29:50Z,paulfantom,pawel@krupa.net.pl,2023-06-20T21:29:50Z,apps/minio: fix typo,apps/minio/values.yaml,False,False,False,False,1,1,2,"---FILE: apps/minio/values.yaml---
@@ -34,7 +34,7 @@ consoleIngress:
 resources:
   requests:
     cpu: 620m
-    memory: 560Gi
+    memory: 560Mi
   limits:
     cpu: 2
     memory: 2Gi"
thaum-xyz,ankhmorpork,b22b821cb94998781a274d5207dce47391aa410e,paulfantom,pawel@krupa.net.pl,2023-06-20T21:23:57Z,paulfantom,pawel@krupa.net.pl,2023-06-20T21:23:57Z,.github: fix kubescape PATH,.github/workflows/kubescape.yml,False,False,False,False,1,1,2,"---FILE: .github/workflows/kubescape.yml---
@@ -15,4 +15,4 @@ jobs:
       - uses: actions/checkout@v3
       - name: Download latest kubescape
         run: curl -s https://raw.githubusercontent.com/armosec/kubescape/master/install.sh | /bin/bash
-      - run: PATH=$PATH:/home/runner/.kubescape/bin/kubescape make kubescape
+      - run: PATH=$PATH:/home/runner/.kubescape/bin make kubescape"
thaum-xyz,ankhmorpork,8518df29e46cf7555fa69082f88f994c7cef5c38,paulfantom,pawel@krupa.net.pl,2023-06-20T20:43:50Z,paulfantom,pawel@krupa.net.pl,2023-06-20T20:43:50Z,"apps/proxy-{docker,ghcr}-io: fix values and add resource requirements",apps/proxy-docker-io/values.yaml;apps/proxy-ghcr-io/values.yaml,False,False,False,False,19,7,26,"---FILE: apps/proxy-docker-io/values.yaml---
@@ -35,14 +35,20 @@ ingress:
 #  secure: false
 #  
 
+resources:
+  #limits:
+  requests:
+    cpu: 10m
+    memory: 10Mi
+
 metrics:
   enabled: true
   port: 6000
   serviceMonitor:
-    enable: true
+    enabled: true
   prometheusRule:
-    enable: true
+    enabled: true
 
 garbageCollect:
-  enable: true
-  schedule: ""48 2 * * *""
\ No newline at end of file
+  enabled: true
+  schedule: ""48 2 * * *""

---FILE: apps/proxy-ghcr-io/values.yaml---
@@ -33,14 +33,20 @@ ingress:
 #  secure: false
 #  
 
+resources:
+  #limits:
+  requests:
+    cpu: 10m
+    memory: 10Mi
+
 metrics:
   enabled: true
   port: 6001
   serviceMonitor:
-    enable: true
+    enabled: true
   prometheusRule:
-    enable: true
+    enabled: true
 
 garbageCollect:
-  enable: true
+  enabled: true
   schedule: ""48 2 * * *"""
thaum-xyz,ankhmorpork,e16f525960119ba00e500f27670b21e6c6a0d2d0,paulfantom,pawel@krupa.net.pl,2023-06-20T07:50:09Z,paulfantom,pawel@krupa.net.pl,2023-06-20T07:50:09Z,*: fix typo,README.md,False,False,False,False,1,1,2,"---FILE: README.md---
@@ -71,7 +71,7 @@ Cluster is [k3s](https://k3s.io/) provisioned on bare-metal Ubuntu 20.04 using a
   </tr>
   <tr>
     <td><img width=""32"" src=""https://github.com/longhorn/website/raw/master/static/img/icon-longhorn.svg""></td>
-    <td><a href=""https://longhorn.io/""></a>Longhorn</td>
+    <td><a href=""https://longhorn.io/"">Longhorn</a></td>
     <td>Distributed PV storage</td>
   </tr>
   <tr>"
thaum-xyz,ankhmorpork,16c78d53f3d3d0eac46e4877debb7e73f9160a83,paulfantom,pawel@krupa.net.pl,2023-06-20T07:48:14Z,paulfantom,pawel@krupa.net.pl,2023-06-20T07:48:14Z,.github: fix kubescape location,.github/workflows/kubescape.yml,False,False,False,False,1,1,2,"---FILE: .github/workflows/kubescape.yml---
@@ -15,4 +15,4 @@ jobs:
       - uses: actions/checkout@v3
       - name: Download latest kubescape
         run: curl -s https://raw.githubusercontent.com/armosec/kubescape/master/install.sh | /bin/bash
-      - run: kubescape scan -t 36 --exceptions 'kubescape-exceptions.json' $(find apps base -name ""*.yaml"" -not -path ""*/jsonnet/*"" -not -path ""*/vendor/*"" -not -name ""settings.yaml"")
+      - run: /home/runner/.kubescape/bin/kubescape scan -t 36 --exceptions 'kubescape-exceptions.json' $(find apps base -name ""*.yaml"" -not -path ""*/jsonnet/*"" -not -path ""*/vendor/*"" -not -name ""settings.yaml"")"
thaum-xyz,ankhmorpork,56801e492df4517a084ba2fe668e3cb7739d3e1f,paulfantom,pawel@krupa.net.pl,2023-06-20T07:41:20Z,paulfantom,pawel@krupa.net.pl,2023-06-20T07:41:20Z,.github: fix typo,.github/workflows/prometheusrule.yml,False,False,False,False,1,1,2,"---FILE: .github/workflows/prometheusrule.yml---
@@ -22,7 +22,7 @@ jobs:
         with:
           go-version: '${{ env.golang-version }}'
       - run: go install github.com/brancz/gojsontoyaml@latest
-      - run: PATH=""${PATH}:${GITHUB_WORKSPACE}"" ./hack/hack/unpack-prometheus-rules.sh
+      - run: PATH=""${PATH}:${GITHUB_WORKSPACE}"" ./hack/unpack-prometheus-rules.sh
       - name: Run pint
         uses: prymitive/pint-action@v1
         with:"
thaum-xyz,ankhmorpork,f6807bdd70cb370ba68a4e65a53820c8c8f907d1,paulfantom,pawel@krupa.net.pl,2023-06-14T15:21:59Z,paulfantom,pawel@krupa.net.pl,2023-06-14T15:21:59Z,metal: disable kube-vip for now as it caused network issues,metal/70_k3s.yml;metal/group_vars/k3s.yml,False,False,False,False,9,7,16,"---FILE: metal/70_k3s.yml---
@@ -38,11 +38,11 @@
       delegate_to: localhost
       run_once: true
 
-    - name: Import manifests bound to infrastructure
-      template:
-        src: ""{{ item }}""
-        dest: ""/var/lib/rancher/k3s/server/manifests/{{ item | basename | regex_replace('\\.j2$', '') }}""
-      with_fileglob: ""templates/manifests/*.yaml.j2""
+    #- name: Import manifests bound to infrastructure
+    #  template:
+    #   src: ""{{ item }}""
+    #   dest: ""/var/lib/rancher/k3s/server/manifests/{{ item | basename | regex_replace('\\.j2$', '') }}""
+    #  with_fileglob: ""templates/manifests/*.yaml.j2""
 
 - hosts: k3s_nodes
   become: true

---FILE: metal/group_vars/k3s.yml---
@@ -1,9 +1,10 @@
 ---
 kube_vip_image: ghcr.io/kube-vip/kube-vip:v0.6.0
+kube_vip_ip: ""192.168.2.29""  # VIP IP managed by kube-vip
 
 k3s_version: v1.27.2+k3s1
-#k3s_master_ip: ""{{ hostvars[groups['k3s_control_plane'][0]]['ansible_default_ipv4']['address'] }}""
-k3s_master_ip: ""192.168.2.29""  # VIP IP managed by kube-vip
+k3s_master_ip: ""{{ hostvars[groups['k3s_control_plane'][0]]['ansible_default_ipv4']['address'] }}""
+#k3s_master_ip: ""{{ kube_vip_ip }}""
 
 k3s_token: ""{{ hostvars[groups['k3s_control_plane'][0]]['token'] }}""
 
@@ -28,6 +29,7 @@ k3s_server_config:
   kube-apiserver-arg:
   - ""feature-gates=PDBUnhealthyPodEvictionPolicy=true""
   - ""enable-admission-plugins=NamespaceAutoProvision""
+  resolv-conf: ""/run/systemd/resolve/resolv.conf""
 
 k3s_agent_config:
   kubelet-arg:"
thaum-xyz,ankhmorpork,9dc89aecc6c3ead57a951934d6b21825eab7e12e,paulfantom,pawel@krupa.net.pl,2023-06-11T13:00:33Z,paulfantom,pawel@krupa.net.pl,2023-06-11T13:00:33Z,apps/homeassistant: fix websockets integration and add workday one,apps/homeassistant/config/configuration.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,7,1,8,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -21,6 +21,8 @@ http:
   use_x_forwarded_for: true
   trusted_proxies: !secret trusted_proxies
 
+websocket_api:
+
 #panel_iframe:
 #  esphome:
 #    title: ""ESPHome""
@@ -77,6 +79,7 @@ zeroconf:
 zone:
 # END OF default_config
 
+workday:
 wake_on_lan:
 media_extractor:
 

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -24,6 +24,8 @@ data:
       use_x_forwarded_for: true
       trusted_proxies: !secret trusted_proxies
 
+    websocket_api:
+
     #panel_iframe:
     #  esphome:
     #    title: ""ESPHome""
@@ -80,6 +82,7 @@ data:
     zone:
     # END OF default_config
 
+    workday:
     wake_on_lan:
     media_extractor:
 

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: 239bae8535b62730f0a069c5f033a3d9
+        checksum.config/md5: f5c941e94407207d25d96327c0ae337d
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,adafe7ac020bd47e36ebc0e39be7974533cb3b0d,paulfantom,pawel@krupa.net.pl,2023-06-07T10:21:56Z,paulfantom,pawel@krupa.net.pl,2023-06-07T10:21:56Z,apps/datalake-metrics: revert to 0.30.2 due to https://github.com/thanos-io/thanos/issues/6257,apps/datalake-metrics/manifests/compact/service.yaml;apps/datalake-metrics/manifests/compact/serviceAccount.yaml;apps/datalake-metrics/manifests/compact/serviceMonitor.yaml;apps/datalake-metrics/manifests/compact/statefulSet.yaml;apps/datalake-metrics/manifests/query/deployment.yaml;apps/datalake-metrics/manifests/query/service.yaml;apps/datalake-metrics/manifests/query/serviceAccount.yaml;apps/datalake-metrics/manifests/query/serviceMonitor.yaml;apps/datalake-metrics/manifests/receiveIngestor/ingestor-default-service.yaml;apps/datalake-metrics/manifests/receiveIngestor/ingestor-default-statefulSet.yaml;apps/datalake-metrics/manifests/receiveIngestor/serviceAccount.yaml;apps/datalake-metrics/manifests/receiveIngestor/serviceMonitor.yaml;apps/datalake-metrics/manifests/receiveRouter/deployment.yaml;apps/datalake-metrics/manifests/receiveRouter/service.yaml;apps/datalake-metrics/manifests/receiveRouter/serviceAccount.yaml;apps/datalake-metrics/manifests/receiveRouter/serviceMonitor.yaml;apps/datalake-metrics/manifests/store/service.yaml;apps/datalake-metrics/manifests/store/serviceAccount.yaml;apps/datalake-metrics/manifests/store/serviceMonitor.yaml;apps/datalake-metrics/manifests/store/statefulSet.yaml;apps/datalake-metrics/settings.yaml,False,False,False,False,34,34,68,"---FILE: apps/datalake-metrics/manifests/compact/service.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: database-compactor
     app.kubernetes.io/instance: thanos-compact
     app.kubernetes.io/name: thanos-compact
-    app.kubernetes.io/version: v0.31.0
+    app.kubernetes.io/version: v0.30.2
   name: thanos-compact
   namespace: datalake-metrics
 spec:

---FILE: apps/datalake-metrics/manifests/compact/serviceAccount.yaml---
@@ -6,6 +6,6 @@ metadata:
     app.kubernetes.io/component: database-compactor
     app.kubernetes.io/instance: thanos-compact
     app.kubernetes.io/name: thanos-compact
-    app.kubernetes.io/version: v0.31.0
+    app.kubernetes.io/version: v0.30.2
   name: thanos-compact
   namespace: datalake-metrics

---FILE: apps/datalake-metrics/manifests/compact/serviceMonitor.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: database-compactor
     app.kubernetes.io/instance: thanos-compact
     app.kubernetes.io/name: thanos-compact
-    app.kubernetes.io/version: v0.31.0
+    app.kubernetes.io/version: v0.30.2
   name: thanos-compact
   namespace: datalake-metrics
 spec:

---FILE: apps/datalake-metrics/manifests/compact/statefulSet.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: database-compactor
     app.kubernetes.io/instance: thanos-compact
     app.kubernetes.io/name: thanos-compact
-    app.kubernetes.io/version: v0.31.0
+    app.kubernetes.io/version: v0.30.2
   name: thanos-compact
   namespace: datalake-metrics
 spec:
@@ -22,7 +22,7 @@ spec:
         app.kubernetes.io/component: database-compactor
         app.kubernetes.io/instance: thanos-compact
         app.kubernetes.io/name: thanos-compact
-        app.kubernetes.io/version: v0.31.0
+        app.kubernetes.io/version: v0.30.2
     spec:
       affinity:
         podAntiAffinity:
@@ -67,7 +67,7 @@ spec:
           valueFrom:
             fieldRef:
               fieldPath: status.hostIP
-        image: quay.io/thanos/thanos:v0.31.0
+        image: quay.io/thanos/thanos:v0.30.2
         imagePullPolicy: IfNotPresent
         livenessProbe:
           failureThreshold: 4

---FILE: apps/datalake-metrics/manifests/query/deployment.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: query-layer
     app.kubernetes.io/instance: thanos-query
     app.kubernetes.io/name: thanos-query
-    app.kubernetes.io/version: v0.31.0
+    app.kubernetes.io/version: v0.30.2
   name: thanos-query
   namespace: datalake-metrics
 spec:
@@ -21,7 +21,7 @@ spec:
         app.kubernetes.io/component: query-layer
         app.kubernetes.io/instance: thanos-query
         app.kubernetes.io/name: thanos-query
-        app.kubernetes.io/version: v0.31.0
+        app.kubernetes.io/version: v0.30.2
     spec:
       affinity:
         podAntiAffinity:
@@ -55,7 +55,7 @@ spec:
           valueFrom:
             fieldRef:
               fieldPath: status.hostIP
-        image: quay.io/thanos/thanos:v0.31.0
+        image: quay.io/thanos/thanos:v0.30.2
         imagePullPolicy: IfNotPresent
         livenessProbe:
           failureThreshold: 4

---FILE: apps/datalake-metrics/manifests/query/service.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: query-layer
     app.kubernetes.io/instance: thanos-query
     app.kubernetes.io/name: thanos-query
-    app.kubernetes.io/version: v0.31.0
+    app.kubernetes.io/version: v0.30.2
   name: thanos-query
   namespace: datalake-metrics
 spec:

---FILE: apps/datalake-metrics/manifests/query/serviceAccount.yaml---
@@ -6,6 +6,6 @@ metadata:
     app.kubernetes.io/component: query-layer
     app.kubernetes.io/instance: thanos-query
     app.kubernetes.io/name: thanos-query
-    app.kubernetes.io/version: v0.31.0
+    app.kubernetes.io/version: v0.30.2
   name: thanos-query
   namespace: datalake-metrics

---FILE: apps/datalake-metrics/manifests/query/serviceMonitor.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: query-layer
     app.kubernetes.io/instance: thanos-query
     app.kubernetes.io/name: thanos-query
-    app.kubernetes.io/version: v0.31.0
+    app.kubernetes.io/version: v0.30.2
   name: thanos-query
   namespace: datalake-metrics
 spec:

---FILE: apps/datalake-metrics/manifests/receiveIngestor/ingestor-default-service.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: database-write-hashring
     app.kubernetes.io/instance: thanos-receive-ingestor-default
     app.kubernetes.io/name: thanos-receive
-    app.kubernetes.io/version: v0.31.0
+    app.kubernetes.io/version: v0.30.2
     controller.receive.thanos.io/hashring: default
   name: thanos-receive-ingestor-default
   namespace: datalake-metrics

---FILE: apps/datalake-metrics/manifests/receiveIngestor/ingestor-default-statefulSet.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: database-write-hashring
     app.kubernetes.io/instance: thanos-receive-ingestor-default
     app.kubernetes.io/name: thanos-receive
-    app.kubernetes.io/version: v0.31.0
+    app.kubernetes.io/version: v0.30.2
     controller.receive.thanos.io: thanos-receive-controller
     controller.receive.thanos.io/hashring: default
   name: thanos-receive-ingestor-default
@@ -26,7 +26,7 @@ spec:
         app.kubernetes.io/component: database-write-hashring
         app.kubernetes.io/instance: thanos-receive-ingestor-default
         app.kubernetes.io/name: thanos-receive
-        app.kubernetes.io/version: v0.31.0
+        app.kubernetes.io/version: v0.30.2
         controller.receive.thanos.io/hashring: default
     spec:
       affinity:
@@ -96,7 +96,7 @@ spec:
             secretKeyRef:
               key: thanos.yaml
               name: thanos-objectstorage
-        image: quay.io/thanos/thanos:v0.31.0
+        image: quay.io/thanos/thanos:v0.30.2
         imagePullPolicy: IfNotPresent
         livenessProbe:
           failureThreshold: 8

---FILE: apps/datalake-metrics/manifests/receiveIngestor/serviceAccount.yaml---
@@ -6,6 +6,6 @@ metadata:
     app.kubernetes.io/component: database-write-hashring
     app.kubernetes.io/instance: thanos-receive-ingestor
     app.kubernetes.io/name: thanos-receive
-    app.kubernetes.io/version: v0.31.0
+    app.kubernetes.io/version: v0.30.2
   name: thanos-receive-ingestor
   namespace: datalake-metrics

---FILE: apps/datalake-metrics/manifests/receiveIngestor/serviceMonitor.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: database-write-hashring
     app.kubernetes.io/instance: thanos-receive-ingestor
     app.kubernetes.io/name: thanos-receive
-    app.kubernetes.io/version: v0.31.0
+    app.kubernetes.io/version: v0.30.2
   name: thanos-receive-ingestor
   namespace: datalake-metrics
 spec:

---FILE: apps/datalake-metrics/manifests/receiveRouter/deployment.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: thanos-receive-router
     app.kubernetes.io/instance: thanos-receive
     app.kubernetes.io/name: thanos-receive
-    app.kubernetes.io/version: v0.31.0
+    app.kubernetes.io/version: v0.30.2
   name: thanos-receive-router
   namespace: datalake-metrics
 spec:
@@ -15,14 +15,14 @@ spec:
       app.kubernetes.io/component: thanos-receive-router
       app.kubernetes.io/instance: thanos-receive
       app.kubernetes.io/name: thanos-receive
-      app.kubernetes.io/version: v0.31.0
+      app.kubernetes.io/version: v0.30.2
   template:
     metadata:
       labels:
         app.kubernetes.io/component: thanos-receive-router
         app.kubernetes.io/instance: thanos-receive
         app.kubernetes.io/name: thanos-receive
-        app.kubernetes.io/version: v0.31.0
+        app.kubernetes.io/version: v0.30.2
     spec:
       containers:
       - args:
@@ -49,7 +49,7 @@ spec:
           valueFrom:
             fieldRef:
               fieldPath: status.hostIP
-        image: quay.io/thanos/thanos:v0.31.0
+        image: quay.io/thanos/thanos:v0.30.2
         imagePullPolicy: IfNotPresent
         livenessProbe:
           failureThreshold: 8

---FILE: apps/datalake-metrics/manifests/receiveRouter/service.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: thanos-receive-router
     app.kubernetes.io/instance: thanos-receive
     app.kubernetes.io/name: thanos-receive
-    app.kubernetes.io/version: v0.31.0
+    app.kubernetes.io/version: v0.30.2
   name: thanos-receive-router
   namespace: datalake-metrics
 spec:
@@ -23,4 +23,4 @@ spec:
     app.kubernetes.io/component: thanos-receive-router
     app.kubernetes.io/instance: thanos-receive
     app.kubernetes.io/name: thanos-receive
-    app.kubernetes.io/version: v0.31.0
+    app.kubernetes.io/version: v0.30.2

---FILE: apps/datalake-metrics/manifests/receiveRouter/serviceAccount.yaml---
@@ -6,6 +6,6 @@ metadata:
     app.kubernetes.io/component: thanos-receive-router
     app.kubernetes.io/instance: thanos-receive
     app.kubernetes.io/name: thanos-receive
-    app.kubernetes.io/version: v0.31.0
+    app.kubernetes.io/version: v0.30.2
   name: thanos-receive-router
   namespace: datalake-metrics

---FILE: apps/datalake-metrics/manifests/receiveRouter/serviceMonitor.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: thanos-receive-router
     app.kubernetes.io/instance: thanos-receive
     app.kubernetes.io/name: thanos-receive
-    app.kubernetes.io/version: v0.31.0
+    app.kubernetes.io/version: v0.30.2
   name: thanos-receive-router
   namespace: datalake-metrics
 spec:

---FILE: apps/datalake-metrics/manifests/store/service.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: object-store-gateway
     app.kubernetes.io/instance: thanos-store
     app.kubernetes.io/name: thanos-store
-    app.kubernetes.io/version: v0.31.0
+    app.kubernetes.io/version: v0.30.2
   name: thanos-store
   namespace: datalake-metrics
 spec:

---FILE: apps/datalake-metrics/manifests/store/serviceAccount.yaml---
@@ -6,6 +6,6 @@ metadata:
     app.kubernetes.io/component: object-store-gateway
     app.kubernetes.io/instance: thanos-store
     app.kubernetes.io/name: thanos-store
-    app.kubernetes.io/version: v0.31.0
+    app.kubernetes.io/version: v0.30.2
   name: thanos-store
   namespace: datalake-metrics

---FILE: apps/datalake-metrics/manifests/store/serviceMonitor.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: object-store-gateway
     app.kubernetes.io/instance: thanos-store
     app.kubernetes.io/name: thanos-store
-    app.kubernetes.io/version: v0.31.0
+    app.kubernetes.io/version: v0.30.2
   name: thanos-store
   namespace: datalake-metrics
 spec:

---FILE: apps/datalake-metrics/manifests/store/statefulSet.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: object-store-gateway
     app.kubernetes.io/instance: thanos-store
     app.kubernetes.io/name: thanos-store
-    app.kubernetes.io/version: v0.31.0
+    app.kubernetes.io/version: v0.30.2
   name: thanos-store
   namespace: datalake-metrics
 spec:
@@ -22,7 +22,7 @@ spec:
         app.kubernetes.io/component: object-store-gateway
         app.kubernetes.io/instance: thanos-store
         app.kubernetes.io/name: thanos-store
-        app.kubernetes.io/version: v0.31.0
+        app.kubernetes.io/version: v0.30.2
     spec:
       affinity:
         podAntiAffinity:
@@ -66,7 +66,7 @@ spec:
           valueFrom:
             fieldRef:
               fieldPath: status.podIP
-        image: quay.io/thanos/thanos:v0.31.0
+        image: quay.io/thanos/thanos:v0.30.2
         imagePullPolicy: IfNotPresent
         livenessProbe:
           failureThreshold: 8

---FILE: apps/datalake-metrics/settings.yaml---
@@ -1,6 +1,6 @@
 ---
-version: 'v0.31.0'  # application-version-from-github: thanos-io/thanos
-image: ""quay.io/thanos/thanos:v0.31.0""  # application-image-from-github: thanos-io/thanos
+version: 'v0.30.2'  # application-version-from-github: thanos-io/thanos
+image: ""quay.io/thanos/thanos:v0.30.2""  # application-image-from-github: thanos-io/thanos
 namespace: ""datalake-metrics""
 imagePullPolicy: 'IfNotPresent'
 hashringConfigMapName: 'hashring-config'"
thaum-xyz,ankhmorpork,10c4fc982bd63ee35e579dbb44053851cffad7a4,paulfantom,pawel@krupa.net.pl,2023-06-06T19:35:15Z,paulfantom,pawel@krupa.net.pl,2023-06-06T19:35:15Z,apps/minio: fix indentation,apps/minio/prometheus-rules.yaml;apps/minio/values.yaml,False,False,False,False,70,22,92,"---FILE: apps/minio/prometheus-rules.yaml---
@@ -7,7 +7,7 @@ spec:
   groups:
   - name: minio-alerts
     rules:
-    - alert: NodesOffline
+    - alert: MinioNodesOffline
       expr: avg_over_time(minio_cluster_nodes_offline_total{namespace=""minio""}[5m]) > 0
       for: 10m
       labels:
@@ -16,11 +16,59 @@ spec:
         summary: ""Node down in MinIO deployment""
         description: ""Node(s) in cluster {{ $labels.instance }} offline for more than 5 minutes""
 
-    - alert: DisksOffline
+    - alert: MinioDisksOffline
       expr: avg_over_time(minio_cluster_disk_offline_total{namespace=""minio""}[5m]) > 0
       for: 10m
       labels:
         severity: warning
       annotations:
         summary: ""Disks down in MinIO deployment""
         description: ""Disks(s) in cluster {{ $labels.instance }} offline for more than 5 minutes""
+
+    - alert: MinioClusterAlmostOutOfSpace
+      expr:  (minio_cluster_capacity_usable_free_bytes / minio_cluster_capacity_usable_total_bytes * 100 < 3)
+      for: 30m
+      labels:
+        severity: critical
+      annotations:
+        summary: ""MinIO cluster has less than 3% space left.""
+        description: 'MinIO cluster {{ $labels.cluster }} at {{ $labels.instance }} has only {{ printf ""%.2f"" $value }}% available space left.'
+    - alert: MinioClusterAlmostOutOfSpace
+      expr:  (minio_cluster_capacity_usable_free_bytes / minio_cluster_capacity_usable_total_bytes * 100 < 5)
+      for: 30m
+      labels:
+        severity: warning
+      annotations:
+        summary: ""MinIO cluster has less than 5% space left.""
+        description: 'MinIO cluster {{ $labels.cluster }} at {{ $labels.instance }} has only {{ printf ""%.2f"" $value }}% available space left.'
+    
+    - alert: MinioClusterSpaceFillingUp
+      expr: |
+        minio_cluster_capacity_usable_free_bytes
+        /
+        minio_cluster_capacity_usable_total_bytes * 100 < 10
+        and
+        predict_linear(
+          minio_cluster_capacity_usable_free_bytes[6h],
+          4 * 60 * 60
+        ) < 0
+      labels:
+        severity: critical
+      annotations:
+        summary: ""MinIO cluster is predicted to run out of space within the next 4 hours.""
+        description: 'MinIO cluster {{ $labels.cluster }} at {{ $labels.instance }} is filling up. Only {{ printf ""%.2f"" $value }}% available space left and is filling up.'
+    - alert: MinioClusterSpaceFillingUp
+      expr: |
+        minio_cluster_capacity_usable_free_bytes
+        /
+        minio_cluster_capacity_usable_total_bytes * 100 < 15
+        and
+        predict_linear(
+          minio_cluster_capacity_usable_free_bytes[6h],
+          24 * 60 * 60
+        ) < 0
+      labels:
+        severity: warning
+      annotations:
+        summary: ""MinIO cluster is predicted to run out of space within the next 24 hours.""
+        description: 'MinIO cluster {{ $labels.cluster }} at {{ $labels.instance }} is filling up. Only {{ printf ""%.2f"" $value }}% available space left and is filling up.'
\ No newline at end of file

---FILE: apps/minio/values.yaml---
@@ -40,26 +40,26 @@ metrics:
   serviceMonitor:
     enabled: true
     includeNode: true
-  relabelConfigs:
-    metricRelabelings:
-    # Drop all metrics that are duplicated when scraped from all nodes
-    - sourceLabels: [__name__]
-      regex: 'minio_cluster_.*'
-      action: drop
-  relabelConfigsCluster:
-    metricRelabelings:
-    # Drop all metrics that should come directly from nodes
-    - sourceLabels: [__name__]
-      regex: 'minio_audit_.*|minio_inter_node_traffic_.*|minio_notify_current_send_in_progress|minio_s3_requests_.*|minio_software_.*'
-      action: drop
-    # Remove server label as it unnecesarily differentiates metrics
-    - action: labeldrop
-      regex: 'server'
-    # Add cluster label to all metrics
-    - sourceLabels: [__name__]
-      action: replace
-      replacement: 'main'
-      targetLabel: cluster
+    relabelConfigs:
+      metricRelabelings:
+      # Drop all metrics that are duplicated when scraped from all nodes
+      - sourceLabels: [__name__]
+        regex: 'minio_cluster_.*'
+        action: drop
+    relabelConfigsCluster:
+      metricRelabelings:
+      # Drop all metrics that should come directly from nodes
+      - sourceLabels: [__name__]
+        regex: 'minio_audit_.*|minio_inter_node_traffic_.*|minio_notify_current_send_in_progress|minio_s3_requests_.*|minio_software_.*'
+        action: drop
+      # Remove server label as it unnecesarily differentiates metrics
+      - action: labeldrop
+        regex: 'server'
+      # Add cluster label to all metrics
+      - sourceLabels: [__name__]
+        action: replace
+        replacement: 'main'
+        targetLabel: cluster
 
 
 podDisruptionBudget:"
thaum-xyz,ankhmorpork,e801456db6d0ac48726ead08053e5e560aeddaec,paulfantom,pawel@krupa.net.pl,2023-06-05T21:02:50Z,paulfantom,pawel@krupa.net.pl,2023-06-05T21:02:50Z,base/topolvm: fix priority classes,base/topolvm/values.yaml,False,False,False,False,4,1,5,"---FILE: base/topolvm/values.yaml---
@@ -21,7 +21,7 @@ node:
   prometheus:
     podMonitor:
       enabled: true
-  priorityClassName: node-critical
+  priorityClassName: system-node-critical
 
 controller:
   storageCapacityTracking:
@@ -62,3 +62,6 @@ podSecurityPolicy:
 
 cert-manager:
   enabled: false
+
+priorityClass:
+  enabled: false
\ No newline at end of file"
thaum-xyz,ankhmorpork,28934d5d49e8a6001e4628ff1cd5d0878b5db500,paulfantom,pawel@krupa.net.pl,2023-06-05T20:55:47Z,paulfantom,pawel@krupa.net.pl,2023-06-05T20:55:47Z,apps/monitoring: fix ingress monitoring for ingress with multiple paths,apps/monitoring/config.jsonnet;apps/monitoring/manifests/blackboxExporter/ingressProbe.yaml,False,False,False,False,26,8,34,"---FILE: apps/monitoring/config.jsonnet---
@@ -129,14 +129,24 @@
             },
           },
           namespaceSelector: { any: true },
-          relabelingConfigs: [{
-            sourceLabels: ['__meta_kubernetes_ingress_scheme', '__meta_kubernetes_ingress_host', '__meta_kubernetes_ingress_annotation_probe_uri'],
-            separator: ';',
-            regex: '(.+);(.+);(.+)',
-            targetLabel: '__param_target',
-            replacement: '${1}://${2}/${3}',
-            action: 'replace',
-          }],
+          relabelingConfigs: [
+            {
+              sourceLabels: ['__meta_kubernetes_ingress_scheme', '__meta_kubernetes_ingress_host'],
+              separator: ';',
+              regex: '(.+);(.+)',
+              targetLabel: '__param_target',
+              replacement: '${1}://${2}',
+              action: 'replace',
+            },
+            {
+              sourceLabels: ['__meta_kubernetes_ingress_scheme', '__meta_kubernetes_ingress_host', '__meta_kubernetes_ingress_annotation_probe_uri'],
+              separator: ';',
+              regex: '(.+);(.+);(.+)',
+              targetLabel: '__param_target',
+              replacement: '${1}://${2}/${3}',
+              action: 'replace',
+            },
+          ],
         },
       },
     },

---FILE: apps/monitoring/manifests/blackboxExporter/ingressProbe.yaml---
@@ -19,6 +19,14 @@ spec:
       namespaceSelector:
         any: true
       relabelingConfigs:
+      - action: replace
+        regex: (.+);(.+)
+        replacement: ${1}://${2}
+        separator: ;
+        sourceLabels:
+        - __meta_kubernetes_ingress_scheme
+        - __meta_kubernetes_ingress_host
+        targetLabel: __param_target
       - action: replace
         regex: (.+);(.+);(.+)
         replacement: ${1}://${2}/${3}"
thaum-xyz,ankhmorpork,0cdae01ce779a6058f4535980c6887d8b11e14b2,paulfantom,pawel@krupa.net.pl,2023-06-05T19:41:30Z,paulfantom,pawel@krupa.net.pl,2023-06-05T19:41:30Z,apps/monitoring: fix SLO grouping,apps/monitoring/jsonnet/main.jsonnet;apps/monitoring/manifests/other/ingresSLO.yaml,False,False,False,False,2,2,4,"---FILE: apps/monitoring/jsonnet/main.jsonnet---
@@ -899,7 +899,7 @@ local kp =
           indicator: {
             bool_gauge: {
               metric: 'probe_success',
-              grouping: ['target'],
+              grouping: ['instance'],
             },
           },
         },

---FILE: apps/monitoring/manifests/other/ingresSLO.yaml---
@@ -7,7 +7,7 @@ spec:
   indicator:
     bool_gauge:
       grouping:
-      - target
+      - instance
       metric: probe_success
   target: ""99.0""
   window: 7d"
thaum-xyz,ankhmorpork,1688b42c01e7c08ed57100e31d738408519742d0,paulfantom,pawel@krupa.net.pl,2023-06-05T19:40:00Z,paulfantom,pawel@krupa.net.pl,2023-06-05T19:40:00Z,apps/monitoring: fix ingress label,apps/monitoring/config.jsonnet;apps/monitoring/jsonnet/main.jsonnet;apps/monitoring/manifests/alertmanager/ingress.yaml;apps/monitoring/manifests/blackboxExporter/ingressProbe.yaml;apps/monitoring/manifests/grafana/ingress.yaml;apps/monitoring/manifests/prometheus/ingress.yaml;apps/monitoring/manifests/pyrra/ingress.yaml,False,False,False,False,7,7,14,"---FILE: apps/monitoring/config.jsonnet---
@@ -130,7 +130,7 @@
           },
           namespaceSelector: { any: true },
           relabelingConfigs: [{
-            sourceLabels: ['__meta_kubernetes_ingress_scheme', '__meta_kubernetes_ingress_host', '__meta_kubernetes_ingress_label_probe_uri'],
+            sourceLabels: ['__meta_kubernetes_ingress_scheme', '__meta_kubernetes_ingress_host', '__meta_kubernetes_ingress_annotation_probe_uri'],
             separator: ';',
             regex: '(.+);(.+);(.+)',
             targetLabel: '__param_target',

---FILE: apps/monitoring/jsonnet/main.jsonnet---
@@ -46,10 +46,10 @@ local ingress(metadata, domain, service) = {
       'reloader.homer/group': 'Administration',
       'reloader.homer/logo': 'https://cncf-branding.netlify.app/img/projects/prometheus/icon/color/prometheus-icon-color.png',  // Default to prometheus logo
       'reloader.homer/name': $.metadata.name,
+      'probe-uri': '/-/healthy',
     },
     labels+: {
       'reloader.homer/enabled': 'true',
-      'probe-uri': '/-/healthy',
     },
   },
   spec: {

---FILE: apps/monitoring/manifests/alertmanager/ingress.yaml---
@@ -9,6 +9,7 @@ metadata:
     nginx.ingress.kubernetes.io/auth-url: https://auth.ankhmorpork.thaum.xyz/oauth2/auth
     nginx.ingress.kubernetes.io/session-cookie-hash: sha1
     nginx.ingress.kubernetes.io/session-cookie-name: routing-cookie
+    probe-uri: /-/healthy
     reloader.homer/group: Administration
     reloader.homer/logo: https://cncf-branding.netlify.app/img/projects/prometheus/icon/color/prometheus-icon-color.png
     reloader.homer/name: alertmanager
@@ -18,7 +19,6 @@ metadata:
     app.kubernetes.io/name: alertmanager
     app.kubernetes.io/part-of: kube-prometheus
     app.kubernetes.io/version: 0.25.0
-    probe-uri: /-/healthy
     reloader.homer/enabled: ""true""
   name: alertmanager
   namespace: monitoring

---FILE: apps/monitoring/manifests/blackboxExporter/ingressProbe.yaml---
@@ -26,7 +26,7 @@ spec:
         sourceLabels:
         - __meta_kubernetes_ingress_scheme
         - __meta_kubernetes_ingress_host
-        - __meta_kubernetes_ingress_label_probe_uri
+        - __meta_kubernetes_ingress_annotation_probe_uri
         targetLabel: __param_target
       selector:
         matchLabels:

---FILE: apps/monitoring/manifests/grafana/ingress.yaml---
@@ -6,6 +6,7 @@ metadata:
     nginx.ingress.kubernetes.io/auth-response-headers: X-Auth-Request-Email
     nginx.ingress.kubernetes.io/auth-signin: https://auth.ankhmorpork.thaum.xyz/oauth2/start?rd=$scheme://$host$escaped_request_uri
     nginx.ingress.kubernetes.io/auth-url: https://auth.ankhmorpork.thaum.xyz/oauth2/auth
+    probe-uri: /-/healthy
     reloader.homer/group: Administration
     reloader.homer/logo: https://grafana.com/static/img/logos/grafana_logo_swirl-events.svg
     reloader.homer/name: grafana
@@ -14,7 +15,6 @@ metadata:
     app.kubernetes.io/name: grafana
     app.kubernetes.io/part-of: kube-prometheus
     app.kubernetes.io/version: 9.1.7
-    probe-uri: /-/healthy
     reloader.homer/enabled: ""true""
   name: grafana
   namespace: monitoring

---FILE: apps/monitoring/manifests/prometheus/ingress.yaml---
@@ -7,6 +7,7 @@ metadata:
       CRDs
     nginx.ingress.kubernetes.io/auth-signin: https://auth.ankhmorpork.thaum.xyz/oauth2/start?rd=$scheme://$host$escaped_request_uri
     nginx.ingress.kubernetes.io/auth-url: https://auth.ankhmorpork.thaum.xyz/oauth2/auth
+    probe-uri: /-/healthy
     reloader.homer/group: Administration
     reloader.homer/logo: https://cncf-branding.netlify.app/img/projects/prometheus/icon/color/prometheus-icon-color.png
     reloader.homer/name: prometheus
@@ -16,7 +17,6 @@ metadata:
     app.kubernetes.io/name: prometheus
     app.kubernetes.io/part-of: kube-prometheus
     app.kubernetes.io/version: 2.42.0
-    probe-uri: /-/healthy
     reloader.homer/enabled: ""true""
   name: prometheus
   namespace: monitoring

---FILE: apps/monitoring/manifests/pyrra/ingress.yaml---
@@ -5,6 +5,7 @@ metadata:
     cert-manager.io/cluster-issuer: letsencrypt-prod
     nginx.ingress.kubernetes.io/auth-signin: https://auth.ankhmorpork.thaum.xyz/oauth2/start?rd=$scheme://$host$escaped_request_uri
     nginx.ingress.kubernetes.io/auth-url: https://auth.ankhmorpork.thaum.xyz/oauth2/auth
+    probe-uri: /-/healthy
     reloader.homer/group: Administration
     reloader.homer/logo: https://avatars.githubusercontent.com/u/87393422?s=200&v=4
     reloader.homer/name: pyrra
@@ -13,7 +14,6 @@ metadata:
     app.kubernetes.io/name: pyrra
     app.kubernetes.io/part-of: kube-prometheus
     app.kubernetes.io/version: 0.6.3
-    probe-uri: /-/healthy
     reloader.homer/enabled: ""true""
   name: pyrra-api
   namespace: monitoring"
thaum-xyz,ankhmorpork,d48a2198c6003af28fb087276c077872e233e715,paulfantom,pawel@krupa.net.pl,2023-06-04T12:00:59Z,paulfantom,pawel@krupa.net.pl,2023-06-04T12:05:12Z,"base/backup-k3s: fix s3 url

Signed-off-by: paulfantom <pawel@krupa.net.pl>",base/backup-k3s/manifests/cronjob.yaml,False,False,False,False,2,2,4,"---FILE: base/backup-k3s/manifests/cronjob.yaml---
@@ -22,7 +22,7 @@ spec:
             - $(S3_SECRET_KEY)
             env:
             - name: S3_ADDRESS
-              value: ""minio-main.minio-main.svc:9000""
+              value: ""http://main-minio.minio-main.svc:9000""
             envFrom:
             - secretRef:
                 name: s3-credentials
@@ -82,4 +82,4 @@ spec:
           - name: k3s-server
             hostPath:
               path: /var/lib/rancher/k3s/server
-              type: Directory
\ No newline at end of file
+              type: Directory"
thaum-xyz,ankhmorpork,0f7c3da30186886d6c8250c9d5d882e38cf9b887,paulfantom,pawel@krupa.net.pl,2023-06-03T18:16:52Z,paulfantom,pawel@krupa.net.pl,2023-06-03T18:27:48Z,"*: fix k3s backup job;

Signed-off-by: paulfantom <pawel@krupa.net.pl>",apps/minio/kustomization.yaml;apps/minio/secret-k3s-db-sa-creds.yaml;apps/minio/values.yaml;base/backup-k3s/manifests/cronjob.yaml,False,False,False,False,33,2,35,"---FILE: apps/minio/kustomization.yaml---
@@ -6,6 +6,7 @@ resources:
   - release.yaml
   - secret-root-creds.yaml
   - secret-thanos-sa-creds.yaml
+  - secret-k3s-db-sa-creds.yaml
 configMapGenerator:
   - name: values
     files:

---FILE: apps/minio/secret-k3s-db-sa-creds.yaml---
@@ -0,0 +1,17 @@
+apiVersion: external-secrets.io/v1beta1
+kind: ExternalSecret
+metadata:
+  creationTimestamp: null
+  name: k3s-db-sa-credentials
+  namespace: minio-main
+spec:
+  data:
+  - remoteRef:
+      key: K3S_DB_S3_SECRET_KEY
+    secretKey: secretKey
+  refreshInterval: 1h
+  secretStoreRef:
+    kind: ClusterSecretStore
+    name: doppler-auth-api
+  target:
+    name: k3s-db-sa-credentials
\ No newline at end of file

---FILE: apps/minio/values.yaml---
@@ -49,8 +49,21 @@ svcaccts:
     existingSecret: thanos-sa-credentials
     existingSecretKey: secretKey
     user: minio
+  - accessKey: k3s-db
+    existingSecret: k3s-db-sa-credentials
+    existingSecretKey: secretKey
+    user: minio
 
 buckets:
   - name: metrics
+    purge: false
     policy: none
+    
+  - name: k3s-db
     purge: false
+    policy: none
+    #  statements:
+    #    - resources:
+    #        - 'arn:aws:s3:::k3s-db/*'
+    #      actions:
+    #        - ""s3:*""

---FILE: base/backup-k3s/manifests/cronjob.yaml---
@@ -22,7 +22,7 @@ spec:
             - $(S3_SECRET_KEY)
             env:
             - name: S3_ADDRESS
-              value: ""http://192.168.2.29:8010""
+              value: ""minio-main.minio-main.svc:9000""
             envFrom:
             - secretRef:
                 name: s3-credentials
@@ -59,7 +59,7 @@ spec:
             - OBJSTORE/$(S3_BUCKET)/$(S3_PREFIX)
             env:
             - name: S3_BUCKET
-              value: etcd
+              value: k3s-db
             - name: S3_PREFIX
               value: ankhmorpork
             volumeMounts:"
thaum-xyz,ankhmorpork,0230541e331227379115134ab46a5a3e55508b5e,paulfantom,pawel@krupa.net.pl,2023-06-02T13:00:40Z,paulfantom,pawel@krupa.net.pl,2023-06-02T13:03:01Z,"apps/datalake-metrics: fix bucket connectivity

Signed-off-by: paulfantom <pawel@krupa.net.pl>",apps/datalake-metrics/manifests/custom/bucketConfig.yaml;apps/datalake-metrics/settings.yaml,False,False,False,False,4,10,14,"---FILE: apps/datalake-metrics/manifests/custom/bucketConfig.yaml---
@@ -24,12 +24,9 @@ spec:
           type: S3
           config:
             bucket: metrics
-            endpoint: 192.168.2.29:8010
+            endpoint: main-minio.minio-main.svc:9000
             access_key: {{ .access_key }}
             secret_key: {{ .secret_key }}
-            http_config:
-              insecure_skip_verify: true
-              tls_config:
-                insecure_skip_verify: true
+            insecure: true
           prefix: thanos
       engineVersion: v2

---FILE: apps/datalake-metrics/settings.yaml---
@@ -21,13 +21,10 @@ objectStorageConfig:
     type: S3
     config:
       bucket: metrics
-      endpoint: 192.168.2.29:8010
+      endpoint: main-minio.minio-main.svc:9000
       access_key: {{ .access_key }}
       secret_key: {{ .secret_key }}
-      http_config:
-        insecure_skip_verify: true
-        tls_config:
-          insecure_skip_verify: true
+      insecure: true
     prefix: thanos
 
 # reference to htpasswd file storred in doppler. Content later available in Secret 'thanos-receive-ingress-auth'."
thaum-xyz,ankhmorpork,c4c2e51e99990f62bae4b5d59cd7ace3aadd15ce,paulfantom,pawel@krupa.net.pl,2023-06-02T12:57:23Z,paulfantom,pawel@krupa.net.pl,2023-06-02T12:57:23Z,apps/minio: fix bucket name,apps/minio/values.yaml,False,False,False,False,1,1,2,"---FILE: apps/minio/values.yaml---
@@ -51,6 +51,6 @@ svcaccts:
     user: minio
 
 buckets:
-  - name: thanos
+  - name: metrics
     policy: none
     purge: false"
thaum-xyz,ankhmorpork,727e495f4a1dc1b65f4d6d9d4d5566b17191cad5,paulfantom,pawel@krupa.net.pl,2023-06-01T15:05:39Z,paulfantom,pawel@krupa.net.pl,2023-06-01T15:05:39Z,*: increase default number of postgres nodes in a cluster to 2 to prevent issues with node drainage,apps/homeassistant/manifests/postgres/cluster.yaml;apps/paperless/manifests/postgres/cluster.yaml;apps/tandoor/manifests/postgres/cluster.yaml;lib/jsonnet/apps/cloudnative-pg-cluster.libsonnet,False,False,False,False,4,4,8,"---FILE: apps/homeassistant/manifests/postgres/cluster.yaml---
@@ -12,7 +12,7 @@ spec:
       owner: homeassistant
       secret:
         name: postgres-user
-  instances: 1
+  instances: 2
   monitoring:
     enablePodMonitor: true
   resources:

---FILE: apps/paperless/manifests/postgres/cluster.yaml---
@@ -12,7 +12,7 @@ spec:
       owner: paperless
       secret:
         name: postgres-user
-  instances: 1
+  instances: 2
   monitoring:
     enablePodMonitor: true
   resources:

---FILE: apps/tandoor/manifests/postgres/cluster.yaml---
@@ -12,7 +12,7 @@ spec:
       owner: recipes
       secret:
         name: postgres-user
-  instances: 1
+  instances: 2
   monitoring:
     enablePodMonitor: true
   resources:

---FILE: lib/jsonnet/apps/cloudnative-pg-cluster.libsonnet---
@@ -13,7 +13,7 @@ local defaults = {
   commonLabels:: {
     'app.kubernetes.io/name': 'postgres',
   },
-  instances: 1,
+  instances: 2,
   db: {
     name: 'postgres',
     user: '',"
thaum-xyz,ankhmorpork,c9a1208cdd852bb82da6e29fe238fe613951f870,paulfantom,pawel@krupa.net.pl,2023-06-01T14:36:36Z,paulfantom,pawel@krupa.net.pl,2023-06-01T14:44:40Z,"base/longhorn-system: fix backup target

Signed-off-by: paulfantom <pawel@krupa.net.pl>",base/longhorn-system/values.yaml,False,False,False,False,1,1,2,"---FILE: base/longhorn-system/values.yaml---
@@ -6,7 +6,7 @@ persistence:
 defaultSettings:
   defaultDataPath: ""/var/lib/rancher/longhorn""
   snapshotDataIntegrity: ""fast-check""
-  backupTarget: ""nfs://192.168.2.29/nfsshare/backups-longhorn""
+  backupTarget: ""nfs://192.168.2.29:/nfsshare/longhorn-backups""
 
 longhornUI:
   replicas: 1"
thaum-xyz,ankhmorpork,34916d273193dd01d3653e34fb041b59af44e7c9,paulfantom,pawel@krupa.net.pl,2023-05-17T17:32:11Z,paulfantom,pawel@krupa.net.pl,2023-05-17T17:32:11Z,apps/cats: fix logo and and app root redirect,apps/cats/manifests/ingress.yaml,False,False,False,False,2,1,3,"---FILE: apps/cats/manifests/ingress.yaml---
@@ -4,9 +4,10 @@ metadata:
   annotations:
     cert-manager.io/cluster-issuer: letsencrypt-prod
     reloader.homer/group: Ankh Cloud
-    reloader.homer/logo: https://publicdomainvectors.org/photos/cat_line_art_pitr_Kitty_icon.png
+    reloader.homer/logo: https://media.istockphoto.com/id/662195090/de/vektor/minimale-cat-logo.jpg?s=612x612&w=0&k=20&c=tx_rWZx2Uzxh-HOHlgFBnyQnm4CzrXO3fAhcW1Mp1i8=
     reloader.homer/name: Random Cat
     reloader.homer/subtitle: Cat as a Service
+    nginx.ingress.kubernetes.io/app-root: /random
   labels:
     app.kubernetes.io/name: cats
     probe: enabled"
thaum-xyz,ankhmorpork,ad1d455f1c566940402b94714cc90a5dd053255f,paulfantom,pawel@krupa.net.pl,2023-05-17T17:12:03Z,paulfantom,pawel@krupa.net.pl,2023-05-17T17:13:07Z,"apps/homer: fix rolebinding for reloader role

Signed-off-by: paulfantom <pawel@krupa.net.pl>",apps/homer/manifests/reloader/role.yaml,False,False,False,False,1,0,1,"---FILE: apps/homer/manifests/reloader/role.yaml---
@@ -2,6 +2,7 @@ apiVersion: rbac.authorization.k8s.io/v1
 kind: Role
 metadata:
   name: homer-reloader
+  namespace: homer
 rules:
   - apiGroups:
       - """""
thaum-xyz,ankhmorpork,9a15a04778cca67cbe406f18d6f8dce8ca1eca96,paulfantom,pawel@krupa.net.pl,2023-05-15T13:48:23Z,paulfantom,pawel@krupa.net.pl,2023-05-15T13:48:49Z,"base/longhorn-system: fix node selector for trim job

Fixes https://github.com/thaum-xyz/ankhmorpork/issues/292",base/longhorn-system/cronjob-trim.yaml,False,False,False,False,1,1,2,"---FILE: base/longhorn-system/cronjob-trim.yaml---
@@ -16,5 +16,5 @@ spec:
             image: ghcr.io/lp0101/longhorn-auto-trim:latest
             imagePullPolicy: IfNotPresent
           nodeSelector:
-            kubernetes.io/arch: arm64
+            kubernetes.io/arch: amd64
           restartPolicy: Never"
thaum-xyz,ankhmorpork,734056d95007ff07ed12e80a6564db795e3208bf,paulfantom,pawel@krupa.net.pl,2023-05-15T10:04:31Z,paulfantom,pawel@krupa.net.pl,2023-05-15T10:04:31Z,apps/cats: fix ingress and add servicemonitor,apps/cats/manifests/service.yaml;apps/cats/manifests/servicemonitor.yaml,False,False,False,False,15,0,15,"---FILE: apps/cats/manifests/service.yaml---
@@ -9,6 +9,7 @@ metadata:
 spec:
   ports:
     - port: 8080
+      name: http
       targetPort: 8080
   selector:
     app.kubernetes.io/name: cats
\ No newline at end of file

---FILE: apps/cats/manifests/servicemonitor.yaml---
@@ -0,0 +1,14 @@
+apiVersion: monitoring.coreos.com/v1
+kind: ServiceMonitor
+metadata:
+  labels:
+    app.kubernetes.io/name: cats
+  name: cats
+  namespace: cats
+spec:
+  endpoints:
+  - path: /metrics
+    port: http
+  selector:
+    matchLabels:
+      app.kubernetes.io/name: cats"
thaum-xyz,ankhmorpork,99abf191ccf495d792e3032b9ec1aa7fd618bc3e,paulfantom,pawel@krupa.net.pl,2023-05-05T06:14:30Z,paulfantom,pawel@krupa.net.pl,2023-05-05T06:14:30Z,base/longhorn-system: fix image name,base/longhorn-system/cronjob-trim.yaml,False,False,False,False,1,1,2,"---FILE: base/longhorn-system/cronjob-trim.yaml---
@@ -13,7 +13,7 @@ spec:
         spec:
           containers:
           - name: longhorn-system
-            image: docker pull ghcr.io/lp0101/longhorn-auto-trim:latest
+            image: ghcr.io/lp0101/longhorn-auto-trim:latest
             imagePullPolicy: IfNotPresent
           nodeSelector:
             kubernetes.io/arch: arm64"
thaum-xyz,ankhmorpork,9fe4593ec1e3f4b41ffcfeb1e712211d2617c910,paulfantom,pawel@krupa.net.pl,2023-05-04T20:21:37Z,paulfantom,pawel@krupa.net.pl,2023-05-04T20:21:37Z,apps/datalake-metrics: fix governing service,apps/datalake-metrics/manifests/store-local/service.yaml;apps/datalake-metrics/manifests/store-local/statefulSet.yaml,False,False,False,False,2,1,3,"---FILE: apps/datalake-metrics/manifests/store-local/service.yaml---
@@ -6,6 +6,7 @@ metadata:
     app.kubernetes.io/instance: thanos-store
     app.kubernetes.io/name: thanos-store
     app.kubernetes.io/version: v0.30.2
+    store: local
   name: thanos-store-local
   namespace: datalake-metrics
 spec:

---FILE: apps/datalake-metrics/manifests/store-local/statefulSet.yaml---
@@ -17,7 +17,7 @@ spec:
       app.kubernetes.io/instance: thanos-store
       app.kubernetes.io/name: thanos-store
       store: local
-  serviceName: thanos-store
+  serviceName: thanos-store-local
   template:
     metadata:
       labels:"
thaum-xyz,ankhmorpork,0cdbf2ffd0dba5509d6281c2ac73374e61910534,paulfantom,pawel@krupa.net.pl,2023-04-28T22:37:31Z,paulfantom,pawel@krupa.net.pl,2023-04-28T22:37:40Z,apps/monitoring: fix incorrect schema,apps/monitoring/config.jsonnet;apps/monitoring/manifests/blackboxExporter/ingressProbe.yaml,False,False,False,False,4,4,8,"---FILE: apps/monitoring/config.jsonnet---
@@ -159,10 +159,10 @@
           },
           namespaceSelector: { any: true },
           relabelingConfigs: [{
-            source_labels: ['__meta_kubernetes_ingress_scheme', '__meta_kubernetes_ingress_host'],
+            sourceLabels: ['__meta_kubernetes_ingress_scheme', '__meta_kubernetes_ingress_host'],
             separator: ';',
             regex: '(.+);(.+)',
-            target_label: '__param_target',
+            targetLabel: '__param_target',
             replacement: '${1}://${2}/',
             action: 'replace',
           }],

---FILE: apps/monitoring/manifests/blackboxExporter/ingressProbe.yaml---
@@ -23,10 +23,10 @@ spec:
         regex: (.+);(.+)
         replacement: ${1}://${2}/
         separator: ;
-        source_labels:
+        sourceLabels:
         - __meta_kubernetes_ingress_scheme
         - __meta_kubernetes_ingress_host
-        target_label: __param_target
+        targetLabel: __param_target
       selector:
         matchLabels:
           probe: enabled"
thaum-xyz,ankhmorpork,b337dcd3e233a4ab27c493814d548038768fc06c,paulfantom,pawel@krupa.net.pl,2023-04-28T21:45:51Z,paulfantom,pawel@krupa.net.pl,2023-04-28T21:45:51Z,apps/monitoring: fix typo,apps/monitoring/config.jsonnet;apps/monitoring/manifests/blackboxExporter/ingressProbe.yaml,False,False,False,False,2,2,4,"---FILE: apps/monitoring/config.jsonnet---
@@ -158,7 +158,7 @@
             },
           },
           namespaceSelector: { any: true },
-          relabelConfigs: [{
+          relabelingConfigs: [{
             source_labels: ['__meta_kubernetes_ingress_scheme', '__meta_kubernetes_ingress_host'],
             separator: ';',
             regex: '(.+);(.+)',

---FILE: apps/monitoring/manifests/blackboxExporter/ingressProbe.yaml---
@@ -18,7 +18,7 @@ spec:
     ingress:
       namespaceSelector:
         any: true
-      relabelConfigs:
+      relabelingConfigs:
       - action: replace
         regex: (.+);(.+)
         replacement: ${1}://${2}/"
thaum-xyz,ankhmorpork,fd0da0c7bb3cb272109ce185eb5352912554cd77,paulfantom,pawel@krupa.net.pl,2023-04-28T15:55:06Z,paulfantom,pawel@krupa.net.pl,2023-04-28T15:55:06Z,base/cnpg-system: fix chart ref,base/cnpg-system/release.yaml;base/cnpg-system/values.yaml,False,False,False,False,2,2,4,"---FILE: base/cnpg-system/release.yaml---
@@ -7,7 +7,7 @@ metadata:
 spec:
   chart:
     spec:
-      chart: cnpg/cloudnative-pg
+      chart: cloudnative-pg
       version: ""0.18.0""
       sourceRef:
         kind: HelmRepository

---FILE: base/cnpg-system/values.yaml---
@@ -1,4 +1,4 @@
-# Config reference: https://github.com/external-secrets/external-secrets/blob/main/deploy/charts/external-secrets/values.yaml
+# Config reference: https://github.com/cloudnative-pg/charts/tree/main
 
 additionalArgs:
 - ""--metrics-bind-address=127.0.0.1:8080"""
thaum-xyz,ankhmorpork,4ea487b5199126e0ed364ab8e2b21936782b6d1e,paulfantom,pawel@krupa.net.pl,2023-04-26T06:57:47Z,paulfantom,pawel@krupa.net.pl,2023-04-26T06:58:39Z,"metal: revert gathering data from CRI and fallback to cAdvisor due to https://github.com/k3s-io/k3s/issues/1857

Signed-off-by: paulfantom <pawel@krupa.net.pl>",metal/group_vars/k3s.yml,False,False,False,False,3,2,5,"---FILE: metal/group_vars/k3s.yml---
@@ -11,7 +11,8 @@ k3s_server_config:
   kubelet-arg:
   - ""system-reserved=cpu=100m,memory=230Mi""
   - ""kube-reserved=cpu=200m,memory=100Mi""
-  - ""feature-gates=PodAndContainerStatsFromCRI=true,ComponentSLIs=true"" # Remove ComponentSLIs when k3s 1.27 is released
+  #- ""feature-gates=PodAndContainerStatsFromCRI=true,ComponentSLIs=true"" # Remove ComponentSLIs when k3s 1.27 is released
+  - ""feature-gates=ComponentSLIs=true"" # Remove ComponentSLIs when k3s 1.27 is released
   kube-controller-manager-arg:
   - ""bind-address={{ k3s_master_ip }}""
   kube-scheduler-arg:
@@ -30,7 +31,7 @@ k3s_agent_config:
   - ""system-reserved=cpu=250m,memory=300Mi""
   - ""kube-reserved=cpu=200m,memory=150Mi""
   - ""allowed-unsafe-sysctls=net.ipv4.tcp_adv_win_scale""
-  - ""feature-gates=PodAndContainerStatsFromCRI=true,ComponentSLIs=true"" # Remove ComponentSLIs when k3s 1.27 is released
+  - ""feature-gates=ComponentSLIs=true"" # Remove ComponentSLIs when k3s 1.27 is released
   node-label:
   - ""network.infra/type={{ network | default('slow') }}""
   - ""storage.infra/local={{ 'false' if k3s_no_local_storage is defined else 'true' }}"""
thaum-xyz,ankhmorpork,f319bdf9bae517f2cca7bf368bc2d1faecde1e71,paulfantom,pawel@krupa.net.pl,2023-04-22T14:24:02Z,paulfantom,pawel@krupa.net.pl,2023-04-22T14:24:02Z,base/external-secrets: fix typo and adjust resources,base/external-secrets/values.yaml,False,False,False,False,3,3,6,"---FILE: base/external-secrets/values.yaml---
@@ -9,9 +9,9 @@ certController:
     enabled: true
 
 resources:
-  resuests:
-    cpu: 4m
-    memory: 43Mi
+  requests:
+    cpu: 1m
+    memory: 49Mi
   limits:
     cpu: 20m
     memory: 70Mi"
thaum-xyz,ankhmorpork,c0f41aada325ffb85e5798d642554ffeda74f38b,paulfantom,pawel@krupa.net.pl,2023-04-22T13:42:50Z,paulfantom,pawel@krupa.net.pl,2023-04-22T13:42:50Z,apps/datalake-metrics: fix query data deduplication,apps/datalake-metrics/jsonnet/main.jsonnet;apps/datalake-metrics/manifests/query/deployment.yaml,False,False,False,False,4,3,7,"---FILE: apps/datalake-metrics/jsonnet/main.jsonnet---
@@ -3,13 +3,13 @@ local externalsecret = (import '../../../lib/jsonnet/utils/externalsecrets.libso
 local settings = std.parseYaml(importstr '../settings.yaml')[0];
 
 local i = t.receiveIngestor(settings + settings.receiveIngestor + {
-  replicaLabels: ['receive_replica'],
+  replicaLabels: ['replica', 'receive_replica'],
   replicationFactor: 1,
   serviceMonitor: true,
 });
 
 local r = t.receiveRouter(settings + settings.receiveRouter + {
-  replicaLabels: ['receive_replica'],
+  replicaLabels: ['replica', 'receive_replica'],
   replicationFactor: 1,
   endpoints: i.endpoints,
 });
@@ -19,7 +19,7 @@ local s = t.store(settings + settings.store + {
 });
 
 local q = t.query(settings + settings.query + {
-  replicaLabels: ['prometheus_replica', 'rule_replica'],
+  replicaLabels: ['replica', 'prometheus_replica', 'rule_replica'],
   serviceMonitor: true,
   stores: [s.storeEndpoint] + i.storeEndpoints,
 });

---FILE: apps/datalake-metrics/manifests/query/deployment.yaml---
@@ -44,6 +44,7 @@ spec:
         - --http-address=0.0.0.0:9090
         - --log.level=info
         - --log.format=logfmt
+        - --query.replica-label=replica
         - --query.replica-label=prometheus_replica
         - --query.replica-label=rule_replica
         - --store=dnssrv+_grpc._tcp.thanos-store.datalake-metrics.svc.cluster.local:10901"
thaum-xyz,ankhmorpork,38831fb2f9bfa8412cb9d43bb2d1c69dcedca888,paulfantom,pawel@krupa.net.pl,2023-04-21T07:38:20Z,paulfantom,pawel@krupa.net.pl,2023-04-21T07:38:20Z,apps/homeassistant: fix we-wash sensors,apps/homeassistant/config/configuration.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,3,3,6,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -190,7 +190,7 @@ sensor:
     senders:
       - noreply@we-wash.com
     value_template: >-
-      {% if 'ready for pickup' in subject %}
+      {% if 'ready for pick up' in subject %}
         Ready
       {% elif 'started' in subject %}
         In progress

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -193,7 +193,7 @@ data:
         senders:
           - noreply@we-wash.com
         value_template: >-
-          {% if 'ready for pickup' in subject %}
+          {% if 'ready for pick up' in subject %}
             Ready
           {% elif 'started' in subject %}
             In progress

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: 73636265fa00bde60388fb7fd4dbb457
+        checksum.config/md5: b5c52f54a4021e987b0282384e96a5df
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,a2e177d0172037e5f2780d84db2955445769955f,paulfantom,pawel@krupa.net.pl,2023-04-18T05:54:29Z,paulfantom,pawel@krupa.net.pl,2023-04-18T05:54:29Z,apps/multimedia: fix plex STS syntax,apps/multimedia/manifests/plex/statefulset.yaml,False,False,False,False,2,3,5,"---FILE: apps/multimedia/manifests/plex/statefulset.yaml---
@@ -52,12 +52,11 @@ spec:
         resources:
           limits:
             nvidia.com/gpu: 1
+            cpu: 2
+            memory: 8Gi
           requests:
             cpu: 500m
             memory: 2500Mi
-          limits:
-            cpu: 2
-            memory: 8Gi
         volumeMounts:
         - mountPath: /config
           name: plex-db"
thaum-xyz,ankhmorpork,37244cefaa93df979ff872ff8ccf82d4a4deb769,paulfantom,pawel@krupa.net.pl,2023-04-17T19:12:17Z,paulfantom,pawel@krupa.net.pl,2023-04-17T19:24:26Z,"apps/monitoring: fix affinity settings

Signed-off-by: paulfantom <pawel@krupa.net.pl>",apps/monitoring/config.jsonnet;apps/monitoring/manifests/prometheus/prometheus.yaml,False,False,False,False,9,7,16,"---FILE: apps/monitoring/config.jsonnet---
@@ -45,15 +45,16 @@
     },
     affinity: {
       nodeAffinity: {
-        prefferedDuringSchedulingIgnoredDuringExecution: {
-          nodeSelectorTerms: [{
+        preferredDuringSchedulingIgnoredDuringExecution: [{
+          weight: 1,
+          preference: {
             matchExpressions: [{
               key: 'kubernetes.io/arch',
               operator: 'In',
               values: ['amd64'],
             }],
-          }],
-        },
+          },
+        }],
       },
     },
     mixin+: {

---FILE: apps/monitoring/manifests/prometheus/prometheus.yaml---
@@ -12,13 +12,14 @@ metadata:
 spec:
   affinity:
     nodeAffinity:
-      prefferedDuringSchedulingIgnoredDuringExecution:
-        nodeSelectorTerms:
-        - matchExpressions:
+      preferredDuringSchedulingIgnoredDuringExecution:
+      - preference:
+          matchExpressions:
           - key: kubernetes.io/arch
             operator: In
             values:
             - amd64
+        weight: 1
     podAntiAffinity:
       preferredDuringSchedulingIgnoredDuringExecution:
       - podAffinityTerm:"
thaum-xyz,ankhmorpork,162b7d31f1ff82b53ec8e93b9a06b8aec4edcfef,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-04-16T15:03:25Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-04-16T15:03:25Z,apps/homeassistant: fix we-wash sensors,apps/homeassistant/config/configuration.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,61,61,122,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -151,16 +151,16 @@ sensor:
     folder: we-wash/T1
     senders:
       - noreply@we-wash.com
-    #value_template: >-
-    #  {% if 'ready for pickup' in subject %}
-    #    Ready
-    #  {% elif 'started' in subject %}
-    #    In progress
-    #  {% elif 'waiting for you' in subject %}
-    #    Waiting
-    #  {% else %}
-    #    Unknown
-    #  {% endif %}
+    value_template: >-
+      {% if 'ready for pick up' in subject %}
+        Ready
+      {% elif 'started' in subject %}
+        In progress
+      {% elif 'waiting for you' in subject %}
+        Waiting
+      {% else %}
+        Unknown
+      {% endif %}
   - name: we_wash_w1
     platform: imap_email_content
     server: imap.gmail.com
@@ -170,16 +170,16 @@ sensor:
     folder: we-wash/W1
     senders:
       - noreply@we-wash.com
-    #value_template: >-
-    #  {% if 'ready for pickup' in subject %}
-    #    Ready
-    #  {% elif 'started' in subject %}
-    #    In progress
-    #  {% elif 'waiting for you' in subject %}
-    #    Waiting
-    #  {% else %}
-    #    Unknown
-    #  {% endif %}
+    value_template: >-
+      {% if 'ready for pick up' in subject %}
+        Ready
+      {% elif 'started' in subject %}
+        In progress
+      {% elif 'waiting for you' in subject %}
+        Waiting
+      {% else %}
+        Unknown
+      {% endif %}
   - name: we_wash_w2
     platform: imap_email_content
     server: imap.gmail.com
@@ -189,16 +189,16 @@ sensor:
     folder: we-wash/W2
     senders:
       - noreply@we-wash.com
-    #value_template: >-
-    #  {% if 'ready for pickup' in subject %}
-    #    Ready
-    #  {% elif 'started' in subject %}
-    #    In progress
-    #  {% elif 'waiting for you' in subject %}
-    #    Waiting
-    #  {% else %}
-    #    Unknown
-    #  {% endif %}
+    value_template: >-
+      {% if 'ready for pickup' in subject %}
+        Ready
+      {% elif 'started' in subject %}
+        In progress
+      {% elif 'waiting for you' in subject %}
+        Waiting
+      {% else %}
+        Unknown
+      {% endif %}
 
 template:
 - sensor:

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -154,16 +154,16 @@ data:
         folder: we-wash/T1
         senders:
           - noreply@we-wash.com
-        #value_template: >-
-        #  {% if 'ready for pickup' in subject %}
-        #    Ready
-        #  {% elif 'started' in subject %}
-        #    In progress
-        #  {% elif 'waiting for you' in subject %}
-        #    Waiting
-        #  {% else %}
-        #    Unknown
-        #  {% endif %}
+        value_template: >-
+          {% if 'ready for pick up' in subject %}
+            Ready
+          {% elif 'started' in subject %}
+            In progress
+          {% elif 'waiting for you' in subject %}
+            Waiting
+          {% else %}
+            Unknown
+          {% endif %}
       - name: we_wash_w1
         platform: imap_email_content
         server: imap.gmail.com
@@ -173,16 +173,16 @@ data:
         folder: we-wash/W1
         senders:
           - noreply@we-wash.com
-        #value_template: >-
-        #  {% if 'ready for pickup' in subject %}
-        #    Ready
-        #  {% elif 'started' in subject %}
-        #    In progress
-        #  {% elif 'waiting for you' in subject %}
-        #    Waiting
-        #  {% else %}
-        #    Unknown
-        #  {% endif %}
+        value_template: >-
+          {% if 'ready for pick up' in subject %}
+            Ready
+          {% elif 'started' in subject %}
+            In progress
+          {% elif 'waiting for you' in subject %}
+            Waiting
+          {% else %}
+            Unknown
+          {% endif %}
       - name: we_wash_w2
         platform: imap_email_content
         server: imap.gmail.com
@@ -192,16 +192,16 @@ data:
         folder: we-wash/W2
         senders:
           - noreply@we-wash.com
-        #value_template: >-
-        #  {% if 'ready for pickup' in subject %}
-        #    Ready
-        #  {% elif 'started' in subject %}
-        #    In progress
-        #  {% elif 'waiting for you' in subject %}
-        #    Waiting
-        #  {% else %}
-        #    Unknown
-        #  {% endif %}
+        value_template: >-
+          {% if 'ready for pickup' in subject %}
+            Ready
+          {% elif 'started' in subject %}
+            In progress
+          {% elif 'waiting for you' in subject %}
+            Waiting
+          {% else %}
+            Unknown
+          {% endif %}
 
     template:
     - sensor:

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: 81cbac15f8a938f2eac9f54ff45f6cd5
+        checksum.config/md5: 73636265fa00bde60388fb7fd4dbb457
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,afd6546ebc761e4b9c1ec2deda2cb67058ad4072,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-03-02T12:20:07Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-03-02T12:23:38Z,".github: fix monitoring workflow

Signed-off-by: Pawe Krupa (paulfantom) <pawel@krupa.net.pl>",.github/workflows/monitoring.yml,False,False,False,False,4,4,8,"---FILE: .github/workflows/monitoring.yml---
@@ -22,11 +22,11 @@ jobs:
       - run: go install github.com/brancz/gojsontoyaml@latest
       - run: go install -a github.com/prometheus/alertmanager/cmd/amtool@latest
       - name: Unpack config
-        run: gojsontoyaml -yamltojson <apps/monitoring/manifests/alertmanager/secret.yaml | jq -rc '.spec.template.data[""alertmanager.yaml""]' > alertmanager.yaml
+        run: gojsontoyaml -yamltojson <apps/monitoring/manifests/alertmanager/configTemplate.yaml | jq -rc '.data[""alertmanager.yaml""]' > alertmanager.yaml
       - name: Replace secrets
         run: |
-          sed -i 's|$(SLACK_API_URL)|https://example.org|g' alertmanager.yaml
-          sed -i 's|$(HEALTHCHECKS_URL)|https://example.org|g' alertmanager.yaml
-          sed -i 's|$(OPSGENIE_API_KEY)|example|g' alertmanager.yaml
+          sed -i 's|{{ .slack_api_url }}|https://example.org|g' alertmanager.yaml
+          sed -i 's|{{ .healthchecks_url }}|https://example.org|g' alertmanager.yaml
+          sed -i 's|{{ .opsgenie_api_key }}|example|g' alertmanager.yaml
       - name: Check config
         run: amtool check-config alertmanager.yaml"
thaum-xyz,ankhmorpork,2937fdecdd23eed6659839f01ca82e122fc84e97,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-03-02T12:08:13Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-03-02T12:08:13Z,*: fix auto-updater,.github/workflows/versions.yaml;Makefile,False,False,False,False,3,6,9,"---FILE: .github/workflows/versions.yaml---
@@ -27,13 +27,13 @@ jobs:
       run: go install github.com/devopyio/yamlfmt@latest
     - name: Upgrade
       run: |
-        export GITHUB_TOKEN=${{ secrets.GITHUB_TOKEN }}
+        export GITHUB_TOKEN=${{ secrets.PAT_SECRET }}
         make upgrade
     - name: Create Pull Request
       uses: peter-evans/create-pull-request@v4
       with:
         commit-message: ""[bot] Automated version update""
-        title: ""[bot] Automated version update""
+        title: ""Automated version update""
         body: |
           This is an automated version update performed from CI on behalf of @paulfantom.
 

---FILE: Makefile---
@@ -5,15 +5,12 @@ DIRS=\
 	base/ingress-nginx \
 	base/flux-system \
 	apps/auth \
+	apps/datalake-metrics \
 	apps/dns \
 	apps/homeassistant \
 	apps/homer \
 	apps/monitoring \
-	apps/parca \
 	apps/portal \
-	apps/recipe \
-	apps/snmp \
-	apps/system-update \
 	apps/unifi
 
 MAKEFILES=$(shell find . -name ""Makefile"" -not -path ""*/vendor/*"" -not -path ""./Makefile"")"
thaum-xyz,ankhmorpork,6bd987130b3e9720297951b4b4360afa32e379dd,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-02-16T13:11:00Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-02-16T13:11:00Z,apps/unifi: fix configuration,apps/unifi/jsonnet/main.jsonnet;apps/unifi/manifests/poller/configuration.yaml;apps/unifi/manifests/poller/deployment.yaml;apps/unifi/settings.yaml,False,False,False,False,16,12,28,"---FILE: apps/unifi/jsonnet/main.jsonnet---
@@ -26,7 +26,7 @@ local all = {
           template+: {
             engineVersion: 'v2',
             data: {
-              'unifi-poller.conf': config.poller.config,
+              'up.conf': config.poller.config,
             },
           },
         },
@@ -48,9 +48,9 @@ local all = {
       }],
       resources: config.poller.resources,
       volumeMounts: [{
-        mountPath: '/config/unifi-poller.conf',
+        mountPath: '/etc/unpoller/up.conf',
         name: 'config',
-        subPath: 'unifi-poller.conf',
+        subPath: 'up.conf',
       }],
     },
     deployment: {
@@ -68,7 +68,8 @@ local all = {
         template: {
           metadata: $.poller._metadata {
             annotations: {
-              'checksum.config/md5': std.md5(std.toString(config.poller.credentialsRefs)),
+              'checksum.credentials/md5': std.md5(std.toString(config.poller.credentialsRefs)),
+              'checksum.config/md5': std.md5(std.toString(config.poller.config)),
             },
           },
           spec: {

---FILE: apps/unifi/manifests/poller/configuration.yaml---
@@ -23,7 +23,7 @@ spec:
     name: poller
     template:
       data:
-        unifi-poller.conf: |
+        up.conf: |
           [poller]
               debug = false
               quiet = false
@@ -36,12 +36,13 @@ spec:
               disable = true
           [webserver]
               enable = false
-          [unifi]
+          [unifi.defaults]
               url = ""https://192.168.2.1""
               user = ""{{ .user }}""
               pass = ""{{ .pass }}""
-              sites = [""default""]
+              sites = [""all""]
               save_sites = true
+              hash_pii = false
               save_ids = false
               save_events = false
               save_alarms = false

---FILE: apps/unifi/manifests/poller/deployment.yaml---
@@ -15,7 +15,8 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: 985702d46b91fbbe23caedf6f32467cc
+        checksum.config/md5: 55923d20e1fadcf735c826cce4cb847f
+        checksum.credentials/md5: 985702d46b91fbbe23caedf6f32467cc
       labels:
         app.kubernetes.io/component: exporter
         app.kubernetes.io/name: unifi-poller
@@ -36,9 +37,9 @@ spec:
             cpu: 5m
             memory: 20Mi
         volumeMounts:
-        - mountPath: /config/unifi-poller.conf
+        - mountPath: /etc/unpoller/up.conf
           name: config
-          subPath: unifi-poller.conf
+          subPath: up.conf
       restartPolicy: Always
       volumes:
       - name: config

---FILE: apps/unifi/settings.yaml---
@@ -30,12 +30,13 @@ poller:
             disable = true
         [webserver]
             enable = false
-        [unifi]
+        [unifi.defaults]
             url = ""https://192.168.2.1""
             user = ""{{ .user }}""
             pass = ""{{ .pass }}""
-            sites = [""default""]
+            sites = [""all""]
             save_sites = true
+            hash_pii = false
             save_ids = false
             save_events = false
             save_alarms = false"
thaum-xyz,ankhmorpork,20f416b59606512ccdc7353ae2c5bc5874e0d5aa,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-02-15T18:50:00Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-02-15T18:50:00Z,apps/unifi: fix image,apps/unifi/manifests/poller/deployment.yaml;apps/unifi/settings.yaml,False,False,False,False,2,2,4,"---FILE: apps/unifi/manifests/poller/deployment.yaml---
@@ -23,7 +23,7 @@ spec:
       namespace: unifi
     spec:
       containers:
-      - image: golift/unifi-poller:2.7.11
+      - image: ghcr.io/unpoller/unpoller:v2.7.11
         name: unifi-poller
         ports:
         - containerPort: 9130

---FILE: apps/unifi/settings.yaml---
@@ -7,7 +7,7 @@ backup:
 
 poller:
   version: 2.7.11 # application-version-from-github: unpoller/unpoller
-  image: golift/unifi-poller:2.7.11  # application-image-from-github: unpoller/unpoller
+  image: ghcr.io/unpoller/unpoller:v2.7.11  # application-image-from-github: unpoller/unpoller
   resources:
     limits:
       memory: 100Mi"
thaum-xyz,ankhmorpork,a1bad889d0cc8f69ea26a411bffe2e92da1d566f,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-02-15T18:13:56Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-02-15T18:13:56Z,apps/paperless: fix database connection secret,apps/paperless/jsonnet/main.jsonnet;apps/paperless/manifests/web/databaseSecret.yaml,False,False,False,False,20,12,32,"---FILE: apps/paperless/jsonnet/main.jsonnet---
@@ -20,12 +20,17 @@ local all = {
       }
     ) + {
       spec+: {
-        template+: {
-          data+: {
-            PAPERLESS_DBHOST: 'db.paperless.svc',
-            PAPERLESS_DBNAME: config.paperless.database.name,
-            PAPERLESS_DBPORT: '5432',
-            PAPERLESS_DBSSLMODE: 'prefer',
+        target+: {
+          template+: {
+            engineVersion: 'v2',
+            data+: {
+              PAPERLESS_DBUSER: '{{ .PAPERLESS_DBUSER }}',
+              PAPERLESS_DBPASS: '{{ .PAPERLESS_DBPASS }}',
+              PAPERLESS_DBHOST: 'db.paperless.svc',
+              PAPERLESS_DBNAME: config.paperless.database.name,
+              PAPERLESS_DBPORT: '5432',
+              PAPERLESS_DBSSLMODE: 'prefer',
+            },
           },
         },
       },

---FILE: apps/paperless/manifests/web/databaseSecret.yaml---
@@ -22,9 +22,12 @@ spec:
     name: doppler-auth-api
   target:
     name: paperless-db
-  template:
-    data:
-      PAPERLESS_DBHOST: db.paperless.svc
-      PAPERLESS_DBNAME: paperless
-      PAPERLESS_DBPORT: ""5432""
-      PAPERLESS_DBSSLMODE: prefer
+    template:
+      data:
+        PAPERLESS_DBHOST: db.paperless.svc
+        PAPERLESS_DBNAME: paperless
+        PAPERLESS_DBPASS: '{{ .PAPERLESS_DBPASS }}'
+        PAPERLESS_DBPORT: ""5432""
+        PAPERLESS_DBSSLMODE: prefer
+        PAPERLESS_DBUSER: '{{ .PAPERLESS_DBUSER }}'
+      engineVersion: v2"
thaum-xyz,ankhmorpork,216d9166d06b6a8289c0cc42080db2f01df7c872,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-02-15T15:17:24Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-02-15T15:17:24Z,apps/dns: fix type error,apps/dns/jsonnet/main.jsonnet;apps/dns/manifests/envs.yaml,False,False,False,False,3,3,6,"---FILE: apps/dns/jsonnet/main.jsonnet---
@@ -28,12 +28,12 @@ local all = {
     envs: externalsecret(
       $.coredns.serviceAccount.metadata { name: $.config.coredns.secretName },
       'doppler-auth-api',
-      {
+      [{
         secretKey: 'NEXTDNS_ID',
         remoteRef: {
           key: $.config.coredns.nextdnsIDRef,
         },
-      }
+      }],
     ),
     local metallbMetadata = {
       metadata+: {

---FILE: apps/dns/manifests/envs.yaml---
@@ -10,7 +10,7 @@ metadata:
   namespace: dns
 spec:
   data:
-    remoteRef:
+  - remoteRef:
       key: DNS_NEXTDNS_ID
     secretKey: NEXTDNS_ID
   refreshInterval: 1h"
thaum-xyz,ankhmorpork,053c433907cef91f13baab513a675bd3d0216f39,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-02-15T13:45:22Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-02-15T13:45:25Z,"apps/homer: downgrade to allow usage of yaml anchors

realted to https://github.com/bastienwirtz/homer/issues/559",apps/homer/manifests/configmap.yaml;apps/homer/manifests/deployment.yaml;apps/homer/manifests/ingress.yaml;apps/homer/manifests/service.yaml;apps/homer/manifests/serviceAccount.yaml;apps/homer/settings.yaml,False,False,False,False,10,10,20,"---FILE: apps/homer/manifests/configmap.yaml---
@@ -190,6 +190,6 @@ metadata:
     app.kubernetes.io/component: server
     app.kubernetes.io/name: homer
     app.kubernetes.io/part-of: homer
-    app.kubernetes.io/version: 22.11.2
+    app.kubernetes.io/version: 22.08.1
   name: homer-config
   namespace: homer

---FILE: apps/homer/manifests/deployment.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: server
     app.kubernetes.io/name: homer
     app.kubernetes.io/part-of: homer
-    app.kubernetes.io/version: 22.11.2
+    app.kubernetes.io/version: 22.08.1
   name: homer
   namespace: homer
 spec:
@@ -18,12 +18,12 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: d243b57b4a8125e24f7ae621d023c9ee
+        checksum.config/md5: 0a2788cd686f1f691019d6c432d8e441
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homer
         app.kubernetes.io/part-of: homer
-        app.kubernetes.io/version: 22.11.2
+        app.kubernetes.io/version: 22.08.1
     spec:
       affinity:
         podAntiAffinity:
@@ -38,7 +38,7 @@ spec:
               topologyKey: kubernetes.io/hostname
             weight: 100
       containers:
-      - image: b4bz/homer:v22.11.2
+      - image: b4bz/homer:v22.08.1
         imagePullPolicy: IfNotPresent
         name: homer
         ports:

---FILE: apps/homer/manifests/ingress.yaml---
@@ -8,7 +8,7 @@ metadata:
     app.kubernetes.io/component: server
     app.kubernetes.io/name: homer
     app.kubernetes.io/part-of: homer
-    app.kubernetes.io/version: 22.11.2
+    app.kubernetes.io/version: 22.08.1
     probe: enabled
   name: homer
   namespace: homer

---FILE: apps/homer/manifests/service.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: server
     app.kubernetes.io/name: homer
     app.kubernetes.io/part-of: homer
-    app.kubernetes.io/version: 22.11.2
+    app.kubernetes.io/version: 22.08.1
   name: homer
   namespace: homer
 spec:

---FILE: apps/homer/manifests/serviceAccount.yaml---
@@ -6,6 +6,6 @@ metadata:
     app.kubernetes.io/component: server
     app.kubernetes.io/name: homer
     app.kubernetes.io/part-of: homer
-    app.kubernetes.io/version: 22.11.2
+    app.kubernetes.io/version: 22.08.1
   name: homer
   namespace: homer

---FILE: apps/homer/settings.yaml---
@@ -1,6 +1,6 @@
 ---
-version: ""22.11.2""  # application-version-from-github: bastienwirtz/homer
-image: ""b4bz/homer:v22.11.2""  # application-image-from-github: bastienwirtz/homer
+version: ""22.08.1""  # application-version-from-github: bastienwirtz/homer
+image: ""b4bz/homer:v22.08.1""  # application-image-from-github: bastienwirtz/homer
 namespace: ""homer""
 replicas: 2
 domain: ""ankhmorpork.thaum.xyz"""
thaum-xyz,ankhmorpork,e116728ed35d72aa6f30a30f6bb5116fa9492b55,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-02-03T14:25:10Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-02-03T14:55:48Z,"apps/homeassistant: fix meal plan sensor

Signed-off-by: Pawe Krupa (paulfantom) <pawel@krupa.net.pl>",apps/homeassistant/config/configuration.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,15,5,20,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -131,11 +131,16 @@ sensor:
       content-type: application/json
       authorization: !secret recipes_token
     resource: https://recipes.krupa.net.pl/api/meal-plan
+    params:
+      from_date: '{{ now().strftime(""%Y-%m-%d"") }}'
+      to_date: '{{ now().strftime(""%Y-%m-%d"") }}'
     value_template: >
       {% if value_json is none %}
         No meal plan
-      {% elif value_json[0] %}
-      {{ value_json[0].recipe.name }}
+      {% elif value_json[0].title %}
+      {{ value_json[0].title }}
+      {% elif value_json[0].recipe_name %}
+      {{ value_json[0].recipe_name }}
       {% endif %}
 
 template:

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -134,11 +134,16 @@ data:
           content-type: application/json
           authorization: !secret recipes_token
         resource: https://recipes.krupa.net.pl/api/meal-plan
+        params:
+          from_date: '{{ now().strftime(""%Y-%m-%d"") }}'
+          to_date: '{{ now().strftime(""%Y-%m-%d"") }}'
         value_template: >
           {% if value_json is none %}
             No meal plan
-          {% elif value_json[0] %}
-          {{ value_json[0].recipe.name }}
+          {% elif value_json[0].title %}
+          {{ value_json[0].title }}
+          {% elif value_json[0].recipe_name %}
+          {{ value_json[0].recipe_name }}
           {% endif %}
 
     template:

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: 0c72ea2b4e67d752744611c8cc34518f
+        checksum.config/md5: 64ae20b11d3215596d8203d57184aa5c
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,33927e3e4a68617ab3c1b34ad5740129d8723280,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-02-02T18:26:53Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-02-02T18:26:53Z,apps/homeassistant: fix projector screen actions,apps/homeassistant/config/configuration.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,387,146,533,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -223,28 +223,28 @@ cover:
       projector_screen:
         device_class: blind
         friendly_name: ""Projector Screen""
-        value_template: ""{{ states('binary_sensor.sonoff_a48004cd69') | bool }}""
+        value_template: ""{{ not (states('binary_sensor.sonoff_a48004cd69') | bool) }}""
         open_cover:
           service: remote.send_command
           target:
             entity_id: remote.sonoff_10011faac6
           data:
             device: RFBridge433
-            command: Down
-        close_cover:        
+            command: Up
+        close_cover:
           service: remote.send_command
           target:
             entity_id: remote.sonoff_10011faac6
           data:
             device: RFBridge433
-            command: Up
+            command: Down
         stop_cover:
           service: remote.send_command
           target:
             entity_id: remote.sonoff_10011faac6
           data:
             device: RFBridge433
-            command: Down
+            command: Stop
 
 input_boolean:
   projector:

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -1,145 +1,386 @@
 apiVersion: v1
 data:
-  configuration.yaml: ""homeassistant:\n  name: Home\n  latitude: !secret home_latitude\n
-    \ longitude: !secret home_longitude\n  elevation: !secret home_elevation\n  unit_system:
-    metric\n  time_zone: Europe/Berlin\n  country: DE\n  customize: !include customize.yaml\n
-    \ #auth_providers:\n  #  - type: homeassistant\n  #  - type: trusted_networks\n
-    \ #    allow_bypass_login: true\n  #    trusted_networks:\n  #      - 192.168.2.0/24\n
-    \ external_url: https://home.ankhmorpork.thaum.xyz\n\n# Uncomment this if you
-    are using SSL/TLS, running in Docker container, etc.\nhttp:\n  # base_url: https://home.ankhmorpork.thaum.xyz\n
-    \ use_x_forwarded_for: true\n  trusted_proxies: !secret trusted_proxies\n\n#panel_iframe:\n#
-    \ esphome:\n#    title: \""ESPHome\""\n#    url: \""http://192.168.2.94:6052\""\n#
-    \   icon: \""mdi:chip\""\n#    require_admin: true\n\n\n# No-config integrations\n#default_config:\n#
-    Redefine configuration options from default_config for more control\n# Current
-    list can be found in https://www.home-assistant.io/integrations/default_config/\nautomation:
-    !include automations.yaml\nbackup:\n#bluetooth:\n#cloud:\nconfig:\ncounter:\ndhcp:\nenergy:\nfrontend:\n#hardware:\nhistory:\nhomeassistant_alerts:\nimage_upload:\n#input_boolean:
-    # configured in lower part of the file\ninput_datetime: # configured in lower
-    part of the file\ninput_number:\n#input_select:  # configured in lower part of
-    the file\ninput_text:\nlogbook:\nmap:\n#media_source:\nmobile_app:\nmy:\nperson:\nscene:
-    !include scenes.yaml\nschedule:\nscript: !include scripts.yaml\nssdp:\nstream:\nsun:\nsystem_health:\n#tag:\ntimer:\n#usb:\nwebhook:\n#zeroconf:\nzone:\n#
-    END OF default_config\n\nwake_on_lan:\nmedia_extractor:\n\ngroup:\n  people:\n
-    \   name: People\n    entities:\n    - person.pawel\n    - person.adrianna\n\nprometheus:\n
-    \ namespace: hass\n  filter:\n    exclude_domains:\n    - device_tracker\n    -
-    light\n\nlock:\n  - platform: kiwi\n    username: !secret kiwi_username\n    password:
-    !secret kiwi_password\n\nalarm_control_panel:\n  - platform: manual\n    name:
-    Home Alarm\n    code_arm_required: false\n    arming_time: 60\n    trigger_time:
-    600\n    disarmed:\n      trigger_time: 0\n    armed_home:\n      arming_time:
-    60\n      delay_time: 30\n\nclimate:\n- platform: generic_thermostat\n  name:
-    Fridge\n  heater: light.on_off_plug_1\n  target_sensor: sensor.fridge_temperature\n
-    \ ac_mode: true\n  min_temp: 4\n  max_temp: 10\n  target_temp: 6\n  cold_tolerance:
-    1\n  hot_tolerance: 1\n\n# Sensors\nsensor:\n  - platform: time_date\n    display_options:\n
-    \     - 'time'\n      - 'date'\n  - platform: rest\n    name: recipes\n    scan_interval:
-    3600\n    headers:\n      content-type: application/json\n      authorization:
-    !secret recipes_token\n    resource: https://recipes.krupa.net.pl/api/meal-plan\n
-    \   value_template: >\n      {% if value_json is none %}\n        No meal plan\n
-    \     {% elif value_json[0] %}\n      {{ value_json[0].recipe.name }}\n      {%
-    endif %}\n\ntemplate:\n- sensor:\n  - name: \""ESP Display\""\n    state: \""{{ states('switch.espdisplay_backlight')
-    }}\""\n    attributes:\n      # First 6 characters of each line are considered
-    a static prefix\n      line1: \""LUNCH {{ states('sensor.recipes') | replace('','a')
-    | replace('','c') | replace('','e') | replace('','l') | replace('','o') |
-    replace('','s') | replace('','z') | replace('','z') | regex_replace(find='[^\\x00-\\x7F]+',
-    replace='', ignorecase=False) }}\""\n      line2: >\n        {%\n          set
-    calendars = [(\n            \""00:00\"",\n            \""-- NEXT DAY --\"",\n            as_timestamp(state_attr('sun.sun','next_midnight'))
-    | int\n          ),(\n            as_timestamp(state_attr('calendar.pawel_krupa_net_pl','start_time'))
-    | int | timestamp_custom(\""%H:%M\""),\n            state_attr('calendar.pawel_krupa_net_pl','message')
-    | regex_replace(find='[^\\x00-\\x7F]+', replace='', ignorecase=False) | trim,\n
-    \           as_timestamp(state_attr('calendar.pawel_krupa_net_pl','start_time'))
-    | int\n          ),(\n            as_timestamp(state_attr('calendar.paulfantom','start_time'))
-    | int | timestamp_custom(\""%H:%M\""),\n            state_attr('calendar.paulfantom','message')
-    | regex_replace(find='[^\\x00-\\x7F]+', replace='', ignorecase=False) | trim,\n
-    \           as_timestamp(state_attr('calendar.paulfantom','start_time')) | int\n
-    \         ),(\n            as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time'))
-    | int | timestamp_custom(\""%H:%M\""),\n            state_attr('calendar.adrianna_wojas_gmail_com','message')
-    | regex_replace(find='[^\\x00-\\x7F]+', replace='', ignorecase=False) | trim,\n
-    \           as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time'))
-    | int\n          )] | rejectattr(2, \""gt\"", as_timestamp(utcnow()) | int + 24*60*60)
-    | sort(attribute=2) | unique | list\n        %}\n        {{ calendars[0][0] }}
-    {{ calendars[0][1] }}\n      line3: >\n        {%\n          set calendars = [(\n
-    \           \""00:00\"",\n            \""-- NEXT DAY --\"",\n            as_timestamp(state_attr('sun.sun','next_midnight'))
-    | int\n          ),(\n            as_timestamp(state_attr('calendar.pawel_krupa_net_pl','start_time'))
-    | int | timestamp_custom(\""%H:%M\""),\n            state_attr('calendar.pawel_krupa_net_pl','message')
-    | regex_replace(find='[^\\x00-\\x7F]+', replace='', ignorecase=False) | trim,\n
-    \           as_timestamp(state_attr('calendar.pawel_krupa_net_pl','start_time'))
-    | int\n          ),(\n            as_timestamp(state_attr('calendar.paulfantom','start_time'))
-    | int | timestamp_custom(\""%H:%M\""),\n            state_attr('calendar.paulfantom','message')
-    | regex_replace(find='[^\\x00-\\x7F]+', replace='', ignorecase=False) | trim,\n
-    \           as_timestamp(state_attr('calendar.paulfantom','start_time')) | int\n
-    \         ),(\n            as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time'))
-    | int | timestamp_custom(\""%H:%M\""),\n            state_attr('calendar.adrianna_wojas_gmail_com','message')
-    | regex_replace(find='[^\\x00-\\x7F]+', replace='', ignorecase=False) | trim,\n
-    \           as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time'))
-    | int\n          )] | rejectattr(2, \""gt\"", as_timestamp(utcnow()) | int + 24*60*60)
-    | sort(attribute=2) | unique | list\n        %}\n        {% if calendars|length
-    > 1 %}\n        {{ calendars[1][0] }} {{ calendars[1][1] }}\n        {% else %}\n\n
-    \       {% endif %}\n      line4: >\n        {%\n          set calendars = [(\n
-    \           \""00:00\"",\n            \""-- NEXT DAY --\"",\n            as_timestamp(state_attr('sun.sun','next_midnight'))
-    | int\n          ),(\n            as_timestamp(state_attr('calendar.pawel_krupa_net_pl','start_time'))
-    | int | timestamp_custom(\""%H:%M\""),\n            state_attr('calendar.pawel_krupa_net_pl','message')
-    | regex_replace(find='[^\\x00-\\x7F]+', replace='', ignorecase=False) | trim,\n
-    \           as_timestamp(state_attr('calendar.pawel_krupa_net_pl','start_time'))
-    | int\n          ),(\n            as_timestamp(state_attr('calendar.paulfantom','start_time'))
-    | int | timestamp_custom(\""%H:%M\""),\n            state_attr('calendar.paulfantom','message')
-    | regex_replace(find='[^\\x00-\\x7F]+', replace='', ignorecase=False) | trim,\n
-    \           as_timestamp(state_attr('calendar.paulfantom','start_time')) | int\n
-    \         ),(\n            as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time'))
-    | int | timestamp_custom(\""%H:%M\""),\n            state_attr('calendar.adrianna_wojas_gmail_com','message')
-    | regex_replace(find='[^\\x00-\\x7F]+', replace='', ignorecase=False) | trim,\n
-    \           as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time'))
-    | int\n          )] | rejectattr(2, \""gt\"", as_timestamp(utcnow()) | int + 24*60*60)
-    | sort(attribute=2) | unique | list\n        %}\n        {% if calendars|length
-    > 2 and calendars[2][1] != \""-- NEXT DAY --\"" %}\n        {{ calendars[2][0] }}
-    {{ calendars[2][1] }}\n        {% else %}\n\n        {% endif %}\n\ncover:\n  -
-    platform: template\n    covers:\n      projector_screen:\n        device_class:
-    blind\n        friendly_name: \""Projector Screen\""\n        value_template: \""{{
-    states('binary_sensor.sonoff_a48004cd69') | bool }}\""\n        open_cover:\n          service:
-    remote.send_command\n          target:\n            entity_id: remote.sonoff_10011faac6\n
-    \         data:\n            device: RFBridge433\n            command: Down\n
-    \       close_cover:        \n          service: remote.send_command\n          target:\n
-    \           entity_id: remote.sonoff_10011faac6\n          data:\n            device:
-    RFBridge433\n            command: Up\n        stop_cover:\n          service:
-    remote.send_command\n          target:\n            entity_id: remote.sonoff_10011faac6\n
-    \         data:\n            device: RFBridge433\n            command: Down\n\ninput_boolean:\n
-    \ projector:\n    name: Projector State\n    icon: mdi:projector\n  projector_screen:\n
-    \   name: Projector Screen State\n    icon: mdi:projector-screen-variant-outline\n
-    \ movie_time:\n    name: Movie Time\n    icon: mdi:movie-open\n\ninput_select:\n
-    \ speakers:\n    name: Speakers Input\n    icon: mdi:speakers\n    options:\n
-    \   - opt/coax\n    - line1/2\n    - bt\n    initial: line1/2\n\nplant:\n  jovita:\n
-    \   sensors:\n      moisture: sensor.jovita_moisture\n      temperature: sensor.jovita_temperature\n
-    \     conductivity: sensor.jovita_soil_conductivity\n      brightness: sensor.jovita_illuminance\n
-    \   min_moisture: 15\n    max_moisture: 60\n    min_conductivity: 350\n    max_conductivity:
-    2000\n    min_temperature: 10\n    max_temperature: 32\n    min_brightness: 500\n
-    \   max_brightness: 12000\n  svetlana:\n    sensors:\n      moisture: sensor.svetlana_plant_moisture\n
-    \     temperature: sensor.svetlana_plant_temperature\n      conductivity: sensor.svetlana_plant_conductivity\n
-    \     brightness: sensor.svetlana_plant_illuminance\n    min_moisture: 15\n    max_moisture:
-    60\n    min_conductivity: 350\n    max_conductivity: 2000\n    min_temperature:
-    10\n    max_temperature: 32\n    min_brightness: 500\n    max_brightness: 12000\n
-    \ violet:\n    sensors:\n      moisture: sensor.violet_moisture\n      temperature:
-    sensor.violet_temperature\n      conductivity: sensor.violet_soil_conductivity\n
-    \     brightness: sensor.violet_illuminance\n    min_moisture: 15\n    max_moisture:
-    60\n    min_conductivity: 350\n    max_conductivity: 2000\n    min_temperature:
-    10\n    max_temperature: 32\n    min_brightness: 600\n    max_brightness: 20000\n
-    \ herbs:\n    sensors:\n      moisture: sensor.herbs_moisture\n      temperature:
-    sensor.herbs_temperature\n      conductivity: sensor.herbs_soil_conductivity\n
-    \     brightness: sensor.herbs_illuminance\n    min_moisture: 15\n    max_moisture:
-    60\n    min_conductivity: 350\n    max_conductivity: 2000\n    min_temperature:
-    10\n    max_temperature: 32\n    min_brightness: 3700\n    max_brightness: 60000\n
-    \ basil:\n    sensors:\n      moisture: sensor.basil_moisture\n      temperature:
-    sensor.basil_temperature\n      conductivity: sensor.basil_soil_conductivity\n
-    \     brightness: sensor.basil_illuminance\n    min_moisture: 15\n    max_moisture:
-    60\n    min_conductivity: 350\n    max_conductivity: 2000\n    min_temperature:
-    8\n    max_temperature: 32\n    min_brightness: 2500\n    max_brightness: 60000\n\n#notify:\n#
-    \ - platform: slack\n#    name: slack\n#    api_key: !secret slack_api_key\n#
-    \   default_channel: '#home'\n#    username: \""home-assistant\""\n\nswitch:\n  -
-    platform: wake_on_lan\n    name: pawel-pc\n    host: \""192.168.2.51\""\n    mac:
-    !secret pawel_pc_mac\n  - platform: wake_on_lan\n    name: adus-pc\n    host:
-    \""192.168.2.50\""\n    mac: !secret adus_pc_mac\n\ngoogle_assistant:\n  project_id:
-    ankhhomeassistant\n  service_account: !include google_service_account.json\n  report_state:
-    true\n\n#google:\n#  client_id: !secret google_client_id\n#  client_secret: !secret
-    google_client_secret\n#  calendar_access: \""read_only\""\n\nsonoff:\n  username:
-    !secret sonoff_username\n  password: !secret sonoff_password\n  scan_interval:
-    60 #(optional, lower values than 60 won't work anymore!)\n  mode: auto\n  #grace_period:
-    600 #(optional)\n  #api_region: 'eu' #(optional)\n  #entity_prefix: True #(optional)\n
-    \ #debug: False #(optional)\n\nrecorder:\n  db_url: !secret postgresql_uri\n""
+  configuration.yaml: |
+    homeassistant:
+      name: Home
+      latitude: !secret home_latitude
+      longitude: !secret home_longitude
+      elevation: !secret home_elevation
+      unit_system: metric
+      time_zone: Europe/Berlin
+      country: DE
+      customize: !include customize.yaml
+      #auth_providers:
+      #  - type: homeassistant
+      #  - type: trusted_networks
+      #    allow_bypass_login: true
+      #    trusted_networks:
+      #      - 192.168.2.0/24
+      external_url: https://home.ankhmorpork.thaum.xyz
+
+    # Uncomment this if you are using SSL/TLS, running in Docker container, etc.
+    http:
+      # base_url: https://home.ankhmorpork.thaum.xyz
+      use_x_forwarded_for: true
+      trusted_proxies: !secret trusted_proxies
+
+    #panel_iframe:
+    #  esphome:
+    #    title: ""ESPHome""
+    #    url: ""http://192.168.2.94:6052""
+    #    icon: ""mdi:chip""
+    #    require_admin: true
+
+
+    # No-config integrations
+    #default_config:
+    # Redefine configuration options from default_config for more control
+    # Current list can be found in https://www.home-assistant.io/integrations/default_config/
+    automation: !include automations.yaml
+    backup:
+    #bluetooth:
+    #cloud:
+    config:
+    counter:
+    dhcp:
+    energy:
+    frontend:
+    #hardware:
+    history:
+    homeassistant_alerts:
+    image_upload:
+    #input_boolean: # configured in lower part of the file
+    input_datetime: # configured in lower part of the file
+    input_number:
+    #input_select:  # configured in lower part of the file
+    input_text:
+    logbook:
+    map:
+    #media_source:
+    mobile_app:
+    my:
+    person:
+    scene: !include scenes.yaml
+    schedule:
+    script: !include scripts.yaml
+    ssdp:
+    stream:
+    sun:
+    system_health:
+    #tag:
+    timer:
+    #usb:
+    webhook:
+    #zeroconf:
+    zone:
+    # END OF default_config
+
+    wake_on_lan:
+    media_extractor:
+
+    group:
+      people:
+        name: People
+        entities:
+        - person.pawel
+        - person.adrianna
+
+    prometheus:
+      namespace: hass
+      filter:
+        exclude_domains:
+        - device_tracker
+        - light
+
+    lock:
+      - platform: kiwi
+        username: !secret kiwi_username
+        password: !secret kiwi_password
+
+    alarm_control_panel:
+      - platform: manual
+        name: Home Alarm
+        code_arm_required: false
+        arming_time: 60
+        trigger_time: 600
+        disarmed:
+          trigger_time: 0
+        armed_home:
+          arming_time: 60
+          delay_time: 30
+
+    climate:
+    - platform: generic_thermostat
+      name: Fridge
+      heater: light.on_off_plug_1
+      target_sensor: sensor.fridge_temperature
+      ac_mode: true
+      min_temp: 4
+      max_temp: 10
+      target_temp: 6
+      cold_tolerance: 1
+      hot_tolerance: 1
+
+    # Sensors
+    sensor:
+      - platform: time_date
+        display_options:
+          - 'time'
+          - 'date'
+      - platform: rest
+        name: recipes
+        scan_interval: 3600
+        headers:
+          content-type: application/json
+          authorization: !secret recipes_token
+        resource: https://recipes.krupa.net.pl/api/meal-plan
+        value_template: >
+          {% if value_json is none %}
+            No meal plan
+          {% elif value_json[0] %}
+          {{ value_json[0].recipe.name }}
+          {% endif %}
+
+    template:
+    - sensor:
+      - name: ""ESP Display""
+        state: ""{{ states('switch.espdisplay_backlight') }}""
+        attributes:
+          # First 6 characters of each line are considered a static prefix
+          line1: ""LUNCH {{ states('sensor.recipes') | replace('','a') | replace('','c') | replace('','e') | replace('','l') | replace('','o') | replace('','s') | replace('','z') | replace('','z') | regex_replace(find='[^\x00-\x7F]+', replace='', ignorecase=False) }}""
+          line2: >
+            {%
+              set calendars = [(
+                ""00:00"",
+                ""-- NEXT DAY --"",
+                as_timestamp(state_attr('sun.sun','next_midnight')) | int
+              ),(
+                as_timestamp(state_attr('calendar.pawel_krupa_net_pl','start_time')) | int | timestamp_custom(""%H:%M""),
+                state_attr('calendar.pawel_krupa_net_pl','message') | regex_replace(find='[^\x00-\x7F]+', replace='', ignorecase=False) | trim,
+                as_timestamp(state_attr('calendar.pawel_krupa_net_pl','start_time')) | int
+              ),(
+                as_timestamp(state_attr('calendar.paulfantom','start_time')) | int | timestamp_custom(""%H:%M""),
+                state_attr('calendar.paulfantom','message') | regex_replace(find='[^\x00-\x7F]+', replace='', ignorecase=False) | trim,
+                as_timestamp(state_attr('calendar.paulfantom','start_time')) | int
+              ),(
+                as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time')) | int | timestamp_custom(""%H:%M""),
+                state_attr('calendar.adrianna_wojas_gmail_com','message') | regex_replace(find='[^\x00-\x7F]+', replace='', ignorecase=False) | trim,
+                as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time')) | int
+              )] | rejectattr(2, ""gt"", as_timestamp(utcnow()) | int + 24*60*60) | sort(attribute=2) | unique | list
+            %}
+            {{ calendars[0][0] }} {{ calendars[0][1] }}
+          line3: >
+            {%
+              set calendars = [(
+                ""00:00"",
+                ""-- NEXT DAY --"",
+                as_timestamp(state_attr('sun.sun','next_midnight')) | int
+              ),(
+                as_timestamp(state_attr('calendar.pawel_krupa_net_pl','start_time')) | int | timestamp_custom(""%H:%M""),
+                state_attr('calendar.pawel_krupa_net_pl','message') | regex_replace(find='[^\x00-\x7F]+', replace='', ignorecase=False) | trim,
+                as_timestamp(state_attr('calendar.pawel_krupa_net_pl','start_time')) | int
+              ),(
+                as_timestamp(state_attr('calendar.paulfantom','start_time')) | int | timestamp_custom(""%H:%M""),
+                state_attr('calendar.paulfantom','message') | regex_replace(find='[^\x00-\x7F]+', replace='', ignorecase=False) | trim,
+                as_timestamp(state_attr('calendar.paulfantom','start_time')) | int
+              ),(
+                as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time')) | int | timestamp_custom(""%H:%M""),
+                state_attr('calendar.adrianna_wojas_gmail_com','message') | regex_replace(find='[^\x00-\x7F]+', replace='', ignorecase=False) | trim,
+                as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time')) | int
+              )] | rejectattr(2, ""gt"", as_timestamp(utcnow()) | int + 24*60*60) | sort(attribute=2) | unique | list
+            %}
+            {% if calendars|length > 1 %}
+            {{ calendars[1][0] }} {{ calendars[1][1] }}
+            {% else %}
+
+            {% endif %}
+          line4: >
+            {%
+              set calendars = [(
+                ""00:00"",
+                ""-- NEXT DAY --"",
+                as_timestamp(state_attr('sun.sun','next_midnight')) | int
+              ),(
+                as_timestamp(state_attr('calendar.pawel_krupa_net_pl','start_time')) | int | timestamp_custom(""%H:%M""),
+                state_attr('calendar.pawel_krupa_net_pl','message') | regex_replace(find='[^\x00-\x7F]+', replace='', ignorecase=False) | trim,
+                as_timestamp(state_attr('calendar.pawel_krupa_net_pl','start_time')) | int
+              ),(
+                as_timestamp(state_attr('calendar.paulfantom','start_time')) | int | timestamp_custom(""%H:%M""),
+                state_attr('calendar.paulfantom','message') | regex_replace(find='[^\x00-\x7F]+', replace='', ignorecase=False) | trim,
+                as_timestamp(state_attr('calendar.paulfantom','start_time')) | int
+              ),(
+                as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time')) | int | timestamp_custom(""%H:%M""),
+                state_attr('calendar.adrianna_wojas_gmail_com','message') | regex_replace(find='[^\x00-\x7F]+', replace='', ignorecase=False) | trim,
+                as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time')) | int
+              )] | rejectattr(2, ""gt"", as_timestamp(utcnow()) | int + 24*60*60) | sort(attribute=2) | unique | list
+            %}
+            {% if calendars|length > 2 and calendars[2][1] != ""-- NEXT DAY --"" %}
+            {{ calendars[2][0] }} {{ calendars[2][1] }}
+            {% else %}
+
+            {% endif %}
+
+    cover:
+      - platform: template
+        covers:
+          projector_screen:
+            device_class: blind
+            friendly_name: ""Projector Screen""
+            value_template: ""{{ not (states('binary_sensor.sonoff_a48004cd69') | bool) }}""
+            open_cover:
+              service: remote.send_command
+              target:
+                entity_id: remote.sonoff_10011faac6
+              data:
+                device: RFBridge433
+                command: Up
+            close_cover:
+              service: remote.send_command
+              target:
+                entity_id: remote.sonoff_10011faac6
+              data:
+                device: RFBridge433
+                command: Down
+            stop_cover:
+              service: remote.send_command
+              target:
+                entity_id: remote.sonoff_10011faac6
+              data:
+                device: RFBridge433
+                command: Stop
+
+    input_boolean:
+      projector:
+        name: Projector State
+        icon: mdi:projector
+      projector_screen:
+        name: Projector Screen State
+        icon: mdi:projector-screen-variant-outline
+      movie_time:
+        name: Movie Time
+        icon: mdi:movie-open
+
+    input_select:
+      speakers:
+        name: Speakers Input
+        icon: mdi:speakers
+        options:
+        - opt/coax
+        - line1/2
+        - bt
+        initial: line1/2
+
+    plant:
+      jovita:
+        sensors:
+          moisture: sensor.jovita_moisture
+          temperature: sensor.jovita_temperature
+          conductivity: sensor.jovita_soil_conductivity
+          brightness: sensor.jovita_illuminance
+        min_moisture: 15
+        max_moisture: 60
+        min_conductivity: 350
+        max_conductivity: 2000
+        min_temperature: 10
+        max_temperature: 32
+        min_brightness: 500
+        max_brightness: 12000
+      svetlana:
+        sensors:
+          moisture: sensor.svetlana_plant_moisture
+          temperature: sensor.svetlana_plant_temperature
+          conductivity: sensor.svetlana_plant_conductivity
+          brightness: sensor.svetlana_plant_illuminance
+        min_moisture: 15
+        max_moisture: 60
+        min_conductivity: 350
+        max_conductivity: 2000
+        min_temperature: 10
+        max_temperature: 32
+        min_brightness: 500
+        max_brightness: 12000
+      violet:
+        sensors:
+          moisture: sensor.violet_moisture
+          temperature: sensor.violet_temperature
+          conductivity: sensor.violet_soil_conductivity
+          brightness: sensor.violet_illuminance
+        min_moisture: 15
+        max_moisture: 60
+        min_conductivity: 350
+        max_conductivity: 2000
+        min_temperature: 10
+        max_temperature: 32
+        min_brightness: 600
+        max_brightness: 20000
+      herbs:
+        sensors:
+          moisture: sensor.herbs_moisture
+          temperature: sensor.herbs_temperature
+          conductivity: sensor.herbs_soil_conductivity
+          brightness: sensor.herbs_illuminance
+        min_moisture: 15
+        max_moisture: 60
+        min_conductivity: 350
+        max_conductivity: 2000
+        min_temperature: 10
+        max_temperature: 32
+        min_brightness: 3700
+        max_brightness: 60000
+      basil:
+        sensors:
+          moisture: sensor.basil_moisture
+          temperature: sensor.basil_temperature
+          conductivity: sensor.basil_soil_conductivity
+          brightness: sensor.basil_illuminance
+        min_moisture: 15
+        max_moisture: 60
+        min_conductivity: 350
+        max_conductivity: 2000
+        min_temperature: 8
+        max_temperature: 32
+        min_brightness: 2500
+        max_brightness: 60000
+
+    #notify:
+    #  - platform: slack
+    #    name: slack
+    #    api_key: !secret slack_api_key
+    #    default_channel: '#home'
+    #    username: ""home-assistant""
+
+    switch:
+      - platform: wake_on_lan
+        name: pawel-pc
+        host: ""192.168.2.51""
+        mac: !secret pawel_pc_mac
+      - platform: wake_on_lan
+        name: adus-pc
+        host: ""192.168.2.50""
+        mac: !secret adus_pc_mac
+
+    google_assistant:
+      project_id: ankhhomeassistant
+      service_account: !include google_service_account.json
+      report_state: true
+
+    #google:
+    #  client_id: !secret google_client_id
+    #  client_secret: !secret google_client_secret
+    #  calendar_access: ""read_only""
+
+    sonoff:
+      username: !secret sonoff_username
+      password: !secret sonoff_password
+      scan_interval: 60 #(optional, lower values than 60 won't work anymore!)
+      mode: auto
+      #grace_period: 600 #(optional)
+      #api_region: 'eu' #(optional)
+      #entity_prefix: True #(optional)
+      #debug: False #(optional)
+
+    recorder:
+      db_url: !secret postgresql_uri
   customize.yaml: |
     switch.adus_pc:
       icon: 'mdi:desktop-classic'

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: 274020a26c387128d307ff00aab460e8
+        checksum.config/md5: 45faf660a54706e7ef7caa283d59874c
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,164cac17b4fbfac25ab9630020fe1165c493faef,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-01-17T14:32:36Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-01-17T14:32:36Z,"apps/snmp: decrease scrape frequency\
Fixes #186 #185",apps/snmp/jsonnet/main.jsonnet;apps/snmp/manifests/qnapProbe.yaml;apps/snmp/manifests/qnaplongProbe.yaml;apps/snmp/settings.yaml,False,False,False,False,50,50,100,"---FILE: apps/snmp/jsonnet/main.jsonnet---
@@ -41,7 +41,7 @@ local all = snmp(config) + {
       template+: {
         metadata+: {
           annotations+: {
-            'parca.dev/scrape': ""true"",
+            'parca.dev/scrape': 'true',
           },
         },
       },
@@ -64,103 +64,103 @@ local all = snmp(config) + {
     config.targets[1].interval
   ),
   prometheusRule: {
-    apiVersion: ""monitoring.coreos.com/v1"",
-    kind: ""PrometheusRule"",
+    apiVersion: 'monitoring.coreos.com/v1',
+    kind: 'PrometheusRule',
     metadata: {
       name: config.name,
       namespace: config.namespace,
       labels: $.deployment.metadata.labels,
     },
     spec: {
       groups: [{
-        name: ""qnap"",
+        name: 'qnap',
         rules: [
           {
-            alert: ""QNAPDiskFailure"",
-            expr: ""diskSmartInfo != 0"",
-            ""for"": ""15m"",
+            alert: 'QNAPDiskFailure',
+            expr: 'diskSmartInfo != 0',
+            'for': '15m',
             labels: {
-              severity: ""critical"",
+              severity: 'critical',
             },
             annotations: {
-              summary: ""QNAP hard drive is faulty"",
-              description: ""SMART data for hard drives number {{ $labels.diskIndex }} on QNAP NAS {{ $labels.instance }} reports disk failure. Disk most probably needs to be replaced as soon as possible."",
+              summary: 'QNAP hard drive is faulty',
+              description: 'SMART data for hard drives number {{ $labels.diskIndex }} on QNAP NAS {{ $labels.instance }} reports disk failure. Disk most probably needs to be replaced as soon as possible.',
               //runbook_url: """"
             },
           },
           {
-            alert: ""QNAPFirmwareAvailable"",
-            expr: ""firmwareUpgradeAvailable != 0"",
-            ""for"": ""24h"",
+            alert: 'QNAPFirmwareAvailable',
+            expr: 'firmwareUpgradeAvailable != 0',
+            'for': '24h',
             labels: {
-              severity: ""info"",
+              severity: 'info',
             },
             annotations: {
-              summary: ""QNAP NAS firmware upgrade available"",
-              description: ""QNAP NAS {{ $labels.instance }} has pending firmware upgrade."",
+              summary: 'QNAP NAS firmware upgrade available',
+              description: 'QNAP NAS {{ $labels.instance }} has pending firmware upgrade.',
               //runbook_url: """"
             },
           },
           {
-            alert: ""QNAPVolumeNotReady"",
-            expr: ""volumeStatus != 0"",
-            ""for"": ""2h"",
+            alert: 'QNAPVolumeNotReady',
+            expr: 'volumeStatus != 0',
+            'for': '2h',
             labels: {
-              severity: ""warning"",
+              severity: 'warning',
             },
             annotations: {
-              summary: ""QNAP volume is not ready"",
-              description: ""Data Volume number {{ $labels.volumeIndex }} on QNAP {{ $labels.instance }} is not ready for last 2h."",
+              summary: 'QNAP volume is not ready',
+              description: 'Data Volume number {{ $labels.volumeIndex }} on QNAP {{ $labels.instance }} is not ready for last 2h.',
               //runbook_url: """"
             },
           },
           {
-            alert: ""QNAPVolumeNotReady"",
-            expr: ""volumeStatus < 0"",
-            ""for"": ""10m"",
+            alert: 'QNAPVolumeNotReady',
+            expr: 'volumeStatus < 0',
+            'for': '10m',
             labels: {
-              severity: ""critical"",
+              severity: 'critical',
             },
             annotations: {
-              summary: ""QNAP volume is in critical state"",
-              description: ""Data Volume number {{ $labels.volumeIndex }} on QNAP {{ $labels.instance }} is in critical state and needs immediate attention."",
+              summary: 'QNAP volume is in critical state',
+              description: 'Data Volume number {{ $labels.volumeIndex }} on QNAP {{ $labels.instance }} is in critical state and needs immediate attention.',
               //runbook_url: """"
             },
           },
           {
-            alert: ""QNAPRAIDProblem"",
-            expr: ""raidStatus < 0"",
-            ""for"": ""20m"",
+            alert: 'QNAPRAIDProblem',
+            expr: 'raidStatus < 0',
+            'for': '20m',
             labels: {
-              severity: ""critical"",
+              severity: 'critical',
             },
             annotations: {
-              summary: ""QNAP RAID is in error state"",
-              description: ""RAID array number {{ $labels.raidIndex }} on QNAP {{ $labels.instance }} is in critical state and needs immediate attention."",
+              summary: 'QNAP RAID is in error state',
+              description: 'RAID array number {{ $labels.raidIndex }} on QNAP {{ $labels.instance }} is in critical state and needs immediate attention.',
               //runbook_url: """"
             },
           },
           {
-            alert: ""QNAPRAIDProblem"",
-            expr: ""raidStatus != 0"",
-            ""for"": ""12h"",
+            alert: 'QNAPRAIDProblem',
+            expr: 'raidStatus != 0',
+            'for': '12h',
             labels: {
-              severity: ""warning"",
+              severity: 'warning',
             },
             annotations: {
-              summary: ""QNAP RAID is in warning state"",
-              description: ""RAID array number {{ $labels.raidIndex }} on QNAP {{ $labels.instance }} is in warning state for last 12h."",
+              summary: 'QNAP RAID is in warning state',
+              description: 'RAID array number {{ $labels.raidIndex }} on QNAP {{ $labels.instance }} is in warning state for last 12h.',
               //runbook_url: """"
             },
           },
           {
-            alert: ""QNAPWriteCacheUnused"",
-            expr: ""max_over_time(cacheWriteHitRate[24h]) == 0 AND cacheAccelerationServiceEnabled == 1"",
+            alert: 'QNAPWriteCacheUnused',
+            expr: 'max_over_time(cacheWriteHitRate[24h]) == 0 AND cacheAccelerationServiceEnabled == 1',
             labels: {
-              severity: ""warning"",
+              severity: 'warning',
             },
             annotations: {
-              summary: ""QNAP Write Cache has 0% hit rate."",
+              summary: 'QNAP Write Cache has 0% hit rate.',
               description: ""Write cache on QNAP {{ $labels.instance }} has 0% hit rate and is most likely unusued. Consider checking if cache setup didn't switch to read-only mode."",
               //runbook_url: """"
             },

---FILE: apps/snmp/manifests/qnapProbe.yaml---
@@ -8,12 +8,12 @@ metadata:
   name: qnap
   namespace: snmp
 spec:
-  interval: 1m
+  interval: 2m
   module: qnap
   prober:
     path: /snmp
     url: snmp-exporter.snmp.svc:9116
-  scrapeTimeout: 1m
+  scrapeTimeout: 2m
   targets:
     staticConfig:
       labels:

---FILE: apps/snmp/manifests/qnaplongProbe.yaml---
@@ -8,12 +8,12 @@ metadata:
   name: qnaplong
   namespace: snmp
 spec:
-  interval: 4m
+  interval: 5m
   module: qnaplong
   prober:
     path: /snmp
     url: snmp-exporter.snmp.svc:9116
-  scrapeTimeout: 4m
+  scrapeTimeout: 5m
   targets:
     staticConfig:
       labels:

---FILE: apps/snmp/settings.yaml---
@@ -14,7 +14,7 @@ resources:
 targets:
   - module: qnap
     hosts: [192.168.2.29]
-    interval: 1m
+    interval: 2m
   - module: qnaplong
     hosts: [192.168.2.29]
-    interval: 4m
\ No newline at end of file
+    interval: 5m"
thaum-xyz,ankhmorpork,9c6d5ab129d66e20ba5354894a40c4769976f56b,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-01-17T14:23:46Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-01-17T14:24:02Z,"apps/homeassistant: remove flaky PostgreSQLCacheHitRatio alert

Fixes #157

Signed-off-by: Pawe Krupa (paulfantom) <pawel@krupa.net.pl>",apps/homeassistant/jsonnet/main.jsonnet;apps/homeassistant/manifests/timescaledb/prometheusRule.yaml,False,False,False,False,18,24,42,"---FILE: apps/homeassistant/jsonnet/main.jsonnet---
@@ -4,6 +4,15 @@ local homeassistant = import 'github.com/thaum-xyz/jsonnet-libs/apps/homeassista
 local timescaledb = import 'github.com/thaum-xyz/jsonnet-libs/apps/timescaledb/timescaledb.libsonnet';
 local sealedsecret = (import 'github.com/thaum-xyz/jsonnet-libs/utils/sealedsecret.libsonnet').sealedsecret;
 
+local removeAlert(groups, name, alert) = std.map(
+  function(g) if g.name == name then
+    g {
+      rules: std.filter(function(rule) rule.alert != alert, g.rules),
+    }
+  else g,
+  groups,
+);
+
 local configYAML = (importstr '../settings.yaml');
 
 // Join multiple configuration sources
@@ -89,6 +98,15 @@ local all = {
         clusterIP:: null,
       },
     },
+    prometheusRule+: {
+      spec+: {
+        groups: removeAlert(
+          super.groups,
+          'PostgreSQL',
+          'PostgreSQLCacheHitRatio'
+        ),
+      },
+    },
   },
   homeassistant: homeassistant(config.homeassistant) + {
     credentials: sealedsecret(

---FILE: apps/homeassistant/manifests/timescaledb/prometheusRule.yaml---
@@ -107,27 +107,3 @@ spec:
       for: 5m
       labels:
         severity: warning
-    - alert: PostgreSQLCacheHitRatio
-      annotations:
-        description: PostgreSQL low on cache hit rate on {{ $labels.cluster }} for
-          database {{ $labels.datname }} with a value of {{ $value }}
-        runbook_url: https://runbooks.thaum.xyz/runbooks/postgresql/postgresqlcachehitratio
-        summary: PostgreSQL low cache hit rate on {{ $labels.cluster }} for database
-          {{ $labels.datname }}
-      expr: |
-        avg by (datname) (
-          rate(pg_stat_database_blks_hit{datname!~""template.*"",job=""timescaledb"", namespace=""homeassistant""}[5m])
-          /
-          (
-            rate(
-              pg_stat_database_blks_hit{datname!~""template.*"",job=""timescaledb"", namespace=""homeassistant""}[5m]
-            )
-            +
-            rate(
-              pg_stat_database_blks_read{datname!~""template.*"",job=""timescaledb"", namespace=""homeassistant""}[5m]
-            )
-          )
-        ) < 0.98
-      for: 5m
-      labels:
-        severity: warning"
thaum-xyz,ankhmorpork,d3fb60d3a57dbf8cffe303c7f1c2e38b1ba98538,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-01-06T09:49:04Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-01-06T09:49:04Z,fix readme,README.md,False,False,False,False,8,3,11,"---FILE: README.md---
@@ -55,7 +55,7 @@ Cluster is [k3s](https://k3s.io/) provisioned on bare-metal Ubuntu 20.04 using a
     <td>Container-orchestration system, the backbone of this project</td>
   </tr>
   <tr>
-    <td><img width=""32"" src=""https://github.com/weaveworks/kured/raw/main/img/logo.png""></td>
+    <td><img width=""32"" src=""https://kured.dev/img/kured.png""></td>
     <td><a href=""https://github.com/weaveworks/kured"">kured</a></td>
     <td>Kubernetes Reboot Daemon</td>
   </tr>
@@ -99,6 +99,11 @@ Cluster is [k3s](https://k3s.io/) provisioned on bare-metal Ubuntu 20.04 using a
     <td><a href=""https://prometheus.io"">Prometheus</a></td>
     <td>Systems monitoring and alerting toolkit</td>
   </tr>
+  <tr>
+    <td><img width=""32"" src=""https://cncf-branding.netlify.app/img/projects/thanos/icon/color/thanos-icon-color.svg""></td>
+    <td><a href=""https://thanos.io"">Thanos</a></td>
+    <td>Metrics datalake</td>
+  </tr>
   <tr>
     <td><img width=""32"" src=""https://grafana.com/static/img/menu/grafana2.svg""></td>
     <td><a href=""https://grafana.com"">Grafana</a></td>
@@ -109,11 +114,11 @@ Cluster is [k3s](https://k3s.io/) provisioned on bare-metal Ubuntu 20.04 using a
     <td><a href=""https://parca.dev"">Parca</a></td>
     <td>Continuous profiling</td>
   </tr>
-  <tr>
+  <!-- <tr>
     <td><img width=""32"" src=""https://github.com/grafana/loki/blob/main/docs/sources/logo.png?raw=true""></td>
     <td><a href=""https://grafana.com/oss/loki"">Loki</a></td>
     <td>Log aggregation system</td>
-  </tr>
+  </tr> -->
   <tr>
     <td><img width=""32"" src=""https://raw.githubusercontent.com//bastienwirtz/homer/main/public/logo.png""></td>
     <td><a href=""https://github.com/bastienwirtz/homer"">Homer</a></td>"
thaum-xyz,ankhmorpork,a7df81a54f8ac2f3e45d38a99de92b43b9058bb8,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-01-02T14:23:43Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2023-01-02T14:23:43Z,apps/monitoring: fix object reference,apps/monitoring/jsonnet/main.jsonnet;apps/monitoring/manifests/prometheus/prometheus.yaml,False,False,False,False,6,6,12,"---FILE: apps/monitoring/jsonnet/main.jsonnet---
@@ -322,17 +322,17 @@ local kp =
           enforcedNamespaceLabel: 'namespace',
           excludedFromEnforcement: [
             {
-              resource: 'ServiceMonitor',
+              resource: 'servicemonitors',
               namespace: $.kubeStateMetrics.serviceMonitor.metadata.namespace,
               name: $.kubeStateMetrics.serviceMonitor.metadata.name,
             },
             {
-              resource: 'ServiceMonitor',
+              resource: 'servicemonitors',
               namespace: $.kubernetesControlPlane.serviceMonitorKubelet.metadata.namespace,
               name: $.kubernetesControlPlane.serviceMonitorKubelet.metadata.name,
             },
             {
-              resource: 'ServiceMonitor',
+              resource: 'servicemonitors',
               namespace: $.kubernetesControlPlane.serviceMonitorCoreDNS.metadata.namespace,
               name: $.kubernetesControlPlane.serviceMonitorCoreDNS.metadata.name,
             },

---FILE: apps/monitoring/manifests/prometheus/prometheus.yaml---
@@ -36,13 +36,13 @@ spec:
   excludedFromEnforcement:
   - name: kube-state-metrics
     namespace: monitoring
-    resource: ServiceMonitor
+    resource: servicemonitors
   - name: kubelet
     namespace: monitoring
-    resource: ServiceMonitor
+    resource: servicemonitors
   - name: coredns
     namespace: monitoring
-    resource: ServiceMonitor
+    resource: servicemonitors
   externalLabels:
     cluster: ankhmorpork
   externalUrl: https://prometheus.ankhmorpork.thaum.xyz"
thaum-xyz,ankhmorpork,fd67e634567f0bf982ed387eadf7323e96eccc24,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-12-23T14:34:32Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-12-23T14:34:32Z,apps/auth: fix regexes,apps/auth/jsonnet/main.jsonnet;apps/auth/manifests/deployment.yaml,False,False,False,False,3,3,6,"---FILE: apps/auth/jsonnet/main.jsonnet---
@@ -25,7 +25,7 @@ local all = oauth(config) + {
           },
         },
         spec+: {
-          containers: addArgs(['--skip-auth-regex=^/-/healthy', '--skip-auth-regex=^/api/health'], 'oauth2-proxy', super.containers),
+          containers: addArgs(['--skip-auth-regex=^.*/-/healthy', '--skip-auth-regex=^.*/api/health'], 'oauth2-proxy', super.containers),
           nodeSelector+: {
             'network.infra/type': 'fast',
           },

---FILE: apps/auth/manifests/deployment.yaml---
@@ -48,8 +48,8 @@ spec:
         - --pass-basic-auth=false
         - --http-address=0.0.0.0:4180
         - --metrics-address=0.0.0.0:8080
-        - --skip-auth-regex=^/-/healthy
-        - --skip-auth-regex=^/api/health
+        - --skip-auth-regex=^.*/-/healthy
+        - --skip-auth-regex=^.*/api/health
         envFrom:
         - secretRef:
             name: oauth-creds"
thaum-xyz,ankhmorpork,bda815bf67ba5b411a2294cd614b048453f02995,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-12-18T18:37:00Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-12-18T18:38:05Z,"apps/monitoring: fix body template for github receiver

Signed-off-by: Pawe Krupa (paulfantom) <pawel@krupa.net.pl>",apps/monitoring/jsonnet/lib/githubReceiver/body-template.tmpl;apps/monitoring/manifests/githubReceiver/configs.yaml;apps/monitoring/manifests/githubReceiver/deployment.yaml,False,False,False,False,9,9,18,"---FILE: apps/monitoring/jsonnet/lib/githubReceiver/body-template.tmpl---
@@ -25,13 +25,13 @@ Issue was last updated at {{timeNow}}.
 {{range $k, $v := $payload.CommonAnnotations}}
 <tr>
     <th>{{$k}}</th>
-    {{-if or (eq $k ""runbook_url"") (eq $k ""dashboard_url"") }}
+    {{- if or (eq $k ""runbook_url"") (eq $k ""dashboard_url"") }}
     <td><a href=""{{$v}}"">{{$v}}</a></td>
-    {{-else}}
+    {{- else}}
     <td>{{$v}}</td>
-    {{-end}}
+    {{- end}}
 </tr>
-{{end}}
+{{end -}}
 </table>
 
 ## Alerts

---FILE: apps/monitoring/manifests/githubReceiver/configs.yaml---
@@ -28,13 +28,13 @@ data:
     {{range $k, $v := $payload.CommonAnnotations}}
     <tr>
         <th>{{$k}}</th>
-        {{-if or (eq $k ""runbook_url"") (eq $k ""dashboard_url"") }}
+        {{- if or (eq $k ""runbook_url"") (eq $k ""dashboard_url"") }}
         <td><a href=""{{$v}}"">{{$v}}</a></td>
-        {{-else}}
+        {{- else}}
         <td>{{$v}}</td>
-        {{-end}}
+        {{- end}}
     </tr>
-    {{end}}
+    {{end -}}
     </table>
 
     ## Alerts

---FILE: apps/monitoring/manifests/githubReceiver/deployment.yaml---
@@ -16,7 +16,7 @@ spec:
   template:
     metadata:
       annotations:
-        template.checksum.md5/body: 5c66a3b1d9e277b54e141670df62d17b
+        template.checksum.md5/body: 978e0810afef6389ecd4ca8ca9b9bb12
         template.checksum.md5/title: e0e001470816a17057e5ee7afe721561
       labels:
         app.kubernetes.io/component: alertmanager-webhook-receiver"
thaum-xyz,ankhmorpork,f11f41a55fea0dbd34c63b1c66fd047bb6814f53,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-12-18T18:32:50Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-12-18T18:32:50Z,apps/monitoring: fix body template for github receiver,apps/monitoring/jsonnet/lib/githubReceiver/body-template.tmpl;apps/monitoring/manifests/githubReceiver/configs.yaml;apps/monitoring/manifests/githubReceiver/deployment.yaml,False,False,False,False,7,7,14,"---FILE: apps/monitoring/jsonnet/lib/githubReceiver/body-template.tmpl---
@@ -25,11 +25,11 @@ Issue was last updated at {{timeNow}}.
 {{range $k, $v := $payload.CommonAnnotations}}
 <tr>
     <th>{{$k}}</th>
-    {{if or (eq $k ""runbook_url"") (eq $k ""dashboard_url"") }}
+    {{-if or (eq $k ""runbook_url"") (eq $k ""dashboard_url"") }}
     <td><a href=""{{$v}}"">{{$v}}</a></td>
-    {{else}}
+    {{-else}}
     <td>{{$v}}</td>
-    {{end}}
+    {{-end}}
 </tr>
 {{end}}
 </table>

---FILE: apps/monitoring/manifests/githubReceiver/configs.yaml---
@@ -28,11 +28,11 @@ data:
     {{range $k, $v := $payload.CommonAnnotations}}
     <tr>
         <th>{{$k}}</th>
-        {{if or (eq $k ""runbook_url"") (eq $k ""dashboard_url"") }}
+        {{-if or (eq $k ""runbook_url"") (eq $k ""dashboard_url"") }}
         <td><a href=""{{$v}}"">{{$v}}</a></td>
-        {{else}}
+        {{-else}}
         <td>{{$v}}</td>
-        {{end}}
+        {{-end}}
     </tr>
     {{end}}
     </table>

---FILE: apps/monitoring/manifests/githubReceiver/deployment.yaml---
@@ -16,7 +16,7 @@ spec:
   template:
     metadata:
       annotations:
-        template.checksum.md5/body: 9fae334bacd5c29541609db23dd2be6d
+        template.checksum.md5/body: 5c66a3b1d9e277b54e141670df62d17b
         template.checksum.md5/title: e0e001470816a17057e5ee7afe721561
       labels:
         app.kubernetes.io/component: alertmanager-webhook-receiver"
thaum-xyz,ankhmorpork,4ba3fdc0376a8d29c41b469ab45d526dd961c8b2,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-12-18T17:35:08Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-12-18T18:25:23Z,"apps/monitoring: add github-receiver

Add alertmanager webhook receiver responsible for creating issues on
GitHub when warning-level alert was triggered

Signed-off-by: Pawe Krupa (paulfantom) <pawel@krupa.net.pl>",apps/monitoring/config.jsonnet;apps/monitoring/jsonnet/lib/github-receiver.libsonnet;apps/monitoring/jsonnet/lib/githubReceiver/body-template.tmpl;apps/monitoring/jsonnet/lib/githubReceiver/title-template.tmpl;apps/monitoring/jsonnet/main.jsonnet;apps/monitoring/manifests/alertmanager/secret.yaml;apps/monitoring/manifests/githubReceiver/configs.yaml;apps/monitoring/manifests/githubReceiver/credentials.yaml;apps/monitoring/manifests/githubReceiver/deployment.yaml;apps/monitoring/manifests/githubReceiver/service.yaml;apps/monitoring/manifests/githubReceiver/serviceAccount.yaml;apps/monitoring/manifests/githubReceiver/serviceMonitor.yaml;apps/monitoring/raw/alertmanager-secret.yaml,False,False,False,False,469,2,471,"---FILE: apps/monitoring/config.jsonnet---
@@ -179,6 +179,13 @@
     ],
   },
   // Following are not in kube-prometheus
+  githubReceiver: {
+    namespace: 'monitoring',
+    version: '0.1.0',  // application-version-from-github: pfnet-research/alertmanager-to-github
+    image: 'ghcr.io/pfnet-research/alertmanager-to-github:v0.1.0',  // application-image-from-github: pfnet-research/alertmanager-to-github
+    githubTokenSecretName: 'github-receiver-credentials',
+    githubTokenEncrypted: 'AgB1S5pLwshknGqtdeP3yrPyvBaZiiKdltO+1CrX7FL7Bf+xBJnxdPf1GQI4oFulBFGtmdH5L3VSOzlw0U0dqKemfdRsDeBfZkx4Ct8rnBRVMw+y3O5tAkXVeVbAkY6h5S/OJ1m3XaOC/tnNQoERbt5GN0+t4NBVlllATPNKjfKSz8RUWrkcwM0PbRszVry9Tlgk+0cVi/c8T4J87A3lTo9MvLPwBC30LoiJt2u542ecTr6aDJjJQyz0LE2l0S5kkHfnx966L9NxSTnBd8Q3f3/K20wlZjwY7kiRof6q31vkPf8bsgFog55oxfkWKfXX7OnqTWSKQ/Lo4wKO9JT1FA3tNFxfc/1mCyRymbYinFZjBSVda0U+g+T5Exkbbh8h8Y/E02DwUgfMoms6Nlsi5LltkF/BGNSylamL8KoI84gwhm76nPj3zBm0lnIn2MmWME1LF3JFxKpOHPyiPu6o1cfvyQozMeib+mvaVpyWx7CZOa4Zjta2KyURyCh+1Tm5WfjMkGsXXfu2kIoYd5LfhyPh1bjFs3UQzX+A/gb/jKvEf0FZ8gJheypM8vhI5i7L+oMDS99uNeg2nZxQ8k6jlgxNP8WcaoGkQQ+LC5X0UqPIJ6RxatyNc1e8yYNfLM43X5eIMnjiVXGmZ2PUbj2OaAS5Md/3Dtjz+mTQBkJ44P6zpw8pyxMNEG7jTwKvIh6iHaw5KRBZWN0lKVuomoyLDJVkVO7uZMD2xSpcHxVZUhMgBHNk+7FYB+yb',
+  },
   pushgateway: {
     namespace: 'monitoring',
     version: '1.4.3',  // application-version-from-github: prometheus/pushgateway

---FILE: apps/monitoring/jsonnet/lib/github-receiver.libsonnet---
@@ -0,0 +1,159 @@
+local defaults = {
+  local defaults = self,
+  name: 'github-receiver',
+  namespace: error 'must provide namespace',
+  version: error 'must provide version',
+  image: error 'must provide image',
+  resources: {
+    requests: { cpu: '2m', memory: '10Mi' },
+    limits: { cpu: '10m', memory: '50Mi' },
+  },
+  commonLabels:: {
+    'app.kubernetes.io/name': 'github-receiver',
+    'app.kubernetes.io/version': defaults.version,
+    'app.kubernetes.io/component': 'alertmanager-webhook-receiver',
+  },
+  selectorLabels:: {
+    [labelName]: defaults.commonLabels[labelName]
+    for labelName in std.objectFields(defaults.commonLabels)
+    if !std.setMember(labelName, ['app.kubernetes.io/version'])
+  },
+  replicas: 1,
+  githubTokenSecretName: '',
+  titleTemplate: (importstr 'githubReceiver/title-template.tmpl'),
+  bodyTemplate: (importstr 'githubReceiver/body-template.tmpl'),
+  autoCloseResolvedIssues: false,
+  issueLabels: ['alert/new'],
+};
+
+function(params) {
+  _config:: defaults + params,
+  _metadata:: {
+    name: $._config.name,
+    namespace: $._config.namespace,
+    labels: $._config.commonLabels,
+  },
+  // Safety check
+  assert std.isObject($._config.resources),
+
+  serviceAccount: {
+    apiVersion: 'v1',
+    kind: 'ServiceAccount',
+    automountServiceAccountToken: false,
+    metadata: $._metadata,
+  },
+
+  service: {
+    apiVersion: 'v1',
+    kind: 'Service',
+    metadata: $._metadata,
+    spec: {
+      ports: [{
+        name: 'http',
+        targetPort: $.deployment.spec.template.spec.containers[0].ports[0].name,
+        port: 8080,
+      }],
+      selector: $._config.selectorLabels,
+      clusterIP: 'None',
+    },
+  },
+
+  configs: {
+    apiVersion: 'v1',
+    kind: 'ConfigMap',
+    metadata: $._metadata {
+      name: $._config.name + '-config',
+    },
+    data: {
+      'title-template.txt': $._config.titleTemplate,
+      'body-template.txt': $._config.bodyTemplate,
+    },
+  },
+
+  deployment: {
+    local c = {
+      name: $._config.name,
+      image: $._config.image,
+      imagePullPolicy: 'IfNotPresent',
+      args: [
+              'start',
+              '--labels=' + std.join(',', $._config.issueLabels),
+              '--auto-close-resolved-issues=' + std.toString($._config.autoCloseResolvedIssues),
+            ] + [
+              if $._config.titleTemplate != '' then '--title-template-file=/etc/github-receiver/title-template.txt',
+            ] +
+            [
+              if $._config.bodyTemplate != '' then '--body-template-file=/etc/github-receiver/body-template.txt',
+            ],
+      envFrom: [{
+        secretRef: {
+          name: $._config.githubTokenSecretName,
+        },
+      }],
+      ports: [{
+        containerPort: 8080,
+        name: 'http',
+      }],
+      livenessProbe: {
+        httpGet: {
+          path: '/metrics',
+          port: 8080,
+        },
+      },
+      volumeMounts: [{
+        mountPath: '/etc/github-receiver',
+        name: 'config',
+        readOnly: true,
+      }],
+      resources: $._config.resources,
+    },
+
+    apiVersion: 'apps/v1',
+    kind: 'Deployment',
+    metadata: $._metadata,
+    spec: {
+      replicas: $._config.replicas,
+      selector: { matchLabels: $._config.selectorLabels },
+      template: {
+        metadata: {
+          annotations: {
+            'template.checksum.md5/body': std.md5($._config.bodyTemplate),
+            'template.checksum.md5/title': std.md5($._config.titleTemplate),
+          },
+          labels: $._config.commonLabels,
+        },
+        spec: {
+          containers: [c],
+          automountServiceAccountToken: false,
+          restartPolicy: 'Always',
+          serviceAccountName: $.serviceAccount.metadata.name,
+          nodeSelector: {
+            'kubernetes.io/os': 'linux',
+            'kubernetes.io/arch': 'amd64',
+          },
+          volumes: [{
+            name: 'config',
+            configMap: {
+              name: $.configs.metadata.name,
+            },
+          }],
+        },
+      },
+    },
+  },
+
+  serviceMonitor: {
+    apiVersion: 'monitoring.coreos.com/v1',
+    kind: 'ServiceMonitor',
+    metadata: $._metadata,
+    spec: {
+      endpoints: [{
+        port: 'http',
+        interval: '30s',
+      }],
+      selector: {
+        matchLabels: $._config.selectorLabels,
+      },
+    },
+  },
+}

---FILE: apps/monitoring/jsonnet/lib/githubReceiver/body-template.tmpl---
@@ -0,0 +1,64 @@
+{{- $payload := .Payload -}}
+
+# Alert {{ $payload.GroupLabels.alertname }} firing in {{ $payload.GroupLabels.namespace }} namespace
+
+This is an automated issue created by the monitoring system. Please do not edit this message.
+
+Alertmanager URL: {{$payload.ExternalURL}}
+
+Issue was last updated at {{timeNow}}.
+
+## Common Labels
+
+<table>
+{{range $k, $v := $payload.CommonLabels}}
+<tr>
+    <th>{{$k}}</th>
+    <td>{{$v}}</td>
+</tr>
+{{end}}
+</table>
+
+## Common Annotations
+
+<table>
+{{range $k, $v := $payload.CommonAnnotations}}
+<tr>
+    <th>{{$k}}</th>
+    {{if or (eq $k ""runbook_url"") (eq $k ""dashboard_url"") }}
+    <td><a href=""{{$v}}"">{{$v}}</a></td>
+    {{else}}
+    <td>{{$v}}</td>
+    {{end}}
+</tr>
+{{end}}
+</table>
+
+## Alerts
+
+<table>
+<tr>
+    {{range $payload.LabelKeysExceptCommon -}}
+    <th>{{.}}</th>
+    {{end -}}
+    {{range $payload.AnnotationKeysExceptCommon -}}
+    <th>{{.}}</th>
+    {{end -}}
+    <th>StartsAt</th>
+    <th>Links</th>
+</tr>
+{{range $alert := $payload.Alerts -}}
+    <tr>
+        {{range $key := $payload.LabelKeysExceptCommon -}}
+            <td>{{index $alert.Labels $key}}</td>
+        {{end -}}
+        {{range $key := $payload.AnnotationKeysExceptCommon -}}
+            <td>{{index $alert.Labels $key}}</td>
+        {{end -}}
+        <td>{{$alert.StartsAt}}</td>
+        <td><a href=""{{$alert.GeneratorURL}}"">GeneratorURL</a></td>
+    </tr>
+{{end -}}
+</table>
+
+<!-- alert data: {{json $payload}} -->

---FILE: apps/monitoring/jsonnet/lib/githubReceiver/title-template.tmpl---
@@ -0,0 +1 @@
+Alert: {{ .Payload.GroupLabels.alertname }} in {{ .Payload.GroupLabels.namespace }}

---FILE: apps/monitoring/jsonnet/main.jsonnet---
@@ -134,6 +134,8 @@ local pushgateway = (import 'github.com/thaum-xyz/jsonnet-libs/apps/pushgateway/
 local windows = (import 'lib/windows-exporter.libsonnet');
 local jsonExporter = (import 'lib/json-exporter.libsonnet');
 
+local githubReceiver = (import 'lib/github-receiver.libsonnet');
+
 local mixin = (import 'kube-prometheus/lib/mixin.libsonnet');
 
 local kp =
@@ -642,6 +644,14 @@ local kp =
       },
     },
 
+    githubReceiver: githubReceiver($.values.githubReceiver) + {
+      credentials: sealedsecret($.githubReceiver.deployment.metadata {
+        name: $.values.githubReceiver.githubTokenSecretName,
+      }, {
+        ATG_GITHUB_TOKEN: $.values.githubReceiver.githubTokenEncrypted,
+      }),
+    },
+
     windowsExporter: windows($.values.windowsExporter),
 
     pushgateway: pushgateway($.values.pushgateway),

---FILE: apps/monitoring/manifests/alertmanager/secret.yaml---
@@ -19,7 +19,6 @@ spec:
           opsgenie_api_url: 'https://api.eu.opsgenie.com'
           opsgenie_api_key: $(OPSGENIE_API_KEY)
         receivers:
-
         - name: 'slack'
           slack_configs:
           - channel: '#alerts'
@@ -103,6 +102,10 @@ spec:
           webhook_configs:
             - send_resolved: false
               url: $(HEALTHCHECKS_URL)
+        - name: 'github'
+          webhook_configs:
+            - send_resolved: true
+              url: ""http://github-receiver.monitoring.svc:8080/v1/webhook?owner=thaum-xyz&repo=ankhmorpork""
         - name: ""null""
         route:
           group_by: ['alertname', 'namespace', 'job']
@@ -125,6 +128,10 @@ spec:
               - ""severity = critical""
               receiver: 'opsgenie'
               continue: true
+            - matchers:
+              - ""severity = warning""
+              receiver: 'github'
+              continue: true
         inhibit_rules:
           - source_matchers:
             - ""severity = critical""

---FILE: apps/monitoring/manifests/githubReceiver/configs.yaml---
@@ -0,0 +1,77 @@
+apiVersion: v1
+data:
+  body-template.txt: |
+    {{- $payload := .Payload -}}
+
+    # Alert {{ $payload.GroupLabels.alertname }} firing in {{ $payload.GroupLabels.namespace }} namespace
+
+    This is an automated issue created by the monitoring system. Please do not edit this message.
+
+    Alertmanager URL: {{$payload.ExternalURL}}
+
+    Issue was last updated at {{timeNow}}.
+
+    ## Common Labels
+
+    <table>
+    {{range $k, $v := $payload.CommonLabels}}
+    <tr>
+        <th>{{$k}}</th>
+        <td>{{$v}}</td>
+    </tr>
+    {{end}}
+    </table>
+
+    ## Common Annotations
+
+    <table>
+    {{range $k, $v := $payload.CommonAnnotations}}
+    <tr>
+        <th>{{$k}}</th>
+        {{if or (eq $k ""runbook_url"") (eq $k ""dashboard_url"") }}
+        <td><a href=""{{$v}}"">{{$v}}</a></td>
+        {{else}}
+        <td>{{$v}}</td>
+        {{end}}
+    </tr>
+    {{end}}
+    </table>
+
+    ## Alerts
+
+    <table>
+    <tr>
+        {{range $payload.LabelKeysExceptCommon -}}
+        <th>{{.}}</th>
+        {{end -}}
+        {{range $payload.AnnotationKeysExceptCommon -}}
+        <th>{{.}}</th>
+        {{end -}}
+        <th>StartsAt</th>
+        <th>Links</th>
+    </tr>
+    {{range $alert := $payload.Alerts -}}
+        <tr>
+            {{range $key := $payload.LabelKeysExceptCommon -}}
+                <td>{{index $alert.Labels $key}}</td>
+            {{end -}}
+            {{range $key := $payload.AnnotationKeysExceptCommon -}}
+                <td>{{index $alert.Labels $key}}</td>
+            {{end -}}
+            <td>{{$alert.StartsAt}}</td>
+            <td><a href=""{{$alert.GeneratorURL}}"">GeneratorURL</a></td>
+        </tr>
+    {{end -}}
+    </table>
+
+    <!-- alert data: {{json $payload}} -->
+  title-template.txt: |
+    Alert: {{ .Payload.GroupLabels.alertname }} in {{ .Payload.GroupLabels.namespace }}
+kind: ConfigMap
+metadata:
+  labels:
+    app.kubernetes.io/component: alertmanager-webhook-receiver
+    app.kubernetes.io/name: github-receiver
+    app.kubernetes.io/version: 0.1.0
+  name: github-receiver-config
+  namespace: monitoring

---FILE: apps/monitoring/manifests/githubReceiver/credentials.yaml---
@@ -0,0 +1,24 @@
+apiVersion: bitnami.com/v1alpha1
+kind: SealedSecret
+metadata:
+  creationTimestamp: null
+  labels:
+    app.kubernetes.io/component: alertmanager-webhook-receiver
+    app.kubernetes.io/name: github-receiver
+    app.kubernetes.io/version: 0.1.0
+  name: github-receiver-credentials
+  namespace: monitoring
+spec:
+  encryptedData:
+    ATG_GITHUB_TOKEN: AgB1S5pLwshknGqtdeP3yrPyvBaZiiKdltO+1CrX7FL7Bf+xBJnxdPf1GQI4oFulBFGtmdH5L3VSOzlw0U0dqKemfdRsDeBfZkx4Ct8rnBRVMw+y3O5tAkXVeVbAkY6h5S/OJ1m3XaOC/tnNQoERbt5GN0+t4NBVlllATPNKjfKSz8RUWrkcwM0PbRszVry9Tlgk+0cVi/c8T4J87A3lTo9MvLPwBC30LoiJt2u542ecTr6aDJjJQyz0LE2l0S5kkHfnx966L9NxSTnBd8Q3f3/K20wlZjwY7kiRof6q31vkPf8bsgFog55oxfkWKfXX7OnqTWSKQ/Lo4wKO9JT1FA3tNFxfc/1mCyRymbYinFZjBSVda0U+g+T5Exkbbh8h8Y/E02DwUgfMoms6Nlsi5LltkF/BGNSylamL8KoI84gwhm76nPj3zBm0lnIn2MmWME1LF3JFxKpOHPyiPu6o1cfvyQozMeib+mvaVpyWx7CZOa4Zjta2KyURyCh+1Tm5WfjMkGsXXfu2kIoYd5LfhyPh1bjFs3UQzX+A/gb/jKvEf0FZ8gJheypM8vhI5i7L+oMDS99uNeg2nZxQ8k6jlgxNP8WcaoGkQQ+LC5X0UqPIJ6RxatyNc1e8yYNfLM43X5eIMnjiVXGmZ2PUbj2OaAS5Md/3Dtjz+mTQBkJ44P6zpw8pyxMNEG7jTwKvIh6iHaw5KRBZWN0lKVuomoyLDJVkVO7uZMD2xSpcHxVZUhMgBHNk+7FYB+yb
+  template:
+    metadata:
+      annotations:
+        sealedsecrets.bitnami.com/managed: ""true""
+      creationTimestamp: null
+      labels:
+        app.kubernetes.io/component: alertmanager-webhook-receiver
+        app.kubernetes.io/name: github-receiver
+        app.kubernetes.io/version: 0.1.0
+      name: github-receiver-credentials
+      namespace: monitoring

---FILE: apps/monitoring/manifests/githubReceiver/deployment.yaml---
@@ -0,0 +1,66 @@
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  labels:
+    app.kubernetes.io/component: alertmanager-webhook-receiver
+    app.kubernetes.io/name: github-receiver
+    app.kubernetes.io/version: 0.1.0
+  name: github-receiver
+  namespace: monitoring
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app.kubernetes.io/component: alertmanager-webhook-receiver
+      app.kubernetes.io/name: github-receiver
+  template:
+    metadata:
+      annotations:
+        template.checksum.md5/body: 9fae334bacd5c29541609db23dd2be6d
+        template.checksum.md5/title: e0e001470816a17057e5ee7afe721561
+      labels:
+        app.kubernetes.io/component: alertmanager-webhook-receiver
+        app.kubernetes.io/name: github-receiver
+        app.kubernetes.io/version: 0.1.0
+    spec:
+      automountServiceAccountToken: false
+      containers:
+      - args:
+        - start
+        - --labels=alert/new
+        - --auto-close-resolved-issues=false
+        - --title-template-file=/etc/github-receiver/title-template.txt
+        - --body-template-file=/etc/github-receiver/body-template.txt
+        envFrom:
+        - secretRef:
+            name: github-receiver-credentials
+        image: ghcr.io/pfnet-research/alertmanager-to-github:v0.1.0
+        imagePullPolicy: IfNotPresent
+        livenessProbe:
+          httpGet:
+            path: /metrics
+            port: 8080
+        name: github-receiver
+        ports:
+        - containerPort: 8080
+          name: http
+        resources:
+          limits:
+            cpu: 10m
+            memory: 50Mi
+          requests:
+            cpu: 2m
+            memory: 10Mi
+        volumeMounts:
+        - mountPath: /etc/github-receiver
+          name: config
+          readOnly: true
+      nodeSelector:
+        kubernetes.io/arch: amd64
+        kubernetes.io/os: linux
+      restartPolicy: Always
+      serviceAccountName: github-receiver
+      volumes:
+      - configMap:
+          name: github-receiver-config
+        name: config

---FILE: apps/monitoring/manifests/githubReceiver/service.yaml---
@@ -0,0 +1,18 @@
+apiVersion: v1
+kind: Service
+metadata:
+  labels:
+    app.kubernetes.io/component: alertmanager-webhook-receiver
+    app.kubernetes.io/name: github-receiver
+    app.kubernetes.io/version: 0.1.0
+  name: github-receiver
+  namespace: monitoring
+spec:
+  clusterIP: None
+  ports:
+  - name: http
+    port: 8080
+    targetPort: http
+  selector:
+    app.kubernetes.io/component: alertmanager-webhook-receiver
+    app.kubernetes.io/name: github-receiver

---FILE: apps/monitoring/manifests/githubReceiver/serviceAccount.yaml---
@@ -0,0 +1,10 @@
+apiVersion: v1
+automountServiceAccountToken: false
+kind: ServiceAccount
+metadata:
+  labels:
+    app.kubernetes.io/component: alertmanager-webhook-receiver
+    app.kubernetes.io/name: github-receiver
+    app.kubernetes.io/version: 0.1.0
+  name: github-receiver
+  namespace: monitoring

---FILE: apps/monitoring/manifests/githubReceiver/serviceMonitor.yaml---
@@ -0,0 +1,17 @@
+apiVersion: monitoring.coreos.com/v1
+kind: ServiceMonitor
+metadata:
+  labels:
+    app.kubernetes.io/component: alertmanager-webhook-receiver
+    app.kubernetes.io/name: github-receiver
+    app.kubernetes.io/version: 0.1.0
+  name: github-receiver
+  namespace: monitoring
+spec:
+  endpoints:
+  - interval: 30s
+    port: http
+  selector:
+    matchLabels:
+      app.kubernetes.io/component: alertmanager-webhook-receiver
+      app.kubernetes.io/name: github-receiver

---FILE: apps/monitoring/raw/alertmanager-secret.yaml---
@@ -19,7 +19,6 @@ spec:
           opsgenie_api_url: 'https://api.eu.opsgenie.com'
           opsgenie_api_key: $(OPSGENIE_API_KEY)
         receivers:
-
         - name: 'slack'
           slack_configs:
           - channel: '#alerts'
@@ -103,6 +102,10 @@ spec:
           webhook_configs:
             - send_resolved: false
               url: $(HEALTHCHECKS_URL)
+        - name: 'github'
+          webhook_configs:
+            - send_resolved: true
+              url: ""http://github-receiver.monitoring.svc:8080/v1/webhook?owner=thaum-xyz&repo=ankhmorpork""
         - name: ""null""
         route:
           group_by: ['alertname', 'namespace', 'job']
@@ -125,6 +128,10 @@ spec:
               - ""severity = critical""
               receiver: 'opsgenie'
               continue: true
+            - matchers:
+              - ""severity = warning""
+              receiver: 'github'
+              continue: true
         inhibit_rules:
           - source_matchers:
             - ""severity = critical"""
thaum-xyz,ankhmorpork,9a8b73d8a698606efe56105c7df32fffa744c48b,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-12-09T12:21:38Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-12-09T12:21:38Z,apps/datalake-metrics: fix SLIs,apps/datalake-metrics/jsonnet/main.jsonnet;apps/datalake-metrics/manifests/monitoring/thanosReceiveRequestsErrors.yaml;apps/datalake-metrics/manifests/monitoring/thanosReceiveRequestsLatency.yaml,False,False,False,False,5,4,9,"---FILE: apps/datalake-metrics/jsonnet/main.jsonnet---
@@ -176,7 +176,7 @@ local monitoring = {
             metric: 'http_requests_total{code=~""5.."", job=~"".*thanos-receive.*"", handler=""receive""}',
           },
           total: {
-            metric: 'http_requests_total{code=~""5.."", job=~"".*thanos-receive.*"", handler=""receive""}',
+            metric: 'http_requests_total{job=~"".*thanos-receive.*"", handler=""receive""}',
           },
         },
       },
@@ -195,7 +195,7 @@ local monitoring = {
       indicator: {
         latency: {
           success: {
-            metric: 'http_request_duration_seconds_bucket{job=~"".*thanos-receive.*"", handler=""receive""}',
+            metric: 'http_request_duration_seconds_bucket{job=~"".*thanos-receive.*"", handler=""receive"", le=""5.0""}',
           },
           total: {
             metric: 'http_request_duration_seconds_count{job=~"".*thanos-receive.*"", handler=""receive""}',

---FILE: apps/datalake-metrics/manifests/monitoring/thanosReceiveRequestsErrors.yaml---
@@ -13,6 +13,6 @@ spec:
       errors:
         metric: http_requests_total{code=~""5.."", job=~"".*thanos-receive.*"", handler=""receive""}
       total:
-        metric: http_requests_total{code=~""5.."", job=~"".*thanos-receive.*"", handler=""receive""}
+        metric: http_requests_total{job=~"".*thanos-receive.*"", handler=""receive""}
   target: ""99""
   window: 2w

---FILE: apps/datalake-metrics/manifests/monitoring/thanosReceiveRequestsLatency.yaml---
@@ -11,7 +11,8 @@ spec:
   indicator:
     latency:
       success:
-        metric: http_request_duration_seconds_bucket{job=~"".*thanos-receive.*"", handler=""receive""}
+        metric: http_request_duration_seconds_bucket{job=~"".*thanos-receive.*"", handler=""receive"",
+          le=""5.0""}
       total:
         metric: http_request_duration_seconds_count{job=~"".*thanos-receive.*"", handler=""receive""}
   target: ""99"""
thaum-xyz,ankhmorpork,92bd356cf0cc927357b9e92ec363f12a945c81fb,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-12-08T12:41:58Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-12-08T12:41:58Z,apps/datalake-metrics: fix router servicemonitor name,apps/datalake-metrics/jsonnet/main.jsonnet;apps/datalake-metrics/manifests/receiveRouter/serviceMonitor.yaml,False,False,False,False,2,4,6,"---FILE: apps/datalake-metrics/jsonnet/main.jsonnet---
@@ -43,9 +43,7 @@ local all = {
   },
   receiveRouter: r {
     serviceMonitor: $.receiveIngestor.serviceMonitor {
-      metadata+: {
-        labels+: r.service.metadata.labels,
-      },
+      metadata: r.service.metadata,
       spec+: {
         selector+: {
           matchLabels: {

---FILE: apps/datalake-metrics/manifests/receiveRouter/serviceMonitor.yaml---
@@ -6,7 +6,7 @@ metadata:
     app.kubernetes.io/instance: thanos-receive
     app.kubernetes.io/name: thanos-receive
     app.kubernetes.io/version: v0.29.0
-  name: thanos-receive-ingestor
+  name: thanos-receive-router
   namespace: datalake-metrics
 spec:
   endpoints:"
thaum-xyz,ankhmorpork,f6074a82d4bdf9c51ed152d49ef4ccf34703f899,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-11-24T20:29:08Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-11-24T20:29:08Z,apps/monitoring: reduce scrape interval due to network issues,apps/monitoring/jsonnet/main.jsonnet;apps/monitoring/manifests/nodeExporter/serviceMonitor.yaml,False,False,False,False,4,4,8,"---FILE: apps/monitoring/jsonnet/main.jsonnet---
@@ -231,8 +231,8 @@ local kp =
           endpoints: std.map(
             function(e) if e.port == 'https' then
               e {
-                interval: '30s',
-                scrapeTimeout: '30s',
+                interval: '90s',
+                scrapeTimeout: '90s',
               }
             else e,
             super.endpoints

---FILE: apps/monitoring/manifests/nodeExporter/serviceMonitor.yaml---
@@ -11,7 +11,7 @@ metadata:
 spec:
   endpoints:
   - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
-    interval: 30s
+    interval: 90s
     port: https
     relabelings:
     - action: replace
@@ -21,7 +21,7 @@ spec:
       - __meta_kubernetes_pod_node_name
       targetLabel: instance
     scheme: https
-    scrapeTimeout: 30s
+    scrapeTimeout: 90s
     tlsConfig:
       insecureSkipVerify: true
   jobLabel: app.kubernetes.io/name"
thaum-xyz,ankhmorpork,93c9fe5c2ab468ccab30e2c47c08b982800dc35e,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-11-19T14:52:02Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-11-19T14:52:02Z,apps/datalake-metrics: fix ingress schema,apps/datalake-metrics/jsonnet/main.jsonnet;apps/datalake-metrics/manifests/custom/ingress.yaml,False,False,False,False,12,4,16,"---FILE: apps/datalake-metrics/jsonnet/main.jsonnet---
@@ -94,9 +94,14 @@ local all = {
           http: {
             paths: [{
               path: '/',
+              pathType: 'Prefix',
               backend: {
-                serviceName: 'thanos-receive-router',
-                servicePort: 19291,
+                service: {
+                  name: 'thanos-receive-router',
+                  port: {
+                    name: 'remote-write',
+                  },
+                },
               },
             }],
           },

---FILE: apps/datalake-metrics/manifests/custom/ingress.yaml---
@@ -15,9 +15,12 @@ spec:
     http:
       paths:
       - backend:
-          serviceName: thanos-receive-router
-          servicePort: 19291
+          service:
+            name: thanos-receive-router
+            port:
+              name: remote-write
         path: /
+        pathType: Prefix
   tls:
   - hosts:
     - metrics.datalake.ankhmorpork.thaum.xyz"
thaum-xyz,ankhmorpork,8937376ea5ca37ec95da52a607be10e13c1744c7,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-11-15T19:53:11Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-11-15T19:53:11Z,"base/flux-apps: fix ""not a directory"" error",base/flux-apps/node-feature-discovery.yaml,False,False,False,False,1,1,2,"---FILE: base/flux-apps/node-feature-discovery.yaml---
@@ -5,7 +5,7 @@ metadata:
   namespace: flux-apps
 spec:
   interval: 15m0s
-  path: ./base/node-feature-discovery/kustomization.yaml
+  path: ./base/node-feature-discovery
   prune: true
   sourceRef:
     kind: GitRepository"
thaum-xyz,ankhmorpork,303164c924eb12c81d2e569c7ad5e68edeff00a4,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-10-27T14:40:03Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-10-27T14:40:03Z,apps/homeassistant: fix ip assignment for WOL plugin,apps/homeassistant/config/configuration.yaml;apps/homeassistant/jsonnet/jsonnetfile.lock.json;apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,9,9,18,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -331,11 +331,11 @@ plant:
 switch:
   - platform: wake_on_lan
     name: pawel-pc
-    host: ""192.168.2.50""
+    host: ""192.168.2.51""
     mac: !secret pawel_pc_mac
   - platform: wake_on_lan
     name: adus-pc
-    host: ""192.168.2.51""
+    host: ""192.168.2.50""
     mac: !secret adus_pc_mac
 
 google_assistant:

---FILE: apps/homeassistant/jsonnet/jsonnetfile.lock.json---
@@ -18,7 +18,7 @@
           ""subdir"": ""grafana-builder""
         }
       },
-      ""version"": ""d73aff453c9784cd6922119f3ce33d8d355a79e1"",
+      ""version"": ""a724a80fb0429e4f1ccb27c02743b4bfd8bbfdaf"",
       ""sum"": ""tDR6yT2GVfw0wTU12iZH+m01HrbIr6g/xN+/8nzNkU0=""
     },
     {
@@ -28,8 +28,8 @@
           ""subdir"": """"
         }
       },
-      ""version"": ""7b559e800a32a2a80caf4c968f37c4999ec44689"",
-      ""sum"": ""OqX/DHB6fuywNgqHAZTGRnfkYTQqoYmGePsrZ6nQELw=""
+      ""version"": ""05a58f765eda05902d4f7dd22098a2b870f7ca1e"",
+      ""sum"": ""ohFopg3a6U8N73iy97/iRIuO3UN5WJaCGoxh5TqYUWw=""
     },
     {
       ""source"": {
@@ -38,7 +38,7 @@
           ""subdir"": ""postgres_mixin""
         }
       },
-      ""version"": ""0adab051b3db7b11ffc26d5b88eddfc0f603d67a"",
+      ""version"": ""20a0133fcadf6cfb5e7fabaea48ef6c483636919"",
       ""sum"": ""H+okh0mBSyJSyvkCadCXck1ouZUhdokidsoDGA9h25c=""
     },
     {

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -130,9 +130,9 @@ data:
     8\n    max_temperature: 32\n    min_brightness: 2500\n    max_brightness: 60000\n\n#notify:\n#
     \ - platform: slack\n#    name: slack\n#    api_key: !secret slack_api_key\n#
     \   default_channel: '#home'\n#    username: \""home-assistant\""\n\nswitch:\n  -
-    platform: wake_on_lan\n    name: pawel-pc\n    host: \""192.168.2.50\""\n    mac:
+    platform: wake_on_lan\n    name: pawel-pc\n    host: \""192.168.2.51\""\n    mac:
     !secret pawel_pc_mac\n  - platform: wake_on_lan\n    name: adus-pc\n    host:
-    \""192.168.2.51\""\n    mac: !secret adus_pc_mac\n\ngoogle_assistant:\n  project_id:
+    \""192.168.2.50\""\n    mac: !secret adus_pc_mac\n\ngoogle_assistant:\n  project_id:
     ankhhomeassistant\n  service_account: !include google_service_account.json\n  report_state:
     true\n\n#google:\n#  client_id: !secret google_client_id\n#  client_secret: !secret
     google_client_secret\n#  calendar_access: \""read_only\""\n\nsonoff:\n  username:

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: 85f2ee4d4978f509796c89b1fe32ae04
+        checksum.config/md5: 2d2ab149e7ba281341c5409bfb698803
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,c2c67a6106b8d75d847390d4a3360d7a8871a130,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-10-25T09:39:58Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-10-25T09:39:58Z,apps/homeassistant: fix config,apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,3,3,6,"---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -130,9 +130,9 @@ data:
     8\n    max_temperature: 32\n    min_brightness: 2500\n    max_brightness: 60000\n\n#notify:\n#
     \ - platform: slack\n#    name: slack\n#    api_key: !secret slack_api_key\n#
     \   default_channel: '#home'\n#    username: \""home-assistant\""\n\nswitch:\n  -
-    platform: wake_on_lan\n    name: pawel-pc\n    host: \""192.168.2.51\""\n    mac:
+    platform: wake_on_lan\n    name: pawel-pc\n    host: \""192.168.2.50\""\n    mac:
     !secret pawel_pc_mac\n  - platform: wake_on_lan\n    name: adus-pc\n    host:
-    \""192.168.2.50\""\n    mac: !secret adus_pc_mac\n\ngoogle_assistant:\n  project_id:
+    \""192.168.2.51\""\n    mac: !secret adus_pc_mac\n\ngoogle_assistant:\n  project_id:
     ankhhomeassistant\n  service_account: !include google_service_account.json\n  report_state:
     true\n\n#google:\n#  client_id: !secret google_client_id\n#  client_secret: !secret
     google_client_secret\n#  calendar_access: \""read_only\""\n\nsonoff:\n  username:

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: 2d2ab149e7ba281341c5409bfb698803
+        checksum.config/md5: 85f2ee4d4978f509796c89b1fe32ae04
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,755f288ca519023de5d5d2bc59409a91d3e139ff,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-10-25T09:38:13Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-10-25T09:38:13Z,apps/homeassistant: fix WOL IP addresses,apps/homeassistant/config/configuration.yaml,False,False,False,False,2,2,4,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -331,11 +331,11 @@ plant:
 switch:
   - platform: wake_on_lan
     name: pawel-pc
-    host: ""192.168.2.51""
+    host: ""192.168.2.50""
     mac: !secret pawel_pc_mac
   - platform: wake_on_lan
     name: adus-pc
-    host: ""192.168.2.50""
+    host: ""192.168.2.51""
     mac: !secret adus_pc_mac
 
 google_assistant:"
thaum-xyz,ankhmorpork,ef85b192aa6875b66eda3b4f37d6eec7d9222096,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-10-05T12:35:25Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-10-05T12:35:25Z,metal: use newest ssh-hardening and fix sftp warnings,metal/01_system.yml;metal/ansible.cfg;metal/roles/requirements.yml,False,False,False,False,10,2,12,"---FILE: metal/01_system.yml---
@@ -2,10 +2,12 @@
 - hosts: all
   become: true
   any_errors_fatal: true
+  #collections:
+  #- devsec.hardening
   roles:
   - { role: oefenweb.locales, when: (ansible_os_family == ""Debian"") }
   - { role: jnv.unattended-upgrades, when: (ansible_os_family == ""Debian"") }
-  - dev-sec.ssh-hardening
+  - devsec.hardening.ssh_hardening
   - cloudalchemy.systemd_exporter
 
 - hosts: all

---FILE: metal/ansible.cfg---
@@ -11,3 +11,5 @@ gathering = smart
 ssh_args = -o ControlMaster=auto -o ControlPersist=3600s -o PreferredAuthentications=publickey
 control_path = %(directory)s/ansible-ssh-%%h-%%p-%%r
 pipelining = True
+scp_if_ssh = True
+scp_extra_args = ""-O""

---FILE: metal/roles/requirements.yml---
@@ -1,10 +1,14 @@
 ---
+roles:
 - name: cloudalchemy.systemd_exporter
 - name: oefenweb.locales
   version: v1.0.49
 - name: jnv.unattended-upgrades
   version: v1.12.2
-- name: dev-sec.ssh-hardening
 - name: paulfantom.raspberry
 - name: paulfantom.system
 - name: xanmanning.k3s
+
+collections:
+- name: devsec.hardening
+  version: 8.2.0"
thaum-xyz,ankhmorpork,3a370cd02f5e42b5ae4a0e5975ca0e837039b929,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-09-19T14:37:47Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-09-19T14:38:36Z,apps/pics-mgmt: fix max_age,apps/pics-mgmt/manifests/script.yaml;apps/pics-mgmt/script.sh,False,False,False,False,6,4,10,"---FILE: apps/pics-mgmt/manifests/script.yaml---
@@ -11,7 +11,8 @@ data:
     OUTPUT_DIR=""$2""
 
     PROM_PREFIX=""pictures""
-    PROM_MAX_AGE=""7200""  # 2h
+    # MAX_AGE needs to account for job scheduling frequency and job runtime
+    PROM_MAX_AGE=""2851200""  # 2h
 
     # PROM_PGW=""""
 
@@ -88,4 +89,4 @@ data:
       ""-filename<createdate"" \
       ""-filename<datetimeoriginal"" \
       ""-overwrite_original"" \
-      ""${INPUT_DIR}"" | tee /tmp/output.txt
\ No newline at end of file
+      ""${INPUT_DIR}"" | tee /tmp/output.txt

---FILE: apps/pics-mgmt/script.sh---
@@ -4,7 +4,8 @@ INPUT_DIR=""$1""
 OUTPUT_DIR=""$2""
 
 PROM_PREFIX=""pictures""
-PROM_MAX_AGE=""7200""  # 2h
+# MAX_AGE needs to account for job scheduling frequency and job runtime
+PROM_MAX_AGE=""2851200""  # 33d
 
 # PROM_PGW=""""
 
@@ -81,4 +82,4 @@ exiftool \
     ""-filename<createdate"" \
     ""-filename<datetimeoriginal"" \
     ""-overwrite_original"" \
-    ""${INPUT_DIR}"" | tee /tmp/output.txt
\ No newline at end of file
+    ""${INPUT_DIR}"" | tee /tmp/output.txt"
thaum-xyz,ankhmorpork,31f2f11c406bca68b54b2931c6cae814914f086c,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-08-16T19:57:27Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-08-16T19:57:27Z,apps/parca: fix agent image,apps/parca/manifests/agent/daemonSet.yaml;apps/parca/settings.yaml,False,False,False,False,2,2,4,"---FILE: apps/parca/manifests/agent/daemonSet.yaml---
@@ -37,7 +37,7 @@ spec:
           valueFrom:
             fieldRef:
               fieldPath: spec.nodeName
-        image: ghcr.io/parca-dev/parca-agent:sha256-c098d5ba1880ff9ed035b9ad0a70f291adb2d40e9006976f5c56448a36182385.sig
+        image: ghcr.io/parca-dev/parca-agent:main-c09f3b16
         name: parca-agent
         ports:
         - containerPort: 7071

---FILE: apps/parca/settings.yaml---
@@ -3,7 +3,7 @@ domain: ""parca.ankhmorpork.thaum.xyz""
 namespace: &namespace ""parca""
 agent:
   version: ""0.9.2-dev""  # application-version-from-github: parca-dev/parca-agent
-  image: ""ghcr.io/parca-dev/parca-agent:sha256-c098d5ba1880ff9ed035b9ad0a70f291adb2d40e9006976f5c56448a36182385.sig""  # application-image-from-github: parca-dev/parca-agent
+  image: ""ghcr.io/parca-dev/parca-agent:main-c09f3b16""  # application-image-from-github: parca-dev/parca-agent
   namespace: *namespace
   stores: ['parca.parca.svc:7070']
   podMonitor: true"
thaum-xyz,ankhmorpork,eb4e3227f5fb56af393555417e34f4744ccc9935,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-08-16T19:35:06Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-08-16T19:35:06Z,metal: fix group names,metal/70_k3s.yml;metal/group_vars/k3s.yml;metal/inventory,False,False,False,False,8,8,16,"---FILE: metal/70_k3s.yml---
@@ -12,7 +12,7 @@
         path: /usr/sbin/iptables-legacy
       when: ansible_os_family == 'Debian'
 
-- hosts: k3s-master
+- hosts: k3s_control_plane
   become: true
   any_errors_fatal: true
   roles:
@@ -38,7 +38,7 @@
         dest: ""/var/lib/rancher/k3s/server/manifests/{{ item | basename }}""
       with_fileglob: ""templates/manifests/*.yaml""
 
-- hosts: k3s-node
+- hosts: k3s_nodes
   become: true
   serial: 2
   roles:

---FILE: metal/group_vars/k3s.yml---
@@ -1,6 +1,6 @@
 ---
 k3s_version: v1.24.3+k3s1
-k3s_master_ip: ""{{ hostvars[groups['k3s-master'][0]]['ansible_default_ipv4']['address'] }}""
+k3s_master_ip: ""{{ hostvars[groups['k3s_control_plane'][0]]['ansible_default_ipv4']['address'] }}""
 
 k3s_server_config:
   disable:
@@ -19,7 +19,7 @@ k3s_server_config:
   kube-proxy-arg:
   - ""metrics-bind-address=0.0.0.0""
 
-k3s_token: ""{{ hostvars[groups['k3s-master'][0]]['token'] }}""
+k3s_token: ""{{ hostvars[groups['k3s_control_plane'][0]]['token'] }}""
 
 k3s_agent_config:
   kubelet-arg:

---FILE: metal/inventory---
@@ -17,16 +17,16 @@ node0[1:2]
 [nvidia]
 metal01
 
-[k3s-master]
+[k3s_control_plane]
 master01
 
-[k3s-node]
+[k3s_nodes]
 node0[1:2]
 metal01
 
 [k3s:children]
-k3s-master
-k3s-node
+k3s_control_plane
+k3s_nodes
 
 [all:vars]
 ansible_python_interpreter=/usr/bin/python3"
thaum-xyz,ankhmorpork,467275e83affab89dc7ba454386e36684ebcf405,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-08-16T19:03:46Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-08-16T19:03:46Z,metal: fix issues after bumping k3s version,metal/01_system.yml;metal/10_storage.yml;metal/ansible.cfg;metal/group_vars/k3s.yml,False,False,False,False,11,14,25,"---FILE: metal/01_system.yml---
@@ -18,20 +18,18 @@
     package:
       name: moreutils
       state: present
-  - set_fact:
-      pkg_mgr: ""{{ 'yum' if ansible_pkg_mgr == 'dnf' else ansible_pkg_mgr }}""
-  - name: Download package manager textfile collector script
+  - name: Download apt_info textfile collector script
     get_url:
-      url: ""https://raw.githubusercontent.com/prometheus-community/node-exporter-textfile-collector-scripts/master/{{ pkg_mgr }}.sh""
-      dest: ""/usr/local/bin/{{ pkg_mgr }}.sh""
+      url: ""https://raw.githubusercontent.com/prometheus-community/node-exporter-textfile-collector-scripts/master/apt_info.py""
+      dest: ""/usr/local/bin/apt_info.py""
       mode: 0755
   - name: Set cronjob for package manager (/etc/crontab)
     cron:
-      cron_file: ""/etc/crontab""
+      cron_file: ""/etc/cron.d/metrics""
       user: root
-      name: ""{{ ansible_pkg_mgr }}-metrics""
+      name: ""apt""
       minute: ""13""
-      job: ""/usr/local/bin/{{ pkg_mgr }}.sh | sponge /var/lib/node_exporter/{{ pkg_mgr }}.prom""
+      job: ""/usr/local/bin/apt_info.py | sponge /var/lib/node_exporter/apt.prom""
   - name: Ensure snapd is removed
     apt:
       name: snapd

---FILE: metal/10_storage.yml---
@@ -18,11 +18,11 @@
         url: ""https://github.com/prometheus-community/node-exporter-textfile-collector-scripts/blob/master/smartmon.sh""
         dest: ""/usr/local/bin/smartmon.sh""
         mode: 0755
-    - name: Set global cronjobs (/etc/crontab)
+    - name: Set SMART metrics collection cronjob
       cron:
-        cron_file: ""/etc/crontab""
+        cron_file: ""/etc/cron.d/metrics""
         user: root
-        name: ""smartmon-metrics""
+        name: ""smartmon""
         minute: ""*/10""
         job: ""/usr/local/bin/smartmon.sh | sponge /var/lib/node_exporter/smartmon.prom""
     when: enable_smartmon is defined

---FILE: metal/ansible.cfg---
@@ -8,7 +8,6 @@ gathering = smart
 # strategy = mitogen_linear
 
 [ssh_connection]
-transfer_method = scp
 ssh_args = -o ControlMaster=auto -o ControlPersist=3600s -o PreferredAuthentications=publickey
 control_path = %(directory)s/ansible-ssh-%%h-%%p-%%r
 pipelining = True

---FILE: metal/group_vars/k3s.yml---
@@ -12,9 +12,9 @@ k3s_server_config:
   - ""system-reserved=cpu=100m,memory=200Mi""
   - ""kube-reserved=cpu=100m,memory=300Mi""
   kube-controller-manager-arg:
-  - ""address={{ k3s_master_ip }}""
+  - ""bind-address={{ k3s_master_ip }}""
   kube-scheduler-arg:
-  - ""address={{ k3s_master_ip }}""
+  - ""bind-address={{ k3s_master_ip }}""
   etcd-expose-metrics: ""true""
   kube-proxy-arg:
   - ""metrics-bind-address=0.0.0.0"""
thaum-xyz,ankhmorpork,d85a2c301a176532efd8c5b309c78dec3073115c,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-08-04T17:35:14Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-08-04T17:35:14Z,apps/nut: fix incorrect rule,apps/nut/jsonnet/main.jsonnet;apps/nut/manifests/prometheusRule.yaml,False,False,False,False,3,3,6,"---FILE: apps/nut/jsonnet/main.jsonnet---
@@ -104,7 +104,7 @@ local all = exporter(config) + {
           {
             alert: 'UPSBatteryCritical',
             annotations: {
-              description: 'UPS {{ $labels.instance }} has less than {{ $value | humanizePercent}} battery remaining.',
+              description: 'UPS {{ $labels.instance }} has less than {{ $value | humanizePercentage }} of battery remaining.',
               summary: ""UPS exited 'online' mode"",
             },
             expr: 'network_ups_tools_battery_charge < 90',

---FILE: apps/nut/manifests/prometheusRule.yaml---
@@ -23,8 +23,8 @@ spec:
         severity: warning
     - alert: UPSBatteryCritical
       annotations:
-        description: UPS {{ $labels.instance }} has less than {{ $value | humanizePercent}}
-          battery remaining.
+        description: UPS {{ $labels.instance }} has less than {{ $value | humanizePercentage
+          }} of battery remaining.
         summary: UPS exited 'online' mode
       expr: network_ups_tools_battery_charge < 90
       labels:"
thaum-xyz,ankhmorpork,c3509998e95624ed5449fc5d2a766d5fa876a54f,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-08-02T20:50:56Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-08-02T20:50:56Z,apps/pics-mgmt: fix incorrect schedule,apps/pics-mgmt/manifests/cronjob.yaml,False,False,False,False,2,2,4,"---FILE: apps/pics-mgmt/manifests/cronjob.yaml---
@@ -4,7 +4,7 @@ metadata:
   name: manager
   namespace: pics-mgmt
 spec:
-  schedule: ""23 59 7 * *""
+  schedule: ""59 23 7 * *""
   concurrencyPolicy: Forbid
   successfulJobsHistoryLimit: 2
   failedJobsHistoryLimit: 3
@@ -38,4 +38,4 @@ spec:
                 defaultMode: 0755
             - name: multimedia
               persistentVolumeClaim:
-                claimName: multimedia
\ No newline at end of file
+                claimName: multimedia"
thaum-xyz,ankhmorpork,86a197407de2407bbfe14b2c865d654cb7c92256,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-08-02T19:12:59Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-08-02T19:12:59Z,apps/parca: remove incorrect cli flag,apps/parca/manifests/parca/deployment.yaml,False,False,False,False,0,1,1,"---FILE: apps/parca/manifests/parca/deployment.yaml---
@@ -34,7 +34,6 @@ spec:
         - --debug-infod-upstream-servers=https://debuginfod.systemtap.org
         - --debug-infod-http-request-timeout=5m
         - '--storage-active-memory=20000000000'
-        - --storage=columnstore
         image: ghcr.io/parca-dev/parca:v0.12.1
         livenessProbe:
           exec:"
thaum-xyz,ankhmorpork,7d5a3611dc526c96c49cd13ce767598ca1f70149,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-08-02T19:10:24Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-08-02T19:10:24Z,apps/parca: fix resource requirements,apps/parca/manifests/parca/deployment.yaml,False,False,False,False,3,0,3,"---FILE: apps/parca/manifests/parca/deployment.yaml---
@@ -55,6 +55,9 @@ spec:
             - -addr=:7070
           initialDelaySeconds: 10
         resources:
+          requests:
+            cpu: 1000m
+            memory: 2Gi
           limits:
             cpu: 2000m
             memory: 10Gi"
thaum-xyz,ankhmorpork,b63763f33d0487c3a4773ff0cfbdc00391ff2a94,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-08-02T18:20:23Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-08-02T18:20:23Z,apps/photoprism: fix issues with incorrectly defined PVCs,apps/photoprism/jsonnet/photoprism.libsonnet;apps/photoprism/manifests/photoprism/additionalPVCs.yaml;apps/photoprism/settings.yaml,False,False,False,False,7,8,15,"---FILE: apps/photoprism/jsonnet/photoprism.libsonnet---
@@ -188,7 +188,6 @@ function(params) {
   [if std.objectHas(params, 'additionalPVCs') then 'additionalPVCs']: {
     apiVersion: 'v1',
     kind: 'PersistentVolumeClaimList',
-    metadata: $._metadata,
     items: [
       {
         apiVersion: 'v1',

---FILE: apps/photoprism/manifests/photoprism/additionalPVCs.yaml---
@@ -11,11 +11,8 @@ items:
   spec:
     accessModes:
     - ReadWriteOnce
+    resources:
+      requests:
+        storage: 4000Gi
     storageClassName: manual
 kind: PersistentVolumeClaimList
-metadata:
-  labels:
-    app.kubernetes.io/name: photoprism
-    app.kubernetes.io/version: ""220302""
-  name: photoprism
-  namespace: photoprism

---FILE: apps/photoprism/settings.yaml---
@@ -42,4 +42,7 @@ photoprism:
       spec:
         storageClassName: ""manual""
         accessModes:
-          - ReadWriteOnce
\ No newline at end of file
+          - ReadWriteOnce
+        resources:
+          requests:
+            storage: 4000Gi
\ No newline at end of file"
thaum-xyz,ankhmorpork,45b09ce341695168f613c54ff9b235e6a1c8c541,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-07-20T20:13:25Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-07-20T20:13:25Z,apps/nut: fix relabelling for the last time,apps/nut/jsonnet/main.jsonnet;apps/nut/manifests/probe.yaml,False,False,False,False,2,9,11,"---FILE: apps/nut/jsonnet/main.jsonnet---
@@ -69,13 +69,9 @@ local all = exporter(config) + {
           static: config.upses,
           relabelingConfigs: [
             {
-              sourceLabels: [""__address__""],
+              sourceLabels: [""__param_target""],
               targetLabel: ""__param_server"",
             },
-            {
-              sourceLabels: [""__param_server""],
-              targetLabel: ""instance"",
-            },
           ],
         },
       },

---FILE: apps/nut/manifests/probe.yaml---
@@ -16,10 +16,7 @@ spec:
     staticConfig:
       relabelingConfigs:
       - sourceLabels:
-        - __address__
+        - __param_target
         targetLabel: __param_server
-      - sourceLabels:
-        - __param_server
-        targetLabel: instance
       static:
       - 192.168.2.29"
thaum-xyz,ankhmorpork,08bbcca6589e268b79bb79118c4b6a71c0872a81,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-07-18T16:41:36Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-07-18T16:41:36Z,apps/parca: fix scrape annotation,apps/parca/jsonnet/main.jsonnet;apps/parca/manifests/agent/daemonSet.yaml;apps/parca/manifests/parca/deployment.yaml,False,False,False,False,16,4,20,"---FILE: apps/parca/jsonnet/main.jsonnet---
@@ -17,16 +17,26 @@ local configYAML = (importstr '../settings.yaml');
 local config = std.parseYaml(configYAML)[0];
 
 local all = {
-  agent: agent(config.agent),
+  agent: agent(config.agent) + {
+    daemonSet+: {
+      spec+: {
+        template+: {
+          metadata+: {
+            annotations: {
+              ""parca.dev/scrape"": ""true"",
+            },
+          },
+        },
+      },
+    }
+  },
   parca: parca(config.parca) + {
     deployment+: {
       spec+: {
         template+: {
           metadata+: {
             annotations: {
               'checksum.config/md5': std.md5(std.toString(config.parca.config)),
-            },
-            labels+: {
               ""parca.dev/scrape"": ""true"",
             },
           },

---FILE: apps/parca/manifests/agent/daemonSet.yaml---
@@ -16,6 +16,8 @@ spec:
       app.kubernetes.io/name: parca-agent
   template:
     metadata:
+      annotations:
+        parca.dev/scrape: ""true""
       labels:
         app.kubernetes.io/component: observability
         app.kubernetes.io/instance: parca-agent

---FILE: apps/parca/manifests/parca/deployment.yaml---
@@ -19,12 +19,12 @@ spec:
     metadata:
       annotations:
         checksum.config/md5: 610e44ed11041b003d6dd9fb8de6408f
+        parca.dev/scrape: ""true""
       labels:
         app.kubernetes.io/component: observability
         app.kubernetes.io/instance: parca
         app.kubernetes.io/name: parca
         app.kubernetes.io/version: 0.12.0-rc.0
-        parca.dev/scrape: ""true""
     spec:
       containers:
       - args:"
thaum-xyz,ankhmorpork,cdf11f08ba0f4c71a636db214f5727b45aad2c04,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-07-18T16:36:55Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-07-18T16:36:55Z,apps/monitoring: fix parca annotation for prom-op,apps/monitoring/jsonnet/main.jsonnet;apps/monitoring/manifests/prometheusOperator/deployment.yaml,False,False,False,False,2,2,4,"---FILE: apps/monitoring/jsonnet/main.jsonnet---
@@ -157,7 +157,7 @@ local kp =
         spec+: {
           template+: {
             metadata+: {
-              labels+: {
+              annotations+: {
                 ""parca.dev/scrape"": ""true"",
               },
             },

---FILE: apps/monitoring/manifests/prometheusOperator/deployment.yaml---
@@ -19,12 +19,12 @@ spec:
     metadata:
       annotations:
         kubectl.kubernetes.io/default-container: prometheus-operator
+        parca.dev/scrape: ""true""
       labels:
         app.kubernetes.io/component: controller
         app.kubernetes.io/name: prometheus-operator
         app.kubernetes.io/part-of: kube-prometheus
         app.kubernetes.io/version: 0.57.0
-        parca.dev/scrape: ""true""
     spec:
       automountServiceAccountToken: true
       containers:"
thaum-xyz,ankhmorpork,7598f22cc62e6ae7a79d8928eae39e7d21fa2920,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-07-18T16:35:23Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-07-18T16:35:23Z,"apps/{auth,monitoring}: fix parca annotation",apps/auth/jsonnet/main.jsonnet;apps/auth/manifests/deployment.yaml;apps/monitoring/jsonnet/main.jsonnet;apps/monitoring/manifests/alertmanager/alertmanager.yaml;apps/monitoring/manifests/blackboxExporter/deployment.yaml;apps/monitoring/manifests/grafana/deployment.yaml;apps/monitoring/manifests/nodeExporter/daemonset.yaml;apps/monitoring/manifests/prometheus/prometheus.yaml;apps/monitoring/manifests/pyrra/kubernetesDeployment.yaml;apps/monitoring/manifests/smokeping/deployment.yaml;apps/monitoring/manifests/uptimerobot/deployment.yaml,False,False,False,False,22,23,45,"---FILE: apps/auth/jsonnet/main.jsonnet---
@@ -13,9 +13,7 @@ local all = oauth(config) + {
         metadata+: {
           annotations: {
             'checksum.config/md5': std.md5(std.toString(config)),
-          },
-          labels+: {
-            ""parca.dev/scrape"": ""true"",
+            'parca.dev/scrape': ""true"",
           },
         },
         spec+: {

---FILE: apps/auth/manifests/deployment.yaml---
@@ -19,12 +19,12 @@ spec:
     metadata:
       annotations:
         checksum.config/md5: f71e524e8e7b3d273e9278ca9f171cf9
+        parca.dev/scrape: ""true""
       labels:
         app.kubernetes.io/component: proxy
         app.kubernetes.io/name: oauth2-proxy
         app.kubernetes.io/part-of: auth
         app.kubernetes.io/version: 7.3.0
-        parca.dev/scrape: ""true""
     spec:
       affinity:
         podAntiAffinity:

---FILE: apps/monitoring/jsonnet/main.jsonnet---
@@ -176,7 +176,7 @@ local kp =
       alertmanager+: {
         spec+: {
           podMetadata+: {
-            labels+: {
+            annotations+: {
               ""parca.dev/scrape"": ""true"",
             },
           },
@@ -213,7 +213,7 @@ local kp =
         spec+: {
           template+: {
             metadata+: {
-              labels+: {
+              annotations+: {
                 ""parca.dev/scrape"": ""true"",
               },
             },
@@ -233,7 +233,7 @@ local kp =
         spec+: {
           template+: {
             metadata+: {
-              labels+: {
+              annotations+: {
                 ""parca.dev/scrape"": ""true"",
               },
             },
@@ -279,7 +279,7 @@ local kp =
           },
 
           podMetadata+: {
-            labels+: {
+            annotations+: {
               ""parca.dev/scrape"": ""true"",
             },
           },
@@ -434,7 +434,7 @@ local kp =
         spec+: {
           template+: {
             metadata+: {
-              labels+: {
+              annotations+: {
                 ""parca.dev/scrape"": ""true"",
               },
             },
@@ -467,9 +467,7 @@ local kp =
         spec+: {
           template+: {
             metadata+: {
-              // Unwanted when using persistance
-              annotations:: {},
-              labels+: {
+              annotations: {
                 ""parca.dev/scrape"": ""true"",
               },
             },
@@ -629,7 +627,7 @@ local kp =
         spec+: {
           template+: {
             metadata+: {
-              labels+: {
+              annotations+: {
                 ""parca.dev/scrape"": ""true"",
               },
             },
@@ -651,8 +649,6 @@ local kp =
             metadata+: {
               annotations+: {
                 'checksum.config/md5': std.md5($.values.uptimerobot.config),
-              },
-              labels+: {
                 ""parca.dev/scrape"": ""true"",
               },
             },

---FILE: apps/monitoring/manifests/alertmanager/alertmanager.yaml---
@@ -29,13 +29,14 @@ spec:
   nodeSelector:
     kubernetes.io/os: linux
   podMetadata:
+    annotations:
+      parca.dev/scrape: ""true""
     labels:
       app.kubernetes.io/component: alert-router
       app.kubernetes.io/instance: main
       app.kubernetes.io/name: alertmanager
       app.kubernetes.io/part-of: kube-prometheus
       app.kubernetes.io/version: 0.24.0
-      parca.dev/scrape: ""true""
   replicas: 3
   resources:
     limits:

---FILE: apps/monitoring/manifests/blackboxExporter/deployment.yaml---
@@ -19,12 +19,12 @@ spec:
     metadata:
       annotations:
         kubectl.kubernetes.io/default-container: blackbox-exporter
+        parca.dev/scrape: ""true""
       labels:
         app.kubernetes.io/component: exporter
         app.kubernetes.io/name: blackbox-exporter
         app.kubernetes.io/part-of: kube-prometheus
         app.kubernetes.io/version: 0.21.1
-        parca.dev/scrape: ""true""
     spec:
       affinity:
         podAntiAffinity:

---FILE: apps/monitoring/manifests/grafana/deployment.yaml---
@@ -17,12 +17,13 @@ spec:
       app.kubernetes.io/part-of: kube-prometheus
   template:
     metadata:
+      annotations:
+        parca.dev/scrape: ""true""
       labels:
         app.kubernetes.io/component: grafana
         app.kubernetes.io/name: grafana
         app.kubernetes.io/part-of: kube-prometheus
         app.kubernetes.io/version: 8.2.1
-        parca.dev/scrape: ""true""
     spec:
       automountServiceAccountToken: false
       containers:

---FILE: apps/monitoring/manifests/nodeExporter/daemonset.yaml---
@@ -18,12 +18,12 @@ spec:
     metadata:
       annotations:
         kubectl.kubernetes.io/default-container: node-exporter
+        parca.dev/scrape: ""true""
       labels:
         app.kubernetes.io/component: exporter
         app.kubernetes.io/name: node-exporter
         app.kubernetes.io/part-of: kube-prometheus
         app.kubernetes.io/version: 1.3.0
-        parca.dev/scrape: ""true""
     spec:
       automountServiceAccountToken: true
       containers:

---FILE: apps/monitoring/manifests/prometheus/prometheus.yaml---
@@ -42,13 +42,14 @@ spec:
     kubernetes.io/os: linux
     storage.infra/local: ""true""
   podMetadata:
+    annotations:
+      parca.dev/scrape: ""true""
     labels:
       app.kubernetes.io/component: prometheus
       app.kubernetes.io/instance: k8s
       app.kubernetes.io/name: prometheus
       app.kubernetes.io/part-of: kube-prometheus
       app.kubernetes.io/version: 2.36.2
-      parca.dev/scrape: ""true""
   podMonitorNamespaceSelector: {}
   podMonitorSelector: {}
   probeNamespaceSelector: {}

---FILE: apps/monitoring/manifests/pyrra/kubernetesDeployment.yaml---
@@ -21,12 +21,13 @@ spec:
       maxUnavailable: 1
   template:
     metadata:
+      annotations:
+        parca.dev/scrape: ""true""
       labels:
         app.kubernetes.io/component: kubernetes
         app.kubernetes.io/name: pyrra
         app.kubernetes.io/part-of: kube-prometheus
         app.kubernetes.io/version: 0.4.4
-        parca.dev/scrape: ""true""
     spec:
       containers:
       - args:

---FILE: apps/monitoring/manifests/smokeping/deployment.yaml---
@@ -15,11 +15,12 @@ spec:
       app.kubernetes.io/name: smokeping
   template:
     metadata:
+      annotations:
+        parca.dev/scrape: ""true""
       labels:
         app.kubernetes.io/component: exporter
         app.kubernetes.io/name: smokeping
         app.kubernetes.io/version: 0.6.1
-        parca.dev/scrape: ""true""
     spec:
       affinity:
         podAntiAffinity:

---FILE: apps/monitoring/manifests/uptimerobot/deployment.yaml---
@@ -17,11 +17,11 @@ spec:
     metadata:
       annotations:
         checksum.config/md5: 9482c4e4a8cda7a10d594f51119c2087
+        parca.dev/scrape: ""true""
       labels:
         app.kubernetes.io/component: exporter
         app.kubernetes.io/name: uptimerobot
         app.kubernetes.io/version: master
-        parca.dev/scrape: ""true""
     spec:
       containers:
       - args:"
thaum-xyz,ankhmorpork,bbb4143684275eff7dbafd3cd384f36ff0246ecf,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-07-15T16:40:29Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-07-15T16:40:29Z,apps/github: decrease scrape interval to prevent GH rate limiter issues,apps/github/manifests/podMonitor.yaml,False,False,False,False,1,1,2,"---FILE: apps/github/manifests/podMonitor.yaml---
@@ -8,7 +8,7 @@ metadata:
   namespace: github
 spec:
   podMetricsEndpoints:
-  - interval: 120s
+  - interval: 270s
     scrapeTimeout: 90s
     port: metrics
   selector:"
thaum-xyz,ankhmorpork,a4731ccf429ae96492fda8cee1eb79415600571d,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-07-15T15:30:37Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-07-15T15:30:37Z,apps/github: fix passing orgs,apps/github/manifests/deployment.yaml,False,False,False,False,1,1,2,"---FILE: apps/github/manifests/deployment.yaml---
@@ -25,7 +25,7 @@ spec:
         name: exporter
         env:
         - name: ORGS
-          value: ""prometheus,prometheus-operator,prometheus-community,open-telemetry,timescale""
+          value: ""prometheus, prometheus-operator, prometheus-community, open-telemetry, timescale""
         - name: GITHUB_TOKEN
           valueFrom:
             secretKeyRef:"
thaum-xyz,ankhmorpork,a88dda378b28360024160fa5e9b0d7016d6e32df,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-07-15T15:28:59Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-07-15T15:28:59Z,*: fix image compat tests,.ignoredimages,False,False,False,False,1,0,1,"---FILE: .ignoredimages---
@@ -18,3 +18,4 @@ lscr.io/linuxserver/sonarr
 lscr.io/linuxserver/radarr
 ghcr.io/pyrra-dev/pyrra
 grafana/mimir
+infinityworks/github-exporter"
thaum-xyz,ankhmorpork,c2768d65d855aac94ed4b8933b7369c77e6405cd,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-07-14T08:13:21Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-07-14T08:13:21Z,apps/monitoring: fix quoting in alertmanager config,apps/monitoring/manifests/alertmanager/secret.yaml;apps/monitoring/raw/alertmanager-secret.yaml,False,False,False,False,2,2,4,"---FILE: apps/monitoring/manifests/alertmanager/secret.yaml---
@@ -40,7 +40,7 @@ spec:
             short_fields: true
             fields:
             - title: Alertname
-              value: {{ .CommonLabels.alertname }}
+              value: '{{ .CommonLabels.alertname }}'
             - title: Severity
               value: '{{ .CommonLabels.severity }}'
             - title: Job

---FILE: apps/monitoring/raw/alertmanager-secret.yaml---
@@ -40,7 +40,7 @@ spec:
             short_fields: true
             fields:
             - title: Alertname
-              value: {{ .CommonLabels.alertname }}
+              value: '{{ .CommonLabels.alertname }}'
             - title: Severity
               value: '{{ .CommonLabels.severity }}'
             - title: Job"
thaum-xyz,ankhmorpork,6334ca6a1222ce7865926590ae7f7e62876b68da,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-06-22T17:56:40Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-06-22T17:56:40Z,"apps/{homer,portal}: fix homer image",apps/homer/manifests/deployment.yaml;apps/homer/settings.yaml;apps/portal/manifests/deployment.yaml;apps/portal/settings.yaml,False,False,False,False,4,4,8,"---FILE: apps/homer/manifests/deployment.yaml---
@@ -38,7 +38,7 @@ spec:
               topologyKey: kubernetes.io/hostname
             weight: 100
       containers:
-      - image: b4bz/homer:22.06.1
+      - image: b4bz/homer:v22.06.1
         imagePullPolicy: IfNotPresent
         name: homer
         ports:

---FILE: apps/homer/settings.yaml---
@@ -1,6 +1,6 @@
 ---
 version: ""22.06.1""  # application-version-from-github: bastienwirtz/homer
-image: ""b4bz/homer:22.06.1""  # application-image-from-github: bastienwirtz/homer
+image: ""b4bz/homer:v22.06.1""  # application-image-from-github: bastienwirtz/homer
 namespace: ""homer""
 replicas: 2
 domain: ""ankhmorpork.thaum.xyz""

---FILE: apps/portal/manifests/deployment.yaml---
@@ -38,7 +38,7 @@ spec:
               topologyKey: kubernetes.io/hostname
             weight: 100
       containers:
-      - image: b4bz/homer:22.06.1
+      - image: b4bz/homer:v22.06.1
         imagePullPolicy: IfNotPresent
         name: homer
         ports:

---FILE: apps/portal/settings.yaml---
@@ -1,6 +1,6 @@
 ---
 version: ""22.06.1""  # application-version-from-github: bastienwirtz/homer
-image: ""b4bz/homer:22.06.1""  # application-image-from-github: bastienwirtz/homer
+image: ""b4bz/homer:v22.06.1""  # application-image-from-github: bastienwirtz/homer
 namespace: ""portal""
 replicas: 1
 domain: ""portal.krupa.net.pl"""
thaum-xyz,ankhmorpork,5b208910cef2ac9e2a7b30bf77b255763f3b19d7,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-06-21T06:19:19Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-06-21T06:19:19Z,apps/multimedia: fix PlexNoMediaLibraries alert expression,apps/multimedia/manifests/plex-exporter/prometheusRule.yaml,False,False,False,False,4,1,5,"---FILE: apps/multimedia/manifests/plex-exporter/prometheusRule.yaml---
@@ -36,7 +36,10 @@ spec:
         description: Plex is not reporting any content in a library
         runbook_url: https://runbooks.thaum.xyz/runbooks/thaum-xyz/plexnomedialibraries
         summary: Plex is not reporting any content in one of libraries
-      expr: plex_media_server_library_media_count
+      expr: |
+        (plex_media_server_library_media_count < 1)
+        OR
+        absent(plex_media_server_library_media_count)
       for: 30m
       labels:
         severity: warning"
thaum-xyz,ankhmorpork,8ae9f8b3c66e550a2553b965d3dc0d2aca9c76cc,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-06-14T18:22:07Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-06-14T18:22:07Z,apps/paperless: fix md5 checksum generation,apps/paperless/jsonnet/paperless.libsonnet;apps/paperless/manifests/web/statefulSet.yaml,False,False,False,False,2,2,4,"---FILE: apps/paperless/jsonnet/paperless.libsonnet---
@@ -248,7 +248,7 @@ function(params) {
           labels: $._config.commonLabels,
           annotations: {
             'kubectl.kubernetes.io/default-container': c.name,
-            'checksum.config/md5': std.md5(std.manifestJsonMinified($._config.config)),
+            'checksum.config/md5': std.md5(std.manifestJsonMinified($.config.data)),
             'checksum.secrets/md5': std.md5(std.manifestJsonMinified($._config.secrets)),
             'checksum.database/md5': std.md5(std.manifestJsonMinified($._config.database)),
           },

---FILE: apps/paperless/manifests/web/statefulSet.yaml---
@@ -17,7 +17,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: a11626cbe2906e4e5196a51b333b7df7
+        checksum.config/md5: 0df4aa3cb8fc36842a200024d31d58ae
         checksum.database/md5: 35a99cbc768e7168fec5e374bdb964b7
         checksum.secrets/md5: 9aa8755169fd680444330b9e1d948f68
         kubectl.kubernetes.io/default-container: paperless"
thaum-xyz,ankhmorpork,edd8dc733877a4bb2ff0525c01bc96e89ea6d76b,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-06-14T18:08:27Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-06-14T18:08:27Z,apps/paperless: fix CORS,apps/paperless/jsonnet/paperless.libsonnet;apps/paperless/manifests/web/config.yaml,False,False,False,False,2,2,4,"---FILE: apps/paperless/jsonnet/paperless.libsonnet---
@@ -121,7 +121,7 @@ function(params) {
       PAPERLESS_URL: 'http://' + $._config.domain,
       PAPERLESS_REDIS: $._config.broker.address,
       PAPERLESS_TIME_ZONE: $._config.timezone,
-      PAPERLESS_CORS_ALLOWED_HOSTS: $._config.name + '.' + $._config.namespace + '.svc',
+      PAPERLESS_CORS_ALLOWED_HOSTS: 'http://' + $._config.name + '.' + $._config.namespace + '.svc,http://' + $._config.domain + ',https://' + $._config.domain,
     },
   },
 

---FILE: apps/paperless/manifests/web/config.yaml---
@@ -1,7 +1,7 @@
 apiVersion: v1
 data:
   PAPERLESS_CONSUMER_POLLING: ""30""
-  PAPERLESS_CORS_ALLOWED_HOSTS: paperless.paperless.svc
+  PAPERLESS_CORS_ALLOWED_HOSTS: http://paperless.paperless.svc,http://papers.krupa.net.pl,https://papers.krupa.net.pl
   PAPERLESS_FILENAME_FORMAT: '{created_year}/{correspondent}/{asn} - {title}'
   PAPERLESS_OCR_LANGUAGE: eng+deu+pol
   PAPERLESS_OCR_LANGUAGES: pol"
thaum-xyz,ankhmorpork,4380e73f2b26e44553bd2664df403c2f00dfc9ba,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-06-14T17:59:35Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-06-14T18:04:05Z,"apps/paperless: fix md5 checksum generation

Signed-off-by: Pawe Krupa (paulfantom) <pawel@krupa.net.pl>",apps/paperless/jsonnet/main.jsonnet;apps/paperless/jsonnet/paperless.libsonnet;apps/paperless/manifests/web/config.yaml;apps/paperless/manifests/web/statefulSet.yaml;apps/paperless/settings.yaml,False,False,False,False,8,8,16,"---FILE: apps/paperless/jsonnet/main.jsonnet---
@@ -33,10 +33,10 @@ local all = {
     secretsEnc: sealedsecret(
       $.web.secrets.metadata,
       {
-        PAPERLESS_ADMIN_USER: config.paperless.encryptedSecrets.user,
-        PAPERLESS_ADMIN_PASSWORD: config.paperless.encryptedSecrets.pass,
-        PAPERLESS_ADMIN_MAIL: config.paperless.encryptedSecrets.email,
-        PAPERLESS_SECRET_KEY: config.paperless.encryptedSecrets.key,
+        PAPERLESS_ADMIN_USER: config.paperless.secrets.user,
+        PAPERLESS_ADMIN_PASSWORD: config.paperless.secrets.pass,
+        PAPERLESS_ADMIN_MAIL: config.paperless.secrets.email,
+        PAPERLESS_SECRET_KEY: config.paperless.secrets.key,
       }
     ),
 

---FILE: apps/paperless/jsonnet/paperless.libsonnet---
@@ -26,7 +26,7 @@ local defaults = {
     pass: '',
   },
   broker: {
-    address: 'redis://broker.paperless.svc:6379',
+    address: 'redis://redis.paperless.svc:6379',
   },
   config: {
     PAPERLESS_FILENAME_FORMAT: '{created_year}/{correspondent}/{asn} - {title}',

---FILE: apps/paperless/manifests/web/config.yaml---
@@ -5,7 +5,7 @@ data:
   PAPERLESS_FILENAME_FORMAT: '{created_year}/{correspondent}/{asn} - {title}'
   PAPERLESS_OCR_LANGUAGE: eng+deu+pol
   PAPERLESS_OCR_LANGUAGES: pol
-  PAPERLESS_REDIS: redis://broker.paperless.svc:6379
+  PAPERLESS_REDIS: redis://redis.paperless.svc:6379
   PAPERLESS_TASK_WORKERS: ""1""
   PAPERLESS_TIKA_ENABLED: ""0""
   PAPERLESS_TIME_ZONE: Europe/Berlin

---FILE: apps/paperless/manifests/web/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
       annotations:
         checksum.config/md5: a11626cbe2906e4e5196a51b333b7df7
         checksum.database/md5: 35a99cbc768e7168fec5e374bdb964b7
-        checksum.secrets/md5: 8dea432d03fb648cef21e26577cc0ffb
+        checksum.secrets/md5: 9aa8755169fd680444330b9e1d948f68
         kubectl.kubernetes.io/default-container: paperless
       labels:
         app.kubernetes.io/component: webservice

---FILE: apps/paperless/settings.yaml---
@@ -40,7 +40,7 @@ paperless:
     name: &dbname paperless
     encryptedUser: AgA2jed27XB5ZRMLgmh0q48dZI7YAcuN4REvTHG3AEXFbXv8lNAAjL7uYlRmjc3Cyq/L0zpzo4m2uFNk4eGvdplZrVmung7K1AFrj6CdYO6TgnbCGRg7hGWrv1qcN+yXBhW+BUjx8YGbdRlIV03wK10uMebHedXJgYcrJq+UbwyMwqFRLmn0HrtPqt78Bpp+8q9V0w5QpNT+RUwgnSIoT52t/dE+CZARZksi1GcEc3HnXCMOujDohPmZcXFs/9PpMDHmbEp6vayPR1zFrsU95sGKUVsUbVN+PNns7WvDNaGIa5LC9QoC4R6ybVkeOm+J4vv+UdWGY3/q/X7qfmO6IExR6AWMtTHhefMkuzUOj61NpS5lWHtbNCBJSsG1v7tXtiO6Fsa8lW51Ug/YVad/uXAMvlh0lvsHJDoX8YT4cxO17t0dQz7Fzc2Ha9SQgAdzhcfItXZ5dA3JhGSszyFLwSQmz1WYFAq+qMrnbD2TpxPNY4lGPSLvvn5p8Fm43dkQ+pCvOfGuqgoZVEtXoU3/28uP73AvteUgNTdqiKMepgb+OSzi3WHC0Fimd4y47Tf0TuVwH/2SNGWASTwgqpB+5s0b2XTHF1PxHp2HMft8c3O4O0xKGx36x5wLmoUGD3xFTtT+ZwgndoyEeyzDlk5F31OSN3j/XihWbjZ04fl1KH73cOdvOJjzlFa0sFk6tceAdyCUZU9orhA=
     encryptedPass: AgBDLA6ascKb68PZhieOZ7DKb6tztEZrzO4mwc5GZ5XHqDZSiRAQx/AIF3s92lC1XgvNvTZ4ydAKDGTMVahXRegO4Vpy/cxho8mb8DmRVKbaTozENsiR3s7254/Nf8VVVNaR1CkM1/ySkjm226MuXeXLjuzTVSDemDPiwo2RJFjJAf1errAlYltpcAEixMwsfG5JuuV5ObKmpbdwAY+fVHOdjpDmihtWgyj/ENL29mnDWqe/J6DHlwCRC4py7G/qFkKI0g0NuQHH/nQ0Ndju+mNdKV6hf2SQGNKzdin6y/aWx8XAMSgnbVpVQo+9jDwGLLtcEx0Zbv5QD7038l3O49Fu4Hk0mnv8vjsJmlkb7MkqWEP/nwC4yKpKdmGVyyBn3FMn9G+TUtdyLbwjWPlWXRmpZUvwwiYvYedZnyudmGPD2LjNE3EaGUTR5FFXrRBsANBGiaOFDVRd9NLsO5E4UO3W0efWla7Z2GoPI//eQLcq8kuatTafhyurrG71aTgSg+gWAHeLPqbnGzNxHPXebGIy4eUViImbKza/yu5KpVzxSNnih+rFEH+WXXXKmfKO5R4fdgGY2ynvutRfn6iRCEj7zcVHa+J9MbVWqPAdaEZ7n7kRRDmSUL3403BE0smee9SDOu0xlD+SLvEKG2J2uJlsG4tSen/h7z334z10eyjoZfgIzG50y6BI486v/tN7SU8hXaIjtwtDrqta6tkY7rPSXqaxFqjLbS9N/P876evx
-  encryptedSecrets:
+  secrets:
     user: AgBtbX96Bcfx30m2sf94OtBrO0xSOZd8pym/4mtuseHtrsxHQ2rx/E3KizKRqkIr37ZVTnTsyLUHwpA+8Glfq5HyG9YaCyFjmzRtYZmZ0MnWBjYeVGHiEGdTCohOL1hTCxpYCsLIyjs0Qood9GYAO5YdwXOmvd1NmdRA5tRxUNxstOseWBmUoIpYWN+BeaEK52a/fFP9ZkgokGpCQAwqUmnkSSJ3/E7fPMLNR7WNW9L79XpwSYwoVqQk1eSm7imwjZq8ZrNA/wGwwGNM8PTSAEVpqEdpzf9VBxYJ7ge6X2gmrpHYmhXW9G3jWw7Y8um3Z1NucEkGQMTrEmlUpVkTjwZ3M1wl/BtCBcrRXPL7x+edF7+K1O/TKmiYdKT+Pb01RhHSvBcxfVoOPBEYHY/4uynB/tyu/+WL+pR8EgJP+KuJvsj9VxL2VzLLuwmzucDCzvX0i9dVQZFfE23ygFTsE5BPBs+TCdCeg/jxWn1kgovFcRtwdl+MQbmK7yfcRB5cGK36FKjWWQXxN8U6Isn7uB225XMZ2c2tnMd07zejJTW6ld1Vdro9ZCCrNiTPJd5SUR/JwGfmxuMNIZbn/yzzJMgNc3o+rRMfpKUOaOvwZBpCgZMXwPeQZGE0LNsmB3XAZ7ecu/YXZMSFV6ZvjHI1enOTJ9qiqETrx+qK+jbosVnMbpJUkjDRNHWMYMZXpIt2pBZ+Z/yOGMM1RW1A
     pass: AgB5Wi/QiQymTD0FxCqLy2FIkQaxjssGhZPxDu8BfE2Xlti4FUJOXyvcXMMlHIWxQzcEftZTyTi7eIN6te0OFFs/+iMWUnmOk8apQqH4ygxtu65DHJZUFyO7QMD4ZMOfG+QNHc+PJMrHqzqceJPdHlZ5Uj4Z912GOi+0DpuqHpxG88McwTc0jmJV3Zr4rlwHsS7VqxKjtTtHuGYXY7HvKKmQpw3GVQnVzSUlrmRMGcJkpQASqkE9ggKm8dsEVlvoCXJFatHRYNNWmGC2xxXwCnnKNmgRcRY1oY5b3JDqZaAqxfb9lt6amEd4E6IcyyWL0w81YBph+TiGe05KjZ9SIlkC4CzNNJ7EZMB/vqeultp0QB7LpocACNYEHGVnfcUybJfRARlGTYK9s0fXUimXGWuRF1XgEKOmYQ1za8zULA2KE3ys5Ltz+2kx3dY2VYewz/651L3vJjmarUvf82wAVB+rJ2EDoeLC20fSgTvzWQk+uaDUw50FQEd56OeinlfhoZV/jE3a2PdaQuy/LZpdizWwnElb4LOq4rIw9RiTOaYZbYdZDVJ2UGASSvc4mCUEr4RAXEUXMkc2+SCmmBEV4XDspg8EJwUnY/VxYJDGYsNA5M9OtY3gTNRb6iqVGT0WOH99h/oC6M69WaFf5wKPk5qAlp2RUS3VqSv1xIlNe4+NU2UK2fG/VKYWeG/X0V15JqBpvHaLGXWIu0xBFGFKHw0uMRJtEB3CFFwOuhr/OCjp
     email: AgBDKXkOVqEK97m+5ejyjmApJ0XJWU15moiWc7C5uwstRmVIaiA3Uk5jRK4c/V4w/jlOATzqdIwwY0jn9U7cckbvnA9usd7VlJoludm1CF98yt8fjAEqDSj0siiJ3icW9/sHVZhcSck+2nqsl5LkmUfS0kY5uhpnS9GIbhQoBClT0a2uTcmfCf96hrzdXPjfsDmxLU/FbZYVoPGjNjPLqz/Zo8L4aDJiyf34pEqoMOQCuvmv+FKjPvTVijn/KHXmGRoJn4n+LjZxYooeoaUWE3w1ooMqFTAVY/zF/nl4DNlh8mJVAJvnZj2c7z6rKxX0xp05VY129dEHzr5T58sboQJc8B22midjN/24qFCV6c55SFBiepNJ/QlbFAFJoLtVjYDJuEuAbEitMuOpI7mTrDBbJt7PxiIaxHW4bjG4kVVmXaHh7BksLorgfuBHSm/fhU3hl6mXJkFwyHUo691fjuxZLsUfa4uijhTjPJGFNr8R9wfd9FzbX26jBDZ38SUp2vQHbnGB3BSUSpkoT196FlDNPJHm5jL+VXzUU3O7a3P7CTiRfza/4sdFE2j0vlvC7JJTNLs0Ibf2um6KMvXaXlFIW0T3lsUYVmORE4kOT4zaGZ9U17453qmoYjZ+1ucpamwwuTpOfXDXGE9jsU7A78HZ/pqD9oMwduUovqran6bbstiBKQJqoov21HM565IAIcYkkuJEAzIOF1A7GGonLAwcqra/rw=="
thaum-xyz,ankhmorpork,0e19b1ed369188739334e039a0ffc1c37a35ebc4,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-06-14T17:56:04Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-06-14T17:56:04Z,apps/paperless: fix database secret,apps/paperless/jsonnet/main.jsonnet;apps/paperless/manifests/web/databaseEnc.yaml,False,False,False,False,17,9,26,"---FILE: apps/paperless/jsonnet/main.jsonnet---
@@ -14,14 +14,21 @@ local all = {
     databaseEnc: sealedsecret(
       $.web.database.metadata,
       {
-        PAPERLESS_DBHOST: 'db.paperless.svc',
-        PAPERLESS_DBNAME: config.paperless.database.name,
-        PAPERLESS_DBPORT: '5432',
-        PAPERLESS_DBSSLMODE: 'prefer',
         PAPERLESS_DBUSER: config.paperless.database.encryptedUser,
         PAPERLESS_DBPASS: config.paperless.database.encryptedPass,
       }
-    ),
+    ) + {
+      spec+: {
+        template+: {
+          data+: {
+            PAPERLESS_DBHOST: 'db.paperless.svc',
+            PAPERLESS_DBNAME: config.paperless.database.name,
+            PAPERLESS_DBPORT: '5432',
+            PAPERLESS_DBSSLMODE: 'prefer',
+          }
+        }
+      }
+    },
     secrets+:: {},
     secretsEnc: sealedsecret(
       $.web.secrets.metadata,

---FILE: apps/paperless/manifests/web/databaseEnc.yaml---
@@ -10,13 +10,14 @@ metadata:
   namespace: paperless
 spec:
   encryptedData:
-    PAPERLESS_DBHOST: db.paperless.svc
-    PAPERLESS_DBNAME: paperless
     PAPERLESS_DBPASS: AgBDLA6ascKb68PZhieOZ7DKb6tztEZrzO4mwc5GZ5XHqDZSiRAQx/AIF3s92lC1XgvNvTZ4ydAKDGTMVahXRegO4Vpy/cxho8mb8DmRVKbaTozENsiR3s7254/Nf8VVVNaR1CkM1/ySkjm226MuXeXLjuzTVSDemDPiwo2RJFjJAf1errAlYltpcAEixMwsfG5JuuV5ObKmpbdwAY+fVHOdjpDmihtWgyj/ENL29mnDWqe/J6DHlwCRC4py7G/qFkKI0g0NuQHH/nQ0Ndju+mNdKV6hf2SQGNKzdin6y/aWx8XAMSgnbVpVQo+9jDwGLLtcEx0Zbv5QD7038l3O49Fu4Hk0mnv8vjsJmlkb7MkqWEP/nwC4yKpKdmGVyyBn3FMn9G+TUtdyLbwjWPlWXRmpZUvwwiYvYedZnyudmGPD2LjNE3EaGUTR5FFXrRBsANBGiaOFDVRd9NLsO5E4UO3W0efWla7Z2GoPI//eQLcq8kuatTafhyurrG71aTgSg+gWAHeLPqbnGzNxHPXebGIy4eUViImbKza/yu5KpVzxSNnih+rFEH+WXXXKmfKO5R4fdgGY2ynvutRfn6iRCEj7zcVHa+J9MbVWqPAdaEZ7n7kRRDmSUL3403BE0smee9SDOu0xlD+SLvEKG2J2uJlsG4tSen/h7z334z10eyjoZfgIzG50y6BI486v/tN7SU8hXaIjtwtDrqta6tkY7rPSXqaxFqjLbS9N/P876evx
-    PAPERLESS_DBPORT: ""5432""
-    PAPERLESS_DBSSLMODE: prefer
     PAPERLESS_DBUSER: AgA2jed27XB5ZRMLgmh0q48dZI7YAcuN4REvTHG3AEXFbXv8lNAAjL7uYlRmjc3Cyq/L0zpzo4m2uFNk4eGvdplZrVmung7K1AFrj6CdYO6TgnbCGRg7hGWrv1qcN+yXBhW+BUjx8YGbdRlIV03wK10uMebHedXJgYcrJq+UbwyMwqFRLmn0HrtPqt78Bpp+8q9V0w5QpNT+RUwgnSIoT52t/dE+CZARZksi1GcEc3HnXCMOujDohPmZcXFs/9PpMDHmbEp6vayPR1zFrsU95sGKUVsUbVN+PNns7WvDNaGIa5LC9QoC4R6ybVkeOm+J4vv+UdWGY3/q/X7qfmO6IExR6AWMtTHhefMkuzUOj61NpS5lWHtbNCBJSsG1v7tXtiO6Fsa8lW51Ug/YVad/uXAMvlh0lvsHJDoX8YT4cxO17t0dQz7Fzc2Ha9SQgAdzhcfItXZ5dA3JhGSszyFLwSQmz1WYFAq+qMrnbD2TpxPNY4lGPSLvvn5p8Fm43dkQ+pCvOfGuqgoZVEtXoU3/28uP73AvteUgNTdqiKMepgb+OSzi3WHC0Fimd4y47Tf0TuVwH/2SNGWASTwgqpB+5s0b2XTHF1PxHp2HMft8c3O4O0xKGx36x5wLmoUGD3xFTtT+ZwgndoyEeyzDlk5F31OSN3j/XihWbjZ04fl1KH73cOdvOJjzlFa0sFk6tceAdyCUZU9orhA=
   template:
+    data:
+      PAPERLESS_DBHOST: db.paperless.svc
+      PAPERLESS_DBNAME: paperless
+      PAPERLESS_DBPORT: ""5432""
+      PAPERLESS_DBSSLMODE: prefer
     metadata:
       annotations:
         sealedsecrets.bitnami.com/managed: ""true"""
thaum-xyz,ankhmorpork,962b14804097903e8df9a78c943b9f4ed00d1040,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-06-14T17:38:51Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-06-14T17:46:15Z,"apps/paperless: fix PVC

Signed-off-by: Pawe Krupa (paulfantom) <pawel@krupa.net.pl>",apps/paperless/jsonnet/paperless.libsonnet;apps/paperless/manifests/web/pvcConsume.yaml;apps/paperless/settings.yaml,False,False,False,False,11,0,11,"---FILE: apps/paperless/jsonnet/paperless.libsonnet---
@@ -60,6 +60,11 @@ local defaults = {
     consume: {
       storageClassName: 'manual',
       accessModes: ['ReadWriteOnce'],
+      resources: {
+        requests: {
+          storage: '10Gi',
+        },
+      },
     },
   },
 };

---FILE: apps/paperless/manifests/web/pvcConsume.yaml---
@@ -10,4 +10,7 @@ metadata:
 spec:
   accessModes:
   - ReadWriteOnce
+  resources:
+    requests:
+      storage: 1Gi
   storageClassName: manual

---FILE: apps/paperless/settings.yaml---
@@ -31,6 +31,9 @@ paperless:
       storageClassName: ""manual""
       accessModes:
         - ReadWriteOnce
+      resources:
+        requests:
+          storage: 1Gi
   domain: ""papers.krupa.net.pl""
   timezone: ""Europe/Berlin""
   database:"
thaum-xyz,ankhmorpork,8b3dc5b743fc6e6ddc9c5174150c902be58460d5,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-06-03T08:59:39Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-06-03T08:59:39Z,*: fix parca logo,README.md,False,False,False,False,1,1,2,"---FILE: README.md---
@@ -105,7 +105,7 @@ Cluster is [k3s](https://k3s.io/) provisioned on bare-metal Ubuntu 20.04 using a
     <td>Operational dashboards</td>
   </tr>
   <tr>
-    <td><img width=""32"" src=""https://www.parca.dev/img/logo.svg""></td>
+    <td><img width=""32"" src=""https://avatars.githubusercontent.com/u/86306284?s=200&v=4""></td>
     <td><a href=""https://parca.dev"">Parca</a></td>
     <td>Continuous profiling</td>
   </tr>"
thaum-xyz,ankhmorpork,b13e15b247baf6b0b924baa6e1fb7ba68b718e82,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-25T09:01:52Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-25T09:01:52Z,apps/homeassistant: include fix from https://github.com/prometheus-community/postgres_exporter/pull/635,apps/homeassistant/jsonnet/jsonnetfile.lock.json;apps/homeassistant/manifests/timescaledb/prometheusRule.yaml,False,False,False,False,7,7,14,"---FILE: apps/homeassistant/jsonnet/jsonnetfile.lock.json---
@@ -38,8 +38,8 @@
           ""subdir"": ""postgres_mixin""
         }
       },
-      ""version"": ""92bdb8755de886b2366de245e559538030ba3668"",
-      ""sum"": ""MVorPR3kqTL+Iqcm/+fM2rb1smwYb476M8benM1MkDI=""
+      ""version"": ""0bacea243a6889e4941c6c89c17587043fa99de6"",
+      ""sum"": ""H+okh0mBSyJSyvkCadCXck1ouZUhdokidsoDGA9h25c=""
     },
     {
       ""source"": {
@@ -48,7 +48,7 @@
           ""subdir"": ""apps/esphome""
         }
       },
-      ""version"": ""ae17eb87b39de538be8d9e707633727ff5620869"",
+      ""version"": ""f84f5e2473d2f4bad278b82e07fa017471563059"",
       ""sum"": ""A0S+dWl7+3qIxDmlQe7j4rqtI1CZH40jLUcjkfivwq8=""
     },
     {
@@ -58,7 +58,7 @@
           ""subdir"": ""apps/homeassistant""
         }
       },
-      ""version"": ""ae17eb87b39de538be8d9e707633727ff5620869"",
+      ""version"": ""f84f5e2473d2f4bad278b82e07fa017471563059"",
       ""sum"": ""ffOZGIvSHTjJmH/Ql5Pq+HmBIB+HAINTFG1UzSts3yo=""
     },
     {
@@ -68,7 +68,7 @@
           ""subdir"": ""utils""
         }
       },
-      ""version"": ""ae17eb87b39de538be8d9e707633727ff5620869"",
+      ""version"": ""f84f5e2473d2f4bad278b82e07fa017471563059"",
       ""sum"": ""fpU9+wurrgNrnBmnPHYehqp3R5TqVWVdg8s8akBRmYM=""
     }
   ],

---FILE: apps/homeassistant/manifests/timescaledb/prometheusRule.yaml---
@@ -79,8 +79,8 @@ spec:
         summary: 'PostgreSQL high number of slow on {{ $labels.cluster }} for database
           {{ $labels.datname }} '
       expr: |
-        avg(
-          rate by (datname) (
+        avg by (datname) (
+          rate (
             pg_stat_activity_max_tx_duration{datname!~""template.*"",job=""timescaledb"", namespace=""homeassistant""}[2m]
           )
         ) > 2 * 60"
thaum-xyz,ankhmorpork,3c52b079da5bd2d3b926a407219445644e2dd6f1,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-24T16:33:34Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-24T16:33:42Z,"apps/homeassistant: fix displaying last line on LCD display

Signed-off-by: Pawe Krupa (paulfantom) <pawel@krupa.net.pl>",apps/homeassistant/config/configuration.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,18,14,32,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -194,6 +194,8 @@ template:
         %}
         {% if calendars|length > 1 %}
         {{ calendars[1].prefix }} {{ calendars[1].data }}
+        {% else %}
+        
         {% endif %}
       line4: >
         {%
@@ -215,8 +217,10 @@ template:
             ""data"": state_attr('calendar.adrianna_wojas_gmail_com','message') | regex_replace(find='[^\x00-\x7F]+', replace='', ignorecase=False) | trim
           }] | rejectattr(""timestamp"", ""gt"", as_timestamp(utcnow()) | int + 24*60*60) | sort(attribute='timestamp') 
         %}
-        {% if calendars|length >= 2 %}
-        {{ calendars[2].prefix }} {{ calendars[2].data }}
+        {% if calendars|length > 1 %}
+        {{ calendars[1].prefix }} {{ calendars[1].data }}
+        {% else %}
+        
         {% endif %}
 
 input_boolean:

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -79,9 +79,9 @@ data:
     \         }] | rejectattr(\""timestamp\"", \""gt\"", as_timestamp(utcnow()) | int
     + 24*60*60) | sort(attribute='timestamp') \n        %}\n        {% if calendars|length
     > 1 %}\n        {{ calendars[1].prefix }} {{ calendars[1].data }}\n        {%
-    endif %}\n      line4: >\n        {%\n          set calendars = [{\n            \""timestamp\"":
-    as_timestamp(state_attr('calendar.pawel_krupa_net_pl','start_time')) | int,\n
-    \           \""prefix\"": as_timestamp(state_attr('calendar.pawel_krupa_net_pl','start_time'))
+    else %}\n        \n        {% endif %}\n      line4: >\n        {%\n          set
+    calendars = [{\n            \""timestamp\"": as_timestamp(state_attr('calendar.pawel_krupa_net_pl','start_time'))
+    | int,\n            \""prefix\"": as_timestamp(state_attr('calendar.pawel_krupa_net_pl','start_time'))
     | int | timestamp_custom(\""%H:%M\""),\n            \""data\"": state_attr('calendar.pawel_krupa_net_pl','message')
     | regex_replace(find='[^\\x00-\\x7F]+', replace='', ignorecase=False) | trim\n
     \         },{\n            \""timestamp\"": as_timestamp(state_attr('calendar.pawel_timescale_com','start_time'))
@@ -98,14 +98,14 @@ data:
     | regex_replace(find='[^\\x00-\\x7F]+', replace='', ignorecase=False) | trim\n
     \         }] | rejectattr(\""timestamp\"", \""gt\"", as_timestamp(utcnow()) | int
     + 24*60*60) | sort(attribute='timestamp') \n        %}\n        {% if calendars|length
-    >= 2 %}\n        {{ calendars[2].prefix }} {{ calendars[2].data }}\n        {%
-    endif %}\n\ninput_boolean:\n  projector:\n    name: Projector State\n    icon:
-    mdi:projector\n  projector_screen:\n    name: Projector Screen State\n    icon:
-    mdi:projector-screen-variant-outline\n\ninput_select:\n  speakers:\n    name:
-    Speakers Input\n    icon: mdi:speakers\n    options:\n    - opt/coax\n    - line1/2\n
-    \   - bt\n    initial: line1/2\n\nplant:\n  jovita:\n    sensors:\n      moisture:
-    sensor.jovita_moisture\n      temperature: sensor.jovita_temperature\n      conductivity:
-    sensor.jovita_soil_conductivity\n      brightness: sensor.jovita_illuminance\n
+    > 1 %}\n        {{ calendars[1].prefix }} {{ calendars[1].data }}\n        {%
+    else %}\n        \n        {% endif %}\n\ninput_boolean:\n  projector:\n    name:
+    Projector State\n    icon: mdi:projector\n  projector_screen:\n    name: Projector
+    Screen State\n    icon: mdi:projector-screen-variant-outline\n\ninput_select:\n
+    \ speakers:\n    name: Speakers Input\n    icon: mdi:speakers\n    options:\n
+    \   - opt/coax\n    - line1/2\n    - bt\n    initial: line1/2\n\nplant:\n  jovita:\n
+    \   sensors:\n      moisture: sensor.jovita_moisture\n      temperature: sensor.jovita_temperature\n
+    \     conductivity: sensor.jovita_soil_conductivity\n      brightness: sensor.jovita_illuminance\n
     \   min_moisture: 15\n    max_moisture: 60\n    min_conductivity: 350\n    max_conductivity:
     2000\n    min_temperature: 10\n    max_temperature: 32\n    min_brightness: 500\n
     \   max_brightness: 12000\n  svetlana:\n    sensors:\n      moisture: sensor.svetlana_moisture\n

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: 0aafca0e2ba1e5a103cb79aecee6d265
+        checksum.config/md5: 57cbd94842b2ba0d785579fcea10c28c
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,c01b652714c23c38ed6d28ccbe4c347fce9dec29,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-24T16:21:10Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-24T16:21:10Z,apps/homeassistant: fix printing last line on LCD display,apps/homeassistant/config/configuration.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,3,3,6,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -215,7 +215,7 @@ template:
             ""data"": state_attr('calendar.adrianna_wojas_gmail_com','message') | regex_replace(find='[^\x00-\x7F]+', replace='', ignorecase=False) | trim
           }] | rejectattr(""timestamp"", ""gt"", as_timestamp(utcnow()) | int + 24*60*60) | sort(attribute='timestamp') 
         %}
-        {% if calendars|length > 2 %}
+        {% if calendars|length >= 2 %}
         {{ calendars[2].prefix }} {{ calendars[2].data }}
         {% endif %}
 

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -98,7 +98,7 @@ data:
     | regex_replace(find='[^\\x00-\\x7F]+', replace='', ignorecase=False) | trim\n
     \         }] | rejectattr(\""timestamp\"", \""gt\"", as_timestamp(utcnow()) | int
     + 24*60*60) | sort(attribute='timestamp') \n        %}\n        {% if calendars|length
-    > 2 %}\n        {{ calendars[2].prefix }} {{ calendars[2].data }}\n        {%
+    >= 2 %}\n        {{ calendars[2].prefix }} {{ calendars[2].data }}\n        {%
     endif %}\n\ninput_boolean:\n  projector:\n    name: Projector State\n    icon:
     mdi:projector\n  projector_screen:\n    name: Projector Screen State\n    icon:
     mdi:projector-screen-variant-outline\n\ninput_select:\n  speakers:\n    name:

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: 0fec4193f5a149309173c1b7396703e0
+        checksum.config/md5: c032a98586dab6cc1b50edfe9cfbaf6f
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,4f94c2e5ef885665dadf2082bef137b82d09fe50,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-23T06:33:04Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-23T06:33:04Z,apps/homeassistant: quick fix for alert rule,apps/homeassistant/manifests/timescaledb/prometheusRule.yaml,False,False,False,False,2,2,4,"---FILE: apps/homeassistant/manifests/timescaledb/prometheusRule.yaml---
@@ -73,8 +73,8 @@ spec:
         summary: 'PostgreSQL high number of slow on {{ $labels.cluster }} for database
           {{ $labels.datname }} '
       expr: |
-        avg(
-          rate by (datname) (
+        avg by (datname) (
+          rate (
             pg_stat_activity_max_tx_duration{datname!~""template.*"",job=""timescaledb""}[2m]
           )
         ) > 2 * 60"
thaum-xyz,ankhmorpork,24bcfd4e6d5b20d9acfc8e007c1dcc7483e232f9,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-22T15:25:30Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-22T15:25:30Z,base/flux-system: fix ingress,base/flux-system/jsonnet/main.jsonnet;base/flux-system/manifests/configs/ingress.yaml,False,False,False,False,8,8,16,"---FILE: base/flux-system/jsonnet/main.jsonnet---
@@ -56,10 +56,10 @@ local all = {
             pathType: 'Prefix',
           }],
         },
-        tls: [{
-          hosts: ['flux.ankhmorpork.thaum.xyz'],
-          secretName: 'flux-tls',
-        }],
+      }],
+      tls: [{
+        hosts: ['flux.ankhmorpork.thaum.xyz'],
+        secretName: 'flux-tls',
       }],
     },
   },

---FILE: base/flux-system/manifests/configs/ingress.yaml---
@@ -22,7 +22,7 @@ spec:
               name: http
         path: /
         pathType: Prefix
-    tls:
-    - hosts:
-      - flux.ankhmorpork.thaum.xyz
-      secretName: flux-tls
+  tls:
+  - hosts:
+    - flux.ankhmorpork.thaum.xyz
+    secretName: flux-tls"
thaum-xyz,ankhmorpork,d5a959ea895b7ab338ffaa0b851711868500d226,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-22T15:19:18Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-22T15:19:18Z,base/flux-system: fix ingress,base/flux-system/jsonnet/main.jsonnet;base/flux-system/manifests/configs/ingress.yaml,False,False,False,False,9,9,18,"---FILE: base/flux-system/jsonnet/main.jsonnet---
@@ -14,7 +14,7 @@ local all = {
     apiVersion: 'networking.k8s.io/v1',
     kind: 'NetworkPolicy',
     metadata: $._metadata {
-      name: ""allow-cert-manager"",
+      name: 'allow-cert-manager',
     },
     spec: {
       ingress: [{
@@ -55,11 +55,11 @@ local all = {
             path: '/',
             pathType: 'Prefix',
           }],
-          tls: [{
-            hosts: ['flux.ankhmorpork.thaum.xyz'],
-            secretName: 'flux-tls',
-          }],
         },
+        tls: [{
+          hosts: ['flux.ankhmorpork.thaum.xyz'],
+          secretName: 'flux-tls',
+        }],
       }],
     },
   },

---FILE: base/flux-system/manifests/configs/ingress.yaml---
@@ -22,7 +22,7 @@ spec:
               name: http
         path: /
         pathType: Prefix
-      tls:
-      - hosts:
-        - flux.ankhmorpork.thaum.xyz
-        secretName: flux-tls
+    tls:
+    - hosts:
+      - flux.ankhmorpork.thaum.xyz
+      secretName: flux-tls"
thaum-xyz,ankhmorpork,07573c7efee7bc5975498023aababba8f5ca6c61,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-22T15:14:30Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-22T15:14:30Z,base/flux-system: fix Secret name,base/flux-system/jsonnet/main.jsonnet;base/flux-system/manifests/configs/slackAddress.yaml,False,False,False,False,3,3,6,"---FILE: base/flux-system/jsonnet/main.jsonnet---
@@ -147,7 +147,7 @@ local all = {
   ),
   slackAddress: sealedsecret(
     {
-      name: 'SealedSecret',
+      name: 'slack-url',
       namespace: $._metadata.namespace,
     },
     {

---FILE: base/flux-system/manifests/configs/slackAddress.yaml---
@@ -2,7 +2,7 @@ apiVersion: bitnami.com/v1alpha1
 kind: SealedSecret
 metadata:
   creationTimestamp: null
-  name: SealedSecret
+  name: slack-url
   namespace: flux-system
 spec:
   encryptedData:
@@ -12,5 +12,5 @@ spec:
       annotations:
         sealedsecrets.bitnami.com/managed: ""true""
       creationTimestamp: null
-      name: SealedSecret
+      name: slack-url
       namespace: flux-system"
thaum-xyz,ankhmorpork,324d8d946e3bcf0b43421262b20042a8c6210a65,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-22T14:12:22Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-22T14:12:22Z,base/sealed-secrets: fix image after upstream removed quay repo,base/kube-system/manifests/sealed-secrets/controller.yaml,False,False,False,False,1,1,2,"---FILE: base/kube-system/manifests/sealed-secrets/controller.yaml---
@@ -251,7 +251,7 @@ spec:
         command:
         - controller
         env: []
-        image: quay.io/bitnami/sealed-secrets-controller:v0.16.0
+        image: bitnami/sealed-secrets-controller:v0.16.0
         imagePullPolicy: Always
         livenessProbe:
           httpGet:"
thaum-xyz,ankhmorpork,92eb012cd20ef5bacfb62210c4c0f4d80c951a93,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-11T15:49:27Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-11T15:49:27Z,apps/homeassistant: fix incorrect reference to one calendar,apps/homeassistant/config/configuration.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,19,19,38,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -154,9 +154,9 @@ template:
             ""prefix"": as_timestamp(state_attr('calendar.pawel_timescale_com','start_time')) | int | timestamp_custom(""%H:%M""),
             ""data"": state_attr('calendar.pawel_timescale_com','message') | regex_replace(find='[^\x00-\x7F]+', replace='', ignorecase=False) | trim
           },{
-            ""timestamp"": as_timestamp(state_attr('calendar.paulfantom_gmail_com','start_time')) | int,
-            ""prefix"": as_timestamp(state_attr('calendar.paulfantom_gmail_com','start_time')) | int | timestamp_custom(""%H:%M""),
-            ""data"": state_attr('calendar.paulfantom_gmail_com','message') | regex_replace(find='[^\x00-\x7F]+', replace='', ignorecase=False) | trim
+            ""timestamp"": as_timestamp(state_attr('calendar.paulfantom','start_time')) | int,
+            ""prefix"": as_timestamp(state_attr('calendar.paulfantom','start_time')) | int | timestamp_custom(""%H:%M""),
+            ""data"": state_attr('calendar.paulfantom','message') | regex_replace(find='[^\x00-\x7F]+', replace='', ignorecase=False) | trim
           },{
             ""timestamp"": as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time')) | int,
             ""prefix"": as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time')) | int | timestamp_custom(""%H:%M""),
@@ -175,9 +175,9 @@ template:
             ""prefix"": as_timestamp(state_attr('calendar.pawel_timescale_com','start_time')) | int | timestamp_custom(""%H:%M""),
             ""data"": state_attr('calendar.pawel_timescale_com','message') | regex_replace(find='[^\x00-\x7F]+', replace='', ignorecase=False) | trim
           },{
-            ""timestamp"": as_timestamp(state_attr('calendar.paulfantom_gmail_com','start_time')) | int,
-            ""prefix"": as_timestamp(state_attr('calendar.paulfantom_gmail_com','start_time')) | int | timestamp_custom(""%H:%M""),
-            ""data"": state_attr('calendar.paulfantom_gmail_com','message') | regex_replace(find='[^\x00-\x7F]+', replace='', ignorecase=False) | trim
+            ""timestamp"": as_timestamp(state_attr('calendar.paulfantom','start_time')) | int,
+            ""prefix"": as_timestamp(state_attr('calendar.paulfantom','start_time')) | int | timestamp_custom(""%H:%M""),
+            ""data"": state_attr('calendar.paulfantom','message') | regex_replace(find='[^\x00-\x7F]+', replace='', ignorecase=False) | trim
           },{
             ""timestamp"": as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time')) | int,
             ""prefix"": as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time')) | int | timestamp_custom(""%H:%M""),
@@ -196,9 +196,9 @@ template:
             ""prefix"": as_timestamp(state_attr('calendar.pawel_timescale_com','start_time')) | int | timestamp_custom(""%H:%M""),
             ""data"": state_attr('calendar.pawel_timescale_com','message') | regex_replace(find='[^\x00-\x7F]+', replace='', ignorecase=False) | trim
           },{
-            ""timestamp"": as_timestamp(state_attr('calendar.paulfantom_gmail_com','start_time')) | int,
-            ""prefix"": as_timestamp(state_attr('calendar.paulfantom_gmail_com','start_time')) | int | timestamp_custom(""%H:%M""),
-            ""data"": state_attr('calendar.paulfantom_gmail_com','message') | regex_replace(find='[^\x00-\x7F]+', replace='', ignorecase=False) | trim
+            ""timestamp"": as_timestamp(state_attr('calendar.paulfantom','start_time')) | int,
+            ""prefix"": as_timestamp(state_attr('calendar.paulfantom','start_time')) | int | timestamp_custom(""%H:%M""),
+            ""data"": state_attr('calendar.paulfantom','message') | regex_replace(find='[^\x00-\x7F]+', replace='', ignorecase=False) | trim
           },{
             ""timestamp"": as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time')) | int,
             ""prefix"": as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time')) | int | timestamp_custom(""%H:%M""),

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -45,9 +45,9 @@ data:
     | int,\n            \""prefix\"": as_timestamp(state_attr('calendar.pawel_timescale_com','start_time'))
     | int | timestamp_custom(\""%H:%M\""),\n            \""data\"": state_attr('calendar.pawel_timescale_com','message')
     | regex_replace(find='[^\\x00-\\x7F]+', replace='', ignorecase=False) | trim\n
-    \         },{\n            \""timestamp\"": as_timestamp(state_attr('calendar.paulfantom_gmail_com','start_time'))
-    | int,\n            \""prefix\"": as_timestamp(state_attr('calendar.paulfantom_gmail_com','start_time'))
-    | int | timestamp_custom(\""%H:%M\""),\n            \""data\"": state_attr('calendar.paulfantom_gmail_com','message')
+    \         },{\n            \""timestamp\"": as_timestamp(state_attr('calendar.paulfantom','start_time'))
+    | int,\n            \""prefix\"": as_timestamp(state_attr('calendar.paulfantom','start_time'))
+    | int | timestamp_custom(\""%H:%M\""),\n            \""data\"": state_attr('calendar.paulfantom','message')
     | regex_replace(find='[^\\x00-\\x7F]+', replace='', ignorecase=False) | trim\n
     \         },{\n            \""timestamp\"": as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time'))
     | int,\n            \""prefix\"": as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time'))
@@ -64,9 +64,9 @@ data:
     | int,\n            \""prefix\"": as_timestamp(state_attr('calendar.pawel_timescale_com','start_time'))
     | int | timestamp_custom(\""%H:%M\""),\n            \""data\"": state_attr('calendar.pawel_timescale_com','message')
     | regex_replace(find='[^\\x00-\\x7F]+', replace='', ignorecase=False) | trim\n
-    \         },{\n            \""timestamp\"": as_timestamp(state_attr('calendar.paulfantom_gmail_com','start_time'))
-    | int,\n            \""prefix\"": as_timestamp(state_attr('calendar.paulfantom_gmail_com','start_time'))
-    | int | timestamp_custom(\""%H:%M\""),\n            \""data\"": state_attr('calendar.paulfantom_gmail_com','message')
+    \         },{\n            \""timestamp\"": as_timestamp(state_attr('calendar.paulfantom','start_time'))
+    | int,\n            \""prefix\"": as_timestamp(state_attr('calendar.paulfantom','start_time'))
+    | int | timestamp_custom(\""%H:%M\""),\n            \""data\"": state_attr('calendar.paulfantom','message')
     | regex_replace(find='[^\\x00-\\x7F]+', replace='', ignorecase=False) | trim\n
     \         },{\n            \""timestamp\"": as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time'))
     | int,\n            \""prefix\"": as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time'))
@@ -83,9 +83,9 @@ data:
     | int,\n            \""prefix\"": as_timestamp(state_attr('calendar.pawel_timescale_com','start_time'))
     | int | timestamp_custom(\""%H:%M\""),\n            \""data\"": state_attr('calendar.pawel_timescale_com','message')
     | regex_replace(find='[^\\x00-\\x7F]+', replace='', ignorecase=False) | trim\n
-    \         },{\n            \""timestamp\"": as_timestamp(state_attr('calendar.paulfantom_gmail_com','start_time'))
-    | int,\n            \""prefix\"": as_timestamp(state_attr('calendar.paulfantom_gmail_com','start_time'))
-    | int | timestamp_custom(\""%H:%M\""),\n            \""data\"": state_attr('calendar.paulfantom_gmail_com','message')
+    \         },{\n            \""timestamp\"": as_timestamp(state_attr('calendar.paulfantom','start_time'))
+    | int,\n            \""prefix\"": as_timestamp(state_attr('calendar.paulfantom','start_time'))
+    | int | timestamp_custom(\""%H:%M\""),\n            \""data\"": state_attr('calendar.paulfantom','message')
     | regex_replace(find='[^\\x00-\\x7F]+', replace='', ignorecase=False) | trim\n
     \         },{\n            \""timestamp\"": as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time'))
     | int,\n            \""prefix\"": as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time'))

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: 5bf56d72fb771498cca1b7b0e25135fb
+        checksum.config/md5: 7db18fab544e905357f16eb22c59898a
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,b362d49d968f354e79505a521dbf8d128fe7c254,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-10T13:04:13Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-10T13:04:13Z,apps/homeassistant: fix setting exporter variables,apps/homeassistant/jsonnet/timescaledb.libsonnet;apps/homeassistant/manifests/timescaledb/statefulSet.yaml,False,False,False,False,4,4,8,"---FILE: apps/homeassistant/jsonnet/timescaledb.libsonnet---
@@ -134,10 +134,10 @@ function(params) {
           value: ""127.0.0.1?sslmode=disable"",
         },{
           name: ""DATA_SOURCE_USER"",
-          value: ""${POSTGRES_USER}"",
+          value: ""$(POSTGRES_USER)"",
         },{
           name: ""DATA_SOURCE_PASS"",
-          value: ""${POSTGRES_PASSWORD}"",
+          value: ""$(POSTGRES_PASSWORD)"",
         },{
           name: ""PG_EXPORTER_AUTO_DISCOVER_DATABASES"",
           value: ""true"",

---FILE: apps/homeassistant/manifests/timescaledb/statefulSet.yaml---
@@ -58,9 +58,9 @@ spec:
         - name: DATA_SOURCE_URI
           value: 127.0.0.1?sslmode=disable
         - name: DATA_SOURCE_USER
-          value: ${POSTGRES_USER}
+          value: $(POSTGRES_USER)
         - name: DATA_SOURCE_PASS
-          value: ${POSTGRES_PASSWORD}
+          value: $(POSTGRES_PASSWORD)
         - name: PG_EXPORTER_AUTO_DISCOVER_DATABASES
           value: ""true""
         envFrom:"
thaum-xyz,ankhmorpork,2fb41711a4d7f1420953f47bddcb9b7195eec1c3,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-10T12:59:14Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-10T12:59:14Z,apps/homeassistant: fix typo,apps/homeassistant/jsonnet/timescaledb.libsonnet;apps/homeassistant/manifests/timescaledb/statefulSet.yaml,False,False,False,False,2,2,4,"---FILE: apps/homeassistant/jsonnet/timescaledb.libsonnet---
@@ -131,7 +131,7 @@ function(params) {
       env: [
         {
           name: ""DATA_SOURCE_URI"",
-          value: ""127.0.0.1?sslmode=disabled"",
+          value: ""127.0.0.1?sslmode=disable"",
         },{
           name: ""DATA_SOURCE_USER"",
           value: ""${POSTGRES_USER}"",

---FILE: apps/homeassistant/manifests/timescaledb/statefulSet.yaml---
@@ -56,7 +56,7 @@ spec:
           name: timescaledb-data
       - env:
         - name: DATA_SOURCE_URI
-          value: 127.0.0.1?sslmode=disabled
+          value: 127.0.0.1?sslmode=disable
         - name: DATA_SOURCE_USER
           value: ${POSTGRES_USER}
         - name: DATA_SOURCE_PASS"
thaum-xyz,ankhmorpork,f67fc5d134a6a594a185511396620be28aa6630f,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-10T12:55:30Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-10T12:55:30Z,apps/homeassistant: fix error connecting to DB,apps/homeassistant/jsonnet/timescaledb.libsonnet;apps/homeassistant/manifests/timescaledb/statefulSet.yaml,False,False,False,False,2,2,4,"---FILE: apps/homeassistant/jsonnet/timescaledb.libsonnet---
@@ -131,7 +131,7 @@ function(params) {
       env: [
         {
           name: ""DATA_SOURCE_URI"",
-          value: ""127.0.0.1"",
+          value: ""127.0.0.1?sslmode=disabled"",
         },{
           name: ""DATA_SOURCE_USER"",
           value: ""${POSTGRES_USER}"",

---FILE: apps/homeassistant/manifests/timescaledb/statefulSet.yaml---
@@ -56,7 +56,7 @@ spec:
           name: timescaledb-data
       - env:
         - name: DATA_SOURCE_URI
-          value: 127.0.0.1
+          value: 127.0.0.1?sslmode=disabled
         - name: DATA_SOURCE_USER
           value: ${POSTGRES_USER}
         - name: DATA_SOURCE_PASS"
thaum-xyz,ankhmorpork,8b62ecb95325657edd01b0a5672d055944c9c4dd,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-10T12:32:31Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-10T12:32:31Z,*: fix image architecture compatibility detection,.ignoredimages,False,False,False,False,2,0,2,"---FILE: .ignoredimages---
@@ -16,3 +16,5 @@ ghcr.io/parca-dev/parca
 lloesche/valheim-server
 lscr.io/linuxserver/sonarr
 lscr.io/linuxserver/radarr
+ghcr.io/pyrra-dev/pyrra
+grafana/mimir"
thaum-xyz,ankhmorpork,23c84ff183f3b225d96fc998bcc365ae6e2f7f69,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-10T11:54:49Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-10T11:54:49Z,apps/monitoring: fix resource settings for pyrra,apps/monitoring/config.jsonnet;apps/monitoring/jsonnet/main.jsonnet;apps/monitoring/manifests/pyrra/apiDeployment.yaml;apps/monitoring/manifests/pyrra/kubernetesDeployment.yaml,False,False,False,False,13,31,44,"---FILE: apps/monitoring/config.jsonnet---
@@ -141,15 +141,15 @@
       },
     },
   },
-  //pyrra+: {
-  //  version: """",
-  //  image: """",
-  //  namespace: ""monitoring"",
-  //  resources: {
-  //    requests: { cpu: '100m', memory: '20Mi' },
-  //    limits: { cpu: '100m', memory: '30Mi' },
-  //  },
-  //},
+  pyrra+: {
+    #version: """",
+    #image: """",
+    #namespace: ""monitoring"",
+    resources: {
+      requests: { cpu: '100m', memory: '20Mi' },
+      limits: { cpu: '100m', memory: '30Mi' },
+    },
+  },
   grafana+: {
     version: '8.2.1',
     image: 'grafana/grafana:8.2.1',

---FILE: apps/monitoring/jsonnet/main.jsonnet---
@@ -366,16 +366,7 @@ local kp =
             spec+: {
               containers: addContainerParameter(
                 'resources',
-                {
-                  requests: {
-                    cpu: '100m',
-                    memory: '20Mi',
-                  },
-                  limits: {
-                    cpu: '100Mi',
-                    memory: '30Mi',
-                  },
-                },
+                $.values.pyrra.resources,
                 'pyrra',
                 super.containers
               ),
@@ -392,16 +383,7 @@ local kp =
             spec+: {
               containers: addContainerParameter(
                 'resources',
-                {
-                  requests: {
-                    cpu: '100m',
-                    memory: '20Mi',
-                  },
-                  limits: {
-                    cpu: '100Mi',
-                    memory: '30Mi',
-                  },
-                },
+                $.values.pyrra.resources,
                 'pyrra',
                 super.containers
               ),

---FILE: apps/monitoring/manifests/pyrra/apiDeployment.yaml---
@@ -38,7 +38,7 @@ spec:
         - containerPort: 9099
         resources:
           limits:
-            cpu: 100Mi
+            cpu: 100m
             memory: 30Mi
           requests:
             cpu: 100m

---FILE: apps/monitoring/manifests/pyrra/kubernetesDeployment.yaml---
@@ -36,7 +36,7 @@ spec:
         - containerPort: 9099
         resources:
           limits:
-            cpu: 100Mi
+            cpu: 100m
             memory: 30Mi
           requests:
             cpu: 100m"
thaum-xyz,ankhmorpork,8de6df36035694796f2947d2292fce77a2f98f16,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-10T11:30:06Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-04-10T11:30:06Z,apps/monitoring: preparing for testing https://github.com/prometheus-operator/kube-prometheus/issues/1718,apps/monitoring/config.jsonnet;apps/monitoring/jsonnet/main.jsonnet;apps/monitoring/manifests/pyrra/apiDeployment.yaml;apps/monitoring/manifests/pyrra/kubernetesDeployment.yaml,False,False,False,False,82,0,82,"---FILE: apps/monitoring/config.jsonnet---
@@ -145,6 +145,10 @@
   #  version: """",
   #  image: """",
   #  namespace: ""monitoring"",
+  #  resources: {
+  #    requests: { cpu: '100m', memory: '20Mi' },
+  #    limits: { cpu: '100m', memory: '30Mi' },
+  #  },
   #},
   grafana+: {
     version: '8.2.1',

---FILE: apps/monitoring/jsonnet/main.jsonnet---
@@ -70,6 +70,15 @@ local addArgs(args, name, containers) = std.map(
   containers,
 );
 
+local addContainerParameter(parameter, value, name, containers) = std.map(
+  function(c) if c.name == name then
+    c {
+      [parameter]+: value,
+    }
+    else c,
+    containers,
+);
+
 local probe(name, namespace, labels, module, targets) = {
   apiVersion: 'monitoring.coreos.com/v1',
   kind: 'Probe',
@@ -350,6 +359,59 @@ local kp =
           },
         },
       ),
+      # TODO: Remove this when https://github.com/prometheus-operator/kube-prometheus/issues/1718 is finished
+      apiDeployment+: {
+        spec+: {
+          template+: {
+            spec+: {
+              containers: addContainerParameter(
+                'resources', 
+                {
+                  requests: {
+                    cpu: '100m',
+                    memory: '20Mi',
+                  },
+                  limits: {
+                    cpu: '100Mi',
+                    memory: '30Mi',
+                  }
+                },
+                'pyrra',
+                super.containers
+              ),
+              nodeSelector+: {
+                ""kubernetes.io/arch"": ""amd64"",
+              },
+            },
+          },
+        },
+      },
+      kubernetesDeployment+: {
+        spec+: {
+          template+: {
+            spec+: {
+              containers: addContainerParameter(
+                'resources', 
+                {
+                  requests: {
+                    cpu: '100m',
+                    memory: '20Mi',
+                  },
+                  limits: {
+                    cpu: '100Mi',
+                    memory: '30Mi',
+                  }
+                },
+                'pyrra',
+                super.containers
+              ),
+              nodeSelector+: {
+                ""kubernetes.io/arch"": ""amd64"",
+              },
+            },
+          },
+        },
+      },
     },
 
     grafana+: {

---FILE: apps/monitoring/manifests/pyrra/apiDeployment.yaml---
@@ -36,8 +36,16 @@ spec:
         name: pyrra
         ports:
         - containerPort: 9099
+        resources:
+          limits:
+            cpu: 100Mi
+            memory: 30Mi
+          requests:
+            cpu: 100m
+            memory: 20Mi
         securityContext:
           allowPrivilegeEscalation: false
           readOnlyRootFilesystem: true
       nodeSelector:
+        kubernetes.io/arch: amd64
         kubernetes.io/os: linux

---FILE: apps/monitoring/manifests/pyrra/kubernetesDeployment.yaml---
@@ -34,9 +34,17 @@ spec:
         name: pyrra
         ports:
         - containerPort: 9099
+        resources:
+          limits:
+            cpu: 100Mi
+            memory: 30Mi
+          requests:
+            cpu: 100m
+            memory: 20Mi
         securityContext:
           allowPrivilegeEscalation: false
           readOnlyRootFilesystem: true
       nodeSelector:
+        kubernetes.io/arch: amd64
         kubernetes.io/os: linux
       serviceAccountName: pyrra-kubernetes"
thaum-xyz,ankhmorpork,eb68e11d69cc70cf38c91dede160575c1716c510,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-03-22T15:10:02Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-03-22T15:10:02Z,apps/homeassistant: fix next meeting time sensor,apps/homeassistant/config/configuration.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,3,3,6,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -131,7 +131,7 @@ template:
       {% set timescale = as_timestamp(state_attr('calendar.pawel_timescale_com','start_time')) | int %}
       {% set paulfantom =  as_timestamp(state_attr('calendar.paulfantom','start_time')) | int %}
       {% set krupa = as_timestamp(state_attr('calendar.pawel_krupa_net_pl','start_time')) | int %}
-      {% set adrianna = as_timestamp(state_attr('calendar.iadrianna_wojas_gmail_com','start_time')) | int %}
+      {% set adrianna = as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time')) | int %}
       {% set sunrise = as_timestamp(state_attr('sun.sun','next_rising')) | int %}
       {% set now = as_timestamp(utcnow()) | int %}
       {% set next = sunrise %}

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -134,7 +134,7 @@ data:
           {% set timescale = as_timestamp(state_attr('calendar.pawel_timescale_com','start_time')) | int %}
           {% set paulfantom =  as_timestamp(state_attr('calendar.paulfantom','start_time')) | int %}
           {% set krupa = as_timestamp(state_attr('calendar.pawel_krupa_net_pl','start_time')) | int %}
-          {% set adrianna = as_timestamp(state_attr('calendar.iadrianna_wojas_gmail_com','start_time')) | int %}
+          {% set adrianna = as_timestamp(state_attr('calendar.adrianna_wojas_gmail_com','start_time')) | int %}
           {% set sunrise = as_timestamp(state_attr('sun.sun','next_rising')) | int %}
           {% set now = as_timestamp(utcnow()) | int %}
           {% set next = sunrise %}

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: 516abe5d95d65d8405cb6fa33729c423
+        checksum.config/md5: e9ffb286e3fd761cd9c51ec22fac8ee1
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,d7eb847b4ca45221042448c42c9dd322ab889ea1,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-03-01T22:29:53Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-03-01T22:29:53Z,apps/homeassistant: fix mealie sensor,apps/homeassistant/config/configuration.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,3,3,6,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -114,7 +114,7 @@ sensor:
       authorization: !secret mealie_token
     resource: https://recipe.krupa.net.pl/api/meal-plans/today
     value_template: >
-      {% if value_json is None %}
+      {% if value_json is none %}
         No meal plan
       {% elif value_json.name %}
       {{   value_json.name }}

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -117,7 +117,7 @@ data:
           authorization: !secret mealie_token
         resource: https://recipe.krupa.net.pl/api/meal-plans/today
         value_template: >
-          {% if value_json is None %}
+          {% if value_json is none %}
             No meal plan
           {% elif value_json.name %}
           {{   value_json.name }}

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: a7acc4441dd41fa27a7774a21f124bc2
+        checksum.config/md5: 5f29d68c0b7081f3a30dd12f7318659f
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,db468aacea432f037ab0f9d1181f9d5ec76ecd30,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-02-01T21:55:59Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-02-01T21:55:59Z,apps/homeassistant: fix typo,apps/homeassistant/config/scripts.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,3,3,6,"---FILE: apps/homeassistant/config/scripts.yaml---
@@ -19,7 +19,7 @@ speakers_line1:
       hours: 0
       minutes: 0
       seconds: 2
-      miliseconds: 0
+      milliseconds: 0
   - service: remote.send_command
     data:
       entity_id: remote.broadlink

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -327,7 +327,7 @@ data:
     toggle\n      num_repeats: 2\n  mode: single\n  icon: mdi:projector\nspeakers_line1:\n
     \ sequence:\n  - service: remote.send_command\n    data:\n      entity_id: remote.broadlink\n
     \     device: speakers\n      command: \""opt/coax\""\n  - delay:\n      hours:
-    0\n      minutes: 0\n      seconds: 2\n      miliseconds: 0\n  - service: remote.send_command\n
+    0\n      minutes: 0\n      seconds: 2\n      milliseconds: 0\n  - service: remote.send_command\n
     \   data:\n      entity_id: remote.broadlink\n      device: speakers\n      command:
     \""line1/2\""\n  mode: single\n  icon: mdi:cast-audio \nalarm_picture_notification:\n
     \ alias: Alarm Picture Notification\n  sequence:\n  - service: camera.snapshot\n

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: 64de2bfd9829c149aae8a3cd5de9487f
+        checksum.config/md5: bdf5e07418b58d6ecf952c32a6c0de19
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,8eabb1d6514115eddacba331de48f2eae3cfb0cb,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-02-01T21:50:42Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-02-01T21:50:42Z,apps/homeassistant: fix line1 script,apps/homeassistant/config/scripts.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,7,7,14,"---FILE: apps/homeassistant/config/scripts.yaml---
@@ -14,17 +14,17 @@ speakers_line1:
     data:
       entity_id: remote.broadlink
       device: speakers
-      command: opt/coax
+      command: ""opt/coax""
   - delay:
       hours: 0
       minutes: 0
-      seconds: 1
+      seconds: 2
       miliseconds: 0
   - service: remote.send_command
     data:
       entity_id: remote.broadlink
       device: speakers
-      command: line1/2  
+      command: ""line1/2""
   mode: single
   icon: mdi:cast-audio 
 alarm_picture_notification:

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -326,10 +326,10 @@ data:
     \   data:\n      entity_id: remote.broadlink\n      device: nebula\n      command:
     toggle\n      num_repeats: 2\n  mode: single\n  icon: mdi:projector\nspeakers_line1:\n
     \ sequence:\n  - service: remote.send_command\n    data:\n      entity_id: remote.broadlink\n
-    \     device: speakers\n      command: opt/coax\n  - delay:\n      hours: 0\n
-    \     minutes: 0\n      seconds: 1\n      miliseconds: 0\n  - service: remote.send_command\n
+    \     device: speakers\n      command: \""opt/coax\""\n  - delay:\n      hours:
+    0\n      minutes: 0\n      seconds: 2\n      miliseconds: 0\n  - service: remote.send_command\n
     \   data:\n      entity_id: remote.broadlink\n      device: speakers\n      command:
-    line1/2  \n  mode: single\n  icon: mdi:cast-audio \nalarm_picture_notification:\n
+    \""line1/2\""\n  mode: single\n  icon: mdi:cast-audio \nalarm_picture_notification:\n
     \ alias: Alarm Picture Notification\n  sequence:\n  - service: camera.snapshot\n
     \   data:\n      entity_id: camera.spy\n      filename: /config/www/images/{{
     filename }}\n  - delay:\n      hours: 0\n      minutes: 0\n      seconds: 10\n

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: d68c2242472722ed6c1479561a379ce6
+        checksum.config/md5: 64de2bfd9829c149aae8a3cd5de9487f
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,357b161a5d1399115d16b7d242bad059a78925a2,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-01-27T23:19:04Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-01-27T23:19:04Z,hack: fix images check,.ignoredimages;hack/checkimages.sh,False,False,False,False,31,22,53,"---FILE: .ignoredimages---
@@ -0,0 +1,18 @@
+homeassistant/aarch64-homeassistant
+plexinc/pms-docker
+quay.io/paulfantom/plex_exporter
+metalmatze/transmission-exporter
+mariadb
+woolfg/mysql-backup-sidecar
+oliver006/redis_exporter
+hipages/php-fpm_exporter
+xperimental/nextcloud-exporter
+quay.io/prometheus/mysqld-exporter
+intel/intel-gpu-plugin
+nvidia/k8s-device-plugin
+foomo/pagespeed_exporter
+ghcr.io/parca-dev/parca-agent
+ghcr.io/parca-dev/parca
+lloesche/valheim-server
+lscr.io/linuxserver/sonarr
+lscr.io/linuxserver/radarr

---FILE: hack/checkimages.sh---
@@ -3,28 +3,6 @@
 set -euo pipefail
 
 CPU_ARCHS=""amd64 arm64""
-MULTI_ARCH_EXCLUDED=$(
-	cat <<EOM
-eu.gcr.io/k8s-artifacts-prod/descheduler/descheduler
-homeassistant/aarch64-homeassistant
-plexinc/pms-docker
-quay.io/paulfantom/plex_exporter
-metalmatze/transmission-exporter
-mariadb
-woolfg/mysql-backup-sidecar
-oliver006/redis_exporter
-hipages/php-fpm_exporter
-xperimental/nextcloud-exporter
-quay.io/prometheus/mysqld-exporter
-intel/intel-gpu-plugin
-nvidia/k8s-device-plugin
-foomo/pagespeed_exporter
-ghcr.io/parca-dev/parca-agent
-ghcr.io/parca-dev/parca
-quay.io/paulfantom/parca
-lloesche/valheim-server
-EOM
-)
 
 FAIL=""[ \e[1m\e[31mFAIL\e[0m ]""
 SKIP=""[ \e[1m\e[33mSKIP\e[0m ]""
@@ -49,9 +27,22 @@ check_cross_compatibility() {
 	fi
 }
 
+# Check if tools are available
+if ! command -v manifest-tool &>/dev/null; then
+	echo -e ""$FAIL 'manifest-tool' is not available""
+	exit 1
+fi
+
+if ! command -v gojsontoyaml &>/dev/null; then
+	echo -e ""$FAIL 'gojsontoyaml' is not available""
+	exit 1
+fi
+
 # Go to top-level
 cd ""$(git rev-parse --show-toplevel)""
 
+MULTI_ARCH_EXCLUDED=$(cat .ignoredimages)
+
 # Find all images used in environment
 DETECTED_IMAGES=""""
 for file in $(find apps/ base/ -name *.yaml -exec grep ""image"" -l {} \;); do"
thaum-xyz,ankhmorpork,bc279558a57bede854ab08adc84ff7de666fcbe7,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-01-27T19:33:06Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-01-27T19:33:06Z,apps/multimedia: fix backup restoration process,apps/multimedia/jsonnet/arr.libsonnet;apps/multimedia/manifests/radarr/statefulset.yaml;apps/multimedia/manifests/sonarr/statefulset.yaml,False,False,False,False,5,5,10,"---FILE: apps/multimedia/jsonnet/arr.libsonnet---
@@ -217,7 +217,7 @@ function(params) {
 
     local init = {
       command: ['/bin/sh'],
-      args: ['-c', ""cd /config && unzip $(find /backup -type f -exec stat -c '%n' {} + | sort -r | head -n1) && chown 1000:1000 /config/*""],
+      args: ['-c', ""cd /config && unzip $(find /backup -type f -exec stat --format '%Y :%y %n' {} + | sort -nr | head -n1 | cut -d' ' -f5) && chown 1000:1000 /config/*""],
       image: 'quay.io/paulfantom/rsync',
       name: 'restore',
       volumeMounts: [

---FILE: apps/multimedia/manifests/radarr/statefulset.yaml---
@@ -101,8 +101,8 @@ spec:
       initContainers:
       - args:
         - -c
-        - cd /config && unzip $(find /backup -type f -exec stat -c '%n' {} + | sort
-          -r | head -n1) && chown 1000:1000 /config/*
+        - cd /config && unzip $(find /backup -type f -exec stat --format '%Y :%y %n'
+          {} + | sort -nr | head -n1 | cut -d' ' -f5) && chown 1000:1000 /config/*
         command:
         - /bin/sh
         image: quay.io/paulfantom/rsync

---FILE: apps/multimedia/manifests/sonarr/statefulset.yaml---
@@ -101,8 +101,8 @@ spec:
       initContainers:
       - args:
         - -c
-        - cd /config && unzip $(find /backup -type f -exec stat -c '%n' {} + | sort
-          -r | head -n1) && chown 1000:1000 /config/*
+        - cd /config && unzip $(find /backup -type f -exec stat --format '%Y :%y %n'
+          {} + | sort -nr | head -n1 | cut -d' ' -f5) && chown 1000:1000 /config/*
         command:
         - /bin/sh
         image: quay.io/paulfantom/rsync"
thaum-xyz,ankhmorpork,8b9371db83970ff920267e9d38af87150bdd07b9,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-01-27T19:02:04Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-01-27T19:02:04Z,apps/multimedia: fix recovery from backup and include manual backups in discovery,apps/multimedia/jsonnet/arr.libsonnet;apps/multimedia/manifests/radarr/statefulset.yaml;apps/multimedia/manifests/sonarr/statefulset.yaml,False,False,False,False,5,5,10,"---FILE: apps/multimedia/jsonnet/arr.libsonnet---
@@ -217,7 +217,7 @@ function(params) {
 
     local init = {
       command: ['/bin/sh'],
-      args: ['-c', ""cd /config && unzip $(find /backup/scheduled -type f -exec stat -c '%n' {} + | sort -r | head -n1) && chown 1000:1000 /config/*""],
+      args: ['-c', ""cd /config && unzip $(find /backup -type f -exec stat -c '%n' {} + | sort -r | head -n1) && chown 1000:1000 /config/*""],
       image: 'quay.io/paulfantom/rsync',
       name: 'restore',
       volumeMounts: [

---FILE: apps/multimedia/manifests/radarr/statefulset.yaml---
@@ -101,8 +101,8 @@ spec:
       initContainers:
       - args:
         - -c
-        - cd /config && unzip $(find /backup/scheduled -type f -exec stat -c '%n'
-          {} + | sort -r | head -n1) && chown 1000:1000 /config/*
+        - cd /config && unzip $(find /backup -type f -exec stat -c '%n' {} + | sort
+          -r | head -n1) && chown 1000:1000 /config/*
         command:
         - /bin/sh
         image: quay.io/paulfantom/rsync

---FILE: apps/multimedia/manifests/sonarr/statefulset.yaml---
@@ -101,8 +101,8 @@ spec:
       initContainers:
       - args:
         - -c
-        - cd /config && unzip $(find /backup/scheduled -type f -exec stat -c '%n'
-          {} + | sort -r | head -n1) && chown 1000:1000 /config/*
+        - cd /config && unzip $(find /backup -type f -exec stat -c '%n' {} + | sort
+          -r | head -n1) && chown 1000:1000 /config/*
         command:
         - /bin/sh
         image: quay.io/paulfantom/rsync"
thaum-xyz,ankhmorpork,93ec72f4b7b63a7cac300e9a73ac6fb50f285b1d,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-01-27T11:53:33Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-01-27T11:53:33Z,apps/monitoring: exclude incorrect metrics coming from qnap,apps/monitoring/jsonnet/main.jsonnet;apps/monitoring/manifests/qnap/serviceMonitor.yaml,False,False,False,False,11,0,11,"---FILE: apps/monitoring/jsonnet/main.jsonnet---
@@ -578,6 +578,11 @@ local kp =
                 targetLabel: 'pod',
               },
             ],
+            metricRelabelings: [{
+              action: ""drop"",
+              regex: ""node_md_disks_required(md9|md13)"",
+              sourceLabels: [""__name__"", ""device""],
+            }],
           }],
           selector+: {
             matchLabels+: {

---FILE: apps/monitoring/manifests/qnap/serviceMonitor.yaml---
@@ -10,6 +10,12 @@ metadata:
 spec:
   endpoints:
   - interval: 15s
+    metricRelabelings:
+    - action: drop
+      regex: node_md_disks_required(md9|md13)
+      sourceLabels:
+      - __name__
+      - device
     port: http
     relabelings:
     - action: replace"
thaum-xyz,ankhmorpork,b0db63d07af89270d9ec5d12eaa40f65d6a6693c,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-01-27T10:41:04Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-01-27T10:41:04Z,apps/snmp: fix incorrect regex parse for volumeStatus,apps/snmp/generator.yml;apps/snmp/manifests/configmap.yaml;apps/snmp/manifests/deployment.yaml,False,False,False,False,6,5,11,"---FILE: apps/snmp/generator.yml---
@@ -64,12 +64,12 @@ modules:
           '':
             - regex: '0x476F6F64.*'  # Good
               value: 0
+            - regex: '0x5265616479.*' # Ready
+              value: 0
             - regex: '0x4572726F72.*' # Error
               value: -1
             - regex: '0x5761726E696E67.*' # Warning
               value: 1
-            - regex: '0x5265616479.*' # Ready
-              value: 0
             - regex: '.*' # Unk
               value: 2
 

---FILE: apps/snmp/manifests/configmap.yaml---
@@ -256,6 +256,8 @@ data:
           """":
           - value: ""0""
             regex: ^(?:0x476F6F64.*)$
+          - value: ""0""
+            regex: ^(?:0x5265616479.*)$
           - value: ""-1""
             regex: ^(?:0x4572726F72.*)$
           - value: ""1""

---FILE: apps/snmp/manifests/deployment.yaml---
@@ -8,15 +8,15 @@ metadata:
   name: snmp-exporter
   namespace: snmp
 spec:
-  replicas: 1
+  replicas: 2
   selector:
     matchLabels:
       app.kubernetes.io/component: exporter
       app.kubernetes.io/name: snmp-exporter
   template:
     metadata:
       annotations:
-        checksum.config/md5: 774d623dc58c2bef56cdfcaafc160db7
+        checksum.config/md5: 6e4abe83bc74bd847bfddfd9a292624e
       labels:
         app.kubernetes.io/component: exporter
         app.kubernetes.io/name: snmp-exporter
@@ -25,7 +25,6 @@ spec:
       containers:
       - args:
         - --config.file=/config/snmp.yaml
-        - --log.level=debug
         image: quay.io/prometheus/snmp-exporter:v0.20.0
         imagePullPolicy: IfNotPresent
         livenessProbe:"
thaum-xyz,ankhmorpork,095a8aeb0a27b859e1b9e46e5c867200050cadf7,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-01-27T10:28:41Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-01-27T10:28:41Z,apps/homeassistant: fix previous fix,apps/homeassistant/config/configuration.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,3,3,6,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -154,7 +154,7 @@ sensor:
       {% elif value_json.details %}
       {{   value_json.details }}
       {% else %}
-        ""unknown issue""
+        ""unknown""
       {% endif %}
 
 template:

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -157,7 +157,7 @@ data:
           {% elif value_json.details %}
           {{   value_json.details }}
           {% else %}
-            ""unknown issue""
+            ""unknown""
           {% endif %}
 
     template:

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: e1706f2a74dd3ae11ded7a0cb0372b64
+        checksum.config/md5: 100e9affc0a7ad66bf5c123e42d9ae7e
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,f8e10a5b0e51c98c9bce19c3246cd984c7a4ba12,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-01-27T10:21:50Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-01-27T10:21:50Z,apps/homeassistant: error handling for mealie responses,apps/homeassistant/config/configuration.yaml;apps/homeassistant/manifests/homeassistant/configs.yaml;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,17,3,20,"---FILE: apps/homeassistant/config/configuration.yaml---
@@ -148,7 +148,14 @@ sensor:
       content-type: application/json
       authorization: !secret mealie_token
     resource: https://recipe.krupa.net.pl/api/meal-plans/today
-    value_template: ""{{ value_json.name }}""
+    value_template: >
+      {% if value_json.name %}
+      {{   value_json.name }}
+      {% elif value_json.details %}
+      {{   value_json.details }}
+      {% else %}
+        ""unknown issue""
+      {% endif %}
 
 template:
 - sensor:

---FILE: apps/homeassistant/manifests/homeassistant/configs.yaml---
@@ -151,7 +151,14 @@ data:
           content-type: application/json
           authorization: !secret mealie_token
         resource: https://recipe.krupa.net.pl/api/meal-plans/today
-        value_template: ""{{ value_json.name }}""
+        value_template: >
+          {% if value_json.name %}
+          {{   value_json.name }}
+          {% elif value_json.details %}
+          {{   value_json.details }}
+          {% else %}
+            ""unknown issue""
+          {% endif %}
 
     template:
     - sensor:

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -19,7 +19,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: 9b6c54c097d94cc04a8b139276b35a13
+        checksum.config/md5: e1706f2a74dd3ae11ded7a0cb0372b64
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homeassistant"
thaum-xyz,ankhmorpork,6c9b6b232e206e9fe4884a87236b7103658d6f4c,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-01-27T09:49:39Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-01-27T09:49:39Z,apps/snmp: debug incorrect parsing of volumeStatus metric,apps/snmp/generator.yml;apps/snmp/manifests/deployment.yaml,False,False,False,False,4,1,5,"---FILE: apps/snmp/generator.yml---
@@ -68,6 +68,8 @@ modules:
               value: -1
             - regex: '0x5761726E696E67.*' # Warning
               value: 1
+            - regex: '0x5265616479.*' # Ready
+              value: 0
             - regex: '.*' # Unk
               value: 2
 

---FILE: apps/snmp/manifests/deployment.yaml---
@@ -8,7 +8,7 @@ metadata:
   name: snmp-exporter
   namespace: snmp
 spec:
-  replicas: 2
+  replicas: 1
   selector:
     matchLabels:
       app.kubernetes.io/component: exporter
@@ -25,6 +25,7 @@ spec:
       containers:
       - args:
         - --config.file=/config/snmp.yaml
+        - --log.level=debug
         image: quay.io/prometheus/snmp-exporter:v0.20.0
         imagePullPolicy: IfNotPresent
         livenessProbe:"
thaum-xyz,ankhmorpork,c46fa49791a4146d527955b76baf332ec53a1d82,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-01-26T13:03:51Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-01-26T13:03:51Z,apps/snmp: fix value parsing,apps/snmp/generator.yml;apps/snmp/manifests/configmap.yaml;apps/snmp/manifests/deployment.yaml,False,False,False,False,26,25,51,"---FILE: apps/snmp/generator.yml---
@@ -42,27 +42,28 @@ modules:
       - diskTemperture
       - enclosureSystemTemp
       - sysFanSpeedEX # TODO: consider removing
-    overrides: # 0 is critical, 1 is normal, 0< is abnormal
+    overrides:
+    # Values: -1 is critical, 0 is normal, >0 is abnormal
       raidStatus:
         regex_extracts:
           '':
-            - regex: 'Ready'
-              value: 1
-            - regex: 'Degraded'
-              value: 0
-            - regex: 'Rebuilding.*'
+            - regex: '0x4465677261646564.*' # Degraded
               value: -1
-            - regex: 'Migrating.*'
-              value: -2
+            - regex: '0x5265616479.*' # Ready
+              value: 0
+            - regex: '0x52656275696C64696E67.*' # Rebuilding
+              value: 1
+            - regex: '0x4D6967726174696E67.*' # Migrating
+              value: 2
       volumeStatus:
         regex_extracts:
           '':
-            - regex: 'Good'
-              value: 1
-            - regex: 'Error'
+            - regex: '0x476F6F64.*'  # Good
               value: 0
-            - regex: 'Warning.*'
+            - regex: '0x4572726F72.*' # Error
               value: -1
+            - regex: '0x5761726E696E67.*' # Warning
+              value: 1
 
 # Additional objects that were checked before but are not used:
 # - raidCapacity  # storagepoolCapacity and volumeCapacity are more important
@@ -73,7 +74,7 @@ modules:
 # - lunCapacity # FIXME: no luns at the moment
 # - lunUsedPercent # FIXME: no luns at the moment
 # - lunStatus # FIXME: This is a string and needs overrides
-# - lunBackupStatus # FIXME: This is a string and needs overrides
+# - lunBackupStatus # FIXME: This is a string and needs overrides. Values: (0) none, (1) backup, (2) restore, (3) snapshot
 # - diskStatus  # FIXME: This needs overrides, but it doesn't look useful when all disks are in RAID groups
 # - diskCapacity # Not needded as all disks are in RAID groups
 # - hdTemperatureEX  # same as diskTemperture

---FILE: apps/snmp/manifests/configmap.yaml---
@@ -192,14 +192,14 @@ data:
           type: gauge
         regex_extracts:
           """":
-          - value: ""1""
-            regex: ^(?:Ready)$
-          - value: ""0""
-            regex: ^(?:Degraded)$
           - value: ""-1""
-            regex: ^(?:Rebuilding.*)$
-          - value: ""-2""
-            regex: ^(?:Migrating.*)$
+            regex: ^(?:0x4465677261646564.*)$
+          - value: ""0""
+            regex: ^(?:0x5265616479.*)$
+          - value: ""1""
+            regex: ^(?:0x52656275696C64696E67.*)$
+          - value: ""2""
+            regex: ^(?:0x4D6967726174696E67.*)$
       - name: storagepoolCapacity
         oid: 1.3.6.1.4.1.55062.1.10.7.1.3
         type: counter
@@ -251,12 +251,12 @@ data:
           type: gauge
         regex_extracts:
           """":
-          - value: ""1""
-            regex: ^(?:Good)$
           - value: ""0""
-            regex: ^(?:Error)$
+            regex: ^(?:0x476F6F64.*)$
           - value: ""-1""
-            regex: ^(?:Warning.*)$
+            regex: ^(?:0x4572726F72.*)$
+          - value: ""1""
+            regex: ^(?:0x5761726E696E67.*)$
 kind: ConfigMap
 metadata:
   labels:

---FILE: apps/snmp/manifests/deployment.yaml---
@@ -16,7 +16,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: a0002c163f5ae3d956bcf99d385d20c9
+        checksum.config/md5: 84c3d09f56b5ad3d7645022fd21a4ad2
       labels:
         app.kubernetes.io/component: exporter
         app.kubernetes.io/name: snmp-exporter"
thaum-xyz,ankhmorpork,cbbc54e73c82541bb2414b3c44cd462adf3a85bd,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-01-21T17:19:45Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-01-21T17:19:45Z,base/metallb-system: fix affinity rule,base/metallb-system/metallb.yaml,False,False,False,False,5,3,8,"---FILE: base/metallb-system/metallb.yaml---
@@ -423,11 +423,13 @@ spec:
       affinity:
         nodeAffinity:
           preferredDuringSchedulingIgnoredDuringExecution:
-            nodeSelectorTerms:
-            - matchExpressions:
+          - weight: 1
+            preference:
+              matchExpressions:
               - key: node-role.kubernetes.io/control-plane
                 operator: In
-                values: ""true""
+                values:
+                - ""true""
       priorityClassName: ""system-node-critical""
       containers:
       - args:"
thaum-xyz,ankhmorpork,dd301e853f44e4e7ccc8c407c5ec4c64ba6099ef,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-01-04T10:02:52Z,Pawe Krupa (paulfantom),pawel@krupa.net.pl,2022-01-04T10:02:52Z,apps/multimedia: fix ombi container image,apps/multimedia/manifests/ombi/statefulset.yaml;apps/multimedia/settings.yaml,False,False,False,False,2,2,4,"---FILE: apps/multimedia/manifests/ombi/statefulset.yaml---
@@ -28,7 +28,7 @@ spec:
       - env:
         - name: TZ
           value: Europe/Berlin
-        image: linuxserver/ombi:4.8.0
+        image: linuxserver/ombi:4.8.0-development
         imagePullPolicy: IfNotPresent
         name: ombi
         ports:

---FILE: apps/multimedia/settings.yaml---
@@ -22,7 +22,7 @@ ombi:
   #version: ""4.3.3""  # application-version-from-github: Ombi-app/Ombi
   #image: ""linuxserver/ombi:4.3.3""  # application-image-from-github: Ombi-app/Ombi
   version: ""4.8.0""  # Ombi stopped publishing those as ""latest""
-  image: ""linuxserver/ombi:4.8.0""
+  image: ""linuxserver/ombi:4.8.0-development""
   namespace: multimedia
   domain: ombi.ankhmorpork.thaum.xyz
   resources:"
thaum-xyz,ankhmorpork,84a13cc2d0882aa6786e4f871f50ddea65b3b31e,paulfantom,pawel@krupa.net.pl,2021-11-16T10:49:14Z,paulfantom,pawel@krupa.net.pl,2021-11-16T10:49:14Z,base/kube-system/device-plugins: fix issues with incorrect daemonset,base/kube-system/device-plugins/nvidia-gpu-plugin.yaml,False,False,False,False,2,1,3,"---FILE: base/kube-system/device-plugins/nvidia-gpu-plugin.yaml---
@@ -19,7 +19,8 @@ spec:
         #args: [""--fail-on-init-error=true""]
         name: nvidia-device-plugin-ctr
         securityContext:
-          allowPrivilegeEscalation: false
+          # TODO: reenable when https://github.com/k3s-io/k3s/issues/4391 is fixed
+          #allowPrivilegeEscalation: false
           capabilities:
             drop: [""ALL""]
           # TODO: remove after https://github.com/k3s-io/k3s/issues/4391 is fixed"
thaum-xyz,ankhmorpork,6a47b5e02288aa532c4a0f64299599866947ecfd,paulfantom,pawel@krupa.net.pl,2021-11-15T13:22:02Z,paulfantom,pawel@krupa.net.pl,2021-11-15T13:22:02Z,apps/monitoring: fix servicemonitor field,apps/monitoring/jsonnet/lib/windows-exporter.libsonnet;apps/monitoring/manifests/windowsExporter/serviceMonitor.yaml,False,False,False,False,2,2,4,"---FILE: apps/monitoring/jsonnet/lib/windows-exporter.libsonnet---
@@ -62,7 +62,7 @@ function(params) {
     kind: 'ServiceMonitor',
     metadata: windows._metadata,
     spec: {
-      jobName: 'windows-exporter',
+      jobLabel: 'windows-exporter',
       endpoints: [{
         interval: '60s',
         port: windows.endpoints.subsets[0].ports[0].name,

---FILE: apps/monitoring/manifests/windowsExporter/serviceMonitor.yaml---
@@ -10,7 +10,7 @@ spec:
   endpoints:
   - interval: 60s
     port: http
-  jobName: windows-exporter
+  jobLabel: windows-exporter
   selector:
     matchLabels:
       app.kubernetes.io/name: windows-exporter"
thaum-xyz,ankhmorpork,7780674ee311a375026a0a2319f6550e54692001,paulfantom,pawel@krupa.net.pl,2021-11-15T13:00:31Z,paulfantom,pawel@krupa.net.pl,2021-11-15T13:00:31Z,apps/monitoring: fix metadata in windows exporter objects,apps/monitoring/jsonnet/lib/windows-exporter.libsonnet;apps/monitoring/manifests/windowsExporter/endpoints.yaml;apps/monitoring/manifests/windowsExporter/service.yaml;apps/monitoring/manifests/windowsExporter/serviceMonitor.yaml,False,False,False,False,4,0,4,"---FILE: apps/monitoring/jsonnet/lib/windows-exporter.libsonnet---
@@ -23,6 +23,7 @@ function(params) {
   _metadata:: {
     labels: windows._config.commonLabels,
     namespace: windows._config.namespace,
+    name: 'windows-exporter',
   },
 
   mixin::

---FILE: apps/monitoring/manifests/windowsExporter/endpoints.yaml---
@@ -4,6 +4,7 @@ metadata:
   labels:
     app.kubernetes.io/name: windows-exporter
     app.kubernetes.io/part-of: kube-prometheus
+  name: windows-exporter
   namespace: monitoring
 subsets:
 - addresses:

---FILE: apps/monitoring/manifests/windowsExporter/service.yaml---
@@ -4,6 +4,7 @@ metadata:
   labels:
     app.kubernetes.io/name: windows-exporter
     app.kubernetes.io/part-of: kube-prometheus
+  name: windows-exporter
   namespace: monitoring
 spec:
   clusterIP: None

---FILE: apps/monitoring/manifests/windowsExporter/serviceMonitor.yaml---
@@ -4,6 +4,7 @@ metadata:
   labels:
     app.kubernetes.io/name: windows-exporter
     app.kubernetes.io/part-of: kube-prometheus
+  name: windows-exporter
   namespace: monitoring
 spec:
   endpoints:"
thaum-xyz,ankhmorpork,463d0a65f1d8277c5b69eea90451864177e44042,paulfantom,pawel@krupa.net.pl,2021-11-11T19:18:55Z,paulfantom,pawel@krupa.net.pl,2021-11-11T19:18:55Z,apps/homer: fix mealie icon,apps/homer/manifests/configmap.yaml;apps/homer/manifests/deployment.yaml;apps/homer/site-config.yml,False,False,False,False,3,3,6,"---FILE: apps/homer/manifests/configmap.yaml---
@@ -81,7 +81,7 @@ data:
             url: ""https://cloud.krupa.net.pl""
           - name: Cookbook
             subtitle: ""Our recipes""
-            logo: ""https://github.com/hay-kot/mealie/raw/master/docs/docs/assets/img/favicon.png""
+            logo: ""https://github.com/hay-kot/mealie/raw/dev/frontend/public/img/icons/android-chrome-512x512.png""
             url: ""https://recipe.krupa.net.pl""
           - name: HomeAssistant
             subtitle: ""Home automation system""

---FILE: apps/homer/manifests/deployment.yaml---
@@ -18,7 +18,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: de0ebcc6abfc4a8b2717ce70304e1920
+        checksum.config/md5: 8725c1e1d0acdef11b515f5b3b978867
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homer

---FILE: apps/homer/site-config.yml---
@@ -78,7 +78,7 @@ services:
         url: ""https://cloud.krupa.net.pl""
       - name: Cookbook
         subtitle: ""Our recipes""
-        logo: ""https://github.com/hay-kot/mealie/raw/master/docs/docs/assets/img/favicon.png""
+        logo: ""https://github.com/hay-kot/mealie/raw/dev/frontend/public/img/icons/android-chrome-512x512.png""
         url: ""https://recipe.krupa.net.pl""
       - name: HomeAssistant
         subtitle: ""Home automation system"""
thaum-xyz,ankhmorpork,addd0a337db098470fd1556c07d50c80ba4f5e4d,paulfantom,pawel@krupa.net.pl,2021-11-10T17:00:35Z,paulfantom,pawel@krupa.net.pl,2021-11-10T17:00:35Z,apps/monitoring: fix node_exporter selector,apps/monitoring/config.jsonnet,False,False,False,False,1,1,2,"---FILE: apps/monitoring/config.jsonnet---
@@ -142,7 +142,7 @@
   },
   nodeExporter+: {
     mixin+: {
-      _config: {
+      _config+: {
         runbookURLPattern: 'https://runbooks.thaum.xyz/runbooks/node/%s',
       },
     },"
thaum-xyz,ankhmorpork,ef28c92fb66113185fb7805c721570c5f192a243,paulfantom,pawel@krupa.net.pl,2021-11-05T15:06:13Z,paulfantom,pawel@krupa.net.pl,2021-11-05T15:06:13Z,apps/homeassistant: fix filename typo,apps/homeassistant/jsonnet/main.jsonnet;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,2,2,4,"---FILE: apps/homeassistant/jsonnet/main.jsonnet---
@@ -147,7 +147,7 @@ local all = {
           spec+: {
             containers: std.map(function(c) c {
               volumeMounts+: [{
-                mountPath: '/config/configuration.yml',
+                mountPath: '/config/configuration.yaml',
                 name: 'configs',
                 subPath: 'configuration.yaml',
                 readOnly: true,

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -56,7 +56,7 @@ spec:
         volumeMounts:
         - mountPath: /config
           name: config
-        - mountPath: /config/configuration.yml
+        - mountPath: /config/configuration.yaml
           name: configs
           readOnly: true
           subPath: configuration.yaml"
thaum-xyz,ankhmorpork,37f7f94128a9ab29bcbe4ccb85ef12c05f1715d5,paulfantom,pawel@krupa.net.pl,2021-11-05T14:42:00Z,paulfantom,pawel@krupa.net.pl,2021-11-05T14:42:00Z,apps/homeassistant: fix STS definition,apps/homeassistant/jsonnet/main.jsonnet;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,6,6,12,"---FILE: apps/homeassistant/jsonnet/main.jsonnet---
@@ -148,15 +148,15 @@ local all = {
             containers: std.map(function(c) c {
               volumeMounts+: [{
                 mountPath: '/test/configuration.yml',
-                name: 'config',
+                name: 'configs',
                 subPath: 'configuration.yaml'
               },{
                 mountPath: '/test/customize.yaml',
-                name: 'customize',
+                name: 'configs',
                 subPath: 'customize.yaml'
               },{
                 mountPath: '/test/scripts.yaml',
-                name: 'scripts',
+                name: 'configs',
                 subPath: 'scripts.yaml'
               },],
             }, super.containers),

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -57,13 +57,13 @@ spec:
         - mountPath: /config
           name: config
         - mountPath: /test/configuration.yml
-          name: config
+          name: configs
           subPath: configuration.yaml
         - mountPath: /test/customize.yaml
-          name: customize
+          name: configs
           subPath: customize.yaml
         - mountPath: /test/scripts.yaml
-          name: scripts
+          name: configs
           subPath: scripts.yaml
       hostNetwork: true
       nodeSelector:"
thaum-xyz,ankhmorpork,3eee8d6d030407c209a845935d2bc0e4d778b266,paulfantom,pawel@krupa.net.pl,2021-11-05T14:37:16Z,paulfantom,pawel@krupa.net.pl,2021-11-05T14:37:16Z,apps/homeassistant: fix duplicated containers in STS,apps/homeassistant/jsonnet/main.jsonnet;apps/homeassistant/manifests/homeassistant/statefulSet.yaml,False,False,False,False,1,30,31,"---FILE: apps/homeassistant/jsonnet/main.jsonnet---
@@ -145,7 +145,7 @@ local all = {
             },
           },
           spec+: {
-            containers+: std.map(function(c) c {
+            containers: std.map(function(c) c {
               volumeMounts+: [{
                 mountPath: '/test/configuration.yml',
                 name: 'config',

---FILE: apps/homeassistant/manifests/homeassistant/statefulSet.yaml---
@@ -27,35 +27,6 @@ spec:
         app.kubernetes.io/version: 2021.11.1
     spec:
       containers:
-      - env:
-        - name: TZ
-          value: Europe/Berlin
-        image: homeassistant/aarch64-homeassistant:2021.11.1
-        imagePullPolicy: IfNotPresent
-        name: homeassistant
-        ports:
-        - containerPort: 8123
-          name: http
-        readinessProbe:
-          failureThreshold: 5
-          httpGet:
-            path: /
-            port: http
-            scheme: HTTP
-          initialDelaySeconds: 60
-          timeoutSeconds: 10
-        resources:
-          limits:
-            cpu: 400m
-            memory: 1600Mi
-          requests:
-            cpu: 200m
-            memory: 800Mi
-        securityContext:
-          privileged: false
-        volumeMounts:
-        - mountPath: /config
-          name: config
       - env:
         - name: TZ
           value: Europe/Berlin"
thaum-xyz,ankhmorpork,c8575bfdb8939ee3fcd7312c0ae57fa63f970285,paulfantom,pawel@krupa.net.pl,2021-11-03T19:03:22Z,paulfantom,pawel@krupa.net.pl,2021-11-03T19:03:22Z,base/kube-system/device-plugins: fix cli flags,base/kube-system/device-plugins/nvidia-gpu-plugin.yaml,False,False,False,False,1,1,2,"---FILE: base/kube-system/device-plugins/nvidia-gpu-plugin.yaml---
@@ -20,7 +20,7 @@ spec:
       priorityClassName: ""system-node-critical""
       containers:
       - image: nvidia/k8s-device-plugin@sha256:194adbf675f90cecf9ef1c09fbec90a225c20edd73a01c0a19688c273a151d4a
-        args: [""--pass-device-specs""]
+        args: [""--fail-on-init-error=true""]
         name: nvidia-device-plugin-ctr
         securityContext:
           allowPrivilegeEscalation: false"
thaum-xyz,ankhmorpork,aff07dbd313d444752e35bf8ba1bc5e05d3a3a52,paulfantom,pawel@krupa.net.pl,2021-11-03T19:01:19Z,paulfantom,pawel@krupa.net.pl,2021-11-03T19:01:19Z,base/kube-system/device-plugins: error out on init failure,base/kube-system/device-plugins/nvidia-gpu-plugin.yaml,False,False,False,False,1,1,2,"---FILE: base/kube-system/device-plugins/nvidia-gpu-plugin.yaml---
@@ -20,7 +20,7 @@ spec:
       priorityClassName: ""system-node-critical""
       containers:
       - image: nvidia/k8s-device-plugin@sha256:194adbf675f90cecf9ef1c09fbec90a225c20edd73a01c0a19688c273a151d4a
-        args: [""--fail-on-init-error=false"", ""--pass-device-specs""]
+        args: [""--pass-device-specs""]
         name: nvidia-device-plugin-ctr
         securityContext:
           allowPrivilegeEscalation: false"
thaum-xyz,ankhmorpork,6d25546e280862b4e46dddd7f8b116b916f35eab,paulfantom,pawel@krupa.net.pl,2021-11-02T20:44:52Z,paulfantom,pawel@krupa.net.pl,2021-11-02T20:44:52Z,apps/nextcloud/mysql: fix duplicate env,apps/nextcloud/mysql/05_deployment.yaml,False,False,False,False,0,2,2,"---FILE: apps/nextcloud/mysql/05_deployment.yaml---
@@ -68,8 +68,6 @@ spec:
       - env:
         - name: CRON_SCHEDULE
           value: ""5 3 * * *""
-        - name: MYSQL_HOST
-          value: ""localhost""
         - name: MYSQL_USER
           value: ""root""
         - name: MYSQL_HOST"
thaum-xyz,ankhmorpork,0408b8fd4226647ba94fbb7d458066c0d251f938,paulfantom,pawel@krupa.net.pl,2021-11-02T19:28:26Z,paulfantom,pawel@krupa.net.pl,2021-11-02T19:28:26Z,hack: fix secrets checking,hack/checksecrets.sh,False,False,False,False,1,1,2,"---FILE: hack/checksecrets.sh---
@@ -5,7 +5,7 @@ cd ""$(git rev-parse --show-toplevel)""
 
 EXCLUDES=$( cat <<EOM
 apps/monitoring/manifests/grafana/dashboardDatasources.yaml
-apps/monitoring/manifests/prometheusk8s/windowsConfig.yaml
+apps/monitoring/manifests/prometheus/windowsConfig.yaml
 EOM
 )
 "
thaum-xyz,ankhmorpork,4c783139c721448130889bc5a346c4bb6d3b0762,paulfantom,pawel@krupa.net.pl,2021-11-01T09:33:12Z,paulfantom,pawel@krupa.net.pl,2021-11-01T09:33:12Z,apps/monitoring: fix NetworkPolicies,apps/monitoring/jsonnet/main.jsonnet;apps/monitoring/manifests/kubeStateMetrics/networkPolicy.yaml;apps/monitoring/manifests/nodeExporter/networkPolicy.yaml,False,False,False,False,99,21,120,"---FILE: apps/monitoring/jsonnet/main.jsonnet---
@@ -167,6 +167,33 @@ local kp =
           },
         },
       ),
+      # TODO: move to kube-prometheus
+      /*networkPolicy: {
+        apiVersion: 'networking.k8s.io/v1',
+        kind: 'NetworkPolicy',
+        metadata: $.alertmanager.service.metadata,
+        spec: {
+          ingress: [{
+            from: [{
+              podSelector: {
+                # Selector should probably be customizable
+                matchExpressions: [{
+                  key: ""app.kubernetes.io/name"",
+                  operator: ""In"",
+                  values: [""prometheus""],
+                }],
+              },
+            }],
+            ports: std.map(function(o) {
+              port: o.port,
+              protocol: ""TCP"",
+            }, $.alertmanager.service.spec.ports),
+          }],
+          podSelector: {
+            matchLabels: $.alertmanager.service.spec.selector,
+          },
+        },
+      },*/
     },
 
     blackboxExporter+: {
@@ -182,6 +209,33 @@ local kp =
       promDemoProbe: probe('prometheus-demo', $.blackboxExporter.deployment.metadata.namespace, $.blackboxExporter._config.commonLabels, 'http_2xx', $.values.blackboxExporter.probes.promDemo),
       thaumProbe: probe('thaum-sites', $.blackboxExporter.deployment.metadata.namespace, $.blackboxExporter._config.commonLabels, 'http_2xx', $.values.blackboxExporter.probes.thaumSites),
       ingressProbe: probe('ankhmorpork', $.blackboxExporter.deployment.metadata.namespace, $.blackboxExporter._config.commonLabels, 'http_2xx', $.values.blackboxExporter.probes.ingress),
+      # TODO: move to kube-prometheus
+      /*networkPolicy: {
+        apiVersion: 'networking.k8s.io/v1',
+        kind: 'NetworkPolicy',
+        metadata: $.blackboxExporter.service.metadata,
+        spec: {
+          ingress: [{
+            from: [{
+              podSelector: {
+                # Selector should probably be customizable
+                matchExpressions: [{
+                  key: ""app.kubernetes.io/name"",
+                  operator: ""In"",
+                  values: [""prometheus""],
+                }],
+              },
+            }],
+            ports: std.map(function(o) {
+              port: o.port,
+              protocol: ""TCP"",
+            }, $.blackboxExporter.service.spec.ports),
+          }],
+          podSelector: {
+            matchLabels: $.blackboxExporter.service.spec.selector,
+          },
+        },
+      },*/
     },
 
     // TODO: Remove Service and move ServiceMonitor to PodMonitor
@@ -230,14 +284,15 @@ local kp =
             from: [{
               podSelector: {
                 # Selector should probably be customizable
-                matchExpressions: [{
-                  key: ""app.kubernetes.io/name"",
-                  operator: ""In"",
-                  values: [""prometheus""],
-                }],
+                matchLabels: {
+                  'app.kubernetes.io/name': ""prometheus"",
+                },
               },
             }],
-            ports: $.nodeExporter.service.spec.ports,
+            ports: std.map(function(o) {
+              port: o.port,
+              protocol: ""TCP"",
+            }, $.nodeExporter.service.spec.ports),
           }],
           podSelector: {
             matchLabels: $.nodeExporter.service.spec.selector,
@@ -318,7 +373,10 @@ local kp =
                 },
               },
             }],
-            ports: $.kubeStateMetrics.service.spec.ports,
+            ports: std.map(function(o) {
+              port: o.port,
+              protocol: ""TCP"",
+            }, $.kubeStateMetrics.service.spec.ports),
           }],
           podSelector: {
             matchLabels: $.kubeStateMetrics.service.spec.selector,
@@ -424,6 +482,32 @@ local kp =
         },
       },
 
+      # TODO: move to kube-prometheus
+      /*networkPolicy: {
+        apiVersion: 'networking.k8s.io/v1',
+        kind: 'NetworkPolicy',
+        metadata: $.grafana.service.metadata,
+        spec: {
+          ingress: [{
+            from: [{
+              podSelector: {
+                # Selector should probably be customizable
+                matchLabels: {
+                  'app.kubernetes.io/name': ""prometheus"",
+                },
+              },
+            }],
+            ports: std.map(function(o) {
+              port: o.port,
+              protocol: ""TCP"",
+            }, $.grafana.service.spec.ports),
+          }],
+          podSelector: {
+            matchLabels: $.grafana.service.spec.selector,
+          },
+        },
+      },*/
+
       // TODO: Remove PrometheusRule object when https://github.com/prometheus-operator/kube-prometheus/pull/1458 is merged
       prometheusRule: {
         apiVersion: 'monitoring.coreos.com/v1',

---FILE: apps/monitoring/manifests/kubeStateMetrics/networkPolicy.yaml---
@@ -15,12 +15,10 @@ spec:
         matchLabels:
           app.kubernetes.io/name: prometheus
     ports:
-    - name: https-main
-      port: 8443
-      targetPort: https-main
-    - name: https-self
-      port: 9443
-      targetPort: https-self
+    - port: 8443
+      protocol: TCP
+    - port: 9443
+      protocol: TCP
   podSelector:
     matchLabels:
       app.kubernetes.io/component: exporter

---FILE: apps/monitoring/manifests/nodeExporter/networkPolicy.yaml---
@@ -12,15 +12,11 @@ spec:
   ingress:
   - from:
     - podSelector:
-        matchExpressions:
-        - key: app.kubernetes.io/name
-          operator: In
-          values:
-          - prometheus
+        matchLabels:
+          app.kubernetes.io/name: prometheus
     ports:
-    - name: https
-      port: 9100
-      targetPort: https
+    - port: 9100
+      protocol: TCP
   podSelector:
     matchLabels:
       app.kubernetes.io/component: exporter"
thaum-xyz,ankhmorpork,a5d15243b3bbf88fc5d2c901d5f15bef833f914c,paulfantom,pawel@krupa.net.pl,2021-10-29T09:26:03Z,paulfantom,pawel@krupa.net.pl,2021-10-29T09:26:03Z,apps/monitoring: fix issues in alertmanager config,apps/monitoring/manifests/alertmanager/secret.yaml;apps/monitoring/raw/alertmanager-secret.yaml,False,False,False,False,4,6,10,"---FILE: apps/monitoring/manifests/alertmanager/secret.yaml---
@@ -80,7 +80,7 @@ spec:
               description: ""{{ .CommonAnnotations.summary }}""
               details:
                 runbookUrl: ""{{ .CommonAnnotations.runbook_url }}""
-                dashboardUrl: ""{{ .CommonAnnotations.dashboard_url }}
+                dashboardUrl: ""{{ .CommonAnnotations.dashboard_url }}""
                 silenceUrl: >-
                   {{ .ExternalURL }}/#/silences/new?filter=%7B
                   {{- range .CommonLabels.SortedPairs -}}
@@ -100,8 +100,7 @@ spec:
                   P4
                   {{- end -}}
                 {{- end -}}
-              tags:
-                test: tag
+              tags: ""test""
               responders:
               - name: 'Main'
                 type: team

---FILE: apps/monitoring/raw/alertmanager-secret.yaml---
@@ -80,7 +80,7 @@ spec:
               description: ""{{ .CommonAnnotations.summary }}""
               details:
                 runbookUrl: ""{{ .CommonAnnotations.runbook_url }}""
-                dashboardUrl: ""{{ .CommonAnnotations.dashboard_url }}
+                dashboardUrl: ""{{ .CommonAnnotations.dashboard_url }}""
                 silenceUrl: >-
                   {{ .ExternalURL }}/#/silences/new?filter=%7B
                   {{- range .CommonLabels.SortedPairs -}}
@@ -100,8 +100,7 @@ spec:
                   P4
                   {{- end -}}
                 {{- end -}}
-              tags:
-                test: tag
+              tags: ""test""
               responders:
               - name: 'Main'
                 type: team"
thaum-xyz,ankhmorpork,a3c6e5905a261c92d8a28084eb0d652e7fb1d1c1,paulfantom,pawel@krupa.net.pl,2021-10-28T12:49:14Z,paulfantom,pawel@krupa.net.pl,2021-10-28T12:49:14Z,apps/parca: update to 0.2.0 to test https://github.com/parca-dev/parca/issues/380,apps/parca/manifests/agent/clusterRole.yaml;apps/parca/manifests/agent/clusterRoleBinding.yaml;apps/parca/manifests/agent/daemonSet.yaml;apps/parca/manifests/agent/podMonitor.yaml;apps/parca/manifests/agent/podSecurityPolicy.yaml;apps/parca/manifests/agent/role.yaml;apps/parca/manifests/agent/roleBinding.yaml;apps/parca/manifests/agent/serviceAccount.yaml;apps/parca/settings.yaml,False,False,False,False,13,13,26,"---FILE: apps/parca/manifests/agent/clusterRole.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: observability
     app.kubernetes.io/instance: parca-agent
     app.kubernetes.io/name: parca-agent
-    app.kubernetes.io/version: 0.1.0
+    app.kubernetes.io/version: 0.2.0
   name: parca-agent
   namespace: parca
 rules:

---FILE: apps/parca/manifests/agent/clusterRoleBinding.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: observability
     app.kubernetes.io/instance: parca-agent
     app.kubernetes.io/name: parca-agent
-    app.kubernetes.io/version: 0.1.0
+    app.kubernetes.io/version: 0.2.0
   name: parca-agent
   namespace: parca
 roleRef:

---FILE: apps/parca/manifests/agent/daemonSet.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: observability
     app.kubernetes.io/instance: parca-agent
     app.kubernetes.io/name: parca-agent
-    app.kubernetes.io/version: 0.1.0
+    app.kubernetes.io/version: 0.2.0
   name: parca-agent
   namespace: parca
 spec:
@@ -20,7 +20,7 @@ spec:
         app.kubernetes.io/component: observability
         app.kubernetes.io/instance: parca-agent
         app.kubernetes.io/name: parca-agent
-        app.kubernetes.io/version: 0.1.0
+        app.kubernetes.io/version: 0.2.0
     spec:
       containers:
       - args:
@@ -37,7 +37,7 @@ spec:
           valueFrom:
             fieldRef:
               fieldPath: spec.nodeName
-        image: ghcr.io/parca-dev/parca-agent:v0.1.0
+        image: ghcr.io/parca-dev/parca-agent:v0.2.0
         name: parca-agent
         ports:
         - containerPort: 7071

---FILE: apps/parca/manifests/agent/podMonitor.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: observability
     app.kubernetes.io/instance: parca-agent
     app.kubernetes.io/name: parca-agent
-    app.kubernetes.io/version: 0.1.0
+    app.kubernetes.io/version: 0.2.0
   name: parca-agent
   namespace: parca
 spec:
@@ -16,4 +16,4 @@ spec:
       app.kubernetes.io/component: observability
       app.kubernetes.io/instance: parca-agent
       app.kubernetes.io/name: parca-agent
-      app.kubernetes.io/version: 0.1.0
+      app.kubernetes.io/version: 0.2.0

---FILE: apps/parca/manifests/agent/podSecurityPolicy.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: observability
     app.kubernetes.io/instance: parca-agent
     app.kubernetes.io/name: parca-agent
-    app.kubernetes.io/version: 0.1.0
+    app.kubernetes.io/version: 0.2.0
   name: parca-agent
   namespace: parca
 spec:

---FILE: apps/parca/manifests/agent/role.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: observability
     app.kubernetes.io/instance: parca-agent
     app.kubernetes.io/name: parca-agent
-    app.kubernetes.io/version: 0.1.0
+    app.kubernetes.io/version: 0.2.0
   name: parca-agent
   namespace: parca
 rules:

---FILE: apps/parca/manifests/agent/roleBinding.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: observability
     app.kubernetes.io/instance: parca-agent
     app.kubernetes.io/name: parca-agent
-    app.kubernetes.io/version: 0.1.0
+    app.kubernetes.io/version: 0.2.0
   name: parca-agent
   namespace: parca
 roleRef:

---FILE: apps/parca/manifests/agent/serviceAccount.yaml---
@@ -5,6 +5,6 @@ metadata:
     app.kubernetes.io/component: observability
     app.kubernetes.io/instance: parca-agent
     app.kubernetes.io/name: parca-agent
-    app.kubernetes.io/version: 0.1.0
+    app.kubernetes.io/version: 0.2.0
   name: parca-agent
   namespace: parca

---FILE: apps/parca/settings.yaml---
@@ -1,8 +1,8 @@
 ---
 domain: ""parca.ankhmorpork.thaum.xyz""
 agent:
-  version: ""0.1.0""  # application-version-from-github: parca-dev/parca-agent
-  image: ""ghcr.io/parca-dev/parca-agent:v0.1.0""  # application-image-from-github: parca-dev/parca-agent
+  version: ""0.2.0""  # application-version-from-github: parca-dev/parca-agent
+  image: ""ghcr.io/parca-dev/parca-agent:v0.2.0""  # application-image-from-github: parca-dev/parca-agent
   namespace: ""parca""
   stores: ['parca.parca.svc:7070']
   podMonitor: true"
thaum-xyz,ankhmorpork,f1488be830e7f5a89bf6aa072d5f3d3efadde75a,paulfantom,pawel@krupa.net.pl,2021-10-26T18:54:01Z,paulfantom,pawel@krupa.net.pl,2021-10-26T18:54:01Z,apps/system-update: fix invalid setting,apps/system-update/manifests/kured/daemonSet.yaml;apps/system-update/settings.yaml,False,False,False,False,2,2,4,"---FILE: apps/system-update/manifests/kured/daemonSet.yaml---
@@ -47,7 +47,7 @@ spec:
           limits:
             cpu: 60m
             memory: 30Mi
-          requirements:
+          requests:
             cpu: 14m
             memory: 23Mi
         securityContext:

---FILE: apps/system-update/settings.yaml---
@@ -7,7 +7,7 @@ kured:
     - ""--reboot-days=sun,fri,sat""
     - ""--period=2m""
   resources:
-    requirements:
+    requests:
       cpu: 14m
       memory: 23Mi
     limits:"
thaum-xyz,ankhmorpork,b628150842a9482498c4d5d9909cbeb173ecb8c6,paulfantom,pawel@krupa.net.pl,2021-10-24T18:17:25Z,paulfantom,pawel@krupa.net.pl,2021-10-24T18:17:25Z,apps/monitoring: fix node-exporter DS,apps/monitoring/jsonnet/main.jsonnet;apps/monitoring/manifests/nodeExporter/daemonset.yaml;apps/monitoring/manifests/other/thaumPrometheusRule.yaml,False,False,False,False,11,58,69,"---FILE: apps/monitoring/jsonnet/main.jsonnet---
@@ -190,7 +190,7 @@ local kp =
         spec+: {
           template+: {
             spec+: {
-              containers+: std.map(
+              containers: std.map(
                 function(c) if c.name == 'node-exporter' then
                   c {
                     args+: ['--collector.textfile.directory=/host/textfile'],

---FILE: apps/monitoring/manifests/nodeExporter/daemonset.yaml---
@@ -23,60 +23,6 @@ spec:
         app.kubernetes.io/version: 1.2.2
     spec:
       containers:
-      - args:
-        - --web.listen-address=127.0.0.1:9100
-        - --path.sysfs=/host/sys
-        - --path.rootfs=/host/root
-        - --no-collector.wifi
-        - --no-collector.hwmon
-        - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/pods/.+)($|/)
-        - --collector.netclass.ignored-devices=^(veth.*|[a-f0-9]{15})$
-        - --collector.netdev.device-exclude=^(veth.*|[a-f0-9]{15})$
-        image: quay.io/prometheus/node-exporter:v1.2.2
-        name: node-exporter
-        resources:
-          limits:
-            cpu: 250m
-            memory: 180Mi
-          requests:
-            cpu: 102m
-            memory: 180Mi
-        volumeMounts:
-        - mountPath: /host/sys
-          mountPropagation: HostToContainer
-          name: sys
-          readOnly: true
-        - mountPath: /host/root
-          mountPropagation: HostToContainer
-          name: root
-          readOnly: true
-      - args:
-        - --logtostderr
-        - --secure-listen-address=[$(IP)]:9100
-        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
-        - --upstream=http://127.0.0.1:9100/
-        env:
-        - name: IP
-          valueFrom:
-            fieldRef:
-              fieldPath: status.podIP
-        image: quay.io/brancz/kube-rbac-proxy:v0.11.0
-        name: kube-rbac-proxy
-        ports:
-        - containerPort: 9100
-          hostPort: 9100
-          name: https
-        resources:
-          limits:
-            cpu: 20m
-            memory: 40Mi
-          requests:
-            cpu: 10m
-            memory: 20Mi
-        securityContext:
-          runAsGroup: 65532
-          runAsNonRoot: true
-          runAsUser: 65532
       - args:
         - --web.listen-address=127.0.0.1:9100
         - --path.sysfs=/host/sys

---FILE: apps/monitoring/manifests/other/thaumPrometheusRule.yaml---
@@ -158,9 +158,16 @@ spec:
           15 minutes. There are many potential causes of OOM errors, however issues
           on a specific node or containers breaching their limits is common.'
         summary: Containers are being killed due to OOM
-      expr: ""sum(\n  max by(namespace, container, pod) (\n    increase(kube_pod_container_status_restarts_total[12m])\n
-        \ )\n  and \n  max by(namespace, container, pod) (\n    kube_pod_container_status_last_terminated_reason{reason=\""OOMKilled\""}\n
-        \ ) == 1\n) > 2\n""
+      expr: |
+        sum(
+          max by(namespace, container, pod) (
+            increase(kube_pod_container_status_restarts_total[12m])
+          )
+          and
+          max by(namespace, container, pod) (
+            kube_pod_container_status_last_terminated_reason{reason=""OOMKilled""}
+          ) == 1
+        ) > 2
       for: 15m
       labels:
         severity: info"
thaum-xyz,ankhmorpork,8f6ad813ea7cc9c2d6d6da003b6594f46311513e,paulfantom,pawel@krupa.net.pl,2021-10-24T11:14:06Z,paulfantom,pawel@krupa.net.pl,2021-10-24T11:14:06Z,ansible: fix link to pkg mgr scripts,ansible/01_system.yml,False,False,False,False,1,1,2,"---FILE: ansible/01_system.yml---
@@ -22,7 +22,7 @@
       pkg_mgr: ""{{ 'yum' if ansible_pkg_mgr == 'dnf' else ansible_pkg_mgr }}""
   - name: Download package manager textfile collector script
     get_url:
-      url: ""https://github.com/prometheus-community/node-exporter-textfile-collector-scripts/blob/master/{{ pkg_mgr }}.sh""
+      url: ""https://raw.githubusercontent.com/prometheus-community/node-exporter-textfile-collector-scripts/master/{{ pkg_mgr }}.sh""
       dest: ""/usr/local/bin/{{ pkg_mgr }}.sh""
       mode: 0755
   - name: Set cronjob for package manager (/etc/crontab)"
thaum-xyz,ankhmorpork,f62e365919db992efffe68079c8b78d534efcd10,paulfantom,pawel@krupa.net.pl,2021-10-22T11:40:12Z,paulfantom,pawel@krupa.net.pl,2021-10-22T11:40:12Z,apps/monitoring: fix generation issues,apps/monitoring/jsonnet/main.jsonnet;apps/monitoring/manifests/grafana/service.yaml;apps/monitoring/raw/sloth-CRDprometheusservicelevels.yaml,False,False,False,False,1,229,230,"---FILE: apps/monitoring/jsonnet/main.jsonnet---
@@ -387,7 +387,7 @@ local kp =
         apiVersion: 'v1',
         metadata: {
           name: 'grafana-data',
-          namespace: $.grafana.deployment.namespace,
+          namespace: $.grafana.deployment.metadata.namespace,
         },
         spec: {
           storageClassName: 'managed-nfs-storage',

---FILE: apps/monitoring/manifests/grafana/service.yaml---
@@ -17,4 +17,3 @@ spec:
     app.kubernetes.io/component: grafana
     app.kubernetes.io/name: grafana
     app.kubernetes.io/part-of: kube-prometheus
-  type: ClusterIP

---FILE: apps/monitoring/raw/sloth-CRDprometheusservicelevels.yaml---
@@ -1,227 +0,0 @@
-
----
-apiVersion: apiextensions.k8s.io/v1
-kind: CustomResourceDefinition
-metadata:
-  annotations:
-    controller-gen.kubebuilder.io/version: (devel)
-  creationTimestamp: null
-  name: prometheusservicelevels.sloth.slok.dev
-spec:
-  group: sloth.slok.dev
-  names:
-    categories:
-    - slo
-    - slos
-    - sli
-    - slis
-    kind: PrometheusServiceLevel
-    listKind: PrometheusServiceLevelList
-    plural: prometheusservicelevels
-    shortNames:
-    - psl
-    - pslo
-    singular: prometheusservicelevel
-  scope: Namespaced
-  versions:
-  - additionalPrinterColumns:
-    - jsonPath: .spec.service
-      name: SERVICE
-      type: string
-    - jsonPath: .status.processedSLOs
-      name: DESIRED SLOs
-      type: integer
-    - jsonPath: .status.promOpRulesGeneratedSLOs
-      name: READY SLOs
-      type: integer
-    - jsonPath: .status.promOpRulesGenerated
-      name: GEN OK
-      type: boolean
-    - jsonPath: .status.lastPromOpRulesSuccessfulGenerated
-      name: GEN AGE
-      type: date
-    - jsonPath: .metadata.creationTimestamp
-      name: AGE
-      type: date
-    name: v1
-    schema:
-      openAPIV3Schema:
-        description: PrometheusServiceLevel is the expected service quality level using Prometheus as the backend used by Sloth.
-        properties:
-          apiVersion:
-            description: 'APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
-            type: string
-          kind:
-            description: 'Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
-            type: string
-          metadata:
-            type: object
-          spec:
-            description: ServiceLevelSpec is the spec for a PrometheusServiceLevel.
-            properties:
-              labels:
-                additionalProperties:
-                  type: string
-                description: Labels are the Prometheus labels that will have all the recording and alerting rules generated for the service SLOs.
-                type: object
-              service:
-                description: Service is the application of the SLOs.
-                type: string
-              slos:
-                description: SLOs are the SLOs of the service.
-                items:
-                  description: SLO is the configuration/declaration of the service level objective of a service.
-                  properties:
-                    alerting:
-                      description: Alerting is the configuration with all the things related with the SLO alerts.
-                      properties:
-                        annotations:
-                          additionalProperties:
-                            type: string
-                          description: Annotations are the Prometheus annotations that will have all the alerts generated by this SLO.
-                          type: object
-                        labels:
-                          additionalProperties:
-                            type: string
-                          description: Labels are the Prometheus labels that will have all the alerts generated by this SLO.
-                          type: object
-                        name:
-                          description: Name is the name used by the alerts generated for this SLO.
-                          type: string
-                        pageAlert:
-                          description: Page alert refers to the critical alert (check multiwindow-multiburn alerts).
-                          properties:
-                            annotations:
-                              additionalProperties:
-                                type: string
-                              description: Annotations are the Prometheus annotations for the specific alert.
-                              type: object
-                            disable:
-                              description: Disable disables the alert and makes Sloth not generating this alert. This can be helpful for example to disable ticket(warning) alerts.
-                              type: boolean
-                            labels:
-                              additionalProperties:
-                                type: string
-                              description: Labels are the Prometheus labels for the specific alert. For example can be useful to route the Page alert to specific Slack channel.
-                              type: object
-                          type: object
-                        ticketAlert:
-                          description: TicketAlert alert refers to the warning alert (check multiwindow-multiburn alerts).
-                          properties:
-                            annotations:
-                              additionalProperties:
-                                type: string
-                              description: Annotations are the Prometheus annotations for the specific alert.
-                              type: object
-                            disable:
-                              description: Disable disables the alert and makes Sloth not generating this alert. This can be helpful for example to disable ticket(warning) alerts.
-                              type: boolean
-                            labels:
-                              additionalProperties:
-                                type: string
-                              description: Labels are the Prometheus labels for the specific alert. For example can be useful to route the Page alert to specific Slack channel.
-                              type: object
-                          type: object
-                      type: object
-                    description:
-                      description: Description is the description of the SLO.
-                      type: string
-                    labels:
-                      additionalProperties:
-                        type: string
-                      description: Labels are the Prometheus labels that will have all the recording and alerting rules for this specific SLO. These labels are merged with the previous level labels.
-                      type: object
-                    name:
-                      description: Name is the name of the SLO.
-                      maxLength: 128
-                      type: string
-                    objective:
-                      description: Objective is target of the SLO the percentage (0, 100] (e.g 99.9).
-                      type: number
-                    sli:
-                      description: SLI is the indicator (service level indicator) for this specific SLO.
-                      properties:
-                        events:
-                          description: Events is the events SLI type.
-                          properties:
-                            errorQuery:
-                              description: ErrorQuery is a Prometheus query that will get the number/count of events that we consider that are bad for the SLO (e.g ""http 5xx"", ""latency > 250ms""...). Requires the usage of `{{.window}}` template variable.
-                              type: string
-                            totalQuery:
-                              description: TotalQuery is a Prometheus query that will get the total number/count of events for the SLO (e.g ""all http requests""...). Requires the usage of `{{.window}}` template variable.
-                              type: string
-                          required:
-                          - errorQuery
-                          - totalQuery
-                          type: object
-                        plugin:
-                          description: Plugin is the pluggable SLI type.
-                          properties:
-                            id:
-                              description: Name is the name of the plugin that needs to load.
-                              type: string
-                            options:
-                              additionalProperties:
-                                type: string
-                              description: Options are the options used for the plugin.
-                              type: object
-                          required:
-                          - id
-                          type: object
-                        raw:
-                          description: Raw is the raw SLI type.
-                          properties:
-                            errorRatioQuery:
-                              description: ErrorRatioQuery is a Prometheus query that will get the raw error ratio (0-1) for the SLO.
-                              type: string
-                          required:
-                          - errorRatioQuery
-                          type: object
-                      type: object
-                  required:
-                  - alerting
-                  - name
-                  - objective
-                  - sli
-                  type: object
-                minItems: 1
-                type: array
-            required:
-            - service
-            type: object
-          status:
-            properties:
-              lastPromOpRulesSuccessfulGenerated:
-                description: LastPromOpRulesGeneration tells the last atemp made for a successful SLO rules generate.
-                format: date-time
-                type: string
-              observedGeneration:
-                description: ObservedGeneration tells the generation was acted on, normally this is required to stop an infinite loop when the status is updated because it sends a watch updated event to the watchers of the K8s object.
-                format: int64
-                type: integer
-              processedSLOs:
-                description: ProcessedSLOs tells how many SLOs haven been processed for Prometheus operator.
-                type: integer
-              promOpRulesGenerated:
-                description: PromOpRulesGenerated tells if the rules for prometheus operator CRD have been generated.
-                type: boolean
-              promOpRulesGeneratedSLOs:
-                description: PromOpRulesGeneratedSLOs tells how many SLOs have been processed and generated for Prometheus operator successfully.
-                type: integer
-            required:
-            - observedGeneration
-            - processedSLOs
-            - promOpRulesGenerated
-            - promOpRulesGeneratedSLOs
-            type: object
-        type: object
-    served: true
-    storage: true
-    subresources:
-      status: {}
-status:
-  acceptedNames:
-    kind: """"
-    plural: """"
-  conditions: []
-  storedVersions: []"
thaum-xyz,ankhmorpork,ce138120f2ee26978b7ffc89577402d535a72032,paulfantom,pawel@krupa.net.pl,2021-10-19T06:59:40Z,paulfantom,pawel@krupa.net.pl,2021-10-19T06:59:40Z,base/kube-system/sealed-secrets: fix rbac api group,base/kube-system/sealed-secrets/controller.yaml,False,False,False,False,5,5,10,"---FILE: base/kube-system/sealed-secrets/controller.yaml---
@@ -24,7 +24,7 @@ rules:
   - create
   - get
 ---
-apiVersion: rbac.authorization.k8s.io/v1beta1
+apiVersion: rbac.authorization.k8s.io/v1
 kind: Role
 metadata:
   annotations: {}
@@ -65,7 +65,7 @@ spec:
     name: sealed-secrets-controller
   type: ClusterIP
 ---
-apiVersion: rbac.authorization.k8s.io/v1beta1
+apiVersion: rbac.authorization.k8s.io/v1
 kind: RoleBinding
 metadata:
   annotations: {}
@@ -114,7 +114,7 @@ spec:
     subresources:
       status: {}
 ---
-apiVersion: rbac.authorization.k8s.io/v1beta1
+apiVersion: rbac.authorization.k8s.io/v1
 kind: RoleBinding
 metadata:
   annotations: {}
@@ -135,7 +135,7 @@ subjects:
   name: sealed-secrets-controller
   namespace: kube-system
 ---
-apiVersion: rbac.authorization.k8s.io/v1beta1
+apiVersion: rbac.authorization.k8s.io/v1
 kind: ClusterRoleBinding
 metadata:
   annotations: {}
@@ -155,7 +155,7 @@ subjects:
   name: sealed-secrets-controller
   namespace: kube-system
 ---
-apiVersion: rbac.authorization.k8s.io/v1beta1
+apiVersion: rbac.authorization.k8s.io/v1
 kind: ClusterRole
 metadata:
   annotations: {}"
thaum-xyz,ankhmorpork,92800f63fbcf8b5e13b43a8b0552855ac13778a2,paulfantom,pawel@krupa.net.pl,2021-10-15T11:32:47Z,paulfantom,pawel@krupa.net.pl,2021-10-15T11:32:47Z,apps/parca: propagate fix from https://github.com/parca-dev/parca-agent/pull/100,apps/parca/ns.yaml,False,False,False,False,1,1,2,"---FILE: apps/parca/ns.yaml---
@@ -2,7 +2,7 @@ apiVersion: 'v1'
 kind: 'Namespace'
 metadata:
   name: 'parca'
-  annotations:
+  labels:
     'pod-security.kubernetes.io/enforce': 'privileged'
     'pod-security.kubernetes.io/audit': 'privileged'
     'pod-security.kubernetes.io/warn': 'privileged'"
thaum-xyz,ankhmorpork,4d2e760a53ce94bb0bd815005b3a99b710150b28,paulfantom,pawel@krupa.net.pl,2021-10-15T09:22:44Z,paulfantom,pawel@krupa.net.pl,2021-10-15T09:22:44Z,apps/parca: include a fix from https://github.com/parca-dev/parca/pull/313,apps/parca/jsonnet/jsonnetfile.lock.json;apps/parca/jsonnet/main.jsonnet,False,False,False,False,2,12,14,"---FILE: apps/parca/jsonnet/jsonnetfile.lock.json---
@@ -18,8 +18,8 @@
           ""subdir"": ""deploy/lib/parca""
         }
       },
-      ""version"": ""2743415a06f47c810fca767c03d1ef9a94dc9599"",
-      ""sum"": ""tTulWtA6/UweWxt5gr6SwrxL+86hyn0wMUqwajdB5+Y=""
+      ""version"": ""cd47bfc86088e2c6788842571cd4d0c275c5f6a1"",
+      ""sum"": ""uanpv3IID+ZxRZyzqAhczwV9m9pTxpCERcBs8duTyLM=""
     }
   ],
   ""legacyImports"": false

---FILE: apps/parca/jsonnet/main.jsonnet---
@@ -36,16 +36,6 @@ local all = {
         'parca.yaml': parcaConfig,
       }
     },
-    // FIXME: THAT'S AN UPSTREAM BUG
-    service+: {
-      spec+: {
-        ports: [{
-          name: 'http',
-          port: 7070,
-          targetPort: 7070,
-        }],
-      },
-    },
     ingress: {
       apiVersion: 'networking.k8s.io/v1',
       kind: 'Ingress',"
thaum-xyz,ankhmorpork,f3767f3e2729ef30c24bb3afdb4c58c7b1078e9c,paulfantom,pawel@krupa.net.pl,2021-10-14T16:17:35Z,paulfantom,pawel@krupa.net.pl,2021-10-14T16:17:35Z,apps/parca: fix parca port name,apps/parca/jsonnet/main.jsonnet;apps/parca/manifests/parca/deployment.yaml;apps/parca/manifests/parca/ingress.yaml;apps/parca/manifests/parca/service.yaml,False,False,False,False,13,3,16,"---FILE: apps/parca/jsonnet/main.jsonnet---
@@ -36,6 +36,16 @@ local all = {
         'parca.yaml': parcaConfig,
       }
     },
+    // FIXME: THAT'S AN UPSTREAM BUG
+    service+: {
+      spec+: {
+        ports: [{
+          name: 'http',
+          port: 7070,
+          targetPort: 7070,
+        }],
+      },
+    },
     ingress: {
       apiVersion: 'networking.k8s.io/v1',
       kind: 'Ingress',

---FILE: apps/parca/manifests/parca/deployment.yaml---
@@ -40,7 +40,7 @@ spec:
         name: parca
         ports:
         - containerPort: 7070
-          name: all
+          name: http
         readinessProbe:
           exec:
             command:

---FILE: apps/parca/manifests/parca/ingress.yaml---
@@ -22,7 +22,7 @@ spec:
           service:
             name: parca
             port:
-              name: all
+              name: http
         path: /
         pathType: Prefix
   tls:

---FILE: apps/parca/manifests/parca/service.yaml---
@@ -10,7 +10,7 @@ metadata:
   namespace: parca
 spec:
   ports:
-  - name: all
+  - name: http
     port: 7070
     targetPort: 7070
   selector:"
thaum-xyz,ankhmorpork,402e9094a87becaeb66942174795e31610188b7c,paulfantom,pawel@krupa.net.pl,2021-10-11T16:36:04Z,paulfantom,pawel@krupa.net.pl,2021-10-11T16:36:04Z,apps/monitoring: fix pyrra ingress,apps/monitoring/manifests/pyrra/ingress.yaml,False,False,False,False,1,1,2,"---FILE: apps/monitoring/manifests/pyrra/ingress.yaml---
@@ -21,7 +21,7 @@ spec:
           service:
             name: pyrra-api
             port:
-              name: all
+              name: http
         path: /
         pathType: Prefix
   tls:"
thaum-xyz,ankhmorpork,88818383c0b932536f8f0495840b1777ab61e1b5,paulfantom,pawel@krupa.net.pl,2021-10-08T09:18:28Z,paulfantom,pawel@krupa.net.pl,2021-10-08T09:18:28Z,base/cert-manager: fix version updates,base/cert-manager/Makefile,False,False,False,False,2,2,4,"---FILE: base/cert-manager/Makefile---
@@ -7,6 +7,6 @@ cert-manager.yaml:
 
 .PHONY: version-update
 version-update:  ## Upgrade component version and image
-	$(TLD)/hack/version-update.sh .
-	if ! git diff-index --quiet HEAD .; then $(MAKE) generate; fi
+	curl --retry 5 --silent --fail -H ""Authorization: token $$GITHUB_TOKEN"" ""https://api.github.com/repos/jetstack/cert-manager/releases/latest"" 2>/dev/null | jq '.tag_name' | tr -d '""v' > VERSION
+	if ! git diff-index --quiet HEAD .; then $(MAKE) --always-make generate; fi
 "
thaum-xyz,ankhmorpork,b47b01a4cda42986f2b14c13faec6484e19cf463,paulfantom,pawel@krupa.net.pl,2021-08-18T08:18:36Z,paulfantom,pawel@krupa.net.pl,2021-08-18T08:18:36Z,base/kube-system/sealed-secrets: fix tolerations setting,base/kube-system/sealed-secrets/controller.yaml,False,False,False,False,0,1,1,"---FILE: base/kube-system/sealed-secrets/controller.yaml---
@@ -288,7 +288,6 @@ spec:
         operator: ""Equal""
         value: ""true""
         effect: ""NoSchedule""
-      tolerations:
       - key: ""node-role.kubernetes.io/control-plane""
         operator: ""Equal""
         value: ""true"""
thaum-xyz,ankhmorpork,1cbdcdfc046c393862709fda8b5089d1549aae51,paulfantom,pawel@krupa.net.pl,2021-08-18T07:42:42Z,paulfantom,pawel@krupa.net.pl,2021-08-18T07:42:42Z,apps/multimedia: fix ombi STS,apps/multimedia/jsonnet/ombi.libsonnet;apps/multimedia/manifests/ombi/statefulset.yaml;apps/multimedia/manifests/transmission/deployment.yaml,False,False,False,False,4,7,11,"---FILE: apps/multimedia/jsonnet/ombi.libsonnet---
@@ -108,7 +108,6 @@ function(params) {
     metadata: o._metadata,
     spec: {
       replicas: 1,
-      strategy: { type: 'Recreate' },
       serviceName: o.service.metadata.name,
       selector: { matchLabels: o._config.selectorLabels },
       template: {

---FILE: apps/multimedia/manifests/ombi/statefulset.yaml---
@@ -16,8 +16,6 @@ spec:
       app.kubernetes.io/name: ombi
       app.kubernetes.io/part-of: ombi
   serviceName: ombi
-  strategy:
-    type: Recreate
   template:
     metadata:
       labels:

---FILE: apps/multimedia/manifests/transmission/deployment.yaml---
@@ -70,16 +70,16 @@ spec:
         - mountPath: /config/openvpn-credentials.txt
           name: vpncreds
           subPath: openvpn-credentials.txt
-      securityContext:
-        sysctls:
-        - name: net.ipv4.tcp_adv_win_scale
-          value: ""4""
       dnsConfig:
         nameservers:
         - 1.1.1.1
         - 1.0.0.1
       dnsPolicy: None
       restartPolicy: Always
+      securityContext:
+        sysctls:
+        - name: net.ipv4.tcp_adv_win_scale
+          value: ""4""
       tolerations: []
       volumes:
       - name: vpncreds"
thaum-xyz,ankhmorpork,021ef8bca750657d27d0ac69155cb5e288a99e13,paulfantom,pawel@krupa.net.pl,2021-08-17T19:06:43Z,paulfantom,pawel@krupa.net.pl,2021-08-17T19:06:43Z,apps/multimedia: fix setting sysctls on transmission pod,apps/multimedia/manifests/transmission/deployment.yaml,False,False,False,False,4,3,7,"---FILE: apps/multimedia/manifests/transmission/deployment.yaml---
@@ -60,9 +60,6 @@ spec:
           capabilities:
             add:
             - NET_ADMIN
-          sysctls:
-          - name: net.ipv4.tcp_adv_win_scale
-            value: ""4""
         volumeMounts:
         - mountPath: /data
           name: data
@@ -73,6 +70,10 @@ spec:
         - mountPath: /config/openvpn-credentials.txt
           name: vpncreds
           subPath: openvpn-credentials.txt
+      securityContext:
+        sysctls:
+        - name: net.ipv4.tcp_adv_win_scale
+          value: ""4""
       dnsConfig:
         nameservers:
         - 1.1.1.1"
thaum-xyz,ankhmorpork,312f6f4361158d7c877053f6eb66442197c0f479,paulfantom,pawel@krupa.net.pl,2021-08-17T17:18:35Z,paulfantom,pawel@krupa.net.pl,2021-08-17T17:18:35Z,apps/multimedia: fix exportarr ports,apps/multimedia/manifests/radarr/service.yaml;apps/multimedia/manifests/radarr/statefulset.yaml;apps/multimedia/manifests/sonarr/statefulset.yaml,False,False,False,False,6,2,8,"---FILE: apps/multimedia/manifests/radarr/service.yaml---
@@ -17,7 +17,7 @@ spec:
     protocol: TCP
     targetPort: http-radarr
   - name: metrics
-    port: 9707
+    port: 9708
     targetPort: metrics
   selector:
     app.kubernetes.io/name: radarr

---FILE: apps/multimedia/manifests/radarr/statefulset.yaml---
@@ -60,11 +60,13 @@ spec:
           value: /radarr/config.xml
         - name: URL
           value: http://localhost
+        - name: PORT
+          value: ""9708""
         image: ghcr.io/onedr0p/exportarr:v0.6.1
         imagePullPolicy: IfNotPresent
         name: exportarr
         ports:
-        - containerPort: 9707
+        - containerPort: 9708
           name: metrics
         readinessProbe:
           failureThreshold: 5

---FILE: apps/multimedia/manifests/sonarr/statefulset.yaml---
@@ -60,6 +60,8 @@ spec:
           value: /sonarr/config.xml
         - name: URL
           value: http://localhost
+        - name: PORT
+          value: ""9707""
         image: ghcr.io/onedr0p/exportarr:v0.6.1
         imagePullPolicy: IfNotPresent
         name: exportarr"
thaum-xyz,ankhmorpork,bb91b24a5fdca167aefb4a5bc40c7bd08a80fc7e,paulfantom,pawel@krupa.net.pl,2021-08-17T15:52:32Z,paulfantom,pawel@krupa.net.pl,2021-08-17T15:52:32Z,apps/multimedia: fix crashlooping exportarr,apps/multimedia/manifests/exportarrRadarr/deployment.yaml;apps/multimedia/manifests/exportarrSonarr/deployment.yaml,False,False,False,False,2,0,2,"---FILE: apps/multimedia/manifests/exportarrRadarr/deployment.yaml---
@@ -27,6 +27,7 @@ spec:
     spec:
       containers:
       - args:
+        - exportarr
         - radarr
         env:
         - name: URL

---FILE: apps/multimedia/manifests/exportarrSonarr/deployment.yaml---
@@ -27,6 +27,7 @@ spec:
     spec:
       containers:
       - args:
+        - exportarr
         - sonarr
         env:
         - name: URL"
thaum-xyz,ankhmorpork,fc7d2fc7dd55b4d42c3b8e505b59901896a984bc,paulfantom,pawel@krupa.net.pl,2021-08-17T14:10:53Z,paulfantom,pawel@krupa.net.pl,2021-08-17T14:10:53Z,apps/multimedia/sonarr: fix pvcs,apps/multimedia/manifests/sonarr/pvc.yaml,False,False,False,False,2,2,4,"---FILE: apps/multimedia/manifests/sonarr/pvc.yaml---
@@ -1,12 +1,12 @@
 apiVersion: v1
 kind: PersistentVolumeClaim
 metadata:
-  name: sonarr-backup
+  name: sonarr-config
   namespace: multimedia
 spec:
   accessModes:
   - ReadWriteOnce
   resources:
     requests:
-      storage: 300Mi
+      storage: 600Mi
   storageClassName: managed-nfs-storage"
thaum-xyz,ankhmorpork,66222fb0fd7b1922dd7088a414cd024eac82f293,paulfantom,pawel@krupa.net.pl,2021-08-17T13:21:16Z,paulfantom,pawel@krupa.net.pl,2021-08-17T13:21:16Z,base/flux-apps: fix path to multimedia manifests,base/flux-apps/multimedia.yaml,False,False,False,False,1,1,2,"---FILE: base/flux-apps/multimedia.yaml---
@@ -5,7 +5,7 @@ metadata:
   namespace: flux-apps
 spec:
   interval: 60m0s
-  path: ./apps/multimedia
+  path: ./apps/multimedia/manifests
   prune: true
   sourceRef:
     kind: GitRepository"
thaum-xyz,ankhmorpork,e0b6e110aa23ad2f865876efbb8d0f8eb7988b70,paulfantom,pawel@krupa.net.pl,2021-08-13T16:07:55Z,paulfantom,pawel@krupa.net.pl,2021-08-13T16:07:55Z,apps/homer: fix esphome link,apps/homer/jsonnet/homer-configuration.yml;apps/homer/manifests/configmap.yaml;apps/homer/manifests/deployment.yaml,False,False,False,False,3,3,6,"---FILE: apps/homer/jsonnet/homer-configuration.yml---
@@ -159,4 +159,4 @@ services:
       - name: ESPHome
         logo: ""https://esphome.io/_static/favicon-512x512.png""
         <<: *Local
-        url: ""http://192.168.2.94:/""
+        url: ""http://192.168.2.94:6052/""

---FILE: apps/homer/manifests/configmap.yaml---
@@ -162,7 +162,7 @@ data:
           - name: ESPHome
             logo: ""https://esphome.io/_static/favicon-512x512.png""
             <<: *Local
-            url: ""http://192.168.2.94:/""
+            url: ""http://192.168.2.94:6052/""
 kind: ConfigMap
 metadata:
   labels:

---FILE: apps/homer/manifests/deployment.yaml---
@@ -18,7 +18,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: b0ecb4b2eaca0b7930d740cfc465b7a3
+        checksum.config/md5: 83271477baaa22ffb90d0b8bbd3f03d0
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homer"
thaum-xyz,ankhmorpork,acf307a98a66b3e5f45f02325bedd6c76f2d38fa,paulfantom,pawel@krupa.net.pl,2021-08-13T15:51:43Z,paulfantom,pawel@krupa.net.pl,2021-08-13T15:51:43Z,apps/homeassistant: fix deploying esphome Service,apps/homeassistant/jsonnet/main.jsonnet;apps/homeassistant/manifests/esphome/service.yaml,False,False,False,False,1,1,2,"---FILE: apps/homeassistant/jsonnet/main.jsonnet---
@@ -25,6 +25,7 @@ local all = {
       spec+: {
         loadBalancerIP: ""192.168.2.94"",
         type: ""LoadBalancer"",
+        clusterIP:: null,
       },
     },
   },

---FILE: apps/homeassistant/manifests/esphome/service.yaml---
@@ -9,7 +9,6 @@ metadata:
   name: esphome
   namespace: homeassistant
 spec:
-  clusterIP: None
   loadBalancerIP: 192.168.2.94
   ports:
   - name: http"
thaum-xyz,ankhmorpork,a2755c5b8165e4a7f42e8df522f2f33255123194,paulfantom,pawel@krupa.net.pl,2021-08-13T15:50:05Z,paulfantom,pawel@krupa.net.pl,2021-08-13T15:50:05Z,apps/homeassistant: fix deployment,apps/homeassistant/jsonnet/jsonnetfile.lock.json;apps/homeassistant/manifests/esphome/statefulset.yaml,False,False,False,False,5,4,9,"---FILE: apps/homeassistant/jsonnet/jsonnetfile.lock.json---
@@ -8,8 +8,8 @@
           ""subdir"": ""apps/esphome""
         }
       },
-      ""version"": ""00bc024098ffddded766af0f343827ebb7312e36"",
-      ""sum"": ""7JuXo53mv2GchZ+J3axlYJ65/PEKoJILYZWjlhKzjcY=""
+      ""version"": ""e09a27dec91702654d1467bd64e98d7604621d2e"",
+      ""sum"": ""22G/dTc3b+ank38iGrlZoIdIQ3e9zPvHQ6FrkFB2LeU=""
     },
     {
       ""source"": {
@@ -18,7 +18,7 @@
           ""subdir"": ""apps/homeassistant""
         }
       },
-      ""version"": ""00bc024098ffddded766af0f343827ebb7312e36"",
+      ""version"": ""e09a27dec91702654d1467bd64e98d7604621d2e"",
       ""sum"": ""h6hZIMIgWwO9SEDyQVv693Pun6SzLxH7UDpK0qNZtrI=""
     },
     {
@@ -28,7 +28,7 @@
           ""subdir"": ""utils""
         }
       },
-      ""version"": ""00bc024098ffddded766af0f343827ebb7312e36"",
+      ""version"": ""e09a27dec91702654d1467bd64e98d7604621d2e"",
       ""sum"": ""fpU9+wurrgNrnBmnPHYehqp3R5TqVWVdg8s8akBRmYM=""
     }
   ],

---FILE: apps/homeassistant/manifests/esphome/statefulset.yaml---
@@ -11,6 +11,7 @@ spec:
   selector:
     matchLabels:
       app.kubernetes.io/name: esphome
+  serviceName: esphome
   template:
     metadata:
       labels:"
thaum-xyz,ankhmorpork,caaedf4bf89945abac820348a393c69efb72b039,paulfantom,pawel@krupa.net.pl,2021-08-06T12:43:31Z,paulfantom,pawel@krupa.net.pl,2021-08-06T12:43:31Z,apps/monitoring: fix url path for pagespeed prober,apps/monitoring/config.jsonnet;apps/monitoring/manifests/pagespeed/probe.yaml,False,False,False,False,2,15,17,"---FILE: apps/monitoring/config.jsonnet---
@@ -212,22 +212,9 @@
       limits: { memory: '30Mi' },
     },
     sites: [
-      'prometheus.io',
+      'https://prometheus.io',
     ],
   },
-  uptimerobot: {
-    name: 'uptimerobot-exporter',
-    namespace: 'monitoring',
-    version: 'latest',
-    image: 'quay.io/paulfantom/uptimerobot:latest',
-    resources: {
-      requests: { cpu: '10m', memory: '13Mi' },
-      limits: { memory: '30Mi' },
-    },
-    port: 9705,
-    secretRefName: 'uptimerobot-api-key',
-    encryptedApiKey: 'AgC4xmdacpwqLMindlipAJDG3UhLuytkYmv7DU1PrNwfexpJwrp8Fp8CyHhz/4YPY00gHxc51oFCWSnfUzlcXn4a3sR+2srMr1GAl1SWUWszG2pO1jyXWiGhB6HrvfAWs3LeunQJCaTYuCoUvQ7zHtRIbK0AQEgQpG3Lkj9cH7Gu022ZSBvIeoz07h4pNL1fEF53TOE2gFs6U0d3q0nzgp2UK9XWcfmr27MafHGsImzfPM7UZKKHzRzvoWE2Q2R9uAushoG17An72TPHbGUtUzjxxjcOMi6/JjtZOhWhtx2LD3touBudqTFK9oDTpGH7ObU85FQX8NxiySMJ3faLkzGkGjv2zmLdgwxjQ3pbTJPJtRILpbCfiCF+qT2aKpp9pGcUAcsB14zLohGFFoayvXn91Bgyfh8/RmE5+3sZW1zOprsFe2TMZPF1Mkl0EpuE5qV0dzBC6TL6zPODDMjwjFNKP2f7spmrw5lULmPU4tKA2hb4zFvAW628fpXsqAtrhSU7NUrwlF2kktt5wiUK1WkSuZuM1FPuHWFE3G6t6DOC4ZUh0DdeQvUnR1947SIVzitVbrtUTrqvTTfrbb/2/A+nhPUU5VbR5J6VJCiJEjvSFHmUlxCft6+Vxe6Ypx2VlQWQo4SARrhgq11zhcZ/+CalvIb0BW+QFj2yGEORq68ThUuxdxbCERoIp8gVyQ+au32AbW5gdrQ+rDGXSNsN6McbDUWfMi30LuGe5TZNJDobVneR',
-  },
   sloth: {
     name: 'sloth',
     namespace: 'monitoring',

---FILE: apps/monitoring/manifests/pagespeed/probe.yaml---
@@ -15,4 +15,4 @@ spec:
   targets:
     staticConfig:
       static:
-      - prometheus.io
+      - https://prometheus.io"
thaum-xyz,ankhmorpork,5db40809a94fc3d305f5694a30a42af82f6de521,paulfantom,pawel@krupa.net.pl,2021-07-19T21:24:45Z,paulfantom,pawel@krupa.net.pl,2021-07-19T21:24:45Z,base/ingress-nginx: fix immutable field upgrade,base/ingress-nginx/deploy.yaml,False,False,False,False,0,2,2,"---FILE: base/ingress-nginx/deploy.yaml---
@@ -585,7 +585,6 @@ spec:
         
         app.kubernetes.io/name: ingress-nginx
         app.kubernetes.io/instance: ingress-nginx
-        app.kubernetes.io/version: 0.48.1
         
         app.kubernetes.io/component: admission-webhook
     spec:
@@ -633,7 +632,6 @@ spec:
         
         app.kubernetes.io/name: ingress-nginx
         app.kubernetes.io/instance: ingress-nginx
-        app.kubernetes.io/version: 0.48.1
         
         app.kubernetes.io/component: admission-webhook
     spec:"
thaum-xyz,ankhmorpork,c8e12a7d242c56d59f739012528e5188e3eb8310,paulfantom,pawel@krupa.net.pl,2021-07-19T09:03:57Z,paulfantom,pawel@krupa.net.pl,2021-07-19T09:03:57Z,apps/dns: debug log to analyze frequent CoreDNSLatencyHigh issues,apps/dns/Corefile;apps/dns/manifests/config.yaml,False,False,False,False,4,2,6,"---FILE: apps/dns/Corefile---
@@ -52,7 +52,7 @@
   prometheus :9153
   forward . tls://45.90.28.182 {
     tls_servername {$NEXTDNS_ID}.dns1.nextdns.io
-    health_check 5s
+    health_check 2s
   }
 }
 
@@ -62,4 +62,5 @@
     tls_servername {$NEXTDNS_ID}.dns2.nextdns.io
     health_check 5s
   }
+  debug
 }

---FILE: apps/dns/manifests/config.yaml---
@@ -55,7 +55,7 @@ data:
       prometheus :9153
       forward . tls://45.90.28.182 {
         tls_servername {$NEXTDNS_ID}.dns1.nextdns.io
-        health_check 5s
+        health_check 2s
       }
     }
 
@@ -65,6 +65,7 @@ data:
         tls_servername {$NEXTDNS_ID}.dns2.nextdns.io
         health_check 5s
       }
+      debug
     }
 kind: ConfigMap
 metadata:"
thaum-xyz,ankhmorpork,4261410fb3ec1f99adaa1f9aa719b30bacc45a65,paulfantom,pawel@krupa.net.pl,2021-07-17T14:41:43Z,paulfantom,pawel@krupa.net.pl,2021-07-17T14:41:43Z,apps/homer: fix photoprism tags,apps/homer/jsonnet/homer-configuration.yml;apps/homer/manifests/configmap.yaml;apps/homer/manifests/deployment.yaml,False,False,False,False,13,5,18,"---FILE: apps/homer/jsonnet/homer-configuration.yml---
@@ -59,6 +59,11 @@ tags:
   Testing: &Testing
     - tag: testing
       tagstyle: ""is-info""
+  LocalTesting: &LocalTesting
+    - tag: testing
+      tagstyle: ""is-info""
+    - tag: local
+      tagstyle: ""is-danger""
 
 # Services
 # First level array represent a group.
@@ -124,8 +129,7 @@ services:
         url: ""http://192.168.2.95:9091/transmission/web/""
       - name: Photoprism
         logo: ""https://dl.photoprism.org/assets/logo/logo-black-bold.svg""
-        <<: *Local
-        <<: *Testing
+        <<: *LocalTesting
         subtitle: ""Photo management""
         url: ""http://192.168.2.96""
 

---FILE: apps/homer/manifests/configmap.yaml---
@@ -62,6 +62,11 @@ data:
       Testing: &Testing
         - tag: testing
           tagstyle: ""is-info""
+      LocalTesting: &LocalTesting
+        - tag: testing
+          tagstyle: ""is-info""
+        - tag: local
+          tagstyle: ""is-danger""
 
     # Services
     # First level array represent a group.
@@ -127,8 +132,7 @@ data:
             url: ""http://192.168.2.95:9091/transmission/web/""
           - name: Photoprism
             logo: ""https://dl.photoprism.org/assets/logo/logo-black-bold.svg""
-            <<: *Local
-            <<: *Testing
+            <<: *LocalTesting
             subtitle: ""Photo management""
             url: ""http://192.168.2.96""
 

---FILE: apps/homer/manifests/deployment.yaml---
@@ -18,7 +18,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: e17a9b78e5218bed9d3dd41dfa726aee
+        checksum.config/md5: a60d8cb895ffaf6f5e6a76967bcfc367
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homer"
thaum-xyz,ankhmorpork,b7b266c53fa9aaa368efb73d3946a7034b3d4431,paulfantom,pawel@krupa.net.pl,2021-07-17T14:37:53Z,paulfantom,pawel@krupa.net.pl,2021-07-17T14:37:53Z,apps/homer: fix indent,apps/homer/jsonnet/homer-configuration.yml;apps/homer/manifests/configmap.yaml;apps/homer/manifests/deployment.yaml,False,False,False,False,3,3,6,"---FILE: apps/homer/jsonnet/homer-configuration.yml---
@@ -56,7 +56,7 @@ tags:
   Local: &Local
     - tag: local
       tagstyle: ""is-danger""
-  Testing: &test
+  Testing: &Testing
     - tag: testing
       tagstyle: ""is-info""
 

---FILE: apps/homer/manifests/configmap.yaml---
@@ -59,7 +59,7 @@ data:
       Local: &Local
         - tag: local
           tagstyle: ""is-danger""
-      Testing: &test
+      Testing: &Testing
         - tag: testing
           tagstyle: ""is-info""
 

---FILE: apps/homer/manifests/deployment.yaml---
@@ -18,7 +18,7 @@ spec:
   template:
     metadata:
       annotations:
-        checksum.config/md5: 70906d7d099f24840823989e3d693a02
+        checksum.config/md5: e17a9b78e5218bed9d3dd41dfa726aee
       labels:
         app.kubernetes.io/component: server
         app.kubernetes.io/name: homer"
thaum-xyz,ankhmorpork,bb2ad619782b14f662eee2c616495148a79991d7,paulfantom,pawel@krupa.net.pl,2021-07-15T13:25:42Z,paulfantom,pawel@krupa.net.pl,2021-07-15T13:25:42Z,apps/monitoring: fix alert labels,apps/monitoring/jsonnet/mixin/alerts/testing.yaml;apps/monitoring/manifests/other/thaumPrometheusRule.yaml,False,False,False,False,2,2,4,"---FILE: apps/monitoring/jsonnet/mixin/alerts/testing.yaml---
@@ -33,5 +33,5 @@ groups:
       summary: Service monitored by exporter is Down
     expr: '{__name__=~"".*_up"",__name__!=""node_network_up""} == 0'
     labels:
-      secerity: warning
+      severity: warning
 

---FILE: apps/monitoring/manifests/other/thaumPrometheusRule.yaml---
@@ -49,7 +49,7 @@ spec:
         summary: Service monitored by exporter is Down
       expr: '{__name__=~"".*_up"",__name__!=""node_network_up""} == 0'
       labels:
-        secerity: warning
+        severity: warning
   - name: custom node alert rules
     rules:
     - alert: PackagesAvailable"
thaum-xyz,ankhmorpork,652952bfe2169282bc959bf8acb60d139320a801,paulfantom,pawel@krupa.net.pl,2021-07-15T12:48:35Z,paulfantom,pawel@krupa.net.pl,2021-07-15T12:48:35Z,apps/nextcloud: fix setting custom values for php-fpm,apps/nextcloud/nextcloud/05_config.yaml;apps/nextcloud/nextcloud/06_statefulset.yaml,False,False,False,False,4,8,12,"---FILE: apps/nextcloud/nextcloud/05_config.yaml---
@@ -7,19 +7,14 @@ metadata:
   labels:
     app.kubernetes.io/name: nextcloud
 data:
-  status.conf: |
+  zzz-custom.conf: |
     [www]
-    pm.status_path = /status
-  www.conf: |
-    [www]
-    user = www-data
-    group = www-data
-    listen = 127.0.0.1:9000
     pm = dynamic
     pm.max_children = 42
     pm.start_servers = 12
     pm.min_spare_servers = 6
     pm.max_spare_servers = 18
+    pm.status_path = /status
 ---
 apiVersion: v1
 kind: ConfigMap

---FILE: apps/nextcloud/nextcloud/06_statefulset.yaml---
@@ -48,7 +48,8 @@ spec:
             port: phpfpm
         volumeMounts:
         - name: phpfpm-config
-          mountPath: /etc/php-fpm.d
+          mountPath: /usr/local/etc/php-fpm.d/zzz-custom.conf
+          subPath: zzz-custom.conf
         - name: php-config
           mountPath: /etc/php/conf.d
         - name: web"
thaum-xyz,ankhmorpork,0c2f87313c2a92038144444e8fbfdedb5b44b3de,paulfantom,pawel@krupa.net.pl,2021-07-07T14:29:59Z,paulfantom,pawel@krupa.net.pl,2021-07-07T14:30:55Z,"apps/monitoring: fix alert expression

Signed-off-by: paulfantom <pawel@krupa.net.pl>",apps/monitoring/jsonnet/mixin/alerts/openshift.yaml;apps/monitoring/manifests/other/thaumPrometheusRule.yaml,False,False,False,False,4,2,6,"---FILE: apps/monitoring/jsonnet/mixin/alerts/openshift.yaml---
@@ -26,7 +26,8 @@ groups:
                 count without(pod) (namespace_workload_pod:kube_pod_owner:relabel) > 1
               )
             )
-          ) == 1
+          )
+        )== 1
       for: 1h
       labels:
         severity: warning

---FILE: apps/monitoring/manifests/other/thaumPrometheusRule.yaml---
@@ -127,7 +127,8 @@ spec:
                 count without(pod) (namespace_workload_pod:kube_pod_owner:relabel) > 1
               )
             )
-          ) == 1
+          )
+        )== 1
       for: 1h
       labels:
         severity: warning"
thaum-xyz,ankhmorpork,2ad7de46c358d525db55d8dd8e852ff17d691717,paulfantom,pawel@krupa.net.pl,2021-07-02T21:53:11Z,paulfantom,pawel@krupa.net.pl,2021-07-02T21:53:11Z,fix runbook links,apps/monitoring/jsonnet/ext/rules/testing.json;apps/monitoring/jsonnet/ext/rules/thaum.json;apps/monitoring/manifests/other/testingPrometheusRule.yaml;apps/monitoring/manifests/other/thaumPrometheusRule.yaml;base/storage-system/managed-nfs-backup/prometheusRule.yaml,False,False,False,False,20,12,32,"---FILE: apps/monitoring/jsonnet/ext/rules/testing.json---
@@ -7,7 +7,7 @@
           ""alert"": ""CPUStealTimeHigh"",
           ""annotations"": {
             ""description"": ""CPU Steal Time is very high on {{ $labels.instance }} hypervisor. This can lead to VM being stalled."",
-            ""runbook_url"": ""https://runbooks.thaum.xyz/runbooks/ankhmorpork/CPUStealTimeHigh.md"",
+            ""runbook_url"": ""https://runbooks.thaum.xyz/runbooks/thaum-xyz/CPUStealTimeHigh"",
             ""summary"": ""High CPU Steal Time""
           },
           ""expr"": ""sum by (instance) (rate(node_cpu_seconds_total{mode=\""steal\""}[3m])) / count by (instance) (node_cpu_seconds_total{mode=\""steal\""}) > 0.1\n"",
@@ -24,7 +24,8 @@
           ""alert"": ""SiteNotUP"",
           ""annotations"": {
             ""description"": ""UptimeRobot reports site {{ $labels.url }} not to be up for 15m. Site is either paused or down."",
-            ""summary"": ""UptimeRobot reports site to be up.""
+            ""summary"": ""UptimeRobot reports site to be up."",
+            ""runbook_url"": ""https://runbooks.thaum.xyz/runbooks/thaum-xyz/SiteNotUP""
           },
           ""expr"": ""uptimerobot_monitor_status != 2"",
           ""for"": ""15m"",

---FILE: apps/monitoring/jsonnet/ext/rules/thaum.json---
@@ -7,7 +7,7 @@
           ""alert"": ""PackagesAvailable"",
           ""annotations"": {
             ""description"": ""{{ $value }} packages are available for upgrade. Maybe it is time to upgrade?"",
-            ""runbook_url"": ""https://runbooks.thaum.xyz/runbooks/ankhmorpork/PackagesAvailable.md"",
+            ""runbook_url"": ""https://runbooks.thaum.xyz/runbooks/thaum-xyz/PackagesAvailable"",
             ""summary"": ""Packages are available for upgrade""
           },
           ""expr"": ""sum by (node,instance) (yum_upgrades_pending) > 200\nor\nsum by (node,instance) (apt_upgrades_pending) > 200\n"",
@@ -20,7 +20,7 @@
           ""alert"": ""RebootRequired"",
           ""annotations"": {
             ""description"": ""Instance '{{ $labels.instance }}' was upgraded and now requires a reboot."",
-            ""runbook_url"": ""https://runbooks.thaum.xyz/runbooks/ankhmorpork/RebootRequired.md"",
+            ""runbook_url"": ""https://runbooks.thaum.xyz/runbooks/thaum-xyz/RebootRequired"",
             ""summary"": ""Reboot is required to finish package upgrade""
           },
           ""expr"": ""node_reboot_required > 0"",
@@ -38,7 +38,8 @@
           ""alert"": ""FilesystemReadOnly"",
           ""annotations"": {
             ""description"": ""Filesystem went read-only on {{ $labels.instance }}. Check FS for possible corruption."",
-            ""summary"": ""Filesystem went read-only possibly due to device error.""
+            ""summary"": ""Filesystem went read-only possibly due to device error."",
+            ""runbook_url"": ""https://runbooks.thaum.xyz/runbooks/thaum-xyz/FilesystemReadOnly""
           },
           ""expr"": ""node_filesystem_readonly{fstype=~\""(vfat|ext4|xfs)\""} != 0\n"",
           ""labels"": {
@@ -49,7 +50,8 @@
           ""alert"": ""TouchscreenNotAvailable"",
           ""annotations"": {
             ""description"": ""Powercycle device {{ $labels.instance }}"",
-            ""summary"": ""Touchscreen not available and automatic remediation failed to restore it""
+            ""summary"": ""Touchscreen not available and automatic remediation failed to restore it"",
+            ""runbook_url"": ""https://runbooks.thaum.xyz/runbooks/thaum-xyz/TouchscreenNotAvailable""
           },
           ""expr"": ""devices_input_touchscreen_up{environment=\""lancre.thaum.xyz\""} == 0 or absent(devices_input_touchscreen_up{environment=\""lancre.thaum.xyz\""})\n"",
           ""for"": ""30m"",
@@ -61,7 +63,8 @@
           ""alert"": ""TemperaturesNotAvailable"",
           ""annotations"": {
             ""description"": ""Temperature data is gone. Immediatelly switch off all relays and check OW bus."",
-            ""summary"": ""Cannot obtain temperature data""
+            ""summary"": ""Cannot obtain temperature data"",
+            ""runbook_url"": ""https://runbooks.thaum.xyz/runbooks/thaum-xyz/TemperaturesNotAvailable""
           },
           ""expr"": ""absent(evok_temperature_celsius{environment=\""lancre.thaum.xyz\""})\n"",
           ""for"": ""15m"",

---FILE: apps/monitoring/manifests/other/testingPrometheusRule.yaml---
@@ -14,7 +14,7 @@ spec:
       annotations:
         description: CPU Steal Time is very high on {{ $labels.instance }} hypervisor.
           This can lead to VM being stalled.
-        runbook_url: https://runbooks.thaum.xyz/runbooks/ankhmorpork/CPUStealTimeHigh.md
+        runbook_url: https://runbooks.thaum.xyz/runbooks/thaum-xyz/CPUStealTimeHigh
         summary: High CPU Steal Time
       expr: |
         sum by (instance) (rate(node_cpu_seconds_total{mode=""steal""}[3m])) / count by (instance) (node_cpu_seconds_total{mode=""steal""}) > 0.1
@@ -27,6 +27,7 @@ spec:
       annotations:
         description: UptimeRobot reports site {{ $labels.url }} not to be up for 15m.
           Site is either paused or down.
+        runbook_url: https://runbooks.thaum.xyz/runbooks/thaum-xyz/SiteNotUP
         summary: UptimeRobot reports site to be up.
       expr: uptimerobot_monitor_status != 2
       for: 15m

---FILE: apps/monitoring/manifests/other/thaumPrometheusRule.yaml---
@@ -14,7 +14,7 @@ spec:
       annotations:
         description: '{{ $value }} packages are available for upgrade. Maybe it is
           time to upgrade?'
-        runbook_url: https://runbooks.thaum.xyz/runbooks/ankhmorpork/PackagesAvailable.md
+        runbook_url: https://runbooks.thaum.xyz/runbooks/thaum-xyz/PackagesAvailable
         summary: Packages are available for upgrade
       expr: |
         sum by (node,instance) (yum_upgrades_pending) > 200
@@ -27,7 +27,7 @@ spec:
       annotations:
         description: Instance '{{ $labels.instance }}' was upgraded and now requires
           a reboot.
-        runbook_url: https://runbooks.thaum.xyz/runbooks/ankhmorpork/RebootRequired.md
+        runbook_url: https://runbooks.thaum.xyz/runbooks/thaum-xyz/RebootRequired
         summary: Reboot is required to finish package upgrade
       expr: node_reboot_required > 0
       for: 4h
@@ -39,6 +39,7 @@ spec:
       annotations:
         description: Filesystem went read-only on {{ $labels.instance }}. Check FS
           for possible corruption.
+        runbook_url: https://runbooks.thaum.xyz/runbooks/thaum-xyz/FilesystemReadOnly
         summary: Filesystem went read-only possibly due to device error.
       expr: |
         node_filesystem_readonly{fstype=~""(vfat|ext4|xfs)""} != 0
@@ -47,6 +48,7 @@ spec:
     - alert: TouchscreenNotAvailable
       annotations:
         description: Powercycle device {{ $labels.instance }}
+        runbook_url: https://runbooks.thaum.xyz/runbooks/thaum-xyz/TouchscreenNotAvailable
         summary: Touchscreen not available and automatic remediation failed to restore
           it
       expr: |
@@ -58,6 +60,7 @@ spec:
       annotations:
         description: Temperature data is gone. Immediatelly switch off all relays
           and check OW bus.
+        runbook_url: https://runbooks.thaum.xyz/runbooks/thaum-xyz/TemperaturesNotAvailable
         summary: Cannot obtain temperature data
       expr: |
         absent(evok_temperature_celsius{environment=""lancre.thaum.xyz""})

---FILE: base/storage-system/managed-nfs-backup/prometheusRule.yaml---
@@ -14,7 +14,7 @@ spec:
       annotations:
         description: '{{ printf ""%.4g"" $value }}% of the {{ $labels.namespace }}/{{ $labels.job }} backup jobs succeeded.'
         summary: Less than 90% of backup jobs succeeded.
-        runbook_url: https://runbooks.thaum.xyz/runbooks/ankhmorpork/BackupsNotCreated.md
+        runbook_url: https://runbooks.thaum.xyz/runbooks/thaum-xyz/BackupsNotCreated
       expr: |
         sum without (pod,instance) (backup_backups_successful_total) / sum without (pod,instance) (backup_backups_all_total) * 100 < 90
       labels:
@@ -23,7 +23,7 @@ spec:
       annotations:
         description: '{{ printf ""%.4g"" $value }}% of the {{ $labels.namespace }}/{{ $labels.job }} backup jobs succeeded.'
         summary: Less than 50% of backup jobs succeeded.
-        runbook_url: https://runbooks.thaum.xyz/runbooks/ankhmorpork/BackupsNotCreated.md
+        runbook_url: https://runbooks.thaum.xyz/runbooks/thaum-xyz/BackupsNotCreated
       expr: |
         sum without (pod,instance) (backup_backups_successful_total) / sum without (pod,instance) (backup_backups_all_total) * 100 < 50
       labels:"
thaum-xyz,ankhmorpork,61c8fddb64818816ac8d487d1750264225569282,paulfantom,pawel@krupa.net.pl,2021-07-02T21:39:01Z,paulfantom,pawel@krupa.net.pl,2021-07-02T21:39:01Z,apps/monitoring: fix runbook_urls,apps/monitoring/config.jsonnet;apps/monitoring/manifests/kubeStateMetrics/prometheusRule.yaml;apps/monitoring/manifests/nodeExporter/prometheusRule.yaml;apps/monitoring/manifests/prometheusOperator/prometheusRule.yaml;apps/monitoring/manifests/prometheusk8s/prometheusRule.yaml,False,False,False,False,159,147,306,"---FILE: apps/monitoring/config.jsonnet---
@@ -56,6 +56,11 @@
       requests: { cpu: '140m', memory: '1900Mi' },
       limits: { cpu: '1' },
     },
+    mixin+: {
+      _config: {
+        runbookURLPattern: 'https://runbooks.thaum.xyz/runbooks/prometheus/%s',
+      },
+    },
     // More in https://kubernetes.github.io/ingress-nginx/examples/auth/basic/
     // Password stored in bitwarden
     remoteWriteAuth: 'AgDGeT9BN6FzkFxAGIEfp/DSRL+jQ+CFoLiwAXUWC6QtfDFgWyQGauDRQqWvsPCWrCFNNSi0qsb8ObppQpVAftJLXZL+HI44me3AviYfMUPif7r5XKvcjhMkR+X7Cpk3/67ewlPDO5kHMuVosyVVbtGF4uznwPsi1mH+pRHsdSo76muFNNY/Cvr5stEtk+6UYakFZvti0Pe24nOI+mf0weBRLkyo45uZWOG4Lgok4AO84h9lKEJb6ROWYHs5neJua6JevdtQSOUo5xKyBCHNpkCrtkn0QkX6pSwwTL90s7em1anJL5pXy/oHSfaqa2VkQ6pDvgFylrXAr049sen8v5zaQoemQ9m3jKD8b5sZbBRhV5AxEGd8AH4f0S33zeVmwNyc0DiSE7riFPPTxvXPmW0JVubYSj7rr1aANNKW8UVzTRNutsX/SyxN8FgLPb41miuNVN0GOH8qA58l3t4LxaoDeAeLfg8VgOZ6yf2g1yhEzpSG98VIvt5hDxwlQvOlpUqXjckuV+bWDhiQYUQZFmzLWNJ/ki7E9mGM8kJ0nIQHiB3zg1cfEIoeSB0930upjll48/r57+m/TSjrymVgMzGwzJ/dd7tjeBagpVBsxnPdLY4PTKA6g5SJsDTDLzdWKsjHhoQR62WIUhC8QV8m8m9xYSAyfnaNVUVwh5b2q+5Q3agilaquFO3Ay1AZbS0x4n3K6WkJQHF2h1qR97PmW5YFrDH3gg6YzNyEDDEUQlNv6KL0D+NUzXXotxMH67A3',
@@ -64,7 +69,7 @@
     mixin+: {
       _config: {
         prometheusOperatorSelector: 'job=""prometheus-operator""',
-        runbookURLPattern: 'https://runbooks.thaum.xyz/runbooks/prometheus/%s',
+        runbookURLPattern: 'https://runbooks.thaum.xyz/runbooks/prometheus-operator/%s',
       },
     },
   },
@@ -130,6 +135,20 @@
       },
     },
   },
+  nodeExporter+: {
+    mixin+: {
+      _config: {
+        runbookURLPattern: 'https://runbooks.thaum.xyz/runbooks/node/%s',
+      },
+    },
+  },
+  kubeStateMetrics+: {
+    mixin+: {
+      _config: {
+        runbookURLPattern: 'https://runbooks.thaum.xyz/runbooks/kube-state-metrics/%s',
+      },
+    },
+  },
   grafana+: {
     version: '7.5.3',
     //image: 'grafana/grafana:7.5.3', // This is overridden in grafana-overrides.libsonnet

---FILE: apps/monitoring/manifests/kubeStateMetrics/prometheusRule.yaml---
@@ -18,7 +18,7 @@ spec:
         description: kube-state-metrics is experiencing errors at an elevated rate
           in list operations. This is likely causing it to not be able to expose metrics
           about Kubernetes objects correctly or at all.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubestatemetricslisterrors
+        runbook_url: https://runbooks.thaum.xyz/runbooks/kube-state-metrics/kubestatemetricslisterrors
         summary: kube-state-metrics is experiencing errors in list operations.
       expr: |
         (sum(rate(kube_state_metrics_list_total{job=""kube-state-metrics"",result=""error""}[5m]))
@@ -33,7 +33,7 @@ spec:
         description: kube-state-metrics is experiencing errors at an elevated rate
           in watch operations. This is likely causing it to not be able to expose
           metrics about Kubernetes objects correctly or at all.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubestatemetricswatcherrors
+        runbook_url: https://runbooks.thaum.xyz/runbooks/kube-state-metrics/kubestatemetricswatcherrors
         summary: kube-state-metrics is experiencing errors in watch operations.
       expr: |
         (sum(rate(kube_state_metrics_watch_total{job=""kube-state-metrics"",result=""error""}[5m]))
@@ -48,7 +48,7 @@ spec:
         description: kube-state-metrics pods are running with different --total-shards
           configuration, some Kubernetes objects may be exposed multiple times or
           not exposed at all.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubestatemetricsshardingmismatch
+        runbook_url: https://runbooks.thaum.xyz/runbooks/kube-state-metrics/kubestatemetricsshardingmismatch
         summary: kube-state-metrics sharding is misconfigured.
       expr: |
         stdvar (kube_state_metrics_total_shards{job=""kube-state-metrics""}) != 0
@@ -59,7 +59,7 @@ spec:
       annotations:
         description: kube-state-metrics shards are missing, some Kubernetes objects
           are not being exposed.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubestatemetricsshardsmissing
+        runbook_url: https://runbooks.thaum.xyz/runbooks/kube-state-metrics/kubestatemetricsshardsmissing
         summary: kube-state-metrics shards are missing.
       expr: |
         2^max(kube_state_metrics_total_shards{job=""kube-state-metrics""}) - 1

---FILE: apps/monitoring/manifests/nodeExporter/prometheusRule.yaml---
@@ -18,15 +18,15 @@ spec:
         description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
           has only {{ printf ""%.2f"" $value }}% available space left and is filling
           up.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/nodefilesystemspacefillingup
+        runbook_url: https://runbooks.thaum.xyz/runbooks/node/nodefilesystemspacefillingup
         summary: Filesystem is predicted to run out of space within the next 24 hours.
       expr: |
         (
-          node_filesystem_avail_bytes{job=""node-exporter"",fstype!=""""} / node_filesystem_size_bytes{job=""node-exporter"",fstype!=""""} * 100 < 40
+          node_filesystem_avail_bytes{job=""node"",fstype!=""""} / node_filesystem_size_bytes{job=""node"",fstype!=""""} * 100 < 40
         and
-          predict_linear(node_filesystem_avail_bytes{job=""node-exporter"",fstype!=""""}[6h], 24*60*60) < 0
+          predict_linear(node_filesystem_avail_bytes{job=""node"",fstype!=""""}[6h], 24*60*60) < 0
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!=""""} == 0
+          node_filesystem_readonly{job=""node"",fstype!=""""} == 0
         )
       for: 1h
       labels:
@@ -36,15 +36,15 @@ spec:
         description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
           has only {{ printf ""%.2f"" $value }}% available space left and is filling
           up fast.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/nodefilesystemspacefillingup
+        runbook_url: https://runbooks.thaum.xyz/runbooks/node/nodefilesystemspacefillingup
         summary: Filesystem is predicted to run out of space within the next 4 hours.
       expr: |
         (
-          node_filesystem_avail_bytes{job=""node-exporter"",fstype!=""""} / node_filesystem_size_bytes{job=""node-exporter"",fstype!=""""} * 100 < 15
+          node_filesystem_avail_bytes{job=""node"",fstype!=""""} / node_filesystem_size_bytes{job=""node"",fstype!=""""} * 100 < 20
         and
-          predict_linear(node_filesystem_avail_bytes{job=""node-exporter"",fstype!=""""}[6h], 4*60*60) < 0
+          predict_linear(node_filesystem_avail_bytes{job=""node"",fstype!=""""}[6h], 4*60*60) < 0
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!=""""} == 0
+          node_filesystem_readonly{job=""node"",fstype!=""""} == 0
         )
       for: 1h
       labels:
@@ -53,13 +53,13 @@ spec:
       annotations:
         description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
           has only {{ printf ""%.2f"" $value }}% available space left.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/nodefilesystemalmostoutofspace
+        runbook_url: https://runbooks.thaum.xyz/runbooks/node/nodefilesystemalmostoutofspace
         summary: Filesystem has less than 5% space left.
       expr: |
         (
-          node_filesystem_avail_bytes{job=""node-exporter"",fstype!=""""} / node_filesystem_size_bytes{job=""node-exporter"",fstype!=""""} * 100 < 5
+          node_filesystem_avail_bytes{job=""node"",fstype!=""""} / node_filesystem_size_bytes{job=""node"",fstype!=""""} * 100 < 5
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!=""""} == 0
+          node_filesystem_readonly{job=""node"",fstype!=""""} == 0
         )
       for: 1h
       labels:
@@ -68,13 +68,13 @@ spec:
       annotations:
         description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
           has only {{ printf ""%.2f"" $value }}% available space left.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/nodefilesystemalmostoutofspace
+        runbook_url: https://runbooks.thaum.xyz/runbooks/node/nodefilesystemalmostoutofspace
         summary: Filesystem has less than 3% space left.
       expr: |
         (
-          node_filesystem_avail_bytes{job=""node-exporter"",fstype!=""""} / node_filesystem_size_bytes{job=""node-exporter"",fstype!=""""} * 100 < 3
+          node_filesystem_avail_bytes{job=""node"",fstype!=""""} / node_filesystem_size_bytes{job=""node"",fstype!=""""} * 100 < 3
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!=""""} == 0
+          node_filesystem_readonly{job=""node"",fstype!=""""} == 0
         )
       for: 1h
       labels:
@@ -84,15 +84,15 @@ spec:
         description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
           has only {{ printf ""%.2f"" $value }}% available inodes left and is filling
           up.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/nodefilesystemfilesfillingup
+        runbook_url: https://runbooks.thaum.xyz/runbooks/node/nodefilesystemfilesfillingup
         summary: Filesystem is predicted to run out of inodes within the next 24 hours.
       expr: |
         (
-          node_filesystem_files_free{job=""node-exporter"",fstype!=""""} / node_filesystem_files{job=""node-exporter"",fstype!=""""} * 100 < 40
+          node_filesystem_files_free{job=""node"",fstype!=""""} / node_filesystem_files{job=""node"",fstype!=""""} * 100 < 40
         and
-          predict_linear(node_filesystem_files_free{job=""node-exporter"",fstype!=""""}[6h], 24*60*60) < 0
+          predict_linear(node_filesystem_files_free{job=""node"",fstype!=""""}[6h], 24*60*60) < 0
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!=""""} == 0
+          node_filesystem_readonly{job=""node"",fstype!=""""} == 0
         )
       for: 1h
       labels:
@@ -102,15 +102,15 @@ spec:
         description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
           has only {{ printf ""%.2f"" $value }}% available inodes left and is filling
           up fast.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/nodefilesystemfilesfillingup
+        runbook_url: https://runbooks.thaum.xyz/runbooks/node/nodefilesystemfilesfillingup
         summary: Filesystem is predicted to run out of inodes within the next 4 hours.
       expr: |
         (
-          node_filesystem_files_free{job=""node-exporter"",fstype!=""""} / node_filesystem_files{job=""node-exporter"",fstype!=""""} * 100 < 20
+          node_filesystem_files_free{job=""node"",fstype!=""""} / node_filesystem_files{job=""node"",fstype!=""""} * 100 < 20
         and
-          predict_linear(node_filesystem_files_free{job=""node-exporter"",fstype!=""""}[6h], 4*60*60) < 0
+          predict_linear(node_filesystem_files_free{job=""node"",fstype!=""""}[6h], 4*60*60) < 0
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!=""""} == 0
+          node_filesystem_readonly{job=""node"",fstype!=""""} == 0
         )
       for: 1h
       labels:
@@ -119,13 +119,13 @@ spec:
       annotations:
         description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
           has only {{ printf ""%.2f"" $value }}% available inodes left.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/nodefilesystemalmostoutoffiles
+        runbook_url: https://runbooks.thaum.xyz/runbooks/node/nodefilesystemalmostoutoffiles
         summary: Filesystem has less than 5% inodes left.
       expr: |
         (
-          node_filesystem_files_free{job=""node-exporter"",fstype!=""""} / node_filesystem_files{job=""node-exporter"",fstype!=""""} * 100 < 5
+          node_filesystem_files_free{job=""node"",fstype!=""""} / node_filesystem_files{job=""node"",fstype!=""""} * 100 < 5
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!=""""} == 0
+          node_filesystem_readonly{job=""node"",fstype!=""""} == 0
         )
       for: 1h
       labels:
@@ -134,13 +134,13 @@ spec:
       annotations:
         description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
           has only {{ printf ""%.2f"" $value }}% available inodes left.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/nodefilesystemalmostoutoffiles
+        runbook_url: https://runbooks.thaum.xyz/runbooks/node/nodefilesystemalmostoutoffiles
         summary: Filesystem has less than 3% inodes left.
       expr: |
         (
-          node_filesystem_files_free{job=""node-exporter"",fstype!=""""} / node_filesystem_files{job=""node-exporter"",fstype!=""""} * 100 < 3
+          node_filesystem_files_free{job=""node"",fstype!=""""} / node_filesystem_files{job=""node"",fstype!=""""} * 100 < 3
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!=""""} == 0
+          node_filesystem_readonly{job=""node"",fstype!=""""} == 0
         )
       for: 1h
       labels:
@@ -149,7 +149,7 @@ spec:
       annotations:
         description: '{{ $labels.instance }} interface {{ $labels.device }} has encountered
           {{ printf ""%.0f"" $value }} receive errors in the last two minutes.'
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/nodenetworkreceiveerrs
+        runbook_url: https://runbooks.thaum.xyz/runbooks/node/nodenetworkreceiveerrs
         summary: Network interface is reporting many receive errors.
       expr: |
         rate(node_network_receive_errs_total[2m]) / rate(node_network_receive_packets_total[2m]) > 0.01
@@ -160,7 +160,7 @@ spec:
       annotations:
         description: '{{ $labels.instance }} interface {{ $labels.device }} has encountered
           {{ printf ""%.0f"" $value }} transmit errors in the last two minutes.'
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/nodenetworktransmiterrs
+        runbook_url: https://runbooks.thaum.xyz/runbooks/node/nodenetworktransmiterrs
         summary: Network interface is reporting many transmit errors.
       expr: |
         rate(node_network_transmit_errs_total[2m]) / rate(node_network_transmit_packets_total[2m]) > 0.01
@@ -170,7 +170,7 @@ spec:
     - alert: NodeHighNumberConntrackEntriesUsed
       annotations:
         description: '{{ $value | humanizePercentage }} of conntrack entries are used.'
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/nodehighnumberconntrackentriesused
+        runbook_url: https://runbooks.thaum.xyz/runbooks/node/nodehighnumberconntrackentriesused
         summary: Number of conntrack are getting close to the limit.
       expr: |
         (node_nf_conntrack_entries / node_nf_conntrack_entries_limit) > 0.75
@@ -179,17 +179,17 @@ spec:
     - alert: NodeTextFileCollectorScrapeError
       annotations:
         description: Node Exporter text file collector failed to scrape.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/nodetextfilecollectorscrapeerror
+        runbook_url: https://runbooks.thaum.xyz/runbooks/node/nodetextfilecollectorscrapeerror
         summary: Node Exporter text file collector failed to scrape.
       expr: |
-        node_textfile_scrape_error{job=""node-exporter""} == 1
+        node_textfile_scrape_error{job=""node""} == 1
       labels:
         severity: warning
     - alert: NodeClockSkewDetected
       annotations:
         description: Clock on {{ $labels.instance }} is out of sync by more than 300s.
           Ensure NTP is configured correctly on this host.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/nodeclockskewdetected
+        runbook_url: https://runbooks.thaum.xyz/runbooks/node/nodeclockskewdetected
         summary: Clock skew detected.
       expr: |
         (
@@ -210,7 +210,7 @@ spec:
       annotations:
         description: Clock on {{ $labels.instance }} is not synchronising. Ensure
           NTP is configured on this host.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/nodeclocknotsynchronising
+        runbook_url: https://runbooks.thaum.xyz/runbooks/node/nodeclocknotsynchronising
         summary: Clock not synchronising.
       expr: |
         min_over_time(node_timex_sync_status[5m]) == 0
@@ -224,7 +224,7 @@ spec:
         description: RAID array '{{ $labels.device }}' on {{ $labels.instance }} is
           in degraded state due to one or more disks failures. Number of spare drives
           is insufficient to fix issue automatically.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/noderaiddegraded
+        runbook_url: https://runbooks.thaum.xyz/runbooks/node/noderaiddegraded
         summary: RAID Array is degraded
       expr: |
         node_md_disks_required - ignoring (state) (node_md_disks{state=""active""}) > 0
@@ -235,7 +235,7 @@ spec:
       annotations:
         description: At least one device in RAID array on {{ $labels.instance }} failed.
           Array '{{ $labels.device }}' needs attention and possibly a disk swap.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/noderaiddiskfailure
+        runbook_url: https://runbooks.thaum.xyz/runbooks/node/noderaiddiskfailure
         summary: Failed device in RAID array
       expr: |
         node_md_disks{state=""failed""} > 0
@@ -246,55 +246,55 @@ spec:
     - expr: |
         count without (cpu) (
           count without (mode) (
-            node_cpu_seconds_total{job=""node-exporter""}
+            node_cpu_seconds_total{job=""node""}
           )
         )
       record: instance:node_num_cpu:sum
     - expr: |
         1 - avg without (cpu, mode) (
-          rate(node_cpu_seconds_total{job=""node-exporter"", mode=""idle""}[5m])
+          rate(node_cpu_seconds_total{job=""node"", mode=""idle""}[5m])
         )
       record: instance:node_cpu_utilisation:rate5m
     - expr: |
         (
-          node_load1{job=""node-exporter""}
+          node_load1{job=""node""}
         /
-          instance:node_num_cpu:sum{job=""node-exporter""}
+          instance:node_num_cpu:sum{job=""node""}
         )
       record: instance:node_load1_per_cpu:ratio
     - expr: |
         1 - (
-          node_memory_MemAvailable_bytes{job=""node-exporter""}
+          node_memory_MemAvailable_bytes{job=""node""}
         /
-          node_memory_MemTotal_bytes{job=""node-exporter""}
+          node_memory_MemTotal_bytes{job=""node""}
         )
       record: instance:node_memory_utilisation:ratio
     - expr: |
-        rate(node_vmstat_pgmajfault{job=""node-exporter""}[5m])
+        rate(node_vmstat_pgmajfault{job=""node""}[5m])
       record: instance:node_vmstat_pgmajfault:rate5m
     - expr: |
-        rate(node_disk_io_time_seconds_total{job=""node-exporter"", device=~""mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""}[5m])
+        rate(node_disk_io_time_seconds_total{job=""node"", device!=""""}[5m])
       record: instance_device:node_disk_io_time_seconds:rate5m
     - expr: |
-        rate(node_disk_io_time_weighted_seconds_total{job=""node-exporter"", device=~""mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""}[5m])
+        rate(node_disk_io_time_weighted_seconds_total{job=""node"", device!=""""}[5m])
       record: instance_device:node_disk_io_time_weighted_seconds:rate5m
     - expr: |
         sum without (device) (
-          rate(node_network_receive_bytes_total{job=""node-exporter"", device!=""lo""}[5m])
+          rate(node_network_receive_bytes_total{job=""node"", device!=""lo""}[5m])
         )
       record: instance:node_network_receive_bytes_excluding_lo:rate5m
     - expr: |
         sum without (device) (
-          rate(node_network_transmit_bytes_total{job=""node-exporter"", device!=""lo""}[5m])
+          rate(node_network_transmit_bytes_total{job=""node"", device!=""lo""}[5m])
         )
       record: instance:node_network_transmit_bytes_excluding_lo:rate5m
     - expr: |
         sum without (device) (
-          rate(node_network_receive_drop_total{job=""node-exporter"", device!=""lo""}[5m])
+          rate(node_network_receive_drop_total{job=""node"", device!=""lo""}[5m])
         )
       record: instance:node_network_receive_drop_excluding_lo:rate5m
     - expr: |
         sum without (device) (
-          rate(node_network_transmit_drop_total{job=""node-exporter"", device!=""lo""}[5m])
+          rate(node_network_transmit_drop_total{job=""node"", device!=""lo""}[5m])
         )
       record: instance:node_network_transmit_drop_excluding_lo:rate5m

---FILE: apps/monitoring/manifests/prometheusOperator/prometheusRule.yaml---
@@ -17,7 +17,7 @@ spec:
       annotations:
         description: Errors while performing List operations in controller {{$labels.controller}}
           in {{$labels.namespace}} namespace.
-        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheusoperatorlisterrors
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus-operator/prometheusoperatorlisterrors
         summary: Errors while performing list operations in controller.
       expr: |
         (sum by (controller,namespace) (rate(prometheus_operator_list_operations_failed_total{job=""prometheus-operator""}[10m])) / sum by (controller,namespace) (rate(prometheus_operator_list_operations_total{job=""prometheus-operator""}[10m]))) > 0.4
@@ -28,7 +28,7 @@ spec:
       annotations:
         description: Errors while performing watch operations in controller {{$labels.controller}}
           in {{$labels.namespace}} namespace.
-        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheusoperatorwatcherrors
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus-operator/prometheusoperatorwatcherrors
         summary: Errors while performing watch operations in controller.
       expr: |
         (sum by (controller,namespace) (rate(prometheus_operator_watch_operations_failed_total{job=""prometheus-operator""}[10m])) / sum by (controller,namespace) (rate(prometheus_operator_watch_operations_total{job=""prometheus-operator""}[10m]))) > 0.4
@@ -39,7 +39,7 @@ spec:
       annotations:
         description: Controller {{ $labels.controller }} in {{ $labels.namespace }}
           namespace fails to reconcile {{ $value }} objects.
-        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheusoperatorsyncfailed
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus-operator/prometheusoperatorsyncfailed
         summary: Last controller reconciliation failed
       expr: |
         min_over_time(prometheus_operator_syncs{status=""failed"",job=""prometheus-operator""}[5m]) > 0
@@ -51,7 +51,7 @@ spec:
         description: '{{ $value | humanizePercentage }} of reconciling operations
           failed for {{ $labels.controller }} controller in {{ $labels.namespace }}
           namespace.'
-        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheusoperatorreconcileerrors
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus-operator/prometheusoperatorreconcileerrors
         summary: Errors while reconciling controller.
       expr: |
         (sum by (controller,namespace) (rate(prometheus_operator_reconcile_errors_total{job=""prometheus-operator""}[5m]))) / (sum by (controller,namespace) (rate(prometheus_operator_reconcile_operations_total{job=""prometheus-operator""}[5m]))) > 0.1
@@ -62,7 +62,7 @@ spec:
       annotations:
         description: Errors while reconciling Prometheus in {{ $labels.namespace }}
           Namespace.
-        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheusoperatornodelookuperrors
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus-operator/prometheusoperatornodelookuperrors
         summary: Errors while reconciling Prometheus.
       expr: |
         rate(prometheus_operator_node_address_lookup_errors_total{job=""prometheus-operator""}[5m]) > 0.1
@@ -73,7 +73,7 @@ spec:
       annotations:
         description: Prometheus operator in {{ $labels.namespace }} namespace isn't
           ready to reconcile {{ $labels.controller }} resources.
-        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheusoperatornotready
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus-operator/prometheusoperatornotready
         summary: Prometheus operator not ready
       expr: |
         min by(namespace, controller) (max_over_time(prometheus_operator_ready{job=""prometheus-operator""}[5m]) == 0)
@@ -85,7 +85,7 @@ spec:
         description: Prometheus operator in {{ $labels.namespace }} namespace rejected
           {{ printf ""%0.0f"" $value }} {{ $labels.controller }}/{{ $labels.resource
           }} resources.
-        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheusoperatorrejectedresources
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus-operator/prometheusoperatorrejectedresources
         summary: Resources rejected by Prometheus operator
       expr: |
         min_over_time(prometheus_operator_managed_resources{state=""rejected"",job=""prometheus-operator""}[5m]) > 0

---FILE: apps/monitoring/manifests/prometheusk8s/prometheusRule.yaml---
@@ -15,47 +15,46 @@ spec:
     rules:
     - alert: PrometheusBadConfig
       annotations:
-        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has failed to
-          reload its configuration.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/prometheusbadconfig
+        description: Prometheus {{$labels.instance}} has failed to reload its configuration.
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheusbadconfig
         summary: Failed Prometheus configuration reload.
       expr: |
         # Without max_over_time, failed scrapes could create false negatives, see
         # https://www.robustperception.io/alerting-on-gauges-in-prometheus-2-0 for details.
-        max_over_time(prometheus_config_last_reload_successful{job=""prometheus-k8s"",namespace=""monitoring""}[5m]) == 0
+        max_over_time(prometheus_config_last_reload_successful{job=""prometheus""}[5m]) == 0
       for: 10m
       labels:
         severity: critical
     - alert: PrometheusNotificationQueueRunningFull
       annotations:
-        description: Alert notification queue of Prometheus {{$labels.namespace}}/{{$labels.pod}}
-          is running full.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/prometheusnotificationqueuerunningfull
+        description: Alert notification queue of Prometheus {{$labels.instance}} is
+          running full.
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheusnotificationqueuerunningfull
         summary: Prometheus alert notification queue predicted to run full in less
           than 30m.
       expr: |
         # Without min_over_time, failed scrapes could create false negatives, see
         # https://www.robustperception.io/alerting-on-gauges-in-prometheus-2-0 for details.
         (
-          predict_linear(prometheus_notifications_queue_length{job=""prometheus-k8s"",namespace=""monitoring""}[5m], 60 * 30)
+          predict_linear(prometheus_notifications_queue_length{job=""prometheus""}[5m], 60 * 30)
         >
-          min_over_time(prometheus_notifications_queue_capacity{job=""prometheus-k8s"",namespace=""monitoring""}[5m])
+          min_over_time(prometheus_notifications_queue_capacity{job=""prometheus""}[5m])
         )
       for: 15m
       labels:
         severity: warning
     - alert: PrometheusErrorSendingAlertsToSomeAlertmanagers
       annotations:
         description: '{{ printf ""%.1f"" $value }}% errors while sending alerts from
-          Prometheus {{$labels.namespace}}/{{$labels.pod}} to Alertmanager {{$labels.alertmanager}}.'
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/prometheuserrorsendingalertstosomealertmanagers
+          Prometheus {{$labels.instance}} to Alertmanager {{$labels.alertmanager}}.'
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheuserrorsendingalertstosomealertmanagers
         summary: Prometheus has encountered more than 1% errors sending alerts to
           a specific Alertmanager.
       expr: |
         (
-          rate(prometheus_notifications_errors_total{job=""prometheus-k8s"",namespace=""monitoring""}[5m])
+          rate(prometheus_notifications_errors_total{job=""prometheus""}[5m])
         /
-          rate(prometheus_notifications_sent_total{job=""prometheus-k8s"",namespace=""monitoring""}[5m])
+          rate(prometheus_notifications_sent_total{job=""prometheus""}[5m])
         )
         * 100
         > 1
@@ -64,96 +63,92 @@ spec:
         severity: warning
     - alert: PrometheusNotConnectedToAlertmanagers
       annotations:
-        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} is not connected
-          to any Alertmanagers.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/prometheusnotconnectedtoalertmanagers
+        description: Prometheus {{$labels.instance}} is not connected to any Alertmanagers.
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheusnotconnectedtoalertmanagers
         summary: Prometheus is not connected to any Alertmanagers.
       expr: |
         # Without max_over_time, failed scrapes could create false negatives, see
         # https://www.robustperception.io/alerting-on-gauges-in-prometheus-2-0 for details.
-        max_over_time(prometheus_notifications_alertmanagers_discovered{job=""prometheus-k8s"",namespace=""monitoring""}[5m]) < 1
+        max_over_time(prometheus_notifications_alertmanagers_discovered{job=""prometheus""}[5m]) < 1
       for: 10m
       labels:
         severity: warning
     - alert: PrometheusTSDBReloadsFailing
       annotations:
-        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has detected
-          {{$value | humanize}} reload failures over the last 3h.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/prometheustsdbreloadsfailing
+        description: Prometheus {{$labels.instance}} has detected {{$value | humanize}}
+          reload failures over the last 3h.
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheustsdbreloadsfailing
         summary: Prometheus has issues reloading blocks from disk.
       expr: |
-        increase(prometheus_tsdb_reloads_failures_total{job=""prometheus-k8s"",namespace=""monitoring""}[3h]) > 0
+        increase(prometheus_tsdb_reloads_failures_total{job=""prometheus""}[3h]) > 0
       for: 4h
       labels:
         severity: warning
     - alert: PrometheusTSDBCompactionsFailing
       annotations:
-        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has detected
-          {{$value | humanize}} compaction failures over the last 3h.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/prometheustsdbcompactionsfailing
+        description: Prometheus {{$labels.instance}} has detected {{$value | humanize}}
+          compaction failures over the last 3h.
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheustsdbcompactionsfailing
         summary: Prometheus has issues compacting blocks.
       expr: |
-        increase(prometheus_tsdb_compactions_failed_total{job=""prometheus-k8s"",namespace=""monitoring""}[3h]) > 0
+        increase(prometheus_tsdb_compactions_failed_total{job=""prometheus""}[3h]) > 0
       for: 4h
       labels:
         severity: warning
     - alert: PrometheusNotIngestingSamples
       annotations:
-        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} is not ingesting
-          samples.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/prometheusnotingestingsamples
+        description: Prometheus {{$labels.instance}} is not ingesting samples.
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheusnotingestingsamples
         summary: Prometheus is not ingesting samples.
       expr: |
         (
-          rate(prometheus_tsdb_head_samples_appended_total{job=""prometheus-k8s"",namespace=""monitoring""}[5m]) <= 0
+          rate(prometheus_tsdb_head_samples_appended_total{job=""prometheus""}[5m]) <= 0
         and
           (
-            sum without(scrape_job) (prometheus_target_metadata_cache_entries{job=""prometheus-k8s"",namespace=""monitoring""}) > 0
+            sum without(scrape_job) (prometheus_target_metadata_cache_entries{job=""prometheus""}) > 0
           or
-            sum without(rule_group) (prometheus_rule_group_rules{job=""prometheus-k8s"",namespace=""monitoring""}) > 0
+            sum without(rule_group) (prometheus_rule_group_rules{job=""prometheus""}) > 0
           )
         )
       for: 10m
       labels:
         severity: warning
     - alert: PrometheusDuplicateTimestamps
       annotations:
-        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} is dropping
-          {{ printf ""%.4g"" $value  }} samples/s with different values but duplicated
-          timestamp.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/prometheusduplicatetimestamps
+        description: Prometheus {{$labels.instance}} is dropping {{ printf ""%.4g""
+          $value  }} samples/s with different values but duplicated timestamp.
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheusduplicatetimestamps
         summary: Prometheus is dropping samples with duplicate timestamps.
       expr: |
-        rate(prometheus_target_scrapes_sample_duplicate_timestamp_total{job=""prometheus-k8s"",namespace=""monitoring""}[5m]) > 0
+        rate(prometheus_target_scrapes_sample_duplicate_timestamp_total{job=""prometheus""}[5m]) > 0
       for: 10m
       labels:
         severity: warning
     - alert: PrometheusOutOfOrderTimestamps
       annotations:
-        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} is dropping
-          {{ printf ""%.4g"" $value  }} samples/s with timestamps arriving out of order.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/prometheusoutofordertimestamps
+        description: Prometheus {{$labels.instance}} is dropping {{ printf ""%.4g""
+          $value  }} samples/s with timestamps arriving out of order.
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheusoutofordertimestamps
         summary: Prometheus drops samples with out-of-order timestamps.
       expr: |
-        rate(prometheus_target_scrapes_sample_out_of_order_total{job=""prometheus-k8s"",namespace=""monitoring""}[5m]) > 0
+        rate(prometheus_target_scrapes_sample_out_of_order_total{job=""prometheus""}[5m]) > 0
       for: 10m
       labels:
         severity: warning
     - alert: PrometheusRemoteStorageFailures
       annotations:
-        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} failed to send
-          {{ printf ""%.1f"" $value }}% of the samples to {{ $labels.remote_name}}:{{
-          $labels.url }}
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/prometheusremotestoragefailures
+        description: Prometheus {{$labels.instance}} failed to send {{ printf ""%.1f""
+          $value }}% of the samples to {{ $labels.remote_name}}:{{ $labels.url }}
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheusremotestoragefailures
         summary: Prometheus fails to send samples to remote storage.
       expr: |
         (
-          (rate(prometheus_remote_storage_failed_samples_total{job=""prometheus-k8s"",namespace=""monitoring""}[5m]) or rate(prometheus_remote_storage_samples_failed_total{job=""prometheus-k8s"",namespace=""monitoring""}[5m]))
+          (rate(prometheus_remote_storage_failed_samples_total{job=""prometheus""}[5m]) or rate(prometheus_remote_storage_samples_failed_total{job=""prometheus""}[5m]))
         /
           (
-            (rate(prometheus_remote_storage_failed_samples_total{job=""prometheus-k8s"",namespace=""monitoring""}[5m]) or rate(prometheus_remote_storage_samples_failed_total{job=""prometheus-k8s"",namespace=""monitoring""}[5m]))
+            (rate(prometheus_remote_storage_failed_samples_total{job=""prometheus""}[5m]) or rate(prometheus_remote_storage_samples_failed_total{job=""prometheus""}[5m]))
           +
-            (rate(prometheus_remote_storage_succeeded_samples_total{job=""prometheus-k8s"",namespace=""monitoring""}[5m]) or rate(prometheus_remote_storage_samples_total{job=""prometheus-k8s"",namespace=""monitoring""}[5m]))
+            (rate(prometheus_remote_storage_succeeded_samples_total{job=""prometheus""}[5m]) or rate(prometheus_remote_storage_samples_total{job=""prometheus""}[5m]))
           )
         )
         * 100
@@ -163,114 +158,112 @@ spec:
         severity: critical
     - alert: PrometheusRemoteWriteBehind
       annotations:
-        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} remote write
-          is {{ printf ""%.1f"" $value }}s behind for {{ $labels.remote_name}}:{{ $labels.url
-          }}.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/prometheusremotewritebehind
+        description: Prometheus {{$labels.instance}} remote write is {{ printf ""%.1f""
+          $value }}s behind for {{ $labels.remote_name}}:{{ $labels.url }}.
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheusremotewritebehind
         summary: Prometheus remote write is behind.
       expr: |
         # Without max_over_time, failed scrapes could create false negatives, see
         # https://www.robustperception.io/alerting-on-gauges-in-prometheus-2-0 for details.
         (
-          max_over_time(prometheus_remote_storage_highest_timestamp_in_seconds{job=""prometheus-k8s"",namespace=""monitoring""}[5m])
+          max_over_time(prometheus_remote_storage_highest_timestamp_in_seconds{job=""prometheus""}[5m])
         - ignoring(remote_name, url) group_right
-          max_over_time(prometheus_remote_storage_queue_highest_sent_timestamp_seconds{job=""prometheus-k8s"",namespace=""monitoring""}[5m])
+          max_over_time(prometheus_remote_storage_queue_highest_sent_timestamp_seconds{job=""prometheus""}[5m])
         )
         > 120
       for: 15m
       labels:
         severity: critical
     - alert: PrometheusRemoteWriteDesiredShards
       annotations:
-        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} remote write
-          desired shards calculation wants to run {{ $value }} shards for queue {{
-          $labels.remote_name}}:{{ $labels.url }}, which is more than the max of {{
-          printf `prometheus_remote_storage_shards_max{instance=""%s"",job=""prometheus-k8s"",namespace=""monitoring""}`
+        description: Prometheus {{$labels.instance}} remote write desired shards calculation
+          wants to run {{ $value }} shards for queue {{ $labels.remote_name}}:{{ $labels.url
+          }}, which is more than the max of {{ printf `prometheus_remote_storage_shards_max{instance=""%s"",job=""prometheus""}`
           $labels.instance | query | first | value }}.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/prometheusremotewritedesiredshards
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheusremotewritedesiredshards
         summary: Prometheus remote write desired shards calculation wants to run more
           than configured max shards.
       expr: |
         # Without max_over_time, failed scrapes could create false negatives, see
         # https://www.robustperception.io/alerting-on-gauges-in-prometheus-2-0 for details.
         (
-          max_over_time(prometheus_remote_storage_shards_desired{job=""prometheus-k8s"",namespace=""monitoring""}[5m])
+          max_over_time(prometheus_remote_storage_shards_desired{job=""prometheus""}[5m])
         >
-          max_over_time(prometheus_remote_storage_shards_max{job=""prometheus-k8s"",namespace=""monitoring""}[5m])
+          max_over_time(prometheus_remote_storage_shards_max{job=""prometheus""}[5m])
         )
       for: 15m
       labels:
         severity: warning
     - alert: PrometheusRuleFailures
       annotations:
-        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has failed to
-          evaluate {{ printf ""%.0f"" $value }} rules in the last 5m.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/prometheusrulefailures
+        description: Prometheus {{$labels.instance}} has failed to evaluate {{ printf
+          ""%.0f"" $value }} rules in the last 5m.
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheusrulefailures
         summary: Prometheus is failing rule evaluations.
       expr: |
-        increase(prometheus_rule_evaluation_failures_total{job=""prometheus-k8s"",namespace=""monitoring""}[5m]) > 0
+        increase(prometheus_rule_evaluation_failures_total{job=""prometheus""}[5m]) > 0
       for: 15m
       labels:
         severity: critical
     - alert: PrometheusMissingRuleEvaluations
       annotations:
-        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has missed {{
-          printf ""%.0f"" $value }} rule group evaluations in the last 5m.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/prometheusmissingruleevaluations
+        description: Prometheus {{$labels.instance}} has missed {{ printf ""%.0f"" $value
+          }} rule group evaluations in the last 5m.
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheusmissingruleevaluations
         summary: Prometheus is missing rule evaluations due to slow rule group evaluation.
       expr: |
-        increase(prometheus_rule_group_iterations_missed_total{job=""prometheus-k8s"",namespace=""monitoring""}[5m]) > 0
+        increase(prometheus_rule_group_iterations_missed_total{job=""prometheus""}[5m]) > 0
       for: 15m
       labels:
         severity: warning
     - alert: PrometheusTargetLimitHit
       annotations:
-        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has dropped
-          {{ printf ""%.0f"" $value }} targets because the number of targets exceeded
-          the configured target_limit.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/prometheustargetlimithit
+        description: Prometheus {{$labels.instance}} has dropped {{ printf ""%.0f""
+          $value }} targets because the number of targets exceeded the configured
+          target_limit.
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheustargetlimithit
         summary: Prometheus has dropped targets because some scrape configs have exceeded
           the targets limit.
       expr: |
-        increase(prometheus_target_scrape_pool_exceeded_target_limit_total{job=""prometheus-k8s"",namespace=""monitoring""}[5m]) > 0
+        increase(prometheus_target_scrape_pool_exceeded_target_limit_total{job=""prometheus""}[5m]) > 0
       for: 15m
       labels:
         severity: warning
     - alert: PrometheusLabelLimitHit
       annotations:
-        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has dropped
-          {{ printf ""%.0f"" $value }} targets because some samples exceeded the configured
-          label_limit, label_name_length_limit or label_value_length_limit.
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/prometheuslabellimithit
+        description: Prometheus {{$labels.instance}} has dropped {{ printf ""%.0f""
+          $value }} targets because some samples exceeded the configured label_limit,
+          label_name_length_limit or label_value_length_limit.
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheuslabellimithit
         summary: Prometheus has dropped targets because some scrape configs have exceeded
           the labels limit.
       expr: |
-        increase(prometheus_target_scrape_pool_exceeded_label_limits_total{job=""prometheus-k8s"",namespace=""monitoring""}[5m]) > 0
+        increase(prometheus_target_scrape_pool_exceeded_label_limits_total{job=""prometheus""}[5m]) > 0
       for: 15m
       labels:
         severity: warning
     - alert: PrometheusTargetSyncFailure
       annotations:
-        description: '{{ printf ""%.0f"" $value }} targets in Prometheus {{$labels.namespace}}/{{$labels.pod}}
+        description: '{{ printf ""%.0f"" $value }} targets in Prometheus {{$labels.instance}}
           have failed to sync because invalid configuration was supplied.'
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/prometheustargetsyncfailure
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheustargetsyncfailure
         summary: Prometheus has failed to sync targets.
       expr: |
-        increase(prometheus_target_sync_failed_total{job=""prometheus-k8s"",namespace=""monitoring""}[30m]) > 0
+        increase(prometheus_target_sync_failed_total{job=""prometheus""}[30m]) > 0
       for: 5m
       labels:
         severity: critical
     - alert: PrometheusErrorSendingAlertsToAnyAlertmanager
       annotations:
         description: '{{ printf ""%.1f"" $value }}% minimum errors while sending alerts
-          from Prometheus {{$labels.namespace}}/{{$labels.pod}} to any Alertmanager.'
-        runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/prometheuserrorsendingalertstoanyalertmanager
+          from Prometheus {{$labels.instance}} to any Alertmanager.'
+        runbook_url: https://runbooks.thaum.xyz/runbooks/prometheus/prometheuserrorsendingalertstoanyalertmanager
         summary: Prometheus encounters more than 3% errors sending alerts to any Alertmanager.
       expr: |
         min without (alertmanager) (
-          rate(prometheus_notifications_errors_total{job=""prometheus-k8s"",namespace=""monitoring"",alertmanager!~``}[5m])
+          rate(prometheus_notifications_errors_total{job=""prometheus"",alertmanager!~``}[5m])
         /
-          rate(prometheus_notifications_sent_total{job=""prometheus-k8s"",namespace=""monitoring"",alertmanager!~``}[5m])
+          rate(prometheus_notifications_sent_total{job=""prometheus"",alertmanager!~``}[5m])
         )
         * 100
         > 3"
thaum-xyz,ankhmorpork,ffa83b0ba7d5d3a4614095df7ed917c297f8b7e6,paulfantom,pawel@krupa.net.pl,2021-06-18T19:59:53Z,paulfantom,pawel@krupa.net.pl,2021-06-18T19:59:53Z,base/flux-apps: fix cookbooks deployments,base/flux-apps/cookbook.yml;base/flux-apps/recipe.yml,False,False,False,False,2,2,4,"---FILE: base/flux-apps/cookbook.yml---
@@ -2,7 +2,7 @@ apiVersion: kustomize.toolkit.fluxcd.io/v1beta1
 kind: Kustomization
 metadata:
   name: cookbook
-  namespace: flux-system
+  namespace: flux-apps
 spec:
   interval: 60m0s
   path: ./apps/cookbook/manifests

---FILE: base/flux-apps/recipe.yml---
@@ -2,7 +2,7 @@ apiVersion: kustomize.toolkit.fluxcd.io/v1beta1
 kind: Kustomization
 metadata:
   name: recipe
-  namespace: flux-system
+  namespace: flux-apps
 spec:
   interval: 60m0s
   path: ./apps/recipe/manifests"
thaum-xyz,ankhmorpork,8f5bb64932308621537a90b70ec94a271500739e,paulfantom,pawel@krupa.net.pl,2021-06-15T09:54:53Z,paulfantom,pawel@krupa.net.pl,2021-06-15T09:54:53Z,base/flux-system: fix alert severity,base/flux-system/prometheusrule.yaml,False,False,False,False,1,1,2,"---FILE: base/flux-system/prometheusrule.yaml---
@@ -14,6 +14,6 @@ spec:
       expr: max(gotk_reconcile_condition{status=""False"",type=""Ready""}) by (namespace, name, kind) + on(namespace, name, kind) (max(gotk_reconcile_condition{status=""Deleted""}) by (namespace, name, kind)) * 2 == 1
       for: 10m
       labels:
-        severity: page
+        severity: warning
       annotations:
         summary: '{{ $labels.kind }} {{ $labels.namespace }}/{{ $labels.name }} reconciliation has been failing for more than ten minutes.'"
thaum-xyz,ankhmorpork,90f8f0e32e818116f7013d574b2944535b77ae81,paulfantom,pawel@krupa.net.pl,2021-06-14T18:30:10Z,paulfantom,pawel@krupa.net.pl,2021-06-14T18:30:10Z,apps/monitoring: fix sloth,apps/monitoring/jsonnet/lib/sloth.libsonnet;apps/monitoring/manifests/sloth/deployment.yaml,False,False,False,False,5,5,10,"---FILE: apps/monitoring/jsonnet/lib/sloth.libsonnet---
@@ -96,9 +96,9 @@ function(params) {
         spec: {
           containers: [container],
           serviceAccountName: $.serviceAccount.metadata.name,
-        },
-        nodeSelector: {
-          'kubernetes.io/os': 'linux',
+          nodeSelector: {
+            'kubernetes.io/os': 'linux',
+          },
         },
       },
     },

---FILE: apps/monitoring/manifests/sloth/deployment.yaml---
@@ -19,8 +19,6 @@ spec:
         app.kubernetes.io/component: exporter
         app.kubernetes.io/name: sloth
         app.kubernetes.io/version: 0.3.1
-    nodeSelector:
-      kubernetes.io/os: linux
     spec:
       containers:
       - args:
@@ -31,4 +29,6 @@ spec:
         - containerPort: 8081
           name: metrics
         resources: {}
+      nodeSelector:
+        kubernetes.io/os: linux
       serviceAccountName: sloth"
thaum-xyz,ankhmorpork,d668743d85808076a9ecffb7a986a315e8f96975,paulfantom,pawel@krupa.net.pl,2021-06-13T06:56:37Z,paulfantom,pawel@krupa.net.pl,2021-06-13T06:56:37Z,apps/dns: fix image name,apps/dns/jsonnet/settings.yaml;apps/dns/manifests/deployment.yaml,False,False,False,False,2,2,4,"---FILE: apps/dns/jsonnet/settings.yaml---
@@ -1,6 +1,6 @@
 ---
 version: ""1.8.4""  # application-version-from-github: coredns/coredns
-image: ""coredns:1.8.4""  # application-image-from-github: coredns/coredns
+image: ""coredns/coredns:1.8.4""  # application-image-from-github: coredns/coredns
 name: 'coredns'
 namespace: 'dns'
 loadBalancerIP: '192.168.2.99'

---FILE: apps/dns/manifests/deployment.yaml---
@@ -40,7 +40,7 @@ spec:
       - args:
         - -conf
         - /etc/coredns/Corefile
-        image: coredns:1.8.4
+        image: coredns/coredns:1.8.4
         imagePullPolicy: Always
         livenessProbe:
           failureThreshold: 5"
thaum-xyz,ankhmorpork,5d3721a7bc2dad24b133c0737a2dcac4a4731ec9,paulfantom,pawel@krupa.net.pl,2021-06-12T11:19:02Z,paulfantom,pawel@krupa.net.pl,2021-06-12T11:19:02Z,*: add local storage and fix node labels,ansible/10_storage.yml;ansible/70_k3s.yml;ansible/group_vars/k3s-local-storage.yml;ansible/host_vars/metal01.yml;ansible/inventory;apps/multimedia/manifests/plex-exporter/deployment.yaml;apps/multimedia/manifests/plex/statefulset.yaml;apps/multimedia/manifests/radarr/statefulset.yaml;apps/multimedia/manifests/sonarr/statefulset.yaml;apps/multimedia/manifests/transmission/deployment.yaml,False,False,False,False,27,11,38,"---FILE: ansible/10_storage.yml---
@@ -24,3 +24,4 @@
         minute: ""*/10""
         job: ""/usr/local/bin/smartmon.sh | sponge /var/lib/node_exporter/smartmon.prom""
     when: enable_smartmon is defined
+

---FILE: ansible/70_k3s.yml---
@@ -50,6 +50,12 @@
         state: present
       with_items:
         - ""{{ 'nfs-common' if (ansible_os_family | lower == 'debian') else 'nfs-utils' }}""
+    - name: Add node local storage labels
+      set_fact:
+        k3s_extra_agent_args: ""{{ k3s_extra_agent_args }} --node-label storage.infra/local=true""
+      when:
+        - local_storage_device is defined
+        - local_storage_device != """"
     - name: Add node labels
       set_fact:
         k3s_extra_agent_args: ""{{ k3s_extra_agent_args }} --node-label {{ node_labels | join(' --node-label ') }}""

---FILE: ansible/group_vars/k3s-local-storage.yml---
@@ -0,0 +1,6 @@
+system_mountpoints:
+  - description: k3s local storage
+    before: k3s-node.service
+    device: ""{{ local_storage_device }}""
+    mountpoint: ""/var/lib/rancher/k3s/storage""
+    type: ""ext4""

---FILE: ansible/host_vars/metal01.yml---
@@ -11,10 +11,7 @@ nfs_exports:
 #   - ""node.infra/hypervisor=true:NoSchedule""
 
 node_labels:
-  - ""storage.infra/local=true""
-  - ""storage.infra/direct=true""
-  - ""storage.infra/replicated=true""
-  - ""storage.infra/capacious=true""
+  - ""storage.infra/main=true""
   - ""gpu.infra/nvidia=true""
 
 system_mountpoints:

---FILE: ansible/inventory---
@@ -4,11 +4,11 @@
 # Assign enable_smartmon=true label to enable SMART monitoring of disks
 
 master01 ansible_user=ubuntu ansible_host=192.168.2.30
-node01   ansible_user=ubuntu ansible_host=192.168.2.31 network=fast
-node02   ansible_user=ubuntu ansible_host=192.168.2.32 network=fast
+node01   ansible_user=ubuntu ansible_host=192.168.2.31 network=fast local_storage_device=/dev/disk/by-uuid/e13f201c-6898-4f5f-85f5-8494189f50a1
+node02   ansible_user=ubuntu ansible_host=192.168.2.32 network=fast local_storage_device=/dev/disk/by-uuid/734bcf0d-0e5e-4de2-af92-f786f6b7b951
 node03   ansible_user=ubuntu ansible_host=192.168.2.33
 node04   ansible_user=ubuntu ansible_host=192.168.2.34
-metal01  ansible_user=ubuntu ansible_host=192.168.2.40 network=fast enable_smartmon=true
+metal01  ansible_user=ubuntu ansible_host=192.168.2.40 network=fast local_storage_device=/dev/ubuntu-vg/k3s-local-storage enable_smartmon=true
 
 [fancontroler]
 master01
@@ -20,6 +20,12 @@ node0[1:4]
 [nvidia]
 metal01
 
+# Remove this group when all hosts have local storage disks
+[k3s-local-storage]
+node01
+node02
+metal01
+
 [k3s-master]
 master01
 

---FILE: apps/multimedia/manifests/plex-exporter/deployment.yaml---
@@ -29,7 +29,7 @@ spec:
       containers:
       - envFrom:
         - secretRef:
-            name: plex-token  # TODO: consider moving this to a separate secret
+            name: plex-token
         name: plex-metrics
         image: quay.io/paulfantom/plex_exporter:0.2.2
         imagePullPolicy: IfNotPresent

---FILE: apps/multimedia/manifests/plex/statefulset.yaml---
@@ -97,5 +97,5 @@ spec:
         emptyDir: {}
       nodeSelector:
         kubernetes.io/arch: ""amd64""
-        kubernetes.io/hostname: ""metal01""  # TODO: remove this after tests
+        storage.infra/main: ""true""
       tolerations: []

---FILE: apps/multimedia/manifests/radarr/statefulset.yaml---
@@ -64,4 +64,5 @@ spec:
           claimName: radarr-config
       nodeSelector:
         kubernetes.io/arch: ""amd64""
+        storage.infra/main: ""true""
       tolerations: []

---FILE: apps/multimedia/manifests/sonarr/statefulset.yaml---
@@ -66,4 +66,5 @@ spec:
           claimName: sonarr-config
       nodeSelector:
         kubernetes.io/arch: ""amd64""
+        storage.infra/main: ""true""
       tolerations: []

---FILE: apps/multimedia/manifests/transmission/deployment.yaml---
@@ -90,6 +90,4 @@ spec:
       - name: completed
         persistentVolumeClaim:
           claimName: torrents
-      nodeSelector:
-        kubernetes.io/arch: ""amd64""  # TODO: images are now multi-arch, consider removing this selector
       tolerations: []"
thaum-xyz,ankhmorpork,891a40870695441730a86bbdadee0bc3866dadfb,paulfantom,pawel@krupa.net.pl,2021-06-08T20:43:35Z,paulfantom,pawel@krupa.net.pl,2021-06-08T20:43:35Z,apps/blog: fix PVC metadata,apps/blog/jsonnet/main.jsonnet;apps/blog/manifests/pvc.yaml,False,False,False,False,7,1,8,"---FILE: apps/blog/jsonnet/main.jsonnet---
@@ -7,7 +7,7 @@ local config = std.parseYaml(configYAML)[0];
 
 local all = ghost(config) + {
   pvc+: {
-    metadata: {
+    metadata+: {
       name: 'data',
     },
     spec+: {

---FILE: apps/blog/manifests/pvc.yaml---
@@ -1,7 +1,13 @@
 apiVersion: v1
 kind: PersistentVolumeClaim
 metadata:
+  labels:
+    app.kubernetes.io/component: server
+    app.kubernetes.io/name: ghost
+    app.kubernetes.io/part-of: ghost
+    app.kubernetes.io/version: 3.32.2
   name: data
+  namespace: blog
 spec:
   accessModes:
   - ReadWriteMany"
thaum-xyz,ankhmorpork,575a74685ff665bd0685f3b9fff0c383df35ed71,paulfantom,pawel@krupa.net.pl,2021-06-07T13:21:29Z,paulfantom,pawel@krupa.net.pl,2021-06-07T13:21:29Z,base/flux-system: set notifications to error only,base/flux-system/configs/notifications.yaml,False,False,False,False,1,1,2,"---FILE: base/flux-system/configs/notifications.yaml---
@@ -18,7 +18,7 @@ metadata:
 spec:
   providerRef:
     name: slack
-  eventSeverity: info  # TODO: consider changing to `error`
+  eventSeverity: error
   eventSources:
     - kind: GitRepository
       name: '*'"
thaum-xyz,ankhmorpork,49300b27c76f6efd1f98877b781be7d1dd0f141a,paulfantom,pawel@krupa.net.pl,2021-06-07T13:00:41Z,paulfantom,pawel@krupa.net.pl,2021-06-07T13:00:41Z,apps/monitoring: fix url to pagespeed exporter,apps/monitoring/jsonnet/lib/lighthouse.libsonnet;apps/monitoring/manifests/pagespeed/probe.yaml,False,False,False,False,2,2,4,"---FILE: apps/monitoring/jsonnet/lib/lighthouse.libsonnet---
@@ -92,7 +92,7 @@ function(params) {
     metadata: $.metadata,
     spec: {
       prober: {
-        url: $.service.metadata.name + '.' + $.config.namespace + ':9271',
+        url: $.service.metadata.name + '.' + $.config.namespace + '.svc:9271',
       },
       targets: {
         staticConfig: {

---FILE: apps/monitoring/manifests/pagespeed/probe.yaml---
@@ -9,7 +9,7 @@ metadata:
   namespace: monitoring
 spec:
   prober:
-    url: pagespeed.monitoring:9271
+    url: pagespeed.monitoring.svc:9271
   targets:
     staticConfig:
       static:"
thaum-xyz,ankhmorpork,e12b40677a150492b08c0e3e1457aabe7372f3ec,paulfantom,pawel@krupa.net.pl,2021-06-04T16:07:16Z,paulfantom,pawel@krupa.net.pl,2021-06-04T16:07:16Z,base/flux-system/configs: fix ingress annotations,base/flux-system/configs/ingress.yaml,False,False,False,False,1,1,2,"---FILE: base/flux-system/configs/ingress.yaml---
@@ -4,7 +4,7 @@ metadata:
   annotations:
     cert-manager.io/cluster-issuer: letsencrypt-prod
     kubernetes.io/ingress.class: nginx
-    nginx.ingress.kubernetes.io/limit-rps: 10
+    nginx.ingress.kubernetes.io/limit-rps: ""10""
   name: flux
   namespace: flux-system
 spec:"
thaum-xyz,ankhmorpork,49f848562b7ea7199c2fa6f3175038fc2249f11f,paulfantom,pawel@krupa.net.pl,2021-06-04T15:08:23Z,paulfantom,pawel@krupa.net.pl,2021-06-04T15:08:23Z,base/flux-system/apps: fix split networking app,base/flux-system/apps/ingress-nginx.yaml;base/flux-system/apps/metallb-system.yaml,False,False,False,False,15,2,17,"---FILE: base/flux-system/apps/ingress-nginx.yaml---
@@ -1,11 +1,11 @@
 apiVersion: kustomize.toolkit.fluxcd.io/v1beta1
 kind: Kustomization
 metadata:
-  name: networking
+  name: ingress-nginx
   namespace: flux-system
 spec:
   interval: 5m0s
-  path: ./base/networking
+  path: ./base/ingress-nginx
   prune: true
   sourceRef:
     kind: GitRepository

---FILE: base/flux-system/apps/metallb-system.yaml---
@@ -0,0 +1,13 @@
+apiVersion: kustomize.toolkit.fluxcd.io/v1beta1
+kind: Kustomization
+metadata:
+  name: metallb-system
+  namespace: flux-system
+spec:
+  interval: 5m0s
+  path: ./base/metallb-system
+  prune: true
+  sourceRef:
+    kind: GitRepository
+    name: ankhmorpork
+  validation: client"
thaum-xyz,ankhmorpork,dacb5355aff7d2becb8d1965225d640b8adbca69,paulfantom,pawel@krupa.net.pl,2021-06-04T14:58:11Z,paulfantom,pawel@krupa.net.pl,2021-06-04T14:58:11Z,base/storage-system: fix kustomization.yaml file,base/storage-system/kustomization.yaml,False,False,False,False,3,3,6,"---FILE: base/storage-system/kustomization.yaml---
@@ -5,9 +5,9 @@ apiVersion: kustomize.config.k8s.io/v1beta1
 kind: Kustomization
 resources:
 - ./managed-nfs-backup/credentials.yaml
-- ./managed-nfs-backup deployment.yaml
-- ./managed-nfs-backup podMonitor.yaml
-- ./managed-nfs-backup prometheusRule.yaml
+- ./managed-nfs-backup/deployment.yaml
+- ./managed-nfs-backup/podMonitor.yaml
+- ./managed-nfs-backup/prometheusRule.yaml
 - ./managed-nfs-storage/class.yaml
 - ./managed-nfs-storage/deployment.yaml
 - ./managed-nfs-storage/rbac.yaml"
thaum-xyz,ankhmorpork,a9cf4ac9c33a5d06d3b880fed352aba66421b4a8,paulfantom,pawel@krupa.net.pl,2021-06-04T14:36:47Z,paulfantom,pawel@krupa.net.pl,2021-06-04T14:36:47Z,/base/flux-system/apps: fix cert-manager deployment,base/flux-system/apps/cert-manager.yaml,False,False,False,False,1,1,2,"---FILE: base/flux-system/apps/cert-manager.yaml---
@@ -5,7 +5,7 @@ metadata:
   namespace: flux-system
 spec:
   interval: 5m0s
-  path: ./apps/cert-manager
+  path: ./base/cert-manager
   prune: true
   sourceRef:
     kind: GitRepository"
thaum-xyz,ankhmorpork,532fa0796ca005cf9e96c32fb67dce248a12aa5d,paulfantom,pawel@krupa.net.pl,2021-06-04T13:59:33Z,paulfantom,pawel@krupa.net.pl,2021-06-04T13:59:33Z,base/flux-system: fix downloading podmonitor definition,base/flux-system/Makefile;base/flux-system/podmonitor.yaml,False,False,False,False,26,1348,1374,"---FILE: base/flux-system/Makefile---
@@ -5,5 +5,5 @@ update: version-update
 
 .PHONY: version-update
 version-update:
-	wget https://github.com/fluxcd/flux2/blob/main/manifests/monitoring/monitoring-config/podmonitor.yaml -O podmonitor.yaml
-	wget https://github.com/fluxcd/flux2/releases/latest/download/install.yaml -O install.yaml 
+	wget -O podmonitor.yaml https://raw.githubusercontent.com/fluxcd/flux2/main/manifests/monitoring/monitoring-config/podmonitor.yaml
+	wget -O install.yaml https://github.com/fluxcd/flux2/releases/latest/download/install.yaml"
thaum-xyz,ankhmorpork,e5cf337b7dbf7578acc2a7b2facb364f29c21595,paulfantom,pawel@krupa.net.pl,2021-06-01T17:03:03Z,paulfantom,pawel@krupa.net.pl,2021-06-01T17:03:03Z,apps/homeassistant: fix label selector,apps/homeassistant/jsonnet/homeassistant.libsonnet;apps/homeassistant/manifests/serviceMonitor.yaml,False,False,False,False,7,4,11,"---FILE: apps/homeassistant/jsonnet/homeassistant.libsonnet---
@@ -134,7 +134,9 @@ function(params) {
         path: '/api/prometheus',
         bearerTokenSecret: h._config.apiTokenSecretKeySelector,
       }],
-      selector: h._config.selectorLabels,
+      selector: {
+        matchLabels: h._config.selectorLabels,
+      },
     },
   },
 

---FILE: apps/homeassistant/manifests/serviceMonitor.yaml---
@@ -17,6 +17,7 @@ spec:
     path: /api/prometheus
     port: http
   selector:
-    app.kubernetes.io/component: server
-    app.kubernetes.io/name: homeassistant
-    app.kubernetes.io/part-of: homeassistant
+    matchLabels:
+      app.kubernetes.io/component: server
+      app.kubernetes.io/name: homeassistant
+      app.kubernetes.io/part-of: homeassistant"
thaum-xyz,ankhmorpork,a584267a7492b419353261a0f7593941406a8528,paulfantom,pawel@krupa.net.pl,2021-05-31T10:55:21Z,paulfantom,pawel@krupa.net.pl,2021-05-31T10:55:21Z,apps/nextcloud/mysql: fix secret name,apps/nextcloud/mysql/05_deployment.yaml,False,False,False,False,2,2,4,"---FILE: apps/nextcloud/mysql/05_deployment.yaml---
@@ -100,12 +100,12 @@ spec:
           valueFrom:
             secretKeyRef:
               key: exporter_user
-              name: mysql-creds
+              name: mysql-init
         - name: PASS
           valueFrom:
             secretKeyRef:
               key: exporter_pass
-              name: mysql-creds
+              name: mysql-init
         - name: DATA_SOURCE_NAME
           value: ""$(USER):$(PASS)@(127.0.0.1:3306)/""
         image: quay.io/prometheus/mysqld-exporter:latest"
thaum-xyz,ankhmorpork,193087a7763ea5b95b7144040df8fe9981bc68f6,paulfantom,pawel@krupa.net.pl,2021-05-25T15:13:35Z,paulfantom,pawel@krupa.net.pl,2021-05-25T15:13:35Z,apps/blog/jsonnet: fix typo,apps/blog/jsonnet/main.jsonnet,False,False,False,False,2,2,4,"---FILE: apps/blog/jsonnet/main.jsonnet---
@@ -1,11 +1,11 @@
-local mealie = import './ghost.libsonnet';
+local ghost = import './ghost.libsonnet';
 
 local configYAML = (importstr './settings.yaml');
 
 // Join multiple configuration sources
 local config = std.parseYaml(configYAML)[0];
 
-local all = mealie(config) + {
+local all = ghost(config) + {
   pvc+: {
     metadata: {
       name: 'data',"
thaum-xyz,ankhmorpork,41b78ab759c8f58fdcedc5f527122291d7d5ca5b,paulfantom,pawel@krupa.net.pl,2021-05-23T17:33:36Z,paulfantom,pawel@krupa.net.pl,2021-05-23T17:33:36Z,*: fixes to version updater,apps/homer/jsonnet/settings.yaml;hack/version-update.sh,False,False,False,False,7,2,9,"---FILE: apps/homer/jsonnet/settings.yaml---
@@ -1,5 +1,5 @@
 ---
-version: ""20.12.19""
+version: ""20.12.19""  # version-updater-repo: bastienwirtz/homer
 image: ""b4bz/homer:20.12.19""
 namespace: ""homer""
 replicas: 2

---FILE: hack/version-update.sh---
@@ -1,6 +1,6 @@
 #!/bin/bash
 
-set -euo pipefail
+set -eo pipefail
 
 # Test only for homer for now
 FILE=apps/homer/jsonnet/settings.yaml
@@ -15,6 +15,11 @@ REPO=$(grep version-updater-repo ""$FILE"" | rev | cut -d: -f1 | xargs | rev)
 LATEST=""$(get_latest_version ""$REPO"")""
 CURRENT=$(grep 'version:' ""$FILE"" | cut -d\"" -f2)
 
+if [ ""$LATEST"" == """" ]; then
+    echo ""Latest version detection failed""
+    exit 1
+fi
+
 echo ""Current: $CURRENT, Latest: $LATEST""
 if [ ""$CURRENT"" == ""$LATEST"" ]; then
     echo ""Nothing to do"""
thaum-xyz,ankhmorpork,4bf5df3c77829c1e4e0c0412af8f0d6fa9d8ae8d,paulfantom,pawel@krupa.net.pl,2021-05-11T12:44:20Z,paulfantom,pawel@krupa.net.pl,2021-05-11T12:44:20Z,apps/monitoring: fix issue with incorrect base64 encoding,apps/monitoring/manifests/prometheusk8s/additionalScrapeConfigs.yaml;apps/monitoring/raw/prometheusk8s-additionalScrapeConfigs.yaml,False,False,False,False,4,4,8,"---FILE: apps/monitoring/manifests/prometheusk8s/additionalScrapeConfigs.yaml---
@@ -7,8 +7,8 @@ metadata:
   namespace: monitoring
 spec:
   encryptedData:
-    lancre_password: AgAGo94USkmdxDPlI3KrmA3tELpJ9PlbpSf+wgUbS0wtVGTDohXC/fOaKNGRxah+Ac+T0xNK0iMgBgyxJ456xWhVc+EJ9kaYjvU5OvBX3GeiiZVWg11mYZAxT4dNnokGil2BQgMHQHCvK/8+g1mqzNLdnxks+4GbVJL9IVMYW9jGcyOvdQB26agzx4WhX01kiUhHpFj541QRdL15Q9aPBeGFRMwxTF6TU4QIkJRyyjFhm8ctGcBVdwZM9MRKCehpEQKG55X4QodnbbUabEiTQddaSMX+dXX5VJICnmEhYk5ALtENw255Y/vIDEK15RgAbMmPQftxjEjOx8IxuyYt3bDRvOi49Es5MFwg0ZL6GAjAZ8prdiNTYi045SBWABmaZoGPzoB7nJhmfEM7Kgyemt4uCNUHDoKdst0yPQF/jNkmh2ep3NDnOQZfdS/dDWYmVXqPcSBwZolWkgdNXeH7/1OcCkuuTeplWYsMAklyP3thrNAUzG4q0l4Jv5ThL9vaYsut4fyiCrJMmKgVu1X1blQKlKzmOg1r17mfqD8NoVYlSuy5gyUwQmUmmnorpAzn+yvKWWR85qGTgbbN+CZBjPGfv8F2n/8UVPu+Z5bdD1tkRAFwqWcvXjhiAVjHrnNS+YX2uYttc5UR+bNqGOMDCqIq17lFwVbn/jf3EU2HFB4wWCkuBpwzF2ZXFMd8bHVZ/IdPZFbWNzrT3eHI6F/hj2Gy2vbTFtshIxKijiI7eWI=
-    lancre_username: AgAdnBImk4Pvf187uBBk7a5PV2Z97mH6MJx7h48JQOGeztFFmKvM/0KBkJ84WuLEUFJk2KaBVbeTpBaDrcNtt1cYAFr/FBLQdxLNyQyXh8k7r7h0cwL6xh1yseTZsfstAQvXOsMACtM2NTepzhTexaTYL3giKygY82EgECKXeSdIZ/pqmG/oQGiGMJg5uElJdRYxx/J4cp2ZY6TtkAX9gX2ugmn+jRU+zfjhPmX8npmtXuQhcLIySUBZJ5uTrQOXRXMBhSwJDuvcIOD5/FZPhVo6QUfzBarPrANkoxSGT/NPAW+9kkTDRBDWpKhuXky7VPdb979UG2Uufc/OJdSa322hj6ixA8FD18bPK1hNV59ymCWP2lUlwyD84Agb6twDzUSocGc0t/LCJHdykO1F+9QJbe+kgm0W4W/bdF3f0/XNbQSwgI5SO1nmRUTWpjB8g87C5wNlkBEP3M7wjRHUV7c2L2fRbNb5wvsWmTzUwGi3GJBhthRnR+9f5Ki/kc2YgWh4U9DV2bWOwONtmu58l/BnYGivVmqJwQB5fnUpm3UzsoE/ZNXh48SlPuS6sfgEqYCubUUwVw4O7/n6gcqQ2PAfEw4yuAhGGaxXZAKOCUVzEfahX2zV5M3POgHK2s6tMgHhm8V7FSccQlhQ7QD3q/M/JP5xFTvOCyBLeVsR1zYCIfnHoOp7fCrJovnmhVBXj9nR4cszSnIhUBz
+    lancre_password: AgBiu5296i4TNNBXYXQ9qcB0HXV9sdExyZsSUOxGZM3VptNUgagBHi4lJXOMezAtzKjqGpNB5x/CikXw2yLglBOKElqWrl91bLPr8D2ZUF6cwlGoTmcsWDdH2yhwuElF0koImCP0YjAg4BeWivn00bumgNIjIfvbodRM1cvHR0UDYFOy9N0zbDpRyoXcj+BcoO9WiDjw3Pf+EJjnpnIlwVX+gTOJm6+gQILfq88fMoHa1pOVIEtGBLRi2xPHasnQYrxAA0iTV7Slh2HbkahkRTfdmuJfY3tztxEeZYmQIpXw8pobTc0ZEypZTKywl5Hhh4hs3TxOtiNCrIS0UP0dgwW8GI+6ePJe3dbwXWDCAVMlDZPkJgkWTiQEnWeBrNp/YoE/rMz6pkbkzpLhKgDuuzHMpBRBKYHOqe5YhDoKsolCha0v6PqcawZJfdP9pifPcS0QgIMY6Moj5SHjVaMH7aSTV/t02r6KkfrffSD0TJvVZXq/3g9ibKtk12nnsFaFBN5GkkBm58phImFgfbae2ML82ML9BJ241xTFzl5H3i1Pn5ss8ZgDNtx6KEZZVH9+EWW1rppSnrdTaBBMCTtJ1qZpGTUhsRSpsjTiLtNnsCpa/ryBOCgceDw+4K/pM0eibKu7hPKoIsvIgVgcOrv3Y3vdw9VI03iLSBNRulMYzIKxCxGCLaeYBzdl/f7i+4pH4Y77UiN5AZgG+WuNmuXe6uJT02MbVi+HOua8Y8p8T/E=
+    lancre_username: AgB/okvPZXByaZFSgKG+MwNqTfJTgzqLzWVpm4xO/amxCg1EQ0CZUp5ex5R94zjPi7YwaTy9m4l0nYfIFq48mEctEyIWSAIiDr6GJvuAVFi4n+YeI7zL8rmsK3g1txUrHZF69sxXsJ/QQsKGy4NZFffHR0gbeeFtKVFKUBOUTUBYZiekdo4aO9paP9bbbZ2So9JyA3kfKx2Y0jfGsfv05dsBYF4R2+b3MQSp95gH2EJ6VPjOCMcAeb8VTKzoWY62XfxXj60JXYgn9ffDOYo5HfLoI0a8cYdrgPfzPqS2Q9cQPMER0RX1Jz8Y6hi5Mxcx8uK6I+9wrZmxzzCm98sKFXdXxUuubmZp59opnGPQuUBWtAhV7ABGBQIiwFQi6bYFh27+otMbYXkGYf+Ay6AsqnD6v0uK6++v4EO59wLkbyJ9ZtfESHhMS9F/JXZzwjkEblf7kQB7rpnoLmiV49DMruuf1++GAVTa+nlWxDPEE4rRMhZXUHM3sY+J9e33fBVB5+HlJgN+fiZ/MQWFhPGmMVyWi8ipk7zvpyWRarE5TdLgx6nDyZyrdQOoi/in0rmKyfTBer3h72AQyVXFKxouzxcoL7jJNBi0jHYY/y3yhZYqrAyWidglXjjv0toVcXHKxxM4zrHKIIh1rSJrIEY4uEIwmV4cc9OlKd/s5YWNpSGM5vSiuve1i5FfoKcuqhK6FWaPCCI3tvaIRYtt
   template:
     metadata:
       annotations:

---FILE: apps/monitoring/raw/prometheusk8s-additionalScrapeConfigs.yaml---
@@ -7,8 +7,8 @@ metadata:
   namespace: monitoring
 spec:
   encryptedData:
-    lancre_password: AgAGo94USkmdxDPlI3KrmA3tELpJ9PlbpSf+wgUbS0wtVGTDohXC/fOaKNGRxah+Ac+T0xNK0iMgBgyxJ456xWhVc+EJ9kaYjvU5OvBX3GeiiZVWg11mYZAxT4dNnokGil2BQgMHQHCvK/8+g1mqzNLdnxks+4GbVJL9IVMYW9jGcyOvdQB26agzx4WhX01kiUhHpFj541QRdL15Q9aPBeGFRMwxTF6TU4QIkJRyyjFhm8ctGcBVdwZM9MRKCehpEQKG55X4QodnbbUabEiTQddaSMX+dXX5VJICnmEhYk5ALtENw255Y/vIDEK15RgAbMmPQftxjEjOx8IxuyYt3bDRvOi49Es5MFwg0ZL6GAjAZ8prdiNTYi045SBWABmaZoGPzoB7nJhmfEM7Kgyemt4uCNUHDoKdst0yPQF/jNkmh2ep3NDnOQZfdS/dDWYmVXqPcSBwZolWkgdNXeH7/1OcCkuuTeplWYsMAklyP3thrNAUzG4q0l4Jv5ThL9vaYsut4fyiCrJMmKgVu1X1blQKlKzmOg1r17mfqD8NoVYlSuy5gyUwQmUmmnorpAzn+yvKWWR85qGTgbbN+CZBjPGfv8F2n/8UVPu+Z5bdD1tkRAFwqWcvXjhiAVjHrnNS+YX2uYttc5UR+bNqGOMDCqIq17lFwVbn/jf3EU2HFB4wWCkuBpwzF2ZXFMd8bHVZ/IdPZFbWNzrT3eHI6F/hj2Gy2vbTFtshIxKijiI7eWI=
-    lancre_username: AgAdnBImk4Pvf187uBBk7a5PV2Z97mH6MJx7h48JQOGeztFFmKvM/0KBkJ84WuLEUFJk2KaBVbeTpBaDrcNtt1cYAFr/FBLQdxLNyQyXh8k7r7h0cwL6xh1yseTZsfstAQvXOsMACtM2NTepzhTexaTYL3giKygY82EgECKXeSdIZ/pqmG/oQGiGMJg5uElJdRYxx/J4cp2ZY6TtkAX9gX2ugmn+jRU+zfjhPmX8npmtXuQhcLIySUBZJ5uTrQOXRXMBhSwJDuvcIOD5/FZPhVo6QUfzBarPrANkoxSGT/NPAW+9kkTDRBDWpKhuXky7VPdb979UG2Uufc/OJdSa322hj6ixA8FD18bPK1hNV59ymCWP2lUlwyD84Agb6twDzUSocGc0t/LCJHdykO1F+9QJbe+kgm0W4W/bdF3f0/XNbQSwgI5SO1nmRUTWpjB8g87C5wNlkBEP3M7wjRHUV7c2L2fRbNb5wvsWmTzUwGi3GJBhthRnR+9f5Ki/kc2YgWh4U9DV2bWOwONtmu58l/BnYGivVmqJwQB5fnUpm3UzsoE/ZNXh48SlPuS6sfgEqYCubUUwVw4O7/n6gcqQ2PAfEw4yuAhGGaxXZAKOCUVzEfahX2zV5M3POgHK2s6tMgHhm8V7FSccQlhQ7QD3q/M/JP5xFTvOCyBLeVsR1zYCIfnHoOp7fCrJovnmhVBXj9nR4cszSnIhUBz
+    lancre_password: AgBiu5296i4TNNBXYXQ9qcB0HXV9sdExyZsSUOxGZM3VptNUgagBHi4lJXOMezAtzKjqGpNB5x/CikXw2yLglBOKElqWrl91bLPr8D2ZUF6cwlGoTmcsWDdH2yhwuElF0koImCP0YjAg4BeWivn00bumgNIjIfvbodRM1cvHR0UDYFOy9N0zbDpRyoXcj+BcoO9WiDjw3Pf+EJjnpnIlwVX+gTOJm6+gQILfq88fMoHa1pOVIEtGBLRi2xPHasnQYrxAA0iTV7Slh2HbkahkRTfdmuJfY3tztxEeZYmQIpXw8pobTc0ZEypZTKywl5Hhh4hs3TxOtiNCrIS0UP0dgwW8GI+6ePJe3dbwXWDCAVMlDZPkJgkWTiQEnWeBrNp/YoE/rMz6pkbkzpLhKgDuuzHMpBRBKYHOqe5YhDoKsolCha0v6PqcawZJfdP9pifPcS0QgIMY6Moj5SHjVaMH7aSTV/t02r6KkfrffSD0TJvVZXq/3g9ibKtk12nnsFaFBN5GkkBm58phImFgfbae2ML82ML9BJ241xTFzl5H3i1Pn5ss8ZgDNtx6KEZZVH9+EWW1rppSnrdTaBBMCTtJ1qZpGTUhsRSpsjTiLtNnsCpa/ryBOCgceDw+4K/pM0eibKu7hPKoIsvIgVgcOrv3Y3vdw9VI03iLSBNRulMYzIKxCxGCLaeYBzdl/f7i+4pH4Y77UiN5AZgG+WuNmuXe6uJT02MbVi+HOua8Y8p8T/E=
+    lancre_username: AgB/okvPZXByaZFSgKG+MwNqTfJTgzqLzWVpm4xO/amxCg1EQ0CZUp5ex5R94zjPi7YwaTy9m4l0nYfIFq48mEctEyIWSAIiDr6GJvuAVFi4n+YeI7zL8rmsK3g1txUrHZF69sxXsJ/QQsKGy4NZFffHR0gbeeFtKVFKUBOUTUBYZiekdo4aO9paP9bbbZ2So9JyA3kfKx2Y0jfGsfv05dsBYF4R2+b3MQSp95gH2EJ6VPjOCMcAeb8VTKzoWY62XfxXj60JXYgn9ffDOYo5HfLoI0a8cYdrgPfzPqS2Q9cQPMER0RX1Jz8Y6hi5Mxcx8uK6I+9wrZmxzzCm98sKFXdXxUuubmZp59opnGPQuUBWtAhV7ABGBQIiwFQi6bYFh27+otMbYXkGYf+Ay6AsqnD6v0uK6++v4EO59wLkbyJ9ZtfESHhMS9F/JXZzwjkEblf7kQB7rpnoLmiV49DMruuf1++GAVTa+nlWxDPEE4rRMhZXUHM3sY+J9e33fBVB5+HlJgN+fiZ/MQWFhPGmMVyWi8ipk7zvpyWRarE5TdLgx6nDyZyrdQOoi/in0rmKyfTBer3h72AQyVXFKxouzxcoL7jJNBi0jHYY/y3yhZYqrAyWidglXjjv0toVcXHKxxM4zrHKIIh1rSJrIEY4uEIwmV4cc9OlKd/s5YWNpSGM5vSiuve1i5FfoKcuqhK6FWaPCCI3tvaIRYtt
   template:
     metadata:
       annotations:"
thaum-xyz,ankhmorpork,87aa7d2885d287f2dfc0896031bd802755622376,paulfantom,pawel@krupa.net.pl,2021-05-03T13:26:13Z,paulfantom,pawel@krupa.net.pl,2021-05-03T13:26:13Z,apps/monitoring/jsonnet: fix typo,apps/monitoring/jsonnet/main.jsonnet,False,False,False,False,1,1,2,"---FILE: apps/monitoring/jsonnet/main.jsonnet---
@@ -584,7 +584,7 @@ local kp =
           ],
         },
       },
-    },'
+    },
 
     kubePrometheus+: {
       // Exclude job=""windows"" from TargetDown alert"
thaum-xyz,ankhmorpork,89982cc39b545c409127cbcb5e63e9b260755cca,paulfantom,pawel@krupa.net.pl,2021-04-20T20:26:53Z,paulfantom,pawel@krupa.net.pl,2021-04-20T20:26:53Z,apps/auth: fix image tag,apps/auth/jsonnet/main.jsonnet;apps/auth/manifests/deployment.yaml,False,False,False,False,2,2,4,"---FILE: apps/auth/jsonnet/main.jsonnet---
@@ -3,7 +3,7 @@ local oauth = import './oauth-proxy.libsonnet';
 
 local config = {
   version: '7.1.2',
-  image: 'quay.io/paulfantom/oauth2-proxy:v' + self.version,
+  image: 'quay.io/paulfantom/oauth2-proxy:' + self.version,
   namespace: 'auth',
   replicas: 2,
   ingressDomain: 'auth.ankhmorpork.thaum.xyz',

---FILE: apps/auth/manifests/deployment.yaml---
@@ -49,7 +49,7 @@ spec:
         envFrom:
         - secretRef:
             name: oauth-creds
-        image: quay.io/paulfantom/oauth2-proxy:v7.1.2
+        image: quay.io/paulfantom/oauth2-proxy:7.1.2
         imagePullPolicy: IfNotPresent
         name: oauth2-proxy
         ports:"
thaum-xyz,ankhmorpork,d29140603ccf400b7b8cab8838a99be8fe70e49c,paulfantom,pawel@krupa.net.pl,2021-04-20T17:45:24Z,paulfantom,pawel@krupa.net.pl,2021-04-20T17:45:24Z,apps/monitoring: fix smokeping data collection; fix smokeping labels,apps/monitoring/jsonnet/main.jsonnet;apps/monitoring/manifests/smokeping/deployment.yaml;apps/monitoring/manifests/smokeping/podMonitor.yaml;apps/monitoring/manifests/smokeping/serviceAccount.yaml,False,False,False,False,5,12,17,"---FILE: apps/monitoring/jsonnet/main.jsonnet---
@@ -114,7 +114,7 @@ local kp =
       smokeping: {
         name: 'smokeping',
         namespace: $.values.common.namespace,
-        version: '1.2.0',
+        version: '0.4.1',
         image: 'quay.io/superq/smokeping-prober:v0.4.1',
         port: 9374,
         resources: {
@@ -268,10 +268,6 @@ local kp =
               containers: std.map(function(c) c {
                 securityContext: { capabilities: { add: ['NET_RAW'] } },
               }, super.containers),
-              securityContext: {
-                runAsNonRoot: true,
-                runAsUser: 65534,
-              },
             },
           },
         },

---FILE: apps/monitoring/manifests/smokeping/deployment.yaml---
@@ -4,7 +4,7 @@ metadata:
   labels:
     app.kubernetes.io/component: exporter
     app.kubernetes.io/name: smokeping
-    app.kubernetes.io/version: 1.2.0
+    app.kubernetes.io/version: 0.4.1
   name: smokeping
   namespace: monitoring
 spec:
@@ -18,7 +18,7 @@ spec:
       labels:
         app.kubernetes.io/component: exporter
         app.kubernetes.io/name: smokeping
-        app.kubernetes.io/version: 1.2.0
+        app.kubernetes.io/version: 0.4.1
     spec:
       affinity:
         podAntiAffinity:
@@ -61,7 +61,4 @@ spec:
           capabilities:
             add:
             - NET_RAW
-      securityContext:
-        runAsNonRoot: true
-        runAsUser: 65534
       serviceAccountName: smokeping

---FILE: apps/monitoring/manifests/smokeping/podMonitor.yaml---
@@ -4,7 +4,7 @@ metadata:
   labels:
     app.kubernetes.io/component: exporter
     app.kubernetes.io/name: smokeping
-    app.kubernetes.io/version: 1.2.0
+    app.kubernetes.io/version: 0.4.1
   name: smokeping
   namespace: monitoring
 spec:

---FILE: apps/monitoring/manifests/smokeping/serviceAccount.yaml---
@@ -4,6 +4,6 @@ metadata:
   labels:
     app.kubernetes.io/component: exporter
     app.kubernetes.io/name: smokeping
-    app.kubernetes.io/version: 1.2.0
+    app.kubernetes.io/version: 0.4.1
   name: smokeping
   namespace: monitoring"
thaum-xyz,ankhmorpork,ac4e1c16b69de8ff8d8e2ae37421536709f950e3,paulfantom,pawel@krupa.net.pl,2021-04-20T16:21:40Z,paulfantom,pawel@krupa.net.pl,2021-04-20T16:21:40Z,apps/monitoring: fix makefile,apps/monitoring/Makefile,False,False,False,False,1,1,2,"---FILE: apps/monitoring/Makefile---
@@ -1,7 +1,7 @@
 SHELL=/bin/bash -o pipefail
 
 MANIFESTS_DIR=manifests
-VENDOR_DIR=jsonnet/vendor
+JSONNET_VENDOR=jsonnet/vendor
 JSONNETFMT_ARGS=-n 2 --max-blank-lines 2 --string-style s --comment-style s
 
 .PHONY: all"
thaum-xyz,ankhmorpork,6a5bbd4932331889aa2a9ed659762990d732e6a1,paulfantom,pawel@krupa.net.pl,2021-04-20T11:20:39Z,paulfantom,pawel@krupa.net.pl,2021-04-20T11:20:39Z,apps/monitoring: fix passing uptimerobot secret,apps/monitoring/manifests/uptimerobot/secret.yaml,False,False,False,False,14,0,14,"---FILE: apps/monitoring/manifests/uptimerobot/secret.yaml---
@@ -0,0 +1,14 @@
+apiVersion: bitnami.com/v1alpha1
+kind: SealedSecret
+metadata:
+  creationTimestamp: null
+  name: uptimerobot-api-key
+  namespace: monitoring
+spec:
+  encryptedData:
+    UPTIMEROBOT_API_KEY: AgDZ2omOrR64V0NRqRdHYqvL67Cc0QY8SOULpBz9Uo62zCMGhZ0KkjvFu1WVA34VM7K/eEig3F0aOr/Wkhxqvgaar05S9egKUHNFhGtwGQKNz+Y1rqin3PZP7/x89WweNV9cKf8QkPFaUCWUMTlS5dWo8dAlq+KqE5K3uTIDGhKQLOlAXmxk+ZqWwV34vD3y7DYz4hxTqqMxouv1poFZIOxO8DzWUYwf/X3i02gB73G5bhcqzNtnobdL0eVXiEHal5feRTcj3n0lrBJ5o21Lwygj/MIvGHj05z+IKHspLHOdhX3S5kOVzSVPd329NwmnGXSIcTvVVvDVipr+TF5buGWuQrZTJsuEwt8DGZsA/I4uM5JtAXXl4jIaW9IeBMrwA+MfivaJGp/qVSghqvMpI0UsI5L19zVIQEjNqmk+8RuWg8Rh/FhqhOZHVsH+ijMA7zaVbJRgEIIJ9pAh5f6bQRVDPikTCA32qNosQRLip4o1RG2R3vXTmTzUbgyehwcMfSq54q60PEoyp/iNEWFoVH/EFh5QmEXCuCVUK/OFzv2X3XoxQh/wfh+G53s8yk+eZyWZkkNS5n9hNpoNYAa0uneVQLV2GsoqTsRN3sUDF/Frlw3eotGviZEqXKX9wUHYlm+joubGZUJBIwWwgloX4ewBR+4GF9K4O2oG+9G3XKz8UVMD/zcDSduOXUYAkMyEzKRmWCLqFSkq1VP76SqNIZ8e/u9RYxGOYJgGEiVjsExKKz0=
+  template:
+    metadata:
+      creationTimestamp: null
+      name: uptimerobot-api-key
+      namespace: monitoring"
thaum-xyz,ankhmorpork,015890d8c00e32d84a4044f4c5fbec1401f56cba,paulfantom,pawel@krupa.net.pl,2021-04-16T16:47:30Z,paulfantom,pawel@krupa.net.pl,2021-04-16T16:47:30Z,apps/homeassistant: fix alert annotations,apps/homeassistant/09_prometheusrule.yaml,False,False,False,False,2,2,4,"---FILE: apps/homeassistant/09_prometheusrule.yaml---
@@ -17,5 +17,5 @@ spec:
           severity: critical
           priority: P1
         annotations:
-          summary: ""Home Assistant instance {{ $labels.instance }} is down""
-          description: ""Home Assistant is down""
+          description: ""Home Assistant instance {{ $labels.instance }} is down""
+          summary: ""Home Assistant is down"""
thaum-xyz,ankhmorpork,62a08ef3a8e8941e980cc11347a8f8a063ef780e,paulfantom,pawel@krupa.net.pl,2021-04-16T15:01:35Z,paulfantom,pawel@krupa.net.pl,2021-04-16T15:01:35Z,apps/blog: fix restic,apps/blog/07_backup.yaml,False,False,False,False,1,1,2,"---FILE: apps/blog/07_backup.yaml---
@@ -31,7 +31,7 @@ spec:
             value: ""/backup""
           - name: SCHEDULE
             value: ""13 1 * * *""  # At 01:13
-          - name: RUN_ON_BOOT
+          - name: PRE_COMMAND
             value: ""restic unlock""
           - name: POST_COMMAND
             value: ""restic forget --keep-last 14 --keep-daily 7 --keep-monthly 6 --keep-yearly 2"""
thaum-xyz,ankhmorpork,4f4ecd9c4ed367ee2ea3e7cf2b5ae3cc0968396d,paulfantom,pawel@krupa.net.pl,2021-04-13T11:27:49Z,paulfantom,pawel@krupa.net.pl,2021-04-13T11:27:49Z,apps/monitoring: fix kubectl annotation,apps/monitoring/jsonnet/main.jsonnet,False,False,False,False,15,15,30,"---FILE: apps/monitoring/jsonnet/main.jsonnet---
@@ -288,13 +288,13 @@ local kp =
     // TODO: Should service expose 2 ports???
     blackboxExporter+: {
       deployment+: {
-        metadata+: {
-          annotations+: {
-            ""kubectl.kubernetes.io/default-container"": ""blackbox-exporter"",
-          }
-        },
         spec+: {
           template+: {
+            metadata+: {
+              annotations+: {
+                ""kubectl.kubernetes.io/default-container"": ""blackbox-exporter"",
+              }
+            },
             spec+: {
               affinity: (import '../../../lib/podantiaffinity.libsonnet').podantiaffinity('blackbox-exporter'),
             },
@@ -307,13 +307,13 @@ local kp =
     },
     prometheusOperator+: {
       deployment+: {
-        metadata+: {
-          annotations+: {
-            ""kubectl.kubernetes.io/default-container"": ""prometheus-operator"",
-          }
-        },
         spec+: {
           template+: {
+            metadata+: {
+              annotations+: {
+                ""kubectl.kubernetes.io/default-container"": ""prometheus-operator"",
+              }
+            },
             spec+: {
               containers: addArgs(['--config-reloader-cpu=150m', '--log-level=debug'], 'prometheus-operator', super.containers),
             },
@@ -407,13 +407,13 @@ local kp =
     },
     kubeStateMetrics+: {
       deployment+: {
-        metadata+: {
-          annotations+: {
-            ""kubectl.kubernetes.io/default-container"": ""kube-state-metrics"",
-          }
-        },
         spec+: {
           template+: {
+            metadata+: {
+              annotations+: {
+                ""kubectl.kubernetes.io/default-container"": ""kube-state-metrics"",
+              }
+            },
             spec+: {
               containers:
                 // addArgs(['--metric-labels-allowlist=nodes=[kubernetes.io/arch,gpu.infra/intel,network.infra/type]'], 'kube-state-metrics', super.containers) +"
thaum-xyz,ankhmorpork,8e5d9befb981dfbf05f791e91261764d5e2369a1,paulfantom,pawel@krupa.net.pl,2021-04-13T11:24:52Z,paulfantom,pawel@krupa.net.pl,2021-04-13T11:24:52Z,apps/monitoring: fix KSM args again,apps/monitoring/jsonnet/main.jsonnet,False,False,False,False,2,2,4,"---FILE: apps/monitoring/jsonnet/main.jsonnet---
@@ -416,7 +416,7 @@ local kp =
           template+: {
             spec+: {
               containers:
-                // addArgs(['--labels-metric-allowlist=nodes=[kubernetes.io/arch,gpu.infra/intel,network.infra/type]'], 'kube-state-metrics', super.containers) +
+                // addArgs(['--metric-labels-allowlist=nodes=[kubernetes.io/arch,gpu.infra/intel,network.infra/type]'], 'kube-state-metrics', super.containers) +
                 // TODO: consider moving this into kube-prometheus
                 std.map(
                   function(c) if c.name == 'kube-rbac-proxy-main' then
@@ -428,7 +428,7 @@ local kp =
                     }
                   else if c.name == 'kube-state-metrics' then
                     c {
-                      args+: ['--labels-metric-allowlist=nodes=[kubernetes.io/arch,gpu.infra/intel,network.infra/type]'],
+                      args+: ['--metric-labels-allowlist=nodes=[kubernetes.io/arch,gpu.infra/intel,network.infra/type]'],
                     }
                   else c,
                   super.containers,"
thaum-xyz,ankhmorpork,baed857dae498993ae68d6f6c930a5cd7cea59d2,paulfantom,pawel@krupa.net.pl,2021-04-13T11:17:22Z,paulfantom,pawel@krupa.net.pl,2021-04-13T11:17:22Z,apps/monitoring: fix KSM args,apps/monitoring/jsonnet/main.jsonnet,False,False,False,False,1,1,2,"---FILE: apps/monitoring/jsonnet/main.jsonnet---
@@ -413,7 +413,7 @@ local kp =
                     }
                   else if c.name == 'kube-state-metrics' then
                     c {
-                      args+: ['--labels-metric-allow-list=nodes=[kubernetes.io/arch,gpu.infra/intel,network.infra/type]'],
+                      args+: ['--labels-metric-allowlist=nodes=[kubernetes.io/arch,gpu.infra/intel,network.infra/type]'],
                     }
                   else c,
                   super.containers,"
thaum-xyz,ankhmorpork,90e810c92d70dd9ef01840292ae1a1a64a0ff307,paulfantom,pawel@krupa.net.pl,2021-03-25T15:13:21Z,paulfantom,pawel@krupa.net.pl,2021-03-25T15:13:21Z,apps/dns: reenable adblocker as issue seems to be with resource limits,apps/dns/Corefile;apps/dns/jsonnet/coredns.libsonnet;apps/dns/manifests/local/config.yaml;apps/dns/manifests/local/deployment.yaml,False,False,False,False,18,18,36,"---FILE: apps/dns/Corefile---
@@ -28,14 +28,14 @@
     192.168.2.40 metal01.ankhmorpork.thaum.xyz
     fallthrough
   }
-  # ads {
-  #   permit cdnpark.com
-  #   permit googleadservices.com
-  #   permit backblazeb2.com
-  #   permit app.adjust.com
-  #   default-lists
-  #   log
-  # }
+  ads {
+    permit cdnpark.com
+    permit googleadservices.com
+    permit backblazeb2.com
+    permit app.adjust.com
+    default-lists
+    log
+  }
   cache {
     success 51200 21600
     prefetch 1000

---FILE: apps/dns/jsonnet/coredns.libsonnet---
@@ -10,7 +10,7 @@ local defaults = {
   replicas: 2,
 
   resources: {
-    limits: { cpu: '20m', memory: '170Mi' },
+    limits: { cpu: '100m', memory: '170Mi' },
     requests: { cpu: '10m', memory: '30Mi' },
   },
   commonLabels:: {

---FILE: apps/dns/manifests/local/config.yaml---
@@ -31,14 +31,14 @@ data:
         192.168.2.40 metal01.ankhmorpork.thaum.xyz
         fallthrough
       }
-      # ads {
-      #   permit cdnpark.com
-      #   permit googleadservices.com
-      #   permit backblazeb2.com
-      #   permit app.adjust.com
-      #   default-lists
-      #   log
-      # }
+      ads {
+        permit cdnpark.com
+        permit googleadservices.com
+        permit backblazeb2.com
+        permit app.adjust.com
+        default-lists
+        log
+      }
       cache {
         success 51200 21600
         prefetch 1000

---FILE: apps/dns/manifests/local/deployment.yaml---
@@ -69,7 +69,7 @@ spec:
             scheme: HTTP
         resources:
           limits:
-            cpu: 20m
+            cpu: 100m
             memory: 170Mi
           requests:
             cpu: 10m"
thaum-xyz,ankhmorpork,fb4a9c8d78c5ae243cc1609d4c82ded286d43a3e,paulfantom,pawel@krupa.net.pl,2021-03-25T14:25:21Z,paulfantom,pawel@krupa.net.pl,2021-03-25T14:25:21Z,apps/dns: fix setting dns nameservers,apps/dns/jsonnet/main.jsonnet;apps/dns/manifests/local/deployment.yaml,False,False,False,False,13,9,22,"---FILE: apps/dns/jsonnet/main.jsonnet---
@@ -51,11 +51,15 @@ local all = {
     serviceUDP+: metallbMetadata,
     deployment+: {
       spec+: {
-        dnsConfig+: {
-          nameservers: [
-            '192.168.2.1',
-            '1.0.0.1',
-          ],
+        template+: {
+          spec+: {
+            dnsConfig+: {
+              nameservers: [
+                '192.168.2.1',
+                '1.0.0.1',
+              ],
+            },
+          },
         },
       },
     },

---FILE: apps/dns/manifests/local/deployment.yaml---
@@ -8,10 +8,6 @@ metadata:
   name: coredns
   namespace: dns
 spec:
-  dnsConfig:
-    nameservers:
-    - 192.168.2.1
-    - 1.0.0.1
   replicas: 2
   selector:
     matchLabels:
@@ -90,6 +86,10 @@ spec:
         - mountPath: /etc/coredns
           name: corefile
           readOnly: true
+      dnsConfig:
+        nameservers:
+        - 192.168.2.1
+        - 1.0.0.1
       dnsPolicy: Default
       serviceAccountName: coredns
       volumes:"
thaum-xyz,ankhmorpork,268d7f19d4e693f4448729b9928ed8973778dfcd,paulfantom,pawel@krupa.net.pl,2021-03-16T15:19:34Z,paulfantom,pawel@krupa.net.pl,2021-03-16T15:20:05Z,apps/monitoring: bump KSM to 2.0.0-rc.0 and fix inclusion of kubernetes control-plane objects,apps/monitoring/jsonnet/main.jsonnet;apps/monitoring/manifests/kube-state-metrics/clusterRole.yaml;apps/monitoring/manifests/kube-state-metrics/clusterRoleBinding.yaml;apps/monitoring/manifests/kube-state-metrics/deployment.yaml;apps/monitoring/manifests/kube-state-metrics/prometheusRule.yaml;apps/monitoring/manifests/kube-state-metrics/service.yaml;apps/monitoring/manifests/kube-state-metrics/serviceAccount.yaml;apps/monitoring/manifests/kube-state-metrics/serviceMonitor.yaml;base/argocd/apps/monitoring.yaml,False,False,False,False,31,12,43,"---FILE: apps/monitoring/jsonnet/main.jsonnet---
@@ -190,8 +190,8 @@ local kp =
         },
       },
       kubeStateMetrics+: {
-        version: 'v2.0.0-beta',
-        image: 'k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0-beta',
+        version: 'v2.0.0-rc.0',
+        image: 'k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0-rc.0',
       },
       grafana+: {
         version: '7.3.7',
@@ -557,7 +557,7 @@ local kp =
 { ['grafana/' + name + '.yaml']: std.manifestYamlDoc(kp.grafana[name]) for name in std.objectFields(kp.grafana) } +
 { ['pushgateway/' + name + '.yaml']: std.manifestYamlDoc(kp.pushgateway[name]) for name in std.objectFields(kp.pushgateway) } +
 { ['smokeping/' + name + '.yaml']: std.manifestYamlDoc(kp.smokeping[name]) for name in std.objectFields(kp.smokeping) } +
-// { ['holiday/' + name + '.yaml']: std.manifestYamlDoc(kp.blackboxExporter[name]) for name in std.objectFields(kp.blackboxExporter) } +
+// { ['holiday/' + name + '.yaml']: std.manifestYamlDoc(kp.holidayExporter[name]) for name in std.objectFields(kp.holidayExporter) } +
 { ['kube-events-exporter/' + name + '.yaml']: std.manifestYamlDoc(kp.kubeEventsExporter[name]) for name in std.objectFields(kp.kubeEventsExporter) } +
 { ['other/' + name + '.yaml']: std.manifestYamlDoc(kp.other[name]) for name in std.objectFields(kp.other) } +
 { 'other/kubePrometheusRule.yaml': std.manifestYamlDoc(kp.kubePrometheus.prometheusRule) } +

---FILE: apps/monitoring/manifests/kube-state-metrics/clusterRole.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: exporter
     app.kubernetes.io/name: kube-state-metrics
     app.kubernetes.io/part-of: kube-prometheus
-    app.kubernetes.io/version: v2.0.0-beta
+    app.kubernetes.io/version: v2.0.0-rc.0
   name: kube-state-metrics
 rules:
 - apiGroups:

---FILE: apps/monitoring/manifests/kube-state-metrics/clusterRoleBinding.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: exporter
     app.kubernetes.io/name: kube-state-metrics
     app.kubernetes.io/part-of: kube-prometheus
-    app.kubernetes.io/version: v2.0.0-beta
+    app.kubernetes.io/version: v2.0.0-rc.0
   name: kube-state-metrics
 roleRef:
   apiGroup: rbac.authorization.k8s.io

---FILE: apps/monitoring/manifests/kube-state-metrics/deployment.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: exporter
     app.kubernetes.io/name: kube-state-metrics
     app.kubernetes.io/part-of: kube-prometheus
-    app.kubernetes.io/version: v2.0.0-beta
+    app.kubernetes.io/version: v2.0.0-rc.0
   name: kube-state-metrics
   namespace: monitoring
 spec:
@@ -21,7 +21,7 @@ spec:
         app.kubernetes.io/component: exporter
         app.kubernetes.io/name: kube-state-metrics
         app.kubernetes.io/part-of: kube-prometheus
-        app.kubernetes.io/version: v2.0.0-beta
+        app.kubernetes.io/version: v2.0.0-rc.0
     spec:
       containers:
       - args:
@@ -30,7 +30,7 @@ spec:
         - --telemetry-host=127.0.0.1
         - --telemetry-port=8082
         - --labels-metric-allow-list=nodes=[kubernetes.io/arch,gpu.infra/intel,network.infra/type]
-        image: k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0-beta
+        image: k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0-rc.0
         name: kube-state-metrics
         resources:
           limits:

---FILE: apps/monitoring/manifests/kube-state-metrics/prometheusRule.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: exporter
     app.kubernetes.io/name: kube-state-metrics
     app.kubernetes.io/part-of: kube-prometheus
-    app.kubernetes.io/version: v2.0.0-beta
+    app.kubernetes.io/version: v2.0.0-rc.0
     role: alert-rules
   name: kube-state-metrics-rules
   namespace: monitoring

---FILE: apps/monitoring/manifests/kube-state-metrics/service.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: exporter
     app.kubernetes.io/name: kube-state-metrics
     app.kubernetes.io/part-of: kube-prometheus
-    app.kubernetes.io/version: v2.0.0-beta
+    app.kubernetes.io/version: v2.0.0-rc.0
   name: kube-state-metrics
   namespace: monitoring
 spec:

---FILE: apps/monitoring/manifests/kube-state-metrics/serviceAccount.yaml---
@@ -5,6 +5,6 @@ metadata:
     app.kubernetes.io/component: exporter
     app.kubernetes.io/name: kube-state-metrics
     app.kubernetes.io/part-of: kube-prometheus
-    app.kubernetes.io/version: v2.0.0-beta
+    app.kubernetes.io/version: v2.0.0-rc.0
   name: kube-state-metrics
   namespace: monitoring

---FILE: apps/monitoring/manifests/kube-state-metrics/serviceMonitor.yaml---
@@ -5,7 +5,7 @@ metadata:
     app.kubernetes.io/component: exporter
     app.kubernetes.io/name: kube-state-metrics
     app.kubernetes.io/part-of: kube-prometheus
-    app.kubernetes.io/version: v2.0.0-beta
+    app.kubernetes.io/version: v2.0.0-rc.0
   name: kube-state-metrics
   namespace: monitoring
 spec:

---FILE: base/argocd/apps/monitoring.yaml---
@@ -227,4 +227,23 @@ spec:
       prune: false
       selfHeal: false
 
+---
+apiVersion: argoproj.io/v1alpha1
+kind: Application
+metadata:
+  name: control-plane-components
+spec:
+  destination:
+    namespace: monitoring
+    server: 'https://kubernetes.default.svc'
+  source:
+    path: apps/monitoring/manifests/kubernetesControlPlane
+    repoURL: 'https://github.com/thaum-xyz/ankhmorpork.git'
+    targetRevision: HEAD
+  project: monitoring
+  syncPolicy:
+    automated:
+      prune: false
+      selfHeal: false
+
 "
thaum-xyz,ankhmorpork,9bdeac6d66fcbe061ea6defe8b19bfae3d5e23f2,paulfantom,pawel@krupa.net.pl,2021-03-04T09:39:24Z,paulfantom,pawel@krupa.net.pl,2021-03-04T09:39:24Z,apps/multimedia/ombi: fix image,apps/multimedia/manifests/ombi/04_statefulset.yaml,False,False,False,False,2,2,4,"---FILE: apps/multimedia/manifests/ombi/04_statefulset.yaml---
@@ -6,7 +6,7 @@ metadata:
   namespace: multimedia
   labels:
     app.kubernetes.io/name: ombi
-    app.kubernetes.io/version: 4.0.1139
+    app.kubernetes.io/version: 4.0.1142
 spec:
   replicas: 1
   selector:
@@ -23,7 +23,7 @@ spec:
         - name: TZ
           value: ""Europe/Berlin""
         name: ombi
-        image: linuxserver/ombi:version-v4.0.1139
+        image: linuxserver/ombi:development-v4.0.1142-ls58
         imagePullPolicy: IfNotPresent
         ports:
           - containerPort: 3579"
thaum-xyz,ankhmorpork,39b8b67eb82d8f961c31cb8da45181c7c06cba88,paulfantom,pawel@krupa.net.pl,2021-02-14T11:07:49Z,paulfantom,pawel@krupa.net.pl,2021-02-14T11:07:49Z,apps/homer: fix transmission link and remove proxmox,apps/homer/jsonnet/config.yml;apps/homer/manifests/configmap.yaml,False,False,False,False,2,10,12,"---FILE: apps/homer/jsonnet/config.yml---
@@ -103,7 +103,7 @@ services:
         subtitle: ""downloader""
         logo: ""https://avatars3.githubusercontent.com/u/223312?s=200&v=4""
         <<: *Local
-        url: ""http://192.168.2.95:9001/transmission/web/""
+        url: ""http://192.168.2.95:9091/transmission/web/""
       #- name: Photoprism
       #  logo: """"
       #  subtitle: ""Photo management""
@@ -121,10 +121,6 @@ services:
       - name: Prometheus
         logo: ""https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Prometheus_software_logo.svg/200px-Prometheus_software_logo.svg.png""
         url: ""https://prometheus.ankhmorpork.thaum.xyz/""
-      - name: Proxmox
-        logo: ""https://www.proxmox.com/images/proxmox/Proxmox_symbol_standard_hex.png""
-        <<: *Local
-        url: ""https://192.168.2.40:8006/""
       - name: Unifi
         logo: ""https://dl.ubnt.com/press/Company_Logos/U_Logo/WEB/U_Logo_RGB.png""
         <<: *Local

---FILE: apps/homer/manifests/configmap.yaml---
@@ -106,7 +106,7 @@ data:
             subtitle: ""downloader""
             logo: ""https://avatars3.githubusercontent.com/u/223312?s=200&v=4""
             <<: *Local
-            url: ""http://192.168.2.95:9001/transmission/web/""
+            url: ""http://192.168.2.95:9091/transmission/web/""
           #- name: Photoprism
           #  logo: """"
           #  subtitle: ""Photo management""
@@ -124,10 +124,6 @@ data:
           - name: Prometheus
             logo: ""https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Prometheus_software_logo.svg/200px-Prometheus_software_logo.svg.png""
             url: ""https://prometheus.ankhmorpork.thaum.xyz/""
-          - name: Proxmox
-            logo: ""https://www.proxmox.com/images/proxmox/Proxmox_symbol_standard_hex.png""
-            <<: *Local
-            url: ""https://192.168.2.40:8006/""
           - name: Unifi
             logo: ""https://dl.ubnt.com/press/Company_Logos/U_Logo/WEB/U_Logo_RGB.png""
             <<: *Local"
thaum-xyz,ankhmorpork,01452a90780e4fd9ba47319ad313a6d9a035152f,paulfantom,pawel@krupa.net.pl,2021-02-12T12:36:27Z,paulfantom,pawel@krupa.net.pl,2021-02-12T12:36:27Z,apps/monitoring: fix what wasn't fixed in 3a6c4c485ece74e2b4686f609783dac61817e610,apps/monitoring/jsonnet/main.jsonnet;apps/monitoring/manifests/other/kubePrometheusRule.yaml,False,False,False,False,3,3,6,"---FILE: apps/monitoring/jsonnet/main.jsonnet---
@@ -454,7 +454,7 @@ local kp =
           groups: std.map(function(ruleGroup) ruleGroup {
             rules: std.map(
               function(rule) if 'alert' in rule && rule.alert == 'TargetDown' then
-                rule { expr: '100 * (count(up{job!=""windows""}, == 0) BY (job, namespace, service) / count(up{job!=""windows""}) BY (job, namespace, service)) > 10' }
+                rule { expr: '100 * (count(up{job!=""windows""} == 0) BY (job, namespace, service) / count(up{job!=""windows""}) BY (job, namespace, service)) > 10' }
               else rule,
               ruleGroup.rules,
             ),

---FILE: apps/monitoring/manifests/other/kubePrometheusRule.yaml---
@@ -16,8 +16,8 @@ spec:
       annotations:
         message: '{{ printf ""%.4g"" $value }}% of the {{ $labels.job }}/{{ $labels.service
           }} targets in {{ $labels.namespace }} namespace are down.'
-      expr: 100 * (count(up{job!=""windows""}, == 0) BY (job, namespace, service) /
-        count(up{job!=""windows""}) BY (job, namespace, service)) > 10
+      expr: 100 * (count(up{job!=""windows""} == 0) BY (job, namespace, service) / count(up{job!=""windows""})
+        BY (job, namespace, service)) > 10
       for: 10m
       labels:
         severity: warning"
thaum-xyz,ankhmorpork,3a6c4c485ece74e2b4686f609783dac61817e610,paulfantom,pawel@krupa.net.pl,2021-02-12T12:12:44Z,paulfantom,pawel@krupa.net.pl,2021-02-12T12:12:44Z,apps/monitoring: fix incorrect rule,apps/monitoring/jsonnet/main.jsonnet;apps/monitoring/manifests/other/kubePrometheusRule.yaml,False,False,False,False,3,3,6,"---FILE: apps/monitoring/jsonnet/main.jsonnet---
@@ -454,7 +454,7 @@ local kp =
           groups: std.map(function(ruleGroup) ruleGroup {
             rules: std.map(
               function(rule) if 'alert' in rule && rule.alert == 'TargetDown' then
-                rule { expr: '100 * (count(up{job!=""windows}, == 0) BY (job, namespace, service) / count(up{job!=""windows}) BY (job, namespace, service)) > 10' }
+                rule { expr: '100 * (count(up{job!=""windows""}, == 0) BY (job, namespace, service) / count(up{job!=""windows""}) BY (job, namespace, service)) > 10' }
               else rule,
               ruleGroup.rules,
             ),

---FILE: apps/monitoring/manifests/other/kubePrometheusRule.yaml---
@@ -16,8 +16,8 @@ spec:
       annotations:
         message: '{{ printf ""%.4g"" $value }}% of the {{ $labels.job }}/{{ $labels.service
           }} targets in {{ $labels.namespace }} namespace are down.'
-      expr: 100 * (count(up{job!=""windows}, == 0) BY (job, namespace, service) / count(up{job!=""windows})
-        BY (job, namespace, service)) > 10
+      expr: 100 * (count(up{job!=""windows""}, == 0) BY (job, namespace, service) /
+        count(up{job!=""windows""}) BY (job, namespace, service)) > 10
       for: 10m
       labels:
         severity: warning"
thaum-xyz,ankhmorpork,b2dd41a814edb4768c6426e82cf7c24177219d47,paulfantom,pawel@krupa.net.pl,2021-01-11T11:50:18Z,paulfantom,pawel@krupa.net.pl,2021-01-11T11:50:18Z,apps/monitoring/rules: fix typo,apps/monitoring/prometheus/rules/general.yaml,False,False,False,False,1,1,2,"---FILE: apps/monitoring/prometheus/rules/general.yaml---
@@ -34,7 +34,7 @@ spec:
       expr: |
         ((time() - (job_success_timestamp_seconds > 0)) > job_max_age_seconds)
         or
-        (time() - jon_start_timestamp_seconds > job_max_age_seconds and job_success_timestamp_seconds == 0)
+        (time() - job_start_timestamp_seconds > job_max_age_seconds and job_success_timestamp_seconds == 0)
       for: 1m
       labels:
         severity: warning"
thaum-xyz,ankhmorpork,76204694ff55b3f48330eb2c96f8995aa6cb80a1,paulfantom,pawel@krupa.net.pl,2021-01-08T18:32:30Z,paulfantom,pawel@krupa.net.pl,2021-01-08T18:32:30Z,apps/homer/manifests: fix configmap,apps/homer/manifests/02_config.yaml,False,False,False,False,2,0,2,"---FILE: apps/homer/manifests/02_config.yaml---
@@ -1,3 +1,4 @@
+apiVersion: v1
 data:
   config.yml: |
     title: ""Ankhmorpork portal""
@@ -138,6 +139,7 @@ data:
           - name: ArgoCD
             logo: ""https://argoproj.github.io/argo-cd/assets/logo.png""
             url: ""https://argocd.ankhmorpork.thaum.xyz""
+kind: ConfigMap
 metadata:
   labels:
     app.kubernetes.io/component: server"
thaum-xyz,ankhmorpork,58864cd33a71eecdbe299db83995dd1136dc090a,paulfantom,pawel@krupa.net.pl,2021-01-08T11:23:13Z,paulfantom,pawel@krupa.net.pl,2021-01-08T11:23:13Z,apps/multimedia/sonarr: fix label conflict in argo,apps/multimedia/sonarr/03_service.yaml;apps/multimedia/sonarr/05_apikey.yaml;apps/multimedia/sonarr/06_deployment.yaml;apps/multimedia/sonarr/07_serviceMonitor.yaml,False,False,False,False,18,18,36,"---FILE: apps/multimedia/sonarr/03_service.yaml---
@@ -27,14 +27,14 @@ metadata:
   name: sonarr-exporter
   namespace: multimedia
   labels:
-    app.kubernetes.io/name: sonarr
-    app.kubernetes.io/instance: exportarr
+    app.kubernetes.io/name: exportarr
+    app.kubernetes.io/instance: sonarr
     app.kubernetes.io/component: exporter
 spec:
   clusterIP: None
   selector:
-    app.kubernetes.io/name: sonarr
-    app.kubernetes.io/instance: exportarr
+    app.kubernetes.io/name: exportarr
+    app.kubernetes.io/instance: sonarr
     app.kubernetes.io/component: exporter
   ports:
   - name: sonarr-metrics

---FILE: apps/multimedia/sonarr/05_apikey.yaml---
@@ -5,8 +5,8 @@ metadata:
   name: sonarr-apikey
   namespace: multimedia
   labels:
-    app.kubernetes.io/name: sonarr
-    app.kubernetes.io/instance: exportarr
+    app.kubernetes.io/name: exportarr
+    app.kubernetes.io/instance: sonarr
     app.kubernetes.io/component: exporter
 spec:
   encryptedData:
@@ -16,8 +16,8 @@ spec:
       annotations:
         sealedsecrets.bitnami.com/managed: ""true""
       labels:
-        app.kubernetes.io/name: sonarr
-        app.kubernetes.io/instance: exportarr
+        app.kubernetes.io/name: exportarr
+        app.kubernetes.io/instance: sonarr
         app.kubernetes.io/component: exporter
       creationTimestamp: null
       name: sonarr-apikey

---FILE: apps/multimedia/sonarr/06_deployment.yaml---
@@ -5,23 +5,23 @@ metadata:
   name: sonarr-exporter
   namespace: multimedia
   labels:
-    app.kubernetes.io/name: sonarr
-    app.kubernetes.io/instance: exportarr
+    app.kubernetes.io/name: exportarr
+    app.kubernetes.io/instance: sonarr
     app.kubernetes.io/component: exporter
     app.kubernetes.io/version: 0.3.4
 spec:
   replicas: 1
   revisionHistoryLimit: 3
   selector:
     matchLabels:
-      app.kubernetes.io/name: sonarr
-      app.kubernetes.io/instance: exportarr
+      app.kubernetes.io/name: exportarr
+      app.kubernetes.io/instance: sonarr
       app.kubernetes.io/component: exporter
   template:
     metadata:
       labels:
-        app.kubernetes.io/name: sonarr
-        app.kubernetes.io/instance: exportarr
+        app.kubernetes.io/name: exportarr
+        app.kubernetes.io/instance: sonarr
         app.kubernetes.io/component: exporter
         app.kubernetes.io/version: 0.3.4
     spec:

---FILE: apps/multimedia/sonarr/07_serviceMonitor.yaml---
@@ -5,14 +5,14 @@ metadata:
   name: sonarr-exporter
   namespace: multimedia
   labels:
-    app.kubernetes.io/name: sonarr
-    app.kubernetes.io/instance: exportarr
+    app.kubernetes.io/name: exportarr
+    app.kubernetes.io/instance: sonarr
     app.kubernetes.io/component: exporter
 spec:
   selector:
     matchLabels:
-      app.kubernetes.io/name: sonarr
-      app.kubernetes.io/instance: exportarr
+      app.kubernetes.io/name: exportarr
+      app.kubernetes.io/instance: sonarr
       app.kubernetes.io/component: exporter
   endpoints:
   - port: sonarr-metrics"
thaum-xyz,ankhmorpork,e7463828c836b4b9cbb00a92ccab566cb52349f5,paulfantom,pawel@krupa.net.pl,2021-01-08T11:18:43Z,paulfantom,pawel@krupa.net.pl,2021-01-08T11:18:43Z,apps/multimedia/sonarr: fix labels,apps/multimedia/sonarr/03_service.yaml;apps/multimedia/sonarr/05_apikey.yaml;apps/multimedia/sonarr/06_deployment.yaml;apps/multimedia/sonarr/07_serviceMonitor.yaml,False,False,False,False,31,16,47,"---FILE: apps/multimedia/sonarr/03_service.yaml---
@@ -27,13 +27,15 @@ metadata:
   name: sonarr-exporter
   namespace: multimedia
   labels:
-    app.kubernetes.io/name: sonarr-exporter
-    app.kubernetes.io/instance: sonarr-exporter
+    app.kubernetes.io/name: sonarr
+    app.kubernetes.io/instance: exportarr
+    app.kubernetes.io/component: exporter
 spec:
   clusterIP: None
   selector:
-    app.kubernetes.io/name: sonarr-exporter
-    app.kubernetes.io/instance: sonarr-exporter
+    app.kubernetes.io/name: sonarr
+    app.kubernetes.io/instance: exportarr
+    app.kubernetes.io/component: exporter
   ports:
   - name: sonarr-metrics
     port: 9708

---FILE: apps/multimedia/sonarr/05_apikey.yaml---
@@ -4,13 +4,21 @@ metadata:
   creationTimestamp: null
   name: sonarr-apikey
   namespace: multimedia
+  labels:
+    app.kubernetes.io/name: sonarr
+    app.kubernetes.io/instance: exportarr
+    app.kubernetes.io/component: exporter
 spec:
   encryptedData:
     APIKEY: AgCbT1jEup+SNJVKszQ/qBZXY9Ur0qcs6ZF/B9OU0t+nxDQFLvHXWDetIAkDVF1FFHK/g6duBzbYt0+YRJ/zGu7uJAqHMLHvKhDPn79TKaZ1LYFdPLcaUaQQXKV2tvZWESlVn3TRUm0/haRqiNs2MdrDlLOzn8WVCK2eGQaGmtpcj1IWaRZExffMtFEyb4xmPr8OI3WcuzlDqWfs3VEOQvFQizgs6ggdEckT+J8mBdWYLPqBRHAdp6VLIXgVuesuvbV1z5hN3/Uv4V4ASJT2DetbNitciBMbSLY4bY16/9AaunDFUqHJw1Dheu+rjwbF47ii2RUkPackTc4yPxbFQVCzEUwhLNgqGwb5n1mg2C7aHE74JTK44abwwXFzm2CG8rR0OxJhGfdVwUzIhDmNFqZOYiwefUhwF8YL4a14YKjnrsltzd0lw2i6Kx0m5OQSqVBbolCWUqIdlTFN/dG8UCCyleD/aF1pXfCQKPjQUOFcAxe3N5WxdRrvj+al64EIYvtq1jI37hXR5Pd8n7AfQXNbrhviKPASSWcV/u0GtfWvw5JlQcmRGzbu0oVlWyw59E96Kw8VCI62yn8siLkd91wNDcOuq6KodL8eZa2jDIW47n9HnX8Iig2Dxy2qUwrVAUAMKNrqg6K/h3YgTqYpr5KKsE60GaAEy0c4gaHTKT14CqyRbWSrME+TPzNVF8aQPtoMxNt9+w2JJNAbAXTo5lPDO0oYcOGjOJf7W5q8H6YCYw==
   template:
     metadata:
       annotations:
         sealedsecrets.bitnami.com/managed: ""true""
+      labels:
+        app.kubernetes.io/name: sonarr
+        app.kubernetes.io/instance: exportarr
+        app.kubernetes.io/component: exporter
       creationTimestamp: null
       name: sonarr-apikey
       namespace: multimedia

---FILE: apps/multimedia/sonarr/06_deployment.yaml---
@@ -5,21 +5,24 @@ metadata:
   name: sonarr-exporter
   namespace: multimedia
   labels:
-    app.kubernetes.io/name: sonarr-exporter
-    app.kubernetes.io/instance: sonarr-exporter
+    app.kubernetes.io/name: sonarr
+    app.kubernetes.io/instance: exportarr
+    app.kubernetes.io/component: exporter
     app.kubernetes.io/version: 0.3.4
 spec:
   replicas: 1
   revisionHistoryLimit: 3
   selector:
     matchLabels:
-      app.kubernetes.io/name: sonarr-exporter
-      app.kubernetes.io/instance: sonarr-exporter
+      app.kubernetes.io/name: sonarr
+      app.kubernetes.io/instance: exportarr
+      app.kubernetes.io/component: exporter
   template:
     metadata:
       labels:
-        app.kubernetes.io/name: sonarr-exporter
-        app.kubernetes.io/instance: sonarr-exporter
+        app.kubernetes.io/name: sonarr
+        app.kubernetes.io/instance: exportarr
+        app.kubernetes.io/component: exporter
         app.kubernetes.io/version: 0.3.4
     spec:
       containers:
@@ -31,7 +34,7 @@ spec:
           value: ""http://sonarr.multimedia.svc:8989""
         envFrom:
         - secretRef:
-            name: sonarr-exporter
+            name: sonarr-apikey
         ports:
         - name: sonarr-metrics
           containerPort: 9708

---FILE: apps/multimedia/sonarr/07_serviceMonitor.yaml---
@@ -3,15 +3,17 @@ apiVersion: monitoring.coreos.com/v1
 kind: ServiceMonitor
 metadata:
   name: sonarr-exporter
-  namespace: monitoring
+  namespace: multimedia
   labels:
-    app.kubernetes.io/name: sonarr-exporter
-    app.kubernetes.io/instance: sonarr-exporter
+    app.kubernetes.io/name: sonarr
+    app.kubernetes.io/instance: exportarr
+    app.kubernetes.io/component: exporter
 spec:
   selector:
     matchLabels:
-      app.kubernetes.io/name: sonarr-exporter
-      app.kubernetes.io/instance: sonarr-exporter
+      app.kubernetes.io/name: sonarr
+      app.kubernetes.io/instance: exportarr
+      app.kubernetes.io/component: exporter
   endpoints:
   - port: sonarr-metrics
     interval: 4m"
thaum-xyz,ankhmorpork,6aaae9708feb8e5c471b29f3172463c80aa53a89,paulfantom,pawel@krupa.net.pl,2021-01-07T21:15:47Z,paulfantom,pawel@krupa.net.pl,2021-01-07T21:15:47Z,apps/monitoring/rules: fix node-exporter alerts,apps/monitoring/prometheus/rules/node-exporter.yaml,False,False,False,False,34,34,68,"---FILE: apps/monitoring/prometheus/rules/node-exporter.yaml---
@@ -13,56 +13,56 @@ spec:
     - expr: |
         count without (cpu) (
           count without (mode) (
-            node_cpu_seconds_total{job=""node-exporter""}
+            node_cpu_seconds_total{job=~""node|node-exporter""}
           )
         )
       record: instance:node_num_cpu:sum
     - expr: |
         1 - avg without (cpu, mode) (
-          rate(node_cpu_seconds_total{job=""node-exporter"", mode=""idle""}[1m])
+          rate(node_cpu_seconds_total{job=~""node|node-exporter"", mode=""idle""}[1m])
         )
       record: instance:node_cpu_utilisation:rate1m
     - expr: |
         (
-          node_load1{job=""node-exporter""}
+          node_load1{job=~""node|node-exporter""}
         /
-          instance:node_num_cpu:sum{job=""node-exporter""}
+          instance:node_num_cpu:sum{job=~""node|node-exporter""}
         )
       record: instance:node_load1_per_cpu:ratio
     - expr: |
         1 - (
-          node_memory_MemAvailable_bytes{job=""node-exporter""}
+          node_memory_MemAvailable_bytes{job=~""node|node-exporter""}
         /
-          node_memory_MemTotal_bytes{job=""node-exporter""}
+          node_memory_MemTotal_bytes{job=~""node|node-exporter""}
         )
       record: instance:node_memory_utilisation:ratio
     - expr: |
-        rate(node_vmstat_pgmajfault{job=""node-exporter""}[1m])
+        rate(node_vmstat_pgmajfault{job=~""node|node-exporter""}[1m])
       record: instance:node_vmstat_pgmajfault:rate1m
     - expr: |
-        rate(node_disk_io_time_seconds_total{job=""node-exporter"", device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""}[1m])
+        rate(node_disk_io_time_seconds_total{job=~""node|node-exporter"", device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""}[1m])
       record: instance_device:node_disk_io_time_seconds:rate1m
     - expr: |
-        rate(node_disk_io_time_weighted_seconds_total{job=""node-exporter"", device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""}[1m])
+        rate(node_disk_io_time_weighted_seconds_total{job=~""node|node-exporter"", device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""}[1m])
       record: instance_device:node_disk_io_time_weighted_seconds:rate1m
     - expr: |
         sum without (device) (
-          rate(node_network_receive_bytes_total{job=""node-exporter"", device!=""lo""}[1m])
+          rate(node_network_receive_bytes_total{job=~""node|node-exporter"", device!=""lo""}[1m])
         )
       record: instance:node_network_receive_bytes_excluding_lo:rate1m
     - expr: |
         sum without (device) (
-          rate(node_network_transmit_bytes_total{job=""node-exporter"", device!=""lo""}[1m])
+          rate(node_network_transmit_bytes_total{job=~""node|node-exporter"", device!=""lo""}[1m])
         )
       record: instance:node_network_transmit_bytes_excluding_lo:rate1m
     - expr: |
         sum without (device) (
-          rate(node_network_receive_drop_total{job=""node-exporter"", device!=""lo""}[1m])
+          rate(node_network_receive_drop_total{job=~""node|node-exporter"", device!=""lo""}[1m])
         )
       record: instance:node_network_receive_drop_excluding_lo:rate1m
     - expr: |
         sum without (device) (
-          rate(node_network_transmit_drop_total{job=""node-exporter"", device!=""lo""}[1m])
+          rate(node_network_transmit_drop_total{job=~""node|node-exporter"", device!=""lo""}[1m])
         )
       record: instance:node_network_transmit_drop_excluding_lo:rate1m
   - name: node-exporter
@@ -74,11 +74,11 @@ spec:
         summary: Filesystem is predicted to run out of space within the next 24 hours.
       expr: |
         (
-          node_filesystem_avail_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} / node_filesystem_size_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} * 100 < 40
+          node_filesystem_avail_bytes{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} / node_filesystem_size_bytes{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} * 100 < 40
         and
-          predict_linear(node_filesystem_avail_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""}[6h], 24*60*60) < 0
+          predict_linear(node_filesystem_avail_bytes{job=~""node|node-exporter"",fstype!~""overlay|nsfs""}[6h], 24*60*60) < 0
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} == 0
+          node_filesystem_readonly{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} == 0
         )
       for: 1h
       labels:
@@ -90,11 +90,11 @@ spec:
         summary: Filesystem is predicted to run out of space within the next 4 hours.
       expr: |
         (
-          node_filesystem_avail_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} / node_filesystem_size_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} * 100 < 20
+          node_filesystem_avail_bytes{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} / node_filesystem_size_bytes{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} * 100 < 20
         and
-          predict_linear(node_filesystem_avail_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""}[6h], 4*60*60) < 0
+          predict_linear(node_filesystem_avail_bytes{job=~""node|node-exporter"",fstype!~""overlay|nsfs""}[6h], 4*60*60) < 0
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} == 0
+          node_filesystem_readonly{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} == 0
         )
       for: 1h
       labels:
@@ -106,9 +106,9 @@ spec:
         summary: Filesystem has less than 5% space left.
       expr: |
         (
-          node_filesystem_avail_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} / node_filesystem_size_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} * 100 < 5
+          node_filesystem_avail_bytes{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} / node_filesystem_size_bytes{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} * 100 < 5
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} == 0
+          node_filesystem_readonly{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} == 0
         )
       for: 1h
       labels:
@@ -120,9 +120,9 @@ spec:
         summary: Filesystem has less than 3% space left.
       expr: |
         (
-          node_filesystem_avail_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} / node_filesystem_size_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} * 100 < 3
+          node_filesystem_avail_bytes{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} / node_filesystem_size_bytes{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} * 100 < 3
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} == 0
+          node_filesystem_readonly{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} == 0
         )
       for: 1h
       labels:
@@ -134,11 +134,11 @@ spec:
         summary: Filesystem is predicted to run out of inodes within the next 24 hours.
       expr: |
         (
-          node_filesystem_files_free{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} / node_filesystem_files{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} * 100 < 40
+          node_filesystem_files_free{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} / node_filesystem_files{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} * 100 < 40
         and
-          predict_linear(node_filesystem_files_free{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""}[6h], 24*60*60) < 0
+          predict_linear(node_filesystem_files_free{job=~""node|node-exporter"",fstype!~""overlay|nsfs""}[6h], 24*60*60) < 0
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} == 0
+          node_filesystem_readonly{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} == 0
         )
       for: 1h
       labels:
@@ -150,11 +150,11 @@ spec:
         summary: Filesystem is predicted to run out of inodes within the next 4 hours.
       expr: |
         (
-          node_filesystem_files_free{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} / node_filesystem_files{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} * 100 < 20
+          node_filesystem_files_free{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} / node_filesystem_files{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} * 100 < 20
         and
-          predict_linear(node_filesystem_files_free{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""}[6h], 4*60*60) < 0
+          predict_linear(node_filesystem_files_free{job=~""node|node-exporter"",fstype!~""overlay|nsfs""}[6h], 4*60*60) < 0
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} == 0
+          node_filesystem_readonly{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} == 0
         )
       for: 1h
       labels:
@@ -166,9 +166,9 @@ spec:
         summary: Filesystem has less than 5% inodes left.
       expr: |
         (
-          node_filesystem_files_free{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} / node_filesystem_files{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} * 100 < 5
+          node_filesystem_files_free{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} / node_filesystem_files{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} * 100 < 5
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} == 0
+          node_filesystem_readonly{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} == 0
         )
       for: 1h
       labels:
@@ -180,9 +180,9 @@ spec:
         summary: Filesystem has less than 3% inodes left.
       expr: |
         (
-          node_filesystem_files_free{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} / node_filesystem_files{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} * 100 < 3
+          node_filesystem_files_free{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} / node_filesystem_files{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} * 100 < 3
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} == 0
+          node_filesystem_readonly{job=~""node|node-exporter"",fstype!~""overlay|nsfs""} == 0
         )
       for: 1h
       labels:
@@ -220,7 +220,7 @@ spec:
         description: Node Exporter text file collector failed to scrape.
         summary: Node Exporter text file collector failed to scrape.
       expr: |
-        node_textfile_scrape_error{job=""node-exporter""} == 1
+        node_textfile_scrape_error{job=~""node|node-exporter""} == 1
       labels:
         severity: warning
     - alert: NodeClockSkewDetected"
thaum-xyz,ankhmorpork,c6645a0f42d53c2a1ff395713fe8b263a287fca4,paulfantom,pawel@krupa.net.pl,2021-01-04T09:00:35Z,paulfantom,pawel@krupa.net.pl,2021-01-04T09:00:35Z,ansible: fix node labels,ansible/host_vars/hyper01.yml;ansible/host_vars/node04.yml;ansible/host_vars/node05.yml,False,False,False,False,40,3,43,"---FILE: ansible/host_vars/hyper01.yml---
@@ -3,13 +3,14 @@ nfs_exports:
   - ""/mnt 192.168.2.40(rw,sync,no_subtree_check,no_root_squash,no_all_squash,insecure)""
   - ""/srv/storage/kubernetes *(rw,sync,no_subtree_check,no_root_squash,no_all_squash,insecure)""
 
-# 8GB is dedicated to ZFS storage
-kubelet_system_resources: ""cpu=2000m,memory=8Gi""
+# 8GB and 2 cores are dedicated to ZFS storage
+# 40GB and 8 cores are dedicated to VMs
+kubelet_system_resources: ""cpu=10000m,memory=48Gi""  # This leaves 2 cores and ~14G
 node_taints:
   - ""node.infra/hypervisor=true:NoSchedule""
 
 node_labels:
-  - ""storage.infra/local=true""
+  - ""storage.infra/direct=true""
   - ""storage.infra/replicated=true""
   - ""storage.infra/capacious=true""
   - ""gpu.infra/nvidia=true""

---FILE: ansible/host_vars/node04.yml---
@@ -0,0 +1,18 @@
+---
+nfs_srv_addr: ""192.168.40.2""
+
+node_labels:
+  - ""storage.infra/local=true""
+  - ""storage.infra/replicated=true""
+
+system_mountpoints:
+  - description: k3s local storage
+    before: k3s-node.service
+    device: ""/dev/ubuntu-vg/k3s-storage""
+    mountpoint: ""/var/lib/rancher/k3s/storage""
+    type: ""ext4""
+  - description: k3s longhorn storage
+    before: k3s-node.service
+    device: ""/dev/ubuntu-vg/longhorn""
+    mountpoint: ""/var/lib/longhorn""
+    type: ""ext4""

---FILE: ansible/host_vars/node05.yml---
@@ -0,0 +1,18 @@
+---
+nfs_srv_addr: ""192.168.40.2""
+
+node_labels:
+  - ""storage.infra/local=true""
+  - ""storage.infra/replicated=true""
+
+system_mountpoints:
+  - description: k3s local storage
+    before: k3s-node.service
+    device: ""/dev/ubuntu-vg/k3s-storage""
+    mountpoint: ""/var/lib/rancher/k3s/storage""
+    type: ""ext4""
+  - description: k3s longhorn storage
+    before: k3s-node.service
+    device: ""/dev/ubuntu-vg/longhorn""
+    mountpoint: ""/var/lib/longhorn""
+    type: ""ext4"""
thaum-xyz,ankhmorpork,c2b088b1a0f9051e79de657a8de19e9c186d9fe0,paulfantom,pawel@krupa.net.pl,2020-12-21T15:27:08Z,paulfantom,pawel@krupa.net.pl,2020-12-21T15:27:08Z,ansible: fix systemd_exporter denylist,ansible/group_vars/all.yml,False,False,False,False,1,3,4,"---FILE: ansible/group_vars/all.yml---
@@ -21,6 +21,4 @@ node_exporter_disabled_collectors:
 
 systemd_exporter_enable_ip_accounting: true
 systemd_exporter_enable_restart_count: true
-systemd_exporter_unit_blacklist:
-  - '.*.mount'
-  - 'user-runtime-dir@0.service'
+systemd_exporter_unit_blacklist: '.*.mount|user-runtime-dir@0.service'"
thaum-xyz,ankhmorpork,8f6e2ff4f89f154a11401cf2f5d579db09bf10c5,paulfantom,pawel@krupa.net.pl,2020-12-19T21:39:00Z,paulfantom,pawel@krupa.net.pl,2020-12-19T21:39:00Z,"hack: fix ""or"" operator",hack/checkimages.sh,False,False,False,False,1,1,2,"---FILE: hack/checkimages.sh---
@@ -79,7 +79,7 @@ for image in ${IMAGES}; do
 		sleep ""$((RANDOM % 10))"" # Add some delay to prevent DDoSing registry
 		info=$(manifest-tool inspect --raw ""${image}"" 2>&1 || :)
 		# Handles 429 Too Many Requests response
-		if [[ ""$info"" =~ ""You have reached your pull rate limit"" ]] -o [[ ""$info"" =~ ""429 Too Many Requests"" ]]; then
+		if [[ ""$info"" =~ ""You have reached your pull rate limit"" ]] || [[ ""$info"" =~ ""429 Too Many Requests"" ]]; then
 			echo -e ""$SKIP Too many retries when trying to validate cross-arch compatibility for \e[1m${image}\e[0m""
 			exit 0
 		fi"
thaum-xyz,ankhmorpork,9de868ad91bf6535c674e156c2e0e3bcbdebb62e,paulfantom,pawel@krupa.net.pl,2020-12-19T14:54:52Z,paulfantom,pawel@krupa.net.pl,2020-12-19T14:54:52Z,hack: surface other issues reported by manifest-tool,hack/checkimages.sh,False,False,False,False,5,1,6,"---FILE: hack/checkimages.sh---
@@ -83,6 +83,10 @@ for image in ${IMAGES}; do
 			echo -e ""$SKIP Too many retries when trying to validate cross-arch compatibility for \e[1m${image}\e[0m""
 			exit 0
 		fi
+		if echo ""${info}"" | grep -q 'level=fatal'; then
+			echo -e ""$FAIL Encountered fatal problems with \e[1m${image}\e[0m: ${info/*msg=/}""
+			exit 1
+		fi
 
 		check_cross_compatibility ""${image}"" ""${info}"" || exit 1
 		echo -e ""$OK Image \e[1m${image}\e[0m is compatible""
@@ -95,7 +99,7 @@ for job in ""${pids[@]}""; do
 	CODE=0
 	wait ${job} || CODE=$?
 	if [[ ""${CODE}"" != ""0"" ]]; then
-		echo ""At least one image is not compatible with specified CPU architectures""
+		echo -e ""$FAIL Detected problems with at least one image""
 		EXIT_CODE=$CODE
 	fi
 done"
thaum-xyz,ankhmorpork,8257dbb7e8e5907c09ed0ccfba4d7db208dd530b,paulfantom,pawel@krupa.net.pl,2020-12-19T14:17:39Z,paulfantom,pawel@krupa.net.pl,2020-12-19T14:17:48Z,"hack: fix handling too many requests and other improvements

- Fix handling Too Many Requests
- Check image exclusion first
- Check if exlusion list is up to date
- Do not fail on manifest-tool immediately",hack/checkimages.sh,False,False,False,False,33,29,62,"---FILE: hack/checkimages.sh---
@@ -2,88 +2,92 @@
 
 set -euo pipefail
 
-CPU_ARCHS=""amd64 arm64 arm""
+CPU_ARCHS=""amd64 arm64""
 MULTI_ARCH_EXCLUDED=$(
 	cat <<EOM
-quay.io/external_storage/nfs-client-provisioner-arm
 quay.io/external_storage/nfs-client-provisioner
-quay.io/paulfantom/nfs-client-provisioner
 eu.gcr.io/k8s-artifacts-prod/descheduler/descheduler
 homeassistant/aarch64-homeassistant
 plexinc/pms-docker
 quay.io/paulfantom/plex_exporter
 metalmatze/transmission-exporter
-haugene/transmission-openvpn
 mariadb
 oliver006/redis_exporter
 hipages/php-fpm_exporter
 xperimental/nextcloud-exporter
-nginx/nginx-prometheus-exporter
 allangood/holiday_exporter
 quay.io/superq/smokeping-prober-linux-arm64
 quay.io/prometheus/mysqld-exporter
 intel/intel-gpu-plugin
-rancher/k3s-upgrade
 EOM
 )
 
 FAIL=""[ \e[1m\e[31mFAIL\e[0m ]""
 SKIP=""[ \e[1m\e[33mSKIP\e[0m ]""
 OK=""[  \e[1m\e[32mOK\e[0m  ]""
+INFO=""[ \e[1m\e[34mSKIP\e[0m ]""
 
 check_cross_compatibility() {
 	local image=""${1}""
 	local manifest=""${2}""
-	local err=0
 	local arch_list
-
-	for exclude in ${MULTI_ARCH_EXCLUDED}; do
-		if [[ ""${image}"" =~ ${exclude} ]]; then
-			echo -e ""$SKIP Validating cross-arch compatibility for \e[1m${image}\e[0m""
-			exit 0
-		fi
-	done
+	local arch_fail=""""
 
 	arch_list=""$(echo ""${manifest}"" | jq -cr '..| .architecture?, .Architecture? | select(type != ""null"") | select(. != """" )' | sort | uniq)""
 	for arch in ${CPU_ARCHS}; do
 		if ! grep -q ""${arch}$"" <<<""$arch_list""; then
-			echo -e ""$FAIL Image \e[1m${image}\e[0m does not support ${arch} !""
-			err=1
+			arch_fail=""${arch_fail} ${arch}""
 		fi
 	done
-	if [ ""$err"" -ne 0 ]; then
+	if [ ""$arch_fail"" != """" ]; then
+		echo -e ""$FAIL Image \e[1m${image}\e[0m does not support following architectures: ${arch_fail}!""
 		exit 129
 	fi
 }
 
 # Go to top-level
 cd ""$(git rev-parse --show-toplevel)""
 
-IMAGES=""""
-
+# Find all images used in environment
+DETECTED_IMAGES=""""
 for file in $(find apps/ base/ -name *.yaml -exec grep ""image"" -l {} \;); do
 	new=$(gojsontoyaml -yamltojson <""$file"" | jq -cr '..| .image? | select(type == ""string"")')
-	IMAGES=""${new} ${IMAGES}""
+	DETECTED_IMAGES=""${new} ${DETECTED_IMAGES}""
 done
 
+# Check if exclusion list is up to date
+for image in ${MULTI_ARCH_EXCLUDED}; do
+	grep ""${image}"" -q -R apps/ base/ || echo -e ""$INFO Excluded image \e[1m${image}\e[0m no longer used""
+done
+
+# Remove duplicates, sanitize, and check if image shoud be skipped
+IMAGES=""""
+for image in $(echo -e ""${DETECTED_IMAGES}"" | tr ' ' '\n' | sort -f | uniq | grep -v '^$'); do
+	# remove version
+	prefix=$(echo ""$image"" | tr ':' '\n' | head -n1)
+	if [[ ${MULTI_ARCH_EXCLUDED} =~ ""${prefix}"" ]]; then
+		echo -e ""$SKIP Validating cross-arch compatibility for \e[1m${image}\e[0m""
+	else
+		IMAGES=""${IMAGES} ${image}""
+	fi
+done
+
+# In parallel check image manifests
 pids=()
-for image in $(echo -e ""${IMAGES}"" | tr ' ' '\n' | sort -f | uniq); do
+for image in ${IMAGES}; do
 	(
-		info=$(manifest-tool inspect --raw ""${image}"" 2>&1)
+		sleep ""$((RANDOM % 10))"" # Add some delay to prevent DDoSing registry
+		info=$(manifest-tool inspect --raw ""${image}"" 2>&1 || :)
 		# Handles 429 Too Many Requests response
-		if [[ ""$info"" =~ ""429 Too Many Requests"" ]]; then
-			echo -e ""$SKIP Too many retries when trying to validate cross-arch compatibility for \e[1m${image}\e[0m - $info""
+		if [[ ""$info"" =~ ""You have reached your pull rate limit"" ]]; then
+			echo -e ""$SKIP Too many retries when trying to validate cross-arch compatibility for \e[1m${image}\e[0m""
 			exit 0
 		fi
 
-		if ! check_cross_compatibility ""${image}"" ""${info}""; then
-			echo -e ""$FAIL Image \e[1m${image}\e[0m is not compatible with system architecture""
-			exit 1
-		fi
+		check_cross_compatibility ""${image}"" ""${info}"" || exit 1
 		echo -e ""$OK Image \e[1m${image}\e[0m is compatible""
 	) &
 	pids+=(""$!"")
-	sleep ""$((RANDOM % 10))"" # Add some delay to prevent DDoSing registry
 done
 
 EXIT_CODE=0"
thaum-xyz,ankhmorpork,af906d75845e5979ee40d43573b05bc64df55e61,paulfantom,pawel@krupa.net.pl,2020-12-18T20:18:19Z,paulfantom,pawel@krupa.net.pl,2020-12-18T20:18:19Z,apps/multimedia: fix download paths,apps/multimedia/radarr/04_statefulset.yaml;apps/multimedia/sonarr/04_statefulset.yaml,False,False,False,False,2,2,4,"---FILE: apps/multimedia/radarr/04_statefulset.yaml---
@@ -40,7 +40,7 @@ spec:
             name: config
           - mountPath: /movies
             name: data
-          - mountPath: /data/completed
+          - mountPath: /download/completed
             name: downloads
         resources:
           requests:

---FILE: apps/multimedia/sonarr/04_statefulset.yaml---
@@ -41,7 +41,7 @@ spec:
             name: config
           - mountPath: /tv
             name: data
-          - mountPath: /data/completed
+          - mountPath: /download/completed
             name: downloads
         resources:
           requests:"
thaum-xyz,ankhmorpork,5c84bd29136aa3b5e8b82bfc9da032c0dd3493a2,paulfantom,pawel@krupa.net.pl,2020-12-18T15:09:35Z,paulfantom,pawel@krupa.net.pl,2020-12-18T15:09:35Z,ansible: fix network label,ansible/group_vars/k3s.yml,False,False,False,False,1,1,2,"---FILE: ansible/group_vars/k3s.yml---
@@ -17,6 +17,6 @@ k3s_token: ""{{ hostvars[groups['k3s-master'][0]]['token'] }}""
 k3s_extra_agent_args: >-
   --kubelet-arg kube-reserved=cpu=100m,memory=200Mi
   --kubelet-arg system-reserved={{ kubelet_system_resources | default('cpu=100m,memory=200Mi') }}
-  --node-label network.infra/network={{ network | default('slow') }}
+  --node-label network.infra/type={{ network | default('slow') }}
 
 system_earlyoom_params: ""-r 60 -m 4"""
thaum-xyz,ankhmorpork,272c70c895a224abe1135f4a00e2a21479f383e2,paulfantom,pawel@krupa.net.pl,2020-12-18T14:52:23Z,paulfantom,pawel@krupa.net.pl,2020-12-18T14:52:23Z,ansible: fix node labelling,ansible/group_vars/k3s.yml;ansible/host_vars/hyper01.yml;ansible/host_vars/node01.yml,False,False,False,False,4,5,9,"---FILE: ansible/group_vars/k3s.yml---
@@ -1,7 +1,8 @@
 ---
 k3s_version: v1.19.4+k3s1
+# k3s_version: v1.20.0-rc5+k3s1
 k3s_master_ip: ""{{ hostvars[groups['k3s-master'][0]]['ansible_default_ipv4']['address'] }}""
-k3s_extra_server_args: >
+k3s_extra_server_args: >-
   --disable servicelb
   --disable traefik
   --disable-cloud-controller
@@ -13,9 +14,9 @@ k3s_extra_server_args: >
 
 k3s_token: ""{{ hostvars[groups['k3s-master'][0]]['token'] }}""
 
-k3s_extra_agent_args: >
+k3s_extra_agent_args: >-
   --kubelet-arg kube-reserved=cpu=100m,memory=200Mi
   --kubelet-arg system-reserved={{ kubelet_system_resources | default('cpu=100m,memory=200Mi') }}
-  --node-label node.infra/network={{ network | default('slow') }}
+  --node-label network.infra/network={{ network | default('slow') }}
 
 system_earlyoom_params: ""-r 60 -m 4""

---FILE: ansible/host_vars/hyper01.yml---
@@ -12,7 +12,6 @@ node_labels:
   - ""storage.infra/local=true""
   - ""storage.infra/replicated=true""
   - ""storage.infra/capacious=true""
-  - ""network.infra/type=fast""
   - ""gpu.infra/nvidia=true""
 
 system_mountpoints:

---FILE: ansible/host_vars/node01.yml---
@@ -4,7 +4,6 @@ nfs_srv_addr: ""192.168.40.2""
 node_labels:
   - ""storage.infra/local=true""
   - ""storage.infra/replicated=true""
-  - ""network.infra/type=fast""
   - ""gpu.infra/intel=true""
 
 system_mountpoints:"
thaum-xyz,ankhmorpork,0fde18b59649e6baf4e6d0cf03a36d0f506eeeca,paulfantom,pawel@krupa.net.pl,2020-12-18T13:37:39Z,paulfantom,pawel@krupa.net.pl,2020-12-18T13:37:39Z,"base,apps: fix labels after #60",apps/monitoring/ksm/04_statefulset.yaml;apps/nextcloud/mysql/05_deployment.yaml;apps/nextcloud/proxy/04_deployment.yaml;base/ingress-nginx/deploy.yaml;base/metallb-system/02_metallb.yaml;base/storage-system/external-nfs/02_deployment.yaml,False,False,False,False,10,23,33,"---FILE: apps/monitoring/ksm/04_statefulset.yaml---
@@ -41,7 +41,7 @@ spec:
         #- --labels-metric-allow-list=nodes=[""kubernetes.io/arch"",""gpu.infra/intel"",""network.infra/fast""]
         #- --labels-metric-allow-list=""nodes=[""kubernetes.io/arch"",""gpu.infra/intel"",""network.infra/fast""]""
         #- --labels-metric-allow-list=""nodes=[kubernetes.io/arch,gpu.infra/intel,network.infra/fast]""
-        - --labels-metric-allow-list=nodes=[kubernetes.io/arch,gpu.infra/intel,network.infra/fast]
+        - --labels-metric-allow-list=nodes=[kubernetes.io/arch,gpu.infra/intel,network.infra/type]
         env:
         - name: POD_NAME
           valueFrom:

---FILE: apps/nextcloud/mysql/05_deployment.yaml---
@@ -115,8 +115,4 @@ spec:
       nodeSelector:
         kubernetes.io/hostname: ""node01""  # TODO: fix this
         # storage.infra/raid: ""true""
-      tolerations:
-      - key: ""storage.infra""
-        operator: ""Equal""
-        value: ""true""
-        effect: ""NoSchedule""
+      tolerations: []

---FILE: apps/nextcloud/proxy/04_deployment.yaml---
@@ -82,8 +82,6 @@ spec:
       - name: apps
         persistentVolumeClaim:
           claimName: nextcloud-apps
-      #nodeSelector:
-      #  kubernetes.io/arch: ""amd64""
-      #  kubernetes.io/hostname: ""storage01""
-      #  storage.infra/raid: ""true""
+      nodeSelector:
+        network.infra/type: ""fast""
       tolerations: []

---FILE: base/ingress-nginx/deploy.yaml---
@@ -414,12 +414,8 @@ spec:
           secret:
             secretName: ingress-nginx-admission
       nodeSelector:
-        network.infra/fast: ""true""
-      tolerations:
-      - key: ""storage.infra""
-        operator: ""Equal""
-        value: ""true""
-        effect: ""NoSchedule""
+        network.infra/type: ""fast""
+      tolerations: []
 ---
 # Source: ingress-nginx/templates/admission-webhooks/validating-webhook.yaml
 # before changing this value, check the required kubernetes version

---FILE: base/metallb-system/02_metallb.yaml---
@@ -331,14 +331,10 @@ spec:
           readOnlyRootFilesystem: true
       hostNetwork: true
       nodeSelector:
-        network.infra/fast: ""true""
+        network.infra/type: ""fast""
       serviceAccountName: speaker
       terminationGracePeriodSeconds: 2
-      tolerations:
-      - key: ""storage.infra""
-        operator: ""Equal""
-        value: ""true""
-        effect: ""NoSchedule""
+      tolerations: []
 ---
 apiVersion: apps/v1
 kind: Deployment

---FILE: base/storage-system/external-nfs/02_deployment.yaml---
@@ -42,8 +42,9 @@ spec:
             path: /srv/storage/kubernetes
       nodeSelector:
         kubernetes.io/arch: amd64
+        storage.infra/capacious: ""true""
       tolerations:
-      - key: ""storage.infra""
+      - key: ""node.infra/hypervisor""
         operator: ""Equal""
         value: ""true""
         effect: ""NoSchedule"""
thaum-xyz,ankhmorpork,54c283c506c783df7670224d7076b83024f1fa7e,paulfantom,pawel@krupa.net.pl,2020-12-17T19:04:31Z,paulfantom,pawel@krupa.net.pl,2020-12-17T19:04:31Z,apps/dns/local: incorrect image was pushed,apps/dns/local/04_deployment.yaml,False,False,False,False,1,0,1,"---FILE: apps/dns/local/04_deployment.yaml---
@@ -40,6 +40,7 @@ spec:
       containers:
       - name: coredns
         image: quay.io/paulfantom/coredns-ads:0.2.5
+        imagePullPolicy: Always
         # image: coredns/coredns
         resources:
           limits:"
thaum-xyz,ankhmorpork,3d83b2308d808ef6335d93fde2033f27cf7c0776,paulfantom,pawel@krupa.net.pl,2020-12-17T16:56:49Z,paulfantom,pawel@krupa.net.pl,2020-12-17T16:56:54Z,apps/dns/local: fix port assignment,apps/dns/local/02_service.yaml,False,False,False,False,2,2,4,"---FILE: apps/dns/local/02_service.yaml---
@@ -36,10 +36,10 @@ spec:
     app.kubernetes.io/name: coredns
     app.kubernetes.io/component: adblocker
   ports:
-  - name: dns
+  - name: dns-tcp
     port: 53
     protocol: TCP
-    targetPort: dns
+    targetPort: dns-tcp
 ---
 apiVersion: v1
 kind: Service"
thaum-xyz,ankhmorpork,8050ed5e7a457ae7d9812ba68b4b28e92ae656a5,paulfantom,pawel@krupa.net.pl,2020-12-15T19:21:27Z,paulfantom,pawel@krupa.net.pl,2020-12-15T19:21:27Z,apps/nextcloud/redis: fix exporter access,apps/nextcloud/redis/03_deployment.yaml,False,False,False,False,8,3,11,"---FILE: apps/nextcloud/redis/03_deployment.yaml---
@@ -38,9 +38,14 @@ spec:
         resources:
           requests:
             memory: 5Mi
-      - env:
-        - name: REDIS_ADDR
-          value: ""127.0.0.1""
+      - args:
+        - ""--redis.password""
+        - ""$(REDIS_HOST_PASSWORD)""
+        - ""--redis.addr""
+        - ""127.0.0.1""
+        envFrom:
+        - secretRef:
+            name: redis-password
         image: oliver006/redis_exporter
         name: redis-exporter
         ports:"
thaum-xyz,ankhmorpork,da89a26dd64c8867dc1e962d0561c0560c57bbc1,paulfantom,pawel@krupa.net.pl,2020-12-11T18:02:02Z,paulfantom,pawel@krupa.net.pl,2020-12-11T18:02:02Z,setup kube-linter and ignore current issues,.kubelinter.yaml;apps/auth/04_deployment.yaml;apps/monitoring/alertmanager/service.yaml;apps/monitoring/ksm/04_statefulset.yaml;apps/monitoring/prometheus/02_service.yaml;apps/monitoring/pushgateway/01_service.yaml;apps/monitoring/pushgateway/02_deployment.yaml;base/argocd/argo/00_crds.yaml;base/storage-system/external-nfs/02_deployment.yaml,False,False,False,False,88,1,89,"---FILE: .kubelinter.yaml---
@@ -3,3 +3,6 @@ checks:
   exclude:
     - ""unset-cpu-requirements""
     - ""unset-memory-requirements""
+    - ""no-read-only-root-fs""
+    - ""run-as-non-root""
+    - ""no-extensions-v1beta""  # argocd still uses invalid API

---FILE: apps/auth/04_deployment.yaml---
@@ -19,6 +19,17 @@ spec:
         app.kubernetes.io/name: oauth2-proxy
         app.kubernetes.io/version: 6.1.1
     spec:
+      affinity:
+        podAntiAffinity:
+          preferredDuringSchedulingIgnoredDuringExecution:
+          - weight: 100
+            podAffinityTerm:
+              labelSelector:
+                matchExpressions:
+                  - key: app.kubernetes.io/name
+                    operator: In
+                    values: [""oauth2-proxy""]
+              topologyKey: kubernetes.io/hostname
       containers:
       - args:
         - --provider=google

---FILE: apps/monitoring/alertmanager/service.yaml---
@@ -1,6 +1,9 @@
+---
 apiVersion: v1
 kind: Service
 metadata:
+  annotations:
+    ignore-check.kube-linter.io/dangling-service: ""Check is incompatible with prometheus-operator CRDs""
   labels:
     alertmanager: main
   name: alertmanager-main

---FILE: apps/monitoring/ksm/04_statefulset.yaml---
@@ -18,6 +18,17 @@ spec:
         app.kubernetes.io/name: kube-state-metrics
         app.kubernetes.io/version: 2.0.0-alpha
     spec:
+      affinity:
+        podAntiAffinity:
+          preferredDuringSchedulingIgnoredDuringExecution:
+          - weight: 100
+            podAffinityTerm:
+              labelSelector:
+                matchExpressions:
+                  - key: app.kubernetes.io/name
+                    operator: In
+                    values: [""kube-state-metrics""]
+              topologyKey: kubernetes.io/hostname
       containers:
       - args:
         - --host=127.0.0.1

---FILE: apps/monitoring/prometheus/02_service.yaml---
@@ -1,6 +1,9 @@
+---
 apiVersion: v1
 kind: Service
 metadata:
+  annotations:
+    ignore-check.kube-linter.io/dangling-service: ""Check is incompatible with prometheus-operator CRDs""
   labels:
     prometheus: k8s
   name: prometheus-k8s

---FILE: apps/monitoring/pushgateway/01_service.yaml---
@@ -15,3 +15,4 @@ spec:
     targetPort: http-push
   selector:
     app.kubernetes.io/name: pushgateway
+    app.kubernetes.io/component: exporter

---FILE: apps/monitoring/pushgateway/02_deployment.yaml---
@@ -3,6 +3,7 @@ apiVersion: apps/v1
 kind: Deployment
 metadata:
   name: pushgateway
+  namespace: monitoring
   labels:
     app.kubernetes.io/name: pushgateway
     app.kubernetes.io/version: 1.2.0
@@ -16,6 +17,7 @@ spec:
     metadata:
       labels:
         app.kubernetes.io/name: pushgateway
+        app.kubernetes.io/component: exporter
     spec:
       containers:
       - name: pushgateway

---FILE: base/argocd/argo/00_crds.yaml---
@@ -7,6 +7,17 @@ metadata:
     app.kubernetes.io/part-of: argocd
   name: applications.argoproj.io
 spec:
+  additionalPrinterColumns:
+  - JSONPath: .status.sync.status
+    name: Sync Status
+    type: string
+  - JSONPath: .status.health.status
+    name: Health Status
+    type: string
+  - JSONPath: .status.sync.revision
+    name: Revision
+    priority: 10
+    type: string
   group: argoproj.io
   names:
     kind: Application
@@ -17,6 +28,7 @@ spec:
     - apps
     singular: application
   scope: Namespaced
+  subresources: {}
   validation:
     openAPIV3Schema:
       description: Application is a definition of Application resource.
@@ -120,6 +132,8 @@ spec:
                     directory:
                       description: Directory holds path/directory specific options
                       properties:
+                        exclude:
+                          type: string
                         jsonnet:
                           description: ApplicationSourceJsonnet holds jsonnet specific options
                           properties:
@@ -237,6 +251,11 @@ spec:
                     kustomize:
                       description: Kustomize holds kustomize specific options
                       properties:
+                        commonAnnotations:
+                          additionalProperties:
+                            type: string
+                          description: CommonAnnotations adds additional kustomize commonAnnotations
+                          type: object
                         commonLabels:
                           additionalProperties:
                             type: string
@@ -381,6 +400,8 @@ spec:
                 directory:
                   description: Directory holds path/directory specific options
                   properties:
+                    exclude:
+                      type: string
                     jsonnet:
                       description: ApplicationSourceJsonnet holds jsonnet specific options
                       properties:
@@ -498,6 +519,11 @@ spec:
                 kustomize:
                   description: Kustomize holds kustomize specific options
                   properties:
+                    commonAnnotations:
+                      additionalProperties:
+                        type: string
+                      description: CommonAnnotations adds additional kustomize commonAnnotations
+                      type: object
                     commonLabels:
                       additionalProperties:
                         type: string
@@ -658,6 +684,8 @@ spec:
                       directory:
                         description: Directory holds path/directory specific options
                         properties:
+                          exclude:
+                            type: string
                           jsonnet:
                             description: ApplicationSourceJsonnet holds jsonnet specific options
                             properties:
@@ -775,6 +803,11 @@ spec:
                       kustomize:
                         description: Kustomize holds kustomize specific options
                         properties:
+                          commonAnnotations:
+                            additionalProperties:
+                              type: string
+                            description: CommonAnnotations adds additional kustomize commonAnnotations
+                            type: object
                           commonLabels:
                             additionalProperties:
                               type: string
@@ -938,6 +971,8 @@ spec:
                             directory:
                               description: Directory holds path/directory specific options
                               properties:
+                                exclude:
+                                  type: string
                                 jsonnet:
                                   description: ApplicationSourceJsonnet holds jsonnet specific options
                                   properties:
@@ -1055,6 +1090,11 @@ spec:
                             kustomize:
                               description: Kustomize holds kustomize specific options
                               properties:
+                                commonAnnotations:
+                                  additionalProperties:
+                                    type: string
+                                  description: CommonAnnotations adds additional kustomize commonAnnotations
+                                  type: object
                                 commonLabels:
                                   additionalProperties:
                                     type: string
@@ -1196,6 +1236,8 @@ spec:
                         directory:
                           description: Directory holds path/directory specific options
                           properties:
+                            exclude:
+                              type: string
                             jsonnet:
                               description: ApplicationSourceJsonnet holds jsonnet specific options
                               properties:
@@ -1313,6 +1355,11 @@ spec:
                         kustomize:
                           description: Kustomize holds kustomize specific options
                           properties:
+                            commonAnnotations:
+                              additionalProperties:
+                                type: string
+                              description: CommonAnnotations adds additional kustomize commonAnnotations
+                              type: object
                             commonLabels:
                               additionalProperties:
                                 type: string
@@ -1451,6 +1498,8 @@ spec:
                         directory:
                           description: Directory holds path/directory specific options
                           properties:
+                            exclude:
+                              type: string
                             jsonnet:
                               description: ApplicationSourceJsonnet holds jsonnet specific options
                               properties:
@@ -1568,6 +1617,11 @@ spec:
                         kustomize:
                           description: Kustomize holds kustomize specific options
                           properties:
+                            commonAnnotations:
+                              additionalProperties:
+                                type: string
+                              description: CommonAnnotations adds additional kustomize commonAnnotations
+                              type: object
                             commonLabels:
                               additionalProperties:
                                 type: string

---FILE: base/storage-system/external-nfs/02_deployment.yaml---
@@ -33,7 +33,6 @@ spec:
           volumeMounts:
             - mountPath: /persistentvolumes
               name: external-nfs-root
-      serviceAccount: external-nfs-provisioner
       serviceAccountName: external-nfs-provisioner
       priorityClassName: system-cluster-critical
       volumes:"
thaum-xyz,ankhmorpork,0872c2b1b95efdb7c82ca72d05cc0e0179b6c583,paulfantom,pawel@krupa.net.pl,2020-11-27T12:50:03Z,paulfantom,pawel@krupa.net.pl,2020-11-27T12:50:03Z,apps/multimedia: move ombi pv to external-nfs and fix pvs,apps/multimedia/02_pv.yaml;apps/multimedia/ombi/04_statefulset.yaml;apps/multimedia/plex/00_pv.yaml;apps/multimedia/transmission/01_pvc.yaml,False,False,False,False,33,99,132,"---FILE: apps/multimedia/02_pv.yaml---
@@ -1,96 +0,0 @@
----
-apiVersion: v1
-kind: PersistentVolume
-metadata:
-  name: movies
-  namespace: multimedia
-spec:
-  capacity:
-    storage: 4000Gi
-  volumeMode: Filesystem
-  accessModes:
-    - ReadWriteOnce
-  persistentVolumeReclaimPolicy: Retain
-  storageClassName: manual
-  # mountOptions:
-  #   - hard
-  #   - nfsvers=4.1
-  nfs:
-    path: /srv/storage/kubernetes/vod/movies
-    server: 192.168.2.40
----
-apiVersion: v1
-kind: PersistentVolume
-metadata:
-  name: tv
-  namespace: multimedia
-spec:
-  capacity:
-    storage: 4000Gi
-  volumeMode: Filesystem
-  accessModes:
-    - ReadWriteOnce
-  persistentVolumeReclaimPolicy: Retain
-  storageClassName: manual
-  # mountOptions:
-  #   - hard
-  #   - nfsvers=4.1
-  nfs:
-    path: /srv/storage/kubernetes/vod/tv
-    server: 192.168.2.40
----
-apiVersion: v1
-kind: PersistentVolume
-metadata:
-  name: torrents
-  namespace: multimedia
-spec:
-  capacity:
-    storage: 100Gi
-  volumeMode: Filesystem
-  accessModes:
-    - ReadWriteOnce
-  persistentVolumeReclaimPolicy: Retain
-  storageClassName: manual
-  nfs:
-    path: /srv/storage/kubernetes/torrents
-    server: 192.168.2.40
----
-apiVersion: v1
-kind: PersistentVolumeClaim
-metadata:
-  name: movies
-  namespace: multimedia
-spec:
-  storageClassName: manual
-  accessModes:
-    - ReadWriteOnce
-  resources:
-    requests:
-      storage: 4000Gi
----
-apiVersion: v1
-kind: PersistentVolumeClaim
-metadata:
-  name: tv
-  namespace: multimedia
-spec:
-  storageClassName: manual
-  accessModes:
-    - ReadWriteOnce
-  resources:
-    requests:
-      storage: 4000Gi
----
-apiVersion: v1
-kind: PersistentVolumeClaim
-metadata:
-  name: torrents
-  namespace: multimedia
-spec:
-  storageClassName: manual
-  accessModes:
-    - ReadWriteOnce
-  resources:
-    requests:
-      storage: 100Gi

---FILE: apps/multimedia/ombi/04_statefulset.yaml---
@@ -47,9 +47,9 @@ spec:
       name: config
       namespace: multimedia
       annotations:
-        volume.beta.kubernetes.io/storage-class: ""nfs-client""
+        volume.beta.kubernetes.io/storage-class: ""external-nfs""
     spec:
-      storageClassName: ""nfs-client""
+      storageClassName: ""external-nfs""
       accessModes:
         - ReadWriteMany
       resources:

---FILE: apps/multimedia/plex/00_pv.yaml---
@@ -1,4 +1,3 @@
-# All this needs to be removed after migration to ZFS
 ---
 apiVersion: v1
 kind: PersistentVolume
@@ -65,3 +64,4 @@ spec:
   resources:
     requests:
       storage: 4000Gi
+

---FILE: apps/multimedia/transmission/01_pvc.yaml---
@@ -1,5 +1,35 @@
 ---
 apiVersion: v1
+kind: PersistentVolume
+metadata:
+  name: torrents
+  namespace: multimedia
+spec:
+  capacity:
+    storage: 100Gi
+  volumeMode: Filesystem
+  accessModes:
+    - ReadWriteOnce
+  persistentVolumeReclaimPolicy: Retain
+  storageClassName: manual
+  nfs:
+    path: /srv/storage/kubernetes/torrents
+    server: 192.168.2.40
+---
+apiVersion: v1
+kind: PersistentVolumeClaim
+metadata:
+  name: torrents
+  namespace: multimedia
+spec:
+  storageClassName: manual
+  accessModes:
+    - ReadWriteOnce
+  resources:
+    requests:
+      storage: 100Gi
+---
+apiVersion: v1
 kind: PersistentVolumeClaim
 metadata:
   namespace: ""multimedia"""
thaum-xyz,ankhmorpork,1c5be5d5bac833c45b4e55996ef68e7863df8e5f,paulfantom,pawel@krupa.net.pl,2020-11-25T19:08:43Z,paulfantom,pawel@krupa.net.pl,2020-11-25T19:08:43Z,apps/monitoring/ksm: fix previous commit,apps/monitoring/ksm/04_statefulset.yaml,False,False,False,False,2,2,4,"---FILE: apps/monitoring/ksm/04_statefulset.yaml---
@@ -27,10 +27,10 @@ spec:
         - --pod=$(POD_NAME)
         - --pod-namespace=$(POD_NAMESPACE)
         #- '--labels-metric-allow-list=""nodes=[""kubernetes.io/arch"",""gpu.infra/intel"",""network.infra/fast""]""'
-        - --labels-metric-allow-list=nodes=[""kubernetes.io/arch"",""gpu.infra/intel"",""network.infra/fast""]
+        #- --labels-metric-allow-list=nodes=[""kubernetes.io/arch"",""gpu.infra/intel"",""network.infra/fast""]
         #- --labels-metric-allow-list=""nodes=[""kubernetes.io/arch"",""gpu.infra/intel"",""network.infra/fast""]""
         #- --labels-metric-allow-list=""nodes=[kubernetes.io/arch,gpu.infra/intel,network.infra/fast]""
-        #- --labels-metric-allow-list=nodes=[kubernetes.io/arch,gpu.infra/intel,network.infra/fast]
+        - --labels-metric-allow-list=nodes=[kubernetes.io/arch,gpu.infra/intel,network.infra/fast]
         env:
         - name: POD_NAME
           valueFrom:"
thaum-xyz,ankhmorpork,97d479e04ce5a57f9faba2f2352828e0343c8d59,paulfantom,pawel@krupa.net.pl,2020-11-25T15:21:59Z,paulfantom,pawel@krupa.net.pl,2020-11-25T15:21:59Z,add PackagesAvailable runbook and fix showing runbooks in alerts,apps/monitoring/alertmanager/config.yaml;docs/runbooks/PackagesAvailable.md,False,False,False,False,28,2,30,"---FILE: apps/monitoring/alertmanager/config.yaml---
@@ -57,13 +57,13 @@ spec:
             actions:
             - type: button
               text: 'Runbook :green_book:'
-              url: '{{ (index .Alerts 0).Annotations.runbook }}'
+              url: '{{ (index .Alerts 0).Annotations.runbook_url }}'
             - type: button
               text: 'Query :mag:'
               url: '{{ (index .Alerts 0).GeneratorURL }}'
             - type: button
               text: 'Dashboard :grafana:'
-              url: '{{ (index .Alerts 0).Annotations.dashboard }}'
+              url: '{{ (index .Alerts 0).Annotations.dashboard_url }}'
             - type: button
               text: 'Silence :no_bell:'
               url: >-

---FILE: docs/runbooks/PackagesAvailable.md---
@@ -0,0 +1,26 @@
+# PackagesAvailable
+
+## Meaning
+
+<!-- What this alert is about? -->
+
+System has more new packages than allowed threshold. Since this doesn't affect any workload, it is only an info-level
+alert.
+
+## Impact
+
+<!-- What this alert affects? -->
+
+A system with not upgraded packages can be a security risk.
+
+## Diagnosis
+
+<!-- How to check symptoms of the alert firing? -->
+
+Log into a node an check how many packages are available for update.
+
+## Mitigation
+
+<!-- How to solve the issue? -->
+
+Upgrade system."
thaum-xyz,ankhmorpork,1648c3d7ea79d3c9b55eeee0f657f81f6d8039fb,paulfantom,pawel@krupa.net.pl,2020-11-23T10:52:57Z,paulfantom,pawel@krupa.net.pl,2020-11-23T10:52:57Z,hack: fix image check,hack/checkimages.sh,False,False,False,False,2,1,3,"---FILE: hack/checkimages.sh---
@@ -5,7 +5,7 @@ set -euo pipefail
 CPU_ARCHS=""amd64 arm64 arm""
 MULTI_ARCH_EXCLUDED=$( cat <<EOM
 quay.io/external_storage/nfs-client-provisioner-arm
-quay.io/kubernetes_incubator/nfs-provisioner
+quay.io/external_storage/nfs-client-provisioner
 quay.io/paulfantom/nfs-client-provisioner
 eu.gcr.io/k8s-artifacts-prod/descheduler/descheduler
 homeassistant/aarch64-homeassistant
@@ -21,6 +21,7 @@ nginx/nginx-prometheus-exporter
 allangood/holiday_exporter
 quay.io/superq/smokeping-prober-linux-arm64
 quay.io/prometheus/mysqld-exporter
+intel/intel-gpu-plugin
 EOM
 )
 "
thaum-xyz,ankhmorpork,c65aeeec7ce4bf983731fc5bc994031f618037cc,paulfantom,pawel@krupa.net.pl,2020-11-22T15:17:54Z,paulfantom,pawel@krupa.net.pl,2020-11-22T15:17:54Z,base/storage-system: fix external-nfs provisioner,base/storage-system/external-nfs/01_rbac.yaml;base/storage-system/external-nfs/02_deployment.yaml,False,False,False,False,5,11,16,"---FILE: base/storage-system/external-nfs/01_rbac.yaml---
@@ -7,12 +7,6 @@ metadata:
   name: external-nfs-provisioner
   namespace: storage-system
 ---
-apiVersion: v1
-kind: ServiceAccount
-metadata:
-  name: default
-  namespace: storage-system
----
 kind: ClusterRole
 apiVersion: rbac.authorization.k8s.io/v1
 metadata:

---FILE: base/storage-system/external-nfs/02_deployment.yaml---
@@ -5,7 +5,7 @@ metadata:
   name: external-nfs-provisioner
   labels:
     app.kubernetes.io/name: external-nfs-provisioner
-    app.kubernetes.io/version: 2.3.0
+    app.kubernetes.io/version: 3.1.0
   namespace: storage-system
 spec:
   replicas: 1
@@ -18,7 +18,7 @@ spec:
     metadata:
       labels:
         app.kubernetes.io/name: external-nfs-provisioner
-        app.kubernetes.io/version: 2.3.0
+        app.kubernetes.io/version: 3.1.0
     spec:
       containers:
         - env:
@@ -27,9 +27,9 @@ spec:
             - name: NFS_SERVER
               value: 192.168.2.40
             - name: NFS_PATH
-              value: /srv/storage/k8s
+              value: /srv/storage/kubernetes/externalnfs
           name: external-nfs-provisioner
-          image: quay.io/kubernetes_incubator/nfs-provisioner:v2.3.0
+          image: quay.io/external_storage/nfs-client-provisioner:v3.1.0-k8s1.11
           volumeMounts:
             - mountPath: /persistentvolumes
               name: external-nfs-root
@@ -40,7 +40,7 @@ spec:
         - name: external-nfs-root
           nfs:
             server: 192.168.2.40
-            path: /srv/storage/k8s
+            path: /srv/storage/kubernetes/externalnfs
       nodeSelector:
         kubernetes.io/arch: amd64
       tolerations:"
thaum-xyz,ankhmorpork,9fb01e83789b0e6bd599d1b3962d6f5e7ae64731,paulfantom,pawel@krupa.net.pl,2020-11-22T09:18:47Z,paulfantom,pawel@krupa.net.pl,2020-11-22T09:18:47Z,"ansible: add node01, deploy SMART mon where needed, fix mountpoints",ansible/10_storage.yml;ansible/host_vars/storage01.yml;ansible/inventory;ansible/roles/system/tasks/main.yml,False,False,False,False,62,39,101,"---FILE: ansible/10_storage.yml---
@@ -29,3 +29,21 @@
     apt:
       name: nfs-client
       state: present
+  - block:
+    - name: Install dependencies
+      package:
+        name: moreutils
+        state: present
+    - name: Copy smartmon textfile collector script
+      copy:
+        src: ""scripts/smartmon.sh""
+        dest: ""/usr/local/bin/smartmon.sh""
+        mode: 0755
+    - name: Set global cronjobs (/etc/crontab)
+      cron:
+        cron_file: ""/etc/crontab""
+        user: root
+        name: ""smartmon-metrics""
+        minute: ""*/10""
+        job: ""/usr/local/bin/smartmon.sh | sponge /var/lib/node_exporter/smartmon.prom""
+    when: enable_smartmon is defined

---FILE: ansible/host_vars/storage01.yml---
@@ -7,53 +7,57 @@ node_labels:
 node_taints:
   - ""storage.infra=true:NoSchedule""
 
-samba_domain_master: true
-samba_local_master: true
-samba_guest_account: paulfantom
-samba_netbios_name: NAS
-samba_server_string: Ankhmorpork fileserver
-samba_shares:
-  - name: torrents
-    path: /srv/torrents
-    guest_ok: true
-    public: true
-    browseable: true
-    writable: true
-  - name: mymultimedia
-    path: ""/srv/nextcloud/data/paulfantom/files/My multimedia""
-    guest_ok: true
-    public: true
-    browseable: true
-    writable: false
+#samba_domain_master: true
+#samba_local_master: true
+#samba_guest_account: paulfantom
+#samba_netbios_name: NAS
+#samba_server_string: Ankhmorpork fileserver
+#samba_shares:
+#  - name: torrents
+#    path: /srv/torrents
+#    guest_ok: true
+#    public: true
+#    browseable: true
+#    writable: true
+#  - name: mymultimedia
+#    path: ""/srv/nextcloud/data/paulfantom/files/My multimedia""
+#    guest_ok: true
+#    public: true
+#    browseable: true
+#    writable: false
 
 system_mountpoints:
   - description: main streaming storage data
     before: k3s-node.service
-    device: ""/dev/vg_storage/netflix""
+    device: ""192.168.2.40:/mnt/old/netflix""
     mountpoint: ""/srv/netflix""
-    type: ""xfs""
+    type: ""nfs""
+    options: ""_netdev,defaults""
   - description: main cloud service data
     before: k3s-node.service
-    device: ""/dev/vg_storage/nextcloud""
+    device: ""192.168.2.40:/mnt/old/nextcloud""
     mountpoint: ""/srv/nextcloud""
-    type: ""xfs""
+    type: ""nfs""
+    options: ""_netdev,defaults""
 
   - description: torrent hot cache mount
     before: k3s-node.service
-    device: ""/dev/ubuntu-vg/torrents""
+    device: ""/dev/disk/by-uuid/7158b9d4-7462-431c-9884-e637d5304bd3""
     mountpoint: ""/srv/torrents""
-    type: ""xfs""
+    type: ""ext4""
   - description: kubernetes NFS storage
     before: nfs-server.service k3s-node.service
-    device: ""/dev/ubuntu-vg/kube_nfs""
+    device: ""192.168.2.40:/mnt/old/kube_nfs""
     mountpoint: ""/srv/kubernetes/nfs""
-    type: ""ext4""
+    type: ""nfs""
+    options: ""_netdev,defaults""
   - description: kubernetes local storage
     before: k3s-node.service
-    device: ""/dev/ubuntu-vg/kube_local""
+    device: ""192.168.2.40:/mnt/old/kube_local""
     mountpoint: ""/var/lib/rancher/k3s/storage""
-    type: ""ext4""
+    type: ""nfs""
+    options: ""_netdev,defaults""
 
 nfs_exports:
   - ""/mnt/sbc/vetinari 192.168.2.0/24(rw,sync,no_subtree_check,no_root_squash)""
-  - ""/srv/kubernetes/nfs *(rw,sync,no_subtree_check,no_root_squash,no_all_squash,insecure)""
+  - ""/srv/kubernetes/nfs *(rw,sync,no_subtree_check,no_root_squash,no_all_squash,insecure,fsid=1)""

---FILE: ansible/inventory---
@@ -1,15 +1,16 @@
 # By default hosts are labeled with `network=slow` label
 # Hosts with label `network=fast` are used for metallb loadbalancer
 
-storage01 ansible_user=ubuntu     ansible_host=192.168.2.3  network=fast
-master01  ansible_user=ubuntu     ansible_host=192.168.2.11
-#node01    ansible_user=ubuntu     ansible_host=192.168.2.12 network=fast
-node02    ansible_user=ubuntu     ansible_host=192.168.2.13
-node03    ansible_user=ubuntu     ansible_host=192.168.2.14
-node04    ansible_user=ubuntu     ansible_host=192.168.2.15 network=fast
-node05    ansible_user=ubuntu     ansible_host=192.168.2.16 network=fast
-# node06    ansible_user=ubuntu     ansible_host=192.168.2.17
-hyper01   ansible_user=root       ansible_host=192.168.2.40
+# Assign enable_smartmon=true label to enable SMART monitoring of disks
+
+storage01 ansible_user=ubuntu ansible_host=192.168.2.3  network=fast
+master01  ansible_user=ubuntu ansible_host=192.168.2.11
+node01    ansible_user=ubuntu ansible_host=192.168.2.41 network=fast enable_smartmon=true
+node02    ansible_user=ubuntu ansible_host=192.168.2.13
+node03    ansible_user=ubuntu ansible_host=192.168.2.14
+node04    ansible_user=ubuntu ansible_host=192.168.2.15 network=fast
+node05    ansible_user=ubuntu ansible_host=192.168.2.16 network=fast
+hyper01   ansible_user=root   ansible_host=192.168.2.40 enable_smartmon=true
 
 [fancontroler]
 master01

---FILE: ansible/roles/system/tasks/main.yml---
@@ -13,7 +13,7 @@
 
 - import_tasks: hostname.yml
 
-- import_tasks: storage.yml
+# - import_tasks: storage.yml
 
 - name: add packages
   package:"
thaum-xyz,ankhmorpork,538bc3e8e2f0ab82b7af6edb0356cee64c7b95a4,paulfantom,pawel@krupa.net.pl,2020-11-22T09:16:21Z,paulfantom,pawel@krupa.net.pl,2020-11-22T09:16:21Z,apps/monitoring/rules: fix CPUStealTime alert,apps/monitoring/prometheus/rules/testing.yaml,False,False,False,False,1,1,2,"---FILE: apps/monitoring/prometheus/rules/testing.yaml---
@@ -31,7 +31,7 @@ spec:
           runbook_url: ""https://github.com/thaum-xyz/ankhmorpork/blob/master/docs/runbooks/RAIDDiskFailure.md""
       - alert: CPUStealTimeHigh
         expr: |
-          sum by (instance) (rate(node_cpu_seconds_total{mode=""steal""}[3m])) / count by (instance) (node_cpu_seconds_total{mode=""steal""}) > 0.000001
+          sum by (instance) (rate(node_cpu_seconds_total{mode=""steal""}[3m])) / count by (instance) (node_cpu_seconds_total{mode=""steal""}) > 0.1
         for: 20m
         labels:
           severity: warning"
thaum-xyz,ankhmorpork,ee6d0d0db4738258f8ceb875bc2ac040b597f2ce,paulfantom,pawel@krupa.net.pl,2020-11-20T14:19:10Z,paulfantom,pawel@krupa.net.pl,2020-11-20T14:19:10Z,hack: fix CI issues,apps/logging/loki/03_config.yaml;hack/checkimages.sh;hack/checksecrets.sh,False,False,False,False,58,5,63,"---FILE: apps/logging/loki/03_config.yaml---
@@ -10,5 +10,47 @@ metadata:
     app.kubernetes.io/version: 2.0.0
     app.kubernetes.io/component: server
     app.kubernetes.io/part-of: loki
-data:
-  loki.yaml: YXV0aF9lbmFibGVkOiBmYWxzZQpjaHVua19zdG9yZV9jb25maWc6CiAgbWF4X2xvb2tfYmFja19wZXJpb2Q6IDBzCmNvbXBhY3RvcjoKICBzaGFyZWRfc3RvcmU6IGZpbGVzeXN0ZW0KICB3b3JraW5nX2RpcmVjdG9yeTogL2RhdGEvbG9raS9ib2x0ZGItc2hpcHBlci1jb21wYWN0b3IKaW5nZXN0ZXI6CiAgY2h1bmtfYmxvY2tfc2l6ZTogMjYyMTQ0CiAgY2h1bmtfaWRsZV9wZXJpb2Q6IDNtCiAgY2h1bmtfcmV0YWluX3BlcmlvZDogMW0KICBsaWZlY3ljbGVyOgogICAgcmluZzoKICAgICAga3ZzdG9yZToKICAgICAgICBzdG9yZTogaW5tZW1vcnkKICAgICAgcmVwbGljYXRpb25fZmFjdG9yOiAxCiAgbWF4X3RyYW5zZmVyX3JldHJpZXM6IDAKbGltaXRzX2NvbmZpZzoKICBlbmZvcmNlX21ldHJpY19uYW1lOiBmYWxzZQogIHJlamVjdF9vbGRfc2FtcGxlczogdHJ1ZQogIHJlamVjdF9vbGRfc2FtcGxlc19tYXhfYWdlOiAxNjhoCnNjaGVtYV9jb25maWc6CiAgY29uZmlnczoKICAtIGZyb206ICIyMDIwLTEwLTI0IgogICAgaW5kZXg6CiAgICAgIHBlcmlvZDogMjRoCiAgICAgIHByZWZpeDogaW5kZXhfCiAgICBvYmplY3Rfc3RvcmU6IGZpbGVzeXN0ZW0KICAgIHNjaGVtYTogdjExCiAgICBzdG9yZTogYm9sdGRiLXNoaXBwZXIKc2VydmVyOgogIGh0dHBfbGlzdGVuX3BvcnQ6IDMxMDAKc3RvcmFnZV9jb25maWc6CiAgYm9sdGRiX3NoaXBwZXI6CiAgICBhY3RpdmVfaW5kZXhfZGlyZWN0b3J5OiAvZGF0YS9sb2tpL2JvbHRkYi1zaGlwcGVyLWFjdGl2ZQogICAgY2FjaGVfbG9jYXRpb246IC9kYXRhL2xva2kvYm9sdGRiLXNoaXBwZXItY2FjaGUKICAgIGNhY2hlX3R0bDogMjRoCiAgICBzaGFyZWRfc3RvcmU6IGZpbGVzeXN0ZW0KICBmaWxlc3lzdGVtOgogICAgZGlyZWN0b3J5OiAvZGF0YS9sb2tpL2NodW5rcwp0YWJsZV9tYW5hZ2VyOgogIHJldGVudGlvbl9kZWxldGVzX2VuYWJsZWQ6IGZhbHNlCiAgcmV0ZW50aW9uX3BlcmlvZDogMHM=
+stringData:
+  loki.yaml: |
+    auth_enabled: false
+    chunk_store_config:
+      max_look_back_period: 0s
+    compactor:
+      shared_store: filesystem
+      working_directory: /data/loki/boltdb-shipper-compactor
+    ingester:
+      chunk_block_size: 262144
+      chunk_idle_period: 3m
+      chunk_retain_period: 1m
+      lifecycler:
+        ring:
+          kvstore:
+            store: inmemory
+          replication_factor: 1
+      max_transfer_retries: 0
+    limits_config:
+      enforce_metric_name: false
+      reject_old_samples: true
+      reject_old_samples_max_age: 168h
+    schema_config:
+      configs:
+      - from: ""2020-10-24""
+        index:
+          period: 24h
+          prefix: index_
+        object_store: filesystem
+        schema: v11
+        store: boltdb-shipper
+    server:
+      http_listen_port: 3100
+    storage_config:
+      boltdb_shipper:
+        active_index_directory: /data/loki/boltdb-shipper-active
+        cache_location: /data/loki/boltdb-shipper-cache
+        cache_ttl: 24h
+        shared_store: filesystem
+      filesystem:
+        directory: /data/loki/chunks
+    table_manager:
+      retention_deletes_enabled: false
+      retention_period: 0s

---FILE: hack/checkimages.sh---
@@ -5,6 +5,7 @@ set -euo pipefail
 CPU_ARCHS=""amd64 arm64 arm""
 MULTI_ARCH_EXCLUDED=$( cat <<EOM
 quay.io/external_storage/nfs-client-provisioner-arm
+quay.io/kubernetes_incubator/nfs-provisioner
 quay.io/paulfantom/nfs-client-provisioner
 eu.gcr.io/k8s-artifacts-prod/descheduler/descheduler
 homeassistant/aarch64-homeassistant

---FILE: hack/checksecrets.sh---
@@ -3,20 +3,30 @@
 # Go to top-level
 cd ""$(git rev-parse --show-toplevel)""
 
+EXCLUDE=""apps/logging/loki/03_config.yaml""
+
+FAIL=""[ \e[1m\e[31mFAIL\e[0m ]""
+SKIP=""[ \e[1m\e[33mSKIP\e[0m ]""
+OK=""[  \e[1m\e[32mOK\e[0m  ]""
+
 LEAKS=""""
 
 for file in $(find apps/ base/ -name *.yaml -exec grep -E 'kind:[[:space:]]*Secret' -l {} \;); do
+	if [ ""$file"" == ""$EXCLUDE"" ]; then
+		echo -e ""$SKIP Skipping validation on $EXCLUDE""
+		continue
+	fi
 	new=$(gojsontoyaml -yamltojson < ""$file"" | jq -cr '..| .data?, .stringData? | select(type != ""null"")')
 	if [ ""$new"" != """" ]; then
 		LEAKS=""${file}\n${LEAKS}""
 	fi
 done
 
 if [ ""$LEAKS"" != """" ]; then
-	echo -e ""Files with secure data leak:""
-	echo -e ""${LEAKS}""
+	echo -e ""$FAIL Files with secure data leak:""
+	echo -e ""$FAIL ${LEAKS}""
 	exit 1
 fi
 
-echo ""No data found in Secret objects.""
+echo -e ""$OK No data found in Secret objects.""
 exit 0"
thaum-xyz,ankhmorpork,c3017330f4d53d5d75756f582e0a505b947acc91,paulfantom,pawel@krupa.net.pl,2020-11-12T10:48:23Z,paulfantom,pawel@krupa.net.pl,2020-11-12T10:48:23Z,base/argocd/apps/logging.yaml: fix formatting issue,base/argocd/apps/logging.yaml,False,False,False,False,1,1,2,"---FILE: base/argocd/apps/logging.yaml---
@@ -1,4 +1,4 @@
---
+---
 apiVersion: argoproj.io/v1alpha1
 kind: AppProject
 metadata:"
thaum-xyz,ankhmorpork,0a0124539aef2338bfde34d0450a7224c6726236,paulfantom,pawel@krupa.net.pl,2020-11-04T18:55:07Z,paulfantom,pawel@krupa.net.pl,2020-11-04T18:55:07Z,base/kube-system/sealed-secrets: fix alert description,base/kube-system/sealed-secrets/04_prometheusrule.yaml,False,False,False,False,1,1,2,"---FILE: base/kube-system/sealed-secrets/04_prometheusrule.yaml---
@@ -16,4 +16,4 @@ spec:
           severity: 'warning'
         annotations:
           summary: ""Sealed Secrets controller experiences high rate of unsealing errors""
-          description: 'High rate of errors unsealing Sealed Secrets on {{ $instance }} due to {{ $reason }} issues'
+          description: 'High rate of errors unsealing Sealed Secrets on {{ $labels.instance }} due to {{ $labels.reason }} issues'"
thaum-xyz,ankhmorpork,4b2992a822d9f8460faeaa280bcbb213e6f31a01,paulfantom,pawel@krupa.net.pl,2020-10-28T12:51:12Z,paulfantom,pawel@krupa.net.pl,2020-10-28T12:51:12Z,apps/monitoring/rules: fix node-exporter label matching,apps/monitoring/prometheus/rules/node-exporter.yaml,False,False,False,False,14,14,28,"---FILE: apps/monitoring/prometheus/rules/node-exporter.yaml---
@@ -74,11 +74,11 @@ spec:
         summary: Filesystem is predicted to run out of space within the next 24 hours.
       expr: |
         (
-          node_filesystem_avail_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} / node_filesystem_size_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} * 100 < 40
+          node_filesystem_avail_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} / node_filesystem_size_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} * 100 < 40
         and
-          predict_linear(node_filesystem_avail_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""}[6h], 24*60*60) < 0
+          predict_linear(node_filesystem_avail_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""}[6h], 24*60*60) < 0
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} == 0
+          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} == 0
         )
       for: 1h
       labels:
@@ -90,11 +90,11 @@ spec:
         summary: Filesystem is predicted to run out of space within the next 4 hours.
       expr: |
         (
-          node_filesystem_avail_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} / node_filesystem_size_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} * 100 < 20
+          node_filesystem_avail_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} / node_filesystem_size_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} * 100 < 20
         and
-          predict_linear(node_filesystem_avail_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""}[6h], 4*60*60) < 0
+          predict_linear(node_filesystem_avail_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""}[6h], 4*60*60) < 0
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} == 0
+          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} == 0
         )
       for: 1h
       labels:
@@ -106,9 +106,9 @@ spec:
         summary: Filesystem has less than 5% space left.
       expr: |
         (
-          node_filesystem_avail_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} / node_filesystem_size_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} * 100 < 5
+          node_filesystem_avail_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} / node_filesystem_size_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} * 100 < 5
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} == 0
+          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} == 0
         )
       for: 1h
       labels:
@@ -120,9 +120,9 @@ spec:
         summary: Filesystem has less than 3% space left.
       expr: |
         (
-          node_filesystem_avail_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} / node_filesystem_size_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} * 100 < 3
+          node_filesystem_avail_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} / node_filesystem_size_bytes{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} * 100 < 3
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} == 0
+          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} == 0
         )
       for: 1h
       labels:
@@ -134,11 +134,11 @@ spec:
         summary: Filesystem is predicted to run out of inodes within the next 24 hours.
       expr: |
         (
-          node_filesystem_files_free{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} / node_filesystem_files{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} * 100 < 40
+          node_filesystem_files_free{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} / node_filesystem_files{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} * 100 < 40
         and
-          predict_linear(node_filesystem_files_free{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""}[6h], 24*60*60) < 0
+          predict_linear(node_filesystem_files_free{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""}[6h], 24*60*60) < 0
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} == 0
+          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} == 0
         )
       for: 1h
       labels:
@@ -180,7 +180,7 @@ spec:
         summary: Filesystem has less than 3% inodes left.
       expr: |
         (
-          node_filesystem_files_free{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} / node_filesystem_files{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} * 100 < 3
+          node_filesystem_files_free{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} / node_filesystem_files{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} * 100 < 3
         and
           node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} == 0
         )"
thaum-xyz,ankhmorpork,e5f69970ede00d2e70f715120012bdfad7ac8cba,paulfantom,pawel@krupa.net.pl,2020-10-28T12:32:20Z,paulfantom,pawel@krupa.net.pl,2020-10-28T12:32:20Z,apps/monitoring/rules: fix node-exporter label matching,apps/monitoring/prometheus/rules/node-exporter.yaml,False,False,False,False,7,7,14,"---FILE: apps/monitoring/prometheus/rules/node-exporter.yaml---
@@ -150,11 +150,11 @@ spec:
         summary: Filesystem is predicted to run out of inodes within the next 4 hours.
       expr: |
         (
-          node_filesystem_files_free{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} / node_filesystem_files{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} * 100 < 20
+          node_filesystem_files_free{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} / node_filesystem_files{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} * 100 < 20
         and
-          predict_linear(node_filesystem_files_free{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""}[6h], 4*60*60) < 0
+          predict_linear(node_filesystem_files_free{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""}[6h], 4*60*60) < 0
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} == 0
+          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} == 0
         )
       for: 1h
       labels:
@@ -166,9 +166,9 @@ spec:
         summary: Filesystem has less than 5% inodes left.
       expr: |
         (
-          node_filesystem_files_free{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} / node_filesystem_files{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} * 100 < 5
+          node_filesystem_files_free{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} / node_filesystem_files{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} * 100 < 5
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} == 0
+          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} == 0
         )
       for: 1h
       labels:
@@ -180,9 +180,9 @@ spec:
         summary: Filesystem has less than 3% inodes left.
       expr: |
         (
-          node_filesystem_files_free{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} / node_filesystem_files{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} * 100 < 3
+          node_filesystem_files_free{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} / node_filesystem_files{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} * 100 < 3
         and
-          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+""""overlay|nsfs""} == 0
+          node_filesystem_readonly{job=""node-exporter"",fstype!~""overlay|nsfs"",device=""nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+|overlay|nsfs""} == 0
         )
       for: 1h
       labels:"
thaum-xyz,ankhmorpork,1c633791e83c6b546b44ebc25fb27b1c8af1e3e8,paulfantom,pawel@krupa.net.pl,2020-10-28T11:19:30Z,paulfantom,pawel@krupa.net.pl,2020-10-28T11:19:30Z,apps/monitoring/rules: fix prom-op rules spec,apps/monitoring/prometheus/rules/prometheus-operator.yaml,False,False,False,False,1,0,1,"---FILE: apps/monitoring/prometheus/rules/prometheus-operator.yaml---
@@ -7,6 +7,7 @@ metadata:
   name: prometheus-operator-rules
   namespace: monitoring
 spec:
+  groups:
   - name: prometheus-operator
     rules:
     - alert: PrometheusOperatorListErrors"
thaum-xyz,ankhmorpork,de811132b0d826ed3e05c4a4c5a5fefb2853db35,paulfantom,pawel@krupa.net.pl,2020-10-28T10:18:06Z,paulfantom,pawel@krupa.net.pl,2020-10-28T10:18:06Z,.github/workflows: fix downloading manifest-tool,.github/workflows/images.yml,False,False,False,False,1,1,2,"---FILE: .github/workflows/images.yml---
@@ -16,6 +16,6 @@ jobs:
         with:
           go-version: '1.15'
       - run: go get -u github.com/brancz/gojsontoyaml
-      - run: go get -u github.com/estesp/manifest-tool
+      - run: wget https://github.com/estesp/manifest-tool/releases/download/v1.0.3/manifest-tool-linux-amd64 -O /tmp/manifest-tool && chmod +x /tmp/manifest-tool && sudo mv /tmp/manifest-tool /usr/bin/
       - run: sudo apt update && sudo apt install -y jq
       - run: ./hack/checkimages.sh"
thaum-xyz,ankhmorpork,952d9438ac7b5fbf4fd97fb54a0e3d6b9a4a529d,paulfantom,pawel@krupa.net.pl,2020-10-15T12:50:16Z,paulfantom,pawel@krupa.net.pl,2020-10-15T12:50:16Z,base/argocd/argo: update to master to fix issues with Ingress,base/argocd/argo/00_crds.yaml;base/argocd/argo/06_install.yaml,False,False,False,False,260,507,767,"---FILE: base/argocd/argo/00_crds.yaml---
@@ -1,4 +1,4 @@
-# This is an auto-generated file. DO NOT EDIT
+---
 apiVersion: apiextensions.k8s.io/v1beta1
 kind: CustomResourceDefinition
 metadata:
@@ -22,14 +22,10 @@ spec:
       description: Application is a definition of Application resource.
       properties:
         apiVersion:
-          description: 'APIVersion defines the versioned schema of this representation
-            of an object. Servers should convert recognized schemas to the latest
-            internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
+          description: 'APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
           type: string
         kind:
-          description: 'Kind is a string value representing the REST resource this
-            object represents. Servers may infer this from the endpoint the client
-            submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
+          description: 'Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
           type: string
         metadata:
           type: object
@@ -49,12 +45,10 @@ spec:
                 type: object
               type: array
             initiatedBy:
-              description: OperationInitiator holds information about the operation
-                initiator
+              description: OperationInitiator holds information about the operation initiator
               properties:
                 automated:
-                  description: Automated is set to true if operation was initiated
-                    automatically by the application controller.
+                  description: Automated is set to true if operation was initiated automatically by the application controller.
                   type: boolean
                 username:
                   description: Name of a user who started operation.
@@ -67,41 +61,34 @@ spec:
                   description: Backoff is a backoff strategy
                   properties:
                     duration:
-                      description: Duration is the amount to back off. Default unit
-                        is seconds, but could also be a duration (e.g. ""2m"", ""1h"")
+                      description: Duration is the amount to back off. Default unit is seconds, but could also be a duration (e.g. ""2m"", ""1h"")
                       type: string
                     factor:
-                      description: Factor is a factor to multiply the base duration
-                        after each failed retry
+                      description: Factor is a factor to multiply the base duration after each failed retry
                       format: int64
                       type: integer
                     maxDuration:
-                      description: MaxDuration is the maximum amount of time allowed
-                        for the backoff strategy
+                      description: MaxDuration is the maximum amount of time allowed for the backoff strategy
                       type: string
                   type: object
                 limit:
-                  description: Limit is the maximum number of attempts when retrying
-                    a container
+                  description: Limit is the maximum number of attempts when retrying a container
                   format: int64
                   type: integer
               type: object
             sync:
               description: SyncOperation contains sync operation details.
               properties:
                 dryRun:
-                  description: DryRun will perform a `kubectl apply --dry-run` without
-                    actually performing the sync
+                  description: DryRun will perform a `kubectl apply --dry-run` without actually performing the sync
                   type: boolean
                 manifests:
-                  description: Manifests is an optional field that overrides sync
-                    source with a local directory for development
+                  description: Manifests is an optional field that overrides sync source with a local directory for development
                   items:
                     type: string
                   type: array
                 prune:
-                  description: Prune deletes resources that are no longer tracked
-                    in git
+                  description: Prune deletes resources that are no longer tracked in git
                   type: boolean
                 resources:
                   description: Resources describes which resources to sync
@@ -122,13 +109,10 @@ spec:
                     type: object
                   type: array
                 revision:
-                  description: Revision is the revision in which to sync the application
-                    to. If omitted, will use the revision specified in app spec.
+                  description: Revision is the revision in which to sync the application to. If omitted, will use the revision specified in app spec.
                   type: string
                 source:
-                  description: Source overrides the source definition set in the application.
-                    This is typically set in a Rollback operation and nil during a
-                    Sync operation
+                  description: Source overrides the source definition set in the application. This is typically set in a Rollback operation and nil during a Sync operation
                   properties:
                     chart:
                       description: Chart is a Helm chart name
@@ -137,8 +121,7 @@ spec:
                       description: Directory holds path/directory specific options
                       properties:
                         jsonnet:
-                          description: ApplicationSourceJsonnet holds jsonnet specific
-                            options
+                          description: ApplicationSourceJsonnet holds jsonnet specific options
                           properties:
                             extVars:
                               description: ExtVars is a list of Jsonnet External Variables
@@ -185,11 +168,9 @@ spec:
                       description: Helm holds helm specific options
                       properties:
                         fileParameters:
-                          description: FileParameters are file parameters to the helm
-                            template
+                          description: FileParameters are file parameters to the helm template
                           items:
-                            description: HelmFileParameter is a file parameter to
-                              a helm template
+                            description: HelmFileParameter is a file parameter to a helm template
                             properties:
                               name:
                                 description: Name is the name of the helm parameter
@@ -205,8 +186,7 @@ spec:
                             description: HelmParameter is a parameter to a helm template
                             properties:
                               forceString:
-                                description: ForceString determines whether to tell
-                                  Helm to interpret booleans and numbers as strings
+                                description: ForceString determines whether to tell Helm to interpret booleans and numbers as strings
                                 type: boolean
                               name:
                                 description: Name is the name of the helm parameter
@@ -217,30 +197,28 @@ spec:
                             type: object
                           type: array
                         releaseName:
-                          description: The Helm release name. If omitted it will use
-                            the application name
+                          description: The Helm release name. If omitted it will use the application name
                           type: string
                         valueFiles:
-                          description: ValuesFiles is a list of Helm value files to
-                            use when generating a template
+                          description: ValuesFiles is a list of Helm value files to use when generating a template
                           items:
                             type: string
                           type: array
                         values:
-                          description: Values is Helm values, typically defined as
-                            a block
+                          description: Values is Helm values, typically defined as a block
+                          type: string
+                        version:
+                          description: Version is the Helm version to use for templating with
                           type: string
                       type: object
                     ksonnet:
                       description: Ksonnet holds ksonnet specific options
                       properties:
                         environment:
-                          description: Environment is a ksonnet application environment
-                            name
+                          description: Environment is a ksonnet application environment name
                           type: string
                         parameters:
-                          description: Parameters are a list of ksonnet component
-                            parameter override values
+                          description: Parameters are a list of ksonnet component parameter override values
                           items:
                             description: KsonnetParameter is a ksonnet component parameter
                             properties:
@@ -270,12 +248,10 @@ spec:
                             type: string
                           type: array
                         namePrefix:
-                          description: NamePrefix is a prefix appended to resources
-                            for kustomize apps
+                          description: NamePrefix is a prefix appended to resources for kustomize apps
                           type: string
                         nameSuffix:
-                          description: NameSuffix is a suffix appended to resources
-                            for kustomize apps
+                          description: NameSuffix is a suffix appended to resources for kustomize apps
                           type: string
                         version:
                           description: Version contains optional Kustomize version
@@ -285,8 +261,7 @@ spec:
                       description: Path is a directory path within the Git repository
                       type: string
                     plugin:
-                      description: ConfigManagementPlugin holds config management
-                        plugin specific options
+                      description: ConfigManagementPlugin holds config management plugin specific options
                       properties:
                         env:
                           items:
@@ -306,13 +281,10 @@ spec:
                           type: string
                       type: object
                     repoURL:
-                      description: RepoURL is the repository URL of the application
-                        manifests
+                      description: RepoURL is the repository URL of the application manifests
                       type: string
                     targetRevision:
-                      description: TargetRevision defines the commit, tag, or branch
-                        in which to sync the application to. If omitted, will sync
-                        to HEAD
+                      description: TargetRevision defines the commit, tag, or branch in which to sync the application to. If omitted, will sync to HEAD
                       type: string
                   required:
                   - repoURL
@@ -326,59 +298,42 @@ spec:
                   description: SyncStrategy describes how to perform the sync
                   properties:
                     apply:
-                      description: Apply wil perform a `kubectl apply` to perform
-                        the sync.
+                      description: Apply will perform a `kubectl apply` to perform the sync.
                       properties:
                         force:
-                          description: Force indicates whether or not to supply the
-                            --force flag to `kubectl apply`. The --force flag deletes
-                            and re-create the resource, when PATCH encounters conflict
-                            and has retried for 5 times.
+                          description: Force indicates whether or not to supply the --force flag to `kubectl apply`. The --force flag deletes and re-create the resource, when PATCH encounters conflict and has retried for 5 times.
                           type: boolean
                       type: object
                     hook:
-                      description: Hook will submit any referenced resources to perform
-                        the sync. This is the default strategy
+                      description: Hook will submit any referenced resources to perform the sync. This is the default strategy
                       properties:
                         force:
-                          description: Force indicates whether or not to supply the
-                            --force flag to `kubectl apply`. The --force flag deletes
-                            and re-create the resource, when PATCH encounters conflict
-                            and has retried for 5 times.
+                          description: Force indicates whether or not to supply the --force flag to `kubectl apply`. The --force flag deletes and re-create the resource, when PATCH encounters conflict and has retried for 5 times.
                           type: boolean
                       type: object
                   type: object
               type: object
           type: object
         spec:
-          description: ApplicationSpec represents desired application state. Contains
-            link to repository with application definition and additional parameters
-            link definition revision.
+          description: ApplicationSpec represents desired application state. Contains link to repository with application definition and additional parameters link definition revision.
           properties:
             destination:
-              description: Destination overrides the kubernetes server and namespace
-                defined in the environment ksonnet app.yaml
+              description: Destination overrides the kubernetes server and namespace defined in the environment ksonnet app.yaml
               properties:
                 name:
-                  description: Name of the destination cluster which can be used instead
-                    of server (url) field
+                  description: Name of the destination cluster which can be used instead of server (url) field
                   type: string
                 namespace:
-                  description: Namespace overrides the environment namespace value
-                    in the ksonnet app.yaml
+                  description: Namespace overrides the environment namespace value in the ksonnet app.yaml
                   type: string
                 server:
-                  description: Server overrides the environment server value in the
-                    ksonnet app.yaml
+                  description: Server overrides the environment server value in the ksonnet app.yaml
                   type: string
               type: object
             ignoreDifferences:
-              description: IgnoreDifferences controls resources fields which should
-                be ignored during comparison
+              description: IgnoreDifferences controls resources fields which should be ignored during comparison
               items:
-                description: ResourceIgnoreDifferences contains resource filter and
-                  list of json paths which should be ignored during comparison with
-                  live state.
+                description: ResourceIgnoreDifferences contains resource filter and list of json paths which should be ignored during comparison with live state.
                 properties:
                   group:
                     type: string
@@ -398,8 +353,7 @@ spec:
                 type: object
               type: array
             info:
-              description: Infos contains a list of useful information (URLs, email
-                addresses, and plain text) that relates to the application
+              description: Infos contains a list of useful information (URLs, email addresses, and plain text) that relates to the application
               items:
                 properties:
                   name:
@@ -412,20 +366,14 @@ spec:
                 type: object
               type: array
             project:
-              description: Project is a application project name. Empty name means
-                that application belongs to 'default' project.
+              description: Project is a application project name. Empty name means that application belongs to 'default' project.
               type: string
             revisionHistoryLimit:
-              description: This limits this number of items kept in the apps revision
-                history. This should only be changed in exceptional circumstances.
-                Setting to zero will store no history. This will reduce storage used.
-                Increasing will increase the space used to store the history, so we
-                do not recommend increasing it. Default is 10.
+              description: This limits this number of items kept in the apps revision history. This should only be changed in exceptional circumstances. Setting to zero will store no history. This will reduce storage used. Increasing will increase the space used to store the history, so we do not recommend increasing it. Default is 10.
               format: int64
               type: integer
             source:
-              description: Source is a reference to the location ksonnet application
-                definition
+              description: Source is a reference to the location ksonnet application definition
               properties:
                 chart:
                   description: Chart is a Helm chart name
@@ -434,8 +382,7 @@ spec:
                   description: Directory holds path/directory specific options
                   properties:
                     jsonnet:
-                      description: ApplicationSourceJsonnet holds jsonnet specific
-                        options
+                      description: ApplicationSourceJsonnet holds jsonnet specific options
                       properties:
                         extVars:
                           description: ExtVars is a list of Jsonnet External Variables
@@ -482,11 +429,9 @@ spec:
                   description: Helm holds helm specific options
                   properties:
                     fileParameters:
-                      description: FileParameters are file parameters to the helm
-                        template
+                      description: FileParameters are file parameters to the helm template
                       items:
-                        description: HelmFileParameter is a file parameter to a helm
-                          template
+                        description: HelmFileParameter is a file parameter to a helm template
                         properties:
                           name:
                             description: Name is the name of the helm parameter
@@ -502,8 +447,7 @@ spec:
                         description: HelmParameter is a parameter to a helm template
                         properties:
                           forceString:
-                            description: ForceString determines whether to tell Helm
-                              to interpret booleans and numbers as strings
+                            description: ForceString determines whether to tell Helm to interpret booleans and numbers as strings
                             type: boolean
                           name:
                             description: Name is the name of the helm parameter
@@ -514,29 +458,28 @@ spec:
                         type: object
                       type: array
                     releaseName:
-                      description: The Helm release name. If omitted it will use the
-                        application name
+                      description: The Helm release name. If omitted it will use the application name
                       type: string
                     valueFiles:
-                      description: ValuesFiles is a list of Helm value files to use
-                        when generating a template
+                      description: ValuesFiles is a list of Helm value files to use when generating a template
                       items:
                         type: string
                       type: array
                     values:
                       description: Values is Helm values, typically defined as a block
                       type: string
+                    version:
+                      description: Version is the Helm version to use for templating with
+                      type: string
                   type: object
                 ksonnet:
                   description: Ksonnet holds ksonnet specific options
                   properties:
                     environment:
-                      description: Environment is a ksonnet application environment
-                        name
+                      description: Environment is a ksonnet application environment name
                       type: string
                     parameters:
-                      description: Parameters are a list of ksonnet component parameter
-                        override values
+                      description: Parameters are a list of ksonnet component parameter override values
                       items:
                         description: KsonnetParameter is a ksonnet component parameter
                         properties:
@@ -566,12 +509,10 @@ spec:
                         type: string
                       type: array
                     namePrefix:
-                      description: NamePrefix is a prefix appended to resources for
-                        kustomize apps
+                      description: NamePrefix is a prefix appended to resources for kustomize apps
                       type: string
                     nameSuffix:
-                      description: NameSuffix is a suffix appended to resources for
-                        kustomize apps
+                      description: NameSuffix is a suffix appended to resources for kustomize apps
                       type: string
                     version:
                       description: Version contains optional Kustomize version
@@ -581,8 +522,7 @@ spec:
                   description: Path is a directory path within the Git repository
                   type: string
                 plugin:
-                  description: ConfigManagementPlugin holds config management plugin
-                    specific options
+                  description: ConfigManagementPlugin holds config management plugin specific options
                   properties:
                     env:
                       items:
@@ -605,8 +545,7 @@ spec:
                   description: RepoURL is the repository URL of the application manifests
                   type: string
                 targetRevision:
-                  description: TargetRevision defines the commit, tag, or branch in
-                    which to sync the application to. If omitted, will sync to HEAD
+                  description: TargetRevision defines the commit, tag, or branch in which to sync the application to. If omitted, will sync to HEAD
                   type: string
               required:
               - repoURL
@@ -615,12 +554,13 @@ spec:
               description: SyncPolicy controls when a sync will be performed
               properties:
                 automated:
-                  description: Automated will keep an application synced to the target
-                    revision
+                  description: Automated will keep an application synced to the target revision
                   properties:
+                    allowEmpty:
+                      description: 'AllowEmpty allows apps have zero live resources (default: false)'
+                      type: boolean
                     prune:
-                      description: 'Prune will prune resources automatically as part
-                        of automated sync (default: false)'
+                      description: 'Prune will prune resources automatically as part of automated sync (default: false)'
                       type: boolean
                     selfHeal:
                       description: 'SelfHeal enables auto-syncing if  (default: false)'
@@ -633,23 +573,18 @@ spec:
                       description: Backoff is a backoff strategy
                       properties:
                         duration:
-                          description: Duration is the amount to back off. Default
-                            unit is seconds, but could also be a duration (e.g. ""2m"",
-                            ""1h"")
+                          description: Duration is the amount to back off. Default unit is seconds, but could also be a duration (e.g. ""2m"", ""1h"")
                           type: string
                         factor:
-                          description: Factor is a factor to multiply the base duration
-                            after each failed retry
+                          description: Factor is a factor to multiply the base duration after each failed retry
                           format: int64
                           type: integer
                         maxDuration:
-                          description: MaxDuration is the maximum amount of time allowed
-                            for the backoff strategy
+                          description: MaxDuration is the maximum amount of time allowed for the backoff strategy
                           type: string
                       type: object
                     limit:
-                      description: Limit is the maximum number of attempts when retrying
-                        a container
+                      description: Limit is the maximum number of attempts when retrying a container
                       format: int64
                       type: integer
                   type: object
@@ -665,22 +600,18 @@ spec:
           - source
           type: object
         status:
-          description: ApplicationStatus contains information about application sync,
-            health status
+          description: ApplicationStatus contains information about application sync, health status
           properties:
             conditions:
               items:
-                description: ApplicationCondition contains details about current application
-                  condition
+                description: ApplicationCondition contains details about current application condition
                 properties:
                   lastTransitionTime:
-                    description: LastTransitionTime is the time the condition was
-                      first observed.
+                    description: LastTransitionTime is the time the condition was first observed.
                     format: date-time
                     type: string
                   message:
-                    description: Message contains human-readable message indicating
-                      details about condition
+                    description: Message contains human-readable message indicating details about condition
                     type: string
                   type:
                     description: Type is an application condition type
@@ -699,11 +630,9 @@ spec:
                   type: string
               type: object
             history:
-              description: RevisionHistories is a array of history, oldest first and
-                newest last
+              description: RevisionHistories is a array of history, oldest first and newest last
               items:
-                description: RevisionHistory contains information relevant to an application
-                  deployment
+                description: RevisionHistory contains information relevant to an application deployment
                 properties:
                   deployStartedAt:
                     description: DeployStartedAt holds the time the deployment started
@@ -721,8 +650,7 @@ spec:
                     description: Revision holds the revision of the sync
                     type: string
                   source:
-                    description: ApplicationSource contains information about github
-                      repository, path within repository and target application environment.
+                    description: ApplicationSource contains information about github repository, path within repository and target application environment.
                     properties:
                       chart:
                         description: Chart is a Helm chart name
@@ -731,12 +659,10 @@ spec:
                         description: Directory holds path/directory specific options
                         properties:
                           jsonnet:
-                            description: ApplicationSourceJsonnet holds jsonnet specific
-                              options
+                            description: ApplicationSourceJsonnet holds jsonnet specific options
                             properties:
                               extVars:
-                                description: ExtVars is a list of Jsonnet External
-                                  Variables
+                                description: ExtVars is a list of Jsonnet External Variables
                                 items:
                                   description: JsonnetVar is a jsonnet variable
                                   properties:
@@ -780,30 +706,25 @@ spec:
                         description: Helm holds helm specific options
                         properties:
                           fileParameters:
-                            description: FileParameters are file parameters to the
-                              helm template
+                            description: FileParameters are file parameters to the helm template
                             items:
-                              description: HelmFileParameter is a file parameter to
-                                a helm template
+                              description: HelmFileParameter is a file parameter to a helm template
                               properties:
                                 name:
                                   description: Name is the name of the helm parameter
                                   type: string
                                 path:
-                                  description: Path is the path value for the helm
-                                    parameter
+                                  description: Path is the path value for the helm parameter
                                   type: string
                               type: object
                             type: array
                           parameters:
                             description: Parameters are parameters to the helm template
                             items:
-                              description: HelmParameter is a parameter to a helm
-                                template
+                              description: HelmParameter is a parameter to a helm template
                               properties:
                                 forceString:
-                                  description: ForceString determines whether to tell
-                                    Helm to interpret booleans and numbers as strings
+                                  description: ForceString determines whether to tell Helm to interpret booleans and numbers as strings
                                   type: boolean
                                 name:
                                   description: Name is the name of the helm parameter
@@ -814,33 +735,30 @@ spec:
                               type: object
                             type: array
                           releaseName:
-                            description: The Helm release name. If omitted it will
-                              use the application name
+                            description: The Helm release name. If omitted it will use the application name
                             type: string
                           valueFiles:
-                            description: ValuesFiles is a list of Helm value files
-                              to use when generating a template
+                            description: ValuesFiles is a list of Helm value files to use when generating a template
                             items:
                               type: string
                             type: array
                           values:
-                            description: Values is Helm values, typically defined
-                              as a block
+                            description: Values is Helm values, typically defined as a block
+                            type: string
+                          version:
+                            description: Version is the Helm version to use for templating with
                             type: string
                         type: object
                       ksonnet:
                         description: Ksonnet holds ksonnet specific options
                         properties:
                           environment:
-                            description: Environment is a ksonnet application environment
-                              name
+                            description: Environment is a ksonnet application environment name
                             type: string
                           parameters:
-                            description: Parameters are a list of ksonnet component
-                              parameter override values
+                            description: Parameters are a list of ksonnet component parameter override values
                             items:
-                              description: KsonnetParameter is a ksonnet component
-                                parameter
+                              description: KsonnetParameter is a ksonnet component parameter
                               properties:
                                 component:
                                   type: string
@@ -868,12 +786,10 @@ spec:
                               type: string
                             type: array
                           namePrefix:
-                            description: NamePrefix is a prefix appended to resources
-                              for kustomize apps
+                            description: NamePrefix is a prefix appended to resources for kustomize apps
                             type: string
                           nameSuffix:
-                            description: NameSuffix is a suffix appended to resources
-                              for kustomize apps
+                            description: NameSuffix is a suffix appended to resources for kustomize apps
                             type: string
                           version:
                             description: Version contains optional Kustomize version
@@ -883,8 +799,7 @@ spec:
                         description: Path is a directory path within the Git repository
                         type: string
                       plugin:
-                        description: ConfigManagementPlugin holds config management
-                          plugin specific options
+                        description: ConfigManagementPlugin holds config management plugin specific options
                         properties:
                           env:
                             items:
@@ -904,13 +819,10 @@ spec:
                             type: string
                         type: object
                       repoURL:
-                        description: RepoURL is the repository URL of the application
-                          manifests
+                        description: RepoURL is the repository URL of the application manifests
                         type: string
                       targetRevision:
-                        description: TargetRevision defines the commit, tag, or branch
-                          in which to sync the application to. If omitted, will sync
-                          to HEAD
+                        description: TargetRevision defines the commit, tag, or branch in which to sync the application to. If omitted, will sync to HEAD
                         type: string
                     required:
                     - repoURL
@@ -922,22 +834,18 @@ spec:
                 type: object
               type: array
             observedAt:
-              description: 'ObservedAt indicates when the application state was updated
-                without querying latest git state Deprecated: controller no longer
-                updates ObservedAt field'
+              description: 'ObservedAt indicates when the application state was updated without querying latest git state Deprecated: controller no longer updates ObservedAt field'
               format: date-time
               type: string
             operationState:
-              description: OperationState contains information about state of currently
-                performing operation on application.
+              description: OperationState contains information about state of currently performing operation on application.
               properties:
                 finishedAt:
                   description: FinishedAt contains time of operation completion
                   format: date-time
                   type: string
                 message:
-                  description: Message hold any pertinent messages when attempting
-                    to perform operation (typically errors).
+                  description: Message hold any pertinent messages when attempting to perform operation (typically errors).
                   type: string
                 operation:
                   description: Operation is the original requested operation
@@ -955,12 +863,10 @@ spec:
                         type: object
                       type: array
                     initiatedBy:
-                      description: OperationInitiator holds information about the
-                        operation initiator
+                      description: OperationInitiator holds information about the operation initiator
                       properties:
                         automated:
-                          description: Automated is set to true if operation was initiated
-                            automatically by the application controller.
+                          description: Automated is set to true if operation was initiated automatically by the application controller.
                           type: boolean
                         username:
                           description: Name of a user who started operation.
@@ -973,48 +879,39 @@ spec:
                           description: Backoff is a backoff strategy
                           properties:
                             duration:
-                              description: Duration is the amount to back off. Default
-                                unit is seconds, but could also be a duration (e.g.
-                                ""2m"", ""1h"")
+                              description: Duration is the amount to back off. Default unit is seconds, but could also be a duration (e.g. ""2m"", ""1h"")
                               type: string
                             factor:
-                              description: Factor is a factor to multiply the base
-                                duration after each failed retry
+                              description: Factor is a factor to multiply the base duration after each failed retry
                               format: int64
                               type: integer
                             maxDuration:
-                              description: MaxDuration is the maximum amount of time
-                                allowed for the backoff strategy
+                              description: MaxDuration is the maximum amount of time allowed for the backoff strategy
                               type: string
                           type: object
                         limit:
-                          description: Limit is the maximum number of attempts when
-                            retrying a container
+                          description: Limit is the maximum number of attempts when retrying a container
                           format: int64
                           type: integer
                       type: object
                     sync:
                       description: SyncOperation contains sync operation details.
                       properties:
                         dryRun:
-                          description: DryRun will perform a `kubectl apply --dry-run`
-                            without actually performing the sync
+                          description: DryRun will perform a `kubectl apply --dry-run` without actually performing the sync
                           type: boolean
                         manifests:
-                          description: Manifests is an optional field that overrides
-                            sync source with a local directory for development
+                          description: Manifests is an optional field that overrides sync source with a local directory for development
                           items:
                             type: string
                           type: array
                         prune:
-                          description: Prune deletes resources that are no longer
-                            tracked in git
+                          description: Prune deletes resources that are no longer tracked in git
                           type: boolean
                         resources:
                           description: Resources describes which resources to sync
                           items:
-                            description: SyncOperationResource contains resources
-                              to sync.
+                            description: SyncOperationResource contains resources to sync.
                             properties:
                               group:
                                 type: string
@@ -1030,29 +927,22 @@ spec:
                             type: object
                           type: array
                         revision:
-                          description: Revision is the revision in which to sync the
-                            application to. If omitted, will use the revision specified
-                            in app spec.
+                          description: Revision is the revision in which to sync the application to. If omitted, will use the revision specified in app spec.
                           type: string
                         source:
-                          description: Source overrides the source definition set
-                            in the application. This is typically set in a Rollback
-                            operation and nil during a Sync operation
+                          description: Source overrides the source definition set in the application. This is typically set in a Rollback operation and nil during a Sync operation
                           properties:
                             chart:
                               description: Chart is a Helm chart name
                               type: string
                             directory:
-                              description: Directory holds path/directory specific
-                                options
+                              description: Directory holds path/directory specific options
                               properties:
                                 jsonnet:
-                                  description: ApplicationSourceJsonnet holds jsonnet
-                                    specific options
+                                  description: ApplicationSourceJsonnet holds jsonnet specific options
                                   properties:
                                     extVars:
-                                      description: ExtVars is a list of Jsonnet External
-                                        Variables
+                                      description: ExtVars is a list of Jsonnet External Variables
                                       items:
                                         description: JsonnetVar is a jsonnet variable
                                         properties:
@@ -1073,8 +963,7 @@ spec:
                                         type: string
                                       type: array
                                     tlas:
-                                      description: TLAS is a list of Jsonnet Top-level
-                                        Arguments
+                                      description: TLAS is a list of Jsonnet Top-level Arguments
                                       items:
                                         description: JsonnetVar is a jsonnet variable
                                         properties:
@@ -1097,72 +986,59 @@ spec:
                               description: Helm holds helm specific options
                               properties:
                                 fileParameters:
-                                  description: FileParameters are file parameters
-                                    to the helm template
+                                  description: FileParameters are file parameters to the helm template
                                   items:
-                                    description: HelmFileParameter is a file parameter
-                                      to a helm template
+                                    description: HelmFileParameter is a file parameter to a helm template
                                     properties:
                                       name:
-                                        description: Name is the name of the helm
-                                          parameter
+                                        description: Name is the name of the helm parameter
                                         type: string
                                       path:
-                                        description: Path is the path value for the
-                                          helm parameter
+                                        description: Path is the path value for the helm parameter
                                         type: string
                                     type: object
                                   type: array
                                 parameters:
-                                  description: Parameters are parameters to the helm
-                                    template
+                                  description: Parameters are parameters to the helm template
                                   items:
-                                    description: HelmParameter is a parameter to a
-                                      helm template
+                                    description: HelmParameter is a parameter to a helm template
                                     properties:
                                       forceString:
-                                        description: ForceString determines whether
-                                          to tell Helm to interpret booleans and numbers
-                                          as strings
+                                        description: ForceString determines whether to tell Helm to interpret booleans and numbers as strings
                                         type: boolean
                                       name:
-                                        description: Name is the name of the helm
-                                          parameter
+                                        description: Name is the name of the helm parameter
                                         type: string
                                       value:
-                                        description: Value is the value for the helm
-                                          parameter
+                                        description: Value is the value for the helm parameter
                                         type: string
                                     type: object
                                   type: array
                                 releaseName:
-                                  description: The Helm release name. If omitted it
-                                    will use the application name
+                                  description: The Helm release name. If omitted it will use the application name
                                   type: string
                                 valueFiles:
-                                  description: ValuesFiles is a list of Helm value
-                                    files to use when generating a template
+                                  description: ValuesFiles is a list of Helm value files to use when generating a template
                                   items:
                                     type: string
                                   type: array
                                 values:
-                                  description: Values is Helm values, typically defined
-                                    as a block
+                                  description: Values is Helm values, typically defined as a block
+                                  type: string
+                                version:
+                                  description: Version is the Helm version to use for templating with
                                   type: string
                               type: object
                             ksonnet:
                               description: Ksonnet holds ksonnet specific options
                               properties:
                                 environment:
-                                  description: Environment is a ksonnet application
-                                    environment name
+                                  description: Environment is a ksonnet application environment name
                                   type: string
                                 parameters:
-                                  description: Parameters are a list of ksonnet component
-                                    parameter override values
+                                  description: Parameters are a list of ksonnet component parameter override values
                                   items:
-                                    description: KsonnetParameter is a ksonnet component
-                                      parameter
+                                    description: KsonnetParameter is a ksonnet component parameter
                                     properties:
                                       component:
                                         type: string
@@ -1182,34 +1058,28 @@ spec:
                                 commonLabels:
                                   additionalProperties:
                                     type: string
-                                  description: CommonLabels adds additional kustomize
-                                    commonLabels
+                                  description: CommonLabels adds additional kustomize commonLabels
                                   type: object
                                 images:
                                   description: Images are kustomize image overrides
                                   items:
                                     type: string
                                   type: array
                                 namePrefix:
-                                  description: NamePrefix is a prefix appended to
-                                    resources for kustomize apps
+                                  description: NamePrefix is a prefix appended to resources for kustomize apps
                                   type: string
                                 nameSuffix:
-                                  description: NameSuffix is a suffix appended to
-                                    resources for kustomize apps
+                                  description: NameSuffix is a suffix appended to resources for kustomize apps
                                   type: string
                                 version:
-                                  description: Version contains optional Kustomize
-                                    version
+                                  description: Version contains optional Kustomize version
                                   type: string
                               type: object
                             path:
-                              description: Path is a directory path within the Git
-                                repository
+                              description: Path is a directory path within the Git repository
                               type: string
                             plugin:
-                              description: ConfigManagementPlugin holds config management
-                                plugin specific options
+                              description: ConfigManagementPlugin holds config management plugin specific options
                               properties:
                                 env:
                                   items:
@@ -1229,48 +1099,34 @@ spec:
                                   type: string
                               type: object
                             repoURL:
-                              description: RepoURL is the repository URL of the application
-                                manifests
+                              description: RepoURL is the repository URL of the application manifests
                               type: string
                             targetRevision:
-                              description: TargetRevision defines the commit, tag,
-                                or branch in which to sync the application to. If
-                                omitted, will sync to HEAD
+                              description: TargetRevision defines the commit, tag, or branch in which to sync the application to. If omitted, will sync to HEAD
                               type: string
                           required:
                           - repoURL
                           type: object
                         syncOptions:
-                          description: SyncOptions provide per-sync sync-options,
-                            e.g. Validate=false
+                          description: SyncOptions provide per-sync sync-options, e.g. Validate=false
                           items:
                             type: string
                           type: array
                         syncStrategy:
                           description: SyncStrategy describes how to perform the sync
                           properties:
                             apply:
-                              description: Apply wil perform a `kubectl apply` to
-                                perform the sync.
+                              description: Apply will perform a `kubectl apply` to perform the sync.
                               properties:
                                 force:
-                                  description: Force indicates whether or not to supply
-                                    the --force flag to `kubectl apply`. The --force
-                                    flag deletes and re-create the resource, when
-                                    PATCH encounters conflict and has retried for
-                                    5 times.
+                                  description: Force indicates whether or not to supply the --force flag to `kubectl apply`. The --force flag deletes and re-create the resource, when PATCH encounters conflict and has retried for 5 times.
                                   type: boolean
                               type: object
                             hook:
-                              description: Hook will submit any referenced resources
-                                to perform the sync. This is the default strategy
+                              description: Hook will submit any referenced resources to perform the sync. This is the default strategy
                               properties:
                                 force:
-                                  description: Force indicates whether or not to supply
-                                    the --force flag to `kubectl apply`. The --force
-                                    flag deletes and re-create the resource, when
-                                    PATCH encounters conflict and has retried for
-                                    5 times.
+                                  description: Force indicates whether or not to supply the --force flag to `kubectl apply`. The --force flag deletes and re-create the resource, when PATCH encounters conflict and has retried for 5 times.
                                   type: boolean
                               type: object
                           type: object
@@ -1291,22 +1147,17 @@ spec:
                   description: SyncResult is the result of a Sync operation
                   properties:
                     resources:
-                      description: Resources holds the sync result of each individual
-                        resource
+                      description: Resources holds the sync result of each individual resource
                       items:
-                        description: ResourceResult holds the operation result details
-                          of a specific resource
+                        description: ResourceResult holds the operation result details of a specific resource
                         properties:
                           group:
                             type: string
                           hookPhase:
-                            description: 'the state of any operation associated with
-                              this resource OR hook note: can contain values for non-hook
-                              resources'
+                            description: 'the state of any operation associated with this resource OR hook note: can contain values for non-hook resources'
                             type: string
                           hookType:
-                            description: the type of the hook, empty for non-hook
-                              resources
+                            description: the type of the hook, empty for non-hook resources
                             type: string
                           kind:
                             type: string
@@ -1318,13 +1169,10 @@ spec:
                           namespace:
                             type: string
                           status:
-                            description: the final result of the sync, this is be
-                              empty if the resources is yet to be applied/pruned and
-                              is always zero-value for hooks
+                            description: the final result of the sync, this is be empty if the resources is yet to be applied/pruned and is always zero-value for hooks
                             type: string
                           syncPhase:
-                            description: indicates the particular phase of the sync
-                              that this is for
+                            description: indicates the particular phase of the sync that this is for
                             type: string
                           version:
                             type: string
@@ -1340,8 +1188,7 @@ spec:
                       description: Revision holds the revision of the sync
                       type: string
                     source:
-                      description: Source records the application source information
-                        of the sync, used for comparing auto-sync
+                      description: Source records the application source information of the sync, used for comparing auto-sync
                       properties:
                         chart:
                           description: Chart is a Helm chart name
@@ -1350,12 +1197,10 @@ spec:
                           description: Directory holds path/directory specific options
                           properties:
                             jsonnet:
-                              description: ApplicationSourceJsonnet holds jsonnet
-                                specific options
+                              description: ApplicationSourceJsonnet holds jsonnet specific options
                               properties:
                                 extVars:
-                                  description: ExtVars is a list of Jsonnet External
-                                    Variables
+                                  description: ExtVars is a list of Jsonnet External Variables
                                   items:
                                     description: JsonnetVar is a jsonnet variable
                                     properties:
@@ -1376,8 +1221,7 @@ spec:
                                     type: string
                                   type: array
                                 tlas:
-                                  description: TLAS is a list of Jsonnet Top-level
-                                    Arguments
+                                  description: TLAS is a list of Jsonnet Top-level Arguments
                                   items:
                                     description: JsonnetVar is a jsonnet variable
                                     properties:
@@ -1400,31 +1244,25 @@ spec:
                           description: Helm holds helm specific options
                           properties:
                             fileParameters:
-                              description: FileParameters are file parameters to the
-                                helm template
+                              description: FileParameters are file parameters to the helm template
                               items:
-                                description: HelmFileParameter is a file parameter
-                                  to a helm template
+                                description: HelmFileParameter is a file parameter to a helm template
                                 properties:
                                   name:
                                     description: Name is the name of the helm parameter
                                     type: string
                                   path:
-                                    description: Path is the path value for the helm
-                                      parameter
+                                    description: Path is the path value for the helm parameter
                                     type: string
                                 type: object
                               type: array
                             parameters:
                               description: Parameters are parameters to the helm template
                               items:
-                                description: HelmParameter is a parameter to a helm
-                                  template
+                                description: HelmParameter is a parameter to a helm template
                                 properties:
                                   forceString:
-                                    description: ForceString determines whether to
-                                      tell Helm to interpret booleans and numbers
-                                      as strings
+                                    description: ForceString determines whether to tell Helm to interpret booleans and numbers as strings
                                     type: boolean
                                   name:
                                     description: Name is the name of the helm parameter
@@ -1435,33 +1273,30 @@ spec:
                                 type: object
                               type: array
                             releaseName:
-                              description: The Helm release name. If omitted it will
-                                use the application name
+                              description: The Helm release name. If omitted it will use the application name
                               type: string
                             valueFiles:
-                              description: ValuesFiles is a list of Helm value files
-                                to use when generating a template
+                              description: ValuesFiles is a list of Helm value files to use when generating a template
                               items:
                                 type: string
                               type: array
                             values:
-                              description: Values is Helm values, typically defined
-                                as a block
+                              description: Values is Helm values, typically defined as a block
+                              type: string
+                            version:
+                              description: Version is the Helm version to use for templating with
                               type: string
                           type: object
                         ksonnet:
                           description: Ksonnet holds ksonnet specific options
                           properties:
                             environment:
-                              description: Environment is a ksonnet application environment
-                                name
+                              description: Environment is a ksonnet application environment name
                               type: string
                             parameters:
-                              description: Parameters are a list of ksonnet component
-                                parameter override values
+                              description: Parameters are a list of ksonnet component parameter override values
                               items:
-                                description: KsonnetParameter is a ksonnet component
-                                  parameter
+                                description: KsonnetParameter is a ksonnet component parameter
                                 properties:
                                   component:
                                     type: string
@@ -1481,21 +1316,18 @@ spec:
                             commonLabels:
                               additionalProperties:
                                 type: string
-                              description: CommonLabels adds additional kustomize
-                                commonLabels
+                              description: CommonLabels adds additional kustomize commonLabels
                               type: object
                             images:
                               description: Images are kustomize image overrides
                               items:
                                 type: string
                               type: array
                             namePrefix:
-                              description: NamePrefix is a prefix appended to resources
-                                for kustomize apps
+                              description: NamePrefix is a prefix appended to resources for kustomize apps
                               type: string
                             nameSuffix:
-                              description: NameSuffix is a suffix appended to resources
-                                for kustomize apps
+                              description: NameSuffix is a suffix appended to resources for kustomize apps
                               type: string
                             version:
                               description: Version contains optional Kustomize version
@@ -1505,8 +1337,7 @@ spec:
                           description: Path is a directory path within the Git repository
                           type: string
                         plugin:
-                          description: ConfigManagementPlugin holds config management
-                            plugin specific options
+                          description: ConfigManagementPlugin holds config management plugin specific options
                           properties:
                             env:
                               items:
@@ -1526,13 +1357,10 @@ spec:
                               type: string
                           type: object
                         repoURL:
-                          description: RepoURL is the repository URL of the application
-                            manifests
+                          description: RepoURL is the repository URL of the application manifests
                           type: string
                         targetRevision:
-                          description: TargetRevision defines the commit, tag, or
-                            branch in which to sync the application to. If omitted,
-                            will sync to HEAD
+                          description: TargetRevision defines the commit, tag, or branch in which to sync the application to. If omitted, will sync to HEAD
                           type: string
                       required:
                       - repoURL
@@ -1546,14 +1374,12 @@ spec:
               - startedAt
               type: object
             reconciledAt:
-              description: ReconciledAt indicates when the application state was reconciled
-                using the latest git version
+              description: ReconciledAt indicates when the application state was reconciled using the latest git version
               format: date-time
               type: string
             resources:
               items:
-                description: ResourceStatus holds the current sync and health status
-                  of a resource
+                description: ResourceStatus holds the current sync and health status of a resource
                 properties:
                   group:
                     type: string
@@ -1576,8 +1402,7 @@ spec:
                   requiresPruning:
                     type: boolean
                   status:
-                    description: SyncStatusCode is a type which represents possible
-                      comparison results
+                    description: SyncStatusCode is a type which represents possible comparison results
                     type: string
                   version:
                     type: string
@@ -1588,8 +1413,7 @@ spec:
             summary:
               properties:
                 externalURLs:
-                  description: ExternalURLs holds all external URLs of application
-                    child resources.
+                  description: ExternalURLs holds all external URLs of application child resources.
                   items:
                     type: string
                   type: array
@@ -1600,34 +1424,26 @@ spec:
                   type: array
               type: object
             sync:
-              description: SyncStatus is a comparison result of application spec and
-                deployed application.
+              description: SyncStatus is a comparison result of application spec and deployed application.
               properties:
                 comparedTo:
-                  description: ComparedTo contains application source and target which
-                    was used for resources comparison
+                  description: ComparedTo contains application source and target which was used for resources comparison
                   properties:
                     destination:
-                      description: ApplicationDestination contains deployment destination
-                        information
+                      description: ApplicationDestination contains deployment destination information
                       properties:
                         name:
-                          description: Name of the destination cluster which can be
-                            used instead of server (url) field
+                          description: Name of the destination cluster which can be used instead of server (url) field
                           type: string
                         namespace:
-                          description: Namespace overrides the environment namespace
-                            value in the ksonnet app.yaml
+                          description: Namespace overrides the environment namespace value in the ksonnet app.yaml
                           type: string
                         server:
-                          description: Server overrides the environment server value
-                            in the ksonnet app.yaml
+                          description: Server overrides the environment server value in the ksonnet app.yaml
                           type: string
                       type: object
                     source:
-                      description: ApplicationSource contains information about github
-                        repository, path within repository and target application
-                        environment.
+                      description: ApplicationSource contains information about github repository, path within repository and target application environment.
                       properties:
                         chart:
                           description: Chart is a Helm chart name
@@ -1636,12 +1452,10 @@ spec:
                           description: Directory holds path/directory specific options
                           properties:
                             jsonnet:
-                              description: ApplicationSourceJsonnet holds jsonnet
-                                specific options
+                              description: ApplicationSourceJsonnet holds jsonnet specific options
                               properties:
                                 extVars:
-                                  description: ExtVars is a list of Jsonnet External
-                                    Variables
+                                  description: ExtVars is a list of Jsonnet External Variables
                                   items:
                                     description: JsonnetVar is a jsonnet variable
                                     properties:
@@ -1662,8 +1476,7 @@ spec:
                                     type: string
                                   type: array
                                 tlas:
-                                  description: TLAS is a list of Jsonnet Top-level
-                                    Arguments
+                                  description: TLAS is a list of Jsonnet Top-level Arguments
                                   items:
                                     description: JsonnetVar is a jsonnet variable
                                     properties:
@@ -1686,31 +1499,25 @@ spec:
                           description: Helm holds helm specific options
                           properties:
                             fileParameters:
-                              description: FileParameters are file parameters to the
-                                helm template
+                              description: FileParameters are file parameters to the helm template
                               items:
-                                description: HelmFileParameter is a file parameter
-                                  to a helm template
+                                description: HelmFileParameter is a file parameter to a helm template
                                 properties:
                                   name:
                                     description: Name is the name of the helm parameter
                                     type: string
                                   path:
-                                    description: Path is the path value for the helm
-                                      parameter
+                                    description: Path is the path value for the helm parameter
                                     type: string
                                 type: object
                               type: array
                             parameters:
                               description: Parameters are parameters to the helm template
                               items:
-                                description: HelmParameter is a parameter to a helm
-                                  template
+                                description: HelmParameter is a parameter to a helm template
                                 properties:
                                   forceString:
-                                    description: ForceString determines whether to
-                                      tell Helm to interpret booleans and numbers
-                                      as strings
+                                    description: ForceString determines whether to tell Helm to interpret booleans and numbers as strings
                                     type: boolean
                                   name:
                                     description: Name is the name of the helm parameter
@@ -1721,33 +1528,30 @@ spec:
                                 type: object
                               type: array
                             releaseName:
-                              description: The Helm release name. If omitted it will
-                                use the application name
+                              description: The Helm release name. If omitted it will use the application name
                               type: string
                             valueFiles:
-                              description: ValuesFiles is a list of Helm value files
-                                to use when generating a template
+                              description: ValuesFiles is a list of Helm value files to use when generating a template
                               items:
                                 type: string
                               type: array
                             values:
-                              description: Values is Helm values, typically defined
-                                as a block
+                              description: Values is Helm values, typically defined as a block
+                              type: string
+                            version:
+                              description: Version is the Helm version to use for templating with
                               type: string
                           type: object
                         ksonnet:
                           description: Ksonnet holds ksonnet specific options
                           properties:
                             environment:
-                              description: Environment is a ksonnet application environment
-                                name
+                              description: Environment is a ksonnet application environment name
                               type: string
                             parameters:
-                              description: Parameters are a list of ksonnet component
-                                parameter override values
+                              description: Parameters are a list of ksonnet component parameter override values
                               items:
-                                description: KsonnetParameter is a ksonnet component
-                                  parameter
+                                description: KsonnetParameter is a ksonnet component parameter
                                 properties:
                                   component:
                                     type: string
@@ -1767,21 +1571,18 @@ spec:
                             commonLabels:
                               additionalProperties:
                                 type: string
-                              description: CommonLabels adds additional kustomize
-                                commonLabels
+                              description: CommonLabels adds additional kustomize commonLabels
                               type: object
                             images:
                               description: Images are kustomize image overrides
                               items:
                                 type: string
                               type: array
                             namePrefix:
-                              description: NamePrefix is a prefix appended to resources
-                                for kustomize apps
+                              description: NamePrefix is a prefix appended to resources for kustomize apps
                               type: string
                             nameSuffix:
-                              description: NameSuffix is a suffix appended to resources
-                                for kustomize apps
+                              description: NameSuffix is a suffix appended to resources for kustomize apps
                               type: string
                             version:
                               description: Version contains optional Kustomize version
@@ -1791,8 +1592,7 @@ spec:
                           description: Path is a directory path within the Git repository
                           type: string
                         plugin:
-                          description: ConfigManagementPlugin holds config management
-                            plugin specific options
+                          description: ConfigManagementPlugin holds config management plugin specific options
                           properties:
                             env:
                               items:
@@ -1812,13 +1612,10 @@ spec:
                               type: string
                           type: object
                         repoURL:
-                          description: RepoURL is the repository URL of the application
-                            manifests
+                          description: RepoURL is the repository URL of the application manifests
                           type: string
                         targetRevision:
-                          description: TargetRevision defines the commit, tag, or
-                            branch in which to sync the application to. If omitted,
-                            will sync to HEAD
+                          description: TargetRevision defines the commit, tag, or branch in which to sync the application to. If omitted, will sync to HEAD
                           type: string
                       required:
                       - repoURL
@@ -1830,8 +1627,7 @@ spec:
                 revision:
                   type: string
                 status:
-                  description: SyncStatusCode is a type which represents possible
-                    comparison results
+                  description: SyncStatusCode is a type which represents possible comparison results
                   type: string
               required:
               - status
@@ -1867,34 +1663,23 @@ spec:
   scope: Namespaced
   validation:
     openAPIV3Schema:
-      description: 'AppProject provides a logical grouping of applications, providing
-        controls for: * where the apps may deploy to (cluster whitelist) * what may
-        be deployed (repository whitelist, resource whitelist/blacklist) * who can
-        access these applications (roles, OIDC group claims bindings) * and what they
-        can do (RBAC policies) * automation access to these roles (JWT tokens)'
+      description: 'AppProject provides a logical grouping of applications, providing controls for: * where the apps may deploy to (cluster whitelist) * what may be deployed (repository whitelist, resource whitelist/blacklist) * who can access these applications (roles, OIDC group claims bindings) * and what they can do (RBAC policies) * automation access to these roles (JWT tokens)'
       properties:
         apiVersion:
-          description: 'APIVersion defines the versioned schema of this representation
-            of an object. Servers should convert recognized schemas to the latest
-            internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
+          description: 'APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
           type: string
         kind:
-          description: 'Kind is a string value representing the REST resource this
-            object represents. Servers may infer this from the endpoint the client
-            submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
+          description: 'Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
           type: string
         metadata:
           type: object
         spec:
           description: AppProjectSpec is the specification of an AppProject
           properties:
             clusterResourceBlacklist:
-              description: ClusterResourceBlacklist contains list of blacklisted cluster
-                level resources
+              description: ClusterResourceBlacklist contains list of blacklisted cluster level resources
               items:
-                description: GroupKind specifies a Group and a Kind, but does not
-                  force a version.  This is useful for identifying concepts during
-                  lookup stages without having partially valid types
+                description: GroupKind specifies a Group and a Kind, but does not force a version.  This is useful for identifying concepts during lookup stages without having partially valid types
                 properties:
                   group:
                     type: string
@@ -1906,12 +1691,9 @@ spec:
                 type: object
               type: array
             clusterResourceWhitelist:
-              description: ClusterResourceWhitelist contains list of whitelisted cluster
-                level resources
+              description: ClusterResourceWhitelist contains list of whitelisted cluster level resources
               items:
-                description: GroupKind specifies a Group and a Kind, but does not
-                  force a version.  This is useful for identifying concepts during
-                  lookup stages without having partially valid types
+                description: GroupKind specifies a Group and a Kind, but does not force a version.  This is useful for identifying concepts during lookup stages without having partially valid types
                 properties:
                   group:
                     type: string
@@ -1926,33 +1708,25 @@ spec:
               description: Description contains optional project description
               type: string
             destinations:
-              description: Destinations contains list of destinations available for
-                deployment
+              description: Destinations contains list of destinations available for deployment
               items:
-                description: ApplicationDestination contains deployment destination
-                  information
+                description: ApplicationDestination contains deployment destination information
                 properties:
                   name:
-                    description: Name of the destination cluster which can be used
-                      instead of server (url) field
+                    description: Name of the destination cluster which can be used instead of server (url) field
                     type: string
                   namespace:
-                    description: Namespace overrides the environment namespace value
-                      in the ksonnet app.yaml
+                    description: Namespace overrides the environment namespace value in the ksonnet app.yaml
                     type: string
                   server:
-                    description: Server overrides the environment server value in
-                      the ksonnet app.yaml
+                    description: Server overrides the environment server value in the ksonnet app.yaml
                     type: string
                 type: object
               type: array
             namespaceResourceBlacklist:
-              description: NamespaceResourceBlacklist contains list of blacklisted
-                namespace level resources
+              description: NamespaceResourceBlacklist contains list of blacklisted namespace level resources
               items:
-                description: GroupKind specifies a Group and a Kind, but does not
-                  force a version.  This is useful for identifying concepts during
-                  lookup stages without having partially valid types
+                description: GroupKind specifies a Group and a Kind, but does not force a version.  This is useful for identifying concepts during lookup stages without having partially valid types
                 properties:
                   group:
                     type: string
@@ -1964,12 +1738,9 @@ spec:
                 type: object
               type: array
             namespaceResourceWhitelist:
-              description: NamespaceResourceWhitelist contains list of whitelisted
-                namespace level resources
+              description: NamespaceResourceWhitelist contains list of whitelisted namespace level resources
               items:
-                description: GroupKind specifies a Group and a Kind, but does not
-                  force a version.  This is useful for identifying concepts during
-                  lookup stages without having partially valid types
+                description: GroupKind specifies a Group and a Kind, but does not force a version.  This is useful for identifying concepts during lookup stages without having partially valid types
                 properties:
                   group:
                     type: string
@@ -1981,8 +1752,7 @@ spec:
                 type: object
               type: array
             orphanedResources:
-              description: OrphanedResources specifies if controller should monitor
-                orphaned resources of apps in this project
+              description: OrphanedResources specifies if controller should monitor orphaned resources of apps in this project
               properties:
                 ignore:
                   items:
@@ -1996,31 +1766,26 @@ spec:
                     type: object
                   type: array
                 warn:
-                  description: Warn indicates if warning condition should be created
-                    for apps which have orphaned resources
+                  description: Warn indicates if warning condition should be created for apps which have orphaned resources
                   type: boolean
               type: object
             roles:
-              description: Roles are user defined RBAC roles associated with this
-                project
+              description: Roles are user defined RBAC roles associated with this project
               items:
                 description: ProjectRole represents a role that has access to a project
                 properties:
                   description:
                     description: Description is a description of the role
                     type: string
                   groups:
-                    description: Groups are a list of OIDC group claims bound to this
-                      role
+                    description: Groups are a list of OIDC group claims bound to this role
                     items:
                       type: string
                     type: array
                   jwtTokens:
-                    description: JWTTokens are a list of generated JWT tokens bound
-                      to this role
+                    description: JWTTokens are a list of generated JWT tokens bound to this role
                     items:
-                      description: JWTToken holds the issuedAt and expiresAt values
-                        of a token
+                      description: JWTToken holds the issuedAt and expiresAt values of a token
                       properties:
                         exp:
                           format: int64
@@ -2038,8 +1803,7 @@ spec:
                     description: Name is a name for this role
                     type: string
                   policies:
-                    description: Policies Stores a list of casbin formated strings
-                      that define access policies for the role in the project
+                    description: Policies Stores a list of casbin formated strings that define access policies for the role in the project
                     items:
                       type: string
                     type: array
@@ -2048,11 +1812,9 @@ spec:
                 type: object
               type: array
             signatureKeys:
-              description: List of PGP key IDs that commits to be synced to must be
-                signed with
+              description: List of PGP key IDs that commits to be synced to must be signed with
               items:
-                description: SignatureKey is the specification of a key required to
-                  verify commit signatures with
+                description: SignatureKey is the specification of a key required to verify commit signatures with
                 properties:
                   keyID:
                     description: The ID of the key in hexadecimal notation
@@ -2062,50 +1824,41 @@ spec:
                 type: object
               type: array
             sourceRepos:
-              description: SourceRepos contains list of repository URLs which can
-                be used for deployment
+              description: SourceRepos contains list of repository URLs which can be used for deployment
               items:
                 type: string
               type: array
             syncWindows:
-              description: SyncWindows controls when syncs can be run for apps in
-                this project
+              description: SyncWindows controls when syncs can be run for apps in this project
               items:
-                description: SyncWindow contains the kind, time, duration and attributes
-                  that are used to assign the syncWindows to apps
+                description: SyncWindow contains the kind, time, duration and attributes that are used to assign the syncWindows to apps
                 properties:
                   applications:
-                    description: Applications contains a list of applications that
-                      the window will apply to
+                    description: Applications contains a list of applications that the window will apply to
                     items:
                       type: string
                     type: array
                   clusters:
-                    description: Clusters contains a list of clusters that the window
-                      will apply to
+                    description: Clusters contains a list of clusters that the window will apply to
                     items:
                       type: string
                     type: array
                   duration:
-                    description: Duration is the amount of time the sync window will
-                      be open
+                    description: Duration is the amount of time the sync window will be open
                     type: string
                   kind:
                     description: Kind defines if the window allows or blocks syncs
                     type: string
                   manualSync:
-                    description: ManualSync enables manual syncs when they would otherwise
-                      be blocked
+                    description: ManualSync enables manual syncs when they would otherwise be blocked
                     type: boolean
                   namespaces:
-                    description: Namespaces contains a list of namespaces that the
-                      window will apply to
+                    description: Namespaces contains a list of namespaces that the window will apply to
                     items:
                       type: string
                     type: array
                   schedule:
-                    description: Schedule is the time the window will begin, specified
-                      in cron format
+                    description: Schedule is the time the window will begin, specified in cron format
                     type: string
                 type: object
               type: array

---FILE: base/argocd/argo/06_install.yaml---
@@ -454,7 +454,7 @@ metadata:
     app.kubernetes.io/component: application-controller
     app.kubernetes.io/name: argocd-application-controller
     app.kubernetes.io/part-of: argocd
-    app.kubernetes.io/version: 1.7.7
+    app.kubernetes.io/version: 1.8.0-alpha
   name: argocd-application-controller
   namespace: argocd
 spec:
@@ -467,7 +467,7 @@ spec:
     metadata:
       labels:
         app.kubernetes.io/name: argocd-application-controller
-        app.kubernetes.io/version: 1.7.7
+        app.kubernetes.io/version: 1.8.0-alpha
     spec:
       containers:
       - command:
@@ -476,7 +476,7 @@ spec:
         - ""10""
         - --operation-processors
         - ""5""
-        image: quay.io/paulfantom/argocd:42818c42  # v1.7.7
+        image: quay.io/paulfantom/argocd:1bed5a14  # v1.8.0-alpha
         livenessProbe:
           httpGet:
             path: /healthz
@@ -507,7 +507,7 @@ metadata:
     app.kubernetes.io/component: dex-server
     app.kubernetes.io/name: argocd-dex-server
     app.kubernetes.io/part-of: argocd
-    app.kubernetes.io/version: 1.7.7
+    app.kubernetes.io/version: 1.8.0-alpha
   name: argocd-dex-server
   namespace: argocd
 spec:
@@ -518,7 +518,7 @@ spec:
     metadata:
       labels:
         app.kubernetes.io/name: argocd-dex-server
-        app.kubernetes.io/version: 1.7.7
+        app.kubernetes.io/version: 1.8.0-alpha
     spec:
       containers:
       - command:
@@ -542,7 +542,7 @@ spec:
         - -n
         - /usr/local/bin/argocd-util
         - /shared
-        image: quay.io/paulfantom/argocd:42818c42  # v1.7.7
+        image: quay.io/paulfantom/argocd:1bed5a14  # v1.8.0-alpha
         name: copyutil
         volumeMounts:
         - mountPath: /shared
@@ -559,7 +559,7 @@ metadata:
     app.kubernetes.io/component: redis
     app.kubernetes.io/name: argocd-redis
     app.kubernetes.io/part-of: argocd
-    app.kubernetes.io/version: 1.7.7
+    app.kubernetes.io/version: 1.8.0-alpha
   name: argocd-redis
   namespace: argocd
 spec:
@@ -570,7 +570,7 @@ spec:
     metadata:
       labels:
         app.kubernetes.io/name: argocd-redis
-        app.kubernetes.io/version: 1.7.7
+        app.kubernetes.io/version: 1.8.0-alpha
     spec:
       containers:
       - args:
@@ -598,7 +598,7 @@ metadata:
     app.kubernetes.io/component: repo-server
     app.kubernetes.io/name: argocd-repo-server
     app.kubernetes.io/part-of: argocd
-    app.kubernetes.io/version: 1.7.7
+    app.kubernetes.io/version: 1.8.0-alpha
   name: argocd-repo-server
   namespace: argocd
 spec:
@@ -617,7 +617,7 @@ spec:
         - argocd-repo-server
         - --redis
         - argocd-redis:6379
-        image: quay.io/paulfantom/argocd:42818c42  # v1.7.7
+        image: quay.io/paulfantom/argocd:1bed5a14  # v1.8.0-alpha
         livenessProbe:
           initialDelaySeconds: 5
           periodSeconds: 10
@@ -664,7 +664,7 @@ metadata:
     app.kubernetes.io/component: server
     app.kubernetes.io/name: argocd-server
     app.kubernetes.io/part-of: argocd
-    app.kubernetes.io/version: 1.7.7
+    app.kubernetes.io/version: 1.8.0-alpha
   name: argocd-server
   namespace: argocd
 spec:
@@ -675,14 +675,14 @@ spec:
     metadata:
       labels:
         app.kubernetes.io/name: argocd-server
-        app.kubernetes.io/version: 1.7.7
+        app.kubernetes.io/version: 1.8.0-alpha
     spec:
       containers:
       - command:
         - argocd-server
         - --staticassets
         - /shared/app
-        image: quay.io/paulfantom/argocd:42818c42  # v1.7.7
+        image: quay.io/paulfantom/argocd:1bed5a14  # v1.8.0-alpha
         livenessProbe:
           httpGet:
             path: /healthz"
thaum-xyz,ankhmorpork,012dbaaca4b479df9462142c166f8282ff0cf706,paulfantom,pawel@krupa.net.pl,2020-10-15T10:16:34Z,paulfantom,pawel@krupa.net.pl,2020-10-15T10:16:34Z,base/ingress-nginx: fix nginx metrics exposition,base/ingress-nginx/deploy.yaml,False,False,False,False,3,0,3,"---FILE: base/ingress-nginx/deploy.yaml---
@@ -396,6 +396,9 @@ spec:
             - name: webhook
               containerPort: 8443
               protocol: TCP
+            - name: metrics
+              containerPort: 10254
+              protocol: TCP
           volumeMounts:
             - name: webhook-cert
               mountPath: /usr/local/certificates/"
thaum-xyz,ankhmorpork,18f122c7b7cbfd1dc222db7a738941f701ac8a86,paulfantom,pawel@krupa.net.pl,2020-09-21T08:49:04Z,paulfantom,pawel@krupa.net.pl,2020-09-21T08:49:04Z,apps/monitoring: fix issues reported by kubeval,apps/monitoring/ksm/04_statefulset.yaml;apps/monitoring/prometheus-operator/crds/0probeCustomResourceDefinition.yaml,False,False,False,False,1,1,2,"---FILE: apps/monitoring/ksm/04_statefulset.yaml---
@@ -8,6 +8,7 @@ metadata:
   namespace: monitoring
 spec:
   replicas: 2
+  serviceName: kube-state-metrics
   selector:
     matchLabels:
       app.kubernetes.io/name: kube-state-metrics

---FILE: apps/monitoring/prometheus-operator/crds/0probeCustomResourceDefinition.yaml---
@@ -1,4 +1,3 @@
-
 ---
 apiVersion: apiextensions.k8s.io/v1
 kind: CustomResourceDefinition"
thaum-xyz,ankhmorpork,ae5ad1164f4673852ebaa6fa5a477d661fd1854a,paulfantom,pawel@krupa.net.pl,2020-09-21T08:37:59Z,paulfantom,pawel@krupa.net.pl,2020-09-21T08:37:59Z,".github/workflows,hack: fix image checking",.github/workflows/images.yml;hack/checkimages.sh,False,False,False,False,2,1,3,"---FILE: .github/workflows/images.yml---
@@ -14,7 +14,7 @@ jobs:
       - uses: actions/checkout@v2
       - uses: actions/setup-go@v2
         with:
-          go-version: '^1.13.1'
+          go-version: '1.15'
       - run: go get -u github.com/brancz/gojsontoyaml
       - run: go get -u github.com/estesp/manifest-tool
       - run: sudo apt update && sudo apt install -y jq

---FILE: hack/checkimages.sh---
@@ -20,6 +20,7 @@ nginx/nginx-prometheus-exporter
 allangood/holiday_exporter
 quay.io/superq/smokeping-prober-linux-arm64
 quay.io/prometheus/mysqld-exporter
+k8s.gcr.io/kube-state-metrics/kube-state-metrics-arm64
 EOM
 )
 "
thaum-xyz,ankhmorpork,3ebff15016ebf9ed24e6eb2db8e953ebf29329d8,paulfantom,pawel@krupa.net.pl,2020-09-21T08:36:47Z,paulfantom,pawel@krupa.net.pl,2020-09-21T08:36:47Z,.github/workflows: fix kubeval validations,.github/workflows/kubeval.yml,False,False,False,False,4,4,8,"---FILE: .github/workflows/kubeval.yml---
@@ -14,15 +14,15 @@ jobs:
       - uses: actions/checkout@v2
       - uses: actions/setup-go@v2
         with:
-          go-version: '^1.13.1'
+          go-version: '1.15'
       - run: go get -u github.com/instrumenta/kubeval
-      - run: kubeval --skip-kinds SealedSecret,ConfigMapSecret,CustomResourceDefinition,ServiceMonitor,PodMonitor,Prometheus,PrometheusRule,Alertmanager,APIService --strict -d apps/
+      - run: kubeval --skip-kinds SealedSecret,ConfigMapSecret,CustomResourceDefinition,ServiceMonitor,PodMonitor,Probe,Prometheus,PrometheusRule,Alertmanager,APIService --strict --force-color -d apps/
   base:
     runs-on: ubuntu-latest
     steps:
       - uses: actions/checkout@v2
       - uses: actions/setup-go@v2
         with:
-          go-version: '^1.13.1'
+          go-version: '1.15'
       - run: go get -u github.com/instrumenta/kubeval
-      - run: kubeval --skip-kinds SealedSecret,Application,CustomResourceDefinition,ClusterIssuer,AppProject,ServiceMonitor,PodMonitor,PrometheusRule --strict -d base/
+      - run: kubeval --skip-kinds SealedSecret,Application,CustomResourceDefinition,ClusterIssuer,AppProject,ServiceMonitor,PodMonitor,PrometheusRule --strict --force-color -d base/"
thaum-xyz,ankhmorpork,886cdf732870efe9dc389bff08bf6a48e14579e5,paulfantom,pawel@krupa.net.pl,2020-09-11T15:39:32Z,paulfantom,pawel@krupa.net.pl,2020-09-11T15:39:32Z,"apps,base: fix issues with immutabe fields",apps/multimedia/plex/05_statefulset.yaml;apps/multimedia/transmission/05_deployment.yaml;base/ingress-nginx/deploy.yaml;base/kube-system/sealed-secrets/controller.yaml,False,False,False,False,0,7,7,"---FILE: apps/multimedia/plex/05_statefulset.yaml---
@@ -13,7 +13,6 @@ spec:
   selector:
     matchLabels:
       app.kubernetes.io/name: plex
-      app.kubernetes.io/version: 1.20.1
   serviceName: plex
   template:
     metadata:

---FILE: apps/multimedia/transmission/05_deployment.yaml---
@@ -14,7 +14,6 @@ spec:
   selector:
     matchLabels:
       app.kubernetes.io/name: transmission
-      app.kubernetes.io/version: 2.13
   template:
     metadata:
       labels:

---FILE: base/ingress-nginx/deploy.yaml---
@@ -510,7 +510,6 @@ metadata:
   labels:
     app.kubernetes.io/name: ingress-nginx
     app.kubernetes.io/instance: ingress-nginx
-    app.kubernetes.io/version: 0.35.0
     app.kubernetes.io/component: admission-webhook
   namespace: ingress-nginx
 spec:
@@ -520,7 +519,6 @@ spec:
       labels:
         app.kubernetes.io/name: ingress-nginx
         app.kubernetes.io/instance: ingress-nginx
-        app.kubernetes.io/version: 0.35.0
         app.kubernetes.io/component: admission-webhook
     spec:
       containers:
@@ -546,7 +544,6 @@ metadata:
   labels:
     app.kubernetes.io/name: ingress-nginx
     app.kubernetes.io/instance: ingress-nginx
-    app.kubernetes.io/version: 0.35.0
     app.kubernetes.io/component: admission-webhook
   namespace: ingress-nginx
 spec:
@@ -556,7 +553,6 @@ spec:
       labels:
         app.kubernetes.io/name: ingress-nginx
         app.kubernetes.io/instance: ingress-nginx
-        app.kubernetes.io/version: 0.35.0
         app.kubernetes.io/component: admission-webhook
     spec:
       containers:

---FILE: base/kube-system/sealed-secrets/controller.yaml---
@@ -21,7 +21,6 @@ spec:
       app.kubernetes.io/managed-by: jsonnet
       app.kubernetes.io/name: kubeseal
       app.kubernetes.io/part-of: kubeseal
-      app.kubernetes.io/version: v0.12.5
       name: sealed-secrets-controller
   strategy:
     rollingUpdate:"
thaum-xyz,ankhmorpork,26cd1377f5894b38c4e4973661e95d82dcb7d970,paulfantom,pawel@krupa.net.pl,2020-09-11T10:15:09Z,paulfantom,pawel@krupa.net.pl,2020-09-11T10:15:09Z,apps/monitoring/prometheus: fix typo,apps/monitoring/prometheus/rules/general.yaml;apps/monitoring/prometheus/rules/thaum.yaml,False,False,False,False,5,5,10,"---FILE: apps/monitoring/prometheus/rules/general.yaml---
@@ -25,7 +25,7 @@ spec:
     - alert: TargetsDown
       annotations:
         summary: ""Prometheus targets went down""
-        desctiption: '{{ printf ""%.4g"" $value }}% of the {{ $labels.job }}/{{ $labels.service }} targets in {{ $labels.namespace }} namespace are down.'
+        description: '{{ printf ""%.4g"" $value }}% of the {{ $labels.job }}/{{ $labels.service }} targets in {{ $labels.namespace }} namespace are down.'
       expr: 100 * (count(up{job!=""windows""} == 0) BY (job, namespace, service) / count(up{job!=""windows""}) BY (job, namespace, service)) > 10
       for: 10m
       labels:
@@ -40,7 +40,7 @@ spec:
         severity: warning
       annotations:
         summary: ""Cron job did not complete""
-        desctiption: ""Cron job {{ $labels.job }} has not started/completed in {{ $value | humanizeDuration }}""
+        description: ""Cron job {{ $labels.job }} has not started/completed in {{ $value | humanizeDuration }}""
         runbook_url: ""https://github.com/thaum-xyz/ankhmorpork/blob/master/docs/runbooks/JobCompletion.md""
   - name: custom node alert rules
     rules:
@@ -54,7 +54,7 @@ spec:
         severity: info
       annotations:
         summary: ""Packages are available for upgrade""
-        desctiption: ""{{ $value }} packages are available for upgrade. Maybe it is time to upgrade?""
+        description: ""{{ $value }} packages are available for upgrade. Maybe it is time to upgrade?""
         runbook_url: ""https://github.com/thaum-xyz/ankhmorpork/blob/master/docs/runbooks/PackagesAvailable.md""
     - alert: RebootRequired
       expr: ""node_reboot_required > 0""
@@ -63,6 +63,6 @@ spec:
         severity: info
       annotations:
         summary: ""Reboot is required to finish package upgrade""
-        desctiption: ""Instance '{{ $labels.instance }}' was upgraded and now requires a reboot.""
+        description: ""Instance '{{ $labels.instance }}' was upgraded and now requires a reboot.""
         runbook_url: ""https://github.com/thaum-xyz/ankhmorpork/blob/master/docs/runbooks/RebootRequired.md""
 

---FILE: apps/monitoring/prometheus/rules/thaum.yaml---
@@ -17,7 +17,7 @@ spec:
           severity: warning
         annotations:
           summary: ""Federated prometheus is down""
-          desctiption: ""Remote Prometheus server {{ $labels.instance }} has been down for more than 10 minutes.""
+          description: ""Remote Prometheus server {{ $labels.instance }} has been down for more than 10 minutes.""
           runbook_url: ""https://github.com/thaum-xyz/ankhmorpork/blob/master/docs/runbooks/FederatedPrometheusDown.md""
       - alert: FilesystemReadOnly
         expr: |"
thaum-xyz,ankhmorpork,de1ca39f154f301cbfcf092158ca70fc29ea8fe1,paulfantom,pawel@krupa.net.pl,2020-08-21T08:30:50Z,paulfantom,pawel@krupa.net.pl,2020-08-21T08:30:50Z,apps/multimedia/ombi: fix image url,apps/multimedia/ombi/04_statefulset.yaml,False,False,False,False,1,1,2,"---FILE: apps/multimedia/ombi/04_statefulset.yaml---
@@ -23,7 +23,7 @@ spec:
         - name: TZ
           value: ""Europe/Berlin""
         name: ombi
-        image: linuxserver/ombi:3.0.5202-ls66
+        image: linuxserver/ombi:v3.0.5202-ls66
         imagePullPolicy: IfNotPresent
         ports:
           - containerPort: 3579"
thaum-xyz,ankhmorpork,8a21245afc07e1e635d93b7a3ef73d6430c9e05e,paulfantom,pawel@krupa.net.pl,2020-08-15T11:01:42Z,paulfantom,pawel@krupa.net.pl,2020-08-15T11:02:03Z,"add kube-events-exporter v0.1.0

version v0.1.0 with almost the same manifests as upstream project, but
with few modifications:
* pinned image to v0.1.0 instead of latest (issue open in
https://github.com/rhobs/kube-events-exporter/issues/65)
* changed component label to be more generic
* obvious namespace change",apps/monitoring/kube-events-exporter/02_rbac.yaml;apps/monitoring/kube-events-exporter/03_deployment.yaml;apps/monitoring/kube-events-exporter/04_podMonitor.yaml;base/argocd/apps/monitoring.yaml,False,False,False,False,117,0,117,"---FILE: apps/monitoring/kube-events-exporter/02_rbac.yaml---
@@ -0,0 +1,45 @@
+apiVersion: rbac.authorization.k8s.io/v1
+kind: ClusterRoleBinding
+metadata:
+  labels:
+    app.kubernetes.io/component: exporter
+    app.kubernetes.io/name: kube-events-exporter
+    app.kubernetes.io/version: 0.1.0
+  name: kube-events-exporter
+  namespace: monitoring
+roleRef:
+  apiGroup: rbac.authorization.k8s.io
+  kind: ClusterRole
+  name: kube-events-exporter
+subjects:
+- kind: ServiceAccount
+  name: kube-events-exporter
+  namespace: monitoring
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: ClusterRole
+metadata:
+  labels:
+    app.kubernetes.io/component: exporter
+    app.kubernetes.io/name: kube-events-exporter
+    app.kubernetes.io/version: 0.1.0
+  name: kube-events-exporter
+  namespace: monitoring
+rules:
+- apiGroups:
+  - """"
+  resources:
+  - events
+  verbs:
+  - list
+  - watch
+---
+apiVersion: v1
+kind: ServiceAccount
+metadata:
+  labels:
+    app.kubernetes.io/component: exporter
+    app.kubernetes.io/name: kube-events-exporter
+    app.kubernetes.io/version: 0.1.0
+  name: kube-events-exporter
+  namespace: monitoring

---FILE: apps/monitoring/kube-events-exporter/03_deployment.yaml---
@@ -0,0 +1,34 @@
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  labels:
+    app.kubernetes.io/component: exporter
+    app.kubernetes.io/name: kube-events-exporter
+    app.kubernetes.io/version: 0.1.0
+  name: kube-events-exporter
+  namespace: monitoring
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app.kubernetes.io/component: exporter
+      app.kubernetes.io/name: kube-events-exporter
+  template:
+    metadata:
+      labels:
+        app.kubernetes.io/component: exporter
+        app.kubernetes.io/name: kube-events-exporter
+        app.kubernetes.io/version: 0.1.0
+    spec:
+      containers:
+      - image: quay.io/dgrisonnet/kube-events-exporter:v0.1.0
+        name: kube-events-exporter
+        ports:
+        - containerPort: 8080
+          name: event
+        - containerPort: 8081
+          name: exporter
+      securityContext:
+        runAsNonRoot: true
+        runAsUser: 65534
+      serviceAccountName: kube-events-exporter

---FILE: apps/monitoring/kube-events-exporter/04_podMonitor.yaml---
@@ -0,0 +1,17 @@
+apiVersion: monitoring.coreos.com/v1
+kind: PodMonitor
+metadata:
+  labels:
+    app.kubernetes.io/component: exporter
+    app.kubernetes.io/name: kube-events-exporter
+    app.kubernetes.io/version: 0.1.0
+  name: kube-events-exporter
+  namespace: monitoring
+spec:
+  podMetricsEndpoints:
+  - port: event
+  - port: exporter
+  selector:
+    matchLabels:
+      app.kubernetes.io/component: exporter
+      app.kubernetes.io/name: kube-events-exporter

---FILE: base/argocd/apps/monitoring.yaml---
@@ -207,3 +207,24 @@ spec:
     automated:
       prune: false
       selfHeal: false
+
+---
+apiVersion: argoproj.io/v1alpha1
+kind: Application
+metadata:
+  name: kube-events-exporter
+spec:
+  destination:
+    namespace: monitoring
+    server: 'https://kubernetes.default.svc'
+  source:
+    path: apps/monitoring/kube-events-exporter
+    repoURL: 'https://github.com/thaum-xyz/ankhmorpork.git'
+    targetRevision: HEAD
+  project: monitoring
+  syncPolicy:
+    automated:
+      prune: true
+      selfHeal: true
+
+"
thaum-xyz,ankhmorpork,b6de208eb7fa946247139040bc6641b2683b7736,paulfantom,pawel@krupa.net.pl,2020-08-09T07:00:21Z,paulfantom,pawel@krupa.net.pl,2020-08-09T07:00:21Z,fix backup backofflimit and  metrics cardinality,apps/adrianna/07_backup.yaml;apps/blog/07_backup.yaml;apps/homeassistant/07_backup.yaml;apps/nextcloud/backup/02_cronjobs.yaml;apps/unifi/backup/03_cronjob.yaml,False,False,False,False,5,13,18,"---FILE: apps/adrianna/07_backup.yaml---
@@ -23,9 +23,7 @@ spec:
                   fieldRef:
                     fieldPath: metadata.namespace
               - name: INSTANCE
-                valueFrom:
-                  fieldRef:
-                    fieldPath: metadata.name
+                value: blog
               - name: PUSHGATEWAY_URL
                 value: ""http://push.monitoring.svc:9091""
               - name: MAX_AGE

---FILE: apps/blog/07_backup.yaml---
@@ -23,9 +23,7 @@ spec:
                   fieldRef:
                     fieldPath: metadata.namespace
               - name: INSTANCE
-                valueFrom:
-                  fieldRef:
-                    fieldPath: metadata.name
+                value: blog
               - name: PUSHGATEWAY_URL
                 value: ""http://push.monitoring.svc:9091""
               - name: MAX_AGE

---FILE: apps/homeassistant/07_backup.yaml---
@@ -23,9 +23,7 @@ spec:
                   fieldRef:
                     fieldPath: metadata.namespace
               - name: INSTANCE
-                valueFrom:
-                  fieldRef:
-                    fieldPath: metadata.name
+                value: config
               - name: PUSHGATEWAY_URL
                 value: ""http://push.monitoring.svc:9091""
               - name: MAX_AGE

---FILE: apps/nextcloud/backup/02_cronjobs.yaml---
@@ -10,7 +10,7 @@ spec:
   schedule: ""43 2 * * *""  # At 02:43
   jobTemplate:
     spec:
-      backoffLimit: 1
+      backoffLimit: 3
       template:
         spec:
           containers:

---FILE: apps/unifi/backup/03_cronjob.yaml---
@@ -38,9 +38,7 @@ spec:
                   fieldRef:
                     fieldPath: metadata.namespace
               - name: INSTANCE
-                valueFrom:
-                  fieldRef:
-                    fieldPath: metadata.name
+                value: autobackup
               - name: DATA_DIRECTORY
                 value: ""/backup""
               - name: PUSHGATEWAY_URL"
thaum-xyz,ankhmorpork,fada7fdfef1ea48a29652a510b94132a657e0eb2,Pawe Krupa,pawel@krupa.net.pl,2020-07-30T18:22:58Z,GitHub,noreply@github.com,2020-07-30T18:22:58Z,fix previous fix,apps/monitoring/prometheus-operator/control-plane-components/serviceMonitorKubeScheduler.yaml,False,False,False,False,1,4,5,"---FILE: apps/monitoring/prometheus-operator/control-plane-components/serviceMonitorKubeScheduler.yaml---
@@ -8,10 +8,7 @@ metadata:
 spec:
   endpoints:
   - interval: 30s
-    port: https-metrics
-    scheme: https
-    tlsConfig:
-      insecureSkipVerify: true
+    port: http-metrics
   jobLabel: k8s-app
   namespaceSelector:
     matchNames:"
thaum-xyz,ankhmorpork,5d228a1117479fbb39fbc89bdf07c130ba82c116,Pawe Krupa,pawel@krupa.net.pl,2020-07-30T18:13:18Z,GitHub,noreply@github.com,2020-07-30T18:13:18Z,apps/monitoring/prometheus-operator: fix kuebe-scheduler SM,apps/monitoring/prometheus-operator/control-plane-components/serviceMonitorKubeScheduler.yaml,False,False,False,False,1,2,3,"---FILE: apps/monitoring/prometheus-operator/control-plane-components/serviceMonitorKubeScheduler.yaml---
@@ -7,8 +7,7 @@ metadata:
   namespace: monitoring
 spec:
   endpoints:
-  - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
-    interval: 30s
+  - interval: 30s
     port: https-metrics
     scheme: https
     tlsConfig:"
thaum-xyz,ankhmorpork,d908657759487fbaddb60fb28b2e072af91c7afc,paulfantom,pawel@krupa.net.pl,2020-07-30T15:07:04Z,paulfantom,pawel@krupa.net.pl,2020-07-30T15:07:52Z,apps/monitoring/prometheus-operator: fix rbac,apps/monitoring/prometheus-operator/02_rbac.yaml,False,False,False,False,1,0,1,"---FILE: apps/monitoring/prometheus-operator/02_rbac.yaml---
@@ -29,6 +29,7 @@ rules:
   - thanosrulers/finalizers
   - servicemonitors
   - podmonitors
+  - probes
   - prometheusrules
   verbs:
   - '*'"
thaum-xyz,ankhmorpork,1a3449d4d50766e75d5b688a549e4dddd26567d4,paulfantom,pawel@krupa.net.pl,2020-07-28T15:42:59Z,paulfantom,pawel@krupa.net.pl,2020-07-28T15:42:59Z,apps: fix env value type,apps/adrianna/07_backup.yaml;apps/ansible/ankhmorpork/04_cronjob.yaml;apps/blog/07_backup.yaml;apps/homeassistant/07_backup.yaml;apps/monitoring/prometheus/rules/thaum.yaml;apps/nextcloud/backup/02_cronjobs.yaml,False,False,False,False,25,7,32,"---FILE: apps/adrianna/07_backup.yaml---
@@ -29,7 +29,7 @@ spec:
               - name: PUSHGATEWAY_URL
                 value: ""http://push.monitoring.svc:9091""
               - name: MAX_AGE
-                value: 220
+                value: ""220""
             envFrom:
               - secretRef:
                   name: restic-repository

---FILE: apps/ansible/ankhmorpork/04_cronjob.yaml---
@@ -34,7 +34,7 @@ spec:
               - name: REPO_URL
                 value: ""https://github.com/thaum-xyz/ankhmorpork.git""
               - name: MAX_AGE
-                value: 1600
+                value: ""1600""
             volumeMounts:
               - name: repository
                 mountPath: /ansible

---FILE: apps/blog/07_backup.yaml---
@@ -29,7 +29,7 @@ spec:
               - name: PUSHGATEWAY_URL
                 value: ""http://push.monitoring.svc:9091""
               - name: MAX_AGE
-                value: 220
+                value: ""220""
             envFrom:
               - secretRef:
                   name: restic-repository

---FILE: apps/homeassistant/07_backup.yaml---
@@ -29,7 +29,7 @@ spec:
               - name: PUSHGATEWAY_URL
                 value: ""http://push.monitoring.svc:9091""
               - name: MAX_AGE
-                value: 410
+                value: ""410""
             envFrom:
               - secretRef:
                   name: restic-repository

---FILE: apps/monitoring/prometheus/rules/thaum.yaml---
@@ -33,3 +33,21 @@ spec:
         annotations:
           message: ""Filesystem went read-only possibly due to device error.""
           runbook: ""Check SD card for FS corruption. Possibly reflash OS to new card.""
+      - alert: TouchscreenNotAvailable
+        expr: |
+          devices_input_touchscreen_up == 0
+        for: 20m
+        labels:
+          severity: warning
+        annotations:
+          message: ""Touchscreen not available""
+          runbook: ""Powercycle device {{ $labels.instance }}""
+      - alert: TouchscreenNotAvailable
+        expr: |
+          devices_input_touchscreen_up == 0
+        for: 1h
+        labels:
+          severity: critical
+        annotations:
+          message: ""Touchscreen not available and automatic remediation failed to restore it""
+          runbook: ""Powercycle device {{ $labels.instance }}""

---FILE: apps/nextcloud/backup/02_cronjobs.yaml---
@@ -28,7 +28,7 @@ spec:
               - name: PUSHGATEWAY_URL
                 value: ""http://push.monitoring.svc:9091""
               - name: MAX_AGE
-                value: 6000
+                value: ""6000""
             envFrom:
               - secretRef:
                   name: restic-repository-files
@@ -50,7 +50,7 @@ spec:
               - name: PUSHGATEWAY_URL
                 value: ""http://push.monitoring.svc:9091""
               - name: MAX_AGE
-                value: 600
+                value: ""600""
             envFrom:
               - secretRef:
                   name: restic-repository-web
@@ -89,7 +89,7 @@ spec:
                     name: mysql-creds
                     key: mysql_pass
               - name: MAX_AGE
-                value: 500
+                value: ""500""
             envFrom:
               - configMapRef:
                   name: nextcloud-envs"
thaum-xyz,ankhmorpork,33a5cd247d9f1f46fe4e7fc2be5e014696c4ad91,paulfantom,pawel@krupa.net.pl,2020-07-22T14:55:00Z,paulfantom,pawel@krupa.net.pl,2020-07-22T14:55:06Z,apps/ansible/ankhmorpork: fix ssh key format,apps/ansible/ankhmorpork/03_sshprivkey.yaml,False,False,False,False,2,1,3,"---FILE: apps/ansible/ankhmorpork/03_sshprivkey.yaml---
@@ -6,11 +6,12 @@ metadata:
   namespace: ansible
 spec:
   encryptedData:
-    id_rsa: AgBsMVgScfBBPhxCMhqzKoHPvRT50JzMWHQzSK5Hzr2DjKoU9U8PzlLXnUN/iMVIWLraEC4M4ay/z7LoEc1MTYpTwQ+PEONlIQn77N0P+Gl7t+Q4D5v38cWxlvRKQSO83NIh9dAn1dPtKlETTIIePUZyY6aNwouhd8cxNAfq4gPWC/5t685Tq+LEwpp2cd4Ad5VZBW864Cu9Cngxw72vlFRAPcARz6Mblt8LTjXe/hP7Yiq1UZqEE0ZM7AV2cnAwmr2Jgh1WB9Kj36qOZbGNvgMiLiixBtMV7lczsbR7m2eIGOXebXbbth1Ot3fUXLFtu1Ghi5reqHdrh3sBnBohUWKqv976hmr2viN7pu58cMXrzuwuWg9xJ4/R4i4W6q8Q6I0mJMHBlCwaOIY12PH5gIszvaZdTBwMAsUFKW+SPd1ghKyTQbRVl5ZYx6rWrOAHLfYYJCVkcfBu34fB+e6yf7a8hy2wDBYCQHfogNhJ7I/4nAnE8L+86oWXtqqgQ3EBtS0vsm/079uJp7CRBpqU/vIxEGzWfYGiwxEv9ZF0nm3sjVNFs40oK/Yx8UoZqViRK1SrdqOb+8wvy48GsYtGCrT3UldM8s0fgu6hlydJhHStTHKecJaSmqaBXlrmin7MvW34dFF5cu8Rt7xbgwV9elW3rLt9mxExkZrDw+aCU23FyquMMMwvWkmim81DBrHM39EjuI8ojMQYr5zKYoo7YvcEEYNe5GY+TJkd67y6Uc3tGMh8/NDblOUwOevnuCAmHDFrMvPh4d2dl75bJ0A/2KesFFODZ/aLrclv1AmA8RLHB4iD/3Ok7RfnVwal2ZZGyp5tqIJ4R5CEMNsB5f5KcKnWNHw6DaGullCjSbmTE2GL0UeCxtRVLdDHFkUWdHPdVErxXe/GriW6df79MEXSZ26bEB8XqUo3ZVbS/sZ+05SEuOm1tRM+1SkaV4wuQJ5Oyurpuvosq2fr0hOMumlOvPLUaIdlE4a6OE3HX+KjoRG4A0sR7xzdZ/KQ0UX9f2aZwTpKAD5nCseXntwXnfYwFngyAgn1w+/OPdPZaKpwzV0jEnBAHQAxMkfGOXMRaWMZPt63v/KLnOLkwcRZfnNrhEP+YpO154l2XI7fXvx+9VpQmnq7ZdPFxpH/ixf6nwafnqj6hLBVnvY1cDd8fDQwx44zv/z+hVJs1tfHW3yH/+TVyKWAmnBCwaV0lVFXZxsbYr09Osif0bH65afnvKeUj1Rnvm2uXYO6xO8CrpyLbraB04acPawncgg1JHb0b8Ve5fKpCWFvZNiZouF07KnafbA8Ag0G2dtB8jdglNMxlXiwScSAMsxyPTOrAc63nS25Z12xsOeTWiqM49/DzrSVYXgR6uGzA/HLJUvXGDzLLGumXx8oMT6ew5+OeaBXuF09E+uavlqa5vkw/nu5B4d1u3juQIfnLis5GahTebAIGxXWzJ1OPV4/zXPuXji4zh3FSOKFM+h6vG5i2HeLEAmqnjLmugCHWqtYbFOpNSMW/+h9OdVIisL+XaRiIR7PRieKBVyeZZpNuzzVu+LbqoFOEHGcStE4+kBwbukPYwV9OR+16TxRsu29o6wagD6KC0/CMi1Xb/da6j0EiYynx5C+0wUhazVcL76PnXhSUsX9Kkeb9oCZ++nCg0cyA7O465WQZ+5eIcHg2sPu9ttaMmKSdfQ+RIIzVBpbBrhUjI5KWgDbXUc8RNFixp04YKJtgi3yiWVxsW0zZ2glEjRrnohYkoxN0Q8vPY/w6V0ulHZR5I44dkqAcVKLyxeL1nueCOmu4Zck3sEyM6Sl5M37+/TKb7M6TnPCECpZwv1P8axFvxsRehUGRvksjErf411QVIrxDss1htACRWYmFCG4kAYlVvotHWEnprlNhxZMu7J0HYhiUDAQPrRL2E7Vz0/+GkomOBUxCnCBb/usp+Jjx3SA6bbuEy/ylaAbN1O9cIw8uA4NrhNxVKGAy8jDEbLEG6I5aK1Q5P+MtKYy0SaMHeaijaAyLltY4JC/elyY9H07+ZEyqgNO1V2QfIWhkJpI/vNq8TjzD7qjK4zV2CeHmYWFimmbSYjvkY7FtaoXnrx7Z6kj4h44TJlqvxEr8ujQPV0/R9LFmVMCDOZjvQ4LZwS5APzjERbvSbXSIKzg30/l+msFMJH8U8wycrSkQDEcQ6K7NgK/tSf3er5hAzZ9Mr0rrB3KmznGhUjpCEv1pnJvGGkytFPjgzxGERV+3ZyVJkKEas0Hh3jC9bt3NjohNUEX/w00xWRWUFlWo0zOIljpUHJSaNbW6aKoCvY8wNsfIz6RLEHbE5mmXC32QJMfps2l6clBQDIzmsGGq6X4PbyyVqMJsj1cPQx4+6L/t8W9VcHDzplMs2iainP0/c5Yxg2eqQCmR1dR5s/C7AnIrKz3S+ak0+RyDa+fouAHGun8dpIlFWdZaezquhjnA0saLoO/sYV0SO6nQacnYi+Ig2toc85dVGGnZWH9Y50Dvc0ElV6Npm7syN+rNpUuLkLo2csWIJGKBiFZy8FYJbajynLTfCMAPFUvMAS+9BxklumhKMvhF3GOO1vuwwsyNknyL8JZx10zt4lBJF7Zgv2Qo0QMlmOQQgjJKukiD7IJi4xUtryzOFEV9QKje3/5/Pvt01xxwp0ibLv5P2WkRI8f/rMcpowkFMQDPM9Pm/PuOmF4JQ2djDK1t4esOZMfJLPjCCRelmTQE66KkshvcrpZZln6tkem5VEY87/1Ovfx0Rr+sQPUjwk2+uk+7cCEGE7eI4ow6H/Qn5v1899yNs2PaLGpEUAQ7Ieiv9m1HoKXtEo5JkunAHne+5s8hAEq5Xynmcm1pb6b+bTwfinlE/jPQfrz4ABEMOGqedIHVCGnUiClwZpPrYMcMkUP95No2KV7nn/Nqm97iQ19RsDw6FuhF9ynzFSqxRX3oolBp2N7KqnGXRZl2iApa3znG8O7+vA8J8DnrhERy1aA1raxNO3a8KBRksSKuNqrXcoi3fz0ly1DKHQ5/3oLvEpQGJxV346TXn3yUdu/TrK2ZaKg8hd0NI+sKiS/Mpx9SmHpn0C34iehg+9Vcyvca09m2GClVVC/owY8DC7UBVywSPq37vmBOs7hd5fcHbxOw9KOizYC2sTz8ToM2kViy2305X4SHprRVvVXCyNXRExZOkC/Cpqpj6Hcwi7R3C8xG/H/rjvx10KZcDa8DvCp7TNBKNkUxYsb4iReTy0rZYqPbZH5XfgEfM3qLY3vAbp3LeWiDwwcKm6bIzpzx5mGCBLVNy7SIjW7I0den290NMb6ClOjLZsQP0vLQ05DYLkjKnEE7qNtXg7/UOgUCUrU2ZHYwX4OLC1I4b8aSBiC4LoStq/go0QiX41Yba3uLqV3MtmB0IbDWLz0hsQhGse5g595ktJ7Mv4gkYe2BKSPX7sURU828xJBhO5f44P/k7hRdqofJN+P1d2InBk2YdOXUmfERCy/fg42OTqzYX/OmH3aohta0ythllfpV3bV0eTu8+a+7mrRSBsEYcQBmh0X/25qz7dv29cvTEhba29CNe/TRJ11Xlhb1gcsb9Xb00ETb94tbu70SM+hoN5e66UvF2BuezPz0+IvRt6MQwSONkCYU1FejCFRO1SXIvbpQ+6hr6Hk8MRUtBco3yhGN861d7+9RVvMuStMn8uTE5I7X5QBqB/HTjXqhs9iR38UXySi84TC32yfLVwQplT3S9Zf0ckMSvnwFlaMbeXBbc2la/6W9TlMhXx0DZ2C5Vep7soaorgf/nOE3TmQtD7qdQpPtmD3wapfaylElGfVYMxBC7vaPgHResAGd9uDRD+lUylKiMoOwlqHRLwv5dhYXDpwmSSrNneinKoxnENi3iCoLBbiz5HwAhynCfZ634wkT1YvLCmq2xcPWs6v28x0kKvqDofvjNWGP+C/HWocLXeilVnjXWbCetTp0MTv0aulIsd0qXYpNeNQyee5QlDCSdDKVx0wfc6bk+Y1PYsHqu5aFtzVHRIrnxb/eg0zkw3JqUb2II/Y6U/Kly3XOW0A4VoZe3mUzAoZpqTtcRyDUc98YAoRHRnm0aOobokbZCRwPW1ApF61dcpLoqgN/+/wYlADQQE99/O40UM+bAw7Y2QR+IEV5KhVZH4uiWZlgVGyGZFhQO3nJvsgYcZUFNDHVAGZuljzeQ1onGsFpjNCwJWXbw==
+    id_rsa: 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
   template:
     metadata:
       annotations:
         sealedsecrets.bitnami.com/managed: ""true""
       creationTimestamp: null
       name: sshprivkey
       namespace: ansible
+    type: Opaque"
thaum-xyz,ankhmorpork,d646368436bfbd0b6582fe62d84d6f27798ddfd1,paulfantom,pawel@krupa.net.pl,2020-07-22T14:34:49Z,paulfantom,pawel@krupa.net.pl,2020-07-22T14:42:30Z,apps/ansible/ankhmorpork: add repo_url to allow initial bootstrap and fix ARA url,apps/ansible/ankhmorpork/04_cronjob.yaml,False,False,False,False,3,1,4,"---FILE: apps/ansible/ankhmorpork/04_cronjob.yaml---
@@ -28,9 +28,11 @@ spec:
               - name: PUSHGATEWAY_URL
                 value: ""http://push.monitoring.svc:9091""
               - name: ARA_SERVER
-                value: ""http://ara.ara.svc:8000""
+                value: ""http://ara.ansible.svc:8000""
               - name: PLAYBOOK_NAME 
                 value: ""00_site.yml""
+              - name: REPO_URL
+                value: ""https://github.com/thaum-xyz/ankhmorpork.git""
             volumeMounts:
               - name: repository
                 mountPath: /ansible"
thaum-xyz,ankhmorpork,594ecfe2cb82446ebd50eb261bd9071a0296dd13,paulfantom,pawel@krupa.net.pl,2020-07-22T14:02:18Z,paulfantom,pawel@krupa.net.pl,2020-07-22T14:02:18Z,base/argocd/apps: fix ara deployment,base/argocd/apps/ara.yaml,False,False,False,False,0,19,19,"---FILE: base/argocd/apps/ara.yaml---
@@ -1,19 +0,0 @@
----
-apiVersion: argoproj.io/v1alpha1
-kind: Application
-metadata:
-  name: ara
-spec:
-  destination:
-    namespace: ara
-    server: 'https://kubernetes.default.svc'
-  source:
-    path: apps/ara
-    repoURL: 'https://github.com/thaum-xyz/ankhmorpork.git'
-    targetRevision: HEAD
-  project: default
-  syncPolicy:
-    automated:
-      prune: false
-      selfHeal: false
-"
thaum-xyz,ankhmorpork,458bc81b55fdec1f9893f8dc3f7e9bd46774f497,paulfantom,pawel@krupa.net.pl,2020-07-21T15:06:19Z,paulfantom,pawel@krupa.net.pl,2020-07-21T15:06:19Z,ansible: fix escape character and run more frequent updates,ansible/group_vars/all.yml,False,False,False,False,1,2,3,"---FILE: ansible/group_vars/all.yml---
@@ -3,7 +3,6 @@ locales_present:
   - en_US.UTF-8
   - en_GB.UTF-8
 unattended_automatic_reboot_time: ""02:00""
-unattended_update_days: 1
 
 node_exporter_enabled_collectors:
   - textfile:
@@ -12,7 +11,7 @@ node_exporter_enabled_collectors:
       ignored-fs-types: ""^(sys|proc|auto|overlay)fs$""
       ignored-mount-points: ""^/(sys|proc|dev)($|/)""
   - diskstats:
-      ignored-devices: '^(ram|loop|fd|(h|v|xv)d[a-z]|dm-)\d+$'
+      ignored-devices: '^(ram|loop|fd|(h|v|xv)d[a-z]|dm-)\\\d+$'
   - netdev:
       device-blacklist: ""^(veth.*|br.*)$""
   - systemd"
thaum-xyz,ankhmorpork,6c24e0d6b7a8eacb970678c866fe7319b5bf9bdc,paulfantom,pawel@krupa.net.pl,2020-07-21T15:05:17Z,paulfantom,pawel@krupa.net.pl,2020-07-21T15:05:17Z,apps/nextcloud/backup: fix secret reference,apps/nextcloud/backup/02_cronjobs.yaml,False,False,False,False,2,2,4,"---FILE: apps/nextcloud/backup/02_cronjobs.yaml---
@@ -77,12 +77,12 @@ spec:
               - name: MYSQL_USER
                 valueFrom:
                   secretKeyRef:
-                    name: credentials
+                    name: mysql-creds
                     key: mysql_user
               - name: MYSQL_PASSWORD
                 valueFrom:
                   secretKeyRef:
-                    name: credentials
+                    name: mysql-creds
                     key: mysql_pass
             envFrom:
               - configMapRef:"
thaum-xyz,ankhmorpork,f05b81935ef1002113cfd0862a14c0bc1cb338bf,paulfantom,pawel@krupa.net.pl,2020-07-21T12:34:36Z,paulfantom,pawel@krupa.net.pl,2020-07-21T12:34:36Z,apps/dns/local: fix job label in servicemonitor,apps/dns/local/05_servicemonitor.yaml,False,False,False,False,1,1,2,"---FILE: apps/dns/local/05_servicemonitor.yaml---
@@ -7,7 +7,7 @@ metadata:
   name: coredns
   namespace: dns
 spec:
-  jobLabel: coredns
+  jobLabel: k8s-app
   endpoints:
   - interval: 30s
     port: metrics"
thaum-xyz,ankhmorpork,714c442d08b5942bde6eaf82ff42d3a980c48815,paulfantom,pawel@krupa.net.pl,2020-07-20T12:21:14Z,paulfantom,pawel@krupa.net.pl,2020-07-20T12:21:14Z,base/kube-system/local-path-provisioner: fix storage node name,base/kube-system/local-path-provisioner/config.yaml,False,False,False,False,1,1,2,"---FILE: base/kube-system/local-path-provisioner/config.yaml---
@@ -15,7 +15,7 @@ data:
             ""paths"":[""/var/lib/rancher/k3s/storage""]
           },
           {
-            ""node"":""nas"",
+            ""node"":""storage01"",
             ""paths"":[""/var/lib/rancher/k3s/storage""]
           }
         ]"
thaum-xyz,ankhmorpork,9913c5d7418bd4ea6538542421fbeeca42ee8f32,paulfantom,pawel@krupa.net.pl,2020-07-20T12:02:19Z,paulfantom,pawel@krupa.net.pl,2020-07-20T12:02:19Z,apps/nextcloud: fix proxy issues,apps/nextcloud/nextcloud/05_config.yaml;apps/nextcloud/proxy/03_config.yaml,False,False,False,False,2,6,8,"---FILE: apps/nextcloud/nextcloud/05_config.yaml---
@@ -45,7 +45,7 @@ data:
   MYSQL_HOST: 'mysql.nextcloud.svc'
   # REDIS_HOST: 'redis.nextcloud.svc'
   # REDIS_PORT: '6379'
-  # TRUSTED_PROXIES: ""127.0.0.1 192.168.2.6""
+  TRUSTED_PROXIES: ""127.0.0.1 10.42.0.0/16""
   NC_mysql.utf8mb4: ""true""
   NC_enable_avatars: ""false""
   SMTP_SECURE: ""tls""

---FILE: apps/nextcloud/proxy/03_config.yaml---
@@ -35,11 +35,7 @@ data:
         #tcp_nopush     on;
     
         keepalive_timeout  65;
-    
-        # Set real IP address from secure proxy
-        set_real_ip_from  192.168.2.6;
-        real_ip_header    X-Real-IP;
-    
+       
         #gzip  on;
     
         # Enable metrics reporting"
thaum-xyz,ankhmorpork,b98e5a58479f885271312f001c9c61ec0d62e16b,paulfantom,pawel@krupa.net.pl,2020-07-17T13:28:39Z,paulfantom,pawel@krupa.net.pl,2020-07-17T13:28:39Z,apps/nextcloud/proxy: do not deploy to storage01 as it has issues with internal DNS,apps/nextcloud/proxy/04_deployment.yaml,False,False,False,False,5,5,10,"---FILE: apps/nextcloud/proxy/04_deployment.yaml---
@@ -83,8 +83,8 @@ spec:
           claimName: nextcloud-apps
       #nodeSelector: 
       #  kubernetes.io/arch: ""amd64""
-      tolerations:
-      - key: ""storage.infra""
-        operator: ""Equal""
-        value: ""true""
-        effect: ""NoSchedule""
+      #tolerations:
+      #- key: ""storage.infra""
+      #  operator: ""Equal""
+      #  value: ""true""
+      #  effect: ""NoSchedule"""
thaum-xyz,ankhmorpork,e475b79e4b080d6ca3629a92e4d5186c61fea212,paulfantom,pawel@krupa.net.pl,2020-07-16T15:30:06Z,paulfantom,pawel@krupa.net.pl,2020-07-16T15:32:24Z,"ansible: fixes after cluster reinstallation

* added disabling of IPv6 on default interface
* disabling cloud-manager
* better node labels and taints
* not removing manifests on master node as those are not deployed when
master is started with --disable=X options
* fix copying manifests which need to be applied by ansible",ansible/70_k3s.yml;ansible/group_vars/k3s.yml;ansible/host_vars/storage01.yml;ansible/inventory;ansible/roles/fans/files/fan.py;ansible/roles/system/tasks/main.yml,False,False,False,False,15,25,40,"---FILE: ansible/70_k3s.yml---
@@ -32,19 +32,11 @@
         replace: ""{{ k3s_master_ip }}""
       delegate_to: localhost
 
-    - name: Remove manifests managed externally
-      file:
-        path: ""/var/lib/rancher/k3s/server/manifests/{{ item }}""
-        state: ""absent""
-      with_items:
-        - ""local-storage.yaml""
-        - ""coredns.yaml""
-
     - name: Import manifests bound to infrastructure
       template:
         src: ""{{ item }}""
         dest: ""/var/lib/rancher/k3s/server/manifests/{{ item | basename }}""
-      with_fileglob: ""manifests/*.yaml""
+      with_fileglob: ""templates/manifests/*.yaml""
 
 - hosts: k3s-node
   become: true

---FILE: ansible/group_vars/k3s.yml---
@@ -1,9 +1,9 @@
 ---
 k3s_version: v1.18.4+k3s1
 k3s_master_ip: ""{{ hostvars[groups['k3s-master'][0]]['ansible_default_ipv4']['address'] }}""
-k3s_extra_server_args: ""--disable coredns --disable servicelb --disable traefik --node-taint node-role.kubernetes.io/master=true:NoSchedule ""
+k3s_extra_server_args: ""--disable coredns --disable servicelb --disable traefik --disable-cloud-controller --node-taint node-role.kubernetes.io/master=true:NoSchedule ""
 k3s_token: ""{{ hostvars[groups['k3s-master'][0]]['token'] }}""
 
-k3s_extra_agent_args: ""--kubelet-arg system-reserved=cpu=100m,memory=200Mi --kubelet-arg kube-reserved=cpu=100m,memory=200Mi --node-label tier/network={{ network | default('slow') }}""
+k3s_extra_agent_args: ""--kubelet-arg system-reserved=cpu=100m,memory=200Mi --kubelet-arg kube-reserved=cpu=100m,memory=200Mi --node-label network.infra/{{ network | default('slow') }}=true""
 
 system_earlyoom_params: ""-r 60 -m 4""

---FILE: ansible/host_vars/storage01.yml---
@@ -1,13 +1,11 @@
 ---
-# k3s_extra_agent_args: ""--node-label node-role.kubernetes.io/storage=true --node-taint node-role.kubernetes.io/storage=true:NoSchedule""
 node_labels:
-  - ""storage.tier/local=true""
-  - ""storage.tier/raid=true""
-  - ""storage.tier/fast=true""
-  - ""network.tier/fast=true""
+  - ""storage.infra/local=true""
+  - ""storage.infra/raid=true""
+  - ""storage.infra/fast=true""
+  - ""network.infra/fast=true""
 node_taints:
-  - ""tier/storage=true:NoSchedule""
-  - ""node-role.kubernetes.io/storage=true:NoSchedule""
+  - ""storage.infra=true:NoSchedule""
 
 samba_domain_master: true
 samba_local_master: true

---FILE: ansible/inventory---
@@ -5,17 +5,17 @@ storage01 ansible_user=paulfantom ansible_host=192.168.2.3  network=fast
 master01  ansible_user=ubuntu     ansible_host=192.168.2.11
 node01    ansible_user=ubuntu     ansible_host=192.168.2.12
 node02    ansible_user=ubuntu     ansible_host=192.168.2.13 network=fast
-node03    ansible_user=ubuntu     ansible_host=192.168.2.14 network=fast
+node03    ansible_user=ubuntu     ansible_host=192.168.2.14
 node04    ansible_user=ubuntu     ansible_host=192.168.2.15
 node05    ansible_user=ubuntu     ansible_host=192.168.2.16 network=fast
-node06    ansible_user=ubuntu     ansible_host=192.168.2.17
+#node06    ansible_user=ubuntu     ansible_host=192.168.2.17
 
 [fancontroler]
-node02
+master01
 
 [raspberry]
 master01
-node0[2:6]
+node0[2:5]
 
 [storage]
 storage01
@@ -25,7 +25,7 @@ master01
 
 [k3s-node]
 storage01
-node0[1:6]
+node0[1:5]
 
 [k3s:children]
 k3s-master

---FILE: ansible/roles/fans/files/fan.py---
@@ -65,7 +65,7 @@ def fell(n):
 
     # This should be handled by getting metrics from prometheus and using highest one
     # add 12 more degrees (value based on historical trends)
-    tempC += 12
+    #tempC += 12
 
     # Tweak here minimal dc (PWM Duty Cycle), temp threshold and ratio
     dc = MIN_DUTY + max(0, int((tempC - 38) * ratio))

---FILE: ansible/roles/system/tasks/main.yml---
@@ -35,7 +35,7 @@
   with_items:
     - net.ipv6.conf.all.disable_ipv6
     - net.ipv6.conf.default.disable_ipv6
-    - net.ipv6.conf.eth0.disable_ipv6
+    - ""net.ipv6.conf.{{ ansible_default_ipv4.interface }}.disable_ipv6""
 
 - import_tasks: earlyoom.yml
 "
thaum-xyz,ankhmorpork,f81179b34ae8931d09d0bea19a1bfc461884f538,paulfantom,pawel@krupa.net.pl,2020-07-12T17:05:29Z,paulfantom,pawel@krupa.net.pl,2020-07-13T04:37:02Z,ansible: fixes after cluster recreation,.gitignore;ansible/00_site.yml;ansible/01_system.yml;ansible/10_storage.yml;ansible/70_k3s.yml;ansible/group_vars/all.yml;ansible/group_vars/k3s.yml;ansible/group_vars/raspberry.yml;ansible/host_vars/master01.yml;ansible/host_vars/storage01.yml;ansible/inventory;ansible/roles/system/handlers/main.yml;ansible/roles/system/tasks/dns.yml;ansible/roles/system/tasks/main.yml;ansible/roles/system/tasks/storage.yml;ansible/roles/system/templates/resolved.conf.j2;ansible/templates/manifests/kubeControllerManagerPrometheusDiscoveryService.yaml.j2;ansible/templates/manifests/kubeSchedulerPrometheusDiscoveryService.yaml.j2,True,False,True,False,91,204,295,"---FILE: .gitignore---
@@ -7,6 +7,7 @@ roles/*
 !roles/fans/*
 !roles/fans
 *.retry
+ansible/kubeconfig
 .kube
 bin/
 templates/

---FILE: ansible/00_site.yml---
@@ -1,8 +1,6 @@
 ---
 - import_playbook: 01_system.yml
 
-- import_playbook: 02_autodeploy.yml
-
 - import_playbook: 10_storage.yml
 
 - import_playbook: 70_k3s.yml

---FILE: ansible/01_system.yml---
@@ -14,17 +14,6 @@
   roles:
   - system
   tasks:
-  - name: Reboot PC once a week
-    cron:
-      cron_file: /etc/crontab
-      name: reboot
-      user: root
-      day: ""4""
-      hour: ""3""
-      minute: ""43""
-      job: reboot
-      state: ""{{ 'present' if reboot_enabled else 'absent' }}""
-    when: reboot_enabled is defined
   - name: Install dependencies
     package:
       name: moreutils
@@ -43,6 +32,12 @@
       name: ""{{ ansible_pkg_mgr }}-metrics""
       minute: ""13""
       job: ""/usr/local/bin/{{ pkg_mgr }}.sh | sponge /var/lib/node_exporter/{{ pkg_mgr }}.prom""
+  - name: Ensure snapd is removed
+    apt:
+      name: snapd
+      state: absent
+      purge: true
+    when: ansible_os_family == ""Debian""
 
 - hosts: raspberry
   become: true

---FILE: ansible/10_storage.yml---
@@ -7,9 +7,8 @@
   tasks:
     - name: Install dependencies
       package:
-        name:
-          - moreutils
-        state: installed
+        name: moreutils
+        state: present
     - name: Copy smartmon textfile collector script
       copy:
         src: ""scripts/smartmon.sh""

---FILE: ansible/70_k3s.yml---
@@ -18,54 +18,63 @@
   roles:
     - k3s-master
   tasks:
-    - name: Create .kube directory on deployer host
-      file:
-        path: ""/root/.kube""
-        state: directory
-      delegate_to: localhost
-      run_once: true
-      when: ansible_user == ""root""
-
     - name: Get kube config to deployer host
       fetch:
-        src: ""/home/pi/.kube/config""
-        dest: ""/root/.kube/config""
+        src: ""/etc/rancher/k3s/k3s.yaml""
+        dest: ""{{ playbook_dir }}/kubeconfig""
         flat: true
-      when: ansible_user == ""root""
+
+    - name: Replace localhost with master IP
+      become: false
+      replace:
+        path: ""{{ playbook_dir }}/kubeconfig""
+        regexp: ""127.0.0.1""
+        replace: ""{{ k3s_master_ip }}""
+      delegate_to: localhost
 
     - name: Remove manifests managed externally
       file:
         path: ""/var/lib/rancher/k3s/server/manifests/{{ item }}""
         state: ""absent""
       with_items:
         - ""local-storage.yaml""
-        # - ""coredns.yaml""
+        - ""coredns.yaml""
 
     - name: Import manifests bound to infrastructure
-      templates:
-        src: ""{{ item | basename }}.j2""
+      template:
+        src: ""{{ item }}""
         dest: ""/var/lib/rancher/k3s/server/manifests/{{ item | basename }}""
-      with_items:
-        - manifests/kubeControllerManagerPrometheusDiscoveryService.yaml
-        - manifests/kubeSchedulerPrometheusDiscoveryService.yaml
+      with_fileglob: ""manifests/*.yaml""
 
 - hosts: k3s-node
   become: true
   serial: 2
   roles:
     - k3s-node
   pre_tasks:
-  - name: Install packages needed for PV providers
-    package:
-      name: ""{{ item }}""
-      state: present
-    with_items:
-      - ""{{ 'nfs-common' if (ansible_os_family | lower == 'debian') else 'nfs-utils' }}""
-  - name: Check if systemd-resolvd is used
-    stat:
-      path: /run/systemd/resolve/resolv.conf
-    register: resolv
-  - name: Use resolv.conf provided by systemd-resolved
-    set_fact:
-      k3s_extra_agent_args: ""{{ k3s_extra_agent_args }} --resolv-conf /run/systemd/resolve/resolv.conf""
-    when: resolv.stat.exists
+    - name: Install packages needed by PV providers
+      package:
+        name: ""{{ item }}""
+        state: present
+      with_items:
+        - ""{{ 'nfs-common' if (ansible_os_family | lower == 'debian') else 'nfs-utils' }}""
+    - name: Add node labels
+      set_fact:
+        k3s_extra_agent_args: ""{{ k3s_extra_agent_args }} --node-label {{ node_labels | join(' --node-label ') }}""
+      when:
+        - node_labels is defined
+        - node_labels != """"
+    - name: Add node taints
+      set_fact:
+        k3s_extra_agent_args: ""{{ k3s_extra_agent_args }} --node-taint {{ node_taints | join(' --node-taint ') }}""
+      when:
+        - node_taints is defined
+        - node_taints != """"
+    - name: Check if systemd-resolvd is used
+      stat:
+        path: /run/systemd/resolve/resolv.conf
+      register: resolv
+    - name: Use resolv.conf provided by systemd-resolved
+      set_fact:
+        k3s_extra_agent_args: ""{{ k3s_extra_agent_args }} --resolv-conf /run/systemd/resolve/resolv.conf""
+      when: resolv.stat.exists

---FILE: ansible/group_vars/all.yml---
@@ -5,7 +5,6 @@ locales_present:
 unattended_automatic_reboot_time: ""02:00""
 unattended_update_days: 1
 
-node_exporter_version: 1.0.0-rc.1
 node_exporter_enabled_collectors:
   - textfile:
       directory: ""/var/lib/node_exporter""

---FILE: ansible/group_vars/k3s.yml---
@@ -1,13 +1,9 @@
 ---
-rpi_swap_size: 0
-
-k3s_version: v1.18.3+k3s1
+k3s_version: v1.18.4+k3s1
 k3s_master_ip: ""{{ hostvars[groups['k3s-master'][0]]['ansible_default_ipv4']['address'] }}""
-k3s_extra_server_args: ""--no-deploy servicelb --no-deploy traefik --node-taint node-role.kubernetes.io/master=true:NoSchedule""
-# k3s_extra_server_args: ""--no-deploy servicelb --no-deploy traefik --no-deploy metrics-server""
+k3s_extra_server_args: ""--disable coredns --disable servicelb --disable traefik --node-taint node-role.kubernetes.io/master=true:NoSchedule ""
 k3s_token: ""{{ hostvars[groups['k3s-master'][0]]['token'] }}""
 
-k3s_extra_agent_args: ""--kubelet-arg system-reserved=cpu=100m,memory=200Mi --kubelet-arg kube-reserved=cpu=100m,memory=200Mi --node-label node.kubernetes.io/network-type={{ network | default('slow') }}""
-# k3s_extra_agent_args: ""--kubelet-arg system-reserved=cpu=100m,memory=200Mi --kubelet-arg kube-reserved=cpu=100m,memory=200Mi""
+k3s_extra_agent_args: ""--kubelet-arg system-reserved=cpu=100m,memory=200Mi --kubelet-arg kube-reserved=cpu=100m,memory=200Mi --node-label tier/network={{ network | default('slow') }}""
 
 system_earlyoom_params: ""-r 60 -m 4""

---FILE: ansible/group_vars/raspberry.yml---
@@ -1,4 +1,4 @@
 ---
-reboot_enabled: false
-
 rpi_bt: true
+rpi_swap_size: 0
+

---FILE: ansible/host_vars/master01.yml---
@@ -2,6 +2,6 @@
 system_mountpoints:
   - description: k3s storage data
     before: k3s.service
-    device: ""/dev/disk/by-uuid/6f7f2bba-5f96-4710-a9e7-cd40d229a512""
+    device: ""/dev/disk/by-uuid/61d07b69-3378-4a9f-9944-8fa0fc2c4eae""
     mountpoint: ""/var/lib/rancher""
     type: ""ext4""

---FILE: ansible/host_vars/storage01.yml---
@@ -1,5 +1,13 @@
 ---
 # k3s_extra_agent_args: ""--node-label node-role.kubernetes.io/storage=true --node-taint node-role.kubernetes.io/storage=true:NoSchedule""
+node_labels:
+  - ""storage.tier/local=true""
+  - ""storage.tier/raid=true""
+  - ""storage.tier/fast=true""
+  - ""network.tier/fast=true""
+node_taints:
+  - ""tier/storage=true:NoSchedule""
+  - ""node-role.kubernetes.io/storage=true:NoSchedule""
 
 samba_domain_master: true
 samba_local_master: true
@@ -22,33 +30,28 @@ samba_shares:
 
 system_mountpoints:
   - description: main streaming storage data
-    before: docker.service
+    before: k3s-node.service
     device: ""/dev/vg_storage/netflix""
     mountpoint: ""/srv/netflix""
     type: ""xfs""
   - description: main cloud service data
-    before: docker.service
+    before: k3s-node.service
     device: ""/dev/vg_storage/nextcloud""
     mountpoint: ""/srv/nextcloud""
     type: ""xfs""
 
   - description: torrent hot cache mount
-    before: docker.service
+    before: k3s-node.service
     device: ""/dev/vg_fast/torrents""
     mountpoint: ""/srv/torrents""
     type: ""xfs""
-  - description: docker data
-    before: docker.service
-    device: ""/dev/vg_fast/docker""
-    mountpoint: ""/var/lib/docker""
-    type: ""ext4""
   - description: kubernetes NFS storage
     before: nfs-server.service k3s-node.service
     device: ""/dev/vg_fast/kube_nfs""
     mountpoint: ""/srv/kubernetes/nfs""
     type: ""ext4""
   - description: kubernetes local storage
-    before: docker.service k3s-node.service
+    before: k3s-node.service
     device: ""/dev/vg_fast/kube_local""
     mountpoint: ""/var/lib/rancher/k3s/storage""
     type: ""ext4""

---FILE: ansible/inventory---
@@ -1,35 +1,31 @@
 # By default hosts are labeled with `network=slow` label
 # Hosts with label `network=fast` are used for metallb loadbalancer
 
-nas      ansible_user=paulfantom ansible_host=192.168.2.3  network=fast
-master01 ansible_user=pi         ansible_host=192.168.2.11 ansible_connection=local
-node01   ansible_user=ubuntu     ansible_host=192.168.2.12 network=fast
-node02   ansible_user=paulfantom ansible_host=192.168.2.13
-node03   ansible_user=ubuntu     ansible_host=192.168.2.14 network=fast
-node04   ansible_user=ubuntu     ansible_host=192.168.2.15
-#node05   ansible_user=ubuntu     ansible_host=192.168.2.16 network=fast
-node06   ansible_user=ubuntu     ansible_host=192.168.2.17 network=fast
-node07   ansible_user=ubuntu     ansible_host=192.168.2.18
+storage01 ansible_user=paulfantom ansible_host=192.168.2.3  network=fast
+master01  ansible_user=ubuntu     ansible_host=192.168.2.11
+node01    ansible_user=ubuntu     ansible_host=192.168.2.12
+node02    ansible_user=ubuntu     ansible_host=192.168.2.13 network=fast
+node03    ansible_user=ubuntu     ansible_host=192.168.2.14 network=fast
+node04    ansible_user=ubuntu     ansible_host=192.168.2.15
+node05    ansible_user=ubuntu     ansible_host=192.168.2.16 network=fast
+node06    ansible_user=ubuntu     ansible_host=192.168.2.17
 
 [fancontroler]
-node01
+node02
 
 [raspberry]
 master01
-node01
-node0[3:4]
-node0[6:7]
+node0[2:6]
 
 [storage]
-nas
+storage01
 
 [k3s-master]
 master01
 
 [k3s-node]
-nas
-node0[1:4]
-node0[6:7]
+storage01
+node0[1:6]
 
 [k3s:children]
 k3s-master

---FILE: ansible/roles/system/handlers/main.yml---
@@ -14,3 +14,11 @@
   systemd:
     name: dhcpcd
     state: restarted
+
+- name: enable mountpoints
+  systemd:
+    name: ""{{ item.mountpoint[1:] | replace('/','-') }}.mount""
+    state: started
+    enabled: true
+    daemon_reload: true
+  with_items: ""{{ system_mountpoints }}""

---FILE: ansible/roles/system/tasks/dns.yml---
@@ -1,31 +0,0 @@
----
-- name: Get services runnning on host
-  service_facts:
-
-- block:
-  - name: Configure static DNS [dhcpcd]
-    lineinfile:
-      path: /etc/dhcpcd.conf
-      regexp: '^static domain_name_servers='
-      line: ""static domain_name_servers={{ system_dns_primary }} {{ system_dns_secondary }}""
-    notify: restart dhcpcd
-
-  - name: Configure DNS search domain [dhcpcd]
-    lineinfile:
-      path: /etc/dhcpcd.conf
-      regexp: '^static domain_search='
-      line: ""static domain_search={{ system_dns_domain }}""
-    when: system_dns_domain | length > 0
-    notify: restart dhcpcd
-  when:
-    - ansible_facts.services['dhcpcd.service'] is defined
-    - ansible_facts.services['dhcpcd.service']['state'] == ""running""
-
-- name: Configure static DNS [systemd-resolved]
-  template:
-    src: resolved.conf.j2
-    dest: /etc/systemd/resolved.conf
-  notify: restart systemd-resolved
-  when:
-    - ansible_facts.services['systemd-resolved.service'] is defined
-    - ansible_facts.services['systemd-resolved.service']['state'] == ""running""

---FILE: ansible/roles/system/tasks/main.yml---
@@ -28,16 +28,14 @@
 
 - name: disable IPv6
   sysctl:
-    sysctl_file: ""/etc/sysctl.d/ipv6.conf""
+    sysctl_file: ""/etc/sysctl.d/01-ipv6.conf""
     name: ""{{ item }}""
     value: '1'
     sysctl_set: true
   with_items:
     - net.ipv6.conf.all.disable_ipv6
     - net.ipv6.conf.default.disable_ipv6
-
-- import_tasks: dns.yml
-  when: system_dns_primary | length > 0
+    - net.ipv6.conf.eth0.disable_ipv6
 
 - import_tasks: earlyoom.yml
 

---FILE: ansible/roles/system/tasks/storage.yml---
@@ -4,3 +4,4 @@
     src: ""systemd-mount.j2""
     dest: ""/etc/systemd/system/{{ item.mountpoint[1:] | replace('/','-') }}.mount""
   with_items: ""{{ system_mountpoints }}""
+  notify: enable mountpoints

---FILE: ansible/roles/system/templates/resolved.conf.j2---
@@ -1,26 +0,0 @@
-#  This file is part of systemd.
-#
-#  systemd is free software; you can redistribute it and/or modify it
-#  under the terms of the GNU Lesser General Public License as published by
-#  the Free Software Foundation; either version 2.1 of the License, or
-#  (at your option) any later version.
-#
-# Entries in this file show the compile time defaults.
-# You can change settings by editing this file.
-# Defaults can be restored by simply deleting this file.
-#
-# See resolved.conf(5) for details
-
-{{ ansible_managed | comment }}
-
-[Resolve]
-DNS={{ system_dns_primary }}
-FallbackDNS={{ system_dns_secondary }}
-Domains={{ system_dns_domain }}
-#LLMNR=no
-#MulticastDNS=no
-#DNSSEC=no
-#DNSOverTLS=no
-#Cache=yes
-#DNSStubListener=yes
-#ReadEtcHosts=yes

---FILE: ansible/templates/manifests/kubeControllerManagerPrometheusDiscoveryService.yaml.j2---
@@ -1,28 +0,0 @@
----
-apiVersion: v1
-kind: Endpoints
-metadata:
-  labels:
-    k8s-app: kube-controller-manager
-  name: kube-controller-manager-prometheus-discovery
-  namespace: kube-system
-subsets:
-  - addresses:
-      - ip: {{ k3s_master_ip }}
-    ports:
-      - name: http-metrics
-        port: 10252
----
-apiVersion: v1
-kind: Service
-metadata:
-  labels:
-    k8s-app: kube-controller-manager
-  name: kube-controller-manager-prometheus-discovery
-  namespace: kube-system
-spec:
-  clusterIP: None
-  ports:
-  - name: http-metrics
-    port: 10252
-    targetPort: 10252

---FILE: ansible/templates/manifests/kubeSchedulerPrometheusDiscoveryService.yaml.j2---
@@ -1,31 +0,0 @@
----
-apiVersion: v1
-kind: Endpoints
-metadata:
-  labels:
-    k8s-app: kube-scheduler
-  name: kube-scheduler-prometheus-discovery
-  namespace: kube-system
-subsets:
-  - addresses:
-      - ip: {{ k3s_master_ip }}
-    ports:
-      - name: http-metrics
-        port: 10251
-        
----
-apiVersion: v1
-kind: Service
-metadata:
-  labels:
-    k8s-app: kube-scheduler
-  name: kube-scheduler-prometheus-discovery
-  namespace: kube-system
-spec:
-  clusterIP: None
-  ports:
-  - name: http-metrics
-    port: 10251
-    targetPort: 10251
-#  selector:
-#    component: kube-scheduler"
thaum-xyz,ankhmorpork,8f932da7970ca56a181c79dedfc9f3ae6eca4b5c,paulfantom,pawel@krupa.net.pl,2020-07-11T09:40:33Z,paulfantom,pawel@krupa.net.pl,2020-07-11T09:40:33Z,apps/monitoring/alertmanager: fix silence link; add inhibitions,apps/monitoring/alertmanager/config.yaml,False,False,False,False,15,6,21,"---FILE: apps/monitoring/alertmanager/config.yaml---
@@ -39,7 +39,7 @@ spec:
                 :question:
               {{- end -}}
               {{ .CommonLabels.alertname }}
-            text: |
+            text: >-
               {{ range .Alerts }}
                 {{- if .Annotations.message }}
                   {{ .Annotations.message }}
@@ -66,14 +66,14 @@ spec:
               url: '{{ (index .Alerts 0).Annotations.dashboard }}'
             - type: button
               text: 'Silence :no_bell:'
-              url: |
+              url: >-
                 {{ .ExternalURL }}/#/silences/new?filter=%7B
                 {{- range .CommonLabels.SortedPairs -}}
-                  {{- if ne .Name ""alertname"" -}}
-                      {{- .Name }}%3D""{{- .Value -}}""%2C%20
-                  {{- end -}}
+                    {{- if ne .Name ""alertname"" -}}
+                        {{- .Name }}%3D%22{{- reReplaceAll "" +"" ""%20"" .Value -}}%22%2C%20
+                    {{- end -}}
                 {{- end -}}
-                alertname%3D""{{ .CommonLabels.alertname }}""%7D
+                alertname%3D%22{{ reReplaceAll "" +"" ""%20"" .CommonLabels.alertname }}%22%7D
         - name: 'opsgenie'
           opsgenie_configs:
             - message: ""{{ .GroupLabels.alertname }}""
@@ -137,6 +137,15 @@ spec:
             target_match_re:
               alertname: ""TargetDown""
               instance: 'lancre.thaum.xyz:443|zmc.krupa.net.pl:443'
+          - source_match:
+              alertname: 'KubeNodeUnreachable'
+            target_match_re:
+              alertname: ""TargetDown""
+              job: ""kubelet|node-exporter""
+          - source_match:
+              alertname: 'KubeNodeUnreachable'
+            target_match:
+              alertname: ""KubeNodeNotReady""
   vars:
     - name: OPSGENIE_API_KEY
       secretValue:"
thaum-xyz,ankhmorpork,a06de6456e54a114923d89c59755a0d6b8254275,paulfantom,pawel@krupa.net.pl,2020-07-10T18:49:45Z,paulfantom,pawel@krupa.net.pl,2020-07-10T18:49:45Z,apps/monitoring: fix external URLs,apps/monitoring/alertmanager/alertmanager.yaml;apps/monitoring/prometheus/05_prometheus.yaml,False,False,False,False,2,0,2,"---FILE: apps/monitoring/alertmanager/alertmanager.yaml---
@@ -20,6 +20,7 @@ spec:
           - monitoring
           topologyKey: kubernetes.io/hostname
         weight: 100
+  externalUrl: https://alertmanager.ankhmorpork.thaum.xyz
   image: quay.io/prometheus/alertmanager:v0.21.0
   nodeSelector:
     kubernetes.io/os: linux

---FILE: apps/monitoring/prometheus/05_prometheus.yaml---
@@ -28,6 +28,7 @@ spec:
     - name: alertmanager-main
       namespace: monitoring
       port: web
+  externalUrl: https://prometheus.ankhmorpork.thaum.xyz
   image: quay.io/prometheus/prometheus:v2.19.2
   nodeSelector:
     kubernetes.io/os: linux"
thaum-xyz,ankhmorpork,fe0f38a604fc3c0bf178aa9c72a9078128284b12,paulfantom,pawel@krupa.net.pl,2020-07-10T12:50:53Z,paulfantom,pawel@krupa.net.pl,2020-07-10T12:50:53Z,apps/homeassistant: fix security leak,apps/homeassistant/08_servicemonitor.yaml;apps/homeassistant/cred.yaml,False,False,False,False,1,9,10,"---FILE: apps/homeassistant/08_servicemonitor.yaml---
@@ -24,7 +24,7 @@ metadata:
   namespace: homeassistant
 spec:
   encryptedData:
-    token: AgCSEYThPE4HXu9j1dA+9PJSIxFcnnYnHO5LTdHcHkxUhOzXQzYZZajQ3oQ+o5O5V21f5ofn5YKFps6XWFN65boRURtgHgRa+EXdj0o9oILXyLvvIBBgrBb1Io34pDuyil0/5YD8h69IAKnc8FiIrFRX8Uu+Fq+3VV1gfeFq3p0Xk0ECuU8DbP9TEivjOvJPqgcwG5IZ6pUw+ki0+rVOGqHXUaL6YiWKLY7G0ZkzUj0LnvcUjhiiMGo5y0TKBhbgmlsBpEaLwP7QLQwRNgCd13w4JFV/zkpPZpUXXvBns+tCbt8PNbLyVC4rximF/ieIogqH5Kstpkv8fVn13rLOWz33m/WBgpdEKx0T/6cvFv1Ho9ElME06kbnJm8sBUni/GalSbqQCZ4lVQvbgD87CSnzeBFhmvxXDJ6XLA7oo71SXjSELdExIfTPeiBk+sxtzHnGxbB04pAQTAq4MOkKdV2D0fGv+rewBeVMhvvKgC4HFdKF1SYVDPydc7m88YLjp8YSi2dkx3ds8eQTMZ04q2bZHbNAJhEOsmywaQkFsfqrGT/8VvXe57l0ufO+biCXKJ9zO1EcG8ykcjpZ08R7NbhN/HL5ODIGwjw3nqMRK7yHdrb3oLNJAq2sjuelLtS6kpQ6r25PCsI8WSKMGNkBBRLP9bNcN/zz77dqrmXR1c35Kl2W0A6b2tv5XGa3mhF2SC+TNXlXehC+c1pnIRTtBMp8Yl40nsnJQTxEQIDX3kLId/AC7fkIhdu+SDIlyQjjtoacBPwCrjLWR/DxuD703dHlpn8TIg6pTOFtGh8cZf3shcRrKJm+bg25ZdBYdW3LVSN2/Fz9klD28dQ4kMM1Pg6hSuUBMvZ8gxSPJ2B0+MJu+es2cePSeDSLzuKDbH5ZURtAueeW910r3wE++n47WftF3BO0FlqMaQNmp3EjnIRC4t5le0HCmiF0=
+    token: AgCWwBiSdXfwjJbk9gm9sjvQtne/4DqzmeTnGCw6YVyjUnF6MUkMT+ZcYp5XZOR1Aym7UtVvFHj2jLX6Io6L5hznzUk6xw4FensCR+itos6eA9j2HmNKHRQUbhoMONBYOvBrIEMV2Zx0Cgw3EtNl3FZNf6xKjp2LmsaAcwde6EH4+YVKJc5OFlPU8xwTlNPp3W1Z76Ied0krcv0husymW9x2OEk4gpXUjNGZcx2lS2iRFej6WFgKIbTMmrxNob2HPStiAHUkQ0iAmAVLL1Xpwd7y4hZY0L/tA/zhuqgEVb+I2TgriCDvIc9GhnAJ7zysT6AGiN8zi+UVwTGMhcIqProrJrc3Xwixf6NKoyxR86E41q4MPtNggLaNRWdYiufKfrfTpKRnhubRZEdLugQeD6iEY6AzCPiEtE2sssAcvI39+H7Ia/S4TQIBYUetE4iCVYU4yLo2gfn8ze3R0h2JjFA4DdQQweCOW9R84NzpeAc9lqUr4J3k4So8pr6hS5pGFxQkvgOVGYBEjkw8Wny0DbwUGFIawN7baB/3NXoO5bYiAjrzohBNhJzIGD4dN5JEe7DaT0xc8cDL8Btl//5Swcwrhvm0GUPPGCMSdkk3EfIANpCqULrWhBoSkRSMt2Et3VFq0zRkBOb5LyjDYCA5RmvDJsAULavpOplHARTv6uhGIwp5DBSwhG/hs+SKu15a7WYoy353LfWb6/ZeSam9VBOl5yoX2lUZJ0524PCAjgoUq/PPd5dx9fTHEJ+k3IQf3Tg0jOAJjpuylmKsy0L3BLRt8JreU0rOml+2pgXQKtaoO23PTBhkywmkaDhPR8cUk9oSufpTYMpwFeXgb6BvEdONXal0PDnMKPGsEataCdgzXYw7yWuQcXx7o/ncrGPkIflKBptmNZacBXjJmjM3ZfBLF89DhapY7eJ74hxglu9jS5Jq81a6Yws=
   template:
     metadata:
       creationTimestamp: null

---FILE: apps/homeassistant/cred.yaml---
@@ -1,8 +0,0 @@
-apiVersion: v1
-kind: Secret
-metadata:
-  name: credentials
-  namespace: homeassistant
-type: Opaque
-stringData:
-  token: eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiIwN2UxYzQ4NGQ0MDM0NTE3OGQ1MDZjOTcwZTEzMjg3OSIsImlhdCI6MTU5MTEwNzA3OSwiZXhwIjoxOTA2NDY3MDc5fQ.tJcCKoUbvl4Pd5xMGeCYByBZ9x_v6S88f9oaK9OXz_o"
thaum-xyz,ankhmorpork,74abe017b6928abc8402172e9eec91c00c288756,paulfantom,pawel@krupa.net.pl,2020-07-08T08:44:53Z,paulfantom,pawel@krupa.net.pl,2020-07-08T08:45:03Z,"apps/monitoring/grafana: bound PVC to previous PV

Needs to be fixed by moving to STS",apps/monitoring/grafana/02_pvc.yaml,False,False,False,False,1,0,1,"---FILE: apps/monitoring/grafana/02_pvc.yaml---
@@ -7,6 +7,7 @@ metadata:
   annotations:
     volume.beta.kubernetes.io/storage-class: ""nfs-client""
 spec:
+  volumeName: pvc-268ae051-7081-4d91-a2eb-8a0b4f3153c5
   accessModes:
     - ReadWriteMany
   resources:"
thaum-xyz,ankhmorpork,8506529d6779e859e35eeeb21036998b734b5b39,paulfantom,pawel@krupa.net.pl,2020-07-06T21:05:07Z,paulfantom,pawel@krupa.net.pl,2020-07-06T21:05:07Z,apps/monitoring/promehteus/rules: fix apiserver selector,apps/monitoring/prometheus/rules/kubernetes.yaml,False,False,False,False,108,108,216,"---FILE: apps/monitoring/prometheus/rules/kubernetes.yaml---
@@ -14,321 +14,321 @@ spec:
         (
           (
             # too slow
-            sum(rate(apiserver_request_duration_seconds_count{job=""kube-apiserver"",verb=~""LIST|GET""}[1d]))
+            sum(rate(apiserver_request_duration_seconds_count{job=""apiserver"",verb=~""LIST|GET""}[1d]))
             -
             (
               (
-                sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=~""resource|"",le=""0.1""}[1d]))
+                sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=~""resource|"",le=""0.1""}[1d]))
                 or
                 vector(0)
               )
               +
-              sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=""namespace"",le=""0.5""}[1d]))
+              sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=""namespace"",le=""0.5""}[1d]))
               +
-              sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=""cluster"",le=""5""}[1d]))
+              sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=""cluster"",le=""5""}[1d]))
             )
           )
           +
           # errors
-          sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""LIST|GET"",code=~""5..""}[1d]))
+          sum(rate(apiserver_request_total{job=""apiserver"",verb=~""LIST|GET"",code=~""5..""}[1d]))
         )
         /
-        sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""LIST|GET""}[1d]))
+        sum(rate(apiserver_request_total{job=""apiserver"",verb=~""LIST|GET""}[1d]))
       labels:
         verb: read
       record: apiserver_request:burnrate1d
     - expr: |
         (
           (
             # too slow
-            sum(rate(apiserver_request_duration_seconds_count{job=""kube-apiserver"",verb=~""LIST|GET""}[1h]))
+            sum(rate(apiserver_request_duration_seconds_count{job=""apiserver"",verb=~""LIST|GET""}[1h]))
             -
             (
               (
-                sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=~""resource|"",le=""0.1""}[1h]))
+                sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=~""resource|"",le=""0.1""}[1h]))
                 or
                 vector(0)
               )
               +
-              sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=""namespace"",le=""0.5""}[1h]))
+              sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=""namespace"",le=""0.5""}[1h]))
               +
-              sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=""cluster"",le=""5""}[1h]))
+              sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=""cluster"",le=""5""}[1h]))
             )
           )
           +
           # errors
-          sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""LIST|GET"",code=~""5..""}[1h]))
+          sum(rate(apiserver_request_total{job=""apiserver"",verb=~""LIST|GET"",code=~""5..""}[1h]))
         )
         /
-        sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""LIST|GET""}[1h]))
+        sum(rate(apiserver_request_total{job=""apiserver"",verb=~""LIST|GET""}[1h]))
       labels:
         verb: read
       record: apiserver_request:burnrate1h
     - expr: |
         (
           (
             # too slow
-            sum(rate(apiserver_request_duration_seconds_count{job=""kube-apiserver"",verb=~""LIST|GET""}[2h]))
+            sum(rate(apiserver_request_duration_seconds_count{job=""apiserver"",verb=~""LIST|GET""}[2h]))
             -
             (
               (
-                sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=~""resource|"",le=""0.1""}[2h]))
+                sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=~""resource|"",le=""0.1""}[2h]))
                 or
                 vector(0)
               )
               +
-              sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=""namespace"",le=""0.5""}[2h]))
+              sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=""namespace"",le=""0.5""}[2h]))
               +
-              sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=""cluster"",le=""5""}[2h]))
+              sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=""cluster"",le=""5""}[2h]))
             )
           )
           +
           # errors
-          sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""LIST|GET"",code=~""5..""}[2h]))
+          sum(rate(apiserver_request_total{job=""apiserver"",verb=~""LIST|GET"",code=~""5..""}[2h]))
         )
         /
-        sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""LIST|GET""}[2h]))
+        sum(rate(apiserver_request_total{job=""apiserver"",verb=~""LIST|GET""}[2h]))
       labels:
         verb: read
       record: apiserver_request:burnrate2h
     - expr: |
         (
           (
             # too slow
-            sum(rate(apiserver_request_duration_seconds_count{job=""kube-apiserver"",verb=~""LIST|GET""}[30m]))
+            sum(rate(apiserver_request_duration_seconds_count{job=""apiserver"",verb=~""LIST|GET""}[30m]))
             -
             (
               (
-                sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=~""resource|"",le=""0.1""}[30m]))
+                sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=~""resource|"",le=""0.1""}[30m]))
                 or
                 vector(0)
               )
               +
-              sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=""namespace"",le=""0.5""}[30m]))
+              sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=""namespace"",le=""0.5""}[30m]))
               +
-              sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=""cluster"",le=""5""}[30m]))
+              sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=""cluster"",le=""5""}[30m]))
             )
           )
           +
           # errors
-          sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""LIST|GET"",code=~""5..""}[30m]))
+          sum(rate(apiserver_request_total{job=""apiserver"",verb=~""LIST|GET"",code=~""5..""}[30m]))
         )
         /
-        sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""LIST|GET""}[30m]))
+        sum(rate(apiserver_request_total{job=""apiserver"",verb=~""LIST|GET""}[30m]))
       labels:
         verb: read
       record: apiserver_request:burnrate30m
     - expr: |
         (
           (
             # too slow
-            sum(rate(apiserver_request_duration_seconds_count{job=""kube-apiserver"",verb=~""LIST|GET""}[3d]))
+            sum(rate(apiserver_request_duration_seconds_count{job=""apiserver"",verb=~""LIST|GET""}[3d]))
             -
             (
               (
-                sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=~""resource|"",le=""0.1""}[3d]))
+                sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=~""resource|"",le=""0.1""}[3d]))
                 or
                 vector(0)
               )
               +
-              sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=""namespace"",le=""0.5""}[3d]))
+              sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=""namespace"",le=""0.5""}[3d]))
               +
-              sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=""cluster"",le=""5""}[3d]))
+              sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=""cluster"",le=""5""}[3d]))
             )
           )
           +
           # errors
-          sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""LIST|GET"",code=~""5..""}[3d]))
+          sum(rate(apiserver_request_total{job=""apiserver"",verb=~""LIST|GET"",code=~""5..""}[3d]))
         )
         /
-        sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""LIST|GET""}[3d]))
+        sum(rate(apiserver_request_total{job=""apiserver"",verb=~""LIST|GET""}[3d]))
       labels:
         verb: read
       record: apiserver_request:burnrate3d
     - expr: |
         (
           (
             # too slow
-            sum(rate(apiserver_request_duration_seconds_count{job=""kube-apiserver"",verb=~""LIST|GET""}[5m]))
+            sum(rate(apiserver_request_duration_seconds_count{job=""apiserver"",verb=~""LIST|GET""}[5m]))
             -
             (
               (
-                sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=~""resource|"",le=""0.1""}[5m]))
+                sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=~""resource|"",le=""0.1""}[5m]))
                 or
                 vector(0)
               )
               +
-              sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=""namespace"",le=""0.5""}[5m]))
+              sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=""namespace"",le=""0.5""}[5m]))
               +
-              sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=""cluster"",le=""5""}[5m]))
+              sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=""cluster"",le=""5""}[5m]))
             )
           )
           +
           # errors
-          sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""LIST|GET"",code=~""5..""}[5m]))
+          sum(rate(apiserver_request_total{job=""apiserver"",verb=~""LIST|GET"",code=~""5..""}[5m]))
         )
         /
-        sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""LIST|GET""}[5m]))
+        sum(rate(apiserver_request_total{job=""apiserver"",verb=~""LIST|GET""}[5m]))
       labels:
         verb: read
       record: apiserver_request:burnrate5m
     - expr: |
         (
           (
             # too slow
-            sum(rate(apiserver_request_duration_seconds_count{job=""kube-apiserver"",verb=~""LIST|GET""}[6h]))
+            sum(rate(apiserver_request_duration_seconds_count{job=""apiserver"",verb=~""LIST|GET""}[6h]))
             -
             (
               (
-                sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=~""resource|"",le=""0.1""}[6h]))
+                sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=~""resource|"",le=""0.1""}[6h]))
                 or
                 vector(0)
               )
               +
-              sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=""namespace"",le=""0.5""}[6h]))
+              sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=""namespace"",le=""0.5""}[6h]))
               +
-              sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=""cluster"",le=""5""}[6h]))
+              sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=""cluster"",le=""5""}[6h]))
             )
           )
           +
           # errors
-          sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""LIST|GET"",code=~""5..""}[6h]))
+          sum(rate(apiserver_request_total{job=""apiserver"",verb=~""LIST|GET"",code=~""5..""}[6h]))
         )
         /
-        sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""LIST|GET""}[6h]))
+        sum(rate(apiserver_request_total{job=""apiserver"",verb=~""LIST|GET""}[6h]))
       labels:
         verb: read
       record: apiserver_request:burnrate6h
     - expr: |
         (
           (
             # too slow
-            sum(rate(apiserver_request_duration_seconds_count{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[1d]))
+            sum(rate(apiserver_request_duration_seconds_count{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[1d]))
             -
-            sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE"",le=""1""}[1d]))
+            sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE"",le=""1""}[1d]))
           )
           +
-          sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE"",code=~""5..""}[1d]))
+          sum(rate(apiserver_request_total{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE"",code=~""5..""}[1d]))
         )
         /
-        sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[1d]))
+        sum(rate(apiserver_request_total{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[1d]))
       labels:
         verb: write
       record: apiserver_request:burnrate1d
     - expr: |
         (
           (
             # too slow
-            sum(rate(apiserver_request_duration_seconds_count{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[1h]))
+            sum(rate(apiserver_request_duration_seconds_count{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[1h]))
             -
-            sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE"",le=""1""}[1h]))
+            sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE"",le=""1""}[1h]))
           )
           +
-          sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE"",code=~""5..""}[1h]))
+          sum(rate(apiserver_request_total{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE"",code=~""5..""}[1h]))
         )
         /
-        sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[1h]))
+        sum(rate(apiserver_request_total{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[1h]))
       labels:
         verb: write
       record: apiserver_request:burnrate1h
     - expr: |
         (
           (
             # too slow
-            sum(rate(apiserver_request_duration_seconds_count{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[2h]))
+            sum(rate(apiserver_request_duration_seconds_count{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[2h]))
             -
-            sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE"",le=""1""}[2h]))
+            sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE"",le=""1""}[2h]))
           )
           +
-          sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE"",code=~""5..""}[2h]))
+          sum(rate(apiserver_request_total{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE"",code=~""5..""}[2h]))
         )
         /
-        sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[2h]))
+        sum(rate(apiserver_request_total{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[2h]))
       labels:
         verb: write
       record: apiserver_request:burnrate2h
     - expr: |
         (
           (
             # too slow
-            sum(rate(apiserver_request_duration_seconds_count{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[30m]))
+            sum(rate(apiserver_request_duration_seconds_count{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[30m]))
             -
-            sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE"",le=""1""}[30m]))
+            sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE"",le=""1""}[30m]))
           )
           +
-          sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE"",code=~""5..""}[30m]))
+          sum(rate(apiserver_request_total{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE"",code=~""5..""}[30m]))
         )
         /
-        sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[30m]))
+        sum(rate(apiserver_request_total{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[30m]))
       labels:
         verb: write
       record: apiserver_request:burnrate30m
     - expr: |
         (
           (
             # too slow
-            sum(rate(apiserver_request_duration_seconds_count{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[3d]))
+            sum(rate(apiserver_request_duration_seconds_count{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[3d]))
             -
-            sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE"",le=""1""}[3d]))
+            sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE"",le=""1""}[3d]))
           )
           +
-          sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE"",code=~""5..""}[3d]))
+          sum(rate(apiserver_request_total{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE"",code=~""5..""}[3d]))
         )
         /
-        sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[3d]))
+        sum(rate(apiserver_request_total{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[3d]))
       labels:
         verb: write
       record: apiserver_request:burnrate3d
     - expr: |
         (
           (
             # too slow
-            sum(rate(apiserver_request_duration_seconds_count{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[5m]))
+            sum(rate(apiserver_request_duration_seconds_count{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[5m]))
             -
-            sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE"",le=""1""}[5m]))
+            sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE"",le=""1""}[5m]))
           )
           +
-          sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE"",code=~""5..""}[5m]))
+          sum(rate(apiserver_request_total{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE"",code=~""5..""}[5m]))
         )
         /
-        sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[5m]))
+        sum(rate(apiserver_request_total{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[5m]))
       labels:
         verb: write
       record: apiserver_request:burnrate5m
     - expr: |
         (
           (
             # too slow
-            sum(rate(apiserver_request_duration_seconds_count{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[6h]))
+            sum(rate(apiserver_request_duration_seconds_count{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[6h]))
             -
-            sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE"",le=""1""}[6h]))
+            sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE"",le=""1""}[6h]))
           )
           +
-          sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE"",code=~""5..""}[6h]))
+          sum(rate(apiserver_request_total{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE"",code=~""5..""}[6h]))
         )
         /
-        sum(rate(apiserver_request_total{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[6h]))
+        sum(rate(apiserver_request_total{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[6h]))
       labels:
         verb: write
       record: apiserver_request:burnrate6h
     - expr: |
-        sum by (code,resource) (rate(apiserver_request_total{job=""kube-apiserver"",verb=~""LIST|GET""}[5m]))
+        sum by (code,resource) (rate(apiserver_request_total{job=""apiserver"",verb=~""LIST|GET""}[5m]))
       labels:
         verb: read
       record: code_resource:apiserver_request_total:rate5m
     - expr: |
-        sum by (code,resource) (rate(apiserver_request_total{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[5m]))
+        sum by (code,resource) (rate(apiserver_request_total{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[5m]))
       labels:
         verb: write
       record: code_resource:apiserver_request_total:rate5m
     - expr: |
-        histogram_quantile(0.99, sum by (le, resource) (rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET""}[5m]))) > 0
+        histogram_quantile(0.99, sum by (le, resource) (rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET""}[5m]))) > 0
       labels:
         quantile: ""0.99""
         verb: read
       record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
     - expr: |
-        histogram_quantile(0.99, sum by (le, resource) (rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[5m]))) > 0
+        histogram_quantile(0.99, sum by (le, resource) (rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""POST|PUT|PATCH|DELETE""}[5m]))) > 0
       labels:
         quantile: ""0.99""
         verb: write
@@ -339,17 +339,17 @@ spec:
         sum(rate(apiserver_request_duration_seconds_count{subresource!=""log"",verb!~""LIST|WATCH|WATCHLIST|DELETECOLLECTION|PROXY|CONNECT""}[5m])) without(instance, pod)
       record: cluster:apiserver_request_duration_seconds:mean5m
     - expr: |
-        histogram_quantile(0.99, sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",subresource!=""log"",verb!~""LIST|WATCH|WATCHLIST|DELETECOLLECTION|PROXY|CONNECT""}[5m])) without(instance, pod))
+        histogram_quantile(0.99, sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",subresource!=""log"",verb!~""LIST|WATCH|WATCHLIST|DELETECOLLECTION|PROXY|CONNECT""}[5m])) without(instance, pod))
       labels:
         quantile: ""0.99""
       record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
     - expr: |
-        histogram_quantile(0.9, sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",subresource!=""log"",verb!~""LIST|WATCH|WATCHLIST|DELETECOLLECTION|PROXY|CONNECT""}[5m])) without(instance, pod))
+        histogram_quantile(0.9, sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",subresource!=""log"",verb!~""LIST|WATCH|WATCHLIST|DELETECOLLECTION|PROXY|CONNECT""}[5m])) without(instance, pod))
       labels:
         quantile: ""0.9""
       record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
     - expr: |
-        histogram_quantile(0.5, sum(rate(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",subresource!=""log"",verb!~""LIST|WATCH|WATCHLIST|DELETECOLLECTION|PROXY|CONNECT""}[5m])) without(instance, pod))
+        histogram_quantile(0.5, sum(rate(apiserver_request_duration_seconds_bucket{job=""apiserver"",subresource!=""log"",verb!~""LIST|WATCH|WATCHLIST|DELETECOLLECTION|PROXY|CONNECT""}[5m])) without(instance, pod))
       labels:
         quantile: ""0.5""
       record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
@@ -390,19 +390,19 @@ spec:
       record: apiserver_request:availability30d
     - expr: |
         1 - (
-          sum(increase(apiserver_request_duration_seconds_count{job=""kube-apiserver"",verb=~""LIST|GET""}[30d]))
+          sum(increase(apiserver_request_duration_seconds_count{job=""apiserver"",verb=~""LIST|GET""}[30d]))
           -
           (
             # too slow
             (
-              sum(increase(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=~""resource|"",le=""0.1""}[30d]))
+              sum(increase(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=~""resource|"",le=""0.1""}[30d]))
               or
               vector(0)
             )
             +
-            sum(increase(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=""namespace"",le=""0.5""}[30d]))
+            sum(increase(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=""namespace"",le=""0.5""}[30d]))
             +
-            sum(increase(apiserver_request_duration_seconds_bucket{job=""kube-apiserver"",verb=~""LIST|GET"",scope=""cluster"",le=""5""}[30d]))
+            sum(increase(apiserver_request_duration_seconds_bucket{job=""apiserver"",verb=~""LIST|GET"",scope=""cluster"",le=""5""}[30d]))
           )
           +
           # errors
@@ -431,76 +431,76 @@ spec:
         verb: write
       record: apiserver_request:availability30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""LIST"",code=~""2..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""LIST"",code=~""2..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""GET"",code=~""2..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""GET"",code=~""2..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""POST"",code=~""2..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""POST"",code=~""2..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""PUT"",code=~""2..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""PUT"",code=~""2..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""PATCH"",code=~""2..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""PATCH"",code=~""2..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""DELETE"",code=~""2..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""DELETE"",code=~""2..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""LIST"",code=~""3..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""LIST"",code=~""3..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""GET"",code=~""3..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""GET"",code=~""3..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""POST"",code=~""3..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""POST"",code=~""3..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""PUT"",code=~""3..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""PUT"",code=~""3..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""PATCH"",code=~""3..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""PATCH"",code=~""3..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""DELETE"",code=~""3..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""DELETE"",code=~""3..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""LIST"",code=~""4..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""LIST"",code=~""4..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""GET"",code=~""4..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""GET"",code=~""4..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""POST"",code=~""4..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""POST"",code=~""4..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""PUT"",code=~""4..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""PUT"",code=~""4..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""PATCH"",code=~""4..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""PATCH"",code=~""4..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""DELETE"",code=~""4..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""DELETE"",code=~""4..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""LIST"",code=~""5..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""LIST"",code=~""5..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""GET"",code=~""5..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""GET"",code=~""5..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""POST"",code=~""5..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""POST"",code=~""5..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""PUT"",code=~""5..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""PUT"",code=~""5..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""PATCH"",code=~""5..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""PATCH"",code=~""5..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
-        sum by (code, verb) (increase(apiserver_request_total{job=""kube-apiserver"",verb=""DELETE"",code=~""5..""}[30d]))
+        sum by (code, verb) (increase(apiserver_request_total{job=""apiserver"",verb=""DELETE"",code=~""5..""}[30d]))
       record: code_verb:apiserver_request_total:increase30d
     - expr: |
         sum by (code) (code_verb:apiserver_request_total:increase30d{verb=~""LIST|GET""})
@@ -1092,15 +1092,15 @@ spec:
         message: A client certificate used to authenticate to the apiserver is expiring in less than 7.0 days.
         runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclientcertificateexpiration
       expr: |
-        apiserver_client_certificate_expiration_seconds_count{job=""kube-apiserver""} > 0 and on(job) histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job=""kube-apiserver""}[5m]))) < 604800
+        apiserver_client_certificate_expiration_seconds_count{job=""apiserver""} > 0 and on(job) histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job=""apiserver""}[5m]))) < 604800
       labels:
         severity: warning
     - alert: KubeClientCertificateExpiration
       annotations:
         message: A client certificate used to authenticate to the apiserver is expiring in less than 24.0 hours.
         runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclientcertificateexpiration
       expr: |
-        apiserver_client_certificate_expiration_seconds_count{job=""kube-apiserver""} > 0 and on(job) histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job=""kube-apiserver""}[5m]))) < 86400
+        apiserver_client_certificate_expiration_seconds_count{job=""apiserver""} > 0 and on(job) histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job=""apiserver""}[5m]))) < 86400
       labels:
         severity: critical
     - alert: AggregatedAPIErrors
@@ -1125,7 +1125,7 @@ spec:
         message: KubeAPI has disappeared from Prometheus target discovery.
         runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapidown
       expr: |
-        absent(up{job=""kube-apiserver""} == 1)
+        absent(up{job=""apiserver""} == 1)
       for: 15m
       labels:
         severity: critical"
thaum-xyz,ankhmorpork,a255a2e79eaca4c6b8dbe5e42b4944caa108dbae,paulfantom,pawel@krupa.net.pl,2020-07-06T17:33:11Z,paulfantom,pawel@krupa.net.pl,2020-07-06T17:33:11Z,apps/monitoring/alertmanager: fix secret ref,apps/monitoring/alertmanager/config.yaml,False,False,False,False,1,1,2,"---FILE: apps/monitoring/alertmanager/config.yaml---
@@ -99,7 +99,7 @@ spec:
       secretValue:
         name: alertmanager-keys
         key: opsgenie_api_key
-    - name: SLACK_API_URL
+    - name: SLACK_API_KEY
       secretValue:
         name: alertmanager-keys
         key: slack_api_key"
thaum-xyz,ankhmorpork,eb49f6eac7805dcecee4f63c1d541a884f9d7b81,paulfantom,pawel@krupa.net.pl,2020-07-06T17:01:25Z,paulfantom,pawel@krupa.net.pl,2020-07-06T17:01:25Z,apps/monitoring/prometheus: fix rules,apps/monitoring/prometheus/rules/rules.yaml,False,False,False,False,1,1,2,"---FILE: apps/monitoring/prometheus/rules/rules.yaml---
@@ -5,7 +5,7 @@ metadata:
     prometheus: k8s
     role: alert-rules
   name: prometheus-k8s-rules
-  namespace: test
+  namespace: monitoring
 spec:
   groups:
   - name: node-exporter.rules"
thaum-xyz,ankhmorpork,8aaafec52f6c0ff454fb6880768b9f96bb3df94c,paulfantom,pawel@krupa.net.pl,2020-07-05T21:44:23Z,paulfantom,pawel@krupa.net.pl,2020-07-06T15:55:01Z,hack: fix checking images when including CRDs,hack/checkimages.sh,False,False,False,False,1,1,2,"---FILE: hack/checkimages.sh---
@@ -53,7 +53,7 @@ cd ""$(git rev-parse --show-toplevel)""
 IMAGES=""""
 
 for file in $(find apps/ base/ -name *.yaml -exec grep ""image"" -l {} \;); do
-        new=$(gojsontoyaml -yamltojson < ""$file"" | jq -cr '..| .image? | select(type != ""null"")')
+        new=$(gojsontoyaml -yamltojson < ""$file"" | jq -cr '..| .image? | select(type == ""string"")')
         IMAGES=""${new} ${IMAGES}""
 done
 "
thaum-xyz,ankhmorpork,997af1fc2023d0ab718ce9c9dd2a51da65876b29,paulfantom,pawel@krupa.net.pl,2020-07-03T21:35:49Z,paulfantom,pawel@krupa.net.pl,2020-07-03T21:35:49Z,ansible/roles/rpi: fix execution on raspios,ansible/roles/rpi/vars/debian.yml,False,False,False,False,4,0,4,"---FILE: ansible/roles/rpi/vars/debian.yml---
@@ -0,0 +1,4 @@
+---
+rpi_cmdline_file: ""/boot/cmdline.txt""
+rpi_cmdline_last_regex: '^(.*rootwait)$'
+rpi_config_file: ""/boot/config.txt"""
thaum-xyz,ankhmorpork,f5bf3724c5703fc9d27ddd001ddc2b21f81fd384,paulfantom,pawel@krupa.net.pl,2020-07-03T21:35:16Z,paulfantom,pawel@krupa.net.pl,2020-07-03T21:35:16Z,ansible: fix errors in system playbook,ansible/01_system.yml,False,False,False,False,2,2,4,"---FILE: ansible/01_system.yml---
@@ -23,12 +23,12 @@
       hour: ""3""
       minute: ""43""
       job: reboot
-      state: ""{{ reboot_enabled }}""
+      state: ""{{ 'present' if reboot_enabled else 'absent' }}""
     when: reboot_enabled is defined
   - name: Install dependencies
     package:
       name: moreutils
-      state: installed
+      state: present
   - set_fact:
       pkg_mgr: ""{{ 'yum' if ansible_pkg_mgr == 'dnf' else ansible_pkg_mgr }}""
   - name: Copy package manager textfile collector script"
thaum-xyz,ankhmorpork,99400096cdbb4ea9eb1a302fd9de96b4c7322f79,paulfantom,pawel@krupa.net.pl,2020-06-28T12:32:01Z,paulfantom,pawel@krupa.net.pl,2020-06-28T12:32:01Z,base/kube-system/descheduler: apply fix from https://github.com/kubernetes-sigs/descheduler/pull/330,base/kube-system/descheduler/02_configmap.yaml,False,False,False,False,6,6,12,"---FILE: base/kube-system/descheduler/02_configmap.yaml---
@@ -32,9 +32,9 @@ data:
                ""cpu"" : 50
                ""memory"": 50
                ""pods"": 50
-       RemovePodsHavingTooManyRestarts:
-         enabled: true
-         params:
-           podsHavingTooManyRestarts:
-             podRestartThresholds: 100
-             includingInitContainers: true
+      RemovePodsHavingTooManyRestarts:
+        enabled: true
+        params:
+          podsHavingTooManyRestarts:
+            podRestartThreshold: 100
+            includingInitContainers: true"
thaum-xyz,ankhmorpork,1ce2e7e9eaf6070f30637ce5a3f79987e6fcdafc,Pawe Krupa,pawel@krupa.net.pl,2020-06-26T12:56:58Z,GitHub,noreply@github.com,2020-06-26T12:56:58Z,hack: Fix parallelism in checkimage script,hack/checkimages.sh,False,False,False,False,44,31,75,"---FILE: hack/checkimages.sh---
@@ -22,30 +22,30 @@ EOM
 )
 
 check_cross_compatibility() {
-	local image=""${1}""
-	local manifest=""${2}""
-	local err=0
-	local arch_list
+        local image=""${1}""
+        local manifest=""${2}""
+        local err=0
+        local arch_list
 
-	for exclude in ${MULTI_ARCH_EXCLUDED}; do
-		if [[ ""${image}"" =~ ${exclude} ]]; then
-			echo ""WARN: Skipping validating cross-arch compatibility for ${image}""
-			return
-		fi
-	done
-	
-	arch_list=""$(echo ""${manifest}"" | jq -cr '..| .architecture?, .Architecture? | select(type != ""null"") | select(. != """" )'  | sort | uniq)""
-	for arch in ${CPU_ARCHS}; do
-		if ! grep -q ""${arch}$"" <<< ""$arch_list""; then	
-			echo ""ERR : Image ${image} does not support ${arch} !""
-			err=1
-		fi
-	done
-	if [ ""$err"" -eq 1 ]; then
-		exit 129
-	else
-		echo ""INFO: Image ${image} is compatible with specified CPU architectures""
-	fi
+        for exclude in ${MULTI_ARCH_EXCLUDED}; do
+                if [[ ""${image}"" =~ ${exclude} ]]; then
+                        echo ""WARN: Skipping validating cross-arch compatibility for ${image}""
+                        return
+                fi
+        done
+
+        arch_list=""$(echo ""${manifest}"" | jq -cr '..| .architecture?, .Architecture? | select(type != ""null"") | select(. != """" )'  | sort | uniq)""
+        for arch in ${CPU_ARCHS}; do
+                if ! grep -q ""${arch}$"" <<< ""$arch_list""; then
+                        echo ""ERR : Image ${image} does not support ${arch} !""
+                        err=1
+                fi
+        done
+        if [ ""$err"" -ne 0 ]; then
+                exit 129
+        else
+                echo ""INFO: Image ${image} is compatible with specified CPU architectures""
+        fi
 }
 
 
@@ -56,15 +56,28 @@ cd ""$(git rev-parse --show-toplevel)""
 IMAGES=""""
 
 for file in $(find apps/ base/ -name *.yaml -exec grep ""image"" -l {} \;); do
-	new=$(gojsontoyaml -yamltojson < ""$file"" | jq -cr '..| .image? | select(type != ""null"")')
-	IMAGES=""${new} ${IMAGES}""
+        new=$(gojsontoyaml -yamltojson < ""$file"" | jq -cr '..| .image? | select(type != ""null"")')
+        IMAGES=""${new} ${IMAGES}""
 done
 
+pids=()
 for image in $(echo -e ""${IMAGES}"" | tr ' ' '\n' | sort -f | uniq); do
-	(
-		echo ""INFO: Inspecting ${image} ...""
-		info=$(manifest-tool inspect --raw ""${image}"")
-		check_cross_compatibility ""${image}"" ""${info}""
-	) &
+        (
+                echo ""INFO: Inspecting ${image} ...""
+                info=$(manifest-tool inspect --raw ""${image}"")
+                check_cross_compatibility ""${image}"" ""${info}""
+        ) &
+        pids+=(""$!"")
+done
+
+EXIT_CODE=0
+for job in ""${pids[@]}""; do
+        CODE=0;
+        wait ${job} || CODE=$?
+        if [[ ""${CODE}"" != ""0"" ]]; then
+                echo ""At least one image is not compatible with specified CPU architectures"" ;
+                EXIT_CODE=$CODE;
+        fi
 done
-wait
+
+exit $EXIT_CODE"
thaum-xyz,ankhmorpork,966ab1c7f4aa41d602da30e394d3160399923272,paulfantom,pawel@krupa.net.pl,2020-06-14T10:04:21Z,paulfantom,pawel@krupa.net.pl,2020-06-14T10:04:21Z,apps/unifi/backup: fix paths,apps/unifi/backup/03_cronjob.yaml,False,False,False,False,2,2,4,"---FILE: apps/unifi/backup/03_cronjob.yaml---
@@ -23,7 +23,7 @@ spec:
               - -e
               - 'ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null'
               - ""root@192.168.2.7:/data/autobackup/""
-              - ""/unifi/""
+              - ""/backup/""
             volumeMounts:
               - name: backups
                 mountPath: /backup
@@ -42,7 +42,7 @@ spec:
                   name: restic-repository
             volumeMounts:
               - name: backups
-                mountPath: /unifi
+                mountPath: /backup
                 readOnly: true
           volumes:
             - name: backups"
thaum-xyz,ankhmorpork,0983f3af0d98110b9bd63ee62d8ade11edae23d5,paulfantom,pawel@krupa.net.pl,2020-06-13T15:59:05Z,paulfantom,pawel@krupa.net.pl,2020-06-13T15:59:05Z,base/argocd/apps/dns: fix project,base/argocd/apps/dns.yaml,False,False,False,False,2,2,4,"---FILE: base/argocd/apps/dns.yaml---
@@ -24,7 +24,7 @@ spec:
     path: apps/dns/external
     repoURL: 'https://github.com/thaum-xyz/ankhmorpork.git'
     targetRevision: HEAD
-  project: default
+  project: dns
   syncPolicy:
     automated:
       prune: false
@@ -42,7 +42,7 @@ spec:
     path: apps/dns/local
     repoURL: 'https://github.com/thaum-xyz/ankhmorpork.git'
     targetRevision: HEAD
-  project: default
+  project: dns
   syncPolicy:
     automated:
       prune: false"
thaum-xyz,ankhmorpork,a2acc19e204cc52da9863b22ade5545dfc0beeb7,paulfantom,pawel@krupa.net.pl,2020-06-11T11:31:05Z,paulfantom,pawel@krupa.net.pl,2020-06-11T11:31:05Z,apps/unifi/backup: fix cronjob expression,apps/unifi/backup/03_cronjob.yaml,False,False,False,False,1,1,2,"---FILE: apps/unifi/backup/03_cronjob.yaml---
@@ -7,7 +7,7 @@ metadata:
 spec:
   successfulJobsHistoryLimit: 1
   failedJobsHistoryLimit: 3
-  schedule: ""6 6 * * 7""  # At 06:06 on Sunday
+  schedule: ""6 6 * * sun""  # At 06:06 on Sunday
   jobTemplate:
     spec:
       template:"
