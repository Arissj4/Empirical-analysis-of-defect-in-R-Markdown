repo_owner,repo_name,commit_hash,author,author_email,date,committer_name,committer_email,committer_date,message,filenames,touches_rmd,touches_r,touches_r_or_rmd,is_merge,added,deleted,changed,diff,_touch_r,_touch_rmd,bug_category,category_score
easystats,effectsize,3974554643644b9476f4aa98c34cd042cf50d49e,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2025-07-25T19:20:52Z,GitHub,noreply@github.com,2025-07-25T19:20:52Z,"Convert change in probability to probability / odds (#676)

* #660

* deprecate df methods

* deprecate df methods 2

* docs

* drop log RR

* typo

* new binomial model converter

* fix tests

* fix note and warning

* deprecation

* news + version bump

* add tests

* NA if RR * p0 > 1

* fix test

* Update NEWS.md

Co-authored-by: Brenton M. Wiernik <bwiernik@users.noreply.github.com>

* Update R/convert_between_riskchange.R

Co-authored-by: Brenton M. Wiernik <bwiernik@users.noreply.github.com>

* Update _pkgdown.yml

* Update oddsratio_to_riskratio.Rd

---------

Co-authored-by: Brenton M. Wiernik <bwiernik@users.noreply.github.com>",DESCRIPTION;NAMESPACE;NEWS.md;R/convert_between_odds_to_probs.R;R/convert_between_riskchange.R;R/convert_between_riskchange_ro_probs.R;R/convert_stat_chisq.R;R/sysdata.rda;R/xtab_diff.R;R/zzz_deprecated.R;data-raw/es_info.R;man/chisq_to_phi.Rd;man/effectsize_deprecated.Rd;man/odds_to_probs.Rd;man/oddsratio.Rd;man/oddsratio_to_probs.Rd;man/oddsratio_to_riskratio.Rd;pkgdown/_pkgdown.yml;tests/testthat/test-convert_between.R;tests/testthat/test-xtab.R,False,True,True,False,510,369,879,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size
-Version: 1.0.1.1
+Version: 1.0.1.2
 Authors@R:
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",

---FILE: NAMESPACE---
@@ -35,8 +35,10 @@ S3method(interpret,effectsize_table)
 S3method(interpret,lavaan)
 S3method(interpret,numeric)
 S3method(interpret,performance_lavaan)
-S3method(odds_to_probs,data.frame)
-S3method(odds_to_probs,numeric)
+S3method(oddsratio_to_arr,default)
+S3method(oddsratio_to_arr,numeric)
+S3method(oddsratio_to_nnt,default)
+S3method(oddsratio_to_nnt,numeric)
 S3method(oddsratio_to_riskratio,default)
 S3method(oddsratio_to_riskratio,numeric)
 S3method(plot,effectsize_table)
@@ -48,13 +50,17 @@ S3method(print_html,effectsize_table)
 S3method(print_html,rules)
 S3method(print_md,effectsize_table)
 S3method(print_md,rules)
-S3method(probs_to_odds,data.frame)
-S3method(probs_to_odds,numeric)
 S3method(r2_semipartial,lm)
 S3method(rb_to_p_superiority,effectsize_difference)
 S3method(rb_to_p_superiority,numeric)
 S3method(rb_to_wmw_odds,effectsize_difference)
 S3method(rb_to_wmw_odds,numeric)
+S3method(riskratio_to_arr,default)
+S3method(riskratio_to_arr,numeric)
+S3method(riskratio_to_nnt,default)
+S3method(riskratio_to_nnt,numeric)
+S3method(riskratio_to_oddsratio,default)
+S3method(riskratio_to_oddsratio,numeric)
 export(.es_aov_simple)
 export(.es_aov_strata)
 export(.es_aov_table)
@@ -70,6 +76,7 @@ export(arr)
 export(arr_to_logoddsratio)
 export(arr_to_nnt)
 export(arr_to_oddsratio)
+export(arr_to_probs)
 export(arr_to_riskratio)
 export(c_to_w)
 export(chisq_to_cohens_w)
@@ -88,14 +95,6 @@ export(cohens_u1)
 export(cohens_u2)
 export(cohens_u3)
 export(cohens_w)
-export(convert_d_to_oddsratio)
-export(convert_d_to_r)
-export(convert_odds_to_probs)
-export(convert_oddsratio_to_d)
-export(convert_oddsratio_to_r)
-export(convert_probs_to_odds)
-export(convert_r_to_d)
-export(convert_r_to_oddsratio)
 export(cov_pooled)
 export(cramers_v)
 export(d_to_logoddsratio)
@@ -165,6 +164,7 @@ export(kendalls_w)
 export(logoddsratio_to_arr)
 export(logoddsratio_to_d)
 export(logoddsratio_to_nnt)
+export(logoddsratio_to_probs)
 export(logoddsratio_to_r)
 export(logoddsratio_to_riskratio)
 export(mad_pooled)
@@ -174,12 +174,14 @@ export(nnt)
 export(nnt_to_arr)
 export(nnt_to_logoddsratio)
 export(nnt_to_oddsratio)
+export(nnt_to_probs)
 export(nnt_to_riskratio)
 export(odds_to_probs)
 export(oddsratio)
 export(oddsratio_to_arr)
 export(oddsratio_to_d)
 export(oddsratio_to_nnt)
+export(oddsratio_to_probs)
 export(oddsratio_to_r)
 export(oddsratio_to_riskratio)
 export(omega_squared)
@@ -207,6 +209,7 @@ export(riskratio_to_arr)
 export(riskratio_to_logoddsratio)
 export(riskratio_to_nnt)
 export(riskratio_to_oddsratio)
+export(riskratio_to_probs)
 export(rm_d)
 export(rules)
 export(sd_pooled)

---FILE: NEWS.md---
@@ -2,8 +2,20 @@
 
 ## New features
 
+- `oddsratio_to_*()` and `riskratio_to_*()` can now convert binomial models with logit- or log-links (respectively) to any of RR, OR, ARR, NNT.
+- New functions to convert between measures of change in probabilities and probabilities. See `?oddsratio_to_probs` for all available functions.
 - `effetsize()` and friends support `datawizard::data_tabulate()` objects as inputs.
 
+## Changes
+
+`riskratio_to_*()` now returns `NA` if the expected risk is larger than 1. This results when impossible combinations of risk ratio `RR` and baseline risk `p0` are provided.
+
+## Breaking Changes
+
+- `probs_to_odds(<data.frame>)` and `odds_to_probs(<data.frame>)` methods has been deprecated.
+- `riskratio(log=)` argument has been deprecated.
+- `convert_*()` aliases, deprecated since March 2023, have been removed. 
+
 # effectsize 1.0.1
 
 ## New features

---FILE: R/convert_between_odds_to_probs.R---
@@ -3,10 +3,6 @@
 #' @param odds The *Odds* (or `log(odds)` when `log = TRUE`) to convert.
 #' @param probs Probability values to convert.
 #' @param log Take in or output log odds (such as in logistic models).
-#' @param select When a data frame is passed, character or list of of column
-#'   names to be transformed.
-#' @param exclude When a data frame is passed, character or list of column names
-#'   to be excluded from transformation.
 #' @param ... Arguments passed to or from other methods.
 #'
 #' @return Converted index.
@@ -22,126 +18,27 @@
 #' probs_to_odds(0.95, log = TRUE)
 #' @export
 odds_to_probs <- function(odds, log = FALSE, ...) {
-  UseMethod(""odds_to_probs"")
-}
+  if (is.data.frame(odds)) {
+    .deprecated_df_methods(""odds_to_probs"")
+  }
 
-#' @export
-odds_to_probs.numeric <- function(odds, log = FALSE, ...) {
   if (log) {
     stats::plogis(odds)
   } else {
     stats::plogis(log(odds))
   }
 }
 
-
-#' @rdname odds_to_probs
-#' @export
-odds_to_probs.data.frame <- function(odds, log = FALSE, select = NULL, exclude = NULL, ...) {
-  .odds_to_probs_df(odds = odds, log = log, select = select, exclude = exclude, ...)
-}
-
-
 #' @rdname odds_to_probs
 #' @export
 probs_to_odds <- function(probs, log = FALSE, ...) {
-  UseMethod(""probs_to_odds"")
-}
+  if (is.data.frame(probs)) {
+    .deprecated_df_methods(""probs_to_odds"")
+  }
 
-#' @export
-probs_to_odds.numeric <- function(probs, log = FALSE, ...) {
   if (log) {
     stats::qlogis(probs)
   } else {
     exp(stats::qlogis(probs))
   }
 }
-
-#' @rdname odds_to_probs
-#' @export
-probs_to_odds.data.frame <- function(probs, log = FALSE, select = NULL, exclude = NULL, ...) {
-  .odds_to_probs_df(probs = probs, log = log, select = select, exclude = exclude, ...)
-}
-
-
-
-
-
-
-
-
-
-# Data frame --------------------------------------------------------------
-
-
-
-#' @keywords internal
-.odds_to_probs_df <- function(odds = NULL, probs = NULL, log = FALSE, select = NULL, exclude = NULL, ...) {
-  # If vector
-  if (is.null(odds)) {
-    mydata <- probs
-  } else {
-    mydata <- odds
-  }
-
-  # check for formula notation, convert to character vector
-  if (inherits(select, ""formula"")) {
-    select <- all.vars(select)
-  }
-  if (inherits(exclude, ""formula"")) {
-    exclude <- all.vars(exclude)
-  }
-
-  # Variable order
-  var_order <- names(mydata)
-
-  # Keep subset
-  if (!is.null(select) && select %in% names(mydata)) {
-    select <- as.vector(select)
-    to_keep <- as.data.frame(mydata[!names(mydata) %in% select])
-    mydata <- mydata[names(mydata) %in% select]
-  } else {
-    to_keep <- NULL
-  }
-
-  # Remove exceptions
-  if (!is.null(exclude) && exclude %in% names(mydata)) {
-    exclude <- as.vector(exclude)
-    if (is.null(to_keep)) {
-      to_keep <- as.data.frame(mydata[exclude])
-    } else {
-      to_keep <- cbind(to_keep, as.data.frame(mydata[exclude]))
-    }
-
-    mydata <- mydata[!names(mydata) %in% exclude]
-  }
-
-  # Remove non-numerics
-  is_num <- vapply(mydata, is.numeric, logical(1))
-  dfother <- mydata[!is_num]
-  dfnum <- mydata[is_num]
-
-  # Tranform
-  if (is.null(odds)) {
-    dfnum <- data.frame(lapply(dfnum, probs_to_odds.numeric, log = log))
-  } else {
-    dfnum <- data.frame(lapply(dfnum, odds_to_probs.numeric, log = log))
-  }
-
-  # Add non-numerics
-  if (is.null(ncol(dfother))) {
-    mydata <- dfnum
-  } else {
-    mydata <- cbind(dfother, dfnum)
-  }
-
-  # Add exceptions
-  if (!is.null(select) || !is.null(exclude) && exists(""to_keep"")) {
-    mydata <- cbind(mydata, to_keep)
-  }
-
-  # Reorder
-  mydata <- mydata[var_order]
-
-  mydata
-}

---FILE: R/convert_between_riskchange.R---
@@ -16,6 +16,12 @@
 #' @inheritParams oddsratio_to_d
 #' @inheritParams cohens_d
 #'
+#' @details
+#' If an impossible combination of risk ratio `RR` and baseline risk `p0` is provided, 
+#' such that `RR * p0 > 1`, then this conversion will produce invalid results where
+#' the expected risk is larger than 1. In such cases `riskratio_to_*()` functions will return `NA`.
+#'
+#'
 #' @return Converted index, or if `OR`/`logOR` is a logistic regression model, a
 #'   parameter table with the converted indices.
 #'
@@ -64,72 +70,46 @@ oddsratio_to_riskratio.numeric <- function(OR, p0, log = FALSE, verbose = TRUE,
 
 #' @export
 oddsratio_to_riskratio.default <- function(OR, p0, log = FALSE, verbose = TRUE, ...) {
-  mi <- .get_model_info(OR, ...)
-  if (!mi$is_binomial || !mi$is_logit) {
-    insight::format_error(""Model must be a binomial model with a logit-link (logistic regression)."")
-  }
-
-  RR <- parameters::model_parameters(OR, exponentiate = !log, effects = ""fixed"", ...)
-  RR$SE <- NULL
-  RR$z <- NULL
-  RR$df_error <- NULL
-  RR$p <- NULL
-
-  used_intercept <- missing(p0)
-  if (used_intercept) {
-    p0 <- RR[[""Coefficient""]][RR$Parameter == ""(Intercept)""]
-    if (!log) p0 <- log(p0)
-    p0 <- stats::plogis(p0)
-
-    if (verbose) {
-      insight::format_warning(
-        ""'p0' not provided."",
-        sprintf(
-          ""RR is relative to the intercept (p0 = %s) - make sure your intercept is meaningful."",
-          insight::format_value(p0)
-        )
-      )
-    }
-  }
-
-  trans_cols <- colnames(RR) %in% c(""Coefficient"", ""CI_low"", ""CI_high"")
-  RR[, trans_cols] <-
-    lapply(RR[, trans_cols, drop = FALSE],
-      oddsratio_to_riskratio,
-      p0 = p0, log = log
-    )
-
-  if (verbose && any(c(""CI_low"", ""CI_high"") %in% colnames(RR))) {
-    insight::format_alert(""CIs are back-transformed from the logit scale."")
-  }
-
-  RR[RR$Parameter == ""(Intercept)"", ""Coefficient""] <- p0
-  RR[RR$Parameter == ""(Intercept)"", c(""CI_low"", ""CI_high"")] <- NA
-
-  if (!used_intercept) {
-    RR[RR$Parameter == ""(Intercept)"", ""Parameter""] <- ""(p0)""
-  }
-
-  attr(RR, ""coefficient_name"") <- ""Risk Ratio""
-  return(RR)
+  .model_to_riskchange(OR, p0 = p0, verbose = verbose,
+                       link = ""logit"", trans = ""riskratio"", ...)
 }
 
 #' @rdname oddsratio_to_riskratio
 #' @export
 oddsratio_to_arr <- function(OR, p0, log = FALSE, verbose = TRUE, ...) {
+  UseMethod(""oddsratio_to_arr"")
+}
+
+#' @export
+oddsratio_to_arr.numeric <- function(OR, p0, log = FALSE, verbose = TRUE, ...) {
   if (log) OR <- exp(OR)
   RR <- oddsratio_to_riskratio(OR, p0, log = FALSE, verbose = verbose)
   riskratio_to_arr(RR, p0, verbose = verbose)
 }
 
+#' @export
+oddsratio_to_arr.default <- function(OR, p0, log = FALSE, verbose = TRUE, ...) {
+  .model_to_riskchange(OR, p0 = p0, verbose = verbose,
+                       link = ""logit"", trans = ""arr"", ...)
+}
+
 #' @rdname oddsratio_to_riskratio
 #' @export
 oddsratio_to_nnt <- function(OR, p0, log = FALSE, verbose = TRUE, ...) {
+  UseMethod(""oddsratio_to_nnt"")
+}
+
+#' @export
+oddsratio_to_nnt.numeric <- function(OR, p0, log = FALSE, verbose = TRUE, ...) {
   ARR <- oddsratio_to_arr(OR, p0, log = log, verbose = verbose)
   arr_to_nnt(ARR)
 }
 
-
+#' @export
+oddsratio_to_nnt.default <- function(OR, p0, log = FALSE, verbose = TRUE, ...) {
+  .model_to_riskchange(OR, p0 = p0, verbose = verbose,
+                       link = ""logit"", trans = ""nnt"", ...)
+}
 
 
 # From logoddsratio -------------------------------------------------------
@@ -161,16 +141,41 @@ logoddsratio_to_nnt <- function(logOR, p0, log = TRUE, verbose = TRUE, ...) {
 #' @rdname oddsratio_to_riskratio
 #' @export
 riskratio_to_oddsratio <- function(RR, p0, log = FALSE, verbose = TRUE, ...) {
-  OR <- RR * (1 - p0) / (1 - RR * p0)
+  UseMethod(""riskratio_to_oddsratio"")
+}
+
+#' @export
+riskratio_to_oddsratio.numeric <- function(RR, p0, log = FALSE, verbose = TRUE, ...) {
+  p1 <- RR * p0
+  OR <- RR * (1 - p0) / (1 - p1)
+  OR[p1 > 1] <- NA
 
   if (log) OR <- log(OR)
   return(OR)
 }
 
+#' @export
+riskratio_to_oddsratio.default <- function(RR, p0, log = FALSE, verbose = TRUE, ...) {
+  .model_to_riskchange(RR, p0 = p0, verbose = verbose,
+                       link = ""log"", trans = if (log) ""logoddsratio"" else ""oddsratio"", ...)
+}
+
 #' @rdname oddsratio_to_riskratio
 #' @export
 riskratio_to_arr <- function(RR, p0, verbose = TRUE, ...) {
-  RR * p0 - p0
+  UseMethod(""riskratio_to_arr"")
+}
+
+#' @export
+riskratio_to_arr.numeric <- function(RR, p0, verbose = TRUE, ...) {
+  p1 <- RR * p0
+  ifelse(p1 > 1, NA, p1 - p0)
+}
+
+#' @export
+riskratio_to_arr.default <- function(RR, p0, verbose = TRUE, ...) {
+  .model_to_riskchange(RR, p0 = p0, verbose = verbose,
+                       link = ""log"", trans = ""arr"", ...)
 }
 
 #' @rdname oddsratio_to_riskratio
@@ -182,10 +187,21 @@ riskratio_to_logoddsratio <- function(RR, p0, log = TRUE, verbose = TRUE, ...) {
 #' @rdname oddsratio_to_riskratio
 #' @export
 riskratio_to_nnt <- function(RR, p0, verbose = TRUE, ...) {
+  UseMethod(""riskratio_to_nnt"")
+}
+
+#' @export
+riskratio_to_nnt.numeric <- function(RR, p0, verbose = TRUE, ...) {
   ARR <- riskratio_to_arr(RR, p0, verbose = verbose)
   arr_to_nnt(ARR)
 }
 
+#' @export
+riskratio_to_nnt.default <- function(RR, p0, verbose = TRUE, ...) {
+  .model_to_riskchange(RR, p0 = p0, verbose = verbose,
+                       link = ""log"", trans = ""nnt"", ...)
+}
+
 
 # ARR ---------------------------------------------------------------------
 
@@ -244,3 +260,83 @@ nnt_to_riskratio <- function(NNT, p0, verbose = TRUE, ...) {
 nnt_to_arr <- function(NNT, ...) {
   arr_to_nnt(NNT)
 }
+
+
+
+# Utils -------------------------------------------------------------------
+
+#' @keywords internal
+.model_to_riskchange <- function(model, p0,
+                                 trans = c(""oddsratio"", ""logoddsratio"", ""riskratio"", ""nnt"", ""arr""),
+                                 link = c(""logit"", ""log""),
+                                 verbose = TRUE,
+                                 ...) {
+  link <- match.arg(link)
+  trans <- match.arg(trans)
+  to_log <- trans == ""logoddsratio""
+  if (to_log) trans <- ""oddsratio""
+  ftrans <- match.fun(paste0(ifelse(link == ""logit"", ""oddsratio"", ""riskratio""), ""_to_"", trans))
+
+  mi <- .get_model_info(model, ...)
+  if (!mi$is_binomial || mi$link_function != link) {
+    insight::format_error(sprintf(""Model must be a binomial model with a %s link function."", link))
+  }
+
+  # Coef table
+  pars <- parameters::model_parameters(model, exponentiate = TRUE, effects = ""fixed"", ...)
+  pars[,setdiff(colnames(pars), c(""Effects"", ""Group"", ""Component"", ""Parameter"", ""Coefficient"", ""CI"", ""CI_low"", ""CI_high""))] <- NULL
+
+  # p0
+  if (missing(p0)) {
+    if (!insight::has_intercept(model)) {
+      insight::format_error(""Model must has an Intercept if 'p0' not provided."")
+    }
+
+    p0 <- pars[[""Coefficient""]][pars$Parameter == ""(Intercept)""]
+    if (link == ""logit"") {
+      p0 <- odds_to_probs(p0)
+    }
+
+    if (verbose) {
+      insight::format_warning(
+        ""'p0' not provided:"",
+        sprintf(""Computing effect size relative to the intercept (p0 = %.3f);"", p0),
+        ""Make sure your intercept is meaningful.""
+      )
+    }
+  }
+
+  # transform
+  trans_cols <- intersect(colnames(pars), c(""Coefficient"", ""CI_low"", ""CI_high""))
+  pars_out <- datawizard::data_modify(pars, .at = trans_cols,
+                                      .modify = function(x) ftrans(x, p0 = p0))
+  if (trans == ""nnt"" && ""CI"" %in% colnames(pars_out)) {
+    for (i in seq_len(nrow(pars_out))) {
+      ci_sign <- unlist(sign(pars_out[i, c(""CI_low"", ""CI_high"")]))
+      if (all(ci_sign == 1) || all(ci_sign == -1)) {
+        pars_out[i, c(""CI_low"", ""CI_high"")] <- pars_out[i, c(""CI_high"", ""CI_low"")]
+      } else {
+        pars_out[i, c(""CI_low"", ""CI_high"")] <- pars_out[i, c(""CI_low"", ""CI_high"")]
+      }
+    }
+  }
+
+  if (to_log) {
+    pars_out <- datawizard::data_modify(pars_out, .at = trans_cols, .modify = log)
+    trans <- ""logoddsratio""
+  }
+
+  # add p0
+  pars_out[pars_out$Parameter == ""(Intercept)"", ""Coefficient""] <- p0
+  pars_out[pars_out$Parameter == ""(Intercept)"", c(""CI_low"", ""CI_high"")] <- NA
+  pars_out[pars_out$Parameter == ""(Intercept)"", ""Parameter""] <- ""(p0)""
+
+  attr(pars_out, ""coefficient_name"") <- switch (trans,
+                                                ""oddsratio"" = ""Odds ratio"",
+                                                ""logoddsratio"" = ""log(Odds ratio)"",
+                                                ""riskratio"" = ""Risk ratio"",
+                                                ""nnt"" = ""NNT"",
+                                                ""arr"" = ""ARR""
+  )
+  return(pars_out)
+}

---FILE: R/convert_between_riskchange_ro_probs.R---
@@ -0,0 +1,72 @@
+#' Convert Between Metrics of Change in Probabilities and Probabilities
+#'
+#' @inheritParams arr_to_nnt
+#' @param odds Should odds be returned instead of probabilities?
+#'
+#' @return Probabilities (or probability odds).
+#'
+#' @seealso [oddsratio()], [riskratio()], [arr()], and [nnt()],
+#' [odds_to_probs()], and [oddsratio_to_arr()] and others.
+#'
+#' @examples
+#'
+#' p0 <- 0.4
+#' p1 <- 0.7
+#'
+#' (OR <- probs_to_odds(p1) / probs_to_odds(p0))
+#' (RR <- p1 / p0)
+#' (ARR <- p1 - p0)
+#' (NNT <- arr_to_nnt(ARR))
+#'
+#' riskratio_to_probs(RR, p0 = p0)
+#' oddsratio_to_probs(OR, p0 = p0)
+#'
+#' all.equal(nnt_to_probs(NNT, p0 = p0, odds = TRUE),
+#'           probs_to_odds(p1))
+#'
+#' arr_to_probs(-ARR, p0 = p1)
+#' nnt_to_probs(-NNT, p0 = p1)
+#'
+#'
+#'
+#' # RR |>
+#' #   riskratio_to_arr(p0) |>
+#' #   arr_to_oddsratio(p0) |>
+#' #   oddsratio_to_nnt(p0) |>
+#' #   nnt_to_probs(p0)
+#'
+#' @export
+oddsratio_to_probs <- function(OR, p0, log = FALSE, odds = FALSE, ...) {
+  ARR <- oddsratio_to_arr(OR, p0, log = log)
+  arr_to_probs(ARR, p0, odds = odds)
+}
+
+#' @export
+#' @rdname oddsratio_to_probs
+logoddsratio_to_probs <- function(logOR, p0, log = TRUE, odds = FALSE, ...) {
+  oddsratio_to_probs(logOR, p0, log = log, odds = odds)
+}
+
+#' @export
+#' @rdname oddsratio_to_probs
+riskratio_to_probs <- function(RR, p0, odds = FALSE, ...) {
+  ARR <- riskratio_to_arr(RR, p0)
+  arr_to_probs(ARR, p0, odds = odds)
+}
+
+#' @export
+#' @rdname oddsratio_to_probs
+arr_to_probs <- function(ARR, p0, odds = FALSE, ...) {
+  p1 <- p0 + ARR
+  if (odds) {
+    return(probs_to_odds(p1))
+  }
+  p1
+}
+
+#' @export
+#' @rdname oddsratio_to_probs
+nnt_to_probs <- function(NNT, p0, odds = FALSE, ...) {
+  ARR <- nnt_to_arr(NNT)
+  arr_to_probs(ARR, p0, odds = odds)
+}

---FILE: R/convert_stat_chisq.R---
@@ -5,8 +5,6 @@
 #' \ifelse{latex}{\eqn{Fei}}{×¤ (Fei)} and Pearson's \eqn{C} for contingency
 #' tables or goodness of fit.
 #'
-#' @name chisq_to_phi
-#' @rdname convert_chisq
 #'
 #' @param chisq The \eqn{\chi^2} (chi-square) statistic.
 #' @param n Total sample size.
@@ -139,7 +137,7 @@ chisq_to_phi <- function(chisq, n, nrow = 2, ncol = 2,
 }
 
 
-#' @rdname convert_chisq
+#' @rdname chisq_to_phi
 #' @export
 chisq_to_cohens_w <- function(chisq, n, nrow, ncol, p,
                               ci = 0.95, alternative = ""greater"",
@@ -173,7 +171,7 @@ chisq_to_cohens_w <- function(chisq, n, nrow, ncol, p,
   return(res)
 }
 
-#' @rdname convert_chisq
+#' @rdname chisq_to_phi
 #' @export
 chisq_to_cramers_v <- function(chisq, n, nrow, ncol,
                                adjust = TRUE,
@@ -205,7 +203,7 @@ chisq_to_cramers_v <- function(chisq, n, nrow, ncol,
   return(res)
 }
 
-#' @rdname convert_chisq
+#' @rdname chisq_to_phi
 #' @export
 chisq_to_tschuprows_t <- function(chisq, n, nrow, ncol,
                                   adjust = TRUE,
@@ -238,7 +236,7 @@ chisq_to_tschuprows_t <- function(chisq, n, nrow, ncol,
 }
 
 
-#' @rdname convert_chisq
+#' @rdname chisq_to_phi
 #' @export
 #' @param p Vector of expected values. See [stats::chisq.test()].
 chisq_to_fei <- function(chisq, n, nrow, ncol, p,
@@ -281,7 +279,7 @@ chisq_to_fei <- function(chisq, n, nrow, ncol, p,
   return(res)
 }
 
-#' @rdname convert_chisq
+#' @rdname chisq_to_phi
 #' @export
 chisq_to_pearsons_c <- function(chisq, n, nrow, ncol,
                                 ci = 0.95, alternative = ""greater"",
@@ -305,7 +303,7 @@ chisq_to_pearsons_c <- function(chisq, n, nrow, ncol,
 
 # Reverse -----------------------------------------------------------------
 
-#' @rdname convert_chisq
+#' @rdname chisq_to_phi
 #' @param phi The \eqn{\phi} (phi) statistic.
 #' @export
 phi_to_chisq <- function(phi, n, ...) {

---FILE: R/xtab_diff.R---
@@ -5,9 +5,11 @@
 #' [`stats::fisher.test()`].
 #' \cr\cr
 #' Note that these are computed with each **column** representing the different
-#' groups, and the *first* column representing the treatment group and the
-#' *second* column baseline (or control). Effects are given as `treatment /
-#' control`. If you wish you use rows as groups you must pass a transposed
+#' groups (the *first* column representing the treatment group and the
+#' *second* column the baseline or control group), and the *first* row
+#' representing the ""positive"" level (the `k` in `p=k/n`).
+#' Effects are given as _p_-treatment _over_ _p_-control.
+#' If you wish you use rows as groups you must pass a transposed
 #' table, or switch the `x` and `y` arguments.
 #'
 #'
@@ -28,9 +30,9 @@
 #' @inheritSection effectsize_CIs CIs and Significance Tests
 #' @inheritSection print.effectsize_table Plotting with `see`
 #'
-#' @return A data frame with the effect size (`Odds_ratio`, `Risk_ratio`
-#'   (possibly with the prefix `log_`), `Cohens_h`, `ARR`, `NNT`) and its CIs
-#'   (`CI_low` and `CI_high`).
+#' @return A data frame with the effect size (`Odds_ratio`, `log_Odds_ratio`,
+#'   `Risk_ratio` `Cohens_h`, `ARR`, `NNT`) and its CIs (`CI_low` and
+#'   `CI_high`).
 #'
 #' @family effect sizes for contingency table
 #'
@@ -117,14 +119,19 @@ oddsratio <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = F
 
 #' @rdname oddsratio
 #' @export
-riskratio <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = FALSE, ...) {
+riskratio <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...) {
+  if (""log"" %in% ...names() && isTRUE(list(...)$log)) {
+    insight::format_warning(""'log' argument has been deprecated."",
+                            ""Returning RR instead of log(RR)"")
+  }
+
   alternative <- .match.alt(alternative)
 
   if (.is_htest_of_type(x, ""Pearson's Chi-squared"", ""Chi-squared-test"") ||
       inherits(x, c(""datawizard_crosstabs"", ""datawizard_crosstab""))) {
-    return(effectsize(x, type = ""rr"", log = log, ci = ci, alternative = alternative))
+    return(effectsize(x, type = ""rr"", ci = ci, alternative = alternative))
   } else if (.is_BF_of_type(x, ""BFcontingencyTable"", ""Chi-squared"")) {
-    return(effectsize(x, type = ""rr"", log = log, ci = ci, ...))
+    return(effectsize(x, type = ""rr"", ci = ci, ...))
   }
 
   res <- .get_data_xtabs(x, y)
@@ -165,12 +172,6 @@ riskratio <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = F
     ci_method <- alternative <- NULL
   }
 
-  if (log) {
-    res[colnames(res) %in% c(""Risk_ratio"", ""CI_low"", ""CI_high"")] <-
-      log(res[colnames(res) %in% c(""Risk_ratio"", ""CI_low"", ""CI_high"")])
-    colnames(res)[1] <- ""log_Risk_ratio""
-  }
-
   class(res) <- c(""effectsize_table"", ""see_effectsize_table"", class(res))
   attr(res, ""ci"") <- ci
   attr(res, ""ci_method"") <- ci_method

---FILE: R/zzz_deprecated.R---
@@ -1,66 +1,25 @@
 #' Deprecated / Defunct Functions
 #'
 #' @param ... Arguments to the deprecated function.
+
+#' @aliases probs_to_odds.data.frame
+#' @aliases oods_to_probs.data.frame
 #'
 #' @rdname effectsize_deprecated
 #' @name effectsize_deprecated
 NULL
 
 
-# March 2023 --------------------------------------------------------------
-
-#' @rdname effectsize_deprecated
-#' @export
-convert_odds_to_probs <- function(...) {
-  .Deprecated(""odds_to_probs"")
-  odds_to_probs(...)
-}
-
-#' @rdname effectsize_deprecated
-#' @export
-convert_probs_to_odds <- function(...) {
-  .Deprecated(""probs_to_odds"")
-  probs_to_odds(...)
-}
-
-#' @rdname effectsize_deprecated
-#' @export
-convert_d_to_r <- function(...) {
-  .Deprecated(""d_to_r"")
-  d_to_r(...)
-}
+# July 2025 ---------------------------------------------------------------
 
-#' @rdname effectsize_deprecated
-#' @export
-convert_r_to_d <- function(...) {
-  .Deprecated(""r_to_d"")
-  r_to_d(...)
-}
-
-#' @rdname effectsize_deprecated
-#' @export
-convert_oddsratio_to_d <- function(...) {
-  .Deprecated(""oddsratio_to_d"")
-  oddsratio_to_d(...)
-}
-
-#' @rdname effectsize_deprecated
-#' @export
-convert_d_to_oddsratio <- function(...) {
-  .Deprecated(""d_to_oddsratio"")
-  d_to_oddsratio(...)
-}
-
-#' @rdname effectsize_deprecated
-#' @export
-convert_oddsratio_to_r <- function(...) {
-  .Deprecated(""oddsratio_to_r"")
-  oddsratio_to_r(...)
-}
-
-#' @rdname effectsize_deprecated
-#' @export
-convert_r_to_oddsratio <- function(...) {
-  .Deprecated(""r_to_oddsratio"")
-  r_to_oddsratio(...)
+#' @keywords internal
+.deprecated_df_methods <- function(funname) {
+  insight::format_error(
+    sprintf(""%s(<data.frame>) is deprecated."", funname),
+    ""You can use:"",
+    sprintf(""datawizard::data_modify(data, .at = ..., .modify = %s)"", funname),
+    ""Or"",
+    sprintf(""dplyr::mutate(data, dplyr::across(..., %s))"", funname),
+    ""Instead.""
+  )
 }

---FILE: data-raw/es_info.R---
@@ -32,7 +32,7 @@ es_info <- tibble::tribble(
   ""Odds_ratio"", ""Odds ratio"", NA, ""twotail"", 0, Inf, 1,
   ""log_Odds_ratio"", ""log(Odds ratio)"", NA, ""twotail"", -Inf, Inf, 0,
   ""Risk_ratio"", ""Risk ratio"", NA, ""twotail"", 0, Inf, 1,
-  ""log_Risk_ratio"", ""log(Risk ratio)"", NA, ""twotail"", -Inf, Inf, 0,
+  # ""log_Risk_ratio"", ""log(Risk ratio)"", NA, ""twotail"", -Inf, Inf, 0,
   ""ARR"", ""ARR"", NA, ""twotail"", -1, 1, 0,
   ""NNT"", ""NNT"", NA, ""twotail"", -Inf, Inf, NaN,
 

---FILE: man/effectsize_deprecated.Rd---
@@ -2,32 +2,9 @@
 % Please edit documentation in R/zzz_deprecated.R
 \name{effectsize_deprecated}
 \alias{effectsize_deprecated}
-\alias{convert_odds_to_probs}
-\alias{convert_probs_to_odds}
-\alias{convert_d_to_r}
-\alias{convert_r_to_d}
-\alias{convert_oddsratio_to_d}
-\alias{convert_d_to_oddsratio}
-\alias{convert_oddsratio_to_r}
-\alias{convert_r_to_oddsratio}
+\alias{probs_to_odds.data.frame}
+\alias{oods_to_probs.data.frame}
 \title{Deprecated / Defunct Functions}
-\usage{
-convert_odds_to_probs(...)
-
-convert_probs_to_odds(...)
-
-convert_d_to_r(...)
-
-convert_r_to_d(...)
-
-convert_oddsratio_to_d(...)
-
-convert_d_to_oddsratio(...)
-
-convert_oddsratio_to_r(...)
-
-convert_r_to_oddsratio(...)
-}
 \arguments{
 \item{...}{Arguments to the deprecated function.}
 }

---FILE: man/odds_to_probs.Rd---
@@ -2,18 +2,12 @@
 % Please edit documentation in R/convert_between_odds_to_probs.R
 \name{odds_to_probs}
 \alias{odds_to_probs}
-\alias{odds_to_probs.data.frame}
 \alias{probs_to_odds}
-\alias{probs_to_odds.data.frame}
 \title{Convert Between Odds and Probabilities}
 \usage{
 odds_to_probs(odds, log = FALSE, ...)
 
-\method{odds_to_probs}{data.frame}(odds, log = FALSE, select = NULL, exclude = NULL, ...)
-
 probs_to_odds(probs, log = FALSE, ...)
-
-\method{probs_to_odds}{data.frame}(probs, log = FALSE, select = NULL, exclude = NULL, ...)
 }
 \arguments{
 \item{odds}{The \emph{Odds} (or \code{log(odds)} when \code{log = TRUE}) to convert.}
@@ -22,12 +16,6 @@ probs_to_odds(probs, log = FALSE, ...)
 
 \item{...}{Arguments passed to or from other methods.}
 
-\item{select}{When a data frame is passed, character or list of of column
-names to be transformed.}
-
-\item{exclude}{When a data frame is passed, character or list of column names
-to be excluded from transformation.}
-
 \item{probs}{Probability values to convert.}
 }
 \value{

---FILE: man/oddsratio.Rd---
@@ -10,7 +10,7 @@
 \usage{
 oddsratio(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = FALSE, ...)
 
-riskratio(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = FALSE, ...)
+riskratio(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...)
 
 cohens_h(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...)
 
@@ -38,18 +38,21 @@ e.g. when the desired input or output are log odds ratios instead odds ratios.}
 \item{...}{Ignored}
 }
 \value{
-A data frame with the effect size (\code{Odds_ratio}, \code{Risk_ratio}
-(possibly with the prefix \code{log_}), \code{Cohens_h}, \code{ARR}, \code{NNT}) and its CIs
-(\code{CI_low} and \code{CI_high}).
+A data frame with the effect size (\code{Odds_ratio}, \code{log_Odds_ratio},
+\code{Risk_ratio} \code{Cohens_h}, \code{ARR}, \code{NNT}) and its CIs (\code{CI_low} and
+\code{CI_high}).
 }
 \description{
 Compute Odds Ratios, Risk Ratios, Cohen's \emph{h}, Absolute Risk Reduction or
 Number Needed to Treat. Report with any \code{\link[stats:chisq.test]{stats::chisq.test()}} or
 \code{\link[stats:fisher.test]{stats::fisher.test()}}.
 \cr\cr
 Note that these are computed with each \strong{column} representing the different
-groups, and the \emph{first} column representing the treatment group and the
-\emph{second} column baseline (or control). Effects are given as \code{treatment / control}. If you wish you use rows as groups you must pass a transposed
+groups (the \emph{first} column representing the treatment group and the
+\emph{second} column the baseline or control group), and the \emph{first} row
+representing the ""positive"" level (the \code{k} in \code{p=k/n}).
+Effects are given as \emph{p}-treatment \emph{over} \emph{p}-control.
+If you wish you use rows as groups you must pass a transposed
 table, or switch the \code{x} and \code{y} arguments.
 }
 \section{Confidence (Compatibility) Intervals (CIs)}{

---FILE: man/oddsratio_to_probs.Rd---
@@ -0,0 +1,84 @@
+% Generated by roxygen2: do not edit by hand
+% Please edit documentation in R/convert_between_riskchange_ro_probs.R
+\name{oddsratio_to_probs}
+\alias{oddsratio_to_probs}
+\alias{logoddsratio_to_probs}
+\alias{riskratio_to_probs}
+\alias{arr_to_probs}
+\alias{nnt_to_probs}
+\title{Convert Between Metrics of Change in Probabilities and Probabilities}
+\usage{
+oddsratio_to_probs(OR, p0, log = FALSE, odds = FALSE, ...)
+
+logoddsratio_to_probs(logOR, p0, log = TRUE, odds = FALSE, ...)
+
+riskratio_to_probs(RR, p0, odds = FALSE, ...)
+
+arr_to_probs(ARR, p0, odds = FALSE, ...)
+
+nnt_to_probs(NNT, p0, odds = FALSE, ...)
+}
+\arguments{
+\item{OR, logOR, RR, ARR, NNT}{Odds-ratio of \code{odds(p1)/odds(p0)}, log-Odds-ratio
+of \code{log(odds(p1)/odds(p0))}, Risk ratio of \code{p1/p0}, Absolute Risk Reduction
+of \code{p1 - p0}, or Number-needed-to-treat of \code{1/(p1 - p0)}. \code{OR} and \code{logOR}
+can also be a logistic regression model.}
+
+\item{p0}{Baseline risk}
+
+\item{log}{If:
+\itemize{
+\item \code{TRUE}:
+\itemize{
+\item In \verb{oddsratio_to_*()}, \code{OR} input is treated as \code{log(OR)}.
+\item In \verb{*_to_oddsratio()}, returned value is \code{log(OR)}.
+}
+\item \code{FALSE}:
+\itemize{
+\item In \verb{logoddsratio_to_*()}, \code{logOR} input is treated as \code{OR}.
+\item In \verb{*_to_logoddsratio()}, returned value is \code{OR}.
+}
+}}
+
+\item{odds}{Should odds be returned instead of probabilities?}
+
+\item{...}{Arguments passed to and from other methods.}
+}
+\value{
+Probabilities (or probability odds).
+}
+\description{
+Convert Between Metrics of Change in Probabilities and Probabilities
+}
+\examples{
+
+p0 <- 0.4
+p1 <- 0.7
+
+(OR <- probs_to_odds(p1) / probs_to_odds(p0))
+(RR <- p1 / p0)
+(ARR <- p1 - p0)
+(NNT <- arr_to_nnt(ARR))
+
+riskratio_to_probs(RR, p0 = p0)
+oddsratio_to_probs(OR, p0 = p0)
+
+all.equal(nnt_to_probs(NNT, p0 = p0, odds = TRUE),
+          probs_to_odds(p1))
+
+arr_to_probs(-ARR, p0 = p1)
+nnt_to_probs(-NNT, p0 = p1)
+
+
+
+# RR |>
+#   riskratio_to_arr(p0) |>
+#   arr_to_oddsratio(p0) |>
+#   oddsratio_to_nnt(p0) |>
+#   nnt_to_probs(p0)
+
+}
+\seealso{
+\code{\link[=oddsratio]{oddsratio()}}, \code{\link[=riskratio]{riskratio()}}, \code{\link[=arr]{arr()}}, and \code{\link[=nnt]{nnt()}},
+\code{\link[=odds_to_probs]{odds_to_probs()}}, and \code{\link[=oddsratio_to_arr]{oddsratio_to_arr()}} and others.
+}

---FILE: man/oddsratio_to_riskratio.Rd---
@@ -90,6 +90,11 @@ parameter table with the converted indices.
 \description{
 Convert Between Odds Ratios, Risk Ratios and Other Metrics of Change in Probabilities
 }
+\details{
+If an impossible combination of risk ratio \code{RR} and baseline risk \code{p0} is provided,
+such that \code{RR * p0 > 1}, then this conversion will produce invalid results where
+the expected risk is larger than 1. In such cases \verb{riskratio_to_*()} functions will return \code{NA}.
+}
 \examples{
 p0 <- 0.4
 p1 <- 0.7

---FILE: pkgdown/_pkgdown.yml---
@@ -53,25 +53,24 @@ reference:
       - correlation::cor_test
 
   - title: ""Effect Size Conversion""
-
   - subtitle: ""From Test Statistics""
     desc: >
       Extract approximate effect sizes from their commonly associated test statistics
     contents:
       - t_to_r
       - F_to_eta2
       - chisq_to_phi
-
   - subtitle: ""Between Effect Sizes""
     desc: >
       Approximate effect sizes by converting between other related effect sizes
     contents:
-      - d_to_r
-      - oddsratio_to_riskratio
       - d_to_u3
       - eta2_to_f2
-      - odds_to_probs
       - v_to_t
+      - d_to_r
+      - oddsratio_to_riskratio
+      - oddsratio_to_probs
+      - odds_to_probs
 
   - title: ""Interpretation""
     contents:
@@ -86,7 +85,9 @@ reference:
       - is_effectsize_name
       - format_standardize
       - print.effectsize_table
-  - subtitle: ""Datasets""
+      - effectsize_options
+
+  - title: ""Datasets""
     contents:
       - hardlyworking
       - rouder2016
@@ -96,15 +97,12 @@ reference:
       - Music_preferences2
       - Smoking_FASD
       - food_class
-  - subtitle: ""Extra Docs""
-    contents:
-      - effectsize_API
-      - effectsize_options
 
   - title: internal
     contents:
       - effectsize_deprecated
       - effectsize_CIs
+      - effectsize_API
 
 # Keep articles organized
 navbar:

---FILE: tests/testthat/test-convert_between.R---
@@ -1,11 +1,14 @@
+
+# OR, d, r ------------------------------
+
 test_that(""oddsratio_to_d"", {
   expect_equal(oddsratio_to_d(0.2), -0.887, tolerance = 0.01)
   expect_equal(oddsratio_to_d(-1.45, log = TRUE), -0.7994, tolerance = 0.01)
   expect_equal(d_to_oddsratio(-0.887), 0.2, tolerance = 0.01)
   expect_equal(d_to_oddsratio(-0.7994, log = TRUE), -1.45, tolerance = 0.01)
 })
 
-test_that(""exact OR to d"", {
+test_that(""oddsratio_to_d (exact)"", {
   d <- c(0, 0.2, 0.5, 0.8)
   p0 <- pnorm(0, lower.tail = FALSE)
   p1 <- pnorm(0, mean = d, lower.tail = FALSE)
@@ -64,8 +67,32 @@ test_that(""d_to_r"", {
   expect_identical(d_to_r(0.5, n2 = 10), d_to_r(0.5, 10, 10))
 })
 
-test_that(""oddsratio_to_RR"", {
-  skip_on_cran()
+test_that(""OR and logOR <=> d, r"", {
+  expect_equal(
+    oddsratio_to_d(3),
+    logoddsratio_to_d(log(3)),
+    tolerance = 1e-4
+  )
+  expect_equal(
+    log(d_to_oddsratio(3)),
+    d_to_logoddsratio(3),
+    tolerance = 1e-4
+  )
+  expect_equal(
+    oddsratio_to_r(2),
+    logoddsratio_to_r(log(2)),
+    tolerance = 1e-4
+  )
+  expect_equal(
+    log(r_to_oddsratio(0.5)),
+    r_to_logoddsratio(0.5),
+    tolerance = 1e-4
+  )
+})
+
+# OR, RR, ARR, NNT -------------------------
+
+test_that(""OR, RR, ARR, NNT | numeric"", {
   p0 <- 0.4
   p1 <- 0.7
 
@@ -89,33 +116,67 @@ test_that(""oddsratio_to_RR"", {
   expect_equal(oddsratio_to_riskratio(log(OR), p0 = p0, log = TRUE), RR, tolerance = 1e-4)
   expect_equal(arr_to_oddsratio(ARR, p0 = p0, log = TRUE), log(OR), tolerance = 1e-4)
   expect_equal(oddsratio_to_arr(log(OR), p0 = p0, log = TRUE), ARR, tolerance = 1e-4)
+})
+
+
+
+test_that(""OR <=> RR | models"", {
+  skip_on_cran()
 
   # -- GLMs --
   data(mtcars)
 
-  m <<- glm(am ~ factor(cyl),
+  m1 <<- glm(am ~ factor(cyl),
     data = mtcars,
-    family = binomial()
+    family = binomial(""logit"")
   )
 
-  expect_warning(RR <- oddsratio_to_riskratio(m, ci = NULL), ""p0"") # nolint
-  expect_true(""(Intercept)"" %in% RR$Parameter)
-  expect_false(""(p0)"" %in% RR$Parameter)
+  expect_warning(RR <- oddsratio_to_riskratio(m1, ci = NULL), ""p0"") # nolint
+  expect_false(""(Intercept)"" %in% RR$Parameter)
+  expect_true(""(p0)"" %in% RR$Parameter)
 
-  expect_message(RR <- oddsratio_to_riskratio(m, ci_method = ""wald"", p0 = 0.7272727), ""CIs"") # nolint
+  expect_warning(RR <- oddsratio_to_riskratio(m1, ci_method = ""wald"", p0 = 0.7272727), NA) # nolint
   expect_false(""(Intercept)"" %in% RR$Parameter)
   expect_true(""(p0)"" %in% RR$Parameter)
   # these values confirmed from emmeans
   expect_equal(RR$Coefficient, c(0.7272, 0.5892, 0.1964), tolerance = 0.001)
   expect_equal(RR$CI_low, c(NA, 0.1267, 0.0303), tolerance = 0.001)
   expect_equal(RR$CI_high, c(NA, 1.1648, 0.7589), tolerance = 0.001)
 
-  expect_message(RR <- oddsratio_to_riskratio(m, p0 = 0.05), ""CIs"") # nolint
+  expect_warning(RR <- oddsratio_to_riskratio(m1, p0 = 0.05), NA) # nolint
   expect_true(""(p0)"" %in% RR$Parameter)
   expect_false(""(Intercept)"" %in% RR$Parameter)
   # these values confirmed from emmeans
   expect_equal(RR$Coefficient, c(0.05, 0.29173, 0.06557), tolerance = 0.001)
 
+  # -- GLMs2 --
+  data(mtcars)
+
+  m2 <<- glm(am ~ factor(cyl),
+            data = mtcars,
+            family = binomial(""log"")
+  )
+
+  ORt <- parameters::model_parameters(m1, exp = TRUE)
+
+  expect_warning(OR <- riskratio_to_oddsratio(m2, ci = NULL), ""p0"") # nolint
+  expect_false(""(Intercept)"" %in% OR$Parameter)
+  expect_true(""(p0)"" %in% OR$Parameter)
+
+  expect_warning(OR <- riskratio_to_oddsratio(m2, ci_method = ""wald"", p0 = 0.7272727), NA) # nolint
+  expect_false(""(Intercept)"" %in% OR$Parameter)
+  expect_true(""(p0)"" %in% OR$Parameter)
+  # these values confirmed from marginaleffects
+  expect_equal(OR$Coefficient[-1], ORt$Coefficient[-1], tolerance = 0.001)
+  expect_equal(OR$CI_low, c(NA, 0.07642535, 0.01467661), tolerance = 0.001)
+  expect_equal(OR$CI_high, c(NA, NA, 0.443517), tolerance = 0.001)
+
+  expect_warning(OR <- riskratio_to_oddsratio(m2, p0 = 0.05), NA) # nolint
+  expect_true(""(p0)"" %in% OR$Parameter)
+  expect_false(""(Intercept)"" %in% OR$Parameter)
+  # these values confirmed from marginaleffects
+  expect_equal(OR$Coefficient, c(0.05, 0.5768169, 0.1884581), tolerance = 0.001)
+
   # -- GLMMs --
   skip_if_not_installed(""lme4"")
   m <<- lme4::glmer(am ~ factor(cyl) + (1 | gear),
@@ -124,10 +185,10 @@ test_that(""oddsratio_to_RR"", {
   )
 
   expect_warning(RR <- oddsratio_to_riskratio(m, ci = NULL), ""p0"") # nolint
-  expect_true(""(Intercept)"" %in% RR$Parameter)
-  expect_false(""(p0)"" %in% RR$Parameter)
+  expect_false(""(Intercept)"" %in% RR$Parameter)
+  expect_true(""(p0)"" %in% RR$Parameter)
 
-  expect_message(RR <- oddsratio_to_riskratio(m, ci_method = ""wald"", p0 = 0.7047536), ""CIs"") # nolint
+  expect_warning(RR <- oddsratio_to_riskratio(m, ci_method = ""wald"", p0 = 0.7047536), NA) # nolint
   expect_false(""(Intercept)"" %in% RR$Parameter)
   expect_true(""(p0)"" %in% RR$Parameter)
   # these values confirmed from emmeans
@@ -136,32 +197,52 @@ test_that(""oddsratio_to_RR"", {
   expect_equal(RR$CI_high, c(NA, 1.2706, 1.3718), tolerance = 0.001)
 })
 
+test_that(""OR and logOR <=> ARR"", {
+  expect_equal(
+    log(arr_to_oddsratio(0.2, p0 = 0.3)),
+    arr_to_logoddsratio(0.2, p0 = 0.3),
+    tolerance = 1e-4
+  )
+  expect_equal(
+    oddsratio_to_arr(2, p0 = 0.3),
+    logoddsratio_to_arr(log(2), p0 = 0.3),
+    tolerance = 1e-4
+  )
+})
+
+test_that(""=> probs"", {
+  p0 <- 0.4
+  p1 <- 0.7
+
+  OR <- probs_to_odds(p1) / probs_to_odds(p0)
+  RR <- p1 / p0
+  ARR <- p1 - p0
+  NNT <- arr_to_nnt(ARR)
+
+  expect_equal(riskratio_to_probs(RR, p0 = p0), p1)
+  expect_equal(oddsratio_to_probs(OR, p0 = p0), p1)
+
+  expect_equal(nnt_to_probs(NNT, p0 = p0, odds = TRUE),
+               probs_to_odds(p1))
+
+  expect_equal(arr_to_probs(-ARR, p0 = p1), p0)
+  expect_equal(nnt_to_probs(-NNT, p0 = p1), p0)
+})
+
+# Odds, p -------------------------------
+
 test_that(""odds_to_probs"", {
   expect_equal(odds_to_probs(3), 0.75, tolerance = 0.01)
   expect_equal(probs_to_odds(0.75), 3, tolerance = 0.01)
   expect_equal(probs_to_odds(0.75, log = TRUE), 1.098, tolerance = 0.01)
   expect_equal(odds_to_probs(1.098, log = TRUE), 0.75, tolerance = 0.01)
 
   # Data frames
-  df <- odds_to_probs(
-    iris,
-    select = ""Sepal.Length"",
-    exclude = ""Petal.Length"",
-    log = TRUE
-  )
-
-  expect_identical(ncol(df), 5L)
-
-  expect_equal(
-    probs_to_odds(df,
-      select = ""Sepal.Length"",
-      exclude = ""Petal.Length"",
-      log = TRUE
-    ), iris,
-    tolerance = 1e-4
-  )
+  expect_error(odds_to_probs(iris), ""deprecated"")
 })
 
+# ANOVA ------------------------------
+
 test_that(""between anova"", {
   expect_equal(eta2_to_f2(0.25), 1 / 3, tolerance = 1e-4)
   expect_equal(eta2_to_f(0.25), sqrt(eta2_to_f2(0.25)), tolerance = 1e-4)
@@ -170,36 +251,3 @@ test_that(""between anova"", {
   expect_equal(f_to_eta2(1 / sqrt(3)), f2_to_eta2(1 / 3), tolerance = 1e-4)
 })
 
-
-test_that(""OR and logOR"", {
-  expect_equal(
-    oddsratio_to_d(3),
-    logoddsratio_to_d(log(3)),
-    tolerance = 1e-4
-  )
-  expect_equal(
-    log(d_to_oddsratio(3)),
-    d_to_logoddsratio(3),
-    tolerance = 1e-4
-  )
-  expect_equal(
-    oddsratio_to_r(2),
-    logoddsratio_to_r(log(2)),
-    tolerance = 1e-4
-  )
-  expect_equal(
-    log(r_to_oddsratio(0.5)),
-    r_to_logoddsratio(0.5),
-    tolerance = 1e-4
-  )
-  expect_equal(
-    log(arr_to_oddsratio(0.2, p0 = 0.3)),
-    arr_to_logoddsratio(0.2, p0 = 0.3),
-    tolerance = 1e-4
-  )
-  expect_equal(
-    oddsratio_to_arr(2, p0 = 0.3),
-    logoddsratio_to_arr(log(2), p0 = 0.3),
-    tolerance = 1e-4
-  )
-})

---FILE: tests/testthat/test-xtab.R---
@@ -181,7 +181,7 @@ test_that(""oddsratio & riskratio"", {
   expect_equal(RR$CI_low, 0.2777954, tolerance = 1e-4)
   expect_equal(RR$CI_high, 0.5567815, tolerance = 1e-4)
 
-  expect_error(riskratio(RCT, log = TRUE), NA)
+  expect_warning(riskratio(RCT, log = TRUE), ""log"")
 
 
   ## OR",True,False,Documentation / Formatting,7
easystats,effectsize,2ed0e4b0822f87dbc931a4269dd3957f8dbdf7af,Daniel,mail@danielluedecke.de,2025-05-21T12:05:15Z,Daniel,mail@danielluedecke.de,2025-05-21T12:05:15Z,fix,R/eta_squared-main.R,False,True,True,False,8,2,10,"---FILE: R/eta_squared-main.R---
@@ -875,11 +875,17 @@ cohens_f_squared <- function(model,
   # TODO this should be in .anova_es.anvoa
   # TODO the aoc method should convert to an anova table, then pass to anova
   ## TODO: add back `effects = ""fixed""` once the deprecation warning in parameters is removed
-  params <- parameters::model_parameters(model, verbose = verbose, es_type = NULL, include_intercept = include_intercept)
+  params <- parameters::model_parameters(
+    model,
+    verbose = verbose,
+    es_type = NULL,
+    include_intercept = include_intercept
+  )
   out <- .es_aov_simple(as.data.frame(params),
     type = type,
     partial = partial, generalized = generalized,
-    ci = ci, alternative = alternative, verbose = verbose, ...
+    ci = ci, alternative = alternative, verbose = verbose,
+    include_intercept = include_intercept, ...
   )
   if (is.null(attr(out, ""anova_type""))) attr(out, ""anova_type"") <- attr(params, ""anova_type"")
   out",True,False,Implementation / Logic,6
easystats,effectsize,80f15ee1b8437988451bd6884a7ae7b76721224b,Daniel,mail@danielluedecke.de,2025-05-21T09:17:38Z,Daniel,mail@danielluedecke.de,2025-05-21T09:17:38Z,fix URL in JOSS paper,papers/effectsize (2020) JOSS/paper.md,False,False,False,False,15,15,30,"---FILE: papers/effectsize (2020) JOSS/paper.md---
@@ -12,7 +12,7 @@ authors:
   orcid: 0000-0001-5375-9967
 
 date: ""28 October, 2020""
-output: 
+output:
   pdf_document:
     latex_engine: xelatex
 bibliography: paper.bib
@@ -41,8 +41,8 @@ In both theoretical and applied research, it is often of interest to assess the
 
 **effectsize**'s functionality is in part comparable to packages like **lm.beta** [@behrendt2014lmbeta], **MOTE** [@buchanan2019MOTE], and **MBESS** [@kelley2020MBESS]. Yet, there are some notable differences, e.g.:
 
-- **lm.beta** provides standardized regression coefficients for linear models, based on post-hoc model matrix standardization. However, the functionality is available only for a limited number of models (models inheriting from the `lm` class), whereas **effectsize** provides support for many types of models, including (generalized) linear mixed models, Bayesian models, and more. Additionally, in additional to post-hoc model matrix standardization, **effectsize** offers other methods of standardization (see below).  
-- Both **MOTE** and **MBESS** provide functions for computing effect sizes such as Cohen's *d* and effect sizes for ANOVAs [@cohen1988statistical], and their confidence intervals. However, both require manual input of *F*- or *t*-statistics, *degrees of freedom*, and *sums of squares* for the computation the effect sizes, whereas **effectsize** can automatically extract this information from the provided models, thus allowing for better ease-of-use as well as reducing any potential for error.  
+- **lm.beta** provides standardized regression coefficients for linear models, based on post-hoc model matrix standardization. However, the functionality is available only for a limited number of models (models inheriting from the `lm` class), whereas **effectsize** provides support for many types of models, including (generalized) linear mixed models, Bayesian models, and more. Additionally, in additional to post-hoc model matrix standardization, **effectsize** offers other methods of standardization (see below).
+- Both **MOTE** and **MBESS** provide functions for computing effect sizes such as Cohen's *d* and effect sizes for ANOVAs [@cohen1988statistical], and their confidence intervals. However, both require manual input of *F*- or *t*-statistics, *degrees of freedom*, and *sums of squares* for the computation the effect sizes, whereas **effectsize** can automatically extract this information from the provided models, thus allowing for better ease-of-use as well as reducing any potential for error.
 - Finally, in **base R**, the function `scale()` can be used to standardize vectors, matrices and data frame, which can be used to standardize data prior to model fitting. The coefficients of a linear model fit on such data are in effect standardized regression coefficients. **effectsize** expands an this, allowing for robust standardization (using the median and the MAD, instead of the mean and SD), post-hoc parameter standardization, and more.
 
 # Examples of Features
@@ -85,17 +85,17 @@ cramers_v(M)
 Standardizing parameters (i.e., coefficients) can allow for their comparison within and between models, variables and studies. To this end, two functions are available: `standardize()`, which returns an updated model, re-fit with standardized data, and `standardize_parameters()`, which returns a table of standardized coefficients from a provided model [for a list of supported models, see the *insight* package; @luedecke2019insight].
 
 ``` r
-model <- lm(mpg ~ cyl * am, 
+model <- lm(mpg ~ cyl * am,
             data = mtcars)
 
 standardize(model)
-#> 
+#>
 #> Call:
 #> lm(formula = mpg ~ cyl * am, data = data_std)
-#> 
+#>
 #> Coefficients:
-#> (Intercept)          cyl           am       cyl:am  
-#>     -0.0977      -0.7426       0.1739      -0.1930 
+#> (Intercept)          cyl           am       cyl:am
+#>     -0.0977      -0.7426       0.1739      -0.1930
 
 standardize_parameters(model)
 #> Parameter   | Coefficient (std.) |         95% CI
@@ -104,7 +104,7 @@ standardize_parameters(model)
 #> cyl         |              -0.74 | [-0.95, -0.53]
 #> am          |               0.17 | [-0.04,  0.39]
 #> cyl:am      |              -0.19 | [-0.41,  0.02]
-#> 
+#>
 #> # Standardization method: refit
 ```
 
@@ -121,11 +121,11 @@ standardize_parameters(model, exponentiate = TRUE)
 #> (Intercept) |              0.53 | [0.18,  1.32]
 #> cyl         |              0.05 | [0.00,  0.29]
 #> hp          |              6.70 | [1.32, 61.54]
-#> 
+#>
 #> # Standardization method: refit
 ```
 
-`standardize_parameters()` provides several standardization methods, such as robust standardization, or *pseudo*-standardized coefficients for (generalized) linear mixed models [@hoffman2015longitudinal]. A full review of these methods can be found in the [*Parameter and Model Standardization* vignette](https://easystats.github.io/effectsize/articles/standardize_parameters.html).
+`standardize_parameters()` provides several standardization methods, such as robust standardization, or *pseudo*-standardized coefficients for (generalized) linear mixed models [@hoffman2015longitudinal]. A full review of these methods can be found in the [*Parameter and Model Standardization* vignette](https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html).
 
 ## Effect Sizes for ANOVAs
 
@@ -141,7 +141,7 @@ ChickWeight <- subset(ChickWeight, ave(weight, Chick, FUN = length) == 12)
 ChickWeight$Time <- factor(ChickWeight$Time)
 
 model <- aov(weight ~ Diet * Time + Error(Chick / Time),
-             data = ChickWeight) 
+             data = ChickWeight)
 
 eta_squared(model, partial = TRUE)
 #> Group      | Parameter | Eta2 (partial) |       90% CI
@@ -164,7 +164,7 @@ eta_squared(model, generalized = ""Time"")
 
 ### From Test Statistics
 
-In many real world applications there are no straightforward ways of obtaining standardized effect sizes. However, it is possible to get approximations of most of the effect size indices (*d*, *r*, $\eta^2_p$...) with the use of test statistics [@friedman1982simplified]. These conversions are based on the idea that test statistics are a function of effect size and sample size (or more often of degrees of freedom). Thus it is possible to reverse-engineer indices of effect size from test statistics (*F*, *t*, $\chi^2$, and *z*). 
+In many real world applications there are no straightforward ways of obtaining standardized effect sizes. However, it is possible to get approximations of most of the effect size indices (*d*, *r*, $\eta^2_p$...) with the use of test statistics [@friedman1982simplified]. These conversions are based on the idea that test statistics are a function of effect size and sample size (or more often of degrees of freedom). Thus it is possible to reverse-engineer indices of effect size from test statistics (*F*, *t*, $\chi^2$, and *z*).
 
 ``` r
 F_to_eta2(f = c(40.72, 33.77),
@@ -188,7 +188,7 @@ t_to_r(t = -5.14, df_error = 22)
 These functions also power the `effectsize()` convenience function for estimating effect sizes from R's `htest`-type objects. For example:
 
 ``` r
-aov1 <- oneway.test(salary ~ n_comps, 
+aov1 <- oneway.test(salary ~ n_comps,
                     data = hardlyworking, var.equal = TRUE)
 effectsize(aov1)
 #> Eta2 |       90% CI
@@ -229,7 +229,7 @@ Finally, **effectsize** provides convenience functions to apply existing or cust
 
 ``` r
 interpret_d(c(0.02, 0.52, 0.86), rules = ""cohen1988"")
-#> [1] ""very small"" ""medium""     ""large""     
+#> [1] ""very small"" ""medium""     ""large""
 #> (Rules: cohen1988)
 ```
 ",False,False,Documentation / Formatting,6
easystats,effectsize,7e46396d0715375eff3fcfaceabffc9b61c20474,Daniel,mail@danielluedecke.de,2025-05-21T09:16:06Z,Daniel,mail@danielluedecke.de,2025-05-21T09:16:06Z,fix check issues,R/eta_squared-methods.R;inst/WORDLIST,False,True,True,False,2,1,3,"---FILE: R/eta_squared-methods.R---
@@ -168,7 +168,7 @@
 
 #' @keywords internal
 .anova_es.manova <- function(model, ...) {
-  pars <- parameters::model_parameters(model, ...)
+  pars <- parameters::model_parameters(model)
   pars$df <- pars$df_num
   pars <- pars[pars$Parameter != ""Residuals"", ]
   out <- .anova_es(pars, ...)

---FILE: inst/WORDLIST---
@@ -173,6 +173,7 @@ analysed
 anova
 arXiv
 arcsin
+bayestestR
 biserial
 blogspot
 bmwiernik",True,False,Documentation / Formatting,3
easystats,effectsize,ead083c8236b231ec6acc1c271fad134cf671f21,Daniel,mail@danielluedecke.de,2025-05-21T09:03:33Z,Daniel,mail@danielluedecke.de,2025-05-21T09:03:33Z,fix,R/eta_squared-main.R,False,True,True,False,17,3,20,"---FILE: R/eta_squared-main.R---
@@ -833,7 +833,16 @@ cohens_f_squared <- function(model,
     )
 
   ## TODO: add back `effects = ""fixed""` once the deprecation warning in parameters is removed
-  attr(out, ""anova_type"") <- tryCatch(attr(parameters::model_parameters(model, verbose = FALSE, es_type = NULL), ""anova_type""),
+  attr(out, ""anova_type"") <- tryCatch(
+    attr(
+      parameters::model_parameters(
+        model,
+        verbose = FALSE,
+        es_type = NULL,
+        include_intercept = include_intercept
+      ),
+      ""anova_type""
+    ),
     error = function(...) 1
   )
   attr(out, ""approximate"") <- TRUE
@@ -865,7 +874,7 @@ cohens_f_squared <- function(model,
   # TODO this should be in .anova_es.anvoa
   # TODO the aoc method should convert to an anova table, then pass to anova
   ## TODO: add back `effects = ""fixed""` once the deprecation warning in parameters is removed
-  params <- parameters::model_parameters(model, verbose = verbose, es_type = NULL)
+  params <- parameters::model_parameters(model, verbose = verbose, es_type = NULL, ...)
   out <- .es_aov_simple(as.data.frame(params),
     type = type,
     partial = partial, generalized = generalized,
@@ -892,7 +901,12 @@ cohens_f_squared <- function(model,
                               include_intercept = FALSE,
                               ...) {
   ## TODO: add back `effects = ""fixed""` once the deprecation warning in parameters is removed
-  params <- parameters::model_parameters(model, verbose = verbose, es_type = NULL)
+  params <- parameters::model_parameters(
+    model,
+    verbose = verbose,
+    es_type = NULL,
+    include_intercept = include_intercept
+  )
   anova_type <- attr(params, ""anova_type"")
   params <- as.data.frame(params)
 ",True,False,Implementation / Logic,6
easystats,effectsize,4573b2d733ff5f3a322ecba17f2d7a8955a5bfbf,Daniel,mail@danielluedecke.de,2025-05-21T08:48:42Z,Daniel,mail@danielluedecke.de,2025-05-21T08:48:42Z,"Reverse dependency issues with parameters-update
Fixes #668",DESCRIPTION;NEWS.md;R/eta_squared-methods.R,False,True,True,False,42,36,78,"---FILE: DESCRIPTION---
@@ -1,8 +1,8 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size
-Version: 1.0.0.1
-Authors@R: 
+Version: 1.0.0.2
+Authors@R:
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",
              role = c(""aut"", ""cre""),
@@ -28,9 +28,9 @@ Authors@R:
              role = ""aut"",
              email = ""brenton@wiernik.org"",
              comment = c(ORCID = ""0000-0001-9560-6336"")),
-      person(given = ""RÃ©mi"", 
+      person(given = ""RÃ©mi"",
              family = ""ThÃ©riault"",
-             role = ""aut"", 
+             role = ""aut"",
              email = ""remi.theriault@mail.mcgill.ca"",
              comment = c(ORCID = ""0000-0003-4315-6788"")),
       person(given = ""Ken"",
@@ -60,9 +60,9 @@ Authors@R:
              email = ""philip.waggoner@gmail.com"",
              comment = c(ORCID = ""0000-0002-7825-7573"")))
 Maintainer: Mattan S. Ben-Shachar <mattansb@msbstats.info>
-Description: Provide utilities to work with indices of effect size for a wide 
-    variety of models and hypothesis tests (see list of supported models using 
-    the function 'insight::supported_models()'), allowing computation of and 
+Description: Provide utilities to work with indices of effect size for a wide
+    variety of models and hypothesis tests (see list of supported models using
+    the function 'insight::supported_models()'), allowing computation of and
     conversion between indices such as Cohen's d, r, odds, etc.
     References: Ben-Shachar et al. (2020) <doi:10.21105/joss.02815>.
 License: MIT + file LICENSE
@@ -71,9 +71,9 @@ BugReports: https://github.com/easystats/effectsize/issues/
 Depends:
     R (>= 3.6)
 Imports:
-    bayestestR (>= 0.15.2),
-    insight (>= 1.1.0),
-    parameters (>= 0.24.2),
+    bayestestR (>= 0.16.8),
+    insight (>= 1.3.0),
+    parameters (>= 0.26.0),
     performance (>= 0.13.0),
     datawizard (>= 1.0.2),
     stats,
@@ -100,7 +100,7 @@ Suggests:
     rstanarm,
     rstantools,
     testthat (>= 3.1.0)
-VignetteBuilder: 
+VignetteBuilder:
     knitr
 Encoding: UTF-8
 Language: en-US
@@ -112,3 +112,4 @@ Config/Needs/website:
     rstudio/bslib,
     r-lib/pkgdown,
     easystats/easystatstemplate
+Remotes: easystats/parameters#1106

---FILE: NEWS.md---
@@ -1,7 +1,13 @@
 # effectsize 1.0.x
 
+## New features
+
 - `cohens_d()`, `p_superiority()`, `rank_biserial()` and their relatives gain a `reference=` argument to control which level of the group variable should be treated as the reference (thanks @profandyfield for the suggestion).
 
+## Changes
+
+- Fixed failing tests related to the recent update of the *parameters* package.
+
 # effectsize 1.0.0
 
 ***First stable release of `{effectsize}`!***
@@ -38,19 +44,19 @@
 
 ## New features
 
-- `cohens_d()` and `glass_delta()` gain an `adjust` argument for applying Hedges' small-sample bias correction (`hedges_g()` is now an alias for `cohens_d(adjust = TRUE)`).  
+- `cohens_d()` and `glass_delta()` gain an `adjust` argument for applying Hedges' small-sample bias correction (`hedges_g()` is now an alias for `cohens_d(adjust = TRUE)`).
 - `repeated_measures_d()` to compute standardized mean differences (SMD) for repeated measures data.
-  - Also supported in `effectsize(<t.test(paired = TRUE)>)`  
+  - Also supported in `effectsize(<t.test(paired = TRUE)>)`
 - New function: `interpret_fei()`
-  
+
 ## Bug fixes
 
 - Minor stability fix to ncp-based CI methods ( #628 )
 - `nnt()` now properly accepts the `y` argument.
 
 # effectsize 0.8.6
 
-This is a minor update to bring `effectsize` in-line with the formula methods 
+This is a minor update to bring `effectsize` in-line with the formula methods
 in `t.test()` and `wilcox.test()` in `R>=4.4.0`.
 
 ## Breaking Changes
@@ -86,7 +92,7 @@ in `t.test()` and `wilcox.test()` in `R>=4.4.0`.
 
 ## Bug fixes
 
-- `riskratio()` returns correct CIs (#584)  
+- `riskratio()` returns correct CIs (#584)
 - `d_to_r()` correctly treats specifying only `n1`/`n2` as equal group sizes (#571)
 
 # effectsize 0.8.3
@@ -104,15 +110,15 @@ in `t.test()` and `wilcox.test()` in `R>=4.4.0`.
 ## Bug fixes
 
 - ANOVA effect sizes for `afex::mixed()` now return effect sizes for the Intercept where applicable.
-- Fixed error in `cohens_w()` for 2-by-X tables.  
+- Fixed error in `cohens_w()` for 2-by-X tables.
 - Solved integer overflow errors in `rank_biserial()` ( #476 )
 - Fixed issue in `effectsize()` for t-tests when input vectors has unequal amount of missing values.
 
 # effectsize 0.8.2
 
 ## Breaking Changes
 
-- `omega_squared()` and `epsilon_squared()` (and `F_to_omega2()` and `F_to_epsilon2()`) always return non-negative estimates (previously estimates were negative when the observed effect size is very small).  
+- `omega_squared()` and `epsilon_squared()` (and `F_to_omega2()` and `F_to_epsilon2()`) always return non-negative estimates (previously estimates were negative when the observed effect size is very small).
 - `rank_eta_squared()` always returns a non-negative estimate (previously estimates were negative when the observed effect size is very small).
 
 # effectsize 0.8.1
@@ -171,16 +177,16 @@ in `t.test()` and `wilcox.test()` in `R>=4.4.0`.
 ## Bug fixes
 
 - `cohens_d()` for paired / one sample now gives more accurate CIs (was off by a factor of `(N - 1) / N`; #457)
-- `kendalls_w()` now deals correctly with singular ties (#448).  
+- `kendalls_w()` now deals correctly with singular ties (#448).
 
 # effectsize 0.7.0
 
 ## Breaking Changes
 
-- **`standardize_parameters()`, `standardize_posteriors()`, & `standardize_info()` have been moved to the `parameters` package.**  
-- **`standardize()` (for models) has been moved to the `datawizard` package.**  
-- `phi()` only works for 2x2 tables.  
-- `cramers_v()` only works for 2D tables.  
+- **`standardize_parameters()`, `standardize_posteriors()`, & `standardize_info()` have been moved to the `parameters` package.**
+- **`standardize()` (for models) has been moved to the `datawizard` package.**
+- `phi()` only works for 2x2 tables.
+- `cramers_v()` only works for 2D tables.
 
 ## New features
 
@@ -190,23 +196,23 @@ in `t.test()` and `wilcox.test()` in `R>=4.4.0`.
 
 ## Bug fixes
 
-- `kendalls_w()` now deals with ties.  
-- `eta_squared()` works with `car::Manova()` that does not have an i-design. 
+- `kendalls_w()` now deals with ties.
+- `eta_squared()` works with `car::Manova()` that does not have an i-design.
 
 # effectsize 0.6.0.1
 
 *This is a patch release.*
 
 ## Bug fixes
 
-- `interpret.performance_lavaan()` now works without attaching `effectsize` ( #410 ).  
+- `interpret.performance_lavaan()` now works without attaching `effectsize` ( #410 ).
 - `eta_squared()` now fully support multi-variate `car` ANOVAs (class `Anova.mlm`; #406 ).
 
 # effectsize 0.6.0
 
 ## Breaking Changes
 
-- `pearsons_c()` effect size column name changed to `Pearsons_c` for consistency. 
+- `pearsons_c()` effect size column name changed to `Pearsons_c` for consistency.
 
 ## New features
 
@@ -226,8 +232,8 @@ See [*Support functions for model extensions* vignette](https://easystats.github
 
 ## Bug fixes
 
-- `eta_squared()` for MLM return effect sizes in the correct order of the responses.  
-- `eta_squared()` family no longer fails when CIs fail due to non-finite *F*s / degrees of freedom.  
+- `eta_squared()` for MLM return effect sizes in the correct order of the responses.
+- `eta_squared()` family no longer fails when CIs fail due to non-finite *F*s / degrees of freedom.
 - `standardize()` for multivariate models standardizes the (multivariate) response.
 - `standardize()` for models with offsets standardizes offset variables according to `include_response` and `two_sd` ( #396 ).
 - `eta_squared()`: fixed a bug that caused `afex_aov` models with more than 2 within-subject factors to return incorrect effect sizes for the lower level factors ( #389 ).
@@ -246,7 +252,7 @@ See [*Support functions for model extensions* vignette](https://easystats.github
 
 - `pearsons_c()` (and `chisq_to_pearsons_c()`) for estimating Pearson's contingency coefficient.
 - `interpret_vif()` for interpretation of *variance inflation factors*.
-- `oddsratio_to_riskratio()` can now convert OR coefficients to RR coefficients from a logistic GLM(M). 
+- `oddsratio_to_riskratio()` can now convert OR coefficients to RR coefficients from a logistic GLM(M).
 - All effect-size functions gain an `alternative` argument which can be used to make one- or two-sided CIs.
 - `interpret()` now accepts as input the results from `cohens_d()`, `eta_squared()`, `rank_biserial()`, etc.
 - `interpret_pd()` for the interpretation of the [*Probability of Direction*](https://easystats.github.io/bayestestR/reference/p_direction.html).
@@ -267,15 +273,15 @@ See [*Support functions for model extensions* vignette](https://easystats.github
 ## New features
 
 - `eta_squared()` family now indicate the type of sum-of-squares used.
-- `rank_biserial()` estimates CIs using the normal approximation (previously used bootstrapping).  
-- `hedges_g()` now used exact bias correction (thanks to @mdelacre for the suggestion!)  
+- `rank_biserial()` estimates CIs using the normal approximation (previously used bootstrapping).
+- `hedges_g()` now used exact bias correction (thanks to @mdelacre for the suggestion!)
 - `glass_delta()` now estimates CIs using the NCP method based on Algina et al (2006).
 
 ## Bug fixes
 
 - `eta_squared()` family returns correctly returns the type 2/3 effect sizes for mixed ANOVAs fit with `afex`.
 - `cohens_d()` family now correctly deals with missing factor levels ( #318 )
-- `cohens_d()` / `hedges_g()` minor fix for CI with unequal variances.  
+- `cohens_d()` / `hedges_g()` minor fix for CI with unequal variances.
 
 
 ## Changes
@@ -628,4 +634,3 @@ See [*Support functions for model extensions* vignette](https://easystats.github
 ## Bug fixes
 
 - Fix CRAN check issues.
-

---FILE: R/eta_squared-methods.R---
@@ -87,7 +87,7 @@
       # TODO this should be the method for manova,
       # so this should be copied there, and here happsed to:
       # .anova_es.manova
-      aov_tab <- parameters::model_parameters(model)
+      aov_tab <- parameters::model_parameters(model, include_intercept = include_intercept)
       aov_tab$df <- aov_tab$df_num
       out <- .anova_es(aov_tab,
         type = type,
@@ -168,7 +168,7 @@
 
 #' @keywords internal
 .anova_es.manova <- function(model, ...) {
-  pars <- parameters::model_parameters(model)
+  pars <- parameters::model_parameters(model, include_intercept = include_intercept)
   pars$df <- pars$df_num
   pars <- pars[pars$Parameter != ""Residuals"", ]
   out <- .anova_es(pars, ...)",True,False,Dependency / Package,7
easystats,effectsize,672a4ddf039c2ae20e96c91f4d21dbc2964a7d1c,Brenton M. Wiernik,bwiernik@users.noreply.github.com,2025-04-20T05:32:57Z,GitHub,noreply@github.com,2025-04-20T05:32:57Z,"Specify reference level when comparing two groups/levels (#666)

Closes https://github.com/easystats/effectsize/issues/665",DESCRIPTION;NEWS.md;R/cohens_d.R;R/common_language.R;R/means_ratio.R;R/rank_diff.R;R/repeated_measures_d.R;R/utils_validate_input_data.R;README.Rmd;README.md;effectsize.Rproj;man/cohens_d.Rd;man/effectsize.Rd;man/means_ratio.Rd;man/p_superiority.Rd;man/rank_biserial.Rd;man/repeated_measures_d.Rd;tests/testthat/test-utils_validate_input_data.R;vignettes/convert_r_d_OR.Rmd,True,True,True,False,308,91,399,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size
-Version: 1.0.0
+Version: 1.0.0.1
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",

---FILE: NEWS.md---
@@ -1,3 +1,7 @@
+# effectsize 1.0.x
+
+- `cohens_d()`, `p_superiority()`, `rank_biserial()` and their relatives gain a `reference=` argument to control which level of the group variable should be treated as the reference (thanks @profandyfield for the suggestion).
+
 # effectsize 1.0.0
 
 ***First stable release of `{effectsize}`!***

---FILE: R/cohens_d.R---
@@ -1,6 +1,6 @@
 #' Cohen's *d* and Other Standardized Differences
 #'
-#' Compute effect size indices for standardized differences: Cohen's *d*,
+#' Compute effect size indices for standardized mean differences: Cohen's *d*,
 #' Hedges' *g* and Glassâs *delta* (\eqn{\Delta}). (This function returns the
 #' **population** estimate.) Pair with any reported [`stats::t.test()`].
 #' \cr\cr
@@ -9,7 +9,7 @@
 #' correction for small-sample bias (using the exact method) to Cohen's *d*. For
 #' sample sizes > 20, the results for both statistics are roughly equivalent.
 #' Glassâs *delta* is appropriate when the standard deviations are significantly
-#' different between the populations, as it uses only the *second* group's
+#' different between the populations, as it uses only the reference group's
 #' standard deviation.
 #'
 #' @param x,y A numeric vector, or a character name of one in `data`.
@@ -29,6 +29,8 @@
 #' @param adjust Should the effect size be adjusted for small-sample bias using
 #'   Hedges' method? Note that `hedges_g()` is an alias for
 #'   `cohens_d(adjust = TRUE)`.
+#' @param reference (Optional) character value of the ""group"" used as the
+#'   reference. By default, the _second_ group is the reference group.
 #' @param ... Arguments passed to or from other methods. When `x` is a formula,
 #'   these can be `subset` and `na.action`.
 #' @inheritParams chisq_to_phi
@@ -136,6 +138,7 @@
 #' @export
 cohens_d <- function(x, y = NULL, data = NULL,
                      pooled_sd = TRUE, mu = 0, paired = FALSE,
+                     reference = NULL,
                      adjust = FALSE,
                      ci = 0.95, alternative = ""two.sided"",
                      verbose = TRUE, ...) {
@@ -147,6 +150,7 @@ cohens_d <- function(x, y = NULL, data = NULL,
     y = y, data = data,
     type = ""d"", adjust = adjust,
     pooled_sd = pooled_sd, mu = mu, paired = paired,
+    reference = reference,
     ci = ci, alternative = alternative,
     verbose = verbose,
     ...
@@ -157,6 +161,7 @@ cohens_d <- function(x, y = NULL, data = NULL,
 #' @export
 hedges_g <- function(x, y = NULL, data = NULL,
                      pooled_sd = TRUE, mu = 0, paired = FALSE,
+                     reference = NULL,
                      ci = 0.95, alternative = ""two.sided"",
                      verbose = TRUE, ...) {
   cl <- match.call()
@@ -169,13 +174,15 @@ hedges_g <- function(x, y = NULL, data = NULL,
 #' @export
 glass_delta <- function(x, y = NULL, data = NULL,
                         mu = 0, adjust = TRUE,
+                        reference = NULL,
                         ci = 0.95, alternative = ""two.sided"",
                         verbose = TRUE, ...) {
   .effect_size_difference(
     x,
     y = y, data = data,
     type = ""delta"",
     mu = mu, adjust = adjust,
+    reference = reference,
     ci = ci, alternative = alternative,
     verbose = verbose,
     pooled_sd = NULL, paired = FALSE,
@@ -189,10 +196,12 @@ glass_delta <- function(x, y = NULL, data = NULL,
 .effect_size_difference <- function(x, y = NULL, data = NULL,
                                     type = ""d"", adjust = FALSE,
                                     mu = 0, pooled_sd = TRUE, paired = FALSE,
+                                    reference = NULL,
                                     ci = 0.95, alternative = ""two.sided"",
                                     verbose = TRUE, ...) {
   if (type == ""d"" && adjust) type <- ""g""
 
+  # TODO: Check if we can do anything with `reference` for these classes
   if (type != ""delta"") {
     if (.is_htest_of_type(x, ""t-test"")) {
       return(effectsize(x, type = type, verbose = verbose, data = data, ...))
@@ -203,7 +212,7 @@ glass_delta <- function(x, y = NULL, data = NULL,
 
 
   alternative <- .match.alt(alternative)
-  out <- .get_data_2_samples(x, y, data, paired = paired, verbose = verbose, ...)
+  out <- .get_data_2_samples(x, y, data, paired = paired, reference = reference, verbose = verbose, ...)
   x <- out[[""x""]]
   y <- out[[""y""]]
   paired <- out[[""paired""]]
@@ -308,7 +317,7 @@ glass_delta <- function(x, y = NULL, data = NULL,
     paired, pooled_sd, mu, ci, ci_method, alternative, adjust,
     approximate = FALSE
   )
-  return(out)
+  out
 }
 
 #' @keywords internal

---FILE: R/common_language.R---
@@ -41,7 +41,7 @@
 #'
 #' Where \eqn{U_1}, \eqn{U_2}, and *Overlap* are agnostic to the direction of
 #' the difference between the groups, \eqn{U_3} and probability of superiority
-#' are not.
+#' are not (this can be controlled with the `reference` argument).
 #'
 #' The parametric version of these effects assumes normality of both populations
 #' and homoscedasticity. If those are not met, the non parametric versions
@@ -111,6 +111,7 @@
 #' @aliases cles
 p_superiority <- function(x, y = NULL, data = NULL,
                           mu = 0, paired = FALSE, parametric = TRUE,
+                          reference = NULL,
                           ci = 0.95, alternative = ""two.sided"",
                           verbose = TRUE, ...) {
   if (.is_htest_of_type(x, ""(t-test|Wilcoxon)"", ""t-test or a Wilcoxon-test"")) {
@@ -120,7 +121,7 @@ p_superiority <- function(x, y = NULL, data = NULL,
   }
 
   data <- .get_data_2_samples(x, y, data,
-    paired = paired,
+    paired = paired, reference = reference,
     allow_ordered = !parametric,
     verbose = verbose, ...
   )
@@ -244,6 +245,7 @@ cohens_u2 <- function(x, y = NULL, data = NULL,
 #' @rdname p_superiority
 cohens_u3 <- function(x, y = NULL, data = NULL,
                       mu = 0, parametric = TRUE,
+                      reference = NULL,
                       ci = 0.95, alternative = ""two.sided"", iterations = 200,
                       verbose = TRUE, ...) {
   if (.is_htest_of_type(x, ""(t-test|Wilcoxon)"", ""t-test or a Wilcoxon-test"")) {
@@ -254,7 +256,7 @@ cohens_u3 <- function(x, y = NULL, data = NULL,
 
 
   data <- .get_data_2_samples(x, y, data,
-    allow_ordered = !parametric,
+    allow_ordered = !parametric, reference = reference,
     verbose = verbose, ...
   )
   x <- data[[""x""]]
@@ -455,13 +457,13 @@ wmw_odds <- function(x, y = NULL, data = NULL,
 
       out$CI <- ci
 
-      R <- boot::boot(
+      res <- boot::boot(
         data = d,
         statistic = est,
         R = iterations
       )
 
-      bCI <- boot::boot.ci(R, conf = ci, type = ""perc"")[[""percent""]]
+      bCI <- boot::boot.ci(res, conf = ci, type = ""perc"")[[""percent""]]
       bCI <- utils::tail(as.vector(bCI), 2)
       out$CI_low <- bCI[1]
       out$CI_high <- bCI[2]
@@ -478,5 +480,5 @@ wmw_odds <- function(x, y = NULL, data = NULL,
       approximate = TRUE,
       table_footer = ""Non-parametric CLES""
     )
-    return(out)
+    out
   }

---FILE: R/means_ratio.R---
@@ -14,8 +14,8 @@
 #'
 #' @details
 #' The Means Ratio ranges from 0 to \eqn{\infty}, with values smaller than 1
-#' indicating that the second mean is larger than the first, values larger than
-#' 1 indicating that the second mean is smaller than the first, and values of 1
+#' indicating that the mean of the reference group is larger, values larger than
+#' 1 indicating that the mean of the reference group is smaller, and values of 1
 #' indicating that the means are equal.
 #'
 #' # Confidence (Compatibility) Intervals (CIs)
@@ -63,15 +63,16 @@
 #' @export
 means_ratio <- function(x, y = NULL, data = NULL,
                         paired = FALSE, adjust = TRUE, log = FALSE,
+                        reference = NULL,
                         ci = 0.95, alternative = ""two.sided"",
                         verbose = TRUE, ...) {
   alternative <- .match.alt(alternative)
 
   ## Prep data
   out <- .get_data_2_samples(
     x = x, y = y, data = data,
+    paired = paired, reference = reference,
     verbose = verbose,
-    paired = paired,
     ...
   )
   x <- out[[""x""]]
@@ -104,14 +105,14 @@ means_ratio <- function(x, y = NULL, data = NULL,
 
     # Calc log RR
     log_val <- .logrom_calc(
-      paired = TRUE,
       m1 = m1,
       sd1 = sd1,
       m2 = m2,
       sd2 = sd2,
       n1 = n,
       r = r,
-      adjust = adjust
+      adjust = adjust,
+      paired = TRUE
     )
   } else {
     ## ------------------------ 2-sample case -------------------------
@@ -121,14 +122,14 @@ means_ratio <- function(x, y = NULL, data = NULL,
 
     # Calc log RR
     log_val <- .logrom_calc(
-      paired = FALSE,
       m1 = m1,
       sd1 = sd1,
       n1 = n1,
       m2 = m2,
       sd2 = sd2,
       n2 = n2,
-      adjust = adjust
+      adjust = adjust,
+      paired = FALSE
     )
   }
 
@@ -175,44 +176,44 @@ means_ratio <- function(x, y = NULL, data = NULL,
     mu = 0,
     approximate = TRUE
   )
-  return(out)
+  out
 }
 
 
 #' @keywords internal
-.logrom_calc <- function(paired = FALSE,
-                         m1,
+.logrom_calc <- function(m1,
                          sd1,
                          n1,
                          m2,
                          sd2,
                          n2 = n1,
                          r = NULL,
-                         adjust = TRUE) {
+                         adjust = TRUE,
+                         paired = FALSE) {
   if (isTRUE(paired)) {
-    yi <- log(m1 / m2)
-    vi <-
+    y_i <- log(m1 / m2)
+    v_i <-
       sd1^2 / (n1 * m1^2) +
       sd2^2 / (n1 * m2^2) -
       2 * r * sd1 * sd2 / (m1 * m2 * n1)
   } else {
-    yi <- log(m1 / m2)
+    y_i <- log(m1 / m2)
     ### large sample approximation to the sampling variance (does not assume homoscedasticity)
-    vi <- sd1^2 / (n1 * m1^2) + sd2^2 / (n2 * m2^2)
+    v_i <- sd1^2 / (n1 * m1^2) + sd2^2 / (n2 * m2^2)
   }
 
 
   if (isTRUE(adjust)) {
     J <- 0.5 * (sd1^2 / (n1 * m1^2) - sd2^2 / (n2 * m2^2))
-    yi <- yi + J
+    y_i <- y_i + J
 
     Jvar <- 0.5 * (sd1^4 / (n1^2 * m1^4) - sd2^4 / (n2^2 * m2^4))
-    vi <- vi + Jvar
+    v_i <- v_i + Jvar
   }
 
 
   list(
-    log_rom = yi,
-    var_rom = vi
+    log_rom = y_i,
+    var_rom = v_i
   )
 }

---FILE: R/rank_diff.R---
@@ -120,6 +120,7 @@
 #' @export
 rank_biserial <- function(x, y = NULL, data = NULL,
                           mu = 0, paired = FALSE,
+                          reference = NULL,
                           ci = 0.95, alternative = ""two.sided"",
                           verbose = TRUE, ...) {
   alternative <- .match.alt(alternative)
@@ -131,6 +132,7 @@ rank_biserial <- function(x, y = NULL, data = NULL,
   ## Prep data
   out <- .get_data_2_samples(x, y, data,
     paired = paired,
+    reference = reference,
     allow_ordered = TRUE,
     verbose = verbose, ...
   )
@@ -201,19 +203,21 @@ rank_biserial <- function(x, y = NULL, data = NULL,
   attr(out, ""ci_method"") <- ci_method
   attr(out, ""approximate"") <- FALSE
   attr(out, ""alternative"") <- alternative
-  return(out)
+  out
 }
 
 #' @export
 #' @rdname rank_biserial
 cliffs_delta <- function(x, y = NULL, data = NULL,
                          mu = 0,
+                         reference = NULL,
                          ci = 0.95, alternative = ""two.sided"",
                          verbose = TRUE, ...) {
   cl <- match.call()
   data <- .get_data_2_samples(x, y, data,
     verbose = verbose,
     allow_ordered = TRUE,
+    reference = reference,
     ...
   )
   x <- data$x
@@ -255,5 +259,5 @@ cliffs_delta <- function(x, y = NULL, data = NULL,
 
   u_ <- U1 / S
   f_ <- U2 / S
-  return(u_ - f_)
+  u_ - f_
 }

---FILE: R/repeated_measures_d.R---
@@ -157,6 +157,7 @@ repeated_measures_d <- function(x, y,
                                 data = NULL,
                                 mu = 0, method = c(""rm"", ""av"", ""z"", ""b"", ""d"", ""r""),
                                 adjust = TRUE,
+                                reference = NULL,
                                 ci = 0.95, alternative = ""two.sided"",
                                 verbose = TRUE, ...) {
   method <- match.arg(method)
@@ -165,7 +166,11 @@ repeated_measures_d <- function(x, y,
   }
 
   alternative <- .match.alt(alternative)
-  data <- .get_data_paired(x, y, data = data, method = method, verbose = verbose, ...)
+  data <- .get_data_paired(x, y,
+    data = data, method = method,
+    reference = reference,
+    verbose = verbose, ...
+  )
 
   if (method %in% c(""d"", ""r"")) {
     values <- .replication_d(data, mu = mu, method = method)
@@ -217,7 +222,7 @@ repeated_measures_d <- function(x, y,
     mu, ci, ci_method, alternative,
     approximate = FALSE
   )
-  return(out)
+  out
 }
 
 #' @rdname repeated_measures_d

---FILE: R/utils_validate_input_data.R---
@@ -1,6 +1,7 @@
 #' @keywords internal
 .get_data_2_samples <- function(x, y = NULL, data = NULL,
-                                paired = FALSE, allow_ordered = FALSE,
+                                paired = FALSE, reference = NULL,
+                                allow_ordered = FALSE,
                                 verbose = TRUE, ...) {
   if (inherits(x, ""formula"")) {
     if (isTRUE(paired)) {
@@ -31,6 +32,10 @@
       y <- mf[[2]]
       if (!is.factor(y)) y <- factor(y)
     }
+    if (inherits(x, ""Pair"")) {
+      s <- colnames(mf)[1]
+      colnames(x) <- regmatches(s, regexec(""Pair\\((.*), (.*)\\)"", s))[[1]][-1]
+    }
   } else {
     # Test if they are they are column names
     x <- .resolve_char(x, data)
@@ -54,8 +59,13 @@
   if (!is.numeric(x)) {
     insight::format_error(""Cannot compute effect size for a non-numeric vector."")
   } else if (inherits(x, ""Pair"")) {
-    y <- x[, 2]
-    x <- x[, 1]
+    if (is.null(reference)) {
+      y <- x[, 2]
+      x <- x[, 1]
+    } else {
+      y <- x[, reference]
+      x <- x[, setdiff(colnames(x), reference)]
+    }
     paired <- TRUE
   }
 
@@ -72,10 +82,17 @@
       }
 
       data <- Filter(length, split(x, y))
-      x <- data[[1]]
-      y <- data[[2]]
+
+      if (is.null(reference)) {
+        x <- data[[1]]
+        y <- data[[2]]
+      } else {
+        y <- data[[reference]]
+        x <- data[[setdiff(names(data), reference)]]
+      }
     }
 
+    # TODO: I think this warning is outdated.
     if (verbose && insight::n_unique(y) == 2) {
       insight::format_warning(
         ""'y' is numeric but has only 2 unique values."",
@@ -97,12 +114,12 @@
     y <- stats::na.omit(y)
   }
 
-
   list(x = x, y = y, paired = paired)
 }
 
 #' @keywords internal
-.get_data_paired <- function(x, y = NULL, data = NULL, method,
+.get_data_paired <- function(x, y = NULL, data = NULL, method = NULL,
+                             reference = NULL,
                              verbose = TRUE, ...) {
   if (inherits(x, ""formula"")) {
     formula_error <-
@@ -119,9 +136,14 @@
       mf <- .resolve_formula(x, data, ...)
       mf <- stats::na.omit(mf)
 
+      mf[[2]] <- as.factor(mf[[2]])
+      mf[[3]] <- as.factor(mf[[3]])
+
+      if (!is.null(reference)) {
+        mf[[2]] <- stats::relevel(mf[[2]], ref = reference)
+      }
+
       if (method %in% c(""d"", ""r"")) {
-        mf[[2]] <- as.factor(mf[[2]])
-        mf[[3]] <- as.factor(mf[[3]])
         colnames(mf) <- c(""y"", ""condition"", ""id"")
         return(mf)
       }
@@ -144,6 +166,8 @@
         insight::format_error(formula_error)
       }
       x <- mf[[1]]
+      s <- colnames(mf)[1]
+      colnames(x) <- regmatches(s, regexec(""Pair\\((.*), (.*)\\)"", s))[[1]][-1]
     } else {
       insight::format_error(formula_error)
     }
@@ -154,8 +178,13 @@
   }
 
   if (inherits(x, ""Pair"")) {
-    y <- x[, 2]
-    x <- x[, 1]
+    if (is.null(reference)) {
+      y <- x[, 2]
+      x <- x[, 1]
+    } else {
+      y <- x[, reference]
+      x <- x[, setdiff(colnames(x), reference)]
+    }
   }
 
   # x should be a numeric vector or a Pair:

---FILE: README.Rmd---
@@ -138,7 +138,7 @@ And more...
 
 <!-- ### Regression Models (Standardized Parameters) -->
 
-<!-- Importantly, `effectsize` also provides [advanced methods](https://easystats.github.io/effectsize/articles/standardize_parameters.html) to compute standardized parameters for regression models. -->
+<!-- Importantly, `effectsize` also provides [advanced methods](https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html) to compute standardized parameters for regression models. -->
 
 <!-- ```{r beta, warning=FALSE, message=FALSE} -->
 <!-- m <- lm(rating ~ complaints + privileges + advance, data = attitude) -->

---FILE: README.md---
@@ -183,7 +183,7 @@ epsilon_squared(model)
 And moreâ¦
 
 <!-- ### Regression Models (Standardized Parameters) -->
-<!-- Importantly, `effectsize` also provides [advanced methods](https://easystats.github.io/effectsize/articles/standardize_parameters.html) to compute standardized parameters for regression models. -->
+<!-- Importantly, `effectsize` also provides [advanced methods](https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html) to compute standardized parameters for regression models. -->
 <!-- ```{r beta, warning=FALSE, message=FALSE} -->
 <!-- m <- lm(rating ~ complaints + privileges + advance, data = attitude) -->
 <!-- standardize_parameters(m) -->

---FILE: effectsize.Rproj---
@@ -1,4 +1,5 @@
 Version: 1.0
+ProjectId: e6b7b313-8c9f-4949-9c7b-3c2ff95eac8a
 
 RestoreWorkspace: No
 SaveWorkspace: No

---FILE: man/cohens_d.Rd---
@@ -13,6 +13,7 @@ cohens_d(
   pooled_sd = TRUE,
   mu = 0,
   paired = FALSE,
+  reference = NULL,
   adjust = FALSE,
   ci = 0.95,
   alternative = ""two.sided"",
@@ -27,6 +28,7 @@ hedges_g(
   pooled_sd = TRUE,
   mu = 0,
   paired = FALSE,
+  reference = NULL,
   ci = 0.95,
   alternative = ""two.sided"",
   verbose = TRUE,
@@ -39,6 +41,7 @@ glass_delta(
   data = NULL,
   mu = 0,
   adjust = TRUE,
+  reference = NULL,
   ci = 0.95,
   alternative = ""two.sided"",
   verbose = TRUE,
@@ -63,6 +66,9 @@ variance). Else the mean SD from both groups is used instead.}
 This produces an effect size that is equivalent to the one-sample effect
 size on \code{x - y}. See also \code{\link[=repeated_measures_d]{repeated_measures_d()}} for more options.}
 
+\item{reference}{(Optional) character value of the ""group"" used as the
+reference. By default, the \emph{second} group is the reference group.}
+
 \item{adjust}{Should the effect size be adjusted for small-sample bias using
 Hedges' method? Note that \code{hedges_g()} is an alias for
 \code{cohens_d(adjust = TRUE)}.}
@@ -84,7 +90,7 @@ A data frame with the effect size ( \code{Cohens_d}, \code{Hedges_g},
 \code{Glass_delta}) and their CIs (\code{CI_low} and \code{CI_high}).
 }
 \description{
-Compute effect size indices for standardized differences: Cohen's \emph{d},
+Compute effect size indices for standardized mean differences: Cohen's \emph{d},
 Hedges' \emph{g} and Glassâs \emph{delta} (\eqn{\Delta}). (This function returns the
 \strong{population} estimate.) Pair with any reported \code{\link[stats:t.test]{stats::t.test()}}.
 \cr\cr
@@ -93,7 +99,7 @@ difference between the means of two populations. Hedges' \emph{g} provides a
 correction for small-sample bias (using the exact method) to Cohen's \emph{d}. For
 sample sizes > 20, the results for both statistics are roughly equivalent.
 Glassâs \emph{delta} is appropriate when the standard deviations are significantly
-different between the populations, as it uses only the \emph{second} group's
+different between the populations, as it uses only the reference group's
 standard deviation.
 }
 \details{

---FILE: man/effectsize.Rd---
@@ -26,11 +26,11 @@ to be estimated. Default to \code{0.95} (\verb{95\%}).}
 
 \item{test}{The indices of effect existence to compute. Character (vector) or
 list with one or more of these options: \code{""p_direction""} (or \code{""pd""}),
-\code{""rope""}, \code{""p_map""}, \code{""equivalence_test""} (or \code{""equitest""}),
-\code{""bayesfactor""} (or \code{""bf""}) or \code{""all""} to compute all tests. For each
-""test"", the corresponding \pkg{bayestestR} function is called (e.g.
-\code{\link[bayestestR:rope]{rope()}} or \code{\link[bayestestR:p_direction]{p_direction()}}) and its results included in the summary
-output.}
+\code{""rope""}, \code{""p_map""}, \code{""p_significance""} (or \code{""ps""}), \code{""p_rope""},
+\code{""equivalence_test""} (or \code{""equitest""}), \code{""bayesfactor""} (or \code{""bf""}) or
+\code{""all""} to compute all tests. For each ""test"", the corresponding
+\strong{bayestestR} function is called (e.g. \code{\link[bayestestR:rope]{rope()}} or \code{\link[bayestestR:p_direction]{p_direction()}})
+and its results included in the summary output.}
 
 \item{verbose}{Toggle off warnings.}
 

---FILE: man/means_ratio.Rd---
@@ -11,6 +11,7 @@ means_ratio(
   paired = FALSE,
   adjust = TRUE,
   log = FALSE,
+  reference = NULL,
   ci = 0.95,
   alternative = ""two.sided"",
   verbose = TRUE,
@@ -34,6 +35,9 @@ Defaults to \code{TRUE}; Advisable for small samples.}
 \item{log}{Should the log-ratio be returned? Defaults to \code{FALSE}.
 Normally distributed and useful for meta-analysis.}
 
+\item{reference}{(Optional) character value of the ""group"" used as the
+reference. By default, the \emph{second} group is the reference group.}
+
 \item{ci}{Confidence Interval (CI) level}
 
 \item{alternative}{a character string specifying the alternative hypothesis;
@@ -57,8 +61,8 @@ Computes the ratio of two means (also known as the ""response ratio""; RR) of
 }
 \details{
 The Means Ratio ranges from 0 to \eqn{\infty}, with values smaller than 1
-indicating that the second mean is larger than the first, values larger than
-1 indicating that the second mean is smaller than the first, and values of 1
+indicating that the mean of the reference group is larger, values larger than
+1 indicating that the mean of the reference group is smaller, and values of 1
 indicating that the means are equal.
 }
 \note{

---FILE: man/p_superiority.Rd---
@@ -18,6 +18,7 @@ p_superiority(
   mu = 0,
   paired = FALSE,
   parametric = TRUE,
+  reference = NULL,
   ci = 0.95,
   alternative = ""two.sided"",
   verbose = TRUE,
@@ -56,6 +57,7 @@ cohens_u3(
   data = NULL,
   mu = 0,
   parametric = TRUE,
+  reference = NULL,
   ci = 0.95,
   alternative = ""two.sided"",
   iterations = 200,
@@ -117,6 +119,9 @@ size on \code{x - y}.}
 \item{parametric}{Use parametric estimation (see \code{\link[=cohens_d]{cohens_d()}}) or
 non-parametric estimation (see \code{\link[=rank_biserial]{rank_biserial()}}). See details.}
 
+\item{reference}{(Optional) character value of the ""group"" used as the
+reference. By default, the \emph{second} group is the reference group.}
+
 \item{ci}{Confidence Interval (CI) level}
 
 \item{alternative}{a character string specifying the alternative hypothesis;
@@ -171,7 +176,7 @@ first group.
 
 Where \eqn{U_1}, \eqn{U_2}, and \emph{Overlap} are agnostic to the direction of
 the difference between the groups, \eqn{U_3} and probability of superiority
-are not.
+are not (this can be controlled with the \code{reference} argument).
 
 The parametric version of these effects assumes normality of both populations
 and homoscedasticity. If those are not met, the non parametric versions

---FILE: man/rank_biserial.Rd---
@@ -11,6 +11,7 @@ rank_biserial(
   data = NULL,
   mu = 0,
   paired = FALSE,
+  reference = NULL,
   ci = 0.95,
   alternative = ""two.sided"",
   verbose = TRUE,
@@ -22,6 +23,7 @@ cliffs_delta(
   y = NULL,
   data = NULL,
   mu = 0,
+  reference = NULL,
   ci = 0.95,
   alternative = ""two.sided"",
   verbose = TRUE,
@@ -44,6 +46,9 @@ estimated. See \link[stats:wilcox.test]{stats::wilcox.test}.}
 This produces an effect size that is equivalent to the one-sample effect
 size on \code{x - y}.}
 
+\item{reference}{(Optional) character value of the ""group"" used as the
+reference. By default, the \emph{second} group is the reference group.}
+
 \item{ci}{Confidence Interval (CI) level}
 
 \item{alternative}{a character string specifying the alternative hypothesis;

---FILE: man/repeated_measures_d.Rd---
@@ -12,6 +12,7 @@ repeated_measures_d(
   mu = 0,
   method = c(""rm"", ""av"", ""z"", ""b"", ""d"", ""r""),
   adjust = TRUE,
+  reference = NULL,
   ci = 0.95,
   alternative = ""two.sided"",
   verbose = TRUE,
@@ -25,6 +26,7 @@ rm_d(
   mu = 0,
   method = c(""rm"", ""av"", ""z"", ""b"", ""d"", ""r""),
   adjust = TRUE,
+  reference = NULL,
   ci = 0.95,
   alternative = ""two.sided"",
   verbose = TRUE,
@@ -49,6 +51,9 @@ details.}
 
 \item{adjust}{Apply Hedges' small-sample bias correction? See \code{\link[=hedges_g]{hedges_g()}}.}
 
+\item{reference}{(Optional) character value of the ""group"" used as the
+reference. By default, the \emph{second} group is the reference group.}
+
 \item{ci}{Confidence Interval (CI) level}
 
 \item{alternative}{a character string specifying the alternative hypothesis;

---FILE: tests/testthat/test-utils_validate_input_data.R---
@@ -4,7 +4,8 @@ test_that("".get_data_2_samples"", {
     b = 2:11,
     c = rep(letters[1:2], each = 5),
     d = c(""a"", ""b"", ""b"", ""c"", ""c"", ""b"", ""c"", ""a"", ""a"", ""b""),
-    e = rep(0:1, each = 5)
+    e = rep(0:1, each = 5),
+    stringsAsFactors = FALSE
   )
   df$exp_a <- exp(df$a)
   a2 <- 1:11
@@ -14,16 +15,16 @@ test_that("".get_data_2_samples"", {
   expect_error(d3 <- cohens_d(df$a ~ df$c), regexp = NA)
   expect_error(d4 <- cohens_d(df$a, df$c), regexp = NA)
   expect_error(d5 <- cohens_d(df$a[df$c == ""a""], df$a[df$c == ""b""]), regexp = NA)
-  expect_equal(d1, d2)
-  expect_equal(d1, d3)
-  expect_equal(d1, d4)
-  expect_equal(d1, d5)
+  expect_identical(d1, d2)
+  expect_identical(d1, d3)
+  expect_identical(d1, d4)
+  expect_identical(d1, d5)
 
   expect_error(cohens_d(""a"", ""b"", data = df), regexp = NA)
   expect_error(cohens_d(a2, df$b), regexp = NA)
   expect_error(cohens_d(b ~ e, data = df), regexp = NA)
 
-  expect_equal(
+  expect_identical(
     cohens_d(exp(a) ~ c, data = df),
     cohens_d(""exp_a"", ""c"", data = df)
   )
@@ -43,8 +44,8 @@ test_that("".get_data_2_samples"", {
 
   expect_warning(d1 <- cohens_d(x, y), ""dropped"")
   expect_warning(d2 <- cohens_d(x, y, paired = TRUE), ""dropped"")
-  expect_equal(d1, cohens_d(1:4, 1:5), tolerance = 0.01) # indep
-  expect_equal(d2, cohens_d(1:4, c(1, 3:5), paired = TRUE), tolerance = 0.01) # paired
+  expect_identical(d1, cohens_d(1:4, 1:5)) # indep
+  expect_identical(d2, cohens_d(1:4, c(1, 3:5), paired = TRUE, verbose = FALSE)) # paired
 
   # no length problems
   expect_error(cohens_d(mtcars$mpg - 23), regexp = NA)
@@ -105,17 +106,118 @@ test_that("".get_data_2_samples | subset"", {
       )
   )
 
-  expect_equal(d1, d2)
-  expect_equal(d1, d3)
-  expect_equal(d1, d4)
+  expect_identical(d1, d2)
+  expect_identical(d1, d3)
+  expect_identical(d1, d4)
+})
+
+test_that("".get_data_2_samples | reference"", {
+  # create data
+  my_tib <- data.frame(
+    group = gl(2, 12, labels = c(""No treatment"", ""Treatment"")),
+    outcome = c(3, 1, 5, 4, 6, 4, 6, 2, 0, 5, 4, 5, 4, 3, 6, 6, 8, 5, 5, 4, 2, 5, 7, 5)
+  )
+  my_tib$group_chr <- as.character(my_tib$group)
+
+  # fomula input w/ factor
+  expect_identical(
+    cohens_d(outcome ~ group, data = my_tib)[[1]],
+    -cohens_d(outcome ~ group, data = my_tib, reference = ""No treatment"")[[1]]
+  )
+
+  # fomula input w/ character
+  expect_identical(
+    cohens_d(outcome ~ group_chr, data = my_tib)[[1]],
+    -cohens_d(outcome ~ group_chr, data = my_tib, reference = ""No treatment"")[[1]]
+  )
+
+  # vector input w/ factor
+  expect_identical(
+    cohens_d(my_tib$outcome, my_tib$group)[[1]],
+    -cohens_d(my_tib$outcome, my_tib$group, reference = ""No treatment"")[[1]]
+  )
+
+  # vector input w/ character
+  expect_identical(
+    cohens_d(my_tib$outcome, my_tib$group_chr)[[1]],
+    -cohens_d(my_tib$outcome, my_tib$group_chr, reference = ""No treatment"")[[1]]
+  )
+
+  # name input w/ factor
+  expect_identical(
+    cohens_d(""outcome"", ""group"", data = my_tib)[[1]],
+    -cohens_d(""outcome"", ""group"", data = my_tib, reference = ""No treatment"")[[1]]
+  )
+
+  # name input w/ character
+  expect_identical(
+    cohens_d(""outcome"", ""group_chr"", data = my_tib)[[1]],
+    -cohens_d(""outcome"", ""group_chr"", data = my_tib, reference = ""No treatment"")[[1]]
+  )
+
+  # sign is opposite, same value
+  expect_identical(
+    rank_biserial(outcome ~ group_chr, data = my_tib)[[1]],
+    -rank_biserial(outcome ~ group_chr, data = my_tib, reference = ""No treatment"")[[1]]
+  )
+
+  # inverse
+  expect_equal(
+    means_ratio(outcome ~ group_chr, data = my_tib)[[1]],
+    1 / means_ratio(outcome ~ group_chr, data = my_tib, reference = ""No treatment"")[[1]],
+    tolerance = 0.001
+  )
+
+  # sum to 1
+  expect_equal(
+    cohens_u3(outcome ~ group_chr, data = my_tib)[[1]],
+    1 - cohens_u3(outcome ~ group_chr, data = my_tib, reference = ""No treatment"")[[1]],
+    tolerance = 0.001
+  )
+
+  # sum to 1
+  expect_equal(
+    p_superiority(outcome ~ group_chr, data = my_tib)[[1]],
+    1 - p_superiority(outcome ~ group_chr, data = my_tib, reference = ""No treatment"")[[1]],
+    tolerance = 0.001
+  )
+
+  # sign is opposite but so is value
+  delta1 <- glass_delta(outcome ~ group_chr, data = my_tib)[[1]]
+  delta2 <- glass_delta(outcome ~ group_chr, data = my_tib, reference = ""No treatment"")[[1]]
+  expect_identical(sign(delta1), -sign(delta2))
+  expect_true(abs(delta1) != abs(delta2))
+
+
+
+
+  data(""sleep"")
+  sleep2 <- reshape(sleep,
+    direction = ""wide"",
+    idvar = ""ID"", timevar = ""group""
+  )
+
+  # formula w/ Pair()
+  expect_identical(
+    hedges_g(Pair(extra.1, extra.2) ~ 1, data = sleep2, verbose = FALSE)[[1]],
+    -hedges_g(Pair(extra.1, extra.2) ~ 1, data = sleep2, verbose = FALSE, reference = ""extra.1"")[[1]]
+  )
+
+
+  # formula w/ arbitrary Pair()
+  expect_identical(
+    cohens_d(Pair(extra[group == 1] + pi, extra[group == 2]) ~ 1, data = sleep, verbose = FALSE)[[1]],
+    -cohens_d(Pair(extra[group == 1] + pi, extra[group == 2]) ~ 1, data = sleep, verbose = FALSE, reference = ""extra[group == 1] + pi"")[[1]]
+  )
 })
 
 test_that("".get_data_multi_group"", {
   df <- data.frame(
     a = 1:15,
     b = 2:16,
     c = rep(letters[1:3], each = 5),
-    e = rep(0:1, length = 15)
+    e = rep(0:1, length = 15),
+    stringsAsFactors = FALSE
   )
   df$exp_a <- exp(df$a)
 
@@ -125,14 +227,14 @@ test_that("".get_data_multi_group"", {
   expect_error(d4 <- rank_epsilon_squared(df$a, df$c, ci = NULL), regexp = NA)
   L <- split(df$a, df$c)
   expect_error(d5 <- rank_epsilon_squared(L, ci = NULL), regexp = NA)
-  expect_equal(d1, d2, tolerance = 0.01)
-  expect_equal(d1, d3, tolerance = 0.01)
-  expect_equal(d1, d4, tolerance = 0.01)
-  expect_equal(d1, d5, tolerance = 0.01)
+  expect_identical(d1, d2)
+  expect_identical(d1, d3)
+  expect_identical(d1, d4)
+  expect_identical(d1, d5)
 
   expect_error(rank_epsilon_squared(b ~ e, data = df), regexp = NA)
 
-  expect_equal(
+  expect_identical(
     rank_epsilon_squared(exp(a) ~ c, data = df, ci = NULL),
     rank_epsilon_squared(""exp_a"", ""c"", data = df, ci = NULL)
   )
@@ -142,14 +244,14 @@ test_that("".get_data_multi_group"", {
 
   df[1, ] <- NA
   expect_warning(E1 <- rank_epsilon_squared(a ~ c, data = df, ci = NULL), ""dropped"")
-  expect_equal(E1, rank_epsilon_squared(df$a[-1], df$c[-1], ci = NULL))
+  expect_identical(E1, rank_epsilon_squared(df$a[-1], df$c[-1], ci = NULL))
 })
 
 
 test_that("".get_data_multi_group | subset"", {
   d <- expand.grid(id = 1:30, g = 1:4)
   d$y <- rnorm(nrow(d)) + d$g
-  expect_equal(
+  expect_identical(
     rank_epsilon_squared(y ~ g, data = d, subset = g < 4, ci = NULL),
     rank_epsilon_squared(y ~ g, data = subset(d, g < 4), ci = NULL)
   )
@@ -170,7 +272,8 @@ test_that("".get_data_nested_groups"", {
       ""Round Out"", ""Narrow Angle"", ""Wide Angle"",
       ""Round Out"", ""Narrow Angle"", ""Wide Angle""
     ),
-    value = c(5.4, 5.5, 5.55, 5.85, 5.7, 5.75, 5.2, 5.6, 5.5)
+    value = c(5.4, 5.5, 5.55, 5.85, 5.7, 5.75, 5.2, 5.6, 5.5),
+    stringsAsFactors = FALSE
   )
 
   set.seed(1)
@@ -179,16 +282,16 @@ test_that("".get_data_nested_groups"", {
   W3 <- kendalls_w(M2$value, M2$name, M2$id, ci = NULL)
   W4 <- kendalls_w(M2$value ~ M2$name | M2$id, ci = NULL)
 
-  expect_equal(W1, W2)
-  expect_equal(W1, W3)
-  expect_equal(W1, W4)
+  expect_identical(W1, W2)
+  expect_identical(W1, W3)
+  expect_identical(W1, W4)
 })
 
 test_that("".get_data_nested_groups | subset"", {
   d <- expand.grid(id = 1:30, g = 1:4)
   d$y <- rnorm(nrow(d)) + d$g
 
-  expect_equal(
+  expect_identical(
     kendalls_w(y ~ g | id, data = d, subset = g < 4, ci = NULL),
     kendalls_w(y ~ g | id, data = subset(d, g < 4), ci = NULL)
   )
@@ -198,22 +301,22 @@ test_that("".get_data_nested_groups | subset"", {
 test_that("".get_data_multivariate"", {
   data(""mtcars"")
   D <- mahalanobis_d(mtcars[, c(""mpg"", ""hp"")])
-  expect_equal(mahalanobis_d(cbind(mpg, hp) ~ 1, data = mtcars), D)
-  expect_equal(mahalanobis_d(mpg + hp ~ 1, data = mtcars), D)
+  expect_identical(mahalanobis_d(cbind(mpg, hp) ~ 1, data = mtcars), D)
+  expect_identical(mahalanobis_d(mpg + hp ~ 1, data = mtcars), D)
 
   D <- mahalanobis_d(
     mtcars[mtcars$am == 0, c(""mpg"", ""hp"")],
     mtcars[mtcars$am == 1, c(""mpg"", ""hp"")]
   )
-  expect_equal(mahalanobis_d(cbind(mpg, hp) ~ am, data = mtcars), D)
-  expect_equal(mahalanobis_d(mpg + hp ~ am, data = mtcars), D)
+  expect_identical(mahalanobis_d(cbind(mpg, hp) ~ am, data = mtcars), D)
+  expect_identical(mahalanobis_d(mpg + hp ~ am, data = mtcars), D)
 })
 
 test_that("".get_data_multivariate | subset"", {
   data(""mtcars"")
   D1 <- mahalanobis_d(mpg + hp ~ am, data = mtcars, subset = hp > 100)
   D2 <- mahalanobis_d(mpg + hp ~ am, data = subset(mtcars, hp > 100))
-  expect_equal(D1, D2)
+  expect_identical(D1, D2)
 })
 
 test_that("".get_data_multivariate | na.action"", {
@@ -222,5 +325,36 @@ test_that("".get_data_multivariate | na.action"", {
   expect_warning(mahalanobis_d(mtcars[, c(""mpg"", ""hp"")]), regexp = ""dropped"")
   expect_warning(mahalanobis_d(mpg + hp ~ 1, data = mtcars, na.action = na.omit), regexp = NA)
   expect_warning(D1 <- mahalanobis_d(mpg + hp ~ 1, data = mtcars), regexp = ""dropped"")
-  expect_equal(D1, mahalanobis_d(mpg + hp ~ 1, data = mtcars[-1, ]))
+  expect_identical(D1, mahalanobis_d(mpg + hp ~ 1, data = mtcars[-1, ]))
+})
+
+
+test_that("".get_data_paired | reference"", {
+  data(""sleep"")
+  sleep2 <- reshape(sleep,
+    direction = ""wide"",
+    idvar = ""ID"", timevar = ""group""
+  )
+
+  # formual w/ Pair()
+  expect_identical(
+    repeated_measures_d(Pair(extra.1, extra.2) ~ 1, data = sleep2)[[1]],
+    -repeated_measures_d(Pair(extra.1, extra.2) ~ 1, data = sleep2, reference = ""extra.1"")[[1]]
+  )
+
+
+  # 3 part formula (+aggragate)
+  data(""rouder2016"")
+  rouder2016$cond_num <- as.numeric(rouder2016$cond)
+
+  # with factor
+  expect_identical(
+    repeated_measures_d(rt ~ cond | id, data = rouder2016, verbose = FALSE)[[1]],
+    -repeated_measures_d(rt ~ cond | id, data = rouder2016, verbose = FALSE, reference = ""2"")[[1]]
+  )
+
+  expect_identical(
+    repeated_measures_d(rt ~ cond_num | id, data = rouder2016, verbose = FALSE)[[1]],
+    -repeated_measures_d(rt ~ cond_num | id, data = rouder2016, verbose = FALSE, reference = ""2"")[[1]]
+  )
 })

---FILE: vignettes/convert_r_d_OR.Rmd---
@@ -138,8 +138,9 @@ Let's give it a try:
 thresh <- 22500
 
 # 2. dichotomize the outcome
-hardlyworking$salary_low <- factor(hardlyworking$salary < thresh, 
-                                   labels = c(""high"", ""low""))
+hardlyworking$salary_low <- factor(hardlyworking$salary < thresh,
+  labels = c(""high"", ""low"")
+)
 
 # 3. Fit a logistic regression:
 fit <- glm(salary_low ~ is_senior,
@@ -160,8 +161,10 @@ by accounting for the rate of low salaries in the reference group.
 
 ```{r}
 proportions(
-  table(is_senior = hardlyworking$is_senior, 
-        salary_low = hardlyworking$salary_low), 
+  table(
+    is_senior = hardlyworking$is_senior,
+    salary_low = hardlyworking$salary_low
+  ),
   margin = 1
 )
 ",True,True,Documentation / Formatting,6
easystats,effectsize,21fc13cfbc54343c0b4e445e50eaa0d013f970b3,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2024-12-08T07:49:19Z,GitHub,noreply@github.com,2024-12-08T07:49:19Z,"add p0 to OR conversion

* Update convert_between_d_to_r.R

* support interperting marix/array

* add tests

* remove chen2010 rule

* fix tests

* syler

* lintr

* fix example

* lintr

[skip]",NEWS.md;R/convert_between_d_to_r.R;R/interpret.R;R/interpret_bf.R;R/interpret_direction.R;R/interpret_oddsratio.R;R/interpret_rope.R;R/rank_ANOVA.R;man/interpret.Rd;man/interpret_direction.Rd;man/interpret_oddsratio.Rd;man/interpret_rope.Rd;tests/testthat/test-convert_between.R;tests/testthat/test-interpret.R,False,True,True,False,200,141,341,"---FILE: NEWS.md---
@@ -3,6 +3,11 @@
 ## New features
 
 - `oddsratio_to_d()` and related functions gain a `p0` argument for exact conversion between odds ratios and Cohen's _d_ (thanks @KohlRaphael for the suggestion).
+- `interpret*()` now accept (and return) matrices and arrays.
+
+## Breaking Changes
+
+- `interpret_oddsratio()` drops the default `""chen2010""` as it was used incorrectly (thanks to @KohlRaphael).
 
 # effectsize 0.8.9
 

---FILE: R/convert_between_d_to_r.R---
@@ -72,7 +72,7 @@ r_to_d <- function(r, n1, n2, ...) {
 #' @rdname d_to_r
 #' @export
 oddsratio_to_d <- function(OR, p0, log = FALSE, ...) {
-  if (missing(p0)) {
+  if (missing(p0) || !is.numeric(p0)) {
     # Use approximation
     if (log) {
       log_OR <- OR
@@ -90,7 +90,7 @@ oddsratio_to_d <- function(OR, p0, log = FALSE, ...) {
 
   odds1 <- OR * probs_to_odds(p0)
   p1 <- odds_to_probs(odds1)
-  qnorm(p1) - qnorm(p0)
+  stats::qnorm(p1) - stats::qnorm(p0)
 }
 
 #' @rdname d_to_r

---FILE: R/interpret.R---
@@ -43,6 +43,10 @@ rules <- function(values, labels = NULL, name = NULL, right = TRUE) {
     insight::format_error(""Too many labels for the number of reference values!"")
   }
 
+  if (!is.numeric(values)) {
+    insight::format_error(""Reference values must be numeric."")
+  }
+
   if (length(values) == length(labels) - 1) {
     if (is.unsorted(values)) {
       insight::format_error(""Reference values must be sorted."")
@@ -129,8 +133,8 @@ is.rules <- function(x) inherits(x, ""rules"")
 #' interpret(eta2, rules = ""field2013"")
 #'
 #' X <- chisq.test(mtcars$am, mtcars$cyl == 8)
-#' interpret(oddsratio(X), rules = ""chen2010"")
-#' interpret(cramers_v(X), ""lovakov2021"")
+#' interpret(oddsratio(X), rules = ""cohen1988"")
+#' interpret(cramers_v(X), rules = ""lovakov2021"")
 #' @export
 interpret <- function(x, ...) {
   UseMethod(""interpret"")
@@ -159,6 +163,9 @@ interpret.numeric <- function(x, rules, name = attr(rules, ""rule_name""),
 
   if (length(x_tran) > 1) {
     out <- vapply(x_tran, .interpret, rules = rules, FUN.VALUE = character(1L))
+    if (is.matrix(x_tran) || is.array(x_tran)) {
+      out <- structure(out, dim = dim(x_tran), dimnames = dimnames(x_tran))
+    }
   } else {
     out <- .interpret(x_tran, rules = rules)
   }

---FILE: R/interpret_bf.R---
@@ -69,19 +69,19 @@ interpret_bf <- function(bf,
     )
   )
 
-  interpretation <- interpret(bf, rules, transform = function(.x) exp(abs(.x)))
+  interpretation <- interpret(bf, rules, transform = function(.x) exp(ifelse(.x < 0, -.x, .x)))
   interpretation[bf == 0] <- ""no""
 
   # interpret direction
-  dir <- interpret(bf, rules(0, c(""against"", ""in favour of"")))
-  dir[bf == 0] <- ""against or in favour of""
+  direction <- interpret(bf, rules(0, c(""against"", ""in favour of"")))
+  direction[bf == 0] <- ""against or in favour of""
 
   # Format text
   if (include_value) {
     bf_fmt <- insight::format_bf(exp(bf), protect_ratio = protect_ratio, exact = exact)
-    interpretation[] <- sprintf(""%s evidence (%s) %s"", interpretation, bf_fmt, dir)
+    interpretation[] <- sprintf(""%s evidence (%s) %s"", interpretation, bf_fmt, direction)
   } else {
-    interpretation[] <- paste0(interpretation, "" evidence "", dir)
+    interpretation[] <- paste0(interpretation, "" evidence "", direction)
   }
 
   interpretation[is.na(bf)] <- """"

---FILE: R/interpret_direction.R---
@@ -6,9 +6,15 @@
 #' @examples
 #' interpret_direction(.02)
 #' interpret_direction(c(.5, -.02))
+#' interpret_direction(0)
 #'
 #' @keywords interpreters
 #' @export
 interpret_direction <- function(x) {
-  interpret(x, rules(0, c(""negative"", ""positive""), name = ""math"", right = FALSE))
+  interpret(x, rules(0, c(""negative"", ""positive""), name = ""math"", right = FALSE),
+    transform = function(.x) {
+      s <- sign(.x)
+      replace(s, s == 0, NA_real_)
+    }
+  )
 }

---FILE: R/interpret_oddsratio.R---
@@ -1,26 +1,23 @@
 #' Interpret Odds Ratio
 #'
 #' @param OR Value or vector of (log) odds ratio values.
-#' @param rules Can be ""`chen2010""` (default), `""cohen1988""` (through
-#'   transformation to standardized difference, see [oddsratio_to_d()]) or custom set
-#'   of [rules()].
+#' @param rules If `""cohen1988""` (default), `OR` is transformed to a
+#'   standardized difference (via [oddsratio_to_d()]) and interpreted according
+#'   to Cohen's rules (see [interpret_cohens_d()]; see Chen et al., 2010). If a
+#'   custom set of [rules()] is used, OR is interpreted as is.
 #' @param log Are the provided values log odds ratio.
 #' @inheritParams interpret
+#' @inheritParams oddsratio_to_d
 #'
 #' @section Rules:
 #'
 #' Rules apply to OR as ratios, so OR of 10 is as extreme as a OR of 0.1 (1/10).
 #'
-#' - Chen et al. (2010) (`""chen2010""`; default)
-#'   - **OR < 1.68** - Very small
-#'   - **1.68 <= OR < 3.47** - Small
-#'   - **3.47 <= OR < 6.71** - Medium
-#'   - **OR >= 6.71 ** - Large
 #' - Cohen (1988) (`""cohen1988""`, based on the [oddsratio_to_d()] conversion, see [interpret_cohens_d()])
 #'   - **OR < 1.44** - Very small
 #'   - **1.44 <= OR < 2.48** - Small
 #'   - **2.48 <= OR < 4.27** - Medium
-#'   - **OR >= 4.27 ** - Large
+#'   - **OR >= 4.27** - Large
 #'
 #' @examples
 #' interpret_oddsratio(1)
@@ -40,28 +37,15 @@
 #'
 #' @keywords interpreters
 #' @export
-interpret_oddsratio <- function(OR, rules = ""chen2010"", log = FALSE, ...) {
-  if (log) {
-    f_transform <- function(.x) exp(abs(.x))
-  } else {
-    f_transform <- function(.x) exp(abs(log(.x)))
-  }
-
-
+interpret_oddsratio <- function(OR, rules = ""cohen1988"", p0 = NULL, log = FALSE, ...) {
   if (is.character(rules) && rules == ""cohen1988"") {
-    d <- oddsratio_to_d(OR, log = log)
+    d <- oddsratio_to_d(OR, p0, log = log)
     return(interpret_cohens_d(d, rules = rules))
   }
 
-  rules <- .match.rules(
-    rules,
-    list(
-      chen2010 = rules(c(1.68, 3.47, 6.71), c(""very small"", ""small"", ""medium"", ""large""),
-        name = ""chen2010"", right = FALSE
-      ),
-      cohen1988 = NA # for correct error msg
-    )
-  )
+  if (log) {
+    OR <- exp(OR)
+  }
 
-  interpret(OR, rules, transform = f_transform)
+  interpret(OR, rules, transform = function(.x) ifelse(.x < 1, 1 / .x, .x))
 }

---FILE: R/interpret_rope.R---
@@ -3,7 +3,8 @@
 #' Interpretation of
 #'
 #' @param rope Value or vector of percentages in ROPE.
-#' @param ci The Credible Interval (CI) probability, corresponding to the proportion of HDI, that was used. Can be `1` in the case of ""full ROPE"".
+#' @param ci The Credible Interval (CI) probability, corresponding to the
+#'   proportion of HDI, that was used. Can be `1` in the case of ""full ROPE"".
 #' @param rules A character string (see details) or a custom set of [rules()].
 #'
 #' @section Rules:
@@ -29,7 +30,7 @@
 #'
 #' @keywords interpreters
 #' @export
-interpret_rope <- function(rope, ci = 0.9, rules = ""default"") {
+interpret_rope <- function(rope, rules = ""default"", ci = 0.9) {
   if (ci < 1) {
     e <- .Machine$double.eps
 

---FILE: R/rank_ANOVA.R---
@@ -280,9 +280,12 @@ kendalls_w <- function(x, groups, blocks, data = NULL,
 
   boot_fun <- function(.data, .i) {
     split(.data$x, .data$groups) <-
-      lapply(split(.data$x, .data$groups),
+      lapply(
+        split(.data$x, .data$groups),
         function(v) {
-          if (length(v) < 2L) return(v)
+          if (length(v) < 2L) {
+            return(v)
+          }
           sample(v, size = length(v), replace = TRUE)
         }
       )

---FILE: man/interpret.Rd---
@@ -63,8 +63,8 @@ eta2 <- eta_squared(m)
 interpret(eta2, rules = ""field2013"")
 
 X <- chisq.test(mtcars$am, mtcars$cyl == 8)
-interpret(oddsratio(X), rules = ""chen2010"")
-interpret(cramers_v(X), ""lovakov2021"")
+interpret(oddsratio(X), rules = ""cohen1988"")
+interpret(cramers_v(X), rules = ""lovakov2021"")
 }
 \seealso{
 \code{\link[=rules]{rules()}}

---FILE: man/interpret_direction.Rd---
@@ -15,6 +15,7 @@ Interpret Direction
 \examples{
 interpret_direction(.02)
 interpret_direction(c(.5, -.02))
+interpret_direction(0)
 
 }
 \keyword{interpreters}

---FILE: man/interpret_oddsratio.Rd---
@@ -4,14 +4,17 @@
 \alias{interpret_oddsratio}
 \title{Interpret Odds Ratio}
 \usage{
-interpret_oddsratio(OR, rules = ""chen2010"", log = FALSE, ...)
+interpret_oddsratio(OR, rules = ""cohen1988"", p0 = NULL, log = FALSE, ...)
 }
 \arguments{
 \item{OR}{Value or vector of (log) odds ratio values.}
 
-\item{rules}{Can be ""\verb{chen2010""} (default), \code{""cohen1988""} (through
-transformation to standardized difference, see \code{\link[=oddsratio_to_d]{oddsratio_to_d()}}) or custom set
-of \code{\link[=rules]{rules()}}.}
+\item{rules}{If \code{""cohen1988""} (default), \code{OR} is transformed to a
+standardized difference (via \code{\link[=oddsratio_to_d]{oddsratio_to_d()}}) and interpreted according
+to Cohen's rules (see \code{\link[=interpret_cohens_d]{interpret_cohens_d()}}; see Chen et al., 2010). If a
+custom set of \code{\link[=rules]{rules()}} is used, OR is interpreted as is.}
+
+\item{p0}{Baseline risk. If not specified, the \emph{d} to \emph{OR} conversion uses am approximation (see details).}
 
 \item{log}{Are the provided values log odds ratio.}
 
@@ -25,19 +28,12 @@ Interpret Odds Ratio
 
 Rules apply to OR as ratios, so OR of 10 is as extreme as a OR of 0.1 (1/10).
 \itemize{
-\item Chen et al. (2010) (\code{""chen2010""}; default)
-\itemize{
-\item \strong{OR < 1.68} - Very small
-\item \strong{1.68 <= OR < 3.47} - Small
-\item \strong{3.47 <= OR < 6.71} - Medium
-\item **OR >= 6.71 ** - Large
-}
 \item Cohen (1988) (\code{""cohen1988""}, based on the \code{\link[=oddsratio_to_d]{oddsratio_to_d()}} conversion, see \code{\link[=interpret_cohens_d]{interpret_cohens_d()}})
 \itemize{
 \item \strong{OR < 1.44} - Very small
 \item \strong{1.44 <= OR < 2.48} - Small
 \item \strong{2.48 <= OR < 4.27} - Medium
-\item **OR >= 4.27 ** - Large
+\item \strong{OR >= 4.27} - Large
 }
 }
 }

---FILE: man/interpret_rope.Rd---
@@ -4,14 +4,15 @@
 \alias{interpret_rope}
 \title{Interpret Bayesian Posterior Percentage in ROPE.}
 \usage{
-interpret_rope(rope, ci = 0.9, rules = ""default"")
+interpret_rope(rope, rules = ""default"", ci = 0.9)
 }
 \arguments{
 \item{rope}{Value or vector of percentages in ROPE.}
 
-\item{ci}{The Credible Interval (CI) probability, corresponding to the proportion of HDI, that was used. Can be \code{1} in the case of ""full ROPE"".}
-
 \item{rules}{A character string (see details) or a custom set of \code{\link[=rules]{rules()}}.}
+
+\item{ci}{The Credible Interval (CI) probability, corresponding to the
+proportion of HDI, that was used. Can be \code{1} in the case of ""full ROPE"".}
 }
 \description{
 Interpretation of

---FILE: tests/testthat/test-convert_between.R---
@@ -13,11 +13,35 @@ test_that(""exact OR to d"", {
 
   expect_equal(cor(oddsratio_to_d(OR), d), 1, tolerance = 0.0001)
   expect_equal(oddsratio_to_d(1), 0, tolerance = 0.0001)
-  expect_equal(oddsratio_to_d(OR, p0), d)
+  expect_equal(oddsratio_to_d(OR, p0), d, tolerance = 0.0001)
 
   expect_equal(cor(oddsratio_to_r(OR), d_to_r(d)), 1, tolerance = 0.0002)
   expect_equal(oddsratio_to_r(1), 0, tolerance = 0.0001)
-  expect_equal(oddsratio_to_r(OR, p0), d_to_r(d))
+  expect_equal(oddsratio_to_r(OR, p0), d_to_r(d), tolerance = 0.0001)
+
+
+  # From Chen et al 2010
+  chen_tab_1 <- as.matrix(
+    read.table(
+      text = ""p0    OR_1    OR_2    OR_3
+        0.0100  1.6814  3.4739  6.7128
+        0.0200  1.6146  3.1332  5.7486
+        0.0300  1.5733  2.9535  5.2592
+        0.0400  1.5455  2.8306  4.9471
+        0.0500  1.5228  2.7416  4.7233
+        0.0600  1.5060  2.6741  4.5536
+        0.0700  1.4926  2.6177  4.4191
+        0.0800  1.4811  2.5707  4.3097
+        0.0900  1.4709  2.5309  4.2167
+        0.1000  1.4615  2.4972  4.1387"",
+      header = TRUE
+    )
+  )
+
+  for (i in seq_len(nrow(chen_tab_1))) {
+    d_recovered <- oddsratio_to_d(chen_tab_1[i, 2:4], p0 = chen_tab_1[i, 1])
+    expect_equal(d_recovered, c(0.2, 0.5, 0.8), tolerance = 0.01, ignore_attr = TRUE)
+  }
 })
 
 

---FILE: tests/testthat/test-interpret.R---
@@ -1,16 +1,19 @@
 # interpret generic ----
 test_that(""interpret generic"", {
   rules_grid <- rules(c(0.01, 0.05), c(""very significant"", ""significant"", ""not significant""))
-  expect_equal(interpret(0.001, rules_grid)[1], ""very significant"")
-  expect_equal(interpret(0.021, rules_grid)[1], ""significant"")
-  expect_equal(interpret(0.08, rules_grid)[1], ""not significant"")
-  expect_equal(
+  expect_identical(interpret(0.001, rules_grid)[1], ""very significant"")
+  expect_identical(interpret(0.021, rules_grid)[1], ""significant"")
+  expect_identical(interpret(0.08, rules_grid)[1], ""not significant"")
+  expect_identical(
     interpret(c(0.01, 0.005, 0.08), rules_grid)[1:3],
     c(""very significant"", ""very significant"", ""not significant"")
   )
-  expect_error(rules(c(0.5), c(""A"", ""B"", ""C"")), ""Too many"")
+  expect_error(rules(0.5, c(""A"", ""B"", ""C"")), ""Too many"")
   expect_error(rules(c(0.5, 0.2, 0.7), c(""A"", ""B"", ""C"", ""D"")), ""sorted"")
 
+  expect_error(rules(1), NA)
+  expect_error(rules(""a""), ""must be numeric"")
+
 
   r1 <- rules(c(0, 1), labels = c(""some"", ""few"", ""many""))
   r2 <- rules(c(0, 1), labels = c(""some"", ""few"", ""many""), right = FALSE)
@@ -19,95 +22,123 @@ test_that(""interpret generic"", {
   expect_equal(interpret(c(0, 1), r2)[], c(""few"", ""many""), ignore_attr = TRUE)
 })
 
+
+test_that(""interpret matrix / array"", {
+  # Matrix
+  r <- cor(mtcars[, 8:11])
+  out <- interpret_r(r)
+
+  expect_identical(dim(out), dim(r))
+  expect_identical(dimnames(out), dimnames(r))
+
+  out2 <- interpret_r(as.vector(r))
+  expect_equal(out2, as.vector(out), ignore_attr = TRUE)
+
+  # Array
+  set.seed(111)
+  p <- array(runif(3 * 2 * 4, max = 0.1), dim = c(3, 2, 4))
+  out <- interpret_p(p, rules = ""rss"")
+
+  expect_identical(dim(out), dim(p))
+
+  out2 <- interpret_p(as.vector(p), rules = ""rss"")
+  expect_equal(out2, as.vector(out), ignore_attr = TRUE)
+})
+
 # interpret types ----
 test_that(""interpret_r"", {
-  expect_equal(interpret_r(0.21)[1], ""medium"")
-  expect_equal(interpret_r(0.21, ""cohen1988"")[1], ""small"")
-  expect_equal(interpret_r(0.21, ""lovakov2021"")[1], ""small"")
-  expect_equal(interpret_r(0.7, ""evans1996"")[1], ""strong"")
-  expect_equal(interpret_r(c(0.5, -0.08), ""cohen1988"")[1:2], c(""large"", ""very small""))
-  expect_equal(interpret_r(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_identical(interpret_r(0.21)[1], ""medium"")
+  expect_identical(interpret_r(0.21, ""cohen1988"")[1], ""small"")
+  expect_identical(interpret_r(0.21, ""lovakov2021"")[1], ""small"")
+  expect_identical(interpret_r(0.7, ""evans1996"")[1], ""strong"")
+  expect_identical(interpret_r(c(0.5, -0.08), ""cohen1988"")[1:2], c(""large"", ""very small""))
+  expect_identical(interpret_r(0.6, rules(0.5, c(""A"", ""B"")))[1], ""B"")
   expect_error(interpret_r(0.6, ""DUPA""), ""must be"")
 })
 
 
 
 test_that(""interpret_p"", {
-  expect_equal(interpret_p(0.021)[1], ""significant"")
-  expect_equal(interpret_p(0.08)[1], ""not significant"")
-  expect_equal(interpret_p(c(0.01, 0.08))[1:2], c(""significant"", ""not significant""))
-  expect_equal(interpret_p(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_identical(interpret_p(0.021)[1], ""significant"")
+  expect_identical(interpret_p(0.08)[1], ""not significant"")
+  expect_identical(interpret_p(c(0.01, 0.08))[1:2], c(""significant"", ""not significant""))
+  expect_identical(interpret_p(0.6, rules(0.5, c(""A"", ""B"")))[1], ""B"")
   expect_error(interpret_p(0.6, ""DUPA""), ""must be"")
 })
 
 
 test_that(""interpret_direction"", {
-  expect_equal(interpret_direction(c(0.01, -0.08))[1:2], c(""positive"", ""negative""))
+  expect_identical(interpret_direction(c(0.01, -0.08))[1:2], c(""positive"", ""negative""))
 })
 
 
 test_that(""interpret_cohens_d"", {
-  expect_equal(interpret_cohens_d(0.021)[1], ""very small"")
-  expect_equal(interpret_cohens_d(1.3, ""sawilowsky2009"")[1], ""very large"")
-  expect_equal(interpret_cohens_d(c(0.45, 0.85), ""cohen1988"")[1:2], c(""small"", ""large""))
-  expect_equal(interpret_cohens_d(c(0.45, 0.85), ""lovakov2021"")[1:2], c(""medium"", ""large""))
-  expect_equal(interpret_cohens_d(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_identical(interpret_cohens_d(0.021)[1], ""very small"")
+  expect_identical(interpret_cohens_d(1.3, ""sawilowsky2009"")[1], ""very large"")
+  expect_identical(interpret_cohens_d(c(0.45, 0.85), ""cohen1988"")[1:2], c(""small"", ""large""))
+  expect_identical(interpret_cohens_d(c(0.45, 0.85), ""lovakov2021"")[1:2], c(""medium"", ""large""))
+  expect_identical(interpret_cohens_d(0.6, rules(0.5, c(""A"", ""B"")))[1], ""B"")
   expect_error(interpret_cohens_d(0.6, ""DUPA""), ""must be"")
 })
 
 test_that(""interpret_cohens_g"", {
-  expect_equal(interpret_cohens_g(0.021)[1], ""very small"")
-  expect_equal(interpret_cohens_g(c(0.10, 0.35), ""cohen1988"")[1:2], c(""small"", ""large""))
-  expect_equal(interpret_cohens_g(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_identical(interpret_cohens_g(0.021)[1], ""very small"")
+  expect_identical(interpret_cohens_g(c(0.10, 0.35), ""cohen1988"")[1:2], c(""small"", ""large""))
+  expect_identical(interpret_cohens_g(0.6, rules(0.5, c(""A"", ""B"")))[1], ""B"")
   expect_error(interpret_cohens_g(0.6, ""DUPA""), ""must be"")
 })
 
 
 test_that(""interpret_rope"", {
-  expect_equal(interpret_rope(0, ci = 0.9)[1], ""significant"")
-  expect_equal(interpret_rope(c(0.50, 1), ci = 0.9)[1:2], c(""undecided"", ""negligible""))
-  expect_equal(interpret_rope(c(0.98, 0.991), ci = 1)[1:2], c(""probably negligible"", ""negligible""))
-  expect_equal(interpret_rope(0.6, , rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-  expect_error(interpret_rope(0.6, , ""DUPA""), ""must be"")
+  expect_identical(interpret_rope(0, ci = 0.9)[1], ""significant"")
+  expect_identical(interpret_rope(c(0.50, 1), ci = 0.9)[1:2], c(""undecided"", ""negligible""))
+  expect_identical(interpret_rope(c(0.98, 0.991), ci = 1)[1:2], c(""probably negligible"", ""negligible""))
+  expect_identical(interpret_rope(0.6, rules(0.5, c(""A"", ""B"")))[1], ""B"")
+  expect_error(interpret_rope(0.6, ""DUPA""), ""must be"")
 })
 
 
 test_that(""interpret_oddsratio"", {
-  expect_equal(interpret_oddsratio(2)[1], ""small"")
-  expect_equal(interpret_oddsratio(c(1, 3))[1:2], c(""very small"", ""small""))
-  expect_equal(interpret_oddsratio(c(1, 3), ""cohen1988"")[1:2], c(""very small"", ""medium""))
-  expect_equal(interpret_oddsratio(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-  expect_error(interpret_oddsratio(0.6, ""DUPA""), ""must be"")
+  # Chen 2010, table 1 row 6
+  OR <- c(1.4, 2.5, 4.4, 7.5)
+  p0 <- 0.06
+  expect_equal(interpret_oddsratio(OR, p0 = p0), c(""very small"", ""small"", ""medium"", ""large""), ignore_attr = TRUE)
+  expect_equal(interpret_oddsratio(OR), c(""very small"", ""medium"", ""large"", ""large""), ignore_attr = TRUE)
+
+  expect_equal(interpret_oddsratio(
+    c(0.1, 0.5, 2, 10),
+    rules(3, c(""A"", ""B""))
+  ), c(""B"", ""A"", ""A"", ""B""), ignore_attr = TRUE)
 })
 
 
 test_that(""interpret_r2"", {
-  expect_equal(interpret_r2(0.4)[1], ""substantial"")
-  expect_equal(interpret_r2(c(0, 0.4), ""falk1992"")[1:2], c(""negligible"", ""adequate""))
-  expect_equal(interpret_r2(c(0.1, 0.4), ""chin1998"")[1:2], c(""very weak"", ""moderate""))
-  expect_equal(interpret_r2(c(0.1, 0.4), ""hair2011"")[1:2], c(""very weak"", ""weak""))
-  expect_equal(interpret_r2(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_identical(interpret_r2(0.4)[1], ""substantial"")
+  expect_identical(interpret_r2(c(0, 0.4), ""falk1992"")[1:2], c(""negligible"", ""adequate""))
+  expect_identical(interpret_r2(c(0.1, 0.4), ""chin1998"")[1:2], c(""very weak"", ""moderate""))
+  expect_identical(interpret_r2(c(0.1, 0.4), ""hair2011"")[1:2], c(""very weak"", ""weak""))
+  expect_identical(interpret_r2(0.6, rules(0.5, c(""A"", ""B"")))[1], ""B"")
   expect_error(interpret_r2(0.6, ""DUPA""), ""must be"")
 })
 
 
 test_that(""interpret_bf"", {
   expect_error(interpret_bf(-2), ""Negative"")
-  expect_equal(interpret_bf(1)[1], ""no evidence against or in favour of"")
-  expect_equal(
+  expect_identical(interpret_bf(1)[1], ""no evidence against or in favour of"")
+  expect_identical(
     interpret_bf(c(0.8, 3.5), ""jeffreys1961"")[1:2],
     c(""anecdotal evidence against"", ""moderate evidence in favour of"")
   )
-  expect_equal(
+  expect_identical(
     interpret_bf(c(0.8, 3.5), ""raftery1995"")[1:2],
     c(""weak evidence against"", ""positive evidence in favour of"")
   )
-  expect_equal(interpret_bf(2, rules(c(0.5), c(""A"", ""B"")))[1], ""B evidence in favour of"")
+  expect_identical(interpret_bf(2, rules(0.5, c(""A"", ""B"")))[1], ""B evidence in favour of"")
   expect_error(interpret_bf(2, ""DUPA""), ""must be"")
 
   skip_on_cran() # just in case there are changes in insight
   bf <- c(10^seq(-4, 4), NA)
-  expect_equal(interpret_bf(bf, include_value = TRUE, protect_ratio = TRUE, exact = TRUE),
+  expect_identical(interpret_bf(bf, include_value = TRUE, protect_ratio = TRUE, exact = TRUE),
     c(
       ""extreme evidence (BF = 1/1.00e+04) against"", ""extreme evidence (BF = 1/1000.00) against"",
       ""very strong evidence (BF = 1/100.00) against"", ""moderate evidence (BF = 1/10.00) against"",
@@ -122,61 +153,61 @@ test_that(""interpret_bf"", {
 
 
 test_that(""interpret_omega_squared"", {
-  expect_equal(interpret_omega_squared(0.1)[1], ""medium"")
-  expect_equal(interpret_omega_squared(c(0.1, 0.25))[1:2], c(""medium"", ""large""))
-  expect_equal(interpret_omega_squared(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_identical(interpret_omega_squared(0.1)[1], ""medium"")
+  expect_identical(interpret_omega_squared(c(0.1, 0.25))[1:2], c(""medium"", ""large""))
+  expect_identical(interpret_omega_squared(0.6, rules(0.5, c(""A"", ""B"")))[1], ""B"")
   expect_error(interpret_omega_squared(0.6, ""DUPA""), ""must be"")
 
   # these should be same
-  expect_equal(interpret_eta_squared(0.1)[1], interpret_omega_squared(0.1)[1])
-  expect_equal(
+  expect_identical(interpret_eta_squared(0.1)[1], interpret_omega_squared(0.1)[1])
+  expect_identical(
     interpret_eta_squared(c(0.1, 0.25))[1:2],
     interpret_omega_squared(c(0.1, 0.25))[1:2]
   )
 })
 
 test_that(""interpret_kendalls_w"", {
-  expect_equal(interpret_kendalls_w(0.1)[1], ""slight agreement"")
-  expect_equal(
+  expect_identical(interpret_kendalls_w(0.1)[1], ""slight agreement"")
+  expect_identical(
     interpret_kendalls_w(c(0.1, 0.25))[1:2],
     c(""slight agreement"", ""fair agreement"")
   )
-  expect_equal(interpret_kendalls_w(0.9)[1], ""almost perfect agreement"")
-  expect_equal(interpret_kendalls_w(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_identical(interpret_kendalls_w(0.9)[1], ""almost perfect agreement"")
+  expect_identical(interpret_kendalls_w(0.6, rules(0.5, c(""A"", ""B"")))[1], ""B"")
   expect_error(interpret_kendalls_w(0.6, ""DUPA""), ""must be"")
 })
 
 
 test_that(""interpret_rhat"", {
-  expect_equal(interpret_rhat(1)[1], ""converged"")
-  expect_equal(interpret_rhat(c(1, 1.02))[1:2], c(""converged"", ""failed""))
-  expect_equal(interpret_rhat(c(1, 1.02), ""gelman1992"")[1:2], c(""converged"", ""converged""))
-  expect_equal(interpret_rhat(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_identical(interpret_rhat(1)[1], ""converged"")
+  expect_identical(interpret_rhat(c(1, 1.02))[1:2], c(""converged"", ""failed""))
+  expect_identical(interpret_rhat(c(1, 1.02), ""gelman1992"")[1:2], c(""converged"", ""converged""))
+  expect_identical(interpret_rhat(0.6, rules(0.5, c(""A"", ""B"")))[1], ""B"")
   expect_error(interpret_rhat(0.6, ""DUPA""), ""must be"")
 })
 
 
 test_that(""interpret_ess"", {
-  expect_equal(interpret_ess(1000)[1], ""sufficient"")
-  expect_equal(interpret_ess(c(1000, 800))[1:2], c(""sufficient"", ""insufficient""))
-  expect_equal(interpret_ess(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_identical(interpret_ess(1000)[1], ""sufficient"")
+  expect_identical(interpret_ess(c(1000, 800))[1:2], c(""sufficient"", ""insufficient""))
+  expect_identical(interpret_ess(0.6, rules(0.5, c(""A"", ""B"")))[1], ""B"")
   expect_error(interpret_ess(0.6, ""DUPA""), ""must be"")
 })
 
 
 test_that(""interpret_fit"", {
-  expect_equal(interpret_gfi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
-  expect_equal(interpret_agfi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
-  expect_equal(interpret_nfi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
-  expect_equal(interpret_nnfi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
-  expect_equal(interpret_cfi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
-  expect_equal(interpret_rfi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
-  expect_equal(interpret_ifi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
-  expect_equal(interpret_pnfi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
-  expect_equal(interpret_rmsea(c(.1, .05)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
-  expect_equal(interpret_srmr(c(.1, .05)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
-
-  cr <- rules(c(0.5), c(""A"", ""B""))
+  expect_equal(interpret_gfi(c(0.5, 0.99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
+  expect_equal(interpret_agfi(c(0.5, 0.99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
+  expect_equal(interpret_nfi(c(0.5, 0.99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
+  expect_equal(interpret_nnfi(c(0.5, 0.99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
+  expect_equal(interpret_cfi(c(0.5, 0.99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
+  expect_equal(interpret_rfi(c(0.5, 0.99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
+  expect_equal(interpret_ifi(c(0.5, 0.99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
+  expect_equal(interpret_pnfi(c(0.5, 0.99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
+  expect_equal(interpret_rmsea(c(0.1, 0.05)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
+  expect_equal(interpret_srmr(c(0.1, 0.05)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
+
+  cr <- rules(0.5, c(""A"", ""B""))
   expect_equal(interpret_gfi(0.6, cr), ""B"", ignore_attr = TRUE)
   expect_equal(interpret_agfi(0.6, cr), ""B"", ignore_attr = TRUE)
   expect_equal(interpret_nfi(0.6, cr), ""B"", ignore_attr = TRUE)
@@ -208,29 +239,29 @@ test_that(""interpret_fit"", {
                    dem60 ~ ind60 ""
   model <- lavaan::sem(structure, data = lavaan::PoliticalDemocracy)
   int <- interpret(model)
-  expect_equal(int$Name, c(""GFI"", ""AGFI"", ""NFI"", ""NNFI"", ""CFI"", ""RMSEA"", ""SRMR"", ""RFI"", ""PNFI"", ""IFI""))
+  expect_identical(int$Name, c(""GFI"", ""AGFI"", ""NFI"", ""NNFI"", ""CFI"", ""RMSEA"", ""SRMR"", ""RFI"", ""PNFI"", ""IFI""))
   expect_equal(int$Value, c(0.9666, 0.9124, 0.9749, 1.0001, 1, 0, 0.0273, 0.9529, 0.5199, 1.0001), tolerance = 0.001)
 
   int2 <- interpret(performance::model_performance(model))
-  expect_equal(int, int2)
+  expect_identical(int, int2)
 })
 
 test_that(""interpret_icc"", {
   expect_equal(interpret_icc(c(0.45, 0.55, 0.8, 0.95)), c(""poor"", ""moderate"", ""good"", ""excellent""), ignore_attr = TRUE)
-  expect_equal(interpret_icc(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_identical(interpret_icc(0.6, rules(0.5, c(""A"", ""B"")))[1], ""B"")
   expect_error(interpret_icc(0.6, ""DUPA""), ""must be"")
 })
 
 test_that(""interpret_vif"", {
   expect_equal(interpret_vif(c(1, 5.5, 10)), c(""low"", ""moderate"", ""high""), ignore_attr = TRUE)
-  expect_equal(interpret_icc(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_identical(interpret_icc(0.6, rules(0.5, c(""A"", ""B"")))[1], ""B"")
   expect_error(interpret_icc(0.6, ""DUPA""), ""must be"")
 })
 
 test_that(""interpret_pd"", {
   expect_equal(interpret_pd(c(0.9, 0.99)), c(""not significant"", ""significant""), ignore_attr = TRUE)
   expect_equal(interpret_pd(c(0.9, 0.99), ""makowski2019""), c(""uncertain"", ""likely existing""), ignore_attr = TRUE)
-  expect_equal(interpret_pd(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_identical(interpret_pd(0.6, rules(0.5, c(""A"", ""B"")))[1], ""B"")
   expect_error(interpret_pd(0.6, ""DUPA""), ""must be"")
 })
 
@@ -258,7 +289,7 @@ test_that(""interpret effectsize_table"", {
   d1_ <- interpret(d1, rules = ""cohen1988"")
   d2_ <- interpret(d2, rules = ""cohen1988"")
 
-  expect_equal(d1_$Interpretation, d2_$Interpretation)
-  expect_equal(d1_[[1]], d1[[1]])
-  expect_equal(d2_[[1]], d2[[1]])
+  expect_identical(d1_$Interpretation, d2_$Interpretation)
+  expect_identical(d1_[[1]], d1[[1]])
+  expect_identical(d2_[[1]], d2[[1]])
 })",True,False,Documentation / Formatting,6
easystats,effectsize,054aa429a0b6797769aabf9909c2287b59115a06,Mattan S. Ben-Shachar,mattansb@msbstats.info,2024-09-25T17:23:54Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2024-09-25T17:23:54Z,"remove status/ lifecycle badges

https://github.com/easystats/easystats/issues/432",README.Rmd;README.md,True,False,True,False,8,12,20,"---FILE: README.Rmd---
@@ -21,8 +21,6 @@ set.seed(111)
 [![DOI](https://joss.theoj.org/papers/10.21105/joss.02815/status.svg/)](https://doi.org/10.21105/joss.02815)
 [![downloads](https://cranlogs.r-pkg.org/badges/effectsize)](https://cran.r-project.org/package=effectsize/)
 [![total](https://cranlogs.r-pkg.org/badges/grand-total/effectsize)](https://cran.r-project.org/package=effectsize/)
-[![status](https://tinyverse.netlify.com/badge/effectsize/)](https://CRAN.R-project.org/package=effectsize/)
-[![lifecycle](https://img.shields.io/badge/lifecycle-maturing-blue.svg)](https://lifecycle.r-lib.org/articles/stages.html)
 
 
 ***Significant is just not enough!***

---FILE: README.md---
@@ -2,10 +2,8 @@
 # effectsize: Indices of Effect Size <img src=""man/figures/logo.png"" align=""right"" width=""120"" />
 
 [![DOI](https://joss.theoj.org/papers/10.21105/joss.02815/status.svg/)](https://doi.org/10.21105/joss.02815)
-[![downloads](https://cranlogs.r-pkg.org/badges/effectsize)](https://CRAN.R-project.org/package=effectsize)
-[![total](https://cranlogs.r-pkg.org/badges/grand-total/effectsize)](https://CRAN.R-project.org/package=effectsize)
-[![status](https://tinyverse.netlify.com/badge/effectsize/)](https://CRAN.R-project.org/package=effectsize)
-[![lifecycle](https://img.shields.io/badge/lifecycle-maturing-blue.svg)](https://lifecycle.r-lib.org/articles/stages.html)
+[![downloads](https://cranlogs.r-pkg.org/badges/effectsize)](https://cran.r-project.org/package=effectsize/)
+[![total](https://cranlogs.r-pkg.org/badges/grand-total/effectsize)](https://cran.r-project.org/package=effectsize/)
 
 ***Significant is just not enough!***
 
@@ -15,7 +13,7 @@ conversion of indices such as Cohenâs *d*, *r*, odds-ratios, etc.
 
 ## Installation
 
-[![CRAN](https://www.r-pkg.org/badges/version/effectsize)](https://CRAN.R-project.org/package=effectsize)
+[![CRAN](https://www.r-pkg.org/badges/version/effectsize)](https://cran.r-project.org/package=effectsize/)
 [![effectsize status
 badge](https://easystats.r-universe.dev/badges/effectsize/)](https://easystats.r-universe.dev/)
 [![R-CMD-check](https://github.com/easystats/effectsize/workflows/R-CMD-check/badge.svg?branch=main)](https://github.com/easystats/effectsize/actions)
@@ -113,13 +111,13 @@ hedges_g(mpg ~ am, data = mtcars)
 ## - Estimated using pooled SD.
 
 glass_delta(mpg ~ am, data = mtcars)
-## Glass' Î |         95% CI
-## -------------------------
-## -1.17    | [-1.93, -0.39]
+## Glass' Î (adj.) |         95% CI
+## --------------------------------
+## -1.10           | [-1.80, -0.37]
 ```
 
-`effectsize` also provides effect sizes for *rank tests*, *common
-language effect sizes* and moreâ¦
+`effectsize` also provides effect sizes for *paired standardized
+differences*, *rank tests*, *common language effect sizes* and moreâ¦
 
 ### Contingency Tables
 ",False,True,Documentation / Formatting,6
easystats,effectsize,5adb6815c20127b2f9d5b76831599f707f9b1cf6,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2024-07-03T08:36:26Z,GitHub,noreply@github.com,2024-07-03T08:36:26Z,"CRAN 0.8.9

deal with #648

* remove effects arg where not needed

* Update interpret_ess_rhat.R

* deal with https://github.com/easystats/report/issues/442

---------

Co-authored-by: Daniel <mail@danielluedecke.de>
Co-authored-by: Indrajeet Patil <patilindrajeet.science@gmail.com>",DESCRIPTION;NEWS.md;R/cohens_g.R;R/common_language.R;R/convert_between_odds_to_probs.R;R/effectsize.htest.R;R/eta_squared-main.R;R/eta_squared-methods.R;R/interpret.R;R/interpret_bf.R;R/interpret_cohens_d.R;R/interpret_cohens_g.R;R/interpret_ess_rhat.R;R/interpret_oddsratio.R;R/interpret_p.R;R/interpret_pd.R;R/interpret_r.R;R/interpret_r2.R;R/rank_ANOVA.R;R/rank_diff.R;R/repeated_measures_d.R;R/utils.R;R/utils_ci.R;R/utils_interpret.R;R/utils_validate_input_data.R;cran-comments.md;data-raw/df data.R;man/interpret.Rd;man/interpret_bf.Rd;man/interpret_p.Rd;tests/testthat/test-interpret.R,False,True,True,False,229,188,417,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size
-Version: 0.8.8.2
+Version: 0.8.9
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",
@@ -72,10 +72,10 @@ Depends:
     R (>= 3.6)
 Imports:
     bayestestR (>= 0.13.2),
-    insight (>= 0.19.10),
-    parameters (>= 0.21.7),
-    performance (>= 0.11.0),
-    datawizard (>= 0.10.0),
+    insight (>= 0.20.1),
+    parameters (>= 0.22.0),
+    performance (>= 0.12.0),
+    datawizard (>= 0.11.0),
     stats,
     utils
 Suggests:
@@ -112,4 +112,3 @@ Config/Needs/website:
     rstudio/bslib,
     r-lib/pkgdown,
     easystats/easystatstemplate
-Remotes: easystats/insight, easystats/datawizard, easystats/bayestestR, easystats/parameters, easystats/performance

---FILE: NEWS.md---
@@ -1,3 +1,9 @@
+# effectsize 0.8.9
+
+## Bug fixes
+
+- `interpret(<effectsize_table>)` no longer returns transformed effect sizes ( #640 )
+
 # effectsize 0.8.8
 
 ## Bug fixes

---FILE: R/cohens_g.R---
@@ -76,25 +76,23 @@ cohens_g <- function(x, y = NULL,
       insight::format_error(""'x' and 'y' must have the same number of levels (minimum 2)"")
     }
     x <- table(x, y)
-  } else {
-    if ((nrow(x) < 2) || (ncol(x) != nrow(x))) {
-      insight::format_error(""'x' must be square with at least two rows and columns"")
-    }
+  } else if ((nrow(x) < 2) || (ncol(x) != nrow(x))) {
+    insight::format_error(""'x' must be square with at least two rows and columns"")
   }
 
 
-  b <- x[upper.tri(x)]
-  c <- t(x)[upper.tri(x)]
+  a <- x[upper.tri(x)]
+  b <- t(x)[upper.tri(x)]
 
-  P <- sum(pmax(b, c)) / (sum(b) + sum(c))
+  P <- sum(pmax(a, b)) / (sum(a) + sum(b))
   g <- P - 0.5
 
   out <- data.frame(Cohens_g = g)
 
   if (.test_ci(ci)) {
     out$CI <- ci
 
-    n <- sum(b) + sum(c)
+    n <- sum(a) + sum(b)
     k <- P * n
 
     res <- stats::prop.test(k, n,

---FILE: R/common_language.R---
@@ -369,8 +369,8 @@ wmw_odds <- function(x, y = NULL, data = NULL,
     y <- data[data$g == ""y"", ""r""]
 
     .foo <- function(p) {
-      diff <- stats::quantile(x, probs = c(p, 1 - p)) - stats::quantile(y, probs = c(1 - p, p))
-      min(abs(diff))
+      difference <- stats::quantile(x, probs = c(p, 1 - p)) - stats::quantile(y, probs = c(1 - p, p))
+      min(abs(difference))
     }
 
     stats::optim(

---FILE: R/convert_between_odds_to_probs.R---
@@ -78,10 +78,10 @@ probs_to_odds.data.frame <- function(probs, log = FALSE, select = NULL, exclude
 #' @keywords internal
 .odds_to_probs_df <- function(odds = NULL, probs = NULL, log = FALSE, select = NULL, exclude = NULL, ...) {
   # If vector
-  if (!is.null(odds)) {
-    df <- odds
+  if (is.null(odds)) {
+    mydata <- probs
   } else {
-    df <- probs
+    mydata <- odds
   }
 
   # check for formula notation, convert to character vector
@@ -93,55 +93,55 @@ probs_to_odds.data.frame <- function(probs, log = FALSE, select = NULL, exclude
   }
 
   # Variable order
-  var_order <- names(df)
+  var_order <- names(mydata)
 
   # Keep subset
-  if (!is.null(select) && select %in% names(df)) {
+  if (!is.null(select) && select %in% names(mydata)) {
     select <- as.vector(select)
-    to_keep <- as.data.frame(df[!names(df) %in% select])
-    df <- df[names(df) %in% select]
+    to_keep <- as.data.frame(mydata[!names(mydata) %in% select])
+    mydata <- mydata[names(mydata) %in% select]
   } else {
     to_keep <- NULL
   }
 
   # Remove exceptions
-  if (!is.null(exclude) && exclude %in% names(df)) {
+  if (!is.null(exclude) && exclude %in% names(mydata)) {
     exclude <- as.vector(exclude)
     if (is.null(to_keep)) {
-      to_keep <- as.data.frame(df[exclude])
+      to_keep <- as.data.frame(mydata[exclude])
     } else {
-      to_keep <- cbind(to_keep, as.data.frame(df[exclude]))
+      to_keep <- cbind(to_keep, as.data.frame(mydata[exclude]))
     }
 
-    df <- df[!names(df) %in% exclude]
+    mydata <- mydata[!names(mydata) %in% exclude]
   }
 
   # Remove non-numerics
-  is_num <- vapply(df, is.numeric, logical(1))
-  dfother <- df[!is_num]
-  dfnum <- df[is_num]
+  is_num <- vapply(mydata, is.numeric, logical(1))
+  dfother <- mydata[!is_num]
+  dfnum <- mydata[is_num]
 
   # Tranform
-  if (!is.null(odds)) {
-    dfnum <- data.frame(lapply(dfnum, odds_to_probs.numeric, log = log))
-  } else {
+  if (is.null(odds)) {
     dfnum <- data.frame(lapply(dfnum, probs_to_odds.numeric, log = log))
+  } else {
+    dfnum <- data.frame(lapply(dfnum, odds_to_probs.numeric, log = log))
   }
 
   # Add non-numerics
   if (is.null(ncol(dfother))) {
-    df <- dfnum
+    mydata <- dfnum
   } else {
-    df <- cbind(dfother, dfnum)
+    mydata <- cbind(dfother, dfnum)
   }
 
   # Add exceptions
   if (!is.null(select) || !is.null(exclude) && exists(""to_keep"")) {
-    df <- cbind(df, to_keep)
+    mydata <- cbind(mydata, to_keep)
   }
 
   # Reorder
-  df <- df[var_order]
+  mydata <- mydata[var_order]
 
-  return(df)
+  mydata
 }

---FILE: R/effectsize.htest.R---
@@ -100,7 +100,7 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
 
   cl <- match.call()
   cl <- cl[-which(names(cl) == ""subset"")]
-  dots <- list(eval(cl, parent.frame()))
+  dots <- insight::compact_list(list(eval(cl, parent.frame())))
 
   dots$alternative <- model$alternative
   dots$ci <- attr(model$conf.int, ""conf.level"")

---FILE: R/eta_squared-main.R---
@@ -294,7 +294,7 @@ cohens_f <- function(model,
 
   es_name <- get_effectsize_name(colnames(res))
   res[[es_name]] <- res[[es_name]] / (1 - res[[es_name]])
-  if (grepl(""_partial"", es_name)) {
+  if (grepl(""_partial"", es_name, fixed = TRUE)) {
     colnames(res)[colnames(res) == es_name] <- ""Cohens_f2_partial""
   } else {
     colnames(res)[colnames(res) == es_name] <- ""Cohens_f2""
@@ -430,7 +430,7 @@ cohens_f_squared <- function(model,
 
 
   # Estimate effect size ---
-  if (type == ""eta"") {
+  if (type == ""eta"") { # nolint
     if (isTRUE(generalized) || is.character(generalized)) {
       ## copied from afex
       obs <- logical(nrow(aov_table))
@@ -448,37 +448,36 @@ cohens_f_squared <- function(model,
 
       aov_table$Eta2_generalized <- aov_table$Sum_Squares /
         (aov_table$Sum_Squares + values$Sum_Squares_residuals + obs_SSn1 - obs_SSn2)
-    } else if (!isTRUE(partial)) {
-      aov_table$Eta2 <- aov_table$Sum_Squares /
-        values$Sum_Squares_total
-    } else {
+    } else if (isTRUE(partial)) {
       aov_table$Eta2_partial <-
         aov_table$Sum_Squares /
           (aov_table$Sum_Squares + values$Sum_Squares_residuals)
+    } else {
+      aov_table$Eta2 <- aov_table$Sum_Squares / values$Sum_Squares_total
     }
   } else if (type == ""omega"") {
-    if (!isTRUE(partial)) {
-      aov_table$Omega2 <-
-        (aov_table$Sum_Squares - aov_table$df * values$Mean_Square_residuals) /
-          (values$Sum_Squares_total + values$Mean_Square_residuals)
-      aov_table$Omega2 <- pmax(0, aov_table$Omega2)
-    } else {
+    if (isTRUE(partial)) {
       aov_table$Omega2_partial <-
         (aov_table$Sum_Squares - aov_table$df * values$Mean_Square_residuals) /
           (aov_table$Sum_Squares + (values$n - aov_table$df) * values$Mean_Square_residuals)
       aov_table$Omega2_partial <- pmax(0, aov_table$Omega2_partial)
+    } else {
+      aov_table$Omega2 <-
+        (aov_table$Sum_Squares - aov_table$df * values$Mean_Square_residuals) /
+          (values$Sum_Squares_total + values$Mean_Square_residuals)
+      aov_table$Omega2 <- pmax(0, aov_table$Omega2)
     }
   } else if (type == ""epsilon"") {
-    if (!isTRUE(partial)) {
-      aov_table$Epsilon2 <-
-        (aov_table$Sum_Squares - aov_table$df * values$Mean_Square_residuals) /
-          values$Sum_Squares_total
-      aov_table$Epsilon2 <- pmax(0, aov_table$Epsilon2)
-    } else {
+    if (isTRUE(partial)) {
       aov_table$Epsilon2_partial <-
         (aov_table$Sum_Squares - aov_table$df * values$Mean_Square_residuals) /
           (aov_table$Sum_Squares + values$Sum_Squares_residuals)
       aov_table$Epsilon2_partial <- pmax(0, aov_table$Epsilon2_partial)
+    } else {
+      aov_table$Epsilon2 <-
+        (aov_table$Sum_Squares - aov_table$df * values$Mean_Square_residuals) /
+          values$Sum_Squares_total
+      aov_table$Epsilon2 <- pmax(0, aov_table$Epsilon2)
     }
   }
 
@@ -570,7 +569,7 @@ cohens_f_squared <- function(model,
 
 
   # Estimate effect size ---
-  if (type == ""eta"") {
+  if (type == ""eta"") { # nolint
     if (isTRUE(generalized) || is.character(generalized)) {
       ## copied from afex
       obs <- logical(nrow(aov_table))
@@ -589,12 +588,12 @@ cohens_f_squared <- function(model,
       aov_table$Eta2_generalized <- aov_table$Sum_Squares /
         (aov_table$Sum_Squares + sum(sapply(values, ""[["", ""Sum_Squares_residuals"")) +
           obs_SSn1 - obs_SSn2)
-    } else if (!isTRUE(partial)) {
-      aov_table$Eta2 <- aov_table$Sum_Squares / Sum_Squares_total
-    } else {
+    } else if (isTRUE(partial)) {
       aov_table$Eta2_partial <-
         aov_table$Sum_Squares /
           (aov_table$Sum_Squares + Sum_Squares_residuals)
+    } else {
+      aov_table$Eta2 <- aov_table$Sum_Squares / Sum_Squares_total
     }
   } else if (type == ""omega"") {
     SSS_values <- values[[which(names(values) %in% DV_names)]]
@@ -603,29 +602,29 @@ cohens_f_squared <- function(model,
     Mean_Squares_Subjects <- SSS_values$Mean_Square_residuals
 
     # implemented from https://www.jasonfinley.com/tools/OmegaSquaredQuickRef_JRF_3-31-13.pdf/
-    if (!isTRUE(partial)) {
-      aov_table$Omega2 <-
-        (aov_table$Sum_Squares - aov_table$df * Mean_Square_residuals) /
-          (Sum_Squares_total + Mean_Squares_Subjects)
-      aov_table$Omega2 <- pmax(0, aov_table$Omega2)
-    } else {
+    if (isTRUE(partial)) {
       aov_table$Omega2_partial <-
         (aov_table$Sum_Squares - aov_table$df * Mean_Square_residuals) /
           (aov_table$Sum_Squares + is_within * Sum_Squares_residuals +
             Sum_Squares_Subjects + Mean_Squares_Subjects)
       aov_table$Omega2_partial <- pmax(0, aov_table$Omega2_partial)
+    } else {
+      aov_table$Omega2 <-
+        (aov_table$Sum_Squares - aov_table$df * Mean_Square_residuals) /
+          (Sum_Squares_total + Mean_Squares_Subjects)
+      aov_table$Omega2 <- pmax(0, aov_table$Omega2)
     }
   } else if (type == ""epsilon"") {
-    if (!isTRUE(partial)) {
-      aov_table$Epsilon2 <-
-        (aov_table$Sum_Squares - aov_table$df * Mean_Square_residuals) /
-          Sum_Squares_total
-      aov_table$Epsilon2 <- pmax(0, aov_table$Epsilon2)
-    } else {
+    if (isTRUE(partial)) {
       aov_table$Epsilon2_partial <-
         (aov_table$Sum_Squares - aov_table$df * Mean_Square_residuals) /
           (aov_table$Sum_Squares + Sum_Squares_residuals)
       aov_table$Epsilon2_partial <- pmax(0, aov_table$Epsilon2_partial)
+    } else {
+      aov_table$Epsilon2 <-
+        (aov_table$Sum_Squares - aov_table$df * Mean_Square_residuals) /
+          Sum_Squares_total
+      aov_table$Epsilon2 <- pmax(0, aov_table$Epsilon2)
     }
   }
 
@@ -819,7 +818,7 @@ cohens_f_squared <- function(model,
     df_error = model[, df_errori],
     stringsAsFactors = FALSE
   )
-  par_table <- par_table[!par_table[[""Parameter""]] %in% ""Residuals"", ]
+  par_table <- par_table[par_table[[""Parameter""]] != ""Residuals"", ]
 
   out <-
     .es_aov_table(
@@ -833,7 +832,8 @@ cohens_f_squared <- function(model,
       include_intercept = include_intercept
     )
 
-  attr(out, ""anova_type"") <- tryCatch(attr(parameters::model_parameters(model, verbose = FALSE, effects = ""fixed"", es_type = NULL), ""anova_type""),
+  ## TODO: add back `effects = ""fixed""` once the deprecation warning in parameters is removed
+  attr(out, ""anova_type"") <- tryCatch(attr(parameters::model_parameters(model, verbose = FALSE, es_type = NULL), ""anova_type""),
     error = function(...) 1
   )
   attr(out, ""approximate"") <- TRUE
@@ -864,7 +864,8 @@ cohens_f_squared <- function(model,
 
   # TODO this should be in .anova_es.anvoa
   # TODO the aoc method should convert to an anova table, then pass to anova
-  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"", es_type = NULL)
+  ## TODO: add back `effects = ""fixed""` once the deprecation warning in parameters is removed
+  params <- parameters::model_parameters(model, verbose = verbose, es_type = NULL)
   out <- .es_aov_simple(as.data.frame(params),
     type = type,
     partial = partial, generalized = generalized,
@@ -890,7 +891,8 @@ cohens_f_squared <- function(model,
                               verbose = TRUE,
                               include_intercept = FALSE,
                               ...) {
-  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"", es_type = NULL)
+  ## TODO: add back `effects = ""fixed""` once the deprecation warning in parameters is removed
+  params <- parameters::model_parameters(model, verbose = verbose, es_type = NULL)
   anova_type <- attr(params, ""anova_type"")
   params <- as.data.frame(params)
 
@@ -944,11 +946,11 @@ cohens_f_squared <- function(model,
   df_residuals <- sum(params[iResid, ""df""])
 
   list(
-    ""Mean_Square_residuals"" = Mean_Square_residuals,
-    ""Sum_Squares_residuals"" = Sum_Squares_residuals,
-    ""Sum_Squares_total"" = Sum_Squares_total,
-    ""n_terms"" = N_terms,
-    ""n"" = N,
-    ""df_residuals"" = df_residuals
+    Mean_Square_residuals = Mean_Square_residuals,
+    Sum_Squares_residuals = Sum_Squares_residuals,
+    Sum_Squares_total = Sum_Squares_total,
+    n_terms = N_terms,
+    n = N,
+    df_residuals = df_residuals
   )
 }

---FILE: R/eta_squared-methods.R---
@@ -78,7 +78,9 @@
            verbose = TRUE,
            include_intercept = FALSE,
            ...) {
-    suppressWarnings(aov_tab <- summary(model)$univariate.tests)
+    suppressWarnings({
+      aov_tab <- summary(model)$univariate.tests
+    })
 
     # if there are univariate.tests, will return a global effect size
     if (is.null(aov_tab)) {
@@ -107,17 +109,17 @@
     aov_tab <- aov_tab[c(""Parameter"", ""Sum_Squares"", ""Error SS"", ""df"", ""den Df"")]
 
     id <- ""Subject""
-    within <- names(model$idata)
-    within <- lapply(within, function(x) c(NA, x))
-    within <- do.call(expand.grid, within)
-    within <- apply(within, 1, stats::na.omit)
-    ns <- sapply(within, length)
-    within <- sapply(within, paste, collapse = "":"")
-    within <- within[order(ns)]
-    within <- Filter(function(x) nchar(x) > 0, within)
-    l <- sapply(within, grepl, x = aov_tab$Parameter, simplify = TRUE)
-    l <- apply(l, 1, function(x) if (!any(x)) 0 else max(which(x)))
-    l <- c(NA, within)[l + 1]
+    within_subj <- names(model$idata)
+    within_subj <- lapply(within_subj, function(x) c(NA, x))
+    within_subj <- do.call(expand.grid, within_subj)
+    within_subj <- apply(within_subj, 1, stats::na.omit)
+    ns <- lengths(within_subj)
+    within_subj <- sapply(within_subj, paste, collapse = "":"")
+    within_subj <- within_subj[order(ns)]
+    within_subj <- Filter(function(x) nzchar(x, keepNA = TRUE), within_subj)
+    l <- sapply(within_subj, grepl, x = aov_tab$Parameter, simplify = TRUE)
+    l <- apply(l, 1, function(x) if (any(x)) max(which(x)) else 0)
+    l <- c(NA, within_subj)[l + 1]
     l <- sapply(l, function(x) paste0(stats::na.omit(c(id, x)), collapse = "":""))
     aov_tab$Group <- l
 
@@ -132,10 +134,10 @@
     aov_tab <- do.call(rbind, aov_tab)
     aov_tab[[""Error SS""]] <- NULL
     aov_tab[[""den Df""]] <- NULL
-    aov_tab$`F` <- ifelse(aov_tab$Parameter == ""Residuals"", NA, 1)
+    aov_tab[[""F""]] <- ifelse(aov_tab$Parameter == ""Residuals"", NA, 1)
     aov_tab$Mean_Square <- aov_tab$Sum_Squares / aov_tab$df
 
-    DV_names <- c(id, setdiff(unlist(strsplit(model$terms, "":"")), ""(Intercept)""))
+    DV_names <- c(id, setdiff(unlist(strsplit(model$terms, "":"", fixed = TRUE)), ""(Intercept)""))
 
     out <-
       .es_aov_strata(
@@ -172,7 +174,7 @@
   out <- .anova_es(pars, ...)
   attr(out, ""anova_type"") <- attr(pars, ""anova_type"")
   attr(out, ""approximate"") <- TRUE
-  return(out)
+  out
 }
 
 
@@ -255,7 +257,8 @@
                            ci = 0.95, alternative = ""greater"",
                            verbose = TRUE,
                            ...) {
-  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"", es_type = NULL)
+  ## TODO: add back `effects = ""fixed""` once the deprecation warning in parameters is removed
+  params <- parameters::model_parameters(model, verbose = verbose, es_type = NULL)
   anova_type <- attr(params, ""anova_type"")
 
   params <- split(params, factor(params$Response, levels = unique(params$Response))) # make sure row order is not changed

---FILE: R/interpret.R---
@@ -91,6 +91,8 @@ is.rules <- function(x) inherits(x, ""rules"")
 #'   frame of class `effectsize_table`.
 #' @param rules Set of [rules()]. When `x` is a data frame, can be a name of an
 #'   established set of rules.
+#' @param transform a function (or name of a function) to apply to `x` before
+#'   interpreting. See examples.
 #' @param ... Currently not used.
 #' @inheritParams rules
 #'
@@ -109,6 +111,10 @@ is.rules <- function(x) inherits(x, ""rules"")
 #' interpret(c(0.35, 0.15), c(""small"" = 0.2, ""large"" = 0.4), name = ""Cohen's Rules"")
 #' interpret(c(0.35, 0.15), rules(c(0.2, 0.4), c(""small"", ""medium"", ""large"")))
 #'
+#' bigness <- rules(c(1, 10), c(""small"", ""medium"", ""big""))
+#' interpret(abs(-5), bigness)
+#' interpret(-5, bigness, transform = abs)
+#'
 #' # ----------
 #' d <- cohens_d(mpg ~ am, data = mtcars)
 #' interpret(d, rules = ""cohen1988"")
@@ -133,21 +139,31 @@ interpret <- function(x, ...) {
 
 #' @rdname interpret
 #' @export
-interpret.numeric <- function(x, rules, name = attr(rules, ""rule_name""), ...) {
+interpret.numeric <- function(x, rules, name = attr(rules, ""rule_name""),
+                              transform = NULL, ...) {
+  # This is meant to circumvent https://github.com/easystats/report/issues/442
+  if (is.character(transform)) {
+    transform <- match.fun(transform)
+  } else if (!is.function(transform)) {
+    transform <- identity
+  }
+
+  x_tran <- transform(x)
+
   if (!inherits(rules, ""rules"")) {
     rules <- rules(rules)
   }
 
   if (is.null(name)) name <- ""Custom rules""
   attr(rules, ""rule_name"") <- name
 
-  if (length(x) > 1) {
-    out <- vapply(x, .interpret, rules = rules, FUN.VALUE = character(1L))
+  if (length(x_tran) > 1) {
+    out <- vapply(x_tran, .interpret, rules = rules, FUN.VALUE = character(1L))
   } else {
-    out <- .interpret(x, rules = rules)
+    out <- .interpret(x_tran, rules = rules)
   }
 
-  names(out) <- names(x)
+  names(out) <- names(x_tran)
 
   class(out) <- c(""effectsize_interpret"", class(out))
   attr(out, ""rules"") <- rules
@@ -156,11 +172,18 @@ interpret.numeric <- function(x, rules, name = attr(rules, ""rule_name""), ...) {
 
 #' @rdname interpret
 #' @export
-interpret.effectsize_table <- function(x, rules, ...) {
+interpret.effectsize_table <- function(x, rules, transform = NULL, ...) {
   if (missing(rules)) insight::format_error(""You {.b must} specify the rules of interpretation!"")
 
+  # This is meant to circumvent https://github.com/easystats/report/issues/442
+  if (is.character(transform)) {
+    transform <- match.fun(transform)
+  } else if (!is.function(transform)) {
+    transform <- identity
+  }
+
   es_name <- colnames(x)[is_effectsize_name(colnames(x))]
-  value <- x[[es_name]]
+  value <- transform(x[[es_name]])
 
   x$Interpretation <- switch(es_name,
     ## std diff

---FILE: R/interpret_bf.R---
@@ -30,7 +30,7 @@
 #'
 #' @examples
 #' interpret_bf(1)
-#' interpret_bf(c(5, 2))
+#' interpret_bf(c(5, 2, 0.01))
 #'
 #' @references
 #' - Jeffreys, H. (1961), Theory of Probability, 3rd ed., Oxford University
@@ -50,21 +50,13 @@ interpret_bf <- function(bf,
                          include_value = FALSE,
                          protect_ratio = TRUE,
                          exact = TRUE) {
-  if (log) bf <- exp(bf)
-
-  if (any(bf < 0, na.rm = TRUE)) {
-    insight::format_warning(""Negative BFs detected. These are not possible, and are {.i ignored}."")
-    bf[bf < 0] <- NA
+  if (!log && any(bf < 0, na.rm = TRUE)) {
+    insight::format_error(""Negative BFs detected. These are not possible, and are {.i ignored}."")
   }
 
-  orig_bf <- bf
-
-  dir <- rep(""against or in favour of"", length.out = length(bf))
-  dir <- replace(dir, is.na(bf), NA_character_)
-  dir <- replace(dir, bf < 1, ""against"")
-  dir <- replace(dir, bf > 1, ""in favour of"")
-  bf <- exp(abs(log(bf)))
+  if (!log) bf <- log(bf)
 
+  # interpret strength
   rules <- .match.rules(
     rules,
     list(
@@ -77,27 +69,23 @@ interpret_bf <- function(bf,
     )
   )
 
-  interpretation <- interpret(bf, rules)
+  interpretation <- interpret(bf, rules, transform = function(.x) exp(abs(.x)))
+  interpretation[bf == 0] <- ""no""
 
-  # Format text
-  interpretation[] <- paste0(interpretation, "" evidence"")
-  interpretation[orig_bf == 1] <- ""no evidence""
+  # interpret direction
+  dir <- interpret(bf, rules(0, c(""against"", ""in favour of"")))
+  dir[bf == 0] <- ""against or in favour of""
 
-  # Add value if asked for
+  # Format text
   if (include_value) {
-    interpretation[] <-
-      paste0(
-        interpretation,
-        "" ("",
-        insight::format_bf(orig_bf, protect_ratio = protect_ratio, exact = exact),
-        "")""
-      )
+    bf_fmt <- insight::format_bf(exp(bf), protect_ratio = protect_ratio, exact = exact)
+    interpretation[] <- sprintf(""%s evidence (%s) %s"", interpretation, bf_fmt, dir)
+  } else {
+    interpretation[] <- paste0(interpretation, "" evidence "", dir)
   }
 
-  # Add direction
-  interpretation[] <- paste(interpretation[], dir)
-
-  interpretation[is.na(orig_bf)] <- """"
+  interpretation[is.na(bf)] <- """"
+  interpretation[] <- trimws(interpretation, ""right"")
 
   interpretation
 }

---FILE: R/interpret_cohens_d.R---
@@ -81,7 +81,7 @@ interpret_cohens_d <- function(d, rules = ""cohen1988"", ...) {
     )
   )
 
-  interpret(abs(d), rules)
+  interpret(d, rules, transform = abs)
 }
 
 #' @rdname interpret_cohens_d

---FILE: R/interpret_cohens_g.R---
@@ -42,5 +42,5 @@ interpret_cohens_g <- function(g, rules = ""cohen1988"", ...) {
     )
   )
 
-  interpret(abs(g), rules)
+  interpret(g, rules, transform = abs)
 }

---FILE: R/interpret_ess_rhat.R---
@@ -45,11 +45,11 @@ interpret_ess <- function(ess, rules = ""burkner2017"") {
   rules <- .match.rules(
     rules,
     list(
-      burkner2017 = rules(c(1000), c(""insufficient"", ""sufficient""), name = ""burkner2017"", right = FALSE)
+      burkner2017 = rules(1000, c(""insufficient"", ""sufficient""), name = ""burkner2017"", right = FALSE)
     )
   )
 
-  interpret(abs(ess), rules)
+  interpret(ess, rules)
 }
 
 
@@ -60,10 +60,10 @@ interpret_rhat <- function(rhat, rules = ""vehtari2019"") {
   rules <- .match.rules(
     rules,
     list(
-      vehtari2019 = rules(c(1.01), c(""converged"", ""failed""), name = ""vehtari2019""),
-      gelman1992 = rules(c(1.1), c(""converged"", ""failed""), name = ""gelman1992"")
+      vehtari2019 = rules(1.01, c(""converged"", ""failed""), name = ""vehtari2019""),
+      gelman1992 = rules(1.1, c(""converged"", ""failed""), name = ""gelman1992"")
     )
   )
 
-  interpret(abs(rhat), rules)
+  interpret(rhat, rules)
 }

---FILE: R/interpret_oddsratio.R---
@@ -42,15 +42,15 @@
 #' @export
 interpret_oddsratio <- function(OR, rules = ""chen2010"", log = FALSE, ...) {
   if (log) {
-    OR <- exp(abs(OR))
+    f_transform <- function(.x) exp(abs(.x))
   } else {
-    OR <- exp(abs(log(OR)))
+    f_transform <- function(.x) exp(abs(log(.x)))
   }
 
 
   if (is.character(rules) && rules == ""cohen1988"") {
-    d <- oddsratio_to_d(OR, log = FALSE)
-    return(interpret_cohens_d(abs(d), rules = rules))
+    d <- oddsratio_to_d(OR, log = log)
+    return(interpret_cohens_d(d, rules = rules))
   }
 
   rules <- .match.rules(
@@ -63,5 +63,5 @@ interpret_oddsratio <- function(OR, rules = ""chen2010"", log = FALSE, ...) {
     )
   )
 
-  interpret(OR, rules)
+  interpret(OR, rules, transform = f_transform)
 }

---FILE: R/interpret_p.R---
@@ -21,6 +21,11 @@
 #' interpret_p(c(.5, .02, 0.001))
 #' interpret_p(c(.5, .02, 0.001), rules = ""rss"")
 #'
+#' stars <- rules(c(0.001, 0.01, 0.05, 0.1), c(""***"", ""**"", ""*"", ""+"", """"),
+#'   right = FALSE, name = ""stars""
+#' )
+#' interpret_p(c(.5, .02, 0.001), rules = stars)
+#'
 #' @keywords interpreters
 #' @export
 interpret_p <- function(p, rules = ""default"") {

---FILE: R/interpret_pd.R---
@@ -30,7 +30,7 @@ interpret_pd <- function(pd, rules = ""default"", ...) {
   rules <- .match.rules(
     rules,
     list(
-      default = rules(c(0.975), c(""not significant"", ""significant""),
+      default = rules(0.975, c(""not significant"", ""significant""),
         name = ""default"", right = TRUE
       ),
       makowski2019 = rules(c(0.95, 0.97, 0.99, 0.999), c(""uncertain"", ""possibly existing"", ""likely existing"", ""probably existing"", ""certainly existing""),

---FILE: R/interpret_r.R---
@@ -106,7 +106,7 @@ interpret_r <- function(r, rules = ""funder2019"", ...) {
     )
   )
 
-  interpret(abs(r), rules)
+  interpret(r, rules, transform = abs)
 }
 
 #' @export

---FILE: R/interpret_r2.R---
@@ -55,7 +55,7 @@ interpret_r2 <- function(r2, rules = ""cohen1988"") {
       cohen1988 = rules(c(0.02, 0.13, 0.26), c(""very weak"", ""weak"", ""moderate"", ""substantial""),
         name = ""cohen1988"", right = FALSE
       ),
-      falk1992 = rules(c(0.10), c(""negligible"", ""adequate""),
+      falk1992 = rules(0.10, c(""negligible"", ""adequate""),
         name = ""falk1992"", right = FALSE
       ),
       chin1998 = rules(c(0.19, 0.33, 0.67), c(""very weak"", ""weak"", ""moderate"", ""substantial""),

---FILE: R/rank_ANOVA.R---
@@ -226,7 +226,7 @@ kendalls_w <- function(x, groups, blocks, data = NULL,
 .reta <- function(data) {
   model <- suppressWarnings(stats::kruskal.test(data$x, data$groups))
 
-  k <- length(levels(data$groups))
+  k <- nlevels(data$groups)
   n <- nrow(data)
   E <- model$statistic
 
@@ -244,7 +244,10 @@ kendalls_w <- function(x, groups, blocks, data = NULL,
   R <- colSums(rankings)
 
   no_ties <- apply(rankings, 1, function(x) length(x) == insight::n_unique(x))
-  if (!all(no_ties)) {
+  if (all(no_ties)) {
+    S <- stats::var(R) * (n - 1)
+    W <- (12 * S) / (m^2 * (n^3 - n))
+  } else {
     if (verbose) {
       insight::format_warning(
         sprintf(
@@ -264,10 +267,6 @@ kendalls_w <- function(x, groups, blocks, data = NULL,
 
     W <- (12 * sum(R^2) - 3 * (m^2) * n * ((n + 1)^2)) /
       (m^2 * (n^3 - n) - m * Tj)
-  } else {
-    S <- stats::var(R) * (n - 1)
-    W <- (12 * S) /
-      (m^2 * (n^3 - n))
   }
   W
 }

---FILE: R/rank_diff.R---
@@ -156,7 +156,7 @@ rank_biserial <- function(x, y = NULL, data = NULL,
 
     alpha <- 1 - ci.level
 
-    rf <- atanh(r_rbs)
+    rank_f <- atanh(r_rbs)
     if (is_paired_or_onesample) {
       nd <- sum((x - mu) != 0)
       maxw <- (nd^2 + nd) / 2
@@ -185,9 +185,9 @@ rank_biserial <- function(x, y = NULL, data = NULL,
       rfSE <- sqrt((n1 + n2 + 1) / (3 * n1 * n2))
     }
 
-    confint <- tanh(rf + c(-1, 1) * stats::qnorm(1 - alpha / 2) * rfSE)
-    out$CI_low <- confint[1]
-    out$CI_high <- confint[2]
+    conf_int <- tanh(rank_f + c(-1, 1) * stats::qnorm(1 - alpha / 2) * rfSE)
+    out$CI_low <- conf_int[1]
+    out$CI_high <- conf_int[2]
     ci_method <- list(method = ""normal"")
     out <- .limit_ci(out, alternative, -1, 1)
   } else {

---FILE: R/repeated_measures_d.R---
@@ -185,9 +185,9 @@ repeated_measures_d <- function(x, y,
     probs <- c(alpha / 2, 1 - alpha / 2)
     qs <- stats::qnorm(probs)
 
-    confint <- out[[""d""]] + qs * values[[""se""]]
-    out$CI_low <- confint[1]
-    out$CI_high <- confint[2]
+    conf_int <- out[[""d""]] + qs * values[[""se""]]
+    out$CI_low <- conf_int[1]
+    out$CI_high <- conf_int[2]
 
     ci_method <- list(method = ""normal"")
     out <- .limit_ci(out, alternative, -Inf, Inf)
@@ -231,11 +231,11 @@ rm_d <- repeated_measures_d
 
   m <- mean(x - y)
   n <- length(x)
-  df <- n - 1
+  dof <- n - 1
   r <- stats::cor(x, y)
   f <- 2 * (1 - r)
 
-  if (method == ""rm"") {
+  if (method == ""rm"") { # nolint
     s <- stats::sd(x - y) / sqrt(f)
     d <- (m - mu) / s
 
@@ -261,7 +261,7 @@ rm_d <- repeated_measures_d
     se <- sqrt(f / n + (d^2) / (2 * n))
   }
 
-  .nlist(d, se, df)
+  .nlist(d, se, df = dof)
 }
 
 #' @keywords internal

---FILE: R/utils.R---
@@ -1,5 +1,5 @@
 #' @keywords internal
-"".someattributes<-"" <- function(x, value) {
+`.someattributes<-` <- function(x, value) {
   for (a in names(value)) {
     attr(x, a) <- value[[a]]
   }

---FILE: R/utils_ci.R---
@@ -1,7 +1,5 @@
 # NCP -------------------------
 
-# TODO: other packages like lmeInfo, MOTE and others use qt/qf for these.
-
 #' @keywords internal
 .get_ncp_F <- function(f, df, df_error, conf.level = 0.9) {
   if (!is.finite(f) || !is.finite(df) || !is.finite(df_error)) {
@@ -15,8 +13,8 @@
   ncp <- suppressWarnings(stats::optim(
     par = 1.1 * rep(lambda, 2),
     fn = function(x) {
-      q <- stats::qf(p = probs, df, df_error, ncp = x)
-      sum(abs(q - f))
+      quan <- stats::qf(p = probs, df, df_error, ncp = x)
+      sum(abs(quan - f))
     },
     control = list(abstol = 1e-09)
   ))
@@ -45,8 +43,8 @@
   ncp <- suppressWarnings(stats::optim(
     par = 1.1 * rep(t, 2),
     fn = function(x) {
-      q <- stats::qt(p = probs, df = df_error, ncp = x)
-      sum(abs(q - t))
+      quan <- stats::qt(p = probs, df = df_error, ncp = x)
+      sum(abs(quan - t))
     },
     control = list(abstol = 1e-09)
   ))
@@ -68,8 +66,8 @@
   ncp <- suppressWarnings(stats::optim(
     par = 1.1 * rep(chisq, 2),
     fn = function(x) {
-      q <- stats::qchisq(p = probs, df, ncp = x)
-      sum(abs(q - chisq))
+      quan <- stats::qchisq(p = probs, df, ncp = x)
+      sum(abs(quan - chisq))
     },
     control = list(abstol = 1e-09)
   ))
@@ -100,7 +98,7 @@
     ci > 1) {
     insight::format_error(""ci must be a single numeric value between (0, 1)"")
   }
-  return(TRUE)
+  TRUE
 }
 
 #' @keywords internal

---FILE: R/utils_interpret.R---
@@ -15,5 +15,5 @@
     )
   }
 
-  return(choices[[rule]])
+  choices[[rule]]
 }

---FILE: R/utils_validate_input_data.R---
@@ -254,8 +254,7 @@
                                     wide = TRUE, allow_ordered = FALSE,
                                     verbose = TRUE, ...) {
   if (inherits(x, ""formula"")) {
-    if (length(x) != 3L ||
-      x[[3L]][[1L]] != as.name(""|"")) {
+    if (length(x) != 3L || x[[3L]][[1L]] != as.name(""|"")) {
       insight::format_error(""Formula must have the 'x ~ groups | blocks'."")
     }
 
@@ -323,7 +322,7 @@
                                    verbose = TRUE, ...) {
   if (inherits(x, ""formula"")) {
     if (length(x) != 3L || length(x[[3]]) != 1L) {
-      insight::format_error(""Formula must have the form of 'DV1 + ... + DVk ~ group', with exactly one term on the RHS."")
+      insight::format_error(""Formula must have the form of 'DV1 + ... + DVk ~ group', with exactly one term on the RHS."") # nolint
     }
 
     data <- .resolve_formula(stats::reformulate(as.character(x)[3:2]), data, ...)

---FILE: cran-comments.md---
@@ -8,9 +8,9 @@
 
 * local installation: R 4.3.2 on Windows
 * GitHub Actions
-    - Windows:        release
+    - Windows:        release, oldrel
     - macOS:          release
-    - ubuntu-18.04:   release, oldrel, 4.0, 3.6
+    - ubuntu-18.04:   release, oldrel, 4.3
 * win-builder:        release
 
 
@@ -21,7 +21,7 @@
 
 ## revdepcheck results
 
-We checked 20 reverse dependencies, comparing R CMD check results across CRAN and dev versions of this package.
+We checked 23 reverse dependencies, comparing R CMD check results across CRAN and dev versions of this package.
 
  * We saw 0 new problems
  * We failed to check 0 packages

---FILE: data-raw/df data.R---
@@ -16,7 +16,7 @@ screening_test <- data.frame(
   Test1 = rep(screening_test[[1]], times = screening_test$Freq),
   Test2 = rep(screening_test[[2]], times = screening_test$Freq)
 )
-i <- sample(1600, size = 800)
+i <- sample.int(1600, size = 800)
 screening_test$Diagnosis[i] <- screening_test$Test1[i]
 screening_test$Diagnosis[-i] <- screening_test$Test2[-i]
 screening_test$Diagnosis <- factor(screening_test$Diagnosis, labels = c(""Neg"", ""Pos""))

---FILE: man/interpret.Rd---
@@ -8,9 +8,9 @@
 \usage{
 interpret(x, ...)
 
-\method{interpret}{numeric}(x, rules, name = attr(rules, ""rule_name""), ...)
+\method{interpret}{numeric}(x, rules, name = attr(rules, ""rule_name""), transform = NULL, ...)
 
-\method{interpret}{effectsize_table}(x, rules, ...)
+\method{interpret}{effectsize_table}(x, rules, transform = NULL, ...)
 }
 \arguments{
 \item{x}{Vector of value break points (edges defining categories), or a data
@@ -22,6 +22,9 @@ frame of class \code{effectsize_table}.}
 established set of rules.}
 
 \item{name}{Name of the set of rules (will be printed).}
+
+\item{transform}{a function (or name of a function) to apply to \code{x} before
+interpreting. See examples.}
 }
 \value{
 \itemize{
@@ -42,6 +45,10 @@ interpret(c(0.01, 0.005, 0.08), rules_grid)
 interpret(c(0.35, 0.15), c(""small"" = 0.2, ""large"" = 0.4), name = ""Cohen's Rules"")
 interpret(c(0.35, 0.15), rules(c(0.2, 0.4), c(""small"", ""medium"", ""large"")))
 
+bigness <- rules(c(1, 10), c(""small"", ""medium"", ""big""))
+interpret(abs(-5), bigness)
+interpret(-5, bigness, transform = abs)
+
 # ----------
 d <- cohens_d(mpg ~ am, data = mtcars)
 interpret(d, rules = ""cohen1988"")

---FILE: man/interpret_bf.Rd---
@@ -62,7 +62,7 @@ Rules apply to BF as ratios, so BF of 10 is as extreme as a BF of 0.1 (1/10).
 
 \examples{
 interpret_bf(1)
-interpret_bf(c(5, 2))
+interpret_bf(c(5, 2, 0.01))
 
 }
 \references{

---FILE: man/interpret_p.Rd---
@@ -36,6 +36,11 @@ Interpret \emph{p}-Values
 interpret_p(c(.5, .02, 0.001))
 interpret_p(c(.5, .02, 0.001), rules = ""rss"")
 
+stars <- rules(c(0.001, 0.01, 0.05, 0.1), c(""***"", ""**"", ""*"", ""+"", """"),
+  right = FALSE, name = ""stars""
+)
+interpret_p(c(.5, .02, 0.001), rules = stars)
+
 }
 \references{
 \itemize{

---FILE: tests/testthat/test-interpret.R---
@@ -92,7 +92,7 @@ test_that(""interpret_r2"", {
 
 
 test_that(""interpret_bf"", {
-  expect_warning(interpret_bf(-2), ""Negative"")
+  expect_error(interpret_bf(-2), ""Negative"")
   expect_equal(interpret_bf(1)[1], ""no evidence against or in favour of"")
   expect_equal(
     interpret_bf(c(0.8, 3.5), ""jeffreys1961"")[1:2],
@@ -252,4 +252,13 @@ test_that(""interpret effectsize_table"", {
   expect_output(print(V_), ""Interpretation rule: funder2019"")
 
   expect_error(interpret(d), ""must specify"")
+
+  d1 <- cohens_d(mtcars$wt, mu = 4)
+  d2 <- cohens_d(-mtcars$wt, mu = -4)
+  d1_ <- interpret(d1, rules = ""cohen1988"")
+  d2_ <- interpret(d2, rules = ""cohen1988"")
+
+  expect_equal(d1_$Interpretation, d2_$Interpretation)
+  expect_equal(d1_[[1]], d1[[1]])
+  expect_equal(d2_[[1]], d2[[1]])
 })",True,False,Dependency / Package,7
easystats,effectsize,985529622411d019c96df196bab745dbfc21083f,Mattan S. Ben-Shachar,mattansb@msbstats.info,2024-06-23T14:31:13Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2024-06-23T14:31:13Z,fix note,R/interpret_r.R;man/interpret_r.Rd,False,True,True,False,8,8,16,"---FILE: R/interpret_r.R---
@@ -6,10 +6,10 @@
 #' @param ... Not directly used.
 #'
 #' @details
-#' Since Cohen's _w_ does not have an upper bound, for all by the most simple of
-#' cases (2-by-2 or 1-by-2 tables), interpreting Cohen's _w_ as a correlation
-#' coefficient is inappropriate (Ben-Shachar, et al., 2024; Cohen, 1988, p.
-#' 222). Please us [cramers_v()] of the like instead.
+#' Since Cohen's _w_ does not have a fixed upper bound, for all by the most
+#' simple of cases (2-by-2 or 1-by-2 tables), interpreting Cohen's _w_ as a
+#' correlation coefficient is inappropriate (Ben-Shachar, et al., 2024; Cohen,
+#' 1988, p. 222). Please us [cramers_v()] of the like instead.
 #'
 #'
 #' @note As \eqn{\phi}{\phi} can be larger than 1 - it is recommended to compute

---FILE: man/interpret_r.Rd---
@@ -30,10 +30,10 @@ interpret_fei(r, rules = ""funder2019"", ...)
 Interpret Correlation Coefficient
 }
 \details{
-Since Cohen's \emph{w} does not have an upper bound, for all by the most simple of
-cases (2-by-2 or 1-by-2 tables), interpreting Cohen's \emph{w} as a correlation
-coefficient is inappropriate (Ben-Shachar, et al., 2024; Cohen, 1988, p.
-222). Please us \code{\link[=cramers_v]{cramers_v()}} of the like instead.
+Since Cohen's \emph{w} does not have a fixed upper bound, for all by the most
+simple of cases (2-by-2 or 1-by-2 tables), interpreting Cohen's \emph{w} as a
+correlation coefficient is inappropriate (Ben-Shachar, et al., 2024; Cohen,
+1988, p. 222). Please us \code{\link[=cramers_v]{cramers_v()}} of the like instead.
 }
 \note{
 As \eqn{\phi}{\phi} can be larger than 1 - it is recommended to compute",True,False,Documentation / Formatting,6
easystats,effectsize,ad36239a9edaa4b33364822aad753ff2ebdfb795,Mattan S. Ben-Shachar,mattansb@msbstats.info,2024-06-19T10:56:00Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2024-06-19T10:56:00Z,"Switch to es_type

https://github.com/easystats/parameters/issues/978",DESCRIPTION;R/eta_squared-main.R;R/eta_squared-methods.R,False,True,True,False,6,6,12,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size
-Version: 0.8.8.1
+Version: 0.8.8.2
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",
@@ -73,7 +73,7 @@ Depends:
 Imports:
     bayestestR (>= 0.13.2),
     insight (>= 0.19.10),
-    parameters (>= 0.21.6),
+    parameters (>= 0.21.7),
     performance (>= 0.11.0),
     datawizard (>= 0.10.0),
     stats,

---FILE: R/eta_squared-main.R---
@@ -833,7 +833,7 @@ cohens_f_squared <- function(model,
       include_intercept = include_intercept
     )
 
-  attr(out, ""anova_type"") <- tryCatch(attr(parameters::model_parameters(model, verbose = FALSE, effects = ""fixed"", effectsize_type = NULL), ""anova_type""),
+  attr(out, ""anova_type"") <- tryCatch(attr(parameters::model_parameters(model, verbose = FALSE, effects = ""fixed"", es_type = NULL), ""anova_type""),
     error = function(...) 1
   )
   attr(out, ""approximate"") <- TRUE
@@ -864,7 +864,7 @@ cohens_f_squared <- function(model,
 
   # TODO this should be in .anova_es.anvoa
   # TODO the aoc method should convert to an anova table, then pass to anova
-  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"", effectsize_type = NULL)
+  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"", es_type = NULL)
   out <- .es_aov_simple(as.data.frame(params),
     type = type,
     partial = partial, generalized = generalized,
@@ -890,7 +890,7 @@ cohens_f_squared <- function(model,
                               verbose = TRUE,
                               include_intercept = FALSE,
                               ...) {
-  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"", effectsize_type = NULL)
+  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"", es_type = NULL)
   anova_type <- attr(params, ""anova_type"")
   params <- as.data.frame(params)
 

---FILE: R/eta_squared-methods.R---
@@ -255,7 +255,7 @@
                            ci = 0.95, alternative = ""greater"",
                            verbose = TRUE,
                            ...) {
-  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"", effectsize_type = NULL)
+  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"", es_type = NULL)
   anova_type <- attr(params, ""anova_type"")
 
   params <- split(params, factor(params$Response, levels = unique(params$Response))) # make sure row order is not changed",True,False,Dependency / Package,6
easystats,effectsize,23a522ed827e68749b2317a3d68c0286350776ed,Mattan S. Ben-Shachar,mattansb@msbstats.info,2024-06-13T07:18:33Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2024-06-13T07:18:33Z,more fixes for #645,R/cohens_d.R;R/common_language.R;R/convert_between_common_language.R;R/rank_diff.R;man/effectsize_CIs.Rd;tests/testthat/test-rankES.R,False,True,True,False,32,17,49,"---FILE: R/cohens_d.R---
@@ -214,13 +214,14 @@ glass_delta <- function(x, y = NULL, data = NULL,
     )
   }
 
-  is_paired_or_onesample <- paired
   if (is.null(y)) {
     if (type == ""delta"") {
       insight::format_error(""For Glass' Delta, please provide data from two samples."")
     }
     y <- 0
     is_paired_or_onesample <- TRUE
+  } else {
+    is_paired_or_onesample <- paired
   }
 
   # Compute index

---FILE: R/common_language.R---
@@ -129,10 +129,6 @@ p_superiority <- function(x, y = NULL, data = NULL,
   paired <- data[[""paired""]]
 
   if (parametric) {
-    if (paired) {
-      x <- x - y
-      y <- NULL
-    }
     d <- cohens_d(
       x = x,
       y = y,

---FILE: R/convert_between_common_language.R---
@@ -257,14 +257,24 @@ d_to_overlap.effectsize_difference <- function(d) {
 
 #' @keywords internal
 .is_cles_applicable <- function(d, allow_paired = FALSE) {
-  !any(colnames(d) %in% c(""Cohens_d"", ""Hedges_g"")) ||
-    (isTRUE(attr(d, ""paired"")) && !allow_paired) ||
-    (!isTRUE(attr(d, ""paired"")) && !isTRUE(attr(d, ""pooled_sd"")))
+  paired <- attr(d, ""paired"")
+  pooled_sd <- attr(d, ""pooled_sd"")
+
+  # Effect size is d or g
+  any(colnames(d) %in% c(""Cohens_d"", ""Hedges_g"")) &&
+    (
+      # Is paired when allowed
+      (isTRUE(paired) && allow_paired) ||
+        # Is one sample when allowed
+        (!isTRUE(paired) && is.null(pooled_sd) && allow_paired) ||
+        # Is independent with pooled sd
+        (!isTRUE(paired) && isTRUE(pooled_sd))
+    )
 }
 
 #' @keywords internal
 .cohens_d_to_cles <- function(d, converter, allow_paired = FALSE) {
-  if (.is_cles_applicable(d, allow_paired)) {
+  if (!.is_cles_applicable(d, allow_paired)) {
     insight::format_error(""Common language effect size only applicable to 2-sample Cohen's d with pooled SD."")
   }
 

---FILE: R/rank_diff.R---
@@ -140,11 +140,13 @@ rank_biserial <- function(x, y = NULL, data = NULL,
 
   if (is.null(y)) {
     y <- 0
-    paired <- TRUE
+    is_paired_or_onesample <- TRUE
+  } else {
+    is_paired_or_onesample <- paired
   }
 
   ## Compute
-  r_rbs <- .r_rbs(x, y, mu = mu, paired = paired, verbose = verbose)
+  r_rbs <- .r_rbs(x, y, mu = mu, paired = is_paired_or_onesample, verbose = verbose)
   out <- data.frame(r_rank_biserial = r_rbs)
 
   ## CI
@@ -155,7 +157,7 @@ rank_biserial <- function(x, y = NULL, data = NULL,
     alpha <- 1 - ci.level
 
     rf <- atanh(r_rbs)
-    if (paired) {
+    if (is_paired_or_onesample) {
       nd <- sum((x - mu) != 0)
       maxw <- (nd^2 + nd) / 2
 
@@ -216,7 +218,7 @@ cliffs_delta <- function(x, y = NULL, data = NULL,
   )
   x <- data$x
   y <- data$y
-  if (is.null(y) || isTRUE(match.call()$paired) || isTRUE(data[[""paired""]])) {
+  if (is.null(y) || isTRUE(cl$paired) || isTRUE(data[[""paired""]])) {
     insight::format_error(""This effect size is only applicable for two independent samples."")
   }
 

---FILE: man/effectsize_CIs.Rd---
@@ -121,7 +121,9 @@ eta_squared(fit) # default, ci = 0.95, alternative = ""greater""
 #> n_comps   | 0.19 | [0.14, 1.00]
 #> 
 #> - One-sided CIs: upper bound fixed at [1.00].
-eta_squared(fit, alternative = ""less"") # Test is eta is smaller than some value
+}\if{html}{\out{</div>}}
+
+\if{html}{\out{<div class=""sourceCode r"">}}\preformatted{eta_squared(fit, alternative = ""less"") # Test is eta is smaller than some value
 #> For one-way between subjects designs, partial eta squared is equivalent
 #>   to eta squared. Returning eta squared.
 #> # Effect Size for ANOVA
@@ -131,15 +133,19 @@ eta_squared(fit, alternative = ""less"") # Test is eta is smaller than some value
 #> n_comps   | 0.19 | [0.00, 0.24]
 #> 
 #> - One-sided CIs: lower bound fixed at [0.00].
-eta_squared(fit, alternative = ""two.sided"") # 2-sided bounds for alpha = .05
+}\if{html}{\out{</div>}}
+
+\if{html}{\out{<div class=""sourceCode r"">}}\preformatted{eta_squared(fit, alternative = ""two.sided"") # 2-sided bounds for alpha = .05
 #> For one-way between subjects designs, partial eta squared is equivalent
 #>   to eta squared. Returning eta squared.
 #> # Effect Size for ANOVA
 #> 
 #> Parameter | Eta2 |       95\% CI
 #> -------------------------------
 #> n_comps   | 0.19 | [0.14, 0.25]
-eta_squared(fit, ci = 0.9, alternative = ""two.sided"") # both 1-sided bounds for alpha = .05
+}\if{html}{\out{</div>}}
+
+\if{html}{\out{<div class=""sourceCode r"">}}\preformatted{eta_squared(fit, ci = 0.9, alternative = ""two.sided"") # both 1-sided bounds for alpha = .05
 #> For one-way between subjects designs, partial eta squared is equivalent
 #>   to eta squared. Returning eta squared.
 #> # Effect Size for ANOVA

---FILE: tests/testthat/test-rankES.R---
@@ -5,7 +5,7 @@ test_that(""rank_biserial"", {
   rRB1 <- rank_biserial(x, y, paired = TRUE)
   rRB2 <- rank_biserial(x - y)
 
-  expect_equal(rRB1, rRB2)
+  expect_equal(rRB1, rRB2, ignore_attr = TRUE)
   expect_equal(rRB1[[1]], 0.777, tolerance = 0.01)
   expect_equal(rRB1$CI_low, 0.2953631, tolerance = 0.01)
   expect_equal(rRB1$CI_high, 0.9441559, tolerance = 0.01)",True,False,Documentation / Formatting,6
easystats,effectsize,e251f1805984d8e1f3c5cd4d46e0a177e0d3d727,Mattan S. Ben-Shachar,mattansb@msbstats.info,2024-06-13T05:54:30Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2024-06-13T05:54:30Z,fix #645,R/cohens_d.R,False,True,True,False,3,2,5,"---FILE: R/cohens_d.R---
@@ -214,16 +214,17 @@ glass_delta <- function(x, y = NULL, data = NULL,
     )
   }
 
+  is_paired_or_onesample <- paired
   if (is.null(y)) {
     if (type == ""delta"") {
       insight::format_error(""For Glass' Delta, please provide data from two samples."")
     }
     y <- 0
-    paired <- TRUE
+    is_paired_or_onesample <- TRUE
   }
 
   # Compute index
-  if (paired) {
+  if (is_paired_or_onesample) {
     if (type == ""delta"") {
       insight::format_error(""This effect size is only applicable for two independent samples."")
     }",True,False,Implementation / Logic,6
easystats,effectsize,a065eae1462749ab6fb0d3cd332d051a631c2531,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2024-05-27T05:22:24Z,GitHub,noreply@github.com,2024-05-27T05:22:24Z,"don't partialy match `effect` in `model_parameters()` (#641)

* don't partialy match effect in parameters

* Build favicons for pkgdown website locally

https://github.com/easystats/easystats/issues/407",R/eta_squared-main.R;R/eta_squared-methods.R;pkgdown/_pkgdown.yml;pkgdown/favicon/apple-touch-icon-120x120.png;pkgdown/favicon/apple-touch-icon-60x60.png;pkgdown/favicon/apple-touch-icon-76x76.png;pkgdown/favicon/apple-touch-icon.png;pkgdown/favicon/favicon-16x16.png;pkgdown/favicon/favicon-32x32.png;pkgdown/favicon/favicon.ico,False,True,True,False,4,4,8,"---FILE: R/eta_squared-main.R---
@@ -833,7 +833,7 @@ cohens_f_squared <- function(model,
       include_intercept = include_intercept
     )
 
-  attr(out, ""anova_type"") <- tryCatch(attr(parameters::model_parameters(model, verbose = FALSE, effects = ""fixed""), ""anova_type""),
+  attr(out, ""anova_type"") <- tryCatch(attr(parameters::model_parameters(model, verbose = FALSE, effects = ""fixed"", effectsize_type = NULL), ""anova_type""),
     error = function(...) 1
   )
   attr(out, ""approximate"") <- TRUE
@@ -864,7 +864,7 @@ cohens_f_squared <- function(model,
 
   # TODO this should be in .anova_es.anvoa
   # TODO the aoc method should convert to an anova table, then pass to anova
-  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"")
+  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"", effectsize_type = NULL)
   out <- .es_aov_simple(as.data.frame(params),
     type = type,
     partial = partial, generalized = generalized,
@@ -890,7 +890,7 @@ cohens_f_squared <- function(model,
                               verbose = TRUE,
                               include_intercept = FALSE,
                               ...) {
-  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"")
+  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"", effectsize_type = NULL)
   anova_type <- attr(params, ""anova_type"")
   params <- as.data.frame(params)
 

---FILE: R/eta_squared-methods.R---
@@ -255,7 +255,7 @@
                            ci = 0.95, alternative = ""greater"",
                            verbose = TRUE,
                            ...) {
-  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"")
+  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"", effectsize_type = NULL)
   anova_type <- attr(params, ""anova_type"")
 
   params <- split(params, factor(params$Response, levels = unique(params$Response))) # make sure row order is not changed",True,False,Implementation / Logic,6
easystats,effectsize,7cbed4ff4aba1f68bcc1a79d93e80cf68f004fd0,RÃ©mi ThÃ©riault,13123390+rempsyc@users.noreply.github.com,2024-05-11T16:44:27Z,GitHub,noreply@github.com,2024-05-11T16:44:27Z,"Adds data argument to effectsize.htest/cohens_d (#522)

Adds data argument to effectsize.htest/cohens_d, fixes #245",R/cohens_d.R;R/effectsize.htest.R;tests/testthat/test-htest_data.R,False,True,True,False,466,84,550,"---FILE: R/cohens_d.R---
@@ -195,7 +195,7 @@ glass_delta <- function(x, y = NULL, data = NULL,
 
   if (type != ""delta"") {
     if (.is_htest_of_type(x, ""t-test"")) {
-      return(effectsize(x, type = type, verbose = verbose, ...))
+      return(effectsize(x, type = type, verbose = verbose, data = data, ...))
     } else if (.is_BF_of_type(x, c(""BFoneSample"", ""BFindepSample""), ""t-squared"")) {
       return(effectsize(x, ci = ci, verbose = verbose, ...))
     }
@@ -234,7 +234,7 @@ glass_delta <- function(x, y = NULL, data = NULL,
 
     hn <- 1 / n
     se <- s / sqrt(n)
-    df <- n - 1
+    df1 <- n - 1
 
     pooled_sd <- NULL
   } else {
@@ -252,22 +252,22 @@ glass_delta <- function(x, y = NULL, data = NULL,
         s <- suppressWarnings(sd_pooled(x, y))
         hn <- (1 / n1 + 1 / n2)
         se <- s * sqrt(1 / n1 + 1 / n2)
-        df <- n - 2
+        df1 <- n - 2
       } else {
         s <- sqrt((s1^2 + s2^2) / 2)
         hn <- (2 * (n2 * s1^2 + n1 * s2^2)) / (n1 * n2 * (s1^2 + s2^2))
         se1 <- sqrt(s1^2 / n1)
         se2 <- sqrt(s2^2 / n2)
         se <- sqrt(se1^2 + se2^2)
-        df <- se^4 / (se1^4 / (n1 - 1) + se2^4 / (n2 - 1))
+        df1 <- se^4 / (se1^4 / (n1 - 1) + se2^4 / (n2 - 1))
       }
     } else if (type == ""delta"") {
       pooled_sd <- NULL
 
       s <- s2
       hn <- 1 / n2 + s1^2 / (n1 * s2^2)
       se <- (s2 * sqrt(1 / n2 + s1^2 / (n1 * s2^2)))
-      df <- n2 - 1
+      df1 <- n2 - 1
     }
   }
 
@@ -278,22 +278,21 @@ glass_delta <- function(x, y = NULL, data = NULL,
   if (.test_ci(ci)) {
     # Add cis
     out$CI <- ci
-    ci.level <- .adjust_ci(ci, alternative)
+    ci_level <- .adjust_ci(ci, alternative)
 
-    t <- (d - mu) / se
-    ts <- .get_ncp_t(t, df, ci.level)
+    t1 <- (d - mu) / se
+    ts1 <- .get_ncp_t(t1, df1, ci_level)
 
-    out$CI_low <- ts[1] * sqrt(hn)
-    out$CI_high <- ts[2] * sqrt(hn)
+    out$CI_low <- ts1[1] * sqrt(hn)
+    out$CI_high <- ts1[2] * sqrt(hn)
     ci_method <- list(method = ""ncp"", distribution = ""t"")
     out <- .limit_ci(out, alternative, -Inf, Inf)
   } else {
     ci_method <- alternative <- NULL
   }
 
-
   if (adjust) {
-    J <- .J(df)
+    J <- .J(df1)
     col_to_adjust <- intersect(colnames(out), c(types[type], ""CI_low"", ""CI_high""))
     out[, col_to_adjust] <- out[, col_to_adjust] * J
 
@@ -311,6 +310,6 @@ glass_delta <- function(x, y = NULL, data = NULL,
 }
 
 #' @keywords internal
-.J <- function(df) {
-  exp(lgamma(df / 2) - log(sqrt(df / 2)) - lgamma((df - 1) / 2)) # exact method
+.J <- function(df1) {
+  exp(lgamma(df1 / 2) - log(sqrt(df1 / 2)) - lgamma((df1 - 1) / 2)) # exact method
 }

---FILE: R/effectsize.htest.R---
@@ -30,28 +30,89 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
   }
 }
 
+#' @keywords internal
+.data_from_formula <- function(model_data, model, verbose = TRUE, ...) {
+  if (is.null(model_data) && ""data"" %in% names(match.call())) {
+    vars <- insight::get_parameters(model)$Parameter
+    vars_split <- unlist(strsplit(vars, "" by | and ""))
+    data_ellipsis <- eval.parent(match.call()[[""data""]])
+    if (!grepl(""\\$|\\["", vars) && length(vars_split) > 1) {
+      if (grepl(""by|and"", vars)) {
+        vars <- sub(""by|and"", ""~"", vars, perl = TRUE)
+        vars <- sub(""and"", ""|"", vars, fixed = TRUE)
+        if (!grepl(""|"", vars, fixed = TRUE)) {
+          form <- stats::as.formula(vars)
+          data_out <- .resolve_formula(form, ...)
+          data_out[[2]] <- factor(data_out[[2]])
+        } else if (all(vars_split %in% names(data_ellipsis))) {
+          # We need a special case for the Friedman test
+          # because ""In Ops.factor(w, t) : â|â not meaningful for factors""
+          # When used with the | operator within the formula
+          data_out <- stats::model.frame(...)
+          if (all(vars_split %in% names(data_out))) {
+            data_out <- data_out[vars_split]
+          } else {
+            data_out <- NULL
+          }
+        }
+      }
+    } else if (grepl(""$"", vars, fixed = TRUE)) {
+      # Special case for square bracket subsetting
+      # E.g., x = dat$mpg[dat$am == 1], y = dat$mpg[dat$am == 0]
+      vars_cols <- gsub(""(\\b\\w+\\$)"", paste0(match.call()[[""data""]], ""$""), vars)
+      columns <- unlist(strsplit(vars_cols, "" and "", fixed = TRUE))
+      x <- eval(parse(text = columns[1]))
+      y <- eval(parse(text = columns[2]))
+      data_out <- list(x, y)
+      # Not necessary to subset/na.omit here because not formula interface
+    } else if (grepl(""\\$|\\["", vars)) {
+      # Special case for single-sample square bracket subsetting
+      # E.g., x = mtcars[[col_y]]
+      if (length(vars_split) == 1) {
+        data_out <- data_ellipsis
+        # Not necessary to subset/na.omit here because not formula interface
+      } else {
+        obj <- gsub("".*?\\[([^\\[\\]]+)\\].*"", ""\\1"", vars, perl = TRUE)
+        message(""Is object '"", obj, ""' still available in your workspace?"")
+      }
+    } else if (length(vars_split) == 1) {
+      form <- stats::as.formula(paste0(vars, ""~1""))
+      data_out <- .resolve_formula(form, ...)
+    } else if (verbose) {
+      message(""To use the `data` argument, consider using modifiers outside the formula."")
+    }
+  } else {
+    data_out <- model_data
+  }
+  data_out
+}
+
 #' @keywords internal
 .effectsize_t.test <- function(model, type = NULL, verbose = TRUE, ...) {
   # Get data?
-  data <- insight::get_data(model)
-  approx <- is.null(data)
+  model_data <- insight::get_data(model)
+  data1 <- .data_from_formula(model_data, model, verbose, ...)
 
-  dots <- list(...)
+  approx1 <- is.null(data1)
 
   if (is.null(type) || tolower(type) == ""cohens_d"") type <- ""d""
   if (tolower(type) == ""hedges_g"") type <- ""g""
 
+  cl <- match.call()
+  cl <- cl[-which(names(cl) == ""subset"")]
+  dots <- list(eval(cl, parent.frame()))
+
   dots$alternative <- model$alternative
   dots$ci <- attr(model$conf.int, ""conf.level"")
   dots$mu <- model$null.value
   dots$paired <- grepl(""Paired"", model$method, fixed = TRUE)
   dots$verbose <- verbose
 
   if (!type %in% c(""d"", ""g"")) {
-    .fail_if_approx(approx, if (startsWith(type, ""rm"")) ""rm_d"" else ""cles"")
+    .fail_if_approx(approx1, if (startsWith(type, ""rm"")) ""rm_d"" else ""cles"")
   }
 
-  if (approx) {
+  if (approx1) {
     if (verbose) {
       insight::format_warning(
         ""Unable to retrieve data from htest object."",
@@ -60,34 +121,41 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
     }
 
     f <- t_to_d
-    args <- list(
+    args1 <- list(
       t = unname(model$statistic),
       df_error = unname(model$parameter)
     )
   } else {
-    if (ncol(data) == 2) {
-      data[[2]] <- factor(data[[2]])
+    if (inherits(data1, ""data.frame"") && ncol(data1) == 2) {
+      data1[[2]] <- factor(data1[[2]])
     }
-    data <- stats::na.omit(data)
+    data1 <- stats::na.omit(data1)
 
-    args <- list(
-      x = data[[1]],
-      y = if (ncol(data) == 2) data[[2]],
-      pooled_sd = !grepl(""Welch"", model$method, fixed = TRUE)
-    )
+    if (inherits(data1, ""numeric"")) {
+      args1 <- list(
+        x = data1,
+        pooled_sd = !grepl(""Welch"", model$method, fixed = TRUE)
+      )
+    } else {
+      args1 <- list(
+        x = data1[[1]],
+        y = if (length(data1) == 2) data1[[2]],
+        pooled_sd = !grepl(""Welch"", model$method, fixed = TRUE)
+      )
+    }
 
     if (type %in% c(""d"", ""g"")) {
       f <- switch(tolower(type),
         d = cohens_d,
         g = hedges_g
       )
     } else if (dots$paired && startsWith(type, ""rm"")) {
-      args[c(""x"", ""y"")] <- split(args$x, args$y)
-      dots$paired <- args$pooled_sd <- NULL
-      args$method <- gsub(""^rm\\_"", """", type)
+      args1[c(""x"", ""y"")] <- split(args1$x, args1$y)
+      dots$paired <- args1$pooled_sd <- NULL
+      args1$method <- gsub(""^rm\\_"", """", type)
       f <- rm_d
     } else {
-      if (!dots$paired && !args$pooled_sd) {
+      if (!dots$paired && !args1$pooled_sd) {
         insight::format_error(""Common language effect size only applicable to Cohen's d with pooled SD."")
       }
 
@@ -102,19 +170,20 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
     }
   }
 
-  out <- do.call(f, c(args, dots))
-  attr(out, ""approximate"") <- approx
+  out <- do.call(f, c(args1, dots))
+  attr(out, ""approximate"") <- approx1
   out
 }
 
 #' @keywords internal
 .effectsize_chisq.test_dep <- function(model, type = NULL, verbose = TRUE, ...) {
   # Get data?
-  data <- insight::get_data(model)
-  approx <- is.null(data)
-
+  model_data <- insight::get_data(model)
+  data1 <- .data_from_formula(model_data, model, verbose, ...)
   dots <- list(...)
 
+  approx1 <- is.null(data1)
+
   Obs <- model$observed
   Exp <- model$expected
 
@@ -197,8 +266,8 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
   if (!is.null(model[[""conf.int""]])) dots$ci <- attr(model[[""conf.int""]], ""conf.level"")
   if (!is.null(model[[""alternative""]])) dots$alternative <- model[[""alternative""]]
 
-  data <- insight::get_data(model)
-  .fail_if_approx(is.null(data), type)
+  data1 <- insight::get_data(model)
+  .fail_if_approx(is.null(data1), type)
 
   f <- switch(tolower(type),
     v = ,
@@ -220,23 +289,24 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
     nnt = nnt
   )
 
-  if (is.table(data)) {
-    args <- list(x = data)
+  if (is.table(data1)) {
+    args1 <- list(x = data1)
   } else {
-    args <- list(x = data[[1]], y = data[[2]])
+    args1 <- list(x = data1[[1]], y = data1[[2]])
   }
 
-  do.call(f, c(args, dots))
+  do.call(f, c(args1, dots))
 }
 
 #' @keywords internal
 .effectsize_chisq.test_gof <- function(model, type = NULL, verbose = TRUE, ...) {
   # Get data?
-  data <- insight::get_data(model)
-  approx <- is.null(data)
-
+  model_data <- insight::get_data(model)
+  data1 <- .data_from_formula(model_data, model, verbose, ...)
   dots <- list(...)
 
+  approx1 <- is.null(data1)
+
   Obs <- model$observed
   Exp <- model$expected
   nr <- length(Obs)
@@ -270,12 +340,13 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
 #' @keywords internal
 .effectsize_oneway.test <- function(model, type = NULL, verbose = TRUE, ...) {
   # Get data?
-  data <- insight::get_data(model)
-  approx <- is.null(data)
+  model_data <- insight::get_data(model)
+  data1 <- .data_from_formula(model_data, model, verbose, ...)
 
-  dots <- list(...)
+  approx1 <- is.null(data1)
 
-  if ((approx <- grepl(""not assuming"", model$method, fixed = TRUE)) && verbose) {
+  approx1 <- grepl(""not assuming"", model$method, fixed = TRUE)
+  if (approx1 && verbose) {
     insight::format_alert(""`var.equal = FALSE` - effect size is an {.b approximation.}"")
   }
 
@@ -306,49 +377,53 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
     ...
   )
   colnames(out)[1] <- sub(""_partial"", """", colnames(out)[1], fixed = TRUE)
-  attr(out, ""approximate"") <- approx
+  attr(out, ""approximate"") <- approx1
   out
 }
 
 #' @keywords internal
 .effectsize_mcnemar.test <- function(model, type = NULL, verbose = TRUE, ...) {
   # Get data?
-  data <- insight::get_data(model)
-  approx <- is.null(data)
+  model_data <- insight::get_data(model)
+  data1 <- .data_from_formula(model_data, model, verbose, ...)
 
-  dots <- list(...)
+  approx1 <- is.null(data1)
 
-  .fail_if_approx(approx, ""cohens_g"")
+  .fail_if_approx(approx1, ""cohens_g"")
 
-  if (inherits(data, ""table"")) {
-    out <- cohens_g(data, verbose = verbose, ...)
+  if (inherits(data1, ""table"")) {
+    out <- cohens_g(data1, verbose = verbose, ...)
   } else {
-    out <- cohens_g(data[[1]], data[[2]], verbose = verbose, ...)
+    out <- cohens_g(data1[[1]], data1[[2]], verbose = verbose, ...)
   }
   out
 }
 
 #' @keywords internal
 .effectsize_wilcox.test <- function(model, type = NULL, verbose = TRUE, ...) {
   # Get data?
-  data <- insight::get_data(model)
-  approx <- is.null(data)
+  model_data <- insight::get_data(model)
+  data1 <- .data_from_formula(model_data, model, verbose, ...)
 
-  dots <- list(...)
+  approx1 <- is.null(data1)
 
   if (is.null(type) || tolower(type) == ""rank_biserial"") type <- ""rb""
 
+  cl <- match.call()
+  cl <- cl[-which(names(cl) == ""subset"")]
+  dots <- list(eval(cl, parent.frame()))
+
   dots$alternative <- model$alternative
   dots$ci <- attr(model$conf.int, ""conf.level"")
   dots$mu <- model$null.value
   dots$paired <- grepl(""signed rank"", model$method, fixed = TRUE)
 
-  .fail_if_approx(approx, type)
+  .fail_if_approx(approx1, type)
 
-  if (ncol(data) == 2) {
-    data[[2]] <- factor(data[[2]])
+  if (ncol(data1) == 2) {
+    data1[[2]] <- factor(data1[[2]])
   }
-  data <- stats::na.omit(data)
+  data1 <- stats::na.omit(data1)
 
   f <- switch(tolower(type),
     rb = rank_biserial,
@@ -361,64 +436,64 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
     wmw_odds = wmw_odds
   )
 
-  args <- list(
-    x = data[[1]],
-    y = if (ncol(data) == 2) data[[2]],
+  args1 <- list(
+    x = data1[[1]],
+    y = if (ncol(data1) == 2) data1[[2]],
     verbose = verbose
   )
 
   if (tolower(type) != ""rb"") {
     if (dots$paired) {
       insight::format_error(""Common language effect size only applicable to 2-sample rank-biserial correlation."")
     }
-    args$parametric <- FALSE
+    args1$parametric <- FALSE
   }
 
-  out <- do.call(f, c(args, dots))
+  out <- do.call(f, c(args1, dots))
   out
 }
 
 #' @keywords internal
 .effectsize_kruskal.test <- function(model, type = NULL, verbose = TRUE, ...) {
   # Get data?
-  data <- insight::get_data(model)
-  approx <- is.null(data)
+  model_data <- insight::get_data(model)
+  data1 <- .data_from_formula(model_data, model, verbose, ...)
 
-  dots <- list(...)
+  approx1 <- is.null(data1)
 
   if (is.null(type)) type <- ""epsilon""
 
-  .fail_if_approx(approx, ""rank_epsilon_squared"")
+  .fail_if_approx(approx1, ""rank_epsilon_squared"")
 
   f <- switch(type,
     epsilon = rank_epsilon_squared,
     eta = rank_eta_squared
   )
 
-  if (inherits(data, ""data.frame"")) {
-    out <- f(data[[1]], data[[2]], verbose = verbose, ...)
+  if (inherits(data1, ""data.frame"")) {
+    out <- f(data1[[1]], data1[[2]], verbose = verbose, ...)
   } else {
     # data frame
-    out <- f(data, verbose = verbose, ...)
+    out <- f(data1, verbose = verbose, ...)
   }
   out
 }
 
 #' @keywords internal
 .effectsize_friedman.test <- function(model, type = NULL, verbose = TRUE, ...) {
   # Get data?
-  data <- insight::get_data(model)
-  approx <- is.null(data)
+  model_data <- insight::get_data(model)
+  data1 <- .data_from_formula(model_data, model, verbose, ...)
 
-  dots <- list(...)
+  approx1 <- is.null(data1)
 
-  .fail_if_approx(approx, ""kendalls_w"")
+  .fail_if_approx(approx1, ""kendalls_w"")
 
-  if (inherits(data, ""table"")) {
-    data <- as.data.frame(data)[c(""Freq"", ""Var2"", ""Var1"")]
+  if (inherits(data1, ""table"")) {
+    data1 <- as.data.frame(data1)[c(""Freq"", ""Var2"", ""Var1"")]
   }
 
-  out <- kendalls_w(data[[1]], data[[2]], data[[3]], verbose = verbose, ...)
+  out <- kendalls_w(data1[[1]], data1[[2]], data1[[3]], verbose = verbose, ...)
   out
 }
 

---FILE: tests/testthat/test-htest_data.R---
@@ -0,0 +1,308 @@
+test_that(""basic examples"", {
+  if (getRversion() < ""4.1.3"") {
+    skip_on_os(""linux"")
+  }
+
+  # t.test
+  x <- t.test(mpg ~ vs, data = mtcars)
+  expect_warning(effectsize(x), ""Unable to retrieve data"")
+  expect_no_warning(effectsize(x, data = mtcars))
+
+  # cor.test
+  # no need to specify the data argument
+  x <- cor.test(~ qsec + drat, data = mtcars)
+  expect_warning(effectsize(x), ""'htest' method is not"")
+
+  # wilcox.test
+  x <- wilcox.test(mpg ~ vs, data = mtcars, exact = FALSE)
+  expect_error(effectsize(x), ""Unable to retrieve data"")
+  expect_no_warning(effectsize(x, data = mtcars))
+
+  # friedman.test
+  wb <- aggregate(warpbreaks$breaks, by = list(
+    w = warpbreaks$wool, t = warpbreaks$tension
+  ), FUN = mean)
+  x <- friedman.test(x ~ w | t, data = wb)
+  expect_error(effectsize(x), ""Unable to retrieve data"")
+  expect_no_warning(effectsize(x, data = wb))
+
+  # kruskal.test
+  airquality2 <- airquality
+  airquality2$Month <- as.factor(airquality2$Month)
+  airquality2$Ozone <- ifelse(is.na(airquality2$Ozone), 10, airquality2$Ozone)
+  x <- kruskal.test(Ozone ~ Month, data = airquality2)
+  expect_error(effectsize(x), ""Unable to retrieve data"")
+  expect_no_warning(effectsize(x, data = airquality2))
+})
+
+test_that(""edge cases"", {
+  # Example 1
+  tt1 <- t.test(mpg ~ I(am + cyl == 4), data = mtcars)
+  dd1 <- cohens_d(mpg ~ I(am + cyl == 4), data = mtcars, pooled_sd = FALSE)
+
+  expect_warning(effectsize(tt1), ""Unable to retrieve data"")
+  expect_no_warning(effectsize(tt1, data = mtcars))
+  expect_identical(effectsize(tt1, data = mtcars)[[1]], dd1[[1]])
+
+  # Example 2
+  dat <- mtcars
+  tt2 <- t.test(dat$mpg[dat$am == 1], dat$mpg[dat$am == 0])
+  dd2 <- cohens_d(dat$mpg[dat$am == 1], dat$mpg[dat$am == 0], pooled_sd = FALSE)
+
+  rm(""dat"")
+  expect_warning(effectsize(tt2), ""Unable to retrieve data"")
+  expect_no_warning(effectsize(tt2, data = mtcars))
+
+  expect_identical(effectsize(tt2, data = mtcars)[[1]], dd2[[1]])
+
+  # Example 3
+  col_y <- ""mpg""
+  tt3 <- t.test(mtcars[[col_y]])
+  dd3 <- cohens_d(mtcars[[col_y]])
+
+  rm(""col_y"")
+  expect_warning(effectsize(tt3), ""Unable to retrieve data"")
+  expect_no_warning(effectsize(tt3, data = mtcars))
+  expect_identical(effectsize(tt3, data = mtcars)[[1]], dd3[[1]])
+
+  # Example 4
+  tt4 <- t.test(mpg ~ as.factor(am), data = mtcars)
+
+  expect_warning(effectsize(tt4), ""Unable to retrieve data"")
+  expect_no_warning(effectsize(tt4, data = mtcars))
+
+  # wilcox.test
+  x <- wilcox.test(mpg ~ as.factor(vs), data = mtcars, exact = FALSE)
+  expect_error(effectsize(x), ""Unable to retrieve data"")
+  expect_no_warning(effectsize(x, data = mtcars))
+
+  # friedman.test does not allow formula modifiers, skipping
+
+  # kruskal.test
+  airquality2 <- airquality
+  airquality2$Month <- as.factor(airquality2$Month)
+  airquality2$Ozone <- ifelse(is.na(airquality2$Ozone), 10, airquality2$Ozone)
+  x <- kruskal.test(Ozone ~ as.factor(Month), data = airquality2)
+
+  expect_error(effectsize(x), ""Unable to retrieve data"")
+  expect_no_warning(effectsize(x, data = airquality2))
+
+  # Paired t-test
+  x <- t.test(mpg ~ 1, data = mtcars)
+  expect_no_warning(effectsize(x, data = mtcars))
+
+  x <- t.test(Pair(mpg, hp) ~ 1, data = mtcars)
+  expect_no_warning(effectsize(x, data = mtcars))
+})
+
+test_that(""subset and na.action"", {
+  if (getRversion() < ""4.1.3"") {
+    skip_on_os(""linux"")
+  }
+
+  # t.test
+  some_data <- mtcars
+  some_data$mpg[1] <- NA
+
+  tt <- t.test(mpg ~ am,
+    data = some_data,
+    alternative = ""less"",
+    mu = 1,
+    var.equal = TRUE,
+    subset = cyl == 4,
+    na.action = na.omit
+  )
+
+  d1 <- effectsize(tt,
+    data = some_data,
+    alternative = ""less"",
+    mu = 1,
+    var.equal = TRUE,
+    subset = cyl == 4,
+    na.action = na.omit
+  )
+
+  d2 <- cohens_d(mpg ~ am,
+    data = some_data,
+    alternative = ""less"",
+    mu = 1,
+    pooled_sd = TRUE,
+    subset = cyl == 4,
+    na.action = na.omit
+  )
+
+  expect_equal(d1, d2, ignore_attr = TRUE)
+
+  # Paired t.test with formula
+  sleep2 <- reshape(sleep,
+    direction = ""wide"",
+    idvar = ""ID"", timevar = ""group""
+  )
+  sleep2$ID <- as.numeric(sleep2$ID)
+  sleep2$extra.2[1] <- NA
+
+  tt_paired <- t.test(
+    Pair(extra.1, extra.2) ~ 1,
+    data = sleep2,
+    alternative = ""less"",
+    var.equal = TRUE,
+    subset = ID > 3,
+    na.action = na.omit
+  )
+
+  d1_paired <- effectsize(
+    tt_paired,
+    data = sleep2,
+    alternative = ""less"",
+    var.equal = TRUE,
+    subset = ID > 3,
+    na.action = na.omit
+  )
+
+  d2_paired <- cohens_d(
+    tt_paired,
+    data = sleep2,
+    alternative = ""less"",
+    paired = TRUE,
+    var.equal = TRUE,
+    subset = ID > 3,
+    na.action = na.omit
+  )
+
+  expect_identical(d1_paired, d2_paired)
+
+  # wilcox.test
+  x <- wilcox.test(
+    mpg ~ vs,
+    data = some_data,
+    alternative = ""less"",
+    mu = 1,
+    var.equal = TRUE,
+    subset = cyl == 4,
+    na.action = na.omit,
+    exact = FALSE
+  )
+
+  d1 <- effectsize(
+    x,
+    data = some_data,
+    alternative = ""less"",
+    mu = 1,
+    var.equal = TRUE,
+    subset = cyl == 4,
+    na.action = na.omit
+  )
+
+  d2 <- rank_biserial(
+    mpg ~ vs,
+    data = some_data,
+    alternative = ""less"",
+    mu = 1,
+    pooled_sd = TRUE,
+    subset = cyl == 4,
+    na.action = na.omit
+  )
+
+  expect_equal(d1, d2, ignore_attr = TRUE)
+
+  # friedman.test
+  wb <- aggregate(warpbreaks$breaks, by = list(
+    w = warpbreaks$wool, t = warpbreaks$tension
+  ), FUN = mean)
+  new_row <- data.frame(w = ""B"", t = ""H"", x = 99, stringsAsFactors = FALSE)
+  wb <- rbind(wb, wb[6, ], new_row)
+  wb$x[7] <- NA
+
+  x <- friedman.test(
+    x ~ w | t,
+    data = wb,
+    subset = x < 99,
+    na.action = na.omit
+  )
+
+  d1 <- effectsize(
+    x,
+    data = wb,
+    subset = x < 99,
+    na.action = na.omit
+  )
+
+  d2 <- kendalls_w(
+    x ~ w | t,
+    data = wb,
+    subset = x < 99,
+    na.action = na.omit
+  )
+
+  expect_equal(d1, d2, ignore_attr = FALSE)
+
+  # kruskal.test
+  airquality2 <- airquality
+  airquality2$Month <- as.factor(airquality2$Month)
+  airquality2$Ozone <- ifelse(is.na(airquality2$Ozone), 10, airquality2$Ozone)
+
+  x <- kruskal.test(
+    Ozone ~ Month,
+    data = airquality2,
+    subset = Month != 5,
+    na.action = na.omit
+  )
+
+  set.seed(42)
+  d1 <- effectsize(
+    x,
+    data = airquality2,
+    alternative = ""less"",
+    subset = Month != 5,
+    na.action = na.omit
+  )
+
+  set.seed(42)
+  d2 <- rank_epsilon_squared(
+    Ozone ~ Month,
+    data = airquality2,
+    alternative = ""less"",
+    subset = Month != 5,
+    na.action = na.omit
+  )
+
+  expect_equal(d1, d2, ignore_attr = TRUE)
+
+  # subset and na.omit arguments do not apply to square bracket subsetting
+  # using the S3 method instead of the formula interface because no other
+  # dataframe is provided on which to do the subsetting. So no test is
+  # necessary here.
+
+  # paired t-test with formula
+  # Removing this test because paired t-test with formula isn't supported anymore
+  #
+  # before <- c(200.1, 190.9, 192.7, 213, 241.4, 196.9, 172.2, 185.5, NA, 999)
+  # after <- c(392.9, 393.2, 345.1, 393, 434, 427.9, 422, 383.9, NA, 999)
+  # my_data <- data.frame(
+  #   group = rep(c(""before"", ""after""), each = 10),
+  #   weight = c(before, after),
+  #   stringsAsFactors = FALSE
+  # )
+  #
+  # res <- t.test(weight ~ group,
+  #   data = my_data, paired = TRUE,
+  #   alternative = ""less"", na.omit = TRUE
+  # )
+  #
+  # d1 <- effectsize(
+  #   res,
+  #   data = my_data,
+  #   subset = weight < 999,
+  #   na.action = na.omit
+  # )
+  #
+  # d2 <- cohens_d(weight ~ group,
+  #   data = my_data,
+  #   paired = TRUE,
+  #   alternative = ""less"",
+  #   subset = weight < 999,
+  #   na.action = na.omit
+  # )
+  #
+  # expect_equal(d1, d2, ignore_attr = TRUE)
+})",True,False,Implementation / Logic,6
easystats,effectsize,aa4a00b97a51714b282c2540c63c50ea767bea5c,Mattan S. Ben-Shachar,mattansb@msbstats.info,2024-04-03T00:37:32Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2024-04-03T00:37:32Z,fix #636,NEWS.md;R/cohens_d.R;R/common_language.R;R/rank_diff.R,False,True,True,False,11,4,15,"---FILE: NEWS.md---
@@ -1,3 +1,9 @@
+# effectsize 0.8.7.x
+
+## Bug fixes
+
+- `hedges_g()`, `vd_a()`, `wmw_odds()`, and `cliffs_delta()` no longer require `{effectsize}` to be loaded to work ( #636 ).
+
 # effectsize 0.8.7
 
 - This release changes the licensing model of `{effectsize}` to an MIT license.

---FILE: R/cohens_d.R---
@@ -160,7 +160,7 @@ hedges_g <- function(x, y = NULL, data = NULL,
                      ci = 0.95, alternative = ""two.sided"",
                      verbose = TRUE, ...) {
   cl <- match.call()
-  cl[[1]] <- quote(cohens_d)
+  cl[[1]] <- quote(effectsize::cohens_d)
   cl$adjust <- TRUE
   eval.parent(cl)
 }

---FILE: R/common_language.R---
@@ -340,7 +340,7 @@ vd_a <- function(x, y = NULL, data = NULL,
                  ci = 0.95, alternative = ""two.sided"",
                  verbose = TRUE, ...) {
   cl <- match.call()
-  cl[[1]] <- quote(p_superiority)
+  cl[[1]] <- quote(effectsize::p_superiority)
   cl$parametric <- FALSE
   eval.parent(cl)
 }
@@ -353,7 +353,7 @@ wmw_odds <- function(x, y = NULL, data = NULL,
                      ci = 0.95, alternative = ""two.sided"",
                      verbose = TRUE, ...) {
   cl <- match.call()
-  cl[[1]] <- quote(rank_biserial)
+  cl[[1]] <- quote(effectsize::rank_biserial)
   out <- eval.parent(cl)
 
   rb_to_wmw_odds(out)
@@ -362,6 +362,7 @@ wmw_odds <- function(x, y = NULL, data = NULL,
 
 
 
+
 # Utils -------------------------------------------------------------------
 
 #' @keywords internal

---FILE: R/rank_diff.R---
@@ -220,7 +220,7 @@ cliffs_delta <- function(x, y = NULL, data = NULL,
     insight::format_error(""This effect size is only applicable for two independent samples."")
   }
 
-  cl[[1]] <- quote(rank_biserial)
+  cl[[1]] <- quote(effectsize::rank_biserial)
   cl$x <- x
   cl$y <- y
   eval.parent(cl)",True,False,Documentation / Formatting,6
easystats,effectsize,250a9d2c0c1ce155c720b9845c15da437d87f48c,Philip Waggoner,31326382+pdwaggoner@users.noreply.github.com,2023-12-12T19:40:25Z,GitHub,noreply@github.com,2023-12-12T19:40:25Z,"Adding power vignette plus a few other changes (#605)

* adding power vignette

# Description

Adding a vignette on the value of statistical power as well as the role of `effectsize` in making this an easy thing to do via #599 

# Proposed Changes

In addition to adding new vignette (`statistical_power.Rmd`), other changes include: 
- adding three new refs to `bibliography.bib`
- adding myself as ctb in `DESCRIPTION
- fixing a few typos here and there

# Question

**Note**: Need to change version number? Didn't think so with only the inclusion of a new vignette, but feel free to bump if needed.

* Update bibliography.bib

updating bib for pwaggoner's new power vignette

* Update DESCRIPTION

adding pwaggoner

* Update standardized_differences.Rmd

small typo and grammatical fixes

* Update statistical_power.Rmd

fixing some linting issues

* Update vignettes/statistical_power.Rmd

Co-authored-by: Dominique Makowski <dom.mak19@gmail.com>

* Update statistical_power.Rmd

fixed warning issues

* fix vignette

* evaluate vignette conditionally

* suppress warnings

* Update standardized_differences.Rmd

reverting two small changes back to fix lint issues

* Update statistical_power.Rmd

* Update statistical_power.Rmd

* Update statistical_power.Rmd

* Update statistical_power.Rmd

* Update README.md

cleaning up CRAN links for lint link rot fail

* Update statistical_power.Rmd

update per Dom's disclaimer suggestion

* Update _pkgdown.yml

* Update statistical_power.Rmd

made changes responding to recent code review

* update vignette

---------

Co-authored-by: Dominique Makowski <dom.mak19@gmail.com>
Co-authored-by: Indrajeet Patil <patilindrajeet.science@gmail.com>
Co-authored-by: Mattan S. Ben-Shachar <mattansb@msbstats.info>
Co-authored-by: Mattan S. Ben-Shachar <35330040+mattansb@users.noreply.github.com>",DESCRIPTION;README.md;_pkgdown.yml;vignettes/bibliography.bib;vignettes/statistical_power.Rmd,True,False,True,False,252,6,258,"---FILE: DESCRIPTION---
@@ -53,7 +53,12 @@ Authors@R:
              family = ""Karreth"",
              role = ""rev"",
              email = ""jkarreth@ursinus.edu"",
-             comment = c(ORCID = ""0000-0003-4586-7153"")))
+             comment = c(ORCID = ""0000-0003-4586-7153"")),
+      person(given = ""Philip"",
+             family = ""Waggoner"",
+             role = c(""aut"", ""ctb""),
+             email = ""philip.waggoner@gmail.com"",
+             comment = c(ORCID = ""0000-0002-7825-7573"")))
 Maintainer: Mattan S. Ben-Shachar <mattansb@msbstats.info>
 Description: Provide utilities to work with indices of effect size for a wide 
     variety of models and hypothesis tests (see list of supported models using 

---FILE: README.md---
@@ -2,9 +2,9 @@
 # effectsize: Indices of Effect Size <img src=""man/figures/logo.png"" align=""right"" width=""120"" />
 
 [![DOI](https://joss.theoj.org/papers/10.21105/joss.02815/status.svg/)](https://doi.org/10.21105/joss.02815)
-[![downloads](https://cranlogs.r-pkg.org/badges/effectsize)](https://cran.r-project.org/package=effectsize/)
-[![total](https://cranlogs.r-pkg.org/badges/grand-total/effectsize)](https://cran.r-project.org/package=effectsize/)
-[![status](https://tinyverse.netlify.com/badge/effectsize/)](https://CRAN.R-project.org/package=effectsize/)
+[![downloads](https://cranlogs.r-pkg.org/badges/effectsize)](https://CRAN.R-project.org/package=effectsize)
+[![total](https://cranlogs.r-pkg.org/badges/grand-total/effectsize)](https://CRAN.R-project.org/package=effectsize)
+[![status](https://tinyverse.netlify.com/badge/effectsize/)](https://CRAN.R-project.org/package=effectsize)
 [![lifecycle](https://img.shields.io/badge/lifecycle-maturing-blue.svg)](https://lifecycle.r-lib.org/articles/stages.html)
 
 ***Significant is just not enough!***
@@ -15,7 +15,7 @@ conversion of indices such as Cohenâs *d*, *r*, odds-ratios, etc.
 
 ## Installation
 
-[![CRAN](https://www.r-pkg.org/badges/version/effectsize)](https://cran.r-project.org/package=effectsize/)
+[![CRAN](https://www.r-pkg.org/badges/version/effectsize)](https://CRAN.R-project.org/package=effectsize)
 [![effectsize status
 badge](https://easystats.r-universe.dev/badges/effectsize/)](https://easystats.r-universe.dev/)
 [![R-CMD-check](https://github.com/easystats/effectsize/workflows/R-CMD-check/badge.svg?branch=main)](https://github.com/easystats/effectsize/actions)

---FILE: _pkgdown.yml---
@@ -126,8 +126,11 @@ navbar:
           href: https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html
         - text: ""Correlation Vignettes""
           href: https://easystats.github.io/correlation/articles/index.html
+        - text: -------
         - text: ""Confidence Intervals""
           href: reference/effectsize_CIs.html
+        - text: ""Statistical Power""
+          href: articles/statistical_power.html
         - text: -------
         - text: ""Plotting Functions""
           href: https://easystats.github.io/see/articles/effectsize.html

---FILE: vignettes/bibliography.bib---
@@ -555,4 +555,34 @@ @article{kelley1935unbiased
   year={1935},
   publisher={National Academy of Sciences},
   doi={10.1073/pnas.21.9.554}
-}
\ No newline at end of file
+}
+
+
+
+
+@article{champley2017,
+  title={pwr: Basic functions for power analysis},
+  author={Champely, Stephane, Claus Ekstrom, Peter Dalgaard, Jeffrey Gill, Stephan Weibelzahl, Aditya Anandkumar, Clay Ford, Robert Volcic, and Helios De Rosario},
+  journal={R package v1.3-0},
+  year={2017}
+}
+
+
+
+@book{cohen1988,
+  title={Statistical power analysis for the behavioral sciences},
+  author={Cohen, Jacob},
+  publisher={Academic press},
+  year={1988/2013}
+}
+
+
+
+@book{greene2000,
+  title={Econometric analysis 4th edition. International edition},
+  author={Greene, William H.},
+  publisher={New Jersey: Prentice Hall},
+  year={2000}
+}
+
+

---FILE: vignettes/statistical_power.Rmd---
@@ -0,0 +1,208 @@
+---
+title: ""Statistical Power""
+output: 
+  rmarkdown::html_vignette:
+    toc: true
+    fig_width: 10.08
+    fig_height: 6
+tags: [r, effect size, power analysis, statistical power]
+vignette: >
+  \usepackage[utf8]{inputenc}
+  %\VignetteIndexEntry{Statistical Power}
+  %\VignetteEngine{knitr::rmarkdown}
+editor_options: 
+  chunk_output_type: console
+bibliography: bibliography.bib
+---
+
+```{r setup, include=FALSE}
+knitr::opts_chunk$set(
+  collapse = TRUE,
+  comment = ""#>"",
+  warning = FALSE,
+  message = FALSE,
+  eval = requireNamespace(""pwr"", quietly = TRUE)
+)
+
+options(digits = 4L, knitr.kable.NA = """")
+
+set.seed(123)
+```
+
+# Overview
+
+In this vignette, we focus on statistical power and the role of the `effectsize` _easystats_ package in power analysis.
+As such, we are interested in accomplishing several things with this vignette: 
+
+  1. Reviewing statistical power and its value in a research task
+  2. Demonstrating the role of the `effectsize` package in the context of exploring statistical power
+  3. Highlighting the ease of calculating and understanding of statistical power via the _easystats_ ecosystem, and the `effectsize` package specifically
+  4. Encouraging wider adoption of power analysis in applied research
+
+*Disclaimer:* This vignette is an initial look at power analysis via _easystats_. 
+There's much more we could do, so please give us a feedback about what features would you like to see in _easystats_ to make power analysis easier.
+
+## What is statistical power and power analysis? 
+
+Statistical power allows for the ability to check whether an effect observed from a statistical test actually exists, or that the null hypothesis really can be rejected (or not). 
+Power involves many related concepts including, but not limited to, sample size, estimation, significance threshold, and of course, the *effect size*. 
+
+## What is `effectsize`? 
+
+The goal of the `effectsize` package is to provide utilities to work with indices of effect size and standardized parameters, allowing computation and conversion of indices such as Cohenâs d, r, odds-ratios, among many others.
+Please explore the breadth of effect size operations included in the package by visiting the [package docs](https://easystats.github.io/effectsize/reference/index.html).
+
+## Putting the Pieces Together: Hypothesis Testing
+
+Let's take a closer looks at the key ingredients involved in statistical power before walking through a simple applied example below. 
+
+  1. *Statistical test*: In research we often start with a statistical test to test expectations or explore data. For example, we might use a t-test to check for differences between two group means. This would help assess whether the difference of means between the groups is likely the same/indistinguishable from zero (null, $H_0$) or not (alternative, $H_A$)
+  
+  2. *Significance threshold*: This is the threshold against which we compare the p-value from our statistical test, which helps determine which hypothesis has the most support (and which we should reject). That is, we need to assess the probability that the result is likely indistinguishable from 0, or whether we have picked up on a likely real difference or result. To this end, if the p-value associated with our test is less than the significance threshold (e.g., $p < 0.05$), then, this tells us that the chance of observing the result we observed due to chance alone is extremely low, and very unlikely. In the case of comparing group mean differences, for example, we would have evidence allowing us to ""reject the null hypothesis of no difference,"" and conclude that there is a greater chance of the group means being significantly different from each other in line with $H_A$.
+  
+  3. *Effect size*: This is the magnitude of difference. A common way to calculate this is via Cohen's $d$, which measures the estimated standardized difference between the means of two populations. There are many other extensions (e.g., correcting for small-sample bias via Hedges' $g$). This is where the `effectsize` package comes in, which allows for easy calculation of many different effect size metrics.
+  
+  4. *Statistical power*: This brings us to statistical power, which can be thought of in many ways, such as the probability that we are *correctly* observing an effect or group difference, or that we are correctly rejecting the null hypothesis, and so on (see, e.g., [@cohen1988], [@greene2000] for more). But regardless of the interpretation, all of these interpretations are all pointing to a common idea: *the ability for us to trust the result we get from the hypothesis test*, regardless of the test. 
+  
+Let's put these pieces together with a simple example. 
+Say we find a ""statistically significant"" ($p < 0.05$) difference between two group means from a two-sample t-test.
+In this case, we might be tempted to stop and conclude that the signal is sufficiently strong to conclude that the groups are different from each other. 
+But our test could be incorrect for a variety of reasons.
+Recall, that the p-value is a *probability*, meaning in part that we could be erroneously rejecting the null hypothesis, or that an insignificant result is insignificant due to a small sample size, and so on. 
+
+> This is where statistical power comes in.
+
+Statistical power helps us go the next step and more thoroughly assess the probability that the ""significant"" result we observed is indeed significant, or detect a cause of an insignificant result (e.g., sample size). 
+In general, *before* beginning a broader analysis, it is a good idea to check for statistical power to ensure that you can trust the results you get from your test(s) downstream, and that your inferences are reliable. 
+  
+So this is where we focus in this vignette, and pay special attention to the ease and role of effect size calculation via the `effectsize` package from _easystats_.
+The following section walks through a simple applied example to ensure 1) the concepts surrounding and involved in power are clear and digestible, and 2) that the role and value of the `effectsize` package are likewise clear and digestible.
+Understanding both of these realities will allow for more complex extensions and applications to a wide array of research problems and questions. 
+
+# Example: Comparing Means of Independant Samples
+
+In addition to relying on the _easystats_ `effectsize` package for effect size calculation, we will also leverage the simple, but excellent `pwr` package for the following implementation of power analysis [@champley2017]. 
+
+```{r}
+library(pwr)
+library(effectsize)
+```
+
+First, let's fit a simple two sample t-test using the mtcars data to explore mean MPG for both transmission groups (`AM`).
+
+```{r}
+t <- t.test(mpg ~ am, data = mtcars)
+```
+
+There are many power tests supported by `pwr` for different contexts, and we encourage you to take a look and select the appropriate one for your application.
+For present purposes of calculating statistical power for our t-test, we will rely on the `pwr.t2n.test()` function. 
+Here's the basic anatomy:
+
+```{r, eval = FALSE}
+pwr.t2n.test(
+  n1 = ..., n2 = ...,
+  d = ...,
+  sig.level = ...,
+  power = ...,
+  alternative = ...
+)
+```
+
+But, before we can get to the power part, we need to collect a few ingredients first, as we can see above. 
+The ingredients we need include:
+
+  - `d`: effect size
+  - `n1` and `n2`: sample size (for each sample)
+  - `sig.level`: significance threshold (e.g., `0.05`)
+  - `alternative`: direction of the t-test (e.g., greater, lesser, two.sided)
+
+(By omitting the `power` argument, we are implying that we want the function to estimate that value for us.)
+
+## Calculate Effect Size
+
+Given the simplicity of this example and the prevalence of Cohen's $d$, we will rely on this effect size index here.
+We have three ways of easily calculating Cohen's $d$ via `effectsize`. 
+
+### Approach 1: `effectsize()`
+
+The first approach is the simplest.
+As previously hinted at, there is a vast literature on different effect size calculations for different applications. 
+So, if you don't want to track down a specific one, or are unaware of options, you can simply pass the statistical test object to `effectsize()`, and either select the `type`, or leave it blank for ""cohens_d"", which is the default option. 
+
+*Note*, when using the formula interface to `t.test()`, this method (currently) only gives an approximate effect size. 
+So for this first simple approach, we update our test (`t_alt`) and then make a call to `effectsize()`.
+
+```{r eval = FALSE}
+t_alt <- t.test(mtcars$mpg[mtcars$am == 0], mtcars$mpg[mtcars$am == 1])
+
+effectsize(t_alt, type = ""cohens_d"")
+```
+
+*Note*, users can easily store the value and/or CIs as you'd like via, e.g., `cohens_d <- effectsize(t, type = ""cohens_d"")[[1]]`. 
+
+### Approach 2: `cohens_d()`
+
+Alternatively, if you knew the index one you wanted to use, you could simply call the associated function directly. For present purposes, we picked Cohen's $d$, so we would call `cohens_d()`. 
+But there are many other indices supported by `effectsize`. For example, see [here](https://easystats.github.io/effectsize/reference/index.html#standardized-differences) for options for standardized differences. Or see [here](https://easystats.github.io/effectsize/reference/index.html#for-contingency-tables) for options for contingency tables. Or see [here](https://easystats.github.io/effectsize/reference/index.html#comparing-multiple-groups) for options for comparing multiple groups, and so on. 
+
+In our simple case here with a t-test, users are encouraged to use `effectsize()` when working with `htest` objects to ensure proper estimation. 
+Therefore, with this second approach of using the ""named"" function, `cohens_d`, users should pass the data directly to the function instead of the `htest` object (e.g., `cohens_d(t)`). 
+
+```{r eval = FALSE}
+cohens_d(mpg ~ am, data = mtcars)
+```
+
+### Approach 3: `t_to_d()`
+
+When the original underlying data is not available, you may get a warning message like: 
+
+> *Warning: ... Returning an approximate effect size using t_to_d()*
+
+In these cases, the default behavior of `effectsize` is to make a back-up call to `t_to_d()` (or which ever conversion function is appropriate based on the input). 
+This step makes the calculation from the t-test to Cohen's $d$. 
+Given the prevalence of calculating effect sizes for different applications and the many effect size indices available for different contexts, we have anticipated this and baked in this conversion ""fail safe"" in the architecture of `effectsize` by detecting the input and making the appropriate conversion. 
+There are many conversions available in the package. 
+Take a look [here](https://easystats.github.io/effectsize/reference/index.html#effect-size-conversion).
+
+This can also be dne directly by the user using the `t_to_d()` function:
+
+```{r}
+t_to_d(
+  t = t$statistic,
+  df_error = t$parameter
+)
+```
+
+## Statistical Power
+
+Now we are ready to calculate the statistical power of our t-test given that we have collected the essential ingredients. 
+
+For the present application, the effect size obtained from `cohens_d()` (or any of the three approaches previously described) can be passed to the `d` argument.
+
+```{r}
+(result <- cohens_d(mpg ~ am, data = mtcars))
+(Ns <- table(mtcars$am))
+
+pwr.t2n.test(
+  n1 = Ns[1], n2 = Ns[2],
+  d = result[[""Cohens_d""]],
+  sig.level = 0.05,
+  alternative = ""two.sided""
+)
+```
+
+The results tell us that we are sufficiently powered, with a very high power for each group, `0.999` and `0.990`.
+
+Notice, though, if you were to change the group sample sizes to something very small, say `n = c(2, 2)`, then you would get a much lower power, suggesting that your sample size is too small to detect any reliable signal or to be able to trust your results.
+
+# Example: Contingency Table
+
+<!-- TODO -->
+_To be added._
+
+# Example: ANOVA (and Model Comparisons)
+
+<!-- TODO -->
+_To be added._
+
+# References",False,True,Documentation / Formatting,7
easystats,effectsize,8b5636fbb2df90b9040e51eb55a05927f425b7d1,Mattan S. Ben-Shachar,mattansb@msbstats.info,2023-12-05T11:10:07Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2023-12-05T11:10:07Z,fix #622,DESCRIPTION;R/utils_validate_input_data.R;tests/testthat/test-rm_d.R,False,True,True,False,8,2,10,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size
-Version: 0.8.6.3
+Version: 0.8.6.4
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",

---FILE: R/utils_validate_input_data.R---
@@ -126,7 +126,7 @@
         return(mf)
       }
 
-      if (verbose && any(tapply(mf[[1]], mf[3:2], length) > 1L)) {
+      if (verbose && any(tapply(mf[[1]], mf[3:2], length) > 1L, na.rm = TRUE)) {
         insight::format_alert(
           paste0(""The "", method, "" standardized difference requires paired data,""),
           ""but data contains more than one observation per design cell."",

---FILE: tests/testthat/test-rm_d.R---
@@ -27,6 +27,12 @@ test_that(""rm_d | paired data"", {
     regexp = ""replications""
   )
 
+  sleep[1, ""extra""] <- NA
+  sleep2[1, ""extra.1""] <- NA
+  expect_no_error(d1NA <- rm_d(extra ~ group | ID, data = sleep))
+  expect_no_error(d2NA <- rm_d(Pair(extra.1, extra.2) ~ 1, data = sleep2))
+  expect_equal(d1NA, d2NA)
+
 
   # equal with equal variance:
   dat <- data.frame(",True,False,Dependency / Package,6
easystats,effectsize,8fdbfad67a82be3de5e39498032cf8ce50aea210,Mattan S. Ben-Shachar,mattansb@msbstats.info,2023-11-08T18:36:57Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2023-11-08T18:36:57Z,fix nnt bug,DESCRIPTION;NEWS.md;R/xtab_diff.R;tests/testthat/test-xtab.R,False,True,True,False,14,2,16,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size
-Version: 0.8.6.2
+Version: 0.8.6.3
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",

---FILE: NEWS.md---
@@ -6,6 +6,10 @@
 
 - `repeated_measures_d()` to compute standardized mean differences (SMD) for repeated measures data.
   - Also supported in `effectsize(<t.test(paired = TRUE)>)`
+  
+## Bug fixes
+
+- `nnt()` now properly accepts the `y` argument.
 
 # effectsize 0.8.7
 

---FILE: R/xtab_diff.R---
@@ -304,7 +304,7 @@ nnt <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...) {
     return(effectsize(x, type = ""nnt"", ci = ci, ...))
   }
 
-  out <- arr(x, y = t, ci = ci, alternative = alternative2, ...)
+  out <- arr(x, y = y, ci = ci, alternative = alternative2, ...)
   out[[1]] <- 1 / out[[1]]
   colnames(out)[1] <- ""NNT""
 

---FILE: tests/testthat/test-xtab.R---
@@ -200,6 +200,14 @@ test_that(""oddsratio & riskratio"", {
   expect_equal(ARR[[1]], -0.4891775, tolerance = 0.001)
   expect_equal(ARR$CI_low, -0.8092576, tolerance = 0.001)
   expect_equal(ARR$CI_high, -0.1690974, tolerance = 0.001)
+
+  # fix
+  set.seed(111)
+  x <- rbinom(10, 1, 0.5)
+  y <- rbinom(10, 1, 0.5)
+
+  expect_no_error(NNT <- nnt(x, y))
+  expect_equal(NNT[[1]], arr_to_nnt(arr(x, y)[[1]]))
 })
 
 ",True,False,Documentation / Formatting,6
easystats,effectsize,9b662516609c50f246f6e38a96ac87bc135e05b3,Mattan S. Ben-Shachar,mattansb@msbstats.info,2023-11-07T08:05:57Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2023-11-07T08:05:57Z,quick typo fix,R/repeated_measures_d.R;man/repeated_measures_d.Rd,False,True,True,False,2,2,4,"---FILE: R/repeated_measures_d.R---
@@ -49,7 +49,7 @@
 #' standardizing by the variance in the of the control (or pre) condition,
 #' Cumming suggests standardizing by the average variance of the two paired
 #' conditions (Cumming, 2013, pp. 291).
-#' - **All Variance: \eqn{d_{d}}** - This is the same as computing a standard
+#' - **All Variance: Just \eqn{d}** - This is the same as computing a standard
 #' independent-groups Cohen's _d_ (Cohen, 1988). Note that CIs _do_ account for
 #' the dependence, and so are typically more narrow (see examples).
 #' - **Residual Variance: \eqn{d_{r}}** (_Requires data with replications_) -

---FILE: man/repeated_measures_d.Rd---
@@ -106,7 +106,7 @@ post-treatment setting, the pre-treatment condition). This is akin to Glass'
 standardizing by the variance in the of the control (or pre) condition,
 Cumming suggests standardizing by the average variance of the two paired
 conditions (Cumming, 2013, pp. 291).
-\item \strong{All Variance: \eqn{d_{d}}} - This is the same as computing a standard
+\item \strong{All Variance: Just \eqn{d}} - This is the same as computing a standard
 independent-groups Cohen's \emph{d} (Cohen, 1988). Note that CIs \emph{do} account for
 the dependence, and so are typically more narrow (see examples).
 \item \strong{Residual Variance: \eqn{d_{r}}} (\emph{Requires data with replications}) -",True,False,Documentation / Formatting,7
easystats,effectsize,448e39bdbb66b24fe1f83922fb1c9696951c51db,Indrajeet Patil,patilindrajeet.science@gmail.com,2023-11-04T07:40:26Z,Indrajeet Patil,patilindrajeet.science@gmail.com,2023-11-04T07:40:26Z,fix warning about licence,.Rbuildignore;DESCRIPTION;LICENSE;LICENSE.md;README.md;man/effectsize.Rd,False,False,False,False,51,47,98,"---FILE: .Rbuildignore---
@@ -28,7 +28,6 @@ publication/*
 ^\.httr-oauth$
 ^CRAN-RELEASE$
 tests\^spelling
-^LICENSE
 ^\.lintr$
 ^\.circleci$
 ^tests/manual$
@@ -52,4 +51,5 @@ hextools
 \.code-workspace$
 # Flip these two to no build vignettes:
 # ^vignettes/(?!additional).*
-^vignettes/additional
\ No newline at end of file
+^vignettes/additional
+^LICENSE\.md$

---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size
-Version: 0.8.6.1
+Version: 0.8.6.2
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",

---FILE: LICENSE---
@@ -1,21 +1,2 @@
-# MIT License
-
-Copyright (c) 2023 easystats team
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the ""Software""), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all
-copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-SOFTWARE.
\ No newline at end of file
+YEAR: 2023
+COPYRIGHT HOLDER: effectsize authors

---FILE: LICENSE.md---
@@ -0,0 +1,21 @@
+# MIT License
+
+Copyright (c) 2023 effectsize authors
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the ""Software""), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.

---FILE: README.md---
@@ -54,22 +54,24 @@ Click on the buttons above to access the package
 [**easystats blog**](https://easystats.github.io/blog/posts/), and
 check-out these vignettes:
 
--   **Effect Sizes**
-    -   [**Standardized
-        Differences**](https://easystats.github.io/effectsize/articles/standardized_differences.html)  
-    -   [**For Contingency
-        Tables**](https://easystats.github.io/effectsize/articles/xtabs.html)  
-    -   [**ANOVA Effect
-        Sizes**](https://easystats.github.io/effectsize/articles/anovaES.html)
--   **Effect Sizes Conversion**
-    -   [**Between Effect
-        Sizes**](https://easystats.github.io/effectsize/articles/convert_r_d_OR.html)  
-    -   [**Between Probabilities and Odds and Risk
-        Ratios**](https://easystats.github.io/effectsize/articles/convert_p_OR_RR.html)  
-    -   [**Effect Size from Test
-        Statistics**](https://easystats.github.io/effectsize/articles/from_test_statistics.html)
--   [**Automated Interpretation of Indices of Effect
-    Size**](https://easystats.github.io/effectsize/articles/interpret.html)
+- **Effect Sizes**
+  - [**Standardized
+    Differences**](https://easystats.github.io/effectsize/articles/standardized_differences.html)  
+  - [**For Contingency
+    Tables**](https://easystats.github.io/effectsize/articles/xtabs.html)  
+  - [**ANOVA Effect
+    Sizes**](https://easystats.github.io/effectsize/articles/anovaES.html)
+- **Effect Sizes Conversion**
+  - [**Between Effect
+    Sizes**](https://easystats.github.io/effectsize/articles/convert_r_d_OR.html)  
+  - [**Between Probabilities and Odds and Risk
+    Ratios**](https://easystats.github.io/effectsize/articles/convert_p_OR_RR.html)  
+  - [**Effect Size from Test
+    Statistics**](https://easystats.github.io/effectsize/articles/from_test_statistics.html)
+- [**Plotting Functions for the âeffectsizeâ
+  Package**](https://easystats.github.io/see/articles/effectsize.html)  
+- [**Automated Interpretation of Indices of Effect
+  Size**](https://easystats.github.io/effectsize/articles/interpret.html)
 
 # Features
 
@@ -122,7 +124,7 @@ language effect sizes* and moreâ¦
 ### Contingency Tables
 
 ``` r
-# Dependence 
+# Dependence
 phi(mtcars$am, mtcars$vs)
 ## Ï (adj.) |       95% CI
 ## -----------------------
@@ -143,7 +145,7 @@ fei(table(mtcars$cyl), p = c(0.1, 0.3, 0.6))
 ## -------------------
 ## 0.27 | [0.17, 1.00]
 ## 
-## - Adjusted for non-uniform expected probabilities.
+## - Adjusted for uniform expected probabilities.
 ## - One-sided CIs: upper bound fixed at [1.00].
 ```
 
@@ -256,9 +258,9 @@ interpret_cohens_d(d = 0.45, rules = ""gignac2016"")
 
 In order to cite this package, please use the following citation:
 
--   Ben-Shachar M, LÃ¼decke D, Makowski D (2020). effectsize: Estimation
-    of Effect Size Indices and Standardized Parameters. *Journal of Open
-    Source Software*, *5*(56), 2815. doi: 10.21105/joss.02815
+- Ben-Shachar M, LÃ¼decke D, Makowski D (2020). effectsize: Estimation of
+  Effect Size Indices and Standardized Parameters. *Journal of Open
+  Source Software*, *5*(56), 2815. doi: 10.21105/joss.02815
 
 Corresponding BibTeX entry:
 

---FILE: man/effectsize.Rd---
@@ -22,7 +22,7 @@ effectsize(model, ...)
 \item{type}{The effect size of interest. See details.}
 
 \item{ci}{Value or vector of probability of the CI (between 0 and 1)
-to be estimated. Default to \code{.95} (\verb{95\%}).}
+to be estimated. Default to \code{0.95} (\verb{95\%}).}
 
 \item{test}{The indices of effect existence to compute. Character (vector) or
 list with one or more of these options: \code{""p_direction""} (or \code{""pd""}),
@@ -32,7 +32,7 @@ For each ""test"", the corresponding \pkg{bayestestR} function is called
 (e.g. \code{\link[bayestestR:rope]{rope()}} or \code{\link[bayestestR:p_direction]{p_direction()}}) and its results
 included in the summary output.}
 
-\item{verbose}{Toggle warnings and messages on or off.}
+\item{verbose}{Toggle off warnings.}
 
 \item{...}{Arguments passed to or from other methods. See details.}
 }",False,False,Documentation / Formatting,6
easystats,effectsize,bf6cb28ac2dd8da2e30d5150e0ab8fe130138613,Mattan S. Ben-Shachar,mattansb@msbstats.info,2023-10-24T09:29:42Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2023-10-24T09:29:42Z,"MIT LICENSE

https://github.com/easystats/easystats/issues/368",DESCRIPTION;LICENSE;NEWS.md,False,False,False,False,26,675,701,"---FILE: DESCRIPTION---
@@ -60,7 +60,7 @@ Description: Provide utilities to work with indices of effect size for a wide
     the function 'insight::supported_models()'), allowing computation of and 
     conversion between indices such as Cohen's d, r, odds, etc.
     References: Ben-Shachar et al. (2020) <doi:10.21105/joss.02815>.
-License: GPL-3
+License: MIT + file LICENSE
 URL: https://easystats.github.io/effectsize/
 BugReports: https://github.com/easystats/effectsize/issues/
 Depends:

---FILE: LICENSE---
@@ -1,674 +1,21 @@
-                    GNU GENERAL PUBLIC LICENSE
-                       Version 3, 29 June 2007
-
- Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
- Everyone is permitted to copy and distribute verbatim copies
- of this license document, but changing it is not allowed.
-
-                            Preamble
-
-  The GNU General Public License is a free, copyleft license for
-software and other kinds of works.
-
-  The licenses for most software and other practical works are designed
-to take away your freedom to share and change the works.  By contrast,
-the GNU General Public License is intended to guarantee your freedom to
-share and change all versions of a program--to make sure it remains free
-software for all its users.  We, the Free Software Foundation, use the
-GNU General Public License for most of our software; it applies also to
-any other work released this way by its authors.  You can apply it to
-your programs, too.
-
-  When we speak of free software, we are referring to freedom, not
-price.  Our General Public Licenses are designed to make sure that you
-have the freedom to distribute copies of free software (and charge for
-them if you wish), that you receive source code or can get it if you
-want it, that you can change the software or use pieces of it in new
-free programs, and that you know you can do these things.
-
-  To protect your rights, we need to prevent others from denying you
-these rights or asking you to surrender the rights.  Therefore, you have
-certain responsibilities if you distribute copies of the software, or if
-you modify it: responsibilities to respect the freedom of others.
-
-  For example, if you distribute copies of such a program, whether
-gratis or for a fee, you must pass on to the recipients the same
-freedoms that you received.  You must make sure that they, too, receive
-or can get the source code.  And you must show them these terms so they
-know their rights.
-
-  Developers that use the GNU GPL protect your rights with two steps:
-(1) assert copyright on the software, and (2) offer you this License
-giving you legal permission to copy, distribute and/or modify it.
-
-  For the developers' and authors' protection, the GPL clearly explains
-that there is no warranty for this free software.  For both users' and
-authors' sake, the GPL requires that modified versions be marked as
-changed, so that their problems will not be attributed erroneously to
-authors of previous versions.
-
-  Some devices are designed to deny users access to install or run
-modified versions of the software inside them, although the manufacturer
-can do so.  This is fundamentally incompatible with the aim of
-protecting users' freedom to change the software.  The systematic
-pattern of such abuse occurs in the area of products for individuals to
-use, which is precisely where it is most unacceptable.  Therefore, we
-have designed this version of the GPL to prohibit the practice for those
-products.  If such problems arise substantially in other domains, we
-stand ready to extend this provision to those domains in future versions
-of the GPL, as needed to protect the freedom of users.
-
-  Finally, every program is threatened constantly by software patents.
-States should not allow patents to restrict development and use of
-software on general-purpose computers, but in those that do, we wish to
-avoid the special danger that patents applied to a free program could
-make it effectively proprietary.  To prevent this, the GPL assures that
-patents cannot be used to render the program non-free.
-
-  The precise terms and conditions for copying, distribution and
-modification follow.
-
-                       TERMS AND CONDITIONS
-
-  0. Definitions.
-
-  ""This License"" refers to version 3 of the GNU General Public License.
-
-  ""Copyright"" also means copyright-like laws that apply to other kinds of
-works, such as semiconductor masks.
-
-  ""The Program"" refers to any copyrightable work licensed under this
-License.  Each licensee is addressed as ""you"".  ""Licensees"" and
-""recipients"" may be individuals or organizations.
-
-  To ""modify"" a work means to copy from or adapt all or part of the work
-in a fashion requiring copyright permission, other than the making of an
-exact copy.  The resulting work is called a ""modified version"" of the
-earlier work or a work ""based on"" the earlier work.
-
-  A ""covered work"" means either the unmodified Program or a work based
-on the Program.
-
-  To ""propagate"" a work means to do anything with it that, without
-permission, would make you directly or secondarily liable for
-infringement under applicable copyright law, except executing it on a
-computer or modifying a private copy.  Propagation includes copying,
-distribution (with or without modification), making available to the
-public, and in some countries other activities as well.
-
-  To ""convey"" a work means any kind of propagation that enables other
-parties to make or receive copies.  Mere interaction with a user through
-a computer network, with no transfer of a copy, is not conveying.
-
-  An interactive user interface displays ""Appropriate Legal Notices""
-to the extent that it includes a convenient and prominently visible
-feature that (1) displays an appropriate copyright notice, and (2)
-tells the user that there is no warranty for the work (except to the
-extent that warranties are provided), that licensees may convey the
-work under this License, and how to view a copy of this License.  If
-the interface presents a list of user commands or options, such as a
-menu, a prominent item in the list meets this criterion.
-
-  1. Source Code.
-
-  The ""source code"" for a work means the preferred form of the work
-for making modifications to it.  ""Object code"" means any non-source
-form of a work.
-
-  A ""Standard Interface"" means an interface that either is an official
-standard defined by a recognized standards body, or, in the case of
-interfaces specified for a particular programming language, one that
-is widely used among developers working in that language.
-
-  The ""System Libraries"" of an executable work include anything, other
-than the work as a whole, that (a) is included in the normal form of
-packaging a Major Component, but which is not part of that Major
-Component, and (b) serves only to enable use of the work with that
-Major Component, or to implement a Standard Interface for which an
-implementation is available to the public in source code form.  A
-""Major Component"", in this context, means a major essential component
-(kernel, window system, and so on) of the specific operating system
-(if any) on which the executable work runs, or a compiler used to
-produce the work, or an object code interpreter used to run it.
-
-  The ""Corresponding Source"" for a work in object code form means all
-the source code needed to generate, install, and (for an executable
-work) run the object code and to modify the work, including scripts to
-control those activities.  However, it does not include the work's
-System Libraries, or general-purpose tools or generally available free
-programs which are used unmodified in performing those activities but
-which are not part of the work.  For example, Corresponding Source
-includes interface definition files associated with source files for
-the work, and the source code for shared libraries and dynamically
-linked subprograms that the work is specifically designed to require,
-such as by intimate data communication or control flow between those
-subprograms and other parts of the work.
-
-  The Corresponding Source need not include anything that users
-can regenerate automatically from other parts of the Corresponding
-Source.
-
-  The Corresponding Source for a work in source code form is that
-same work.
-
-  2. Basic Permissions.
-
-  All rights granted under this License are granted for the term of
-copyright on the Program, and are irrevocable provided the stated
-conditions are met.  This License explicitly affirms your unlimited
-permission to run the unmodified Program.  The output from running a
-covered work is covered by this License only if the output, given its
-content, constitutes a covered work.  This License acknowledges your
-rights of fair use or other equivalent, as provided by copyright law.
-
-  You may make, run and propagate covered works that you do not
-convey, without conditions so long as your license otherwise remains
-in force.  You may convey covered works to others for the sole purpose
-of having them make modifications exclusively for you, or provide you
-with facilities for running those works, provided that you comply with
-the terms of this License in conveying all material for which you do
-not control copyright.  Those thus making or running the covered works
-for you must do so exclusively on your behalf, under your direction
-and control, on terms that prohibit them from making any copies of
-your copyrighted material outside their relationship with you.
-
-  Conveying under any other circumstances is permitted solely under
-the conditions stated below.  Sublicensing is not allowed; section 10
-makes it unnecessary.
-
-  3. Protecting Users' Legal Rights From Anti-Circumvention Law.
-
-  No covered work shall be deemed part of an effective technological
-measure under any applicable law fulfilling obligations under article
-11 of the WIPO copyright treaty adopted on 20 December 1996, or
-similar laws prohibiting or restricting circumvention of such
-measures.
-
-  When you convey a covered work, you waive any legal power to forbid
-circumvention of technological measures to the extent such circumvention
-is effected by exercising rights under this License with respect to
-the covered work, and you disclaim any intention to limit operation or
-modification of the work as a means of enforcing, against the work's
-users, your or third parties' legal rights to forbid circumvention of
-technological measures.
-
-  4. Conveying Verbatim Copies.
-
-  You may convey verbatim copies of the Program's source code as you
-receive it, in any medium, provided that you conspicuously and
-appropriately publish on each copy an appropriate copyright notice;
-keep intact all notices stating that this License and any
-non-permissive terms added in accord with section 7 apply to the code;
-keep intact all notices of the absence of any warranty; and give all
-recipients a copy of this License along with the Program.
-
-  You may charge any price or no price for each copy that you convey,
-and you may offer support or warranty protection for a fee.
-
-  5. Conveying Modified Source Versions.
-
-  You may convey a work based on the Program, or the modifications to
-produce it from the Program, in the form of source code under the
-terms of section 4, provided that you also meet all of these conditions:
-
-    a) The work must carry prominent notices stating that you modified
-    it, and giving a relevant date.
-
-    b) The work must carry prominent notices stating that it is
-    released under this License and any conditions added under section
-    7.  This requirement modifies the requirement in section 4 to
-    ""keep intact all notices"".
-
-    c) You must license the entire work, as a whole, under this
-    License to anyone who comes into possession of a copy.  This
-    License will therefore apply, along with any applicable section 7
-    additional terms, to the whole of the work, and all its parts,
-    regardless of how they are packaged.  This License gives no
-    permission to license the work in any other way, but it does not
-    invalidate such permission if you have separately received it.
-
-    d) If the work has interactive user interfaces, each must display
-    Appropriate Legal Notices; however, if the Program has interactive
-    interfaces that do not display Appropriate Legal Notices, your
-    work need not make them do so.
-
-  A compilation of a covered work with other separate and independent
-works, which are not by their nature extensions of the covered work,
-and which are not combined with it such as to form a larger program,
-in or on a volume of a storage or distribution medium, is called an
-""aggregate"" if the compilation and its resulting copyright are not
-used to limit the access or legal rights of the compilation's users
-beyond what the individual works permit.  Inclusion of a covered work
-in an aggregate does not cause this License to apply to the other
-parts of the aggregate.
-
-  6. Conveying Non-Source Forms.
-
-  You may convey a covered work in object code form under the terms
-of sections 4 and 5, provided that you also convey the
-machine-readable Corresponding Source under the terms of this License,
-in one of these ways:
-
-    a) Convey the object code in, or embodied in, a physical product
-    (including a physical distribution medium), accompanied by the
-    Corresponding Source fixed on a durable physical medium
-    customarily used for software interchange.
-
-    b) Convey the object code in, or embodied in, a physical product
-    (including a physical distribution medium), accompanied by a
-    written offer, valid for at least three years and valid for as
-    long as you offer spare parts or customer support for that product
-    model, to give anyone who possesses the object code either (1) a
-    copy of the Corresponding Source for all the software in the
-    product that is covered by this License, on a durable physical
-    medium customarily used for software interchange, for a price no
-    more than your reasonable cost of physically performing this
-    conveying of source, or (2) access to copy the
-    Corresponding Source from a network server at no charge.
-
-    c) Convey individual copies of the object code with a copy of the
-    written offer to provide the Corresponding Source.  This
-    alternative is allowed only occasionally and noncommercially, and
-    only if you received the object code with such an offer, in accord
-    with subsection 6b.
-
-    d) Convey the object code by offering access from a designated
-    place (gratis or for a charge), and offer equivalent access to the
-    Corresponding Source in the same way through the same place at no
-    further charge.  You need not require recipients to copy the
-    Corresponding Source along with the object code.  If the place to
-    copy the object code is a network server, the Corresponding Source
-    may be on a different server (operated by you or a third party)
-    that supports equivalent copying facilities, provided you maintain
-    clear directions next to the object code saying where to find the
-    Corresponding Source.  Regardless of what server hosts the
-    Corresponding Source, you remain obligated to ensure that it is
-    available for as long as needed to satisfy these requirements.
-
-    e) Convey the object code using peer-to-peer transmission, provided
-    you inform other peers where the object code and Corresponding
-    Source of the work are being offered to the general public at no
-    charge under subsection 6d.
-
-  A separable portion of the object code, whose source code is excluded
-from the Corresponding Source as a System Library, need not be
-included in conveying the object code work.
-
-  A ""User Product"" is either (1) a ""consumer product"", which means any
-tangible personal property which is normally used for personal, family,
-or household purposes, or (2) anything designed or sold for incorporation
-into a dwelling.  In determining whether a product is a consumer product,
-doubtful cases shall be resolved in favor of coverage.  For a particular
-product received by a particular user, ""normally used"" refers to a
-typical or common use of that class of product, regardless of the status
-of the particular user or of the way in which the particular user
-actually uses, or expects or is expected to use, the product.  A product
-is a consumer product regardless of whether the product has substantial
-commercial, industrial or non-consumer uses, unless such uses represent
-the only significant mode of use of the product.
-
-  ""Installation Information"" for a User Product means any methods,
-procedures, authorization keys, or other information required to install
-and execute modified versions of a covered work in that User Product from
-a modified version of its Corresponding Source.  The information must
-suffice to ensure that the continued functioning of the modified object
-code is in no case prevented or interfered with solely because
-modification has been made.
-
-  If you convey an object code work under this section in, or with, or
-specifically for use in, a User Product, and the conveying occurs as
-part of a transaction in which the right of possession and use of the
-User Product is transferred to the recipient in perpetuity or for a
-fixed term (regardless of how the transaction is characterized), the
-Corresponding Source conveyed under this section must be accompanied
-by the Installation Information.  But this requirement does not apply
-if neither you nor any third party retains the ability to install
-modified object code on the User Product (for example, the work has
-been installed in ROM).
-
-  The requirement to provide Installation Information does not include a
-requirement to continue to provide support service, warranty, or updates
-for a work that has been modified or installed by the recipient, or for
-the User Product in which it has been modified or installed.  Access to a
-network may be denied when the modification itself materially and
-adversely affects the operation of the network or violates the rules and
-protocols for communication across the network.
-
-  Corresponding Source conveyed, and Installation Information provided,
-in accord with this section must be in a format that is publicly
-documented (and with an implementation available to the public in
-source code form), and must require no special password or key for
-unpacking, reading or copying.
-
-  7. Additional Terms.
-
-  ""Additional permissions"" are terms that supplement the terms of this
-License by making exceptions from one or more of its conditions.
-Additional permissions that are applicable to the entire Program shall
-be treated as though they were included in this License, to the extent
-that they are valid under applicable law.  If additional permissions
-apply only to part of the Program, that part may be used separately
-under those permissions, but the entire Program remains governed by
-this License without regard to the additional permissions.
-
-  When you convey a copy of a covered work, you may at your option
-remove any additional permissions from that copy, or from any part of
-it.  (Additional permissions may be written to require their own
-removal in certain cases when you modify the work.)  You may place
-additional permissions on material, added by you to a covered work,
-for which you have or can give appropriate copyright permission.
-
-  Notwithstanding any other provision of this License, for material you
-add to a covered work, you may (if authorized by the copyright holders of
-that material) supplement the terms of this License with terms:
-
-    a) Disclaiming warranty or limiting liability differently from the
-    terms of sections 15 and 16 of this License; or
-
-    b) Requiring preservation of specified reasonable legal notices or
-    author attributions in that material or in the Appropriate Legal
-    Notices displayed by works containing it; or
-
-    c) Prohibiting misrepresentation of the origin of that material, or
-    requiring that modified versions of such material be marked in
-    reasonable ways as different from the original version; or
-
-    d) Limiting the use for publicity purposes of names of licensors or
-    authors of the material; or
-
-    e) Declining to grant rights under trademark law for use of some
-    trade names, trademarks, or service marks; or
-
-    f) Requiring indemnification of licensors and authors of that
-    material by anyone who conveys the material (or modified versions of
-    it) with contractual assumptions of liability to the recipient, for
-    any liability that these contractual assumptions directly impose on
-    those licensors and authors.
-
-  All other non-permissive additional terms are considered ""further
-restrictions"" within the meaning of section 10.  If the Program as you
-received it, or any part of it, contains a notice stating that it is
-governed by this License along with a term that is a further
-restriction, you may remove that term.  If a license document contains
-a further restriction but permits relicensing or conveying under this
-License, you may add to a covered work material governed by the terms
-of that license document, provided that the further restriction does
-not survive such relicensing or conveying.
-
-  If you add terms to a covered work in accord with this section, you
-must place, in the relevant source files, a statement of the
-additional terms that apply to those files, or a notice indicating
-where to find the applicable terms.
-
-  Additional terms, permissive or non-permissive, may be stated in the
-form of a separately written license, or stated as exceptions;
-the above requirements apply either way.
-
-  8. Termination.
-
-  You may not propagate or modify a covered work except as expressly
-provided under this License.  Any attempt otherwise to propagate or
-modify it is void, and will automatically terminate your rights under
-this License (including any patent licenses granted under the third
-paragraph of section 11).
-
-  However, if you cease all violation of this License, then your
-license from a particular copyright holder is reinstated (a)
-provisionally, unless and until the copyright holder explicitly and
-finally terminates your license, and (b) permanently, if the copyright
-holder fails to notify you of the violation by some reasonable means
-prior to 60 days after the cessation.
-
-  Moreover, your license from a particular copyright holder is
-reinstated permanently if the copyright holder notifies you of the
-violation by some reasonable means, this is the first time you have
-received notice of violation of this License (for any work) from that
-copyright holder, and you cure the violation prior to 30 days after
-your receipt of the notice.
-
-  Termination of your rights under this section does not terminate the
-licenses of parties who have received copies or rights from you under
-this License.  If your rights have been terminated and not permanently
-reinstated, you do not qualify to receive new licenses for the same
-material under section 10.
-
-  9. Acceptance Not Required for Having Copies.
-
-  You are not required to accept this License in order to receive or
-run a copy of the Program.  Ancillary propagation of a covered work
-occurring solely as a consequence of using peer-to-peer transmission
-to receive a copy likewise does not require acceptance.  However,
-nothing other than this License grants you permission to propagate or
-modify any covered work.  These actions infringe copyright if you do
-not accept this License.  Therefore, by modifying or propagating a
-covered work, you indicate your acceptance of this License to do so.
-
-  10. Automatic Licensing of Downstream Recipients.
-
-  Each time you convey a covered work, the recipient automatically
-receives a license from the original licensors, to run, modify and
-propagate that work, subject to this License.  You are not responsible
-for enforcing compliance by third parties with this License.
-
-  An ""entity transaction"" is a transaction transferring control of an
-organization, or substantially all assets of one, or subdividing an
-organization, or merging organizations.  If propagation of a covered
-work results from an entity transaction, each party to that
-transaction who receives a copy of the work also receives whatever
-licenses to the work the party's predecessor in interest had or could
-give under the previous paragraph, plus a right to possession of the
-Corresponding Source of the work from the predecessor in interest, if
-the predecessor has it or can get it with reasonable efforts.
-
-  You may not impose any further restrictions on the exercise of the
-rights granted or affirmed under this License.  For example, you may
-not impose a license fee, royalty, or other charge for exercise of
-rights granted under this License, and you may not initiate litigation
-(including a cross-claim or counterclaim in a lawsuit) alleging that
-any patent claim is infringed by making, using, selling, offering for
-sale, or importing the Program or any portion of it.
-
-  11. Patents.
-
-  A ""contributor"" is a copyright holder who authorizes use under this
-License of the Program or a work on which the Program is based.  The
-work thus licensed is called the contributor's ""contributor version"".
-
-  A contributor's ""essential patent claims"" are all patent claims
-owned or controlled by the contributor, whether already acquired or
-hereafter acquired, that would be infringed by some manner, permitted
-by this License, of making, using, or selling its contributor version,
-but do not include claims that would be infringed only as a
-consequence of further modification of the contributor version.  For
-purposes of this definition, ""control"" includes the right to grant
-patent sublicenses in a manner consistent with the requirements of
-this License.
-
-  Each contributor grants you a non-exclusive, worldwide, royalty-free
-patent license under the contributor's essential patent claims, to
-make, use, sell, offer for sale, import and otherwise run, modify and
-propagate the contents of its contributor version.
-
-  In the following three paragraphs, a ""patent license"" is any express
-agreement or commitment, however denominated, not to enforce a patent
-(such as an express permission to practice a patent or covenant not to
-sue for patent infringement).  To ""grant"" such a patent license to a
-party means to make such an agreement or commitment not to enforce a
-patent against the party.
-
-  If you convey a covered work, knowingly relying on a patent license,
-and the Corresponding Source of the work is not available for anyone
-to copy, free of charge and under the terms of this License, through a
-publicly available network server or other readily accessible means,
-then you must either (1) cause the Corresponding Source to be so
-available, or (2) arrange to deprive yourself of the benefit of the
-patent license for this particular work, or (3) arrange, in a manner
-consistent with the requirements of this License, to extend the patent
-license to downstream recipients.  ""Knowingly relying"" means you have
-actual knowledge that, but for the patent license, your conveying the
-covered work in a country, or your recipient's use of the covered work
-in a country, would infringe one or more identifiable patents in that
-country that you have reason to believe are valid.
-
-  If, pursuant to or in connection with a single transaction or
-arrangement, you convey, or propagate by procuring conveyance of, a
-covered work, and grant a patent license to some of the parties
-receiving the covered work authorizing them to use, propagate, modify
-or convey a specific copy of the covered work, then the patent license
-you grant is automatically extended to all recipients of the covered
-work and works based on it.
-
-  A patent license is ""discriminatory"" if it does not include within
-the scope of its coverage, prohibits the exercise of, or is
-conditioned on the non-exercise of one or more of the rights that are
-specifically granted under this License.  You may not convey a covered
-work if you are a party to an arrangement with a third party that is
-in the business of distributing software, under which you make payment
-to the third party based on the extent of your activity of conveying
-the work, and under which the third party grants, to any of the
-parties who would receive the covered work from you, a discriminatory
-patent license (a) in connection with copies of the covered work
-conveyed by you (or copies made from those copies), or (b) primarily
-for and in connection with specific products or compilations that
-contain the covered work, unless you entered into that arrangement,
-or that patent license was granted, prior to 28 March 2007.
-
-  Nothing in this License shall be construed as excluding or limiting
-any implied license or other defenses to infringement that may
-otherwise be available to you under applicable patent law.
-
-  12. No Surrender of Others' Freedom.
-
-  If conditions are imposed on you (whether by court order, agreement or
-otherwise) that contradict the conditions of this License, they do not
-excuse you from the conditions of this License.  If you cannot convey a
-covered work so as to satisfy simultaneously your obligations under this
-License and any other pertinent obligations, then as a consequence you may
-not convey it at all.  For example, if you agree to terms that obligate you
-to collect a royalty for further conveying from those to whom you convey
-the Program, the only way you could satisfy both those terms and this
-License would be to refrain entirely from conveying the Program.
-
-  13. Use with the GNU Affero General Public License.
-
-  Notwithstanding any other provision of this License, you have
-permission to link or combine any covered work with a work licensed
-under version 3 of the GNU Affero General Public License into a single
-combined work, and to convey the resulting work.  The terms of this
-License will continue to apply to the part which is the covered work,
-but the special requirements of the GNU Affero General Public License,
-section 13, concerning interaction through a network will apply to the
-combination as such.
-
-  14. Revised Versions of this License.
-
-  The Free Software Foundation may publish revised and/or new versions of
-the GNU General Public License from time to time.  Such new versions will
-be similar in spirit to the present version, but may differ in detail to
-address new problems or concerns.
-
-  Each version is given a distinguishing version number.  If the
-Program specifies that a certain numbered version of the GNU General
-Public License ""or any later version"" applies to it, you have the
-option of following the terms and conditions either of that numbered
-version or of any later version published by the Free Software
-Foundation.  If the Program does not specify a version number of the
-GNU General Public License, you may choose any version ever published
-by the Free Software Foundation.
-
-  If the Program specifies that a proxy can decide which future
-versions of the GNU General Public License can be used, that proxy's
-public statement of acceptance of a version permanently authorizes you
-to choose that version for the Program.
-
-  Later license versions may give you additional or different
-permissions.  However, no additional obligations are imposed on any
-author or copyright holder as a result of your choosing to follow a
-later version.
-
-  15. Disclaimer of Warranty.
-
-  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
-APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
-HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM ""AS IS"" WITHOUT WARRANTY
-OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
-THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
-PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
-IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
-ALL NECESSARY SERVICING, REPAIR OR CORRECTION.
-
-  16. Limitation of Liability.
-
-  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
-WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
-THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
-GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
-USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
-DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
-PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
-EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
-SUCH DAMAGES.
-
-  17. Interpretation of Sections 15 and 16.
-
-  If the disclaimer of warranty and limitation of liability provided
-above cannot be given local legal effect according to their terms,
-reviewing courts shall apply local law that most closely approximates
-an absolute waiver of all civil liability in connection with the
-Program, unless a warranty or assumption of liability accompanies a
-copy of the Program in return for a fee.
-
-                     END OF TERMS AND CONDITIONS
-
-            How to Apply These Terms to Your New Programs
-
-  If you develop a new program, and you want it to be of the greatest
-possible use to the public, the best way to achieve this is to make it
-free software which everyone can redistribute and change under these terms.
-
-  To do so, attach the following notices to the program.  It is safest
-to attach them to the start of each source file to most effectively
-state the exclusion of warranty; and each file should have at least
-the ""copyright"" line and a pointer to where the full notice is found.
-
-    <one line to give the program's name and a brief idea of what it does.>
-    Copyright (C) <year>  <name of author>
-
-    This program is free software: you can redistribute it and/or modify
-    it under the terms of the GNU General Public License as published by
-    the Free Software Foundation, either version 3 of the License, or
-    (at your option) any later version.
-
-    This program is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU General Public License for more details.
-
-    You should have received a copy of the GNU General Public License
-    along with this program.  If not, see <https://www.gnu.org/licenses/>.
-
-Also add information on how to contact you by electronic and paper mail.
-
-  If the program does terminal interaction, make it output a short
-notice like this when it starts in an interactive mode:
-
-    <program>  Copyright (C) <year>  <name of author>
-    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
-    This is free software, and you are welcome to redistribute it
-    under certain conditions; type `show c' for details.
-
-The hypothetical commands `show w' and `show c' should show the appropriate
-parts of the General Public License.  Of course, your program's commands
-might be different; for a GUI interface, you would use an ""about box"".
-
-  You should also get your employer (if you work as a programmer) or school,
-if any, to sign a ""copyright disclaimer"" for the program, if necessary.
-For more information on this, and how to apply and follow the GNU GPL, see
-<https://www.gnu.org/licenses/>.
-
-  The GNU General Public License does not permit incorporating your program
-into proprietary programs.  If your program is a subroutine library, you
-may consider it more useful to permit linking proprietary applications with
-the library.  If this is what you want to do, use the GNU Lesser General
-Public License instead of this License.  But first, please read
-<https://www.gnu.org/licenses/why-not-lgpl.html>.
+# MIT License
+
+Copyright (c) 2023 easystats team
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the ""Software""), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
\ No newline at end of file

---FILE: NEWS.md---
@@ -1,3 +1,7 @@
+# effectsize 0.8.7.xxx
+
+- This release changes the licensing model of `{effectsize}` to an MIT license.
+
 # effectsize 0.8.7
 
 ## New features",False,False,Dependency / Package,6
easystats,effectsize,9a6bb14ca68a8364bdf12109c8f7071c13f2e19a,Indrajeet Patil,patilindrajeet.science@gmail.com,2023-09-20T19:53:07Z,GitHub,noreply@github.com,2023-09-20T19:53:07Z,"Remove unnecessary import directives (#607)

* Remove unnecessary import directives

Discovered while thinking about https://github.com/easystats/easystats/issues/379

* fix strict workflow

* clean up some lints",NAMESPACE;R/cohens_d.R;R/convert_stat_chisq.R;R/effectsize-package.R;R/eta_squared-main.R;R/eta_squared-methods.R;R/xtab_diff.R;man/convert_chisq.Rd;man/effectsize-package.Rd;tests/testthat/test-effectsize.R;tests/testthat/test-eta_squared.R,False,True,True,False,116,53,169,"---FILE: NAMESPACE---
@@ -247,14 +247,8 @@ importFrom(bayestestR,equivalence_test)
 importFrom(datawizard,standardise)
 importFrom(datawizard,standardize)
 importFrom(insight,display)
-importFrom(insight,find_predictors)
 importFrom(insight,print_html)
 importFrom(insight,print_md)
-importFrom(parameters,model_parameters)
 importFrom(parameters,standardize_info)
 importFrom(parameters,standardize_parameters)
 importFrom(parameters,standardize_posteriors)
-importFrom(stats,anova)
-importFrom(stats,aov)
-importFrom(stats,na.omit)
-importFrom(utils,packageVersion)

---FILE: R/cohens_d.R---
@@ -266,7 +266,7 @@ glass_delta <- function(x, y = NULL, data = NULL,
   }
 
   out <- data.frame(d = (d - mu) / s)
-  types <- c(""d"" = ""Cohens_d"", ""g"" = ""Hedges_g"", ""delta"" = ""Glass_delta"")
+  types <- c(d = ""Cohens_d"", g = ""Hedges_g"", delta = ""Glass_delta"")
   colnames(out) <- types[type]
 
   if (.test_ci(ci)) {

---FILE: R/convert_stat_chisq.R---
@@ -48,7 +48,8 @@
 #'
 #' \deqn{\textrm{Pearson's } C = \sqrt{\chi^2 / (\chi^2 + n)}}{Pearson's C = sqrt(\chi^2 / (\chi^2 + n))}
 #'
-#' For versions adjusted for small-sample bias of \eqn{\phi}, \eqn{V}, and \eqn{T}, see [Bergsma, 2013](https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V#Bias_correction).
+#' For versions adjusted for small-sample bias of \eqn{\phi}, \eqn{V}, and \eqn{T},
+#' see [Bergsma, 2013](https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V#Bias_correction).
 #'
 #' @inheritSection effectsize_CIs Confidence (Compatibility) Intervals (CIs)
 #' @inheritSection effectsize_CIs CIs and Significance Tests

---FILE: R/effectsize-package.R---
@@ -18,8 +18,9 @@
 #' and hypothesis tests, such as [cohens_d()], [phi()], [eta_squared()], and
 #' many more.
 #'
-#' See [`vignette(""effectsize"", package = ""effectsize"")`](https://easystats.github.io/effectsize/articles/effectsize.html) for more details,
-#' or [`vignette(package = ""effectsize"")`](https://easystats.github.io/effectsize/articles/) for a full list of vignettes.
+#' See [`vignette(""effectsize"", package = ""effectsize"")`](https://easystats.github.io/effectsize/articles/effectsize.html)
+#' for more details, or [`vignette(package = ""effectsize"")`](https://easystats.github.io/effectsize/articles/)
+#' for a full list of vignettes.
 #'
 #' References: Ben-Shachar et al. (2020) \doi{10.21105/joss.02815}.
 #'

---FILE: R/eta_squared-main.R---
@@ -764,7 +764,6 @@ cohens_f_squared <- function(model,
 
 
 #' @keywords internal
-#' @importFrom stats anova
 .anova_es.default <- function(model, ...) {
   .anova_es.anova(stats::anova(model), ...)
 }
@@ -842,8 +841,6 @@ cohens_f_squared <- function(model,
 }
 
 #' @keywords internal
-#' @importFrom parameters model_parameters
-#' @importFrom stats anova
 .anova_es.aov <- function(model,
                           type = c(""eta"", ""omega"", ""epsilon""),
                           partial = TRUE,
@@ -885,8 +882,6 @@ cohens_f_squared <- function(model,
 .anova_es.glm <- .anova_es.lm
 
 #' @keywords internal
-#' @importFrom parameters model_parameters
-#' @importFrom insight find_predictors
 .anova_es.aovlist <- function(model,
                               type = c(""eta"", ""omega"", ""epsilon""),
                               partial = TRUE,

---FILE: R/eta_squared-methods.R---
@@ -110,7 +110,7 @@
     within <- names(model$idata)
     within <- lapply(within, function(x) c(NA, x))
     within <- do.call(expand.grid, within)
-    within <- apply(within, 1, na.omit)
+    within <- apply(within, 1, stats::na.omit)
     ns <- sapply(within, length)
     within <- sapply(within, paste, collapse = "":"")
     within <- within[order(ns)]
@@ -179,7 +179,6 @@
 #' @keywords internal
 .anova_es.anova.lme <- .anova_es.anova
 
-#' @importFrom stats na.omit
 #' @keywords internal
 .anova_es.parameters_model <- function(model,
                                        type = c(""eta"", ""omega"", ""epsilon""),
@@ -249,8 +248,6 @@
 # Specific models ---------------------------------------------------------
 
 #' @keywords internal
-#' @importFrom stats aov
-#' @importFrom utils packageVersion
 .anova_es.maov <- function(model,
                            type = c(""eta"", ""omega"", ""epsilon""),
                            partial = TRUE,

---FILE: R/xtab_diff.R---
@@ -295,7 +295,7 @@ arr <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...) {
 nnt <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...) {
   alternative <- .match.alt(alternative)
 
-  flip_alt <- c(""less"" = ""greater"", ""greater"" = ""less"", ""two.sided"" = ""two.sided"")
+  flip_alt <- c(less = ""greater"", greater = ""less"", two.sided = ""two.sided"")
   alternative2 <- unname(flip_alt[alternative])
 
   if (.is_htest_of_type(x, ""Pearson's Chi-squared"", ""Chi-squared-test"")) {

---FILE: man/convert_chisq.Rd---
@@ -127,7 +127,8 @@ Where \eqn{p_E} are the expected probabilities.
 
 \deqn{\textrm{Pearson's } C = \sqrt{\chi^2 / (\chi^2 + n)}}{Pearson's C = sqrt(\chi^2 / (\chi^2 + n))}
 
-For versions adjusted for small-sample bias of \eqn{\phi}, \eqn{V}, and \eqn{T}, see \href{https://en.wikipedia.org/wiki/Cram\%C3\%A9r\%27s_V#Bias_correction}{Bergsma, 2013}.
+For versions adjusted for small-sample bias of \eqn{\phi}, \eqn{V}, and \eqn{T},
+see \href{https://en.wikipedia.org/wiki/Cram\%C3\%A9r\%27s_V#Bias_correction}{Bergsma, 2013}.
 }
 \section{Confidence (Compatibility) Intervals (CIs)}{
 Unless stated otherwise, confidence (compatibility) intervals (CIs) are

---FILE: man/effectsize-package.Rd---
@@ -20,8 +20,9 @@ and their confidence intervals (CIs), from a variety of statistical models
 and hypothesis tests, such as \code{\link[=cohens_d]{cohens_d()}}, \code{\link[=phi]{phi()}}, \code{\link[=eta_squared]{eta_squared()}}, and
 many more.
 
-See \href{https://easystats.github.io/effectsize/articles/effectsize.html}{\code{vignette(""effectsize"", package = ""effectsize"")}} for more details,
-or \href{https://easystats.github.io/effectsize/articles/}{\code{vignette(package = ""effectsize"")}} for a full list of vignettes.
+See \href{https://easystats.github.io/effectsize/articles/effectsize.html}{\code{vignette(""effectsize"", package = ""effectsize"")}}
+for more details, or \href{https://easystats.github.io/effectsize/articles/}{\code{vignette(package = ""effectsize"")}}
+for a full list of vignettes.
 
 References: Ben-Shachar et al. (2020) \doi{10.21105/joss.02815}.
 }

---FILE: tests/testthat/test-effectsize.R---
@@ -252,14 +252,56 @@ test_that(""htest | rank"", {
 })
 
 test_that(""htest | Get args from htest"", {
-  tt <- t.test(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3, conf.level = 0.8, var.equal = TRUE)
-  expect_equal(cohens_d(tt), cohens_d(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3, ci = 0.8), ignore_attr = TRUE)
+  tt <- t.test(
+    mtcars$hp,
+    mtcars$mpg,
+    alternative = ""l"",
+    mu = -3,
+    conf.level = 0.8,
+    var.equal = TRUE
+  )
+  expect_equal(
+    cohens_d(tt),
+    cohens_d(
+      mtcars$hp,
+      mtcars$mpg,
+      alternative = ""l"",
+      mu = -3,
+      ci = 0.8
+    ),
+    ignore_attr = TRUE
+  )
 
-  suppressWarnings(ww1 <- wilcox.test(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3))
-  expect_equal(rank_biserial(ww1), rank_biserial(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3), ignore_attr = TRUE)
+  suppressWarnings({
+    ww1 <- wilcox.test(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3)
+  })
+  expect_equal(
+    rank_biserial(ww1),
+    rank_biserial(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3),
+    ignore_attr = TRUE
+  )
 
-  suppressWarnings(ww2 <- wilcox.test(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3, conf.int = TRUE, conf.level = 0.8))
-  expect_equal(rank_biserial(ww2), rank_biserial(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3, ci = 0.8), ignore_attr = TRUE)
+  suppressWarnings({
+    ww2 <- wilcox.test(
+      mtcars$hp,
+      mtcars$mpg,
+      alternative = ""l"",
+      mu = -3,
+      conf.int = TRUE,
+      conf.level = 0.8
+    )
+  })
+  expect_equal(
+    rank_biserial(ww2),
+    rank_biserial(
+      mtcars$hp,
+      mtcars$mpg,
+      alternative = ""l"",
+      mu = -3,
+      ci = 0.8
+    ),
+    ignore_attr = TRUE
+  )
 })
 
 

---FILE: tests/testthat/test-eta_squared.R---
@@ -516,19 +516,47 @@ test_that(""afex | mixed()"", {
   # Intercept
   data(""stroop"", package = ""afex"")
   stroop <- subset(stroop, study == 1 & acc == 1 & trialnum < 20)
-  suppressMessages(m1 <- afex::mixed(rt ~ condition + (condition | pno), data = stroop, method = ""KR""))
-  suppressMessages(m2 <- afex::mixed(rt ~ condition + (condition | pno), data = stroop, test_intercept = TRUE, method = ""KR""))
+  suppressMessages({
+    m1 <- afex::mixed(rt ~ condition + (condition | pno), data = stroop, method = ""KR"")
+  })
+  suppressMessages({
+    m2 <- afex::mixed(rt ~ condition + (condition | pno),
+      data = stroop,
+      test_intercept = TRUE,
+      method = ""KR""
+    )
+  })
 
-  expect_warning(a1a <- eta_squared(m1, include_intercept = TRUE), regexp = ""Intercept"")
-  expect_warning(a1b <- eta_squared(m1, include_intercept = FALSE), regexp = NA)
+  expect_warning(
+    {
+      a1a <- eta_squared(m1, include_intercept = TRUE)
+    },
+    regexp = ""Intercept""
+  )
+  expect_warning(
+    {
+      a1b <- eta_squared(m1, include_intercept = FALSE)
+    },
+    regexp = NA
+  )
   expect_equal(a1a, a1b)
   expect_equal(nrow(a1a), 1L)
 
-  expect_warning(a2a <- eta_squared(m2, include_intercept = TRUE), regexp = NA)
-  expect_warning(a2b <- eta_squared(m2, include_intercept = FALSE), regexp = NA)
+  expect_warning(
+    {
+      a2a <- eta_squared(m2, include_intercept = TRUE)
+    },
+    regexp = NA
+  )
+  expect_warning(
+    {
+      a2b <- eta_squared(m2, include_intercept = FALSE)
+    },
+    regexp = NA
+  )
   expect_equal(nrow(a2a), 2L)
   expect_equal(nrow(a2b), 1L)
-  expect_equal(a1a, a2a[2, ], ignore_attr = TRUE)
+  expect_equal(a1a, a2a[2L, ], ignore_attr = TRUE)
 })
 
 
@@ -546,17 +574,18 @@ test_that(""car MVM"", {
     id = 1:8
   )
 
-  ds_long <-
-    datawizard::reshape_longer(ds,
-      select = 1:4,
-      names_to = ""ind_var"",
-      values_to = ""score""
-    )
+  ds_long <- datawizard::reshape_longer(ds,
+    select = 1:4,
+    names_to = ""ind_var"",
+    values_to = ""score""
+  )
 
 
   fit <- lm(cbind(I, II, III, IV) ~ 1, data = ds)
-  in_rep <- data.frame(ind_var = gl(4, 1))
-  suppressMessages(A_car <- car::Anova(fit, idata = in_rep, idesign = ~ind_var))
+  in_rep <- data.frame(ind_var = gl(4L, 1L))
+  suppressMessages({
+    A_car <- car::Anova(fit, idata = in_rep, idesign = ~ind_var)
+  })
 
   eta_car <- effectsize::eta_squared(A_car, ci = NULL)[[2]]
 
@@ -570,11 +599,13 @@ test_that(""car MVM"", {
   # Complex ---
   data(obk.long, package = ""afex"")
 
-  suppressMessages(mod <- afex::aov_ez(""id"", ""value"", obk.long,
-    between = c(""treatment"", ""gender""),
-    within = c(""phase"", ""hour""),
-    observed = ""gender""
-  ))
+  suppressMessages({
+    mod <- afex::aov_ez(""id"", ""value"", obk.long,
+      between = c(""treatment"", ""gender""),
+      within = c(""phase"", ""hour""),
+      observed = ""gender""
+    )
+  })
   expect_equal(
     sort(eta_squared(mod$Anova, generalized = ""gender"")[[2]]),
     sort(mod$anova_table$ges)
@@ -592,7 +623,7 @@ test_that(""Anova.mlm Manova"", {
 
   mod <- lm(cbind(mpg, qsec, disp) ~ am_f * cyl_f, data = mtcars)
 
-  Manova <- car::Manova(mod, type = 2)
+  Manova <- car::Manova(mod, type = 2L)
 
   expect_true(is.null(summary(Manova, univariate = TRUE)[[""univariate.tests""]]))
   expect_error(eta_squared(Manova), regexp = NA)
@@ -622,8 +653,8 @@ test_that(""merMod and lmerModLmerTest"", {
 
   data(""sleepstudy"", package = ""lme4"")
 
-  m <- lme4::lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
-  mtest <- lmerTest::lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
+  m <- lme4::lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy)
+  mtest <- lmerTest::lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy)
 
   expect_equal(
     eta_squared(m),
@@ -676,7 +707,7 @@ test_that(""ets_squared | rms"", {
 
   skip_if_not_installed(""car"")
   skip_if_not_installed(""base"", minimum_version = ""3.6.1"")
-  b_lm <- car::Anova(lm(mpg ~ cyl + am, data = mtcars), type = 2)
+  b_lm <- car::Anova(lm(mpg ~ cyl + am, data = mtcars), type = 2L)
   out_lm <- eta_squared(b_lm)
   expect_equal(out[1:2, ], out_lm, ignore_attr = TRUE)
 })",True,False,Dependency / Package,7
easystats,effectsize,90e88e5f76c818f6240f012a5644cd03844d8a32,Indrajeet Patil,patilindrajeet.science@gmail.com,2023-09-14T11:50:48Z,Indrajeet Patil,patilindrajeet.science@gmail.com,2023-09-14T11:50:48Z,fix styling workflow,R/rank_diff.R;man/rank_biserial.Rd;vignettes/from_test_statistics.Rmd,True,True,True,False,5,5,10,"---FILE: R/rank_diff.R---
@@ -71,7 +71,7 @@
 #'
 #' # One Sample ----------
 #' # from help(""wilcox.test"")
-#' x <- c(1.83,  0.50,  1.62,  2.48, 1.68, 1.88, 1.55, 3.06, 1.30)
+#' x <- c(1.83, 0.50, 1.62, 2.48, 1.68, 1.88, 1.55, 3.06, 1.30)
 #' y <- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)
 #' depression <- data.frame(first = x, second = y, change = y - x)
 #'

---FILE: man/rank_biserial.Rd---
@@ -140,7 +140,7 @@ print(rb, append_CLES = TRUE)
 
 # One Sample ----------
 # from help(""wilcox.test"")
-x <- c(1.83,  0.50,  1.62,  2.48, 1.68, 1.88, 1.55, 3.06, 1.30)
+x <- c(1.83, 0.50, 1.62, 2.48, 1.68, 1.88, 1.55, 3.06, 1.30)
 y <- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)
 depression <- data.frame(first = x, second = y, change = y - x)
 

---FILE: vignettes/from_test_statistics.Rmd---
@@ -125,7 +125,7 @@ F_to_eta2(
 We can also use `t_to_eta2()` for contrast analysis:
 
 ```{r, eval = .eval_if_requireNamespace(""afex"", ""emmeans"")}
-pairs(emmeans(aov_fit, ~ angle))
+pairs(emmeans(aov_fit, ~angle))
 
 t_to_eta2(
   t = c(-6.2, -8.2, -3.2),
@@ -212,7 +212,7 @@ This measure is also sometimes used in contrast analysis, where it is called the
 point bi-serial correlation - $r_{pb}$ [@cohen1965some; @rosnow2000contrasts]:
 
 ```{r, eval = .eval_if_requireNamespace(""afex"", ""emmeans"")}
-pairs(emmeans(aov_fit, ~ angle))
+pairs(emmeans(aov_fit, ~angle))
 
 t_to_r(
   t = c(-6.2, -8.2, -3.2),
@@ -254,7 +254,7 @@ eff_size(em_tension, sigma = sigma(m), edf = df.residual(m))
 ### Within-Subject Contrasts
 
 ```{r, eval = .eval_if_requireNamespace(""afex"", ""emmeans"")}
-pairs(emmeans(aov_fit, ~ angle))
+pairs(emmeans(aov_fit, ~angle))
 
 t_to_d(
   t = c(-6.2, -8.2, -3.3),",True,True,Documentation / Formatting,6
easystats,effectsize,6102cd792041e6e0f6c73a97d7d7b026482bb3f3,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2023-09-14T11:28:55Z,GitHub,noreply@github.com,2023-09-14T11:28:55Z,fix devel 4.4.0 (#602),DESCRIPTION;NEWS.md;R/cohens_d.R;R/common_language.R;R/eta_squared-methods.R;R/means_ratio.R;R/pooled.R;R/rank_diff.R;R/utils_validate_input_data.R;inst/WORDLIST;man/rank_biserial.Rd;tests/testthat/test-eta_squared.R;tests/testthat/test-rom.R;vignettes/standardized_differences.Rmd,True,True,True,False,125,49,174,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size
-Version: 0.8.5
+Version: 0.8.6
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",
@@ -66,16 +66,16 @@ BugReports: https://github.com/easystats/effectsize/issues/
 Depends:
     R (>= 3.6)
 Imports:
-    bayestestR (>= 0.13.0),
-    insight (>= 0.19.3.2),
-    parameters (>= 0.20.2),
-    performance (>= 0.10.2),
-    datawizard (>= 0.6.5),
+    bayestestR (>= 0.13.1),
+    insight (>= 0.19.5),
+    parameters (>= 0.21.1),
+    performance (>= 0.10.5),
+    datawizard (>= 0.8.0),
     stats,
     utils
 Suggests:
-    correlation (>= 0.8.3),
-    see (>= 0.7.4),
+    correlation (>= 0.8.4),
+    see (>= 0.8.0),
     afex,
     BayesFactor,
     boot,
@@ -107,4 +107,3 @@ Config/Needs/website:
     rstudio/bslib,
     r-lib/pkgdown,
     easystats/easystatstemplate
-Remotes: easystats/insight

---FILE: NEWS.md---
@@ -1,3 +1,16 @@
+# effectsize 0.8.6
+
+This is a minor update to bring `effectsize` in-line with the formula methods 
+in `t.test()` and `wilcox.test()` in `R>=4.4.0`.
+
+## Breaking Changes
+
+- `cohens_d()`, `hedges_g()`, `p_superiority()`, `wmw_odds()`, `means_ratio()` and `rank_biserial()` no longer support setting `paired = TRUE` when using the formula method.
+
+## Bug fixes
+
+- `eta_squared(<gam>)` returns (approximate) effect sizes for smooths.
+
 # effectsize 0.8.5
 
 ## New features

---FILE: R/cohens_d.R---
@@ -206,6 +206,7 @@ glass_delta <- function(x, y = NULL, data = NULL,
   out <- .get_data_2_samples(x, y, data, paired = paired, verbose = verbose, ...)
   x <- out[[""x""]]
   y <- out[[""y""]]
+  paired <- out[[""paired""]]
 
   if (is.null(y)) {
     if (type == ""delta"") {
@@ -217,6 +218,10 @@ glass_delta <- function(x, y = NULL, data = NULL,
 
   # Compute index
   if (paired) {
+    if (type == ""delta"") {
+      insight::format_error(""This effect size is only applicable for two independent samples."")
+    }
+
     d <- mean(x - y)
     n <- length(x)
     s <- stats::sd(x - y)

---FILE: R/common_language.R---
@@ -123,6 +123,7 @@ p_superiority <- function(x, y = NULL, data = NULL,
   )
   x <- data[[""x""]]
   y <- data[[""y""]]
+  paired <- data[[""paired""]]
 
   if (parametric) {
     d <- cohens_d(
@@ -162,14 +163,15 @@ cohens_u1 <- function(x, y = NULL, data = NULL,
     return(effectsize(x, type = ""u1"", ci = ci, verbose = verbose, ...))
   }
 
-
   data <- .get_data_2_samples(x, y, data,
     allow_ordered = !parametric,
     verbose = verbose, ...
   )
   x <- data[[""x""]]
   y <- data[[""y""]]
-  if (is.null(y)) insight::format_error(""cohens_u3 only applicable to two sample case."")
+  if (is.null(y) || isTRUE(match.call()$paired) || isTRUE(data[[""paired""]])) {
+    insight::format_error(""This effect size is only applicable for two independent samples."")
+  }
 
   if (!parametric) {
     insight::format_error(""Cohen's U1 only available for parametric estimation."")
@@ -202,14 +204,15 @@ cohens_u2 <- function(x, y = NULL, data = NULL,
     return(effectsize(x, type = ""u2"", ci = ci, verbose = verbose, ...))
   }
 
-
   data <- .get_data_2_samples(x, y, data,
     allow_ordered = !parametric,
     verbose = verbose, ...
   )
   x <- data[[""x""]]
   y <- data[[""y""]]
-  if (is.null(y)) insight::format_error(""cohens_u3 only applicable to two sample case."")
+  if (is.null(y) || isTRUE(match.call()$paired) || isTRUE(data[[""paired""]])) {
+    insight::format_error(""This effect size is only applicable for two independent samples."")
+  }
 
   if (parametric) {
     d <- cohens_d(
@@ -253,7 +256,9 @@ cohens_u3 <- function(x, y = NULL, data = NULL,
   )
   x <- data[[""x""]]
   y <- data[[""y""]]
-  if (is.null(y)) insight::format_error(""cohens_u3 only applicable to two sample case."")
+  if (is.null(y) || isTRUE(match.call()$paired) || isTRUE(data[[""paired""]])) {
+    insight::format_error(""This effect size is only applicable for two independent samples."")
+  }
 
   if (parametric) {
     d <- cohens_d(
@@ -289,14 +294,15 @@ p_overlap <- function(x, y = NULL, data = NULL,
     return(effectsize(x, type = ""overlap"", ci = ci, verbose = verbose, ...))
   }
 
-
   data <- .get_data_2_samples(x, y, data,
     allow_ordered = !parametric,
     verbose = verbose, ...
   )
   x <- data[[""x""]]
   y <- data[[""y""]]
-  if (is.null(y)) insight::format_error(""Overlap only applicable to two sample case."")
+  if (is.null(y) || isTRUE(match.call()$paired) || isTRUE(data[[""paired""]])) {
+    insight::format_error(""This effect size is only applicable for two independent samples."")
+  }
 
   if (parametric) {
     d <- cohens_d(

---FILE: R/eta_squared-methods.R---
@@ -354,13 +354,16 @@
   model <- stats::anova(model)
 
   p.table <- as.data.frame(model$pTerms.table)
+  p.table$Component <- ""conditional""
   s.table <- as.data.frame(model$s.table)
+  s.table$Component <- ""smooth_terms""
+  colnames(s.table)[colnames(s.table) == ""Ref.df""] <- ""df""
   s.table[setdiff(colnames(p.table), colnames(s.table))] <- NA
   p.table[setdiff(colnames(s.table), colnames(p.table))] <- NA
   tab <- rbind(p.table, s.table)
-  colnames(tab)[colnames(tab) == ""F""] <- ""F-value""
   colnames(tab)[colnames(tab) == ""df""] <- ""npar""
   tab$df_error <- model$residual.df
+  # tab$df_error <- Inf
 
   out <-
     .anova_es.anova(
@@ -371,6 +374,8 @@
       ci = ci, alternative = alternative,
       verbose = verbose
     )
+  out$Component <- tab$Component
+  out <- datawizard::data_relocate(out, select = ""Component"", before = 1)
 
   attr(out, ""anova_type"") <- 3
   attr(out, ""approximate"") <- TRUE

---FILE: R/means_ratio.R---
@@ -76,6 +76,7 @@ means_ratio <- function(x, y = NULL, data = NULL,
   )
   x <- out[[""x""]]
   y <- out[[""y""]]
+  paired <- out[[""paired""]]
 
   if (is.null(y)) {
     insight::format_error(""Only one sample provided. y or data must be provided."")

---FILE: R/pooled.R---
@@ -28,6 +28,9 @@ sd_pooled <- function(x, y = NULL, data = NULL, verbose = TRUE, ...) {
   data <- .get_data_2_samples(x, y, data, verbose = verbose, ...)
   x <- data[[""x""]]
   y <- data[[""y""]]
+  if (is.null(y) || isTRUE(match.call()$paired) || isTRUE(data[[""paired""]])) {
+    insight::format_error(""This effect size is only applicable for two independent samples."")
+  }
 
   V <- cov_pooled(
     data.frame(x = x),
@@ -46,6 +49,9 @@ mad_pooled <- function(x, y = NULL, data = NULL,
   data <- .get_data_2_samples(x, y, data, verbose = verbose, ...)
   x <- data[[""x""]]
   y <- data[[""y""]]
+  if (is.null(y) || isTRUE(match.call()$paired) || isTRUE(data[[""paired""]])) {
+    insight::format_error(""This effect size is only applicable for two independent samples."")
+  }
 
   n1 <- length(x)
   n2 <- length(y)

---FILE: R/rank_diff.R---
@@ -62,28 +62,34 @@
 #' # Same as:
 #' # rank_biserial(""mpg"", ""am"", data = mtcars)
 #' # rank_biserial(mtcars$mpg[mtcars$am==""0""], mtcars$mpg[mtcars$am==""1""])
+#' # cliffs_delta(mpg ~ am, data = mtcars)
 #'
 #' # More options:
 #' rank_biserial(mpg ~ am, data = mtcars, mu = -5)
 #' print(rb, append_CLES = TRUE)
 #'
 #'
 #' # One Sample ----------
-#' rank_biserial(wt ~ 1, data = mtcars, mu = 3)
+#' # from help(""wilcox.test"")
+#' x <- c(1.83,  0.50,  1.62,  2.48, 1.68, 1.88, 1.55, 3.06, 1.30)
+#' y <- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)
+#' depression <- data.frame(first = x, second = y, change = y - x)
+#'
+#' rank_biserial(change ~ 1, data = depression)
+#'
 #' # same as:
-#' # rank_biserial(""wt"", data = mtcars, mu = 3)
-#' # rank_biserial(mtcars$wt, mu = 3)
+#' # rank_biserial(""change"", data = depression)
+#' # rank_biserial(mtcars$wt)
+#'
+#' # More options:
+#' rank_biserial(change ~ 1, data = depression, mu = -0.5)
 #'
 #'
 #' # Paired Samples ----------
-#' dat <- data.frame(
-#'   Cond1 = c(1.83, 0.5, 1.62, 2.48, 1.68, 1.88, 1.55, 3.06, 1.3),
-#'   Cond2 = c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)
-#' )
-#' (rb <- rank_biserial(Pair(Cond1, Cond2) ~ 1, data = dat, paired = TRUE))
+#' (rb <- rank_biserial(Pair(first, second) ~ 1, data = depression))
 #'
 #' # same as:
-#' # rank_biserial(dat$Cond1, dat$Cond2, paired = TRUE)
+#' # rank_biserial(depression$first, depression$second, paired = TRUE)
 #'
 #' interpret_rank_biserial(0.78)
 #' interpret(rb, rules = ""funder2019"")
@@ -127,8 +133,9 @@ rank_biserial <- function(x, y = NULL, data = NULL,
     allow_ordered = TRUE,
     verbose = verbose, ...
   )
-  x <- out$x
-  y <- out$y
+  x <- out[[""x""]]
+  y <- out[[""y""]]
+  paired <- out[[""paired""]]
 
   if (is.null(y)) {
     y <- 0
@@ -208,7 +215,7 @@ cliffs_delta <- function(x, y = NULL, data = NULL,
   )
   x <- data$x
   y <- data$y
-  if (is.null(y) || isTRUE(eval.parent(cl$paired))) {
+  if (is.null(y) || isTRUE(match.call()$paired) || isTRUE(data[[""paired""]])) {
     insight::format_error(""This effect size is only applicable for two independent samples."")
   }
 

---FILE: R/utils_validate_input_data.R---
@@ -3,11 +3,18 @@
                                 paired = FALSE, allow_ordered = FALSE,
                                 verbose = TRUE, ...) {
   if (inherits(x, ""formula"")) {
+    if (isTRUE(paired)) {
+      # This is to be consistent with R>=4.4.0
+      insight::format_error(""cannot use 'paired = TRUE' in formula method."")
+    }
+
     # Validate:
     if (length(x) != 3L) {
       insight::format_error(
         ""Formula must have one of the following forms:"",
-        ""\n\ty ~ group,\n\ty ~ 1,\n\tPair(x,y) ~ 1""
+        ""          y ~ group   (independant samples)"",
+        ""          y ~ 1       (one sample)"",
+        ""  Pair(x,y) ~ 1       (paired samples)""
       )
     }
 
@@ -49,6 +56,7 @@
   } else if (inherits(x, ""Pair"")) {
     x <- x[, 1] - x[, 2]
     y <- NULL
+    paired <- TRUE
   }
 
 
@@ -90,7 +98,7 @@
   }
 
 
-  list(x = x, y = y)
+  list(x = x, y = y, paired = paired)
 }
 
 

---FILE: inst/WORDLIST---
@@ -83,6 +83,7 @@ Koo
 Kruschke
 LMM
 Labelled
+labelled
 Lajeunesse
 Lakens
 Landis

---FILE: man/rank_biserial.Rd---
@@ -131,28 +131,34 @@ mtcars$cyl <- factor(mtcars$cyl)
 # Same as:
 # rank_biserial(""mpg"", ""am"", data = mtcars)
 # rank_biserial(mtcars$mpg[mtcars$am==""0""], mtcars$mpg[mtcars$am==""1""])
+# cliffs_delta(mpg ~ am, data = mtcars)
 
 # More options:
 rank_biserial(mpg ~ am, data = mtcars, mu = -5)
 print(rb, append_CLES = TRUE)
 
 
 # One Sample ----------
-rank_biserial(wt ~ 1, data = mtcars, mu = 3)
+# from help(""wilcox.test"")
+x <- c(1.83,  0.50,  1.62,  2.48, 1.68, 1.88, 1.55, 3.06, 1.30)
+y <- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)
+depression <- data.frame(first = x, second = y, change = y - x)
+
+rank_biserial(change ~ 1, data = depression)
+
 # same as:
-# rank_biserial(""wt"", data = mtcars, mu = 3)
-# rank_biserial(mtcars$wt, mu = 3)
+# rank_biserial(""change"", data = depression)
+# rank_biserial(mtcars$wt)
+
+# More options:
+rank_biserial(change ~ 1, data = depression, mu = -0.5)
 
 
 # Paired Samples ----------
-dat <- data.frame(
-  Cond1 = c(1.83, 0.5, 1.62, 2.48, 1.68, 1.88, 1.55, 3.06, 1.3),
-  Cond2 = c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)
-)
-(rb <- rank_biserial(Pair(Cond1, Cond2) ~ 1, data = dat, paired = TRUE))
+(rb <- rank_biserial(Pair(first, second) ~ 1, data = depression))
 
 # same as:
-# rank_biserial(dat$Cond1, dat$Cond2, paired = TRUE)
+# rank_biserial(depression$first, depression$second, paired = TRUE)
 
 interpret_rank_biserial(0.78)
 interpret(rb, rules = ""funder2019"")

---FILE: tests/testthat/test-eta_squared.R---
@@ -660,6 +660,7 @@ test_that(""ets_squared | gam"", {
   b <- mgcv::gam(y ~ x0 + s(x1) + s(x2) + t2(x1, x2) + s(x3), data = dat)
 
   expect_error(out <- eta_squared(b), regexp = NA)
+  expect_warning(eta_squared(b), regexp = NA)
   expect_output(print(out), ""Type III"")
 })
 

---FILE: tests/testthat/test-rom.R---
@@ -73,7 +73,14 @@ test_that(""means_ratio paired - adjusted"", {
   expect_error(means_ratio(extra ~ group, data = sleep), ""negative"")
 
   sleep$y <- sleep$extra + 4
-  x <- means_ratio(y ~ group,
+  sleep_wide <- datawizard::data_to_wide(sleep,
+    id_cols = ""ID"",
+    values_from = ""y"",
+    names_from = ""group"",
+    names_prefix = ""extra_""
+  )
+
+  x <- means_ratio(sleep_wide[[""extra_1""]], sleep_wide[[""extra_2""]],
     data = sleep,
     adjust = TRUE, paired = TRUE
   )
@@ -86,7 +93,13 @@ test_that(""means_ratio paired - adjusted"", {
 test_that(""means_ratio paired - not adjusted"", {
   data(sleep)
   sleep$y <- sleep$extra + 4
-  x <- means_ratio(y ~ group,
+  sleep_wide <- datawizard::data_to_wide(sleep,
+    id_cols = ""ID"",
+    values_from = ""y"",
+    names_from = ""group"",
+    names_prefix = ""extra_""
+  )
+  x <- means_ratio(sleep_wide[[""extra_1""]], sleep_wide[[""extra_2""]],
     data = sleep,
     adjust = FALSE, paired = TRUE
   )

---FILE: vignettes/standardized_differences.Rmd---
@@ -108,11 +108,18 @@ hedges_g(mtcars$wt, mu = 2.7)
 For paired-samples, the difference is standardized by the variation in the differences. This effect size, known as Cohen's $d_z$, represents the difference in terms of its homogeneity (a small but stable difference will have a large $d_z$).
 
 ```{r}
-t.test(extra ~ group, data = sleep, paired = TRUE)
+sleep_wide <- datawizard::data_to_wide(sleep,
+  id_cols = ""ID"",
+  values_from = ""extra"",
+  names_from = ""group"",
+  names_prefix = ""extra_""
+)
+
+t.test(sleep_wide[[""extra_1""]], sleep_wide[[""extra_2""]], paired = TRUE)
 
-cohens_d(extra ~ group, data = sleep, paired = TRUE)
+cohens_d(sleep_wide[[""extra_1""]], sleep_wide[[""extra_2""]], paired = TRUE)
 
-hedges_g(extra ~ group, data = sleep, paired = TRUE)
+hedges_g(sleep_wide[[""extra_1""]], sleep_wide[[""extra_2""]], paired = TRUE)
 ```
 
 ## For a Bayesian *t*-test
@@ -297,13 +304,11 @@ p_superiority(mtcars$wt, mu = 2.75, parametric = FALSE)
 For paired samples, *probability of superiority* is the probability that, when sampling an observation at random, its *difference* will be larger than $\mu$.
 
 ```{r}
-p_superiority(extra ~ group,
-  data = sleep,
+p_superiority(sleep_wide[[""extra_1""]], sleep_wide[[""extra_2""]],
   paired = TRUE, mu = -1
 )
 
-p_superiority(extra ~ group,
-  data = sleep,
+p_superiority(sleep_wide[[""extra_1""]], sleep_wide[[""extra_2""]],
   paired = TRUE, mu = -1,
   parametric = FALSE
 )",True,True,Documentation / Formatting,6
easystats,effectsize,4474b4f1a22b43732b206dd289751e2f0a374680,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2023-07-25T10:40:09Z,GitHub,noreply@github.com,2023-07-25T10:40:09Z,"Clean up anova effect size (#552)

* reorgANOVA functions

* fix named args

* clean up mlm

* Apply automatic changes

* clean up afex::mixed

* Clean up

* more tests

* Apply automatic changes

* temp

[skip ci]

* final fix on MANOVAs

* don't use MEMSS

* binding

* styler

---------

Co-authored-by: mattansb <mattansb@users.noreply.github.com>",NAMESPACE;NEWS.md;R/eta_squared-main.R;R/eta_squared-methods.R;tests/testthat/test-eta_squared.R,False,True,True,False,334,303,637,"---FILE: NAMESPACE---
@@ -247,8 +247,14 @@ importFrom(bayestestR,equivalence_test)
 importFrom(datawizard,standardise)
 importFrom(datawizard,standardize)
 importFrom(insight,display)
+importFrom(insight,find_predictors)
 importFrom(insight,print_html)
 importFrom(insight,print_md)
+importFrom(parameters,model_parameters)
 importFrom(parameters,standardize_info)
 importFrom(parameters,standardize_parameters)
 importFrom(parameters,standardize_posteriors)
+importFrom(stats,anova)
+importFrom(stats,aov)
+importFrom(stats,na.omit)
+importFrom(utils,packageVersion)

---FILE: NEWS.md---
@@ -38,6 +38,7 @@
 
 ## Bug fixes
 
+- ANOVA effect sizes for `afex::mixed()` now return effect sizes for the Intercept where applicable.
 - Fixed error in `cohens_w()` for 2-by-X tables.  
 - Solved integer overflow errors in `rank_biserial()` ( #476 )
 - Fixed issue in `effectsize()` for t-tests when input vectors has unequal amount of missing values.

---FILE: R/eta_squared-main.R---
@@ -756,87 +756,11 @@ cohens_f_squared <- function(model,
     UseMethod("".anova_es"")
   }
 
-#' @keywords internal
-.anova_es.default <- function(model,
-                              type = c(""eta"", ""omega"", ""epsilon""),
-                              partial = TRUE,
-                              generalized = FALSE,
-                              ci = 0.95, alternative = ""greater"",
-                              verbose = TRUE,
-                              ...) {
-  .anova_es.anova(
-    stats::anova(model),
-    type = type,
-    partial = partial,
-    generalized = generalized,
-    ci = ci,
-    alternative = alternative,
-    verbose = verbose
-  )
-}
 
 #' @keywords internal
-.anova_es.aov <- function(model,
-                          type = c(""eta"", ""omega"", ""epsilon""),
-                          partial = TRUE,
-                          generalized = FALSE,
-                          ci = 0.95, alternative = ""greater"",
-                          verbose = TRUE,
-                          ...) {
-  if (!inherits(model, c(""Gam"", ""anova""))) {
-    # Pass to ANOVA table method
-    res <- .anova_es.anova(
-      stats::anova(model),
-      type = type,
-      partial = partial,
-      generalized = generalized,
-      ci = ci, alternative = alternative,
-      verbose = verbose,
-      ...
-    )
-    return(res)
-  }
-
-  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"")
-  out <- .es_aov_simple(as.data.frame(params), type, partial, generalized, ci, alternative, verbose = verbose, ...)
-  if (is.null(attr(out, ""anova_type""))) attr(out, ""anova_type"") <- attr(params, ""anova_type"")
-  out
-}
-
-.anova_es.lm <- .anova_es.aov
-
-.anova_es.glm <- .anova_es.aov
-
-.anova_es.manova <- .anova_es.aov
-
-#' @keywords internal
-.anova_es.aovlist <- function(model,
-                              type = c(""eta"", ""omega"", ""epsilon""),
-                              partial = TRUE,
-                              generalized = FALSE,
-                              ci = 0.95, alternative = ""greater"",
-                              verbose = TRUE,
-                              include_intercept = FALSE,
-                              ...) {
-  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"")
-  anova_type <- attr(params, ""anova_type"")
-  params <- as.data.frame(params)
-
-  DV_names <- insight::find_predictors(model)[[1]]
-
-  out <-
-    .es_aov_strata(
-      params,
-      DV_names = DV_names,
-      type = type,
-      partial = partial,
-      generalized = generalized,
-      ci = ci, alternative = alternative,
-      verbose = verbose,
-      include_intercept = include_intercept
-    )
-  attr(out, ""anova_type"") <- anova_type
-  out
+#' @importFrom stats anova
+.anova_es.default <- function(model, ...) {
+  .anova_es.anova(stats::anova(model), ...)
 }
 
 #' @keywords internal
@@ -852,7 +776,7 @@ cohens_f_squared <- function(model,
   df.nm <- c(""NumDF"", ""num Df"", ""numDF"", ""npar"", ""Df"")
   df_error.nm <- c(""DenDF"", ""den Df"", ""denDF"", ""df_error"", ""Df.res"")
 
-  # If there is no df_error *or* is there IS a residuals row...
+  # If there is no df_error *or* if there IS a residuals row...
   if (!any(df_error.nm %in% colnames(model))) {
     # Pass to AOV method
     res <- .anova_es.aov(model,
@@ -868,7 +792,10 @@ cohens_f_squared <- function(model,
   }
 
   if (!any(F.nm %in% colnames(model)) || !any(df.nm %in% colnames(model))) {
-    insight::format_error(""ANOVA table does not have F values or degrees of freedom - cannot compute effect size."")
+    insight::format_error(
+      ""ANOVA table does not have F values or degrees of freedom,"",
+      ""cannot compute effect size.""
+    )
   }
 
   Fi <- F.nm[F.nm %in% colnames(model)]
@@ -884,7 +811,8 @@ cohens_f_squared <- function(model,
     Parameter = rownames(model),
     F = model[, Fi],
     df = model[, dfi],
-    df_error = model[, df_errori]
+    df_error = model[, df_errori],
+    stringsAsFactors = FALSE
   )
   par_table <- par_table[!par_table[[""Parameter""]] %in% ""Residuals"", ]
 
@@ -907,7 +835,80 @@ cohens_f_squared <- function(model,
   out
 }
 
+#' @keywords internal
+#' @importFrom parameters model_parameters
+#' @importFrom stats anova
+.anova_es.aov <- function(model,
+                          type = c(""eta"", ""omega"", ""epsilon""),
+                          partial = TRUE,
+                          generalized = FALSE,
+                          ci = 0.95, alternative = ""greater"",
+                          verbose = TRUE,
+                          ...) {
+  # if (!inherits(model, c(""Gam"", ""anova""))) {
+  #   # Pass to ANOVA table method
+  #   res <- .anova_es.anova(
+  #     stats::anova(model),
+  #     type = type,
+  #     partial = partial,
+  #     generalized = generalized,
+  #     ci = ci, alternative = alternative,
+  #     verbose = verbose,
+  #     ...
+  #   )
+  #   return(res)
+  # }
+
+  # TODO this should be in .anova_es.anvoa
+  # TODO the aoc method should convert to an anova table, then pass to anova
+  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"")
+  out <- .es_aov_simple(as.data.frame(params),
+    type = type,
+    partial = partial, generalized = generalized,
+    ci = ci, alternative = alternative, verbose = verbose, ...
+  )
+  if (is.null(attr(out, ""anova_type""))) attr(out, ""anova_type"") <- attr(params, ""anova_type"")
+  out
+}
 
+#' @keywords internal
+.anova_es.lm <- function(model, ...) {
+  .anova_es.aov(stats::aov(model), ...)
+}
+
+.anova_es.glm <- .anova_es.lm
+
+#' @keywords internal
+#' @importFrom parameters model_parameters
+#' @importFrom insight find_predictors
+.anova_es.aovlist <- function(model,
+                              type = c(""eta"", ""omega"", ""epsilon""),
+                              partial = TRUE,
+                              generalized = FALSE,
+                              ci = 0.95, alternative = ""greater"",
+                              verbose = TRUE,
+                              include_intercept = FALSE,
+                              ...) {
+  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"")
+  anova_type <- attr(params, ""anova_type"")
+  params <- as.data.frame(params)
+
+  DV_names <- insight::find_predictors(model)[[1]]
+
+  out <-
+    .es_aov_strata(
+      params,
+      DV_names = DV_names,
+      type = type,
+      partial = partial,
+      generalized = generalized,
+      ci = ci, alternative = alternative,
+      verbose = verbose,
+      include_intercept = include_intercept
+    )
+  attr(out, ""anova_type"") <- anova_type
+  out
+}
 
 
 # Utils -------------------------------------------------------------------

---FILE: R/eta_squared-methods.R---
@@ -1,138 +1,62 @@
-# Specific models ---------------------------------------------------------
+# Specific tables ---------------------------------------------------------
 
 #' @keywords internal
-.anova_es.mlm <- function(model,
-                          type = c(""eta"", ""omega"", ""epsilon""),
-                          partial = TRUE,
-                          generalized = FALSE,
-                          ci = 0.95, alternative = ""greater"",
-                          verbose = TRUE,
-                          ...) {
-  model <- stats::aov(model)
-  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"")
-  anova_type <- attr(params, ""anova_type"")
-
-  params <- split(params, factor(params$Response, levels = unique(params$Response))) # make sure row order is not changed
-  params <- lapply(params, .es_aov_simple,
-    type = type,
-    partial = partial,
-    generalized = generalized,
-    ci = ci, alternative = alternative,
-    verbose = verbose,
-    ...
-  )
-
-  params <- lapply(names(params), function(nm) {
-    cbind(Response = nm, params[[nm]])
-  })
-  out <- do.call(""rbind"", params)
-  rownames(out) <- NULL
-  out$Response <- as.character(out$Response)
-
-  attr(out, ""generalized"") <- attr(params[[1]], ""generalized"")
-  attr(out, ""ci"") <- attr(params[[1]], ""ci"", exact = TRUE)
-  attr(out, ""anova_type"") <- anova_type
-  attr(out, ""approximate"") <- FALSE
-  attr(out, ""alternative"") <- if (is.numeric(attr(out, ""ci""))) alternative
-  out
-}
-
-.anova_es.maov <- .anova_es.mlm
-
-
-
-#' @keywords internal
-.anova_es.anova.lme <- .anova_es.anova
+.anova_es.afex_aov <- function(model,
+                               type = c(""eta"", ""omega"", ""epsilon""),
+                               partial = TRUE,
+                               generalized = FALSE,
+                               ci = 0.95, alternative = ""greater"",
+                               verbose = TRUE,
+                               include_intercept = FALSE,
+                               ...) {
+  type <- match.arg(type)
+  if (type == ""eta"" && isTRUE(generalized) && length(attr(model$anova_table, ""observed""))) {
+    generalized <- attr(model$anova_table, ""observed"")
+  }
 
-#' @keywords internal
-.anova_es.parameters_model <- function(model,
-                                       type = c(""eta"", ""omega"", ""epsilon""),
-                                       partial = TRUE,
-                                       generalized = FALSE,
-                                       ci = 0.95, alternative = ""greater"",
-                                       verbose = TRUE,
-                                       by_response = TRUE,
-                                       ...) {
-  if (by_response && ""Response"" %in% colnames(model)) {
-    out <- split(model, model[[""Response""]])
-    out <- lapply(out, .anova_es.parameters_model,
-      type = type, partial = partial, generalized = generalized,
+  out <-
+    .anova_es(
+      model$Anova,
+      type = type,
+      partial = partial,
+      generalized = generalized,
       ci = ci, alternative = alternative,
-      verbose = verbose,
-      by_response = FALSE,
+      verbose = FALSE,
+      include_intercept = include_intercept,
       ...
     )
-    saved_attr <- attributes(out[[1]])
-    out <- Map(function(x, nm) cbind(Response = nm, x), out, names(out))
-    out <- do.call(rbind, out)
-    out$Parameter <- as.character(out$Parameter)
-
-    # Set attributes ---
-    attr(out, ""generalized"") <- saved_attr$generalized
-    attr(out, ""ci"") <- saved_attr$ci
-    attr(out, ""alternative"") <- saved_attr$alternative
-    attr(out, ""anova_type"") <- attr(model, ""anova_type"")
-    attr(out, ""approximate"") <- saved_attr$approximate
-    return(out)
-  }
-
 
-  approximate <- FALSE
-  if (""Sum_Squares"" %in% colnames(model) && ""Residuals"" %in% model[[""Parameter""]]) {
-    if (""Group"" %in% colnames(model)) {
-      DVs <- unlist(insight::find_predictors(.get_object_from_params(model)))
-      out <- .es_aov_strata(
-        model,
-        DV_names = DVs,
-        type = type, partial = partial, generalized = generalized,
-        ci = ci, alternative = alternative,
-        verbose = verbose, ...
-      )
-    } else {
-      out <- .es_aov_simple(
-        model,
-        type = type, partial = partial, generalized = generalized,
-        ci = ci, alternative = alternative,
-        verbose = verbose, ...
-      )
-    }
-  } else {
-    out <- .es_aov_table(
-      model,
-      type = type, partial = partial, generalized = generalized,
-      ci = ci, alternative = alternative,
-      verbose = verbose, ...
-    )
-    approximate <- TRUE
-  }
-  attr(out, ""anova_type"") <- attr(model, ""anova_type"")
-  attr(out, ""approximate"") <- approximate
+  attr(out, ""anova_type"") <- attr(model, ""type"", exact = TRUE)
+  attr(out, ""approximate"") <- FALSE
   out
 }
 
 #' @keywords internal
-.anova_es.htest <- function(model,
-                            type = c(""eta"", ""omega"", ""epsilon""),
-                            partial = TRUE,
-                            generalized = FALSE,
-                            ci = 0.95, alternative = ""greater"",
+.anova_es.mixed <- function(model,
                             verbose = TRUE,
+                            include_intercept = FALSE,
                             ...) {
-  if (!grepl(""One-way"", model$method, fixed = TRUE)) {
-    insight::format_error(""'model' is not a one-way test!"")
+  aov_tab <- as.data.frame(model[[""anova_table""]])
+
+  if (!""F"" %in% colnames(aov_tab)) {
+    insight::format_error(""Cannot estimate approx effect size for `mixed` type model - no F-statistic found."")
   }
 
-  if (verbose && (partial || isTRUE(generalized) || is.character(generalized))) {
-    txt_type <- ifelse(isTRUE(generalized) || is.character(generalized), ""generalized"", ""partial"")
-    insight::format_alert(
-      sprintf(
-        ""For one-way between subjects designs, %s %s squared is equivalent to %s squared. Returning %s squared."",
-        txt_type, type, type, type
-      )
-    )
+  if (verbose && include_intercept && !""(Intercept)"" %in% rownames(aov_tab)) {
+    insight::format_warning(""Cannot estimate (Intercept) effect size for `mixed` model."")
+    include_intercept <- FALSE
   }
 
-  effectsize(model, type = type, ci = ci, alternative = alternative, verbose = verbose, ...)
+  aov_tab$Parameter <- rownames(aov_tab)
+  aov_tab$df <- aov_tab[[""num Df""]]
+  aov_tab$df_error <- aov_tab[[""den Df""]]
+  aov_tab <- aov_tab[, c(""Parameter"", ""df"", ""df_error"", ""F"")]
+
+  out <- .es_aov_table(aov_tab, verbose = verbose, include_intercept = include_intercept, ...)
+
+  attr(out, ""anova_type"") <- attr(model, ""type"")
+  attr(out, ""approximate"") <- TRUE
+  out
 }
 
 #' @keywords internal
@@ -145,12 +69,15 @@
            verbose = TRUE,
            include_intercept = FALSE,
            ...) {
-    # Faking the model_parameters.aovlist output:
-    suppressWarnings(aov_tab <- summary(model)$univariate.tests) # nolint
+    suppressWarnings(aov_tab <- summary(model)$univariate.tests)
+
+    # if there are univariate.tests, will return a global effect size
     if (is.null(aov_tab)) {
+      # TODO this should be the method for manova,
+      # so this should be copied there, and here happsed to:
+      # .anova_es.manova
       aov_tab <- parameters::model_parameters(model)
       aov_tab$df <- aov_tab$df_num
-      aov_tab$df_num <- NULL
       out <- .anova_es(aov_tab,
         type = type,
         partial = partial, generalized = generalized,
@@ -162,6 +89,8 @@
       attr(out, ""approximate"") <- FALSE
       return(out)
     }
+
+    # Faking the model_parameters.aovlist output:
     aov_tab <- as.data.frame(unclass(aov_tab))
     aov_tab$Parameter <- rownames(aov_tab)
     colnames(aov_tab)[colnames(aov_tab) == ""Sum Sq""] <- ""Sum_Squares""
@@ -172,8 +101,8 @@
     within <- names(model$idata)
     within <- lapply(within, function(x) c(NA, x))
     within <- do.call(expand.grid, within)
-    within <- apply(within, 1, stats::na.omit)
-    ns <- sapply(within, length) # nolint
+    within <- apply(within, 1, na.omit)
+    ns <- sapply(within, length)
     within <- sapply(within, paste, collapse = "":"")
     within <- within[order(ns)]
     within <- Filter(function(x) nchar(x) > 0, within)
@@ -197,7 +126,7 @@
     aov_tab$`F` <- ifelse(aov_tab$Parameter == ""Residuals"", NA, 1)
     aov_tab$Mean_Square <- aov_tab$Sum_Squares / aov_tab$df
 
-    DV_names <- c(id, setdiff(unlist(strsplit(model$terms, "":"", fixed = TRUE)), ""(Intercept)""))
+    DV_names <- c(id, setdiff(unlist(strsplit(model$terms, "":"")), ""(Intercept)""))
 
     out <-
       .es_aov_strata(
@@ -226,6 +155,158 @@
     out
   }
 
+#' @keywords internal
+.anova_es.manova <- function(model, ...) {
+  pars <- parameters::model_parameters(model)
+  pars$df <- pars$df_num
+  pars <- pars[pars$Parameter != ""Residuals"", ]
+  out <- .anova_es(pars, ...)
+  attr(out, ""anova_type"") <- attr(pars, ""anova_type"")
+  attr(out, ""approximate"") <- TRUE
+  return(out)
+}
+
+
+#' @keywords internal
+.anova_es.anova.lme <- .anova_es.anova
+
+#' @importFrom stats na.omit
+#' @keywords internal
+.anova_es.parameters_model <- function(model,
+                                       type = c(""eta"", ""omega"", ""epsilon""),
+                                       partial = TRUE,
+                                       generalized = FALSE,
+                                       ci = 0.95, alternative = ""greater"",
+                                       verbose = TRUE,
+                                       by_response = TRUE,
+                                       ...) {
+  if (by_response && ""Response"" %in% colnames(model)) {
+    out <- split(model, model[[""Response""]])
+    out <- lapply(out, .anova_es.parameters_model,
+      type = type, partial = partial, generalized = generalized,
+      ci = ci, alternative = alternative,
+      verbose = verbose,
+      by_response = FALSE,
+      ...
+    )
+    saved_attr <- attributes(out[[1]])
+    out <- Map(function(x, nm) cbind(Response = nm, x), out, names(out))
+    out <- do.call(rbind, out)
+    out$Parameter <- as.character(out$Parameter)
+
+    # Set attributes ---
+    attr(out, ""generalized"") <- saved_attr$generalized
+    attr(out, ""ci"") <- saved_attr$ci
+    attr(out, ""alternative"") <- saved_attr$alternative
+    attr(out, ""anova_type"") <- attr(model, ""anova_type"")
+    attr(out, ""approximate"") <- saved_attr$approximate
+    return(out)
+  }
+
+
+  approximate <- FALSE
+  if (""Sum_Squares"" %in% colnames(model) && ""Residuals"" %in% model[[""Parameter""]]) {
+    if (""Group"" %in% colnames(model)) {
+      DVs <- unlist(insight::find_predictors(.get_object_from_params(model)))
+      out <- .es_aov_strata(
+        model,
+        DV_names = DVs,
+        type = type, partial = partial, generalized = generalized,
+        ci = ci, alternative = alternative,
+        verbose = verbose, ...
+      )
+    } else {
+      out <- .es_aov_simple(
+        model,
+        type = type, partial = partial, generalized = generalized,
+        ci = ci, alternative = alternative,
+        verbose = verbose, ...
+      )
+    }
+  } else {
+    out <- .es_aov_table(
+      model,
+      type = type, partial = partial, generalized = generalized,
+      ci = ci, alternative = alternative,
+      verbose = verbose, ...
+    )
+    approximate <- TRUE
+  }
+  attr(out, ""anova_type"") <- attr(model, ""anova_type"")
+  attr(out, ""approximate"") <- approximate
+  out
+}
+
+# Specific models ---------------------------------------------------------
+
+#' @keywords internal
+#' @importFrom stats aov
+#' @importFrom utils packageVersion
+.anova_es.maov <- function(model,
+                           type = c(""eta"", ""omega"", ""epsilon""),
+                           partial = TRUE,
+                           generalized = FALSE,
+                           ci = 0.95, alternative = ""greater"",
+                           verbose = TRUE,
+                           ...) {
+  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"")
+  anova_type <- attr(params, ""anova_type"")
+
+  params <- split(params, factor(params$Response, levels = unique(params$Response))) # make sure row order is not changed
+  params <- lapply(params, .es_aov_simple,
+    type = type,
+    partial = partial,
+    generalized = generalized,
+    ci = ci, alternative = alternative,
+    verbose = verbose,
+    ...
+  )
+
+  params <- lapply(names(params), function(nm) {
+    cbind(Response = nm, params[[nm]])
+  })
+  out <- do.call(""rbind"", params)
+  rownames(out) <- NULL
+  out$Response <- as.character(out$Response)
+
+  attr(out, ""generalized"") <- attr(params[[1]], ""generalized"")
+  attr(out, ""ci"") <- attr(params[[1]], ""ci"", exact = TRUE)
+  attr(out, ""anova_type"") <- anova_type
+  attr(out, ""approximate"") <- FALSE
+  attr(out, ""alternative"") <- if (is.numeric(attr(out, ""ci""))) alternative
+  out
+}
+
+#' @keywords internal
+.anova_es.mlm <- function(model, ...) {
+  .anova_es.maov(stats::aov(model), ...)
+}
+
+
+#' @keywords internal
+.anova_es.htest <- function(model,
+                            type = c(""eta"", ""omega"", ""epsilon""),
+                            partial = TRUE,
+                            generalized = FALSE,
+                            ci = 0.95, alternative = ""greater"",
+                            verbose = TRUE,
+                            ...) {
+  if (!grepl(""One-way"", model$method, fixed = TRUE)) {
+    insight::format_error(""'model' is not a one-way test!"")
+  }
+
+  if (verbose && (partial || isTRUE(generalized) || is.character(generalized))) {
+    txt_type <- ifelse(isTRUE(generalized) || is.character(generalized), ""generalized"", ""partial"")
+    insight::format_alert(
+      sprintf(
+        ""For one-way between subjects designs, %s %s squared is equivalent to %s squared. Returning %s squared."",
+        txt_type, type, type, type
+      )
+    )
+  }
+
+  effectsize(model, type = type, ci = ci, alternative = alternative, verbose = verbose, ...)
+}
 
 #' @keywords internal
 .anova_es.merMod <- function(model,
@@ -265,7 +346,6 @@
 
   p.table <- as.data.frame(model$pTerms.table)
   s.table <- as.data.frame(model$s.table)
-  colnames(s.table)[colnames(s.table) == ""Ref.df""] <- ""df""
   s.table[setdiff(colnames(p.table), colnames(s.table))] <- NA
   p.table[setdiff(colnames(s.table), colnames(p.table))] <- NA
   tab <- rbind(p.table, s.table)
@@ -288,64 +368,6 @@
   out
 }
 
-#' @keywords internal
-.anova_es.afex_aov <- function(model,
-                               type = c(""eta"", ""omega"", ""epsilon""),
-                               partial = TRUE,
-                               generalized = FALSE,
-                               ci = 0.95, alternative = ""greater"",
-                               verbose = TRUE,
-                               include_intercept = FALSE,
-                               ...) {
-  type <- match.arg(type)
-  if (type == ""eta"" && isTRUE(generalized) && length(attr(model$anova_table, ""observed""))) {
-    generalized <- attr(model$anova_table, ""observed"")
-  }
-
-  out <-
-    .anova_es(
-      model$Anova,
-      type = type,
-      partial = partial,
-      generalized = generalized,
-      ci = ci, alternative = alternative,
-      verbose = FALSE,
-      include_intercept = include_intercept,
-      ...
-    )
-
-  attr(out, ""anova_type"") <- attr(model, ""type"", exact = TRUE)
-  attr(out, ""approximate"") <- FALSE
-  out
-}
-
-#' @keywords internal
-.anova_es.mixed <- function(model,
-                            verbose = TRUE,
-                            include_intercept = FALSE,
-                            ...) {
-  aov_tab <- as.data.frame(model[[""anova_table""]])
-
-  if (!""F"" %in% colnames(aov_tab)) {
-    insight::format_error(""Cannot estimate approx effect size for `mixed` type model - no F-statistic found."")
-  }
-
-  if (verbose && include_intercept) {
-    insight::format_warning(""Cannot estimate (Intercept) effect size for `mixed` model."")
-  }
-
-  aov_tab$Parameter <- rownames(aov_tab)
-  aov_tab$df <- aov_tab[[""num Df""]]
-  aov_tab$df_error <- aov_tab[[""den Df""]]
-  aov_tab <- aov_tab[, c(""Parameter"", ""df"", ""df_error"", ""F"")]
-
-  out <- .es_aov_table(aov_tab, verbose = verbose, ...)
-
-  attr(out, ""anova_type"") <- attr(model, ""type"")
-  attr(out, ""approximate"") <- TRUE
-  out
-}
-
 
 #' @keywords internal
 .anova_es.rms <- function(model,
@@ -384,22 +406,8 @@
 
 
 #' @export
-.anova_es.model_fit <- function(model,
-                                type = c(""eta"", ""omega"", ""epsilon""),
-                                partial = TRUE,
-                                generalized = FALSE,
-                                ci = 0.95, alternative = ""greater"",
-                                verbose = TRUE,
-                                ...) {
-  .anova_es(
-    model$fit,
-    type = type,
-    partial = partial,
-    generalized = generalized,
-    ci = ci, alternative = alternative,
-    verbose = verbose,
-    ...
-  )
+.anova_es.model_fit <- function(model, ...) {
+  .anova_es(model$fit, ...)
 }
 
 

---FILE: tests/testthat/test-eta_squared.R---
@@ -512,6 +512,23 @@ test_that(""afex | mixed()"", {
     eta_squared(t15.4a),
     eta_squared(t15.4a$full_model)
   )
+
+  # Intercept
+  data(""stroop"", package = ""afex"")
+  stroop <- subset(stroop, study == 1 & acc == 1 & trialnum < 20)
+  suppressMessages(m1 <- afex::mixed(rt ~ condition + (condition | pno), data = stroop, method = ""KR""))
+  suppressMessages(m2 <- afex::mixed(rt ~ condition + (condition | pno), data = stroop, test_intercept = TRUE, method = ""KR""))
+
+  expect_warning(a1a <- eta_squared(m1, include_intercept = TRUE), regexp = ""Intercept"")
+  expect_warning(a1b <- eta_squared(m1, include_intercept = FALSE), regexp = NA)
+  expect_equal(a1a, a1b)
+  expect_equal(nrow(a1a), 1L)
+
+  expect_warning(a2a <- eta_squared(m2, include_intercept = TRUE), regexp = NA)
+  expect_warning(a2b <- eta_squared(m2, include_intercept = FALSE), regexp = NA)
+  expect_equal(nrow(a2a), 2L)
+  expect_equal(nrow(a2b), 1L)
+  expect_equal(a1a, a2a[2, ], ignore_attr = TRUE)
 })
 
 
@@ -529,27 +546,12 @@ test_that(""car MVM"", {
     id = 1:8
   )
 
-  ds_long <- data.frame(
-    id = c(
-      1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
-      1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
-      1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
-      1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L
-    ),
-    ind_var = c(
-      ""I"", ""I"", ""I"", ""I"", ""I"", ""I"", ""I"", ""I"",
-      ""II"", ""II"", ""II"", ""II"", ""II"", ""II"", ""II"", ""II"",
-      ""III"", ""III"", ""III"", ""III"", ""III"", ""III"", ""III"", ""III"",
-      ""IV"", ""IV"", ""IV"", ""IV"", ""IV"", ""IV"", ""IV"", ""IV""
-    ),
-    score = c(
-      116, 96, 120, 110, 116, 126, 86, 80,
-      76, 93, 112, 113, 75, 120, 90, 105,
-      85, 63, 89, 60, 115, 101, 129, 67,
-      50, 87, 100, 60, 79, 70, 65, 65
+  ds_long <-
+    datawizard::reshape_longer(ds,
+      select = 1:4,
+      names_to = ""ind_var"",
+      values_to = ""score""
     )
-  )
-
 
 
   fit <- lm(cbind(I, II, III, IV) ~ 1, data = ds)
@@ -584,19 +586,32 @@ test_that(""Anova.mlm Manova"", {
   skip_if_not_installed(""car"")
 
   data(""mtcars"")
+  mtcars <- mtcars[c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 18L, 29L, 31L), ]
   mtcars$am_f <- factor(mtcars$am)
   mtcars$cyl_f <- factor(mtcars$cyl)
 
-  mod <- lm(cbind(mpg, qsec) ~ am_f * cyl_f, data = mtcars)
+  mod <- lm(cbind(mpg, qsec, disp) ~ am_f * cyl_f, data = mtcars)
 
-  Manova <- car::Manova(mod)
+  Manova <- car::Manova(mod, type = 2)
 
   expect_true(is.null(summary(Manova, univariate = TRUE)[[""univariate.tests""]]))
   expect_error(eta_squared(Manova), regexp = NA)
   expect_equal(
     eta_squared(manova(mod))[[2]][2:3],
     eta_squared(Manova)[[2]][2:3]
   )
+
+  Anova <- car::Anova(mod, idesign = ~g, idata = data.frame(g = factor(1:3)))
+  mtcars$id <- factor(seq(nrow(mtcars)))
+  mtcars_long <- datawizard::reshape_longer(mtcars,
+    select = c(""mpg"", ""qsec"", ""disp""), names_to = ""g""
+  )
+  a1 <- aov(value ~ am_f * cyl_f * g + Error(id / g), data = mtcars_long)
+
+  A1 <- eta_squared(Anova)
+  A2 <- eta_squared(a1)
+  expect_equal(A1$Parameter, A2$Parameter)
+  expect_equal(A1[c(2:4, 6:7), ], A2[c(2:4, 6:7), -1], ignore_attr = TRUE)
 })
 
 ## merMod --------------------",True,False,Documentation / Formatting,6
easystats,effectsize,eaaeb90580cb7a4e5b4ab44e5c25f70c3f164a97,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2023-04-24T02:48:16Z,GitHub,noreply@github.com,2023-04-24T02:48:16Z,"Clean chisq (#590)

* init

* Update DESCRIPTION

* fix CI errors",DESCRIPTION;NAMESPACE;NEWS.md;R/convert_between_xtabcorr.R;R/convert_stat_chisq.R;man/d_to_r.Rd;man/diff_to_cles.Rd;man/eta2_to_f2.Rd;man/odds_to_probs.Rd;man/oddsratio_to_riskratio.Rd;man/w_to_fei.Rd,False,True,True,False,131,47,178,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size
-Version: 0.8.3.10
+Version: 0.8.3.11
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",
@@ -89,6 +89,7 @@ Suggests:
     lmerTest,
     mgcv,
     parsnip,
+    pwr,
     rmarkdown,
     rms,
     rstanarm,

---FILE: NAMESPACE---
@@ -67,6 +67,7 @@ export(arr_to_logoddsratio)
 export(arr_to_nnt)
 export(arr_to_oddsratio)
 export(arr_to_riskratio)
+export(c_to_w)
 export(chisq_to_cohens_w)
 export(chisq_to_cramers_v)
 export(chisq_to_fei)
@@ -230,10 +231,15 @@ export(t_to_f2)
 export(t_to_omega2)
 export(t_to_r)
 export(t_to_v)
+export(t_to_w)
 export(tschuprows_t)
 export(v_to_t)
+export(v_to_w)
 export(vd_a)
+export(w_to_c)
 export(w_to_fei)
+export(w_to_t)
+export(w_to_v)
 export(wmw_odds)
 export(z_to_d)
 export(z_to_r)

---FILE: NEWS.md---
@@ -3,7 +3,7 @@
 ## New features
 
 - `tschuprows_t()` now returns an effect size corrected for small-sample bias. Set `adjust = FALSE` to preserve old behavior.
-- `v_to_t()` and `w_to_fei()` and their inverses for converting between effect sizes of Chi-square tests.
+- `w_to_v()` and others for converting between effect sizes of Chi-square tests.
 - `arr()` and `nnt()` for Absolute Risk Reduction or Number Needed to Treat.
 - `oddsratio_to_arr()`, `riskratio_to_arr()`, `nnt_to_arr()` and their inverses.
 - `logoddsratio_to_*()` and `*_to_logoddsratio()` have been added as convenient shortcuts for `oddsratio_to_*(log = TRUE)` and `*_to_oddsratio(log = TRUE)`.

---FILE: R/convert_between_xtabcorr.R---
@@ -4,7 +4,7 @@
 #' Cohen's *w* to \ifelse{latex}{\eqn{Fei}}{×¤ (Fei)}, and Cramer's *V* to
 #' Tschuprow's *T*.
 #'
-#' @param v,t,w,fei Effect size to be converted
+#' @param w,c,v,t,fei Effect size to be converted
 #' @inheritParams chisq_to_tschuprows_t
 #' @inheritParams fei
 #'
@@ -38,36 +38,86 @@
 #'
 #' fei(Smoking_FASD, p = c(0.015, 0.010, 0.975))
 #'
+#' @examplesIf require(pwr)
+#' ## Power analysis
+#' ## --------------
+#' # See https://osf.io/cg64s/
+#'
+#' p0 <- c(0.35, 0.65)
+#' Fei <- 0.3
+#'
+#' pwr::pwr.chisq.test(
+#'   w = fei_to_w(Fei, p = p0),
+#'   df = length(p0) - 1,
+#'   sig.level = 0.01,
+#'   power = 0.85
+#' )
+#'
 #' @references
 #' - Ben-Shachar, M.S., Patil, I., ThÃ©riault, R., Wiernik, B.M., LÃ¼decke, D.
 #' (2023). Phi, Fei, Fo, Fum: Effect Sizes for Categorical Data That Use the
 #' ChiâSquared Statistic. Mathematics, 11, 1982. \doi{10.3390/math11091982}
+#' - Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
 #'
 #' @export
-v_to_t <- function(v, nrow, ncol) {
-  f_v <- sqrt(pmin(nrow - 1, ncol - 1))
-  f_t <- sqrt(sqrt((nrow - 1) * (ncol - 1)))
-  v * f_v / f_t
+w_to_fei <- function(w, p) {
+  w / sqrt(1 / min(p) - 1)
 }
 
 #' @export
-#' @rdname v_to_t
-t_to_v <- function(t, nrow, ncol) {
-  f_v <- sqrt(pmin(nrow - 1, ncol - 1))
-  f_t <- sqrt(sqrt((nrow - 1) * (ncol - 1)))
-  t * f_t / f_v
+#' @rdname w_to_fei
+w_to_v <- function(w, nrow, ncol) {
+  w / sqrt(pmin(nrow - 1, ncol - 1))
 }
 
 #' @export
-#' @rdname v_to_t
+#' @rdname w_to_fei
+w_to_t <- function(w, nrow, ncol) {
+  w / sqrt(sqrt((nrow - 1) * (ncol - 1)))
+}
+
+#' @export
+#' @rdname w_to_fei
+w_to_c <- function(w) {
+  w / sqrt(w^2 + 1)
+}
+
+## To w -----------------------
+
+#' @export
+#' @rdname w_to_fei
 fei_to_w <- function(fei, p) {
-  f <- sqrt(1 / min(p) - 1)
-  fei * f
+  fei * sqrt(1 / min(p) - 1)
 }
 
 #' @export
-#' @rdname v_to_t
-w_to_fei <- function(w, p) {
-  f <- sqrt(1 / min(p) - 1)
-  w / f
+#' @rdname w_to_fei
+v_to_w <- function(v, nrow, ncol) {
+  v * sqrt(pmin(nrow - 1, ncol - 1))
+}
+
+#' @export
+#' @rdname w_to_fei
+t_to_w <- function(t, nrow, ncol) {
+  t * sqrt(sqrt((nrow - 1) * (ncol - 1)))
+}
+
+#' @export
+#' @rdname w_to_fei
+c_to_w <- function(c) {
+  c / sqrt(1 - c^2)
+}
+
+## Other ----------------------
+
+#' @export
+#' @rdname w_to_fei
+v_to_t <- function(v, nrow, ncol) {
+  w_to_t(v_to_w(v, nrow, ncol), nrow, ncol)
+}
+
+#' @export
+#' @rdname w_to_fei
+t_to_v <- function(t, nrow, ncol) {
+  w_to_v(t_to_w(t, nrow, ncol), nrow, ncol)
 }

---FILE: R/convert_stat_chisq.R---
@@ -189,10 +189,8 @@ chisq_to_cramers_v <- function(chisq, n, nrow, ncol,
 
   # Convert
   kl <- .possibly_adjust_k_and_l(nrow, ncol, n, adjust = adjust)
-  div <- sqrt((pmin(kl[[""k""]], kl[[""l""]]) - 1))
-
-  res[grepl(""^(phi|CI_)"", colnames(res))] <-
-    lapply(res[grepl(""^(phi|CI_)"", colnames(res))], ""/"", y = div)
+  to_convert <- grepl(""^(phi|CI_)"", colnames(res))
+  res[to_convert] <- lapply(res[to_convert], w_to_v, nrow = kl[[""k""]], ncol = kl[[""l""]])
   colnames(res)[1] <- gsub(""phi"", ""Cramers_v"", colnames(res)[1], fixed = TRUE)
 
   if (""CI"" %in% colnames(res)) {
@@ -223,10 +221,8 @@ chisq_to_tschuprows_t <- function(chisq, n, nrow, ncol,
 
   # Convert
   kl <- .possibly_adjust_k_and_l(nrow, ncol, n, adjust = adjust)
-  div <- sqrt(sqrt((kl[[""k""]] - 1) * (kl[[""l""]] - 1)))
-
-  res[grepl(""^(phi|CI_)"", colnames(res))] <-
-    lapply(res[grepl(""^(phi|CI_)"", colnames(res))], ""/"", y = div)
+  to_convert <- grepl(""^(phi|CI_)"", colnames(res))
+  res[to_convert] <- lapply(res[to_convert], w_to_t, nrow = kl[[""k""]], ncol = kl[[""l""]])
   colnames(res)[1] <- gsub(""phi"", ""Tschuprows_t"", colnames(res)[1], fixed = TRUE)
 
   if (""CI"" %in% colnames(res)) {
@@ -263,11 +259,8 @@ chisq_to_fei <- function(chisq, n, nrow, ncol, p,
 
   # Convert
   p <- p / sum(p)
-  q <- min(p)
-  div <- sqrt((1 / q) - 1)
-
-  res[grepl(""^(phi|CI_)"", colnames(res))] <-
-    lapply(res[grepl(""^(phi|CI_)"", colnames(res))], ""/"", y = div)
+  to_convert <- grepl(""^(phi|CI_)"", colnames(res))
+  res[to_convert] <- lapply(res[to_convert], w_to_fei, p = p)
   colnames(res)[1] <- ""Fei""
 
   if (""CI"" %in% colnames(res)) {
@@ -297,7 +290,7 @@ chisq_to_pearsons_c <- function(chisq, n, nrow, ncol,
   )
 
   to_convert <- grepl(""^(phi|CI_)"", colnames(res))
-  res[to_convert] <- lapply(res[to_convert], function(phi) sqrt(1 / (1 / phi^2 + 1)))
+  res[to_convert] <- lapply(res[to_convert], w_to_c)
   colnames(res)[1] <- ""Pearsons_c""
 
   if (""CI"" %in% colnames(res)) {

---FILE: man/d_to_r.Rd---
@@ -101,6 +101,6 @@ Other convert between effect sizes:
 \code{\link{eta2_to_f2}()},
 \code{\link{odds_to_probs}()},
 \code{\link{oddsratio_to_riskratio}()},
-\code{\link{v_to_t}()}
+\code{\link{w_to_fei}()}
 }
 \concept{convert between effect sizes}

---FILE: man/diff_to_cles.Rd---
@@ -86,6 +86,6 @@ Other convert between effect sizes:
 \code{\link{eta2_to_f2}()},
 \code{\link{odds_to_probs}()},
 \code{\link{oddsratio_to_riskratio}()},
-\code{\link{v_to_t}()}
+\code{\link{w_to_fei}()}
 }
 \concept{convert between effect sizes}

---FILE: man/eta2_to_f2.Rd---
@@ -54,6 +54,6 @@ Other convert between effect sizes:
 \code{\link{diff_to_cles}},
 \code{\link{odds_to_probs}()},
 \code{\link{oddsratio_to_riskratio}()},
-\code{\link{v_to_t}()}
+\code{\link{w_to_fei}()}
 }
 \concept{convert between effect sizes}

---FILE: man/odds_to_probs.Rd---
@@ -51,6 +51,6 @@ Other convert between effect sizes:
 \code{\link{diff_to_cles}},
 \code{\link{eta2_to_f2}()},
 \code{\link{oddsratio_to_riskratio}()},
-\code{\link{v_to_t}()}
+\code{\link{w_to_fei}()}
 }
 \concept{convert between effect sizes}

---FILE: man/oddsratio_to_riskratio.Rd---
@@ -124,6 +124,6 @@ Other convert between effect sizes:
 \code{\link{diff_to_cles}},
 \code{\link{eta2_to_f2}()},
 \code{\link{odds_to_probs}()},
-\code{\link{v_to_t}()}
+\code{\link{w_to_fei}()}
 }
 \concept{convert between effect sizes}

---FILE: man/w_to_fei.Rd---
@@ -1,26 +1,44 @@
 % Generated by roxygen2: do not edit by hand
 % Please edit documentation in R/convert_between_xtabcorr.R
-\name{v_to_t}
+\name{w_to_fei}
+\alias{w_to_fei}
+\alias{w_to_v}
+\alias{w_to_t}
+\alias{w_to_c}
+\alias{fei_to_w}
+\alias{v_to_w}
+\alias{t_to_w}
+\alias{c_to_w}
 \alias{v_to_t}
 \alias{t_to_v}
-\alias{fei_to_w}
-\alias{w_to_fei}
 \title{Convert Between \emph{d}, \emph{r}, and Odds Ratio}
 \usage{
-v_to_t(v, nrow, ncol)
+w_to_fei(w, p)
 
-t_to_v(t, nrow, ncol)
+w_to_v(w, nrow, ncol)
+
+w_to_t(w, nrow, ncol)
+
+w_to_c(w)
 
 fei_to_w(fei, p)
 
-w_to_fei(w, p)
+v_to_w(v, nrow, ncol)
+
+t_to_w(t, nrow, ncol)
+
+c_to_w(c)
+
+v_to_t(v, nrow, ncol)
+
+t_to_v(t, nrow, ncol)
 }
 \arguments{
-\item{v, t, w, fei}{Effect size to be converted}
-
-\item{nrow, ncol}{The number of rows/columns in the contingency table.}
+\item{w, c, v, t, fei}{Effect size to be converted}
 
 \item{p}{Vector of expected values. See \code{\link[stats:chisq.test]{stats::chisq.test()}}.}
+
+\item{nrow, ncol}{The number of rows/columns in the contingency table.}
 }
 \description{
 Enables a conversion between different indices of effect size, such as
@@ -54,12 +72,28 @@ w_to_fei(0.11, p = c(0.015, 0.010, 0.975))
 
 fei(Smoking_FASD, p = c(0.015, 0.010, 0.975))
 
+\dontshow{if (require(pwr)) (if (getRversion() >= ""3.4"") withAutoprint else force)(\{ # examplesIf}
+## Power analysis
+## --------------
+# See https://osf.io/cg64s/
+
+p0 <- c(0.35, 0.65)
+Fei <- 0.3
+
+pwr::pwr.chisq.test(
+  w = fei_to_w(Fei, p = p0),
+  df = length(p0) - 1,
+  sig.level = 0.01,
+  power = 0.85
+)
+\dontshow{\}) # examplesIf}
 }
 \references{
 \itemize{
 \item Ben-Shachar, M.S., Patil, I., ThÃ©riault, R., Wiernik, B.M., LÃ¼decke, D.
 (2023). Phi, Fei, Fo, Fum: Effect Sizes for Categorical Data That Use the
 ChiâSquared Statistic. Mathematics, 11, 1982. \doi{10.3390/math11091982}
+\item Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
 }
 }
 \seealso{",True,False,Dependency / Package,7
easystats,effectsize,9d0f2ff3f4c36c059f73630ac11d2ac44c573063,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2023-04-11T11:56:54Z,GitHub,noreply@github.com,2023-04-11T11:56:54Z,"Correct CI for RR (#585)

* fix to #584

* news + tests",DESCRIPTION;NEWS.md;R/xtab_diff.R;tests/testthat/test-xtab.R,False,True,True,False,7,2,9,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size
-Version: 0.8.3.6
+Version: 0.8.3.7
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",

---FILE: NEWS.md---
@@ -18,6 +18,7 @@
 
 ## Bug fixes
 
+- `riskratio()` returns correct CIs (#584)  
 - `d_to_r()` correctly treats specifying only `n1`/`n2` as equal group sizes (#571)
 
 # effectsize 0.8.3

---FILE: R/xtab_diff.R---
@@ -150,7 +150,7 @@ riskratio <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = F
 
     alpha <- 1 - ci.level
 
-    SE_logRR <- sqrt(p1 / ((1 - p1) * n1)) + sqrt(p2 / ((1 - p2) * n2))
+    SE_logRR <- sqrt((1 - p1) / (n1 * p1) + (1 - p2) / (n2 * p2))
     Z_logRR <- stats::qnorm(alpha / 2, lower.tail = FALSE)
     confs <- exp(log(RR) + c(-1, 1) * SE_logRR * Z_logRR)
 

---FILE: tests/testthat/test-xtab.R---
@@ -176,6 +176,10 @@ test_that(""oddsratio & riskratio"", {
     tolerance = 1e-4
   )
 
+  # verified with PropCIs::riskscoreci
+  expect_equal(RR$CI_low, 0.2777954, tolerance = 1e-4)
+  expect_equal(RR$CI_high, 0.5567815, tolerance = 1e-4)
+
   expect_error(riskratio(RCT, log = TRUE), NA)
 
 ",True,False,Documentation / Formatting,7
easystats,effectsize,4c60e28d396d9979d22142191ad9f93ab5ee2c79,Indrajeet Patil,patilindrajeet.science@gmail.com,2023-03-28T06:46:08Z,GitHub,noreply@github.com,2023-03-28T06:46:08Z,"Remove commented code in tests (#582)

cf. https://github.com/easystats/easystats/issues/361",tests/testthat/test-cohens_d.R;tests/testthat/test-common_language.R;tests/testthat/test-convert_between.R;tests/testthat/test-convert_between_CLES.R;tests/testthat/test-convert_statistic.R;tests/testthat/test-effectsize.R;tests/testthat/test-eta_squared.R;tests/testthat/test-interpret.R;tests/testthat/test-print.R;tests/testthat/test-r2_semipartial.R;tests/testthat/test-rankES.R;tests/testthat/test-rom.R;tests/testthat/test-utils_validate_input_data.R;tests/testthat/test-xtab.R,False,True,True,False,3,63,66,"---FILE: tests/testthat/test-cohens_d.R---
@@ -26,7 +26,6 @@ test_that(""cohens_d - mu"", {
     ignore_attr = TRUE
   )
 
-  # t.test(x, y, mu = 3.125, var.equal = TRUE)
   d <- cohens_d(x, y, mu = 3.125)
   expect_equal(d[[1]], -0.969, tolerance = 0.01)
   expect_equal(d$CI_low, -1.913, tolerance = 0.01)

---FILE: tests/testthat/test-common_language.R---
@@ -1,5 +1,3 @@
-# library(testthat)
-
 test_that(""CLES"", {
   x <- 1:3
   y <- c(1, 1:3)

---FILE: tests/testthat/test-convert_between.R---
@@ -1,5 +1,3 @@
-# library(testthat)
-
 test_that(""oddsratio_to_d"", {
   expect_equal(oddsratio_to_d(0.2), -0.887, tolerance = 0.01)
   expect_equal(oddsratio_to_d(-1.45, log = TRUE), -0.7994, tolerance = 0.01)

---FILE: tests/testthat/test-convert_between_CLES.R---
@@ -1,5 +1,3 @@
-# library(testthat)
-
 test_that(""d/rbs_to_cles | numeric"", {
   # Null ----------------------
   expect_equal(d_to_overlap(0), 1)

---FILE: tests/testthat/test-convert_statistic.R---
@@ -1,5 +1,3 @@
-# library(testthat)
-
 test_that(""xtab"", {
   xtab <- as.table(rbind(
     c(762, 327, 468),

---FILE: tests/testthat/test-effectsize.R---
@@ -1,4 +1,3 @@
-# library(testthat)
 # htest -------------------------------------------------------------------
 test_that(""t-test"", {
   x <<- 1:10

---FILE: tests/testthat/test-eta_squared.R---
@@ -1,5 +1,3 @@
-# library(testthat)
-
 test_that(""alternative = NULL"", {
   m <- aov(mpg ~ factor(cyl) + hp, mtcars)
   expect_equal(

---FILE: tests/testthat/test-interpret.R---
@@ -1,5 +1,3 @@
-# library(testthat)
-
 # interpret generic ----
 test_that(""interpret generic"", {
   rules_grid <- rules(c(0.01, 0.05), c(""very significant"", ""significant"", ""not significant""))

---FILE: tests/testthat/test-print.R---
@@ -1,5 +1,3 @@
-# library(testthat)
-
 test_that(""print | effectsize table"", {
   ## digits
   d <- cohens_d(1:4, c(1, 1:5))
@@ -42,7 +40,7 @@ test_that(""print | effectsize table"", {
   expect_output(print(w_), regexp = ""funder2019"")
   expect_output(print(w_), regexp = ""Interpretation"")
 
-  ## md / html
+  ## md or html
   skip_if_not_installed(""gt"")
   skip_if_not_installed(""knitr"")
   expect_s3_class(print_html(d), ""gt_tbl"")
@@ -55,7 +53,7 @@ test_that(""print | effectsize_difference"", {
   expect_error(expect_output(print(d1), regexp = ""Deviation from a difference""))
   expect_output(print(d1), regexp = "" pooled"", fixed = TRUE)
 
-  ## Un-pooled + mu
+  ## Un-pooled and mu
   d2 <- cohens_d(1:3, c(1, 1:3), pooled_sd = FALSE, mu = -1)
   expect_output(print(d2), regexp = ""Deviation from a difference of -1"")
   expect_output(print(d2), regexp = ""un-pooled"", fixed = TRUE)
@@ -65,7 +63,7 @@ test_that(""print | effectsize_difference"", {
   expect_error(expect_output(print(d3), regexp = ""Deviation from a difference""))
   expect_error(expect_output(print(d3), regexp = ""pooled""))
 
-  ## paired + mu
+  ## paired and mu
   d4 <- cohens_d(1:5, c(1, 1:4), paired = TRUE, mu = 0.1)
   expect_output(print(d4), regexp = ""Deviation from a difference of 0.1"")
 
@@ -94,39 +92,6 @@ test_that(""print | effectsize_anova"", {
   expect_output(print(e4), regexp = ""(Type III)"", fixed = TRUE)
 })
 
-# test_that(""print | effectsize_std_params"", {
-#   mod <- lm(mpg ~ cyl + gear, mtcars)
-#
-#   ## Methods
-#   es <- standardize_parameters(mod)
-#   expect_output(print(es), regexp = ""refit"")
-#
-#   es <- standardize_parameters(mod, method = ""basic"")
-#   expect_output(print(es), regexp = ""basic"")
-#
-#   ## Robust / two_sd / include_response
-#   es <- standardize_parameters(mod, robust = TRUE)
-#   expect_output(print(es), regexp = ""one MAD from the median"")
-#
-#   es <- standardize_parameters(mod, two_sd = TRUE)
-#   expect_output(print(es), regexp = ""two"")
-#
-#   es <- standardize_parameters(mod, include_response = FALSE)
-#   expect_output(print(es), regexp = ""unstandardized"")
-#
-#   es <- standardize_parameters(mod, include_response = FALSE, two_sd = TRUE, robust = TRUE)
-#   expect_output(print(es), regexp = ""two MADs from the median"")
-#
-#   # ES Name
-#   expect_output(print(es), regexp = ""Coefficient (std.)"", fixed = TRUE)
-#
-#   mod <- glm(am ~ mpg, binomial(), mtcars)
-#   es <- standardize_parameters(mod, exp = TRUE)
-#   expect_output(print(es), regexp = ""Odds Ratio (std.)"", fixed = TRUE)
-#   expect_output(print(es), regexp = ""unstandardized"")
-# })
-
-
 test_that(""print | equivalence_test_effectsize"", {
   d <- cohens_d(1:3, c(1, 1:3))
 

---FILE: tests/testthat/test-r2_semipartial.R---
@@ -1,5 +1,3 @@
-# library(testthat)
-
 test_that(""r2_semipartial basic"", {
   # Type terms
   m <- lm(log(mpg) ~ factor(cyl) + disp + hp * drat, data = mtcars)

---FILE: tests/testthat/test-rankES.R---
@@ -1,5 +1,3 @@
-# library(testthat)
-
 test_that(""rank_biserial"", {
   x <- c(1.83, 0.50, 1.62, 2.48, 1.68, 1.88, 1.55, 3.06, 1.30)
   y <- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)

---FILE: tests/testthat/test-rom.R---
@@ -1,5 +1,3 @@
-# library(testthat)
-
 test_that(""means_ratio"", {
   # Direction ---------------------------------------------------------------
   rez_t <- t.test(iris$Sepal.Length, iris$Sepal.Width)

---FILE: tests/testthat/test-utils_validate_input_data.R---
@@ -1,5 +1,3 @@
-# library(testthat)
-
 test_that("".get_data_2_samples"", {
   df <- data.frame(
     a = 1:10,

---FILE: tests/testthat/test-xtab.R---
@@ -1,5 +1,3 @@
-# library(testthat)
-
 test_that(""contingency table"", {
   contingency_table <- as.table(rbind(
     c(762, 327, 468),
@@ -186,7 +184,6 @@ test_that(""oddsratio & riskratio"", {
   expect_error(oddsratio(mtcars$am, mtcars$cyl), ""only"")
 
   mtcars$Ind <- mtcars$cyl > 4
-  # m <- glm(am ~ Ind, data = mtcars, family = binomial())
 
   # confirmed by emmeans
   or <- oddsratio(mtcars$am, mtcars$Ind)",True,False,Implementation / Logic,6
easystats,effectsize,01b59a584efe6bf5a5b20d6da48e816b0f3d866c,Indrajeet Patil,patilindrajeet.science@gmail.com,2023-03-23T07:17:04Z,GitHub,noreply@github.com,2023-03-23T07:17:04Z,"Run tests in parallel (#581)

* Run tests in parallel

* fix spelling

* Create check-random-test-order.yaml",.github/workflows/check-random-test-order.yaml;DESCRIPTION;inst/WORDLIST,False,False,False,False,16,4,20,"---FILE: .github/workflows/check-random-test-order.yaml---
@@ -0,0 +1,12 @@
+# Run tests in random order
+on:
+  push:
+    branches: [main, master]
+  pull_request:
+    branches: [main, master]
+
+name: check-random-test-order
+
+jobs:
+  check-random-test-order:
+    uses: easystats/workflows/.github/workflows/check-random-test-order.yaml@main

---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size
-Version: 0.8.3.5
+Version: 0.8.3.6
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",
@@ -67,7 +67,7 @@ Depends:
     R (>= 3.6)
 Imports:
     bayestestR (>= 0.13.0),
-    insight (>= 0.19.0.2),
+    insight (>= 0.19.1),
     parameters (>= 0.20.2),
     performance (>= 0.10.2),
     datawizard (>= 0.6.5),
@@ -94,15 +94,14 @@ Suggests:
     rstanarm,
     rstantools,
     testthat (>= 3.1.0)
-Remotes:
-    easystats/insight
 VignetteBuilder: 
     knitr
 Encoding: UTF-8
 Language: en-US
 Roxygen: list(markdown = TRUE)
 RoxygenNote: 7.2.3.9000
 Config/testthat/edition: 3
+Config/testthat/parallel: true
 Config/Needs/website:
     rstudio/bslib,
     r-lib/pkgdown,

---FILE: inst/WORDLIST---
@@ -226,6 +226,7 @@ rescale
 rmANOVA
 sd
 semipartial
+shinyapps
 statswiki
 strengejacke
 th",False,False,Dependency / Package,6
easystats,effectsize,59d7d8acc9eaf64eb7cfa4420a8b0cc85fcc7066,Indrajeet Patil,patilindrajeet.science@gmail.com,2023-03-19T08:27:21Z,GitHub,noreply@github.com,2023-03-19T08:27:21Z,"Add check styling workflow (#579)

* Create check-styling.yaml

https://github.com/easystats/easystats/issues/357

* Delete styler.yaml

* Update test-interpret.R",.github/workflows/check-styling.yaml;.github/workflows/styler.yaml;tests/testthat/test-interpret.R,False,True,True,False,11,13,24,"---FILE: .github/workflows/check-styling.yaml---
@@ -0,0 +1,11 @@
+on:
+  push:
+    branches: [main, master]
+  pull_request:
+    branches: [main, master]
+
+name: check-styling
+
+jobs:
+  check-styling:
+    uses: easystats/workflows/.github/workflows/check-styling.yaml@main

---FILE: .github/workflows/styler.yaml---
@@ -1,12 +0,0 @@
-# Workflow derived from https://github.com/r-lib/actions/tree/v2/examples
-# Need help debugging build failures? Start at https://github.com/r-lib/actions#where-to-find-help
-on:
-  pull_request:
-    branches: [main, master]
-    paths: [""**.[rR]"", ""**.[qrR]md"", ""**.[rR]markdown"", ""**.[rR]nw""]
-
-name: Style
-
-jobs:
-  styler:
-    uses: easystats/workflows/.github/workflows/styler.yaml@main

---FILE: tests/testthat/test-interpret.R---
@@ -255,4 +255,3 @@ test_that(""interpret effectsize_table"", {
 
   expect_error(interpret(d), ""must specify"")
 })
-",True,False,Environment / Configuration,4
easystats,effectsize,3a3f9f6b0f633e99a5e01213885c77523f572620,RÃ©mi ThÃ©riault,13123390+rempsyc@users.noreply.github.com,2023-03-13T12:23:48Z,GitHub,noreply@github.com,2023-03-13T12:23:48Z,"new function: `interpret_r2_semipartial()` (#577)

* interpret_r2_semipartial

* minor clean up

* fix tests

* fix typo

[skip ci]

* fix lintr

[skip ci]

---------

Co-authored-by: Mattan S. Ben-Shachar <mattansb@msbstats.info>",NAMESPACE;NEWS.md;R/interpret.R;R/interpret_omega_squared.R;man/interpret_omega_squared.Rd;tests/testthat/test-convert_between.R;tests/testthat/test-eta_squared.R;tests/testthat/test-interpret.R,False,True,True,False,32,23,55,"---FILE: NAMESPACE---
@@ -155,6 +155,7 @@ export(interpret_phi)
 export(interpret_pnfi)
 export(interpret_r)
 export(interpret_r2)
+export(interpret_r2_semipartial)
 export(interpret_rank_biserial)
 export(interpret_rfi)
 export(interpret_rhat)

---FILE: NEWS.md---
@@ -216,7 +216,7 @@ See [*Support functions for model extensions* vignette](https://easystats.github
 
 ## New features
 
-- `standardize_parameters()` + `eta_sqaured()` support `tidymodels` (when that the underlying model is supported; #311 ).
+- `standardize_parameters()` + `eta_squared()` support `tidymodels` (when that the underlying model is supported; #311 ).
 - `cohens_d()` family now supports `Pairs()` objects as input.
 - `standardize_parameters()` gains the `include_response` argument (default to `TRUE`) ( #309 ).
 

---FILE: R/interpret.R---
@@ -142,9 +142,9 @@ interpret.numeric <- function(x, rules, name = attr(rules, ""rule_name""), ...) {
   attr(rules, ""rule_name"") <- name
 
   if (length(x) > 1) {
-    out <- sapply(x, .interpret, rules)
+    out <- vapply(x, .interpret, rules = rules, FUN.VALUE = character(1L))
   } else {
-    out <- .interpret(x, rules)
+    out <- .interpret(x, rules = rules)
   }
 
   names(out) <- names(x)
@@ -194,6 +194,7 @@ interpret.effectsize_table <- function(x, rules, ...) {
     Eta2 = ,
     Eta2_partial = ,
     Eta2_generalized = ,
+    r2_semipartial = ,
     Epsilon2 = ,
     Epsilon2_partial = ,
     Omega2 = ,
@@ -224,7 +225,7 @@ interpret.effectsize_table <- function(x, rules, ...) {
 #' @keywords internal
 .interpret <- function(x, rules) {
   if (is.na(x)) {
-    return(NA)
+    return(NA_character_)
   }
 
   if (length(rules$values) == length(rules$labels)) {

---FILE: R/interpret_omega_squared.R---
@@ -1,6 +1,6 @@
 #' Interpret ANOVA Effect Sizes
 #'
-#' @param es Value or vector of eta / omega / epsilon squared values.
+#' @param es Value or vector of (partial) eta / omega / epsilon squared or semipartial r squared values.
 #' @param rules Can be `""field2013""` (default), `""cohen1992""` or custom set of [rules()].
 #' @param ... Not used for now.
 #'
@@ -54,7 +54,10 @@ interpret_omega_squared <- function(es, rules = ""field2013"", ...) {
 #' @rdname interpret_omega_squared
 interpret_eta_squared <- interpret_omega_squared
 
-
 #' @export
 #' @rdname interpret_omega_squared
 interpret_epsilon_squared <- interpret_omega_squared
+
+#' @export
+#' @rdname interpret_omega_squared
+interpret_r2_semipartial <- interpret_omega_squared

---FILE: man/interpret_omega_squared.Rd---
@@ -4,16 +4,19 @@
 \alias{interpret_omega_squared}
 \alias{interpret_eta_squared}
 \alias{interpret_epsilon_squared}
+\alias{interpret_r2_semipartial}
 \title{Interpret ANOVA Effect Sizes}
 \usage{
 interpret_omega_squared(es, rules = ""field2013"", ...)
 
 interpret_eta_squared(es, rules = ""field2013"", ...)
 
 interpret_epsilon_squared(es, rules = ""field2013"", ...)
+
+interpret_r2_semipartial(es, rules = ""field2013"", ...)
 }
 \arguments{
-\item{es}{Value or vector of eta / omega / epsilon squared values.}
+\item{es}{Value or vector of (partial) eta / omega / epsilon squared or semipartial r squared values.}
 
 \item{rules}{Can be \code{""field2013""} (default), \code{""cohen1992""} or custom set of \code{\link[=rules]{rules()}}.}
 

---FILE: tests/testthat/test-convert_between.R---
@@ -113,7 +113,7 @@ test_that(""odds_to_probs"", {
     log = TRUE
   )
 
-  expect_identical(ncol(df), 5)
+  expect_identical(ncol(df), 5L)
 
   expect_equal(
     probs_to_odds(df,

---FILE: tests/testthat/test-eta_squared.R---
@@ -211,7 +211,7 @@ test_that(""mlm / anova table"", {
 
   # MANOVA table
   mod <- manova(cbind(mpg, qsec) ~ am_f * cyl_f, data = mtcars)
-  expect_equal(nrow(eta_squared(mod)), 3L)
+  expect_identical(nrow(eta_squared(mod)), 3L)
 
   # Row order
   fit <- lm(cbind(mpg, disp, hp) ~ factor(cyl), data = mtcars)
@@ -360,12 +360,12 @@ test_that(""failed CIs"", {
 
   expect_warning(eta_squared(model), regexp = ""CIs"")
   expect_warning(eta <- eta_squared(model, verbose = FALSE), regexp = NA)
-  expect_equal(nrow(eta), 2L)
+  expect_identical(nrow(eta), 2L)
   expect_equal(eta[1, ""Eta2_partial""], 1)
 
   expect_warning(eta_squared(model, partial = FALSE), regexp = ""CIs"")
   expect_warning(eta <- eta_squared(model, partial = FALSE, verbose = FALSE), regexp = NA)
-  expect_equal(nrow(eta), 2L)
+  expect_identical(nrow(eta), 2L)
   expect_equal(eta[1, ""Eta2""], 0.34, tolerance = 0.01)
 })
 
@@ -380,23 +380,23 @@ test_that(""include_intercept | car"", {
 
   res0 <- eta_squared(AOV, verbose = FALSE)
   res1 <- eta_squared(AOV, include_intercept = TRUE, verbose = FALSE)
-  expect_equal(nrow(res0), 3)
-  expect_equal(nrow(res1), nrow(res0) + 1)
-  expect_equal(res1[[1]][1], ""(Intercept)"")
+  expect_identical(nrow(res0), 3L)
+  expect_identical(nrow(res1), nrow(res0) + 1L)
+  expect_identical(res1[[1]][1], ""(Intercept)"")
   expect_equal(res1[[2]][1], 0.8680899, tolerance = 0.01)
 
   res0 <- epsilon_squared(AOV, verbose = FALSE)
   res1 <- epsilon_squared(AOV, include_intercept = TRUE, verbose = FALSE)
-  expect_equal(nrow(res0), 3)
-  expect_equal(nrow(res1), nrow(res0) + 1)
+  expect_identical(nrow(res0), 3L)
+  expect_identical(nrow(res1), nrow(res0) + 1L)
   expect_equal(res1[[1]][1], ""(Intercept)"")
 
 
   res0 <- omega_squared(AOV, verbose = FALSE)
   res1 <- omega_squared(AOV, include_intercept = TRUE, verbose = FALSE)
-  expect_equal(nrow(res0), 3)
-  expect_equal(nrow(res1), nrow(res0) + 1)
-  expect_equal(res1[[1]][1], ""(Intercept)"")
+  expect_identical(nrow(res0), 3L)
+  expect_identical(nrow(res1), nrow(res0) + 1L)
+  expect_identical(res1[[1]][1], ""(Intercept)"")
 
   # generalized
   res1 <- eta_squared(AOV, generalized = ""cyl"", include_intercept = TRUE, verbose = FALSE)
@@ -418,14 +418,14 @@ test_that(""include_intercept | afex"", {
 
   resE0 <- eta_squared(a, verbose = FALSE)
   resA0 <- anova(a, es = ""pes"")
-  expect_equal(nrow(resE0), 3)
-  expect_equal(nrow(resE0), nrow(resA0))
+  expect_identical(nrow(resE0), 3L)
+  expect_identical(nrow(resE0), nrow(resA0))
 
 
   resE1 <- eta_squared(a, include_intercept = TRUE, verbose = FALSE)
   resA1 <- anova(a, es = ""pes"", intercept = TRUE)
-  expect_equal(nrow(resE1), nrow(resE0) + 1)
-  expect_equal(nrow(resE1), nrow(resA1))
+  expect_identical(nrow(resE1), nrow(resE0) + 1L)
+  expect_identical(nrow(resE1), nrow(resA1))
 
   skip_if_not_installed(""car"")
   resE1 <- eta_squared(car::Anova(a$aov, type = 3), include_intercept = TRUE, generalized = ""gender"", verbose = FALSE)

---FILE: tests/testthat/test-interpret.R---
@@ -255,3 +255,4 @@ test_that(""interpret effectsize_table"", {
 
   expect_error(interpret(d), ""must specify"")
 })
+",True,False,Documentation / Formatting,7
easystats,effectsize,66341ee043436408f4338c522f15837557e2cb0a,Daniel,mail@danielluedecke.de,2023-03-10T08:14:16Z,GitHub,noreply@github.com,2023-03-10T08:14:16Z,"Add logoddsratio-functions (#569)

* Add logoddsratio-functions

* news, version bump

* fix lints

* Apply automatic changes

* kill convert_ aliases

* add missing prob-change functions

* fix

* lint and spell check

[skip ci]

---------

Co-authored-by: strengejacke <strengejacke@users.noreply.github.com>
Co-authored-by: Mattan S. Ben-Shachar <mattansb@msbstats.info>
Co-authored-by: Mattan S. Ben-Shachar <35330040+mattansb@users.noreply.github.com>",NAMESPACE;NEWS.md;R/convert_between_d_to_r.R;R/convert_between_odds_to_probs.R;R/convert_between_riskchange.R;R/zzz_deprecated.R;inst/WORDLIST;man/d_to_r.Rd;man/effectsize_deprecated.Rd;man/odds_to_probs.Rd;man/oddsratio.Rd;man/oddsratio_to_riskratio.Rd;tests/testthat/test-convert_between.R,False,True,True,False,369,173,542,"---FILE: NAMESPACE---
@@ -63,6 +63,7 @@ export(F_to_f2)
 export(F_to_omega2)
 export(F_to_r)
 export(arr)
+export(arr_to_logoddsratio)
 export(arr_to_nnt)
 export(arr_to_oddsratio)
 export(arr_to_riskratio)
@@ -88,8 +89,6 @@ export(common_language)
 export(convert_d_to_common_language)
 export(convert_d_to_oddsratio)
 export(convert_d_to_r)
-export(convert_logoddsratio_to_d)
-export(convert_logoddsratio_to_r)
 export(convert_odds_to_probs)
 export(convert_oddsratio_to_d)
 export(convert_oddsratio_to_r)
@@ -101,6 +100,7 @@ export(cov_pooled)
 export(cramers_v)
 export(d_to_cles)
 export(d_to_common_language)
+export(d_to_logoddsratio)
 export(d_to_oddsratio)
 export(d_to_overlap)
 export(d_to_p_superiority)
@@ -165,18 +165,25 @@ export(interpret_vif)
 export(is.rules)
 export(is_effectsize_name)
 export(kendalls_w)
+export(logoddsratio_to_arr)
 export(logoddsratio_to_d)
+export(logoddsratio_to_nnt)
 export(logoddsratio_to_r)
+export(logoddsratio_to_riskratio)
 export(mad_pooled)
 export(mahalanobis_d)
 export(means_ratio)
 export(nnt)
 export(nnt_to_arr)
+export(nnt_to_logoddsratio)
+export(nnt_to_oddsratio)
+export(nnt_to_riskratio)
 export(normalized_chi)
 export(odds_to_probs)
 export(oddsratio)
 export(oddsratio_to_arr)
 export(oddsratio_to_d)
+export(oddsratio_to_nnt)
 export(oddsratio_to_r)
 export(oddsratio_to_riskratio)
 export(omega_squared)
@@ -190,6 +197,7 @@ export(print_md)
 export(probs_to_odds)
 export(r2_semipartial)
 export(r_to_d)
+export(r_to_logoddsratio)
 export(r_to_oddsratio)
 export(rank_biserial)
 export(rank_epsilon_squared)
@@ -201,6 +209,8 @@ export(rb_to_vda)
 export(rb_to_wmw_odds)
 export(riskratio)
 export(riskratio_to_arr)
+export(riskratio_to_logoddsratio)
+export(riskratio_to_nnt)
 export(riskratio_to_oddsratio)
 export(rules)
 export(sd_pooled)

---FILE: NEWS.md---
@@ -4,10 +4,17 @@
 
 - `arr()` and `nnt()` for Absolute Risk Reduction or Number Needed to Treat.
 - `oddsratio_to_arr()`, `riskratio_to_arr()`, `nnt_to_arr()` and their inverses.
+- `logoddsratio_to_*()` and `*_to_logoddsratio()` have been added as convenient shortcuts for `oddsratio_to_*(log = TRUE)` and `*_to_oddsratio(log = TRUE)`.
+- Added all missing functions to convert between (log) OR, RR, ARR, and NNT.
 
 ## Changes
 
 - `fei()` gives a more informative error method for invalid table inputs (#566).
+- `convert_*()` aliases are deprecated.
+
+## Breaking Changes
+
+- `*_to_riskratio()` and `riskratio_to_*()` argument `log` not longer converts RR to/from log(RR).
 
 ## Bug fixes
 

---FILE: R/convert_between_d_to_r.R---
@@ -3,11 +3,11 @@
 #' Enables a conversion between different indices of effect size, such as
 #' standardized difference (Cohen's d), (point-biserial) correlation r or (log) odds ratios.
 #'
-#' @param d Standardized difference value (Cohen's d).
-#' @param r Correlation coefficient r.
+#' @param d,r,OR,logOR Standardized difference value (Cohen's d), correlation
+#'   coefficient (r), Odds ratio, or logged Odds ratio.
 #' @param n1,n2 Group sample sizes. If either is missing, groups are assumed to be of equal size.
-#' @param OR *Odds ratio* values in vector or data frame.
-#' @param log Take in or output the log of the ratio (such as in logistic models).
+#' @param log Take in or output the log of the ratio (such as in logistic models),
+#'   e.g. when the desired input or output are log odds ratios instead odds ratios.
 #' @param ... Arguments passed to or from other methods.
 #'
 #' @family convert between effect sizes
@@ -54,37 +54,21 @@
 #' methods, 8(4), 448.
 #'
 #' @export
-#' @aliases convert_d_to_r
 d_to_r <- function(d, n1, n2, ...) {
   h <- .get_rd_h(n1, n2)
   d / (sqrt(d^2 + h))
 }
 
-#' @export
-convert_d_to_r <- d_to_r
-
-
-
-
-
-
 #' @rdname d_to_r
-#' @aliases convert_r_to_d
 #' @export
 r_to_d <- function(r, n1, n2, ...) {
   h <- .get_rd_h(n1, n2)
   sqrt(h) * r / sqrt(1 - r^2)
 }
 
-#' @export
-convert_r_to_d <- r_to_d
-
-
-
 # OR - d ----------------------------------------------------------------
 
 #' @rdname d_to_r
-#' @aliases convert_oddsratio_to_d
 #' @export
 oddsratio_to_d <- function(OR, log = FALSE, ...) {
   if (log) {
@@ -96,25 +80,13 @@ oddsratio_to_d <- function(OR, log = FALSE, ...) {
   log_OR * (sqrt(3) / pi)
 }
 
-#' @export
-convert_oddsratio_to_d <- oddsratio_to_d
-
-
-
 #' @rdname d_to_r
-#' @aliases convert_logoddsratio_to_d
 #' @export
-logoddsratio_to_d <- function(OR, log = TRUE, ...) {
-  oddsratio_to_d(OR, log = log, ...)
+logoddsratio_to_d <- function(logOR, log = TRUE, ...) {
+  oddsratio_to_d(logOR, log = log, ...)
 }
 
-#' @export
-convert_logoddsratio_to_d <- logoddsratio_to_d
-
-
-
 #' @rdname d_to_r
-#' @aliases convert_d_to_oddsratio
 #' @export
 d_to_oddsratio <- function(d, log = FALSE, ...) {
   log_OR <- d * pi / sqrt(3)
@@ -126,45 +98,41 @@ d_to_oddsratio <- function(d, log = FALSE, ...) {
   }
 }
 
+#' @rdname d_to_r
 #' @export
-convert_d_to_oddsratio <- d_to_oddsratio
+d_to_logoddsratio <- function(d, log = TRUE, ...) {
+  d_to_oddsratio(d, log = log, ...)
+}
 
 
 
 
 # OR - r ----------------------------------------------------------------
 
 #' @rdname d_to_r
-#' @aliases convert_oddsratio_to_r
 #' @export
 oddsratio_to_r <- function(OR, n1, n2, log = FALSE, ...) {
   d_to_r(oddsratio_to_d(OR, log = log), n1, n2)
 }
 
-#' @export
-convert_oddsratio_to_r <- oddsratio_to_r
-
 #' @rdname d_to_r
-#' @aliases convert_logoddsratio_to_r
 #' @export
-logoddsratio_to_r <- function(OR, log = TRUE, ...) {
-  oddsratio_to_r(OR, log = log, ...)
+logoddsratio_to_r <- function(logOR, log = TRUE, ...) {
+  oddsratio_to_r(logOR, log = log, ...)
 }
 
-#' @export
-convert_logoddsratio_to_r <- logoddsratio_to_r
-
-
 
 #' @rdname d_to_r
-#' @aliases convert_r_to_oddsratio
 #' @export
 r_to_oddsratio <- function(r, n1, n2, log = FALSE, ...) {
   d_to_oddsratio(r_to_d(r), log = log, n1, n2)
 }
 
+#' @rdname d_to_r
 #' @export
-convert_r_to_oddsratio <- r_to_oddsratio
+r_to_logoddsratio <- function(r, n1, n2, log = TRUE, ...) {
+  r_to_oddsratio(r, n1, n2, log = log)
+}
 
 
 # Utils -------------------------------------------------------------------

---FILE: R/convert_between_odds_to_probs.R---
@@ -21,15 +21,10 @@
 #' probs_to_odds(0.95)
 #' probs_to_odds(0.95, log = TRUE)
 #' @export
-#' @aliases convert_odds_to_probs
 odds_to_probs <- function(odds, log = FALSE, ...) {
   UseMethod(""odds_to_probs"")
 }
 
-#' @export
-convert_odds_to_probs <- odds_to_probs
-
-
 #' @export
 odds_to_probs.numeric <- function(odds, log = FALSE, ...) {
   if (log) {
@@ -48,15 +43,11 @@ odds_to_probs.data.frame <- function(odds, log = FALSE, select = NULL, exclude =
 
 
 #' @rdname odds_to_probs
-#' @aliases convert_probs_to_odds
 #' @export
 probs_to_odds <- function(probs, log = FALSE, ...) {
   UseMethod(""probs_to_odds"")
 }
 
-#' @export
-convert_probs_to_odds <- probs_to_odds
-
 #' @export
 probs_to_odds.numeric <- function(probs, log = FALSE, ...) {
   if (log) {

---FILE: R/convert_between_riskchange.R---
@@ -1,15 +1,22 @@
-#' Convert Between Odds Ratios and Risk Ratios
+#' Convert Between Odds Ratios, Risk Ratios and Other Metrics of Change in Probabilities
 #'
-#' @param OR,RR,ARR Risk ratio of `p1/p0` Odds ratio of `odds(p1)/odds(p0)`
-#'   (possibly log-ed), or Absolute Risk Reduction or `p1 - p0`. `OR` can also
-#'   be a logistic regression model.
-#' @param x Absolute Risk Reduction or Number Needed to Treat.
+#' @param OR,logOR,RR,ARR,NNT Odds-ratio of `odds(p1)/odds(p0)`, log-Odds-ratio
+#'   of `log(odds(p1)/odds(p0))`, Risk ratio of `p1/p0`, Absolute Risk Reduction
+#'   of `p1 - p0`, or Number-needed-to-treat of `1/(p1 - p0)`. `OR` and `logOR`
+#'   can also be a logistic regression model.
 #' @param p0 Baseline risk
+#' @param log If:
+#'   - `TRUE`:
+#'       - In `oddsratio_to_*()`, `OR` input is treated as `log(OR)`.
+#'       - In `*_to_oddsratio()`, returned value is `log(OR)`.
+#'   - `FALSE`:
+#'       - In `logoddsratio_to_*()`, `logOR` input is treated as `OR`.
+#'       - In `*_to_logoddsratio()`, returned value is `OR`.
 #' @param ... Arguments passed to and from other methods.
 #' @inheritParams oddsratio_to_d
 #' @inheritParams cohens_d
 #'
-#' @return Converted index, or if `OR` is a logistic regression model, a
+#' @return Converted index, or if `OR`/`logOR` is a logistic regression model, a
 #'   parameter table with the converted indices.
 #'
 #' @family convert between effect sizes
@@ -52,7 +59,6 @@ oddsratio_to_riskratio.numeric <- function(OR, p0, log = FALSE, verbose = TRUE,
 
   RR <- OR / (1 - p0 + (p0 * OR))
 
-  if (log) RR <- log(RR)
   return(RR)
 }
 
@@ -104,17 +110,57 @@ oddsratio_to_riskratio.default <- function(OR, p0, log = FALSE, verbose = TRUE,
     RR[RR$Parameter == ""(Intercept)"", ""Parameter""] <- ""(p0)""
   }
 
-  attr(RR, ""coefficient_name"") <- if (log) ""Log-RR"" else ""Risk Ratio""
+  attr(RR, ""coefficient_name"") <- ""Risk Ratio""
   return(RR)
 }
 
+#' @rdname oddsratio_to_riskratio
+#' @export
+oddsratio_to_arr <- function(OR, p0, log = FALSE, verbose = TRUE, ...) {
+  if (log) OR <- exp(OR)
+  RR <- oddsratio_to_riskratio(OR, p0, log = FALSE, verbose = verbose)
+  riskratio_to_arr(RR, p0, verbose = verbose)
+}
+
+#' @rdname oddsratio_to_riskratio
+#' @export
+oddsratio_to_nnt <- function(OR, p0, log = FALSE, verbose = TRUE, ...) {
+  ARR <- oddsratio_to_arr(OR, p0, log = log, verbose = verbose)
+  arr_to_nnt(ARR)
+}
+
 
 
+
+# From logoddsratio -------------------------------------------------------
+
 #' @rdname oddsratio_to_riskratio
 #' @export
-riskratio_to_oddsratio <- function(RR, p0, log = FALSE, verbose = TRUE, ...) {
-  if (log) RR <- exp(RR)
+logoddsratio_to_riskratio <- function(logOR, p0, log = TRUE, verbose = TRUE, ...) {
+  oddsratio_to_riskratio(logOR, p0, log = log, verbose = verbose)
+}
 
+
+#' @rdname oddsratio_to_riskratio
+#' @export
+logoddsratio_to_arr <- function(logOR, p0, log = TRUE, verbose = TRUE, ...) {
+  oddsratio_to_arr(logOR, p0, log = log, verbose = verbose)
+}
+
+
+#' @rdname oddsratio_to_riskratio
+#' @export
+logoddsratio_to_nnt <- function(logOR, p0, log = TRUE, verbose = TRUE, ...) {
+  oddsratio_to_nnt(logOR, p0, log = log, verbose = verbose)
+}
+
+
+
+# From RR -----------------------------------------------------------------
+
+#' @rdname oddsratio_to_riskratio
+#' @export
+riskratio_to_oddsratio <- function(RR, p0, log = FALSE, verbose = TRUE, ...) {
   OR <- RR * (1 - p0) / (1 - RR * p0)
 
   if (log) OR <- log(OR)
@@ -123,40 +169,78 @@ riskratio_to_oddsratio <- function(RR, p0, log = FALSE, verbose = TRUE, ...) {
 
 #' @rdname oddsratio_to_riskratio
 #' @export
-riskratio_to_arr <- function(RR, p0, log = FALSE, verbose = TRUE, ...) {
-  if (log) RR <- exp(RR)
+riskratio_to_arr <- function(RR, p0, verbose = TRUE, ...) {
   RR * p0 - p0
 }
 
 #' @rdname oddsratio_to_riskratio
 #' @export
-oddsratio_to_arr <- function(OR, p0, log = FALSE, verbose = TRUE, ...) {
-  if (log) OR <- exp(OR)
-  RR <- oddsratio_to_riskratio(OR, p0, log = FALSE, verbose = verbose)
-  riskratio_to_arr(RR, p0, verbose = verbose)
+riskratio_to_logoddsratio <- function(RR, p0, log = TRUE, verbose = TRUE, ...) {
+  riskratio_to_oddsratio(RR = RR, p0 = p0, log = log, verbose = verbose, ...)
 }
 
 #' @rdname oddsratio_to_riskratio
 #' @export
-arr_to_riskratio <- function(ARR, p0, log = FALSE, verbose = TRUE, ...) {
+riskratio_to_nnt <- function(RR, p0, verbose = TRUE, ...) {
+  ARR <- riskratio_to_arr(RR, p0, verbose = verbose)
+  arr_to_nnt(ARR)
+}
+
+
+# ARR ---------------------------------------------------------------------
+
+#' @rdname oddsratio_to_riskratio
+#' @export
+arr_to_riskratio <- function(ARR, p0, verbose = TRUE, ...) {
   RR <- ARR / p0 + 1
-  if (log) RR <- log(RR)
   RR
 }
 
 #' @rdname oddsratio_to_riskratio
 #' @export
 arr_to_oddsratio <- function(ARR, p0, log = FALSE, verbose = TRUE, ...) {
-  RR <- arr_to_riskratio(ARR, p0, log = log, verbose = verbose)
+  RR <- arr_to_riskratio(ARR, p0, verbose = verbose)
   riskratio_to_oddsratio(RR, p0, log = log, verbose = verbose)
 }
 
 #' @rdname oddsratio_to_riskratio
 #' @export
-arr_to_nnt <- function(x) {
-  1 / x
+arr_to_logoddsratio <- function(ARR, p0, log = TRUE, verbose = TRUE, ...) {
+  arr_to_oddsratio(ARR = ARR, p0 = p0, log = log, verbose = verbose, ...)
+}
+
+#' @rdname oddsratio_to_riskratio
+#' @export
+arr_to_nnt <- function(ARR, ...) {
+  1 / ARR
+}
+
+
+# From NNT ----------------------------------------------------------------
+
+#' @rdname oddsratio_to_riskratio
+#' @export
+nnt_to_oddsratio <- function(NNT, p0, log = FALSE, verbose = TRUE, ...) {
+  ARR <- nnt_to_arr(NNT)
+  arr_to_oddsratio(ARR, p0, log = log, verbose = verbose)
 }
 
 #' @rdname oddsratio_to_riskratio
 #' @export
-nnt_to_arr <- arr_to_nnt
+nnt_to_logoddsratio <- function(NNT, p0, log = TRUE, verbose = TRUE, ...) {
+  ARR <- nnt_to_arr(NNT)
+  arr_to_logoddsratio(ARR, p0, log = log, verbose = verbose)
+}
+
+#' @rdname oddsratio_to_riskratio
+#' @export
+nnt_to_riskratio <- function(NNT, p0, verbose = TRUE, ...) {
+  ARR <- nnt_to_arr(NNT)
+  arr_to_riskratio(ARR, p0, verbose = verbose)
+}
+
+#' @rdname oddsratio_to_riskratio
+#' @export
+nnt_to_arr <- function(NNT, ...) {
+  arr_to_nnt(NNT)
+}

---FILE: R/zzz_deprecated.R---
@@ -2,20 +2,71 @@
 #'
 #' @param ... Arguments to the deprecated function.
 #'
-#' @details
-#' - `interpret_d` is now [`interpret_cohens_d`].
-#' - `interpret_g` is now [`interpret_hedges_g`].
-#' - `interpret_delta` is now [`interpret_glass_delta`].
-#' - `interpret_parameters` for *standardized parameters* was incorrect. Use [`interpret_r`] instead.
-#' - `normalized_chi` is now [`fei`].
-#' - `chisq_to_normalized` is now [`chisq_to_fei`].
-#' - `d_to_cles` and `rb_to_cles` are now one of the available functions for CLES conversion, e.g. [`d_to_u1`].
-#'
 #' @rdname effectsize_deprecated
 #' @name effectsize_deprecated
 NULL
 
 
+# March 2023 --------------------------------------------------------------
+
+#' @rdname effectsize_deprecated
+#' @export
+convert_odds_to_probs <- function(...) {
+  .Deprecated(""odds_to_probs"")
+  odds_to_probs(...)
+}
+
+#' @rdname effectsize_deprecated
+#' @export
+convert_probs_to_odds <- function(...) {
+  .Deprecated(""probs_to_odds"")
+  probs_to_odds(...)
+}
+
+#' @rdname effectsize_deprecated
+#' @export
+convert_d_to_r <- function(...) {
+  .Deprecated(""d_to_r"")
+  d_to_r(...)
+}
+
+#' @rdname effectsize_deprecated
+#' @export
+convert_r_to_d <- function(...) {
+  .Deprecated(""r_to_d"")
+  r_to_d(...)
+}
+
+#' @rdname effectsize_deprecated
+#' @export
+convert_oddsratio_to_d <- function(...) {
+  .Deprecated(""oddsratio_to_d"")
+  oddsratio_to_d(...)
+}
+
+#' @rdname effectsize_deprecated
+#' @export
+convert_d_to_oddsratio <- function(...) {
+  .Deprecated(""d_to_oddsratio"")
+  d_to_oddsratio(...)
+}
+
+#' @rdname effectsize_deprecated
+#' @export
+convert_oddsratio_to_r <- function(...) {
+  .Deprecated(""oddsratio_to_r"")
+  oddsratio_to_r(...)
+}
+
+#' @rdname effectsize_deprecated
+#' @export
+convert_r_to_oddsratio <- function(...) {
+  .Deprecated(""r_to_oddsratio"")
+  r_to_oddsratio(...)
+}
+
+# Older -------------------------------------------------------------------
+
 #' @rdname effectsize_deprecated
 #' @export
 interpret_d <- function(...) {

---FILE: inst/WORDLIST---
@@ -104,6 +104,7 @@ Moscoso
 NCP
 NFI
 NNFI
+NNT
 Nordholm
 Normed
 Nosek

---FILE: man/d_to_r.Rd---
@@ -2,21 +2,15 @@
 % Please edit documentation in R/convert_between_d_to_r.R
 \name{d_to_r}
 \alias{d_to_r}
-\alias{convert_d_to_r}
 \alias{r_to_d}
-\alias{convert_r_to_d}
 \alias{oddsratio_to_d}
-\alias{convert_oddsratio_to_d}
 \alias{logoddsratio_to_d}
-\alias{convert_logoddsratio_to_d}
 \alias{d_to_oddsratio}
-\alias{convert_d_to_oddsratio}
+\alias{d_to_logoddsratio}
 \alias{oddsratio_to_r}
-\alias{convert_oddsratio_to_r}
 \alias{logoddsratio_to_r}
-\alias{convert_logoddsratio_to_r}
 \alias{r_to_oddsratio}
-\alias{convert_r_to_oddsratio}
+\alias{r_to_logoddsratio}
 \title{Convert Between \emph{d}, \emph{r}, and Odds Ratio}
 \usage{
 d_to_r(d, n1, n2, ...)
@@ -25,28 +19,30 @@ r_to_d(r, n1, n2, ...)
 
 oddsratio_to_d(OR, log = FALSE, ...)
 
-logoddsratio_to_d(OR, log = TRUE, ...)
+logoddsratio_to_d(logOR, log = TRUE, ...)
 
 d_to_oddsratio(d, log = FALSE, ...)
 
+d_to_logoddsratio(d, log = TRUE, ...)
+
 oddsratio_to_r(OR, n1, n2, log = FALSE, ...)
 
-logoddsratio_to_r(OR, log = TRUE, ...)
+logoddsratio_to_r(logOR, log = TRUE, ...)
 
 r_to_oddsratio(r, n1, n2, log = FALSE, ...)
+
+r_to_logoddsratio(r, n1, n2, log = TRUE, ...)
 }
 \arguments{
-\item{d}{Standardized difference value (Cohen's d).}
+\item{d, r, OR, logOR}{Standardized difference value (Cohen's d), correlation
+coefficient (r), Odds ratio, or logged Odds ratio.}
 
 \item{n1, n2}{Group sample sizes. If either is missing, groups are assumed to be of equal size.}
 
 \item{...}{Arguments passed to or from other methods.}
 
-\item{r}{Correlation coefficient r.}
-
-\item{OR}{\emph{Odds ratio} values in vector or data frame.}
-
-\item{log}{Take in or output the log of the ratio (such as in logistic models).}
+\item{log}{Take in or output the log of the ratio (such as in logistic models),
+e.g. when the desired input or output are log odds ratios instead odds ratios.}
 }
 \value{
 Converted index.

---FILE: man/effectsize_deprecated.Rd---
@@ -2,6 +2,14 @@
 % Please edit documentation in R/zzz_deprecated.R
 \name{effectsize_deprecated}
 \alias{effectsize_deprecated}
+\alias{convert_odds_to_probs}
+\alias{convert_probs_to_odds}
+\alias{convert_d_to_r}
+\alias{convert_r_to_d}
+\alias{convert_oddsratio_to_d}
+\alias{convert_d_to_oddsratio}
+\alias{convert_oddsratio_to_r}
+\alias{convert_r_to_oddsratio}
 \alias{interpret_d}
 \alias{interpret_g}
 \alias{interpret_delta}
@@ -15,6 +23,22 @@
 \alias{common_language}
 \title{Deprecated / Defunct Functions}
 \usage{
+convert_odds_to_probs(...)
+
+convert_probs_to_odds(...)
+
+convert_d_to_r(...)
+
+convert_r_to_d(...)
+
+convert_oddsratio_to_d(...)
+
+convert_d_to_oddsratio(...)
+
+convert_oddsratio_to_r(...)
+
+convert_r_to_oddsratio(...)
+
 interpret_d(...)
 
 interpret_g(...)
@@ -43,14 +67,3 @@ common_language(...)
 \description{
 Deprecated / Defunct Functions
 }
-\details{
-\itemize{
-\item \code{interpret_d} is now \code{\link{interpret_cohens_d}}.
-\item \code{interpret_g} is now \code{\link{interpret_hedges_g}}.
-\item \code{interpret_delta} is now \code{\link{interpret_glass_delta}}.
-\item \code{interpret_parameters} for \emph{standardized parameters} was incorrect. Use \code{\link{interpret_r}} instead.
-\item \code{normalized_chi} is now \code{\link{fei}}.
-\item \code{chisq_to_normalized} is now \code{\link{chisq_to_fei}}.
-\item \code{d_to_cles} and \code{rb_to_cles} are now one of the available functions for CLES conversion, e.g. \code{\link{d_to_u1}}.
-}
-}

---FILE: man/odds_to_probs.Rd---
@@ -2,10 +2,8 @@
 % Please edit documentation in R/convert_between_odds_to_probs.R
 \name{odds_to_probs}
 \alias{odds_to_probs}
-\alias{convert_odds_to_probs}
 \alias{odds_to_probs.data.frame}
 \alias{probs_to_odds}
-\alias{convert_probs_to_odds}
 \alias{probs_to_odds.data.frame}
 \title{Convert Between Odds and Probabilities}
 \usage{

---FILE: man/oddsratio.Rd---
@@ -33,7 +33,8 @@ Controls the type of CI returned: \code{""two.sided""} (two-sided CI; default),
 allowed (e.g., \code{""g""}, \code{""l""}, \code{""two""}...). See \emph{One-Sided CIs} in
 \link{effectsize_CIs}.}
 
-\item{log}{Take in or output the log of the ratio (such as in logistic models).}
+\item{log}{Take in or output the log of the ratio (such as in logistic models),
+e.g. when the desired input or output are log odds ratios instead odds ratios.}
 
 \item{...}{Ignored}
 }

---FILE: man/oddsratio_to_riskratio.Rd---
@@ -1,53 +1,94 @@
 % Generated by roxygen2: do not edit by hand
-% Please edit documentation in R/convert_between_riskdiff.R
+% Please edit documentation in R/convert_between_riskchange.R
 \name{oddsratio_to_riskratio}
 \alias{oddsratio_to_riskratio}
+\alias{oddsratio_to_arr}
+\alias{oddsratio_to_nnt}
+\alias{logoddsratio_to_riskratio}
+\alias{logoddsratio_to_arr}
+\alias{logoddsratio_to_nnt}
 \alias{riskratio_to_oddsratio}
 \alias{riskratio_to_arr}
-\alias{oddsratio_to_arr}
+\alias{riskratio_to_logoddsratio}
+\alias{riskratio_to_nnt}
 \alias{arr_to_riskratio}
 \alias{arr_to_oddsratio}
+\alias{arr_to_logoddsratio}
 \alias{arr_to_nnt}
+\alias{nnt_to_oddsratio}
+\alias{nnt_to_logoddsratio}
+\alias{nnt_to_riskratio}
 \alias{nnt_to_arr}
-\title{Convert Between Odds Ratios and Risk Ratios}
+\title{Convert Between Odds Ratios, Risk Ratios and Other Metrics of Change in Probabilities}
 \usage{
 oddsratio_to_riskratio(OR, p0, log = FALSE, verbose = TRUE, ...)
 
+oddsratio_to_arr(OR, p0, log = FALSE, verbose = TRUE, ...)
+
+oddsratio_to_nnt(OR, p0, log = FALSE, verbose = TRUE, ...)
+
+logoddsratio_to_riskratio(logOR, p0, log = TRUE, verbose = TRUE, ...)
+
+logoddsratio_to_arr(logOR, p0, log = TRUE, verbose = TRUE, ...)
+
+logoddsratio_to_nnt(logOR, p0, log = TRUE, verbose = TRUE, ...)
+
 riskratio_to_oddsratio(RR, p0, log = FALSE, verbose = TRUE, ...)
 
-riskratio_to_arr(RR, p0, log = FALSE, verbose = TRUE, ...)
+riskratio_to_arr(RR, p0, verbose = TRUE, ...)
 
-oddsratio_to_arr(OR, p0, log = FALSE, verbose = TRUE, ...)
+riskratio_to_logoddsratio(RR, p0, log = TRUE, verbose = TRUE, ...)
 
-arr_to_riskratio(ARR, p0, log = FALSE, verbose = TRUE, ...)
+riskratio_to_nnt(RR, p0, verbose = TRUE, ...)
+
+arr_to_riskratio(ARR, p0, verbose = TRUE, ...)
 
 arr_to_oddsratio(ARR, p0, log = FALSE, verbose = TRUE, ...)
 
-arr_to_nnt(x)
+arr_to_logoddsratio(ARR, p0, log = TRUE, verbose = TRUE, ...)
+
+arr_to_nnt(ARR, ...)
+
+nnt_to_oddsratio(NNT, p0, log = FALSE, verbose = TRUE, ...)
+
+nnt_to_logoddsratio(NNT, p0, log = TRUE, verbose = TRUE, ...)
 
-nnt_to_arr(x)
+nnt_to_riskratio(NNT, p0, verbose = TRUE, ...)
+
+nnt_to_arr(NNT, ...)
 }
 \arguments{
-\item{OR, RR, ARR}{Risk ratio of \code{p1/p0} Odds ratio of \code{odds(p1)/odds(p0)}
-(possibly log-ed), or Absolute Risk Reduction or \code{p1 - p0}. \code{OR} can also
-be a logistic regression model.}
+\item{OR, logOR, RR, ARR, NNT}{Odds-ratio of \code{odds(p1)/odds(p0)}, log-Odds-ratio
+of \code{log(odds(p1)/odds(p0))}, Risk ratio of \code{p1/p0}, Absolute Risk Reduction
+of \code{p1 - p0}, or Number-needed-to-treat of \code{1/(p1 - p0)}. \code{OR} and \code{logOR}
+can also be a logistic regression model.}
 
 \item{p0}{Baseline risk}
 
-\item{log}{Take in or output the log of the ratio (such as in logistic models).}
+\item{log}{If:
+\itemize{
+\item \code{TRUE}:
+\itemize{
+\item In \verb{oddsratio_to_*()}, \code{OR} input is treated as \code{log(OR)}.
+\item In \verb{*_to_oddsratio()}, returned value is \code{log(OR)}.
+}
+\item \code{FALSE}:
+\itemize{
+\item In \verb{logoddsratio_to_*()}, \code{logOR} input is treated as \code{OR}.
+\item In \verb{*_to_logoddsratio()}, returned value is \code{OR}.
+}
+}}
 
 \item{verbose}{Toggle warnings and messages on or off.}
 
 \item{...}{Arguments passed to and from other methods.}
-
-\item{x}{Absolute Risk Reduction or Number Needed to Treat.}
 }
 \value{
-Converted index, or if \code{OR} is a logistic regression model, a
+Converted index, or if \code{OR}/\code{logOR} is a logistic regression model, a
 parameter table with the converted indices.
 }
 \description{
-Convert Between Odds Ratios and Risk Ratios
+Convert Between Odds Ratios, Risk Ratios and Other Metrics of Change in Probabilities
 }
 \examples{
 p0 <- 0.4

---FILE: tests/testthat/test-convert_between.R---
@@ -18,13 +18,13 @@ test_that(""d_to_r"", {
   r <- cor(mtcars$hp, -mtcars$am)
   d <- cohens_d(hp ~ am, data = mtcars, ci = NULL)[[1]]
   n <- table(mtcars$am)
-  expect_true(r_to_d(r) > d)
-  expect_true(d_to_r(d) < r)
+  expect_gt(r_to_d(r), d)
+  expect_lt(d_to_r(d), r)
   expect_equal(r_to_d(r, n[1], n[2]), d, ignore_attr = TRUE)
   expect_equal(d_to_r(d, n[1], n[2]), r, ignore_attr = TRUE)
 
-  expect_identical(d_to_r(.5, n1 = 10), d_to_r(.5, 10, 10))
-  expect_identical(d_to_r(.5, n2 = 10), d_to_r(.5, 10, 10))
+  expect_identical(d_to_r(0.5, n1 = 10), d_to_r(0.5, 10, 10))
+  expect_identical(d_to_r(0.5, n2 = 10), d_to_r(0.5, 10, 10))
 })
 
 test_that(""oddsratio_to_RR"", {
@@ -37,21 +37,21 @@ test_that(""oddsratio_to_RR"", {
   ARR <- p1 - p0
   NNT <- 1 / ARR
 
-  expect_equal(nnt_to_arr(NNT), ARR)
-  expect_equal(arr_to_nnt(ARR), NNT)
+  expect_equal(nnt_to_arr(NNT), ARR, tolerance = 1e-4)
+  expect_equal(arr_to_nnt(ARR), NNT, tolerance = 1e-4)
 
-  expect_equal(riskratio_to_oddsratio(RR, p0 = p0), OR)
-  expect_equal(oddsratio_to_riskratio(OR, p0 = p0), RR)
-  expect_equal(oddsratio_to_riskratio(1 / OR, p0 = p1), 1 / RR)
-  expect_equal(riskratio_to_arr(RR, p0 = p0), ARR)
-  expect_equal(oddsratio_to_arr(OR, p0 = p0), ARR)
-  expect_equal(arr_to_oddsratio(ARR, p0 = p0), OR)
-  expect_equal(arr_to_riskratio(ARR, p0 = p0), RR)
+  expect_equal(riskratio_to_oddsratio(RR, p0 = p0), OR, tolerance = 1e-4)
+  expect_equal(oddsratio_to_riskratio(OR, p0 = p0), RR, tolerance = 1e-4)
+  expect_equal(oddsratio_to_riskratio(1 / OR, p0 = p1), 1 / RR, tolerance = 1e-4)
+  expect_equal(riskratio_to_arr(RR, p0 = p0), ARR, tolerance = 1e-4)
+  expect_equal(oddsratio_to_arr(OR, p0 = p0), ARR, tolerance = 1e-4)
+  expect_equal(arr_to_oddsratio(ARR, p0 = p0), OR, tolerance = 1e-4)
+  expect_equal(arr_to_riskratio(ARR, p0 = p0), RR, tolerance = 1e-4)
 
-  expect_equal(riskratio_to_oddsratio(log(RR), p0 = p0, log = TRUE), log(OR))
-  expect_equal(oddsratio_to_riskratio(log(OR), p0 = p0, log = TRUE), log(RR))
-  expect_equal(arr_to_oddsratio(ARR, p0 = p0, log = TRUE), log(OR))
-  expect_equal(oddsratio_to_arr(log(OR), p0 = p0, log = TRUE), ARR)
+  expect_equal(riskratio_to_oddsratio(RR, p0 = p0, log = TRUE), log(OR), tolerance = 1e-4)
+  expect_equal(oddsratio_to_riskratio(log(OR), p0 = p0, log = TRUE), RR, tolerance = 1e-4)
+  expect_equal(arr_to_oddsratio(ARR, p0 = p0, log = TRUE), log(OR), tolerance = 1e-4)
+  expect_equal(oddsratio_to_arr(log(OR), p0 = p0, log = TRUE), ARR, tolerance = 1e-4)
 
   # -- GLMs --
   data(mtcars)
@@ -61,19 +61,19 @@ test_that(""oddsratio_to_RR"", {
     family = binomial()
   )
 
-  expect_warning(RR <- oddsratio_to_riskratio(m, ci = NULL), ""p0"")
+  expect_warning(RR <- oddsratio_to_riskratio(m, ci = NULL), ""p0"") # nolint
   expect_true(""(Intercept)"" %in% RR$Parameter)
   expect_false(""(p0)"" %in% RR$Parameter)
 
-  expect_message(RR <- oddsratio_to_riskratio(m, ci_method = ""wald"", p0 = 0.7272727), ""CIs"")
+  expect_message(RR <- oddsratio_to_riskratio(m, ci_method = ""wald"", p0 = 0.7272727), ""CIs"") # nolint
   expect_false(""(Intercept)"" %in% RR$Parameter)
   expect_true(""(p0)"" %in% RR$Parameter)
   # these values confirmed from emmeans
   expect_equal(RR$Coefficient, c(0.7272, 0.5892, 0.1964), tolerance = 0.001)
   expect_equal(RR$CI_low, c(NA, 0.1267, 0.0303), tolerance = 0.001)
   expect_equal(RR$CI_high, c(NA, 1.1648, 0.7589), tolerance = 0.001)
 
-  expect_message(RR <- oddsratio_to_riskratio(m, p0 = 0.05), ""CIs"")
+  expect_message(RR <- oddsratio_to_riskratio(m, p0 = 0.05), ""CIs"") # nolint
   expect_true(""(p0)"" %in% RR$Parameter)
   expect_false(""(Intercept)"" %in% RR$Parameter)
   # these values confirmed from emmeans
@@ -86,11 +86,11 @@ test_that(""oddsratio_to_RR"", {
     family = binomial()
   )
 
-  expect_warning(RR <- oddsratio_to_riskratio(m, ci = NULL), ""p0"")
+  expect_warning(RR <- oddsratio_to_riskratio(m, ci = NULL), ""p0"") # nolint
   expect_true(""(Intercept)"" %in% RR$Parameter)
   expect_false(""(p0)"" %in% RR$Parameter)
 
-  expect_message(RR <- oddsratio_to_riskratio(m, ci_method = ""wald"", p0 = 0.7047536), ""CIs"")
+  expect_message(RR <- oddsratio_to_riskratio(m, ci_method = ""wald"", p0 = 0.7047536), ""CIs"") # nolint
   expect_false(""(Intercept)"" %in% RR$Parameter)
   expect_true(""(p0)"" %in% RR$Parameter)
   # these values confirmed from emmeans
@@ -105,29 +105,64 @@ test_that(""odds_to_probs"", {
   expect_equal(probs_to_odds(0.75, log = TRUE), 1.098, tolerance = 0.01)
   expect_equal(odds_to_probs(1.098, log = TRUE), 0.75, tolerance = 0.01)
 
-  expect_equal(
-    ncol(df <- odds_to_probs(
-      iris,
-      select = c(""Sepal.Length""),
-      exclude = c(""Petal.Length""),
-      log = TRUE
-    )), 5
+  # Data frames
+  df <- odds_to_probs(
+    iris,
+    select = ""Sepal.Length"",
+    exclude = ""Petal.Length"",
+    log = TRUE
   )
 
+  expect_identical(ncol(df), 5)
+
   expect_equal(
-    ncol(probs_to_odds(
-      df,
-      select = c(""Sepal.Length""),
-      exclude = c(""Petal.Length""),
+    probs_to_odds(df,
+      select = ""Sepal.Length"",
+      exclude = ""Petal.Length"",
       log = TRUE
-    )), 5
+    ), iris,
+    tolerance = 1e-4
   )
 })
 
 test_that(""between anova"", {
-  expect_equal(eta2_to_f2(0.25), 1 / 3)
-  expect_equal(eta2_to_f(0.25), sqrt(eta2_to_f2(0.25)))
+  expect_equal(eta2_to_f2(0.25), 1 / 3, tolerance = 1e-4)
+  expect_equal(eta2_to_f(0.25), sqrt(eta2_to_f2(0.25)), tolerance = 1e-4)
 
   expect_equal(f2_to_eta2(1 / 3), 0.25)
-  expect_equal(f_to_eta2(1 / sqrt(3)), f2_to_eta2(1 / 3))
+  expect_equal(f_to_eta2(1 / sqrt(3)), f2_to_eta2(1 / 3), tolerance = 1e-4)
+})
+
+
+test_that(""OR and logOR"", {
+  expect_equal(
+    oddsratio_to_d(3),
+    logoddsratio_to_d(log(3)),
+    tolerance = 1e-4
+  )
+  expect_equal(
+    log(d_to_oddsratio(3)),
+    d_to_logoddsratio(3),
+    tolerance = 1e-4
+  )
+  expect_equal(
+    oddsratio_to_r(2),
+    logoddsratio_to_r(log(2)),
+    tolerance = 1e-4
+  )
+  expect_equal(
+    log(r_to_oddsratio(0.5)),
+    r_to_logoddsratio(0.5),
+    tolerance = 1e-4
+  )
+  expect_equal(
+    log(arr_to_oddsratio(0.2, p0 = 0.3)),
+    arr_to_logoddsratio(0.2, p0 = 0.3),
+    tolerance = 1e-4
+  )
+  expect_equal(
+    oddsratio_to_arr(2, p0 = 0.3),
+    logoddsratio_to_arr(log(2), p0 = 0.3),
+    tolerance = 1e-4
+  )
 })",True,False,Documentation / Formatting,7
easystats,effectsize,585f7c197420a73ca32b78a1863a328d3e81624d,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2023-03-09T08:14:04Z,GitHub,noreply@github.com,2023-03-09T08:14:04Z,"fix #571 (#572)

* fix #571

* Update NEWS.md",DESCRIPTION;NEWS.md;R/convert_between_d_to_r.R;tests/testthat/test-convert_between.R,False,True,True,False,9,2,11,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size
-Version: 0.8.3.4
+Version: 0.8.3.5
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",

---FILE: NEWS.md---
@@ -9,6 +9,10 @@
 
 - `fei()` gives a more informative error method for invalid table inputs (#566).
 
+## Bug fixes
+
+- `d_to_r()` correctly treats specifying only `n1`/`n2` as equal group sizes (#571)
+
 # effectsize 0.8.3
 
 ## Changes

---FILE: R/convert_between_d_to_r.R---
@@ -171,7 +171,7 @@ convert_r_to_oddsratio <- r_to_oddsratio
 
 #' @keywords internal
 .get_rd_h <- function(n1, n2) {
-  if (missing(n1) || missing(n2)) {
+  if (missing(n1) && missing(n2)) {
     h <- 4
   } else {
     if (missing(n1)) n1 <- n2

---FILE: tests/testthat/test-convert_between.R---
@@ -22,6 +22,9 @@ test_that(""d_to_r"", {
   expect_true(d_to_r(d) < r)
   expect_equal(r_to_d(r, n[1], n[2]), d, ignore_attr = TRUE)
   expect_equal(d_to_r(d, n[1], n[2]), r, ignore_attr = TRUE)
+
+  expect_identical(d_to_r(.5, n1 = 10), d_to_r(.5, 10, 10))
+  expect_identical(d_to_r(.5, n2 = 10), d_to_r(.5, 10, 10))
 })
 
 test_that(""oddsratio_to_RR"", {",True,False,Documentation / Formatting,7
easystats,effectsize,535a657d776b1f3085ead2dd500bf4578a5bcd98,Daniel,mail@danielluedecke.de,2023-03-05T07:30:51Z,GitHub,noreply@github.com,2023-03-05T07:30:51Z,"`fei()` doesn't work with table or matrix? (#567)

* `fei()` doesn't work with table or matrix?
Fixes #566

* update news, version bump

* revise input check

* add tests

* fix

* check

* styler

* rename var

* comment code

* more strict

* Apply automatic changes

* fix

* Apply automatic changes

* typo

* fix lintr

* ...

* lintr

* fix

* add tolerance to avoid lints

* Update xtab_corr.R

---------

Co-authored-by: strengejacke <strengejacke@users.noreply.github.com>
Co-authored-by: Mattan S. Ben-Shachar <mattansb@msbstats.info>",DESCRIPTION;NEWS.md;R/convert_stat_chisq.R;R/effectsize.R;R/xtab_corr.R;tests/testthat/test-xtab.R,False,True,True,False,69,33,102,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size
-Version: 0.8.3.3
+Version: 0.8.3.4
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",

---FILE: NEWS.md---
@@ -5,6 +5,10 @@
 - `arr()` and `nnt()` for Absolute Risk Reduction or Number Needed to Treat.
 - `oddsratio_to_arr()`, `riskratio_to_arr()`, `nnt_to_arr()` and their inverses.
 
+## Changes
+
+- `fei()` gives a more informative error method for invalid table inputs (#566).
+
 # effectsize 0.8.3
 
 ## Changes

---FILE: R/convert_stat_chisq.R---
@@ -328,7 +328,8 @@ phi_to_chisq <- function(phi, n, ...) {
                                   ...) {
   alternative <- .match.alt(alternative, FALSE)
 
-  if (ci_numeric <- .test_ci(ci)) {
+  ci_numeric <- .test_ci(ci)
+  if (ci_numeric) {
     is_goodness <- ncol == 1 || nrow == 1
 
     if (is_goodness) {

---FILE: R/effectsize.R---
@@ -128,7 +128,8 @@ effectsize.aovlist <- effectsize.anova
 
 #' @export
 effectsize.easycorrelation <- function(model, ...) {
-  if (is.null(r_name <- attr(model, ""coefficient_name""))) {
+  r_name <- attr(model, ""coefficient_name"")
+  if (is.null(r_name)) {
     r_name <- ""r""
   }
 

---FILE: R/xtab_corr.R---
@@ -1,3 +1,5 @@
+# styler: off
+
 #' \eqn{\phi} and Other Contingency Tables Correlations
 #'
 #' Compute phi (\eqn{\phi}), Cramer's *V*, Tschuprow's *T*, Cohen's *w*,
@@ -185,6 +187,14 @@ fei <- function(x, p = rep(1, length(x)),
   } else if (!.is_htest_of_type(x, ""Chi-squared test for given probabilities"", ""Chi-squared-test"")) {
     x <- suppressWarnings(stats::chisq.test(x, y = NULL, p = p, rescale.p = TRUE))
     x$data.name <- NULL
+
+    table_dim <- dim(x$observed)
+    is_1d_table <- is.null(table_dim) ||            # vector
+      length(table_dim) == 1 ||                     # 1D table
+      (length(table_dim) == 2 && table_dim[2] == 1)
+    if (!is_1d_table) {
+      insight::format_error(""Fei is only applicable to goodness of fit tests."")
+    }
   }
 
   effectsize(x, type = ""fei"", ci = ci, alternative = alternative)
@@ -209,3 +219,6 @@ pearsons_c <- function(x, y = NULL, p = rep(1, length(x)),
 
   effectsize(x, type = ""pearsons_c"", ci = ci, alternative = alternative)
 }
+
+
+# styler: on

---FILE: tests/testthat/test-xtab.R---
@@ -10,7 +10,7 @@ test_that(""contingency table"", {
 
   expect_equal(res$Cramers_v, 0.072, tolerance = 0.01)
   expect_equal(res$CI_low, 0.051, tolerance = 0.01)
-  expect_equal(res$CI_high, 1)
+  expect_equal(res$CI_high, 1, tolerance = 1e-4)
 
   expect_error(phi(contingency_table), ""appropriate"")
 
@@ -26,19 +26,19 @@ test_that(""contingency table"", {
   cv1 <- cramers_v(xtab, adjust = FALSE)
   cv2 <- cramers_v(xtab / 2, adjust = FALSE)
 
-  expect_equal(cv1$Cramers_v, cv2$Cramers_v)
+  expect_equal(cv1$Cramers_v, cv2$Cramers_v, tolerance = 1e-4)
 
   # Upper bound of phi is the ratio between phi / V and sqrt(min(K,L)-1)
-  expect_equal(cohens_w(xtab, alternative = ""greater"")$CI_high, sqrt(2))
-  expect_equal(cohens_w(xtab)[[1]] / cramers_v(xtab, adjust = FALSE)[[1]], sqrt(2))
+  expect_equal(cohens_w(xtab, alternative = ""greater"")$CI_high, sqrt(2), tolerance = 1e-4)
+  expect_equal(cohens_w(xtab)[[1]] / cramers_v(xtab, adjust = FALSE)[[1]], sqrt(2), tolerance = 1e-4)
 
   # Tschuprows_t with non-square tables
   xtab <- rbind(
     c(9, 0, 1),
     c(0, 1, 0)
   )
-  expect_equal(cramers_v(xtab, adjust = FALSE)[[1]], 1)
-  expect_true(tschuprows_t(xtab)[[1]] < cramers_v(xtab, adjust = FALSE)[[1]])
+  expect_equal(cramers_v(xtab, adjust = FALSE)[[1]], 1, tolerance = 1e-4)
+  expect_lt(tschuprows_t(xtab)[[1]], cramers_v(xtab, adjust = FALSE)[[1]])
 
 
   ## 2*2 tables return phi and cramers_v
@@ -49,7 +49,8 @@ test_that(""contingency table"", {
 
   expect_equal(
     cramers_v(xtab, adjust = FALSE)[[1]],
-    phi(xtab, adjust = FALSE)[[1]]
+    phi(xtab, adjust = FALSE)[[1]],
+    tolerance = 1e-4
   )
 
   res <- pearsons_c(xtab)
@@ -61,16 +62,18 @@ test_that(""contingency table"", {
     c(100, 0),
     c(0, 200)
   )
-  expect_equal(V <- cramers_v(xtab, adjust = FALSE)[[1]], 1)
-  expect_true(pearsons_c(xtab)[[1]] < V) # C is not perfect
+
+  V <- cramers_v(xtab, adjust = FALSE)[[1]]
+  expect_equal(V, 1, tolerance = 1e-4)
+  expect_lt(pearsons_c(xtab)[[1]], V) # C is not perfect
 
 
   ## 2*2 0 correlation
   xtab <- rbind(
     c(50, 50),
     c(100, 100)
   )
-  expect_equal(cramers_v(xtab, adjust = FALSE)$Cramers_v, 0)
+  expect_equal(cramers_v(xtab, adjust = FALSE)$Cramers_v, 0, tolerance = 1e-5)
 
 
   ## Empty rows/columns
@@ -83,9 +86,9 @@ test_that(""contingency table"", {
   ## 0
   xtab <- table(mtcars$am, mtcars$vs)
   phi3 <- phi(xtab, adjust = TRUE)
-  expect_equal(phi3$phi_adjusted, 0)
-  expect_equal(phi3$CI_low, 0)
-  expect_equal(phi3$CI_high, 1)
+  expect_equal(phi3$phi_adjusted, 0, tolerance = 1e-4)
+  expect_equal(phi3$CI_low, 0, tolerance = 1e-4)
+  expect_equal(phi3$CI_high, 1, tolerance = 1e-4)
 })
 
 
@@ -98,24 +101,24 @@ test_that(""goodness of fit"", {
   Fei1 <- fei(table(mtcars$cyl), p = c(0.34375, 0.21875, 0.43750))
   Fei2 <- fei(table(mtcars$cyl), p = c(0.8, 0.1, 0.1))
 
-  expect_equal(w1[[1]], 0)
-  expect_true(w1[[1]] < w2[[1]])
-  expect_true(Fei1[[1]] < Fei2[[1]])
-  expect_true(Fei2[[1]] < w2[[1]])
-  expect_equal(w2[[1]] * sqrt(0.1 / 0.9), Fei2[[1]])
-  expect_true(w1$CI_low < w2$CI_low)
-  expect_true(w2$CI_low < w2$CI_high)
-  expect_equal(w2$CI_high, sqrt(0.9 / 0.1))
+  expect_equal(w1[[1]], 0, tolerance = 1e-4)
+  expect_lt(w1[[1]], w2[[1]])
+  expect_lt(Fei1[[1]], Fei2[[1]])
+  expect_lt(Fei2[[1]], w2[[1]])
+  expect_equal(w2[[1]] * sqrt(0.1 / 0.9), Fei2[[1]], tolerance = 1e-4)
+  expect_lt(w1$CI_low, w2$CI_low)
+  expect_lt(w2$CI_low, w2$CI_high)
+  expect_equal(w2$CI_high, sqrt(0.9 / 0.1), tolerance = 1e-4)
 
   C <- pearsons_c(table(mtcars$cyl), p = c(0.8, 0.1, 0.1))
   expect_equal(C[[1]], sqrt(49.289 / (49.289 + sum(table(mtcars$cyl)))), tolerance = 0.001)
-  expect_equal(C$CI_high, 1)
+  expect_equal(C$CI_high, 1, tolerance = 1e-4)
 
   # some weird exeptions...
   df <- subset(mtcars, am == ""0"")
   expect_equal(cohens_w(table(df$am, df$cyl))[[1]], 0.64, tolerance = 0.01)
-  expect_equal(cohens_w(table(df$am, df$cyl)), cohens_w(table(df$cyl)))
-  expect_equal(cohens_w(table(df$am, df$cyl)), cohens_w(table(df$cyl, df$am)))
+  expect_equal(cohens_w(table(df$am, df$cyl)), cohens_w(table(df$cyl)), tolerance = 1e-4)
+  expect_equal(cohens_w(table(df$am, df$cyl)), cohens_w(table(df$cyl, df$am)), tolerance = 1e-4)
 
   # p is a table
   O <- as.table(c(10, 20, 30, 40))
@@ -124,15 +127,18 @@ test_that(""goodness of fit"", {
 
   expect_equal(
     cohens_w(O, p = E_vec, rescale.p = TRUE),
-    cohens_w(O, p = E_tab, rescale.p = TRUE)
+    cohens_w(O, p = E_tab, rescale.p = TRUE),
+    tolerance = 1e-4
   )
   expect_equal(
     fei(O, p = E_vec, rescale.p = TRUE),
-    fei(O, p = E_tab, rescale.p = TRUE)
+    fei(O, p = E_tab, rescale.p = TRUE),
+    tolerance = 1e-4
   )
   expect_equal(
     pearsons_c(O, p = E_vec, rescale.p = TRUE),
-    pearsons_c(O, p = E_tab, rescale.p = TRUE)
+    pearsons_c(O, p = E_tab, rescale.p = TRUE),
+    tolerance = 1e-4
   )
 })
 
@@ -158,15 +164,18 @@ test_that(""oddsratio & riskratio"", {
 
   expect_equal(
     oddsratio_to_riskratio(OR$Odds_ratio, p0),
-    RR$Risk_ratio
+    RR$Risk_ratio,
+    tolerance = 1e-4
   )
   expect_equal(
     riskratio_to_oddsratio(RR$Risk_ratio, p0),
-    OR$Odds_ratio
+    OR$Odds_ratio,
+    tolerance = 1e-4
   )
   expect_equal(
     oddsratio_to_arr(OR$Odds_ratio, p0),
-    ARR$ARR
+    ARR$ARR,
+    tolerance = 1e-4
   )
 
   expect_error(riskratio(RCT, log = TRUE), NA)
@@ -190,3 +199,11 @@ test_that(""oddsratio & riskratio"", {
   expect_equal(ARR$CI_low, -0.8092576, tolerance = 0.001)
   expect_equal(ARR$CI_high, -0.1690974, tolerance = 0.001)
 })
+
+
+test_that(""fei() for 1D tables"", {
+  data(Titanic)
+  Titanic_xtab <- as.table(apply(Titanic, c(2, 4), sum))
+  expect_error(fei(Titanic_xtab))
+  testthat::expect_no_error(fei(as.matrix(1:10)))
+})",True,False,Documentation / Formatting,7
easystats,effectsize,6cc3776be4673760cfbfff85f0830b4989d50221,Daniel,mail@danielluedecke.de,2023-02-26T08:36:10Z,GitHub,noreply@github.com,2023-02-26T08:36:10Z,fix error with report.htest() #563,DESCRIPTION;NAMESPACE;NEWS.md;R/cohens_d.R;R/cohens_g.R;R/common_language.R;R/convert_between_common_language.R;R/convert_between_odds_to_probs.R;R/convert_between_riskdiff.R;R/convert_stat_to_d.R;R/convert_stat_to_r.R;R/effectsize.BFBayesFactor.R;R/effectsize.htest.R;R/eta_squared-main.R;R/eta_squared-methods.R;R/eta_squared_posterior.R;R/format_standardize.R;R/mahalanobis_D.R;R/means_ratio.R;R/plot.R;R/pooled.R;R/print.effectsize_table.R;R/r2_semipartial.R;R/rank_ANOVA.R;R/rank_diff.R;R/utils.R;R/utils_ci.R;R/utils_validate_input_data.R;R/xtab_corr.R;R/xtab_diff.R;tests/testthat/test-effectsize.R,False,True,True,False,56,168,224,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size
-Version: 0.8.3.2
+Version: 0.8.3.3
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",
@@ -67,7 +67,7 @@ Depends:
     R (>= 3.6)
 Imports:
     bayestestR (>= 0.13.0),
-    insight (>= 0.18.8),
+    insight (>= 0.19.0.2),
     parameters (>= 0.20.2),
     performance (>= 0.10.2),
     datawizard (>= 0.6.5),
@@ -94,6 +94,8 @@ Suggests:
     rstanarm,
     rstantools,
     testthat (>= 3.1.0)
+Remotes:
+    easystats/insight
 VignetteBuilder: 
     knitr
 Encoding: UTF-8

---FILE: NAMESPACE---
@@ -222,57 +222,12 @@ export(vd_a)
 export(wmw_odds)
 export(z_to_d)
 export(z_to_r)
-importFrom(bayestestR,describe_posterior)
 importFrom(bayestestR,equivalence_test)
 importFrom(datawizard,standardise)
 importFrom(datawizard,standardize)
-importFrom(insight,check_if_installed)
 importFrom(insight,display)
-importFrom(insight,find_formula)
-importFrom(insight,find_predictors)
-importFrom(insight,find_response)
-importFrom(insight,format_value)
-importFrom(insight,get_data)
-importFrom(insight,get_parameters)
-importFrom(insight,get_predictors)
-importFrom(insight,model_info)
 importFrom(insight,print_html)
 importFrom(insight,print_md)
-importFrom(parameters,model_parameters)
 importFrom(parameters,standardize_info)
 importFrom(parameters,standardize_parameters)
 importFrom(parameters,standardize_posteriors)
-importFrom(stats,anova)
-importFrom(stats,aov)
-importFrom(stats,ave)
-importFrom(stats,chisq.test)
-importFrom(stats,complete.cases)
-importFrom(stats,cov)
-importFrom(stats,kruskal.test)
-importFrom(stats,lm)
-importFrom(stats,mad)
-importFrom(stats,median)
-importFrom(stats,model.frame)
-importFrom(stats,na.omit)
-importFrom(stats,na.pass)
-importFrom(stats,optim)
-importFrom(stats,pchisq)
-importFrom(stats,pf)
-importFrom(stats,plogis)
-importFrom(stats,pnorm)
-importFrom(stats,prop.test)
-importFrom(stats,pt)
-importFrom(stats,qchisq)
-importFrom(stats,qf)
-importFrom(stats,qlogis)
-importFrom(stats,qnorm)
-importFrom(stats,qt)
-importFrom(stats,quantile)
-importFrom(stats,reformulate)
-importFrom(stats,reshape)
-importFrom(stats,sd)
-importFrom(stats,setNames)
-importFrom(stats,var)
-importFrom(utils,as.roman)
-importFrom(utils,packageVersion)
-importFrom(utils,tail)

---FILE: NEWS.md---
@@ -21,7 +21,7 @@
 
 - Fixed error in `cohens_w()` for 2-by-X tables.  
 - Solved integer overflow errors in `rank_biserial()` ( #476 )
-
+- Fixed issue in `effectsize()` for t-tests when input vectors has unequal amount of missing values.
 
 # effectsize 0.8.2
 

---FILE: R/cohens_d.R---
@@ -127,7 +127,6 @@
 #' - Hunter, J. E., & Schmidt, F. L. (2004). Methods of meta-analysis:
 #' Correcting error and bias in research findings. Sage.
 #'
-#' @importFrom stats var model.frame
 #' @export
 cohens_d <- function(x, y = NULL, data = NULL,
                      pooled_sd = TRUE, mu = 0, paired = FALSE,
@@ -187,7 +186,6 @@ glass_delta <- function(x, y = NULL, data = NULL,
 
 
 
-#' @importFrom stats sd
 #' @keywords internal
 .effect_size_difference <- function(x, y = NULL, data = NULL,
                                     type = ""d"",

---FILE: R/cohens_g.R---
@@ -52,7 +52,6 @@
 #' # Test 2 gives a negative result more than test 1!
 #'
 #' @export
-#' @importFrom stats complete.cases prop.test
 cohens_g <- function(x, y = NULL,
                      ci = 0.95, alternative = ""two.sided"",
                      ...) {

---FILE: R/common_language.R---
@@ -351,7 +351,6 @@ wmw_odds <- function(x, y = NULL, data = NULL,
 # Utils -------------------------------------------------------------------
 
 #' @keywords internal
-#' @importFrom stats quantile optim
 .cohens_u2_non_parametric <- function(..., mu, alternative) {
   U2_np <- function(data, i = seq_len(nrow(data))) {
     data <- data[i, ]
@@ -388,7 +387,7 @@ wmw_odds <- function(x, y = NULL, data = NULL,
     x <- data[data$g == ""x"", ""r""] - mu
     y <- data[data$g == ""y"", ""r""]
 
-    sum(y < median(x)) / length(y)
+    sum(y < stats::median(x)) / length(y)
   }
   out <- .cles_non_parametric(..., est = U3_np)
   colnames(out)[1] <- ""Cohens_U3""
@@ -423,7 +422,6 @@ wmw_odds <- function(x, y = NULL, data = NULL,
 ## BOOT and stuff ---------------
 
 #' @keywords internal
-#' @importFrom utils tail
 .cles_non_parametric <-
   function(x,
            y,

---FILE: R/convert_between_common_language.R---
@@ -60,7 +60,6 @@ d_to_p_superiority <- function(d) {
 }
 
 #' @export
-#' @importFrom stats pnorm
 d_to_p_superiority.numeric <- function(d) {
   stats::pnorm(d / sqrt(2))
 }
@@ -89,7 +88,6 @@ d_to_u2 <- function(d) {
 }
 
 #' @export
-#' @importFrom stats pnorm
 d_to_u2.numeric <- function(d) {
   stats::pnorm(abs(d) / 2)
 }
@@ -117,7 +115,6 @@ d_to_u3 <- function(d) {
 }
 
 #' @export
-#' @importFrom stats pnorm
 d_to_u3.numeric <- function(d) {
   stats::pnorm(d)
 }
@@ -132,7 +129,6 @@ d_to_overlap <- function(d) {
 }
 
 #' @export
-#' @importFrom stats pnorm
 d_to_overlap.numeric <- function(d) {
   2 * stats::pnorm(-abs(d) / 2)
 }

---FILE: R/convert_between_odds_to_probs.R---
@@ -31,7 +31,6 @@ convert_odds_to_probs <- odds_to_probs
 
 
 #' @export
-#' @importFrom stats plogis
 odds_to_probs.numeric <- function(odds, log = FALSE, ...) {
   if (log) {
     stats::plogis(odds)
@@ -59,7 +58,6 @@ probs_to_odds <- function(probs, log = FALSE, ...) {
 convert_probs_to_odds <- probs_to_odds
 
 #' @export
-#' @importFrom stats qlogis
 probs_to_odds.numeric <- function(probs, log = FALSE, ...) {
   if (log) {
     stats::qlogis(probs)

---FILE: R/convert_between_riskdiff.R---
@@ -73,7 +73,7 @@ oddsratio_to_riskratio.default <- function(OR, p0, log = FALSE, verbose = TRUE,
   if (used_intercept) {
     p0 <- RR[[""Coefficient""]][RR$Parameter == ""(Intercept)""]
     if (!log) p0 <- log(p0)
-    p0 <- plogis(p0)
+    p0 <- stats::plogis(p0)
 
     if (verbose) {
       insight::format_warning(

---FILE: R/convert_stat_to_d.R---
@@ -43,7 +43,6 @@ t_to_d <- function(t, df_error,
 
 
 #' @rdname t_to_r
-#' @importFrom stats qnorm
 #' @export
 z_to_d <- function(z, n,
                    paired = FALSE,

---FILE: R/convert_stat_to_r.R---
@@ -131,7 +131,6 @@ t_to_r <- function(t, df_error,
 
 
 #' @rdname t_to_r
-#' @importFrom stats qnorm
 #' @export
 z_to_r <- function(z, n,
                    ci = 0.95, alternative = ""two.sided"",

---FILE: R/effectsize.BFBayesFactor.R---
@@ -1,8 +1,6 @@
 #' @export
 #' @rdname effectsize
 #' @inheritParams bayestestR::describe_posterior
-#' @importFrom insight get_data get_parameters check_if_installed
-#' @importFrom bayestestR describe_posterior
 effectsize.BFBayesFactor <- function(model, type = NULL, ci = 0.95, test = NULL, verbose = TRUE, ...) {
   insight::check_if_installed(""BayesFactor"")
 

---FILE: R/effectsize.htest.R---
@@ -65,21 +65,17 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
       df_error = unname(model$parameter)
     )
   } else {
-    if (grepl("" by "", model$data.name, fixed = TRUE)) {
+    if (ncol(data) == 2) {
       data[[2]] <- factor(data[[2]])
     }
+    data <- stats::na.omit(data)
 
     args <- list(
       x = data[[1]],
       y = if (ncol(data) == 2) data[[2]],
       pooled_sd = !grepl(""Welch"", model$method, fixed = TRUE)
     )
 
-    if (!isTRUE(dots$paired)) {
-      args$x <- stats::na.omit(args$x)
-      args$y <- stats::na.omit(args$y)
-    }
-
     if (type %in% c(""d"", ""g"")) {
       f <- switch(tolower(type),
         d = cohens_d,
@@ -344,6 +340,11 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
 
   .fail_if_approx(approx, type)
 
+  if (ncol(data) == 2) {
+    data[[2]] <- factor(data[[2]])
+  }
+  data <- stats::na.omit(data)
+
   f <- switch(tolower(type),
     rb = rank_biserial,
     u1 = cohens_u1,
@@ -361,11 +362,6 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
     verbose = verbose
   )
 
-  if (!isTRUE(dots$paired)) {
-    args$x <- na.omit(args$x)
-    args$y <- na.omit(args$y)
-  }
-
   if (tolower(type) != ""rb"") {
     if (dots$paired) {
       insight::format_error(""Common language effect size only applicable to 2-sample rank-biserial correlation."")

---FILE: R/eta_squared-main.R---
@@ -315,7 +315,6 @@ cohens_f_squared <- function(model,
 
 
 #' @keywords internal
-#' @importFrom insight model_info
 .cohens_f_delta <- function(model, model2,
                             squared = FALSE,
                             ci = 0.95, alternative = ""greater"",
@@ -329,7 +328,7 @@ cohens_f_squared <- function(model,
   }
 
   # Anova
-  ANOVA <- anova(model, model2)
+  ANOVA <- stats::anova(model, model2)
   out <- F_to_f(ANOVA[2, ""F""], abs(ANOVA[2, ""Df""]), min(ANOVA[""Res.Df""]),
     ci = ci, alternative = alternative,
     squared = squared
@@ -737,7 +736,6 @@ cohens_f_squared <- function(model,
   }
 
 #' @keywords internal
-#' @importFrom stats anova
 .anova_es.default <- function(model,
                               type = c(""eta"", ""omega"", ""epsilon""),
                               partial = TRUE,
@@ -757,8 +755,6 @@ cohens_f_squared <- function(model,
 }
 
 #' @keywords internal
-#' @importFrom parameters model_parameters
-#' @importFrom stats anova
 .anova_es.aov <- function(model,
                           type = c(""eta"", ""omega"", ""epsilon""),
                           partial = TRUE,
@@ -793,8 +789,6 @@ cohens_f_squared <- function(model,
 .anova_es.manova <- .anova_es.aov
 
 #' @keywords internal
-#' @importFrom parameters model_parameters
-#' @importFrom insight find_predictors
 .anova_es.aovlist <- function(model,
                               type = c(""eta"", ""omega"", ""epsilon""),
                               partial = TRUE,

---FILE: R/eta_squared-methods.R---
@@ -1,8 +1,6 @@
 # Specific models ---------------------------------------------------------
 
 #' @keywords internal
-#' @importFrom stats aov
-#' @importFrom utils packageVersion
 .anova_es.mlm <- function(model,
                           type = c(""eta"", ""omega"", ""epsilon""),
                           partial = TRUE,
@@ -46,7 +44,6 @@
 #' @keywords internal
 .anova_es.anova.lme <- .anova_es.anova
 
-#' @importFrom stats na.omit
 #' @keywords internal
 .anova_es.parameters_model <- function(model,
                                        type = c(""eta"", ""omega"", ""epsilon""),
@@ -66,10 +63,7 @@
       ...
     )
     saved_attr <- attributes(out[[1]])
-    out <- mapply(out, names(out),
-      FUN = function(x, nm) cbind(Response = nm, x),
-      SIMPLIFY = FALSE
-    )
+    out <- Map(function(x, nm) cbind(Response = nm, x), out, names(out))
     out <- do.call(rbind, out)
     out$Parameter <- as.character(out$Parameter)
 
@@ -152,8 +146,7 @@
            include_intercept = FALSE,
            ...) {
     # Faking the model_parameters.aovlist output:
-    aov_tab <- summary(model)$univariate.tests
-    suppressWarnings(aov_tab)
+    suppressWarnings(aov_tab <- summary(model)$univariate.tests) # nolint
     if (is.null(aov_tab)) {
       aov_tab <- parameters::model_parameters(model)
       aov_tab$df <- aov_tab$df_num
@@ -165,7 +158,7 @@
         include_intercept = include_intercept,
         verbose = verbose
       )
-      attr(out, ""anova_type"") <- as.numeric(as.roman(model$type))
+      attr(out, ""anova_type"") <- as.numeric(utils::as.roman(model$type))
       attr(out, ""approximate"") <- FALSE
       return(out)
     }
@@ -179,15 +172,15 @@
     within <- names(model$idata)
     within <- lapply(within, function(x) c(NA, x))
     within <- do.call(expand.grid, within)
-    within <- apply(within, 1, na.omit)
-    ns <- lengths(within)
+    within <- apply(within, 1, stats::na.omit)
+    ns <- sapply(within, length) # nolint
     within <- sapply(within, paste, collapse = "":"")
     within <- within[order(ns)]
     within <- Filter(function(x) nchar(x) > 0, within)
     l <- sapply(within, grepl, x = aov_tab$Parameter, simplify = TRUE)
     l <- apply(l, 1, function(x) if (!any(x)) 0 else max(which(x)))
     l <- c(NA, within)[l + 1]
-    l <- sapply(l, function(x) paste0(na.omit(c(id, x)), collapse = "":""))
+    l <- sapply(l, function(x) paste0(stats::na.omit(c(id, x)), collapse = "":""))
     aov_tab$Group <- l
 
     aov_tab <- split(aov_tab, aov_tab$Group)
@@ -228,15 +221,13 @@
     }
     out <- out[match(out$Parameter, orig_terms), ]
 
-    attr(out, ""anova_type"") <- as.numeric(as.roman(model$type))
+    attr(out, ""anova_type"") <- as.numeric(utils::as.roman(model$type))
     attr(out, ""approximate"") <- FALSE
     out
   }
 
 
 #' @keywords internal
-#' @importFrom stats anova
-#' @importFrom insight check_if_installed
 .anova_es.merMod <- function(model,
                              type = c(""eta"", ""omega"", ""epsilon""),
                              partial = TRUE,
@@ -263,7 +254,6 @@
 }
 
 #' @keywords internal
-#' @importFrom stats anova
 .anova_es.gam <- function(model,
                           type = c(""eta"", ""omega"", ""epsilon""),
                           partial = TRUE,
@@ -358,7 +348,6 @@
 
 
 #' @keywords internal
-#' @importFrom stats anova
 .anova_es.rms <- function(model,
                           type = c(""eta"", ""omega"", ""epsilon""),
                           partial = TRUE,

---FILE: R/eta_squared_posterior.R---
@@ -18,8 +18,6 @@ eta_squared_posterior <- function(model,
 }
 
 #' @export
-#' @importFrom stats lm setNames
-#' @importFrom insight find_formula get_predictors find_response check_if_installed
 eta_squared_posterior.stanreg <- function(model,
                                           partial = TRUE,
                                           generalized = FALSE,
@@ -111,7 +109,6 @@ eta_squared_posterior.brmsfit <- eta_squared_posterior.stanreg
 
 
 #' #' @keywords internal
-#' #' @importFrom stats contrasts
 #' .all_centered <- function(X) {
 #'   numeric <- sapply(X, inherits, what = c(""numeric"", ""integer""))
 #'   numerics <- colnames(X)[numeric]

---FILE: R/format_standardize.R---
@@ -15,8 +15,6 @@
 #'
 #' format_standardize(standardize(mtcars$wt), digits = 1)
 #' format_standardize(standardize(mtcars$wt, robust = TRUE), digits = 1)
-#' @importFrom stats median mad sd
-#' @importFrom insight format_value
 #' @export
 format_standardize <- function(x, reference = x, robust = FALSE, digits = 1, protect_integers = TRUE, ...) {
   # Check if robust info stored in attributes
@@ -59,7 +57,7 @@ format_standardize <- function(x, reference = x, robust = FALSE, digits = 1, pro
   L <- insight::format_value(x, digits = digits, ...)
 
   # Complete
-  L[!grepl(""-"", L)] <- paste0(""+"", L[!grepl(""-"", L)])
+  L[!grepl(""-"", L, fixed = TRUE)] <- paste0(""+"", L[!grepl(""-"", L, fixed = TRUE)])
   L <- paste(L, deviation_name)
   L[x == 0] <- central_name
 

---FILE: R/mahalanobis_D.R---
@@ -79,7 +79,6 @@
 #'   mu = c(mpg = 15, hp = 5, cyl = 3)
 #' )
 #'
-#' @importFrom stats cov
 #' @export
 mahalanobis_d <- function(x, y = NULL, data = NULL,
                           pooled_cov = TRUE, mu = 0,
@@ -109,7 +108,7 @@ mahalanobis_d <- function(x, y = NULL, data = NULL,
     insight::format_error(""mu must be of length 1 or a named vector/list of length ncol(x)."")
   } else if (!all(names(mu) == colnames(x))) {
     insight::format_error(""x,y must have the same variables (in the same order)"")
-  } else if (!all(lengths(mu) == 1L) || !all(sapply(mu, is.numeric))) {
+  } else if (!all(lengths(mu) == 1L) || !all(vapply(mu, is.numeric, TRUE))) {
     insight::format_error(""Each element of mu must be a numeric vector of length 1."")
   }
   mu <- unlist(mu)

---FILE: R/means_ratio.R---
@@ -164,7 +164,7 @@ means_ratio <- function(x, y = NULL, data = NULL,
     if (!is.null(ci)) {
       out[c(""CI_low"", ""CI_high"")] <- exp(out[c(""CI_low"", ""CI_high"")])
     }
-    colnames(out)[1] <- gsub(""log_"", """", colnames(out)[1])
+    colnames(out)[1] <- gsub(""log_"", """", colnames(out)[1], fixed = TRUE)
   }
 
   class(out) <- c(""effectsize_difference"", ""effectsize_table"", ""see_effectsize_table"", class(out))
@@ -177,9 +177,7 @@ means_ratio <- function(x, y = NULL, data = NULL,
 }
 
 
-#' @importFrom stats sd
 #' @keywords internal
-
 .logrom_calc <- function(paired = FALSE,
                          m1,
                          sd1,

---FILE: R/plot.R---
@@ -1,6 +1,5 @@
 #' @rdname print.effectsize_table
 #' @export
-#' @importFrom insight check_if_installed
 plot.effectsize_table <- function(x, ...) {
   insight::check_if_installed(""see"", reason = ""for plotting"")
   NextMethod()

---FILE: R/pooled.R---
@@ -23,10 +23,8 @@
 #'
 #' @seealso [cohens_d()], [mahalanobis_d()]
 #'
-#' @importFrom stats ave sd
 #' @export
-sd_pooled <- function(x, y = NULL, data = NULL,
-                      verbose = TRUE, ...) {
+sd_pooled <- function(x, y = NULL, data = NULL, verbose = TRUE, ...) {
   data <- .get_data_2_samples(x, y, data, verbose = verbose, ...)
   x <- data[[""x""]]
   y <- data[[""y""]]
@@ -35,13 +33,12 @@ sd_pooled <- function(x, y = NULL, data = NULL,
     data.frame(x = x),
     data.frame(x = y)
   )
-  c(sqrt(V))
+  as.vector(sqrt(V))
 }
 
 
 
 #' @rdname sd_pooled
-#' @importFrom stats ave mad median
 #' @export
 mad_pooled <- function(x, y = NULL, data = NULL,
                        constant = 1.4826,
@@ -62,7 +59,6 @@ mad_pooled <- function(x, y = NULL, data = NULL,
 
 
 #' @rdname sd_pooled
-#' @importFrom stats cov
 #' @export
 cov_pooled <- function(x, y = NULL, data = NULL,
                        verbose = TRUE, ...) {

---FILE: R/print.effectsize_table.R---
@@ -40,7 +40,8 @@ format.effectsize_table <- function(x, digits = 2, output = c(""text"", ""markdown""
   ## Clean footer
   footer <- attr(x, ""table_footer"")
 
-  if (!is.null(alt <- attr(x, ""alternative"")) && alt != ""two.sided"") {
+  alt <- attr(x, ""alternative"")
+  if (!is.null(alt) && alt != ""two.sided"") {
     bound <- if (alt == ""less"") x$CI_low[1] else x$CI_high[1]
     bound_ <- insight::format_value(bound, digits = digits)
     if (!is.character(digits) &&
@@ -62,7 +63,8 @@ format.effectsize_table <- function(x, digits = 2, output = c(""text"", ""markdown""
   #   footer <- c(footer, approx_footer)
   # }
 
-  if (!is.null(rule_name <- attr(attr(x, ""rules""), ""rule_name"", exact = TRUE))) {
+  rule_name <- attr(attr(x, ""rules""), ""rule_name"", exact = TRUE)
+  if (!is.null(rule_name)) {
     rule_footer <- sprintf(""Interpretation rule: %s"", rule_name)
     footer <- c(footer, rule_footer)
   }
@@ -163,7 +165,8 @@ format.effectsize_difference <- function(x, digits = 2, ...) {
     footer <- c(footer, mu_footer)
   }
 
-  if (!is.null(sd_type <- attr(x, ""pooled_sd"", exact = TRUE))) {
+  sd_type <- attr(x, ""pooled_sd"", exact = TRUE)
+  if (!is.null(sd_type)) {
     sd_type <- sprintf(
       ""Estimated using %spooled SD."",
       ifelse(sd_type, """", ""un-"")
@@ -179,7 +182,6 @@ format.effectsize_difference <- function(x, digits = 2, ...) {
 }
 
 #' @export
-#' @importFrom utils as.roman
 format.effectsize_anova <- function(x, digits = 2, ...) {
   footer <- caption <- subtitle <- NULL
 
@@ -198,7 +200,7 @@ format.effectsize_anova <- function(x, digits = 2, ...) {
     if (isTRUE(obs)) {
       obs <- ""All""
     } else {
-      obs <- paste0(obs, collapse = "", "")
+      obs <- toString(obs)
     }
     gen_footer <- sprintf(""Observed variables: %s"", obs)
     footer <- c(footer, gen_footer)

---FILE: R/r2_semipartial.R---
@@ -145,13 +145,13 @@ r2_semipartial.lm <- function(model, type = c(""terms"", ""parameters""),
 
     # Fix lower bound according to sig
     p_comps <- sapply(sub_mods, function(.mod) {
-      anova(tot_mod, .mod)[2, ""Pr(>F)""]
+      stats::anova(tot_mod, .mod)[2, ""Pr(>F)""]
     })
 
     is_sig <- p_comps < (1 - ci)
     lb_is_zero <- out$CI_low == 0
 
-    if (any(!is_sig)) {
+    if (!all(is_sig)) {
       out$CI_low[!is_sig] <- 0
     }
 

---FILE: R/rank_ANOVA.R---
@@ -84,7 +84,6 @@
 #' sport sciences, 1(21), 19-25.
 #'
 #' @export
-#' @importFrom insight check_if_installed
 rank_epsilon_squared <- function(x, groups, data = NULL,
                                  ci = 0.95, alternative = ""greater"",
                                  iterations = 200,
@@ -125,7 +124,6 @@ rank_epsilon_squared <- function(x, groups, data = NULL,
 
 #' @export
 #' @rdname rank_epsilon_squared
-#' @importFrom insight check_if_installed
 rank_eta_squared <- function(x, groups, data = NULL,
                              ci = 0.95, alternative = ""greater"",
                              iterations = 200,
@@ -170,8 +168,6 @@ rank_eta_squared <- function(x, groups, data = NULL,
 
 #' @rdname rank_epsilon_squared
 #' @export
-#' @importFrom stats na.omit
-#' @importFrom insight check_if_installed
 kendalls_w <- function(x, groups, blocks, data = NULL,
                        blocks_on_rows = TRUE,
                        ci = 0.95, alternative = ""greater"",
@@ -216,7 +212,6 @@ kendalls_w <- function(x, groups, blocks, data = NULL,
 ## Get ----
 
 #' @keywords internal
-#' @importFrom stats kruskal.test
 .repsilon <- function(data) {
   model <- suppressWarnings(stats::kruskal.test(data$x, data$groups))
 
@@ -227,7 +222,6 @@ kendalls_w <- function(x, groups, blocks, data = NULL,
 }
 
 #' @keywords internal
-#' @importFrom stats kruskal.test
 .reta <- function(data) {
   model <- suppressWarnings(stats::kruskal.test(data$x, data$groups))
 
@@ -270,7 +264,7 @@ kendalls_w <- function(x, groups, blocks, data = NULL,
     W <- (12 * sum(R^2) - 3 * (m^2) * n * ((n + 1)^2)) /
       (m^2 * (n^3 - n) - m * Tj)
   } else {
-    S <- var(R) * (n - 1)
+    S <- stats::var(R) * (n - 1)
     W <- (12 * S) /
       (m^2 * (n^3 - n))
   }
@@ -279,7 +273,6 @@ kendalls_w <- function(x, groups, blocks, data = NULL,
 
 ## CI ----
 
-#' @importFrom utils tail
 #' @keywords internal
 .boot_two_group_es <- function(data, foo_es, iterations,
                                ci, alternative, lim) {
@@ -301,7 +294,7 @@ kendalls_w <- function(x, groups, blocks, data = NULL,
   )
 
   bCI <- boot::boot.ci(R, conf = ci.level, type = ""perc"")$percent
-  bCI <- tail(as.vector(bCI), 2)
+  bCI <- utils::tail(as.vector(bCI), 2)
 
   out <- data.frame(
     CI = ci,
@@ -311,7 +304,6 @@ kendalls_w <- function(x, groups, blocks, data = NULL,
   .limit_ci(out, alternative, 0, 1)
 }
 
-#' @importFrom utils tail
 #' @keywords internal
 .kendalls_w_ci <- function(data, ci, alternative, iterations) {
   ci.level <- .adjust_ci(ci, alternative)
@@ -327,7 +319,7 @@ kendalls_w <- function(x, groups, blocks, data = NULL,
   )
 
   bCI <- boot::boot.ci(R, conf = ci.level, type = ""perc"")$percent
-  bCI <- tail(as.vector(bCI), 2)
+  bCI <- utils::tail(as.vector(bCI), 2)
 
   out <- data.frame(
     CI = ci,

---FILE: R/rank_diff.R---
@@ -174,7 +174,7 @@ rank_biserial <- function(x, y = NULL, data = NULL,
       rfSE <- sqrt((n1 + n2 + 1) / (3 * n1 * n2))
     }
 
-    confint <- tanh(rf + c(-1, 1) * qnorm(1 - alpha / 2) * rfSE)
+    confint <- tanh(rf + c(-1, 1) * stats::qnorm(1 - alpha / 2) * rfSE)
     out$CI_low <- confint[1]
     out$CI_high <- confint[2]
     ci_method <- list(method = ""normal"")
@@ -221,7 +221,6 @@ cliffs_delta <- function(x, y = NULL, data = NULL,
 # Utils -------------------------------------------------------------------
 
 #' @keywords internal
-#' @importFrom stats na.omit
 .r_rbs <- function(x, y, mu, paired, verbose = FALSE) {
   if (paired) {
     Ry <- .safe_ranktransform((x - y) - mu, sign = TRUE, verbose = verbose)

---FILE: R/utils.R---
@@ -27,7 +27,6 @@
 }
 
 #' @keywords internal
-#' @importFrom insight model_info
 .get_model_info <- function(model, model_info = NULL, ...) {
   if (is.null(model_info)) model_info <- insight::model_info(model)
 

---FILE: R/utils_ci.R---
@@ -1,7 +1,6 @@
 # NCP -------------------------
 
 #' @keywords internal
-#' @importFrom stats pf qf optim
 .get_ncp_F <- function(f, df, df_error, conf.level = 0.9) {
   if (!is.finite(f) || !is.finite(df) || !is.finite(df_error)) {
     return(c(NA, NA))
@@ -35,9 +34,6 @@
 }
 
 #' @keywords internal
-#' @importFrom stats pt
-#' @importFrom stats qt
-#' @importFrom stats optim
 .get_ncp_t <- function(t, df_error, conf.level = 0.95) {
   # # Note: these aren't actually needed - all t related functions would fail earlier
   # if (!is.finite(t) || !is.finite(df_error)) {
@@ -47,10 +43,10 @@
   alpha <- 1 - conf.level
   probs <- c(alpha / 2, 1 - alpha / 2)
 
-  ncp <- suppressWarnings(optim(
+  ncp <- suppressWarnings(stats::optim(
     par = 1.1 * rep(t, 2),
     fn = function(x) {
-      p <- pt(q = t, df = df_error, ncp = x)
+      p <- stats::pt(q = t, df = df_error, ncp = x)
 
       abs(max(p) - probs[2]) +
         abs(min(p) - probs[1])
@@ -63,7 +59,6 @@
 }
 
 #' @keywords internals
-#' @importFrom stats pchisq qchisq optim
 .get_ncp_chi <- function(chi, df, conf.level = 0.95) {
   # # Note: these aren't actually needed - all chisq related functions would fail earlier
   # if (!is.finite(chi) || !is.finite(df)) {

---FILE: R/utils_validate_input_data.R---
@@ -1,5 +1,4 @@
 #' @keywords internal
-#' @importFrom stats na.omit complete.cases
 .get_data_2_samples <- function(x, y = NULL, data = NULL,
                                 paired = FALSE, allow_ordered = FALSE,
                                 verbose = TRUE, ...) {
@@ -98,7 +97,8 @@
 #' @keywords internal
 .get_data_xtabs <- function(x, y = NULL, p = NULL) {
   # TODO dont rely on chisq.test
-  res <- suppressWarnings(stats::chisq.test(x,
+  res <- suppressWarnings(stats::chisq.test(
+    x,
     y = y,
     p = p,
     correct = FALSE,
@@ -128,7 +128,7 @@
     groups <- mf[[2]]
     if (!is.factor(groups)) groups <- factor(groups)
   } else if (inherits(x, ""list"")) {
-    groups <- rep(letters[seq_along(x)], sapply(x, length))
+    groups <- rep(letters[seq_along(x)], sapply(x, length)) # nolint
     x <- unsplit(x, groups)
   } else {
     # If they are column names
@@ -161,7 +161,6 @@
 }
 
 #' @keywords internal
-#' @importFrom stats reshape
 .get_data_nested_groups <- function(x, groups = NULL, blocks = NULL, data = NULL,
                                     wide = TRUE, allow_ordered = FALSE,
                                     verbose = TRUE, ...) {
@@ -197,7 +196,7 @@
     x <- as.table(x)
   }
 
-  if (inherits(x, c(""table""))) {
+  if (inherits(x, ""table"")) {
     x <- as.data.frame(x)[, c(3, 2, 1)]
   }
 
@@ -231,7 +230,6 @@
 }
 
 #' @keywords internal
-#' @importFrom stats na.pass reformulate
 .get_data_multivariate <- function(x, y = NULL, data = NULL,
                                    verbose = TRUE, ...) {
   if (inherits(x, ""formula"")) {
@@ -266,7 +264,7 @@
     insight::format_error(""x must be a data frame."")
   }
 
-  if (!all(sapply(x, is.numeric))) {
+  if (!all(vapply(x, is.numeric, TRUE))) {
     insight::format_error(""All DVs must be numeric."")
   }
 
@@ -279,7 +277,7 @@
       insight::format_error(""y must be a data frame."")
     }
 
-    if (!all(sapply(y, is.numeric))) {
+    if (!all(vapply(y, is.numeric, TRUE))) {
       insight::format_error(""All DVs must be numeric."")
     }
 
@@ -302,7 +300,6 @@
 
 
 #' @keywords internal
-#' @importFrom stats model.frame na.pass
 .resolve_formula <- function(formula, data, subset, na.action = stats::na.pass, ...) {
   cl <- match.call(expand.dots = FALSE)
   cl[[1]] <- quote(stats::model.frame)

---FILE: R/xtab_corr.R---
@@ -99,7 +99,6 @@
 #' tests to effect sizes for meta-analysis. PloS one, 5(4), e10059.
 #'
 #'
-#' @importFrom stats chisq.test
 #' @export
 phi <- function(x, y = NULL,
                 adjust = TRUE,
@@ -118,7 +117,6 @@ phi <- function(x, y = NULL,
 }
 
 #' @rdname phi
-#' @importFrom stats chisq.test
 #' @export
 cramers_v <- function(x, y = NULL,
                       adjust = TRUE,
@@ -138,7 +136,6 @@ cramers_v <- function(x, y = NULL,
 
 
 #' @rdname phi
-#' @importFrom stats chisq.test
 #' @export
 tschuprows_t <- function(x, y = NULL,
                          ci = 0.95, alternative = ""greater"",
@@ -156,7 +153,6 @@ tschuprows_t <- function(x, y = NULL,
 }
 
 #' @rdname phi
-#' @importFrom stats chisq.test
 #' @export
 cohens_w <- function(x, y = NULL, p = rep(1, length(x)),
                      ci = 0.95, alternative = ""greater"",
@@ -178,7 +174,6 @@ cohens_w <- function(x, y = NULL, p = rep(1, length(x)),
 
 
 #' @rdname phi
-#' @importFrom stats chisq.test
 #' @export
 fei <- function(x, p = rep(1, length(x)),
                 ci = 0.95, alternative = ""greater"",
@@ -196,7 +191,6 @@ fei <- function(x, p = rep(1, length(x)),
 }
 
 #' @rdname phi
-#' @importFrom stats chisq.test
 #' @export
 pearsons_c <- function(x, y = NULL, p = rep(1, length(x)),
                        ci = 0.95, alternative = ""greater"",

---FILE: R/xtab_diff.R---
@@ -56,7 +56,6 @@
 #' nnt(RCT_table)
 #'
 #' @export
-#' @importFrom stats chisq.test qnorm
 oddsratio <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = FALSE, ...) {
   alternative <- .match.alt(alternative)
 
@@ -117,7 +116,6 @@ oddsratio <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = F
 
 #' @rdname oddsratio
 #' @export
-#' @importFrom stats chisq.test qnorm
 riskratio <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = FALSE, ...) {
   alternative <- .match.alt(alternative)
 
@@ -181,7 +179,6 @@ riskratio <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = F
 
 #' @rdname oddsratio
 #' @export
-#' @importFrom stats qnorm
 cohens_h <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...) {
   alternative <- .match.alt(alternative)
 
@@ -238,7 +235,6 @@ cohens_h <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...) {
 
 #' @rdname oddsratio
 #' @export
-#' @importFrom stats qnorm
 arr <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...) {
   alternative <- .match.alt(alternative)
 
@@ -295,7 +291,6 @@ arr <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...) {
 
 #' @rdname oddsratio
 #' @export
-#' @importFrom stats qnorm
 nnt <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...) {
   alternative <- .match.alt(alternative)
 

---FILE: tests/testthat/test-effectsize.R---
@@ -45,6 +45,13 @@ test_that(""t-test"", {
     cohens_d(z, mu = 3),
     ignore_attr = TRUE
   )
+
+  ## Missing
+  y <<- rnorm(12)
+  g <<- c(rep(letters[1:2], each = 5), NA, NA)
+  tt <- t.test(y ~ g, var.equal = TRUE)
+
+  expect_equal(effectsize(tt), cohens_d(y ~ g), ignore_attr = TRUE)
 })
 
 test_that(""t-test | CLES"", {
@@ -71,7 +78,7 @@ test_that(""t-test | CLES"", {
 test_that(""Wilcox | CLES"", {
   x <<- 1:4
   y <<- c(1, 1:3)
-  Wt <- suppressWarnings(wilcox.test(x, y, var.equal = TRUE))
+  Wt <- suppressWarnings(wilcox.test(x, y))
 
   expect_equal(e <- p_superiority(Wt), p_superiority(x, y, parametric = FALSE), ignore_attr = TRUE)
   expect_equal(effectsize(Wt, type = ""p_superiority""), e)",True,False,Documentation / Formatting,6
easystats,effectsize,1f82dc551bb67537cf5b09939f6c37365305e736,Indrajeet Patil,patilindrajeet.science@gmail.com,2023-02-08T06:33:43Z,Indrajeet Patil,patilindrajeet.science@gmail.com,2023-02-08T06:33:43Z,fix spelling mistakes,NEWS.md;vignettes/convert_p_OR_RR.Rmd,True,False,True,False,2,2,4,"---FILE: NEWS.md---
@@ -1,4 +1,4 @@
-# effectsize 0.8.3.xxxx
+# effectsize (development version)
 
 ## New features
 

---FILE: vignettes/convert_p_OR_RR.Rmd---
@@ -104,7 +104,7 @@ That is - for every bowl of brussels sprouts, we increase the chances of
 reducing the migraine by a mere 12%! Is if worth it? Depends on you affinity to
 brussels sprouts...
 
-Similiarly, we can look at ARR, which can be converted via
+Similarly, we can look at ARR, which can be converted via
 
 $$
 ARR = RR \times p0 - p0",False,True,Documentation / Formatting,4
easystats,effectsize,62bad98e2773ab566d52eab358b934ad636edae2,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2023-02-02T21:24:40Z,GitHub,noreply@github.com,2023-02-02T21:24:40Z,"ARR / NNT (#561)

* init

* Apply automatic changes

* temp fix on grepl

* arr nnt converters

* rename file

* tests

* vignettes

---------

Co-authored-by: mattansb <mattansb@users.noreply.github.com>",DESCRIPTION;NAMESPACE;NEWS.md;R/convert_between_riskdiff.R;R/effectsize.BFBayesFactor.R;R/effectsize.R;R/effectsize.htest.R;R/sysdata.rda;R/xtab_diff.R;data-raw/es_info.R;man/effectsize.Rd;man/oddsratio.Rd;man/oddsratio_to_riskratio.Rd;tests/testthat/test-convert_between.R;tests/testthat/test-xtab.R;vignettes/convert_p_OR_RR.Rmd;vignettes/xtabs.Rmd,True,True,True,False,288,41,329,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size
-Version: 0.8.3.1
+Version: 0.8.3.2
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",

---FILE: NAMESPACE---
@@ -62,6 +62,10 @@ export(F_to_f)
 export(F_to_f2)
 export(F_to_omega2)
 export(F_to_r)
+export(arr)
+export(arr_to_nnt)
+export(arr_to_oddsratio)
+export(arr_to_riskratio)
 export(chisq_to_cohens_w)
 export(chisq_to_cramers_v)
 export(chisq_to_fei)
@@ -166,9 +170,12 @@ export(logoddsratio_to_r)
 export(mad_pooled)
 export(mahalanobis_d)
 export(means_ratio)
+export(nnt)
+export(nnt_to_arr)
 export(normalized_chi)
 export(odds_to_probs)
 export(oddsratio)
+export(oddsratio_to_arr)
 export(oddsratio_to_d)
 export(oddsratio_to_r)
 export(oddsratio_to_riskratio)
@@ -193,6 +200,7 @@ export(rb_to_p_superiority)
 export(rb_to_vda)
 export(rb_to_wmw_odds)
 export(riskratio)
+export(riskratio_to_arr)
 export(riskratio_to_oddsratio)
 export(rules)
 export(sd_pooled)

---FILE: NEWS.md---
@@ -1,3 +1,10 @@
+# effectsize 0.8.3.xxxx
+
+## New features
+
+- `arr()` and `nnt()` for Absolute Risk Reduction or Number Needed to Treat.
+- `oddsratio_to_arr()`, `riskratio_to_arr()`, `nnt_to_arr()` and their inverses.
+
 # effectsize 0.8.3
 
 ## Changes

---FILE: R/convert_between_riskdiff.R---
@@ -1,7 +1,9 @@
 #' Convert Between Odds Ratios and Risk Ratios
 #'
-#' @param OR,RR Risk ratio of `p1/p0` or Odds ratio of `odds(p1)/odds(p0)`,
-#'   possibly log-ed. `OR` can also be a logistic regression model.
+#' @param OR,RR,ARR Risk ratio of `p1/p0` Odds ratio of `odds(p1)/odds(p0)`
+#'   (possibly log-ed), or Absolute Risk Reduction or `p1 - p0`. `OR` can also
+#'   be a logistic regression model.
+#' @param x Absolute Risk Reduction or Number Needed to Treat.
 #' @param p0 Baseline risk
 #' @param ... Arguments passed to and from other methods.
 #' @inheritParams oddsratio_to_d
@@ -11,23 +13,28 @@
 #'   parameter table with the converted indices.
 #'
 #' @family convert between effect sizes
-#' @seealso [oddsratio()] and [riskratio()]
+#' @seealso [oddsratio()], [riskratio()], [arr()], and [nnt()].
 #'
 #' @examples
 #' p0 <- 0.4
 #' p1 <- 0.7
 #'
 #' (OR <- probs_to_odds(p1) / probs_to_odds(p0))
 #' (RR <- p1 / p0)
+#' (ARR <- p1 - p0)
+#' (NNT <- arr_to_nnt(ARR))
 #'
 #' riskratio_to_oddsratio(RR, p0 = p0)
 #' oddsratio_to_riskratio(OR, p0 = p0)
+#' riskratio_to_arr(RR, p0 = p0)
+#' arr_to_oddsratio(nnt_to_arr(NNT), p0 = p0)
 #'
 #' m <- glm(am ~ factor(cyl),
 #'   data = mtcars,
 #'   family = binomial()
 #' )
 #' oddsratio_to_riskratio(m, verbose = FALSE) # RR is relative to the intercept if p0 not provided
+#'
 #' @references
 #'
 #' Grant, R. L. (2014). Converting an odds ratio to a range of plausible
@@ -113,3 +120,43 @@ riskratio_to_oddsratio <- function(RR, p0, log = FALSE, verbose = TRUE, ...) {
   if (log) OR <- log(OR)
   return(OR)
 }
+
+#' @rdname oddsratio_to_riskratio
+#' @export
+riskratio_to_arr <- function(RR, p0, log = FALSE, verbose = TRUE, ...) {
+  if (log) RR <- exp(RR)
+  RR * p0 - p0
+}
+
+#' @rdname oddsratio_to_riskratio
+#' @export
+oddsratio_to_arr <- function(OR, p0, log = FALSE, verbose = TRUE, ...) {
+  if (log) OR <- exp(OR)
+  RR <- oddsratio_to_riskratio(OR, p0, log = FALSE, verbose = verbose)
+  riskratio_to_arr(RR, p0, verbose = verbose)
+}
+
+#' @rdname oddsratio_to_riskratio
+#' @export
+arr_to_riskratio <- function(ARR, p0, log = FALSE, verbose = TRUE, ...) {
+  RR <- ARR / p0 + 1
+  if (log) RR <- log(RR)
+  RR
+}
+
+#' @rdname oddsratio_to_riskratio
+#' @export
+arr_to_oddsratio <- function(ARR, p0, log = FALSE, verbose = TRUE, ...) {
+  RR <- arr_to_riskratio(ARR, p0, log = log, verbose = verbose)
+  riskratio_to_oddsratio(RR, p0, log = log, verbose = verbose)
+}
+
+#' @rdname oddsratio_to_riskratio
+#' @export
+arr_to_nnt <- function(x) {
+  1 / x
+}
+
+#' @rdname oddsratio_to_riskratio
+#' @export
+nnt_to_arr <- arr_to_nnt

---FILE: R/effectsize.BFBayesFactor.R---
@@ -63,7 +63,9 @@ effectsize.BFBayesFactor <- function(model, type = NULL, ci = 0.95, test = NULL,
     or = ,
     oddsratio = oddsratio,
     rr = ,
-    riskratio = riskratio
+    riskratio = riskratio,
+    arr = arr,
+    nnt = nnt
   )
   data <- insight::get_data(model)
   posts <- insight::get_parameters(model)

---FILE: R/effectsize.R---
@@ -12,7 +12,7 @@
 #'
 #' - For an object of class `htest`, data is extracted via [insight::get_data()], and passed to the relevant function according to:
 #'   - A **t-test** depending on `type`: `""cohens_d""` (default), `""hedges_g""`, or one of `""p_superiority""`, `""u1""`, `""u2""`, `""u3""`, `""overlap""`.
-#'   - A **Chi-squared tests of independence** or **Fisher's Exact Test**, depending on `type`: `""cramers_v""` (default), `""tschuprows_t""`, `""phi""`, `""cohens_w""`, `""pearsons_c""`, `""cohens_h""`, `""oddsratio""`, or `""riskratio""`.
+#'   - A **Chi-squared tests of independence** or **Fisher's Exact Test**, depending on `type`: `""cramers_v""` (default), `""tschuprows_t""`, `""phi""`, `""cohens_w""`, `""pearsons_c""`, `""cohens_h""`, `""oddsratio""`, `""riskratio""`, `""arr""`, or `""nnt""`.
 #'   - A **Chi-squared tests of goodness-of-fit**, depending on `type`: `""fei""` (default) `""cohens_w""`, `""pearsons_c""`
 #'   - A **One-way ANOVA test**, depending on `type`: `""eta""` (default), `""omega""` or `""epsilon""` -squared, `""f""`, or `""f2""`.
 #'   - A **McNemar test** returns *Cohen's g*.
@@ -23,7 +23,7 @@
 #' - For an object of class `BFBayesFactor`, using [bayestestR::describe_posterior()],
 #'   - A **t-test** depending on `type`: `""cohens_d""` (default) or one of `""p_superiority""`, `""u1""`, `""u2""`, `""u3""`, `""overlap""`.
 #'   - A **correlation test** returns *r*.
-#'   - A **contingency table test**, depending on `type`: `""cramers_v""` (default), `""phi""`, `""tschuprows_t""`, `""cohens_w""`, `""pearsons_c""`, `""cohens_h""`, `""oddsratio""`, or `""riskratio""`.
+#'   - A **contingency table test**, depending on `type`: `""cramers_v""` (default), `""phi""`, `""tschuprows_t""`, `""cohens_w""`, `""pearsons_c""`, `""cohens_h""`, `""oddsratio""`, or `""riskratio""`, `""arr""`, or `""nnt""`.
 #'   - A **proportion test** returns *p*.
 #' - Objects of class `anova`, `aov`, `aovlist` or `afex_aov`, depending on `type`: `""eta""` (default), `""omega""` or `""epsilon""` -squared, `""f""`, or `""f2""`.
 #' - Other objects are passed to [parameters::standardize_parameters()].
@@ -78,6 +78,7 @@
 #' bf_xtab <- BayesFactor::contingencyTableBF(RCT_table, sampleType = ""poisson"", fixedMargin = ""cols"")
 #' effectsize(bf_xtab)
 #' effectsize(bf_xtab, type = ""oddsratio"")
+#' effectsize(bf_xtab, type = ""arr"")
 #'
 #' bf_ttest <- BayesFactor::ttestBF(sleep$extra[sleep$group == 1],
 #'   sleep$extra[sleep$group == 2],

---FILE: R/effectsize.htest.R---
@@ -125,7 +125,7 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
 
   if (is.null(type)) type <- ""cramers_v""
 
-  if (grepl(""(c|v|t|w|phi)$"", tolower(type))) {
+  if (grepl(""(c|v|t|w|phi)$"", tolower(type)) && tolower(type) != ""nnt"") {
     f <- switch(tolower(type),
       v = ,
       cramers_v = chisq_to_cramers_v,
@@ -153,7 +153,9 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
       rr = ,
       riskratio = riskratio,
       h = ,
-      cohens_h = cohens_h
+      cohens_h = cohens_h,
+      arr = arr,
+      nnt = nnt
     )
 
     out <- f(x = model$observed, ...)

---FILE: R/xtab_diff.R---
@@ -1,6 +1,8 @@
-#' Odds Ratios, Risk Ratios and Cohen's *h* for 2-by-2 Contingency Tables
+#' Odds Ratios, Risk Ratios and Other Effect Sizes for 2-by-2 Contingency Tables
 #'
-#' Report with any [`stats::chisq.test()`] or [`stats::fisher.test()`].
+#' Compute Odds Ratios, Risk Ratios, Cohen's *h*, Absolute Risk Reduction or
+#' Number Needed to Treat. Report with any [`stats::chisq.test()`] or
+#' [`stats::fisher.test()`].
 #' \cr\cr
 #' Note that these are computed with each **column** representing the different
 #' groups, and the *first* column representing the treatment group and the
@@ -21,15 +23,14 @@
 #' @details
 #'
 #' # Confidence (Compatibility) Intervals (CIs)
-#' For Odds ratios, Risk ratios and Cohen's *h*, confidence intervals are
-#' estimated using the standard normal parametric method (see Katz et al., 1978;
-#' Szumilas, 2010).
+#' Confidence intervals are estimated using the standard normal parametric
+#' method (see Katz et al., 1978; Szumilas, 2010).
 #'
 #' @inheritSection effectsize_CIs CIs and Significance Tests
 #'
 #' @return A data frame with the effect size (`Odds_ratio`, `Risk_ratio`
-#'   (possibly with the prefix `log_`), `Cohens_h`) and its CIs (`CI_low` and
-#'   `CI_high`).
+#'   (possibly with the prefix `log_`), `Cohens_h`, `ARR`, `NNT`) and its CIs
+#'   (`CI_low` and `CI_high`).
 #'
 #' @family effect sizes for contingency table
 #'
@@ -50,6 +51,10 @@
 #'
 #' cohens_h(RCT_table)
 #'
+#' arr(RCT_table)
+#'
+#' nnt(RCT_table)
+#'
 #' @export
 #' @importFrom stats chisq.test qnorm
 oddsratio <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = FALSE, ...) {
@@ -211,10 +216,10 @@ cohens_h <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...) {
 
     alpha <- 1 - ci.level
 
-    se_arcsin <- sqrt(0.25 * (1 / n1 + 1 / n2))
+    se_arcsin <- 2 * sqrt(0.25 * (1 / n1 + 1 / n2))
     Zc <- stats::qnorm(alpha / 2, lower.tail = FALSE)
-    out$CI_low <- H - Zc * (2 * se_arcsin)
-    out$CI_high <- H + Zc * (2 * se_arcsin)
+    out$CI_low <- H - Zc * se_arcsin
+    out$CI_high <- H + Zc * se_arcsin
 
     ci_method <- list(method = ""normal"")
     out <- .limit_ci(out, alternative, -pi, pi)
@@ -229,3 +234,97 @@ cohens_h <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...) {
   attr(out, ""alternative"") <- alternative
   return(out)
 }
+
+
+#' @rdname oddsratio
+#' @export
+#' @importFrom stats qnorm
+arr <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...) {
+  alternative <- .match.alt(alternative)
+
+  if (.is_htest_of_type(x, ""Pearson's Chi-squared"", ""Chi-squared-test"")) {
+    return(effectsize(x, type = ""arr"", ci = ci, alternative = alternative))
+  } else if (.is_BF_of_type(x, ""BFcontingencyTable"", ""Chi-squared"")) {
+    return(effectsize(x, type = ""arr"", ci = ci, ...))
+  }
+
+  res <- .get_data_xtabs(x, y)
+  Obs <- res$observed
+
+  if (any(c(colSums(Obs), rowSums(Obs)) == 0L)) {
+    insight::format_error(""Cannot have empty rows/columns in the contingency tables."")
+  }
+
+  if (nrow(Obs) != 2 || ncol(Obs) != 2) {
+    insight::format_error(""This effect size is only available for 2-by-2 contingency tables"")
+  }
+
+  n1 <- sum(Obs[, 1])
+  n2 <- sum(Obs[, 2])
+  p1 <- Obs[1, 1] / n1
+  p2 <- Obs[1, 2] / n2
+  ARR <- p1 - p2
+
+  out <- data.frame(ARR)
+
+  if (.test_ci(ci)) {
+    out$CI <- ci
+    ci.level <- .adjust_ci(ci, alternative)
+
+    alpha <- 1 - ci.level
+
+    se <- sqrt(p1 * (1 - p1) / n1 + p2 * (1 - p2) / n2)
+    Zc <- stats::qnorm(alpha / 2, lower.tail = FALSE)
+    out$CI_low <- ARR - Zc * se
+    out$CI_high <- ARR + Zc * se
+
+    ci_method <- list(method = ""normal"")
+    out <- .limit_ci(out, alternative, -1, 1)
+  } else {
+    ci_method <- alternative <- NULL
+  }
+
+  class(out) <- c(""effectsize_table"", ""see_effectsize_table"", class(out))
+  attr(out, ""ci"") <- ci
+  attr(out, ""ci_method"") <- ci_method
+  attr(out, ""approximate"") <- FALSE
+  attr(out, ""alternative"") <- alternative
+  return(out)
+}
+
+
+#' @rdname oddsratio
+#' @export
+#' @importFrom stats qnorm
+nnt <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...) {
+  alternative <- .match.alt(alternative)
+
+  flip_alt <- c(""less"" = ""greater"", ""greater"" = ""less"", ""two.sided"" = ""two.sided"")
+  alternative2 <- unname(flip_alt[alternative])
+
+  if (.is_htest_of_type(x, ""Pearson's Chi-squared"", ""Chi-squared-test"")) {
+    return(effectsize(x, type = ""nnt"", ci = ci, alternative = alternative))
+  } else if (.is_BF_of_type(x, ""BFcontingencyTable"", ""Chi-squared"")) {
+    return(effectsize(x, type = ""nnt"", ci = ci, ...))
+  }
+
+  out <- arr(x, y = t, ci = ci, alternative = alternative2, ...)
+  out[[1]] <- 1 / out[[1]]
+  colnames(out)[1] <- ""NNT""
+
+  if (""CI"" %in% colnames(out)) {
+    ci_sign <- unlist(sign(out[c(""CI_low"", ""CI_high"")]))
+    if (all(ci_sign == 1) || all(ci_sign == -1)) {
+      out[c(""CI_low"", ""CI_high"")] <- 1 / out[c(""CI_high"", ""CI_low"")]
+    } else {
+      out[c(""CI_low"", ""CI_high"")] <- 1 / out[c(""CI_low"", ""CI_high"")]
+    }
+
+    out <- .limit_ci(out, alternative, -Inf, Inf)
+  } else {
+    alternative <- NULL
+  }
+
+  attr(out, ""alternative"") <- alternative
+  return(out)
+}

---FILE: data-raw/es_info.R---
@@ -26,6 +26,8 @@ es_info <- tibble::tribble(
   ""log_Odds_ratio"", ""log(Odds ratio)"", NA, ""twotail"", -Inf, Inf, 0,
   ""Risk_ratio"", ""Risk ratio"", NA, ""twotail"", 0, Inf, 1,
   ""log_Risk_ratio"", ""log(Risk ratio)"", NA, ""twotail"", -Inf, Inf, 0,
+  ""ARR"", ""ARR"", NA, ""twotail"", -1, 1, 0,
+  ""NNT"", ""NNT"", NA, ""twotail"", -Inf, Inf, NaN,
 
   ## xtab dep
   ""Cohens_g"", ""Cohen's g"", NA, ""onetail"", -0.5, 0.5, 0,

---FILE: man/effectsize.Rd---
@@ -49,7 +49,7 @@ input model. See details.
 \item For an object of class \code{htest}, data is extracted via \code{\link[insight:get_data]{insight::get_data()}}, and passed to the relevant function according to:
 \itemize{
 \item A \strong{t-test} depending on \code{type}: \code{""cohens_d""} (default), \code{""hedges_g""}, or one of \code{""p_superiority""}, \code{""u1""}, \code{""u2""}, \code{""u3""}, \code{""overlap""}.
-\item A \strong{Chi-squared tests of independence} or \strong{Fisher's Exact Test}, depending on \code{type}: \code{""cramers_v""} (default), \code{""tschuprows_t""}, \code{""phi""}, \code{""cohens_w""}, \code{""pearsons_c""}, \code{""cohens_h""}, \code{""oddsratio""}, or \code{""riskratio""}.
+\item A \strong{Chi-squared tests of independence} or \strong{Fisher's Exact Test}, depending on \code{type}: \code{""cramers_v""} (default), \code{""tschuprows_t""}, \code{""phi""}, \code{""cohens_w""}, \code{""pearsons_c""}, \code{""cohens_h""}, \code{""oddsratio""}, \code{""riskratio""}, \code{""arr""}, or \code{""nnt""}.
 \item A \strong{Chi-squared tests of goodness-of-fit}, depending on \code{type}: \code{""fei""} (default) \code{""cohens_w""}, \code{""pearsons_c""}
 \item A \strong{One-way ANOVA test}, depending on \code{type}: \code{""eta""} (default), \code{""omega""} or \code{""epsilon""} -squared, \code{""f""}, or \code{""f2""}.
 \item A \strong{McNemar test} returns \emph{Cohen's g}.
@@ -62,7 +62,7 @@ input model. See details.
 \itemize{
 \item A \strong{t-test} depending on \code{type}: \code{""cohens_d""} (default) or one of \code{""p_superiority""}, \code{""u1""}, \code{""u2""}, \code{""u3""}, \code{""overlap""}.
 \item A \strong{correlation test} returns \emph{r}.
-\item A \strong{contingency table test}, depending on \code{type}: \code{""cramers_v""} (default), \code{""phi""}, \code{""tschuprows_t""}, \code{""cohens_w""}, \code{""pearsons_c""}, \code{""cohens_h""}, \code{""oddsratio""}, or \code{""riskratio""}.
+\item A \strong{contingency table test}, depending on \code{type}: \code{""cramers_v""} (default), \code{""phi""}, \code{""tschuprows_t""}, \code{""cohens_w""}, \code{""pearsons_c""}, \code{""cohens_h""}, \code{""oddsratio""}, or \code{""riskratio""}, \code{""arr""}, or \code{""nnt""}.
 \item A \strong{proportion test} returns \emph{p}.
 }
 \item Objects of class \code{anova}, \code{aov}, \code{aovlist} or \code{afex_aov}, depending on \code{type}: \code{""eta""} (default), \code{""omega""} or \code{""epsilon""} -squared, \code{""f""}, or \code{""f2""}.
@@ -114,6 +114,7 @@ data(RCT_table)
 bf_xtab <- BayesFactor::contingencyTableBF(RCT_table, sampleType = ""poisson"", fixedMargin = ""cols"")
 effectsize(bf_xtab)
 effectsize(bf_xtab, type = ""oddsratio"")
+effectsize(bf_xtab, type = ""arr"")
 
 bf_ttest <- BayesFactor::ttestBF(sleep$extra[sleep$group == 1],
   sleep$extra[sleep$group == 2],

---FILE: man/oddsratio.Rd---
@@ -4,13 +4,19 @@
 \alias{oddsratio}
 \alias{riskratio}
 \alias{cohens_h}
-\title{Odds Ratios, Risk Ratios and Cohen's \emph{h} for 2-by-2 Contingency Tables}
+\alias{arr}
+\alias{nnt}
+\title{Odds Ratios, Risk Ratios and Other Effect Sizes for 2-by-2 Contingency Tables}
 \usage{
 oddsratio(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = FALSE, ...)
 
 riskratio(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = FALSE, ...)
 
 cohens_h(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...)
+
+arr(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...)
+
+nnt(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...)
 }
 \arguments{
 \item{x}{a numeric vector or matrix. \code{x} and \code{y} can also
@@ -33,21 +39,22 @@ allowed (e.g., \code{""g""}, \code{""l""}, \code{""two""}...). See \emph{One-Sided CIs
 }
 \value{
 A data frame with the effect size (\code{Odds_ratio}, \code{Risk_ratio}
-(possibly with the prefix \code{log_}), \code{Cohens_h}) and its CIs (\code{CI_low} and
-\code{CI_high}).
+(possibly with the prefix \code{log_}), \code{Cohens_h}, \code{ARR}, \code{NNT}) and its CIs
+(\code{CI_low} and \code{CI_high}).
 }
 \description{
-Report with any \code{\link[stats:chisq.test]{stats::chisq.test()}} or \code{\link[stats:fisher.test]{stats::fisher.test()}}.
+Compute Odds Ratios, Risk Ratios, Cohen's \emph{h}, Absolute Risk Reduction or
+Number Needed to Treat. Report with any \code{\link[stats:chisq.test]{stats::chisq.test()}} or
+\code{\link[stats:fisher.test]{stats::fisher.test()}}.
 \cr\cr
 Note that these are computed with each \strong{column} representing the different
 groups, and the \emph{first} column representing the treatment group and the
 \emph{second} column baseline (or control). Effects are given as \code{treatment / control}. If you wish you use rows as groups you must pass a transposed
 table, or switch the \code{x} and \code{y} arguments.
 }
 \section{Confidence (Compatibility) Intervals (CIs)}{
-For Odds ratios, Risk ratios and Cohen's \emph{h}, confidence intervals are
-estimated using the standard normal parametric method (see Katz et al., 1978;
-Szumilas, 2010).
+Confidence intervals are estimated using the standard normal parametric
+method (see Katz et al., 1978; Szumilas, 2010).
 }
 
 \section{CIs and Significance Tests}{
@@ -82,6 +89,10 @@ riskratio(RCT_table)
 
 cohens_h(RCT_table)
 
+arr(RCT_table)
+
+nnt(RCT_table)
+
 }
 \references{
 \itemize{

---FILE: man/oddsratio_to_riskratio.Rd---
@@ -1,17 +1,36 @@
 % Generated by roxygen2: do not edit by hand
-% Please edit documentation in R/convert_between_OR_to_RR.R
+% Please edit documentation in R/convert_between_riskdiff.R
 \name{oddsratio_to_riskratio}
 \alias{oddsratio_to_riskratio}
 \alias{riskratio_to_oddsratio}
+\alias{riskratio_to_arr}
+\alias{oddsratio_to_arr}
+\alias{arr_to_riskratio}
+\alias{arr_to_oddsratio}
+\alias{arr_to_nnt}
+\alias{nnt_to_arr}
 \title{Convert Between Odds Ratios and Risk Ratios}
 \usage{
 oddsratio_to_riskratio(OR, p0, log = FALSE, verbose = TRUE, ...)
 
 riskratio_to_oddsratio(RR, p0, log = FALSE, verbose = TRUE, ...)
+
+riskratio_to_arr(RR, p0, log = FALSE, verbose = TRUE, ...)
+
+oddsratio_to_arr(OR, p0, log = FALSE, verbose = TRUE, ...)
+
+arr_to_riskratio(ARR, p0, log = FALSE, verbose = TRUE, ...)
+
+arr_to_oddsratio(ARR, p0, log = FALSE, verbose = TRUE, ...)
+
+arr_to_nnt(x)
+
+nnt_to_arr(x)
 }
 \arguments{
-\item{OR, RR}{Risk ratio of \code{p1/p0} or Odds ratio of \code{odds(p1)/odds(p0)},
-possibly log-ed. \code{OR} can also be a logistic regression model.}
+\item{OR, RR, ARR}{Risk ratio of \code{p1/p0} Odds ratio of \code{odds(p1)/odds(p0)}
+(possibly log-ed), or Absolute Risk Reduction or \code{p1 - p0}. \code{OR} can also
+be a logistic regression model.}
 
 \item{p0}{Baseline risk}
 
@@ -20,6 +39,8 @@ possibly log-ed. \code{OR} can also be a logistic regression model.}
 \item{verbose}{Toggle warnings and messages on or off.}
 
 \item{...}{Arguments passed to and from other methods.}
+
+\item{x}{Absolute Risk Reduction or Number Needed to Treat.}
 }
 \value{
 Converted index, or if \code{OR} is a logistic regression model, a
@@ -34,23 +55,28 @@ p1 <- 0.7
 
 (OR <- probs_to_odds(p1) / probs_to_odds(p0))
 (RR <- p1 / p0)
+(ARR <- p1 - p0)
+(NNT <- arr_to_nnt(ARR))
 
 riskratio_to_oddsratio(RR, p0 = p0)
 oddsratio_to_riskratio(OR, p0 = p0)
+riskratio_to_arr(RR, p0 = p0)
+arr_to_oddsratio(nnt_to_arr(NNT), p0 = p0)
 
 m <- glm(am ~ factor(cyl),
   data = mtcars,
   family = binomial()
 )
 oddsratio_to_riskratio(m, verbose = FALSE) # RR is relative to the intercept if p0 not provided
+
 }
 \references{
 Grant, R. L. (2014). Converting an odds ratio to a range of plausible
 relative risks for better communication of research findings. Bmj, 348,
 f7450.
 }
 \seealso{
-\code{\link[=oddsratio]{oddsratio()}} and \code{\link[=riskratio]{riskratio()}}
+\code{\link[=oddsratio]{oddsratio()}}, \code{\link[=riskratio]{riskratio()}}, \code{\link[=arr]{arr()}}, and \code{\link[=nnt]{nnt()}}.
 
 Other convert between effect sizes: 
 \code{\link{d_to_r}()},

---FILE: tests/testthat/test-convert_between.R---
@@ -31,13 +31,24 @@ test_that(""oddsratio_to_RR"", {
 
   OR <- probs_to_odds(p1) / probs_to_odds(p0)
   RR <- p1 / p0
+  ARR <- p1 - p0
+  NNT <- 1 / ARR
+
+  expect_equal(nnt_to_arr(NNT), ARR)
+  expect_equal(arr_to_nnt(ARR), NNT)
 
   expect_equal(riskratio_to_oddsratio(RR, p0 = p0), OR)
   expect_equal(oddsratio_to_riskratio(OR, p0 = p0), RR)
   expect_equal(oddsratio_to_riskratio(1 / OR, p0 = p1), 1 / RR)
+  expect_equal(riskratio_to_arr(RR, p0 = p0), ARR)
+  expect_equal(oddsratio_to_arr(OR, p0 = p0), ARR)
+  expect_equal(arr_to_oddsratio(ARR, p0 = p0), OR)
+  expect_equal(arr_to_riskratio(ARR, p0 = p0), RR)
 
   expect_equal(riskratio_to_oddsratio(log(RR), p0 = p0, log = TRUE), log(OR))
   expect_equal(oddsratio_to_riskratio(log(OR), p0 = p0, log = TRUE), log(RR))
+  expect_equal(arr_to_oddsratio(ARR, p0 = p0, log = TRUE), log(OR))
+  expect_equal(oddsratio_to_arr(log(OR), p0 = p0, log = TRUE), ARR)
 
   # -- GLMs --
   data(mtcars)

---FILE: tests/testthat/test-xtab.R---
@@ -144,8 +144,18 @@ test_that(""oddsratio & riskratio"", {
   )
   OR <- oddsratio(RCT)
   RR <- riskratio(RCT)
+  ARR <- arr(RCT)
+  NNT <- nnt(RCT)
   p0 <- RCT[1, 2] / sum(RCT[, 2])
 
+  expect_lt(NNT$CI_low, NNT$CI_high)
+  expect_lt(NNT$CI_high, 0)
+
+  NNT_0 <- nnt(RCT / 9.8)
+  expect_lt(NNT_0$CI_low, NNT_0$CI_high)
+  expect_lt(NNT_0$CI_low, 0)
+  expect_gt(NNT_0$CI_high, 0)
+
   expect_equal(
     oddsratio_to_riskratio(OR$Odds_ratio, p0),
     RR$Risk_ratio
@@ -154,6 +164,10 @@ test_that(""oddsratio & riskratio"", {
     riskratio_to_oddsratio(RR$Risk_ratio, p0),
     OR$Odds_ratio
   )
+  expect_equal(
+    oddsratio_to_arr(OR$Odds_ratio, p0),
+    ARR$ARR
+  )
 
   expect_error(riskratio(RCT, log = TRUE), NA)
 

---FILE: vignettes/convert_p_OR_RR.Rmd---
@@ -67,16 +67,16 @@ OR = \frac{Odds_1}{Odds_2} = \frac{\frac{p_1}{1-p_1}}{\frac{p_2}{1-p_2}}
 $$
 The intercept, however, *does* represent the (log) odds, when all other variables are fixed at 0.
 
-# Converting Odds ratios to Risk Ratios
+# Converting Between Odds Ratios, Risk Ratios and Absolute Risk Reduction
 
 Odds ratio, although popular, are not very intuitive in their interpretations.
 We don't often think about the chances of catching a disease in terms of *odds*,
 instead we instead tend to think in terms of *probability* or some event - or
 the *risk*. Talking about *risks* we can also talk about the *change in risk*,
-knows as the *risk ratio* (*RR*).
+either as a *risk ratio* (*RR*), or a(n *absolute) risk reduction* (ARR).
 
 For example, if we find that for individual suffering from a migraine, for every
-bowl of brussels sprouts they eat, they're odds of reducing the migraine
+bowl of brussels sprouts they eat, their odds of reducing the migraine
 increase by an $OR = 3.5$ over a period of an hour. So, should people eat
 brussels sprouts to effectively reduce pain? Well, hard to say... Maybe if we
 look at *RR* we'll get a clue.
@@ -97,21 +97,33 @@ hour without eating any brussels sprouts). If it the base-rate risk is, say,
 OR <- 3.5
 baserate <- 0.85
 
-oddsratio_to_riskratio(OR, baserate)
+(RR <- oddsratio_to_riskratio(OR, baserate))
 ```
 
 That is - for every bowl of brussels sprouts, we increase the chances of
 reducing the migraine by a mere 12%! Is if worth it? Depends on you affinity to
 brussels sprouts...
 
+Similiarly, we can look at ARR, which can be converted via
+
+$$
+ARR = RR \times p0 - p0
+$$
+```{r}
+riskratio_to_arr(RR, baserate)
+```
+
+Or directly:
+
+```{r}
+oddsratio_to_arr(OR, baserate)
+```
+
 Note that the base-rate risk is crucial here. If instead of 85% it was only 4%,
 then the *RR* would be:
 
 ```{r}
-OR <- 3.5
-baserate <- 0.04
-
-oddsratio_to_riskratio(OR, baserate)
+oddsratio_to_riskratio(OR, 0.04)
 ```
 
 That is - for every bowl of brussels sprouts, we increase the chances of

---FILE: vignettes/xtabs.Rmd---
@@ -180,10 +180,14 @@ oddsratio(RCT_table)
 ```
 
 We can also compute the Risk-ratio (RR), which is the ratio between the
-proportions of the two groups - a measure which some claim is more intuitive.
+proportions of the two groups, and the Absolute Risk Reduction (ARR), which is
+the *difference* between the proportions of the two groups - both are measures
+which some claim to be more intuitive.
 
 ```{r}
 riskratio(RCT_table)
+
+arr(RCT_table)
 ```
 
 Additionally, Cohen's *h* can also be computed, which uses the *arcsin*",True,True,Documentation / Formatting,6
easystats,effectsize,7067d877a425bab29268f746939cf5be9f73411a,Mattan S. Ben-Shachar,mattansb@msbstats.info,2023-01-31T11:44:25Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2023-01-31T11:44:25Z,fix #560,DESCRIPTION;R/convert_between_d_to_r.R;R/means_ratio.R;man/d_to_r.Rd;man/means_ratio.Rd,False,True,True,False,9,9,18,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size
-Version: 0.8.3
+Version: 0.8.3.1
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",

---FILE: R/convert_between_d_to_r.R---
@@ -43,7 +43,7 @@
 #' (2009). Converting among effect sizes. Introduction to meta-analysis, 45-49.
 #'
 #' - Jacobs, P., & Viechtbauer, W. (2017). Estimation of the biserial
-#' correlation and its sampling variance for use in metaâanalysis. Research
+#' correlation and its sampling variance for use in meta-analysis. Research
 #' synthesis methods, 8(2), 161-180. \doi{10.1002/jrsm.1218}
 #'
 #' - Rosenthal, R., & Rubin, D. B. (1982). A simple, general purpose display of

---FILE: R/means_ratio.R---
@@ -48,12 +48,12 @@
 #' means_ratio(3 * x, 3 * y)
 #'
 #' @references
-#' Lajeunesse, M. J. (2011). On the metaâanalysis of response ratios for studies
-#' with correlated and multiâgroup designs. Ecology, 92(11), 2049-2055.
+#' Lajeunesse, M. J. (2011). On the meta-analysis of response ratios for studies
+#' with correlated and multi-group designs. Ecology, 92(11), 2049-2055.
 #' \doi{10.1890/11-0423.1}
 #'
 #' Lajeunesse, M. J. (2015). Bias and correction for the log response ratio in
-#' ecological metaâanalysis. Ecology, 96(8), 2056-2063. \doi{10.1890/14-2402.1}
+#' ecological meta-analysis. Ecology, 96(8), 2056-2063. \doi{10.1890/14-2402.1}
 #'
 #' Hedges, L. V., Gurevitch, J., & Curtis, P. S. (1999). The meta-analysis of
 #' response ratios in experimental ecology. Ecology, 80(4), 1150â1156.

---FILE: man/d_to_r.Rd---
@@ -88,7 +88,7 @@ oddsratio_to_d(1.813799, log = TRUE)
 \item Borenstein, M., Hedges, L. V., Higgins, J. P. T., & Rothstein, H. R.
 (2009). Converting among effect sizes. Introduction to meta-analysis, 45-49.
 \item Jacobs, P., & Viechtbauer, W. (2017). Estimation of the biserial
-correlation and its sampling variance for use in metaâanalysis. Research
+correlation and its sampling variance for use in meta-analysis. Research
 synthesis methods, 8(2), 161-180. \doi{10.1002/jrsm.1218}
 \item Rosenthal, R., & Rubin, D. B. (1982). A simple, general purpose display of
 magnitude of experimental effect. Journal of educational psychology, 74(2), 166.

---FILE: man/means_ratio.Rd---
@@ -108,12 +108,12 @@ means_ratio(3 * x, 3 * y)
 
 }
 \references{
-Lajeunesse, M. J. (2011). On the metaâanalysis of response ratios for studies
-with correlated and multiâgroup designs. Ecology, 92(11), 2049-2055.
+Lajeunesse, M. J. (2011). On the meta-analysis of response ratios for studies
+with correlated and multi-group designs. Ecology, 92(11), 2049-2055.
 \doi{10.1890/11-0423.1}
 
 Lajeunesse, M. J. (2015). Bias and correction for the log response ratio in
-ecological metaâanalysis. Ecology, 96(8), 2056-2063. \doi{10.1890/14-2402.1}
+ecological meta-analysis. Ecology, 96(8), 2056-2063. \doi{10.1890/14-2402.1}
 
 Hedges, L. V., Gurevitch, J., & Curtis, P. S. (1999). The meta-analysis of
 response ratios in experimental ecology. Ecology, 80(4), 1150â1156.",True,False,Documentation / Formatting,6
easystats,effectsize,13b46a66f06599dd655f75d396ea446f7d927fe8,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2023-01-24T20:06:00Z,GitHub,noreply@github.com,2023-01-24T20:06:00Z,"deal with `alternative = NULL` (#555)

* init

* Apply automatic changes

* fix tests

* Apply automatic changes

* [skip ci]

Co-authored-by: mattansb <mattansb@users.noreply.github.com>",DESCRIPTION;NEWS.md;R/convert_stat_chisq.R;R/convert_stat_to_anova.R;R/eta_squared-main.R;R/mahalanobis_D.R;R/r2_semipartial.R;R/rank_ANOVA.R;R/utils.R;R/utils_ci.R;R/xtab_corr.R;man/mahalanobis_d.Rd;tests/testthat/test-eta_squared.R;tests/testthat/test-mahalanobis_D.R,False,True,True,False,95,72,167,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size
-Version: 0.8.2.6
+Version: 0.8.2.10
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",

---FILE: NEWS.md---
@@ -1,5 +1,9 @@
 # effectsize 0.8.2.xxx
 
+## Changes
+
+- `mahalanobis_d()` now defaults to one-sided CIs.
+
 ## New features
 
 - `means_ratio()` for computing ratios of two means for ratio-scales outcomes (thanks to @arcaldwell49!)
@@ -23,7 +27,7 @@
 
 ## Changes
 
-- cohens_w() has an exact upper bound when used as an effect size for goodness-of-fit.
+- `cohens_w()` has an exact upper bound when used as an effect size for goodness-of-fit.
 
 ## Bug fixes
 

---FILE: R/convert_stat_chisq.R---
@@ -326,7 +326,7 @@ phi_to_chisq <- function(phi, n, ...) {
 .chisq_to_generic_phi <- function(chisq, den, nrow, ncol,
                                   ci = NULL, alternative = ""greater"",
                                   ...) {
-  alternative <- .match.alt(alternative)
+  alternative <- .match.alt(alternative, FALSE)
 
   if (ci_numeric <- .test_ci(ci)) {
     is_goodness <- ncol == 1 || nrow == 1

---FILE: R/convert_stat_to_anova.R---
@@ -183,7 +183,8 @@ F_to_omega2 <- function(f, df, df_error,
 #' @rdname F_to_eta2
 #' @export
 t_to_omega2 <- function(t, df_error,
-                        ci = 0.95, alternative = ""greater"", ...) {
+                        ci = 0.95, alternative = ""greater"",
+                        ...) {
   F_to_omega2(t^2, 1, df_error,
     ci = ci, alternative = alternative,
     ...
@@ -274,7 +275,7 @@ t_to_f2 <- function(t, df_error,
                       es = ""eta2"",
                       ci = 0.95, alternative = ""greater"",
                       verbose = TRUE, ...) {
-  alternative <- .match.alt(alternative)
+  alternative <- .match.alt(alternative, FALSE)
 
   res <- switch(tolower(es),
     eta2 = data.frame(Eta2_partial = (f * df) / (f * df + df_error)),

---FILE: R/eta_squared-main.R---
@@ -203,7 +203,7 @@ eta_squared <- function(model,
                         partial = TRUE, generalized = FALSE,
                         ci = 0.95, alternative = ""greater"",
                         verbose = TRUE, ...) {
-  alternative <- .match.alt(alternative)
+  alternative <- .match.alt(alternative, FALSE)
   out <- .anova_es(
     model,
     type = ""eta"",
@@ -225,7 +225,7 @@ omega_squared <- function(model,
                           partial = TRUE,
                           ci = 0.95, alternative = ""greater"",
                           verbose = TRUE, ...) {
-  alternative <- .match.alt(alternative)
+  alternative <- .match.alt(alternative, FALSE)
   out <- .anova_es(model, type = ""omega"", partial = partial, ci = ci, alternative = alternative, verbose = verbose, ...)
   class(out) <- unique(c(""effectsize_anova"", ""effectsize_table"", ""see_effectsize_table"", class(out)))
   if (""CI"" %in% colnames(out)) attr(out, ""ci_method"") <- list(method = ""ncp"", distribution = ""F"")
@@ -239,7 +239,7 @@ epsilon_squared <- function(model,
                             partial = TRUE,
                             ci = 0.95, alternative = ""greater"",
                             verbose = TRUE, ...) {
-  alternative <- .match.alt(alternative)
+  alternative <- .match.alt(alternative, FALSE)
   out <- .anova_es(model, type = ""epsilon"", partial = partial, ci = ci, alternative = alternative, verbose = verbose, ...)
   class(out) <- unique(c(""effectsize_anova"", ""effectsize_table"", ""see_effectsize_table"", class(out)))
   if (""CI"" %in% colnames(out)) attr(out, ""ci_method"") <- list(method = ""ncp"", distribution = ""F"")
@@ -256,7 +256,7 @@ cohens_f <- function(model,
                      partial = TRUE, squared = FALSE, model2 = NULL,
                      ci = 0.95, alternative = ""greater"",
                      verbose = TRUE, ...) {
-  alternative <- .match.alt(alternative)
+  alternative <- .match.alt(alternative, FALSE)
   if (!is.null(model2)) {
     return(.cohens_f_delta(model, model2,
       squared = squared,

---FILE: R/mahalanobis_D.R---
@@ -55,7 +55,7 @@
 #' # Or
 #' mahalanobis_d(mpg + hp + cyl ~ am, data = mtcars)
 #'
-#' mahalanobis_d(mpg + hp + cyl ~ am, data = mtcars, alternative = ""greater"")
+#' mahalanobis_d(mpg + hp + cyl ~ am, data = mtcars, alternative = ""two.sided"")
 #'
 #' # Different mu:
 #' mahalanobis_d(mpg + hp + cyl ~ am,
@@ -83,11 +83,11 @@
 #' @export
 mahalanobis_d <- function(x, y = NULL, data = NULL,
                           pooled_cov = TRUE, mu = 0,
-                          ci = 0.95, alternative = ""two.sided"",
+                          ci = 0.95, alternative = ""greater"",
                           verbose = TRUE, ...) {
   # TODO add one sample case DV1 + DV2 ~ 1
   # TODO add paired samples case DV1 + DV2 ~ 1 | ID
-  alternative <- .match.alt(alternative)
+  alternative <- .match.alt(alternative, FALSE)
   data <- .get_data_multivariate(x, y, data, verbose = verbose, ...)
   x <- data[[""x""]]
   y <- data[[""y""]]

---FILE: R/r2_semipartial.R---
@@ -97,7 +97,7 @@ r2_semipartial.lm <- function(model, type = c(""terms"", ""parameters""),
                               ci = 0.95, alternative = ""greater"",
                               ...) {
   type <- match.arg(type)
-  alternative <- .match.alt(alternative)
+  alternative <- .match.alt(alternative, FALSE)
 
   y <- stats::model.frame(model)[[1]]
   mm <- insight::get_modelmatrix(model)

---FILE: R/rank_ANOVA.R---
@@ -89,7 +89,7 @@ rank_epsilon_squared <- function(x, groups, data = NULL,
                                  ci = 0.95, alternative = ""greater"",
                                  iterations = 200,
                                  verbose = TRUE, ...) {
-  alternative <- .match.alt(alternative)
+  alternative <- .match.alt(alternative, FALSE)
 
   if (.is_htest_of_type(x, ""Kruskal-Wallis"", ""Kruskal-Wallis-test"")) {
     return(effectsize(x, type = ""epsilon"", ci = ci, iterations = iterations, alternative = alternative))
@@ -130,7 +130,7 @@ rank_eta_squared <- function(x, groups, data = NULL,
                              ci = 0.95, alternative = ""greater"",
                              iterations = 200,
                              verbose = TRUE, ...) {
-  alternative <- .match.alt(alternative)
+  alternative <- .match.alt(alternative, FALSE)
 
   if (.is_htest_of_type(x, ""Kruskal-Wallis"", ""Kruskal-Wallis-test"")) {
     return(effectsize(x, type = ""eta"", ci = ci, iterations = iterations, alternative = alternative))
@@ -177,7 +177,7 @@ kendalls_w <- function(x, groups, blocks, data = NULL,
                        ci = 0.95, alternative = ""greater"",
                        iterations = 200,
                        verbose = TRUE, ...) {
-  alternative <- .match.alt(alternative)
+  alternative <- .match.alt(alternative, FALSE)
 
   if (.is_htest_of_type(x, ""Friedman"", ""Friedman-test"")) {
     return(effectsize(x, ci = ci, iterations = iterations, verbose = verbose, alternative = alternative))

---FILE: R/utils.R---
@@ -68,49 +68,3 @@
     return(FALSE)
   }
 }
-
-
-# CI Utils ----------------------------------------------------------------
-
-#' @keywords internal
-.test_ci <- function(ci) {
-  if (is.null(ci)) {
-    return(FALSE)
-  }
-  if (!is.numeric(ci) ||
-    length(ci) != 1L ||
-    ci < 0 ||
-    ci > 1) {
-    insight::format_error(""ci must be a single numeric value between (0, 1)"")
-  }
-  return(TRUE)
-}
-
-#' @keywords internal
-.adjust_ci <- function(ci, alternative) {
-  if (alternative == ""two.sided"") {
-    return(ci)
-  }
-
-  2 * ci - 1
-}
-
-#' @keywords internal
-.limit_ci <- function(out, alternative, lb, ub) {
-  if (alternative == ""two.sided"") {
-    return(out)
-  }
-
-  if (alternative == ""less"") {
-    out$CI_low <- lb
-  } else if (alternative == ""greater"") {
-    out$CI_high <- ub
-  }
-
-  out
-}
-
-#' @keywords internal
-.match.alt <- function(alternative) {
-  match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
-}

---FILE: R/utils_ci.R---
@@ -1,3 +1,5 @@
+# NCP -------------------------
+
 #' @keywords internal
 #' @importFrom stats pf qf optim
 .get_ncp_F <- function(f, df, df_error, conf.level = 0.9) {
@@ -93,3 +95,57 @@
 
   chi_ncp
 }
+
+# Validators --------------------------------------
+
+
+#' @keywords internal
+.test_ci <- function(ci) {
+  if (is.null(ci)) {
+    return(FALSE)
+  }
+  if (!is.numeric(ci) ||
+    length(ci) != 1L ||
+    ci < 0 ||
+    ci > 1) {
+    insight::format_error(""ci must be a single numeric value between (0, 1)"")
+  }
+  return(TRUE)
+}
+
+#' @keywords internal
+.adjust_ci <- function(ci, alternative) {
+  if (alternative == ""two.sided"") {
+    return(ci)
+  }
+
+  2 * ci - 1
+}
+
+#' @keywords internal
+.limit_ci <- function(out, alternative, lb, ub) {
+  if (alternative == ""two.sided"") {
+    return(out)
+  }
+
+  if (alternative == ""less"") {
+    out$CI_low <- lb
+  } else if (alternative == ""greater"") {
+    out$CI_high <- ub
+  }
+
+  out
+}
+
+#' @keywords internal
+.match.alt <- function(alternative, two.sided = TRUE) {
+  if (is.null(alternative)) {
+    if (two.sided) {
+      return(""two.sided"")
+    } else {
+      return(""greater"")
+    }
+  }
+
+  match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
+}

---FILE: R/xtab_corr.R---
@@ -105,7 +105,7 @@ phi <- function(x, y = NULL,
                 adjust = TRUE,
                 ci = 0.95, alternative = ""greater"",
                 ...) {
-  alternative <- .match.alt(alternative)
+  alternative <- .match.alt(alternative, FALSE)
 
   if (.is_BF_of_type(x, ""BFcontingencyTable"", ""Chi-squared"")) {
     return(effectsize(x, type = ""phi"", adjust = adjust, ci = ci))
@@ -124,7 +124,7 @@ cramers_v <- function(x, y = NULL,
                       adjust = TRUE,
                       ci = 0.95, alternative = ""greater"",
                       ...) {
-  alternative <- .match.alt(alternative)
+  alternative <- .match.alt(alternative, FALSE)
 
   if (.is_BF_of_type(x, ""BFcontingencyTable"", ""Chi-squared"")) {
     return(effectsize(x, type = ""cramers_v"", adjust = adjust, ci = ci))
@@ -143,7 +143,7 @@ cramers_v <- function(x, y = NULL,
 tschuprows_t <- function(x, y = NULL,
                          ci = 0.95, alternative = ""greater"",
                          ...) {
-  alternative <- .match.alt(alternative)
+  alternative <- .match.alt(alternative, FALSE)
 
   if (.is_BF_of_type(x, ""BFcontingencyTable"", ""Chi-squared"")) {
     return(effectsize(x, type = ""tschuprows_t"", ci = ci))
@@ -161,7 +161,7 @@ tschuprows_t <- function(x, y = NULL,
 cohens_w <- function(x, y = NULL, p = rep(1, length(x)),
                      ci = 0.95, alternative = ""greater"",
                      ...) {
-  alternative <- .match.alt(alternative)
+  alternative <- .match.alt(alternative, FALSE)
 
   if (.is_BF_of_type(x, ""BFcontingencyTable"", ""Chi-squared"")) {
     return(effectsize(x, type = ""cohens_w"", ci = ci))
@@ -183,7 +183,7 @@ cohens_w <- function(x, y = NULL, p = rep(1, length(x)),
 fei <- function(x, p = rep(1, length(x)),
                 ci = 0.95, alternative = ""greater"",
                 ...) {
-  alternative <- .match.alt(alternative)
+  alternative <- .match.alt(alternative, FALSE)
 
   if (inherits(x, ""BFBayesFactor"")) {
     insight::format_error(""Fei is only applicable to goodness of fit tests."")
@@ -201,7 +201,7 @@ fei <- function(x, p = rep(1, length(x)),
 pearsons_c <- function(x, y = NULL, p = rep(1, length(x)),
                        ci = 0.95, alternative = ""greater"",
                        ...) {
-  alternative <- .match.alt(alternative)
+  alternative <- .match.alt(alternative, FALSE)
 
   if (.is_BF_of_type(x, ""BFcontingencyTable"", ""Chi-squared"")) {
     return(effectsize(x, type = ""pearsons_c"", ci = ci))

---FILE: man/mahalanobis_d.Rd---
@@ -11,7 +11,7 @@ mahalanobis_d(
   pooled_cov = TRUE,
   mu = 0,
   ci = 0.95,
-  alternative = ""two.sided"",
+  alternative = ""greater"",
   verbose = TRUE,
   ...
 )
@@ -115,7 +115,7 @@ mahalanobis_d(mtcars_am0, mtcars_am1)
 # Or
 mahalanobis_d(mpg + hp + cyl ~ am, data = mtcars)
 
-mahalanobis_d(mpg + hp + cyl ~ am, data = mtcars, alternative = ""greater"")
+mahalanobis_d(mpg + hp + cyl ~ am, data = mtcars, alternative = ""two.sided"")
 
 # Different mu:
 mahalanobis_d(mpg + hp + cyl ~ am,

---FILE: tests/testthat/test-eta_squared.R---
@@ -1,5 +1,13 @@
 # library(testthat)
 
+test_that(""alternative = NULL"", {
+  m <- aov(mpg ~ factor(cyl) + hp, mtcars)
+  expect_equal(
+    eta_squared(m),
+    eta_squared(m, alternative = NULL)
+  )
+})
+
 # anova() -----------------------------------------------------------------
 test_that(""anova()"", {
   # Make minimal ANOVA table

---FILE: tests/testthat/test-mahalanobis_D.R---
@@ -12,7 +12,7 @@ test_that(""mahalanobis_d | two sample | vs cohens_d"", {
   y <- within(x, {
     B <- B + 15
   })
-  D <- mahalanobis_d(x, y)
+  D <- mahalanobis_d(x, y, alternative = ""two"")
   d <- cohens_d(-x$B, -y$B)
   expect_equal(D[[1]], d[[1]], tolerance = 0.01)
   expect_equal(D[[3]], d[[3]], tolerance = 0.1)
@@ -45,7 +45,7 @@ test_that(""mahalanobis_d | one sample | vs cohens_d"", {
 
 
   # Simple:
-  D <- mahalanobis_d(x)
+  D <- mahalanobis_d(x, alternative = ""two"")
   d <- cohens_d(x$B)
   expect_equal(D[[1]], d[[1]], tolerance = 0.01)
   expect_equal(D[[3]], d[[3]], tolerance = 0.1)",True,False,Documentation / Formatting,6
easystats,effectsize,1b8ad84dcb208b179e99b103c529817866f533f5,Victor Souza,32229843+souza-victor@users.noreply.github.com,2023-01-24T06:45:05Z,GitHub,noreply@github.com,2023-01-24T06:45:05Z,"Corrected typo in interpret_omega_squared help (#556)

* Corrected typo in interpret_omega_squared help

* fix typos

[skip ci]

Co-authored-by: Mattan S. Ben-Shachar <mattansb@msbstats.info>",R/interpret_omega_squared.R;man/interpret_omega_squared.Rd;vignettes/interpret.Rmd,True,True,True,False,3,3,6,"---FILE: R/interpret_omega_squared.R---
@@ -9,7 +9,7 @@
 #' - Field (2013) (`""field2013""`; default)
 #'   - **ES < 0.01** - Very small
 #'   - **0.01 <= ES < 0.06** - Small
-#'   - **0.16 <= ES < 0.14** - Medium
+#'   - **0.06 <= ES < 0.14** - Medium
 #'   - **ES >= 0.14 ** - Large
 #' - Cohen (1992) (`""cohen1992""`) applicable to one-way anova, or to *partial*
 #' eta / omega / epsilon squared in multi-way anova.

---FILE: man/interpret_omega_squared.Rd---
@@ -29,7 +29,7 @@ Interpret ANOVA Effect Sizes
 \itemize{
 \item \strong{ES < 0.01} - Very small
 \item \strong{0.01 <= ES < 0.06} - Small
-\item \strong{0.16 <= ES < 0.14} - Medium
+\item \strong{0.06 <= ES < 0.14} - Medium
 \item **ES >= 0.14 ** - Large
 }
 \item Cohen (1992) (\code{""cohen1992""}) applicable to one-way anova, or to \emph{partial}

---FILE: vignettes/interpret.Rmd---
@@ -346,7 +346,7 @@ interpret_omega_squared(x, rules = ""field2013"")
 
 - **0.01 <= ES < 0.06** - Small
 
-- **0.16 <= ES < 0.14** - Medium
+- **0.06 <= ES < 0.14** - Medium
 
 - **ES >= 0.14 ** - Large
 ",True,True,Documentation / Formatting,7
easystats,effectsize,16d2b8d2550f114cb7c7a443549774f8cf2ff0e6,Indrajeet Patil,patilindrajeet.science@gmail.com,2023-01-12T22:41:58Z,Indrajeet Patil,patilindrajeet.science@gmail.com,2023-01-12T22:41:58Z,"add a list of words to ignore for spell check

https://github.com/easystats/easystats/issues/346",inst/WORDLIST;tests/spelling.R,False,True,True,False,236,0,236,"---FILE: inst/WORDLIST---
@@ -0,0 +1,233 @@
+AGFI
+ANOVA's
+APA's
+Agadullina
+Agresti
+Albers
+Alf
+Algina
+Awang
+Azen
+BESD
+BMC
+Baptista
+BayestestR's
+Behaviour
+Bergsma
+Biometrics
+Biometrika
+Bmj
+Bollen's
+Borenstein
+Byrne
+BÃ¼rkner
+CFA
+CFI
+CLES
+CLESs
+CMD
+Castelloe
+Cesarini
+ChacÃ³n
+Chisq
+Codecov
+Compatibiity
+Cramer's
+CramÃ©r's
+Cureton
+DOI
+Delacre
+Dom
+Doutelle
+Doutelle's
+EQS
+ESS
+Erlbaum
+FASD
+Falk
+Faraggi
+Fei
+Funder
+GFI
+Gelman
+Gignac
+Gignac's
+Giudice
+Glassâ
+Graf
+Guilford
+Gurevitch
+Gustafson
+HDI
+HLM
+Hedgesâ
+Hjort
+Hoekstra
+Hotelling's
+IFI
+IRRs
+Intraclass
+Jarosz
+Jeffreys
+Johannesson
+Katz
+Kerby
+Keselman
+Kieser
+Kiesser
+Koo
+Kruschke
+LMM
+Lajeunesse
+Lakens
+Landis
+Ley
+Leys
+Liu
+Lomax
+Lovakov
+MBESS
+MLM
+Mahwah
+MartÃ­nez
+MarÃ­n
+Mattan
+McGraw
+McNemar
+McNemar's
+Meca
+Mielke
+Minium
+Mordkoff
+Morey
+Moscoso
+NCP
+NFI
+NNFI
+Nordholm
+Normed
+Nosek
+ORCID
+OVL
+Olejnik
+Olkin
+Ozer
+PLOS
+PNFI
+PPD
+Penfield
+PloS
+Psychometrika
+Psychonomic
+RFI
+RMR
+RMSEA
+Rafi
+Raftery
+Reiser
+Rhat
+Ringle
+Rosenthal
+Rothstein
+Rouder
+Routledge
+Ruscio
+SDs
+SEM
+SRMR
+Sarstedt
+Sawilowsky
+Schumacker
+Schweder
+Shachar
+Shmekels
+Steiger
+Szodorai
+Szumilas
+SÃ¡nchez
+TLI
+TOST
+Tomczak
+Tschuprow's
+Un
+VIF
+VIFs
+Vargha
+Vehtari
+Viechtbauer
+Wagenmakers
+Welch's
+Wilcoxon's
+Xie
+al
+analysed
+anova
+arXiv
+arcsin
+biserial
+bmwiernik
+brglm
+brms
+brussels
+cbu
+cfa
+cgam
+cglm
+cles
+cohens
+complmrob
+cplm
+dichotomize
+doi
+dynamicfit
+easystats
+effectSize
+et
+fixest
+frac
+friedman
+ggstatsplot
+github
+glmmadmb
+gtsummary
+homoscedasticity
+https
+infty
+intraclass
+io
+joss
+kruskal
+lifecycle
+lm
+mattansb
+mis
+mixor
+modelling
+mrc
+multicollinearity
+ncp
+ncps
+nd
+noncentral
+noncentrality
+num
+partialled
+partilled
+patilindrajeets
+pb
+pkgdown
+ppd
+pre
+preprint
+rb
+rempsyc
+rescale
+rmANOVA
+sd
+semipartial
+statswiki
+strengejacke
+th
+uk
+wilcox
+×¤

---FILE: tests/spelling.R---
@@ -0,0 +1,3 @@
+if(requireNamespace('spelling', quietly = TRUE))
+  spelling::spell_check_test(vignettes = TRUE, error = FALSE,
+                             skip_on_cran = TRUE)",True,False,Documentation / Formatting,3
easystats,effectsize,25eb16b49648649c7c3e2e3506c7e933247e9355,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2023-01-10T16:40:37Z,GitHub,noreply@github.com,2023-01-10T16:40:37Z,"Update effectsize.htest.R (#551)

* Update effectsize.htest.R

* fix 2

* fix 3

* fix 4",R/convert_between_OR_to_RR.R;R/effectsize.R;R/effectsize.htest.R;R/equivalence_test.R;R/eta_squared-main.R;man/effectsize.Rd;man/equivalence_test.effectsize_table.Rd;man/eta_squared.Rd;man/oddsratio_to_riskratio.Rd,False,True,True,False,38,23,61,"---FILE: R/convert_between_OR_to_RR.R---
@@ -5,6 +5,7 @@
 #' @param p0 Baseline risk
 #' @param ... Arguments passed to and from other methods.
 #' @inheritParams oddsratio_to_d
+#' @inheritParams cohens_d
 #'
 #' @return Converted index, or if `OR` is a logistic regression model, a
 #'   parameter table with the converted indices.
@@ -26,20 +27,20 @@
 #'   data = mtcars,
 #'   family = binomial()
 #' )
-#' oddsratio_to_riskratio(m)
+#' oddsratio_to_riskratio(m, verbose = FALSE) # RR is relative to the intercept if p0 not provided
 #' @references
 #'
 #' Grant, R. L. (2014). Converting an odds ratio to a range of plausible
 #' relative risks for better communication of research findings. Bmj, 348,
 #' f7450.
 #'
 #' @export
-oddsratio_to_riskratio <- function(OR, p0, log = FALSE, ...) {
+oddsratio_to_riskratio <- function(OR, p0, log = FALSE, verbose = TRUE, ...) {
   UseMethod(""oddsratio_to_riskratio"")
 }
 
 #' @export
-oddsratio_to_riskratio.numeric <- function(OR, p0, log = FALSE, ...) {
+oddsratio_to_riskratio.numeric <- function(OR, p0, log = FALSE, verbose = TRUE, ...) {
   if (log) OR <- exp(OR)
 
   RR <- OR / (1 - p0 + (p0 * OR))
@@ -49,7 +50,7 @@ oddsratio_to_riskratio.numeric <- function(OR, p0, log = FALSE, ...) {
 }
 
 #' @export
-oddsratio_to_riskratio.default <- function(OR, p0, log = FALSE, ...) {
+oddsratio_to_riskratio.default <- function(OR, p0, log = FALSE, verbose = TRUE, ...) {
   mi <- .get_model_info(OR, ...)
   if (!mi$is_binomial || !mi$is_logit) {
     insight::format_error(""Model must be a binomial model with a logit-link (logistic regression)."")
@@ -66,10 +67,12 @@ oddsratio_to_riskratio.default <- function(OR, p0, log = FALSE, ...) {
     if (!log) p0 <- log(p0)
     p0 <- plogis(p0)
 
-    insight::format_warning(
-      ""'p0' not provided."",
-      sprintf(""RR is relative to the intercept (p0 = %s) - make sure your intercept is meaningful."", insight::format_value(p0))
-    )
+    if (verbose) {
+      insight::format_warning(
+        ""'p0' not provided."",
+        sprintf(""RR is relative to the intercept (p0 = %s) - make sure your intercept is meaningful."", insight::format_value(p0))
+      )
+    }
   }
 
   RR[, colnames(RR) %in% c(""Coefficient"", ""CI_low"", ""CI_high"")] <-
@@ -78,7 +81,7 @@ oddsratio_to_riskratio.default <- function(OR, p0, log = FALSE, ...) {
       p0 = p0, log = log
     )
 
-  if (any(c(""CI_low"", ""CI_high"") %in% colnames(RR))) {
+  if (verbose && any(c(""CI_low"", ""CI_high"") %in% colnames(RR))) {
     insight::format_warning(""CIs are back-transformed from the logit scale."")
   }
 
@@ -97,7 +100,7 @@ oddsratio_to_riskratio.default <- function(OR, p0, log = FALSE, ...) {
 
 #' @rdname oddsratio_to_riskratio
 #' @export
-riskratio_to_oddsratio <- function(RR, p0, log = FALSE) {
+riskratio_to_oddsratio <- function(RR, p0, log = FALSE, verbose = TRUE, ...) {
   if (log) RR <- exp(RR)
 
   OR <- RR * (1 - p0) / (1 - RR * p0)

---FILE: R/effectsize.R---
@@ -52,14 +52,14 @@
 #' effectsize(Aov)
 #' effectsize(Aov, type = ""omega"")
 #'
-#' Wt <- wilcox.test(1:10, 7:20, mu = -3, alternative = ""less"")
+#' Wt <- wilcox.test(1:10, 7:20, mu = -3, alternative = ""less"", exact = FALSE)
 #' effectsize(Wt)
 #' effectsize(Wt, type = ""u2"")
 #'
 #' ## Models and Anova Tables
 #' ## -----------------------
 #' fit <- lm(mpg ~ factor(cyl) * wt + hp, data = mtcars)
-#' effectsize(fit)
+#' effectsize(fit, method = ""basic"")
 #'
 #' anova_table <- anova(fit)
 #' effectsize(anova_table)

---FILE: R/effectsize.htest.R---
@@ -72,6 +72,11 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
       pooled_sd = !grepl(""Welch"", model$method)
     )
 
+    if (!isTRUE(dots$paired)) {
+      args$x <- na.omit(args$x)
+      args$y <- na.omit(args$y)
+    }
+
     if (type %in% c(""d"", ""g"")) {
       f <- switch(tolower(type),
         d = cohens_d,
@@ -348,6 +353,11 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
     verbose = verbose
   )
 
+  if (!isTRUE(dots$paired)) {
+    args$x <- na.omit(args$x)
+    args$y <- na.omit(args$y)
+  }
+
   if (tolower(type) != ""rb"") {
     if (dots$paired) {
       insight::format_error(""Common language effect size only applicable to 2-sample rank-biserial correlation."")

---FILE: R/equivalence_test.R---
@@ -59,11 +59,11 @@
 #' data(""hardlyworking"")
 #' model <- aov(salary ~ age + factor(n_comps) * cut(seniority, 3), data = hardlyworking)
 #' es <- eta_squared(model, ci = 0.9, alternative = ""two.sided"")
-#' equivalence_test(es, range = 0.15) # TOST
+#' equivalence_test(es, range = c(0, 0.15)) # TOST
 #'
 #' data(""RCT_table"")
 #' OR <- oddsratio(RCT_table, alternative = ""greater"")
-#' equivalence_test(OR, range = 1)
+#' equivalence_test(OR, range = c(0, 1))
 #'
 #' ds <- t_to_d(
 #'   t = c(0.45, -0.65, 7, -2.2, 2.25),

---FILE: R/eta_squared-main.R---
@@ -136,7 +136,7 @@
 #' @examplesIf require(""car"") && require(""afex"")
 #' # afex takes care of both type-3 effects and effects coding:
 #' data(obk.long, package = ""afex"")
-#' model <- afex::aov_car(value ~ treatment * gender + Error(id / (phase)),
+#' model <- afex::aov_car(value ~ gender + Error(id / (phase * hour)),
 #'   data = obk.long, observed = ""gender""
 #' )
 #'

---FILE: man/effectsize.Rd---
@@ -88,14 +88,14 @@ Aov <- oneway.test(extra ~ group, data = sleep, var.equal = TRUE)
 effectsize(Aov)
 effectsize(Aov, type = ""omega"")
 
-Wt <- wilcox.test(1:10, 7:20, mu = -3, alternative = ""less"")
+Wt <- wilcox.test(1:10, 7:20, mu = -3, alternative = ""less"", exact = FALSE)
 effectsize(Wt)
 effectsize(Wt, type = ""u2"")
 
 ## Models and Anova Tables
 ## -----------------------
 fit <- lm(mpg ~ factor(cyl) * wt + hp, data = mtcars)
-effectsize(fit)
+effectsize(fit, method = ""basic"")
 
 anova_table <- anova(fit)
 effectsize(anova_table)

---FILE: man/equivalence_test.effectsize_table.Rd---
@@ -65,11 +65,11 @@ the function used to make the effect size table (\code{cohens_d}, \code{eta_squa
 data(""hardlyworking"")
 model <- aov(salary ~ age + factor(n_comps) * cut(seniority, 3), data = hardlyworking)
 es <- eta_squared(model, ci = 0.9, alternative = ""two.sided"")
-equivalence_test(es, range = 0.15) # TOST
+equivalence_test(es, range = c(0, 0.15)) # TOST
 
 data(""RCT_table"")
 OR <- oddsratio(RCT_table, alternative = ""greater"")
-equivalence_test(OR, range = 1)
+equivalence_test(OR, range = c(0, 1))
 
 ds <- t_to_d(
   t = c(0.45, -0.65, 7, -2.2, 2.25),

---FILE: man/eta_squared.Rd---
@@ -273,7 +273,7 @@ epsilon_squared(model_anova)
 \dontshow{if (require(""car"") && require(""afex"")) (if (getRversion() >= ""3.4"") withAutoprint else force)(\{ # examplesIf}
 # afex takes care of both type-3 effects and effects coding:
 data(obk.long, package = ""afex"")
-model <- afex::aov_car(value ~ treatment * gender + Error(id / (phase)),
+model <- afex::aov_car(value ~ gender + Error(id / (phase * hour)),
   data = obk.long, observed = ""gender""
 )
 

---FILE: man/oddsratio_to_riskratio.Rd---
@@ -5,9 +5,9 @@
 \alias{riskratio_to_oddsratio}
 \title{Convert Between Odds Ratios and Risk Ratios}
 \usage{
-oddsratio_to_riskratio(OR, p0, log = FALSE, ...)
+oddsratio_to_riskratio(OR, p0, log = FALSE, verbose = TRUE, ...)
 
-riskratio_to_oddsratio(RR, p0, log = FALSE)
+riskratio_to_oddsratio(RR, p0, log = FALSE, verbose = TRUE, ...)
 }
 \arguments{
 \item{OR, RR}{Risk ratio of \code{p1/p0} or Odds ratio of \code{odds(p1)/odds(p0)},
@@ -17,6 +17,8 @@ possibly log-ed. \code{OR} can also be a logistic regression model.}
 
 \item{log}{Take in or output the log of the ratio (such as in logistic models).}
 
+\item{verbose}{Toggle warnings and messages on or off.}
+
 \item{...}{Arguments passed to and from other methods.}
 }
 \value{
@@ -40,7 +42,7 @@ m <- glm(am ~ factor(cyl),
   data = mtcars,
   family = binomial()
 )
-oddsratio_to_riskratio(m)
+oddsratio_to_riskratio(m, verbose = FALSE) # RR is relative to the intercept if p0 not provided
 }
 \references{
 Grant, R. L. (2014). Converting an odds ratio to a range of plausible",True,False,Documentation / Formatting,6
easystats,effectsize,dc4f2f0e8d2093a8045e404c9c9609512acf418e,Indrajeet Patil,patilindrajeet.science@gmail.com,2022-12-25T06:51:24Z,GitHub,noreply@github.com,2022-12-25T06:51:24Z,"Iron out deviations from styler (#546)

* Iron out deviations from styler

I'd like these to be resolved because I am going to add a GHA workflow styling and so want to avoid large git diffs later on.

* cleanup lint

* Update effectsize.R

* avoid indentation issue

* Create check-test-warnings.yaml

* fixes the issue?

Co-authored-by: Mattan S. Ben-Shachar <mattansb@msbstats.info>",.github/workflows/check-test-warnings.yaml;DESCRIPTION;R/common_language.R;R/convert_between_OR_to_RR.R;R/convert_between_common_language.R;R/convert_between_odds_to_probs.R;R/effectsize.R,False,True,True,False,42,20,62,"---FILE: .github/workflows/check-test-warnings.yaml---
@@ -0,0 +1,12 @@
+# Running tests with options(warn = 2) to fail on test warnings
+on:
+  push:
+    branches: [main, master]
+  pull_request:
+    branches: [main, master]
+
+name: check-test-warnings
+
+jobs:
+  check-test-warnings:
+    uses: easystats/workflows/.github/workflows/check-test-warnings.yaml@main

---FILE: DESCRIPTION---
@@ -101,7 +101,6 @@ Language: en-US
 Roxygen: list(markdown = TRUE)
 RoxygenNote: 7.2.3
 Config/testthat/edition: 3
-Config/testthat/parallel: true
 Config/Needs/website:
     rstudio/bslib,
     r-lib/pkgdown,

---FILE: R/common_language.R---
@@ -359,8 +359,8 @@ wmw_odds <- function(x, y = NULL, data = NULL,
     y <- data[data$g == ""y"", ""r""]
 
     .foo <- function(p) {
-      min(abs(stats::quantile(x, probs = c(p, 1 - p)) -
-                stats::quantile(y, probs = c(1 - p, p))))
+      diff <- stats::quantile(x, probs = c(p, 1 - p)) - stats::quantile(y, probs = c(1 - p, p))
+      min(abs(diff))
     }
 
     stats::optim(
@@ -434,13 +434,14 @@ wmw_odds <- function(x, y = NULL, data = NULL,
            iterations = 200) {
     d <- data.frame(
       r = c(x, y),
-      g = rep(c(""x"", ""y""), c(length(x), length(y)))
+      g = rep(c(""x"", ""y""), c(length(x), length(y))),
+      stringsAsFactors = TRUE
     )
 
     out <- data.frame(ES = est(d))
 
     if (.test_ci(ci) &&
-        insight::check_if_installed(""boot"", ""for estimating CIs"", stop = FALSE)) {
+      insight::check_if_installed(""boot"", ""for estimating CIs"", stop = FALSE)) {
       ci.level <- .adjust_ci(ci, alternative)
 
       out$CI <- ci
@@ -463,9 +464,10 @@ wmw_odds <- function(x, y = NULL, data = NULL,
     class(out) <- c(""effectsize_table"", class(out))
     # TODO
     # class(out) <- c(""effectsize_difference"", ""effectsize_table"", ""see_effectsize_table"", class(out))
-    .someattributes(out) <- .nlist(mu, ci, ci_method, alternative,
-                                   approximate = TRUE,
-                                   table_footer = ""Non-parametric CLES""
+    .someattributes(out) <- .nlist(
+      mu, ci, ci_method, alternative,
+      approximate = TRUE,
+      table_footer = ""Non-parametric CLES""
     )
     return(out)
   }

---FILE: R/convert_between_OR_to_RR.R---
@@ -51,7 +51,9 @@ oddsratio_to_riskratio.numeric <- function(OR, p0, log = FALSE, ...) {
 #' @export
 oddsratio_to_riskratio.default <- function(OR, p0, log = FALSE, ...) {
   mi <- .get_model_info(OR, ...)
-  if (!mi$is_binomial || !mi$is_logit) insight::format_error(""Model must a binomial model with logit-link (logistic regression)."")
+  if (!mi$is_binomial || !mi$is_logit) {
+    insight::format_error(""Model must be a binomial model with a logit-link (logistic regression)."")
+  }
 
   RR <- parameters::model_parameters(OR, exponentiate = !log, effects = ""fixed"", ...)
   RR$SE <- NULL

---FILE: R/convert_between_common_language.R---
@@ -259,11 +259,16 @@ d_to_overlap.effectsize_difference <- function(d) {
 
 ## Main ----------------
 
+#' @keywords internal
+.is_cles_applicable <- function(d, allow_paired = FALSE) {
+  !any(colnames(d) %in% c(""Cohens_d"", ""Hedges_g"")) ||
+    (isTRUE(attr(d, ""paired"")) && !allow_paired) ||
+    (!isTRUE(attr(d, ""paired"")) && !isTRUE(attr(d, ""pooled_sd"")))
+}
+
 #' @keywords internal
 .cohens_d_to_cles <- function(d, converter, allow_paired = FALSE) {
-  if (!any(colnames(d) %in% c(""Cohens_d"", ""Hedges_g"")) ||
-      (isTRUE(attr(d, ""paired"")) && !allow_paired) ||
-      (!isTRUE(attr(d, ""paired"")) && !isTRUE(attr(d, ""pooled_sd"")))) {
+  if (.is_cles_applicable(d, allow_paired)) {
     insight::format_error(""Common language effect size only applicable to 2-sample Cohen's d with pooled SD."")
   }
 

---FILE: R/convert_between_odds_to_probs.R---
@@ -108,26 +108,29 @@ probs_to_odds.data.frame <- function(probs, log = FALSE, select = NULL, exclude
 
   # Keep subset
   if (!is.null(select) && select %in% names(df)) {
-    to_keep <- as.data.frame(df[!names(df) %in% c(select)])
-    df <- df[names(df) %in% c(select)]
+    select <- as.vector(select)
+    to_keep <- as.data.frame(df[!names(df) %in% select])
+    df <- df[names(df) %in% select]
   } else {
     to_keep <- NULL
   }
 
   # Remove exceptions
   if (!is.null(exclude) && exclude %in% names(df)) {
+    exclude <- as.vector(exclude)
     if (is.null(to_keep)) {
       to_keep <- as.data.frame(df[exclude])
     } else {
       to_keep <- cbind(to_keep, as.data.frame(df[exclude]))
     }
 
-    df <- df[!names(df) %in% c(exclude)]
+    df <- df[!names(df) %in% exclude]
   }
 
   # Remove non-numerics
-  dfother <- df[!sapply(df, is.numeric, simplify = TRUE)]
-  dfnum <- df[sapply(df, is.numeric, simplify = TRUE)]
+  is_num <- vapply(df, is.numeric, logical(1))
+  dfother <- df[!is_num]
+  dfnum <- df[is_num]
 
   # Tranform
   if (!is.null(odds)) {
@@ -144,7 +147,7 @@ probs_to_odds.data.frame <- function(probs, log = FALSE, select = NULL, exclude
   }
 
   # Add exceptions
-  if (!is.null(select) | !is.null(exclude) && exists(""to_keep"")) {
+  if (!is.null(select) || !is.null(exclude) && exists(""to_keep"")) {
     df <- cbind(df, to_keep)
   }
 

---FILE: R/effectsize.R---
@@ -134,8 +134,7 @@ effectsize.easycorrelation <- function(model, ...) {
   r_cols <- 1:which(colnames(model) == r_name)
   if (!is.null(attr(model, ""ci""))) {
     model$CI <- attr(model, ""ci"")
-    CI_cols <- c(""CI"", ""CI_low"", ""CI_high"")
-    CI_cols <- sapply(CI_cols, function(ici) which(colnames(model) == ici))
+    CI_cols <- match(c(""CI"", ""CI_low"", ""CI_high""), colnames(model))
     r_cols <- c(r_cols, CI_cols)
   }
 ",True,False,Dependency / Package,7
easystats,effectsize,a174d2b496ecbe186efc3b92d9945c7c48d27a39,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2022-12-21T07:17:58Z,GitHub,noreply@github.com,2022-12-21T07:17:58Z,"Fix 543 (#545)

* fix error in Cohen's w

* Add interpret for Tschuprows_t

* version bump",DESCRIPTION;NEWS.md;R/convert_stat_chisq.R;R/interpret.R,False,True,True,False,7,5,12,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size
-Version: 0.8.2.00004
+Version: 0.8.2.00005
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",

---FILE: NEWS.md---
@@ -1,4 +1,4 @@
-# effectsize 0.8.2.00004
+# effectsize 0.8.2.xxx
 
 ## New features
 
@@ -8,6 +8,7 @@
 
 ## Bug fixes
 
+- Fixed error in `cohens_w()` for 2-by-X tables.  
 - Solved integer overflow errors in `rank_biserial()` ( #476 )
 
 

---FILE: R/convert_stat_chisq.R---
@@ -151,15 +151,15 @@ chisq_to_cohens_w <- function(chisq, n, nrow, ncol, p,
   colnames(res)[1] <- ""Cohens_w""
 
   if (""CI"" %in% colnames(res)) {
-    if (ncol > 2 && nrow > 2) {
-      max_possible <- sqrt((pmin(ncol, nrow) - 1))
-    } else if (ncol == 1 || nrow == 1) {
+    if (ncol == 1 || nrow == 1) {
       if (missing(p)) {
         max_possible <- Inf # really is chisqMax, but can't compute it without p
       } else {
         q <- min(p / sum(p))
         max_possible <- sqrt((1 - q) / q)
       }
+    } else {
+      max_possible <- sqrt((pmin(ncol, nrow) - 1))
     }
 
     if (attr(res, ""alternative"") == ""greater"") {

---FILE: R/interpret.R---
@@ -176,6 +176,7 @@ interpret.effectsize_table <- function(x, rules, ...) {
     phi_adjusted = ,
     Pearsons_c = ,
     Cohens_w = ,
+    Tschuprows_t = ,
     fei = interpret_cramers_v(value, rules = rules),
 
     ## xtab 2x2",True,False,Reproducibility / Versioning,7
easystats,effectsize,ac13c14587f4581a64051acde462d94f28f99d4b,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-12-12T13:40:16Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-12-12T13:40:16Z,use insight message/warning/error formatting,R/effectsize.R;R/eta_squared_posterior.R;R/means_ratio.R;R/utils.R,False,True,True,False,7,8,15,"---FILE: R/effectsize.R---
@@ -148,6 +148,6 @@ effectsize.easycorrelation <- function(model, ...) {
 
 #' @export
 effectsize.default <- function(model, ...) {
-  # message(""Using standardize_parameters()."")
+  # message(insight::format_message(""Using standardize_parameters().""))
   parameters::standardize_parameters(model, ...)
 }

---FILE: R/eta_squared_posterior.R---
@@ -143,11 +143,10 @@ eta_squared_posterior.brmsfit <- eta_squared_posterior.stanreg
 #'     length(factors_centered) && !all(factors_centered)) {
 #'     non_centered <- !c(numerics_centered, factors_centered)
 #'     non_centered <- names(non_centered)[non_centered]
-#'     warning(
+#'     insight::format_warning(
 #'       ""Not all variables are centered:\n "",
 #'       paste(non_centered, collapse = "", ""),
-#'       ""\n Results might be bogus if involved in interactions..."",
-#'       call. = FALSE
+#'       ""\n Results might be bogus if involved in interactions...""
 #'     )
 #'   }
 #'

---FILE: R/means_ratio.R---
@@ -77,11 +77,11 @@ means_ratio <- function(x, y = NULL, data = NULL,
   y <- out[[""y""]]
 
   if (is.null(y)) {
-    stop(""Only one sample provided. y or data must be provided."", call. = FALSE)
+    insight::format_error(""Only one sample provided. y or data must be provided."")
   }
 
   if (any(x < 0) || any(y < 0)) {
-    stop(""x,y must be non-negative (on a ratio scale)."", call. = FALSE)
+    insight::format_error(""x,y must be non-negative (on a ratio scale)."")
   }
 
   # Get summary stats
@@ -91,7 +91,7 @@ means_ratio <- function(x, y = NULL, data = NULL,
   sd2 <- stats::sd(y)
 
   if (isTRUE(all.equal(m1, 0)) || isTRUE(all.equal(m2, 0))) {
-    stop(""Mean(s) equal to equal zero. Unable to calculate means ratio."", call. = FALSE)
+    insight::format_error(""Mean(s) equal to equal zero. Unable to calculate means ratio."")
   }
 
 

---FILE: R/utils.R---
@@ -81,7 +81,7 @@
     length(ci) != 1L ||
     ci < 0 ||
     ci > 1) {
-    stop(""ci must be a single numeric value between (0, 1)"", call. = FALSE)
+    insight::format_error(""ci must be a single numeric value between (0, 1)"")
   }
   return(TRUE)
 }",True,False,Implementation / Logic,6
easystats,effectsize,982a0ae3527af13cf79c86e20273c721dd494cd2,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-10-21T19:46:26Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-10-21T19:46:26Z,"use Use examplesIf

https://github.com/easystats/easystats/issues/318",R/effectsize.R;man/effectsize.Rd,False,True,True,False,46,46,92,"---FILE: R/effectsize.R---
@@ -56,29 +56,6 @@
 #' effectsize(Wt)
 #' effectsize(Wt, type = ""u2"")
 #'
-#' ## Bayesian Hypothesis Testing
-#' ## ---------------------------
-#' \donttest{
-#' if (require(BayesFactor)) {
-#'   bf_prop <- proportionBF(3, 7, p = 0.3)
-#'   effectsize(bf_prop)
-#'
-#'   bf_corr <- correlationBF(attitude$rating, attitude$complaints)
-#'   effectsize(bf_corr)
-#'
-#'   data(raceDolls)
-#'   bf_xtab <- contingencyTableBF(raceDolls, sampleType = ""poisson"", fixedMargin = ""cols"")
-#'   effectsize(bf_xtab)
-#'   effectsize(bf_xtab, type = ""oddsratio"")
-#'
-#'   bf_ttest <- ttestBF(sleep$extra[sleep$group == 1],
-#'     sleep$extra[sleep$group == 2],
-#'     paired = TRUE, mu = -1
-#'   )
-#'   effectsize(bf_ttest)
-#' }
-#' }
-#'
 #' ## Models and Anova Tables
 #' ## -----------------------
 #' fit <- lm(mpg ~ factor(cyl) * wt + hp, data = mtcars)
@@ -87,6 +64,29 @@
 #' anova_table <- anova(fit)
 #' effectsize(anova_table)
 #' effectsize(anova_table, type = ""epsilon"")
+#'
+#' @examplesIf requireNamespace(""BayesFactor"", quietly = TRUE)
+#' ## Bayesian Hypothesis Testing
+#' ## ---------------------------
+#' \donttest{
+#' bf_prop <- BayesFactor::proportionBF(3, 7, p = 0.3)
+#' effectsize(bf_prop)
+#'
+#' bf_corr <- BayesFactor::correlationBF(attitude$rating, attitude$complaints)
+#' effectsize(bf_corr)
+#'
+#' data(RCT_table)
+#' bf_xtab <- BayesFactor::contingencyTableBF(RCT_table, sampleType = ""poisson"", fixedMargin = ""cols"")
+#' effectsize(bf_xtab)
+#' effectsize(bf_xtab, type = ""oddsratio"")
+#'
+#' bf_ttest <- BayesFactor::ttestBF(sleep$extra[sleep$group == 1],
+#'   sleep$extra[sleep$group == 2],
+#'   paired = TRUE, mu = -1
+#' )
+#' effectsize(bf_ttest)
+#' }
+#'
 #' @export
 effectsize <- function(model, ...) {
   UseMethod(""effectsize"")

---FILE: man/effectsize.Rd---
@@ -92,29 +92,6 @@ Wt <- wilcox.test(1:10, 7:20, mu = -3, alternative = ""less"")
 effectsize(Wt)
 effectsize(Wt, type = ""u2"")
 
-## Bayesian Hypothesis Testing
-## ---------------------------
-\donttest{
-if (require(BayesFactor)) {
-  bf_prop <- proportionBF(3, 7, p = 0.3)
-  effectsize(bf_prop)
-
-  bf_corr <- correlationBF(attitude$rating, attitude$complaints)
-  effectsize(bf_corr)
-
-  data(raceDolls)
-  bf_xtab <- contingencyTableBF(raceDolls, sampleType = ""poisson"", fixedMargin = ""cols"")
-  effectsize(bf_xtab)
-  effectsize(bf_xtab, type = ""oddsratio"")
-
-  bf_ttest <- ttestBF(sleep$extra[sleep$group == 1],
-    sleep$extra[sleep$group == 2],
-    paired = TRUE, mu = -1
-  )
-  effectsize(bf_ttest)
-}
-}
-
 ## Models and Anova Tables
 ## -----------------------
 fit <- lm(mpg ~ factor(cyl) * wt + hp, data = mtcars)
@@ -123,6 +100,29 @@ effectsize(fit)
 anova_table <- anova(fit)
 effectsize(anova_table)
 effectsize(anova_table, type = ""epsilon"")
+
+\dontshow{if (requireNamespace(""BayesFactor"", quietly = TRUE)) (if (getRversion() >= ""3.4"") withAutoprint else force)(\{ # examplesIf}
+## Bayesian Hypothesis Testing
+## ---------------------------
+\donttest{
+bf_prop <- BayesFactor::proportionBF(3, 7, p = 0.3)
+effectsize(bf_prop)
+
+bf_corr <- BayesFactor::correlationBF(attitude$rating, attitude$complaints)
+effectsize(bf_corr)
+
+data(RCT_table)
+bf_xtab <- BayesFactor::contingencyTableBF(RCT_table, sampleType = ""poisson"", fixedMargin = ""cols"")
+effectsize(bf_xtab)
+effectsize(bf_xtab, type = ""oddsratio"")
+
+bf_ttest <- BayesFactor::ttestBF(sleep$extra[sleep$group == 1],
+  sleep$extra[sleep$group == 2],
+  paired = TRUE, mu = -1
+)
+effectsize(bf_ttest)
+}
+\dontshow{\}) # examplesIf}
 }
 \seealso{
 \code{vignette(package = ""effectsize"")}",True,False,Documentation / Formatting,6
easystats,effectsize,fb7137d8b4d1ae41af5290ba62830cd0dc4057e8,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2022-10-18T09:52:09Z,GitHub,noreply@github.com,2022-10-18T09:52:09Z,fix CRAN unicode issue (#521),DESCRIPTION;NEWS.md;R/is_effectsize_name.R;R/sysdata.rda;WIP/convert_stat_H.R;data-raw/es_info.R;dev/rhub.R;man/es_info.Rd;tests/testthat/test-eta_squared.R;tests/testthat/test-print.R;vignettes/anovaES.Rmd,True,True,True,False,113,113,226,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size
-Version: 0.8.0.0001
+Version: 0.8.1
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",

---FILE: NEWS.md---
@@ -1,4 +1,4 @@
-# effectsize 0.8.0.0001
+# effectsize 0.8.1
 
 ## Changes
 

---FILE: R/is_effectsize_name.R---
@@ -42,99 +42,12 @@ get_effectsize_label <- function(x, ignore_case = TRUE, use_symbols = getOption(
 
 # es_info -----------------------------------------------------------------
 
-
-#' List of effect size names
-#'
-#' Can always add more info here if need be...
-#'
-#' @keywords internal
-es_info <- matrix(
-  c(
-    ## Diffs
-    ""Cohens_d"", ""Cohen's d"", NA, ""twotail"", -Inf, Inf, 0,
-    ""Hedges_g"", ""Hedges' g"", NA, ""twotail"", -Inf, Inf, 0,
-    ""Glass_delta"", ""Glass' delta"", ""Glass' \u0394"", ""twotail"", -Inf, Inf, 0,
-    ""Mahalanobis_D"", ""Mahalanobis' D"", NA, ""onetail"", 0, Inf, 0,
-
-    ## xtab cor
-    ""Cramers_v"", ""Cramer's V"", NA, ""onetail"", 0, 1, 0,
-    ""Cramers_v_adjusted"", ""Cramer's V (adj.)"", NA, ""onetail"", 0, 1, 0,
-    ""Tschuprows_t"", ""Tschuprow's T"", NA, ""onetail"", 0, 1, 0,
-    ""phi"", ""Phi"", ""\u03D5"", ""onetail"", 0, 1, 0,
-    ""phi_adjusted"", ""Phi (adj.)"", ""\u03D5 (adj.)"", ""onetail"", 0, 1, 0,
-    ""Pearsons_c"", ""Pearson's C"", NA, ""onetail"", 0, 1, 0,
-    ""Cohens_w"", ""Cohen's w"", NA, ""onetail"", 0, Inf, 0,
-    ""Fei"", ""Fei"", ""\u05E4\u200E"", ""onetail"", 0, 1, 0,
-
-    ## xtab 2x2
-    ""Cohens_h"", ""Cohen's h"", NA, ""twotail"", -pi, pi, 0,
-    ""Odds_ratio"", ""Odds ratio"", NA, ""twotail"", 0, Inf, 1,
-    ""log_Odds_ratio"", ""log(Odds ratio)"", NA, ""twotail"", -Inf, Inf, 0,
-    ""Risk_ratio"", ""Risk ratio"", NA, ""twotail"", 0, Inf, 1,
-    ""log_Risk_ratio"", ""log(Risk ratio)"", NA, ""twotail"", -Inf, Inf, 0,
-
-    ## xtab dep
-    ""Cohens_g"", ""Cohen's g"", NA, ""onetail"", -0.5, 0.5, 0,
-
-    ## ANOVA
-    ""Eta2"", ""Eta2"", ""\u03B7\u00b2"", ""onetail"", 0, 1, 0,
-    ""Eta2_partial"", ""Eta2 (partial)"", ""\u03B7\u00b2 (partial)"", ""onetail"", 0, 1, 0,
-    ""Eta2_generalized"", ""Eta2 (generalized)"", ""\u03B7\u00b2 (generalized)"", ""onetail"", 0, 1, 0,
-    ""Epsilon2"", ""Epsilon2"", ""\u03B5\u00b2"", ""onetail"", 0, 1, 0,
-    ""Epsilon2_partial"", ""Epsilon2 (partial)"", ""\u03B5\u00b2 (partial)"", ""onetail"", 0, 1, 0,
-    ""Omega2"", ""Omega2"", ""\u03C9\u00b2"", ""onetail"", 0, 1, 0,
-    ""Omega2_partial"", ""Omega2 (partial)"", ""\u03C9\u00b2 (partial)"", ""onetail"", 0, 1, 0,
-    ""Cohens_f"", ""Cohen's f"", NA, ""onetail"", 0, Inf, 0,
-    ""Cohens_f_partial"", ""Cohen's f (partial)"", NA, ""onetail"", 0, Inf, 0,
-    ""Cohens_f2"", ""Cohen's f2"", ""Cohen's f\u00b2"", ""onetail"", 0, Inf, 0,
-    ""Cohens_f2_partial"", ""Cohen's f2 (partial)"", ""Cohen's f\u00b2 (partial)"", ""onetail"", 0, Inf, 0,
-
-    ## Rank
-    ""r_rank_biserial"", ""r (rank biserial)"", NA, ""twotail"", -1, 1, 0,
-    ""Kendalls_W"", ""Kendall's W"", NA, ""onetail"", 0, 1, 0,
-    ""rank_epsilon_squared"", ""Epsilon2 (rank)"", ""\u03B5\u00b2(R)"", ""onetail"", 0, 1, 0,
-    ""rank_eta_squared"", ""Eta2 (rank)"", ""\u03B7\u00b2(H)"", ""onetail"", 0, 1, 0,
-
-    ## CLES
-    ""p_superiority"", ""Pr(superiority)"", NA, ""twotail"", 0, 1, 0.5,
-    ""WMW_odds"", ""WMW Odds"", NA, ""twotail"", 0, Inf, 1,
-    ""Cohens_U1"", ""Cohen's U1"", NA, ""onetail"", 0, 1, 0,
-    ""Cohens_U2"", ""Cohen's U2"", NA, ""onetail"", 0.5, 1, 0.5,
-    ""Cohens_U3"", ""Cohen's U3"", NA, ""twotail"", 0, 1, 0.5,
-    ""overlap"", ""Overlap"", NA, ""onetail"", 0, 1, 1,
-
-    ## Other
-    ""r"", ""r"", NA, ""twotail"", -1, 1, 0,
-    ""d"", ""d"", NA, ""twotail"", -Inf, Inf, 0,
-
-    ## Std Coefficient
-    ""Std_Coefficient"", ""Coefficient (std.)"", NA, ""twotail"", -Inf, Inf, 0,
-    ""Std_Odds_ratio"", ""Odds Ratio (std.)"", NA, ""twotail"", 0, Inf, 1,
-    ""Std_Risk_ratio"", ""Risk Ratio (std.)"", NA, ""twotail"", 0, Inf, 1,
-    ""Std_IRR"", ""IRR (std.)"", ""twotail"", NA, 0, Inf, 1,
-    ""Std_Median"", ""Median (std.)"", NA, ""twotail"", -Inf, Inf, 0,
-    ""Std_Mean"", ""Mean (std.)"", NA, ""twotail"", -Inf, Inf, 0,
-    ""Std_MAP"", ""MAP (std.)"", NA, ""twotail"", -Inf, Inf, 0
-  ),
-  ncol = 7, byrow = TRUE,
-  dimnames = list(NULL, c(""name"", ""label"", ""symbol"", ""direction"", ""lb"", ""ub"", ""null""))
-)
-es_info <- as.data.frame(es_info, stringsAsFactors = FALSE)
-es_info$lb <- as.numeric(es_info$lb)
-es_info$ub <- as.numeric(es_info$ub)
-es_info$null <- as.numeric(es_info$null)
-es_info$symbol[is.na(es_info$symbol)] <- es_info$label[is.na(es_info$symbol)]
-rownames(es_info) <- es_info$name
-
+# See data-raw/es_info.R
 
 # Utils -------------------------------------------------------------------
 
 
 #' @keywords internal
 .resolve_use_symbols <- function(use_symbols) {
-  use_symbols &&
-    !(
-      (Sys.info()[""sysname""] == ""windows"" || grepl(""^mingw"", R.version$os)) &&
-        getRversion() < ""4.2""
-    )
+  use_symbols && l10n_info()[[""UTF-8""]]
 }

---FILE: WIP/convert_stat_H.R---
@@ -0,0 +1,18 @@
+#' Convert H statistic to Rank Epsilon / Eta Squared
+#'
+#' @param H Kruskal-Wallis rank sum test statistic. See [stats::kruskal.test()]
+#' @param N Total sample size
+#' @param k Number of groups
+#'
+#' @export
+h_to_epsilon <- function(H, N) {
+  H / ((N^2 - 1) / (N + 1))
+}
+
+#' @export
+#' @rdname h_to_epsilon
+h_to_epsilon <- function(H, N, k) {
+  (H - k + 1) / (N - k)
+}
+
+# TODO use these internally
\ No newline at end of file

---FILE: data-raw/es_info.R---
@@ -0,0 +1,73 @@
+es_info <- tibble::tribble(
+  ~name, ~label, ~symbol, ~direction, ~lb, ~ub, ~null,
+  ## Std. diffs
+  ""Cohens_d"", ""Cohen's d"", NA, ""twotail"", -Inf, Inf, 0,
+  ""Hedges_g"", ""Hedges' g"", NA, ""twotail"", -Inf, Inf, 0,
+  ""Glass_delta"", ""Glass' delta"", ""Glass' \u0394"", ""twotail"", -Inf, Inf, 0,
+  ""Mahalanobis_D"", ""Mahalanobis' D"", NA, ""onetail"", 0, Inf, 0,
+
+  ## xtab cor
+  ""Cramers_v"", ""Cramer's V"", NA, ""onetail"", 0, 1, 0,
+  ""Cramers_v_adjusted"", ""Cramer's V (adj.)"", NA, ""onetail"", 0, 1, 0,
+  ""Tschuprows_t"", ""Tschuprow's T"", NA, ""onetail"", 0, 1, 0,
+  ""phi"", ""Phi"", ""\u03D5"", ""onetail"", 0, 1, 0,
+  ""phi_adjusted"", ""Phi (adj.)"", ""\u03D5 (adj.)"", ""onetail"", 0, 1, 0,
+  ""Pearsons_c"", ""Pearson's C"", NA, ""onetail"", 0, 1, 0,
+  ""Cohens_w"", ""Cohen's w"", NA, ""onetail"", 0, Inf, 0,
+  ""Fei"", ""Fei"", ""\u05E4\u200E"", ""onetail"", 0, 1, 0,
+
+  ## xtab 2x2
+  ""Cohens_h"", ""Cohen's h"", NA, ""twotail"", -pi, pi, 0,
+  ""Odds_ratio"", ""Odds ratio"", NA, ""twotail"", 0, Inf, 1,
+  ""log_Odds_ratio"", ""log(Odds ratio)"", NA, ""twotail"", -Inf, Inf, 0,
+  ""Risk_ratio"", ""Risk ratio"", NA, ""twotail"", 0, Inf, 1,
+  ""log_Risk_ratio"", ""log(Risk ratio)"", NA, ""twotail"", -Inf, Inf, 0,
+
+  ## xtab dep
+  ""Cohens_g"", ""Cohen's g"", NA, ""onetail"", -0.5, 0.5, 0,
+
+  ## ANOVA
+  ""Eta2"", ""Eta2"", ""\u03B7\u00b2"", ""onetail"", 0, 1, 0,
+  ""Eta2_partial"", ""Eta2 (partial)"", ""\u03B7\u00b2 (partial)"", ""onetail"", 0, 1, 0,
+  ""Eta2_generalized"", ""Eta2 (generalized)"", ""\u03B7\u00b2 (generalized)"", ""onetail"", 0, 1, 0,
+  ""Epsilon2"", ""Epsilon2"", ""\u03B5\u00b2"", ""onetail"", 0, 1, 0,
+  ""Epsilon2_partial"", ""Epsilon2 (partial)"", ""\u03B5\u00b2 (partial)"", ""onetail"", 0, 1, 0,
+  ""Omega2"", ""Omega2"", ""\u03C9\u00b2"", ""onetail"", 0, 1, 0,
+  ""Omega2_partial"", ""Omega2 (partial)"", ""\u03C9\u00b2 (partial)"", ""onetail"", 0, 1, 0,
+  ""Cohens_f"", ""Cohen's f"", NA, ""onetail"", 0, Inf, 0,
+  ""Cohens_f_partial"", ""Cohen's f (partial)"", NA, ""onetail"", 0, Inf, 0,
+  ""Cohens_f2"", ""Cohen's f2"", ""Cohen's f\u00b2"", ""onetail"", 0, Inf, 0,
+  ""Cohens_f2_partial"", ""Cohen's f2 (partial)"", ""Cohen's f\u00b2 (partial)"", ""onetail"", 0, Inf, 0,
+
+  ## Rank
+  ""r_rank_biserial"", ""r (rank biserial)"", NA, ""twotail"", -1, 1, 0,
+  ""Kendalls_W"", ""Kendall's W"", NA, ""onetail"", 0, 1, 0,
+  ""rank_epsilon_squared"", ""Epsilon2 (rank)"", ""\u03B5\u00b2(R)"", ""onetail"", 0, 1, 0,
+  ""rank_eta_squared"", ""Eta2 (rank)"", ""\u03B7\u00b2(H)"", ""onetail"", 0, 1, 0,
+
+  ## CLES
+  ""p_superiority"", ""Pr(superiority)"", NA, ""twotail"", 0, 1, 0.5,
+  ""WMW_odds"", ""WMW Odds"", NA, ""twotail"", 0, Inf, 1,
+  ""Cohens_U1"", ""Cohen's U1"", NA, ""onetail"", 0, 1, 0,
+  ""Cohens_U2"", ""Cohen's U2"", NA, ""onetail"", 0.5, 1, 0.5,
+  ""Cohens_U3"", ""Cohen's U3"", NA, ""twotail"", 0, 1, 0.5,
+  ""overlap"", ""Overlap"", NA, ""onetail"", 0, 1, 1,
+
+  ## Other
+  ""r"", ""r"", NA, ""twotail"", -1, 1, 0,
+  ""d"", ""d"", NA, ""twotail"", -Inf, Inf, 0,
+
+  ## Std Coefficient
+  ""Std_Coefficient"", ""Coefficient (std.)"", NA, ""twotail"", -Inf, Inf, 0,
+  ""Std_Odds_ratio"", ""Odds Ratio (std.)"", NA, ""twotail"", 0, Inf, 1,
+  ""Std_Risk_ratio"", ""Risk Ratio (std.)"", NA, ""twotail"", 0, Inf, 1,
+  ""Std_IRR"", ""IRR (std.)"", ""twotail"", NA, 0, Inf, 1,
+  ""Std_Median"", ""Median (std.)"", NA, ""twotail"", -Inf, Inf, 0,
+  ""Std_Mean"", ""Mean (std.)"", NA, ""twotail"", -Inf, Inf, 0,
+  ""Std_MAP"", ""MAP (std.)"", NA, ""twotail"", -Inf, Inf, 0
+)
+
+es_info <- as.data.frame(es_info)
+es_info[is.na(es_info[[""symbol""]]), ""symbol""] <- es_info[is.na(es_info[[""symbol""]]), ""label""]
+rownames(es_info) <- es_info[[""name""]]
+usethis::use_data(es_info, internal = TRUE)

---FILE: dev/rhub.R---
@@ -0,0 +1,5 @@
+library(rhub)
+
+# validate_email()
+# list_validated_emails()
+check(platforms = ""debian-clang-devel"")

---FILE: man/es_info.Rd---
@@ -1,16 +0,0 @@
-% Generated by roxygen2: do not edit by hand
-% Please edit documentation in R/is_effectsize_name.R
-\docType{data}
-\name{es_info}
-\alias{es_info}
-\title{List of effect size names}
-\format{
-An object of class \code{data.frame} with 48 rows and 7 columns.
-}
-\usage{
-es_info
-}
-\description{
-Can always add more info here if need be...
-}
-\keyword{internal}

---FILE: tests/testthat/test-eta_squared.R---
@@ -494,7 +494,10 @@ test_that(""afex | mixed()"", {
 
   data(md_15.1, package = ""afex"")
   # random intercept plus random slope
-  t15.4a <- afex::mixed(iq ~ timecat + (1 + time | id), data = md_15.1)
+  t15.4a <- afex::mixed(iq ~ timecat + (1 + time | id),
+    data = md_15.1,
+    method = ""S""
+  )
   expect_equal(
     eta_squared(t15.4a),
     eta_squared(t15.4a$full_model)

---FILE: tests/testthat/test-print.R---
@@ -1,3 +1,4 @@
+# library(testthat)
 
 test_that(""print | effectsize table"", {
   ## digits
@@ -168,9 +169,7 @@ test_that(""rules"", {
 
 
 test_that(""printing symbols works as expected"", {
-  skip_if(getRversion() < 4.2 &&
-    (Sys.info()[""sysname""] == ""windows"" ||
-      grepl(""^mingw"", R.version$os)))
+  skip_if_not(l10n_info()[[""UTF-8""]])
 
   RCT <- matrix(c(71, 50, 30, 100), nrow = 2L)
   P <- phi(RCT)

---FILE: vignettes/anovaES.Rmd---
@@ -233,7 +233,12 @@ always the case.
 
 For example, in linear mixed models (LMM/HLM/MLM), the estimation of all required *SS*s is not straightforward. However, we can still *approximate* these effect sizes (only their partial versions) based on the **test-statistic approximation method** (learn more in the [*Effect Size from Test Statistics* vignette](https://easystats.github.io/effectsize/articles/from_test_statistics.html)).
 
-```{r, eval=require(lmerTest)}
+```{r, echo = FALSE, eval=TRUE}
+lmm_pkgs <- c(""lmerTest"", ""lme4"")
+eval_lmm <- all(sapply(lmm_pkgs, requireNamespace, quietly = TRUE))
+```
+
+```{r, eval=eval_lmm}
 library(lmerTest)
 
 fit_lmm <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
@@ -246,7 +251,7 @@ F_to_eta2(45.8, df = 1, df_error = 17)
 Or directly with `eta_squared() and co.:
 
 
-```{r, eval=require(lmerTest)}
+```{r, eval=eval_lmm}
 eta_squared(fit_lmm)
 epsilon_squared(fit_lmm)
 omega_squared(fit_lmm)",True,True,Dependency / Package,7
easystats,effectsize,1b048edd408f124c51aa78adc0d9c9c204d1adaf,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2022-10-14T14:20:07Z,GitHub,noreply@github.com,2022-10-14T14:20:07Z,"Misc (#519)

* use insight::format_ for warning and error

* t(music)

* Update xtabs.Rmd

* Update _pkgdown.yml

* fix test

* insight::format_alert

* Update xtabs.Rmd

* UB for cohens_w

* fix error/warning formatting

* styler

* Update test-eta_squared.R",NEWS.md;R/cohens_d.R;R/cohens_g.R;R/common_language.R;R/convert_between_OR_to_RR.R;R/convert_between_common_language.R;R/convert_stat_chisq.R;R/convert_stat_to_anova.R;R/convert_stat_to_d.R;R/convert_stat_to_r.R;R/effectsize.BFBayesFactor.R;R/effectsize.htest.R;R/equivalence_test.R;R/eta_squared-main.R;R/eta_squared-methods.R;R/eta_squared_posterior.R;R/interpret.R;R/interpret_bf.R;R/mahalanobis_D.R;R/print.effectsize_table.R;R/rank_ANOVA.R;R/rank_diff.R;R/utils.R;R/utils_interpret.R;R/utils_validate_input_data.R;R/xtab_corr.R;R/xtab_diff.R;WIP/paired_d2.R;_pkgdown.yml;data-raw/tabular data.R;data/Music_preferences.rdata;man/Music_preferences.Rd;man/convert_chisq.Rd;man/effectsize_CIs.Rd;tests/testthat/test-eta_squared.R;tests/testthat/test-interpret.R;tests/testthat/test-xtab.R;vignettes/xtabs.Rmd,True,True,True,False,178,169,347,"---FILE: NEWS.md---
@@ -1,5 +1,9 @@
 # effectsize 0.8.0.0001
 
+## Changes
+
+- cohens_w() has an exact upper bound when used as an effect size for goodness-of-fit.
+
 ## Bug fixes
 
 - When using formula input to effect size function, `na.action` arguments are respected (#517)

---FILE: R/cohens_d.R---
@@ -210,7 +210,7 @@ glass_delta <- function(x, y = NULL, data = NULL,
 
   if (is.null(y)) {
     if (type == ""delta"") {
-      stop(""For Glass' Delta, please provide data from two samples."", call. = FALSE)
+      insight::format_error(""For Glass' Delta, please provide data from two samples."")
     }
     y <- rep(0, length.out = length(x))
     paired <- TRUE

---FILE: R/cohens_g.R---
@@ -65,21 +65,21 @@ cohens_g <- function(x, y = NULL,
 
   if (!is.matrix(x)) {
     if (is.null(y)) {
-      stop(""if 'x' is not a matrix, 'y' must be given"", call. = FALSE)
+      insight::format_error(""if 'x' is not a matrix, 'y' must be given"")
     }
     if (length(x) != length(y)) {
-      stop(""'x' and 'y' must have the same length"", call. = FALSE)
+      insight::format_error(""'x' and 'y' must have the same length"")
     }
     OK <- stats::complete.cases(x, y)
     x <- as.factor(x[OK])
     y <- as.factor(y[OK])
     if ((nlevels(x) < 2) || (nlevels(y) != nlevels(x))) {
-      stop(""'x' and 'y' must have the same number of levels (minimum 2)"", call. = FALSE)
+      insight::format_error(""'x' and 'y' must have the same number of levels (minimum 2)"")
     }
     x <- table(x, y)
   } else {
     if ((nrow(x) < 2) || (ncol(x) != nrow(x))) {
-      stop(""'x' must be square with at least two rows and columns"", call. = FALSE)
+      insight::format_error(""'x' must be square with at least two rows and columns"")
     }
   }
 

---FILE: R/common_language.R---
@@ -168,10 +168,10 @@ cohens_u1 <- function(x, y = NULL, data = NULL,
   )
   x <- data[[""x""]]
   y <- data[[""y""]]
-  if (is.null(y)) stop(""cohens_u3 only applicable to two sample case."", call. = FALSE)
+  if (is.null(y)) insight::format_error(""cohens_u3 only applicable to two sample case."")
 
   if (!parametric) {
-    stop(""Cohen's U1 only available for parametric estimation."", call. = FALSE)
+    insight::format_error(""Cohen's U1 only available for parametric estimation."")
   }
 
   d <- cohens_d(
@@ -208,7 +208,7 @@ cohens_u2 <- function(x, y = NULL, data = NULL,
   )
   x <- data[[""x""]]
   y <- data[[""y""]]
-  if (is.null(y)) stop(""cohens_u3 only applicable to two sample case."", call. = FALSE)
+  if (is.null(y)) insight::format_error(""cohens_u3 only applicable to two sample case."")
 
   if (parametric) {
     d <- cohens_d(
@@ -252,7 +252,7 @@ cohens_u3 <- function(x, y = NULL, data = NULL,
   )
   x <- data[[""x""]]
   y <- data[[""y""]]
-  if (is.null(y)) stop(""cohens_u3 only applicable to two sample case."", call. = FALSE)
+  if (is.null(y)) insight::format_error(""cohens_u3 only applicable to two sample case."")
 
   if (parametric) {
     d <- cohens_d(
@@ -295,7 +295,7 @@ p_overlap <- function(x, y = NULL, data = NULL,
   )
   x <- data[[""x""]]
   y <- data[[""y""]]
-  if (is.null(y)) stop(""Overlap only applicable to two sample case."", call. = FALSE)
+  if (is.null(y)) insight::format_error(""Overlap only applicable to two sample case."")
 
   if (parametric) {
     d <- cohens_d(

---FILE: R/convert_between_OR_to_RR.R---
@@ -51,7 +51,7 @@ oddsratio_to_riskratio.numeric <- function(OR, p0, log = FALSE, ...) {
 #' @export
 oddsratio_to_riskratio.default <- function(OR, p0, log = FALSE, ...) {
   mi <- .get_model_info(OR, ...)
-  if (!mi$is_binomial || !mi$is_logit) stop(""Model must a binomial model with logit-link (logistic regression)"", call. = FALSE)
+  if (!mi$is_binomial || !mi$is_logit) insight::format_error(""Model must a binomial model with logit-link (logistic regression)."")
 
   RR <- parameters::model_parameters(OR, exponentiate = !log, effects = ""fixed"", ...)
   RR$SE <- NULL
@@ -64,11 +64,9 @@ oddsratio_to_riskratio.default <- function(OR, p0, log = FALSE, ...) {
     if (!log) p0 <- log(p0)
     p0 <- plogis(p0)
 
-    warning(
+    insight::format_warning(
       ""'p0' not provided."",
-      ""RR is relative to the intercept (p0 = "",
-      insight::format_value(p0),
-      "") - make sure your intercept is meaningful.""
+      sprintf(""RR is relative to the intercept (p0 = %s) - make sure your intercept is meaningful."", insight::format_value(p0))
     )
   }
 
@@ -79,7 +77,7 @@ oddsratio_to_riskratio.default <- function(OR, p0, log = FALSE, ...) {
     )
 
   if (any(c(""CI_low"", ""CI_high"") %in% colnames(RR))) {
-    warning(""CIs are back-transformed from the logit scale."", call. = FALSE)
+    insight::format_warning(""CIs are back-transformed from the logit scale."")
   }
 
   RR[RR$Parameter == ""(Intercept)"", ""Coefficient""] <- p0

---FILE: R/convert_between_common_language.R---
@@ -155,7 +155,7 @@ rb_to_wmw_odds.numeric <- function(rb) {
 #' @export
 rb_to_wmw_odds.effectsize_difference <- function(rb) {
   if (!any(colnames(rb) == ""r_rank_biserial"")) {
-    stop(""Common language effect size only applicable rank-biserial correlation."", call. = FALSE)
+    insight::format_error(""Common language effect size only applicable rank-biserial correlation."")
   }
 
   cols_to_conv <- colnames(rb) %in% c(""r_rank_biserial"", ""CI_low"", ""CI_high"")
@@ -264,7 +264,7 @@ d_to_overlap.effectsize_difference <- function(d) {
   if (!any(colnames(d) %in% c(""Cohens_d"", ""Hedges_g"")) ||
     (isTRUE(attr(d, ""paired"")) && !allow_paired) ||
     (!isTRUE(attr(d, ""paired"")) && !isTRUE(attr(d, ""pooled_sd"")))) {
-    stop(""Common language effect size only applicable to 2-sample Cohen's d with pooled SD."", call. = FALSE)
+    insight::format_error(""Common language effect size only applicable to 2-sample Cohen's d with pooled SD."")
   }
 
   cols_to_convert <- colnames(d) %in% c(""Cohens_d"", ""Hedges_g"", ""CI_low"", ""CI_high"")
@@ -287,7 +287,7 @@ d_to_overlap.effectsize_difference <- function(d) {
 #' @export
 rb_to_p_superiority.effectsize_difference <- function(rb) {
   if (!any(colnames(rb) == ""r_rank_biserial"")) {
-    stop(""Common language effect size only applicable rank-biserial correlation."", call. = FALSE)
+    insight::format_error(""Common language effect size only applicable rank-biserial correlation."")
   }
 
   cols_to_conv <- colnames(rb) %in% c(""r_rank_biserial"", ""CI_low"", ""CI_high"")

---FILE: R/convert_stat_chisq.R---
@@ -115,7 +115,7 @@ chisq_to_phi <- function(chisq, n, nrow = 2, ncol = 2,
                          ci = 0.95, alternative = ""greater"",
                          ...) {
   if ((!missing(nrow) && nrow != 2) || (!missing(ncol) && ncol != 2)) {
-    stop(""Phi is not appropriate for non-2x2 tables."", call. = FALSE)
+    insight::format_error(""Phi is not appropriate for non-2x2 tables."")
   }
 
   res <- .chisq_to_generic_phi(chisq, n, nrow, ncol,
@@ -141,7 +141,7 @@ chisq_to_phi <- function(chisq, n, nrow = 2, ncol = 2,
 
 #' @rdname convert_chisq
 #' @export
-chisq_to_cohens_w <- function(chisq, n, nrow, ncol,
+chisq_to_cohens_w <- function(chisq, n, nrow, ncol, p,
                               ci = 0.95, alternative = ""greater"",
                               ...) {
   res <- .chisq_to_generic_phi(chisq, n, nrow, ncol,
@@ -154,7 +154,12 @@ chisq_to_cohens_w <- function(chisq, n, nrow, ncol,
     if (ncol > 2 && nrow > 2) {
       max_possible <- sqrt((pmin(ncol, nrow) - 1))
     } else if (ncol == 1 || nrow == 1) {
-      max_possible <- Inf # really is chisqMax, but can't compute it without p
+      if (missing(p)) {
+        max_possible <- Inf # really is chisqMax, but can't compute it without p
+      } else {
+        q <- min(p / sum(p))
+        max_possible <- sqrt((1 - q) / q)
+      }
     }
 
     if (attr(res, ""alternative"") == ""greater"") {
@@ -174,7 +179,7 @@ chisq_to_cramers_v <- function(chisq, n, nrow, ncol,
                                ci = 0.95, alternative = ""greater"",
                                ...) {
   if (nrow == 1 || ncol == 1) {
-    stop(""Cramer's V not applicable to goodness-of-fit tests."", call. = FALSE)
+    insight::format_error(""Cramer's V not applicable to goodness-of-fit tests."")
   }
 
   res <- .chisq_to_generic_phi(chisq, n, nrow, ncol,
@@ -215,7 +220,7 @@ chisq_to_tschuprows_t <- function(chisq, n, nrow, ncol,
                                   ci = 0.95, alternative = ""greater"",
                                   ...) {
   if (nrow == 1 || ncol == 1) {
-    stop(""Tschuprow's T not applicable to goodness-of-fit tests."", call. = FALSE)
+    insight::format_error(""Tschuprow's T not applicable to goodness-of-fit tests."")
   }
 
   res <- .chisq_to_generic_phi(chisq, n, nrow, ncol,
@@ -248,11 +253,11 @@ chisq_to_fei <- function(chisq, n, nrow, ncol, p,
                          ...) {
   if (!missing(nrow) && !missing(ncol)) {
     if (!1 %in% c(nrow, ncol)) {
-      stop(""Fei is only applicable to goodness of fit tests."", call. = FALSE)
+      insight::format_error(""Fei is only applicable to goodness of fit tests."")
     }
 
     if (!length(p) %in% c(ncol, nrow)) {
-      stop(""Length of `p` must match number of rows/columns."", call. = FALSE)
+      insight::format_error(""Length of `p` must match number of rows/columns."")
     }
   }
 

---FILE: R/convert_stat_to_anova.R---
@@ -287,7 +287,7 @@ t_to_f2 <- function(t, df_error,
     eta2 = data.frame(Eta2_partial = (f * df) / (f * df + df_error)),
     epsilon2 = data.frame(Epsilon2_partial = ((f - 1) * df) / (f * df + df_error)),
     omega2 = data.frame(Omega2_partial = ((f - 1) * df) / (f * df + df_error + 1)),
-    stop(""'es' must be 'eta2', 'epsilon2', or 'omega2'."", call. = FALSE)
+    insight::format_error(""'es' must be 'eta2', 'epsilon2', or 'omega2'."")
   )
 
   ci_method <- NULL
@@ -301,7 +301,7 @@ t_to_f2 <- function(t, df_error,
     fs <- t(mapply(.get_ncp_F, f, df, df_error, ci.level)) / df
 
     if (isTRUE(verbose) && anyNA(fs)) {
-      warning(""Some CIs could not be estimated due to non-finite F, df, or df_error values."", call. = FALSE)
+      insight::format_warning(""Some CIs could not be estimated due to non-finite F, df, or df_error values."")
     }
 
     # This really is a generic F_to_R2

---FILE: R/convert_stat_to_d.R---
@@ -107,7 +107,7 @@ F_to_d <- function(f, df, df_error,
                    ci = 0.95, alternative = ""two.sided"",
                    ...) {
   if (df > 1) {
-    stop(""Cannot convert F with more than 1 df to (partial) r."", call. = FALSE)
+    insight::format_error(""Cannot convert F with more than 1 df to (partial) r."")
   }
   t_to_d(sqrt(f), df_error,
     paired = paired,

---FILE: R/convert_stat_to_r.R---
@@ -187,7 +187,7 @@ F_to_r <- function(f, df, df_error,
                    ci = 0.95, alternative = ""two.sided"",
                    ...) {
   if (df > 1) {
-    stop(""Cannot convert F with more than 1 df to r."", call. = FALSE)
+    insight::format_error(""Cannot convert F with more than 1 df to r."")
   }
   t_to_r(sqrt(f), df_error,
     ci = ci, alternative = alternative,

---FILE: R/effectsize.BFBayesFactor.R---
@@ -8,7 +8,7 @@ effectsize.BFBayesFactor <- function(model, type = NULL, ci = 0.95, test = NULL,
 
   if (length(model) > 1) {
     if (verbose) {
-      warning(""Multiple models detected. Using first only."", call. = FALSE)
+      insight::format_warning(""Multiple models detected. Using first only."")
     }
     model <- model[1]
   }
@@ -22,7 +22,7 @@ effectsize.BFBayesFactor <- function(model, type = NULL, ci = 0.95, test = NULL,
   } else if (inherits(model@numerator[[1]], ""BFproportion"")) {
     pars <- .effectsize_proportionBF(model, type = type, verbose = verbose)
   } else {
-    stop(""No effect size for this type of 'BayesFactor' object."", call. = FALSE)
+    insight::format_error(""No effect size for this type of 'BayesFactor' object."")
   }
 
   # Clean up
@@ -106,7 +106,7 @@ effectsize.BFBayesFactor <- function(model, type = NULL, ci = 0.95, test = NULL,
   if (type == ""d"") {
     xtra_class <- ""effectsize_difference""
   } else if (tolower(type) %in% c(""p_superiority"", ""u1"", ""u2"", ""u3"", ""overlap"")) {
-    if (paired && type != ""p_superiority"") stop(""CLES only applicable to two independent samples."", call. = FALSE)
+    if (paired && type != ""p_superiority"") insight::format_error(""CLES only applicable to two independent samples."")
 
     converter <- match.fun(paste0(""d_to_"", tolower(type)))
     if (grepl(""^(u|U)"", type)) type <- paste0(""Cohens_"", toupper(type))

---FILE: R/effectsize.htest.R---
@@ -21,9 +21,9 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
     .effectsize_friedman.test(model, type = type, verbose = verbose, ...)
   } else {
     if (verbose) {
-      warning(""This 'htest' method is not (yet?, call. = FALSE) supported.\n"",
-        ""Returning 'parameters::model_parameters(model)'."",
-        call. = FALSE
+      insight::format_warning(
+        ""This 'htest' method is not (yet?) supported."",
+        ""Returning 'parameters::model_parameters(model)'.""
       )
     }
     parameters::model_parameters(model, verbose = verbose, ...)
@@ -53,9 +53,7 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
 
   if (approx) {
     if (verbose) {
-      warning(insight::format_message(""Unable to retrieve data from htest object. Returning an approximate effect size using t_to_d().""),
-        call. = FALSE
-      )
+      insight::format_warning(""Unable to retrieve data from htest object. Returning an {.b approximate} effect size using t_to_d()."")
     }
 
     f <- t_to_d
@@ -81,7 +79,7 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
       )
     } else {
       if (!dots$paired && !args$pooled_sd) {
-        stop(""Common language effect size only applicable to Cohen's d with pooled SD."", call. = FALSE)
+        insight::format_error(""Common language effect size only applicable to Cohen's d with pooled SD."")
       }
 
       f <- switch(tolower(type),
@@ -112,7 +110,7 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
   Exp <- model$expected
 
   if (any(c(colSums(Obs), rowSums(Obs)) == 0L)) {
-    stop(""Cannot have empty rows/columns in the contingency tables."", call. = FALSE)
+    insight::format_error(""Cannot have empty rows/columns in the contingency tables."")
   }
   nr <- nrow(Obs)
   nc <- ncol(Obs)
@@ -238,7 +236,7 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
     c = ,
     pearsons_c = chisq_to_pearsons_c,
     fei = chisq_to_fei,
-    stop(""The selected effect size is not supported for goodness-of-fit tests."", call. = FALSE)
+    insight::format_error(""The selected effect size is not supported for goodness-of-fit tests."")
   )
 
   out <- f(
@@ -264,7 +262,7 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
   dots <- list(...)
 
   if ((approx <- grepl(""not assuming"", model$method, fixed = TRUE)) && verbose) {
-    warning(""`var.equal = FALSE` - effect size is an approximation."", call. = FALSE)
+    insight::format_warning(""`var.equal = FALSE` - effect size is an {.b approximation.}"")
   }
 
   if (is.null(type)) type <- ""eta""
@@ -352,7 +350,7 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
 
   if (tolower(type) != ""rb"") {
     if (dots$paired) {
-      stop(""Common language effect size only applicable to 2-sample rank-biserial correlation."", call. = FALSE)
+      insight::format_error(""Common language effect size only applicable to 2-sample rank-biserial correlation."")
     }
     args$parametric <- FALSE
   }
@@ -416,9 +414,9 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
 #' @keywords internal
 .fail_if_approx <- function(approx, esf_name) {
   if (approx) {
-    stop(""Unable to retrieve data from htest object."",
-      ""\nTry using '"", esf_name, ""()' directly."",
-      call. = FALSE
+    insight::format_error(
+      ""Unable to retrieve data from htest object."",
+      sprintf(""Try using '%s()' directly."", esf_name)
     )
   }
   invisible(NULL)

---FILE: R/equivalence_test.R---
@@ -84,7 +84,7 @@ equivalence_test.effectsize_table <- function(x,
   rule <- match.arg(rule)
 
   if (!all(c(""CI"", ""CI_low"", ""CI_high"") %in% colnames(x))) {
-    stop(""CI values missing from effect size table."", call. = FALSE)
+    insight::format_error(""CI values missing from effect size table."")
   }
 
   if (any(range == ""default"")) {
@@ -109,11 +109,11 @@ equivalence_test.effectsize_table <- function(x,
 
   if (range[1] < x_es_info$lb) {
     range[1] <- x_es_info$lb
-    warning(""Lower bound set to "", range[1], ""."", immediate. = FALSE, call. = FALSE)
+    insight::format_warning(sprintf(""Lower bound set to %s."", insight::format_value(range[1])))
   }
   if (range[2] > x_es_info$ub) {
     range[2] <- x_es_info$ub
-    warning(""Upper bound set to "", range[2], ""."", immediate. = FALSE, call. = FALSE)
+    insight::format_warning(sprintf(""Upper bound set to %s."", insight::format_value(range[2])))
   }
 
   # Test ---

---FILE: R/eta_squared-main.R---
@@ -329,9 +329,7 @@ cohens_f_squared <- function(model,
     !inherits(model2, ""lm"") ||
     !insight::model_info(model)$is_linear ||
     !insight::model_info(model2)$is_linear) {
-    stop(""Cohen's f for R2-change only supported for fixed effect linear models."",
-      call. = FALSE
-    )
+    insight::format_error(""Cohen's f for R2-change only supported for fixed effect linear models."")
   }
 
   # Anova
@@ -371,14 +369,14 @@ cohens_f_squared <- function(model,
   }
 
   if (!""Residuals"" %in% aov_table$Parameter) {
-    stop(insight::format_message(""No residuals data found - cannot compute effect size.""), call. = FALSE)
+    insight::format_error(""No residuals data found - cannot compute effect size."")
   }
 
 
   # Include intercept? ---
   if (include_intercept) {
     if (verbose && !""(Intercept)"" %in% aov_table$Parameter) {
-      warning(insight::format_message(""Could not find Sum-of-Squares for the (Intercept) in the ANOVA table.""), call. = FALSE)
+      insight::format_warning(""Could not find Sum-of-Squares for the (Intercept) in the ANOVA table."")
     }
     values <- .values_aov(aov_table[aov_table$Parameter != ""(Intercept)"", ])
   } else {
@@ -397,9 +395,11 @@ cohens_f_squared <- function(model,
     (partial || isTRUE(generalized) || is.character(generalized))) {
     if (verbose) {
       txt_type <- ifelse(isTRUE(generalized) || is.character(generalized), ""generalized"", ""partial"")
-      message(
-        ""For one-way between subjects designs, "", txt_type, "" "", type, "" squared is equivalent to "", type, "" squared.\n"",
-        ""Returning "", type, "" squared.""
+      insight::format_alert(
+        sprintf(
+          ""For one-way between subjects designs, %s %s squared is equivalent to %s squared. Returning %s squared."",
+          txt_type, type, type, type
+        )
       )
     }
     partial <- FALSE
@@ -416,7 +416,7 @@ cohens_f_squared <- function(model,
         for (o in generalized) {
           oi <- grepl(paste0(""\\b"", o, ""\\b""), aov_table$Parameter)
 
-          if (!any(oi)) stop(""Observed variable not in data: "", o, call. = FALSE)
+          if (!any(oi)) insight::format_error(sprintf(""Observed variable not in data: %s"", o))
 
           obs <- obs | oi
         }
@@ -518,14 +518,14 @@ cohens_f_squared <- function(model,
   }
 
   if (!""Residuals"" %in% aov_table$Parameter) {
-    stop(insight::format_message(""No residuals data found - cannot compute effect size.""), call. = FALSE)
+    insight::format_error(""No residuals data found - cannot compute effect size."")
   }
 
 
   # Include intercept? ---
   if (include_intercept) {
     if (verbose && !""(Intercept)"" %in% aov_table$Parameter) {
-      warning(insight::format_message(""Could not find Sum-of-Squares for the (Intercept) in the ANOVA table.""), call. = FALSE)
+      insight::format_warning(""Could not find Sum-of-Squares for the (Intercept) in the ANOVA table."")
     }
     values <- .values_aov(aov_table[aov_table$Parameter != ""(Intercept)"", ], group = TRUE)
   } else {
@@ -552,7 +552,7 @@ cohens_f_squared <- function(model,
         for (o in generalized) {
           oi <- grepl(paste0(""\\b"", o, ""\\b""), aov_table$Parameter)
 
-          if (!any(oi)) stop(""Observed variable not in data: "", o, call. = FALSE)
+          if (!any(oi)) insight::format_error(sprintf(""Observed variable not in data: %s"", o))
 
           obs <- obs | oi
         }
@@ -663,19 +663,14 @@ cohens_f_squared <- function(model,
   # Non-Partial / Generalized -> BAD ---
   if (verbose) {
     if (!isTRUE(partial)) {
-      warning(
-        ""Currently only supports partial "",
-        type,
-        "" squared for this class of objects."",
-        call. = FALSE
+      insight::format_warning(
+        sprintf(""Currently only supports partial %s squared for this class of objects."", type)
       )
     }
 
     if (isTRUE(generalized) || is.character(generalized)) {
-      warning(
-        ""generalized "", type, "" squared "",
-        ""is not supported for this class of object."",
-        call. = FALSE
+      insight::format_warning(
+        sprintf(""Generalized %s squared is not supported for this class of object."", type)
       )
     }
   }
@@ -687,15 +682,15 @@ cohens_f_squared <- function(model,
       aov_table[[""F""]] <- aov_table[[""t""]]^2
       aov_table[[""df""]] <- 1
     } else {
-      stop(insight::format_message(""ANOVA table does not have F values - cannot compute effect size.""), call. = FALSE)
+      insight::format_error(""ANOVA table does not have F values - cannot compute effect size."")
     }
   }
 
 
   # include_intercept? ---
   if (include_intercept) {
     if (verbose && !""(Intercept)"" %in% aov_table$Parameter) {
-      warning(insight::format_message(""Could not find F statistic for the (Intercept) in the ANOVA table.""), call. = FALSE)
+      insight::format_warning(""Could not find F statistic for the (Intercept) in the ANOVA table."")
     }
   } else {
     aov_table <- aov_table[aov_table$Parameter != ""(Intercept)"", , drop = FALSE]
@@ -854,7 +849,7 @@ cohens_f_squared <- function(model,
   }
 
   if (!any(F.nm %in% colnames(model)) || !any(df.nm %in% colnames(model))) {
-    stop(insight::format_message(""ANOVA table does not have F values or degrees of freedom - cannot compute effect size.""), call. = FALSE)
+    insight::format_error(""ANOVA table does not have F values or degrees of freedom - cannot compute effect size."")
   }
 
   Fi <- F.nm[F.nm %in% colnames(model)]

---FILE: R/eta_squared-methods.R---
@@ -125,14 +125,16 @@
                             verbose = TRUE,
                             ...) {
   if (!grepl(""One-way"", model$method)) {
-    stop(""'model' is not a one-way test!"", call. = FALSE)
+    insight::format_error(""'model' is not a one-way test!"")
   }
 
   if (verbose && (partial || isTRUE(generalized) || is.character(generalized))) {
     txt_type <- ifelse(isTRUE(generalized) || is.character(generalized), ""generalized"", ""partial"")
-    message(
-      ""For one-way between subjects designs, "", txt_type, "" "", type, "" squared is equivalent to "", type, "" squared.\n"",
-      ""Returning "", type, "" squared.""
+    insight::format_alert(
+      sprintf(
+        ""For one-way between subjects designs, %s %s squared is equivalent to %s squared. Returning %s squared."",
+        txt_type, type, type, type
+      )
     )
   }
 
@@ -338,7 +340,7 @@
   }
 
   if (verbose && include_intercept) {
-    warning(""Cannot estimate (Intercept) effect size for `mixed` model."", call. = FALSE)
+    insight::format_warning(""Cannot estimate (Intercept) effect size for `mixed` model."")
   }
 
   aov_tab$Parameter <- rownames(aov_tab)

---FILE: R/eta_squared_posterior.R---
@@ -31,14 +31,14 @@ eta_squared_posterior.stanreg <- function(model,
 
   mi <- .get_model_info(model, ...)
   if (!mi$is_linear || mi$is_multivariate) {
-    stop(""Computation of Eta Squared is only applicable to univariate linear models."", call. = FALSE)
+    insight::format_error(""Computation of Eta Squared is only applicable to univariate linear models."")
   }
 
   if (mi$is_mixed) {
     if (partial) {
       if (verbose) {
-        warning(
-          ""Bayesian Partial Eta Squared not supported for mixed models.\n"",
+        insight::format_warning(
+          ""Bayesian Partial Eta Squared not supported for mixed models."",
           ""Returning Eta Squared instead.""
         )
       }
@@ -49,8 +49,8 @@ eta_squared_posterior.stanreg <- function(model,
 
     if (isTRUE(generalized) || is.character(generalized)) {
       if (verbose) {
-        warning(
-          ""Bayesian Generalized Eta Squared not supported for mixed models.\n"",
+        insight::format_warning(
+          ""Bayesian Generalized Eta Squared not supported for mixed models."",
           ""Returning Eta Squared instead.""
         )
       }
@@ -75,7 +75,7 @@ eta_squared_posterior.stanreg <- function(model,
 
   ## 3. Compute effect size...
   if (verbose) {
-    message(""Simulating effect size... This can take a while..."")
+    insight::format_alert(""Simulating effect size... This can take a while..."")
   }
   res <- apply(ppd, 1, function(r) {
     # sampled outcome + predictors

---FILE: R/interpret.R---
@@ -38,14 +38,14 @@ rules <- function(values, labels = NULL, name = NULL, right = TRUE) {
 
   # Sanity checks
   if (length(labels) < length(values)) {
-    stop(""There cannot be less labels than reference values!"", call. = FALSE)
+    insight::format_error(""There cannot be less labels than reference values!"")
   } else if (length(labels) > length(values) + 1) {
-    stop(""Too many labels for the number of reference values!"", call. = FALSE)
+    insight::format_error(""Too many labels for the number of reference values!"")
   }
 
   if (length(values) == length(labels) - 1) {
     if (is.unsorted(values)) {
-      stop(""Reference values must be sorted."", call. = FALSE)
+      insight::format_error(""Reference values must be sorted."")
     }
   } else {
     right <- NULL
@@ -157,7 +157,7 @@ interpret.numeric <- function(x, rules, name = attr(rules, ""rule_name""), ...) {
 #' @rdname interpret
 #' @export
 interpret.effectsize_table <- function(x, rules, ...) {
-  if (missing(rules)) stop(""You MUST specify the rules of interpretation!"", call. = FALSE)
+  if (missing(rules)) insight::format_error(""You {.b must} specify the rules of interpretation!"")
 
   es_name <- colnames(x)[is_effectsize_name(colnames(x))]
   value <- x[[es_name]]

---FILE: R/interpret_bf.R---
@@ -53,7 +53,7 @@ interpret_bf <- function(bf,
   if (log) bf <- exp(bf)
 
   if (any(bf < 0, na.rm = TRUE)) {
-    warning(""Negative BFs detected. These are not possible. Ignoring."", call. = FALSE)
+    insight::format_warning(""Negative BFs detected. These are not possible. Ignoring."")
     bf[bf < 0] <- NA
   }
 

---FILE: R/mahalanobis_D.R---
@@ -99,18 +99,18 @@ mahalanobis_d <- function(x, y = NULL, data = NULL,
       mu <- rep(mu, length.out = ncol(x))
       names(mu) <- colnames(x)
     } else if (length(mu) != ncol(x) || is.null(names(mu))) {
-      stop(""mu must be of length 1 or a named vector/list of length ncol(x)."", call. = FALSE)
+      insight::format_error(""mu must be of length 1 or a named vector/list of length ncol(x)."")
     }
 
     mu <- as.list(mu)
   }
 
   if (!is.list(mu)) {
-    stop(""mu must be of length 1 or a named vector/list of length ncol(x)."", call. = FALSE)
+    insight::format_error(""mu must be of length 1 or a named vector/list of length ncol(x)."")
   } else if (!all(names(mu) == colnames(x))) {
-    stop(""x,y must have the same variables (in the same order)"", call. = FALSE)
+    insight::format_error(""x,y must have the same variables (in the same order)"")
   } else if (!all(lengths(mu) == 1L) || !all(sapply(mu, is.numeric))) {
-    stop(""Each element of mu must be a numeric vector of length 1."", call. = FALSE)
+    insight::format_error(""Each element of mu must be a numeric vector of length 1."")
   }
   mu <- unlist(mu)
 
@@ -129,7 +129,7 @@ mahalanobis_d <- function(x, y = NULL, data = NULL,
     d <- colMeans(x) - colMeans(y) - mu
 
     if (!pooled_cov) {
-      warning(""Non-pooled cov not supported."", call. = FALSE)
+      insight::format_warning(""Non-pooled cov not supported."")
     }
     COV <- cov_pooled(x, y, verbose = verbose)
 

---FILE: R/print.effectsize_table.R---
@@ -140,7 +140,7 @@ print.effectsize_difference <- function(x, digits = 2, append_CLES = NULL, ...)
 
       cles_tab <- cles_tab[c(ncol(cles_tab), seq_len(ncol(cles_tab) - 1))]
     } else {
-      stop(""CLES not applicable for this effect size."", call. = FALSE)
+      insight::format_error(""CLES not applicable for this effect size."")
     }
 
     insight::print_color(""\n\n## Common Language Effect Sizes:\n"", .pcl[""subtitle""])

---FILE: R/rank_ANOVA.R---
@@ -272,15 +272,14 @@ kendalls_w <- function(x, groups, blocks, data = NULL,
   no_ties <- apply(rankings, 1, function(x) length(x) == insight::n_unique(x))
   if (!all(no_ties)) {
     if (verbose) {
-      warning(
+      insight::format_warning(
         sprintf(
           ""%d block(s) contain ties%s."",
           sum(!no_ties),
           ifelse(any(apply(as.data.frame(rankings)[!no_ties, ], 1, insight::n_unique) == 1),
             "", some containing only 1 unique ranking"", """"
           )
-        ),
-        call. = FALSE
+        )
       )
     }
 

---FILE: R/rank_diff.R---
@@ -214,7 +214,7 @@ cliffs_delta <- function(x, y = NULL, data = NULL,
   x <- data$x
   y <- data$y
   if (is.null(y) || isTRUE(eval.parent(cl$paired))) {
-    stop(""This effect size is only applicable for two independent samples."", call. = FALSE)
+    insight::format_error(""This effect size is only applicable for two independent samples."")
   }
 
   cl[[1]] <- quote(rank_biserial)

---FILE: R/utils.R---
@@ -49,7 +49,7 @@
 .is_BF_of_type <- function(x, type, msg = type) {
   if (inherits(x, ""BFBayesFactor"")) {
     if (!inherits(x@numerator[[1]], type)) {
-      stop(""'x' is not a "", msg, ""!"", call. = FALSE)
+      insight::format_error(sprintf(""'x' is not a %s!"", msg))
     }
     return(TRUE)
   } else {
@@ -61,7 +61,7 @@
 .is_htest_of_type <- function(x, pattern, msg) {
   if (inherits(x, ""htest"")) {
     if (!grepl(pattern, x$method)) {
-      stop(""'x' is not a "", msg, ""!"", call. = FALSE)
+      insight::format_error(sprintf(""'x' is not a %s!"", msg))
     }
     return(TRUE)
   } else {

---FILE: R/utils_interpret.R---
@@ -7,10 +7,11 @@
   rule <- pmatch(rules, names(choices))
 
   if (!is.character(rules) || length(rules) != 1 || is.na(rule)) {
-    stop(""'rules' must be "",
-      paste0(""'"", names(choices), ""'"", collapse = "", ""),
-      "" or an object of type 'rules'."",
-      call. = FALSE
+    insight::format_error(
+      sprintf(
+        ""'rules' must be %s or an object of type 'rules'."",
+        paste0(""'"", names(choices), ""'"", collapse = "", "")
+      )
     )
   }
 

---FILE: R/utils_validate_input_data.R---
@@ -7,17 +7,17 @@
   if (inherits(x, ""formula"")) {
     # Validate:
     if (length(x) != 3L) {
-      stop(""Formula must have one of the following forms:"",
-        ""\n\ty ~ group,\n\ty ~ 1,\n\tPair(x,y) ~ 1"",
-        call. = FALSE
+      insight::format_error(
+        ""Formula must have one of the following forms:"",
+        ""\n\ty ~ group,\n\ty ~ 1,\n\tPair(x,y) ~ 1""
       )
     }
 
     # Pull columns
     mf <- .resolve_formula(x, data, ...)
 
     if (ncol(mf) > 2L) {
-      stop(""Formula must have only one term on the RHS."", call. = FALSE)
+      insight::format_error(""Formula must have only one term on the RHS."")
     }
 
     x <- mf[[1]]
@@ -37,7 +37,7 @@
   if (allow_ordered && is.ordered(x)) {
     if (is.ordered(y)) {
       if (!isTRUE(all.equal(levels(y), levels(x)))) {
-        stop(""x and y are ordered, but do not have the same levels."", call. = FALSE)
+        insight::format_error(""x and y are ordered, but do not have the same levels."")
       }
       y <- as.numeric(y)
     }
@@ -47,7 +47,7 @@
 
   # x should be a numeric vector or a Pair:
   if (!is.numeric(x)) {
-    stop(""Cannot compute effect size for a non-numeric vector."", call. = FALSE)
+    insight::format_error(""Cannot compute effect size for a non-numeric vector."")
   } else if (inherits(x, ""Pair"")) {
     x <- x[, 1] - x[, 2]
     y <- NULL
@@ -58,11 +58,11 @@
   if (!is.null(y)) {
     if (!is.numeric(y)) {
       if (insight::n_unique(y) != 2) {
-        stop(""Grouping variable y must have exactly 2 levels."", call. = FALSE)
+        insight::format_error(""Grouping variable y must have exactly 2 levels."")
       }
 
       if (length(x) != length(y)) {
-        stop(""Grouping variable must be the same length."", call. = FALSE)
+        insight::format_error(""Grouping variable must be the same length."")
       }
 
       data <- Filter(length, split(x, y))
@@ -71,15 +71,15 @@
     }
 
     if (verbose && insight::n_unique(y) == 2) {
-      warning(""'y' is numeric but has only 2 unique values."",
-        ""\nIf this is a grouping variable, convert it to a factor."",
-        call. = FALSE
+      insight::format_warning(
+        ""'y' is numeric but has only 2 unique values."",
+        ""If this is a grouping variable, convert it to a factor.""
       )
     }
   }
 
   if (verbose && (anyNA(x) || anyNA(y))) {
-    warning(""Missing values detected. NAs dropped."", call. = FALSE)
+    insight::format_warning(""Missing values detected. NAs dropped."")
   }
 
   if (paired && !is.null(y)) {
@@ -116,13 +116,13 @@
                                   verbose = TRUE, ...) {
   if (inherits(x, ""formula"")) {
     if (length(x) != 3) {
-      stop(""Formula must have the form of 'outcome ~ group'."", call. = FALSE)
+      insight::format_error(""Formula must have the form of 'outcome ~ group'."")
     }
 
     mf <- .resolve_formula(x, data, ...)
 
     if (ncol(mf) != 2L) {
-      stop(""Formula must have only one term on the RHS."", call. = FALSE)
+      insight::format_error(""Formula must have only one term on the RHS."")
     }
 
     x <- mf[[1]]
@@ -142,21 +142,21 @@
     x <- as.numeric(x)
   }
   if (!is.numeric(x)) {
-    stop(""Cannot compute effect size for a non-numeric vector."", call. = FALSE)
+    insight::format_error(""Cannot compute effect size for a non-numeric vector."")
   }
 
   # groups should be not numeric
   if (length(x) != length(groups)) {
-    stop(""x and groups must be of the same length."", call. = FALSE)
+    insight::format_error(""x and groups must be of the same length."")
   }
 
   if (is.numeric(groups)) {
-    stop(""groups cannot be numeric."", call. = FALSE)
+    insight::format_error(""groups cannot be numeric."")
   }
 
   out <- data.frame(x, groups)
   if (verbose && anyNA(out)) {
-    warning(""Missing values detected. NAs dropped."", call. = FALSE)
+    insight::format_warning(""Missing values detected. NAs dropped."")
   }
   stats::na.omit(out)
 }
@@ -169,15 +169,15 @@
   if (inherits(x, ""formula"")) {
     if (length(x) != 3L ||
       x[[3L]][[1L]] != as.name(""|"")) {
-      stop(""Formula must have the 'x ~ groups | blocks'."", call. = FALSE)
+      insight::format_error(""Formula must have the 'x ~ groups | blocks'."")
     }
 
     x[[3L]][[1L]] <- as.name(""+"")
 
     x <- .resolve_formula(x, data, ...)
 
     if (ncol(x) != 3L) {
-      stop(""Formula must have only two term on the RHS."", call. = FALSE)
+      insight::format_error(""Formula must have only two term on the RHS."")
     }
   } else if (inherits(x, ""data.frame"")) {
     x <- as.matrix(x)
@@ -187,7 +187,7 @@
     blocks <- .resolve_char(blocks, data)
 
     if (length(x) != length(groups) || length(x) != length(blocks)) {
-      stop(""x, groups and blocks must be of the same length."", call. = FALSE)
+      insight::format_error(""x, groups and blocks must be of the same length."")
     }
 
     x <- data.frame(x, groups, blocks)
@@ -208,14 +208,14 @@
     x$x <- as.numeric(x$x)
   }
   if (!is.numeric(x$x)) {
-    stop(""Cannot compute effect size for a non-numeric vector."", call. = FALSE)
+    insight::format_error(""Cannot compute effect size for a non-numeric vector."")
   }
   if (!is.factor(x$groups)) x$groups <- factor(x$groups)
   if (!is.factor(x$blocks)) x$blocks <- factor(x$blocks)
 
 
   if (verbose && anyNA(x)) {
-    warning(""Missing values detected. NAs dropped."", call. = FALSE)
+    insight::format_warning(""Missing values detected. NAs dropped."")
   }
   x <- stats::na.omit(x)
 
@@ -237,7 +237,7 @@
                                    verbose = TRUE, ...) {
   if (inherits(x, ""formula"")) {
     if (length(x) != 3L || length(x[[3]]) != 1L) {
-      stop(""Formula must have the form of 'DV1 + ... + DVk ~ group', with exactly one term on the RHS."", call. = FALSE)
+      insight::format_error(""Formula must have the form of 'DV1 + ... + DVk ~ group', with exactly one term on the RHS."")
     }
 
     data <- .resolve_formula(stats::reformulate(as.character(x)[3:2]), data, ...)
@@ -248,7 +248,7 @@
     } else {
       data <- split(data[, -1, drop = FALSE], f = data[[1]])
       if (length(data) != 2) {
-        stop(""~ group must have 2 levels exactly."", call. = FALSE)
+        insight::format_error(""~ group must have 2 levels exactly."")
       }
       x <- data[[1]]
       y <- data[[2]]
@@ -264,11 +264,11 @@
   if (is.matrix(x)) {
     x <- as.data.frame(x)
   } else if (!is.data.frame(x)) {
-    stop(""x must be a data frame."", call. = FALSE)
+    insight::format_error(""x must be a data frame."")
   }
 
   if (!all(sapply(x, is.numeric))) {
-    stop(""All DVs must be numeric."", call. = FALSE)
+    insight::format_error(""All DVs must be numeric."")
   }
 
 
@@ -277,20 +277,20 @@
     if (is.matrix(y)) {
       y <- as.data.frame(y)
     } else if (!is.data.frame(y)) {
-      stop(""y must be a data frame."", call. = FALSE)
+      insight::format_error(""y must be a data frame."")
     }
 
     if (!all(sapply(y, is.numeric))) {
-      stop(""All DVs must be numeric."", call. = FALSE)
+      insight::format_error(""All DVs must be numeric."")
     }
 
     if (!all(colnames(x) == colnames(y))) {
-      stop(""x,y must have the same variables (in the same order)"", call. = FALSE)
+      insight::format_error(""x,y must have the same variables (in the same order)."")
     }
   }
 
   if (verbose && (anyNA(x) || anyNA(y))) {
-    warning(""Missing values detected. NAs dropped."", call. = FALSE)
+    insight::format_warning(""Missing values detected. NAs dropped."")
   }
   x <- stats::na.omit(x)
   y <- stats::na.omit(y)
@@ -324,9 +324,11 @@
 .resolve_char <- function(nm, data) {
   if (is.character(nm) && length(nm) == 1L) {
     if (is.null(data)) {
-      stop(""Please provide data argument."", call. = FALSE)
-    } else if (!nm %in% names(data)) {
-      stop(""Column "", nm, "" missing from data."", call. = FALSE)
+      insight::format_error(""Please provide data argument."")
+    }
+
+    if (!nm %in% names(data)) {
+      insight::format_error(sprintf(""Column %s missing from data."", nm))
     }
 
     return(data[[nm]])

---FILE: R/xtab_corr.R---
@@ -186,7 +186,7 @@ fei <- function(x, p = rep(1, length(x)),
   alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
 
   if (inherits(x, ""BFBayesFactor"")) {
-    stop(""Fei is only applicable to goodness of fit tests."", call. = FALSE)
+    insight::format_error(""Fei is only applicable to goodness of fit tests."")
   } else if (!.is_htest_of_type(x, ""Chi-squared test for given probabilities"", ""Chi-squared-test"")) {
     x <- suppressWarnings(stats::chisq.test(x, y = NULL, p = p, rescale.p = TRUE))
     x$data.name <- NULL

---FILE: R/xtab_diff.R---
@@ -65,11 +65,11 @@ oddsratio <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = F
   Obs <- res$observed
 
   if (any(c(colSums(Obs), rowSums(Obs)) == 0L)) {
-    stop(""Cannot have empty rows/columns in the contingency tables."", call. = FALSE)
+    insight::format_error(""Cannot have empty rows/columns in the contingency tables."")
   }
 
   if (nrow(Obs) != 2 || ncol(Obs) != 2) {
-    stop(""Odds ratio only available for 2-by-2 contingency tables"", call. = FALSE)
+    insight::format_error(""Odds ratio only available for 2-by-2 contingency tables"")
   }
 
   OR <- (Obs[1, 1] / Obs[2, 1]) /
@@ -132,11 +132,11 @@ riskratio <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = F
   Obs <- res$observed
 
   if (any(c(colSums(Obs), rowSums(Obs)) == 0L)) {
-    stop(""Cannot have empty rows/columns in the contingency tables."", call. = FALSE)
+    insight::format_error(""Cannot have empty rows/columns in the contingency tables."")
   }
 
   if (nrow(Obs) != 2 || ncol(Obs) != 2) {
-    stop(""Risk ratio only available for 2-by-2 contingency tables"", call. = FALSE)
+    insight::format_error(""Risk ratio only available for 2-by-2 contingency tables"")
   }
 
   n1 <- sum(Obs[, 1])
@@ -202,11 +202,11 @@ cohens_h <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...) {
   Obs <- res$observed
 
   if (any(c(colSums(Obs), rowSums(Obs)) == 0L)) {
-    stop(""Cannot have empty rows/columns in the contingency tables."", call. = FALSE)
+    insight::format_error(""Cannot have empty rows/columns in the contingency tables."")
   }
 
   if (nrow(Obs) != 2 || ncol(Obs) != 2) {
-    stop(""Cohen's h only available for 2-by-2 contingency tables"", call. = FALSE)
+    insight::format_error(""Cohen's h only available for 2-by-2 contingency tables"")
   }
 
   n1 <- sum(Obs[, 1])

---FILE: WIP/paired_d2.R---
@@ -194,10 +194,10 @@ paired_d <- function(x, group, block, data = NULL,
     g <- list(g)
   }
   if ((dim(cov)[1] != n) || (dim(cov)[2] != n)) {
-    stop(paste(
+    insight::format_error(
       ""Covariances should be a "", n, "" by "", n,
-      "" matrix""
-    ), call. = FALSE)
+      "" matrix.""
+    )
   }
   syms <- paste(""x"", 1:n, sep = """")
   for (i in 1:n) assign(syms[i], mean[i])

---FILE: _pkgdown.yml---
@@ -39,11 +39,12 @@ reference:
 
 - subtitle: ""Standardized parameters""
   desc: >
-    Functions from other packages relating to parameter standardization
+    Functions from other packages relating to parameter standardization and perdictor dominance
   contents:
   - parameters::standardize_parameters
   - datawizard::standardize_models
   - parameters::standardize_info
+  - parameters::dominance_analysis
 
 - subtitle: ""Correlations""
   desc: >

---FILE: data-raw/tabular data.R---
@@ -26,7 +26,7 @@ dimnames(Music_preferences) <- list(
   c(""Pop"", ""Rock"", ""Jazz"", ""Classic""),
   c(""Psych"", ""Econ"", ""Law"")
 )
-Music_preferences <- as.table(Music_preferences)
+Music_preferences <- as.table(t(Music_preferences))
 
 save(Music_preferences, file = ""data/Music_preferences.rdata"")
 

---FILE: man/Music_preferences.Rd---
@@ -9,11 +9,10 @@ A 4-by-3 table, with a \emph{column} for each major and a \emph{row} for each ty
 
 \if{html}{\out{<div class=""sourceCode r"">}}\preformatted{data(""Music_preferences"")
 Music_preferences
-#>         Psych Econ Law
-#> Pop       150   50   2
-#> Rock      100   65  55
-#> Jazz      165   35  40
-#> Classic   130   10  25
+#>       Pop Rock Jazz Classic
+#> Psych 150  100  165     130
+#> Econ   50   65   35      10
+#> Law     2   55   40      25
 }\if{html}{\out{</div>}}
 }
 \description{

---FILE: man/convert_chisq.Rd---
@@ -26,6 +26,7 @@ chisq_to_cohens_w(
   n,
   nrow,
   ncol,
+  p,
   ci = 0.95,
   alternative = ""greater"",
   ...

---FILE: man/effectsize_CIs.Rd---
@@ -112,8 +112,8 @@ parameter value. For that, construct a 95\% 2-sided CI.
 \if{html}{\out{<div class=""sourceCode r"">}}\preformatted{data(""hardlyworking"")
 fit <- lm(salary ~ n_comps, data = hardlyworking)
 eta_squared(fit) # default, ci = 0.95, alternative = ""greater""
-#> For one-way between subjects designs, partial eta squared is equivalent to eta squared.
-#> Returning eta squared.
+#> For one-way between subjects designs, partial eta squared is equivalent
+#>   to eta squared. Returning eta squared.
 #> # Effect Size for ANOVA
 #> 
 #> Parameter | Eta2 |       95\% CI
@@ -122,8 +122,8 @@ eta_squared(fit) # default, ci = 0.95, alternative = ""greater""
 #> 
 #> - One-sided CIs: upper bound fixed at [1.00].
 eta_squared(fit, alternative = ""less"") # Test is eta is smaller than some value
-#> For one-way between subjects designs, partial eta squared is equivalent to eta squared.
-#> Returning eta squared.
+#> For one-way between subjects designs, partial eta squared is equivalent
+#>   to eta squared. Returning eta squared.
 #> # Effect Size for ANOVA
 #> 
 #> Parameter | Eta2 |       95\% CI
@@ -132,16 +132,16 @@ eta_squared(fit, alternative = ""less"") # Test is eta is smaller than some value
 #> 
 #> - One-sided CIs: lower bound fixed at [0.00].
 eta_squared(fit, alternative = ""two.sided"") # 2-sided bounds for alpha = .05
-#> For one-way between subjects designs, partial eta squared is equivalent to eta squared.
-#> Returning eta squared.
+#> For one-way between subjects designs, partial eta squared is equivalent
+#>   to eta squared. Returning eta squared.
 #> # Effect Size for ANOVA
 #> 
 #> Parameter | Eta2 |       95\% CI
 #> -------------------------------
 #> n_comps   | 0.19 | [0.14, 0.25]
 eta_squared(fit, ci = 0.9, alternative = ""two.sided"") # both 1-sided bounds for alpha = .05
-#> For one-way between subjects designs, partial eta squared is equivalent to eta squared.
-#> Returning eta squared.
+#> For one-way between subjects designs, partial eta squared is equivalent
+#>   to eta squared. Returning eta squared.
 #> # Effect Size for ANOVA
 #> 
 #> Parameter | Eta2 |       90\% CI

---FILE: tests/testthat/test-eta_squared.R---
@@ -1,3 +1,4 @@
+# library(testthat)
 
 # anova() -----------------------------------------------------------------
 test_that(""anova()"", {
@@ -15,7 +16,7 @@ test_that(""anova()"", {
     ignore_attr = TRUE
   )
   expect_warning(eta_squared(mod1, partial = FALSE), ""partial"")
-  expect_warning(eta_squared(mod1, generalized = TRUE), ""generalized"")
+  expect_warning(eta_squared(mod1, generalized = TRUE), ""Generalized"")
 
   mod2 <- mod1
   mod2$`F value` <- NULL

---FILE: tests/testthat/test-interpret.R---
@@ -1,3 +1,5 @@
+# library(testthat)
+
 # interpret generic ----
 test_that(""interpret generic"", {
   rules_grid <- rules(c(0.01, 0.05), c(""very significant"", ""significant"", ""not significant""))
@@ -251,5 +253,5 @@ test_that(""interpret effectsize_table"", {
   expect_output(print(V_), ""large"")
   expect_output(print(V_), ""Interpretation rule: funder2019"")
 
-  expect_error(interpret(d), ""MUST specify"")
+  expect_error(interpret(d), ""must specify"")
 })

---FILE: tests/testthat/test-xtab.R---
@@ -1,3 +1,4 @@
+# library(testthat)
 
 test_that(""contingency table"", {
   contingency_table <- as.table(rbind(
@@ -104,7 +105,7 @@ test_that(""goodness of fit"", {
   expect_equal(w2[[1]] * sqrt(0.1 / 0.9), Fei2[[1]])
   expect_true(w1$CI_low < w2$CI_low)
   expect_true(w2$CI_low < w2$CI_high)
-  expect_equal(w2$CI_high, Inf)
+  expect_equal(w2$CI_high, sqrt(0.9 / 0.1))
 
   C <- pearsons_c(table(mtcars$cyl), p = c(0.8, 0.1, 0.1))
   expect_equal(C[[1]], sqrt(49.289 / (49.289 + sum(table(mtcars$cyl)))), tolerance = 0.001)

---FILE: vignettes/xtabs.Rmd---
@@ -41,7 +41,7 @@ For 2-by-2 contingency tables, $\phi$ (Phi) is homologous (though directionless)
 ```{r}
 (MPG_Gear <- table(mtcars$mpg < 20, mtcars$vs))
 
-phi(MPG_Gear)
+phi(MPG_Gear, adjust = FALSE)
 
 # Same as:
 cor(mtcars$mpg < 20, mtcars$vs)",True,True,Documentation / Formatting,6
easystats,effectsize,a8617bf209966202f28046defc6429941eb04cf1,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2022-10-11T06:07:20Z,GitHub,noreply@github.com,2022-10-11T06:07:20Z,"fix #517 (#518)

* fix #517

* v bump

* mahalanobis_d with na.action

* na.action tests

* more informative warnings",DESCRIPTION;NEWS.md;R/effectsize.htest.R;R/eta_squared-main.R;R/mahalanobis_D.R;R/utils_validate_input_data.R;tests/testthat/test-mahalanobis_D.R;tests/testthat/test-utils_validate_input_data.R,False,True,True,False,60,33,93,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size
-Version: 0.8.0
+Version: 0.8.0.0001
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",

---FILE: NEWS.md---
@@ -1,3 +1,9 @@
+# effectsize 0.8.0.0001
+
+## Bug fixes
+
+- When using formula input to effect size function, `na.action` arguments are respected (#517)
+
 # effectsize 0.8.0
 
 ## Breaking Changes

---FILE: R/effectsize.htest.R---
@@ -53,7 +53,9 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
 
   if (approx) {
     if (verbose) {
-      warning(""Unable to retrieve data from htest object. Using t_to_d() approximation."", call. = FALSE)
+      warning(insight::format_message(""Unable to retrieve data from htest object. Returning an approximate effect size using t_to_d().""),
+        call. = FALSE
+      )
     }
 
     f <- t_to_d

---FILE: R/eta_squared-main.R---
@@ -378,7 +378,7 @@ cohens_f_squared <- function(model,
   # Include intercept? ---
   if (include_intercept) {
     if (verbose && !""(Intercept)"" %in% aov_table$Parameter) {
-      message(insight::format_message(""Could not find Sum-of-Squares for the (Intercept) in the ANOVA table.""))
+      warning(insight::format_message(""Could not find Sum-of-Squares for the (Intercept) in the ANOVA table.""), call. = FALSE)
     }
     values <- .values_aov(aov_table[aov_table$Parameter != ""(Intercept)"", ])
   } else {
@@ -525,7 +525,7 @@ cohens_f_squared <- function(model,
   # Include intercept? ---
   if (include_intercept) {
     if (verbose && !""(Intercept)"" %in% aov_table$Parameter) {
-      message(insight::format_message(""Could not find Sum-of-Squares for the (Intercept) in the ANOVA table.""))
+      warning(insight::format_message(""Could not find Sum-of-Squares for the (Intercept) in the ANOVA table.""), call. = FALSE)
     }
     values <- .values_aov(aov_table[aov_table$Parameter != ""(Intercept)"", ], group = TRUE)
   } else {
@@ -695,7 +695,7 @@ cohens_f_squared <- function(model,
   # include_intercept? ---
   if (include_intercept) {
     if (verbose && !""(Intercept)"" %in% aov_table$Parameter) {
-      message(insight::format_message(""Could not find F statistic for the (Intercept) in the ANOVA table.""))
+      warning(insight::format_message(""Could not find F statistic for the (Intercept) in the ANOVA table.""), call. = FALSE)
     }
   } else {
     aov_table <- aov_table[aov_table$Parameter != ""(Intercept)"", , drop = FALSE]

---FILE: R/mahalanobis_D.R---
@@ -88,7 +88,7 @@ mahalanobis_d <- function(x, y = NULL, data = NULL,
   # TODO add one sample case DV1 + DV2 ~ 1
   # TODO add paired samples case DV1 + DV2 ~ 1 | ID
   alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
-  data <- .get_data_multivariate(x, y, data, verbose = verbose)
+  data <- .get_data_multivariate(x, y, data, verbose = verbose, ...)
   x <- data[[""x""]]
   y <- data[[""y""]]
 

---FILE: R/utils_validate_input_data.R---
@@ -240,10 +240,7 @@
       stop(""Formula must have the form of 'DV1 + ... + DVk ~ group', with exactly one term on the RHS."", call. = FALSE)
     }
 
-    data <- model.frame(
-      formula = stats::reformulate(as.character(x)[3:2]),
-      data = data, na.action = stats::na.pass
-    )
+    data <- .resolve_formula(stats::reformulate(as.character(x)[3:2]), data, ...)
 
     if (x[[3]] == 1) {
       # Then it is one sampled
@@ -307,14 +304,19 @@
 
 #' @keywords internal
 #' @importFrom stats model.frame na.pass
-.resolve_formula <- function(formula, data, subset, na.action, ...) {
+.resolve_formula <- function(formula, data, subset, na.action = stats::na.pass, ...) {
   cl <- match.call(expand.dots = FALSE)
   cl[[1]] <- quote(stats::model.frame)
+
+  if (!""na.action"" %in% names(cl)) {
+    cl$na.action <- quote(stats::na.pass)
+  }
+
   if (""subset"" %in% names(cl)) {
     cl$subset <- substitute(subset)
   }
+
   cl$... <- NULL
-  cl$na.action <- stats::na.pass
   eval.parent(cl)
 }
 

---FILE: tests/testthat/test-mahalanobis_D.R---
@@ -62,27 +62,6 @@ test_that(""mahalanobis_d | one sample | vs cohens_d"", {
 })
 
 
-test_that(""mahalanobis_d | inputs"", {
-  data(""mtcars"")
-
-  D <- mahalanobis_d(mtcars[, c(""mpg"", ""hp"")])
-  expect_equal(mahalanobis_d(cbind(mpg, hp) ~ 1, data = mtcars), D)
-  expect_equal(mahalanobis_d(mpg + hp ~ 1, data = mtcars), D)
-
-  D <- mahalanobis_d(
-    mtcars[mtcars$am == 0, c(""mpg"", ""hp"")],
-    mtcars[mtcars$am == 1, c(""mpg"", ""hp"")]
-  )
-  expect_equal(mahalanobis_d(cbind(mpg, hp) ~ am, data = mtcars), D)
-  expect_equal(mahalanobis_d(mpg + hp ~ am, data = mtcars), D)
-
-  mtcars$mpg[1] <- NA
-  expect_warning(mahalanobis_d(mtcars[, c(""mpg"", ""hp"")]), regexp = ""dropped"")
-  expect_warning(D1 <- mahalanobis_d(mpg + hp ~ 1, data = mtcars), regexp = ""dropped"")
-  expect_equal(D1, mahalanobis_d(mpg + hp ~ 1, data = mtcars[-1, ]))
-})
-
-
 test_that(""mahalanobis_d | mu types"", {
   mu <- 0
   expect_error(D1 <- mahalanobis_d(mtcars[, c(""mpg"", ""hp"")], mu = mu), regexp = NA)

---FILE: tests/testthat/test-utils_validate_input_data.R---
@@ -57,6 +57,13 @@ test_that("".get_data_2_samples"", {
   expect_true(attr(d, ""pooled_sd""))
 })
 
+test_that("".get_data_2_samples | na.action"", {
+  data(""mtcars"")
+  mtcars$mpg[1] <- NA
+  expect_warning(d1 <- cohens_d(mpg ~ am, data = mtcars), ""dropped"")
+  expect_warning(d2 <- cohens_d(mpg ~ am, data = mtcars, na.action = na.omit), NA)
+})
+
 test_that("".get_data_2_samples | subset"", {
   expect_error(cohens_d(mpg ~ cyl, data = mtcars), ""exactly"")
   expect_error(cohens_d(mpg ~ cyl, data = mtcars, subset = cyl %in% c(4, 6)), regexp = NA)
@@ -186,3 +193,34 @@ test_that("".get_data_nested_groups | subset"", {
     kendalls_w(y ~ g | id, data = subset(d, g < 4), ci = NULL)
   )
 })
+
+
+test_that("".get_data_multivariate"", {
+  data(""mtcars"")
+  D <- mahalanobis_d(mtcars[, c(""mpg"", ""hp"")])
+  expect_equal(mahalanobis_d(cbind(mpg, hp) ~ 1, data = mtcars), D)
+  expect_equal(mahalanobis_d(mpg + hp ~ 1, data = mtcars), D)
+
+  D <- mahalanobis_d(
+    mtcars[mtcars$am == 0, c(""mpg"", ""hp"")],
+    mtcars[mtcars$am == 1, c(""mpg"", ""hp"")]
+  )
+  expect_equal(mahalanobis_d(cbind(mpg, hp) ~ am, data = mtcars), D)
+  expect_equal(mahalanobis_d(mpg + hp ~ am, data = mtcars), D)
+})
+
+test_that("".get_data_multivariate | subset"", {
+  data(""mtcars"")
+  D1 <- mahalanobis_d(mpg + hp ~ am, data = mtcars, subset = hp > 100)
+  D2 <- mahalanobis_d(mpg + hp ~ am, data = subset(mtcars, hp > 100))
+  expect_equal(D1, D2)
+})
+
+test_that("".get_data_multivariate | na.action"", {
+  data(""mtcars"")
+  mtcars$mpg[1] <- NA
+  expect_warning(mahalanobis_d(mtcars[, c(""mpg"", ""hp"")]), regexp = ""dropped"")
+  expect_warning(mahalanobis_d(mpg + hp ~ 1, data = mtcars, na.action = na.omit), regexp = NA)
+  expect_warning(D1 <- mahalanobis_d(mpg + hp ~ 1, data = mtcars), regexp = ""dropped"")
+  expect_equal(D1, mahalanobis_d(mpg + hp ~ 1, data = mtcars[-1, ]))
+})",True,False,Documentation / Formatting,6
easystats,effectsize,45f6172cf2c9b813a57ce398a82572bdcab1b72f,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2022-10-10T07:07:07Z,GitHub,noreply@github.com,2022-10-10T07:07:07Z,"Cran 0.8 (#516)

* version bump

* styler

* close #471

* Update interpret_bf.Rd

* add links

* Update effectsize.Rmd

* fix doi tag

* Update cran-comments.md

* revdev

* Update _pkgdown.yml

* update email

* update email

* fix link",.Rbuildignore;.github/CODE_OF_CONDUCT.md;DESCRIPTION;NEWS.md;R/effectsize-package.R;R/interpret_bf.R;_pkgdown.yml;cran-comments.md;dev/revdepcheck.R;man/effectsize-package.Rd;man/interpret_bf.Rd;vignettes/effectsize.Rmd;vignettes/interpret.Rmd,True,True,True,False,65,43,108,"---FILE: .Rbuildignore---
@@ -48,6 +48,7 @@ references.bib
 hextools
 ^paper/.
 ^WIP/.
+^dev/.
 # Flip these two to no build vignettes:
 # ^vignettes/(?!additional).*
 ^vignettes/additional
\ No newline at end of file

---FILE: .github/CODE_OF_CONDUCT.md---
@@ -59,7 +59,7 @@ representative at an online or offline event.
 ## Enforcement
 
 Instances of abusive, harassing, or otherwise unacceptable behavior may be
-reported to the community leaders responsible for enforcement at matanshm@post.bgu.ac.il. 
+reported to the community leaders responsible for enforcement at mattansb@msbstats.info. 
 All complaints will be reviewed and investigated promptly and fairly.
 
 All community leaders are obligated to respect the privacy and security of the

---FILE: DESCRIPTION---
@@ -1,12 +1,12 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size
-Version: 0.7.9.2999
+Version: 0.8.0
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",
              role = c(""aut"", ""cre""),
-             email = ""matanshm@post.bgu.ac.il"",
+             email = ""mattansb@msbstats.info"",
              comment = c(ORCID = ""0000-0002-4287-4801"", Twitter = ""@mattansb"")),
       person(given = ""Dominique"",
              family = ""Makowski"",
@@ -44,7 +44,7 @@ Authors@R:
              role = ""rev"",
              email = ""jkarreth@ursinus.edu"",
              comment = c(ORCID = ""0000-0003-4586-7153"")))
-Maintainer: Mattan S. Ben-Shachar <matanshm@post.bgu.ac.il>
+Maintainer: Mattan S. Ben-Shachar <mattansb@msbstats.info>
 Description: Provide utilities to work with indices of effect size for a wide 
     variety of models and hypothesis tests (see list of supported models using 
     the function 'insight::supported_models()'), allowing computation of and 
@@ -58,14 +58,14 @@ Depends:
 Imports:
     bayestestR (>= 0.13.0),
     insight (>= 0.18.4),
-    parameters (>= 0.18.2),
-    performance (>= 0.9.2),
-    datawizard (>= 0.6.1),
+    parameters (>= 0.19.0),
+    performance (>= 0.10.0),
+    datawizard (>= 0.6.2),
     stats,
     utils
 Suggests:
-    correlation (>= 0.8.1),
-    see (>= 0.7.1),
+    correlation (>= 0.8.2),
+    see (>= 0.7.3),
     afex,
     BayesFactor,
     boot,

---FILE: NEWS.md---
@@ -1,4 +1,4 @@
-# effectsize 0.7.0.9999
+# effectsize 0.8.0
 
 ## Breaking Changes
 

---FILE: R/effectsize-package.R---
@@ -18,13 +18,13 @@
 #' and hypothesis tests, such as [cohens_d()], [phi()], [eta_squared()], and
 #' many more.
 #'
-#' See `vignette(""effectsize"", package = ""effectsize"")` for more details,
-#' or `vignette(package = ""effectsize"")` for a full list of vignettes.
+#' See [`vignette(""effectsize"", package = ""effectsize"")`](https://easystats.github.io/effectsize/articles/effectsize.html) for more details,
+#' or [`vignette(package = ""effectsize"")`](https://easystats.github.io/effectsize/articles/) for a full list of vignettes.
 #'
-#' References: Ben-Shachar et al. (2020) <doi:10.21105/joss.02815>.
+#' References: Ben-Shachar et al. (2020) \doi{10.21105/joss.02815}.
 #'
 #' @docType package
 #' @aliases effectsize-package
 #' @name effectsize-package
 #' @keywords internal
-""_PACKAGE""
\ No newline at end of file
+""_PACKAGE""

---FILE: R/interpret_bf.R---
@@ -32,7 +32,6 @@
 #' interpret_bf(1)
 #' interpret_bf(c(5, 2))
 #'
-#'
 #' @references
 #' - Jeffreys, H. (1961), Theory of Probability, 3rd ed., Oxford University
 #' Press, Oxford.

---FILE: _pkgdown.yml---
@@ -45,25 +45,32 @@ reference:
   - datawizard::standardize_models
   - parameters::standardize_info
 
+- subtitle: ""Correlations""
+  desc: >
+    Correlations are a standardized effect size of association
+  contents:
+  - correlation::correlation
+  - correlation::cor_test
 
-- title: ""Effect Size Conversion / Extraction""
+
+- title: ""Effect Size Conversion""
 
 - subtitle: ""From Test Statistics""
   desc: >
     Extract approximate effect sizes from their commonly associated test statistics
   contents:
-  - F_to_eta2
   - t_to_r
+  - F_to_eta2
   - chisq_to_phi
 
 - subtitle: ""Between Effect Sizes""
   desc: >
     Approximate effect sizes by converting between other related effect sizes
   contents:
   - d_to_r
+  - oddsratio_to_riskratio
   - d_to_u3
   - eta2_to_f2
-  - oddsratio_to_riskratio
   - odds_to_probs
 
 
@@ -126,6 +133,8 @@ navbar:
         href: articles/anovaES.html
       - text: ""Standardized Parameters""
         href: https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html
+      - text: ""Correlation Vignettes""
+        href: https://easystats.github.io/correlation/articles/index.html
       - text: ""Confidence Intervals""
         href: reference/effectsize_CIs.html
       - text: -------

---FILE: cran-comments.md---
@@ -6,8 +6,8 @@ DOI issues are a false positive.
 * local installation: R 4.2.1 on Windows
 * GitHub Actions
     - Windows:        devel, release, oldrel
-    - macOS:          devel, release, oldrel, 4.0, 3.6, 3.5
-    - ubuntu-18.04:   devel, release, oldrel
+    - macOS:          devel, release, oldrel
+    - ubuntu-18.04:   devel, release, oldrel, 4.0, 3.6
 * win-builder:        release
 
 
@@ -20,11 +20,16 @@ DOI issues are a false positive.
 
 - Failed handshake with *shinyapps.io* is a false positive.
 - Unavailable DOI link are false positives.
+- Spelling mistakes are false positives.
 
 
 ## revdepcheck results
 
-We checked 16 reverse dependencies, comparing R CMD check results across CRAN and dev versions of this package.
+We checked 18 reverse dependencies, comparing R CMD check results across CRAN and dev versions of this package.
 
- * We saw 0 new problems
+ * We saw 1 new problems
  * We failed to check 0 packages
+
+### New problems
+
+* statsExpressions - 1 new error. Package maintainer has been informed.

---FILE: dev/revdepcheck.R---
@@ -0,0 +1,5 @@
+library(revdepcheck)
+
+revdep_check(num_workers = 4)
+revdep_report()
+revdep_reset()
\ No newline at end of file

---FILE: man/effectsize-package.Rd---
@@ -20,10 +20,10 @@ and their confidence intervals (CIs), from a variety of statistical models
 and hypothesis tests, such as \code{\link[=cohens_d]{cohens_d()}}, \code{\link[=phi]{phi()}}, \code{\link[=eta_squared]{eta_squared()}}, and
 many more.
 
-See \code{vignette(""effectsize"", package = ""effectsize"")} for more details,
-or \code{vignette(package = ""effectsize"")} for a full list of vignettes.
+See \href{https://easystats.github.io/effectsize/articles/effectsize.html}{\code{vignette(""effectsize"", package = ""effectsize"")}} for more details,
+or \href{https://easystats.github.io/effectsize/articles/}{\code{vignette(package = ""effectsize"")}} for a full list of vignettes.
 
-References: Ben-Shachar et al. (2020) \url{doi:10.21105/joss.02815}.
+References: Ben-Shachar et al. (2020) \doi{10.21105/joss.02815}.
 }
 \details{
 \code{effectsize}
@@ -37,7 +37,7 @@ Useful links:
 
 }
 \author{
-\strong{Maintainer}: Mattan S. Ben-Shachar \email{matanshm@post.bgu.ac.il} (\href{https://orcid.org/0000-0002-4287-4801}{ORCID}) (@mattansb)
+\strong{Maintainer}: Mattan S. Ben-Shachar \email{mattansb@msbstats.info} (\href{https://orcid.org/0000-0002-4287-4801}{ORCID}) (@mattansb)
 
 Authors:
 \itemize{

---FILE: man/interpret_bf.Rd---
@@ -64,7 +64,6 @@ Rules apply to BF as ratios, so BF of 10 is as extreme as a BF of 0.1 (1/10).
 interpret_bf(1)
 interpret_bf(c(5, 2))
 
-
 }
 \references{
 \itemize{

---FILE: vignettes/effectsize.Rmd---
@@ -65,30 +65,32 @@ M <- rbind(
 cramers_v(M)
 ```
 
-<!-- ## Parameter and Model Standardization -->
+## Parameter and Model Standardization
 
-<!-- Standardizing parameters (i.e., coefficients) can allow for their comparison within and between models, variables and studies. To this end, two functions are available: `standardize()`, which returns an updated model, re-fit with standardized data, and `standardize_parameters()`, which returns a table of standardized coefficients from a provided model [for a list of supported models, see the *insight* package; @luedecke2019insight]. -->
+> Note: this functionality has been moved to the `parameters` and `datawizard` packages.
 
-<!-- ```{r} -->
-<!-- model <- lm(mpg ~ cyl * am,  -->
-<!--             data = mtcars) -->
+Standardizing parameters (i.e., coefficients) can allow for their comparison within and between models, variables and studies. To this end, two functions are available: `standardize()`, which returns an updated model, re-fit with standardized data, and `standardize_parameters()`, which returns a table of standardized coefficients from a provided model [for a list of supported models, see the *insight* package; @luedecke2019insight].
 
-<!-- standardize(model) -->
+```{r}
+model <- lm(mpg ~ cyl * am,
+            data = mtcars)
 
-<!-- standardize_parameters(model) -->
-<!-- ``` -->
+datawizard::standardize(model)
 
-<!-- Standardized parameters can also be produced for generalized linear models (GLMs; where only the predictors are standardized): -->
+parameters::standardize_parameters(model)
+```
 
-<!-- ```{r} -->
-<!-- model <- glm(am ~ cyl + hp, -->
-<!--              family = ""binomial"", -->
-<!--              data = mtcars) -->
+Standardized parameters can also be produced for generalized linear models (GLMs; where only the predictors are standardized):
 
-<!-- standardize_parameters(model, exponentiate = TRUE) -->
-<!-- ``` -->
+```{r}
+model <- glm(am ~ cyl + hp,
+             family = ""binomial"",
+             data = mtcars)
+
+parameters::standardize_parameters(model, exponentiate = TRUE)
+```
 
-<!-- `standardize_parameters()` provides several standardization methods, such as robust standardization, or *pseudo*-standardized coefficients for (generalized) linear mixed models [@hoffman2015longitudinal]. A full review of these methods can be found in the [*Parameter and Model Standardization* vignette](https://easystats.github.io/effectsize/articles/standardize_parameters.html). -->
+`standardize_parameters()` provides several standardization methods, such as robust standardization, or *pseudo*-standardized coefficients for (generalized) linear mixed models [@hoffman2015longitudinal]. A full review of these methods can be found in the [*Parameter and Model Standardization* vignette](https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html).
 
 ## Effect Sizes for ANOVAs
 

---FILE: vignettes/interpret.Rmd---
@@ -67,6 +67,8 @@ more believable.
 
 ## Correlation *r*
 
+There can be used to interpret not only Pearson's correlation coefficient, but also Spearman's, $\phi$ (phi), Cramer's *V* and Tschuprow's *T*. Although Cohen's *w* and Pearson's *C* are _not_ a correlation coefficients, they are often also interpreted as such.
+
 #### @funder2019evaluating
 
 ```r",True,True,Documentation / Formatting,7
easystats,effectsize,e1627f755970e0e0f2eb30db05e088b82aeb4cd3,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-10-03T09:59:27Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-10-03T09:59:27Z,https://github.com/easystats/easystats/issues/314,DESCRIPTION;R/effectsize-package.R;man/effectsize-package.Rd,False,True,True,False,94,6,100,"---FILE: DESCRIPTION---
@@ -1,6 +1,6 @@
 Type: Package
 Package: effectsize
-Title: Indices of Effect Size and Standardized Parameters
+Title: Indices of Effect Size
 Version: 0.7.9.2999
 Authors@R: 
     c(person(given = ""Mattan S."",
@@ -45,11 +45,10 @@ Authors@R:
              email = ""jkarreth@ursinus.edu"",
              comment = c(ORCID = ""0000-0003-4586-7153"")))
 Maintainer: Mattan S. Ben-Shachar <matanshm@post.bgu.ac.il>
-Description: Provide utilities to work with indices of effect size and
-    standardized parameters for a wide variety of models (see list of
-    supported models using the function 'insight::supported_models()'),
-    allowing computation of and conversion between indices such as Cohen's
-    d, r, odds, etc.
+Description: Provide utilities to work with indices of effect size for a wide 
+    variety of models and hypothesis tests (see list of supported models using 
+    the function 'insight::supported_models()'), allowing computation of and 
+    conversion between indices such as Cohen's d, r, odds, etc.
     References: Ben-Shachar et al. (2020) <doi:10.21105/joss.02815>.
 License: GPL-3
 URL: https://easystats.github.io/effectsize/

---FILE: R/effectsize-package.R---
@@ -0,0 +1,30 @@
+#' \code{effectsize}
+#'
+#' @title effectsize: Indices of Effect Size
+#'
+#' @description
+#'
+#' In both theoretical and applied research, it is often of interest to assess
+#' the strength of an observed association. This is typically done to allow the
+#' judgment of the magnitude of an effect, especially when units of measurement
+#' are not meaningful. Though some indices of effect size, such as the
+#' correlation coefficient (itself a standardized covariance coefficient) are
+#' readily available, other measures are often harder to obtain.
+#'
+#' **effectsize** fills this important gap, providing utilities for easily
+#' estimating a wide variety of standardized effect sizes (i.e., effect sizes
+#' that are not tied to the units of measurement of the variables of interest)
+#' and their confidence intervals (CIs), from a variety of statistical models
+#' and hypothesis tests, such as [cohens_d()], [phi()], [eta_squared()], and
+#' many more.
+#'
+#' See `vignette(""effectsize"", package = ""effectsize"")` for more details,
+#' or `vignette(package = ""effectsize"")` for a full list of vignettes.
+#'
+#' References: Ben-Shachar et al. (2020) <doi:10.21105/joss.02815>.
+#'
+#' @docType package
+#' @aliases effectsize-package
+#' @name effectsize-package
+#' @keywords internal
+""_PACKAGE""
\ No newline at end of file

---FILE: man/effectsize-package.Rd---
@@ -0,0 +1,59 @@
+% Generated by roxygen2: do not edit by hand
+% Please edit documentation in R/effectsize-package.R
+\docType{package}
+\name{effectsize-package}
+\alias{effectsize-package}
+\alias{_PACKAGE}
+\title{effectsize: Indices of Effect Size}
+\description{
+In both theoretical and applied research, it is often of interest to assess
+the strength of an observed association. This is typically done to allow the
+judgment of the magnitude of an effect, especially when units of measurement
+are not meaningful. Though some indices of effect size, such as the
+correlation coefficient (itself a standardized covariance coefficient) are
+readily available, other measures are often harder to obtain.
+
+\strong{effectsize} fills this important gap, providing utilities for easily
+estimating a wide variety of standardized effect sizes (i.e., effect sizes
+that are not tied to the units of measurement of the variables of interest)
+and their confidence intervals (CIs), from a variety of statistical models
+and hypothesis tests, such as \code{\link[=cohens_d]{cohens_d()}}, \code{\link[=phi]{phi()}}, \code{\link[=eta_squared]{eta_squared()}}, and
+many more.
+
+See \code{vignette(""effectsize"", package = ""effectsize"")} for more details,
+or \code{vignette(package = ""effectsize"")} for a full list of vignettes.
+
+References: Ben-Shachar et al. (2020) \url{doi:10.21105/joss.02815}.
+}
+\details{
+\code{effectsize}
+}
+\seealso{
+Useful links:
+\itemize{
+  \item \url{https://easystats.github.io/effectsize/}
+  \item Report bugs at \url{https://github.com/easystats/effectsize/issues/}
+}
+
+}
+\author{
+\strong{Maintainer}: Mattan S. Ben-Shachar \email{matanshm@post.bgu.ac.il} (\href{https://orcid.org/0000-0002-4287-4801}{ORCID}) (@mattansb)
+
+Authors:
+\itemize{
+  \item Dominique Makowski \email{dom.makowski@gmail.com} (\href{https://orcid.org/0000-0001-5375-9967}{ORCID}) (@Dom_Makowski)
+  \item Daniel LÃ¼decke \email{d.luedecke@uke.de} (\href{https://orcid.org/0000-0002-8895-3206}{ORCID}) (@strengejacke)
+  \item Indrajeet Patil \email{patilindrajeet.science@gmail.com} (\href{https://orcid.org/0000-0003-1995-6531}{ORCID}) (@patilindrajeets)
+  \item Brenton M. Wiernik \email{brenton@wiernik.org} (\href{https://orcid.org/0000-0001-9560-6336}{ORCID}) (@bmwiernik)
+}
+
+Other contributors:
+\itemize{
+  \item Ken Kelley [contributor]
+  \item David Stanley [contributor]
+  \item Jessica Burnett \email{jburnett@usgs.gov} (\href{https://orcid.org/0000-0002-0896-5099}{ORCID}) [reviewer]
+  \item Johannes Karreth \email{jkarreth@ursinus.edu} (\href{https://orcid.org/0000-0003-4586-7153}{ORCID}) [reviewer]
+}
+
+}
+\keyword{internal}",True,False,Documentation / Formatting,6
easystats,effectsize,6aa870454c3624a3745e955674a442b2bdc91584,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2022-10-03T07:34:11Z,GitHub,noreply@github.com,2022-10-03T07:34:11Z,"fix some tests and errors (#513)

* init

* more tests

* Update test-utils_validate_input_data.R

* styler",R/xtab_corr.R;man/phi.Rd;tests/testthat/test-cohens_d.R;tests/testthat/test-cohens_g.R;tests/testthat/test-common_language.R;tests/testthat/test-convert_between_CLES.R;tests/testthat/test-effectsize.R;tests/testthat/test-helpers.R;tests/testthat/test-is_effectsize_name.R;tests/testthat/test-print.R;tests/testthat/test-rankES.R;tests/testthat/test-utils_validate_input_data.R;tests/testthat/test-xtab.R;vignettes/effectsize_API.Rmd,True,True,True,False,284,258,542,"---FILE: R/xtab_corr.R---
@@ -7,8 +7,7 @@
 #'
 #' @inheritParams stats::chisq.test
 #' @inheritParams chisq_to_phi
-#' @param ... For goodness-of-fit effect sizes, can pass `rescale.p` (see
-#'   [stats::chisq.test()]). Else, ignored.
+#' @param ... Ignored.
 #'
 #' @details
 #'
@@ -160,6 +159,7 @@ tschuprows_t <- function(x, y = NULL,
 #' @importFrom stats chisq.test
 #' @export
 cohens_w <- function(x, y = NULL, p = rep(1 / length(x), length(x)),
+                     rescale.p = TRUE,
                      ci = 0.95, alternative = ""greater"",
                      ...) {
   alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
@@ -170,7 +170,7 @@ cohens_w <- function(x, y = NULL, p = rep(1 / length(x), length(x)),
     x, ""(Pearson's Chi-squared|Chi-squared test for given probabilities)"",
     ""Chi-squared-test""
   )) {
-    x <- suppressWarnings(stats::chisq.test(x, y, p = p, ...))
+    x <- suppressWarnings(stats::chisq.test(x, y, p = p, rescale.p = rescale.p))
     x$data.name <- NULL
   }
 
@@ -182,14 +182,15 @@ cohens_w <- function(x, y = NULL, p = rep(1 / length(x), length(x)),
 #' @importFrom stats chisq.test
 #' @export
 fei <- function(x, p = rep(1 / length(x), length(x)),
+                rescale.p = TRUE,
                 ci = 0.95, alternative = ""greater"",
                 ...) {
   alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
 
   if (inherits(x, ""BFBayesFactor"")) {
     stop(""Fei is only applicable to goodness of fit tests."", call. = FALSE)
   } else if (!.is_htest_of_type(x, ""Chi-squared test for given probabilities"", ""Chi-squared-test"")) {
-    x <- suppressWarnings(stats::chisq.test(x, y = NULL, p = p, ...))
+    x <- suppressWarnings(stats::chisq.test(x, y = NULL, p = p, rescale.p = rescale.p))
     x$data.name <- NULL
   }
 
@@ -200,6 +201,7 @@ fei <- function(x, p = rep(1 / length(x), length(x)),
 #' @importFrom stats chisq.test
 #' @export
 pearsons_c <- function(x, y = NULL, p = rep(1 / length(x), length(x)),
+                       rescale.p = TRUE,
                        ci = 0.95, alternative = ""greater"",
                        ...) {
   alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
@@ -210,7 +212,7 @@ pearsons_c <- function(x, y = NULL, p = rep(1 / length(x), length(x)),
     x, ""(Pearson's Chi-squared|Chi-squared test for given probabilities)"",
     ""Chi-squared-test""
   )) {
-    x <- suppressWarnings(stats::chisq.test(x, y, p = p, ...))
+    x <- suppressWarnings(stats::chisq.test(x, y, p = p, rescale.p = rescale.p))
     x$data.name <- NULL
   }
 

---FILE: man/phi.Rd---
@@ -19,6 +19,7 @@ cohens_w(
   x,
   y = NULL,
   p = rep(1/length(x), length(x)),
+  rescale.p = TRUE,
   ci = 0.95,
   alternative = ""greater"",
   ...
@@ -27,6 +28,7 @@ cohens_w(
 fei(
   x,
   p = rep(1/length(x), length(x)),
+  rescale.p = TRUE,
   ci = 0.95,
   alternative = ""greater"",
   ...
@@ -36,6 +38,7 @@ pearsons_c(
   x,
   y = NULL,
   p = rep(1/length(x), length(x)),
+  rescale.p = TRUE,
   ci = 0.95,
   alternative = ""greater"",
   ...
@@ -59,11 +62,14 @@ Controls the type of CI returned: \code{""greater""} (default) or \code{""less""}
 is allowed (e.g., \code{""g""}, \code{""l""}, \code{""two""}...). See \emph{One-Sided CIs} in
 \link{effectsize_CIs}.}
 
-\item{...}{For goodness-of-fit effect sizes, can pass \code{rescale.p} (see
-\code{\link[stats:chisq.test]{stats::chisq.test()}}). Else, ignored.}
+\item{...}{Ignored.}
 
 \item{p}{a vector of probabilities of the same length as \code{x}.
     An error is given if any entry of \code{p} is negative.}
+
+\item{rescale.p}{a logical scalar; if TRUE then \code{p} is rescaled
+    (if necessary) to sum to 1.  If \code{rescale.p} is FALSE, and
+    \code{p} does not sum to 1, an error is given.}
 }
 \value{
 A data frame with the effect size (\code{Cramers_v}, \code{phi} (possibly with

---FILE: tests/testthat/test-cohens_d.R---
@@ -12,53 +12,6 @@ test_that(""cohens_d errors and warnings"", {
   d3 <- cohens_d(iris$Sepal.Length, iris$Sepal.Width, ci = 0.90, alternative = ""g"")
   expect_equal(d1$CI_high, d2$CI_high)
   expect_equal(d1$CI_low, d3$CI_low)
-
-
-  # Errors and warnings -----------------------------------------------------
-  df <- data.frame(
-    a = 1:10,
-    b = 2:11,
-    c = rep(letters[1:2], each = 5),
-    d = c(""a"", ""b"", ""b"", ""c"", ""c"", ""b"", ""c"", ""a"", ""a"", ""b""),
-    e = rep(0:1, each = 5)
-  )
-  df$exp_a <- exp(df$a)
-  a2 <- 1:11
-
-  expect_error(cohens_d(a ~ c, data = df), regexp = NA)
-  expect_error(cohens_d(""a"", ""c"", data = df), regexp = NA)
-  expect_error(cohens_d(""a"", ""b"", data = df), regexp = NA)
-  expect_error(cohens_d(a2, df$b), regexp = NA)
-  expect_error(cohens_d(b ~ e, data = df), regexp = NA)
-
-  expect_error(cohens_d(df$a ~ df$c), regexp = NA)
-  expect_equal(cohens_d(""exp_a"", ""c"", data = df), cohens_d(exp(a) ~ c, data = df))
-
-  expect_error(cohens_d(a ~ b, data = df), ""exactly"")
-  expect_error(cohens_d(a ~ d, data = df), ""exactly"")
-  expect_error(cohens_d(""a"", ""d"", data = df), ""exactly"")
-  expect_error(cohens_d(""c"", ""c"", data = df), ""non-numeric"")
-  expect_error(cohens_d(a2, df$c), ""length"")
-  expect_error(cohens_d(""a"", ""aa"", data = df), ""missing"")
-
-  expect_warning(cohens_d(""b"", ""e"", data = df), ""convert"")
-})
-
-test_that(""cohens d - grouping character vector"", {
-  dat <- data.frame(
-    g = rep(c(""treatment"", ""control""), each = 100),
-    y = c(rnorm(n = 200))
-  )
-
-  d <- cohens_d(dat$y, factor(dat$g), ci = NULL)[[1]]
-  expect_equal(cohens_d(dat$y, dat$g, ci = NULL)[[1]], d)
-  expect_equal(cohens_d(y ~ g, data = dat, ci = NULL)[[1]], d)
-  expect_equal(cohens_d(y ~ factor(g), data = dat, ci = NULL)[[1]], d)
-  expect_equal(cohens_d(dat$y ~ dat$g, ci = NULL)[[1]], d)
-  expect_equal(cohens_d(dat$y ~ factor(dat$g), ci = NULL)[[1]], d)
-  expect_equal(cohens_d(""y"", ""g"", data = dat, ci = NULL)[[1]], d)
-  expect_equal(cohens_d(""y"", dat$g, data = dat, ci = NULL)[[1]], d)
-  expect_equal(cohens_d(dat$y, ""g"", data = dat, ci = NULL)[[1]], d)
 })
 
 test_that(""cohens_d - mu"", {
@@ -132,23 +85,3 @@ test_that(""fixed values"", {
   expect_equal(cohens_d(x1, x2)[[1]], -sqrt(0.9), tolerance = 1e-2)
   expect_equal(glass_delta(x2, x1, ci = NULL)[[1]], 1.5, tolerance = 1e-2)
 })
-
-test_that(""Missing values"", {
-  x <- c(1, NA, 2, 3, 4)
-  y <- c(1, 2, 3, 4, 5)
-
-  expect_warning(d1 <- cohens_d(x, y), ""dropped"")
-  expect_warning(d2 <- cohens_d(x, y, paired = TRUE), ""dropped"")
-  expect_equal(d1, cohens_d(1:4, 1:5), tolerance = 0.01) # indep
-  expect_equal(d2, cohens_d(1:4, c(1, 3:5), paired = TRUE), tolerance = 0.01) # paired
-
-  # no length problems
-  expect_error(cohens_d(mtcars$mpg - 23), regexp = NA)
-
-  # Missing factor levels: the actual levels in the data are 3rd and 4th
-  f <- factor(letters[1:2], levels = c(""d"", ""e"", ""a"", ""b""))
-  f <- rep(f, each = 5)
-  y <- c(2, 4, 3, 5, 1, 7, 9, 8, 6, 1)
-  expect_error(d <- cohens_d(y, f), regexp = NA)
-  expect_true(attr(d, ""pooled_sd""))
-})

---FILE: tests/testthat/test-cohens_g.R---
@@ -0,0 +1,39 @@
+test_that(""Cohen's g"", {
+  # From mcnemar.test
+  Performance <-
+    matrix(c(794, 86, 150, 570),
+      nrow = 2,
+      dimnames = list(
+        ""1st Survey"" = c(""Approve"", ""Disapprove""),
+        ""2nd Survey"" = c(""Approve"", ""Disapprove"")
+      )
+    )
+  g <- cohens_g(Performance)
+  expect_equal(g$Cohens_g, 0.136, tolerance = 0.01)
+  expect_equal(g$CI_low, 0.072, tolerance = 0.01)
+  expect_equal(g$CI_high, 0.194, tolerance = 0.01)
+
+
+  AndersonRainBarrel <- matrix(c(
+    9L, 17L,
+    5L, 15L
+  ), nrow = 2)
+  g <- cohens_g(AndersonRainBarrel)
+  expect_equal(g$Cohens_g, 0.273, tolerance = 0.01)
+  expect_equal(g$CI_low, 0.066, tolerance = 0.01)
+  expect_equal(g$CI_high, 0.399, tolerance = 0.01)
+
+
+  M <- matrix(
+    c(
+      794, 86, 150,
+      570, 794, 86,
+      150, 570, 15
+    ),
+    nrow = 3
+  )
+  g <- cohens_g(M)
+  expect_equal(g$Cohens_g, 0.300, tolerance = 0.01)
+  expect_equal(g$CI_low, 0.280, tolerance = 0.01)
+  expect_equal(g$CI_high, 0.319, tolerance = 0.01)
+})

---FILE: tests/testthat/test-common_language.R---
@@ -108,40 +108,3 @@ test_that(""CLES | errors"", {
   expect_error(cohens_u3(1:3), ""two"")
   expect_error(p_overlap(1:3), ""two"")
 })
-
-
-test_that(""CLES | htest - t-test"", {
-  x <<- 1:4
-  y <<- c(1, 1:3)
-  Tt <- t.test(x, y, var.equal = TRUE)
-
-  expect_equal(e <- p_superiority(Tt), p_superiority(x, y), ignore_attr = TRUE)
-  expect_equal(effectsize(Tt, type = ""p_superiority""), e)
-
-  expect_equal(e <- cohens_u1(Tt), cohens_u1(x, y), ignore_attr = TRUE)
-  expect_equal(effectsize(Tt, type = ""u1""), e)
-
-  expect_equal(e <- cohens_u2(Tt), cohens_u2(x, y), ignore_attr = TRUE)
-  expect_equal(effectsize(Tt, type = ""u2""), e)
-
-  expect_equal(e <- cohens_u3(Tt), cohens_u3(x, y), ignore_attr = TRUE)
-  expect_equal(effectsize(Tt, type = ""u3""), e)
-
-  expect_equal(e <- p_overlap(Tt), p_overlap(x, y), ignore_attr = TRUE)
-  expect_equal(effectsize(Tt, type = ""overlap""), e)
-})
-
-
-test_that(""CLES | htest - Wilcox"", {
-  x <<- 1:4
-  y <<- c(1, 1:3)
-  Wt <- suppressWarnings(wilcox.test(x, y, var.equal = TRUE))
-
-  expect_equal(e <- p_superiority(Wt), p_superiority(x, y, parametric = FALSE), ignore_attr = TRUE)
-  expect_equal(effectsize(Wt, type = ""p_superiority""), e)
-
-  expect_error(effectsize(Wt, type = ""u1""), ""parametric"")
-
-  expect_equal(e <- cohens_u3(Wt), cohens_u3(x, y, parametric = FALSE), ignore_attr = TRUE)
-  expect_equal(effectsize(Wt, type = ""u3""), e)
-})

---FILE: tests/testthat/test-effectsize.R---
@@ -47,6 +47,41 @@ test_that(""t-test"", {
   )
 })
 
+test_that(""t-test | CLES"", {
+  x <<- 1:4
+  y <<- c(1, 1:3)
+  Tt <- t.test(x, y, var.equal = TRUE)
+
+  expect_equal(e <- p_superiority(Tt), p_superiority(x, y), ignore_attr = TRUE)
+  expect_equal(effectsize(Tt, type = ""p_superiority""), e)
+
+  expect_equal(e <- cohens_u1(Tt), cohens_u1(x, y), ignore_attr = TRUE)
+  expect_equal(effectsize(Tt, type = ""u1""), e)
+
+  expect_equal(e <- cohens_u2(Tt), cohens_u2(x, y), ignore_attr = TRUE)
+  expect_equal(effectsize(Tt, type = ""u2""), e)
+
+  expect_equal(e <- cohens_u3(Tt), cohens_u3(x, y), ignore_attr = TRUE)
+  expect_equal(effectsize(Tt, type = ""u3""), e)
+
+  expect_equal(e <- p_overlap(Tt), p_overlap(x, y), ignore_attr = TRUE)
+  expect_equal(effectsize(Tt, type = ""overlap""), e)
+})
+
+test_that(""Wilcox | CLES"", {
+  x <<- 1:4
+  y <<- c(1, 1:3)
+  Wt <- suppressWarnings(wilcox.test(x, y, var.equal = TRUE))
+
+  expect_equal(e <- p_superiority(Wt), p_superiority(x, y, parametric = FALSE), ignore_attr = TRUE)
+  expect_equal(effectsize(Wt, type = ""p_superiority""), e)
+
+  expect_error(effectsize(Wt, type = ""u1""), ""parametric"")
+
+  expect_equal(e <- cohens_u3(Wt), cohens_u3(x, y, parametric = FALSE), ignore_attr = TRUE)
+  expect_equal(effectsize(Wt, type = ""u3""), e)
+})
+
 test_that(""Chisq-test"", {
   contingency_table <-
     as.table(rbind(c(760, 330, 470), c(480, 240, 480), c(480, 240, 480)))

---FILE: tests/testthat/test-helpers.R---
@@ -1,64 +0,0 @@
-
-test_that(""is_effectsize_name works"", {
-  expect_false(is_effectsize_name(""is_effectsize_name""))
-  expect_true(is_effectsize_name(""Eta2""))
-  expect_equal(get_effectsize_label(""hEDgES_G""), ""Hedges' g"")
-})
-
-test_that(""validate data from formula"", {
-  expect_error(cohens_d(mpg ~ cyl, data = mtcars), ""exactly"")
-  expect_error(cohens_d(mpg ~ cyl, data = mtcars, subset = cyl %in% c(4, 6)), regexp = NA)
-
-  d1 <- cohens_d(mpg ~ cyl,
-    data = mtcars,
-    subset = cyl < 8
-  )
-
-  x <- mtcars$cyl < 8
-  d2 <- cohens_d(mpg ~ cyl,
-    data = mtcars,
-    subset = x
-  )
-
-  x <- mtcars$cyl
-  d3 <- cohens_d(mpg ~ cyl,
-    data = mtcars,
-    subset = x < 8
-  )
-
-  d4 <- cohens_d(mpg ~ cyl,
-    data = mtcars,
-    subset =
-      c(
-        TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, FALSE, TRUE, TRUE, TRUE,
-        TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE,
-        TRUE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE,
-        FALSE, TRUE
-      )
-  )
-
-  expect_equal(d1, d2)
-  expect_equal(d1, d3)
-  expect_equal(d1, d4)
-
-  expect_error(rank_biserial(mpg ~ cyl, data = mtcars), ""exactly"")
-  expect_error(rank_biserial(mpg ~ cyl, data = mtcars, subset = cyl %in% c(4, 6)), regexp = NA)
-
-  expect_error(sd_pooled(mpg ~ cyl, data = mtcars), ""exactly"")
-  expect_error(sd_pooled(mpg ~ cyl, data = mtcars, subset = cyl %in% c(4, 6)), regexp = NA)
-
-  expect_error(cohens_u1(mpg ~ cyl, data = mtcars), ""exactly"")
-  expect_error(cohens_u1(mpg ~ cyl, data = mtcars, subset = cyl %in% c(4, 6)), regexp = NA)
-
-  d <- expand.grid(id = 1:30, g = 1:4)
-  d$y <- rnorm(nrow(d)) + d$g
-  expect_equal(
-    rank_epsilon_squared(y ~ g, data = d, subset = g < 4, ci = NULL),
-    rank_epsilon_squared(y ~ g, data = subset(d, g < 4), ci = NULL)
-  )
-
-  expect_equal(
-    kendalls_w(y ~ g | id, data = d, subset = g < 4, ci = NULL),
-    kendalls_w(y ~ g | id, data = subset(d, g < 4), ci = NULL)
-  )
-})

---FILE: tests/testthat/test-is_effectsize_name.R---
@@ -0,0 +1,6 @@
+
+test_that(""is_effectsize_name works"", {
+  expect_false(is_effectsize_name(""is_effectsize_name""))
+  expect_true(is_effectsize_name(""Eta2""))
+  expect_equal(get_effectsize_label(""hEDgES_G""), ""Hedges' g"")
+})

---FILE: tests/testthat/test-rankES.R---
@@ -15,20 +15,6 @@ test_that(""rank_biserial"", {
   A <- c(48, 48, 77, 86, 85, 85, 16)
   B <- c(14, 34, 34, 77)
   expect_equal(rank_biserial(A, B)[[1]], 0.6071429, tolerance = 0.01)
-
-
-  df <- data.frame(
-    outcome = c(x, y),
-    g = factor(rep(0:1, each = 9))
-  )
-  expect_equal(
-    rank_biserial(outcome ~ g, data = df, ci = NULL),
-    rank_biserial(df$outcome ~ df$g, ci = NULL)
-  )
-  expect_equal(
-    rank_biserial(outcome ~ g, data = df, ci = NULL),
-    rank_biserial(""outcome"", ""g"", data = df, ci = NULL)
-  )
 })
 
 
@@ -42,7 +28,6 @@ test_that(""rank_biserial | ordered"", {
     rank_biserial(as.numeric(x1), as.numeric(x2))
   )
 
-
   x1 <- ordered(as.numeric(x1))
   x2 <- ordered(as.numeric(x2))
   expect_error(rank_biserial(x1, x2), ""levels"")
@@ -64,15 +49,6 @@ test_that(""rank_epsilon_squared"", {
   expect_equal(E[[1]], 0.05934066, tolerance = 0.01)
   expect_equal(E$CI_low, 0.01726463, tolerance = 0.01)
   expect_equal(E$CI_high, 1)
-
-  expect_equal(
-    rank_epsilon_squared(x ~ g, ci = NULL),
-    rank_epsilon_squared(x, g, ci = NULL)
-  )
-
-  g[1] <- NA
-  expect_warning(E1 <- rank_epsilon_squared(x, g, ci = NULL), ""dropped"")
-  expect_equal(E1, rank_epsilon_squared(x[-1], g[-1], ci = NULL))
 })
 
 
@@ -98,25 +74,8 @@ test_that(""kendalls_w"", {
     ""Wide Angle"" = c(5.55, 5.75, 5.5)
   )
 
-  M2 <- data.frame(
-    id = c(1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 3L),
-    name = c(
-      ""Round Out"", ""Narrow Angle"", ""Wide Angle"",
-      ""Round Out"", ""Narrow Angle"", ""Wide Angle"",
-      ""Round Out"", ""Narrow Angle"", ""Wide Angle""
-    ),
-    value = c(5.4, 5.5, 5.55, 5.85, 5.7, 5.75, 5.2, 5.6, 5.5)
-  )
-
   set.seed(1)
   W1 <- kendalls_w(M1)
-  W2 <- kendalls_w(value ~ name | id, data = M2, ci = NULL)
-  W3 <- kendalls_w(M2$value, M2$name, M2$id, ci = NULL)
-  W4 <- kendalls_w(M2$value ~ M2$name | M2$id, ci = NULL)
-
-  expect_equal(W1[[1]], W2[[1]])
-  expect_equal(W1[[1]], W3[[1]])
-  expect_equal(W1[[1]], W4[[1]])
   expect_equal(W1[[1]], 0.11111111, tolerance = 0.01)
   expect_equal(W1$CI_low, 0.11111111, tolerance = 0.01)
   expect_equal(W1$CI_high, 1, tolerance = 0.01)

---FILE: tests/testthat/test-utils_validate_input_data.R---
@@ -0,0 +1,188 @@
+test_that("".get_data_2_samples"", {
+  df <- data.frame(
+    a = 1:10,
+    b = 2:11,
+    c = rep(letters[1:2], each = 5),
+    d = c(""a"", ""b"", ""b"", ""c"", ""c"", ""b"", ""c"", ""a"", ""a"", ""b""),
+    e = rep(0:1, each = 5)
+  )
+  df$exp_a <- exp(df$a)
+  a2 <- 1:11
+
+  expect_error(d1 <- cohens_d(a ~ c, data = df), regexp = NA)
+  expect_error(d2 <- cohens_d(""a"", ""c"", data = df), regexp = NA)
+  expect_error(d3 <- cohens_d(df$a ~ df$c), regexp = NA)
+  expect_error(d4 <- cohens_d(df$a, df$c), regexp = NA)
+  expect_error(d5 <- cohens_d(df$a[df$c == ""a""], df$a[df$c == ""b""]), regexp = NA)
+  expect_equal(d1, d2)
+  expect_equal(d1, d3)
+  expect_equal(d1, d4)
+  expect_equal(d1, d5)
+
+  expect_error(cohens_d(""a"", ""b"", data = df), regexp = NA)
+  expect_error(cohens_d(a2, df$b), regexp = NA)
+  expect_error(cohens_d(b ~ e, data = df), regexp = NA)
+
+  expect_equal(
+    cohens_d(exp(a) ~ c, data = df),
+    cohens_d(""exp_a"", ""c"", data = df)
+  )
+
+
+  expect_error(cohens_d(a ~ b, data = df), ""exactly"")
+  expect_error(cohens_d(a ~ d, data = df), ""exactly"")
+  expect_error(cohens_d(""a"", ""d"", data = df), ""exactly"")
+  expect_error(cohens_d(""c"", ""c"", data = df), ""non-numeric"")
+  expect_error(cohens_d(a2, df$c), ""length"")
+  expect_error(cohens_d(""a"", ""aa"", data = df), ""missing"")
+
+  expect_warning(cohens_d(""b"", ""e"", data = df), ""convert"")
+
+  x <- c(1, NA, 2, 3, 4)
+  y <- c(1, 2, 3, 4, 5)
+
+  expect_warning(d1 <- cohens_d(x, y), ""dropped"")
+  expect_warning(d2 <- cohens_d(x, y, paired = TRUE), ""dropped"")
+  expect_equal(d1, cohens_d(1:4, 1:5), tolerance = 0.01) # indep
+  expect_equal(d2, cohens_d(1:4, c(1, 3:5), paired = TRUE), tolerance = 0.01) # paired
+
+  # no length problems
+  expect_error(cohens_d(mtcars$mpg - 23), regexp = NA)
+
+  # Missing factor levels: the actual levels in the data are 3rd and 4th
+  f <- factor(letters[1:2], levels = c(""d"", ""e"", ""a"", ""b""))
+  f <- rep(f, each = 5)
+  y <- c(2, 4, 3, 5, 1, 7, 9, 8, 6, 1)
+  expect_error(d <- cohens_d(y, f), regexp = NA)
+  expect_true(attr(d, ""pooled_sd""))
+})
+
+test_that("".get_data_2_samples | subset"", {
+  expect_error(cohens_d(mpg ~ cyl, data = mtcars), ""exactly"")
+  expect_error(cohens_d(mpg ~ cyl, data = mtcars, subset = cyl %in% c(4, 6)), regexp = NA)
+
+  expect_error(rank_biserial(mpg ~ cyl, data = mtcars), ""exactly"")
+  expect_error(rank_biserial(mpg ~ cyl, data = mtcars, subset = cyl %in% c(4, 6)), regexp = NA)
+
+  expect_error(sd_pooled(mpg ~ cyl, data = mtcars), ""exactly"")
+  expect_error(sd_pooled(mpg ~ cyl, data = mtcars, subset = cyl %in% c(4, 6)), regexp = NA)
+
+  expect_error(cohens_u1(mpg ~ cyl, data = mtcars), ""exactly"")
+  expect_error(cohens_u1(mpg ~ cyl, data = mtcars, subset = cyl %in% c(4, 6)), regexp = NA)
+
+  d1 <- cohens_d(mpg ~ cyl,
+    data = mtcars,
+    subset = cyl < 8
+  )
+
+  x <- mtcars$cyl < 8
+  d2 <- cohens_d(mpg ~ cyl,
+    data = mtcars,
+    subset = x
+  )
+
+  x <- mtcars$cyl
+  d3 <- cohens_d(mpg ~ cyl,
+    data = mtcars,
+    subset = x < 8
+  )
+
+  d4 <- cohens_d(mpg ~ cyl,
+    data = mtcars,
+    subset =
+      c(
+        TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, FALSE, TRUE, TRUE, TRUE,
+        TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE,
+        TRUE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE,
+        FALSE, TRUE
+      )
+  )
+
+  expect_equal(d1, d2)
+  expect_equal(d1, d3)
+  expect_equal(d1, d4)
+})
+
+test_that("".get_data_multi_group"", {
+  df <- data.frame(
+    a = 1:15,
+    b = 2:16,
+    c = rep(letters[1:3], each = 5),
+    e = rep(0:1, length = 15)
+  )
+  df$exp_a <- exp(df$a)
+
+  expect_error(d1 <- rank_epsilon_squared(a ~ c, data = df), regexp = NA)
+  expect_error(d2 <- rank_epsilon_squared(""a"", ""c"", data = df), regexp = NA)
+  expect_error(d3 <- rank_epsilon_squared(df$a ~ df$c), regexp = NA)
+  expect_error(d4 <- rank_epsilon_squared(df$a, df$c), regexp = NA)
+  L <- list(df$a[df$c == ""a""], df$a[df$c == ""b""], df$a[df$c == ""c""])
+  expect_error(d5 <- rank_epsilon_squared(L), regexp = NA)
+  expect_equal(d1, d2)
+  expect_equal(d1, d3)
+  expect_equal(d1, d4)
+  expect_equal(d1, d5)
+
+  expect_error(rank_epsilon_squared(b ~ e, data = df), regexp = NA)
+
+  expect_equal(
+    rank_epsilon_squared(exp(a) ~ c, data = df),
+    rank_epsilon_squared(""exp_a"", ""c"", data = df)
+  )
+
+  expect_error(rank_epsilon_squared(""c"", ""c"", data = df), ""non-numeric"")
+  expect_error(rank_epsilon_squared(""a"", ""aa"", data = df), ""missing"")
+
+  df[1, ] <- NA
+  expect_warning(E1 <- rank_epsilon_squared(a ~ c, data = df, ci = NULL), ""dropped"")
+  expect_equal(E1, rank_epsilon_squared(df$a[-1], df$c[-1], ci = NULL))
+})
+
+
+test_that("".get_data_multi_group | subset"", {
+  d <- expand.grid(id = 1:30, g = 1:4)
+  d$y <- rnorm(nrow(d)) + d$g
+  expect_equal(
+    rank_epsilon_squared(y ~ g, data = d, subset = g < 4, ci = NULL),
+    rank_epsilon_squared(y ~ g, data = subset(d, g < 4), ci = NULL)
+  )
+})
+
+test_that("".get_data_nested_groups"", {
+  skip_if_not_installed(""base"", minimum_version = ""3.6.1"")
+  M1 <- cbind(
+    ""Round Out"" = c(5.4, 5.85, 5.2),
+    ""Narrow Angle"" = c(5.5, 5.7, 5.6),
+    ""Wide Angle"" = c(5.55, 5.75, 5.5)
+  )
+
+  M2 <- data.frame(
+    id = c(1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 3L),
+    name = c(
+      ""Round Out"", ""Narrow Angle"", ""Wide Angle"",
+      ""Round Out"", ""Narrow Angle"", ""Wide Angle"",
+      ""Round Out"", ""Narrow Angle"", ""Wide Angle""
+    ),
+    value = c(5.4, 5.5, 5.55, 5.85, 5.7, 5.75, 5.2, 5.6, 5.5)
+  )
+
+  set.seed(1)
+  W1 <- kendalls_w(M1, ci = NULL)
+  W2 <- kendalls_w(value ~ name | id, data = M2, ci = NULL)
+  W3 <- kendalls_w(M2$value, M2$name, M2$id, ci = NULL)
+  W4 <- kendalls_w(M2$value ~ M2$name | M2$id, ci = NULL)
+
+  expect_equal(W1, W2)
+  expect_equal(W1, W3)
+  expect_equal(W1, W4)
+})
+
+test_that("".get_data_nested_groups | subset"", {
+  d <- expand.grid(id = 1:30, g = 1:4)
+  d$y <- rnorm(nrow(d)) + d$g
+
+  expect_equal(
+    kendalls_w(y ~ g | id, data = d, subset = g < 4, ci = NULL),
+    kendalls_w(y ~ g | id, data = subset(d, g < 4), ci = NULL)
+  )
+})

---FILE: tests/testthat/test-xtab.R---
@@ -177,44 +177,3 @@ test_that(""oddsratio & riskratio"", {
     ignore_attr = TRUE
   )
 })
-
-
-test_that(""Cohen's g"", {
-  # From mcnemar.test
-  Performance <-
-    matrix(c(794, 86, 150, 570),
-      nrow = 2,
-      dimnames = list(
-        ""1st Survey"" = c(""Approve"", ""Disapprove""),
-        ""2nd Survey"" = c(""Approve"", ""Disapprove"")
-      )
-    )
-  g <- cohens_g(Performance)
-  expect_equal(g$Cohens_g, 0.136, tolerance = 0.01)
-  expect_equal(g$CI_low, 0.072, tolerance = 0.01)
-  expect_equal(g$CI_high, 0.194, tolerance = 0.01)
-
-
-  AndersonRainBarrel <- matrix(c(
-    9L, 17L,
-    5L, 15L
-  ), nrow = 2)
-  g <- cohens_g(AndersonRainBarrel)
-  expect_equal(g$Cohens_g, 0.273, tolerance = 0.01)
-  expect_equal(g$CI_low, 0.066, tolerance = 0.01)
-  expect_equal(g$CI_high, 0.399, tolerance = 0.01)
-
-
-  M <- matrix(
-    c(
-      794, 86, 150,
-      570, 794, 86,
-      150, 570, 15
-    ),
-    nrow = 3
-  )
-  g <- cohens_g(M)
-  expect_equal(g$Cohens_g, 0.300, tolerance = 0.01)
-  expect_equal(g$CI_low, 0.280, tolerance = 0.01)
-  expect_equal(g$CI_high, 0.319, tolerance = 0.01)
-})

---FILE: vignettes/effectsize_API.Rmd---
@@ -8,7 +8,7 @@ output:
 tags: [r, effect size, ANOVA, standardization, standardized coefficients]
 vignette: >
   \usepackage[utf8]{inputenc}
-  %\VignetteIndexEntry{Support functions for model extensions}
+  %\VignetteIndexEntry{Support Functions for Model Extensions}
   %\VignetteEngine{knitr::rmarkdown}
 editor_options: 
   chunk_output_type: console",True,True,Documentation / Formatting,6
easystats,effectsize,00f1dbf43c8cabbfc2070f99c38b8643a1b89a44,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-10-03T03:30:33Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-10-03T03:30:33Z,fix passing of args,R/effectsize.BFBayesFactor.R;R/xtab_corr.R;R/xtab_diff.R;man/effectsize.Rd,False,True,True,False,16,17,33,"---FILE: R/effectsize.BFBayesFactor.R---
@@ -3,7 +3,7 @@
 #' @inheritParams bayestestR::describe_posterior
 #' @importFrom insight get_data get_parameters check_if_installed
 #' @importFrom bayestestR describe_posterior
-effectsize.BFBayesFactor <- function(model, type = NULL, verbose = TRUE, test = NULL, ...) {
+effectsize.BFBayesFactor <- function(model, type = NULL, ci = 0.95, test = NULL, verbose = TRUE, ...) {
   insight::check_if_installed(""BayesFactor"")
 
   if (length(model) > 1) {
@@ -26,7 +26,7 @@ effectsize.BFBayesFactor <- function(model, type = NULL, verbose = TRUE, test =
   }
 
   # Clean up
-  out <- bayestestR::describe_posterior(pars$res, test = test, ...)
+  out <- bayestestR::describe_posterior(pars$res, ci = ci, test = test, ...)
   if (isTRUE(type == ""cles"")) {
     colnames(out)[2] <- ""Coefficient""
   } else {
@@ -45,7 +45,7 @@ effectsize.BFBayesFactor <- function(model, type = NULL, verbose = TRUE, test =
 }
 
 #' @keywords internal
-.effectsize_contingencyTableBF <- function(model, type = NULL, verbose = TRUE, ...) {
+.effectsize_contingencyTableBF <- function(model, type = NULL, verbose = TRUE, adjust = TRUE, ...) {
   if (is.null(type)) type <- ""cramers_v""
 
   f <- switch(tolower(type),
@@ -74,7 +74,7 @@ effectsize.BFBayesFactor <- function(model, type = NULL, verbose = TRUE, test =
   })
 
   res <- data.frame(ES)
-  colnames(res) <- colnames(f(data, ci = NULL, ...))
+  colnames(res) <- colnames(f(data, ci = NULL, adjust = TRUE))
 
   list(
     res = res,

---FILE: R/xtab_corr.R---
@@ -109,7 +109,7 @@ phi <- function(x, y = NULL,
   alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
 
   if (.is_BF_of_type(x, ""BFcontingencyTable"", ""Chi-squared"")) {
-    return(effectsize(x, type = ""phi"", adjust = adjust, ci = ci, ...))
+    return(effectsize(x, type = ""phi"", adjust = adjust, ci = ci))
   } else if (!.is_htest_of_type(x, ""Pearson's Chi-squared"", ""Chi-squared-test"")) {
     x <- suppressWarnings(stats::chisq.test(x, y))
     x$data.name <- NULL
@@ -128,7 +128,7 @@ cramers_v <- function(x, y = NULL,
   alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
 
   if (.is_BF_of_type(x, ""BFcontingencyTable"", ""Chi-squared"")) {
-    return(effectsize(x, type = ""cramers_v"", adjust = adjust, ci = ci, ...))
+    return(effectsize(x, type = ""cramers_v"", adjust = adjust, ci = ci))
   } else if (!.is_htest_of_type(x, ""Pearson's Chi-squared"", ""Chi-squared-test"")) {
     x <- suppressWarnings(stats::chisq.test(x, y))
     x$data.name <- NULL
@@ -147,7 +147,7 @@ tschuprows_t <- function(x, y = NULL,
   alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
 
   if (.is_BF_of_type(x, ""BFcontingencyTable"", ""Chi-squared"")) {
-    return(effectsize(x, type = ""tschuprows_t"", ci = ci, ...))
+    return(effectsize(x, type = ""tschuprows_t"", ci = ci))
   } else if (!.is_htest_of_type(x, ""Pearson's Chi-squared"", ""Chi-squared-test"")) {
     x <- suppressWarnings(stats::chisq.test(x, y))
     x$data.name <- NULL
@@ -165,7 +165,7 @@ cohens_w <- function(x, y = NULL, p = rep(1 / length(x), length(x)),
   alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
 
   if (.is_BF_of_type(x, ""BFcontingencyTable"", ""Chi-squared"")) {
-    return(effectsize(x, type = ""phi"", ci = ci, ...))
+    return(effectsize(x, type = ""cohens_w"", ci = ci))
   } else if (!.is_htest_of_type(
     x, ""(Pearson's Chi-squared|Chi-squared test for given probabilities)"",
     ""Chi-squared-test""
@@ -205,7 +205,7 @@ pearsons_c <- function(x, y = NULL, p = rep(1 / length(x), length(x)),
   alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
 
   if (.is_BF_of_type(x, ""BFcontingencyTable"", ""Chi-squared"")) {
-    return(effectsize(x, type = ""pearsons_c"", ci = ci, ...))
+    return(effectsize(x, type = ""pearsons_c"", ci = ci))
   } else if (!.is_htest_of_type(
     x, ""(Pearson's Chi-squared|Chi-squared test for given probabilities)"",
     ""Chi-squared-test""

---FILE: R/xtab_diff.R---
@@ -57,13 +57,9 @@ oddsratio <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = F
   alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
 
   if (.is_htest_of_type(x, ""(Pearson's Chi-squared|Fisher's Exact)"", ""Chi-squared-test or Fisher's Exact test"")) {
-    if (grepl(""Fisher's Exact"", x$method)) {
-      return(effectsize(x, alternative = alternative, ...))
-    } else {
-      return(effectsize(x, type = ""or"", log = log, ci = ci, alternative = alternative))
-    }
+    return(effectsize(x, type = ""or"", log = log, ci = ci, alternative = alternative))
   } else if (.is_BF_of_type(x, ""BFcontingencyTable"", ""Chi-squared"")) {
-    return(effectsize(x, type = ""or"", log = log, ci = ci, ...))
+    return(effectsize(x, type = ""or"", log = log, ci = ci))
   }
 
   res <- suppressWarnings(stats::chisq.test(x, y))

---FILE: man/effectsize.Rd---
@@ -8,7 +8,7 @@
 \alias{effectsize.htest}
 \title{Effect Sizes}
 \usage{
-\method{effectsize}{BFBayesFactor}(model, type = NULL, verbose = TRUE, test = NULL, ...)
+\method{effectsize}{BFBayesFactor}(model, type = NULL, ci = 0.95, test = NULL, verbose = TRUE, ...)
 
 effectsize(model, ...)
 
@@ -21,7 +21,8 @@ effectsize(model, ...)
 
 \item{type}{The effect size of interest. See details.}
 
-\item{verbose}{Toggle warnings and messages on or off.}
+\item{ci}{Value or vector of probability of the CI (between 0 and 1)
+to be estimated. Default to \code{.95} (\verb{95\%}).}
 
 \item{test}{The indices of effect existence to compute. Character (vector) or
 list with one or more of these options: \code{""p_direction""} (or \code{""pd""}),
@@ -31,6 +32,8 @@ For each ""test"", the corresponding \pkg{bayestestR} function is called
 (e.g. \code{\link[bayestestR:rope]{rope()}} or \code{\link[bayestestR:p_direction]{p_direction()}}) and its results
 included in the summary output.}
 
+\item{verbose}{Toggle warnings and messages on or off.}
+
 \item{...}{Arguments passed to or from other methods. See details.}
 }
 \value{",True,False,Documentation / Formatting,6
easystats,effectsize,00081d8bccb0e6156992234a918a2926635b92cb,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-09-30T15:59:08Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-09-30T15:59:08Z,fix tests,tests/testthat/test-convert_statistic.R;tests/testthat/test-effectsize.R,False,True,True,False,9,5,14,"---FILE: tests/testthat/test-convert_statistic.R---
@@ -1,3 +1,5 @@
+# library(testthat)
+
 test_that(""xtab"", {
   xtab <- as.table(rbind(
     c(762, 327, 468),
@@ -12,7 +14,7 @@ test_that(""xtab"", {
     nrow = nrow(xtab),
     ncol = ncol(xtab)
   )
-  expect_equal(res, cramers_v(xtab, adjust = FALSE), ignore_attr = TRUE)
+  expect_equal(res, cramers_v(xtab), ignore_attr = TRUE)
 
 
   res <- chisq_to_cohens_w(
@@ -94,3 +96,4 @@ test_that(""eta2"", {
   expect_equal(F_to_f(4, 3, 123), F_to_f2(4, 3, 123, squared = FALSE))
   expect_equal(F_to_f2(4, 3, 123), F_to_f(4, 3, 123, squared = TRUE))
 })
+

---FILE: tests/testthat/test-effectsize.R---
@@ -1,3 +1,4 @@
+# library(testthat)
 # htest -------------------------------------------------------------------
 test_that(""t-test"", {
   x <<- 1:10
@@ -53,15 +54,15 @@ test_that(""Chisq-test"", {
   Xsq1 <- chisq.test(contingency_table)
   Xsq2 <- chisq.test(contingency_table / 10)
 
-  expect_equal(effectsize(Xsq1)$Cramers_v, 0.073, tolerance = 0.01)
+  expect_equal(effectsize(Xsq1, adjust = FALSE)[[1]], 0.073, tolerance = 0.01)
   expect_equal(
-    effectsize(Xsq1)$Cramers_v,
-    effectsize(Xsq2)$Cramers_v
+    effectsize(Xsq1, adjust = FALSE)[[1]],
+    effectsize(Xsq2, adjust = FALSE)[[1]]
   )
 
   # types
   expect_error(effectsize(Xsq1, type = ""phi""), ""appropriate"")
-  expect_equal(effectsize(Xsq1), cramers_v(contingency_table, adjust = FALSE))
+  expect_equal(effectsize(Xsq1), cramers_v(contingency_table))
   expect_equal(effectsize(Xsq1, type = ""w""), w <- cohens_w(contingency_table))
   expect_equal(cohens_w(Xsq1), w)
 ",True,False,Dependency / Package,3
easystats,effectsize,bf1397ee8458a9cbddf4bfadf5ad1fd2385a4c23,Indrajeet Patil,patilindrajeet.science@gmail.com,2022-09-30T10:33:57Z,Indrajeet Patil,patilindrajeet.science@gmail.com,2022-09-30T10:33:57Z,"Apply small sample bias correction by default

For `phi()` and `cramers_v()`

Closes #505",NEWS.md;R/convert_stat_chisq.R;R/xtab_corr.R;man/convert_chisq.Rd;man/mahalanobis_D.Rd;man/phi.Rd;tests/testthat/test-convert_statistic.R;tests/testthat/test-effectsize.R;tests/testthat/test-xtab.R,False,True,True,False,31,185,216,"---FILE: NEWS.md---
@@ -8,8 +8,12 @@
 - `normalized_chi()` has been renamed `fei()`.
 - `cles`, `d_to_cles` and `rb_to_cles` are deprecated in favor of their respective effect size functions.
 
-## New features
+## Changes to defaults
+
+- Small sample bias correction is applied by default for `phi()` and `cramers_v()`. 
+  To restore previous behaviour, set `adjust = FALSE`.
 
+## New features
 
 - Set `options(es.use_symbols = TRUE)` to print proper symbols instead of transliterated effect size names. (On Windows, requires `R >= 4.2.0`)
 - `tschuprows_t()` and `chisq_to_tschuprows_t()` for computing Tschuprow's *T* - a relative of Cramer's *V*.

---FILE: R/convert_stat_chisq.R---
@@ -17,8 +17,8 @@
 #'   (one-sided CI), or `""two.sided""` (default, two-sided CI). Partial matching
 #'   is allowed (e.g., `""g""`, `""l""`, `""two""`...). See *One-Sided CIs* in
 #'   [effectsize_CIs].
-#' @param adjust Should the effect size be bias-corrected? Defaults to `FALSE`;
-#'   For small samples and large tables, it is advisable to set to `TRUE`.
+#' @param adjust Should the effect size be bias-corrected? Defaults to `TRUE`;
+#'   For small samples and large tables, it is advisable to keep it `TRUE`.
 #' @param ... Arguments passed to or from other methods.
 #'
 #' @return A data frame with the effect size(s), and confidence interval(s). See

---FILE: R/xtab_corr.R---
@@ -112,7 +112,7 @@
 #' @importFrom stats chisq.test
 #' @export
 phi <- function(x, y = NULL,
-                adjust = FALSE,
+                adjust = TRUE,
                 ci = 0.95, alternative = ""greater"",
                 ...) {
   alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
@@ -131,7 +131,7 @@ phi <- function(x, y = NULL,
 #' @importFrom stats chisq.test
 #' @export
 cramers_v <- function(x, y = NULL,
-                      adjust = FALSE,
+                      adjust = TRUE,
                       ci = 0.95, alternative = ""greater"",
                       ...) {
   alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))

---FILE: man/convert_chisq.Rd---
@@ -74,8 +74,8 @@ phi_to_chisq(phi, n, ...)
 
 \item{nrow, ncol}{The number of rows/columns in the contingency table.}
 
-\item{adjust}{Should the effect size be bias-corrected? Defaults to \code{FALSE};
-For small samples and large tables, it is advisable to set to \code{TRUE}.}
+\item{adjust}{Should the effect size be bias-corrected? Defaults to \code{TRUE};
+For small samples and large tables, it is advisable to keep it \code{TRUE}.}
 
 \item{ci}{Confidence Interval (CI) level}
 

---FILE: man/mahalanobis_D.Rd---
@@ -1,158 +0,0 @@
-% Generated by roxygen2: do not edit by hand
-% Please edit documentation in R/mahalanobis_D.R
-\name{mahalanobis_d}
-\alias{mahalanobis_d}
-\title{Mahalanobis' \emph{D} (a multivariate Cohen's \emph{d})}
-\usage{
-mahalanobis_d(
-  x,
-  y = NULL,
-  data = NULL,
-  pooled_cov = TRUE,
-  mu = 0,
-  ci = 0.95,
-  alternative = ""two.sided"",
-  verbose = TRUE,
-  ...
-)
-}
-\arguments{
-\item{x, y}{A data frame or matrix. Any incomplete observations (with \code{NA}
-values) are dropped. \code{x} can also be a formula (see details) in which case
-\code{y} is ignored.}
-
-\item{data}{An optional data frame containing the variables.}
-
-\item{pooled_cov}{Should equal covariance be assumed? Currently only
-\code{pooled_cov = TRUE} is supported.}
-
-\item{mu}{A named list/vector of the true difference in means for each
-variable. Can also be a vector of length 1, which will be recycled.}
-
-\item{ci}{Confidence Interval (CI) level}
-
-\item{alternative}{a character string specifying the alternative hypothesis;
-Controls the type of CI returned: \code{""two.sided""} (default, two-sided CI),
-\code{""greater""} or \code{""less""} (one-sided CI). Partial matching is allowed (e.g.,
-\code{""g""}, \code{""l""}, \code{""two""}...). See \emph{One-Sided CIs} in \link{effectsize_CIs}.}
-
-\item{verbose}{Toggle warnings and messages on or off.}
-
-\item{...}{Not used.}
-}
-\value{
-A data frame with the \code{Mahalanobis_D} and potentially its CI
-(\code{CI_low} and \code{CI_high}).
-}
-\description{
-Compute effect size indices for standardized difference between two normal
-multivariate distributions or between one multivariate distribution and a
-defined point. This is the standardized effect size for Hotelling's \eqn{T^2}
-test (e.g., \code{DescTools::HotellingsT2Test()}). \emph{D} is computed as:
-\cr\cr
-\deqn{D = \sqrt{(\bar{X}_1-\bar{X}_2-\mu)^T \Sigma_p^{-1} (\bar{X}_1-\bar{X}_2-\mu)}}
-\cr\cr
-Where \eqn{\bar{X}_i} are the column means, \eqn{\Sigma_p} is the \emph{pooled}
-covariance matrix, and \eqn{\mu} is a vector of the null differences for each
-variable. When there is only one variate, this formula reduces to Cohen's
-\emph{d}.
-}
-\details{
-To specify a \code{x} as a formula:
-\itemize{
-\item Two sample case: \code{DV1 + DV2 ~ group} or \code{cbind(DV1, DV2) ~ group}
-\item One sample case: \code{DV1 + DV2 ~ 1} or \code{cbind(DV1, DV2) ~ 1}
-}
-}
-\section{Confidence (Compatibility) Intervals (CIs)}{
-Unless stated otherwise, confidence (compatibility) intervals (CIs) are
-estimated using the noncentrality parameter method (also called the ""pivot
-method""). This method finds the noncentrality parameter (""\emph{ncp}"") of a
-noncentral \emph{t}, \emph{F}, or \eqn{\chi^2} distribution that places the observed
-\emph{t}, \emph{F}, or \eqn{\chi^2} test statistic at the desired probability point of
-the distribution. For example, if the observed \emph{t} statistic is 2.0, with 50
-degrees of freedom, for which cumulative noncentral \emph{t} distribution is \emph{t} =
-2.0 the .025 quantile (answer: the noncentral \emph{t} distribution with \emph{ncp} =
-.04)? After estimating these confidence bounds on the \emph{ncp}, they are
-converted into the effect size metric to obtain a confidence interval for the
-effect size (Steiger, 2004).
-\cr\cr
-For additional details on estimation and troubleshooting, see \link{effectsize_CIs}.
-}
-
-\section{CIs and Significance Tests}{
-""Confidence intervals on measures of effect size convey all the information
-in a hypothesis test, and more."" (Steiger, 2004). Confidence (compatibility)
-intervals and p values are complementary summaries of parameter uncertainty
-given the observed data. A dichotomous hypothesis test could be performed
-with either a CI or a p value. The 100 (1 - \eqn{\alpha})\% confidence
-interval contains all of the parameter values for which \emph{p} > \eqn{\alpha}
-for the current data and model. For example, a 95\% confidence interval
-contains all of the values for which p > .05.
-\cr\cr
-Note that a confidence interval including 0 \emph{does not} indicate that the null
-(no effect) is true. Rather, it suggests that the observed data together with
-the model and its assumptions combined do not provided clear evidence against
-a parameter value of 0 (same as with any other value in the interval), with
-the level of this evidence defined by the chosen \eqn{\alpha} level (Rafi &
-Greenland, 2020; Schweder & Hjort, 2016; Xie & Singh, 2013). To infer no
-effect, additional judgments about what parameter values are ""close enough""
-to 0 to be negligible are needed (""equivalence testing""; Bauer & Kiesser,
-1996).
-}
-
-\examples{
-## Two samples --------------
-mtcars_am0 <- subset(mtcars, am == 0,
-                     select = c(mpg, hp, cyl))
-mtcars_am1 <- subset(mtcars, am == 1,
-                     select = c(mpg, hp, cyl))
-
-mahalanobis_d(mtcars_am0, mtcars_am1)
-
-# Or
-mahalanobis_d(mpg + hp + cyl ~ am, data = mtcars)
-
-mahalanobis_d(mpg + hp + cyl ~ am, data = mtcars, alternative = ""greater"")
-
-# Different mu:
-mahalanobis_d(mpg + hp + cyl ~ am, data = mtcars,
-              mu = c(mpg = -4, hp = 15, cyl = 0))
-
-
-# D is a multivariate d, so when only 1 variate is provided:
-mahalanobis_d(hp ~ am, data = mtcars)
-
-cohens_d(hp ~ am, data = mtcars)
-
-
-# One sample ---------------------------
-mahalanobis_d(mtcars[,c(""mpg"", ""hp"", ""cyl"")])
-
-# Or
-mahalanobis_d(mpg + hp + cyl ~ 1, data = mtcars,
-              mu = c(mpg = 15, hp = 5, cyl = 3))
-
-}
-\references{
-\itemize{
-\item Del Giudice, M. (2017). Heterogeneity coefficients for Mahalanobis' D as a multivariate effect size. Multivariate Behavioral Research, 52(2), 216-221.
-\item Mahalanobis, P. C. (1936). On the generalized distance in statistics. National Institute of Science of India.
-\item Reiser, B. (2001). Confidence intervals for the Mahalanobis distance. Communications in Statistics-Simulation and Computation, 30(1), 37-45.
-}
-}
-\seealso{
-\code{\link[=cohens_d]{cohens_d()}}, \code{\link[=cov_pooled]{cov_pooled()}}, \code{\link[stats:mahalanobis]{stats::mahalanobis()}}
-
-Other effect size indices: 
-\code{\link{cohens_d}()},
-\code{\link{cohens_g}()},
-\code{\link{effectsize.BFBayesFactor}()},
-\code{\link{eta_squared}()},
-\code{\link{oddsratio}()},
-\code{\link{p_superiority}()},
-\code{\link{phi}()},
-\code{\link{rank_biserial}()},
-\code{\link{rank_epsilon_squared}()}
-}
-\concept{effect size indices}

---FILE: man/phi.Rd---
@@ -9,9 +9,9 @@
 \alias{pearsons_c}
 \title{\eqn{\phi} and Other Contingency Tables Correlations}
 \usage{
-phi(x, y = NULL, adjust = FALSE, ci = 0.95, alternative = ""greater"", ...)
+phi(x, y = NULL, adjust = TRUE, ci = 0.95, alternative = ""greater"", ...)
 
-cramers_v(x, y = NULL, adjust = FALSE, ci = 0.95, alternative = ""greater"", ...)
+cramers_v(x, y = NULL, adjust = TRUE, ci = 0.95, alternative = ""greater"", ...)
 
 tschuprows_t(x, y = NULL, ci = 0.95, alternative = ""greater"", ...)
 
@@ -48,8 +48,8 @@ pearsons_c(
 \item{y}{a numeric vector; ignored if \code{x} is a matrix.  If
     \code{x} is a factor, \code{y} should be a factor of the same length.}
 
-\item{adjust}{Should the effect size be bias-corrected? Defaults to \code{FALSE};
-For small samples and large tables, it is advisable to set to \code{TRUE}.}
+\item{adjust}{Should the effect size be bias-corrected? Defaults to \code{TRUE};
+For small samples and large tables, it is advisable to keep it \code{TRUE}.}
 
 \item{ci}{Confidence Interval (CI) level}
 

---FILE: tests/testthat/test-convert_statistic.R---
@@ -12,7 +12,7 @@ test_that(""xtab"", {
     nrow = nrow(xtab),
     ncol = ncol(xtab)
   )
-  expect_equal(res, cramers_v(xtab), ignore_attr = TRUE)
+  expect_equal(res, cramers_v(xtab, adjust = FALSE), ignore_attr = TRUE)
 
 
   res <- chisq_to_cohens_w(

---FILE: tests/testthat/test-effectsize.R---
@@ -61,7 +61,7 @@ test_that(""Chisq-test"", {
 
   # types
   expect_error(effectsize(Xsq1, type = ""phi""), ""appropriate"")
-  expect_equal(effectsize(Xsq1), cramers_v(contingency_table))
+  expect_equal(effectsize(Xsq1), cramers_v(contingency_table, adjust = FALSE))
   expect_equal(effectsize(Xsq1, type = ""w""), w <- cohens_w(contingency_table))
   expect_equal(cohens_w(Xsq1), w)
 
@@ -70,8 +70,8 @@ test_that(""Chisq-test"", {
 
   contingency_table22 <- contingency_table[1:2, 1:2]
   Xsq4 <- chisq.test(contingency_table22)
-  expect_equal(effectsize(Xsq4, type = ""phi""), ph <- phi(contingency_table22))
-  expect_equal(phi(Xsq4), ph)
+  expect_equal(effectsize(Xsq4, type = ""phi"", adjust = FALSE), ph <- phi(contingency_table22, adjust = FALSE))
+  expect_equal(phi(Xsq4, adjust = FALSE), ph)
 
   expect_equal(effectsize(Xsq4, type = ""oddsratio""), or <- oddsratio(contingency_table22))
   expect_equal(oddsratio(Xsq4), or)
@@ -225,7 +225,7 @@ test_that(""BayesFactor"", {
   set.seed(6)
   data(raceDolls, package = ""BayesFactor"")
   bf1 <- BayesFactor::contingencyTableBF(raceDolls, sampleType = ""poisson"", fixedMargin = ""cols"")
-  expect_equal(effectsize(bf1)[[1]], 0.164, tolerance = 0.01)
+  expect_equal(effectsize(bf1)[[1]], 0.143, tolerance = 0.01)
   expect_equal(effectsize(bf1, type = ""OR"")[[1]], 1 / 0.503, tolerance = 0.03)
 
   bf2 <- BayesFactor::ttestBF(mtcars$mpg[mtcars$am == 1], mtcars$mpg[mtcars$am == 0])

---FILE: tests/testthat/test-xtab.R---
@@ -5,7 +5,7 @@ test_that(""contingency table"", {
     c(484, 239, 477),
     c(484, 239, 477)
   ))
-  res <- cramers_v(contingency_table)
+  res <- cramers_v(contingency_table, adjust = FALSE)
 
   expect_equal(res$Cramers_v, 0.072, tolerance = 0.01)
   expect_equal(res$CI_low, 0.051, tolerance = 0.01)
@@ -22,22 +22,22 @@ test_that(""contingency table"", {
     c(480, 240, 480)
   )
 
-  cv1 <- cramers_v(xtab)
-  cv2 <- cramers_v(xtab / 2)
+  cv1 <- cramers_v(xtab, adjust = FALSE)
+  cv2 <- cramers_v(xtab / 2, adjust = FALSE)
 
   expect_equal(cv1$Cramers_v, cv2$Cramers_v)
 
   # Upper bound of phi is the ratio between phi / V and sqrt(min(K,L)-1)
   expect_equal(cohens_w(xtab, alternative = ""greater"")$CI_high, sqrt(2))
-  expect_equal(cohens_w(xtab)[[1]] / cramers_v(xtab)[[1]], sqrt(2))
+  expect_equal(cohens_w(xtab)[[1]] / cramers_v(xtab, adjust = FALSE)[[1]], sqrt(2))
 
   # Tschuprows_t with non-square tables
   xtab <- rbind(
     c(9, 0, 1),
     c(0, 1, 0)
   )
-  expect_equal(cramers_v(xtab)[[1]], 1)
-  expect_true(tschuprows_t(xtab)[[1]] < cramers_v(xtab)[[1]])
+  expect_equal(cramers_v(xtab, adjust = FALSE)[[1]], 1)
+  expect_true(tschuprows_t(xtab)[[1]] < cramers_v(xtab, adjust = FALSE)[[1]])
 
 
   ## 2*2 tables return phi and cramers_v
@@ -47,8 +47,8 @@ test_that(""contingency table"", {
   )
 
   expect_equal(
-    cramers_v(xtab)[[1]],
-    phi(xtab)[[1]]
+    cramers_v(xtab, adjust = FALSE)[[1]],
+    phi(xtab, adjust = FALSE)[[1]]
   )
 
   res <- pearsons_c(xtab)
@@ -60,7 +60,7 @@ test_that(""contingency table"", {
     c(100, 0),
     c(0, 200)
   )
-  expect_equal(V <- cramers_v(xtab)[[1]], 1)
+  expect_equal(V <- cramers_v(xtab, adjust = FALSE)[[1]], 1)
   expect_true(pearsons_c(xtab)[[1]] < V) # C is not perfect
 
 
@@ -69,15 +69,15 @@ test_that(""contingency table"", {
     c(50, 50),
     c(100, 100)
   )
-  expect_equal(cramers_v(xtab)$Cramers_v, 0)
+  expect_equal(cramers_v(xtab, adjust = FALSE)$Cramers_v, 0)
 
 
   ## Empty rows/columns
   xtab <- rbind(
     c(50, 50, 0),
     c(100, 100, 0)
   )
-  expect_error(cramers_v(xtab), ""empty"")
+  expect_error(cramers_v(xtab, adjust = FALSE), ""empty"")
 
   ## 0
   xtab <- table(mtcars$am, mtcars$vs)",True,False,Documentation / Formatting,6
easystats,effectsize,70c49026e423401217d420b1c0551a1ee002116c,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2022-09-24T13:34:45Z,GitHub,noreply@github.com,2022-09-24T13:34:45Z,"Better data validation  (#498)

* init

* fix tests

* allow p_sup for one/paired sample

* allow ordered

* fix error with missing paired arg",NEWS.md;R/cohens_d.R;R/common_language.R;R/convert_between_common_language.R;R/effectsize.BFBayesFactor.R;R/interpret.R;R/mahalanobis_D.R;R/pooled.R;R/print.effectsize_table.R;R/rank_ANOVA.R;R/rank_diff.R;R/utils_validate_input_data.R;WIP/paired_d2.R;man/diff_to_cles.Rd;man/interpret.Rd;man/p_superiority.Rd;man/rank_biserial.Rd;man/rank_epsilon_squared.Rd;man/rules.Rd;tests/testthat/test-CLES.R;tests/testthat/test-mahalanobis_D.R;tests/testthat/test-rankES.R;tests/testthat/test-standardized_differences.R,False,True,True,False,207,209,416,"---FILE: NEWS.md---
@@ -10,6 +10,8 @@
 
 ## New features
 
+- Rank based effect sizes now accept ordered (`ordered()`) outcomes.
+- `p_superiority()` now supports paired and one-sample cases.
 - Set `options(es.use_symbols = TRUE)` to print proper symbols instead of transliterated effect size names. (On Windows, requires `R >= 4.2.0`)
 - `tschuprows_t()` and `chisq_to_tschuprows_t()` for computing Tschuprow's *T* - a relative of Cramer's *V*.
 - `vd_a()` and `rb_to_vda()` for Vargha and Delaney's *A* dominance effect size (aliases for `p_superiority(parametric = FALSE)` and `rb_to_p_superiority()`).

---FILE: R/cohens_d.R---
@@ -133,7 +133,7 @@ cohens_d <- function(x, y = NULL, data = NULL,
                      pooled_sd = TRUE, mu = 0, paired = FALSE,
                      ci = 0.95, alternative = ""two.sided"",
                      verbose = TRUE, ...) {
-  var.equal <- eval(match.call()[[""var.equal""]], envir = parent.frame())
+  var.equal <- eval.parent(match.call()[[""var.equal""]])
   if (!is.null(var.equal)) pooled_sd <- var.equal
 
   .effect_size_difference(
@@ -152,7 +152,7 @@ hedges_g <- function(x, y = NULL, data = NULL,
                      pooled_sd = TRUE, mu = 0, paired = FALSE,
                      ci = 0.95, alternative = ""two.sided"",
                      verbose = TRUE, ...) {
-  var.equal <- eval(match.call()[[""var.equal""]], envir = parent.frame())
+  var.equal <- eval.parent(match.call()[[""var.equal""]])
   if (!is.null(var.equal)) pooled_sd <- var.equal
 
   .effect_size_difference(
@@ -184,7 +184,7 @@ glass_delta <- function(x, y = NULL, data = NULL,
 
 
 
-#' @importFrom stats sd na.omit complete.cases
+#' @importFrom stats sd
 #' @keywords internal
 .effect_size_difference <-
   function(x, y = NULL, data = NULL,
@@ -206,9 +206,9 @@ glass_delta <- function(x, y = NULL, data = NULL,
 
 
   alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
-  out <- .get_data_2_samples(x, y, data, verbose, ...)
-  x <- out$x
-  y <- out$y
+  out <- .get_data_2_samples(x, y, data, paired = paired, verbose = verbose, ...)
+  x <- out[[""x""]]
+  y <- out[[""y""]]
 
   if (is.null(y)) {
     if (type == ""delta"") {
@@ -220,10 +220,6 @@ glass_delta <- function(x, y = NULL, data = NULL,
 
   # Compute index
   if (paired) {
-    o <- stats::complete.cases(x, y)
-    x <- x[o]
-    y <- y[o]
-
     d <- mean(x - y)
     n <- length(x)
     s <- stats::sd(x - y)
@@ -234,9 +230,6 @@ glass_delta <- function(x, y = NULL, data = NULL,
 
     pooled_sd <- NULL
   } else {
-    x <- stats::na.omit(x)
-    y <- stats::na.omit(y)
-
     d <- mean(x) - mean(y)
 
     s1 <- stats::sd(x)

---FILE: R/common_language.R---
@@ -17,7 +17,9 @@
 #' terms:
 #' - **Probability of superiority** is the probability that, when sampling an
 #'   observation from each of the groups at random, that the observation from
-#'   the second group will be larger than the sample from the first group.
+#'   the second group will be larger than the sample from the first group. For
+#'   the one-sample (or paired) case, it is the probability that the sample (or
+#'   difference) is larger than *mu*.
 #' - **Cohen's \eqn{U_1}** is the proportion of the total of both distributions
 #'   that does not overlap.
 #' - **Cohen's \eqn{U_2}** is the proportion of one of the groups that exceeds
@@ -69,7 +71,7 @@
 #' common language effect size statistics of McGraw and Wong. Journal of
 #' Educational and Behavioral Statistics, 25(2), 101-132.
 #'
-#' @seealso [d_to_cles] [sd_pooled()]
+#' @seealso [d_to_cles()] [sd_pooled()]
 #' @family effect size indices
 #'
 #' @examples
@@ -89,7 +91,7 @@
 #' @export
 #' @aliases cles
 p_superiority <- function(x, y = NULL, data = NULL,
-                          mu = 0, parametric = TRUE,
+                          mu = 0, paired = FALSE, parametric = TRUE,
                           ci = 0.95, alternative = ""two.sided"",
                           verbose = TRUE, ...) {
   if (inherits(x, ""htest"")) {
@@ -104,16 +106,17 @@ p_superiority <- function(x, y = NULL, data = NULL,
     return(effectsize(x, type = ""p_superiority"", ci = ci, verbose = verbose, ...))
   }
 
-  data <- .get_data_2_samples(x, y, data, verbose, ...)
-  x <- na.omit(data[[""x""]])
-  y <- na.omit(data[[""y""]])
-  if (is.null(y)) stop(""p_superiority only applicable to two sample case."")
+  data <- .get_data_2_samples(x, y, data, paired = paired,
+                              allow_ordered = !parametric,
+                              verbose = verbose, ...)
+  x <- data[[""x""]]
+  y <- data[[""y""]]
 
   if (parametric) {
     d <- cohens_d(
       x = x,
       y = y,
-      paired = FALSE, pooled_sd = TRUE,
+      paired = paired, pooled_sd = TRUE,
       mu = mu,
       ci = ci,
       alternative = alternative,
@@ -125,7 +128,7 @@ p_superiority <- function(x, y = NULL, data = NULL,
     rb <- rank_biserial(
       x = x,
       y = y,
-      paired = FALSE,
+      paired = paired,
       mu = mu,
       ci = ci,
       alternative = alternative,
@@ -155,10 +158,12 @@ cohens_u1 <- function(x, y = NULL, data = NULL,
   }
 
 
-  data <- .get_data_2_samples(x, y, data, verbose, ...)
-  x <- na.omit(data[[""x""]])
-  y <- na.omit(data[[""y""]])
-  if (is.null(y)) stop(""cohens_u3 only applicable to two sample case."")
+  data <- .get_data_2_samples(x, y, data,
+                              allow_ordered = !parametric,
+                              verbose = verbose, ...)
+  x <- data[[""x""]]
+  y <- data[[""y""]]
+  if (is.null(y)) stop(""cohens_u3 only applicable to two sample case."", call. = FALSE)
 
   if (!parametric) {
     stop(""Cohen's U1 only available for parametric estimation."", call. = FALSE)
@@ -199,10 +204,12 @@ cohens_u2 <- function(x, y = NULL, data = NULL,
   }
 
 
-  data <- .get_data_2_samples(x, y, data, verbose, ...)
-  x <- na.omit(data[[""x""]])
-  y <- na.omit(data[[""y""]])
-  if (is.null(y)) stop(""cohens_u3 only applicable to two sample case."")
+  data <- .get_data_2_samples(x, y, data,
+                              allow_ordered = !parametric,
+                              verbose = verbose, ...)
+  x <- data[[""x""]]
+  y <- data[[""y""]]
+  if (is.null(y)) stop(""cohens_u3 only applicable to two sample case."", call. = FALSE)
 
   if (parametric) {
     d <- cohens_d(
@@ -246,10 +253,12 @@ cohens_u3 <- function(x, y = NULL, data = NULL,
   }
 
 
-  data <- .get_data_2_samples(x, y, data, verbose, ...)
-  x <- na.omit(data[[""x""]])
-  y <- na.omit(data[[""y""]])
-  if (is.null(y)) stop(""cohens_u3 only applicable to two sample case."")
+  data <- .get_data_2_samples(x, y, data,
+                              allow_ordered = !parametric,
+                              verbose = verbose, ...)
+  x <- data[[""x""]]
+  y <- data[[""y""]]
+  if (is.null(y)) stop(""cohens_u3 only applicable to two sample case."", call. = FALSE)
 
   if (parametric) {
     d <- cohens_d(
@@ -292,10 +301,12 @@ p_overlap <- function(x, y = NULL, data = NULL,
   }
 
 
-  data <- .get_data_2_samples(x, y, data, verbose, ...)
-  x <- na.omit(data[[""x""]])
-  y <- na.omit(data[[""y""]])
-  if (is.null(y)) stop(""Overlap only applicable to two sample case."")
+  data <- .get_data_2_samples(x, y, data,
+                              allow_ordered = !parametric,
+                              verbose = verbose, ...)
+  x <- data[[""x""]]
+  y <- data[[""y""]]
+  if (is.null(y)) stop(""Overlap only applicable to two sample case."", call. = FALSE)
 
   if (parametric) {
     d <- cohens_d(

---FILE: R/convert_between_common_language.R---
@@ -29,7 +29,7 @@
 #' Vargha and Delaney's *A* is an alias for the non-parametric *probability of
 #' superiority*.
 #'
-#' @seealso See [cohens_u3] for descriptions of the effect sizes (also,
+#' @seealso See [cohens_u3()] for descriptions of the effect sizes (also,
 #'   [cohens_d()], [rank_biserial()]).
 #' @family convert between effect sizes
 #'
@@ -140,7 +140,7 @@ d_to_overlap.numeric <- function(d) {
 
 #' @export
 d_to_p_superiority.effectsize_difference <- function(d) {
-  out <- .cohens_d_to_cles(d, converter = d_to_p_superiority)
+  out <- .cohens_d_to_cles(d, converter = d_to_p_superiority, allow_paired = TRUE)
   colnames(out)[1] <- ""p_superiority""
   out
 }
@@ -224,10 +224,10 @@ d_to_overlap.effectsize_difference <- function(d) {
 ## Main ----------------
 
 #' @keywords internal
-.cohens_d_to_cles <- function(d, converter) {
+.cohens_d_to_cles <- function(d, converter, allow_paired = FALSE) {
   if (!any(colnames(d) %in% c(""Cohens_d"", ""Hedges_g"")) ||
-      attr(d, ""paired"") ||
-      !attr(d, ""pooled_sd"")) {
+      (isTRUE(attr(d, ""paired"")) && !allow_paired) ||
+       (!isTRUE(attr(d, ""paired"")) && !isTRUE(attr(d, ""pooled_sd"")))) {
     stop(""Common language effect size only applicable to 2-sample Cohen's d with pooled SD."", call. = FALSE)
   }
 
@@ -250,9 +250,8 @@ d_to_overlap.effectsize_difference <- function(d) {
 
 #' @export
 rb_to_p_superiority.effectsize_difference <- function(rb) {
-  if (!any(colnames(rb) == ""r_rank_biserial"") ||
-    attr(rb, ""paired"")) {
-    stop(""Common language effect size only applicable to 2-sample rank-biserial correlation."", call. = FALSE)
+  if (!any(colnames(rb) == ""r_rank_biserial"")) {
+    stop(""Common language effect size only applicable rank-biserial correlation."", call. = FALSE)
   }
 
   cols_to_conv <- colnames(rb) %in% c(""r_rank_biserial"", ""CI_low"", ""CI_high"")

---FILE: R/effectsize.BFBayesFactor.R---
@@ -103,7 +103,7 @@ effectsize.BFBayesFactor <- function(model, type = NULL, verbose = TRUE, test =
   if (type == ""d"") {
     xtra_class <- ""effectsize_difference""
   } else if (tolower(type) %in% c(""p_superiority"", ""u1"", ""u2"", ""u3"", ""overlap"")) {
-    if (paired) stop(""CLES only applicable to two independent samples."")
+    if (paired) stop(""CLES only applicable to two independent samples."", call. = FALSE)
 
     converter <- match.fun(paste0(""d_to_"", tolower(type)))
     if (grepl(""^(u|U)"", type)) type <- paste0(""Cohens_"", toupper(type))

---FILE: R/interpret.R---
@@ -17,7 +17,7 @@
 #'
 #'
 #'
-#' @seealso interpret
+#' @seealso [interpret()]
 #'
 #' @examples
 #' rules(c(0.05), c(""significant"", ""not significant""), right = FALSE)
@@ -98,7 +98,7 @@ is.rules <- function(x) inherits(x, ""rules"")
 #' - For numeric input: A character vector of interpretations.
 #' - For data frames: the `x` input with an additional `Interpretation` column.
 #'
-#' @seealso rules
+#' @seealso [rules()]
 #' @examples
 #' rules_grid <- rules(c(0.01, 0.05), c(""very significant"", ""significant"", ""not significant""))
 #' interpret(0.001, rules_grid)

---FILE: R/mahalanobis_D.R---
@@ -85,11 +85,6 @@ mahalanobis_d <- function(x, y = NULL, data = NULL,
   data <- .get_data_multivariate(x, y, data, verbose = verbose)
   x <- data[[""x""]]
   y <- data[[""y""]]
-  if (verbose && (anyNA(x) || anyNA(y))) {
-    warning(""Missing values detected. NAs dropped."", call. = FALSE)
-  }
-  x <- na.omit(x)
-  y <- na.omit(y)
 
 
   # deal with mu

---FILE: R/pooled.R---
@@ -28,9 +28,9 @@
 #' @export
 sd_pooled <- function(x, y = NULL, data = NULL,
                       verbose = TRUE, ...) {
-  data <- .get_data_2_samples(x, y, data, verbose, ...)
-  x <- na.omit(data$x)
-  y <- na.omit(data$y)
+  data <- .get_data_2_samples(x, y, data, verbose = verbose, ...)
+  x <- data[[""x""]]
+  y <- data[[""y""]]
 
   V <- cov_pooled(data.frame(x = x),
                   data.frame(x = y))
@@ -45,9 +45,9 @@ sd_pooled <- function(x, y = NULL, data = NULL,
 mad_pooled <- function(x, y = NULL, data = NULL,
                        constant = 1.4826,
                        verbose = TRUE, ...) {
-  data <- .get_data_2_samples(x, y, data, verbose, ...)
-  x <- na.omit(data$x)
-  y <- na.omit(data$y)
+  data <- .get_data_2_samples(x, y, data, verbose = verbose, ...)
+  x <- data[[""x""]]
+  y <- data[[""y""]]
 
   n1 <- length(x)
   n2 <- length(y)
@@ -66,8 +66,8 @@ mad_pooled <- function(x, y = NULL, data = NULL,
 cov_pooled <- function(x, y = NULL, data = NULL,
                        verbose = TRUE, ...) {
   data <- .get_data_multivariate(x, y, data = data, verbose = verbose)
-  x <- na.omit(data[[""x""]])
-  y <- na.omit(data[[""y""]])
+  x <- data[[""x""]]
+  y <- data[[""y""]]
 
   n1 <- nrow(x)
   n2 <- nrow(y)

---FILE: R/print.effectsize_table.R---
@@ -120,17 +120,9 @@ print.effectsize_difference <- function(x, digits = 2, append_CLES = NULL, ...)
   print.effectsize_table(x, digits = digits, ...)
 
   if (is.logical(append_CLES) || is.character(append_CLES)) {
-    if (isTRUE(attr(x_orig, ""paired""))) {
-      stop(""CLES only applicable to independent samples."")
-    }
-
     if (colnames(x_orig)[1] == ""r_rank_biserial"") {
       cles_tab <- rb_to_p_superiority(x_orig)
     } else if (colnames(x_orig)[1] %in% c(""Cohens_d"", ""Hedges_g"")) {
-      if (!isTRUE(attr(x_orig, ""pooled_sd""))) {
-        stop(""CLES only applicable to pooled-sd Cohen's d / Hedge's g."")
-      }
-
       if (isTRUE(append_CLES)) {
         append_CLES <- c(""p_superiority"", ""u1"", ""u2"", ""u3"", ""overlap"")
       }
@@ -146,7 +138,7 @@ print.effectsize_difference <- function(x, digits = 2, append_CLES = NULL, ...)
       cles_tab <- cles_tab[c(ncol(cles_tab), seq_len(ncol(cles_tab)-1))]
 
     } else {
-      stop(""CLES not applicable for this effect size."")
+      stop(""CLES not applicable for this effect size."", call. = FALSE)
     }
 
     insight::print_color(""\n\n## Common Language Effect Sizes:\n"", .pcl[""subtitle""])

---FILE: R/rank_ANOVA.R---
@@ -7,7 +7,7 @@
 #'
 #' @inheritParams rank_biserial
 #' @param x Can be one of:
-#'   - A numeric vector, or a character name of one in `data`.
+#'   - A numeric or ordered vector, or a character name of one in `data`.
 #'   - A list of vectors (for `rank_eta/epsilon_squared()`).
 #'   - A matrix of `blocks x groups` (for `kendalls_w()`) (or `groups x blocks`
 #'   if `blocks_on_rows = FALSE`). See details for the `blocks` and `groups`
@@ -84,12 +84,11 @@
 #' sport sciences, 1(21), 19-25.
 #'
 #' @export
-#' @importFrom stats na.omit
 #' @importFrom insight check_if_installed
 rank_epsilon_squared <- function(x, groups, data = NULL,
                                  ci = 0.95, alternative = ""greater"",
                                  iterations = 200,
-                                 ...) {
+                                 verbose = TRUE, ...) {
   alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
 
   if (inherits(x, ""htest"")) {
@@ -100,8 +99,9 @@ rank_epsilon_squared <- function(x, groups, data = NULL,
   }
 
   ## pep data
-  data <- .get_data_multi_group(x, groups, data, ...)
-  data <- stats::na.omit(data)
+  data <- .get_data_multi_group(x, groups, data,
+                                allow_ordered = TRUE,
+                                verbose = verbose, ...)
 
   ## compute
   out <- data.frame(rank_epsilon_squared = .repsilon(data))
@@ -132,12 +132,11 @@ rank_epsilon_squared <- function(x, groups, data = NULL,
 
 #' @export
 #' @rdname rank_epsilon_squared
-#' @importFrom stats na.omit
 #' @importFrom insight check_if_installed
 rank_eta_squared <- function(x, groups, data = NULL,
                              ci = 0.95, alternative = ""greater"",
                              iterations = 200,
-                             ...) {
+                             verbose = TRUE, ...) {
   alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
 
   if (inherits(x, ""htest"")) {
@@ -148,8 +147,9 @@ rank_eta_squared <- function(x, groups, data = NULL,
   }
 
   ## pep data
-  data <- .get_data_multi_group(x, groups, data, ...)
-  data <- stats::na.omit(data)
+  data <- .get_data_multi_group(x, groups, data,
+                                allow_ordered = TRUE,
+                                verbose = verbose, ...)
 
   out <- data.frame(rank_eta_squared = .reta(data))
 
@@ -202,8 +202,10 @@ kendalls_w <- function(x, groups, blocks, data = NULL,
 
   ## prep data
   if (is.matrix(x) && !blocks_on_rows) x <- t(x)
-  data <- .get_data_nested_groups(x, groups, blocks, data, ...)
-  data <- stats::na.omit(data)
+  data <- .get_data_nested_groups(x, groups, blocks, data,
+                                  allow_ordered = TRUE,
+                                  verbose = verbose, ...)
+  data <- stats::na.omit(data) # wide data - drop non complete cases
 
   ## compute
   W <- .kendalls_w(data, verbose = verbose)
@@ -232,34 +234,6 @@ kendalls_w <- function(x, groups, blocks, data = NULL,
   return(out)
 }
 
-# rank_eta_squared <- function(x, g, data = NULL, ci = 0.95, iterations = 200) {
-#
-#   data <- .get_data_multi_group(x, g, data)
-#   data <- stats::na.omit(data)
-#   x <- data$x
-#   g <- data$g
-#
-#   model <- stats::kruskal.test(x, g)
-#
-#   H <- unname(model$statistic)
-#   k <- length(unique(g)) # model$parameter + 1
-#   n <- length(g)
-#
-#   E <- (H - k + 1) / (n - k)
-#
-#   out <- data.frame(rank_eta_squared = E)
-#
-#   if (is.numeric(ci)) {
-#     warning(""Nope. Not yet."", call. = FALSE)
-#     out$CI <- ci
-#     out$CI_low <- 0
-#     out$CI_high <- 1
-#   }
-#
-#   class(out) <- c(""effectsize_table"", class(out))
-#   return(out)
-# }
-
 # Utils -------------------------------------------------------------------
 
 ## Get ----

---FILE: R/rank_diff.R---
@@ -7,6 +7,10 @@
 #' [`stats::wilcox.test()`].
 #'
 #' @inheritParams cohens_d
+#' @param x,y A numeric or ordered vector, or a character name of one in `data`.
+#'   Any missing values (`NA`s) are dropped from the resulting vector. `x` can
+#'   also be a formula (see [`stats::wilcox.test()`]), in which case `y` is
+#'   ignored.
 #' @param mu a number indicating the value around which (a-)symmetry (for
 #'   one-sample or paired samples) or shift (for independent samples) is to be
 #'   estimated. See [stats::wilcox.test].
@@ -105,7 +109,6 @@
 #'
 #'
 #' @export
-#' @importFrom stats na.omit complete.cases
 rank_biserial <- function(x, y = NULL, data = NULL,
                           mu = 0, paired = FALSE,
                           ci = 0.95, alternative = ""two.sided"",
@@ -120,7 +123,9 @@ rank_biserial <- function(x, y = NULL, data = NULL,
   }
 
   ## Prep data
-  out <- .get_data_2_samples(x, y, data, verbose, ...)
+  out <- .get_data_2_samples(x, y, data, paired = paired,
+                             allow_ordered = TRUE,
+                             verbose = verbose, ...)
   x <- out$x
   y <- out$y
 
@@ -129,38 +134,13 @@ rank_biserial <- function(x, y = NULL, data = NULL,
     paired <- TRUE
   }
 
-  if (paired) {
-    oo <- stats::complete.cases(x, y)
-    x <- x[oo]
-    y <- y[oo]
-  } else {
-    x <- stats::na.omit(x)
-    y <- stats::na.omit(y)
-  }
-
   ## Compute
   r_rbs <- .r_rbs(x, y, mu = mu, paired = paired, verbose = verbose)
   out <- data.frame(r_rank_biserial = r_rbs)
 
   ## CI
   ci_method <- NULL
   if (is.numeric(ci)) {
-    # if (requireNamespace(""boot"", quietly = TRUE)) {
-    #   out <- cbind(out, .rbs_ci_boot(
-    #     y,
-    #     mu = mu,
-    #     paired = paired,
-    #     ci = ci,
-    #     iterations = iterations
-    #   ))
-    #
-    #   ci_method <- list(method = ""bootstrap"", iterations = iterations)
-    # } else {
-    #   ci <- NULL
-    #   warning(""For CIs, the 'boot' package must be installed."", call. = FALSE)
-    # }
-
-    # Parametric method
     stopifnot(length(ci) == 1, ci < 1, ci > 0)
     out$CI <- ci
     ci.level <- if (alternative == ""two.sided"") ci else 2 * ci - 1
@@ -226,7 +206,9 @@ cliffs_delta <- function(x, y = NULL, data = NULL,
                          ci = 0.95, alternative = ""two.sided"",
                          verbose = TRUE, ...) {
   cl <- match.call()
-  data <- .get_data_2_samples(x, y, data, verbose, ...)
+  data <- .get_data_2_samples(x, y, data, verbose = verbose,
+                              allow_ordered = TRUE,
+                              ...)
   x <- data$x
   y <- data$y
   if (is.null(y) || isTRUE(eval.parent(cl$paired))) {
@@ -268,48 +250,4 @@ cliffs_delta <- function(x, y = NULL, data = NULL,
   u_ <- U1 / S
   f_ <- U2 / S
   return(u_ - f_)
-}
-
-# #' @keywords internal
-# #' @importFrom bayestestR ci
-# .rbs_ci_boot <- function(x,
-#                          y,
-#                          mu = 0,
-#                          paired = FALSE,
-#                          ci = 0.95,
-#                          iterations = 200) {
-#   stopifnot(length(ci) == 1, ci < 1, ci > 0)
-#
-#   if (paired) {
-#     data <- data.frame(x, y)
-#     boot_rbs <- function(.data, .i) {
-#       .data <- .data[.i, ]
-#       .x <- .data$x
-#       .y <- .data$y
-#       .r_rbs(.x, .y, mu = mu, paired = TRUE, verbose = FALSE)
-#     }
-#   } else {
-#     data <- data.frame(
-#       i = seq_along(c(x, y))
-#     )
-#
-#     boot_rbs <- function(.data, .i) {
-#       .x <- sample(x, replace = TRUE)
-#       .y <- sample(y, replace = TRUE)
-#
-#       .r_rbs(.x, .y, mu = mu, paired = FALSE, verbose = FALSE)
-#     }
-#   }
-#
-#   R <- boot::boot(
-#     data = data,
-#     statistic = boot_rbs,
-#     R = iterations
-#   )
-#
-#   out <- as.data.frame(
-#     bayestestR::ci(na.omit(R$t), ci = ci, verbose = FALSE)
-#   )
-#   out$CI <- ci
-#   out
-# }
\ No newline at end of file
+}
\ No newline at end of file

---FILE: R/utils_validate_input_data.R---
@@ -1,6 +1,9 @@
 
 #' @keywords internal
-.get_data_2_samples <- function(x, y = NULL, data = NULL, verbose = TRUE, ...) {
+#' @importFrom stats na.omit complete.cases
+.get_data_2_samples <- function(x, y = NULL, data = NULL,
+                                paired = FALSE, allow_ordered = FALSE,
+                                verbose = TRUE, ...) {
   if (inherits(x, ""formula"")) {
     # Validate:
     if (length(x) != 3L) {
@@ -30,6 +33,18 @@
   }
 
 
+  # If x is ordered and allowed to be...
+  if (allow_ordered && is.ordered(x)) {
+    if (is.ordered(y)) {
+      if (!isTRUE(all.equal(levels(y),levels(x)))) {
+        stop(""x and y are ordered, but do not have the same levels."", call. = FALSE)
+      }
+      y <- as.numeric(y)
+    }
+
+    x <- as.numeric(x)
+  }
+
   # x should be a numeric vector or a Pair:
   if (!is.numeric(x)) {
     stop(""Cannot compute effect size for a non-numeric vector."", call. = FALSE)
@@ -63,13 +78,29 @@
     }
   }
 
+  if (verbose && (anyNA(x) || anyNA(y))) {
+    warning(""Missing values detected. NAs dropped."", call. = FALSE)
+  }
+
+  if (paired && !is.null(y)) {
+    o <- stats::complete.cases(x, y)
+    x <- x[o]
+    y <- y[o]
+  } else {
+    x <- stats::na.omit(x)
+    y <- stats::na.omit(y)
+  }
+
+
   list(x = x, y = y)
 }
 
 
 
 #' @keywords internal
-.get_data_multi_group <- function(x, groups, data = NULL, ...) {
+.get_data_multi_group <- function(x, groups, data = NULL,
+                                  allow_ordered = FALSE,
+                                  verbose = TRUE, ...) {
   if (inherits(x, ""formula"")) {
     if (length(x) != 3) {
       stop(""Formula must have the form of 'outcome ~ group'."", call. = FALSE)
@@ -94,6 +125,9 @@
   }
 
   # x should be a numeric vector or a Pair:
+  if (allow_ordered && is.ordered(x)) {
+    x <- as.numeric(x)
+  }
   if (!is.numeric(x)) {
     stop(""Cannot compute effect size for a non-numeric vector."", call. = FALSE)
   }
@@ -107,12 +141,18 @@
     stop(""groups cannot be numeric."", call. = FALSE)
   }
 
-  data.frame(x, groups)
+  out <- data.frame(x, groups)
+  if (verbose && anyNA(out)) {
+    warning(""Missing values detected. NAs dropped."", call. = FALSE)
+  }
+  stats::na.omit(out)
 }
 
 #' @keywords internal
 #' @importFrom stats reshape
-.get_data_nested_groups <- function(x, groups = NULL, blocks = NULL, data = NULL, wide = TRUE, ...) {
+.get_data_nested_groups <- function(x, groups = NULL, blocks = NULL, data = NULL,
+                                    wide = TRUE, allow_ordered = FALSE,
+                                    verbose = TRUE, ...) {
   if (inherits(x, ""formula"")) {
     if (length(x) != 3L ||
       x[[3L]][[1L]] != as.name(""|"")) {
@@ -151,12 +191,21 @@
 
   colnames(x) <- c(""x"", ""groups"", ""blocks"")
 
+  if (allow_ordered && is.ordered(x$x)) {
+    x$x <- as.numeric(x$x)
+  }
   if (!is.numeric(x$x)) {
     stop(""Cannot compute effect size for a non-numeric vector."", call. = FALSE)
   }
   if (!is.factor(x$groups)) x$groups <- factor(x$groups)
   if (!is.factor(x$blocks)) x$blocks <- factor(x$blocks)
 
+
+  if (verbose && anyNA(x)) {
+    warning(""Missing values detected. NAs dropped."", call. = FALSE)
+  }
+  x <- stats::na.omit(x)
+
   # By this point, the data is in long format
   if (wide) {
     x <- datawizard::data_to_wide(x,
@@ -171,7 +220,8 @@
 
 #' @keywords internal
 #' @importFrom stats na.pass reformulate
-.get_data_multivariate <- function(x, y, data = data, ...) {
+.get_data_multivariate <- function(x, y = NULL, data = NULL,
+                                   verbose = TRUE, ...) {
   if (inherits(x, ""formula"")) {
     if (length(x) != 3L || length(x[[3]]) != 1L) {
       stop(""Formula must have the form of 'DV1 + ... + DVk ~ group', with exactly one term on the RHS."", call. = FALSE)
@@ -227,6 +277,12 @@
     }
   }
 
+  if (verbose && (anyNA(x) || anyNA(y))) {
+    warning(""Missing values detected. NAs dropped."", call. = FALSE)
+  }
+  x <- stats::na.omit(x)
+  y <- stats::na.omit(y)
+
   .nlist(x, y)
 }
 
@@ -235,15 +291,16 @@
 
 
 #' @keywords internal
-#' @importFrom stats model.frame
+#' @importFrom stats model.frame na.pass
 .resolve_formula <- function(formula, data, subset, na.action, ...) {
   cl <- match.call(expand.dots = FALSE)
   cl[[1]] <- quote(stats::model.frame)
   if (""subset"" %in% names(cl)) {
     cl$subset <- substitute(subset)
   }
   cl$... <- NULL
-  eval(cl, envir = parent.frame())
+  cl$na.action <- stats::na.pass
+  eval.parent(cl)
 }
 
 #' @keywords internal

---FILE: WIP/paired_d2.R---
@@ -9,7 +9,6 @@ paired_d <- function(x, group, block, data = NULL,
   if (!is.factor(data$blocks)) data$blocks <- factor(data$blocks)
   contrasts(data$groups) <- contr.treatment
   contrasts(data$blocks) <- contr.treatment
-  data <- na.omit(data)
 
   stopifnot(nlevels(data$groups) == 2L)
 
@@ -198,7 +197,7 @@ paired_d <- function(x, group, block, data = NULL,
     stop(paste(
       ""Covariances should be a "", n, "" by "", n,
       "" matrix""
-    ))
+    ), call. = FALSE)
   }
   syms <- paste(""x"", 1:n, sep = """")
   for (i in 1:n) assign(syms[i], mean[i])

---FILE: man/diff_to_cles.Rd---
@@ -73,7 +73,7 @@ to base rates and other factors. Psychological methods, 13(1), 19â30.
 }
 }
 \seealso{
-See \link{cohens_u3} for descriptions of the effect sizes (also,
+See \code{\link[=cohens_u3]{cohens_u3()}} for descriptions of the effect sizes (also,
 \code{\link[=cohens_d]{cohens_d()}}, \code{\link[=rank_biserial]{rank_biserial()}}).
 
 Other convert between effect sizes: 

---FILE: man/interpret.Rd---
@@ -60,5 +60,5 @@ interpret(oddsratio(X), rules = ""chen2010"")
 interpret(cramers_v(X), ""lovakov2021"")
 }
 \seealso{
-rules
+\code{\link[=rules]{rules()}}
 }

---FILE: man/p_superiority.Rd---
@@ -15,6 +15,7 @@ p_superiority(
   y = NULL,
   data = NULL,
   mu = 0,
+  paired = FALSE,
   parametric = TRUE,
   ci = 0.95,
   alternative = ""two.sided"",
@@ -96,6 +97,10 @@ ignored.}
 \item{mu}{a number indicating the true value of the mean (or
     difference in means if you are performing a two sample test).}
 
+\item{paired}{If \code{TRUE}, the values of \code{x} and \code{y} are considered as paired.
+This produces an effect size that is equivalent to the one-sample effect
+size on \code{x - y}.}
+
 \item{parametric}{Use parametric estimation (see \code{\link[=cohens_d]{cohens_d()}}) or
 non-parametric estimation (see \code{\link[=rank_biserial]{rank_biserial()}}). See details.}
 
@@ -131,7 +136,9 @@ terms:
 \itemize{
 \item \strong{Probability of superiority} is the probability that, when sampling an
 observation from each of the groups at random, that the observation from
-the second group will be larger than the sample from the first group.
+the second group will be larger than the sample from the first group. For
+the one-sample (or paired) case, it is the probability that the sample (or
+difference) is larger than \emph{mu}.
 \item \strong{Cohen's \eqn{U_1}} is the proportion of the total of both distributions
 that does not overlap.
 \item \strong{Cohen's \eqn{U_2}} is the proportion of one of the groups that exceeds
@@ -230,7 +237,7 @@ Educational and Behavioral Statistics, 25(2), 101-132.
 }
 }
 \seealso{
-\link{d_to_cles} \code{\link[=sd_pooled]{sd_pooled()}}
+\code{\link[=d_to_cles]{d_to_cles()}} \code{\link[=sd_pooled]{sd_pooled()}}
 
 Other effect size indices: 
 \code{\link{cohens_d}()},

---FILE: man/rank_biserial.Rd---
@@ -29,9 +29,9 @@ cliffs_delta(
 )
 }
 \arguments{
-\item{x, y}{A numeric vector, or a character name of one in \code{data}.
-Any missing values (\code{NA}s) are dropped from the resulting vector.
-\code{x} can also be a formula (see \code{\link[stats:t.test]{stats::t.test()}}), in which case \code{y} is
+\item{x, y}{A numeric or ordered vector, or a character name of one in \code{data}.
+Any missing values (\code{NA}s) are dropped from the resulting vector. \code{x} can
+also be a formula (see \code{\link[stats:wilcox.test]{stats::wilcox.test()}}), in which case \code{y} is
 ignored.}
 
 \item{data}{An optional data frame containing the variables.}

---FILE: man/rank_epsilon_squared.Rd---
@@ -13,6 +13,7 @@ rank_epsilon_squared(
   ci = 0.95,
   alternative = ""greater"",
   iterations = 200,
+  verbose = TRUE,
   ...
 )
 
@@ -23,6 +24,7 @@ rank_eta_squared(
   ci = 0.95,
   alternative = ""greater"",
   iterations = 200,
+  verbose = TRUE,
   ...
 )
 
@@ -42,7 +44,7 @@ kendalls_w(
 \arguments{
 \item{x}{Can be one of:
 \itemize{
-\item A numeric vector, or a character name of one in \code{data}.
+\item A numeric or ordered vector, or a character name of one in \code{data}.
 \item A list of vectors (for \code{rank_eta/epsilon_squared()}).
 \item A matrix of \verb{blocks x groups} (for \code{kendalls_w()}) (or \verb{groups x blocks}
 if \code{blocks_on_rows = FALSE}). See details for the \code{blocks} and \code{groups}
@@ -71,12 +73,12 @@ Controls the type of CI returned: \code{""two.sided""} (default, two-sided CI),
 \item{iterations}{The number of bootstrap replicates for computing confidence
 intervals. Only applies when \code{ci} is not \code{NULL}.}
 
+\item{verbose}{Toggle warnings and messages on or off.}
+
 \item{...}{Arguments passed to or from other methods. When \code{x} is a formula,
 these can be \code{subset} and \code{na.action}.}
 
 \item{blocks_on_rows}{Are blocks on rows (\code{TRUE}) or columns (\code{FALSE}).}
-
-\item{verbose}{Toggle warnings and messages on or off.}
 }
 \value{
 A data frame with the effect size and its CI.

---FILE: man/rules.Rd---
@@ -34,5 +34,5 @@ rules(c(0.2, 0.5, 0.8), c(""small"", ""medium"", ""large""))
 rules(c(""small"" = 0.2, ""medium"" = 0.5), name = ""Cohen's Rules"")
 }
 \seealso{
-interpret
+\code{\link[=interpret]{interpret()}}
 }

---FILE: tests/testthat/test-CLES.R---
@@ -89,7 +89,7 @@ test_that(""CLES | par vs non-par"", {
 test_that(""CLES | errors"", {
   expect_error(cohens_u1(1:3, 1:4, parametric = FALSE), ""parametric"")
 
-  expect_error(p_superiority(1:3), ""two"")
+  expect_error(p_superiority(1:3), NA)
   expect_error(cohens_u1(1:3), ""two"")
   expect_error(cohens_u2(1:3), ""two"")
   expect_error(cohens_u3(1:3), ""two"")

---FILE: tests/testthat/test-mahalanobis_D.R---
@@ -64,7 +64,8 @@ test_that(""mahalanobis_d | inputs"", {
 
   mtcars$mpg[1] <- NA
   expect_warning(mahalanobis_d(mtcars[,c(""mpg"", ""hp"")]), regexp = ""dropped"")
-  expect_warning(mahalanobis_d(mpg + hp ~ 1, data = mtcars), regexp = ""dropped"")
+  expect_warning(D1 <- mahalanobis_d(mpg + hp ~ 1, data = mtcars), regexp = ""dropped"")
+  expect_equal(D1, mahalanobis_d(mpg + hp ~ 1, data = mtcars[-1,]))
 })
 
 

---FILE: tests/testthat/test-rankES.R---
@@ -32,6 +32,22 @@ test_that(""rank_biserial"", {
 })
 
 
+test_that(""rank_biserial | ordered"", {
+  x <- rep(ordered(1:5), each = 3)
+  x1 <- x[1:5]
+  x2 <- x[6:15]
+
+  expect_equal(rank_biserial(x1, x2),
+               rank_biserial(as.numeric(x1), as.numeric(x2)))
+
+
+  x1 <- ordered(as.numeric(x1))
+  x2 <- ordered(as.numeric(x2))
+  expect_error(rank_biserial(x1, x2), ""levels"")
+
+})
+
+
 test_that(""rank_epsilon_squared"", {
   skip_if_not_installed(""boot"")
   skip_if_not_installed(""base"", minimum_version = ""3.6.1"")
@@ -52,6 +68,10 @@ test_that(""rank_epsilon_squared"", {
     rank_epsilon_squared(x ~ g, ci = NULL),
     rank_epsilon_squared(x, g, ci = NULL)
   )
+
+  g[1] <- NA
+  expect_warning(E1 <- rank_epsilon_squared(x, g, ci = NULL), ""dropped"")
+  expect_equal(E1, rank_epsilon_squared(x[-1], g[-1], ci = NULL))
 })
 
 
@@ -132,4 +152,9 @@ test_that(""kendalls_w"", {
   expect_warning(W <- kendalls_w(m, ci = NULL), ""unique ranking"")
   expect_equal(W[[1]], 0.4666667, tolerance = 0.001)
   expect_equal(kendalls_w(t(m), blocks_on_rows = FALSE, ci = NULL, verbose = FALSE)[[1]], W[[1]])
+
+  m[1,1] <- NA
+  warns <- capture_warnings(W1 <- kendalls_w(m, ci = NULL))
+  expect_match(warns[1], ""dropped"")
+  expect_equal(W1, kendalls_w(m[,-1], ci = NULL, verbose = FALSE))
 })

---FILE: tests/testthat/test-standardized_differences.R---
@@ -134,10 +134,13 @@ test_that(""fixed values"", {
 })
 
 test_that(""Missing values"", {
-  x <- c(1, 2, NA, 3)
-  y <- c(1, 1, 2, 3)
-  expect_equal(cohens_d(x, y)[[1]], 0.2564946, tolerance = 0.01) # indep
-  expect_equal(cohens_d(x, y, paired = TRUE)[[1]], 0.5773503, tolerance = 0.01) # paired
+  x <- c(1, NA, 2, 3, 4)
+  y <- c(1,  2, 3, 4, 5)
+
+  expect_warning(d1 <- cohens_d(x, y), ""dropped"")
+  expect_warning(d2 <- cohens_d(x, y, paired = TRUE), ""dropped"")
+  expect_equal(d1, cohens_d(1:4, 1:5), tolerance = 0.01) # indep
+  expect_equal(d2, cohens_d(1:4, c(1, 3:5), paired = TRUE), tolerance = 0.01) # paired
 
   # no length problems
   expect_error(cohens_d(mtcars$mpg - 23), regexp = NA)",True,False,Documentation / Formatting,6
easystats,effectsize,9a10f7383603164c902f4297a3dc18726912c9e4,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-09-23T10:52:18Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-09-23T10:52:18Z,https://github.com/easystats/easystats/issues/310,tests/testthat/test-convert_between.R;tests/testthat/test-convert_statistic.R;tests/testthat/test-effectsize.R;tests/testthat/test-equivalence_test.R;tests/testthat/test-eta_squared.R;tests/testthat/test-eta_squared_posterior.R;tests/testthat/test-format_standardize.R;tests/testthat/test-helpers.R;tests/testthat/test-interpret.R;tests/testthat/test-plot.R;tests/testthat/test-printing.R;tests/testthat/test-rankES.R;tests/testthat/test-standardized_differences.R;tests/testthat/test-xtab.R,False,True,True,False,2159,2179,4338,"---FILE: tests/testthat/test-convert_between.R---
@@ -1,106 +1,104 @@
-if (require(""testthat"") && require(""effectsize"")) {
-  test_that(""oddsratio_to_d"", {
-    expect_equal(oddsratio_to_d(0.2), -0.887, tolerance = 0.01)
-    expect_equal(oddsratio_to_d(-1.45, log = TRUE), -0.7994, tolerance = 0.01)
-    expect_equal(d_to_oddsratio(-0.887), 0.2, tolerance = 0.01)
-    expect_equal(d_to_oddsratio(-0.7994, log = TRUE), -1.45, tolerance = 0.01)
-  })
-
-
-  test_that(""d_to_r"", {
-    expect_equal(d_to_r(1.1547), 0.5, tolerance = 0.01)
-    expect_equal(r_to_d(0.5), 1.1547, tolerance = 0.01)
-
-    expect_equal(oddsratio_to_r(d_to_oddsratio(r_to_d(0.5))), 0.5, tolerance = 0.001)
-    expect_equal(oddsratio_to_d(r_to_oddsratio(d_to_r(1), log = TRUE), log = TRUE), 1, tolerance = 0.001)
-  })
-
-  test_that(""oddsratio_to_RR"", {
-    skip_on_cran()
-    p0 <- 0.4
-    p1 <- 0.7
-
-    OR <- probs_to_odds(p1) / probs_to_odds(p0)
-    RR <- p1 / p0
-
-    expect_equal(riskratio_to_oddsratio(RR, p0 = p0), OR)
-    expect_equal(oddsratio_to_riskratio(OR, p0 = p0), RR)
-    expect_equal(oddsratio_to_riskratio(1 / OR, p0 = p1), 1 / RR)
-
-    expect_equal(riskratio_to_oddsratio(log(RR), p0 = p0, log = TRUE), log(OR))
-    expect_equal(oddsratio_to_riskratio(log(OR), p0 = p0, log = TRUE), log(RR))
-
-    # -- GLMs --
-    data(mtcars)
-
-    m <<- glm(am ~ factor(cyl),
-      data = mtcars,
-      family = binomial()
-    )
-
-    w <- capture_warnings(RR <- oddsratio_to_riskratio(m, ci_method = ""wald""))
-    expect_match(w[1], ""p0"")
-    expect_match(w[2], ""CIs"")
-    expect_true(""(Intercept)"" %in% RR$Parameter)
-    expect_false(""(p0)"" %in% RR$Parameter)
-    # these values confirmed from emmeans
-    expect_equal(RR$Coefficient, c(0.7272, 0.5892, 0.1964), tolerance = 0.001)
-    expect_equal(RR$CI_low, c(NA, 0.1267, 0.0303), tolerance = 0.001)
-    expect_equal(RR$CI_high, c(NA, 1.1648, 0.7589), tolerance = 0.001)
-
-    expect_warning(RR <- oddsratio_to_riskratio(m, p0 = 0.05), ""CIs"")
-    expect_true(""(p0)"" %in% RR$Parameter)
-    expect_false(""(Intercept)"" %in% RR$Parameter)
-    # these values confirmed from emmeans
-    expect_equal(RR$Coefficient, c(0.05, 0.29173, 0.06557), tolerance = 0.001)
-
-    # -- GLMMs --
-    skip_if_not_installed(""lme4"")
-    m <<- lme4::glmer(am ~ factor(cyl) + (1 | gear),
-      data = mtcars,
-      family = binomial()
-    )
-    w <- capture_warnings(RR <- oddsratio_to_riskratio(m))
-    expect_match(w[1], ""p0"")
-    expect_match(w[2], ""CIs"")
-    expect_true(""(Intercept)"" %in% RR$Parameter)
-    expect_false(""(p0)"" %in% RR$Parameter)
-    # these values confirmed from emmeans
-    expect_equal(RR$Coefficient, c(0.7048, 0.6042, 0.4475), tolerance = 0.001)
-    expect_equal(RR$CI_low, c(NA, 0.08556, 0.0102), tolerance = 0.001)
-    expect_equal(RR$CI_high, c(NA, 1.2706, 1.3718), tolerance = 0.001)
-  })
-
-  test_that(""odds_to_probs"", {
-    expect_equal(odds_to_probs(3), 0.75, tolerance = 0.01)
-    expect_equal(probs_to_odds(0.75), 3, tolerance = 0.01)
-    expect_equal(probs_to_odds(0.75, log = TRUE), 1.098, tolerance = 0.01)
-    expect_equal(odds_to_probs(1.098, log = TRUE), 0.75, tolerance = 0.01)
-
-    expect_equal(
-      ncol(df <- odds_to_probs(
-        iris,
-        select = c(""Sepal.Length""),
-        exclude = c(""Petal.Length""),
-        log = TRUE
-      )), 5
-    )
-
-    expect_equal(
-      ncol(probs_to_odds(
-        df,
-        select = c(""Sepal.Length""),
-        exclude = c(""Petal.Length""),
-        log = TRUE
-      )), 5
-    )
-  })
-
-  test_that(""between anova"", {
-    expect_equal(eta2_to_f2(0.25), 1 / 3)
-    expect_equal(eta2_to_f(0.25), sqrt(eta2_to_f2(0.25)))
-
-    expect_equal(f2_to_eta2(1 / 3), 0.25)
-    expect_equal(f_to_eta2(1 / sqrt(3)), f2_to_eta2(1 / 3))
-  })
-}
+test_that(""oddsratio_to_d"", {
+  expect_equal(oddsratio_to_d(0.2), -0.887, tolerance = 0.01)
+  expect_equal(oddsratio_to_d(-1.45, log = TRUE), -0.7994, tolerance = 0.01)
+  expect_equal(d_to_oddsratio(-0.887), 0.2, tolerance = 0.01)
+  expect_equal(d_to_oddsratio(-0.7994, log = TRUE), -1.45, tolerance = 0.01)
+})
+
+
+test_that(""d_to_r"", {
+  expect_equal(d_to_r(1.1547), 0.5, tolerance = 0.01)
+  expect_equal(r_to_d(0.5), 1.1547, tolerance = 0.01)
+
+  expect_equal(oddsratio_to_r(d_to_oddsratio(r_to_d(0.5))), 0.5, tolerance = 0.001)
+  expect_equal(oddsratio_to_d(r_to_oddsratio(d_to_r(1), log = TRUE), log = TRUE), 1, tolerance = 0.001)
+})
+
+test_that(""oddsratio_to_RR"", {
+  skip_on_cran()
+  p0 <- 0.4
+  p1 <- 0.7
+
+  OR <- probs_to_odds(p1) / probs_to_odds(p0)
+  RR <- p1 / p0
+
+  expect_equal(riskratio_to_oddsratio(RR, p0 = p0), OR)
+  expect_equal(oddsratio_to_riskratio(OR, p0 = p0), RR)
+  expect_equal(oddsratio_to_riskratio(1 / OR, p0 = p1), 1 / RR)
+
+  expect_equal(riskratio_to_oddsratio(log(RR), p0 = p0, log = TRUE), log(OR))
+  expect_equal(oddsratio_to_riskratio(log(OR), p0 = p0, log = TRUE), log(RR))
+
+  # -- GLMs --
+  data(mtcars)
+
+  m <<- glm(am ~ factor(cyl),
+            data = mtcars,
+            family = binomial()
+  )
+
+  w <- capture_warnings(RR <- oddsratio_to_riskratio(m, ci_method = ""wald""))
+  expect_match(w[1], ""p0"")
+  expect_match(w[2], ""CIs"")
+  expect_true(""(Intercept)"" %in% RR$Parameter)
+  expect_false(""(p0)"" %in% RR$Parameter)
+  # these values confirmed from emmeans
+  expect_equal(RR$Coefficient, c(0.7272, 0.5892, 0.1964), tolerance = 0.001)
+  expect_equal(RR$CI_low, c(NA, 0.1267, 0.0303), tolerance = 0.001)
+  expect_equal(RR$CI_high, c(NA, 1.1648, 0.7589), tolerance = 0.001)
+
+  expect_warning(RR <- oddsratio_to_riskratio(m, p0 = 0.05), ""CIs"")
+  expect_true(""(p0)"" %in% RR$Parameter)
+  expect_false(""(Intercept)"" %in% RR$Parameter)
+  # these values confirmed from emmeans
+  expect_equal(RR$Coefficient, c(0.05, 0.29173, 0.06557), tolerance = 0.001)
+
+  # -- GLMMs --
+  skip_if_not_installed(""lme4"")
+  m <<- lme4::glmer(am ~ factor(cyl) + (1 | gear),
+                    data = mtcars,
+                    family = binomial()
+  )
+  w <- capture_warnings(RR <- oddsratio_to_riskratio(m))
+  expect_match(w[1], ""p0"")
+  expect_match(w[2], ""CIs"")
+  expect_true(""(Intercept)"" %in% RR$Parameter)
+  expect_false(""(p0)"" %in% RR$Parameter)
+  # these values confirmed from emmeans
+  expect_equal(RR$Coefficient, c(0.7048, 0.6042, 0.4475), tolerance = 0.001)
+  expect_equal(RR$CI_low, c(NA, 0.08556, 0.0102), tolerance = 0.001)
+  expect_equal(RR$CI_high, c(NA, 1.2706, 1.3718), tolerance = 0.001)
+})
+
+test_that(""odds_to_probs"", {
+  expect_equal(odds_to_probs(3), 0.75, tolerance = 0.01)
+  expect_equal(probs_to_odds(0.75), 3, tolerance = 0.01)
+  expect_equal(probs_to_odds(0.75, log = TRUE), 1.098, tolerance = 0.01)
+  expect_equal(odds_to_probs(1.098, log = TRUE), 0.75, tolerance = 0.01)
+
+  expect_equal(
+    ncol(df <- odds_to_probs(
+      iris,
+      select = c(""Sepal.Length""),
+      exclude = c(""Petal.Length""),
+      log = TRUE
+    )), 5
+  )
+
+  expect_equal(
+    ncol(probs_to_odds(
+      df,
+      select = c(""Sepal.Length""),
+      exclude = c(""Petal.Length""),
+      log = TRUE
+    )), 5
+  )
+})
+
+test_that(""between anova"", {
+  expect_equal(eta2_to_f2(0.25), 1 / 3)
+  expect_equal(eta2_to_f(0.25), sqrt(eta2_to_f2(0.25)))
+
+  expect_equal(f2_to_eta2(1 / 3), 0.25)
+  expect_equal(f_to_eta2(1 / sqrt(3)), f2_to_eta2(1 / 3))
+})

---FILE: tests/testthat/test-convert_statistic.R---
@@ -1,98 +1,96 @@
-if (require(""testthat"") && require(""effectsize"")) {
-  test_that(""xtab"", {
-    xtab <- as.table(rbind(
-      c(762, 327, 468),
-      c(484, 239, 477),
-      c(484, 239, 477)
-    ))
-    chisq <- chisq.test(xtab, correct = FALSE)
+test_that(""xtab"", {
+  xtab <- as.table(rbind(
+    c(762, 327, 468),
+    c(484, 239, 477),
+    c(484, 239, 477)
+  ))
+  chisq <- chisq.test(xtab, correct = FALSE)
 
-    res <- chisq_to_cramers_v(
-      chisq$statistic,
-      n = sum(xtab),
-      nrow = nrow(xtab),
-      ncol = ncol(xtab)
-    )
-    expect_equal(res, cramers_v(xtab), ignore_attr = TRUE)
+  res <- chisq_to_cramers_v(
+    chisq$statistic,
+    n = sum(xtab),
+    nrow = nrow(xtab),
+    ncol = ncol(xtab)
+  )
+  expect_equal(res, cramers_v(xtab), ignore_attr = TRUE)
 
 
-    res <- chisq_to_cohens_w(
-      chisq$statistic,
-      n = sum(xtab),
-      nrow = nrow(xtab),
-      ncol = ncol(xtab)
-    )
-    expect_equal(res, cohens_w(xtab), ignore_attr = TRUE)
-  })
+  res <- chisq_to_cohens_w(
+    chisq$statistic,
+    n = sum(xtab),
+    nrow = nrow(xtab),
+    ncol = ncol(xtab)
+  )
+  expect_equal(res, cohens_w(xtab), ignore_attr = TRUE)
+})
 
-  test_that(""r"", {
-    res1 <- cor.test(iris[[1]], iris[[2]])
+test_that(""r"", {
+  res1 <- cor.test(iris[[1]], iris[[2]])
 
-    res2 <- t_to_r(t = res1$statistic, res1$parameter)
-    expect_equal(res2$r, res1$estimate, tolerance = 0.01, ignore_attr = TRUE)
-    expect_equal(res2$CI_low, res1$conf.int[1], tolerance = 0.02, ignore_attr = TRUE)
-    expect_equal(res2$CI_high, res1$conf.int[2], tolerance = 0.01, ignore_attr = TRUE)
+  res2 <- t_to_r(t = res1$statistic, res1$parameter)
+  expect_equal(res2$r, res1$estimate, tolerance = 0.01, ignore_attr = TRUE)
+  expect_equal(res2$CI_low, res1$conf.int[1], tolerance = 0.02, ignore_attr = TRUE)
+  expect_equal(res2$CI_high, res1$conf.int[2], tolerance = 0.01, ignore_attr = TRUE)
 
-    res3 <- F_to_r(res1$statistic^2, 1, res1$parameter)
-    expect_equal(res3$r, -res1$estimate, tolerance = 0.01, ignore_attr = TRUE)
-    expect_equal(res3$CI_low, -res1$conf.int[2], tolerance = 0.02, ignore_attr = TRUE)
-    expect_equal(res3$CI_high, -res1$conf.int[1], tolerance = 0.02, ignore_attr = TRUE)
-    expect_error(F_to_r(3, 2, 3), ""df"")
+  res3 <- F_to_r(res1$statistic^2, 1, res1$parameter)
+  expect_equal(res3$r, -res1$estimate, tolerance = 0.01, ignore_attr = TRUE)
+  expect_equal(res3$CI_low, -res1$conf.int[2], tolerance = 0.02, ignore_attr = TRUE)
+  expect_equal(res3$CI_high, -res1$conf.int[1], tolerance = 0.02, ignore_attr = TRUE)
+  expect_error(F_to_r(3, 2, 3), ""df"")
 
-    res4 <- z_to_r(res1$statistic, res1$parameter)
-    expect_equal(res4$r, res1$estimate, tolerance = 0.01, ignore_attr = TRUE)
-    expect_equal(res4$CI_low, res1$conf.int[1], tolerance = 0.02, ignore_attr = TRUE)
-    expect_equal(res4$CI_high, res1$conf.int[2], tolerance = 0.02, ignore_attr = TRUE)
-  })
+  res4 <- z_to_r(res1$statistic, res1$parameter)
+  expect_equal(res4$r, res1$estimate, tolerance = 0.01, ignore_attr = TRUE)
+  expect_equal(res4$CI_low, res1$conf.int[1], tolerance = 0.02, ignore_attr = TRUE)
+  expect_equal(res4$CI_high, res1$conf.int[2], tolerance = 0.02, ignore_attr = TRUE)
+})
 
-  test_that(""d"", {
-    res <- t_to_d(4, 68)
-    expect_equal(res$d, 0.970, tolerance = 0.01)
-    expect_equal(res$CI_low, 0.464, tolerance = 0.01)
-    expect_equal(res$CI_high, 1.469, tolerance = 0.01)
+test_that(""d"", {
+  res <- t_to_d(4, 68)
+  expect_equal(res$d, 0.970, tolerance = 0.01)
+  expect_equal(res$CI_low, 0.464, tolerance = 0.01)
+  expect_equal(res$CI_high, 1.469, tolerance = 0.01)
 
-    res <- t_to_d(4, 68, paired = TRUE)
-    expect_equal(res$d, 0.970 / 2, tolerance = 0.01)
-    expect_equal(res$CI_low, 0.464 / 2, tolerance = 0.01)
-    expect_equal(res$CI_high, 1.469 / 2, tolerance = 0.01)
+  res <- t_to_d(4, 68, paired = TRUE)
+  expect_equal(res$d, 0.970 / 2, tolerance = 0.01)
+  expect_equal(res$CI_low, 0.464 / 2, tolerance = 0.01)
+  expect_equal(res$CI_high, 1.469 / 2, tolerance = 0.01)
 
-    res <- F_to_d(16, 1, 68)
-    expect_equal(res$d, 0.970, tolerance = 0.01)
-    expect_equal(res$CI_low, 0.464, tolerance = 0.01)
-    expect_equal(res$CI_high, 1.469, tolerance = 0.01)
-    expect_error(F_to_d(16, 2, 68), ""df"")
+  res <- F_to_d(16, 1, 68)
+  expect_equal(res$d, 0.970, tolerance = 0.01)
+  expect_equal(res$CI_low, 0.464, tolerance = 0.01)
+  expect_equal(res$CI_high, 1.469, tolerance = 0.01)
+  expect_error(F_to_d(16, 2, 68), ""df"")
 
-    res <- z_to_d(4, 68)
-    expect_equal(res$d, 0.970, tolerance = 0.01)
-    expect_equal(res$CI_low, 0.494, tolerance = 0.01)
-    expect_equal(res$CI_high, 1.446, tolerance = 0.01)
-  })
+  res <- z_to_d(4, 68)
+  expect_equal(res$d, 0.970, tolerance = 0.01)
+  expect_equal(res$CI_low, 0.494, tolerance = 0.01)
+  expect_equal(res$CI_high, 1.446, tolerance = 0.01)
+})
 
-  test_that(""eta2"", {
-    res <- F_to_eta2(4, 3, 123)
-    expect_equal(res[[1]], 0.089, tolerance = 0.01)
-    expect_equal(res$CI_low, 0.014, tolerance = 0.02)
-    expect_equal(res$CI_high, 1)
-    expect_equal(t_to_eta2(2, 123), F_to_eta2(4, 1, 123))
+test_that(""eta2"", {
+  res <- F_to_eta2(4, 3, 123)
+  expect_equal(res[[1]], 0.089, tolerance = 0.01)
+  expect_equal(res$CI_low, 0.014, tolerance = 0.02)
+  expect_equal(res$CI_high, 1)
+  expect_equal(t_to_eta2(2, 123), F_to_eta2(4, 1, 123))
 
-    res <- F_to_epsilon2(4, 3, 123)
-    expect_equal(res[[1]], 0.067, tolerance = 0.01)
-    expect_equal(res$CI_low, 0.002, tolerance = 0.01)
-    expect_equal(res$CI_high, 1)
-    expect_equal(t_to_epsilon2(2, 123), F_to_epsilon2(4, 1, 123))
+  res <- F_to_epsilon2(4, 3, 123)
+  expect_equal(res[[1]], 0.067, tolerance = 0.01)
+  expect_equal(res$CI_low, 0.002, tolerance = 0.01)
+  expect_equal(res$CI_high, 1)
+  expect_equal(t_to_epsilon2(2, 123), F_to_epsilon2(4, 1, 123))
 
-    res <- F_to_omega2(4, 3, 123)
-    expect_equal(res[[1]], 0.066, tolerance = 0.01)
-    expect_equal(res$CI_low, 0.002, tolerance = 0.01)
-    expect_equal(res$CI_high, 1)
-    expect_equal(t_to_epsilon2(2, 123), F_to_epsilon2(4, 1, 123))
+  res <- F_to_omega2(4, 3, 123)
+  expect_equal(res[[1]], 0.066, tolerance = 0.01)
+  expect_equal(res$CI_low, 0.002, tolerance = 0.01)
+  expect_equal(res$CI_high, 1)
+  expect_equal(t_to_epsilon2(2, 123), F_to_epsilon2(4, 1, 123))
 
-    res <- F_to_eta2(4, 3, 123)
-    resf2 <- F_to_f2(4, 3, 123)
-    resf <- F_to_f(4, 3, 123)
-    expect_equal(resf2[[1]], res[[1]] / (1 - res[[1]]), ignore_attr = TRUE)
-    expect_equal(resf[[1]]^2, res[[1]] / (1 - res[[1]]), ignore_attr = TRUE)
-    expect_equal(F_to_f(4, 3, 123), F_to_f2(4, 3, 123, squared = FALSE))
-    expect_equal(F_to_f2(4, 3, 123), F_to_f(4, 3, 123, squared = TRUE))
-  })
-}
+  res <- F_to_eta2(4, 3, 123)
+  resf2 <- F_to_f2(4, 3, 123)
+  resf <- F_to_f(4, 3, 123)
+  expect_equal(resf2[[1]], res[[1]] / (1 - res[[1]]), ignore_attr = TRUE)
+  expect_equal(resf[[1]]^2, res[[1]] / (1 - res[[1]]), ignore_attr = TRUE)
+  expect_equal(F_to_f(4, 3, 123), F_to_f2(4, 3, 123, squared = FALSE))
+  expect_equal(F_to_f2(4, 3, 123), F_to_f(4, 3, 123, squared = TRUE))
+})

---FILE: tests/testthat/test-effectsize.R---
@@ -1,261 +1,259 @@
-if (require(""testthat"") && require(""effectsize"")) {
-  # htest -------------------------------------------------------------------
-  test_that(""t-test"", {
-    x <<- 1:10
-    y <<- c(1, 1:9)
-    model <- t.test(x, y)
-    expect_equal(effectsize(model), d <- cohens_d(x, y, pooled_sd = FALSE), ignore_attr = TRUE)
-    expect_equal(cohens_d(model), d, ignore_attr = TRUE)
-    expect_equal(effectsize(model, type = ""g""), hedges_g(x, y, pooled_sd = FALSE), ignore_attr = TRUE)
-    expect_error(effectsize(model, type = ""u1""), ""applicable"")
-
-    model <- t.test(x, y, var.equal = TRUE)
-    expect_equal(effectsize(model, type = ""u1""), cohens_u1(x, y), ignore_attr = TRUE)
-    expect_equal(effectsize(model, type = ""u2""), cohens_u2(x, y), ignore_attr = TRUE)
-    expect_equal(effectsize(model, type = ""u3""), cohens_u3(x, y), ignore_attr = TRUE)
-
-    model <- t.test(x, y, alternative = ""less"", conf.level = 0.8)
-    expect_equal(effectsize(model), cohens_d(x, y, pooled_sd = FALSE, alternative = ""less"", ci = 0.8), ignore_attr = TRUE)
-
-    model <- t.test(x, y, paired = TRUE)
-    expect_equal(effectsize(model), cohens_d(x, y, paired = TRUE), ignore_attr = TRUE)
-
-    model <- t.test(x, y, var.equal = TRUE)
-    expect_equal(effectsize(model), cohens_d(x, y), ignore_attr = TRUE)
-
-    model <- t.test(x, y, var.equal = TRUE, mu = 3)
-    expect_equal(effectsize(model), cohens_d(x, y, mu = 3), ignore_attr = TRUE)
-
-    df <- data.frame(DV = c(x, y), g = rep(1:2, each = 10))
-    model <- t.test(DV ~ g, data = df, var.equal = TRUE, mu = 3)
-    expect_warning(effectsize(model), ""data"")
-
-    ## Auto convert y to factor
-    Ts <- t.test(mtcars$mpg ~ mtcars$vs)
-    expect_equal(effectsize(Ts, verbose = FALSE),
-      cohens_d(mtcars$mpg, factor(mtcars$vs), pooled_sd = FALSE),
-      ignore_attr = TRUE
-    )
-
-
-    # one sample
-    z <<- mtcars$wt
-    model <- t.test(z, mu = 3, var.equal = TRUE)
-    expect_equal(effectsize(model),
-      cohens_d(z, mu = 3),
-      ignore_attr = TRUE
-    )
-  })
-
-  test_that(""Chisq-test"", {
-    contingency_table <-
-      as.table(rbind(c(760, 330, 470), c(480, 240, 480), c(480, 240, 480)))
-
-    Xsq1 <- chisq.test(contingency_table)
-    Xsq2 <- chisq.test(contingency_table / 10)
-
-    expect_equal(effectsize(Xsq1)$Cramers_v, 0.073, tolerance = 0.01)
-    expect_equal(
-      effectsize(Xsq1)$Cramers_v,
-      effectsize(Xsq2)$Cramers_v
-    )
-
-    # types
-    expect_error(effectsize(Xsq1, type = ""phi""), ""appropriate"")
-    expect_equal(effectsize(Xsq1), cramers_v(contingency_table))
-    expect_equal(effectsize(Xsq1, type = ""w""), w <- cohens_w(contingency_table))
-    expect_equal(cohens_w(Xsq1), w)
-
-    expect_error(effectsize(Xsq1, type = ""riskratio""), ""only"")
-    expect_error(riskratio(Xsq1), ""only"")
-
-    contingency_table22 <- contingency_table[1:2, 1:2]
-    Xsq4 <- chisq.test(contingency_table22)
-    expect_equal(effectsize(Xsq4, type = ""phi""), ph <- phi(contingency_table22))
-    expect_equal(phi(Xsq4), ph)
-
-    expect_equal(effectsize(Xsq4, type = ""oddsratio""), or <- oddsratio(contingency_table22))
-    expect_equal(oddsratio(Xsq4), or)
-
-    expect_equal(effectsize(Xsq4, type = ""riskratio""), rr <- riskratio(contingency_table22))
-    expect_equal(riskratio(Xsq4), rr)
-
-    expect_equal(effectsize(Xsq4, type = ""pearsons_c""), pc <- pearsons_c(contingency_table22))
-    expect_equal(pearsons_c(Xsq4), pc)
-
-    expect_equal(effectsize(Xsq4, type = ""h""), h <- cohens_h(contingency_table22))
-    expect_equal(cohens_h(Xsq4), h)
-
-    # goodness of fit
-    observed.dfc <<- c(119, 61)
-    expected.dfc <<- c(0.165, 0.835)
-
-    x <- chisq.test(x = observed.dfc, p = expected.dfc)
-    expect_error(effectsize(x, type = ""v""), ""goodness"")
-    expect_error(effectsize(x, type = ""phi""), ""appropriate"")
-    expect_equal(effectsize(x), effectsize(x, type = ""fei""))
-    expect_equal(effectsize(x, type = ""fei""), Fei <- fei(observed.dfc, p = expected.dfc))
-    expect_equal(fei(x), Fei)
-  })
-
-  test_that(""cor.test / other"", {
-    r_ <- cor.test(iris$Sepal.Width, iris$Sepal.Length)
-    expect_warning(effectsize(r_), ""parameters"")
-  })
-
-  test_that(""one way"", {
-    onew <- oneway.test(mpg ~ cyl, mtcars)
-    expect_warning(effectsize(onew), ""var"")
-
-
-    onew <- oneway.test(mpg ~ cyl, mtcars, var.equal = TRUE)
-    m <- aov(mpg ~ cyl, mtcars)
-
-    expect_equal(eta_squared(m, partial = FALSE)[, -1], effectsize(onew),
-      tolerance = 0.03, ignore_attr = TRUE
-    )
-    expect_equal(eta_squared(m, partial = FALSE)[, -1], eta_squared(onew),
-      tolerance = 0.03, ignore_attr = TRUE
-    )
-    expect_equal(omega_squared(m, partial = FALSE)[, -1], effectsize(onew, type = ""omega""),
-      tolerance = 0.03, ignore_attr = TRUE
-    )
-    expect_equal(cohens_f(m, partial = FALSE)[, -1], effectsize(onew, type = ""f""),
-      tolerance = 0.03, ignore_attr = TRUE
-    )
-  })
-
-  test_that(""McNemar"", {
-    Performance <<- rbind(
-      c(794, 86),
-      c(150, 570)
-    )
-
-    model <- mcnemar.test(Performance)
-    expect_equal(effectsize(model), g <- cohens_g(Performance), ignore_attr = TRUE)
-    expect_equal(cohens_g(model), g, ignore_attr = TRUE)
-
-    model <- mcnemar.test(mtcars$cyl, mtcars$gear)
-    expect_equal(effectsize(model), cohens_g(mtcars$cyl, mtcars$gear), ignore_attr = TRUE)
-  })
-
-  test_that(""htest | rank"", {
-    suppressWarnings(ww <- wilcox.test(mtcars$hp, mtcars$mpg + 80))
-    expect_equal(effectsize(ww), rbs <- rank_biserial(mtcars$hp, mtcars$mpg + 80), ignore_attr = TRUE)
-    expect_equal(rank_biserial(ww), rbs, ignore_attr = TRUE)
-    expect_equal(effectsize(ww, type = ""u2"", ci = NULL)[[1]],
-                 cohens_u2(mtcars$hp, mtcars$mpg + 80, parametric = FALSE, ci = NULL)[[1]],
-                 tolerance = 0.001)
-    expect_equal(effectsize(ww, type = ""overlap"")[[1]],
-                 p_overlap(mtcars$hp, mtcars$mpg + 80, parametric = FALSE, ci = NULL)[[1]],
-                 tolerance = 0.001)
-
-
-    RoundingTimes <-
-      matrix(
-        c(
-          5.40, 5.50, 5.55,
-          5.85, 5.70, 5.75,
-          5.20, 5.60, 5.50,
-          5.55, 5.50, 5.40,
-          5.90, 5.85, 5.70,
-          5.45, 5.55, 5.60,
-          5.40, 5.40, 5.35,
-          5.45, 5.50, 5.35,
-          5.25, 5.15, 5.00,
-          5.85, 5.80, 5.70,
-          5.25, 5.20, 5.10,
-          5.65, 5.55, 5.45,
-          5.60, 5.35, 5.45,
-          5.05, 5.00, 4.95,
-          5.50, 5.50, 5.40,
-          5.45, 5.55, 5.50,
-          5.55, 5.55, 5.35,
-          5.45, 5.50, 5.55,
-          5.50, 5.45, 5.25,
-          5.65, 5.60, 5.40,
-          5.70, 5.65, 5.55,
-          6.30, 6.30, 6.25
-        ),
-        nrow = 22,
-        byrow = TRUE,
-        dimnames = list(
-          1:22,
-          c(""Round Out"", ""Narrow Angle"", ""Wide Angle"")
-        )
+# htest -------------------------------------------------------------------
+test_that(""t-test"", {
+  x <<- 1:10
+  y <<- c(1, 1:9)
+  model <- t.test(x, y)
+  expect_equal(effectsize(model), d <- cohens_d(x, y, pooled_sd = FALSE), ignore_attr = TRUE)
+  expect_equal(cohens_d(model), d, ignore_attr = TRUE)
+  expect_equal(effectsize(model, type = ""g""), hedges_g(x, y, pooled_sd = FALSE), ignore_attr = TRUE)
+  expect_error(effectsize(model, type = ""u1""), ""applicable"")
+
+  model <- t.test(x, y, var.equal = TRUE)
+  expect_equal(effectsize(model, type = ""u1""), cohens_u1(x, y), ignore_attr = TRUE)
+  expect_equal(effectsize(model, type = ""u2""), cohens_u2(x, y), ignore_attr = TRUE)
+  expect_equal(effectsize(model, type = ""u3""), cohens_u3(x, y), ignore_attr = TRUE)
+
+  model <- t.test(x, y, alternative = ""less"", conf.level = 0.8)
+  expect_equal(effectsize(model), cohens_d(x, y, pooled_sd = FALSE, alternative = ""less"", ci = 0.8), ignore_attr = TRUE)
+
+  model <- t.test(x, y, paired = TRUE)
+  expect_equal(effectsize(model), cohens_d(x, y, paired = TRUE), ignore_attr = TRUE)
+
+  model <- t.test(x, y, var.equal = TRUE)
+  expect_equal(effectsize(model), cohens_d(x, y), ignore_attr = TRUE)
+
+  model <- t.test(x, y, var.equal = TRUE, mu = 3)
+  expect_equal(effectsize(model), cohens_d(x, y, mu = 3), ignore_attr = TRUE)
+
+  df <- data.frame(DV = c(x, y), g = rep(1:2, each = 10))
+  model <- t.test(DV ~ g, data = df, var.equal = TRUE, mu = 3)
+  expect_warning(effectsize(model), ""data"")
+
+  ## Auto convert y to factor
+  Ts <- t.test(mtcars$mpg ~ mtcars$vs)
+  expect_equal(effectsize(Ts, verbose = FALSE),
+               cohens_d(mtcars$mpg, factor(mtcars$vs), pooled_sd = FALSE),
+               ignore_attr = TRUE
+  )
+
+
+  # one sample
+  z <<- mtcars$wt
+  model <- t.test(z, mu = 3, var.equal = TRUE)
+  expect_equal(effectsize(model),
+               cohens_d(z, mu = 3),
+               ignore_attr = TRUE
+  )
+})
+
+test_that(""Chisq-test"", {
+  contingency_table <-
+    as.table(rbind(c(760, 330, 470), c(480, 240, 480), c(480, 240, 480)))
+
+  Xsq1 <- chisq.test(contingency_table)
+  Xsq2 <- chisq.test(contingency_table / 10)
+
+  expect_equal(effectsize(Xsq1)$Cramers_v, 0.073, tolerance = 0.01)
+  expect_equal(
+    effectsize(Xsq1)$Cramers_v,
+    effectsize(Xsq2)$Cramers_v
+  )
+
+  # types
+  expect_error(effectsize(Xsq1, type = ""phi""), ""appropriate"")
+  expect_equal(effectsize(Xsq1), cramers_v(contingency_table))
+  expect_equal(effectsize(Xsq1, type = ""w""), w <- cohens_w(contingency_table))
+  expect_equal(cohens_w(Xsq1), w)
+
+  expect_error(effectsize(Xsq1, type = ""riskratio""), ""only"")
+  expect_error(riskratio(Xsq1), ""only"")
+
+  contingency_table22 <- contingency_table[1:2, 1:2]
+  Xsq4 <- chisq.test(contingency_table22)
+  expect_equal(effectsize(Xsq4, type = ""phi""), ph <- phi(contingency_table22))
+  expect_equal(phi(Xsq4), ph)
+
+  expect_equal(effectsize(Xsq4, type = ""oddsratio""), or <- oddsratio(contingency_table22))
+  expect_equal(oddsratio(Xsq4), or)
+
+  expect_equal(effectsize(Xsq4, type = ""riskratio""), rr <- riskratio(contingency_table22))
+  expect_equal(riskratio(Xsq4), rr)
+
+  expect_equal(effectsize(Xsq4, type = ""pearsons_c""), pc <- pearsons_c(contingency_table22))
+  expect_equal(pearsons_c(Xsq4), pc)
+
+  expect_equal(effectsize(Xsq4, type = ""h""), h <- cohens_h(contingency_table22))
+  expect_equal(cohens_h(Xsq4), h)
+
+  # goodness of fit
+  observed.dfc <<- c(119, 61)
+  expected.dfc <<- c(0.165, 0.835)
+
+  x <- chisq.test(x = observed.dfc, p = expected.dfc)
+  expect_error(effectsize(x, type = ""v""), ""goodness"")
+  expect_error(effectsize(x, type = ""phi""), ""appropriate"")
+  expect_equal(effectsize(x), effectsize(x, type = ""fei""))
+  expect_equal(effectsize(x, type = ""fei""), Fei <- fei(observed.dfc, p = expected.dfc))
+  expect_equal(fei(x), Fei)
+})
+
+test_that(""cor.test / other"", {
+  r_ <- cor.test(iris$Sepal.Width, iris$Sepal.Length)
+  expect_warning(effectsize(r_), ""parameters"")
+})
+
+test_that(""one way"", {
+  onew <- oneway.test(mpg ~ cyl, mtcars)
+  expect_warning(effectsize(onew), ""var"")
+
+
+  onew <- oneway.test(mpg ~ cyl, mtcars, var.equal = TRUE)
+  m <- aov(mpg ~ cyl, mtcars)
+
+  expect_equal(eta_squared(m, partial = FALSE)[, -1], effectsize(onew),
+               tolerance = 0.03, ignore_attr = TRUE
+  )
+  expect_equal(eta_squared(m, partial = FALSE)[, -1], eta_squared(onew),
+               tolerance = 0.03, ignore_attr = TRUE
+  )
+  expect_equal(omega_squared(m, partial = FALSE)[, -1], effectsize(onew, type = ""omega""),
+               tolerance = 0.03, ignore_attr = TRUE
+  )
+  expect_equal(cohens_f(m, partial = FALSE)[, -1], effectsize(onew, type = ""f""),
+               tolerance = 0.03, ignore_attr = TRUE
+  )
+})
+
+test_that(""McNemar"", {
+  Performance <<- rbind(
+    c(794, 86),
+    c(150, 570)
+  )
+
+  model <- mcnemar.test(Performance)
+  expect_equal(effectsize(model), g <- cohens_g(Performance), ignore_attr = TRUE)
+  expect_equal(cohens_g(model), g, ignore_attr = TRUE)
+
+  model <- mcnemar.test(mtcars$cyl, mtcars$gear)
+  expect_equal(effectsize(model), cohens_g(mtcars$cyl, mtcars$gear), ignore_attr = TRUE)
+})
+
+test_that(""htest | rank"", {
+  suppressWarnings(ww <- wilcox.test(mtcars$hp, mtcars$mpg + 80))
+  expect_equal(effectsize(ww), rbs <- rank_biserial(mtcars$hp, mtcars$mpg + 80), ignore_attr = TRUE)
+  expect_equal(rank_biserial(ww), rbs, ignore_attr = TRUE)
+  expect_equal(effectsize(ww, type = ""u2"", ci = NULL)[[1]],
+               cohens_u2(mtcars$hp, mtcars$mpg + 80, parametric = FALSE, ci = NULL)[[1]],
+               tolerance = 0.001)
+  expect_equal(effectsize(ww, type = ""overlap"")[[1]],
+               p_overlap(mtcars$hp, mtcars$mpg + 80, parametric = FALSE, ci = NULL)[[1]],
+               tolerance = 0.001)
+
+
+  RoundingTimes <-
+    matrix(
+      c(
+        5.40, 5.50, 5.55,
+        5.85, 5.70, 5.75,
+        5.20, 5.60, 5.50,
+        5.55, 5.50, 5.40,
+        5.90, 5.85, 5.70,
+        5.45, 5.55, 5.60,
+        5.40, 5.40, 5.35,
+        5.45, 5.50, 5.35,
+        5.25, 5.15, 5.00,
+        5.85, 5.80, 5.70,
+        5.25, 5.20, 5.10,
+        5.65, 5.55, 5.45,
+        5.60, 5.35, 5.45,
+        5.05, 5.00, 4.95,
+        5.50, 5.50, 5.40,
+        5.45, 5.55, 5.50,
+        5.55, 5.55, 5.35,
+        5.45, 5.50, 5.55,
+        5.50, 5.45, 5.25,
+        5.65, 5.60, 5.40,
+        5.70, 5.65, 5.55,
+        6.30, 6.30, 6.25
+      ),
+      nrow = 22,
+      byrow = TRUE,
+      dimnames = list(
+        1:22,
+        c(""Round Out"", ""Narrow Angle"", ""Wide Angle"")
       )
-    ft <- friedman.test(RoundingTimes)
-    W <- kendalls_w(RoundingTimes, verbose = FALSE, ci = NULL)
-    expect_equal(effectsize(ft, verbose = FALSE, ci = NULL), W, ignore_attr = TRUE)
-    expect_equal(kendalls_w(ft, verbose = FALSE, ci = NULL), W, ignore_attr = TRUE)
-
-    X <<- c(2.9, 3.0, 2.5, 2.6, 3.2) # normal subjects
-    Y <<- c(3.8, 2.7, 4.0, 2.4) # with obstructive airway disease
-    Z <<- c(2.8, 3.4, 3.7, 2.2, 2.0) # with asbestosis
-    kt <- kruskal.test(list(X, Y, Z))
-    expect_equal(effectsize(kt)[[1]], E <- rank_epsilon_squared(list(X, Y, Z))[[1]], ignore_attr = TRUE)
-    expect_equal(rank_epsilon_squared(kt)[[1]], E, ignore_attr = TRUE)
-  })
-
-  test_that(""htest | Get args from htest"", {
-    tt <- t.test(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3, conf.level = 0.8, var.equal = TRUE)
-    expect_equal(cohens_d(tt), cohens_d(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3, ci = 0.8), ignore_attr = TRUE)
-
-    suppressWarnings(ww1 <- wilcox.test(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3))
-    expect_equal(rank_biserial(ww1), rank_biserial(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3), ignore_attr = TRUE)
-
-    suppressWarnings(ww2 <- wilcox.test(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3, conf.int = TRUE, conf.level = 0.8))
-    expect_equal(rank_biserial(ww2), rank_biserial(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3, ci = 0.8), ignore_attr = TRUE)
-  })
-
-
-  # aov ---------------------------------------------------------------------
-  test_that(""aov"", {
-    data <- iris
-    data$Cat1 <- rep(c(""A"", ""B""), length.out = nrow(data))
-    model <- aov(Sepal.Length ~ Species * Cat1, data = data)
-    expect_equal(effectsize(model), eta_squared(model))
-    expect_equal(effectsize(model, type = ""omega""), omega_squared(model))
-  })
-
-
-  # BayesFactor -------------------------------------------------------------
-  test_that(""BayesFactor"", {
-    skip_if_not_installed(""BayesFactor"")
-    skip_on_cran()
-    set.seed(6)
-    data(raceDolls, package = ""BayesFactor"")
-    bf1 <- BayesFactor::contingencyTableBF(raceDolls, sampleType = ""poisson"", fixedMargin = ""cols"")
-    expect_equal(effectsize(bf1)[[1]], 0.164, tolerance = 0.01)
-    expect_equal(effectsize(bf1, type = ""OR"")[[1]], 1 / 0.503, tolerance = 0.03)
-
-    bf2 <- BayesFactor::ttestBF(mtcars$mpg[mtcars$am == 1], mtcars$mpg[mtcars$am == 0])
-    expect_equal(effectsize(bf2)[[1]], 1.30, tolerance = 0.03)
-    expect_equal(effectsize(bf2, type = ""u1"")[[1]], 0.65, tolerance = 0.05)
-    expect_equal(effectsize(bf2, type = ""u2"")[[1]], 0.74, tolerance = 0.05)
-    expect_equal(effectsize(bf2, type = ""u3"")[[1]], 0.9, tolerance = 0.05)
-    expect_equal(effectsize(bf2, type = ""overlap"")[[1]], 0.52, tolerance = 0.05)
-    expect_equal(effectsize(bf2, type = ""p_superiority"")[[1]], 0.8, tolerance = 0.05)
-
-    bf3 <- BayesFactor::correlationBF(iris$Sepal.Length, iris$Sepal.Width)
-    expect_equal(effectsize(bf3)[[1]], -0.116, tolerance = 0.03)
-
-    bf4 <- BayesFactor::proportionBF(4, 12, 0.5)
-    expect_equal(effectsize(bf4)[[1]], 0.3911, tolerance = 0.03)
-  })
-
-  test_that(""effectsize | easycorrelation"", {
-    skip_if_not_installed(""correlation"")
-    r <- correlation::correlation(mtcars)
-    expect_error(effectsize(r), regexp = NA)
-  })
-
-  test_that(""effectsize | other"", {
-    m <- lm(mpg ~ ., mtcars)
-
-    expect_equal(effectsize(m),
-      parameters::standardize_parameters(m),
-      ignore_attr = TRUE
     )
-  })
-}
+  ft <- friedman.test(RoundingTimes)
+  W <- kendalls_w(RoundingTimes, verbose = FALSE, ci = NULL)
+  expect_equal(effectsize(ft, verbose = FALSE, ci = NULL), W, ignore_attr = TRUE)
+  expect_equal(kendalls_w(ft, verbose = FALSE, ci = NULL), W, ignore_attr = TRUE)
+
+  X <<- c(2.9, 3.0, 2.5, 2.6, 3.2) # normal subjects
+  Y <<- c(3.8, 2.7, 4.0, 2.4) # with obstructive airway disease
+  Z <<- c(2.8, 3.4, 3.7, 2.2, 2.0) # with asbestosis
+  kt <- kruskal.test(list(X, Y, Z))
+  expect_equal(effectsize(kt)[[1]], E <- rank_epsilon_squared(list(X, Y, Z))[[1]], ignore_attr = TRUE)
+  expect_equal(rank_epsilon_squared(kt)[[1]], E, ignore_attr = TRUE)
+})
+
+test_that(""htest | Get args from htest"", {
+  tt <- t.test(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3, conf.level = 0.8, var.equal = TRUE)
+  expect_equal(cohens_d(tt), cohens_d(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3, ci = 0.8), ignore_attr = TRUE)
+
+  suppressWarnings(ww1 <- wilcox.test(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3))
+  expect_equal(rank_biserial(ww1), rank_biserial(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3), ignore_attr = TRUE)
+
+  suppressWarnings(ww2 <- wilcox.test(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3, conf.int = TRUE, conf.level = 0.8))
+  expect_equal(rank_biserial(ww2), rank_biserial(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3, ci = 0.8), ignore_attr = TRUE)
+})
+
+
+# aov ---------------------------------------------------------------------
+test_that(""aov"", {
+  data <- iris
+  data$Cat1 <- rep(c(""A"", ""B""), length.out = nrow(data))
+  model <- aov(Sepal.Length ~ Species * Cat1, data = data)
+  expect_equal(effectsize(model), eta_squared(model))
+  expect_equal(effectsize(model, type = ""omega""), omega_squared(model))
+})
+
+
+# BayesFactor -------------------------------------------------------------
+test_that(""BayesFactor"", {
+  skip_if_not_installed(""BayesFactor"")
+  skip_on_cran()
+  set.seed(6)
+  data(raceDolls, package = ""BayesFactor"")
+  bf1 <- BayesFactor::contingencyTableBF(raceDolls, sampleType = ""poisson"", fixedMargin = ""cols"")
+  expect_equal(effectsize(bf1)[[1]], 0.164, tolerance = 0.01)
+  expect_equal(effectsize(bf1, type = ""OR"")[[1]], 1 / 0.503, tolerance = 0.03)
+
+  bf2 <- BayesFactor::ttestBF(mtcars$mpg[mtcars$am == 1], mtcars$mpg[mtcars$am == 0])
+  expect_equal(effectsize(bf2)[[1]], 1.30, tolerance = 0.03)
+  expect_equal(effectsize(bf2, type = ""u1"")[[1]], 0.65, tolerance = 0.05)
+  expect_equal(effectsize(bf2, type = ""u2"")[[1]], 0.74, tolerance = 0.05)
+  expect_equal(effectsize(bf2, type = ""u3"")[[1]], 0.9, tolerance = 0.05)
+  expect_equal(effectsize(bf2, type = ""overlap"")[[1]], 0.52, tolerance = 0.05)
+  expect_equal(effectsize(bf2, type = ""p_superiority"")[[1]], 0.8, tolerance = 0.05)
+
+  bf3 <- BayesFactor::correlationBF(iris$Sepal.Length, iris$Sepal.Width)
+  expect_equal(effectsize(bf3)[[1]], -0.116, tolerance = 0.03)
+
+  bf4 <- BayesFactor::proportionBF(4, 12, 0.5)
+  expect_equal(effectsize(bf4)[[1]], 0.3911, tolerance = 0.03)
+})
+
+test_that(""effectsize | easycorrelation"", {
+  skip_if_not_installed(""correlation"")
+  r <- correlation::correlation(mtcars)
+  expect_error(effectsize(r), regexp = NA)
+})
+
+test_that(""effectsize | other"", {
+  m <- lm(mpg ~ ., mtcars)
+
+  expect_equal(effectsize(m),
+               parameters::standardize_parameters(m),
+               ignore_attr = TRUE
+  )
+})

---FILE: tests/testthat/test-equivalence_test.R---
@@ -1,25 +1,23 @@
-if (require(""testthat"") && require(""effectsize"")) {
-  test_that(""equivalence_test"", {
-    ds <- t_to_d(
-      t = c(0.45, -0.65, 7, -2.2, 2.25),
-      df_error = c(675, 525, 2000, 900, 1875),
-      ci = 0.9
-    ) # TOST approach
+test_that(""equivalence_test"", {
+  ds <- t_to_d(
+    t = c(0.45, -0.65, 7, -2.2, 2.25),
+    df_error = c(675, 525, 2000, 900, 1875),
+    ci = 0.9
+  ) # TOST approach
 
 
-    expect_equal(
-      equivalence_test(ds, range = 0.2)$ROPE_Equivalence,
-      c(""Accepted"", ""Undecided"", ""Rejected"", ""Rejected"", ""Accepted"")
-    )
+  expect_equal(
+    equivalence_test(ds, range = 0.2)$ROPE_Equivalence,
+    c(""Accepted"", ""Undecided"", ""Rejected"", ""Rejected"", ""Accepted"")
+  )
 
-    expect_equal(
-      equivalence_test(ds, range = 0.2, rule = ""cet"")$ROPE_Equivalence,
-      c(""Accepted"", ""Undecided"", ""Rejected"", ""Rejected"", ""Rejected"")
-    )
+  expect_equal(
+    equivalence_test(ds, range = 0.2, rule = ""cet"")$ROPE_Equivalence,
+    c(""Accepted"", ""Undecided"", ""Rejected"", ""Rejected"", ""Rejected"")
+  )
 
-    expect_equal(
-      equivalence_test(ds, range = 0.2, rule = ""bayes"")$ROPE_Equivalence,
-      c(""Accepted"", ""Undecided"", ""Rejected"", ""Undecided"", ""Accepted"")
-    )
-  })
-}
+  expect_equal(
+    equivalence_test(ds, range = 0.2, rule = ""bayes"")$ROPE_Equivalence,
+    c(""Accepted"", ""Undecided"", ""Rejected"", ""Undecided"", ""Accepted"")
+  )
+})

---FILE: tests/testthat/test-eta_squared.R---
@@ -1,655 +1,652 @@
-if (require(""testthat"") && require(""effectsize"")) {
-  # anova() -----------------------------------------------------------------
-  test_that(""anova()"", {
-    # Make minimal ANOVA table
-    mod <- anova(lm(mpg ~ cyl + hp, mtcars))
-
-    mod1 <- mod
-    mod1$DenDF <- mod1$Df[nrow(mod1)]
-    mod1 <- mod1[-nrow(mod1), ]
-
-    expect_error(eta_squared(mod1), regexp = NA)
-    expect_equal(
-      eta_squared(mod1)[, -1],
-      F_to_eta2(mod1[[""F value""]], mod1$Df, mod1$DenDF),
-      ignore_attr = TRUE
-    )
-    expect_warning(eta_squared(mod1, partial = FALSE), ""partial"")
-    expect_warning(eta_squared(mod1, generalized = TRUE), ""generalized"")
-
-    mod2 <- mod1
-    mod2$`F value` <- NULL
-    expect_error(eta_squared(mod2), ""does not"")
-  })
-
-  # aov ---------------------------------------------------------------------
-  test_that(""aov"", {
-    df <- iris
-    df$Sepal.Big <- ifelse(df$Sepal.Width >= 3, ""Yes"", ""No"")
-
-    fit <- aov(Sepal.Length ~ Species * Sepal.Big, df)
-
-    # eta
-    expect_equal(eta_squared(fit, partial = FALSE)$Eta2,
-      c(0.618, 0.046, 0.000),
-      tolerance = 0.01
-    )
-    expect_equal(eta_squared(fit, partial = TRUE)$Eta2_partial,
-      c(0.649, 0.121, 0.001),
-      tolerance = 0.01
-    )
-
-    # omega
-    expect_equal(omega_squared(fit, partial = FALSE)$Omega2,
-      c(0.612, 0.043, -0.004),
-      tolerance = 0.01
-    )
-    expect_equal(omega_squared(fit, partial = TRUE)$Omega2_partial,
-      c(0.638, 0.112, -0.012),
-      tolerance = 0.01
-    )
-
-    # epsilon
-    expect_equal(epsilon_squared(fit, partial = FALSE)$Epsilon2,
-      c(0.614, 0.044, -0.004),
-      tolerance = 0.001
-    )
-    expect_equal(epsilon_squared(fit, partial = TRUE)$Epsilon2_partial,
-      c(0.644, 0.115, -0.012),
-      tolerance = 0.01
-    )
-
-    # Cohen's f/f2
-    expect_equal(cohens_f_squared(fit, partial = FALSE)$Cohens_f2,
-      c(1.623, 0.049, 0.000),
-      tolerance = 0.001
-    )
-    expect_equal(cohens_f_squared(fit, partial = TRUE)$Cohens_f2_partial,
-      c(1.850, 0.139, 0.001),
-      tolerance = 0.001
-    )
-    expect_equal(cohens_f(fit, partial = FALSE)$Cohens_f,
-      c(1.273, 0.220, 0.021),
-      tolerance = 0.01
-    )
-    expect_equal(cohens_f(fit, partial = TRUE)$Cohens_f_partial,
-      c(1.360, 0.373, 0.036),
-      tolerance = 0.001
-    )
-    expect_equal(cohens_f(fit, squared = TRUE), cohens_f_squared(fit))
-    expect_equal(cohens_f_squared(fit, squared = FALSE), cohens_f(fit))
-
-
-
-    #### One way-between
-    expect_message(eta_squared(aov(mpg ~ factor(gear), mtcars)))
-    expect_message(eta_squared(aov(mpg ~ factor(gear) + am, mtcars)), regexp = NA)
-
-    #### Alternative
-    m <<- aov(mpg ~ factor(gear) + am, mtcars)
-    et1 <- eta_squared(m)
-    et2 <- eta_squared(m, ci = 0.9, alternative = ""two.sided"")
-    expect_equal(et1$CI_low, et2$CI_low)
-
-    ### parameters:
-    expect_equal(
-      eta_squared(parameters::model_parameters(m)),
-      eta_squared(m)
-    )
-  })
-
-
-  # aovlist -----------------------------------------------------------------
-  test_that(""aovlist"", {
-    skip_on_cran()
-    df <- iris
-    df$Sepal.Big <- ifelse(df$Sepal.Width >= 3, ""Yes"", ""No"")
-
-    model <<- aov(Sepal.Length ~ Sepal.Big + Error(Species), data = df)
-
-    res <- eta_squared(model, partial = TRUE)
-    expect_true(all(c(""Group"", ""Parameter"") %in% colnames(res)))
-    expect_equal(res$Eta2_partial, c(0.4472423, 0.1217329), tolerance = 0.001)
-    expect_equal(eta_squared(model, partial = FALSE)$Eta2,
-      c(0.27671136, 0.04641607),
-      tolerance = 0.001
-    )
-
-    res <- omega_squared(model, partial = TRUE)
-    expect_true(all(c(""Group"", ""Parameter"") %in% colnames(res)))
-    expect_equal(res$Omega2_partial, c(-0.06795358, 0.04141846), tolerance = 0.001)
-    expect_equal(omega_squared(model, partial = FALSE)$Omega2,
-      c(-0.04864626, 0.03287821),
-      tolerance = 0.001
-    )
-
-    res <- epsilon_squared(model, partial = TRUE)
-    expect_true(all(c(""Group"", ""Parameter"") %in% colnames(res)))
-    expect_equal(res$Epsilon2_partial, c(-0.1055154, 0.1157174), tolerance = 0.001)
-    expect_equal(epsilon_squared(model, partial = FALSE)$Epsilon2,
-      c(-0.06528301, 0.04412238),
-      tolerance = 0.001
-    )
-
-
-    expect_equal(
-      eta_squared(parameters::model_parameters(model)),
-      eta_squared(model)
-    )
-
-
-    skip_if_not_installed(""afex"")
-    # non-partial Eta2 should be the same for aov and aovlist
-    data(obk.long, package = ""afex"")
-    model <- afex::aov_car(value ~ treatment * gender + Error(id / (phase * hour)),
-      data = obk.long, observed = ""gender"",
-      include_aov = TRUE
-    )
-
-    model2 <- aov(value ~ treatment * gender * phase * hour,
-      data = model$data$long,
-      contrasts = list(
-        treatment = contr.sum,
-        gender = contr.sum,
-        phase = contr.sum,
-        hour = contr.sum
-      )
-    )
-
-    a1 <- eta_squared(model2, partial = FALSE)
-    a2 <- eta_squared(model$aov, partial = FALSE)
-
-    rownames(a1) <- a1$Parameter
-    rownames(a2) <- a2$Parameter
-
-    expect_equal(
-      a1[a1$Parameter, ""Eta2""],
-      a2[a1$Parameter, ""Eta2""]
-    )
-  })
-
-  # mlm / anova table -------------------------------------------------------
-  test_that(""mlm / anova table"", {
-    data(""mtcars"")
-    mtcars$am_f <- factor(mtcars$am)
-    mtcars$cyl_f <- factor(mtcars$cyl)
-
-    mod <- lm(cbind(mpg, qsec) ~ am_f * cyl_f, data = mtcars)
-    m1 <- lm(mpg ~ am_f * cyl_f, data = mtcars)
-    m2 <- lm(qsec ~ am_f * cyl_f, data = mtcars)
-
-    expect_equal(
-      eta_squared(mod)$Eta2_partial[1:3],
-      eta_squared(m1)$Eta2_partial
-    )
-
-    expect_equal(
-      eta_squared(mod)$Eta2_partial[4:6],
-      eta_squared(m2)$Eta2_partial
-    )
-
-    expect_equal(
-      eta_squared(mod, partial = FALSE)$Eta2[1:3],
-      eta_squared(m1, partial = FALSE)$Eta2
-    )
-
-    expect_equal(
-      eta_squared(mod, partial = FALSE)$Eta2[4:6],
-      eta_squared(m2, partial = FALSE)$Eta2
-    )
-
-    # MANOVA table
-    mod <- manova(cbind(mpg, qsec) ~ am_f * cyl_f, data = mtcars)
-    expect_equal(nrow(eta_squared(mod)), 3L)
-
-    # Row order
-    fit <- lm(cbind(mpg, disp, hp) ~ factor(cyl), data = mtcars)
-    out <- eta_squared(fit, partial = FALSE, ci = NULL)
-    expect_equal(as.character(out$Response), c(""mpg"", ""disp"", ""hp""))
-  })
-
-
-  # Cohen's f - R2 change ---------------------------------------------------
-  test_that(""Cohen's f - R2 change"", {
-    data(hardlyworking)
-    m1 <- lm(salary ~ xtra_hours, data = hardlyworking)
-    m2 <- lm(salary ~ xtra_hours + n_comps, data = hardlyworking)
-
-    fsD <- cohens_f_squared(m1, model2 = m2)[, 1:4]
-    fs <- cohens_f_squared(m2)[-1, -1] # this ONLY works because of the default type-I errors!!!!
-    rownames(fsD) <- rownames(fs) <- 1
-    expect_equal(fsD, fs, tolerance = 0.01, ignore_attr = TRUE)
-
-    fsD <- cohens_f_squared(m1, model2 = m2)
-    R2_1 <- performance::r2(m1)[[1]]
-    R2_2 <- performance::r2(m2)[[1]]
-    expect_equal(
-      fsD$Cohens_f2_partial,
-      unname((R2_2 - R2_1) / (1 - R2_2))
-    )
-  })
-
-  # generalized Eta -------------------------------------------------------------
-  test_that(""generalized | between"", {
-    skip_if_not_installed(""afex"")
-    skip_if_not_installed(""car"")
-
-    data(obk.long, package = ""afex"")
-    m <- suppressWarnings(
-      afex::aov_car(value ~ treatment * gender + Error(id),
-        data = obk.long, observed = ""gender"",
-        include_aov = TRUE
-      )
-    )
-
-    Aov <- car::Anova(m$aov, type = 3)
-
-    expect_equal(
-      anova(m, es = ""ges"", observed = NULL)$ges,
-      eta_squared(Aov, generalized = TRUE, verbose = FALSE)$Eta2_generalized
-    )
-
-
-    expect_equal(
-      anova(m, es = ""ges"", observed = ""gender"")$ges,
-      eta_squared(Aov, generalized = ""gender"", verbose = FALSE)$Eta2_generalized
-    )
-
-    # in a completely between design, with all measured,
-    # all are equal to total
-    expect_equal(
-      eta_squared(Aov, generalized = c(""gender"", ""treatment""), verbose = FALSE)[[2]],
-      eta_squared(Aov, partial = FALSE, verbose = FALSE)[[2]]
-    )
-  })
-
-
-  test_that(""generalized | within-mixed"", {
-    skip_if_not_installed(""afex"")
-    data(obk.long, package = ""afex"")
-
-    # estimate mixed ANOVA on the full design:
-    m <- afex::aov_car(value ~ treatment * gender + Error(id / (phase * hour)),
-      data = obk.long, observed = ""gender"",
-      include_aov = TRUE
-    )
-
-
-    ef <- eta_squared(m$aov, generalized = ""gender"")
-    af <- anova(m, es = ""ges"", observed = ""gender"")
-    expect_equal(ef$Eta2_generalized,
-      c(
-        0.211, 0.083, 0.186, 0.193, 0.099,
-        0.002, 0.015, 0.132, 0.001, 0.004,
-        0.011, 0.016, 0.008, 0.01, 0.02
-      ),
-      tolerance = 0.05
-    )
-    expect_equal(ef$Eta2_generalized,
-      af$ges,
-      tolerance = 0.1
-    )
-
-
-    ef <- eta_squared(m$aov, generalized = TRUE)
-    af <- anova(m, es = ""ges"", observed = NULL)
-    expect_equal(ef$Eta2_generalized,
-      c(
-        0.286, 0.111, 0.218, 0.264, 0.142,
-        0.004, 0.021, 0.185, 0.002, 0.005,
-        0.016, 0.023, 0.013, 0.014, 0.029
-      ),
-      tolerance = 0.05
-    )
-    expect_equal(ef$Eta2_generalized,
-      af$ges,
-      tolerance = 0.1
-    )
-  })
-
-
-
-  # rm-omega ----------------------------------------------------------------
-  test_that(""omega"", {
-    skip_if_not_installed(""afex"")
-    # cross validated with MOTE
-    data(obk.long, package = ""afex"")
-
-    m <- suppressWarnings(
-      afex::aov_car(value ~ treatment * gender + Error(id / (phase)),
-        data = obk.long, observed = ""gender"",
-        include_aov = TRUE
-      )
-    )
-
-
-    ef <- omega_squared(m, partial = TRUE, alternative = ""two"")
-    expect_equal(ef$Omega2_partial,
-      c(0.3115, 0.1814, 0.2221, 0.2637, 0.1512, -0.0173, -0.0171),
-      tolerance = 0.01
-    )
-    expect_equal(ef$CI_low,
-      c(0, 0, 0, 0, 0, 0, 0),
-      tolerance = 0.01
-    )
-
-    expect_equal(ef$CI_high,
-      c(0.626, 0.553, 0.557, 0.518, 0.355, 0, 0),
-      tolerance = 0.01
-    )
-  })
-
-
-  # failed CIs --------------------------------------------------------------
-
-  test_that(""failed CIs"", {
-    library(testthat)
-
-    model <- aov(wt ~ cyl + Error(gear), data = mtcars)
-
-    expect_warning(eta_squared(model), regexp = ""CIs"")
-    expect_warning(eta <- eta_squared(model, verbose = FALSE), regexp = NA)
-    expect_equal(nrow(eta), 2L)
-    expect_equal(eta[1, ""Eta2_partial""], 1)
-
-    expect_warning(eta_squared(model, partial = FALSE), regexp = ""CIs"")
-    expect_warning(eta <- eta_squared(model, partial = FALSE, verbose = FALSE), regexp = NA)
-    expect_equal(nrow(eta), 2L)
-    expect_equal(eta[1, ""Eta2""], 0.34, tolerance = 0.01)
-  })
-
-
-  # Include intercept -------------------------------------------------------
-  test_that(""include_intercept | car"", {
-    skip_on_cran()
-    skip_if_not_installed(""car"")
-
-    m <- lm(mpg ~ factor(cyl) * factor(am), data = mtcars)
-    AOV <- car::Anova(m, type = 3)
-
-    res0 <- eta_squared(AOV, verbose = FALSE)
-    res1 <- eta_squared(AOV, include_intercept = TRUE, verbose = FALSE)
-    expect_equal(nrow(res0), 3)
-    expect_equal(nrow(res1), nrow(res0) + 1)
-    expect_equal(res1[[1]][1], ""(Intercept)"")
-    expect_equal(res1[[2]][1], 0.8680899, tolerance = 0.01)
-
-    res0 <- epsilon_squared(AOV, verbose = FALSE)
-    res1 <- epsilon_squared(AOV, include_intercept = TRUE, verbose = FALSE)
-    expect_equal(nrow(res0), 3)
-    expect_equal(nrow(res1), nrow(res0) + 1)
-    expect_equal(res1[[1]][1], ""(Intercept)"")
-
-
-    res0 <- omega_squared(AOV, verbose = FALSE)
-    res1 <- omega_squared(AOV, include_intercept = TRUE, verbose = FALSE)
-    expect_equal(nrow(res0), 3)
-    expect_equal(nrow(res1), nrow(res0) + 1)
-    expect_equal(res1[[1]][1], ""(Intercept)"")
-
-    # generalized
-    res1 <- eta_squared(AOV, generalized = ""cyl"", include_intercept = TRUE, verbose = FALSE)
-    expect_equal(res1[[1]][1], ""(Intercept)"")
-    expect_equal(res1[[2]][1], 0.784483, tolerance = 0.01)
-  })
-
-
-  test_that(""include_intercept | afex"", {
-    skip_if_not_installed(""afex"")
-    data(obk.long, package = ""afex"")
-
-    suppressWarnings(suppressMessages(
-      a <- afex::aov_car(value ~ treatment * gender + Error(id),
-        include_aov = TRUE,
-        data = obk.long
-      )
-    ))
-
-    resE0 <- eta_squared(a, verbose = FALSE)
-    resA0 <- anova(a, es = ""pes"")
-    expect_equal(nrow(resE0), 3)
-    expect_equal(nrow(resE0), nrow(resA0))
-
-
-    resE1 <- eta_squared(a, include_intercept = TRUE, verbose = FALSE)
-    resA1 <- anova(a, es = ""pes"", intercept = TRUE)
-    expect_equal(nrow(resE1), nrow(resE0) + 1)
-    expect_equal(nrow(resE1), nrow(resA1))
-
-    skip_if_not_installed(""car"")
-    resE1 <- eta_squared(car::Anova(a$aov, type = 3), include_intercept = TRUE, generalized = ""gender"", verbose = FALSE)
-    resA1 <- anova(a, es = ""ges"", intercept = TRUE, observed = ""gender"")
-    expect_equal(resE1[[2]][1], 0.9386555, tolerance = 0.01)
-    expect_equal(resE1[[2]][1], resA1[[5]][1], tolerance = 0.01)
-  })
-
-  # Special cases --------------------------------------------------------------
-
-  ## afex --------------------------------------------------------------------
-  test_that(""afex | within-mixed"", {
-    skip_if_not_installed(""afex"")
-
-    data(obk.long, package = ""afex"")
-
-    mod <- afex::aov_ez(""id"", ""value"", obk.long,
-      between = c(""treatment"", ""gender""),
-      within = c(""phase"", ""hour""),
-      observed = ""gender""
-    )
-
-    x <- eta_squared(mod, generalized = TRUE)
-    a <- anova(mod, observed = ""gender"")
-    expect_equal(a$ges, x$Eta2_generalized)
-
-    x <- eta_squared(mod)
-    a <- anova(mod, es = ""pes"")
-    expect_equal(a$pes, x$Eta2_partial)
-
-
-    x <- eta_squared(mod, include_intercept = TRUE)
-    a <- anova(mod, es = ""pes"", intercept = TRUE)
-    expect_equal(a$pes, x$Eta2_partial)
-
-    # see issue #389
-    data <- data.frame(
-      subject = c(
-        1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
-        2L, 1L, 2L, 1L, 2L, 1L, 2L
-      ),
-      y = c(
-        0.0586978983148275, -0.159870038198774, 0.0125690871484012,
-        -0.0152529928817782, 0.092433880558952, 0.0359796249184537,
-        -0.00786545388312909, 0.0340005375703463, 0.165294695432772,
-        0.0201040753050847, 0.0741924965491503, -0.0345053066539826,
-        0.0108194665250311, -0.163941830205729, 0.310344189786906,
-        -0.106627229564326
-      ),
-      A = c(
-        ""A1"", ""A1"", ""A1"", ""A1"", ""A1"", ""A1"", ""A1"", ""A1"", ""A2"",
-        ""A2"", ""A2"", ""A2"", ""A2"", ""A2"", ""A2"", ""A2""
-      ),
-      B = c(
-        ""B1"", ""B1"", ""B1"", ""B1"", ""B2"", ""B2"", ""B2"", ""B2"", ""B1"",
-        ""B1"", ""B1"", ""B1"", ""B2"", ""B2"", ""B2"", ""B2""
-      ),
-      C = c(
-        ""C1"", ""C1"", ""C2"", ""C2"", ""C1"", ""C1"", ""C2"", ""C2"", ""C1"",
-        ""C1"", ""C2"", ""C2"", ""C1"", ""C1"", ""C2"", ""C2""
-      )
-    )
-    mod <- afex::aov_ez(""subject"", ""y"", data, within = c(""A"", ""B"", ""C""))
-    tab <- as.data.frame(anova(mod, es = ""pes""))
-    res <- eta_squared(mod)
-
-    tab <- tab[order(rownames(tab)), ]
-    res <- res[order(res$Parameter), ]
-
-    expect_equal(res$Eta2_partial, tab$pes, tolerance = 0.001)
-  })
-
-
-  test_that(""afex | mixed()"", {
-    skip_if_not_installed(""afex"")
-    skip_if_not_installed(""lmerTest"")
-    skip_if_not_installed(""base"", minimum_version = ""3.6.1"")
-
-    data(md_15.1, package = ""afex"")
-    # random intercept plus random slope
-    t15.4a <- afex::mixed(iq ~ timecat + (1 + time | id), data = md_15.1)
-    expect_equal(
-      eta_squared(t15.4a),
-      eta_squared(t15.4a$full_model)
-    )
-  })
-
-
-  ## car ---------------------------------------------------------------------
-  test_that(""car MVM"", {
-    skip_if_not_installed(""afex"")
-    skip_if_not_installed(""car"")
-
-    # Simple ---
-    ds <- data.frame(
-      I = c(116, 96, 120, 110, 116, 126, 86, 80),
-      II = c(76, 93, 112, 113, 75, 120, 90, 105),
-      III = c(85, 63, 89, 60, 115, 101, 129, 67),
-      IV = c(50, 87, 100, 60, 79, 70, 65, 65),
-      id = 1:8
-    )
-
-    ds_long <- data.frame(
-      id = c(
-        1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
-        1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
-        1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
-        1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L
-      ),
-      ind_var = c(
-        ""I"", ""I"", ""I"", ""I"", ""I"", ""I"", ""I"", ""I"",
-        ""II"", ""II"", ""II"", ""II"", ""II"", ""II"", ""II"", ""II"",
-        ""III"", ""III"", ""III"", ""III"", ""III"", ""III"", ""III"", ""III"",
-        ""IV"", ""IV"", ""IV"", ""IV"", ""IV"", ""IV"", ""IV"", ""IV""
-      ),
-      score = c(
-        116, 96, 120, 110, 116, 126, 86, 80,
-        76, 93, 112, 113, 75, 120, 90, 105,
-        85, 63, 89, 60, 115, 101, 129, 67,
-        50, 87, 100, 60, 79, 70, 65, 65
-      )
-    )
-
-
-
-    fit <- lm(cbind(I, II, III, IV) ~ 1, data = ds)
-    in_rep <- data.frame(ind_var = gl(4, 1))
-    A_car <- car::Anova(fit, idata = in_rep, idesign = ~ind_var)
-
-    eta_car <- effectsize::eta_squared(A_car, ci = NULL)[[2]]
-
-    eta_afex <- afex::aov_ez(""id"", ""score"", ds_long,
-      within = ""ind_var"",
-      anova_table = list(es = ""pes"")
-    )$anova_table$pes
-
-    expect_equal(eta_car, eta_afex)
-
-    # Complex ---
-    data(obk.long, package = ""afex"")
-
-    mod <- afex::aov_ez(""id"", ""value"", obk.long,
-      between = c(""treatment"", ""gender""),
-      within = c(""phase"", ""hour""),
-      observed = ""gender""
-    )
-    expect_equal(
-      sort(eta_squared(mod$Anova, generalized = ""gender"")[[2]]),
-      sort(mod$anova_table$ges)
-    )
-  })
-
-
-  test_that(""Anova.mlm Manova"", {
-    skip_if_not_installed(""car"")
-
-    data(""mtcars"")
-    mtcars$am_f <- factor(mtcars$am)
-    mtcars$cyl_f <- factor(mtcars$cyl)
-
-    mod <- lm(cbind(mpg, qsec) ~ am_f * cyl_f, data = mtcars)
-
-    Manova <- car::Manova(mod)
-
-    expect_true(is.null(summary(Manova, univariate = TRUE)[[""univariate.tests""]]))
-    expect_error(eta_squared(Manova), regexp = NA)
-    expect_equal(
-      eta_squared(manova(mod))[[2]][2:3],
-      eta_squared(Manova)[[2]][2:3]
-    )
-  })
-
-  ## merMod --------------------
-
-  test_that(""merMod and lmerModLmerTest"", {
-    skip_if_not_installed(""lmerTest"")
-    skip_if_not_installed(""lme4"")
-
-    data(""sleepstudy"", package = ""lme4"")
-
-    m <- lme4::lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
-    mtest <- lmerTest::lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
-
-    expect_equal(
-      eta_squared(m),
-      eta_squared(mtest)
-    )
-  })
-
-
-  ## tidymodels -------------------
-  test_that(""ets_squared | tidymodels"", {
-    skip_on_cran()
-    skip_if_not_installed(""parsnip"")
-    skip_if_not_installed(""base"", minimum_version = ""3.6.1"")
-
-    set.seed(123)
-    mod_lm <- parsnip::linear_reg(engine = ""lm"", mode = ""regression"")
-    mod_lm <- parsnip::fit(mod_lm, mpg ~ am + vs, data = mtcars)
-
-    set.seed(123)
-    tidy_lm <- eta_squared(mod_lm)
-    lm_lm <- eta_squared(lm(mpg ~ am + vs, data = mtcars))
 
-    expect_equal(tidy_lm, lm_lm, tolerance = 0.001)
-  })
+# anova() -----------------------------------------------------------------
+test_that(""anova()"", {
+  # Make minimal ANOVA table
+  mod <- anova(lm(mpg ~ cyl + hp, mtcars))
+
+  mod1 <- mod
+  mod1$DenDF <- mod1$Df[nrow(mod1)]
+  mod1 <- mod1[-nrow(mod1), ]
+
+  expect_error(eta_squared(mod1), regexp = NA)
+  expect_equal(
+    eta_squared(mod1)[, -1],
+    F_to_eta2(mod1[[""F value""]], mod1$Df, mod1$DenDF),
+    ignore_attr = TRUE
+  )
+  expect_warning(eta_squared(mod1, partial = FALSE), ""partial"")
+  expect_warning(eta_squared(mod1, generalized = TRUE), ""generalized"")
+
+  mod2 <- mod1
+  mod2$`F value` <- NULL
+  expect_error(eta_squared(mod2), ""does not"")
+})
+
+# aov ---------------------------------------------------------------------
+test_that(""aov"", {
+  df <- iris
+  df$Sepal.Big <- ifelse(df$Sepal.Width >= 3, ""Yes"", ""No"")
+
+  fit <- aov(Sepal.Length ~ Species * Sepal.Big, df)
+
+  # eta
+  expect_equal(eta_squared(fit, partial = FALSE)$Eta2,
+               c(0.618, 0.046, 0.000),
+               tolerance = 0.01
+  )
+  expect_equal(eta_squared(fit, partial = TRUE)$Eta2_partial,
+               c(0.649, 0.121, 0.001),
+               tolerance = 0.01
+  )
+
+  # omega
+  expect_equal(omega_squared(fit, partial = FALSE)$Omega2,
+               c(0.612, 0.043, -0.004),
+               tolerance = 0.01
+  )
+  expect_equal(omega_squared(fit, partial = TRUE)$Omega2_partial,
+               c(0.638, 0.112, -0.012),
+               tolerance = 0.01
+  )
+
+  # epsilon
+  expect_equal(epsilon_squared(fit, partial = FALSE)$Epsilon2,
+               c(0.614, 0.044, -0.004),
+               tolerance = 0.001
+  )
+  expect_equal(epsilon_squared(fit, partial = TRUE)$Epsilon2_partial,
+               c(0.644, 0.115, -0.012),
+               tolerance = 0.01
+  )
+
+  # Cohen's f/f2
+  expect_equal(cohens_f_squared(fit, partial = FALSE)$Cohens_f2,
+               c(1.623, 0.049, 0.000),
+               tolerance = 0.001
+  )
+  expect_equal(cohens_f_squared(fit, partial = TRUE)$Cohens_f2_partial,
+               c(1.850, 0.139, 0.001),
+               tolerance = 0.001
+  )
+  expect_equal(cohens_f(fit, partial = FALSE)$Cohens_f,
+               c(1.273, 0.220, 0.021),
+               tolerance = 0.01
+  )
+  expect_equal(cohens_f(fit, partial = TRUE)$Cohens_f_partial,
+               c(1.360, 0.373, 0.036),
+               tolerance = 0.001
+  )
+  expect_equal(cohens_f(fit, squared = TRUE), cohens_f_squared(fit))
+  expect_equal(cohens_f_squared(fit, squared = FALSE), cohens_f(fit))
+
+
+
+  #### One way-between
+  expect_message(eta_squared(aov(mpg ~ factor(gear), mtcars)))
+  expect_message(eta_squared(aov(mpg ~ factor(gear) + am, mtcars)), regexp = NA)
+
+  #### Alternative
+  m <<- aov(mpg ~ factor(gear) + am, mtcars)
+  et1 <- eta_squared(m)
+  et2 <- eta_squared(m, ci = 0.9, alternative = ""two.sided"")
+  expect_equal(et1$CI_low, et2$CI_low)
+
+  ### parameters:
+  expect_equal(
+    eta_squared(parameters::model_parameters(m)),
+    eta_squared(m)
+  )
+})
+
+
+# aovlist -----------------------------------------------------------------
+test_that(""aovlist"", {
+  skip_on_cran()
+  df <- iris
+  df$Sepal.Big <- ifelse(df$Sepal.Width >= 3, ""Yes"", ""No"")
+
+  model <<- aov(Sepal.Length ~ Sepal.Big + Error(Species), data = df)
+
+  res <- eta_squared(model, partial = TRUE)
+  expect_true(all(c(""Group"", ""Parameter"") %in% colnames(res)))
+  expect_equal(res$Eta2_partial, c(0.4472423, 0.1217329), tolerance = 0.001)
+  expect_equal(eta_squared(model, partial = FALSE)$Eta2,
+               c(0.27671136, 0.04641607),
+               tolerance = 0.001
+  )
+
+  res <- omega_squared(model, partial = TRUE)
+  expect_true(all(c(""Group"", ""Parameter"") %in% colnames(res)))
+  expect_equal(res$Omega2_partial, c(-0.06795358, 0.04141846), tolerance = 0.001)
+  expect_equal(omega_squared(model, partial = FALSE)$Omega2,
+               c(-0.04864626, 0.03287821),
+               tolerance = 0.001
+  )
+
+  res <- epsilon_squared(model, partial = TRUE)
+  expect_true(all(c(""Group"", ""Parameter"") %in% colnames(res)))
+  expect_equal(res$Epsilon2_partial, c(-0.1055154, 0.1157174), tolerance = 0.001)
+  expect_equal(epsilon_squared(model, partial = FALSE)$Epsilon2,
+               c(-0.06528301, 0.04412238),
+               tolerance = 0.001
+  )
+
+
+  expect_equal(
+    eta_squared(parameters::model_parameters(model)),
+    eta_squared(model)
+  )
+
+
+  skip_if_not_installed(""afex"")
+  # non-partial Eta2 should be the same for aov and aovlist
+  data(obk.long, package = ""afex"")
+  model <- afex::aov_car(value ~ treatment * gender + Error(id / (phase * hour)),
+                         data = obk.long, observed = ""gender"",
+                         include_aov = TRUE
+  )
+
+  model2 <- aov(value ~ treatment * gender * phase * hour,
+                data = model$data$long,
+                contrasts = list(
+                  treatment = contr.sum,
+                  gender = contr.sum,
+                  phase = contr.sum,
+                  hour = contr.sum
+                )
+  )
+
+  a1 <- eta_squared(model2, partial = FALSE)
+  a2 <- eta_squared(model$aov, partial = FALSE)
+
+  rownames(a1) <- a1$Parameter
+  rownames(a2) <- a2$Parameter
+
+  expect_equal(
+    a1[a1$Parameter, ""Eta2""],
+    a2[a1$Parameter, ""Eta2""]
+  )
+})
+
+# mlm / anova table -------------------------------------------------------
+test_that(""mlm / anova table"", {
+  data(""mtcars"")
+  mtcars$am_f <- factor(mtcars$am)
+  mtcars$cyl_f <- factor(mtcars$cyl)
+
+  mod <- lm(cbind(mpg, qsec) ~ am_f * cyl_f, data = mtcars)
+  m1 <- lm(mpg ~ am_f * cyl_f, data = mtcars)
+  m2 <- lm(qsec ~ am_f * cyl_f, data = mtcars)
+
+  expect_equal(
+    eta_squared(mod)$Eta2_partial[1:3],
+    eta_squared(m1)$Eta2_partial
+  )
+
+  expect_equal(
+    eta_squared(mod)$Eta2_partial[4:6],
+    eta_squared(m2)$Eta2_partial
+  )
+
+  expect_equal(
+    eta_squared(mod, partial = FALSE)$Eta2[1:3],
+    eta_squared(m1, partial = FALSE)$Eta2
+  )
+
+  expect_equal(
+    eta_squared(mod, partial = FALSE)$Eta2[4:6],
+    eta_squared(m2, partial = FALSE)$Eta2
+  )
+
+  # MANOVA table
+  mod <- manova(cbind(mpg, qsec) ~ am_f * cyl_f, data = mtcars)
+  expect_equal(nrow(eta_squared(mod)), 3L)
+
+  # Row order
+  fit <- lm(cbind(mpg, disp, hp) ~ factor(cyl), data = mtcars)
+  out <- eta_squared(fit, partial = FALSE, ci = NULL)
+  expect_equal(as.character(out$Response), c(""mpg"", ""disp"", ""hp""))
+})
+
+
+# Cohen's f - R2 change ---------------------------------------------------
+test_that(""Cohen's f - R2 change"", {
+  data(hardlyworking)
+  m1 <- lm(salary ~ xtra_hours, data = hardlyworking)
+  m2 <- lm(salary ~ xtra_hours + n_comps, data = hardlyworking)
+
+  fsD <- cohens_f_squared(m1, model2 = m2)[, 1:4]
+  fs <- cohens_f_squared(m2)[-1, -1] # this ONLY works because of the default type-I errors!!!!
+  rownames(fsD) <- rownames(fs) <- 1
+  expect_equal(fsD, fs, tolerance = 0.01, ignore_attr = TRUE)
+
+  fsD <- cohens_f_squared(m1, model2 = m2)
+  R2_1 <- performance::r2(m1)[[1]]
+  R2_2 <- performance::r2(m2)[[1]]
+  expect_equal(
+    fsD$Cohens_f2_partial,
+    unname((R2_2 - R2_1) / (1 - R2_2))
+  )
+})
+
+# generalized Eta -------------------------------------------------------------
+test_that(""generalized | between"", {
+  skip_if_not_installed(""afex"")
+  skip_if_not_installed(""car"")
+
+  data(obk.long, package = ""afex"")
+  m <- suppressWarnings(
+    afex::aov_car(value ~ treatment * gender + Error(id),
+                  data = obk.long, observed = ""gender"",
+                  include_aov = TRUE
+    )
+  )
+
+  Aov <- car::Anova(m$aov, type = 3)
+
+  expect_equal(
+    anova(m, es = ""ges"", observed = NULL)$ges,
+    eta_squared(Aov, generalized = TRUE, verbose = FALSE)$Eta2_generalized
+  )
+
+
+  expect_equal(
+    anova(m, es = ""ges"", observed = ""gender"")$ges,
+    eta_squared(Aov, generalized = ""gender"", verbose = FALSE)$Eta2_generalized
+  )
+
+  # in a completely between design, with all measured,
+  # all are equal to total
+  expect_equal(
+    eta_squared(Aov, generalized = c(""gender"", ""treatment""), verbose = FALSE)[[2]],
+    eta_squared(Aov, partial = FALSE, verbose = FALSE)[[2]]
+  )
+})
+
+
+test_that(""generalized | within-mixed"", {
+  skip_if_not_installed(""afex"")
+  data(obk.long, package = ""afex"")
+
+  # estimate mixed ANOVA on the full design:
+  m <- afex::aov_car(value ~ treatment * gender + Error(id / (phase * hour)),
+                     data = obk.long, observed = ""gender"",
+                     include_aov = TRUE
+  )
+
+
+  ef <- eta_squared(m$aov, generalized = ""gender"")
+  af <- anova(m, es = ""ges"", observed = ""gender"")
+  expect_equal(ef$Eta2_generalized,
+               c(
+                 0.211, 0.083, 0.186, 0.193, 0.099,
+                 0.002, 0.015, 0.132, 0.001, 0.004,
+                 0.011, 0.016, 0.008, 0.01, 0.02
+               ),
+               tolerance = 0.05
+  )
+  expect_equal(ef$Eta2_generalized,
+               af$ges,
+               tolerance = 0.1
+  )
+
+
+  ef <- eta_squared(m$aov, generalized = TRUE)
+  af <- anova(m, es = ""ges"", observed = NULL)
+  expect_equal(ef$Eta2_generalized,
+               c(
+                 0.286, 0.111, 0.218, 0.264, 0.142,
+                 0.004, 0.021, 0.185, 0.002, 0.005,
+                 0.016, 0.023, 0.013, 0.014, 0.029
+               ),
+               tolerance = 0.05
+  )
+  expect_equal(ef$Eta2_generalized,
+               af$ges,
+               tolerance = 0.1
+  )
+})
+
+
+
+# rm-omega ----------------------------------------------------------------
+test_that(""omega"", {
+  skip_if_not_installed(""afex"")
+  # cross validated with MOTE
+  data(obk.long, package = ""afex"")
+
+  m <- suppressWarnings(
+    afex::aov_car(value ~ treatment * gender + Error(id / (phase)),
+                  data = obk.long, observed = ""gender"",
+                  include_aov = TRUE
+    )
+  )
+
+
+  ef <- omega_squared(m, partial = TRUE, alternative = ""two"")
+  expect_equal(ef$Omega2_partial,
+               c(0.3115, 0.1814, 0.2221, 0.2637, 0.1512, -0.0173, -0.0171),
+               tolerance = 0.01
+  )
+  expect_equal(ef$CI_low,
+               c(0, 0, 0, 0, 0, 0, 0),
+               tolerance = 0.01
+  )
+
+  expect_equal(ef$CI_high,
+               c(0.626, 0.553, 0.557, 0.518, 0.355, 0, 0),
+               tolerance = 0.01
+  )
+})
+
+
+# failed CIs --------------------------------------------------------------
+
+test_that(""failed CIs"", {
+  model <- aov(wt ~ cyl + Error(gear), data = mtcars)
+
+  expect_warning(eta_squared(model), regexp = ""CIs"")
+  expect_warning(eta <- eta_squared(model, verbose = FALSE), regexp = NA)
+  expect_equal(nrow(eta), 2L)
+  expect_equal(eta[1, ""Eta2_partial""], 1)
+
+  expect_warning(eta_squared(model, partial = FALSE), regexp = ""CIs"")
+  expect_warning(eta <- eta_squared(model, partial = FALSE, verbose = FALSE), regexp = NA)
+  expect_equal(nrow(eta), 2L)
+  expect_equal(eta[1, ""Eta2""], 0.34, tolerance = 0.01)
+})
+
+
+# Include intercept -------------------------------------------------------
+test_that(""include_intercept | car"", {
+  skip_on_cran()
+  skip_if_not_installed(""car"")
+
+  m <- lm(mpg ~ factor(cyl) * factor(am), data = mtcars)
+  AOV <- car::Anova(m, type = 3)
+
+  res0 <- eta_squared(AOV, verbose = FALSE)
+  res1 <- eta_squared(AOV, include_intercept = TRUE, verbose = FALSE)
+  expect_equal(nrow(res0), 3)
+  expect_equal(nrow(res1), nrow(res0) + 1)
+  expect_equal(res1[[1]][1], ""(Intercept)"")
+  expect_equal(res1[[2]][1], 0.8680899, tolerance = 0.01)
+
+  res0 <- epsilon_squared(AOV, verbose = FALSE)
+  res1 <- epsilon_squared(AOV, include_intercept = TRUE, verbose = FALSE)
+  expect_equal(nrow(res0), 3)
+  expect_equal(nrow(res1), nrow(res0) + 1)
+  expect_equal(res1[[1]][1], ""(Intercept)"")
+
+
+  res0 <- omega_squared(AOV, verbose = FALSE)
+  res1 <- omega_squared(AOV, include_intercept = TRUE, verbose = FALSE)
+  expect_equal(nrow(res0), 3)
+  expect_equal(nrow(res1), nrow(res0) + 1)
+  expect_equal(res1[[1]][1], ""(Intercept)"")
+
+  # generalized
+  res1 <- eta_squared(AOV, generalized = ""cyl"", include_intercept = TRUE, verbose = FALSE)
+  expect_equal(res1[[1]][1], ""(Intercept)"")
+  expect_equal(res1[[2]][1], 0.784483, tolerance = 0.01)
+})
+
+
+test_that(""include_intercept | afex"", {
+  skip_if_not_installed(""afex"")
+  data(obk.long, package = ""afex"")
+
+  suppressWarnings(suppressMessages(
+    a <- afex::aov_car(value ~ treatment * gender + Error(id),
+                       include_aov = TRUE,
+                       data = obk.long
+    )
+  ))
+
+  resE0 <- eta_squared(a, verbose = FALSE)
+  resA0 <- anova(a, es = ""pes"")
+  expect_equal(nrow(resE0), 3)
+  expect_equal(nrow(resE0), nrow(resA0))
+
+
+  resE1 <- eta_squared(a, include_intercept = TRUE, verbose = FALSE)
+  resA1 <- anova(a, es = ""pes"", intercept = TRUE)
+  expect_equal(nrow(resE1), nrow(resE0) + 1)
+  expect_equal(nrow(resE1), nrow(resA1))
+
+  skip_if_not_installed(""car"")
+  resE1 <- eta_squared(car::Anova(a$aov, type = 3), include_intercept = TRUE, generalized = ""gender"", verbose = FALSE)
+  resA1 <- anova(a, es = ""ges"", intercept = TRUE, observed = ""gender"")
+  expect_equal(resE1[[2]][1], 0.9386555, tolerance = 0.01)
+  expect_equal(resE1[[2]][1], resA1[[5]][1], tolerance = 0.01)
+})
+
+# Special cases --------------------------------------------------------------
+
+## afex --------------------------------------------------------------------
+test_that(""afex | within-mixed"", {
+  skip_if_not_installed(""afex"")
+
+  data(obk.long, package = ""afex"")
+
+  mod <- afex::aov_ez(""id"", ""value"", obk.long,
+                      between = c(""treatment"", ""gender""),
+                      within = c(""phase"", ""hour""),
+                      observed = ""gender""
+  )
+
+  x <- eta_squared(mod, generalized = TRUE)
+  a <- anova(mod, observed = ""gender"")
+  expect_equal(a$ges, x$Eta2_generalized)
+
+  x <- eta_squared(mod)
+  a <- anova(mod, es = ""pes"")
+  expect_equal(a$pes, x$Eta2_partial)
+
+
+  x <- eta_squared(mod, include_intercept = TRUE)
+  a <- anova(mod, es = ""pes"", intercept = TRUE)
+  expect_equal(a$pes, x$Eta2_partial)
+
+  # see issue #389
+  data <- data.frame(
+    subject = c(
+      1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
+      2L, 1L, 2L, 1L, 2L, 1L, 2L
+    ),
+    y = c(
+      0.0586978983148275, -0.159870038198774, 0.0125690871484012,
+      -0.0152529928817782, 0.092433880558952, 0.0359796249184537,
+      -0.00786545388312909, 0.0340005375703463, 0.165294695432772,
+      0.0201040753050847, 0.0741924965491503, -0.0345053066539826,
+      0.0108194665250311, -0.163941830205729, 0.310344189786906,
+      -0.106627229564326
+    ),
+    A = c(
+      ""A1"", ""A1"", ""A1"", ""A1"", ""A1"", ""A1"", ""A1"", ""A1"", ""A2"",
+      ""A2"", ""A2"", ""A2"", ""A2"", ""A2"", ""A2"", ""A2""
+    ),
+    B = c(
+      ""B1"", ""B1"", ""B1"", ""B1"", ""B2"", ""B2"", ""B2"", ""B2"", ""B1"",
+      ""B1"", ""B1"", ""B1"", ""B2"", ""B2"", ""B2"", ""B2""
+    ),
+    C = c(
+      ""C1"", ""C1"", ""C2"", ""C2"", ""C1"", ""C1"", ""C2"", ""C2"", ""C1"",
+      ""C1"", ""C2"", ""C2"", ""C1"", ""C1"", ""C2"", ""C2""
+    )
+  )
+  mod <- afex::aov_ez(""subject"", ""y"", data, within = c(""A"", ""B"", ""C""))
+  tab <- as.data.frame(anova(mod, es = ""pes""))
+  res <- eta_squared(mod)
+
+  tab <- tab[order(rownames(tab)), ]
+  res <- res[order(res$Parameter), ]
+
+  expect_equal(res$Eta2_partial, tab$pes, tolerance = 0.001)
+})
+
+
+test_that(""afex | mixed()"", {
+  skip_if_not_installed(""afex"")
+  skip_if_not_installed(""lmerTest"")
+  skip_if_not_installed(""base"", minimum_version = ""3.6.1"")
+
+  data(md_15.1, package = ""afex"")
+  # random intercept plus random slope
+  t15.4a <- afex::mixed(iq ~ timecat + (1 + time | id), data = md_15.1)
+  expect_equal(
+    eta_squared(t15.4a),
+    eta_squared(t15.4a$full_model)
+  )
+})
+
+
+## car ---------------------------------------------------------------------
+test_that(""car MVM"", {
+  skip_if_not_installed(""afex"")
+  skip_if_not_installed(""car"")
+
+  # Simple ---
+  ds <- data.frame(
+    I = c(116, 96, 120, 110, 116, 126, 86, 80),
+    II = c(76, 93, 112, 113, 75, 120, 90, 105),
+    III = c(85, 63, 89, 60, 115, 101, 129, 67),
+    IV = c(50, 87, 100, 60, 79, 70, 65, 65),
+    id = 1:8
+  )
+
+  ds_long <- data.frame(
+    id = c(
+      1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
+      1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
+      1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
+      1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L
+    ),
+    ind_var = c(
+      ""I"", ""I"", ""I"", ""I"", ""I"", ""I"", ""I"", ""I"",
+      ""II"", ""II"", ""II"", ""II"", ""II"", ""II"", ""II"", ""II"",
+      ""III"", ""III"", ""III"", ""III"", ""III"", ""III"", ""III"", ""III"",
+      ""IV"", ""IV"", ""IV"", ""IV"", ""IV"", ""IV"", ""IV"", ""IV""
+    ),
+    score = c(
+      116, 96, 120, 110, 116, 126, 86, 80,
+      76, 93, 112, 113, 75, 120, 90, 105,
+      85, 63, 89, 60, 115, 101, 129, 67,
+      50, 87, 100, 60, 79, 70, 65, 65
+    )
+  )
+
+
+
+  fit <- lm(cbind(I, II, III, IV) ~ 1, data = ds)
+  in_rep <- data.frame(ind_var = gl(4, 1))
+  A_car <- car::Anova(fit, idata = in_rep, idesign = ~ind_var)
+
+  eta_car <- effectsize::eta_squared(A_car, ci = NULL)[[2]]
+
+  eta_afex <- afex::aov_ez(""id"", ""score"", ds_long,
+                           within = ""ind_var"",
+                           anova_table = list(es = ""pes"")
+  )$anova_table$pes
+
+  expect_equal(eta_car, eta_afex)
+
+  # Complex ---
+  data(obk.long, package = ""afex"")
+
+  mod <- afex::aov_ez(""id"", ""value"", obk.long,
+                      between = c(""treatment"", ""gender""),
+                      within = c(""phase"", ""hour""),
+                      observed = ""gender""
+  )
+  expect_equal(
+    sort(eta_squared(mod$Anova, generalized = ""gender"")[[2]]),
+    sort(mod$anova_table$ges)
+  )
+})
+
+
+test_that(""Anova.mlm Manova"", {
+  skip_if_not_installed(""car"")
+
+  data(""mtcars"")
+  mtcars$am_f <- factor(mtcars$am)
+  mtcars$cyl_f <- factor(mtcars$cyl)
+
+  mod <- lm(cbind(mpg, qsec) ~ am_f * cyl_f, data = mtcars)
+
+  Manova <- car::Manova(mod)
+
+  expect_true(is.null(summary(Manova, univariate = TRUE)[[""univariate.tests""]]))
+  expect_error(eta_squared(Manova), regexp = NA)
+  expect_equal(
+    eta_squared(manova(mod))[[2]][2:3],
+    eta_squared(Manova)[[2]][2:3]
+  )
+})
+
+## merMod --------------------
+
+test_that(""merMod and lmerModLmerTest"", {
+  skip_if_not_installed(""lmerTest"")
+  skip_if_not_installed(""lme4"")
+
+  data(""sleepstudy"", package = ""lme4"")
+
+  m <- lme4::lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
+  mtest <- lmerTest::lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
+
+  expect_equal(
+    eta_squared(m),
+    eta_squared(mtest)
+  )
+})
+
+
+## tidymodels -------------------
+test_that(""ets_squared | tidymodels"", {
+  skip_on_cran()
+  skip_if_not_installed(""parsnip"")
+  skip_if_not_installed(""base"", minimum_version = ""3.6.1"")
+
+  set.seed(123)
+  mod_lm <- parsnip::linear_reg(engine = ""lm"", mode = ""regression"")
+  mod_lm <- parsnip::fit(mod_lm, mpg ~ am + vs, data = mtcars)
+
+  set.seed(123)
+  tidy_lm <- eta_squared(mod_lm)
+  lm_lm <- eta_squared(lm(mpg ~ am + vs, data = mtcars))
+
+  expect_equal(tidy_lm, lm_lm, tolerance = 0.001)
+})
 
 
-  ## GAMs -------------------
-  test_that(""ets_squared | gam"", {
-    skip_on_cran()
-    skip_if_not_installed(""mgcv"")
+## GAMs -------------------
+test_that(""ets_squared | gam"", {
+  skip_on_cran()
+  skip_if_not_installed(""mgcv"")
 
-    set.seed(2) ## simulate some data...
-    dat <- mgcv::gamSim(1, n = 400, dist = ""normal"", scale = 2)
-    b <- mgcv::gam(y ~ x0 + s(x1) + s(x2) + t2(x1, x2) + s(x3), data = dat)
+  set.seed(2) ## simulate some data...
+  dat <- mgcv::gamSim(1, n = 400, dist = ""normal"", scale = 2)
+  b <- mgcv::gam(y ~ x0 + s(x1) + s(x2) + t2(x1, x2) + s(x3), data = dat)
 
-    expect_error(out <- eta_squared(b), regexp = NA)
-    expect_output(print(out), ""Type III"")
-  })
+  expect_error(out <- eta_squared(b), regexp = NA)
+  expect_output(print(out), ""Type III"")
+})
 
-  ## rms -------------------
-  test_that(""ets_squared | rms"", {
-    skip_on_cran()
-    skip_if_not_installed(""rms"")
-    data(""mtcars"")
+## rms -------------------
+test_that(""ets_squared | rms"", {
+  skip_on_cran()
+  skip_if_not_installed(""rms"")
+  data(""mtcars"")
 
-    b <- rms::ols(mpg ~ cyl + am, data = mtcars)
-    expect_error(out <- eta_squared(b), regexp = NA)
-    expect_output(print(out), ""Type II"")
+  b <- rms::ols(mpg ~ cyl + am, data = mtcars)
+  expect_error(out <- eta_squared(b), regexp = NA)
+  expect_output(print(out), ""Type II"")
 
-    skip_if_not_installed(""car"")
-    skip_if_not_installed(""base"", minimum_version = ""3.6.1"")
-    b_lm <- car::Anova(lm(mpg ~ cyl + am, data = mtcars), type = 2)
-    out_lm <- eta_squared(b_lm)
-    expect_equal(out[1:2, ], out_lm, ignore_attr = TRUE)
-  })
-}
+  skip_if_not_installed(""car"")
+  skip_if_not_installed(""base"", minimum_version = ""3.6.1"")
+  b_lm <- car::Anova(lm(mpg ~ cyl + am, data = mtcars), type = 2)
+  out_lm <- eta_squared(b_lm)
+  expect_equal(out[1:2, ], out_lm, ignore_attr = TRUE)
+})

---FILE: tests/testthat/test-eta_squared_posterior.R---
@@ -1,48 +1,47 @@
-if (require(""testthat"") && require(""effectsize"")) {
-  test_that(""eta_squared_posterior"", {
-    skip_on_cran()
-    skip_if_not_installed(""rstanarm"")
-    skip_if_not_installed(""bayestestR"")
-    skip_if_not_installed(""car"")
-
-    set.seed(444)
-    data(""mtcars"")
-    mtcars$cyl <- factor(mtcars$cyl)
-
-    fit_bayes <- rstanarm::stan_glm(mpg ~ cyl * wt + qsec,
-      data = mtcars,
-      family = gaussian(),
-      refresh = 0
-    )
-
-
-    # PARTIAL, type = 3 -------------------------------------------------------
-    mod <- lm(mpg ~ cyl * wt + qsec, data = mtcars)
-    a <- car::Anova(mod, type = 3)
-    es_tab <- eta_squared(a, partial = TRUE)
-
-    es_post <- eta_squared_posterior(fit_bayes,
-      ss_function = car::Anova, type = 3
-    )
-    expect_equal(colnames(es_post), es_tab$Parameter)
-
-    # this is a very soft test...
-    es_tab_bayes <- bayestestR::describe_posterior(es_post)
-    expect_equal(order(es_tab_bayes$Median), order(es_tab$Eta2))
-
-
-
-    # non-PARTIAL, type = 3 ---------------------------------------------------
-    es_tab <- eta_squared(a, partial = FALSE)
-
-    es_post <- eta_squared_posterior(fit_bayes,
-      partial = FALSE,
-      ss_function = car::Anova, type = 3
-    )
-    expect_equal(colnames(es_post), es_tab$Parameter)
-
-    # this is a very soft test...
-    es_tab_bayes <- bayestestR::describe_posterior(es_post)
-    expect_equal(order(es_tab_bayes$Median), order(es_tab$Eta2))
-  })
-}
+
+test_that(""eta_squared_posterior"", {
+  skip_on_cran()
+  skip_if_not_installed(""rstanarm"")
+  skip_if_not_installed(""bayestestR"")
+  skip_if_not_installed(""car"")
+
+  set.seed(444)
+  data(""mtcars"")
+  mtcars$cyl <- factor(mtcars$cyl)
+
+  fit_bayes <- rstanarm::stan_glm(mpg ~ cyl * wt + qsec,
+                                  data = mtcars,
+                                  family = gaussian(),
+                                  refresh = 0
+  )
+
+
+  # PARTIAL, type = 3 -------------------------------------------------------
+  mod <- lm(mpg ~ cyl * wt + qsec, data = mtcars)
+  a <- car::Anova(mod, type = 3)
+  es_tab <- eta_squared(a, partial = TRUE)
+
+  es_post <- eta_squared_posterior(fit_bayes,
+                                   ss_function = car::Anova, type = 3
+  )
+  expect_equal(colnames(es_post), es_tab$Parameter)
+
+  # this is a very soft test...
+  es_tab_bayes <- bayestestR::describe_posterior(es_post)
+  expect_equal(order(es_tab_bayes$Median), order(es_tab$Eta2))
+
+
+
+  # non-PARTIAL, type = 3 ---------------------------------------------------
+  es_tab <- eta_squared(a, partial = FALSE)
+
+  es_post <- eta_squared_posterior(fit_bayes,
+                                   partial = FALSE,
+                                   ss_function = car::Anova, type = 3
+  )
+  expect_equal(colnames(es_post), es_tab$Parameter)
+
+  # this is a very soft test...
+  es_tab_bayes <- bayestestR::describe_posterior(es_post)
+  expect_equal(order(es_tab_bayes$Median), order(es_tab$Eta2))
+})

---FILE: tests/testthat/test-format_standardize.R---
@@ -1,36 +1,35 @@
-if (require(""testthat"") && require(""effectsize"")) {
-  test_that(""format_standardize"", {
-    expect_equal(
-      format_standardize(c(-1, 0, 1), digits = 0),
-      structure(3:1, .Label = c(""+1 SD"", ""Mean"", ""-1 SD""), class = ""factor"")
-    )
+
+test_that(""format_standardize"", {
+  expect_equal(
+    format_standardize(c(-1, 0, 1), digits = 0),
+    structure(3:1, .Label = c(""+1 SD"", ""Mean"", ""-1 SD""), class = ""factor"")
+  )
 
 
-    skip_if_not_installed(""bayestestR"")
-    ref <- bayestestR::distribution_normal(1000)
+  skip_if_not_installed(""bayestestR"")
+  ref <- bayestestR::distribution_normal(1000)
 
-    expect_equal(
-      format_standardize(c(-1, 0, 1, 2), reference = ref, digits = 0),
-      structure(4:1,
-        .Label = c(""+2 SD"", ""+1 SD"", ""Mean"", ""-1 SD""),
-        class = ""factor""
-      )
+  expect_equal(
+    format_standardize(c(-1, 0, 1, 2), reference = ref, digits = 0),
+    structure(4:1,
+              .Label = c(""+2 SD"", ""+1 SD"", ""Mean"", ""-1 SD""),
+              class = ""factor""
     )
+  )
 
-    expect_equal(
-      format_standardize(c(-1, 0, 1, 2), reference = ref, robust = TRUE, digits = 0),
-      structure(4:1,
-        .Label = c(""+2 MAD"", ""+1 MAD"", ""Median"", ""-1 MAD""),
-        class = ""factor""
-      )
+  expect_equal(
+    format_standardize(c(-1, 0, 1, 2), reference = ref, robust = TRUE, digits = 0),
+    structure(4:1,
+              .Label = c(""+2 MAD"", ""+1 MAD"", ""Median"", ""-1 MAD""),
+              class = ""factor""
     )
+  )
 
-    expect_equal(
-      format_standardize(c(-1, 0, 1, 2), reference = ref, robust = TRUE, digits = 2, protect_integers = FALSE),
-      structure(4:1,
-        .Label = c(""+2.00 MAD"", ""+1.00 MAD"", ""Median"", ""-1.00 MAD""),
-        class = ""factor""
-      )
+  expect_equal(
+    format_standardize(c(-1, 0, 1, 2), reference = ref, robust = TRUE, digits = 2, protect_integers = FALSE),
+    structure(4:1,
+              .Label = c(""+2.00 MAD"", ""+1.00 MAD"", ""Median"", ""-1.00 MAD""),
+              class = ""factor""
     )
-  })
-}
+  )
+})

---FILE: tests/testthat/test-helpers.R---
@@ -1,65 +1,64 @@
-if (require(""testthat"") && require(""effectsize"")) {
-  test_that(""is_effectsize_name works"", {
-    expect_false(is_effectsize_name(""is_effectsize_name""))
-    expect_true(is_effectsize_name(""Eta2""))
-    expect_equal(get_effectsize_label(""hEDgES_G""), ""Hedges' g"")
-  })
 
-  test_that(""validate data from formula"", {
-    expect_error(cohens_d(mpg ~ cyl, data = mtcars), ""exactly"")
-    expect_error(cohens_d(mpg ~ cyl, data = mtcars, subset = cyl %in% c(4, 6)), regexp = NA)
+test_that(""is_effectsize_name works"", {
+  expect_false(is_effectsize_name(""is_effectsize_name""))
+  expect_true(is_effectsize_name(""Eta2""))
+  expect_equal(get_effectsize_label(""hEDgES_G""), ""Hedges' g"")
+})
 
-    d1 <- cohens_d(mpg ~ cyl,
-      data = mtcars,
-      subset = cyl < 8
-    )
+test_that(""validate data from formula"", {
+  expect_error(cohens_d(mpg ~ cyl, data = mtcars), ""exactly"")
+  expect_error(cohens_d(mpg ~ cyl, data = mtcars, subset = cyl %in% c(4, 6)), regexp = NA)
 
-    x <- mtcars$cyl < 8
-    d2 <- cohens_d(mpg ~ cyl,
-      data = mtcars,
-      subset = x
-    )
+  d1 <- cohens_d(mpg ~ cyl,
+                 data = mtcars,
+                 subset = cyl < 8
+  )
 
-    x <- mtcars$cyl
-    d3 <- cohens_d(mpg ~ cyl,
-      data = mtcars,
-      subset = x < 8
-    )
+  x <- mtcars$cyl < 8
+  d2 <- cohens_d(mpg ~ cyl,
+                 data = mtcars,
+                 subset = x
+  )
 
-    d4 <- cohens_d(mpg ~ cyl,
-      data = mtcars,
-      subset =
-        c(
-          TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, FALSE, TRUE, TRUE, TRUE,
-          TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE,
-          TRUE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE,
-          FALSE, TRUE
-        )
-    )
+  x <- mtcars$cyl
+  d3 <- cohens_d(mpg ~ cyl,
+                 data = mtcars,
+                 subset = x < 8
+  )
 
-    expect_equal(d1, d2)
-    expect_equal(d1, d3)
-    expect_equal(d1, d4)
+  d4 <- cohens_d(mpg ~ cyl,
+                 data = mtcars,
+                 subset =
+                   c(
+                     TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, FALSE, TRUE, TRUE, TRUE,
+                     TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE,
+                     TRUE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE,
+                     FALSE, TRUE
+                   )
+  )
 
-    expect_error(rank_biserial(mpg ~ cyl, data = mtcars), ""exactly"")
-    expect_error(rank_biserial(mpg ~ cyl, data = mtcars, subset = cyl %in% c(4, 6)), regexp = NA)
+  expect_equal(d1, d2)
+  expect_equal(d1, d3)
+  expect_equal(d1, d4)
 
-    expect_error(sd_pooled(mpg ~ cyl, data = mtcars), ""exactly"")
-    expect_error(sd_pooled(mpg ~ cyl, data = mtcars, subset = cyl %in% c(4, 6)), regexp = NA)
+  expect_error(rank_biserial(mpg ~ cyl, data = mtcars), ""exactly"")
+  expect_error(rank_biserial(mpg ~ cyl, data = mtcars, subset = cyl %in% c(4, 6)), regexp = NA)
 
-    expect_error(cohens_u1(mpg ~ cyl, data = mtcars), ""exactly"")
-    expect_error(cohens_u1(mpg ~ cyl, data = mtcars, subset = cyl %in% c(4, 6)), regexp = NA)
+  expect_error(sd_pooled(mpg ~ cyl, data = mtcars), ""exactly"")
+  expect_error(sd_pooled(mpg ~ cyl, data = mtcars, subset = cyl %in% c(4, 6)), regexp = NA)
 
-    d <- expand.grid(id = 1:30, g = 1:4)
-    d$y <- rnorm(nrow(d)) + d$g
-    expect_equal(
-      rank_epsilon_squared(y ~ g, data = d, subset = g < 4, ci = NULL),
-      rank_epsilon_squared(y ~ g, data = subset(d, g < 4), ci = NULL)
-    )
+  expect_error(cohens_u1(mpg ~ cyl, data = mtcars), ""exactly"")
+  expect_error(cohens_u1(mpg ~ cyl, data = mtcars, subset = cyl %in% c(4, 6)), regexp = NA)
 
-    expect_equal(
-      kendalls_w(y ~ g | id, data = d, subset = g < 4, ci = NULL),
-      kendalls_w(y ~ g | id, data = subset(d, g < 4), ci = NULL)
-    )
-  })
-}
+  d <- expand.grid(id = 1:30, g = 1:4)
+  d$y <- rnorm(nrow(d)) + d$g
+  expect_equal(
+    rank_epsilon_squared(y ~ g, data = d, subset = g < 4, ci = NULL),
+    rank_epsilon_squared(y ~ g, data = subset(d, g < 4), ci = NULL)
+  )
+
+  expect_equal(
+    kendalls_w(y ~ g | id, data = d, subset = g < 4, ci = NULL),
+    kendalls_w(y ~ g | id, data = subset(d, g < 4), ci = NULL)
+  )
+})

---FILE: tests/testthat/test-interpret.R---
@@ -1,257 +1,255 @@
-if (require(""testthat"") && require(""effectsize"")) {
-  # interpret generic ----
-  test_that(""interpret generic"", {
-    rules_grid <- rules(c(0.01, 0.05), c(""very significant"", ""significant"", ""not significant""))
-    expect_equal(interpret(0.001, rules_grid)[1], ""very significant"")
-    expect_equal(interpret(0.021, rules_grid)[1], ""significant"")
-    expect_equal(interpret(0.08, rules_grid)[1], ""not significant"")
-    expect_equal(
-      interpret(c(0.01, 0.005, 0.08), rules_grid)[1:3],
-      c(""very significant"", ""very significant"", ""not significant"")
-    )
-    expect_error(rules(c(0.5), c(""A"", ""B"", ""C"")), ""Too many"")
-    expect_error(rules(c(0.5, 0.2, 0.7), c(""A"", ""B"", ""C"", ""D"")), ""sorted"")
-
-
-    r1 <- rules(c(0, 1), labels = c(""some"", ""few"", ""many""))
-    r2 <- rules(c(0, 1), labels = c(""some"", ""few"", ""many""), right = FALSE)
-
-    expect_equal(interpret(c(0, 1), r1)[], c(""some"", ""few""), ignore_attr = TRUE)
-    expect_equal(interpret(c(0, 1), r2)[], c(""few"", ""many""), ignore_attr = TRUE)
-  })
-
-  # interpret types ----
-  test_that(""interpret_r"", {
-    expect_equal(interpret_r(0.21)[1], ""medium"")
-    expect_equal(interpret_r(0.21, ""cohen1988"")[1], ""small"")
-    expect_equal(interpret_r(0.21, ""lovakov2021"")[1], ""small"")
-    expect_equal(interpret_r(0.7, ""evans1996"")[1], ""strong"")
-    expect_equal(interpret_r(c(0.5, -0.08), ""cohen1988"")[1:2], c(""large"", ""very small""))
-    expect_equal(interpret_r(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_r(0.6, ""DUPA""), ""must be"")
-  })
-
-
-
-  test_that(""interpret_p"", {
-    expect_equal(interpret_p(0.021)[1], ""significant"")
-    expect_equal(interpret_p(0.08)[1], ""not significant"")
-    expect_equal(interpret_p(c(0.01, 0.08))[1:2], c(""significant"", ""not significant""))
-    expect_equal(interpret_p(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_p(0.6, ""DUPA""), ""must be"")
-  })
-
-
-  test_that(""interpret_direction"", {
-    expect_equal(interpret_direction(c(0.01, -0.08))[1:2], c(""positive"", ""negative""))
-  })
-
-
-  test_that(""interpret_cohens_d"", {
-    expect_equal(interpret_cohens_d(0.021)[1], ""very small"")
-    expect_equal(interpret_cohens_d(1.3, ""sawilowsky2009"")[1], ""very large"")
-    expect_equal(interpret_cohens_d(c(0.45, 0.85), ""cohen1988"")[1:2], c(""small"", ""large""))
-    expect_equal(interpret_cohens_d(c(0.45, 0.85), ""lovakov2021"")[1:2], c(""medium"", ""large""))
-    expect_equal(interpret_cohens_d(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_cohens_d(0.6, ""DUPA""), ""must be"")
-  })
-
-  test_that(""interpret_cohens_g"", {
-    expect_equal(interpret_cohens_g(0.021)[1], ""very small"")
-    expect_equal(interpret_cohens_g(c(0.10, 0.35), ""cohen1988"")[1:2], c(""small"", ""large""))
-    expect_equal(interpret_cohens_g(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_cohens_g(0.6, ""DUPA""), ""must be"")
-  })
-
-
-  test_that(""interpret_rope"", {
-    expect_equal(interpret_rope(0, ci = 0.9)[1], ""significant"")
-    expect_equal(interpret_rope(c(0.50, 1), ci = 0.9)[1:2], c(""undecided"", ""negligible""))
-    expect_equal(interpret_rope(c(0.98, 0.991), ci = 1)[1:2], c(""probably negligible"", ""negligible""))
-    expect_equal(interpret_rope(0.6, , rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_rope(0.6, , ""DUPA""), ""must be"")
-  })
-
-
-  test_that(""interpret_oddsratio"", {
-    expect_equal(interpret_oddsratio(2)[1], ""small"")
-    expect_equal(interpret_oddsratio(c(1, 3))[1:2], c(""very small"", ""small""))
-    expect_equal(interpret_oddsratio(c(1, 3), ""cohen1988"")[1:2], c(""very small"", ""medium""))
-    expect_equal(interpret_oddsratio(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_oddsratio(0.6, ""DUPA""), ""must be"")
-  })
-
-
-  test_that(""interpret_r2"", {
-    expect_equal(interpret_r2(0.4)[1], ""substantial"")
-    expect_equal(interpret_r2(c(0, 0.4), ""falk1992"")[1:2], c(""negligible"", ""adequate""))
-    expect_equal(interpret_r2(c(0.1, 0.4), ""chin1998"")[1:2], c(""very weak"", ""moderate""))
-    expect_equal(interpret_r2(c(0.1, 0.4), ""hair2011"")[1:2], c(""very weak"", ""weak""))
-    expect_equal(interpret_r2(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_r2(0.6, ""DUPA""), ""must be"")
-  })
-
-
-  test_that(""interpret_bf"", {
-    expect_warning(interpret_bf(-2), ""Negative"")
-    expect_equal(interpret_bf(1)[1], ""no evidence against or in favour of"")
-    expect_equal(
-      interpret_bf(c(0.8, 3.5), ""jeffreys1961"")[1:2],
-      c(""anecdotal evidence against"", ""moderate evidence in favour of"")
-    )
-    expect_equal(
-      interpret_bf(c(0.8, 3.5), ""raftery1995"")[1:2],
-      c(""weak evidence against"", ""positive evidence in favour of"")
-    )
-    expect_equal(interpret_bf(2, rules(c(0.5), c(""A"", ""B"")))[1], ""B evidence in favour of"")
-    expect_error(interpret_bf(2, ""DUPA""), ""must be"")
-
-    skip_on_cran() # just in case there are changes in insight
-    bf <- c(10^seq(-4, 4), NA)
-    expect_equal(interpret_bf(bf, include_value = TRUE, protect_ratio = TRUE, exact = TRUE),
-      c(
-        ""extreme evidence (BF = 1/1.00e+04) against"", ""extreme evidence (BF = 1/1000.00) against"",
-        ""very strong evidence (BF = 1/100.00) against"", ""moderate evidence (BF = 1/10.00) against"",
-        ""no evidence (BF = 1.00) against or in favour of"", ""strong evidence (BF = 10.00) in favour of"",
-        ""extreme evidence (BF = 100.00) in favour of"", ""extreme evidence (BF = 1000.00) in favour of"",
-        ""extreme evidence (BF = 1.00e+04) in favour of"", """"
-      ),
-      ignore_attr = TRUE
-    )
-  })
-
-
-
-  test_that(""interpret_omega_squared"", {
-    expect_equal(interpret_omega_squared(0.1)[1], ""medium"")
-    expect_equal(interpret_omega_squared(c(0.1, 0.25))[1:2], c(""medium"", ""large""))
-    expect_equal(interpret_omega_squared(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_omega_squared(0.6, ""DUPA""), ""must be"")
-
-    # these should be same
-    expect_equal(interpret_eta_squared(0.1)[1], interpret_omega_squared(0.1)[1])
-    expect_equal(
-      interpret_eta_squared(c(0.1, 0.25))[1:2],
-      interpret_omega_squared(c(0.1, 0.25))[1:2]
-    )
-  })
-
-  test_that(""interpret_kendalls_w"", {
-    expect_equal(interpret_kendalls_w(0.1)[1], ""slight agreement"")
-    expect_equal(
-      interpret_kendalls_w(c(0.1, 0.25))[1:2],
-      c(""slight agreement"", ""fair agreement"")
-    )
-    expect_equal(interpret_kendalls_w(0.9)[1], ""almost perfect agreement"")
-    expect_equal(interpret_kendalls_w(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_kendalls_w(0.6, ""DUPA""), ""must be"")
-  })
-
-
-  test_that(""interpret_rhat"", {
-    expect_equal(interpret_rhat(1)[1], ""converged"")
-    expect_equal(interpret_rhat(c(1, 1.02))[1:2], c(""converged"", ""failed""))
-    expect_equal(interpret_rhat(c(1, 1.02), ""gelman1992"")[1:2], c(""converged"", ""converged""))
-    expect_equal(interpret_rhat(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_rhat(0.6, ""DUPA""), ""must be"")
-  })
-
-
-  test_that(""interpret_ess"", {
-    expect_equal(interpret_ess(1000)[1], ""sufficient"")
-    expect_equal(interpret_ess(c(1000, 800))[1:2], c(""sufficient"", ""insufficient""))
-    expect_equal(interpret_ess(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_ess(0.6, ""DUPA""), ""must be"")
-  })
-
-
-  test_that(""interpret_fit"", {
-    expect_equal(interpret_gfi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
-    expect_equal(interpret_agfi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
-    expect_equal(interpret_nfi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
-    expect_equal(interpret_nnfi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
-    expect_equal(interpret_cfi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
-    expect_equal(interpret_rfi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
-    expect_equal(interpret_ifi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
-    expect_equal(interpret_pnfi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
-    expect_equal(interpret_rmsea(c(.1, .05)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
-    expect_equal(interpret_srmr(c(.1, .05)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
-
-    cr <- rules(c(0.5), c(""A"", ""B""))
-    expect_equal(interpret_gfi(0.6, cr), ""B"", ignore_attr = TRUE)
-    expect_equal(interpret_agfi(0.6, cr), ""B"", ignore_attr = TRUE)
-    expect_equal(interpret_nfi(0.6, cr), ""B"", ignore_attr = TRUE)
-    expect_equal(interpret_nnfi(0.6, cr), ""B"", ignore_attr = TRUE)
-    expect_equal(interpret_cfi(0.6, cr), ""B"", ignore_attr = TRUE)
-    expect_equal(interpret_rfi(0.6, cr), ""B"", ignore_attr = TRUE)
-    expect_equal(interpret_ifi(0.6, cr), ""B"", ignore_attr = TRUE)
-    expect_equal(interpret_pnfi(0.6, cr), ""B"", ignore_attr = TRUE)
-    expect_equal(interpret_rmsea(0.6, cr), ""B"", ignore_attr = TRUE)
-    expect_equal(interpret_srmr(0.6, cr), ""B"", ignore_attr = TRUE)
-
-    expect_error(interpret_gfi(0.6, ""DUPA""), ""must be"")
-    expect_error(interpret_agfi(0.6, ""DUPA""), ""must be"")
-    expect_error(interpret_nfi(0.6, ""DUPA""), ""must be"")
-    expect_error(interpret_nnfi(0.6, ""DUPA""), ""must be"")
-    expect_error(interpret_cfi(0.6, ""DUPA""), ""must be"")
-    expect_error(interpret_rfi(0.6, ""DUPA""), ""must be"")
-    expect_error(interpret_ifi(0.6, ""DUPA""), ""must be"")
-    expect_error(interpret_pnfi(0.6, ""DUPA""), ""must be"")
-    expect_error(interpret_rmsea(0.6, ""DUPA""), ""must be"")
-    expect_error(interpret_srmr(0.6, ""DUPA""), ""must be"")
-
-    skip_on_cran()
-    skip_if_not_installed(""lavaan"")
-    skip_if_not_installed(""performance"")
-
-    structure <- "" ind60 =~ x1 + x2 + x3
+# interpret generic ----
+test_that(""interpret generic"", {
+  rules_grid <- rules(c(0.01, 0.05), c(""very significant"", ""significant"", ""not significant""))
+  expect_equal(interpret(0.001, rules_grid)[1], ""very significant"")
+  expect_equal(interpret(0.021, rules_grid)[1], ""significant"")
+  expect_equal(interpret(0.08, rules_grid)[1], ""not significant"")
+  expect_equal(
+    interpret(c(0.01, 0.005, 0.08), rules_grid)[1:3],
+    c(""very significant"", ""very significant"", ""not significant"")
+  )
+  expect_error(rules(c(0.5), c(""A"", ""B"", ""C"")), ""Too many"")
+  expect_error(rules(c(0.5, 0.2, 0.7), c(""A"", ""B"", ""C"", ""D"")), ""sorted"")
+
+
+  r1 <- rules(c(0, 1), labels = c(""some"", ""few"", ""many""))
+  r2 <- rules(c(0, 1), labels = c(""some"", ""few"", ""many""), right = FALSE)
+
+  expect_equal(interpret(c(0, 1), r1)[], c(""some"", ""few""), ignore_attr = TRUE)
+  expect_equal(interpret(c(0, 1), r2)[], c(""few"", ""many""), ignore_attr = TRUE)
+})
+
+# interpret types ----
+test_that(""interpret_r"", {
+  expect_equal(interpret_r(0.21)[1], ""medium"")
+  expect_equal(interpret_r(0.21, ""cohen1988"")[1], ""small"")
+  expect_equal(interpret_r(0.21, ""lovakov2021"")[1], ""small"")
+  expect_equal(interpret_r(0.7, ""evans1996"")[1], ""strong"")
+  expect_equal(interpret_r(c(0.5, -0.08), ""cohen1988"")[1:2], c(""large"", ""very small""))
+  expect_equal(interpret_r(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_error(interpret_r(0.6, ""DUPA""), ""must be"")
+})
+
+
+
+test_that(""interpret_p"", {
+  expect_equal(interpret_p(0.021)[1], ""significant"")
+  expect_equal(interpret_p(0.08)[1], ""not significant"")
+  expect_equal(interpret_p(c(0.01, 0.08))[1:2], c(""significant"", ""not significant""))
+  expect_equal(interpret_p(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_error(interpret_p(0.6, ""DUPA""), ""must be"")
+})
+
+
+test_that(""interpret_direction"", {
+  expect_equal(interpret_direction(c(0.01, -0.08))[1:2], c(""positive"", ""negative""))
+})
+
+
+test_that(""interpret_cohens_d"", {
+  expect_equal(interpret_cohens_d(0.021)[1], ""very small"")
+  expect_equal(interpret_cohens_d(1.3, ""sawilowsky2009"")[1], ""very large"")
+  expect_equal(interpret_cohens_d(c(0.45, 0.85), ""cohen1988"")[1:2], c(""small"", ""large""))
+  expect_equal(interpret_cohens_d(c(0.45, 0.85), ""lovakov2021"")[1:2], c(""medium"", ""large""))
+  expect_equal(interpret_cohens_d(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_error(interpret_cohens_d(0.6, ""DUPA""), ""must be"")
+})
+
+test_that(""interpret_cohens_g"", {
+  expect_equal(interpret_cohens_g(0.021)[1], ""very small"")
+  expect_equal(interpret_cohens_g(c(0.10, 0.35), ""cohen1988"")[1:2], c(""small"", ""large""))
+  expect_equal(interpret_cohens_g(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_error(interpret_cohens_g(0.6, ""DUPA""), ""must be"")
+})
+
+
+test_that(""interpret_rope"", {
+  expect_equal(interpret_rope(0, ci = 0.9)[1], ""significant"")
+  expect_equal(interpret_rope(c(0.50, 1), ci = 0.9)[1:2], c(""undecided"", ""negligible""))
+  expect_equal(interpret_rope(c(0.98, 0.991), ci = 1)[1:2], c(""probably negligible"", ""negligible""))
+  expect_equal(interpret_rope(0.6, , rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_error(interpret_rope(0.6, , ""DUPA""), ""must be"")
+})
+
+
+test_that(""interpret_oddsratio"", {
+  expect_equal(interpret_oddsratio(2)[1], ""small"")
+  expect_equal(interpret_oddsratio(c(1, 3))[1:2], c(""very small"", ""small""))
+  expect_equal(interpret_oddsratio(c(1, 3), ""cohen1988"")[1:2], c(""very small"", ""medium""))
+  expect_equal(interpret_oddsratio(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_error(interpret_oddsratio(0.6, ""DUPA""), ""must be"")
+})
+
+
+test_that(""interpret_r2"", {
+  expect_equal(interpret_r2(0.4)[1], ""substantial"")
+  expect_equal(interpret_r2(c(0, 0.4), ""falk1992"")[1:2], c(""negligible"", ""adequate""))
+  expect_equal(interpret_r2(c(0.1, 0.4), ""chin1998"")[1:2], c(""very weak"", ""moderate""))
+  expect_equal(interpret_r2(c(0.1, 0.4), ""hair2011"")[1:2], c(""very weak"", ""weak""))
+  expect_equal(interpret_r2(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_error(interpret_r2(0.6, ""DUPA""), ""must be"")
+})
+
+
+test_that(""interpret_bf"", {
+  expect_warning(interpret_bf(-2), ""Negative"")
+  expect_equal(interpret_bf(1)[1], ""no evidence against or in favour of"")
+  expect_equal(
+    interpret_bf(c(0.8, 3.5), ""jeffreys1961"")[1:2],
+    c(""anecdotal evidence against"", ""moderate evidence in favour of"")
+  )
+  expect_equal(
+    interpret_bf(c(0.8, 3.5), ""raftery1995"")[1:2],
+    c(""weak evidence against"", ""positive evidence in favour of"")
+  )
+  expect_equal(interpret_bf(2, rules(c(0.5), c(""A"", ""B"")))[1], ""B evidence in favour of"")
+  expect_error(interpret_bf(2, ""DUPA""), ""must be"")
+
+  skip_on_cran() # just in case there are changes in insight
+  bf <- c(10^seq(-4, 4), NA)
+  expect_equal(interpret_bf(bf, include_value = TRUE, protect_ratio = TRUE, exact = TRUE),
+               c(
+                 ""extreme evidence (BF = 1/1.00e+04) against"", ""extreme evidence (BF = 1/1000.00) against"",
+                 ""very strong evidence (BF = 1/100.00) against"", ""moderate evidence (BF = 1/10.00) against"",
+                 ""no evidence (BF = 1.00) against or in favour of"", ""strong evidence (BF = 10.00) in favour of"",
+                 ""extreme evidence (BF = 100.00) in favour of"", ""extreme evidence (BF = 1000.00) in favour of"",
+                 ""extreme evidence (BF = 1.00e+04) in favour of"", """"
+               ),
+               ignore_attr = TRUE
+  )
+})
+
+
+
+test_that(""interpret_omega_squared"", {
+  expect_equal(interpret_omega_squared(0.1)[1], ""medium"")
+  expect_equal(interpret_omega_squared(c(0.1, 0.25))[1:2], c(""medium"", ""large""))
+  expect_equal(interpret_omega_squared(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_error(interpret_omega_squared(0.6, ""DUPA""), ""must be"")
+
+  # these should be same
+  expect_equal(interpret_eta_squared(0.1)[1], interpret_omega_squared(0.1)[1])
+  expect_equal(
+    interpret_eta_squared(c(0.1, 0.25))[1:2],
+    interpret_omega_squared(c(0.1, 0.25))[1:2]
+  )
+})
+
+test_that(""interpret_kendalls_w"", {
+  expect_equal(interpret_kendalls_w(0.1)[1], ""slight agreement"")
+  expect_equal(
+    interpret_kendalls_w(c(0.1, 0.25))[1:2],
+    c(""slight agreement"", ""fair agreement"")
+  )
+  expect_equal(interpret_kendalls_w(0.9)[1], ""almost perfect agreement"")
+  expect_equal(interpret_kendalls_w(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_error(interpret_kendalls_w(0.6, ""DUPA""), ""must be"")
+})
+
+
+test_that(""interpret_rhat"", {
+  expect_equal(interpret_rhat(1)[1], ""converged"")
+  expect_equal(interpret_rhat(c(1, 1.02))[1:2], c(""converged"", ""failed""))
+  expect_equal(interpret_rhat(c(1, 1.02), ""gelman1992"")[1:2], c(""converged"", ""converged""))
+  expect_equal(interpret_rhat(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_error(interpret_rhat(0.6, ""DUPA""), ""must be"")
+})
+
+
+test_that(""interpret_ess"", {
+  expect_equal(interpret_ess(1000)[1], ""sufficient"")
+  expect_equal(interpret_ess(c(1000, 800))[1:2], c(""sufficient"", ""insufficient""))
+  expect_equal(interpret_ess(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_error(interpret_ess(0.6, ""DUPA""), ""must be"")
+})
+
+
+test_that(""interpret_fit"", {
+  expect_equal(interpret_gfi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
+  expect_equal(interpret_agfi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
+  expect_equal(interpret_nfi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
+  expect_equal(interpret_nnfi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
+  expect_equal(interpret_cfi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
+  expect_equal(interpret_rfi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
+  expect_equal(interpret_ifi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
+  expect_equal(interpret_pnfi(c(.5, .99)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
+  expect_equal(interpret_rmsea(c(.1, .05)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
+  expect_equal(interpret_srmr(c(.1, .05)), c(""poor"", ""satisfactory""), ignore_attr = TRUE)
+
+  cr <- rules(c(0.5), c(""A"", ""B""))
+  expect_equal(interpret_gfi(0.6, cr), ""B"", ignore_attr = TRUE)
+  expect_equal(interpret_agfi(0.6, cr), ""B"", ignore_attr = TRUE)
+  expect_equal(interpret_nfi(0.6, cr), ""B"", ignore_attr = TRUE)
+  expect_equal(interpret_nnfi(0.6, cr), ""B"", ignore_attr = TRUE)
+  expect_equal(interpret_cfi(0.6, cr), ""B"", ignore_attr = TRUE)
+  expect_equal(interpret_rfi(0.6, cr), ""B"", ignore_attr = TRUE)
+  expect_equal(interpret_ifi(0.6, cr), ""B"", ignore_attr = TRUE)
+  expect_equal(interpret_pnfi(0.6, cr), ""B"", ignore_attr = TRUE)
+  expect_equal(interpret_rmsea(0.6, cr), ""B"", ignore_attr = TRUE)
+  expect_equal(interpret_srmr(0.6, cr), ""B"", ignore_attr = TRUE)
+
+  expect_error(interpret_gfi(0.6, ""DUPA""), ""must be"")
+  expect_error(interpret_agfi(0.6, ""DUPA""), ""must be"")
+  expect_error(interpret_nfi(0.6, ""DUPA""), ""must be"")
+  expect_error(interpret_nnfi(0.6, ""DUPA""), ""must be"")
+  expect_error(interpret_cfi(0.6, ""DUPA""), ""must be"")
+  expect_error(interpret_rfi(0.6, ""DUPA""), ""must be"")
+  expect_error(interpret_ifi(0.6, ""DUPA""), ""must be"")
+  expect_error(interpret_pnfi(0.6, ""DUPA""), ""must be"")
+  expect_error(interpret_rmsea(0.6, ""DUPA""), ""must be"")
+  expect_error(interpret_srmr(0.6, ""DUPA""), ""must be"")
+
+  skip_on_cran()
+  skip_if_not_installed(""lavaan"")
+  skip_if_not_installed(""performance"")
+
+  structure <- "" ind60 =~ x1 + x2 + x3
                    dem60 =~ y1 + y2 + y3
                    dem60 ~ ind60 ""
-    model <- lavaan::sem(structure, data = lavaan::PoliticalDemocracy)
-    int <- interpret(model)
-    expect_equal(int$Name, c(""GFI"", ""AGFI"", ""NFI"", ""NNFI"", ""CFI"", ""RMSEA"", ""SRMR"", ""RFI"", ""PNFI"", ""IFI""))
-    expect_equal(int$Value, c(0.9666, 0.9124, 0.9749, 1.0001, 1, 0, 0.0273, 0.9529, 0.5199, 1.0001), tolerance = 0.001)
-
-    int2 <- interpret(performance::model_performance(model))
-    expect_equal(int, int2)
-  })
-
-  test_that(""interpret_icc"", {
-    expect_equal(interpret_icc(c(0.45, 0.55, 0.8, 0.95)), c(""poor"", ""moderate"", ""good"", ""excellent""), ignore_attr = TRUE)
-    expect_equal(interpret_icc(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_icc(0.6, ""DUPA""), ""must be"")
-  })
-
-  test_that(""interpret_vif"", {
-    expect_equal(interpret_vif(c(1, 5.5, 10)), c(""low"", ""moderate"", ""high""), ignore_attr = TRUE)
-    expect_equal(interpret_icc(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_icc(0.6, ""DUPA""), ""must be"")
-  })
-
-  test_that(""interpret_pd"", {
-    expect_equal(interpret_pd(c(0.9, 0.99)), c(""not significant"", ""significant""), ignore_attr = TRUE)
-    expect_equal(interpret_pd(c(0.9, 0.99), ""makowski2019""), c(""uncertain"", ""likely existing""), ignore_attr = TRUE)
-    expect_equal(interpret_pd(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_pd(0.6, ""DUPA""), ""must be"")
-  })
-
-  # interpret effectsize_table ----
-  test_that(""interpret effectsize_table"", {
-    d <- cohens_d(mpg ~ am, data = mtcars)
-    d_ <- interpret(d, rules = ""cohen1988"")
-    expect_equal(d_[[""Interpretation""]], ""large"", ignore_attr = TRUE)
-    expect_s3_class(d_[[""Interpretation""]], ""effectsize_interpret"")
-    expect_output(print(d_), ""large"")
-    expect_output(print(d_), ""Interpretation rule: cohen1988"")
-
-
-    V <- cramers_v(matrix(c(71, 30, 50, 100), 2))
-    V_ <- interpret(V, rules = ""funder2019"")
-    expect_equal(V_[[""Interpretation""]], ""large"", ignore_attr = TRUE)
-    expect_s3_class(V_[[""Interpretation""]], ""effectsize_interpret"")
-    expect_output(print(V_), ""large"")
-    expect_output(print(V_), ""Interpretation rule: funder2019"")
-
-    expect_error(interpret(d), ""MUST specify"")
-  })
-}
+  model <- lavaan::sem(structure, data = lavaan::PoliticalDemocracy)
+  int <- interpret(model)
+  expect_equal(int$Name, c(""GFI"", ""AGFI"", ""NFI"", ""NNFI"", ""CFI"", ""RMSEA"", ""SRMR"", ""RFI"", ""PNFI"", ""IFI""))
+  expect_equal(int$Value, c(0.9666, 0.9124, 0.9749, 1.0001, 1, 0, 0.0273, 0.9529, 0.5199, 1.0001), tolerance = 0.001)
+
+  int2 <- interpret(performance::model_performance(model))
+  expect_equal(int, int2)
+})
+
+test_that(""interpret_icc"", {
+  expect_equal(interpret_icc(c(0.45, 0.55, 0.8, 0.95)), c(""poor"", ""moderate"", ""good"", ""excellent""), ignore_attr = TRUE)
+  expect_equal(interpret_icc(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_error(interpret_icc(0.6, ""DUPA""), ""must be"")
+})
+
+test_that(""interpret_vif"", {
+  expect_equal(interpret_vif(c(1, 5.5, 10)), c(""low"", ""moderate"", ""high""), ignore_attr = TRUE)
+  expect_equal(interpret_icc(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_error(interpret_icc(0.6, ""DUPA""), ""must be"")
+})
+
+test_that(""interpret_pd"", {
+  expect_equal(interpret_pd(c(0.9, 0.99)), c(""not significant"", ""significant""), ignore_attr = TRUE)
+  expect_equal(interpret_pd(c(0.9, 0.99), ""makowski2019""), c(""uncertain"", ""likely existing""), ignore_attr = TRUE)
+  expect_equal(interpret_pd(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+  expect_error(interpret_pd(0.6, ""DUPA""), ""must be"")
+})
+
+# interpret effectsize_table ----
+test_that(""interpret effectsize_table"", {
+  d <- cohens_d(mpg ~ am, data = mtcars)
+  d_ <- interpret(d, rules = ""cohen1988"")
+  expect_equal(d_[[""Interpretation""]], ""large"", ignore_attr = TRUE)
+  expect_s3_class(d_[[""Interpretation""]], ""effectsize_interpret"")
+  expect_output(print(d_), ""large"")
+  expect_output(print(d_), ""Interpretation rule: cohen1988"")
+
+
+  V <- cramers_v(matrix(c(71, 30, 50, 100), 2))
+  V_ <- interpret(V, rules = ""funder2019"")
+  expect_equal(V_[[""Interpretation""]], ""large"", ignore_attr = TRUE)
+  expect_s3_class(V_[[""Interpretation""]], ""effectsize_interpret"")
+  expect_output(print(V_), ""large"")
+  expect_output(print(V_), ""Interpretation rule: funder2019"")
+
+  expect_error(interpret(d), ""MUST specify"")
+})

---FILE: tests/testthat/test-plot.R---
@@ -1,11 +1,10 @@
-if (require(effectsize) && require(testthat)) {
-  test_that(""plot methods"", {
-    skip_if_not_installed(""see"")
-    skip_if_not_installed(""ggplot2"")
-    expect_error(plot(d <- cohens_d(mpg ~ am, data = mtcars)), NA)
-    expect_s3_class(plot(d), ""ggplot"")
 
-    expect_error(plot(eqi <- equivalence_test(d)), NA)
-    expect_s3_class(plot(eqi), ""ggplot"")
-  })
-}
+test_that(""plot methods"", {
+  skip_if_not_installed(""see"")
+  skip_if_not_installed(""ggplot2"")
+  expect_error(plot(d <- cohens_d(mpg ~ am, data = mtcars)), NA)
+  expect_s3_class(plot(d), ""ggplot"")
+
+  expect_error(plot(eqi <- equivalence_test(d)), NA)
+  expect_s3_class(plot(eqi), ""ggplot"")
+})

---FILE: tests/testthat/test-printing.R---
@@ -1,170 +1,170 @@
-if (require(""testthat"") && require(""effectsize"")) {
-  test_that(""print | effectsize table"", {
-    ## digits
-    d <- cohens_d(1:4, c(1, 1:5))
-    expect_output(print(d), ""[-1.37, 1.16]"", fixed = TRUE)
-    expect_output(print(d, digits = 4), ""[-1.3730, 1.1595]"", fixed = TRUE)
-    expect_output(print(d, digits = ""signif4""), ""[-1.373, 1.16]"", fixed = TRUE)
-    expect_output(print(d, digits = ""scientific4""), ""[-1.3730e+00, 1.1595e+00]"", fixed = TRUE)
-
-    ## alternative + rounded bound
-    RCT <- matrix(c(71, 30, 31, 13, 50, 100, 4, 5, 7), nrow = 3, byrow = TRUE)
-    V1 <- cramers_v(RCT)
-    V2 <- cramers_v(RCT, alternative = ""two"")
-    w <- cohens_w(RCT)
-
-    expect_output(print(V1), regexp = ""[1.00]"", fixed = TRUE)
-    expect_output(print(V1, digits = ""signif4""), regexp = ""[1]"", fixed = TRUE)
-    expect_output(print(V1, digits = ""scientific2""), regexp = ""[1.00e+00]"", fixed = TRUE)
-    expect_error(expect_output(print(V2), regexp = ""fixed""))
-    expect_output(print(w), regexp = ""[1.41~]"", fixed = TRUE)
-    expect_output(print(w, digits = ""signif4""), regexp = ""[1.414]"", fixed = TRUE)
-    expect_output(print(w, digits = ""scientific2""), regexp = ""[1.41e+00]"", fixed = TRUE)
-
-
-    ## Column name
-    expect_output(print(d), ""Cohen's d"")
-    expect_output(print(V1), ""Cramer's V"")
-    expect_output(print(w), ""Cohen's w"")
-
-
-    ## Interpretation
-    d_ <- interpret(d, rules = ""sawilowsky2009"")
-    expect_output(print(d_), regexp = ""sawilowsky2009"")
-    expect_output(print(d_), regexp = ""Interpretation"")
-
-    V1_ <- interpret(V1, rules = ""funder2019"")
-    expect_output(print(V1_), regexp = ""funder2019"")
-    expect_output(print(V1_), regexp = ""Interpretation"")
-
-    w_ <- interpret(w, rules = ""funder2019"")
-    expect_output(print(w_), regexp = ""funder2019"")
-    expect_output(print(w_), regexp = ""Interpretation"")
-
-    ## md / html
-    skip_if_not_installed(""gt"")
-    skip_if_not_installed(""knitr"")
-    expect_s3_class(print_html(d), ""gt_tbl"")
-    expect_s3_class(print_md(d), ""knitr_kable"")
-  })
-
-  test_that(""print | effectsize_difference"", {
-    ## Pooled
-    d1 <- cohens_d(1:3, c(1, 1:3))
-    expect_error(expect_output(print(d1), regexp = ""Deviation from a difference""))
-    expect_output(print(d1), regexp = "" pooled"", fixed = TRUE)
-
-    ## Un-pooled + mu
-    d2 <- cohens_d(1:3, c(1, 1:3), pooled_sd = FALSE, mu = -1)
-    expect_output(print(d2), regexp = ""Deviation from a difference of -1"")
-    expect_output(print(d2), regexp = ""un-pooled"", fixed = TRUE)
-
-    ## paired
-    d3 <- cohens_d(1:5, c(1, 1:4), paired = TRUE)
-    expect_error(expect_output(print(d3), regexp = ""Deviation from a difference""))
-    expect_error(expect_output(print(d3), regexp = ""pooled""))
-
-    ## paired + mu
-    d4 <- cohens_d(1:5, c(1, 1:4), paired = TRUE, mu = 0.1)
-    expect_output(print(d4), regexp = ""Deviation from a difference of 0.1"")
-
-    ## CLSE
-    expect_output(print(d1, append_CLES = TRUE), regexp = ""U3"")
-    expect_error(expect_output(print(d2, append_CLES = TRUE), regexp = ""U3""))
-  })
-
-  test_that(""print | effectsize_anova"", {
-    a <- aov(mpg ~ cyl + gear, mtcars)
-
-    e1 <- eta_squared(a)
-    expect_output(print(e1), regexp = ""(Type I)"", fixed = TRUE)
-    expect_output(print(e1), regexp = ""Eta2 (partial)"", fixed = TRUE)
-    expect_output(print(e1), regexp = ""One-sided CIs: upper bound fixed at [1.00]"", fixed = TRUE)
-
-    e2 <- eta_squared(a, generalized = ""gear"")
-    expect_output(print(e2), regexp = ""Observed variables: gear"", fixed = TRUE)
-
-    e3 <- eta_squared(a, generalized = TRUE)
-    expect_output(print(e3), regexp = ""Observed variables: All"", fixed = TRUE)
-
-    skip_if_not_installed(""car"")
-    A <- car::Anova(a, type = 3)
-    e4 <- eta_squared(A)
-    expect_output(print(e4), regexp = ""(Type III)"", fixed = TRUE)
-  })
-
-  # test_that(""print | effectsize_std_params"", {
-  #   mod <- lm(mpg ~ cyl + gear, mtcars)
-  #
-  #   ## Methods
-  #   es <- standardize_parameters(mod)
-  #   expect_output(print(es), regexp = ""refit"")
-  #
-  #   es <- standardize_parameters(mod, method = ""basic"")
-  #   expect_output(print(es), regexp = ""basic"")
-  #
-  #   ## Robust / two_sd / include_response
-  #   es <- standardize_parameters(mod, robust = TRUE)
-  #   expect_output(print(es), regexp = ""one MAD from the median"")
-  #
-  #   es <- standardize_parameters(mod, two_sd = TRUE)
-  #   expect_output(print(es), regexp = ""two"")
-  #
-  #   es <- standardize_parameters(mod, include_response = FALSE)
-  #   expect_output(print(es), regexp = ""unstandardized"")
-  #
-  #   es <- standardize_parameters(mod, include_response = FALSE, two_sd = TRUE, robust = TRUE)
-  #   expect_output(print(es), regexp = ""two MADs from the median"")
-  #
-  #   # ES Name
-  #   expect_output(print(es), regexp = ""Coefficient (std.)"", fixed = TRUE)
-  #
-  #   mod <- glm(am ~ mpg, binomial(), mtcars)
-  #   es <- standardize_parameters(mod, exp = TRUE)
-  #   expect_output(print(es), regexp = ""Odds Ratio (std.)"", fixed = TRUE)
-  #   expect_output(print(es), regexp = ""unstandardized"")
-  # })
-
-
-  test_that(""print | equivalence_test_effectsize"", {
-    d <- cohens_d(1:3, c(1, 1:3))
-
-    equtest <- equivalence_test(d)
-    expect_output(print(equtest), regexp = ""ROPE: [-0.10, 0.10]"", fixed = TRUE)
-
-    equtest2 <- equivalence_test(d, rule = ""cet"")
-    expect_output(print(equtest2), regexp = ""Conditional"")
-
-    equtest3 <- equivalence_test(d, rule = ""bayes"")
-    expect_output(print(equtest3), regexp = ""Using Bayesian guidlines"", fixed = TRUE)
-  })
-
-  # Rules -----------
-  test_that(""rules"", {
-    skip_on_cran()
-    r1 <- rules(1:3, letters[1:4], name = ""XX"")
-    expect_output(print(r1), regexp = ""Thresholds"")
-    expect_output(print(r1), regexp = ""<="")
-    expect_output(print(r1), regexp = ""XX"")
-    expect_output(print(r1), regexp = ""1 <   b   <= 2"")
-    expect_output(print(r1, digits = ""scientific1""),
-      regexp = ""2.0e+00 <   c   <= 3.0e+00"", fixed = TRUE
-    )
-
-
-    r2 <- rules(c(1, 2, 3.1), letters[1:3], name = ""YY"")
-    expect_output(print(r2), regexp = ""Values"")
-    expect_output(print(r2), regexp = ""YY"")
-    expect_output(print(r2), regexp = ""b ~ 2"")
-    expect_output(print(r2), regexp = ""c ~ 3.1"")
-    expect_output(print(r2, digits = ""signif3""), regexp = ""c ~ 3.1"")
-    expect_output(print(r2, digits = ""scientific1""), regexp = ""a ~ 1.0e+00"", fixed = TRUE)
-
-
-    expect_output(print(interpret(0, r1)), '""a""')
-    expect_output(print(interpret(0, r1)), ""XX"")
-  })
-}
+
+test_that(""print | effectsize table"", {
+  ## digits
+  d <- cohens_d(1:4, c(1, 1:5))
+  expect_output(print(d), ""[-1.37, 1.16]"", fixed = TRUE)
+  expect_output(print(d, digits = 4), ""[-1.3730, 1.1595]"", fixed = TRUE)
+  expect_output(print(d, digits = ""signif4""), ""[-1.373, 1.16]"", fixed = TRUE)
+  expect_output(print(d, digits = ""scientific4""), ""[-1.3730e+00, 1.1595e+00]"", fixed = TRUE)
+
+  ## alternative + rounded bound
+  RCT <- matrix(c(71, 30, 31, 13, 50, 100, 4, 5, 7), nrow = 3, byrow = TRUE)
+  V1 <- cramers_v(RCT)
+  V2 <- cramers_v(RCT, alternative = ""two"")
+  w <- cohens_w(RCT)
+
+  expect_output(print(V1), regexp = ""[1.00]"", fixed = TRUE)
+  expect_output(print(V1, digits = ""signif4""), regexp = ""[1]"", fixed = TRUE)
+  expect_output(print(V1, digits = ""scientific2""), regexp = ""[1.00e+00]"", fixed = TRUE)
+  expect_error(expect_output(print(V2), regexp = ""fixed""))
+  expect_output(print(w), regexp = ""[1.41~]"", fixed = TRUE)
+  expect_output(print(w, digits = ""signif4""), regexp = ""[1.414]"", fixed = TRUE)
+  expect_output(print(w, digits = ""scientific2""), regexp = ""[1.41e+00]"", fixed = TRUE)
+
+
+  ## Column name
+  expect_output(print(d), ""Cohen's d"")
+  expect_output(print(V1), ""Cramer's V"")
+  expect_output(print(w), ""Cohen's w"")
+
+
+  ## Interpretation
+  d_ <- interpret(d, rules = ""sawilowsky2009"")
+  expect_output(print(d_), regexp = ""sawilowsky2009"")
+  expect_output(print(d_), regexp = ""Interpretation"")
+
+  V1_ <- interpret(V1, rules = ""funder2019"")
+  expect_output(print(V1_), regexp = ""funder2019"")
+  expect_output(print(V1_), regexp = ""Interpretation"")
+
+  w_ <- interpret(w, rules = ""funder2019"")
+  expect_output(print(w_), regexp = ""funder2019"")
+  expect_output(print(w_), regexp = ""Interpretation"")
+
+  ## md / html
+  skip_if_not_installed(""gt"")
+  skip_if_not_installed(""knitr"")
+  expect_s3_class(print_html(d), ""gt_tbl"")
+  expect_s3_class(print_md(d), ""knitr_kable"")
+})
+
+test_that(""print | effectsize_difference"", {
+  ## Pooled
+  d1 <- cohens_d(1:3, c(1, 1:3))
+  expect_error(expect_output(print(d1), regexp = ""Deviation from a difference""))
+  expect_output(print(d1), regexp = "" pooled"", fixed = TRUE)
+
+  ## Un-pooled + mu
+  d2 <- cohens_d(1:3, c(1, 1:3), pooled_sd = FALSE, mu = -1)
+  expect_output(print(d2), regexp = ""Deviation from a difference of -1"")
+  expect_output(print(d2), regexp = ""un-pooled"", fixed = TRUE)
+
+  ## paired
+  d3 <- cohens_d(1:5, c(1, 1:4), paired = TRUE)
+  expect_error(expect_output(print(d3), regexp = ""Deviation from a difference""))
+  expect_error(expect_output(print(d3), regexp = ""pooled""))
+
+  ## paired + mu
+  d4 <- cohens_d(1:5, c(1, 1:4), paired = TRUE, mu = 0.1)
+  expect_output(print(d4), regexp = ""Deviation from a difference of 0.1"")
+
+  ## CLSE
+  expect_output(print(d1, append_CLES = TRUE), regexp = ""U3"")
+  expect_error(expect_output(print(d2, append_CLES = TRUE), regexp = ""U3""))
+})
+
+test_that(""print | effectsize_anova"", {
+  a <- aov(mpg ~ cyl + gear, mtcars)
+
+  e1 <- eta_squared(a)
+  expect_output(print(e1), regexp = ""(Type I)"", fixed = TRUE)
+  expect_output(print(e1), regexp = ""Eta2 (partial)"", fixed = TRUE)
+  expect_output(print(e1), regexp = ""One-sided CIs: upper bound fixed at [1.00]"", fixed = TRUE)
+
+  e2 <- eta_squared(a, generalized = ""gear"")
+  expect_output(print(e2), regexp = ""Observed variables: gear"", fixed = TRUE)
+
+  e3 <- eta_squared(a, generalized = TRUE)
+  expect_output(print(e3), regexp = ""Observed variables: All"", fixed = TRUE)
+
+  skip_if_not_installed(""car"")
+  A <- car::Anova(a, type = 3)
+  e4 <- eta_squared(A)
+  expect_output(print(e4), regexp = ""(Type III)"", fixed = TRUE)
+})
+
+# test_that(""print | effectsize_std_params"", {
+#   mod <- lm(mpg ~ cyl + gear, mtcars)
+#
+#   ## Methods
+#   es <- standardize_parameters(mod)
+#   expect_output(print(es), regexp = ""refit"")
+#
+#   es <- standardize_parameters(mod, method = ""basic"")
+#   expect_output(print(es), regexp = ""basic"")
+#
+#   ## Robust / two_sd / include_response
+#   es <- standardize_parameters(mod, robust = TRUE)
+#   expect_output(print(es), regexp = ""one MAD from the median"")
+#
+#   es <- standardize_parameters(mod, two_sd = TRUE)
+#   expect_output(print(es), regexp = ""two"")
+#
+#   es <- standardize_parameters(mod, include_response = FALSE)
+#   expect_output(print(es), regexp = ""unstandardized"")
+#
+#   es <- standardize_parameters(mod, include_response = FALSE, two_sd = TRUE, robust = TRUE)
+#   expect_output(print(es), regexp = ""two MADs from the median"")
+#
+#   # ES Name
+#   expect_output(print(es), regexp = ""Coefficient (std.)"", fixed = TRUE)
+#
+#   mod <- glm(am ~ mpg, binomial(), mtcars)
+#   es <- standardize_parameters(mod, exp = TRUE)
+#   expect_output(print(es), regexp = ""Odds Ratio (std.)"", fixed = TRUE)
+#   expect_output(print(es), regexp = ""unstandardized"")
+# })
+
+
+test_that(""print | equivalence_test_effectsize"", {
+  d <- cohens_d(1:3, c(1, 1:3))
+
+  equtest <- equivalence_test(d)
+  expect_output(print(equtest), regexp = ""ROPE: [-0.10, 0.10]"", fixed = TRUE)
+
+  equtest2 <- equivalence_test(d, rule = ""cet"")
+  expect_output(print(equtest2), regexp = ""Conditional"")
+
+  equtest3 <- equivalence_test(d, rule = ""bayes"")
+  expect_output(print(equtest3), regexp = ""Using Bayesian guidlines"", fixed = TRUE)
+})
+
+# Rules -----------
+test_that(""rules"", {
+  skip_on_cran()
+  r1 <- rules(1:3, letters[1:4], name = ""XX"")
+  expect_output(print(r1), regexp = ""Thresholds"")
+  expect_output(print(r1), regexp = ""<="")
+  expect_output(print(r1), regexp = ""XX"")
+  expect_output(print(r1), regexp = ""1 <   b   <= 2"")
+  expect_output(print(r1, digits = ""scientific1""),
+                regexp = ""2.0e+00 <   c   <= 3.0e+00"", fixed = TRUE
+  )
+
+
+  r2 <- rules(c(1, 2, 3.1), letters[1:3], name = ""YY"")
+  expect_output(print(r2), regexp = ""Values"")
+  expect_output(print(r2), regexp = ""YY"")
+  expect_output(print(r2), regexp = ""b ~ 2"")
+  expect_output(print(r2), regexp = ""c ~ 3.1"")
+  expect_output(print(r2, digits = ""signif3""), regexp = ""c ~ 3.1"")
+  expect_output(print(r2, digits = ""scientific1""), regexp = ""a ~ 1.0e+00"", fixed = TRUE)
+
+
+  expect_output(print(interpret(0, r1)), '""a""')
+  expect_output(print(interpret(0, r1)), ""XX"")
+})
+
 
 
 test_that(""printing symbols works as expected"", {

---FILE: tests/testthat/test-rankES.R---
@@ -1,136 +1,135 @@
-if (require(""testthat"") && require(""effectsize"")) {
-  test_that(""rank_biserial"", {
-    x <- c(1.83, 0.50, 1.62, 2.48, 1.68, 1.88, 1.55, 3.06, 1.30)
-    y <- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)
 
-    rRB1 <- rank_biserial(x, y, paired = TRUE)
-    rRB2 <- rank_biserial(x - y)
-
-    expect_equal(rRB1, rRB2)
-    expect_equal(rRB1[[1]], 0.777, tolerance = 0.01)
-    expect_equal(rRB1$CI_low, 0.2953631, tolerance = 0.01)
-    expect_equal(rRB1$CI_high, 0.9441559, tolerance = 0.01)
-
-
-    A <- c(48, 48, 77, 86, 85, 85, 16)
-    B <- c(14, 34, 34, 77)
-    expect_equal(rank_biserial(A, B)[[1]], 0.6071429, tolerance = 0.01)
-
-
-    df <- data.frame(
-      outcome = c(x, y),
-      g = factor(rep(0:1, each = 9))
-    )
-    expect_equal(
-      rank_biserial(outcome ~ g, data = df, ci = NULL),
-      rank_biserial(df$outcome ~ df$g, ci = NULL)
+test_that(""rank_biserial"", {
+  x <- c(1.83, 0.50, 1.62, 2.48, 1.68, 1.88, 1.55, 3.06, 1.30)
+  y <- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)
+
+  rRB1 <- rank_biserial(x, y, paired = TRUE)
+  rRB2 <- rank_biserial(x - y)
+
+  expect_equal(rRB1, rRB2)
+  expect_equal(rRB1[[1]], 0.777, tolerance = 0.01)
+  expect_equal(rRB1$CI_low, 0.2953631, tolerance = 0.01)
+  expect_equal(rRB1$CI_high, 0.9441559, tolerance = 0.01)
+
+
+  A <- c(48, 48, 77, 86, 85, 85, 16)
+  B <- c(14, 34, 34, 77)
+  expect_equal(rank_biserial(A, B)[[1]], 0.6071429, tolerance = 0.01)
+
+
+  df <- data.frame(
+    outcome = c(x, y),
+    g = factor(rep(0:1, each = 9))
+  )
+  expect_equal(
+    rank_biserial(outcome ~ g, data = df, ci = NULL),
+    rank_biserial(df$outcome ~ df$g, ci = NULL)
+  )
+  expect_equal(
+    rank_biserial(outcome ~ g, data = df, ci = NULL),
+    rank_biserial(""outcome"", ""g"", data = df, ci = NULL)
+  )
+})
+
+
+test_that(""rank_epsilon_squared"", {
+  skip_if_not_installed(""boot"")
+  skip_if_not_installed(""base"", minimum_version = ""3.6.1"")
+  x1 <- c(2.9, 3.0, 2.5, 2.6, 3.2) # normal subjects
+  x2 <- c(3.8, 2.7, 4.0, 2.4) # with obstructive airway disease
+  x3 <- c(2.8, 3.4, 3.7, 2.2, 2.0) # with asbestosis
+  x <- c(x1, x2, x3)
+  g <- factor(rep(1:3, c(5, 4, 5)))
+
+  set.seed(1)
+  E <- rank_epsilon_squared(x, g)
+
+  expect_equal(E[[1]], 0.05934066, tolerance = 0.01)
+  expect_equal(E$CI_low, 0.01726463, tolerance = 0.01)
+  expect_equal(E$CI_high, 1)
+
+  expect_equal(
+    rank_epsilon_squared(x ~ g, ci = NULL),
+    rank_epsilon_squared(x, g, ci = NULL)
+  )
+})
+
+
+test_that(""kendalls_w"", {
+  skip_if_not_installed(""boot"")
+  skip_if_not_installed(""base"", minimum_version = ""3.6.1"")
+  M1 <- cbind(
+    ""Round Out"" = c(5.4, 5.85, 5.2),
+    ""Narrow Angle"" = c(5.5, 5.7, 5.6),
+    ""Wide Angle"" = c(5.55, 5.75, 5.5)
+  )
+
+  M2 <- data.frame(
+    id = c(1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 3L),
+    name = c(
+      ""Round Out"", ""Narrow Angle"", ""Wide Angle"",
+      ""Round Out"", ""Narrow Angle"", ""Wide Angle"",
+      ""Round Out"", ""Narrow Angle"", ""Wide Angle""
+    ),
+    value = c(5.4, 5.5, 5.55, 5.85, 5.7, 5.75, 5.2, 5.6, 5.5)
+  )
+
+  set.seed(1)
+  W1 <- kendalls_w(M1)
+  W2 <- kendalls_w(value ~ name | id, data = M2, ci = NULL)
+  W3 <- kendalls_w(M2$value, M2$name, M2$id, ci = NULL)
+  W4 <- kendalls_w(M2$value ~ M2$name | M2$id, ci = NULL)
+
+  expect_equal(W1[[1]], W2[[1]])
+  expect_equal(W1[[1]], W3[[1]])
+  expect_equal(W1[[1]], W4[[1]])
+  expect_equal(W1[[1]], 0.11111111, tolerance = 0.01)
+  expect_equal(W1$CI_low, 0.11111111, tolerance = 0.01)
+  expect_equal(W1$CI_high, 1, tolerance = 0.01)
+
+  # Ties
+  dat <- data.frame(
+    pno = c(
+      1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L,
+      3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 7L, 7L,
+      7L, 7L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L
+    ),
+    condition = c(
+      1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L,
+      1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L,
+      1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L,
+      2L
+    ),
+    congruency = c(
+      1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
+      1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
+      2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
+      1L, 2L
+    ),
+    mrt = c(
+      0.86, 0.86, 0.86, 0.78, 0.56, 0.56, 0.59, 0.66, 0.48,
+      0.5, 0.47, 0.51, 0.48, 0.52, 0.45, 0.47, 0.65, 0.79, 0.7,
+      0.81, 0.58, 0.6, 0.57, 0.6, 0.53, 0.61, 0.47, 0.49, 0.56,
+      0.64, 0.56, 0.6, 0.56, 0.66, 0.59, 0.63, 0.7, 0.92, 0.8,
+      0.96
     )
-    expect_equal(
-      rank_biserial(outcome ~ g, data = df, ci = NULL),
-      rank_biserial(""outcome"", ""g"", data = df, ci = NULL)
-    )
-  })
-
-
-  test_that(""rank_epsilon_squared"", {
-    skip_if_not_installed(""boot"")
-    skip_if_not_installed(""base"", minimum_version = ""3.6.1"")
-    x1 <- c(2.9, 3.0, 2.5, 2.6, 3.2) # normal subjects
-    x2 <- c(3.8, 2.7, 4.0, 2.4) # with obstructive airway disease
-    x3 <- c(2.8, 3.4, 3.7, 2.2, 2.0) # with asbestosis
-    x <- c(x1, x2, x3)
-    g <- factor(rep(1:3, c(5, 4, 5)))
+  )
+  dat
 
-    set.seed(1)
-    E <- rank_epsilon_squared(x, g)
+  W <- kendalls_w(mrt ~ interaction(condition, congruency) | pno, data = dat, verbose = FALSE)
+  expect_equal(W[[1]], 0.4011, tolerance = 0.01)
 
-    expect_equal(E[[1]], 0.05934066, tolerance = 0.01)
-    expect_equal(E$CI_low, 0.01726463, tolerance = 0.01)
-    expect_equal(E$CI_high, 1)
-
-    expect_equal(
-      rank_epsilon_squared(x ~ g, ci = NULL),
-      rank_epsilon_squared(x, g, ci = NULL)
-    )
-  })
 
 
-  test_that(""kendalls_w"", {
-    skip_if_not_installed(""boot"")
-    skip_if_not_installed(""base"", minimum_version = ""3.6.1"")
-    M1 <- cbind(
-      ""Round Out"" = c(5.4, 5.85, 5.2),
-      ""Narrow Angle"" = c(5.5, 5.7, 5.6),
-      ""Wide Angle"" = c(5.55, 5.75, 5.5)
-    )
-
-    M2 <- data.frame(
-      id = c(1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 3L),
-      name = c(
-        ""Round Out"", ""Narrow Angle"", ""Wide Angle"",
-        ""Round Out"", ""Narrow Angle"", ""Wide Angle"",
-        ""Round Out"", ""Narrow Angle"", ""Wide Angle""
-      ),
-      value = c(5.4, 5.5, 5.55, 5.85, 5.7, 5.75, 5.2, 5.6, 5.5)
-    )
-
-    set.seed(1)
-    W1 <- kendalls_w(M1)
-    W2 <- kendalls_w(value ~ name | id, data = M2, ci = NULL)
-    W3 <- kendalls_w(M2$value, M2$name, M2$id, ci = NULL)
-    W4 <- kendalls_w(M2$value ~ M2$name | M2$id, ci = NULL)
-
-    expect_equal(W1[[1]], W2[[1]])
-    expect_equal(W1[[1]], W3[[1]])
-    expect_equal(W1[[1]], W4[[1]])
-    expect_equal(W1[[1]], 0.11111111, tolerance = 0.01)
-    expect_equal(W1$CI_low, 0.11111111, tolerance = 0.01)
-    expect_equal(W1$CI_high, 1, tolerance = 0.01)
-
-    # Ties
-    dat <- data.frame(
-      pno = c(
-        1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L,
-        3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 7L, 7L,
-        7L, 7L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L
-      ),
-      condition = c(
-        1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L,
-        1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L,
-        1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L,
-        2L
-      ),
-      congruency = c(
-        1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
-        1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
-        2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
-        1L, 2L
-      ),
-      mrt = c(
-        0.86, 0.86, 0.86, 0.78, 0.56, 0.56, 0.59, 0.66, 0.48,
-        0.5, 0.47, 0.51, 0.48, 0.52, 0.45, 0.47, 0.65, 0.79, 0.7,
-        0.81, 0.58, 0.6, 0.57, 0.6, 0.53, 0.61, 0.47, 0.49, 0.56,
-        0.64, 0.56, 0.6, 0.56, 0.66, 0.59, 0.63, 0.7, 0.92, 0.8,
-        0.96
-      )
-    )
-    dat
-
-    W <- kendalls_w(mrt ~ interaction(condition, congruency) | pno, data = dat, verbose = FALSE)
-    expect_equal(W[[1]], 0.4011, tolerance = 0.01)
-
-
-
-    # singular ties
-    m <- rbind(
-      c(1, 2, 3, 4),
-      c(7, 7, 7, 7), # THIS
-      c(2, 3, 1, 4)
-    )
+  # singular ties
+  m <- rbind(
+    c(1, 2, 3, 4),
+    c(7, 7, 7, 7), # THIS
+    c(2, 3, 1, 4)
+  )
 
-    expect_warning(kendalls_w(m, ci = NULL), ""contain ties"")
-    expect_warning(W <- kendalls_w(m, ci = NULL), ""unique ranking"")
-    expect_equal(W[[1]], 0.4666667, tolerance = 0.001)
-    expect_equal(kendalls_w(t(m), blocks_on_rows = FALSE, ci = NULL, verbose = FALSE)[[1]], W[[1]])
-  })
-}
+  expect_warning(kendalls_w(m, ci = NULL), ""contain ties"")
+  expect_warning(W <- kendalls_w(m, ci = NULL), ""unique ranking"")
+  expect_equal(W[[1]], 0.4666667, tolerance = 0.001)
+  expect_equal(kendalls_w(t(m), blocks_on_rows = FALSE, ci = NULL, verbose = FALSE)[[1]], W[[1]])
+})

---FILE: tests/testthat/test-standardized_differences.R---
@@ -1,152 +1,151 @@
-if (require(""testthat"") && require(""effectsize"")) {
-  test_that(""cohens_d errors and warnings"", {
-    # Direction ---------------------------------------------------------------
-    rez_t <- t.test(iris$Sepal.Length, iris$Sepal.Width)
-    rez_d <- cohens_d(iris$Sepal.Length, iris$Sepal.Width)
-    expect_equal(sign(rez_t$statistic), sign(rez_d$Cohens_d), ignore_attr = TRUE)
-
-
-    # Alternative -------------------------------------------------------------
-    d1 <- cohens_d(iris$Sepal.Length, iris$Sepal.Width, ci = 0.80)
-    d2 <- cohens_d(iris$Sepal.Length, iris$Sepal.Width, ci = 0.90, alternative = ""l"")
-    d3 <- cohens_d(iris$Sepal.Length, iris$Sepal.Width, ci = 0.90, alternative = ""g"")
-    expect_equal(d1$CI_high, d2$CI_high)
-    expect_equal(d1$CI_low, d3$CI_low)
-
-
-    # Errors and warnings -----------------------------------------------------
-    df <- data.frame(
-      a = 1:10,
-      b = 2:11,
-      c = rep(letters[1:2], each = 5),
-      d = c(""a"", ""b"", ""b"", ""c"", ""c"", ""b"", ""c"", ""a"", ""a"", ""b""),
-      e = rep(0:1, each = 5)
-    )
-    df$exp_a <- exp(df$a)
-    a2 <- 1:11
-
-    expect_error(cohens_d(a ~ c, data = df), regexp = NA)
-    expect_error(cohens_d(""a"", ""c"", data = df), regexp = NA)
-    expect_error(cohens_d(""a"", ""b"", data = df), regexp = NA)
-    expect_error(cohens_d(a2, df$b), regexp = NA)
-    expect_error(cohens_d(b ~ e, data = df), regexp = NA)
-
-    expect_error(cohens_d(df$a ~ df$c), regexp = NA)
-    expect_equal(cohens_d(""exp_a"", ""c"", data = df), cohens_d(exp(a) ~ c, data = df))
-
-    expect_error(cohens_d(a ~ b, data = df), ""exactly"")
-    expect_error(cohens_d(a ~ d, data = df), ""exactly"")
-    expect_error(cohens_d(""a"", ""d"", data = df), ""exactly"")
-    expect_error(cohens_d(""c"", ""c"", data = df), ""non-numeric"")
-    expect_error(cohens_d(a2, df$c), ""length"")
-    expect_error(cohens_d(""a"", ""aa"", data = df), ""missing"")
-
-    expect_warning(cohens_d(""b"", ""e"", data = df), ""convert"")
-  })
-
-  test_that(""cohens d - grouping character vector"", {
-    dat <- data.frame(
-      g = rep(c(""treatment"", ""control""), each = 100),
-      y = c(rnorm(n = 200))
-    )
-
-    d <- cohens_d(dat$y, factor(dat$g), ci = NULL)[[1]]
-    expect_equal(cohens_d(dat$y, dat$g, ci = NULL)[[1]], d)
-    expect_equal(cohens_d(y ~ g, data = dat, ci = NULL)[[1]], d)
-    expect_equal(cohens_d(y ~ factor(g), data = dat, ci = NULL)[[1]], d)
-    expect_equal(cohens_d(dat$y ~ dat$g, ci = NULL)[[1]], d)
-    expect_equal(cohens_d(dat$y ~ factor(dat$g), ci = NULL)[[1]], d)
-    expect_equal(cohens_d(""y"", ""g"", data = dat, ci = NULL)[[1]], d)
-    expect_equal(cohens_d(""y"", dat$g, data = dat, ci = NULL)[[1]], d)
-    expect_equal(cohens_d(dat$y, ""g"", data = dat, ci = NULL)[[1]], d)
-  })
-
-  test_that(""cohens_d - mu"", {
-    expect_equal(cohens_d(mtcars$mpg - 5),
-      cohens_d(mtcars$mpg, mu = 5),
-      ignore_attr = TRUE
-    )
-
-    x <- 1:9
-    y <- c(1, 1:9)
-    expect_equal(cohens_d(x - 3, y),
-      cohens_d(x, y, mu = 3),
-      ignore_attr = TRUE
-    )
-
-    # t.test(x, y, mu = 3.125, var.equal = TRUE)
-    d <- cohens_d(x, y, mu = 3.125)
-    expect_equal(d[[1]], -0.969, tolerance = 0.01)
-    expect_equal(d$CI_low, -1.913, tolerance = 0.01)
-    expect_equal(d$CI_high[[1]], 0, tolerance = 0.01)
-  })
-
-  test_that(""cohens_d - pooled"", {
-    x <- cohens_d(wt ~ am, data = mtcars, pooled_sd = TRUE)
-    expect_equal(colnames(x)[1], ""Cohens_d"")
-    expect_equal(x[[1]], 1.892, tolerance = 0.001)
-    expect_equal(x$CI_low, 1.030, tolerance = 0.001)
-    expect_equal(x$CI_high, 2.732, tolerance = 0.001)
-  })
-
-  test_that(""cohens_d - non-pooled"", {
-    x <- cohens_d(wt ~ am, data = mtcars, pooled_sd = FALSE)
-    expect_equal(colnames(x)[1], ""Cohens_d"")
-    expect_equal(x[[1]], 1.934, tolerance = 0.001)
-    expect_equal(x$CI_low, 1.075151, tolerance = 0.001)
-    expect_equal(x$CI_high, 2.772516, tolerance = 0.001)
-  })
-
-  test_that(""hedges_g (and other bias correction things"", {
-    x <- hedges_g(wt ~ am, data = mtcars)
-    expect_equal(colnames(x)[1], ""Hedges_g"")
-    expect_equal(x[[1]], 1.844, tolerance = 0.001)
-    expect_equal(x$CI_low, 1.004, tolerance = 0.001)
-    expect_equal(x$CI_high, 2.664, tolerance = 0.001)
-  })
-
-  test_that(""glass_delta"", {
-    # must be 2 samples
-    expect_error(glass_delta(1:10), ""two"")
-    expect_error(glass_delta(""wt"", data = mtcars), ""two"")
-
-    x <- glass_delta(wt ~ am, data = mtcars)
-    expect_equal(colnames(x)[1], ""Glass_delta"")
-    expect_equal(x[[1]], 2.200, tolerance = 0.001)
-    expect_equal(x$CI_low, 1.008664, tolerance = 0.001)
-    expect_equal(x$CI_high, 3.352597, tolerance = 0.001)
-  })
-
-
-  test_that(""fixed values"", {
-    skip_if_not_installed(""bayestestR"")
-
-    x1 <- bayestestR::distribution_normal(1e4, mean = 0, sd = 1)
-    x2 <- bayestestR::distribution_normal(1e4, mean = 1, sd = 1)
-    expect_equal(cohens_d(x1, x2)$Cohens_d, -1, tolerance = 1e-3)
-
-
-    x1 <- bayestestR::distribution_normal(1e4, mean = 0, sd = 1)
-    x2 <- bayestestR::distribution_normal(1e4, mean = 1.5, sd = 2)
-
-    expect_equal(cohens_d(x1, x2)[[1]], -sqrt(0.9), tolerance = 1e-2)
-    expect_equal(glass_delta(x2, x1, ci = NULL)[[1]], 1.5, tolerance = 1e-2)
-  })
-
-  test_that(""Missing values"", {
-    x <- c(1, 2, NA, 3)
-    y <- c(1, 1, 2, 3)
-    expect_equal(cohens_d(x, y)[[1]], 0.2564946, tolerance = 0.01) # indep
-    expect_equal(cohens_d(x, y, paired = TRUE)[[1]], 0.5773503, tolerance = 0.01) # paired
-
-    # no length problems
-    expect_error(cohens_d(mtcars$mpg - 23), regexp = NA)
-
-    # Missing factor levels: the actual levels in the data are 3rd and 4th
-    f <- factor(letters[1:2], levels = c(""d"", ""e"", ""a"", ""b""))
-    f <- rep(f, each = 5)
-    y <- c(2, 4, 3, 5, 1, 7, 9, 8, 6, 1)
-    expect_error(d <- cohens_d(y, f), regexp = NA)
-    expect_true(attr(d, ""pooled_sd""))
-  })
-}
+
+test_that(""cohens_d errors and warnings"", {
+  # Direction ---------------------------------------------------------------
+  rez_t <- t.test(iris$Sepal.Length, iris$Sepal.Width)
+  rez_d <- cohens_d(iris$Sepal.Length, iris$Sepal.Width)
+  expect_equal(sign(rez_t$statistic), sign(rez_d$Cohens_d), ignore_attr = TRUE)
+
+
+  # Alternative -------------------------------------------------------------
+  d1 <- cohens_d(iris$Sepal.Length, iris$Sepal.Width, ci = 0.80)
+  d2 <- cohens_d(iris$Sepal.Length, iris$Sepal.Width, ci = 0.90, alternative = ""l"")
+  d3 <- cohens_d(iris$Sepal.Length, iris$Sepal.Width, ci = 0.90, alternative = ""g"")
+  expect_equal(d1$CI_high, d2$CI_high)
+  expect_equal(d1$CI_low, d3$CI_low)
+
+
+  # Errors and warnings -----------------------------------------------------
+  df <- data.frame(
+    a = 1:10,
+    b = 2:11,
+    c = rep(letters[1:2], each = 5),
+    d = c(""a"", ""b"", ""b"", ""c"", ""c"", ""b"", ""c"", ""a"", ""a"", ""b""),
+    e = rep(0:1, each = 5)
+  )
+  df$exp_a <- exp(df$a)
+  a2 <- 1:11
+
+  expect_error(cohens_d(a ~ c, data = df), regexp = NA)
+  expect_error(cohens_d(""a"", ""c"", data = df), regexp = NA)
+  expect_error(cohens_d(""a"", ""b"", data = df), regexp = NA)
+  expect_error(cohens_d(a2, df$b), regexp = NA)
+  expect_error(cohens_d(b ~ e, data = df), regexp = NA)
+
+  expect_error(cohens_d(df$a ~ df$c), regexp = NA)
+  expect_equal(cohens_d(""exp_a"", ""c"", data = df), cohens_d(exp(a) ~ c, data = df))
+
+  expect_error(cohens_d(a ~ b, data = df), ""exactly"")
+  expect_error(cohens_d(a ~ d, data = df), ""exactly"")
+  expect_error(cohens_d(""a"", ""d"", data = df), ""exactly"")
+  expect_error(cohens_d(""c"", ""c"", data = df), ""non-numeric"")
+  expect_error(cohens_d(a2, df$c), ""length"")
+  expect_error(cohens_d(""a"", ""aa"", data = df), ""missing"")
+
+  expect_warning(cohens_d(""b"", ""e"", data = df), ""convert"")
+})
+
+test_that(""cohens d - grouping character vector"", {
+  dat <- data.frame(
+    g = rep(c(""treatment"", ""control""), each = 100),
+    y = c(rnorm(n = 200))
+  )
+
+  d <- cohens_d(dat$y, factor(dat$g), ci = NULL)[[1]]
+  expect_equal(cohens_d(dat$y, dat$g, ci = NULL)[[1]], d)
+  expect_equal(cohens_d(y ~ g, data = dat, ci = NULL)[[1]], d)
+  expect_equal(cohens_d(y ~ factor(g), data = dat, ci = NULL)[[1]], d)
+  expect_equal(cohens_d(dat$y ~ dat$g, ci = NULL)[[1]], d)
+  expect_equal(cohens_d(dat$y ~ factor(dat$g), ci = NULL)[[1]], d)
+  expect_equal(cohens_d(""y"", ""g"", data = dat, ci = NULL)[[1]], d)
+  expect_equal(cohens_d(""y"", dat$g, data = dat, ci = NULL)[[1]], d)
+  expect_equal(cohens_d(dat$y, ""g"", data = dat, ci = NULL)[[1]], d)
+})
+
+test_that(""cohens_d - mu"", {
+  expect_equal(cohens_d(mtcars$mpg - 5),
+               cohens_d(mtcars$mpg, mu = 5),
+               ignore_attr = TRUE
+  )
+
+  x <- 1:9
+  y <- c(1, 1:9)
+  expect_equal(cohens_d(x - 3, y),
+               cohens_d(x, y, mu = 3),
+               ignore_attr = TRUE
+  )
+
+  # t.test(x, y, mu = 3.125, var.equal = TRUE)
+  d <- cohens_d(x, y, mu = 3.125)
+  expect_equal(d[[1]], -0.969, tolerance = 0.01)
+  expect_equal(d$CI_low, -1.913, tolerance = 0.01)
+  expect_equal(d$CI_high[[1]], 0, tolerance = 0.01)
+})
+
+test_that(""cohens_d - pooled"", {
+  x <- cohens_d(wt ~ am, data = mtcars, pooled_sd = TRUE)
+  expect_equal(colnames(x)[1], ""Cohens_d"")
+  expect_equal(x[[1]], 1.892, tolerance = 0.001)
+  expect_equal(x$CI_low, 1.030, tolerance = 0.001)
+  expect_equal(x$CI_high, 2.732, tolerance = 0.001)
+})
+
+test_that(""cohens_d - non-pooled"", {
+  x <- cohens_d(wt ~ am, data = mtcars, pooled_sd = FALSE)
+  expect_equal(colnames(x)[1], ""Cohens_d"")
+  expect_equal(x[[1]], 1.934, tolerance = 0.001)
+  expect_equal(x$CI_low, 1.075151, tolerance = 0.001)
+  expect_equal(x$CI_high, 2.772516, tolerance = 0.001)
+})
+
+test_that(""hedges_g (and other bias correction things"", {
+  x <- hedges_g(wt ~ am, data = mtcars)
+  expect_equal(colnames(x)[1], ""Hedges_g"")
+  expect_equal(x[[1]], 1.844, tolerance = 0.001)
+  expect_equal(x$CI_low, 1.004, tolerance = 0.001)
+  expect_equal(x$CI_high, 2.664, tolerance = 0.001)
+})
+
+test_that(""glass_delta"", {
+  # must be 2 samples
+  expect_error(glass_delta(1:10), ""two"")
+  expect_error(glass_delta(""wt"", data = mtcars), ""two"")
+
+  x <- glass_delta(wt ~ am, data = mtcars)
+  expect_equal(colnames(x)[1], ""Glass_delta"")
+  expect_equal(x[[1]], 2.200, tolerance = 0.001)
+  expect_equal(x$CI_low, 1.008664, tolerance = 0.001)
+  expect_equal(x$CI_high, 3.352597, tolerance = 0.001)
+})
+
+
+test_that(""fixed values"", {
+  skip_if_not_installed(""bayestestR"")
+
+  x1 <- bayestestR::distribution_normal(1e4, mean = 0, sd = 1)
+  x2 <- bayestestR::distribution_normal(1e4, mean = 1, sd = 1)
+  expect_equal(cohens_d(x1, x2)$Cohens_d, -1, tolerance = 1e-3)
+
+
+  x1 <- bayestestR::distribution_normal(1e4, mean = 0, sd = 1)
+  x2 <- bayestestR::distribution_normal(1e4, mean = 1.5, sd = 2)
+
+  expect_equal(cohens_d(x1, x2)[[1]], -sqrt(0.9), tolerance = 1e-2)
+  expect_equal(glass_delta(x2, x1, ci = NULL)[[1]], 1.5, tolerance = 1e-2)
+})
+
+test_that(""Missing values"", {
+  x <- c(1, 2, NA, 3)
+  y <- c(1, 1, 2, 3)
+  expect_equal(cohens_d(x, y)[[1]], 0.2564946, tolerance = 0.01) # indep
+  expect_equal(cohens_d(x, y, paired = TRUE)[[1]], 0.5773503, tolerance = 0.01) # paired
+
+  # no length problems
+  expect_error(cohens_d(mtcars$mpg - 23), regexp = NA)
+
+  # Missing factor levels: the actual levels in the data are 3rd and 4th
+  f <- factor(letters[1:2], levels = c(""d"", ""e"", ""a"", ""b""))
+  f <- rep(f, each = 5)
+  y <- c(2, 4, 3, 5, 1, 7, 9, 8, 6, 1)
+  expect_error(d <- cohens_d(y, f), regexp = NA)
+  expect_true(attr(d, ""pooled_sd""))
+})

---FILE: tests/testthat/test-xtab.R---
@@ -1,221 +1,220 @@
-if (require(""testthat"") && require(""effectsize"")) {
-  test_that(""contingency table"", {
-    contingency_table <- as.table(rbind(
-      c(762, 327, 468),
-      c(484, 239, 477),
-      c(484, 239, 477)
-    ))
-    res <- cramers_v(contingency_table)
-
-    expect_equal(res$Cramers_v, 0.072, tolerance = 0.01)
-    expect_equal(res$CI_low, 0.051, tolerance = 0.01)
-    expect_equal(res$CI_high, 1)
-
-    expect_error(phi(contingency_table), ""appropriate"")
-
-    expect_equal(tschuprows_t(contingency_table), res, ignore_attr = TRUE)
-
-    ## Size does not affect estimate
-    xtab <- rbind(
-      c(760, 330, 470),
-      c(480, 240, 480),
-      c(480, 240, 480)
-    )
-
-    cv1 <- cramers_v(xtab)
-    cv2 <- cramers_v(xtab / 2)
-
-    expect_equal(cv1$Cramers_v, cv2$Cramers_v)
-
-    # Upper bound of phi is the ratio between phi / V and sqrt(min(K,L)-1)
-    expect_equal(cohens_w(xtab, alternative = ""greater"")$CI_high, sqrt(2))
-    expect_equal(cohens_w(xtab)[[1]] / cramers_v(xtab)[[1]], sqrt(2))
-
-    # Tschuprows_t with non-square tables
-    xtab <- rbind(
-      c(9, 0, 1),
-      c(0, 1, 0)
-    )
-    expect_equal(cramers_v(xtab)[[1]], 1)
-    expect_true(tschuprows_t(xtab)[[1]] < cramers_v(xtab)[[1]])
-
-
-    ## 2*2 tables return phi and cramers_v
-    xtab <- rbind(
-      c(760, 330),
-      c(480, 240)
-    )
-
-    expect_equal(
-      cramers_v(xtab)[[1]],
-      phi(xtab)[[1]]
-    )
-
-    res <- pearsons_c(xtab)
-    expect_equal(res[[1]], 0.032, tolerance = 0.01)
-
-
-    ## 2*2 perfect correlation
-    xtab <- rbind(
-      c(100, 0),
-      c(0, 200)
-    )
-    expect_equal(V <- cramers_v(xtab)[[1]], 1)
-    expect_true(pearsons_c(xtab)[[1]] < V) # C is not perfect
-
-
-    ## 2*2 0 correlation
-    xtab <- rbind(
-      c(50, 50),
-      c(100, 100)
-    )
-    expect_equal(cramers_v(xtab)$Cramers_v, 0)
-
 
-    ## Empty rows/columns
-    xtab <- rbind(
-      c(50, 50, 0),
-      c(100, 100, 0)
-    )
-    expect_error(cramers_v(xtab), ""empty"")
-
-    ## 0
-    xtab <- table(mtcars$am, mtcars$vs)
-    phi3 <- phi(xtab, adjust = TRUE)
-    expect_equal(phi3$phi_adjusted, 0)
-    expect_equal(phi3$CI_low, 0)
-    expect_equal(phi3$CI_high, 1)
-  })
-
-
-  test_that(""goodness of fit"", {
-    expect_error(cramers_v(table(mtcars$cyl)), ""goodness"")
-
-    w1 <- cohens_w(table(mtcars$cyl), p = c(0.34375, 0.21875, 0.43750))
-    w2 <- cohens_w(table(mtcars$cyl), p = c(0.8, 0.1, 0.1))
-
-    Fei1 <- fei(table(mtcars$cyl), p = c(0.34375, 0.21875, 0.43750))
-    Fei2 <- fei(table(mtcars$cyl), p = c(0.8, 0.1, 0.1))
-
-    expect_equal(w1[[1]], 0)
-    expect_true(w1[[1]] < w2[[1]])
-    expect_true(Fei1[[1]] < Fei2[[1]])
-    expect_true(Fei2[[1]] < w2[[1]])
-    expect_equal(w2[[1]] * sqrt(0.1 / 0.9), Fei2[[1]])
-    expect_true(w1$CI_low < w2$CI_low)
-    expect_true(w2$CI_low < w2$CI_high)
-    expect_equal(w2$CI_high, Inf)
-
-    C <- pearsons_c(table(mtcars$cyl), p = c(0.8, 0.1, 0.1))
-    expect_equal(C[[1]], sqrt(49.289 / (49.289 + sum(table(mtcars$cyl)))), tolerance = 0.001)
-    expect_equal(C$CI_high, 1)
-
-    # some weird exeptions...
-    df <- subset(mtcars, am == ""0"")
-    expect_equal(cohens_w(table(df$am, df$cyl))[[1]], 0.64, tolerance = 0.01)
-    expect_equal(cohens_w(table(df$am, df$cyl)), cohens_w(table(df$cyl)))
-    expect_equal(cohens_w(table(df$am, df$cyl)), cohens_w(table(df$cyl, df$am)))
-
-    # p is a table
-    O <- as.table(c(10, 20, 30, 40))
-    E_vec <- c(11, 13, 44, 23)
-    E_tab <- as.table(E_vec)
-
-    expect_equal(
-      cohens_w(O, p = E_vec, rescale.p = TRUE),
-      cohens_w(O, p = E_tab, rescale.p = TRUE)
-    )
-    expect_equal(
-      fei(O, p = E_vec, rescale.p = TRUE),
-      fei(O, p = E_tab, rescale.p = TRUE)
-    )
-    expect_equal(
-      pearsons_c(O, p = E_vec, rescale.p = TRUE),
-      pearsons_c(O, p = E_tab, rescale.p = TRUE)
-    )
-  })
-
-  test_that(""oddsratio & riskratio"", {
-    ## Risk ratio
-    RCT <- rbind(
-      c(30, 71),
-      c(100, 50)
-    )
-    OR <- oddsratio(RCT)
-    RR <- riskratio(RCT)
-    p0 <- RCT[1, 2] / sum(RCT[, 2])
-
-    expect_equal(
-      oddsratio_to_riskratio(OR$Odds_ratio, p0),
-      RR$Risk_ratio
-    )
-    expect_equal(
-      riskratio_to_oddsratio(RR$Risk_ratio, p0),
-      OR$Odds_ratio
-    )
-
-    expect_error(riskratio(RCT, log = TRUE), NA)
-
-
-    ## OR
-    data(""mtcars"")
-    expect_error(oddsratio(mtcars$am, mtcars$cyl), ""only"")
-
-    m <- glm(am ~ I(cyl > 4), data = mtcars, family = binomial())
-    log_or <- oddsratio(mtcars$am, mtcars$cyl > 4, log = TRUE)
-
-    expect_equal(coef(m)[2], log_or$log_Odds_ratio,
-      ignore_attr = TRUE
-    )
-
-    expect_equal(log_or, oddsratio(mtcars$cyl > 4, mtcars$am, log = TRUE))
-
-    skip_if_not_installed(""MASS"")
-    expect_equal(confint(m)[2, ],
-      unlist(log_or[c(""CI_low"", ""CI_high"")]),
-      tolerance = 0.1, # different methods, give slightly different values
-      ignore_attr = TRUE
-    )
-  })
-
-
-  test_that(""Cohen's g"", {
-    # From mcnemar.test
-    Performance <-
-      matrix(c(794, 86, 150, 570),
-        nrow = 2,
-        dimnames = list(
-          ""1st Survey"" = c(""Approve"", ""Disapprove""),
-          ""2nd Survey"" = c(""Approve"", ""Disapprove"")
-        )
-      )
-    g <- cohens_g(Performance)
-    expect_equal(g$Cohens_g, 0.136, tolerance = 0.01)
-    expect_equal(g$CI_low, 0.072, tolerance = 0.01)
-    expect_equal(g$CI_high, 0.194, tolerance = 0.01)
-
-
-    AndersonRainBarrel <- matrix(c(
-      9L, 17L,
-      5L, 15L
-    ), nrow = 2)
-    g <- cohens_g(AndersonRainBarrel)
-    expect_equal(g$Cohens_g, 0.273, tolerance = 0.01)
-    expect_equal(g$CI_low, 0.066, tolerance = 0.01)
-    expect_equal(g$CI_high, 0.399, tolerance = 0.01)
-
-
-    M <- matrix(
-      c(
-        794, 86, 150,
-        570, 794, 86,
-        150, 570, 15
-      ),
-      nrow = 3
-    )
-    g <- cohens_g(M)
-    expect_equal(g$Cohens_g, 0.300, tolerance = 0.01)
-    expect_equal(g$CI_low, 0.280, tolerance = 0.01)
-    expect_equal(g$CI_high, 0.319, tolerance = 0.01)
-  })
-}
+test_that(""contingency table"", {
+  contingency_table <- as.table(rbind(
+    c(762, 327, 468),
+    c(484, 239, 477),
+    c(484, 239, 477)
+  ))
+  res <- cramers_v(contingency_table)
+
+  expect_equal(res$Cramers_v, 0.072, tolerance = 0.01)
+  expect_equal(res$CI_low, 0.051, tolerance = 0.01)
+  expect_equal(res$CI_high, 1)
+
+  expect_error(phi(contingency_table), ""appropriate"")
+
+  expect_equal(tschuprows_t(contingency_table), res, ignore_attr = TRUE)
+
+  ## Size does not affect estimate
+  xtab <- rbind(
+    c(760, 330, 470),
+    c(480, 240, 480),
+    c(480, 240, 480)
+  )
+
+  cv1 <- cramers_v(xtab)
+  cv2 <- cramers_v(xtab / 2)
+
+  expect_equal(cv1$Cramers_v, cv2$Cramers_v)
+
+  # Upper bound of phi is the ratio between phi / V and sqrt(min(K,L)-1)
+  expect_equal(cohens_w(xtab, alternative = ""greater"")$CI_high, sqrt(2))
+  expect_equal(cohens_w(xtab)[[1]] / cramers_v(xtab)[[1]], sqrt(2))
+
+  # Tschuprows_t with non-square tables
+  xtab <- rbind(
+    c(9, 0, 1),
+    c(0, 1, 0)
+  )
+  expect_equal(cramers_v(xtab)[[1]], 1)
+  expect_true(tschuprows_t(xtab)[[1]] < cramers_v(xtab)[[1]])
+
+
+  ## 2*2 tables return phi and cramers_v
+  xtab <- rbind(
+    c(760, 330),
+    c(480, 240)
+  )
+
+  expect_equal(
+    cramers_v(xtab)[[1]],
+    phi(xtab)[[1]]
+  )
+
+  res <- pearsons_c(xtab)
+  expect_equal(res[[1]], 0.032, tolerance = 0.01)
+
+
+  ## 2*2 perfect correlation
+  xtab <- rbind(
+    c(100, 0),
+    c(0, 200)
+  )
+  expect_equal(V <- cramers_v(xtab)[[1]], 1)
+  expect_true(pearsons_c(xtab)[[1]] < V) # C is not perfect
+
+
+  ## 2*2 0 correlation
+  xtab <- rbind(
+    c(50, 50),
+    c(100, 100)
+  )
+  expect_equal(cramers_v(xtab)$Cramers_v, 0)
+
+
+  ## Empty rows/columns
+  xtab <- rbind(
+    c(50, 50, 0),
+    c(100, 100, 0)
+  )
+  expect_error(cramers_v(xtab), ""empty"")
+
+  ## 0
+  xtab <- table(mtcars$am, mtcars$vs)
+  phi3 <- phi(xtab, adjust = TRUE)
+  expect_equal(phi3$phi_adjusted, 0)
+  expect_equal(phi3$CI_low, 0)
+  expect_equal(phi3$CI_high, 1)
+})
+
+
+test_that(""goodness of fit"", {
+  expect_error(cramers_v(table(mtcars$cyl)), ""goodness"")
+
+  w1 <- cohens_w(table(mtcars$cyl), p = c(0.34375, 0.21875, 0.43750))
+  w2 <- cohens_w(table(mtcars$cyl), p = c(0.8, 0.1, 0.1))
+
+  Fei1 <- fei(table(mtcars$cyl), p = c(0.34375, 0.21875, 0.43750))
+  Fei2 <- fei(table(mtcars$cyl), p = c(0.8, 0.1, 0.1))
+
+  expect_equal(w1[[1]], 0)
+  expect_true(w1[[1]] < w2[[1]])
+  expect_true(Fei1[[1]] < Fei2[[1]])
+  expect_true(Fei2[[1]] < w2[[1]])
+  expect_equal(w2[[1]] * sqrt(0.1 / 0.9), Fei2[[1]])
+  expect_true(w1$CI_low < w2$CI_low)
+  expect_true(w2$CI_low < w2$CI_high)
+  expect_equal(w2$CI_high, Inf)
+
+  C <- pearsons_c(table(mtcars$cyl), p = c(0.8, 0.1, 0.1))
+  expect_equal(C[[1]], sqrt(49.289 / (49.289 + sum(table(mtcars$cyl)))), tolerance = 0.001)
+  expect_equal(C$CI_high, 1)
+
+  # some weird exeptions...
+  df <- subset(mtcars, am == ""0"")
+  expect_equal(cohens_w(table(df$am, df$cyl))[[1]], 0.64, tolerance = 0.01)
+  expect_equal(cohens_w(table(df$am, df$cyl)), cohens_w(table(df$cyl)))
+  expect_equal(cohens_w(table(df$am, df$cyl)), cohens_w(table(df$cyl, df$am)))
+
+  # p is a table
+  O <- as.table(c(10, 20, 30, 40))
+  E_vec <- c(11, 13, 44, 23)
+  E_tab <- as.table(E_vec)
+
+  expect_equal(
+    cohens_w(O, p = E_vec, rescale.p = TRUE),
+    cohens_w(O, p = E_tab, rescale.p = TRUE)
+  )
+  expect_equal(
+    fei(O, p = E_vec, rescale.p = TRUE),
+    fei(O, p = E_tab, rescale.p = TRUE)
+  )
+  expect_equal(
+    pearsons_c(O, p = E_vec, rescale.p = TRUE),
+    pearsons_c(O, p = E_tab, rescale.p = TRUE)
+  )
+})
+
+test_that(""oddsratio & riskratio"", {
+  ## Risk ratio
+  RCT <- rbind(
+    c(30, 71),
+    c(100, 50)
+  )
+  OR <- oddsratio(RCT)
+  RR <- riskratio(RCT)
+  p0 <- RCT[1, 2] / sum(RCT[, 2])
+
+  expect_equal(
+    oddsratio_to_riskratio(OR$Odds_ratio, p0),
+    RR$Risk_ratio
+  )
+  expect_equal(
+    riskratio_to_oddsratio(RR$Risk_ratio, p0),
+    OR$Odds_ratio
+  )
+
+  expect_error(riskratio(RCT, log = TRUE), NA)
+
+
+  ## OR
+  data(""mtcars"")
+  expect_error(oddsratio(mtcars$am, mtcars$cyl), ""only"")
+
+  m <- glm(am ~ I(cyl > 4), data = mtcars, family = binomial())
+  log_or <- oddsratio(mtcars$am, mtcars$cyl > 4, log = TRUE)
+
+  expect_equal(coef(m)[2], log_or$log_Odds_ratio,
+               ignore_attr = TRUE
+  )
+
+  expect_equal(log_or, oddsratio(mtcars$cyl > 4, mtcars$am, log = TRUE))
+
+  skip_if_not_installed(""MASS"")
+  expect_equal(confint(m)[2, ],
+               unlist(log_or[c(""CI_low"", ""CI_high"")]),
+               tolerance = 0.1, # different methods, give slightly different values
+               ignore_attr = TRUE
+  )
+})
+
+
+test_that(""Cohen's g"", {
+  # From mcnemar.test
+  Performance <-
+    matrix(c(794, 86, 150, 570),
+           nrow = 2,
+           dimnames = list(
+             ""1st Survey"" = c(""Approve"", ""Disapprove""),
+             ""2nd Survey"" = c(""Approve"", ""Disapprove"")
+           )
+    )
+  g <- cohens_g(Performance)
+  expect_equal(g$Cohens_g, 0.136, tolerance = 0.01)
+  expect_equal(g$CI_low, 0.072, tolerance = 0.01)
+  expect_equal(g$CI_high, 0.194, tolerance = 0.01)
+
+
+  AndersonRainBarrel <- matrix(c(
+    9L, 17L,
+    5L, 15L
+  ), nrow = 2)
+  g <- cohens_g(AndersonRainBarrel)
+  expect_equal(g$Cohens_g, 0.273, tolerance = 0.01)
+  expect_equal(g$CI_low, 0.066, tolerance = 0.01)
+  expect_equal(g$CI_high, 0.399, tolerance = 0.01)
+
+
+  M <- matrix(
+    c(
+      794, 86, 150,
+      570, 794, 86,
+      150, 570, 15
+    ),
+    nrow = 3
+  )
+  g <- cohens_g(M)
+  expect_equal(g$Cohens_g, 0.300, tolerance = 0.01)
+  expect_equal(g$CI_low, 0.280, tolerance = 0.01)
+  expect_equal(g$CI_high, 0.319, tolerance = 0.01)
+})",True,False,Implementation / Logic,6
easystats,effectsize,baa52aa9f02efc6ba87f900a244d13c7e027465b,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-09-22T04:14:52Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-09-22T04:14:52Z,"use varepsilon

https://github.com/easystats/effectsize/issues/488#issuecomment-1253646104

@strengejacke If you need to also change in insight",R/is_effectsize_name.R;tests/testthat/test-printing.R,False,True,True,False,5,4,9,"---FILE: R/is_effectsize_name.R---
@@ -79,8 +79,8 @@ es_info <- matrix(
     ""Eta2"", ""Eta2"", ""\u03B7\u00b2"", ""onetail"", 0, 1, 0,
     ""Eta2_partial"", ""Eta2 (partial)"", ""\u03B7\u00b2 (partial)"", ""onetail"", 0, 1, 0,
     ""Eta2_generalized"", ""Eta2 (generalized)"", ""\u03B7\u00b2 (generalized)"", ""onetail"", 0, 1, 0,
-    ""Epsilon2"", ""Epsilon2"", ""\u03F5\u00b2"", ""onetail"", 0, 1, 0,
-    ""Epsilon2_partial"", ""Epsilon2 (partial)"", ""\u03F5\u00b2 (partial)"", ""onetail"", 0, 1, 0,
+    ""Epsilon2"", ""Epsilon2"", ""\u03B5\u00b2"", ""onetail"", 0, 1, 0,
+    ""Epsilon2_partial"", ""Epsilon2 (partial)"", ""\u03B5\u00b2 (partial)"", ""onetail"", 0, 1, 0,
     ""Omega2"", ""Omega2"", ""\u03C9\u00b2"", ""onetail"", 0, 1, 0,
     ""Omega2_partial"", ""Omega2 (partial)"", ""\u03C9\u00b2 (partial)"", ""onetail"", 0, 1, 0,
     ""Cohens_f"", ""Cohen's f"", NA, ""onetail"", 0, Inf, 0,

---FILE: tests/testthat/test-printing.R---
@@ -168,8 +168,9 @@ if (require(""testthat"") && require(""effectsize"")) {
 
 
 test_that(""printing symbols works as expected"", {
-  skip_if_not(packageVersion(""base"") >= package_version(""4.2"") &&
-                Sys.info()[""sysname""] != ""windows"")
+  skip_if(getRversion() < 4.2 &&
+            (Sys.info()[""sysname""] == ""windows"" ||
+               grepl(""^mingw"", R.version$os)))
 
   RCT <- matrix(c(71, 50, 30, 100), nrow = 2L)
   P <- phi(RCT)",True,False,Implementation / Logic,6
easystats,effectsize,ee5c9701a177f81a46dc240b9b1f27b770f55676,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-09-21T13:18:24Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-09-21T13:18:24Z,fix system detection,R/is_effectsize_name.R,False,True,True,False,4,2,6,"---FILE: R/is_effectsize_name.R---
@@ -132,6 +132,8 @@ rownames(es_info) <- es_info$name
 #' @importFrom utils packageVersion
 .resolve_use_symbols <- function(use_symbols) {
   use_symbols &&
-    utils::packageVersion(""base"") >= package_version(""4.2"") &&
-    Sys.info()[""sysname""] != ""windows""
+    !(
+      (Sys.info()[""sysname""] == ""windows"" || grepl(""^mingw"", R.version$os)) &&
+        getRversion() < ""4.2""
+    )
 }",True,False,Documentation / Formatting,3
easystats,effectsize,65fbee3c539b79cb5f0d3a9af590d22107097798,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-09-20T21:01:45Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-09-20T21:01:45Z,fix winbuilder render issue,R/convert_between_common_language.R;R/convert_stat_chisq.R;man/convert_chisq.Rd;man/diff_to_cles.Rd,False,True,True,False,8,8,16,"---FILE: R/convert_between_common_language.R---
@@ -7,11 +7,11 @@
 #' This function use the following formulae for Cohen's *d*:
 #' \deqn{Pr(superiority) = \Phi(d/\sqrt{2})}{Pr(superiority) = pnorm(d / sqrt(2))}
 #' \cr
-#' \deqn{\text{Cohen's }U_3 = \Phi(d)}{U3 = pnorm(d)}
+#' \deqn{\textrm{Cohen's } U_3 = \Phi(d)}{U3 = pnorm(d)}
 #' \cr
-#' \deqn{\text{Cohen's }U_2 = \Phi(|d|/2)}{U2 = pnorm(abs(d)/2)}
+#' \deqn{\textrm{Cohen's } U_2 = \Phi(|d|/2)}{U2 = pnorm(abs(d)/2)}
 #' \cr
-#' \deqn{\text{Cohen's }U_1 = (2\times U_2 - 1)/U_2}{U1 = (2 * U2 - 1) / U2}
+#' \deqn{\textrm{Cohen's } U_1 = (2\times U_2 - 1)/U_2}{U1 = (2 * U2 - 1) / U2}
 #' \cr
 #' \deqn{Overlap = 2 \times \Phi(-|d|/2)}{Overlap = 2 * pnorm(-abs(d) / 2)}
 #' \cr

---FILE: R/convert_stat_chisq.R---
@@ -29,7 +29,7 @@
 #' \ifelse{latex}{
 #' \deqn{\textrm{Cramer's } V = \phi / \sqrt{\min(\textit{nrow}, \textit{ncol}) - 1}}
 #' }{
-#' \deqn{\textrm{Cramer's } V = \phi / \sqrt{\min(\textit{nrow}, \textit{ncol }) - 1}}{Cramer's V = \phi / sqrt(min(nrow, ncol) - 1)}
+#' \deqn{\textrm{Cramer's } V = \phi / \sqrt{\min(\textit{nrow}, \textit{ncol}) - 1}}{Cramer's V = \phi / sqrt(min(nrow, ncol) - 1)}
 #' }
 #'
 #' \ifelse{latex}{

---FILE: man/convert_chisq.Rd---
@@ -95,7 +95,7 @@ These functions use the following formulas:
 \ifelse{latex}{
 \deqn{\textrm{Cramer's } V = \phi / \sqrt{\min(\textit{nrow}, \textit{ncol}) - 1}}
 }{
-\deqn{\textrm{Cramer's } V = \phi / \sqrt{\min(\textit{nrow}, \textit{ncol }) - 1}}{Cramer's V = \phi / sqrt(min(nrow, ncol) - 1)}
+\deqn{\textrm{Cramer's } V = \phi / \sqrt{\min(\textit{nrow}, \textit{ncol}) - 1}}{Cramer's V = \phi / sqrt(min(nrow, ncol) - 1)}
 }
 
 \ifelse{latex}{

---FILE: man/diff_to_cles.Rd---
@@ -43,11 +43,11 @@ Convert Standardized Differences to Common Language Effect Sizes
 This function use the following formulae for Cohen's \emph{d}:
 \deqn{Pr(superiority) = \Phi(d/\sqrt{2})}{Pr(superiority) = pnorm(d / sqrt(2))}
 \cr
-\deqn{\text{Cohen's }U_3 = \Phi(d)}{U3 = pnorm(d)}
+\deqn{\textrm{Cohen's } U_3 = \Phi(d)}{U3 = pnorm(d)}
 \cr
-\deqn{\text{Cohen's }U_2 = \Phi(|d|/2)}{U2 = pnorm(abs(d)/2)}
+\deqn{\textrm{Cohen's } U_2 = \Phi(|d|/2)}{U2 = pnorm(abs(d)/2)}
 \cr
-\deqn{\text{Cohen's }U_1 = (2\times U_2 - 1)/U_2}{U1 = (2 * U2 - 1) / U2}
+\deqn{\textrm{Cohen's } U_1 = (2\times U_2 - 1)/U_2}{U1 = (2 * U2 - 1) / U2}
 \cr
 \deqn{Overlap = 2 \times \Phi(-|d|/2)}{Overlap = 2 * pnorm(-abs(d) / 2)}
 \cr",True,False,Documentation / Formatting,6
easystats,effectsize,e48e19bb60866066f96c59bf90af7593cf1cd768,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-09-20T19:41:45Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-09-20T19:41:45Z,"Update NEWS.md

https://github.com/easystats/effectsize/issues/490",NEWS.md,False,False,False,False,1,0,1,"---FILE: NEWS.md---
@@ -19,6 +19,7 @@
 
 - Common-language effect sizes now respects `mu` argument for all effect sizes.
 - `mad_pooled()` not returns correct value (previously was inflated by a factor of 1.4826).
+- `pearsons_c()` and `chisq_to_pearsons_c()` lose the `adjust` argument which applied an irrelevant adjustment to the effect size.
 - Effect sizes for goodness-of-fit now work when passing a `p` that is a table.
 
 # effectsize 0.7.0.5",False,False,Documentation / Formatting,4
easystats,effectsize,ec666ffec988babe5a0370cd54ab096d65496518,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2022-09-20T13:58:44Z,GitHub,noreply@github.com,2022-09-20T13:58:44Z,"remove some unused attributes (#487)

* remove some unused attributes

* fix internal function

* Update eta_squared_posterior.R",R/cohens_d.R;R/convert_stat_chisq.R;R/convert_stat_to_anova.R;R/effectsize.BFBayesFactor.R;R/eta_squared.R;R/eta_squared_posterior.R;R/mahalanobis_D.R;R/utils_ncp_ci.R;R/xtab_diff.R;vignettes/effectsize_API.Rmd,True,True,True,False,7,20,27,"---FILE: R/cohens_d.R---
@@ -343,7 +343,6 @@ glass_delta <- function(x,
   class(out) <- c(""effectsize_difference"", ""effectsize_table"", ""see_effectsize_table"", class(out))
   .someattributes(out) <- .nlist(
     paired, pooled_sd, mu, ci, ci_method, alternative,
-    correction = type == ""g"",
     approximate = FALSE
   )
   return(out)

---FILE: R/convert_stat_chisq.R---
@@ -164,7 +164,6 @@ chisq_to_phi <- function(chisq, n, nrow = 2, ncol = 2, ci = 0.95, alternative =
   class(res) <- c(""effectsize_table"", ""see_effectsize_table"", class(res))
   attr(res, ""ci"") <- ci
   attr(res, ""ci_method"") <- ci_method
-  attr(res, ""adjust"") <- adjust
   attr(res, ""alternative"") <- alternative
   return(res)
 }

---FILE: R/convert_stat_to_anova.R---
@@ -239,7 +239,7 @@ t_to_f2 <- function(t, df_error, ci = 0.95, alternative = ""greater"", squared = T
 
     # based on MBESS::ci.R2
     f <- pmax(0, (res[[1]] / df) / ((1 - res[[1]]) / df_error))
-    fs <- t(mapply(.get_ncp_F, f, df, df_error, ci.level))
+    fs <- t(mapply(.get_ncp_F, f, df, df_error, ci.level)) / df
 
     if (isTRUE(verbose) && anyNA(fs)) {
       warning(""Some CIs could not be estimated due to non-finite F, df, or df_error values."", call. = FALSE)

---FILE: R/effectsize.BFBayesFactor.R---
@@ -38,9 +38,6 @@ effectsize.BFBayesFactor <- function(model, type = NULL, verbose = TRUE, test =
   .someattributes(out) <- pars$attr
   .someattributes(out) <- list(
     ci = out$CI,
-    # ci_method - inherited from bayestestR
-    correction = NULL,
-    pooled_sd = NULL,
     approximate = FALSE,
     alternative = ""two.sided""
   )
@@ -118,7 +115,7 @@ effectsize.BFBayesFactor <- function(model, type = NULL, verbose = TRUE, test =
 
   list(
     res = res,
-    attr = list(mu = mu, paired = paired),
+    attr = list(mu = mu, paired = paired, pooled_sd = TRUE),
     xtra_class = xtra_class
   )
 }

---FILE: R/eta_squared.R---
@@ -489,7 +489,6 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
   out$Parameter <- as.character(out$Parameter)
 
   # Set attributes ---
-  attr(out, ""partial"") <- partial
   attr(out, ""generalized"") <- generalized
   attr(out, ""ci"") <- ci
   attr(out, ""anova_type"") <- anova_type
@@ -635,7 +634,6 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
   rownames(out) <- NULL
   out$Parameter <- as.character(out$Parameter)
 
-  attr(out, ""partial"") <- partial
   attr(out, ""generalized"") <- generalized
   attr(out, ""ci"") <- ci
   attr(out, ""approximate"") <- FALSE
@@ -717,7 +715,6 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
   out$Parameter <- as.character(out$Parameter)
 
   # Set attributes ---
-  attr(out, ""partial"") <- TRUE
   attr(out, ""generalized"") <- FALSE
   attr(out, ""ci"") <- if (""CI"" %in% colnames(out)) ci
   attr(out, ""alternative"") <- if (!is.null(attr(out, ""ci""))) alternative
@@ -861,7 +858,6 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
   rownames(out) <- NULL
   out$Response <- as.character(out$Response)
 
-  attr(out, ""partial"") <- attr(params[[1]], ""partial"")
   attr(out, ""generalized"") <- attr(params[[1]], ""generalized"")
   attr(out, ""ci"") <- attr(params[[1]], ""ci"", exact = TRUE)
   attr(out, ""anova_type"") <- anova_type
@@ -971,7 +967,6 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
     out$Parameter <- as.character(out$Parameter)
 
     # Set attributes ---
-    attr(out, ""partial"") <- saved_attr$partial
     attr(out, ""generalized"") <- saved_attr$generalized
     attr(out, ""ci"") <- saved_attr$ci
     attr(out, ""alternative"") <- saved_attr$alternative

---FILE: R/eta_squared_posterior.R---
@@ -99,7 +99,6 @@ eta_squared_posterior.stanreg <- function(model,
   })
 
   res <- do.call(""rbind"", res)
-  attr(res, ""partial"") <- partial
   attr(res, ""generalized"") <- generalized
   return(res)
 }

---FILE: R/mahalanobis_D.R---
@@ -155,7 +155,7 @@ mahalanobis_d <- function(x, y = NULL, data = NULL,
 
     f <- ff * out[[1]]^2
 
-    fs <- .get_ncp_F(f, p, df, ci.level) * p
+    fs <- .get_ncp_F(f, p, df, ci.level)
 
     out$CI_low <- sqrt(fs[1] / hn)
     out$CI_high <- sqrt(fs[2] / hn)

---FILE: R/utils_ncp_ci.R---
@@ -20,7 +20,7 @@
     },
     control = list(abstol = 1e-09)
   ))
-  f_ncp <- sort(ncp$par) / df
+  f_ncp <- sort(ncp$par)
 
   if (f <= stats::qf(probs[1], df, df_error)) {
     f_ncp[2] <- 0

---FILE: R/xtab_diff.R---
@@ -127,7 +127,6 @@ oddsratio <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = F
   class(res) <- c(""effectsize_table"", ""see_effectsize_table"", class(res))
   attr(res, ""ci"") <- ci
   attr(res, ""ci_method"") <- ci_method
-  attr(res, ""log"") <- log
   attr(res, ""approximate"") <- FALSE
   attr(res, ""alternative"") <- alternative
   return(res)
@@ -205,7 +204,6 @@ riskratio <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = F
   class(res) <- c(""effectsize_table"", ""see_effectsize_table"", class(res))
   attr(res, ""ci"") <- ci
   attr(res, ""ci_method"") <- ci_method
-  attr(res, ""log"") <- log
   attr(res, ""approximate"") <- FALSE
   attr(res, ""alternative"") <- alternative
   return(res)

---FILE: vignettes/effectsize_API.Rmd---
@@ -83,7 +83,7 @@ Pass the data frame to `.es_aov_simple()`:
 
 The output is a data frame with the columns: `Parameter`, the effect size, and (optionally) `CI` + `CI_low` + `CI_high`,
 
-And with the following attributes: `partial`, `generalized`, `ci`, `alternative`, `anova_type` (`NA` or `NULL`), `approximate`.
+And with the following attributes: `generalized`, `ci`, `alternative`, `anova_type` (`NA` or `NULL`), `approximate`.
 
 You can then set the `anova_type` attribute to {1, 2, 3, or `NA`} and return the output.
 
@@ -129,7 +129,7 @@ Pass the data frame to `.es_aov_strata()`, along with a list of predictors (incl
 
 The output is a data frame with the columns: `Group`, `Parameter`, the effect size, and (optionally) `CI` + `CI_low` + `CI_high`,
 
-And with the following attributes: `partial`, `generalized`, `ci`, `alternative`, `approximate`.
+And with the following attributes: `generalized`, `ci`, `alternative`, `approximate`.
 
 You can then set the `anova_type` attribute to {1, 2, 3, or `NA`} and return the output.
 
@@ -173,7 +173,7 @@ Pass the table to `.es_aov_table()`:
 
 The output is a data frame with the columns: `Parameter`, the effect size, and (optionally) `CI` + `CI_low` + `CI_high`,
 
-And with the following attributes: `partial`, `generalized`, `ci`, `alternative`, `approximate`.
+And with the following attributes: `generalized`, `ci`, `alternative`, `approximate`.
 
 You can then set the `anova_type` attribute to {1, 2, 3, or `NA`} and return the output, and optionally the `approximate` attribute, and return the output.
 ",True,True,Implementation / Logic,6
easystats,effectsize,2da0c85320e9897480073793d6a925771d9d29aa,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2022-09-20T06:21:21Z,GitHub,noreply@github.com,2022-09-20T06:21:21Z,"new ES for Rank (#486)

* new vd_a

* Update zzz.R

* new rank_eta

* cleanup interp

* fix Eta maybe?

* oops, greek

* fix some links and stuff

* vda is just p_sup(param = F)

* simplify code for W

* plug easystats

https://github.com/easystats/easystats/issues/308",DESCRIPTION;NAMESPACE;NEWS.md;R/common_language.R;R/convert_between_common_language.R;R/effectsize.R;R/effectsize.htest.R;R/interpret.R;R/is_effectsize_name.R;R/rank_ANOVA.R;R/rank_diff.R;R/zzz.R;README.Rmd;README.md;man/diff_to_cles.Rd;man/effectsize.Rd;man/es_info.Rd;man/p_superiority.Rd;man/rank_biserial.Rd;man/rank_epsilon_squared.Rd;vignettes/simple_htests.Rmd,True,True,True,False,368,166,534,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size and Standardized Parameters
-Version: 0.7.0.99991
+Version: 0.7.9
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",

---FILE: NAMESPACE---
@@ -180,9 +180,11 @@ export(r_to_d)
 export(r_to_oddsratio)
 export(rank_biserial)
 export(rank_epsilon_squared)
+export(rank_eta_squared)
 export(rb_to_cles)
 export(rb_to_common_language)
 export(rb_to_p_superiority)
+export(rb_to_vda)
 export(riskratio)
 export(riskratio_to_oddsratio)
 export(rules)
@@ -200,6 +202,7 @@ export(t_to_f)
 export(t_to_f2)
 export(t_to_omega2)
 export(t_to_r)
+export(vd_a)
 export(z_to_d)
 export(z_to_r)
 importFrom(bayestestR,describe_posterior)

---FILE: NEWS.md---
@@ -8,6 +8,8 @@
 
 ## New features
 
+- `vd_a()` and `rb_to_vda()` for Vargha and Delaney's *A* dominance effect size (aliases for `p_superiority(parametric = FALSE)` and `rb_to_p_superiority()`).
+- `rank_eta_squared()` for one-way rank ANOVA.
 - `cohens_u1()`, `cohens_u2()`, `d_to_u1()`, and `d_to_u2()` added for Cohen's U1 and U2
 - `mahalanobis_d()` for multivariate standardized differences.
 

---FILE: R/common_language.R---
@@ -1,10 +1,10 @@
 #' Cohen's *U*s and Other Common Language Effect Sizes (CLES)
 #'
-#' Cohen's \eqn{U_1}, \eqn{U_2}, and \eqn{U_3}, probability of superiority, and
-#' proportion of overlap are CLESs. These are effect sizes that represent
-#' differences between two (independent) distributions in probabilistic terms
-#' (See details). Pair with any reported [`stats::t.test()`] or
-#' [`stats::wilcox.test()`].
+#' Cohen's \eqn{U_1}, \eqn{U_2}, and \eqn{U_3}, probability of superiority,
+#' Vargha and Delaney's *A*, and proportion of overlap are CLESs. These are
+#' effect sizes that represent differences between two (independent)
+#' distributions in probabilistic terms (See details). Pair with any reported
+#' [`stats::t.test()`] or [`stats::wilcox.test()`].
 #'
 #' @inheritParams cohens_d
 #' @param parametric Use parametric estimation (see [cohens_d()]) or
@@ -31,6 +31,9 @@
 #' and homoscedasticity. If those are not met, the non parametric versions
 #' should be used.
 #'
+#' Vargha and Delaney's *A* is an alias for the non-parametric *probability of
+#' superiority*.
+#'
 #' Where \eqn{U_1}, \eqn{U_2}, and *Overlap* are agnostic to the direction of
 #' the difference between the groups, \eqn{U_1} and probability of superiority
 #' are not.
@@ -62,6 +65,10 @@
 #' - Ruscio, J. (2008). A probability-based measure of effect size: robustness
 #' to base rates and other factors. Psychological methods, 13(1), 19â30.
 #'
+#' - Vargha, A., & Delaney, H. D. (2000). A critique and improvement of the CL
+#' common language effect size statistics of McGraw and Wong. Journal of
+#' Educational and Behavioral Statistics, 25(2), 101-132.
+#'
 #' @seealso [d_to_cles] [sd_pooled()]
 #' @family effect size indices
 #'
@@ -341,7 +348,21 @@ p_overlap <- function(x,
   out
 }
 
-
+#' @export
+#' @rdname p_superiority
+vd_a <- function(x,
+                 y = NULL,
+                 data = NULL,
+                 mu = 0,
+                 ci = 0.95,
+                 alternative = ""two.sided"",
+                 verbose = TRUE,
+                 ...) {
+  cl <- match.call()
+  cl[[1]] <- quote(p_superiority)
+  cl$parametric <- FALSE
+  eval.parent(cl)
+}
 
 
 

---FILE: R/convert_between_common_language.R---
@@ -23,8 +23,11 @@
 #'   on the input.
 #'
 #' @note
-#' These calculations assume that the populations have equal variance and are
-#' normally distributed.
+#' For *d*, these calculations assume that the populations have equal variance
+#' and are normally distributed.
+#'
+#' Vargha and Delaney's *A* is an alias for the non-parametric *probability of
+#' superiority*.
 #'
 #' @seealso See [cohens_u3] for descriptions of the effect sizes (also,
 #'   [cohens_d()], [rank_biserial()]).
@@ -71,6 +74,10 @@ rb_to_p_superiority.numeric <- function(rb) {
   (rb + 1) / 2
 }
 
+#' @export
+#' @rdname diff_to_cles
+rb_to_vda <- rb_to_p_superiority
+
 # U2 ----------------------------------------------------------------------
 
 #' @export

---FILE: R/effectsize.R---
@@ -16,12 +16,12 @@
 #'   - A **Chi-squared tests of goodness-of-fit**, depending on `type`: `""fei""` (default) `""cohens_w""`, `""pearsons_c""`
 #'   - A **One-way ANOVA test**, depending on `type`: `""eta""` (default), `""omega""` or `""epsilon""` -squared, `""f""`, or `""f2""`.
 #'   - A **McNemar test** returns *Cohen's g*.
-#'   - A **Wilcoxon test** depending on `type`: returns ""`rank_biserial`"" correlation (default) or one of `""p_superiority""`, `""u2""`, `""u3""`, `""overlap""`.
-#'   - A **Kruskal-Wallis test** returns *rank Epsilon squared*.
+#'   - A **Wilcoxon test** depending on `type`: returns ""`rank_biserial`"" correlation (default) or one of `""p_superiority""`, `""vda""`, `""u2""`, `""u3""`, `""overlap""`.
+#'   - A **Kruskal-Wallis test** depending on `type`: `""epsilon""` (default) or `""eta""`.
 #'   - A **Friedman test** returns *Kendall's W*.
 #'   (Where applicable, `ci` and `alternative` are taken from the `htest` if not otherwise provided.)
 #' - For an object of class `BFBayesFactor`, using [bayestestR::describe_posterior()],
-#'   - A **t-test** depending on `type`: ""cohens_d""` (default) or one of `""p_superiority""`, `""u1""`, `""u2""`, `""u3""`, `""overlap""`.
+#'   - A **t-test** depending on `type`: `""cohens_d""` (default) or one of `""p_superiority""`, `""u1""`, `""u2""`, `""u3""`, `""overlap""`.
 #'   - A **correlation test** returns *r*.
 #'   - A **contingency table test**, depending on `type`: `""cramers_v""` (default), `""phi""`, `""cohens_w""`, `""pearsons_c""`, `""cohens_h""`, `""oddsratio""`, or `""riskratio""`.
 #'   - A **proportion test** returns *p*.

---FILE: R/effectsize.htest.R---
@@ -254,7 +254,8 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
     u2 = cohens_u2,
     u3 = cohens_u3,
     overlap = p_overlap,
-    p_superiority = p_superiority
+    vda = ,
+    p_superiority = p_superiority,
   )
 
   args <- list(
@@ -284,14 +285,20 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
 
   dots <- list(...)
 
+  if (is.null(type)) type <- ""epsilon""
+
   .fail_if_approx(approx, ""rank_epsilon_squared"")
 
+  f <- switch (type,
+    epsilon = rank_epsilon_squared,
+    eta = rank_eta_squared
+  )
 
   if (inherits(data, ""data.frame"")) {
-    out <- rank_epsilon_squared(data[[1]], data[[2]], verbose = verbose, ...)
+    out <- f(data[[1]], data[[2]], verbose = verbose, ...)
   } else {
     # data frame
-    out <- rank_epsilon_squared(data, verbose = verbose, ...)
+    out <- f(data, verbose = verbose, ...)
   }
   out
 }

---FILE: R/interpret.R---
@@ -163,23 +163,33 @@ interpret.effectsize_table <- function(x, rules, ...) {
   value <- x[[es_name]]
 
   x$Interpretation <- switch(es_name,
-    # std diff
+    ## std diff
     Cohens_d = ,
     Hedges_g = ,
     Glass_delta = ,
-    d = interpret_cohens_d(value, rules = rules),
-    # xtab
+    Mahalanobis_D = interpret_cohens_d(value, rules = rules),
+
+    ## xtab cor
     Cramers_v = ,
     Cramers_v_adjusted = ,
-    normalized_chi = ,
-    fei = ,
-    Cohens_w = ,
     phi = ,
-    phi_adjusted = interpret_cramers_v(value, rules = rules),
-    Cohens_g = interpret_cohens_g(value, rules = rules),
+    phi_adjusted = ,
+    Pearsons_c = ,
+    Cohens_w = ,
+    fei = interpret_cramers_v(value, rules = rules),
+
+    ## xtab 2x2
+    Cohens_h = interpret_cohens_d(value, rules = rules),
     Odds_ratio = interpret_oddsratio(value, rules = rules, log = FALSE),
     log_Odds_ratio = interpret_oddsratio(value, rules = rules, log = TRUE),
-    # anova
+    # TODO:
+    # Risk_ratio = ,
+    # log_Risk_ratio = ,
+
+    ## xtab dep
+    Cohens_g = interpret_cohens_g(value, rules = rules),
+
+    ## anova
     Eta2 = ,
     Eta2_partial = ,
     Eta2_generalized = ,
@@ -191,12 +201,19 @@ interpret.effectsize_table <- function(x, rules, ...) {
     Cohens_f_partial = interpret_omega_squared(f_to_eta2(value), rules = rules),
     Cohens_f2 = ,
     Cohens_f2_partial = interpret_omega_squared(f2_to_eta2(value), rules = rules),
-    # rank
+
+    ## Rank
+    r_rank_biserial = interpret_r(value, rules = rules),
+    VDs_A = interpret_r(value * 2 - 1, rules = rules),
     Kendalls_W = interpret_kendalls_w(value, rules = rules),
-    r_rank_biserial = ,
     rank_epsilon_squared = ,
-    # corr
-    r = interpret_r(value, rules = rules)
+    rank_eta_squared = interpret_omega_squared(value, rules = rules),
+
+    # TODO: add cles as a transformation of d?
+
+    ## other
+    r = interpret_r(value, rules = rules),
+    d = interpret_cohens_d(value, rules = rules)
   )
 
   attr(x, ""rules"") <- attr(x$Interpretation, ""rules"")

---FILE: R/is_effectsize_name.R---
@@ -49,21 +49,25 @@ es_info <- matrix(
     ""Glass_delta"", ""Glass' delta"", ""twotail"", -Inf, Inf, 0,
     ""Mahalanobis_D"", ""Mahalanobis' D"", ""onetail"", 0, Inf, 0,
 
-    ## xtab
+    ## xtab cor
     ""Cramers_v"", ""Cramer's V"", ""onetail"", 0, 1, 0,
     ""Cramers_v_adjusted"", ""Cramer's V (adj.)"", ""onetail"", 0, 1, 0,
     ""phi"", ""Phi"", ""onetail"", 0, 1, 0,
     ""phi_adjusted"", ""Phi (adj.)"", ""onetail"", 0, 1, 0,
     ""Pearsons_c"", ""Pearson's C"", ""onetail"", 0, 1, 0,
     ""Cohens_w"", ""Cohen's w"", ""onetail"", 0, Inf, 0,
     ""Fei"", ""Fei"", ""onetail"", 0, 1, 0,
-    ""Cohens_g"", ""Cohen's g"", ""onetail"", -0.5, 0.5, 0,
+
+    ## xtab 2x2
     ""Cohens_h"", ""Cohen's h"", ""twotail"", -pi, pi, 0,
     ""Odds_ratio"", ""Odds ratio"", ""twotail"", 0, Inf, 1,
     ""log_Odds_ratio"", ""log(Odds ratio)"", ""twotail"", -Inf, Inf, 0,
     ""Risk_ratio"", ""Risk ratio"", ""twotail"", 0, Inf, 1,
     ""log_Risk_ratio"", ""log(Risk ratio)"", ""twotail"", -Inf, Inf, 0,
 
+    ## xtab dep
+    ""Cohens_g"", ""Cohen's g"", ""onetail"", -0.5, 0.5, 0,
+
     ## ANOVA
     ""Eta2"", ""Eta2"", ""onetail"", 0, 1, 0,
     ""Eta2_partial"", ""Eta2 (partial)"", ""onetail"", 0, 1, 0,
@@ -81,15 +85,7 @@ es_info <- matrix(
     ""r_rank_biserial"", ""r (rank biserial)"", ""twotail"", -1, 1, 0,
     ""Kendalls_W"", ""Kendall's W"", ""onetail"", 0, 1, 0,
     ""rank_epsilon_squared"", ""Epsilon2 (rank)"", ""onetail"", 0, 1, 0,
-
-    ## Std Coefficient
-    ""Std_Coefficient"", ""Coefficient (std.)"", ""twotail"", -Inf, Inf, 0,
-    ""Std_Odds_ratio"", ""Odds Ratio (std.)"", ""twotail"", 0, Inf, 1,
-    ""Std_Risk_ratio"", ""Risk Ratio (std.)"", ""twotail"", 0, Inf, 1,
-    ""Std_IRR"", ""IRR (std.)"", ""twotail"", 0, Inf, 1,
-    ""Std_Median"", ""Median (std.)"", ""twotail"", -Inf, Inf, 0,
-    ""Std_Mean"", ""Mean (std.)"", ""twotail"", -Inf, Inf, 0,
-    ""Std_MAP"", ""MAP (std.)"", ""twotail"", -Inf, Inf, 0,
+    ""rank_eta_squared"", ""Eta2 (rank)"", ""onetail"", 0, 1, 0,
 
     ## CLES
     ""p_superiority"", ""Pr(superiority)"", ""twotail"", 0, 1, 0.5,
@@ -100,7 +96,16 @@ es_info <- matrix(
 
     ## Other
     ""r"", ""r"", ""twotail"", -1, 1, 0,
-    ""d"", ""d"", ""twotail"", -Inf, Inf, 0
+    ""d"", ""d"", ""twotail"", -Inf, Inf, 0,
+
+    ## Std Coefficient
+    ""Std_Coefficient"", ""Coefficient (std.)"", ""twotail"", -Inf, Inf, 0,
+    ""Std_Odds_ratio"", ""Odds Ratio (std.)"", ""twotail"", 0, Inf, 1,
+    ""Std_Risk_ratio"", ""Risk Ratio (std.)"", ""twotail"", 0, Inf, 1,
+    ""Std_IRR"", ""IRR (std.)"", ""twotail"", 0, Inf, 1,
+    ""Std_Median"", ""Median (std.)"", ""twotail"", -Inf, Inf, 0,
+    ""Std_Mean"", ""Mean (std.)"", ""twotail"", -Inf, Inf, 0,
+    ""Std_MAP"", ""MAP (std.)"", ""twotail"", -Inf, Inf, 0
   ),
   ncol = 6, byrow = TRUE,
   dimnames = list(NULL, c(""name"", ""label"", ""direction"", ""lb"", ""ub"", ""null""))

---FILE: R/rank_ANOVA.R---
@@ -1,20 +1,19 @@
 #' Effect Size for Rank Based ANOVA
 #'
-#' Compute rank epsilon squared (\eqn{\varepsilon^2}{\epsilon^2}) (to accompany
-#' [stats::kruskal.test()]), and Kendall's *W* (to accompany
-#' [stats::friedman.test()]) effect sizes for non-parametric (rank sum) one-way
-#' ANOVAs.
+#' Compute rank epsilon squared (\eqn{E^2_R}) or rank eta squared
+#' (\eqn{\eta^2_H}) (to accompany [stats::kruskal.test()]), and Kendall's *W*
+#' (to accompany [stats::friedman.test()]) effect sizes for non-parametric (rank
+#' sum) one-way ANOVAs.
 #'
-#' @inheritParams phi
 #' @inheritParams rank_biserial
 #' @param x Can be one of:
 #'   - A numeric vector, or a character name of one in `data`.
-#'   - A list of vectors (for `rank_epsilon_squared()`).
+#'   - A list of vectors (for `rank_eta/epsilon_squared()`).
 #'   - A matrix of `blocks x groups` (for `kendalls_w()`) (or `groups x blocks`
 #'   if `blocks_on_rows = FALSE`). See details for the `blocks` and `groups`
 #'   terminology used here.
 #'   - A formula in the form of:
-#'       - `DV ~ groups` for `rank_epsilon_squared()`.
+#'       - `DV ~ groups` for `rank_eta/epsilon_squared()`.
 #'       - `DV ~ groups | blocks` for `kendalls_w()` (See details for the
 #'       `blocks` and `groups` terminology used here).
 #' @param groups,blocks A factor vector giving the group / block for the
@@ -26,10 +25,10 @@
 #'
 #'
 #' @details
-#' The rank epsilon squared is appropriate for non-parametric tests of
-#' differences between 2 or more samples (a rank based ANOVA). See
-#' [stats::kruskal.test]. Values range from 0 to 1, with larger values
-#' indicating larger differences between groups.
+#' The rank epsilon squared and rank eta squared are appropriate for
+#' non-parametric tests of differences between 2 or more samples (a rank based
+#' ANOVA). See [stats::kruskal.test]. Values range from 0 to 1, with larger
+#' values indicating larger differences between groups.
 #' \cr\cr
 #' Kendall's *W* is appropriate for non-parametric tests of differences between
 #' 2 or more dependent samples (a rank based rmANOVA), where each `group` (e.g.,
@@ -40,24 +39,25 @@
 #' / higher agreement between raters.
 #'
 #' # Confidence (Compatibility) Intervals (CIs)
-#' Confidence intervals for rank Epsilon squared, and Kendall's *W* are
+#' Confidence intervals for \eqn{E^2_R}, \eqn{\eta^2_H}, and Kendall's *W* are
 #' estimated using the bootstrap method (using the `{boot}` package).
 #'
 #' @inheritSection effectsize_CIs CIs and Significance Tests
 #' @inheritSection effectsize_CIs Bootstrapped CIs
 #' @inheritSection rank_biserial Ties
 #'
 #'
-#' @return A data frame with the effect size `(`rank_epsilon_squared` or
-#'   `Kendalls_W`) and its CI (`CI_low` and `CI_high`).
+#' @return A data frame with the effect size and its CI.
 #'
 #' @family effect size indices
 #' @seealso [rank_biserial()] for more rank based effect sizes
 #'
 #' @examples
 #' \donttest{
-#' # Rank Epsilon Squared
-#' # ====================
+#' # Rank Eta/Epsilon Squared
+#' # ========================
+#'
+#' rank_eta_squared(mpg ~ cyl, data = mtcars)
 #'
 #' rank_epsilon_squared(mpg ~ cyl, data = mtcars)
 #'
@@ -76,6 +76,12 @@
 #' interpret(W, rules = ""landis1977"")
 #' }
 #'
+#' @references
+#' - Kendall, M.G. (1948) Rank correlation methods. London: Griffin.
+#'
+#' - Tomczak, M., & Tomczak, E. (2014). The need to report effect size estimates
+#' revisited. An overview of some recommended measures of effect size. Trends in
+#' sport sciences, 1(21), 19-25.
 #'
 #' @export
 #' @importFrom stats na.omit
@@ -93,7 +99,7 @@ rank_epsilon_squared <- function(x,
     if (!grepl(""Kruskal-Wallis"", x$method)) {
       stop(""'x' is not a Kruskal-Wallis-test!"", call. = FALSE)
     }
-    return(effectsize(x, ci = ci, iterations = iterations, alternative = alternative))
+    return(effectsize(x, type = ""epsilon"", ci = ci, iterations = iterations, alternative = alternative))
   }
 
   ## pep data
@@ -104,16 +110,70 @@ rank_epsilon_squared <- function(x,
   out <- data.frame(rank_epsilon_squared = .repsilon(data))
 
   ## CI
-  ci_method <- NULL
   if (is.numeric(ci)) {
     if (insight::check_if_installed(""boot"", ""for estimating CIs"", stop = FALSE)) {
-      out <- cbind(out, .repsilon_ci(data, ci, alternative, iterations))
+      out <- cbind(out, .boot_two_group_es(data, .repsilon, iterations,
+                                           ci, alternative, c(0, 1)))
+      ci_method <- list(method = ""percentile bootstrap"", iterations = iterations)
+    } else {
+      ci <- NULL
+    }
+  }
+
+  if (!is.numeric(ci)) {
+    alternative <- NULL
+    ci_method <- NULL
+  }
+
+  class(out) <- c(""effectsize_table"", ""see_effectsize_table"", class(out))
+  attr(out, ""ci"") <- ci
+  attr(out, ""ci_method"") <- ci_method
+  attr(out, ""approximate"") <- FALSE
+  attr(out, ""alternative"") <- alternative
+  return(out)
+}
+
+#' @export
+#' @rdname rank_epsilon_squared
+#' @importFrom stats na.omit
+#' @importFrom insight check_if_installed
+rank_eta_squared <- function(x,
+                             groups,
+                             data = NULL,
+                             ci = 0.95,
+                             alternative = ""greater"",
+                             iterations = 200,
+                             ...) {
+  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
+
+  if (inherits(x, ""htest"")) {
+    if (!grepl(""Kruskal-Wallis"", x$method)) {
+      stop(""'x' is not a Kruskal-Wallis-test!"", call. = FALSE)
+    }
+    return(effectsize(x, type = ""eta"", ci = ci, iterations = iterations, alternative = alternative))
+  }
+
+  ## pep data
+  data <- .get_data_multi_group(x, groups, data, ...)
+  data <- stats::na.omit(data)
+
+  out <- data.frame(rank_eta_squared = .reta(data))
+
+  ## CI
+  if (is.numeric(ci)) {
+    if (insight::check_if_installed(""boot"", ""for estimating CIs"", stop = FALSE)) {
+      out <- cbind(out, .boot_two_group_es(data, .reta, iterations,
+                                           ci, alternative, c(0, 1)))
       ci_method <- list(method = ""percentile bootstrap"", iterations = iterations)
     } else {
       ci <- NULL
     }
   }
-  if (is.null(ci)) alternative <- NULL
+
+  if (!is.numeric(ci)) {
+    alternative <- NULL
+    ci_method <- NULL
+  }
 
   class(out) <- c(""effectsize_table"", ""see_effectsize_table"", class(out))
   attr(out, ""ci"") <- ci
@@ -123,6 +183,11 @@ rank_epsilon_squared <- function(x,
   return(out)
 }
 
+
+
+
+
+
 #' @rdname rank_epsilon_squared
 #' @export
 #' @importFrom stats na.omit
@@ -156,7 +221,6 @@ kendalls_w <- function(x,
   out <- data.frame(Kendalls_W = W)
 
   ## CI
-  ci_method <- NULL
   if (is.numeric(ci)) {
     if (insight::check_if_installed(""boot"", ""for estimating CIs"", stop = FALSE)) {
       out <- cbind(out, .kendalls_w_ci(data, ci, alternative, iterations))
@@ -165,7 +229,11 @@ kendalls_w <- function(x,
       ci <- NULL
     }
   }
-  if (is.null(ci)) alternative <- NULL
+
+  if (!is.numeric(ci)) {
+    alternative <- NULL
+    ci_method <- NULL
+  }
 
   class(out) <- c(""effectsize_table"", ""see_effectsize_table"", class(out))
   attr(out, ""ci"") <- ci
@@ -210,14 +278,26 @@ kendalls_w <- function(x,
 #' @keywords internal
 #' @importFrom stats kruskal.test
 .repsilon <- function(data) {
-  model <- stats::kruskal.test(data$x, data$groups)
+  model <- suppressWarnings(stats::kruskal.test(data$x, data$groups))
 
   H <- unname(model$statistic)
   n <- nrow(data)
 
   E <- H / ((n^2 - 1) / (n + 1))
 }
 
+#' @keywords internal
+#' @importFrom stats kruskal.test
+.reta <- function(data) {
+  model <- suppressWarnings(stats::kruskal.test(data$x, data$groups))
+
+  k <- length(levels(data$groups))
+  n <- nrow(data)
+  E <- model$statistic
+
+  (E - k + 1)/(n - k)
+}
+
 
 #' @keywords internal
 .kendalls_w <- function(data, verbose) {
@@ -243,13 +323,10 @@ kendalls_w <- function(x,
       )
     }
 
-    Tj <- 0
-    for (i in seq_len(m)) {
-      rater <- table(rankings[i, ])
-      ties <- rater[rater > 1]
-      l <- as.numeric(ties)
-      Tj <- Tj + sum(l^3 - l)
-    }
+    Tj <- sum(apply(rankings, 1, function(.r) {
+      TTi <- table(.r)
+      sum(TTi ^ 3 - TTi)
+    }))
 
     W <- (12 * sum(R^2) - 3 * (m^2) * n * ((n + 1)^2)) /
       (m^2 * (n^3 - n) - m * Tj)
@@ -263,26 +340,24 @@ kendalls_w <- function(x,
 
 ## CI ----
 
-
-
 #' @importFrom utils tail
 #' @keywords internal
-.repsilon_ci <- function(data, ci, alternative, iterations) {
+.boot_two_group_es <- function(data, foo_es, iterations,
+                               ci, alternative, lim) {
   stopifnot(length(ci) == 1, ci < 1, ci > 0)
   ci.level <- if (alternative == ""two.sided"") ci else 2 * ci - 1
 
-
-  boot_r_epsilon <- function(.data, .i) {
-    split(.data$x, .data$groups) <- lapply(split(.data$x, .data$groups),
-                                           sample,
-                                           replace = TRUE
-    )
-    .repsilon(.data)
+  boot_fun <- function(.data, .i) {
+    split(.data$x, .data$groups) <-
+      lapply(split(.data$x, .data$groups),
+             sample,
+             replace = TRUE)
+    foo_es(.data)
   }
 
   R <- boot::boot(
     data = data,
-    statistic = boot_r_epsilon,
+    statistic = boot_fun,
     R = iterations
   )
 
@@ -291,8 +366,8 @@ kendalls_w <- function(x,
 
   data.frame(
     CI = ci,
-    CI_low = if (alternative == ""less"") 0 else bCI[1],
-    CI_high = if (alternative == ""greater"") 1 else bCI[2]
+    CI_low = if (alternative == ""less"") lim[1] else bCI[1],
+    CI_high = if (alternative == ""greater"") lim[2] else bCI[2]
   )
 }
 

---FILE: R/rank_diff.R---
@@ -1,8 +1,10 @@
-#' Standardized Rank Based Differences
+#' Dominance Effect Sizes for Rank Based Differences
 #'
 #' Compute the rank-biserial correlation (\eqn{r_{rb}}{r_rb}) and Cliff's *delta*
-#' (\eqn{\delta}) effect sizes for non-parametric (rank sum) differences. Pair
-#' with any reported [`stats::wilcox.test()`].
+#' (\eqn{\delta}) effect sizes for non-parametric
+#' (rank sum) differences. These effect sizes of dominance are closely related
+#' to the [Common Language Effect Sizes][cohens_u3]. Pair with any reported
+#' [`stats::wilcox.test()`].
 #'
 #' @inheritParams cohens_d
 #' @param mu a number indicating the value around which (a-)symmetry (for
@@ -19,10 +21,12 @@
 #' **Glass'** rank-biserial correlation). See [stats::wilcox.test]. In both
 #' cases, the correlation represents the difference between the proportion of
 #' favorable and unfavorable pairs / signed ranks (Kerby, 2014). Values range
-#' from `-1` (*all* values of the second sample are larger than *all* the values
-#' of the first sample) to `+1` (*all* values of the second sample are smaller
-#' than *all* the values of the first sample). Cliff's *delta* is an alias to
-#' the rank-biserial correlation in the two sample case.
+#' from `-1` complete dominance of the second sample (*all* values of the second
+#' sample are larger than *all* the values of the first sample) to `+1` complete
+#' dominance of the fist sample (*all* values of the second sample are smaller
+#' than *all* the values of the first sample).
+#' \cr\cr
+#' Cliff's *delta* is an alias to the rank-biserial correlation in the two sample case.
 #'
 #' # Ties
 #' When tied values occur, they are each given the average of the ranks that
@@ -87,8 +91,6 @@
 #' Implications for short-cut item analysis. Journal of Educational Measurement,
 #' 2(1), 91-95.
 #'
-#' - Kendall, M.G. (1948) Rank correlation methods. London: Griffin.
-#'
 #' - Kerby, D. S. (2014). The simple difference formula: An approach to teaching
 #' nonparametric correlation. Comprehensive Psychology, 3, 11-IT.
 #'
@@ -101,6 +103,7 @@
 #' - Tomczak, M., & Tomczak, E. (2014). The need to report effect size estimates
 #' revisited. An overview of some recommended measures of effect size.
 #'
+#'
 #' @export
 #' @importFrom stats na.omit complete.cases
 rank_biserial <- function(x,
@@ -231,18 +234,19 @@ cliffs_delta <- function(x,
                          alternative = ""two.sided"",
                          verbose = TRUE,
                          ...) {
-  rank_biserial(
-    x, y,
-    data = data,
-    mu = mu,
-    paired = FALSE,
-    ci = ci,
-    alternative = alternative,
-    verbose = verbose,
-    ...
-  )
-}
+  cl <- match.call()
+  data <- .get_data_2_samples(x, y, data, verbose, ...)
+  x <- data$x
+  y <- data$y
+  if (is.null(y) || isTRUE(eval.parent(cl$paired))) {
+    stop(""This effect size is only applicable for two independent samples."", call. = FALSE)
+  }
 
+  cl[[1]] <- quote(rank_biserial)
+  cl$x <- x
+  cl$y <- y
+  eval.parent(cl)
+}
 
 
 # Utils -------------------------------------------------------------------

---FILE: R/zzz.R---
@@ -1,11 +1,9 @@
-#
 # .onLoad <- function(libname, pkgname) {
 #   op <- options()
 #   op.es <- list(
-#     es.ci.mag = 0.95,
-#     es.ci.diff = 0.95,
-#     es.alt.mag = ""greater"",
-#     es.alt.diff = ""two.sided""
+#     es.digits = 2,
+#     es.ci = c(0.95, 0.95),
+#     es.alt = c(""two.sided"", ""greater"")
 #   )
 #
 #   toset <- !names(op.es) %in% names(op)
@@ -16,4 +14,4 @@
 #
 # .onAttach <- function(libname, pkgname) {
 #   # packageStartupMessage()
-# }
+# }
\ No newline at end of file

---FILE: README.Rmd---
@@ -83,6 +83,14 @@ This package is focused on indices of effect size. Check out the package website
 library(effectsize)
 ```
 
+> **Tip:**
+>
+> **Instead of `library(effectsize)`, use `library(easystats)`.**
+> **This will make all features of the  easystats-ecosystem available.**
+>
+> **To stay updated, use `easystats::install_latest()`.**
+
+
 ## Effect Size Computation
 
 ### Standardized Differences (Cohen's *d*, Hedges' *g*, Glass' *delta*)

---FILE: README.md---
@@ -30,7 +30,7 @@ CRAN:
 install.packages(""effectsize"")
 ```
 
-Or you can install the latest development version `0.7.0.9999` from
+Or you can install the latest development version `0.7.0.99991` from
 [*R-universe*](https://easystats.r-universe.dev):
 
 ``` r
@@ -54,18 +54,18 @@ Click on the buttons above to access the package
 [**easystats blog**](https://easystats.github.io/blog/posts/), and
 check-out these vignettes:
 
-- **Effect Sizes**
-  - [**For Simple Hypothesis
-    Tests**](https://easystats.github.io/effectsize/articles/simple_htests.html)  
-  - [**ANOVA Effect
-    Sizes**](https://easystats.github.io/effectsize/articles/anovaES.html)
-- **Effect Sizes Conversion**
-  - [**Between Effect
-    Sizes**](https://easystats.github.io/effectsize/articles/convert.html)
-  - [**Effect Size from Test
-    Statistics**](https://easystats.github.io/effectsize/articles/from_test_statistics.html)
-- [**Automated Interpretation of Indices of Effect
-  Size**](https://easystats.github.io/effectsize/articles/interpret.html)
+-   **Effect Sizes**
+    -   [**For Simple Hypothesis
+        Tests**](https://easystats.github.io/effectsize/articles/simple_htests.html)  
+    -   [**ANOVA Effect
+        Sizes**](https://easystats.github.io/effectsize/articles/anovaES.html)
+-   **Effect Sizes Conversion**
+    -   [**Between Effect
+        Sizes**](https://easystats.github.io/effectsize/articles/convert.html)
+    -   [**Effect Size from Test
+        Statistics**](https://easystats.github.io/effectsize/articles/from_test_statistics.html)
+-   [**Automated Interpretation of Indices of Effect
+    Size**](https://easystats.github.io/effectsize/articles/interpret.html)
 
 # Features
 
@@ -77,6 +77,13 @@ website for [**a full list of features and functions** provided by
 library(effectsize)
 ```
 
+> **Tip:**
+>
+> **Instead of `library(effectsize)`, use `library(easystats)`.** **This
+> will make all features of the easystats-ecosystem available.**
+>
+> **To stay updated, use `easystats::install_latest()`.**
+
 ## Effect Size Computation
 
 ### Standardized Differences (Cohenâs *d*, Hedgesâ *g*, Glassâ *delta*)
@@ -216,9 +223,9 @@ interpret_cohens_d(d = 0.45, rules = ""gignac2016"")
 
 In order to cite this package, please use the following citation:
 
-- Ben-Shachar M, LÃ¼decke D, Makowski D (2020). effectsize: Estimation of
-  Effect Size Indices and Standardized Parameters. *Journal of Open
-  Source Software*, *5*(56), 2815. doi: 10.21105/joss.02815
+-   Ben-Shachar M, LÃ¼decke D, Makowski D (2020). effectsize: Estimation
+    of Effect Size Indices and Standardized Parameters. *Journal of Open
+    Source Software*, *5*(56), 2815. doi: 10.21105/joss.02815
 
 Corresponding BibTeX entry:
 

---FILE: man/diff_to_cles.Rd---
@@ -6,6 +6,7 @@
 \alias{d_to_cles}
 \alias{rb_to_cles}
 \alias{rb_to_p_superiority}
+\alias{rb_to_vda}
 \alias{d_to_u2}
 \alias{d_to_u1}
 \alias{d_to_u3}
@@ -16,6 +17,8 @@ d_to_p_superiority(d)
 
 rb_to_p_superiority(rb)
 
+rb_to_vda(rb)
+
 d_to_u2(d)
 
 d_to_u1(d)
@@ -52,8 +55,11 @@ And the following for the rank-biserial correlation:
 \deqn{Pr(superiority) = (r_{rb} + 1)/2}{Pr(superiority) = (rb + 1)/2}
 }
 \note{
-These calculations assume that the populations have equal variance and are
-normally distributed.
+For \emph{d}, these calculations assume that the populations have equal variance
+and are normally distributed.
+
+Vargha and Delaney's \emph{A} is an alias for the non-parametric \emph{probability of
+superiority}.
 }
 \references{
 \itemize{

---FILE: man/effectsize.Rd---
@@ -50,14 +50,14 @@ input model. See details.
 \item A \strong{Chi-squared tests of goodness-of-fit}, depending on \code{type}: \code{""fei""} (default) \code{""cohens_w""}, \code{""pearsons_c""}
 \item A \strong{One-way ANOVA test}, depending on \code{type}: \code{""eta""} (default), \code{""omega""} or \code{""epsilon""} -squared, \code{""f""}, or \code{""f2""}.
 \item A \strong{McNemar test} returns \emph{Cohen's g}.
-\item A \strong{Wilcoxon test} depending on \code{type}: returns ""\code{rank_biserial}"" correlation (default) or one of \code{""p_superiority""}, \code{""u2""}, \code{""u3""}, \code{""overlap""}.
-\item A \strong{Kruskal-Wallis test} returns \emph{rank Epsilon squared}.
+\item A \strong{Wilcoxon test} depending on \code{type}: returns ""\code{rank_biserial}"" correlation (default) or one of \code{""p_superiority""}, \code{""vda""}, \code{""u2""}, \code{""u3""}, \code{""overlap""}.
+\item A \strong{Kruskal-Wallis test} depending on \code{type}: \code{""epsilon""} (default) or \code{""eta""}.
 \item A \strong{Friedman test} returns \emph{Kendall's W}.
 (Where applicable, \code{ci} and \code{alternative} are taken from the \code{htest} if not otherwise provided.)
 }
 \item For an object of class \code{BFBayesFactor}, using \code{\link[bayestestR:describe_posterior]{bayestestR::describe_posterior()}},
 \itemize{
-\item A \strong{t-test} depending on \code{type}: ""cohens_d""\verb{(default) or one of}""p_superiority""\verb{, }""u1""\verb{, }""u2""\verb{, }""u3""\verb{, }""overlap""`.
+\item A \strong{t-test} depending on \code{type}: \code{""cohens_d""} (default) or one of \code{""p_superiority""}, \code{""u1""}, \code{""u2""}, \code{""u3""}, \code{""overlap""}.
 \item A \strong{correlation test} returns \emph{r}.
 \item A \strong{contingency table test}, depending on \code{type}: \code{""cramers_v""} (default), \code{""phi""}, \code{""cohens_w""}, \code{""pearsons_c""}, \code{""cohens_h""}, \code{""oddsratio""}, or \code{""riskratio""}.
 \item A \strong{proportion test} returns \emph{p}.

---FILE: man/es_info.Rd---
@@ -5,7 +5,7 @@
 \alias{es_info}
 \title{List of effect size names}
 \format{
-An object of class \code{data.frame} with 45 rows and 6 columns.
+An object of class \code{data.frame} with 46 rows and 6 columns.
 }
 \usage{
 es_info

---FILE: man/p_superiority.Rd---
@@ -7,6 +7,7 @@
 \alias{cohens_u2}
 \alias{cohens_u3}
 \alias{p_overlap}
+\alias{vd_a}
 \title{Cohen's \emph{U}s and Other Common Language Effect Sizes (CLES)}
 \usage{
 p_superiority(
@@ -72,6 +73,17 @@ p_overlap(
   iterations = 200,
   ...
 )
+
+vd_a(
+  x,
+  y = NULL,
+  data = NULL,
+  mu = 0,
+  ci = 0.95,
+  alternative = ""two.sided"",
+  verbose = TRUE,
+  ...
+)
 }
 \arguments{
 \item{x, y}{A numeric vector, or a character name of one in \code{data}.
@@ -107,11 +119,11 @@ A data frame containing the common language effect sizes (and
 optionally their CIs).
 }
 \description{
-Cohen's \eqn{U_1}, \eqn{U_2}, and \eqn{U_3}, probability of superiority, and
-proportion of overlap are CLESs. These are effect sizes that represent
-differences between two (independent) distributions in probabilistic terms
-(See details). Pair with any reported \code{\link[stats:t.test]{stats::t.test()}} or
-\code{\link[stats:wilcox.test]{stats::wilcox.test()}}.
+Cohen's \eqn{U_1}, \eqn{U_2}, and \eqn{U_3}, probability of superiority,
+Vargha and Delaney's \emph{A}, and proportion of overlap are CLESs. These are
+effect sizes that represent differences between two (independent)
+distributions in probabilistic terms (See details). Pair with any reported
+\code{\link[stats:t.test]{stats::t.test()}} or \code{\link[stats:wilcox.test]{stats::wilcox.test()}}.
 }
 \details{
 These measures of effect size present group differences in probabilistic
@@ -134,6 +146,9 @@ The parametric version of these effects assumes normality of both populations
 and homoscedasticity. If those are not met, the non parametric versions
 should be used.
 
+Vargha and Delaney's \emph{A} is an alias for the non-parametric \emph{probability of
+superiority}.
+
 Where \eqn{U_1}, \eqn{U_2}, and \emph{Overlap} are agnostic to the direction of
 the difference between the groups, \eqn{U_1} and probability of superiority
 are not.
@@ -209,6 +224,9 @@ coefficient: the normal equal variance case. Journal of the Royal Statistical
 Society, 48(3), 413-418.
 \item Ruscio, J. (2008). A probability-based measure of effect size: robustness
 to base rates and other factors. Psychological methods, 13(1), 19â30.
+\item Vargha, A., & Delaney, H. D. (2000). A critique and improvement of the CL
+common language effect size statistics of McGraw and Wong. Journal of
+Educational and Behavioral Statistics, 25(2), 101-132.
 }
 }
 \seealso{

---FILE: man/rank_biserial.Rd---
@@ -3,7 +3,7 @@
 \name{rank_biserial}
 \alias{rank_biserial}
 \alias{cliffs_delta}
-\title{Standardized Rank Based Differences}
+\title{Dominance Effect Sizes for Rank Based Differences}
 \usage{
 rank_biserial(
   x,
@@ -62,8 +62,10 @@ A data frame with the effect size \code{r_rank_biserial} and its CI
 }
 \description{
 Compute the rank-biserial correlation (\eqn{r_{rb}}{r_rb}) and Cliff's \emph{delta}
-(\eqn{\delta}) effect sizes for non-parametric (rank sum) differences. Pair
-with any reported \code{\link[stats:wilcox.test]{stats::wilcox.test()}}.
+(\eqn{\delta}) effect sizes for non-parametric
+(rank sum) differences. These effect sizes of dominance are closely related
+to the \link[=cohens_u3]{Common Language Effect Sizes}. Pair with any reported
+\code{\link[stats:wilcox.test]{stats::wilcox.test()}}.
 }
 \details{
 The rank-biserial correlation is appropriate for non-parametric tests of
@@ -74,10 +76,12 @@ case, that would normally be tested with Mann-Whitney's \emph{U} Test (giving
 \strong{Glass'} rank-biserial correlation). See \link[stats:wilcox.test]{stats::wilcox.test}. In both
 cases, the correlation represents the difference between the proportion of
 favorable and unfavorable pairs / signed ranks (Kerby, 2014). Values range
-from \code{-1} (\emph{all} values of the second sample are larger than \emph{all} the values
-of the first sample) to \code{+1} (\emph{all} values of the second sample are smaller
-than \emph{all} the values of the first sample). Cliff's \emph{delta} is an alias to
-the rank-biserial correlation in the two sample case.
+from \code{-1} complete dominance of the second sample (\emph{all} values of the second
+sample are larger than \emph{all} the values of the first sample) to \code{+1} complete
+dominance of the fist sample (\emph{all} values of the second sample are smaller
+than \emph{all} the values of the first sample).
+\cr\cr
+Cliff's \emph{delta} is an alias to the rank-biserial correlation in the two sample case.
 }
 \section{Ties}{
 When tied values occur, they are each given the average of the ranks that
@@ -157,7 +161,6 @@ interpret(rb, rules = ""funder2019"")
 \item Glass, G. V. (1965). A ranking variable analogue of biserial correlation:
 Implications for short-cut item analysis. Journal of Educational Measurement,
 2(1), 91-95.
-\item Kendall, M.G. (1948) Rank correlation methods. London: Griffin.
 \item Kerby, D. S. (2014). The simple difference formula: An approach to teaching
 nonparametric correlation. Comprehensive Psychology, 3, 11-IT.
 \item King, B. M., & Minium, E. W. (2008). Statistical reasoning in the

---FILE: man/rank_epsilon_squared.Rd---
@@ -2,6 +2,7 @@
 % Please edit documentation in R/rank_ANOVA.R
 \name{rank_epsilon_squared}
 \alias{rank_epsilon_squared}
+\alias{rank_eta_squared}
 \alias{kendalls_w}
 \title{Effect Size for Rank Based ANOVA}
 \usage{
@@ -15,6 +16,16 @@ rank_epsilon_squared(
   ...
 )
 
+rank_eta_squared(
+  x,
+  groups,
+  data = NULL,
+  ci = 0.95,
+  alternative = ""greater"",
+  iterations = 200,
+  ...
+)
+
 kendalls_w(
   x,
   groups,
@@ -32,13 +43,13 @@ kendalls_w(
 \item{x}{Can be one of:
 \itemize{
 \item A numeric vector, or a character name of one in \code{data}.
-\item A list of vectors (for \code{rank_epsilon_squared()}).
+\item A list of vectors (for \code{rank_eta/epsilon_squared()}).
 \item A matrix of \verb{blocks x groups} (for \code{kendalls_w()}) (or \verb{groups x blocks}
 if \code{blocks_on_rows = FALSE}). See details for the \code{blocks} and \code{groups}
 terminology used here.
 \item A formula in the form of:
 \itemize{
-\item \code{DV ~ groups} for \code{rank_epsilon_squared()}.
+\item \code{DV ~ groups} for \code{rank_eta/epsilon_squared()}.
 \item \code{DV ~ groups | blocks} for \code{kendalls_w()} (See details for the
 \code{blocks} and \code{groups} terminology used here).
 }
@@ -53,35 +64,34 @@ Ignored if \code{x} is not a vector.}
 \item{ci}{Confidence Interval (CI) level}
 
 \item{alternative}{a character string specifying the alternative hypothesis;
-Controls the type of CI returned: \code{""greater""} (one-sided CI; default),
-\code{""two.sided""} (two-sided CI) or \code{""less""} (one-sided CI). Partial matching
-is allowed (e.g., \code{""g""}, \code{""l""}, \code{""two""}...). See \emph{One-Sided CIs} in
-\link{effectsize_CIs}.}
+Controls the type of CI returned: \code{""two.sided""} (default, two-sided CI),
+\code{""greater""} or \code{""less""} (one-sided CI). Partial matching is allowed (e.g.,
+\code{""g""}, \code{""l""}, \code{""two""}...). See \emph{One-Sided CIs} in \link{effectsize_CIs}.}
 
 \item{iterations}{The number of bootstrap replicates for computing confidence
 intervals. Only applies when \code{ci} is not \code{NULL}.}
 
-\item{...}{For goodness-of-fit effect sizes, can pass \code{rescale.p} (see
-\code{\link[stats:chisq.test]{stats::chisq.test()}}). Else, ignored.}
+\item{...}{Arguments passed to or from other methods. When \code{x} is a formula,
+these can be \code{subset} and \code{na.action}.}
 
 \item{blocks_on_rows}{Are blocks on rows (\code{TRUE}) or columns (\code{FALSE}).}
 
 \item{verbose}{Toggle warnings and messages on or off.}
 }
 \value{
-A data frame with the effect size \code{(}rank_epsilon_squared\code{or}Kendalls_W\verb{) and its CI (}CI_low\code{and}CI_high`).
+A data frame with the effect size and its CI.
 }
 \description{
-Compute rank epsilon squared (\eqn{\varepsilon^2}{\epsilon^2}) (to accompany
-\code{\link[stats:kruskal.test]{stats::kruskal.test()}}), and Kendall's \emph{W} (to accompany
-\code{\link[stats:friedman.test]{stats::friedman.test()}}) effect sizes for non-parametric (rank sum) one-way
-ANOVAs.
+Compute rank epsilon squared (\eqn{E^2_R}) or rank eta squared
+(\eqn{\eta^2_H}) (to accompany \code{\link[stats:kruskal.test]{stats::kruskal.test()}}), and Kendall's \emph{W}
+(to accompany \code{\link[stats:friedman.test]{stats::friedman.test()}}) effect sizes for non-parametric (rank
+sum) one-way ANOVAs.
 }
 \details{
-The rank epsilon squared is appropriate for non-parametric tests of
-differences between 2 or more samples (a rank based ANOVA). See
-\link[stats:kruskal.test]{stats::kruskal.test}. Values range from 0 to 1, with larger values
-indicating larger differences between groups.
+The rank epsilon squared and rank eta squared are appropriate for
+non-parametric tests of differences between 2 or more samples (a rank based
+ANOVA). See \link[stats:kruskal.test]{stats::kruskal.test}. Values range from 0 to 1, with larger
+values indicating larger differences between groups.
 \cr\cr
 Kendall's \emph{W} is appropriate for non-parametric tests of differences between
 2 or more dependent samples (a rank based rmANOVA), where each \code{group} (e.g.,
@@ -92,7 +102,7 @@ from 0 to 1, with larger values indicating larger differences between groups
 / higher agreement between raters.
 }
 \section{Confidence (Compatibility) Intervals (CIs)}{
-Confidence intervals for rank Epsilon squared, and Kendall's \emph{W} are
+Confidence intervals for \eqn{E^2_R}, \eqn{\eta^2_H}, and Kendall's \emph{W} are
 estimated using the bootstrap method (using the \code{{boot}} package).
 }
 
@@ -139,8 +149,10 @@ reduced magnitude. A correction has been applied for Kendall's \emph{W}.
 
 \examples{
 \donttest{
-# Rank Epsilon Squared
-# ====================
+# Rank Eta/Epsilon Squared
+# ========================
+
+rank_eta_squared(mpg ~ cyl, data = mtcars)
 
 rank_epsilon_squared(mpg ~ cyl, data = mtcars)
 
@@ -159,7 +171,14 @@ interpret_kendalls_w(0.11)
 interpret(W, rules = ""landis1977"")
 }
 
-
+}
+\references{
+\itemize{
+\item Kendall, M.G. (1948) Rank correlation methods. London: Griffin.
+\item Tomczak, M., & Tomczak, E. (2014). The need to report effect size estimates
+revisited. An overview of some recommended measures of effect size. Trends in
+sport sciences, 1(21), 19-25.
+}
 }
 \seealso{
 \code{\link[=rank_biserial]{rank_biserial()}} for more rank based effect sizes

---FILE: vignettes/simple_htests.Rmd---
@@ -396,7 +396,7 @@ rank_biserial(x, y, paired = TRUE)
 
 ### Rank One way ANOVA
 
-The Rank-Epsilon-Squared ($\varepsilon^2$) is a measure of association
+The Rank-Epsilon-Squared ($E^2_R$) and Rank-Eta-Squared ($\eta^2_H$) are measures of association
 for the rank based one-way ANOVA. Values range between 0 (no relative
 superiority between any of the groups) to 1 (complete separation - with no
 overlap in ranks between the groups).
@@ -411,6 +411,8 @@ group_data <- list(
 kruskal.test(group_data)
 
 rank_epsilon_squared(group_data)
+
+rank_eta_squared(group_data)
 ```
 
 ### Rank One way Repeated-Measures ANOVA",True,True,Dependency / Package,7
easystats,effectsize,6fe0f8fe5644a8d4a0367e87ba1788e04fadc185,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-09-18T12:57:49Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-09-18T12:57:49Z,fix some docs,R/common_language.R;_pkgdown.yml;man/p_superiority.Rd;vignettes/simple_htests.Rmd,True,True,True,False,23,17,40,"---FILE: R/common_language.R---
@@ -42,7 +42,7 @@
 #' ([`rb_to_p_superiority()`]), while for all others, confidence intervals are
 #' bootstrapped (requires the `boot` package).
 #'
-#' @inheritSection effectsize_CIs Confidence (Compatibility) Intervals (CIs)
+#' @inheritSection effectsize_CIs CIs and Significance Tests
 #'
 #' @return A data frame containing the common language effect sizes (and
 #'   optionally their CIs).

---FILE: _pkgdown.yml---
@@ -57,11 +57,11 @@ reference:
   desc: >
     Approximate effect sizes by converting between other related effect sizes
   contents:
-  - d_to_cles
   - d_to_r
+  - d_to_u3
   - eta2_to_f2
-  - odds_to_probs
   - oddsratio_to_riskratio
+  - odds_to_probs
 
 
 

---FILE: man/p_superiority.Rd---
@@ -151,21 +151,26 @@ For parametric CLES, the CIs are transformed CIs for Cohen's \emph{d} (see
 bootstrapped (requires the \code{boot} package).
 }
 
-\section{Confidence (Compatibility) Intervals (CIs)}{
-
-Unless stated otherwise, confidence (compatibility) intervals (CIs) are
-estimated using the noncentrality parameter method (also called the ""pivot
-method""). This method finds the noncentrality parameter (""\emph{ncp}"") of a
-noncentral \emph{t}, \emph{F}, or \eqn{\chi^2} distribution that places the observed
-\emph{t}, \emph{F}, or \eqn{\chi^2} test statistic at the desired probability point of
-the distribution. For example, if the observed \emph{t} statistic is 2.0, with 50
-degrees of freedom, for which cumulative noncentral \emph{t} distribution is \emph{t} =
-2.0 the .025 quantile (answer: the noncentral \emph{t} distribution with \emph{ncp} =
-.04)? After estimating these confidence bounds on the \emph{ncp}, they are
-converted into the effect size metric to obtain a confidence interval for the
-effect size (Steiger, 2004).
+\section{CIs and Significance Tests}{
+
+""Confidence intervals on measures of effect size convey all the information
+in a hypothesis test, and more."" (Steiger, 2004). Confidence (compatibility)
+intervals and p values are complementary summaries of parameter uncertainty
+given the observed data. A dichotomous hypothesis test could be performed
+with either a CI or a p value. The 100 (1 - \eqn{\alpha})\% confidence
+interval contains all of the parameter values for which \emph{p} > \eqn{\alpha}
+for the current data and model. For example, a 95\% confidence interval
+contains all of the values for which p > .05.
 \cr\cr
-For additional details on estimation and troubleshooting, see \link{effectsize_CIs}.
+Note that a confidence interval including 0 \emph{does not} indicate that the null
+(no effect) is true. Rather, it suggests that the observed data together with
+the model and its assumptions combined do not provided clear evidence against
+a parameter value of 0 (same as with any other value in the interval), with
+the level of this evidence defined by the chosen \eqn{\alpha} level (Rafi &
+Greenland, 2020; Schweder & Hjort, 2016; Xie & Singh, 2013). To infer no
+effect, additional judgments about what parameter values are ""close enough""
+to 0 to be negligible are needed (""equivalence testing""; Bauer & Kiesser,
+1996).
 }
 
 \examples{

---FILE: vignettes/simple_htests.Rmd---
@@ -144,6 +144,7 @@ ggplot2::ggplot() +
   ggplot2::stat_function(ggplot2::aes(fill = ""1""), size = 1, geom = ""area"", 
                          color = ""black"", outline.type = ""full"", 
                 fun = dnorm, args = list(mean = mu[2], sd = sigma), xlim = c(xlim[1], mu[1])) +
+  ggplot2::geom_vline(ggplot2::aes(xintercept = mu[1]), linetype = ""dashed"") + 
   ggplot2::annotate(""text"", x = mu[1]-2, y = -seg_u2$y, label = ""U3"") + 
   # U2
   ggplot2::geom_vline(ggplot2::aes(xintercept = mean(mu))) + ",True,True,Documentation / Formatting,7
easystats,effectsize,b7ef5592b0a37a0a3e9819c3d27e19c870ebb030,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2022-09-15T10:03:33Z,GitHub,noreply@github.com,2022-09-15T10:03:33Z,"bump version to R3.6 (#482)

* bump version to R3.6

https://github.com/easystats/easystats/issues/304

* need more than 3.6

@IndrajeetPatil Need here a version that is later than 3.6 :O

* Update NEWS.md

* Update DESCRIPTION",DESCRIPTION;NEWS.md;tests/testthat/test-eta_squared.R;tests/testthat/test-plot.R;tests/testthat/test-rankES.R,False,True,True,False,9,8,17,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size and Standardized Parameters
-Version: 0.7.0.9999
+Version: 0.7.0.99991
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",
@@ -54,7 +54,7 @@ License: GPL-3
 URL: https://easystats.github.io/effectsize/
 BugReports: https://github.com/easystats/effectsize/issues/
 Depends:
-    R (>= 3.5)
+    R (>= 3.6)
 Imports:
     bayestestR (>= 0.12.1),
     insight (>= 0.18.2),

---FILE: NEWS.md---
@@ -2,6 +2,7 @@
 
 ## Breaking Changes
 
+- `{effectsize}` now requires *`R >= 3.6`*
 - `normalized_chi()` has been renamed `fei()`.
 
 ## New features

---FILE: tests/testthat/test-eta_squared.R---
@@ -491,7 +491,7 @@ if (require(""testthat"") && require(""effectsize"")) {
   test_that(""afex | mixed()"", {
     skip_if_not_installed(""afex"")
     skip_if_not_installed(""lmerTest"")
-    skip_if(getRversion() <= ""3.6"")
+    skip_if_not_installed(""base"", minimum_version = ""3.6.1"")
 
     data(md_15.1, package = ""afex"")
     # random intercept plus random slope
@@ -609,7 +609,7 @@ if (require(""testthat"") && require(""effectsize"")) {
   test_that(""ets_squared | tidymodels"", {
     skip_on_cran()
     skip_if_not_installed(""parsnip"")
-    skip_if(getRversion() <= ""3.6"")
+    skip_if_not_installed(""base"", minimum_version = ""3.6.1"")
 
     set.seed(123)
     mod_lm <- parsnip::linear_reg(engine = ""lm"", mode = ""regression"")
@@ -647,7 +647,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_output(print(out), ""Type II"")
 
     skip_if_not_installed(""car"")
-    skip_if(getRversion() <= ""3.6"")
+    skip_if_not_installed(""base"", minimum_version = ""3.6.1"")
     b_lm <- car::Anova(lm(mpg ~ cyl + am, data = mtcars), type = 2)
     out_lm <- eta_squared(b_lm)
     expect_equal(out[1:2, ], out_lm, ignore_attr = TRUE)

---FILE: tests/testthat/test-plot.R---
@@ -1,6 +1,6 @@
 if (require(effectsize) && require(testthat)) {
   test_that(""plot methods"", {
-    skip_if_not_installed(""see"", ""0.6.8"")
+    skip_if_not_installed(""see"")
     skip_if_not_installed(""ggplot2"")
     expect_error(plot(d <- cohens_d(mpg ~ am, data = mtcars)), NA)
     expect_s3_class(plot(d), ""ggplot"")

---FILE: tests/testthat/test-rankES.R---
@@ -34,7 +34,7 @@ if (require(""testthat"") && require(""effectsize"")) {
 
   test_that(""rank_epsilon_squared"", {
     skip_if_not_installed(""boot"")
-    skip_if_not_installed(""base"", minimum_version = ""3.6.0"")
+    skip_if_not_installed(""base"", minimum_version = ""3.6.1"")
     x1 <- c(2.9, 3.0, 2.5, 2.6, 3.2) # normal subjects
     x2 <- c(3.8, 2.7, 4.0, 2.4) # with obstructive airway disease
     x3 <- c(2.8, 3.4, 3.7, 2.2, 2.0) # with asbestosis
@@ -57,7 +57,7 @@ if (require(""testthat"") && require(""effectsize"")) {
 
   test_that(""kendalls_w"", {
     skip_if_not_installed(""boot"")
-    skip_if_not_installed(""base"", minimum_version = ""3.6.0"")
+    skip_if_not_installed(""base"", minimum_version = ""3.6.1"")
     M1 <- cbind(
       ""Round Out"" = c(5.4, 5.85, 5.2),
       ""Narrow Angle"" = c(5.5, 5.7, 5.6),",True,False,Documentation / Formatting,7
easystats,effectsize,593ad08ad6b5ac4dc7166eb7aaa7821b262827b6,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-09-14T19:20:56Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-09-14T19:20:56Z,fix bug in mad_pooled,NAMESPACE;NEWS.md;R/pooled.R;tests/testthat/test-pooled.R,False,True,True,False,39,104,143,"---FILE: NAMESPACE---
@@ -208,7 +208,6 @@ importFrom(parameters,standardize_parameters)
 importFrom(parameters,standardize_posteriors)
 importFrom(stats,anova)
 importFrom(stats,aov)
-importFrom(stats,as.formula)
 importFrom(stats,ave)
 importFrom(stats,chisq.test)
 importFrom(stats,complete.cases)

---FILE: NEWS.md---
@@ -11,6 +11,7 @@
 ## Bug fixes
 
 - `cles()` now respects `mu` argument for all effect sizes.
+- `mad_pooled()` not returns correct value (previously was inflated by a factor of 1.4826).
 - Effect sizes for goodness-of-fit now work when passing a `p` that is a table.
 
 # effectsize 0.7.0.5

---FILE: R/pooled.R---
@@ -24,39 +24,39 @@
 #'
 #' @seealso [cohens_d()], [mahalanobis_d()]
 #'
+#' @importFrom stats ave sd
 #' @export
 sd_pooled <- function(x, y = NULL, data = NULL, verbose = TRUE, ...) {
-  # This actually works, you must see if you want to keep this code. If you do,
-  # following will work:
-  # sd_pooled(mpg, hp, data = mtcars)
-  # sd_pooled(x, y) # called from a different function, like cohens_d()
+  data <- .get_data_2_samples(x, y, data, verbose, ...)
+  x <- na.omit(data$x)
+  y <- na.omit(data$y)
 
-  # needs modification in in "".sd_pooled()"" as well...
-
-  # x1 <- try(expr = eval(x), silent = TRUE)
-  # y1 <- try(expr = eval(y), silent = TRUE)
-  #
-  # if (inherits(x1, ""try-error""))
-  #   x <- deparse(substitute(x), width.cutoff = 500)
-  # else
-  #   x <- x1
-  #
-  # if (inherits(y1, ""try-error""))
-  #   y <- deparse(substitute(y), width.cutoff = 500)
-  # else
-  #   y <- y1
-
-  .sd_pooled(x, y, data, robust = FALSE, verbose = verbose, ...)
+  V <- cov_pooled(data.frame(x = x),
+                  data.frame(x = y))
+  c(sqrt(V))
 }
 
 
 
 #' @rdname sd_pooled
+#' @importFrom stats ave mad median
 #' @export
 mad_pooled <- function(x, y = NULL, data = NULL, constant = 1.4826, verbose = TRUE, ...) {
-  .sd_pooled(x, y, data, robust = TRUE, verbose = verbose, constant = constant, ...)
+  data <- .get_data_2_samples(x, y, data, verbose, ...)
+  x <- na.omit(data$x)
+  y <- na.omit(data$y)
+
+  n1 <- length(x)
+  n2 <- length(y)
+
+  Y <- c(x, y)
+  G <- rep(1:2, times = c(n1, n2))
+  Yc <- Y - stats::ave(Y, factor(G), FUN = stats::median)
+
+  stats::mad(Yc, center = 0, constant = constant)
 }
 
+
 #' @rdname sd_pooled
 #' @importFrom stats cov
 #' @export
@@ -68,80 +68,12 @@ cov_pooled <- function(x, y = NULL, data = NULL, verbose = TRUE, ...) {
   n1 <- nrow(x)
   n2 <- nrow(y)
 
-  S1 <- stats::cov(x)
-  S2 <- stats::cov(y)
-  (S1 * (n1 - 1) + S2 * (n2 - 1)) / (n1 + n2 - 2)
-}
-
-# cor_pooled <- function(x, y = NULL, data = NULL, verbose = TRUE, ...) {
-#   stats::cov2cor(
-#     cov_pooled(x, y = y, data = data, verbose = verbose, ...)
-#   )
-# }
-
-
-# Utils -------------------------------------------------------------------
+  Y <- rbind(x, y)
+  G <- rep(1:2, times = c(n1, n2))
+  Yc <- lapply(Y, function(.y) .y - stats::ave(.y, factor(G), FUN = mean))
+  Yc <- as.data.frame(Yc)
 
-
-
-#' @importFrom stats mad sd as.formula ave
-.sd_pooled <- function(x, y = NULL, data = NULL, robust = FALSE, verbose = TRUE, constant = 1, ...) {
-  # Activate here for evaluation of arguments...
-
-  # eval_args <- .evaluate_arguments(x, y, data)
-  # out <- .get_data_2_samples(eval_args$x, eval_args$y, eval_args$data, verbose, ...)
-
-  out <- .get_data_2_samples(x, y, data, verbose, ...)
-  x <- na.omit(out$x)
-  y <- na.omit(out$y)
-
-  if (robust) {
-    f <- constant
-    center <- stats::median
-    div <- stats::mad
-  } else {
-    n1 <- length(x)
-    n2 <- length(y)
-
-    f <- sqrt(c(n1 + n2 - 1) / c(n1 + n2 - 2))
-    center <- mean
-    div <- stats::sd
-  }
-
-  div(c(
-    x - stats::ave(x, FUN = center),
-    y - stats::ave(y, FUN = center)
-  )) * f
+  stats::cov(Yc) * (n1 + n2 - 1) / (n1 + n2 - 2)
 }
 
-# .evaluate_arguments <- function(x, y, data) {
-#   eval_x <- .evaluate_argument(x)
-#   if (!is.null(eval_x$variable)) x <- eval_x$variable
-#   if (!is.null(eval_x$data) && is.null(data)) data <- get(eval_x$data)
-#
-#   eval_y <- .evaluate_argument(y)
-#   if (!is.null(eval_y$variable)) y <- eval_y$variable
-#   if (!is.null(eval_y$data) && is.null(data)) data <- get(eval_y$data)
-#
-#   list(x = x, y = y, data = data)
-# }
-
-
-# .evaluate_argument <- function(arg) {
-#   data_frame <- NULL
-#   if (!is.null(arg)) {
-#     if (is.numeric(arg) && length(arg) > 1) {
-#       # do nothiung
-#     } else if (arg == ""NULL"") {
-#       arg <- NULL
-#     } else if (grepl(""~"", arg, fixed = TRUE)) {
-#       arg <- stats::as.formula(arg)
-#     } else if (grepl(""\"""", arg, fixed = TRUE)) {
-#       arg <- gsub(""\"""", """", arg, fixed = TRUE)
-#     } else if (grepl(""$"", arg, fixed = TRUE)) {
-#       data_frame <- gsub(""(.*)\\$(.*)"", ""\\1"", arg)
-#       arg <- gsub(""(.*)\\$(.*)"", ""\\2"", arg)
-#     }
-#   }
-#   list(variable = arg, data = data_frame)
-# }
+# TODO Add com_pooled?
\ No newline at end of file

---FILE: tests/testthat/test-pooled.R---
@@ -1,9 +1,12 @@
-if (require(""testthat"") && require(""effectsize"")) {
-  test_that(""sd_pooled"", {
-    expect_equal(sd_pooled(1:4, 1:3 * 5), 3.316625, tolerance = 0.001)
-    expect_equal(mad_pooled(1:4, 1:3 * 5), 3.297154, tolerance = 0.001)
+test_that(""sd_pooled"", {
+  expect_equal(sd_pooled(1:4, 1:3 * 5), 3.316625, tolerance = 0.001)
+  expect_equal(mad_pooled(1:4, 1:3 * 5), 2.2239, tolerance = 0.001)
 
-    expect_equal(sd_pooled(c(1:3, 40), 1:3 * 5), 15.06652, tolerance = 0.001)
-    expect_equal(mad_pooled(c(1:3, 40), 1:3 * 5), 3.297154, tolerance = 0.001)
-  })
-}
+  expect_equal(sd_pooled(c(1:3, 40), 1:3 * 5), 15.06652, tolerance = 0.001)
+  expect_equal(mad_pooled(c(1:3, 40), 1:3 * 5), 2.2239, tolerance = 0.001)
+
+  x <- 1:5
+  y <- 1:5
+  expect_equal(mad_pooled(x, y), mad(c(x, y)))
+  expect_equal(sd_pooled(x, y), sd(c(x, y)) * sqrt(9/8))
+})",True,False,Documentation / Formatting,6
easystats,effectsize,cee870b58e27065105d6606be15eff17ba01af46,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2022-09-14T19:17:14Z,GitHub,noreply@github.com,2022-09-14T19:17:14Z,"split xtab into 3 files (#481)

* split xtab into 3 files

* split rank into 2 files

* typo

* fix check issues

* fix bug in CLES()

and make code more eff

* condition emmeans examples

* fix test",NAMESPACE;NEWS.md;R/cohens_g.R;R/common_language.R;R/convert_stat_to_anova.R;R/eta_squared.R;R/mahalanobis_D.R;R/pooled.R;R/rank_ANOVA.R;R/rank_diff.R;R/rank_effectsizes.R;R/utils.R;R/utils_validate_input_data.R;R/xtab.R;R/xtab_corr.R;R/xtab_diff.R;_pkgdown.yml;man/F_to_eta2.Rd;man/cles.Rd;man/cohens_d.Rd;man/cohens_g.Rd;man/effectsize.Rd;man/eta_squared.Rd;man/mahalanobis_D.Rd;man/oddsratio.Rd;man/phi.Rd;man/rank_biserial.Rd;man/rank_epsilon_squared.Rd;tests/testthat/test-standardized_differences.R,False,True,True,False,1852,1562,3414,"---FILE: NAMESPACE---
@@ -212,12 +212,14 @@ importFrom(stats,as.formula)
 importFrom(stats,ave)
 importFrom(stats,chisq.test)
 importFrom(stats,complete.cases)
+importFrom(stats,cov)
 importFrom(stats,kruskal.test)
 importFrom(stats,lm)
 importFrom(stats,mad)
 importFrom(stats,median)
 importFrom(stats,model.frame)
 importFrom(stats,na.omit)
+importFrom(stats,na.pass)
 importFrom(stats,optim)
 importFrom(stats,pchisq)
 importFrom(stats,pf)
@@ -230,6 +232,7 @@ importFrom(stats,qf)
 importFrom(stats,qlogis)
 importFrom(stats,qnorm)
 importFrom(stats,qt)
+importFrom(stats,reformulate)
 importFrom(stats,reshape)
 importFrom(stats,sd)
 importFrom(stats,setNames)

---FILE: NEWS.md---
@@ -10,6 +10,7 @@
 
 ## Bug fixes
 
+- `cles()` now respects `mu` argument for all effect sizes.
 - Effect sizes for goodness-of-fit now work when passing a `p` that is a table.
 
 # effectsize 0.7.0.5

---FILE: R/cohens_g.R---
@@ -0,0 +1,116 @@
+#' Effect Sizes for Paired Contingency Tables
+#'
+#' Cohen's *g* is an effect size of asymmetry (or marginal heterogeneity) for
+#' dependent (paired) contingency tables ranging between 0 (perfect symmetry)
+#' and 0.5 (perfect asymmetry) (see [stats::mcnemar.test()]). (Note this is not
+#' *not* a measure of (dis)agreement between the pairs, but of (a)symmetry.)
+#'
+#' @inheritParams oddsratio_to_d
+#' @inheritParams phi
+#' @param alternative a character string specifying the alternative hypothesis;
+#'   Controls the type of CI returned: `""two.sided""` (two-sided CI; default),
+#'   `""greater""` (one-sided CI) or `""less""` (one-sided CI). Partial matching is
+#'   allowed (e.g., `""g""`, `""l""`, `""two""`...). See *One-Sided CIs* in
+#'   [effectsize_CIs].
+#' @param ... Ignored
+#'
+#' @details
+#'
+#' # Confidence Intervals for Cohen's *g*
+#' Confidence intervals are based on the proportion (\eqn{P = g + 0.5})
+#' confidence intervals returned by [stats::prop.test()] (minus 0.5), which give
+#' a good close approximation.
+#'
+#' @inheritSection effectsize_CIs CIs and Significance Tests
+#'
+#' @return A data frame with the effect size (`Cohens_g`, `Risk_ratio`
+#'   (possibly with the prefix `log_`), `Cohens_h`) and its CIs (`CI_low` and
+#'   `CI_high`).
+#'
+#' @seealso [phi()] and friends for other effect sizes for contingency tables.
+#' @family effect size indices
+#'
+#'
+#' @references
+#' - Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
+#'
+#' @examples
+#' Performance <- matrix(c(794, 150,
+#'                         86, 570), nrow = 2)
+#' dimnames(Performance) <- list(""1st Survey"" = c(""Approve"", ""Disapprove""),
+#'                               ""2nd Survey"" = c(""Approve"", ""Disapprove""))
+#' Performance
+#'
+#' cohens_g(Performance)
+#'
+#' @export
+#' @importFrom stats complete.cases prop.test
+cohens_g <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...) {
+  alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
+
+  if (inherits(x, ""htest"")) {
+    if (!grepl(""McNemar"", x$method)) {
+      stop(""'x' is not a McNemar test!"", call. = FALSE)
+    }
+    return(effectsize(x, ci = ci, alternative = alternative))
+  }
+
+
+  if (!is.matrix(x)) {
+    if (is.null(y)) {
+      stop(""if 'x' is not a matrix, 'y' must be given"", call. = FALSE)
+    }
+    if (length(x) != length(y)) {
+      stop(""'x' and 'y' must have the same length"", call. = FALSE)
+    }
+    OK <- stats::complete.cases(x, y)
+    x <- as.factor(x[OK])
+    y <- as.factor(y[OK])
+    if ((nlevels(x) < 2) || (nlevels(y) != nlevels(x))) {
+      stop(""'x' and 'y' must have the same number of levels (minimum 2)"", call. = FALSE)
+    }
+    x <- table(x, y)
+  } else {
+    if ((nrow(x) < 2) || (ncol(x) != nrow(x))) {
+      stop(""'x' must be square with at least two rows and columns"", call. = FALSE)
+    }
+  }
+
+
+  b <- x[upper.tri(x)]
+  c <- t(x)[upper.tri(x)]
+
+  P <- sum(pmax(b, c)) / (sum(b) + sum(c))
+  g <- P - 0.5
+
+  out <- data.frame(Cohens_g = g)
+
+  ci_method <- NULL
+  if (is.numeric(ci)) {
+    stopifnot(length(ci) == 1, ci < 1, ci > 0)
+    out$CI <- ci
+
+    n <- sum(b) + sum(c)
+    k <- P * n
+
+    res <- stats::prop.test(k, n,
+                            p = 0.5,
+                            alternative = alternative,
+                            conf.level = ci,
+                            correct = FALSE
+    )
+
+    out$CI <- ci
+    out$CI_low <- res$conf.int[1] - 0.5
+    out$CI_high <- res$conf.int[2] - 0.5
+
+    ci_method <- list(method = ""binomial"")
+  }
+
+  class(out) <- c(""effectsize_table"", ""see_effectsize_table"", class(out))
+  attr(out, ""ci"") <- ci
+  attr(out, ""ci_method"") <- ci_method
+  attr(out, ""approximate"") <- FALSE
+  attr(out, ""alternative"") <- alternative
+  return(out)
+}

---FILE: R/common_language.R---
@@ -114,9 +114,9 @@ cles <- function(x,
     )
     out <- rbind(
       rb_to_cles(rb),
-      .np_U3_OVL(x, y,
+      .np_U3_OVL(x, y, mu = mu,
         ci = ci, alternative = alternative,
-        iterations = iterations
+        iterations = iterations, ...
       )
     )
     attr(out, ""table_footer"") <- ""Non-parametric CLES""
@@ -150,63 +150,72 @@ p_overlap <- function(...) {
 
 #' @importFrom utils tail
 #' @keywords internal
-.np_U3_OVL <- function(x, y, ci = 0.95, alternative = ""two.sided"", iterations) {
-  .get_np_U3_OVL <- function(data, i = seq_len(nrow(data))) {
-    data <- data[i, ]
-
-    c(
-      U3 = sum(data[data$g == ""y"", ""r""] < median(data[data$g == ""x"", ""r""])) /
-        nrow(data[data$g == ""y"", ]),
-      OVL = bayestestR::overlap(
-        data[data$g == ""x"", ""r""],
-        data[data$g == ""y"", ""r""]
-      )
-    )
-  }
-
-  d <- data.frame(
-    r = c(x, y),
-    g = rep(c(""x"", ""y""), c(length(x), length(y)))
-  )
-
-  out <- data.frame(
-    Parameter = c(""Cohen's U3"", ""Overlap""),
-    Coefficient = .get_np_U3_OVL(d)
-  )
-
-  if (is.numeric(ci)) {
-    if (insight::check_if_installed(""boot"", ""for estimating CIs"", stop = FALSE)) {
-      stopifnot(length(ci) == 1, ci < 1, ci > 0)
-      ci.level <- if (alternative == ""two.sided"") ci else 2 * ci - 1
+.np_U3_OVL <-
+  function(x, y,
+           cles_type = c(""u3"", ""ovl""),
+           ci = 0.95,
+           mu = 0,
+           alternative = ""two.sided"",
+           iterations = 200) {
+    if (!any(cles_type %in% c(""u3"", ""ovl""))) return(NULL)
+
+    .get_np_U3_OVL <- function(data, i = seq_len(nrow(data))) {
+      data <- data[i, ]
+      x <- data[data$g == ""x"", ""r""] - mu
+      y <- data[data$g == ""y"", ""r""]
+
+      val <- c()
+      if (""u3"" %in% cles_type) val <- c(val, U3 = sum(y < median(x)) / length(y))
+      if (""ovl"" %in% cles_type) val <- c(val, OVL = bayestestR::overlap(x, y))
+      val
+    }
 
-      R <- boot::boot(
-        data = d,
-        statistic = .get_np_U3_OVL,
-        R = iterations
-      )
+    d <- data.frame(
+      r = c(x, y),
+      g = rep(c(""x"", ""y""), c(length(x), length(y)))
+    )
 
-      bCI <- list(
-        boot::boot.ci(R, conf = ci.level, type = ""perc"", 1)$percent,
-        boot::boot.ci(R, conf = ci.level, type = ""perc"", 2)$percent
-      )
-      bCI <- lapply(bCI, function(.bci) tail(as.vector(.bci), 2))
-      bCI <- matrix(unlist(bCI), 2, byrow = TRUE, dimnames = list(NULL, c(""CI_low"", ""CI_high"")))
-      bCI <- cbind(CI = ci, as.data.frame(bCI))
+    out <- data.frame(
+      Parameter = c(""Cohen's U3"", ""Overlap"")[c(""u3"", ""ovl"") %in% cles_type],
+      Coefficient = .get_np_U3_OVL(d)
+    )
 
-      if (alternative == ""less"") bCI$CI_low <- 0
-      if (alternative == ""greater"") bCI$CI_high <- 1
-    } else {
+    if (is.numeric(ci)) {
       bCI <- data.frame(
         CI = NA, CI_low = NA, CI_high = NA
-      )[c(1, 1), ]
+      )[rep(1, length(cles_type)), ]
+
+      if (insight::check_if_installed(""boot"", ""for estimating CIs"", stop = FALSE)) {
+        stopifnot(length(ci) == 1, ci < 1, ci > 0)
+        ci.level <- if (alternative == ""two.sided"") ci else 2 * ci - 1
+
+        R <- boot::boot(
+          data = d,
+          statistic = .get_np_U3_OVL,
+          R = iterations
+        )
+
+        bCI <- lapply(seq_along(cles_type), boot::boot.ci,
+                      boot.out = R,
+                      conf = ci,
+                      type = ""perc"")
+        bCI <- lapply(bCI, ""[["", ""percent"")
+        bCI <- lapply(bCI, as.vector)
+        bCI <- lapply(bCI, utils::tail, 2)
+        bCI <- matrix(unlist(bCI), ncol = 2, byrow = TRUE,
+                      dimnames = list(NULL, c(""CI_low"", ""CI_high"")))
+        bCI <- cbind(CI = ci, as.data.frame(bCI))
+
+        if (alternative == ""less"") bCI$CI_low <- 0
+        if (alternative == ""greater"") bCI$CI_high <- 1
+      }
+      out <- cbind(out, bCI)
     }
-    out <- cbind(out, bCI)
+    out
   }
-  out
-}
 
 #' @keywords internal
-.cles_which <- function(type,
+.cles_which <- function(cles_type,
                         x,
                         y = NULL,
                         data = NULL,
@@ -225,17 +234,19 @@ p_overlap <- function(...) {
     alternative = alternative,
     verbose = verbose,
     parametric = parametric,
+    cles_type = cles_type,
     ...
   )
 
-  if (type == ""p"") {
-    out <- CLES[1, ]
+
+  if (cles_type == ""p"") {
+    out <- CLES[grepl(""Pr"", CLES$Parameter), ]
     colnames(out)[2] <- ""p_superiority""
-  } else if (type == ""u3"") {
-    out <- CLES[2, ]
+  } else if (cles_type == ""u3"") {
+    out <- CLES[grepl(""U3"", CLES$Parameter), ]
     colnames(out)[2] <- ""Cohens_U3""
-  } else if (type == ""ovl"") {
-    out <- CLES[3, ]
+  } else if (cles_type == ""ovl"") {
+    out <- CLES[grepl(""Ov"", CLES$Parameter), ]
     colnames(out)[2] <- ""overlap""
   }
   out[[1]] <- NULL

---FILE: R/convert_stat_to_anova.R---
@@ -84,7 +84,7 @@
 #' }
 #'
 #' #' @examplesIf require(emmeans)
-#' \donttest{
+#' if (require(emmeans)) {
 #' ## Use with emmeans based contrasts
 #' ## --------------------------------
 #' warp.lm <- lm(breaks ~ wool * tension, data = warpbreaks)

---FILE: R/eta_squared.R---
@@ -486,6 +486,7 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
     if (!is.null(ci)) c(""CI"", ""CI_low"", ""CI_high"")
   ), drop = FALSE]
   rownames(out) <- NULL
+  out$Parameter <- as.character(out$Parameter)
 
   # Set attributes ---
   attr(out, ""partial"") <- partial
@@ -632,6 +633,7 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
     if (!is.null(ci)) c(""CI"", ""CI_low"", ""CI_high"")
   ), drop = FALSE]
   rownames(out) <- NULL
+  out$Parameter <- as.character(out$Parameter)
 
   attr(out, ""partial"") <- partial
   attr(out, ""generalized"") <- generalized
@@ -712,6 +714,7 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
 
   out <- cbind(Parameter = aov_table[[""Parameter""]], ES_tab)
   rownames(out) <- NULL
+  out$Parameter <- as.character(out$Parameter)
 
   # Set attributes ---
   attr(out, ""partial"") <- TRUE
@@ -856,6 +859,7 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
   })
   out <- do.call(""rbind"", params)
   rownames(out) <- NULL
+  out$Response <- as.character(out$Response)
 
   attr(out, ""partial"") <- attr(params[[1]], ""partial"")
   attr(out, ""generalized"") <- attr(params[[1]], ""generalized"")
@@ -964,6 +968,7 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
       SIMPLIFY = FALSE
     )
     out <- do.call(rbind, out)
+    out$Parameter <- as.character(out$Parameter)
 
     # Set attributes ---
     attr(out, ""partial"") <- saved_attr$partial

---FILE: R/mahalanobis_D.R---
@@ -73,6 +73,7 @@
 #' mahalanobis_d(mpg + hp + cyl ~ 1, data = mtcars,
 #'               mu = c(mpg = 15, hp = 5, cyl = 3))
 #'
+#' @importFrom stats cov
 #' @export
 mahalanobis_d <- function(x, y = NULL, data = NULL,
                           pooled_cov = TRUE, mu = 0,
@@ -117,7 +118,7 @@ mahalanobis_d <- function(x, y = NULL, data = NULL,
   if (is.null(y)) {
     d <- colMeans(x) - mu
 
-    COV <- cov(x)
+    COV <- stats::cov(x)
 
     n <- nrow(x)
     p <- ncol(x)

---FILE: R/pooled.R---
@@ -58,6 +58,7 @@ mad_pooled <- function(x, y = NULL, data = NULL, constant = 1.4826, verbose = TR
 }
 
 #' @rdname sd_pooled
+#' @importFrom stats cov
 #' @export
 cov_pooled <- function(x, y = NULL, data = NULL, verbose = TRUE, ...) {
   data <- .get_data_multivariate(x, y, data = data, verbose = verbose)
@@ -67,8 +68,8 @@ cov_pooled <- function(x, y = NULL, data = NULL, verbose = TRUE, ...) {
   n1 <- nrow(x)
   n2 <- nrow(y)
 
-  S1 <- cov(x)
-  S2 <- cov(y)
+  S1 <- stats::cov(x)
+  S2 <- stats::cov(y)
   (S1 * (n1 - 1) + S2 * (n2 - 1)) / (n1 + n2 - 2)
 }
 

---FILE: R/rank_ANOVA.R---
@@ -0,0 +1,320 @@
+#' Effect size for (rank sum) one-way ANOVAs
+#'
+#' Compute rank epsilon squared (\eqn{\varepsilon^2}{\epsilon^2}), and Kendall's
+#' *W* effect sizes for non-parametric (rank sum) one-way ANOVAs.
+#'
+#' @inheritParams phi
+#' @inheritParams rank_biserial
+#' @param x Can be one of:
+#'   - A numeric vector, or a character name of one in `data`.
+#'   - A list of vectors (for `rank_epsilon_squared()`).
+#'   - A matrix of `blocks x groups` (for `kendalls_w()`) (or `groups x blocks`
+#'   if `blocks_on_rows = FALSE`). See details for the `blocks` and `groups`
+#'   terminology used here.
+#'   - A formula in the form of:
+#'       - `DV ~ groups` for `rank_epsilon_squared()`.
+#'       - `DV ~ groups | blocks` for `kendalls_w()` (See details for the
+#'       `blocks` and `groups` terminology used here).
+#' @param groups,blocks A factor vector giving the group / block for the
+#'   corresponding elements of `x`, or a character name of one in `data`.
+#'   Ignored if `x` is not a vector.
+#' @param blocks_on_rows Are blocks on rows (`TRUE`) or columns (`FALSE`).
+#' @param iterations The number of bootstrap replicates for computing confidence
+#'   intervals. Only applies when `ci` is not `NULL`.
+#'
+#'
+#' @details
+#' The rank epsilon squared is appropriate for non-parametric tests of
+#' differences between 2 or more samples (a rank based ANOVA). See
+#' [stats::kruskal.test]. Values range from 0 to 1, with larger values
+#' indicating larger differences between groups.
+#' \cr\cr
+#' Kendall's *W* is appropriate for non-parametric tests of differences between
+#' 2 or more dependent samples (a rank based rmANOVA), where each `group` (e.g.,
+#' experimental condition) was measured for each `block` (e.g., subject). This
+#' measure is also common as a measure of reliability of the rankings of the
+#' `groups` between raters (`blocks`). See [stats::friedman.test]. Values range
+#' from 0 to 1, with larger values indicating larger differences between groups
+#' / higher agreement between raters.
+#'
+#' # Confidence Intervals
+#' Confidence intervals for rank Epsilon squared, and Kendall's *W* are
+#' estimated using the bootstrap method (using the `{boot}` package).
+#'
+#' @inheritSection effectsize_CIs CIs and Significance Tests
+#' @inheritSection rank_biserial Ties
+#'
+#'
+#' @return A data frame with the effect size `(`rank_epsilon_squared` or
+#'   `Kendalls_W`) and its CI (`CI_low` and `CI_high`).
+#'
+#' @family effect size indices
+#' @seealso [rank_biserial()] for more rank based effect sizes
+#'
+#' @examples
+#' \donttest{
+#' # Rank Epsilon Squared
+#' # ====================
+#'
+#' rank_epsilon_squared(mpg ~ cyl, data = mtcars)
+#'
+#'
+#'
+#' # Kendall's W
+#' # ===========
+#' dat <- data.frame(
+#'   cond = c(""A"", ""B"", ""A"", ""B"", ""A"", ""B""),
+#'   ID = c(""L"", ""L"", ""M"", ""M"", ""H"", ""H""),
+#'   y = c(44.56, 28.22, 24, 28.78, 24.56, 18.78)
+#' )
+#' (W <- kendalls_w(y ~ cond | ID, data = dat, verbose = FALSE))
+#'
+#' interpret_kendalls_w(0.11)
+#' interpret(W, rules = ""landis1977"")
+#' }
+#'
+#'
+#' @export
+#' @importFrom stats na.omit
+#' @importFrom insight check_if_installed
+rank_epsilon_squared <- function(x,
+                                 groups,
+                                 data = NULL,
+                                 ci = 0.95,
+                                 alternative = ""greater"",
+                                 iterations = 200,
+                                 ...) {
+  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
+
+  if (inherits(x, ""htest"")) {
+    if (!grepl(""Kruskal-Wallis"", x$method)) {
+      stop(""'x' is not a Kruskal-Wallis-test!"", call. = FALSE)
+    }
+    return(effectsize(x, ci = ci, iterations = iterations, alternative = alternative))
+  }
+
+  ## pep data
+  data <- .get_data_multi_group(x, groups, data, ...)
+  data <- stats::na.omit(data)
+
+  ## compute
+  out <- data.frame(rank_epsilon_squared = .repsilon(data))
+
+  ## CI
+  ci_method <- NULL
+  if (is.numeric(ci)) {
+    if (insight::check_if_installed(""boot"", ""for estimating CIs"", stop = FALSE)) {
+      out <- cbind(out, .repsilon_ci(data, ci, alternative, iterations))
+      ci_method <- list(method = ""percentile bootstrap"", iterations = iterations)
+    } else {
+      ci <- NULL
+    }
+  }
+  if (is.null(ci)) alternative <- NULL
+
+  class(out) <- c(""effectsize_table"", ""see_effectsize_table"", class(out))
+  attr(out, ""ci"") <- ci
+  attr(out, ""ci_method"") <- ci_method
+  attr(out, ""approximate"") <- FALSE
+  attr(out, ""alternative"") <- alternative
+  return(out)
+}
+
+#' @rdname rank_epsilon_squared
+#' @export
+#' @importFrom stats na.omit
+#' @importFrom insight check_if_installed
+kendalls_w <- function(x,
+                       groups,
+                       blocks,
+                       data = NULL,
+                       blocks_on_rows = TRUE,
+                       ci = 0.95,
+                       alternative = ""greater"",
+                       iterations = 200,
+                       verbose = TRUE,
+                       ...) {
+  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
+
+  if (inherits(x, ""htest"")) {
+    if (!grepl(""Friedman"", x$method)) {
+      stop(""'x' is not a Friedman-test!"", call. = FALSE)
+    }
+    return(effectsize(x, ci = ci, iterations = iterations, verbose = verbose, alternative = alternative))
+  }
+
+  ## prep data
+  if (is.matrix(x) && !blocks_on_rows) x <- t(x)
+  data <- .get_data_nested_groups(x, groups, blocks, data, ...)
+  data <- stats::na.omit(data)
+
+  ## compute
+  W <- .kendalls_w(data, verbose = verbose)
+  out <- data.frame(Kendalls_W = W)
+
+  ## CI
+  ci_method <- NULL
+  if (is.numeric(ci)) {
+    if (insight::check_if_installed(""boot"", ""for estimating CIs"", stop = FALSE)) {
+      out <- cbind(out, .kendalls_w_ci(data, ci, alternative, iterations))
+      ci_method <- list(method = ""percentile bootstrap"", iterations = iterations)
+    } else {
+      ci <- NULL
+    }
+  }
+  if (is.null(ci)) alternative <- NULL
+
+  class(out) <- c(""effectsize_table"", ""see_effectsize_table"", class(out))
+  attr(out, ""ci"") <- ci
+  attr(out, ""ci_method"") <- ci_method
+  attr(out, ""approximate"") <- FALSE
+  attr(out, ""alternative"") <- alternative
+  return(out)
+}
+
+# rank_eta_squared <- function(x, g, data = NULL, ci = 0.95, iterations = 200) {
+#
+#   data <- .get_data_multi_group(x, g, data)
+#   data <- stats::na.omit(data)
+#   x <- data$x
+#   g <- data$g
+#
+#   model <- stats::kruskal.test(x, g)
+#
+#   H <- unname(model$statistic)
+#   k <- length(unique(g)) # model$parameter + 1
+#   n <- length(g)
+#
+#   E <- (H - k + 1) / (n - k)
+#
+#   out <- data.frame(rank_eta_squared = E)
+#
+#   if (is.numeric(ci)) {
+#     warning(""Nope. Not yet."", call. = FALSE)
+#     out$CI <- ci
+#     out$CI_low <- 0
+#     out$CI_high <- 1
+#   }
+#
+#   class(out) <- c(""effectsize_table"", class(out))
+#   return(out)
+# }
+
+# Utils -------------------------------------------------------------------
+
+## Get ----
+
+#' @keywords internal
+#' @importFrom stats kruskal.test
+.repsilon <- function(data) {
+  model <- stats::kruskal.test(data$x, data$groups)
+
+  H <- unname(model$statistic)
+  n <- nrow(data)
+
+  E <- H / ((n^2 - 1) / (n + 1))
+}
+
+
+#' @keywords internal
+.kendalls_w <- function(data, verbose) {
+  rankings <- apply(data, 1, .safe_ranktransform, verbose = verbose)
+  rankings <- t(rankings) # keep dims
+
+  n <- ncol(rankings) # items
+  m <- nrow(rankings) # judges
+  R <- colSums(rankings)
+
+  no_ties <- apply(rankings, 1, function(x) length(x) == insight::n_unique(x))
+  if (!all(no_ties)) {
+    if (verbose) {
+      warning(
+        sprintf(
+          ""%d block(s) contain ties%s."",
+          sum(!no_ties),
+          ifelse(any(apply(as.data.frame(rankings)[!no_ties, ], 1, insight::n_unique) == 1),
+                 "", some containing only 1 unique ranking"", """"
+          )
+        ),
+        call. = FALSE
+      )
+    }
+
+    Tj <- 0
+    for (i in seq_len(m)) {
+      rater <- table(rankings[i, ])
+      ties <- rater[rater > 1]
+      l <- as.numeric(ties)
+      Tj <- Tj + sum(l^3 - l)
+    }
+
+    W <- (12 * sum(R^2) - 3 * (m^2) * n * ((n + 1)^2)) /
+      (m^2 * (n^3 - n) - m * Tj)
+  } else {
+    S <- var(R) * (n - 1)
+    W <- (12 * S) /
+      (m^2 * (n^3 - n))
+  }
+  W
+}
+
+## CI ----
+
+
+
+#' @importFrom utils tail
+#' @keywords internal
+.repsilon_ci <- function(data, ci, alternative, iterations) {
+  stopifnot(length(ci) == 1, ci < 1, ci > 0)
+  ci.level <- if (alternative == ""two.sided"") ci else 2 * ci - 1
+
+
+  boot_r_epsilon <- function(.data, .i) {
+    split(.data$x, .data$groups) <- lapply(split(.data$x, .data$groups),
+                                           sample,
+                                           replace = TRUE
+    )
+    .repsilon(.data)
+  }
+
+  R <- boot::boot(
+    data = data,
+    statistic = boot_r_epsilon,
+    R = iterations
+  )
+
+  bCI <- boot::boot.ci(R, conf = ci.level, type = ""perc"")$percent
+  bCI <- tail(as.vector(bCI), 2)
+
+  data.frame(
+    CI = ci,
+    CI_low = if (alternative == ""less"") 0 else bCI[1],
+    CI_high = if (alternative == ""greater"") 1 else bCI[2]
+  )
+}
+
+#' @importFrom utils tail
+#' @keywords internal
+.kendalls_w_ci <- function(data, ci, alternative, iterations) {
+  stopifnot(length(ci) == 1, ci < 1, ci > 0)
+  ci.level <- if (alternative == ""two.sided"") ci else 2 * ci - 1
+
+  boot_w <- function(.data, .i) {
+    .kendalls_w(.data[.i, ], verbose = FALSE) # sample rows
+  }
+
+  R <- boot::boot(
+    data = data,
+    statistic = boot_w,
+    R = iterations
+  )
+
+  bCI <- boot::boot.ci(R, conf = ci.level, type = ""perc"")$percent
+  bCI <- tail(as.vector(bCI), 2)
+
+  data.frame(
+    CI = ci,
+    CI_low = if (alternative == ""less"") 0 else bCI[1],
+    CI_high = if (alternative == ""greater"") 1 else bCI[2]
+  )
+}

---FILE: R/rank_diff.R---
@@ -0,0 +1,319 @@
+#' Effect size for (rank sum) differences
+#'
+#' Compute the rank-biserial correlation (\eqn{r_{rb}}{r_rb}) and Cliff's *delta*
+#' (\eqn{\delta}) effect sizes for non-parametric (rank sum) differences.
+#'
+#' @inheritParams cohens_d
+#' @param mu a number indicating the value around which (a-)symmetry (for
+#'   one-sample or paired samples) or shift (for independent samples) is to be
+#'   estimated. See [stats::wilcox.test].
+#'
+#' @details
+#'
+#' The rank-biserial correlation is appropriate for non-parametric tests of
+#' differences - both for the one sample or paired samples case, that would
+#' normally be tested with Wilcoxon's Signed Rank Test (giving the
+#' **matched-pairs** rank-biserial correlation) and for two independent samples
+#' case, that would normally be tested with Mann-Whitney's *U* Test (giving
+#' **Glass'** rank-biserial correlation). See [stats::wilcox.test]. In both
+#' cases, the correlation represents the difference between the proportion of
+#' favorable and unfavorable pairs / signed ranks (Kerby, 2014). Values range
+#' from `-1` (*all* values of the second sample are larger than *all* the values
+#' of the first sample) to `+1` (*all* values of the second sample are smaller
+#' than *all* the values of the first sample). Cliff's *delta* is an alias to
+#' the rank-biserial correlation in the two sample case.
+#'
+#' # Ties
+#' When tied values occur, they are each given the average of the ranks that
+#' would have been given had no ties occurred. This results in an effect size of
+#' reduced magnitude. A correction has been applied for Kendall's *W*.
+#'
+#' # Confidence Intervals
+#' Confidence intervals for the rank-biserial correlation (and Cliff's *delta*)
+#' are estimated using the normal approximation (via Fisher's transformation).
+#'
+#' @inheritSection effectsize_CIs CIs and Significance Tests
+#'
+#' @return A data frame with the effect size `r_rank_biserial` and its CI
+#'   (`CI_low` and `CI_high`).
+#'
+#' @family effect size indices
+#' @seealso [rank_epsilon_squared()] for more rank based effect sizes
+#'
+#' @examples
+#' \donttest{
+#' data(mtcars)
+#' mtcars$am <- factor(mtcars$am)
+#' mtcars$cyl <- factor(mtcars$cyl)
+#'
+#' # Two Independent Samples ----------
+#' (rb <- rank_biserial(mpg ~ am, data = mtcars))
+#' # Same as:
+#' # rank_biserial(""mpg"", ""am"", data = mtcars)
+#' # rank_biserial(mtcars$mpg[mtcars$am==""0""], mtcars$mpg[mtcars$am==""1""])
+#'
+#' # More options:
+#' rank_biserial(mpg ~ am, data = mtcars, mu = -5)
+#' print(rb, append_CLES = TRUE)
+#'
+#'
+#' # One Sample ----------
+#' rank_biserial(wt ~ 1, data = mtcars, mu = 3)
+#' # same as:
+#' # rank_biserial(""wt"", data = mtcars, mu = 3)
+#' # rank_biserial(mtcars$wt, mu = 3)
+#'
+#'
+#' # Paired Samples ----------
+#' dat <- data.frame(
+#'   Cond1 = c(1.83, 0.5, 1.62, 2.48, 1.68, 1.88, 1.55, 3.06, 1.3),
+#'   Cond2 = c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)
+#' )
+#' (rb <- rank_biserial(Pair(Cond1, Cond2) ~ 1, data = dat, paired = TRUE))
+#'
+#' # same as:
+#' # rank_biserial(dat$Cond1, dat$Cond2, paired = TRUE)
+#'
+#' interpret_rank_biserial(0.78)
+#' interpret(rb, rules = ""funder2019"")
+#' }
+#'
+#' @references
+#' - Cureton, E. E. (1956). Rank-biserial correlation. Psychometrika, 21(3),
+#' 287-290.
+#'
+#' - Glass, G. V. (1965). A ranking variable analogue of biserial correlation:
+#' Implications for short-cut item analysis. Journal of Educational Measurement,
+#' 2(1), 91-95.
+#'
+#' - Kendall, M.G. (1948) Rank correlation methods. London: Griffin.
+#'
+#' - Kerby, D. S. (2014). The simple difference formula: An approach to teaching
+#' nonparametric correlation. Comprehensive Psychology, 3, 11-IT.
+#'
+#' - King, B. M., & Minium, E. W. (2008). Statistical reasoning in the
+#' behavioral sciences. John Wiley & Sons Inc.
+#'
+#' - Cliff, N. (1993). Dominance statistics: Ordinal analyses to answer ordinal
+#' questions. Psychological bulletin, 114(3), 494.
+#'
+#' - Tomczak, M., & Tomczak, E. (2014). The need to report effect size estimates
+#' revisited. An overview of some recommended measures of effect size.
+#'
+#' @export
+#' @importFrom stats na.omit complete.cases
+rank_biserial <- function(x,
+                          y = NULL,
+                          data = NULL,
+                          mu = 0,
+                          ci = 0.95,
+                          alternative = ""two.sided"",
+                          paired = FALSE,
+                          verbose = TRUE,
+                          ...) {
+  alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
+
+  if (inherits(x, ""htest"")) {
+    if (!grepl(""Wilcoxon"", x$method)) {
+      stop(""'x' is not a Wilcoxon-test!"", call. = FALSE)
+    }
+    return(effectsize(x, verbose = verbose, type = ""rb""))
+  }
+
+  ## Prep data
+  out <- .get_data_2_samples(x, y, data, verbose, ...)
+  x <- out$x
+  y <- out$y
+
+  if (is.null(y)) {
+    y <- rep(0, length.out = length(x))
+    paired <- TRUE
+  }
+
+  if (paired) {
+    oo <- stats::complete.cases(x, y)
+    x <- x[oo]
+    y <- y[oo]
+  } else {
+    x <- stats::na.omit(x)
+    y <- stats::na.omit(y)
+  }
+
+  ## Compute
+  r_rbs <- .r_rbs(x, y, mu = mu, paired = paired, verbose = verbose)
+  out <- data.frame(r_rank_biserial = r_rbs)
+
+  ## CI
+  ci_method <- NULL
+  if (is.numeric(ci)) {
+    # if (requireNamespace(""boot"", quietly = TRUE)) {
+    #   out <- cbind(out, .rbs_ci_boot(
+    #     y,
+    #     mu = mu,
+    #     paired = paired,
+    #     ci = ci,
+    #     iterations = iterations
+    #   ))
+    #
+    #   ci_method <- list(method = ""bootstrap"", iterations = iterations)
+    # } else {
+    #   ci <- NULL
+    #   warning(""For CIs, the 'boot' package must be installed."", call. = FALSE)
+    # }
+
+    # Parametric method
+    stopifnot(length(ci) == 1, ci < 1, ci > 0)
+    out$CI <- ci
+    ci.level <- if (alternative == ""two.sided"") ci else 2 * ci - 1
+
+    alpha <- 1 - ci.level
+
+    rf <- atanh(r_rbs)
+    if (paired) {
+      nd <- sum((x - mu) != 0)
+      maxw <- (nd^2 + nd) / 2
+
+      # From: https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test#Historical_T_statistic/
+      # wSE <- sqrt((n * (n + 1) * (2 * n + 1)) / 24)
+      # Delta method for f(x) = w * 2 / (maxw) - 1
+      # r_rbsSE <- wSE * sqrt(4 / (maxw)^2)
+      # Delta method for z: z_rbsSE <- r_rbsSE / (1 - r_rbs^2)
+      #   But simulations suggest that z_rbsSE is positively biased
+      #   more than r_rbsSE is negatively biased, especially when r_rbs is large,
+      #   so we use r_rbsSE instead
+      rfSE <- sqrt((2 * nd^3 + 3 * nd^2 + nd) / 6) / maxw
+    } else {
+      n1 <- length(x)
+      n2 <- length(y)
+
+      # From: https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test#Normal_approximation_and_tie_correction/
+      # wSE <- sqrt((n1 * n2 * (n1 + n2 + 1)) / 12)
+      # Delta method for f(x) = 1 - 2 * w / (n1 * n2) * sign(diff)
+      # r_rbsSE <- wSE * sqrt(4 / (n1 * n2)^2)
+      # Delta method for z: z_rbsSE <- r_rbsSE / (1 - r_rbs^2)
+      #   But simulations suggest that z_rbsSE is positively biased
+      #   more than r_rbsSE is negatively biased, especially when r_rbs is large,
+      #   so we use r_rbsSE instead
+      rfSE <- sqrt((n1 + n2 + 1) / (3 * n1 * n2))
+    }
+
+    confint <- tanh(rf + c(-1, 1) * qnorm(1 - alpha / 2) * rfSE)
+    out$CI_low <- confint[1]
+    out$CI_high <- confint[2]
+    ci_method <- list(method = ""normal"")
+    if (alternative == ""less"") {
+      out$CI_low <- -1
+    } else if (alternative == ""greater"") {
+      out$CI_high <- 1
+    }
+  } else {
+    alternative <- NULL
+  }
+
+  class(out) <- c(""effectsize_difference"", ""effectsize_table"", ""see_effectsize_table"", class(out))
+  attr(out, ""paired"") <- paired
+  attr(out, ""mu"") <- mu
+  attr(out, ""ci"") <- ci
+  attr(out, ""ci_method"") <- ci_method
+  attr(out, ""approximate"") <- FALSE
+  attr(out, ""alternative"") <- alternative
+  return(out)
+}
+
+#' @export
+#' @rdname rank_biserial
+cliffs_delta <- function(x,
+                         y = NULL,
+                         data = NULL,
+                         mu = 0,
+                         ci = 0.95,
+                         alternative = ""two.sided"",
+                         verbose = TRUE,
+                         ...) {
+  rank_biserial(
+    x, y,
+    data = data,
+    mu = mu,
+    paired = FALSE,
+    ci = ci,
+    alternative = alternative,
+    verbose = verbose,
+    ...
+  )
+}
+
+
+
+# Utils -------------------------------------------------------------------
+
+#' @keywords internal
+#' @importFrom stats na.omit
+.r_rbs <- function(x, y, mu, paired, verbose = FALSE) {
+  if (paired) {
+    Ry <- .safe_ranktransform((x - y) - mu, sign = TRUE, verbose = verbose)
+    Ry <- stats::na.omit(Ry)
+
+    n <- length(Ry)
+    S <- (n * (n + 1) / 2)
+
+    U1 <- sum(Ry[Ry > 0], na.rm = TRUE)
+    U2 <- -sum(Ry[Ry < 0], na.rm = TRUE)
+  } else {
+    Ry <- .safe_ranktransform(c(x - mu, y), verbose = verbose)
+
+    n1 <- length(x)
+    n2 <- length(y)
+    S <- (n1 * n2)
+
+    U1 <- sum(Ry[seq_along(x)]) - n1 * (n1 + 1) / 2
+    U2 <- sum(Ry[-seq_along(x)]) - n2 * (n2 + 1) / 2
+  }
+
+  u_ <- U1 / S
+  f_ <- U2 / S
+  return(u_ - f_)
+}
+
+# #' @keywords internal
+# #' @importFrom bayestestR ci
+# .rbs_ci_boot <- function(x,
+#                          y,
+#                          mu = 0,
+#                          paired = FALSE,
+#                          ci = 0.95,
+#                          iterations = 200) {
+#   stopifnot(length(ci) == 1, ci < 1, ci > 0)
+#
+#   if (paired) {
+#     data <- data.frame(x, y)
+#     boot_rbs <- function(.data, .i) {
+#       .data <- .data[.i, ]
+#       .x <- .data$x
+#       .y <- .data$y
+#       .r_rbs(.x, .y, mu = mu, paired = TRUE, verbose = FALSE)
+#     }
+#   } else {
+#     data <- data.frame(
+#       i = seq_along(c(x, y))
+#     )
+#
+#     boot_rbs <- function(.data, .i) {
+#       .x <- sample(x, replace = TRUE)
+#       .y <- sample(y, replace = TRUE)
+#
+#       .r_rbs(.x, .y, mu = mu, paired = FALSE, verbose = FALSE)
+#     }
+#   }
+#
+#   R <- boot::boot(
+#     data = data,
+#     statistic = boot_rbs,
+#     R = iterations
+#   )
+#
+#   out <- as.data.frame(
+#     bayestestR::ci(na.omit(R$t), ci = ci, verbose = FALSE)
+#   )
+#   out$CI <- ci
+#   out
+# }
\ No newline at end of file

---FILE: R/rank_effectsizes.R---
@@ -1,639 +0,0 @@
-#' Effect size for non-parametric (rank sum) tests
-#'
-#' Compute the rank-biserial correlation (\eqn{r_{rb}}{r_rb}), Cliff's *delta*
-#' (\eqn{\delta}), rank epsilon squared (\eqn{\varepsilon^2}{\epsilon^2}), and
-#' Kendall's *W* effect sizes for non-parametric (rank sum) tests.
-#'
-#' @inheritParams cohens_d
-#' @param x Can be one of:
-#'   - A numeric vector, or a character name of one in `data`.
-#'   - A formula in to form of `DV ~ groups` (for `rank_biserial()` and
-#'   `rank_epsilon_squared()`) or `DV ~ groups | blocks` (for `kendalls_w()`;
-#'   See details for the `blocks` and `groups` terminology used here).
-#'   - A list of vectors (for `rank_epsilon_squared()`).
-#'   - A matrix of `blocks x groups` (for `kendalls_w()`) (or `groups x blocks`
-#'   if `blocks_on_rows = FALSE`). See details for the `blocks` and `groups`
-#'   terminology used here.
-#' @param y An optional numeric vector of data values to compare to `x`, or a
-#'   character name of one in `data`. Ignored if `x` is not a vector.
-#' @param groups,blocks A factor vector giving the group / block for the
-#'   corresponding elements of `x`, or a character name of one in `data`.
-#'   Ignored if `x` is not a vector.
-#' @param blocks_on_rows Are blocks on rows (`TRUE`) or columns (`FALSE`).
-#' @param mu a number indicating the value around which (a-)symmetry (for
-#'   one-sample or paired samples) or shift (for independent samples) is to be
-#'   estimated. See [stats::wilcox.test].
-#' @param iterations The number of bootstrap replicates for computing confidence
-#'   intervals. Only applies when `ci` is not `NULL`. (Deprecated for
-#'   `rank_biserial()`).
-#' @param alternative a character string specifying the alternative hypothesis;
-#'   Controls the type of CI returned: `""two.sided""` (two-sided CI; default for
-#'   rank-biserial correlation and Cliff's *delta*), `""greater""` (default for
-#'   rank epsilon squared and Kendall's *W*) or `""less""` (one-sided CI). Partial
-#'   matching is allowed (e.g., `""g""`, `""l""`, `""two""`...). See *One-Sided CIs*
-#'   in [effectsize_CIs].
-#'
-#' @details
-#' The rank-biserial correlation is appropriate for non-parametric tests of
-#' differences - both for the one sample or paired samples case, that would
-#' normally be tested with Wilcoxon's Signed Rank Test (giving the
-#' **matched-pairs** rank-biserial correlation) and for two independent samples
-#' case, that would normally be tested with Mann-Whitney's *U* Test (giving
-#' **Glass'** rank-biserial correlation). See [stats::wilcox.test]. In both
-#' cases, the correlation represents the difference between the proportion of
-#' favorable and unfavorable pairs / signed ranks (Kerby, 2014). Values range
-#' from `-1` (*all* values of the second sample are larger than *all* the values
-#' of the first sample) to `+1` (*all* values of the second sample are smaller
-#' than *all* the values of the first sample). Cliff's *delta* is an alias to
-#' the rank-biserial correlation in the two sample case.
-#' \cr\cr
-#' The rank epsilon squared is appropriate for non-parametric tests of
-#' differences between 2 or more samples (a rank based ANOVA). See
-#' [stats::kruskal.test]. Values range from 0 to 1, with larger values
-#' indicating larger differences between groups.
-#' \cr\cr
-#' Kendall's *W* is appropriate for non-parametric tests of differences between
-#' 2 or more dependent samples (a rank based rmANOVA), where each `group` (e.g.,
-#' experimental condition) was measured for each `block` (e.g., subject). This
-#' measure is also common as a measure of reliability of the rankings of the
-#' `groups` between raters (`blocks`). See [stats::friedman.test]. Values range
-#' from 0 to 1, with larger values indicating larger differences between groups
-#' / higher agreement between raters.
-#'
-#' ## Ties
-#' When tied values occur, they are each given the average of the ranks that
-#' would have been given had no ties occurred. This results in an effect size of
-#' reduced magnitude. A correction has been applied for Kendall's *W*.
-#'
-#' # Confidence Intervals
-#' Confidence intervals for the rank-biserial correlation (and Cliff's *delta*)
-#' are estimated using the normal approximation (via Fisher's transformation).
-#' Confidence intervals for rank Epsilon squared, and Kendall's *W* are
-#' estimated using the bootstrap method (using the `{boot}` package).
-#'
-#' @return A data frame with the effect size (`r_rank_biserial`,
-#'   `rank_epsilon_squared` or `Kendalls_W`) and its CI (`CI_low` and
-#'   `CI_high`).
-#'
-#' @family effect size indices
-#'
-#' @examples
-#' \donttest{
-#' data(mtcars)
-#' mtcars$am <- factor(mtcars$am)
-#' mtcars$cyl <- factor(mtcars$cyl)
-#'
-#' # Rank Biserial Correlation
-#' # =========================
-#'
-#' # Two Independent Samples ----------
-#' (rb <- rank_biserial(mpg ~ am, data = mtcars))
-#' # Same as:
-#' # rank_biserial(""mpg"", ""am"", data = mtcars)
-#' # rank_biserial(mtcars$mpg[mtcars$am==""0""], mtcars$mpg[mtcars$am==""1""])
-#'
-#' # More options:
-#' rank_biserial(mpg ~ am, data = mtcars, mu = -5)
-#' print(rb, append_CLES = TRUE)
-#'
-#'
-#' # One Sample ----------
-#' rank_biserial(wt ~ 1, data = mtcars, mu = 3)
-#' # same as:
-#' # rank_biserial(""wt"", data = mtcars, mu = 3)
-#' # rank_biserial(mtcars$wt, mu = 3)
-#'
-#'
-#' # Paired Samples ----------
-#' dat <- data.frame(
-#'   Cond1 = c(1.83, 0.5, 1.62, 2.48, 1.68, 1.88, 1.55, 3.06, 1.3),
-#'   Cond2 = c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)
-#' )
-#' (rb <- rank_biserial(Pair(Cond1, Cond2) ~ 1, data = dat, paired = TRUE))
-#'
-#' # same as:
-#' # rank_biserial(dat$Cond1, dat$Cond2, paired = TRUE)
-#'
-#' interpret_rank_biserial(0.78)
-#' interpret(rb, rules = ""funder2019"")
-#'
-#'
-#' # Rank Epsilon Squared
-#' # ====================
-#'
-#' rank_epsilon_squared(mpg ~ cyl, data = mtcars)
-#'
-#'
-#'
-#' # Kendall's W
-#' # ===========
-#' dat <- data.frame(
-#'   cond = c(""A"", ""B"", ""A"", ""B"", ""A"", ""B""),
-#'   ID = c(""L"", ""L"", ""M"", ""M"", ""H"", ""H""),
-#'   y = c(44.56, 28.22, 24, 28.78, 24.56, 18.78)
-#' )
-#' (W <- kendalls_w(y ~ cond | ID, data = dat, verbose = FALSE))
-#'
-#' interpret_kendalls_w(0.11)
-#' interpret(W, rules = ""landis1977"")
-#' }
-#'
-#' @references
-#' - Cureton, E. E. (1956). Rank-biserial correlation. Psychometrika, 21(3),
-#' 287-290.
-#'
-#' - Glass, G. V. (1965). A ranking variable analogue of biserial correlation:
-#' Implications for short-cut item analysis. Journal of Educational Measurement,
-#' 2(1), 91-95.
-#'
-#' - Kendall, M.G. (1948) Rank correlation methods. London: Griffin.
-#'
-#' - Kerby, D. S. (2014). The simple difference formula: An approach to teaching
-#' nonparametric correlation. Comprehensive Psychology, 3, 11-IT.
-#'
-#' - King, B. M., & Minium, E. W. (2008). Statistical reasoning in the
-#' behavioral sciences. John Wiley & Sons Inc.
-#'
-#' - Cliff, N. (1993). Dominance statistics: Ordinal analyses to answer ordinal
-#' questions. Psychological bulletin, 114(3), 494.
-#'
-#' - Tomczak, M., & Tomczak, E. (2014). The need to report effect size estimates
-#' revisited. An overview of some recommended measures of effect size.
-#'
-#' @export
-#' @importFrom stats na.omit complete.cases
-rank_biserial <- function(x,
-                          y = NULL,
-                          data = NULL,
-                          mu = 0,
-                          ci = 0.95,
-                          alternative = ""two.sided"",
-                          paired = FALSE,
-                          verbose = TRUE,
-                          ...,
-                          iterations) {
-  alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
-
-  if (inherits(x, ""htest"")) {
-    if (!grepl(""Wilcoxon"", x$method)) {
-      stop(""'x' is not a Wilcoxon-test!"", call. = FALSE)
-    }
-    return(effectsize(x, verbose = verbose, type = ""rb""))
-  }
-
-  if (!missing(iterations) && verbose) {
-    warning(
-      ""'iterations' argument is deprecated. CIs are estimated using a parametric normal approximation."",
-      immediate. = TRUE
-    )
-  }
-
-  ## Prep data
-  out <- .get_data_2_samples(x, y, data, verbose, ...)
-  x <- out$x
-  y <- out$y
-
-  if (is.null(y)) {
-    y <- rep(0, length.out = length(x))
-    paired <- TRUE
-  }
-
-  if (paired) {
-    oo <- stats::complete.cases(x, y)
-    x <- x[oo]
-    y <- y[oo]
-  } else {
-    x <- stats::na.omit(x)
-    y <- stats::na.omit(y)
-  }
-
-  ## Compute
-  r_rbs <- .r_rbs(x, y, mu = mu, paired = paired, verbose = verbose)
-  out <- data.frame(r_rank_biserial = r_rbs)
-
-  ## CI
-  ci_method <- NULL
-  if (is.numeric(ci)) {
-    # if (requireNamespace(""boot"", quietly = TRUE)) {
-    #   out <- cbind(out, .rbs_ci_boot(
-    #     y,
-    #     mu = mu,
-    #     paired = paired,
-    #     ci = ci,
-    #     iterations = iterations
-    #   ))
-    #
-    #   ci_method <- list(method = ""bootstrap"", iterations = iterations)
-    # } else {
-    #   ci <- NULL
-    #   warning(""For CIs, the 'boot' package must be installed."", call. = FALSE)
-    # }
-
-    # Parametric method
-    stopifnot(length(ci) == 1, ci < 1, ci > 0)
-    out$CI <- ci
-    ci.level <- if (alternative == ""two.sided"") ci else 2 * ci - 1
-
-    alpha <- 1 - ci.level
-
-    rf <- atanh(r_rbs)
-    if (paired) {
-      nd <- sum((x - mu) != 0)
-      maxw <- (nd^2 + nd) / 2
-
-      # From: https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test#Historical_T_statistic/
-      # wSE <- sqrt((n * (n + 1) * (2 * n + 1)) / 24)
-      # Delta method for f(x) = w * 2 / (maxw) - 1
-      # r_rbsSE <- wSE * sqrt(4 / (maxw)^2)
-      # Delta method for z: z_rbsSE <- r_rbsSE / (1 - r_rbs^2)
-      #   But simulations suggest that z_rbsSE is positively biased
-      #   more than r_rbsSE is negatively biased, especially when r_rbs is large,
-      #   so we use r_rbsSE instead
-      rfSE <- sqrt((2 * nd^3 + 3 * nd^2 + nd) / 6) / maxw
-    } else {
-      n1 <- length(x)
-      n2 <- length(y)
-
-      # From: https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test#Normal_approximation_and_tie_correction/
-      # wSE <- sqrt((n1 * n2 * (n1 + n2 + 1)) / 12)
-      # Delta method for f(x) = 1 - 2 * w / (n1 * n2) * sign(diff)
-      # r_rbsSE <- wSE * sqrt(4 / (n1 * n2)^2)
-      # Delta method for z: z_rbsSE <- r_rbsSE / (1 - r_rbs^2)
-      #   But simulations suggest that z_rbsSE is positively biased
-      #   more than r_rbsSE is negatively biased, especially when r_rbs is large,
-      #   so we use r_rbsSE instead
-      rfSE <- sqrt((n1 + n2 + 1) / (3 * n1 * n2))
-    }
-
-    confint <- tanh(rf + c(-1, 1) * qnorm(1 - alpha / 2) * rfSE)
-    out$CI_low <- confint[1]
-    out$CI_high <- confint[2]
-    ci_method <- list(method = ""normal"")
-    if (alternative == ""less"") {
-      out$CI_low <- -1
-    } else if (alternative == ""greater"") {
-      out$CI_high <- 1
-    }
-  } else {
-    alternative <- NULL
-  }
-
-  class(out) <- c(""effectsize_difference"", ""effectsize_table"", ""see_effectsize_table"", class(out))
-  attr(out, ""paired"") <- paired
-  attr(out, ""mu"") <- mu
-  attr(out, ""ci"") <- ci
-  attr(out, ""ci_method"") <- ci_method
-  attr(out, ""approximate"") <- FALSE
-  attr(out, ""alternative"") <- alternative
-  return(out)
-}
-
-#' @export
-#' @rdname rank_biserial
-cliffs_delta <- function(x,
-                         y = NULL,
-                         data = NULL,
-                         mu = 0,
-                         ci = 0.95,
-                         alternative = ""two.sided"",
-                         verbose = TRUE,
-                         ...) {
-  rank_biserial(
-    x, y,
-    data = data,
-    mu = mu,
-    paired = FALSE,
-    ci = ci,
-    alternative = alternative,
-    verbose = verbose,
-    ...
-  )
-}
-
-
-#' @rdname rank_biserial
-#' @export
-#' @importFrom stats na.omit
-#' @importFrom insight check_if_installed
-rank_epsilon_squared <- function(x,
-                                 groups,
-                                 data = NULL,
-                                 ci = 0.95,
-                                 alternative = ""greater"",
-                                 iterations = 200,
-                                 ...) {
-  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
-
-  if (inherits(x, ""htest"")) {
-    if (!grepl(""Kruskal-Wallis"", x$method)) {
-      stop(""'x' is not a Kruskal-Wallis-test!"", call. = FALSE)
-    }
-    return(effectsize(x, ci = ci, iterations = iterations, alternative = alternative))
-  }
-
-  ## pep data
-  data <- .get_data_multi_group(x, groups, data, ...)
-  data <- stats::na.omit(data)
-
-  ## compute
-  out <- data.frame(rank_epsilon_squared = .repsilon(data))
-
-  ## CI
-  ci_method <- NULL
-  if (is.numeric(ci)) {
-    if (insight::check_if_installed(""boot"", ""for estimating CIs"", stop = FALSE)) {
-      out <- cbind(out, .repsilon_ci(data, ci, alternative, iterations))
-      ci_method <- list(method = ""percentile bootstrap"", iterations = iterations)
-    } else {
-      ci <- NULL
-    }
-  }
-  if (is.null(ci)) alternative <- NULL
-
-  class(out) <- c(""effectsize_table"", ""see_effectsize_table"", class(out))
-  attr(out, ""ci"") <- ci
-  attr(out, ""ci_method"") <- ci_method
-  attr(out, ""approximate"") <- FALSE
-  attr(out, ""alternative"") <- alternative
-  return(out)
-}
-
-#' @rdname rank_biserial
-#' @export
-#' @importFrom stats na.omit
-#' @importFrom insight check_if_installed
-kendalls_w <- function(x,
-                       groups,
-                       blocks,
-                       data = NULL,
-                       blocks_on_rows = TRUE,
-                       ci = 0.95,
-                       alternative = ""greater"",
-                       iterations = 200,
-                       verbose = TRUE,
-                       ...) {
-  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
-
-  if (inherits(x, ""htest"")) {
-    if (!grepl(""Friedman"", x$method)) {
-      stop(""'x' is not a Friedman-test!"", call. = FALSE)
-    }
-    return(effectsize(x, ci = ci, iterations = iterations, verbose = verbose, alternative = alternative))
-  }
-
-  ## prep data
-  if (is.matrix(x) && !blocks_on_rows) x <- t(x)
-  data <- .get_data_nested_groups(x, groups, blocks, data, ...)
-  data <- stats::na.omit(data)
-
-  ## compute
-  W <- .kendalls_w(data, verbose = verbose)
-  out <- data.frame(Kendalls_W = W)
-
-  ## CI
-  ci_method <- NULL
-  if (is.numeric(ci)) {
-    if (insight::check_if_installed(""boot"", ""for estimating CIs"", stop = FALSE)) {
-      out <- cbind(out, .kendalls_w_ci(data, ci, alternative, iterations))
-      ci_method <- list(method = ""percentile bootstrap"", iterations = iterations)
-    } else {
-      ci <- NULL
-    }
-  }
-  if (is.null(ci)) alternative <- NULL
-
-  class(out) <- c(""effectsize_table"", ""see_effectsize_table"", class(out))
-  attr(out, ""ci"") <- ci
-  attr(out, ""ci_method"") <- ci_method
-  attr(out, ""approximate"") <- FALSE
-  attr(out, ""alternative"") <- alternative
-  return(out)
-}
-
-# rank_eta_squared <- function(x, g, data = NULL, ci = 0.95, iterations = 200) {
-#
-#   data <- .get_data_multi_group(x, g, data)
-#   data <- stats::na.omit(data)
-#   x <- data$x
-#   g <- data$g
-#
-#   model <- stats::kruskal.test(x, g)
-#
-#   H <- unname(model$statistic)
-#   k <- length(unique(g)) # model$parameter + 1
-#   n <- length(g)
-#
-#   E <- (H - k + 1) / (n - k)
-#
-#   out <- data.frame(rank_eta_squared = E)
-#
-#   if (is.numeric(ci)) {
-#     warning(""Nope. Not yet."", call. = FALSE)
-#     out$CI <- ci
-#     out$CI_low <- 0
-#     out$CI_high <- 1
-#   }
-#
-#   class(out) <- c(""effectsize_table"", class(out))
-#   return(out)
-# }
-
-
-# Utils -------------------------------------------------------------------
-
-## Get ----
-
-#' @keywords internal
-#' @importFrom stats na.omit
-.r_rbs <- function(x, y, mu, paired, verbose = FALSE) {
-  if (paired) {
-    Ry <- .safe_ranktransform((x - y) - mu, sign = TRUE, verbose = verbose)
-    Ry <- stats::na.omit(Ry)
-
-    n <- length(Ry)
-    S <- (n * (n + 1) / 2)
-
-    U1 <- sum(Ry[Ry > 0], na.rm = TRUE)
-    U2 <- -sum(Ry[Ry < 0], na.rm = TRUE)
-  } else {
-    Ry <- .safe_ranktransform(c(x - mu, y), verbose = verbose)
-
-    n1 <- length(x)
-    n2 <- length(y)
-    S <- (n1 * n2)
-
-    U1 <- sum(Ry[seq_along(x)]) - n1 * (n1 + 1) / 2
-    U2 <- sum(Ry[-seq_along(x)]) - n2 * (n2 + 1) / 2
-  }
-
-  u_ <- U1 / S
-  f_ <- U2 / S
-  return(u_ - f_)
-}
-
-#' @keywords internal
-#' @importFrom stats kruskal.test
-.repsilon <- function(data) {
-  model <- stats::kruskal.test(data$x, data$groups)
-
-  H <- unname(model$statistic)
-  n <- nrow(data)
-
-  E <- H / ((n^2 - 1) / (n + 1))
-}
-
-
-#' @keywords internal
-.kendalls_w <- function(data, verbose) {
-  rankings <- apply(data, 1, .safe_ranktransform, verbose = verbose)
-  rankings <- t(rankings) # keep dims
-
-  n <- ncol(rankings) # items
-  m <- nrow(rankings) # judges
-  R <- colSums(rankings)
-
-  no_ties <- apply(rankings, 1, function(x) length(x) == insight::n_unique(x))
-  if (!all(no_ties)) {
-    if (verbose) {
-      warning(
-        sprintf(
-          ""%d block(s) contain ties%s."",
-          sum(!no_ties),
-          ifelse(any(apply(as.data.frame(rankings)[!no_ties, ], 1, insight::n_unique) == 1),
-            "", some containing only 1 unique ranking"", """"
-          )
-        ),
-        call. = FALSE
-      )
-    }
-
-    Tj <- 0
-    for (i in seq_len(m)) {
-      rater <- table(rankings[i, ])
-      ties <- rater[rater > 1]
-      l <- as.numeric(ties)
-      Tj <- Tj + sum(l^3 - l)
-    }
-
-    W <- (12 * sum(R^2) - 3 * (m^2) * n * ((n + 1)^2)) /
-      (m^2 * (n^3 - n) - m * Tj)
-  } else {
-    S <- var(R) * (n - 1)
-    W <- (12 * S) /
-      (m^2 * (n^3 - n))
-  }
-  W
-}
-
-## CI ----
-
-# #' @keywords internal
-# #' @importFrom bayestestR ci
-# .rbs_ci_boot <- function(x,
-#                          y,
-#                          mu = 0,
-#                          paired = FALSE,
-#                          ci = 0.95,
-#                          iterations = 200) {
-#   stopifnot(length(ci) == 1, ci < 1, ci > 0)
-#
-#   if (paired) {
-#     data <- data.frame(x, y)
-#     boot_rbs <- function(.data, .i) {
-#       .data <- .data[.i, ]
-#       .x <- .data$x
-#       .y <- .data$y
-#       .r_rbs(.x, .y, mu = mu, paired = TRUE, verbose = FALSE)
-#     }
-#   } else {
-#     data <- data.frame(
-#       i = seq_along(c(x, y))
-#     )
-#
-#     boot_rbs <- function(.data, .i) {
-#       .x <- sample(x, replace = TRUE)
-#       .y <- sample(y, replace = TRUE)
-#
-#       .r_rbs(.x, .y, mu = mu, paired = FALSE, verbose = FALSE)
-#     }
-#   }
-#
-#   R <- boot::boot(
-#     data = data,
-#     statistic = boot_rbs,
-#     R = iterations
-#   )
-#
-#   out <- as.data.frame(
-#     bayestestR::ci(na.omit(R$t), ci = ci, verbose = FALSE)
-#   )
-#   out$CI <- ci
-#   out
-# }
-
-#' @importFrom utils tail
-#' @keywords internal
-.repsilon_ci <- function(data, ci, alternative, iterations) {
-  stopifnot(length(ci) == 1, ci < 1, ci > 0)
-  ci.level <- if (alternative == ""two.sided"") ci else 2 * ci - 1
-
-
-  boot_r_epsilon <- function(.data, .i) {
-    split(.data$x, .data$groups) <- lapply(split(.data$x, .data$groups),
-      sample,
-      replace = TRUE
-    )
-    .repsilon(.data)
-  }
-
-  R <- boot::boot(
-    data = data,
-    statistic = boot_r_epsilon,
-    R = iterations
-  )
-
-  bCI <- boot::boot.ci(R, conf = ci.level, type = ""perc"")$percent
-  bCI <- tail(as.vector(bCI), 2)
-
-  data.frame(
-    CI = ci,
-    CI_low = if (alternative == ""less"") 0 else bCI[1],
-    CI_high = if (alternative == ""greater"") 1 else bCI[2]
-  )
-}
-
-#' @importFrom utils tail
-#' @keywords internal
-.kendalls_w_ci <- function(data, ci, alternative, iterations) {
-  stopifnot(length(ci) == 1, ci < 1, ci > 0)
-  ci.level <- if (alternative == ""two.sided"") ci else 2 * ci - 1
-
-  boot_w <- function(.data, .i) {
-    .kendalls_w(.data[.i, ], verbose = FALSE) # sample rows
-  }
-
-  R <- boot::boot(
-    data = data,
-    statistic = boot_w,
-    R = iterations
-  )
-
-  bCI <- boot::boot.ci(R, conf = ci.level, type = ""perc"")$percent
-  bCI <- tail(as.vector(bCI), 2)
-
-  data.frame(
-    CI = ci,
-    CI_low = if (alternative == ""less"") 0 else bCI[1],
-    CI_high = if (alternative == ""greater"") 1 else bCI[2]
-  )
-}
-
-
-# Utils -------------------------------------------------------------------
-
-.safe_ranktransform <- function(x, verbose = TRUE, ...) {
-  if (insight::n_unique(x) == 1) {
-    return(rep(mean(seq_along(x)), length(x)))
-  }
-  datawizard::ranktransform(x, method = ""average"", ..., verbose = FALSE)
-}

---FILE: R/utils.R---
@@ -62,3 +62,11 @@
   }
   model
 }
+
+
+.safe_ranktransform <- function(x, verbose = TRUE, ...) {
+  if (insight::n_unique(x) == 1) {
+    return(rep(mean(seq_along(x)), length(x)))
+  }
+  datawizard::ranktransform(x, method = ""average"", ..., verbose = FALSE)
+}

---FILE: R/utils_validate_input_data.R---
@@ -169,15 +169,16 @@
   x
 }
 
-
+#' @keywords internal
+#' @importFrom stats na.pass reformulate
 .get_data_multivariate <- function(x, y, data = data, ...) {
   if (inherits(x, ""formula"")) {
     if (length(x) != 3L || length(x[[3]]) != 1L) {
       stop(""Formula must have the form of 'DV1 + ... + DVk ~ group', with exactly one term on the RHS."", call. = FALSE)
     }
 
-    data <- model.frame(formula = reformulate(as.character(x)[3:2]),
-                        data = data, na.action = na.pass)
+    data <- model.frame(formula = stats::reformulate(as.character(x)[3:2]),
+                        data = data, na.action = stats::na.pass)
 
     if (x[[3]] == 1) {
       # Then it is one sampled

---FILE: R/xtab.R---
@@ -1,623 +0,0 @@
-#' Effect size for contingency tables
-#'
-#' Compute Cramer's *V*, phi (\eqn{\phi}), Cohen's *w*,
-#' \ifelse{latex}{\eqn{Fei}}{×¤ (Fei)}, Pearson's contingency coefficient, Odds
-#' ratios, Risk ratios, Cohen's *h* and Cohen's *g* for contingency tables or
-#' goodness-of-fit. See details.
-#'
-#' @inheritParams stats::chisq.test
-#' @param ci Confidence Interval (CI) level
-#' @param alternative a character string specifying the alternative hypothesis;
-#'   Controls the type of CI returned: `""greater""` (two-sided CI; default for
-#'   Cramer's *V*, phi (\eqn{\phi}), and Cohen's *w*), `""two.sided""` (default
-#'   for OR, RR, Cohen's *h* and Cohen's *g*) or `""less""` (one-sided CI).
-#'   Partial matching is allowed (e.g., `""g""`, `""l""`, `""two""`...). See
-#'   *One-Sided CIs* in [effectsize_CIs].
-#' @param adjust Should the effect size be bias-corrected? Defaults to `FALSE`.
-#' @param ... For goodness-of-fit effect sizes, can pass `rescale.p` (see
-#'   [stats::chisq.test()]). Else, ignored.
-#'
-#' @details
-#'
-#' ## Correlation-like Effect Sizes
-#'
-#' Cramer's *V*, phi (\eqn{\phi}), Cohen's *w*, and Pearson's *C* are effect
-#' sizes for tests of independence in 2D contingency tables. For 2-by-2 tables,
-#' Cramer's *V*, phi and Cohen's *w* are identical, and are equal to the simple
-#' correlation between two dichotomous variables, ranging between  0 (no
-#' dependence) and 1 (perfect dependence). For larger tables, Cramer's *V* or
-#' Pearson's *C* should be used, as they are bounded between 0-1. Cohen's *w*
-#' can also be used, but since it is not bounded at 1 (can be larger) its
-#' interpretation is more difficult.
-#' \cr \cr
-#' For goodness-of-fit in 1D tables Cohen's *W*, \ifelse{latex}{\eqn{Fei}}{×¤ (Fei)}
-#' or Pearson's *C* can be used. Cohen's *w* has no upper bound (can be
-#' arbitrarily large, depending on the expected distribution). *Fei* is an
-#' adjusted Cohen's *w*, accounting for the expected distribution, making it
-#' bounded between 0-1. Pearson's *C* is also bounded between 0-1.
-#' \cr \cr
-#' To summarize, for correlation-like effect sizes, we recommend:
-#'
-#' - For a 2x2 table, use `phi()`
-#' - For larger tables, use `cramers_v()`
-#' - For goodness-of-fit, use `fei()`
-#'
-#' ## Other Effect Sizes for 2-by-2 xtabs
-#'
-#' For 2-by-2 contingency tables, Odds ratios, Risk ratios and Cohen's *h* can
-#' also be estimated. Note that these are computed with each **column**
-#' representing the different groups, and the *first* column representing the
-#' treatment group and the *second* column baseline (or control). Effects are
-#' given as `treatment / control`. If you wish you use rows as groups you must
-#' pass a transposed table, or switch the `x` and `y` arguments.
-#'
-#' ## Effect Sizes for Paired xtabs
-#'
-#' Cohen's *g* is an effect size of asymmetry (or marginal heterogeneity) for
-#' dependent (paired) contingency tables ranging between 0 (perfect symmetry)
-#' and 0.5 (perfect asymmetry) (see [stats::mcnemar.test()]). (Note this is not
-#' *not* a measure of (dis)agreement between the pairs, but of (a)symmetry.)
-#'
-#' # Confidence Intervals for Cohen's g, OR, RR and Cohen's h
-#' For Cohen's *g*, confidence intervals are based on the proportion (\eqn{P = g
-#' + 0.5}) confidence intervals returned by [stats::prop.test()] (minus 0.5),
-#' which give a good close approximation.
-#' \cr \cr
-#' For Odds ratios, Risk ratios and Cohen's *h*, confidence intervals are
-#' estimated using the standard normal parametric method (see Katz et al., 1978;
-#' Szumilas, 2010).
-#' \cr \cr
-#' See *Confidence (Compatibility) Intervals (CIs)*, *CIs and Significance Tests*,
-#' and *One-Sided CIs* sections for *phi*, Cohen's *w*, Cramer's *V*,
-#' Pearson's *C*, and *Fei*.
-#'
-#' @inheritSection effectsize_CIs Confidence (Compatibility) Intervals (CIs)
-#' @inheritSection effectsize_CIs CIs and Significance Tests
-#'
-#' @return A data frame with the effect size (`Cramers_v`, `phi` (possibly with
-#'   the suffix `_adjusted`), `Cohens_w`, `Fei`, `Odds_ratio`, `Risk_ratio`
-#'   (possibly with the prefix `log_`), `Cohens_h`, or `Cohens_g`) and its CIs
-#'   (`CI_low` and `CI_high`).
-#'
-#' @seealso [chisq_to_phi()] for details regarding estimation and CIs.
-#' @family effect size indices
-#'
-#' @examples
-#'
-#' ## 2-by-2 tables
-#' ## -------------
-#' RCT <-
-#'   matrix(
-#'     c(
-#'       71, 30,
-#'       50, 100
-#'     ),
-#'     nrow = 2, byrow = TRUE,
-#'     dimnames = list(
-#'       Diagnosis = c(""Sick"", ""Recovered""),
-#'       Group = c(""Treatment"", ""Control"")
-#'     )
-#'   )
-#' RCT # note groups are COLUMNS
-#'
-#' phi(RCT)
-#' pearsons_c(RCT)
-#'
-#' oddsratio(RCT)
-#' oddsratio(RCT, alternative = ""greater"")
-#'
-#' riskratio(RCT)
-#'
-#' cohens_h(RCT)
-#'
-#' ## Larger tables
-#' ## -------------
-#'
-#' M <-
-#'   matrix(
-#'     c(
-#'       150, 100, 165,
-#'       130, 50, 65,
-#'       35, 10, 2,
-#'       55, 40, 25
-#'     ),
-#'     nrow = 4,
-#'     dimnames = list(
-#'       Music = c(""Pop"", ""Rock"", ""Jazz"", ""Classic""),
-#'       Study = c(""Psych"", ""Econ"", ""Law"")
-#'     )
-#'   )
-#' M
-#'
-#' cohens_w(M)
-#'
-#' cramers_v(M)
-#'
-#' pearsons_c(M)
-#'
-#'
-#' ## Goodness of fit
-#' ## ---------------
-#'
-#' Smoking_ASD <- as.table(c(ASD = 17, ASP = 11, TD = 640))
-#'
-#' fei(Smoking_ASD)
-#'
-#' cohens_w(Smoking_ASD)
-#'
-#' pearsons_c(Smoking_ASD)
-#'
-#' # Use custom expected values:
-#' fei(Smoking_ASD, p = c(0.015, 0.010, 0.975))
-#'
-#' cohens_w(Smoking_ASD, p = c(0.015, 0.010, 0.975))
-#'
-#' pearsons_c(Smoking_ASD, p = c(0.015, 0.010, 0.975))
-#'
-#'
-#'
-#'
-#'
-#' ## Dependent (Paired) Contingency Tables
-#' ## -------------------------------------
-#' #
-#' Performance <-
-#'   matrix(
-#'     c(
-#'       794, 150,
-#'       86, 570
-#'     ),
-#'     nrow = 2,
-#'     dimnames = list(
-#'       ""1st Survey"" = c(""Approve"", ""Disapprove""),
-#'       ""2nd Survey"" = c(""Approve"", ""Disapprove"")
-#'     )
-#'   )
-#' Performance
-#'
-#' cohens_g(Performance)
-#'
-#' @references
-#' - Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
-#' - Katz, D. J. S. M., Baptista, J., Azen, S. P., & Pike, M. C. (1978). Obtaining confidence intervals for the risk ratio in cohort studies. Biometrics, 469-474.
-#' - Szumilas, M. (2010). Explaining odds ratios. Journal of the Canadian academy of child and adolescent psychiatry, 19(3), 227.
-#' - Johnston, J. E., Berry, K. J., & Mielke Jr, P. W. (2006). Measures of
-#' effect size for chi-squared and likelihood-ratio goodness-of-fit tests.
-#' Perceptual and motor skills, 103(2), 412-414.
-#' - Rosenberg, M. S. (2010). A generalized formula for converting chi-square
-#' tests to effect sizes for meta-analysis. PloS one, 5(4), e10059.
-#' @importFrom stats chisq.test
-#' @export
-phi <- function(x, y = NULL, ci = 0.95, alternative = ""greater"", adjust = FALSE, ...) {
-  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
-
-  if (inherits(x, ""BFBayesFactor"")) {
-    if (!inherits(x@numerator[[1]], ""BFcontingencyTable"")) {
-      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
-    }
-    return(effectsize(x, type = ""phi"", adjust = adjust, ci = ci, ...))
-  }
-
-
-  if (inherits(x, ""htest"")) {
-    if (!(grepl(""Pearson's Chi-squared"", x$method) ||
-      grepl(""Chi-squared test for given probabilities"", x$method))) {
-      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
-    }
-  } else {
-    x <- suppressWarnings(stats::chisq.test(x, y))
-    x$data.name <- NULL
-  }
-
-  effectsize(x, type = ""phi"", adjust = adjust, ci = ci, alternative = alternative)
-}
-
-#' @rdname phi
-#' @importFrom stats chisq.test
-#' @export
-cramers_v <- function(x, y = NULL, ci = 0.95, alternative = ""greater"", adjust = FALSE, ...) {
-  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
-
-  if (inherits(x, ""BFBayesFactor"")) {
-    if (!inherits(x@numerator[[1]], ""BFcontingencyTable"")) {
-      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
-    }
-    return(effectsize(x, type = ""cramers_v"", adjust = adjust, ci = ci, ...))
-  }
-
-
-  if (inherits(x, ""htest"")) {
-    if (!(grepl(""Pearson's Chi-squared"", x$method) ||
-          grepl(""Chi-squared test for given probabilities"", x$method))) {
-      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
-    }
-  } else {
-    x <- suppressWarnings(stats::chisq.test(x, y))
-    x$data.name <- NULL
-  }
-
-  effectsize(x, type = ""cramers_v"", adjust = adjust, ci = ci, alternative = alternative)
-}
-
-#' @rdname phi
-#' @importFrom stats chisq.test
-#' @export
-cohens_w <- function(x, y = NULL, p = rep(1/length(x), length(x)),
-                     ci = 0.95, alternative = ""greater"", ...) {
-  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
-
-  if (inherits(x, ""BFBayesFactor"")) {
-    if (!inherits(x@numerator[[1]], ""BFcontingencyTable"")) {
-      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
-    }
-    return(effectsize(x, type = ""phi"", ci = ci, ...))
-  }
-
-
-  if (inherits(x, ""htest"")) {
-    if (!(grepl(""Pearson's Chi-squared"", x$method) ||
-      grepl(""Chi-squared test for given probabilities"", x$method))) {
-      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
-    }
-  } else {
-    x <- suppressWarnings(stats::chisq.test(x, y, p = p, ...))
-    x$data.name <- NULL
-  }
-
-  effectsize(x, type = ""cohens_w"", ci = ci, alternative = alternative)
-}
-
-
-#' @rdname phi
-#' @importFrom stats chisq.test
-#' @export
-fei <- function(x, p = rep(1/length(x), length(x)), ci = 0.95, alternative = ""greater"", ...) {
-  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
-
-  if (inherits(x, ""BFBayesFactor"")) {
-    stop(""Fei is only applicable to goodness of fit tests."", call. = FALSE)
-  }
-
-
-  if (inherits(x, ""htest"")) {
-    if (!(grepl(""Pearson's Chi-squared"", x$method) ||
-      grepl(""Chi-squared test for given probabilities"", x$method))) {
-      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
-    }
-  } else {
-    x <- suppressWarnings(stats::chisq.test(x, y = NULL, p = p, ...))
-    x$data.name <- NULL
-  }
-
-  effectsize(x, type = ""fei"", ci = ci, alternative = alternative)
-}
-
-#' @rdname phi
-#' @importFrom stats chisq.test
-#' @export
-pearsons_c <- function(x, y = NULL, p = rep(1/length(x), length(x)),
-                     ci = 0.95, alternative = ""greater"", ...) {
-  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
-
-  if (inherits(x, ""BFBayesFactor"")) {
-    if (!inherits(x@numerator[[1]], ""BFcontingencyTable"")) {
-      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
-    }
-    return(effectsize(x, type = ""pearsons_c"", ci = ci, ...))
-  }
-
-
-  if (inherits(x, ""htest"")) {
-    if (!(grepl(""Pearson's Chi-squared"", x$method) ||
-      grepl(""Chi-squared test for given probabilities"", x$method))) {
-      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
-    }
-  } else {
-    x <- suppressWarnings(stats::chisq.test(x, y, p = p, ...))
-    x$data.name <- NULL
-  }
-
-  effectsize(x, type = ""pearsons_c"", ci = ci, alternative = alternative)
-}
-
-
-#' @rdname phi
-#' @inheritParams oddsratio_to_d
-#' @export
-#' @importFrom stats chisq.test qnorm
-oddsratio <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = FALSE, ...) {
-  alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
-
-  if (inherits(x, ""htest"")) {
-    if (grepl(""Pearson's Chi-squared"", x$method) ||
-      grepl(""Chi-squared test for given probabilities"", x$method)) {
-      return(effectsize(x, type = ""or"", log = log, ci = ci, alternative = alternative))
-    } else if (grepl(""Fisher's Exact"", x$method)) {
-      return(effectsize(x, alternative = alternative, ...))
-    } else {
-      stop(""'x' is not a Chi-squared / Fisher's Exact test!"", call. = FALSE)
-    }
-  } else if (inherits(x, ""BFBayesFactor"")) {
-    if (!inherits(x@numerator[[1]], ""BFcontingencyTable"")) {
-      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
-    }
-    return(effectsize(x, type = ""or"", log = log, ci = ci, ...))
-  }
-
-  res <- suppressWarnings(stats::chisq.test(x, y))
-  Obs <- res$observed
-
-  if (any(c(colSums(Obs), rowSums(Obs)) == 0L)) {
-    stop(""Cannot have empty rows/columns in the contingency tables."", call. = FALSE)
-  }
-
-  if (nrow(Obs) != 2 || ncol(Obs) != 2) {
-    stop(""Odds ratio only available for 2-by-2 contingency tables"", call. = FALSE)
-  }
-
-  OR <- (Obs[1, 1] / Obs[2, 1]) /
-    (Obs[1, 2] / Obs[2, 2])
-
-  res <- data.frame(Odds_ratio = OR)
-
-  ci_method <- NULL
-  if (is.numeric(ci)) {
-    stopifnot(length(ci) == 1, ci < 1, ci > 0)
-    res$CI <- ci
-    ci.level <- if (alternative == ""two.sided"") ci else 2 * ci - 1
-
-    alpha <- 1 - ci.level
-
-    SE_logodds <- sqrt(sum(1 / Obs))
-    Z_logodds <- stats::qnorm(alpha / 2, lower.tail = FALSE)
-    confs <- exp(log(OR) + c(-1, 1) * SE_logodds * Z_logodds)
-
-    res$CI_low <- confs[1]
-    res$CI_high <- confs[2]
-
-    ci_method <- list(method = ""normal"")
-    if (alternative == ""less"") {
-      res$CI_low <- 0
-    } else if (alternative == ""greater"") {
-      res$CI_high <- Inf
-    }
-  } else {
-    alternative <- NULL
-  }
-
-  if (log) {
-    res[colnames(res) %in% c(""Odds_ratio"", ""CI_low"", ""CI_high"")] <-
-      log(res[colnames(res) %in% c(""Odds_ratio"", ""CI_low"", ""CI_high"")])
-    colnames(res)[1] <- ""log_Odds_ratio""
-  }
-
-  class(res) <- c(""effectsize_table"", ""see_effectsize_table"", class(res))
-  attr(res, ""ci"") <- ci
-  attr(res, ""ci_method"") <- ci_method
-  attr(res, ""log"") <- log
-  attr(res, ""approximate"") <- FALSE
-  attr(res, ""alternative"") <- alternative
-  return(res)
-}
-
-#' @rdname phi
-#' @inheritParams oddsratio_to_d
-#' @export
-#' @importFrom stats chisq.test qnorm
-riskratio <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = FALSE, ...) {
-  alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
-
-  if (inherits(x, ""htest"")) {
-    if (!(grepl(""Pearson's Chi-squared"", x$method) ||
-      grepl(""Chi-squared test for given probabilities"", x$method))) {
-      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
-    }
-    return(effectsize(x, type = ""rr"", log = log, ci = ci, alternative = alternative))
-  } else if (inherits(x, ""BFBayesFactor"")) {
-    if (!inherits(x@numerator[[1]], ""BFcontingencyTable"")) {
-      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
-    }
-    return(effectsize(x, type = ""rr"", log = log, ci = ci, ...))
-  }
-
-  res <- suppressWarnings(stats::chisq.test(x, y))
-  Obs <- res$observed
-
-  if (any(c(colSums(Obs), rowSums(Obs)) == 0L)) {
-    stop(""Cannot have empty rows/columns in the contingency tables."", call. = FALSE)
-  }
-
-  if (nrow(Obs) != 2 || ncol(Obs) != 2) {
-    stop(""Risk ratio only available for 2-by-2 contingency tables"", call. = FALSE)
-  }
-
-  n1 <- sum(Obs[, 1])
-  n2 <- sum(Obs[, 2])
-  p1 <- Obs[1, 1] / n1
-  p2 <- Obs[1, 2] / n2
-  RR <- p1 / p2
-
-  res <- data.frame(Risk_ratio = RR)
-
-  ci_method <- NULL
-  if (is.numeric(ci)) {
-    stopifnot(length(ci) == 1, ci < 1, ci > 0)
-    res$CI <- ci
-    ci.level <- if (alternative == ""two.sided"") ci else 2 * ci - 1
-
-    alpha <- 1 - ci.level
-
-    SE_logRR <- sqrt(p1 / ((1 - p1) * n1)) + sqrt(p2 / ((1 - p2) * n2))
-    Z_logRR <- stats::qnorm(alpha / 2, lower.tail = FALSE)
-    confs <- exp(log(RR) + c(-1, 1) * SE_logRR * Z_logRR)
-
-    res$CI_low <- confs[1]
-    res$CI_high <- confs[2]
-
-    ci_method <- list(method = ""normal"")
-    if (alternative == ""less"") {
-      res$CI_low <- 0
-    } else if (alternative == ""greater"") {
-      res$CI_high <- Inf
-    }
-  } else {
-    alternative <- NULL
-  }
-
-  if (log) {
-    res[colnames(res) %in% c(""Risk_ratio"", ""CI_low"", ""CI_high"")] <-
-      log(res[colnames(res) %in% c(""Risk_ratio"", ""CI_low"", ""CI_high"")])
-    colnames(res)[1] <- ""log_Risk_ratio""
-  }
-
-  class(res) <- c(""effectsize_table"", ""see_effectsize_table"", class(res))
-  attr(res, ""ci"") <- ci
-  attr(res, ""ci_method"") <- ci_method
-  attr(res, ""log"") <- log
-  attr(res, ""approximate"") <- FALSE
-  attr(res, ""alternative"") <- alternative
-  return(res)
-}
-
-#' @rdname phi
-#' @export
-#' @importFrom stats qnorm
-cohens_h <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...) {
-  alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
-
-  if (inherits(x, ""htest"")) {
-    if (!(grepl(""Pearson's Chi-squared"", x$method) ||
-      grepl(""Chi-squared test for given probabilities"", x$method))) {
-      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
-    }
-    return(effectsize(x, type = ""cohens_h"", ci = ci, alternative = alternative))
-  } else if (inherits(x, ""BFBayesFactor"")) {
-    if (!inherits(x@numerator[[1]], ""BFcontingencyTable"")) {
-      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
-    }
-    return(effectsize(x, type = ""cohens_h"", ci = ci, ...))
-  }
-
-  res <- suppressWarnings(stats::chisq.test(x, y))
-  Obs <- res$observed
-
-  if (any(c(colSums(Obs), rowSums(Obs)) == 0L)) {
-    stop(""Cannot have empty rows/columns in the contingency tables."", call. = FALSE)
-  }
-
-  if (nrow(Obs) != 2 || ncol(Obs) != 2) {
-    stop(""Cohen's h only available for 2-by-2 contingency tables"", call. = FALSE)
-  }
-
-  n1 <- sum(Obs[, 1])
-  n2 <- sum(Obs[, 2])
-  p1 <- Obs[1, 1] / n1
-  p2 <- Obs[1, 2] / n2
-  H <- 2 * asin(sqrt(p1)) - 2 * asin(sqrt(p2))
-
-  out <- data.frame(Cohens_h = H)
-
-  ci_method <- NULL
-  if (is.numeric(ci)) {
-    stopifnot(length(ci) == 1, ci < 1, ci > 0)
-    out$CI <- ci
-    ci.level <- if (alternative == ""two.sided"") ci else 2 * ci - 1
-
-    alpha <- 1 - ci.level
-
-    se_arcsin <- sqrt(0.25 * (1 / n1 + 1 / n2))
-    Zc <- stats::qnorm(alpha / 2, lower.tail = FALSE)
-    out$CI_low <- H - Zc * (2 * se_arcsin)
-    out$CI_high <- H + Zc * (2 * se_arcsin)
-
-    ci_method <- list(method = ""normal"")
-    if (alternative == ""less"") {
-      out$CI_low <- -pi
-    } else if (alternative == ""greater"") {
-      out$CI_high <- pi
-    }
-  } else {
-    alternative <- NULL
-  }
-
-  class(out) <- c(""effectsize_table"", ""see_effectsize_table"", class(out))
-  attr(out, ""ci"") <- ci
-  attr(out, ""ci_method"") <- ci_method
-  attr(out, ""approximate"") <- FALSE
-  attr(out, ""alternative"") <- alternative
-  return(out)
-}
-
-
-#' @rdname phi
-#' @export
-#' @importFrom stats complete.cases prop.test
-cohens_g <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...) {
-  alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
-
-  if (inherits(x, ""htest"")) {
-    if (!grepl(""McNemar"", x$method)) {
-      stop(""'x' is not a McNemar test!"", call. = FALSE)
-    }
-    return(effectsize(x, ci = ci, alternative = alternative))
-  }
-
-
-  if (!is.matrix(x)) {
-    if (is.null(y)) {
-      stop(""if 'x' is not a matrix, 'y' must be given"", call. = FALSE)
-    }
-    if (length(x) != length(y)) {
-      stop(""'x' and 'y' must have the same length"", call. = FALSE)
-    }
-    OK <- stats::complete.cases(x, y)
-    x <- as.factor(x[OK])
-    y <- as.factor(y[OK])
-    if ((nlevels(x) < 2) || (nlevels(y) != nlevels(x))) {
-      stop(""'x' and 'y' must have the same number of levels (minimum 2)"", call. = FALSE)
-    }
-    x <- table(x, y)
-  } else {
-    if ((nrow(x) < 2) || (ncol(x) != nrow(x))) {
-      stop(""'x' must be square with at least two rows and columns"", call. = FALSE)
-    }
-  }
-
-
-  b <- x[upper.tri(x)]
-  c <- t(x)[upper.tri(x)]
-
-  P <- sum(pmax(b, c)) / (sum(b) + sum(c))
-  g <- P - 0.5
-
-  out <- data.frame(Cohens_g = g)
-
-  ci_method <- NULL
-  if (is.numeric(ci)) {
-    stopifnot(length(ci) == 1, ci < 1, ci > 0)
-    out$CI <- ci
-
-    n <- sum(b) + sum(c)
-    k <- P * n
-
-    res <- stats::prop.test(k, n,
-      p = 0.5,
-      alternative = alternative,
-      conf.level = ci,
-      correct = FALSE
-    )
-
-    out$CI <- ci
-    out$CI_low <- res$conf.int[1] - 0.5
-    out$CI_high <- res$conf.int[2] - 0.5
-
-    ci_method <- list(method = ""binomial"")
-  }
-
-  class(out) <- c(""effectsize_table"", ""see_effectsize_table"", class(out))
-  attr(out, ""ci"") <- ci
-  attr(out, ""ci_method"") <- ci_method
-  attr(out, ""approximate"") <- FALSE
-  attr(out, ""alternative"") <- alternative
-  return(out)
-}

---FILE: R/xtab_corr.R---
@@ -0,0 +1,244 @@
+#' Correlation effect size for contingency tables
+#'
+#' Compute Cramer's *V*, phi (\eqn{\phi}), Cohen's *w*,
+#' \ifelse{latex}{\eqn{Fei}}{×¤ (Fei)}, Pearson's contingency coefficient for
+#' contingency tables or goodness-of-fit. See details.
+#'
+#' @inheritParams stats::chisq.test
+#' @param ci Confidence Interval (CI) level
+#' @param alternative a character string specifying the alternative hypothesis;
+#'   Controls the type of CI returned: `""greater""` (one-sided CI; default),
+#'   `""two.sided""` (two-sided CI) or `""less""` (one-sided CI). Partial matching
+#'   is allowed (e.g., `""g""`, `""l""`, `""two""`...). See *One-Sided CIs* in
+#'   [effectsize_CIs].
+#' @param adjust Should the effect size be bias-corrected? Defaults to `FALSE`.
+#' @param ... For goodness-of-fit effect sizes, can pass `rescale.p` (see
+#'   [stats::chisq.test()]). Else, ignored.
+#'
+#' @details
+#'
+#' Cramer's *V*, phi (\eqn{\phi}), Cohen's *w*, and Pearson's *C* are effect
+#' sizes for tests of independence in 2D contingency tables. For 2-by-2 tables,
+#' Cramer's *V*, phi and Cohen's *w* are identical, and are equal to the simple
+#' correlation between two dichotomous variables, ranging between  0 (no
+#' dependence) and 1 (perfect dependence). For larger tables, Cramer's *V* or
+#' Pearson's *C* should be used, as they are bounded between 0-1. Cohen's *w*
+#' can also be used, but since it is not bounded at 1 (can be larger) its
+#' interpretation is more difficult.
+#' \cr \cr
+#' For goodness-of-fit in 1D tables Cohen's *W*, \ifelse{latex}{\eqn{Fei}}{×¤ (Fei)}
+#' or Pearson's *C* can be used. Cohen's *w* has no upper bound (can be
+#' arbitrarily large, depending on the expected distribution). *Fei* is an
+#' adjusted Cohen's *w*, accounting for the expected distribution, making it
+#' bounded between 0-1. Pearson's *C* is also bounded between 0-1.
+#' \cr \cr
+#' To summarize, for correlation-like effect sizes, we recommend:
+#'
+#' - For a 2x2 table, use `phi()`
+#' - For larger tables, use `cramers_v()`
+#' - For goodness-of-fit, use `fei()`
+#'
+#' @inheritSection effectsize_CIs Confidence (Compatibility) Intervals (CIs)
+#' @inheritSection effectsize_CIs CIs and Significance Tests
+#'
+#' @return A data frame with the effect size (`Cramers_v`, `phi` (possibly with
+#'   the suffix `_adjusted`), `Cohens_w`, `Fei`) and its CIs (`CI_low` and
+#'   `CI_high`).
+#'
+#' @seealso [chisq_to_phi()] for details regarding estimation and CIs.
+#' @family effect size indices
+#'
+#' @examples
+#'
+#' ## 2-by-2 tables
+#' ## -------------
+#' RCT <- matrix(c(71, 50,
+#'                 30, 100), nrow = 2)
+#' dimnames(RCT) <- list(Diagnosis = c(""Sick"", ""Recovered""),
+#'                       Group = c(""Treatment"", ""Control""))
+#' RCT # note groups are COLUMNS
+#'
+#' phi(RCT)
+#' pearsons_c(RCT)
+#'
+#'
+#'
+#' ## Larger tables
+#' ## -------------
+#' M <- matrix(c(150, 100, 165,
+#'               130, 50, 65,
+#'               35, 10, 2,
+#'               55, 40, 25), nrow = 4)
+#' dimnames(M) <- list(Music = c(""Pop"", ""Rock"", ""Jazz"", ""Classic""),
+#'                     Study = c(""Psych"", ""Econ"", ""Law""))
+#' M
+#'
+#' cramers_v(M)
+#'
+#' cohens_w(M)
+#'
+#' pearsons_c(M)
+#'
+#'
+#'
+#' ## Goodness of fit
+#' ## ---------------
+#' Smoking_ASD <- as.table(c(ASD = 17, ASP = 11, TD = 640))
+#'
+#' fei(Smoking_ASD)
+#'
+#' cohens_w(Smoking_ASD)
+#'
+#' pearsons_c(Smoking_ASD)
+#'
+#' # Use custom expected values:
+#' fei(Smoking_ASD, p = c(0.015, 0.010, 0.975))
+#'
+#' cohens_w(Smoking_ASD, p = c(0.015, 0.010, 0.975))
+#'
+#' pearsons_c(Smoking_ASD, p = c(0.015, 0.010, 0.975))
+#'
+#'
+#' @references
+#' - Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
+#' - Johnston, J. E., Berry, K. J., & Mielke Jr, P. W. (2006). Measures of
+#' effect size for chi-squared and likelihood-ratio goodness-of-fit tests.
+#' Perceptual and motor skills, 103(2), 412-414.
+#' - Rosenberg, M. S. (2010). A generalized formula for converting chi-square
+#' tests to effect sizes for meta-analysis. PloS one, 5(4), e10059.
+#'
+#'
+#' @importFrom stats chisq.test
+#' @export
+phi <- function(x, y = NULL, ci = 0.95, alternative = ""greater"", adjust = FALSE, ...) {
+  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
+
+  if (inherits(x, ""BFBayesFactor"")) {
+    if (!inherits(x@numerator[[1]], ""BFcontingencyTable"")) {
+      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
+    }
+    return(effectsize(x, type = ""phi"", adjust = adjust, ci = ci, ...))
+  }
+
+
+  if (inherits(x, ""htest"")) {
+    if (!(grepl(""Pearson's Chi-squared"", x$method) ||
+      grepl(""Chi-squared test for given probabilities"", x$method))) {
+      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
+    }
+  } else {
+    x <- suppressWarnings(stats::chisq.test(x, y))
+    x$data.name <- NULL
+  }
+
+  effectsize(x, type = ""phi"", adjust = adjust, ci = ci, alternative = alternative)
+}
+
+#' @rdname phi
+#' @importFrom stats chisq.test
+#' @export
+cramers_v <- function(x, y = NULL, ci = 0.95, alternative = ""greater"", adjust = FALSE, ...) {
+  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
+
+  if (inherits(x, ""BFBayesFactor"")) {
+    if (!inherits(x@numerator[[1]], ""BFcontingencyTable"")) {
+      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
+    }
+    return(effectsize(x, type = ""cramers_v"", adjust = adjust, ci = ci, ...))
+  }
+
+
+  if (inherits(x, ""htest"")) {
+    if (!(grepl(""Pearson's Chi-squared"", x$method) ||
+          grepl(""Chi-squared test for given probabilities"", x$method))) {
+      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
+    }
+  } else {
+    x <- suppressWarnings(stats::chisq.test(x, y))
+    x$data.name <- NULL
+  }
+
+  effectsize(x, type = ""cramers_v"", adjust = adjust, ci = ci, alternative = alternative)
+}
+
+#' @rdname phi
+#' @importFrom stats chisq.test
+#' @export
+cohens_w <- function(x, y = NULL, p = rep(1/length(x), length(x)),
+                     ci = 0.95, alternative = ""greater"", ...) {
+  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
+
+  if (inherits(x, ""BFBayesFactor"")) {
+    if (!inherits(x@numerator[[1]], ""BFcontingencyTable"")) {
+      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
+    }
+    return(effectsize(x, type = ""phi"", ci = ci, ...))
+  }
+
+
+  if (inherits(x, ""htest"")) {
+    if (!(grepl(""Pearson's Chi-squared"", x$method) ||
+      grepl(""Chi-squared test for given probabilities"", x$method))) {
+      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
+    }
+  } else {
+    x <- suppressWarnings(stats::chisq.test(x, y, p = p, ...))
+    x$data.name <- NULL
+  }
+
+  effectsize(x, type = ""cohens_w"", ci = ci, alternative = alternative)
+}
+
+
+#' @rdname phi
+#' @importFrom stats chisq.test
+#' @export
+fei <- function(x, p = rep(1/length(x), length(x)), ci = 0.95, alternative = ""greater"", ...) {
+  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
+
+  if (inherits(x, ""BFBayesFactor"")) {
+    stop(""Fei is only applicable to goodness of fit tests."", call. = FALSE)
+  }
+
+
+  if (inherits(x, ""htest"")) {
+    if (!(grepl(""Pearson's Chi-squared"", x$method) ||
+      grepl(""Chi-squared test for given probabilities"", x$method))) {
+      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
+    }
+  } else {
+    x <- suppressWarnings(stats::chisq.test(x, y = NULL, p = p, ...))
+    x$data.name <- NULL
+  }
+
+  effectsize(x, type = ""fei"", ci = ci, alternative = alternative)
+}
+
+#' @rdname phi
+#' @importFrom stats chisq.test
+#' @export
+pearsons_c <- function(x, y = NULL, p = rep(1/length(x), length(x)),
+                     ci = 0.95, alternative = ""greater"", ...) {
+  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
+
+  if (inherits(x, ""BFBayesFactor"")) {
+    if (!inherits(x@numerator[[1]], ""BFcontingencyTable"")) {
+      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
+    }
+    return(effectsize(x, type = ""pearsons_c"", ci = ci, ...))
+  }
+
+
+  if (inherits(x, ""htest"")) {
+    if (!(grepl(""Pearson's Chi-squared"", x$method) ||
+      grepl(""Chi-squared test for given probabilities"", x$method))) {
+      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
+    }
+  } else {
+    x <- suppressWarnings(stats::chisq.test(x, y, p = p, ...))
+    x$data.name <- NULL
+  }
+
+  effectsize(x, type = ""pearsons_c"", ci = ci, alternative = alternative)
+}
+

---FILE: R/xtab_diff.R---
@@ -0,0 +1,279 @@
+#' Odds ratios, Risk ratios, Cohen's *h* for 2-by-2 contingency tables
+#'
+#' Note that these are computed with each **column** representing the different
+#' groups, and the *first* column representing the treatment group and the
+#' *second* column baseline (or control). Effects are given as `treatment /
+#' control`. If you wish you use rows as groups you must pass a transposed
+#' table, or switch the `x` and `y` arguments.
+#'
+#'
+#' @inheritParams oddsratio_to_d
+#' @inheritParams phi
+#' @param alternative a character string specifying the alternative hypothesis;
+#'   Controls the type of CI returned: `""two.sided""` (two-sided CI; default),
+#'   `""greater""` (one-sided CI) or `""less""` (one-sided CI). Partial matching is
+#'   allowed (e.g., `""g""`, `""l""`, `""two""`...). See *One-Sided CIs* in
+#'   [effectsize_CIs].
+#' @param ... Ignored
+#'
+#' @details
+#'
+#' # Confidence Intervals for OR, RR and Cohen's *h*
+#' For Odds ratios, Risk ratios and Cohen's *h*, confidence intervals are
+#' estimated using the standard normal parametric method (see Katz et al., 1978;
+#' Szumilas, 2010).
+#'
+#' @inheritSection effectsize_CIs CIs and Significance Tests
+#'
+#' @return A data frame with the effect size (`Odds_ratio`, `Risk_ratio`
+#'   (possibly with the prefix `log_`), `Cohens_h`) and its CIs (`CI_low` and
+#'   `CI_high`).
+#'
+#' @seealso [phi()] and friends for other effect sizes for contingency tables.
+#' @family effect size indices
+#'
+#'
+#' @references
+#' - Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
+#' - Katz, D. J. S. M., Baptista, J., Azen, S. P., & Pike, M. C. (1978). Obtaining confidence intervals for the risk ratio in cohort studies. Biometrics, 469-474.
+#' - Szumilas, M. (2010). Explaining odds ratios. Journal of the Canadian academy of child and adolescent psychiatry, 19(3), 227.
+#'
+#' @examples
+#' RCT <- matrix(c(71, 50,
+#'                 30, 100), nrow = 2)
+#' dimnames(RCT) <- list(Diagnosis = c(""Sick"", ""Recovered""),
+#'                       Group = c(""Treatment"", ""Control""))
+#' RCT # note groups are COLUMNS
+#'
+#' oddsratio(RCT)
+#' oddsratio(RCT, alternative = ""greater"")
+#'
+#' riskratio(RCT)
+#'
+#' cohens_h(RCT)
+#'
+#'
+#'
+#' @export
+#' @importFrom stats chisq.test qnorm
+oddsratio <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = FALSE, ...) {
+  alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
+
+  if (inherits(x, ""htest"")) {
+    if (grepl(""Pearson's Chi-squared"", x$method) ||
+        grepl(""Chi-squared test for given probabilities"", x$method)) {
+      return(effectsize(x, type = ""or"", log = log, ci = ci, alternative = alternative))
+    } else if (grepl(""Fisher's Exact"", x$method)) {
+      return(effectsize(x, alternative = alternative, ...))
+    } else {
+      stop(""'x' is not a Chi-squared / Fisher's Exact test!"", call. = FALSE)
+    }
+  } else if (inherits(x, ""BFBayesFactor"")) {
+    if (!inherits(x@numerator[[1]], ""BFcontingencyTable"")) {
+      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
+    }
+    return(effectsize(x, type = ""or"", log = log, ci = ci, ...))
+  }
+
+  res <- suppressWarnings(stats::chisq.test(x, y))
+  Obs <- res$observed
+
+  if (any(c(colSums(Obs), rowSums(Obs)) == 0L)) {
+    stop(""Cannot have empty rows/columns in the contingency tables."", call. = FALSE)
+  }
+
+  if (nrow(Obs) != 2 || ncol(Obs) != 2) {
+    stop(""Odds ratio only available for 2-by-2 contingency tables"", call. = FALSE)
+  }
+
+  OR <- (Obs[1, 1] / Obs[2, 1]) /
+    (Obs[1, 2] / Obs[2, 2])
+
+  res <- data.frame(Odds_ratio = OR)
+
+  ci_method <- NULL
+  if (is.numeric(ci)) {
+    stopifnot(length(ci) == 1, ci < 1, ci > 0)
+    res$CI <- ci
+    ci.level <- if (alternative == ""two.sided"") ci else 2 * ci - 1
+
+    alpha <- 1 - ci.level
+
+    SE_logodds <- sqrt(sum(1 / Obs))
+    Z_logodds <- stats::qnorm(alpha / 2, lower.tail = FALSE)
+    confs <- exp(log(OR) + c(-1, 1) * SE_logodds * Z_logodds)
+
+    res$CI_low <- confs[1]
+    res$CI_high <- confs[2]
+
+    ci_method <- list(method = ""normal"")
+    if (alternative == ""less"") {
+      res$CI_low <- 0
+    } else if (alternative == ""greater"") {
+      res$CI_high <- Inf
+    }
+  } else {
+    alternative <- NULL
+  }
+
+  if (log) {
+    res[colnames(res) %in% c(""Odds_ratio"", ""CI_low"", ""CI_high"")] <-
+      log(res[colnames(res) %in% c(""Odds_ratio"", ""CI_low"", ""CI_high"")])
+    colnames(res)[1] <- ""log_Odds_ratio""
+  }
+
+  class(res) <- c(""effectsize_table"", ""see_effectsize_table"", class(res))
+  attr(res, ""ci"") <- ci
+  attr(res, ""ci_method"") <- ci_method
+  attr(res, ""log"") <- log
+  attr(res, ""approximate"") <- FALSE
+  attr(res, ""alternative"") <- alternative
+  return(res)
+}
+
+#' @rdname oddsratio
+#' @export
+#' @importFrom stats chisq.test qnorm
+riskratio <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = FALSE, ...) {
+  alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
+
+  if (inherits(x, ""htest"")) {
+    if (!(grepl(""Pearson's Chi-squared"", x$method) ||
+          grepl(""Chi-squared test for given probabilities"", x$method))) {
+      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
+    }
+    return(effectsize(x, type = ""rr"", log = log, ci = ci, alternative = alternative))
+  } else if (inherits(x, ""BFBayesFactor"")) {
+    if (!inherits(x@numerator[[1]], ""BFcontingencyTable"")) {
+      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
+    }
+    return(effectsize(x, type = ""rr"", log = log, ci = ci, ...))
+  }
+
+  res <- suppressWarnings(stats::chisq.test(x, y))
+  Obs <- res$observed
+
+  if (any(c(colSums(Obs), rowSums(Obs)) == 0L)) {
+    stop(""Cannot have empty rows/columns in the contingency tables."", call. = FALSE)
+  }
+
+  if (nrow(Obs) != 2 || ncol(Obs) != 2) {
+    stop(""Risk ratio only available for 2-by-2 contingency tables"", call. = FALSE)
+  }
+
+  n1 <- sum(Obs[, 1])
+  n2 <- sum(Obs[, 2])
+  p1 <- Obs[1, 1] / n1
+  p2 <- Obs[1, 2] / n2
+  RR <- p1 / p2
+
+  res <- data.frame(Risk_ratio = RR)
+
+  ci_method <- NULL
+  if (is.numeric(ci)) {
+    stopifnot(length(ci) == 1, ci < 1, ci > 0)
+    res$CI <- ci
+    ci.level <- if (alternative == ""two.sided"") ci else 2 * ci - 1
+
+    alpha <- 1 - ci.level
+
+    SE_logRR <- sqrt(p1 / ((1 - p1) * n1)) + sqrt(p2 / ((1 - p2) * n2))
+    Z_logRR <- stats::qnorm(alpha / 2, lower.tail = FALSE)
+    confs <- exp(log(RR) + c(-1, 1) * SE_logRR * Z_logRR)
+
+    res$CI_low <- confs[1]
+    res$CI_high <- confs[2]
+
+    ci_method <- list(method = ""normal"")
+    if (alternative == ""less"") {
+      res$CI_low <- 0
+    } else if (alternative == ""greater"") {
+      res$CI_high <- Inf
+    }
+  } else {
+    alternative <- NULL
+  }
+
+  if (log) {
+    res[colnames(res) %in% c(""Risk_ratio"", ""CI_low"", ""CI_high"")] <-
+      log(res[colnames(res) %in% c(""Risk_ratio"", ""CI_low"", ""CI_high"")])
+    colnames(res)[1] <- ""log_Risk_ratio""
+  }
+
+  class(res) <- c(""effectsize_table"", ""see_effectsize_table"", class(res))
+  attr(res, ""ci"") <- ci
+  attr(res, ""ci_method"") <- ci_method
+  attr(res, ""log"") <- log
+  attr(res, ""approximate"") <- FALSE
+  attr(res, ""alternative"") <- alternative
+  return(res)
+}
+
+#' @rdname oddsratio
+#' @export
+#' @importFrom stats qnorm
+cohens_h <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...) {
+  alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
+
+  if (inherits(x, ""htest"")) {
+    if (!(grepl(""Pearson's Chi-squared"", x$method) ||
+          grepl(""Chi-squared test for given probabilities"", x$method))) {
+      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
+    }
+    return(effectsize(x, type = ""cohens_h"", ci = ci, alternative = alternative))
+  } else if (inherits(x, ""BFBayesFactor"")) {
+    if (!inherits(x@numerator[[1]], ""BFcontingencyTable"")) {
+      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
+    }
+    return(effectsize(x, type = ""cohens_h"", ci = ci, ...))
+  }
+
+  res <- suppressWarnings(stats::chisq.test(x, y))
+  Obs <- res$observed
+
+  if (any(c(colSums(Obs), rowSums(Obs)) == 0L)) {
+    stop(""Cannot have empty rows/columns in the contingency tables."", call. = FALSE)
+  }
+
+  if (nrow(Obs) != 2 || ncol(Obs) != 2) {
+    stop(""Cohen's h only available for 2-by-2 contingency tables"", call. = FALSE)
+  }
+
+  n1 <- sum(Obs[, 1])
+  n2 <- sum(Obs[, 2])
+  p1 <- Obs[1, 1] / n1
+  p2 <- Obs[1, 2] / n2
+  H <- 2 * asin(sqrt(p1)) - 2 * asin(sqrt(p2))
+
+  out <- data.frame(Cohens_h = H)
+
+  ci_method <- NULL
+  if (is.numeric(ci)) {
+    stopifnot(length(ci) == 1, ci < 1, ci > 0)
+    out$CI <- ci
+    ci.level <- if (alternative == ""two.sided"") ci else 2 * ci - 1
+
+    alpha <- 1 - ci.level
+
+    se_arcsin <- sqrt(0.25 * (1 / n1 + 1 / n2))
+    Zc <- stats::qnorm(alpha / 2, lower.tail = FALSE)
+    out$CI_low <- H - Zc * (2 * se_arcsin)
+    out$CI_high <- H + Zc * (2 * se_arcsin)
+
+    ci_method <- list(method = ""normal"")
+    if (alternative == ""less"") {
+      out$CI_low <- -pi
+    } else if (alternative == ""greater"") {
+      out$CI_high <- pi
+    }
+  } else {
+    alternative <- NULL
+  }
+
+  class(out) <- c(""effectsize_table"", ""see_effectsize_table"", class(out))
+  attr(out, ""ci"") <- ci
+  attr(out, ""ci_method"") <- ci_method
+  attr(out, ""approximate"") <- FALSE
+  attr(out, ""alternative"") <- alternative
+  return(out)
+}
\ No newline at end of file

---FILE: _pkgdown.yml---
@@ -9,11 +9,18 @@ reference:
   contents:
   - effectsize
   - cohens_d
-  - phi
   - eta_squared
-  - rank_biserial
   - cles
   - mahalanobis_d
+- subtitle: ""For Contingency Tables""
+  contents:
+  - phi
+  - oddsratio
+  - cohens_g
+- subtitle: ""Rank Based""
+  contents:
+  - rank_biserial
+  - rank_epsilon_squared
 
 - title: ""Effect Size Conversion""
 - subtitle: ""From Test Statistics""

---FILE: man/F_to_eta2.Rd---
@@ -191,7 +191,7 @@ F_to_f(16.501, 1, 9)
 }
 
 #' @examplesIf require(emmeans)
-\donttest{
+if (require(emmeans)) {
 ## Use with emmeans based contrasts
 ## --------------------------------
 warp.lm <- lm(breaks ~ wool * tension, data = warpbreaks)

---FILE: man/cles.Rd---
@@ -134,10 +134,13 @@ to base rates and other factors. Psychological methods, 13(1), 19â30.
 
 Other effect size indices: 
 \code{\link{cohens_d}()},
+\code{\link{cohens_g}()},
 \code{\link{effectsize.BFBayesFactor}()},
 \code{\link{eta_squared}()},
 \code{\link{mahalanobis_d}()},
+\code{\link{oddsratio}()},
 \code{\link{phi}()},
-\code{\link{rank_biserial}()}
+\code{\link{rank_biserial}()},
+\code{\link{rank_epsilon_squared}()}
 }
 \concept{effect size indices}

---FILE: man/cohens_d.Rd---
@@ -220,10 +220,13 @@ Correcting error and bias in research findings. Sage.
 
 Other effect size indices: 
 \code{\link{cles}()},
+\code{\link{cohens_g}()},
 \code{\link{effectsize.BFBayesFactor}()},
 \code{\link{eta_squared}()},
 \code{\link{mahalanobis_d}()},
+\code{\link{oddsratio}()},
 \code{\link{phi}()},
-\code{\link{rank_biserial}()}
+\code{\link{rank_biserial}()},
+\code{\link{rank_epsilon_squared}()}
 }
 \concept{effect size indices}

---FILE: man/cohens_g.Rd---
@@ -0,0 +1,94 @@
+% Generated by roxygen2: do not edit by hand
+% Please edit documentation in R/cohens_g.R
+\name{cohens_g}
+\alias{cohens_g}
+\title{Effect Sizes for Paired Contingency Tables}
+\usage{
+cohens_g(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...)
+}
+\arguments{
+\item{x}{a numeric vector or matrix. \code{x} and \code{y} can also
+    both be factors.}
+
+\item{y}{a numeric vector; ignored if \code{x} is a matrix.  If
+    \code{x} is a factor, \code{y} should be a factor of the same length.}
+
+\item{ci}{Confidence Interval (CI) level}
+
+\item{alternative}{a character string specifying the alternative hypothesis;
+Controls the type of CI returned: \code{""two.sided""} (two-sided CI; default),
+\code{""greater""} (one-sided CI) or \code{""less""} (one-sided CI). Partial matching is
+allowed (e.g., \code{""g""}, \code{""l""}, \code{""two""}...). See \emph{One-Sided CIs} in
+\link{effectsize_CIs}.}
+
+\item{...}{Ignored}
+}
+\value{
+A data frame with the effect size (\code{Cohens_g}, \code{Risk_ratio}
+(possibly with the prefix \code{log_}), \code{Cohens_h}) and its CIs (\code{CI_low} and
+\code{CI_high}).
+}
+\description{
+Cohen's \emph{g} is an effect size of asymmetry (or marginal heterogeneity) for
+dependent (paired) contingency tables ranging between 0 (perfect symmetry)
+and 0.5 (perfect asymmetry) (see \code{\link[stats:mcnemar.test]{stats::mcnemar.test()}}). (Note this is not
+\emph{not} a measure of (dis)agreement between the pairs, but of (a)symmetry.)
+}
+\section{Confidence Intervals for Cohen's \emph{g}}{
+Confidence intervals are based on the proportion (\eqn{P = g + 0.5})
+confidence intervals returned by \code{\link[stats:prop.test]{stats::prop.test()}} (minus 0.5), which give
+a good close approximation.
+}
+
+\section{CIs and Significance Tests}{
+
+""Confidence intervals on measures of effect size convey all the information
+in a hypothesis test, and more."" (Steiger, 2004). Confidence (compatibility)
+intervals and p values are complementary summaries of parameter uncertainty
+given the observed data. A dichotomous hypothesis test could be performed
+with either a CI or a p value. The 100 (1 - \eqn{\alpha})\% confidence
+interval contains all of the parameter values for which \emph{p} > \eqn{\alpha}
+for the current data and model. For example, a 95\% confidence interval
+contains all of the values for which p > .05.
+\cr\cr
+Note that a confidence interval including 0 \emph{does not} indicate that the null
+(no effect) is true. Rather, it suggests that the observed data together with
+the model and its assumptions combined do not provided clear evidence against
+a parameter value of 0 (same as with any other value in the interval), with
+the level of this evidence defined by the chosen \eqn{\alpha} level (Rafi &
+Greenland, 2020; Schweder & Hjort, 2016; Xie & Singh, 2013). To infer no
+effect, additional judgments about what parameter values are ""close enough""
+to 0 to be negligible are needed (""equivalence testing""; Bauer & Kiesser,
+1996).
+}
+
+\examples{
+Performance <- matrix(c(794, 150,
+                        86, 570), nrow = 2)
+dimnames(Performance) <- list(""1st Survey"" = c(""Approve"", ""Disapprove""),
+                              ""2nd Survey"" = c(""Approve"", ""Disapprove""))
+Performance
+
+cohens_g(Performance)
+
+}
+\references{
+\itemize{
+\item Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
+}
+}
+\seealso{
+\code{\link[=phi]{phi()}} and friends for other effect sizes for contingency tables.
+
+Other effect size indices: 
+\code{\link{cles}()},
+\code{\link{cohens_d}()},
+\code{\link{effectsize.BFBayesFactor}()},
+\code{\link{eta_squared}()},
+\code{\link{mahalanobis_d}()},
+\code{\link{oddsratio}()},
+\code{\link{phi}()},
+\code{\link{rank_biserial}()},
+\code{\link{rank_epsilon_squared}()}
+}
+\concept{effect size indices}

---FILE: man/effectsize.Rd---
@@ -125,9 +125,12 @@ effectsize(anova_table, type = ""epsilon"")
 Other effect size indices: 
 \code{\link{cles}()},
 \code{\link{cohens_d}()},
+\code{\link{cohens_g}()},
 \code{\link{eta_squared}()},
 \code{\link{mahalanobis_d}()},
+\code{\link{oddsratio}()},
 \code{\link{phi}()},
-\code{\link{rank_biserial}()}
+\code{\link{rank_biserial}()},
+\code{\link{rank_epsilon_squared}()}
 }
 \concept{effect size indices}

---FILE: man/eta_squared.Rd---
@@ -342,9 +342,12 @@ Psychological Methods, 9, 164-182.
 Other effect size indices: 
 \code{\link{cles}()},
 \code{\link{cohens_d}()},
+\code{\link{cohens_g}()},
 \code{\link{effectsize.BFBayesFactor}()},
 \code{\link{mahalanobis_d}()},
+\code{\link{oddsratio}()},
 \code{\link{phi}()},
-\code{\link{rank_biserial}()}
+\code{\link{rank_biserial}()},
+\code{\link{rank_epsilon_squared}()}
 }
 \concept{effect size indices}

---FILE: man/mahalanobis_D.Rd---
@@ -1,5 +1,5 @@
 % Generated by roxygen2: do not edit by hand
-% Please edit documentation in R/mahalanobis_d.R
+% Please edit documentation in R/mahalanobis_D.R
 \name{mahalanobis_d}
 \alias{mahalanobis_d}
 \title{Compute Mahalanobis' D (multivariate Cohen's d)}
@@ -149,9 +149,12 @@ mahalanobis_d(mpg + hp + cyl ~ 1, data = mtcars,
 Other effect size indices: 
 \code{\link{cles}()},
 \code{\link{cohens_d}()},
+\code{\link{cohens_g}()},
 \code{\link{effectsize.BFBayesFactor}()},
 \code{\link{eta_squared}()},
+\code{\link{oddsratio}()},
 \code{\link{phi}()},
-\code{\link{rank_biserial}()}
+\code{\link{rank_biserial}()},
+\code{\link{rank_epsilon_squared}()}
 }
 \concept{effect size indices}

---FILE: man/oddsratio.Rd---
@@ -0,0 +1,111 @@
+% Generated by roxygen2: do not edit by hand
+% Please edit documentation in R/xtab_diff.R
+\name{oddsratio}
+\alias{oddsratio}
+\alias{riskratio}
+\alias{cohens_h}
+\title{Odds ratios, Risk ratios, Cohen's \emph{h} for 2-by-2 contingency tables}
+\usage{
+oddsratio(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = FALSE, ...)
+
+riskratio(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = FALSE, ...)
+
+cohens_h(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...)
+}
+\arguments{
+\item{x}{a numeric vector or matrix. \code{x} and \code{y} can also
+    both be factors.}
+
+\item{y}{a numeric vector; ignored if \code{x} is a matrix.  If
+    \code{x} is a factor, \code{y} should be a factor of the same length.}
+
+\item{ci}{Confidence Interval (CI) level}
+
+\item{alternative}{a character string specifying the alternative hypothesis;
+Controls the type of CI returned: \code{""two.sided""} (two-sided CI; default),
+\code{""greater""} (one-sided CI) or \code{""less""} (one-sided CI). Partial matching is
+allowed (e.g., \code{""g""}, \code{""l""}, \code{""two""}...). See \emph{One-Sided CIs} in
+\link{effectsize_CIs}.}
+
+\item{log}{Take in or output the log of the ratio (such as in logistic models).}
+
+\item{...}{Ignored}
+}
+\value{
+A data frame with the effect size (\code{Odds_ratio}, \code{Risk_ratio}
+(possibly with the prefix \code{log_}), \code{Cohens_h}) and its CIs (\code{CI_low} and
+\code{CI_high}).
+}
+\description{
+Note that these are computed with each \strong{column} representing the different
+groups, and the \emph{first} column representing the treatment group and the
+\emph{second} column baseline (or control). Effects are given as \code{treatment / control}. If you wish you use rows as groups you must pass a transposed
+table, or switch the \code{x} and \code{y} arguments.
+}
+\section{Confidence Intervals for OR, RR and Cohen's \emph{h}}{
+For Odds ratios, Risk ratios and Cohen's \emph{h}, confidence intervals are
+estimated using the standard normal parametric method (see Katz et al., 1978;
+Szumilas, 2010).
+}
+
+\section{CIs and Significance Tests}{
+
+""Confidence intervals on measures of effect size convey all the information
+in a hypothesis test, and more."" (Steiger, 2004). Confidence (compatibility)
+intervals and p values are complementary summaries of parameter uncertainty
+given the observed data. A dichotomous hypothesis test could be performed
+with either a CI or a p value. The 100 (1 - \eqn{\alpha})\% confidence
+interval contains all of the parameter values for which \emph{p} > \eqn{\alpha}
+for the current data and model. For example, a 95\% confidence interval
+contains all of the values for which p > .05.
+\cr\cr
+Note that a confidence interval including 0 \emph{does not} indicate that the null
+(no effect) is true. Rather, it suggests that the observed data together with
+the model and its assumptions combined do not provided clear evidence against
+a parameter value of 0 (same as with any other value in the interval), with
+the level of this evidence defined by the chosen \eqn{\alpha} level (Rafi &
+Greenland, 2020; Schweder & Hjort, 2016; Xie & Singh, 2013). To infer no
+effect, additional judgments about what parameter values are ""close enough""
+to 0 to be negligible are needed (""equivalence testing""; Bauer & Kiesser,
+1996).
+}
+
+\examples{
+RCT <- matrix(c(71, 50,
+                30, 100), nrow = 2)
+dimnames(RCT) <- list(Diagnosis = c(""Sick"", ""Recovered""),
+                      Group = c(""Treatment"", ""Control""))
+RCT # note groups are COLUMNS
+
+oddsratio(RCT)
+oddsratio(RCT, alternative = ""greater"")
+
+riskratio(RCT)
+
+cohens_h(RCT)
+
+
+
+}
+\references{
+\itemize{
+\item Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
+\item Katz, D. J. S. M., Baptista, J., Azen, S. P., & Pike, M. C. (1978). Obtaining confidence intervals for the risk ratio in cohort studies. Biometrics, 469-474.
+\item Szumilas, M. (2010). Explaining odds ratios. Journal of the Canadian academy of child and adolescent psychiatry, 19(3), 227.
+}
+}
+\seealso{
+\code{\link[=phi]{phi()}} and friends for other effect sizes for contingency tables.
+
+Other effect size indices: 
+\code{\link{cles}()},
+\code{\link{cohens_d}()},
+\code{\link{cohens_g}()},
+\code{\link{effectsize.BFBayesFactor}()},
+\code{\link{eta_squared}()},
+\code{\link{mahalanobis_d}()},
+\code{\link{phi}()},
+\code{\link{rank_biserial}()},
+\code{\link{rank_epsilon_squared}()}
+}
+\concept{effect size indices}

---FILE: man/phi.Rd---
@@ -1,16 +1,12 @@
 % Generated by roxygen2: do not edit by hand
-% Please edit documentation in R/xtab.R
+% Please edit documentation in R/xtab_corr.R
 \name{phi}
 \alias{phi}
 \alias{cramers_v}
 \alias{cohens_w}
 \alias{fei}
 \alias{pearsons_c}
-\alias{oddsratio}
-\alias{riskratio}
-\alias{cohens_h}
-\alias{cohens_g}
-\title{Effect size for contingency tables}
+\title{Correlation effect size for contingency tables}
 \usage{
 phi(x, y = NULL, ci = 0.95, alternative = ""greater"", adjust = FALSE, ...)
 
@@ -41,14 +37,6 @@ pearsons_c(
   alternative = ""greater"",
   ...
 )
-
-oddsratio(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = FALSE, ...)
-
-riskratio(x, y = NULL, ci = 0.95, alternative = ""two.sided"", log = FALSE, ...)
-
-cohens_h(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...)
-
-cohens_g(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...)
 }
 \arguments{
 \item{x}{a numeric vector or matrix. \code{x} and \code{y} can also
@@ -60,11 +48,10 @@ cohens_g(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...)
 \item{ci}{Confidence Interval (CI) level}
 
 \item{alternative}{a character string specifying the alternative hypothesis;
-Controls the type of CI returned: \code{""greater""} (two-sided CI; default for
-Cramer's \emph{V}, phi (\eqn{\phi}), and Cohen's \emph{w}), \code{""two.sided""} (default
-for OR, RR, Cohen's \emph{h} and Cohen's \emph{g}) or \code{""less""} (one-sided CI).
-Partial matching is allowed (e.g., \code{""g""}, \code{""l""}, \code{""two""}...). See
-\emph{One-Sided CIs} in \link{effectsize_CIs}.}
+Controls the type of CI returned: \code{""greater""} (one-sided CI; default),
+\code{""two.sided""} (two-sided CI) or \code{""less""} (one-sided CI). Partial matching
+is allowed (e.g., \code{""g""}, \code{""l""}, \code{""two""}...). See \emph{One-Sided CIs} in
+\link{effectsize_CIs}.}
 
 \item{adjust}{Should the effect size be bias-corrected? Defaults to \code{FALSE}.}
 
@@ -73,24 +60,18 @@ Partial matching is allowed (e.g., \code{""g""}, \code{""l""}, \code{""two""}...). See
 
 \item{p}{a vector of probabilities of the same length as \code{x}.
     An error is given if any entry of \code{p} is negative.}
-
-\item{log}{Take in or output the log of the ratio (such as in logistic models).}
 }
 \value{
 A data frame with the effect size (\code{Cramers_v}, \code{phi} (possibly with
-the suffix \verb{_adjusted}), \code{Cohens_w}, \code{Fei}, \code{Odds_ratio}, \code{Risk_ratio}
-(possibly with the prefix \code{log_}), \code{Cohens_h}, or \code{Cohens_g}) and its CIs
-(\code{CI_low} and \code{CI_high}).
+the suffix \verb{_adjusted}), \code{Cohens_w}, \code{Fei}) and its CIs (\code{CI_low} and
+\code{CI_high}).
 }
 \description{
 Compute Cramer's \emph{V}, phi (\eqn{\phi}), Cohen's \emph{w},
-\ifelse{latex}{\eqn{Fei}}{×¤ (Fei)}, Pearson's contingency coefficient, Odds
-ratios, Risk ratios, Cohen's \emph{h} and Cohen's \emph{g} for contingency tables or
-goodness-of-fit. See details.
+\ifelse{latex}{\eqn{Fei}}{×¤ (Fei)}, Pearson's contingency coefficient for
+contingency tables or goodness-of-fit. See details.
 }
 \details{
-\subsection{Correlation-like Effect Sizes}{
-
 Cramer's \emph{V}, phi (\eqn{\phi}), Cohen's \emph{w}, and Pearson's \emph{C} are effect
 sizes for tests of independence in 2D contingency tables. For 2-by-2 tables,
 Cramer's \emph{V}, phi and Cohen's \emph{w} are identical, and are equal to the simple
@@ -113,39 +94,6 @@ To summarize, for correlation-like effect sizes, we recommend:
 \item For goodness-of-fit, use \code{fei()}
 }
 }
-
-\subsection{Other Effect Sizes for 2-by-2 xtabs}{
-
-For 2-by-2 contingency tables, Odds ratios, Risk ratios and Cohen's \emph{h} can
-also be estimated. Note that these are computed with each \strong{column}
-representing the different groups, and the \emph{first} column representing the
-treatment group and the \emph{second} column baseline (or control). Effects are
-given as \code{treatment / control}. If you wish you use rows as groups you must
-pass a transposed table, or switch the \code{x} and \code{y} arguments.
-}
-
-\subsection{Effect Sizes for Paired xtabs}{
-
-Cohen's \emph{g} is an effect size of asymmetry (or marginal heterogeneity) for
-dependent (paired) contingency tables ranging between 0 (perfect symmetry)
-and 0.5 (perfect asymmetry) (see \code{\link[stats:mcnemar.test]{stats::mcnemar.test()}}). (Note this is not
-\emph{not} a measure of (dis)agreement between the pairs, but of (a)symmetry.)
-}
-}
-\section{Confidence Intervals for Cohen's g, OR, RR and Cohen's h}{
-For Cohen's \emph{g}, confidence intervals are based on the proportion (\eqn{P = g
-+ 0.5}) confidence intervals returned by \code{\link[stats:prop.test]{stats::prop.test()}} (minus 0.5),
-which give a good close approximation.
-\cr \cr
-For Odds ratios, Risk ratios and Cohen's \emph{h}, confidence intervals are
-estimated using the standard normal parametric method (see Katz et al., 1978;
-Szumilas, 2010).
-\cr \cr
-See \emph{Confidence (Compatibility) Intervals (CIs)}, \emph{CIs and Significance Tests},
-and \emph{One-Sided CIs} sections for \emph{phi}, Cohen's \emph{w}, Cramer's \emph{V},
-Pearson's \emph{C}, and \emph{Fei}.
-}
-
 \section{Confidence (Compatibility) Intervals (CIs)}{
 
 Unless stated otherwise, confidence (compatibility) intervals (CIs) are
@@ -189,59 +137,37 @@ to 0 to be negligible are needed (""equivalence testing""; Bauer & Kiesser,
 
 ## 2-by-2 tables
 ## -------------
-RCT <-
-  matrix(
-    c(
-      71, 30,
-      50, 100
-    ),
-    nrow = 2, byrow = TRUE,
-    dimnames = list(
-      Diagnosis = c(""Sick"", ""Recovered""),
-      Group = c(""Treatment"", ""Control"")
-    )
-  )
+RCT <- matrix(c(71, 50,
+                30, 100), nrow = 2)
+dimnames(RCT) <- list(Diagnosis = c(""Sick"", ""Recovered""),
+                      Group = c(""Treatment"", ""Control""))
 RCT # note groups are COLUMNS
 
 phi(RCT)
 pearsons_c(RCT)
 
-oddsratio(RCT)
-oddsratio(RCT, alternative = ""greater"")
 
-riskratio(RCT)
-
-cohens_h(RCT)
 
 ## Larger tables
 ## -------------
-
-M <-
-  matrix(
-    c(
-      150, 100, 165,
-      130, 50, 65,
-      35, 10, 2,
-      55, 40, 25
-    ),
-    nrow = 4,
-    dimnames = list(
-      Music = c(""Pop"", ""Rock"", ""Jazz"", ""Classic""),
-      Study = c(""Psych"", ""Econ"", ""Law"")
-    )
-  )
+M <- matrix(c(150, 100, 165,
+              130, 50, 65,
+              35, 10, 2,
+              55, 40, 25), nrow = 4)
+dimnames(M) <- list(Music = c(""Pop"", ""Rock"", ""Jazz"", ""Classic""),
+                    Study = c(""Psych"", ""Econ"", ""Law""))
 M
 
-cohens_w(M)
-
 cramers_v(M)
 
+cohens_w(M)
+
 pearsons_c(M)
 
 
+
 ## Goodness of fit
 ## ---------------
-
 Smoking_ASD <- as.table(c(ASD = 17, ASP = 11, TD = 640))
 
 fei(Smoking_ASD)
@@ -258,34 +184,10 @@ cohens_w(Smoking_ASD, p = c(0.015, 0.010, 0.975))
 pearsons_c(Smoking_ASD, p = c(0.015, 0.010, 0.975))
 
 
-
-
-
-## Dependent (Paired) Contingency Tables
-## -------------------------------------
-#
-Performance <-
-  matrix(
-    c(
-      794, 150,
-      86, 570
-    ),
-    nrow = 2,
-    dimnames = list(
-      ""1st Survey"" = c(""Approve"", ""Disapprove""),
-      ""2nd Survey"" = c(""Approve"", ""Disapprove"")
-    )
-  )
-Performance
-
-cohens_g(Performance)
-
 }
 \references{
 \itemize{
 \item Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
-\item Katz, D. J. S. M., Baptista, J., Azen, S. P., & Pike, M. C. (1978). Obtaining confidence intervals for the risk ratio in cohort studies. Biometrics, 469-474.
-\item Szumilas, M. (2010). Explaining odds ratios. Journal of the Canadian academy of child and adolescent psychiatry, 19(3), 227.
 \item Johnston, J. E., Berry, K. J., & Mielke Jr, P. W. (2006). Measures of
 effect size for chi-squared and likelihood-ratio goodness-of-fit tests.
 Perceptual and motor skills, 103(2), 412-414.
@@ -299,9 +201,12 @@ tests to effect sizes for meta-analysis. PloS one, 5(4), e10059.
 Other effect size indices: 
 \code{\link{cles}()},
 \code{\link{cohens_d}()},
+\code{\link{cohens_g}()},
 \code{\link{effectsize.BFBayesFactor}()},
 \code{\link{eta_squared}()},
 \code{\link{mahalanobis_d}()},
-\code{\link{rank_biserial}()}
+\code{\link{oddsratio}()},
+\code{\link{rank_biserial}()},
+\code{\link{rank_epsilon_squared}()}
 }
 \concept{effect size indices}

---FILE: man/rank_biserial.Rd---
@@ -1,11 +1,9 @@
 % Generated by roxygen2: do not edit by hand
-% Please edit documentation in R/rank_effectsizes.R
+% Please edit documentation in R/rank_diff.R
 \name{rank_biserial}
 \alias{rank_biserial}
 \alias{cliffs_delta}
-\alias{rank_epsilon_squared}
-\alias{kendalls_w}
-\title{Effect size for non-parametric (rank sum) tests}
+\title{Effect size for (rank sum) differences}
 \usage{
 rank_biserial(
   x,
@@ -16,8 +14,7 @@ rank_biserial(
   alternative = ""two.sided"",
   paired = FALSE,
   verbose = TRUE,
-  ...,
-  iterations
+  ...
 )
 
 cliffs_delta(
@@ -30,45 +27,12 @@ cliffs_delta(
   verbose = TRUE,
   ...
 )
-
-rank_epsilon_squared(
-  x,
-  groups,
-  data = NULL,
-  ci = 0.95,
-  alternative = ""greater"",
-  iterations = 200,
-  ...
-)
-
-kendalls_w(
-  x,
-  groups,
-  blocks,
-  data = NULL,
-  blocks_on_rows = TRUE,
-  ci = 0.95,
-  alternative = ""greater"",
-  iterations = 200,
-  verbose = TRUE,
-  ...
-)
 }
 \arguments{
-\item{x}{Can be one of:
-\itemize{
-\item A numeric vector, or a character name of one in \code{data}.
-\item A formula in to form of \code{DV ~ groups} (for \code{rank_biserial()} and
-\code{rank_epsilon_squared()}) or \code{DV ~ groups | blocks} (for \code{kendalls_w()};
-See details for the \code{blocks} and \code{groups} terminology used here).
-\item A list of vectors (for \code{rank_epsilon_squared()}).
-\item A matrix of \verb{blocks x groups} (for \code{kendalls_w()}) (or \verb{groups x blocks}
-if \code{blocks_on_rows = FALSE}). See details for the \code{blocks} and \code{groups}
-terminology used here.
-}}
-
-\item{y}{An optional numeric vector of data values to compare to \code{x}, or a
-character name of one in \code{data}. Ignored if \code{x} is not a vector.}
+\item{x, y}{A numeric vector, or a character name of one in \code{data}.
+Any missing values (\code{NA}s) are dropped from the resulting vector.
+\code{x} can also be a formula (see \code{\link[stats:t.test]{stats::t.test()}}), in which case \code{y} is
+ignored.}
 
 \item{data}{An optional data frame containing the variables.}
 
@@ -79,11 +43,9 @@ estimated. See \link[stats:wilcox.test]{stats::wilcox.test}.}
 \item{ci}{Confidence Interval (CI) level}
 
 \item{alternative}{a character string specifying the alternative hypothesis;
-Controls the type of CI returned: \code{""two.sided""} (two-sided CI; default for
-rank-biserial correlation and Cliff's \emph{delta}), \code{""greater""} (default for
-rank epsilon squared and Kendall's \emph{W}) or \code{""less""} (one-sided CI). Partial
-matching is allowed (e.g., \code{""g""}, \code{""l""}, \code{""two""}...). See \emph{One-Sided CIs}
-in \link{effectsize_CIs}.}
+Controls the type of CI returned: \code{""two.sided""} (default, two-sided CI),
+\code{""greater""} or \code{""less""} (one-sided CI). Partial matching is allowed (e.g.,
+\code{""g""}, \code{""l""}, \code{""two""}...). See \emph{One-Sided CIs} in \link{effectsize_CIs}.}
 
 \item{paired}{If \code{TRUE}, the values of \code{x} and \code{y} are considered as paired.
 This produces an effect size that is equivalent to the one-sample effect
@@ -93,26 +55,14 @@ size on \code{x - y}.}
 
 \item{...}{Arguments passed to or from other methods. When \code{x} is a formula,
 these can be \code{subset} and \code{na.action}.}
-
-\item{iterations}{The number of bootstrap replicates for computing confidence
-intervals. Only applies when \code{ci} is not \code{NULL}. (Deprecated for
-\code{rank_biserial()}).}
-
-\item{groups, blocks}{A factor vector giving the group / block for the
-corresponding elements of \code{x}, or a character name of one in \code{data}.
-Ignored if \code{x} is not a vector.}
-
-\item{blocks_on_rows}{Are blocks on rows (\code{TRUE}) or columns (\code{FALSE}).}
 }
 \value{
-A data frame with the effect size (\code{r_rank_biserial},
-\code{rank_epsilon_squared} or \code{Kendalls_W}) and its CI (\code{CI_low} and
-\code{CI_high}).
+A data frame with the effect size \code{r_rank_biserial} and its CI
+(\code{CI_low} and \code{CI_high}).
 }
 \description{
-Compute the rank-biserial correlation (\eqn{r_{rb}}{r_rb}), Cliff's \emph{delta}
-(\eqn{\delta}), rank epsilon squared (\eqn{\varepsilon^2}{\epsilon^2}), and
-Kendall's \emph{W} effect sizes for non-parametric (rank sum) tests.
+Compute the rank-biserial correlation (\eqn{r_{rb}}{r_rb}) and Cliff's \emph{delta}
+(\eqn{\delta}) effect sizes for non-parametric (rank sum) differences.
 }
 \details{
 The rank-biserial correlation is appropriate for non-parametric tests of
@@ -127,31 +77,38 @@ from \code{-1} (\emph{all} values of the second sample are larger than \emph{all
 of the first sample) to \code{+1} (\emph{all} values of the second sample are smaller
 than \emph{all} the values of the first sample). Cliff's \emph{delta} is an alias to
 the rank-biserial correlation in the two sample case.
-\cr\cr
-The rank epsilon squared is appropriate for non-parametric tests of
-differences between 2 or more samples (a rank based ANOVA). See
-\link[stats:kruskal.test]{stats::kruskal.test}. Values range from 0 to 1, with larger values
-indicating larger differences between groups.
-\cr\cr
-Kendall's \emph{W} is appropriate for non-parametric tests of differences between
-2 or more dependent samples (a rank based rmANOVA), where each \code{group} (e.g.,
-experimental condition) was measured for each \code{block} (e.g., subject). This
-measure is also common as a measure of reliability of the rankings of the
-\code{groups} between raters (\code{blocks}). See \link[stats:friedman.test]{stats::friedman.test}. Values range
-from 0 to 1, with larger values indicating larger differences between groups
-/ higher agreement between raters.
-\subsection{Ties}{
-
+}
+\section{Ties}{
 When tied values occur, they are each given the average of the ranks that
 would have been given had no ties occurred. This results in an effect size of
 reduced magnitude. A correction has been applied for Kendall's \emph{W}.
 }
-}
+
 \section{Confidence Intervals}{
 Confidence intervals for the rank-biserial correlation (and Cliff's \emph{delta})
 are estimated using the normal approximation (via Fisher's transformation).
-Confidence intervals for rank Epsilon squared, and Kendall's \emph{W} are
-estimated using the bootstrap method (using the \code{{boot}} package).
+}
+
+\section{CIs and Significance Tests}{
+
+""Confidence intervals on measures of effect size convey all the information
+in a hypothesis test, and more."" (Steiger, 2004). Confidence (compatibility)
+intervals and p values are complementary summaries of parameter uncertainty
+given the observed data. A dichotomous hypothesis test could be performed
+with either a CI or a p value. The 100 (1 - \eqn{\alpha})\% confidence
+interval contains all of the parameter values for which \emph{p} > \eqn{\alpha}
+for the current data and model. For example, a 95\% confidence interval
+contains all of the values for which p > .05.
+\cr\cr
+Note that a confidence interval including 0 \emph{does not} indicate that the null
+(no effect) is true. Rather, it suggests that the observed data together with
+the model and its assumptions combined do not provided clear evidence against
+a parameter value of 0 (same as with any other value in the interval), with
+the level of this evidence defined by the chosen \eqn{\alpha} level (Rafi &
+Greenland, 2020; Schweder & Hjort, 2016; Xie & Singh, 2013). To infer no
+effect, additional judgments about what parameter values are ""close enough""
+to 0 to be negligible are needed (""equivalence testing""; Bauer & Kiesser,
+1996).
 }
 
 \examples{
@@ -160,9 +117,6 @@ data(mtcars)
 mtcars$am <- factor(mtcars$am)
 mtcars$cyl <- factor(mtcars$cyl)
 
-# Rank Biserial Correlation
-# =========================
-
 # Two Independent Samples ----------
 (rb <- rank_biserial(mpg ~ am, data = mtcars))
 # Same as:
@@ -193,26 +147,6 @@ dat <- data.frame(
 
 interpret_rank_biserial(0.78)
 interpret(rb, rules = ""funder2019"")
-
-
-# Rank Epsilon Squared
-# ====================
-
-rank_epsilon_squared(mpg ~ cyl, data = mtcars)
-
-
-
-# Kendall's W
-# ===========
-dat <- data.frame(
-  cond = c(""A"", ""B"", ""A"", ""B"", ""A"", ""B""),
-  ID = c(""L"", ""L"", ""M"", ""M"", ""H"", ""H""),
-  y = c(44.56, 28.22, 24, 28.78, 24.56, 18.78)
-)
-(W <- kendalls_w(y ~ cond | ID, data = dat, verbose = FALSE))
-
-interpret_kendalls_w(0.11)
-interpret(W, rules = ""landis1977"")
 }
 
 }
@@ -235,12 +169,17 @@ revisited. An overview of some recommended measures of effect size.
 }
 }
 \seealso{
+\code{\link[=rank_epsilon_squared]{rank_epsilon_squared()}} for more rank based effect sizes
+
 Other effect size indices: 
 \code{\link{cles}()},
 \code{\link{cohens_d}()},
+\code{\link{cohens_g}()},
 \code{\link{effectsize.BFBayesFactor}()},
 \code{\link{eta_squared}()},
 \code{\link{mahalanobis_d}()},
-\code{\link{phi}()}
+\code{\link{oddsratio}()},
+\code{\link{phi}()},
+\code{\link{rank_epsilon_squared}()}
 }
 \concept{effect size indices}

---FILE: man/rank_epsilon_squared.Rd---
@@ -0,0 +1,163 @@
+% Generated by roxygen2: do not edit by hand
+% Please edit documentation in R/rank_ANOVA.R
+\name{rank_epsilon_squared}
+\alias{rank_epsilon_squared}
+\alias{kendalls_w}
+\title{Effect size for (rank sum) one-way ANOVAs}
+\usage{
+rank_epsilon_squared(
+  x,
+  groups,
+  data = NULL,
+  ci = 0.95,
+  alternative = ""greater"",
+  iterations = 200,
+  ...
+)
+
+kendalls_w(
+  x,
+  groups,
+  blocks,
+  data = NULL,
+  blocks_on_rows = TRUE,
+  ci = 0.95,
+  alternative = ""greater"",
+  iterations = 200,
+  verbose = TRUE,
+  ...
+)
+}
+\arguments{
+\item{x}{Can be one of:
+\itemize{
+\item A numeric vector, or a character name of one in \code{data}.
+\item A list of vectors (for \code{rank_epsilon_squared()}).
+\item A matrix of \verb{blocks x groups} (for \code{kendalls_w()}) (or \verb{groups x blocks}
+if \code{blocks_on_rows = FALSE}). See details for the \code{blocks} and \code{groups}
+terminology used here.
+\item A formula in the form of:
+\itemize{
+\item \code{DV ~ groups} for \code{rank_epsilon_squared()}.
+\item \code{DV ~ groups | blocks} for \code{kendalls_w()} (See details for the
+\code{blocks} and \code{groups} terminology used here).
+}
+}}
+
+\item{groups, blocks}{A factor vector giving the group / block for the
+corresponding elements of \code{x}, or a character name of one in \code{data}.
+Ignored if \code{x} is not a vector.}
+
+\item{data}{An optional data frame containing the variables.}
+
+\item{ci}{Confidence Interval (CI) level}
+
+\item{alternative}{a character string specifying the alternative hypothesis;
+Controls the type of CI returned: \code{""greater""} (one-sided CI; default),
+\code{""two.sided""} (two-sided CI) or \code{""less""} (one-sided CI). Partial matching
+is allowed (e.g., \code{""g""}, \code{""l""}, \code{""two""}...). See \emph{One-Sided CIs} in
+\link{effectsize_CIs}.}
+
+\item{iterations}{The number of bootstrap replicates for computing confidence
+intervals. Only applies when \code{ci} is not \code{NULL}.}
+
+\item{...}{For goodness-of-fit effect sizes, can pass \code{rescale.p} (see
+\code{\link[stats:chisq.test]{stats::chisq.test()}}). Else, ignored.}
+
+\item{blocks_on_rows}{Are blocks on rows (\code{TRUE}) or columns (\code{FALSE}).}
+
+\item{verbose}{Toggle warnings and messages on or off.}
+}
+\value{
+A data frame with the effect size \code{(}rank_epsilon_squared\code{or}Kendalls_W\verb{) and its CI (}CI_low\code{and}CI_high`).
+}
+\description{
+Compute rank epsilon squared (\eqn{\varepsilon^2}{\epsilon^2}), and Kendall's
+\emph{W} effect sizes for non-parametric (rank sum) one-way ANOVAs.
+}
+\details{
+The rank epsilon squared is appropriate for non-parametric tests of
+differences between 2 or more samples (a rank based ANOVA). See
+\link[stats:kruskal.test]{stats::kruskal.test}. Values range from 0 to 1, with larger values
+indicating larger differences between groups.
+\cr\cr
+Kendall's \emph{W} is appropriate for non-parametric tests of differences between
+2 or more dependent samples (a rank based rmANOVA), where each \code{group} (e.g.,
+experimental condition) was measured for each \code{block} (e.g., subject). This
+measure is also common as a measure of reliability of the rankings of the
+\code{groups} between raters (\code{blocks}). See \link[stats:friedman.test]{stats::friedman.test}. Values range
+from 0 to 1, with larger values indicating larger differences between groups
+/ higher agreement between raters.
+}
+\section{Confidence Intervals}{
+Confidence intervals for rank Epsilon squared, and Kendall's \emph{W} are
+estimated using the bootstrap method (using the \code{{boot}} package).
+}
+
+\section{CIs and Significance Tests}{
+
+""Confidence intervals on measures of effect size convey all the information
+in a hypothesis test, and more."" (Steiger, 2004). Confidence (compatibility)
+intervals and p values are complementary summaries of parameter uncertainty
+given the observed data. A dichotomous hypothesis test could be performed
+with either a CI or a p value. The 100 (1 - \eqn{\alpha})\% confidence
+interval contains all of the parameter values for which \emph{p} > \eqn{\alpha}
+for the current data and model. For example, a 95\% confidence interval
+contains all of the values for which p > .05.
+\cr\cr
+Note that a confidence interval including 0 \emph{does not} indicate that the null
+(no effect) is true. Rather, it suggests that the observed data together with
+the model and its assumptions combined do not provided clear evidence against
+a parameter value of 0 (same as with any other value in the interval), with
+the level of this evidence defined by the chosen \eqn{\alpha} level (Rafi &
+Greenland, 2020; Schweder & Hjort, 2016; Xie & Singh, 2013). To infer no
+effect, additional judgments about what parameter values are ""close enough""
+to 0 to be negligible are needed (""equivalence testing""; Bauer & Kiesser,
+1996).
+}
+
+\section{Ties}{
+When tied values occur, they are each given the average of the ranks that
+would have been given had no ties occurred. This results in an effect size of
+reduced magnitude. A correction has been applied for Kendall's \emph{W}.
+}
+
+\examples{
+\donttest{
+# Rank Epsilon Squared
+# ====================
+
+rank_epsilon_squared(mpg ~ cyl, data = mtcars)
+
+
+
+# Kendall's W
+# ===========
+dat <- data.frame(
+  cond = c(""A"", ""B"", ""A"", ""B"", ""A"", ""B""),
+  ID = c(""L"", ""L"", ""M"", ""M"", ""H"", ""H""),
+  y = c(44.56, 28.22, 24, 28.78, 24.56, 18.78)
+)
+(W <- kendalls_w(y ~ cond | ID, data = dat, verbose = FALSE))
+
+interpret_kendalls_w(0.11)
+interpret(W, rules = ""landis1977"")
+}
+
+
+}
+\seealso{
+\code{\link[=rank_biserial]{rank_biserial()}} for more rank based effect sizes
+
+Other effect size indices: 
+\code{\link{cles}()},
+\code{\link{cohens_d}()},
+\code{\link{cohens_g}()},
+\code{\link{effectsize.BFBayesFactor}()},
+\code{\link{eta_squared}()},
+\code{\link{mahalanobis_d}()},
+\code{\link{oddsratio}()},
+\code{\link{phi}()},
+\code{\link{rank_biserial}()}
+}
+\concept{effect size indices}

---FILE: tests/testthat/test-standardized_differences.R---
@@ -172,6 +172,15 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_error(p_overlap(x, y, parametric = FALSE), NA)
     expect_error(p_superiority(x, y, parametric = FALSE), NA)
 
+    # Mu?
+    CLES0 <- cles(x, y, ci = NULL)
+    CLES1 <- cles(x, y, mu = 0.2, ci = NULL)
+    expect_true(all(CLES0[[2]] > CLES1[[2]]))
+    expect_equal(cles(x, y, mu = 0.2, ci = NULL),
+                 cles(x, y, mu = 0.2, ci = NULL, parametric = FALSE),
+                 tolerance = 0.05,
+                 ignore_attr = TRUE)
+
     x <- 1:3
     y <- c(1, 1:3)
     CLES <- cles(x, y)",True,False,Documentation / Formatting,7
easystats,effectsize,b9d31490c8b6c515a0ad4f6123c71a79ed57cb34,Indrajeet Patil,patilindrajeet.science@gmail.com,2022-09-06T16:40:04Z,GitHub,noreply@github.com,2022-09-06T16:40:04Z,"Use standardized GHA workflows (#473)

* Use standardized GHA workflows

https://github.com/easystats/easystats/issues/234

* Update README

* Run example conditionally

* Bump needed versions",.github/workflows/R-CMD-check.yaml;.github/workflows/R-check.yaml;.github/workflows/check-readme.yaml;.github/workflows/html-5-check.yaml;.github/workflows/lint.yaml;.github/workflows/pkgdown.yaml;.github/workflows/render-readme.yaml;.github/workflows/test-coverage.yaml;DESCRIPTION;R/convert_stat_to_anova.R;README.Rmd;README.md;man/F_to_eta2.Rd,True,True,True,False,61,197,258,"---FILE: .github/workflows/R-CMD-check.yaml---
@@ -0,0 +1,17 @@
+# Workflow derived from https://github.com/r-lib/actions/tree/v2/examples
+# Need help debugging build failures? Start at https://github.com/r-lib/actions#where-to-find-help
+#
+# NOTE: This workflow is overkill for most R packages and
+# check-standard.yaml is likely a better choice.
+# usethis::use_github_action(""check-standard"") will install it.
+on:
+  push:
+    branches: [main, master]
+  pull_request:
+    branches: [main, master]
+
+name: R-CMD-check
+
+jobs:
+  R-CMD-check:
+    uses: easystats/workflows/.github/workflows/R-CMD-check.yaml@main

---FILE: .github/workflows/R-check.yaml---
@@ -1,65 +0,0 @@
-# Workflow derived from https://github.com/r-lib/actions/tree/v2/examples
-# Need help debugging build failures? Start at https://github.com/r-lib/actions#where-to-find-help
-#
-# NOTE: This workflow is overkill for most R packages and
-# check-standard.yaml is likely a better choice.
-# usethis::use_github_action(""check-standard"") will install it.
-on:
-  push:
-    branches: [main, master]
-  pull_request:
-    branches: [main, master]
-
-name: R-CMD-check
-
-jobs:
-  R-CMD-check:
-    runs-on: ${{ matrix.config.os }}
-
-    name: ${{ matrix.config.os }} (${{ matrix.config.r }})
-
-    strategy:
-      fail-fast: false
-      matrix:
-        config:
-          #- {os: macOS-latest,   r: 'devel'}
-          - {os: macOS-latest,   r: 'release'}
-          - {os: macOS-latest,   r: 'oldrel-1'}
-          - {os: macOS-latest,   r: '4.0.0'}
-          - {os: macOS-latest,   r: '3.6.0'}
-          - {os: macOS-latest,   r: '3.5.0'}
-
-          - {os: windows-latest, r: 'devel'}
-          - {os: windows-latest, r: 'release'}
-
-          - {os: ubuntu-latest,   r: 'devel', http-user-agent: 'release'}
-          - {os: ubuntu-latest,   r: 'release'}
-          - {os: ubuntu-latest,   r: 'oldrel-1'}
-
-    env:
-      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}
-      R_KEEP_PKG_SOURCE: yes
-      _R_CHECK_CRAN_INCOMING_: false
-      _R_CHECK_FORCE_SUGGESTS_: false
-
-    steps:
-      - uses: actions/checkout@v2
-
-      - uses: r-lib/actions/setup-pandoc@v2
-
-      - uses: r-lib/actions/setup-r@v2
-        with:
-          r-version: ${{ matrix.config.r }}
-          http-user-agent: ${{ matrix.config.http-user-agent }}
-          use-public-rspm: true
-
-      - uses: r-lib/actions/setup-r-dependencies@v2
-        with:
-          extra-packages: |
-            any::rcmdcheck
-            lme4=?ignore-before-r=3.6.0
-          needs: check
-
-      - uses: r-lib/actions/check-r-package@v2
-        with:
-          error-on: '""note""'
\ No newline at end of file

---FILE: .github/workflows/check-readme.yaml---
@@ -0,0 +1,14 @@
+# Workflow derived from https://github.com/r-lib/actions/tree/v2/examples
+# Need help debugging build failures? Start at https://github.com/r-lib/actions#where-to-find-help
+
+on:
+  push:
+    branches: [main, master]
+  pull_request:
+    branches: [main, master]
+
+name: check-readme
+
+jobs:
+  check-readme:
+    uses: easystats/workflows/.github/workflows/check-readme.yaml@main

---FILE: .github/workflows/html-5-check.yaml---
@@ -0,0 +1,13 @@
+# Workflow derived from https://github.com/r-lib/actions/tree/v2/examples
+# Need help debugging build failures? Start at https://github.com/r-lib/actions#where-to-find-help
+on:
+  push:
+    branches: [main, master]
+  pull_request:
+    branches: [main, master]
+
+name: HTML5 check
+
+jobs:
+  HTML5-check:
+    uses: easystats/workflows/.github/workflows/html-5-check.yaml@main

---FILE: .github/workflows/lint.yaml---
@@ -1,47 +1,13 @@
+# Workflow derived from https://github.com/r-lib/actions/tree/v2/examples
+# Need help debugging build failures? Start at https://github.com/r-lib/actions#where-to-find-help
 on:
   push:
-    branches:
-      - main
+    branches: [main, master]
   pull_request:
-    branches:
-      - main
+    branches: [main, master]
 
 name: lint
 
 jobs:
   lint:
-    runs-on: macOS-latest
-    env:
-      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}
-    steps:
-      - uses: actions/checkout@v2
-
-      - uses: r-lib/actions/setup-r@master
-
-      - name: Query dependencies
-        run: |
-          install.packages('remotes')
-          saveRDS(remotes::dev_package_deps(dependencies = TRUE), "".github/depends.Rds"", version = 2)
-          writeLines(sprintf(""R-%i.%i"", getRversion()$major, getRversion()$minor), "".github/R-version"")
-        shell: Rscript {0}
-
-      - name: Cache R packages
-        uses: actions/cache@v2
-        with:
-          path: ${{ env.R_LIBS_USER }}
-          key: ${{ runner.os }}-${{ hashFiles('.github/R-version') }}-1-${{ hashFiles('.github/depends.Rds') }}
-          restore-keys: ${{ runner.os }}-${{ hashFiles('.github/R-version') }}-1-
-
-      - name: Install dependencies
-        run: |
-          install.packages(c(""remotes""))
-          remotes::install_deps(dependencies = TRUE)
-          remotes::install_cran(""lintr"")
-        shell: Rscript {0}
-
-      - name: Install package
-        run: R CMD INSTALL .
-
-      - name: Lint
-        run: lintr::lint_package()
-        shell: Rscript {0}
+    uses: easystats/workflows/.github/workflows/lint.yaml@main

---FILE: .github/workflows/pkgdown.yaml---
@@ -13,38 +13,4 @@ name: pkgdown
 
 jobs:
   pkgdown:
-    runs-on: ubuntu-latest
-    # Only restrict concurrency for non-PR jobs
-    concurrency:
-      group: pkgdown-${{ github.event_name != 'pull_request' || github.run_id }}
-    env:
-      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}
-    steps:
-      - uses: actions/checkout@v2
-
-      - uses: r-lib/actions/setup-pandoc@v2
-        with:
-            pandoc-version: '2.19.2'
-
-      - uses: r-lib/actions/setup-r@v2
-        with:
-          use-public-rspm: true
-
-      - uses: r-lib/actions/setup-r-dependencies@v2
-        with:
-          extra-packages: |
-            local::.
-            r-lib/pkgdown
-          needs: website
-
-      - name: Build site
-        run: pkgdown::build_site_github_pages(new_process = FALSE, install = FALSE)
-        shell: Rscript {0}
-
-      - name: Deploy to GitHub pages ð
-        if: github.event_name != 'pull_request'
-        uses: JamesIves/github-pages-deploy-action@4.1.4
-        with:
-          clean: false
-          branch: gh-pages
-          folder: docs
+    uses: easystats/workflows/.github/workflows/pkgdown.yaml@main

---FILE: .github/workflows/render-readme.yaml---
@@ -1,30 +0,0 @@
-on:
-  push:
-    branches: main
-
-name: Render README
-
-jobs:
-  render:
-    name: Render README
-    runs-on: macOS-latest
-    env:
-      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}
-    steps:
-      - uses: actions/checkout@v2
-      - uses: r-lib/actions/setup-r@v2
-      - uses: r-lib/actions/setup-pandoc@v2
-      - name: Install rmarkdown, remotes, and the local package
-        run: |
-          install.packages(""remotes"")
-          remotes::install_local(""."")
-          remotes::install_cran(""rmarkdown"")
-        shell: Rscript {0}
-      - name: Render README
-        run: Rscript -e 'rmarkdown::render(""README.Rmd"")'
-      - name: Commit results
-        run: |
-          git config --local user.email ""actions@github.com""
-          git config --local user.name ""GitHub Actions""
-          git commit README.md -m 'Re-build README.Rmd' || echo ""No changes to commit""
-          git push origin || echo ""No changes to commit""

---FILE: .github/workflows/test-coverage.yaml---
@@ -10,22 +10,4 @@ name: test-coverage
 
 jobs:
   test-coverage:
-    runs-on: ubuntu-latest
-    env:
-      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}
-
-    steps:
-      - uses: actions/checkout@v2
-
-      - uses: r-lib/actions/setup-r@v2
-        with:
-          use-public-rspm: true
-
-      - uses: r-lib/actions/setup-r-dependencies@v2
-        with:
-          extra-packages: any::covr
-          needs: coverage
-
-      - name: Test coverage
-        run: covr::codecov()
-        shell: Rscript {0}
\ No newline at end of file
+    uses: easystats/workflows/.github/workflows/test-coverage.yaml@main

---FILE: DESCRIPTION---
@@ -57,10 +57,10 @@ Depends:
     R (>= 3.5)
 Imports:
     bayestestR (>= 0.12.1),
-    insight (>= 0.18.0),
-    parameters (>= 0.18.1),
-    performance (>= 0.9.1),
-    datawizard (>= 0.5.0),
+    insight (>= 0.18.2),
+    parameters (>= 0.18.2),
+    performance (>= 0.9.2),
+    datawizard (>= 0.5.1),
     stats,
     utils
 Suggests:

---FILE: R/convert_stat_to_anova.R---
@@ -83,7 +83,7 @@
 #' F_to_f(16.501, 1, 9)
 #' }
 #'
-#' #' @examplesIf require(lmerTest)
+#' #' @examplesIf require(emmeans)
 #' \donttest{
 #' ## Use with emmeans based contrasts
 #' ## --------------------------------

---FILE: README.Rmd---
@@ -34,7 +34,7 @@ The goal of this package is to provide utilities to work with indices of effect
 
 [![CRAN](https://www.r-pkg.org/badges/version/effectsize)](https://cran.r-project.org/package=effectsize/)
 [![effectsize status badge](https://easystats.r-universe.dev/badges/effectsize/)](https://easystats.r-universe.dev/)
-[![R-check](https://github.com/easystats/effectsize/workflows/R-check/badge.svg/)](https://github.com/easystats/effectsize/actions/)
+[![R-CMD-check](https://github.com/easystats/effectsize/workflows/R-CMD-check/badge.svg?branch=main)](https://github.com/easystats/effectsize/actions)
 [![pkgdown](https://github.com/easystats/effectsize/workflows/pkgdown/badge.svg/)](https://github.com/easystats/effectsize/actions/)
 [![Codecov test coverage](https://codecov.io/gh/easystats/effectsize/branch/main/graph/badge.svg/)](https://app.codecov.io/gh/easystats/effectsize?branch=main/)
 

---FILE: README.md---
@@ -5,6 +5,7 @@
 [![downloads](https://cranlogs.r-pkg.org/badges/effectsize)](https://cran.r-project.org/package=effectsize/)
 [![total](https://cranlogs.r-pkg.org/badges/grand-total/effectsize)](https://cran.r-project.org/package=effectsize/)
 [![status](https://tinyverse.netlify.com/badge/effectsize/)](https://CRAN.R-project.org/package=effectsize/)
+[![lifecycle](https://img.shields.io/badge/lifecycle-maturing-blue.svg)](https://lifecycle.r-lib.org/articles/stages.html)
 
 ***Significant is just not enough!***
 
@@ -17,7 +18,7 @@ conversion of indices such as Cohenâs *d*, *r*, odds-ratios, etc.
 [![CRAN](https://www.r-pkg.org/badges/version/effectsize)](https://cran.r-project.org/package=effectsize/)
 [![effectsize status
 badge](https://easystats.r-universe.dev/badges/effectsize/)](https://easystats.r-universe.dev/)
-[![R-check](https://github.com/easystats/effectsize/workflows/R-check/badge.svg/)](https://github.com/easystats/effectsize/actions/)
+[![R-CMD-check](https://github.com/easystats/effectsize/workflows/R-CMD-check/badge.svg?branch=main)](https://github.com/easystats/effectsize/actions)
 [![pkgdown](https://github.com/easystats/effectsize/workflows/pkgdown/badge.svg/)](https://github.com/easystats/effectsize/actions/)
 [![Codecov test
 coverage](https://codecov.io/gh/easystats/effectsize/branch/main/graph/badge.svg/)](https://app.codecov.io/gh/easystats/effectsize?branch=main/)
@@ -29,7 +30,7 @@ CRAN:
 install.packages(""effectsize"")
 ```
 
-Or you can install the latest development version `0.7.0.1` from
+Or you can install the latest development version `0.7.0.9999` from
 [*R-universe*](https://easystats.r-universe.dev):
 
 ``` r

---FILE: man/F_to_eta2.Rd---
@@ -190,7 +190,7 @@ F_to_epsilon2(16.501, 1, 9)
 F_to_f(16.501, 1, 9)
 }
 
-#' @examplesIf require(lmerTest)
+#' @examplesIf require(emmeans)
 \donttest{
 ## Use with emmeans based contrasts
 ## --------------------------------",True,True,Documentation / Formatting,7
easystats,effectsize,492928abc4577d4b56a303fc1b3dee5a1250f39b,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2022-08-31T10:45:04Z,GitHub,noreply@github.com,2022-08-31T10:45:04Z,"Humble offerings to @IndrajeetPatil  (#472)

* Create SUPPORT.md

* expect_error with regexp

* expect_warning/error with regexp

* lifecycle badge",.github/SUPPORT.md;README.Rmd;tests/testthat/test-convert_statistic.R;tests/testthat/test-effectsize.R;tests/testthat/test-eta_squared.R;tests/testthat/test-helpers.R;tests/testthat/test-interpret.R;tests/testthat/test-standardized_differences.R;tests/testthat/test-xtab.R,True,False,True,False,93,63,156,"---FILE: .github/SUPPORT.md---
@@ -0,0 +1,29 @@
+# Getting help with `{effectsize}`
+
+Thanks for using `{effectsize}`. Before filing an issue, there are a few places
+to explore and pieces to put together to make the process as smooth as possible.
+
+Start by making a minimal **repr**oducible **ex**ample using the
+[reprex](http://reprex.tidyverse.org/) package. If you haven't heard of or used
+reprex before, you're in for a treat! Seriously, reprex will make all of your
+R-question-asking endeavors easier (which is a pretty insane ROI for the five to
+ten minutes it'll take you to learn what it's all about). For additional reprex
+pointers, check out the [Get help!](https://www.tidyverse.org/help/) resource
+used by the tidyverse team.
+
+Armed with your reprex, the next step is to figure out where to ask:
+
+  * If it's a question: start with StackOverflow. There are more people there to answer questions.
+  * If it's a bug: you're in the right place, file an issue.
+  * If you're not sure: let's [discuss](https://github.com/easystats/effectsize/discussions) it and try to figure it out! If your
+    problem _is_ a bug or a feature request, you can easily return here and
+    report it.
+
+Before opening a new issue, be sure to [search issues and pull requests](https://github.com/easystats/effectsize/issues) to make sure the
+bug hasn't been reported and/or already fixed in the development version. By
+default, the search will be pre-populated with `is:issue is:open`. You can
+[edit the qualifiers](https://help.github.com/articles/searching-issues-and-pull-requests/)
+(e.g. `is:pr`, `is:closed`) as needed. For example, you'd simply
+remove `is:open` to search _all_ issues in the repo, open or closed.
+
+Thanks for your help!
\ No newline at end of file

---FILE: README.Rmd---
@@ -22,6 +22,7 @@ set.seed(111)
 [![downloads](https://cranlogs.r-pkg.org/badges/effectsize)](https://cran.r-project.org/package=effectsize/)
 [![total](https://cranlogs.r-pkg.org/badges/grand-total/effectsize)](https://cran.r-project.org/package=effectsize/)
 [![status](https://tinyverse.netlify.com/badge/effectsize/)](https://CRAN.R-project.org/package=effectsize/)
+[![lifecycle](https://img.shields.io/badge/lifecycle-maturing-blue.svg)](https://lifecycle.r-lib.org/articles/stages.html)
 
 
 ***Significant is just not enough!***

---FILE: tests/testthat/test-convert_statistic.R---
@@ -37,7 +37,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(res3$r, -res1$estimate, tolerance = 0.01, ignore_attr = TRUE)
     expect_equal(res3$CI_low, -res1$conf.int[2], tolerance = 0.02, ignore_attr = TRUE)
     expect_equal(res3$CI_high, -res1$conf.int[1], tolerance = 0.02, ignore_attr = TRUE)
-    expect_error(F_to_r(3, 2, 3))
+    expect_error(F_to_r(3, 2, 3), ""df"")
 
     res4 <- z_to_r(res1$statistic, res1$parameter)
     expect_equal(res4$r, res1$estimate, tolerance = 0.01, ignore_attr = TRUE)
@@ -60,17 +60,17 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(res$d, 0.970, tolerance = 0.01)
     expect_equal(res$CI_low, 0.464, tolerance = 0.01)
     expect_equal(res$CI_high, 1.469, tolerance = 0.01)
-    expect_error(F_to_d(16, 2, 68))
+    expect_error(F_to_d(16, 2, 68), ""df"")
 
     res <- z_to_d(4, 68)
     expect_equal(res$d, 0.970, tolerance = 0.01)
     expect_equal(res$CI_low, 0.494, tolerance = 0.01)
     expect_equal(res$CI_high, 1.446, tolerance = 0.01)
 
     # depr arg
-    expect_warning(F_to_d(4^2, 1, 68, pooled = TRUE))
-    expect_warning(t_to_d(4, 68, pooled = TRUE))
-    expect_warning(z_to_d(4, 68, pooled = TRUE))
+    expect_warning(F_to_d(4^2, 1, 68, pooled = TRUE), ""deprecated"")
+    expect_warning(t_to_d(4, 68, pooled = TRUE), ""deprecated"")
+    expect_warning(z_to_d(4, 68, pooled = TRUE), ""deprecated"")
   })
 
   test_that(""eta2"", {

---FILE: tests/testthat/test-effectsize.R---
@@ -22,7 +22,7 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     df <- data.frame(DV = c(x, y), g = rep(1:2, each = 10))
     model <- t.test(DV ~ g, data = df, var.equal = TRUE, mu = 3)
-    expect_warning(effectsize(model))
+    expect_warning(effectsize(model), ""data"")
 
     ## Auto convert y to factor
     Ts <- t.test(mtcars$mpg ~ mtcars$vs)
@@ -55,13 +55,13 @@ if (require(""testthat"") && require(""effectsize"")) {
     )
 
     # types
-    expect_error(effectsize(Xsq1, type = ""phi""))
+    expect_error(effectsize(Xsq1, type = ""phi""), ""appropriate"")
     expect_equal(effectsize(Xsq1), cramers_v(contingency_table))
     expect_equal(effectsize(Xsq1, type = ""w""), w <- cohens_w(contingency_table))
     expect_equal(cohens_w(Xsq1), w)
 
-    expect_error(effectsize(Xsq1, type = ""riskratio""))
-    expect_error(riskratio(Xsq1))
+    expect_error(effectsize(Xsq1, type = ""riskratio""), ""only"")
+    expect_error(riskratio(Xsq1), ""only"")
 
     contingency_table22 <- contingency_table[1:2, 1:2]
     Xsq4 <- chisq.test(contingency_table22)
@@ -85,21 +85,21 @@ if (require(""testthat"") && require(""effectsize"")) {
     expected.dfc <<- c(0.165, 0.835)
 
     x <- chisq.test(x = observed.dfc, p = expected.dfc)
-    expect_error(effectsize(x, type = ""v""))
-    expect_error(effectsize(x, type = ""phi""))
+    expect_error(effectsize(x, type = ""v""), ""goodness"")
+    expect_error(effectsize(x, type = ""phi""), ""appropriate"")
     expect_equal(effectsize(x), effectsize(x, type = ""chi""))
     expect_equal(effectsize(x, type = ""chi""), nchi <- normalized_chi(observed.dfc, p = expected.dfc))
     expect_equal(normalized_chi(x), nchi)
   })
 
   test_that(""cor.test / other"", {
     r_ <- cor.test(iris$Sepal.Width, iris$Sepal.Length)
-    expect_warning(effectsize(r_))
+    expect_warning(effectsize(r_), ""parameters"")
   })
 
   test_that(""one way"", {
     onew <- oneway.test(mpg ~ cyl, mtcars)
-    expect_warning(effectsize(onew))
+    expect_warning(effectsize(onew), ""var"")
 
 
     onew <- oneway.test(mpg ~ cyl, mtcars, var.equal = TRUE)

---FILE: tests/testthat/test-eta_squared.R---
@@ -14,12 +14,12 @@ if (require(""testthat"") && require(""effectsize"")) {
       F_to_eta2(mod1[[""F value""]], mod1$Df, mod1$DenDF),
       ignore_attr = TRUE
     )
-    expect_warning(eta_squared(mod1, partial = FALSE))
-    expect_warning(eta_squared(mod1, generalized = TRUE))
+    expect_warning(eta_squared(mod1, partial = FALSE), ""partial"")
+    expect_warning(eta_squared(mod1, generalized = TRUE), ""generalized"")
 
     mod2 <- mod1
     mod2$`F value` <- NULL
-    expect_error(eta_squared(mod2))
+    expect_error(eta_squared(mod2), ""does not"")
   })
 
   # aov ---------------------------------------------------------------------

---FILE: tests/testthat/test-helpers.R---
@@ -6,7 +6,7 @@ if (require(""testthat"") && require(""effectsize"")) {
   })
 
   test_that(""validate data from formula"", {
-    expect_error(cohens_d(mpg ~ cyl, data = mtcars))
+    expect_error(cohens_d(mpg ~ cyl, data = mtcars), ""exactly"")
     expect_error(cohens_d(mpg ~ cyl, data = mtcars, subset = cyl %in% c(4, 6)), regexp = NA)
 
     d1 <- cohens_d(mpg ~ cyl,
@@ -41,13 +41,13 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(d1, d3)
     expect_equal(d1, d4)
 
-    expect_error(rank_biserial(mpg ~ cyl, data = mtcars))
+    expect_error(rank_biserial(mpg ~ cyl, data = mtcars), ""exactly"")
     expect_error(rank_biserial(mpg ~ cyl, data = mtcars, subset = cyl %in% c(4, 6)), regexp = NA)
 
-    expect_error(sd_pooled(mpg ~ cyl, data = mtcars))
+    expect_error(sd_pooled(mpg ~ cyl, data = mtcars), ""exactly"")
     expect_error(sd_pooled(mpg ~ cyl, data = mtcars, subset = cyl %in% c(4, 6)), regexp = NA)
 
-    expect_error(cles(mpg ~ cyl, data = mtcars))
+    expect_error(cles(mpg ~ cyl, data = mtcars), ""exactly"")
     expect_error(cles(mpg ~ cyl, data = mtcars, subset = cyl %in% c(4, 6)), regexp = NA)
 
     d <- expand.grid(id = 1:30, g = 1:4)

---FILE: tests/testthat/test-interpret.R---
@@ -9,8 +9,8 @@ if (require(""testthat"") && require(""effectsize"")) {
       interpret(c(0.01, 0.005, 0.08), rules_grid)[1:3],
       c(""very significant"", ""very significant"", ""not significant"")
     )
-    expect_error(interpret_r(0.6, rules(c(0.5), c(""A"", ""B"", ""C""))))
-    expect_error(interpret_r(0.6, rules(c(0.5, 0.2, 0.7), c(""A"", ""B"", ""C"", ""D""))))
+    expect_error(rules(c(0.5), c(""A"", ""B"", ""C"")), ""Too many"")
+    expect_error(rules(c(0.5, 0.2, 0.7), c(""A"", ""B"", ""C"", ""D"")), ""sorted"")
 
 
     r1 <- rules(c(0, 1), labels = c(""some"", ""few"", ""many""))
@@ -28,7 +28,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(interpret_r(0.7, ""evans1996"")[1], ""strong"")
     expect_equal(interpret_r(c(0.5, -0.08), ""cohen1988"")[1:2], c(""large"", ""very small""))
     expect_equal(interpret_r(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_r(0.6, ""DUPA""))
+    expect_error(interpret_r(0.6, ""DUPA""), ""must be"")
   })
 
 
@@ -38,7 +38,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(interpret_p(0.08)[1], ""not significant"")
     expect_equal(interpret_p(c(0.01, 0.08))[1:2], c(""significant"", ""not significant""))
     expect_equal(interpret_p(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_p(0.6, ""DUPA""))
+    expect_error(interpret_p(0.6, ""DUPA""), ""must be"")
   })
 
 
@@ -53,14 +53,14 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(interpret_cohens_d(c(0.45, 0.85), ""cohen1988"")[1:2], c(""small"", ""large""))
     expect_equal(interpret_cohens_d(c(0.45, 0.85), ""lovakov2021"")[1:2], c(""medium"", ""large""))
     expect_equal(interpret_cohens_d(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_cohens_d(0.6, ""DUPA""))
+    expect_error(interpret_cohens_d(0.6, ""DUPA""), ""must be"")
   })
 
   test_that(""interpret_cohens_g"", {
     expect_equal(interpret_cohens_g(0.021)[1], ""very small"")
     expect_equal(interpret_cohens_g(c(0.10, 0.35), ""cohen1988"")[1:2], c(""small"", ""large""))
     expect_equal(interpret_cohens_g(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_cohens_g(0.6, ""DUPA""))
+    expect_error(interpret_cohens_g(0.6, ""DUPA""), ""must be"")
   })
 
 
@@ -69,7 +69,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(interpret_rope(c(0.50, 1), ci = 0.9)[1:2], c(""undecided"", ""negligible""))
     expect_equal(interpret_rope(c(0.98, 0.991), ci = 1)[1:2], c(""probably negligible"", ""negligible""))
     expect_equal(interpret_rope(0.6, , rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_rope(0.6, , ""DUPA""))
+    expect_error(interpret_rope(0.6, , ""DUPA""), ""must be"")
   })
 
 
@@ -78,7 +78,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(interpret_oddsratio(c(1, 3))[1:2], c(""very small"", ""small""))
     expect_equal(interpret_oddsratio(c(1, 3), ""cohen1988"")[1:2], c(""very small"", ""medium""))
     expect_equal(interpret_oddsratio(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_oddsratio(0.6, ""DUPA""))
+    expect_error(interpret_oddsratio(0.6, ""DUPA""), ""must be"")
   })
 
 
@@ -88,12 +88,12 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(interpret_r2(c(0.1, 0.4), ""chin1998"")[1:2], c(""very weak"", ""moderate""))
     expect_equal(interpret_r2(c(0.1, 0.4), ""hair2011"")[1:2], c(""very weak"", ""weak""))
     expect_equal(interpret_r2(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_r2(0.6, ""DUPA""))
+    expect_error(interpret_r2(0.6, ""DUPA""), ""must be"")
   })
 
 
   test_that(""interpret_bf"", {
-    expect_warning(interpret_bf(-2))
+    expect_warning(interpret_bf(-2), ""Negative"")
     expect_equal(interpret_bf(1)[1], ""no evidence against or in favour of"")
     expect_equal(
       interpret_bf(c(0.8, 3.5), ""jeffreys1961"")[1:2],
@@ -104,7 +104,7 @@ if (require(""testthat"") && require(""effectsize"")) {
       c(""weak evidence against"", ""positive evidence in favour of"")
     )
     expect_equal(interpret_bf(2, rules(c(0.5), c(""A"", ""B"")))[1], ""B evidence in favour of"")
-    expect_error(interpret_bf(2, ""DUPA""))
+    expect_error(interpret_bf(2, ""DUPA""), ""must be"")
 
     skip_on_cran() # just in case there are changes in insight
     bf <- c(10^seq(-4, 4), NA)
@@ -126,7 +126,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(interpret_omega_squared(0.1)[1], ""medium"")
     expect_equal(interpret_omega_squared(c(0.1, 0.25))[1:2], c(""medium"", ""large""))
     expect_equal(interpret_omega_squared(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_omega_squared(0.6, ""DUPA""))
+    expect_error(interpret_omega_squared(0.6, ""DUPA""), ""must be"")
 
     # these should be same
     expect_equal(interpret_eta_squared(0.1)[1], interpret_omega_squared(0.1)[1])
@@ -144,7 +144,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     )
     expect_equal(interpret_kendalls_w(0.9)[1], ""almost perfect agreement"")
     expect_equal(interpret_kendalls_w(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_kendalls_w(0.6, ""DUPA""))
+    expect_error(interpret_kendalls_w(0.6, ""DUPA""), ""must be"")
   })
 
 
@@ -153,15 +153,15 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(interpret_rhat(c(1, 1.02))[1:2], c(""converged"", ""failed""))
     expect_equal(interpret_rhat(c(1, 1.02), ""gelman1992"")[1:2], c(""converged"", ""converged""))
     expect_equal(interpret_rhat(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_rhat(0.6, ""DUPA""))
+    expect_error(interpret_rhat(0.6, ""DUPA""), ""must be"")
   })
 
 
   test_that(""interpret_ess"", {
     expect_equal(interpret_ess(1000)[1], ""sufficient"")
     expect_equal(interpret_ess(c(1000, 800))[1:2], c(""sufficient"", ""insufficient""))
     expect_equal(interpret_ess(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_ess(0.6, ""DUPA""))
+    expect_error(interpret_ess(0.6, ""DUPA""), ""must be"")
   })
 
 
@@ -189,16 +189,16 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(interpret_rmsea(0.6, cr), ""B"", ignore_attr = TRUE)
     expect_equal(interpret_srmr(0.6, cr), ""B"", ignore_attr = TRUE)
 
-    expect_error(interpret_gfi(0.6, ""DUPA""))
-    expect_error(interpret_agfi(0.6, ""DUPA""))
-    expect_error(interpret_nfi(0.6, ""DUPA""))
-    expect_error(interpret_nnfi(0.6, ""DUPA""))
-    expect_error(interpret_cfi(0.6, ""DUPA""))
-    expect_error(interpret_rfi(0.6, ""DUPA""))
-    expect_error(interpret_ifi(0.6, ""DUPA""))
-    expect_error(interpret_pnfi(0.6, ""DUPA""))
-    expect_error(interpret_rmsea(0.6, ""DUPA""))
-    expect_error(interpret_srmr(0.6, ""DUPA""))
+    expect_error(interpret_gfi(0.6, ""DUPA""), ""must be"")
+    expect_error(interpret_agfi(0.6, ""DUPA""), ""must be"")
+    expect_error(interpret_nfi(0.6, ""DUPA""), ""must be"")
+    expect_error(interpret_nnfi(0.6, ""DUPA""), ""must be"")
+    expect_error(interpret_cfi(0.6, ""DUPA""), ""must be"")
+    expect_error(interpret_rfi(0.6, ""DUPA""), ""must be"")
+    expect_error(interpret_ifi(0.6, ""DUPA""), ""must be"")
+    expect_error(interpret_pnfi(0.6, ""DUPA""), ""must be"")
+    expect_error(interpret_rmsea(0.6, ""DUPA""), ""must be"")
+    expect_error(interpret_srmr(0.6, ""DUPA""), ""must be"")
 
     skip_on_cran()
     skip_if_not_installed(""lavaan"")
@@ -219,20 +219,20 @@ if (require(""testthat"") && require(""effectsize"")) {
   test_that(""interpret_icc"", {
     expect_equal(interpret_icc(c(0.45, 0.55, 0.8, 0.95)), c(""poor"", ""moderate"", ""good"", ""excellent""), ignore_attr = TRUE)
     expect_equal(interpret_icc(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_icc(0.6, ""DUPA""))
+    expect_error(interpret_icc(0.6, ""DUPA""), ""must be"")
   })
 
   test_that(""interpret_vif"", {
     expect_equal(interpret_vif(c(1, 5.5, 10)), c(""low"", ""moderate"", ""high""), ignore_attr = TRUE)
     expect_equal(interpret_icc(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_icc(0.6, ""DUPA""))
+    expect_error(interpret_icc(0.6, ""DUPA""), ""must be"")
   })
 
   test_that(""interpret_pd"", {
     expect_equal(interpret_pd(c(0.9, 0.99)), c(""not significant"", ""significant""), ignore_attr = TRUE)
     expect_equal(interpret_pd(c(0.9, 0.99), ""makowski2019""), c(""uncertain"", ""likely existing""), ignore_attr = TRUE)
     expect_equal(interpret_pd(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
-    expect_error(interpret_pd(0.6, ""DUPA""))
+    expect_error(interpret_pd(0.6, ""DUPA""), ""must be"")
   })
 
   # interpret effectsize_table ----
@@ -252,6 +252,6 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_output(print(V_), ""large"")
     expect_output(print(V_), ""Interpretation rule: funder2019"")
 
-    expect_error(interpret(d))
+    expect_error(interpret(d), ""MUST specify"")
   })
 }

---FILE: tests/testthat/test-standardized_differences.R---
@@ -34,14 +34,14 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_error(cohens_d(df$a ~ df$c), regexp = NA)
     expect_equal(cohens_d(""exp_a"", ""c"", data = df), cohens_d(exp(a) ~ c, data = df))
 
-    expect_error(cohens_d(a ~ b, data = df))
-    expect_error(cohens_d(a ~ d, data = df))
-    expect_error(cohens_d(""a"", ""d"", data = df))
-    expect_error(cohens_d(""c"", ""c"", data = df))
-    expect_error(cohens_d(a2, df$c))
-    expect_error(cohens_d(""a"", ""aa"", data = df))
-
-    expect_warning(cohens_d(""b"", ""e"", data = df))
+    expect_error(cohens_d(a ~ b, data = df), ""exactly"")
+    expect_error(cohens_d(a ~ d, data = df), ""exactly"")
+    expect_error(cohens_d(""a"", ""d"", data = df), ""exactly"")
+    expect_error(cohens_d(""c"", ""c"", data = df), ""non-numeric"")
+    expect_error(cohens_d(a2, df$c), ""length"")
+    expect_error(cohens_d(""a"", ""aa"", data = df), ""missing"")
+
+    expect_warning(cohens_d(""b"", ""e"", data = df), ""convert"")
   })
 
   test_that(""cohens d - grouping character vector"", {
@@ -107,8 +107,8 @@ if (require(""testthat"") && require(""effectsize"")) {
 
   test_that(""glass_delta"", {
     # must be 2 samples
-    expect_error(glass_delta(1:10))
-    expect_error(glass_delta(wt, data = mtcars))
+    expect_error(glass_delta(1:10), ""two"")
+    expect_error(glass_delta(""wt"", data = mtcars), ""two"")
 
     x <- glass_delta(wt ~ am, data = mtcars)
     expect_equal(colnames(x)[1], ""Glass_delta"")

---FILE: tests/testthat/test-xtab.R---
@@ -11,7 +11,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(res$CI_low, 0.051, tolerance = 0.01)
     expect_equal(res$CI_high, 1)
 
-    expect_error(phi(contingency_table))
+    expect_error(phi(contingency_table), ""appropriate"")
 
 
     ## Size does not affect estimate
@@ -67,7 +67,7 @@ if (require(""testthat"") && require(""effectsize"")) {
       c(50, 50, 0),
       c(100, 100, 0)
     )
-    expect_error(cramers_v(xtab))
+    expect_error(cramers_v(xtab), ""empty"")
 
     ## 0
     xtab <- table(mtcars$am, mtcars$vs)
@@ -79,7 +79,7 @@ if (require(""testthat"") && require(""effectsize"")) {
 
 
   test_that(""goodness of fit"", {
-    expect_error(cramers_v(table(mtcars$cyl)))
+    expect_error(cramers_v(table(mtcars$cyl)), ""goodness"")
 
     w1 <- cohens_w(table(mtcars$cyl), p = c(0.34375, 0.21875, 0.43750))
     w2 <- cohens_w(table(mtcars$cyl), p = c(0.8, 0.1, 0.1))
@@ -149,7 +149,7 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     ## OR
     data(""mtcars"")
-    expect_error(oddsratio(mtcars$am, mtcars$cyl))
+    expect_error(oddsratio(mtcars$am, mtcars$cyl), ""only"")
 
     m <- glm(am ~ I(cyl > 4), data = mtcars, family = binomial())
     log_or <- oddsratio(mtcars$am, mtcars$cyl > 4, log = TRUE)",True,True,Documentation / Formatting,6
easystats,effectsize,58722cc1c3a85f7580b5290cde0080c37c9c15c9,Indrajeet Patil,patilindrajeet.science@gmail.com,2022-08-26T05:04:54Z,GitHub,noreply@github.com,2022-08-26T05:04:54Z,"Leave out function call in condition messages (#469)

- https://github.com/easystats/easystats/issues/263
- style
- sundry CI/CD",.github/workflows/pkgdown.yaml;R/convert_between_OR_to_RR.R;R/convert_between_common_language.R;R/convert_stat_chisq.R;R/convert_stat_to_anova.R;R/convert_stat_to_d.R;R/convert_stat_to_r.R;R/effectsize.BFBayesFactor.R;R/effectsize.htest.R;R/equivalence_test.R;R/eta_squared.R;R/eta_squared_posterior.R;R/interpret.R;R/interpret_bf.R;R/is_effectsize_name.R;R/rank_effectsizes.R;R/xtab.R;man/phi.Rd;tests/testthat/test-effectsize.R;tests/testthat/test-xtab.R,False,True,True,False,206,190,396,"---FILE: .github/workflows/pkgdown.yaml---
@@ -24,7 +24,7 @@ jobs:
 
       - uses: r-lib/actions/setup-pandoc@v2
         with:
-            pandoc-version: '2.19.1'
+            pandoc-version: '2.19.2'
 
       - uses: r-lib/actions/setup-r@v2
         with:
@@ -33,7 +33,8 @@ jobs:
       - uses: r-lib/actions/setup-r-dependencies@v2
         with:
           extra-packages: |
-              local::.
+            local::.
+            r-lib/pkgdown
           needs: website
 
       - name: Build site
@@ -46,4 +47,4 @@ jobs:
         with:
           clean: false
           branch: gh-pages
-          folder: docs
\ No newline at end of file
+          folder: docs

---FILE: R/convert_between_OR_to_RR.R---
@@ -50,7 +50,7 @@ oddsratio_to_riskratio.numeric <- function(OR, p0, log = FALSE, ...) {
 #' @export
 oddsratio_to_riskratio.default <- function(OR, p0, log = FALSE, ...) {
   mi <- .get_model_info(OR, ...)
-  if (!mi$is_binomial || !mi$is_logit) stop(""Model must a binomial model with logit-link (logistic regression)"")
+  if (!mi$is_binomial || !mi$is_logit) stop(""Model must a binomial model with logit-link (logistic regression)"", call. = FALSE)
 
   RR <- parameters::model_parameters(OR, exponentiate = !log, effects = ""fixed"", ...)
   RR$SE <- NULL
@@ -78,7 +78,7 @@ oddsratio_to_riskratio.default <- function(OR, p0, log = FALSE, ...) {
     )
 
   if (any(c(""CI_low"", ""CI_high"") %in% colnames(RR))) {
-    warning(""CIs are back-transformed from the logit scale."")
+    warning(""CIs are back-transformed from the logit scale."", call. = FALSE)
   }
 
   RR[RR$Parameter == ""(Intercept)"", ""Coefficient""] <- p0

---FILE: R/convert_between_common_language.R---
@@ -57,7 +57,7 @@ d_to_cles.effectsize_difference <- function(d) {
   if (!any(colnames(d) %in% c(""Cohens_d"", ""Hedges_g"")) ||
     attr(d, ""paired"") ||
     !attr(d, ""pooled_sd"")) {
-    stop(""Common language effect size only applicable to 2-sample Cohen's d with pooled SD."")
+    stop(""Common language effect size only applicable to 2-sample Cohen's d with pooled SD."", call. = FALSE)
   }
 
   out <- lapply(
@@ -105,7 +105,7 @@ rb_to_cles.numeric <- function(rb) {
 rb_to_cles.effectsize_difference <- function(rb) {
   if (!any(colnames(rb) == ""r_rank_biserial"") ||
     attr(rb, ""paired"")) {
-    stop(""Common language effect size only applicable to 2-sample rank-biserial correlation."")
+    stop(""Common language effect size only applicable to 2-sample rank-biserial correlation."", call. = FALSE)
   }
 
   out <- lapply(

---FILE: R/convert_stat_chisq.R---
@@ -97,7 +97,7 @@ chisq_to_phi <- function(chisq, n, nrow = 2, ncol = 2, ci = 0.95, alternative =
   if (is.null(dont_stop)) dont_stop <- FALSE
 
   if (!dont_stop && (nrow != 2 || ncol != 2)) {
-    stop(""Phi is not appropriate for non-2x2 tables."")
+    stop(""Phi is not appropriate for non-2x2 tables."", call. = FALSE)
   }
 
   if (adjust || is.numeric(ci)) {
@@ -241,14 +241,14 @@ chisq_to_normalized <- function(chisq, n, nrow, ncol, p,
   }
 
   # if (!1 %in% c(nrow, ncol)) {
-  #   stop(""Correlation coefficiant is only applicable to goodness of fit tests."")
+  #   stop(""Correlation coefficiant is only applicable to goodness of fit tests."", call. = FALSE)
   # }
 
   # if (is.null(p)) {
   #   p <- rep(1, pmax(nrow, ncol))
   # }
 
-  if (!length(p) %in% c(ncol, nrow)) stop(""Length of `p` must match number of rows/columns."")
+  if (!length(p) %in% c(ncol, nrow)) stop(""Length of `p` must match number of rows/columns."", call. = FALSE)
   p <- p / sum(p)
 
   q <- min(p)

---FILE: R/convert_stat_to_anova.R---
@@ -229,7 +229,7 @@ t_to_f2 <- function(t, df_error, ci = 0.95, alternative = ""greater"", squared = T
     eta2 = data.frame(Eta2_partial = (f * df) / (f * df + df_error)),
     epsilon2 = data.frame(Epsilon2_partial = ((f - 1) * df) / (f * df + df_error)),
     omega2 = data.frame(Omega2_partial = ((f - 1) * df) / (f * df + df_error + 1)),
-    stop(""'es' must be 'eta2', 'epsilon2', or 'omega2'."")
+    stop(""'es' must be 'eta2', 'epsilon2', or 'omega2'."", call. = FALSE)
   )
 
   ci_method <- NULL

---FILE: R/convert_stat_to_d.R---
@@ -115,7 +115,7 @@ z_to_d <- function(z, n, paired = FALSE, ci = 0.95, alternative = ""two.sided"", p
 #' @export
 F_to_d <- function(f, df, df_error, paired = FALSE, ci = 0.95, alternative = ""two.sided"", ...) {
   if (df > 1) {
-    stop(""Cannot convert F with more than 1 df to (partial) r."")
+    stop(""Cannot convert F with more than 1 df to (partial) r."", call. = FALSE)
   }
   t_to_d(sqrt(f), df_error, paired = paired, ci = ci, alternative = alternative, ...)
 }

---FILE: R/convert_stat_to_r.R---
@@ -186,7 +186,7 @@ z_to_r <- function(z, n, ci = 0.95, alternative = ""two.sided"", ...) {
 #' @export
 F_to_r <- function(f, df, df_error, ci = 0.95, alternative = ""two.sided"", ...) {
   if (df > 1) {
-    stop(""Cannot convert F with more than 1 df to r."")
+    stop(""Cannot convert F with more than 1 df to r."", call. = FALSE)
   }
   t_to_r(sqrt(f), df_error, ci = ci, alternative = alternative, ...)
 }

---FILE: R/effectsize.BFBayesFactor.R---
@@ -22,7 +22,7 @@ effectsize.BFBayesFactor <- function(model, type = NULL, verbose = TRUE, test =
   } else if (inherits(model@numerator[[1]], ""BFproportion"")) {
     pars <- .effectsize_proportionBF(model, type = type, verbose = verbose)
   } else {
-    stop(""No effect size for this type of 'BayesFactor' object."")
+    stop(""No effect size for this type of 'BayesFactor' object."", call. = FALSE)
   }
 
   # Clean up

---FILE: R/effectsize.htest.R---
@@ -18,7 +18,7 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
     .effectsize_friedman.test(model, type = type, verbose = verbose, ...)
   } else {
     if (verbose) {
-      warning(""This 'htest' method is not (yet?) supported.\n"",
+      warning(""This 'htest' method is not (yet?, call. = FALSE) supported.\n"",
         ""Returning 'parameters::model_parameters(model)'."",
         call. = FALSE
       )
@@ -47,7 +47,7 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
 
   if (approx) {
     if (verbose) {
-      warning(""Unable to retrieve data from htest object. Using t_to_d() approximation."")
+      warning(""Unable to retrieve data from htest object. Using t_to_d() approximation."", call. = FALSE)
     }
 
     f <- t_to_d
@@ -80,7 +80,7 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
 
     if (type == ""cles"") {
       if (args$paired || !args$pooled_sd) {
-        stop(""Common language effect size only applicable to 2-sample Cohen's d with pooled SD."")
+        stop(""Common language effect size only applicable to 2-sample Cohen's d with pooled SD."", call. = FALSE)
       }
       args$pooled_sd <- args$paired <- NULL
     }
@@ -260,7 +260,7 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
 
   if (type == ""cles"") {
     if (args$paired) {
-      stop(""Common language effect size only applicable to 2-sample rank-biserial correlation."")
+      stop(""Common language effect size only applicable to 2-sample rank-biserial correlation."", call. = FALSE)
     }
     args$paired <- NULL
     args$parametric <- FALSE

---FILE: R/equivalence_test.R---
@@ -111,11 +111,11 @@ equivalence_test.effectsize_table <- function(x,
 
   if (range[1] < x_es_info$lb) {
     range[1] <- x_es_info$lb
-    warning(""Lower bound set to "", range[1], ""."", immediate. = FALSE)
+    warning(""Lower bound set to "", range[1], ""."", immediate. = FALSE, call. = FALSE)
   }
   if (range[2] > x_es_info$ub) {
     range[2] <- x_es_info$ub
-    warning(""Upper bound set to "", range[2], ""."", immediate. = FALSE)
+    warning(""Upper bound set to "", range[2], ""."", immediate. = FALSE, call. = FALSE)
   }
 
   # Test ---

---FILE: R/eta_squared.R---
@@ -370,7 +370,7 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
   }
 
   if (!""Residuals"" %in% aov_table$Parameter) {
-    stop(insight::format_message(""No residuals data found - cannot compute effect size.""))
+    stop(insight::format_message(""No residuals data found - cannot compute effect size.""), call. = FALSE)
   }
 
 
@@ -518,7 +518,7 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
   }
 
   if (!""Residuals"" %in% aov_table$Parameter) {
-    stop(insight::format_message(""No residuals data found - cannot compute effect size.""))
+    stop(insight::format_message(""No residuals data found - cannot compute effect size.""), call. = FALSE)
   }
 
 
@@ -688,7 +688,7 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
       aov_table[[""F""]] <- aov_table[[""t""]]^2
       aov_table[[""df""]] <- 1
     } else {
-      stop(insight::format_message(""ANOVA table does not have F values - cannot compute effect size.""))
+      stop(insight::format_message(""ANOVA table does not have F values - cannot compute effect size.""), call. = FALSE)
     }
   }
 
@@ -897,7 +897,7 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
   }
 
   if (!any(F.nm %in% colnames(model)) || !any(df.nm %in% colnames(model))) {
-    stop(insight::format_message(""ANOVA table does not have F values or degrees of freedom - cannot compute effect size.""))
+    stop(insight::format_message(""ANOVA table does not have F values or degrees of freedom - cannot compute effect size.""), call. = FALSE)
   }
 
   Fi <- F.nm[F.nm %in% colnames(model)]

---FILE: R/eta_squared_posterior.R---
@@ -31,7 +31,7 @@ eta_squared_posterior.stanreg <- function(model,
 
   mi <- .get_model_info(model, ...)
   if (!mi$is_linear || mi$is_multivariate) {
-    stop(""Computation of Eta Squared is only applicable to univariate linear models."")
+    stop(""Computation of Eta Squared is only applicable to univariate linear models."", call. = FALSE)
   }
 
   if (partial && mi$is_mixed) {

---FILE: R/interpret.R---
@@ -38,14 +38,14 @@ rules <- function(values, labels = NULL, name = NULL, right = TRUE) {
 
   # Sanity checks
   if (length(labels) < length(values)) {
-    stop(""There cannot be less labels than reference values!"")
+    stop(""There cannot be less labels than reference values!"", call. = FALSE)
   } else if (length(labels) > length(values) + 1) {
-    stop(""Too many labels for the number of reference values!"")
+    stop(""Too many labels for the number of reference values!"", call. = FALSE)
   }
 
   if (length(values) == length(labels) - 1) {
     if (is.unsorted(values)) {
-      stop(""Reference values must be sorted."")
+      stop(""Reference values must be sorted."", call. = FALSE)
     }
   } else {
     right <- NULL
@@ -157,7 +157,7 @@ interpret.numeric <- function(x, rules, name = attr(rules, ""rule_name""), ...) {
 #' @rdname interpret
 #' @export
 interpret.effectsize_table <- function(x, rules, ...) {
-  if (missing(rules)) stop(""You MUST specify the rules of interpretation!"")
+  if (missing(rules)) stop(""You MUST specify the rules of interpretation!"", call. = FALSE)
 
   es_name <- colnames(x)[is_effectsize_name(colnames(x))]
   value <- x[[es_name]]

---FILE: R/interpret_bf.R---
@@ -51,7 +51,7 @@ interpret_bf <- function(bf,
   if (log) bf <- exp(bf)
 
   if (any(bf < 0, na.rm = TRUE)) {
-    warning(""Negative BFs detected. These are not possible. Ignoring."")
+    warning(""Negative BFs detected. These are not possible. Ignoring."", call. = FALSE)
     bf[bf < 0] <- NA
   }
 

---FILE: R/is_effectsize_name.R---
@@ -41,65 +41,66 @@ get_effectsize_label <- function(x, ignore_case = TRUE) {
 #' Can always add more info here if need be...
 #'
 #' @keywords internal
-es_info <- matrix(c(
-  ## Diffs
-  ""Cohens_d"", ""Cohen's d"", ""twotail"", -Inf, Inf, 0,
-  ""Hedges_g"", ""Hedges' g"", ""twotail"", -Inf, Inf, 0,
-  ""Glass_delta"", ""Glass' delta"", ""twotail"", -Inf, Inf, 0,
+es_info <- matrix(
+  c(
+    ## Diffs
+    ""Cohens_d"", ""Cohen's d"", ""twotail"", -Inf, Inf, 0,
+    ""Hedges_g"", ""Hedges' g"", ""twotail"", -Inf, Inf, 0,
+    ""Glass_delta"", ""Glass' delta"", ""twotail"", -Inf, Inf, 0,
 
-  ## xtab
-  ""Cramers_v"", ""Cramer's V"", ""onetail"", 0, 1, 0,
-  ""Cramers_v_adjusted"", ""Cramer's V (adj.)"", ""onetail"", 0, 1, 0,
-  ""phi"", ""Phi"", ""onetail"", 0, 1, 0,
-  ""phi_adjusted"", ""Phi (adj.)"", ""onetail"", 0, 1, 0,
-  ""Pearsons_c"", ""Pearson's C"", ""onetail"", 0, 1, 0,
-  ""Cohens_w"", ""Cohen's w"", ""onetail"", 0, Inf, 0,
-  ""normalized_chi"", ""Norm. Chi"", ""onetail"", 0, 1, 0,
-  ""Cohens_g"", ""Cohen's g"", ""onetail"", -0.5, 0.5, 0,
-  ""Cohens_h"", ""Cohen's h"", ""twotail"", -pi, pi, 0,
-  ""Odds_ratio"", ""Odds ratio"", ""twotail"", 0, Inf, 1,
-  ""log_Odds_ratio"", ""log(Odds ratio)"", ""twotail"", -Inf, Inf, 0,
-  ""Risk_ratio"", ""Risk ratio"", ""twotail"", 0, Inf, 1,
-  ""log_Risk_ratio"", ""log(Risk ratio)"", ""twotail"", -Inf, Inf, 0,
+    ## xtab
+    ""Cramers_v"", ""Cramer's V"", ""onetail"", 0, 1, 0,
+    ""Cramers_v_adjusted"", ""Cramer's V (adj.)"", ""onetail"", 0, 1, 0,
+    ""phi"", ""Phi"", ""onetail"", 0, 1, 0,
+    ""phi_adjusted"", ""Phi (adj.)"", ""onetail"", 0, 1, 0,
+    ""Pearsons_c"", ""Pearson's C"", ""onetail"", 0, 1, 0,
+    ""Cohens_w"", ""Cohen's w"", ""onetail"", 0, Inf, 0,
+    ""normalized_chi"", ""Norm. Chi"", ""onetail"", 0, 1, 0,
+    ""Cohens_g"", ""Cohen's g"", ""onetail"", -0.5, 0.5, 0,
+    ""Cohens_h"", ""Cohen's h"", ""twotail"", -pi, pi, 0,
+    ""Odds_ratio"", ""Odds ratio"", ""twotail"", 0, Inf, 1,
+    ""log_Odds_ratio"", ""log(Odds ratio)"", ""twotail"", -Inf, Inf, 0,
+    ""Risk_ratio"", ""Risk ratio"", ""twotail"", 0, Inf, 1,
+    ""log_Risk_ratio"", ""log(Risk ratio)"", ""twotail"", -Inf, Inf, 0,
 
-  ## ANOVA
-  ""Eta2"", ""Eta2"", ""onetail"", 0, 1, 0,
-  ""Eta2_partial"", ""Eta2 (partial)"", ""onetail"", 0, 1, 0,
-  ""Eta2_generalized"", ""Eta2 (generalized)"", ""onetail"", 0, 1, 0,
-  ""Epsilon2"", ""Epsilon2"", ""onetail"", 0, 1, 0,
-  ""Epsilon2_partial"", ""Epsilon2 (partial)"", ""onetail"", 0, 1, 0,
-  ""Omega2"", ""Omega2"", ""onetail"", 0, 1, 0,
-  ""Omega2_partial"", ""Omega2 (partial)"", ""onetail"", 0, 1, 0,
-  ""Cohens_f"", ""Cohen's f"", ""onetail"", 0, Inf, 0,
-  ""Cohens_f_partial"", ""Cohen's f (partial)"", ""onetail"", 0, Inf, 0,
-  ""Cohens_f2"", ""Cohen's f2"", ""onetail"", 0, Inf, 0,
-  ""Cohens_f2_partial"", ""Cohen's f2 (partial)"", ""onetail"", 0, Inf, 0,
+    ## ANOVA
+    ""Eta2"", ""Eta2"", ""onetail"", 0, 1, 0,
+    ""Eta2_partial"", ""Eta2 (partial)"", ""onetail"", 0, 1, 0,
+    ""Eta2_generalized"", ""Eta2 (generalized)"", ""onetail"", 0, 1, 0,
+    ""Epsilon2"", ""Epsilon2"", ""onetail"", 0, 1, 0,
+    ""Epsilon2_partial"", ""Epsilon2 (partial)"", ""onetail"", 0, 1, 0,
+    ""Omega2"", ""Omega2"", ""onetail"", 0, 1, 0,
+    ""Omega2_partial"", ""Omega2 (partial)"", ""onetail"", 0, 1, 0,
+    ""Cohens_f"", ""Cohen's f"", ""onetail"", 0, Inf, 0,
+    ""Cohens_f_partial"", ""Cohen's f (partial)"", ""onetail"", 0, Inf, 0,
+    ""Cohens_f2"", ""Cohen's f2"", ""onetail"", 0, Inf, 0,
+    ""Cohens_f2_partial"", ""Cohen's f2 (partial)"", ""onetail"", 0, Inf, 0,
 
-  ## Rank
-  ""r_rank_biserial"", ""r (rank biserial)"", ""twotail"", -1, 1, 0,
-  ""Kendalls_W"", ""Kendall's W"", ""onetail"", 0, 1, 0,
-  ""rank_epsilon_squared"", ""Epsilon2 (rank)"", ""onetail"", 0, 1, 0,
+    ## Rank
+    ""r_rank_biserial"", ""r (rank biserial)"", ""twotail"", -1, 1, 0,
+    ""Kendalls_W"", ""Kendall's W"", ""onetail"", 0, 1, 0,
+    ""rank_epsilon_squared"", ""Epsilon2 (rank)"", ""onetail"", 0, 1, 0,
 
-  ## Std Coefficient
-  ""Std_Coefficient"", ""Coefficient (std.)"", ""twotail"", -Inf, Inf, 0,
-  ""Std_Odds_ratio"", ""Odds Ratio (std.)"", ""twotail"", 0, Inf, 1,
-  ""Std_Risk_ratio"", ""Risk Ratio (std.)"", ""twotail"", 0, Inf, 1,
-  ""Std_IRR"", ""IRR (std.)"", ""twotail"", 0, Inf, 1,
-  ""Std_Median"", ""Median (std.)"", ""twotail"", -Inf, Inf, 0,
-  ""Std_Mean"", ""Mean (std.)"", ""twotail"", -Inf, Inf, 0,
-  ""Std_MAP"", ""MAP (std.)"", ""twotail"", -Inf, Inf, 0,
+    ## Std Coefficient
+    ""Std_Coefficient"", ""Coefficient (std.)"", ""twotail"", -Inf, Inf, 0,
+    ""Std_Odds_ratio"", ""Odds Ratio (std.)"", ""twotail"", 0, Inf, 1,
+    ""Std_Risk_ratio"", ""Risk Ratio (std.)"", ""twotail"", 0, Inf, 1,
+    ""Std_IRR"", ""IRR (std.)"", ""twotail"", 0, Inf, 1,
+    ""Std_Median"", ""Median (std.)"", ""twotail"", -Inf, Inf, 0,
+    ""Std_Mean"", ""Mean (std.)"", ""twotail"", -Inf, Inf, 0,
+    ""Std_MAP"", ""MAP (std.)"", ""twotail"", -Inf, Inf, 0,
 
-  ## CLES
-  ""p_superiority"", ""Pr(superiority)"", ""onetail"", 0, 1, 0.5,
-  ""Cohens_U3"", ""Cohen's U3"", ""onetail"", 0, 1, 0.5,
-  ""overlap"", ""Overlap"", ""onetail"", 0, 1, 1,
+    ## CLES
+    ""p_superiority"", ""Pr(superiority)"", ""onetail"", 0, 1, 0.5,
+    ""Cohens_U3"", ""Cohen's U3"", ""onetail"", 0, 1, 0.5,
+    ""overlap"", ""Overlap"", ""onetail"", 0, 1, 1,
 
-  ## Other
-  ""r"", ""r"", ""twotail"", -1, 1, 0,
-  ""d"", ""d"", ""twotail"", -Inf, Inf, 0
-),
-ncol = 6, byrow = TRUE,
-dimnames = list(NULL, c(""name"", ""label"", ""direction"", ""lb"", ""ub"", ""null""))
+    ## Other
+    ""r"", ""r"", ""twotail"", -1, 1, 0,
+    ""d"", ""d"", ""twotail"", -Inf, Inf, 0
+  ),
+  ncol = 6, byrow = TRUE,
+  dimnames = list(NULL, c(""name"", ""label"", ""direction"", ""lb"", ""ub"", ""null""))
 )
 es_info <- as.data.frame(es_info, stringsAsFactors = FALSE)
 es_info$lb <- as.numeric(es_info$lb)

---FILE: R/rank_effectsizes.R---
@@ -226,7 +226,7 @@ rank_biserial <- function(x,
     #   ci_method <- list(method = ""bootstrap"", iterations = iterations)
     # } else {
     #   ci <- NULL
-    #   warning(""For CIs, the 'boot' package must be installed."")
+    #   warning(""For CIs, the 'boot' package must be installed."", call. = FALSE)
     # }
 
     # Parametric method
@@ -428,7 +428,7 @@ kendalls_w <- function(x,
 #   out <- data.frame(rank_eta_squared = E)
 #
 #   if (is.numeric(ci)) {
-#     warning(""Nope. Not yet."")
+#     warning(""Nope. Not yet."", call. = FALSE)
 #     out$CI <- ci
 #     out$CI_low <- 0
 #     out$CI_high <- 1

---FILE: R/xtab.R---
@@ -87,15 +87,16 @@
 #' ## 2-by-2 tables
 #' ## -------------
 #' RCT <-
-#'   matrix(c(
-#'     71, 30,
-#'     50, 100
-#'   ),
-#'   nrow = 2, byrow = TRUE,
-#'   dimnames = list(
-#'     Diagnosis = c(""Sick"", ""Recovered""),
-#'     Group = c(""Treatment"", ""Control"")
-#'   )
+#'   matrix(
+#'     c(
+#'       71, 30,
+#'       50, 100
+#'     ),
+#'     nrow = 2, byrow = TRUE,
+#'     dimnames = list(
+#'       Diagnosis = c(""Sick"", ""Recovered""),
+#'       Group = c(""Treatment"", ""Control"")
+#'     )
 #'   )
 #' RCT # note groups are COLUMNS
 #'
@@ -113,17 +114,18 @@
 #' ## -------------
 #'
 #' M <-
-#'   matrix(c(
-#'     150, 100, 165,
-#'     130, 50, 65,
-#'     35, 10, 2,
-#'     55, 40, 25
-#'   ),
-#'   nrow = 4,
-#'   dimnames = list(
-#'     Music = c(""Pop"", ""Rock"", ""Jazz"", ""Classic""),
-#'     Study = c(""Psych"", ""Econ"", ""Law"")
-#'   )
+#'   matrix(
+#'     c(
+#'       150, 100, 165,
+#'       130, 50, 65,
+#'       35, 10, 2,
+#'       55, 40, 25
+#'     ),
+#'     nrow = 4,
+#'     dimnames = list(
+#'       Music = c(""Pop"", ""Rock"", ""Jazz"", ""Classic""),
+#'       Study = c(""Psych"", ""Econ"", ""Law"")
+#'     )
 #'   )
 #' M
 #'
@@ -160,15 +162,16 @@
 #' ## -------------------------------------
 #' #
 #' Performance <-
-#'   matrix(c(
-#'     794, 150,
-#'     86, 570
-#'   ),
-#'   nrow = 2,
-#'   dimnames = list(
-#'     ""1st Survey"" = c(""Approve"", ""Disapprove""),
-#'     ""2nd Survey"" = c(""Approve"", ""Disapprove"")
-#'   )
+#'   matrix(
+#'     c(
+#'       794, 150,
+#'       86, 570
+#'     ),
+#'     nrow = 2,
+#'     dimnames = list(
+#'       ""1st Survey"" = c(""Approve"", ""Disapprove""),
+#'       ""2nd Survey"" = c(""Approve"", ""Disapprove"")
+#'     )
 #'   )
 #' Performance
 #'
@@ -269,7 +272,7 @@ normalized_chi <- function(x, y = NULL, ci = 0.95, alternative = ""greater"", ...)
   alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
 
   if (inherits(x, ""BFBayesFactor"")) {
-    stop(""Normalized Chi is only applicable to goodness of fit tests."")
+    stop(""Normalized Chi is only applicable to goodness of fit tests."", call. = FALSE)
   }
 
 
@@ -558,21 +561,21 @@ cohens_g <- function(x, y = NULL, ci = 0.95, alternative = ""two.sided"", ...) {
 
   if (!is.matrix(x)) {
     if (is.null(y)) {
-      stop(""if 'x' is not a matrix, 'y' must be given"")
+      stop(""if 'x' is not a matrix, 'y' must be given"", call. = FALSE)
     }
     if (length(x) != length(y)) {
-      stop(""'x' and 'y' must have the same length"")
+      stop(""'x' and 'y' must have the same length"", call. = FALSE)
     }
     OK <- stats::complete.cases(x, y)
     x <- as.factor(x[OK])
     y <- as.factor(y[OK])
     if ((nlevels(x) < 2) || (nlevels(y) != nlevels(x))) {
-      stop(""'x' and 'y' must have the same number of levels (minimum 2)"")
+      stop(""'x' and 'y' must have the same number of levels (minimum 2)"", call. = FALSE)
     }
     x <- table(x, y)
   } else {
     if ((nrow(x) < 2) || (ncol(x) != nrow(x))) {
-      stop(""'x' must be square with at least two rows and columns"")
+      stop(""'x' must be square with at least two rows and columns"", call. = FALSE)
     }
   }
 

---FILE: man/phi.Rd---
@@ -174,15 +174,16 @@ to 0 to be negligible are needed (""equivalence testing""; Bauer & Kiesser,
 ## 2-by-2 tables
 ## -------------
 RCT <-
-  matrix(c(
-    71, 30,
-    50, 100
-  ),
-  nrow = 2, byrow = TRUE,
-  dimnames = list(
-    Diagnosis = c(""Sick"", ""Recovered""),
-    Group = c(""Treatment"", ""Control"")
-  )
+  matrix(
+    c(
+      71, 30,
+      50, 100
+    ),
+    nrow = 2, byrow = TRUE,
+    dimnames = list(
+      Diagnosis = c(""Sick"", ""Recovered""),
+      Group = c(""Treatment"", ""Control"")
+    )
   )
 RCT # note groups are COLUMNS
 
@@ -200,17 +201,18 @@ cohens_h(RCT)
 ## -------------
 
 M <-
-  matrix(c(
-    150, 100, 165,
-    130, 50, 65,
-    35, 10, 2,
-    55, 40, 25
-  ),
-  nrow = 4,
-  dimnames = list(
-    Music = c(""Pop"", ""Rock"", ""Jazz"", ""Classic""),
-    Study = c(""Psych"", ""Econ"", ""Law"")
-  )
+  matrix(
+    c(
+      150, 100, 165,
+      130, 50, 65,
+      35, 10, 2,
+      55, 40, 25
+    ),
+    nrow = 4,
+    dimnames = list(
+      Music = c(""Pop"", ""Rock"", ""Jazz"", ""Classic""),
+      Study = c(""Psych"", ""Econ"", ""Law"")
+    )
   )
 M
 
@@ -247,15 +249,16 @@ pearsons_c(Smoking_ASD, p = c(0.015, 0.010, 0.975))
 ## -------------------------------------
 #
 Performance <-
-  matrix(c(
-    794, 150,
-    86, 570
-  ),
-  nrow = 2,
-  dimnames = list(
-    ""1st Survey"" = c(""Approve"", ""Disapprove""),
-    ""2nd Survey"" = c(""Approve"", ""Disapprove"")
-  )
+  matrix(
+    c(
+      794, 150,
+      86, 570
+    ),
+    nrow = 2,
+    dimnames = list(
+      ""1st Survey"" = c(""Approve"", ""Disapprove""),
+      ""2nd Survey"" = c(""Approve"", ""Disapprove"")
+    )
   )
 Performance
 

---FILE: tests/testthat/test-effectsize.R---
@@ -139,36 +139,37 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(rank_biserial(ww), rbs, ignore_attr = TRUE)
 
     RoundingTimes <-
-      matrix(c(
-        5.40, 5.50, 5.55,
-        5.85, 5.70, 5.75,
-        5.20, 5.60, 5.50,
-        5.55, 5.50, 5.40,
-        5.90, 5.85, 5.70,
-        5.45, 5.55, 5.60,
-        5.40, 5.40, 5.35,
-        5.45, 5.50, 5.35,
-        5.25, 5.15, 5.00,
-        5.85, 5.80, 5.70,
-        5.25, 5.20, 5.10,
-        5.65, 5.55, 5.45,
-        5.60, 5.35, 5.45,
-        5.05, 5.00, 4.95,
-        5.50, 5.50, 5.40,
-        5.45, 5.55, 5.50,
-        5.55, 5.55, 5.35,
-        5.45, 5.50, 5.55,
-        5.50, 5.45, 5.25,
-        5.65, 5.60, 5.40,
-        5.70, 5.65, 5.55,
-        6.30, 6.30, 6.25
-      ),
-      nrow = 22,
-      byrow = TRUE,
-      dimnames = list(
-        1:22,
-        c(""Round Out"", ""Narrow Angle"", ""Wide Angle"")
-      )
+      matrix(
+        c(
+          5.40, 5.50, 5.55,
+          5.85, 5.70, 5.75,
+          5.20, 5.60, 5.50,
+          5.55, 5.50, 5.40,
+          5.90, 5.85, 5.70,
+          5.45, 5.55, 5.60,
+          5.40, 5.40, 5.35,
+          5.45, 5.50, 5.35,
+          5.25, 5.15, 5.00,
+          5.85, 5.80, 5.70,
+          5.25, 5.20, 5.10,
+          5.65, 5.55, 5.45,
+          5.60, 5.35, 5.45,
+          5.05, 5.00, 4.95,
+          5.50, 5.50, 5.40,
+          5.45, 5.55, 5.50,
+          5.55, 5.55, 5.35,
+          5.45, 5.50, 5.55,
+          5.50, 5.45, 5.25,
+          5.65, 5.60, 5.40,
+          5.70, 5.65, 5.55,
+          6.30, 6.30, 6.25
+        ),
+        nrow = 22,
+        byrow = TRUE,
+        dimnames = list(
+          1:22,
+          c(""Round Out"", ""Narrow Angle"", ""Wide Angle"")
+        )
       )
     ft <- friedman.test(RoundingTimes)
     W <- kendalls_w(RoundingTimes, verbose = FALSE, ci = NULL)

---FILE: tests/testthat/test-xtab.R---
@@ -111,12 +111,18 @@ if (require(""testthat"") && require(""effectsize"")) {
     E_vec <- c(11, 13, 44, 23)
     E_tab <- as.table(E_vec)
 
-    expect_equal(cohens_w(O, p = E_vec, rescale.p = TRUE),
-                 cohens_w(O, p = E_tab, rescale.p = TRUE))
-    expect_equal(normalized_chi(O, p = E_vec, rescale.p = TRUE),
-                 normalized_chi(O, p = E_tab, rescale.p = TRUE))
-    expect_equal(pearsons_c(O, p = E_vec, rescale.p = TRUE),
-                 pearsons_c(O, p = E_tab, rescale.p = TRUE))
+    expect_equal(
+      cohens_w(O, p = E_vec, rescale.p = TRUE),
+      cohens_w(O, p = E_tab, rescale.p = TRUE)
+    )
+    expect_equal(
+      normalized_chi(O, p = E_vec, rescale.p = TRUE),
+      normalized_chi(O, p = E_tab, rescale.p = TRUE)
+    )
+    expect_equal(
+      pearsons_c(O, p = E_vec, rescale.p = TRUE),
+      pearsons_c(O, p = E_tab, rescale.p = TRUE)
+    )
   })
 
   test_that(""oddsratio & riskratio"", {
@@ -189,12 +195,13 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(g$CI_high, 0.399, tolerance = 0.01)
 
 
-    M <- matrix(c(
-      794, 86, 150,
-      570, 794, 86,
-      150, 570, 15
-    ),
-    nrow = 3
+    M <- matrix(
+      c(
+        794, 86, 150,
+        570, 794, 86,
+        150, 570, 15
+      ),
+      nrow = 3
     )
     g <- cohens_g(M)
     expect_equal(g$Cohens_g, 0.300, tolerance = 0.01)",True,False,Documentation / Formatting,6
easystats,effectsize,2c89cdab025e69bd9a6d61a32e47d38e33874157,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2022-08-25T11:48:39Z,GitHub,noreply@github.com,2022-08-25T11:48:39Z,"fix bug in goodness of fit

when passing `p` as a table",DESCRIPTION;NEWS.md;R/effectsize.htest.R;R/xtab.R;man/phi.Rd;tests/testthat/test-xtab.R,False,True,True,False,49,12,61,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size and Standardized Parameters
-Version: 0.7.0.5
+Version: 0.7.0.9999
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",

---FILE: NEWS.md---
@@ -1,3 +1,10 @@
+
+# effectsize 0.7.0.9999
+
+## Bug fixes
+
+- Effect sizes for goodness-of-fit now work when passing a `p` that is a table.
+
 # effectsize 0.7.0.5
 
 ## Breaking Changes

---FILE: R/effectsize.htest.R---
@@ -101,7 +101,7 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
   Obs <- model$observed
   Exp <- model$expected
 
-  if (!is.null(dim(Exp))) {
+  if (!is.null(dim(Exp)) && length(dim(Exp)) == 2) {
     if (any(c(colSums(Obs), rowSums(Obs)) == 0L)) {
       stop(""Cannot have empty rows/columns in the contingency tables."", call. = FALSE)
     }

---FILE: R/xtab.R---
@@ -18,6 +18,9 @@
 #'   goodness-of-fit. Ignored for `cohens_g()`.
 #'
 #' @details
+#'
+#' ## Correlation-like Effect Sizes
+#'
 #' Cramer's *V*, phi (\eqn{\phi}), Cohen's *w*, and Pearson's *C* are effect
 #' sizes for tests of independence in 2D contingency tables. For 2-by-2 tables,
 #' Cramer's *V*, phi and Cohen's *w* are identical, and are equal to the simple
@@ -38,17 +41,22 @@
 #' - For a 2x2 table, use `phi()`
 #' - For larger tables, use `cramers_v()`
 #' - For goodness-of-fit, use `normalized_chi()`
-#' \cr \cr
+#'
+#' ## Other Effect Sizes for 2-by-2 xtabs
+#'
 #' For 2-by-2 contingency tables, Odds ratios, Risk ratios and Cohen's *h* can
 #' also be estimated. Note that these are computed with each **column**
 #' representing the different groups, and the *first* column representing the
 #' treatment group and the *second* column baseline (or control). Effects are
 #' given as `treatment / control`. If you wish you use rows as groups you must
 #' pass a transposed table, or switch the `x` and `y` arguments.
-#' \cr \cr
-#' Cohen's *g* is an effect size for dependent (paired) contingency tables
-#' ranging between 0 (perfect symmetry) and 0.5 (perfect asymmetry) (see
-#' [stats::mcnemar.test()]).
+#'
+#' ## Effect Sizes for Paired xtabs
+#'
+#' Cohen's *g* is an effect size of asymmetry (or marginal heterogeneity) for
+#' dependent (paired) contingency tables ranging between 0 (perfect symmetry)
+#' and 0.5 (perfect asymmetry) (see [stats::mcnemar.test()]). (Note this is not
+#' *not* a measure of (dis)agreement between the pairs, but of (a)symmetry.)
 #'
 #' # Confidence Intervals for Cohen's g, OR, RR and Cohen's h
 #' For Cohen's *g*, confidence intervals are based on the proportion (\eqn{P = g

---FILE: man/phi.Rd---
@@ -73,6 +73,8 @@ Cohen's \emph{h} and Cohen's \emph{g} for contingency tables or goodness-of-fit.
 details.
 }
 \details{
+\subsection{Correlation-like Effect Sizes}{
+
 Cramer's \emph{V}, phi (\eqn{\phi}), Cohen's \emph{w}, and Pearson's \emph{C} are effect
 sizes for tests of independence in 2D contingency tables. For 2-by-2 tables,
 Cramer's \emph{V}, phi and Cohen's \emph{w} are identical, and are equal to the simple
@@ -93,17 +95,25 @@ To summarize, for correlation-like effect sizes, we recommend:
 \item For a 2x2 table, use \code{phi()}
 \item For larger tables, use \code{cramers_v()}
 \item For goodness-of-fit, use \code{normalized_chi()}
-\cr \cr
+}
+}
+
+\subsection{Other Effect Sizes for 2-by-2 xtabs}{
+
 For 2-by-2 contingency tables, Odds ratios, Risk ratios and Cohen's \emph{h} can
 also be estimated. Note that these are computed with each \strong{column}
 representing the different groups, and the \emph{first} column representing the
 treatment group and the \emph{second} column baseline (or control). Effects are
 given as \code{treatment / control}. If you wish you use rows as groups you must
 pass a transposed table, or switch the \code{x} and \code{y} arguments.
-\cr \cr
-Cohen's \emph{g} is an effect size for dependent (paired) contingency tables
-ranging between 0 (perfect symmetry) and 0.5 (perfect asymmetry) (see
-\code{\link[stats:mcnemar.test]{stats::mcnemar.test()}}).
+}
+
+\subsection{Effect Sizes for Paired xtabs}{
+
+Cohen's \emph{g} is an effect size of asymmetry (or marginal heterogeneity) for
+dependent (paired) contingency tables ranging between 0 (perfect symmetry)
+and 0.5 (perfect asymmetry) (see \code{\link[stats:mcnemar.test]{stats::mcnemar.test()}}). (Note this is not
+\emph{not} a measure of (dis)agreement between the pairs, but of (a)symmetry.)
 }
 }
 \section{Confidence Intervals for Cohen's g, OR, RR and Cohen's h}{

---FILE: tests/testthat/test-xtab.R---
@@ -105,6 +105,18 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(cohens_w(table(df$am, df$cyl))[[1]], 0.64, tolerance = 0.01)
     expect_equal(cohens_w(table(df$am, df$cyl)), cohens_w(table(df$cyl)))
     expect_equal(cohens_w(table(df$am, df$cyl)), cohens_w(table(df$cyl, df$am)))
+
+    # p is a table
+    O <- as.table(c(10, 20, 30, 40))
+    E_vec <- c(11, 13, 44, 23)
+    E_tab <- as.table(E_vec)
+
+    expect_equal(cohens_w(O, p = E_vec, rescale.p = TRUE),
+                 cohens_w(O, p = E_tab, rescale.p = TRUE))
+    expect_equal(normalized_chi(O, p = E_vec, rescale.p = TRUE),
+                 normalized_chi(O, p = E_tab, rescale.p = TRUE))
+    expect_equal(pearsons_c(O, p = E_vec, rescale.p = TRUE),
+                 pearsons_c(O, p = E_tab, rescale.p = TRUE))
   })
 
   test_that(""oddsratio & riskratio"", {",True,False,Documentation / Formatting,6
easystats,effectsize,8bb2b3fedb172d627d2feaf64ec5273180d641f4,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-08-24T15:14:26Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-08-24T15:14:26Z,"Update R-check.yaml

https://github.com/easystats/easystats/issues/269",.github/workflows/R-check.yaml,False,False,False,False,3,3,6,"---FILE: .github/workflows/R-check.yaml---
@@ -32,9 +32,9 @@ jobs:
           - {os: windows-latest, r: 'devel'}
           - {os: windows-latest, r: 'release'}
 
-          - {os: ubuntu-18.04,   r: 'devel', http-user-agent: 'release'}
-          - {os: ubuntu-18.04,   r: 'release'}
-          - {os: ubuntu-18.04,   r: 'oldrel-1'}
+          - {os: ubuntu-latest,   r: 'devel', http-user-agent: 'release'}
+          - {os: ubuntu-latest,   r: 'release'}
+          - {os: ubuntu-latest,   r: 'oldrel-1'}
 
     env:
       GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}",False,False,Environment / Configuration,4
easystats,effectsize,861e99cfebfed0c39b9854c9cddc771ea8d45e4d,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-08-24T15:13:47Z,Mattan S. Ben-Shachar,mattansb@msbstats.info,2022-08-24T15:13:47Z,"Update R-check.yaml

https://github.com/easystats/easystats/issues/268",.github/workflows/R-check.yaml,False,False,False,False,3,1,4,"---FILE: .github/workflows/R-check.yaml---
@@ -60,4 +60,6 @@ jobs:
             lme4=?ignore-before-r=3.6.0
           needs: check
 
-      - uses: r-lib/actions/check-r-package@v2
\ No newline at end of file
+      - uses: r-lib/actions/check-r-package@v2
+        with:
+          error-on: '""note""'
\ No newline at end of file",False,False,Environment / Configuration,4
easystats,effectsize,2d5f84a21e52abe54eac7738e9d6a17370e65a16,Indrajeet Patil,patilindrajeet.science@gmail.com,2022-08-20T08:57:31Z,Indrajeet Patil,patilindrajeet.science@gmail.com,2022-08-20T08:57:31Z,"use standard template workflow

https://github.com/easystats/easystats/issues/264",.github/workflows/pkgdown.yml;DESCRIPTION,False,False,False,False,6,2,8,"---FILE: .github/workflows/pkgdown.yml---
@@ -23,6 +23,8 @@ jobs:
       - uses: actions/checkout@v2
 
       - uses: r-lib/actions/setup-pandoc@v2
+        with:
+            pandoc-version: '2.19.1'
 
       - uses: r-lib/actions/setup-r@v2
         with:
@@ -32,8 +34,6 @@ jobs:
         with:
           extra-packages: |
               local::.
-              r-lib/pkgdown
-              easystats/easystatstemplate
           needs: website
 
       - name: Build site

---FILE: DESCRIPTION---
@@ -92,3 +92,7 @@ Roxygen: list(markdown = TRUE)
 RoxygenNote: 7.2.1
 Config/testthat/edition: 3
 Config/testthat/parallel: true
+Config/Needs/website:
+    rstudio/bslib,
+    r-lib/pkgdown,
+    easystats/easystatstemplate",False,False,Dependency / Package,6
easystats,effectsize,114d9dea37856164e0bc5f633865f5aca40d21de,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2022-08-10T09:36:10Z,GitHub,noreply@github.com,2022-08-10T09:36:10Z,"Cran 0.7.0.5 (#465)

## Breaking Changes

`effectsize` now requires minimal *`R`* version of `3.5`.

## Bug fixes

- `cohens_d()` for paired / one sample now gives more accurate CIs (was off by a factor of `(N - 1) / N`; #457)
- `kendalls_w()` now deals correctly with singular ties (#448).",DESCRIPTION;NEWS.md;R/effectsize.htest.R;R/eta_squared.R;R/interpret_bf.R;cran-comments.md;man/eta_squared.Rd;man/interpret_bf.Rd;tests/testthat/test-effectsize.R;tests/testthat/test-rankES.R,False,True,True,False,46,57,103,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size and Standardized Parameters
-Version: 0.7.0.1
+Version: 0.7.0.5
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",
@@ -59,16 +59,10 @@ Imports:
     bayestestR (>= 0.12.1),
     insight (>= 0.18.0),
     parameters (>= 0.18.1),
-    performance (>= 0.9.0),
-    datawizard (>= 0.4.1.10),
+    performance (>= 0.9.1),
+    datawizard (>= 0.5.0),
     stats,
     utils
-Remotes: 
-    easystats/datawizard, 
-    easystats/parameters, 
-    easystats/performance,
-    easystats/correlation,
-    easystats/bayestestR
 Suggests:
     correlation (>= 0.8.1),
     see (>= 0.7.1),

---FILE: NEWS.md---
@@ -1,17 +1,12 @@
-# effectsize 0.7.1.9990
-
-## Bug fixes
-
-- `cohens_d()` for paired / one sample now gives more accurate CIs (was off by a factor of `(N - 1) / N`; #457)
-
-# effectsize 0.7.0.9
+# effectsize 0.7.0.5
 
 ## Breaking Changes
 
 `effectsize` now requires minimal *`R`* version of `3.5`.
 
 ## Bug fixes
 
+- `cohens_d()` for paired / one sample now gives more accurate CIs (was off by a factor of `(N - 1) / N`; #457)
 - `kendalls_w()` now deals correctly with singular ties (#448).  
 
 # effectsize 0.7.0

---FILE: R/effectsize.htest.R---
@@ -54,7 +54,8 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
     args <- list(
       t = unname(model$statistic),
       df_error = unname(model$parameter),
-      paired = !grepl(""Two"", model$method)
+      paired = !grepl(""Two"", model$method),
+      verbose = verbose
     )
   } else {
     if (grepl("" by "", model$data.name, fixed = TRUE)) {
@@ -144,6 +145,7 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
       nrow = nr,
       ncol = nc,
       p = p,
+      verbose = verbose,
       ...
     )
   } else {
@@ -198,6 +200,7 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
     f = model$statistic,
     df = model$parameter[1],
     df_error = model$parameter[2],
+    verbose = verbose,
     ...
   )
   colnames(out)[1] <- sub(""_partial"", """", colnames(out)[1])
@@ -216,9 +219,9 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
   .fail_if_approx(approx, ""cohens_g"")
 
   if (inherits(data, ""table"")) {
-    out <- cohens_g(data, ...)
+    out <- cohens_g(data, verbose = verbose, ...)
   } else {
-    out <- cohens_g(data[[1]], data[[2]], ...)
+    out <- cohens_g(data[[1]], data[[2]], verbose = verbose, ...)
   }
   out
 }
@@ -251,7 +254,8 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
   args <- list(
     x = data[[1]],
     y = if (ncol(data) == 2) data[[2]],
-    paired = grepl(""signed rank"", model$method, fixed = TRUE)
+    paired = grepl(""signed rank"", model$method, fixed = TRUE),
+    verbose = verbose
   )
 
   if (type == ""cles"") {
@@ -278,10 +282,10 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
 
 
   if (inherits(data, ""data.frame"")) {
-    out <- rank_epsilon_squared(data[[1]], data[[2]], ...)
+    out <- rank_epsilon_squared(data[[1]], data[[2]], verbose = verbose, ...)
   } else {
     # data frame
-    out <- rank_epsilon_squared(data, ...)
+    out <- rank_epsilon_squared(data, verbose = verbose, ...)
   }
   out
 }
@@ -300,7 +304,7 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
     data <- as.data.frame(data)[c(""Freq"", ""Var2"", ""Var1"")]
   }
 
-  out <- kendalls_w(data[[1]], data[[2]], data[[3]], ...)
+  out <- kendalls_w(data[[1]], data[[2]], data[[3]], verbose = verbose, ...)
   out
 }
 

---FILE: R/eta_squared.R---
@@ -111,8 +111,6 @@
 #' epsilon_squared(model)
 #' cohens_f(model)
 #'
-#' if (require(see)) plot(eta2)
-#'
 #' model0 <- aov(mpg ~ am_f + cyl_f, data = mtcars) # no interaction
 #' cohens_f_squared(model0, model2 = model)
 #'
@@ -125,7 +123,10 @@
 #'
 #' interpret(eta2, rules = ""cohen1992"")
 #'
-#' @examplesIf require(""car"") && require(""afex"")
+#' @examplesIf require(""see"") && FALSE
+#' plot(eta2) # Requires the {see} package
+#'
+#' @examplesIf require(""car"")
 #' # Recommended: Type-2 or -3 effect sizes + effects coding
 #' # -------------------------------------------------------
 #' contrasts(mtcars$am_f) <- contr.sum
@@ -134,28 +135,27 @@
 #' model <- aov(mpg ~ am_f * cyl_f, data = mtcars)
 #' model_anova <- car::Anova(model, type = 3)
 #'
-#' eta_squared(model_anova)
+#' epsilon_squared(model_anova)
 #'
+#' @examplesIf require(""car"") && require(""afex"")
 #' # afex takes care of both type-3 effects and effects coding:
 #' data(obk.long, package = ""afex"")
 #' model <- afex::aov_car(value ~ treatment * gender + Error(id / (phase)),
 #'   data = obk.long, observed = ""gender""
 #' )
-#' eta_squared(model)
-#' epsilon_squared(model)
+#'
 #' omega_squared(model)
 #' eta_squared(model, generalized = TRUE) # observed vars are pulled from the afex model.
 #'
-#' @examplesIf require(""lmerTest"") && require(""lme4"")
+#' @examplesIf require(""lmerTest"") && require(""lme4"") && FALSE
 #' ## Approx. effect sizes for mixed models
 #' ## -------------------------------------
 #' model <- lme4::lmer(mpg ~ am_f * cyl_f + (1 | vs), data = mtcars)
 #' omega_squared(model)
 #'
-#' @examplesIf require(rstanarm) && require(bayestestR) && require(car)
+#' @examplesIf require(rstanarm) && require(bayestestR) && require(car) && FALSE
 #' ## Bayesian Models (PPD)
 #' ## ---------------------
-#' \dontrun{
 #' fit_bayes <- rstanarm::stan_glm(
 #'   mpg ~ factor(cyl) * wt + qsec,
 #'   data = mtcars, family = gaussian(),
@@ -175,7 +175,6 @@
 #' )
 #' aov_table <- car::Anova(fit_freq, type = 3)
 #' eta_squared(aov_table)
-#' }
 #'
 #' @return A data frame containing the effect size values and their confidence
 #'   intervals.

---FILE: R/interpret_bf.R---
@@ -39,8 +39,7 @@
 #' Sociological methodology, 25, 111-164.
 #'
 #' - Jarosz, A. F., & Wiley, J. (2014). What are the odds? A practical guide to
-#' computing and reporting Bayes factors. The Journal of Problem Solving, 7(1),
-#' 2.
+#' computing and reporting Bayes factors. The Journal of Problem Solving, 7(1), 2.
 #'
 #' @export
 interpret_bf <- function(bf,

---FILE: cran-comments.md---
@@ -1,12 +1,13 @@
 All URL issues have been resolved.
+DOI issues are a false positive.
 
 ## Test environments
 
-* local installation: R 4.1.1 on Windows
+* local installation: R 4.2.1 on Windows
 * GitHub Actions
     - Windows:        devel, release, oldrel
-    - macOS:          devel, release, oldrel
-    - ubuntu-16.04:   devel, release, oldrel, 4.0, 3.6, 3.5
+    - macOS:          devel, release, oldrel, 4.0, 3.6, 3.5
+    - ubuntu-18.04:   devel, release, oldrel
 * win-builder:        release
 
 
@@ -23,7 +24,7 @@ All URL issues have been resolved.
 
 ## revdepcheck results
 
-We checked 17 reverse dependencies, comparing R CMD check results across CRAN and dev versions of this package.
+We checked 16 reverse dependencies, comparing R CMD check results across CRAN and dev versions of this package.
 
  * We saw 0 new problems
  * We failed to check 0 packages

---FILE: man/eta_squared.Rd---
@@ -250,8 +250,6 @@ omega_squared(model)
 epsilon_squared(model)
 cohens_f(model)
 
-if (require(see)) plot(eta2)
-
 model0 <- aov(mpg ~ am_f + cyl_f, data = mtcars) # no interaction
 cohens_f_squared(model0, model2 = model)
 
@@ -264,7 +262,10 @@ interpret_epsilon_squared(0.10, rules = ""cohen1992"")
 
 interpret(eta2, rules = ""cohen1992"")
 
-\dontshow{if (require(""car"") && require(""afex"")) (if (getRversion() >= ""3.4"") withAutoprint else force)(\{ # examplesIf}
+\dontshow{if (require(""see"") && FALSE) (if (getRversion() >= ""3.4"") withAutoprint else force)(\{ # examplesIf}
+plot(eta2) # Requires the {see} package
+\dontshow{\}) # examplesIf}
+\dontshow{if (require(""car"")) (if (getRversion() >= ""3.4"") withAutoprint else force)(\{ # examplesIf}
 # Recommended: Type-2 or -3 effect sizes + effects coding
 # -------------------------------------------------------
 contrasts(mtcars$am_f) <- contr.sum
@@ -273,28 +274,27 @@ contrasts(mtcars$cyl_f) <- contr.sum
 model <- aov(mpg ~ am_f * cyl_f, data = mtcars)
 model_anova <- car::Anova(model, type = 3)
 
-eta_squared(model_anova)
-
+epsilon_squared(model_anova)
+\dontshow{\}) # examplesIf}
+\dontshow{if (require(""car"") && require(""afex"")) (if (getRversion() >= ""3.4"") withAutoprint else force)(\{ # examplesIf}
 # afex takes care of both type-3 effects and effects coding:
 data(obk.long, package = ""afex"")
 model <- afex::aov_car(value ~ treatment * gender + Error(id / (phase)),
   data = obk.long, observed = ""gender""
 )
-eta_squared(model)
-epsilon_squared(model)
+
 omega_squared(model)
 eta_squared(model, generalized = TRUE) # observed vars are pulled from the afex model.
 \dontshow{\}) # examplesIf}
-\dontshow{if (require(""lmerTest"") && require(""lme4"")) (if (getRversion() >= ""3.4"") withAutoprint else force)(\{ # examplesIf}
+\dontshow{if (require(""lmerTest"") && require(""lme4"") && FALSE) (if (getRversion() >= ""3.4"") withAutoprint else force)(\{ # examplesIf}
 ## Approx. effect sizes for mixed models
 ## -------------------------------------
 model <- lme4::lmer(mpg ~ am_f * cyl_f + (1 | vs), data = mtcars)
 omega_squared(model)
 \dontshow{\}) # examplesIf}
-\dontshow{if (require(rstanarm) && require(bayestestR) && require(car)) (if (getRversion() >= ""3.4"") withAutoprint else force)(\{ # examplesIf}
+\dontshow{if (require(rstanarm) && require(bayestestR) && require(car) && FALSE) (if (getRversion() >= ""3.4"") withAutoprint else force)(\{ # examplesIf}
 ## Bayesian Models (PPD)
 ## ---------------------
-\dontrun{
 fit_bayes <- rstanarm::stan_glm(
   mpg ~ factor(cyl) * wt + qsec,
   data = mtcars, family = gaussian(),
@@ -314,7 +314,6 @@ fit_freq <- lm(mpg ~ factor(cyl) * wt + qsec,
 )
 aov_table <- car::Anova(fit_freq, type = 3)
 eta_squared(aov_table)
-}
 \dontshow{\}) # examplesIf}
 }
 \references{

---FILE: man/interpret_bf.Rd---
@@ -71,9 +71,6 @@ Press, Oxford.
 \item Raftery, A. E. (1995). Bayesian model selection in social research.
 Sociological methodology, 25, 111-164.
 \item Jarosz, A. F., & Wiley, J. (2014). What are the odds? A practical guide to
-computing and reporting Bayes factors. The Journal of Problem Solving, 7(1),
-}
-\enumerate{
-\item 
+computing and reporting Bayes factors. The Journal of Problem Solving, 7(1), 2.
 }
 }

---FILE: tests/testthat/test-effectsize.R---
@@ -171,8 +171,9 @@ if (require(""testthat"") && require(""effectsize"")) {
       )
       )
     ft <- friedman.test(RoundingTimes)
-    expect_equal(effectsize(ft)[[1]], W <- kendalls_w(RoundingTimes)[[1]], ignore_attr = TRUE)
-    expect_equal(kendalls_w(ft)[[1]], W, ignore_attr = TRUE)
+    W <- kendalls_w(RoundingTimes, verbose = FALSE, ci = NULL)
+    expect_equal(effectsize(ft, verbose = FALSE, ci = NULL), W, ignore_attr = TRUE)
+    expect_equal(kendalls_w(ft, verbose = FALSE, ci = NULL), W, ignore_attr = TRUE)
 
     X <<- c(2.9, 3.0, 2.5, 2.6, 3.2) # normal subjects
     Y <<- c(3.8, 2.7, 4.0, 2.4) # with obstructive airway disease

---FILE: tests/testthat/test-rankES.R---
@@ -116,7 +116,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     )
     dat
 
-    W <- kendalls_w(mrt ~ interaction(condition, congruency) | pno, data = dat)
+    W <- kendalls_w(mrt ~ interaction(condition, congruency) | pno, data = dat, verbose = FALSE)
     expect_equal(W[[1]], 0.4011, tolerance = 0.01)
 
 ",True,False,Dependency / Package,7
easystats,effectsize,7dbef9aef8cda8395bf20ba06883e3ca97d4c730,etiennebacher,etienne.bacher@protonmail.com,2022-08-05T08:04:24Z,etiennebacher,etienne.bacher@protonmail.com,2022-08-05T08:04:24Z,fix articles structure,_pkgdown.yml,False,False,False,False,30,1,31,"---FILE: _pkgdown.yml---
@@ -65,6 +65,35 @@ reference:
   - effectsize_deprecated
 
 
-
+# Keep articles organized
+navbar:
+  left:
+    - icon: fa fa-file-code
+      text: Reference
+      href: reference/index.html
+    - text: ""Get Started""
+      href: articles/effectsize.html
+    - text: ""Effect sizes""
+      menu:
+      - text: ""ANOVA Effect Sizes""
+        href: articles/anovaES.html
+      - text: ""Effect Sizes for Simple Hypothesis Tests""
+        href: articles/simple_htests.html
+      - text: ""Confidence Intervals""
+        href: reference/effectsize_CIs.html
+      - text: -------
+      - text: ""Extending effectsize""
+        href: articles/effectsize_API.html
+    - text: ""Conversion""
+      menu:
+      - text: ""Between d, r, OR""
+        href: articles/convert.html
+      - text: ""From Test Statistics""
+        href: articles/from_test_statistics.html
+    - text: ""Interpretation""
+      href: articles/interpret.html
+    - icon: fa fa-newspaper
+      text: News
+      href: news/index.html
 
 ",False,False,Documentation / Formatting,3
easystats,effectsize,238480488259890a303e65eca0c16dd033c77ac5,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2022-06-15T11:43:50Z,GitHub,noreply@github.com,2022-06-15T11:43:50Z,"min version of R is now 3.5 (#456)

* min version of R is now 3.5

* skip this one test on older MacOS

No idea why this fails - I think its something in the rms package, not here.

* Update NEWS.md

* Update test-eta_squared.R

* patch up more tests

* Update test-eta_squared.R

* oops",.github/workflows/R-check.yaml;DESCRIPTION;NEWS.md;cran-comments.md;tests/testthat/test-eta_squared.R,False,True,True,False,11,5,16,"---FILE: .github/workflows/R-check.yaml---
@@ -29,7 +29,6 @@ jobs:
           - {os: macOS-latest, r: '4.0.0'}
           - {os: macOS-latest, r: '3.6.0'}
           - {os: macOS-latest, r: '3.5.0'}
-          - {os: macOS-latest, r: '3.4.0'}
 
           - {os: windows-latest, r: 'devel'}
           - {os: windows-latest, r: 'release'}
@@ -60,7 +59,6 @@ jobs:
           extra-packages: |
             any::rcmdcheck
             lme4=?ignore-before-r=3.6.0
-            emmeans=?ignore-before-r=3.5.0
           needs: check
 
       - uses: r-lib/actions/check-r-package@v2
\ No newline at end of file

---FILE: DESCRIPTION---
@@ -54,7 +54,7 @@ License: GPL-3
 URL: https://easystats.github.io/effectsize/
 BugReports: https://github.com/easystats/effectsize/issues/
 Depends:
-    R (>= 3.4)
+    R (>= 3.5)
 Imports:
     bayestestR (>= 0.12.1),
     insight (>= 0.17.0),

---FILE: NEWS.md---
@@ -1,5 +1,9 @@
 # effectsize 0.7.0.9
 
+## Breaking Changes
+
+`effectsize` now requires minimal *`R`* version of `3.5`.
+
 ## Bug fixes
 
 - `kendalls_w()` now deals correctly with singular ties (#448).  

---FILE: cran-comments.md---
@@ -6,7 +6,7 @@ All URL issues have been resolved.
 * GitHub Actions
     - Windows:        devel, release, oldrel
     - macOS:          devel, release, oldrel
-    - ubuntu-16.04:   devel, release, oldrel, 4.0, 3.6, 3.5, 3.4
+    - ubuntu-16.04:   devel, release, oldrel, 4.0, 3.6, 3.5
 * win-builder:        release
 
 

---FILE: tests/testthat/test-eta_squared.R---
@@ -470,6 +470,7 @@ if (require(""testthat"") && require(""effectsize"")) {
   test_that(""afex | mixed()"", {
     skip_if_not_installed(""afex"")
     skip_if_not_installed(""lmerTest"")
+    skip_if(getRversion() <= ""3.6"")
 
     data(md_15.1, package = ""afex"")
     # random intercept plus random slope
@@ -567,7 +568,6 @@ if (require(""testthat"") && require(""effectsize"")) {
     m <- lme4::lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
     mtest <- lmerTest::lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
 
-    t15.4a <- afex::mixed(iq ~ timecat + (1 + time | id), data = md_15.1)
     expect_equal(
       eta_squared(m),
       eta_squared(mtest)
@@ -579,6 +579,7 @@ if (require(""testthat"") && require(""effectsize"")) {
   test_that(""ets_squared | tidymodels"", {
     skip_on_cran()
     skip_if_not_installed(""parsnip"")
+    skip_if(getRversion() <= ""3.6"")
 
     set.seed(123)
     mod_lm <- parsnip::linear_reg(engine = ""lm"", mode = ""regression"")
@@ -609,12 +610,15 @@ if (require(""testthat"") && require(""effectsize"")) {
   test_that(""ets_squared | rms"", {
     skip_on_cran()
     skip_if_not_installed(""rms"")
+    data(""mtcars"")
 
     b <- rms::ols(mpg ~ cyl + am, data = mtcars)
     expect_error(out <- eta_squared(b), regexp = NA)
     expect_output(print(out), ""Type II"")
 
     skip_if_not_installed(""car"")
+    skip_if(getRversion() <= ""3.6"" &&
+              Sys.info()[""sysname""] == ""Darwin"")
     b_lm <- car::Anova(lm(mpg ~ cyl + am, data = mtcars), type = 2)
     out_lm <- eta_squared(b_lm)
     expect_equal(out[1:2, ], out_lm, ignore_attr = TRUE)",True,False,Dependency / Package,7
easystats,effectsize,c7ed185c326adfb8080be93791005a346da9641e,Indrajeet Patil,patilindrajeet.science@gmail.com,2022-06-12T12:40:27Z,GitHub,noreply@github.com,2022-06-12T12:40:27Z,"check more older R versions (#453)

* check more older R versions

* try windows

* Update R-check.yaml

* Update R-check.yaml

* yaml problem?

* Update R-check.yaml

* Update R-check.yaml

* Update DESCRIPTION

* covr not needed

* close #454

* dropping suggested pkgs

@IndrajeetPatil There packages are not used or tested at all.

* Update R-check.yaml

* suggest parsnip for testing

@IndrajeetPatil so annoying!!

* skip on older versions

* Get rid of spelling from deps

https://github.com/easystats/easystats/issues/239

* running tests in parallel doesn't seem to work

* Update test-eta_squared.R

* Update test-convert_between.R

Co-authored-by: Mattan S. Ben-Shachar <matanshm@post.bgu.ac.il>",.github/workflows/R-check.yaml;DESCRIPTION;NEWS.md;R/interpret.R;inst/WORDLIST;tests/spelling.R;tests/testthat/test-eta_squared.R,False,True,True,False,18,235,253,"---FILE: .github/workflows/R-check.yaml---
@@ -25,10 +25,14 @@ jobs:
           #- {os: macOS-latest,   r: 'devel'}
           - {os: macOS-latest,   r: 'release'}
           - {os: macOS-latest,   r: 'oldrel-1'}
+          - {os: macOS-latest, r: 'oldrel-1'}
+          - {os: macOS-latest, r: '4.0.0'}
+          - {os: macOS-latest, r: '3.6.0'}
+          - {os: macOS-latest, r: '3.5.0'}
+          - {os: macOS-latest, r: '3.4.0'}
 
           - {os: windows-latest, r: 'devel'}
           - {os: windows-latest, r: 'release'}
-          - {os: windows-latest, r: 'oldrel-1'}
 
           - {os: ubuntu-18.04,   r: 'devel', http-user-agent: 'release'}
           - {os: ubuntu-18.04,   r: 'release'}
@@ -37,6 +41,8 @@ jobs:
     env:
       GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}
       R_KEEP_PKG_SOURCE: yes
+      _R_CHECK_CRAN_INCOMING_: false
+      _R_CHECK_FORCE_SUGGESTS_: false
 
     steps:
       - uses: actions/checkout@v2
@@ -51,7 +57,10 @@ jobs:
 
       - uses: r-lib/actions/setup-r-dependencies@v2
         with:
-          extra-packages: any::rcmdcheck
+          extra-packages: |
+            any::rcmdcheck
+            lme4=?ignore-before-r=3.6.0
+            emmeans=?ignore-before-r=3.5.0
           needs: check
 
       - uses: r-lib/actions/check-r-package@v2
\ No newline at end of file

---FILE: DESCRIPTION---
@@ -68,29 +68,22 @@ Suggests:
     see (>= 0.6.9),
     afex,
     BayesFactor,
-    biglm,
     boot,
     brms,
     car,
-    covr,
     emmeans,
-    gamm4,
     knitr,
     lavaan,
-    lm.beta,
     lme4,
     lmerTest,
     MASS,
-    mediation,
     mgcv,
-    pscl,
+    parsnip,
     rmarkdown,
     rms,
     rstanarm,
     rstantools,
-    spelling,
-    testthat,
-    tidymodels
+    testthat (>= 3.1.0)
 VignetteBuilder: 
     knitr
 Encoding: UTF-8

---FILE: NEWS.md---
@@ -67,7 +67,7 @@ See [*Support functions for model extensions* vignette](https://easystats.github
 
 ## Breaking Changes
 
-- `cramers_v()` correctly does not work with 1-dimentional tables (for goodness-of-fit tests).
+- `cramers_v()` correctly does not work with 1-dimensional tables (for goodness-of-fit tests).
 - `interpret_d()`, `interpret_g()`, and `interpret_delta()` are now `interpret_cohens_d()`, `interpret_hedges_g()`, and `interpret_glass_delta()`.
 - `interpret_parameters()` was removed. Use `interpret_r()` instead (with caution!).
 - Phi, Cohen's *w*, Cramer's *V*, ANOVA effect sizes, rank Epsilon squared, Kendall's *W* - CIs default to 95% one-sided CIs (`alternative = ""greater""`). (To restore previous behavior, set `ci = .9, alternative = ""two.sided""`.)

---FILE: R/interpret.R---
@@ -95,7 +95,7 @@ is.rules <- function(x) inherits(x, ""rules"")
 #' @inheritParams rules
 #'
 #' @return
-#' - For numeric input: A character vector of interpertations.
+#' - For numeric input: A character vector of interpretations.
 #' - For data frames: the `x` input with an additional `Interpretation` column.
 #'
 #' @seealso rules

---FILE: inst/WORDLIST---
@@ -1,207 +0,0 @@
-ADF
-AGFI
-ANOVA's
-APA's
-Agadullina
-Albers
-Algina
-Awang
-Azen
-BESD
-Baptista
-BayestestR's
-Behaviour
-Bergsma
-Biometrics
-Bmj
-Bollen's
-Borenstein
-Byrne
-BÃ¼rkner
-CFA
-CFI
-Cesarini
-ChacÃ³n
-Chisq
-Codecov
-Cramer's
-CramÃ©r's
-Cureton
-DOI
-Delacre
-EQS
-ESS
-Erlbaum
-Falk
-Faraggi
-Funder
-GFI
-GLMM
-Gelman
-Gignac
-Gignac's
-Glassâ
-Guilford
-Gustafson
-HDI
-HLM
-Hedgesâ
-Hoekstra
-IFI
-IRR
-IRRs
-Jarosz
-Jeffreys
-Johannesson
-Katz
-Kerby
-Keselman
-Kruschke
-Kutner
-LMM
-LMMs
-Lakens
-Landis
-Ley
-Leys
-Liu
-Lomax
-Lovakov
-MADs
-MLM
-Mahwah
-MartÃ­nez
-MarÃ­n
-McNemar
-McNemar's
-Meca
-Minium
-Mordkoff
-Morey
-Moscoso
-NCP
-NFI
-NNFI
-Neter
-Noncentrality
-Nordholm
-Normed
-Nosek
-Olejnik
-Olkin
-Ozer
-PLOS
-PNFI
-PPD
-Pearon's
-Penfield
-Psychometrika
-Psychonomic
-RFI
-RMR
-RMSEA
-Raftery
-Reiser
-Rescale
-Rhat
-Ringle
-Rosenthal
-Rothstein
-Rouder
-Routledge
-Ruscio
-SDs
-SEM
-SEs
-SRMR
-Sarstedt
-Sawilowsky
-Schumacker
-Shachar
-Shmekels
-Steiger
-Szodorai
-Szumilas
-SÃ¡nchez
-TLI
-TOST
-Tomczak
-Tschuprow's
-Un
-Vehtari
-Verkuilen
-Verkuilen's
-Wagenmakers
-Waggoner
-Wasserman
-Welch's
-Wilcoxon's
-al
-anova
-arXiv
-arcsin
-automagically
-biserial
-brglm
-brms
-brussels
-cbu
-cfa
-cgam
-cglm
-complmrob
-cplm
-df
-dichotomize
-doi
-dynamicfit
-easystats
-effectSize
-et
-fixest
-frac
-friedman
-github
-glmmadmb
-http
-https
-ifelse
-infty
-interpretability
-io
-joss
-kruskal
-lm
-mis
-mixor
-modelling
-mrc
-ncp
-ncps
-nd
-noncentral
-osf
-partialization
-partialled
-partilled
-pb
-pkgdown
-posthoc
-ppd
-pre
-preprint
-reproducibility
-rescale
-rescaled
-rescaling
-rmANOVA
-sd
-statswiki
-th
-tu
-uk
-un
-unitless
-varialbe
-visualise
-wilcox

---FILE: tests/spelling.R---
@@ -1,6 +0,0 @@
-if (requireNamespace(""spelling"", quietly = TRUE)) {
-  spelling::spell_check_test(
-    vignettes = TRUE, error = FALSE,
-    skip_on_cran = TRUE
-  )
-}

---FILE: tests/testthat/test-eta_squared.R---
@@ -578,17 +578,11 @@ if (require(""testthat"") && require(""effectsize"")) {
   ## tidymodels -------------------
   test_that(""ets_squared | tidymodels"", {
     skip_on_cran()
-    skip_if_not_installed(""tidymodels"")
-    suppressPackageStartupMessages(require(""tidymodels"",
-                                           quietly = TRUE,
-                                           warn.conflicts = FALSE))
+    skip_if_not_installed(""parsnip"")
 
     set.seed(123)
-    mod_lm <-
-      linear_reg() %>%
-      set_engine(""lm"") %>%
-      set_mode(""regression"") %>%
-      fit(mpg ~ am + vs, data = mtcars)
+    mod_lm <- parsnip::linear_reg(engine = ""lm"", mode = ""regression"")
+    mod_lm <- parsnip::fit(mod_lm, mpg ~ am + vs, data = mtcars)
 
     set.seed(123)
     tidy_lm <- eta_squared(mod_lm)",True,False,Documentation / Formatting,7
easystats,effectsize,088a10cf5e85aac3d1e68f6302ec6f861af6407a,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2022-06-02T10:53:32Z,GitHub,noreply@github.com,2022-06-02T10:53:32Z,"Fix Kendall's W with ties (#449)

* Update rank_effectsizes.R

* Update rank_effectsizes.R

#448

* close #448

* Update test-rankES.R

* add warning",NEWS.md;R/rank_effectsizes.R;R/utils_validate_input_data.R;man/rank_biserial.Rd;tests/testthat/test-rankES.R,False,True,True,False,56,15,71,"---FILE: NEWS.md---
@@ -1,3 +1,9 @@
+# effectsize 0.7.0.9
+
+## Bug fixes
+
+- `kendalls_w()` now deals correctly with singular ties (#448).  
+
 # effectsize 0.7.0
 
 ## Breaking Changes

---FILE: R/rank_effectsizes.R---
@@ -11,13 +11,15 @@
 #'   `rank_epsilon_squared()`) or `DV ~ groups | blocks` (for `kendalls_w()`;
 #'   See details for the `blocks` and `groups` terminology used here).
 #'   - A list of vectors (for `rank_epsilon_squared()`).
-#'   - A matrix of `blocks x groups` (for `kendalls_w()`). See details for the
-#'   `blocks` and `groups` terminology used here.
+#'   - A matrix of `blocks x groups` (for `kendalls_w()`) (or `groups x blocks`
+#'   if `blocks_on_rows = FALSE`). See details for the `blocks` and `groups`
+#'   terminology used here.
 #' @param y An optional numeric vector of data values to compare to `x`, or a
 #'   character name of one in `data`. Ignored if `x` is not a vector.
 #' @param groups,blocks A factor vector giving the group / block for the
 #'   corresponding elements of `x`, or a character name of one in `data`.
 #'   Ignored if `x` is not a vector.
+#' @param blocks_on_rows Are blocks on rows (`TRUE`) or columns (`FALSE`).
 #' @param mu a number indicating the value around which (a-)symmetry (for
 #'   one-sample or paired samples) or shift (for independent samples) is to be
 #'   estimated. See [stats::wilcox.test].
@@ -360,6 +362,7 @@ kendalls_w <- function(x,
                        groups,
                        blocks,
                        data = NULL,
+                       blocks_on_rows = TRUE,
                        ci = 0.95,
                        alternative = ""greater"",
                        iterations = 200,
@@ -375,6 +378,7 @@ kendalls_w <- function(x,
   }
 
   ## prep data
+  if (is.matrix(x) && !blocks_on_rows) x <- t(x)
   data <- .get_data_nested_groups(x, groups, blocks, data, ...)
   data <- stats::na.omit(data)
 
@@ -484,19 +488,32 @@ kendalls_w <- function(x,
   m <- nrow(rankings) # judges
   R <- colSums(rankings)
 
-  if (!all(has_tie <- apply(rankings, 1, function(x) length(x) == insight::n_unique(x)))) {
-    # there are ties
-    have_ties <- rankings[!has_tie, , drop = FALSE]
-    Ti <- apply(have_ties, 1, function(r) {
-      ti <- apply(outer(unique(r), r, FUN = ""==""), 1, sum)
-      sum(ti^3 - ti)
-    })
+  no_ties <- apply(rankings, 1, function(x) length(x) == insight::n_unique(x))
+  if (!all(no_ties)) {
+    if (verbose) {
+      warning(
+        sprintf(""%d block(s) contain ties%s."",
+                sum(!no_ties),
+                ifelse(any(apply(as.data.frame(rankings)[!no_ties, ], 1, insight::n_unique) == 1),
+                       "", some containing only 1 unique ranking"", """")),
+        call. = FALSE
+      )
+    }
+
+    Tj <- 0
+    for (i in seq_len(m)) {
+      rater <- table(rankings[i, ])
+      ties <- rater[rater > 1]
+      l <- as.numeric(ties)
+      Tj <- Tj + sum(l^3 - l)
+    }
 
     W <- (12 * sum(R^2) - 3 * (m^2) * n * ((n + 1)^2)) /
-      ((m^2) * n * (n^2 - 1) - m * sum(Ti))
+      (m^2 * (n^3 - n) - m * Tj)
   } else {
     S <- var(R) * (n - 1)
-    W <- (12 * S) / (m^2 * (n^3 - n))
+    W <- (12 * S) /
+      (m^2 * (n^3 - n))
   }
   W
 }
@@ -609,8 +626,7 @@ kendalls_w <- function(x,
 
 .safe_ranktransform <- function(x, verbose = TRUE, ...) {
   if (insight::n_unique(x) == 1) {
-    if (verbose) warning(""Only one unique value - rank fixed at 1"")
-    return(rep(1, length(x)))
+    return(rep(mean(seq_along(x)), length(x)))
   }
   datawizard::ranktransform(x, method = ""average"", ..., verbose = FALSE)
 }

---FILE: R/utils_validate_input_data.R---
@@ -162,6 +162,7 @@
   if (wide) {
     x <- datawizard::data_to_wide(x,
                                   values_from = ""x"",
+                                  rows_from = ""blocks"",
                                   colnames_from = ""groups"")
     x <- x[,-1]
   }

---FILE: man/rank_biserial.Rd---
@@ -46,6 +46,7 @@ kendalls_w(
   groups,
   blocks,
   data = NULL,
+  blocks_on_rows = TRUE,
   ci = 0.95,
   alternative = ""greater"",
   iterations = 200,
@@ -61,8 +62,9 @@ kendalls_w(
 \code{rank_epsilon_squared()}) or \code{DV ~ groups | blocks} (for \code{kendalls_w()};
 See details for the \code{blocks} and \code{groups} terminology used here).
 \item A list of vectors (for \code{rank_epsilon_squared()}).
-\item A matrix of \verb{blocks x groups} (for \code{kendalls_w()}). See details for the
-\code{blocks} and \code{groups} terminology used here.
+\item A matrix of \verb{blocks x groups} (for \code{kendalls_w()}) (or \verb{groups x blocks}
+if \code{blocks_on_rows = FALSE}). See details for the \code{blocks} and \code{groups}
+terminology used here.
 }}
 
 \item{y}{An optional numeric vector of data values to compare to \code{x}, or a
@@ -99,6 +101,8 @@ intervals. Only applies when \code{ci} is not \code{NULL}. (Deprecated for
 \item{groups, blocks}{A factor vector giving the group / block for the
 corresponding elements of \code{x}, or a character name of one in \code{data}.
 Ignored if \code{x} is not a vector.}
+
+\item{blocks_on_rows}{Are blocks on rows (\code{TRUE}) or columns (\code{FALSE}).}
 }
 \value{
 A data frame with the effect size (\code{r_rank_biserial},

---FILE: tests/testthat/test-rankES.R---
@@ -108,5 +108,19 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     W <- kendalls_w(mrt ~ interaction(condition, congruency) | pno, data = dat)
     expect_equal(W[[1]], 0.4011, tolerance = 0.01)
+
+
+
+    # singular ties
+    m <- rbind(
+      c(1, 2, 3, 4),
+      c(7, 7, 7, 7), # THIS
+      c(2, 3, 1, 4)
+    )
+
+    expect_warning(kendalls_w(m, ci = NULL), ""contain ties"")
+    expect_warning(W <- kendalls_w(m, ci = NULL), ""unique ranking"")
+    expect_equal(W[[1]], 0.4666667, tolerance = 0.001)
+    expect_equal(kendalls_w(t(m), blocks_on_rows = FALSE, ci = NULL, verbose = FALSE)[[1]], W[[1]])
   })
 }",True,False,Documentation / Formatting,6
easystats,effectsize,133daee9b62a5145639e00880fde3e57082c07c6,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2022-05-26T13:30:17Z,GitHub,noreply@github.com,2022-05-26T13:30:17Z,"CRAN 0.7 (#447)

* remove format std pars

* version bump

* fix typo

* use updated versions of easystats

* Update cran-comments.md

* run revdep

* add recommendation

* datawiz version bump

* use parameters from CRAN

* Update README.md

* update to roxygen7.2

@IndrajeetPatil

* fix rd issue

* remove bad URL

* Update cran-comments.md

Co-authored-by: Daniel <mail@danielluedecke.de>",DESCRIPTION;NAMESPACE;NEWS.md;R/print.effectsize_table.R;R/xtab.R;README.md;cran-comments.md;man/effectsize_CIs.Rd;man/phi.Rd;vignettes/anovaES.Rmd;vignettes/simple_htests.Rmd,True,True,True,False,102,132,234,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size and Standardized Parameters
-Version: 0.6.0.7
+Version: 0.7.0
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",
@@ -56,11 +56,11 @@ BugReports: https://github.com/easystats/effectsize/issues/
 Depends:
     R (>= 3.4)
 Imports:
-    bayestestR (>= 0.11.5.1),
-    insight (>= 0.16.0.16),
-    parameters (>= 0.17.0.10),
-    performance (>= 0.8.0.8),
-    datawizard (>= 0.4.0.17),
+    bayestestR (>= 0.12.1),
+    insight (>= 0.17.0),
+    parameters (>= 0.18.0),
+    performance (>= 0.9.0),
+    datawizard (>= 0.4.1),
     stats,
     utils
 Suggests:
@@ -91,17 +91,11 @@ Suggests:
     spelling,
     testthat,
     tidymodels
-Remotes:
-    easystats/insight,
-    easystats/performance,
-    easystats/parameters,
-    easystats/datawizard,
-    easystats/bayestestR
 VignetteBuilder: 
     knitr
 Encoding: UTF-8
 Language: en-US
 Roxygen: list(markdown = TRUE)
-RoxygenNote: 7.1.2
+RoxygenNote: 7.2.0
 Config/testthat/edition: 3
 Config/testthat/parallel: true

---FILE: NAMESPACE---
@@ -16,7 +16,6 @@ S3method(eta_squared_posterior,brmsfit)
 S3method(eta_squared_posterior,stanreg)
 S3method(format,effectsize_anova)
 S3method(format,effectsize_difference)
-S3method(format,effectsize_std_params)
 S3method(format,effectsize_table)
 S3method(format,equivalence_test_effectsize)
 S3method(format,rules)

---FILE: NEWS.md---
@@ -1,23 +1,23 @@
-# effectsize 0.6.0.3
+# effectsize 0.7.0
 
 ## Breaking Changes
 
-- `standardize_parameters()`, `standardize_posteriors()`, & `standardize_info()` have been moved to the `parameters` package.  
-- `standardize()` (for models) has been moved to the `datawizard` package.
-- `phi()` only works for 2x2 tables.
-- `cramers_v()` only works for 2D tables.
-
-## Bug fixes
-
-- `kendalls_w()` now deals with ties.  
-- `eta_squared()` works with `car::Manova()` that does not have an i-design. 
+- **`standardize_parameters()`, `standardize_posteriors()`, & `standardize_info()` have been moved to the `parameters` package.**  
+- **`standardize()` (for models) has been moved to the `datawizard` package.**  
+- `phi()` only works for 2x2 tables.  
+- `cramers_v()` only works for 2D tables.  
 
 ## New features
 
 - `normalized_chi()` gives an adjusted Cohen's *w* for goodness of fit.
 - `cohens_w()` is now a fully-fledged function for x-tables and goodness-of-fit effect size (not just an alias for `phi()`).
 - Support for `insight`'s `display`, `print_md` and `print_html` for all `{effectsize}` outputs.
 
+## Bug fixes
+
+- `kendalls_w()` now deals with ties.  
+- `eta_squared()` works with `car::Manova()` that does not have an i-design. 
+
 # effectsize 0.6.0.1
 
 *This is a patch release.*

---FILE: R/print.effectsize_table.R---
@@ -189,33 +189,6 @@ format.effectsize_anova <- function(x, digits = 2, ...) {
   format.effectsize_table(x, digits = digits, ...)
 }
 
-#' @export
-format.effectsize_std_params <- function(x, digits = 2, ...) {
-  footer <- caption <- subtitle <- NULL
-
-  caption <- sprintf(""Standardization method: %s"", attr(x, ""std_method""))
-
-  # robust / two_sd
-  if (attr(x, ""two_sd"") || attr(x, ""robust"")) {
-    footer <- sprintf(""Scaled by %s %s%s from the %s."",
-                      ifelse(attr(x, ""two_sd""), ""two"", ""one""),
-                      ifelse(attr(x, ""robust""), ""MAD"", ""SD""),
-                      ifelse(attr(x, ""two_sd""), ""s"", """"),
-                      ifelse(attr(x, ""robust""), ""median"", ""mean""))
-  }
-
-  # include_response
-  if (!attr(x, ""include_response"")) {
-    resp_footer <- ""Response is unstandardized.""
-    footer <- c(footer, resp_footer)
-  }
-
-  attr(x, ""table_footer"") <- footer
-  attr(x, ""table_caption"") <- caption
-  attr(x, ""table_subtitle"") <- subtitle
-  format.effectsize_table(x, digits = digits, ...)
-}
-
 #' @export
 format.equivalence_test_effectsize <- function(x, digits = 2, ...) {
   colnames(x)[colnames(x) == ""ROPE_Equivalence""] <- ""H0""

---FILE: R/xtab.R---
@@ -26,20 +26,26 @@
 #' Pearson's *C* should be used, as they are bounded between 0-1. Cohen's *w*
 #' can also be used, but since it is not bounded at 1 (can be larger) its
 #' interpretation is more difficult.
-#' \cr\cr
+#' \cr \cr
 #' For goodness-of-fit in 1D tables Cohen's *W*, normalized Chi (\eqn{\chi}) or
 #' Pearson's *C* can be used. Cohen's *w* has no upper bound (can be arbitrarily
 #' large, depending on the expected distribution). Normalized Chi is an adjusted
 #' Cohen's *w*, accounting for the expected distribution, making it bounded
 #' between 0-1. Pearson's *C* is also bounded between 0-1.
-#' \cr\cr
+#' \cr \cr
+#' To summarize, for correlation-like effect sizes, we recommend:
+#'
+#' - For a 2x2 table, use `phi()`
+#' - For larger tables, use `cramers_v()`
+#' - For goodness-of-fit, use `normalized_chi()`
+#' \cr \cr
 #' For 2-by-2 contingency tables, Odds ratios, Risk ratios and Cohen's *h* can
 #' also be estimated. Note that these are computed with each **column**
 #' representing the different groups, and the *first* column representing the
 #' treatment group and the *second* column baseline (or control). Effects are
 #' given as `treatment / control`. If you wish you use rows as groups you must
 #' pass a transposed table, or switch the `x` and `y` arguments.
-#' \cr\cr
+#' \cr \cr
 #' Cohen's *g* is an effect size for dependent (paired) contingency tables
 #' ranging between 0 (perfect symmetry) and 0.5 (perfect asymmetry) (see
 #' [stats::mcnemar.test()]).
@@ -48,13 +54,13 @@
 #' For Cohen's *g*, confidence intervals are based on the proportion (\eqn{P = g
 #' + 0.5}) confidence intervals returned by [stats::prop.test()] (minus 0.5),
 #' which give a good close approximation.
-#' \cr\cr
+#' \cr \cr
 #' For Odds ratios, Risk ratios and Cohen's *h*, confidence intervals are
 #' estimated using the standard normal parametric method (see Katz et al., 1978;
 #' Szumilas, 2010).
-#' \cr\cr
-#' See *Confidence (Compatibility) Intervals (CIs)*, *CIs and Significance
-#' Tests*, and *One-Sided CIs* sections for *phi*, Cohen's *w*, Cramer's *V*,
+#' \cr \cr
+#' See *Confidence (Compatibility) Intervals (CIs)*, *CIs and Significance Tests*,
+#' and *One-Sided CIs* sections for *phi*, Cohen's *w*, Cramer's *V*,
 #' Pearson's *C*, and normalized Chi.
 #'
 #' @inheritSection effectsize_CIs Confidence (Compatibility) Intervals (CIs)

---FILE: README.md---
@@ -6,7 +6,7 @@
 [![total](https://cranlogs.r-pkg.org/badges/grand-total/effectsize)](https://cran.r-project.org/package=effectsize/)
 [![status](https://tinyverse.netlify.com/badge/effectsize/)](https://CRAN.R-project.org/package=effectsize/)
 
-***Significant is just not enough\!***
+***Significant is just not enough!***
 
 The goal of this package is to provide utilities to work with indices of
 effect size and standardized parameters, allowing computation and
@@ -29,21 +29,17 @@ CRAN:
 install.packages(""effectsize"")
 ```
 
-Or you can install the latest development version `0.6.0.3` from
+Or you can install the latest development version `0.6.0.7` from
 [*R-universe*](https://easystats.r-universe.dev):
 
 ``` r
 install.packages(""effectsize"", repos = ""https://easystats.r-universe.dev/"")
 ```
 
 <!-- Or from *GitHub*: -->
-
 <!-- ```{r, warning=FALSE, message=FALSE, eval=FALSE} -->
-
 <!-- if (!require(""remotes"")) install.packages(""remotes"") -->
-
 <!-- remotes::install_github(""easystats/effectsize"") -->
-
 <!-- ``` -->
 
 ## Documentation
@@ -57,21 +53,17 @@ Click on the buttons above to access the package
 [**easystats blog**](https://easystats.github.io/blog/posts/), and
 check-out these vignettes:
 
-  - **Effect Sizes**
-      - [**Parameter and Model
-        Standardization**](https://easystats.github.io/effectsize/articles/standardize_parameters.html)
-      - [**ANOVA Effect
-        Sizes**](https://easystats.github.io/effectsize/articles/anovaES.html)
-      - [**Effect Sizes in Bayesian
-        Models**](https://easystats.github.io/effectsize/articles/bayesian_models.html)  
-      - [**For Simple Hypothesis
+-   **Effect Sizes**
+    -   [**For Simple Hypothesis
         Tests**](https://easystats.github.io/effectsize/articles/simple_htests.html)  
-  - **Effect Sizes Conversion**
-      - [**Between Effect
+    -   [**ANOVA Effect
+        Sizes**](https://easystats.github.io/effectsize/articles/anovaES.html)
+-   **Effect Sizes Conversion**
+    -   [**Between Effect
         Sizes**](https://easystats.github.io/effectsize/articles/convert.html)
-      - [**Effect Size from Test
+    -   [**Effect Size from Test
         Statistics**](https://easystats.github.io/effectsize/articles/from_test_statistics.html)
-  - [**Automated Interpretation of Indices of Effect
+-   [**Automated Interpretation of Indices of Effect
     Size**](https://easystats.github.io/effectsize/articles/interpret.html)
 
 # Features
@@ -149,38 +141,16 @@ epsilon_squared(model)
 
 And moreâ¦
 
-### Regression Models (Standardized Parameters)
-
-Importantly, `effectsize` also provides [advanced
-methods](https://easystats.github.io/effectsize/articles/standardize_parameters.html)
-to compute standardized parameters for regression models.
-
-``` r
-m <- lm(rating ~ complaints + privileges + advance, data = attitude)
-
-standardize_parameters(m)
-## # Standardization method: refit
-## 
-## Parameter   | Coefficient (std.) |        95% CI
-## ------------------------------------------------
-## (Intercept) |          -9.57e-16 | [-0.22, 0.22]
-## complaints  |               0.85 | [ 0.58, 1.13]
-## privileges  |              -0.04 | [-0.33, 0.24]
-## advance     |              -0.02 | [-0.26, 0.22]
-```
-
-Also, models can be re-fit with standardized data:
-
-``` r
-standardize(m)
-## 
-## Call:
-## lm(formula = rating ~ complaints + privileges + advance, data = data_std)
-## 
-## Coefficients:
-## (Intercept)   complaints   privileges      advance  
-##   -9.57e-16     8.55e-01    -4.35e-02    -2.19e-02
-```
+<!-- ### Regression Models (Standardized Parameters) -->
+<!-- Importantly, `effectsize` also provides [advanced methods](https://easystats.github.io/effectsize/articles/standardize_parameters.html) to compute standardized parameters for regression models. -->
+<!-- ```{r beta, warning=FALSE, message=FALSE} -->
+<!-- m <- lm(rating ~ complaints + privileges + advance, data = attitude) -->
+<!-- standardize_parameters(m) -->
+<!-- ``` -->
+<!-- Also, models can be re-fit with standardized data: -->
+<!-- ```{r std-model, warning=FALSE, message=FALSE} -->
+<!-- standardize(m) -->
+<!-- ``` -->
 
 ## Effect Size Conversion
 
@@ -245,7 +215,7 @@ interpret_cohens_d(d = 0.45, rules = ""gignac2016"")
 
 In order to cite this package, please use the following citation:
 
-  - Ben-Shachar M, LÃ¼decke D, Makowski D (2020). effectsize: Estimation
+-   Ben-Shachar M, LÃ¼decke D, Makowski D (2020). effectsize: Estimation
     of Effect Size Indices and Standardized Parameters. *Journal of Open
     Source Software*, *5*(56), 2815. doi: 10.21105/joss.02815
 

---FILE: cran-comments.md---
@@ -6,7 +6,7 @@ All URL issues have been resolved.
 * GitHub Actions
     - Windows:        devel, release, oldrel
     - macOS:          devel, release, oldrel
-    - ubuntu-16.04:   devel, release, oldrel, 3.6, 3.5, 3.4
+    - ubuntu-16.04:   devel, release, oldrel, 4.0, 3.6, 3.5, 3.4
 * win-builder:        release
 
 
@@ -18,11 +18,12 @@ All URL issues have been resolved.
 ### Known issues
 
 - Failed handshake with *shinyapps.io* is a false positive.
+- Unavailable DOI link are false positives.
 
 
 ## revdepcheck results
 
-We checked 16 reverse dependencies, comparing R CMD check results across CRAN and dev versions of this package.
+We checked 17 reverse dependencies, comparing R CMD check results across CRAN and dev versions of this package.
 
  * We saw 0 new problems
  * We failed to check 0 packages

---FILE: man/effectsize_CIs.Rd---
@@ -96,41 +96,57 @@ An alternative approach to aligning significance tests using CIs and 1-tailed
 conducting \strong{equivalence tests}. For example, a 90\% 2-sided interval gives
 the bounds for an equivalence test with \eqn{\alpha} = .05. However, be aware
 that this interval does not give 95\% coverage for the underlying effect size
-parameter value. For that, construct a 95\% 2-sided CI.\if{html}{\out{<div class=""sourceCode r"">}}\preformatted{data(""hardlyworking"")
+parameter value. For that, construct a 95\% 2-sided CI.
+
+\if{html}{\out{<div class=""sourceCode r"">}}\preformatted{data(""hardlyworking"")
 fit <- lm(salary ~ n_comps + age, data = hardlyworking)
 eta_squared(fit) # default, ci = 0.95, alternative = ""greater""
-}\if{html}{\out{</div>}}\preformatted{## # Effect Size for ANOVA (Type I)
+}\if{html}{\out{</div>}}
+
+\if{html}{\out{<div class=""sourceCode"">}}\preformatted{## # Effect Size for ANOVA (Type I)
 ## 
 ## Parameter | Eta2 (partial) |       95\% CI
 ## -----------------------------------------
 ## n_comps   |           0.21 | [0.16, 1.00]
 ## age       |           0.10 | [0.06, 1.00]
 ## 
 ## - One-sided CIs: upper bound fixed at [1.00].
-}\if{html}{\out{<div class=""sourceCode r"">}}\preformatted{eta_squared(fit, alternative = ""less"") # Test is eta is smaller than some value
-}\if{html}{\out{</div>}}\preformatted{## # Effect Size for ANOVA (Type I)
+}\if{html}{\out{</div>}}
+
+\if{html}{\out{<div class=""sourceCode r"">}}\preformatted{eta_squared(fit, alternative = ""less"") # Test is eta is smaller than some value
+}\if{html}{\out{</div>}}
+
+\if{html}{\out{<div class=""sourceCode"">}}\preformatted{## # Effect Size for ANOVA (Type I)
 ## 
 ## Parameter | Eta2 (partial) |       95\% CI
 ## -----------------------------------------
 ## n_comps   |           0.21 | [0.00, 0.26]
 ## age       |           0.10 | [0.00, 0.14]
 ## 
 ## - One-sided CIs: lower bound fixed at [0.00].
-}\if{html}{\out{<div class=""sourceCode r"">}}\preformatted{eta_squared(fit, alternative = ""two.sided"") # 2-sided bounds for alpha = .05
-}\if{html}{\out{</div>}}\preformatted{## # Effect Size for ANOVA (Type I)
+}\if{html}{\out{</div>}}
+
+\if{html}{\out{<div class=""sourceCode r"">}}\preformatted{eta_squared(fit, alternative = ""two.sided"") # 2-sided bounds for alpha = .05
+}\if{html}{\out{</div>}}
+
+\if{html}{\out{<div class=""sourceCode"">}}\preformatted{## # Effect Size for ANOVA (Type I)
 ## 
 ## Parameter | Eta2 (partial) |       95\% CI
 ## -----------------------------------------
 ## n_comps   |           0.21 | [0.15, 0.27]
 ## age       |           0.10 | [0.06, 0.15]
-}\if{html}{\out{<div class=""sourceCode r"">}}\preformatted{eta_squared(fit, ci = 0.9, alternative = ""two.sided"") # both 1-sided bounds for alpha = .05
-}\if{html}{\out{</div>}}\preformatted{## # Effect Size for ANOVA (Type I)
+}\if{html}{\out{</div>}}
+
+\if{html}{\out{<div class=""sourceCode r"">}}\preformatted{eta_squared(fit, ci = 0.9, alternative = ""two.sided"") # both 1-sided bounds for alpha = .05
+}\if{html}{\out{</div>}}
+
+\if{html}{\out{<div class=""sourceCode"">}}\preformatted{## # Effect Size for ANOVA (Type I)
 ## 
 ## Parameter | Eta2 (partial) |       90\% CI
 ## -----------------------------------------
 ## n_comps   |           0.21 | [0.16, 0.26]
 ## age       |           0.10 | [0.06, 0.14]
-}
+}\if{html}{\out{</div>}}
 }
 
 \section{CI Does Not Contain the Estimate}{
@@ -139,11 +155,15 @@ For very large sample sizes or effect sizes, the width of the CI can be
 smaller than the tolerance of the optimizer, resulting in CIs of width 0.
 This can also result in the estimated CIs excluding the point estimate.
 
-For example:\if{html}{\out{<div class=""sourceCode r"">}}\preformatted{t_to_d(80, df_error = 4555555)
-}\if{html}{\out{</div>}}\preformatted{## d    |       95\% CI
+For example:
+
+\if{html}{\out{<div class=""sourceCode r"">}}\preformatted{t_to_d(80, df_error = 4555555)
+}\if{html}{\out{</div>}}
+
+\if{html}{\out{<div class=""sourceCode"">}}\preformatted{## d    |       95\% CI
 ## -------------------
 ## 0.07 | [0.08, 0.08]
-}
+}\if{html}{\out{</div>}}
 
 In these cases, consider an alternative optimizer, or an alternative method
 for computing CIs, such as the bootstrap.

---FILE: man/phi.Rd---
@@ -81,35 +81,42 @@ dependence) and 1 (perfect dependence). For larger tables, Cramer's \emph{V} or
 Pearson's \emph{C} should be used, as they are bounded between 0-1. Cohen's \emph{w}
 can also be used, but since it is not bounded at 1 (can be larger) its
 interpretation is more difficult.
-\cr\cr
+\cr \cr
 For goodness-of-fit in 1D tables Cohen's \emph{W}, normalized Chi (\eqn{\chi}) or
 Pearson's \emph{C} can be used. Cohen's \emph{w} has no upper bound (can be arbitrarily
 large, depending on the expected distribution). Normalized Chi is an adjusted
 Cohen's \emph{w}, accounting for the expected distribution, making it bounded
 between 0-1. Pearson's \emph{C} is also bounded between 0-1.
-\cr\cr
+\cr \cr
+To summarize, for correlation-like effect sizes, we recommend:
+\itemize{
+\item For a 2x2 table, use \code{phi()}
+\item For larger tables, use \code{cramers_v()}
+\item For goodness-of-fit, use \code{normalized_chi()}
+\cr \cr
 For 2-by-2 contingency tables, Odds ratios, Risk ratios and Cohen's \emph{h} can
 also be estimated. Note that these are computed with each \strong{column}
 representing the different groups, and the \emph{first} column representing the
 treatment group and the \emph{second} column baseline (or control). Effects are
 given as \code{treatment / control}. If you wish you use rows as groups you must
 pass a transposed table, or switch the \code{x} and \code{y} arguments.
-\cr\cr
+\cr \cr
 Cohen's \emph{g} is an effect size for dependent (paired) contingency tables
 ranging between 0 (perfect symmetry) and 0.5 (perfect asymmetry) (see
 \code{\link[stats:mcnemar.test]{stats::mcnemar.test()}}).
 }
+}
 \section{Confidence Intervals for Cohen's g, OR, RR and Cohen's h}{
 For Cohen's \emph{g}, confidence intervals are based on the proportion (\eqn{P = g
 + 0.5}) confidence intervals returned by \code{\link[stats:prop.test]{stats::prop.test()}} (minus 0.5),
 which give a good close approximation.
-\cr\cr
+\cr \cr
 For Odds ratios, Risk ratios and Cohen's \emph{h}, confidence intervals are
 estimated using the standard normal parametric method (see Katz et al., 1978;
 Szumilas, 2010).
-\cr\cr
-See \emph{Confidence (Compatibility) Intervals (CIs)}, \emph{CIs and Significance
-Tests}, and \emph{One-Sided CIs} sections for \emph{phi}, Cohen's \emph{w}, Cramer's \emph{V},
+\cr \cr
+See \emph{Confidence (Compatibility) Intervals (CIs)}, \emph{CIs and Significance Tests},
+and \emph{One-Sided CIs} sections for \emph{phi}, Cohen's \emph{w}, Cramer's \emph{V},
 Pearson's \emph{C}, and normalized Chi.
 }
 

---FILE: vignettes/anovaES.Rmd---
@@ -252,7 +252,7 @@ epsilon_squared(fit_lmm)
 omega_squared(fit_lmm)
 ```
 
-Another case where *SS*s are not available is when use Bayesian models. `effectsize` has Bayesian solutions for Bayesian models, about which you can read in the [*Effect Sizes for Bayesian Models* vignette](https://easystats.github.io/effectsize/articles/bayesian_models.html).
+Another case where *SS*s are not available is when using Bayesian models...
 
 ## For Bayesian Models
 

---FILE: vignettes/simple_htests.Rmd---
@@ -138,7 +138,7 @@ eta_squared(onew)
 
 ### 2-by-2 Tables
 
-For 2-by-2 contingency tables, $\phi$ (Phi) is homologous (though directionless) to the bi-serial correlation between the two dichotomous variables, with 0 representing to association, and 1 representing a perfect association. A ""cousin"" effect size is Pearson's contingency coefficient.
+For 2-by-2 contingency tables, $\phi$ (Phi) is homologous (though directionless) to the bi-serial correlation between the two dichotomous variables, with 0 representing no association, and 1 representing a perfect association. A ""cousin"" effect size is Pearson's contingency coefficient.
 
 ```{r}
 MPG_Gear <- table(mtcars$mpg < 20, mtcars$vs)",True,True,Documentation / Formatting,7
easystats,effectsize,b7fe5feea7fd746af5443f33eb23d170c87897b7,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2022-05-05T07:25:57Z,GitHub,noreply@github.com,2022-05-05T07:25:57Z,"Phi, x, and r for xtab (#442)

* fix phi add w

phi only allowed for 2x2
w is no longer just an alias to phi

* new chisq_correlation

horrid name #437

* rename norm_chi

* fix xtab tests

* cleanup after removal of std_pars

* Update bayesian_models.Rmd

* Update NEWS.md

* fix / remove Bayes vignette

* fix and update vignette

* fix equation for chi

* fix example

* fix CLES printing

* Update R-check.yaml

* fix vignette

* Update effectsize.Rmd",.github/workflows/R-check.yaml;NAMESPACE;NEWS.md;R/common_language.R;R/convert_between_common_language.R;R/convert_stat_chisq.R;R/effectsize.BFBayesFactor.R;R/effectsize.R;R/effectsize.htest.R;R/interpret.R;R/is_effectsize_name.R;R/xtab.R;README.Rmd;_pkgdown.yml;man/chisq_to_phi.Rd;man/effectsize.Rd;man/es_info.Rd;man/phi.Rd;tests/testthat/test-convert_statistic.R;tests/testthat/test-effectsize.R;tests/testthat/test-printing.R;tests/testthat/test-xtab.R;vignettes/anovaES.Rmd;vignettes/bayesian_models.Rmd;vignettes/effectsize.Rmd;vignettes/interpret.Rmd;vignettes/simple_htests.Rmd,True,True,True,False,642,473,1115,"---FILE: .github/workflows/R-check.yaml---
@@ -27,7 +27,7 @@ jobs:
           - {os: windows-latest, r: 'oldrel'}
           - {os: macOS-latest,   r: 'oldrel'}
           - {os: ubuntu-18.04,   r: 'oldrel'}
-          # - {os: ubuntu-18.04,   r: '4.0.0'}
+          - {os: ubuntu-18.04,   r: '4.0.0'}
           - {os: ubuntu-18.04,   r: '3.6.0'}
           - {os: ubuntu-18.04,   r: '3.5.0'}
           - {os: ubuntu-18.04,   r: '3.4.0'}

---FILE: NAMESPACE---
@@ -54,6 +54,7 @@ export(F_to_omega2)
 export(F_to_r)
 export(chisq_to_cohens_w)
 export(chisq_to_cramers_v)
+export(chisq_to_normalized)
 export(chisq_to_pearsons_c)
 export(chisq_to_phi)
 export(cles)
@@ -142,6 +143,7 @@ export(kendalls_w)
 export(logoddsratio_to_d)
 export(logoddsratio_to_r)
 export(mad_pooled)
+export(normalized_chi)
 export(odds_to_probs)
 export(oddsratio)
 export(oddsratio_to_d)

---FILE: NEWS.md---
@@ -4,6 +4,8 @@
 
 - `standardize_parameters()`, `standardize_posteriors()`, & `standardize_info()` have been moved to the `parameters` package.  
 - `standardize()` (for models) has been moved to the `datawizard` package.
+- `phi()` only works for 2x2 tables.
+- `cramers_v()` only works for 2D tables.
 
 ## Bug fixes
 
@@ -12,6 +14,8 @@
 
 ## New features
 
+- `normalized_chi()` gives an adjusted Cohen's *w* for goodness of fit.
+- `cohens_w()` is now a fully-fledged function for x-tables and goodness-of-fit effect size (not just an alias for `phi()`).
 - Support for `insight`'s `display`, `print_md` and `print_html` for all `{effectsize}` outputs.
 
 # effectsize 0.6.0.1

---FILE: R/common_language.R---
@@ -118,7 +118,7 @@ cles <- function(x,
                  ci = ci, alternative = alternative,
                  iterations = iterations)
     )
-    attr(out, ""table_footer"") <- c(""\n- Non-parametric CLES"", ""cyan"")
+    attr(out, ""table_footer"") <- ""Non-parametric CLES""
     out
   }
 }

---FILE: R/convert_between_common_language.R---
@@ -122,7 +122,7 @@ rb_to_cles.effectsize_difference <- function(rb) {
   }
 
   class(out) <- c(""effectsize_table"", class(out))
-  attr(out, ""table_footer"") <- c(""\n- Non-parametric CLES"", ""cyan"")
+  attr(out, ""table_footer"") <- ""Non-parametric CLES""
   out
 }
 

---FILE: R/convert_stat_chisq.R---
@@ -1,12 +1,12 @@
 #' Conversion Chi-Squared to Phi or Cramer's V
 #'
 #' Convert between Chi square (\eqn{\chi^2}), Cramer's V, phi (\eqn{\phi}),
-#' Cohen's *w* and Pearson's *C* for contingency tables or goodness of fit.
+#' Cohen's *w*, normalized Chi (\eqn{\chi}) and Pearson's *C* for contingency
+#' tables or goodness of fit.
 #'
 #' @param chisq The Chi-squared statistic.
 #' @param n Total sample size.
-#' @param nrow,ncol The number of rows/columns in the contingency table (ignored
-#'   for Phi when `adjust=FALSE` and `CI=NULL`).
+#' @param nrow,ncol The number of rows/columns in the contingency table.
 #' @param ci Confidence Interval (CI) level
 #' @param alternative a character string specifying the alternative hypothesis;
 #'   Controls the type of CI returned: `""greater""` (default) or `""less""`
@@ -26,16 +26,17 @@
 #' \deqn{Cramer's V = \phi / \sqrt{min(nrow,ncol)-1}}{Cramer's V = \phi / sqrt(min(nrow,ncol)-1)}
 #' \cr
 #' \deqn{Pearson's C = \sqrt{\chi^2 / (\chi^2 + n)}}{Pearson's C = sqrt(\chi^2 / (\chi^2 + n))}
+#' \cr
+#' \deqn{\chi_{Normalized} = w \times \sqrt{\frac{q}{1-q}}}{Chi (Normalized) = w * sqrt(q/(1-q))}
+#' Where `q` is the smallest of the expected probabilities.
 #' \cr\cr
-#' For adjusted versions, see Bergsma, 2013.
+#' For adjusted versions of *phi* and *V*, see Bergsma, 2013.
 #'
 #' @inheritSection effectsize_CIs Confidence (Compatibility) Intervals (CIs)
 #' @inheritSection effectsize_CIs CIs and Significance Tests
 #'
 #' @family effect size from test statistic
 #'
-#' @note Cohen's *w* is equivalent to *Phi*.
-#'
 #' @examples
 #' contingency_table <- as.table(rbind(c(762, 327, 468), c(484, 239, 477), c(484, 239, 477)))
 #'
@@ -46,21 +47,32 @@
 #' #> data:  contingency_table
 #' #> X-squared = 41.234, df = 4, p-value = 2.405e-08
 #'
-#' chisq_to_phi(41.234,
-#'   n = sum(contingency_table),
-#'   nrow = nrow(contingency_table),
-#'   ncol = ncol(contingency_table)
-#' )
-#' chisq_to_cramers_v(41.234,
+#' chisq_to_cohens_w(41.234,
 #'   n = sum(contingency_table),
 #'   nrow = nrow(contingency_table),
 #'   ncol = ncol(contingency_table)
 #' )
-#' chisq_to_pearsons_c(41.234,
-#'   n = sum(contingency_table),
-#'   nrow = nrow(contingency_table),
-#'   ncol = ncol(contingency_table)
+#'
+#'
+#'
+#'
+#' Smoking_ASD <- as.table(c(ASD = 17, ASP = 11, TD = 640))
+#'
+#' # chisq.test(Smoking_ASD, p = c(0.015, 0.010, 0.975))
+#' #>
+#' #> 	Chi-squared test for given probabilities
+#' #>
+#' #> data:  Smoking_ASD
+#' #> X-squared = 7.8521, df = 2, p-value = 0.01972
+#'
+#' chisq_to_normalized(
+#'   7.8521,
+#'   n = sum(Smoking_ASD),
+#'   nrow = 1,
+#'   ncol = 3,
+#'   p = c(0.015, 0.010, 0.975)
 #' )
+#'
 #' @references
 #' - Cumming, G., & Finch, S. (2001). A primer on the understanding, use, and
 #' calculation of confidence intervals that are based on central and noncentral
@@ -69,18 +81,32 @@
 #' - Bergsma, W. (2013). A bias-correction for Cramer's V and Tschuprow's T.
 #' Journal of the Korean Statistical Society, 42(3), 323-328.
 #'
+#' - Johnston, J. E., Berry, K. J., & Mielke Jr, P. W. (2006). Measures of
+#' effect size for chi-squared and likelihood-ratio goodness-of-fit tests.
+#' Perceptual and motor skills, 103(2), 412-414.
+#'
+#' - Rosenberg, M. S. (2010). A generalized formula for converting chi-square
+#' tests to effect sizes for meta-analysis. PloS one, 5(4), e10059.
+#'
 #' @export
-chisq_to_phi <- function(chisq, n, nrow, ncol, ci = 0.95, alternative = ""greater"", adjust = FALSE, ...) {
+chisq_to_phi <- function(chisq, n, nrow = 2, ncol = 2, ci = 0.95, alternative = ""greater"", adjust = FALSE, ...) {
   alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
+
+  cl <- match.call()
+  dont_stop <- eval(cl[[""dont_stop""]], envir = parent.frame())
+  if (is.null(dont_stop)) dont_stop <- FALSE
+
+  if (!dont_stop && (nrow != 2 || ncol != 2)) {
+    stop(""Phi is not appropriate for non-2x2 tables."")
+  }
+
   if (adjust || is.numeric(ci)) {
     is_goodness <- ncol == 1 || nrow == 1
 
     if (is_goodness) {
       df <- pmax(nrow - 1, ncol - 1)
-      max_upper <- Inf
     } else {
       df <- (nrow - 1) * (ncol - 1)
-      max_upper <- sqrt((pmin(nrow, ncol) - 1))
     }
   }
 
@@ -105,15 +131,17 @@ chisq_to_phi <- function(chisq, n, nrow, ncol, ci = 0.95, alternative = ""greater
     ))
 
     res$CI_low <-
-      chisq_to_phi(chisqs[, 1], n, nrow, ncol, ci = NULL, adjust = adjust)[[1]]
+      chisq_to_phi(chisqs[, 1], n, nrow, ncol, ci = NULL, adjust = adjust,
+                   dont_stop = dont_stop)[[1]]
     res$CI_high <-
-      chisq_to_phi(chisqs[, 2], n, nrow, ncol, ci = NULL, adjust = adjust)[[1]]
+      chisq_to_phi(chisqs[, 2], n, nrow, ncol, ci = NULL, adjust = adjust,
+                   dont_stop = dont_stop)[[1]]
 
     ci_method <- list(method = ""ncp"", distribution = ""chisq"")
     if (alternative == ""less"") {
       res$CI_low <- 0
     } else if (alternative == ""greater"") {
-      res$CI_high <- max_upper
+      res$CI_high <- 1
     }
   } else {
     alternative <- NULL
@@ -130,8 +158,35 @@ chisq_to_phi <- function(chisq, n, nrow, ncol, ci = 0.95, alternative = ""greater
 
 #' @rdname chisq_to_phi
 #' @export
-chisq_to_cohens_w <- chisq_to_phi
+chisq_to_cohens_w <- function(chisq, n, nrow, ncol, ci = 0.95, alternative = ""greater"", ...) {
+
+  res <- chisq_to_phi(chisq, n, nrow, ncol, ci = ci, alternative = alternative, adjust = FALSE, dont_stop = TRUE)
+  colnames(res)[1] <- ""Cohens_w""
+
+  max_value <- Inf
+
+  if (!missing(nrow) && !missing(ncol)) {
+
+  }
 
+  if (""CI"" %in% colnames(res)) {
+    if (ncol == 2 && nrow == 2) {
+      max_value <- 1
+    } else if (ncol == 1 || nrow == 1) {
+      max_value <- Inf # really is sqrt(chisqMax/N)
+    } else if (ncol > 2 || nrow > 2) {
+      max_value <- sqrt((pmin(ncol, nrow) - 1))
+    }
+
+    if ((alternative <- attr(res, ""alternative"")) == ""less"") {
+      res$CI_low <- 0
+    } else if (alternative == ""greater"") {
+      res$CI_high <- max_value
+    }
+  }
+
+  return(res)
+}
 
 #' @rdname chisq_to_phi
 #' @export
@@ -150,7 +205,8 @@ chisq_to_cramers_v <- function(chisq, n, nrow, ncol, ci = 0.95, alternative = ""g
 
   phi_2_V <- sqrt((pmin(k, l) - 1))
 
-  res <- chisq_to_phi(chisq, n, nrow, ncol, ci = ci, alternative = alternative, adjust = adjust)
+  res <- chisq_to_phi(chisq, n, nrow, ncol, ci = ci, alternative = alternative, adjust = adjust,
+                      dont_stop = TRUE)
   res[grepl(""^(phi|CI_)"", colnames(res))] <- res[grepl(""^(phi|CI_)"", colnames(res))] / phi_2_V
   colnames(res)[1] <- gsub(""phi"", ""Cramers_v"", colnames(res)[1])
 
@@ -164,11 +220,55 @@ chisq_to_cramers_v <- function(chisq, n, nrow, ncol, ci = 0.95, alternative = ""g
 }
 
 
+#' @rdname chisq_to_phi
+#' @export
+#' @param p Vector of expected values. See [stats::chisq.test()].
+chisq_to_normalized <- function(chisq, n, nrow, ncol, p,
+                                ci = 0.95, alternative = ""greater"", ...) {
+  if (is.numeric(ci) || (!missing(nrow) && !missing(ncol))) {
+    # This means that the user passed ncol/nrow
+    if (ncol == 2 && nrow == 2) {
+      return(chisq_to_phi(chisq, n, nrow, ncol, ci = ci, alternative = alternative))
+    } else if ((nrow != 1 && ncol > 2) || (ncol != 1 && nrow > 2)) {
+      return(chisq_to_cramers_v(chisq, n, nrow, ncol, ci = ci, alternative = alternative))
+    }
+  }
+
+  # if (!1 %in% c(nrow, ncol)) {
+  #   stop(""Correlation coefficiant is only applicable to goodness of fit tests."")
+  # }
+
+  # if (is.null(p)) {
+  #   p <- rep(1, pmax(nrow, ncol))
+  # }
+
+  if (!length(p) %in% c(ncol, nrow)) stop(""Length of `p` must match number of rows/columns."")
+  p <- p / sum(p)
+
+  q <- min(p)
+  N <- n * (1 - q) / q
+
+  res <- chisq_to_phi(chisq, N, nrow, ncol, ci = ci, alternative = alternative, adjust = FALSE, dont_stop = TRUE)
+  colnames(res)[1] <- ""normalized_chi""
+
+  if (""CI"" %in% colnames(res))
+    if ((alternative <- attr(res, ""alternative"")) == ""less"") {
+      res$CI_low <- 0
+    } else if (alternative == ""greater"") {
+      res$CI_high <- 1
+    }
+
+  is_uniform <- length(unique(p)) > 1L
+  attr(res, ""table_footer"") <- if (!is_uniform || max(ncol,nrow) > 2)
+    sprintf(""Adjusted for %suniform expected probabilities."", if (is_uniform) ""non-"" else """")
+  return(res)
+}
+
 #' @rdname chisq_to_phi
 #' @export
 chisq_to_pearsons_c <- function(chisq, n, nrow, ncol, ci = 0.95, alternative = ""greater"", ...) {
 
-  res <- chisq_to_phi(chisq, n, nrow, ncol, ci = ci, alternative = alternative, adjust = FALSE)
+  res <- chisq_to_phi(chisq, n, nrow, ncol, ci = ci, alternative = alternative, adjust = FALSE, dont_stop = TRUE)
   res[grepl(""^(phi|CI_)"", colnames(res))] <- lapply(res[grepl(""^(phi|CI_)"", colnames(res))], function(phi) sqrt(1/(1/phi^2 + 1)))
   colnames(res)[1] <- ""Pearsons_c""
 

---FILE: R/effectsize.BFBayesFactor.R---
@@ -55,7 +55,7 @@ effectsize.BFBayesFactor <- function(model, type = NULL, verbose = TRUE, test =
               v = ,
               cramers_v = cramers_v,
               w = ,
-              cohens_w = ,
+              cohens_w = cohens_w,
               phi = phi,
               c = ,
               pearsons_c = pearsons_c,

---FILE: R/effectsize.R---
@@ -12,7 +12,8 @@
 #'
 #' - For an object of class `htest`, data is extracted via [insight::get_data()], and passed to the relevant function according to:
 #'   - A **t-test** depending on `type`: `""cohens_d""` (default), `""hedges_g""`, or `""cles""`.
-#'   - A **Chi-squared tests of independence or goodness-of-fit**, depending on `type`: `""cramers_v""` (default), `""phi""`, `""cohens_w""`, `""pearsons_c""`, `""cohens_h""`, `""oddsratio""`, or `""riskratio""`.
+#'   - A **Chi-squared tests of independence**, depending on `type`: `""cramers_v""` (default), `""phi""`, `""cohens_w""`, `""pearsons_c""`, `""cohens_h""`, `""oddsratio""`, or `""riskratio""`.
+#'   - A **Chi-squared tests of goodness-of-fit**, depending on `type`: `""normalized_chi""` (default) `""cohens_w""`, `""pearsons_c""`
 #'   - A **One-way ANOVA test**, depending on `type`: `""eta""` (default), `""omega""` or `""epsilon""` -squared, `""f""`, or `""f2""`.
 #'   - A **McNemar test** returns *Cohen's g*.
 #'   - A **Wilcoxon test** depending on `type`: returns ""`rank_biserial`"" correlation (default) or `""cles""`.
@@ -42,7 +43,7 @@
 #' contingency_table <- as.table(rbind(c(762, 327, 468), c(484, 239, 477), c(484, 239, 477)))
 #' Xsq <- chisq.test(contingency_table)
 #' effectsize(Xsq)
-#' effectsize(Xsq, type = ""phi"")
+#' effectsize(Xsq, type = ""cohens_w"")
 #'
 #' Tt <- t.test(1:10, y = c(7:20), alternative = ""less"")
 #' effectsize(Tt)

---FILE: R/effectsize.htest.R---
@@ -94,42 +94,55 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
 
   dots <- list(...)
 
-  if (is.null(type)) type <- ""cramers_v""
+  Obs <- model$observed
+  Exp <- model$expected
+
+  if (!is.null(dim(Exp))) {
+    if (any(c(colSums(Obs), rowSums(Obs)) == 0L)) {
+      stop(""Cannot have empty rows/columns in the contingency tables."", call. = FALSE)
+    }
+    nr <- nrow(Obs)
+    nc <- ncol(Obs)
+  } else {
+    nr <- length(Obs)
+    nc <- 1
+  }
+
+  if (is.null(type)) {
+    if (nr == 1 || nc == 1) {
+      type <- ""normalized_chi""
+    } else {
+      type <- ""cramers_v""
+    }
+  }
+
+  if (grepl(""(c|v|w|phi)$"", tolower(type)) || tolower(type) %in% c(""normalized_chi"", ""chi"")) {
+    if (tolower(type) %in% c(""normalized_chi"", ""chi"")) {
+      p <- Exp
+    } else {
+      p <- NULL
+    }
 
-  if (grepl(""(c|v|w|phi)$"", tolower(type))) {
     f <- switch(tolower(type),
                 v = ,
                 cramers_v = chisq_to_cramers_v,
                 w = ,
-                cohens_w = ,
+                cohens_w = chisq_to_cohens_w,
                 phi = chisq_to_phi,
                 c = ,
-                pearsons_c = chisq_to_pearsons_c
+                pearsons_c = chisq_to_pearsons_c,
+                chi = ,
+                normalized_chi = chisq_to_normalized
     )
 
-    Obs <- model$observed
-    Exp <- model$expected
-
-    if (!is.null(dim(Exp))) {
-      if (any(c(colSums(Obs), rowSums(Obs)) == 0L)) {
-        stop(""Cannot have empty rows/columns in the contingency tables."", call. = FALSE)
-      }
-      nr <- nrow(Obs)
-      nc <- ncol(Obs)
-    } else {
-      nr <- length(Obs)
-      nc <- 1
-    }
-
     out <- f(
       chisq = .chisq(Obs, Exp),
       n = sum(Obs),
       nrow = nr,
       ncol = nc,
+      p = p,
       ...
     )
-    attr(out, ""approximate"") <- FALSE
-    return(out)
   } else {
     f <- switch(tolower(type),
                 or = ,
@@ -139,9 +152,11 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
                 h = ,
                 cohens_h = cohens_h
     )
+
+    out <- f(x = model$observed, ...)
   }
 
-  out <- f(x = model$observed, ...)
+  attr(out, ""approximate"") <- FALSE
   out
 }
 

---FILE: R/interpret.R---
@@ -171,6 +171,8 @@ interpret.effectsize_table <- function(x, rules, ...) {
     # xtab
     Cramers_v = ,
     Cramers_v_adjusted = ,
+    normalized_chi = ,
+    Cohens_w = ,
     phi = ,
     phi_adjusted = interpret_cramers_v(value, rules = rules),
     Cohens_g = interpret_cohens_g(value, rules = rules),

---FILE: R/is_effectsize_name.R---
@@ -50,9 +50,11 @@ es_info <- matrix(c(
   ## xtab
   ""Cramers_v"", ""Cramer's V"", ""onetail"", 0, 1, 0,
   ""Cramers_v_adjusted"", ""Cramer's V (adj.)"", ""onetail"", 0, 1, 0,
-  ""phi"", ""Phi"", ""onetail"", 0, NA, 0,
-  ""phi_adjusted"", ""Phi (adj.)"", ""onetail"", 0, NA, 0,
+  ""phi"", ""Phi"", ""onetail"", 0, 1, 0,
+  ""phi_adjusted"", ""Phi (adj.)"", ""onetail"", 0, 1, 0,
   ""Pearsons_c"", ""Pearson's C"", ""onetail"", 0, 1, 0,
+  ""Cohens_w"", ""Cohen's w"", ""onetail"", 0, Inf, 0,
+  ""normalized_chi"", ""Norm. Chi"", ""onetail"", 0, 1, 0,
   ""Cohens_g"", ""Cohen's g"", ""onetail"", -0.5, 0.5, 0,
   ""Cohens_h"", ""Cohen's h"", ""twotail"", -pi, pi, 0,
   ""Odds_ratio"", ""Odds ratio"", ""twotail"", 0, Inf, 1,

---FILE: R/xtab.R---
@@ -1,8 +1,9 @@
 #' Effect size for contingency tables
 #'
-#' Compute Cramer's *V*, phi (\eqn{\phi}), Cohen's *w* (an alias of phi),
-#' Pearson's contingency coefficient, Odds ratios, Risk ratios, Cohen's *h* and
-#' Cohen's *g* for contingency tables or goodness-of-fit. See details.
+#' Compute Cramer's *V*, phi (\eqn{\phi}), Cohen's *w*, normalized Chi
+#' (\eqn{\chi}), Pearson's contingency coefficient, Odds ratios, Risk ratios,
+#' Cohen's *h* and Cohen's *g* for contingency tables or goodness-of-fit. See
+#' details.
 #'
 #' @inheritParams stats::chisq.test
 #' @param ci Confidence Interval (CI) level
@@ -13,26 +14,29 @@
 #'   Partial matching is allowed (e.g., `""g""`, `""l""`, `""two""`...). See
 #'   *One-Sided CIs* in [effectsize_CIs].
 #' @param adjust Should the effect size be bias-corrected? Defaults to `FALSE`.
-#' @param ... Arguments passed to [stats::chisq.test()], such as `p`. Ignored
-#'   for `cohens_g()`.
+#' @param ... Arguments passed to [stats::chisq.test()], such as `p` for
+#'   goodness-of-fit. Ignored for `cohens_g()`.
 #'
 #' @details
-#' Cramer's *V*, phi (\eqn{\phi}) and Pearson's *C* are effect sizes for tests
-#' of independence in 2D contingency tables. For 2-by-k tables, Cramer's *V* and
-#' phi are identical, and are equal to the simple correlation between two
-#' dichotomous variables, ranging between  0 (no dependence) and 1 (perfect
-#' dependence). For larger tables, Cramer's *V* or Pearson's *C* should be used,
-#' as they are bounded between 0-1, whereas phi can be larger than 1 (upper
-#' bound is `sqrt(min(nrow, ncol) - 1))`).
+#' Cramer's *V*, phi (\eqn{\phi}), Cohen's *w*, and Pearson's *C* are effect
+#' sizes for tests of independence in 2D contingency tables. For 2-by-2 tables,
+#' Cramer's *V*, phi and Cohen's *w* are identical, and are equal to the simple
+#' correlation between two dichotomous variables, ranging between  0 (no
+#' dependence) and 1 (perfect dependence). For larger tables, Cramer's *V* or
+#' Pearson's *C* should be used, as they are bounded between 0-1. Cohen's *w*
+#' can also be used, but since it is not bounded at 1 (can be larger) its
+#' interpretation is more difficult.
 #' \cr\cr
-#' For goodness-of-fit in 1D tables Pearson's *C* or phi can be used. Phi has no
-#' upper bound (can be arbitrarily large, depending on the expected
-#' distribution), while Pearson's *C* is bounded between 0-1.
+#' For goodness-of-fit in 1D tables Cohen's *W*, normalized Chi (\eqn{\chi}) or
+#' Pearson's *C* can be used. Cohen's *w* has no upper bound (can be arbitrarily
+#' large, depending on the expected distribution). Normalized Chi is an adjusted
+#' Cohen's *w*, accounting for the expected distribution, making it bounded
+#' between 0-1. Pearson's *C* is also bounded between 0-1.
 #' \cr\cr
 #' For 2-by-2 contingency tables, Odds ratios, Risk ratios and Cohen's *h* can
 #' also be estimated. Note that these are computed with each **column**
-#' representing the different groups, and the first column representing the
-#' treatment group and the second column baseline (or control). Effects are
+#' representing the different groups, and the *first* column representing the
+#' treatment group and the *second* column baseline (or control). Effects are
 #' given as `treatment / control`. If you wish you use rows as groups you must
 #' pass a transposed table, or switch the `x` and `y` arguments.
 #' \cr\cr
@@ -50,21 +54,45 @@
 #' Szumilas, 2010).
 #' \cr\cr
 #' See *Confidence (Compatibility) Intervals (CIs)*, *CIs and Significance
-#' Tests*, and *One-Sided CIs* sections for *phi*, Cohen's *w*, Cramer's *V* and
-#' Pearson's *C*.
+#' Tests*, and *One-Sided CIs* sections for *phi*, Cohen's *w*, Cramer's *V*,
+#' Pearson's *C*, and normalized Chi.
 #'
 #' @inheritSection effectsize_CIs Confidence (Compatibility) Intervals (CIs)
 #' @inheritSection effectsize_CIs CIs and Significance Tests
 #'
 #' @return A data frame with the effect size (`Cramers_v`, `phi` (possibly with
-#'   the suffix `_adjusted`), `Odds_ratio`, `Risk_ratio` (possibly with the
-#'   prefix `log_`), `Cohens_h`, or `Cohens_g`) and its CIs (`CI_low` and
-#'   `CI_high`).
+#'   the suffix `_adjusted`), `Cohens_w`, `normalized_chi`, `Odds_ratio`,
+#'   `Risk_ratio` (possibly with the prefix `log_`), `Cohens_h`, or `Cohens_g`)
+#'   and its CIs (`CI_low` and `CI_high`).
 #'
 #' @seealso [chisq_to_phi()] for details regarding estimation and CIs.
 #' @family effect size indices
 #'
 #' @examples
+#'
+#' ## 2-by-2 tables
+#' ## -------------
+#' RCT <-
+#'   matrix(c(71, 30,
+#'            50, 100), nrow = 2, byrow = TRUE,
+#'          dimnames = list(
+#'            Diagnosis = c(""Sick"", ""Recovered""),
+#'            Group = c(""Treatment"", ""Control"")))
+#' RCT # note groups are COLUMNS
+#'
+#' phi(RCT)
+#' pearsons_c(RCT)
+#'
+#' oddsratio(RCT)
+#' oddsratio(RCT, alternative = ""greater"")
+#'
+#' riskratio(RCT)
+#'
+#' cohens_h(RCT)
+#'
+#' ## Larger tables
+#' ## -------------
+#'
 #' M <-
 #'   matrix(c(150, 100, 165,
 #'            130, 50, 65,
@@ -75,31 +103,32 @@
 #'            Study = c(""Psych"", ""Econ"", ""Law"")))
 #' M
 #'
-#' # Note that Phi is not bound to [0-1], but instead
-#' # the upper bound for phi is sqrt(min(nrow, ncol) - 1)
-#' phi(M)
+#' cohens_w(M)
 #'
 #' cramers_v(M)
 #'
 #' pearsons_c(M)
 #'
 #'
-#' ## 2-by-2 tables
-#' ## -------------
-#' RCT <-
-#'   matrix(c(71, 30,
-#'            50, 100), nrow = 2, byrow = TRUE,
-#'          dimnames = list(
-#'            Diagnosis = c(""Sick"", ""Recovered""),
-#'            Group = c(""Treatment"", ""Control"")))
-#' RCT # note groups are COLUMNS
+#' ## Goodness of fit
+#' ## ---------------
 #'
-#' oddsratio(RCT)
-#' oddsratio(RCT, alternative = ""greater"")
+#' Smoking_ASD <- as.table(c(ASD = 17, ASP = 11, TD = 640))
+#'
+#' normalized_chi(Smoking_ASD)
+#'
+#' cohens_w(Smoking_ASD)
+#'
+#' pearsons_c(Smoking_ASD)
+#'
+#' # Use custom expected values:
+#' normalized_chi(Smoking_ASD, p = c(0.015, 0.010, 0.975))
+#'
+#' cohens_w(Smoking_ASD, p = c(0.015, 0.010, 0.975))
+#'
+#' pearsons_c(Smoking_ASD, p = c(0.015, 0.010, 0.975))
 #'
-#' riskratio(RCT)
 #'
-#' cohens_h(RCT)
 #'
 #'
 #'
@@ -120,7 +149,11 @@
 #' - Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
 #' - Katz, D. J. S. M., Baptista, J., Azen, S. P., & Pike, M. C. (1978). Obtaining confidence intervals for the risk ratio in cohort studies. Biometrics, 469-474.
 #' - Szumilas, M. (2010). Explaining odds ratios. Journal of the Canadian academy of child and adolescent psychiatry, 19(3), 227.
-#'
+#' - Johnston, J. E., Berry, K. J., & Mielke Jr, P. W. (2006). Measures of
+#' effect size for chi-squared and likelihood-ratio goodness-of-fit tests.
+#' Perceptual and motor skills, 103(2), 412-414.
+#' - Rosenberg, M. S. (2010). A generalized formula for converting chi-square
+#' tests to effect sizes for meta-analysis. PloS one, 5(4), e10059.
 #' @importFrom stats chisq.test
 #' @export
 phi <- function(x, y = NULL, ci = 0.95, alternative = ""greater"", adjust = FALSE, ...) {
@@ -149,7 +182,29 @@ phi <- function(x, y = NULL, ci = 0.95, alternative = ""greater"", adjust = FALSE,
 
 #' @rdname phi
 #' @export
-cohens_w <- phi
+cohens_w <- function(x, y = NULL, ci = 0.95, alternative = ""greater"", ...) {
+  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
+
+  if (inherits(x, ""BFBayesFactor"")) {
+    if (!inherits(x@numerator[[1]], ""BFcontingencyTable"")) {
+      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
+    }
+    return(effectsize(x, type = ""phi"", ci = ci, ...))
+  }
+
+
+  if (inherits(x, ""htest"")) {
+    if (!(grepl(""Pearson's Chi-squared"", x$method) ||
+          grepl(""Chi-squared test for given probabilities"", x$method))) {
+      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
+    }
+  } else {
+    x <- suppressWarnings(stats::chisq.test(x, y, ...))
+    x$data.name <- NULL
+  }
+
+  effectsize(x, type = ""cohens_w"", ci = ci, alternative = alternative)
+}
 
 #' @rdname phi
 #' @importFrom stats chisq.test
@@ -179,6 +234,29 @@ cramers_v <- function(x, y = NULL, ci = 0.95, alternative = ""greater"", adjust =
 }
 
 
+#' @rdname phi
+#' @export
+normalized_chi <- function(x, y = NULL, ci = 0.95, alternative = ""greater"", ...) {
+  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
+
+  if (inherits(x, ""BFBayesFactor"")) {
+    stop(""Normalized Chi is only applicable to goodness of fit tests."")
+  }
+
+
+  if (inherits(x, ""htest"")) {
+    if (!(grepl(""Pearson's Chi-squared"", x$method) ||
+          grepl(""Chi-squared test for given probabilities"", x$method))) {
+      stop(""'x' is not a Chi-squared test!"", call. = FALSE)
+    }
+  } else {
+    x <- suppressWarnings(stats::chisq.test(x, y, ...))
+    x$data.name <- NULL
+  }
+
+  effectsize(x, type = ""normalized_chi"", ci = ci, alternative = alternative)
+}
+
 #' @rdname phi
 #' @importFrom stats chisq.test
 #' @export

---FILE: README.Rmd---
@@ -77,10 +77,8 @@ install.packages(""effectsize"", repos = ""https://easystats.r-universe.dev/"")
 Click on the buttons above to access the package [**documentation**](https://easystats.github.io/effectsize/) and the [**easystats blog**](https://easystats.github.io/blog/posts/), and check-out these vignettes:
 
 - **Effect Sizes**  
-  - [**Parameter and Model Standardization**](https://easystats.github.io/effectsize/articles/standardize_parameters.html)
-  - [**ANOVA Effect Sizes**](https://easystats.github.io/effectsize/articles/anovaES.html)
-  - [**Effect Sizes in Bayesian Models**](https://easystats.github.io/effectsize/articles/bayesian_models.html)  
   - [**For Simple Hypothesis Tests**](https://easystats.github.io/effectsize/articles/simple_htests.html)  
+  - [**ANOVA Effect Sizes**](https://easystats.github.io/effectsize/articles/anovaES.html)
 - **Effect Sizes Conversion**    
   - [**Between Effect Sizes**](https://easystats.github.io/effectsize/articles/convert.html)
   - [**Effect Size from Test Statistics**](https://easystats.github.io/effectsize/articles/from_test_statistics.html)

---FILE: _pkgdown.yml---
@@ -41,8 +41,6 @@ navbar:
         href: articles/simple_htests.html
       - text: ""Confidence Intervals""
         href: reference/effectsize_CIs.html
-      - text: ""For Bayesian Models""
-        href: articles/bayesian_models.html
       - text: -------
       - text: ""Extending effectsize""
         href: articles/effectsize_API.html

---FILE: man/chisq_to_phi.Rd---
@@ -4,15 +4,16 @@
 \alias{chisq_to_phi}
 \alias{chisq_to_cohens_w}
 \alias{chisq_to_cramers_v}
+\alias{chisq_to_normalized}
 \alias{chisq_to_pearsons_c}
 \alias{phi_to_chisq}
 \title{Conversion Chi-Squared to Phi or Cramer's V}
 \usage{
 chisq_to_phi(
   chisq,
   n,
-  nrow,
-  ncol,
+  nrow = 2,
+  ncol = 2,
   ci = 0.95,
   alternative = ""greater"",
   adjust = FALSE,
@@ -26,7 +27,6 @@ chisq_to_cohens_w(
   ncol,
   ci = 0.95,
   alternative = ""greater"",
-  adjust = FALSE,
   ...
 )
 
@@ -41,6 +41,17 @@ chisq_to_cramers_v(
   ...
 )
 
+chisq_to_normalized(
+  chisq,
+  n,
+  nrow,
+  ncol,
+  p,
+  ci = 0.95,
+  alternative = ""greater"",
+  ...
+)
+
 chisq_to_pearsons_c(
   chisq,
   n,
@@ -58,8 +69,7 @@ phi_to_chisq(phi, n, ...)
 
 \item{n}{Total sample size.}
 
-\item{nrow, ncol}{The number of rows/columns in the contingency table (ignored
-for Phi when \code{adjust=FALSE} and \code{CI=NULL}).}
+\item{nrow, ncol}{The number of rows/columns in the contingency table.}
 
 \item{ci}{Confidence Interval (CI) level}
 
@@ -73,6 +83,8 @@ is allowed (e.g., \code{""g""}, \code{""l""}, \code{""two""}...). See \emph{One-Sided
 
 \item{...}{Arguments passed to or from other methods.}
 
+\item{p}{Vector of expected values. See \code{\link[stats:chisq.test]{stats::chisq.test()}}.}
+
 \item{phi}{The Phi statistic.}
 }
 \value{
@@ -81,7 +93,8 @@ A data frame with the effect size(s), and confidence interval(s). See
 }
 \description{
 Convert between Chi square (\eqn{\chi^2}), Cramer's V, phi (\eqn{\phi}),
-Cohen's \emph{w} and Pearson's \emph{C} for contingency tables or goodness of fit.
+Cohen's \emph{w}, normalized Chi (\eqn{\chi}) and Pearson's \emph{C} for contingency
+tables or goodness of fit.
 }
 \details{
 These functions use the following formulae:
@@ -91,11 +104,11 @@ These functions use the following formulae:
 \deqn{Cramer's V = \phi / \sqrt{min(nrow,ncol)-1}}{Cramer's V = \phi / sqrt(min(nrow,ncol)-1)}
 \cr
 \deqn{Pearson's C = \sqrt{\chi^2 / (\chi^2 + n)}}{Pearson's C = sqrt(\chi^2 / (\chi^2 + n))}
+\cr
+\deqn{\chi_{Normalized} = w \times \sqrt{\frac{q}{1-q}}}{Chi (Normalized) = w * sqrt(q/(1-q))}
+Where \code{q} is the smallest of the expected probabilities.
 \cr\cr
-For adjusted versions, see Bergsma, 2013.
-}
-\note{
-Cohen's \emph{w} is equivalent to \emph{Phi}.
+For adjusted versions of \emph{phi} and \emph{V}, see Bergsma, 2013.
 }
 \section{Confidence (Compatibility) Intervals (CIs)}{
 
@@ -146,21 +159,32 @@ contingency_table <- as.table(rbind(c(762, 327, 468), c(484, 239, 477), c(484, 2
 #> data:  contingency_table
 #> X-squared = 41.234, df = 4, p-value = 2.405e-08
 
-chisq_to_phi(41.234,
+chisq_to_cohens_w(41.234,
   n = sum(contingency_table),
   nrow = nrow(contingency_table),
   ncol = ncol(contingency_table)
 )
-chisq_to_cramers_v(41.234,
-  n = sum(contingency_table),
-  nrow = nrow(contingency_table),
-  ncol = ncol(contingency_table)
-)
-chisq_to_pearsons_c(41.234,
-  n = sum(contingency_table),
-  nrow = nrow(contingency_table),
-  ncol = ncol(contingency_table)
+
+
+
+
+Smoking_ASD <- as.table(c(ASD = 17, ASP = 11, TD = 640))
+
+# chisq.test(Smoking_ASD, p = c(0.015, 0.010, 0.975))
+#>
+#> 	Chi-squared test for given probabilities
+#>
+#> data:  Smoking_ASD
+#> X-squared = 7.8521, df = 2, p-value = 0.01972
+
+chisq_to_normalized(
+  7.8521,
+  n = sum(Smoking_ASD),
+  nrow = 1,
+  ncol = 3,
+  p = c(0.015, 0.010, 0.975)
 )
+
 }
 \references{
 \itemize{
@@ -169,6 +193,11 @@ calculation of confidence intervals that are based on central and noncentral
 distributions. Educational and Psychological Measurement, 61(4), 532-574.
 \item Bergsma, W. (2013). A bias-correction for Cramer's V and Tschuprow's T.
 Journal of the Korean Statistical Society, 42(3), 323-328.
+\item Johnston, J. E., Berry, K. J., & Mielke Jr, P. W. (2006). Measures of
+effect size for chi-squared and likelihood-ratio goodness-of-fit tests.
+Perceptual and motor skills, 103(2), 412-414.
+\item Rosenberg, M. S. (2010). A generalized formula for converting chi-square
+tests to effect sizes for meta-analysis. PloS one, 5(4), e10059.
 }
 }
 \seealso{

---FILE: man/effectsize.Rd---
@@ -46,7 +46,8 @@ input model. See details.
 \item For an object of class \code{htest}, data is extracted via \code{\link[insight:get_data]{insight::get_data()}}, and passed to the relevant function according to:
 \itemize{
 \item A \strong{t-test} depending on \code{type}: \code{""cohens_d""} (default), \code{""hedges_g""}, or \code{""cles""}.
-\item A \strong{Chi-squared tests of independence or goodness-of-fit}, depending on \code{type}: \code{""cramers_v""} (default), \code{""phi""}, \code{""cohens_w""}, \code{""pearsons_c""}, \code{""cohens_h""}, \code{""oddsratio""}, or \code{""riskratio""}.
+\item A \strong{Chi-squared tests of independence}, depending on \code{type}: \code{""cramers_v""} (default), \code{""phi""}, \code{""cohens_w""}, \code{""pearsons_c""}, \code{""cohens_h""}, \code{""oddsratio""}, or \code{""riskratio""}.
+\item A \strong{Chi-squared tests of goodness-of-fit}, depending on \code{type}: \code{""normalized_chi""} (default) \code{""cohens_w""}, \code{""pearsons_c""}
 \item A \strong{One-way ANOVA test}, depending on \code{type}: \code{""eta""} (default), \code{""omega""} or \code{""epsilon""} -squared, \code{""f""}, or \code{""f2""}.
 \item A \strong{McNemar test} returns \emph{Cohen's g}.
 \item A \strong{Wilcoxon test} depending on \code{type}: returns ""\code{rank_biserial}"" correlation (default) or \code{""cles""}.
@@ -75,7 +76,7 @@ functions, for the full range of options they provide.}
 contingency_table <- as.table(rbind(c(762, 327, 468), c(484, 239, 477), c(484, 239, 477)))
 Xsq <- chisq.test(contingency_table)
 effectsize(Xsq)
-effectsize(Xsq, type = ""phi"")
+effectsize(Xsq, type = ""cohens_w"")
 
 Tt <- t.test(1:10, y = c(7:20), alternative = ""less"")
 effectsize(Tt)

---FILE: man/es_info.Rd---
@@ -5,7 +5,7 @@
 \alias{es_info}
 \title{List of effect size names}
 \format{
-An object of class \code{data.frame} with 40 rows and 6 columns.
+An object of class \code{data.frame} with 42 rows and 6 columns.
 }
 \usage{
 es_info

---FILE: man/phi.Rd---
@@ -4,6 +4,7 @@
 \alias{phi}
 \alias{cohens_w}
 \alias{cramers_v}
+\alias{normalized_chi}
 \alias{pearsons_c}
 \alias{oddsratio}
 \alias{riskratio}
@@ -13,10 +14,12 @@
 \usage{
 phi(x, y = NULL, ci = 0.95, alternative = ""greater"", adjust = FALSE, ...)
 
-cohens_w(x, y = NULL, ci = 0.95, alternative = ""greater"", adjust = FALSE, ...)
+cohens_w(x, y = NULL, ci = 0.95, alternative = ""greater"", ...)
 
 cramers_v(x, y = NULL, ci = 0.95, alternative = ""greater"", adjust = FALSE, ...)
 
+normalized_chi(x, y = NULL, ci = 0.95, alternative = ""greater"", ...)
+
 pearsons_c(
   x,
   y = NULL,
@@ -52,39 +55,43 @@ Partial matching is allowed (e.g., \code{""g""}, \code{""l""}, \code{""two""}...). See
 
 \item{adjust}{Should the effect size be bias-corrected? Defaults to \code{FALSE}.}
 
-\item{...}{Arguments passed to \code{\link[stats:chisq.test]{stats::chisq.test()}}, such as \code{p}. Ignored
-for \code{cohens_g()}.}
+\item{...}{Arguments passed to \code{\link[stats:chisq.test]{stats::chisq.test()}}, such as \code{p} for
+goodness-of-fit. Ignored for \code{cohens_g()}.}
 
 \item{log}{Take in or output the log of the ratio (such as in logistic models).}
 }
 \value{
 A data frame with the effect size (\code{Cramers_v}, \code{phi} (possibly with
-the suffix \verb{_adjusted}), \code{Odds_ratio}, \code{Risk_ratio} (possibly with the
-prefix \code{log_}), \code{Cohens_h}, or \code{Cohens_g}) and its CIs (\code{CI_low} and
-\code{CI_high}).
+the suffix \verb{_adjusted}), \code{Cohens_w}, \code{normalized_chi}, \code{Odds_ratio},
+\code{Risk_ratio} (possibly with the prefix \code{log_}), \code{Cohens_h}, or \code{Cohens_g})
+and its CIs (\code{CI_low} and \code{CI_high}).
 }
 \description{
-Compute Cramer's \emph{V}, phi (\eqn{\phi}), Cohen's \emph{w} (an alias of phi),
-Pearson's contingency coefficient, Odds ratios, Risk ratios, Cohen's \emph{h} and
-Cohen's \emph{g} for contingency tables or goodness-of-fit. See details.
+Compute Cramer's \emph{V}, phi (\eqn{\phi}), Cohen's \emph{w}, normalized Chi
+(\eqn{\chi}), Pearson's contingency coefficient, Odds ratios, Risk ratios,
+Cohen's \emph{h} and Cohen's \emph{g} for contingency tables or goodness-of-fit. See
+details.
 }
 \details{
-Cramer's \emph{V}, phi (\eqn{\phi}) and Pearson's \emph{C} are effect sizes for tests
-of independence in 2D contingency tables. For 2-by-k tables, Cramer's \emph{V} and
-phi are identical, and are equal to the simple correlation between two
-dichotomous variables, ranging between  0 (no dependence) and 1 (perfect
-dependence). For larger tables, Cramer's \emph{V} or Pearson's \emph{C} should be used,
-as they are bounded between 0-1, whereas phi can be larger than 1 (upper
-bound is \verb{sqrt(min(nrow, ncol) - 1))}).
+Cramer's \emph{V}, phi (\eqn{\phi}), Cohen's \emph{w}, and Pearson's \emph{C} are effect
+sizes for tests of independence in 2D contingency tables. For 2-by-2 tables,
+Cramer's \emph{V}, phi and Cohen's \emph{w} are identical, and are equal to the simple
+correlation between two dichotomous variables, ranging between  0 (no
+dependence) and 1 (perfect dependence). For larger tables, Cramer's \emph{V} or
+Pearson's \emph{C} should be used, as they are bounded between 0-1. Cohen's \emph{w}
+can also be used, but since it is not bounded at 1 (can be larger) its
+interpretation is more difficult.
 \cr\cr
-For goodness-of-fit in 1D tables Pearson's \emph{C} or phi can be used. Phi has no
-upper bound (can be arbitrarily large, depending on the expected
-distribution), while Pearson's \emph{C} is bounded between 0-1.
+For goodness-of-fit in 1D tables Cohen's \emph{W}, normalized Chi (\eqn{\chi}) or
+Pearson's \emph{C} can be used. Cohen's \emph{w} has no upper bound (can be arbitrarily
+large, depending on the expected distribution). Normalized Chi is an adjusted
+Cohen's \emph{w}, accounting for the expected distribution, making it bounded
+between 0-1. Pearson's \emph{C} is also bounded between 0-1.
 \cr\cr
 For 2-by-2 contingency tables, Odds ratios, Risk ratios and Cohen's \emph{h} can
 also be estimated. Note that these are computed with each \strong{column}
-representing the different groups, and the first column representing the
-treatment group and the second column baseline (or control). Effects are
+representing the different groups, and the \emph{first} column representing the
+treatment group and the \emph{second} column baseline (or control). Effects are
 given as \code{treatment / control}. If you wish you use rows as groups you must
 pass a transposed table, or switch the \code{x} and \code{y} arguments.
 \cr\cr
@@ -102,8 +109,8 @@ estimated using the standard normal parametric method (see Katz et al., 1978;
 Szumilas, 2010).
 \cr\cr
 See \emph{Confidence (Compatibility) Intervals (CIs)}, \emph{CIs and Significance
-Tests}, and \emph{One-Sided CIs} sections for \emph{phi}, Cohen's \emph{w}, Cramer's \emph{V} and
-Pearson's \emph{C}.
+Tests}, and \emph{One-Sided CIs} sections for \emph{phi}, Cohen's \emph{w}, Cramer's \emph{V},
+Pearson's \emph{C}, and normalized Chi.
 }
 
 \section{Confidence (Compatibility) Intervals (CIs)}{
@@ -146,6 +153,30 @@ to 0 to be negligible are needed (""equivalence testing""; Bauer & Kiesser,
 }
 
 \examples{
+
+## 2-by-2 tables
+## -------------
+RCT <-
+  matrix(c(71, 30,
+           50, 100), nrow = 2, byrow = TRUE,
+         dimnames = list(
+           Diagnosis = c(""Sick"", ""Recovered""),
+           Group = c(""Treatment"", ""Control"")))
+RCT # note groups are COLUMNS
+
+phi(RCT)
+pearsons_c(RCT)
+
+oddsratio(RCT)
+oddsratio(RCT, alternative = ""greater"")
+
+riskratio(RCT)
+
+cohens_h(RCT)
+
+## Larger tables
+## -------------
+
 M <-
   matrix(c(150, 100, 165,
            130, 50, 65,
@@ -156,31 +187,32 @@ M <-
            Study = c(""Psych"", ""Econ"", ""Law"")))
 M
 
-# Note that Phi is not bound to [0-1], but instead
-# the upper bound for phi is sqrt(min(nrow, ncol) - 1)
-phi(M)
+cohens_w(M)
 
 cramers_v(M)
 
 pearsons_c(M)
 
 
-## 2-by-2 tables
-## -------------
-RCT <-
-  matrix(c(71, 30,
-           50, 100), nrow = 2, byrow = TRUE,
-         dimnames = list(
-           Diagnosis = c(""Sick"", ""Recovered""),
-           Group = c(""Treatment"", ""Control"")))
-RCT # note groups are COLUMNS
+## Goodness of fit
+## ---------------
 
-oddsratio(RCT)
-oddsratio(RCT, alternative = ""greater"")
+Smoking_ASD <- as.table(c(ASD = 17, ASP = 11, TD = 640))
+
+normalized_chi(Smoking_ASD)
+
+cohens_w(Smoking_ASD)
+
+pearsons_c(Smoking_ASD)
+
+# Use custom expected values:
+normalized_chi(Smoking_ASD, p = c(0.015, 0.010, 0.975))
+
+cohens_w(Smoking_ASD, p = c(0.015, 0.010, 0.975))
+
+pearsons_c(Smoking_ASD, p = c(0.015, 0.010, 0.975))
 
-riskratio(RCT)
 
-cohens_h(RCT)
 
 
 
@@ -202,6 +234,11 @@ cohens_g(Performance)
 \item Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
 \item Katz, D. J. S. M., Baptista, J., Azen, S. P., & Pike, M. C. (1978). Obtaining confidence intervals for the risk ratio in cohort studies. Biometrics, 469-474.
 \item Szumilas, M. (2010). Explaining odds ratios. Journal of the Canadian academy of child and adolescent psychiatry, 19(3), 227.
+\item Johnston, J. E., Berry, K. J., & Mielke Jr, P. W. (2006). Measures of
+effect size for chi-squared and likelihood-ratio goodness-of-fit tests.
+Perceptual and motor skills, 103(2), 412-414.
+\item Rosenberg, M. S. (2010). A generalized formula for converting chi-square
+tests to effect sizes for meta-analysis. PloS one, 5(4), e10059.
 }
 }
 \seealso{

---FILE: tests/testthat/test-convert_statistic.R---
@@ -16,13 +16,13 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(res, cramers_v(xtab), ignore_attr = TRUE)
 
 
-    res <- chisq_to_phi(
+    res <- chisq_to_cohens_w(
       chisq$statistic,
       n = sum(xtab),
       nrow = nrow(xtab),
       ncol = ncol(xtab)
     )
-    expect_equal(res, phi(xtab), ignore_attr = TRUE)
+    expect_equal(res, cohens_w(xtab), ignore_attr = TRUE)
   })
 
   test_that(""r"", {

---FILE: tests/testthat/test-effectsize.R---
@@ -56,9 +56,8 @@ if (require(""testthat"") && require(""effectsize"")) {
     )
 
     # types
-    expect_equal(effectsize(Xsq1, type = ""phi""), phi <- phi(contingency_table))
-    expect_equal(phi(Xsq1), phi)
-
+    expect_error(effectsize(Xsq1, type = ""phi""))
+    expect_equal(effectsize(Xsq1), cramers_v(contingency_table))
     expect_equal(effectsize(Xsq1, type = ""w""), w <- cohens_w(contingency_table))
     expect_equal(cohens_w(Xsq1), w)
 
@@ -67,6 +66,9 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     contingency_table22 <- contingency_table[1:2, 1:2]
     Xsq4 <- chisq.test(contingency_table22)
+    expect_equal(effectsize(Xsq4, type = ""phi""), ph <- phi(contingency_table22))
+    expect_equal(phi(Xsq4), ph)
+
     expect_equal(effectsize(Xsq4, type = ""oddsratio""), or <- oddsratio(contingency_table22))
     expect_equal(oddsratio(Xsq4), or)
 
@@ -85,6 +87,10 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     x <- chisq.test(x = observed.dfc, p = expected.dfc)
     expect_error(effectsize(x, type = ""v""))
+    expect_error(effectsize(x, type = ""phi""))
+    expect_equal(effectsize(x), effectsize(x, type = ""chi""))
+    expect_equal(effectsize(x, type = ""chi""), nchi <- normalized_chi(observed.dfc, p = expected.dfc))
+    expect_equal(normalized_chi(x), nchi)
   })
 
   test_that(""cor.test / other"", {
@@ -222,7 +228,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     m <- lm(mpg ~ ., mtcars)
 
     expect_equal(effectsize(m),
-                 standardize_parameters(m),
+                 parameters::standardize_parameters(m),
                  ignore_attr = TRUE)
   })
 

---FILE: tests/testthat/test-printing.R---
@@ -12,21 +12,21 @@ if (require(""testthat"") && require(""effectsize"")) {
     RCT <- matrix(c(71, 30, 31, 13, 50, 100, 4, 5, 7), nrow = 3, byrow = TRUE)
     V1 <- cramers_v(RCT)
     V2 <- cramers_v(RCT, alternative = ""two"")
-    fh <- phi(RCT)
+    w <- cohens_w(RCT)
 
     expect_output(print(V1), regexp = ""[1.00]"", fixed = TRUE)
     expect_output(print(V1, digits = ""signif4""), regexp = ""[1]"", fixed = TRUE)
     expect_output(print(V1, digits = ""scientific2""), regexp = ""[1.00e+00]"", fixed = TRUE)
     expect_error(expect_output(print(V2), regexp = ""fixed""))
-    expect_output(print(fh), regexp = ""[1.41~]"", fixed = TRUE)
-    expect_output(print(fh, digits = ""signif4""), regexp = ""[1.414]"", fixed = TRUE)
-    expect_output(print(fh, digits = ""scientific2""), regexp = ""[1.41e+00]"", fixed = TRUE)
+    expect_output(print(w), regexp = ""[1.41~]"", fixed = TRUE)
+    expect_output(print(w, digits = ""signif4""), regexp = ""[1.414]"", fixed = TRUE)
+    expect_output(print(w, digits = ""scientific2""), regexp = ""[1.41e+00]"", fixed = TRUE)
 
 
     ## Column name
     expect_output(print(d), ""Cohen's d"")
     expect_output(print(V1), ""Cramer's V"")
-    expect_output(print(fh), ""Phi"")
+    expect_output(print(w), ""Cohen's w"")
 
 
     ## Interpretation
@@ -38,9 +38,9 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_output(print(V1_), regexp = ""funder2019"")
     expect_output(print(V1_), regexp = ""Interpretation"")
 
-    fh_ <- interpret(fh, rules = ""funder2019"")
-    expect_output(print(fh_), regexp = ""funder2019"")
-    expect_output(print(fh_), regexp = ""Interpretation"")
+    w_ <- interpret(w, rules = ""funder2019"")
+    expect_output(print(w_), regexp = ""funder2019"")
+    expect_output(print(w_), regexp = ""Interpretation"")
 
     ## md / html
     skip_if_not_installed(""gt"")
@@ -94,37 +94,37 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_output(print(e4), regexp = ""(Type III)"", fixed = TRUE)
   })
 
-  test_that(""print | effectsize_std_params"", {
-    mod <- lm(mpg ~ cyl + gear, mtcars)
-
-    ## Methods
-    es <- standardize_parameters(mod)
-    expect_output(print(es), regexp = ""refit"")
-
-    es <- standardize_parameters(mod, method = ""basic"")
-    expect_output(print(es), regexp = ""basic"")
-
-    ## Robust / two_sd / include_response
-    es <- standardize_parameters(mod, robust = TRUE)
-    expect_output(print(es), regexp = ""one MAD from the median"")
-
-    es <- standardize_parameters(mod, two_sd = TRUE)
-    expect_output(print(es), regexp = ""two"")
-
-    es <- standardize_parameters(mod, include_response = FALSE)
-    expect_output(print(es), regexp = ""unstandardized"")
-
-    es <- standardize_parameters(mod, include_response = FALSE, two_sd = TRUE, robust = TRUE)
-    expect_output(print(es), regexp = ""two MADs from the median"")
-
-    # ES Name
-    expect_output(print(es), regexp = ""Coefficient (std.)"", fixed = TRUE)
-
-    mod <- glm(am ~ mpg, binomial(), mtcars)
-    es <- standardize_parameters(mod, exp = TRUE)
-    expect_output(print(es), regexp = ""Odds Ratio (std.)"", fixed = TRUE)
-    expect_output(print(es), regexp = ""unstandardized"")
-  })
+  # test_that(""print | effectsize_std_params"", {
+  #   mod <- lm(mpg ~ cyl + gear, mtcars)
+  #
+  #   ## Methods
+  #   es <- standardize_parameters(mod)
+  #   expect_output(print(es), regexp = ""refit"")
+  #
+  #   es <- standardize_parameters(mod, method = ""basic"")
+  #   expect_output(print(es), regexp = ""basic"")
+  #
+  #   ## Robust / two_sd / include_response
+  #   es <- standardize_parameters(mod, robust = TRUE)
+  #   expect_output(print(es), regexp = ""one MAD from the median"")
+  #
+  #   es <- standardize_parameters(mod, two_sd = TRUE)
+  #   expect_output(print(es), regexp = ""two"")
+  #
+  #   es <- standardize_parameters(mod, include_response = FALSE)
+  #   expect_output(print(es), regexp = ""unstandardized"")
+  #
+  #   es <- standardize_parameters(mod, include_response = FALSE, two_sd = TRUE, robust = TRUE)
+  #   expect_output(print(es), regexp = ""two MADs from the median"")
+  #
+  #   # ES Name
+  #   expect_output(print(es), regexp = ""Coefficient (std.)"", fixed = TRUE)
+  #
+  #   mod <- glm(am ~ mpg, binomial(), mtcars)
+  #   es <- standardize_parameters(mod, exp = TRUE)
+  #   expect_output(print(es), regexp = ""Odds Ratio (std.)"", fixed = TRUE)
+  #   expect_output(print(es), regexp = ""unstandardized"")
+  # })
 
 
   test_that(""print | equivalence_test_effectsize"", {

---FILE: tests/testthat/test-xtab.R---
@@ -11,6 +11,8 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(res$CI_low, 0.051, tolerance = 0.01)
     expect_equal(res$CI_high, 1)
 
+    expect_error(phi(contingency_table))
+
 
     ## Size does not affect estimate
     xtab <- rbind(
@@ -25,8 +27,8 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(cv1$Cramers_v, cv2$Cramers_v)
 
     # Upper bound of phi is the ratio between phi / V and sqrt(min(K,L)-1)
-    expect_equal(phi(xtab, alternative = ""greater"")$CI_high, sqrt(2))
-    expect_equal(phi(xtab)[[1]] / cramers_v(xtab)[[1]], sqrt(2))
+    expect_equal(cohens_w(xtab, alternative = ""greater"")$CI_high, sqrt(2))
+    expect_equal(cohens_w(xtab)[[1]] / cramers_v(xtab)[[1]], sqrt(2))
 
     ## 2*2 tables return phi and cramers_v
     xtab <- rbind(
@@ -79,24 +81,30 @@ if (require(""testthat"") && require(""effectsize"")) {
   test_that(""goodness of fit"", {
     expect_error(cramers_v(table(mtcars$cyl)))
 
-    phi1 <- phi(table(mtcars$cyl), p = c(0.34375, 0.21875, 0.43750))
-    phi2 <- phi(table(mtcars$cyl), p = c(0.8, 0.1, 0.1))
+    w1 <- cohens_w(table(mtcars$cyl), p = c(0.34375, 0.21875, 0.43750))
+    w2 <- cohens_w(table(mtcars$cyl), p = c(0.8, 0.1, 0.1))
+
+    nchi1 <- normalized_chi(table(mtcars$cyl), p = c(0.34375, 0.21875, 0.43750))
+    nchi2 <- normalized_chi(table(mtcars$cyl), p = c(0.8, 0.1, 0.1))
 
-    expect_equal(phi1$phi, 0)
-    expect_true(phi1$phi < phi2$phi)
-    expect_true(phi1$CI_low < phi2$CI_low)
-    expect_true(phi2$CI_low < phi2$CI_high)
-    expect_equal(phi2$CI_high, Inf)
+    expect_equal(w1[[1]], 0)
+    expect_true(w1[[1]] < w2[[1]])
+    expect_true(nchi1[[1]] < nchi2[[1]])
+    expect_true(nchi2[[1]] < w2[[1]])
+    expect_equal(w2[[1]] * sqrt(0.1/0.9), nchi2[[1]])
+    expect_true(w1$CI_low < w2$CI_low)
+    expect_true(w2$CI_low < w2$CI_high)
+    expect_equal(w2$CI_high, Inf)
 
     C <- pearsons_c(table(mtcars$cyl), p = c(0.8, 0.1, 0.1))
     expect_equal(C[[1]], sqrt(49.289 / (49.289 + sum(table(mtcars$cyl)))), tolerance = 0.001)
     expect_equal(C$CI_high, 1)
 
     # some weird exeptions...
     df <- subset(mtcars, am == ""0"")
-    expect_equal(phi(table(df$am, df$cyl))[[1]], 0.64, tolerance = 0.01)
-    expect_equal(phi(table(df$am, df$cyl)), phi(table(df$cyl)))
-    expect_equal(phi(table(df$am, df$cyl)), phi(table(df$cyl, df$am)))
+    expect_equal(cohens_w(table(df$am, df$cyl))[[1]], 0.64, tolerance = 0.01)
+    expect_equal(cohens_w(table(df$am, df$cyl)), cohens_w(table(df$cyl)))
+    expect_equal(cohens_w(table(df$am, df$cyl)), cohens_w(table(df$cyl, df$am)))
   })
 
   test_that(""oddsratio & riskratio"", {

---FILE: vignettes/anovaES.Rmd---
@@ -31,7 +31,7 @@ if (!all(sapply(pkgs, require, quietly = TRUE, character.only = TRUE))) {
 
 ## Eta<sup>2</sup>
 
-In the context of ANOVA-like tests, it is common to report ANOVA-like effect sizes. Unlike [standardized parameters](https://easystats.github.io/effectsize/articles/standardize_parameters.html), these effect sizes represent the amount of variance explained by each of the model's terms, where each term can be represented by 1 *or more* parameters.
+In the context of ANOVA-like tests, it is common to report ANOVA-like effect sizes. These effect sizes represent the amount of variance explained by each of the model's terms, where each term can be represented by 1 *or more* parameters.
 
 For example, in the following case, the parameters for the `treatment` term represent specific contrasts between the factor's levels (treatment groups) - the difference between each level and the reference level (`obk.long == 'control'`).
 
@@ -254,5 +254,67 @@ omega_squared(fit_lmm)
 
 Another case where *SS*s are not available is when use Bayesian models. `effectsize` has Bayesian solutions for Bayesian models, about which you can read in the [*Effect Sizes for Bayesian Models* vignette](https://easystats.github.io/effectsize/articles/bayesian_models.html).
 
+## For Bayesian Models
+
+An alternative route to obtaining effect sizes of explained variance, is via the
+use of the ***posterior predictive distribution*** (*PPD*). The PPD is the
+Bayesian expected distribution of possible unobserved values. Thus, after
+observing some data, we can estimate not just the expected mean values (the
+conditional marginal means), but also the full *distribution* of data around
+these values [@gelman2014bayesian, chapter 7].
+
+By sampling from the PPD, we can decompose the sample to the various *SS*s
+needed for the computation of explained variance measures. By repeatedly
+sampling from the PPD, we can generate a posterior distribution of explained
+variance estimates. But note that **these estimates are conditioned not only on
+the location-parameters of the model, but also on the scale-parameters of the
+model!** So it is vital to [validate the
+PPD](https://mc-stan.org/docs/2_23/stan-users-guide/meta-models-part.html#meta-models.part/)
+before using it to estimate explained variance measures.
+
+```{r, echo = FALSE, eval=TRUE}
+if (eval_bayes <- knitr::opts_chunk$get(""eval"")) {
+  bayes_pkgs <- c(""rstanarm"", ""bayestestR"", ""car"")
+  eval_bayes <- all(sapply(bayes_pkgs, require, quietly = TRUE, character.only = TRUE))  
+}
+```
+
+Let's fit our model:
+
+```{r, eval = eval_bayes}
+library(rstanarm)
+
+m_bayes <- stan_glm(value ~ gender + phase + treatment, 
+                    data = obk.long, family = gaussian(),
+                    refresh = 0)
+```
+
+We can use `eta_squared_posterior()` to get the posterior distribution of
+$eta^2$ or $eta^2_p$ for each effect. Like an ANOVA table, we must make sure to
+use the right effects-coding and *SS*-type:
+
+```{r, eval = eval_bayes}
+pes_posterior <- eta_squared_posterior(m_bayes,
+  draws = 500, # how many samples from the PPD?
+  partial = TRUE, # partial eta squared
+  # type 3 SS
+  ss_function = car::Anova, type = 3, 
+  verbose = FALSE
+)
+
+head(pes_posterior)
+
+bayestestR::describe_posterior(pes_posterior, 
+  rope_range = c(0, 0.1), test = ""rope""
+)
+```
+
+Compare to:
+
+```{r, eval = eval_bayes}
+m_ML <- lm(value ~ gender + phase + treatment, data = obk.long)
+
+eta_squared(car::Anova(m_ML, type = 3))
+```
 
 # References

---FILE: vignettes/bayesian_models.Rmd---
@@ -1,197 +0,0 @@
----
-title: ""Effect Sizes for Bayesian Models""
-output: 
-  rmarkdown::html_vignette:
-    toc: true
-    fig_width: 10.08
-    fig_height: 6
-tags: [r, bayesian, effect size]
-vignette: >
-  \usepackage[utf8]{inputenc}
-  %\VignetteIndexEntry{Effect Sizes for Bayesian Models}
-  %\VignetteEngine{knitr::rmarkdown}
-editor_options: 
-  chunk_output_type: console
-bibliography: bibliography.bib
----
-
-```{r message=FALSE, warning=FALSE, include=FALSE}
-library(knitr)
-options(knitr.kable.NA = """")
-options(digits = 2)
-knitr::opts_chunk$set(comment = "">"")
-
-set.seed(1)
-pkgs <- c(""effectsize"", ""parameters"", ""rstanarm"", ""bayestestR"", ""car"")
-if (!all(sapply(pkgs, require, quietly = TRUE, character.only = TRUE))) {
-  knitr::opts_chunk$set(eval = FALSE)
-}
-```
-
-## Standardized Parameters
-
-### Introduction
-
-Like in OLS / ML or other frequentists methods of model parameter estimation,
-standardizing the parameters of Bayesian (generalized) linear regression models
-can allow for the comparison of so-called ""effects"" within and between models,
-variables and studies.
-
-As with frequentists methods, standardizing parameters should not be the only
-method of examining the role different predictors play in a particular Bayesian
-model, and this vignette generally assumes that the issues of model convergence,
-goodness of fit and model selection have already been taken care of. (Learn more
-about how to become a Bayesian master with [the `bayestestR`
-package](https://easystats.github.io/bayestestR/).)
-
-### Setup
-
-We will examine the predictive role of overtime (`xtra_hours`), number of
-compliments given to the boss (`n_comps`) and seniority in predicting workers
-salaries. Let's fit the model:
-
-```{r, warning=FALSE}
-library(rstanarm)
-
-data(""hardlyworking"", package = ""effectsize"")
-
-head(hardlyworking)
-
-
-mod <- stan_glm(salary ~ xtra_hours + n_comps + seniority,
-  data = hardlyworking,
-  prior = normal(0, scale = c(1, 0.5, 0.5), autoscale = TRUE), # set some priors
-  refresh = 0
-)
-
-parameters::model_parameters(mod, test = NULL)
-```
-
-Looking at the un-standardized (""raw"") parameters, it looks like all predictors
-positively predict workers' salaries, but which has the highest predictive
-power? Unfortunately, the predictors are not on the same scale (hours,
-compliments, years), so comparing them is hard when looking at the raw data.
-This is where standardization comes in.
-
-Like with [frequentists
-models](https://easystats.github.io/effectsize/articles/standardize_parameters.html)
-we can choose from the same standardization methods. Let's use the (slow)
-`""refit""` method.
-
-```{r}
-library(effectsize)
-
-standardize_parameters(mod, method = ""refit"", ci = 0.89)
-```
-
-Note that the central tendency of the posterior distribution is still the
-*median* - the median of the standardized posterior distribution. We can easily
-change this, of the type of credible interval used:
-
-```{r}
-library(effectsize)
-
-standardize_parameters(mod,
-  method = ""basic"", ci = 0.89,
-  centrality = ""MAP"", ci_method = ""eti""
-)
-```
-
-As we can see, working harder (or at least for longer hours) has stronger
-predictive power than complementing or seniority. (Do note, however, that this
-does not mean that if you wish to have a higher salary you should work overtime
-- the raw parameters seem to suggest that complementing your boss is the way to
-go, with one compliment worth almost 3.5 times **more** than a full hours'
-work!)
-
-## Eta<sup>2</sup>
-
-### Introduction
-
-In classical frequentists models, the computation of $\eta^2$ or $\eta^2_p$ is
-straightforward: based on the right combinations of sums-of-squares (*SS*s), we
-get the correct proportion of variance accounted for by some predictor term.
-However such a computation is not as straightforward for Bayesian models, for
-various reasons (e.g., the model-*SS* and the residual-*SS* don't necessarily
-sum to the total-*SS*). Although some have proposed Bayesian methods of
-estimating explained variance in ANOVA designs [@marsman2019bayesian], these are
-not yet easy to implement with `stan`-based models.
-
-An alternative route to obtaining effect sizes of explained variance, is via the
-use of the ***posterior predictive distribution*** (*PPD*). The PPD is the
-Bayesian expected distribution of possible unobserved values. Thus, after
-observing some data, we can estimate not just the expected mean values (the
-conditional marginal means), but also the full *distribution* of data around
-these values [@gelman2014bayesian, chapter 7].
-
-By sampling from the PPD, we can decompose the sample to the various *SS*s
-needed for the computation of explained variance measures. By repeatedly
-sampling from the PPD, we can generate a posterior distribution of explained
-variance estimates. But note that **these estimates are conditioned not only on
-the location-parameters of the model, but also on the scale-parameters of the
-model!** So it is vital to [validate the
-PPD](https://mc-stan.org/docs/2_23/stan-users-guide/meta-models-part.html#meta-models.part/)
-before using it to estimate explained variance measures.
-
-### Setup
-
-Let's factorize our data from above:
-
-```{r}
-hardlyworking$age_f <- cut(hardlyworking$age,
-  breaks = c(25, 35, 45), right = FALSE,
-  labels = c(""Young"", ""Less_young"")
-)
-hardlyworking$comps_f <- cut(hardlyworking$n_comps,
-  breaks = c(0, 1, 2, 3),
-  include.lowest = TRUE,
-  right = FALSE
-)
-
-table(hardlyworking$age_f, hardlyworking$comps_f)
-```
-
-And fit our model:
-
-```{r}
-# use (special) effects coding
-contrasts(hardlyworking$age_f) <- bayestestR::contr.orthonorm
-contrasts(hardlyworking$comps_f) <- bayestestR::contr.orthonorm
-
-modAOV <- stan_glm(salary ~ age_f * comps_f,
-  data = hardlyworking, family = gaussian(),
-  refresh = 0
-)
-```
-
-We can use `eta_squared_posterior()` to get the posterior distribution of
-$eta^2$ or $eta^2_p$ for each effect. Like an ANOVA table, we must make sure to
-use the right effects-coding and *SS*-type:
-
-```{r}
-pes_posterior <- eta_squared_posterior(modAOV,
-  draws = 500, # how many samples from the PPD?
-  partial = TRUE, # partial eta squared
-  # type 3 SS
-  ss_function = car::Anova, type = 3, 
-  verbose = FALSE
-)
-
-head(pes_posterior)
-
-bayestestR::describe_posterior(pes_posterior, 
-  rope_range = c(0, 0.1), test = ""rope""
-)
-```
-
-Compare to:
-
-```{r}
-modAOV_f <- lm(salary ~ age_f * comps_f,
-  data = hardlyworking
-)
-
-eta_squared(car::Anova(modAOV_f, type = 3))
-```
-
-# References

---FILE: vignettes/effectsize.Rmd---
@@ -8,7 +8,7 @@ output:
 tags: [r, effect size, rules of thumb, guidelines, conversion]
 vignette: >
   \usepackage[utf8]{inputenc}
-  %\VignetteIndexEntry{effectsize}
+  %\VignetteIndexEntry{Effect Sizes: Getting Started}
   %\VignetteEngine{knitr::rmarkdown}
 editor_options: 
   chunk_output_type: console

---FILE: vignettes/interpret.Rmd---
@@ -234,9 +234,7 @@ However, they are also the parameters of ***logistic*** regressions, where they
 can be used as indices of effect size. Note that the (log) odds ratio from
 logistic regression coefficients are *unstandardized*, as they depend on the
 scale of the predictor. In order to apply the following guidelines, make sure
-you
-[*standardize*](https://easystats.github.io/effectsize/articles/standardize_parameters.html)
-your predictors!
+you *standardize* your predictors!
 
 Keep in mind that these apply to Odds *ratios*, so Odds ratio of 10 is as
 extreme as a Odds ratio of 0.1 (1/10).

---FILE: vignettes/simple_htests.Rmd---
@@ -134,72 +134,36 @@ onew <- oneway.test(mpg ~ gear, data = mtcars, var.equal = TRUE)
 eta_squared(onew)
 ```
 
-## Contingency Tables and Proportions
+## Contingency Tables
 
-For contingency tables CramÃ©r's *V*, $\phi$ (Phi, also known as Cohen's *w*) and Pearson's contingency coefficient indicate the strength of association with 0 indicating no association between the variables.
-While CramÃ©r's *V* and Pearson's *C* are capped at 1 (perfect association), $\phi$ can be larger than 1.
+### 2-by-2 Tables
 
-```{r}
-(Music <- matrix(
-  c(
-    150, 130, 35, 55,
-    100, 50, 10, 40,
-    165, 65, 2, 25
-  ),
-  byrow = TRUE, nrow = 3,
-  dimnames = list(
-    Study = c(""Psych"", ""Econ"", ""Law""),
-    Music = c(""Pop"", ""Rock"", ""Jazz"", ""Classic"")
-  )
-))
-
-chisq.test(Music)
-
-cramers_v(Music)
-
-phi(Music)
-
-pearsons_c(Music)
-```
-
-Pearson's *C* and $\phi$ are also applicable to tests of goodness-of-fit, where small values indicate no deviation from the hypothetical probabilities and large values indicate... large deviation from the hypothetical probabilities.
+For 2-by-2 contingency tables, $\phi$ (Phi) is homologous (though directionless) to the bi-serial correlation between the two dichotomous variables, with 0 representing to association, and 1 representing a perfect association. A ""cousin"" effect size is Pearson's contingency coefficient.
 
 ```{r}
-O <- c(89,  37,  130, 28,  2) # observed group sizes
-E <- c(.40, .20, .20, .15, .05) # expected group freq
-
-chisq.test(O, p = E, rescale.p = TRUE)
+MPG_Gear <- table(mtcars$mpg < 20, mtcars$vs)
 
-pearsons_c(O, p = E, rescale.p = TRUE)
+phi(MPG_Gear)
 
-phi(O, p = E, rescale.p = TRUE)
-```
-
-These can also be extracted from the equivalent Bayesian test:
+# Same as:
+cor(mtcars$mpg < 20, mtcars$vs)
 
-```{r}
-(BFX <- contingencyTableBF(Music, sampleType = ""jointMulti""))
-
-effectsize(BFX, type = ""cramers_v"", test = NULL)
 
-effectsize(BFX, type = ""phi"", test = NULL)
 
-effectsize(BFX, type = ""pearsons_c"", test = NULL)
+pearsons_c(MPG_Gear)
 ```
 
-### Comparing Two Proportions (2x2 tables)
+(Cramer's *V* or Cohen's *w* can also be used, but for 2-by-2 tables, they are equivalent to $\phi$.)
 
-For $2\times 2$ tables, in addition to CramÃ©r's *V*, $\phi$ and Pearson's *C*, we can also
-compute the Odds-ratio (OR), where each column represents a different group.
+In addition to $\phi$ and Pearson's *C*, we can also
+compute the Odds-ratio (OR), where each column represents a different *group*.
 Values larger than 1 indicate that the odds are higher in the first group (and
 vice versa).
 
 ```{r}
 (RCT <- matrix(
-  c(
-    71, 30,
-    50, 100
-  ),
+  c(71, 30,
+    50, 100),
   nrow = 2, byrow = TRUE,
   dimnames = list(
     Diagnosis = c(""Sick"", ""Recovered""),
@@ -227,17 +191,78 @@ transformation. Negative values indicate smaller proportion in the first group
 cohens_h(RCT)
 ```
 
+### Larger Tables
+
+For larger contingency tables CramÃ©r's *V*, Cohen's *w* and Pearson's *C* can be used.
+While CramÃ©r's *V* and Pearson's *C* are capped at 1 (perfect association), Cohen's *w* can be larger than 1
+(for all three, 0 indicates no association between the variables).
+
+```{r}
+(Music <- matrix(
+  c(150, 130, 35, 55,
+    100, 50, 10, 40,
+    165, 65, 2, 25),
+  byrow = TRUE, nrow = 3,
+  dimnames = list(
+    Study = c(""Psych"", ""Econ"", ""Law""),
+    Music = c(""Pop"", ""Rock"", ""Jazz"", ""Classic"")
+  )
+))
+
+chisq.test(Music)
+
+cramers_v(Music)
+
+cohens_w(Music)
+
+pearsons_c(Music)
+```
+
+These can also be extracted from the equivalent Bayesian test:
+
+```{r}
+(BFX <- contingencyTableBF(Music, sampleType = ""jointMulti""))
+
+effectsize(BFX, type = ""cramers_v"", test = NULL)
+
+effectsize(BFX, type = ""cohens_w"", test = NULL)
+
+effectsize(BFX, type = ""pearsons_c"", test = NULL)
+```
+
+### Goodness-of-Fit
+
+Cohen's *w* and Pearson's *C* are also applicable to tests of goodness-of-fit, 
+where small values indicate no deviation from the hypothetical probabilities and large values indicate... large deviation from the hypothetical probabilities.
+
+```{r}
+O <- c(89,  37,  130, 28,  2) # observed group sizes
+E <- c(.40, .20, .20, .15, .05) # expected group freq
+
+chisq.test(O, p = E)
+
+pearsons_c(O, p = E)
+
+cohens_w(O, p = E)
+```
+
+However, Cohen's *w* does not account for the distribution of expected probabilities, 
+and as such may be seen is an inflated effect size, and since it can be larger than 1 it is also harder to interpret. 
+For these reasons, we recommend the Normalized $\chi$ (Chi), which adjusted Cohen's *w* to account for the expected distribution of probabilities, making it range between 0 (observed distribution matches the expected distribution perfectly) and 1 (the observed distribution is maximally different than the expected one).
+
+```{r}
+normalized_chi(O, p = E)
+```
+
 ### Paired Contingency Tables
 
 For dependent (paired) contingency tables, Cohen's *g* represents the symmetry
 of the table, ranging between 0 (perfect symmetry) and 0.5 (perfect asymmetry).
 
 ```{r}
 (Performance <- matrix(
-  c(
-    794, 86,
-    150, 570
-  ),
+  c(794, 86,
+    150, 570),
   nrow = 2, byrow = TRUE,
   dimnames = list(
     ""1st Survey"" = c(""Approve"", ""Disapprove""),",True,True,Documentation / Formatting,7
easystats,effectsize,1a3e4ded6ca8b48a51bc2654566a8ca3a3352e2e,Mattan S. Ben-Shachar,35330040+mattansb@users.noreply.github.com,2022-05-03T05:38:30Z,GitHub,noreply@github.com,2022-05-03T05:38:30Z,"Remove std.models/default (#440)

* Remove std.models/default

https://github.com/easystats/datawizard/pull/158

* remove std_params

* fix docs",DESCRIPTION;NAMESPACE;NEWS.md;R/effectsize.R;R/format_standardize.R;R/reexports.R;R/standardize.models.R;R/standardize_info.R;R/standardize_parameters.R;R/utils.R;R/utils_standardize.R;README.Rmd;_pkgdown.yml;man/cles.Rd;man/cohens_d.Rd;man/effectsize.Rd;man/eta_squared.Rd;man/phi.Rd;man/rank_biserial.Rd;man/reexports.Rd;man/standardize.default.Rd;man/standardize_info.Rd;man/standardize_parameters.Rd;tests/testthat/test-standardize_models.R;tests/testthat/test-standardize_parameters.R;vignettes/effectsize.Rmd;vignettes/effectsize_API.Rmd;vignettes/standardize_parameters.Rmd,True,True,True,False,105,3511,3616,"---FILE: DESCRIPTION---
@@ -58,9 +58,9 @@ Depends:
 Imports:
     bayestestR (>= 0.11.5.1),
     insight (>= 0.16.0.16),
-    parameters (>= 0.17.0.3),
+    parameters (>= 0.17.0.10),
     performance (>= 0.8.0.8),
-    datawizard (>= 0.3.0.9006),
+    datawizard (>= 0.4.0.17),
     stats,
     utils
 Suggests:

---FILE: NAMESPACE---
@@ -41,23 +41,6 @@ S3method(probs_to_odds,data.frame)
 S3method(probs_to_odds,numeric)
 S3method(rb_to_cles,effectsize_difference)
 S3method(rb_to_cles,numeric)
-S3method(standardize,Surv)
-S3method(standardize,bcplm)
-S3method(standardize,biglm)
-S3method(standardize,brmsfit)
-S3method(standardize,clm2)
-S3method(standardize,default)
-S3method(standardize,mediate)
-S3method(standardize,mixor)
-S3method(standardize,wbgee)
-S3method(standardize,wbm)
-S3method(standardize_info,default)
-S3method(standardize_parameters,bootstrap_model)
-S3method(standardize_parameters,bootstrap_parameters)
-S3method(standardize_parameters,default)
-S3method(standardize_parameters,mediate)
-S3method(standardize_parameters,model_fit)
-S3method(standardize_parameters,parameters_model)
 export(.es_aov_simple)
 export(.es_aov_strata)
 export(.es_aov_table)
@@ -184,9 +167,6 @@ export(riskratio_to_oddsratio)
 export(rules)
 export(sd_pooled)
 export(standardise)
-export(standardise_info)
-export(standardise_parameters)
-export(standardise_posteriors)
 export(standardize)
 export(standardize_info)
 export(standardize_parameters)
@@ -203,32 +183,24 @@ export(z_to_d)
 export(z_to_r)
 importFrom(bayestestR,describe_posterior)
 importFrom(bayestestR,equivalence_test)
-importFrom(datawizard,demean)
 importFrom(datawizard,standardise)
 importFrom(datawizard,standardize)
 importFrom(insight,check_if_installed)
-importFrom(insight,clean_names)
 importFrom(insight,display)
 importFrom(insight,find_formula)
 importFrom(insight,find_predictors)
-importFrom(insight,find_random)
 importFrom(insight,find_response)
-importFrom(insight,find_terms)
-importFrom(insight,find_weights)
 importFrom(insight,format_value)
 importFrom(insight,get_data)
 importFrom(insight,get_parameters)
 importFrom(insight,get_predictors)
-importFrom(insight,get_random)
-importFrom(insight,get_response)
-importFrom(insight,get_variance)
-importFrom(insight,get_weights)
 importFrom(insight,model_info)
 importFrom(insight,print_html)
 importFrom(insight,print_md)
 importFrom(parameters,model_parameters)
-importFrom(parameters,parameters_type)
-importFrom(performance,check_heterogeneity_bias)
+importFrom(parameters,standardize_info)
+importFrom(parameters,standardize_parameters)
+importFrom(parameters,standardize_posteriors)
 importFrom(stats,anova)
 importFrom(stats,aov)
 importFrom(stats,as.formula)
@@ -256,10 +228,7 @@ importFrom(stats,qt)
 importFrom(stats,reshape)
 importFrom(stats,sd)
 importFrom(stats,setNames)
-importFrom(stats,update)
 importFrom(stats,var)
 importFrom(utils,as.roman)
-importFrom(utils,capture.output)
-importFrom(utils,head)
 importFrom(utils,packageVersion)
 importFrom(utils,tail)

---FILE: NEWS.md---
@@ -1,5 +1,10 @@
 # effectsize 0.6.0.3
 
+## Breaking Changes
+
+- `standardize_parameters()`, `standardize_posteriors()`, & `standardize_info()` have been moved to the `parameters` package.  
+- `standardize()` (for models) has been moved to the `datawizard` package.
+
 ## Bug fixes
 
 - `kendalls_w()` now deals with ties.  

---FILE: R/effectsize.R---
@@ -6,7 +6,7 @@
 #' @param model An object of class `htest`, or a statistical model. See details.
 #' @param type The effect size of interest. See details.
 #' @param ... Arguments passed to or from other methods. See details.
-#' @inheritParams standardize.default
+#' @inheritParams datawizard::standardize.default
 #'
 #' @details
 #'
@@ -25,7 +25,7 @@
 #'   - A **contingency table test**, depending on `type`: `""cramers_v""` (default), `""phi""`, `""cohens_w""`, `""pearsons_c""`, `""cohens_h""`, `""oddsratio""`, or `""riskratio""`.
 #'   - A **proportion test** returns *p*.
 #' - Objects of class `anova`, `aov`, or `aovlist`, depending on `type`: `""eta""` (default), `""omega""` or `""epsilon""` -squared, `""f""`, or `""f2""`.
-#' - Other objects are passed to [standardize_parameters()].
+#' - Other objects are passed to [parameters::standardize_parameters()].
 #'
 #' **For statistical models it is recommended to directly use the listed
 #' functions, for the full range of options they provide.**
@@ -149,5 +149,5 @@ effectsize.easycorrelation <- function(model, ...) {
 #' @export
 effectsize.default <- function(model, ...) {
   # message(""Using standardize_parameters()."")
-  standardize_parameters(model, ...)
+  parameters::standardize_parameters(model, ...)
 }

---FILE: R/format_standardize.R---
@@ -4,7 +4,7 @@
 #'
 #' @param x A standardized numeric vector.
 #' @param reference The reference vector from which to compute the mean and SD.
-#' @inheritParams standardize.default
+#' @inheritParams datawizard::standardize.default
 #' @inheritParams insight::format_value
 #' @param ... Other arguments to pass to \code{\link[insight:format_value]{insight::format_value()}} such as \code{digits}, etc.
 #'

---FILE: R/reexports.R---
@@ -10,6 +10,20 @@ datawizard::standardize
 #' @importFrom datawizard standardise
 datawizard::standardise
 
+#' @export
+#' @importFrom parameters standardize_parameters
+parameters::standardize_parameters
+
+#' @export
+#' @importFrom parameters standardize_posteriors
+parameters::standardize_posteriors
+
+
+#' @export
+#' @importFrom parameters standardize_info
+parameters::standardize_info
+
+
 
 # Printing ----------------------------------------------------------------
 

---FILE: R/standardize.models.R---
@@ -1,510 +0,0 @@
-#' Re-fit a model with standardized data
-#'
-#' Performs a standardization of data (z-scoring) using
-#' [`datawizard::standardize()`] and then re-fits the model to the standardized
-#' data.
-#' \cr\cr
-#' Standardization is done by completely refitting the model on the standardized
-#' data. Hence, this approach is equal to standardizing the variables *before*
-#' fitting the model and will return a new model object. This method is
-#' particularly recommended for complex models that include interactions or
-#' transformations (e.g., polynomial or spline terms). The `robust` (default to
-#' `FALSE`) argument enables a robust standardization of data, based on the
-#' `median` and the `MAD` instead of the `mean` and the `SD`.
-#'
-#' @param x A statistical model.
-#' @param weights If `TRUE` (default), a weighted-standardization is carried out.
-#' @param include_response If `TRUE` (default), the response value will also be
-#'   standardized. If `FALSE`, only the predictors will be standardized.
-#'   - Note that for GLMs and models with non-linear link functions, the
-#'   response value will not be standardized, to make re-fitting the model work.
-#'   - If the model contains an [stats::offset()], the offset variable(s) will
-#'   be standardized only if the response is standardized. If `two_sd = TRUE`,
-#'   offsets are standardized by one-sd (similar to the response).
-#'   - (For `mediate` models, the `include_response` refers to the outcome in
-#'   the y model; m model's response will always be standardized when possible).
-#' @inheritParams datawizard::standardize
-#'
-#' @return A statistical model fitted on standardized data
-#'
-#' @details
-#'
-#' # Generalized Linear Models
-#' Standardization for generalized linear models (GLM, GLMM, etc) is done only
-#' with respect to the predictors (while the outcome remains as-is,
-#' unstandardized) - maintaining the interpretability of the coefficients (e.g.,
-#' in a binomial model: the exponent of the standardized parameter is the OR of
-#' a change of 1 SD in the predictor, etc.)
-#'
-#' # Dealing with Factors
-#' `standardize(model)` or `standardize_parameters(model, method = ""refit"")` do
-#' *not* standardize categorical predictors (i.e. factors) / their
-#' dummy-variables, which may be a different behaviour compared to other R
-#' packages (such as \pkg{lm.beta}) or other software packages (like SPSS). To
-#' mimic such behaviours, either use `standardize_parameters(model, method =
-#' ""basic"")` to obtain post-hoc standardized parameters, or standardize the data
-#' with `datawizard::standardize(data, force = TRUE)` *before* fitting the
-#' model.
-#'
-#' # Transformed Variables
-#' When the model's formula contains transformations (e.g. `y ~ exp(X)`) the
-#' transformation effectively takes place after standardization (e.g.,
-#' `exp(scale(X))`). Since some transformations are undefined for none positive
-#' values, such as `log()` and `sqrt()`, the releven variables are shifted (post
-#' standardization) by `Z - min(Z) + 1` or `Z - min(Z)` (respectively).
-#'
-#'
-#' @family standardize
-#' @examples
-#' model <- lm(Infant.Mortality ~ Education * Fertility, data = swiss)
-#' coef(standardize(model))
-#'
-#' @export
-#' @aliases standardize_models
-#' @aliases standardize.models
-#' @aliases standardise.models
-#' @aliases standardise.default
-standardize.default <- function(x,
-                                robust = FALSE,
-                                two_sd = FALSE,
-                                weights = TRUE,
-                                verbose = TRUE,
-                                include_response = TRUE,
-                                ...) {
-  data_std <- NULL # needed to avoid note
-  .standardize_models(x,
-                     robust = robust, two_sd = two_sd,
-                     weights = weights,
-                     verbose = verbose,
-                     include_response = include_response,
-                     update_expr = stats::update(x, data = data_std),
-                     ...)
-}
-
-
-#' @importFrom stats update
-#' @importFrom insight get_data find_response get_response find_weights get_weights
-#' @importFrom datawizard standardize
-#' @importFrom utils capture.output
-.standardize_models <- function(x,
-                                robust = FALSE,
-                                two_sd = FALSE,
-                                weights = TRUE,
-                                verbose = TRUE,
-                                include_response = TRUE,
-                                update_expr,
-                                ...) {
-  m_info <- .get_model_info(x, ...)
-  data <- insight::get_data(x)
-
-  if (isTRUE(attr(data, ""is_subset""))) {
-    stop(""Cannot standardize a model fit with a 'subset = '."", call. = FALSE)
-  }
-
-  if (m_info$is_bayesian) {
-    warning(insight::format_message(""Standardizing variables without adjusting priors may lead to bogus results unless priors are auto-scaled.""),
-            call. = FALSE, immediate. = TRUE
-    )
-  }
-
-
-
-  ## ---- Z the RESPONSE? ----
-  # Some models have special responses that should not be standardized. This
-  # includes:
-  # - generalized linear models (counts, binomial, etc...)
-  # - Survival models
-
-  include_response <- include_response && .safe_to_standardize_response(m_info)
-
-  resp <- NULL
-  if (!include_response) {
-    resp <- unique(c(insight::find_response(x), insight::find_response(x, combine = FALSE)))
-  } else if (include_response && two_sd) {
-    resp <- unique(c(insight::find_response(x), insight::find_response(x, combine = FALSE)))
-  }
-
-  # If there's an offset, don't standardize offset OR response
-  offsets <- insight::find_offset(x)
-  if (length(offsets)) {
-    if (include_response) {
-      if (verbose) {
-        warning(""Offset detected and will be standardized."", call. = FALSE)
-      }
-
-      if (two_sd) {
-        # Treat offsets like responses - only standardize by 1 SD
-        resp <- c(resp, offsets)
-        offsets <- NULL
-      }
-    } else if (!include_response) {
-      # Don't standardize offsets if not standardizing the response
-      offsets <- NULL
-    }
-  }
-
-
-
-  ## ---- DO NOT Z: ----
-
-  # 1. WEIGHTS:
-  # because negative weights will cause errors in ""update()""
-  weight_variable <- insight::find_weights(x)
-
-  if (!is.null(weight_variable) && !weight_variable %in% colnames(data) && ""(weights)"" %in% colnames(data)) {
-    data$.missing_weight <- data[[""(weights)""]]
-    colnames(data)[ncol(data)] <- weight_variable
-    weight_variable <- c(weight_variable, ""(weights)"")
-  }
-
-  # 2. RANDOM-GROUPS:
-  random_group_factor <- insight::find_random(x, flatten = TRUE, split_nested = TRUE)
-
-
-
-
-  ## ---- SUMMARY: TO Z OR NOT TO Z? ----
-  dont_standardize <- c(resp, weight_variable, random_group_factor)
-  do_standardize <- setdiff(colnames(data), dont_standardize)
-
-  # can't std data$var variables
-  if (any(doller_vars <- grepl(""(.*)\\$(.*)"", do_standardize))) {
-    doller_vars <- colnames(data)[doller_vars]
-    warning(insight::format_message(
-      ""Unable to standardize variables evaluated in the environment (i.e., not in `data`)."",
-      ""The following variables will not be standardizd:"",
-      paste0(doller_vars, collapse = "", "")),
-      call. = FALSE
-    )
-    do_standardize <- setdiff(do_standardize, doller_vars)
-    dont_standardize <- c(dont_standardize, doller_vars)
-  }
-
-
-  if (!length(do_standardize)) {
-    warning(""No variables could be standardized."", call. = FALSE)
-    return(x)
-  }
-
-
-
-
-  ## ---- STANDARDIZE! ----
-  w <- insight::get_weights(x, na_rm = TRUE)
-
-  data_std <- datawizard::standardize(data[do_standardize],
-                                      robust = robust,
-                                      two_sd = two_sd,
-                                      weights = if (weights) w,
-                                      verbose = verbose)
-
-  # if two_sd, it must not affect the response!
-  if (include_response && two_sd) {
-    data_std[resp] <- datawizard::standardize(data[resp],
-                                              robust = robust,
-                                              two_sd = FALSE,
-                                              weights = if (weights) w,
-                                              verbose = verbose)
-
-    dont_standardize <- setdiff(dont_standardize, resp)
-  }
-
-  # FIX LOG-SQRT VARS:
-  # if we standardize log-terms, standardization will fail (because log of
-  # negative value is NaN). Do some back-transformation here
-
-  log_terms <- .log_terms(x, data_std)
-  if (length(log_terms) > 0) {
-    data_std[log_terms] <- lapply(data_std[log_terms],
-                                  function(i) i - min(i, na.rm = TRUE) + 1)
-  }
-
-  # same for sqrt
-  sqrt_terms <- .sqrt_terms(x, data_std)
-  if (length(sqrt_terms) > 0) {
-    data_std[sqrt_terms] <- lapply(data_std[sqrt_terms],
-                                   function(i) i - min(i, na.rm = TRUE))
-  }
-
-  if (verbose && length(c(log_terms, sqrt_terms))) {
-    message(insight::format_message(""Formula contains log- or sqrt-terms. See help(\""standardize\"") for how such terms are standardized.""))
-  }
-
-
-
-
-
-  ## ---- ADD BACK VARS THAT WHERE NOT Z ----
-  if (length(dont_standardize)) {
-    remaining_columns <- intersect(colnames(data), dont_standardize)
-    data_std <- cbind(data[, remaining_columns, drop = FALSE], data_std)
-  }
-
-
-
-
-
-  ## ---- UPDATE MODEL WITH Z DATA ----
-  on.exit(.update_failed())
-
-  if (isTRUE(verbose)) {
-     model_std <- eval(substitute(update_expr))
-  } else {
-    utils::capture.output(model_std <- eval(substitute(update_expr)))
-  }
-
-  on.exit() # undo previous on.exit()
-
-  model_std
-}
-
-
-# Special methods ---------------------------------------------------------
-
-
-#' @importFrom stats update
-#' @export
-standardize.brmsfit <- function(x,
-                                robust = FALSE,
-                                two_sd = FALSE,
-                                weights = TRUE,
-                                verbose = TRUE,
-                                include_response = TRUE,
-                                ...) {
-  data_std <- NULL # needed to avoid note
-  if (insight::is_multivariate(x)) {
-    stop(insight::format_message(
-      ""multivariate brmsfit models not supported."",
-      ""As an alternative: you may standardize your data (and adjust your priors), and re-fit the model.""),
-      call. = FALSE
-    )
-  }
-
-  .standardize_models(x,
-                      robust = robust, two_sd = two_sd,
-                      weights = weights,
-                      verbose = verbose,
-                      include_response = include_response,
-                      update_expr = stats::update(x, newdata = data_std),
-                      ...)
-}
-
-#' @importFrom stats update
-#' @export
-standardize.mixor <- function(x,
-                              robust = FALSE,
-                              two_sd = FALSE,
-                              weights = TRUE,
-                              verbose = TRUE,
-                              include_response = TRUE,
-                              ...) {
-  data_std <- random_group_factor <- NULL # needed to avoid note
-  .standardize_models(x,
-                      robust = robust, two_sd = two_sd,
-                      weights = weights,
-                      verbose = verbose,
-                      include_response = include_response,
-                      update_expr = {
-                        data_std <- data_std[order(data_std[, random_group_factor, drop = FALSE]), ]
-                        stats::update(x, data = data_std)
-                      },
-                      ...)
-}
-
-#' @export
-#' @importFrom utils capture.output
-#' @importFrom insight get_data
-#' @importFrom stats update
-standardize.mediate <- function(x,
-                                robust = FALSE,
-                                two_sd = FALSE,
-                                weights = TRUE,
-                                verbose = TRUE,
-                                include_response = TRUE,
-                                ...) {
-
-
-  # models and data
-  y <- x$model.y
-  m <- x$model.m
-  y_data <- insight::get_data(y)
-  m_data <- insight::get_data(m)
-
-  # std models and data
-  y_std <- datawizard::standardize(y,
-    robust = robust, two_sd = two_sd,
-    weights = weights, verbose = verbose,
-    include_response = include_response, ...
-  )
-  m_std <- datawizard::standardize(m,
-    robust = robust, two_sd = two_sd,
-    weights = weights, verbose = verbose,
-    include_response = TRUE, ...
-  )
-  y_data_std <- insight::get_data(y_std)
-  m_data_std <- insight::get_data(m_std)
-
-  # fixed values
-  covs <- x$covariates
-  control.value <- x$control.value
-  treat.value <- x$treat.value
-
-
-  if (!is.null(covs)) {
-    covs <- mapply(.rescale_fixed_values, covs, names(covs),
-      SIMPLIFY = FALSE,
-      MoreArgs = list(
-        y_data = y_data, m_data = m_data,
-        y_data_std = y_data_std, m_data_std = m_data_std
-      )
-    )
-    if (verbose) message(insight::format_message(""Covariates' values have been rescaled to their standardized scales.""))
-  }
-
-  # if (is.numeric(y_data[[x$treat]]) || is.numeric(m_data[[x$treat]])) {
-  #   if (!(is.numeric(y_data[[x$treat]]) && is.numeric(m_data[[x$treat]]))) {
-  #     stop(""'treat' variable is not of same type across both y and m models."",
-  #          ""\nCannot consistently standardize."", call. = FALSE)
-  #   }
-  #
-  #   temp_vals <- .rescale_fixed_values(c(control.value, treat.value), x$treat,
-  #                                      y_data = y_data, m_data = m_data,
-  #                                      y_data_std = y_data_std, m_data_std = m_data_std)
-  #
-  #   control.value <- temp_vals[1]
-  #   treat.value <- temp_vals[2]
-  #   if (verbose) message(""control and treatment values have been rescaled to their standardized scales."")
-  # }
-
-  if (verbose && !all(c(control.value, treat.value) %in% c(0, 1))) {
-    warning(insight::format_message(
-      ""Control and treat values are not 0 and 1, and have not been re-scaled."",
-      ""Interpret results with caution.""),
-      call. = FALSE
-    )
-  }
-
-
-  text <- utils::capture.output(
-    model_std <- stats::update(x,
-      model.y = y_std, model.m = m_std,
-      # control.value = control.value, treat.value = treat.value
-      covariates = covs
-    )
-  )
-
-  model_std
-}
-
-
-# Cannot ------------------------------------------------------------------
-
-
-#' @export
-standardize.wbm <- function(x, ...) {
-  .update_failed(class(x))
-}
-
-#' @export
-standardize.Surv <- standardize.wbm
-
-#' @export
-standardize.clm2 <- standardize.wbm
-
-#' @export
-standardize.bcplm <- standardize.wbm
-
-#' @export
-standardize.wbgee <- standardize.wbm
-
-#' @export
-standardize.biglm <- standardize.wbm
-# biglm doesn't regit the model to new data - it ADDs MORE data to the model.
-
-
-
-
-
-# helper ----------------------------
-
-# Find log-terms inside model formula, and return ""clean"" term names
-#' @importFrom insight find_terms
-.log_terms <- function(model, data) {
-  x <- insight::find_terms(model, flatten = TRUE)
-  # log_pattern <- ""^log\\((.*)\\)""
-  log_pattern <- ""(log\\(log|log|log1|log10|log1p|log2)\\(([^,\\+)]*).*""
-  out <- insight::trim_ws(gsub(log_pattern, ""\\2"", x[grepl(log_pattern, x)]))
-  intersect(colnames(data), out)
-}
-
-# Find log-terms inside model formula, and return ""clean"" term names
-#' @importFrom insight find_terms
-.sqrt_terms <- function(model, data) {
-  x <- insight::find_terms(model, flatten = TRUE)
-  pattern <- ""sqrt\\(([^,\\+)]*).*""
-  out <- insight::trim_ws(gsub(pattern, ""\\1"", x[grepl(pattern, x)]))
-  intersect(colnames(data), out)
-}
-
-
-#' @keywords internal
-.safe_to_standardize_response <- function(info, verbose = TRUE) {
-  if (is.null(info)) {
-    if (verbose) {
-      warning(insight::format_message(
-        ""Unable to verify if response should not be standardized."",
-        ""Response will be standardized.""),
-        immediate. = TRUE, call. = FALSE)
-    }
-    return(TRUE)
-  }
-
-  # check if model has a response variable that should not be standardized.
-  info$is_linear &&
-    !info$family == ""inverse.gaussian"" &&
-    !info$is_survival &&
-    !info$is_censored
-
-  # # alternative would be to keep something like:
-  # !info$is_count &&
-  #   !info$is_ordinal &&
-  #   !info$is_multinomial &&
-  #   !info$is_beta &&
-  #   !info$is_censored &&
-  #   !info$is_binomial &&
-  #   !info$is_survival
-  # # And then treating response for ""Gamma()"" or ""inverse.gaussian"" similar to
-  # # log-terms...
-}
-
-#' @keywords internal
-.rescale_fixed_values <- function(val, cov_nm,
-                                  y_data, m_data, y_data_std, m_data_std) {
-  if (cov_nm %in% colnames(y_data)) {
-    temp_data <- y_data
-    temp_data_std <- y_data_std
-  } else {
-    temp_data <- m_data
-    temp_data_std <- m_data_std
-  }
-
-  datawizard::data_rescale(val,
-                           to = range(temp_data_std[[cov_nm]]),
-                           range = range(temp_data[[cov_nm]])
-  )
-}
-
-
-#' @keywords internal
-.update_failed <- function(class = NULL, ...) {
-  if (is.null(class)) {
-    msg1 <- ""Unable to refit the model with standardized data.""
-  } else {
-    msg1 <- sprintf(""Standardization of parameters not possible for models of class '%s'."", class)
-  }
-
-  stop(insight::format_message(
-    msg1,
-    ""Try instead to standardize the data (standardize(data)) and refit the model manually.""),
-    call. = FALSE)
-}
\ No newline at end of file

---FILE: R/standardize_info.R---
@@ -1,533 +0,0 @@
-#' Get Standardization Information
-#'
-#' This function extracts information, such as the deviations (SD or MAD) from
-#' parent variables, that are necessary for post-hoc standardization of
-#' parameters. This function gives a window on how standardized are obtained,
-#' i.e., by what they are divided. The ""basic"" method of standardization uses.
-#'
-#' @inheritParams standardize_parameters
-#' @param include_pseudo (For (G)LMMs) Should Pseudo-standardized information be
-#'   included?
-#' @param ... Arguments passed to or from other methods.
-#'
-#' @return A data frame with information on each parameter (see
-#'   [parameters::parameters_type]), and various standardization coefficients
-#'   for the post-hoc methods (see [standardize_parameters()]) for the predictor
-#'   and the response.
-#'
-#' @family standardize
-#'
-#' @examples
-#' model <- lm(mpg ~ ., data = mtcars)
-#' standardize_info(model)
-#' standardize_info(model, robust = TRUE)
-#' standardize_info(model, two_sd = TRUE)
-#' @importFrom parameters parameters_type
-#' @aliases standardise_info
-#' @export
-standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseudo = FALSE, ...) {
-  UseMethod(""standardize_info"")
-}
-
-#' @export
-standardise_info <- standardize_info
-
-#' @export
-standardize_info.default <- function(model, robust = FALSE, two_sd = FALSE, include_pseudo = FALSE, ...) {
-  mi <- .get_model_info(model, ...)
-
-  params <- if (inherits(model, c(""glmmTMB"", ""MixMod""))) {
-    insight::find_parameters(model, effects = ""fixed"", component = ""conditional"", flatten = TRUE, ...)
-  } else {
-    insight::find_parameters(model, effects = ""fixed"", flatten = TRUE, ...)
-  }
-  types <- parameters::parameters_type(model)
-  model_matrix <- as.data.frame(stats::model.matrix(model))
-  data <- insight::get_data(model)
-  wgts <- insight::get_weights(model, na_rm = TRUE)
-
-  # Sanity Check for ZI
-  if (mi$is_zero_inflated) {
-    warning(""Non-refit parameter standardization is ignoring the zero-inflation component."", call. = FALSE)
-    # would need to also get the binomial model matrix...
-  }
-
-  # Sanity Check for glmmTMB with dispersion
-  if (length(params) != nrow(types)) {
-    types <- types[types$Parameter %in% params, ]
-  }
-
-  out <- data.frame(
-    Parameter = params,
-    Type = types$Type,
-    Link = types$Link,
-    Secondary_Parameter = types$Secondary_Parameter,
-    stringsAsFactors = FALSE
-  )
-
-  # Type of effect size
-  out$EffectSize_Type <- ifelse(types$Type == ""interaction"", ""interaction"",
-    ifelse(types$Link == ""Association"", ""r"",
-      ifelse(types$Link == ""Difference"", ""d"", NA)
-    )
-  )
-
-
-
-
-  # Response - Basic
-  out <- merge(
-    out,
-    .std_info_response_basic(model, mi, params, robust = robust, w = wgts),
-    by = ""Parameter"", all = TRUE
-  )
-
-  # Response - Smart
-  out <- merge(
-    out,
-    .std_info_response_smart(model, mi, data, model_matrix, types, robust = robust, w = wgts),
-    by = ""Parameter"", all = TRUE
-  )
-
-  # Basic
-  out <- merge(
-    out,
-    .std_info_predictors_basic(model, model_matrix, types, robust = robust, two_sd = two_sd, w = wgts),
-    by = ""Parameter"", all = TRUE
-  )
-
-  # Smart
-  out <- merge(
-    out,
-    .std_info_predictors_smart(model,
-      data,
-      params,
-      types,
-      robust = robust,
-      two_sd = two_sd,
-      w = wgts
-    ),
-    by = ""Parameter"", all = TRUE
-  )
-
-  # Pseudo (for LMM)
-  if (include_pseudo &&
-      mi$is_mixed &&
-      length(insight::find_random(model)$random) == 1) {
-    out <- merge(
-      out,
-      .std_info_pseudo(
-        model, mi,
-        params,
-        model_matrix,
-        data,
-        types = types$Type,
-        robust = robust,
-        two_sd = two_sd
-      )
-    )
-  }
-
-  # Reorder
-  out <- out[match(params, out$Parameter), ]
-  out$Parameter <- params
-  row.names(out) <- NULL
-
-  # Remove all means for now (because it's not used)
-  out <- out[!grepl(""Mean_"", names(out))]
-
-  # Select only desired columns
-  # if(method == ""all"") method <- c(""smart"", ""basic"")
-  # if(!any(method == ""smart"")){
-  #   out <- out[!grepl(""_Smart"", names(out))]
-  # }
-  # if(!any(method == ""basic"")){
-  #   out <- out[!grepl(""_Basic"", names(out))]
-  # }
-
-  out
-}
-
-
-
-
-# Predictors - Smart ------------------------------------------------------------
-
-
-#' @keywords internal
-.std_info_predictors_smart <- function(model,
-                                       data,
-                                       params,
-                                       types,
-                                       robust = FALSE,
-                                       two_sd = FALSE,
-                                       w = NULL,
-                                       ...) {
-  # Get deviations for all parameters
-  means <- deviations <- rep(NA_real_, times = length(params))
-  for (i in seq_along(params)) {
-    var <- params[i]
-    info <- .std_info_predictor_smart(
-      data = data,
-      variable = types[types$Parameter == var, ""Variable""],
-      type = types[types$Parameter == var, ""Type""],
-      robust = robust,
-      two_sd = two_sd,
-      weights = w
-    )
-    deviations[i] <- info$sd
-    means[i] <- info$mean
-  }
-
-  # Out
-  data.frame(
-    Parameter = params,
-    Deviation_Smart = deviations,
-    Mean_Smart = means
-  )
-}
-
-
-
-#' @keywords internal
-.std_info_predictor_smart <- function(data,
-                                      variable,
-                                      type,
-                                      robust = FALSE,
-                                      two_sd = FALSE,
-                                      weights = NULL,
-                                      ...) {
-  if (type == ""intercept"") {
-    info <- list(sd = 0, mean = 0)
-  } else if (type == ""numeric"") {
-    info <- .compute_std_info(
-      data = data,
-      variable = variable,
-      robust = robust,
-      two_sd = two_sd,
-      weights = weights
-    )
-  } else if (type == ""factor"") {
-    info <- list(sd = 1, mean = 0)
-
-    # TO BE IMPROVED: Adjust if involved in interactions
-    # interactions <- types[types$Type %in% c(""interaction""), ]
-    # if(variable %in% interactions$Secondary_Variable){
-    #   interac_var <- unique(interactions[interactions$Secondary_Variable == variable, ""Variable""])
-    #   for(i in interac_var){
-    #     if(types[types$Parameter == i, ""Type""] == ""numeric""){
-    #       sd_x <- sd_x * .get_deviation(data, i, robust)
-    #     }
-    #   }
-    # }
-  } else if (type %in% c(""interaction"", ""nested"")) {
-    if (is.numeric(data[, variable])) {
-      info <- .compute_std_info(
-        data = data,
-        variable = variable,
-        robust = robust,
-        two_sd = two_sd,
-        weights = weights
-      )
-    } else if (is.factor(data[, variable])) {
-      info <- list(sd = 1, mean = 0)
-    } else {
-      info <- list(sd = 1, mean = 0)
-    }
-  } else {
-    info <- list(sd = 1, mean = 0)
-  }
-
-  list(sd = info$sd, mean = info$mean)
-}
-
-
-# Predictors - Basic ------------------------------------------------------------
-
-
-#' @keywords internal
-.std_info_predictors_basic <- function(model,
-                                       model_matrix,
-                                       types,
-                                       robust = FALSE,
-                                       two_sd = FALSE,
-                                       w = NULL,
-                                       ...) {
-  # Get deviations for all parameters
-  means <- deviations <- rep(NA_real_, length = length(names(model_matrix)))
-  for (i in seq_along(names(model_matrix))) {
-    var <- names(model_matrix)[i]
-    if (types[i, ""Type""] == ""intercept"") {
-      means[i] <- deviations[i] <- 0
-    } else {
-      std_info <- .compute_std_info(
-        data = model_matrix, variable = var,
-        robust = robust, two_sd = two_sd, weights = w
-      )
-      deviations[i] <- std_info$sd
-      means[i] <- std_info$mean
-    }
-  }
-
-  # Out
-  data.frame(
-    Parameter = types$Parameter[seq_along(names(model_matrix))],
-    Deviation_Basic = deviations,
-    Mean_Basic = means
-  )
-}
-
-
-
-
-
-# Response ------------------------------------------------------------
-
-#' @keywords internal
-.std_info_response_smart <- function(model, info, data, model_matrix, types, robust = FALSE, w = NULL,...) {
-  if (info$is_linear) {
-    # response <- insight::get_response(model)
-    response <- model.frame(model)[[1]]
-    means <- deviations <- rep(NA_real_, length = length(names(model_matrix)))
-    for (i in seq_along(names(model_matrix))) {
-      var <- names(model_matrix)[i]
-      if (any(types$Parameter == var) &&
-          types$Link[types$Parameter == var] == ""Difference"") {
-        parent_var <- types$Variable[types$Parameter == var]
-        intercept <- unique(data[[parent_var]])[1]
-        response_at_intercept <- response[data[[parent_var]] == intercept]
-        weights_at_intercept <- if (length(w)) w[data[[parent_var]] == intercept] else NULL
-
-        std_info <- .compute_std_info(
-          response = response_at_intercept,
-          robust = robust, weights = weights_at_intercept
-        )
-      } else {
-        std_info <- .compute_std_info(
-          response = response,
-          robust = robust, weights = w
-        )
-      }
-      deviations[i] <- std_info$sd
-      means[i] <- std_info$mean
-    }
-  } else {
-    deviations <- 1
-    means <- 0
-  }
-
-  # Out
-  data.frame(
-    Parameter = types$Parameter[seq_along(names(model_matrix))],
-    Deviation_Response_Smart = deviations,
-    Mean_Response_Smart = means
-  )
-}
-
-
-
-#' @importFrom stats model.frame
-#' @keywords internal
-.std_info_response_basic <- function(model, info, params, robust = FALSE, w = NULL, ...) {
-  # response <- insight::get_response(model)
-  response <- stats::model.frame(model)[[1]]
-
-  if (info$is_linear) {
-    if (robust == FALSE) {
-      sd_y <- datawizard::weighted_sd(response, w)
-      mean_y <- datawizard::weighted_mean(response, w)
-    } else {
-      sd_y <- datawizard::weighted_mad(response, w)
-      mean_y <- datawizard::weighted_median(response, w)
-    }
-  } else {
-    sd_y <- 1
-    mean_y <- 0
-  }
-
-  # Out
-  data.frame(
-    Parameter = params,
-    Deviation_Response_Basic = sd_y,
-    Mean_Response_Basic = mean_y
-  )
-}
-
-
-
-# Pseudo (GLMM) -----------------------------------------------------------
-
-#' @importFrom insight clean_names get_random find_formula get_variance get_data check_if_installed
-#' @importFrom performance check_heterogeneity_bias
-#' @importFrom datawizard demean
-#' @importFrom stats as.formula sd
-.std_info_pseudo <- function(model,
-                             mi,
-                             params,
-                             model_matrix,
-                             data,
-                             types,
-                             robust = FALSE,
-                             two_sd = FALSE,
-                             ...) {
-  if (robust) {
-    warning(""'robust' standardization not available for 'pseudo' method."",
-      call. = FALSE
-    )
-  }
-
-  f <- if (two_sd) 2 else 1
-
-  within_vars <- unclass(performance::check_heterogeneity_bias(model))
-  id <- insight::get_random(model)[[1]]
-  w <- insight::get_weights(model, na_rm = TRUE)
-
-  ## Find which parameters vary on level 1 (""within"")
-  is_within <- logical(length = length(params))
-  is_within[] <- NA
-  for (i in seq_along(params)) {
-    if (types[i] == ""intercept"") {
-      is_within[i] <- FALSE
-    } else if (types[i] == ""numeric"") {
-      is_within[i] <- insight::clean_names(params[i]) %in% within_vars
-    } else if (types[i] == ""factor"") {
-      is_within[i] <- any(sapply(paste0(""^"", within_vars), grepl, insight::clean_names(params[i])))
-    } else if (types[i] == ""interaction"") {
-      ints <- unlist(strsplit(params[i], "":"", fixed = TRUE))
-      is_within[i] <- any(sapply(ints, function(int) {
-        int <- insight::clean_names(int)
-        int %in% within_vars | # numeric
-          any(sapply(paste0(""^"", within_vars), grepl, int)) # factor
-      }))
-    }
-  }
-
-  ## test ""within""s are fully ""within""
-  # only relevant to numeric predictors that can have variance
-  if (any(check_within <- is_within & types == ""numeric"")) {
-    p_check_within <- params[check_within]
-    temp_d <- data.frame(model_matrix[, p_check_within, drop = FALSE])
-    colnames(temp_d) <- paste0(""W"", seq_len(ncol(temp_d))) # overwrite because can't deal with "":""
-
-    dm <- datawizard::demean(cbind(id, temp_d),
-      select = colnames(temp_d),
-      group = ""id""
-    )
-    dm <- dm[, paste0(colnames(temp_d), ""_between""), drop = FALSE]
-
-    has_lvl2_var <- sapply(seq_along(colnames(temp_d)), function(i) {
-      # If more than 1% of the variance in the within-var is between:
-      var(dm[, i]) /
-        var(temp_d[, i])
-    }) > 0.01
-    also_between <- p_check_within[has_lvl2_var]
-
-    if (length(also_between)) {
-      warning(
-        ""The following within-group terms have between-group variance:\n\t"",
-        paste0(also_between, collapse = "", ""),
-        ""\nThis can inflate standardized within-group parameters associated with"",
-        ""\nthese terms. See help(\""demean\"", package = \""datawizard\"") for modeling"",
-        ""\nbetween- and within-subject effects."",
-        call. = FALSE
-      )
-    }
-  }
-
-
-  ## Get 2 types of Deviation_Response_Pseudo
-  sd_y_within <- sd_y_between <- 1
-  if (mi$is_linear) {
-    insight::check_if_installed(""lme4"")
-
-    rand_name <- insight::find_random(model)$random
-
-    # maintain any y-transformations
-    frm <- insight::find_formula(model)
-    frm <- paste0(frm$conditional[2], "" ~ (1|"", rand_name, "")"")
-
-    m0 <- suppressWarnings(suppressMessages(
-      lme4::lmer(stats::as.formula(frm),
-        weights = w,
-        data = data
-      )
-    ))
-    m0v <- insight::get_variance(m0)
-
-    sd_y_between <- unname(sqrt(m0v$var.intercept))
-    sd_y_within <- unname(sqrt(m0v$var.residual))
-  }
-
-
-  ## Get scaling factors for each parameter
-  Deviation_Response_Pseudo <- Deviation_Pseudo <- numeric(ncol(model_matrix))
-  for (i in seq_along(params)) {
-    if (types[i] == ""intercept"") {
-      Deviation_Response_Pseudo[i] <- sd_y_between # doesn't matter
-      Deviation_Pseudo[i] <- 0
-    } else {
-      ## dumb way
-      if (is_within[i]) {
-        ## is within
-        X <- model_matrix[[i]]
-        Deviation_Response_Pseudo[i] <- sd_y_within
-      } else {
-        ## is between
-        X <- tapply(model_matrix[[i]], id, mean)
-        Deviation_Response_Pseudo[i] <- sd_y_between
-      }
-      Deviation_Pseudo[i] <- f * datawizard::weighted_sd(X, w)
-
-      ## smart way?
-      ## DONT USE: see correspondence with between Mattan and Eran BC
-      # m <- suppressWarnings(suppressMessages(lme4::lmer(model_matrix[[i]] ~ (1|id))))
-      # if (is_within[i]) {
-      #   ## is within
-      #   Deviation_Pseudo[i] <- sqrt(unname(unlist(suppressWarnings(
-      #     insight::get_variance(m, component = ""residual"")
-      #   ))))
-      #   Deviation_Response_Pseudo[i] <- sd_y_within
-      # } else {
-      #   ## is between
-      #   Deviation_Pseudo[i] <- sqrt(unname(unlist(suppressWarnings(
-      #     insight::get_variance(m, component = ""intercept"")
-      #   ))))
-      #   Deviation_Response_Pseudo[i] <- sd_y_between
-      # }
-    }
-  }
-
-  data.frame(
-    Parameter = params,
-    Deviation_Response_Pseudo,
-    Deviation_Pseudo
-  )
-}
-
-
-
-# Utils -------------------------------------------------------------------
-
-
-#' @keywords internal
-.compute_std_info <- function(data = NULL,
-                              variable = NULL,
-                              response = NULL,
-                              robust = FALSE,
-                              two_sd = FALSE,
-                              weights = NULL) {
-  f <- if (two_sd) 2 else 1
-  if (is.null(response)) {
-    response <- as.numeric(data[, variable])
-  }
-
-  if (robust == FALSE) {
-    sd_x <- datawizard::weighted_sd(response, weights)
-    mean_x <- datawizard::weighted_mean(response, weights)
-  } else {
-    sd_x <- datawizard::weighted_mad(response, weights)
-    mean_x <- datawizard::weighted_median(response, weights)
-  }
-
-  list(sd = f * sd_x, mean = mean_x)
-}

---FILE: R/standardize_parameters.R---
@@ -1,606 +0,0 @@
-#' Parameters standardization
-#'
-#' Compute standardized model parameters (coefficients).
-#'
-#' @param model A statistical model.
-#' @param method The method used for standardizing the parameters. Can be
-#'   `""refit""` (default), `""posthoc""`, `""smart""`, `""basic""` or `""pseudo""`. See
-#'   'Details'.
-#' @param include_response If `TRUE` (default), the response value will also be
-#'   standardized. If `FALSE`, only the predictors will be standardized. For
-#'   GLMs the response value will never be standardized (see *Generalized Linear
-#'   Models* section).
-#' @inheritParams standardize.default
-#' @inheritParams chisq_to_phi
-#' @param ... For `standardize_parameters()`, arguments passed to
-#'   [parameters::model_parameters], such as:
-#' - `ci_method`, `centrality` for Mixed models and Bayesian models...
-#' - `exponentiate`, ...
-#' - etc.
-#' @param parameters Deprecated.
-#'
-#' @details
-#'
-#' # Standardization Methods:
-#' - **refit**: This method is based on a complete model re-fit with a
-#' standardized version of the data. Hence, this method is equal to
-#' standardizing the variables before fitting the model. It is the ""purest"" and
-#' the most accurate (Neter et al., 1989), but it is also the most
-#' computationally costly and long (especially for heavy models such as Bayesian
-#' models). This method is particularly recommended for complex models that
-#' include interactions or transformations (e.g., polynomial or spline terms).
-#' The `robust` (default to `FALSE`) argument enables a robust standardization
-#' of data, i.e., based on the `median` and `MAD` instead of the `mean` and
-#' `SD`. **See [standardize()] for more details.**
-#'   - **Note** that `standardize_parameters(method = ""refit"")` may not return
-#'   the same results as fitting a model on data that has been standardized with
-#'   `standardize()`; `standardize_parameters()` used the data used by the model
-#'   fitting function, which might not be same data if there are missing values.
-#'   see the `remove_na` argument in `standardize()`.
-#' - **posthoc**: Post-hoc standardization of the parameters, aiming at
-#' emulating the results obtained by ""refit"" without refitting the model. The
-#' coefficients are divided by the standard deviation (or MAD if `robust`) of
-#' the outcome (which becomes their expression 'unit'). Then, the coefficients
-#' related to numeric variables are additionally multiplied by the standard
-#' deviation (or MAD if `robust`) of the related terms, so that they correspond
-#' to changes of 1 SD of the predictor (e.g., ""A change in 1 SD of `x` is
-#' related to a change of 0.24 of the SD of `y`). This does not apply to binary
-#' variables or factors, so the coefficients are still related to changes in
-#' levels. This method is not accurate and tend to give aberrant results when
-#' interactions are specified.
-#' - **basic**: This method is similar to `method = ""posthoc""`, but treats all
-#' variables as continuous: it also scales the coefficient by the standard
-#' deviation of model's matrix' parameter of factors levels (transformed to
-#' integers) or binary predictors. Although being inappropriate for these cases,
-#' this method is the one implemented by default in other software packages,
-#' such as [lm.beta::lm.beta()].
-#' - **smart** (Standardization of Model's parameters with Adjustment,
-#' Reconnaissance and Transformation - *experimental*): Similar to `method =
-#' ""posthoc""` in that it does not involve model refitting. The difference is
-#' that the SD (or MAD if `robust`) of the response is computed on the relevant
-#' section of the data. For instance, if a factor with 3 levels A (the
-#' intercept), B and C is entered as a predictor, the effect corresponding to B
-#' vs. A will be scaled by the variance of the response at the intercept only.
-#' As a results, the coefficients for effects of factors are similar to a Glass'
-#' delta.
-#' - **pseudo** (*for 2-level (G)LMMs only*): In this (post-hoc) method, the
-#' response and the predictor are standardized based on the level of prediction
-#' (levels are detected with [performance::check_heterogeneity_bias()]): Predictors
-#' are standardized based on their SD at level of prediction (see also
-#' [datawizard::demean()]); The outcome (in linear LMMs) is standardized based
-#' on a fitted random-intercept-model, where `sqrt(random-intercept-variance)`
-#' is used for level 2 predictors, and `sqrt(residual-variance)` is used for
-#' level 1 predictors (Hoffman 2015, page 342). A warning is given when a
-#' within-group varialbe is found to have access between-group variance.
-#'
-#' # Transformed Variables
-#' When the model's formula contains transformations (e.g. `y ~ exp(X)`) `method
-#' = ""refit""` will give different results compared to `method = ""basic""`
-#' (`""posthoc""` and `""smart""` do not support such transformations): While
-#' `""refit""` standardizes the data *prior* to the transformation (e.g.
-#' equivalent to `exp(scale(X))`), the `""basic""` method standardizes the
-#' transformed data (e.g. equivalent to `scale(exp(X))`).
-#' \cr\cr
-#' See the *Transformed Variables* section in [standardize.default()] for more
-#' details on how different transformations are dealt with when `method =
-#' ""refit""`.
-#'
-#' # Confidence Intervals
-#' The returned confidence intervals are re-scaled versions of the
-#' unstandardized confidence intervals, and not ""true"" confidence intervals of
-#' the standardized coefficients (cf. Jones & Waller, 2015).
-#'
-#' @inheritSection standardize.default Generalized Linear Models
-#' @inheritSection standardize.default Dealing with Factors
-#'
-#' @return A data frame with the standardized parameters (`Std_*`, depending on
-#'   the model type) and their CIs (`CI_low` and `CI_high`). Where applicable,
-#'   standard errors (SEs) are returned as an attribute (`attr(x,
-#'   ""standard_error"")`).
-#'
-#' @family standardize
-#' @family effect size indices
-#'
-#' @examples
-#' library(effectsize)
-#'
-#' model <- lm(len ~ supp * dose, data = ToothGrowth)
-#' standardize_parameters(model, method = ""refit"")
-#' \donttest{
-#' standardize_parameters(model, method = ""posthoc"")
-#' standardize_parameters(model, method = ""smart"")
-#' standardize_parameters(model, method = ""basic"")
-#'
-#' # Robust and 2 SD
-#' standardize_parameters(model, robust = TRUE)
-#' standardize_parameters(model, two_sd = TRUE)
-#'
-#'
-#' model <- glm(am ~ cyl * mpg, data = mtcars, family = ""binomial"")
-#' standardize_parameters(model, method = ""refit"")
-#' standardize_parameters(model, method = ""posthoc"")
-#' standardize_parameters(model, method = ""basic"", exponentiate = TRUE)
-#' }
-#'
-#'
-#' @examplesIf require(""lme4"")
-#' \donttest{
-#' m <- lme4::lmer(mpg ~ cyl + am + vs + (1 | cyl), mtcars)
-#' standardize_parameters(m, method = ""pseudo"", ci_method = ""satterthwaite"")
-#' }
-#'
-#'
-#' @examplesIf require(""rstanarm"")
-#' \dontrun{
-#' model <- stanarm::stan_glm(rating ~ critical + privileges, data = attitude, refresh = 0)
-#' standardize_posteriors(model, method = ""refit"")
-#' standardize_posteriors(model, method = ""posthoc"")
-#' standardize_posteriors(model, method = ""smart"")
-#' head(standardize_posteriors(model, method = ""basic""))
-#' }
-#'
-#' @references
-#' - Hoffman, L. (2015). Longitudinal analysis: Modeling within-person fluctuation and change. Routledge.
-#' - Jones, J. A., & Waller, N. G. (2015). The normal-theory and asymptotic distribution-free (ADF) covariance matrix of standardized regression coefficients: theoretical extensions and finite sample behavior. Psychometrika, 80(2), 365-378.
-#' - Neter, J., Wasserman, W., & Kutner, M. H. (1989). Applied linear regression models.
-#' - Gelman, A. (2008). Scaling regression inputs by dividing by two standard deviations. Statistics in medicine, 27(15), 2865-2873.
-#'
-#' @export
-#' @aliases standardise_parameters
-standardize_parameters <- function(model, method = ""refit"", ci = 0.95, robust = FALSE, two_sd = FALSE, include_response = TRUE, verbose = TRUE, parameters, ...) {
-  if (!missing(parameters)) {
-    warning(
-      ""'parameters' argument is deprecated, and will not be used."",
-      immediate. = TRUE
-    )
-  }
-
-  UseMethod(""standardize_parameters"")
-}
-
-#' @export
-standardise_parameters <- standardize_parameters
-
-#' @importFrom parameters model_parameters
-#' @importFrom insight model_info
-#' @importFrom utils head
-#' @export
-standardize_parameters.default <- function(model, method = ""refit"", ci = 0.95, robust = FALSE, two_sd = FALSE, include_response = TRUE, verbose = TRUE, ...) {
-  object_name <- insight::safe_deparse(substitute(model))
-  method <- match.arg(method, c(""refit"", ""posthoc"", ""smart"", ""basic"", ""classic"", ""pseudo""))
-
-  m_info <- .get_model_info(model, ...)
-  include_response <- include_response && .safe_to_standardize_response(m_info, verbose = verbose)
-
-  if (method == ""refit"") {
-    model <- standardize(model,
-                         robust = robust, two_sd = two_sd, include_response = include_response,
-                         verbose = verbose, m_info = m_info)
-  }
-
-  # need model_parameters to return the parameters, not the terms
-  if (inherits(model, ""aov"")) class(model) <- class(model)[class(model) != ""aov""]
-  pars <- parameters::model_parameters(model, ci = ci, standardize = NULL, effects = ""fixed"", ...)
-
-  # should post hoc exponentiate?
-  exponentiate <- isTRUE(eval(match.call()[[""exponentiate""]], envir = parent.frame()))
-  coefficient_name <- attr(pars, ""coefficient_name"")
-
-  if (method %in% c(""posthoc"", ""smart"", ""basic"", ""classic"", ""pseudo"")) {
-    if (m_info$is_multivariate) {
-      stop('Cannot post-hoc standardize multivariate models. Try using method ""refit"" instead.')
-    }
-
-    pars <- .standardize_parameters_posthoc(pars, method, model, m_info, robust, two_sd, exponentiate,
-                                            include_response, verbose)
-
-    method <- attr(pars, ""std_method"")
-    robust <- attr(pars, ""robust"")
-  }
-
-  ## clean cols
-  if (!is.null(ci)) pars$CI <- attr(pars, ""ci"")
-  colnm <- c(""Component"", ""Response"", ""Group"", ""Parameter"", head(.col_2_scale, -2), ""CI"", ""CI_low"", ""CI_high"")
-  pars <- pars[, colnm[colnm %in% colnames(pars)]]
-
-  if (!is.null(coefficient_name) && coefficient_name %in% c(""Odds Ratio"", ""Risk Ratio"", ""IRR"")) {
-    colnames(pars)[colnames(pars) == ""Coefficient""] <- gsub("" "", ""_"", coefficient_name)
-  }
-
-  i <- colnames(pars) %in% c(""Coefficient"", ""Median"", ""Mean"", ""MAP"", c(""Odds_Ratio"", ""Risk_Ratio"", ""IRR""))
-  colnames(pars)[i] <- paste0(""Std_"", colnames(pars)[i])
-
-  ## SE attribute?
-  if (""SE"" %in% colnames(pars)) {
-    attr(pars, ""standard_error"") <- pars$SE
-    pars$SE <- NULL
-  }
-
-  ## attributes
-  attr(pars, ""std_method"") <- method
-  attr(pars, ""two_sd"") <- two_sd
-  attr(pars, ""robust"") <- robust
-  attr(pars, ""object_name"") <- object_name
-  attr(pars, ""ci"") <- ci
-  attr(pars, ""include_response"") <- include_response
-  class(pars) <- c(""effectsize_std_params"", ""effectsize_table"", ""see_effectsize_table"", ""data.frame"")
-  return(pars)
-}
-
-#' @export
-standardize_parameters.mediate <- function(model, method = ""refit"", ci = 0.95, robust = FALSE, two_sd = FALSE, include_response = TRUE, verbose = TRUE, ...) {
-  if (method != ""refit"")
-    warning(""Only method = 'refit' is supported for mediation models."", immediate. = TRUE)
-
-  NextMethod(""standardize_parameters"", method = ""refit"", ci = ci, robust = robust, two_sd = two_sd, include_response = include_response, verbose = verbose)
-}
-
-#' @export
-standardize_parameters.parameters_model <- function(model, method = ""refit"", ci = NULL, robust = FALSE, two_sd = FALSE, include_response = TRUE, verbose = TRUE, ...) {
-  if (method == ""refit"") {
-    stop(""Method 'refit' not supported for 'model_parameters()"", call. = TRUE)
-  }
-
-  if (!is.null(ci)) {
-    warnings(""Argument 'ci' argument not supported for 'model_parameters(). It is ignored."", call. = TRUE)
-  }
-
-  pars <- model
-  ci <- attr(pars, ""ci"")
-  model <- .get_object(pars)
-  if (is.null(model)) model <- attr(pars, ""object"")
-
-  m_info <- .get_model_info(model, ...)
-  include_response <- include_response && .safe_to_standardize_response(m_info, verbose = verbose)
-
-  if (is.null(exponentiate <- attr(pars, ""exponentiate""))) exponentiate <- FALSE
-  pars <- .standardize_parameters_posthoc(pars, method, model, m_info, robust, two_sd, exponentiate, include_response, verbose)
-  method <- attr(pars, ""std_method"")
-  robust <- attr(pars, ""robust"")
-
-  ## clean cols
-  if (!is.null(ci)) pars$CI <- attr(pars, ""ci"")
-  colnm <- c(""Component"", ""Response"", ""Group"", ""Parameter"", head(.col_2_scale, -2), ""CI"", ""CI_low"", ""CI_high"")
-  pars <- pars[, colnm[colnm %in% colnames(pars)]]
-  i <- colnames(pars) %in% c(""Coefficient"", ""Median"", ""Mean"", ""MAP"")
-  colnames(pars)[i] <- paste0(""Std_"", colnames(pars)[i])
-
-  ## SE attribute?
-  if (""SE"" %in% colnames(pars)) {
-    attr(pars, ""standard_error"") <- pars$SE
-    pars$SE <- NULL
-  }
-
-  ## attributes
-  attr(pars, ""std_method"") <- method
-  attr(pars, ""two_sd"") <- two_sd
-  attr(pars, ""robust"") <- robust
-  attr(pars, ""ci"") <- ci
-  attr(pars, ""include_response"") <- include_response
-  class(pars) <- c(""effectsize_std_params"", ""effectsize_table"", ""see_effectsize_table"", ""data.frame"")
-  return(pars)
-}
-
-#' @export
-standardize_parameters.bootstrap_model <-
-  function(model,
-           method = ""refit"",
-           ci = 0.95,
-           robust = FALSE,
-           two_sd = FALSE,
-           include_response = TRUE,
-           verbose = TRUE,
-           ...) {
-    object_name <- insight::safe_deparse(substitute(model))
-    method <- match.arg(method, c(""refit"", ""posthoc"", ""smart"", ""basic"", ""classic"", ""pseudo""))
-
-    pars <- model
-    model <- attr(pars, ""original_model"")
-
-    m_info <- .get_model_info(model, ...)
-    include_response <- include_response && .safe_to_standardize_response(m_info, verbose = verbose)
-
-    if (method == ""refit"") {
-      stop(""The 'refit' method is not supported for bootstrapped models."")
-      ## But it would look something like this:
-      # model <- standardize(model, robust = robust, two_sd = two_sd, verbose = verbose, m_info = m_info)
-      # model <- parameters::bootstrap_model(model, iterations = 1000, verbose = verbose)
-      # return(model)
-    }
-
-    # need model_parameters to return the parameters, not the terms
-    if (inherits(model, ""aov"")) class(model) <- class(model)[class(model) != ""aov""]
-
-
-    if (method %in% c(""posthoc"", ""smart"", ""basic"", ""classic"", ""pseudo"")) {
-      pars <- .standardize_posteriors_posthoc(pars, method, model, m_info, robust, two_sd, include_response, verbose)
-
-      method <- attr(pars, ""std_method"")
-      robust <- attr(pars, ""robust"")
-    }
-
-    pars <- bayestestR::describe_posterior(pars, centrality = ""median"",
-                                           ci = ci, ci_method = ""quantile"",
-                                           test = NULL)
-    names(pars)[names(pars) == ""Median""] <- ""Std_Coefficient""
-
-
-    attr(pars, ""std_method"") <- method
-    attr(pars, ""two_sd"") <- two_sd
-    attr(pars, ""robust"") <- robust
-    attr(pars, ""object_name"") <- object_name
-    attr(pars, ""ci"") <- ci
-    attr(pars, ""include_response"") <- include_response
-    class(pars) <- c(""effectsize_std_params"", ""effectsize_table"", ""see_effectsize_table"", ""data.frame"")
-    return(pars)
-  }
-
-#' @export
-standardize_parameters.bootstrap_parameters <-
-  function(model,
-           method = ""refit"",
-           ci = 0.95,
-           robust = FALSE,
-           two_sd = FALSE,
-           include_response = TRUE,
-           verbose = TRUE,
-           ...) {
-
-    standardize_parameters(attr(model, ""boot_samples""),
-                           method = method,
-                           ci = ci,
-                           robust = robust,
-                           two_sd = two_sd,
-                           include_response = include_response,
-                           verbose = verbose,
-                           ...)
-  }
-
-
-#' @export
-standardize_parameters.model_fit <-
-  function(model,
-           method = ""refit"",
-           ci = 0.95,
-           robust = FALSE,
-           two_sd = FALSE,
-           include_response = TRUE,
-           verbose = TRUE,
-           ...) {
-
-    standardize_parameters(
-      model$fit,
-      method = method,
-      ci = ci,
-      robust = robust,
-      two_sd = two_sd,
-      include_response = include_response,
-      verbose = verbose,
-      ...
-    )
-  }
-
-
-
-#' @keywords internal
-#' @importFrom insight model_info find_random
-.standardize_parameters_posthoc <- function(pars, method, model, mi, robust, two_sd, exponentiate, include_response, verbose) {
-  # Sanity Check for ""pseudo""
-  method <- .should_pseudo(method, model, mi)
-
-  method <- .cant_smart_or_posthoc(method, model, mi, pars$Parameter)
-
-  if (robust && method == ""pseudo"") {
-    warning(""'robust' standardization not available for 'pseudo' method."",
-      call. = FALSE
-    )
-    robust <- FALSE
-  }
-
-
-  ## Get scaling factors
-  deviations <- standardize_info(model, robust = robust, include_pseudo = method == ""pseudo"", two_sd = two_sd,
-                                 model_info = mi)
-  i_missing <- setdiff(seq_len(nrow(pars)), seq_len(nrow(deviations)))
-  unstd <- pars
-  if (length(i_missing)) {
-    deviations[i_missing, ] <- NA
-  }
-
-  if (method == ""basic"") {
-    col_dev_resp <- ""Deviation_Response_Basic""
-    col_dev_pred <- ""Deviation_Basic""
-  } else if (method == ""posthoc"") {
-    col_dev_resp <- ""Deviation_Response_Basic""
-    col_dev_pred <- ""Deviation_Smart""
-  } else if (method == ""smart"") {
-    col_dev_resp <- ""Deviation_Response_Smart""
-    col_dev_pred <- ""Deviation_Smart""
-  } else if (method == ""pseudo"") {
-    col_dev_resp <- ""Deviation_Response_Pseudo""
-    col_dev_pred <- ""Deviation_Pseudo""
-  } else {
-    stop(""'method' must be one of 'basic', 'posthoc', 'smart' or 'pseudo'."")
-  }
-
-
-  .dev_pred <- deviations[[col_dev_pred]]
-  .dev_resp <- deviations[[col_dev_resp]]
-  if (!include_response) .dev_resp <- 1
-  .dev_factor <- .dev_pred / .dev_resp
-
-  # Sapply standardization
-  pars[, colnames(pars) %in% .col_2_scale] <- lapply(
-    pars[, colnames(pars) %in% .col_2_scale, drop = FALSE],
-    function(x) {
-      if (exponentiate) {
-        x ^ .dev_factor
-      } else {
-        x * .dev_factor
-      }
-    }
-  )
-
-  to_complete <- apply(pars[, colnames(pars) %in% .col_2_scale], 1, anyNA)
-  if (length(i_missing) || any(to_complete)) {
-    i_missing <- union(i_missing, which(to_complete))
-
-    pars[i_missing, colnames(pars) %in% .col_2_scale] <-
-      unstd[i_missing, colnames(pars) %in% .col_2_scale]
-  }
-
-  attr(pars, ""std_method"") <- method
-  attr(pars, ""two_sd"") <- two_sd
-  attr(pars, ""robust"") <- robust
-
-  return(pars)
-}
-
-#' @keywords internal
-.col_2_scale <- c(""Coefficient"", ""Median"", ""Mean"", ""MAP"", ""SE"", ""CI_low"", ""CI_high"")
-
-
-# standardize_posteriors --------------------------------------------------
-
-
-
-#' @rdname standardize_parameters
-#' @export
-#' @aliases standardise_posteriors
-standardize_posteriors <- function(model, method = ""refit"", robust = FALSE, two_sd = FALSE, include_response = TRUE, verbose = TRUE, ...) {
-  object_name <- insight::safe_deparse(substitute(model))
-
-  m_info <- .get_model_info(model, ...)
-  include_response <- include_response && .safe_to_standardize_response(m_info, verbose = verbose)
-
-  if (method == ""refit"") {
-    model <- standardize(model, robust = robust, two_sd = two_sd, include_response = include_response,
-                         verbose = verbose, m_info = m_info)
-  }
-
-  pars <- insight::get_parameters(model)
-
-
-  if (method %in% c(""posthoc"", ""smart"", ""basic"", ""classic"", ""pseudo"")) {
-    pars <- .standardize_posteriors_posthoc(pars, method, model, m_info, robust, two_sd, include_response, verbose)
-
-    method <- attr(pars, ""std_method"")
-    robust <- attr(pars, ""robust"")
-  }
-
-  ## attributes
-  attr(pars, ""std_method"") <- method
-  attr(pars, ""two_sd"") <- two_sd
-  attr(pars, ""robust"") <- robust
-  attr(pars, ""include_response"") <- include_response
-  attr(pars, ""object_name"") <- object_name
-  class(pars) <- c(""effectsize_std_params"", class(pars))
-  return(pars)
-}
-
-#' @export
-standardise_posteriors <- standardize_posteriors
-
-
-#' @keywords internal
-#' @importFrom insight find_random
-.standardize_posteriors_posthoc <- function(pars, method, model, mi, robust, two_sd, include_response, verbose) {
-  # Sanity Check for ""pseudo""
-  method <- .should_pseudo(method, model)
-
-  method <- .cant_smart_or_posthoc(method, model, mi, pars$Parameter)
-
-  if (robust && method == ""pseudo"") {
-    warning(""'robust' standardization not available for 'pseudo' method."",
-      call. = FALSE
-    )
-    robust <- FALSE
-  }
-
-  ## Get scaling factors
-  deviations <- standardize_info(model, robust = robust, include_pseudo = method == ""pseudo"", two_sd = two_sd,
-                                 model_info = mi)
-  i <- match(deviations$Parameter, colnames(pars))
-  pars <- pars[, i]
-
-  if (method == ""basic"") {
-    col_dev_resp <- ""Deviation_Response_Basic""
-    col_dev_pred <- ""Deviation_Basic""
-  } else if (method == ""posthoc"") {
-    col_dev_resp <- ""Deviation_Response_Basic""
-    col_dev_pred <- ""Deviation_Smart""
-  } else if (method == ""smart"") {
-    col_dev_resp <- ""Deviation_Response_Smart""
-    col_dev_pred <- ""Deviation_Smart""
-  } else if (method == ""pseudo"") {
-    col_dev_resp <- ""Deviation_Response_Pseudo""
-    col_dev_pred <- ""Deviation_Pseudo""
-  } else {
-    stop(""'method' must be one of 'basic', 'posthoc', 'smart' or 'pseudo'."")
-  }
-
-  .dev_pred <- deviations[[col_dev_pred]]
-  .dev_resp <- deviations[[col_dev_resp]]
-  if (!include_response) .dev_resp <- 1
-  .dev_factor <- .dev_pred / .dev_resp
-
-  # Sapply standardization
-  pars <- t(t(pars) * .dev_factor)
-  pars <- as.data.frame(pars)
-
-  attr(pars, ""std_method"") <- method
-  attr(pars, ""two_sd"") <- two_sd
-  attr(pars, ""robust"") <- robust
-
-  return(pars)
-}
-
-
-# util --------------------------------------------------------------------
-
-
-
-#' @keywords internal
-.cant_smart_or_posthoc <- function(method, model, mi, params) {
-  if (method %in% c(""smart"", ""posthoc"")) {
-    cant_posthocsmart <- FALSE
-
-    if (mi$is_linear) {
-      if (!colnames(model.frame(model))[1] == insight::find_response(model)) {
-        can_posthocsmart <- TRUE
-      }
-    }
-
-    # factors are allowed
-    if (!cant_posthocsmart &&
-        !all(params == insight::clean_names(params) |
-             grepl(""(as.factor|factor)\\("", params))) {
-      cant_posthocsmart <- TRUE
-    }
-
-    if (cant_posthocsmart) {
-      warning(""Method '"", method, ""' does not currently support models with transformed parameters."",
-              ""\nReverting to 'basic' method. Concider using the 'refit' method directly."",
-              call. = FALSE
-      )
-      method <- ""basic""
-    }
-  }
-  method
-}
-
-
-#' @keywords internal
-.should_pseudo <- function(method, model, mi) {
-  if (method == ""pseudo"" &&
-      !(mi$is_mixed &&
-        length(insight::find_random(model)$random) == 1)) {
-    warning(
-      ""'pseudo' method only available for 2-level (G)LMMs.\n"",
-      ""Setting method to 'basic'."",
-      call. = FALSE
-    )
-    method <- ""basic""
-  }
-  method
-}

---FILE: R/utils.R---
@@ -30,4 +30,33 @@
   if (is.null(model_info)) model_info <- insight::model_info(model)
 
   model_info
+}
+
+#' @keywords internal
+.get_object <- function(x, attribute_name = ""object_name"") {
+  obj_name <- attr(x, attribute_name, exact = TRUE)
+  model <- NULL
+  if (!is.null(obj_name)) {
+    model <- tryCatch(
+      {
+        get(obj_name, envir = parent.frame())
+      },
+      error = function(e) {
+        NULL
+      }
+    )
+    if (is.null(model) ||
+        # prevent self reference
+        inherits(model, ""parameters_model"")) {
+      model <- tryCatch(
+        {
+          get(obj_name, envir = globalenv())
+        },
+        error = function(e) {
+          NULL
+        }
+      )
+    }
+  }
+  model
 }
\ No newline at end of file

---FILE: R/utils_standardize.R---
@@ -1,32 +0,0 @@
-
-# For standardize_parameters ----------------------------------------------
-
-#' @keywords internal
-.get_object <- function(x, attribute_name = ""object_name"") {
-  obj_name <- attr(x, attribute_name, exact = TRUE)
-  model <- NULL
-  if (!is.null(obj_name)) {
-    model <- tryCatch(
-      {
-        get(obj_name, envir = parent.frame())
-      },
-      error = function(e) {
-        NULL
-      }
-    )
-    if (is.null(model) ||
-      # prevent self reference
-      inherits(model, ""parameters_model"")) {
-      model <- tryCatch(
-        {
-          get(obj_name, envir = globalenv())
-        },
-        error = function(e) {
-          NULL
-        }
-      )
-    }
-  }
-  model
-}
-

---FILE: README.Rmd---
@@ -127,21 +127,21 @@ epsilon_squared(model)
 And more...
 
 
-### Regression Models (Standardized Parameters)
+<!-- ### Regression Models (Standardized Parameters) -->
 
-Importantly, `effectsize` also provides [advanced methods](https://easystats.github.io/effectsize/articles/standardize_parameters.html) to compute standardized parameters for regression models.
+<!-- Importantly, `effectsize` also provides [advanced methods](https://easystats.github.io/effectsize/articles/standardize_parameters.html) to compute standardized parameters for regression models. -->
 
-```{r beta, warning=FALSE, message=FALSE}
-m <- lm(rating ~ complaints + privileges + advance, data = attitude)
+<!-- ```{r beta, warning=FALSE, message=FALSE} -->
+<!-- m <- lm(rating ~ complaints + privileges + advance, data = attitude) -->
 
-standardize_parameters(m)
-```
+<!-- standardize_parameters(m) -->
+<!-- ``` -->
 
-Also, models can be re-fit with standardized data:
+<!-- Also, models can be re-fit with standardized data: -->
 
-```{r std-model, warning=FALSE, message=FALSE}
-standardize(m)
-```
+<!-- ```{r std-model, warning=FALSE, message=FALSE} -->
+<!-- standardize(m) -->
+<!-- ``` -->
 
 ## Effect Size Conversion
 

---FILE: _pkgdown.yml---
@@ -35,8 +35,6 @@ navbar:
       href: reference/index.html
     - text: ""Effect Sizes""
       menu:
-      - text: ""Parameter and Model Standardization""
-        href: articles/standardize_parameters.html
       - text: ""ANOVA Effect Sizes""
         href: articles/anovaES.html
       - text: ""Effect Sizes for Simple Hypothesis Tests""
@@ -71,12 +69,6 @@ reference:
   - rank_biserial
   - cles
 
-- title: ""Standardization""
-  contents:
-  - standardize.default
-  - standardize_parameters
-  - standardize_info
-
 - title: ""Effect Size Conversion""
 - subtitle: ""From Test Statistics""
   contents:

---FILE: man/cles.Rd---
@@ -137,7 +137,6 @@ Other effect size indices:
 \code{\link{effectsize.BFBayesFactor}()},
 \code{\link{eta_squared}()},
 \code{\link{phi}()},
-\code{\link{rank_biserial}()},
-\code{\link{standardize_parameters}()}
+\code{\link{rank_biserial}()}
 }
 \concept{effect size indices}

---FILE: man/cohens_d.Rd---
@@ -223,7 +223,6 @@ Other effect size indices:
 \code{\link{effectsize.BFBayesFactor}()},
 \code{\link{eta_squared}()},
 \code{\link{phi}()},
-\code{\link{rank_biserial}()},
-\code{\link{standardize_parameters}()}
+\code{\link{rank_biserial}()}
 }
 \concept{effect size indices}

---FILE: man/effectsize.Rd---
@@ -62,7 +62,7 @@ input model. See details.
 \item A \strong{proportion test} returns \emph{p}.
 }
 \item Objects of class \code{anova}, \code{aov}, or \code{aovlist}, depending on \code{type}: \code{""eta""} (default), \code{""omega""} or \code{""epsilon""} -squared, \code{""f""}, or \code{""f2""}.
-\item Other objects are passed to \code{\link[=standardize_parameters]{standardize_parameters()}}.
+\item Other objects are passed to \code{\link[parameters:standardize_parameters]{parameters::standardize_parameters()}}.
 }
 
 \strong{For statistical models it is recommended to directly use the listed
@@ -125,7 +125,6 @@ Other effect size indices:
 \code{\link{cohens_d}()},
 \code{\link{eta_squared}()},
 \code{\link{phi}()},
-\code{\link{rank_biserial}()},
-\code{\link{standardize_parameters}()}
+\code{\link{rank_biserial}()}
 }
 \concept{effect size indices}

---FILE: man/eta_squared.Rd---
@@ -344,7 +344,6 @@ Other effect size indices:
 \code{\link{cohens_d}()},
 \code{\link{effectsize.BFBayesFactor}()},
 \code{\link{phi}()},
-\code{\link{rank_biserial}()},
-\code{\link{standardize_parameters}()}
+\code{\link{rank_biserial}()}
 }
 \concept{effect size indices}

---FILE: man/phi.Rd---
@@ -212,7 +212,6 @@ Other effect size indices:
 \code{\link{cohens_d}()},
 \code{\link{effectsize.BFBayesFactor}()},
 \code{\link{eta_squared}()},
-\code{\link{rank_biserial}()},
-\code{\link{standardize_parameters}()}
+\code{\link{rank_biserial}()}
 }
 \concept{effect size indices}

---FILE: man/rank_biserial.Rd---
@@ -232,7 +232,6 @@ Other effect size indices:
 \code{\link{cohens_d}()},
 \code{\link{effectsize.BFBayesFactor}()},
 \code{\link{eta_squared}()},
-\code{\link{phi}()},
-\code{\link{standardize_parameters}()}
+\code{\link{phi}()}
 }
 \concept{effect size indices}

---FILE: man/reexports.Rd---
@@ -6,6 +6,9 @@
 \alias{equivalence_test}
 \alias{standardize}
 \alias{standardise}
+\alias{standardize_parameters}
+\alias{standardize_posteriors}
+\alias{standardize_info}
 \alias{display}
 \alias{print_html}
 \alias{print_md}
@@ -21,5 +24,7 @@ below to see their documentation.
   \item{datawizard}{\code{\link[datawizard:standardize]{standardise}}, \code{\link[datawizard]{standardize}}}
 
   \item{insight}{\code{\link[insight]{display}}, \code{\link[insight:display]{print_html}}, \code{\link[insight:display]{print_md}}}
+
+  \item{parameters}{\code{\link[parameters]{standardize_info}}, \code{\link[parameters]{standardize_parameters}}, \code{\link[parameters:standardize_parameters]{standardize_posteriors}}}
 }}
 

---FILE: man/standardize.default.Rd---
@@ -1,105 +0,0 @@
-% Generated by roxygen2: do not edit by hand
-% Please edit documentation in R/standardize.models.R
-\name{standardize.default}
-\alias{standardize.default}
-\alias{standardize_models}
-\alias{standardize.models}
-\alias{standardise.models}
-\alias{standardise.default}
-\title{Re-fit a model with standardized data}
-\usage{
-\method{standardize}{default}(
-  x,
-  robust = FALSE,
-  two_sd = FALSE,
-  weights = TRUE,
-  verbose = TRUE,
-  include_response = TRUE,
-  ...
-)
-}
-\arguments{
-\item{x}{A statistical model.}
-
-\item{robust}{Logical, if \code{TRUE}, centering is done by subtracting the
-median from the variables and dividing it by the median absolute deviation
-(MAD). If \code{FALSE}, variables are standardized by subtracting the
-mean and dividing it by the standard deviation (SD).}
-
-\item{two_sd}{If \code{TRUE}, the variables are scaled by two times the deviation
-(SD or MAD depending on \code{robust}). This method can be useful to obtain
-model coefficients of continuous parameters comparable to coefficients
-related to binary predictors, when applied to \strong{the predictors} (not the
-outcome) (Gelman, 2008).}
-
-\item{weights}{If \code{TRUE} (default), a weighted-standardization is carried out.}
-
-\item{verbose}{Toggle warnings and messages on or off.}
-
-\item{include_response}{If \code{TRUE} (default), the response value will also be
-standardized. If \code{FALSE}, only the predictors will be standardized.
-\itemize{
-\item Note that for GLMs and models with non-linear link functions, the
-response value will not be standardized, to make re-fitting the model work.
-\item If the model contains an \code{\link[stats:offset]{stats::offset()}}, the offset variable(s) will
-be standardized only if the response is standardized. If \code{two_sd = TRUE},
-offsets are standardized by one-sd (similar to the response).
-\item (For \code{mediate} models, the \code{include_response} refers to the outcome in
-the y model; m model's response will always be standardized when possible).
-}}
-
-\item{...}{Arguments passed to or from other methods.}
-}
-\value{
-A statistical model fitted on standardized data
-}
-\description{
-Performs a standardization of data (z-scoring) using
-\code{\link[datawizard:standardize]{datawizard::standardize()}} and then re-fits the model to the standardized
-data.
-\cr\cr
-Standardization is done by completely refitting the model on the standardized
-data. Hence, this approach is equal to standardizing the variables \emph{before}
-fitting the model and will return a new model object. This method is
-particularly recommended for complex models that include interactions or
-transformations (e.g., polynomial or spline terms). The \code{robust} (default to
-\code{FALSE}) argument enables a robust standardization of data, based on the
-\code{median} and the \code{MAD} instead of the \code{mean} and the \code{SD}.
-}
-\section{Generalized Linear Models}{
-Standardization for generalized linear models (GLM, GLMM, etc) is done only
-with respect to the predictors (while the outcome remains as-is,
-unstandardized) - maintaining the interpretability of the coefficients (e.g.,
-in a binomial model: the exponent of the standardized parameter is the OR of
-a change of 1 SD in the predictor, etc.)
-}
-
-\section{Dealing with Factors}{
-\code{standardize(model)} or \code{standardize_parameters(model, method = ""refit"")} do
-\emph{not} standardize categorical predictors (i.e. factors) / their
-dummy-variables, which may be a different behaviour compared to other R
-packages (such as \pkg{lm.beta}) or other software packages (like SPSS). To
-mimic such behaviours, either use \code{standardize_parameters(model, method = ""basic"")} to obtain post-hoc standardized parameters, or standardize the data
-with \code{datawizard::standardize(data, force = TRUE)} \emph{before} fitting the
-model.
-}
-
-\section{Transformed Variables}{
-When the model's formula contains transformations (e.g. \code{y ~ exp(X)}) the
-transformation effectively takes place after standardization (e.g.,
-\code{exp(scale(X))}). Since some transformations are undefined for none positive
-values, such as \code{log()} and \code{sqrt()}, the releven variables are shifted (post
-standardization) by \code{Z - min(Z) + 1} or \code{Z - min(Z)} (respectively).
-}
-
-\examples{
-model <- lm(Infant.Mortality ~ Education * Fertility, data = swiss)
-coef(standardize(model))
-
-}
-\seealso{
-Other standardize: 
-\code{\link{standardize_info}()},
-\code{\link{standardize_parameters}()}
-}
-\concept{standardize}

---FILE: man/standardize_info.Rd---
@@ -1,58 +0,0 @@
-% Generated by roxygen2: do not edit by hand
-% Please edit documentation in R/standardize_info.R
-\name{standardize_info}
-\alias{standardize_info}
-\alias{standardise_info}
-\title{Get Standardization Information}
-\usage{
-standardize_info(
-  model,
-  robust = FALSE,
-  two_sd = FALSE,
-  include_pseudo = FALSE,
-  ...
-)
-}
-\arguments{
-\item{model}{A statistical model.}
-
-\item{robust}{Logical, if \code{TRUE}, centering is done by subtracting the
-median from the variables and dividing it by the median absolute deviation
-(MAD). If \code{FALSE}, variables are standardized by subtracting the
-mean and dividing it by the standard deviation (SD).}
-
-\item{two_sd}{If \code{TRUE}, the variables are scaled by two times the deviation
-(SD or MAD depending on \code{robust}). This method can be useful to obtain
-model coefficients of continuous parameters comparable to coefficients
-related to binary predictors, when applied to \strong{the predictors} (not the
-outcome) (Gelman, 2008).}
-
-\item{include_pseudo}{(For (G)LMMs) Should Pseudo-standardized information be
-included?}
-
-\item{...}{Arguments passed to or from other methods.}
-}
-\value{
-A data frame with information on each parameter (see
-\link[parameters:parameters_type]{parameters::parameters_type}), and various standardization coefficients
-for the post-hoc methods (see \code{\link[=standardize_parameters]{standardize_parameters()}}) for the predictor
-and the response.
-}
-\description{
-This function extracts information, such as the deviations (SD or MAD) from
-parent variables, that are necessary for post-hoc standardization of
-parameters. This function gives a window on how standardized are obtained,
-i.e., by what they are divided. The ""basic"" method of standardization uses.
-}
-\examples{
-model <- lm(mpg ~ ., data = mtcars)
-standardize_info(model)
-standardize_info(model, robust = TRUE)
-standardize_info(model, two_sd = TRUE)
-}
-\seealso{
-Other standardize: 
-\code{\link{standardize.default}()},
-\code{\link{standardize_parameters}()}
-}
-\concept{standardize}

---FILE: man/standardize_parameters.Rd---
@@ -1,229 +0,0 @@
-% Generated by roxygen2: do not edit by hand
-% Please edit documentation in R/standardize_parameters.R
-\name{standardize_parameters}
-\alias{standardize_parameters}
-\alias{standardise_parameters}
-\alias{standardize_posteriors}
-\alias{standardise_posteriors}
-\title{Parameters standardization}
-\usage{
-standardize_parameters(
-  model,
-  method = ""refit"",
-  ci = 0.95,
-  robust = FALSE,
-  two_sd = FALSE,
-  include_response = TRUE,
-  verbose = TRUE,
-  parameters,
-  ...
-)
-
-standardize_posteriors(
-  model,
-  method = ""refit"",
-  robust = FALSE,
-  two_sd = FALSE,
-  include_response = TRUE,
-  verbose = TRUE,
-  ...
-)
-}
-\arguments{
-\item{model}{A statistical model.}
-
-\item{method}{The method used for standardizing the parameters. Can be
-\code{""refit""} (default), \code{""posthoc""}, \code{""smart""}, \code{""basic""} or \code{""pseudo""}. See
-'Details'.}
-
-\item{ci}{Confidence Interval (CI) level}
-
-\item{robust}{Logical, if \code{TRUE}, centering is done by subtracting the
-median from the variables and dividing it by the median absolute deviation
-(MAD). If \code{FALSE}, variables are standardized by subtracting the
-mean and dividing it by the standard deviation (SD).}
-
-\item{two_sd}{If \code{TRUE}, the variables are scaled by two times the deviation
-(SD or MAD depending on \code{robust}). This method can be useful to obtain
-model coefficients of continuous parameters comparable to coefficients
-related to binary predictors, when applied to \strong{the predictors} (not the
-outcome) (Gelman, 2008).}
-
-\item{include_response}{If \code{TRUE} (default), the response value will also be
-standardized. If \code{FALSE}, only the predictors will be standardized. For
-GLMs the response value will never be standardized (see \emph{Generalized Linear
-Models} section).}
-
-\item{verbose}{Toggle warnings and messages on or off.}
-
-\item{parameters}{Deprecated.}
-
-\item{...}{For \code{standardize_parameters()}, arguments passed to
-\link[parameters:model_parameters]{parameters::model_parameters}, such as:
-\itemize{
-\item \code{ci_method}, \code{centrality} for Mixed models and Bayesian models...
-\item \code{exponentiate}, ...
-\item etc.
-}}
-}
-\value{
-A data frame with the standardized parameters (\verb{Std_*}, depending on
-the model type) and their CIs (\code{CI_low} and \code{CI_high}). Where applicable,
-standard errors (SEs) are returned as an attribute (\code{attr(x, ""standard_error"")}).
-}
-\description{
-Compute standardized model parameters (coefficients).
-}
-\section{Standardization Methods:}{
-\itemize{
-\item \strong{refit}: This method is based on a complete model re-fit with a
-standardized version of the data. Hence, this method is equal to
-standardizing the variables before fitting the model. It is the ""purest"" and
-the most accurate (Neter et al., 1989), but it is also the most
-computationally costly and long (especially for heavy models such as Bayesian
-models). This method is particularly recommended for complex models that
-include interactions or transformations (e.g., polynomial or spline terms).
-The \code{robust} (default to \code{FALSE}) argument enables a robust standardization
-of data, i.e., based on the \code{median} and \code{MAD} instead of the \code{mean} and
-\code{SD}. \strong{See \code{\link[=standardize]{standardize()}} for more details.}
-\itemize{
-\item \strong{Note} that \code{standardize_parameters(method = ""refit"")} may not return
-the same results as fitting a model on data that has been standardized with
-\code{standardize()}; \code{standardize_parameters()} used the data used by the model
-fitting function, which might not be same data if there are missing values.
-see the \code{remove_na} argument in \code{standardize()}.
-}
-\item \strong{posthoc}: Post-hoc standardization of the parameters, aiming at
-emulating the results obtained by ""refit"" without refitting the model. The
-coefficients are divided by the standard deviation (or MAD if \code{robust}) of
-the outcome (which becomes their expression 'unit'). Then, the coefficients
-related to numeric variables are additionally multiplied by the standard
-deviation (or MAD if \code{robust}) of the related terms, so that they correspond
-to changes of 1 SD of the predictor (e.g., ""A change in 1 SD of \code{x} is
-related to a change of 0.24 of the SD of \code{y}). This does not apply to binary
-variables or factors, so the coefficients are still related to changes in
-levels. This method is not accurate and tend to give aberrant results when
-interactions are specified.
-\item \strong{basic}: This method is similar to \code{method = ""posthoc""}, but treats all
-variables as continuous: it also scales the coefficient by the standard
-deviation of model's matrix' parameter of factors levels (transformed to
-integers) or binary predictors. Although being inappropriate for these cases,
-this method is the one implemented by default in other software packages,
-such as \code{\link[lm.beta:lm.beta]{lm.beta::lm.beta()}}.
-\item \strong{smart} (Standardization of Model's parameters with Adjustment,
-Reconnaissance and Transformation - \emph{experimental}): Similar to \code{method = ""posthoc""} in that it does not involve model refitting. The difference is
-that the SD (or MAD if \code{robust}) of the response is computed on the relevant
-section of the data. For instance, if a factor with 3 levels A (the
-intercept), B and C is entered as a predictor, the effect corresponding to B
-vs. A will be scaled by the variance of the response at the intercept only.
-As a results, the coefficients for effects of factors are similar to a Glass'
-delta.
-\item \strong{pseudo} (\emph{for 2-level (G)LMMs only}): In this (post-hoc) method, the
-response and the predictor are standardized based on the level of prediction
-(levels are detected with \code{\link[performance:check_heterogeneity_bias]{performance::check_heterogeneity_bias()}}): Predictors
-are standardized based on their SD at level of prediction (see also
-\code{\link[datawizard:demean]{datawizard::demean()}}); The outcome (in linear LMMs) is standardized based
-on a fitted random-intercept-model, where \code{sqrt(random-intercept-variance)}
-is used for level 2 predictors, and \code{sqrt(residual-variance)} is used for
-level 1 predictors (Hoffman 2015, page 342). A warning is given when a
-within-group varialbe is found to have access between-group variance.
-}
-}
-
-\section{Transformed Variables}{
-When the model's formula contains transformations (e.g. \code{y ~ exp(X)}) \code{method = ""refit""} will give different results compared to \code{method = ""basic""}
-(\code{""posthoc""} and \code{""smart""} do not support such transformations): While
-\code{""refit""} standardizes the data \emph{prior} to the transformation (e.g.
-equivalent to \code{exp(scale(X))}), the \code{""basic""} method standardizes the
-transformed data (e.g. equivalent to \code{scale(exp(X))}).
-\cr\cr
-See the \emph{Transformed Variables} section in \code{\link[=standardize.default]{standardize.default()}} for more
-details on how different transformations are dealt with when \code{method = ""refit""}.
-}
-
-\section{Confidence Intervals}{
-The returned confidence intervals are re-scaled versions of the
-unstandardized confidence intervals, and not ""true"" confidence intervals of
-the standardized coefficients (cf. Jones & Waller, 2015).
-}
-
-\section{Generalized Linear Models}{
-Standardization for generalized linear models (GLM, GLMM, etc) is done only
-with respect to the predictors (while the outcome remains as-is,
-unstandardized) - maintaining the interpretability of the coefficients (e.g.,
-in a binomial model: the exponent of the standardized parameter is the OR of
-a change of 1 SD in the predictor, etc.)
-}
-
-\section{Dealing with Factors}{
-\code{standardize(model)} or \code{standardize_parameters(model, method = ""refit"")} do
-\emph{not} standardize categorical predictors (i.e. factors) / their
-dummy-variables, which may be a different behaviour compared to other R
-packages (such as \pkg{lm.beta}) or other software packages (like SPSS). To
-mimic such behaviours, either use \code{standardize_parameters(model, method = ""basic"")} to obtain post-hoc standardized parameters, or standardize the data
-with \code{datawizard::standardize(data, force = TRUE)} \emph{before} fitting the
-model.
-}
-
-\examples{
-library(effectsize)
-
-model <- lm(len ~ supp * dose, data = ToothGrowth)
-standardize_parameters(model, method = ""refit"")
-\donttest{
-standardize_parameters(model, method = ""posthoc"")
-standardize_parameters(model, method = ""smart"")
-standardize_parameters(model, method = ""basic"")
-
-# Robust and 2 SD
-standardize_parameters(model, robust = TRUE)
-standardize_parameters(model, two_sd = TRUE)
-
-
-model <- glm(am ~ cyl * mpg, data = mtcars, family = ""binomial"")
-standardize_parameters(model, method = ""refit"")
-standardize_parameters(model, method = ""posthoc"")
-standardize_parameters(model, method = ""basic"", exponentiate = TRUE)
-}
-
-
-\dontshow{if (require(""lme4"")) (if (getRversion() >= ""3.4"") withAutoprint else force)(\{ # examplesIf}
-\donttest{
-m <- lme4::lmer(mpg ~ cyl + am + vs + (1 | cyl), mtcars)
-standardize_parameters(m, method = ""pseudo"", ci_method = ""satterthwaite"")
-}
-
-\dontshow{\}) # examplesIf}
-\dontshow{if (require(""rstanarm"")) (if (getRversion() >= ""3.4"") withAutoprint else force)(\{ # examplesIf}
-\dontrun{
-model <- stanarm::stan_glm(rating ~ critical + privileges, data = attitude, refresh = 0)
-standardize_posteriors(model, method = ""refit"")
-standardize_posteriors(model, method = ""posthoc"")
-standardize_posteriors(model, method = ""smart"")
-head(standardize_posteriors(model, method = ""basic""))
-}
-\dontshow{\}) # examplesIf}
-}
-\references{
-\itemize{
-\item Hoffman, L. (2015). Longitudinal analysis: Modeling within-person fluctuation and change. Routledge.
-\item Jones, J. A., & Waller, N. G. (2015). The normal-theory and asymptotic distribution-free (ADF) covariance matrix of standardized regression coefficients: theoretical extensions and finite sample behavior. Psychometrika, 80(2), 365-378.
-\item Neter, J., Wasserman, W., & Kutner, M. H. (1989). Applied linear regression models.
-\item Gelman, A. (2008). Scaling regression inputs by dividing by two standard deviations. Statistics in medicine, 27(15), 2865-2873.
-}
-}
-\seealso{
-Other standardize: 
-\code{\link{standardize.default}()},
-\code{\link{standardize_info}()}
-
-Other effect size indices: 
-\code{\link{cles}()},
-\code{\link{cohens_d}()},
-\code{\link{effectsize.BFBayesFactor}()},
-\code{\link{eta_squared}()},
-\code{\link{phi}()},
-\code{\link{rank_biserial}()}
-}
-\concept{effect size indices}
-\concept{standardize}

---FILE: tests/testthat/test-standardize_models.R---
@@ -1,279 +0,0 @@
-if (require(""testthat"") && require(""effectsize"")) {
-  # standardize.lm ----------------------------------------------------------
-  test_that(""standardize.lm"", {
-    iris2 <- na.omit(iris)
-    iris_z <- standardize(iris2)
-
-    m0 <- lm(Sepal.Length ~ Species * Petal.Width, data = iris_z)
-    m1 <- lm(Sepal.Length ~ Species * Petal.Width, data = iris2)
-    model <- standardize(m1)
-    expect_equal(coef(m0), coef(model))
-  })
-
-  test_that(""standardize, mlm"", {
-    m <- lm(cbind(mpg, hp) ~ cyl + am, data = mtcars)
-    m2 <- lm(scale(cbind(mpg, hp)) ~ scale(cyl) + scale(am), data = mtcars)
-
-    mz <- standardize(m)
-    expect_equal(coef(mz), coef(m2), ignore_attr = TRUE)
-  })
-
-  test_that(""standardize | errors"", {
-    my_lm_external_formula <- function(.dat, predicted, predictor){
-      my_formula <- as.formula(paste0(predicted, ""~"", predictor))
-      lm(formula = my_formula, data = .dat)
-    }
-
-    m <- my_lm_external_formula(mtcars, ""mpg"", ""am"")
-    ers <- capture_error(standardize(m))
-    expect_match(as.character(ers), ""Try instead to standardize the data"",
-                 fixed = TRUE)
-
-    skip_if_not_installed(""biglm"")
-    mod <- biglm::biglm(mpg ~ hp, mtcars)
-    expect_error(standardize(mod), ""not possible"")
-  })
-
-
-  # Transformations ---------------------------------------------------------
-  test_that(""transformations"", {
-    # deal with log / sqrt terms
-    expect_message(standardize(lm(mpg ~ sqrt(cyl) + log(hp), mtcars)))
-    expect_message(standardize(lm(mpg ~ sqrt(cyl), mtcars)))
-    expect_message(standardize(lm(mpg ~ log(hp), mtcars)))
-
-    # difference between stand-methods:
-    mt <- mtcars
-    mt$hp_100 <- mt$hp / 100
-    fit_exp <- lm(mpg ~ exp(hp_100), mt)
-    fit_scale1 <- lm(scale(mpg) ~ exp(scale(hp_100)), mt)
-    fit_scale2 <- lm(scale(mpg) ~ scale(exp(hp_100)), mt)
-    expect_equal(
-      standardize_parameters(fit_exp, method = ""refit"")[2, 2],
-      unname(coef(fit_scale1)[2])
-    )
-
-    expect_equal(
-      standardize_parameters(fit_exp, method = ""basic"")[2, 2],
-      unname(coef(fit_scale2)[2])
-    )
-
-    skip_if_not_installed(""insight"", minimum_version = ""0.10.0"")
-    d <- data.frame(
-      time = as.factor(c(1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5)),
-      group = c(1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2),
-      sum = c(0, 5, 10, 15, 20, 0, 20, 25, 45, 50, 0, 5, 10, 15, 20, 0, 20, 25, 45, 50, 0, 5, 10, 15, 20, 0, 20, 25, 45, 50)
-    )
-    m <- lm(log(sum + 1) ~ as.numeric(time) * group, data = d)
-
-
-    expect_message(out <- standardize(m))
-    expect_equal(coef(m), c(
-      `(Intercept)` = -0.4575, `as.numeric(time)` = 0.5492, group = 0.3379,
-      `as.numeric(time):group` = 0.15779
-    ), tolerance = 0.01)
-  })
-
-
-
-
-
-  # W/ weights --------------------------------------------------------------
-  test_that(""weights"", {
-    expect_warning(standardize(mtcars, weights = ""xx""))
-
-    m <- lm(mpg ~ wt + hp, weights = cyl, mtcars)
-
-    sm <- standardize(m, weights = TRUE)
-    sm_data <- insight::get_data(sm)
-    sm_data2 <- standardize(mtcars, select = c(""mpg"", ""wt"", ""hp""), weights = ""cyl"")
-    expect_equal(sm_data[, c(""mpg"", ""wt"", ""hp"")], sm_data2[, c(""mpg"", ""wt"", ""hp"")])
-
-    expect_error(standardize(m, weights = TRUE, robust = TRUE), NA)
-
-    # no weights in stding
-    sm_xw <- standardize(m, weights = FALSE)
-    sm_data_xw <- insight::get_data(sm_xw)
-    expect_false(isTRUE(all.equal(coef(sm)[-1], coef(sm_xw)[-1])))
-
-    # refit and posthoc should give same results
-    stdREFIT <- standardize_parameters(m, method = ""refit"")
-    expect_equal(
-      stdREFIT[[2]],
-      standardize_parameters(m, method = ""posthoc"")[[2]]
-    )
-
-    expect_equal(
-      stdREFIT[[2]],
-      standardize_parameters(m, method = ""basic"")[[2]]
-    )
-  })
-
-
-  # weights + missing data --------------------------------------------------
-  test_that(""weights + NA"", {
-    set.seed(1234)
-    data(iris)
-
-    # data setup
-    iris$weight_me <- runif(nrow(iris))
-    iris$Sepal.Length[sample(nrow(iris), size = 10)] <- NA
-    iris$weight_me[sample(nrow(iris), size = 10)] <- NA
-
-    # standardize 2nd data set
-    iris2 <- standardize(iris,
-      select = c(""Sepal.Length"", ""Petal.Width""),
-      remove_na = ""all""
-    )
-    iris3 <- standardize(iris,
-      select = c(""Sepal.Length"", ""Petal.Width""),
-      weights = ""weight_me"",
-      remove_na = ""selected""
-    )
-
-
-
-    m1 <- lm(Sepal.Length ~ Species + Petal.Width, data = iris, weights = weight_me)
-
-
-    # weights, missing data, but data isn't weight-stdized
-    m2 <- lm(Sepal.Length ~ Species + Petal.Width, data = iris2, weights = weight_me)
-    sm2 <- standardize(m1, weights = FALSE)
-    expect_equal(coef(m2), coef(sm2))
-
-    # weights, missing data, and data is weight-stdized
-    m3 <- lm(Sepal.Length ~ Species + Petal.Width, data = iris3, weights = weight_me)
-    sm3 <- standardize(m1, weights = TRUE)
-    expect_equal(coef(m3), coef(sm3))
-  })
-
-
-  # weights + missing data Â´+ na.action = na.exclude --------------------------------------------------
-  test_that(""weights + NA + na.exclude"", {
-    set.seed(1234)
-    data(iris)
-
-    # data setup
-    iris$weight_me <- runif(nrow(iris))
-    iris$Sepal.Length[sample(nrow(iris), size = 25)] <- NA
-    iris$weight_me[sample(nrow(iris), size = 15)] <- NA
-
-    m1 <- lm(Sepal.Length ~ Species + Petal.Width, data = iris, weights = weight_me, na.action = na.exclude)
-    m2 <- lm(Sepal.Length ~ Species + Petal.Width, data = iris, weights = weight_me)
-
-    expect_equal(coef(standardize(m2)), coef(standardize(m1)), tolerance = 1e-3)
-    expect_equal(standardize_parameters(m1, method = ""basic"")[[2]],
-      standardize_parameters(m2, method = ""basic"")[[2]],
-      tolerance = 1e-3
-    )
-  })
-
-  # subset ------------------
-  test_that(""fail with subset"", {
-    data(""mtcars"")
-
-    mod1 <- lm(mpg ~ hp, data = mtcars,
-               subset = cyl > 4)
-
-    expect_error(standardise(mod1), regexp = ""subset"")
-  })
-
-
-  # don't standardize non-Gaussian response ------------------------------------
-  test_that(""standardize non-Gaussian response"", {
-    skip_on_cran()
-    skip_if_not_installed(""lme4"")
-    set.seed(1234)
-    data(sleepstudy, package = ""lme4"")
-
-    m1 <- glm(Reaction ~ Days, family = Gamma(), data = sleepstudy)
-    m2 <- glm(Reaction ~ Days, family = Gamma(link = ""identity""), data = sleepstudy)
-    m3 <- glm(Reaction ~ Days, family = inverse.gaussian(), data = sleepstudy)
-
-    expect_equal(coef(standardize(m1)), c(`(Intercept)` = 0.00338, Days = -0.00034), tolerance = 1e-2)
-    expect_equal(coef(standardize(m2)), c(`(Intercept)` = 298.48571, Days = 29.70754), tolerance = 1e-3)
-    expect_equal(coef(standardize(m3)), c(`(Intercept)` = 1e-05, Days = 0), tolerance = 1e-3)
-  })
-
-
-  # variables evaluated in the environment $$$ ------------------------------
-  test_that(""variables evaluated in the environment"", {
-    m <- lm(mtcars$mpg ~ mtcars$cyl + am, data = mtcars)
-    w <- capture_warnings(standardize(m))
-    expect_true(any(grepl(""mtcars$mpg"", w, fixed = TRUE)))
-
-
-    skip_if(packageVersion(""base"") == package_version(3.4))
-    ## Note:
-    # No idea why this is suddenly not giving a warning on older R versions.
-    m <- lm(mtcars$mpg ~ mtcars$cyl + mtcars$am, data = mtcars)
-    warns <- capture_warnings(standardize(m))
-    expect_true(any(grepl(""mtcars$mpg"", warns, fixed = TRUE)))
-    expect_true(any(grepl(""No variables"", warns, fixed = TRUE)))
-  })
-
-
-  # mediation models --------------------------------------------------------
-  test_that(""standardize mediation"", {
-    skip_on_cran()
-    skip_if_not_installed(""mediation"")
-    set.seed(444)
-    data(jobs, package = ""mediation"")
-    jobs$econ_hard <- jobs$econ_hard * 20
-    b.int <- lm(job_seek ~ treat * age + econ_hard + sex, data = jobs)
-    d.int <- lm(depress2 ~ treat * job_seek * age + econ_hard + sex, data = jobs)
-
-    med1 <- mediation::mediate(b.int, d.int, sims = 200, treat = ""treat"", mediator = ""job_seek"")
-    med2 <- mediation::mediate(b.int, d.int,
-      sims = 200, treat = ""treat"", mediator = ""job_seek"",
-      covariates = list(age = mean(jobs$age))
-    )
-
-    out1 <- summary(standardize(med1))
-    expect_message(out2 <- summary(standardize(med2)))
-    expect_equal(unlist(out1[c(""d0"", ""d1"", ""z0"", ""z1"", ""n0"", ""n1"", ""tau.coef"")]),
-      unlist(out2[c(""d0"", ""d1"", ""z0"", ""z1"", ""n0"", ""n1"", ""tau.coef"")]),
-      tolerance = 0.1
-    )
-
-    med0 <- mediation::mediate(standardize(b.int), standardize(d.int), sims = 200, treat = ""treat"", mediator = ""job_seek"")
-    out0 <- summary(med0)
-    medz <- standardize(mediation::mediate(b.int, d.int, sims = 200, treat = ""treat"", mediator = ""job_seek""))
-    outz <- summary(medz)
-    expect_equal(unlist(out0[c(""d0"", ""d1"", ""z0"", ""z1"", ""n0"", ""n1"", ""tau.coef"")]),
-      unlist(outz[c(""d0"", ""d1"", ""z0"", ""z1"", ""n0"", ""n1"", ""tau.coef"")]),
-      tolerance = 0.1
-    )
-  })
-
-  # Offsets -----------------------------------------------------------------
-
-  test_that(""offsets"", {
-    m <- lm(mpg ~ hp + offset(wt), data = mtcars)
-
-    expect_warning(mz1 <- standardize(m))
-    expect_warning(mz2 <- standardize(m, two_sd = TRUE))
-    expect_equal(c(1, 2) * coef(mz1), coef(mz2))
-
-
-    m <- glm(cyl ~ hp + offset(wt), family = poisson(), data = mtcars)
-    expect_warning(mz <- standardize(m), regexp = NA)
-
-    par1 <- parameters::model_parameters(mz)
-    par2 <- standardize_parameters(m, method = ""basic"")
-    expect_equal(par2[2,2], par1[2,2], tolerance = 0.05)
-  })
-
-
-  # BRMS --------------------------------------------------------------------
-
-  test_that(""brms"", {
-    skip_on_cran()
-    skip_if_not_installed(""brms"")
-
-    mod <- brms::brm(mpg ~ hp, data = mtcars,
-                     refresh = 0, chains = 1)
-
-    expect_error(standardize(mod), regexp = NA)
-  })
-}

---FILE: tests/testthat/test-standardize_parameters.R---
@@ -1,509 +0,0 @@
-if (require(""testthat"") && require(""effectsize"")) {
-  data(""iris"")
-  df <- iris
-
-  # simple ------------------------------------------------------------------
-  test_that(""standardize_parameters (simple)"", {
-    r <- as.numeric(cor.test(df$Sepal.Length, df$Petal.Length)$estimate)
-
-    model <- lm(Sepal.Length ~ Petal.Length, data = df)
-    es <- standardize_parameters(model)
-    expect_equal(es[2, 2], r, tolerance = 0.01)
-
-
-    expect_error(standardize_parameters(model, robust = TRUE), NA)
-  })
-
-  # Robust ------------------------------------------------------------------
-  test_that(""Robust post hoc"", {
-    model <- lm(mpg ~ hp, weights = gear, data = mtcars)
-    expect_error(standardize_parameters(model, method = ""basic"", robust = TRUE), NA)
-    expect_error(standardize_parameters(model, method = ""basic"", robust = TRUE, two_sd = TRUE), NA)
-
-    model <- lm(mpg ~ hp, data = mtcars)
-    expect_error(standardize_parameters(model, method = ""basic"", robust = TRUE), NA)
-    expect_error(standardize_parameters(model, method = ""basic"", robust = TRUE, two_sd = TRUE), NA)
-  })
-
-
-  # model_parameters -------------------------------
-  test_that(""standardize_parameters (model_parameters)"", {
-    skip_on_cran()
-    model <<- lm(mpg ~ cyl + am, data = mtcars)
-    mp <<- parameters::model_parameters(model, effects = ""fixed"")
-
-    s1 <- standardize_parameters(model, method = ""basic"")
-    s2 <- standardize_parameters(mp, method = ""basic"")
-
-    expect_equal(s1$Parameter, s2$Parameter)
-    expect_equal(s1$Std_Coefficient, s2$Std_Coefficient)
-    expect_equal(s1$CI_low, s2$CI_low)
-    expect_equal(s1$CI_high, s2$CI_high)
-
-    mp_exp <<- parameters::model_parameters(model, exponentiate = TRUE, effects = ""fixed"")
-    se1 <- standardize_parameters(model, method = ""basic"", exponentiate = TRUE)
-    se2 <- standardize_parameters(mp_exp, method = ""basic"", exponentiate = TRUE)
-
-    expect_equal(se1$Parameter, se2$Parameter)
-    expect_equal(se1$Std_Coefficient, se2$Std_Coefficient)
-    expect_equal(se1$CI_low, se2$CI_low)
-    expect_equal(se1$CI_high, se2$CI_high)
-  })
-
-  # bootstrap_model ---------------------------------------------------------
-
-  test_that(""standardize_parameters (bootstrap_model)"", {
-    skip_on_cran()
-    skip_if_not_installed(""boot"")
-    m <- lm(mpg ~ factor(cyl) + hp, mtcars)
-
-    set.seed(1)
-    bm_draws <- parameters::bootstrap_model(m, iterations = 599)
-    set.seed(1)
-    bm_tab <- parameters::bootstrap_parameters(m, iterations = 599)
-
-    out_true <- standardize_parameters(m, method = ""basic"")
-    out_boot1 <- standardize_parameters(bm_draws, method = ""basic"")
-    out_boot2 <- standardize_parameters(bm_tab, method = ""basic"")
-
-    expect_equal(out_boot1$Std_Coefficient, out_true$Std_Coefficient,
-      tolerance = 0.05
-    )
-    expect_equal(out_boot1, out_boot2, ignore_attr = TRUE)
-    expect_error(standardize_parameters(bm_draws, method = ""refit""))
-    expect_error(standardize_parameters(bm_tab, method = ""refit""))
-  })
-
-
-
-  # lm with ci -----------------------------------
-  test_that(""standardize_parameters (lm with ci)"", {
-    data(""iris"")
-    model <- lm(Sepal.Length ~ Species + Petal.Width, data = iris)
-
-    expect_equal(
-      standardize_parameters(model, method = ""refit"")$Std_Coefficient,
-      c(0.044, -0.072, -0.060, 0.844),
-      tolerance = 0.01
-    )
-
-    expect_equal(
-      standardize_parameters(model, method = ""posthoc"")$Std_Coefficient,
-      c(0, -0.072, -0.060, 0.844),
-      tolerance = 0.01
-    )
-
-    expect_equal(
-      standardize_parameters(model, method = ""smart"")$Std_Coefficient,
-      c(0, -0.170, -0.142, 0.844),
-      tolerance = 0.01
-    )
-
-    z_basic <- standardize_parameters(model, method = ""basic"")
-
-    expect_equal(
-      z_basic$Std_Coefficient,
-      c(0, -0.034, -0.028, 0.844),
-      tolerance = 0.01
-    )
-
-    ## CI
-    expect_equal(
-      z_basic$CI_low,
-      c(0, -0.294, -0.433, 0.491),
-      tolerance = 0.01
-    )
-
-    expect_equal(
-      z_basic$CI_high,
-      c(0, 0.225, 0.375, 1.196),
-      tolerance = 0.01
-    )
-
-    z_basic.0.80 <- standardize_parameters(model, ci = 0.8, method = ""basic"")
-    expect_equal(
-      z_basic.0.80$CI_low,
-      c(0, -0.203, -0.292, 0.614),
-      tolerance = 0.01
-    )
-
-    expect_equal(
-      z_basic.0.80$CI_high,
-      c(0, 0.135, 0.234, 1.073),
-      tolerance = 0.01
-    )
-
-    data(""mtcars"")
-    m0 <- lm(mpg ~ cyl + factor(am), mtcars)
-    expect_equal(
-      standardize_parameters(m0, method = ""refit"")[[2]][-1],
-      standardize_parameters(m0, method = ""smart"")[[2]][-1],
-      tolerance = 0.01
-    )
-    expect_equal(
-      standardize_parameters(m0, method = ""refit"", two_sd = TRUE)[[2]][-1],
-      standardize_parameters(m0, method = ""smart"", two_sd = TRUE)[[2]][-1],
-      tolerance = 0.01
-    )
-  })
-
-
-  # aov ---------------------------------------------------------------------
-  test_that(""standardize_parameters (aov)"", {
-    data <- iris
-
-    data$Cat1 <- rep(c(""A"", ""B""), length.out = nrow(data))
-
-    m_aov <- aov(Sepal.Length ~ Species * Cat1, data = data)
-    m_lm <- lm(Sepal.Length ~ Species * Cat1, data = data)
-
-    expect_equal(standardize_parameters(m_aov),
-      standardize_parameters(m_lm),
-      ignore_attr = TRUE
-    )
-  })
-
-
-
-  # with function interactions"" -------------------
-  test_that(""standardize_parameters (with functions /  interactions)"", {
-    skip_on_cran()
-    X <- scale(rnorm(100), T, F)
-    Z <- scale(rnorm(100), T, F)
-    Y <- scale(Z + X * Z + rnorm(100), T, F)
-
-    m1 <- lm(Y ~ X * Z)
-    m2 <- lm(Y ~ X * scale(Z))
-    m3 <- lm(Y ~ scale(X) * Z)
-    m4 <- lm(Y ~ scale(X) * scale(Z))
-
-    expect_equal(
-      standardize_parameters(m1, method = ""basic"")$Std_Coefficient,
-      standardize_parameters(m2, method = ""basic"")$Std_Coefficient
-    )
-    expect_equal(
-      standardize_parameters(m1, method = ""basic"")$Std_Coefficient,
-      standardize_parameters(m3, method = ""basic"")$Std_Coefficient
-    )
-    # expect_equal(
-    #   standardize_parameters(m1, method = ""basic"")$Std_Coefficient,
-    #   standardize_parameters(m4, method = ""basic"")$Std_Coefficient
-    # )
-
-
-    # transformed resp or pred should not affect
-    mtcars$cyl_exp <- exp(mtcars$cyl)
-    mtcars$mpg_sqrt <- sqrt(mtcars$mpg)
-    m1 <- lm(exp(cyl) ~ am + sqrt(mpg), mtcars)
-    m2 <- lm(cyl_exp ~ am + mpg_sqrt, mtcars)
-
-    expect_message(stdX <- standardize_parameters(m1, method = ""refit""))
-    expect_false(isTRUE(all.equal(
-      stdX[[2]],
-      standardize_parameters(m2, method = ""refit"")[[2]]
-    )))
-    expect_equal(
-      standardize_parameters(m1, method = ""basic"")[[2]],
-      standardize_parameters(m2, method = ""basic"")[[2]]
-    )
-
-    # posthoc / smart don't support data transformation
-    expect_warning(standardize_parameters(m1, method = ""smart""))
-    expect_warning(standardize_parameters(m1, method = ""posthoc""))
-  })
-
-
-  # exponentiate ------------------------------------------------------------
-  test_that(""standardize_parameters (exponentiate)"", {
-    mod_b <- glm(am ~ mpg + cyl + hp,
-      data = mtcars,
-      family = poisson()
-    )
-    mod_refit <- standardize_parameters(mod_b, method = ""refit"", exponentiate = TRUE)
-
-    expect_equal(
-      mod_refit[[2]][-1],
-      standardize_parameters(mod_b, method = ""basic"", exponentiate = TRUE)[[2]][-1]
-    )
-    expect_equal(
-      mod_refit[[2]][-1],
-      standardize_parameters(mod_b, method = ""posthoc"", exponentiate = TRUE)[[2]][-1]
-    )
-    expect_equal(
-      mod_refit[[2]][-1],
-      exp(standardize_parameters(mod_b, method = ""basic"")[[2]])[-1]
-    )
-
-
-    mod_b <- glm(am ~ mpg + cyl,
-      data = mtcars,
-      family = binomial()
-    )
-    mod_refit <- standardize_parameters(mod_b, method = ""refit"", exponentiate = TRUE)
-
-    expect_equal(
-      mod_refit[[2]][-1],
-      standardize_parameters(mod_b, method = ""basic"", exponentiate = TRUE)[[2]][-1]
-    )
-    expect_equal(
-      mod_refit[[2]][-1],
-      standardize_parameters(mod_b, method = ""posthoc"", exponentiate = TRUE)[[2]][-1]
-    )
-    expect_equal(
-      mod_refit[[2]][-1],
-      exp(standardize_parameters(mod_b, method = ""basic"")[[2]])[-1]
-    )
-
-
-    mod_b <- glm(am ~ mpg + cyl + hp,
-      data = mtcars,
-      family = gaussian()
-    )
-    mod_refit <- standardize_parameters(mod_b, method = ""refit"", exponentiate = TRUE)
-
-    expect_equal(
-      mod_refit[[2]][-1],
-      standardize_parameters(mod_b, method = ""basic"", exponentiate = TRUE)[[2]][-1]
-    )
-    expect_equal(
-      mod_refit[[2]][-1],
-      standardize_parameters(mod_b, method = ""posthoc"", exponentiate = TRUE)[[2]][-1]
-    )
-    expect_equal(
-      mod_refit[[2]][-1],
-      exp(standardize_parameters(mod_b, method = ""basic"")[[2]])[-1]
-    )
-  })
-
-
-  # Bayes ----------------------------------------
-  test_that(""standardize_parameters (Bayes)"", {
-    skip_on_cran()
-    skip_on_ci()
-    skip_if_not_installed(""rstanarm"")
-    set.seed(1234)
-    suppressWarnings(
-      model <- rstanarm::stan_glm(Sepal.Length ~ Species + Petal.Width,
-        data = iris,
-        iter = 500, refresh = 0
-      )
-    )
-
-    expect_equal(
-      suppressWarnings(standardize_parameters(model, method = ""refit"")$Std_Median[1:4]),
-      c(0.065, -0.094, -0.100, 0.862),
-      tolerance = 0.01
-    )
-
-    expect_equal(
-      suppressWarnings(standardize_parameters(model, method = ""posthoc"")$Std_Median[1:4]),
-      c(0, -0.058, -0.053, 0.838),
-      tolerance = 0.01
-    )
-
-    posts <- standardize_posteriors(model, method = ""posthoc"")
-    expect_equal(dim(posts), c(1000, 4))
-    expect_s3_class(posts, ""data.frame"")
-  })
-
-
-  # Pseudo - GLMM --------------------------------
-  test_that(""standardize_parameters (Pseudo - GLMM)"", {
-    skip_on_cran()
-    skip_if_not_installed(""lme4"")
-    set.seed(1)
-
-    dat <- data.frame(
-      X = rnorm(1000),
-      Z = rnorm(1000),
-      C = sample(letters[1:3], size = 1000, replace = TRUE),
-      ID = sort(rep(letters, length.out = 1000))
-    )
-    dat <- transform(dat, Y = X + Z + rnorm(1000))
-    dat <- cbind(dat, datawizard::demean(dat, c(""X"", ""Z""), ""ID""))
-
-
-    m <- lme4::lmer(Y ~ scale(X_within) * X_between + C + (scale(X_within) | ID),
-      data = dat
-    )
-
-    ## No robust methods... (yet)
-    expect_warning(standardize_parameters(m, method = ""pseudo"", robust = TRUE, verbose = FALSE), regexp = ""robust"")
-
-
-    ## Correctly identify within and between terms
-    dev_resp <- standardize_info(m, include_pseudo = TRUE)$Deviation_Response_Pseudo
-    expect_equal(insight::n_unique(dev_resp[c(2, 4, 5, 6)]), 1)
-    expect_true(dev_resp[2] != dev_resp[3])
-
-
-    ## Calc
-    b <- lme4::fixef(m)[-1]
-    mm <- model.matrix(m)[, -1]
-    SD_x <- numeric(ncol(mm))
-
-    SD_x[c(1, 3, 4, 5)] <- apply(mm[, c(1, 3, 4, 5)], 2, sd)
-    SD_x[2] <- sd(tapply(mm[, 2], dat$ID, mean))
-
-    m0 <- lme4::lmer(Y ~ 1 + (1 | ID), data = dat)
-    m0v <- insight::get_variance(m0)
-    SD_y <- c(sqrt(m0v$var.residual), sqrt(m0v$var.intercept))
-    SD_y <- SD_y[c(1, 2, 1, 1, 1)]
-
-    expect_equal(
-      data.frame(Deviation_Response_Pseudo = c(SD_y[2], SD_y), Deviation_Pseudo = c(0, SD_x)),
-      standardize_info(m, include_pseudo = TRUE)[, c(""Deviation_Response_Pseudo"", ""Deviation_Pseudo"")]
-    )
-    expect_equal(
-      standardize_parameters(m, method = ""pseudo"")$Std_Coefficient[-1],
-      unname(b * SD_x / SD_y)
-    )
-
-
-    ## scaling should not affect
-    m1 <- lme4::lmer(Y ~ X_within + X_between + C + (X_within | ID),
-      data = dat
-    )
-    m2 <- lme4::lmer(scale(Y) ~ X_within + X_between + C + (X_within | ID),
-      data = dat
-    )
-    m3 <- lme4::lmer(Y ~ scale(X_within) + X_between + C + (scale(X_within) | ID),
-      data = dat
-    )
-    m4 <- lme4::lmer(Y ~ X_within + scale(X_between) + C + (X_within | ID),
-      data = dat
-    )
-
-    std1 <- standardize_parameters(m1, method = ""pseudo"")
-    expect_equal(std1$Std_Coefficient,
-      standardize_parameters(m2, method = ""pseudo"")$Std_Coefficient,
-      tolerance = 0.001
-    )
-    expect_equal(std1$Std_Coefficient,
-      standardize_parameters(m3, method = ""pseudo"")$Std_Coefficient,
-      tolerance = 0.001
-    )
-    expect_equal(std1$Std_Coefficient,
-      standardize_parameters(m4, method = ""pseudo"")$Std_Coefficient,
-      tolerance = 0.001
-    )
-
-
-
-    ## Give warning for within that is also between
-    mW <- lme4::lmer(Y ~ X_between + Z_within + C + (1 | ID), dat)
-    mM <- lme4::lmer(Y ~ X + Z + C + (1 | ID), dat)
-
-    expect_warning(standardize_parameters(mW, method = ""pseudo""), regexp = NA)
-    expect_warning(standardize_parameters(mM, method = ""pseudo""), regexp = ""within-group"")
-  })
-
-
-  # ZI models ---------------------------------------------------------------
-  test_that(""standardize_parameters (pscl)"", {
-    skip_on_cran()
-    skip_if_not_installed(""pscl"")
-    data(""bioChemists"", package = ""pscl"")
-
-    m <- pscl::zeroinfl(art ~ fem + mar + kid5 + ment | kid5 + phd, data = bioChemists)
-
-    mp <- parameters::model_parameters(m, effects = ""fixed"")
-    sm1 <- standardize_parameters(m, method = ""refit"")
-    expect_warning(sm2 <- standardize_parameters(m, method = ""posthoc""))
-    suppressWarnings({
-      sm3 <- standardize_parameters(m, method = ""basic"")
-      sm4 <- standardize_parameters(m, method = ""smart"")
-    })
-
-    # post hoc does it right (bar intercept)
-    expect_equal(sm1$Std_Coefficient[-c(1, 6)],
-      sm2$Std_Coefficient[-c(1, 6)],
-      tolerance = 0.01
-    )
-
-    # basic / smart miss the ZI
-    expect_equal(mp$Coefficient[6:8],
-      sm3$Std_Coefficient[6:8],
-      tolerance = 0.01
-    )
-    expect_equal(mp$Coefficient[7:8],
-      sm4$Std_Coefficient[7:8],
-      tolerance = 0.1
-    )
-
-    # get count numerics al right
-    expect_equal(sm1$Std_Coefficient[4:5],
-      sm3$Std_Coefficient[4:5],
-      tolerance = 0.01
-    )
-    expect_equal(sm1$Std_Coefficient[4:5],
-      sm4$Std_Coefficient[4:5],
-      tolerance = 0.01
-    )
-  })
-}
-
-test_that(""include_response | (g)lm"", {
-  # lm ---
-  data(iris)
-  iris$Sepal.Length <- iris$Sepal.Length * 5
-  m <- lm(Sepal.Length ~ Petal.Length + Petal.Width, data = iris)
-
-  m_z <- standardize(m, include_response = FALSE)
-  par_z0 <- standardize_parameters(m, method = ""basic"")
-  par_z1 <- standardize_parameters(m, include_response = FALSE)
-  par_z2 <- standardize_parameters(m, method = ""basic"", include_response = FALSE)
-
-  expect_equal(coef(m_z), par_z1$Std_Coefficient, ignore_attr = TRUE)
-  expect_equal(par_z1$Std_Coefficient[-1], par_z2$Std_Coefficient[-1])
-  expect_equal(par_z0$Std_Coefficient * sd(iris$Sepal.Length), par_z2$Std_Coefficient)
-
-  # glm ---
-  m <- glm(am ~ mpg, mtcars, family = binomial())
-  expect_equal(
-    standardize_parameters(m),
-    standardize_parameters(m, include_response = FALSE),
-    ignore_attr = TRUE
-  )
-})
-
-
-test_that(""include_response | parameters"", {
-  skip_if_not_installed(""parameters"")
-
-  data(iris)
-  iris$Sepal.Length <- iris$Sepal.Length * 5
-  m <<- lm(Sepal.Length ~ Petal.Length + Petal.Width, data = iris)
-
-  # parameters ---
-  pars <- parameters::model_parameters(m, effects = ""fixed"")
-  pars_z0 <- standardize_parameters(pars, method = ""basic"")
-  pars_z1 <- standardize_parameters(pars, method = ""basic"", include_response = FALSE)
-  expect_equal(pars_z0$Std_Coefficient[-1] * sd(iris$Sepal.Length), pars_z1$Std_Coefficient[-1])
-
-  # boot ---
-  skip_if_not_installed(""boot"")
-  pars <- parameters::bootstrap_parameters(m)
-  pars_z0 <- standardize_parameters(pars, method = ""basic"")
-  pars_z1 <- standardize_parameters(pars, method = ""basic"", include_response = FALSE)
-  expect_equal(pars_z0$Std_Coefficient[-1] * sd(iris$Sepal.Length), pars_z1$Std_Coefficient[-1])
-})
-
-
-test_that(""include_response | bayes"", {
-  skip_if_not_installed(""rstanarm"")
-  skip_on_cran()
-
-  data(iris)
-  iris$Sepal.Length <- iris$Sepal.Length * 5
-  m <- rstanarm::stan_glm(Sepal.Length ~ Petal.Length + Petal.Width, data = iris, refresh = 0)
-
-  expect_warning(m_z <- standardize(m, include_response = FALSE))
-  expect_warning(par_z1 <- standardize_posteriors(m, include_response = FALSE))
-  par_z0 <- standardize_posteriors(m, method = ""basic"")
-  par_z2 <- standardize_posteriors(m, method = ""basic"", include_response = FALSE)
-
-  expect_equal(sapply(insight::get_parameters(m_z), mean), sapply(par_z1, mean), tolerance = 0.1)
-  expect_equal(sapply(par_z1, mean)[-1], sapply(par_z2, mean)[-1], tolerance = 0.1)
-  expect_equal(sapply(par_z0, mean) * sd(iris$Sepal.Length), sapply(par_z2, mean), tolerance = 0.1)
-})

---FILE: vignettes/effectsize.Rmd---
@@ -30,7 +30,7 @@ In both theoretical and applied research, it is often of interest to assess the
 
 **effectsize**'s functionality is in part comparable to packages like **lm.beta** [@behrendt2014lmbeta], **MOTE** [@buchanan2019MOTE], and **MBESS** [@kelley2020MBESS]. Yet, there are some notable differences, e.g.:
 
-- **lm.beta** provides standardized regression coefficients for linear models, based on post-hoc model matrix standardization. However, the functionality is available only for a limited number of models (models inheriting from the `lm` class), whereas **effectsize** provides support for many types of models, including (generalized) linear mixed models, Bayesian models, and more. Additionally, in additional to post-hoc model matrix standardization, **effectsize** offers other methods of standardization (see below).  
+<!-- - **lm.beta** provides standardized regression coefficients for linear models, based on post-hoc model matrix standardization. However, the functionality is available only for a limited number of models (models inheriting from the `lm` class), whereas **effectsize** provides support for many types of models, including (generalized) linear mixed models, Bayesian models, and more. Additionally, in additional to post-hoc model matrix standardization, **effectsize** offers other methods of standardization (see below).   -->
 - Both **MOTE** and **MBESS** provide functions for computing effect sizes such as Cohen's *d* and effect sizes for ANOVAs [@cohen1988statistical], and their confidence intervals. However, both require manual input of *F*- or *t*-statistics, *degrees of freedom*, and *sums of squares* for the computation the effect sizes, whereas **effectsize** can automatically extract this information from the provided models, thus allowing for better ease-of-use as well as reducing any potential for error.  
 <!-- - Finally, in **base R**, the function `scale()` can be used to standardize vectors, matrices and data frame, which can be used to standardize data prior to model fitting. The coefficients of a linear model fit on such data are in effect standardized regression coefficients. **effectsize** expands an this, allowing for robust standardization (using the median and the MAD, instead of the mean and SD), post-hoc parameter standardization, and more. -->
 
@@ -62,30 +62,30 @@ M <- rbind(c(150, 130, 35, 55),
 cramers_v(M)
 ```
 
-## Parameter and Model Standardization
+<!-- ## Parameter and Model Standardization -->
 
-Standardizing parameters (i.e., coefficients) can allow for their comparison within and between models, variables and studies. To this end, two functions are available: `standardize()`, which returns an updated model, re-fit with standardized data, and `standardize_parameters()`, which returns a table of standardized coefficients from a provided model [for a list of supported models, see the *insight* package; @luedecke2019insight].
+<!-- Standardizing parameters (i.e., coefficients) can allow for their comparison within and between models, variables and studies. To this end, two functions are available: `standardize()`, which returns an updated model, re-fit with standardized data, and `standardize_parameters()`, which returns a table of standardized coefficients from a provided model [for a list of supported models, see the *insight* package; @luedecke2019insight]. -->
 
-```{r}
-model <- lm(mpg ~ cyl * am, 
-            data = mtcars)
+<!-- ```{r} -->
+<!-- model <- lm(mpg ~ cyl * am,  -->
+<!--             data = mtcars) -->
 
-standardize(model)
+<!-- standardize(model) -->
 
-standardize_parameters(model)
-```
+<!-- standardize_parameters(model) -->
+<!-- ``` -->
 
-Standardized parameters can also be produced for generalized linear models (GLMs; where only the predictors are standardized):
+<!-- Standardized parameters can also be produced for generalized linear models (GLMs; where only the predictors are standardized): -->
 
-```{r}
-model <- glm(am ~ cyl + hp,
-             family = ""binomial"",
-             data = mtcars)
+<!-- ```{r} -->
+<!-- model <- glm(am ~ cyl + hp, -->
+<!--              family = ""binomial"", -->
+<!--              data = mtcars) -->
 
-standardize_parameters(model, exponentiate = TRUE)
-```
+<!-- standardize_parameters(model, exponentiate = TRUE) -->
+<!-- ``` -->
 
-`standardize_parameters()` provides several standardization methods, such as robust standardization, or *pseudo*-standardized coefficients for (generalized) linear mixed models [@hoffman2015longitudinal]. A full review of these methods can be found in the [*Parameter and Model Standardization* vignette](https://easystats.github.io/effectsize/articles/standardize_parameters.html).
+<!-- `standardize_parameters()` provides several standardization methods, such as robust standardization, or *pseudo*-standardized coefficients for (generalized) linear mixed models [@hoffman2015longitudinal]. A full review of these methods can be found in the [*Parameter and Model Standardization* vignette](https://easystats.github.io/effectsize/articles/standardize_parameters.html). -->
 
 ## Effect Sizes for ANOVAs
 

---FILE: vignettes/effectsize_API.Rmd---
@@ -219,21 +219,21 @@ omega_squared(mod)
 ```
 
 
-## Supporting Model Re-Fitting with Standardized Data
+<!-- ## Supporting Model Re-Fitting with Standardized Data -->
 
-`effectsize::standardize.default()` should support your model if you have methods for:
+<!-- `effectsize::standardize.default()` should support your model if you have methods for: -->
 
-1. `{insight}` functions.
-2. An `update()` method that can take the model and a data frame via the `data = ` argument.
+<!-- 1. `{insight}` functions. -->
+<!-- 2. An `update()` method that can take the model and a data frame via the `data = ` argument. -->
 
-Or you can make your own `standardize.my_class()` function, DIY-style (possibly using `datawizard::standardize.data.frame()` or `datawizard::standardize.numeric()`). This function should return a fiffed model of the same class as the input model.
+<!-- Or you can make your own `standardize.my_class()` function, DIY-style (possibly using `datawizard::standardize.data.frame()` or `datawizard::standardize.numeric()`). This function should return a fiffed model of the same class as the input model. -->
 
-## Supporting Standardized Parameters
+<!-- ## Supporting Standardized Parameters -->
 
-`standardize_parameters.default()` offers a few methods of parameter standardization:
+<!-- `standardize_parameters.default()` offers a few methods of parameter standardization: -->
 
-- For `method = ""refit""` all you need is to have `effectsize::standardize()` support (see above) as well as `parameters::model_parameters()`.  
-- ***API for post-hoc methods coming soon...***  
+<!-- - For `method = ""refit""` all you need is to have `effectsize::standardize()` support (see above) as well as `parameters::model_parameters()`.   -->
+<!-- - ***API for post-hoc methods coming soon...***   -->
 
 <!-- `standardize_parameters.default()` should support your model if it is already supported by `{parameters}` and `{insight}`. -->
 

---FILE: vignettes/standardize_parameters.Rmd---
@@ -1,553 +0,0 @@
----
-title: ""Parameter and Model Standardization""
-output: 
-  rmarkdown::html_vignette:
-    toc: true
-    fig_width: 10.08
-    fig_height: 6
-tags: [r, standardization, effect size, cohen d, standardized coefficients]
-vignette: >
-  %\VignetteIndexEntry{Parameter and Model Standardization}
-  \usepackage[utf8]{inputenc}
-  %\VignetteEngine{knitr::rmarkdown}
-editor_options: 
-  chunk_output_type: console
-bibliography: bibliography.bib
----
-
-```{r message=FALSE, warning=FALSE, include=FALSE}
-library(knitr)
-knitr::opts_chunk$set(comment = "">"",
-                      warning = FALSE,
-                      message = FALSE)
-options(digits = 2)
-options(knitr.kable.NA = '')
-
-pkgs <- c(""effectsize"", ""parameters"", ""correlation"")
-if (!all(sapply(pkgs, requireNamespace, quietly = TRUE))) {
-  knitr::opts_chunk$set(eval = FALSE)
-}
-
-set.seed(333)
-```
-
-<!-- centering and interactions! -->
-
-# Introduction
-
-Standardizing parameters (*i.e.*, coefficients) can allow for their comparison
-within and between models, variables and studies. Moreover, as it returns
-coefficients expressed in terms of **change of variance** (for instance,
-coefficients expressed in terms of SD of the response variable), it can allow
-for the usage of [effect size interpretation
-guidelines](https://easystats.github.io/effectsize/articles/interpret.html),
-such as Cohen's (1988) famous rules of thumb.
-
-However, standardizing a model's parameters should *not* be automatically and
-mindlessly done: for some research fields, particular variables or types of
-studies (*e.g.*, replications), it sometimes makes more sense to keep, use and
-interpret the original parameters, especially if they are well known or easily
-understood.
-
-Critically, **parameters standardization is not a trivial process**. Different
-techniques exist, that can lead to drastically different results. Thus, it is
-critical that the standardization method is explicitly documented and detailed.
-
-<!-- **`parameters` include different techniques of parameters
-standardization**, described below
-[@bring1994standardize;@menard2004six;@gelman2008scaling;@schielzeth2010simple;@menard2011standards].
--->
-
-## Standardizing Parameters of Simple Models
-
-### Standardized Associations
-
-```{r}
-library(effectsize)
-
-m <- lm(rating ~ complaints, data = attitude)
-
-standardize_parameters(m)
-```
-
-Standardizing the coefficient of this *simple* linear regression gives a value
-of `0.87`, but did you know that for a simple regression this is actually the
-**same as a correlation**? Thus, you can eventually apply some (*in*)famous
-interpretation guidelines (e.g., Cohen's rules of thumb).
-
-```{r}
-correlation::correlation(attitude, select = c(""rating"", ""complaints""))
-```
-
-### Standardized Differences
-
-How does it work in the case of differences, when **factors** are entered and
-differences between a given level and a reference level? You might have heard
-that it is similar to a **Cohen's *d***. Well, let's see.
-
-```{r include=FALSE}
-mtcars <- datasets::mtcars
-```
-
-```{r}
-# Select portion of data containing the two levels of interest
-mtcars$am <- factor(mtcars$am, labels = c(""Manual"", ""Automatic""))
-
-m <- lm(mpg ~ am, data = mtcars)
-standardize_parameters(m)
-```
-
-This linear model suggests that the *standardized* difference between *Manual*
-(the reference level - the model's intercept) and *Automatic* is of 1.20
-standard deviation of `mpg` (because the response variable was standardized,
-right?). Let's compute the **Cohen's *d*** between these two levels:
-
-```{r}
-cohens_d(mpg ~ am, data = mtcars) 
-```
-
-***It is larger!*** Why? How? Both differences should be expressed in units of
-SD! But which SDs? Different SDs!
-
-When looking at the difference between groups as a **slope**, the standardized
-parameter is the difference between the means in $SD_{mpg}$. That is, the
-*slope* between `Manual` and `Automatic` is a change of 1.20 $SD_{mpg}$s.
-
-However, when looking a the difference as a **distance between two populations**, Cohen's d is the distance between the means in units of [**pooled SDs**](https://easystats.github.io/effectsize/reference/sd_pooled.html). That
-is, the *distance* between `Manual` and `Automatic` is of 1.48 SDs of *each of
-the groups* (here assumed to be equal).
-
-In this simple model, the pooled SD is the residual SD, so we can also estimate
-Cohen's *d* as:
-
-```{r}
-coef(m)[2] / sigma(m)
-```
-
-And we can also get an approximation of Cohen's *d* by converting the
-$t$-statistic from the regression model via `t_to_d()`:
-
-```{r}
-parameters::model_parameters(m)
-
-t_to_d(4.11, df_error = 30)
-```
-
-It is also interesting to note that using the `smart` method (explained in
-detail below) when standardizing parameters will give you indices equivalent to
-**Glass' *delta***, which is a standardized difference expressed in terms of SD
-of the reference group.
-
-```{r}
-m <- lm(mpg ~ am, data = mtcars)
-
-standardize_parameters(m, method = ""smart"")
-
-glass_delta(mpg ~ am, data = mtcars)
-```
-
-***... So note that some standardized differences are different than others!
-:)***
-
-## Standardizing Parameters of Linear Models
-
-As mentioned above, standardization of parameters can also be used to compare
-among parameters within the same model. Essentially, what prevents us from
-normally being able to compare among different parameters is that their
-underlying variables are on different scales.[^But also as noted above, this is
-not always an issue. For example, when the variables scale is important for the
-interpretation of results, standardization might in fact hinder interpretation!]
-
-For example, in the following example, we use a liner regression model to
-predict a worker's salary (in Shmekels) from their age (years), seniority
-(years), overtime (`xtra_hours`) and how many compliments they give their boss
-(`n_comps`).
-
-Let us explore the different parameter standardization methods provided by
-`effectsize`.
-
-### Standardized Slopes are Not (Always) Correlations
-
-We saw that in simple linear models, the standardized slope is equal to the
-correlation between the outcome and predictor - does this hold for **multiple
-regression** as well? As in each effect in a regression model is ""adjusted"" for
-the other ones, we might expect coefficients to be somewhat alike to **partial
-correlations**. Let's first start by computing the partial correlation between
-numeric predictors and the outcome.
-
-```{r}
-data(""hardlyworking"", package = ""effectsize"")
-
-head(hardlyworking)
-
-correlation::correlation(
-  hardlyworking,
-  select = ""salary"",
-  select2 = c(""xtra_hours"", ""n_comps"", ""age"", ""seniority""),
-  partial = TRUE # get partial correlations
-) 
-```
-
-Let's compare these to the standardized slopes:
-
-```{r}
-mod <- lm(salary ~ xtra_hours + n_comps + age + seniority,
-          data = hardlyworking)
-
-standardize_parameters(mod)
-```
-
-They are quite different! It seems then that ***standardized slopes in multiple
-linear regressions are not the same a correlations or partial correlations***
-:(
-
-However, not all hope is lost yet - we can still try and recover the partial
-correlations from our model, in another way: by converting the *t*-statistics
-(and their degrees of freedom, *df*) into a partial correlation coefficient
-*r*.
-
-```{r}
-params <- parameters::model_parameters(mod)
-
-t_to_r(params$t[-1], df_error = params$df_error[-1])
-```
-
-Wow, the retrieved correlations coefficients from the regression model are
-**exactly** the same as the partial correlations we estimated above! So these
-""*r*"" effect sizes can also be used.
-
-### Methods of Standardizing Parameters
-
-Let's convert `age` into a 3-level factor:
-
-```{r}
-hardlyworking$age_g <- cut(hardlyworking$age,
-                           breaks = c(25,30,35,45))
-
-mod <- lm(salary ~ xtra_hours + n_comps + age_g + seniority,
-          data = hardlyworking)
-
-parameters::model_parameters(mod)
-```
-
-It seems like the best or most important predictor is `n_comps` as it has the
-coefficient. However, it is hard to compare among predictors, as they are on
-different scales. To address this issue, we must have all the predictors on the
-same scale - usually in the arbitrary unit of *standard deviations*.
-
-#### **`""refit""`**: Re-fitting the model with standardized data
-
-**This method is based on a complete model re-fit with a standardized version of
-data**. Hence, this method is equal to standardizing the variables *before*
-fitting the model. It is the ""purest"" and the most accurate [@neter1989applied],
-but it is also the most computationally costly and long (especially for heavy
-models such as Bayesian models, or complex mixed models). This method is
-particularly recommended for models that include interactions or transformations
-(e.g., exponentiation, log, polynomial or spline terms).
-
-```{r}
-standardize_parameters(mod, method = ""refit"")
-```
-
-`standardize_parameters` also has a `robust` argument (default to `FALSE`),
-which enables a **robust standardization of the data**, *i.e.*, based on the
-**median** and **MAD** instead of the **mean** and **SD**:
-
-```{r}
-standardize_parameters(mod, method = ""refit"", robust = TRUE)
-```
-
-Note that since `age_g` is a factor, it is not numerically standardized, and so
-it standardized parameter is still not directly comparable to those of numeric
-variables. To address this, we can set `two_sd = TRUE`, thereby scaling
-parameters on 2 SDs (or MADs) of the predictors [@gelman2008scaling].
-
-```{r}
-standardize_parameters(mod, method = ""refit"", two_sd = TRUE)
-```
-
-`effectsize` also comes with a helper function that returns the re-fit model,
-without summarizing it, which can then be used as the original model would:
-
-```{r}
-mod_z <- standardize(mod, two_sd = FALSE, robust = FALSE)
-mod_z
-
-parameters::model_parameters(mod_z)
-```
-
-#### **`""posthoc""`**: Refit without refitting
-
-Post-hoc standardization of the parameters aims at emulating the results
-obtained by `""refit""` without refitting the model. The coefficients are divided
-by the standard deviation (or MAD if `robust`) of the outcome (which becomes
-their expression 'unit'). Then, the coefficients related to numeric variables
-are additionally multiplied by the standard deviation (or MAD if `robust`) of
-the related terms, so that they correspond to changes of 1 SD of the predictor
-(e.g., ""A change in 1 SD of *x* is related to a change of 0.24 of the SD of
-*y*). This does not apply to binary variables or factors, so the coefficients
-are still related to changes in levels. This method is not accurate and tend to
-give aberrant results when interactions are specified.
-
-```{r}
-standardize_parameters(mod, method = ""posthoc"")
-```
-
-#### **`""smart""`**: Standardization of Model's parameters with Adjustment, Reconnaissance and Transformation
-
-> Experimental
-
-Similar to `method = ""posthoc""` in that it does not involve model refitting. The
-difference is that the SD of the response is computed on the relevant section of
-the data. For instance, if a factor with 3 levels A (the intercept), B and C is
-entered as a predictor, the effect corresponding to B vs. A will be scaled by
-the variance of the response at the intercept only. As a results, the
-coefficients for effects of factors are similar to a Glass' *delta*.
-
-```{r}
-standardize_parameters(mod, method = ""smart"")
-```
-
-#### **`""basic""`**: Raw scaling of the model frame
-
-This method is similar to `method = ""posthoc""`, but treats all variables as
-continuous: it scales the coefficient by the standard deviation of model's
-matrix' parameter of factors levels (transformed to integers) or binary
-predictors. Although it can be argued that this might be inappropriate for these
-cases, this method allows for easier importance judgment across all predictor
-type (numeric, factor, interactions...). It is also the type of standardization
-implemented by default in other software packages (also `lm.beta::lm.beta()`),
-and, such as can be used for reproducibility and replication purposes.
-
-```{r}
-standardize_parameters(mod, method = ""basic"")
-```
-
-### Standardizing Parameters In Mixed Models
-
-Linear mixed models (LMM/HLM/MLM) offer an additional conundrum to
-standardization - how does one even calculate the SDs of the various predictors?
-Or of the response - is it the deviations within each group? Or perhaps between
-them?
-
-The solution: standardize according to level of the predictor
-[@hoffman2015longitudinal, page 342]! Level 1 parameters are standardized
-according to variance *within* groups, while level 2 parameters are standardized
-according to variance *between* groups. The resulting standardized coefficient
-are also called *pseudo*-standardized coefficients.[^Note that like method
-`""basic""`, these are based on the model matrix.]
-
-```{r, eval=knitr::opts_chunk$get(""eval"") && require(lme4) && require(lmerTest), warning=FALSE}
-m <- lme4::lmer(Reaction ~ Days + (Days|Subject), data = lme4::sleepstudy)
-
-standardize_parameters(m, method = ""pseudo"", ci_method = ""satterthwaite"")
-
-# compare to:
-standardize_parameters(m, method = ""basic"", ci_method = ""satterthwaite"")
-```
-
-### Standardizing Parameters In Generalized Linear Models
-
-Unlike linear (/mixed) models, in generalized linear (/mixed) models (GLMs)
-there is *less* of a need for standardization. Why? Because in many GLMs the
-estimated coefficients are themselves measures of effect size, such as
-*odds-ratios* (OR) in logistic regression, or *incidence rate ratios* (IRR) in
-Poisson regressions. This is because in such model the outcome is **not** on an
-arbitrary scale - that is, the meaning of rates and probabilities are changed by
-arbitrary linear transformations.
-
-But still, some standardization is sometimes needed, for the predictors.
-Luckily, `standardize_parameters()` (and `standardize()`) are smart enough to
-know when GLMs are passed so as to only standardize according to the
-predictors:
-
-```{r}
-mod_b <- glm(am ~ mpg + factor(cyl),
-             data = mtcars,
-             family = binomial())
-
-standardize_parameters(mod_b, method = ""refit"", two_sd = TRUE)
-# standardize_parameters(mod_b, method = ""posthoc"", two_sd = TRUE)
-# standardize_parameters(mod_b, method = ""basic"")
-```
-
-These can then be converted to OR (with `exp()`) and discussed as the ""*change
-in Odds as a function of a change in one SD of x*"".
-
-```{r}
-std <- standardize_parameters(mod_b, method = ""refit"", two_sd = TRUE)
-exp(std$Std_Coefficient)
-```
-
-Or we can directly ask for the coefficients to be exponentiated:
-
-```{r}
-standardize_parameters(mod_b, method = ""refit"", two_sd = TRUE, exponentiate = TRUE)
-```
-
-## Cohen's *f*
-
-Cohen's $f$ (of [ANOVA fame](https://easystats.github.io/effectsize/articles/anovaES.html)) can be used as a measure of effect size in the context of sequential multiple regression (i.e., [**nested models**](https://easystats.github.io/performance/reference/test_performance.html)).
-That is, when comparing two models, we can examine the ratio between the
-increase in $R^2$ and the unexplained variance:
-
-$$
-f^{2}={R_{AB}^{2}-R_{A}^{2} \over 1-R_{AB}^{2}}
-$$
-
-```{r}
-m1 <- lm(salary ~ xtra_hours, data = hardlyworking)
-m2 <- lm(salary ~ xtra_hours + n_comps + seniority, data = hardlyworking)
-
-cohens_f_squared(m1, model2 = m2)
-```
-
-<!-- ## Methods Comparison -->
-
-<!-- We will use the ""refit"" method as the baseline. We will then compute the
-differences between these standardized parameters and the ones provided by the
-other functions. The **bigger the (absolute) number, the worse it is**. -->
-
-<!-- > **SPOILER ALERT: the standardization implemented in `effectsize` is the
-most accurate and the most flexible.** -->
-
-<!-- ### Convenience function -->
-
-<!-- ```{r message=FALSE, warning=FALSE} --> <!-- library(effectsize) --> <!--
-library(lm.beta) --> <!-- library(MuMIn) -->
-
-<!-- comparison <- function(model, robust=FALSE){ --> <!-- out <-
-standardize_parameters(model, method=""refit"", robust=robust)[1:2] -->
-
-<!-- out$posthoc <- tryCatch({ --> <!-- out[, 2] - standardize_parameters(model,
-method=""posthoc"", robust=robust)[, 2] --> <!-- }, error =
-function(error_condition) { --> <!-- ""Error"" --> <!-- }) --> <!-- out$basic <-
-tryCatch({ --> <!-- out[, 2] - standardize_parameters(model, method=""basic"",
-robust=robust)[, 2] --> <!-- }, error = function(error_condition) { --> <!--
-""Error"" --> <!-- }) -->
-
-<!-- out$lm.beta <- tryCatch({ --> <!-- out[, 2] -
-lm.beta::lm.beta(model)$standardized.coefficients --> <!-- }, error =
-function(error_condition) { --> <!-- ""Error"" --> <!-- }, warning =
-function(warning_condition) { --> <!-- ""Error"" --> <!-- }) -->
-
-<!-- out$MuMIn <- tryCatch({ --> <!-- out[, 2] - MuMIn::std.coef(model,
-partial.sd=FALSE)[, 1] --> <!-- }, error = function(error_condition) { --> <!--
-""Error"" --> <!-- }) -->
-
-<!-- ### Data -->
-
-<!-- ```{r message=FALSE, warning=FALSE} --> <!-- data <- iris --> <!--
-data$Group_Sepal.Width <- as.factor(ifelse(data$Sepal.Width > 3, ""High"", ""Low""))
---> <!-- data$Binary_Sepal.Width <- as.factor(ifelse(data$Sepal.Width > 3, 1,
-0)) -->
-
-<!-- summary(data) --> <!-- ``` -->
-
-<!-- ### Models with only numeric predictors --> <!-- HERE -->
-
-<!-- #### Linear Model -->
-
-<!-- ```{r message=FALSE, warning=FALSE} --> <!-- model <- lm(Sepal.Length ~
-Petal.Width + Sepal.Width, data=data) --> <!-- comparison(model) --> <!-- ```
--->
-
-<!-- #### Linear Mixed Model -->
-
-<!-- ```{r message=FALSE, warning=FALSE} --> <!-- library(lme4) -->
-
-<!-- model <- lme4::lmer(Sepal.Length ~ Petal.Width + Sepal.Width + (1|Species),
---> <!-- data=data) --> <!-- comparison(model) --> <!-- ``` -->
-
-<!-- #### Bayesian Models -->
-
-<!-- ```{r message=FALSE, warning=FALSE} --> <!-- library(rstanarm) -->
-
-<!-- model <- stan_glm(Sepal.Length ~ Petal.Width + Sepal.Width, data=data) -->
-<!-- comparison(model) --> <!-- ``` -->
-
-<!-- For these simple models, **all methods return results equal to the ""refit""
-method** (although the other packages fail). -->
-
-<!-- #### Transformation -->
-
-<!-- ```{r message=FALSE, warning=FALSE} --> <!-- model <- lm(Sepal.Length ~
-poly(Petal.Width, 2) + poly(Sepal.Width, 2), data=data) --> <!--
-comparison(model) --> <!-- ``` -->
-
-<!-- When transformation are involved (e.g., polynomial transformations), **the
-basic method becomes very unreliable**. -->
-
-<!-- ```{r message=FALSE, warning=FALSE} --> <!-- model <- lm(Sepal.Length ~
-Petal.Width + Group_Sepal.Width, data=data) --> <!-- comparison(model) --> <!--
-``` -->
-
-<!-- #### Logistic Model -->
-
-<!-- ```{r message=FALSE, warning=FALSE} --> <!-- model <-
-glm(Binary_Sepal.Width ~ Petal.Width + Species, data=data, family=""binomial"")
---> <!-- comparison(model) --> <!-- ``` -->
-
-<!-- #### Linear Mixed Model -->
-
-<!-- ```{r message=FALSE, warning=FALSE} --> <!-- library(lme4) -->
-
-<!-- model <- lme4::lmer(Sepal.Length ~ Petal.Length + Group_Sepal.Width +
-(1|Species), data=data) --> <!-- comparison(model) --> <!-- ``` -->
-
-<!-- #### Bayesian Models -->
-
-<!-- ```{r message=FALSE, warning=FALSE} --> <!-- library(rstanarm) -->
-
-<!-- model <- stan_lmer(Sepal.Length ~ Petal.Width + Group_Sepal.Width +
-(1|Species), --> <!-- data=data) --> <!-- comparison(model) --> <!-- ``` -->
-
-<!-- When factors are involved, the basic method (that standardizes the numeric
-transformation of factors) give again different results. --> <!-- HERE -->
-
-<!-- ### Models with interactions -->
-
-<!-- Long story short, coeffcient obtained via **posthoc** standardization
-(without refitting the model) go berserk when interactions are involved.
-However, **this is ""normal""**: a regression model estimates coefficient between
-two variables when the other predictors are at 0 (are *fixed* at 0, that people
-interpret as *""adjusted for""*). When a standardized data is passed (in the
-*refit* method), the effects and interactions are estimated at the **means** of
-the other predictors (because 0 is the mean for a standardized variable).
-Whereas in posthoc standardization, this coefficient correspond to something
-different (because the 0 corresponds to something different in standardzed and
-non-standardized data). In other words, when it comes to interaction, passing
-standardized data results in a different model, which coefficient have an
-intrinsically different meaning from unstandardized data. And as [for
-now](https://github.com/easystats/effectsize/issues/6/), we are unable to
-retrieve one from another. -->
-
-<!-- #### Between continuous -->
-
-<!-- ```{r message=FALSE, warning=FALSE} --> <!-- model <- lm(Sepal.Length ~
-Petal.Width * Sepal.Width, data=data) --> <!-- comparison(model) --> <!-- ```
--->
-
-<!-- #### Between factors -->
-
-<!-- ```{r message=FALSE, warning=FALSE} --> <!-- model <- lm(Sepal.Length ~
-Species * Group_Sepal.Width, data=data) --> <!-- comparison(model) --> <!-- ```
--->
-
-<!-- #### Between factors and continuous -->
-
-<!-- ```{r message=FALSE, warning=FALSE} --> <!-- model <- lm(Sepal.Length ~
-Petal.Width * Group_Sepal.Width, data=data) --> <!-- comparison(model) --> <!--
-``` -->
-
-<!-- ```{r message=FALSE, warning=FALSE} --> <!-- model <- lm(Sepal.Length ~
-Group_Sepal.Width * Petal.Width, data=data) --> <!-- comparison(model) --> <!--
-``` -->
-
-<!-- ## Conclusion -->
-
-<!-- Use `refit` if possible, but if no interactions, can use `posthoc` or
-`smart`. -->
-
-# References
-",True,True,Documentation / Formatting,7
easystats,effectsize,fcdb16394fde5bcc9d1a2d76e37ed67b489b1dd8,Dominique Makowski,dom.mak19@gmail.com,2022-03-20T01:32:36Z,Dominique Makowski,dom.mak19@gmail.com,2022-03-20T01:32:36Z,"allow for ""..."" to avoid bugs in report",R/interpret_r.R;man/interpret_r.Rd,False,True,True,False,8,5,13,"---FILE: R/interpret_r.R---
@@ -3,6 +3,7 @@
 #' @param r Value or vector of correlation coefficient.
 #' @param rules Can be `""funder2019""` (default), `""gignac2016""`, `""cohen1988""`,
 #'   `""evans1996""`, `""lovakov2021""` or a custom set of [rules()].
+#' @param ... Not directly used.
 #'
 #' @note As \eqn{\phi}{\phi} can be larger than 1 - it is recommended to compute
 #'   and interpret Cramer's *V* instead.
@@ -66,7 +67,7 @@
 #' sciences. Thomson Brooks/Cole Publishing Co.
 #'
 #' @export
-interpret_r <- function(r, rules = ""funder2019"") {
+interpret_r <- function(r, rules = ""funder2019"", ...) {
   rules <- .match.rules(
     rules,
     list(

---FILE: man/interpret_r.Rd---
@@ -7,19 +7,21 @@
 \alias{interpret_rank_biserial}
 \title{Interpret correlation coefficient}
 \usage{
-interpret_r(r, rules = ""funder2019"")
+interpret_r(r, rules = ""funder2019"", ...)
 
-interpret_phi(r, rules = ""funder2019"")
+interpret_phi(r, rules = ""funder2019"", ...)
 
-interpret_cramers_v(r, rules = ""funder2019"")
+interpret_cramers_v(r, rules = ""funder2019"", ...)
 
-interpret_rank_biserial(r, rules = ""funder2019"")
+interpret_rank_biserial(r, rules = ""funder2019"", ...)
 }
 \arguments{
 \item{r}{Value or vector of correlation coefficient.}
 
 \item{rules}{Can be \code{""funder2019""} (default), \code{""gignac2016""}, \code{""cohen1988""},
 \code{""evans1996""}, \code{""lovakov2021""} or a custom set of \code{\link[=rules]{rules()}}.}
+
+\item{...}{Not directly used.}
 }
 \description{
 Interpret correlation coefficient",True,False,Documentation / Formatting,6
easystats,effectsize,12cd8c96526da6e821cb0748f95ff3b7f38d9c54,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-03-15T10:15:16Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-03-15T10:15:16Z,"use insights new internals

https://github.com/easystats/easystats/issues/220",R/rank_effectsizes.R;R/standardize.models.R;R/standardize_parameters.R;R/utils_validate_input_data.R;tests/testthat/test-standardize_parameters.R,False,True,True,False,10,10,20,"---FILE: R/rank_effectsizes.R---
@@ -484,7 +484,7 @@ kendalls_w <- function(x,
   m <- nrow(rankings) # judges
   R <- colSums(rankings)
 
-  if (!all(has_tie <- apply(rankings, 1, function(x) length(x) == length(unique(x))))) {
+  if (!all(has_tie <- apply(rankings, 1, function(x) length(x) == insight::n_unique(x)))) {
     # there are ties
     have_ties <- rankings[!has_tie, , drop = FALSE]
     Ti <- apply(have_ties, 1, function(r) {
@@ -608,7 +608,7 @@ kendalls_w <- function(x,
 # Utils -------------------------------------------------------------------
 
 .safe_ranktransform <- function(x, verbose = TRUE, ...) {
-  if (length(unique(x)) == 1) {
+  if (insight::n_unique(x) == 1) {
     if (verbose) warning(""Only one unique value - rank fixed at 1"")
     return(rep(1, length(x)))
   }

---FILE: R/standardize.models.R---
@@ -428,7 +428,7 @@ standardize.biglm <- standardize.wbm
   x <- insight::find_terms(model, flatten = TRUE)
   # log_pattern <- ""^log\\((.*)\\)""
   log_pattern <- ""(log\\(log|log|log1|log10|log1p|log2)\\(([^,\\+)]*).*""
-  out <- trimws(gsub(log_pattern, ""\\2"", x[grepl(log_pattern, x)]))
+  out <- insight::trim_ws(gsub(log_pattern, ""\\2"", x[grepl(log_pattern, x)]))
   intersect(colnames(data), out)
 }
 
@@ -437,7 +437,7 @@ standardize.biglm <- standardize.wbm
 .sqrt_terms <- function(model, data) {
   x <- insight::find_terms(model, flatten = TRUE)
   pattern <- ""sqrt\\(([^,\\+)]*).*""
-  out <- trimws(gsub(pattern, ""\\1"", x[grepl(pattern, x)]))
+  out <- insight::trim_ws(gsub(pattern, ""\\1"", x[grepl(pattern, x)]))
   intersect(colnames(data), out)
 }
 

---FILE: R/standardize_parameters.R---
@@ -166,7 +166,7 @@ standardise_parameters <- standardize_parameters
 #' @importFrom utils head
 #' @export
 standardize_parameters.default <- function(model, method = ""refit"", ci = 0.95, robust = FALSE, two_sd = FALSE, include_response = TRUE, verbose = TRUE, ...) {
-  object_name <- deparse(substitute(model), width.cutoff = 500)
+  object_name <- insight::safe_deparse(substitute(model))
   method <- match.arg(method, c(""refit"", ""posthoc"", ""smart"", ""basic"", ""classic"", ""pseudo""))
 
   m_info <- insight::model_info(model)
@@ -290,7 +290,7 @@ standardize_parameters.bootstrap_model <-
            include_response = TRUE,
            verbose = TRUE,
            ...) {
-    object_name <- deparse(substitute(model), width.cutoff = 500)
+    object_name <- insight::safe_deparse(substitute(model))
     method <- match.arg(method, c(""refit"", ""posthoc"", ""smart"", ""basic"", ""classic"", ""pseudo""))
 
     pars <- model
@@ -466,7 +466,7 @@ standardize_parameters.model_fit <-
 #' @export
 #' @aliases standardise_posteriors
 standardize_posteriors <- function(model, method = ""refit"", robust = FALSE, two_sd = FALSE, include_response = TRUE, verbose = TRUE, ...) {
-  object_name <- deparse(substitute(model), width.cutoff = 500)
+  object_name <- insight::safe_deparse(substitute(model))
 
   m_info <- insight::model_info(model)
   include_response <- include_response && .safe_to_standardize_response(m_info, verbose = verbose)

---FILE: R/utils_validate_input_data.R---
@@ -42,7 +42,7 @@
   # y should be NULL, numeric, or a factor:
   if (!is.null(y)) {
     if (!is.numeric(y)) {
-      if (length(unique(y)) != 2L) {
+      if (insight::n_unique(y) != 2) {
         stop(""Grouping variable y must have exactly 2 levels."", call. = FALSE)
       }
 
@@ -55,7 +55,7 @@
       y <- data[[2]]
     }
 
-    if (verbose && length(unique(y)) == 2) {
+    if (verbose && insight::n_unique(y) == 2) {
       warning(""'y' is numeric but has only 2 unique values."",
               ""\nIf this is a grouping variable, convert it to a factor."",
               call. = FALSE)

---FILE: tests/testthat/test-standardize_parameters.R---
@@ -333,7 +333,7 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     ## Correctly identify within and between terms
     dev_resp <- standardize_info(m, include_pseudo = TRUE)$Deviation_Response_Pseudo
-    expect_equal(length(unique(dev_resp[c(2, 4, 5, 6)])), 1)
+    expect_equal(insight::n_unique(dev_resp[c(2, 4, 5, 6)]), 1)
     expect_true(dev_resp[2] != dev_resp[3])
 
 ",True,False,Implementation / Logic,6
easystats,effectsize,f4191545b83fc93cbeda1888096523245ff4fb18,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-03-08T12:50:01Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-03-08T12:50:01Z,fix note,R/standardize.models.R,False,True,True,False,4,6,10,"---FILE: R/standardize.models.R---
@@ -69,6 +69,7 @@ standardize.default <- function(x,
                                 verbose = TRUE,
                                 include_response = TRUE,
                                 ...) {
+  data_std <- NULL # needed to avoid note
   .standardize_models(x,
                      robust = robust, two_sd = two_sd,
                      weights = weights,
@@ -265,6 +266,7 @@ standardize.brmsfit <- function(x,
                                 verbose = TRUE,
                                 include_response = TRUE,
                                 ...) {
+  data_std <- NULL # needed to avoid note
   if (insight::is_multivariate(x)) {
     stop(""multivariate brmsfit models not supported."",
          ""\nAs an alternative: you may standardize your data (and adjust your priors), and re-fit the model."",
@@ -290,6 +292,7 @@ standardize.mixor <- function(x,
                               verbose = TRUE,
                               include_response = TRUE,
                               ...) {
+  data_std <- random_group_factor <- NULL # needed to avoid note
   .standardize_models(x,
                       robust = robust, two_sd = two_sd,
                       weights = weights,
@@ -391,12 +394,7 @@ standardize.mediate <- function(x,
 
 
 #' @export
-standardize.wbm <- function(x,
-                            robust = FALSE,
-                            two_sd = FALSE,
-                            weights = TRUE,
-                            verbose = TRUE,
-                            ...) {
+standardize.wbm <- function(x, ...) {
   .update_failed(class(x))
 }
 ",True,False,Implementation / Logic,6
easystats,effectsize,2610471186553255c2039a4b6532b4a0d1cb9b1f,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-03-08T12:49:51Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-03-08T12:49:51Z,fix warning,DESCRIPTION,False,False,False,False,1,0,1,"---FILE: DESCRIPTION---
@@ -68,6 +68,7 @@ Suggests:
     see (>= 0.6.4),
     afex,
     BayesFactor,
+    biglm,
     boot,
     brms,
     car,",False,False,Dependency / Package,6
easystats,effectsize,f8b7c3223194db887c8a66b2273eb7d6678d665d,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-03-08T10:38:11Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-03-08T10:38:11Z,fix eta tests,R/eta_squared.R;tests/testthat/test-eta_squared.R,False,True,True,False,14,5,19,"---FILE: R/eta_squared.R---
@@ -882,12 +882,20 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
     stop(insight::format_message(""ANOVA table does not have F values or degrees of freedom - cannot compute effect size.""))
   }
 
+  Fi <- F.nm[F.nm %in% colnames(model)]
+  dfi <- df.nm[df.nm %in% colnames(model)]
+  df_errori <- df_error.nm[df_error.nm %in% colnames(model)]
+
+  if (length(dfi) > 1L) {
+    dfi <- dfi[1] # For MANOVA this should not use the MV-df
+  }
+
   # Clean up table ---
   par_table <- data.frame(
     Parameter = rownames(model),
-    F = model[,F.nm[F.nm %in% colnames(model)]],
-    df = model[,df.nm[df.nm %in% colnames(model)]],
-    df_error = model[,df_error.nm[df_error.nm %in% colnames(model)]]
+    F = model[,Fi],
+    df = model[,dfi],
+    df_error = model[,df_errori]
   )
   par_table <- par_table[!par_table[[""Parameter""]] %in% ""Residuals"",]
 

---FILE: tests/testthat/test-eta_squared.R---
@@ -7,7 +7,6 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     mod1 <- mod
     mod1$DenDF <- mod1$Df[nrow(mod1)]
-    mod1$NumDF <- mod1$Df
     mod1 <- mod1[-nrow(mod1),]
 
     expect_error(eta_squared(mod1), regexp = NA)
@@ -580,7 +579,9 @@ if (require(""testthat"") && require(""effectsize"")) {
   test_that(""ets_squared | tidymodels"", {
     skip_on_cran()
     skip_if_not_installed(""tidymodels"")
-    require(""tidymodels"", quietly = TRUE)
+    suppressPackageStartupMessages(require(""tidymodels"",
+                                           quietly = TRUE,
+                                           warn.conflicts = FALSE))
 
     set.seed(123)
     mod_lm <-",True,False,Implementation / Logic,6
easystats,effectsize,6fbfc22875f1deb49523065b9a7c8dca1c6d6f4a,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-03-08T10:26:02Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-03-08T10:26:02Z,fix test for multiple error capture,tests/testthat/test-standardize_models.R,False,True,True,False,3,4,7,"---FILE: tests/testthat/test-standardize_models.R---
@@ -25,8 +25,9 @@ if (require(""testthat"") && require(""effectsize"")) {
     }
 
     m <- my_lm_external_formula(mtcars, ""mpg"", ""am"")
-    expect_error(standardize(m), ""Try instead to standardize the data"", fixed = TRUE)
-    # This SHOULD work...
+    ers <- capture_error(standardize(m))
+    expect_match(as.character(ers), ""Try instead to standardize the data"",
+                 fixed = TRUE)
 
     skip_if_not_installed(""biglm"")
     mod <- biglm::biglm(mpg ~ hp, mtcars)
@@ -265,6 +266,4 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     expect_error(standardize(mod), regexp = NA)
   })
-
-
 }",True,False,Implementation / Logic,6
easystats,effectsize,46288415a0fb390cac4abda27b4ea8043f244629,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-03-07T20:10:08Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-03-07T20:10:08Z,fix for car::Anova of various models,R/eta_squared.R,False,True,True,False,3,3,6,"---FILE: R/eta_squared.R---
@@ -859,9 +859,9 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
                             verbose = TRUE,
                             include_intercept = FALSE,
                             ...) {
-  F.nm <- c(""F value"", ""approx F"", ""F-value"")
-  df.nm <- c(""NumDF"", ""num Df"", ""numDF"", ""npar"")
-  df_error.nm <- c(""DenDF"", ""den Df"", ""denDF"", ""df_error"")
+  F.nm <- c(""F value"", ""approx F"", ""F-value"", ""F"")
+  df.nm <- c(""NumDF"", ""num Df"", ""numDF"", ""npar"", ""Df"")
+  df_error.nm <- c(""DenDF"", ""den Df"", ""denDF"", ""df_error"", ""Df.res"")
 
   # If there is no df_error *or* is there IS a residuals row...
   if (!any(df_error.nm %in% colnames(model))) {",True,False,Implementation / Logic,3
easystats,effectsize,a57c6daca50a9be16ee916509aedc2f736084f92,Indrajeet Patil,patilindrajeet.science@gmail.com,2022-03-06T17:31:03Z,Indrajeet Patil,patilindrajeet.science@gmail.com,2022-03-06T17:31:03Z,"update COC to v2.1

https://github.com/easystats/easystats/issues/219",.github/CODE_OF_CONDUCT.md,False,False,False,False,21,21,42,"---FILE: .github/CODE_OF_CONDUCT.md---
@@ -6,8 +6,8 @@ We as members, contributors, and leaders pledge to make participation in our
 community a harassment-free experience for everyone, regardless of age, body
 size, visible or invisible disability, ethnicity, sex characteristics, gender
 identity and expression, level of experience, education, socio-economic status,
-nationality, personal appearance, race, religion, or sexual identity and
-orientation.
+nationality, personal appearance, race, caste, color, religion, or sexual
+identity and orientation.
 
 We pledge to act and interact in ways that contribute to an open, welcoming,
 diverse, inclusive, and healthy community.
@@ -21,25 +21,25 @@ community include:
 * Being respectful of differing opinions, viewpoints, and experiences
 * Giving and gracefully accepting constructive feedback
 * Accepting responsibility and apologizing to those affected by our mistakes,
-and learning from the experience
+  and learning from the experience
 * Focusing on what is best not just for us as individuals, but for the overall
-community
+  community
 
 Examples of unacceptable behavior include:
 
-* The use of sexualized language or imagery, and sexual attention or
-advances of any kind
+* The use of sexualized language or imagery, and sexual attention or advances of
+  any kind
 * Trolling, insulting or derogatory comments, and personal or political attacks
 * Public or private harassment
-* Publishing others' private information, such as a physical or email
-address, without their explicit permission
+* Publishing others' private information, such as a physical or email address,
+  without their explicit permission
 * Other conduct which could reasonably be considered inappropriate in a
-professional setting
+  professional setting
 
 ## Enforcement Responsibilities
 
-Community leaders are responsible for clarifying and enforcing our standards
-of acceptable behavior and will take appropriate and fair corrective action in
+Community leaders are responsible for clarifying and enforcing our standards of
+acceptable behavior and will take appropriate and fair corrective action in
 response to any behavior that they deem inappropriate, threatening, offensive,
 or harmful.
 
@@ -50,10 +50,10 @@ decisions when appropriate.
 
 ## Scope
 
-This Code of Conduct applies within all community spaces, and also applies
-when an individual is officially representing the community in public spaces.
-Examples of representing our community include using an official e-mail
-address, posting via an official social media account, or acting as an appointed
+This Code of Conduct applies within all community spaces, and also applies when
+an individual is officially representing the community in public spaces.
+Examples of representing our community include using an official e-mail address,
+posting via an official social media account, or acting as an appointed
 representative at an online or offline event.
 
 ## Enforcement
@@ -114,13 +114,13 @@ community.
 ## Attribution
 
 This Code of Conduct is adapted from the [Contributor Covenant][homepage],
-version 2.0,
-available at <https://www.contributor-covenant.org/version/2/0/code_of_conduct.html>.
+version 2.1, available at
+<https://www.contributor-covenant.org/version/2/1/code_of_conduct.html>.
 
-Community Impact Guidelines were inspired by [Mozilla's code of conduct
-enforcement ladder](https://github.com/mozilla/diversity).
-
-[homepage]: https://www.contributor-covenant.org
+Community Impact Guidelines were inspired by
+[Mozilla's code of conduct enforcement ladder][https://github.com/mozilla/inclusion].
 
 For answers to common questions about this code of conduct, see the FAQ at
 <https://www.contributor-covenant.org/faq>. Translations are available at <https://www.contributor-covenant.org/translations>.
+
+[homepage]: https://www.contributor-covenant.org",False,False,Documentation / Formatting,3
easystats,effectsize,f901e7c615b760b62fd9b6a932feb3a0ab48bf93,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-03-05T14:24:33Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-03-05T14:24:33Z,fix examples,R/eta_squared.R;man/eta_squared.Rd,False,True,True,False,2,4,6,"---FILE: R/eta_squared.R---
@@ -96,7 +96,6 @@
 #' @family effect size indices
 #'
 #' @examples
-#' \donttest{
 #' data(mtcars)
 #' mtcars$am_f <- factor(mtcars$am)
 #' mtcars$cyl_f <- factor(mtcars$cyl)
@@ -125,7 +124,7 @@
 #' interpret_epsilon_squared(0.10, rules = ""cohen1992"")
 #'
 #' interpret(eta2, rules = ""cohen1992"")
-#' }
+#'
 #'
 #' @examplesIf require(""car"") && require(""afex"")
 #' # Recommended: Type-2 or -3 effect sizes + effects coding

---FILE: man/eta_squared.Rd---
@@ -235,7 +235,6 @@ to 0 to be negligible are needed (""equivalence testing""; Bauer & Kiesser,
 }
 
 \examples{
-\donttest{
 data(mtcars)
 mtcars$am_f <- factor(mtcars$am)
 mtcars$cyl_f <- factor(mtcars$cyl)
@@ -264,7 +263,7 @@ interpret_eta_squared(0.10, rules = ""cohen1992"")
 interpret_epsilon_squared(0.10, rules = ""cohen1992"")
 
 interpret(eta2, rules = ""cohen1992"")
-}
+
 
 \dontshow{if (require(""car"") && require(""afex"")) (if (getRversion() >= ""3.4"") withAutoprint else force)(\{ # examplesIf}
 # Recommended: Type-2 or -3 effect sizes + effects coding",True,False,Documentation / Formatting,6
easystats,effectsize,8973b0abb1a4837d1887c463fbe9e311d369899a,Daniel,mail@danielluedecke.de,2022-03-05T00:16:26Z,Daniel,mail@danielluedecke.de,2022-03-05T00:16:26Z,close https://github.com/easystats/parameters/issues/671,R/standardize_info.R,False,True,True,False,5,0,5,"---FILE: R/standardize_info.R---
@@ -45,6 +45,11 @@ standardize_info.default <- function(model, robust = FALSE, two_sd = FALSE, incl
     # would need to also get the binomial model matrix...
   }
 
+  # Sanity Check for glmmTMB with dispersion
+  if (length(params) != nrow(types)) {
+    types <- types[types$Parameter %in% params, ]
+  }
+
   out <- data.frame(
     Parameter = params,
     Type = types$Type,",True,False,Implementation / Logic,6
easystats,effectsize,998007812f173a1960fa283362b3e8067ad7e197,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-03-02T14:08:01Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-03-02T14:08:01Z,fix test,R/interpret_cfa_fit.R,False,True,True,False,2,1,3,"---FILE: R/interpret_cfa_fit.R---
@@ -260,7 +260,8 @@ interpret.performance_lavaan <- function(x, ...) {
       Name = ind_name,
       Value = x[[ind_name]],
       Threshold = rules$values,
-      Interpretation = interp
+      Interpretation = interp,
+      stringsAsFactors = FALSE
     )
   })
 ",True,False,Implementation / Logic,3
easystats,effectsize,ed01c9b87396cda771f92dc1f49ea66a9789d626,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-03-02T13:27:02Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-03-02T13:27:02Z,fix bayes eta,R/eta_squared_posterior.R;tests/testthat/test-eta_squared_posterior.R,False,True,True,False,65,88,153,"---FILE: R/eta_squared_posterior.R---
@@ -30,17 +30,14 @@ eta_squared_posterior.stanreg <- function(model,
   insight::check_if_installed(""rstantools"")
 
   mo_inf <- insight::model_info(model)
-  if ((!mo_inf$is_linear) ||
-    mo_inf$is_multivariate) {
+  if (!mo_inf$is_linear || mo_inf$is_multivariate) {
     stop(""Computation of Eta Squared is only applicable to univariate linear models."")
   }
 
   if (partial && mo_inf$is_mixed) {
     if (verbose) {
-      warning(
-        ""Bayesian Partial Eta Squared not supported for mixed models.\n"",
-        ""Returning Eta Squared instead.""
-      )
+      warning(""Bayesian Partial Eta Squared not supported for mixed models.\n"",
+              ""Returning Eta Squared instead."")
     }
     partial <- FALSE
     # would need to account for random effects if present.
@@ -49,10 +46,8 @@ eta_squared_posterior.stanreg <- function(model,
 
   if ((isTRUE(generalized) || is.character(generalized)) && mo_inf$is_mixed) {
     if (verbose) {
-      warning(
-        ""Bayesian Generalized Eta Squared not supported for mixed models.\n"",
-        ""Returning Eta Squared instead.""
-      )
+      warning(""Bayesian Generalized Eta Squared not supported for mixed models.\n"",
+              ""Returning Eta Squared instead."")
     }
     generalized <- FALSE
   }
@@ -63,13 +58,13 @@ eta_squared_posterior.stanreg <- function(model,
   resp_name <- insight::find_response(model)
 
   # test centered predictors
-  if (verbose) .all_centered(X)
+  # if (verbose) .all_centered(X)
 
   ## 2. get ppd
   ppd <- rstantools::posterior_predict(model,
     draws = draws, # for rstanreg
-    nsamples = draws
-  ) # for brms
+    nsamples = draws # for brms
+  )
 
   ## 3. Compute effect size...
   if (verbose) {
@@ -104,46 +99,46 @@ eta_squared_posterior.stanreg <- function(model,
 eta_squared_posterior.brmsfit <- eta_squared_posterior.stanreg
 
 
-#' @keywords internal
-#' @importFrom stats contrasts
-.all_centered <- function(X) {
-  numeric <- sapply(X, inherits, what = c(""numeric"", ""integer""))
-  numerics <- colnames(X)[numeric]
-  factors <- colnames(X)[!numeric]
-
-  numerics_centered <- factors_centered <- logical(0)
-
-  if (length(numerics)) {
-    numerics_centered <- sapply(
-      X[, numerics, drop = FALSE],
-      function(xi) isTRUE(all.equal(mean(xi), 0))
-    )
-  }
-
-
-  of <- options()$contrasts
-  if (length(factors)) {
-    factors_centered <- sapply(X[, factors, drop = FALSE], function(xi) {
-      # if a contrast has negative and positive values, it is assumed to be one of:
-      # ""contr.sum"", ""contr.helmert"", ""contr.poly"", ""contr.bayes""
-      (is.factor(xi) && (any(contrasts(xi) < 0) & any(contrasts(xi) > 0))) ||
-        # Or if it is not a factor, is the default method one of these?
-        (!is.factor(xi) && all(of %in% c(""contr.sum"", ""contr.poly"", ""contr.bayes"", ""contr.helmert"")))
-    })
-  }
-
-
-  if ((length(numerics_centered) && !all(numerics_centered)) ||
-    length(factors_centered) && !all(factors_centered)) {
-    non_centered <- !c(numerics_centered, factors_centered)
-    non_centered <- names(non_centered)[non_centered]
-    warning(
-      ""Not all variables are centered:\n "",
-      paste(non_centered, collapse = "", ""),
-      ""\n Results might be bogus if involved in interactions..."",
-      call. = FALSE, immediate. = TRUE
-    )
-  }
-
-  return(invisible(NULL))
-}
+#' #' @keywords internal
+#' #' @importFrom stats contrasts
+#' .all_centered <- function(X) {
+#'   numeric <- sapply(X, inherits, what = c(""numeric"", ""integer""))
+#'   numerics <- colnames(X)[numeric]
+#'   factors <- colnames(X)[!numeric]
+#'
+#'   numerics_centered <- factors_centered <- logical(0)
+#'
+#'   if (length(numerics)) {
+#'     numerics_centered <- sapply(
+#'       X[, numerics, drop = FALSE],
+#'       function(xi) isTRUE(all.equal(mean(xi), 0))
+#'     )
+#'   }
+#'
+#'
+#'   of <- options()$contrasts
+#'   if (length(factors)) {
+#'     factors_centered <- sapply(X[, factors, drop = FALSE], function(xi) {
+#'       # if a contrast has negative and positive values, it is assumed to be one of:
+#'       # ""contr.sum"", ""contr.helmert"", ""contr.poly"", ""contr.bayes""
+#'       (is.factor(xi) && (any(contrasts(xi) < 0) & any(contrasts(xi) > 0))) ||
+#'         # Or if it is not a factor, is the default method one of these?
+#'         (!is.factor(xi) && all(of %in% c(""contr.sum"", ""contr.poly"", ""contr.bayes"", ""contr.helmert"")))
+#'     })
+#'   }
+#'
+#'
+#'   if ((length(numerics_centered) && !all(numerics_centered)) ||
+#'     length(factors_centered) && !all(factors_centered)) {
+#'     non_centered <- !c(numerics_centered, factors_centered)
+#'     non_centered <- names(non_centered)[non_centered]
+#'     warning(
+#'       ""Not all variables are centered:\n "",
+#'       paste(non_centered, collapse = "", ""),
+#'       ""\n Results might be bogus if involved in interactions..."",
+#'       call. = FALSE
+#'     )
+#'   }
+#'
+#'   return(invisible(NULL))
+#' }

---FILE: tests/testthat/test-eta_squared_posterior.R---
@@ -5,30 +5,24 @@ if (require(""testthat"") && require(""effectsize"")) {
     skip_if_not_installed(""bayestestR"")
     skip_if_not_installed(""car"")
 
-    fit_bayes <- rstanarm::stan_glm(mpg ~ factor(cyl) * wt + qsec,
+    set.seed(444)
+    data(""mtcars"")
+    mtcars$cyl <- factor(mtcars$cyl)
+
+    fit_bayes <- rstanarm::stan_glm(mpg ~ cyl * wt + qsec,
       data = mtcars,
       family = gaussian(),
       refresh = 0
     )
 
 
     # PARTIAL, type = 3 -------------------------------------------------------
-    es_tab <- eta_squared(
-      car::Anova(
-        lm(mpg ~ factor(cyl) * wt + qsec,
-          data = mtcars
-        ),
-        type = 3
-      ),
-      partial = TRUE
-    )
+    mod <- lm(mpg ~ cyl * wt + qsec, data = mtcars)
+    a <- car::Anova(mod, type = 3)
+    es_tab <- eta_squared(a, partial = TRUE)
 
-    expect_warning(
-      es_post <- eta_squared_posterior(fit_bayes,
-        ss_function = car::Anova, type = 3
-      ),
-      regexp = ""bogus""
-    )
+    es_post <- eta_squared_posterior(fit_bayes,
+                                     ss_function = car::Anova, type = 3)
     expect_equal(colnames(es_post), es_tab$Parameter)
 
     # this is a very soft test...
@@ -38,23 +32,11 @@ if (require(""testthat"") && require(""effectsize"")) {
 
 
     # non-PARTIAL, type = 3 ---------------------------------------------------
-    es_tab <- eta_squared(
-      car::Anova(
-        lm(mpg ~ factor(cyl) * wt + qsec,
-          data = mtcars
-        ),
-        type = 3
-      ),
-      partial = FALSE
-    )
+    es_tab <- eta_squared(a, partial = FALSE)
 
-    expect_warning(
-      es_post <- eta_squared_posterior(fit_bayes,
-        partial = FALSE,
-        ss_function = car::Anova, type = 3
-      ),
-      regexp = ""bogus""
-    )
+    es_post <- eta_squared_posterior(fit_bayes,
+                                     partial = FALSE,
+                                     ss_function = car::Anova, type = 3)
     expect_equal(colnames(es_post), es_tab$Parameter)
 
     # this is a very soft test...",True,False,Implementation / Logic,6
easystats,effectsize,cf9743b122acd991c2361107cc37f2811386633d,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-03-01T13:26:25Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-03-01T13:26:25Z,fix tests,R/utils_validate_input_data.R;tests/testthat/test-standardized_differences.R,False,True,True,False,49,46,95,"---FILE: R/utils_validate_input_data.R---
@@ -6,19 +6,22 @@
   if (inherits(x, ""formula"")) {
     # Validate:
     if (length(x) != 3L) {
-      stop(""Formula must be two sided."", call. = FALSE)
+      stop(""Formula must have one of the following forms:"",
+           ""\n\ty ~ group,\n\ty ~ 1,\n\tPair(x,y) ~ 1"", call. = FALSE)
     }
 
     # Pull columns
     mf <- .resolve_formula(x, data, ...)
 
+    if (ncol(mf) > 2L) {
+      stop(""Formula must have only one term on the RHS."", call. = FALSE)
+    }
+
     x <- mf[[1]]
     y <- NULL
     if (ncol(mf) == 2L) {
       y <- mf[[2]]
       if (!is.factor(y)) y <- factor(y)
-    } else {
-      stop(""Formula must have only one term on the RHS."", call. = FALSE)
     }
   } else {
     # Test if they are they are column names
@@ -67,11 +70,15 @@
 #' @keywords internal
 .get_data_multi_group <- function(x, groups, data = NULL, ...) {
 
-  if (inherits(frm <- x, ""formula"")) {
+  if (inherits(x, ""formula"")) {
+    if (length(x) != 3) {
+      stop(""Formula must have the form of 'outcome ~ group'."", call. = FALSE)
+    }
+
     mf <- .resolve_formula(x, data, ...)
 
-    if (length(frm) != 3 | ncol(mf) != 2) {
-      stop(""Formula must have the form of 'outcome ~ group'."", call. = FALSE)
+    if (ncol(mf) != 2L) {
+      stop(""Formula must have only one term on the RHS."", call. = FALSE)
     }
 
     x <- mf[[1]]
@@ -105,64 +112,60 @@
 
 #' @keywords internal
 #' @importFrom stats reshape
-.get_data_nested_groups <- function(x, groups, blocks, data = NULL, wide = TRUE, ...) {
+.get_data_nested_groups <- function(x, groups = NULL, blocks = NULL, data = NULL, wide = TRUE, ...) {
 
   if (inherits(x, ""formula"")) {
-    if ((length(x) != 3L) ||
-        (length(x[[3L]]) != 3L) ||
-        (x[[3L]][[1L]] != as.name(""|""))) {
+    if (length(x) != 3L ||
+        x[[3L]][[1L]] != as.name(""|"")) {
       stop(""Formula must have the 'x ~ groups | blocks'."", call. = FALSE)
     }
 
     x[[3L]][[1L]] <- as.name(""+"")
 
-    mf <- .resolve_formula(x, data, ...)
+    x <- .resolve_formula(x, data, ...)
 
-    if (ncol(mf) != 3) {
-      stop(""Formula must have only two terms on the RHS."", call. = FALSE)
+    if (ncol(x) != 3L) {
+      stop(""Formula must have only two term on the RHS."", call. = FALSE)
     }
-
-    x <- mf[[1]]
-    groups <- mf[[2]]
-    blocks <- mf[[3]]
-  } else if (inherits(x, c(""table"", ""matrix"", ""array"", ""data.frame""))) {
-    data <- data.frame(
-      x = c(x),
-      groups = rep(factor(seq_len(ncol(x))), each = nrow(x)),
-      blocks = rep(factor(seq_len(nrow(x))), ncol(x))
-    )
-
-    x <- data[[1]]
-    groups <- data[[2]]
-    blocks <- data[[3]]
-  } else {
-    # If they are column names
+  } else if (inherits(x, ""data.frame"")) {
+    x <- as.matrix(x)
+  } else if (!inherits(x, c(""table"", ""matrix"", ""array""))) {
     x <- .resolve_char(x, data)
     groups <- .resolve_char(groups, data)
     blocks <- .resolve_char(blocks, data)
+
+    if (length(x) != length(groups) || length(x) != length(blocks)) {
+      stop(""x, groups and blocks must be of the same length."", call. = FALSE)
+    }
+
+    x <- data.frame(x, groups, blocks)
+  }
+
+
+  if (inherits(x, c(""matrix"", ""array""))) {
+    x <- as.table(x)
   }
 
-  if (length(x) != length(groups) || length(x) != length(blocks)) {
-    stop(""x, groups and blocks must be of the same length."", call. = FALSE)
+  if (inherits(x, c(""table""))) {
+    x <- as.data.frame(x)[,c(3, 2, 1)]
   }
 
-  if (!is.factor(groups)) groups <- factor(groups)
-  if (!is.factor(blocks)) blocks <- factor(blocks)
+  colnames(x) <- c(""x"", ""groups"", ""blocks"")
 
-  data <- data.frame(x, groups, blocks, stringsAsFactors = FALSE)
+  if (!is.numeric(x$x)) {
+    stop(""Cannot compute effect size for a non-numeric vector."", call. = FALSE)
+  }
+  if (!is.factor(x$groups)) x$groups <- factor(x$groups)
+  if (!is.factor(x$blocks)) x$blocks <- factor(x$blocks)
 
+  # By this point, the data is in long format
   if (wide) {
-    data <- stats::reshape(
-      data,
-      direction = ""wide"",
-      v.names = ""x"",
-      timevar = ""groups"",
-      idvar = ""blocks""
-    )
-
-    data <- as.matrix(data[, -1])
+    x <- datawizard::data_to_wide(x,
+                                  values_from = ""x"",
+                                  colnames_from = ""groups"")
+    x <- x[,-1]
   }
-  data
+  x
 }
 
 
@@ -187,7 +190,7 @@
     if (is.null(data)) {
       stop(""Please provide data argument."", call. = FALSE)
     } else if (!nm %in% names(data)) {
-      stop(""Column "", x, "" missing from data."", call. = FALSE)
+      stop(""Column "", nm, "" missing from data."", call. = FALSE)
     }
 
     return(data[[nm]])

---FILE: tests/testthat/test-standardized_differences.R---
@@ -99,7 +99,7 @@ if (require(""testthat"") && require(""effectsize"")) {
   })
 
   test_that(""hedges_g (and other bias correction things"", {
-    x <- hedges_g(wt ~ am, data = mtcars, poop = 1)
+    x <- hedges_g(wt ~ am, data = mtcars)
     expect_equal(colnames(x)[1], ""Hedges_g"")
     expect_equal(x[[1]], 1.844, tolerance = 0.001)
     expect_equal(x$CI_low, 1.004, tolerance = 0.001)",True,False,Implementation / Logic,6
easystats,effectsize,3b968a7d8cccadba0e2e1c380ab0fafb1a3f8060,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-02-27T12:50:32Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-02-27T12:50:32Z,fix tests,NAMESPACE;R/utils_validate_input_data.R;tests/testthat/test-standardized_differences.R,False,True,True,False,18,11,29,"---FILE: NAMESPACE---
@@ -228,7 +228,6 @@ importFrom(stats,ave)
 importFrom(stats,chisq.test)
 importFrom(stats,complete.cases)
 importFrom(stats,contrasts)
-importFrom(stats,delete.response)
 importFrom(stats,kruskal.test)
 importFrom(stats,lm)
 importFrom(stats,mad)
@@ -250,7 +249,6 @@ importFrom(stats,qt)
 importFrom(stats,reshape)
 importFrom(stats,sd)
 importFrom(stats,setNames)
-importFrom(stats,terms)
 importFrom(stats,update)
 importFrom(stats,var)
 importFrom(stats,weighted.mean)

---FILE: R/utils_validate_input_data.R---
@@ -1,7 +1,5 @@
 
 #' @keywords internal
-#' @importFrom stats terms
-#' @importFrom stats delete.response
 .get_data_2_samples <- function(x, y = NULL, data = NULL, verbose = TRUE, ...) {
 
   # Sanity checks
@@ -19,7 +17,7 @@
       stop(""Formula must be two sided."", call. = FALSE)
     }
 
-    mf <- stats::model.frame(formula = x, data = data, ...)
+    mf <- .resolve_formula(x, data, ...)
 
     x <- mf[[1]]
     if (ncol(mf) == 1) {
@@ -88,10 +86,9 @@
 
 
 #' @keywords internal
-#' @importFrom stats model.frame
-.get_data_multi_group <- function(x, groups, data, ...) {
+.get_data_multi_group <- function(x, groups, data = NULL, ...) {
   if (inherits(frm <- x, ""formula"")) {
-    mf <- stats::model.frame(formula = frm, data = data, ...)
+    mf <- .resolve_formula(x, data, ...)
 
     if (length(frm) != 3 | ncol(mf) != 2) {
       stop(""Formula must have the form of 'outcome ~ group'."", call. = FALSE)
@@ -113,7 +110,7 @@
 }
 
 #' @keywords internal
-#' @importFrom stats model.frame reshape
+#' @importFrom stats reshape
 .get_data_nested_groups <- function(x, groups, blocks, data = NULL, ...) {
   if (inherits(frm <- x, ""formula"")) {
     if ((length(frm) != 3L) ||
@@ -124,7 +121,7 @@
 
     frm[[3L]][[1L]] <- as.name(""+"")
 
-    mf <- stats::model.frame(formula = frm, data = data, ...)
+    mf <- .resolve_formula(x, data, ...)
 
     if (ncol(mf) != 3) {
       stop(""Formula must have only two terms on the RHS."", call. = FALSE)
@@ -168,3 +165,15 @@
 
   as.matrix(data[, -1])
 }
+
+
+#' @keywords internal
+#' @importFrom stats model.frame
+.resolve_formula <- function(formula, data, subset, na.action, ...) {
+  cl <- match.call(expand.dots = FALSE)
+  cl[[1L]] <- quote(stats::model.frame)
+  cl$... <- NULL
+  eval(cl, envir = parent.frame())
+}
+
+

---FILE: tests/testthat/test-standardized_differences.R---
@@ -99,7 +99,7 @@ if (require(""testthat"") && require(""effectsize"")) {
   })
 
   test_that(""hedges_g (and other bias correction things"", {
-    expect_warning(x <- hedges_g(wt ~ am, data = mtcars, correction = TRUE))
+    x <- hedges_g(wt ~ am, data = mtcars, poop = 1)
     expect_equal(colnames(x)[1], ""Hedges_g"")
     expect_equal(x[[1]], 1.844, tolerance = 0.001)
     expect_equal(x$CI_low, 1.004, tolerance = 0.001)",True,False,Dependency / Package,6
easystats,effectsize,da5f9e1ea02cdf897fb1e83f0c59b1a72d3eb53a,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-02-25T12:59:59Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-02-25T12:59:59Z,"fix lazy eval

Stupid parent.frame......",R/cohens_d.R;R/standardize.models.R;R/standardize_parameters.R,False,True,True,False,7,10,17,"---FILE: R/cohens_d.R---
@@ -138,9 +138,8 @@ cohens_d <- function(x,
                      alternative = ""two.sided"",
                      verbose = TRUE,
                      ...) {
-  if (!is.null(var.equal <- match.call()[[""var.equal""]])) {
-    pooled_sd <- eval(var.equal)
-  }
+  var.equal <- eval(match.call()[[""var.equal""]], envir = parent.frame())
+  if (!is.null(var.equal)) pooled_sd <- var.equal
 
   .effect_size_difference(
     x,
@@ -169,9 +168,8 @@ hedges_g <- function(x,
                      alternative = ""two.sided"",
                      verbose = TRUE,
                      ...) {
-  if (!is.null(var.equal <- match.call()[[""var.equal""]])) {
-    pooled_sd <- eval(var.equal)
-  }
+  var.equal <- eval(match.call()[[""var.equal""]], envir = parent.frame())
+  if (!is.null(var.equal)) pooled_sd <- var.equal
 
   .effect_size_difference(
     x,

---FILE: R/standardize.models.R---
@@ -73,9 +73,8 @@ standardize.default <- function(x,
                                 verbose = TRUE,
                                 include_response = TRUE,
                                 ...) {
-  if (is.null(m_info <- match.call()[[""m_info""]])){
-    m_info <- insight::model_info(x)
-  }
+  m_info <- eval(match.call()[[""m_info""]], envir = parent.frame())
+  if (is.null(m_info)) m_info <- insight::model_info(x)
 
   data <- insight::get_data(x)
 

---FILE: R/standardize_parameters.R---
@@ -179,7 +179,7 @@ standardize_parameters.default <- function(model, method = ""refit"", ci = 0.95, r
   pars <- parameters::model_parameters(model, ci = ci, standardize = NULL, effects = ""fixed"", ...)
 
   # should post hoc exponentiate?
-  exponentiate <- isTRUE(match.call()[[""exponentiate""]])
+  exponentiate <- isTRUE(eval(match.call()[[""exponentiate""]], envir = parent.frame()))
   coefficient_name <- attr(pars, ""coefficient_name"")
 
   if (method %in% c(""posthoc"", ""smart"", ""basic"", ""classic"", ""pseudo"")) {",True,False,Implementation / Logic,6
easystats,effectsize,c15356528065ef965007a17d88a5e1db7dc5b681,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-02-22T11:53:11Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-02-22T11:53:11Z,fix test,R/print.rules.R,False,True,True,False,4,2,6,"---FILE: R/print.rules.R---
@@ -40,7 +40,7 @@ print_html.rules <- function(x, digits = ""signif2"", ...) {
 format.rules <- function(x, digits = ""signif2"", output = ""text"", ...) {
   name <- attr(x, ""rule_name"")
 
-  V <- insight::format_value(x$values, ...)
+  V <- insight::format_value(x$values, digits = digits, ...)
   V <- insight::format_value(V, width = max(nchar(V)), ...)
   L <- x$labels
 
@@ -71,7 +71,9 @@ format.rules <- function(x, digits = ""signif2"", output = ""text"", ...) {
   }
 
   if (output == ""text"") {
-    colnames(out)[c(1,3)] <- "" ""
+    if (length(L) != length(V)) {
+      colnames(out)[c(1,3)] <- "" ""
+    }
     caption <- c(sprintf(""# Reference %s (%s)"", title_type, name),
                  .pcl[""interpret""])
   } else {",True,False,Implementation / Logic,6
easystats,effectsize,19a85b70fa0999203914e8f54977e445b24ef26a,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-02-22T09:21:50Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-02-22T09:21:50Z,fix missing parameter doc,R/print.effectsize_table.R;man/effectsize_CIs.Rd;man/print.effectsize_table.Rd,False,True,True,False,9,4,13,"---FILE: R/print.effectsize_table.R---
@@ -30,6 +30,8 @@ print_html.effectsize_table <- function(x, digits = 2, ...) {
 }
 
 #' @rdname print.effectsize_table
+#' @param output Which output is the formatting intended for? Affects how title
+#'   and footers are formatted.
 #' @export
 format.effectsize_table <- function(x, digits = 2, output = c(""text"", ""markdown"", ""html""), ...) {
   output <- match.arg(output)

---FILE: man/effectsize_CIs.Rd---
@@ -99,7 +99,7 @@ that this interval does not give 95\% coverage for the underlying effect size
 parameter value. For that, construct a 95\% 2-sided CI.\if{html}{\out{<div class=""sourceCode r"">}}\preformatted{data(""hardlyworking"")
 fit <- lm(salary ~ n_comps + age, data = hardlyworking)
 eta_squared(fit) # default, ci = 0.95, alternative = ""greater""
-}\if{html}{\out{</div>}}\preformatted{## # Effect Size for ANOVA(Type I)
+}\if{html}{\out{</div>}}\preformatted{## # Effect Size for ANOVA (Type I)
 ## 
 ## Parameter | Eta2 (partial) |       95\% CI
 ## -----------------------------------------
@@ -108,7 +108,7 @@ eta_squared(fit) # default, ci = 0.95, alternative = ""greater""
 ## 
 ## - One-sided CIs: upper bound fixed at [1.00].
 }\if{html}{\out{<div class=""sourceCode r"">}}\preformatted{eta_squared(fit, alternative = ""less"") # Test is eta is smaller than some value
-}\if{html}{\out{</div>}}\preformatted{## # Effect Size for ANOVA(Type I)
+}\if{html}{\out{</div>}}\preformatted{## # Effect Size for ANOVA (Type I)
 ## 
 ## Parameter | Eta2 (partial) |       95\% CI
 ## -----------------------------------------
@@ -117,14 +117,14 @@ eta_squared(fit) # default, ci = 0.95, alternative = ""greater""
 ## 
 ## - One-sided CIs: lower bound fixed at [0.00].
 }\if{html}{\out{<div class=""sourceCode r"">}}\preformatted{eta_squared(fit, alternative = ""two.sided"") # 2-sided bounds for alpha = .05
-}\if{html}{\out{</div>}}\preformatted{## # Effect Size for ANOVA(Type I)
+}\if{html}{\out{</div>}}\preformatted{## # Effect Size for ANOVA (Type I)
 ## 
 ## Parameter | Eta2 (partial) |       95\% CI
 ## -----------------------------------------
 ## n_comps   |           0.21 | [0.15, 0.27]
 ## age       |           0.10 | [0.06, 0.15]
 }\if{html}{\out{<div class=""sourceCode r"">}}\preformatted{eta_squared(fit, ci = 0.9, alternative = ""two.sided"") # both 1-sided bounds for alpha = .05
-}\if{html}{\out{</div>}}\preformatted{## # Effect Size for ANOVA(Type I)
+}\if{html}{\out{</div>}}\preformatted{## # Effect Size for ANOVA (Type I)
 ## 
 ## Parameter | Eta2 (partial) |       90\% CI
 ## -----------------------------------------

---FILE: man/print.effectsize_table.Rd---
@@ -33,6 +33,9 @@ value as suffix, e.g. \code{digits = ""scientific4""} to have scientific
 notation with 4 decimal places, or \code{digits = ""signif5""} for 5
 significant figures (see also \code{\link[=signif]{signif()}}).}
 
+\item{output}{Which output is the formatting intended for? Affects how title
+and footers are formatted.}
+
 \item{append_CLES}{Should the Common Language Effect Sizes be printed as well?
 Only applicable to Cohen's \emph{d}, Hedges' \emph{g} for independent samples of
 equal variance (pooled sd) or for the rank-biserial correlation for",True,False,Documentation / Formatting,6
easystats,effectsize,ef34797978128bced63726bc423db6e7743eb65a,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-02-08T11:31:23Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-02-08T11:31:23Z,fix eta for manova,NEWS.md;R/eta_squared.R,False,True,True,False,15,0,15,"---FILE: NEWS.md---
@@ -1,6 +1,8 @@
 # effectsize 0.6.0.2
 
+## Bug fixes
 
+- `eta_squared()` works with `car::Manova()` that does not have an i-design. 
 
 # effectsize 0.6.0.1
 

---FILE: R/eta_squared.R---
@@ -1027,6 +1027,19 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
            ...) {
     # Faking the model_parameters.aovlist output:
     suppressWarnings(aov_tab <- summary(model)$univariate.tests)
+    if (is.null(aov_tab)) {
+      aov_tab <- parameters::model_parameters(model)
+      aov_tab$df <- aov_tab$df_num
+      aov_tab$df_num <- NULL
+      out <- .anova_es(aov_tab, type = type,
+                       partial = partial, generalized = generalized,
+                       ci = ci, alternative = alternative,
+                       include_intercept = include_intercept,
+                       verbose = verbose)
+      attr(out, ""anova_type"") <- as.numeric(as.roman(model$type))
+      attr(out, ""approximate"") <- FALSE
+      return(out)
+    }
     aov_tab <- as.data.frame(unclass(aov_tab))
     aov_tab$Parameter <- rownames(aov_tab)
     colnames(aov_tab)[colnames(aov_tab)== ""Sum Sq""] <- ""Sum_Squares""",True,False,Implementation / Logic,6
easystats,effectsize,d65c0e574fd970c818fadc6c40e1748f9206044b,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-01-31T06:50:24Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-01-31T06:50:24Z,patch up,WIP/paired_d examples.R;WIP/paired_d2.R;WIP/sim CIs.R,False,True,True,False,61,2,63,"---FILE: WIP/paired_d examples.R---
@@ -9,7 +9,8 @@ dat <- read.table(""http://pcl.missouri.edu/exp/effectSizePuzzler.txt"", header=TR
 # https://doi.org/10.3389/fpsyg.2013.00863
 # https://journals.sagepub.com/doi/pdf/10.1177/0013164403256358 (CIs)
 
-aggregate(dat$rt, dat['cond'], mean)
+# Are CIs correct?
+# Need to simulate data with a big subject:condition interaction.
 
 #' Single measurement:
 #' d - classic definition

---FILE: WIP/paired_d2.R---
@@ -7,6 +7,8 @@ paired_d <- function(x, group, block, data = NULL,
   data <- effectsize:::.kendalls_w_data(x, group, block, data, wide = FALSE)
   if (!is.factor(data$groups)) data$groups <- factor(data$groups)
   if (!is.factor(data$blocks)) data$blocks <- factor(data$blocks)
+  contrasts(data$groups) <- contr.treatment
+  contrasts(data$blocks) <- contr.treatment
   data <- na.omit(data)
 
   stopifnot(nlevels(data$groups) == 2L)
@@ -158,4 +160,12 @@ paired_d_av_rm <- function(data, type,
   attr(out, ""approximate"") <- FALSE
   attr(out, ""alternative"") <- alternative
   return(out)
-}
\ No newline at end of file
+}
+
+# .sample_within <- function(.data) {
+#   .data |>
+#     tidyr::nest(data = -id) |>
+#     dplyr::slice_sample(prop = 1, replace = TRUE) |>
+#     dplyr::mutate(id = seq_along(id)) |>
+#     tidyr::unnest(cols = data)
+# }

---FILE: WIP/sim CIs.R---
@@ -0,0 +1,48 @@
+library(dplyr)
+library(effectsize)
+
+source(""WIP/paired_d2.R"")
+
+set.seed(1)
+dat <- expand.grid(t = 1:100,
+                   id = letters[1:10],
+                   cond = LETTERS[1:2]) |>
+  as.data.frame() |>
+  select(-t) |>
+  mutate(
+    across(.fns = factor),
+    across(.fns = `contrasts<-`, value = contr.sum),
+    y = model.matrix(~ id * cond) %*%
+      c(0, c(scale(seq(0, 1, length = 9))), 0.9, c(scale(seq(0, 1, length = 9)))) +
+      rnorm(2000, sd = 0.85)
+  )
+
+# aov(y ~ cond + Error(id/cond), data = dat) |>
+#   parameters::model_parameters() |>
+#   as.data.frame()
+
+cohens_d(y ~ cond, data = d)
+paired_d(y ~ cond | id, data = d, type = ""d"") # 0.2497971
+paired_d(y ~ cond | id, data = d, type = ""r"") # 0.2587388
+
+
+paired_d(y ~ cond | id, data = d, type = ""a"") # 0.8357347
+paired_d(y ~ cond | id, data = d, type = ""z"") # 1.353713
+paired_d(y ~ cond | id, data = d, type = ""rm"")
+paired_d(y ~ cond | id, data = d, type = ""av"")
+
+B <- 200
+d <- numeric(B)
+
+for (b in seq_along(d)) {
+  d[b] <- paired_d(y ~ cond | id,
+                   data = .sample_within(dat),
+                   ci = NULL,
+                   type = ""r"")[[1]]
+}
+
+bayestestR::describe_posterior(d, test = NULL)
+
+paired_d(y ~ cond | id, data = dat,
+         type = ""r"")
+",True,False,Implementation / Logic,6
easystats,effectsize,4a8939fa36a58e5bf11c29fb0f9811d43d94fd39,Indrajeet Patil,patilindrajeet.science@gmail.com,2022-01-22T15:05:36Z,Indrajeet Patil,patilindrajeet.science@gmail.com,2022-01-22T15:05:36Z,"use data_rescale

https://github.com/easystats/datawizard/issues/53",NAMESPACE;NEWS.md;R/reexports.R;R/standardize.models.R;man/reexports.Rd,False,True,True,False,9,9,18,"---FILE: NAMESPACE---
@@ -63,7 +63,6 @@ export(F_to_f2)
 export(F_to_omega2)
 export(F_to_r)
 export(adjust)
-export(change_scale)
 export(chisq_to_cohens_w)
 export(chisq_to_cramers_v)
 export(chisq_to_pearsons_c)
@@ -95,6 +94,7 @@ export(d_to_cles)
 export(d_to_common_language)
 export(d_to_oddsratio)
 export(d_to_r)
+export(data_rescale)
 export(effectsize)
 export(epsilon_squared)
 export(equivalence_test)
@@ -195,7 +195,7 @@ export(z_to_r)
 importFrom(bayestestR,describe_posterior)
 importFrom(bayestestR,equivalence_test)
 importFrom(datawizard,adjust)
-importFrom(datawizard,change_scale)
+importFrom(datawizard,data_rescale)
 importFrom(datawizard,demean)
 importFrom(datawizard,normalize)
 importFrom(datawizard,ranktransform)

---FILE: NEWS.md---
@@ -42,7 +42,7 @@ See [*Support functions for model extensions* vignette](https://easystats.github
 - `interpret_d()`, `interpret_g()`, and `interpret_delta()` are now `interpret_cohens_d()`, `interpret_hedges_g()`, and `interpret_glass_delta()`.
 - `interpret_parameters()` was removed. Use `interpret_r()` instead (with caution!).
 - Phi, Cohen's *w*, Cramer's *V*, ANOVA effect sizes, rank Epsilon squared, Kendall's *W* - CIs default to 95% one-sided CIs (`alternative = ""greater""`). (To restore previous behavior, set `ci = .9, alternative = ""two.sided""`.)
-- `adjust()`, `change_scale()`, `normalize()`, `ranktransform()`, `standardize()` (data), and `unstandardize()` have moved to the new [`{datawizard}`](https://easystats.github.io/datawizard/) package!
+- `adjust()`, `data_rescale()`, `normalize()`, `ranktransform()`, `standardize()` (data), and `unstandardize()` have moved to the new [`{datawizard}`](https://easystats.github.io/datawizard/) package!
 
 ## New features
 

---FILE: R/reexports.R---
@@ -3,8 +3,8 @@
 datawizard::adjust
 
 #' @export
-#' @importFrom datawizard change_scale
-datawizard::change_scale
+#' @importFrom datawizard data_rescale
+datawizard::data_rescale
 
 #' @export
 #' @importFrom datawizard normalize

---FILE: R/standardize.models.R---
@@ -417,8 +417,8 @@ standardize.wbgee <- standardize.wbm
     temp_data_std <- m_data_std
   }
 
-  datawizard::change_scale(val,
+  datawizard::data_rescale(val,
                            to = range(temp_data_std[[cov_nm]]),
                            range = range(temp_data[[cov_nm]])
   )
-}
\ No newline at end of file
+}

---FILE: man/reexports.Rd---
@@ -5,7 +5,7 @@
 \alias{reexports}
 \alias{equivalence_test}
 \alias{adjust}
-\alias{change_scale}
+\alias{data_rescale}
 \alias{normalize}
 \alias{ranktransform}
 \alias{standardize}
@@ -19,6 +19,6 @@ below to see their documentation.
 \describe{
   \item{bayestestR}{\code{\link[bayestestR]{equivalence_test}}}
 
-  \item{datawizard}{\code{\link[datawizard]{adjust}}, \code{\link[datawizard:data_rescale]{change_scale}}, \code{\link[datawizard]{normalize}}, \code{\link[datawizard]{ranktransform}}, \code{\link[datawizard]{standardize}}, \code{\link[datawizard:standardize]{unstandardize}}}
+  \item{datawizard}{\code{\link[datawizard]{adjust}}, \code{\link[datawizard]{data_rescale}}, \code{\link[datawizard]{normalize}}, \code{\link[datawizard]{ranktransform}}, \code{\link[datawizard]{standardize}}, \code{\link[datawizard:standardize]{unstandardize}}}
 }}
 ",True,False,Documentation / Formatting,6
easystats,effectsize,8f28d9b9e57d73ab5e6adae4df3e7c99626717d3,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-01-14T11:59:19Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-01-14T11:59:19Z,fix more effing URLs,R/cohens_d.R;R/equivalence_test.R;README.Rmd;README.md;inst/CITATION;man/cohens_d.Rd;man/equivalence_test.effectsize_table.Rd,True,True,True,False,12,12,24,"---FILE: R/cohens_d.R---
@@ -117,7 +117,7 @@
 #'
 #' - Delacre, M., Lakens, D., Ley, C., Liu, L., & Leys, C. (2021, May 7). Why
 #' Hedgesâ g*s based on the non-pooled standard deviation should be reported
-#' with Welch's t-test. https://doi.org/10.31234/osf.io/tu6mp/
+#' with Welch's t-test. https://doi.org/10.31234/osf.io/tu6mp
 #'
 #' - Hedges, L. V. & Olkin, I. (1985). Statistical methods for
 #' meta-analysis. Orlando, FL: Academic Press.

---FILE: R/equivalence_test.R---
@@ -45,18 +45,18 @@ bayestestR::equivalence_test
 #' @references
 #' - Campbell, H., & Gustafson, P. (2018). Conditional equivalence testing: An
 #' alternative remedy for publication bias. PLOS ONE, 13(4), e0195145.
-#' https://doi.org/10.1371/journal.pone.0195145/
+#' https://doi.org/10.1371/journal.pone.0195145
 #'
 #' - Kruschke, J. K. (2014). Doing Bayesian data analysis: A tutorial with R,
 #' JAGS, and Stan. Academic Press
 #'
 #' - Kruschke, J. K. (2018). Rejecting or accepting parameter values in Bayesian
 #' estimation. Advances in Methods and Practices in Psychological Science, 1(2),
-#' 270-280. doi: 10.1177/2515245918771304/
+#' 270-280. doi: 10.1177/2515245918771304
 #'
 #' - Lakens, D. (2017). Equivalence Tests: A Practical Primer for t Tests,
 #' Correlations, and Meta-Analyses. Social Psychological and Personality
-#' Science, 8(4), 355â362. https://doi.org/10.1177/1948550617697177/
+#' Science, 8(4), 355â362. https://doi.org/10.1177/1948550617697177
 #'
 #' @examples
 #' \donttest{

---FILE: README.Rmd---
@@ -30,7 +30,7 @@ knitr::opts_chunk$set(
 set.seed(111)
 ```
 
-[![DOI](https://joss.theoj.org/papers/10.21105/joss.02815/status.svg/)](https://doi.org/10.21105/joss.02815/)
+[![DOI](https://joss.theoj.org/papers/10.21105/joss.02815/status.svg/)](https://doi.org/10.21105/joss.02815)
 [![downloads](https://cranlogs.r-pkg.org/badges/effectsize/)](https://cran.r-project.org/package=effectsize/)
 [![total](https://cranlogs.r-pkg.org/badges/grand-total/effectsize/)](https://cran.r-project.org/package=effectsize/)
 [![status](https://tinyverse.netlify.com/badge/effectsize/)](https://CRAN.R-project.org/package=effectsize/)
@@ -200,7 +200,7 @@ Corresponding BibTeX entry:
   pages = {2815},
   publisher = {The Open Journal},
   doi = {10.21105/joss.02815},
-  url = {https://doi.org/10.21105/joss.02815/}
+  url = {https://doi.org/10.21105/joss.02815}
 }
 ```
 

---FILE: README.md---
@@ -1,7 +1,7 @@
 
 # effectsize <img src=""man/figures/logo.png"" align=""right"" width=""120"" />
 
-[![DOI](https://joss.theoj.org/papers/10.21105/joss.02815/status.svg/)](https://doi.org/10.21105/joss.02815/)
+[![DOI](https://joss.theoj.org/papers/10.21105/joss.02815/status.svg/)](https://doi.org/10.21105/joss.02815)
 [![downloads](https://cranlogs.r-pkg.org/badges/effectsize/)](https://cran.r-project.org/package=effectsize/)
 [![total](https://cranlogs.r-pkg.org/badges/grand-total/effectsize/)](https://cran.r-project.org/package=effectsize/)
 [![status](https://tinyverse.netlify.com/badge/effectsize/)](https://CRAN.R-project.org/package=effectsize/)

---FILE: inst/CITATION---
@@ -18,5 +18,5 @@ bibentry(
   pages = ""2815"",
   publisher = ""The Open Journal"",
   doi = ""10.21105/joss.02815"",
-  url = ""https://doi.org/10.21105/joss.02815/""
+  url = ""https://doi.org/10.21105/joss.02815""
 )
\ No newline at end of file

---FILE: man/cohens_d.Rd---
@@ -211,7 +211,7 @@ Statistical Methods, 5(1), 2.
 sciences (2nd Ed.). New York: Routledge.
 \item Delacre, M., Lakens, D., Ley, C., Liu, L., & Leys, C. (2021, May 7). Why
 Hedgesâ g*s based on the non-pooled standard deviation should be reported
-with Welch's t-test. https://doi.org/10.31234/osf.io/tu6mp/
+with Welch's t-test. https://doi.org/10.31234/osf.io/tu6mp
 \item Hedges, L. V. & Olkin, I. (1985). Statistical methods for
 meta-analysis. Orlando, FL: Academic Press.
 \item Hunter, J. E., & Schmidt, F. L. (2004). Methods of meta-analysis:

---FILE: man/equivalence_test.effectsize_table.Rd---
@@ -88,15 +88,15 @@ if (require(see)) plot(equivalence_test(ds, range = 0.2, rule = ""bayes""))
 \itemize{
 \item Campbell, H., & Gustafson, P. (2018). Conditional equivalence testing: An
 alternative remedy for publication bias. PLOS ONE, 13(4), e0195145.
-https://doi.org/10.1371/journal.pone.0195145/
+https://doi.org/10.1371/journal.pone.0195145
 \item Kruschke, J. K. (2014). Doing Bayesian data analysis: A tutorial with R,
 JAGS, and Stan. Academic Press
 \item Kruschke, J. K. (2018). Rejecting or accepting parameter values in Bayesian
 estimation. Advances in Methods and Practices in Psychological Science, 1(2),
-270-280. doi: 10.1177/2515245918771304/
+270-280. doi: 10.1177/2515245918771304
 \item Lakens, D. (2017). Equivalence Tests: A Practical Primer for t Tests,
 Correlations, and Meta-Analyses. Social Psychological and Personality
-Science, 8(4), 355â362. https://doi.org/10.1177/1948550617697177/
+Science, 8(4), 355â362. https://doi.org/10.1177/1948550617697177
 }
 }
 \seealso{",True,True,Documentation / Formatting,6
easystats,effectsize,c6f9c44b407a4a2dce61d742309df113adfee7f0,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-01-13T18:28:01Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-01-13T18:28:01Z,fix urls,LICENSE;NEWS.md;R/cohens_d.R;R/convert_stat_to_anova.R;R/convert_stat_to_r.R;R/docs_extra.R;R/equivalence_test.R;R/eta_squared.R;R/interpret_omega_squared.R;R/interpret_rope.R;R/rank_effectsizes.R;README.Rmd;README.md;_pkgdown.yml;inst/CITATION;man/F_to_eta2.Rd;man/cohens_d.Rd;man/effectsize_API.Rd;man/equivalence_test.effectsize_table.Rd;man/interpret_omega_squared.Rd;man/interpret_rope.Rd;man/t_to_r.Rd;paper/paper.bib;paper/paper.md;vignettes/anovaES.Rmd;vignettes/bayesian_models.Rmd;vignettes/bibliography.bib;vignettes/effectsize.Rmd;vignettes/interpret.Rmd;vignettes/simple_htests.Rmd;vignettes/standardize_parameters.Rmd,True,True,True,False,92,91,183,"---FILE: LICENSE---
@@ -671,4 +671,4 @@ into proprietary programs.  If your program is a subroutine library, you
 may consider it more useful to permit linking proprietary applications with
 the library.  If this is what you want to do, use the GNU Lesser General
 Public License instead of this License.  But first, please read
-<https://www.gnu.org/licenses/why-not-lgpl.html>.
+<https://www.gnu.org/licenses/why-not-lgpl.html/>.

---FILE: NEWS.md---
@@ -8,7 +8,7 @@
 
 ### New API
 
-See [*Support functions for model extensions* vignette](https://easystats.github.io/effectsize/articles/effectsize_API.html).
+See [*Support functions for model extensions* vignette](https://easystats.github.io/effectsize/articles/effectsize_API.html/).
 
 ### Other features
 
@@ -45,7 +45,7 @@ See [*Support functions for model extensions* vignette](https://easystats.github
 - `oddsratio_to_riskratio()` can now convert OR coefficients to RR coefficients from a logistic GLM(M). 
 - All effect-size functions gain an `alternative` argument which can be used to make one- or two-sided CIs.
 - `interpret()` now accepts as input the results from `cohens_d()`, `eta_squared()`, `rank_biserial()`, etc.
-- `interpret_pd()` for the interpretation of the [*Probability of Direction*](https://easystats.github.io/bayestestR/reference/p_direction.html).
+- `interpret_pd()` for the interpretation of the [*Probability of Direction*](https://easystats.github.io/bayestestR/reference/p_direction.html/).
 
 ## Bug fixes
 

---FILE: R/cohens_d.R---
@@ -117,7 +117,7 @@
 #'
 #' - Delacre, M., Lakens, D., Ley, C., Liu, L., & Leys, C. (2021, May 7). Why
 #' Hedgesâ g*s based on the non-pooled standard deviation should be reported
-#' with Welch's t-test. https://doi.org/10.31234/osf.io/tu6mp
+#' with Welch's t-test. https://doi.org/10.31234/osf.io/tu6mp/
 #'
 #' - Hedges, L. V. & Olkin, I. (1985). Statistical methods for
 #' meta-analysis. Orlando, FL: Academic Press.

---FILE: R/convert_stat_to_anova.R---
@@ -10,7 +10,7 @@
 #' from `lm` and `aov` models, these functions give exact results. For all other
 #' cases, they return close approximations.
 #' \cr
-#' See [Effect Size from Test Statistics vignette.](https://easystats.github.io/effectsize/articles/from_test_statistics.html)
+#' See [Effect Size from Test Statistics vignette.](https://easystats.github.io/effectsize/articles/from_test_statistics.html/)
 #'
 #' @param t,f The t or the F statistics.
 #' @param df,df_error Degrees of freedom of numerator or of the error estimate

---FILE: R/convert_stat_to_r.R---
@@ -9,7 +9,7 @@
 #' computation is not straightforward (e.g., in liner mixed models, contrasts,
 #' etc.).
 #' \cr
-#' See [Effect Size from Test Statistics vignette.](https://easystats.github.io/effectsize/articles/from_test_statistics.html)
+#' See [Effect Size from Test Statistics vignette.](https://easystats.github.io/effectsize/articles/from_test_statistics.html/)
 #'
 #' @param t,f,z The t, the F or the z statistics.
 #' @param df,df_error Degrees of freedom of numerator or of the error estimate

---FILE: R/docs_extra.R---
@@ -145,7 +145,7 @@ NULL
 
 #' `effectsize` API
 #'
-#' Read the [*Support functions for model extensions*](https://easystats.github.io/effectsize/articles/effectsize_API.html) vignette.
+#' Read the [*Support functions for model extensions*](https://easystats.github.io/effectsize/articles/effectsize_API.html/) vignette.
 #'
 #' @rdname effectsize_API
 #' @name effectsize_API

---FILE: R/equivalence_test.R---
@@ -45,18 +45,18 @@ bayestestR::equivalence_test
 #' @references
 #' - Campbell, H., & Gustafson, P. (2018). Conditional equivalence testing: An
 #' alternative remedy for publication bias. PLOS ONE, 13(4), e0195145.
-#' https://doi.org/10.1371/journal.pone.0195145
+#' https://doi.org/10.1371/journal.pone.0195145/
 #'
 #' - Kruschke, J. K. (2014). Doing Bayesian data analysis: A tutorial with R,
 #' JAGS, and Stan. Academic Press
 #'
 #' - Kruschke, J. K. (2018). Rejecting or accepting parameter values in Bayesian
 #' estimation. Advances in Methods and Practices in Psychological Science, 1(2),
-#' 270-280. doi: 10.1177/2515245918771304
+#' 270-280. doi: 10.1177/2515245918771304/
 #'
 #' - Lakens, D. (2017). Equivalence Tests: A Practical Primer for t Tests,
 #' Correlations, and Meta-Analyses. Social Psychological and Personality
-#' Science, 8(4), 355â362. https://doi.org/10.1177/1948550617697177
+#' Science, 8(4), 355â362. https://doi.org/10.1177/1948550617697177/
 #'
 #' @examples
 #' \donttest{

---FILE: R/eta_squared.R---
@@ -584,7 +584,7 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
     Sum_Squares_Subjects <- SSS_values$Sum_Squares_residuals
     Mean_Squares_Subjects <- SSS_values$Mean_Square_residuals
 
-    # implemented from https://www.jasonfinley.com/tools/OmegaSquaredQuickRef_JRF_3-31-13.pdf
+    # implemented from https://www.jasonfinley.com/tools/OmegaSquaredQuickRef_JRF_3-31-13.pdf/
     if (!isTRUE(partial)) {
       aov_table$Omega2 <-
         (aov_table$Sum_Squares - aov_table$df * Mean_Square_residuals) /

---FILE: R/interpret_omega_squared.R---
@@ -21,7 +21,7 @@
 #' @examples
 #' interpret_eta_squared(.02)
 #' interpret_eta_squared(c(.5, .02), rules = ""cohen1992"")
-#' @seealso http://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/effectSize
+#' @seealso https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/effectSize/
 #'
 #'
 #' @references

---FILE: R/interpret_rope.R---
@@ -25,7 +25,7 @@
 #' interpret_rope(0, ci = 0.9)
 #' interpret_rope(c(0.005, 0.99), ci = 1)
 #' @references
-#' [BayestestR's reporting guidelines](https://easystats.github.io/bayestestR/articles/guidelines.html)
+#' [BayestestR's reporting guidelines](https://easystats.github.io/bayestestR/articles/guidelines.html/)
 #'
 #' @export
 interpret_rope <- function(rope, ci = 0.9, rules = ""default"") {

---FILE: R/rank_effectsizes.R---
@@ -235,7 +235,7 @@ rank_biserial <- function(x,
       nd <- sum((x - mu) != 0)
       maxw <- (nd^2 + nd) / 2
 
-      # From: https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test#Historical_T_statistic
+      # From: https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test#Historical_T_statistic/
       # wSE <- sqrt((n * (n + 1) * (2 * n + 1)) / 24)
       # Delta method for f(x) = w * 2 / (maxw) - 1
       # r_rbsSE <- wSE * sqrt(4 / (maxw)^2)
@@ -248,7 +248,7 @@ rank_biserial <- function(x,
       n1 <- length(x)
       n2 <- length(y)
 
-      # From: https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test#Normal_approximation_and_tie_correction
+      # From: https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test#Normal_approximation_and_tie_correction/
       # wSE <- sqrt((n1 * n2 * (n1 + n2 + 1)) / 12)
       # Delta method for f(x) = 1 - 2 * w / (n1 * n2) * sign(diff)
       # r_rbsSE <- wSE * sqrt(4 / (n1 * n2)^2)

---FILE: README.Rmd---
@@ -30,9 +30,10 @@ knitr::opts_chunk$set(
 set.seed(111)
 ```
 
-[![DOI](https://joss.theoj.org/papers/10.21105/joss.02815/status.svg)](https://doi.org/10.21105/joss.02815)
-[![downloads](http://cranlogs.r-pkg.org/badges/effectsize)](https://cran.r-project.org/package=effectsize)
-[![total](https://cranlogs.r-pkg.org/badges/grand-total/effectsize)](https://cran.r-project.org/package=effectsize) [![status](https://tinyverse.netlify.com/badge/effectsize)](https://CRAN.R-project.org/package=effectsize)
+[![DOI](https://joss.theoj.org/papers/10.21105/joss.02815/status.svg/)](https://doi.org/10.21105/joss.02815/)
+[![downloads](https://cranlogs.r-pkg.org/badges/effectsize/)](https://cran.r-project.org/package=effectsize/)
+[![total](https://cranlogs.r-pkg.org/badges/grand-total/effectsize/)](https://cran.r-project.org/package=effectsize/)
+[![status](https://tinyverse.netlify.com/badge/effectsize/)](https://CRAN.R-project.org/package=effectsize/)
 
 
 ***Significant is just not enough!***
@@ -42,22 +43,22 @@ The goal of this package is to provide utilities to work with indices of effect
 
 ## Installation
 
-[![CRAN](http://www.r-pkg.org/badges/version/effectsize)](https://cran.r-project.org/package=effectsize)
-[![effectsize status badge](https://easystats.r-universe.dev/badges/effectsize)](https://easystats.r-universe.dev)
-[![R-check](https://github.com/easystats/effectsize/workflows/R-check/badge.svg)](https://github.com/easystats/effectsize/actions)
-[![pkgdown](https://github.com/easystats/effectsize/workflows/pkgdown/badge.svg)](https://github.com/easystats/effectsize/actions)
-[![Codecov test coverage](https://codecov.io/gh/easystats/effectsize/branch/main/graph/badge.svg)](https://codecov.io/gh/easystats/effectsize?branch=main)
+[![CRAN](https://www.r-pkg.org/badges/version/effectsize/)](https://cran.r-project.org/package=effectsize/)
+[![effectsize status badge](https://easystats.r-universe.dev/badges/effectsize/)](https://easystats.r-universe.dev/)
+[![R-check](https://github.com/easystats/effectsize/workflows/R-check/badge.svg/)](https://github.com/easystats/effectsize/actions/)
+[![pkgdown](https://github.com/easystats/effectsize/workflows/pkgdown/badge.svg/)](https://github.com/easystats/effectsize/actions/)
+[![Codecov test coverage](https://codecov.io/gh/easystats/effectsize/branch/main/graph/badge.svg/)](https://app.codecov.io/gh/easystats/effectsize?branch=main/)
 
 Run the following to install the stable release of **effectsize** from CRAN:
 
 ```{r install-CRAN, warning=FALSE, message=FALSE, eval=FALSE}
 install.packages(""effectsize"")
 ```
 
-Or you can install the latest development version ``r available.packages(repos = ""https://easystats.r-universe.dev"")[""effectsize"",""Version""]`` from [*R-universe*](https://easystats.r-universe.dev):
+Or you can install the latest development version ``r available.packages(repos = ""https://easystats.r-universe.dev/"")[""effectsize"",""Version""]`` from [*R-universe*](https://easystats.r-universe.dev):
 
 ```{r install-R-universe, warning=FALSE, message=FALSE, eval=FALSE}
-install.packages(""effectsize"", repos = ""https://easystats.r-universe.dev"")
+install.packages(""effectsize"", repos = ""https://easystats.r-universe.dev/"")
 ```
 
 <!-- Or from *GitHub*: -->
@@ -69,27 +70,27 @@ install.packages(""effectsize"", repos = ""https://easystats.r-universe.dev"")
 
 ## Documentation
 
-[![Documentation](https://img.shields.io/badge/documentation-effectsize-orange.svg?colorB=E91E63)](https://easystats.github.io/effectsize/)
-[![Blog](https://img.shields.io/badge/blog-easystats-orange.svg?colorB=FF9800)](https://easystats.github.io/blog/posts/)
-[![Features](https://img.shields.io/badge/features-effectsize-orange.svg?colorB=2196F3)](https://easystats.github.io/effectsize/reference/index.html)
+[![Documentation](https://img.shields.io/badge/documentation-effectsize-orange.svg?colorB=E91E63/)](https://easystats.github.io/effectsize/)
+[![Blog](https://img.shields.io/badge/blog-easystats-orange.svg?colorB=FF9800/)](https://easystats.github.io/blog/posts/)
+[![Features](https://img.shields.io/badge/features-effectsize-orange.svg?colorB=2196F3/)](https://easystats.github.io/effectsize/reference/index.html/)
 
 Click on the buttons above to access the package [**documentation**](https://easystats.github.io/effectsize/) and the [**easystats blog**](https://easystats.github.io/blog/posts/), and check-out these vignettes:
 
 - **Effect Sizes**  
-  - [**Parameter and Model Standardization**](https://easystats.github.io/effectsize/articles/standardize_parameters.html)
-  - [**ANOVA Effect Sizes**](https://easystats.github.io/effectsize/articles/anovaES.html)
-  - [**Effect Sizes in Bayesian Models**](https://easystats.github.io/effectsize/articles/bayesian_models.html)  
-  - [**For Simple Hypothesis Tests**](https://easystats.github.io/effectsize/articles/simple_htests.html)  
+  - [**Parameter and Model Standardization**](https://easystats.github.io/effectsize/articles/standardize_parameters.html/)
+  - [**ANOVA Effect Sizes**](https://easystats.github.io/effectsize/articles/anovaES.html/)
+  - [**Effect Sizes in Bayesian Models**](https://easystats.github.io/effectsize/articles/bayesian_models.html/)  
+  - [**For Simple Hypothesis Tests**](https://easystats.github.io/effectsize/articles/simple_htests.html/)  
 - **Effect Sizes Conversion**    
-  - [**Between Effect Sizes**](https://easystats.github.io/effectsize/articles/convert.html)
-  - [**Effect Size from Test Statistics**](https://easystats.github.io/effectsize/articles/from_test_statistics.html)
-- [**Automated Interpretation of Indices of Effect Size**](https://easystats.github.io/effectsize/articles/interpret.html)
+  - [**Between Effect Sizes**](https://easystats.github.io/effectsize/articles/convert.html/)
+  - [**Effect Size from Test Statistics**](https://easystats.github.io/effectsize/articles/from_test_statistics.html/)
+- [**Automated Interpretation of Indices of Effect Size**](https://easystats.github.io/effectsize/articles/interpret.html/)
 
 
 
 # Features
 
-This package is focused on indices of effect size. Check out the package website for [**a full list of features and functions** provided by `effectsize`](https://easystats.github.io/effectsize/reference/index.html).
+This package is focused on indices of effect size. Check out the package website for [**a full list of features and functions** provided by `effectsize`](https://easystats.github.io/effectsize/reference/index.html/).
 
 ```{r load, message=FALSE, warning=FALSE}
 library(effectsize)
@@ -128,7 +129,7 @@ And more...
 
 ### Regression Models (Standardized Parameters)
 
-Importantly, `effectsize` also provides [advanced methods](https://easystats.github.io/effectsize/articles/standardize_parameters.html) to compute standardized parameters for regression models.
+Importantly, `effectsize` also provides [advanced methods](https://easystats.github.io/effectsize/articles/standardize_parameters.html/) to compute standardized parameters for regression models.
 
 ```{r beta, warning=FALSE, message=FALSE}
 m <- lm(rating ~ complaints + privileges + advance, data = attitude)
@@ -170,7 +171,7 @@ The package allows for an automated interpretation of different indices.
 interpret_r(r = 0.3)
 ```
 
-Different sets of ""rules of thumb"" are implemented ([**guidelines are detailed here**](https://easystats.github.io/effectsize/articles/interpret.html)) and can be easily changed.
+Different sets of ""rules of thumb"" are implemented ([**guidelines are detailed here**](https://easystats.github.io/effectsize/articles/interpret.html/)) and can be easily changed.
 
 
 ```{r interp-d, warning=FALSE, message=FALSE}
@@ -199,10 +200,10 @@ Corresponding BibTeX entry:
   pages = {2815},
   publisher = {The Open Journal},
   doi = {10.21105/joss.02815},
-  url = {https://doi.org/10.21105/joss.02815}
+  url = {https://doi.org/10.21105/joss.02815/}
 }
 ```
 
 # Contributing and Support
 
-If you have any questions regarding the the functionality of the package, you may either contact us via email or also [file an issue](https://github.com/easystats/effectsize/issues). Anyone wishing to contribute to the package by adding functions, features, or in another way, please follow [this guide](https://github.com/easystats/effectsize/blob/main/.github/CONTRIBUTING.md) and our [code of conduct](https://github.com/easystats/effectsize/blob/main/.github/CODE_OF_CONDUCT.md).
+If you have any questions regarding the the functionality of the package, you may either contact us via email or also [file an issue](https://github.com/easystats/effectsize/issues/). Anyone wishing to contribute to the package by adding functions, features, or in another way, please follow [this guide](https://github.com/easystats/effectsize/blob/main/.github/CONTRIBUTING.md/) and our [code of conduct](https://github.com/easystats/effectsize/blob/main/.github/CODE_OF_CONDUCT.md/).

---FILE: README.md---
@@ -1,10 +1,10 @@
 
 # effectsize <img src=""man/figures/logo.png"" align=""right"" width=""120"" />
 
-[![DOI](https://joss.theoj.org/papers/10.21105/joss.02815/status.svg)](https://doi.org/10.21105/joss.02815)
-[![downloads](http://cranlogs.r-pkg.org/badges/effectsize)](https://cran.r-project.org/package=effectsize)
-[![total](https://cranlogs.r-pkg.org/badges/grand-total/effectsize)](https://cran.r-project.org/package=effectsize)
-[![status](https://tinyverse.netlify.com/badge/effectsize)](https://CRAN.R-project.org/package=effectsize)
+[![DOI](https://joss.theoj.org/papers/10.21105/joss.02815/status.svg/)](https://doi.org/10.21105/joss.02815/)
+[![downloads](https://cranlogs.r-pkg.org/badges/effectsize/)](https://cran.r-project.org/package=effectsize/)
+[![total](https://cranlogs.r-pkg.org/badges/grand-total/effectsize/)](https://cran.r-project.org/package=effectsize/)
+[![status](https://tinyverse.netlify.com/badge/effectsize/)](https://CRAN.R-project.org/package=effectsize/)
 
 ***Significant is just not enough\!***
 
@@ -14,7 +14,7 @@ conversion of indices such as Cohenâs *d*, *r*, odds-ratios, etc.
 
 ## Installation
 
-[![CRAN](http://www.r-pkg.org/badges/version/effectsize)](https://cran.r-project.org/package=effectsize)
+[![CRAN](https://www.r-pkg.org/badges/version/effectsize)](https://cran.r-project.org/package=effectsize)
 [![effectsize status
 badge](https://easystats.r-universe.dev/badges/effectsize)](https://easystats.r-universe.dev)
 [![R-check](https://github.com/easystats/effectsize/workflows/R-check/badge.svg)](https://github.com/easystats/effectsize/actions)

---FILE: _pkgdown.yml---
@@ -1,10 +1,10 @@
 authors:
   Mattan S. Ben-Shachar:
-    href: https://github.com/mattansb
+    href: https://github.com/mattansb/
   Dominique Makowski:
     href: https://dominiquemakowski.github.io/
   Daniel LÃ¼decke:
-    href: https://github.com/strengejacke
+    href: https://github.com/strengejacke/
   Indrajeet Patil:
     href: https://sites.google.com/site/indrajeetspatilmorality/
   Brenton M. Wiernik:
@@ -24,7 +24,7 @@ navbar:
   components:
     twitter:
       icon: fa-twitter
-      href: http://twitter.com/easystats4u
+      href: https://twitter.com/easystats4u
       aria-label: Twitter
   left:
     - icon: fa-home fa-lg

---FILE: inst/CITATION---
@@ -18,5 +18,5 @@ bibentry(
   pages = ""2815"",
   publisher = ""The Open Journal"",
   doi = ""10.21105/joss.02815"",
-  url = ""https://doi.org/10.21105/joss.02815""
+  url = ""https://doi.org/10.21105/joss.02815/""
 )
\ No newline at end of file

---FILE: man/F_to_eta2.Rd---
@@ -92,7 +92,7 @@ Squares are not easily available or their computation is not straightforward
 from \code{lm} and \code{aov} models, these functions give exact results. For all other
 cases, they return close approximations.
 \cr
-See \href{https://easystats.github.io/effectsize/articles/from_test_statistics.html}{Effect Size from Test Statistics vignette.}
+See \href{https://easystats.github.io/effectsize/articles/from_test_statistics.html/}{Effect Size from Test Statistics vignette.}
 }
 \details{
 These functions use the following formulae:

---FILE: man/cohens_d.Rd---
@@ -211,7 +211,7 @@ Statistical Methods, 5(1), 2.
 sciences (2nd Ed.). New York: Routledge.
 \item Delacre, M., Lakens, D., Ley, C., Liu, L., & Leys, C. (2021, May 7). Why
 Hedgesâ g*s based on the non-pooled standard deviation should be reported
-with Welch's t-test. https://doi.org/10.31234/osf.io/tu6mp
+with Welch's t-test. https://doi.org/10.31234/osf.io/tu6mp/
 \item Hedges, L. V. & Olkin, I. (1985). Statistical methods for
 meta-analysis. Orlando, FL: Academic Press.
 \item Hunter, J. E., & Schmidt, F. L. (2004). Methods of meta-analysis:

---FILE: man/effectsize_API.Rd---
@@ -54,5 +54,5 @@
 including the grouping variable (e.g., \code{""Subject""}).}
 }
 \description{
-Read the \href{https://easystats.github.io/effectsize/articles/effectsize_API.html}{\emph{Support functions for model extensions}} vignette.
+Read the \href{https://easystats.github.io/effectsize/articles/effectsize_API.html/}{\emph{Support functions for model extensions}} vignette.
 }

---FILE: man/equivalence_test.effectsize_table.Rd---
@@ -88,15 +88,15 @@ if (require(see)) plot(equivalence_test(ds, range = 0.2, rule = ""bayes""))
 \itemize{
 \item Campbell, H., & Gustafson, P. (2018). Conditional equivalence testing: An
 alternative remedy for publication bias. PLOS ONE, 13(4), e0195145.
-https://doi.org/10.1371/journal.pone.0195145
+https://doi.org/10.1371/journal.pone.0195145/
 \item Kruschke, J. K. (2014). Doing Bayesian data analysis: A tutorial with R,
 JAGS, and Stan. Academic Press
 \item Kruschke, J. K. (2018). Rejecting or accepting parameter values in Bayesian
 estimation. Advances in Methods and Practices in Psychological Science, 1(2),
-270-280. doi: 10.1177/2515245918771304
+270-280. doi: 10.1177/2515245918771304/
 \item Lakens, D. (2017). Equivalence Tests: A Practical Primer for t Tests,
 Correlations, and Meta-Analyses. Social Psychological and Personality
-Science, 8(4), 355â362. https://doi.org/10.1177/1948550617697177
+Science, 8(4), 355â362. https://doi.org/10.1177/1948550617697177/
 }
 }
 \seealso{

---FILE: man/interpret_omega_squared.Rd---
@@ -55,5 +55,5 @@ Edition. Sage:London.
 }
 }
 \seealso{
-http://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/effectSize
+https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/effectSize/
 }

---FILE: man/interpret_rope.Rd---
@@ -44,5 +44,5 @@ interpret_rope(0, ci = 0.9)
 interpret_rope(c(0.005, 0.99), ci = 1)
 }
 \references{
-\href{https://easystats.github.io/bayestestR/articles/guidelines.html}{BayestestR's reporting guidelines}
+\href{https://easystats.github.io/bayestestR/articles/guidelines.html/}{BayestestR's reporting guidelines}
 }

---FILE: man/t_to_r.Rd---
@@ -71,7 +71,7 @@ the data required to compute these are not easily available or their
 computation is not straightforward (e.g., in liner mixed models, contrasts,
 etc.).
 \cr
-See \href{https://easystats.github.io/effectsize/articles/from_test_statistics.html}{Effect Size from Test Statistics vignette.}
+See \href{https://easystats.github.io/effectsize/articles/from_test_statistics.html/}{Effect Size from Test Statistics vignette.}
 }
 \details{
 These functions use the following formulae to approximate \emph{r} and \emph{d}:

---FILE: paper/paper.bib---
@@ -79,7 +79,7 @@ @article{patil2020ggstatsplot
   author = {Indrajeet Patil},
   year = {2018},
   journal = {CRAN},
-  url = {https://CRAN.R-project.org/package=ggstatsplot},
+  url = {https://CRAN.R-project.org/package=ggstatsplot/},
   doi = {10.5281/zenodo.2074621},
 }
 
@@ -88,7 +88,7 @@ @manual{sjoberg2020gtsummary
   author = {Daniel D. Sjoberg and Michael Curry and Margie Hannum and Karissa Whiting and Emily C. Zabor},
   year = {2020},
   note = {R package version 1.3.5},
-  url = {https://CRAN.R-project.org/package=gtsummary},
+  url = {https://CRAN.R-project.org/package=gtsummary/},
 }
 
 @article{luedecke2019insight,
@@ -107,23 +107,23 @@ @manual{behrendt2014lmbeta
   author = {Stefan Behrendt},
   year = {2014},
   note = {R package version 1.5-1},
-  url = {https://CRAN.R-project.org/package=lm.beta},
+  url = {https://CRAN.R-project.org/package=lm.beta/},
 }
 
 @manual{buchanan2019MOTE,
   title = {{MOTE: Measure of the Effect}: Package to assist in effect size calculations and their confidence intervals},
   author = {Erin M. Buchanan and Amber Gillenwaters and John E. Scofield and K.D. Valentine},
   year = {2019},
   note = {R package version 1.0.2},
-  url = {http://github.com/doomlab/MOTE},
+  url = {https://github.com/doomlab/MOTE/},
 }
 
 @manual{kelley2020MBESS,
   title = {MBESS: The MBESS {R} Package},
   author = {Ken Kelley},
   year = {2020},
   note = {R package version 4.8.0},
-  url = {https://CRAN.R-project.org/package=MBESS},
+  url = {https://CRAN.R-project.org/package=MBESS/},
 }
 
 @book{cohen1988statistical,

---FILE: paper/paper.md---
@@ -47,7 +47,7 @@ In both theoretical and applied research, it is often of interest to assess the
 
 # Examples of Features
 
-**effectsize** provides various functions for extracting and estimating effect sizes and their confidence intervals [estimated using the noncentrality parameter method; @steiger2004beyond]. In this article, we provide basic usage examples for estimating some of the most common effect size. A comprehensive overview, including in-depth examples and [a full list of features and functions](https://easystats.github.io/effectsize/reference/index.html), are accessible via a dedicated website (https://easystats.github.io/effectsize/).
+**effectsize** provides various functions for extracting and estimating effect sizes and their confidence intervals [estimated using the noncentrality parameter method; @steiger2004beyond]. In this article, we provide basic usage examples for estimating some of the most common effect size. A comprehensive overview, including in-depth examples and [a full list of features and functions](https://easystats.github.io/effectsize/reference/index.html/), are accessible via a dedicated website (https://easystats.github.io/effectsize/).
 
 ## Indices of Effect Size
 
@@ -125,7 +125,7 @@ standardize_parameters(model, exponentiate = TRUE)
 #> # Standardization method: refit
 ```
 
-`standardize_parameters()` provides several standardization methods, such as robust standardization, or *pseudo*-standardized coefficients for (generalized) linear mixed models [@hoffman2015longitudinal]. A full review of these methods can be found in the [*Parameter and Model Standardization* vignette](https://easystats.github.io/effectsize/articles/standardize_parameters.html).
+`standardize_parameters()` provides several standardization methods, such as robust standardization, or *pseudo*-standardized coefficients for (generalized) linear mixed models [@hoffman2015longitudinal]. A full review of these methods can be found in the [*Parameter and Model Standardization* vignette](https://easystats.github.io/effectsize/articles/standardize_parameters.html/).
 
 ## Effect Sizes for ANOVAs
 
@@ -158,7 +158,7 @@ eta_squared(model, generalized = ""Time"")
 #> Chick:Time | Diet:Time |               0.03 | [0.00, 0.00]
 ```
 
-**effectsize** also offers $\epsilon^2_p$ (`epsilon_squared()`) and $\omega^2_p$ (`omega_squared()`), which are less biased estimates of the variance explained in the population [@kelley1935unbiased; @olejnik2003generalized]. For more details about the various effect size measures and their applications, see the [*Effect sizes for ANOVAs* vignette](https://easystats.github.io/effectsize/articles/anovaES.html).
+**effectsize** also offers $\epsilon^2_p$ (`epsilon_squared()`) and $\omega^2_p$ (`omega_squared()`), which are less biased estimates of the variance explained in the population [@kelley1935unbiased; @olejnik2003generalized]. For more details about the various effect size measures and their applications, see the [*Effect sizes for ANOVAs* vignette](https://easystats.github.io/effectsize/articles/anovaES.html/).
 
 ## Effect Size Conversion
 
@@ -225,7 +225,7 @@ oddsratio_to_r(34.99)
 
 ## Effect Size Interpretation
 
-Finally, **effectsize** provides convenience functions to apply existing or custom interpretation rules of thumb, such as for instance Cohen's (1988). Although we strongly advocate for the cautious and parsimonious use of such judgment-replacing tools, we provide these functions to allow users and developers to explore and hopefully gain a deeper understanding of the relationship between data values and their interpretation. More information is available in the [*Automated Interpretation of Indices of Effect Size* vignette](https://easystats.github.io/effectsize/articles/interpret.html).
+Finally, **effectsize** provides convenience functions to apply existing or custom interpretation rules of thumb, such as for instance Cohen's (1988). Although we strongly advocate for the cautious and parsimonious use of such judgment-replacing tools, we provide these functions to allow users and developers to explore and hopefully gain a deeper understanding of the relationship between data values and their interpretation. More information is available in the [*Automated Interpretation of Indices of Effect Size* vignette](https://easystats.github.io/effectsize/articles/interpret.html/).
 
 ``` r
 interpret_d(c(0.02, 0.52, 0.86), rules = ""cohen1988"")
@@ -236,10 +236,10 @@ interpret_d(c(0.02, 0.52, 0.86), rules = ""cohen1988"")
 
 # Licensing and Availability
 
-**effectsize** is licensed under the GNU General Public License (v3.0), with all source code stored at GitHub (https://github.com/easystats/effectsize), and with a corresponding issue tracker for bug reporting and feature enhancements. In the spirit of honest and open science, we encourage requests/tips for fixes, feature updates, as well as general questions and concerns via direct interaction with contributors and developers, by [filing an issue](https://github.com/easystats/effectsize/issues). See the package's [*Contribution Guidelines*](https://github.com/easystats/effectsize/blob/main/.github/CONTRIBUTING.md).
+**effectsize** is licensed under the GNU General Public License (v3.0), with all source code stored at GitHub (https://github.com/easystats/effectsize), and with a corresponding issue tracker for bug reporting and feature enhancements. In the spirit of honest and open science, we encourage requests/tips for fixes, feature updates, as well as general questions and concerns via direct interaction with contributors and developers, by [filing an issue](https://github.com/easystats/effectsize/issues/). See the package's [*Contribution Guidelines*](https://github.com/easystats/effectsize/blob/main/.github/CONTRIBUTING.md/).
 
 # Acknowledgments
 
-**effectsize** is part of the [*easystats*](https://github.com/easystats/easystats) ecosystem, a collaborative project created to facilitate the usage of R for statistical analyses. Thus, we would like to thank the [members of easystats](https://github.com/orgs/easystats/people) as well as the users.
+**effectsize** is part of the [*easystats*](https://github.com/easystats/easystats/) ecosystem, a collaborative project created to facilitate the usage of R for statistical analyses. Thus, we would like to thank the [members of easystats](https://github.com/orgs/easystats/people/) as well as the users.
 
 # References

---FILE: vignettes/anovaES.Rmd---
@@ -31,7 +31,7 @@ if (!all(sapply(pkgs, require, quietly = TRUE, character.only = TRUE))) {
 
 ## Eta<sup>2</sup>
 
-In the context of ANOVA-like tests, it is common to report ANOVA-like effect sizes. Unlike [standardized parameters](https://easystats.github.io/effectsize/articles/standardize_parameters.html), these effect sizes represent the amount of variance explained by each of the model's terms, where each term can be represented by 1 *or more* parameters.
+In the context of ANOVA-like tests, it is common to report ANOVA-like effect sizes. Unlike [standardized parameters](https://easystats.github.io/effectsize/articles/standardize_parameters.html/), these effect sizes represent the amount of variance explained by each of the model's terms, where each term can be represented by 1 *or more* parameters.
 
 For example, in the following case, the parameters for the `treatment` term represent specific contrasts between the factor's levels (treatment groups) - the difference between each level and the reference level (`obk.long == 'control'`).
 
@@ -231,7 +231,7 @@ repeated-measures ANOVA's - cases where the *SS*s are readily available, and so
 the various effect sized presented can easily be estimated. How ever this is not
 always the case.
 
-For example, in linear mixed models (LMM/HLM/MLM), the estimation of all required *SS*s is not straightforward. However, we can still *approximate* these effect sizes (only their partial versions) based on the **test-statistic approximation method** (learn more in the [*Effect Size from Test Statistics* vignette](https://easystats.github.io/effectsize/articles/from_test_statistics.html)).
+For example, in linear mixed models (LMM/HLM/MLM), the estimation of all required *SS*s is not straightforward. However, we can still *approximate* these effect sizes (only their partial versions) based on the **test-statistic approximation method** (learn more in the [*Effect Size from Test Statistics* vignette](https://easystats.github.io/effectsize/articles/from_test_statistics.html/)).
 
 ```{r, eval=require(lmerTest)}
 library(lmerTest)
@@ -252,7 +252,7 @@ epsilon_squared(fit_lmm)
 omega_squared(fit_lmm)
 ```
 
-Another case where *SS*s are not available is when use Bayesian models. `effectsize` has Bayesian solutions for Bayesian models, about which you can read in the [*Effect Sizes for Bayesian Models* vignette](https://easystats.github.io/effectsize/articles/bayesian_models.html).
+Another case where *SS*s are not available is when use Bayesian models. `effectsize` has Bayesian solutions for Bayesian models, about which you can read in the [*Effect Sizes for Bayesian Models* vignette](https://easystats.github.io/effectsize/articles/bayesian_models.html/).
 
 
 # References

---FILE: vignettes/bayesian_models.Rmd---
@@ -74,7 +74,7 @@ compliments, years), so comparing them is hard when looking at the raw data.
 This is where standardization comes in.
 
 Like with [frequentists
-models](https://easystats.github.io/effectsize/articles/standardize_parameters.html)
+models](https://easystats.github.io/effectsize/articles/standardize_parameters.html/)
 we can choose from the same standardization methods. Let's use the (slow)
 `""refit""` method.
 
@@ -130,7 +130,7 @@ sampling from the PPD, we can generate a posterior distribution of explained
 variance estimates. But note that **these estimates are conditioned not only on
 the location-parameters of the model, but also on the scale-parameters of the
 model!** So it is vital to [validate the
-PPD](https://mc-stan.org/docs/2_23/stan-users-guide/meta-models-part.html#meta-models.part)
+PPD](https://mc-stan.org/docs/2_23/stan-users-guide/meta-models-part.html#meta-models.part/)
 before using it to estimate explained variance measures.
 
 ### Setup

---FILE: vignettes/bibliography.bib---
@@ -468,7 +468,7 @@ @article{patil2020ggstatsplot
   author = {Indrajeet Patil},
   year = {2018},
   journal = {CRAN},
-  url = {https://CRAN.R-project.org/package=ggstatsplot},
+  url = {https://CRAN.R-project.org/package=ggstatsplot/},
   doi = {10.5281/zenodo.2074621},
 }
 
@@ -477,31 +477,31 @@ @manual{sjoberg2020gtsummary
   author = {Daniel D. Sjoberg and Michael Curry and Margie Hannum and Karissa Whiting and Emily C. Zabor},
   year = {2020},
   note = {R package version 1.3.5},
-  url = {https://CRAN.R-project.org/package=gtsummary},
+  url = {https://CRAN.R-project.org/package=gtsummary/},
 }
 
 @manual{behrendt2014lmbeta,
   title = {{l}m.beta: Add Standardized Regression Coefficients to lm-Objects},
   author = {Stefan Behrendt},
   year = {2014},
   note = {R package version 1.5-1},
-  url = {https://CRAN.R-project.org/package=lm.beta},
+  url = {https://CRAN.R-project.org/package=lm.beta/},
 }
 
 @manual{buchanan2019MOTE,
   title = {{MOTE: Measure of the Effect}: Package to assist in effect size calculations and their confidence intervals},
   author = {Erin M. Buchanan and Amber Gillenwaters and John E. Scofield and K.D. Valentine},
   year = {2019},
   note = {R package version 1.0.2},
-  url = {http://github.com/doomlab/MOTE},
+  url = {https://github.com/doomlab/MOTE/},
 }
 
 @manual{kelley2020MBESS,
   title = {MBESS: The MBESS {R} Package},
   author = {Ken Kelley},
   year = {2020},
   note = {R package version 4.8.0},
-  url = {https://CRAN.R-project.org/package=MBESS},
+  url = {https://CRAN.R-project.org/package=MBESS/},
 }
 
 @article{steiger2004beyond,

---FILE: vignettes/effectsize.Rmd---
@@ -36,7 +36,7 @@ In both theoretical and applied research, it is often of interest to assess the
 
 # Examples of Features
 
-**effectsize** provides various functions for extracting and estimating effect sizes and their confidence intervals [estimated using the noncentrality parameter method; @steiger2004beyond]. In this article, we provide basic usage examples for estimating some of the most common effect size. A comprehensive overview, including in-depth examples and [a full list of features and functions](https://easystats.github.io/effectsize/reference/index.html), are accessible via a dedicated website (https://easystats.github.io/effectsize/).
+**effectsize** provides various functions for extracting and estimating effect sizes and their confidence intervals [estimated using the noncentrality parameter method; @steiger2004beyond]. In this article, we provide basic usage examples for estimating some of the most common effect size. A comprehensive overview, including in-depth examples and [a full list of features and functions](https://easystats.github.io/effectsize/reference/index.html/), are accessible via a dedicated website (https://easystats.github.io/effectsize/).
 
 ## Indices of Effect Size
 
@@ -85,7 +85,7 @@ model <- glm(am ~ cyl + hp,
 standardize_parameters(model, exponentiate = TRUE)
 ```
 
-`standardize_parameters()` provides several standardization methods, such as robust standardization, or *pseudo*-standardized coefficients for (generalized) linear mixed models [@hoffman2015longitudinal]. A full review of these methods can be found in the [*Parameter and Model Standardization* vignette](https://easystats.github.io/effectsize/articles/standardize_parameters.html).
+`standardize_parameters()` provides several standardization methods, such as robust standardization, or *pseudo*-standardized coefficients for (generalized) linear mixed models [@hoffman2015longitudinal]. A full review of these methods can be found in the [*Parameter and Model Standardization* vignette](https://easystats.github.io/effectsize/articles/standardize_parameters.html/).
 
 ## Effect Sizes for ANOVAs
 
@@ -107,7 +107,7 @@ eta_squared(model, partial = TRUE)
 eta_squared(model, generalized = ""Time"")
 ```
 
-**effectsize** also offers $\epsilon^2_p$ (`epsilon_squared()`) and $\omega^2_p$ (`omega_squared()`), which are less biased estimates of the variance explained in the population [@kelley1935unbiased; @olejnik2003generalized]. For more details about the various effect size measures and their applications, see the [*Effect sizes for ANOVAs* vignette](https://easystats.github.io/effectsize/articles/anovaES.html).
+**effectsize** also offers $\epsilon^2_p$ (`epsilon_squared()`) and $\omega^2_p$ (`omega_squared()`), which are less biased estimates of the variance explained in the population [@kelley1935unbiased; @olejnik2003generalized]. For more details about the various effect size measures and their applications, see the [*Effect sizes for ANOVAs* vignette](https://easystats.github.io/effectsize/articles/anovaES.html/).
 
 ## Effect Size Conversion
 
@@ -156,7 +156,7 @@ oddsratio_to_r(34.99)
 
 ## Effect Size Interpretation
 
-Finally, **effectsize** provides convenience functions to apply existing or custom interpretation rules of thumb, such as for instance Cohen's (1988). Although we strongly advocate for the cautious and parsimonious use of such judgment-replacing tools, we provide these functions to allow users and developers to explore and hopefully gain a deeper understanding of the relationship between data values and their interpretation. More information is available in the [*Automated Interpretation of Indices of Effect Size* vignette](https://easystats.github.io/effectsize/articles/interpret.html).
+Finally, **effectsize** provides convenience functions to apply existing or custom interpretation rules of thumb, such as for instance Cohen's (1988). Although we strongly advocate for the cautious and parsimonious use of such judgment-replacing tools, we provide these functions to allow users and developers to explore and hopefully gain a deeper understanding of the relationship between data values and their interpretation. More information is available in the [*Automated Interpretation of Indices of Effect Size* vignette](https://easystats.github.io/effectsize/articles/interpret.html/).
 
 ```{r}
 interpret_cohens_d(c(0.02, 0.52, 0.86), rules = ""cohen1988"")
@@ -165,10 +165,10 @@ interpret_cohens_d(c(0.02, 0.52, 0.86), rules = ""cohen1988"")
 
 # Licensing and Availability
 
-**effectsize** is licensed under the GNU General Public License (v3.0), with all source code stored at GitHub (https://github.com/easystats/effectsize), and with a corresponding issue tracker for bug reporting and feature enhancements. In the spirit of honest and open science, we encourage requests/tips for fixes, feature updates, as well as general questions and concerns via direct interaction with contributors and developers, by [filing an issue](https://github.com/easystats/effectsize/issues). See the package's [*Contribution Guidelines*](https://github.com/easystats/effectsize/blob/main/.github/CONTRIBUTING.md).
+**effectsize** is licensed under the GNU General Public License (v3.0), with all source code stored at GitHub (https://github.com/easystats/effectsize), and with a corresponding issue tracker for bug reporting and feature enhancements. In the spirit of honest and open science, we encourage requests/tips for fixes, feature updates, as well as general questions and concerns via direct interaction with contributors and developers, by [filing an issue](https://github.com/easystats/effectsize/issues/). See the package's [*Contribution Guidelines*](https://github.com/easystats/effectsize/blob/main/.github/CONTRIBUTING.md/).
 
 # Acknowledgments
 
-**effectsize** is part of the [*easystats*](https://github.com/easystats/easystats) ecosystem, a collaborative project created to facilitate the usage of R for statistical analyses. Thus, we would like to thank the [members of easystats](https://github.com/orgs/easystats/people) as well as the users.
+**effectsize** is part of the [*easystats*](https://github.com/easystats/easystats/) ecosystem, a collaborative project created to facilitate the usage of R for statistical analyses. Thus, we would like to thank the [members of easystats](https://github.com/orgs/easystats/people/) as well as the users.
 
 # References

---FILE: vignettes/interpret.Rmd---
@@ -235,7 +235,7 @@ can be used as indices of effect size. Note that the (log) odds ratio from
 logistic regression coefficients are *unstandardized*, as they depend on the
 scale of the predictor. In order to apply the following guidelines, make sure
 you
-[*standardize*](https://easystats.github.io/effectsize/articles/standardize_parameters.html)
+[*standardize*](https://easystats.github.io/effectsize/articles/standardize_parameters.html/)
 your predictors!
 
 Keep in mind that these apply to Odds *ratios*, so Odds ratio of 10 is as

---FILE: vignettes/simple_htests.Rmd---
@@ -126,7 +126,7 @@ effectsize(BFt, test = NULL)
 ## One way ANOVA
 
 For more details, see [ANOVA
-vignette](https://easystats.github.io/effectsize/articles/anovaES.html).
+vignette](https://easystats.github.io/effectsize/articles/anovaES.html/).
 
 ```{r, message=FALSE}
 onew <- oneway.test(mpg ~ gear, data = mtcars, var.equal = TRUE)

---FILE: vignettes/standardize_parameters.Rmd---
@@ -40,7 +40,7 @@ within and between models, variables and studies. Moreover, as it returns
 coefficients expressed in terms of **change of variance** (for instance,
 coefficients expressed in terms of SD of the response variable), it can allow
 for the usage of [effect size interpretation
-guidelines](https://easystats.github.io/effectsize/articles/interpret.html),
+guidelines](https://easystats.github.io/effectsize/articles/interpret.html/),
 such as Cohen's (1988) famous rules of thumb.
 
 However, standardizing a model's parameters should *not* be automatically and
@@ -113,7 +113,7 @@ When looking at the difference between groups as a **slope**, the standardized
 parameter is the difference between the means in $SD_{mpg}$. That is, the
 *slope* between `Manual` and `Automatic` is a change of 1.20 $SD_{mpg}$s.
 
-However, when looking a the difference as a **distance between two populations**, Cohen's d is the distance between the means in units of [**pooled SDs**](https://easystats.github.io/effectsize/reference/sd_pooled.html). That
+However, when looking a the difference as a **distance between two populations**, Cohen's d is the distance between the means in units of [**pooled SDs**](https://easystats.github.io/effectsize/reference/sd_pooled.html/). That
 is, the *distance* between `Manual` and `Automatic` is of 1.48 SDs of *each of
 the groups* (here assumed to be equal).
 
@@ -387,7 +387,7 @@ standardize_parameters(mod_b, method = ""refit"", two_sd = TRUE, exponentiate = TR
 
 ## Cohen's *f*
 
-Cohen's $f$ (of [ANOVA fame](https://easystats.github.io/effectsize/articles/anovaES.html)) can be used as a measure of effect size in the context of sequential multiple regression (i.e., [**nested models**](https://easystats.github.io/performance/reference/test_performance.html)).
+Cohen's $f$ (of [ANOVA fame](https://easystats.github.io/effectsize/articles/anovaES.html/)) can be used as a measure of effect size in the context of sequential multiple regression (i.e., [**nested models**](https://easystats.github.io/performance/reference/test_performance.html/)).
 That is, when comparing two models, we can examine the ratio between the
 increase in $R^2$ and the unexplained variance:
 
@@ -519,7 +519,7 @@ different (because the 0 corresponds to something different in standardzed and
 non-standardized data). In other words, when it comes to interaction, passing
 standardized data results in a different model, which coefficient have an
 intrinsically different meaning from unstandardized data. And as [for
-now](https://github.com/easystats/effectsize/issues/6), we are unable to
+now](https://github.com/easystats/effectsize/issues/6/), we are unable to
 retrieve one from another. -->
 
 <!-- #### Between continuous -->",True,True,Documentation / Formatting,6
easystats,effectsize,83b3a4c1df38cfbac7480c393d43f3f66d208747,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-01-08T13:32:37Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-01-08T13:32:37Z,weird bug fix for CRAN tests,R/standardize_info.R,False,True,True,False,3,1,4,"---FILE: R/standardize_info.R---
@@ -282,11 +282,13 @@ standardize_info.default <- function(model, robust = FALSE, two_sd = FALSE, incl
     means <- deviations <- rep(NA_real_, length = length(names(model_matrix)))
     for (i in seq_along(names(model_matrix))) {
       var <- names(model_matrix)[i]
-      if (types$Link[types$Parameter == var] == ""Difference"") {
+      if (any(types$Parameter == var) &&
+          types$Link[types$Parameter == var] == ""Difference"") {
         parent_var <- types$Variable[types$Parameter == var]
         intercept <- unique(data[[parent_var]])[1]
         response_at_intercept <- response[data[[parent_var]] == intercept]
         weights_at_intercept <- if (length(w)) w[data[[parent_var]] == intercept] else NULL
+
         std_info <- .compute_std_info(
           response = response_at_intercept,
           robust = robust, weights = weights_at_intercept",True,False,Implementation / Logic,6
easystats,effectsize,0773d046b0753059ae51c2d0ec2451a34b377b01,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-01-05T20:56:02Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-01-05T20:56:02Z,fix test on older versions of R,tests/testthat/test-eta_squared.R,False,True,True,False,1,1,2,"---FILE: tests/testthat/test-eta_squared.R---
@@ -172,7 +172,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     # Row order
     fit <- lm(cbind(mpg, disp, hp) ~ factor(cyl), data = mtcars)
     out <- eta_squared(fit, partial = FALSE, ci = NULL)
-    expect_equal(out$Response, c(""mpg"", ""disp"", ""hp""))
+    expect_equal(as.character(out$Response), c(""mpg"", ""disp"", ""hp""))
 
   })
 ",True,False,Implementation / Logic,6
easystats,effectsize,346580773750f1000000ed93353f75a819753ec9,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-01-05T08:33:25Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2022-01-05T08:33:25Z,fix,DESCRIPTION;NEWS.md;R/eta_squared.R;tests/testthat/test-eta_squared.R,False,True,True,False,9,2,11,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Type: Package
 Package: effectsize
 Title: Indices of Effect Size and Standardized Parameters
-Version: 0.5.0.10
+Version: 0.5.0.2
 Authors@R: 
     c(person(given = ""Mattan S."",
              family = ""Ben-Shachar"",

---FILE: NEWS.md---
@@ -16,6 +16,7 @@
 
 ## Bug fixes
 
+- `eta_squared()` for MLM return effect sizes in the correct order of the responses.  
 - `eta_squared()` family no longer fails when CIs fail due to non-finite *F*s / degrees of freedom.  
 - `standardize()` for multivariate models standardizes the (multivariate) response.
 - `standardize()` for models with offsets standardizes offset variables according to `include_response` and `two_sd` ( #396 ).

---FILE: R/eta_squared.R---
@@ -838,7 +838,7 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
   params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"")
   anova_type <- attr(params, ""anova_type"")
 
-  params <- split(params, params$Response)
+  params <- split(params, factor(params$Response, levels = unique(params$Response))) # make sure row order is not changed
   params <- lapply(params, .es_aov_simple,
     type = type,
     partial = partial,

---FILE: tests/testthat/test-eta_squared.R---
@@ -168,6 +168,12 @@ if (require(""testthat"") && require(""effectsize"")) {
     # MANOVA table
     mod <- manova(cbind(mpg, qsec) ~ am_f * cyl_f, data = mtcars)
     expect_equal(nrow(eta_squared(mod)), 3L)
+
+    # Row order
+    fit <- lm(cbind(mpg, disp, hp) ~ factor(cyl), data = mtcars)
+    out <- eta_squared(fit, partial = FALSE, ci = NULL)
+    expect_equal(out$Response, c(""mpg"", ""disp"", ""hp""))
+
   })
 
 ",True,False,Documentation / Formatting,6
easystats,effectsize,653412750f1bf46dcbda0e18cf39db7ff4d8665f,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-12-12T07:24:20Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-12-12T07:24:20Z,"Create effectsize.Rmd

https://github.com/easystats/easystats/issues/196",vignettes/effectsize.Rmd,True,False,True,False,167,0,167,"---FILE: vignettes/effectsize.Rmd---
@@ -0,0 +1,167 @@
+
+---
+title: ""Effect Sizes: Getting Started""
+output: rmarkdown::html_vignette
+vignette: >
+  %\VignetteIndexEntry{insight}
+  %\VignetteEngine{knitr::rmarkdown}
+  %\VignetteEncoding{UTF-8}
+---
+
+```{r, include = FALSE}
+knitr::opts_chunk$set(
+  collapse = TRUE,
+  comment = ""#>""
+)
+```
+
+# Aims of the Package
+
+In both theoretical and applied research, it is often of interest to assess the strength of an observed association. This is typically done to allow the judgment of the magnitude of an effect [especially when units of measurement are not meaningful, e.g., in the use of estimated latent variables; @bollen1989structural], to facilitate comparing between predictors' importance within a given model, or both. Though some indices of effect size, such as the correlation coefficient (itself a standardized covariance coefficient) are readily available, other measures are often harder to obtain. **effectsize** is an R package [@rcore] that fills this important gap, providing utilities for easily estimating a wide variety of standardized effect sizes (i.e., effect sizes that are not tied to the units of measurement of the variables of interest) and their confidence intervals (CIs), from a variety of statistical models. **effectsize** provides easy-to-use functions, with full documentation and explanation of the various effect sizes offered, and is also used by developers of other R packages as the back-end for effect size computation, such as **parameters** [@ludecke2020extracting], **ggstatsplot** [@patil2020ggstatsplot], **gtsummary** [@sjoberg2020gtsummary] and more.
+
+# Comparison to Other Packages
+
+**effectsize**'s functionality is in part comparable to packages like **lm.beta** [@behrendt2014lmbeta], **MOTE** [@buchanan2019MOTE], and **MBESS** [@kelley2020MBESS]. Yet, there are some notable differences, e.g.:
+
+- **lm.beta** provides standardized regression coefficients for linear models, based on post-hoc model matrix standardization. However, the functionality is available only for a limited number of models (models inheriting from the `lm` class), whereas **effectsize** provides support for many types of models, including (generalized) linear mixed models, Bayesian models, and more. Additionally, in additional to post-hoc model matrix standardization, **effectsize** offers other methods of standardization (see below).  
+- Both **MOTE** and **MBESS** provide functions for computing effect sizes such as Cohen's *d* and effect sizes for ANOVAs [@cohen1988statistical], and their confidence intervals. However, both require manual input of *F*- or *t*-statistics, *degrees of freedom*, and *sums of squares* for the computation the effect sizes, whereas **effectsize** can automatically extract this information from the provided models, thus allowing for better ease-of-use as well as reducing any potential for error.  
+<!-- - Finally, in **base R**, the function `scale()` can be used to standardize vectors, matrices and data frame, which can be used to standardize data prior to model fitting. The coefficients of a linear model fit on such data are in effect standardized regression coefficients. **effectsize** expands an this, allowing for robust standardization (using the median and the MAD, instead of the mean and SD), post-hoc parameter standardization, and more. -->
+
+# Examples of Features
+
+**effectsize** provides various functions for extracting and estimating effect sizes and their confidence intervals [estimated using the noncentrality parameter method; @steiger2004beyond]. In this article, we provide basic usage examples for estimating some of the most common effect size. A comprehensive overview, including in-depth examples and [a full list of features and functions](https://easystats.github.io/effectsize/reference/index.html), are accessible via a dedicated website (https://easystats.github.io/effectsize/).
+
+## Indices of Effect Size
+
+### Standardized Differences
+
+**effectsize** provides functions for estimating the common indices of standardized differences such as Cohen's *d* (`cohens_d()`), Hedges' *g* (`hedges_g()`) for both paired and independent samples [@cohen1988statistical; @hedges1985statistical], and Glass' $\Delta$ (`glass_delta()`) for independent samples with different variances [@hedges1985statistical].
+
+```{r}
+library(effectsize)
+
+cohens_d(mpg ~ am, data = mtcars)
+```
+
+### Contingency Tables
+
+Pearson's $\phi$ (`phi()`) and CramÃ©r's *V* (`cramers_v()`) can be used to estimate the strength of association between two categorical variables [@cramer1946mathematical], while Cohen's *g* (`cohens_g()`) estimates the deviance between paired categorical variables [@cohen1988statistical].
+
+```{r}
+M <- rbind(c(150, 130, 35, 55),
+           c(100, 50,  10, 40),
+           c(165, 65,  2,  25))
+
+cramers_v(M)
+```
+
+## Parameter and Model Standardization
+
+Standardizing parameters (i.e., coefficients) can allow for their comparison within and between models, variables and studies. To this end, two functions are available: `standardize()`, which returns an updated model, re-fit with standardized data, and `standardize_parameters()`, which returns a table of standardized coefficients from a provided model [for a list of supported models, see the *insight* package; @luedecke2019insight].
+
+```{r}
+model <- lm(mpg ~ cyl * am, 
+            data = mtcars)
+
+standardize(model)
+
+standardize_parameters(model)
+```
+
+Standardized parameters can also be produced for generalized linear models (GLMs; where only the predictors are standardized):
+
+```{r}
+model <- glm(am ~ cyl + hp,
+             family = ""binomial"",
+             data = mtcars)
+
+standardize_parameters(model, exponentiate = TRUE)
+```
+
+`standardize_parameters()` provides several standardization methods, such as robust standardization, or *pseudo*-standardized coefficients for (generalized) linear mixed models [@hoffman2015longitudinal]. A full review of these methods can be found in the [*Parameter and Model Standardization* vignette](https://easystats.github.io/effectsize/articles/standardize_parameters.html).
+
+## Effect Sizes for ANOVAs
+
+Unlike standardized parameters, the effect sizes reported in the context of ANOVAs (analysis of variance) or ANOVA-like tables represent the amount of variance explained by each of the model's terms, where each term can be represented by one or more parameters. `eta_squared()` can produce such popular effect sizes as Eta-squared ($\eta^2$), its partial version ($\eta^2_p$), as well as the generalized $\eta^2_G$ [@cohen1988statistical; @olejnik2003generalized]:
+
+```{r}
+options(contrasts = c('contr.sum', 'contr.poly'))
+
+data(""ChickWeight"")
+# keep only complete cases and convert `Time` to a factor
+ChickWeight <- subset(ChickWeight, ave(weight, Chick, FUN = length) == 12)
+ChickWeight$Time <- factor(ChickWeight$Time)
+
+model <- aov(weight ~ Diet * Time + Error(Chick / Time),
+             data = ChickWeight) 
+
+eta_squared(model, partial = TRUE)
+
+eta_squared(model, generalized = ""Time"")
+```
+
+**effectsize** also offers $\epsilon^2_p$ (`epsilon_squared()`) and $\omega^2_p$ (`omega_squared()`), which are less biased estimates of the variance explained in the population [@kelley1935unbiased; @olejnik2003generalized]. For more details about the various effect size measures and their applications, see the [*Effect sizes for ANOVAs* vignette](https://easystats.github.io/effectsize/articles/anovaES.html).
+
+## Effect Size Conversion
+
+### From Test Statistics
+
+In many real world applications there are no straightforward ways of obtaining standardized effect sizes. However, it is possible to get approximations of most of the effect size indices (*d*, *r*, $\eta^2_p$...) with the use of test statistics [@friedman1982simplified]. These conversions are based on the idea that test statistics are a function of effect size and sample size (or more often of degrees of freedom). Thus it is possible to reverse-engineer indices of effect size from test statistics (*F*, *t*, $\chi^2$, and *z*). 
+
+```{r}
+F_to_eta2(f = c(40.72, 33.77),
+          df = c(2, 1), df_error = c(18, 9))
+
+t_to_d(t = -5.14, df_error = 22)
+
+t_to_r(t = -5.14, df_error = 22)
+```
+
+These functions also power the `effectsize()` convenience function for estimating effect sizes from R's `htest`-type objects. For example:
+
+```{r}
+data(hardlyworking, package = ""effectsize"")
+
+aov1 <- oneway.test(salary ~ n_comps, 
+                    data = hardlyworking, var.equal = TRUE)
+effectsize(aov1)
+
+xtab <- rbind(c(762, 327, 468), c(484, 239, 477), c(484, 239, 477))
+Xsq <- chisq.test(xtab)
+effectsize(Xsq)
+```
+
+These functions also power our *Effect Sizes From Test Statistics* shiny app (https://easystats4u.shinyapps.io/statistic2effectsize/).
+
+### Between Effect Sizes
+
+For comparisons between different types of designs and analyses, it is useful to be able to convert between different types of effect sizes [*d*, *r*, Odds ratios and Risk ratios; @borenstein2009converting; @grant2014converting].
+
+```{r}
+r_to_d(0.7)
+
+d_to_oddsratio(1.96)
+
+oddsratio_to_riskratio(34.99, p0 = 0.4)
+
+oddsratio_to_r(34.99)
+```
+
+## Effect Size Interpretation
+
+Finally, **effectsize** provides convenience functions to apply existing or custom interpretation rules of thumb, such as for instance Cohen's (1988). Although we strongly advocate for the cautious and parsimonious use of such judgment-replacing tools, we provide these functions to allow users and developers to explore and hopefully gain a deeper understanding of the relationship between data values and their interpretation. More information is available in the [*Automated Interpretation of Indices of Effect Size* vignette](https://easystats.github.io/effectsize/articles/interpret.html).
+
+```{r}
+interpret_cohens_d(c(0.02, 0.52, 0.86), rules = ""cohen1988"")
+```
+
+
+# Licensing and Availability
+
+**effectsize** is licensed under the GNU General Public License (v3.0), with all source code stored at GitHub (https://github.com/easystats/effectsize), and with a corresponding issue tracker for bug reporting and feature enhancements. In the spirit of honest and open science, we encourage requests/tips for fixes, feature updates, as well as general questions and concerns via direct interaction with contributors and developers, by [filing an issue](https://github.com/easystats/effectsize/issues). See the package's [*Contribution Guidelines*](https://github.com/easystats/effectsize/blob/main/.github/CONTRIBUTING.md).
+
+# Acknowledgments
+
+**effectsize** is part of the [*easystats*](https://github.com/easystats/easystats) ecosystem, a collaborative project created to facilitate the usage of R for statistical analyses. Thus, we would like to thank the [members of easystats](https://github.com/orgs/easystats/people) as well as the users.
+
+# References",False,True,Documentation / Formatting,6
easystats,effectsize,3091d6e18bbd1e96b65d3d8ce162a98e1383723a,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-12-03T11:28:35Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-12-03T11:28:35Z,"Update _pkgdown.yml

https://github.com/easystats/easystats/issues/194",_pkgdown.yml,False,False,False,False,7,19,26,"---FILE: _pkgdown.yml---
@@ -52,22 +52,7 @@ reference:
   - equivalence_test.effectsize_table
   - interpret
   - rules
-  - interpret_cohens_d
-  - interpret_r
-  - interpret_eta_squared
-  - interpret_cohens_g
-  - interpret_kendalls_w
-  - interpret_oddsratio
-  - interpret_r2
-  - interpret_icc
-  - interpret_vif
-  - interpret_gfi
-  - interpret_direction
-  - interpret_p
-  - interpret_bf
-  - interpret_pd
-  - interpret_rope
-  - interpret_ess
+  - starts_with(""interpret_"")
 
 - title: ""Miscellaneous""
   contents:
@@ -78,14 +63,17 @@ reference:
 - subtitle: ""Datasets""
   contents:
   - hardlyworking
-- subtitle: ""Extra Docs""
+
+- title: ""internal""
   contents:
   - effectsize_CIs
   - effectsize_API
-- subtitle: ""Deprecated functions""
-  contents:
   - effectsize_deprecated
 
+
+
+
+
 navbar:
   structure:
     right: [twitter, github]",False,False,Documentation / Formatting,3
easystats,effectsize,064b8eca901549c04a1942bd05328939e1deb78b,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-11-30T07:26:48Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-11-30T07:26:48Z,"Update _pkgdown.yml

https://github.com/easystats/easystats/issues/193",_pkgdown.yml,False,False,False,False,19,2,21,"---FILE: _pkgdown.yml---
@@ -5,10 +5,27 @@ authors:
     href: https://dominiquemakowski.github.io/
   Daniel LÃ¼decke:
     href: https://github.com/strengejacke
+  Indrajeet Patil:
+    href: https://sites.google.com/site/indrajeetspatilmorality/
+  Brenton M. Wiernik:
+    href: https://wiernik.org/
+
 
 template:
-  params:
-    bootswatch: cosmo
+  bootstrap: 5
+  bslib:
+    primary: ""#4caf50""
+
+
+navbar:
+  structure:
+    right: [twitter, github]
+  components:
+    twitter:
+      icon: fa-twitter
+      href: http://twitter.com/easystats4u
+      aria-label: Twitter
+
 
 reference:
 - title: ""Indices of Effect Size""",False,False,Documentation / Formatting,3
easystats,effectsize,019bc65e2091ab06cd8b280d7aed98344256fb00,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-11-25T07:36:24Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-11-25T07:36:24Z,fix: vignette failing,vignettes/standardize_parameters.Rmd,True,False,True,False,1,1,2,"---FILE: vignettes/standardize_parameters.Rmd---
@@ -338,7 +338,7 @@ are also called *pseudo*-standardized coefficients.[^Note that like method
 `""basic""`, these are based on the model matrix.]
 
 ```{r, eval=knitr::opts_chunk$get(""eval"") && require(lme4) && require(lmerTest), warning=FALSE}
-m <- lme4::lmer(mpg ~ cyl + am + vs + (1|cyl), mtcars)
+m <- lme4::lmer(Reaction ~ Days + (Days|Subject), data = lme4::sleepstudy)
 
 standardize_parameters(m, method = ""pseudo"", ci_method = ""satterthwaite"")
 ",False,True,Documentation / Formatting,4
easystats,effectsize,f98939c44bd72538debe0861ce17802919159e02,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-11-24T14:09:54Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-11-24T14:09:54Z,fix: tests for std models,tests/testthat/test-standardize_models.R,False,True,True,False,4,3,7,"---FILE: tests/testthat/test-standardize_models.R---
@@ -177,15 +177,16 @@ if (require(""testthat"") && require(""effectsize"")) {
   test_that(""variables evaluated in the environment"", {
     m <- lm(mtcars$mpg ~ mtcars$cyl + am, data = mtcars)
     w <- capture_warnings(standardize(m))
-    expect_match(w[1], ""mtcars$mpg"", fixed = TRUE)
+    expect_true(any(grepl(""mtcars$mpg"", w, fixed = TRUE)))
+
 
     skip_if(packageVersion(""base"") == package_version(3.4))
     ## Note:
     # No idea why this is suddenly not giving a warning on older R versions.
     m <- lm(mtcars$mpg ~ mtcars$cyl + mtcars$am, data = mtcars)
     warns <- capture_warnings(standardize(m))
-    expect_true(grepl(""mtcars$mpg"", warns[1], fixed = TRUE))
-    expect_true(grepl(""No variables"", warns[2], fixed = TRUE))
+    expect_true(any(grepl(""mtcars$mpg"", warns, fixed = TRUE)))
+    expect_true(any(grepl(""No variables"", warns, fixed = TRUE)))
   })
 
 ",True,False,Dependency / Package,3
easystats,effectsize,013c46af79c92babeb8231f20ca39b6bedab6cf7,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-11-09T10:12:26Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-11-09T10:12:26Z,"em dash bad

https://github.com/easystats/easystats/issues/188",R/interpret_oddsratio.R;man/interpret_oddsratio.Rd,False,True,True,False,2,2,4,"---FILE: R/interpret_oddsratio.R---
@@ -32,7 +32,7 @@
 #'
 #' - Chen, H., Cohen, P., & Chen, S. (2010). How big is a big odds ratio?
 #' Interpreting the magnitudes of odds ratios in epidemiological studies.
-#' Communications in StatisticsâSimulation and Computation, 39(4), 860-864.
+#' Communications in Statistics-Simulation and Computation, 39(4), 860-864.
 #'
 #' - SÃ¡nchez-Meca, J., MarÃ­n-MartÃ­nez, F., & ChacÃ³n-Moscoso, S. (2003).
 #' Effect-size indices for dichotomized outcomes in meta-analysis. Psychological

---FILE: man/interpret_oddsratio.Rd---
@@ -53,7 +53,7 @@ interpret_oddsratio(c(5, 2))
 (2nd Ed.). New York: Routledge.
 \item Chen, H., Cohen, P., & Chen, S. (2010). How big is a big odds ratio?
 Interpreting the magnitudes of odds ratios in epidemiological studies.
-Communications in StatisticsâSimulation and Computation, 39(4), 860-864.
+Communications in Statistics-Simulation and Computation, 39(4), 860-864.
 \item SÃ¡nchez-Meca, J., MarÃ­n-MartÃ­nez, F., & ChacÃ³n-Moscoso, S. (2003).
 Effect-size indices for dichotomized outcomes in meta-analysis. Psychological
 methods, 8(4), 448.",True,False,Documentation / Formatting,6
easystats,effectsize,e666f1d796f10f21d09d63c46a369917639eb995,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-11-07T13:08:12Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-11-07T13:08:12Z,fixup some parameters_model issues,R/eta_squared.R,False,True,True,False,39,24,63,"---FILE: R/eta_squared.R---
@@ -474,15 +474,14 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
     ES <- pmax(0, out[[ncol(out)]])
     f <- (ES / out$df) / ((1 - ES) / df_error)
 
-    out <- cbind(
-      out,
-      # This really is a generic F_to_R2
+    CI_tab <- # This really is a generic F_to_R2
       F_to_eta2(f,
                 out$df,
                 df_error,
                 ci = ci, alternative = alternative
       )[-1]
-    )
+
+    out[c(""CI"", ""CI_low"", ""CI_high"")] <- CI_tab[c(""CI"", ""CI_low"", ""CI_high"")]
   } else {
     alternative <- NULL
   }
@@ -494,7 +493,7 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
     ""Eta2"", ""Eta2_partial"", ""Eta2_generalized"",
     ""Omega2"", ""Omega2_partial"",
     ""Epsilon2"", ""Epsilon2_partial"",
-    ""CI"", ""CI_low"", ""CI_high""
+    if (!is.null(ci)) c(""CI"", ""CI_low"", ""CI_high"")
   ), drop = FALSE]
   rownames(out) <- NULL
 
@@ -616,15 +615,14 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
     ES <- pmax(0, out[[ncol(out)]])
     f <- (ES / out$df) / ((1 - ES) / df_residuals)
 
-    out <- cbind(
-      out,
-      # This really is a generic F_to_R2
+    CI_tab <- # This really is a generic F_to_R2
       F_to_eta2(f,
                 out$df,
                 df_residuals,
                 ci = ci, alternative = alternative
       )[-1]
-    )
+
+    out[c(""CI"", ""CI_low"", ""CI_high"")] <- CI_tab[c(""CI"", ""CI_low"", ""CI_high"")]
   } else {
     alternative <- NULL
   }
@@ -637,7 +635,7 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
     ""Eta2"", ""Eta2_generalized"", ""Eta2_partial"",
     ""Omega2"", ""Omega2_partial"",
     ""Epsilon2"", ""Epsilon2_partial"",
-    ""CI"", ""CI_low"", ""CI_high""
+    if (!is.null(ci)) c(""CI"", ""CI_low"", ""CI_high"")
   ), drop = FALSE]
   rownames(out) <- NULL
 
@@ -701,21 +699,12 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
   if (!include_intercept)
     aov_table <- aov_table[aov_table$Parameter != ""(Intercept)"", , drop = FALSE]
 
-  out <- cbind(aov_table,
-               es_fun(aov_table[[""F""]],
-                      aov_table[[""df""]],
-                      aov_table[[""df_error""]],
-                      ci = ci, alternative = alternative
-               ))
+  ES_tab <- es_fun(aov_table[[""F""]],
+                   aov_table[[""df""]],
+                   aov_table[[""df_error""]],
+                   ci = ci, alternative = alternative)
 
-  # Clean up output ---
-  out <- out[, colnames(out) %in% c(
-    ""Parameter"",
-    ""Eta2"", ""Eta2_partial"", ""Eta2_generalized"",
-    ""Omega2"", ""Omega2_partial"",
-    ""Epsilon2"", ""Epsilon2_partial"",
-    ""CI"", ""CI_low"", ""CI_high""
-  ), drop = FALSE]
+  out <- cbind(Parameter = aov_table[[""Parameter""]], ES_tab)
   rownames(out) <- NULL
 
   # Set attributes ---
@@ -938,7 +927,33 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
                                        generalized = FALSE,
                                        ci = 0.95, alternative = ""greater"",
                                        verbose = TRUE,
+                                       by_response = TRUE,
                                        ...) {
+  if (by_response && ""Response"" %in% colnames(model)) {
+    out <- split(model, model[[""Response""]])
+    out <- lapply(out, .anova_es.parameters_model,
+                  type = type, partial = partial, generalized = generalized,
+                  ci = ci, alternative = alternative,
+                  verbose = verbose,
+                  by_response = FALSE,
+                  ...)
+    saved_attr <- attributes(out[[1]])
+    out <- mapply(out, names(out),
+                  FUN = function(x, nm) cbind(Response = nm, x),
+                  SIMPLIFY = FALSE)
+    out <- do.call(rbind, out)
+
+    # Set attributes ---
+    attr(out, ""partial"") <- saved_attr$partial
+    attr(out, ""generalized"") <- saved_attr$generalized
+    attr(out, ""ci"") <- saved_attr$ci
+    attr(out, ""alternative"") <- saved_attr$alternative
+    attr(out, ""anova_type"") <- attr(model, ""anova_type"")
+    attr(out, ""approximate"") <- saved_attr$approximate
+    return(out)
+  }
+
+
   if (""Sum_Squares"" %in% colnames(model) && ""Residuals"" %in% model[[""Parameter""]]) {
     if (""Group"" %in% colnames(model)) {
       DVs <- unlist(insight::find_predictors(.get_object(model)))",True,False,Implementation / Logic,6
easystats,effectsize,8252423e00de6ceed5152c6e7f3d671dae7aab33,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-11-04T13:56:44Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-11-04T13:56:44Z,fix: CLES tests,R/convert_between_common_language.R;R/effectsize.htest.R;tests/testthat/test-standardized_differences.R,False,True,True,False,6,5,11,"---FILE: R/convert_between_common_language.R---
@@ -122,7 +122,7 @@ rb_to_cles.effectsize_difference <- function(rb) {
   }
 
   class(out) <- c(""effectsize_table"", class(out))
-  attr(out, ""table_footer"") <- c(""\n- Rank based CLES"", ""cyan"")
+  attr(out, ""table_footer"") <- c(""\n- Non-parametric CLES"", ""cyan"")
   out
 }
 

---FILE: R/effectsize.htest.R---
@@ -195,7 +195,7 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
         stop(""Common language effect size only applicable to 2-sample rank-biserial correlation."")
       }
       args$paired <- NULL
-      args$rank <- TRUE
+      args$parametric <- FALSE
     }
 
     out <- do.call(f, c(args, dots))

---FILE: tests/testthat/test-standardized_differences.R---
@@ -161,10 +161,11 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(CLES <- d_to_cles(d), cles(x, y))
     expect_equal(cles(tt), CLES, ignore_attr = TRUE)
 
-    rb <- rank_biserial(x, y)
+    rb <- rank_biserial(x, y, ci = NULL)
     w <- wilcox.test(x, y)
-    expect_equal(rb_to_cles(rb), (CLES <- cles(x, y, rank = TRUE))[1,])
-    expect_equal(cles(w, rank = TRUE), CLES)
+    CLES <- cles(x, y, parametric = FALSE, ci = NULL)
+    expect_equal(rb_to_cles(rb), CLES[1,], ignore_attr = TRUE)
+    expect_equal(cles(w, parametric = FALSE)[,1:2], CLES, ignore_attr = TRUE)
 
     x <- 1:3
     y <- c(1,1:3)",True,False,Implementation / Logic,6
easystats,effectsize,ffc288153fd033c6c96dec5c69905a9881c0c648,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-10-31T13:06:39Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-10-31T13:06:39Z,"fix: effectsize(wilcox)

failed do to wrong default ""type""",R/effectsize.R;R/effectsize.htest.R;R/rank_effectsizes.R;man/effectsize.Rd,False,True,True,False,8,6,14,"---FILE: R/effectsize.R---
@@ -11,11 +11,11 @@
 #' @details
 #'
 #' - For an object of class `htest`, data is extracted via [insight::get_data()], and passed to the relevant function according to:
-#'   - A **t-test** depending on `type`: `""cohens_d""` (default), `""hedges_g""`.
+#'   - A **t-test** depending on `type`: `""cohens_d""` (default), `""hedges_g""`, or `""cles""`.
 #'   - A **Chi-squared tests of independence or goodness-of-fit**, depending on `type`: `""cramers_v""` (default), `""phi""`, `""cohens_w""`, `""pearsons_c""`, `""cohens_h""`, `""oddsratio""`, or `""riskratio""`.
 #'   - A **One-way ANOVA test**, depending on `type`: `""eta""` (default), `""omega""` or `""epsilon""` -squared, `""f""`, or `""f2""`.
 #'   - A **McNemar test** returns *Cohen's g*.
-#'   - A **Wilcoxon test** returns *rank biserial correlation*.
+#'   - A **Wilcoxon test** depending on `type`: returns ""`rank_biserial`"" correlation (default) or `""cles""`.
 #'   - A **Kruskal-Wallis test** returns *rank Epsilon squared*.
 #'   - A **Friedman test** returns *Kendall's W*.
 #'   (Where applicable, `ci` and `alternative` are taken from the `htest` if not otherwise provided.)
@@ -53,6 +53,7 @@
 #'
 #' Wt <- wilcox.test(1:10, 7:20, mu = -3, alternative = ""less"")
 #' effectsize(Wt)
+#' effectsize(Wt, type = ""cles"")
 #'
 #' ## Bayesian Hypothesis Testing
 #' ## ---------------------------

---FILE: R/effectsize.htest.R---
@@ -164,7 +164,7 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
     return(out)
   } else if (grepl(""Wilcoxon"", model$method)) {
     # Wilcoxon ----
-    if (is.null(type)) type <- ""d""
+    if (is.null(type)) type <- ""rb""
 
     dots$alternative <- model$alternative
     dots$ci <- attr(model$conf.int,""conf.level"")

---FILE: R/rank_effectsizes.R---
@@ -172,7 +172,7 @@ rank_biserial <- function(x,
     if (!grepl(""Wilcoxon"", x$method)) {
       stop(""'x' is not a Wilcoxon-test!"", call. = FALSE)
     }
-    return(effectsize(x, verbose = verbose))
+    return(effectsize(x, verbose = verbose, type = ""rb""))
   }
 
   if (!missing(iterations) && verbose) {

---FILE: man/effectsize.Rd---
@@ -45,11 +45,11 @@ input model. See details.
 \itemize{
 \item For an object of class \code{htest}, data is extracted via \code{\link[insight:get_data]{insight::get_data()}}, and passed to the relevant function according to:
 \itemize{
-\item A \strong{t-test} depending on \code{type}: \code{""cohens_d""} (default), \code{""hedges_g""}.
+\item A \strong{t-test} depending on \code{type}: \code{""cohens_d""} (default), \code{""hedges_g""}, or \code{""cles""}.
 \item A \strong{Chi-squared tests of independence or goodness-of-fit}, depending on \code{type}: \code{""cramers_v""} (default), \code{""phi""}, \code{""cohens_w""}, \code{""pearsons_c""}, \code{""cohens_h""}, \code{""oddsratio""}, or \code{""riskratio""}.
 \item A \strong{One-way ANOVA test}, depending on \code{type}: \code{""eta""} (default), \code{""omega""} or \code{""epsilon""} -squared, \code{""f""}, or \code{""f2""}.
 \item A \strong{McNemar test} returns \emph{Cohen's g}.
-\item A \strong{Wilcoxon test} returns \emph{rank biserial correlation}.
+\item A \strong{Wilcoxon test} depending on \code{type}: returns ""\code{rank_biserial}"" correlation (default) or \code{""cles""}.
 \item A \strong{Kruskal-Wallis test} returns \emph{rank Epsilon squared}.
 \item A \strong{Friedman test} returns \emph{Kendall's W}.
 (Where applicable, \code{ci} and \code{alternative} are taken from the \code{htest} if not otherwise provided.)
@@ -86,6 +86,7 @@ effectsize(Aov, type = ""omega"")
 
 Wt <- wilcox.test(1:10, 7:20, mu = -3, alternative = ""less"")
 effectsize(Wt)
+effectsize(Wt, type = ""cles"")
 
 ## Bayesian Hypothesis Testing
 ## ---------------------------",True,False,Documentation / Formatting,6
easystats,effectsize,a1e8701e89e69344c955925edc68f4474cf838c3,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-10-31T08:39:57Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-10-31T08:39:57Z,fix: tests fail due to no longer using match.call,man/effectsize_CIs.Rd;tests/testthat/test-effectsize.R,False,True,True,False,5,14,19,"---FILE: man/effectsize_CIs.Rd---
@@ -96,7 +96,7 @@ An alternative approach to aligning significance tests using CIs and 1-tailed
 conducting \strong{equivalence tests}. For example, a 90\% 2-sided interval gives
 the bounds for an equivalence test with \eqn{\alpha} = .05. However, be aware
 that this interval does not give 95\% coverage for the underlying effect size
-parameter value. For that, construct a 95\% 2-sided CI.\if{html}{\out{<div class=""r"">}}\preformatted{data(""hardlyworking"")
+parameter value. For that, construct a 95\% 2-sided CI.\if{html}{\out{<div class=""sourceCode r"">}}\preformatted{data(""hardlyworking"")
 fit <- lm(salary ~ n_comps + age, data = hardlyworking)
 eta_squared(fit) # default, ci = 0.95, alternative = ""greater""
 }\if{html}{\out{</div>}}\preformatted{## # Effect Size for ANOVA (Type I)
@@ -107,7 +107,7 @@ eta_squared(fit) # default, ci = 0.95, alternative = ""greater""
 ## age       |           0.10 | [0.06, 1.00]
 ## 
 ## - One-sided CIs: upper bound fixed at (1).
-}\if{html}{\out{<div class=""r"">}}\preformatted{eta_squared(fit, alternative = ""less"") # Test is eta is smaller than some value
+}\if{html}{\out{<div class=""sourceCode r"">}}\preformatted{eta_squared(fit, alternative = ""less"") # Test is eta is smaller than some value
 }\if{html}{\out{</div>}}\preformatted{## # Effect Size for ANOVA (Type I)
 ## 
 ## Parameter | Eta2 (partial) |       95\% CI
@@ -116,14 +116,14 @@ eta_squared(fit) # default, ci = 0.95, alternative = ""greater""
 ## age       |           0.10 | [0.00, 0.14]
 ## 
 ## - One-sided CIs: lower bound fixed at (0).
-}\if{html}{\out{<div class=""r"">}}\preformatted{eta_squared(fit, alternative = ""two.sided"") # 2-sided bounds for alpha = .05
+}\if{html}{\out{<div class=""sourceCode r"">}}\preformatted{eta_squared(fit, alternative = ""two.sided"") # 2-sided bounds for alpha = .05
 }\if{html}{\out{</div>}}\preformatted{## # Effect Size for ANOVA (Type I)
 ## 
 ## Parameter | Eta2 (partial) |       95\% CI
 ## -----------------------------------------
 ## n_comps   |           0.21 | [0.15, 0.27]
 ## age       |           0.10 | [0.06, 0.15]
-}\if{html}{\out{<div class=""r"">}}\preformatted{eta_squared(fit, ci = 0.9, alternative = ""two.sided"") # both 1-sided bounds for alpha = .05
+}\if{html}{\out{<div class=""sourceCode r"">}}\preformatted{eta_squared(fit, ci = 0.9, alternative = ""two.sided"") # both 1-sided bounds for alpha = .05
 }\if{html}{\out{</div>}}\preformatted{## # Effect Size for ANOVA (Type I)
 ## 
 ## Parameter | Eta2 (partial) |       90\% CI
@@ -139,7 +139,7 @@ For very large sample sizes or effect sizes, the width of the CI can be
 smaller than the tolerance of the optimizer, resulting in CIs of width 0.
 This can also result in the estimated CIs excluding the point estimate.
 
-For example:\if{html}{\out{<div class=""r"">}}\preformatted{t_to_d(80, df_error = 4555555)
+For example:\if{html}{\out{<div class=""sourceCode r"">}}\preformatted{t_to_d(80, df_error = 4555555)
 }\if{html}{\out{</div>}}\preformatted{## d    |       95\% CI
 ## -------------------
 ## 0.07 | [0.08, 0.08]

---FILE: tests/testthat/test-effectsize.R---
@@ -178,21 +178,12 @@ if (require(""testthat"") && require(""effectsize"")) {
   test_that(""htest | Get args from htest"", {
     tt <- t.test(mtcars$hp, mtcars$mpg, alternative = ""l"", mu=-3, conf.level = 0.8, var.equal = TRUE)
     expect_equal(cohens_d(tt), cohens_d(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3, ci = 0.8), ignore_attr = TRUE)
-    expect_equal(cohens_d(tt, mu = -4, ci = 0.99, alternative = ""t""),
-                 cohens_d(mtcars$hp, mtcars$mpg, mu = -4, ci = 0.99, alternative = ""t""),
-                 ignore_attr = TRUE)
 
     suppressWarnings(ww1 <- wilcox.test(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3))
     expect_equal(rank_biserial(ww1), rank_biserial(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3), ignore_attr = TRUE)
-    expect_equal(rank_biserial(ww1, mu = -4, alternative = ""t""),
-                 rank_biserial(mtcars$hp, mtcars$mpg, mu = -4, alternative = ""t""),
-                 ignore_attr = TRUE)
 
     suppressWarnings(ww2 <- wilcox.test(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3,  conf.int = TRUE, conf.level = 0.8))
     expect_equal(rank_biserial(ww2), rank_biserial(mtcars$hp, mtcars$mpg, alternative = ""l"", mu = -3, ci = 0.8), ignore_attr = TRUE)
-    expect_equal(rank_biserial(ww2, mu = -4, alternative = ""t"", ci = 0.99),
-                 rank_biserial(mtcars$hp, mtcars$mpg, mu = -4, alternative = ""t"", ci = 0.99),
-                 ignore_attr = TRUE)
   })
 
 ",True,False,Documentation / Formatting,6
easystats,effectsize,4c4e3495646eb1a3f50c76e2725d6d840e8d8477,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-10-30T19:07:31Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-10-30T19:07:31Z,"fix: test failed due to use of match.call

All match.call removed from package",R/cohens_d.R;R/common_language.R;R/rank_effectsizes.R;tests/testthat/test-standardized_differences.R,False,True,True,False,28,39,67,"---FILE: R/cohens_d.R---
@@ -137,13 +137,6 @@ cohens_d <- function(x,
                      alternative = ""two.sided"",
                      verbose = TRUE,
                      ...) {
-  if (inherits(x, ""htest"")) {
-    cl <- match.call()
-    alternative <- cl$alternative
-    mu <- cl$mu
-    ci <- cl$ci
-  }
-
   .effect_size_difference(
     x,
     y = y,
@@ -178,13 +171,6 @@ hedges_g <- function(x,
     )
   }
 
-  if (inherits(x, ""htest"")) {
-    cl <- match.call()
-    alternative <- cl$alternative
-    mu <- cl$mu
-    ci <- cl$ci
-  }
-
   .effect_size_difference(
     x,
     y = y,
@@ -217,13 +203,6 @@ glass_delta <- function(x,
     )
   }
 
-  if (inherits(x, ""htest"")) {
-    cl <- match.call()
-    alternative <- cl$alternative
-    mu <- cl$mu
-    ci <- cl$ci
-  }
-
   .effect_size_difference(
     x,
     y = y,
@@ -258,7 +237,7 @@ glass_delta <- function(x,
     if (!grepl(""t-test"", x$method)) {
       stop(""'x' is not a t-test!"", call. = FALSE)
     }
-    return(effectsize(x, type = type, ci = ci, alternative = alternative, mu = mu, verbose = verbose, ...))
+    return(effectsize(x, type = type, verbose = verbose, ...))
   } else if (type != ""delta"" && inherits(x, ""BFBayesFactor"")) {
     if (!inherits(x@numerator[[1]], c(""BFoneSample"", ""BFindepSample""))) {
       stop(""'x' is not a t-test!"", call. = FALSE)

---FILE: R/common_language.R---
@@ -47,17 +47,32 @@ cles <- function(x,
                  verbose = TRUE,
                  rank = FALSE,
                  ...) {
-  cl <- match.call()
-  cl$paired <- FALSE
-
   if (rank) {
-    cl[[1]] <- as.name(""rank_biserial"")
-    rb_to_cles(eval(cl))
+    rb <- rank_biserial(
+      x = x,
+      y = y,
+      data = data,
+      paired = FALSE,
+      mu = mu,
+      ci = ci,
+      alternative = alternative,
+      verbose = verbose,
+      ...
+    )
+    rb_to_cles(rb)
   } else {
-    cl$pooled_sd <- TRUE
-    cl[[1]] <- as.name(""cohens_d"")
-
-    d_to_cles(eval(cl))
+    d <- cohens_d(
+      x = x,
+      y = y,
+      data = data,
+      paired = FALSE, pooled_sd = TRUE,
+      mu = mu,
+      ci = ci,
+      alternative = alternative,
+      verbose = verbose,
+      ...
+    )
+    d_to_cles(d)
   }
 }
 

---FILE: R/rank_effectsizes.R---
@@ -172,12 +172,7 @@ rank_biserial <- function(x,
     if (!grepl(""Wilcoxon"", x$method)) {
       stop(""'x' is not a Wilcoxon-test!"", call. = FALSE)
     }
-    cl <- match.call()
-    return(effectsize(
-      x, ci = cl$ci,
-      mu = cl$mu, alternative = cl$alternative,
-      verbose = verbose
-    ))
+    return(effectsize(x, verbose = verbose))
   }
 
   if (!missing(iterations) && verbose) {

---FILE: tests/testthat/test-standardized_differences.R---
@@ -152,8 +152,8 @@ if (require(""testthat"") && require(""effectsize"")) {
   })
 
   test_that(""CLES"", {
-    x <- rnorm(1000)
-    y <- rnorm(1000, mean = 0.2)
+    x <<- rnorm(1000)
+    y <<- rnorm(1000, mean = 0.2)
 
     d <- cohens_d(x, y)
     tt <- t.test(x,y, var.equal = TRUE)",True,False,Implementation / Logic,6
easystats,effectsize,be69a76dbb72ff088a5a65c79dba2a75c59917e5,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-10-30T18:59:14Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-10-30T18:59:14Z,fix: check arg append_CLES missnamed,R/print.effectsize_table.R;man/print.effectsize_table.Rd;tests/testthat/test-printing.R,False,True,True,False,3,3,6,"---FILE: R/print.effectsize_table.R---
@@ -123,7 +123,7 @@ print.equivalence_test_effectsize <- function(x, digits = 2, ...) {
 
 #' @export
 #' @rdname print.effectsize_table
-#' @param append_CL Should the Common Language Effect Sizes be printed as well?
+#' @param append_CLES Should the Common Language Effect Sizes be printed as well?
 #'   Only applicable to Cohen's *d*, Hedges' *g* for independent samples of
 #'   equal variance (pooled sd) or for the rank-biserial correlation for
 #'   independent samples (See [d_to_cles()])

---FILE: man/print.effectsize_table.Rd---
@@ -30,7 +30,7 @@ value as suffix, e.g. \code{digits = ""scientific4""} to have scientific
 notation with 4 decimal places, or \code{digits = ""signif5""} for 5
 significant figures (see also \code{\link[=signif]{signif()}}).}
 
-\item{append_CL}{Should the Common Language Effect Sizes be printed as well?
+\item{append_CLES}{Should the Common Language Effect Sizes be printed as well?
 Only applicable to Cohen's \emph{d}, Hedges' \emph{g} for independent samples of
 equal variance (pooled sd) or for the rank-biserial correlation for
 independent samples (See \code{\link[=d_to_cles]{d_to_cles()}})}

---FILE: tests/testthat/test-printing.R---
@@ -33,7 +33,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     d <- cohens_d(1:3, c(1, 1:3))
     expect_output(print(d), regexp = ""Cohen"")
     expect_output(print(d), regexp = "" pooled"", fixed = TRUE)
-    expect_output(print(d, append_CL = TRUE), regexp = ""U3"")
+    expect_output(print(d, append_CLES = TRUE), regexp = ""U3"")
 
     d <- cohens_d(1:3, c(1, 1:3), pooled_sd = FALSE)
     expect_output(print(d), regexp = ""un-pooled"")",True,False,Documentation / Formatting,6
easystats,effectsize,fbe56d3953791a8c457217e901dd8f59d3e960e0,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-10-29T18:04:14Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-10-29T18:04:14Z,fix: cles overlap CI,R/convert_between_common_language.R,False,True,True,False,4,3,7,"---FILE: R/convert_between_common_language.R---
@@ -68,10 +68,11 @@ d_to_cles.effectsize_difference <- function(d) {
     out$CI <- d$CI
     out <- out[c(""Parameter"", ""Coefficient"", ""CI"", ""CI_low"", ""CI_high"")]
 
+    if (d[[1]] > 0) {
+      out[2, 4:5] <- out[2, 5:4]
+    }
+
     if (sign(d$CI_low) != sign(d$CI_high)) {
-      if (d[[1]] > 0) {
-        out$CI_low[2] <- out$CI_high[2]
-      }
       out$CI_high[2] <- 1
     }
   } else {",True,False,Implementation / Logic,3
easystats,effectsize,7d753a39296c177af6707facbb1948a99559d55b,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-10-29T17:28:21Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-10-29T17:28:21Z,fix: alias Undocumented code objects,R/convert_between_common_language.R;man/d_to_cles.Rd,False,True,True,False,6,5,11,"---FILE: R/convert_between_common_language.R---
@@ -34,7 +34,7 @@
 #' to base rates and other factors. Psychological methods, 13(1), 19â30.
 #'
 #' @export
-#' @aliases convert_d_to_common_language, d_to_common_language, rbs_to_common_language, convert_rbs_to_common_language
+#' @aliases convert_d_to_common_language d_to_common_language
 #' @importFrom stats pnorm
 d_to_cles <- function(d) {
   UseMethod(""d_to_cles"")
@@ -84,6 +84,7 @@ d_to_cles.effectsize_difference <- function(d) {
 
 
 #' @export
+#' @aliases rbs_to_common_language convert_rbs_to_common_language
 #' @rdname d_to_cles
 rbs_to_cles <- function(rbs) {
   UseMethod(""rbs_to_cles"")

---FILE: man/d_to_cles.Rd---
@@ -2,11 +2,11 @@
 % Please edit documentation in R/convert_between_common_language.R
 \name{d_to_cles}
 \alias{d_to_cles}
-\alias{convert_d_to_common_language,}
-\alias{d_to_common_language,}
-\alias{rbs_to_common_language,}
-\alias{convert_rbs_to_common_language}
+\alias{convert_d_to_common_language}
+\alias{d_to_common_language}
 \alias{rbs_to_cles}
+\alias{rbs_to_common_language}
+\alias{convert_rbs_to_common_language}
 \title{Convert Standardized Mean Difference to Common Language Effect Sizes}
 \usage{
 d_to_cles(d)",True,False,Documentation / Formatting,6
easystats,effectsize,0c5fefee3efc795b2ca7c7eefddbfe6b38e53114,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-10-24T12:34:55Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-10-24T12:34:55Z,fix: incorrectly names MS column,R/eta_squared.R;vignettes/effectsize_API.Rmd,True,True,True,False,8,4,12,"---FILE: R/eta_squared.R---
@@ -376,10 +376,11 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
                            verbose = TRUE,
                            include_intercept = FALSE) {
   type <- match.arg(type)
+  aov_table <- as.data.frame(aov_table)
 
   # Clean up data ---
-  if (!""Mean_Square_residuals"" %in% colnames(aov_table)) {
-    aov_table[[""Mean_Square_residuals""]] = aov_table[[""Sum_Squares""]] / aov_table[[""df""]]
+  if (!""Mean_Square"" %in% colnames(aov_table)) {
+    aov_table[[""Mean_Square""]] <- aov_table[[""Sum_Squares""]] / aov_table[[""df""]]
   }
 
   if (!""Residuals"" %in% aov_table$Parameter) {
@@ -523,8 +524,8 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
   aov_table <- as.data.frame(aov_table)
 
   # Clean up data ---
-  if (!""Mean_Square_residuals"" %in% colnames(aov_table)) {
-    aov_table[[""Mean_Square_residuals""]] <- aov_table[[""Sum_Squares""]] / aov_table[[""df""]]
+  if (!""Mean_Square"" %in% colnames(aov_table)) {
+    aov_table[[""Mean_Square""]] <- aov_table[[""Sum_Squares""]] / aov_table[[""df""]]
   }
 
   if (!""Residuals"" %in% aov_table$Parameter) {
@@ -657,6 +658,7 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
                           ci = 0.95, alternative = ""greater"",
                           verbose = TRUE,
                           include_intercept = FALSE) {
+  aov_table <- as.data.frame(aov_table)
 
   # Get correct function ---
   type <- match.arg(type)

---FILE: vignettes/effectsize_API.Rmd---
@@ -214,6 +214,8 @@ eta_squared(mod)
 eta_squared(mod, partial = FALSE)
 
 omega_squared(mod)
+
+# Etc...
 ```
 
 ",True,True,Implementation / Logic,6
easystats,effectsize,1473805bc8b72eced22c55feb4699b149bc79105,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-10-21T11:16:41Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-10-21T11:16:41Z,fix: API vignette,vignettes/effectsize_API.Rmd,True,False,True,False,12,0,12,"---FILE: vignettes/effectsize_API.Rmd---
@@ -22,6 +22,18 @@ knitr::opts_chunk$set(comment = "">"",
                       message = FALSE)
 options(digits = 2)
 options(knitr.kable.NA = '')
+
+
+pkgs <- c(""effectsize"")
+if (!all(sapply(pkgs, requireNamespace, quietly = TRUE))) {
+  knitr::opts_chunk$set(eval = FALSE)
+}
+
+set.seed(333)
+```
+
+```{r}
+library(effectsize)
 ```
 
 # Supporting ANOVA Effect Sizes",False,True,Implementation / Logic,6
easystats,effectsize,cfb82d504ee35d9fe3bb95d2ba15a76841bdda45,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-10-21T07:32:48Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-10-21T07:32:48Z,fix: vignette error,R/cohens_d.R;vignettes/standardize_parameters.Rmd,True,True,True,False,9,7,16,"---FILE: R/cohens_d.R---
@@ -234,7 +234,7 @@ glass_delta <- function(x,
     ci = ci,
     verbose = verbose,
     pooled_sd = NULL,
-    paired = NULL,
+    paired = FALSE,
     ...
   )
 }

---FILE: vignettes/standardize_parameters.Rmd---
@@ -76,9 +76,7 @@ of `0.87`, but did you know that for a simple regression this is actually the
 interpretation guidelines (e.g., Cohen's rules of thumb).
 
 ```{r}
-r <- cor.test(attitude$rating, attitude$complaints)
-
-effectsize(r)
+correlation::correlation(attitude, select = c(""rating"", ""complaints""))
 ```
 
 ## Standardized Differences
@@ -90,6 +88,7 @@ that it is similar to a **Cohen's *d***. Well, let's see.
 ```{r include=FALSE}
 mtcars <- datasets::mtcars
 ```
+
 ```{r}
 # Select portion of data containing the two levels of interest
 mtcars$am <- factor(mtcars$am, labels = c(""Manual"", ""Automatic""))
@@ -181,9 +180,12 @@ data(""hardlyworking"", package = ""effectsize"")
 
 head(hardlyworking)
 
-correlation::correlation(data = hardlyworking[,1], # the outcome of salary
-                         data2 = hardlyworking[,-1], # the predictors
-                         partial = TRUE) # get partial correlations
+correlation::correlation(
+  hardlyworking,
+  select = ""salary"",
+  select2 = c(""xtra_hours"", ""n_comps"", ""age"", ""seniority""),
+  partial = TRUE # get partial correlations
+) 
 ```
 
 Let's compare these to the standardized slopes:",True,True,Implementation / Logic,6
easystats,effectsize,2a2853ecb90a8d155710bee2108c5c93f6561cb4,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-10-19T11:39:42Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-10-19T11:39:42Z,fix: print rules tests,tests/testthat/test-printing.R,False,True,True,False,2,2,4,"---FILE: tests/testthat/test-printing.R---
@@ -51,13 +51,13 @@ if (require(""testthat"") && require(""effectsize"")) {
 
   test_that(""rules"", {
     r1 <- rules(1:3, letters[1:4], name = ""XX"")
-    expect_output(print(r1), regexp = ""thresholds"")
+    expect_output(print(r1), regexp = ""Thresholds"")
     expect_output(print(r1), regexp = ""<="")
     expect_output(print(r1), regexp = ""XX"")
 
 
     r2 <- rules(1:3, letters[1:3], name = ""YY"")
-    expect_output(print(r2), regexp = ""values"")
+    expect_output(print(r2), regexp = ""Values"")
     expect_output(print(r2), regexp = ""YY"")
 
 ",True,False,Dependency / Package,3
easystats,effectsize,e5a24a6ea6ba8129e9182be8893c2fb4663369e5,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-10-19T04:47:14Z,Mattan S. Ben-Shachar,matanshm@post.bgu.ac.il,2021-10-19T04:47:14Z,simplify fix to #389,R/eta_squared.R,False,True,True,False,9,13,22,"---FILE: R/eta_squared.R---
@@ -1103,9 +1103,14 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
     aov_tab <- aov_tab[c(""Parameter"", ""Sum_Squares"",""Error SS"", ""df"", ""den Df"")]
 
     id <- attr(model, ""id"")
-    within <- c(NA, names(attr(model, ""within"")))
-    within <- sapply(seq_len(length(within) - 1), .get_all_combs, V = within)
-    within <- unique(unlist(within))
+    within <- names(attr(model, ""within""))
+    within <- lapply(within, function(x) c(NA, x))
+    within <- do.call(expand.grid, within)
+    within <- apply(within, 1, na.omit)
+    ns <- sapply(within, length)
+    within <- sapply(within, paste, collapse = "":"")
+    within <- within[order(ns)]
+    within <- Filter(function(x) nchar(x) > 0, within)
     l <- sapply(within, grepl, x = aov_tab$Parameter, simplify = TRUE)
     l <- apply(l, 1, function(x) if (!any(x)) 0 else max(which(x)))
     l <- c(NA, within)[l+1]
@@ -1212,13 +1217,4 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.95, alternative = ""gr
   out <- .F_to_pve(stats::na.omit(f), df = df_num, df_error = df_error, ci = ci, alternative = alternative, es = paste0(type, ""2""))
   out$Parameter <- model$Parameter[!is.na(f)]
   out[c(ncol(out), 1:(ncol(out) - 1))]
-}
-
-#' @keywords internal
-.get_all_combs <- function(V, n) {
-  within <- utils::combn(V, n)
-  within <- apply(within, 2, as.list)
-  within <- Filter(f = function(x) !all(is.na(x)), within)
-  within <- lapply(within, Filter, f = Negate(is.na))
-  within <- sapply(within, paste0, collapse = "":"")
-}
+}
\ No newline at end of file",True,False,Implementation / Logic,6
easystats,effectsize,e61653efeda2ba7fe211e0f75c9894cc79d4da9b,mattansb,35330040+mattansb@users.noreply.github.com,2021-10-04T14:04:48Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-10-04T14:04:48Z,fix effectsize.BF tests,tests/testthat/test-effectsize.R,False,True,True,False,5,5,10,"---FILE: tests/testthat/test-effectsize.R---
@@ -213,16 +213,16 @@ if (require(""testthat"") && require(""effectsize"")) {
     set.seed(6)
     data(raceDolls, package = ""BayesFactor"")
     bf1 <- BayesFactor::contingencyTableBF(raceDolls, sampleType = ""poisson"", fixedMargin = ""cols"")
-    expect_equal(effectsize(bf1, test = NULL)[[2]], 0.164, tolerance = 0.01)
-    expect_equal(effectsize(bf1, test = NULL, type = ""OR"")[[2]], 1 / 0.503, tolerance = 0.03)
+    expect_equal(effectsize(bf1)[[1]], 0.164, tolerance = 0.01)
+    expect_equal(effectsize(bf1, type = ""OR"")[[1]], 1 / 0.503, tolerance = 0.03)
 
     bf2 <- BayesFactor::ttestBF(mtcars$mpg[mtcars$am == 1], mtcars$mpg[mtcars$am == 0])
-    expect_equal(effectsize(bf2, test = NULL)[[2]], 1.30, tolerance = 0.03)
+    expect_equal(effectsize(bf2)[[1]], 1.30, tolerance = 0.03)
 
     bf3 <- BayesFactor::correlationBF(iris$Sepal.Length, iris$Sepal.Width)
-    expect_equal(effectsize(bf3, test = NULL)[[2]], -0.116, tolerance = 0.03)
+    expect_equal(effectsize(bf3)[[1]], -0.116, tolerance = 0.03)
 
     bf4 <- BayesFactor::proportionBF(4, 12, 0.5)
-    expect_equal(effectsize(bf4, test = NULL)[[2]], 0.3911, tolerance = 0.03)
+    expect_equal(effectsize(bf4)[[1]], 0.3911, tolerance = 0.03)
   })
 }",True,False,Implementation / Logic,6
easystats,effectsize,4895ff947582854b5678b5fbd4387f7c6aaa8516,mattansb,35330040+mattansb@users.noreply.github.com,2021-10-03T05:45:43Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-10-03T05:45:43Z,fix winbuilder doc issues,NEWS.md;R/docs_extra.R;cran-comments.md;man/F_to_eta2.Rd;man/chisq_to_phi.Rd;man/cohens_d.Rd;man/effectsize_CIs.Rd;man/eta_squared.Rd;man/phi.Rd;man/t_to_r.Rd,False,True,True,False,162,234,396,"---FILE: NEWS.md---
@@ -6,7 +6,7 @@
 - `interpret_d()`, `interpret_g()`, and `interpret_delta()` are now `interpret_cohens_d()`, `interpret_hedges_g()`, and `interpret_glass_delta()`.
 - `interpret_parameters()` was removed. Use `interpret_r()` instead (with caution!).
 - Phi, Cohen's *w*, Cramer's *V*, ANOVA effect sizes, rank Epsilon squared, Kendall's *W* - CIs default to 95% one-sided CIs (`alternative = ""greater""`). (To restore previous behavior, set `ci = .9, alternative = ""two.sided""`.)
-- `adjust()`, `change_scale()`, `normalize()`, `ranktransform()`, `standardize()` (data), and `unstandardize()` have moved to the new [`{datawizard}`](https://easystats.github.io/datawizard) package!
+- `adjust()`, `change_scale()`, `normalize()`, `ranktransform()`, `standardize()` (data), and `unstandardize()` have moved to the new [`{datawizard}`](https://easystats.github.io/datawizard/) package!
 
 ## New features
 

---FILE: R/docs_extra.R---
@@ -5,17 +5,14 @@
 #'
 #' @section Confidence (Compatibility) Intervals (CIs):
 #' Unless stated otherwise, confidence (compatibility) intervals (CIs) are
-#' estimated using the noncentrality parameter method (also called the
-#' ""pivot method""). This method finds the noncentrality parameter (""*ncp*"") of
-#' a noncentral *t*, *F*, or
-#' \ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
-#' distribution that places the observed *t*, *F*, or
-#' \ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
-#' test statistic at the desired probability point of the distribution.
-#' For example, if the observed *t* statistic is 2.0, with 50
-#' degrees of freedom, for which cumulative noncentral *t* distribution is
-#' *t* = 2.0 the .025 quantile (answer: the noncentral *t* distribution with
-#' *ncp* = .04)? After estimating these confidence bounds on the *ncp*, they are
+#' estimated using the noncentrality parameter method (also called the ""pivot
+#' method""). This method finds the noncentrality parameter (""*ncp*"") of a
+#' noncentral *t*, *F*, or \eqn{\chi^2} distribution that places the observed
+#' *t*, *F*, or \eqn{\chi^2} test statistic at the desired probability point of
+#' the distribution. For example, if the observed *t* statistic is 2.0, with 50
+#' degrees of freedom, for which cumulative noncentral *t* distribution is *t* =
+#' 2.0 the .025 quantile (answer: the noncentral *t* distribution with *ncp* =
+#' .04)? After estimating these confidence bounds on the *ncp*, they are
 #' converted into the effect size metric to obtain a confidence interval for the
 #' effect size (Steiger, 2004).
 #' \cr\cr
@@ -26,23 +23,20 @@
 #' in a hypothesis test, and more."" (Steiger, 2004). Confidence (compatibility)
 #' intervals and p values are complementary summaries of parameter uncertainty
 #' given the observed data. A dichotomous hypothesis test could be performed
-#' with either a CI or a p value. The
-#' 100(\ifelse{latex}{\out{$1 - \alpha$}}{\ifelse{html}{\out{1 &minus; &alpha;}}{1 - alpha}})%
-#' confidence interval contains all of the parameter values for which
-#' \ifelse{latex}{\out{$p > \alpha$}}{\ifelse{html}{\out{p > &alpha;}}{p > alpha}}
+#' with either a CI or a p value. The 100 (1 - \eqn{\alpha})% confidence
+#' interval contains all of the parameter values for which *p* > \eqn{\alpha}
 #' for the current data and model. For example, a 95% confidence interval
 #' contains all of the values for which p > .05.
 #' \cr\cr
 #' Note that a confidence interval including 0 *does not* indicate that the null
 #' (no effect) is true. Rather, it suggests that the observed data together with
 #' the model and its assumptions combined do not provided clear evidence against
 #' a parameter value of 0 (same as with any other value in the interval), with
-#' the level of this evidence defined by the chosen
-#' \ifelse{latex}{\out{$\alpha$}}{\ifelse{html}{\out{&alpha;}}{alpha}} level
-#' (Rafi & Greenland, 2020; Schweder & Hjort, 2016; Xie & Singh, 2013). To infer
-#' no effect, additional judgments about what parameter values are ""close
-#' enough"" to 0 to be negligible are needed (""equivalence testing""; Bauer &
-#' Kiesser, 1996).
+#' the level of this evidence defined by the chosen \eqn{\alpha} level (Rafi &
+#' Greenland, 2020; Schweder & Hjort, 2016; Xie & Singh, 2013). To infer no
+#' effect, additional judgments about what parameter values are ""close enough""
+#' to 0 to be negligible are needed (""equivalence testing""; Bauer & Kiesser,
+#' 1996).
 #'
 #' @section One-Sided CIs:
 #' Typically, CIs are constructed as two-tailed intervals, with an equal
@@ -59,51 +53,39 @@
 #' are generally tested using 2-tailed tests and 2-sided CIs.
 #' \cr\cr
 #' Some effect sizes are strictly positive--they do have a minimum value, of 0.
-#' For example,
-#' \ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{<i>R</i><sup>2</sup>}}{R^2}},
-#' \ifelse{latex}{\out{$\eta^2$}}{\ifelse{html}{\out{&eta;<sup>2</sup>}}{eta^2}},
-#' and other variance-accounted-for effect sizes, as well as Cramer's *V* and
-#' multiple *R*, range from 0 to 1. These typically involve *F*- or
-#' \ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}-statistics
-#' and are generally tested using *1-tailed* tests which test whether the
-#' estimated effect size is *larger* than the hypothesized null value (e.g., 0).
-#' In order for a CI to yield the same significance decision it must then by a
-#' *1-sided* CI, estimating only a lower bound. This is the default CI computed
-#' by *effectsize* for these effect sizes, where `alternative = ""greater""` is
-#' set.
+#' For example, \eqn{R^2}, \eqn{\eta^2}, and other variance-accounted-for effect
+#' sizes, as well as Cramer's *V* and multiple *R*, range from 0 to 1. These
+#' typically involve *F*- or \eqn{\chi^2}-statistics and are generally tested
+#' using *1-tailed* tests which test whether the estimated effect size is
+#' *larger* than the hypothesized null value (e.g., 0). In order for a CI to
+#' yield the same significance decision it must then by a *1-sided* CI,
+#' estimating only a lower bound. This is the default CI computed by
+#' *effectsize* for these effect sizes, where `alternative = ""greater""` is set.
 #' \cr\cr
 #' This lower bound interval indicates the smallest effect size that is not
 #' significantly different from the observed effect size. That is, it is the
 #' minimum effect size compatible with the observed data, background model
-#' assumptions, and
-#' \ifelse{latex}{\out{$\alpha$}}{\ifelse{html}{\out{&alpha;}}{alpha}} level.
-#' This type of interval does not indicate a maximum effect size value; anything
-#' up to the maximum possible value of the effect size (e.g., 1) is in the
-#' interval.
+#' assumptions, and \eqn{\alpha} level. This type of interval does not indicate
+#' a maximum effect size value; anything up to the maximum possible value of the
+#' effect size (e.g., 1) is in the interval.
 #' \cr\cr
 #' One-sided CIs can also be used to test against a maximum effect size value
-#' (e.g., is
-#' \ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{<i>R</i><sup>2</sup>}}{R^2}}
-#' significantly smaller than a perfect correlation of 1.0?) can by setting
-#' `alternative = ""less""`. This estimates a CI with only an *upper* bound;
-#' anything from the minimum possible value of the effect size (e.g., 0) up to
-#' this upper bound is in the interval.
+#' (e.g., is \eqn{R^2} significantly smaller than a perfect correlation of 1.0?)
+#' can by setting `alternative = ""less""`. This estimates a CI with only an
+#' *upper* bound; anything from the minimum possible value of the effect size
+#' (e.g., 0) up to this upper bound is in the interval.
 #' \cr\cr
 #' We can also obtain a 2-sided interval by setting `alternative = ""two-sided""`.
 #' These intervals can be interpreted in the same way as other 2-sided
 #' intervals, such as those for *r*, *d*, or *g*.
 #' \cr\cr
 #' An alternative approach to aligning significance tests using CIs and 1-tailed
 #' *p* values that can often be found in the literature is to construct a
-#' 2-sided CI at a lower confidence level (e.g., 100(\ifelse{latex}{\out{$1 -
-#' 2\alpha$}}{\ifelse{html}{\out{1 &minus; 2&alpha;}}{1 - 2*alpha}})% =
-#' \ifelse{latex}{\out{$100 - 2 \times 5\% = 90\%$}}{\ifelse{html}{\out{100
-#' &minus; 2 &times; 5&percnt; = 90&percnt;}}{100 - 2*5% = 90%}}). This
-#' estimates the lower bound and upper bound for the above 1-sided intervals
-#' simultaneously. These intervals are commonly reported when conducting
-#' **equivalence tests**. For example, a 90% 2-sided interval gives the bounds
-#' for an equivalence test with \ifelse{latex}{\out{$\alpha =
-#' .05$}}{\ifelse{html}{\out{&alpha; = .05}}{alpha = .05}}. However, be aware
+#' 2-sided CI at a lower confidence level (e.g., 100(1-2\eqn{\alpha})% = 100 -
+#' 2*5% = 90%. This estimates the lower bound and upper bound for the above
+#' 1-sided intervals simultaneously. These intervals are commonly reported when
+#' conducting **equivalence tests**. For example, a 90% 2-sided interval gives
+#' the bounds for an equivalence test with \eqn{\alpha} = .05. However, be aware
 #' that this interval does not give 95% coverage for the underlying effect size
 #' parameter value. For that, construct a 95% 2-sided CI.
 #'

---FILE: cran-comments.md---
@@ -4,7 +4,7 @@
 * GitHub Actions (windows):      devel, release, oldrel
 * Github Actions (macOS):        devel, release, oldrel
 * GitHub Actions (ubuntu-16.04): devel, release, oldrel, 3.6, 3.5, 3.4
-* win-builder:                   devel????
+* win-builder:                   release
 
 
 ## R CMD check results

---FILE: man/F_to_eta2.Rd---
@@ -124,17 +124,14 @@ Adjusted (partial) Eta-squared is an alias for (partial) Epsilon-squared.
 \section{Confidence (Compatibility) Intervals (CIs)}{
 
 Unless stated otherwise, confidence (compatibility) intervals (CIs) are
-estimated using the noncentrality parameter method (also called the
-""pivot method""). This method finds the noncentrality parameter (""\emph{ncp}"") of
-a noncentral \emph{t}, \emph{F}, or
-\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
-distribution that places the observed \emph{t}, \emph{F}, or
-\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
-test statistic at the desired probability point of the distribution.
-For example, if the observed \emph{t} statistic is 2.0, with 50
-degrees of freedom, for which cumulative noncentral \emph{t} distribution is
-\emph{t} = 2.0 the .025 quantile (answer: the noncentral \emph{t} distribution with
-\emph{ncp} = .04)? After estimating these confidence bounds on the \emph{ncp}, they are
+estimated using the noncentrality parameter method (also called the ""pivot
+method""). This method finds the noncentrality parameter (""\emph{ncp}"") of a
+noncentral \emph{t}, \emph{F}, or \eqn{\chi^2} distribution that places the observed
+\emph{t}, \emph{F}, or \eqn{\chi^2} test statistic at the desired probability point of
+the distribution. For example, if the observed \emph{t} statistic is 2.0, with 50
+degrees of freedom, for which cumulative noncentral \emph{t} distribution is \emph{t} =
+2.0 the .025 quantile (answer: the noncentral \emph{t} distribution with \emph{ncp} =
+.04)? After estimating these confidence bounds on the \emph{ncp}, they are
 converted into the effect size metric to obtain a confidence interval for the
 effect size (Steiger, 2004).
 \cr\cr
@@ -147,23 +144,20 @@ For additional details on estimation and troubleshooting, see \link{effectsize_C
 in a hypothesis test, and more."" (Steiger, 2004). Confidence (compatibility)
 intervals and p values are complementary summaries of parameter uncertainty
 given the observed data. A dichotomous hypothesis test could be performed
-with either a CI or a p value. The
-100(\ifelse{latex}{\out{$1 - \alpha$}}{\ifelse{html}{\out{1 &minus; &alpha;}}{1 - alpha}})\%
-confidence interval contains all of the parameter values for which
-\ifelse{latex}{\out{$p > \alpha$}}{\ifelse{html}{\out{p > &alpha;}}{p > alpha}}
+with either a CI or a p value. The 100 (1 - \eqn{\alpha})\% confidence
+interval contains all of the parameter values for which \emph{p} > \eqn{\alpha}
 for the current data and model. For example, a 95\% confidence interval
 contains all of the values for which p > .05.
 \cr\cr
 Note that a confidence interval including 0 \emph{does not} indicate that the null
 (no effect) is true. Rather, it suggests that the observed data together with
 the model and its assumptions combined do not provided clear evidence against
 a parameter value of 0 (same as with any other value in the interval), with
-the level of this evidence defined by the chosen
-\ifelse{latex}{\out{$\alpha$}}{\ifelse{html}{\out{&alpha;}}{alpha}} level
-(Rafi & Greenland, 2020; Schweder & Hjort, 2016; Xie & Singh, 2013). To infer
-no effect, additional judgments about what parameter values are ""close
-enough"" to 0 to be negligible are needed (""equivalence testing""; Bauer &
-Kiesser, 1996).
+the level of this evidence defined by the chosen \eqn{\alpha} level (Rafi &
+Greenland, 2020; Schweder & Hjort, 2016; Xie & Singh, 2013). To infer no
+effect, additional judgments about what parameter values are ""close enough""
+to 0 to be negligible are needed (""equivalence testing""; Bauer & Kiesser,
+1996).
 }
 
 \examples{

---FILE: man/chisq_to_phi.Rd---
@@ -100,17 +100,14 @@ Cohen's \emph{w} is equivalent to \emph{Phi}.
 \section{Confidence (Compatibility) Intervals (CIs)}{
 
 Unless stated otherwise, confidence (compatibility) intervals (CIs) are
-estimated using the noncentrality parameter method (also called the
-""pivot method""). This method finds the noncentrality parameter (""\emph{ncp}"") of
-a noncentral \emph{t}, \emph{F}, or
-\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
-distribution that places the observed \emph{t}, \emph{F}, or
-\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
-test statistic at the desired probability point of the distribution.
-For example, if the observed \emph{t} statistic is 2.0, with 50
-degrees of freedom, for which cumulative noncentral \emph{t} distribution is
-\emph{t} = 2.0 the .025 quantile (answer: the noncentral \emph{t} distribution with
-\emph{ncp} = .04)? After estimating these confidence bounds on the \emph{ncp}, they are
+estimated using the noncentrality parameter method (also called the ""pivot
+method""). This method finds the noncentrality parameter (""\emph{ncp}"") of a
+noncentral \emph{t}, \emph{F}, or \eqn{\chi^2} distribution that places the observed
+\emph{t}, \emph{F}, or \eqn{\chi^2} test statistic at the desired probability point of
+the distribution. For example, if the observed \emph{t} statistic is 2.0, with 50
+degrees of freedom, for which cumulative noncentral \emph{t} distribution is \emph{t} =
+2.0 the .025 quantile (answer: the noncentral \emph{t} distribution with \emph{ncp} =
+.04)? After estimating these confidence bounds on the \emph{ncp}, they are
 converted into the effect size metric to obtain a confidence interval for the
 effect size (Steiger, 2004).
 \cr\cr
@@ -123,23 +120,20 @@ For additional details on estimation and troubleshooting, see \link{effectsize_C
 in a hypothesis test, and more."" (Steiger, 2004). Confidence (compatibility)
 intervals and p values are complementary summaries of parameter uncertainty
 given the observed data. A dichotomous hypothesis test could be performed
-with either a CI or a p value. The
-100(\ifelse{latex}{\out{$1 - \alpha$}}{\ifelse{html}{\out{1 &minus; &alpha;}}{1 - alpha}})\%
-confidence interval contains all of the parameter values for which
-\ifelse{latex}{\out{$p > \alpha$}}{\ifelse{html}{\out{p > &alpha;}}{p > alpha}}
+with either a CI or a p value. The 100 (1 - \eqn{\alpha})\% confidence
+interval contains all of the parameter values for which \emph{p} > \eqn{\alpha}
 for the current data and model. For example, a 95\% confidence interval
 contains all of the values for which p > .05.
 \cr\cr
 Note that a confidence interval including 0 \emph{does not} indicate that the null
 (no effect) is true. Rather, it suggests that the observed data together with
 the model and its assumptions combined do not provided clear evidence against
 a parameter value of 0 (same as with any other value in the interval), with
-the level of this evidence defined by the chosen
-\ifelse{latex}{\out{$\alpha$}}{\ifelse{html}{\out{&alpha;}}{alpha}} level
-(Rafi & Greenland, 2020; Schweder & Hjort, 2016; Xie & Singh, 2013). To infer
-no effect, additional judgments about what parameter values are ""close
-enough"" to 0 to be negligible are needed (""equivalence testing""; Bauer &
-Kiesser, 1996).
+the level of this evidence defined by the chosen \eqn{\alpha} level (Rafi &
+Greenland, 2020; Schweder & Hjort, 2016; Xie & Singh, 2013). To infer no
+effect, additional judgments about what parameter values are ""close enough""
+to 0 to be negligible are needed (""equivalence testing""; Bauer & Kiesser,
+1996).
 }
 
 \examples{

---FILE: man/cohens_d.Rd---
@@ -105,17 +105,14 @@ applying Bessel's correction).
 \section{Confidence (Compatibility) Intervals (CIs)}{
 
 Unless stated otherwise, confidence (compatibility) intervals (CIs) are
-estimated using the noncentrality parameter method (also called the
-""pivot method""). This method finds the noncentrality parameter (""\emph{ncp}"") of
-a noncentral \emph{t}, \emph{F}, or
-\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
-distribution that places the observed \emph{t}, \emph{F}, or
-\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
-test statistic at the desired probability point of the distribution.
-For example, if the observed \emph{t} statistic is 2.0, with 50
-degrees of freedom, for which cumulative noncentral \emph{t} distribution is
-\emph{t} = 2.0 the .025 quantile (answer: the noncentral \emph{t} distribution with
-\emph{ncp} = .04)? After estimating these confidence bounds on the \emph{ncp}, they are
+estimated using the noncentrality parameter method (also called the ""pivot
+method""). This method finds the noncentrality parameter (""\emph{ncp}"") of a
+noncentral \emph{t}, \emph{F}, or \eqn{\chi^2} distribution that places the observed
+\emph{t}, \emph{F}, or \eqn{\chi^2} test statistic at the desired probability point of
+the distribution. For example, if the observed \emph{t} statistic is 2.0, with 50
+degrees of freedom, for which cumulative noncentral \emph{t} distribution is \emph{t} =
+2.0 the .025 quantile (answer: the noncentral \emph{t} distribution with \emph{ncp} =
+.04)? After estimating these confidence bounds on the \emph{ncp}, they are
 converted into the effect size metric to obtain a confidence interval for the
 effect size (Steiger, 2004).
 \cr\cr
@@ -128,23 +125,20 @@ For additional details on estimation and troubleshooting, see \link{effectsize_C
 in a hypothesis test, and more."" (Steiger, 2004). Confidence (compatibility)
 intervals and p values are complementary summaries of parameter uncertainty
 given the observed data. A dichotomous hypothesis test could be performed
-with either a CI or a p value. The
-100(\ifelse{latex}{\out{$1 - \alpha$}}{\ifelse{html}{\out{1 &minus; &alpha;}}{1 - alpha}})\%
-confidence interval contains all of the parameter values for which
-\ifelse{latex}{\out{$p > \alpha$}}{\ifelse{html}{\out{p > &alpha;}}{p > alpha}}
+with either a CI or a p value. The 100 (1 - \eqn{\alpha})\% confidence
+interval contains all of the parameter values for which \emph{p} > \eqn{\alpha}
 for the current data and model. For example, a 95\% confidence interval
 contains all of the values for which p > .05.
 \cr\cr
 Note that a confidence interval including 0 \emph{does not} indicate that the null
 (no effect) is true. Rather, it suggests that the observed data together with
 the model and its assumptions combined do not provided clear evidence against
 a parameter value of 0 (same as with any other value in the interval), with
-the level of this evidence defined by the chosen
-\ifelse{latex}{\out{$\alpha$}}{\ifelse{html}{\out{&alpha;}}{alpha}} level
-(Rafi & Greenland, 2020; Schweder & Hjort, 2016; Xie & Singh, 2013). To infer
-no effect, additional judgments about what parameter values are ""close
-enough"" to 0 to be negligible are needed (""equivalence testing""; Bauer &
-Kiesser, 1996).
+the level of this evidence defined by the chosen \eqn{\alpha} level (Rafi &
+Greenland, 2020; Schweder & Hjort, 2016; Xie & Singh, 2013). To infer no
+effect, additional judgments about what parameter values are ""close enough""
+to 0 to be negligible are needed (""equivalence testing""; Bauer & Kiesser,
+1996).
 }
 
 \examples{

---FILE: man/effectsize_CIs.Rd---
@@ -10,17 +10,14 @@ they are computed in \emph{effectsize}.
 \section{Confidence (Compatibility) Intervals (CIs)}{
 
 Unless stated otherwise, confidence (compatibility) intervals (CIs) are
-estimated using the noncentrality parameter method (also called the
-""pivot method""). This method finds the noncentrality parameter (""\emph{ncp}"") of
-a noncentral \emph{t}, \emph{F}, or
-\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
-distribution that places the observed \emph{t}, \emph{F}, or
-\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
-test statistic at the desired probability point of the distribution.
-For example, if the observed \emph{t} statistic is 2.0, with 50
-degrees of freedom, for which cumulative noncentral \emph{t} distribution is
-\emph{t} = 2.0 the .025 quantile (answer: the noncentral \emph{t} distribution with
-\emph{ncp} = .04)? After estimating these confidence bounds on the \emph{ncp}, they are
+estimated using the noncentrality parameter method (also called the ""pivot
+method""). This method finds the noncentrality parameter (""\emph{ncp}"") of a
+noncentral \emph{t}, \emph{F}, or \eqn{\chi^2} distribution that places the observed
+\emph{t}, \emph{F}, or \eqn{\chi^2} test statistic at the desired probability point of
+the distribution. For example, if the observed \emph{t} statistic is 2.0, with 50
+degrees of freedom, for which cumulative noncentral \emph{t} distribution is \emph{t} =
+2.0 the .025 quantile (answer: the noncentral \emph{t} distribution with \emph{ncp} =
+.04)? After estimating these confidence bounds on the \emph{ncp}, they are
 converted into the effect size metric to obtain a confidence interval for the
 effect size (Steiger, 2004).
 \cr\cr
@@ -33,23 +30,20 @@ For additional details on estimation and troubleshooting, see \link{effectsize_C
 in a hypothesis test, and more."" (Steiger, 2004). Confidence (compatibility)
 intervals and p values are complementary summaries of parameter uncertainty
 given the observed data. A dichotomous hypothesis test could be performed
-with either a CI or a p value. The
-100(\ifelse{latex}{\out{$1 - \alpha$}}{\ifelse{html}{\out{1 &minus; &alpha;}}{1 - alpha}})\%
-confidence interval contains all of the parameter values for which
-\ifelse{latex}{\out{$p > \alpha$}}{\ifelse{html}{\out{p > &alpha;}}{p > alpha}}
+with either a CI or a p value. The 100 (1 - \eqn{\alpha})\% confidence
+interval contains all of the parameter values for which \emph{p} > \eqn{\alpha}
 for the current data and model. For example, a 95\% confidence interval
 contains all of the values for which p > .05.
 \cr\cr
 Note that a confidence interval including 0 \emph{does not} indicate that the null
 (no effect) is true. Rather, it suggests that the observed data together with
 the model and its assumptions combined do not provided clear evidence against
 a parameter value of 0 (same as with any other value in the interval), with
-the level of this evidence defined by the chosen
-\ifelse{latex}{\out{$\alpha$}}{\ifelse{html}{\out{&alpha;}}{alpha}} level
-(Rafi & Greenland, 2020; Schweder & Hjort, 2016; Xie & Singh, 2013). To infer
-no effect, additional judgments about what parameter values are ""close
-enough"" to 0 to be negligible are needed (""equivalence testing""; Bauer &
-Kiesser, 1996).
+the level of this evidence defined by the chosen \eqn{\alpha} level (Rafi &
+Greenland, 2020; Schweder & Hjort, 2016; Xie & Singh, 2013). To infer no
+effect, additional judgments about what parameter values are ""close enough""
+to 0 to be negligible are needed (""equivalence testing""; Bauer & Kiesser,
+1996).
 }
 
 \section{One-Sided CIs}{
@@ -68,51 +62,39 @@ Most effect sizes are not bounded by zero (e.g., \emph{r}, \emph{d}, \emph{g}),
 are generally tested using 2-tailed tests and 2-sided CIs.
 \cr\cr
 Some effect sizes are strictly positive--they do have a minimum value, of 0.
-For example,
-\ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{<i>R</i><sup>2</sup>}}{R^2}},
-\ifelse{latex}{\out{$\eta^2$}}{\ifelse{html}{\out{&eta;<sup>2</sup>}}{eta^2}},
-and other variance-accounted-for effect sizes, as well as Cramer's \emph{V} and
-multiple \emph{R}, range from 0 to 1. These typically involve \emph{F}- or
-\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}-statistics
-and are generally tested using \emph{1-tailed} tests which test whether the
-estimated effect size is \emph{larger} than the hypothesized null value (e.g., 0).
-In order for a CI to yield the same significance decision it must then by a
-\emph{1-sided} CI, estimating only a lower bound. This is the default CI computed
-by \emph{effectsize} for these effect sizes, where \code{alternative = ""greater""} is
-set.
+For example, \eqn{R^2}, \eqn{\eta^2}, and other variance-accounted-for effect
+sizes, as well as Cramer's \emph{V} and multiple \emph{R}, range from 0 to 1. These
+typically involve \emph{F}- or \eqn{\chi^2}-statistics and are generally tested
+using \emph{1-tailed} tests which test whether the estimated effect size is
+\emph{larger} than the hypothesized null value (e.g., 0). In order for a CI to
+yield the same significance decision it must then by a \emph{1-sided} CI,
+estimating only a lower bound. This is the default CI computed by
+\emph{effectsize} for these effect sizes, where \code{alternative = ""greater""} is set.
 \cr\cr
 This lower bound interval indicates the smallest effect size that is not
 significantly different from the observed effect size. That is, it is the
 minimum effect size compatible with the observed data, background model
-assumptions, and
-\ifelse{latex}{\out{$\alpha$}}{\ifelse{html}{\out{&alpha;}}{alpha}} level.
-This type of interval does not indicate a maximum effect size value; anything
-up to the maximum possible value of the effect size (e.g., 1) is in the
-interval.
+assumptions, and \eqn{\alpha} level. This type of interval does not indicate
+a maximum effect size value; anything up to the maximum possible value of the
+effect size (e.g., 1) is in the interval.
 \cr\cr
 One-sided CIs can also be used to test against a maximum effect size value
-(e.g., is
-\ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{<i>R</i><sup>2</sup>}}{R^2}}
-significantly smaller than a perfect correlation of 1.0?) can by setting
-\code{alternative = ""less""}. This estimates a CI with only an \emph{upper} bound;
-anything from the minimum possible value of the effect size (e.g., 0) up to
-this upper bound is in the interval.
+(e.g., is \eqn{R^2} significantly smaller than a perfect correlation of 1.0?)
+can by setting \code{alternative = ""less""}. This estimates a CI with only an
+\emph{upper} bound; anything from the minimum possible value of the effect size
+(e.g., 0) up to this upper bound is in the interval.
 \cr\cr
 We can also obtain a 2-sided interval by setting \code{alternative = ""two-sided""}.
 These intervals can be interpreted in the same way as other 2-sided
 intervals, such as those for \emph{r}, \emph{d}, or \emph{g}.
 \cr\cr
 An alternative approach to aligning significance tests using CIs and 1-tailed
 \emph{p} values that can often be found in the literature is to construct a
-2-sided CI at a lower confidence level (e.g., 100(\ifelse{latex}{\out{$1 -
-2\alpha$}}{\ifelse{html}{\out{1 &minus; 2&alpha;}}{1 - 2*alpha}})\% =
-\ifelse{latex}{\out{$100 - 2 \times 5\% = 90\%$}}{\ifelse{html}{\out{100
-&minus; 2 &times; 5&percnt; = 90&percnt;}}{100 - 2*5\% = 90\%}}). This
-estimates the lower bound and upper bound for the above 1-sided intervals
-simultaneously. These intervals are commonly reported when conducting
-\strong{equivalence tests}. For example, a 90\% 2-sided interval gives the bounds
-for an equivalence test with \ifelse{latex}{\out{$\alpha =
-.05$}}{\ifelse{html}{\out{&alpha; = .05}}{alpha = .05}}. However, be aware
+2-sided CI at a lower confidence level (e.g., 100(1-2\eqn{\alpha})\% = 100 -
+2*5\% = 90\%. This estimates the lower bound and upper bound for the above
+1-sided intervals simultaneously. These intervals are commonly reported when
+conducting \strong{equivalence tests}. For example, a 90\% 2-sided interval gives
+the bounds for an equivalence test with \eqn{\alpha} = .05. However, be aware
 that this interval does not give 95\% coverage for the underlying effect size
 parameter value. For that, construct a 95\% 2-sided CI.\if{html}{\out{<div class=""r"">}}\preformatted{data(""hardlyworking"")
 fit <- lm(salary ~ n_comps + age, data = hardlyworking)

---FILE: man/eta_squared.Rd---
@@ -198,17 +198,14 @@ more info.
 \section{Confidence (Compatibility) Intervals (CIs)}{
 
 Unless stated otherwise, confidence (compatibility) intervals (CIs) are
-estimated using the noncentrality parameter method (also called the
-""pivot method""). This method finds the noncentrality parameter (""\emph{ncp}"") of
-a noncentral \emph{t}, \emph{F}, or
-\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
-distribution that places the observed \emph{t}, \emph{F}, or
-\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
-test statistic at the desired probability point of the distribution.
-For example, if the observed \emph{t} statistic is 2.0, with 50
-degrees of freedom, for which cumulative noncentral \emph{t} distribution is
-\emph{t} = 2.0 the .025 quantile (answer: the noncentral \emph{t} distribution with
-\emph{ncp} = .04)? After estimating these confidence bounds on the \emph{ncp}, they are
+estimated using the noncentrality parameter method (also called the ""pivot
+method""). This method finds the noncentrality parameter (""\emph{ncp}"") of a
+noncentral \emph{t}, \emph{F}, or \eqn{\chi^2} distribution that places the observed
+\emph{t}, \emph{F}, or \eqn{\chi^2} test statistic at the desired probability point of
+the distribution. For example, if the observed \emph{t} statistic is 2.0, with 50
+degrees of freedom, for which cumulative noncentral \emph{t} distribution is \emph{t} =
+2.0 the .025 quantile (answer: the noncentral \emph{t} distribution with \emph{ncp} =
+.04)? After estimating these confidence bounds on the \emph{ncp}, they are
 converted into the effect size metric to obtain a confidence interval for the
 effect size (Steiger, 2004).
 \cr\cr
@@ -221,23 +218,20 @@ For additional details on estimation and troubleshooting, see \link{effectsize_C
 in a hypothesis test, and more."" (Steiger, 2004). Confidence (compatibility)
 intervals and p values are complementary summaries of parameter uncertainty
 given the observed data. A dichotomous hypothesis test could be performed
-with either a CI or a p value. The
-100(\ifelse{latex}{\out{$1 - \alpha$}}{\ifelse{html}{\out{1 &minus; &alpha;}}{1 - alpha}})\%
-confidence interval contains all of the parameter values for which
-\ifelse{latex}{\out{$p > \alpha$}}{\ifelse{html}{\out{p > &alpha;}}{p > alpha}}
+with either a CI or a p value. The 100 (1 - \eqn{\alpha})\% confidence
+interval contains all of the parameter values for which \emph{p} > \eqn{\alpha}
 for the current data and model. For example, a 95\% confidence interval
 contains all of the values for which p > .05.
 \cr\cr
 Note that a confidence interval including 0 \emph{does not} indicate that the null
 (no effect) is true. Rather, it suggests that the observed data together with
 the model and its assumptions combined do not provided clear evidence against
 a parameter value of 0 (same as with any other value in the interval), with
-the level of this evidence defined by the chosen
-\ifelse{latex}{\out{$\alpha$}}{\ifelse{html}{\out{&alpha;}}{alpha}} level
-(Rafi & Greenland, 2020; Schweder & Hjort, 2016; Xie & Singh, 2013). To infer
-no effect, additional judgments about what parameter values are ""close
-enough"" to 0 to be negligible are needed (""equivalence testing""; Bauer &
-Kiesser, 1996).
+the level of this evidence defined by the chosen \eqn{\alpha} level (Rafi &
+Greenland, 2020; Schweder & Hjort, 2016; Xie & Singh, 2013). To infer no
+effect, additional judgments about what parameter values are ""close enough""
+to 0 to be negligible are needed (""equivalence testing""; Bauer & Kiesser,
+1996).
 }
 
 \examples{

---FILE: man/phi.Rd---
@@ -109,17 +109,14 @@ Pearson's \emph{C}.
 \section{Confidence (Compatibility) Intervals (CIs)}{
 
 Unless stated otherwise, confidence (compatibility) intervals (CIs) are
-estimated using the noncentrality parameter method (also called the
-""pivot method""). This method finds the noncentrality parameter (""\emph{ncp}"") of
-a noncentral \emph{t}, \emph{F}, or
-\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
-distribution that places the observed \emph{t}, \emph{F}, or
-\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
-test statistic at the desired probability point of the distribution.
-For example, if the observed \emph{t} statistic is 2.0, with 50
-degrees of freedom, for which cumulative noncentral \emph{t} distribution is
-\emph{t} = 2.0 the .025 quantile (answer: the noncentral \emph{t} distribution with
-\emph{ncp} = .04)? After estimating these confidence bounds on the \emph{ncp}, they are
+estimated using the noncentrality parameter method (also called the ""pivot
+method""). This method finds the noncentrality parameter (""\emph{ncp}"") of a
+noncentral \emph{t}, \emph{F}, or \eqn{\chi^2} distribution that places the observed
+\emph{t}, \emph{F}, or \eqn{\chi^2} test statistic at the desired probability point of
+the distribution. For example, if the observed \emph{t} statistic is 2.0, with 50
+degrees of freedom, for which cumulative noncentral \emph{t} distribution is \emph{t} =
+2.0 the .025 quantile (answer: the noncentral \emph{t} distribution with \emph{ncp} =
+.04)? After estimating these confidence bounds on the \emph{ncp}, they are
 converted into the effect size metric to obtain a confidence interval for the
 effect size (Steiger, 2004).
 \cr\cr
@@ -132,23 +129,20 @@ For additional details on estimation and troubleshooting, see \link{effectsize_C
 in a hypothesis test, and more."" (Steiger, 2004). Confidence (compatibility)
 intervals and p values are complementary summaries of parameter uncertainty
 given the observed data. A dichotomous hypothesis test could be performed
-with either a CI or a p value. The
-100(\ifelse{latex}{\out{$1 - \alpha$}}{\ifelse{html}{\out{1 &minus; &alpha;}}{1 - alpha}})\%
-confidence interval contains all of the parameter values for which
-\ifelse{latex}{\out{$p > \alpha$}}{\ifelse{html}{\out{p > &alpha;}}{p > alpha}}
+with either a CI or a p value. The 100 (1 - \eqn{\alpha})\% confidence
+interval contains all of the parameter values for which \emph{p} > \eqn{\alpha}
 for the current data and model. For example, a 95\% confidence interval
 contains all of the values for which p > .05.
 \cr\cr
 Note that a confidence interval including 0 \emph{does not} indicate that the null
 (no effect) is true. Rather, it suggests that the observed data together with
 the model and its assumptions combined do not provided clear evidence against
 a parameter value of 0 (same as with any other value in the interval), with
-the level of this evidence defined by the chosen
-\ifelse{latex}{\out{$\alpha$}}{\ifelse{html}{\out{&alpha;}}{alpha}} level
-(Rafi & Greenland, 2020; Schweder & Hjort, 2016; Xie & Singh, 2013). To infer
-no effect, additional judgments about what parameter values are ""close
-enough"" to 0 to be negligible are needed (""equivalence testing""; Bauer &
-Kiesser, 1996).
+the level of this evidence defined by the chosen \eqn{\alpha} level (Rafi &
+Greenland, 2020; Schweder & Hjort, 2016; Xie & Singh, 2013). To infer no
+effect, additional judgments about what parameter values are ""close enough""
+to 0 to be negligible are needed (""equivalence testing""; Bauer & Kiesser,
+1996).
 }
 
 \examples{

---FILE: man/t_to_r.Rd---
@@ -94,17 +94,14 @@ functions.
 \section{Confidence (Compatibility) Intervals (CIs)}{
 
 Unless stated otherwise, confidence (compatibility) intervals (CIs) are
-estimated using the noncentrality parameter method (also called the
-""pivot method""). This method finds the noncentrality parameter (""\emph{ncp}"") of
-a noncentral \emph{t}, \emph{F}, or
-\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
-distribution that places the observed \emph{t}, \emph{F}, or
-\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
-test statistic at the desired probability point of the distribution.
-For example, if the observed \emph{t} statistic is 2.0, with 50
-degrees of freedom, for which cumulative noncentral \emph{t} distribution is
-\emph{t} = 2.0 the .025 quantile (answer: the noncentral \emph{t} distribution with
-\emph{ncp} = .04)? After estimating these confidence bounds on the \emph{ncp}, they are
+estimated using the noncentrality parameter method (also called the ""pivot
+method""). This method finds the noncentrality parameter (""\emph{ncp}"") of a
+noncentral \emph{t}, \emph{F}, or \eqn{\chi^2} distribution that places the observed
+\emph{t}, \emph{F}, or \eqn{\chi^2} test statistic at the desired probability point of
+the distribution. For example, if the observed \emph{t} statistic is 2.0, with 50
+degrees of freedom, for which cumulative noncentral \emph{t} distribution is \emph{t} =
+2.0 the .025 quantile (answer: the noncentral \emph{t} distribution with \emph{ncp} =
+.04)? After estimating these confidence bounds on the \emph{ncp}, they are
 converted into the effect size metric to obtain a confidence interval for the
 effect size (Steiger, 2004).
 \cr\cr
@@ -117,23 +114,20 @@ For additional details on estimation and troubleshooting, see \link{effectsize_C
 in a hypothesis test, and more."" (Steiger, 2004). Confidence (compatibility)
 intervals and p values are complementary summaries of parameter uncertainty
 given the observed data. A dichotomous hypothesis test could be performed
-with either a CI or a p value. The
-100(\ifelse{latex}{\out{$1 - \alpha$}}{\ifelse{html}{\out{1 &minus; &alpha;}}{1 - alpha}})\%
-confidence interval contains all of the parameter values for which
-\ifelse{latex}{\out{$p > \alpha$}}{\ifelse{html}{\out{p > &alpha;}}{p > alpha}}
+with either a CI or a p value. The 100 (1 - \eqn{\alpha})\% confidence
+interval contains all of the parameter values for which \emph{p} > \eqn{\alpha}
 for the current data and model. For example, a 95\% confidence interval
 contains all of the values for which p > .05.
 \cr\cr
 Note that a confidence interval including 0 \emph{does not} indicate that the null
 (no effect) is true. Rather, it suggests that the observed data together with
 the model and its assumptions combined do not provided clear evidence against
 a parameter value of 0 (same as with any other value in the interval), with
-the level of this evidence defined by the chosen
-\ifelse{latex}{\out{$\alpha$}}{\ifelse{html}{\out{&alpha;}}{alpha}} level
-(Rafi & Greenland, 2020; Schweder & Hjort, 2016; Xie & Singh, 2013). To infer
-no effect, additional judgments about what parameter values are ""close
-enough"" to 0 to be negligible are needed (""equivalence testing""; Bauer &
-Kiesser, 1996).
+the level of this evidence defined by the chosen \eqn{\alpha} level (Rafi &
+Greenland, 2020; Schweder & Hjort, 2016; Xie & Singh, 2013). To infer no
+effect, additional judgments about what parameter values are ""close enough""
+to 0 to be negligible are needed (""equivalence testing""; Bauer & Kiesser,
+1996).
 }
 
 \examples{",True,False,Documentation / Formatting,6
easystats,effectsize,196674359d2527715f76b6756f26d803d1e2b021,mattansb,35330040+mattansb@users.noreply.github.com,2021-10-02T18:10:04Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-10-02T18:10:04Z,fix this weird ass bug with different CI methods,tests/testthat/test-convert_between.R,False,True,True,False,6,5,11,"---FILE: tests/testthat/test-convert_between.R---
@@ -16,6 +16,7 @@ if (require(""testthat"") && require(""effectsize"")) {
   })
 
   test_that(""oddsratio_to_RR"", {
+    skip_on_cran()
     p0 <- 0.4
     p1 <- 0.7
 
@@ -32,18 +33,18 @@ if (require(""testthat"") && require(""effectsize"")) {
     # -- GLMs --
     data(mtcars)
 
-    m <- glm(am ~ factor(cyl), data = mtcars,
-             family = binomial())
+    m <<- glm(am ~ factor(cyl), data = mtcars,
+              family = binomial())
 
-    w <- capture_warnings(RR <- oddsratio_to_riskratio(m))
+    w <- capture_warnings(RR <- oddsratio_to_riskratio(m, df_method = ""wald""))
     expect_match(w[1],""p0"")
     expect_match(w[2],""CIs"")
     expect_true(""(Intercept)"" %in% RR$Parameter)
     expect_false(""(p0)"" %in% RR$Parameter)
     # these values confirmed from emmeans
     expect_equal(RR$Coefficient, c(0.7272, 0.5892, 0.1964), tolerance = 0.001)
-    expect_equal(RR$CI_low, c(NA, 0.1118, 0.0232), tolerance = 0.001)
-    # expect_equal(RR$CI_high, c(NA, 1.157, 0.703), tolerance = 0.001) # Don't know why this fails...
+    expect_equal(RR$CI_low, c(NA, 0.1267, 0.0303), tolerance = 0.001)
+    expect_equal(RR$CI_high, c(NA, 1.1648, 0.7589), tolerance = 0.001)
 
     expect_warning(RR <- oddsratio_to_riskratio(m, p0 = 0.05), ""CIs"")
     expect_true(""(p0)"" %in% RR$Parameter)",True,False,Implementation / Logic,6
easystats,effectsize,8f5095d9a00d3ba764c0746e5dd271bab24dc317,mattansb,35330040+mattansb@users.noreply.github.com,2021-10-02T13:10:50Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-10-02T13:10:50Z,fix std mod/params docs,R/standardize.models.R;R/standardize_parameters.R;man/standardize.default.Rd;man/standardize_info.Rd;man/standardize_parameters.Rd,False,True,True,False,112,51,163,"---FILE: R/standardize.models.R---
@@ -3,6 +3,14 @@
 #' Performs a standardization of data (z-scoring) using
 #' [`datawizard::standardize()`] and then re-fits the model to the standardized
 #' data.
+#' \cr\cr
+#' Standardization is done by completely refitting the model on the standardized
+#' data. Hence, this approach is equal to standardizing the variables *before*
+#' fitting the model and will return a new model object. This method is
+#' particularly recommended for complex models that include interactions or
+#' transformations (e.g., polynomial or spline terms). The `robust` (default to
+#' `FALSE`) argument enables a robust standardization of data, based on the
+#' `median` and the `MAD` instead of the `mean` and the `SD`.
 #'
 #' @param x A statistical model.
 #' @param weights If `TRUE` (default), a weighted-standardization is carried out.
@@ -16,11 +24,37 @@
 #'
 #' @return A statistical model fitted on standardized data
 #'
-#' @inheritSection standardize_parameters Generalized Linear Models
+#' @details
 #'
+#' # Generalized Linear Models
+#' Standardization for generalized linear models (GLM, GLMM, etc) is done only
+#' with respect to the predictors (while the outcome remains as-is,
+#' unstandardized) - maintaining the interpretability of the coefficients (e.g.,
+#' in a binomial model: the exponent of the standardized parameter is the OR of
+#' a change of 1 SD in the predictor, etc.)
+#'
+#' # Dealing with Factors
+#' `standardize(model)` or `standardize_parameters(model, method = ""refit"")` do
+#' *not* standardized categorical predictors (i.e. factors) / their
+#' dummy-variables, which may be a different behaviour compared to other R
+#' packages (such as \pkg{lm.beta}) or other software packages (like SPSS). To
+#' mimic such behaviours, either use `standardize_parameters(model, method =
+#' ""basic"")` to obtain post-hoc standardized parameters, or standardize the data
+#' with `datawizard::standardize(data, force = TRUE)` *before* fitting the
+#' model.
+#'
+#' # Transformed Variables
+#' When the model's formula contains transformations (e.g. `y ~ exp(X)`) the
+#' transformation effectively takes place after standardization (e.g.,
+#' `exp(scale(X))`). Since some transformations are undefined for none positive
+#' values, such as `log()` and `sqrt()`, the releven variables are shifted (post
+#' standardization) by `Z - min(Z) + 1` or `Z - min(Z)` (respectively).
+#'
+#' @family standardize
 #' @examples
 #' model <- lm(Infant.Mortality ~ Education * Fertility, data = swiss)
 #' coef(standardize(model))
+#'
 #' @importFrom stats update
 #' @importFrom insight get_data model_info find_response get_response find_weights get_weights
 #' @importFrom datawizard standardize

---FILE: R/standardize_parameters.R---
@@ -74,33 +74,25 @@
 #' level 1 predictors (Hoffman 2015, page 342). A warning is given when a
 #' within-group varialbe is found to have access between-group variance.
 #'
-#' ## Dealing with Factors
-#' The `""refit""` method does *not* standardized categorical predictors (i.e.
-#' factors), which may be a different behaviour compared to other R packages
-#' (such as \pkg{lm.beta}) or other software packages (like SPSS). to mimic such
-#' behaviours, either use the `""basic""` method or standardize the data with
-#' `effectsize::standardize(force=TRUE)` *before* fitting the model.
-#'
-#' ## Transformed Variables
-#' When the model's formula contains transformations (e.g. `y ~ exp(X)`)
-#' `method = ""refit""` might give different results compared to
-#' `method = ""basic""` (`""posthoc""` and `""smart""` do not support such
-#' transformations): where `""refit""` standardizes the data prior to the
-#' transformation (e.g. equivalent to `exp(scale(X))`), the `""basic""` method
-#' standardizes the transformed data (e.g. equivalent to `scale(exp(X))`). See
-#' [standardize()] for more details on how different transformations are dealt
-#' with.
+#' # Transformed Variables
+#' When the model's formula contains transformations (e.g. `y ~ exp(X)`) `method
+#' = ""refit""` will give different results compared to `method = ""basic""`
+#' (`""posthoc""` and `""smart""` do not support such transformations): While
+#' `""refit""` standardizes the data *prior* to the transformation (e.g.
+#' equivalent to `exp(scale(X))`), the `""basic""` method standardizes the
+#' transformed data (e.g. equivalent to `scale(exp(X))`).
+#' \cr\cr
+#' See the *Transformed Variables* section in [standardize.default()] for more
+#' details on how different transformations are dealt with when `method =
+#' ""refit""`.
 #'
 #' # Confidence Intervals
 #' The returned confidence intervals are re-scaled versions of the
 #' unstandardized confidence intervals, and not ""true"" confidence intervals of
 #' the standardized coefficients (cf. Jones & Waller, 2015).
 #'
-#' # Generalized Linear Models
-#' When standardizing coefficients of a generalized model (GLM, GLMM, etc), only
-#' the predictors are standardized, maintaining the interpretability of the
-#' coefficients (e.g., in a binomial model: the exponent of the standardized
-#' parameter is the OR of a change of 1 SD in the predictor, etc.)
+#' @inheritSection standardize.default Generalized Linear Models
+#' @inheritSection standardize.default Dealing with Factors
 #'
 #' @return A data frame with the standardized parameters (`Std_*`, depending on
 #'   the model type) and their CIs (`CI_low` and `CI_high`). Where applicable,
@@ -109,7 +101,6 @@
 #'
 #' @family standardize
 #' @family effect size indices
-#' @seealso [standardize_info()]
 #'
 #' @examples
 #' library(effectsize)

---FILE: man/standardize.default.Rd---
@@ -49,15 +49,49 @@ A statistical model fitted on standardized data
 Performs a standardization of data (z-scoring) using
 \code{\link[datawizard:standardize]{datawizard::standardize()}} and then re-fits the model to the standardized
 data.
+\cr\cr
+Standardization is done by completely refitting the model on the standardized
+data. Hence, this approach is equal to standardizing the variables \emph{before}
+fitting the model and will return a new model object. This method is
+particularly recommended for complex models that include interactions or
+transformations (e.g., polynomial or spline terms). The \code{robust} (default to
+\code{FALSE}) argument enables a robust standardization of data, based on the
+\code{median} and the \code{MAD} instead of the \code{mean} and the \code{SD}.
 }
 \section{Generalized Linear Models}{
-When standardizing coefficients of a generalized model (GLM, GLMM, etc), only
-the predictors are standardized, maintaining the interpretability of the
-coefficients (e.g., in a binomial model: the exponent of the standardized
-parameter is the OR of a change of 1 SD in the predictor, etc.)
+Standardization for generalized linear models (GLM, GLMM, etc) is done only
+with respect to the predictors (while the outcome remains as-is,
+unstandardized) - maintaining the interpretability of the coefficients (e.g.,
+in a binomial model: the exponent of the standardized parameter is the OR of
+a change of 1 SD in the predictor, etc.)
+}
+
+\section{Dealing with Factors}{
+\code{standardize(model)} or \code{standardize_parameters(model, method = ""refit"")} do
+\emph{not} standardized categorical predictors (i.e. factors) / their
+dummy-variables, which may be a different behaviour compared to other R
+packages (such as \pkg{lm.beta}) or other software packages (like SPSS). To
+mimic such behaviours, either use \code{standardize_parameters(model, method = ""basic"")} to obtain post-hoc standardized parameters, or standardize the data
+with \code{datawizard::standardize(data, force = TRUE)} \emph{before} fitting the
+model.
+}
+
+\section{Transformed Variables}{
+When the model's formula contains transformations (e.g. \code{y ~ exp(X)}) the
+transformation effectively takes place after standardization (e.g.,
+\code{exp(scale(X))}). Since some transformations are undefined for none positive
+values, such as \code{log()} and \code{sqrt()}, the releven variables are shifted (post
+standardization) by \code{Z - min(Z) + 1} or \code{Z - min(Z)} (respectively).
 }
 
 \examples{
 model <- lm(Infant.Mortality ~ Education * Fertility, data = swiss)
 coef(standardize(model))
+
+}
+\seealso{
+Other standardize: 
+\code{\link{standardize_info}()},
+\code{\link{standardize_parameters}()}
 }
+\concept{standardize}

---FILE: man/standardize_info.Rd---
@@ -51,6 +51,7 @@ standardize_info(model, two_sd = TRUE)
 }
 \seealso{
 Other standardize: 
+\code{\link{standardize.default}()},
 \code{\link{standardize_parameters}()}
 }
 \concept{standardize}

---FILE: man/standardize_parameters.Rd---
@@ -127,26 +127,17 @@ is used for level 2 predictors, and \code{sqrt(residual-variance)} is used for
 level 1 predictors (Hoffman 2015, page 342). A warning is given when a
 within-group varialbe is found to have access between-group variance.
 }
-\subsection{Dealing with Factors}{
-
-The \code{""refit""} method does \emph{not} standardized categorical predictors (i.e.
-factors), which may be a different behaviour compared to other R packages
-(such as \pkg{lm.beta}) or other software packages (like SPSS). to mimic such
-behaviours, either use the \code{""basic""} method or standardize the data with
-\code{effectsize::standardize(force=TRUE)} \emph{before} fitting the model.
 }
 
-\subsection{Transformed Variables}{
-
-When the model's formula contains transformations (e.g. \code{y ~ exp(X)})
-\code{method = ""refit""} might give different results compared to
-\code{method = ""basic""} (\code{""posthoc""} and \code{""smart""} do not support such
-transformations): where \code{""refit""} standardizes the data prior to the
-transformation (e.g. equivalent to \code{exp(scale(X))}), the \code{""basic""} method
-standardizes the transformed data (e.g. equivalent to \code{scale(exp(X))}). See
-\code{\link[=standardize]{standardize()}} for more details on how different transformations are dealt
-with.
-}
+\section{Transformed Variables}{
+When the model's formula contains transformations (e.g. \code{y ~ exp(X)}) \code{method = ""refit""} will give different results compared to \code{method = ""basic""}
+(\code{""posthoc""} and \code{""smart""} do not support such transformations): While
+\code{""refit""} standardizes the data \emph{prior} to the transformation (e.g.
+equivalent to \code{exp(scale(X))}), the \code{""basic""} method standardizes the
+transformed data (e.g. equivalent to \code{scale(exp(X))}).
+\cr\cr
+See the \emph{Transformed Variables} section in \code{\link[=standardize.default]{standardize.default()}} for more
+details on how different transformations are dealt with when \code{method = ""refit""}.
 }
 
 \section{Confidence Intervals}{
@@ -156,10 +147,21 @@ the standardized coefficients (cf. Jones & Waller, 2015).
 }
 
 \section{Generalized Linear Models}{
-When standardizing coefficients of a generalized model (GLM, GLMM, etc), only
-the predictors are standardized, maintaining the interpretability of the
-coefficients (e.g., in a binomial model: the exponent of the standardized
-parameter is the OR of a change of 1 SD in the predictor, etc.)
+Standardization for generalized linear models (GLM, GLMM, etc) is done only
+with respect to the predictors (while the outcome remains as-is,
+unstandardized) - maintaining the interpretability of the coefficients (e.g.,
+in a binomial model: the exponent of the standardized parameter is the OR of
+a change of 1 SD in the predictor, etc.)
+}
+
+\section{Dealing with Factors}{
+\code{standardize(model)} or \code{standardize_parameters(model, method = ""refit"")} do
+\emph{not} standardized categorical predictors (i.e. factors) / their
+dummy-variables, which may be a different behaviour compared to other R
+packages (such as \pkg{lm.beta}) or other software packages (like SPSS). To
+mimic such behaviours, either use \code{standardize_parameters(model, method = ""basic"")} to obtain post-hoc standardized parameters, or standardize the data
+with \code{datawizard::standardize(data, force = TRUE)} \emph{before} fitting the
+model.
 }
 
 \examples{
@@ -211,9 +213,8 @@ if (require(""rstanarm"")) {
 }
 }
 \seealso{
-\code{\link[=standardize_info]{standardize_info()}}
-
 Other standardize: 
+\code{\link{standardize.default}()},
 \code{\link{standardize_info}()}
 
 Other effect size indices: ",True,False,Documentation / Formatting,7
easystats,effectsize,7a7356ceb44e2f530976589545f50083209ac746,mattansb,35330040+mattansb@users.noreply.github.com,2021-09-28T07:33:16Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-09-28T07:33:16Z,fix: phi and V are equal for any 2xk,R/xtab.R;man/phi.Rd,False,True,True,False,2,2,4,"---FILE: R/xtab.R---
@@ -18,7 +18,7 @@
 #'
 #' @details
 #' Cramer's *V*, phi (\eqn{\phi}) and Pearson's *C* are effect sizes for tests
-#' of independence in 2D contingency tables. For 2-by-2 tables, Cramer's *V* and
+#' of independence in 2D contingency tables. For 2-by-k tables, Cramer's *V* and
 #' phi are identical, and are equal to the simple correlation between two
 #' dichotomous variables, ranging between  0 (no dependence) and 1 (perfect
 #' dependence). For larger tables, Cramer's *V* or Pearson's *C* should be used,

---FILE: man/phi.Rd---
@@ -70,7 +70,7 @@ Cohen's \emph{g} for contingency tables or goodness-of-fit. See details.
 }
 \details{
 Cramer's \emph{V}, phi (\eqn{\phi}) and Pearson's \emph{C} are effect sizes for tests
-of independence in 2D contingency tables. For 2-by-2 tables, Cramer's \emph{V} and
+of independence in 2D contingency tables. For 2-by-k tables, Cramer's \emph{V} and
 phi are identical, and are equal to the simple correlation between two
 dichotomous variables, ranging between  0 (no dependence) and 1 (perfect
 dependence). For larger tables, Cramer's \emph{V} or Pearson's \emph{C} should be used,",True,False,Documentation / Formatting,6
easystats,effectsize,6b6fa397f8004da36d492541577d50c7cd69bf97,mattansb,35330040+mattansb@users.noreply.github.com,2021-09-28T07:22:45Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-09-28T07:22:45Z,fix: xtab tests,tests/testthat/test-effectsize.R;tests/testthat/test-xtab.R,False,True,True,False,23,27,50,"---FILE: tests/testthat/test-effectsize.R---
@@ -54,13 +54,6 @@ if (require(""testthat"") && require(""effectsize"")) {
       effectsize(Xsq2)$Cramers_v
     )
 
-    Xsq3 <- chisq.test(table(mtcars$cyl))
-    expect_equal(effectsize(Xsq3)$Cramers_v, 0.19, tolerance = 0.01)
-    expect_equal(
-      effectsize(Xsq3)$Cramers_v,
-      cramers_v(table(mtcars$cyl))$Cramers_v
-    )
-
     # types
     expect_equal(
       effectsize(Xsq1, type = ""phi""),
@@ -88,10 +81,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     expected.dfc <<- c(0.165, 0.835)
 
     x <- chisq.test(x = observed.dfc, p = expected.dfc)
-    ref <- cramers_v(x = observed.dfc, p = expected.dfc)
-
-    expect_equal(effectsize(x, type = ""v""), ref)
-    expect_equal(cramers_v(x), ref)
+    expect_error(effectsize(x, type = ""v""))
   })
 
   test_that(""cor.test / other"", {

---FILE: tests/testthat/test-xtab.R---
@@ -39,13 +39,17 @@ if (require(""testthat"") && require(""effectsize"")) {
       phi(xtab)[[1]]
     )
 
+    res <- pearsons_c(xtab)
+    expect_equal(res$pearsons_c, 0.032, tolerance = 0.01)
+
 
     ## 2*2 perfect correlation
     xtab <- rbind(
       c(100, 0),
       c(0, 200)
     )
-    expect_equal(cramers_v(xtab)$Cramers_v, 1)
+    expect_equal(V <- cramers_v(xtab)$Cramers_v, 1)
+    expect_true(pearsons_c(xtab)$pearsons_c < V) # C is not perfect
 
 
     ## 2*2 0 correlation
@@ -62,35 +66,37 @@ if (require(""testthat"") && require(""effectsize"")) {
       c(100, 100, 0)
     )
     expect_error(cramers_v(xtab))
+
+    ## 0
+    xtab <- table(mtcars$am, mtcars$vs)
+    phi3 <- phi(xtab, adjust = TRUE)
+    expect_equal(phi3$phi_adjusted, 0)
+    expect_equal(phi3$CI_low, 0)
+    expect_equal(phi3$CI_high, 1)
   })
 
 
   test_that(""goodness of fit"", {
-    cv1 <- cramers_v(table(mtcars$cyl), p = c(0.34375, 0.21875, 0.43750))
-    cv2 <- cramers_v(table(mtcars$cyl), p = c(0.8, 0.1, 0.1))
-
-    expect_equal(cv1$Cramers_v, 0)
-    expect_true(cv1$Cramers_v < cv2$Cramers_v)
-    expect_true(cv2$CI_low < cv2$CI_high)
+    expect_error(cramers_v(table(mtcars$cyl)))
 
     phi1 <- phi(table(mtcars$cyl), p = c(0.34375, 0.21875, 0.43750))
     phi2 <- phi(table(mtcars$cyl), p = c(0.8, 0.1, 0.1))
 
     expect_equal(phi1$phi, 0)
     expect_true(phi1$phi < phi2$phi)
+    expect_true(phi1$CI_low < phi2$CI_low)
     expect_true(phi2$CI_low < phi2$CI_high)
+    expect_equal(phi2$CI_high, Inf)
+
+    C <- pearsons_c(table(mtcars$cyl), p = c(0.8, 0.1, 0.1))
+    expect_equal(C$pearsons_c, sqrt(49.289 / (49.289 + sum(table(mtcars$cyl)))), tolerance = 0.001)
+    expect_equal(C$CI_high, 1)
 
     # some weird exeptions...
     df <- subset(mtcars, am == ""0"")
-    expect_equal(cramers_v(table(df$am, df$cyl))[[1]], 0.45, tolerance = 0.01)
-    expect_equal(cramers_v(table(df$am, df$cyl)), cramers_v(table(df$cyl)))
-    expect_equal(cramers_v(table(df$am, df$cyl)), cramers_v(table(df$cyl, df$am)))
-
-    xtab <- table(mtcars$am, mtcars$vs)
-    V <- cramers_v(xtab, adjust = TRUE)
-    expect_equal(V$Cramers_v_adjusted, 0)
-    expect_equal(V$CI_low, 0)
-    expect_equal(V$CI_high, 1)
+    expect_equal(phi(table(df$am, df$cyl))[[1]], 0.64, tolerance = 0.01)
+    expect_equal(phi(table(df$am, df$cyl)), phi(table(df$cyl)))
+    expect_equal(phi(table(df$am, df$cyl)), phi(table(df$cyl, df$am)))
   })
 
   test_that(""oddsratio & riskratio"", {",True,False,Implementation / Logic,6
easystats,effectsize,7d50d801313504cdfba336aea18b0c878958a8ed,mattansb,35330040+mattansb@users.noreply.github.com,2021-09-23T07:06:47Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-09-23T07:06:47Z,fix: upper bound of V is 1,R/convert_stat_chisq.R,False,True,True,False,7,0,7,"---FILE: R/convert_stat_chisq.R---
@@ -148,6 +148,13 @@ chisq_to_cramers_v <- function(chisq, n, nrow, ncol, ci = 0.95, alternative = ""g
   res <- chisq_to_phi(chisq, n, nrow, ncol, ci = ci, alternative = alternative, adjust = adjust)
   res[grepl(""^(phi|CI_)"", colnames(res))] <- res[grepl(""^(phi|CI_)"", colnames(res))] / phi_2_V
   colnames(res)[1] <- gsub(""phi"", ""Cramers_v"", colnames(res)[1])
+
+  if (""CI"" %in% colnames(res))
+    if ((alternative <- attr(res, ""alternative"")) == ""less"") {
+      res$CI_low <- 0
+    } else if (alternative == ""greater"") {
+      res$CI_high <- 1
+    }
   return(res)
 }
 ",True,False,Implementation / Logic,3
easystats,effectsize,367362de12c2d3aeff52609f8c2373dfcce20d05,mattansb,35330040+mattansb@users.noreply.github.com,2021-09-17T07:36:49Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-09-17T07:36:49Z,fix: interpret_cohens_g test,tests/testthat/test-interpret.R,False,True,True,False,2,2,4,"---FILE: tests/testthat/test-interpret.R---
@@ -57,8 +57,8 @@ if (require(""testthat"") && require(""effectsize"")) {
   })
 
   test_that(""interpret_cohens_g"", {
-    expect_equal(interpret_cohens_g(0.021)[1], ""small"")
-    expect_equal(interpret_cohens_g(c(0.10, 0.35), ""cohen1988"")[1:2], c(""medium"", ""large""))
+    expect_equal(interpret_cohens_g(0.021)[1], ""very small"")
+    expect_equal(interpret_cohens_g(c(0.10, 0.35), ""cohen1988"")[1:2], c(""small"", ""large""))
     expect_equal(interpret_cohens_g(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
     expect_error(interpret_cohens_g(0.6, ""DUPA""))
   })",True,False,Dependency / Package,3
easystats,effectsize,20e551952c8cd1511316f5d927bf341a6ea08e33,mattansb,35330040+mattansb@users.noreply.github.com,2021-09-17T07:15:51Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-09-17T07:15:51Z,fix cohens g threshold,R/interpret_cohens_g.R;man/interpret_cohens_g.Rd;vignettes/interpret.Rmd,True,True,True,False,31,11,42,"---FILE: R/interpret_cohens_g.R---
@@ -11,10 +11,10 @@
 #' absolute values).
 #'
 #' - Cohen (1988) (`""cohen1988""`; default)
-#'   - **d < 0.2** - Very small
-#'   - **0.2 <= d < 0.5** - Small
-#'   - **0.5 <= d < 0.8** - Medium
-#'   - **d >= 0.8** - Large
+#'   - **d < 0.05** - Very small
+#'   - **0.05 <= d < 0.15** - Small
+#'   - **0.15 <= d < 0.25** - Medium
+#'   - **d >= 0.25** - Large
 #'
 #' @note ""*Since **g** is so transparently clear a unit, it is expected that
 #'   workers in any given substantive area of the behavioral sciences will very
@@ -35,7 +35,7 @@ interpret_cohens_g <- function(g, rules = ""cohen1988"", ...) {
   rules <- .match.rules(
     rules,
     list(
-      cohen1988 = rules(c(0.05, 0.15, 0.25), c(""small"", ""medium"", ""large""),
+      cohen1988 = rules(c(0.05, 0.15, 0.25), c(""very small"", ""small"", ""medium"", ""large""),
         name = ""cohen1988"", right = FALSE)
     )
   )

---FILE: man/interpret_cohens_g.Rd---
@@ -31,10 +31,10 @@ absolute values).
 \itemize{
 \item Cohen (1988) (\code{""cohen1988""}; default)
 \itemize{
-\item \strong{d < 0.2} - Very small
-\item \strong{0.2 <= d < 0.5} - Small
-\item \strong{0.5 <= d < 0.8} - Medium
-\item \strong{d >= 0.8} - Large
+\item \strong{d < 0.05} - Very small
+\item \strong{0.05 <= d < 0.15} - Small
+\item \strong{0.15 <= d < 0.25} - Medium
+\item \strong{d >= 0.25} - Large
 }
 }
 }

---FILE: vignettes/interpret.Rmd---
@@ -375,8 +375,8 @@ interpret_omega_squared(x, rules = ""cohen1992"")
 
 ##  Kendall's coefficient of concordance
 
-The  Interpret Kendall's coefficient of concordance (*w*) is a measure of effect
-size used in non-parametric ANOVAs (the Friedman rank sum test). It is an
+The interpretation of Kendall's coefficient of concordance (*w*) is a measure of
+effect size used in non-parametric ANOVAs (the Friedman rank sum test). It is an
 estimate of agreement among multiple raters.
 
 #### @landis1977measurement
@@ -391,6 +391,26 @@ interpret_omega_squared(w, rules = ""landis1977"")
 - **0.60 <= w < 0.80** - Substantial agreement
 - **w >= 0.80**        - Almost perfect agreement
 
+## Cohen's *g*
+
+Cohen's *g* is a measure of effect size used for McNemar's test of agreement in
+selection - when repeating a multiple chose selection, is the percent of matches
+(first response is equal to the second response) different than 50%?
+
+#### @cohen1988statistical
+
+```r
+interpret_cohens_g(x, rules = ""cohen1988"")
+```
+
+- **d < 0.05** - Very small
+
+- **0.05 <= d < 0.15** - Small
+
+- **0.15 <= d < 0.25** - Medium
+
+- **d >= 0.25** - Large
+
 # Interpretation of other Indices
 
 `effectsize` also offers functions for interpreting other statistical indices:",True,True,Documentation / Formatting,6
easystats,effectsize,d33b9a3380fac1312f2141edf0b21bcda5c5a561,mattansb,35330040+mattansb@users.noreply.github.com,2021-09-17T06:51:37Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-09-17T06:51:37Z,fix incorrect link to function interpret_hedges_g,R/zzz_deprecated.R;man/effectsize_deprecated.Rd,False,True,True,False,2,2,4,"---FILE: R/zzz_deprecated.R---
@@ -4,7 +4,7 @@
 #'
 #' @details
 #' - `interpret_d` is now [`interpret_cohens_d`].
-#' - `interpret_g` is now [`interpret_hedges_d`].
+#' - `interpret_g` is now [`interpret_hedges_g`].
 #' - `interpret_delta` is now [`interpret_glass_delta`].
 #'
 #' @rdname effectsize_deprecated

---FILE: man/effectsize_deprecated.Rd---
@@ -22,7 +22,7 @@ Deprecated functions
 \details{
 \itemize{
 \item \code{interpret_d} is now \code{\link{interpret_cohens_d}}.
-\item \code{interpret_g} is now \code{\link{interpret_hedges_d}}.
+\item \code{interpret_g} is now \code{\link{interpret_hedges_g}}.
 \item \code{interpret_delta} is now \code{\link{interpret_glass_delta}}.
 }
 }",True,False,Documentation / Formatting,7
easystats,effectsize,906dbd0c92badfd319258d0ed82904a6f7049f97,mattansb,35330040+mattansb@users.noreply.github.com,2021-09-17T06:37:39Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-09-17T06:37:39Z,"fix: when alternative = NULL, use default value",R/convert_stat_chisq.R;R/convert_stat_to_anova.R;R/eta_squared.R;R/rank_effectsizes.R;R/xtab.R,False,True,True,False,11,11,22,"---FILE: R/convert_stat_chisq.R---
@@ -64,7 +64,7 @@
 #'
 #' @export
 chisq_to_phi <- function(chisq, n, nrow, ncol, ci = 0.95, alternative = ""greater"", adjust = FALSE, ...) {
-  alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
+  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
   if (adjust || is.numeric(ci)) {
     is_goodness <- ncol == 1 || nrow == 1
 
@@ -131,7 +131,7 @@ chisq_to_cohens_w <- chisq_to_phi
 #' @rdname chisq_to_phi
 #' @export
 chisq_to_cramers_v <- function(chisq, n, nrow, ncol, ci = 0.95, alternative = ""greater"", adjust = FALSE, ...) {
-  alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
+  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
   is_goodness <- ncol == 1 || nrow == 1
 
 

---FILE: R/convert_stat_to_anova.R---
@@ -226,7 +226,7 @@ t_to_f2 <- function(t, df_error, ci = 0.95, alternative = ""greater"", squared = T
 
 #' @keywords internal
 .F_to_pve <- function(f, df, df_error, ci = 0.95, alternative = ""greater"", es = ""eta2"") {
-  alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
+  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
 
   res <- switch(tolower(es),
     eta2 = data.frame(Eta2_partial = (f * df) / (f * df + df_error)),

---FILE: R/eta_squared.R---
@@ -224,7 +224,7 @@ eta_squared <- function(model,
                         ci = 0.95, alternative = ""greater"",
                         verbose = TRUE,
                         ...) {
-  alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
+  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
   out <- .anova_es(
     model,
     type = ""eta"",
@@ -247,7 +247,7 @@ omega_squared <- function(model,
                           ci = 0.95, alternative = ""greater"",
                           verbose = TRUE,
                           ...) {
-  alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
+  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
   out <- .anova_es(model, type = ""omega"", partial = partial, ci = ci, alternative = alternative, verbose = verbose, ...)
   class(out) <- unique(c(""effectsize_anova"",""effectsize_table"", ""see_effectsize_table"", class(out)))
   if (""CI"" %in% colnames(out)) attr(out, ""ci_method"") <- list(method = ""ncp"", distribution = ""F"")
@@ -262,7 +262,7 @@ epsilon_squared <- function(model,
                             ci = 0.95, alternative = ""greater"",
                             verbose = TRUE,
                             ...) {
-  alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
+  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
   out <- .anova_es(model, type = ""epsilon"", partial = partial, ci = ci, alternative = alternative, verbose = verbose, ...)
   class(out) <- unique(c(""effectsize_anova"",""effectsize_table"", ""see_effectsize_table"", class(out)))
   if (""CI"" %in% colnames(out)) attr(out, ""ci_method"") <- list(method = ""ncp"", distribution = ""F"")
@@ -278,7 +278,7 @@ epsilon_squared <- function(model,
 cohens_f <- function(model, partial = TRUE, ci = 0.95, alternative = ""greater"", squared = FALSE,
                      verbose = TRUE,
                      model2 = NULL, ...) {
-  alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
+  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
   if (!is.null(model2)) {
     return(.cohens_f_delta(model, model2, ci = ci, alternative = alternative, squared = squared, verbose = verbose))
   }

---FILE: R/rank_effectsizes.R---
@@ -321,7 +321,7 @@ rank_epsilon_squared <- function(x,
                                  alternative = ""greater"",
                                  iterations = 200,
                                  ...) {
-  alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
+  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
 
   if (inherits(x, ""htest"")) {
     if (!grepl(""Kruskal-Wallis"", x$method)) {
@@ -370,7 +370,7 @@ kendalls_w <- function(x,
                        iterations = 200,
                        verbose = TRUE,
                        ...) {
-  alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
+  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
 
   if (inherits(x, ""htest"")) {
     if (!grepl(""Friedman"", x$method)) {

---FILE: R/xtab.R---
@@ -119,7 +119,7 @@
 #' @importFrom stats chisq.test
 #' @export
 phi <- function(x, y = NULL, ci = 0.95, alternative = ""greater"", adjust = FALSE, ...) {
-  alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
+  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
 
   if (inherits(x, ""BFBayesFactor"")) {
     if (!inherits(x@numerator[[1]], ""BFcontingencyTable"")) {
@@ -150,7 +150,7 @@ cohens_w <- phi
 #' @importFrom stats chisq.test
 #' @export
 cramers_v <- function(x, y = NULL, ci = 0.95, alternative = ""greater"", adjust = FALSE, ...) {
-  alternative <- match.arg(alternative, c(""two.sided"", ""less"", ""greater""))
+  alternative <- match.arg(alternative, c(""greater"", ""two.sided"", ""less""))
 
   if (inherits(x, ""BFBayesFactor"")) {
     if (!inherits(x@numerator[[1]], ""BFcontingencyTable"")) {",True,False,Implementation / Logic,6
easystats,effectsize,af7e8a78c0960f9319aef644918844a94febe257,mattansb,35330040+mattansb@users.noreply.github.com,2021-09-17T06:20:45Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-09-17T06:20:45Z,fix zzz files,R/zzz deprecated.R;R/zzz_deprecated.R;R/zzz_interpret_parameters.R;man/effectsize_deprecated.Rd,False,True,True,False,62,17,79,"---FILE: R/zzz deprecated.R---
@@ -1,17 +0,0 @@
-#' @export
-interpret_d <- function(...) {
-  .Deprecated(""interpret_cohens_d"")
-  interpret_cohens_d(...)
-}
-
-#' @export
-interpret_g <- function(...) {
-  .Deprecated(""interpret_hedges_g"")
-  interpret_hedges_g(...)
-}
-
-#' @export
-interpret_delta <- function(...) {
-  .Deprecated(""interpret_glass_delta"")
-  interpret_glass_delta(...)
-}
\ No newline at end of file

---FILE: R/zzz_deprecated.R---
@@ -0,0 +1,34 @@
+#' Deprecated functions
+#'
+#' @param ... Arguments to the deprecated function.
+#'
+#' @details
+#' - `interpret_d` is now [`interpret_cohens_d`].
+#' - `interpret_g` is now [`interpret_hedges_d`].
+#' - `interpret_delta` is now [`interpret_glass_delta`].
+#'
+#' @rdname effectsize_deprecated
+#' @name effectsize_deprecated
+NULL
+
+
+#' @rdname effectsize_deprecated
+#' @export
+interpret_d <- function(...) {
+  .Deprecated(""interpret_cohens_d"")
+  interpret_cohens_d(...)
+}
+
+#' @rdname effectsize_deprecated
+#' @export
+interpret_g <- function(...) {
+  .Deprecated(""interpret_hedges_g"")
+  interpret_hedges_g(...)
+}
+
+#' @rdname effectsize_deprecated
+#' @export
+interpret_delta <- function(...) {
+  .Deprecated(""interpret_glass_delta"")
+  interpret_glass_delta(...)
+}
\ No newline at end of file

---FILE: man/effectsize_deprecated.Rd---
@@ -0,0 +1,28 @@
+% Generated by roxygen2: do not edit by hand
+% Please edit documentation in R/zzz_deprecated.R
+\name{effectsize_deprecated}
+\alias{effectsize_deprecated}
+\alias{interpret_d}
+\alias{interpret_g}
+\alias{interpret_delta}
+\title{Deprecated functions}
+\usage{
+interpret_d(...)
+
+interpret_g(...)
+
+interpret_delta(...)
+}
+\arguments{
+\item{...}{Arguments to the deprecated function.}
+}
+\description{
+Deprecated functions
+}
+\details{
+\itemize{
+\item \code{interpret_d} is now \code{\link{interpret_cohens_d}}.
+\item \code{interpret_g} is now \code{\link{interpret_hedges_d}}.
+\item \code{interpret_delta} is now \code{\link{interpret_glass_delta}}.
+}
+}",True,False,Documentation / Formatting,6
easystats,effectsize,9d6d52fd23a2d0189cb8ad322dc2273a51514a6d,mattansb,35330040+mattansb@users.noreply.github.com,2021-09-17T06:04:11Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-09-17T06:04:11Z,fix interpret_cohens_g docs,R/interpret_cohens_g.R;man/interpret_cohens_g.Rd,False,True,True,False,8,8,16,"---FILE: R/interpret_cohens_g.R---
@@ -16,11 +16,11 @@
 #'   - **0.5 <= d < 0.8** - Medium
 #'   - **d >= 0.8** - Large
 #'
-#' @note *Since **g** is so transparently clear a unit, it is expected that
+#' @note ""*Since **g** is so transparently clear a unit, it is expected that
 #'   workers in any given substantive area of the behavioral sciences will very
-#'   frequently be able to set relevant ES values without the proposed
-#'   conventions, or set up conventions of their own which are suited to their
-#'   area of inquiry.* - Cohen, 1988, page 147.
+#'   frequently be able to set relevant \[effect size\] values without the
+#'   proposed conventions, or set up conventions of their own which are suited
+#'   to their area of inquiry.*"" - Cohen, 1988, page 147.
 #'
 #' @examples
 #' interpret_cohens_g(.02)

---FILE: man/interpret_cohens_g.Rd---
@@ -17,11 +17,11 @@ interpret_cohens_g(g, rules = ""cohen1988"", ...)
 Interpret Cohen's g
 }
 \note{
-\emph{Since \strong{g} is so transparently clear a unit, it is expected that
+""\emph{Since \strong{g} is so transparently clear a unit, it is expected that
 workers in any given substantive area of the behavioral sciences will very
-frequently be able to set relevant ES values without the proposed
-conventions, or set up conventions of their own which are suited to their
-area of inquiry.} - Cohen, 1988, page 147.
+frequently be able to set relevant [effect size] values without the
+proposed conventions, or set up conventions of their own which are suited
+to their area of inquiry.}"" - Cohen, 1988, page 147.
 }
 \section{Rules}{
 ",True,False,Documentation / Formatting,7
easystats,effectsize,f8508afdc054f001d17a6d2c10769bc850504a31,mattansb,35330040+mattansb@users.noreply.github.com,2021-09-10T12:11:30Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-09-10T12:11:30Z,fix test,tests/testthat/test-standardize_parameters.R,False,True,True,False,2,2,4,"---FILE: tests/testthat/test-standardize_parameters.R---
@@ -474,9 +474,9 @@ test_that(""include_response | bayes"", {
   iris$Sepal.Length <- iris$Sepal.Length * 5
   m <- rstanarm::stan_glm(Sepal.Length ~ Petal.Length + Petal.Width, data = iris, refresh = 0)
 
-  m_z <- standardize(m, include_response = FALSE)
+  expect_warning(m_z <- standardize(m, include_response = FALSE))
+  expect_warning(par_z1 <- standardize_posteriors(m, include_response = FALSE))
   par_z0 <- standardize_posteriors(m, method = ""basic"")
-  par_z1 <- standardize_posteriors(m, include_response = FALSE)
   par_z2 <- standardize_posteriors(m, method = ""basic"", include_response = FALSE)
 
   expect_equal(sapply(insight::get_parameters(m_z), mean), sapply(par_z1, mean), tolerance = 0.1)",True,False,Implementation / Logic,6
easystats,effectsize,3d67b12bc671d903a146ea6e8cb3d076b84031cb,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-31T14:29:01Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-31T14:29:01Z,fix: for real this time,R/convert_between_odds_to_probs.R;README.Rmd;man/odds_to_probs.Rd,True,True,True,False,5,1,6,"---FILE: R/convert_between_odds_to_probs.R---
@@ -21,6 +21,7 @@
 #' probs_to_odds(0.95)
 #' probs_to_odds(0.95, log = TRUE)
 #' @export
+#' @aliases convert_odds_to_probs
 odds_to_probs <- function(odds, log = FALSE, ...) {
   UseMethod(""odds_to_probs"")
 }

---FILE: README.Rmd---
@@ -146,7 +146,9 @@ standardize(m)
 The package also provides ways of converting between different effect sizes.
 
 ```{r, warning=FALSE, message=FALSE}
-convert_d_to_r(d = 1)
+d_to_r(d = 0.2)
+
+oddsratio_to_riskratio(2.6, p0 = 0.4)
 ```
 
 And for recovering effect sizes from test statistics.

---FILE: man/odds_to_probs.Rd---
@@ -2,6 +2,7 @@
 % Please edit documentation in R/convert_between_odds_to_probs.R
 \name{odds_to_probs}
 \alias{odds_to_probs}
+\alias{convert_odds_to_probs}
 \alias{odds_to_probs.data.frame}
 \alias{probs_to_odds}
 \alias{convert_probs_to_odds}",True,True,Documentation / Formatting,6
easystats,effectsize,60657f2da9813f88bddeb61592d5561eb1655132,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-31T12:26:04Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-31T12:26:04Z,fix: some Rd cross-references,R/interpret_oddsratio.R;R/xtab.R;man/interpret_oddsratio.Rd;man/phi.Rd,False,True,True,False,4,4,8,"---FILE: R/interpret_oddsratio.R---
@@ -2,7 +2,7 @@
 #'
 #' @param OR Value or vector of (log) odds ratio values.
 #' @param rules Can be ""`chen2010""` (default), `""cohen1988""` (through
-#'   transformation to standardized difference, see [odds_to_d()]) or custom set
+#'   transformation to standardized difference, see [oddsratio_to_d()]) or custom set
 #'   of [rules()].
 #' @param log Are the provided values log odds ratio.
 #' @inheritParams interpret

---FILE: R/xtab.R---
@@ -46,7 +46,7 @@
 #' \cr\cr
 #' See *Confidence (Compatibility) Intervals (CIs)*, *CIs and Significance
 #' Tests*, and *One-Sided CIs* sections for *phi*, Cohen's *w* and Cramer's *V*.
-#' (*Note* that *phi* (and Cohen's *w*) is not bound to [0-1], but instead the
+#' (*Note* that *phi* (and Cohen's *w*) is not bound to (0-1), but instead the
 #' upper bound for is `sqrt(min(nrow, ncol) - 1))`.)
 #'
 #' @inheritSection effectsize_CIs Confidence (Compatibility) Intervals (CIs)

---FILE: man/interpret_oddsratio.Rd---
@@ -10,7 +10,7 @@ interpret_oddsratio(OR, rules = ""chen2010"", log = FALSE, ...)
 \item{OR}{Value or vector of (log) odds ratio values.}
 
 \item{rules}{Can be ""\verb{chen2010""} (default), \code{""cohen1988""} (through
-transformation to standardized difference, see \code{\link[=odds_to_d]{odds_to_d()}}) or custom set
+transformation to standardized difference, see \code{\link[=oddsratio_to_d]{oddsratio_to_d()}}) or custom set
 of \code{\link[=rules]{rules()}}.}
 
 \item{log}{Are the provided values log odds ratio.}

---FILE: man/phi.Rd---
@@ -88,7 +88,7 @@ Szumilas, 2010).
 \cr\cr
 See \emph{Confidence (Compatibility) Intervals (CIs)}, \emph{CIs and Significance
 Tests}, and \emph{One-Sided CIs} sections for \emph{phi}, Cohen's \emph{w} and Cramer's \emph{V}.
-(\emph{Note} that \emph{phi} (and Cohen's \emph{w}) is not bound to \link{0-1}, but instead the
+(\emph{Note} that \emph{phi} (and Cohen's \emph{w}) is not bound to (0-1), but instead the
 upper bound for is \verb{sqrt(min(nrow, ncol) - 1))}.)
 }
 ",True,False,Documentation / Formatting,6
easystats,effectsize,e7176a85469069ee7c34c6cb1c3395034c493aa4,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-31T11:49:15Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-31T11:49:15Z,fix: remove deprecated functions from namespace,NAMESPACE;R/interpret_oddsratio.R;man/d_to_r.Rd;man/dot-factor_to_numeric.Rd;man/interpret_oddsratio.Rd;man/odds_to_probs.Rd,False,True,True,False,2,36,38,"---FILE: NAMESPACE---
@@ -71,23 +71,18 @@ export(cohens_g)
 export(cohens_h)
 export(cohens_w)
 export(convert_d_to_common_language)
-export(convert_d_to_odds)
 export(convert_d_to_oddsratio)
 export(convert_d_to_r)
 export(convert_logoddsratio_to_d)
 export(convert_logoddsratio_to_r)
-export(convert_odds_to_d)
 export(convert_odds_to_probs)
-export(convert_odds_to_r)
 export(convert_oddsratio_to_d)
 export(convert_oddsratio_to_r)
 export(convert_probs_to_odds)
 export(convert_r_to_d)
-export(convert_r_to_odds)
 export(convert_r_to_oddsratio)
 export(cramers_v)
 export(d_to_common_language)
-export(d_to_odds)
 export(d_to_oddsratio)
 export(d_to_r)
 export(effectsize)
@@ -122,7 +117,6 @@ export(interpret_ifi)
 export(interpret_kendalls_w)
 export(interpret_nfi)
 export(interpret_nnfi)
-export(interpret_odds)
 export(interpret_oddsratio)
 export(interpret_omega_squared)
 export(interpret_p)
@@ -141,15 +135,11 @@ export(interpret_srmr)
 export(is.rules)
 export(is_effectsize_name)
 export(kendalls_w)
-export(logodds_to_d)
-export(logodds_to_r)
 export(logoddsratio_to_d)
 export(logoddsratio_to_r)
 export(mad_pooled)
 export(normalize)
-export(odds_to_d)
 export(odds_to_probs)
-export(odds_to_r)
 export(oddsratio)
 export(oddsratio_to_d)
 export(oddsratio_to_r)
@@ -159,7 +149,6 @@ export(phi)
 export(phi_to_chisq)
 export(probs_to_odds)
 export(r_to_d)
-export(r_to_odds)
 export(r_to_oddsratio)
 export(rank_biserial)
 export(rank_epsilon_squared)

---FILE: R/interpret_oddsratio.R---
@@ -25,7 +25,6 @@
 #' @examples
 #' interpret_oddsratio(1)
 #' interpret_oddsratio(c(5, 2))
-#' @aliases interpret_odds
 #'
 #' @references
 #' - Cohen, J. (1988). Statistical power analysis for the behavioral sciences

---FILE: man/d_to_r.Rd---
@@ -2,16 +2,6 @@
 % Please edit documentation in R/convert_between_d_to_r.R
 \name{d_to_r}
 \alias{d_to_r}
-\alias{convert_r_to_odds}
-\alias{r_to_odds}
-\alias{logodds_to_r}
-\alias{convert_odds_to_r}
-\alias{odds_to_r}
-\alias{convert_d_to_odds}
-\alias{d_to_odds}
-\alias{logodds_to_d}
-\alias{convert_odds_to_d}
-\alias{odds_to_d}
 \alias{convert_d_to_r}
 \alias{r_to_d}
 \alias{convert_r_to_d}
@@ -84,6 +74,7 @@ oddsratio_to_r(8.120534)
 d_to_r(1)
 r_to_oddsratio(0.4472136, log = TRUE)
 oddsratio_to_d(1.813799, log = TRUE)
+
 }
 \references{
 \itemize{

---FILE: man/dot-factor_to_numeric.Rd---
@@ -1,12 +0,0 @@
-% Generated by roxygen2: do not edit by hand
-% Please edit documentation in R/utils_factor_to_numeric.R
-\name{.factor_to_numeric}
-\alias{.factor_to_numeric}
-\title{Safe transformation from factor/character to numeric}
-\usage{
-.factor_to_numeric(x)
-}
-\description{
-Safe transformation from factor/character to numeric
-}
-\keyword{internal}

---FILE: man/interpret_oddsratio.Rd---
@@ -2,7 +2,6 @@
 % Please edit documentation in R/interpret_oddsratio.R
 \name{interpret_oddsratio}
 \alias{interpret_oddsratio}
-\alias{interpret_odds}
 \title{Interpret Odds ratio}
 \usage{
 interpret_oddsratio(OR, rules = ""chen2010"", log = FALSE, ...)
@@ -46,6 +45,7 @@ Rules apply to OR as ratios, so OR of 10 is as extreme as a OR of 0.1 (1/10).
 \examples{
 interpret_oddsratio(1)
 interpret_oddsratio(c(5, 2))
+
 }
 \references{
 \itemize{

---FILE: man/odds_to_probs.Rd---
@@ -2,7 +2,6 @@
 % Please edit documentation in R/convert_between_odds_to_probs.R
 \name{odds_to_probs}
 \alias{odds_to_probs}
-\alias{convert_odds_to_probs}
 \alias{odds_to_probs.data.frame}
 \alias{probs_to_odds}
 \alias{convert_probs_to_odds}",True,False,Dependency / Package,7
easystats,effectsize,bf86c5e0f0d02a246f5e94cd1e84e848a6461791,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-31T11:31:28Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-31T11:31:28Z,Fix: correct upper limit for phi,R/convert_stat_chisq.R;R/is_effectsize_name.R;R/xtab.R;man/phi.Rd;tests/testthat/test-xtab.R,False,True,True,False,22,10,32,"---FILE: R/convert_stat_chisq.R---
@@ -70,8 +70,10 @@ chisq_to_phi <- function(chisq, n, nrow, ncol, ci = 0.95, alternative = ""greater
 
     if (is_goodness) {
       df <- pmax(nrow - 1, ncol - 1)
+      max_upper <- sqrt((pmax(nrow, ncol) - 1))
     } else {
       df <- (nrow - 1) * (ncol - 1)
+      max_upper <- sqrt((pmin(nrow, ncol) - 1))
     }
   }
 
@@ -106,7 +108,7 @@ chisq_to_phi <- function(chisq, n, nrow, ncol, ci = 0.95, alternative = ""greater
     if (alternative == ""less"") {
       res$CI_low <- 0
     } else if (alternative == ""greater"") {
-      res$CI_high <- 1
+      res$CI_high <- max_upper
     }
   } else {
     alternative <- NULL

---FILE: R/is_effectsize_name.R---
@@ -50,8 +50,8 @@ es_info <- matrix(c(
   ## xtab
   ""Cramers_v"", ""Cramer's V"", ""onetail"", 0, 1, 0,
   ""Cramers_v_adjusted"", ""Cramer's V (adj.)"", ""onetail"", 0, 1, 0,
-  ""phi"", ""Phi"", ""onetail"", 0, 1, 0,
-  ""phi_adjusted"", ""Phi (adj.)"", ""onetail"", 0, 1, 0,
+  ""phi"", ""Phi"", ""onetail"", 0, NA, 0,
+  ""phi_adjusted"", ""Phi (adj.)"", ""onetail"", 0, NA, 0,
   ""Cohens_g"", ""Cohen's g"", ""onetail"", -0.5, 0.5, 0,
   ""Cohens_h"", ""Cohen's h"", ""twotail"", -pi, pi, 0,
   ""Odds_ratio"", ""Odds ratio"", ""twotail"", 0, Inf, 1,

---FILE: R/xtab.R---
@@ -44,8 +44,10 @@
 #' estimated using the standard normal parametric method (see Katz et al., 1978;
 #' Szumilas, 2010).
 #' \cr\cr
-#' See *Confidence (Compatibility) Intervals (CIs)*, *CIs and Significance Tests*,
-#' and *One-Sided CIs* sections for *phi*, Cohen's *w* and Cramer's *V*.
+#' See *Confidence (Compatibility) Intervals (CIs)*, *CIs and Significance
+#' Tests*, and *One-Sided CIs* sections for *phi*, Cohen's *w* and Cramer's *V*.
+#' (*Note* that *phi* (and Cohen's *w*) is not bound to [0-1], but instead the
+#' upper bound for is `sqrt(min(nrow, ncol) - 1))`.)
 #'
 #' @inheritSection effectsize_CIs Confidence (Compatibility) Intervals (CIs)
 #' @inheritSection effectsize_CIs CIs and Significance Tests
@@ -69,6 +71,8 @@
 #'            Study = c(""Psych"", ""Econ"", ""Law"")))
 #' M
 #'
+#' # Note that Phi is not bound to [0-1], but instead
+#' # the upper bound for phi is sqrt(min(nrow, ncol) - 1)
 #' phi(M)
 #'
 #' cramers_v(M)

---FILE: man/phi.Rd---
@@ -86,8 +86,10 @@ For Odds ratios, Risk ratios and Cohen's \emph{h}, confidence intervals are
 estimated using the standard normal parametric method (see Katz et al., 1978;
 Szumilas, 2010).
 \cr\cr
-See \emph{Confidence (Compatibility) Intervals (CIs)}, \emph{CIs and Significance Tests},
-and \emph{One-Sided CIs} sections for \emph{phi}, Cohen's \emph{w} and Cramer's \emph{V}.
+See \emph{Confidence (Compatibility) Intervals (CIs)}, \emph{CIs and Significance
+Tests}, and \emph{One-Sided CIs} sections for \emph{phi}, Cohen's \emph{w} and Cramer's \emph{V}.
+(\emph{Note} that \emph{phi} (and Cohen's \emph{w}) is not bound to \link{0-1}, but instead the
+upper bound for is \verb{sqrt(min(nrow, ncol) - 1))}.)
 }
 
 \section{Confidence (Compatibility) Intervals (CIs)}{
@@ -146,6 +148,8 @@ M <-
            Study = c(""Psych"", ""Econ"", ""Law"")))
 M
 
+# Note that Phi is not bound to [0-1], but instead
+# the upper bound for phi is sqrt(min(nrow, ncol) - 1)
 phi(M)
 
 cramers_v(M)

---FILE: tests/testthat/test-xtab.R---
@@ -24,7 +24,9 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     expect_equal(cv1$Cramers_v, cv2$Cramers_v)
 
-
+    # Upper bound of phi is the ratio between phi / V and sqrt(min(K,L)-1)
+    expect_equal(phi(xtab, alternative = ""greater"")$CI_high, sqrt(2))
+    expect_equal(phi(xtab)[[1]] / cramers_v(xtab)[[1]], sqrt(2))
 
     ## 2*2 tables return phi and cramers_v
     xtab <- rbind(
@@ -33,8 +35,8 @@ if (require(""testthat"") && require(""effectsize"")) {
     )
 
     expect_equal(
-      cramers_v(xtab)$Cramers_v,
-      phi(xtab)$phi
+      cramers_v(xtab)[[1]],
+      phi(xtab)[[1]]
     )
 
 ",True,False,Documentation / Formatting,6
easystats,effectsize,9e64571647bd0a0eb7c6d52c1b88790e607bdb3a,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-23T07:25:06Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-23T07:25:06Z,fix readme workflow,.github/workflows/render-readme.yaml,False,False,False,False,2,2,4,"---FILE: .github/workflows/render-readme.yaml---
@@ -21,10 +21,10 @@ jobs:
           remotes::install_cran(""rmarkdown"")
         shell: Rscript {0}
       - name: Render README
-        run: Rscript -e 'rmarkdown::render(""examples/README.Rmd"")'
+        run: Rscript -e 'rmarkdown::render(""README.Rmd"")'
       - name: Commit results
         run: |
           git config --local user.email ""actions@github.com""
           git config --local user.name ""GitHub Actions""
-          git commit examples/README.md -m 'Re-build README.Rmd' || echo ""No changes to commit""
+          git commit README.md -m 'Re-build README.Rmd' || echo ""No changes to commit""
           git push origin || echo ""No changes to commit""
\ No newline at end of file",False,False,Documentation / Formatting,4
easystats,effectsize,4ac22722f0aa25def258c92c1b30eb2650abc8fc,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-22T08:31:36Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-22T08:31:36Z,error when cant update to a standardize model,R/standardize.models.R;tests/testthat/test-standardize_models.R,False,True,True,False,29,10,39,"---FILE: R/standardize.models.R---
@@ -148,16 +148,23 @@ standardize.default <- function(x,
 
   # update model with standardized data
 
-  if (inherits(x, ""brmsfit"")) {
-    text <- utils::capture.output(model_std <- stats::update(x, newdata = data_std))
-  } else if (inherits(x, ""biglm"")) {
-    text <- utils::capture.output(model_std <- stats::update(x, moredata = data_std))
-  } else if (inherits(x, ""mixor"")) {
-    data_std <- data_std[order(data_std[, random_group_factor, drop = FALSE]), ]
-    text <- utils::capture.output(model_std <- stats::update(x, data = data_std))
-  } else {
-    text <- utils::capture.output(model_std <- stats::update(x, data = data_std))
-  }
+  tryCatch({
+    if (inherits(x, ""brmsfit"")) {
+      text <- utils::capture.output(model_std <- stats::update(x, newdata = data_std))
+    } else if (inherits(x, ""biglm"")) {
+      text <- utils::capture.output(model_std <- stats::update(x, moredata = data_std))
+    } else {
+      if (inherits(x, ""mixor"")) {
+        data_std <- data_std[order(data_std[, random_group_factor, drop = FALSE]), ]
+      }
+      text <- utils::capture.output(model_std <- stats::update(x, data = data_std))
+    }
+  }, error = function(er) {
+    stop(""Unable to refit the model with standardized data.\n"",
+         ""Failed with the following error:\n\"""", er, ""\b\""\n\n"",
+         ""Try instead to standardize the data (standardize(data)) and refit the model manually."",
+         call. = FALSE)
+  })
 
   model_std
 }

---FILE: tests/testthat/test-standardize_models.R---
@@ -10,6 +10,18 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(coef(m0), coef(model))
   })
 
+  test_that(""standardize | errors"", {
+    my_lm_external_formula <- function(.dat, predicted, predictor){
+      my_formula <- as.formula(paste0(predicted, ""~"", predictor))
+      lm(formula = my_formula, data = .dat)
+    }
+
+    m <- my_lm_external_formula(mtcars, ""mpg"", ""am"")
+
+    expect_error(standardize(m), ""Try instead to standardize the data"", fixed = TRUE)
+
+  })
+
 
   # Transformations ---------------------------------------------------------
   test_that(""transformations"", {",True,False,Implementation / Logic,6
easystats,effectsize,49c58267b116d38907b4acc56f04f0ae596653b5,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-18T14:45:15Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-18T14:45:15Z,fix duplicated equivalence_test,R/equivalence_test.R;man/equivalence_test.effectsize_table.Rd,False,True,True,False,12,1,13,"---FILE: R/equivalence_test.R---
@@ -65,6 +65,11 @@ bayestestR::equivalence_test
 #' es <- eta_squared(model, ci = 0.9, alternative = ""two.sided"")
 #' equivalence_test(es, range = 0.30) # TOST
 #'
+#' RCT <- matrix(c(71, 101,
+#'                 50, 100), nrow = 2)
+#' OR <- oddsratio(RCT, alternative = ""greater"")
+#' equivalence_test(OR, range = 1)
+#'
 #' ds <- t_to_d(
 #'   t = c(0.45, -0.65, 7, -2.2, 2.25),
 #'   df_error = c(675, 525, 2000, 900, 1875),
@@ -116,7 +121,7 @@ equivalence_test.effectsize_table <- function(x,
   }
 
   # Test ---
-  signif <- x$CI_high < 0 | 0 < x$CI_low
+  signif <- x$CI_high < x_es_info$null | x_es_info$null < x$CI_low
   in_rope <- range[1] <= x$CI_low & x$CI_high <= range[2]
   out_rope <- x$CI_high < range[1] | range[2] < x$CI_low
 
@@ -140,6 +145,7 @@ equivalence_test.effectsize_table <- function(x,
   attr(x, ""rule"") <- rule
   return(x)
 }
+
 #' @importFrom bayestestR equivalence_test
 #' @export
 bayestestR::equivalence_test

---FILE: man/equivalence_test.effectsize_table.Rd---
@@ -107,6 +107,11 @@ model <- aov(mpg ~ hp + am * factor(cyl), data = mtcars)
 es <- eta_squared(model, ci = 0.9, alternative = ""two.sided"")
 equivalence_test(es, range = 0.30) # TOST
 
+RCT <- matrix(c(71, 101,
+                50, 100), nrow = 2)
+OR <- oddsratio(RCT, alternative = ""greater"")
+equivalence_test(OR, range = 1)
+
 ds <- t_to_d(
   t = c(0.45, -0.65, 7, -2.2, 2.25),
   df_error = c(675, 525, 2000, 900, 1875),",True,False,Documentation / Formatting,6
easystats,effectsize,aacc24608514be5d0c042d8b684c00baabfadb52,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-18T13:59:21Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-18T13:59:21Z,fix typo + update readme,R/docs_extra.R;README.md;man/effectsize_CIs.Rd,False,True,True,False,18,10,28,"---FILE: R/docs_extra.R---
@@ -55,7 +55,7 @@
 #' and using *p* values (whether p < alpha for that value) are only guaranteed
 #' to agree when both are constructed using the same number of sides/tails.
 #' \cr\cr
-#' Most effect sizes are not bounded by zero (e.g., *r*, *d*, *g*), as as such
+#' Most effect sizes are not bounded by zero (e.g., *r*, *d*, *g*), and as such
 #' are generally tested using 2-tailed tests and 2-sided CIs.
 #' \cr\cr
 #' Some effect sizes are strictly positive--they do have a minimum value, of 0.

---FILE: README.md---
@@ -114,23 +114,29 @@ model <- aov(mpg ~ factor(gear), data = mtcars)
 eta_squared(model)
 ## # Effect Size for ANOVA
 ## 
-## Parameter    | Eta2 |       90% CI
+## Parameter    | Eta2 |       95% CI
 ## ----------------------------------
-## factor(gear) | 0.43 | [0.18, 0.59]
+## factor(gear) | 0.43 | [0.18, 1.00]
+## 
+## - One-sided CIs: upper bound fixed at (1).
 
 omega_squared(model)
 ## # Effect Size for ANOVA
 ## 
-## Parameter    | Omega2 |       90% CI
+## Parameter    | Omega2 |       95% CI
 ## ------------------------------------
-## factor(gear) |   0.38 | [0.14, 0.55]
+## factor(gear) |   0.38 | [0.14, 1.00]
+## 
+## - One-sided CIs: upper bound fixed at (1).
 
 epsilon_squared(model)
 ## # Effect Size for ANOVA
 ## 
-## Parameter    | Epsilon2 |       90% CI
+## Parameter    | Epsilon2 |       95% CI
 ## --------------------------------------
-## factor(gear) |     0.39 | [0.14, 0.56]
+## factor(gear) |     0.39 | [0.14, 1.00]
+## 
+## - One-sided CIs: upper bound fixed at (1).
 ```
 
 And moreâ¦
@@ -192,9 +198,11 @@ F_to_r(15, df = 1, df_error = 60)
 ## 0.45 | [0.22, 0.61]
 
 F_to_eta2(15, df = 1, df_error = 60)
-## Eta2 (partial) |       90% CI
+## Eta2 (partial) |       95% CI
 ## -----------------------------
-## 0.20           | [0.07, 0.34]
+## 0.20           | [0.07, 1.00]
+## 
+## - One-sided CIs: upper bound fixed at (1).
 ```
 
 ## Effect Size Interpretation

---FILE: man/effectsize_CIs.Rd---
@@ -64,7 +64,7 @@ Significance tests conducted using CIs (whether a value is inside the interval)
 and using \emph{p} values (whether p < alpha for that value) are only guaranteed
 to agree when both are constructed using the same number of sides/tails.
 \cr\cr
-Most effect sizes are not bounded by zero (e.g., \emph{r}, \emph{d}, \emph{g}), as as such
+Most effect sizes are not bounded by zero (e.g., \emph{r}, \emph{d}, \emph{g}), and as such
 are generally tested using 2-tailed tests and 2-sided CIs.
 \cr\cr
 Some effect sizes are strictly positive--they do have a minimum value, of 0.",True,False,Documentation / Formatting,7
easystats,effectsize,0aafc4958151ae3b4f3a233d313084222519a870,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-18T09:51:21Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-18T09:51:21Z,ref fix in docs,R/cohens_d.R;man/cohens_d.Rd,False,True,True,False,2,2,4,"---FILE: R/cohens_d.R---
@@ -18,7 +18,7 @@
 #' @param alternative a character string specifying the alternative hypothesis;
 #'   Controls the type of CI returned: `""two.sided""` (default, two-sided CI),
 #'   `""greater""` or `""less""` (one-sided CI). Partial matching is allowed (e.g.,
-#'   `""g""`, `""l""`, `""two""`...). See *One-Sided CIs* in [effectsize-CIs].
+#'   `""g""`, `""l""`, `""two""`...). See *One-Sided CIs* in [effectsize_CIs].
 #' @param data An optional data frame containing the variables.
 #' @param pooled_sd If `TRUE` (default), a [sd_pooled()] is used (assuming equal
 #'   variance). Else the mean SD from both groups is used instead.

---FILE: man/cohens_d.Rd---
@@ -68,7 +68,7 @@ size on \code{x - y}.}
 \item{alternative}{a character string specifying the alternative hypothesis;
 Controls the type of CI returned: \code{""two.sided""} (default, two-sided CI),
 \code{""greater""} or \code{""less""} (one-sided CI). Partial matching is allowed (e.g.,
-\code{""g""}, \code{""l""}, \code{""two""}...). See \emph{One-Sided CIs} in \link{effectsize-CIs}.}
+\code{""g""}, \code{""l""}, \code{""two""}...). See \emph{One-Sided CIs} in \link{effectsize_CIs}.}
 
 \item{verbose}{Toggle warnings and messages on or off.}
 ",True,False,Documentation / Formatting,7
easystats,effectsize,9bcc22048681faeba2296a766aca022145616d80,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-18T09:40:14Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-18T09:40:14Z,fix bugs in build,R/convert_stat_to_r.R;R/rank_effectsizes.R;man/rank_biserial.Rd;man/t_to_r.Rd,False,True,True,False,8,6,14,"---FILE: R/convert_stat_to_r.R---
@@ -20,7 +20,7 @@
 #' @param alternative a character string specifying the alternative hypothesis;
 #'   Controls the type of CI returned: `""two.sided""` (default, two-sided CI),
 #'   `""greater""` or `""less""` (one-sided CI). Partial matching is allowed (e.g.,
-#'   `""g""`, `""l""`, `""two""`...). See *One-Sided CIs* in [effectsize-CIs].
+#'   `""g""`, `""l""`, `""two""`...). See *One-Sided CIs* in [effectsize_CIs].
 #' @param pooled Deprecated. Use `paired`.
 #' @inheritParams chisq_to_phi
 #' @param ... Arguments passed to or from other methods.

---FILE: R/rank_effectsizes.R---
@@ -28,7 +28,8 @@
 #'   Controls the type of CI returned: `""two.sided""` (two-sided CI; default for
 #'   rank-biserial correlation and Cliff's *delta*), `""greater""` (default for
 #'   rank epsilon squared and Kendall's *W*) or `""less""` (one-sided CI). Partial
-#'   matching is allowed (e.g., `""g""`, `""l""`, `""two""`...).
+#'   matching is allowed (e.g., `""g""`, `""l""`, `""two""`...). See *One-Sided CIs*
+#'   in [effectsize_CIs].
 #'
 #' @details
 #' The rank-biserial correlation is appropriate for non-parametric tests of
@@ -677,10 +678,10 @@ kendalls_w <- function(x,
 
 # Utils -------------------------------------------------------------------
 
-.safe_ranktransform <- function(x, ...) {
+.safe_ranktransform <- function(x, verbose = TRUE, ...) {
   if (length(unique(x)) == 1) {
     if (verbose) warning(""Only one unique value - rank fixed at 1"")
     return(rep(1, length(x)))
   }
-  datawizard::ranktransform(x, ...)
+  datawizard::ranktransform(x, verbose = verbose, ...)
 }

---FILE: man/rank_biserial.Rd---
@@ -80,7 +80,8 @@ estimated. See \link[stats:wilcox.test]{stats::wilcox.test}.}
 Controls the type of CI returned: \code{""two.sided""} (two-sided CI; default for
 rank-biserial correlation and Cliff's \emph{delta}), \code{""greater""} (default for
 rank epsilon squared and Kendall's \emph{W}) or \code{""less""} (one-sided CI). Partial
-matching is allowed (e.g., \code{""g""}, \code{""l""}, \code{""two""}...).}
+matching is allowed (e.g., \code{""g""}, \code{""l""}, \code{""two""}...). See \emph{One-Sided CIs}
+in \link{effectsize_CIs}.}
 
 \item{paired}{If \code{TRUE}, the values of \code{x} and \code{y} are considered as paired.
 This produces an effect size that is equivalent to the one-sample effect

---FILE: man/t_to_r.Rd---
@@ -49,7 +49,7 @@ difference between dependent means?}
 \item{alternative}{a character string specifying the alternative hypothesis;
 Controls the type of CI returned: \code{""two.sided""} (default, two-sided CI),
 \code{""greater""} or \code{""less""} (one-sided CI). Partial matching is allowed (e.g.,
-\code{""g""}, \code{""l""}, \code{""two""}...). See \emph{One-Sided CIs} in \link{effectsize-CIs}.}
+\code{""g""}, \code{""l""}, \code{""two""}...). See \emph{One-Sided CIs} in \link{effectsize_CIs}.}
 
 \item{pooled}{Deprecated. Use \code{paired}.}
 ",True,False,Documentation / Formatting,6
easystats,effectsize,f02eba6e9130f3cb96c01ec05bdb25a2eaea19c9,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-18T07:50:59Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-18T07:50:59Z,fix tests,NEWS.md;tests/testthat/test-convert_statistic.R;tests/testthat/test-rankES.R;tests/testthat/test-xtab.R,False,True,True,False,10,8,18,"---FILE: NEWS.md---
@@ -2,7 +2,7 @@
 
 ## Breaking Changes
 
-- Phi, Cohen's *w*, Cramer's *V*, ANOVA effect sizes, rank Epsilon squared, Kendall's *W* - CIs default to 95% one-sided CIs (`alternative = ""greater""`). To restore previous behavior, set `ci = .9, alternative = ""two.sided""`.
+- Phi, Cohen's *w*, Cramer's *V*, ANOVA effect sizes, rank Epsilon squared, Kendall's *W* - CIs default to 95% one-sided CIs (`alternative = ""greater""`). (To restore previous behavior, set `ci = .9, alternative = ""two.sided""`.)
 - `adjust()`, `change_scale()`, `normalize()`, `ranktransform()`, `standardize()` (data), and `unstandardize()` have moved to the new [`{datawizard}`](https://easystats.github.io/datawizard) package!
 
 ## New features

---FILE: tests/testthat/test-convert_statistic.R---
@@ -77,19 +77,19 @@ if (require(""testthat"") && require(""effectsize"")) {
     res <- F_to_eta2(4, 3, 123)
     expect_equal(res[[1]], 0.089, tolerance = 0.01)
     expect_equal(res$CI_low, 0.014, tolerance = 0.02)
-    expect_equal(res$CI_high, 0.163, tolerance = 0.01)
+    expect_equal(res$CI_high, 1)
     expect_equal(t_to_eta2(2, 123), F_to_eta2(4, 1, 123))
 
     res <- F_to_epsilon2(4, 3, 123)
     expect_equal(res[[1]], 0.067, tolerance = 0.01)
     expect_equal(res$CI_low, 0.002, tolerance = 0.01)
-    expect_equal(res$CI_high, 0.133, tolerance = 0.01)
+    expect_equal(res$CI_high, 1)
     expect_equal(t_to_epsilon2(2, 123), F_to_epsilon2(4, 1, 123))
 
     res <- F_to_omega2(4, 3, 123)
     expect_equal(res[[1]], 0.066, tolerance = 0.01)
     expect_equal(res$CI_low, 0.002, tolerance = 0.01)
-    expect_equal(res$CI_high, 0.132, tolerance = 0.01)
+    expect_equal(res$CI_high, 1)
     expect_equal(t_to_epsilon2(2, 123), F_to_epsilon2(4, 1, 123))
 
     res <- F_to_eta2(4, 3, 123)

---FILE: tests/testthat/test-rankES.R---
@@ -45,8 +45,8 @@ if (require(""testthat"") && require(""effectsize"")) {
     E <- rank_epsilon_squared(x, g)
 
     expect_equal(E[[1]], 0.05934066, tolerance = 0.01)
-    expect_equal(E$CI_low, 0.004149302, tolerance = 0.01)
-    expect_equal(E$CI_high, 0.7596009, tolerance = 0.01)
+    expect_equal(E$CI_low, 0.01726463, tolerance = 0.01)
+    expect_equal(E$CI_high, 1)
 
     expect_equal(
       rank_epsilon_squared(x ~ g, ci = NULL),

---FILE: tests/testthat/test-xtab.R---
@@ -9,7 +9,7 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     expect_equal(res$Cramers_v, 0.072, tolerance = 0.01)
     expect_equal(res$CI_low, 0.051, tolerance = 0.01)
-    expect_equal(res$CI_high, 0.088, tolerance = 0.01)
+    expect_equal(res$CI_high, 1)
 
 
     ## Size does not affect estimate
@@ -86,7 +86,9 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     xtab <- table(mtcars$am, mtcars$vs)
     V <- cramers_v(xtab, adjust = TRUE)
-    expect_equal(unname(unlist(V[c(1, 3, 4)])), rep(0, 3))
+    expect_equal(V$Cramers_v_adjusted, 0)
+    expect_equal(V$CI_low, 0)
+    expect_equal(V$CI_high, 1)
   })
 
   test_that(""oddsratio & riskratio"", {",True,False,Implementation / Logic,6
easystats,effectsize,06f7f8d616b0c2643c8939eb6ba83a4b17f339d4,Brenton M. Wiernik,bwiernik@users.noreply.github.com,2021-08-17T17:20:32Z,Brenton M. Wiernik,bwiernik@users.noreply.github.com,2021-08-17T17:20:32Z,Fix HTML syntax,R/docs_extra.R;man/F_to_eta2.Rd;man/chisq_to_phi.Rd;man/cohens_d.Rd;man/effectsize_CIs.Rd;man/eta_squared.Rd;man/phi.Rd;man/t_to_r.Rd,False,True,True,False,84,60,144,"---FILE: R/docs_extra.R---
@@ -7,9 +7,12 @@
 #' Unless stated otherwise, confidence (compatibility) intervals (CIs) are
 #' estimated using the noncentrality parameter method (also called the
 #' ""pivot method""). This method finds the noncentrality parameter (""*ncp*"") of
-#' a noncentral *t*, *F*, or chi-squared distribution that places the observed
-#' *t*, *F*, or chi-squared test statistic at the desired probability point of
-#' the distribution. For example, if the observed *t* statistic is 2.0, with 50
+#' a noncentral *t*, *F*, or
+#' \ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
+#' distribution that places the observed *t*, *F*, or
+#' \ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
+#' test statistic at the desired probability point of the distribution.
+#' For example, if the observed *t* statistic is 2.0, with 50
 #' degrees of freedom, for which cumulative noncentral *t* distribution is
 #' *t* = 2.0 the .025 quantile (answer: the noncentral *t* distribution with
 #' *ncp* = .04)? After estimating these confidence bounds on the *ncp*, they are
@@ -57,11 +60,11 @@
 #' \cr\cr
 #' Some effect sizes are strictly positive--they have a minimum value of 0.
 #' For example,
-#' \ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{*R*<sup>2</sup>}}{R^2}},
+#' \ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{<i>R</i><sup>2</sup>}}{R^2}},
 #' \ifelse{latex}{\out{$\eta^2$}}{\ifelse{html}{\out{&eta;<sup>2</sup>}}{eta^2}},
 #' and other variance-accounted-for effect sizes, as well as Cramer's *V* and
 #' multiple *R*, range from 0 to 1. These typically involve *F*- or
-#' \ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{\chi;<sup>2</sup>}}{chi-squared}}-statistics
+#' \ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}-statistics
 #' and are generally tested using *1-tailed* tests. These test test whether the
 #' estimated effect size is *larger* than the hypothesized value (e.g., 0). The
 #' corresponding CI that yields the same significance decision is a *1-sided* CI
@@ -77,7 +80,7 @@
 #' \cr\cr
 #' An alternative 1-sided CI that can be used to test against the maximum effect
 #' size value (e.g., is
-#' \ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{*R*<sup>2</sup>}}{R^2}}
+#' \ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{<i>R</i><sup>2</sup>}}{R^2}}
 #' significantly different from a perfect correlation of 1.0?) can by setting
 #' `alternative = ""less""`. This estimates a CI with only an *upper* bound;
 #' anything from the minimum possible value of the effect size (e.g., 0) up to
@@ -90,10 +93,10 @@
 #' \cr\cr
 #' An alternative approach to aligning significance tests using CIs and 1-tailed
 #' *p* values that can often be found in the literature is to
-#' construct a 2-sided CI at a lower confidence level (
+#' construct a 2-sided CI at a lower confidence level (e.g.,
 #' 100(\ifelse{latex}{\out{$1 - 2\alpha$}}{\ifelse{html}{\out{1 &minus; 2&alpha;}}{1 - 2*alpha}})%
-#' = \ifelse{latex}{\out{$100 - 2 \times 5\% = 90\%$}}{\ifelse{html}{\out{100 &minus; 2 %times; 5% = 90%}}{100 - 2*5% = 90%}}),
-#' estimates the lower bound and upper bound for the above 1-sided intervals
+#' = \ifelse{latex}{\out{$100 - 2 \times 5\% = 90\%$}}{\ifelse{html}{\out{100 &minus; 2 &times; 5&percnt; = 90&percnt;}}{100 - 2*5% = 90%}}).
+#' This estimates the lower bound and upper bound for the above 1-sided intervals
 #' simultaneously. These intervals are commonly reported when conducting equivalence
 #' tests. For example, a 90% 2-sided interval gives the bounds for an equivalence
 #' test with \ifelse{latex}{\out{$\alpha = .05$}}{\ifelse{html}{\out{&alpha; = .05}}{alpha = .05}}.

---FILE: man/F_to_eta2.Rd---
@@ -126,9 +126,12 @@ Adjusted (partial) Eta-squared is an alias for (partial) Epsilon-squared.
 Unless stated otherwise, confidence (compatibility) intervals (CIs) are
 estimated using the noncentrality parameter method (also called the
 ""pivot method""). This method finds the noncentrality parameter (""\emph{ncp}"") of
-a noncentral \emph{t}, \emph{F}, or chi-squared distribution that places the observed
-\emph{t}, \emph{F}, or chi-squared test statistic at the desired probability point of
-the distribution. For example, if the observed \emph{t} statistic is 2.0, with 50
+a noncentral \emph{t}, \emph{F}, or
+\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
+distribution that places the observed \emph{t}, \emph{F}, or
+\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
+test statistic at the desired probability point of the distribution.
+For example, if the observed \emph{t} statistic is 2.0, with 50
 degrees of freedom, for which cumulative noncentral \emph{t} distribution is
 \emph{t} = 2.0 the .025 quantile (answer: the noncentral \emph{t} distribution with
 \emph{ncp} = .04)? After estimating these confidence bounds on the \emph{ncp}, they are
@@ -180,11 +183,11 @@ typically involve \emph{t}- or \emph{z}-statistics and are generally tested usin
 \cr\cr
 Some effect sizes are strictly positive--they have a minimum value of 0.
 For example,
-\ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{*R*<sup>2</sup>}}{R^2}},
+\ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{<i>R</i><sup>2</sup>}}{R^2}},
 \ifelse{latex}{\out{$\eta^2$}}{\ifelse{html}{\out{&eta;<sup>2</sup>}}{eta^2}},
 and other variance-accounted-for effect sizes, as well as Cramer's \emph{V} and
 multiple \emph{R}, range from 0 to 1. These typically involve \emph{F}- or
-\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{\chi;<sup>2</sup>}}{chi-squared}}-statistics
+\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}-statistics
 and are generally tested using \emph{1-tailed} tests. These test test whether the
 estimated effect size is \emph{larger} than the hypothesized value (e.g., 0). The
 corresponding CI that yields the same significance decision is a \emph{1-sided} CI
@@ -200,7 +203,7 @@ up to the maximum possible value of the effect size (e.g., 1) is in the interval
 \cr\cr
 An alternative 1-sided CI that can be used to test against the maximum effect
 size value (e.g., is
-\ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{*R*<sup>2</sup>}}{R^2}}
+\ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{<i>R</i><sup>2</sup>}}{R^2}}
 significantly different from a perfect correlation of 1.0?) can by setting
 \code{alternative = ""less""}. This estimates a CI with only an \emph{upper} bound;
 anything from the minimum possible value of the effect size (e.g., 0) up to
@@ -213,10 +216,10 @@ for \emph{r}, \emph{d}, or \emph{g}.
 \cr\cr
 An alternative approach to aligning significance tests using CIs and 1-tailed
 \emph{p} values that can often be found in the literature is to
-construct a 2-sided CI at a lower confidence level (
+construct a 2-sided CI at a lower confidence level (e.g.,
 100(\ifelse{latex}{\out{$1 - 2\alpha$}}{\ifelse{html}{\out{1 &minus; 2&alpha;}}{1 - 2*alpha}})\%
-= \ifelse{latex}{\out{$100 - 2 \times 5\% = 90\%$}}{\ifelse{html}{\out{100 â 2 \%times; 5\% = 90\%}}{100 - 2*5\% = 90\%}}),
-estimates the lower bound and upper bound for the above 1-sided intervals
+= \ifelse{latex}{\out{$100 - 2 \times 5\% = 90\%$}}{\ifelse{html}{\out{100 &minus; 2 &times; 5&percnt; = 90&percnt;}}{100 - 2*5\% = 90\%}}).
+This estimates the lower bound and upper bound for the above 1-sided intervals
 simultaneously. These intervals are commonly reported when conducting equivalence
 tests. For example, a 90\% 2-sided interval gives the bounds for an equivalence
 test with \ifelse{latex}{\out{$\alpha = .05$}}{\ifelse{html}{\out{&alpha; = .05}}{alpha = .05}}.

---FILE: man/chisq_to_phi.Rd---
@@ -89,9 +89,12 @@ Cohen's \emph{w} is equivalent to \emph{Phi}.
 Unless stated otherwise, confidence (compatibility) intervals (CIs) are
 estimated using the noncentrality parameter method (also called the
 ""pivot method""). This method finds the noncentrality parameter (""\emph{ncp}"") of
-a noncentral \emph{t}, \emph{F}, or chi-squared distribution that places the observed
-\emph{t}, \emph{F}, or chi-squared test statistic at the desired probability point of
-the distribution. For example, if the observed \emph{t} statistic is 2.0, with 50
+a noncentral \emph{t}, \emph{F}, or
+\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
+distribution that places the observed \emph{t}, \emph{F}, or
+\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
+test statistic at the desired probability point of the distribution.
+For example, if the observed \emph{t} statistic is 2.0, with 50
 degrees of freedom, for which cumulative noncentral \emph{t} distribution is
 \emph{t} = 2.0 the .025 quantile (answer: the noncentral \emph{t} distribution with
 \emph{ncp} = .04)? After estimating these confidence bounds on the \emph{ncp}, they are
@@ -143,11 +146,11 @@ typically involve \emph{t}- or \emph{z}-statistics and are generally tested usin
 \cr\cr
 Some effect sizes are strictly positive--they have a minimum value of 0.
 For example,
-\ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{*R*<sup>2</sup>}}{R^2}},
+\ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{<i>R</i><sup>2</sup>}}{R^2}},
 \ifelse{latex}{\out{$\eta^2$}}{\ifelse{html}{\out{&eta;<sup>2</sup>}}{eta^2}},
 and other variance-accounted-for effect sizes, as well as Cramer's \emph{V} and
 multiple \emph{R}, range from 0 to 1. These typically involve \emph{F}- or
-\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{\chi;<sup>2</sup>}}{chi-squared}}-statistics
+\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}-statistics
 and are generally tested using \emph{1-tailed} tests. These test test whether the
 estimated effect size is \emph{larger} than the hypothesized value (e.g., 0). The
 corresponding CI that yields the same significance decision is a \emph{1-sided} CI
@@ -163,7 +166,7 @@ up to the maximum possible value of the effect size (e.g., 1) is in the interval
 \cr\cr
 An alternative 1-sided CI that can be used to test against the maximum effect
 size value (e.g., is
-\ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{*R*<sup>2</sup>}}{R^2}}
+\ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{<i>R</i><sup>2</sup>}}{R^2}}
 significantly different from a perfect correlation of 1.0?) can by setting
 \code{alternative = ""less""}. This estimates a CI with only an \emph{upper} bound;
 anything from the minimum possible value of the effect size (e.g., 0) up to
@@ -176,10 +179,10 @@ for \emph{r}, \emph{d}, or \emph{g}.
 \cr\cr
 An alternative approach to aligning significance tests using CIs and 1-tailed
 \emph{p} values that can often be found in the literature is to
-construct a 2-sided CI at a lower confidence level (
+construct a 2-sided CI at a lower confidence level (e.g.,
 100(\ifelse{latex}{\out{$1 - 2\alpha$}}{\ifelse{html}{\out{1 &minus; 2&alpha;}}{1 - 2*alpha}})\%
-= \ifelse{latex}{\out{$100 - 2 \times 5\% = 90\%$}}{\ifelse{html}{\out{100 â 2 \%times; 5\% = 90\%}}{100 - 2*5\% = 90\%}}),
-estimates the lower bound and upper bound for the above 1-sided intervals
+= \ifelse{latex}{\out{$100 - 2 \times 5\% = 90\%$}}{\ifelse{html}{\out{100 &minus; 2 &times; 5&percnt; = 90&percnt;}}{100 - 2*5\% = 90\%}}).
+This estimates the lower bound and upper bound for the above 1-sided intervals
 simultaneously. These intervals are commonly reported when conducting equivalence
 tests. For example, a 90\% 2-sided interval gives the bounds for an equivalence
 test with \ifelse{latex}{\out{$\alpha = .05$}}{\ifelse{html}{\out{&alpha; = .05}}{alpha = .05}}.

---FILE: man/cohens_d.Rd---
@@ -107,9 +107,12 @@ applying Bessel's correction).
 Unless stated otherwise, confidence (compatibility) intervals (CIs) are
 estimated using the noncentrality parameter method (also called the
 ""pivot method""). This method finds the noncentrality parameter (""\emph{ncp}"") of
-a noncentral \emph{t}, \emph{F}, or chi-squared distribution that places the observed
-\emph{t}, \emph{F}, or chi-squared test statistic at the desired probability point of
-the distribution. For example, if the observed \emph{t} statistic is 2.0, with 50
+a noncentral \emph{t}, \emph{F}, or
+\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
+distribution that places the observed \emph{t}, \emph{F}, or
+\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
+test statistic at the desired probability point of the distribution.
+For example, if the observed \emph{t} statistic is 2.0, with 50
 degrees of freedom, for which cumulative noncentral \emph{t} distribution is
 \emph{t} = 2.0 the .025 quantile (answer: the noncentral \emph{t} distribution with
 \emph{ncp} = .04)? After estimating these confidence bounds on the \emph{ncp}, they are

---FILE: man/effectsize_CIs.Rd---
@@ -12,9 +12,12 @@ they are computed in \emph{effectsize}.
 Unless stated otherwise, confidence (compatibility) intervals (CIs) are
 estimated using the noncentrality parameter method (also called the
 ""pivot method""). This method finds the noncentrality parameter (""\emph{ncp}"") of
-a noncentral \emph{t}, \emph{F}, or chi-squared distribution that places the observed
-\emph{t}, \emph{F}, or chi-squared test statistic at the desired probability point of
-the distribution. For example, if the observed \emph{t} statistic is 2.0, with 50
+a noncentral \emph{t}, \emph{F}, or
+\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
+distribution that places the observed \emph{t}, \emph{F}, or
+\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
+test statistic at the desired probability point of the distribution.
+For example, if the observed \emph{t} statistic is 2.0, with 50
 degrees of freedom, for which cumulative noncentral \emph{t} distribution is
 \emph{t} = 2.0 the .025 quantile (answer: the noncentral \emph{t} distribution with
 \emph{ncp} = .04)? After estimating these confidence bounds on the \emph{ncp}, they are
@@ -66,11 +69,11 @@ typically involve \emph{t}- or \emph{z}-statistics and are generally tested usin
 \cr\cr
 Some effect sizes are strictly positive--they have a minimum value of 0.
 For example,
-\ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{*R*<sup>2</sup>}}{R^2}},
+\ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{<i>R</i><sup>2</sup>}}{R^2}},
 \ifelse{latex}{\out{$\eta^2$}}{\ifelse{html}{\out{&eta;<sup>2</sup>}}{eta^2}},
 and other variance-accounted-for effect sizes, as well as Cramer's \emph{V} and
 multiple \emph{R}, range from 0 to 1. These typically involve \emph{F}- or
-\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{\chi;<sup>2</sup>}}{chi-squared}}-statistics
+\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}-statistics
 and are generally tested using \emph{1-tailed} tests. These test test whether the
 estimated effect size is \emph{larger} than the hypothesized value (e.g., 0). The
 corresponding CI that yields the same significance decision is a \emph{1-sided} CI
@@ -86,7 +89,7 @@ up to the maximum possible value of the effect size (e.g., 1) is in the interval
 \cr\cr
 An alternative 1-sided CI that can be used to test against the maximum effect
 size value (e.g., is
-\ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{*R*<sup>2</sup>}}{R^2}}
+\ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{<i>R</i><sup>2</sup>}}{R^2}}
 significantly different from a perfect correlation of 1.0?) can by setting
 \code{alternative = ""less""}. This estimates a CI with only an \emph{upper} bound;
 anything from the minimum possible value of the effect size (e.g., 0) up to
@@ -99,10 +102,10 @@ for \emph{r}, \emph{d}, or \emph{g}.
 \cr\cr
 An alternative approach to aligning significance tests using CIs and 1-tailed
 \emph{p} values that can often be found in the literature is to
-construct a 2-sided CI at a lower confidence level (
+construct a 2-sided CI at a lower confidence level (e.g.,
 100(\ifelse{latex}{\out{$1 - 2\alpha$}}{\ifelse{html}{\out{1 &minus; 2&alpha;}}{1 - 2*alpha}})\%
-= \ifelse{latex}{\out{$100 - 2 \times 5\% = 90\%$}}{\ifelse{html}{\out{100 â 2 \%times; 5\% = 90\%}}{100 - 2*5\% = 90\%}}),
-estimates the lower bound and upper bound for the above 1-sided intervals
+= \ifelse{latex}{\out{$100 - 2 \times 5\% = 90\%$}}{\ifelse{html}{\out{100 &minus; 2 &times; 5&percnt; = 90&percnt;}}{100 - 2*5\% = 90\%}}).
+This estimates the lower bound and upper bound for the above 1-sided intervals
 simultaneously. These intervals are commonly reported when conducting equivalence
 tests. For example, a 90\% 2-sided interval gives the bounds for an equivalence
 test with \ifelse{latex}{\out{$\alpha = .05$}}{\ifelse{html}{\out{&alpha; = .05}}{alpha = .05}}.

---FILE: man/eta_squared.Rd---
@@ -200,9 +200,12 @@ more info.
 Unless stated otherwise, confidence (compatibility) intervals (CIs) are
 estimated using the noncentrality parameter method (also called the
 ""pivot method""). This method finds the noncentrality parameter (""\emph{ncp}"") of
-a noncentral \emph{t}, \emph{F}, or chi-squared distribution that places the observed
-\emph{t}, \emph{F}, or chi-squared test statistic at the desired probability point of
-the distribution. For example, if the observed \emph{t} statistic is 2.0, with 50
+a noncentral \emph{t}, \emph{F}, or
+\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
+distribution that places the observed \emph{t}, \emph{F}, or
+\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
+test statistic at the desired probability point of the distribution.
+For example, if the observed \emph{t} statistic is 2.0, with 50
 degrees of freedom, for which cumulative noncentral \emph{t} distribution is
 \emph{t} = 2.0 the .025 quantile (answer: the noncentral \emph{t} distribution with
 \emph{ncp} = .04)? After estimating these confidence bounds on the \emph{ncp}, they are
@@ -254,11 +257,11 @@ typically involve \emph{t}- or \emph{z}-statistics and are generally tested usin
 \cr\cr
 Some effect sizes are strictly positive--they have a minimum value of 0.
 For example,
-\ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{*R*<sup>2</sup>}}{R^2}},
+\ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{<i>R</i><sup>2</sup>}}{R^2}},
 \ifelse{latex}{\out{$\eta^2$}}{\ifelse{html}{\out{&eta;<sup>2</sup>}}{eta^2}},
 and other variance-accounted-for effect sizes, as well as Cramer's \emph{V} and
 multiple \emph{R}, range from 0 to 1. These typically involve \emph{F}- or
-\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{\chi;<sup>2</sup>}}{chi-squared}}-statistics
+\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}-statistics
 and are generally tested using \emph{1-tailed} tests. These test test whether the
 estimated effect size is \emph{larger} than the hypothesized value (e.g., 0). The
 corresponding CI that yields the same significance decision is a \emph{1-sided} CI
@@ -274,7 +277,7 @@ up to the maximum possible value of the effect size (e.g., 1) is in the interval
 \cr\cr
 An alternative 1-sided CI that can be used to test against the maximum effect
 size value (e.g., is
-\ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{*R*<sup>2</sup>}}{R^2}}
+\ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{<i>R</i><sup>2</sup>}}{R^2}}
 significantly different from a perfect correlation of 1.0?) can by setting
 \code{alternative = ""less""}. This estimates a CI with only an \emph{upper} bound;
 anything from the minimum possible value of the effect size (e.g., 0) up to
@@ -287,10 +290,10 @@ for \emph{r}, \emph{d}, or \emph{g}.
 \cr\cr
 An alternative approach to aligning significance tests using CIs and 1-tailed
 \emph{p} values that can often be found in the literature is to
-construct a 2-sided CI at a lower confidence level (
+construct a 2-sided CI at a lower confidence level (e.g.,
 100(\ifelse{latex}{\out{$1 - 2\alpha$}}{\ifelse{html}{\out{1 &minus; 2&alpha;}}{1 - 2*alpha}})\%
-= \ifelse{latex}{\out{$100 - 2 \times 5\% = 90\%$}}{\ifelse{html}{\out{100 â 2 \%times; 5\% = 90\%}}{100 - 2*5\% = 90\%}}),
-estimates the lower bound and upper bound for the above 1-sided intervals
+= \ifelse{latex}{\out{$100 - 2 \times 5\% = 90\%$}}{\ifelse{html}{\out{100 &minus; 2 &times; 5&percnt; = 90&percnt;}}{100 - 2*5\% = 90\%}}).
+This estimates the lower bound and upper bound for the above 1-sided intervals
 simultaneously. These intervals are commonly reported when conducting equivalence
 tests. For example, a 90\% 2-sided interval gives the bounds for an equivalence
 test with \ifelse{latex}{\out{$\alpha = .05$}}{\ifelse{html}{\out{&alpha; = .05}}{alpha = .05}}.

---FILE: man/phi.Rd---
@@ -95,9 +95,12 @@ and \emph{One-Sided CIs} sections for \emph{phi}, Cohen's \emph{w} and Cramer's
 Unless stated otherwise, confidence (compatibility) intervals (CIs) are
 estimated using the noncentrality parameter method (also called the
 ""pivot method""). This method finds the noncentrality parameter (""\emph{ncp}"") of
-a noncentral \emph{t}, \emph{F}, or chi-squared distribution that places the observed
-\emph{t}, \emph{F}, or chi-squared test statistic at the desired probability point of
-the distribution. For example, if the observed \emph{t} statistic is 2.0, with 50
+a noncentral \emph{t}, \emph{F}, or
+\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
+distribution that places the observed \emph{t}, \emph{F}, or
+\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
+test statistic at the desired probability point of the distribution.
+For example, if the observed \emph{t} statistic is 2.0, with 50
 degrees of freedom, for which cumulative noncentral \emph{t} distribution is
 \emph{t} = 2.0 the .025 quantile (answer: the noncentral \emph{t} distribution with
 \emph{ncp} = .04)? After estimating these confidence bounds on the \emph{ncp}, they are
@@ -149,11 +152,11 @@ typically involve \emph{t}- or \emph{z}-statistics and are generally tested usin
 \cr\cr
 Some effect sizes are strictly positive--they have a minimum value of 0.
 For example,
-\ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{*R*<sup>2</sup>}}{R^2}},
+\ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{<i>R</i><sup>2</sup>}}{R^2}},
 \ifelse{latex}{\out{$\eta^2$}}{\ifelse{html}{\out{&eta;<sup>2</sup>}}{eta^2}},
 and other variance-accounted-for effect sizes, as well as Cramer's \emph{V} and
 multiple \emph{R}, range from 0 to 1. These typically involve \emph{F}- or
-\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{\chi;<sup>2</sup>}}{chi-squared}}-statistics
+\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}-statistics
 and are generally tested using \emph{1-tailed} tests. These test test whether the
 estimated effect size is \emph{larger} than the hypothesized value (e.g., 0). The
 corresponding CI that yields the same significance decision is a \emph{1-sided} CI
@@ -169,7 +172,7 @@ up to the maximum possible value of the effect size (e.g., 1) is in the interval
 \cr\cr
 An alternative 1-sided CI that can be used to test against the maximum effect
 size value (e.g., is
-\ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{*R*<sup>2</sup>}}{R^2}}
+\ifelse{latex}{\out{$R^2$}}{\ifelse{html}{\out{<i>R</i><sup>2</sup>}}{R^2}}
 significantly different from a perfect correlation of 1.0?) can by setting
 \code{alternative = ""less""}. This estimates a CI with only an \emph{upper} bound;
 anything from the minimum possible value of the effect size (e.g., 0) up to
@@ -182,10 +185,10 @@ for \emph{r}, \emph{d}, or \emph{g}.
 \cr\cr
 An alternative approach to aligning significance tests using CIs and 1-tailed
 \emph{p} values that can often be found in the literature is to
-construct a 2-sided CI at a lower confidence level (
+construct a 2-sided CI at a lower confidence level (e.g.,
 100(\ifelse{latex}{\out{$1 - 2\alpha$}}{\ifelse{html}{\out{1 &minus; 2&alpha;}}{1 - 2*alpha}})\%
-= \ifelse{latex}{\out{$100 - 2 \times 5\% = 90\%$}}{\ifelse{html}{\out{100 â 2 \%times; 5\% = 90\%}}{100 - 2*5\% = 90\%}}),
-estimates the lower bound and upper bound for the above 1-sided intervals
+= \ifelse{latex}{\out{$100 - 2 \times 5\% = 90\%$}}{\ifelse{html}{\out{100 &minus; 2 &times; 5&percnt; = 90&percnt;}}{100 - 2*5\% = 90\%}}).
+This estimates the lower bound and upper bound for the above 1-sided intervals
 simultaneously. These intervals are commonly reported when conducting equivalence
 tests. For example, a 90\% 2-sided interval gives the bounds for an equivalence
 test with \ifelse{latex}{\out{$\alpha = .05$}}{\ifelse{html}{\out{&alpha; = .05}}{alpha = .05}}.

---FILE: man/t_to_r.Rd---
@@ -96,9 +96,12 @@ functions.
 Unless stated otherwise, confidence (compatibility) intervals (CIs) are
 estimated using the noncentrality parameter method (also called the
 ""pivot method""). This method finds the noncentrality parameter (""\emph{ncp}"") of
-a noncentral \emph{t}, \emph{F}, or chi-squared distribution that places the observed
-\emph{t}, \emph{F}, or chi-squared test statistic at the desired probability point of
-the distribution. For example, if the observed \emph{t} statistic is 2.0, with 50
+a noncentral \emph{t}, \emph{F}, or
+\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
+distribution that places the observed \emph{t}, \emph{F}, or
+\ifelse{latex}{\out{$\chi^2$}}{\ifelse{html}{\out{&chi;<sup>2</sup>}}{chi-squared}}
+test statistic at the desired probability point of the distribution.
+For example, if the observed \emph{t} statistic is 2.0, with 50
 degrees of freedom, for which cumulative noncentral \emph{t} distribution is
 \emph{t} = 2.0 the .025 quantile (answer: the noncentral \emph{t} distribution with
 \emph{ncp} = .04)? After estimating these confidence bounds on the \emph{ncp}, they are",True,False,Documentation / Formatting,6
easystats,effectsize,fd8e2cc9f7c9594ee2f21778a575cc640da8ff71,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-16T17:58:30Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-08-16T17:58:30Z,fix tests,tests/testthat/test-convert_between.R;tests/testthat/test-convert_statistic.R;tests/testthat/test-eta_squared.R;tests/testthat/test-odds_probs.R;tests/testthat/test-standardize_models.R;tests/testthat/test-xtab.R,False,True,True,False,27,30,57,"---FILE: tests/testthat/test-convert_between.R---
@@ -29,4 +29,29 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(riskratio_to_oddsratio(log(RR), p0 = p0, log = TRUE), log(OR))
     expect_equal(oddsratio_to_riskratio(log(OR), p0 = p0, log = TRUE), log(RR))
   })
+
+  test_that(""odds_to_probs"", {
+    expect_equal(odds_to_probs(3), 0.75, tolerance = 0.01)
+    expect_equal(probs_to_odds(0.75), 3, tolerance = 0.01)
+    expect_equal(probs_to_odds(0.75, log = TRUE), 1.098, tolerance = 0.01)
+    expect_equal(odds_to_probs(1.098, log = TRUE), 0.75, tolerance = 0.01)
+
+    expect_equal(
+      ncol(df <- odds_to_probs(
+        iris,
+        select = c(""Sepal.Length""),
+        exclude = c(""Petal.Length""),
+        log = TRUE
+      )), 5
+    )
+
+    expect_equal(
+      ncol(probs_to_odds(
+        df,
+        select = c(""Sepal.Length""),
+        exclude = c(""Petal.Length""),
+        log = TRUE
+      )), 5
+    )
+  })
 }

---FILE: tests/testthat/test-odds_probs.R---
@@ -1,28 +0,0 @@
-if (require(""testthat"") && require(""effectsize"")) {
-  test_that(""odds_to_probs"", {
-    expect_equal(odds_to_probs(3), 0.75, tolerance = 0.01)
-    expect_equal(probs_to_odds(0.75), 3, tolerance = 0.01)
-    expect_equal(probs_to_odds(0.75, log = TRUE), 1.098, tolerance = 0.01)
-    expect_equal(odds_to_probs(1.098, log = TRUE), 0.75, tolerance = 0.01)
-
-
-
-    expect_equal(
-      ncol(df <- odds_to_probs(
-        iris,
-        select = c(""Sepal.Length""),
-        exclude = c(""Petal.Length""),
-        log = TRUE
-      )), 5
-    )
-
-    expect_equal(
-      ncol(probs_to_odds(
-        df,
-        select = c(""Sepal.Length""),
-        exclude = c(""Petal.Length""),
-        log = TRUE
-      )), 5
-    )
-  })
-}

---FILE: tests/testthat/test-xtab.R---
@@ -8,8 +8,8 @@ if (require(""testthat"") && require(""effectsize"")) {
     res <- cramers_v(contingency_table)
 
     expect_equal(res$Cramers_v, 0.072, tolerance = 0.01)
-    expect_equal(res$CI_low, 0.047, tolerance = 0.01)
-    expect_equal(res$CI_high, 0.091, tolerance = 0.01)
+    expect_equal(res$CI_low, 0.051, tolerance = 0.01)
+    expect_equal(res$CI_high, 0.088, tolerance = 0.01)
 
 
     ## Size does not affect estimate",True,False,Dependency / Package,3
easystats,effectsize,e04cd3fb3761e0d84e39676f53943ba495d3b152,mattansb,35330040+mattansb@users.noreply.github.com,2021-06-18T18:45:29Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-06-18T18:45:29Z,fix: typo in link to datawiz,R/standardize.models.R;man/standardize.default.Rd,False,True,True,False,2,2,4,"---FILE: R/standardize.models.R---
@@ -1,7 +1,7 @@
 #' Re-fit a model with standardized data
 #'
 #' Performs a standardization of data (z-scoring) using
-#' [`datawizrd:standardize()`] and then re-fits the model to the standardized
+#' [`datawizard::standardize()`] and then re-fits the model to the standardized
 #' data.
 #'
 #' @param x A statistical model.

---FILE: man/standardize.default.Rd---
@@ -47,7 +47,7 @@ A statistical model fitted on standardized data
 }
 \description{
 Performs a standardization of data (z-scoring) using
-\code{\link[=datawizrd:standardize]{datawizrd:standardize()}} and then re-fits the model to the standardized
+\code{\link[datawizard:standardize]{datawizard::standardize()}} and then re-fits the model to the standardized
 data.
 }
 \section{Generalized Linear Models}{",True,False,Documentation / Formatting,7
easystats,effectsize,4a7708ab5d69ad96d87e41a2bdb31d1ef8941c31,Indrajeet Patil,inderonline1988@gmail.com,2021-06-14T07:12:19Z,Indrajeet Patil,inderonline1988@gmail.com,2021-06-14T07:12:19Z,https://github.com/easystats/easystats/issues/146,DESCRIPTION,False,False,False,False,9,9,18,"---FILE: DESCRIPTION---
@@ -31,20 +31,20 @@ Authors@R:
              role = ""ctb""),
       person(given = ""Jessica"",
              family = ""Burnett"",
-             role = c(""rev""),
+             role = ""rev"",
              email = ""jburnett@usgs.gov"",
              comment = c(ORCID = ""0000-0002-0896-5099"")),
       person(given = ""Johannes"",
              family = ""Karreth"",
-             role = c(""rev""),
+             role = ""rev"",
              email = ""jkarreth@ursinus.edu"",
              comment = c(ORCID = ""0000-0003-4586-7153"")))
 Maintainer: Mattan S. Ben-Shachar <matanshm@post.bgu.ac.il>
 Description: Provide utilities to work with indices of effect size and
     standardized parameters for a wide variety of models (see list of
-    supported models in insight; LÃ¼decke, Waggoner & Makowski (2019)
-    <doi:10.21105/joss.01412>), allowing computation of and conversion
-    between indices such as Cohen's d, r, odds, etc.
+    supported models using the function 'insight::supported_models()'),
+    allowing computation of and conversion between indices such as Cohen's
+    d, r, odds, etc.
 License: GPL-3
 URL: https://easystats.github.io/effectsize/
 BugReports: https://github.com/easystats/effectsize/issues/
@@ -89,13 +89,13 @@ Suggests:
     testthat,
     tidymodels,
     tidyr
-Remotes:
-    easystats/bayestestR
 VignetteBuilder: 
     knitr
-Config/testthat/edition: 3
-Config/testthat/parallel: true
+Remotes:
+    easystats/bayestestR
 Encoding: UTF-8
 Language: en-US
 Roxygen: list(markdown = TRUE)
 RoxygenNote: 7.1.1
+Config/testthat/edition: 3
+Config/testthat/parallel: true",False,False,Dependency / Package,6
easystats,effectsize,6c24ef438d85fc5d06ae9bb4a9a355b7219ff6df,mattansb,35330040+mattansb@users.noreply.github.com,2021-06-13T10:56:06Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-06-13T10:56:06Z,fix build warning for interp_pd,R/interpret_pd.R;man/interpret_pd.Rd,False,True,True,False,12,4,16,"---FILE: R/interpret_pd.R---
@@ -1,6 +1,9 @@
 #' Interpret Probability of Direction (pd)
 #'
-#' @param x Value or vector of probabilities of direction (pd).
+#' @param pd Value or vector of probabilities of direction.
+#' @param rules Can be `""default""`, `""makowski2019""` or a custom set of
+#'   [rules()].
+#' @param ... Not directly used.
 #'
 #' @section Rules:
 #'
@@ -28,10 +31,10 @@ interpret_pd <- function(pd, rules = ""default"") {
     rules,
     list(
       default = rules(c(0.975), c(""not significant"", ""significant""),
-                      name = ""default"", right = FALSE
+                      name = ""default"", right = TRUE
       ),
       makowski2019 = rules(c(0.95, 0.97, 0.99, 0.999), c(""uncertain"", ""possibly existing"", ""likely existing"", ""probably existing"", ""certainly existing""),
-                  name = ""makowski2019"", right = FALSE
+                  name = ""makowski2019"", right = TRUE
       )
     )
   )

---FILE: man/interpret_pd.Rd---
@@ -7,7 +7,12 @@
 interpret_pd(pd, rules = ""default"")
 }
 \arguments{
-\item{x}{Value or vector of probabilities of direction (pd).}
+\item{pd}{Value or vector of probabilities of direction.}
+
+\item{rules}{Can be \code{""default""}, \code{""makowski2019""} or a custom set of
+\code{\link[=rules]{rules()}}.}
+
+\item{...}{Not directly used.}
 }
 \description{
 Interpret Probability of Direction (pd)",True,False,Documentation / Formatting,6
easystats,effectsize,7eebc979b77f5bdbba20c3623a423f47100511b0,Dominique Makowski,dom.mak19@gmail.com,2021-06-10T09:03:32Z,Dominique Makowski,dom.mak19@gmail.com,2021-06-10T09:03:32Z,"allows ""...""

https://github.com/easystats/report/issues/182",R/interpret_oddsratio.R;man/interpret_oddsratio.Rd;man/interpret_pd.Rd,False,True,True,False,6,3,9,"---FILE: R/interpret_oddsratio.R---
@@ -5,6 +5,7 @@
 #'   transformation to standardized difference, see [odds_to_d()]) or custom set
 #'   of [rules()].
 #' @param log Are the provided values log odds ratio.
+#' @inheritParams interpret
 #'
 #' @section Rules:
 #'
@@ -39,7 +40,7 @@
 #' methods, 8(4), 448.
 #'
 #' @export
-interpret_oddsratio <- function(OR, rules = ""chen2010"", log = FALSE) {
+interpret_oddsratio <- function(OR, rules = ""chen2010"", log = FALSE, ...) {
   if (log) {
     OR <- exp(abs(OR))
   } else {

---FILE: man/interpret_oddsratio.Rd---
@@ -5,7 +5,7 @@
 \alias{interpret_odds}
 \title{Interpret Odds ratio}
 \usage{
-interpret_oddsratio(OR, rules = ""chen2010"", log = FALSE)
+interpret_oddsratio(OR, rules = ""chen2010"", log = FALSE, ...)
 }
 \arguments{
 \item{OR}{Value or vector of (log) odds ratio values.}
@@ -15,6 +15,8 @@ transformation to standardized difference, see \code{\link[=odds_to_d]{odds_to_d
 of \code{\link[=rules]{rules()}}.}
 
 \item{log}{Are the provided values log odds ratio.}
+
+\item{...}{Currently not used.}
 }
 \description{
 Interpret Odds ratio

---FILE: man/interpret_pd.Rd---
@@ -32,7 +32,7 @@ Interpret Probability of Direction (pd)
 }
 
 \examples{
-interpret_pd(.96)
+interpret_pd(.98)
 interpret_pd(c(.96, .99), rules = ""makowski2019"")
 
 }",True,False,Documentation / Formatting,6
easystats,effectsize,c40d81ccc5d6ec073a5fef08c58292748d25f163,Brenton M. Wiernik,bwiernik@users.noreply.github.com,2021-05-28T19:58:39Z,Brenton M. Wiernik,bwiernik@users.noreply.github.com,2021-05-28T19:58:39Z,"Document sources of r_rbs SEs

Closes https://github.com/easystats/effectsize/issues/336",R/rank_effectsizes.R,False,True,True,False,10,2,12,"---FILE: R/rank_effectsizes.R---
@@ -204,12 +204,20 @@ rank_biserial <- function(x,
       nd <- sum((x - mu) != 0)
       maxw <- (nd^2 + nd) / 2
 
-      rfSE <- sqrt((2 * nd^3 + 3 * nd^2 + nd) / (6 * maxw ^ 2))
+      # From: https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test#Historical_T_statistic
+      # wSE <- sqrt((n * (n + 1) * (2 * n + 1)) / 24)
+      # Delta method for f(x) = w * 2 / (maxw) - 1
+      # r_rbsSE <- wSE * sqrt(4 / (maxw)^2)
+      rfSE <- sqrt((2 * nd^3 + 3 * nd^2 + nd) / (6 * maxw ^ 2)) # I think this needs to be further divided by (1 - r_rbs^2)
     } else {
       n1 <- length(x)
       n2 <- length(y)
 
-      rfSE <- sqrt(4 * 1 / (n1 * n2) * (n1 + n2 + 1) / 12)
+      # From: https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test#Normal_approximation_and_tie_correction
+      # wSE <- sqrt((n1 * n2 * (n1 + n2 + 1)) / 12)
+      # Delta method for f(x) = 1 - 2 * w / (n1 * n2) * sign(diff)
+      # r_rbsSE <- wSE * sqrt(4 / (n1 * n2)^2)
+      rfSE <- sqrt((n1 + n2 + 1) / (3 * n1 * n2)) # I think this needs to be further divided by (1 - r_rbs^2)
     }
 
     confint <- tanh(rf + c(-1, 1) * qnorm(1 - alpha / 2) * rfSE)",True,False,Implementation / Logic,6
easystats,effectsize,fd4a8fbc3f859d46aae0c8e6cb60547e926ad144,Dominique Makowski,dom.mak19@gmail.com,2021-05-24T05:00:56Z,Dominique Makowski,dom.mak19@gmail.com,2021-05-24T05:00:56Z,minor fix,R/format_standardize.R,False,True,True,False,1,1,2,"---FILE: R/format_standardize.R---
@@ -48,7 +48,7 @@ format_standardize <- function(x, reference = x, robust = FALSE, digits = 1, pro
 
 
   # Express in deviations
-  if(any(x != reference)) {
+  if(length(x) != length(reference) || any(x != reference)) {
     x <- (x - central) / deviation
   }
 ",True,False,Implementation / Logic,6
easystats,effectsize,3b76f60d10e3ab0bfd474c03cd28127e72073c09,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-23T12:51:08Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-23T12:51:08Z,fix backward com with parameters,tests/testthat/test-eta_squared_etc.R,False,True,True,False,1,1,2,"---FILE: tests/testthat/test-eta_squared_etc.R---
@@ -455,6 +455,6 @@ if (require(""testthat"") && require(""effectsize"")) {
     skip_if_not_installed(""car"")
     b_lm <- car::Anova(lm(mpg ~ cyl + am, data = mtcars), type = 2)
     out_lm <- eta_squared(b_lm)
-    expect_equal(out[1:2, ], out_lm)
+    expect_equal(out[1:2, ], out_lm, ignore_attr = TRUE)
   })
 }",True,False,Dependency / Package,3
easystats,effectsize,96beaa9fa5ea408265ec743ac06f504657547e97,Dominique Makowski,dom.mak19@gmail.com,2021-05-23T10:29:09Z,Dominique Makowski,dom.mak19@gmail.com,2021-05-23T10:29:09Z,hotfix,R/unstandardize.R,False,True,True,False,1,1,2,"---FILE: R/unstandardize.R---
@@ -118,7 +118,7 @@ unstandardize.data.frame <- function(x,
 
   # Apply unstandardization to cols
   for(col in cols) {
-    x[cols] <- unstandardize(x[[col]], center = center[[col]], scale = scale[[col]])
+    x[col] <- unstandardize(x[[col]], center = center[[col]], scale = scale[[col]])
   }
   x
 }",True,False,Implementation / Logic,3
easystats,effectsize,45cafa5a2b17bb3653b5c723a1686d76a897171a,Dominique Makowski,dom.mak19@gmail.com,2021-05-23T09:26:59Z,Dominique Makowski,dom.mak19@gmail.com,2021-05-23T09:26:59Z,hotfix (prevent overwriting the var class),R/unstandardize.R,False,True,True,False,3,4,7,"---FILE: R/unstandardize.R---
@@ -117,10 +117,9 @@ unstandardize.data.frame <- function(x,
   if(!is.null(exclude)) cols <- cols[!cols %in% exclude]
 
   # Apply unstandardization to cols
-  x[cols] <- mapply(unstandardize, x[cols],
-    center = center[cols],
-    scale = scale[cols]
-  )
+  for(col in cols) {
+    x[cols] <- unstandardize(x[[col]], center = center[[col]], scale = scale[[col]])
+  }
   x
 }
 ",True,False,Implementation / Logic,6
easystats,effectsize,067c9f9b524d14eebe3b2b9918f7740f6ffaa9f1,Dominique Makowski,dom.mak19@gmail.com,2021-05-23T07:45:32Z,Dominique Makowski,dom.mak19@gmail.com,2021-05-23T07:45:32Z,improve/fix format_standardize,R/format_standardize.R;R/standardize.data.R;man/format_standardize.Rd;tests/testthat/test-format_standardize.R,False,True,True,False,54,16,70,"---FILE: R/format_standardize.R---
@@ -6,15 +6,26 @@
 #' @param reference The reference vector from which to compute the mean and SD.
 #' @inheritParams standardize
 #' @inheritParams insight::format_value
+#' @param ... Other arguments to pass to \code{\link[insight:format_value]{insight::format_value()}} such as \code{digits}, etc.
 #'
 #' @examples
 #' format_standardize(c(-1, 0, 1))
 #' format_standardize(c(-1, 0, 1, 2), reference = rnorm(1000))
 #' format_standardize(c(-1, 0, 1, 2), reference = rnorm(1000), robust = TRUE)
+#'
+#' format_standardize(standardize(mtcars$wt), digits = 1)
+#' format_standardize(standardize(mtcars$wt, robust = TRUE), digits = 1)
 #' @importFrom stats median mad sd
 #' @importFrom insight format_value
 #' @export
-format_standardize <- function(x, reference = x, robust = FALSE, digits = NULL, ...) {
+format_standardize <- function(x, reference = x, robust = FALSE, digits = 1, protect_integers = TRUE, ...) {
+
+  # Check if robust info stored in attributes
+  if(""robust"" %in% names(attributes(reference))) {
+    robust <- attributes(reference)$robust
+  }
+
+  # Find parameters and their names
   if (robust) {
     central <- stats::median(reference, na.rm = TRUE)
     central_name <- ""Median""
@@ -27,21 +38,33 @@ format_standardize <- function(x, reference = x, robust = FALSE, digits = NULL,
     deviation_name <- ""SD""
   }
 
+  # See if they are not stored as attributes
+  if(""center"" %in% names(attributes(reference))) {
+    central <- attributes(reference)$center
+  }
+  if(""scale"" %in% names(attributes(reference))) {
+    deviation <- attributes(reference)$scale
+  }
+
+
   # Express in deviations
-  x <- (x - central) / deviation
+  if(any(x != reference)) {
+    x <- (x - central) / deviation
+  }
 
   # Round
-  if (is.null(digits)) {
-    L <- insight::format_value(x, round(1 / diff(range(x, na.rm = TRUE))), protect_integers = TRUE)
-  } else {
-    L <- insight::format_value(x, digits = digits, protect_integers = TRUE)
-  }
+  x <- round(x, digits = digits)
+
+
+  # Format vector as character
+  L <- insight::format_value(x, digits = digits, ...)
 
   # Complete
   L[!grepl(""-"", L)] <- paste0(""+"", L[!grepl(""-"", L)])
   L <- paste(L, deviation_name)
-  is_central <- sapply(x, function(.) isTRUE(all.equal(., 0)))
-  L[is_central] <- central_name
+  L[x == 0] <- central_name
 
-  factor(L, levels = rev(unique(L)))
+  # Order
+  idx <- L[order(x, decreasing = TRUE)]
+  factor(L, levels = unique(idx))
 }

---FILE: R/standardize.data.R---
@@ -45,6 +45,7 @@ standardize.numeric <- function(x,
   scaled_x[valid_x] <- x
   attr(scaled_x, ""center"") <- ref$center
   attr(scaled_x, ""scale"") <- ref$scale
+  attr(scaled_x, ""robust"") <- robust
   scaled_x
 }
 
@@ -202,6 +203,7 @@ standardize.data.frame <- function(x,
 
   attr(x, ""center"") <- sapply(x[select], function(z) attributes(z)$center)
   attr(x, ""scale"") <- sapply(x[select], function(z) attributes(z)$scale)
+  attr(x, ""robust"") <- robust
   x
 }
 

---FILE: man/format_standardize.Rd---
@@ -4,7 +4,14 @@
 \alias{format_standardize}
 \title{Transform a standardized vector into character}
 \usage{
-format_standardize(x, reference = x, robust = FALSE, digits = NULL, ...)
+format_standardize(
+  x,
+  reference = x,
+  robust = FALSE,
+  digits = 1,
+  protect_integers = TRUE,
+  ...
+)
 }
 \arguments{
 \item{x}{A standardized numeric vector.}
@@ -21,7 +28,10 @@ to return scientific notation. For the latter case, control the number of
 digits by adding the value as suffix, e.g. \code{digits = ""scientific4""}
 to have scientific notation with 4 decimal places.}
 
-\item{...}{Arguments passed to or from other methods.}
+\item{protect_integers}{Should integers be kept as integers (i.e., without
+decimals)?}
+
+\item{...}{Other arguments to pass to \code{\link[insight:format_value]{insight::format_value()}} such as \code{digits}, etc.}
 }
 \description{
 Transform a standardized vector into character, e.g., \code{c(""-1 SD"", ""Mean"", ""+1 SD"")}.
@@ -30,4 +40,7 @@ Transform a standardized vector into character, e.g., \code{c(""-1 SD"", ""Mean"", ""
 format_standardize(c(-1, 0, 1))
 format_standardize(c(-1, 0, 1, 2), reference = rnorm(1000))
 format_standardize(c(-1, 0, 1, 2), reference = rnorm(1000), robust = TRUE)
+
+format_standardize(standardize(mtcars$wt), digits = 1)
+format_standardize(standardize(mtcars$wt, robust = TRUE), digits = 1)
 }

---FILE: tests/testthat/test-format_standardize.R---
@@ -1,7 +1,7 @@
 if (require(""testthat"") && require(""effectsize"")) {
   test_that(""format_standardize"", {
     expect_equal(
-      format_standardize(c(-1, 0, 1)),
+      format_standardize(c(-1, 0, 1), digits = 0),
       structure(3:1, .Label = c(""+1 SD"", ""Mean"", ""-1 SD""), class = ""factor"")
     )
 
@@ -10,23 +10,23 @@ if (require(""testthat"") && require(""effectsize"")) {
     ref <- bayestestR::distribution_normal(1000)
 
     expect_equal(
-      format_standardize(c(-1, 0, 1, 2), reference = ref),
+      format_standardize(c(-1, 0, 1, 2), reference = ref, digits = 0),
       structure(4:1,
         .Label = c(""+2 SD"", ""+1 SD"", ""Mean"", ""-1 SD""),
         class = ""factor""
       )
     )
 
     expect_equal(
-      format_standardize(c(-1, 0, 1, 2), reference = ref, robust = TRUE),
+      format_standardize(c(-1, 0, 1, 2), reference = ref, robust = TRUE, digits = 0),
       structure(4:1,
         .Label = c(""+2 MAD"", ""+1 MAD"", ""Median"", ""-1 MAD""),
         class = ""factor""
       )
     )
 
     expect_equal(
-      format_standardize(c(-1, 0, 1, 2), reference = ref, robust = TRUE, digits = 2),
+      format_standardize(c(-1, 0, 1, 2), reference = ref, robust = TRUE, digits = 2, protect_integers = FALSE),
       structure(4:1,
         .Label = c(""+2.00 MAD"", ""+1.00 MAD"", ""Median"", ""-1.00 MAD""),
         class = ""factor""",True,False,Documentation / Formatting,6
easystats,effectsize,e5f06d3d95218f06fdbbea2ca198062b75499b5f,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-23T06:09:35Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-23T06:09:35Z,"explicit effects = ""fixed""",R/eta_squared.R;tests/testthat/test-standardize_parameters.R;vignettes/from_test_statistics.Rmd,True,True,True,False,11,11,22,"---FILE: R/eta_squared.R---
@@ -410,7 +410,7 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
 
   type <- match.arg(type)
 
-  params <- parameters::model_parameters(model, verbose = verbose)
+  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"")
   out <- .es_aov(as.data.frame(params), type, partial, generalized, ci, verbose = verbose, ...)
   if (is.null(attr(out, ""anova_type""))) attr(out, ""anova_type"") <- attr(params, ""anova_type"")
   out
@@ -562,7 +562,7 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
                               verbose = TRUE,
                               include_intercept = FALSE,
                               ...) {
-  params <- parameters::model_parameters(model, verbose = verbose)
+  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"")
   anova_type <- attr(params, ""anova_type"")
   params <- as.data.frame(params)
 
@@ -723,7 +723,7 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
                           verbose = TRUE,
                           ...) {
   model <- stats::aov(model)
-  params <- parameters::model_parameters(model, verbose = verbose)
+  params <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"")
   anova_type <- attr(params, ""anova_type"")
 
   params <- as.data.frame(params)
@@ -782,7 +782,7 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
     return(res)
   }
 
-  anova_type <- tryCatch(attr(parameters::model_parameters(model, verbose = FALSE), ""anova_type""),
+  anova_type <- tryCatch(attr(parameters::model_parameters(model, verbose = FALSE, effects = ""fixed""), ""anova_type""),
                          error = function(...) 1)
 
   if (!include_intercept) model <- model[rownames(model) != ""(Intercept)"", , drop = FALSE]
@@ -951,7 +951,7 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
   #                 ...)
 
   ## For the multivariate test
-  model <- parameters::model_parameters(model, verbose = verbose, ...)
+  model <- parameters::model_parameters(model, verbose = verbose, effects = ""fixed"", ...)
   anova_type <- attr(model, ""anova_type"")
 
   if (""df_num"" %in% colnames(model))

---FILE: tests/testthat/test-standardize_parameters.R---
@@ -15,7 +15,7 @@ if (require(""testthat"") && require(""effectsize"")) {
   # model_parameters -------------------------------
   test_that(""standardize_parameters (model_parameters)"", {
     model <<- lm(mpg ~ cyl + am, data = mtcars)
-    mp <<- parameters::model_parameters(model)
+    mp <<- parameters::model_parameters(model, effects = ""fixed"")
 
     s1 <- standardize_parameters(model, method = ""basic"")
     s2 <- standardize_parameters(mp, method = ""basic"")
@@ -25,7 +25,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(s1$CI_low, s2$CI_low)
     expect_equal(s1$CI_high, s2$CI_high)
 
-    mp_exp <<- parameters::model_parameters(model, exponentiate = TRUE)
+    mp_exp <<- parameters::model_parameters(model, exponentiate = TRUE, effects = ""fixed"")
     se1 <- standardize_parameters(model, method = ""basic"", exponentiate = TRUE)
     se2 <- standardize_parameters(mp_exp, method = ""basic"", exponentiate = TRUE)
 
@@ -383,7 +383,7 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     m <- pscl::zeroinfl(art ~ fem + mar + kid5 + ment | kid5 + phd, data = bioChemists)
 
-    mp <- parameters::model_parameters(m)
+    mp <- parameters::model_parameters(m, effects = ""fixed"")
     sm1 <- standardize_parameters(m, method = ""refit"")
     expect_warning(sm2 <- standardize_parameters(m, method = ""posthoc""))
     suppressWarnings({
@@ -452,7 +452,7 @@ test_that(""include_response | parameters"", {
   m <<- lm(Sepal.Length ~ Petal.Length + Petal.Width, data = iris)
 
   # parameters ---
-  pars <- parameters::model_parameters(m)
+  pars <- parameters::model_parameters(m, effects = ""fixed"")
   pars_z0 <- standardize_parameters(pars, method = ""basic"")
   pars_z1 <- standardize_parameters(pars, method = ""basic"", include_response = FALSE)
   expect_equal(pars_z0$Std_Coefficient[-1] * sd(iris$Sepal.Length), pars_z1$Std_Coefficient[-1])

---FILE: vignettes/from_test_statistics.Rmd---
@@ -153,7 +153,7 @@ We can also use `t_to_eta2()` for the slope of `Days` (which in this case gives
 the same result).
 
 ```{r}
-parameters::model_parameters(fit_lmm, df_method = ""satterthwaite"")
+parameters::model_parameters(fit_lmm, effects = ""fixed"", df_method = ""satterthwaite"")
 
 t_to_eta2(6.77, df_error = 17)
 ```
@@ -181,7 +181,7 @@ better).
 ### For Slopes
 
 ```{r}
-parameters::model_parameters(fit_lmm, df_method = ""satterthwaite"")
+parameters::model_parameters(fit_lmm, effects = ""fixed"", df_method = ""satterthwaite"")
 
 t_to_r(6.77, df_error = 17)
 ```",True,True,Implementation / Logic,6
easystats,effectsize,16b7151ea1933c043066400f02e164832570fcd4,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-21T06:44:02Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-21T06:44:02Z,fix: docs,R/eta_squared.R;man/eta_squared.Rd,False,True,True,False,4,8,12,"---FILE: R/eta_squared.R---
@@ -14,7 +14,7 @@
 #' @param model A model, ANOVA object, or the result of `parameters::model_parameters`.
 #' @param partial If `TRUE`, return partial indices.
 #' @param generalized If TRUE, returns generalized Eta Squared, assuming all
-#'   variables are **observed**. Can also be a character vector of observed
+#'   variables are manipulated. Can also be a character vector of observed
 #'   (non-manipulated) variables, in which case generalized Eta Squared is
 #'   calculated taking these observed variables into account. For `afex_aov`
 #'   model, when `generalized = TRUE`, the observed variables are extracted
@@ -1053,12 +1053,8 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
                                include_intercept = FALSE,
                                ...) {
   type <- match.arg(type)
-  if (type == ""eta"" && isTRUE(generalized)) {
-    if (length(attr(model$anova_table, ""observed""))) {
-      generalized <- attr(model$anova_table, ""observed"")
-    } else {
-      generalized <- names(c(attr(model, ""between""),attr(model, ""within"")))
-    }
+  if (type == ""eta"" && isTRUE(generalized) && length(attr(model$anova_table, ""observed""))) {
+    generalized <- attr(model$anova_table, ""observed"")
   }
 
   # For completely between, covers all

---FILE: man/eta_squared.Rd---
@@ -58,7 +58,7 @@ eta_squared_posterior(
 \item{partial}{If \code{TRUE}, return partial indices.}
 
 \item{generalized}{If TRUE, returns generalized Eta Squared, assuming all
-variables are \strong{observed}. Can also be a character vector of observed
+variables are manipulated. Can also be a character vector of observed
 (non-manipulated) variables, in which case generalized Eta Squared is
 calculated taking these observed variables into account. For \code{afex_aov}
 model, when \code{generalized = TRUE}, the observed variables are extracted",True,False,Documentation / Formatting,7
easystats,effectsize,8f71cc581d989fccb3e708b5aa3a40248b4c6282,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-21T05:34:58Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-21T05:34:58Z,fix: miss spec-ed column names,R/eta_squared.R;tests/testthat/test-eta_squared_etc.R,False,True,True,False,9,11,20,"---FILE: R/eta_squared.R---
@@ -1079,9 +1079,9 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
     aov_tab <- summary(model$Anova)$univariate.tests
     aov_tab <- as.data.frame(unclass(aov_tab))
     aov_tab$Parameter <- rownames(aov_tab)
-    aov_tab$Sum_Squares <- aov_tab$`Sum Sq`
-    aov_tab$df <- aov_tab$`num Df`
-    aov_tab <- aov_tab[c(""Parameter"", ""Sum_Squares"",""Error.SS"", ""df"", ""den.Df"")]
+    colnames(aov_tab)[colnames(aov_tab)== ""Sum Sq""] <- ""Sum_Squares""
+    colnames(aov_tab)[colnames(aov_tab)== ""num Df""] <- ""df""
+    aov_tab <- aov_tab[c(""Parameter"", ""Sum_Squares"",""Error SS"", ""df"", ""den Df"")]
 
     id <- attr(model, ""id"")
 
@@ -1100,14 +1100,14 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
     aov_tab <- split(aov_tab, aov_tab$Group)
     aov_tab <- lapply(aov_tab, function (x) {
       x <- x[c(seq_len(nrow(x)), 1), ]
-      x$Sum_Squares[nrow(x)] <- x$Error.SS[1]
-      x$df[nrow(x)] <- x$den.Df[1]
+      x$Sum_Squares[nrow(x)] <- x[[""Error SS""]][1]
+      x$df[nrow(x)] <- x[[""den Df""]][1]
       x$Parameter[nrow(x)] <- ""Residuals""
       x
     })
     aov_tab <- do.call(rbind, aov_tab)
-    aov_tab$Error.SS <- NULL
-    aov_tab$den.Df <- NULL
+    aov_tab[[""Error SS""]] <- NULL
+    aov_tab[[""den Df""]] <- NULL
     aov_tab$`F` <- ifelse(aov_tab$Parameter == ""Residuals"", NA, 1)
     aov_tab$Mean_Square <- aov_tab$Sum_Squares/aov_tab$df
 

---FILE: tests/testthat/test-eta_squared_etc.R---
@@ -310,13 +310,11 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     x <- eta_squared(mod, generalized = TRUE)
     a <- anova(mod, observed = ""gender"")
-    r <- cor(a$ges, x$Eta2_generalized)
-    expect_equal(r, 1, tolerance = 0.005)
+    expect_equal(a$ges, x$Eta2_generalized)
 
     x <- eta_squared(mod)
     a <- anova(mod, es = ""pes"")
-    r <- cor(a$pes, x$Eta2_partial)
-    expect_equal(r, 1, tolerance = 0.005)
+    expect_equal(a$pes, x$Eta2_partial)
 
 
     x <- eta_squared(mod, include_intercept = TRUE)",True,False,Implementation / Logic,6
easystats,effectsize,2908f9d6d3b3ffee0ebbde414a30fc382ec522a7,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-21T05:04:43Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-21T05:04:43Z,fix: add suggests and imported functions,DESCRIPTION;NAMESPACE;R/eta_squared.R;R/print.effectsize_table.R;R/sd_pooled.R,False,True,True,False,13,9,22,"---FILE: DESCRIPTION---
@@ -62,11 +62,13 @@ Suggests:
     lmerTest,
     MASS,
     mediation,
+    mgcv,
     modelbased,
     MuMIn,
     performance,
     pscl,
     rmarkdown,
+    rms,
     rstanarm,
     rstantools,
     see,

---FILE: NAMESPACE---
@@ -231,6 +231,7 @@ importFrom(parameters,parameters_type)
 importFrom(stats,anova)
 importFrom(stats,aov)
 importFrom(stats,as.formula)
+importFrom(stats,ave)
 importFrom(stats,chisq.test)
 importFrom(stats,complete.cases)
 importFrom(stats,contrasts)
@@ -260,6 +261,7 @@ importFrom(stats,terms)
 importFrom(stats,update)
 importFrom(stats,var)
 importFrom(stats,weighted.mean)
+importFrom(utils,as.roman)
 importFrom(utils,capture.output)
 importFrom(utils,head)
 importFrom(utils,packageVersion)

---FILE: R/eta_squared.R---
@@ -1078,11 +1078,10 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
     # Faking the model_parameters.aovlist output:
     aov_tab <- summary(model$Anova)$univariate.tests
     aov_tab <- as.data.frame(unclass(aov_tab))
-    aov_tab <- transform(aov_tab,
-                         Parameter = rownames(aov_tab),
-                         Sum_Squares = `Sum Sq`,
-                         df = `num Df`)
-    aov_tab <- subset(aov_tab, select = c(""Parameter"", ""Sum_Squares"",""Error.SS"", ""df"", ""den.Df""))
+    aov_tab$Parameter <- rownames(aov_tab)
+    aov_tab$Sum_Squares <- aov_tab$`Sum Sq`
+    aov_tab$df <- aov_tab$`num Df`
+    aov_tab <- aov_tab[c(""Parameter"", ""Sum_Squares"",""Error.SS"", ""df"", ""den.Df"")]
 
     id <- attr(model, ""id"")
 

---FILE: R/print.effectsize_table.R---
@@ -155,6 +155,7 @@ print.effectsize_difference <- function(x, digits = 2, append_CL = FALSE, ...) {
 
 
 #' @export
+#' @importFrom utils as.roman
 print.effectsize_anova <- function(x, digits = 2, ...) {
   x_orig <- x
 
@@ -165,7 +166,7 @@ print.effectsize_anova <- function(x, digits = 2, ...) {
   if (is.null(anova_type) || is.na(anova_type)) {
     caption <- ""# Effect Size for ANOVA""
   } else {
-    caption <- paste0(""# Effect Size for ANOVA (Type "", as.roman(anova_type), "")"")
+    caption <- paste0(""# Effect Size for ANOVA (Type "", utils::as.roman(anova_type), "")"")
   }
   caption <- c(caption, ""blue"")
 

---FILE: R/sd_pooled.R---
@@ -61,7 +61,7 @@ mad_pooled <- function(x, y = NULL, data = NULL, constant = 1.4826, verbose = TR
 
 
 
-#' @importFrom stats mad sd as.formula
+#' @importFrom stats mad sd as.formula ave
 .sd_pooled <- function(x, y = NULL, data = NULL, robust = FALSE, verbose = TRUE, constant = 1) {
 
   # Activate here for evaluation of arguments...
@@ -87,8 +87,8 @@ mad_pooled <- function(x, y = NULL, data = NULL, constant = 1.4826, verbose = TR
   }
 
   div(c(
-    x - ave(x, FUN = center),
-    y - ave(y, FUN = center)
+    x - stats::ave(x, FUN = center),
+    y - stats::ave(y, FUN = center)
   )) * f
 }
 ",True,False,Dependency / Package,6
easystats,effectsize,ee8a5121e4bf6fbd6584350686a3726b6e86ee16,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-21T04:48:52Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-21T04:48:52Z,fix gam and rms::ols with new anova printing,R/eta_squared.R;tests/testthat/test-eta_squared_etc.R,False,True,True,False,55,16,71,"---FILE: R/eta_squared.R---
@@ -1019,21 +1019,27 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
 
   model <- stats::anova(model)
 
-  tab <- data.frame(model$s.table)
+  p.table <- as.data.frame(model$pTerms.table)
+  s.table <- as.data.frame(model$s.table)
+  colnames(s.table)[colnames(s.table)==""Ref.df""] <- ""df""
+  s.table[setdiff(colnames(p.table), colnames(s.table))] <- NA
+  p.table[setdiff(colnames(s.table), colnames(p.table))] <- NA
+  tab <- rbind(p.table, s.table)
+  colnames(tab)[colnames(tab)==""F""] <- ""F-value""
+  colnames(tab)[colnames(tab)==""df""] <- ""npar""
+  tab$df_error <- model$residual.df
 
-  out <- cbind(
-    Parameter = rownames(tab),
-    es_fun(
-      f = tab$`F`,
-      df = tab$Ref.df,
-      df_error = model$residual.df,
-      ci = ci
+  out <-
+    .anova_es.anova(
+      tab,
+      type = type,
+      generalized = generalized,
+      partial = partial,
+      ci = ci,
+      verbose = verbose
     )
-  )
 
-  attr(out, ""ci"") <- ci
-  attr(out, ""partial"") <- partial
-  attr(out, ""generalized"") <- generalized
+  attr(out, ""anova_type"") <- 3
   out
 }
 
@@ -1144,9 +1150,9 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
                           verbose = TRUE,
                           ...) {
   if (!inherits(model, ""anova.rms"")) {
-    model <- stats::anova(model)
+    model <- stats::anova(model, test = ""F"")
   }
-
+  i <- rownames(model)
   model <- as.data.frame(model)
 
   colnames(model) <- gsub(""F"", ""F value"", colnames(model), fixed = TRUE)
@@ -1155,7 +1161,10 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
 
   model <- model[rownames(model) != ""ERROR"", ]
 
-  .anova_es.anova(model, type = type, partial = partial, generalized = generalized, ci = ci, ...)
+  out <- .anova_es.anova(model, type = type, partial = partial, generalized = generalized, ci = ci, ...)
+  out$Parameter <- i[match(make.names(i), out$Parameter, nomatch = 0)]
+  attr(out, ""anova_type"") <- 2
+  out
 }
 
 .anova_es.anova.rms <- .anova_es.rms

---FILE: tests/testthat/test-eta_squared_etc.R---
@@ -410,8 +410,9 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(resE1[[2]][1], resA1[[5]][1], tolerance = 0.01)
   })
 
+  # Special cases --------------------------------------------------------------
 
-  # tidymodels --------------------------------------------------------------
+  ## tidymodels -------------------
   test_that(""ets_squared | tidymodels"", {
     skip_on_cran()
     skip_if_not_installed(""tidymodels"")
@@ -430,4 +431,33 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     expect_equal(tidy_lm, lm_lm, tolerance = 0.001)
   })
+
+
+  ## GAMs -------------------
+  test_that(""ets_squared | gam"", {
+    skip_on_cran()
+    skip_if_not_installed(""mgcv"")
+
+    set.seed(2) ## simulate some data...
+    dat <- mgcv::gamSim(1, n = 400, dist = ""normal"", scale = 2)
+    b <- mgcv::gam(y ~ x0 + s(x1) + s(x2) + t2(x1, x2) + s(x3), data = dat)
+
+    expect_error(out <- eta_squared(b), regexp = NA)
+    expect_output(print(out), ""Type III"")
+  })
+
+  ## rms -------------------
+  test_that(""ets_squared | rms"", {
+    skip_on_cran()
+    skip_if_not_installed(""rms"")
+
+    b <- rms::ols(mpg ~ cyl + am, data = mtcars)
+    expect_error(out <- eta_squared(b), regexp = NA)
+    expect_output(print(out), ""Type II"")
+
+    skip_if_not_installed(""car"")
+    b_lm <- car::Anova(lm(mpg ~ cyl + am, data = mtcars), type = 2)
+    out_lm <- eta_squared(b_lm)
+    expect_equal(out[1:2, ], out_lm)
+  })
 }",True,False,Implementation / Logic,6
easystats,effectsize,f148c37c17f384cf03dddd4a8bf4509fa5b6999f,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-20T14:16:06Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-20T14:16:06Z,fix row order in afex effect size,R/eta_squared.R;tests/testthat/test-eta_squared_etc.R,False,True,True,False,25,8,33,"---FILE: R/eta_squared.R---
@@ -1047,8 +1047,13 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
                                include_intercept = FALSE,
                                ...) {
   type <- match.arg(type)
-  if (type == ""eta"" && isTRUE(generalized))
-    generalized <- attr(model$anova_table, ""observed"")
+  if (type == ""eta"" && isTRUE(generalized)) {
+    if (length(attr(model$anova_table, ""observed""))) {
+      generalized <- attr(model$anova_table, ""observed"")
+    } else {
+      generalized <- names(c(attr(model, ""between""),attr(model, ""within"")))
+    }
+  }
 
   # For completely between, covers all
   if (!inherits(model$Anova, ""Anova.mlm"")) {
@@ -1117,6 +1122,12 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
     out$Group <- NULL
   }
 
+  # Reorder rows
+  orig_terms <- rownames(model$anova_table)
+  if (include_intercept && !""(Intercept)"" %in% orig_terms) {
+    orig_terms <- c(""(Intercept)"", orig_terms)
+  }
+  out <- out[match(out$Parameter, orig_terms),]
   attr(out, ""anova_type"") <- attr(model, ""type"", exact = TRUE)
   out
 }

---FILE: tests/testthat/test-eta_squared_etc.R---
@@ -303,19 +303,25 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     data(obk.long, package = ""afex"")
 
-    mod <- afex::aov_ez(""id"", ""value"", obk.long, between = c(""treatment"", ""gender""),
+    mod <- afex::aov_ez(""id"", ""value"", obk.long,
+                        between = c(""treatment"", ""gender""),
                         within = c(""phase"", ""hour""),
-                        observed = ""gender"",
-                        anova_table = list(correction = ""none""))
+                        observed = ""gender"")
 
     x <- eta_squared(mod, generalized = TRUE)
-    a <- anova(mod)
-    r <- cor(a$ges[order(rownames(a))], x$Eta2_generalized[order(x$Parameter)])
+    a <- anova(mod, observed = ""gender"")
+    r <- cor(a$ges, x$Eta2_generalized)
     expect_equal(r, 1, tolerance = 0.005)
 
     x <- eta_squared(mod)
     a <- anova(mod, es = ""pes"")
-    r <- cor(a$pes[order(rownames(a))], x$Eta2_partial[order(x$Parameter)])
+    r <- cor(a$pes, x$Eta2_partial)
+    expect_equal(r, 1, tolerance = 0.005)
+
+
+    x <- eta_squared(mod, include_intercept = TRUE)
+    a <- anova(mod, es = ""pes"", intercept = TRUE)
+    r <- cor(a$pes, x$Eta2_partial)
     expect_equal(r, 1, tolerance = 0.005)
   })
 ",True,False,Implementation / Logic,6
easystats,effectsize,4bf9a39f38736ff04dfd1eced262165b1ae9afaa,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-20T07:02:18Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-20T07:02:18Z,"fix: ets_squared, tidymodels test",tests/testthat/test-eta_squared_etc.R,False,True,True,False,3,20,23,"---FILE: tests/testthat/test-eta_squared_etc.R---
@@ -418,26 +418,9 @@ if (require(""testthat"") && require(""effectsize"")) {
       fit(mpg ~ am + vs, data = mtcars)
 
     set.seed(123)
-    df_lm <- as.data.frame(eta_squared(mod_lm, ci = 0.95))
+    tidy_lm <- eta_squared(mod_lm)
+    lm_lm <- eta_squared(lm(mpg ~ am + vs, data = mtcars))
 
-    expect_equal(
-      df_lm,
-      structure(
-        list(
-          Parameter = c(""am"", ""vs""),
-          Eta2_partial = c(0.534050980382337, 0.509657899929074),
-          CI = c(0.95, 0.95),
-          CI_low = c(0.270477566572333, 0.242410781810851),
-          CI_high = c(0.698019260414593, 0.681154789342689)
-        ),
-        class = ""data.frame"",
-        row.names = 1:2,
-        partial = TRUE,
-        generalized = FALSE,
-        ci = 0.95,
-        ci_method = list(method = ""ncp"", distribution = ""F"")
-      ),
-      tolerance = 0.001
-    )
+    expect_equal(tidy_lm, lm_lm, tolerance = 0.001)
   })
 }",True,False,Dependency / Package,3
easystats,effectsize,f8cf301069b9a77b8b5ace121179e61fa600bbaa,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-12T10:13:01Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-12T10:13:01Z,fix: tests,tests/testthat/test-eta_squared_etc.R;tests/testthat/test-standardize-models.R,False,True,True,False,3,2,5,"---FILE: tests/testthat/test-eta_squared_etc.R---
@@ -432,7 +432,7 @@ if (require(""testthat"") && require(""effectsize"")) {
         partial = TRUE,
         generalized = FALSE,
         ci = 0.95,
-        ci_method = list(method = ""ncp"", distribution = ""t"")
+        ci_method = list(method = ""ncp"", distribution = ""F"")
       ),
       tolerance = 0.001
     )

---FILE: tests/testthat/test-standardize-models.R---
@@ -163,7 +163,8 @@ if (require(""testthat"") && require(""effectsize"")) {
   # variables evaluated in the environment $$$ ------------------------------
   test_that(""variables evaluated in the environment"", {
     m <- lm(mtcars$mpg ~ mtcars$cyl + am, data = mtcars)
-    expect_warning(standardize(m), ""mtcars$mpg"", fixed = TRUE)
+    w <- testthat::capture_warnings(standardize(m))
+    expect_match(w[1], ""mtcars$mpg"", fixed = TRUE)
 
     skip_if(packageVersion(""base"") == package_version(3.4))
     ## Note:",True,False,Implementation / Logic,6
easystats,effectsize,bd26c42a0df5f9cf9a91bf3ee89583c86671f91c,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-12T05:56:23Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-12T05:56:23Z,"Use log for correction

#317",R/cohens_d.R,False,True,True,False,1,5,6,"---FILE: R/cohens_d.R---
@@ -297,11 +297,7 @@ glass_delta <- function(x,
 
 
   if (type == ""g"") {
-    J <- gamma(df / 2) / (sqrt(df / 2) * gamma((df - 1) / 2)) # exact method
-    if (is.na(J) || is.nan(J) || is.infinite(J)) J <- 1
-
-    # J <- 1 - 3 / (4 * df - 1) # orig method
-    # J <- ((n - 3) / (n - 2.25)) * sqrt((n - 2) / n) # McGrath & Meyer (2006)
+    J <- exp(lgamma(df / 2) - log(sqrt(df / 2)) - lgamma((df - 1) / 2)) # exact method
 
     out[, colnames(out) %in% c(""Hedges_g"", ""CI_low"", ""CI_high"")] <-
       out[, colnames(out) %in% c(""Hedges_g"", ""CI_low"", ""CI_high"")] * J",True,False,Implementation / Logic,6
easystats,effectsize,3e037f3d4da78bdf0ea4802d1e0ed3eb199c7a91,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-11T06:00:18Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-11T06:00:18Z,fix equation rendering + undoc `convert_*()` functions,NAMESPACE;R/convert_chisq.R;R/convert_d_to_common_language.R;R/convert_d_to_r.R;R/convert_odds_to_probs.R;R/convert_tF_to_anova.R;R/eta_squared.R;R/sd_pooled.R;man/F_to_eta2.Rd;man/chisq_to_phi.Rd;man/d_to_common_language.Rd;man/d_to_r.Rd;man/eta_squared.Rd;man/odds_to_probs.Rd;man/sd_pooled.Rd,False,True,True,False,97,106,203,"---FILE: NAMESPACE---
@@ -98,6 +98,8 @@ export(convert_d_to_common_language)
 export(convert_d_to_odds)
 export(convert_d_to_oddsratio)
 export(convert_d_to_r)
+export(convert_logoddsratio_to_d)
+export(convert_logoddsratio_to_r)
 export(convert_odds_to_d)
 export(convert_odds_to_probs)
 export(convert_odds_to_r)

---FILE: R/convert_chisq.R---
@@ -1,11 +1,10 @@
 #' Conversion Chi-Squared to Phi or Cramer's V
 #'
-#' Convert between Chi square, (\eqn{\chi^2}), Cramer's V, phi (\eqn{\phi}) and
+#' Convert between Chi square \eqn{(\chi^2)}{}, Cramer's V, phi (\eqn{\phi}) and
 #' Cohen's *w* for contingency tables or goodness of fit.
 #'
 #' @param chisq The Chi-squared statistic.
-#' @param phi The Phi statistic.
-#' @param n Sample size.
+#' @param n Total sample size.
 #' @param nrow,ncol The number of rows/columns in the contingency table (ignored
 #'   for Phi when `adjust=FALSE` and `CI=NULL`).
 #' @param ci Confidence Interval (CI) level
@@ -17,9 +16,9 @@
 #'
 #' @details These functions use the following formulae:
 #' \cr
-#' \deqn{\phi = \sqrt{\chi^2 / n}}
+#' \deqn{\phi = \sqrt{\chi^2 / n}}{phi = sqrt(X^2 / n)}
 #' \cr
-#' \deqn{Cramer's V = \phi / \sqrt{min(nrow,ncol)-1}}
+#' \deqn{Cramer's V = \phi / \sqrt{min(nrow,ncol)-1}}{Cramer's V = Phi / sqrt(min(nrow,ncol)-1)}
 #' \cr
 #' For adjusted versions, see Bergsma, 2013.
 #'
@@ -178,6 +177,7 @@ chisq_to_cramers_v <- function(chisq, n, nrow, ncol, ci = 0.95, adjust = FALSE,
 # Reverse -----------------------------------------------------------------
 
 #' @rdname chisq_to_phi
+#' @param phi The Phi statistic.
 #' @export
 phi_to_chisq <- function(phi, n, ...) {
   n * (phi^2)

---FILE: R/convert_d_to_common_language.R---
@@ -4,11 +4,11 @@
 #'
 #' @details
 #' This function use the following formulae:
-#' \deqn{Cohen's U_3 = \Phi(d)}
+#' \deqn{Cohen's U_3 = \Phi(d)}{U3 = pnorm(d)}
 #' \cr\cr
-#' \deqn{Overlap = 2 \times \Phi(-|d|/2)}
+#' \deqn{Overlap = 2 \times \Phi(-|d|/2)}{Overlap = 2 * pnorm(-abs(d) / 2)}
 #' \cr\cr
-#' \deqn{Pr(superiority) = \Phi(d/\sqrt{2})}
+#' \deqn{Pr(superiority) = \Phi(d/\sqrt{2})}{Pr(superiority) = pnorm(d / sqrt(2))}
 #'
 #' @return A list of `Cohen's U3`, `Overlap`, `Probability of superiority`.
 #'
@@ -31,6 +31,7 @@
 #' to base rates and other factors. Psychological methods, 13(1), 19â30.
 #'
 #' @export
+#' @aliases convert_d_to_common_language
 #' @importFrom stats pnorm
 d_to_common_language <- function(d) {
   list(
@@ -41,5 +42,4 @@ d_to_common_language <- function(d) {
 }
 
 #' @export
-#' @rdname d_to_common_language
 convert_d_to_common_language <- d_to_common_language

---FILE: R/convert_d_to_r.R---
@@ -25,11 +25,11 @@
 #' @return Converted index.
 #'
 #' @details
-#' Conversions between *OR* and *r* is done through these formulae.
-#' - *d to r*: \eqn{d = \frac{2 * r}{\sqrt{1 - r^2}}}
-#' - *r to d*: \eqn{r = \frac{d}{\sqrt{d^2 + 4}}}
-#' - *OR to d*: \eqn{d = \frac{\log(OR)\times\sqrt{3}}{\pi}}
-#' - *d to OR*: \eqn{log(OR) = d * \frac{\pi}{\sqrt(3)}}
+#' Conversions between *d* and *OR* or *r* is done through these formulae.
+#' - \eqn{d = \frac{2 * r}{\sqrt{1 - r^2}}}{d = 2 * r / sqrt(1 - r^2)}
+#' - \eqn{r = \frac{d}{\sqrt{d^2 + 4}}}{r = d / sqrt(d^2 + 4)}
+#' - \eqn{d = \frac{\log(OR)\times\sqrt{3}}{\pi}}{d = log(OR) * sqrt(3) / pi}
+#' - \eqn{log(OR) = d * \frac{\pi}{\sqrt(3)}}{log(OR) = d * pi / sqrt(3)}
 #'
 #' The conversion from *d* to *r* assumes equally sized groups. The resulting
 #' *r* is also called the binomial effect size display (BESD; Rosenthal et al.,
@@ -44,38 +44,38 @@
 #' (2009). Converting among effect sizes. Introduction to meta-analysis, 45-49.
 #'
 #' - Rosenthal, R., & Rubin, D. B. (1982). A simple, general purpose display of
-#' magnitude of experimental effect. Journal of educational psychology, 74(2),
-#' 166.
+#' magnitude of experimental effect. Journal of educational psychology, 74(2), 166.
 #'
 #' @export
+#' @aliases convert_d_to_r
 d_to_r <- function(d, ...) {
   d / (sqrt(d^2 + 4))
 }
 
-
-#' @rdname d_to_r
 #' @export
-r_to_d <- function(r, ...) {
-  2 * r / sqrt(1 - r^2)
-}
+convert_d_to_r <- d_to_r
+
+
+
 
 
 
 #' @rdname d_to_r
+#' @aliases convert_r_to_d
 #' @export
-convert_d_to_r <- d_to_r
+r_to_d <- function(r, ...) {
+  2 * r / sqrt(1 - r^2)
+}
 
-#' @rdname d_to_r
 #' @export
 convert_r_to_d <- r_to_d
 
 
 
 # OR - d ----------------------------------------------------------------
 
-
-
 #' @rdname d_to_r
+#' @aliases convert_oddsratio_to_d
 #' @export
 oddsratio_to_d <- function(OR, log = FALSE, ...) {
   if (log) {
@@ -87,19 +87,25 @@ oddsratio_to_d <- function(OR, log = FALSE, ...) {
   log_OR * (sqrt(3) / pi)
 }
 
-#' @rdname d_to_r
 #' @export
 convert_oddsratio_to_d <- oddsratio_to_d
 
+
+
 #' @rdname d_to_r
+#' @aliases convert_logoddsratio_to_d
 #' @export
 logoddsratio_to_d <- function(OR, log = TRUE, ...) {
   oddsratio_to_d(OR, log = log, ...)
 }
 
+#' @export
+convert_logoddsratio_to_d <- logoddsratio_to_d
+
 
 
 #' @rdname d_to_r
+#' @aliases convert_d_to_oddsratio
 #' @export
 d_to_oddsratio <- function(d, log = FALSE, ...) {
   log_OR <- d * pi / sqrt(3)
@@ -111,7 +117,6 @@ d_to_oddsratio <- function(d, log = FALSE, ...) {
   }
 }
 
-#' @rdname d_to_r
 #' @export
 convert_d_to_oddsratio <- d_to_oddsratio
 
@@ -121,29 +126,33 @@ convert_d_to_oddsratio <- d_to_oddsratio
 # OR - r ----------------------------------------------------------------
 
 #' @rdname d_to_r
+#' @aliases convert_oddsratio_to_r
 #' @export
 oddsratio_to_r <- function(OR, log = FALSE, ...) {
   d_to_r(oddsratio_to_d(OR, log = log))
 }
 
-#' @rdname d_to_r
 #' @export
 convert_oddsratio_to_r <- oddsratio_to_r
 
 #' @rdname d_to_r
+#' @aliases convert_logoddsratio_to_r
 #' @export
 logoddsratio_to_r <- function(OR, log = TRUE, ...) {
   oddsratio_to_r(OR, log = log, ...)
 }
 
+#' @export
+convert_logoddsratio_to_r <- logoddsratio_to_r
+
 
 
 #' @rdname d_to_r
+#' @aliases convert_r_to_oddsratio
 #' @export
 r_to_oddsratio <- function(r, log = FALSE, ...) {
   d_to_oddsratio(r_to_d(r), log = log)
 }
 
-#' @rdname d_to_r
 #' @export
 convert_r_to_oddsratio <- r_to_oddsratio

---FILE: R/convert_odds_to_probs.R---
@@ -21,10 +21,15 @@
 #' probs_to_odds(0.95)
 #' probs_to_odds(0.95, log = TRUE)
 #' @export
+#' @aliases convert_odds_to_probs
 odds_to_probs <- function(odds, log = FALSE, ...) {
   UseMethod(""odds_to_probs"")
 }
 
+#' @export
+convert_odds_to_probs <- odds_to_probs
+
+
 #' @export
 #' @importFrom stats plogis
 odds_to_probs.numeric <- function(odds, log = FALSE, ...) {
@@ -44,11 +49,15 @@ odds_to_probs.data.frame <- function(odds, log = FALSE, select = NULL, exclude =
 
 
 #' @rdname odds_to_probs
+#' @aliases convert_probs_to_odds
 #' @export
 probs_to_odds <- function(probs, log = FALSE, ...) {
   UseMethod(""probs_to_odds"")
 }
 
+#' @export
+convert_probs_to_odds <- probs_to_odds
+
 #' @export
 #' @importFrom stats qlogis
 probs_to_odds.numeric <- function(probs, log = FALSE, ...) {
@@ -66,18 +75,6 @@ probs_to_odds.data.frame <- function(probs, log = FALSE, select = NULL, exclude
 }
 
 
-#' @rdname odds_to_probs
-#' @export
-convert_odds_to_probs <- odds_to_probs
-
-#' @rdname odds_to_probs
-#' @export
-convert_probs_to_odds <- probs_to_odds
-
-
-
-
-
 
 
 

---FILE: R/convert_tF_to_anova.R---
@@ -2,8 +2,8 @@
 #' (**partial** Eta / Omega / Epsilon squared and Cohen's f)
 #'
 #' These functions are convenience functions to convert F and t test statistics
-#' to **partial** Eta squared, (\eqn{\eta{_p}^2}), Omega squared
-#' (\eqn{\omega{_p}^2}), Epsilon squared (\eqn{\epsilon{_p}^2}; an alias for the
+#' to **partial** Eta squared \eqn{(\eta{_p}^2)}{}, Omega squared
+#' \eqn{(\omega{_p}^2)}{}, Epsilon squared (\eqn{\epsilon{_p}^2;}{} an alias for the
 #' adjusted Eta squared) and Cohen's f. These are useful in cases where the
 #' various Sum of Squares and Mean Squares are not easily available or their
 #' computation is not straightforward (e.g., in liner mixed models, contrasts,
@@ -22,21 +22,21 @@
 #' @return A data frame with the effect size(s) between 0-1 (`Eta2_partial`,
 #'   `Epsilon2_partial`, `Omega2_partial`, `Cohens_f_partial` or
 #'   `Cohens_f2_partial`), and their CIs (`CI_low` and `CI_high`). (Note that
-#'   for \eqn{\omega_p^2} and \eqn{\epsilon_p^2} it is possible to compute a
+#'   for \eqn{\omega_p^2}{Omega2p} and \eqn{\epsilon_p^2}{Epsilon2p} it is possible to compute a
 #'   negative number; even though this doesn't make any practical sense, it is
 #'   recommended to report the negative number and not a 0).
 #'
 #' @details These functions use the following formulae:
 #' \cr
-#' \deqn{\eta_p^2 = \frac{F \times df_{num}}{F \times df_{num} + df_{den}}}
+#' \deqn{\eta_p^2 = \frac{F \times df_{num}}{F \times df_{num} + df_{den}}}{Eta2p = F * df1 / (F * df1 + df2)}
 #' \cr
-#' \deqn{\epsilon_p^2 = \frac{(F - 1) \times df_{num}}{F \times df_{num} + df_{den}}}
+#' \deqn{\epsilon_p^2 = \frac{(F - 1) \times df_{num}}{F \times df_{num} + df_{den}}}{Epsilon2p = (F - 1) * df1 / (F * df1 + df2)}
 #' \cr
-#' \deqn{\omega_p^2 = \frac{(F - 1) \times df_{num}}{F \times df_{num} + df_{den} + 1}}
+#' \deqn{\omega_p^2 = \frac{(F - 1) \times df_{num}}{F \times df_{num} + df_{den} + 1}}{Omega2p=(F - 1) * df1 / (F * df1 + df2 + 1)}
 #' \cr
-#' \deqn{f_p = \sqrt{\frac{\eta_p^2}{1-\eta_p^2}}}
+#' \deqn{f_p = \sqrt{\frac{\eta_p^2}{1-\eta_p^2}}}{f = Eta2 / (1 - Eta2)}
 #' \cr\cr
-#' For \eqn{t}, the conversion is based on the equality of \eqn{t^2 = F} when \eqn{df_{num}=1}.
+#' For \eqn{t}, the conversion is based on the equality of \eqn{t^2 = F} when \eqn{df_{num}=1}{df1 = 1}.
 #'
 #' ## Choosing an Un-Biased Estimate
 #' Both Omega and Epsilon are unbiased estimators of the population Eta. But
@@ -49,7 +49,7 @@
 #' @inheritSection effectsize-CIs Confidence Intervals
 #' @inheritSection effectsize-CIs CI Contains Zero
 #'
-#' @note \eqn{Adj. \eta_p^2} is an alias for \eqn{\epsilon_p^2}.
+#' @note \eqn{Adj. \eta_p^2}{adjusted (partial) Eta squared} is an alias for \eqn{\epsilon_p^2}{partial) Epsilon squared}.
 #'
 #' @seealso [eta_squared()] for more details.
 #' @family effect size from test statistic

---FILE: R/eta_squared.R---
@@ -63,9 +63,10 @@
 #' analogous to adjusted R2 (Allen, 2017, p. 382), and has been found to be less
 #' biased (Carroll & Nordholm, 1975).
 #' \cr\cr
-#' (Note that for \eqn{\omega_p^2} and \eqn{\epsilon_p^2} it is possible to
-#' compute a negative number; even though this doesn't make any practical sense,
-#' it is recommended to report the negative number and not a 0.)
+#' (Note that for \eqn{\omega_p^2}{Omega2p} and \eqn{\epsilon_p^2}{Epsilon2p} it
+#' is possible to compute a negative number; even though this doesn't make any
+#' practical sense, it is recommended to report the negative number and not a
+#' 0.)
 #'
 #' ## Cohen's f
 #' Cohen's f can take on values between zero, when the population means are all

---FILE: R/sd_pooled.R---
@@ -9,9 +9,9 @@
 #'
 #' @details
 #' The standard version is calculated as:
-#' \deqn{\sqrt{\frac{\Sum (x_i - \bar{x})^2}{n_1 + n_2 - 2}}}{sqrt(sum(c(x - mean(x), y - mean(y))^2) / (n1 + n2 - 2))}
+#' \deqn{\sqrt{\frac{\sum (x_i - \bar{x})^2}{n_1 + n_2 - 2}}}{sqrt(sum(c(x - mean(x), y - mean(y))^2) / (n1 + n2 - 2))}
 #' The robust version is calculated as:
-#' \deqn{1.4826 \times MAD {x - Median_x; y - Median_y}}{mad(c(x - median(x), y - median(y)), constant = 1.4826)}
+#' \deqn{1.4826 \times Median(|\left\{x - Median_x,\,y - Median_y\right\}|)}{mad(c(x - median(x), y - median(y)), constant = 1.4826)}
 #'
 #' @return Numeric, the pooled standard deviation.
 #'

---FILE: man/F_to_eta2.Rd---
@@ -56,14 +56,14 @@ t_to_f2(t, df_error, ci = 0.9, squared = TRUE, ...)
 A data frame with the effect size(s) between 0-1 (\code{Eta2_partial},
 \code{Epsilon2_partial}, \code{Omega2_partial}, \code{Cohens_f_partial} or
 \code{Cohens_f2_partial}), and their CIs (\code{CI_low} and \code{CI_high}). (Note that
-for \eqn{\omega_p^2} and \eqn{\epsilon_p^2} it is possible to compute a
+for \eqn{\omega_p^2}{Omega2p} and \eqn{\epsilon_p^2}{Epsilon2p} it is possible to compute a
 negative number; even though this doesn't make any practical sense, it is
 recommended to report the negative number and not a 0).
 }
 \description{
 These functions are convenience functions to convert F and t test statistics
-to \strong{partial} Eta squared, (\eqn{\eta{_p}^2}), Omega squared
-(\eqn{\omega{_p}^2}), Epsilon squared (\eqn{\epsilon{_p}^2}; an alias for the
+to \strong{partial} Eta squared \eqn{(\eta{_p}^2)}{}, Omega squared
+\eqn{(\omega{_p}^2)}{}, Epsilon squared (\eqn{\epsilon{_p}^2;}{} an alias for the
 adjusted Eta squared) and Cohen's f. These are useful in cases where the
 various Sum of Squares and Mean Squares are not easily available or their
 computation is not straightforward (e.g., in liner mixed models, contrasts,
@@ -76,15 +76,15 @@ See \href{https://easystats.github.io/effectsize/articles/from_test_statistics.h
 \details{
 These functions use the following formulae:
 \cr
-\deqn{\eta_p^2 = \frac{F \times df_{num}}{F \times df_{num} + df_{den}}}
+\deqn{\eta_p^2 = \frac{F \times df_{num}}{F \times df_{num} + df_{den}}}{Eta2p = F * df1 / (F * df1 + df2)}
 \cr
-\deqn{\epsilon_p^2 = \frac{(F - 1) \times df_{num}}{F \times df_{num} + df_{den}}}
+\deqn{\epsilon_p^2 = \frac{(F - 1) \times df_{num}}{F \times df_{num} + df_{den}}}{Epsilon2p = (F - 1) * df1 / (F * df1 + df2)}
 \cr
-\deqn{\omega_p^2 = \frac{(F - 1) \times df_{num}}{F \times df_{num} + df_{den} + 1}}
+\deqn{\omega_p^2 = \frac{(F - 1) \times df_{num}}{F \times df_{num} + df_{den} + 1}}{Omega2p=(F - 1) * df1 / (F * df1 + df2 + 1)}
 \cr
-\deqn{f_p = \sqrt{\frac{\eta_p^2}{1-\eta_p^2}}}
+\deqn{f_p = \sqrt{\frac{\eta_p^2}{1-\eta_p^2}}}{f = Eta2 / (1 - Eta2)}
 \cr\cr
-For \eqn{t}, the conversion is based on the equality of \eqn{t^2 = F} when \eqn{df_{num}=1}.
+For \eqn{t}, the conversion is based on the equality of \eqn{t^2 = F} when \eqn{df_{num}=1}{df1 = 1}.
 \subsection{Choosing an Un-Biased Estimate}{
 
 Both Omega and Epsilon are unbiased estimators of the population Eta. But
@@ -98,7 +98,7 @@ designs.
 }
 }
 \note{
-\eqn{Adj. \eta_p^2} is an alias for \eqn{\epsilon_p^2}.
+\eqn{Adj. \eta_p^2}{adjusted (partial) Eta squared} is an alias for \eqn{\epsilon_p^2}{partial) Epsilon squared}.
 }
 \section{Confidence Intervals}{
 

---FILE: man/chisq_to_phi.Rd---
@@ -18,7 +18,7 @@ phi_to_chisq(phi, n, ...)
 \arguments{
 \item{chisq}{The Chi-squared statistic.}
 
-\item{n}{Sample size.}
+\item{n}{Total sample size.}
 
 \item{nrow, ncol}{The number of rows/columns in the contingency table (ignored
 for Phi when \code{adjust=FALSE} and \code{CI=NULL}).}
@@ -36,15 +36,15 @@ A data frame with the effect size(s) between 0-1, and confidence
 interval(s). See \code{\link[=cramers_v]{cramers_v()}}.
 }
 \description{
-Convert between Chi square, (\eqn{\chi^2}), Cramer's V, phi (\eqn{\phi}) and
+Convert between Chi square \eqn{(\chi^2)}{}, Cramer's V, phi (\eqn{\phi}) and
 Cohen's \emph{w} for contingency tables or goodness of fit.
 }
 \details{
 These functions use the following formulae:
 \cr
-\deqn{\phi = \sqrt{\chi^2 / n}}
+\deqn{\phi = \sqrt{\chi^2 / n}}{phi = sqrt(X^2 / n)}
 \cr
-\deqn{Cramer's V = \phi / \sqrt{min(nrow,ncol)-1}}
+\deqn{Cramer's V = \phi / \sqrt{min(nrow,ncol)-1}}{Cramer's V = Phi / sqrt(min(nrow,ncol)-1)}
 \cr
 For adjusted versions, see Bergsma, 2013.
 }

---FILE: man/d_to_common_language.Rd---
@@ -6,8 +6,6 @@
 \title{Convert Standardized Mean Difference to Common Language Effect Sizes}
 \usage{
 d_to_common_language(d)
-
-convert_d_to_common_language(d)
 }
 \arguments{
 \item{d}{Standardized difference value (Cohen's d).}
@@ -20,11 +18,11 @@ Convert Standardized Mean Difference to Common Language Effect Sizes
 }
 \details{
 This function use the following formulae:
-\deqn{Cohen's U_3 = \Phi(d)}
+\deqn{Cohen's U_3 = \Phi(d)}{U3 = pnorm(d)}
 \cr\cr
-\deqn{Overlap = 2 \times \Phi(-|d|/2)}
+\deqn{Overlap = 2 \times \Phi(-|d|/2)}{Overlap = 2 * pnorm(-abs(d) / 2)}
 \cr\cr
-\deqn{Pr(superiority) = \Phi(d/\sqrt{2})}
+\deqn{Pr(superiority) = \Phi(d/\sqrt{2})}{Pr(superiority) = pnorm(d / sqrt(2))}
 }
 \note{
 These calculations assume that the populations have equal variance and are

---FILE: man/d_to_r.Rd---
@@ -12,17 +12,19 @@
 \alias{logodds_to_d}
 \alias{convert_odds_to_d}
 \alias{odds_to_d}
-\alias{r_to_d}
 \alias{convert_d_to_r}
+\alias{r_to_d}
 \alias{convert_r_to_d}
 \alias{oddsratio_to_d}
 \alias{convert_oddsratio_to_d}
 \alias{logoddsratio_to_d}
+\alias{convert_logoddsratio_to_d}
 \alias{d_to_oddsratio}
 \alias{convert_d_to_oddsratio}
 \alias{oddsratio_to_r}
 \alias{convert_oddsratio_to_r}
 \alias{logoddsratio_to_r}
+\alias{convert_logoddsratio_to_r}
 \alias{r_to_oddsratio}
 \alias{convert_r_to_oddsratio}
 \title{Convert between \emph{d}, \emph{r} and \emph{Odds ratio}}
@@ -31,29 +33,17 @@ d_to_r(d, ...)
 
 r_to_d(r, ...)
 
-convert_d_to_r(d, ...)
-
-convert_r_to_d(r, ...)
-
 oddsratio_to_d(OR, log = FALSE, ...)
 
-convert_oddsratio_to_d(OR, log = FALSE, ...)
-
 logoddsratio_to_d(OR, log = TRUE, ...)
 
 d_to_oddsratio(d, log = FALSE, ...)
 
-convert_d_to_oddsratio(d, log = FALSE, ...)
-
 oddsratio_to_r(OR, log = FALSE, ...)
 
-convert_oddsratio_to_r(OR, log = FALSE, ...)
-
 logoddsratio_to_r(OR, log = TRUE, ...)
 
 r_to_oddsratio(r, log = FALSE, ...)
-
-convert_r_to_oddsratio(r, log = FALSE, ...)
 }
 \arguments{
 \item{d}{Standardized difference value (Cohen's d).}
@@ -74,12 +64,12 @@ Enables a conversion between different indices of effect size, such as
 standardized difference (Cohen's d), correlation r or (log) odds ratios.
 }
 \details{
-Conversions between \emph{OR} and \emph{r} is done through these formulae.
+Conversions between \emph{d} and \emph{OR} or \emph{r} is done through these formulae.
 \itemize{
-\item \emph{d to r}: \eqn{d = \frac{2 * r}{\sqrt{1 - r^2}}}
-\item \emph{r to d}: \eqn{r = \frac{d}{\sqrt{d^2 + 4}}}
-\item \emph{OR to d}: \eqn{d = \frac{\log(OR)\times\sqrt{3}}{\pi}}
-\item \emph{d to OR}: \eqn{log(OR) = d * \frac{\pi}{\sqrt(3)}}
+\item \eqn{d = \frac{2 * r}{\sqrt{1 - r^2}}}{d = 2 * r / sqrt(1 - r^2)}
+\item \eqn{r = \frac{d}{\sqrt{d^2 + 4}}}{r = d / sqrt(d^2 + 4)}
+\item \eqn{d = \frac{\log(OR)\times\sqrt{3}}{\pi}}{d = log(OR) * sqrt(3) / pi}
+\item \eqn{log(OR) = d * \frac{\pi}{\sqrt(3)}}{log(OR) = d * pi / sqrt(3)}
 }
 
 The conversion from \emph{d} to \emph{r} assumes equally sized groups. The resulting
@@ -103,10 +93,7 @@ methods, 8(4), 448.
 \item Borenstein, M., Hedges, L. V., Higgins, J. P. T., & Rothstein, H. R.
 (2009). Converting among effect sizes. Introduction to meta-analysis, 45-49.
 \item Rosenthal, R., & Rubin, D. B. (1982). A simple, general purpose display of
-magnitude of experimental effect. Journal of educational psychology, 74(2),
-}
-\enumerate{
-\item 
+magnitude of experimental effect. Journal of educational psychology, 74(2), 166.
 }
 }
 \seealso{

---FILE: man/eta_squared.Rd---
@@ -140,9 +140,10 @@ Though Omega is the more popular choice (Albers \& Lakens, 2018), Epsilon is
 analogous to adjusted R2 (Allen, 2017, p. 382), and has been found to be less
 biased (Carroll & Nordholm, 1975).
 \cr\cr
-(Note that for \eqn{\omega_p^2} and \eqn{\epsilon_p^2} it is possible to
-compute a negative number; even though this doesn't make any practical sense,
-it is recommended to report the negative number and not a 0.)
+(Note that for \eqn{\omega_p^2}{Omega2p} and \eqn{\epsilon_p^2}{Epsilon2p} it
+is possible to compute a negative number; even though this doesn't make any
+practical sense, it is recommended to report the negative number and not a
+0.)
 }
 
 \subsection{Cohen's f}{

---FILE: man/odds_to_probs.Rd---
@@ -2,11 +2,11 @@
 % Please edit documentation in R/convert_odds_to_probs.R
 \name{odds_to_probs}
 \alias{odds_to_probs}
+\alias{convert_odds_to_probs}
 \alias{odds_to_probs.data.frame}
 \alias{probs_to_odds}
-\alias{probs_to_odds.data.frame}
-\alias{convert_odds_to_probs}
 \alias{convert_probs_to_odds}
+\alias{probs_to_odds.data.frame}
 \title{Convert between Odds and Probabilities}
 \usage{
 odds_to_probs(odds, log = FALSE, ...)
@@ -16,10 +16,6 @@ odds_to_probs(odds, log = FALSE, ...)
 probs_to_odds(probs, log = FALSE, ...)
 
 \method{probs_to_odds}{data.frame}(probs, log = FALSE, select = NULL, exclude = NULL, ...)
-
-convert_odds_to_probs(odds, log = FALSE, ...)
-
-convert_probs_to_odds(probs, log = FALSE, ...)
 }
 \arguments{
 \item{odds}{The \emph{Odds} (or \code{log(odds)} when \code{log = TRUE}) to convert.}

---FILE: man/sd_pooled.Rd---
@@ -31,9 +31,9 @@ common deviation among the groups, around each of their respective means.
 }
 \details{
 The standard version is calculated as:
-\deqn{\sqrt{\frac{\Sum (x_i - \bar{x})^2}{n_1 + n_2 - 2}}}{sqrt(sum(c(x - mean(x), y - mean(y))^2) / (n1 + n2 - 2))}
+\deqn{\sqrt{\frac{\sum (x_i - \bar{x})^2}{n_1 + n_2 - 2}}}{sqrt(sum(c(x - mean(x), y - mean(y))^2) / (n1 + n2 - 2))}
 The robust version is calculated as:
-\deqn{1.4826 \times MAD {x - Median_x; y - Median_y}}{mad(c(x - median(x), y - median(y)), constant = 1.4826)}
+\deqn{1.4826 \times Median(|\left\{x - Median_x,\,y - Median_y\right\}|)}{mad(c(x - median(x), y - median(y)), constant = 1.4826)}
 }
 \examples{
 sd_pooled(mpg ~ am, data = mtcars)",True,False,Documentation / Formatting,6
easystats,effectsize,2f5ddf647b72d87a2076d41680700589cee4fe9e,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-11T05:18:38Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-11T05:18:38Z,remove correction type when printing g,R/cohens_d.R;R/print.effectsize_table.R;man/cohens_d.Rd;tests/testthat/test-printing.R,False,True,True,False,11,17,28,"---FILE: R/cohens_d.R---
@@ -6,10 +6,11 @@
 #' \cr\cr
 #' Both Cohen's *d* and Hedges' *g* are the estimated the standardized
 #' difference between the means of two populations. Hedges' *g* provides a bias
-#' correction to Cohen's *d* for small sample sizes. For sample sizes > 20, the
-#' results for both statistics are roughly equivalent. Glassâs *delta* is
-#' appropriate when the standard deviations are significantly different between
-#' the populations, as it uses only the *second* group's standard deviation.
+#' correction (using the exact method) to Cohen's *d* for small sample sizes.
+#' For sample sizes > 20, the results for both statistics are roughly
+#' equivalent. Glassâs *delta* is appropriate when the standard deviations are
+#' significantly different between the populations, as it uses only the *second*
+#' group's standard deviation.
 #'
 #' @param x A formula, a numeric vector, or a character name of one in `data`.
 #' @param y A numeric vector, a grouping (character / factor) vector, a or a
@@ -309,7 +310,7 @@ glass_delta <- function(x,
 
   class(out) <- c(""effectsize_difference"", ""effectsize_table"", ""see_effectsize_table"", class(out))
   attr(out, ""paired"") <- paired
-  attr(out, ""correction"") <- type == ""g""
+  attr(out, ""correction"") <- type == ""g"" # Don't actually need this
   attr(out, ""pooled_sd"") <- pooled_sd
   attr(out, ""mu"") <- mu
   attr(out, ""ci"") <- ci

---FILE: R/print.effectsize_table.R---
@@ -129,11 +129,6 @@ print.effectsize_difference <- function(x, digits = 2, append_CL = FALSE, ...) {
     footer <- c(footer, list(c(sd_type, ""cyan"")))
   }
 
-  if (any(colnames(x) == ""Hedges_g"")) {
-    correction <- ""\n- Bias corrected using exact method.""
-    footer <- c(footer, list(c(correction, ""cyan"")))
-  }
-
   attr(x, ""table_footer"") <- footer
   attr(x, ""table_caption"") <- caption
   attr(x, ""table_subtitle"") <- subtitle

---FILE: man/cohens_d.Rd---
@@ -79,10 +79,11 @@ estimate.)
 \cr\cr
 Both Cohen's \emph{d} and Hedges' \emph{g} are the estimated the standardized
 difference between the means of two populations. Hedges' \emph{g} provides a bias
-correction to Cohen's \emph{d} for small sample sizes. For sample sizes > 20, the
-results for both statistics are roughly equivalent. Glassâs \emph{delta} is
-appropriate when the standard deviations are significantly different between
-the populations, as it uses only the \emph{second} group's standard deviation.
+correction (using the exact method) to Cohen's \emph{d} for small sample sizes.
+For sample sizes > 20, the results for both statistics are roughly
+equivalent. Glassâs \emph{delta} is appropriate when the standard deviations are
+significantly different between the populations, as it uses only the \emph{second}
+group's standard deviation.
 }
 \details{
 Set \code{pooled_sd = FALSE} for effect sizes that are to accompany a Welch's

---FILE: tests/testthat/test-printing.R---
@@ -39,9 +39,6 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     d <- cohens_d(1:5, c(1, 1:4), paired = TRUE)
     expect_error(expect_output(print(d), regexp = ""pooled""))
-
-    d <- hedges_g(1:3, c(1, 1:3))
-    expect_output(print(d), regexp = ""exact method"")
   })
 
   test_that(""equivalence test effectsize"", {",True,False,Documentation / Formatting,6
easystats,effectsize,ce0f556ae3700adc203dec939a092b3a493a630b,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-09T08:46:40Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-09T08:46:40Z,fix: comment out Pair example in cohens_d,R/cohens_d.R;man/cohens_d.Rd,False,True,True,False,4,2,6,"---FILE: R/cohens_d.R---
@@ -58,7 +58,8 @@
 #' glass_delta(sleep$extra, sleep$group)
 #' hedges_g(""extra"", ""group"", data = sleep)
 #' cohens_d(sleep$extra[sleep$group == 1], sleep$extra[sleep$group == 2], paired = TRUE)
-#' cohens_d(stats::Pair(extra[group == 1], extra[group == 2]) ~ 1, data = sleep, paired = TRUE)
+#' # cohens_d(Pair(extra[group == 1], extra[group == 2]) ~ 1,
+#' #          data = sleep, paired = TRUE)
 #'
 #' # one-sample tests -----------------------
 #'

---FILE: man/cohens_d.Rd---
@@ -142,7 +142,8 @@ print(cohens_d(mpg ~ am, data = mtcars), append_CL = TRUE)
 glass_delta(sleep$extra, sleep$group)
 hedges_g(""extra"", ""group"", data = sleep)
 cohens_d(sleep$extra[sleep$group == 1], sleep$extra[sleep$group == 2], paired = TRUE)
-cohens_d(stats::Pair(extra[group == 1], extra[group == 2]) ~ 1, data = sleep, paired = TRUE)
+# cohens_d(Pair(extra[group == 1], extra[group == 2]) ~ 1,
+#          data = sleep, paired = TRUE)
 
 # one-sample tests -----------------------
 ",True,False,Documentation / Formatting,6
easystats,effectsize,b752b087d93ed5c05556d1e57da8476b0ab56abd,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-09T08:34:11Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-09T08:34:11Z,"fix: CI on GH

Undefined global functions or variables:
    correction

could not find function ""Pair""",R/cohens_d.R;man/cohens_d.Rd,False,True,True,False,3,3,6,"---FILE: R/cohens_d.R---
@@ -58,7 +58,7 @@
 #' glass_delta(sleep$extra, sleep$group)
 #' hedges_g(""extra"", ""group"", data = sleep)
 #' cohens_d(sleep$extra[sleep$group == 1], sleep$extra[sleep$group == 2], paired = TRUE)
-#' cohens_d(Pair(extra[group == 1], extra[group == 2]) ~ 1, data = sleep, paired = TRUE)
+#' cohens_d(stats::Pair(extra[group == 1], extra[group == 2]) ~ 1, data = sleep, paired = TRUE)
 #'
 #' # one-sample tests -----------------------
 #'
@@ -105,7 +105,7 @@ cohens_d <- function(x,
     if (!grepl(""t-test"", x$method)) {
       stop(""'x' is not a t-test!"", call. = FALSE)
     }
-    return(effectsize(x, type = ""d"", correction = correction, ci = ci, verbose = verbose))
+    return(effectsize(x, type = ""d"", ci = ci, verbose = verbose))
   } else if (inherits(x, ""BFBayesFactor"")) {
     if (!inherits(x@numerator[[1]], c(""BFoneSample"", ""BFindepSample""))) {
       stop(""'x' is not a t-test!"", call. = FALSE)

---FILE: man/cohens_d.Rd---
@@ -142,7 +142,7 @@ print(cohens_d(mpg ~ am, data = mtcars), append_CL = TRUE)
 glass_delta(sleep$extra, sleep$group)
 hedges_g(""extra"", ""group"", data = sleep)
 cohens_d(sleep$extra[sleep$group == 1], sleep$extra[sleep$group == 2], paired = TRUE)
-cohens_d(Pair(extra[group == 1], extra[group == 2]) ~ 1, data = sleep, paired = TRUE)
+cohens_d(stats::Pair(extra[group == 1], extra[group == 2]) ~ 1, data = sleep, paired = TRUE)
 
 # one-sample tests -----------------------
 ",True,False,Documentation / Formatting,6
easystats,effectsize,38f65dbb8f1aa0515cc72ba2f3eba099d50cdb0f,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-09T07:49:00Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-09T07:49:00Z,fix: re-add iterations to rankES docs,R/rank_effectsizes.R;man/rank_biserial.Rd,False,True,True,False,4,1,5,"---FILE: R/rank_effectsizes.R---
@@ -20,6 +20,8 @@
 #' @param mu a number indicating the value around which (a-)symmetry (for
 #'   one-sample or paired samples) or shift (for independent samples) is to be
 #'   estimated. See [stats::wilcox.test].
+#' @param iterations The number of bootstrap replicates for computing confidence
+#'   intervals. Only applies when `ci` is not `NULL`.
 #'
 #' @details
 #' The rank-biserial correlation is appropriate for non-parametric tests of

---FILE: man/rank_biserial.Rd---
@@ -66,7 +66,8 @@ estimated. See \link[stats:wilcox.test]{stats::wilcox.test}.}
 
 \item{ci}{Confidence Interval (CI) level}
 
-\item{iterations}{deprecated.}
+\item{iterations}{The number of bootstrap replicates for computing confidence
+intervals. Only applies when \code{ci} is not \code{NULL}.}
 
 \item{paired}{If \code{TRUE}, the values of \code{x} and \code{y} are considered as paired.
 This produces an effect size that is equivalent to the one-sample effect",True,False,Documentation / Formatting,7
easystats,effectsize,52d0a907bea150f316aba9369f4e0d33868a57d5,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-09T07:35:25Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-09T07:35:25Z,fix: Duplicated iterations arg in cohens_d docs,R/cohens_d.R;man/cohens_d.Rd,False,True,True,False,28,31,59,"---FILE: R/cohens_d.R---
@@ -128,7 +128,6 @@ cohens_d <- function(x,
 }
 
 #' @rdname cohens_d
-#' @param iterations The number of bootstrap replicates for computing confidence intervals. Only applies when \code{ci} is not \code{NULL}.
 #' @export
 hedges_g <- function(x,
                      y = NULL,
@@ -402,31 +401,31 @@ glass_delta <- function(x,
   list(x = x, y = y)
 }
 
-.delta_ci <- function(x, y, mu = 0, ci = 0.95, iterations = 200) {
-  boot_delta <- function(data, .i, mu = 0) {
-    .x <- sample(x, replace = TRUE)
-    .y <- sample(y, replace = TRUE)
-
-    d <- mean(.x) - mean(.y)
-    s <- stats::sd(.y)
-    (d - mu) / s
-  }
-
-  # dud, not actually used
-  data <- data.frame(
-    i = seq_along(c(x, y))
-  )
-
-  R <- boot::boot(
-    data = data,
-    statistic = boot_delta,
-    R = iterations,
-    mu = mu
-  )
-
-  out <- as.data.frame(
-    bayestestR::ci(na.omit(R$t), ci = ci, verbose = FALSE)
-  )
-  out$CI <- ci
-  out
-}
+# .delta_ci <- function(x, y, mu = 0, ci = 0.95, iterations = 200) {
+#   boot_delta <- function(data, .i, mu = 0) {
+#     .x <- sample(x, replace = TRUE)
+#     .y <- sample(y, replace = TRUE)
+#
+#     d <- mean(.x) - mean(.y)
+#     s <- stats::sd(.y)
+#     (d - mu) / s
+#   }
+#
+#   # dud, not actually used
+#   data <- data.frame(
+#     i = seq_along(c(x, y))
+#   )
+#
+#   R <- boot::boot(
+#     data = data,
+#     statistic = boot_delta,
+#     R = iterations,
+#     mu = mu
+#   )
+#
+#   out <- as.data.frame(
+#     bayestestR::ci(na.omit(R$t), ci = ci, verbose = FALSE)
+#   )
+#   out$CI <- ci
+#   out
+# }

---FILE: man/cohens_d.Rd---
@@ -67,8 +67,6 @@ size on \code{x - y}.}
 \item{...}{Arguments passed to or from other methods.}
 
 \item{iterations, correction}{deprecated.}
-
-\item{iterations}{The number of bootstrap replicates for computing confidence intervals. Only applies when \code{ci} is not \code{NULL}.}
 }
 \value{
 A data frame with the effect size ( \code{Cohens_d}, \code{Hedges_g},",True,False,Documentation / Formatting,7
easystats,effectsize,70f5d1c29a210f34ef61966c66fbd94540ecc54f,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-09T07:23:40Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-09T07:23:40Z,fix: parametric CI for Glass' delta,NEWS.md;R/cohens_d.R;man/cohens_d.Rd;man/rank_biserial.Rd;tests/testthat/test-standardized_differences.R,False,True,True,False,58,64,122,"---FILE: NEWS.md---
@@ -2,7 +2,8 @@
 
 ## New features
 
-- `hedges_g()` now used exact bias correction (thanks to @mdelacre for the suggestion!)
+- `hedges_g()` now used exact bias correction (thanks to @mdelacre for the suggestion!)  
+- `glass_delta()` now estimates CIs using the NCP method based on Algina et al (2006).
 
 ## Bug fixes
 

---FILE: R/cohens_d.R---
@@ -15,15 +15,12 @@
 #' @param y A numeric vector, a grouping (character / factor) vector, a or a
 #'   character  name of one in `data`. Ignored if `x` is a formula.
 #' @param data An optional data frame containing the variables.
-#' @param correction Type of small sample bias correction to apply to produce
-#'   Hedges' *g*. Can be `1` for Hedges and Olkin's original correction
-#'   (default) or `2` for Hunter and Schmidt's correction (see McGrath & Meyer,
-#'   2006).
 #' @param pooled_sd If `TRUE` (default), a [sd_pooled()] is used (assuming equal
 #'   variance). Else the mean SD from both groups is used instead.
 #' @param paired If `TRUE`, the values of `x` and `y` are considered as paired.
 #'   This produces an effect size that is equivalent to the one-sample effect
 #'   size on `x - y`.
+#' @param iterations,correction deprecated.
 #' @inheritParams chisq_to_phi
 #' @inheritParams eta_squared
 #' @inheritParams stats::t.test
@@ -33,10 +30,8 @@
 #'   applying Bessel's correction).
 #'
 #' @details
-#'
-#' ## Confidence Intervals for Glass' *delta*
-#' Confidence Intervals for Glass' *delta* are estimated using the bootstrap
-#' method.
+#' Set `pooled_sd = FALSE` for effect sizes that are to accompany a Welch's
+#' *t*-test (Delacre et al, 2021).
 #'
 #' @inheritSection effectsize-CIs Confidence Intervals
 #' @inheritSection effectsize-CIs CI Contains Zero
@@ -56,13 +51,14 @@
 #' cohens_d(mpg ~ am, data = mtcars, pooled_sd = FALSE)
 #' cohens_d(mpg ~ am, data = mtcars, mu = -5)
 #' hedges_g(mpg ~ am, data = mtcars)
-#' if (require(boot)) glass_delta(mpg ~ am, data = mtcars)
+#' glass_delta(mpg ~ am, data = mtcars)
 #' print(cohens_d(mpg ~ am, data = mtcars), append_CL = TRUE)
 #'
 #' # other acceptable ways to specify arguments
-#' cohens_d(sleep$extra, sleep$group)
+#' glass_delta(sleep$extra, sleep$group)
 #' hedges_g(""extra"", ""group"", data = sleep)
 #' cohens_d(sleep$extra[sleep$group == 1], sleep$extra[sleep$group == 2], paired = TRUE)
+#' cohens_d(Pair(extra[group == 1], extra[group == 2]) ~ 1, data = sleep, paired = TRUE)
 #'
 #' # one-sample tests -----------------------
 #'
@@ -75,19 +71,25 @@
 #' d_to_common_language(0.4)
 #' interpret_g(0.4, rules = ""sawilowsky2009"")
 #' interpret_delta(0.4, rules = ""gignac2016"")
+#'
 #' @references
+#' - Algina, J., Keselman, H. J., & Penfield, R. D. (2006). Confidence intervals
+#' for an effect size when variances are not equal. Journal of Modern Applied
+#' Statistical Methods, 5(1), 2.
+#'
 #' - Cohen, J. (1988). Statistical power analysis for the behavioral
 #' sciences (2nd Ed.). New York: Routledge.
 #'
+#' - Delacre, M., Lakens, D., Ley, C., Liu, L., & Leys, C. (2021, May 7). Why
+#' Hedgesâ g*s based on the non-pooled standard deviation should be reported
+#' with Welchâs t-test. https://doi.org/10.31234/osf.io/tu6mp
+#'
 #' - Hedges, L. V. & Olkin, I. (1985). Statistical methods for
 #' meta-analysis. Orlando, FL: Academic Press.
 #'
 #' - Hunter, J. E., & Schmidt, F. L. (2004). Methods of meta-analysis:
 #' Correcting error and bias in research findings. Sage.
 #'
-#' - McGrath, R. E., & Meyer, G. J. (2006). When effect sizes disagree: the
-#' case of r and d. Psychological methods, 11(4), 386.
-#'
 #' @importFrom stats var model.frame
 #' @export
 cohens_d <- function(x,
@@ -176,18 +178,23 @@ glass_delta <- function(x,
                         data = NULL,
                         mu = 0,
                         ci = 0.95,
-                        iterations = 200,
                         verbose = TRUE,
-                        ...) {
+                        ...,
+                        iterations) {
+  if (!missing(iterations)) {
+    warning(""`iterations` argument is deprecated. Parametric CIs are estimated."",
+            call. = FALSE, immediate. = TRUE
+    )
+  }
+
   .effect_size_difference(
     x,
     y = y,
     data = data,
     mu = mu,
     type = ""delta"",
     ci = ci,
-    verbose = verbose,
-    iterations = iterations
+    verbose = verbose
   )
 }
 
@@ -204,7 +211,6 @@ glass_delta <- function(x,
                                     paired = FALSE,
                                     ci = 0.95,
                                     verbose = TRUE,
-                                    iterations = NULL,
                                     ...) {
   out <- .deal_with_cohens_d_arguments(x, y, data, verbose)
   x <- out$x
@@ -238,32 +244,34 @@ glass_delta <- function(x,
     y <- stats::na.omit(y)
 
     d <- mean(x) - mean(y)
+
+    s1 <- stats::sd(x)
+    s2 <- stats::sd(y)
+
     n1 <- length(x)
     n2 <- length(y)
     n <- n1 + n2
 
     if (type %in% c(""d"", ""g"")) {
       if (pooled_sd) {
         s <- suppressWarnings(sd_pooled(x, y))
-
         hn <- (1 / n1 + 1 / n2)
         se <- s * sqrt(1 / n1 + 1 / n2)
         df <- n - 2
       } else {
-        s1 <- stats::sd(x)
-        s2 <- stats::sd(y)
         s <- sqrt((s1^2 + s2^2) / 2)
-
+        hn <- (2 * (n2 * s1 ^ 2 + n1 * s2 ^ 2)) / (n1 * n2 * (s1 ^ 2 + s2 ^ 2))
         se1 <- sqrt(s1^2 / n1)
         se2 <- sqrt(s2^2 / n2)
-
-        hn <- (2 * (n2 * s1 ^ 2 + n1 * s2 ^ 2)) / (n1 * n2 * (s1 ^ 2 + s2 ^ 2))
         se <- sqrt(se1^2 + se2^2)
         df <- se^4 / (se1^4 / (n1 - 1) + se2^4 / (n2 - 1))
       }
     } else if (type == ""delta"") {
       pooled_sd <- NULL
       s <- stats::sd(y)
+      hn <- 1 / n2 + s1 ^ 2 / (n1 * s2 ^ 2)
+      se <- (s2 * sqrt(1 / n2 + s1 ^ 2 / (n1 * s2 ^ 2)))
+      df <- n2 - 1
     }
   }
 
@@ -276,24 +284,14 @@ glass_delta <- function(x,
     stopifnot(length(ci) == 1, ci < 1, ci > 0)
 
     # Add cis
-    if (type %in% c(""d"", ""g"")) {
-      out$CI <- ci
+    out$CI <- ci
 
-      t <- (d - mu) / se
-      ts <- .get_ncp_t(t, df, ci)
+    t <- (d - mu) / se
+    ts <- .get_ncp_t(t, df, ci)
 
-      out$CI_low <- ts[1] * sqrt(hn)
-      out$CI_high <- ts[2] * sqrt(hn)
-      ci_method <- list(method = ""ncp"", distribution = ""t"")
-    } else if (type == ""delta"") {
-      if (requireNamespace(""boot"", quietly = TRUE)) {
-        out <- cbind(out, .delta_ci(x, y, mu = mu, ci = ci, ...))
-        ci_method <- list(method = ""bootstrap"", iterations = iterations)
-      } else {
-        ci <- NULL
-        warning(""'boot' package required for estimating CIs for Glass' delta. Please install the package and try again."", call. = FALSE)
-      }
-    }
+    out$CI_low <- ts[1] * sqrt(hn)
+    out$CI_high <- ts[2] * sqrt(hn)
+    ci_method <- list(method = ""ncp"", distribution = ""t"")
   }
 
 

---FILE: man/cohens_d.Rd---
@@ -37,9 +37,9 @@ glass_delta(
   data = NULL,
   mu = 0,
   ci = 0.95,
-  iterations = 200,
   verbose = TRUE,
-  ...
+  ...,
+  iterations
 )
 }
 \arguments{
@@ -66,10 +66,7 @@ size on \code{x - y}.}
 
 \item{...}{Arguments passed to or from other methods.}
 
-\item{correction}{Type of small sample bias correction to apply to produce
-Hedges' \emph{g}. Can be \code{1} for Hedges and Olkin's original correction
-(default) or \code{2} for Hunter and Schmidt's correction (see McGrath & Meyer,
-2006).}
+\item{iterations, correction}{deprecated.}
 
 \item{iterations}{The number of bootstrap replicates for computing confidence intervals. Only applies when \code{ci} is not \code{NULL}.}
 }
@@ -90,11 +87,8 @@ appropriate when the standard deviations are significantly different between
 the populations, as it uses only the \emph{second} group's standard deviation.
 }
 \details{
-\subsection{Confidence Intervals for Glass' \emph{delta}}{
-
-Confidence Intervals for Glass' \emph{delta} are estimated using the bootstrap
-method.
-}
+Set \code{pooled_sd = FALSE} for effect sizes that are to accompany a Welch's
+\emph{t}-test (Delacre et al, 2021).
 }
 \note{
 The indices here give the population estimated standardized difference.
@@ -143,13 +137,14 @@ cohens_d(mpg ~ am, data = mtcars)
 cohens_d(mpg ~ am, data = mtcars, pooled_sd = FALSE)
 cohens_d(mpg ~ am, data = mtcars, mu = -5)
 hedges_g(mpg ~ am, data = mtcars)
-if (require(boot)) glass_delta(mpg ~ am, data = mtcars)
+glass_delta(mpg ~ am, data = mtcars)
 print(cohens_d(mpg ~ am, data = mtcars), append_CL = TRUE)
 
 # other acceptable ways to specify arguments
-cohens_d(sleep$extra, sleep$group)
+glass_delta(sleep$extra, sleep$group)
 hedges_g(""extra"", ""group"", data = sleep)
 cohens_d(sleep$extra[sleep$group == 1], sleep$extra[sleep$group == 2], paired = TRUE)
+cohens_d(Pair(extra[group == 1], extra[group == 2]) ~ 1, data = sleep, paired = TRUE)
 
 # one-sample tests -----------------------
 
@@ -162,17 +157,22 @@ interpret_d(0.4, rules = ""cohen1988"")
 d_to_common_language(0.4)
 interpret_g(0.4, rules = ""sawilowsky2009"")
 interpret_delta(0.4, rules = ""gignac2016"")
+
 }
 \references{
 \itemize{
+\item Algina, J., Keselman, H. J., & Penfield, R. D. (2006). Confidence intervals
+for an effect size when variances are not equal. Journal of Modern Applied
+Statistical Methods, 5(1), 2.
 \item Cohen, J. (1988). Statistical power analysis for the behavioral
 sciences (2nd Ed.). New York: Routledge.
+\item Delacre, M., Lakens, D., Ley, C., Liu, L., & Leys, C. (2021, May 7). Why
+Hedgesâ g*s based on the non-pooled standard deviation should be reported
+with Welchâs t-test. https://doi.org/10.31234/osf.io/tu6mp
 \item Hedges, L. V. & Olkin, I. (1985). Statistical methods for
 meta-analysis. Orlando, FL: Academic Press.
 \item Hunter, J. E., & Schmidt, F. L. (2004). Methods of meta-analysis:
 Correcting error and bias in research findings. Sage.
-\item McGrath, R. E., & Meyer, G. J. (2006). When effect sizes disagree: the
-case of r and d. Psychological methods, 11(4), 386.
 }
 }
 \seealso{

---FILE: man/rank_biserial.Rd---
@@ -66,7 +66,7 @@ estimated. See \link[stats:wilcox.test]{stats::wilcox.test}.}
 
 \item{ci}{Confidence Interval (CI) level}
 
-\item{iterations}{The number of bootstrap replicates for computing confidence intervals. Only applies when \code{ci} is not \code{NULL}.}
+\item{iterations}{deprecated.}
 
 \item{paired}{If \code{TRUE}, the values of \code{x} and \code{y} are considered as paired.
 This produces an effect size that is equivalent to the one-sample effect

---FILE: tests/testthat/test-standardized_differences.R---
@@ -84,18 +84,13 @@ if (require(""testthat"") && require(""effectsize"")) {
   test_that(""glass_delta"", {
     # must be 2 samples
     expect_error(glass_delta(1:10))
-
-    skip_if_not_installed(""boot"")
-    skip_if_not_installed(""base"", minimum_version = ""3.6.0"")
-
     expect_error(glass_delta(wt, data = mtcars))
 
-    set.seed(8007)
     x <- glass_delta(wt ~ am, data = mtcars)
     expect_equal(colnames(x)[1], ""Glass_delta"")
     expect_equal(x[[1]], 2.200, tolerance = 0.001)
-    expect_equal(x$CI_low, 1.490089, tolerance = 0.001)
-    expect_equal(x$CI_high, 3.858925, tolerance = 0.001)
+    expect_equal(x$CI_low, 1.008664, tolerance = 0.001)
+    expect_equal(x$CI_high, 3.352597, tolerance = 0.001)
   })
 
 ",True,False,Documentation / Formatting,6
easystats,effectsize,127a5ba22273bfeff1564e194a054da7d45ba0cc,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-09T05:39:02Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-09T05:39:02Z,fix: harmonic n for unequal var,NEWS.md;R/cohens_d.R;tests/testthat/test-standardized_differences.R,False,True,True,False,9,3,12,"---FILE: NEWS.md---
@@ -4,6 +4,10 @@
 
 - `hedges_g()` now used exact bias correction (thanks to @mdelacre for the suggestion!)
 
+## Bug fixes
+
+- `cohens_d()` / `hedges_g()` minor fix for CI with unequal variances.
+
 # effectsize 0.4.4-1
 
 ## New features

---FILE: R/cohens_d.R---
@@ -243,10 +243,10 @@ glass_delta <- function(x,
     n <- n1 + n2
 
     if (type %in% c(""d"", ""g"")) {
-      hn <- (1 / n1 + 1 / n2)
       if (pooled_sd) {
         s <- suppressWarnings(sd_pooled(x, y))
 
+        hn <- (1 / n1 + 1 / n2)
         se <- s * sqrt(1 / n1 + 1 / n2)
         df <- n - 2
       } else {
@@ -256,6 +256,8 @@ glass_delta <- function(x,
 
         se1 <- sqrt(s1^2 / n1)
         se2 <- sqrt(s2^2 / n2)
+
+        hn <- (2 * (n2 * s1 ^ 2 + n1 * s2 ^ 2)) / (n1 * n2 * (s1 ^ 2 + s2 ^ 2))
         se <- sqrt(se1^2 + se2^2)
         df <- se^4 / (se1^4 / (n1 - 1) + se2^4 / (n2 - 1))
       }

---FILE: tests/testthat/test-standardized_differences.R---
@@ -69,8 +69,8 @@ if (require(""testthat"") && require(""effectsize"")) {
     x <- cohens_d(wt ~ am, data = mtcars, pooled_sd = FALSE)
     expect_equal(colnames(x)[1], ""Cohens_d"")
     expect_equal(x[[1]], 1.934, tolerance = 0.001)
-    expect_equal(x$CI_low, 1.098798, tolerance = 0.001)
-    expect_equal(x$CI_high, 2.833495, tolerance = 0.001)
+    expect_equal(x$CI_low, 1.075151, tolerance = 0.001)
+    expect_equal(x$CI_high, 2.772516, tolerance = 0.001)
   })
 
   test_that(""hedges_g (and other bias correction things"", {",True,False,Implementation / Logic,6
easystats,effectsize,10a2dff45dde1788ab087936a472ee3a4effb59a,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-09T05:26:18Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-09T05:26:18Z,fix: hedges g printing test,tests/testthat/test-printing.R,False,True,True,False,2,5,7,"---FILE: tests/testthat/test-printing.R---
@@ -40,11 +40,8 @@ if (require(""testthat"") && require(""effectsize"")) {
     d <- cohens_d(1:5, c(1, 1:4), paired = TRUE)
     expect_error(expect_output(print(d), regexp = ""pooled""))
 
-    d <- hedges_g(1:3, c(1, 1:3), correction = 1)
-    expect_output(print(d), regexp = ""Hedges and Olkin"")
-
-    d <- hedges_g(1:3, c(1, 1:3), correction = 2)
-    expect_output(print(d), regexp = ""Hunter and Schmidt"")
+    d <- hedges_g(1:3, c(1, 1:3))
+    expect_output(print(d), regexp = ""exact method"")
   })
 
   test_that(""equivalence test effectsize"", {",True,False,Dependency / Package,3
easystats,effectsize,3d0857cbf7ff8eb6512c65aa97ee148e6dbfa602,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-09T05:24:45Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-05-09T05:24:45Z,use exact bias correction method in Hedges g,NEWS.md;R/cohens_d.R;R/print.effectsize_table.R;man/cohens_d.Rd;tests/testthat/test-standardized_differences.R,False,True,True,False,24,59,83,"---FILE: NEWS.md---
@@ -1,3 +1,9 @@
+# effectsize 0.4.4-2
+
+## New features
+
+- `hedges_g()` now used exact bias correction (thanks to @mdelacre for the suggestion!)
+
 # effectsize 0.4.4-1
 
 ## New features

---FILE: R/cohens_d.R---
@@ -98,14 +98,7 @@ cohens_d <- function(x,
                      paired = FALSE,
                      ci = 0.95,
                      verbose = TRUE,
-                     ...,
-                     correction) {
-  if (!missing(correction)) {
-    warning(""`correction` argument is deprecated. To apply bias correction, use `hedges_g()`."",
-      call. = FALSE, immediate. = TRUE
-    )
-  }
-
+                     ...) {
   if (inherits(x, ""htest"")) {
     if (!grepl(""t-test"", x$method)) {
       stop(""'x' is not a t-test!"", call. = FALSE)
@@ -138,25 +131,24 @@ cohens_d <- function(x,
 hedges_g <- function(x,
                      y = NULL,
                      data = NULL,
-                     correction = 1,
                      pooled_sd = TRUE,
                      mu = 0,
                      paired = FALSE,
                      ci = 0.95,
                      verbose = TRUE,
-                     ...) {
-  if (isTRUE(correction) || !correction %in% c(1, 2)) {
-    warning(""`correction` must be 1 or 2. See ?hedges_g. Setting to 1 for Hedges & Olkin's correction."",
-      call. = FALSE, immediate. = TRUE
+                     ...,
+                     correction) {
+  if (!missing(correction)) {
+    warning(""`correction` argument is deprecated. *Exact* bias correction method is used."",
+            call. = FALSE, immediate. = TRUE
     )
-    correction <- 1
   }
 
   if (inherits(x, ""htest"")) {
     if (!grepl(""t-test"", x$method)) {
       stop(""'x' is not a t-test!"", call. = FALSE)
     }
-    return(effectsize(x, type = ""g"", correction = correction, ci = ci, verbose = verbose))
+    return(effectsize(x, type = ""g"", ci = ci, verbose = verbose))
   } else if (inherits(x, ""BFBayesFactor"")) {
     if (!inherits(x@numerator[[1]], c(""BFoneSample"", ""BFindepSample""))) {
       stop(""'x' is not a t-test!"", call. = FALSE)
@@ -169,7 +161,6 @@ hedges_g <- function(x,
     y = y,
     data = data,
     type = ""g"",
-    correction = correction,
     pooled_sd = pooled_sd,
     mu = mu,
     paired = paired,
@@ -187,14 +178,7 @@ glass_delta <- function(x,
                         ci = 0.95,
                         iterations = 200,
                         verbose = TRUE,
-                        ...,
-                        correction) {
-  if (!missing(correction)) {
-    warning(""`correction` argument is deprecated. To apply bias correction, use `hedges_g()`."",
-      call. = FALSE, immediate. = TRUE
-    )
-  }
-
+                        ...) {
   .effect_size_difference(
     x,
     y = y,
@@ -216,7 +200,6 @@ glass_delta <- function(x,
                                     data = NULL,
                                     type = ""d"",
                                     mu = 0,
-                                    correction = NULL,
                                     pooled_sd = TRUE,
                                     paired = FALSE,
                                     ci = 0.95,
@@ -313,24 +296,17 @@ glass_delta <- function(x,
 
 
   if (type == ""g"") {
-    if (correction == 1) {
-      if (paired) {
-        J <- 1 - 3 / (4 * (n - 1) - 1)
-      } else {
-        J <- 1 - 3 / (4 * n - 9)
-      }
-    } else if (correction == 2) {
-      # McGrath & Meyer (2006)
-      J <- ((n - 3) / (n - 2.25)) * sqrt((n - 2) / n)
-    }
+    J <- gamma(df / 2) / (sqrt(df / 2) * gamma((df - 1) / 2)) # exact method
+    # J <- 1 - 3 / (4 * df - 1) # orig method
+    # J <- ((n - 3) / (n - 2.25)) * sqrt((n - 2) / n) # McGrath & Meyer (2006)
 
     out[, colnames(out) %in% c(""Hedges_g"", ""CI_low"", ""CI_high"")] <-
       out[, colnames(out) %in% c(""Hedges_g"", ""CI_low"", ""CI_high"")] * J
   }
 
   class(out) <- c(""effectsize_difference"", ""effectsize_table"", ""see_effectsize_table"", class(out))
   attr(out, ""paired"") <- paired
-  attr(out, ""correction"") <- correction
+  attr(out, ""correction"") <- type == ""g""
   attr(out, ""pooled_sd"") <- pooled_sd
   attr(out, ""mu"") <- mu
   attr(out, ""ci"") <- ci

---FILE: R/print.effectsize_table.R---
@@ -130,15 +130,10 @@ print.effectsize_difference <- function(x, digits = 2, append_CL = FALSE, ...) {
   }
 
   if (any(colnames(x) == ""Hedges_g"")) {
-    correction <- sprintf(
-      ""\n- Bias corrected using %s method."",
-      ifelse(attr(x, ""correction"") == 1, ""Hedges and Olkin's"", ""Hunter and Schmidt's"")
-    )
-
+    correction <- ""\n- Bias corrected using exact method.""
     footer <- c(footer, list(c(correction, ""cyan"")))
   }
 
-
   attr(x, ""table_footer"") <- footer
   attr(x, ""table_caption"") <- caption
   attr(x, ""table_subtitle"") <- subtitle

---FILE: man/cohens_d.Rd---
@@ -15,21 +15,20 @@ cohens_d(
   paired = FALSE,
   ci = 0.95,
   verbose = TRUE,
-  ...,
-  correction
+  ...
 )
 
 hedges_g(
   x,
   y = NULL,
   data = NULL,
-  correction = 1,
   pooled_sd = TRUE,
   mu = 0,
   paired = FALSE,
   ci = 0.95,
   verbose = TRUE,
-  ...
+  ...,
+  correction
 )
 
 glass_delta(
@@ -40,8 +39,7 @@ glass_delta(
   ci = 0.95,
   iterations = 200,
   verbose = TRUE,
-  ...,
-  correction
+  ...
 )
 }
 \arguments{

---FILE: tests/testthat/test-standardized_differences.R---
@@ -74,21 +74,11 @@ if (require(""testthat"") && require(""effectsize"")) {
   })
 
   test_that(""hedges_g (and other bias correction things"", {
-    x <- hedges_g(wt ~ am, data = mtcars, correction = 1)
+    expect_warning(x <- hedges_g(wt ~ am, data = mtcars, correction = TRUE))
     expect_equal(colnames(x)[1], ""Hedges_g"")
     expect_equal(x[[1]], 1.844, tolerance = 0.001)
     expect_equal(x$CI_low, 1.004, tolerance = 0.001)
     expect_equal(x$CI_high, 2.664, tolerance = 0.001)
-
-    x <- hedges_g(wt ~ am, data = mtcars, correction = 2)
-    expect_equal(colnames(x)[1], ""Hedges_g"")
-    expect_equal(x[[1]], 1.786, tolerance = 0.001)
-    expect_equal(x$CI_low, 0.972, tolerance = 0.001)
-    expect_equal(x$CI_high, 2.579, tolerance = 0.001)
-
-    expect_warning(hedges_g(wt ~ am, data = mtcars, correction = TRUE))
-    expect_warning(cohens_d(wt ~ am, data = mtcars, correction = TRUE))
-    expect_warning(glass_delta(wt ~ am, data = mtcars, correction = TRUE, ci = NULL))
   })
 
   test_that(""glass_delta"", {",True,False,Documentation / Formatting,6
easystats,effectsize,eac019cd4cd41165f5176e37821292831aa59ea0,Daniel,mail@danielluedecke.de,2021-04-08T17:26:05Z,Daniel,mail@danielluedecke.de,2021-04-08T17:26:05Z,make sure only fixed part is returned for mixed models,R/standardize_parameters.R,False,True,True,False,1,1,2,"---FILE: R/standardize_parameters.R---
@@ -178,7 +178,7 @@ standardize_parameters.default <- function(model, method = ""refit"", ci = 0.95, r
 
   # need model_parameters to return the parameters, not the terms
   if (inherits(model, ""aov"")) class(model) <- class(model)[class(model) != ""aov""]
-  pars <- parameters::model_parameters(model, ci = ci, standardize = NULL, ...)
+  pars <- parameters::model_parameters(model, ci = ci, standardize = NULL, effects = ""fixed"", ...)
 
   # should post hoc exponentiate?
   dots <- list(...)",True,False,Implementation / Logic,6
easystats,effectsize,87303782cd0d15bec18ae424d123c9ff8a682eed,Indrajeet Patil,inderonline1988@gmail.com,2021-04-02T16:58:07Z,Indrajeet Patil,inderonline1988@gmail.com,2021-04-02T16:58:07Z,fix typo,R/eta_squared.R,False,True,True,False,2,2,4,"---FILE: R/eta_squared.R---
@@ -441,7 +441,7 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
     if (verbose) {
       txt_type <- ifelse(isTRUE(generalized) || is.character(generalized), ""generalized"", ""partial"")
       message(
-        ""For one-way between subjects designs, "", txt_type, "" "", type, "" squared is equvilant to "", type, "" squared.\n"",
+        ""For one-way between subjects designs, "", txt_type, "" "", type, "" squared is equivalent to "", type, "" squared.\n"",
         ""Returning "", type, "" squared.""
       )
     }
@@ -880,7 +880,7 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
   if (verbose && (partial || isTRUE(generalized) || is.character(generalized))) {
     txt_type <- ifelse(isTRUE(generalized) || is.character(generalized), ""generalized"", ""partial"")
     message(
-      ""For one-way between subjects designs, "", txt_type, "" "", type, "" squared is equvilant to "", type, "" squared.\n"",
+      ""For one-way between subjects designs, "", txt_type, "" "", type, "" squared is equivalent to "", type, "" squared.\n"",
       ""Returning "", type, "" squared.""
     )
   }",True,False,Implementation / Logic,3
easystats,effectsize,5da7068ff029d769c44b599f74db109978de29cb,mattansb,35330040+mattansb@users.noreply.github.com,2021-04-02T11:43:19Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-04-02T11:43:19Z,fix: test fails because of binding,tests/testthat/test-standardize_parameters.R,False,True,True,False,2,2,4,"---FILE: tests/testthat/test-standardize_parameters.R---
@@ -25,9 +25,9 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(s1$CI_low, s2$CI_low)
     expect_equal(s1$CI_high, s2$CI_high)
 
-    mpe <<- parameters::model_parameters(model, exponentiate = TRUE)
+    mp_exp <<- parameters::model_parameters(model, exponentiate = TRUE)
     se1 <- standardize_parameters(model, method = ""basic"", exponentiate = TRUE)
-    se2 <- standardize_parameters(mpe, method = ""basic"", exponentiate = TRUE)
+    se2 <- standardize_parameters(mp_exp, method = ""basic"", exponentiate = TRUE)
 
     expect_equal(se1$Parameter, se2$Parameter)
     expect_equal(se1$Std_Coefficient, se2$Std_Coefficient)",True,False,Dependency / Package,3
easystats,effectsize,13cdcaa7480212ce69341b10888a314b39764f2f,mattansb,35330040+mattansb@users.noreply.github.com,2021-03-29T14:48:24Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-03-29T14:48:24Z,fix: slight problem with mediation,NAMESPACE;R/standardize.models.R;R/standardize_parameters.R;tests/testthat/test-standardize-models.R,False,True,True,False,30,6,36,"---FILE: NAMESPACE---
@@ -65,6 +65,7 @@ S3method(standardize,wbm)
 S3method(standardize_parameters,bootstrap_model)
 S3method(standardize_parameters,bootstrap_parameters)
 S3method(standardize_parameters,default)
+S3method(standardize_parameters,mediate)
 S3method(standardize_parameters,parameters_model)
 S3method(unstandardize,array)
 S3method(unstandardize,data.frame)

---FILE: R/standardize.models.R---
@@ -363,9 +363,15 @@ standardize.wbgee <- standardize.wbm
 
 
 #' @keywords internal
-.no_response_standardize <- function(info) {
+.no_response_standardize <- function(info, verbose = TRUE) {
+  if (is.null(info)) {
+    if (verbose)
+      warning(""Unable to varify if response should not be standardized.\nResponse will be standardized."",
+              immediate. = TRUE, call. = FALSE)
+    return(FALSE)
+  }
   # check if model has a response variable that should not be standardized.
-  !info$is_linear | info$is_censored | info$family == ""inverse.gaussian""
+  !info$is_linear || info$is_censored || info$family == ""inverse.gaussian""
 
   ## TODO alternative would be to keep the below line for checking if no std possible
   ##      and then treat response for ""Gamma()"" or ""inverse.gaussian"" similar to log-terms

---FILE: R/standardize_parameters.R---
@@ -169,7 +169,7 @@ standardize_parameters.default <- function(model, method = ""refit"", ci = 0.95, r
   method <- match.arg(method, c(""refit"", ""posthoc"", ""smart"", ""basic"", ""classic"", ""pseudo""))
 
   m_info <- insight::model_info(model)
-  include_response <- include_response && !.no_response_standardize(m_info)
+  include_response <- include_response && !.no_response_standardize(m_info, verbose = verbose)
 
   if (method == ""refit"") {
     model <- standardize(model, robust = robust, two_sd = two_sd, verbose = verbose, include_response = include_response)
@@ -227,6 +227,14 @@ standardize_parameters.default <- function(model, method = ""refit"", ci = 0.95, r
   return(pars)
 }
 
+#' @export
+standardize_parameters.mediate <- function(model, method = ""refit"", ci = 0.95, robust = FALSE, two_sd = FALSE, include_response = TRUE, verbose = TRUE, ...) {
+  if (method != ""refit"")
+    warning(""Only method = 'refit' is supported for mediation models."", immediate. = TRUE)
+
+  NextMethod(""standardize_parameters"", method = ""refit"", ci = ci, robust = robust, two_sd = two_sd, include_response = include_response, verbose = verbose)
+}
+
 #' @export
 standardize_parameters.parameters_model <- function(model, method = ""refit"", ci = NULL, robust = FALSE, two_sd = FALSE, include_response = TRUE, verbose = TRUE, ...) {
   if (method == ""refit"") {
@@ -243,7 +251,7 @@ standardize_parameters.parameters_model <- function(model, method = ""refit"", ci
   if (is.null(model)) model <- attr(pars, ""object"")
 
   m_info <- insight::model_info(model)
-  include_response <- include_response && !.no_response_standardize(m_info)
+  include_response <- include_response && !.no_response_standardize(m_info, verbose = verbose)
 
   if (is.null(exponentiate <- attr(pars, ""exponentiate""))) exponentiate <- FALSE
   pars <- .standardize_parameters_posthoc(pars, method, model, robust, two_sd, exponentiate, include_response, verbose)
@@ -290,7 +298,7 @@ standardize_parameters.bootstrap_model <-
     model <- attr(pars, ""original_model"")
 
     m_info <- insight::model_info(model)
-    include_response <- include_response && !.no_response_standardize(m_info)
+    include_response <- include_response && !.no_response_standardize(m_info, verbose = verbose)
 
     if (method == ""refit"") {
       stop(""The 'refit' method is not supported for bootstrapped models."")
@@ -438,7 +446,7 @@ standardize_posteriors <- function(model, method = ""refit"", robust = FALSE, two_
   object_name <- deparse(substitute(model), width.cutoff = 500)
 
   m_info <- insight::model_info(model)
-  include_response <- include_response && !.no_response_standardize(m_info)
+  include_response <- include_response && !.no_response_standardize(m_info, verbose = verbose)
 
   if (method == ""refit"") {
     model <- standardize(model, robust = robust, two_sd = two_sd, include_response = include_response,

---FILE: tests/testthat/test-standardize-models.R---
@@ -192,5 +192,14 @@ if (require(""testthat"") && require(""effectsize"")) {
       unlist(out2[c(""d0"", ""d1"", ""z0"", ""z1"", ""n0"", ""n1"", ""tau.coef"")]),
       tolerance = 0.1
     )
+
+    med0 <- mediation::mediate(standardize(b.int), standardize(d.int), sims = 200, treat = ""treat"", mediator = ""job_seek"")
+    out0 <- summary(med0)
+    medz <- standardize(mediation::mediate(b.int, d.int, sims = 200, treat = ""treat"", mediator = ""job_seek""))
+    outz <- summary(medz)
+    expect_equal(unlist(out0[c(""d0"", ""d1"", ""z0"", ""z1"", ""n0"", ""n1"", ""tau.coef"")]),
+                 unlist(outz[c(""d0"", ""d1"", ""z0"", ""z1"", ""n0"", ""n1"", ""tau.coef"")]),
+                 tolerance = 0.1
+    )
   })
 }",True,False,Dependency / Package,6
easystats,effectsize,3be3a682143537673ab79bb82079999d371e38c6,mattansb,35330040+mattansb@users.noreply.github.com,2021-03-21T11:39:43Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-03-21T11:39:43Z,"fix: ""include_response | parameters"" test",tests/testthat/test-standardize_parameters.R,False,True,True,False,1,1,2,"---FILE: tests/testthat/test-standardize_parameters.R---
@@ -446,7 +446,7 @@ test_that(""include_response | parameters"", {
 
   data(iris)
   iris$Sepal.Length <- iris$Sepal.Length * 5
-  m <- lm(Sepal.Length ~ Petal.Length + Petal.Width, data = iris)
+  m <<- lm(Sepal.Length ~ Petal.Length + Petal.Width, data = iris)
 
   # parameters ---
   pars <- parameters::model_parameters(m)",True,False,Implementation / Logic,3
easystats,effectsize,9522ce2792676df2c5deb9f8c3a397e3142bca66,mattansb,35330040+mattansb@users.noreply.github.com,2021-03-19T19:27:42Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-03-19T19:27:42Z,"Fix: kendalls_w

@IndrajeetPatil Note if you were using this elsewhere, it was totally off.",NAMESPACE;NEWS.md;R/rank_effectsizes.R;man/rank_biserial.Rd;tests/testthat/test-rankES.R;vignettes/simple_htests.Rmd,True,True,True,False,28,34,62,"---FILE: NAMESPACE---
@@ -229,7 +229,6 @@ importFrom(stats,chisq.test)
 importFrom(stats,complete.cases)
 importFrom(stats,contrasts)
 importFrom(stats,delete.response)
-importFrom(stats,friedman.test)
 importFrom(stats,kruskal.test)
 importFrom(stats,lm)
 importFrom(stats,mad)

---FILE: NEWS.md---
@@ -1,3 +1,9 @@
+# effectsize 0.4.4.0001
+
+## Bug fixes
+
+- `kendalls_w()` now actually returns correct effect size. Previous estimates were incorrect, and based on transposing the groups and blocks.
+
 # effectsize 0.4.4
 
 `effectsize` now supports `R >= 3.4`.

---FILE: R/rank_effectsizes.R---
@@ -14,11 +14,9 @@
 #'   `blocks` and `groups` terminology used here.
 #' @param y An optional numeric vector of data values to compare to `x`, or a
 #'   character name of one in `data`. Ignored if `x` is not a vector.
-#' @param groups A vector or factor object giving the group for the
+#' @param groups,blocks A factor vector giving the group / block for the
 #'   corresponding elements of `x`, or a character name of one in `data`.
 #'   Ignored if `x` is not a vector.
-#' @param blocks A vector giving the block for the corresponding elements of
-#'   `x`, or a character name of one in `data`. Ignored if `x` is not a vector.
 #' @param mu a number indicating the value around which (a-)symmetry (for
 #'   one-sample or paired samples) or shift (for independent samples) is to be
 #'   estimated. See [stats::wilcox.test].
@@ -270,16 +268,18 @@ kendalls_w <- function(x,
   ## prep data
   data <- .kendalls_w_data(x, groups, blocks, data)
   data <- stats::na.omit(data)
+  rankings <- apply(data, 1, ranktransform, verbose = FALSE)
+  rankings <- t(rankings) # keep dims
 
   ## compute
-  W <- .kendalls_w(data)
+  W <- .kendalls_w(rankings)
   out <- data.frame(Kendalls_W = W)
 
   ## CI
   ci_method <- NULL
   if (is.numeric(ci)) {
     if (requireNamespace(""boot"", quietly = TRUE)) {
-      out <- cbind(out, .kendalls_w_ci(data, ci, iterations))
+      out <- cbind(out, .kendalls_w_ci(rankings, ci, iterations))
       ci_method <- list(method = ""bootstrap"", iterations = iterations)
     } else {
       ci <- NULL
@@ -367,14 +367,13 @@ kendalls_w <- function(x,
 
 
 #' @keywords internal
-#' @importFrom stats friedman.test
-.kendalls_w <- function(ratings) {
+.kendalls_w <- function(rankings) {
   # TODO add ties correction?
-  n <- nrow(ratings)
-  m <- ncol(ratings)
+  n <- ncol(rankings) # items
+  m <- nrow(rankings) # judges
 
-  col_ranks <- apply(ratings, 2, ranktransform)
-  S <- var(rowSums(col_ranks)) * (n - 1)
+  R <- colSums(rankings)
+  S <- var(R) * (n - 1)
   W <- (12 * S) / (m^2 * (n^3 - n))
 }
 
@@ -454,11 +453,11 @@ kendalls_w <- function(x,
   stopifnot(length(ci) == 1, ci < 1, ci > 0)
 
   boot_w <- function(.data, .i) {
-    .kendalls_w(t(.data[.i, ]))
+    .kendalls_w(.data[.i, ]) # sample rows
   }
 
   R <- boot::boot(
-    data = t(data),
+    data = data,
     statistic = boot_w,
     R = iterations
   )

---FILE: man/rank_biserial.Rd---
@@ -67,12 +67,9 @@ size on \code{x - y}.}
 
 \item{...}{Arguments passed to or from other methods.}
 
-\item{groups}{A vector or factor object giving the group for the
+\item{groups, blocks}{A factor vector giving the group / block for the
 corresponding elements of \code{x}, or a character name of one in \code{data}.
 Ignored if \code{x} is not a vector.}
-
-\item{blocks}{A vector giving the block for the corresponding elements of
-\code{x}, or a character name of one in \code{data}. Ignored if \code{x} is not a vector.}
 }
 \value{
 A data frame with the effect size (\code{r_rank_biserial}, \code{Kendalls_W} or

---FILE: tests/testthat/test-rankES.R---
@@ -68,22 +68,15 @@ if (require(""testthat"") && require(""effectsize"")) {
       class = c(""tbl_df"", ""tbl"", ""data.frame"")
     )
 
-    W1 <- {
-      set.seed(1)
-      kendalls_w(M1)
-    }
-    W2 <- {
-      set.seed(1)
-      kendalls_w(value ~ name | id, data = M2)
-    }
-    W3 <- {
-      set.seed(1)
-      kendalls_w(M2$value, M2$name, M2$id)
-    }
+    set.seed(1)
+    W1 <- kendalls_w(M1)
+    W2 <- kendalls_w(value ~ name | id, data = M2, ci = NULL)
+    W3 <- kendalls_w(M2$value, M2$name, M2$id, ci = NULL)
 
-    expect_equal(W1, W2)
-    expect_equal(W1, W3)
-    expect_equal(W1$CI_low, 0.7777778, tolerance = 0.01)
+    expect_equal(W1[[1]], W2[[1]])
+    expect_equal(W1[[1]], W3[[1]])
+    expect_equal(W1[[1]], 0.11111111, tolerance = 0.01)
+    expect_equal(W1$CI_low, 0.11111111, tolerance = 0.01)
     expect_equal(W1$CI_high, 1, tolerance = 0.01)
   })
 }

---FILE: vignettes/simple_htests.Rmd---
@@ -305,7 +305,7 @@ rank_epsilon_squared(group_data)
 For a rank based repeated measures one-way ANOVA, Kendall's *W* is a measure of
 agreement on the effect of condition between various ""blocks"" (the subjects), or
 more often conceptualized as a measure of reliability of the rating / scores of
-observations (or ""groups"") between ""raters"".
+observations (or ""groups"") between ""raters"" (""blocks"").
 
 ```{r}
 # Subjects are COLUMNS",True,True,Documentation / Formatting,6
easystats,effectsize,ade5ba6933f97e3346ff17b925b2d221b9fbf884,mattansb,35330040+mattansb@users.noreply.github.com,2021-03-17T15:11:14Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-03-17T15:11:14Z,fix vignette example of kendalls_w,R/rank_effectsizes.R;man/rank_biserial.Rd;vignettes/simple_htests.Rmd,True,True,True,False,30,26,56,"---FILE: R/rank_effectsizes.R---
@@ -6,10 +6,12 @@
 #' @inheritParams cohens_d
 #' @param x Can be one of:
 #'   - A numeric vector, or a character name of one in `data`.
-#'   - A formula in to form of `x ~ groups` (for `rank_biserial()` and
-#'   `rank_epsilon_squared()`) or `x ~ groups | blocks` (for `kendalls_w()`).
+#'   - A formula in to form of `DV ~ groups` (for `rank_biserial()` and
+#'   `rank_epsilon_squared()`) or `DV ~ groups | blocks` (for `kendalls_w()`;
+#'   See details for the `blocks` and `groups` terminology used here).
 #'   - A list of vectors (for `rank_epsilon_squared()`).
-#'   - A matrix of `blocks x groups` (for `kendalls_w()`).
+#'   - A matrix of `blocks x groups` (for `kendalls_w()`). See details for the
+#'   `blocks` and `groups` terminology used here.
 #' @param y An optional numeric vector of data values to compare to `x`, or a
 #'   character name of one in `data`. Ignored if `x` is not a vector.
 #' @param groups A vector or factor object giving the group for the
@@ -22,8 +24,6 @@
 #'   estimated. See [stats::wilcox.test].
 #'
 #' @details
-#' Compute effect sizes for non-parametric (rank sum) tests.
-#' \cr\cr
 #' The rank-biserial correlation is appropriate for non-parametric tests of
 #' differences - both for the one sample or paired samples case, that would
 #' normally be tested with Wilcoxon's Signed Rank Test (giving the
@@ -43,9 +43,12 @@
 #' indicating larger differences between groups.
 #' \cr\cr
 #' Kendall's *W* is appropriate for non-parametric tests of differences between
-#' 2 or more dependent samples (a rank based rmANOVA). See
-#' [stats::friedman.test]. Values range from 0 to 1, with larger values
-#' indicating larger differences between groups.
+#' 2 or more dependent samples (a rank based rmANOVA), where each `group` (e.g.,
+#' experimental condition) was measured for each `block` (e.g., subject). This
+#' measure is also common as a measure of reliability of the rankings of the
+#' `groups` between raters (`blocks`). See [stats::friedman.test]. Values range
+#' from 0 to 1, with larger values indicating larger differences between groups
+#' / higher agreement between raters.
 #'
 #' # Confidence Intervals
 #' Confidence Intervals are estimated using the bootstrap method.
@@ -366,12 +369,12 @@ kendalls_w <- function(x,
 #' @keywords internal
 #' @importFrom stats friedman.test
 .kendalls_w <- function(ratings) {
-  # TODO add ties corrction?
+  # TODO add ties correction?
   n <- nrow(ratings)
   m <- ncol(ratings)
 
-  ratings.rank <- apply(ratings, 2, rank)
-  S <- var(apply(ratings.rank, 1, sum)) * (n - 1)
+  col_ranks <- apply(ratings, 2, ranktransform)
+  S <- var(rowSums(col_ranks)) * (n - 1)
   W <- (12 * S) / (m^2 * (n^3 - n))
 }
 

---FILE: man/rank_biserial.Rd---
@@ -38,10 +38,12 @@ kendalls_w(x, groups, blocks, data = NULL, ci = 0.95, iterations = 200, ...)
 \item{x}{Can be one of:
 \itemize{
 \item A numeric vector, or a character name of one in \code{data}.
-\item A formula in to form of \code{x ~ groups} (for \code{rank_biserial()} and
-\code{rank_epsilon_squared()}) or \code{x ~ groups | blocks} (for \code{kendalls_w()}).
+\item A formula in to form of \code{DV ~ groups} (for \code{rank_biserial()} and
+\code{rank_epsilon_squared()}) or \code{DV ~ groups | blocks} (for \code{kendalls_w()};
+See details for the \code{blocks} and \code{groups} terminology used here).
 \item A list of vectors (for \code{rank_epsilon_squared()}).
-\item A matrix of \verb{blocks x groups} (for \code{kendalls_w()}).
+\item A matrix of \verb{blocks x groups} (for \code{kendalls_w()}). See details for the
+\code{blocks} and \code{groups} terminology used here.
 }}
 
 \item{y}{An optional numeric vector of data values to compare to \code{x}, or a
@@ -81,8 +83,6 @@ Compute the rank-biserial correlation, Cliff's \emph{delta}, rank Epsilon square
 and Kendall's \emph{W} effect sizes for non-parametric (rank sum) tests.
 }
 \details{
-Compute effect sizes for non-parametric (rank sum) tests.
-\cr\cr
 The rank-biserial correlation is appropriate for non-parametric tests of
 differences - both for the one sample or paired samples case, that would
 normally be tested with Wilcoxon's Signed Rank Test (giving the
@@ -102,9 +102,12 @@ differences between 2 or more samples (a rank based ANOVA). See
 indicating larger differences between groups.
 \cr\cr
 Kendall's \emph{W} is appropriate for non-parametric tests of differences between
-2 or more dependent samples (a rank based rmANOVA). See
-\link[stats:friedman.test]{stats::friedman.test}. Values range from 0 to 1, with larger values
-indicating larger differences between groups.
+2 or more dependent samples (a rank based rmANOVA), where each \code{group} (e.g.,
+experimental condition) was measured for each \code{block} (e.g., subject). This
+measure is also common as a measure of reliability of the rankings of the
+\code{groups} between raters (\code{blocks}). See \link[stats:friedman.test]{stats::friedman.test}. Values range
+from 0 to 1, with larger values indicating larger differences between groups
+/ higher agreement between raters.
 }
 \section{Confidence Intervals}{
 Confidence Intervals are estimated using the bootstrap method.

---FILE: vignettes/simple_htests.Rmd---
@@ -303,28 +303,26 @@ rank_epsilon_squared(group_data)
 ## Rank One way Repeated-Measures ANOVA
 
 For a rank based repeated measures one-way ANOVA, Kendall's *W* is a measure of
-agreement on the effect of condition between the ""blocks"" (the subjects), or
+agreement on the effect of condition between various ""blocks"" (the subjects), or
 more often conceptualized as a measure of reliability of the rating / scores of
 observations (or ""groups"") between ""raters"".
 
 ```{r}
 # Subjects are COLUMNS
-(ReactionTimes <- t(matrix(
-  c(
-    398, 338, 520,
+(ReactionTimes <- matrix(
+  c(398, 338, 520,
     325, 388, 555,
     393, 363, 561,
     367, 433, 470,
     286, 492, 536,
     362, 475, 496,
-    253, 334, 610
-  ),
+    253, 334, 610),
   nrow = 7, byrow = TRUE,
   dimnames = list(
     paste0(""Subject"", 1:7),
     c(""Congruent"", ""Neutral"", ""Incongruent"")
   )
-)))
+))
 
 friedman.test(ReactionTimes)
 ",True,True,Documentation / Formatting,7
easystats,effectsize,b13294ffce4b72a0e3b9cbed974efe8ab6c8f667,mattansb,35330040+mattansb@users.noreply.github.com,2021-03-10T11:42:51Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-03-10T11:42:51Z,fix/new: std_pars.boot,NAMESPACE;NEWS.md;R/standardize_parameters.R;tests/testthat/test-standardize_parameters.R,False,True,True,False,93,44,137,"---FILE: NAMESPACE---
@@ -63,6 +63,7 @@ S3method(standardize,numeric)
 S3method(standardize,wbgee)
 S3method(standardize,wbm)
 S3method(standardize_parameters,bootstrap_model)
+S3method(standardize_parameters,bootstrap_parameters)
 S3method(standardize_parameters,default)
 S3method(standardize_parameters,parameters_model)
 S3method(unstandardize,array)

---FILE: NEWS.md---
@@ -1,9 +1,10 @@
-# effectsize 0.4.3-1
+# effectsize 0.4.4
 
 `effectsize` now supports `R >= 3.4`.
 
 ## New features
 
+- `standardize_parameters()` now supports bootstrapped estimates (from `parameters::bootstrap_model()` and `parameters::bootstrap_parameters()`).
 - `unstandardize()` which will reverse the effects of `standardize()`.
 - `interpret_kendalls_w()` to interpret Kendall's coefficient of concordance.
 - `eta_squared()` family of functions can now also return effect sizes for the intercept by setting `include_intercept = TRUE` ( #156 ).

---FILE: R/standardize_parameters.R---
@@ -261,49 +261,75 @@ standardize_parameters.parameters_model <- function(model, method = ""refit"", ci
   return(pars)
 }
 
-#' #' @export
-#' standardize_parameters.bootstrap_model <-
-#'   function(model,
-#'            method = ""refit"",
-#'            ci = 0.95,
-#'            robust = FALSE,
-#'            two_sd = FALSE,
-#'            verbose = TRUE,
-#'            ...) {
-#'     object_name <- deparse(substitute(model), width.cutoff = 500)
-#'     method <- match.arg(method, c(""refit"", ""posthoc"", ""smart"", ""basic"", ""classic"", ""pseudo""))
-#'
-#'     pars <- model
-#'     model <- attr(pars, ""original_model"")
-#'
-#'     if (method == ""refit"") {
-#'       stop(""Not yet..."")
-#'       # model <- standardize(model, robust = robust, two_sd = two_sd, verbose = verbose)
-#'       # model <- parameters::bootstrap_model(model, iterations = 1000, verbose = verbose)
-#'       # return(model)
-#'     }
-#'     mi <- insight::model_info(model)
-#'
-#'     # need model_parameters to return the parameters, not the terms
-#'     if (inherits(model, ""aov"")) class(model) <- class(model)[class(model) != ""aov""]
-#'
-#'
-#'     if (method %in% c(""posthoc"", ""smart"", ""basic"", ""classic"", ""pseudo"")) {
-#'       pars <- .standardize_posteriors_posthoc(pars, method, model, robust, two_sd, verbose)
-#'
-#'       method <- attr(pars, ""std_method"")
-#'       robust <- attr(pars, ""robust"")
-#'     }
-#'
-#'     attr(pars, ""std_method"") <- method
-#'     attr(pars, ""two_sd"") <- two_sd
-#'     attr(pars, ""robust"") <- robust
-#'     attr(pars, ""object_name"") <- object_name
-#'     attr(pars, ""ci"") <- ci
-#'     class(pars) <- c(""effectsize_std_params"", class(pars))
-#'     return(pars)
-#'
-#'   }
+#' @export
+standardize_parameters.bootstrap_model <-
+  function(model,
+           method = ""refit"",
+           ci = 0.95,
+           robust = FALSE,
+           two_sd = FALSE,
+           verbose = TRUE,
+           ...) {
+    object_name <- deparse(substitute(model), width.cutoff = 500)
+    method <- match.arg(method, c(""refit"", ""posthoc"", ""smart"", ""basic"", ""classic"", ""pseudo""))
+
+    pars <- model
+    model <- attr(pars, ""original_model"")
+
+    if (method == ""refit"") {
+      stop(""The 'refit' method is not supported for bootstrapped models."")
+      ## But it would look something like this:
+      # model <- standardize(model, robust = robust, two_sd = two_sd, verbose = verbose)
+      # model <- parameters::bootstrap_model(model, iterations = 1000, verbose = verbose)
+      # return(model)
+    }
+    mi <- insight::model_info(model)
+
+    # need model_parameters to return the parameters, not the terms
+    if (inherits(model, ""aov"")) class(model) <- class(model)[class(model) != ""aov""]
+
+
+    if (method %in% c(""posthoc"", ""smart"", ""basic"", ""classic"", ""pseudo"")) {
+      pars <- .standardize_posteriors_posthoc(pars, method, model, robust, two_sd, verbose)
+
+      method <- attr(pars, ""std_method"")
+      robust <- attr(pars, ""robust"")
+    }
+
+    pars <- bayestestR::describe_posterior(pars, centrality = ""median"",
+                                           ci = ci, ci_method = ""quantile"",
+                                           test = NULL)
+    names(pars)[names(pars) == ""Median""] <- ""Std_Coefficient""
+
+
+    attr(pars, ""std_method"") <- method
+    attr(pars, ""two_sd"") <- two_sd
+    attr(pars, ""robust"") <- robust
+    attr(pars, ""object_name"") <- object_name
+    attr(pars, ""ci"") <- ci
+    class(pars) <- c(""effectsize_std_params"", ""effectsize_table"", ""see_effectsize_table"", ""data.frame"")
+    return(pars)
+  }
+
+#' @export
+standardize_parameters.bootstrap_parameters <-
+  function(model,
+           method = ""refit"",
+           ci = 0.95,
+           robust = FALSE,
+           two_sd = FALSE,
+           verbose = TRUE,
+           ...) {
+
+    standardize_parameters(attr(model, ""boot_samples""),
+                           method = method,
+                           ci = ci,
+                           robust = robust,
+                           two_sd = two_sd,
+                           verbose = verbose,
+                           ...)
+  }
+
 
 
 #' @keywords internal

---FILE: tests/testthat/test-standardize_parameters.R---
@@ -35,6 +35,27 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(se1$CI_high, se2$CI_high)
   })
 
+  # bootstrap_model ---------------------------------------------------------
+
+  test_that(""standardize_parameters (bootstrap_model)"",{
+    m <- lm(mpg ~ factor(cyl) + hp, mtcars)
+
+    set.seed(1); bm_draws <- parameters::bootstrap_model(m, iterations = 599)
+    set.seed(1); bm_tab <- parameters::bootstrap_parameters(m, iterations = 599)
+
+    out_true <- standardize_parameters(m, method = ""basic"")
+    out_boot1 <- standardize_parameters(bm_draws, method = ""basic"")
+    out_boot2 <- standardize_parameters(bm_tab, method = ""basic"")
+
+    expect_equal(out_boot1$Std_Coefficient, out_true$Std_Coefficient,
+                 tolerance = 0.05)
+    expect_equal(out_boot1, out_boot2, ignore_attr = TRUE)
+    expect_error(standardize_parameters(bm_draws, method = ""refit""))
+    expect_error(standardize_parameters(bm_tab, method = ""refit""))
+  })
+
+
+
   # lm with ci -----------------------------------
   test_that(""standardize_parameters (lm with ci)"", {
     data(""iris"")",True,False,Documentation / Formatting,6
easystats,effectsize,112f96c34570baebc644b6ec7310ad30d5798d84,mattansb,35330040+mattansb@users.noreply.github.com,2021-03-07T14:51:19Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-03-07T14:51:19Z,fix: full name of aov_car,tests/testthat/test-eta_squared_etc.R,False,True,True,False,3,3,6,"---FILE: tests/testthat/test-eta_squared_etc.R---
@@ -376,9 +376,9 @@ if (require(""testthat"") && require(""effectsize"")) {
     data(obk.long, package = ""afex"")
 
     suppressWarnings(suppressMessages(
-      a <- aov_car(value ~ treatment * gender + Error(id),
-                   include_aov = TRUE,
-                   data = obk.long)
+      a <- afex::aov_car(value ~ treatment * gender + Error(id),
+                         include_aov = TRUE,
+                         data = obk.long)
     ))
 
     resE0 <- eta_squared(a)",True,False,Dependency / Package,3
easystats,effectsize,029567b6f528ec81a4b37e05d9a84a16381cbcbf,mattansb,35330040+mattansb@users.noreply.github.com,2021-02-28T09:10:40Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-02-28T09:10:40Z,fix: std dates #300,NAMESPACE;NEWS.md;R/standardize.data.R;man/standardize.Rd;tests/testthat/test-standardize-data.R,False,True,True,False,25,4,29,"---FILE: NAMESPACE---
@@ -43,6 +43,7 @@ S3method(ranktransform,factor)
 S3method(ranktransform,grouped_df)
 S3method(ranktransform,numeric)
 S3method(standardize,AsIs)
+S3method(standardize,Date)
 S3method(standardize,Surv)
 S3method(standardize,bcplm)
 S3method(standardize,character)

---FILE: NEWS.md---
@@ -6,6 +6,11 @@
 
 - `unstandardize()` which will reverse the effects of `standardize()`.
 
+## Bug fixes
+
+- `standardize()` can now deal with dates ( #300 ).
+
+
 # effectsize 0.4.3
 
 ## Breaking Changes

---FILE: R/standardize.data.R---
@@ -85,6 +85,9 @@ standardize.character <- standardize.factor
 #' @export
 standardize.logical <- standardize.factor
 
+#' @export
+standardize.Date <- standardize.factor
+
 #' @export
 standardize.AsIs <- standardize.numeric
 
@@ -101,8 +104,8 @@ standardize.AsIs <- standardize.numeric
 #'   `NA`s. Else, rows with `NA` in the columns selected with `select` /
 #'   `exclude` (`""selected""`) or in all columns (`""all""`) are dropped before
 #'   standardization, and the resulting data frame does not include these cases.
-#' @param force Logical, if `TRUE`, forces standardization of factors as
-#'   well. Factors are converted to numerical values, with the lowest level
+#' @param force Logical, if `TRUE`, forces standardization of factors and dates
+#'   as well. Factors are converted to numerical values, with the lowest level
 #'   being the value `1` (unless the factor has numeric levels, which are
 #'   converted to the corresponding numeric value).
 #' @param append Logical, if `TRUE` and `x` is a data frame, standardized

---FILE: man/standardize.Rd---
@@ -99,8 +99,8 @@ variables will be selected.}
 \code{exclude} (\code{""selected""}) or in all columns (\code{""all""}) are dropped before
 standardization, and the resulting data frame does not include these cases.}
 
-\item{force}{Logical, if \code{TRUE}, forces standardization of factors as
-well. Factors are converted to numerical values, with the lowest level
+\item{force}{Logical, if \code{TRUE}, forces standardization of factors and dates
+as well. Factors are converted to numerical values, with the lowest level
 being the value \code{1} (unless the factor has numeric levels, which are
 converted to the corresponding numeric value).}
 

---FILE: tests/testthat/test-standardize-data.R---
@@ -18,6 +18,18 @@ if (require(""testthat"") && require(""effectsize"")) {
   })
 
 
+  # standardize factor / Date -----------------------------------------------
+  test_that(""standardize.numeric"", {
+    f <- factor(c(""c"", ""a"", ""b""))
+    expect_equal(standardize(f), f)
+    expect_equal(standardize(f, force = TRUE), c(1, -1, 0), ignore_attr = TRUE)
+
+    d <- as.Date(c(""1989/08/06"", ""1989/08/04"", ""1989/08/05""))
+    expect_equal(standardize(d), d)
+    expect_equal(standardize(d, force = TRUE), c(1, -1, 0), ignore_attr = TRUE)
+  })
+
+
   # standardize.data.frame --------------------------------------------------
   test_that(""standardize.data.frame"", {
     data(iris)",True,False,Documentation / Formatting,6
easystats,effectsize,b654ed0a0339b8a4e51f63f263d41beba21fd713,mattansb,35330040+mattansb@users.noreply.github.com,2021-02-25T07:46:32Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-02-25T07:46:32Z,fix: tests on R3.4,tests/testthat/test-es_from_statistic.R,False,True,True,False,2,2,4,"---FILE: tests/testthat/test-es_from_statistic.R---
@@ -95,8 +95,8 @@ if (require(""testthat"") && require(""effectsize"")) {
     res <- F_to_eta2(4, 3, 123)
     resf2 <- F_to_f2(4, 3, 123)
     resf <- F_to_f(4, 3, 123)
-    expect_equal(resf2[-2], res[-2] / (1 - res[-2]), ignore_attr = TRUE)
-    expect_equal(resf[-2]^2, res[-2] / (1 - res[-2]), ignore_attr = TRUE)
+    expect_equal(resf2[[1]], res[[1]] / (1 - res[[1]]), ignore_attr = TRUE)
+    expect_equal(resf[[1]]^2, res[[1]] / (1 - res[[1]]), ignore_attr = TRUE)
     expect_equal(F_to_f(4, 3, 123), F_to_f2(4, 3, 123, squared = FALSE))
     expect_equal(F_to_f2(4, 3, 123), F_to_f(4, 3, 123, squared = TRUE))
   })",True,False,Dependency / Package,3
easystats,effectsize,90a66bc2744d19ab0219bfcc497a6b9ab8b5b0cc,mattansb,35330040+mattansb@users.noreply.github.com,2021-02-22T13:45:05Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-02-22T13:45:05Z,fix: xtab test,tests/testthat/test-es_from_statistic.R,False,True,True,False,1,1,2,"---FILE: tests/testthat/test-es_from_statistic.R---
@@ -13,7 +13,7 @@ if (require(""testthat"") && require(""effectsize"")) {
       nrow = nrow(xtab),
       ncol = ncol(xtab)
     )
-    expect_equal(res1, cramers_v(xtab), ignore_attr = TRUE)
+    expect_equal(res, cramers_v(xtab), ignore_attr = TRUE)
 
 
     res <- chisq_to_phi(",True,False,Dependency / Package,3
easystats,effectsize,2997ddaf6d36511fc192b671c4f30f860bfbe67d,Indrajeet Patil,inderonline1988@gmail.com,2021-02-21T16:45:22Z,Indrajeet Patil,inderonline1988@gmail.com,2021-02-21T16:45:22Z,does this solve acitons issue?,DESCRIPTION,False,False,False,False,1,2,3,"---FILE: DESCRIPTION---
@@ -38,7 +38,7 @@ Description: Provide utilities to work with indices of effect size and standardi
 Depends:
     R (>= 3.4)
 Imports:
-    bayestestR (>= 0.8.2.1),
+    bayestestR (>= 0.8.2),
     insight (>= 0.13.0),
     parameters (>= 0.11.0.1),
     stats,
@@ -76,7 +76,6 @@ Suggests:
     tidyr,
     spelling
 Remotes:
-    easystats/bayestestR,
     easystats/parameters
 RoxygenNote: 7.1.1.9000
 Language: en-US",False,False,Dependency / Package,6
easystats,effectsize,8ff20f99f3cd8564bed36efa35f8e306aad106e2,mattansb,35330040+mattansb@users.noreply.github.com,2021-02-21T09:44:35Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-02-21T09:44:35Z,"fix: Unknown packages âcarâ, âemmeansâ in Rd xrefs",R/convert_tFz_to_r.R;R/eta_squared_posterior.R;man/eta_squared.Rd;man/t_to_r.Rd,False,True,True,False,4,4,8,"---FILE: R/convert_tFz_to_r.R---
@@ -39,7 +39,7 @@
 #'
 #' The resulting `d` effect size is an *approximation* to Cohen's *d*, and
 #' assumes two equal group sizes. When possible, it is advised to directly
-#' estimate Cohen's *d*, with [cohens_d()], [emmeans::eff_size()], or similar
+#' estimate Cohen's *d*, with [cohens_d()], `emmeans::eff_size()`, or similar
 #' functions.
 #'
 #' @inheritSection cohens_d Confidence Intervals

---FILE: R/eta_squared_posterior.R---
@@ -1,5 +1,5 @@
 #' @param ss_function For Bayesian models, the function used to extract
-#'   sum-of-squares. Uses [`anova()`] by default, but can also be [car::Anova()]
+#'   sum-of-squares. Uses [`anova()`] by default, but can also be `car::Anova()`
 #'   for simple linear models.
 #' @param draws For Bayesian models, an integer indicating the number of draws
 #'   from the posterior predictive distribution to return. Larger numbers take

---FILE: man/eta_squared.Rd---
@@ -76,7 +76,7 @@ automatically from the fitted model, if they were provided then.}
 returns the effect size for R-squared-change between the two models.}
 
 \item{ss_function}{For Bayesian models, the function used to extract
-sum-of-squares. Uses \code{\link[=anova]{anova()}} by default, but can also be \code{\link[car:Anova]{car::Anova()}}
+sum-of-squares. Uses \code{\link[=anova]{anova()}} by default, but can also be \code{car::Anova()}
 for simple linear models.}
 
 \item{draws}{For Bayesian models, an integer indicating the number of draws

---FILE: man/t_to_r.Rd---
@@ -66,7 +66,7 @@ These functions use the following formulae to approximate \emph{r} and \emph{d}:
 
 The resulting \code{d} effect size is an \emph{approximation} to Cohen's \emph{d}, and
 assumes two equal group sizes. When possible, it is advised to directly
-estimate Cohen's \emph{d}, with \code{\link[=cohens_d]{cohens_d()}}, \code{\link[emmeans:eff_size]{emmeans::eff_size()}}, or similar
+estimate Cohen's \emph{d}, with \code{\link[=cohens_d]{cohens_d()}}, \code{emmeans::eff_size()}, or similar
 functions.
 }
 \section{Confidence Intervals}{",True,False,Documentation / Formatting,6
easystats,effectsize,1894112313c3269dbad251fa43d83cefca7db06d,mattansb,35330040+mattansb@users.noreply.github.com,2021-02-21T09:41:24Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-02-21T09:41:24Z,fix: File LICENSE is not mentioned in the DESCRIPTION file,DESCRIPTION,False,False,False,False,1,1,2,"---FILE: DESCRIPTION---
@@ -31,7 +31,7 @@ Authors@R: c(
         role = c(""ctb""))
     )
 Maintainer: Mattan S. Ben-Shachar <matanshm@post.bgu.ac.il>
-License: GPL-3
+License: GPL-3 + file LICENSE
 URL: https://easystats.github.io/effectsize/
 BugReports: https://github.com/easystats/effectsize/issues/
 Description: Provide utilities to work with indices of effect size and standardized parameters for a wide variety of models (see list of supported models in insight; LÃ¼decke, Waggoner & Makowski (2019) <doi:10.21105/joss.01412>), allowing computation of and conversion between indices such as Cohen's d, r, odds, etc.",False,False,Dependency / Package,6
easystats,effectsize,d880a7f0c974babf15ceaaa07e55b54c1e728430,Indrajeet Patil,inderonline1988@gmail.com,2021-02-21T07:27:08Z,Indrajeet Patil,inderonline1988@gmail.com,2021-02-21T07:27:08Z,fix examples,R/cohens_d.R;man/cohens_d.Rd,False,True,True,False,14,13,27,"---FILE: R/cohens_d.R---
@@ -65,9 +65,9 @@
 #'
 #' # one-sample tests -----------------------
 #'
-#' cohens_d(wt, data = mtcars, mu = 3)
-#' hedges_g(wt, data = mtcars, mu = 3)
-#' if (require(boot)) glass_delta(wt, data = mtcars, mu = 3)
+#' cohens_d(""wt"", data = mtcars, mu = 3)
+#' hedges_g(""wt"", data = mtcars, mu = 3)
+#' if (require(boot)) glass_delta(""wt"", data = mtcars, mu = 3)
 #'
 #' # interpretation -----------------------
 #'
@@ -76,16 +76,17 @@
 #' interpret_delta(0.4, rules = ""gignac2016"")
 #'
 #' @references
-#' \itemize {
-#' \item Cohen, J. (1988). Statistical power analysis for the behavioral
+#' - Cohen, J. (1988). Statistical power analysis for the behavioral
 #' sciences (2nd Ed.). New York: Routledge.
-#' \item Hedges, L. V. & Olkin, I. (1985). Statistical methods for
+#'
+#' - Hedges, L. V. & Olkin, I. (1985). Statistical methods for
 #' meta-analysis. Orlando, FL: Academic Press.
-#' \item Hunter, J. E., & Schmidt, F. L. (2004). Methods of meta-analysis:
+#'
+#' - Hunter, J. E., & Schmidt, F. L. (2004). Methods of meta-analysis:
 #' Correcting error and bias in research findings. Sage.
-#' \item McGrath, R. E., & Meyer, G. J. (2006). When effect sizes disagree: the
+#'
+#' - McGrath, R. E., & Meyer, G. J. (2006). When effect sizes disagree: the
 #' case of r and d. Psychological methods, 11(4), 386.
-#' }
 #'
 #' @importFrom stats var model.frame
 #' @export

---FILE: man/cohens_d.Rd---
@@ -132,9 +132,9 @@ cohens_d(sleep$extra[sleep$group == 1], sleep$extra[sleep$group == 2], paired =
 
 # one-sample tests -----------------------
 
-cohens_d(wt, data = mtcars, mu = 3)
-hedges_g(wt, data = mtcars, mu = 3)
-if (require(boot)) glass_delta(wt, data = mtcars, mu = 3)
+cohens_d(""wt"", data = mtcars, mu = 3)
+hedges_g(""wt"", data = mtcars, mu = 3)
+if (require(boot)) glass_delta(""wt"", data = mtcars, mu = 3)
 
 # interpretation -----------------------
 
@@ -144,7 +144,7 @@ interpret_delta(0.4, rules = ""gignac2016"")
 
 }
 \references{
-\itemize {
+\itemize{
 \item Cohen, J. (1988). Statistical power analysis for the behavioral
 sciences (2nd Ed.). New York: Routledge.
 \item Hedges, L. V. & Olkin, I. (1985). Statistical methods for",True,False,Documentation / Formatting,6
easystats,effectsize,3d4826ea7d345765af5e8d456f219f12c7fd2fd3,mattansb,35330040+mattansb@users.noreply.github.com,2021-02-17T14:05:56Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-02-17T14:05:56Z,"Update .Rbuildignore

fix issue with missing vignette folder, maybe?",.Rbuildignore,False,False,False,False,1,1,2,"---FILE: .Rbuildignore---
@@ -48,4 +48,4 @@ references.bib
 hextools
 ^paper/.
 ^WIP/.
-^vignettes(?!/additional).*
\ No newline at end of file
+^vignettes/(?!additional).*
\ No newline at end of file",False,False,Environment / Configuration,3
easystats,effectsize,e12eed8f88e688bce98d53301da03eb9c3fc6c3f,mattansb,35330040+mattansb@users.noreply.github.com,2021-02-15T08:49:51Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-02-15T08:49:51Z,fix format_standardize test,tests/testthat/test-format_standardize.R,False,True,True,False,1,2,3,"---FILE: tests/testthat/test-format_standardize.R---
@@ -1,6 +1,5 @@
 if (require(""testthat"") && require(""effectsize"")) {
   test_that(""format_standardize"", {
-    set.seed(123)
     expect_equal(
       format_standardize(c(-1, 0, 1)),
       structure(3:1, .Label = c(""+1 SD"", ""Mean"", ""-1 SD""), class = ""factor"")
@@ -24,7 +23,7 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     expect_equal(
       format_standardize(c(-1, 0, 1, 2), reference = ref, robust = TRUE, digits = 2),
-      structure(4:1, .Label = c(""+2.00 MAD"", ""+1.00 MAD"", ""+0.00 MAD"", ""-1.00 MAD""),
+      structure(4:1, .Label = c(""+2.00 MAD"", ""+1.00 MAD"", ""Median"", ""-1.00 MAD""),
                 class = ""factor"")
     )
   })",True,False,Dependency / Package,3
easystats,effectsize,c6034bb90d00b9b74987b8641e6b2a56cc804797,DominiqueMakowski,dom.mak19@gmail.com,2021-02-10T13:38:36Z,DominiqueMakowski,dom.mak19@gmail.com,2021-02-10T13:38:36Z,fix docs + test,R/interpret_r.R;man/interpret_r.Rd;tests/testthat/test-interpret.R,False,True,True,False,10,8,18,"---FILE: R/interpret_r.R---
@@ -25,10 +25,10 @@
 #'   - **0.3 <= r < 0.5** - Moderate
 #'   - **r >= 0.5** - Large
 #' - Lovakov & Agadullina (2021) (`""lovakov2021""`)
-#'   - **r < 0.1** - Very small
-#'   - **0.1 <= r < 0.3** - Small
-#'   - **0.3 <= r < 0.5** - Moderate
-#'   - **r >= 0.5** - Large
+#'   - **r < 0.12** - Very small
+#'   - **0.12 <= r < 0.24** - Small
+#'   - **0.24 <= r < 0.41** - Moderate
+#'   - **r >= 0.41** - Large
 #' - Evans (1996) (`""evans1996""`)
 #'   - **r < 0.2** - Very weak
 #'   - **0.2 <= r < 0.4** - Weak

---FILE: man/interpret_r.Rd---
@@ -44,10 +44,10 @@ Rules apply positive and negative \emph{r} alike.
 }
 \item Lovakov & Agadullina (2021) (\code{""lovakov2021""})
 \itemize{
-\item \strong{r < 0.1} - Very small
-\item \strong{0.1 <= r < 0.3} - Small
-\item \strong{0.3 <= r < 0.5} - Moderate
-\item \strong{r >= 0.5} - Large
+\item \strong{r < 0.12} - Very small
+\item \strong{0.12 <= r < 0.24} - Small
+\item \strong{0.24 <= r < 0.41} - Moderate
+\item \strong{r >= 0.41} - Large
 }
 \item Evans (1996) (\code{""evans1996""})
 \itemize{

---FILE: tests/testthat/test-interpret.R---
@@ -20,6 +20,7 @@ if (require(""testthat"") && require(""effectsize"")) {
   test_that(""interpret_r"", {
     expect_equal(interpret_r(0.21)[1], ""medium"")
     expect_equal(interpret_r(0.21, ""cohen1988"")[1], ""small"")
+    expect_equal(interpret_r(0.21, ""lovakov2021"")[1], ""small"")
     expect_equal(interpret_r(0.7, ""evans1996"")[1], ""strong"")
     expect_equal(interpret_r(c(0.5, -0.08), ""cohen1988"")[1:2], c(""large"", ""very small""))
     expect_equal(interpret_r(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
@@ -46,6 +47,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     expect_equal(interpret_d(0.021)[1], ""very small"")
     expect_equal(interpret_d(1.3, ""sawilowsky2009"")[1], ""very large"")
     expect_equal(interpret_d(c(0.45, 0.85), ""cohen1988"")[1:2], c(""small"", ""large""))
+    expect_equal(interpret_d(c(0.45, 0.85), ""lovakov2021"")[1:2], c(""medium"", ""large""))
     expect_equal(interpret_d(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
     expect_error(interpret_d(0.6, ""DUPA""))
   })",True,False,Documentation / Formatting,7
easystats,effectsize,c371c053e8d67724a09ca89e2a3558c1b43b82ef,Dominique Makowski,dom.mak19@gmail.com,2021-02-09T04:59:16Z,Dominique Makowski,dom.mak19@gmail.com,2021-02-09T04:59:16Z,fix typo,vignettes/standardize_parameters.Rmd,True,False,True,False,1,1,2,"---FILE: vignettes/standardize_parameters.Rmd---
@@ -329,7 +329,7 @@ standardize_parameters(mod, method = ""basic"")
 
 Linear mixed models (LMM/HLM/MLM) offer an additional conundrum to
 standardization - how does one even calculate the SDs of the various predictors?
-Of of the response - is it the deviations within each group? Or perhaps between
+Or of the response - is it the deviations within each group? Or perhaps between
 them?
 
 The solution: standardize according to level of the predictor",False,True,Documentation / Formatting,4
easystats,effectsize,6d94e49e9c072a30f6f638eccadb4a527c343120,mattansb,35330040+mattansb@users.noreply.github.com,2021-02-07T07:52:49Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-02-07T07:52:49Z,fix printing issue,R/cohens_d.R;R/convert_chisq.R;R/convert_tF_to_anova.R;R/convert_tFz_to_d.R;R/convert_tFz_to_r.R;R/print.effectsize_table.R;R/rank_effectsizes.R;R/xtab.R,False,True,True,False,37,18,55,"---FILE: R/cohens_d.R---
@@ -245,6 +245,7 @@ glass_delta <- function(x, y = NULL, data = NULL, mu = 0, ci = 0.95, iterations
   types <- c(""d"" = ""Cohens_d"", ""g"" = ""Hedges_g"", ""delta"" = ""Glass_delta"")
   colnames(out) <- types[type]
 
+  ci_method <- NULL
   if (is.numeric(ci)) {
     stopifnot(length(ci) == 1, ci < 1, ci > 0)
 
@@ -263,6 +264,7 @@ glass_delta <- function(x, y = NULL, data = NULL, mu = 0, ci = 0.95, iterations
         out <- cbind(out, .delta_ci(x, y, mu = mu, ci = ci, ...))
         ci_method <- list(method = ""bootstrap"", iterations = iterations)
       } else {
+        ci <- NULL
         warning(""'boot' package required for estimating CIs for Glass' delta. Please install the package and try again."", call. = FALSE)
       }
     }
@@ -291,7 +293,7 @@ glass_delta <- function(x, y = NULL, data = NULL, mu = 0, ci = 0.95, iterations
   attr(out, ""pooled_sd"") <- pooled_sd
   attr(out, ""mu"") <- mu
   attr(out, ""ci"") <- ci
-  attr(out, ""ci_method"") <- if (exists(""ci_method"")) ci_method
+  attr(out, ""ci_method"") <- ci_method
   return(out)
 }
 

---FILE: R/convert_chisq.R---
@@ -74,7 +74,7 @@ chisq_to_phi <- function(chisq, n, nrow, ncol, ci = 0.95, adjust = FALSE, ...) {
     res <- data.frame(phi = sqrt(chisq / n))
   }
 
-
+  ci_method <- NULL
   if (is.numeric(ci)) {
     stopifnot(length(ci) == 1, ci < 1, ci > 0)
     res$CI <- ci
@@ -96,7 +96,7 @@ chisq_to_phi <- function(chisq, n, nrow, ncol, ci = 0.95, adjust = FALSE, ...) {
 
   class(res) <- c(""effectsize_table"", ""see_effectsize_table"", class(res))
   attr(res, ""ci"") <- ci
-  attr(res, ""ci_method"") <- if (exists(""ci_method"")) ci_method
+  # attr(res, ""ci_method"") <- ci_method
   attr(res, ""adjust"") <- adjust
   return(res)
 }
@@ -142,7 +142,7 @@ chisq_to_cramers_v <- function(chisq, n, nrow, ncol, ci = 0.95, adjust = FALSE,
     res <- data.frame(Cramers_v = V)
   }
 
-
+  ci_method <- NULL
   if (is.numeric(ci)) {
     stopifnot(length(ci) == 1, ci < 1, ci > 0)
     res$CI <- ci
@@ -164,7 +164,7 @@ chisq_to_cramers_v <- function(chisq, n, nrow, ncol, ci = 0.95, adjust = FALSE,
 
   class(res) <- c(""effectsize_table"", ""see_effectsize_table"", class(res))
   attr(res, ""ci"") <- ci
-  attr(res, ""ci_method"") <- if (exists(""ci_method"")) ci_method
+  # attr(res, ""ci_method"") <- ci_method
   attr(res, ""adjust"") <- adjust
   return(res)
 }

---FILE: R/convert_tF_to_anova.R---
@@ -158,6 +158,7 @@ F_to_f <- function(f, df, df_error, ci = 0.9, squared = FALSE, ...) {
       res_eta$Eta2_partial / (1 - res_eta$Eta2_partial)
   )
 
+  ci_method <- NULL
   if (is.numeric(ci)) {
     res$CI <- res_eta$CI
     res$CI_low <- res_eta$CI_low / (1 - res_eta$CI_low)
@@ -174,7 +175,7 @@ F_to_f <- function(f, df, df_error, ci = 0.9, squared = FALSE, ...) {
 
   class(res) <- c(""effectsize_table"", ""see_effectsize_table"", class(res))
   attr(res, ""ci"") <- ci
-  attr(res, ""ci_method"") <- if (exists(""ci_method"")) ci_method
+  attr(res, ""ci_method"") <- ci_method
   return(res)
 }
 
@@ -207,6 +208,7 @@ t_to_f2 <- function(t, df_error, ci = 0.9, squared = TRUE, ...) {
     stop(""'es' must be 'eta2', 'epsilon2', or 'omega2'."")
   )
 
+  ci_method <- NULL
   if (is.numeric(ci)) {
     stopifnot(length(ci) == 1, ci < 1, ci > 0)
     res$CI <- ci
@@ -223,6 +225,6 @@ t_to_f2 <- function(t, df_error, ci = 0.9, squared = TRUE, ...) {
 
   class(res) <- c(""effectsize_table"", ""see_effectsize_table"", class(res))
   attr(res, ""ci"") <- ci
-  attr(res, ""ci_method"") <- if (exists(""ci_method"")) ci_method
+  attr(res, ""ci_method"") <- ci_method
   return(res)
 }

---FILE: R/convert_tFz_to_d.R---
@@ -14,6 +14,7 @@ t_to_d <- function(t, df_error, paired = FALSE, ci = 0.95, pooled, ...) {
 
   res <- data.frame(d = paired * t / sqrt(df_error))
 
+  ci_method <- NULL
   if (is.numeric(ci)) {
     stopifnot(length(ci) == 1, ci < 1, ci > 0)
     res$CI <- ci
@@ -31,7 +32,7 @@ t_to_d <- function(t, df_error, paired = FALSE, ci = 0.95, pooled, ...) {
 
   class(res) <- c(""effectsize_table"", ""see_effectsize_table"", class(res))
   attr(res, ""ci"") <- ci
-  attr(res, ""ci_method"") <- if (exists(""ci_method"")) ci_method
+  attr(res, ""ci_method"") <- ci_method
   return(res)
 }
 
@@ -59,6 +60,7 @@ z_to_d <- function(z, n, paired = FALSE, ci = 0.95, pooled, ...) {
 
   res <- data.frame(d = paired * z / sqrt(n))
 
+  ci_method <- NULL
   if (is.numeric(ci)) {
     stopifnot(length(ci) == 1, ci < 1, ci > 0)
     res$CI <- ci
@@ -77,7 +79,7 @@ z_to_d <- function(z, n, paired = FALSE, ci = 0.95, pooled, ...) {
 
   class(res) <- c(""effectsize_table"", ""see_effectsize_table"", class(res))
   attr(res, ""ci"") <- ci
-  attr(res, ""ci_method"") <- if (exists(""ci_method"")) ci_method
+  attr(res, ""ci_method"") <- ci_method
   return(res)
 }
 

---FILE: R/convert_tFz_to_r.R---
@@ -93,6 +93,7 @@
 t_to_r <- function(t, df_error, ci = 0.95, ...) {
   res <- data.frame(r = t / sqrt(t^2 + df_error))
 
+  ci_method <- NULL
   if (is.numeric(ci)) {
     stopifnot(length(ci) == 1, ci < 1, ci > 0)
     res$CI <- ci
@@ -110,7 +111,7 @@ t_to_r <- function(t, df_error, ci = 0.95, ...) {
 
   class(res) <- c(""effectsize_table"", ""see_effectsize_table"", class(res))
   attr(res, ""ci"") <- ci
-  attr(res, ""ci_method"") <- if (exists(""ci_method"")) ci_method
+  attr(res, ""ci_method"") <- ci_method
   return(res)
 }
 
@@ -124,6 +125,7 @@ t_to_r <- function(t, df_error, ci = 0.95, ...) {
 z_to_r <- function(z, n, ci = 0.95, ...) {
   res <- data.frame(r = z / sqrt(z^2 + n))
 
+  ci_method <- NULL
   if (is.numeric(ci)) {
     stopifnot(length(ci) == 1, ci < 1, ci > 0)
     res$CI <- ci
@@ -142,7 +144,7 @@ z_to_r <- function(z, n, ci = 0.95, ...) {
 
   class(res) <- c(""effectsize_table"", ""see_effectsize_table"", class(res))
   attr(res, ""ci"") <- ci
-  attr(res, ""ci_method"") <- if (exists(""ci_method"")) ci_method
+  attr(res, ""ci_method"") <- ci_method
   return(res)
 }
 

---FILE: R/print.effectsize_table.R---
@@ -25,6 +25,7 @@ format.effectsize_table <- function(x, digits = 2, ...) {
   colnames(x)[i] <- labs[i]
 
   attr(x, ""ci"") <- NULL
+  attr(x, ""ci_method"") <- NULL
 
   insight::format_table(x, digits = digits, ci_digits = digits, preserve_attributes = TRUE, ...)
 }

---FILE: R/rank_effectsizes.R---
@@ -132,6 +132,7 @@ rank_biserial <- function(x, y = NULL, data = NULL, mu = 0,
   out <- data.frame(r_rank_biserial = r_rbs)
 
   ## CI
+  ci_method <- NULL
   if (is.numeric(ci)) {
     if (requireNamespace(""boot"", quietly = TRUE)) {
       out <- cbind(out, .rbs_ci_boot(
@@ -145,6 +146,7 @@ rank_biserial <- function(x, y = NULL, data = NULL, mu = 0,
 
       ci_method <- list(method = ""bootstrap"", iterations = iterations)
     } else {
+      ci <- NULL
       warning(""For CIs, the 'boot' package must be installed."")
     }
   }
@@ -153,7 +155,7 @@ rank_biserial <- function(x, y = NULL, data = NULL, mu = 0,
   attr(out, ""paired"") <- paired
   attr(out, ""mu"") <- mu
   attr(out, ""ci"") <- ci
-  attr(out, ""ci_method"") <- if (exists(""ci_method"")) ci_method
+  attr(out, ""ci_method"") <- ci_method
   return(out)
 }
 
@@ -194,18 +196,20 @@ rank_epsilon_squared <- function(x, groups, data = NULL, ci = 0.95, iterations =
   out <- data.frame(rank_epsilon_squared = E)
 
   ## CI
+  ci_method <- NULL
   if (is.numeric(ci)) {
     if (requireNamespace(""boot"", quietly = TRUE)) {
       out <- cbind(out, .repsilon_ci(data, ci, iterations))
       ci_method <- list(method = ""bootstrap"", iterations = iterations)
     } else {
+      ci <- NULL
       warning(""'boot' package required for estimating CIs for Glass' delta. Please install the package and try again."", call. = FALSE)
     }
   }
 
   class(out) <- c(""effectsize_table"", ""see_effectsize_table"", class(out))
   attr(out, ""ci"") <- ci
-  attr(out, ""ci_method"") <- if (exists(""ci_method"")) ci_method
+  attr(out, ""ci_method"") <- ci_method
   return(out)
 }
 
@@ -229,18 +233,20 @@ kendalls_w <- function(x, groups, blocks, data = NULL, ci = 0.95, iterations = 2
   out <- data.frame(Kendalls_W = W)
 
   ## CI
+  ci_method <- NULL
   if (is.numeric(ci)) {
     if (requireNamespace(""boot"", quietly = TRUE)) {
       out <- cbind(out, .kendalls_w_ci(data, ci, iterations))
       ci_method <- list(method = ""bootstrap"", iterations = iterations)
     } else {
+      ci <- NULL
       warning(""'boot' package required for estimating CIs for Glass' delta. Please install the package and try again."", call. = FALSE)
     }
   }
 
   class(out) <- c(""effectsize_table"", ""see_effectsize_table"", class(out))
   attr(out, ""ci"") <- ci
-  attr(out, ""ci_method"") <- if (exists(""ci_method"")) ci_method
+  attr(out, ""ci_method"") <- ci_method
   return(out)
 }
 

---FILE: R/xtab.R---
@@ -231,6 +231,7 @@ oddsratio <- function(x, y = NULL, ci = 0.95, log = FALSE, ...) {
 
   res <- data.frame(Odds_ratio = OR)
 
+  ci_method <- NULL
   if (is.numeric(ci)) {
     stopifnot(length(ci) == 1, ci < 1, ci > 0)
     res$CI <- ci
@@ -255,7 +256,7 @@ oddsratio <- function(x, y = NULL, ci = 0.95, log = FALSE, ...) {
 
   class(res) <- c(""effectsize_table"", ""see_effectsize_table"", class(res))
   attr(res, ""ci"") <- ci
-  attr(res, ""ci_method"") <- if (exists(""ci_method"")) ci_method
+  attr(res, ""ci_method"") <- ci_method
   attr(res, ""log"") <- log
   return(res)
 }
@@ -292,6 +293,7 @@ riskratio <- function(x, y = NULL, ci = 0.95, log = FALSE, ...) {
 
   res <- data.frame(Risk_ratio = RR)
 
+  ci_method <- NULL
   if (is.numeric(ci)) {
     stopifnot(length(ci) == 1, ci < 1, ci > 0)
     res$CI <- ci
@@ -316,7 +318,7 @@ riskratio <- function(x, y = NULL, ci = 0.95, log = FALSE, ...) {
 
   class(res) <- c(""effectsize_table"", ""see_effectsize_table"", class(res))
   attr(res, ""ci"") <- ci
-  attr(res, ""ci_method"") <- if (exists(""ci_method"")) ci_method
+  attr(res, ""ci_method"") <- ci_method
   attr(res, ""log"") <- log
   return(res)
 }
@@ -352,6 +354,7 @@ cohens_h <- function(x, y = NULL, ci = 0.95, ...) {
 
   out <- data.frame(Cohens_h = H)
 
+  ci_method <- NULL
   if (is.numeric(ci)) {
     stopifnot(length(ci) == 1, ci < 1, ci > 0)
 
@@ -368,7 +371,7 @@ cohens_h <- function(x, y = NULL, ci = 0.95, ...) {
 
   class(out) <- c(""effectsize_table"", ""see_effectsize_table"", class(out))
   attr(out, ""ci"") <- ci
-  attr(out, ""ci_method"") <- if (exists(""ci_method"")) ci_method
+  attr(out, ""ci_method"") <- ci_method
   return(out)
 }
 
@@ -414,6 +417,7 @@ cohens_g <- function(x, y = NULL, ci = 0.95, ...) {
 
   out <- data.frame(Cohens_g = g)
 
+  ci_method <- NULL
   if (is.numeric(ci)) {
     n <- sum(b) + sum(c)
     k <- P * n
@@ -433,7 +437,7 @@ cohens_g <- function(x, y = NULL, ci = 0.95, ...) {
 
   class(out) <- c(""effectsize_table"", ""see_effectsize_table"", class(out))
   attr(out, ""ci"") <- ci
-  attr(out, ""ci_method"") <- if (exists(""ci_method"")) ci_method
+  attr(out, ""ci_method"") <- ci_method
   return(out)
 }
 ",True,False,Implementation / Logic,6
easystats,effectsize,523c051b5585bf33d97fca918bf80af5b913e443,mattansb,35330040+mattansb@users.noreply.github.com,2021-02-04T15:21:39Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-02-04T15:21:39Z,"fix covecov badge

@IndrajeetPatil found it (:",README.Rmd;README.md,True,False,True,False,3,3,6,"---FILE: README.Rmd---
@@ -42,7 +42,7 @@ The goal of this package is to provide utilities to work with indices of effect
 [![CRAN](http://www.r-pkg.org/badges/version/effectsize)](https://cran.r-project.org/package=effectsize)
 [![R-check](https://github.com/easystats/effectsize/workflows/R-check/badge.svg)](https://github.com/easystats/effectsize/actions)
 [![pkgdown](https://github.com/easystats/effectsize/workflows/pkgdown/badge.svg)](https://github.com/easystats/effectsize/actions)
-[![Codecov test coverage](https://codecov.io/gh/easystats/effectsize/branch/master/graph/badge.svg)](https://codecov.io/gh/easystats/effectsize?branch=master)
+[![Codecov test coverage](https://codecov.io/gh/easystats/effectsize/branch/main/graph/badge.svg)](https://codecov.io/gh/easystats/effectsize?branch=main)
 
 Run the following to install the stable release of **effectsize** from CRAN:
 

---FILE: README.md---
@@ -17,7 +17,7 @@ conversion of indices such as Cohenâs *d*, *r*, odds-ratios, etc.
 [![R-check](https://github.com/easystats/effectsize/workflows/R-check/badge.svg)](https://github.com/easystats/effectsize/actions)
 [![pkgdown](https://github.com/easystats/effectsize/workflows/pkgdown/badge.svg)](https://github.com/easystats/effectsize/actions)
 [![Codecov test
-coverage](https://codecov.io/gh/easystats/effectsize/branch/master/graph/badge.svg)](https://codecov.io/gh/easystats/effectsize?branch=master)
+coverage](https://codecov.io/gh/easystats/effectsize/branch/main/graph/badge.svg)](https://codecov.io/gh/easystats/effectsize?branch=main)
 
 Run the following to install the stable release of **effectsize** from
 CRAN:
@@ -98,7 +98,7 @@ hedges_g(mpg ~ am, data = mtcars)
 glass_delta(mpg ~ am, data = mtcars)
 ## Glass' delta |         95% CI
 ## -----------------------------
-## -1.17        | [-1.91, -0.69]
+## -1.17        | [-1.81, -0.64]
 ```
 
 ### ANOVAs (Eta<sup>2</sup>, Omega<sup>2</sup>, â¦)",False,True,Documentation / Formatting,6
easystats,effectsize,566a3909221c441660069b7687f382a54020dd80,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-23T07:34:01Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-23T07:34:01Z,fix test due to addition of ci attribute,tests/testthat/test-eta_squared_etc.R,False,True,True,False,2,1,3,"---FILE: tests/testthat/test-eta_squared_etc.R---
@@ -12,7 +12,8 @@ if (require(""testthat"") && require(""effectsize"")) {
     testthat::expect_error(eta_squared(m), regexp = NA)
     testthat::expect_equal(
       eta_squared(m)[,-1],
-      F_to_eta2(3, 1, 1)
+      F_to_eta2(3, 1, 1),
+      ignore_attr = TRUE
     )
   })
 ",True,False,Implementation / Logic,6
easystats,effectsize,d2f4d6d00e8411a8fc31a38a0e17823a69b3989a,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-23T07:23:17Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-23T07:23:17Z,fix printing due to added attributes,R/print.effectsize_table.R,False,True,True,False,2,0,2,"---FILE: R/print.effectsize_table.R---
@@ -24,6 +24,8 @@ format.effectsize_table <- function(x, digits = 2, ...) {
   labs <- get_effectsize_label(colnames(x))
   colnames(x)[i] <- labs[i]
 
+  attr(x, ""ci"") <- NULL
+
   insight::format_table(x, digits = digits, ci_digits = digits, preserve_attributes = TRUE, ...)
 }
 ",True,False,Implementation / Logic,6
easystats,effectsize,434024ad41ad8045a85c01757d7ae17a3518e874,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-23T07:23:08Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-23T07:23:08Z,fix docs mismatch,man/t_to_r.Rd,False,False,False,False,1,1,2,"---FILE: man/t_to_r.Rd---
@@ -13,7 +13,7 @@ t_to_d(t, df_error, paired = FALSE, ci = 0.95, pooled, ...)
 
 z_to_d(z, n, paired = FALSE, ci = 0.95, pooled, ...)
 
-F_to_d(f, df, df_error, paired = FALSE, ci = 0.95, pooled, ...)
+F_to_d(f, df, df_error, paired = FALSE, ci = 0.95, ...)
 
 t_to_r(t, df_error, ci = 0.95, ...)
 ",False,False,Documentation / Formatting,7
easystats,effectsize,891068c5366b968b9c8742c7fb09e1a0e123eb4a,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-18T17:53:46Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-18T17:53:46Z,"Rollback to R3.4

#277
https://github.com/easystats/easystats/issues/98",.github/workflows/R-check.yaml;DESCRIPTION;NEWS.md,False,False,False,False,16,8,24,"---FILE: .github/workflows/R-check.yaml---
@@ -27,9 +27,9 @@ jobs:
           - {os: windows-latest, r: 'oldrel'}
           - {os: macOS-latest,   r: 'oldrel'}
           - {os: ubuntu-16.04,   r: 'oldrel',  rspm: ""https://packagemanager.rstudio.com/cran/__linux__/xenial/latest""}
-          # - {os: windows-latest, r: '3.5.0'}
-          # - {os: macOS-latest,   r: '3.5.0'}
-          # - {os: ubuntu-16.04,   r: '3.5.0',   rspm: ""https://packagemanager.rstudio.com/cran/__linux__/xenial/latest""}
+          - {os: windows-latest, r: '3.4.0'}
+          - {os: macOS-latest,   r: '3.4.0'}
+          - {os: ubuntu-16.04,   r: '3.4.0',   rspm: ""https://packagemanager.rstudio.com/cran/__linux__/xenial/latest""}
 
     env:
       R_REMOTES_NO_ERRORS_FROM_WARNINGS: true

---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Package: effectsize
 Type: Package
 Title: Indices of Effect Size and Standardized Parameters
-Version: 0.4.3
+Version: 0.4.3.1
 Authors@R: c(
     person(""Mattan S."", 
         ""Ben-Shachar"", 
@@ -36,11 +36,11 @@ URL: https://easystats.github.io/effectsize/
 BugReports: https://github.com/easystats/effectsize/issues/
 Description: Provide utilities to work with indices of effect size and standardized parameters for a wide variety of models (see support list of insight; LÃ¼decke, Waggoner & Makowski (2019) <doi:10.21105/joss.01412>), allowing computation and conversion of indices such as Cohen's d, r, odds, etc.
 Depends:
-    R (>= 3.6)
+    R (>= 3.4)
 Imports:
-    bayestestR (>= 0.8.0),
-    insight (>= 0.12.0),
-    parameters (>= 0.11.0),
+    bayestestR (>= 0.8.1),
+    insight (>= 0.12.0.1),
+    parameters (>= 0.11.0.1),
     stats,
     utils
 Suggests:
@@ -74,6 +74,10 @@ Suggests:
     see,
     testthat,
     tidyr
+Remotes:
+    easystats/bayestestR,
+    easystats/insight,
+    easystats/parameters
 RoxygenNote: 7.1.1
 Language: en-GB
 VignetteBuilder: knitr

---FILE: NEWS.md---
@@ -1,3 +1,7 @@
+# effectsize 0.4.3.1
+
+`effectsize` now supports `R >= 3.4`.
+
 # effectsize 0.4.3
 
 ## Breaking Changes",False,False,Documentation / Formatting,6
easystats,effectsize,9006f18242525daedc9cc1887e77eb26bb449292,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-17T06:25:39Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-17T06:25:39Z,"fix test + 3.5

fix adjust test
roll back to 3.5",.github/workflows/R-check.yaml;DESCRIPTION;NEWS.md;tests/testthat/test-adjust.R,False,True,True,False,7,11,18,"---FILE: .github/workflows/R-check.yaml---
@@ -27,9 +27,9 @@ jobs:
           - {os: windows-latest, r: 'oldrel'}
           - {os: macOS-latest,   r: 'oldrel'}
           - {os: ubuntu-16.04,   r: 'oldrel',  rspm: ""https://packagemanager.rstudio.com/cran/__linux__/xenial/latest""}
-          # - {os: windows-latest, r: '3.5.0'}
-          # - {os: macOS-latest,   r: '3.5.0'}
-          # - {os: ubuntu-16.04,   r: '3.5.0',   rspm: ""https://packagemanager.rstudio.com/cran/__linux__/xenial/latest""}
+          - {os: windows-latest, r: '3.5.0'}
+          - {os: macOS-latest,   r: '3.5.0'}
+          - {os: ubuntu-16.04,   r: '3.5.0',   rspm: ""https://packagemanager.rstudio.com/cran/__linux__/xenial/latest""}
 
     env:
       R_REMOTES_NO_ERRORS_FROM_WARNINGS: true

---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Package: effectsize
 Type: Package
 Title: Indices of Effect Size and Standardized Parameters
-Version: 0.4.3.1
+Version: 0.4.3
 Authors@R: c(
     person(""Mattan S."", 
         ""Ben-Shachar"", 
@@ -36,7 +36,7 @@ URL: https://easystats.github.io/effectsize/
 BugReports: https://github.com/easystats/effectsize/issues/
 Description: Provide utilities to work with indices of effect size and standardized parameters for a wide variety of models (see support list of insight; LÃ¼decke, Waggoner & Makowski (2019) <doi:10.21105/joss.01412>), allowing computation and conversion of indices such as Cohen's d, r, odds, etc.
 Depends:
-    R (>= 3.6)
+    R (>= 3.5)
 Imports:
     bayestestR (>= 0.8.0),
     insight (>= 0.12.0),

---FILE: NEWS.md---
@@ -1,9 +1,3 @@
-# effectsize 0.4.4
-
-## Bug fixes
-
-- Fixed bug in `adjust()` when `multilevel` was set to `TRUE`.
-
 # effectsize 0.4.3
 
 ## Breaking Changes
@@ -24,6 +18,7 @@
 
 ## Bug fixes
 
+- `adjust()` properly works when `multilevel = TRUE`.
 - `cohens_d()` family / `sd_pooled()` now properly fails when given a missing column name.
 
 ## Changes

---FILE: tests/testthat/test-adjust.R---
@@ -1,6 +1,7 @@
 if (require(""testthat"") && require(""effectsize"")) {
   data(iris)
   test_that(""adjust multilevel"", {
+    skip_if_not_installed(""lme4"")
     adj <- effectsize::adjust(iris[c(""Sepal.Length"", ""Species"")], multilevel = TRUE, bayesian = FALSE)
     expect_equal(
       head(adj$Sepal.Length),",True,False,Documentation / Formatting,6
easystats,effectsize,bc3279a0f3f190d93fdb39fead5e7787235313d2,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-15T14:47:11Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-15T14:47:11Z,fix winbuild note/warning,R/convert_between_anova.R;R/effectsize.R;man/effectsize.Rd;man/eta2_to_f2.Rd,False,True,True,False,14,6,20,"---FILE: R/convert_between_anova.R---
@@ -7,9 +7,9 @@
 #' @details
 #' Any measure of variance explained can be converted to a corresponding Cohen's
 #' *f* via:
-#' \cr
+#' \cr\cr
 #' \deqn{\text{Cohen's }f^2 = \frac{\eta^2}{1 - \eta^2}}
-#' \cr
+#' \cr\cr
 #' \deqn{\eta^2 = \frac{f^2}{1 + f^2}}
 #' \cr\cr
 #' If a partial Eta-Squared is used, the resulting Cohen's *f* is a

---FILE: R/effectsize.R---
@@ -54,6 +54,8 @@
 #'
 #' ## Bayesian Hypothesis Testing
 #' ## ---------------------------
+#' \donttest{
+#' \dontrun{
 #' if (require(BayesFactor)) {
 #'   bf1 <- ttestBF(mtcars$mpg[mtcars$am == 1], mtcars$mpg[mtcars$am == 0])
 #'   effectsize(bf1, test = NULL)
@@ -66,7 +68,8 @@
 #'   effectsize(bf3, test = NULL)
 #'   effectsize(bf3, type = ""oddsratio"", test = NULL)
 #' }
-#'
+#' }
+#' }
 #'
 #' ## Models and Anova Tables
 #' ## -----------------------
@@ -76,6 +79,7 @@
 #' anova_table <- anova(fit)
 #' effectsize(anova_table)
 #' effectsize(anova_table, type = ""epsilon"")
+#'
 #' @export
 effectsize <- function(model, ...) {
   UseMethod(""effectsize"")

---FILE: man/effectsize.Rd---
@@ -78,6 +78,8 @@ effectsize(Aov, type = ""omega"")
 
 ## Bayesian Hypothesis Testing
 ## ---------------------------
+\donttest{
+\dontrun{
 if (require(BayesFactor)) {
   bf1 <- ttestBF(mtcars$mpg[mtcars$am == 1], mtcars$mpg[mtcars$am == 0])
   effectsize(bf1, test = NULL)
@@ -90,7 +92,8 @@ if (require(BayesFactor)) {
   effectsize(bf3, test = NULL)
   effectsize(bf3, type = ""oddsratio"", test = NULL)
 }
-
+}
+}
 
 ## Models and Anova Tables
 ## -----------------------
@@ -100,6 +103,7 @@ effectsize(fit)
 anova_table <- anova(fit)
 effectsize(anova_table)
 effectsize(anova_table, type = ""epsilon"")
+
 }
 \seealso{
 Other effect size indices: 

---FILE: man/eta2_to_f2.Rd---
@@ -27,9 +27,9 @@ Convert between ANOVA effect sizes
 \details{
 Any measure of variance explained can be converted to a corresponding Cohen's
 \emph{f} via:
-\cr
+\cr\cr
 \deqn{\text{Cohen's }f^2 = \frac{\eta^2}{1 - \eta^2}}
-\cr
+\cr\cr
 \deqn{\eta^2 = \frac{f^2}{1 + f^2}}
 \cr\cr
 If a partial Eta-Squared is used, the resulting Cohen's \emph{f} is a",True,False,Documentation / Formatting,6
easystats,effectsize,12d31049d9482103c71b5ae6666edd25de644781,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-09T15:51:38Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-09T15:51:38Z,minor fix to vignette,vignettes/simple_htests.Rmd,True,False,True,False,1,7,8,"---FILE: vignettes/simple_htests.Rmd---
@@ -55,7 +55,7 @@ t.test(mpg ~ am, data = mtcars, var.equal = TRUE)
 cohens_d(mpg ~ am, data = mtcars)
 ```
 
-Hedge's *g* provides a bias correction for small sample sizes ($N \< 20$).
+Hedge's *g* provides a bias correction for small sample sizes ($N < 20$).
 
 ```{r}
 hedges_g(mpg ~ am, data = mtcars)
@@ -144,12 +144,6 @@ cramers_v(O, p = E, rescale.p = TRUE)
 phi(O, p = E, rescale.p = TRUE)
 ```
 
-```{r}
-cramers_v(Music)
-
-phi(Music)
-```
-
 These can also be extracted from the equivalent Bayesian test:
 
 ```{r}",False,True,Documentation / Formatting,4
easystats,effectsize,52e8dc49b62a748b68df0c908684c42c0af5f7f5,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-09T14:36:42Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-09T14:36:42Z,fix: rank-eta - set groups numerically,R/rank_effectsizes.R,False,True,True,False,1,1,2,"---FILE: R/rank_effectsizes.R---
@@ -411,7 +411,7 @@ kendalls_w <- function(x, groups, blocks, data = NULL, ci = 0.95, iterations = 2
       stop(""Formula must have the 'outcome ~ group'."", call. = FALSE)
     }
   } else if (inherits(x, ""list"")) {
-    groups <- rep(names(x), sapply(x, length))
+    groups <- rep(seq_along(x), sapply(x, length))
     x <- unsplit(x, groups)
   } else  if (is.character(x)) {
     x <- data[[x]]",True,False,Implementation / Logic,6
easystats,effectsize,703f9e444d50ad0e7b55484650390927d638a802,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-09T08:31:55Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-09T08:31:55Z,"fix: R-CHECK errors

various minor fixes",DESCRIPTION;NAMESPACE;R/adjust.R;R/cohens_d.R;R/effectsize.R;R/print.effectsize_table.R;R/rank_effectsizes.R;man/adjust.Rd;man/cohens_d.Rd;man/print.effectsize_table.Rd;man/rank_biserial.Rd;tests/testthat/test-cramers_v_etc.R;tests/testthat/test-rankES.R;tests/testthat/test-standardized_differences.R;vignettes/from_test_statistics.Rmd;vignettes/interpret.Rmd;vignettes/standardize_parameters.Rmd,True,True,True,False,90,77,167,"---FILE: DESCRIPTION---
@@ -60,6 +60,7 @@ Suggests:
     lm.beta,
     lme4,
     lmerTest,
+    MASS,
     mediation,
     modelbased,
     MuMIn,

---FILE: NAMESPACE---
@@ -239,6 +239,7 @@ importFrom(stats,qf)
 importFrom(stats,qlogis)
 importFrom(stats,qnorm)
 importFrom(stats,qt)
+importFrom(stats,reshape)
 importFrom(stats,residuals)
 importFrom(stats,sd)
 importFrom(stats,setNames)

---FILE: R/adjust.R---
@@ -43,7 +43,7 @@
 #' adjust(attitude, effect = ""complaints_LMH"", select = ""rating"", multilevel = TRUE)
 #' }
 #' }
-#' if(require(""bayestestR"")){
+#' if(require(""bayestestR"") && require(""MASS"")){
 #' # Generate data
 #' data <- bayestestR::simulate_correlation(n=100, r=0.7)
 #' data$V2 <- (5 * data$V2) + 20  # Add intercept
@@ -143,13 +143,13 @@ data_adjust <- adjust
   if (additive) {
     # Bayesian
     if (bayesian) {
-      if (!requireNamespace(""rstanarm"")) {
+      if (!requireNamespace(""rstanarm"", quietly = TRUE)) {
         stop(""This function needs `rstanarm` to be installed. Please install by running `install.packages('rstanarm')`."")
       }
       model <- rstanarm::stan_gamm4(stats::as.formula(formula), random = formula_random, data = data, refresh = 0)
       # Frequentist
     } else {
-      if (!requireNamespace(""gamm4"")) {
+      if (!requireNamespace(""gamm4"", quietly = TRUE)) {
         stop(""This function needs `gamm4` to be installed. Please install by running `install.packages('gamm4')`."")
       }
       model <- gamm4::gamm4(stats::as.formula(formula), random = formula_random, data = data)
@@ -159,7 +159,7 @@ data_adjust <- adjust
   } else {
     # Bayesian
     if (bayesian) {
-      if (!requireNamespace(""rstanarm"")) {
+      if (!requireNamespace(""rstanarm"", quietly = TRUE)) {
         stop(""This function needs `rstanarm` to be installed. Please install by running `install.packages('rstanarm')`."")
       }
       if (multilevel) {
@@ -170,7 +170,7 @@ data_adjust <- adjust
       # Frequentist
     } else {
       if (multilevel) {
-        if (!requireNamespace(""lme4"")) {
+        if (!requireNamespace(""lme4"", quietly = TRUE)) {
           stop(""This function needs `lme4` to be installed. Please install by running `install.packages('lme4')`."")
         }
         model <- insight::get_residuals(lme4::lmer(paste(formula, formula_random), data = data))

---FILE: R/cohens_d.R---
@@ -56,7 +56,7 @@
 #' cohens_d(mpg ~ am, data = mtcars, pooled_sd = FALSE)
 #' cohens_d(mpg ~ am, data = mtcars, mu = -5)
 #' hedges_g(mpg ~ am, data = mtcars)
-#' glass_delta(mpg ~ am, data = mtcars)
+#' if (require(boot)) glass_delta(mpg ~ am, data = mtcars)
 #'
 #' print(cohens_d(mpg ~ am, data = mtcars), append_CL = TRUE)
 #' @references
@@ -255,7 +255,11 @@ glass_delta <- function(x, y = NULL, data = NULL, mu = 0, ci = 0.95, iterations
       out$CI_low <- ts[1] * sqrt(hn)
       out$CI_high <- ts[2] * sqrt(hn)
     } else if (type == ""delta"") {
-      out <- cbind(out, .delta_ci(x, y, mu = mu, ci = ci, ...))
+      if (requireNamespace(""boot"", quietly = TRUE)) {
+        out <- cbind(out, .delta_ci(x, y, mu = mu, ci = ci, ...))
+      } else {
+        warning(""'boot' package required for estimating CIs for Glass' delta. Please install the package and try again."", call. = FALSE)
+      }
     }
   }
 
@@ -370,11 +374,6 @@ glass_delta <- function(x, y = NULL, data = NULL, mu = 0, ci = 0.95, iterations
 }
 
 .delta_ci <- function(x, y, mu = 0, ci = 0.95, iterations = 200) {
-  if (!requireNamespace(""boot"")) {
-    warning(""'boot' package required for estimating CIs for Glass' delta. Please install the package and try again."", call. = FALSE)
-    return(NULL)
-  }
-
   boot_delta <- function(data, .i, mu = 0) {
     .x <- sample(x, replace = TRUE)
     .y <- sample(y, replace = TRUE)

---FILE: R/effectsize.R---
@@ -86,7 +86,7 @@ effectsize <- function(model, ...) {
 #' @importFrom insight get_data get_parameters
 #' @importFrom bayestestR describe_posterior
 effectsize.BFBayesFactor <- function(model, type = NULL, verbose = TRUE, ...) {
-  if (!requireNamespace(""BayesFactor"")) {
+  if (!requireNamespace(""BayesFactor"", quietly = TRUE)) {
     stop(""This function requires 'BayesFactor' to work. Please install it."")
   }
 

---FILE: R/print.effectsize_table.R---
@@ -92,7 +92,8 @@ print.equivalence_test_effectsize <- function(x, digits = 2, ...) {
 #' @export
 #' @rdname print.effectsize_table
 #' @param append_CL Should the Common Language Effect Sizes be printed as well?
-#'   Not applicable to Glass' Delta (See [d_to_common_language()])
+#'   Only applicable to Cohen's *d*, Hedges' *g* for independent samples of
+#'   equal variance (pooled sd) (See [d_to_common_language()])
 print.effectsize_difference <- function(x, digits = 2, append_CL = FALSE, ...) {
   x_orig <- x
 
@@ -130,13 +131,17 @@ print.effectsize_difference <- function(x, digits = 2, append_CL = FALSE, ...) {
   print.effectsize_table(x, digits = digits, ...)
 
 
-  if (append_CL && any(colnames(x_orig) %in% c(""Cohens_d"", ""Hedges_g"")) && !attr(x_orig, ""paired"")) {
-    # Common lang
-    cl <- d_to_common_language(x_orig[[any(colnames(x_orig) %in% c(""Cohens_d"", ""Hedges_g""))]])
-    cl <- lapply(cl, insight::format_value, as_percent = TRUE, digits = digits)
-    cl <- data.frame(cl, check.names = FALSE)
-    cat(insight::export_table(cl, digits = digits,
-                              caption = c(""\n\n# Common Language Effect Sizes"", ""blue""), ...))
+  if (append_CL) {
+    if (any(colnames(x_orig) %in% c(""Cohens_d"", ""Hedges_g"")) &&
+        attr(x_orig, ""pooled_sd"") &&
+        !attr(x_orig, ""paired"")) {
+      # Common lang
+      cl <- d_to_common_language(x_orig[[any(colnames(x_orig) %in% c(""Cohens_d"", ""Hedges_g""))]])
+      cl <- lapply(cl, insight::format_value, as_percent = TRUE, digits = digits)
+      cl <- data.frame(cl, check.names = FALSE)
+      cat(insight::export_table(cl, digits = digits,
+                                caption = c(""\n\n# Common Language Effect Sizes"", ""blue""), ...))
+    }
   }
 
   invisible(x_orig)

---FILE: R/rank_effectsizes.R---
@@ -56,6 +56,7 @@
 #' @family effect size indices
 #'
 #' @examples
+#' \donttest{
 #' A <- c(48, 48, 77, 86, 85, 85)
 #' B <- c(14, 34, 34, 77)
 #' rank_biserial(A, B)
@@ -79,6 +80,7 @@
 #'                           t = warpbreaks$tension),
 #'                 FUN = mean)
 #' kendalls_w(x ~ w | t, data = wb)
+#' }
 #'
 #' @references
 #' - Cureton, E. E. (1956). Rank-biserial correlation. Psychometrika, 21(3), 287-290.
@@ -127,14 +129,18 @@ rank_biserial <- function(x, y = NULL, data = NULL, mu = 0,
 
   ## CI
   if (is.numeric(ci)) {
-    out <- cbind(out, .rbs_ci_boot(
-      x,
-      y,
-      mu = mu,
-      paired = paired,
-      ci = ci,
-      iterations = iterations
-    ))
+    if (requireNamespace(""boot"", quietly = TRUE)) {
+      out <- cbind(out, .rbs_ci_boot(
+        x,
+        y,
+        mu = mu,
+        paired = paired,
+        ci = ci,
+        iterations = iterations
+      ))
+    } else {
+      warning(""For CIs, the 'boot' package must be installed."")
+    }
   }
 
   class(out) <- c(""effectsize_difference"", ""effectsize_table"", ""see_effectsize_table"", class(out))
@@ -179,7 +185,11 @@ rank_epsilon_squared <- function(x, groups, data = NULL, ci = 0.95, iterations =
 
   ## CI
   if (is.numeric(ci)) {
-    out <- cbind(out, .repsilon_ci(data, ci, iterations))
+    if (requireNamespace(""boot"", quietly = TRUE)) {
+      out <- cbind(out, .repsilon_ci(data, ci, iterations))
+    } else {
+      warning(""'boot' package required for estimating CIs for Glass' delta. Please install the package and try again."", call. = FALSE)
+    }
   }
 
   class(out) <- c(""effectsize_table"", ""see_effectsize_table"", class(out))
@@ -207,7 +217,11 @@ kendalls_w <- function(x, groups, blocks, data = NULL, ci = 0.95, iterations = 2
 
   ## CI
   if (is.numeric(ci)) {
-    out <- cbind(out, .kendalls_w_ci(data, ci, iterations))
+    if (requireNamespace(""boot"", quietly = TRUE)) {
+      out <- cbind(out, .kendalls_w_ci(data, ci, iterations))
+    } else {
+      warning(""'boot' package required for estimating CIs for Glass' delta. Please install the package and try again."", call. = FALSE)
+    }
   }
 
   class(out) <- c(""effectsize_table"", class(out))
@@ -304,12 +318,6 @@ kendalls_w <- function(x, groups, blocks, data = NULL, ci = 0.95, iterations = 2
 #' @keywords internal
 #' @importFrom bayestestR ci
 .rbs_ci_boot <- function(x, y, mu = 0, paired = FALSE, ci = 0.95, iterations = 200) {
-
-  if (!requireNamespace(""boot"")) {
-    warning(""For CIs, the 'boot' package must be installed."")
-    return(NULL)
-  }
-
   stopifnot(length(ci) == 1, ci < 1, ci > 0)
 
   if (paired) {
@@ -346,11 +354,6 @@ kendalls_w <- function(x, groups, blocks, data = NULL, ci = 0.95, iterations = 2
 
 #' @keywords internal
 .repsilon_ci <- function(data, ci, iterations){
-  if (!requireNamespace(""boot"")) {
-    warning(""'boot' package required for estimating CIs for Glass' delta. Please install the package and try again."", call. = FALSE)
-    return(NULL)
-  }
-
   stopifnot(length(ci) == 1, ci < 1, ci > 0)
 
   boot_r_epsilon <- function(.data, .i) {
@@ -372,11 +375,6 @@ kendalls_w <- function(x, groups, blocks, data = NULL, ci = 0.95, iterations = 2
 
 #' @keywords internal
 .kendalls_w_ci <- function(data, ci, iterations) {
-  if (!requireNamespace(""boot"")) {
-    warning(""'boot' package required for estimating CIs for Glass' delta. Please install the package and try again."", call. = FALSE)
-    return(NULL)
-  }
-
   stopifnot(length(ci) == 1, ci < 1, ci > 0)
 
   boot_w <- function(.data, .i) {
@@ -426,7 +424,7 @@ kendalls_w <- function(x, groups, blocks, data = NULL, ci = 0.95, iterations = 2
 }
 
 #' @keywords internal
-#' @importFrom stats model.frame lm
+#' @importFrom stats model.frame lm reshape
 .kendalls_w_data <- function(x, groups, blocks, data = NULL) {
   if (inherits(frm <- x, ""formula"")) {
     if ((length(frm) != 3L) ||
@@ -465,7 +463,7 @@ kendalls_w <- function(x, groups, blocks, data = NULL, ci = 0.95, iterations = 2
 
   data <- data.frame(x, groups, blocks)
 
-  data <- reshape(
+  data <- stats::reshape(
     data,
     direction = ""wide"",
     v.names = ""x"",

---FILE: man/adjust.Rd---
@@ -82,7 +82,7 @@ attitude$complaints_LMH <- cut(attitude$complaints, 3)
 adjust(attitude, effect = ""complaints_LMH"", select = ""rating"", multilevel = TRUE)
 }
 }
-if(require(""bayestestR"")){
+if(require(""bayestestR"") && require(""MASS"")){
 # Generate data
 data <- bayestestR::simulate_correlation(n=100, r=0.7)
 data$V2 <- (5 * data$V2) + 20  # Add intercept

---FILE: man/cohens_d.Rd---
@@ -123,7 +123,7 @@ cohens_d(mpg ~ am, data = mtcars)
 cohens_d(mpg ~ am, data = mtcars, pooled_sd = FALSE)
 cohens_d(mpg ~ am, data = mtcars, mu = -5)
 hedges_g(mpg ~ am, data = mtcars)
-glass_delta(mpg ~ am, data = mtcars)
+if (require(boot)) glass_delta(mpg ~ am, data = mtcars)
 
 print(cohens_d(mpg ~ am, data = mtcars), append_CL = TRUE)
 }

---FILE: man/print.effectsize_table.Rd---
@@ -23,7 +23,8 @@
 \item{digits}{Number of significant digits.}
 
 \item{append_CL}{Should the Common Language Effect Sizes be printed as well?
-Not applicable to Glass' Delta (See \code{\link[=d_to_common_language]{d_to_common_language()}})}
+Only applicable to Cohen's \emph{d}, Hedges' \emph{g} for independent samples of
+equal variance (pooled sd) (See \code{\link[=d_to_common_language]{d_to_common_language()}})}
 }
 \description{
 Printing, formatting and plotting methods for \code{effectsize} tables.

---FILE: man/rank_biserial.Rd---
@@ -111,6 +111,7 @@ Confidence Intervals are estimated using the bootstrap method.
 }
 
 \examples{
+\donttest{
 A <- c(48, 48, 77, 86, 85, 85)
 B <- c(14, 34, 34, 77)
 rank_biserial(A, B)
@@ -134,6 +135,7 @@ wb <- aggregate(warpbreaks$breaks,
                           t = warpbreaks$tension),
                 FUN = mean)
 kendalls_w(x ~ w | t, data = wb)
+}
 
 }
 \references{

---FILE: tests/testthat/test-cramers_v_etc.R---
@@ -78,23 +78,6 @@ if (require(""testthat"") && require(""effectsize"")) {
   })
 
   test_that(""oddsratio & riskratio"", {
-    data(""mtcars"")
-    testthat::expect_error(oddsratio(mtcars$am, mtcars$cyl))
-
-    m <- glm(am ~ I(cyl > 4), data = mtcars, family = binomial())
-    log_or <- oddsratio(mtcars$am, mtcars$cyl > 4, log = TRUE)
-
-    testthat::expect_equal(coef(m)[2], log_or$log_Odds_ratio,
-      ignore_attr = TRUE
-    )
-    testthat::expect_equal(confint(m)[2, ],
-      unlist(log_or[c(""CI_low"", ""CI_high"")]),
-      tolerance = 0.1, # different methods, give slightly different values
-      ignore_attr = TRUE
-    )
-
-    testthat::expect_equal(log_or, oddsratio(mtcars$cyl > 4, mtcars$am, log = TRUE))
-
     ## Risk ratio
     RCT <- rbind(
       c(30, 71),
@@ -112,6 +95,27 @@ if (require(""testthat"") && require(""effectsize"")) {
       riskratio_to_oddsratio(RR$Risk_ratio, p0),
       OR$Odds_ratio
     )
+
+
+    ## OR
+    data(""mtcars"")
+    testthat::expect_error(oddsratio(mtcars$am, mtcars$cyl))
+
+    m <- glm(am ~ I(cyl > 4), data = mtcars, family = binomial())
+    log_or <- oddsratio(mtcars$am, mtcars$cyl > 4, log = TRUE)
+
+    testthat::expect_equal(coef(m)[2], log_or$log_Odds_ratio,
+      ignore_attr = TRUE
+    )
+
+    testthat::expect_equal(log_or, oddsratio(mtcars$cyl > 4, mtcars$am, log = TRUE))
+
+    testthat::skip_if_not_installed(""MASS"")
+    testthat::expect_equal(confint(m)[2, ],
+      unlist(log_or[c(""CI_low"", ""CI_high"")]),
+      tolerance = 0.1, # different methods, give slightly different values
+      ignore_attr = TRUE
+    )
   })
 
 

---FILE: tests/testthat/test-rankES.R---
@@ -1,5 +1,6 @@
 if (require(""testthat"") && require(""effectsize"")) {
   test_that(""rank_biserial"", {
+    skip_if_not_installed(""boot"")
     x <- c(1.83,  0.50,  1.62,  2.48, 1.68, 1.88, 1.55, 3.06, 1.30)
     y <- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)
     rRB1 <- {set.seed(1); rank_biserial(x, y, paired = TRUE)}
@@ -14,6 +15,7 @@ if (require(""testthat"") && require(""effectsize"")) {
 
 
   test_that(""rank_epsilon_squared"", {
+    skip_if_not_installed(""boot"")
     x1 <- c(2.9, 3.0, 2.5, 2.6, 3.2) # normal subjects
     x2 <- c(3.8, 2.7, 4.0, 2.4)      # with obstructive airway disease
     x3 <- c(2.8, 3.4, 3.7, 2.2, 2.0) # with asbestosis
@@ -30,6 +32,7 @@ if (require(""testthat"") && require(""effectsize"")) {
 
 
   test_that(""kendalls_w"", {
+    skip_if_not_installed(""boot"")
     M1 <- structure(
       c(5.4, 5.85, 5.2, 5.5, 5.7, 5.6, 5.55, 5.75, 5.5),
       .Dim = c(3L, 3L),

---FILE: tests/testthat/test-standardized_differences.R---
@@ -85,19 +85,18 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     testthat::expect_warning(hedges_g(wt ~ am, data = mtcars, correction = TRUE))
     testthat::expect_warning(cohens_d(wt ~ am, data = mtcars, correction = TRUE))
-    testthat::expect_warning(glass_delta(wt ~ am, data = mtcars, correction = TRUE))
+    testthat::expect_warning(glass_delta(wt ~ am, data = mtcars, correction = TRUE, ci = NULL))
   })
 
   test_that(""glass_delta"", {
     # must be 2 samples
     testthat::expect_error(glass_delta(1:10))
 
+    testthat::skip_if_not_installed(""boot"")
     set.seed(8007)
     x <- glass_delta(wt ~ am, data = mtcars)
     testthat::expect_equal(colnames(x)[1], ""Glass_delta"")
     testthat::expect_equal(x[[1]], 2.200, tolerance = 0.001)
-
-    testthat::skip_if_not_installed(""boot"")
     testthat::expect_equal(x$CI_low, 1.490089, tolerance = 0.001)
     testthat::expect_equal(x$CI_high, 3.858925, tolerance = 0.001)
   })
@@ -114,8 +113,8 @@ if (require(""testthat"") && require(""effectsize"")) {
     x1 <- bayestestR::distribution_normal(1e4, mean = 0, sd = 1)
     x2 <- bayestestR::distribution_normal(1e4, mean = 1.5, sd = 2)
 
-    testthat::expect_equal(cohens_d(x1, x2)$Cohens_d, -sqrt(0.9), tolerance = 1e-2)
-    testthat::expect_equal(glass_delta(x2, x1)$Glass_delta, 1.5, tolerance = 1e-2)
+    testthat::expect_equal(cohens_d(x1, x2)[[1]], -sqrt(0.9), tolerance = 1e-2)
+    testthat::expect_equal(glass_delta(x2, x1, ci = NULL)[[1]], 1.5, tolerance = 1e-2)
   })
 
   test_that(""Missing values"", {

---FILE: vignettes/from_test_statistics.Rmd---
@@ -28,7 +28,7 @@ options(digits = 2)
 options(knitr.kable.NA = '')
 
 pkgs <- c(""effectsize"", ""afex"", ""lmerTest"", ""emmeans"", ""parameters"")
-if (!all(sapply(pkgs, requireNamespace))) {
+if (!all(sapply(pkgs, requireNamespace, quietly = TRUE))) {
   knitr::opts_chunk$set(eval = FALSE)
 } else {
   library(afex)

---FILE: vignettes/interpret.Rmd---
@@ -27,7 +27,7 @@ knitr::opts_chunk$set(comment="">"")
 options(digits=2)
 
 pkgs <- c(""effectsize"")
-if (!all(sapply(pkgs, requireNamespace))) {
+if (!all(sapply(pkgs, requireNamespace, quietly = TRUE))) {
   knitr::opts_chunk$set(eval = FALSE)
 }
 ```

---FILE: vignettes/standardize_parameters.Rmd---
@@ -28,7 +28,7 @@ options(digits = 2)
 options(knitr.kable.NA = '')
 
 pkgs <- c(""effectsize"", ""parameters"", ""correlation"")
-if (!all(sapply(pkgs, requireNamespace))) {
+if (!all(sapply(pkgs, requireNamespace, quietly = TRUE))) {
   knitr::opts_chunk$set(eval = FALSE)
 }
 ",True,True,Documentation / Formatting,6
easystats,effectsize,6571e4f1c9d7fd3f5189f7843aa00d9037a9f2f5,Daniel,mail@danielluedecke.de,2021-01-08T21:21:58Z,Daniel,mail@danielluedecke.de,2021-01-08T21:21:58Z,fix check issues,NAMESPACE;R/rank_effectsizes.R,False,True,True,False,4,3,7,"---FILE: NAMESPACE---
@@ -239,6 +239,7 @@ importFrom(stats,qf)
 importFrom(stats,qlogis)
 importFrom(stats,qnorm)
 importFrom(stats,qt)
+importFrom(stats,reshape)
 importFrom(stats,residuals)
 importFrom(stats,sd)
 importFrom(stats,setNames)

---FILE: R/rank_effectsizes.R---
@@ -484,7 +484,7 @@ kendalls_w <- function(x, groups, blocks, data = NULL, ci = 0.95, iterations = 2
 }
 
 #' @keywords internal
-#' @importFrom stats model.frame lm
+#' @importFrom stats model.frame lm reshape
 .kendalls_w_data <- function(x, groups, blocks, data = NULL) {
   if (inherits(frm <- x, ""formula"")) {
     if ((length(frm) != 3L) ||
@@ -521,9 +521,9 @@ kendalls_w <- function(x, groups, blocks, data = NULL, ci = 0.95, iterations = 2
     stop(""x, groups and blocks must be of the same length."", call. = FALSE)
   }
 
-  data <- data.frame(x, groups, blocks)
+  data <- data.frame(x, groups, blocks, stringsAsFactors = FALSE)
 
-  data <- reshape(
+  data <- stats::reshape(
     data,
     direction = ""wide"",
     v.names = ""x"",",True,False,Dependency / Package,6
easystats,effectsize,5bc93ba0e02c9d7dad0c8426bc49218b3e9c18c3,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-08T14:31:33Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-08T14:31:33Z,"""fix"" #265",NAMESPACE;R/effectsize.R,False,True,True,False,4,0,4,"---FILE: NAMESPACE---
@@ -5,6 +5,7 @@ S3method(change_scale,factor)
 S3method(change_scale,grouped_df)
 S3method(change_scale,numeric)
 S3method(effectsize,BFBayesFactor)
+S3method(effectsize,afex_aov)
 S3method(effectsize,anova)
 S3method(effectsize,aov)
 S3method(effectsize,aovlist)

---FILE: R/effectsize.R---
@@ -166,6 +166,9 @@ effectsize.anova <- function(model, type = NULL, ...) {
   f(model, ...)
 }
 
+#' @export
+effectsize.afex_aov <- effectsize.anova
+
 #' @export
 #' @rdname effectsize
 effectsize.aov <- effectsize.anova",True,False,Dependency / Package,6
easystats,effectsize,7697405d483730c0e6d891a0d922ee2a217af16e,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-06T20:21:26Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-06T20:21:26Z,"fix: verbose in effectsize.htest.t.test

https://github.com/easystats/report/issues/114",R/cohens_d.R;R/effectsize.htest.R,False,True,True,False,3,2,5,"---FILE: R/cohens_d.R---
@@ -86,7 +86,7 @@ cohens_d <- function(x,
   if (inherits(x, ""htest"")) {
     if (!grepl(""t-test"", x$method))
       stop(""'x' is not a t-test!"", call. = FALSE)
-    return(effectsize(x, type = ""d"", correction = correction, ci = ci))
+    return(effectsize(x, type = ""d"", correction = correction, ci = ci, verbose = verbose))
   }
 
 
@@ -126,7 +126,7 @@ hedges_g <- function(x,
   if (inherits(x, ""htest"")) {
     if (!grepl(""t-test"", x$method))
       stop(""'x' is not a t-test!"", call. = FALSE)
-    return(effectsize(x, type = ""g"", correction = correction, ci = ci))
+    return(effectsize(x, type = ""g"", correction = correction, ci = ci, verbose = verbose))
   }
 
   .effect_size_difference(

---FILE: R/effectsize.htest.R---
@@ -29,6 +29,7 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
                mu = model$null.value,
                paired = !grepl(""Two"", model$method),
                pooled_sd = !grepl(""Welch"", model$method),
+               verbose = verbose,
                ...)
     }
 ",True,False,Implementation / Logic,6
easystats,effectsize,73e376d19ce6167173e282efb46a18908ef75597,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-06T20:09:20Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-06T20:09:20Z,fix: digits in printing,R/print.effectsize_table.R,False,True,True,False,3,3,6,"---FILE: R/print.effectsize_table.R---
@@ -23,7 +23,7 @@ format.effectsize_table <- function(x, digits = 2, ...) {
   i <- is_effectsize_name(colnames(x))
   colnames(x)[i] <- es_info$label[es_info$name == colnames(x)[i]]
 
-  insight::format_table(x, digits = digits, preserve_attributes = TRUE, ...)
+  insight::format_table(x, digits = digits, ci_digits = digits, preserve_attributes = TRUE, ...)
 }
 
 
@@ -84,7 +84,7 @@ print.equivalence_test_effectsize <- function(x, digits = 2, ...) {
   attr(x, ""table_footer"") <- footer
   attr(x, ""table_caption"") <- caption
   attr(x, ""table_subtitle"") <- subtitle
-  print.effectsize_table(x, ...)
+  print.effectsize_table(x, digits = digits, ...)
   invisible(x_orig)
 }
 
@@ -126,7 +126,7 @@ print.effectsize_difference <- function(x, digits = 2, append_CL = FALSE, ...) {
   attr(x, ""table_footer"") <- footer
   attr(x, ""table_caption"") <- caption
   attr(x, ""table_subtitle"") <- subtitle
-  print.effectsize_table(x, ...)
+  print.effectsize_table(x, digits = digits, ...)
 
 
   if (append_CL && any(colnames(x_orig) %in% c(""Cohens_d"", ""Hedges_g"")) && !attr(x_orig, ""paired"")) {",True,False,Implementation / Logic,3
easystats,effectsize,7dc226cef402cf258491d2a31782250ea2c5bde0,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-06T13:58:49Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-06T13:58:49Z,fix: OR/RR tests,tests/testthat/test-cramers_v_etc.R;tests/testthat/test-effectsize.R,False,True,True,False,4,4,8,"---FILE: tests/testthat/test-cramers_v_etc.R---
@@ -84,10 +84,10 @@ if (require(""testthat"") && require(""effectsize"")) {
     m <- glm(am ~ I(cyl > 4), data = mtcars, family = binomial())
     log_or <- oddsratio(mtcars$am, mtcars$cyl > 4, log = TRUE)
 
-    testthat::expect_equal(coef(m)[2], -log_or$log_Odds_ratio,
+    testthat::expect_equal(coef(m)[2], log_or$log_Odds_ratio,
       ignore_attr = TRUE
     )
-    testthat::expect_equal(-rev(confint(m)[2, ]),
+    testthat::expect_equal(confint(m)[2, ],
       unlist(log_or[c(""CI_low"", ""CI_high"")]),
       tolerance = 0.1, # different methods, give slightly different values
       ignore_attr = TRUE
@@ -102,7 +102,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     )
     OR <- oddsratio(RCT)
     RR <- riskratio(RCT)
-    p0 <- 30 / 130
+    p0 <- RCT[1,2] / sum(RCT[,2])
 
     testthat::expect_equal(
       oddsratio_to_riskratio(OR$Odds_ratio, p0),

---FILE: tests/testthat/test-effectsize.R---
@@ -186,7 +186,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     data(raceDolls, package = ""BayesFactor"")
     bf1 <- BayesFactor::contingencyTableBF(raceDolls, sampleType = ""poisson"", fixedMargin = ""cols"")
     testthat::expect_equal(effectsize(bf1, test = NULL)[[2]], 0.164, tolerance = 0.01)
-    testthat::expect_equal(effectsize(bf1, test = NULL, type = ""OR"")[[2]], 0.503, tolerance = 0.03)
+    testthat::expect_equal(effectsize(bf1, test = NULL, type = ""OR"")[[2]], 1/0.503, tolerance = 0.03)
 
     bf2 <- BayesFactor::ttestBF(mtcars$mpg[mtcars$am == 1], mtcars$mpg[mtcars$am == 0])
     testthat::expect_equal(effectsize(bf2, test = NULL)[[2]], 1.30, tolerance = 0.03)",True,False,Implementation / Logic,6
easystats,effectsize,a90327670212b1ab459abed33a746590915041a3,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-06T10:02:24Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-06T10:02:24Z,"fix direction for paired

@IndrajeetPatil oops, you were right!",R/rank_effectsizes.R,False,True,True,False,25,13,38,"---FILE: R/rank_effectsizes.R---
@@ -82,6 +82,7 @@
 #' - Tomczak, M., & Tomczak, E. (2014). The need to report effect size estimates revisited. An overview of some recommended measures of effect size.
 #'
 #' @export
+#' @importFrom stats na.omit complete.cases
 rank_biserial <- function(x, y = NULL, data = NULL, mu = 0,
                           ci = 0.95, iterations = 200,
                           paired = FALSE,
@@ -93,8 +94,8 @@ rank_biserial <- function(x, y = NULL, data = NULL, mu = 0,
     return(effectsize(x, ci = ci, iterations = iterations))
   }
 
+  ## Prep data
   out <- .deal_with_cohens_d_arguments(x, y, data)
-
   x <- out$x
   y <- out$y
 
@@ -103,15 +104,24 @@ rank_biserial <- function(x, y = NULL, data = NULL, mu = 0,
     paired <- TRUE
   }
 
+  if (paired) {
+    oo <- stats::complete.cases(x, y)
+    x <- x[oo]
+    y <- y[oo]
+  } else {
+    x <- stats::na.omit(x)
+    y <- stats::na.omit(y)
+  }
+
+  ## Compute
   if (paired) {
     r_rbs <- .r_rbs_paired(x, y, mu = mu, verbose = verbose)
   } else {
     r_rbs <- .r_rbs_indep(x, y, mu = mu, verbose = verbose)
   }
-
-
   out <- data.frame(r_rank_biserial = r_rbs)
 
+  ## CI
   if (is.numeric(ci)) {
     out <- cbind(out, .rbs_ci_boot(
       x,
@@ -123,7 +133,7 @@ rank_biserial <- function(x, y = NULL, data = NULL, mu = 0,
     ))
   }
 
-  class(out) <- c(""effectsize_difference"", ""effectsize_table"", class(out)) # ""see_effectsize_table""
+  class(out) <- c(""effectsize_difference"", ""effectsize_table"", ""see_effectsize_table"", class(out))
   attr(out, ""paired"") <- paired
   attr(out, ""mu"") <- mu
   return(out)
@@ -141,20 +151,22 @@ rank_epsilon_squared <- function(x, groups, data = NULL, ci = 0.95, iterations =
     return(effectsize(x, ci = ci, iterations = iterations))
   }
 
+  ## pep data
   data <- .rank_anova_xg(x, groups, data)
   data <- stats::na.omit(data)
   x <- data$x
   groups <- data$groups
 
+  ## compute
   E <- .repsilon(x, groups)
-
   out <- data.frame(rank_epsilon_squared = E)
 
+  ## CI
   if (is.numeric(ci)) {
     out <- cbind(out, .repsilon_ci(data, ci, iterations))
   }
 
-  class(out) <- c(""effectsize_table"", class(out)) # ""see_effectsize_table""
+  class(out) <- c(""effectsize_table"", ""see_effectsize_table"", class(out))
   return(out)
 }
 
@@ -169,13 +181,15 @@ kendalls_w <- function(x, groups, blocks, data = NULL, ci = 0.95, iterations = 2
     return(effectsize(x, ci = ci, iterations = iterations))
   }
 
+  ## prep data
   data <- .kendalls_w_data(x, groups, blocks, data)
   data <- stats::na.omit(data)
 
+  ## compute
   W <- .kendalls_w(data)
-
   out <- data.frame(Kendalls_W = W)
 
+  ## CI
   if (is.numeric(ci)) {
     out <- cbind(out, .kendalls_w_ci(data, ci, iterations))
   }
@@ -230,18 +244,16 @@ kendalls_w <- function(x, groups, blocks, data = NULL, ci = 0.95, iterations = 2
   T_ <- min(r_pos, r_neg)
   n <- length(r_sign)
 
-  r_rbs <- 4 * abs(T_ - (r_pos + r_neg) / 2) / (n * (n + 1))
-  if (r_pos >= r_neg) r_rbs <- -r_rbs
+  r_rbs <- 4 * -(T_ - (r_pos + r_neg) / 2) / (n * (n + 1))
+  ## same as:
+  # r_rbs <- 4 * abs(T_ - (r_pos + r_neg) / 2) / (n * (n + 1))
+  # if (r_pos < r_neg) r_rbs <- -r_rbs
   r_rbs <- sign(r_rbs) * pmin(abs(r_rbs), 1)
   r_rbs
 }
 
 #' @keywords internal
-#' @importFrom stats na.omit
 .r_rbs_indep <- function(x, y, mu, verbose = FALSE){
-  x <- stats::na.omit(x)
-  y <- stats::na.omit(y)
-
   Ry <- ranktransform(c(x - mu, y), verbose = verbose)
   Group <- c(rep(""A"", length(x)),
              rep(""B"", length(y)))",True,False,Implementation / Logic,6
easystats,effectsize,057fb91662e416e7d1fd89bf1e457450d121d8b1,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-06T07:32:40Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-06T07:32:40Z,fix kendall's W,R/rank_effectsizes.R;man/rank_biserial.Rd,False,True,True,False,23,22,45,"---FILE: R/rank_effectsizes.R---
@@ -77,6 +77,7 @@
 #'
 #' @references
 #' - Cureton, E. E. (1956). Rank-biserial correlation. Psychometrika, 21(3), 287-290.
+#' - Kendall, M.G. (1948) Rank correlation methods. London: Griffin.
 #' - Kerby, D. S. (2014). The simple difference formula: An approach to teaching nonparametric correlation. Comprehensive Psychology, 3, 11-IT.
 #' - Tomczak, M., & Tomczak, E. (2014). The need to report effect size estimates revisited. An overview of some recommended measures of effect size.
 #'
@@ -170,11 +171,8 @@ kendalls_w <- function(x, groups, blocks, data = NULL, ci = 0.95, iterations = 2
 
   data <- .kendalls_w_data(x, groups, blocks, data)
   data <- stats::na.omit(data)
-  x <- data$x
-  groups <- data$groups
-  blocks <- data$blocks
 
-  W <- .kendalls_w(x, groups, blocks)
+  W <- .kendalls_w(data)
 
   out <- data.frame(Kendalls_W = W)
 
@@ -303,14 +301,13 @@ kendalls_w <- function(x, groups, blocks, data = NULL, ci = 0.95, iterations = 2
 
 #' @keywords internal
 #' @importFrom stats friedman.test
-.kendalls_w <- function(x, groups, blocks) {
-  model <- stats::friedman.test(x, groups, blocks)
+.kendalls_w <- function(ratings) {
+  n <- nrow(ratings)
+  m <- ncol(ratings)
 
-  Chi <- unname(model$statistic)
-  N <- length(unique(groups))
-  k <- length(unique(blocks))
-
-  W <- Chi / (N * (k - 1))
+  ratings.rank <- apply(ratings, 2, rank)
+  S <- var(apply(ratings.rank, 1, sum)) * (n - 1)
+  W <- (12 * S) / (m^2 * (n^3 - n))
 }
 
 ## CI ----
@@ -394,17 +391,10 @@ kendalls_w <- function(x, groups, blocks, data = NULL, ci = 0.95, iterations = 2
   stopifnot(length(ci) == 1, ci < 1, ci > 0)
 
   boot_w <- function(.data, .i) {
-    rp <- sample(split(.data, .data$blocks), replace = TRUE)
-    rp <- mapply(function(tmp, L) {
-      tmp$blocks <- L
-      tmp
-    }, rp, factor(seq_along(rp)), SIMPLIFY = FALSE)
-    .data <- do.call(""rbind"", rp)
-
-    .kendalls_w(.data$x, .data$groups, .data$blocks)
+    .kendalls_w(t(.data[.i, ]))
   }
 
-  R <- boot::boot(data = data,
+  R <- boot::boot(data = t(data),
                   statistic = boot_w,
                   R = iterations)
 
@@ -484,5 +474,15 @@ kendalls_w <- function(x, groups, blocks, data = NULL, ci = 0.95, iterations = 2
     stop(""x, groups and blocks must be of the same length."", call. = FALSE)
   }
 
-  data.frame(x, groups, blocks)
-}
\ No newline at end of file
+  data <- data.frame(x, groups, blocks)
+
+  data <- reshape(
+    data,
+    direction = ""wide"",
+    v.names = ""x"",
+    timevar = ""groups"",
+    idvar = ""blocks""
+  )
+
+  as.matrix(data[, -1])
+}

---FILE: man/rank_biserial.Rd---
@@ -122,6 +122,7 @@ kendalls_w(x ~ w | t, data = wb)
 \references{
 \itemize{
 \item Cureton, E. E. (1956). Rank-biserial correlation. Psychometrika, 21(3), 287-290.
+\item Kendall, M.G. (1948) Rank correlation methods. London: Griffin.
 \item Kerby, D. S. (2014). The simple difference formula: An approach to teaching nonparametric correlation. Comprehensive Psychology, 3, 11-IT.
 \item Tomczak, M., & Tomczak, E. (2014). The need to report effect size estimates revisited. An overview of some recommended measures of effect size.
 }",True,False,Documentation / Formatting,6
easystats,effectsize,7950a445008256020c693b5334d5408753553ed1,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-06T03:23:42Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-06T03:23:42Z,"fix kendall's W dealing with data

with no col/row names",R/rank_effectsizes.R,False,True,True,False,9,4,13,"---FILE: R/rank_effectsizes.R---
@@ -464,10 +464,15 @@ kendalls_w <- function(x, groups, blocks, data = NULL, ci = 0.95, iterations = 2
     x <- mf[[1]]
     groups <- mf[[2]]
     blocks <- mf[[3]]
-  } else if (inherits(x, c(""table"", ""matrix"", ""array""))) {
-    data <- data.frame(x = c(x),
-                       groups = rep(colnames(x), each=nrow(x)),
-                       blocks = rep(rownames(x), ncol(x)))
+  } else if (inherits(x, c(""table"", ""matrix"", ""array"", ""data.frame""))) {
+    data <- data.frame(
+      x = c(x),
+      groups = rep(factor(seq_len(ncol(x))),
+                   each = nrow(x)),
+      blocks = rep(factor(seq_len(nrow(x))),
+                   ncol(x))
+    )
+
     x <- data[[1]]
     groups <- data[[2]]
     blocks <- data[[3]]",True,False,Implementation / Logic,6
easystats,effectsize,c60b330c66399f38584e6f9f1cb8ce2cf5bf1913,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-06T03:07:28Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-06T03:07:28Z,fix bug in kendalls_w when there are many blocks,R/rank_effectsizes.R,False,True,True,False,1,1,2,"---FILE: R/rank_effectsizes.R---
@@ -398,7 +398,7 @@ kendalls_w <- function(x, groups, blocks, data = NULL, ci = 0.95, iterations = 2
     rp <- mapply(function(tmp, L) {
       tmp$blocks <- L
       tmp
-    }, rp, letters[seq_along(rp)], SIMPLIFY = FALSE)
+    }, rp, factor(seq_along(rp)), SIMPLIFY = FALSE)
     .data <- do.call(""rbind"", rp)
 
     .kendalls_w(.data$x, .data$groups, .data$blocks)",True,False,Implementation / Logic,6
easystats,effectsize,3aba4f2a2e9429cbc012a23deed5147286784535,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-05T13:37:24Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-05T13:37:24Z,"fix: one sample ttest effectsize

pull only one column
#259",R/effectsize.htest.R,False,True,True,False,2,2,4,"---FILE: R/effectsize.htest.R---
@@ -25,7 +25,7 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
       if (grepl("" by "", model$data.name, fixed = TRUE))
         data[[2]] <- factor(data[[2]])
 
-      out <- f(data[[1]], data[[2]],
+      out <- f(data[[1]], if (ncol(data) == 2) data[[2]],
                mu = model$null.value,
                paired = !grepl(""Two"", model$method),
                pooled_sd = !grepl(""Welch"", model$method),
@@ -139,7 +139,7 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
     mu <- model$null.value
 
     x <- data[[1]]
-    y <- data[[2]]
+    y <- if (ncol(data) == 2) data[[2]]
 
     out <- rank_biserial(x, y, mu = mu, paired = paired, ...)
     return(out)",True,False,Implementation / Logic,6
easystats,effectsize,22e9d49ba93bb27725f7ece574fa22baba72f3fe,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-04T05:49:01Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-04T05:49:01Z,"fix: pull from insight::get_data with index, not name",R/effectsize.htest.R,False,True,True,False,4,7,11,"---FILE: R/effectsize.htest.R---
@@ -23,9 +23,9 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
       )
 
       if (grepl("" by "", model$data.name, fixed = TRUE))
-        data$y <- factor(data$y)
+        data[[2]] <- factor(data[[2]])
 
-      out <- f(data$x, data$y,
+      out <- f(data[[1]], data[[2]],
                mu = model$null.value,
                paired = !grepl(""Two"", model$method),
                pooled_sd = !grepl(""Welch"", model$method),
@@ -111,7 +111,7 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
     if (inherits(data, ""table"")) {
       out <- cohens_g(data, ...)
     } else {
-      out <- cohens_g(data$x, data$y, ...)
+      out <- cohens_g(data[[1]], data[[2]], ...)
     }
     return(out)
   } else if (grepl(""Fisher's Exact"", model$method)) {
@@ -122,10 +122,7 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
     )
   } else if (grepl(""Wilcoxon"", model$method)) {
     # Wilcoxon ----
-    stop(""Cannot extract effect size from an 'htest' of Wilcoxon's test."",
-         ""\nTry using 'ranktransform()' and 'cohens_d()' directly."",
-         call. = FALSE
-    )
+    stop(""This 'htest' method is not (yet?) supported."", call. = FALSE)
   } else {
     stop(""This 'htest' method is not (yet?) supported."", call. = FALSE)
   }",True,False,Implementation / Logic,6
easystats,effectsize,1bf15912350bda2ee28385b2c5716d63d59f738e,DominiqueMakowski,dom.mak19@gmail.com,2021-01-03T13:21:23Z,DominiqueMakowski,dom.mak19@gmail.com,2021-01-03T13:21:23Z,hotfix,R/adjust.R;man/adjust.Rd,False,True,True,False,2,2,4,"---FILE: R/adjust.R---
@@ -55,7 +55,7 @@
 #' # Visualize
 #' plot(data$V1, data$V2, pch = 19, col = ""blue"",
 #'   ylim=c(min(adjusted$V2), max(data$V2)),
-#'   main = ""Original (blue), adjusted (green), and adjusted - intercept kept (blue) data"")
+#'   main = ""Original (blue), adjusted (green), and adjusted - intercept kept (red) data"")
 #' abline(lm(V2 ~ V1, data = data), col = ""blue"")
 #' points(adjusted$V1, adjusted$V2, pch = 19, col = ""green"")
 #' abline(lm(V2 ~ V1, data = adjusted), col = ""green"")

---FILE: man/adjust.Rd---
@@ -94,7 +94,7 @@ adjusted_icpt <- adjust(data, effect=""V1"", select=""V2"", keep_intercept=TRUE)
 # Visualize
 plot(data$V1, data$V2, pch = 19, col = ""blue"",
   ylim=c(min(adjusted$V2), max(data$V2)),
-  main = ""Original (blue), adjusted (green), and adjusted - intercept kept (blue) data"")
+  main = ""Original (blue), adjusted (green), and adjusted - intercept kept (red) data"")
 abline(lm(V2 ~ V1, data = data), col = ""blue"")
 points(adjusted$V1, adjusted$V2, pch = 19, col = ""green"")
 abline(lm(V2 ~ V1, data = adjusted), col = ""green"")",True,False,Documentation / Formatting,6
easystats,effectsize,280a0f6e6541caaf4419e92fbbf98a3ab879d0de,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-01T16:39:24Z,mattansb,35330040+mattansb@users.noreply.github.com,2021-01-01T16:39:24Z,"fix: glass_delta uses boot-CI

#255",NEWS.md;R/cohens_d.R;R/docs_extra.R;man/F_to_eta2.Rd;man/chisq_to_phi.Rd;man/cohens_d.Rd;man/effectsize-CIs.Rd;man/eta_squared.Rd;man/phi.Rd;man/t_to_r.Rd;tests/testthat/test-standardized_differences.R,False,True,True,False,118,60,178,"---FILE: NEWS.md---
@@ -10,14 +10,14 @@
 ## Bug fixes
 
 - `cohens_d()` family / `sd_pooled()` now properly fails when given a missing column name.
-- `glass_delta()` returns correct CIs (was too narrow).
 
 ## Changes
 
 - `effectsize()` for `htest` objects now tries first to extract the data used for testing, and computed the effect size directly on that data.
 - `cohens_d()` family / `sd_pooled()` now respect any transformations (e.g. `I(log(x) - 3) ~ factor(y)`) in a passed formula.
 - `eta_squared()` family of functions gains a `verbose` argument.
 - `verbose` argument more strictly respected.
+- `glass_delta()` returns CIs based on the bootstrap.
 
 # effectsize 0.4.1
 

---FILE: R/cohens_d.R---
@@ -35,6 +35,10 @@
 #'
 #' @details
 #'
+#' ## Confidence Intervals for Glass' *delta*
+#' Confidence Intervals for Glass' *delta* are estimated using the bootstrap
+#' method.
+#'
 #' @inheritSection effectsize-CIs Confidence Intervals
 #'
 #' @return A data frame with the effect size ( `Cohens_d`, `Hedges_g`,
@@ -100,6 +104,7 @@ cohens_d <- function(x,
 }
 
 #' @rdname cohens_d
+#' @param iterations The number of bootstrap replicates for computing confidence intervals. Only applies when \code{ci} is not \code{NULL}.
 #' @export
 hedges_g <- function(x,
                      y = NULL,
@@ -139,7 +144,7 @@ hedges_g <- function(x,
 
 #' @rdname cohens_d
 #' @export
-glass_delta <- function(x, y = NULL, data = NULL, mu = 0, ci = 0.95, verbose = TRUE, correction) {
+glass_delta <- function(x, y = NULL, data = NULL, mu = 0, ci = 0.95, iterations = 200, verbose = TRUE, correction) {
   if (!missing(correction)) {
     warning(""`correction` argument is deprecated. To apply bias correction, use `hedges_g()`."",
       call. = FALSE, immediate. = TRUE
@@ -153,7 +158,8 @@ glass_delta <- function(x, y = NULL, data = NULL, mu = 0, ci = 0.95, verbose = T
     mu = mu,
     type = ""delta"",
     ci = ci,
-    verbose = verbose
+    verbose = verbose,
+    iterations = iterations
   )
 }
 
@@ -170,7 +176,8 @@ glass_delta <- function(x, y = NULL, data = NULL, mu = 0, ci = 0.95, verbose = T
                                     pooled_sd = TRUE,
                                     paired = FALSE,
                                     ci = 0.95,
-                                    verbose = TRUE) {
+                                    verbose = TRUE,
+                                    ...) {
   out <- .deal_with_cohens_d_arguments(x, y, data, verbose)
   x <- out$x
   y <- out$y
@@ -207,7 +214,7 @@ glass_delta <- function(x, y = NULL, data = NULL, mu = 0, ci = 0.95, verbose = T
     n2 <- length(y)
     n <- n1 + n2
 
-    if (type == ""d"" | type == ""g"") {
+    if (type %in% c(""d"", ""g"")) {
       hn <- (1 / n1 + 1 / n2)
       if (pooled_sd) {
         s <- suppressWarnings(sd_pooled(x, y))
@@ -226,12 +233,7 @@ glass_delta <- function(x, y = NULL, data = NULL, mu = 0, ci = 0.95, verbose = T
       }
     } else if (type == ""delta"") {
       pooled_sd <- NULL
-      hn <- 1 / (n2 - 1)
       s <- stats::sd(y)
-
-      se <- s / sqrt(n2)
-      df <- n2 - 1
-
     }
   }
 
@@ -240,14 +242,20 @@ glass_delta <- function(x, y = NULL, data = NULL, mu = 0, ci = 0.95, verbose = T
   colnames(out) <- types[type]
 
   if (is.numeric(ci)) {
+    stopifnot(length(ci) == 1, ci < 1, ci > 0)
+
     # Add cis
-    out$CI <- ci
+    if (type %in% c(""d"", ""g"")) {
+      out$CI <- ci
 
-    t <- (d - mu) / se
-    ts <- .get_ncp_t(t, df, ci)
+      t <- (d - mu) / se
+      ts <- .get_ncp_t(t, df, ci)
 
-    out$CI_low <- ts[1] * sqrt(hn)
-    out$CI_high <- ts[2] * sqrt(hn)
+      out$CI_low <- ts[1] * sqrt(hn)
+      out$CI_high <- ts[2] * sqrt(hn)
+    } else if (type == ""delta"") {
+      out <- cbind(out, .delta_ci(x, y, mu = mu, ci = ci, ...))
+    }
   }
 
 
@@ -263,7 +271,6 @@ glass_delta <- function(x, y = NULL, data = NULL, mu = 0, ci = 0.95, verbose = T
       J <- ((n - 3) / (n - 2.25)) * sqrt((n - 2) / n)
     }
 
-
     out[, colnames(out) %in% c(""Hedges_g"", ""CI_low"", ""CI_high"")] <-
       out[, colnames(out) %in% c(""Hedges_g"", ""CI_low"", ""CI_high"")] * J
   }
@@ -360,3 +367,36 @@ glass_delta <- function(x, y = NULL, data = NULL, mu = 0, ci = 0.95, verbose = T
 
   list(x = x, y = y)
 }
+
+.delta_ci <- function(x, y, mu = 0, ci = 0.95, iterations = 200) {
+  if (!requireNamespace(""boot"")) {
+    warning(""'boot' package required for estimating CIs for Glass' delta. Please install the package and try again."", call. = FALSE)
+    return(NULL)
+  }
+
+  boot_delta <- function(data, .i, mu = 0) {
+    .x <- sample(x, replace = TRUE)
+    .y <- sample(y, replace = TRUE)
+
+    d <- mean(.x) - mean(.y)
+    s <- stats::sd(.y)
+    (d - mu) / s
+  }
+
+  # dud, not actually used
+  data <- data.frame(
+    i = seq_along(c(x, y))
+  )
+
+  R <- boot::boot(data = data,
+                  statistic = boot_delta,
+                  R = iterations,
+                  mu = mu)
+
+  out <- as.data.frame(
+    bayestestR::ci(na.omit(R$t), ci = ci, verbose = FALSE)
+  )
+  out$CI <- ci
+  out
+}
+

---FILE: R/docs_extra.R---
@@ -4,11 +4,12 @@
 #' `effectsize`.
 #'
 #' @section Confidence Intervals:
-#' Confidence intervals are estimated using the Noncentrality parameter method;
-#' These methods searches for a the best non-central parameters (`ncp`s) of the
-#' noncentral t-, F- or Chi-squared distribution for the desired
-#' tail-probabilities, and then convert these `ncp`s to the corresponding effect
-#' sizes. (See full [effectsize-CIs] for more.)
+#' Unless stated otherwise, confidence intervals are estimated using the
+#' Noncentrality parameter method; These methods searches for a the best
+#' non-central parameters (`ncp`s) of the noncentral t-, F- or Chi-squared
+#' distribution for the desired tail-probabilities, and then convert these
+#' `ncp`s to the corresponding effect sizes. (See full [effectsize-CIs] for
+#' more.)
 #'
 #'
 #' @section CI Contains Zero:

---FILE: man/F_to_eta2.Rd---
@@ -98,11 +98,12 @@ designs.
 }
 \section{Confidence Intervals}{
 
-Confidence intervals are estimated using the Noncentrality parameter method;
-These methods searches for a the best non-central parameters (\code{ncp}s) of the
-noncentral t-, F- or Chi-squared distribution for the desired
-tail-probabilities, and then convert these \code{ncp}s to the corresponding effect
-sizes. (See full \link{effectsize-CIs} for more.)
+Unless stated otherwise, confidence intervals are estimated using the
+Noncentrality parameter method; These methods searches for a the best
+non-central parameters (\code{ncp}s) of the noncentral t-, F- or Chi-squared
+distribution for the desired tail-probabilities, and then convert these
+\code{ncp}s to the corresponding effect sizes. (See full \link{effectsize-CIs} for
+more.)
 }
 
 \section{CI Contains Zero}{

---FILE: man/chisq_to_phi.Rd---
@@ -52,11 +52,12 @@ Cohen's \emph{w} is equivalent to \emph{Phi}.
 }
 \section{Confidence Intervals}{
 
-Confidence intervals are estimated using the Noncentrality parameter method;
-These methods searches for a the best non-central parameters (\code{ncp}s) of the
-noncentral t-, F- or Chi-squared distribution for the desired
-tail-probabilities, and then convert these \code{ncp}s to the corresponding effect
-sizes. (See full \link{effectsize-CIs} for more.)
+Unless stated otherwise, confidence intervals are estimated using the
+Noncentrality parameter method; These methods searches for a the best
+non-central parameters (\code{ncp}s) of the noncentral t-, F- or Chi-squared
+distribution for the desired tail-probabilities, and then convert these
+\code{ncp}s to the corresponding effect sizes. (See full \link{effectsize-CIs} for
+more.)
 }
 
 \section{CI Contains Zero}{

---FILE: man/cohens_d.Rd---
@@ -37,6 +37,7 @@ glass_delta(
   data = NULL,
   mu = 0,
   ci = 0.95,
+  iterations = 200,
   verbose = TRUE,
   correction
 )
@@ -71,6 +72,8 @@ Hedges' \emph{g}. Can be \code{1} for Hedges and Olkin's original correction
 (default) or \code{2} for Hunter and Schmidt's correction (see McGrath & Meyer,
 2006).}
 
+\item{iterations}{The number of bootstrap replicates for computing confidence intervals. Only applies when \code{ci} is not \code{NULL}.}
+
 \item{digits}{Number of significant digits.}
 
 \item{append_CL}{Should the Common Language Effect Sizes be printed as well?
@@ -95,7 +98,11 @@ appropriate when the standard deviations are significantly different between
 the populations, as it uses only the \emph{second} group's standard deviation.
 }
 \details{
+\subsection{Confidence Intervals for Glass' \emph{delta}}{
 
+Confidence Intervals for Glass' \emph{delta} are estimated using the bootstrap
+method.
+}
 }
 \note{
 The indices here give the population estimated standardized difference.
@@ -104,11 +111,12 @@ applying Bessel's correction).
 }
 \section{Confidence Intervals}{
 
-Confidence intervals are estimated using the Noncentrality parameter method;
-These methods searches for a the best non-central parameters (\code{ncp}s) of the
-noncentral t-, F- or Chi-squared distribution for the desired
-tail-probabilities, and then convert these \code{ncp}s to the corresponding effect
-sizes. (See full \link{effectsize-CIs} for more.)
+Unless stated otherwise, confidence intervals are estimated using the
+Noncentrality parameter method; These methods searches for a the best
+non-central parameters (\code{ncp}s) of the noncentral t-, F- or Chi-squared
+distribution for the desired tail-probabilities, and then convert these
+\code{ncp}s to the corresponding effect sizes. (See full \link{effectsize-CIs} for
+more.)
 }
 
 \examples{

---FILE: man/effectsize-CIs.Rd---
@@ -9,11 +9,12 @@ More information regarding Confidence Intervals and how they are computed in
 }
 \section{Confidence Intervals}{
 
-Confidence intervals are estimated using the Noncentrality parameter method;
-These methods searches for a the best non-central parameters (\code{ncp}s) of the
-noncentral t-, F- or Chi-squared distribution for the desired
-tail-probabilities, and then convert these \code{ncp}s to the corresponding effect
-sizes. (See full \link{effectsize-CIs} for more.)
+Unless stated otherwise, confidence intervals are estimated using the
+Noncentrality parameter method; These methods searches for a the best
+non-central parameters (\code{ncp}s) of the noncentral t-, F- or Chi-squared
+distribution for the desired tail-probabilities, and then convert these
+\code{ncp}s to the corresponding effect sizes. (See full \link{effectsize-CIs} for
+more.)
 }
 
 \section{CI Contains Zero}{

---FILE: man/eta_squared.Rd---
@@ -167,11 +167,12 @@ more info.
 }
 \section{Confidence Intervals}{
 
-Confidence intervals are estimated using the Noncentrality parameter method;
-These methods searches for a the best non-central parameters (\code{ncp}s) of the
-noncentral t-, F- or Chi-squared distribution for the desired
-tail-probabilities, and then convert these \code{ncp}s to the corresponding effect
-sizes. (See full \link{effectsize-CIs} for more.)
+Unless stated otherwise, confidence intervals are estimated using the
+Noncentrality parameter method; These methods searches for a the best
+non-central parameters (\code{ncp}s) of the noncentral t-, F- or Chi-squared
+distribution for the desired tail-probabilities, and then convert these
+\code{ncp}s to the corresponding effect sizes. (See full \link{effectsize-CIs} for
+more.)
 }
 
 \section{CI Contains Zero}{

---FILE: man/phi.Rd---
@@ -81,11 +81,12 @@ See \emph{Confidence Intervals} and \emph{CI Contains Zero} sections for \emph{p
 
 \section{Confidence Intervals}{
 
-Confidence intervals are estimated using the Noncentrality parameter method;
-These methods searches for a the best non-central parameters (\code{ncp}s) of the
-noncentral t-, F- or Chi-squared distribution for the desired
-tail-probabilities, and then convert these \code{ncp}s to the corresponding effect
-sizes. (See full \link{effectsize-CIs} for more.)
+Unless stated otherwise, confidence intervals are estimated using the
+Noncentrality parameter method; These methods searches for a the best
+non-central parameters (\code{ncp}s) of the noncentral t-, F- or Chi-squared
+distribution for the desired tail-probabilities, and then convert these
+\code{ncp}s to the corresponding effect sizes. (See full \link{effectsize-CIs} for
+more.)
 }
 
 \section{CI Contains Zero}{

---FILE: man/t_to_r.Rd---
@@ -71,11 +71,12 @@ functions.
 }
 \section{Confidence Intervals}{
 
-Confidence intervals are estimated using the Noncentrality parameter method;
-These methods searches for a the best non-central parameters (\code{ncp}s) of the
-noncentral t-, F- or Chi-squared distribution for the desired
-tail-probabilities, and then convert these \code{ncp}s to the corresponding effect
-sizes. (See full \link{effectsize-CIs} for more.)
+Unless stated otherwise, confidence intervals are estimated using the
+Noncentrality parameter method; These methods searches for a the best
+non-central parameters (\code{ncp}s) of the noncentral t-, F- or Chi-squared
+distribution for the desired tail-probabilities, and then convert these
+\code{ncp}s to the corresponding effect sizes. (See full \link{effectsize-CIs} for
+more.)
 }
 
 \examples{

---FILE: tests/testthat/test-standardized_differences.R---
@@ -89,14 +89,17 @@ if (require(""testthat"") && require(""effectsize"")) {
   })
 
   test_that(""glass_delta"", {
+    # must be 2 samples
+    testthat::expect_error(glass_delta(1:10))
+
+    set.seed(8007)
     x <- glass_delta(wt ~ am, data = mtcars)
     testthat::expect_equal(colnames(x)[1], ""Glass_delta"")
     testthat::expect_equal(x[[1]], 2.200, tolerance = 0.001)
-    testthat::expect_equal(x$CI_low, 1.210, tolerance = 0.001)
-    testthat::expect_equal(x$CI_high, 3.344, tolerance = 0.001)
 
-    # must be 2 samples
-    testthat::expect_error(glass_delta(1:10))
+    testthat::skip_if_not_installed(""boot"")
+    testthat::expect_equal(x$CI_low, 1.490089, tolerance = 0.001)
+    testthat::expect_equal(x$CI_high, 3.858925, tolerance = 0.001)
   })
 
 ",True,False,Documentation / Formatting,6
easystats,effectsize,d365d33072b764b2497d45dcca4e9e8c5c213dd5,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-31T01:57:05Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-31T01:57:05Z,fix: auto convert y to factor for t.test,R/effectsize.htest.R;tests/testthat/test-effectsize.R,False,True,True,False,8,0,8,"---FILE: R/effectsize.htest.R---
@@ -22,6 +22,8 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
                   hedges_g = hedges_g
       )
 
+      if (grepl("" by "", model$data.name, fixed = TRUE))
+        data$y <- factor(data$y)
 
       out <- f(data$x, data$y,
                mu = model$null.value,

---FILE: tests/testthat/test-effectsize.R---
@@ -20,6 +20,12 @@ if (require(""testthat"") && require(""effectsize"")) {
     df <- data.frame(DV = c(x, y), g = rep(1:2, each = 10))
     model <- t.test(DV ~ g, data = df, var.equal = TRUE, mu = 3)
     expect_warning(effectsize(model))
+
+    ## Auto convert y to factor
+    Ts <- t.test(mtcars$mpg ~ mtcars$vs)
+    expect_equal(effectsize(Ts, verbose = FALSE),
+                 cohens_d(mtcars$mpg,factor(mtcars$vs), pooled_sd = FALSE),
+                 ignore_attr = TRUE)
   })
 
   test_that(""Chisq-test"", {",True,False,Implementation / Logic,6
easystats,effectsize,db5e68dc3c0e42e6621f98db446d95ef34b8840a,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-30T14:09:56Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-30T14:09:56Z,"Update eta_squared.R

https://github.com/easystats/parameters/issues/369",R/eta_squared.R,False,True,True,False,9,7,16,"---FILE: R/eta_squared.R---
@@ -206,7 +206,7 @@ eta_squared <- function(model,
   }
 
 
-  out <- .anova_es(model, type = ""eta"", partial = partial, generalized = generalized, ci = ci, verbose = verbose)
+  out <- .anova_es(model, type = ""eta"", partial = partial, generalized = generalized, ci = ci, verbose = verbose, ...)
   class(out) <- unique(c(""effectsize_table"", ""see_effectsize_table"", class(out)))
   return(out)
 }
@@ -224,7 +224,7 @@ omega_squared <- function(model,
     return(effectsize(model, type = ""omega"", ci = ci))
   }
 
-  out <- .anova_es(model, type = ""omega"", partial = partial, ci = ci, verbose = verbose)
+  out <- .anova_es(model, type = ""omega"", partial = partial, ci = ci, verbose = verbose, ...)
   class(out) <- unique(c(""effectsize_table"", ""see_effectsize_table"", class(out)))
   return(out)
 }
@@ -242,7 +242,7 @@ epsilon_squared <- function(model,
     return(effectsize(model, type = ""epsilon"", ci = ci))
   }
 
-  out <- .anova_es(model, type = ""epsilon"", partial = partial, ci = ci, verbose = verbose)
+  out <- .anova_es(model, type = ""epsilon"", partial = partial, ci = ci, verbose = verbose, ...)
   class(out) <- unique(c(""effectsize_table"", ""see_effectsize_table"", class(out)))
   return(out)
 }
@@ -268,7 +268,8 @@ cohens_f <- function(model, partial = TRUE, ci = 0.9, squared = FALSE,
   res <- eta_squared(model,
     partial = partial,
     ci = ci,
-    verbose = verbose
+    verbose = verbose,
+    ...
   )
 
   if (""Eta2_partial"" %in% colnames(res)) {
@@ -307,7 +308,7 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
     return(effectsize(model, type = ""f2"", ci = ci))
   }
 
-  cohens_f(model, partial = partial, ci = ci, squared = squared, verbose = verbose, model2 = model2)
+  cohens_f(model, partial = partial, ci = ci, squared = squared, verbose = verbose, model2 = model2, ...)
 }
 
 
@@ -807,8 +808,9 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
   #                 ...)
 
   ## For the multivariate test
-  model <- parameters::model_parameters(model)
-  model$df <- model$df_num
+  model <- parameters::model_parameters(model, ...)
+  if (""df_num"" %in% colnames(model))
+    model$df <- model$df_num
   model <- model[model$Parameter != ""(Intercept)"", , drop = FALSE]
   .anova_es.parameters_model(model, type = type,
                              partial = partial,",True,False,Implementation / Logic,3
easystats,effectsize,86ef40e118806ebf2d6c080cd61ea390de2d457b,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-30T10:11:49Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-30T10:11:49Z,"effectsize.htest get hedges g

https://github.com/easystats/effectsize/issues/214",R/effectsize.R;R/effectsize.htest.R;man/effectsize.Rd;tests/testthat/test-effectsize.R,False,True,True,False,18,7,25,"---FILE: R/effectsize.R---
@@ -11,7 +11,7 @@
 #' @details
 #'
 #' - For an object of class `htest`, data is extracted via [insight::get_data()], and passed to the relevant function according to:
-#'   - A **t-test** returns *Cohen's d*.
+#'   - A **t-test** depending on `type`: `""cohens_d""` (default), `""hedges_g""`.
 #'   - A **correlation test** returns *r*.
 #'   - A **Chi-squared tests of independence or goodness-of-fit**, depending on `type`: `""cramers_v""` (default), `""phi""` or `""cohens_w""`, `""oddsratio""`, or `""riskratio""`.
 #'   - A **One-way ANOVA test**, depending on `type`: `""eta""` (default), `""omega""` or `""epsilon""` -squared, `""f""`, or `""f2""`.

---FILE: R/effectsize.htest.R---
@@ -13,11 +13,21 @@ effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
         ...
       )
     } else {
-      out <- cohens_d(data$x, data$y,
-                      mu = model$null.value,
-                      paired = !grepl(""Two"", model$method),
-                      pooled_sd = !grepl(""Welch"", model$method),
-                      ...)
+      if (is.null(type)) type <- ""d""
+      f <- switch(tolower(type),
+                  d = ,
+                  cohens_d = cohens_d,
+
+                  g = ,
+                  hedges_g = hedges_g
+      )
+
+
+      out <- f(data$x, data$y,
+               mu = model$null.value,
+               paired = !grepl(""Two"", model$method),
+               pooled_sd = !grepl(""Welch"", model$method),
+               ...)
     }
 
     return(out)

---FILE: man/effectsize.Rd---
@@ -36,7 +36,7 @@ input model. See details.
 \itemize{
 \item For an object of class \code{htest}, data is extracted via \code{\link[insight:get_data]{insight::get_data()}}, and passed to the relevant function according to:
 \itemize{
-\item A \strong{t-test} returns \emph{Cohen's d}.
+\item A \strong{t-test} depending on \code{type}: \code{""cohens_d""} (default), \code{""hedges_g""}.
 \item A \strong{correlation test} returns \emph{r}.
 \item A \strong{Chi-squared tests of independence or goodness-of-fit}, depending on \code{type}: \code{""cramers_v""} (default), \code{""phi""} or \code{""cohens_w""}, \code{""oddsratio""}, or \code{""riskratio""}.
 \item A \strong{One-way ANOVA test}, depending on \code{type}: \code{""eta""} (default), \code{""omega""} or \code{""epsilon""} -squared, \code{""f""}, or \code{""f2""}.

---FILE: tests/testthat/test-effectsize.R---
@@ -6,6 +6,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     y <<- c(1,1:9)
     model <- t.test(x, y)
     expect_equal(effectsize(model), cohens_d(x, y, pooled_sd = FALSE), ignore_attr = TRUE)
+    expect_equal(effectsize(model, type = ""g""), hedges_g(x, y, pooled_sd = FALSE), ignore_attr = TRUE)
 
     model <- t.test(x, y, paired = TRUE)
     expect_equal(effectsize(model), cohens_d(x, y, paired = TRUE), ignore_attr = TRUE)",True,False,Documentation / Formatting,6
easystats,effectsize,607146f10d25370fc5af997a491a8d546e1bb72a,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-30T08:31:57Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-30T08:31:57Z,fix: Missing commas separating Remotes,DESCRIPTION,False,False,False,False,1,1,2,"---FILE: DESCRIPTION---
@@ -74,7 +74,7 @@ Suggests:
     testthat,
     tidyr
 Remotes:
-    github::easystats/insight
+    github::easystats/insight,
     github::easystats/parameters
 RoxygenNote: 7.1.1
 Language: en-GB",False,False,Dependency / Package,6
easystats,effectsize,0e1fcc88628db9190cbe16861d981df9c60c0861,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-30T07:47:12Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-30T07:47:12Z,"ANOVA effectsize for Anova.mlm

https://github.com/easystats/effectsize/issues/247",DESCRIPTION;NEWS.md;R/eta_squared.R;tests/testthat/test-eta_squared_etc.R,False,True,True,False,55,4,59,"---FILE: DESCRIPTION---
@@ -40,7 +40,7 @@ Depends:
 Imports:
     bayestestR (>= 0.8.0),
     insight (>= 0.11.1.1),
-    parameters (>= 0.10.0),
+    parameters (>= 0.10.1.1),
     stats,
     utils
 Suggests:
@@ -73,7 +73,9 @@ Suggests:
     see,
     testthat,
     tidyr
-Remotes: github::easystats/insight
+Remotes:
+    github::easystats/insight
+    github::easystats/parameters
 RoxygenNote: 7.1.1
 Language: en-GB
 VignetteBuilder: knitr

---FILE: NEWS.md---
@@ -2,6 +2,7 @@
 
 ## New features
 
+- `eta_squared()` family of functions supports `Anova.mlm` objects (from the `car` package).
 - `effectsize()` supports Cohen's *g* for McNemar's test.
 - `eta2_to_f2()` / `f2_to_eta2()` to convert between two types of effect sizes for ANOVA ( #240 ).
 - `cohens_d()` family of functions gain `mu` argument.

---FILE: R/eta_squared.R---
@@ -520,8 +520,8 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
     )
     return(res)
   }
-  model <- model[rownames(model) != ""(Intercept)"", ]
-  model <- model[rownames(model) != ""Residuals"", ]
+  model <- model[rownames(model) != ""(Intercept)"", , drop = FALSE]
+  model <- model[rownames(model) != ""Residuals"", , drop = FALSE]
 
   F_val <- F_val[F_val %in% colnames(model)]
   numDF <- numDF[numDF %in% colnames(model)]
@@ -558,6 +558,35 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
   out
 }
 
+#' @keywords internal
+.anova_es.Anova.mlm <- function(model,
+                                type = c(""eta"", ""omega"", ""epsilon""),
+                                partial = TRUE,
+                                generalized = FALSE,
+                                ci = 0.9,
+                                verbose = TRUE,
+                                ...) {
+  # ## For the univariate test
+  # model <- summary(mlm1.aov)$univariate.tests
+  # .anova_es.anova(model, type = type,
+  #                 partial = partial,
+  #                 generalized = generalized,
+  #                 ci = ci,
+  #                 verbose = verbose,
+  #                 ...)
+
+  ## For the multivariate test
+  model <- parameters::model_parameters(model)
+  model$df <- model$df_num
+  model <- model[model$Parameter != ""(Intercept)"", , drop = FALSE]
+  .anova_es.parameters_model(model, type = type,
+                             partial = partial,
+                             generalized = generalized,
+                             ci = ci,
+                             verbose = verbose,
+                             ...)
+}
+
 #' @keywords internal
 .anova_es.anova.lme <- .anova_es.anova
 

---FILE: tests/testthat/test-eta_squared_etc.R---
@@ -294,4 +294,23 @@ if (require(""testthat"") && require(""effectsize"")) {
     testthat::expect_error(omega_squared(model1, partial = FALSE))
     testthat::expect_error(omega_squared(model1, partial = TRUE))
   })
+
+
+  # car ---------------------------------------------------------------------
+  test_that(""car MLM"", {
+    testthat::skip_if_not_installed(""afex"")
+    testthat::skip_if_not_installed(""car"")
+    data(obk.long, package = ""afex"")
+    model1 <- afex::aov_car(value ~ treatment * gender + Error(id / (phase * hour)),
+                            data = obk.long, observed = ""gender"",
+                            include_aov = FALSE
+    )
+
+    testthat::expect_warning(eta_squared(model1$Anova, partial = FALSE))
+    testthat::expect_equal(
+      eta_squared(model1$Anova)[1:3, ][[2]],
+      c(0.4407468, 0.2678884, 0.3635011),
+      tolerance = 0.01
+    )
+  })
 }",True,False,Documentation / Formatting,6
easystats,effectsize,bab700c6c629047cc6ca8ba7e55573e1ca2eb17d,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-24T12:22:06Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-24T12:22:06Z,"depends on R3.6.X

https://github.com/easystats/easystats/issues/96",.github/workflows/R-check.yaml;DESCRIPTION,False,False,False,False,9,9,18,"---FILE: .github/workflows/R-check.yaml---
@@ -18,18 +18,18 @@ jobs:
       fail-fast: false
       matrix:
         config:
-          - {os: macOS-latest,   r: 'devel'}
-          - {os: macOS-latest,   r: 'release'}
-          - {os: macOS-latest,   r: 'oldrel'}
-          - {os: macOS-latest,   r: '3.5.0'}
           - {os: windows-latest, r: 'devel'}
-          - {os: windows-latest, r: 'release'}
-          - {os: windows-latest, r: 'oldrel'}
-          - {os: windows-latest, r: '3.5.0'}
+          - {os: macOS-latest,   r: 'devel'}
           - {os: ubuntu-16.04,   r: 'devel',   rspm: ""https://packagemanager.rstudio.com/cran/__linux__/xenial/latest""}
+          - {os: windows-latest, r: 'release'}
+          - {os: macOS-latest,   r: 'release'}
           - {os: ubuntu-16.04,   r: 'release', rspm: ""https://packagemanager.rstudio.com/cran/__linux__/xenial/latest""}
+          - {os: windows-latest, r: 'oldrel'}
+          - {os: macOS-latest,   r: 'oldrel'}
           - {os: ubuntu-16.04,   r: 'oldrel',  rspm: ""https://packagemanager.rstudio.com/cran/__linux__/xenial/latest""}
-          - {os: ubuntu-16.04,   r: '3.5.0',   rspm: ""https://packagemanager.rstudio.com/cran/__linux__/xenial/latest""}
+          # - {os: windows-latest, r: '3.5.0'}
+          # - {os: macOS-latest,   r: '3.5.0'}
+          # - {os: ubuntu-16.04,   r: '3.5.0',   rspm: ""https://packagemanager.rstudio.com/cran/__linux__/xenial/latest""}
 
     env:
       R_REMOTES_NO_ERRORS_FROM_WARNINGS: true

---FILE: DESCRIPTION---
@@ -36,7 +36,7 @@ URL: https://easystats.github.io/effectsize/
 BugReports: https://github.com/easystats/effectsize/issues/
 Description: Provide utilities to work with indices of effect size and standardized parameters for a wide variety of models (see support list of insight; LÃ¼decke, Waggoner & Makowski (2019) <doi:10.21105/joss.01412>), allowing computation and conversion of indices such as Cohen's d, r, odds, etc.
 Depends:
-    R (>= 3.5)
+    R (>= 3.6)
 Imports:
     bayestestR (>= 0.8.0),
     insight (>= 0.11.1.1),",False,False,Dependency / Package,6
easystats,effectsize,78e72dd20b43243ebb5d45998873090a3cbe4f96,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-23T10:39:15Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-23T10:39:15Z,"fix: maintain class for interpret_bf

Also changed the interpretation of BF=1 to ""no evidence against or in favour of""",R/interpret_bf.R;tests/testthat/test-interpret.R,False,True,True,False,13,4,17,"---FILE: R/interpret_bf.R---
@@ -46,7 +46,7 @@ interpret_bf <- function(bf, rules = ""jeffreys1961"", include_value = FALSE, prot
 
   orig_bf <- bf
 
-  dir <- ifelse(bf < 1, ""against"", ""in favour of"")
+  dir <- ifelse(bf < 1, ""against"", ifelse(bf > 1, ""in favour of"", ""against or in favour of""))
   bf <- exp(abs(log(bf)))
 
   rules <- .match.rules(
@@ -73,7 +73,7 @@ interpret_bf <- function(bf, rules = ""jeffreys1961"", include_value = FALSE, prot
   }
 
   # Add direction
-  interpretation <- paste(interpretation, dir)
+  interpretation[] <- paste(interpretation[], dir)
 
   interpretation[is.na(orig_bf)] <- """"
 

---FILE: tests/testthat/test-interpret.R---
@@ -82,12 +82,21 @@ if (require(""testthat"") && require(""effectsize"")) {
 
   test_that(""interpret_bf"", {
     testthat::expect_warning(interpret_bf(-2))
-    testthat::expect_equal(interpret_bf(1)[1], ""no evidence in favour of"")
+    testthat::expect_equal(interpret_bf(1)[1], ""no evidence against or in favour of"")
     testthat::expect_equal(interpret_bf(c(0.8, 3.5), ""jeffreys1961"")[1:2], c(""anecdotal evidence against"", ""moderate evidence in favour of""))
     testthat::expect_equal(interpret_bf(c(0.8, 3.5), ""raftery1995"")[1:2], c(""weak evidence against"", ""positive evidence in favour of""))
     testthat::expect_equal(interpret_bf(2, rules(c(0.5), c(""A"", ""B"")))[1], ""B evidence in favour of"")
     testthat::expect_error(interpret_bf(2, ""DUPA""))
-    testthat::expect_equal(interpret_bf(c(0.8), include_value = TRUE), c(""anecdotal evidence (BF = 1/1.25) against""))
+
+    testthat::skip_on_cran() # just in case there are changes in insight
+    bf <- c(10^seq(-4,4), NA)
+    testthat::expect_equal(interpret_bf(bf, include_value = TRUE, protect_ratio = TRUE, exact = TRUE),
+                           c(""extreme evidence (BF = 1/1.00e+04) against"", ""extreme evidence (BF = 1/1000.00) against"",
+                             ""very strong evidence (BF = 1/100.00) against"", ""moderate evidence (BF = 1/10.00) against"",
+                             ""no evidence (BF = 1.00) against or in favour of"", ""strong evidence (BF = 10.00) in favour of"",
+                             ""extreme evidence (BF = 100.00) in favour of"", ""extreme evidence (BF = 1000.00) in favour of"",
+                             ""extreme evidence (BF = 1.00e+04) in favour of"", """"),
+                           ignore_attr = TRUE)
   })
 
 ",True,False,Implementation / Logic,6
easystats,effectsize,9782fbb9f33fee5c7914783bd921205c060de4e0,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-22T16:01:38Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-22T16:01:38Z,fix tests for retriving data in effectsize(),tests/testthat/test-effectsize.R,False,True,True,False,4,8,12,"---FILE: tests/testthat/test-effectsize.R---
@@ -2,8 +2,8 @@ if (require(""testthat"") && require(""effectsize"")) {
 
   # htest -------------------------------------------------------------------
   test_that(""t-test"", {
-    x <- 1:10
-    y <- c(1,1:9)
+    x <<- 1:10
+    y <<- c(1,1:9)
     model <- t.test(x, y)
     expect_equal(effectsize(model), cohens_d(x, y, pooled_sd = FALSE), ignore_attr = TRUE)
 
@@ -18,10 +18,9 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     df <- data.frame(DV = c(x, y), g = rep(1:2, each = 10))
     model <- t.test(DV ~ g, data = df, var.equal = TRUE, mu = 3)
-    expect_error(effectsize(model))
+    expect_warning(effectsize(model))
   })
 
-
   test_that(""Chisq-test"", {
     contingency_table <-
       as.table(rbind(c(760, 330, 470), c(480, 240, 480), c(480, 240, 480)))
@@ -80,7 +79,6 @@ if (require(""testthat"") && require(""effectsize"")) {
     testthat::expect_equal(ncol(effectsize(t_)), 1L)
   })
 
-
   test_that(""one way"", {
     onew <- oneway.test(mpg ~ cyl, mtcars)
     testthat::expect_warning(effectsize(onew))
@@ -101,7 +99,7 @@ if (require(""testthat"") && require(""effectsize"")) {
   })
 
   test_that(""McNemar"", {
-    Performance <- rbind(
+    Performance <<- rbind(
       c(794, 86),
       c(150, 570)
     )
@@ -111,8 +109,6 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     model <- mcnemar.test(mtcars$cyl, mtcars$gear)
     expect_equal(effectsize(model), cohens_g(mtcars$cyl, mtcars$gear), ignore_attr = TRUE)
-
-
   })
 
 ",True,False,Implementation / Logic,6
easystats,effectsize,53e631e3f04b1bbfe37dc93f7c4b3c941c91bcf5,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-22T14:37:27Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-22T14:37:27Z,"add verbose to `effectsize()`

https://github.com/easystats/parameters/issues/371",R/effectsize.R;R/effectsize.htest.R;man/effectsize.Rd,False,True,True,False,12,7,19,"---FILE: R/effectsize.R---
@@ -6,6 +6,7 @@
 #' @param model An object of class `htest`, or a statistical model. See details.
 #' @param type The effect size of interest. See details.
 #' @param ... Arguments passed to or from other methods. See details.
+#' @inheritParams standardize
 #'
 #' @details
 #'
@@ -80,13 +81,14 @@ effectsize <- function(model, ...) {
 #' @rdname effectsize
 #' @importFrom insight get_data get_parameters
 #' @importFrom bayestestR describe_posterior
-effectsize.BFBayesFactor <- function(model, type = NULL, ...) {
+effectsize.BFBayesFactor <- function(model, type = NULL, verbose = TRUE, ...) {
   if (!requireNamespace(""BayesFactor"")) {
     stop(""This function requires 'BayesFactor' to work. Please install it."")
   }
 
   if (length(model) > 1) {
-    warning(""Multiple models detected. Using first only."", call. = FALSE)
+    if (verbose)
+      warning(""Multiple models detected. Using first only."", call. = FALSE)
     model <- model[1]
   }
 

---FILE: R/effectsize.htest.R---
@@ -1,10 +1,11 @@
 #' @export
 #' @rdname effectsize
-effectsize.htest <- function(model, type = NULL, ...) {
+effectsize.htest <- function(model, type = NULL, verbose = TRUE, ...) {
   if (grepl(""t-test"", model$method)) {
     # t-test ----
     if (is.null(data <- insight::get_data(model))) {
-      warning(""Unable to retrieve data from htest object. Using t_to_d() approximation."")
+      if (verbose)
+        warning(""Unable to retrieve data from htest object. Using t_to_d() approximation."")
       out <- t_to_d(
         unname(model$statistic),
         unname(model$parameter),
@@ -52,7 +53,7 @@ effectsize.htest <- function(model, type = NULL, ...) {
     return(out)
   } else if (grepl(""One-way"", model$method)) {
     # one way anove ----
-    if (grepl(""not assuming"", model$method, fixed = TRUE)) {
+    if (grepl(""not assuming"", model$method, fixed = TRUE) && verbose) {
       warning(""`var.equal = FALSE` - effect size is an approximation."", call. = FALSE)
     }
 

---FILE: man/effectsize.Rd---
@@ -9,18 +9,20 @@
 \usage{
 effectsize(model, ...)
 
-\method{effectsize}{BFBayesFactor}(model, type = NULL, ...)
+\method{effectsize}{BFBayesFactor}(model, type = NULL, verbose = TRUE, ...)
 
 \method{effectsize}{aov}(model, type = NULL, ...)
 
-\method{effectsize}{htest}(model, type = NULL, ...)
+\method{effectsize}{htest}(model, type = NULL, verbose = TRUE, ...)
 }
 \arguments{
 \item{model}{An object of class \code{htest}, or a statistical model. See details.}
 
 \item{...}{Arguments passed to or from other methods. See details.}
 
 \item{type}{The effect size of interest. See details.}
+
+\item{verbose}{Toggle warnings and messages on or off.}
 }
 \value{
 A data frame with the effect size (depending on input) and and its",True,False,Documentation / Formatting,6
easystats,effectsize,48d852269808febb1e3037c77afcf5a98cb1ede2,DominiqueMakowski,dom.mak19@gmail.com,2020-12-22T12:33:30Z,DominiqueMakowski,dom.mak19@gmail.com,2020-12-22T12:33:30Z,fix interpret_bf when include_value is TRUE,R/interpret_bf.R;tests/testthat/test-interpret.R,False,True,True,False,9,3,12,"---FILE: R/interpret_bf.R---
@@ -63,13 +63,18 @@ interpret_bf <- function(bf, rules = ""jeffreys1961"", include_value = FALSE, prot
 
   interpretation <- interpret(bf, rules)
 
-
-  interpretation[] <- paste0(interpretation, "" evidence "", dir)
+  # Format text
+  interpretation[] <- paste0(interpretation, "" evidence"")
   interpretation[orig_bf == 1] <- ""no evidence""
+
+  # Add value if asked for
   if (include_value) {
     interpretation[] <- paste0(interpretation, "" ("", insight::format_bf(orig_bf, protect_ratio = protect_ratio, exact = exact), "")"")
   }
 
+  # Add direction
+  interpretation <- paste(interpretation, dir)
+
   interpretation[is.na(orig_bf)] <- """"
 
   interpretation

---FILE: tests/testthat/test-interpret.R---
@@ -82,11 +82,12 @@ if (require(""testthat"") && require(""effectsize"")) {
 
   test_that(""interpret_bf"", {
     testthat::expect_warning(interpret_bf(-2))
-    testthat::expect_equal(interpret_bf(1)[1], ""no evidence"")
+    testthat::expect_equal(interpret_bf(1)[1], ""no evidence in favour of"")
     testthat::expect_equal(interpret_bf(c(0.8, 3.5), ""jeffreys1961"")[1:2], c(""anecdotal evidence against"", ""moderate evidence in favour of""))
     testthat::expect_equal(interpret_bf(c(0.8, 3.5), ""raftery1995"")[1:2], c(""weak evidence against"", ""positive evidence in favour of""))
     testthat::expect_equal(interpret_bf(2, rules(c(0.5), c(""A"", ""B"")))[1], ""B evidence in favour of"")
     testthat::expect_error(interpret_bf(2, ""DUPA""))
+    testthat::expect_equal(interpret_bf(c(0.8), include_value = TRUE), c(""anecdotal evidence (BF = 1/1.25) against""))
   })
 
 ",True,False,Implementation / Logic,6
easystats,effectsize,72a77e2c41a8fcf9a857983d93192e12697730ba,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-19T14:12:18Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-19T14:12:18Z,enhance and fix bugs in data arguments passed to cohens_d,NEWS.md;R/cohens_d.R;tests/testthat/test-standardized_differences.R,False,True,True,False,30,31,61,"---FILE: NEWS.md---
@@ -6,10 +6,12 @@
 
 ## Bug fixes
 
+- `cohens_d()` family / `sd_pooled()` now properly fails when given a missing column name.
 - `glass_delta()` returns correct CIs (was too narrow).
 
 ## Changes
 
+- `cohens_d()` family / `sd_pooled()` now respect any transformations (e.g. `I(log(x) - 3) ~ factor(y)`) in a passed formula.
 - `eta_squared()` family of functions gains a `verbose` argument.
 - `verbose` argument more strictly respected.
 

---FILE: R/cohens_d.R---
@@ -270,35 +270,43 @@ glass_delta <- function(x, y = NULL, data = NULL, mu = 0, ci = 0.95, correction)
 
   # Sanity checks
   if (inherits(x, ""formula"") | is.character(x) | is.character(y)) {
-    if (is.null(data)) {
+    if (is.null(data)) { # && !is.data.frame(data <- y) ?
       stop(""Please provide data argument."")
     }
   }
 
+
   ## Preprocess data
 
   # Formula
   if (inherits(x, ""formula"")) {
-    trms <- stats::terms(x)
+    if (length(x) != 3)
+      stop(""Formula must have the 'outcome ~ group'."", call. = FALSE)
 
-    group <- all.vars(stats::delete.response(trms))
-    outcome <- setdiff(all.vars(trms), group)
+    mf <- stats::model.frame(stats::lm(formula = x, data = data))
 
-    if (!(length(outcome) == 1 & length(group) == 1)) {
+    x <- mf[[1]]
+    if (ncol(mf) == 1) {
+      y <- NULL
+    } else if (ncol(mf) == 2) {
+      y <- mf[[2]]
+    } else {
       stop(""Formula must have the 'outcome ~ group'."", call. = FALSE)
     }
 
-    x <- data[[outcome]]
-    y <- as.factor(data[[group]])
+    if (!is.null(y) && !is.factor(y)) y <- factor(y)
   }
 
-
   if (is.character(x)) {
-    x <- data[[x]]
+    if (is.null(x <- data[[xn <- x]])) {
+      stop(""Column "", xn, "" missing from data."", call. = FALSE)
+    }
   }
 
   if (is.character(y)) {
-    y <- data[[y]]
+    if (is.null(y <- data[[yn <- y]])) {
+      stop(""Column "", yn, "" missing from data."", call. = FALSE)
+    }
   }
 
   if (!is.numeric(x)) {

---FILE: tests/testthat/test-standardized_differences.R---
@@ -4,7 +4,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     # Direction ---------------------------------------------------------------
     rez_t <- t.test(iris$Sepal.Length, iris$Sepal.Width)
     rez_d <- cohens_d(iris$Sepal.Length, iris$Sepal.Width)
-    testthat::expect_true(sign(rez_t$statistic) == sign(rez_d$Cohens_d))
+    testthat::expect_equal(sign(rez_t$statistic), sign(rez_d$Cohens_d), ignore_attr = TRUE)
 
 
     # Errors and warnings -----------------------------------------------------
@@ -15,34 +15,23 @@ if (require(""testthat"") && require(""effectsize"")) {
       d = c(""a"", ""b"", ""b"", ""c"", ""c"", ""b"", ""c"", ""a"", ""a"", ""b""),
       e = rep(0:1, each = 5)
     )
+    df$exp_a <- exp(df$a)
     a2 <- 1:11
 
-    testthat::expect_true({
-      cohens_d(a ~ c, data = df)
-      TRUE
-    })
-    testthat::expect_true({
-      cohens_d(""a"", ""c"", data = df)
-      TRUE
-    })
-    testthat::expect_true({
-      cohens_d(""a"", ""b"", data = df)
-      TRUE
-    })
-    testthat::expect_true({
-      cohens_d(a2, df$b)
-      TRUE
-    })
-    testthat::expect_true({
-      cohens_d(b ~ e, data = df)
-      TRUE
-    })
+    testthat::expect_error(cohens_d(a ~ c, data = df), regexp = NA)
+    testthat::expect_error(cohens_d(""a"", ""c"", data = df), regexp = NA)
+    testthat::expect_error(cohens_d(""a"", ""b"", data = df), regexp = NA)
+    testthat::expect_error(cohens_d(a2, df$b), regexp = NA)
+    testthat::expect_error(cohens_d(b ~ e, data = df), regexp = NA)
+
+    testthat::expect_equal(cohens_d(""exp_a"", ""c"", data = df), cohens_d(exp(a) ~ c, data = df))
 
     testthat::expect_error(cohens_d(a ~ b, data = df))
     testthat::expect_error(cohens_d(a ~ d, data = df))
     testthat::expect_error(cohens_d(""a"", ""d"", data = df))
     testthat::expect_error(cohens_d(""c"", ""c"", data = df))
     testthat::expect_error(cohens_d(a2, df$c))
+    testthat::expect_error(cohens_d(""a"", ""aa"", data = df))
 
     testthat::expect_warning(cohens_d(""b"", ""e"", data = df))
   })",True,False,Implementation / Logic,6
easystats,effectsize,71a52569810d0b93d771818573893eef1cd02fdc,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-17T19:08:38Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-17T19:08:38Z,Fix printing of paried cohen's d (not un/pooled sd),R/cohens_d.R;tests/testthat/test-printing.R,False,True,True,False,6,2,8,"---FILE: R/cohens_d.R---
@@ -161,7 +161,6 @@ glass_delta <- function(x, y = NULL, data = NULL, mu = 0, ci = 0.95, correction)
     }
     y <- rep(0, length.out = length(x))
     paired <- TRUE
-    pooled_sd <- NULL
   }
 
   # Compute index
@@ -177,6 +176,8 @@ glass_delta <- function(x, y = NULL, data = NULL, mu = 0, ci = 0.95, correction)
     hn <- 1 / (n - 1)
     se <- s / sqrt(n)
     df <- n - 1
+
+    pooled_sd <- NULL
   } else {
     x <- stats::na.omit(x)
     y <- stats::na.omit(y)

---FILE: tests/testthat/test-printing.R---
@@ -13,12 +13,15 @@ if (require(""testthat"") && require(""effectsize"")) {
   test_that(""effectsize difference"", {
     d <- cohens_d(1:3, c(1, 1:3))
     testthat::expect_output(print(d), regexp = ""Cohen"")
-    testthat::expect_output(print(d), regexp = ""pooled"")
+    testthat::expect_output(print(d), regexp = "" pooled"", fixed = TRUE)
     testthat::expect_output(print(d, append_CL = TRUE), regexp = ""U3"")
 
     d <- cohens_d(1:3, c(1, 1:3), pooled_sd = FALSE)
     testthat::expect_output(print(d), regexp = ""un-pooled"")
 
+    d <- cohens_d(1:5, c(1,1:4), paired = TRUE)
+    testthat::expect_error(testthat::expect_output(print(d), regexp = ""pooled""))
+
     d <- hedges_g(1:3, c(1, 1:3), correction = 1)
     testthat::expect_output(print(d), regexp = ""Hedges and Olkin"")
 ",True,False,Implementation / Logic,6
easystats,effectsize,948d276a673a08d9c2fe14c2899a6576fba66cb7,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-15T08:54:57Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-15T08:54:57Z,"Update DESCRIPTION

https://github.com/easystats/easystats/issues/79#issuecomment-744632884",DESCRIPTION,False,False,False,False,0,1,1,"---FILE: DESCRIPTION---
@@ -81,5 +81,4 @@ Encoding: UTF-8
 Roxygen: list(markdown = TRUE)
 Config/testthat/edition: 3
 Config/testthat/parallel: true
-Config/testthat/start-first: watcher, parallel*
 ",False,False,Dependency / Package,7
easystats,effectsize,e5b6f2e0774cf702e57bea37173ebb1d75948e10,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-11T07:50:13Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-11T07:50:13Z,"use insight for BF-prop-test

https://github.com/easystats/parameters/issues/362",DESCRIPTION;R/effectsize.R;tests/testthat/test-effectsize.R,False,True,True,False,6,3,9,"---FILE: DESCRIPTION---
@@ -39,7 +39,7 @@ Depends:
     R (>= 3.5)
 Imports:
     bayestestR (>= 0.8.0),
-    insight (>= 0.11.0),
+    insight (>= 0.11.1.1),
     parameters (>= 0.10.0),
     stats,
     utils
@@ -73,6 +73,7 @@ Suggests:
     see,
     testthat,
     tidyr
+Remotes: github::easystats/insight
 RoxygenNote: 7.1.1
 Language: en-GB
 VignetteBuilder: knitr

---FILE: R/effectsize.R---
@@ -223,8 +223,7 @@ effectsize.BFBayesFactor <- function(model, type = NULL, ...) {
     rho <- insight::get_parameters(model)[[""rho""]]
     res <- data.frame(rho = rho)
   } else if (inherits(model@numerator[[1]], ""BFproportion"")) {
-    p <- as.matrix(BayesFactor::posterior(model, iterations = 4000))[, ""p""]
-    res <- data.frame(p = p)
+    res <- insight::get_parameters(model)
   } else {
     stop(""No effect size for this type of BayesFactor object."")
   }

---FILE: tests/testthat/test-effectsize.R---
@@ -121,5 +121,8 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     bf3 <- BayesFactor::correlationBF(iris$Sepal.Length, iris$Sepal.Width)
     testthat::expect_equal(effectsize(bf3, test = NULL)[[2]], -0.116, tolerance = 0.03)
+
+    bf4 <- BayesFactor::proportionBF(4, 12, 0.5)
+    testthat::expect_equal(effectsize(bf4, test = NULL)[[2]], 0.3911, tolerance = 0.03)
   })
 }",True,False,Dependency / Package,6
easystats,effectsize,e2ec3b9d57cb1d2b8757abe5987b4e6caac2e7b8,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-11T07:12:44Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-11T07:12:44Z,"Fix citations

#227",paper/paper.bib;paper/paper.md,False,False,False,False,45,37,82,"---FILE: paper/paper.bib---
@@ -1,4 +1,4 @@
-@Manual{rcore,
+@manual{rcore,
   title = {{R}: A Language and Environment for Statistical Computing},
   author = {{R Core Team}},
   organization = {R Foundation for Statistical Computing},
@@ -8,12 +8,12 @@ @Manual{rcore
 }
 
 @article{steiger2004beyond,
-  title={Beyond the F test: effect size confidence intervals and tests of close fit in the analysis of variance and contrast analysis.},
+  title={Beyond the F test: effect size confidence intervals and tests of close fit in the analysis of variance and contrast analysis},
   author={Steiger, James H},
-  journal={Psychological methods},
+  journal={Psychological Methods},
   volume={9},
   number={2},
-  pages={164},
+  pages={164--182},
   year={2004},
   publisher={American Psychological Association},
   doi = {10.1037/1082-989X.9.2.164}
@@ -24,23 +24,26 @@ @book{hoffman2015longitudinal
   author={Hoffman, Lesa},
   year={2015},
   publisher={Routledge},
+  address={New York},
   ISBN = {9780415876025}
 }
 
-@article{borenstein2009converting,
+@inbook{borenstein2009converting,
   title={Converting among effect sizes},
-  author={Borenstein, Michael and Hedges, Larry V and Higgins, JPT and Rothstein, Hannah R},
-  journal={Introduction to meta-analysis},
-  pages={45--49},
+  booktitle={Introduction to meta-analysis},
+  author={Borenstein, Michael and Hedges, Larry V and Higgins, Julian PT and Rothstein, Hannah R},
   year={2009},
-  publisher={John Wiley \& Sons, Chichester},
+  chapter={7},
+  pages={45--49},
+  publisher={John Wiley \& Sons},
+  address={Chichester},
   doi = {10.1002/9780470743386.ch7}
 }
 
 @article{grant2014converting,
   title={Converting an odds ratio to a range of plausible relative risks for better communication of research findings},
   author={Grant, Robert L},
-  journal={Bmj},
+  journal={British Medical Journal},
   volume={348},
   pages={f7450},
   year={2014},
@@ -49,19 +52,19 @@ @article{grant2014converting
 }
 
 @article{olejnik2003generalized,
-  title={Generalized eta and omega squared statistics: measures of effect size for some common research designs.},
+  title={Generalized eta and omega squared statistics: measures of effect size for some common research designs},
   author={Olejnik, Stephen and Algina, James},
-  journal={Psychological methods},
+  journal={Psychological Methods},
   volume={8},
   number={4},
-  pages={434},
+  pages={434--447},
   year={2003},
   publisher={American Psychological Association},
   doi = {10.1037/1082-989X.8.4.434}
 }
 
 @article{ludecke2020extracting,
-  title={Extracting, Computing and Exploring the Parameters of Statistical Models using R},
+  title={Extracting, computing and exploring the parameters of statistical models using R},
   author={L{\""u}decke, Daniel and Ben-Shachar, Mattan S and Patil, Indrajeet and Makowski, Dominique},
   journal={Journal of Open Source Software},
   volume={5},
@@ -80,7 +83,7 @@ @article{patil2020ggstatsplot
   doi = {10.5281/zenodo.2074621},
 }
 
-@Manual{sjoberg2020gtsummary,
+@manual{sjoberg2020gtsummary,
   title = {gtsummary: Presentation-Ready Data Summary and Analytic Result Tables},
   author = {Daniel D. Sjoberg and Michael Curry and Margie Hannum and Karissa Whiting and Emily C. Zabor},
   year = {2020},
@@ -89,7 +92,7 @@ @Manual{sjoberg2020gtsummary
 }
 
 @article{luedecke2019insight,
-  title = {insight: A Unified Interface to Access Information from Model Objects in R.},
+  title = {insight: A unified interface to access information from model objects in R},
   volume = {4},
   doi = {10.21105/joss.01412},
   number = {38},
@@ -127,35 +130,37 @@ @book{cohen1988statistical
   title={Statistical power analysis for the behavioral sciences, 2nd ed.},
   author={Cohen, J},
   year={1988},
-  publisher={New York: Routledge}
+  publisher={Routledge},
+  address={New York},
+  ISBN = {9780805802832}
 }
 
-@article{hedges1985statistical,
-  title={Statistical Methods for Meta-Analysis (Orlando, FL: Academic)},
+@book{hedges1985statistical,
+  title={Statistical methods for meta-analysis},
   author={Hedges, L and Olkin, I},
-  journal={HedgesStatistical Methods for Meta-Analysis1985},
+  publisher={Academic Press},
+  address={San Diego},
+  ISBN={9780080570655},
+  doi={C2009-0-03396-0},
   year={1985}
 }
 
-@book{hedges2014statistical,
-  title={Statistical methods for meta-analysis},
-  author={Hedges, Larry V and Olkin, Ingram},
-  year={2014},
-  publisher={Academic press}
-}
-
-@article{bollen1989structural,
-  title={Structural equations with latent variables Wiley},
+@book{bollen1989structural,
+  title={Structural equations with latent variables},
   author={Bollen, Kenneth A},
-  journal={New York},
-  year={1989}
+  publisher={John Wiley \& Sons},
+  address={New York},
+  year={1989},
+  ISBN={9780471011712}
 }
 
 @book{cramer1946mathematical,
-  title={Mathematical Methods of Statistics},
+  title={Mathematical methods of statistics},
   author={Cram{\'e}r, Harald},
   year={1946},
-  publisher={Princeton: Princeton University Press}
+  publisher={Princeton University Press},
+  address={Princeton},
+  ISBN={9781400883868}
 }
 
 @article{kelley1935unbiased,
@@ -164,9 +169,10 @@ @article{kelley1935unbiased
   journal={Proceedings of the National Academy of Sciences of the United States of America},
   volume={21},
   number={9},
-  pages={554},
+  pages={554--559},
   year={1935},
-  publisher={National Academy of Sciences}
+  publisher={National Academy of Sciences},
+  doi={10.1073/pnas.21.9.554}
 }
 
 
@@ -178,5 +184,7 @@ @article{friedman1982simplified
   number={2},
   pages={521--526},
   year={1982},
-  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
+  publisher={Sage Publications},
+  address={Thousand Oaks, CA},
+  doi={10.1177/001316448204200214}
 }
\ No newline at end of file

---FILE: paper/paper.md---
@@ -53,7 +53,7 @@ In both theoretical and applied research, it is often of interest to assess the
 
 ### Standardized Differences
 
-**effectsize** provides functions for estimating the common indices of standardized differences such as Cohen's *d* (`cohens_d()`), Hedge's *g* (`hedges_g()`) for both paired and independent samples [@cohen1988statistical; @hedges1985statistical], and Glass' $\Delta$ (`glass_delta()`) for independent samples with different variances [@hedges2014statistical].
+**effectsize** provides functions for estimating the common indices of standardized differences such as Cohen's *d* (`cohens_d()`), Hedge's *g* (`hedges_g()`) for both paired and independent samples [@cohen1988statistical; @hedges1985statistical], and Glass' $\Delta$ (`glass_delta()`) for independent samples with different variances [@hedges1985statistical].
 
 ``` r
 cohens_d(mpg ~ am, data = mtcars)",False,False,Documentation / Formatting,3
easystats,effectsize,a6c12db478740cf6e0c214e347635876c3e5ee70,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-10T11:18:14Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-10T11:18:14Z,Minor printing fixes,R/cohens_d.R;R/print.effectsize_difference.R;R/print.effectsize_table.R,False,True,True,False,19,13,32,"---FILE: R/cohens_d.R---
@@ -150,6 +150,7 @@ glass_delta <- function(x, y = NULL, data = NULL, ci = 0.95, correction) {
     }
     y <- rep(0, length.out = length(x))
     paired <- TRUE
+    pooled_sd <- NULL
   }
 
   # Compute index

---FILE: R/print.effectsize_difference.R---
@@ -10,20 +10,23 @@ print.effectsize_difference <- function(x, digits = 2, append_CL = FALSE, ...) {
   footer <- caption <- NULL
 
   ## Add footer
-  if (any(colnames(x) %in% c(""Cohens_d"", ""Hedges_g""))) {
-    footer <- paste0("" - Estimate using "", ifelse(attr(x, ""pooled_sd""), ""pooled SD"", ""un-pooled SD""), ""\n"")
+  if (!is.null(sd_type <- attr(x, ""pooled_sd"", exact = TRUE))) {
+    sd_type <- sprintf(
+      "" - Estimated using %s.\n"",
+      ifelse(sd_type, ""pooled SD"", ""un-pooled SD"")
+    )
+
+    footer <- c(footer, list(c(sd_type, ""cyan"")))
   }
 
   if (any(colnames(x) == ""Hedges_g"")) {
-    correction <- paste0(
-      "" - Sample samle bias corrected using "",
-      ifelse(attr(x, ""correction"") == 1, ""Hedges and Olkin's"", ""Hunter and Schmidt's""),
-      "" correction.\n""
+    correction <- sprintf(
+      "" - Bias corrected using %s method.\n"",
+      ifelse(attr(x, ""correction"") == 1, ""Hedges and Olkin's"", ""Hunter and Schmidt's"")
     )
-    footer <- paste0(footer, correction)
-  }
 
-  if (!is.null(footer)) footer <- c(footer, ""cyan"")
+    footer <- c(footer, list(c(correction, ""cyan"")))
+  }
 
   x <- .print_effectsize_table(x, digits = digits)
   cat(insight::export_table(x, digits = digits, caption = caption, footer = footer))

---FILE: R/print.effectsize_table.R---
@@ -6,10 +6,12 @@ print.effectsize_table <- function(x, digits = 2, ...) {
 
   ## Footer
   ## MSB: Move to own printing function?
-  if (!is.null(method <- attr(x_orig, ""std_method""))) {
-    footer <- paste0(toupper(substr(method, 1L, 1L)), substr(method, 2L, nchar(method)))
-    footer <- paste0(""\n# Standardization method: "", method, ""\n"")
-    footer <- c(footer, ""blue"")
+  if (!is.null(std_method <- attr(x_orig, ""std_method""))) {
+    std_method <- sprintf(
+      ""\n# Standardization method: %s\n"",
+      std_method
+    )
+    footer <- list(c(std_method, ""blue""))
   }
 
   x <- .print_effectsize_table(x, digits = digits)",True,False,Implementation / Logic,6
easystats,effectsize,f44a3fa900537d7232f54e8f6a54ee532654fb46,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-10T06:20:58Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-10T06:20:58Z,"Fix Cohen (1988) citation

#227",R/cohens_d.R;R/convert_d_to_common_language.R;R/interpret_d.R;R/interpret_oddsratio.R;R/interpret_r.R;R/interpret_r2.R;R/xtab.R;man/cohens_d.Rd;man/d_to_common_language.Rd;man/interpret_d.Rd;man/interpret_oddsratio.Rd;man/interpret_r.Rd;man/interpret_r2.Rd;man/phi.Rd;paper/paper.bib;vignettes/bibliography.bib,False,True,True,False,20,20,40,"---FILE: R/cohens_d.R---
@@ -59,7 +59,7 @@
 #'
 #' print(cohens_d(mpg ~ am, data = mtcars), append_CL = TRUE)
 #' @references
-#' - Cohen, J. (2013). Statistical power analysis for the behavioral sciences. Routledge.
+#' - Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
 #' - Hedges, L. V. & Olkin, I. (1985). Statistical methods for meta-analysis. Orlando, FL: Academic Press.
 #' - Hunter, J. E., & Schmidt, F. L. (2004). Methods of meta-analysis: Correcting error and bias in research findings. Sage.
 #' - McGrath, R. E., & Meyer, G. J. (2006). When effect sizes disagree: the case of r and d. Psychological methods, 11(4), 386.

---FILE: R/convert_d_to_common_language.R---
@@ -20,7 +20,7 @@
 #' @family convert between effect sizes
 #'
 #' @references
-#' - Cohen, J. (1977). Statistical power analysis for the behavioral sciencies. Routledge.
+#' - Cohen, J. (1977). Statistical power analysis for the behavioral sciences. New York: Routledge.
 #' - Reiser, B., & Faraggi, D. (1999). Confidence intervals for the overlapping coefficient: the normal equal variance case. Journal of the Royal Statistical Society, 48(3), 413-418.
 #' - Ruscio, J. (2008). A probability-based measure of effect size: robustness to base rates and other factors. Psychological methods, 13(1), 19â30.
 #'

---FILE: R/interpret_d.R---
@@ -35,7 +35,7 @@
 #' interpret_d(c(.5, .02))
 #' @references
 #' - Gignac, G. E., & Szodorai, E. T. (2016). Effect size guidelines for individual differences researchers. Personality and individual differences, 102, 74-78.
-#' - Cohen, J. (1988). Statistical power analysis for the behavioural sciences.
+#' - Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
 #' - Sawilowsky, S. S. (2009). New effect size rules of thumb.
 #'
 #' @export

---FILE: R/interpret_oddsratio.R---
@@ -25,7 +25,7 @@
 #' @aliases interpret_odds
 #'
 #' @references
-#' - Cohen, J. (1988). Statistical power analysis for the behavioural sciences.
+#' - Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
 #' - Chen, H., Cohen, P., & Chen, S. (2010). How big is a big odds ratio? Interpreting the magnitudes of odds ratios in epidemiological studies. Communications in StatisticsâSimulation and Computation, 39(4), 860-864.
 #' - SÃ¡nchez-Meca, J., MarÃ­n-MartÃ­nez, F., & ChacÃ³n-Moscoso, S. (2003). Effect-size indices for dichotomized outcomes in meta-analysis. Psychological methods, 8(4), 448.
 #'

---FILE: R/interpret_r.R---
@@ -39,7 +39,7 @@
 #' @references
 #' - Funder, D. C., & Ozer, D. J. (2019). Evaluating effect size in psychological research: sense and nonsense. Advances in Methods and Practices in Psychological Science.
 #' - Gignac, G. E., & Szodorai, E. T. (2016). Effect size guidelines for individual differences researchers. Personality and individual differences, 102, 74-78.
-#' - Cohen, J. (1988). Statistical power analysis for the behavioural sciences.
+#' - Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
 #' - Evans, J. D. (1996). Straightforward statistics for the behavioral sciences. Thomson Brooks/Cole Publishing Co.
 #'
 #' @export

---FILE: R/interpret_r2.R---
@@ -33,7 +33,7 @@
 #' interpret_r2(.02)
 #' interpret_r2(c(.5, .02))
 #' @references
-#' - Cohen, J. (1988). Statistical power analysis for the behavioural sciences.
+#' - Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
 #' - Falk, R. F., & Miller, N. B. (1992). A primer for soft modeling. University of Akron Press.
 #' - Chin, W. W. (1998). The partial least squares approach to structural equation modeling. Modern methods for business research, 295(2), 295-336.
 #' - Hair, J. F., Ringle, C. M., & Sarstedt, M. (2011). PLS-SEM: Indeed a silver bullet. Journal of Marketing theory and Practice, 19(2), 139-152.

---FILE: R/xtab.R---
@@ -100,7 +100,7 @@
 #'
 #' cohens_g(Performance)
 #' @references
-#' - Cohen, J. (1988). Statistical power analysis for the behavioural sciences.
+#' - Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
 #' - Katz, D. J. S. M., Baptista, J., Azen, S. P., & Pike, M. C. (1978). Obtaining confidence intervals for the risk ratio in cohort studies. Biometrics, 469-474.
 #' - Szumilas, M. (2010). Explaining odds ratios. Journal of the Canadian academy of child and adolescent psychiatry, 19(3), 227.
 #'

---FILE: man/cohens_d.Rd---
@@ -105,7 +105,7 @@ print(cohens_d(mpg ~ am, data = mtcars), append_CL = TRUE)
 }
 \references{
 \itemize{
-\item Cohen, J. (2013). Statistical power analysis for the behavioral sciences. Routledge.
+\item Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
 \item Hedges, L. V. & Olkin, I. (1985). Statistical methods for meta-analysis. Orlando, FL: Academic Press.
 \item Hunter, J. E., & Schmidt, F. L. (2004). Methods of meta-analysis: Correcting error and bias in research findings. Sage.
 \item McGrath, R. E., & Meyer, G. J. (2006). When effect sizes disagree: the case of r and d. Psychological methods, 11(4), 386.

---FILE: man/d_to_common_language.Rd---
@@ -32,7 +32,7 @@ normally distributed.
 }
 \references{
 \itemize{
-\item Cohen, J. (1977). Statistical power analysis for the behavioral sciencies. Routledge.
+\item Cohen, J. (1977). Statistical power analysis for the behavioral sciences. New York: Routledge.
 \item Reiser, B., & Faraggi, D. (1999). Confidence intervals for the overlapping coefficient: the normal equal variance case. Journal of the Royal Statistical Society, 48(3), 413-418.
 \item Ruscio, J. (2008). A probability-based measure of effect size: robustness to base rates and other factors. Psychological methods, 13(1), 19â30.
 }

---FILE: man/interpret_d.Rd---
@@ -61,7 +61,7 @@ interpret_d(c(.5, .02))
 \references{
 \itemize{
 \item Gignac, G. E., & Szodorai, E. T. (2016). Effect size guidelines for individual differences researchers. Personality and individual differences, 102, 74-78.
-\item Cohen, J. (1988). Statistical power analysis for the behavioural sciences.
+\item Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
 \item Sawilowsky, S. S. (2009). New effect size rules of thumb.
 }
 }

---FILE: man/interpret_oddsratio.Rd---
@@ -45,7 +45,7 @@ interpret_oddsratio(c(5, 2))
 }
 \references{
 \itemize{
-\item Cohen, J. (1988). Statistical power analysis for the behavioural sciences.
+\item Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
 \item Chen, H., Cohen, P., & Chen, S. (2010). How big is a big odds ratio? Interpreting the magnitudes of odds ratios in epidemiological studies. Communications in StatisticsâSimulation and Computation, 39(4), 860-864.
 \item SÃ¡nchez-Meca, J., MarÃ­n-MartÃ­nez, F., & ChacÃ³n-Moscoso, S. (2003). Effect-size indices for dichotomized outcomes in meta-analysis. Psychological methods, 8(4), 448.
 }

---FILE: man/interpret_r.Rd---
@@ -61,7 +61,7 @@ interpret_r(c(.5, -.02))
 \itemize{
 \item Funder, D. C., & Ozer, D. J. (2019). Evaluating effect size in psychological research: sense and nonsense. Advances in Methods and Practices in Psychological Science.
 \item Gignac, G. E., & Szodorai, E. T. (2016). Effect size guidelines for individual differences researchers. Personality and individual differences, 102, 74-78.
-\item Cohen, J. (1988). Statistical power analysis for the behavioural sciences.
+\item Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
 \item Evans, J. D. (1996). Straightforward statistics for the behavioral sciences. Thomson Brooks/Cole Publishing Co.
 }
 }

---FILE: man/interpret_r2.Rd---
@@ -59,7 +59,7 @@ interpret_r2(c(.5, .02))
 }
 \references{
 \itemize{
-\item Cohen, J. (1988). Statistical power analysis for the behavioural sciences.
+\item Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
 \item Falk, R. F., & Miller, N. B. (1992). A primer for soft modeling. University of Akron Press.
 \item Chin, W. W. (1998). The partial least squares approach to structural equation modeling. Modern methods for business research, 295(2), 295-336.
 \item Hair, J. F., Ringle, C. M., & Sarstedt, M. (2011). PLS-SEM: Indeed a silver bullet. Journal of Marketing theory and Practice, 19(2), 139-152.

---FILE: man/phi.Rd---
@@ -146,7 +146,7 @@ cohens_g(Performance)
 }
 \references{
 \itemize{
-\item Cohen, J. (1988). Statistical power analysis for the behavioural sciences.
+\item Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
 \item Katz, D. J. S. M., Baptista, J., Azen, S. P., & Pike, M. C. (1978). Obtaining confidence intervals for the risk ratio in cohort studies. Biometrics, 469-474.
 \item Szumilas, M. (2010). Explaining odds ratios. Journal of the Canadian academy of child and adolescent psychiatry, 19(3), 227.
 }

---FILE: paper/paper.bib---
@@ -124,10 +124,10 @@ @manual{kelley2020MBESS
 }
 
 @book{cohen1988statistical,
-  title={Statistical power analysis for the behavioral sciences, 2nd edn. {\'A}/L},
+  title={Statistical power analysis for the behavioral sciences, 2nd ed.},
   author={Cohen, J},
   year={1988},
-  publisher={New York: Academic Press, Inc.}
+  publisher={New York: Routledge}
 }
 
 @article{hedges1985statistical,

---FILE: vignettes/bibliography.bib---
@@ -249,11 +249,11 @@ @book{falk1992primer
 
 
 
-@article{cohen1988statistical,
-  title={Statistical power analysis for the social sciences},
-  author={Cohen, Jacob},
+@book{cohen1988statistical,
+  title={Statistical power analysis for the behavioral sciences, 2nd ed.},
+  author={Cohen, J},
   year={1988},
-  publisher={Hillsdale, NJ: Erlbaum}
+  publisher={New York: Routledge}
 }
 
 ",True,False,Documentation / Formatting,6
easystats,effectsize,1d6f3f3a727837d775fbf23e2721621c101eaded,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-09T06:16:07Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-09T06:16:07Z,Minor printing issue,R/print.effectsize_difference.R;README.md;paper/paper.md,False,True,True,False,7,7,14,"---FILE: R/print.effectsize_difference.R---
@@ -11,14 +11,14 @@ print.effectsize_difference <- function(x, digits = 2, append_CL = FALSE, ...) {
 
   ## Add footer
   if (any(colnames(x) %in% c(""Cohens_d"", ""Hedges_g""))) {
-    footer <- paste0("" - Estimate using "", ifelse(attr(x, ""pooled_sd""), ""pooled SD"", ""un-pooled SD""), ""\n"")
+    footer <- paste0("" - Estimated using "", ifelse(attr(x, ""pooled_sd""), ""pooled SD"", ""un-pooled SD""), ""\n"")
   }
 
   if (any(colnames(x) == ""Hedges_g"")) {
     correction <- paste0(
-      "" - Sample samle bias corrected using "",
+      "" - Bias corrected using "",
       ifelse(attr(x, ""correction"") == 1, ""Hedges and Olkin's"", ""Hunter and Schmidt's""),
-      "" correction.\n""
+      "" correction\n""
     )
     footer <- paste0(footer, correction)
   }

---FILE: README.md---
@@ -74,14 +74,14 @@ cohens_d(mpg ~ am, data = mtcars)
 ## Cohen's d |         95% CI
 ## --------------------------
 ##     -1.48 | [-2.27, -0.67]
-##  - Estimate using pooled SD
+##  - Estimated using pooled SD
 
 hedges_g(mpg ~ am, data = mtcars)
 ## Hedge's g |         95% CI
 ## --------------------------
 ##     -1.44 | [-2.21, -0.65]
-##  - Estimate using pooled SD
-##  - Sample samle bias corrected using Hedges and Olkin's correction.
+##  - Estimated using pooled SD
+##  - Bias corrected using Hedges and Olkin's correction
 
 glass_delta(mpg ~ am, data = mtcars)
 ## Glass' delta |         95% CI

---FILE: paper/paper.md---
@@ -60,7 +60,7 @@ cohens_d(mpg ~ am, data = mtcars)
 #> Cohen's d |         95% CI
 #> --------------------------
 #>     -1.48 | [-2.27, -0.67]
-#> - Estimate using pooled SD
+#> - Estimated using pooled SD
 
 ```
 ",True,False,Documentation / Formatting,6
easystats,effectsize,4aeb3367b917b7bc6a6333cb40998786d212b794,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-09T01:22:00Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-09T01:22:00Z,"don't run adjust examples

https://github.com/easystats/easystats/issues/89",R/adjust.R;man/adjust.Rd,False,True,True,False,4,0,4,"---FILE: R/adjust.R---
@@ -12,6 +12,7 @@
 #' @examples
 #' adjust(iris, effect = ""Species"", select = ""Sepal.Length"")
 #' \donttest{
+#' \dontrun{
 #' adjust(iris, effect = ""Species"", select = ""Sepal.Length"", multilevel = TRUE)
 #' adjust(iris, effect = ""Species"", select = ""Sepal.Length"", bayesian = TRUE)
 #' adjust(iris, effect = ""Petal.Width"", select = ""Sepal.Length"", additive = TRUE)
@@ -25,6 +26,7 @@
 #' )
 #' adjust(iris)
 #' }
+#' }
 #'
 #' @export
 adjust <- function(data, effect = NULL, select = NULL, exclude = NULL, multilevel = FALSE, additive = FALSE, bayesian = FALSE) {

---FILE: man/adjust.Rd---
@@ -36,6 +36,7 @@ This function can be used to adjust the data for the effect of other variables p
 \examples{
 adjust(iris, effect = ""Species"", select = ""Sepal.Length"")
 \donttest{
+\dontrun{
 adjust(iris, effect = ""Species"", select = ""Sepal.Length"", multilevel = TRUE)
 adjust(iris, effect = ""Species"", select = ""Sepal.Length"", bayesian = TRUE)
 adjust(iris, effect = ""Petal.Width"", select = ""Sepal.Length"", additive = TRUE)
@@ -49,5 +50,6 @@ adjust(iris,
 )
 adjust(iris)
 }
+}
 
 }",True,False,Documentation / Formatting,6
easystats,effectsize,57d6b88640c3d2ebcccd7162e1a9a4cfb6b91edd,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-08T08:39:20Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-08T08:39:20Z,"Revert change to warning, and fix tests.",R/standardize_info.R;tests/testthat/test-standardize_parameters.R,False,True,True,False,8,6,14,"---FILE: R/standardize_info.R---
@@ -301,9 +301,11 @@ standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseu
 #' @importFrom parameters check_heterogeneity demean
 #' @importFrom stats as.formula sd
 .std_info_pseudo <- function(model, params, model_matrix, types, robust = FALSE, two_sd = FALSE) {
-  warning(""'robust' standardization not available for 'pseudo' method."",
-          call. = FALSE
-  )
+  if (robust) {
+    warning(""'robust' standardization not available for 'pseudo' method."",
+            call. = FALSE
+    )
+  }
 
   f <- if (two_sd) 2 else 1
 

---FILE: tests/testthat/test-standardize_parameters.R---
@@ -280,7 +280,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     )
 
     ## No robust methods... (yet)
-    expect_warning(standardize_parameters(m, method = ""pseudo"", robust = TRUE))
+    expect_warning(standardize_parameters(m, method = ""pseudo"", robust = TRUE), regexp = ""robust"")
 
 
     ## Correctly identify within and between terms
@@ -346,8 +346,8 @@ if (require(""testthat"") && require(""effectsize"")) {
     mW <- lme4::lmer(Y ~ X_between + Z_within + C + (1 | ID), dat)
     mM <- lme4::lmer(Y ~ X + Z + C + (1 | ID), dat)
 
-    expect_warning(standardize_parameters(mW, method = ""pseudo""), NA)
-    expect_warning(standardize_parameters(mM, method = ""pseudo""))
+    expect_warning(standardize_parameters(mW, method = ""pseudo""), regexp = NA)
+    expect_warning(standardize_parameters(mM, method = ""pseudo""), regexp = ""within-group"")
   })
 
 ",True,False,Implementation / Logic,6
easystats,effectsize,97d7229e15079e3cb3491e6b7c037f5fe8747e7b,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-08T05:56:32Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-08T05:56:32Z,Fix warning tests,tests/testthat/test-eta_squared_posterior.R,False,True,True,False,3,4,7,"---FILE: tests/testthat/test-eta_squared_posterior.R---
@@ -25,9 +25,8 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     testthat::expect_warning(
       es_post <- eta_squared_posterior(fit_bayes,
-        verbose = FALSE,
         ss_function = car::Anova, type = 3
-      )
+      ), regexp = ""bogus""
     )
     testthat::expect_equal(colnames(es_post), es_tab$Parameter)
 
@@ -50,9 +49,9 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     testthat::expect_warning(
       es_post <- eta_squared_posterior(fit_bayes,
-        verbose = FALSE, partial = FALSE,
+        partial = FALSE,
         ss_function = car::Anova, type = 3
-      )
+      ), regexp = ""bogus""
     )
     testthat::expect_equal(colnames(es_post), es_tab$Parameter)
 ",True,False,Implementation / Logic,6
easystats,effectsize,edc3d861498f5767cc509be1955fa0636d66dc17,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-05T12:42:20Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-05T12:42:20Z,fix printing of CL for std-d,R/print.effectsize_difference.R,False,True,True,False,1,1,2,"---FILE: R/print.effectsize_difference.R---
@@ -26,7 +26,7 @@ print.effectsize_difference <- function(x, digits = 2, append_CL = FALSE, ...) {
   x <- .print_effectsize_table(x, digits = digits)
   cat(insight::export_table(x, digits = digits, caption = caption, footer = footer))
 
-  if (append_CL && any(colnames(x_orig) %in% c(""Cohens_d"", ""Hedges_g"")) && attr(x_orig, ""paired"")) {
+  if (append_CL && any(colnames(x_orig) %in% c(""Cohens_d"", ""Hedges_g"")) && !attr(x_orig, ""paired"")) {
     # Common lang
     cl <- d_to_common_language(x_orig[[any(colnames(x_orig) %in% c(""Cohens_d"", ""Hedges_g""))]])
     cl <- lapply(cl, insight::format_value, as_percent = TRUE, digits = digits)",True,False,Implementation / Logic,3
easystats,effectsize,c39f3296d86dbaaa976ada1b15007cc924d45c5e,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-05T12:22:32Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-05T12:22:32Z,"""fix"" d and g (with corrections) #222",NEWS.md;R/cohens_d.R;R/print.effectsize_difference.R;man/cohens_d.Rd;tests/testthat/test-printing.R;tests/testthat/test-standardized_differences.R,False,True,True,False,109,58,167,"---FILE: NEWS.md---
@@ -2,6 +2,7 @@
 
 ## Breaking Changes
 
+- `cohens_d()` and `glass_delta()`: The `correction` argument has been deprecated, in favor of it being correctly implemented in `hedges_g()` ( #222 ).
 - `eta_squared_posterior()` no longer uses `car::Anova()` by default.
 
 ## New features
@@ -18,7 +19,8 @@
 
 ## Bug fixes
 
-Fixed width of CI for Cohen's d and Hedge's g when using *non*-pooled SD.
+- `hedges_g()` correctly implements the available bias correction methods ( #222 ).
+- Fixed width of CI for Cohen's *d* and Hedges' *g* when using *non*-pooled SD.
 
 # effectsize 0.4.0
 

---FILE: R/cohens_d.R---
@@ -1,25 +1,34 @@
 #' Effect size for differences
 #'
-#' Compute different indices of effect size. For very small sample sizes (n <
-#' 20) Hedges' g is considered as less biased than Cohen's d. For sample sizes >
-#' 20, the results for both statistics are roughly equivalent.
+#' Compute effect size indices for standardized differences: Cohen's *d*,
+#' Hedges' *g* and Glassâs *delta*. (This function returns the **population**
+#' estimate.)
 #' \cr\cr
-#' The Glassâs delta is appropriate if standard deviations are significantly
-#' different between groups, as it uses only the *second* group's standard
-#' deviation.
+#' Both Cohen's *d* and Hedges' *g* are the estimated the standardized
+#' difference between the means of two populations. Hedges' *g* provides a bias
+#' correction to Cohen's *d* for small sample sizes. For sample sizes > 20, the
+#' results for both statistics are roughly equivalent. Glassâs *delta* is
+#' appropriate when the standard deviations are significantly different between
+#' the populations, as it uses only the *second* group's standard deviation.
 #'
 #' @param x A formula, a numeric vector, or a character name of one in `data`.
 #'   (For `print()` the result of one of the standardized difference functions.)
 #' @param y A numeric vector, a grouping (character / factor) vector, a or a
 #'   character  name of one in `data`. Ignored if `x` is a formula.
 #' @param data An optional data frame containing the variables.
-#' @param correction If `TRUE`, applies a correction to make it less biased for
-#'   small samples (McGrath & Meyer, 2006).
+#' @param correction Type of small sample bias correction to apply to produce
+#'   Hedges' *g*. Can be `1` for Hedges and Olkin's original correction
+#'   (default) or `2` for Hunter and Schmidt's correction (see McGrath & Meyer,
+#'   2006).
 #' @param pooled_sd If `TRUE` (default), a [sd_pooled()] is used (assuming equal
 #'   variance). Else the mean SD from both groups is used instead.
 #' @param paired If `TRUE`, the values of `x` and `y` are considered as paired.
 #' @inheritParams chisq_to_phi
 #'
+#' @note The indices here give the population estimated standardized difference.
+#'   Some statistical packages give the sample estimate instead (without
+#'   applying Bessel's correction).
+#'
 #' @details
 #'
 #' # Confidence Intervals
@@ -46,24 +55,29 @@
 #' print(cohens_d(mpg ~ am, data = mtcars), append_CL = TRUE)
 #' @references
 #' - Cohen, J. (2013). Statistical power analysis for the behavioral sciences. Routledge.
-#' - McGrath, R. E., & Meyer, G. J. (2006). When effect sizes disagree: the case of r and d. Psychological methods, 11(4), 386.
 #' - Hedges, L. V. & Olkin, I. (1985). Statistical methods for meta-analysis. Orlando, FL: Academic Press.
+#' - Hunter, J. E., & Schmidt, F. L. (2004). Methods of meta-analysis: Correcting error and bias in research findings. Sage.
+#' - McGrath, R. E., & Meyer, G. J. (2006). When effect sizes disagree: the case of r and d. Psychological methods, 11(4), 386.
 #'
 #' @importFrom stats var model.frame
 #' @export
 cohens_d <- function(x,
                      y = NULL,
                      data = NULL,
-                     correction = FALSE,
                      pooled_sd = TRUE,
                      paired = FALSE,
-                     ci = 0.95) {
+                     ci = 0.95,
+                     correction) {
+  if (!missing(correction)) {
+    warning(""`correction` argument is deprecated. To apply bias correction, use `hedges_g()`."",
+            call. = FALSE, immediate. = TRUE)
+  }
+
   .effect_size_difference(
     x,
     y = y,
     data = data,
     type = ""d"",
-    correction = correction,
     pooled_sd = pooled_sd,
     paired = paired,
     ci = ci
@@ -75,10 +89,16 @@ cohens_d <- function(x,
 hedges_g <- function(x,
                      y = NULL,
                      data = NULL,
-                     correction = FALSE,
+                     correction = 1,
                      pooled_sd = TRUE,
                      paired = FALSE,
                      ci = 0.95) {
+  if (isTRUE(correction) || !correction %in% c(1, 2)) {
+    warning(""`correction` must be 1 or 2. See ?hedges_g. Setting to 1 for Hedges & Olkin's correction."",
+            call. = FALSE, immediate. = TRUE)
+    correction <- 1
+  }
+
   .effect_size_difference(
     x,
     y = y,
@@ -93,13 +113,17 @@ hedges_g <- function(x,
 
 #' @rdname cohens_d
 #' @export
-glass_delta <- function(x, y = NULL, data = NULL, correction = FALSE, ci = 0.95) {
+glass_delta <- function(x, y = NULL, data = NULL, ci = 0.95, correction) {
+  if (!missing(correction)) {
+    warning(""`correction` argument is deprecated. To apply bias correction, use `hedges_g()`."",
+            call. = FALSE, immediate. = TRUE)
+  }
+
   .effect_size_difference(
     x,
     y = y,
     data = data,
     type = ""delta"",
-    correction = correction,
     ci = ci
   )
 }
@@ -112,7 +136,7 @@ glass_delta <- function(x, y = NULL, data = NULL, correction = FALSE, ci = 0.95)
                                     y = NULL,
                                     data = NULL,
                                     type = ""d"",
-                                    correction = FALSE,
+                                    correction = NULL,
                                     pooled_sd = TRUE,
                                     paired = FALSE,
                                     ci = 0.95) {
@@ -192,25 +216,24 @@ glass_delta <- function(x, y = NULL, data = NULL, correction = FALSE, ci = 0.95)
 
 
   if (type == ""g"") {
-    if (paired) {
-      J <- 1 - 3 / (4 * (n - 1) - 1)
-    } else {
-      J <- 1 - 3 / (4 * n - 9)
+    if (correction == 1) {
+      if (paired) {
+        J <- 1 - 3 / (4 * (n - 1) - 1)
+      } else {
+        J <- 1 - 3 / (4 * n - 9)
+      }
+    } else if (correction == 2) {
+      # McGrath & Meyer (2006)
+      J <- ((n - 3) / (n - 2.25)) * sqrt((n - 2) / n)
     }
 
+
     out[, colnames(out) %in% c(""Hedges_g"", ""CI_low"", ""CI_high"")] <-
       out[, colnames(out) %in% c(""Hedges_g"", ""CI_low"", ""CI_high"")] * J
   }
 
-  # McGrath & Meyer (2006)
-  if (correction) {
-    correction <- ((n - 3) / (n - 2.25)) * sqrt((n - 2) / n)
-
-    out[, colnames(out) %in% c(types, ""CI_low"", ""CI_high"")] <-
-      out[, colnames(out) %in% c(types, ""CI_low"", ""CI_high"")] * correction
-  }
-
   class(out) <- c(""effectsize_difference"", ""effectsize_table"", ""see_effectsize_table"", class(out))
+  attr(out, ""paired"") <- paired
   attr(out, ""correction"") <- correction
   attr(out, ""pooled_sd"") <- pooled_sd
   return(out)

---FILE: R/print.effectsize_difference.R---
@@ -10,21 +10,23 @@ print.effectsize_difference <- function(x, digits = 2, append_CL = FALSE, ...) {
   footer <- caption <- NULL
 
   ## Add footer
-  if (attr(x, ""correction"")) {
-    footer <- ""Bias-corrected ""
+  if (any(colnames(x) %in% c(""Cohens_d"", ""Hedges_g""))) {
+    footer <- paste0("" - Estimate using "", ifelse(attr(x, ""pooled_sd""), ""pooled SD"", ""un-pooled SD""), ""\n"")
   }
 
-  if (any(colnames(x) %in% c(""Cohens_d"", ""Hedges_g""))) {
-    footer <- paste0(footer,
-                     paste0(""Estimate Using "", ifelse(attr(x, ""pooled_sd""), ""Pooled SD"", ""Unpooled SD"")),
-                     collapse = "" "")
-    footer <- c(footer, ""cyan"")
+  if (any(colnames(x) == ""Hedges_g"")) {
+    correction <- paste0("" - Sample samle bias corrected using "",
+                         ifelse(attr(x, ""correction"") == 1, ""Hedges and Olkin's"", ""Hunter and Schmidt's""),
+                         "" correction.\n"")
+    footer <- paste0(footer, correction)
   }
 
+  if (!is.null(footer)) footer <- c(footer, ""cyan"")
+
   x <- .print_effectsize_table(x, digits = digits)
   cat(insight::export_table(x, digits = digits, caption = caption, footer = footer))
 
-  if (append_CL && any(colnames(x_orig) %in% c(""Cohens_d"", ""Hedges_g""))) {
+  if (append_CL && any(colnames(x_orig) %in% c(""Cohens_d"", ""Hedges_g"")) && attr(x_orig, ""paired"")) {
     # Common lang
     cl <- d_to_common_language(x_orig[[any(colnames(x_orig) %in% c(""Cohens_d"", ""Hedges_g""))]])
     cl <- lapply(cl, insight::format_value, as_percent = TRUE, digits = digits)

---FILE: man/cohens_d.Rd---
@@ -11,23 +11,23 @@ cohens_d(
   x,
   y = NULL,
   data = NULL,
-  correction = FALSE,
   pooled_sd = TRUE,
   paired = FALSE,
-  ci = 0.95
+  ci = 0.95,
+  correction
 )
 
 hedges_g(
   x,
   y = NULL,
   data = NULL,
-  correction = FALSE,
+  correction = 1,
   pooled_sd = TRUE,
   paired = FALSE,
   ci = 0.95
 )
 
-glass_delta(x, y = NULL, data = NULL, correction = FALSE, ci = 0.95)
+glass_delta(x, y = NULL, data = NULL, ci = 0.95, correction)
 
 \method{print}{effectsize_difference}(x, digits = 2, append_CL = FALSE, ...)
 }
@@ -40,16 +40,18 @@ character  name of one in \code{data}. Ignored if \code{x} is a formula.}
 
 \item{data}{An optional data frame containing the variables.}
 
-\item{correction}{If \code{TRUE}, applies a correction to make it less biased for
-small samples (McGrath & Meyer, 2006).}
-
 \item{pooled_sd}{If \code{TRUE} (default), a \code{\link[=sd_pooled]{sd_pooled()}} is used (assuming equal
 variance). Else the mean SD from both groups is used instead.}
 
 \item{paired}{If \code{TRUE}, the values of \code{x} and \code{y} are considered as paired.}
 
 \item{ci}{Confidence Interval (CI) level}
 
+\item{correction}{Type of small sample bias correction to apply to produce
+Hedges' \emph{g}. Can be \code{1} for Hedges and Olkin's original correction
+(default) or \code{2} for Hunter and Schmidt's correction (see McGrath & Meyer,
+2006).}
+
 \item{digits}{Number of significant digits.}
 
 \item{append_CL}{Should the Common Language Effect Sizes be printed as well?
@@ -61,13 +63,21 @@ Not applicable to Glass' Delta (See \code{\link[=d_to_common_language]{d_to_comm
 A data frame with the effect size(s) and confidence interval(s).
 }
 \description{
-Compute different indices of effect size. For very small sample sizes (n <
-20) Hedges' g is considered as less biased than Cohen's d. For sample sizes >
-20, the results for both statistics are roughly equivalent.
+Compute effect size indices for standardized differences: Cohen's \emph{d},
+Hedges' \emph{g} and Glassâs \emph{delta}. (This function returns the \strong{population}
+estimate.)
 \cr\cr
-The Glassâs delta is appropriate if standard deviations are significantly
-different between groups, as it uses only the \emph{second} group's standard
-deviation.
+Both Cohen's \emph{d} and Hedges' \emph{g} are the estimated the standardized
+difference between the means of two populations. Hedges' \emph{g} provides a bias
+correction to Cohen's \emph{d} for small sample sizes. For sample sizes > 20, the
+results for both statistics are roughly equivalent. Glassâs \emph{delta} is
+appropriate when the standard deviations are significantly different between
+the populations, as it uses only the \emph{second} group's standard deviation.
+}
+\note{
+The indices here give the population estimated standardized difference.
+Some statistical packages give the sample estimate instead (without
+applying Bessel's correction).
 }
 \section{Confidence Intervals}{
 Confidence intervals are estimated using the Noncentrality parameter method;
@@ -91,8 +101,9 @@ print(cohens_d(mpg ~ am, data = mtcars), append_CL = TRUE)
 \references{
 \itemize{
 \item Cohen, J. (2013). Statistical power analysis for the behavioral sciences. Routledge.
-\item McGrath, R. E., & Meyer, G. J. (2006). When effect sizes disagree: the case of r and d. Psychological methods, 11(4), 386.
 \item Hedges, L. V. & Olkin, I. (1985). Statistical methods for meta-analysis. Orlando, FL: Academic Press.
+\item Hunter, J. E., & Schmidt, F. L. (2004). Methods of meta-analysis: Correcting error and bias in research findings. Sage.
+\item McGrath, R. E., & Meyer, G. J. (2006). When effect sizes disagree: the case of r and d. Psychological methods, 11(4), 386.
 }
 }
 \seealso{

---FILE: tests/testthat/test-printing.R---
@@ -13,14 +13,17 @@ if (require(""testthat"") && require(""effectsize"")) {
   test_that(""effectsize difference"", {
     d <- cohens_d(1:3, c(1,1:3))
     testthat::expect_output(print(d), regexp = ""Cohen"")
-    testthat::expect_output(print(d), regexp = ""Pooled"")
+    testthat::expect_output(print(d), regexp = ""pooled"")
     testthat::expect_output(print(d, append_CL = TRUE), regexp = ""U3"")
 
-    d <- cohens_d(1:3, c(1,1:3), correction = TRUE)
-    testthat::expect_output(print(d), regexp = ""Bias-corrected"")
-
     d <- cohens_d(1:3, c(1,1:3), pooled_sd = FALSE)
-    testthat::expect_output(print(d), regexp = ""Unpooled"")
+    testthat::expect_output(print(d), regexp = ""un-pooled"")
+
+    d <- hedges_g(1:3, c(1,1:3), correction = 1)
+    testthat::expect_output(print(d), regexp = ""Hedges and Olkin"")
+
+    d <- hedges_g(1:3, c(1,1:3), correction = 2)
+    testthat::expect_output(print(d), regexp = ""Hunter and Schmidt"")
   })
 
   test_that(""equivalence test effectsize"", {

---FILE: tests/testthat/test-standardized_differences.R---
@@ -63,12 +63,22 @@ if (require(""testthat"") && require(""effectsize"")) {
     testthat::expect_equal(x$CI_high, 2.833495, tolerance = 0.001)
   })
 
-  test_that(""hedges_g"", {
-    x <- hedges_g(wt ~ am, data = mtcars)
+  test_that(""hedges_g (and other bias correction things"", {
+    x <- hedges_g(wt ~ am, data = mtcars, correction = 1)
     testthat::expect_equal(colnames(x)[1], ""Hedges_g"")
     testthat::expect_equal(x[[1]], 1.844, tolerance = 0.001)
     testthat::expect_equal(x$CI_low, 1.004, tolerance = 0.001)
     testthat::expect_equal(x$CI_high, 2.664, tolerance = 0.001)
+
+    x <- hedges_g(wt ~ am, data = mtcars, correction = 2)
+    testthat::expect_equal(colnames(x)[1], ""Hedges_g"")
+    testthat::expect_equal(x[[1]], 1.786, tolerance = 0.001)
+    testthat::expect_equal(x$CI_low, 0.972, tolerance = 0.001)
+    testthat::expect_equal(x$CI_high, 2.579, tolerance = 0.001)
+
+    testthat::expect_warning(hedges_g(wt ~ am, data = mtcars, correction = TRUE))
+    testthat::expect_warning(cohens_d(wt ~ am, data = mtcars, correction = TRUE))
+    testthat::expect_warning(glass_delta(wt ~ am, data = mtcars, correction = TRUE))
   })
 
   test_that(""glass_delta"", {",True,False,Documentation / Formatting,6
easystats,effectsize,54dfc64938c29b9cc6a29a58152d3fa7e5c4ebdf,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-02T12:25:31Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-02T12:25:31Z,fix tolerance,tests/testthat/test-effectsize.R,False,True,True,False,4,3,7,"---FILE: tests/testthat/test-effectsize.R---
@@ -97,17 +97,18 @@ if (require(""testthat"") && require(""effectsize"")) {
 
   if (require(""BayesFactor"")) {
     test_that(""BayesFactor"", {
+      testthat::skip_on_cran()
       set.seed(6)
       data(raceDolls)
       bf1 <- contingencyTableBF(raceDolls, sampleType = ""poisson"", fixedMargin = ""cols"")
       testthat::expect_equal(effectsize(bf1, test = NULL)[[2]], 0.164, tolerance = 0.01)
-      testthat::expect_equal(effectsize(bf1, test = NULL, type = ""OR"")[[2]], 0.498, tolerance = 0.01)
+      testthat::expect_equal(effectsize(bf1, test = NULL, type = ""OR"")[[2]], 0.503, tolerance = 0.03)
 
       bf2 <- ttestBF(mtcars$mpg[mtcars$am == 1], mtcars$mpg[mtcars$am == 0])
-      testthat::expect_equal(effectsize(bf2, test = NULL)[[2]], 1.30, tolerance = 0.01)
+      testthat::expect_equal(effectsize(bf2, test = NULL)[[2]], 1.30, tolerance = 0.03)
 
       bf3 <- correlationBF(iris$Sepal.Length, iris$Sepal.Width)
-      testthat::expect_equal(effectsize(bf3, test = NULL)[[2]], -0.116, tolerance = 0.01)
+      testthat::expect_equal(effectsize(bf3, test = NULL)[[2]], -0.116, tolerance = 0.03)
     })
   }
 }
\ No newline at end of file",True,False,Implementation / Logic,6
easystats,effectsize,23771798f5562bc8a15718329dc3dbfe226a062d,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-02T11:13:01Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-02T11:13:01Z,Fix some errors in CI,R/effectsize.R;tests/testthat/test-effectsize.R,False,True,True,False,2,2,4,"---FILE: R/effectsize.R---
@@ -247,7 +247,7 @@ effectsize.anova <- function(model, type = NULL, ...) {
 
                f2 = ,
                f_squared = ,
-               cohens_f2 = cohens_f2)
+               cohens_f2 = cohens_f_squared)
 
   f(model, ...)
 }

---FILE: tests/testthat/test-effectsize.R---
@@ -96,7 +96,7 @@ if (require(""testthat"") && require(""effectsize"")) {
   # BayesFactor -------------------------------------------------------------
 
   if (require(""BayesFactor"")) {
-    test_that(""aov"", {
+    test_that(""BayesFactor"", {
       set.seed(6)
       data(raceDolls)
       bf1 <- contingencyTableBF(raceDolls, sampleType = ""poisson"", fixedMargin = ""cols"")",True,False,Implementation / Logic,6
easystats,effectsize,e79fed2efeab076cb0f1e0ab24b8558c8aadf454,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-02T07:37:57Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-02T07:37:57Z,"fix CI for non-pooled sd

invoke @IndrajeetPatil to find where I fucked up.",NEWS.md;R/cohens_d.R;tests/testthat/test-standardized_differences.R,False,True,True,False,23,14,37,"---FILE: NEWS.md---
@@ -11,6 +11,10 @@
 - `standardize()` gains support for `mediation::mediate()` models.
 - `eta_squared()` family available for `manova` objects.
 
+## Bug fixes
+
+Fixed width of CI for Cohen's d and Hedge's g when using *non*-pooled SD.
+
 # effectsize 0.4.0
 
 ## Breaking Changes

---FILE: R/cohens_d.R---
@@ -136,11 +136,12 @@ glass_delta <- function(x, y = NULL, data = NULL, correction = FALSE, ci = 0.95)
     y <- y[o]
 
     d <- mean(x - y)
-    s <- stats::sd(x - y)
     n <- length(x)
+    s <- stats::sd(x - y)
+
+    hn <- 1 / (n - 1)
+    se <- s / sqrt(n)
     df <- n - 1
-    hn <- 1 / df
-    t <- d / (s / sqrt(n))
   } else {
     x <- stats::na.omit(x)
     y <- stats::na.omit(y)
@@ -149,21 +150,29 @@ glass_delta <- function(x, y = NULL, data = NULL, correction = FALSE, ci = 0.95)
     n1 <- length(x)
     n2 <- length(y)
     n <- n1 + n2
-    df <- n - 2
+
     hn <- (1 / n1 + 1 / n2)
+    df <- n - 2
     if (type == ""d"" | type == ""g"") {
       if (pooled_sd) {
         s <- suppressWarnings(sd_pooled(x, y))
-        t <- d / (s * sqrt(1 / n1 + 1 / n2))
+
+        se <- s * sqrt(1 / n1 + 1 / n2)
+        df <- n - 2
       } else {
         s1 <- stats::sd(x)
         s2 <- stats::sd(y)
         s <- sqrt((s1 ^ 2 + s2 ^ 2) / 2)
-        t <- d / sqrt(s1 ^ 2 / n1 + s2 ^ 2 / n2)
+
+        se1 <- sqrt(s1 ^ 2 / n1)
+        se2 <- sqrt(s2 ^ 2 / n2)
+        se <- sqrt(se1^2 + se2^2)
+        df <- se ^ 4 / (se1 ^ 4 / (n1 - 1) + se2 ^ 4 / (n2 - 1))
       }
     } else if (type == ""delta"") {
       s <- stats::sd(y)
-      t <- d / (s * sqrt(1 / n1 + 1 / n2))
+
+      se <- s * sqrt(1 / n1 + 1 / n2)
     }
   }
 
@@ -175,13 +184,9 @@ glass_delta <- function(x, y = NULL, data = NULL, correction = FALSE, ci = 0.95)
     # Add cis
     out$CI <- ci
 
+    t <- d / se
     ts <- .get_ncp_t(t, df, ci)
 
-    # paired <- 2 - paired
-    #
-    # out$CI_low <- paired * ts[1] / sqrt(hn)
-    # out$CI_high <- paired * ts[2] / sqrt(hn)
-
     out$CI_low <- ts[1] * sqrt(hn)
     out$CI_high <- ts[2] * sqrt(hn)
   }

---FILE: tests/testthat/test-standardized_differences.R---
@@ -45,8 +45,8 @@ if (require(""testthat"") && require(""effectsize"")) {
     x <- cohens_d(wt ~ am, data = mtcars, pooled_sd = FALSE)
     testthat::expect_equal(colnames(x)[1], ""Cohens_d"")
     testthat::expect_equal(x[[1]], 1.934, tolerance = 0.001)
-    testthat::expect_equal(x$CI_low, 1.102, tolerance = 0.001)
-    testthat::expect_equal(x$CI_high, 2.829, tolerance = 0.001)
+    testthat::expect_equal(x$CI_low, 1.098798, tolerance = 0.001)
+    testthat::expect_equal(x$CI_high, 2.833495, tolerance = 0.001)
   })
 
   test_that(""hedges_g"", {",True,False,Implementation / Logic,6
easystats,effectsize,7d3d0f70026f533e7ffb877b186de3b08ae2b76a,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-01T14:37:55Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-01T14:37:55Z,"Update README.Rmd

https://github.com/easystats/easystats/issues/85",README.Rmd,True,False,True,False,2,2,4,"---FILE: README.Rmd---
@@ -43,8 +43,8 @@ The goal of this package is to provide utilities to work with indices of effect
 
 Run the following to install the latest GitHub-version of `effectsize`:
 ```{r eval=FALSE, message=FALSE, warning=FALSE}
-install.packages(""devtools"")
-devtools::install_github(""easystats/effectsize"")
+install.packages(""remotes"")
+remotes::install_github(""easystats/effectsize"")
 ```
 
 Or install the latest stable release from CRAN:",False,True,Documentation / Formatting,7
easystats,effectsize,b5d1a55e553092f49b35ca20fb1e9dfb518b2215,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-01T14:34:48Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-12-01T14:34:48Z,"#215

Fix issue introduced with complete.cases",R/cohens_d.R;tests/testthat/test-standardized_differences.R,False,True,True,False,20,7,27,"---FILE: R/cohens_d.R---
@@ -125,7 +125,7 @@ glass_delta <- function(x, y = NULL, data = NULL, correction = FALSE, ci = 0.95)
     if (type == ""delta"") {
       stop(""For Glass' Delta, please provide data from two samples."", call. = FALSE)
     }
-    y <- 0
+    y <- rep(0, length.out = length(x))
     paired <- TRUE
   }
 
@@ -142,9 +142,12 @@ glass_delta <- function(x, y = NULL, data = NULL, correction = FALSE, ci = 0.95)
     hn <- 1 / df
     t <- d / (s / sqrt(n))
   } else {
-    d <- mean(x, na.rm = TRUE) - mean(y, na.rm = TRUE)
-    n1 <- length(stats::na.omit(x))
-    n2 <- length(stats::na.omit(y))
+    x <- stats::na.omit(x)
+    y <- stats::na.omit(y)
+
+    d <- mean(x) - mean(y)
+    n1 <- length(x)
+    n2 <- length(y)
     n <- n1 + n2
     df <- n - 2
     hn <- (1 / n1 + 1 / n2)
@@ -153,13 +156,13 @@ glass_delta <- function(x, y = NULL, data = NULL, correction = FALSE, ci = 0.95)
         s <- suppressWarnings(sd_pooled(x, y))
         t <- d / (s * sqrt(1 / n1 + 1 / n2))
       } else {
-        s1 <- stats::sd(x, na.rm = TRUE)
-        s2 <- stats::sd(y, na.rm = TRUE)
+        s1 <- stats::sd(x)
+        s2 <- stats::sd(y)
         s <- sqrt((s1 ^ 2 + s2 ^ 2) / 2)
         t <- d / sqrt(s1 ^ 2 / n1 + s2 ^ 2 / n2)
       }
     } else if (type == ""delta"") {
-      s <- stats::sd(y, na.rm = TRUE)
+      s <- stats::sd(y)
       t <- d / (s * sqrt(1 / n1 + 1 / n2))
     }
   }

---FILE: tests/testthat/test-standardized_differences.R---
@@ -84,4 +84,14 @@ if (require(""testthat"") && require(""effectsize"")) {
       testthat::expect_equal(glass_delta(x2, x1)$Glass_delta, 1.5, tolerance = 1e-2)
     })
   }
+
+  test_that(""Missing values"", {
+    x <- c(1, 2, NA, 3)
+    y <- c(1, 1, 2, 3)
+    testthat::expect_equal(cohens_d(x, y)[[1]], 0.2564946, tolerance = 0.01) # indep
+    testthat::expect_equal(cohens_d(x, y, paired = TRUE)[[1]], 0.5773503, tolerance = 0.01) # paired
+
+    # no length problems
+    testthat::expect_error(cohens_d(mtcars$mpg - 23), regexp = NA)
+  })
 }",True,False,Implementation / Logic,6
easystats,effectsize,a2ae2aee3545354491fd329a2cc0100e1aa2b353,mattansb,35330040+mattansb@users.noreply.github.com,2020-11-26T14:47:42Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-11-26T14:47:42Z,"Use export_table

https://github.com/easystats/easystats/issues/83",DESCRIPTION;R/print.effectsize_table.R;R/print.rules.R,False,True,True,False,3,3,6,"---FILE: DESCRIPTION---
@@ -34,7 +34,7 @@ Encoding: UTF-8
 Depends:
 	R (>= 3.5)
 Imports:
-	insight (>= 0.10.0),
+	insight (>= 0.11.0),
 	bayestestR (>= 0.7.5),
 	parameters (>= 0.8.6),
 	stats,

---FILE: R/print.effectsize_table.R---
@@ -19,7 +19,7 @@ print.effectsize_table <- function(x, digits = 2, ...){
     x$CI_low <- x$CI_high <- NULL
   }
 
-  cat(insight::format_table(x, digits = digits))
+  cat(insight::export_table(x, digits = digits))
 
   ## MSB: Move to own printing function?
   if (!is.null(method <- attr(x_orig, ""std_method""))) {

---FILE: R/print.rules.R---
@@ -9,7 +9,7 @@ print.rules <- function(x, ...){
     df <- data.frame(setNames(as.list(x$values), x$labels), check.names = FALSE)
     df <- cbind(""Label "" = ""Value "", df)
     insight::print_color(paste0(""# Reference values ("",name,"")\n\n""), ""blue"")
-    cat(insight::format_table(df))
+    cat(insight::export_table(df))
   } else{
     if (isTRUE(attr(x, ""right""))) {
       gLeft <- "" <= """,True,False,Dependency / Package,6
easystats,effectsize,61e95cb89880fcafb7a500f786876235fe141be4,Daniel,mail@danielluedecke.de,2020-11-24T16:47:06Z,Daniel,mail@danielluedecke.de,2020-11-24T16:47:06Z,fix check issues,R/interpret.R;R/interpret.lavaan.R;man/interpret.lavaan.Rd,False,True,True,False,11,8,19,"---FILE: R/interpret.R---
@@ -27,26 +27,26 @@
 #' @export
 rules <- function(values, labels = NULL, name = NULL, right = TRUE) {
 
-  if(is.null(labels)){
-    if(is.list(values)){
+  if (is.null(labels)) {
+    if (is.list(values)) {
       values <- unlist(values)
     }
-    if(is.null(names(values))){
+    if (is.null(names(values))) {
       labels <- values
     } else{
       labels <- names(values)
     }
   }
 
   # Sanity checks
-  if(length(labels) < length(values)){
+  if (length(labels) < length(values)) {
     stop(""There cannot be less labels than reference values!"")
-  } else if(length(labels) > length(values) + 1){
+  } else if (length(labels) > length(values) + 1) {
     stop(""Too many labels for the number of reference values!"")
   }
 
   if (length(values) == length(labels) - 1) {
-    if (is.unsorted(values)){
+    if (is.unsorted(values)) {
       stop(""Reference values must be sorted."")
     }
   } else {
@@ -59,7 +59,7 @@ rules <- function(values, labels = NULL, name = NULL, right = TRUE) {
     labels = labels
   )
 
-  if(is.null(name)){
+  if (is.null(name)) {
     attr(out, ""rule_name"") <- ""Custom rules""
   } else{
     attr(out, ""rule_name"") <- name

---FILE: R/interpret.lavaan.R---
@@ -1,6 +1,7 @@
 #' Interpretation for lavaan objects
 #'
 #' @param x An object of class \code{lavaan}.
+#' @inheritParams interpret
 #'
 #' @examples
 #' library(effectsize)
@@ -14,7 +15,7 @@
 #'   interpret(model)
 #' }
 #' @export
-interpret.lavaan <- function(x, ...){
+interpret.lavaan <- function(x, ...) {
   interpret(performance::model_performance(x, ...), ...)
 }
 

---FILE: man/interpret.lavaan.Rd---
@@ -8,6 +8,8 @@
 }
 \arguments{
 \item{x}{An object of class \code{lavaan}.}
+
+\item{...}{Currently not used.}
 }
 \description{
 Interpretation for lavaan objects",True,False,Documentation / Formatting,6
easystats,effectsize,c972b5624ae1f19c279050a4e1e3d2148d7feb9c,Daniel,mail@danielluedecke.de,2020-11-24T16:14:59Z,Daniel,mail@danielluedecke.de,2020-11-24T16:14:59Z,fix check issues,NAMESPACE;R/interpret.R;man/interpret.Rd,False,True,True,False,15,4,19,"---FILE: NAMESPACE---
@@ -15,6 +15,7 @@ S3method(equivalence_test,effectsize_table)
 S3method(eta_squared_posterior,brmsfit)
 S3method(eta_squared_posterior,stanreg)
 S3method(interpret,lavaan)
+S3method(interpret,numeric)
 S3method(interpret,performance_lavaan)
 S3method(interpret_parameters,lm)
 S3method(normalize,data.frame)

---FILE: R/interpret.R---
@@ -91,6 +91,7 @@ is.rules <- function(x) inherits(x, ""rules"")
 #'
 #' @param x Vector of value break points (edges defining categories).
 #' @param rules Set of [rules()].
+#' @param ... Currently not used.
 #' @inheritParams rules
 #'
 #' @seealso rules
@@ -104,14 +105,16 @@ is.rules <- function(x) inherits(x, ""rules"")
 #' interpret(c(0.35, 0.15), c(""small"" = 0.2, ""large"" = 0.4), name = ""Cohen's Rules"")
 #' interpret(c(0.35, 0.15), rules(c(0.2, 0.4), c(""small"", ""medium"", ""large"")))
 #' @export
-interpret <- function(x, ...){
+interpret <- function(x, ...) {
   UseMethod(""interpret"")
 }
 
 
+#' @rdname interpret
+#' @export
 interpret.numeric <- function(x, rules, name = attr(rules, ""rule_name""), ...) {
 
-  if(!inherits(rules, ""rules"")){
+  if (!inherits(rules, ""rules"")) {
     rules <- rules(rules)
   }
 
@@ -121,7 +124,7 @@ interpret.numeric <- function(x, rules, name = attr(rules, ""rule_name""), ...) {
     out <- .interpret(x, rules)
   }
 
-  if(is.null(name)){
+  if (is.null(name)) {
     attr(out, ""rule_name"") <- ""Custom rules""
   } else{
     attr(out, ""rule_name"") <- name
@@ -136,7 +139,7 @@ interpret.numeric <- function(x, rules, name = attr(rules, ""rule_name""), ...) {
 .interpret <- function(x, rules) {
   if (is.na(x)) return(NA)
 
-  if(length(rules$values) == length(rules$labels)){
+  if (length(rules$values) == length(rules$labels)) {
     index <- which.min(abs(x - rules$values))
   } else{
     if (isTRUE(attr(rules, ""right""))) {

---FILE: man/interpret.Rd---
@@ -2,14 +2,21 @@
 % Please edit documentation in R/interpret.R
 \name{interpret}
 \alias{interpret}
+\alias{interpret.numeric}
 \title{Generic function for interpretation}
 \usage{
 interpret(x, ...)
+
+\method{interpret}{numeric}(x, rules, name = attr(rules, ""rule_name""), ...)
 }
 \arguments{
 \item{x}{Vector of value break points (edges defining categories).}
 
+\item{...}{Currently not used.}
+
 \item{rules}{Set of \code{\link[=rules]{rules()}}.}
+
+\item{name}{Name of the set of rules (stored as a 'rule_name' attribute).}
 }
 \description{
 Interpret a value based on a set of rules. See \code{\link[=rules]{rules()}}.",True,False,Documentation / Formatting,6
easystats,effectsize,82acb25b1f3047919f9d76454d4506a2b8aff1a9,mattansb,35330040+mattansb@users.noreply.github.com,2020-11-12T10:09:07Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-11-12T10:09:07Z,fix workflow to main is action,.github/workflows/R-check.yaml;.github/workflows/pkgdown.yml,False,False,False,False,3,3,6,"---FILE: .github/workflows/R-check.yaml---
@@ -1,10 +1,10 @@
 on:
   push:
     branches:
-      - master
+      - main
   pull_request:
     branches:
-      - master
+      - main
 
 name: R-check
 

---FILE: .github/workflows/pkgdown.yml---
@@ -1,6 +1,6 @@
 on:
   push:
-    branches: master
+    branches: main
 
 name: pkgdown
 ",False,False,Documentation / Formatting,3
easystats,effectsize,bbec0d95a86a5082b969d72f61da80ec770f6777,mattansb,35330040+mattansb@users.noreply.github.com,2020-11-10T09:27:34Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-11-10T09:27:34Z,"testthat 3rd ed

tol -> tolerance (and fix test values)
check.attributes -> ignore_attr",DESCRIPTION;tests/testthat/test-convert.R;tests/testthat/test-cramers_v_etc.R;tests/testthat/test-datatransform.R;tests/testthat/test-effectsize.R;tests/testthat/test-es_from_statistic.R;tests/testthat/test-eta_squared_etc.R;tests/testthat/test-interpret.R;tests/testthat/test-standardize-data.R;tests/testthat/test-standardize-models.R;tests/testthat/test-standardize_parameters.R;tests/testthat/test-standardized_differences.R,False,True,True,False,158,151,309,"---FILE: DESCRIPTION---
@@ -72,3 +72,6 @@ RoxygenNote: 7.1.1
 Language: en-GB
 VignetteBuilder: knitr
 Roxygen: list(markdown = TRUE)
+Config/testthat/edition: 3
+Config/testthat/parallel: true
+Config/testthat/start-first: watcher, parallel*

---FILE: tests/testthat/test-convert.R---
@@ -11,7 +11,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     testthat::expect_equal(d_to_r(1.1547), 0.5, tolerance = 0.01)
     testthat::expect_equal(r_to_d(0.5), 1.1547, tolerance = 0.01)
 
-    testthat::expect_equal(oddsratio_to_r(d_to_oddsratio(r_to_d(0.5))), 0.5, tol = 0.001)
+    testthat::expect_equal(oddsratio_to_r(d_to_oddsratio(r_to_d(0.5))), 0.5, tolerance = 0.001)
     testthat::expect_equal(oddsratio_to_d(r_to_oddsratio(d_to_r(1), log = TRUE), log = TRUE), 1, tolerance = 0.001)
   })
 

---FILE: tests/testthat/test-cramers_v_etc.R---
@@ -50,7 +50,7 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     # some weird exeptions...
     df <- subset(mtcars, am == ""0"")
-    testthat::expect_equal(cramers_v(table(df$am, df$cyl))[[1]], 0.45, tol = 0.01)
+    testthat::expect_equal(cramers_v(table(df$am, df$cyl))[[1]], 0.45, tolerance = 0.01)
     testthat::expect_equal(cramers_v(table(df$am, df$cyl)), cramers_v(table(df$cyl)))
     testthat::expect_equal(cramers_v(table(df$am, df$cyl)), cramers_v(table(df$cyl, df$am)))
 
@@ -67,11 +67,11 @@ if (require(""testthat"") && require(""effectsize"")) {
     log_or <- oddsratio(mtcars$am, mtcars$cyl > 4, log = TRUE)
 
     testthat::expect_equal(coef(m)[2], -log_or$log_Odds_ratio,
-                           check.attributes = FALSE)
+                           ignore_attr = TRUE)
     testthat::expect_equal(-rev(confint(m)[2,]),
                            unlist(log_or[c(""CI_low"", ""CI_high"")]),
-                           tol = 0.1, # different methods, give slightly different values
-                           check.attributes = FALSE)
+                           tolerance = 0.1, # different methods, give slightly different values
+                           ignore_attr = TRUE)
 
     testthat::expect_equal(log_or, oddsratio(mtcars$cyl > 4, mtcars$am, log = TRUE))
 
@@ -98,27 +98,27 @@ if (require(""testthat"") && require(""effectsize"")) {
              dimnames = list(""1st Survey"" = c(""Approve"", ""Disapprove""),
                              ""2nd Survey"" = c(""Approve"", ""Disapprove"")))
     g <- cohens_g(Performance)
-    testthat::expect_equal(g$Cohens_g, 0.136, tol = 0.01)
-    testthat::expect_equal(g$CI_low, 0.072, tol = 0.01)
-    testthat::expect_equal(g$CI_high, 0.194, tol = 0.01)
+    testthat::expect_equal(g$Cohens_g, 0.136, tolerance = 0.01)
+    testthat::expect_equal(g$CI_low, 0.072, tolerance = 0.01)
+    testthat::expect_equal(g$CI_high, 0.194, tolerance = 0.01)
 
 
     AndersonRainBarrel <- matrix(c(9L, 17L,
                                    5L, 15L), nrow = 2)
     g <- cohens_g(AndersonRainBarrel)
-    testthat::expect_equal(g$Cohens_g, 0.273, tol = 0.01)
-    testthat::expect_equal(g$CI_low, 0.066, tol = 0.01)
-    testthat::expect_equal(g$CI_high, 0.399, tol = 0.01)
+    testthat::expect_equal(g$Cohens_g, 0.273, tolerance = 0.01)
+    testthat::expect_equal(g$CI_low, 0.066, tolerance = 0.01)
+    testthat::expect_equal(g$CI_high, 0.399, tolerance = 0.01)
 
 
     M <- matrix(c(794, 86, 150,
                   570, 794, 86,
                   150, 570, 15),
                 nrow = 3)
     g <- cohens_g(M)
-    testthat::expect_equal(g$Cohens_g, 0.300, tol = 0.01)
-    testthat::expect_equal(g$CI_low, 0.280, tol = 0.01)
-    testthat::expect_equal(g$CI_high, 0.319, tol = 0.01)
+    testthat::expect_equal(g$Cohens_g, 0.300, tolerance = 0.01)
+    testthat::expect_equal(g$CI_low, 0.280, tolerance = 0.01)
+    testthat::expect_equal(g$CI_high, 0.319, tolerance = 0.01)
   })
 
 }
\ No newline at end of file

---FILE: tests/testthat/test-datatransform.R---
@@ -1,49 +1,49 @@
 if (require(""testthat"") && require(""effectsize"") && require(""dplyr"")) {
   test_that(""normalize"", {
     x <- normalize(iris)
-    testthat::expect_equal(mean(x$Sepal.Length), 0.42, tol = 0.01)
+    testthat::expect_equal(mean(x$Sepal.Length), 0.43, tolerance = 0.01)
     testthat::expect_length(levels(x$Species), 3)
-    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 0.635, tol = 0.01)
+    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 0.635, tolerance = 0.01)
 
     x <- normalize(dplyr::group_by(iris, .data$Species))
-    testthat::expect_equal(mean(x$Sepal.Length), 0.509, tol = 0.01)
+    testthat::expect_equal(mean(x$Sepal.Length), 0.509, tolerance = 0.01)
     testthat::expect_length(levels(x$Species), 3)
-    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 0.562, tol = 0.01)
+    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 0.562, tolerance = 0.01)
   })
 
 
 
   test_that(""ranktransform"", {
     x <- ranktransform(iris)
-    testthat::expect_equal(mean(x$Sepal.Length), 75.5, tol = 0.01)
+    testthat::expect_equal(mean(x$Sepal.Length), 75.5, tolerance = 0.01)
     testthat::expect_length(levels(x$Species), 3)
-    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 114 , tol = 0.01)
+    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 114 , tolerance = 0.01)
 
     x <- ranktransform(dplyr::group_by(iris, .data$Species))
-    testthat::expect_equal(mean(x$Sepal.Length), 25.5, tol = 0.01)
+    testthat::expect_equal(mean(x$Sepal.Length), 25.5, tolerance = 0.01)
     testthat::expect_length(levels(x$Species), 3)
-    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 25.5, tol = 0.01)
+    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 25.5, tolerance = 0.01)
   })
 
 
 
   test_that(""change_scale"", {
     x <- change_scale(iris)
-    testthat::expect_equal(mean(x$Sepal.Length), 42.9, tol = 0.01)
+    testthat::expect_equal(mean(x$Sepal.Length), 42.9, tolerance = 0.01)
     testthat::expect_length(levels(x$Species), 3)
-    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 63.6 , tol = 0.01)
+    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 63.6 , tolerance = 0.01)
 
     x <- change_scale(dplyr::group_by(iris, .data$Species))
-    testthat::expect_equal(mean(x$Sepal.Length), 50.9, tol = 0.01)
+    testthat::expect_equal(mean(x$Sepal.Length), 50.9, tolerance = 0.01)
     testthat::expect_length(levels(x$Species), 3)
-    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 56.3, tol = 0.01)
+    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 56.3, tolerance = 0.01)
   })
 
 
   test_that(""adjust"", {
     x <- adjust(iris)
-    testthat::expect_equal(mean(x$Sepal.Length), 0, tol = 0.01)
+    testthat::expect_equal(mean(x$Sepal.Length), 0, tolerance = 0.01)
     testthat::expect_length(levels(x$Species), 3)
-    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 0 , tol = 0.01)
+    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 0 , tolerance = 0.01)
   })
-}
\ No newline at end of file
+}

---FILE: tests/testthat/test-effectsize.R---
@@ -5,15 +5,15 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     ## One sample
     htest <- t.test(mtcars$mpg - 15)
-    testthat::expect_equal(effectsize::effectsize(htest)$d, 0.858, tol = 0.001)
+    testthat::expect_equal(effectsize::effectsize(htest)$d, 0.858, tolerance = 0.001)
 
     ## paired
     htest <- t.test(iris$Sepal.Length, iris$Sepal.Width, paired = TRUE)
-    testthat::expect_equal(effectsize::effectsize(htest)$d, 2.852, tol = 0.001)
+    testthat::expect_equal(effectsize::effectsize(htest)$d, 2.852, tolerance = 0.001)
 
     ## two sample
     htest <- t.test(mpg ~ am, mtcars, var.equal = TRUE)
-    testthat::expect_equal(effectsize::effectsize(htest)$d, -1.499, tol = 0.001)
+    testthat::expect_equal(effectsize::effectsize(htest)$d, -1.499, tolerance = 0.001)
   })
 
 
@@ -24,12 +24,12 @@ if (require(""testthat"") && require(""effectsize"")) {
     Xsq1 <- chisq.test(contingency_table)
     Xsq2 <- chisq.test(contingency_table/10)
 
-    testthat::expect_equal(effectsize(Xsq1)$Cramers_v, 0.07, tol = 0.01)
+    testthat::expect_equal(effectsize(Xsq1)$Cramers_v, 0.073, tolerance = 0.01)
     testthat::expect_equal(effectsize(Xsq1)$Cramers_v,
                            effectsize(Xsq2)$Cramers_v)
 
     Xsq3 <- chisq.test(table(mtcars$cyl))
-    testthat::expect_equal(effectsize(Xsq3)$Cramers_v, 0.19, tol = 0.01)
+    testthat::expect_equal(effectsize(Xsq3)$Cramers_v, 0.19, tolerance = 0.01)
     testthat::expect_equal(
       effectsize(Xsq3)$Cramers_v,
       cramers_v(table(mtcars$cyl))$Cramers_v
@@ -41,9 +41,9 @@ if (require(""testthat"") && require(""effectsize"")) {
     s_ <- suppressWarnings(cor.test(iris$Sepal.Width, iris$Sepal.Length, method = ""spearman""))
     t_ <- cor.test(iris$Sepal.Width, iris$Sepal.Length, method = ""kendall"")
 
-    testthat::expect_equal(effectsize(r_)[[1]], -0.118, tol = 0.01)
-    testthat::expect_equal(effectsize(s_)[[1]], -0.167, tol = 0.01)
-    testthat::expect_equal(effectsize(t_)[[1]], -0.077, tol = 0.01)
+    testthat::expect_equal(effectsize(r_)[[1]], -0.118, tolerance = 0.01)
+    testthat::expect_equal(effectsize(s_)[[1]], -0.167, tolerance = 0.01)
+    testthat::expect_equal(effectsize(t_)[[1]], -0.077, tolerance = 0.01)
 
     # no CI for tau or sr
     testthat::expect_equal(ncol(effectsize(r_)), 4L)
@@ -64,15 +64,17 @@ if (require(""testthat"") && require(""effectsize"")) {
   # BayesFactor -------------------------------------------------------------
 
   if (require(""BayesFactor"")) {
-    set.seed(6)
-    data(raceDolls)
-    bf1 <- contingencyTableBF(raceDolls, sampleType = ""poisson"", fixedMargin = ""cols"")
-    testthat::expect_equal(effectsize(bf1, test = NULL)[[2]], 0.16, tol = 0.01)
-
-    bf2 <- ttestBF(mtcars$mpg[mtcars$am == 1], mtcars$mpg[mtcars$am == 0])
-    testthat::expect_equal(effectsize(bf2, test = NULL)[[2]], 1.30, tol = 0.01)
-
-    bf3 <- correlationBF(iris$Sepal.Length, iris$Sepal.Width)
-    testthat::expect_equal(effectsize(bf3, test = NULL)[[2]], -0.12, tol = 0.01)
+    test_that(""aov"", {
+      set.seed(6)
+      data(raceDolls)
+      bf1 <- contingencyTableBF(raceDolls, sampleType = ""poisson"", fixedMargin = ""cols"")
+      testthat::expect_equal(effectsize(bf1, test = NULL)[[2]], 0.164, tolerance = 0.01)
+
+      bf2 <- ttestBF(mtcars$mpg[mtcars$am == 1], mtcars$mpg[mtcars$am == 0])
+      testthat::expect_equal(effectsize(bf2, test = NULL)[[2]], 1.30, tolerance = 0.01)
+
+      bf3 <- correlationBF(iris$Sepal.Length, iris$Sepal.Width)
+      testthat::expect_equal(effectsize(bf3, test = NULL)[[2]], -0.116, tolerance = 0.01)
+    })
   }
 }
\ No newline at end of file

---FILE: tests/testthat/test-es_from_statistic.R---
@@ -4,7 +4,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     res2 <- t_to_r(t = res1$statistic, res1$parameter)
 
     testthat::expect_equal(unname(res1$estimate), res2$r, tolerance = 0.01)
-    testthat::expect_equal(unname(res1$conf.int[1]), res2$CI_low, tolerance = 0.01)
+    testthat::expect_equal(unname(res1$conf.int[1]), res2$CI_low, tolerance = 0.02)
     testthat::expect_equal(unname(res1$conf.int[2]), res2$CI_high, tolerance = 0.01)
   })
 
@@ -15,26 +15,26 @@ if (require(""testthat"") && require(""effectsize"")) {
                                         c(484, 239, 477)))
     res <- cramers_v(contingency_table)
 
-    testthat::expect_equal(res$Cramers_v, 0.072, tolerance = 0.001)
-    testthat::expect_equal(res$CI_low, 0.046, tolerance = 0.001)
-    testthat::expect_equal(res$CI_high, 0.091, tolerance = 0.001)
+    testthat::expect_equal(res$Cramers_v, 0.072, tolerance = 0.01)
+    testthat::expect_equal(res$CI_low, 0.047, tolerance = 0.01)
+    testthat::expect_equal(res$CI_high, 0.091, tolerance = 0.01)
   })
 
 
   test_that(""d"", {
     res <- t_to_d(4, 68)
 
-    testthat::expect_equal(res$d, 0.970, tolerance = 0.001)
-    testthat::expect_equal(res$CI_low, 0.464, tolerance = 0.001)
-    testthat::expect_equal(res$CI_high, 1.469, tolerance = 0.001)
+    testthat::expect_equal(res$d, 0.970, tolerance = 0.01)
+    testthat::expect_equal(res$CI_low, 0.464, tolerance = 0.01)
+    testthat::expect_equal(res$CI_high, 1.469, tolerance = 0.01)
   })
 
   test_that(""eta2"", {
     res <- F_to_eta2(4, 3, 123)
 
-    testthat::expect_equal(res$Eta2_partial, 0.088, tolerance = 0.001)
-    testthat::expect_equal(res$CI_low, 0.013, tolerance = 0.001)
-    testthat::expect_equal(res$CI_high, 0.163, tolerance = 0.001)
+    testthat::expect_equal(res$Eta2_partial, 0.089, tolerance = 0.01)
+    testthat::expect_equal(res$CI_low, 0.014, tolerance = 0.02)
+    testthat::expect_equal(res$CI_high, 0.163, tolerance = 0.01)
 
     resf2 <- F_to_f2(4, 3, 123)
     resf <- F_to_f(4, 3, 123)

---FILE: tests/testthat/test-eta_squared_etc.R---
@@ -10,40 +10,40 @@ if (require(""testthat"") && require(""effectsize"")) {
     # eta
     testthat::expect_equal(eta_squared(fit, partial = FALSE)$Eta2,
                            c(0.618, 0.046, 0.000),
-                           tol = 0.001)
+                           tolerance = 0.01)
     testthat::expect_equal(eta_squared(fit, partial = TRUE)$Eta2_partial,
                            c(0.649, 0.121, 0.001),
-                           tol = 0.001)
+                           tolerance = 0.01)
 
     # omega
     testthat::expect_equal(omega_squared(fit, partial = FALSE)$Omega2,
                            c(0.612, 0.043, -0.004),
-                           tol = 0.001)
+                           tolerance = 0.01)
     testthat::expect_equal(omega_squared(fit, partial = TRUE)$Omega2_partial,
                            c(0.638, 0.112, -0.012),
-                           tol = 0.001)
+                           tolerance = 0.01)
 
     # epsilon
     testthat::expect_equal(epsilon_squared(fit, partial = FALSE)$Epsilon2,
                            c(0.614, 0.044, -0.004),
-                           tol = 0.001)
+                           tolerance = 0.001)
     testthat::expect_equal(epsilon_squared(fit, partial = TRUE)$Epsilon2_partial,
                            c(0.644, 0.115, -0.012),
-                           tol = 0.001)
+                           tolerance = 0.01)
 
     # Cohen's f/f2
     testthat::expect_equal(cohens_f_squared(fit, partial = FALSE)$Cohens_f2,
                            c(1.623, 0.049, 0.000),
-                           tol = 0.001)
+                           tolerance = 0.001)
     testthat::expect_equal(cohens_f_squared(fit, partial = TRUE)$Cohens_f2_partial,
                            c(1.850, 0.139, 0.001),
-                           tol = 0.001)
+                           tolerance = 0.001)
     testthat::expect_equal(cohens_f(fit, partial = FALSE)$Cohens_f,
                            c(1.273, 0.220, 0.021),
-                           tol = 0.001)
+                           tolerance = 0.01)
     testthat::expect_equal(cohens_f(fit, partial = TRUE)$Cohens_f_partial,
                            c(1.360, 0.373, 0.036),
-                           tol = 0.001)
+                           tolerance = 0.001)
     testthat::expect_equal(cohens_f(fit, squared = TRUE), cohens_f_squared(fit))
     testthat::expect_equal(cohens_f_squared(fit, squared = FALSE), cohens_f(fit))
   })
@@ -129,7 +129,7 @@ if (require(""testthat"") && require(""effectsize"")) {
     fsD <- cohens_f_squared(m1, model2 = m2)[,1:4]
     fs <- cohens_f_squared(m2)[-1,-1] # this ONLY works because of the default type-I errors!!!!
     rownames(fsD) <- rownames(fs) <- 1
-    testthat::expect_equal(fsD, fs, tol = 0.01)
+    testthat::expect_equal(fsD, fs, tolerance = 0.01)
 
     if (require(""performance"")) {
       fsD <- cohens_f_squared(m1, model2 = m2)
@@ -184,19 +184,19 @@ if (require(""testthat"") && require(""effectsize"")) {
       testthat::expect_equal(ef$Eta2_generalized,
                              c(0.211, 0.083, 0.186, 0.193, 0.099,
                                0.002, 0.015, 0.132, 0.001, 0.004,
-                               0.011, 0.016, 0.008, 0.01, 0.02), tol = 0.05)
+                               0.011, 0.016, 0.008, 0.01, 0.02), tolerance = 0.05)
       testthat::expect_equal(ef$Eta2_generalized,
-                             af$ges, tol = 0.05)
+                             af$ges, tolerance = 0.1)
 
 
       ef <- eta_squared(m$aov, generalized = TRUE)
       af <- anova(m, es = ""ges"",  observed = NULL)
       testthat::expect_equal(ef$Eta2_generalized,
                              c(0.286, 0.111, 0.218, 0.264, 0.142,
                                0.004, 0.021, 0.185, 0.002, 0.005,
-                               0.016, 0.023, 0.013, 0.014, 0.029), tol = 0.05)
+                               0.016, 0.023, 0.013, 0.014, 0.029), tolerance = 0.05)
       testthat::expect_equal(ef$Eta2_generalized,
-                             af$ges, tol = 0.05)
+                             af$ges, tolerance = 0.1)
     })
 
 
@@ -215,11 +215,11 @@ if (require(""testthat"") && require(""effectsize"")) {
 
       ef <- omega_squared(m, partial = TRUE)
       testthat::expect_equal(ef$Omega2_partial,
-                             c(0.323, 0.115, 0.222, 0.320, 0.149, -0.019, -0.017), tol = 0.01)
+                             c(0.323, 0.115, 0.222, 0.320, 0.149, -0.019, -0.017), tolerance = 0.01)
       testthat::expect_equal(ef$CI_low,
-                             c(0, 0, 0, 0.036, 0, 0, 0), tol = 0.01)
+                             c(0, 0, 0, 0.036, 0, 0, 0), tolerance = 0.01)
       testthat::expect_equal(ef$CI_high,
-                             c(0.590, 0.441, 0.505, 0.528, 0.300, 0, 0), tol = 0.01)
+                             c(0.590, 0.441, 0.505, 0.528, 0.300, 0, 0), tolerance = 0.01)
     })
   }
 

---FILE: tests/testthat/test-interpret.R---
@@ -12,8 +12,8 @@ if (require(""testthat"") && require(""effectsize"")) {
     r1 <- rules(c(0, 1), labels = c(""some"", ""few"", ""many""))
     r2 <- rules(c(0, 1), labels = c(""some"", ""few"", ""many""), right = FALSE)
 
-    testthat::expect_equal(interpret(c(0, 1), r1)[], c(""some"", ""few""), check.attributes = FALSE)
-    testthat::expect_equal(interpret(c(0, 1), r2)[], c(""few"", ""many""), check.attributes = FALSE)
+    testthat::expect_equal(interpret(c(0, 1), r1)[], c(""some"", ""few""), ignore_attr = TRUE)
+    testthat::expect_equal(interpret(c(0, 1), r2)[], c(""few"", ""many""), ignore_attr = TRUE)
   })
 
 

---FILE: tests/testthat/test-standardize-data.R---
@@ -3,16 +3,16 @@ if (require(""testthat"") && require(""effectsize"") && require(""dplyr"") && require(
   # standardize.numeric -----------------------------------------------------
   test_that(""standardize.numeric"", {
     x <- standardize(seq(0, 1, length.out = 100))
-    testthat::expect_equal(mean(x), 0, tol = 0.01)
+    testthat::expect_equal(mean(x), 0, tolerance = 0.01)
 
     x <- standardize(seq(0, 1, length.out = 100), two_sd = TRUE)
-    testthat::expect_equal(sd(x), 0.5, tol = 0.01)
+    testthat::expect_equal(sd(x), 0.5, tolerance = 0.01)
 
     x <- standardize(seq(0, 1, length.out = 100), robust = TRUE)
-    testthat::expect_equal(median(x), 0, tol = 0.01)
+    testthat::expect_equal(median(x), 0, tolerance = 0.01)
 
     x <- standardize(seq(0, 1, length.out = 100), robust = TRUE, two_sd = TRUE)
-    testthat::expect_equal(mad(x), 0.5, tol = 0.01)
+    testthat::expect_equal(mad(x), 0.5, tolerance = 0.01)
 
     testthat::expect_message(standardize(c(0, 0, 0, 1, 1)))
   })
@@ -22,14 +22,14 @@ if (require(""testthat"") && require(""effectsize"") && require(""dplyr"") && require(
   test_that(""standardize.data.frame"", {
     data(iris)
     x <- standardize(iris)
-    testthat::expect_equal(mean(x$Sepal.Length), 0, tol = 0.01)
+    testthat::expect_equal(mean(x$Sepal.Length), 0, tolerance = 0.01)
     testthat::expect_length(levels(x$Species), 3)
-    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 0.89, tol = 0.01)
+    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 0.90, tolerance = 0.01)
 
     x <- standardize(dplyr::group_by(iris, Species))
-    testthat::expect_equal(mean(x$Sepal.Length), 0, tol = 0.01)
+    testthat::expect_equal(mean(x$Sepal.Length), 0, tolerance = 0.01)
     testthat::expect_length(levels(x$Species), 3)
-    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 0, tol = 0.01)
+    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 0, tolerance = 0.01)
   })
 
 
@@ -40,18 +40,18 @@ if (require(""testthat"") && require(""effectsize"") && require(""dplyr"") && require(
     iris$Sepal.Length[sample(1:150, 10)] <- NA
 
     x <- standardize(iris)
-    testthat::expect_equal(head(x$Sepal.Length), c(-0.9163, -1.1588, -1.4013, -1.5226, -1.0376, -0.5526), tol = 0.01)
-    testthat::expect_equal(head(x$Sepal.Width), c(0.9965, -0.1377, 0.316, 0.0891, 1.2233, 1.9038), tol = 0.01)
+    testthat::expect_equal(head(x$Sepal.Length), c(-0.9163, -1.1588, -1.4013, -1.5226, -1.0376, -0.5526), tolerance = 0.01)
+    testthat::expect_equal(head(x$Sepal.Width), c(0.9965, -0.1377, 0.316, 0.0891, 1.2233, 1.9038), tolerance = 0.01)
     testthat::expect_equal(mean(x$Sepal.Length), as.numeric(NA))
 
     x <- standardize(iris, two_sd = TRUE)
-    testthat::expect_equal(head(x$Sepal.Length), c(-0.4582, -0.5794, -0.7007, -0.7613, -0.5188, -0.2763), tol = 0.01)
-    testthat::expect_equal(head(x$Sepal.Width), c(0.4982, -0.0689, 0.158, 0.0446, 0.6116, 0.9519), tol = 0.01)
+    testthat::expect_equal(head(x$Sepal.Length), c(-0.4582, -0.5794, -0.7007, -0.7613, -0.5188, -0.2763), tolerance = 0.01)
+    testthat::expect_equal(head(x$Sepal.Width), c(0.4982, -0.0689, 0.158, 0.0446, 0.6116, 0.9519), tolerance = 0.01)
     testthat::expect_equal(mean(x$Sepal.Length), as.numeric(NA))
 
     x <- standardize(dplyr::group_by(iris, .data$Species))
-    testthat::expect_equal(head(x$Sepal.Length), c(0.2086, -0.3681, -0.9447, -1.233, -0.0797, 1.0735), tol = 0.01)
-    testthat::expect_equal(head(x$Sepal.Width), c(0.1441, -1.1586, -0.6375, -0.8981, 0.4047, 1.1863), tol = 0.01)
+    testthat::expect_equal(head(x$Sepal.Length), c(0.2086, -0.3681, -0.9447, -1.233, -0.0797, 1.0735), tolerance = 0.01)
+    testthat::expect_equal(head(x$Sepal.Width), c(0.1441, -1.1586, -0.6375, -0.8981, 0.4047, 1.1863), tolerance = 0.01)
     testthat::expect_equal(mean(x$Sepal.Length), as.numeric(NA))
   })
 
@@ -66,18 +66,18 @@ if (require(""testthat"") && require(""effectsize"") && require(""dplyr"") && require(
     testthat::expect_equal(colnames(x), c(""Sepal.Length"", ""Sepal.Width"", ""Petal.Length"", ""Petal.Width"",
                                           ""Species"", ""Sepal.Length_z"", ""Sepal.Width_z"", ""Petal.Length_z"",
                                           ""Petal.Width_z""))
-    testthat::expect_equal(head(x$Sepal.Length_z), c(-0.9163, -1.1588, -1.4013, -1.5226, -1.0376, -0.5526), tol = 0.01)
-    testthat::expect_equal(head(x$Sepal.Width_z), c(0.9965, -0.1377, 0.316, 0.0891, 1.2233, 1.9038), tol = 0.01)
+    testthat::expect_equal(head(x$Sepal.Length_z), c(-0.9163, -1.1588, -1.4013, -1.5226, -1.0376, -0.5526), tolerance = 0.01)
+    testthat::expect_equal(head(x$Sepal.Width_z), c(0.9965, -0.1377, 0.316, 0.0891, 1.2233, 1.9038), tolerance = 0.01)
     testthat::expect_equal(mean(x$Sepal.Length_z), as.numeric(NA))
 
     x <- standardize(iris, two_sd = TRUE, append = TRUE)
-    testthat::expect_equal(head(x$Sepal.Length_z), c(-0.4582, -0.5794, -0.7007, -0.7613, -0.5188, -0.2763), tol = 0.01)
-    testthat::expect_equal(head(x$Sepal.Width_z), c(0.4982, -0.0689, 0.158, 0.0446, 0.6116, 0.9519), tol = 0.01)
+    testthat::expect_equal(head(x$Sepal.Length_z), c(-0.4582, -0.5794, -0.7007, -0.7613, -0.5188, -0.2763), tolerance = 0.01)
+    testthat::expect_equal(head(x$Sepal.Width_z), c(0.4982, -0.0689, 0.158, 0.0446, 0.6116, 0.9519), tolerance = 0.01)
     testthat::expect_equal(mean(x$Sepal.Length_z), as.numeric(NA))
 
     x <- standardize(dplyr::group_by(iris, .data$Species), append = TRUE)
-    testthat::expect_equal(head(x$Sepal.Length_z), c(0.2086, -0.3681, -0.9447, -1.233, -0.0797, 1.0735), tol = 0.01)
-    testthat::expect_equal(head(x$Sepal.Width_z), c(0.1441, -1.1586, -0.6375, -0.8981, 0.4047, 1.1863), tol = 0.01)
+    testthat::expect_equal(head(x$Sepal.Length_z), c(0.2086, -0.3681, -0.9447, -1.233, -0.0797, 1.0735), tolerance = 0.01)
+    testthat::expect_equal(head(x$Sepal.Width_z), c(0.1441, -1.1586, -0.6375, -0.8981, 0.4047, 1.1863), tolerance = 0.01)
     testthat::expect_equal(mean(x$Sepal.Length_z), as.numeric(NA))
   })
 

---FILE: tests/testthat/test-standardize-models.R---
@@ -118,27 +118,29 @@ if (require(""testthat"") && require(""effectsize"") && require(""lme4"")) {
     m2 <- glm(Reaction ~ Days, family = Gamma(link = ""identity""), data = sleepstudy)
     m3 <- glm(Reaction ~ Days, family = inverse.gaussian(), data = sleepstudy)
 
-    testthat::expect_equal(coef(standardize(m1)), c(`(Intercept)` = 0.00338, Days = -0.00034), tolerance = 1e-3)
+    testthat::expect_equal(coef(standardize(m1)), c(`(Intercept)` = 0.00338, Days = -0.00034), tolerance = 1e-2)
     testthat::expect_equal(coef(standardize(m2)), c(`(Intercept)` = 298.48571, Days = 29.70754), tolerance = 1e-3)
     testthat::expect_equal(coef(standardize(m3)), c(`(Intercept)` = 1e-05, Days = 0), tolerance = 1e-3)
   })
 
 
   # mediation models --------------------------------------------------------
   if (require(mediation)) {
-    set.seed(444)
-    data(jobs, package = ""mediation"")
-    b.int <- lm(job_seek ~ treat * age + econ_hard + sex, data = jobs)
-    d.int <- lm(depress2 ~ treat * job_seek * age + econ_hard + sex, data = jobs)
-
-    med1 <- mediate(b.int, d.int, sims = 200, treat = ""treat"", mediator = ""job_seek"")
-    med2 <- mediate(b.int, d.int, sims = 200, treat = ""treat"", mediator = ""job_seek"",
-                    covariates = list(age = mean(jobs$age)))
-
-    out1 <- summary(standardize(med1))
-    testthat::expect_message(out2 <- summary(standardize(med2)))
-    testthat::expect_equal(unlist(out1[c(""d0"",""d1"",""z0"",""z1"",""n0"",""n1"", ""tau.coef"")]),
-                           unlist(out2[c(""d0"",""d1"",""z0"",""z1"",""n0"",""n1"", ""tau.coef"")]), tol = 0.1)
+    test_that(""standardize non-Gaussian response"", {
+      set.seed(444)
+      data(jobs, package = ""mediation"")
+      b.int <- lm(job_seek ~ treat * age + econ_hard + sex, data = jobs)
+      d.int <- lm(depress2 ~ treat * job_seek * age + econ_hard + sex, data = jobs)
+
+      med1 <- mediate(b.int, d.int, sims = 200, treat = ""treat"", mediator = ""job_seek"")
+      med2 <- mediate(b.int, d.int, sims = 200, treat = ""treat"", mediator = ""job_seek"",
+                      covariates = list(age = mean(jobs$age)))
+
+      out1 <- summary(standardize(med1))
+      testthat::expect_message(out2 <- summary(standardize(med2)))
+      testthat::expect_equal(unlist(out1[c(""d0"",""d1"",""z0"",""z1"",""n0"",""n1"", ""tau.coef"")]),
+                             unlist(out2[c(""d0"",""d1"",""z0"",""z1"",""n0"",""n1"", ""tau.coef"")]), tolerance = 0.1)
+    })
   }
 
 }

---FILE: tests/testthat/test-standardize_parameters.R---
@@ -8,7 +8,7 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     model <- lm(Sepal.Length ~ Petal.Length, data = df)
     es <- standardize_parameters(model)
-    testthat::expect_equal(es[2,2], r, tol = 0.01)
+    testthat::expect_equal(es[2,2], r, tolerance = 0.01)
   })
 
 
@@ -43,58 +43,58 @@ if (require(""testthat"") && require(""effectsize"")) {
     testthat::expect_equal(
       standardize_parameters(model, method = ""refit"")$Std_Coefficient,
       c(0.044, -0.072, -0.060, 0.844),
-      tol = 0.01
+      tolerance = 0.01
     )
 
     testthat::expect_equal(
       standardize_parameters(model, method = ""posthoc"")$Std_Coefficient,
       c(0, -0.072, -0.060, 0.844),
-      tol = 0.01
+      tolerance = 0.01
     )
 
     testthat::expect_equal(
       standardize_parameters(model, method = ""smart"")$Std_Coefficient,
       c(0, -0.170, -0.142, 0.844),
-      tol = 0.01
+      tolerance = 0.01
     )
 
     testthat::expect_equal(
       standardize_parameters(model, method = ""basic"")$Std_Coefficient,
       c(0, -0.034, -0.028, 0.844),
-      tol = 0.01
+      tolerance = 0.01
     )
 
     ## CI
     testthat::expect_equal(
       standardize_parameters(model, method = ""basic"")$CI_low,
       c(0, -0.294, -0.433, 0.491),
-      tol = 0.01
+      tolerance = 0.01
     )
 
     testthat::expect_equal(
       standardize_parameters(model, method = ""basic"")$CI_high,
       c(0, 0.225, 0.375, 1.196),
-      tol = 0.01
+      tolerance = 0.01
     )
 
     testthat::expect_equal(
       standardize_parameters(model, ci = 0.8, method = ""basic"")$CI_low,
       c(0, -0.203, -0.292, 0.614),
-      tol = 0.01
+      tolerance = 0.01
     )
 
     testthat::expect_equal(
       standardize_parameters(model, ci = 0.8, method = ""basic"")$CI_high,
       c(0, 0.135, 0.234, 1.073),
-      tol = 0.01
+      tolerance = 0.01
     )
 
     data(""mtcars"")
     m0 <- lm(mpg ~ cyl + factor(am), mtcars)
     testthat::expect_equal(standardize_parameters(m0, method = ""refit"")[[2]][-1],
-                           standardize_parameters(m0, method = ""smart"")[[2]][-1], tol = 0.01)
+                           standardize_parameters(m0, method = ""smart"")[[2]][-1], tolerance = 0.01)
     testthat::expect_equal(standardize_parameters(m0, method = ""refit"", two_sd = TRUE)[[2]][-1],
-                           standardize_parameters(m0, method = ""smart"", two_sd = TRUE)[[2]][-1], tol = 0.01)
+                           standardize_parameters(m0, method = ""smart"", two_sd = TRUE)[[2]][-1], tolerance = 0.01)
   })
 
 
@@ -109,7 +109,7 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     testthat::expect_equal(standardize_parameters(m_aov),
                            standardize_parameters(m_lm),
-                           check.attributes = FALSE)
+                           ignore_attr = TRUE)
   })
 
 
@@ -232,18 +232,18 @@ if (require(""testthat"") && require(""effectsize"")) {
       testthat::expect_equal(
         suppressWarnings(standardize_parameters(model, method = ""refit"")$Std_Median[1:4]),
         c(0.065, -0.094, -0.100, 0.862),
-        tol = 0.01
+        tolerance = 0.01
       )
 
       testthat::expect_equal(
         suppressWarnings(standardize_parameters(model, method = ""posthoc"")$Std_Median[1:4]),
         c(0, -0.058, -0.053,  0.838),
-        tol = 0.01
+        tolerance = 0.01
       )
 
       posts <- standardize_posteriors(model, method = ""posthoc"")
       testthat::expect_equal(dim(posts), c(1000, 4))
-      testthat::expect_is(posts, ""data.frame"")
+      testthat::expect_s3_class(posts, ""data.frame"")
     })
   }
 
@@ -309,11 +309,11 @@ if (require(""testthat"") && require(""effectsize"")) {
 
       std1 <- standardize_parameters(m1, method = ""pseudo"")
       expect_equal(std1$Std_Coefficient,
-                   standardize_parameters(m2, method = ""pseudo"")$Std_Coefficient, tol = 0.001)
+                   standardize_parameters(m2, method = ""pseudo"")$Std_Coefficient, tolerance = 0.001)
       expect_equal(std1$Std_Coefficient,
-                   standardize_parameters(m3, method = ""pseudo"")$Std_Coefficient, tol = 0.001)
+                   standardize_parameters(m3, method = ""pseudo"")$Std_Coefficient, tolerance = 0.001)
       expect_equal(std1$Std_Coefficient,
-                   standardize_parameters(m4, method = ""pseudo"")$Std_Coefficient, tol = 0.001)
+                   standardize_parameters(m4, method = ""pseudo"")$Std_Coefficient, tolerance = 0.001)
 
 
 
@@ -343,18 +343,18 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     # post hoc does it right (bar intercept)
     testthat::expect_equal(sm1$Std_Coefficient[-c(1,6)],
-                           sm2$Std_Coefficient[-c(1,6)], tol = 0.01)
+                           sm2$Std_Coefficient[-c(1,6)], tolerance = 0.01)
 
     # basic / smart miss the ZI
     testthat::expect_equal(mp$Coefficient[6:8],
-                           sm3$Std_Coefficient[6:8], tol = 0.01)
+                           sm3$Std_Coefficient[6:8], tolerance = 0.01)
     testthat::expect_equal(mp$Coefficient[6:8],
-                           sm4$Std_Coefficient[6:8], tol = 0.01)
+                           sm4$Std_Coefficient[6:8], tolerance = 0.01)
 
     # get count numerics al right
     testthat::expect_equal(sm1$Std_Coefficient[4:5],
-                           sm3$Std_Coefficient[4:5], tol = 0.01)
+                           sm3$Std_Coefficient[4:5], tolerance = 0.01)
     testthat::expect_equal(sm1$Std_Coefficient[4:5],
-                           sm4$Std_Coefficient[4:5], tol = 0.01)
+                           sm4$Std_Coefficient[4:5], tolerance = 0.01)
   }
 }

---FILE: tests/testthat/test-standardized_differences.R---
@@ -36,52 +36,52 @@ if (require(""testthat"") && require(""effectsize"")) {
   test_that(""cohens_d - pooled"", {
     x <- cohens_d(wt ~ am, data = mtcars, pooled_sd = TRUE)
     testthat::expect_equal(colnames(x)[1], ""Cohens_d"")
-    testthat::expect_equal(x[[1]], 1.892, tol = 0.001)
-    testthat::expect_equal(x$CI_low, 1.030, tol = 0.001)
-    testthat::expect_equal(x$CI_high, 2.732, tol = 0.001)
+    testthat::expect_equal(x[[1]], 1.892, tolerance = 0.001)
+    testthat::expect_equal(x$CI_low, 1.030, tolerance = 0.001)
+    testthat::expect_equal(x$CI_high, 2.732, tolerance = 0.001)
   })
 
   test_that(""cohens_d - non-pooled"", {
     x <- cohens_d(wt ~ am, data = mtcars, pooled_sd = FALSE)
     testthat::expect_equal(colnames(x)[1], ""Cohens_d"")
-    testthat::expect_equal(x[[1]], 1.934, tol = 0.001)
-    testthat::expect_equal(x$CI_low, 1.102, tol = 0.001)
-    testthat::expect_equal(x$CI_high, 2.829, tol = 0.001)
+    testthat::expect_equal(x[[1]], 1.934, tolerance = 0.001)
+    testthat::expect_equal(x$CI_low, 1.102, tolerance = 0.001)
+    testthat::expect_equal(x$CI_high, 2.829, tolerance = 0.001)
   })
 
   test_that(""hedges_g"", {
     x <- hedges_g(wt ~ am, data = mtcars)
     testthat::expect_equal(colnames(x)[1], ""Hedges_g"")
-    testthat::expect_equal(x[[1]], 1.844, tol = 0.001)
-    testthat::expect_equal(x$CI_low, 1.004, tol = 0.001)
-    testthat::expect_equal(x$CI_high, 2.664, tol = 0.001)
+    testthat::expect_equal(x[[1]], 1.844, tolerance = 0.001)
+    testthat::expect_equal(x$CI_low, 1.004, tolerance = 0.001)
+    testthat::expect_equal(x$CI_high, 2.664, tolerance = 0.001)
   })
 
   test_that(""glass_delta"", {
     x <- glass_delta(wt ~ am, data = mtcars)
     testthat::expect_equal(colnames(x)[1], ""Glass_delta"")
-    testthat::expect_equal(x[[1]], 2.200, tol = 0.001)
-    testthat::expect_equal(x$CI_low, 1.292, tol = 0.001)
-    testthat::expect_equal(x$CI_high, 3.086, tol = 0.001)
+    testthat::expect_equal(x[[1]], 2.200, tolerance = 0.001)
+    testthat::expect_equal(x$CI_low, 1.292, tolerance = 0.001)
+    testthat::expect_equal(x$CI_high, 3.086, tolerance = 0.001)
 
     # must be 2 samples
     testthat::expect_error(glass_delta(1:10))
   })
 
 
-  if (require(""bayestestR"")) {
+  if (require(""bayestestR"", quietly = TRUE)) {
     test_that(""fixed values"", {
 
       x1 <- bayestestR::distribution_normal(1e4, mean = 0, sd = 1)
       x2 <- bayestestR::distribution_normal(1e4, mean = 1, sd = 1)
-      testthat::expect_equal(cohens_d(x1, x2)$Cohens_d, -1, tol = 1e-3)
+      testthat::expect_equal(cohens_d(x1, x2)$Cohens_d, -1, tolerance = 1e-3)
 
 
       x1 <- bayestestR::distribution_normal(1e4, mean = 0, sd = 1)
       x2 <- bayestestR::distribution_normal(1e4, mean = 1.5, sd = 2)
 
-      testthat::expect_equal(cohens_d(x1, x2)$Cohens_d, -sqrt(0.9), tol = 1e-2)
-      testthat::expect_equal(glass_delta(x2, x1)$Glass_delta, 1.5, tol = 1e-2)
+      testthat::expect_equal(cohens_d(x1, x2)$Cohens_d, -sqrt(0.9), tolerance = 1e-2)
+      testthat::expect_equal(glass_delta(x2, x1)$Glass_delta, 1.5, tolerance = 1e-2)
     })
   }
-}
\ No newline at end of file
+}",True,False,Dependency / Package,6
easystats,effectsize,49633ce9583224814b9033a4c38be6fa94d6a366,Daniel,mail@danielluedecke.de,2020-11-09T08:10:09Z,Daniel,mail@danielluedecke.de,2020-11-09T08:10:09Z,https://github.com/easystats/report/issues/109,R/standardize.models.R,False,True,True,False,2,2,4,"---FILE: R/standardize.models.R---
@@ -292,7 +292,7 @@ standardize.wbgee <- standardize.wbm
 .log_terms <- function(model, data) {
   x <- insight::find_terms(model, flatten = TRUE)
   # log_pattern <- ""^log\\((.*)\\)""
-  log_pattern <- ""(log\\(log|log|log1|log10|log1p|log2)\\(([^,)]*).*""
+  log_pattern <- ""(log\\(log|log|log1|log10|log1p|log2)\\(([^,)\\+]*).*""
   out <- gsub(log_pattern, ""\\2"", x[grepl(log_pattern, x)])
   intersect(colnames(data), out)
 }
@@ -301,7 +301,7 @@ standardize.wbgee <- standardize.wbm
 #' @importFrom insight find_terms
 .sqrt_terms <- function(model, data) {
   x <- insight::find_terms(model, flatten = TRUE)
-  pattern <- ""sqrt\\(([^,)]*).*""
+  pattern <- ""sqrt\\(([^,\\+)]*).*""
   out <- gsub(pattern, ""\\1"", x[grepl(pattern, x)])
   intersect(colnames(data), out)
 }",True,False,Documentation / Formatting,3
easystats,effectsize,9ebef5988bb720e030136eb5d752bfdddca9102c,Daniel,mail@danielluedecke.de,2020-11-03T14:29:26Z,Daniel,mail@danielluedecke.de,2020-11-03T14:29:26Z,fix test,tests/testthat/test-standardize-models.R,False,True,True,False,1,1,2,"---FILE: tests/testthat/test-standardize-models.R---
@@ -120,6 +120,6 @@ if (require(""testthat"") && require(""effectsize"") && require(""lme4"")) {
 
     testthat::expect_equal(coef(standardize(m1)), c(`(Intercept)` = 0.00338, Days = -0.00034), tolerance = 1e-3)
     testthat::expect_equal(coef(standardize(m2)), c(`(Intercept)` = 298.48571, Days = 29.70754), tolerance = 1e-3)
-    testthat::expect_equal(coef(standardize(m1)), c(`(Intercept)` = 1e-05, Days = 0), tolerance = 1e-3)
+    testthat::expect_equal(coef(standardize(m3)), c(`(Intercept)` = 1e-05, Days = 0), tolerance = 1e-3)
   })
 }",True,False,Dependency / Package,3
easystats,effectsize,2244a857a734bcb87aa2b5a8ff19fc0d64f0da16,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-29T06:16:39Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-29T06:16:39Z,fix title,paper/paper.md,False,False,False,False,4,4,8,"---FILE: paper/paper.md---
@@ -1,5 +1,5 @@
 ---
-title: ""Size does matter: Estimation and Interpretation of Effect Size Indices and Standardized Parameters""
+title: ""Estimation of Effect Size Indices and Standardized Parameters""
 authors:
 - affiliation: 1
   name: Mattan S. Ben-Shachar
@@ -39,7 +39,7 @@ affiliations:
 
 It is often of interest to to assess the strength of an observed association. This is typically done to allow the judgment of the magnitude of an effect (especially when units of measurement are not meaningful), to facilitate comparing predictors' importance within a given model, or both. Though some indices of effect size, such a the correlation coefficient (a standardized covariance coefficient) are readily available, other measures are often harder to obtain. 
 
-**effectsize** is an R-package [@rcore] that fills this important gap. Its primary goal is to provide utilities for estimating a wide variety of standardized effect sizes (i.e., effect sizes that are not tied to the units of measurement of the variables of interest, i.e., they are scale-invariant) and their confidence intervals (CI), from a variety of statistical models. **effectsize** provides easy to use functions, with full documentation and explanation of the various effect sizes offered, and is also used by developers of other R packages as the back-end for effect size computation, such as *parameters* [@ludecke2020extracting] and *ggstatsplot* [@patil2020ggstatsplot], *gtsummary* [@sjoberg2020gtsummary] and more.
+**effectsize** is an R-package [@rcore] that fills this important gap. Its primary goal is to provide utilities for estimating a wide variety of standardized effect sizes (i.e., effect sizes that are not tied to the units of measurement of the variables of interest, i.e., they are scale-invariant) and their confidence intervals (CIs), from a variety of statistical models. **effectsize** provides easy to use functions, with full documentation and explanation of the various effect sizes offered, and is also used by developers of other R packages as the back-end for effect size computation, such as *parameters* [@ludecke2020extracting], *ggstatsplot* [@patil2020ggstatsplot], *gtsummary* [@sjoberg2020gtsummary] and more.
 
 # Examples of Features
 
@@ -117,7 +117,7 @@ standardize_parameters(model, exponentiate = TRUE)
 
 ## Effect Sizes for ANOVAs
 
-In the context of ANOVAs (analysis of variance) or ANOVA-like tables, it is common to report ANOVA-like effect sizes. Unlike standardized parameters, these effect sizes represent the amount of variance explained by each of the model's terms, where each term can be represented by one or more parameters. `eta_squared()` can produce such popular effect sizes as Eta-squared ($\eta^2$), its partial version ($\eta^2_p$), as well as the generalized $\eta^2_G$ [@olejnik2003generalized]:
+Unlike standardized parameters, the effect sizes reported in the context of ANOVAs (analysis of variance) or ANOVA-like tables represent the amount of variance explained by each of the model's terms, where each term can be represented by one or more parameters. `eta_squared()` can produce such popular effect sizes as Eta-squared ($\eta^2$), its partial version ($\eta^2_p$), as well as the generalized $\eta^2_G$ [@olejnik2003generalized]:
 
 
 ``` r
@@ -193,7 +193,7 @@ These functions also power our *Effect Sizes From Test Statistics* shiny app (ht
 
 ### Between Effect Sizes
 
-For comparisons between different types of designs and analyses, it is useful to be able to convert between different types of effect sizes [*d*, *r*, Odds ratios and Risk ratios; @borenstein2009converting; grant2014converting].
+For comparisons between different types of designs and analyses, it is useful to be able to convert between different types of effect sizes [*d*, *r*, Odds ratios and Risk ratios; @borenstein2009converting; @grant2014converting].
 
 ``` r
 r_to_d(0.7)",False,False,Documentation / Formatting,6
easystats,effectsize,5660c59ac2ffb44352e0a2eb4907dd5962dfd589,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-25T08:06:57Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-25T08:06:57Z,fix url,vignettes/standardize_parameters.Rmd,True,False,True,False,1,1,2,"---FILE: vignettes/standardize_parameters.Rmd---
@@ -298,7 +298,7 @@ standardize_parameters(mod_b, method = ""refit"", two_sd = TRUE, exponentiate = TR
 
 # Cohen's *f*
 
-Cohen's $f$ (of [ANOVA fame](https://easystats.github.io/effectsize/articles/anovaES.html/)) can be used as a measure of effect size in the context of sequential multiple regression. That is, when comparing two models, we can examine the ratio between the increase in $R^2$ and the unexplained variance:
+Cohen's $f$ (of [ANOVA fame](https://easystats.github.io/effectsize/articles/anovaES.html)) can be used as a measure of effect size in the context of sequential multiple regression. That is, when comparing two models, we can examine the ratio between the increase in $R^2$ and the unexplained variance:
 
 $$
 f^{2}={R_{AB}^{2}-R_{A}^{2} \over 1-R_{AB}^{2}}",False,True,Rendering / Conversion,3
easystats,effectsize,d1d2f7054d027018a1d77e4e89e9d2f5c1bb23cf,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-23T14:02:29Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-23T14:02:29Z,fix issue raised with LMMs,R/standardize_info.R;R/standardize_parameters.R;tests/testthat/test-standardize_parameters.R,False,True,True,False,4,5,9,"---FILE: R/standardize_info.R---
@@ -380,7 +380,8 @@ standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseu
   Deviation_Response_Pseudo <- Deviation_Pseudo <- numeric(ncol(model_matrix))
   for (i in seq_along(params)) {
     if (types[i] == ""intercept"") {
-      Deviation_Response_Pseudo[i] <- Deviation_Pseudo[i] <- NA
+      Deviation_Response_Pseudo[i] <- sd_y_between # doesn't matter
+      Deviation_Pseudo[i] <- 0
     } else {
       ## dumb way
       if (is_within[i]) {

---FILE: R/standardize_parameters.R---
@@ -311,9 +311,7 @@ standardize_parameters.parameters_model <- function(model, method = ""refit"", ci
   )
 
   if (length(i_missing) ||
-      any(to_complete <-
-          apply(pars[, colnames(pars) %in% .col_2_scale], 1, anyNA) &
-          deviations$Type != ""intercept"")) {
+      any(to_complete <- apply(pars[, colnames(pars) %in% .col_2_scale], 1, anyNA))) {
 
     i_missing <- union(i_missing, which(to_complete))
 

---FILE: tests/testthat/test-standardize_parameters.R---
@@ -288,7 +288,7 @@ if (require(""testthat"") && require(""effectsize"")) {
       SD_y <- SD_y[c(1,2,1,1,1)]
 
       expect_equal(
-        data.frame(Deviation_Response_Pseudo = c(NA,SD_y),Deviation_Pseudo = c(NA,SD_x)),
+        data.frame(Deviation_Response_Pseudo = c(SD_y[2],SD_y),Deviation_Pseudo = c(0,SD_x)),
         standardize_info(m, include_pseudo = TRUE)[, c(""Deviation_Response_Pseudo"", ""Deviation_Pseudo"")]
       )
       expect_equal(",True,False,Implementation / Logic,6
easystats,effectsize,dbd52af4e001a117b6eaca899e767984e4f4dfbc,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-23T08:48:00Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-23T08:48:00Z,fix bug introduced 10 minutes ago ^_^,R/standardize_parameters.R,False,True,True,False,6,2,8,"---FILE: R/standardize_parameters.R---
@@ -310,8 +310,12 @@ standardize_parameters.parameters_model <- function(model, method = ""refit"", ci
     }
   )
 
-  if (length(i_missing) || anyNA(pars[,colnames(pars) %in% .col_2_scale])) {
-    i_missing <- union(i_missing, which(apply(pars[,colnames(pars) %in% .col_2_scale], 1, anyNA)))
+  if (length(i_missing) ||
+      any(to_complete <-
+          apply(pars[, colnames(pars) %in% .col_2_scale], 1, anyNA) &
+          deviations$Type != ""intercept"")) {
+
+    i_missing <- union(i_missing, which(to_complete))
 
     pars[i_missing, colnames(pars) %in% .col_2_scale] <-
       unstd[i_missing, colnames(pars) %in% .col_2_scale]",True,False,Implementation / Logic,6
easystats,effectsize,eb48a86457481a0a9b4883bc116701ccd61379e2,DominiqueMakowski,dom.mak19@gmail.com,2020-10-23T01:37:42Z,DominiqueMakowski,dom.mak19@gmail.com,2020-10-23T01:37:42Z,"allow for ellipsis in interpret_d

This is so that if this function is used in another function with ellipsis it doesn't throw an error if other arguments are passed through it (otherwise it fails in report).",R/interpret_d.R;man/interpret_d.Rd,False,True,True,False,5,2,7,"---FILE: R/interpret_d.R---
@@ -5,6 +5,7 @@
 #'
 #' @param d,g,delta Value or vector of effect size values.
 #' @param rules Can be `""cohen1988""` (default), `""gignac2016""`, `""sawilowsky2009""` or custom set of [rules()].
+#' @param ... Not directly used.
 #'
 #' @section Rules:
 #'
@@ -39,7 +40,7 @@
 #' - Sawilowsky, S. S. (2009). New effect size rules of thumb.
 #'
 #' @export
-interpret_d <- function(d, rules = ""cohen1988"") {
+interpret_d <- function(d, rules = ""cohen1988"", ...) {
   if (is.character(rules) && rules == ""gignac2016"") {
     return(interpret_r(d_to_r(d), rules))
   }

---FILE: man/interpret_d.Rd---
@@ -6,7 +6,7 @@
 \alias{interpret_delta}
 \title{Interpret standardized differences}
 \usage{
-interpret_d(d, rules = ""cohen1988"")
+interpret_d(d, rules = ""cohen1988"", ...)
 
 interpret_g(g, rules = ""cohen1988"")
 
@@ -16,6 +16,8 @@ interpret_delta(delta, rules = ""cohen1988"")
 \item{d, g, delta}{Value or vector of effect size values.}
 
 \item{rules}{Can be \code{""cohen1988""} (default), \code{""gignac2016""}, \code{""sawilowsky2009""} or custom set of \code{\link[=rules]{rules()}}.}
+
+\item{...}{Not directly used.}
 }
 \description{
 Interpretation of standardized differences using different sets of rules of thumb.",True,False,Documentation / Formatting,6
easystats,effectsize,8c0627380ef86442925ad66f95e5b5712f7e380e,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-22T11:50:54Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-22T11:50:54Z,minor vignette fix,vignettes/bayesian_models.Rmd,True,False,True,False,4,4,8,"---FILE: vignettes/bayesian_models.Rmd---
@@ -87,7 +87,7 @@ As we can see, working harder (or at least for longer hours) has stronger predic
 
 ## Introduction
 
-In classical frequentists models, the computation of $eta^2$ or $eta^2_p$ is straightforward: based on the right combinations of sums-of-squares (*SS*s), we get the correct proportion of variance accounted for by some predictor term. However such a computation is not as straightforward for Bayesian models, for various reasons (e.g., the model-*SS* and the residual-*SS* don't necessarily sum to the total-*SS*). Although some have proposed Bayesian methods of estimating explained variance in ANOVA designs [@marsman2019bayesian], these are not yet easy to implement with `stan`-based models.
+In classical frequentists models, the computation of $\eta^2$ or $\eta^2_p$ is straightforward: based on the right combinations of sums-of-squares (*SS*s), we get the correct proportion of variance accounted for by some predictor term. However such a computation is not as straightforward for Bayesian models, for various reasons (e.g., the model-*SS* and the residual-*SS* don't necessarily sum to the total-*SS*). Although some have proposed Bayesian methods of estimating explained variance in ANOVA designs [@marsman2019bayesian], these are not yet easy to implement with `stan`-based models.
 
 An alternative route to obtaining effect sizes of explained variance, is via the use of the ***posterior predictive distribution*** (*PPD*). The PPD is the Bayesian expected distribution of possible unobserved values. Thus, after observing some data, we can estimate not just the expected mean values (the conditional marginal means), but also the full *distribution* of data around these values [@gelman2014bayesian, chapter 7].
 
@@ -111,9 +111,9 @@ table(hardlyworking$age_f,hardlyworking$comps_f)
 And fit our model:
 
 ```{r}
-# use effects coding
-contrasts(hardlyworking$age_f) <- contr.sum
-contrasts(hardlyworking$comps_f) <- contr.sum
+# use (special) effects coding
+contrasts(hardlyworking$age_f) <- bayestestR::contr.bayes
+contrasts(hardlyworking$comps_f) <- bayestestR::contr.bayes
 
 modAOV <- stan_glm(salary ~ age_f * comps_f,
                    data = hardlyworking, family = gaussian(),",False,True,Documentation / Formatting,4
easystats,effectsize,5f73268e2d22a4431bc4af8e37a8abc857f4bca0,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-20T13:27:06Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-20T13:27:06Z,fix attribute pulling,R/standardize_parameters.R,False,True,True,False,2,2,4,"---FILE: R/standardize_parameters.R---
@@ -213,8 +213,8 @@ standardize_parameters.parameters_model <- function(model, method = ""refit"", ci
 
   pars <- model
   ci <- attr(pars, ""ci"")
-  model <- attr(pars, ""object_name"")
-  if (is.character(model)) model <- .get_object(model)
+  model <- .get_object(pars)
+  if (is.null(model)) model <- attr(pars, ""object"")
 
   if (is.null(exponentiate <- attr(pars, ""exponentiate""))) exponentiate <- FALSE
   pars <- .standardize_parameters_posthoc(pars, method, model, robust, two_sd, exponentiate, verbose)",True,False,Implementation / Logic,6
easystats,effectsize,0b269de39d45ead782c94222d3f95fceeea68ddb,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-20T13:01:38Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-20T13:01:38Z,fix attribute name in model_parameters,R/standardize_parameters.R,False,True,True,False,1,1,2,"---FILE: R/standardize_parameters.R---
@@ -213,7 +213,7 @@ standardize_parameters.parameters_model <- function(model, method = ""refit"", ci
 
   pars <- model
   ci <- attr(pars, ""ci"")
-  model <- attr(pars, ""obj_name"")
+  model <- attr(pars, ""object_name"")
   if (is.character(model)) model <- .get_object(model)
 
   if (is.null(exponentiate <- attr(pars, ""exponentiate""))) exponentiate <- FALSE",True,False,Implementation / Logic,6
easystats,effectsize,a28c70ed1ce0a1ff0d2191f51c0ec08ce7cd509d,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-15T12:49:28Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-15T12:49:28Z,"Fix eta2G

@IndrajeetPatil note that in mixed models, this accidently gave extreme underestimation!
Should now give results nearly identical to afex... oops!",R/eta_squared.R;tests/testthat/test-eta_squared_etc.R,False,True,True,False,12,3,15,"---FILE: R/eta_squared.R---
@@ -558,7 +558,8 @@ cohens_f_squared <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
       obs_SSn2 <- params$Sum_Squares * obs
 
       params$Eta2_generalized <- params$Sum_Squares /
-        (params$Sum_Squares + sum(Sum_Squares_residuals) + obs_SSn1 - obs_SSn2)
+        (params$Sum_Squares + sum(sapply(values, ""[["", ""Sum_Squares_residuals"")) +
+           obs_SSn1 - obs_SSn2)
     } else if (!isTRUE(partial)) {
       params$Eta2 <- params$Sum_Squares / Sum_Squares_total
     } else {

---FILE: tests/testthat/test-eta_squared_etc.R---
@@ -160,13 +160,21 @@ if (require(""testthat"") && require(""effectsize"")) {
       ef <- eta_squared(m$aov, generalized = ""gender"")
       af <- anova(m, es = ""ges"",  observed = ""gender"")
       testthat::expect_equal(ef$Eta2_generalized,
-                             af$ges, tol = 0.1)
+                             c(0.211, 0.083, 0.186, 0.193, 0.099,
+                               0.002, 0.015, 0.132, 0.001, 0.004,
+                               0.011, 0.016, 0.008, 0.01, 0.02), tol = 0.05)
+      testthat::expect_equal(ef$Eta2_generalized,
+                             af$ges, tol = 0.05)
 
 
       ef <- eta_squared(m$aov, generalized = TRUE)
       af <- anova(m, es = ""ges"",  observed = NULL)
       testthat::expect_equal(ef$Eta2_generalized,
-                             af$ges, tol = 0.1)
+                             c(0.286, 0.111, 0.218, 0.264, 0.142,
+                               0.004, 0.021, 0.185, 0.002, 0.005,
+                               0.016, 0.023, 0.013, 0.014, 0.029), tol = 0.05)
+      testthat::expect_equal(ef$Eta2_generalized,
+                             af$ges, tol = 0.05)
     })
 
 ",True,False,Implementation / Logic,6
easystats,effectsize,b1bf4df526d6c169a3c8ca20cbe912ad10d98c49,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-15T08:43:38Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-15T08:43:38Z,fix test,R/effectsize.R;tests/testthat/test-effectsize.R,False,True,True,False,9,5,14,"---FILE: R/effectsize.R---
@@ -55,7 +55,8 @@ effectsize.htest <- function(model, ...) {
     out$CI_low <- model$conf.int[1]
     out$CI_high <- model$conf.int[2]
     return(out)
-  } else if (grepl(""Pearson's Chi-squared"", model$method)) {
+  } else if (grepl(""Pearson's Chi-squared"", model$method) ||
+             grepl(""Chi-squared test for given probabilities"", model$method)) {
     Obs <- model$observed
     Exp <- model$expected
 

---FILE: tests/testthat/test-effectsize.R---
@@ -24,12 +24,15 @@ if (require(""testthat"") && require(""effectsize"")) {
     Xsq1 <- chisq.test(contingency_table)
     Xsq2 <- chisq.test(contingency_table/10)
 
-    testthat::expect_equal(effectsize(Xsq1)$cramers_v,
-                           effectsize(Xsq2)$cramers_v)
+    testthat::expect_equal(effectsize(Xsq1)$Cramers_v, 0.07, tol = 0.01)
+    testthat::expect_equal(effectsize(Xsq1)$Cramers_v,
+                           effectsize(Xsq2)$Cramers_v)
 
+    Xsq3 <- chisq.test(table(mtcars$cyl))
+    testthat::expect_equal(effectsize(Xsq3)$Cramers_v, 0.19, tol = 0.01)
     testthat::expect_equal(
-      effectsize(chisq.test(table(mtcars$cyl)))$cramers_v,
-      cramers_v(table(mtcars$cyl))$cramers_v
+      effectsize(Xsq3)$Cramers_v,
+      cramers_v(table(mtcars$cyl))$Cramers_v
     )
   })
 ",True,False,Dependency / Package,3
easystats,effectsize,4eec4b85040d686b10cf6463f1df84e2145d17ed,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-13T10:27:28Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-13T10:27:28Z,fixy fix?,R/standardize_parameters.R,False,True,True,False,3,3,6,"---FILE: R/standardize_parameters.R---
@@ -176,11 +176,11 @@ standardize_parameters.default <- function(model, method = ""refit"", ci = 0.95, r
   if (!is.null(ci)) pars$CI <- attr(pars, ""ci"")
   pars <- pars[,colnames(pars) %in% c(""Parameter"", ""CI"", .col_2_scale)]
 
-  if (coefficient_name == ""Odds Ratio"")
+  if (!is.null(coefficient_name) && coefficient_name == ""Odds Ratio"")
     colnames(pars)[colnames(pars) == ""Coefficient""] <- ""Odds_ratio""
-  if (coefficient_name == ""Risk Ratio"")
+  if (!is.null(coefficient_name) && coefficient_name == ""Risk Ratio"")
     colnames(pars)[colnames(pars) == ""Coefficient""] <- ""Risk_ratio""
-  if (coefficient_name == ""IRR"")
+  if (!is.null(coefficient_name) && coefficient_name == ""IRR"")
     colnames(pars)[colnames(pars) == ""Coefficient""] <- ""IRR""
 
   i <- colnames(pars) %in% c(""Coefficient"", ""Median"", ""Mean"", ""MAP"", ""Odds_ratio"", ""IRR"")",True,False,Implementation / Logic,6
easystats,effectsize,cd744c643187dca6e26aaed7a03c2fac7155185c,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-13T10:21:42Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-13T10:21:42Z,fix vignette?,vignettes/anovaES.Rmd,True,False,True,False,1,5,6,"---FILE: vignettes/anovaES.Rmd---
@@ -160,11 +160,7 @@ $\eta^2_G$ is useful in repeated-measures designs, as it can estimate what a *wi
 
 ## Cohen's *f*
 
-Finally, we have the forgotten child - Cohen's $f$. Cohen's $f$ is a transformation of $\eta^2_p$, and is the ratio between the term-*SS* and the error-*SS*. 
-
-$$\text{Cohen's} f_p = \sqrt{\frac{\eta^2_p}{1-\eta^2_p}} = \sqrt{\frac{SS_{effect}}{SS_{error}}}$$
-
-It can take on values between zero, when the population means are all equal, and an indefinitely large number as the means are further and further apart. It is analogous to Cohen's $d$ when there are only two groups.
+Finally, we have the forgotten child - Cohen's $f$. Cohen's $f$ is a transformation of $\eta^2_p$, and is the ratio between the term-*SS* and the error-*SS*. It can take on values between zero, when the population means are all equal, and an indefinitely large number as the means are further and further apart. It is analogous to Cohen's $d$ when there are only two groups.
 
 ```{r}
 cohens_f(m_afex)",False,True,Documentation / Formatting,4
easystats,effectsize,3c0f28b47fbf87045f84eeebc277ec85ce04efab,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-13T09:34:10Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-13T09:34:10Z,fix vignette?,vignettes/anovaES.Rmd,True,False,True,False,2,5,7,"---FILE: vignettes/anovaES.Rmd---
@@ -160,12 +160,9 @@ $\eta^2_G$ is useful in repeated-measures designs, as it can estimate what a *wi
 
 ## Cohen's *f*
 
-Finally, we have the forgotten child - Cohen's $f$. Cohen's $f$ is a transformation of $\eta^2_p$, and is the ratio between the term-*SS* and the error-*SS*.
+Finally, we have the forgotten child - Cohen's $f$. Cohen's $f$ is a transformation of $\eta^2_p$, and is the ratio between the term-*SS* and the error-*SS*. 
 
-$$\text{Cohen's} f_p
-= \sqrt{\frac{\eta^2_p}{1-\eta^2_p}}
-= \sqrt{\frac{SS_{effect}}{SS_{error}}}
-$$
+$$\text{Cohen's} f_p = \sqrt{\frac{\eta^2_p}{1-\eta^2_p}} = \sqrt{\frac{SS_{effect}}{SS_{error}}}$$
 
 It can take on values between zero, when the population means are all equal, and an indefinitely large number as the means are further and further apart. It is analogous to Cohen's $d$ when there are only two groups.
 ",False,True,Documentation / Formatting,4
easystats,effectsize,3884cb9db1361f3a1d91b157d8612f5b666c7d85,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-12T23:15:48Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-12T23:15:48Z,fix little bug,R/effectsize.R,False,True,True,False,10,2,12,"---FILE: R/effectsize.R---
@@ -59,11 +59,19 @@ effectsize.htest <- function(model, ...) {
     Obs <- model$observed
     Exp <- model$expected
 
+    if (!is.null(dim(Exp))) {
+      nr <- nrow(Obs)
+      nc <- ncol(Obs)
+    } else {
+      nr <- length(Obs)
+      nc <- 1
+    }
+
     out <- chisq_to_cramers_v(
       chisq = .chisq(Obs, Exp),
       n = sum(Obs),
-      nrow = nrow(Obs),
-      ncol = ncol(Obs),
+      nrow = nr,
+      ncol = nc,
       ...
     )
     return(out)",True,False,Implementation / Logic,6
easystats,effectsize,01c7fa9b758622b466ad5b6fedd1cfdce2a4b989,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-12T06:24:02Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-12T06:24:02Z,fix #166,NAMESPACE;R/effectsize.R;man/effectsize.Rd;tests/testthat/test-effectsize.R,False,True,True,False,21,2,23,"---FILE: NAMESPACE---
@@ -5,6 +5,8 @@ S3method(change_scale,factor)
 S3method(change_scale,grouped_df)
 S3method(change_scale,numeric)
 S3method(effectsize,anova)
+S3method(effectsize,aov)
+S3method(effectsize,aovlist)
 S3method(effectsize,default)
 S3method(effectsize,htest)
 S3method(equivalence_test,effectsize_table)

---FILE: R/effectsize.R---
@@ -13,7 +13,7 @@
 #'   - A **correlation test** returns *r*. See [t_to_r()].
 #'   - A **Chi-squared test** returns *Cramer's V* via [cramers_v()].
 #'   - A **One-way ANOVA test** returns *Eta squared* via [F_to_eta2()].
-#' - An object of class `anova` is passed to [eta_squared()].
+#' - Objects of class `anova`, `aov`, or `aovlist` are passed to [eta_squared()].
 #' - Other objects are passed to [standardize_parameters()].
 #'
 #' @examples
@@ -85,6 +85,12 @@ effectsize.anova <- function(model, ...) {
   eta_squared(model, ...)
 }
 
+#' @export
+effectsize.aov <- effectsize.anova
+
+#' @export
+effectsize.aovlist <- effectsize.anova
+
 #' @export
 effectsize.default <- function(model, ...) {
   standardize_parameters(model, ...)

---FILE: man/effectsize.Rd---
@@ -24,7 +24,7 @@ See details below.
 \item A \strong{Chi-squared test} returns \emph{Cramer's V} via \code{\link[=cramers_v]{cramers_v()}}.
 \item A \strong{One-way ANOVA test} returns \emph{Eta squared} via \code{\link[=F_to_eta2]{F_to_eta2()}}.
 }
-\item An object of class \code{anova} is passed to \code{\link[=eta_squared]{eta_squared()}}.
+\item Objects of class \code{anova}, \code{aov}, or \code{aovlist} are passed to \code{\link[=eta_squared]{eta_squared()}}.
 \item Other objects are passed to \code{\link[=standardize_parameters]{standardize_parameters()}}.
 }
 }

---FILE: tests/testthat/test-effectsize.R---
@@ -1,4 +1,6 @@
 if (require(""testthat"") && require(""effectsize"")) {
+
+  # htest -------------------------------------------------------------------
   test_that(""t-test"", {
 
     ## One sample
@@ -45,4 +47,13 @@ if (require(""testthat"") && require(""effectsize"")) {
     testthat::expect_equal(ncol(effectsize(s_)), 1L)
     testthat::expect_equal(ncol(effectsize(t_)), 1L)
   })
+
+
+  # aov ---------------------------------------------------------------------
+  test_that(""aov"", {
+    data <- iris
+    data$Cat1 <- rep(c(""A"", ""B""), length.out = nrow(data))
+    model <- aov(Sepal.Length ~ Species * Cat1, data = data)
+    testthat::expect_equal(effectsize(model), eta_squared(model))
+  })
 }
\ No newline at end of file",True,False,Documentation / Formatting,6
easystats,effectsize,9716d6e5a340fc462cac7cefa1e0f22607fed6b4,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-11T10:31:59Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-11T10:31:59Z,fix test,tests/testthat/test-eta_squared_etc.R,False,True,True,False,2,2,4,"---FILE: tests/testthat/test-eta_squared_etc.R---
@@ -112,9 +112,9 @@ if (require(""testthat"") && require(""effectsize"")) {
     m2 <- lm(salary ~ xtra_hours + n_comps, data = hardlyworking)
 
     fsD <- cohens_f2(m1, model2 = m2)[,1:4]
-    fs <- cohens_f2(m2)[-1,-1] # this only works because of the defaul type-I errors! :(
+    fs <- cohens_f2(m2)[-1,-1] # this ONLY works because of the default type-I errors!!!!
     rownames(fsD) <- rownames(fs) <- 1
-    testthat::expect_equal(fsD, fs)
+    testthat::expect_equal(fsD, fs, tol = 0.01)
 
     if (require(""performance"")) {
       fsD <- cohens_f2(m1, model2 = m2)",True,False,Dependency / Package,3
easystats,effectsize,fc79d45cecf3d6737bd0e35370c29be930a70eea,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-11T10:03:56Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-11T10:03:56Z,"fix tests

have to index results due to calss conflicts",R/interpret_direction.R;tests/testthat/test-interpret.R,False,True,True,False,59,59,118,"---FILE: R/interpret_direction.R---
@@ -10,5 +10,5 @@
 #' #
 #' @export
 interpret_direction <- function(x) {
-  interpret(0, rules(0, c(""negative"", ""positive""), name = ""math""))
+  interpret(x, rules(0, c(""negative"", ""positive""), name = ""math""))
 }

---FILE: tests/testthat/test-interpret.R---
@@ -1,111 +1,111 @@
 if (require(""testthat"") && require(""effectsize"")) {
   test_that(""interpret"", {
     rules_grid <- rules(c(0.01, 0.05), c(""very significant"", ""significant"", ""not significant""))
-    testthat::expect_equal(interpret(0.001, rules_grid), ""very significant"")
-    testthat::expect_equal(interpret(0.021, rules_grid), ""significant"")
-    testthat::expect_equal(interpret(0.08, rules_grid), ""not significant"")
-    testthat::expect_equal(interpret(c(0.01, 0.005, 0.08), rules_grid), c(""significant"", ""very significant"", ""not significant""))
-    testthat::expect_error(interpret_r(0.6, rules = rules(c(0.5), c(""A"", ""B"", ""C""))))
-    testthat::expect_error(interpret_r(0.6, rules = rules(c(0.5, 0.2, 0.7), c(""A"", ""B"", ""C"", ""D""))))
+    testthat::expect_equal(interpret(0.001, rules_grid)[1], ""very significant"")
+    testthat::expect_equal(interpret(0.021, rules_grid)[1], ""significant"")
+    testthat::expect_equal(interpret(0.08, rules_grid)[1], ""not significant"")
+    testthat::expect_equal(interpret(c(0.01, 0.005, 0.08), rules_grid)[1:3], c(""significant"", ""very significant"", ""not significant""))
+    testthat::expect_error(interpret_r(0.6, rules(c(0.5), c(""A"", ""B"", ""C""))))
+    testthat::expect_error(interpret_r(0.6, rules(c(0.5, 0.2, 0.7), c(""A"", ""B"", ""C"", ""D""))))
   })
 
 
   test_that(""interpret_r"", {
-    testthat::expect_equal(interpret_r(0.21), ""medium"")
-    testthat::expect_equal(interpret_r(0.21, rules = ""cohen1988""), ""small"")
-    testthat::expect_equal(interpret_r(0.7, rules = ""evans1996""), ""strong"")
-    testthat::expect_equal(interpret_r(c(0.5, -0.08), rules = ""cohen1988""), c(""large"", ""very small""))
-    testthat::expect_equal(interpret_r(0.6, rules = rules(c(0.5), c(""A"", ""B""))), ""B"")
-    testthat::expect_error(interpret_r(0.6, rules = ""DUPA""))
+    testthat::expect_equal(interpret_r(0.21)[1], ""medium"")
+    testthat::expect_equal(interpret_r(0.21, ""cohen1988"")[1], ""small"")
+    testthat::expect_equal(interpret_r(0.7, ""evans1996"")[1], ""strong"")
+    testthat::expect_equal(interpret_r(c(0.5, -0.08), ""cohen1988"")[1:2], c(""large"", ""very small""))
+    testthat::expect_equal(interpret_r(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+    testthat::expect_error(interpret_r(0.6, ""DUPA""))
   })
 
 
 
   test_that(""interpret_p"", {
-    testthat::expect_equal(interpret_p(0.021), ""significant"")
-    testthat::expect_equal(interpret_p(0.08), ""not significant"")
-    testthat::expect_equal(interpret_p(c(0.01, 0.08)), c(""significant"", ""not significant""))
-    testthat::expect_equal(interpret_p(0.6, rules = rules(c(0.5), c(""A"", ""B""))), ""B"")
-    testthat::expect_error(interpret_p(0.6, rules = ""DUPA""))
+    testthat::expect_equal(interpret_p(0.021)[1], ""significant"")
+    testthat::expect_equal(interpret_p(0.08)[1], ""not significant"")
+    testthat::expect_equal(interpret_p(c(0.01, 0.08))[1:2], c(""significant"", ""not significant""))
+    testthat::expect_equal(interpret_p(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+    testthat::expect_error(interpret_p(0.6, ""DUPA""))
   })
 
 
   test_that(""interpret_direction"", {
-    testthat::expect_equal(interpret_direction(c(0.01, -0.08)), c(""positive"", ""negative""))
+    testthat::expect_equal(interpret_direction(c(0.01, -0.08))[1:2], c(""positive"", ""negative""))
   })
 
 
   test_that(""interpret_d"", {
-    testthat::expect_equal(interpret_d(0.021), ""very small"")
-    testthat::expect_equal(interpret_d(1.3, rules = ""sawilowsky2009""), ""very large"")
-    testthat::expect_equal(interpret_d(c(0.45, 0.85), rules = ""cohen1988""), c(""small"", ""large""))
-    testthat::expect_equal(interpret_d(0.6, rules = rules(c(0.5), c(""A"", ""B""))), ""B"")
-    testthat::expect_error(interpret_d(0.6, rules = ""DUPA""))
+    testthat::expect_equal(interpret_d(0.021)[1], ""very small"")
+    testthat::expect_equal(interpret_d(1.3, ""sawilowsky2009"")[1], ""very large"")
+    testthat::expect_equal(interpret_d(c(0.45, 0.85), ""cohen1988"")[1:2], c(""small"", ""large""))
+    testthat::expect_equal(interpret_d(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+    testthat::expect_error(interpret_d(0.6, ""DUPA""))
   })
 
 
 
   test_that(""interpret_rope"", {
-    testthat::expect_equal(interpret_rope(0, ci = 0.9), ""significant"")
-    testthat::expect_equal(interpret_rope(c(0.50, 1), ci = 0.9), c(""undecided"", ""negligible""))
-    testthat::expect_equal(interpret_rope(c(0.98, 0.991), ci = 1), c(""probably negligible"", ""negligible""))
-    testthat::expect_equal(interpret_rope(0.6, rules = rules(c(0.5), c(""A"", ""B""))), ""B"")
-    testthat::expect_error(interpret_rope(0.6, rules = ""DUPA""))
+    testthat::expect_equal(interpret_rope(0, ci = 0.9)[1], ""significant"")
+    testthat::expect_equal(interpret_rope(c(0.50, 1), ci = 0.9)[1:2], c(""undecided"", ""negligible""))
+    testthat::expect_equal(interpret_rope(c(0.98, 0.991), ci = 1)[1:2], c(""probably negligible"", ""negligible""))
+    testthat::expect_equal(interpret_rope(0.6, , rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+    testthat::expect_error(interpret_rope(0.6, , ""DUPA""))
   })
 
 
   test_that(""interpret_oddsratio"", {
-    testthat::expect_equal(interpret_oddsratio(2), ""small"")
-    testthat::expect_equal(interpret_oddsratio(c(1, 3)), c(""very small"", ""small""))
-    testthat::expect_equal(interpret_oddsratio(c(1, 3), rules = ""cohen1988""), c(""very small"", ""medium""))
-    testthat::expect_equal(interpret_oddsratio(0.6, rules = rules(c(0.5), c(""A"", ""B""))), ""B"")
-    testthat::expect_error(interpret_oddsratio(0.6, rules = ""DUPA""))
+    testthat::expect_equal(interpret_oddsratio(2)[1], ""small"")
+    testthat::expect_equal(interpret_oddsratio(c(1, 3))[1:2], c(""very small"", ""small""))
+    testthat::expect_equal(interpret_oddsratio(c(1, 3), ""cohen1988"")[1:2], c(""very small"", ""medium""))
+    testthat::expect_equal(interpret_oddsratio(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+    testthat::expect_error(interpret_oddsratio(0.6, ""DUPA""))
   })
 
 
   test_that(""interpret_r2"", {
-    testthat::expect_equal(interpret_r2(0.4), ""substantial"")
-    testthat::expect_equal(interpret_r2(c(0, 0.4), rules = ""falk1992""), c(""negligible"", ""adequate""))
-    testthat::expect_equal(interpret_r2(c(0.1, 0.4), rules = ""chin1998""), c(""very weak"", ""moderate""))
-    testthat::expect_equal(interpret_r2(c(0.1, 0.4), rules = ""hair2011""), c(""very weak"", ""weak""))
-    testthat::expect_equal(interpret_r2(0.6, rules = rules(c(0.5), c(""A"", ""B""))), ""B"")
-    testthat::expect_error(interpret_r2(0.6, rules = ""DUPA""))
+    testthat::expect_equal(interpret_r2(0.4)[1], ""substantial"")
+    testthat::expect_equal(interpret_r2(c(0, 0.4), ""falk1992"")[1:2], c(""negligible"", ""adequate""))
+    testthat::expect_equal(interpret_r2(c(0.1, 0.4), ""chin1998"")[1:2], c(""very weak"", ""moderate""))
+    testthat::expect_equal(interpret_r2(c(0.1, 0.4), ""hair2011"")[1:2], c(""very weak"", ""weak""))
+    testthat::expect_equal(interpret_r2(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+    testthat::expect_error(interpret_r2(0.6, ""DUPA""))
   })
 
 
   test_that(""interpret_bf"", {
     testthat::expect_warning(interpret_bf(-2))
-    testthat::expect_equal(interpret_bf(1), ""no evidence"")
-    testthat::expect_equal(interpret_bf(c(0.8, 3.5), rules = ""jeffreys1961""), c(""anecdotal evidence against"", ""moderate evidence in favour of""))
-    testthat::expect_equal(interpret_bf(c(0.8, 3.5), rules = ""raftery1995""), c(""weak evidence against"", ""positive evidence in favour of""))
-    testthat::expect_equal(interpret_bf(2, rules = rules(c(0.5), c(""A"", ""B""))), ""B evidence in favour of"")
-    testthat::expect_error(interpret_bf(2, rules = ""DUPA""))
+    testthat::expect_equal(interpret_bf(1)[1], ""no evidence"")
+    testthat::expect_equal(interpret_bf(c(0.8, 3.5), ""jeffreys1961"")[1:2], c(""anecdotal evidence against"", ""moderate evidence in favour of""))
+    testthat::expect_equal(interpret_bf(c(0.8, 3.5), ""raftery1995"")[1:2], c(""weak evidence against"", ""positive evidence in favour of""))
+    testthat::expect_equal(interpret_bf(2, rules(c(0.5), c(""A"", ""B"")))[1], ""B evidence in favour of"")
+    testthat::expect_error(interpret_bf(2, ""DUPA""))
   })
 
 
 
   test_that(""interpret_omega_squared"", {
-    testthat::expect_equal(interpret_omega_squared(0.1), ""medium"")
-    testthat::expect_equal(interpret_omega_squared(c(0.1, 0.25)), c(""medium"", ""large""))
-    testthat::expect_equal(interpret_omega_squared(0.6, rules = rules(c(0.5), c(""A"", ""B""))), ""B"")
-    testthat::expect_error(interpret_omega_squared(0.6, rules = ""DUPA""))
+    testthat::expect_equal(interpret_omega_squared(0.1)[1], ""medium"")
+    testthat::expect_equal(interpret_omega_squared(c(0.1, 0.25))[1:2], c(""medium"", ""large""))
+    testthat::expect_equal(interpret_omega_squared(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+    testthat::expect_error(interpret_omega_squared(0.6, ""DUPA""))
   })
 
 
 
   test_that(""interpret_rhat"", {
-    testthat::expect_equal(interpret_rhat(1), ""converged"")
-    testthat::expect_equal(interpret_rhat(c(1, 1.02)), c(""converged"", ""failed""))
-    testthat::expect_equal(interpret_rhat(c(1, 1.02), rules = ""gelman1992""), c(""converged"", ""converged""))
-    testthat::expect_equal(interpret_rhat(0.6, rules = rules(c(0.5), c(""A"", ""B""))), ""B"")
-    testthat::expect_error(interpret_rhat(0.6, rules = ""DUPA""))
+    testthat::expect_equal(interpret_rhat(1)[1], ""converged"")
+    testthat::expect_equal(interpret_rhat(c(1, 1.02))[1:2], c(""converged"", ""failed""))
+    testthat::expect_equal(interpret_rhat(c(1, 1.02), ""gelman1992"")[1:2], c(""converged"", ""converged""))
+    testthat::expect_equal(interpret_rhat(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+    testthat::expect_error(interpret_rhat(0.6, ""DUPA""))
   })
 
 
   test_that(""interpret_ess"", {
-    testthat::expect_equal(interpret_ess(1000), ""sufficient"")
-    testthat::expect_equal(interpret_ess(c(1000, 800)), c(""sufficient"", ""insufficient""))
-    testthat::expect_equal(interpret_ess(0.6, rules = rules(c(0.5), c(""A"", ""B""))), ""B"")
-    testthat::expect_error(interpret_ess(0.6, rules = ""DUPA""))
+    testthat::expect_equal(interpret_ess(1000)[1], ""sufficient"")
+    testthat::expect_equal(interpret_ess(c(1000, 800))[1:2], c(""sufficient"", ""insufficient""))
+    testthat::expect_equal(interpret_ess(0.6, rules(c(0.5), c(""A"", ""B"")))[1], ""B"")
+    testthat::expect_error(interpret_ess(0.6, ""DUPA""))
   })
-}
\ No newline at end of file
+}",True,False,Implementation / Logic,6
easystats,effectsize,f90519534a89a5a9d371080cc914544636599ace,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-11T09:54:54Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-11T09:54:54Z,fix all rules in interpert(s),R/interpret_bayesian_indices.R;R/interpret_bf.R;R/interpret_cfa_fit.R;R/interpret_d.R;R/interpret_direction.R;R/interpret_oddsratio.R;R/interpret_omega_squared.R;R/interpret_p.R;R/interpret_r.R;R/interpret_r2.R;R/interpret_rope.R;man/interpret_gfi.Rd;man/interpret_p.Rd;man/interpret_r.Rd,False,True,True,False,97,83,180,"---FILE: R/interpret_bayesian_indices.R---
@@ -36,28 +36,28 @@
 #' }
 #' @export
 interpret_ess <- function(ess, rules = ""burkner2017"") {
-  rule <- .match.rules(
+  rules <- .match.rules(
     rules,
     list(
-      burkner2017 = rules(c(1000), c(""insufficient"", ""sufficient""))
+      burkner2017 = rules(c(1000), c(""insufficient"", ""sufficient""), name = ""burkner2017"")
     )
   )
 
-  interpret(abs(ess), rule, name=rules)
+  interpret(abs(ess), rules)
 }
 
 
 
 #' @rdname interpret_ess
 #' @export
 interpret_rhat <- function(rhat, rules = ""vehtari2019"") {
-  rule <- .match.rules(
+  rules <- .match.rules(
     rules,
     list(
-      vehtari2019 = rules(c(1.01), c(""converged"", ""failed"")),
-      gelman1992 = rules(c(1.1), c(""converged"", ""failed""))
+      vehtari2019 = rules(c(1.01), c(""converged"", ""failed""), name = ""vehtari2019""),
+      gelman1992 = rules(c(1.1), c(""converged"", ""failed""), name = ""gelman1992"")
     )
   )
 
-  interpret(abs(rhat), rule, name=rules)
+  interpret(abs(rhat), rules)
 }

---FILE: R/interpret_bf.R---
@@ -43,21 +43,23 @@ interpret_bf <- function(bf, rules = ""jeffreys1961"", include_value = FALSE) {
   dir <- ifelse(bf < 1, ""against"", ""in favour of"")
   bf <- exp(abs(log(bf)))
 
-  rule <- .match.rules(
+  rules <- .match.rules(
     rules,
     list(
-      jeffreys1961 = rules(c(3, 10, 30, 100), c(""anecdotal"", ""moderate"", ""strong"", ""very strong"", ""extreme"")),
-      raftery1995 = rules(c(3, 20, 150), c(""weak"", ""positive"", ""strong"", ""very strong""))
+      jeffreys1961 = rules(c(3, 10, 30, 100), c(""anecdotal"", ""moderate"", ""strong"", ""very strong"", ""extreme""),
+                           name = ""jeffreys1961""),
+      raftery1995 = rules(c(3, 20, 150), c(""weak"", ""positive"", ""strong"", ""very strong""),
+                          name = ""raftery1995"")
     )
   )
 
-  interpretation <- interpret(bf, rule, name=rules)
+  interpretation <- interpret(bf, rules)
 
 
-  interpretation <- paste0(interpretation, "" evidence "", dir)
+  interpretation[] <- paste0(interpretation, "" evidence "", dir)
   interpretation[orig_bf==1] <- ""no evidence""
   if (include_value) {
-    interpretation <- paste0(interpretation, "" ("", insight::format_bf(orig_bf, protect_ratio = TRUE),"")"")
+    interpretation[] <- paste0(interpretation, "" ("", insight::format_bf(orig_bf, protect_ratio = TRUE),"")"")
   }
 
   interpretation[is.na(orig_bf)] <- NA

---FILE: R/interpret_cfa_fit.R---
@@ -35,7 +35,7 @@
 #' interpret_nfi(c(.5, .99))
 #' interpret_nnfi(c(.5, .99))
 #' interpret_cfi(c(.5, .99))
-#' interpret_rmsea(c(.5, .99))
+#' interpret_rmsea(c(.07, .04))
 #' interpret_srmr(c(.5, .99))
 #' interpret_rfi(c(.5, .99))
 #' interpret_ifi(c(.5, .99))
@@ -51,43 +51,43 @@
 #'
 #' @export
 interpret_gfi <- function(x, rules = ""default"") {
-  rule <- .match.rules(
+  rules <- .match.rules(
     rules,
     list(
-      default = rules(c(0.95), c(""poor"", ""satisfactory""))
+      default = rules(c(0.95), c(""poor"", ""satisfactory""), name = ""default"")
     )
   )
 
-  interpret(x, rule, name=rules)
+  interpret(x, rules)
 }
 
 
 #' @rdname interpret_gfi
 #' @export
 interpret_agfi <- function(x, rules = ""default"") {
-  rule <- .match.rules(
+  rules <- .match.rules(
     rules,
     list(
-      default = rules(c(0.90), c(""poor"", ""satisfactory""))
+      default = rules(c(0.90), c(""poor"", ""satisfactory""), name = ""default"")
     )
   )
 
-  interpret(x, rule, name=rules)
+  interpret(x, rules)
 }
 
 
 #' @rdname interpret_gfi
 #' @export
 interpret_nfi <- function(x, rules = ""byrne1994"") {
-  rule <- .match.rules(
+  rules <- .match.rules(
     rules,
     list(
-      byrne1994 = rules(c(0.90), c(""poor"", ""satisfactory"")),
-      schumacker2004 =  rules(c(0.95), c(""poor"", ""satisfactory""))
+      byrne1994 = rules(c(0.90), c(""poor"", ""satisfactory""), name = ""byrne1994""),
+      schumacker2004 =  rules(c(0.95), c(""poor"", ""satisfactory""), name = ""schumacker2004"")
     )
   )
 
-  interpret(x, rule, name=rules)
+  interpret(x, rules)
 }
 
 #' @rdname interpret_gfi
@@ -98,14 +98,14 @@ interpret_nnfi <- interpret_nfi
 #' @rdname interpret_gfi
 #' @export
 interpret_cfi <- function(x, rules = ""default"") {
-  rule <- .match.rules(
+  rules <- .match.rules(
     rules,
     list(
-      default = rules(c(0.90), c(""poor"", ""satisfactory""))
+      default = rules(c(0.90), c(""poor"", ""satisfactory""), name = ""default"")
     )
   )
 
-  interpret(x, rule, name=rules)
+  interpret(x, rules)
 }
 
 
@@ -114,55 +114,55 @@ interpret_cfi <- function(x, rules = ""default"") {
 #' @rdname interpret_gfi
 #' @export
 interpret_rmsea <- function(x, rules = ""default"") {
-  rule <- .match.rules(
+  rules <- .match.rules(
     rules,
     list(
-      default = rules(c(0.05), c(""satisfactory"", ""poor"")),
-      awang2012 = rules(c(0.05, 0.08), c(""good"", ""satisfactory"", ""poor""))
+      default = rules(c(0.05), c(""satisfactory"", ""poor""), name = ""default""),
+      awang2012 = rules(c(0.05, 0.08), c(""good"", ""satisfactory"", ""poor""), name = ""awang2012"")
     )
   )
 
-  interpret(x, rule, name=rules)
+  interpret(x, rules)
 }
 
 
 #' @rdname interpret_gfi
 #' @export
 interpret_srmr <- function(x, rules = ""default"") {
-  rule <- .match.rules(
+  rules <- .match.rules(
     rules,
     list(
-      default = rules(c(0.08), c(""satisfactory"", ""poor""))
+      default = rules(c(0.08), c(""satisfactory"", ""poor""), name = ""default"")
     )
   )
 
-  interpret(x, rules, name=rules)
+  interpret(x, rules)
 }
 
 #' @rdname interpret_gfi
 #' @export
 interpret_rfi <- function(x, rules = ""default"") {
-  rule <- .match.rules(
+  rules <- .match.rules(
     rules,
     list(
-      default = rules(c(0.90), c(""poor"", ""satisfactory""))
+      default = rules(c(0.90), c(""poor"", ""satisfactory""), name = ""default"")
     )
   )
 
-  interpret(x, rule, name=rules)
+  interpret(x, rules)
 }
 
 #' @rdname interpret_gfi
 #' @export
 interpret_ifi <- function(x, rules = ""default"") {
-  rule <- .match.rules(
+  rules <- .match.rules(
     rules,
     list(
-      default = rules(c(0.90), c(""poor"", ""satisfactory""))
+      default = rules(c(0.90), c(""poor"", ""satisfactory""), name = ""default"")
     )
   )
 
-  interpret(x, rule, name=rules)
+  interpret(x, rules)
 }
 
 #' @rdname interpret_gfi
@@ -171,7 +171,7 @@ interpret_pnfi <- function(x, rules = ""default"") {
   rules <- .match.rules(
     rules,
     list(
-      default = rules(c(0.50), c(""poor"", ""satisfactory""))
+      default = rules(c(0.50), c(""poor"", ""satisfactory""), name = ""default"")
     )
   )
 

---FILE: R/interpret_d.R---
@@ -44,17 +44,19 @@ interpret_d <- function(d, rules = ""cohen1988"") {
     return(interpret_r(d_to_r(d), rules))
   }
 
-  rule <- .match.rules(
+  rules <- .match.rules(
     rules,
     list(
-      cohen1988 = rules(c(0.2, 0.5, 0.8), c(""very small"", ""small"", ""medium"", ""large"")),
+      cohen1988 = rules(c(0.2, 0.5, 0.8), c(""very small"", ""small"", ""medium"", ""large""),
+                        name = ""cohen1988""),
       sawilowsky2009 = rules(c(0.1, 0.2, 0.5, 0.8, 1.2, 2),
-                             c(""tiny"", ""very small"", ""small"", ""medium"", ""large"", ""very large"", ""huge"")),
+                             c(""tiny"", ""very small"", ""small"", ""medium"", ""large"", ""very large"", ""huge""),
+                             name = ""sawilowsky2009""),
       gignac2016 = NA # added for the correct error msg
     )
   )
 
-  interpret(abs(d), rule, name=rules)
+  interpret(abs(d), rules)
 }
 
 #' @rdname interpret_d

---FILE: R/interpret_direction.R---
@@ -10,5 +10,5 @@
 #' #
 #' @export
 interpret_direction <- function(x) {
-  ifelse(x >= 0, ""positive"", ""negative"")
+  interpret(0, rules(0, c(""negative"", ""positive""), name = ""math""))
 }

---FILE: R/interpret_oddsratio.R---
@@ -45,13 +45,13 @@ interpret_oddsratio <- function(OR, rules = ""chen2010"", log = FALSE) {
     return(interpret_d(abs(d), rules = rules))
   }
 
-  rule <- .match.rules(
+  rules <- .match.rules(
     rules,
     list(
-      chen2010 = rules(c(1.68, 3.47, 6.71), c(""very small"", ""small"", ""medium"", ""large"")),
+      chen2010 = rules(c(1.68, 3.47, 6.71), c(""very small"", ""small"", ""medium"", ""large""), name = ""chen2010""),
       cohen1988 = NA # for correct error msg
     )
   )
 
-  interpret(OR, rule, name=rules)
+  interpret(OR, rules)
 }

---FILE: R/interpret_omega_squared.R---
@@ -32,17 +32,19 @@
 #'
 #' @export
 interpret_omega_squared <- function(es, rules = ""field2013"") {
-  rule <- .match.rules(
+  rules <- .match.rules(
     rules,
     list(
       field2013 = rules(c(0.01, 0.06, 0.14),
-                        c(""very small"", ""small"", ""medium"", ""large"")),
+                        c(""very small"", ""small"", ""medium"", ""large""),
+                        name = ""field2013""),
       cohen1992 = rules(c(0.02, 0.13, 0.26),
-                        c(""very small"", ""small"", ""medium"", ""large""))
+                        c(""very small"", ""small"", ""medium"", ""large""),
+                        name = ""cohen1992"")
     )
   )
 
-  interpret(es, rule, name=rules)
+  interpret(es, rules)
 }
 
 #' @export

---FILE: R/interpret_p.R---
@@ -18,18 +18,18 @@
 #' - Benjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E. J., Berk, R., ... & Cesarini, D. (2018). Redefine statistical significance. Nature Human Behaviour, 2(1), 6-10.
 #'
 #' @examples
-#' interpret_p(.02)
-#' interpret_p(c(.5, .02))
+#' interpret_p(c(.5, .02, 0.001))
+#' interpret_p(c(.5, .02, 0.001), rules = ""rss"")
 #'
 #' @export
 interpret_p <- function(p, rules = ""default"") {
-  rule <- .match.rules(
+  rules <- .match.rules(
     rules,
     list(
-      default = rules(c(0.05), c(""significant"", ""not significant"")),
-      rss = rules(c(0.005, 0.05), c(""significant"", ""suggestive"", ""not significant""))
+      default = rules(c(0.05), c(""significant"", ""not significant""), name = ""default""),
+      rss = rules(c(0.005, 0.05), c(""significant"", ""suggestive"", ""not significant""), name = ""rss"")
     )
   )
 
-  interpret(p, rule, name=rules)
+  interpret(p, rules)
 }

---FILE: R/interpret_r.R---
@@ -32,8 +32,8 @@
 #'   - **r > 0.8** - Very strong
 #'
 #' @examples
-#' interpret_r(r = .015)
-#' interpret_r(r = c(.5, -.02))
+#' interpret_r(.015)
+#' interpret_r(c(.5, -.02))
 #'
 #' @seealso Page 88 of APA's 6th Edition.
 #'
@@ -49,13 +49,17 @@ interpret_r <- function(r, rules = ""funder2019"") {
     rules,
     list(
       funder2019 = rules(c(0.05, 0.1, 0.2, 0.3, 0.4),
-                         c(""tiny"", ""very small"", ""small"", ""medium"", ""large"", ""very large"")),
+                         c(""tiny"", ""very small"", ""small"", ""medium"", ""large"", ""very large""),
+                         name = ""funder2019""),
       gignac2016 = rules(c(0.1, 0.2, 0.3),
-                         c(""very small"", ""small"", ""moderate"", ""large"")),
+                         c(""very small"", ""small"", ""moderate"", ""large""),
+                         name = ""gignac2016""),
       cohen1988 = rules(c(0.1, 0.3, 0.5),
-                        c(""very small"", ""small"", ""moderate"", ""large"")),
+                        c(""very small"", ""small"", ""moderate"", ""large""),
+                        name = ""cohen1988""),
       evans1996 = rules(c(0.2, 0.4, 0.6, 0.8),
-                        c(""very weak"", ""weak"", ""moderate"", ""strong"", ""very strong""))
+                        c(""very weak"", ""weak"", ""moderate"", ""strong"", ""very strong""),
+                        name = ""evans1996"")
     )
   )
 

---FILE: R/interpret_r2.R---
@@ -44,10 +44,10 @@ interpret_r2 <- function(r2, rules = ""cohen1988"") {
   rules <- .match.rules(
     rules,
     list(
-      cohen1988 = rules(c(0.02, 0.13, 0.26), c(""very weak"", ""weak"", ""moderate"", ""substantial"")),
-      falk1992 = rules(c(0.10), c(""negligible"", ""adequate"")),
-      chin1998 = rules(c(0.19, 0.33, 0.67), c(""very weak"", ""weak"", ""moderate"", ""substantial"")),
-      hair2011 = rules(c(0.25, 0.50, 0.75), c(""very weak"", ""weak"", ""moderate"", ""substantial""))
+      cohen1988 = rules(c(0.02, 0.13, 0.26), c(""very weak"", ""weak"", ""moderate"", ""substantial""), name = ""cohen1988""),
+      falk1992 = rules(c(0.10), c(""negligible"", ""adequate""), name = ""falk1992""),
+      chin1998 = rules(c(0.19, 0.33, 0.67), c(""very weak"", ""weak"", ""moderate"", ""substantial""), name = ""chin1998""),
+      hair2011 = rules(c(0.25, 0.50, 0.75), c(""very weak"", ""weak"", ""moderate"", ""substantial""), name = ""hair2011"")
     )
   )
 

---FILE: R/interpret_rope.R---
@@ -30,20 +30,24 @@
 #'
 #' @export
 interpret_rope <- function(rope, ci = 0.9, rules = ""default"") {
-  if (is.character(rules) && rules == ""default"" && ci < 1) {
-    return(ifelse(rope == 0, ""significant"",
-                  ifelse(rope == 1, ""negligible"",
-                         ""undecided"")))
-  }
+  if (ci < 1) {
+    e <- .Machine$double.eps
 
+    default_rule <- rules(c(0, 0 + e, 1 - e, 1),
+                          c(""significant"", ""undecided"", ""undecided"", ""negligible""),
+                          name = ""default"")
+  } else {
+    default_rule <- rules(c(0.01, 0.025, 0.975, 0.99),
+                          c(""significant"", ""probably significant"",
+                            ""undecided"",
+                            ""probably negligible"", ""negligible""),
+                          name = ""default"")
+  }
 
   rules <- .match.rules(
     rules,
     list(
-      default = rules(c(0.01, 0.025,0.975, 0.99),
-                      c(""significant"", ""probably significant"",
-                        ""undecided"",
-                        ""probably negligible"", ""negligible""))
+      default = default_rule
     )
   )
 

---FILE: man/interpret_gfi.Rd---
@@ -69,7 +69,7 @@ interpret_agfi(c(.5, .99))
 interpret_nfi(c(.5, .99))
 interpret_nnfi(c(.5, .99))
 interpret_cfi(c(.5, .99))
-interpret_rmsea(c(.5, .99))
+interpret_rmsea(c(.07, .04))
 interpret_srmr(c(.5, .99))
 interpret_rfi(c(.5, .99))
 interpret_ifi(c(.5, .99))

---FILE: man/interpret_p.Rd---
@@ -33,8 +33,8 @@ Interpret p-values
 }
 
 \examples{
-interpret_p(.02)
-interpret_p(c(.5, .02))
+interpret_p(c(.5, .02, 0.001))
+interpret_p(c(.5, .02, 0.001), rules = ""rss"")
 
 }
 \references{

---FILE: man/interpret_r.Rd---
@@ -54,8 +54,8 @@ Rules apply positive and negative \emph{r} alike.
 }
 
 \examples{
-interpret_r(r = .015)
-interpret_r(r = c(.5, -.02))
+interpret_r(.015)
+interpret_r(c(.5, -.02))
 
 }
 \references{",True,False,Documentation / Formatting,6
easystats,effectsize,b2fd7aa8b09b07b86bdb0fb84f84f76350280dc5,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-11T07:24:30Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-11T07:24:30Z,fix test,tests/testthat/test-eta_squared_etc.R,False,True,True,False,5,3,8,"---FILE: tests/testthat/test-eta_squared_etc.R---
@@ -131,9 +131,11 @@ if (require(""testthat"") && require(""effectsize"")) {
   if (require(""car"") && require(""afex"")) {
     test_that(""generalized | between"", {
       data(obk.long, package = ""afex"")
-      m <- afex::aov_car(value ~ treatment * gender + Error(id),
-                         data = obk.long, observed = ""gender"",
-                         include_aov = TRUE)
+      m <- suppressWarnings(
+        afex::aov_car(value ~ treatment * gender + Error(id),
+                      data = obk.long, observed = ""gender"",
+                      include_aov = TRUE)
+      )
 
       testthat::expect_equal(anova(m, es = ""ges"", observed = NULL)$ges,
                              eta_squared(car::Anova(m$aov, type=3),",True,False,Implementation / Logic,6
easystats,effectsize,bbca00deabd5af7f2a0642c285763fde34ad0023,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-11T07:18:37Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-11T07:18:37Z,Fix partial onega squared,R/eta_squared.R;man/eta_squared.Rd,False,True,True,False,63,79,142,"---FILE: R/eta_squared.R---
@@ -18,7 +18,7 @@
 #'   (non-manipulated) variables, in which case generalized Eta Squared is
 #'   calculated taking these observed variables into account. For `afex_aov`
 #'   model, `generalized = TRUE`, the observed variables are extracted
-#'   automatically from the model.
+#'   automatically from the fitted model, if they were provided then.
 #' @inheritParams chisq_to_phi
 #' @param ... Arguments passed to or from other methods (ignored).
 #'
@@ -282,10 +282,6 @@ cohens_f2 <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
   }
 
   type <- match.arg(type)
-  es_fun <- switch(type,
-                   eta = F_to_eta2,
-                   omega = F_to_omega2,
-                   epsilon = F_to_epsilon2)
 
   params <- as.data.frame(parameters::model_parameters(model))
   params <- params[params$Parameter != ""(Intercept)"", ]
@@ -299,44 +295,33 @@ cohens_f2 <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
   df_error <- params$df[params$Parameter == ""Residuals""]
   params <- params[params$Parameter != ""Residuals"",,drop = FALSE]
 
-  # We need these for the F statistic for CIs
-  if (isTRUE(generalized) || is.character(generalized)) {
-    ## copied from afex
-    obs <- logical(nrow(params))
-    if (is.character(generalized)) {
-      for (o in generalized) {
-        oi <- grepl(paste0(""\\b"", o, ""\\b""), params$Parameter)
-
-        if (!any(oi)) stop(""Observed variable not in data: "", o, call. = FALSE)
-
-        obs <- obs | oi
-      }
-    }
-    obs_SSn1 <- sum(params$Sum_Squares * obs)
-    obs_SSn2 <- params$Sum_Squares * obs
 
-    ES <- params$Sum_Squares /
-      (params$Sum_Squares + values$Sum_Squares_residuals + obs_SSn1 - obs_SSn2)
 
-    generalized <- TRUE
-  } else if (!isTRUE(partial)) {
-    ES <- params$Sum_Squares /
-      values$Sum_Squares_total
-  } else {
-    ES <-
-      params$Sum_Squares /
-      (params$Sum_Squares + values$Sum_Squares_residuals)
-  }
+  if (type == ""eta"") {
+    if (isTRUE(generalized) || is.character(generalized)) {
+      ## copied from afex
+      obs <- logical(nrow(params))
+      if (is.character(generalized)) {
+        for (o in generalized) {
+          oi <- grepl(paste0(""\\b"", o, ""\\b""), params$Parameter)
 
+          if (!any(oi)) stop(""Observed variable not in data: "", o, call. = FALSE)
 
+          obs <- obs | oi
+        }
+      }
+      obs_SSn1 <- sum(params$Sum_Squares * obs)
+      obs_SSn2 <- params$Sum_Squares * obs
 
-  if (type == ""eta"") {
-    if (isTRUE(generalized)) {
-      params$Eta_Sq_generalized <- ES
+      params$Eta_Sq_generalized <- params$Sum_Squares /
+        (params$Sum_Squares + values$Sum_Squares_residuals + obs_SSn1 - obs_SSn2)
     } else if (!isTRUE(partial)) {
-      params$Eta_Sq <- ES
+      params$Eta_Sq <- params$Sum_Squares /
+        values$Sum_Squares_total
     } else {
-      params$Eta_Sq_partial <- ES
+      params$Eta_Sq_partial <-
+        params$Sum_Squares /
+        (params$Sum_Squares + values$Sum_Squares_residuals)
     }
   } else if (type == ""omega"") {
     if (!isTRUE(partial)) {
@@ -362,17 +347,19 @@ cohens_f2 <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
 
 
 
-  ES <- ES
   out <- params
 
   if (is.numeric(ci)) {
+    # based on MBESS::ci.R2
+    ES <- pmax(0, out[[ncol(out)]])
     f <- (ES / out$df) / ((1 - ES) / df_error)
 
     out <- cbind(out,
-                 es_fun(f,
-                        out$df,
-                        df_error,
-                        ci = ci)[-1])
+                 # This really is a generic F_to_R2
+                 F_to_eta2(f,
+                           out$df,
+                           df_error,
+                           ci = ci)[-1])
   }
 
 
@@ -535,10 +522,6 @@ cohens_f2 <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
                               ci = 0.9,
                               ...) {
   type <- match.arg(type)
-  es_fun <- switch(type,
-                   eta = F_to_eta2,
-                   omega = F_to_omega2,
-                   epsilon = F_to_epsilon2)
 
   params <- as.data.frame(parameters::model_parameters(model))
   params <- params[params$Parameter != ""(Intercept)"", ]
@@ -556,48 +539,45 @@ cohens_f2 <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
   df_residuals <- sapply(values[params$Group], ""[["", ""df_residuals"")
   ns <- sapply(values[params$Group], ""[["", ""n"")
 
-  if (isTRUE(generalized) || is.character(generalized)) {
-    ## copied from afex
-    obs <- logical(nrow(params))
-    if (is.character(generalized)) {
-      for (o in generalized) {
-        oi <- grepl(paste0(""\\b"", o, ""\\b""), params$Parameter)
+  SSS_values <- values[[which(names(values) %in% insight::find_predictors(model)[[1]])]]
+  Sum_Squares_Subjects <- SSS_values$Sum_Squares_residuals
+  Mean_Squares_Subjects <- SSS_values$Mean_Square_residuals
 
-        if (!any(oi)) stop(""Observed variable not in data: "", o, call. = FALSE)
 
-        obs <- obs | oi
-      }
-    }
-    obs_SSn1 <- sum(params$Sum_Squares * obs)
-    obs_SSn2 <- params$Sum_Squares * obs
-
-    ES <- params$Sum_Squares /
-      (params$Sum_Squares + sum(sapply(values, ""[["", ""Sum_Squares_residuals"")) + obs_SSn1 - obs_SSn2)
+  if (type == ""eta"") {
+    if (isTRUE(generalized) || is.character(generalized)) {
+      ## copied from afex
+      obs <- logical(nrow(params))
+      if (is.character(generalized)) {
+        for (o in generalized) {
+          oi <- grepl(paste0(""\\b"", o, ""\\b""), params$Parameter)
 
-    generalized <- TRUE
-  } else if (!isTRUE(partial)) {
-    ES <- params$Sum_Squares / Sum_Squares_total
-  } else {
-    ES <- F_to_eta2(params[[""F""]], params[[""df""]], df_residuals, ci = NULL)[[1]]
-  }
+          if (!any(oi)) stop(""Observed variable not in data: "", o, call. = FALSE)
 
+          obs <- obs | oi
+        }
+      }
+      obs_SSn1 <- sum(params$Sum_Squares * obs)
+      obs_SSn2 <- params$Sum_Squares * obs
 
-  if (type == ""eta"") {
-    if (isTRUE(generalized) || is.character(generalized)) {
-      params$Eta_Sq_generalized <- ES
+      params$Eta_Sq_generalized <- params$Sum_Squares /
+        (params$Sum_Squares + sum(Sum_Squares_residuals) + obs_SSn1 - obs_SSn2)
     } else if (!isTRUE(partial)) {
-      params$Eta_Sq <- ES
+      params$Eta_Sq <- params$Sum_Squares / Sum_Squares_total
     } else {
-      params$Eta_Sq_partial <- ES
+      params$Eta_Sq_partial <-
+        params$Sum_Squares /
+        (params$Sum_Squares + Sum_Squares_residuals)
     }
   } else if (type == ""omega"") {
     if (!isTRUE(partial)) {
       params$Omega_Sq <-
         (params$Sum_Squares - params$df * Mean_Square_residuals) /
         (Sum_Squares_total + Mean_Square_residuals)
     } else {
-      params$Omega_Sq_partial <-
-        F_to_omega2(params[[""F""]], params[[""df""]], df_residuals, ci = NULL)[[1]]
+      # implemented from MOTE::omega.partial.SS.rm
+      params$Omega_Sq_partial <- (params$df * (params$Mean_Square - Mean_Square_residuals)) /
+        (params$df * params$Mean_Square + Sum_Squares_residuals + Sum_Squares_Subjects + Mean_Squares_Subjects)
     }
   } else if (type == ""epsilon"") {
     if (!isTRUE(partial)) {
@@ -606,20 +586,24 @@ cohens_f2 <- function(model, partial = TRUE, ci = 0.9, squared = TRUE,
         Sum_Squares_total
     } else {
       params$Epsilon_Sq_partial <-
-        F_to_epsilon2(params[[""F""]], params[[""df""]], df_residuals, ci = NULL)[[1]]
+        (params$Sum_Squares - params$df * Mean_Square_residuals) /
+        (params$Sum_Squares + Sum_Squares_residuals)
     }
   }
 
   out <- params
 
   if (!is.null(ci)) {
+    # based on MBESS::ci.R2
+    ES <- pmax(0, out[[ncol(out)]])
     f <- (ES / out$df) / ((1 - ES)/df_residuals)
 
     out <- cbind(out,
-                 es_fun(f,
-                        out$df,
-                        df_residuals,
-                        ci = ci)[-1])
+                 # This really is a generic F_to_R2
+                 F_to_eta2(f,
+                           out$df,
+                           df_residuals,
+                           ci = ci)[-1])
   }
 
   out <- out[, colnames(out) %in% c(

---FILE: man/eta_squared.Rd---
@@ -28,7 +28,7 @@ variables are manipulated. Can also be a character vector of observed
 (non-manipulated) variables, in which case generalized Eta Squared is
 calculated taking these observed variables into account. For \code{afex_aov}
 model, \code{generalized = TRUE}, the observed variables are extracted
-automatically from the model.}
+automatically from the fitted model, if they were provided then.}
 
 \item{ci}{Confidence Interval (CI) level}
 ",True,False,Documentation / Formatting,6
easystats,effectsize,5d3cbf1498e8b09c5c5ab0d5f3c6c28518b7f40a,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-08T11:45:08Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-08T11:45:08Z,fix bugs,R/standardize_parameters.R;tests/testthat/test-standardize_parameters.R,False,True,True,False,11,1,12,"---FILE: R/standardize_parameters.R---
@@ -212,7 +212,8 @@ standardize_parameters.parameters_model <- function(model, method = ""refit"", ci
   obj_name <- attr(pars, ""obj_name"")
   model <- .get_object(model)
 
-  pars <- .standardize_parameters_posthoc(pars, method, model, robust, two_sd, verbose)
+  if (is.null(exponentiate <- attr(pars, ""exponentiate""))) exponentiate <- FALSE
+  pars <- .standardize_parameters_posthoc(pars, method, model, robust, two_sd, exponentiate, verbose)
   method <- attr(pars, ""std_method"")
   robust <- attr(pars, ""robust"")
 

---FILE: tests/testthat/test-standardize_parameters.R---
@@ -24,6 +24,15 @@ if (require(""testthat"") && require(""effectsize"")) {
     testthat::expect_equal(s1$Std_Coefficient, s2$Std_Coefficient)
     testthat::expect_equal(s1$CI_low, s2$CI_low)
     testthat::expect_equal(s1$CI_high, s2$CI_high)
+
+    mpe <<- parameters::model_parameters(model, exponentiate = TRUE)
+    se1 <- standardize_parameters(model, method = ""basic"", exponentiate = TRUE)
+    se2 <- standardize_parameters(mpe, method = ""basic"", exponentiate = TRUE)
+
+    testthat::expect_equal(se1$Parameter, se2$Parameter)
+    testthat::expect_equal(se1$Std_Coefficient, se2$Std_Coefficient)
+    testthat::expect_equal(se1$CI_low, se2$CI_low)
+    testthat::expect_equal(se1$CI_high, se2$CI_high)
   })
 
   # lm with ci -----------------------------------",True,False,Implementation / Logic,6
easystats,effectsize,177f16022129e79587521f3405c759f29c6b0aa3,Daniel,mail@danielluedecke.de,2020-10-02T10:31:10Z,Daniel,mail@danielluedecke.de,2020-10-02T10:31:10Z,fix?,R/standardize_info.R;R/utils_standardize.R,False,True,True,False,9,1,10,"---FILE: R/standardize_info.R---
@@ -208,7 +208,10 @@ standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseu
 #' @keywords internal
 .std_info_response_smart <- function(model, data, model_matrix, types, robust = FALSE, ...) {
   info <- insight::model_info(model)
-  w <- insight::get_weights(model)
+  w <- insight::get_weights(model, na_rm = TRUE)
+
+  ## TODO after insight 0.9.7 on CRAN, use get_weights(model, na_rm = TRUE) and remove this line
+  if (anyNA(w)) w <- stats::na.omit(w)
 
   if (info$is_linear) {
     # response <- insight::get_response(model)

---FILE: R/utils_standardize.R---
@@ -36,6 +36,11 @@
   }
 
   stopifnot(all(weights > 0, na.rm = TRUE))
+
+  # remove missings
+  if (anyNA(x)) x <- stats::na.omit(x)
+  if (anyNA(weights)) weights <- stats::na.omit(weights)
+
   stats::weighted.mean(x, weights, na.rm = TRUE)
 }
 ",True,False,Implementation / Logic,6
easystats,effectsize,298cb25c4d4a6988e0f238e2ee1ee8bdda2febd1,Daniel,mail@danielluedecke.de,2020-10-02T07:38:17Z,Daniel,mail@danielluedecke.de,2020-10-02T07:38:17Z,fix with NA in weights,R/standardize_info.R;R/utils_standardize.R,False,True,True,False,15,4,19,"---FILE: R/standardize_info.R---
@@ -220,7 +220,7 @@ standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseu
         parent_var <- types$Variable[types$Parameter == var]
         intercept <- unique(data[[parent_var]])[1]
         response_at_intercept <- response[data[[parent_var]] == intercept]
-        weights_at_intercept <- if(length(w)) w[data[[parent_var]] == intercept] else NULL
+        weights_at_intercept <- if (length(w)) w[data[[parent_var]] == intercept] else NULL
         std_info <- .compute_std_info(response = response_at_intercept,
                                       robust = robust, weights = weights_at_intercept)
       } else {
@@ -245,12 +245,18 @@ standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseu
 
 
 
+#' @importFrom stats na.omit model.frame
 #' @keywords internal
 .std_info_response_basic <- function(model, params, robust = FALSE, ...) {
   info <- insight::model_info(model)
   w <- insight::get_weights(model)
   # response <- insight::get_response(model)
-  response <- model.frame(model)[[1]]
+  response <- stats::model.frame(model)[[1]]
+
+  # remove missing from weights
+  if (!is.null(w) && anyNA(w) && length(w) > length(response)) {
+    w <- stats::na.omit(w)
+  }
 
   if (info$is_linear) {
     if (robust == FALSE) {
@@ -325,7 +331,7 @@ standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseu
                              group = ""id"")
     dm <- dm[,paste0(colnames(temp_d), ""_between""), drop = FALSE]
 
-    has_lvl2_var <- sapply(seq_along(colnames(temp_d)), function (i) {
+    has_lvl2_var <- sapply(seq_along(colnames(temp_d)), function(i) {
       # If more than 1% of the variance in the within-var is between:
       var(dm[,i]) /
          var(temp_d[,i])

---FILE: R/utils_standardize.R---
@@ -48,9 +48,14 @@
     return(stats::sd(x))
   }
 
+  # remove missing from weights
+  if (anyNA(weights)) {
+    weights <- stats::na.omit(weights)
+  }
+
   stopifnot(all(weights > 0))
 
-  weights1 <- weights/sum(weights)
+  weights1 <- weights / sum(weights)
   center <- sum(weights1 * x)
   xc <- sqrt(weights1) * (x - center)
   var <- (t(xc) %*% xc) / (1 - sum(weights1 ^ 2))",True,False,Implementation / Logic,6
easystats,effectsize,9b94c137b21b3ae7a887606b81d3e0a6dddc4131,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-01T06:32:37Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-10-01T06:32:37Z,"fix missing weight test

#147",tests/testthat/test-standardize-models.R,False,True,True,False,2,3,5,"---FILE: tests/testthat/test-standardize-models.R---
@@ -67,7 +67,7 @@ if (require(""testthat"") && require(""effectsize"")) {
 
     # standardize 2nd data set
     iris2 <- standardize(iris, select = c(""Sepal.Length"", ""Petal.Width""),
-                         na_action = ""select"")
+                         na_action = ""all"")
     iris3 <- standardize(iris, select = c(""Sepal.Length"", ""Petal.Width""),
                          weights = ""weight_me"",
                          na_action = ""select"")
@@ -80,12 +80,11 @@ if (require(""testthat"") && require(""effectsize"")) {
     # weights, missing data, but data isn't weight-stdized
     m2 <- lm(Sepal.Length ~ Species + Petal.Width, data = iris2, weights = weight_me)
     sm2 <- standardize(m1, weights = FALSE)
-    # testthat::expect_equal(coef(m2), coef(sm2)) #<<<<<<
+    testthat::expect_equal(coef(m2), coef(sm2))
 
     # weights, missing data, and data is weight-stdized
     m3 <- lm(Sepal.Length ~ Species + Petal.Width, data = iris3, weights = weight_me)
     sm3 <- standardize(m1, weights = TRUE)
     testthat::expect_equal(coef(m3), coef(sm3))
-
   })
 }",True,False,Dependency / Package,3
easystats,effectsize,401c970eddcb5356584d98fe7e485caf7d5fe2f7,Daniel,mail@danielluedecke.de,2020-09-30T15:42:42Z,Daniel,mail@danielluedecke.de,2020-09-30T15:42:42Z,fix,tests/testthat/test-standardize-weights.R,False,True,True,False,1,1,2,"---FILE: tests/testthat/test-standardize-weights.R---
@@ -27,7 +27,7 @@ if (require(""testthat"") && require(""effectsize"")) {
   test_that(""standardize-weight"", {
     expect_equal(unname(coef(sm1)), c(-0.01782, -0.091, 0.14961, 0.79504), tolerance = 1e-3)
     expect_equal(unname(coef(sm2)), c(-0.01847, -0.09095, 0.14953, 0.80802), tolerance = 1e-3)
-    expect_equal(unname(coef(model2)), c(-0.01782, -0.091, 0.14961, 0.79504), tolerance = 1e-3)
+    expect_equal(unname(coef(model2)), c(-0.01387, -0.09228, 0.15172, 0.82143), tolerance = 1e-3)
     expect_equal(unname(coef(model3)), c(0.00767, -0.11275, 0.0216, 0.81173), tolerance = 1e-3)
     expect_equal(unname(coef(model4)), c(-0.04349, -0.0914, 0.15028, 0.77812), tolerance = 1e-3)
     expect_equal(unname(coef(model5)), c(0.00506, -0.12284, 0.04546, 0.81432), tolerance = 1e-3)",True,False,Dependency / Package,3
easystats,effectsize,46070003e53a24244f4020f679e90de2eaaa7513,Daniel,mail@danielluedecke.de,2020-09-30T12:18:56Z,Daniel,mail@danielluedecke.de,2020-09-30T12:18:56Z,minor fixes with standardizing models with weights,NAMESPACE;R/standardize.models.R,False,True,True,False,12,4,16,"---FILE: NAMESPACE---
@@ -168,6 +168,7 @@ importFrom(insight,get_predictors)
 importFrom(insight,get_random)
 importFrom(insight,get_response)
 importFrom(insight,get_variance)
+importFrom(insight,get_weights)
 importFrom(insight,model_info)
 importFrom(parameters,check_heterogeneity)
 importFrom(parameters,demean)

---FILE: R/standardize.models.R---
@@ -1,6 +1,6 @@
 #' @rdname standardize
-#' @importFrom stats update
-#' @importFrom insight get_data model_info find_response get_response find_weights
+#' @importFrom stats update na.omit
+#' @importFrom insight get_data model_info find_response get_response find_weights get_weights
 #' @importFrom utils capture.output
 #' @export
 standardize.default <- function(x, robust = FALSE, two_sd = FALSE, weights = TRUE, include_response = TRUE, verbose = TRUE, ...) {
@@ -22,6 +22,12 @@ standardize.default <- function(x, robust = FALSE, two_sd = FALSE, weights = TRU
   # cause errors in ""update()""
   weight_variable <- insight::find_weights(x)
 
+  if (!is.null(weight_variable) && !weight_variable %in% colnames(data) && ""(weights)"" %in% colnames(data)) {
+    data$.missing_weight <- data[[""(weights)""]]
+    colnames(data)[ncol(data)] <- weight_variable
+    weight_variable <- c(weight_variable, ""(weights)"")
+  }
+
   # don't standardize random effects
   random_group_factor <- insight::find_random(x, flatten = TRUE, split_nested = TRUE)
 
@@ -34,7 +40,7 @@ standardize.default <- function(x, robust = FALSE, two_sd = FALSE, weights = TRU
     data_std <- standardize(data[do_standardize],
                             robust = robust,
                             two_sd = two_sd,
-                            weights = if (weights) insight::get_weights(x) else NULL,
+                            weights = if (weights) stats::na.omit(insight::get_weights(x)) else NULL,
                             verbose = verbose)
 
     if (!.no_response_standardize(m_info) && include_response && two_sd) {
@@ -76,7 +82,8 @@ standardize.default <- function(x, robust = FALSE, two_sd = FALSE, weights = TRU
   # restore data that should not be standardized
 
   if (length(dont_standardize)) {
-    data_std <- cbind(data[, dont_standardize, drop = FALSE], data_std)
+    remaining_columns <- intersect(colnames(data), dont_standardize)
+    data_std <- cbind(data[, remaining_columns, drop = FALSE], data_std)
   }
 
   # update model with standardized data",True,False,Dependency / Package,6
easystats,effectsize,22b4b7621a28693e5763ac47683dc68ba99c9dc2,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-30T06:03:40Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-30T06:03:40Z,fix README example,README.Rmd;README.md,True,False,True,False,60,20,80,"---FILE: README.Rmd---
@@ -16,8 +16,6 @@ editor_options:
 # effectsize <img src='man/figures/logo.png' align=""right"" height=""139"" />
 
 ```{r, echo = FALSE, warning=FALSE, message=FALSE}
-library(ggplot2)
-library(dplyr)
 library(effectsize)
 
 options(digits=3)
@@ -85,7 +83,7 @@ library(effectsize)
 
 ## Effect Size Computation
 
-### Basic Indices (Cohen's *d*, Hedges' *g*, Glass' *delta*)
+### Standardized Differences (Cohen's *d*, Hedges' *g*, Glass' *delta*)
 
 The package provides functions to compute indices of effect size.
 
@@ -107,13 +105,20 @@ cohens_f(model)
 ```
 
 
-### Regression Models
+### Regression Models (Standardized Parameters)
 
 Importantly, `effectsize` also provides [advanced methods](https://easystats.github.io/effectsize/articles/standardize_parameters.html) to compute standardized parameters for regression models.
 
 ```{r, warning=FALSE, message=FALSE}
-lm(Sepal.Length ~ Species + Sepal.Length, data = iris) %>% 
-  standardize_parameters()
+m <- lm(Sepal.Length ~ Species + Sepal.Width, data = iris)
+
+standardize_parameters(m)
+```
+
+Also, models can be re-fit with standardized data:
+
+```{r, warning=FALSE, message=FALSE}
+standardize(m)
 ```
 
 ## Effect Size Interpretation
@@ -141,12 +146,17 @@ The package also provides ways of converting between different effect sizes.
 convert_d_to_r(d = 1)
 ```
 
+And for recovering effect sizes from test statistics.
 
-## Standardization
+```{r, warning=FALSE, message=FALSE}
+F_to_d(15, df = 1, df_error = 60)
+F_to_r(15, df = 1, df_error = 60)
+F_to_eta2(15, df = 1, df_error = 60)
+```
 
-Many indices of effect size stem out, or are related, to [*standardization*](https://easystats.github.io/effectsize/articles/standardize_parameters.html). Thus, it is expected that `effectsize` provides functions to standardize data and models.
+## Data Standardization, Normalization, Scaling, and Rank-Transforming
 
-### Data standardization, normalization and rank-transformation
+Many indices of effect size stem out, or are related, to [*standardization*](https://easystats.github.io/effectsize/articles/standardize_parameters.html). Thus, it is expected that `effectsize` provides functions to standardize data.
 
 
 A standardization sets the mean and SD to 0 and 1:

---FILE: README.md---
@@ -69,7 +69,7 @@ library(effectsize)
 
 ## Effect Size Computation
 
-### Basic Indices (Cohenâs *d*, Hedgesâ *g*, Glassâ *delta*)
+### Standardized Differences (Cohenâs *d*, Hedgesâ *g*, Glassâ *delta*)
 
 The package provides functions to compute indices of effect size.
 
@@ -111,24 +111,39 @@ cohens_f(model)
 ## Species   |                1.27 | [1.09, 1.45]
 ```
 
-### Regression Models
+### Regression Models (Standardized Parameters)
 
 Importantly, `effectsize` also provides [advanced
 methods](https://easystats.github.io/effectsize/articles/standardize_parameters.html)
 to compute standardized parameters for regression models.
 
 ``` r
-lm(Sepal.Length ~ Species + Sepal.Length, data = iris) %>% 
-  standardize_parameters()
+m <- lm(Sepal.Length ~ Species + Sepal.Width, data = iris)
+
+standardize_parameters(m)
 ## Parameter         | Coefficient (std.) |         95% CI
 ## -------------------------------------------------------
-## (Intercept)       |              -1.01 | [-1.18, -0.84]
-## Speciesversicolor |               1.12 | [ 0.88,  1.37]
-## Speciesvirginica  |               1.91 | [ 1.66,  2.16]
+## (Intercept)       |              -1.37 | [-1.55, -1.20]
+## Speciesversicolor |               1.76 | [ 1.49,  2.03]
+## Speciesvirginica  |               2.35 | [ 2.11,  2.59]
+## Sepal.Width       |               0.42 | [ 0.31,  0.53]
 ## 
 ## # Standardization method: Refit
 ```
 
+Also, models can be re-fit with standardized data:
+
+``` r
+standardize(m)
+## 
+## Call:
+## lm(formula = Sepal.Length ~ Species + Sepal.Width, data = data_std)
+## 
+## Coefficients:
+##       (Intercept)  Speciesversicolor   Speciesvirginica        Sepal.Width  
+##            -1.371              1.762              2.351              0.423
+```
+
 ## Effect Size Interpretation
 
 The package allows for an automated interpretation of different indices.
@@ -160,14 +175,29 @@ convert_d_to_r(d = 1)
 ## [1] 0.447
 ```
 
-## Standardization
+And for recovering effect sizes from test statistics.
+
+``` r
+F_to_d(15, df = 1, df_error = 60)
+## d |       95% CI
+## ----------------
+## 1 | [0.46, 1.53]
+F_to_r(15, df = 1, df_error = 60)
+##    r |       95% CI
+## -------------------
+## 0.45 | [0.22, 0.61]
+F_to_eta2(15, df = 1, df_error = 60)
+## Eta2 (partial) |       90% CI
+## -----------------------------
+##           0.20 | [0.07, 0.34]
+```
+
+## Data Standardization, Normalization, Scaling, and Rank-Transforming
 
 Many indices of effect size stem out, or are related, to
 [*standardization*](https://easystats.github.io/effectsize/articles/standardize_parameters.html).
 Thus, it is expected that `effectsize` provides functions to standardize
-data and models.
-
-### Data standardization, normalization and rank-transformation
+data.
 
 A standardization sets the mean and SD to 0 and 1:
 ",False,True,Documentation / Formatting,7
easystats,effectsize,952da4136d82c42ffef26d58d7b1b44dc1be1a62,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-29T06:17:13Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-29T06:17:13Z,fix cantposthoc for bayes models,R/standardize_parameters.R,False,True,True,False,5,5,10,"---FILE: R/standardize_parameters.R---
@@ -239,7 +239,7 @@ standardize_parameters.parameters_model <- function(model, method = ""refit"", ci
   }
 
   if (method %in% c(""smart"", ""posthoc"") &&
-      .cant_smart_or_posthoc(model, pars)) {
+      .cant_smart_or_posthoc(model, pars$Parameter)) {
     warning(""Method '"", method, ""' does not currently support models with transformed parameters."",
             ""\nReverting to 'basic' method. Concider using the 'refit' method directly."",
             call. = FALSE)
@@ -343,7 +343,7 @@ standardize_posteriors <- function(model, method = ""refit"", robust = FALSE, two_
   }
 
   if (method %in% c(""smart"", ""posthoc"") &&
-      .cant_smart_or_posthoc(model, pars)) {
+      .cant_smart_or_posthoc(model, colnames(pars))) {
     warning(""Method '"", method, ""' does not currently support models with transformed parameters."",
             ""\nReverting to 'basic' method. Concider using the 'refit' method directly."",
             call. = FALSE)
@@ -391,7 +391,7 @@ standardize_posteriors <- function(model, method = ""refit"", robust = FALSE, two_
 
 
 #' @keywords internal
-.cant_smart_or_posthoc <- function(model,pars) {
+.cant_smart_or_posthoc <- function(model,params) {
 
   cant_posthocsmart <- FALSE
 
@@ -403,8 +403,8 @@ standardize_posteriors <- function(model, method = ""refit"", robust = FALSE, two_
 
   # factors are allowed
   if (!cant_posthocsmart &&
-      !all(pars$Parameter == insight::clean_names(pars$Parameter) |
-           grepl(""(as.factor|factor)\\("", pars$Parameter))) {
+      !all(params == insight::clean_names(params) |
+           grepl(""(as.factor|factor)\\("", params))) {
     cant_posthocsmart <- TRUE
   }
 ",True,False,Implementation / Logic,6
easystats,effectsize,23f989fb63fc60c0b1ed332a67a316af4324cf1b,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-29T06:16:41Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-29T06:16:41Z,"fix weighted std

caused by messy merger :(",R/standardize_info.R;tests/testthat/test-standardize.R,False,True,True,False,40,24,64,"---FILE: R/standardize_info.R---
@@ -57,14 +57,14 @@ standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseu
   # Basic
   out <- merge(
     out,
-    .std_info_predictors_basic(model_matrix, types, robust = robust, two_sd = two_sd),
+    .std_info_predictors_basic(model, model_matrix, types, robust = robust, two_sd = two_sd),
     by = ""Parameter"", all = TRUE
   )
 
   # Smart
   out <- merge(
     out,
-    .std_info_predictors_smart(data, params, types, robust = robust, two_sd = two_sd),
+    .std_info_predictors_smart(model, data, params, types, robust = robust, two_sd = two_sd),
     by = ""Parameter"", all = TRUE
   )
 
@@ -105,8 +105,8 @@ standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseu
 
 
 #' @keywords internal
-.std_info_predictors_smart <- function(data, params, types, robust = FALSE, two_sd = FALSE, ...) {
-
+.std_info_predictors_smart <- function(model, data, params, types, robust = FALSE, two_sd = FALSE, ...) {
+  w <- insight::get_weights(model)
   # Get deviations for all parameters
   means <- deviations <- rep(NA_real_, times = length(params))
   for (i in seq_along(params)) {
@@ -116,7 +116,8 @@ standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseu
       variable = types[types$Parameter == var, ""Variable""],
       type = types[types$Parameter == var, ""Type""],
       robust = robust,
-      two_sd = two_sd
+      two_sd = two_sd,
+      weights = w
     )
     deviations[i] <- info$sd
     means[i] <- info$mean
@@ -133,11 +134,12 @@ standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseu
 
 
 #' @keywords internal
-.std_info_predictor_smart <- function(data, variable, type, robust = FALSE, two_sd = FALSE, ...) {
+.std_info_predictor_smart <- function(data, variable, type, robust = FALSE, two_sd = FALSE, weights = NULL, ...) {
   if (type == ""intercept"") {
     info <- list(sd = 0, mean = 0)
   } else if (type == ""numeric"") {
-    info <- .compute_std_info(data = data, variable = variable, robust = robust, two_sd = two_sd)
+    info <- .compute_std_info(data = data, variable = variable,
+                              robust = robust, two_sd = two_sd, weights = weights)
   } else if (type == ""factor"") {
     info <- list(sd = 1, mean = 0)
 
@@ -153,7 +155,8 @@ standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseu
     # }
   } else if (type %in% c(""interaction"", ""nested"")) {
     if (is.numeric(data[, variable])) {
-      info <- .compute_std_info(data = data, variable = variable, robust = robust, two_sd = two_sd)
+      info <- .compute_std_info(data = data, variable = variable,
+                                robust = robust, two_sd = two_sd, weights = weights)
     } else if (is.factor(data[, variable])) {
       info <- list(sd = 1, mean = 0)
     } else {
@@ -171,7 +174,8 @@ standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseu
 
 
 #' @keywords internal
-.std_info_predictors_basic <- function(model_matrix, types, robust = FALSE, two_sd = FALSE, ...) {
+.std_info_predictors_basic <- function(model, model_matrix, types, robust = FALSE, two_sd = FALSE, ...) {
+  w <- insight::get_weights(model)
 
   # Get deviations for all parameters
   means <- deviations <- rep(NA_real_, length = length(names(model_matrix)))
@@ -180,7 +184,8 @@ standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseu
     if (types[i, ""Type""] == ""intercept"") {
       means[i] <- deviations[i] <- 0
     } else {
-      std_info <- .compute_std_info(data = model_matrix, variable = var, robust = robust, two_sd = two_sd)
+      std_info <- .compute_std_info(data = model_matrix, variable = var,
+                                    robust = robust, two_sd = two_sd, weights = w)
       deviations[i] <- std_info$sd
       means[i] <- std_info$mean
     }
@@ -203,6 +208,7 @@ standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseu
 #' @keywords internal
 .std_info_response_smart <- function(model, data, model_matrix, types, robust = FALSE, ...) {
   info <- insight::model_info(model)
+  w <- insight::get_weights(model)
 
   if (info$is_linear) {
     # response <- insight::get_response(model)
@@ -214,9 +220,12 @@ standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseu
         parent_var <- types$Variable[types$Parameter == var]
         intercept <- unique(data[[parent_var]])[1]
         response_at_intercept <- response[data[[parent_var]] == intercept]
-        std_info <- .compute_std_info(response = response_at_intercept, robust = robust)
+        weights_at_intercept <- if(length(w)) w[data[[parent_var]] == intercept] else NULL
+        std_info <- .compute_std_info(response = response_at_intercept,
+                                      robust = robust, weights = weights_at_intercept)
       } else {
-        std_info <- .compute_std_info(response = response, robust = robust)
+        std_info <- .compute_std_info(response = response,
+                                      robust = robust, weights = w)
       }
       deviations[i] <- std_info$sd
       means[i] <- std_info$mean
@@ -239,16 +248,17 @@ standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseu
 #' @keywords internal
 .std_info_response_basic <- function(model, params, robust = FALSE, ...) {
   info <- insight::model_info(model)
+  w <- insight::get_weights(model)
   # response <- insight::get_response(model)
   response <- model.frame(model)[[1]]
 
   if (info$is_linear) {
     if (robust == FALSE) {
-      sd_y <- stats::sd(response)
-      mean_y <- mean(response)
+      sd_y <- .sd(response, w)
+      mean_y <- .mean(response, w)
     } else {
-      sd_y <- stats::mad(response)
-      mean_y <- stats::median(response)
+      sd_y <- .mad(response, w)
+      mean_y <- .median(response, w)
     }
   } else {
     sd_y <- 1
@@ -281,6 +291,7 @@ standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseu
 
   within_vars <- unclass(parameters::check_heterogeneity(model))
   id <- insight::get_random(model)[[1]]
+  w <- insight::get_weights(model)
 
   ## Find which parameters vary on level 1 (""within"")
   is_within <- logical(length = length(params))
@@ -348,6 +359,7 @@ standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseu
 
     m0 <- suppressWarnings(suppressMessages(
       lme4::lmer(stats::as.formula(frm),
+                 weights = w,
                  data = insight::get_data(model))
     ))
     m0v <- insight::get_variance(m0)
@@ -373,7 +385,7 @@ standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseu
         X <- tapply(model_matrix[[i]], id, mean)
         Deviation_Response_Pseudo[i] <- sd_y_between
       }
-      Deviation_Pseudo[i] <- f * stats::sd(X)
+      Deviation_Pseudo[i] <- f * .sd(X, w)
 
       ## smart way?
       ## DONT USE: see correspondence with between Mattan and Eran BC
@@ -407,18 +419,18 @@ standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseu
 
 
 #' @keywords internal
-.compute_std_info <- function(data = NULL, variable = NULL, response = NULL, robust = FALSE, two_sd = FALSE) {
+.compute_std_info <- function(data = NULL, variable = NULL, response = NULL, robust = FALSE, two_sd = FALSE, weights = NULL) {
   f <- if (two_sd) 2 else 1
   if (is.null(response)) {
     response <- as.numeric(data[, variable])
   }
 
   if (robust == FALSE) {
-    sd_x <- stats::sd(response, na.rm = TRUE)
-    mean_x <- mean(response, na.rm = TRUE)
+    sd_x <- .sd(response, weights)
+    mean_x <- .mean(response, weights)
   } else {
-    sd_x <- stats::mad(response, na.rm = TRUE)
-    mean_x <- stats::median(response, na.rm = TRUE)
+    sd_x <- .mad(response, weights)
+    mean_x <- .median(response, weights)
   }
 
   list(sd = f * sd_x, mean = mean_x)

---FILE: tests/testthat/test-standardize.R---
@@ -112,7 +112,7 @@ if (require(""testthat"") && require(""effectsize"") && require(""dplyr"") && require(
 
 
 # W/ weights --------------------------------------------------------------
-  test_that(""standardize.lm"", {
+  test_that(""weights"", {
     expect_warning(standardize(mtcars, weights = ""xx""))
 
     m <- lm(mpg ~ am + hp, weights = cyl, mtcars)
@@ -129,9 +129,13 @@ if (require(""testthat"") && require(""effectsize"") && require(""dplyr"") && require(
     expect_false(isTRUE(all.equal(coef(sm)[-1], coef(sm_xw)[-1])))
 
     # refit and posthoc should give same results
-    expect_equal(standardize_parameters(m, method = ""refit"")[[2]],
+    stdREFIT <- standardize_parameters(m, method = ""refit"")
+    expect_equal(stdREFIT[[2]],
                  standardize_parameters(m, method = ""posthoc"")[[2]])
 
+    expect_equal(stdREFIT[[2]],
+                 standardize_parameters(m, method = ""basic"")[[2]])
+
 
     x <- rexp(30)
     w <- rpois(30, 20) + 1",True,False,Implementation / Logic,6
easystats,effectsize,82b099d6b05d7f616c9e8ea995cbc520c4d67214,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-29T05:25:22Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-29T05:25:22Z,fix vignette,R/eta_squared_posterior.R;_pkgdown.yml;vignettes/bayesian_models.Rmd,True,True,True,False,29,21,50,"---FILE: R/eta_squared_posterior.R---
@@ -135,7 +135,7 @@ eta_squared_posterior.brmsfit <- eta_squared_posterior.stanreg
 #' @keywords internal
 #' @importFrom stats contrasts
 .all_centered <- function(X) {
-  numeric <- sapply(X, inherits, what = c(""numeric"",""integer""))
+  numeric <- sapply(X, inherits, what = c(""numeric"", ""integer""))
   numerics <- colnames(X)[numeric]
   factors <- colnames(X)[!numeric]
 
@@ -148,11 +148,14 @@ eta_squared_posterior.brmsfit <- eta_squared_posterior.stanreg
 
 
   of <- options()$contrasts
-  if (length(factors) && !all(of %in% c('contr.sum', 'contr.poly', ""contr.bayes"", ""contr.helmert""))) {
-    # if a contrast has negative and positive values, it is assumed to be one of:
-    # ""contr.sum"", ""contr.helmert"", ""contr.poly"", ""contr.bayes""
-    factors_centered <- sapply(X[, factors, drop = FALSE],
-                               function(xi) any(contrasts(xi) < 0) & any(contrasts(xi) > 0))
+  if (length(factors)) {
+    factors_centered <- sapply(X[, factors, drop = FALSE], function(xi) {
+      # if a contrast has negative and positive values, it is assumed to be one of:
+      # ""contr.sum"", ""contr.helmert"", ""contr.poly"", ""contr.bayes""
+      (is.factor(xi) && (any(contrasts(xi) < 0) & any(contrasts(xi) > 0))) ||
+        # Or if it is not a factor, is the default method one of these?
+        (!is.factor(xi) && all(of %in% c('contr.sum', 'contr.poly', ""contr.bayes"", ""contr.helmert"")))
+    })
   }
 
 

---FILE: _pkgdown.yml---
@@ -87,6 +87,8 @@ navbar:
         href: articles/standardize_parameters.html
       - text: ""Effect Sizes for ANOVA""
         herf: articles/anovaES.html
+      - text: ""For Bayesian Models""
+        herf: articles/bayesian_models.html
   - text: ""Conversion""
     menu:
       - text: ""Between *d*, *r*, *OR*""

---FILE: vignettes/bayesian_models.Rmd---
@@ -97,7 +97,9 @@ By sampling from the PPD, we can decompose the sample to the various *SS*s neede
 
 Let's factorize out data from above:
 ```{r}
-hardlyworking$age_f <- ifelse(hardlyworking$age < 35, ""Young"", ""Less_young"")
+hardlyworking$age_f <- cut(hardlyworking$age, 
+                           breaks = c(25,35,45), right = FALSE,
+                           labels = c(""Young"", ""Less_young""))
 hardlyworking$comps_f <- cut(hardlyworking$n_comps, 
                              breaks = c(0,1,2,3),
                              include.lowest = TRUE, 
@@ -109,35 +111,36 @@ table(hardlyworking$age_f,hardlyworking$comps_f)
 And fit our model:
 
 ```{r}
+# use effects coding
+contrasts(hardlyworking$age_f) <- contr.sum
+contrasts(hardlyworking$comps_f) <- contr.sum
+
 modAOV <- stan_glm(salary ~ age_f * comps_f,
-                   data = hardlyworking,
-                   family = gaussian(), refresh = 0)
+                   data = hardlyworking, family = gaussian(),
+                   refresh = 0)
 ```
 
 We can use `eta_squared_posterior()` to get the posterior distribution of $eta^2$ or $eta^2_p$ for each effect. Like an ANOVA table, we must make sure to use the right effects-coding and *SS*-type:
 
-```{r echo=FALSE}
-# save old effects-coding
-old_contrasts <- getOption(""contrasts"")
-```
-
 ```{r}
-# set effects-coding
-options(contrasts = c('contr.sum', 'contr.poly'))
-
 pes_posterior <- eta_squared_posterior(modAOV, 
                                        draws = 500, # how many times should the PPD be estimated
                                        partial = TRUE, # partial eta squared
                                        type = 3) # type 3 SS
 
 head(pes_posterior)
 
-bayestestR::describe_posterior(pes_posterior, rope_range = c(0, 0.1))
+bayestestR::describe_posterior(pes_posterior, rope_range = c(0, 0.1), test = ""rope"")
+
 ```
 
-```{r echo=FALSE}
-# set back effects-coding
-options(contrasts = old_contrasts)
+# Compare to:
+
+```{r}
+modAOV_f <- lm(salary ~ age_f * comps_f,
+               data = hardlyworking)
+
+eta_squared(car::Anova(modAOV_f, type = 3))
 ```
 
 ",True,True,Documentation / Formatting,7
easystats,effectsize,23f6b81d11cfeda4a8d8011fb81df56614f9c8e1,DominiqueMakowski,dom.mak19@gmail.com,2020-09-28T14:58:58Z,DominiqueMakowski,dom.mak19@gmail.com,2020-09-28T14:58:58Z,I might have the fix @mattansb,vignettes/standardize_parameters.Rmd,True,False,True,False,3,0,3,"---FILE: vignettes/standardize_parameters.Rmd---
@@ -74,6 +74,9 @@ model_parameters(r)
 
 How does it work in the case of differences, when **factors** are entered and differences between a given level and a reference level? You might have heard that it is similar to a **Cohen's *d***. Well, let's see.
 
+```{r include=FALSE}
+mtcars <- datasets::mtcars
+```
 ```{r}
 # Select portion of data containing the two levels of interest
 mtcars$am <- factor(mtcars$am, labels = c(""Manual"", ""Automatic""))",False,True,Rendering / Conversion,3
easystats,effectsize,93ba0747b43f5d08954fc97caaf94b00491f1bd7,Daniel,mail@danielluedecke.de,2020-09-28T13:24:29Z,Daniel,mail@danielluedecke.de,2020-09-28T13:24:29Z,fix cross ref,R/interpret_cfa_fit.R;man/interpret_gfi.Rd,False,True,True,False,2,2,4,"---FILE: R/interpret_cfa_fit.R---
@@ -20,7 +20,7 @@
 #' - **IFI**: the Incremental Fit Index (IFI) adjusts the Normed Fit Index (NFI) for sample size and degrees of freedom (Bollen's, 1989). Over 0.90 is a good fit, but the index can exceed 1.
 #' - **PNFI**: the Parsimony-Adjusted Measures Index. There is no commonly agreed-upon cutoff value for an acceptable model for this index. Should be > 0.50.
 #'
-#' See the documentation for [lavaan::fitmeasures()].
+#' See the documentation for \code{\link[lavaan:fitmeasures]{fitmeasures()}}.
 #'
 #'
 #' ## What to report

---FILE: man/interpret_gfi.Rd---
@@ -55,7 +55,7 @@ Interpretation of indices of fit found in confirmatory analysis or structural eq
 \item \strong{PNFI}: the Parsimony-Adjusted Measures Index. There is no commonly agreed-upon cutoff value for an acceptable model for this index. Should be > 0.50.
 }
 
-See the documentation for \code{\link[lavaan:fitMeasures]{lavaan::fitmeasures()}}.
+See the documentation for \code{\link[lavaan:fitmeasures]{fitmeasures()}}.
 }
 
 \subsection{What to report}{",True,False,Documentation / Formatting,6
easystats,effectsize,654760bcc5c78e57cdc9743906ee405221e2afe5,Daniel,mail@danielluedecke.de,2020-09-28T10:42:20Z,Daniel,mail@danielluedecke.de,2020-09-28T10:42:20Z,fixing serious issues,R/eta_squared_posterior.R,False,True,True,False,1,1,2,"---FILE: R/eta_squared_posterior.R---
@@ -152,7 +152,7 @@ eta_squared_posterior.brmsfit <- eta_squared_posterior.stanreg
     # if a contrast has negative and positive values, it is assumed to be one of:
     # ""contr.sum"", ""contr.helmert"", ""contr.poly"", ""contr.bayes""
     factors_centered <- sapply(X[, factors, drop = FALSE],
-                               function (xi) any(contrasts(xi) < 0) & any(contrasts(xi) > 0))
+                               function(xi) any(contrasts(xi) < 0) & any(contrasts(xi) > 0))
   }
 
 ",True,False,Implementation / Logic,3
easystats,effectsize,16989d6b2c406ba17d90ab8209308acf44d9f451,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-27T19:57:20Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-27T19:57:20Z,fix std of transformed outcome,NEWS.md;R/standardize_info.R;tests/testthat/test-standardize_parameters.R,False,True,True,False,19,3,22,"---FILE: NEWS.md---
@@ -14,6 +14,7 @@
 
 ## Bug fixes
 
+- `standardize_parameters()` for post-hoc correctly standardizes transformed outcome.
 - Setting `two_sd = TRUE` in `standardize()` and `standardize_parameters()` (correctly) on uses 2-SDs of the predictors (and not the response). 
 - `standardize_info()` / `standardize_parameters(method = ""posthoc"")` work for zero-inflated models ( #135 )
 - `standardize_info(include_pseudo = TRUE)` / `standardize_parameters(method = ""pseudo"")` are less sensitive in detecting between-group variation of within-group variables.

---FILE: R/standardize_info.R---
@@ -205,7 +205,8 @@ standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseu
   info <- insight::model_info(model)
 
   if (info$is_linear) {
-    response <- insight::get_response(model)
+    # response <- insight::get_response(model)
+    response <- model.frame(model)[[1]]
     means <- deviations <- rep(NA_real_, length = length(names(model_matrix)))
     for (i in seq_along(names(model_matrix))) {
       var <- names(model_matrix)[i]
@@ -238,7 +239,8 @@ standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseu
 #' @keywords internal
 .std_info_response_basic <- function(model, params, robust = FALSE, ...) {
   info <- insight::model_info(model)
-  response <- insight::get_response(model)
+  # response <- insight::get_response(model)
+  response <- model.frame(model)[[1]]
 
   if (info$is_linear) {
     if (robust == FALSE) {

---FILE: tests/testthat/test-standardize_parameters.R---
@@ -89,7 +89,7 @@ if (require(""testthat"") && require(""effectsize"")) {
 
 
   # ""standardize_parameters (with function interactions)"" -------------------
-  test_that(""standardize_parameters (with function interactions)"", {
+  test_that(""standardize_parameters (with functions /  interactions)"", {
     X <- scale(rnorm(100),T,F)
     Z <- scale(rnorm(100),T,F)
     Y <- scale(Z + X * Z + rnorm(100),T,F)
@@ -111,6 +111,19 @@ if (require(""testthat"") && require(""effectsize"")) {
     #   standardize_parameters(m1, method = ""basic"")$Std_Coefficient,
     #   standardize_parameters(m4, method = ""basic"")$Std_Coefficient
     # )
+
+
+    # transformed resp or pred should not affect
+    mtcars$cyl_exp <- exp(mtcars$cyl)
+    mtcars$mpg_sqrt <- sqrt(mtcars$mpg)
+    m1 <- lm(exp(cyl) ~ am + sqrt(mpg), mtcars)
+    m2 <- lm(cyl_exp ~ am + mpg_sqrt, mtcars)
+
+    expect_message(stdX <- standardize_parameters(m1, method = ""refit""))
+    expect_false(isTRUE(all.equal(stdX[[2]],
+                                  standardize_parameters(m2, method = ""refit"")[[2]])))
+    expect_equal(standardize_parameters(m1, method = ""basic"")[[2]],
+                 standardize_parameters(m2, method = ""basic"")[[2]])
   })
 
 ",True,False,Documentation / Formatting,6
easystats,effectsize,41fd6e2644fc429f30ebc56db741baeacbdcc3f1,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-27T16:02:03Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-27T16:02:03Z,"Update test-standardize_parameters.R

https://github.com/easystats/parameters/issues/305",tests/testthat/test-standardize_parameters.R,False,True,True,False,1,1,2,"---FILE: tests/testthat/test-standardize_parameters.R---
@@ -139,7 +139,7 @@ if (require(""testthat"") && require(""effectsize"")) {
       )
 
       posts <- standardize_posteriors(model, method = ""posthoc"")
-      testthat::expect_equal(dim(posts), c(1000, 4))
+      testthat::expect_equal(dim(posts), c(1000, 5))
       testthat::expect_is(posts, ""data.frame"")
     })
   }",True,False,Dependency / Package,4
easystats,effectsize,d6d3619b7577dcbfb9ef60bcd7ccf61e72f3cc48,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-27T13:36:16Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-27T13:36:16Z,try fix vignette,vignettes/standardize_parameters.Rmd,True,False,True,False,3,2,5,"---FILE: vignettes/standardize_parameters.Rmd---
@@ -112,8 +112,9 @@ t_to_d(4.11, df_error = 30)
 It is also interesting to note that using the `smart` method (explained in detail below) when standardizing parameters will give you indices equivalent to **Glass' *delta***, which is a standardized difference expressed in terms of SD of the reference group.
 
 ```{r}
-lm(mpg ~ am, data = mtcars) %>%
-  standardize_parameters(method = ""smart"")
+m <- lm(mpg ~ am, data = mtcars)
+
+standardize_parameters(m, method = ""smart"")
 ```
 
 ```{r}",False,True,Documentation / Formatting,4
easystats,effectsize,bb618c797303fddaaa689a56c84747cb636d14fc,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-27T12:13:03Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-27T12:13:03Z,fix two_sd,NEWS.md;R/standardize.R;R/standardize.models.R;R/standardize_info.R;R/standardize_parameters.R;man/standardize.Rd;man/standardize_info.Rd;man/standardize_parameters.Rd;tests/testthat/test-standardize.R;tests/testthat/test-standardize_parameters.R,False,True,True,False,81,44,125,"---FILE: NEWS.md---
@@ -14,6 +14,7 @@
 
 ## Bug fixes
 
+- Setting `two_sd = TRUE` in `standardize()` and `standardize_parameters()` (correctly) on uses 2-SDs of the predictors (and not the response). 
 - `standardize_info()` / `standardize_parameters(method = ""posthoc"")` work for zero-inflated models ( #135 )
 - `standardize_info(include_pseudo = TRUE)` / `standardize_parameters(method = ""pseudo"")` are less sensitive in detecting between-group variation of within-group variables.
 - `interpret_oddsratio()` correctly treats extremely small odds the same as treats extremely large ones.

---FILE: R/standardize.R---
@@ -16,7 +16,8 @@
 #' @param two_sd If `TRUE`, the variables are scaled by two times the deviation
 #'   (SD or MAD depending on `robust`). This method can be useful to obtain
 #'   model coefficients of continuous parameters comparable to coefficients
-#'   related to binary predictors (Gelman, 2008).
+#'   related to binary predictors, when applied to **the predictors** (not the
+#'   outcome) (Gelman, 2008).
 #' @param verbose Toggle warnings on or off.
 #' @param force Logical, if `TRUE`, forces standardization of factors as
 #'   well. Factors are converted to numerical values, with the lowest level

---FILE: R/standardize.models.R---
@@ -12,19 +12,17 @@ standardize.default <- function(x, robust = FALSE, two_sd = FALSE, include_respo
   # with positive integers, or beta with ratio between 0 and 1), we need to
   # make sure that the original response value will be restored after
   # standardizing, as these models also require a non-standardized response.
-
   if (.no_response_standardize(m_info) || !include_response) {
     resp <- unique(c(insight::find_response(x), insight::find_response(x, combine = FALSE)))
+  } else if (include_response && two_sd) {
+    resp <- unique(c(insight::find_response(x), insight::find_response(x, combine = FALSE)))
   }
 
-
   # Do not standardize weighting-variable, because negative weights will
   # cause errors in ""update()""
-
   weight_variable <- insight::find_weights(x)
 
   # don't standardize random effects
-
   random_group_factor <- insight::find_random(x, flatten = TRUE, split_nested = TRUE)
 
   # standardize data
@@ -34,6 +32,12 @@ standardize.default <- function(x, robust = FALSE, two_sd = FALSE, include_respo
 
   if (length(do_standardize)) {
     data_std <- standardize(data[do_standardize], robust = robust, two_sd = two_sd, verbose = verbose)
+
+    if (!.no_response_standardize(m_info) && include_response && two_sd) {
+      # if two_sd, it must not affect the response!
+      data_std[resp] <- standardize(data[resp], robust = robust, two_sd = FALSE, verbose = verbose)
+      dont_standardize <- setdiff(dont_standardize,resp)
+    }
   } else {
     if (verbose) {
       insight::print_color(""No variables could be standardized.\n"", ""red"")

---FILE: R/standardize_info.R---
@@ -10,7 +10,7 @@
 #' model <- lm(Sepal.Width ~ Sepal.Length * Species, data = iris)
 #' @importFrom parameters parameters_type
 #' @export
-standardize_info <- function(model, robust = FALSE, include_pseudo = FALSE, ...) {
+standardize_info <- function(model, robust = FALSE, two_sd = FALSE, include_pseudo = FALSE, ...) {
   params <- insight::find_parameters(model, effects = ""fixed"", flatten = TRUE, ...)
   types <- parameters::parameters_type(model)
   model_matrix <- as.data.frame(stats::model.matrix(model))
@@ -57,14 +57,14 @@ standardize_info <- function(model, robust = FALSE, include_pseudo = FALSE, ...)
   # Basic
   out <- merge(
     out,
-    .std_info_predictors_basic(model_matrix, types, robust = robust),
+    .std_info_predictors_basic(model_matrix, types, robust = robust, two_sd = two_sd),
     by = ""Parameter"", all = TRUE
   )
 
   # Smart
   out <- merge(
     out,
-    .std_info_predictors_smart(data, params, types, robust = robust),
+    .std_info_predictors_smart(data, params, types, robust = robust, two_sd = two_sd),
     by = ""Parameter"", all = TRUE
   )
 
@@ -74,7 +74,7 @@ standardize_info <- function(model, robust = FALSE, include_pseudo = FALSE, ...)
       length(insight::find_random(model)$random) == 1) {
     out <- merge(
       out,
-      .std_info_pseudo(model, params, model_matrix, types = types$Type, robust = robust)
+      .std_info_pseudo(model, params, model_matrix, types = types$Type, robust = robust, two_sd = two_sd)
     )
   }
 
@@ -105,7 +105,7 @@ standardize_info <- function(model, robust = FALSE, include_pseudo = FALSE, ...)
 
 
 #' @keywords internal
-.std_info_predictors_smart <- function(data, params, types, robust = FALSE, ...) {
+.std_info_predictors_smart <- function(data, params, types, robust = FALSE, two_sd = FALSE, ...) {
 
   # Get deviations for all parameters
   means <- deviations <- rep(NA_real_, times = length(params))
@@ -115,7 +115,8 @@ standardize_info <- function(model, robust = FALSE, include_pseudo = FALSE, ...)
       data = data,
       variable = types[types$Parameter == var, ""Variable""],
       type = types[types$Parameter == var, ""Type""],
-      robust = robust
+      robust = robust,
+      two_sd = two_sd
     )
     deviations[i] <- info$sd
     means[i] <- info$mean
@@ -132,11 +133,11 @@ standardize_info <- function(model, robust = FALSE, include_pseudo = FALSE, ...)
 
 
 #' @keywords internal
-.std_info_predictor_smart <- function(data, variable, type, robust = FALSE, ...) {
+.std_info_predictor_smart <- function(data, variable, type, robust = FALSE, two_sd = FALSE, ...) {
   if (type == ""intercept"") {
     info <- list(sd = 0, mean = 0)
   } else if (type == ""numeric"") {
-    info <- .compute_std_info(data = data, variable = variable, robust = robust)
+    info <- .compute_std_info(data = data, variable = variable, robust = robust, two_sd = two_sd)
   } else if (type == ""factor"") {
     info <- list(sd = 1, mean = 0)
 
@@ -152,7 +153,7 @@ standardize_info <- function(model, robust = FALSE, include_pseudo = FALSE, ...)
     # }
   } else if (type %in% c(""interaction"", ""nested"")) {
     if (is.numeric(data[, variable])) {
-      info <- .compute_std_info(data = data, variable = variable, robust = robust)
+      info <- .compute_std_info(data = data, variable = variable, robust = robust, two_sd = two_sd)
     } else if (is.factor(data[, variable])) {
       info <- list(sd = 1, mean = 0)
     } else {
@@ -170,7 +171,7 @@ standardize_info <- function(model, robust = FALSE, include_pseudo = FALSE, ...)
 
 
 #' @keywords internal
-.std_info_predictors_basic <- function(model_matrix, types, robust = FALSE, ...) {
+.std_info_predictors_basic <- function(model_matrix, types, robust = FALSE, two_sd = FALSE, ...) {
 
   # Get deviations for all parameters
   means <- deviations <- rep(NA_real_, length = length(names(model_matrix)))
@@ -179,7 +180,7 @@ standardize_info <- function(model, robust = FALSE, include_pseudo = FALSE, ...)
     if (types[i, ""Type""] == ""intercept"") {
       means[i] <- deviations[i] <- 0
     } else {
-      std_info <- .compute_std_info(data = model_matrix, variable = var, robust = robust)
+      std_info <- .compute_std_info(data = model_matrix, variable = var, robust = robust, two_sd = two_sd)
       deviations[i] <- std_info$sd
       means[i] <- std_info$mean
     }
@@ -268,12 +269,14 @@ standardize_info <- function(model, robust = FALSE, include_pseudo = FALSE, ...)
 #' @importFrom insight clean_names get_random model_info find_formula get_variance get_data
 #' @importFrom parameters check_heterogeneity demean
 #' @importFrom stats as.formula sd
-.std_info_pseudo <- function(model, params, model_matrix, types, robust = FALSE) {
+.std_info_pseudo <- function(model, params, model_matrix, types, robust = FALSE, two_sd = FALSE) {
   if (robust) {
     warning(""'robust' standardization not available for 'pseudo' method."",
             call. = FALSE)
   }
 
+  f <- if (two_sd) 2 else 1
+
   within_vars <- unclass(parameters::check_heterogeneity(model))
   id <- insight::get_random(model)[[1]]
 
@@ -338,11 +341,11 @@ standardize_info <- function(model, robust = FALSE, include_pseudo = FALSE, ...)
     rand_name <- insight::find_random(model)$random
 
     # maintain any y-transformations
-    f <- insight::find_formula(model)
-    f <- paste0(f$conditional[2], "" ~ (1|"",rand_name,"")"")
+    frm <- insight::find_formula(model)
+    frm <- paste0(frm$conditional[2], "" ~ (1|"",rand_name,"")"")
 
     m0 <- suppressWarnings(suppressMessages(
-      lme4::lmer(stats::as.formula(f),
+      lme4::lmer(stats::as.formula(frm),
                  data = insight::get_data(model))
     ))
     m0v <- insight::get_variance(m0)
@@ -368,10 +371,10 @@ standardize_info <- function(model, robust = FALSE, include_pseudo = FALSE, ...)
         X <- tapply(model_matrix[[i]], id, mean)
         Deviation_Response_Pseudo[i] <- sd_y_between
       }
-      Deviation_Pseudo[i] <- stats::sd(X)
+      Deviation_Pseudo[i] <- f * stats::sd(X)
 
       ## smart way?
-      ## DONT USE: see corespondance with between Mattan and Eran BC
+      ## DONT USE: see correspondence with between Mattan and Eran BC
       # m <- suppressWarnings(suppressMessages(lme4::lmer(model_matrix[[i]] ~ (1|id))))
       # if (is_within[i]) {
       #   ## is within
@@ -402,7 +405,8 @@ standardize_info <- function(model, robust = FALSE, include_pseudo = FALSE, ...)
 
 
 #' @keywords internal
-.compute_std_info <- function(data = NULL, variable = NULL, response = NULL, robust = FALSE) {
+.compute_std_info <- function(data = NULL, variable = NULL, response = NULL, robust = FALSE, two_sd = FALSE) {
+  f <- if (two_sd) 2 else 1
   if (is.null(response)) {
     response <- as.numeric(data[, variable])
   }
@@ -415,5 +419,5 @@ standardize_info <- function(model, robust = FALSE, include_pseudo = FALSE, ...)
     mean_x <- stats::median(response, na.rm = TRUE)
   }
 
-  list(sd = sd_x, mean = mean_x)
+  list(sd = f * sd_x, mean = mean_x)
 }

---FILE: R/standardize_parameters.R---
@@ -242,7 +242,7 @@ standardize_parameters.parameters_model <- function(model, method = ""refit"", ci
 
 
   ## Get scaling factors
-  deviations <- standardize_info(model, robust = robust, include_pseudo = method == ""pseudo"")
+  deviations <- standardize_info(model, robust = robust, include_pseudo = method == ""pseudo"", two_sd = two_sd)
   i <- match(deviations$Parameter, pars$Parameter)
   pars <- pars[i,]
 
@@ -263,12 +263,10 @@ standardize_parameters.parameters_model <- function(model, method = ""refit"", ci
   }
 
   # Sapply standardization
-  f <- if (two_sd) 2 else 1
-
   pars[,colnames(pars) %in% .col_2_scale] <- lapply(
     pars[, colnames(pars) %in% .col_2_scale, drop = FALSE],
     function(x) {
-      x * (f * deviations[[col_dev_pred]] / deviations[[col_dev_resp]])
+      x * deviations[[col_dev_pred]] / deviations[[col_dev_resp]]
     }
   )
 
@@ -339,7 +337,7 @@ standardize_posteriors <- function(model, method = ""refit"", robust = FALSE, two_
   }
 
   ## Get scaling factors
-  deviations <- standardize_info(model, robust = robust, include_pseudo = method == ""pseudo"")
+  deviations <- standardize_info(model, robust = robust, include_pseudo = method == ""pseudo"", two_sd = two_sd)
   i <- match(deviations$Parameter, colnames(pars))
   pars <- pars[,i]
 
@@ -360,9 +358,7 @@ standardize_posteriors <- function(model, method = ""refit"", robust = FALSE, two_
   }
 
   # Sapply standardization
-  f <- if (two_sd) 2 else 1
-
-  pars <- t(t(pars) * (f * deviations[[col_dev_pred]] / deviations[[col_dev_resp]]))
+  pars <- t(t(pars) * deviations[[col_dev_pred]] / deviations[[col_dev_resp]])
   pars <- as.data.frame(pars)
 
   attr(pars, ""std_method"") <- method

---FILE: man/standardize.Rd---
@@ -44,7 +44,8 @@ mean and dividing it by the standard deviation (SD).}
 \item{two_sd}{If \code{TRUE}, the variables are scaled by two times the deviation
 (SD or MAD depending on \code{robust}). This method can be useful to obtain
 model coefficients of continuous parameters comparable to coefficients
-related to binary predictors (Gelman, 2008).}
+related to binary predictors, when applied to \strong{the predictors} (not the
+outcome) (Gelman, 2008).}
 
 \item{select}{Character vector of column names. If \code{NULL} (the default), all
 variables will be selected.}

---FILE: man/standardize_info.Rd---
@@ -4,7 +4,13 @@
 \alias{standardize_info}
 \title{Get Standardization Information}
 \usage{
-standardize_info(model, robust = FALSE, include_pseudo = FALSE, ...)
+standardize_info(
+  model,
+  robust = FALSE,
+  two_sd = FALSE,
+  include_pseudo = FALSE,
+  ...
+)
 }
 \arguments{
 \item{model}{A statistical model.}
@@ -14,6 +20,12 @@ median from the variables and dividing it by the median absolute deviation
 (MAD). If \code{FALSE}, variables are standardized by subtracting the
 mean and dividing it by the standard deviation (SD).}
 
+\item{two_sd}{If \code{TRUE}, the variables are scaled by two times the deviation
+(SD or MAD depending on \code{robust}). This method can be useful to obtain
+model coefficients of continuous parameters comparable to coefficients
+related to binary predictors, when applied to \strong{the predictors} (not the
+outcome) (Gelman, 2008).}
+
 \item{include_pseudo}{(For (G)LMMs) Should Pseudo-standardized information be included?}
 
 \item{...}{Arguments passed to or from other methods.}

---FILE: man/standardize_parameters.Rd---
@@ -42,7 +42,8 @@ mean and dividing it by the standard deviation (SD).}
 \item{two_sd}{If \code{TRUE}, the variables are scaled by two times the deviation
 (SD or MAD depending on \code{robust}). This method can be useful to obtain
 model coefficients of continuous parameters comparable to coefficients
-related to binary predictors (Gelman, 2008).}
+related to binary predictors, when applied to \strong{the predictors} (not the
+outcome) (Gelman, 2008).}
 
 \item{verbose}{Toggle warnings on or off.}
 

---FILE: tests/testthat/test-standardize.R---
@@ -1,10 +1,16 @@
 if (require(""testthat"") && require(""effectsize"") && require(""dplyr"") && require(""rlang"")) {
   test_that(""standardize.numeric"", {
     x <- standardize(seq(0, 1, length.out = 100))
-    testthat::expect_equal(mean(0), 0, tol = 0.01)
+    testthat::expect_equal(mean(x), 0, tol = 0.01)
+
+    x <- standardize(seq(0, 1, length.out = 100), two_sd = TRUE)
+    testthat::expect_equal(sd(x), 0.5, tol = 0.01)
 
     x <- standardize(seq(0, 1, length.out = 100), robust = TRUE)
-    testthat::expect_equal(median(0), 0, tol = 0.01)
+    testthat::expect_equal(median(x), 0, tol = 0.01)
+
+    x <- standardize(seq(0, 1, length.out = 100), robust = TRUE, two_sd = TRUE)
+    testthat::expect_equal(mad(x), 0.5, tol = 0.01)
 
     testthat::expect_message(standardize(c(0, 0, 0, 1, 1)))
   })
@@ -73,10 +79,13 @@ if (require(""testthat"") && require(""effectsize"") && require(""dplyr"") && require(
   })
 
   test_that(""standardize.lm"", {
-    model <- standardize(lm(Sepal.Length ~ Species * Petal.Width, data = iris))
-    testthat::expect_equal(unname(coef(model)),
-                           c(0.06, -0.166, 0.19, 0.856, 0.457, -0.257),
-                           tol = 0.01)
+    iris2 <- na.omit(iris)
+    iris_z <- standardize(iris2)
+
+    m0 <- lm(Sepal.Length ~ Species * Petal.Width, data = iris_z)
+    m1 <- lm(Sepal.Length ~ Species * Petal.Width, data = iris2)
+    model <- standardize(m1)
+    testthat::expect_equal(coef(m0), coef(model))
 
     # deal with log / sqrt terms
     testthat::expect_message(standardize(lm(mpg ~ sqrt(cyl) + log(hp), mtcars)))

---FILE: tests/testthat/test-standardize_parameters.R---
@@ -1,8 +1,9 @@
 if (require(""testthat"") && require(""effectsize"")) {
+  data(""iris"")
+  df <- iris
 
   # ""standardize_parameters (simple)"" ---------------------------------------
   test_that(""standardize_parameters (simple)"", {
-    df <- iris
     r <- as.numeric(cor.test(df$Sepal.Length, df$Petal.Length)$estimate)
 
     model <- lm(Sepal.Length ~ Petal.Length, data = df)
@@ -77,6 +78,13 @@ if (require(""testthat"") && require(""effectsize"")) {
       c(0, 0.135, 0.234, 1.073),
       tol = 0.01
     )
+
+
+    m0 <- lm(mpg ~ cyl + factor(am), mtcars)
+    expect_equal(standardize_parameters(m0, method = ""refit"")[[2]][-1],
+                 standardize_parameters(m0, method = ""smart"")[[2]][-1], tol = 0.01)
+    expect_equal(standardize_parameters(m0, method = ""refit"", two_sd = TRUE)[[2]][-1],
+                 standardize_parameters(m0, method = ""smart"", two_sd = TRUE)[[2]][-1], tol = 0.01)
   })
 
 
@@ -119,13 +127,13 @@ if (require(""testthat"") && require(""effectsize"")) {
       )
 
       testthat::expect_equal(
-        suppressWarnings(standardize_parameters(model, method = ""refit"")$Std_Median),
+        suppressWarnings(standardize_parameters(model, method = ""refit"")$Std_Median[1:4]),
         c(0.065, -0.094, -0.100, 0.862),
         tol = 0.01
       )
 
       testthat::expect_equal(
-        suppressWarnings(standardize_parameters(model, method = ""posthoc"")$Std_Median),
+        suppressWarnings(standardize_parameters(model, method = ""posthoc"")$Std_Median[1:4]),
         c(0, -0.058, -0.053,  0.838),
         tol = 0.01
       )",True,False,Documentation / Formatting,6
easystats,effectsize,49d793c31a533cbfea408a98356383c7cee1da78,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-27T07:01:11Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-27T07:01:11Z,fix weights,R/utils_standardize.R;tests/testthat/test-standardize.R,False,True,True,False,17,10,27,"---FILE: R/utils_standardize.R---
@@ -31,18 +31,20 @@
 #' @keywords internal
 #' @importFrom stats weighted.mean
 .mean <- function(x, weights = NULL) {
-  if (is.null(weights) || length(weights) == 0) {
-    mean(x)
-  } else {
-    stats::weighted.mean(x, weights)
+  if (!.are_weights(weights)) {
+    return(mean(x))
   }
+
+  stopifnot(all(weights > 0))
+
+  stats::weighted.mean(x, weights)
 }
 
 #' @keywords internal
 #' @importFrom stats sd
 .sd <- function(x, weights = NULL) {
   # from cov.wt
-  if (is.null(weights) || length(weights) == 0) {
+  if (!.are_weights(weights)) {
     return(stats::sd(x))
   }
 
@@ -61,7 +63,7 @@
 #' @importFrom stats mad
 .mad <- function(x, weights = NULL, constant = 1.4826) {
   # From matrixStats
-  if (is.null(weights) || length(weights) == 0) {
+  if (!.are_weights(weights)) {
     return(stats::mad(x))
   }
   stopifnot(all(weights > 0))
@@ -77,9 +79,10 @@
 #' @importFrom stats median
 .median <- function(x, weights = NULL) {
   # From spatstat + wiki
-  if (is.null(weights) || length(weights) == 0) {
+  if (!.are_weights(weights)) {
     return(stats::median(x))
   }
+
   stopifnot(all(weights > 0))
 
   oo <- order(x)
@@ -98,11 +101,15 @@
 
     if (!(Fx[left-1] < 0.5 && 1-Fx[left] < 0.5)) {
       right <- left + 1
-      y <- x[left]*Fx[left] + x[right]*Fx[right]
+      y <- x[left] * Fx[left] + x[right] * Fx[right]
       if(is.finite(y)) result <- y
     }
   }
 
   return(result)
 }
 
+.are_weights <- function(w) {
+  !is.null(w) && length(w) && !all(w == 1) && !all(w == w[1])
+}
+

---FILE: tests/testthat/test-standardize.R---
@@ -133,11 +133,11 @@ if (require(""testthat"") && require(""effectsize"") && require(""dplyr"") && require(
                  standardize(data.frame(x), weights = w)$x)
 
     # name and vector give same results
-    expect_equal(standardize(mtcars, exclude = ""cyl"", weights = d$cyl),
+    expect_equal(standardize(mtcars, exclude = ""cyl"", weights = mtcars$cyl),
                  standardize(mtcars, weights = ""cyl""))
 
     if (require(dplyr)) {
-      d <- group_by(mtcars, am)
+      d <- dplyr::group_by(mtcars, am)
       expect_warning(standardize(d, weights = d$cyl))
     }
   })",True,False,Implementation / Logic,6
easystats,effectsize,2f495d74b9f56a6bfb00c39edda724ee233b6ff0,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-26T18:28:15Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-26T18:28:15Z,try fixing dataset,DESCRIPTION;R/data.R;man/hardlyworking.Rd,False,True,True,False,1,7,8,"---FILE: DESCRIPTION---
@@ -31,7 +31,6 @@ BugReports: https://github.com/easystats/effectsize/issues/
 Description: Provide utilities to work with indices of effect size and standardized parameters for a wide variety of models (see support list of insight; LÃ¼decke, Waggoner & Makowski (2019) <doi:10.21105/joss.01412>), allowing computation and conversion of indices such as Cohen's d, r, odds, etc.
 License: GPL-3
 Encoding: UTF-8
-LazyData: true
 Depends:
 	R (>= 3.5)
 Imports:

---FILE: R/data.R---
@@ -2,8 +2,6 @@
 #'
 #' A sample (simulated) dataset, used in tests and some examples.
 #'
-#' @usage data(hardlyworking)
-#'
 #' @docType data
 #'
 #' @name hardlyworking
@@ -19,4 +17,4 @@
 #'   \item{seniority}{How many years with the company}
 #' }
 #'
-""hardlyworking""
\ No newline at end of file
+NULL
\ No newline at end of file

---FILE: man/hardlyworking.Rd---
@@ -14,9 +14,6 @@ A data frame with 500 rows and 5 variables:
 \item{seniority}{How many years with the company}
 }
 }
-\usage{
-data(hardlyworking)
-}
 \description{
 A sample (simulated) dataset, used in tests and some examples.
 }",True,False,Documentation / Formatting,6
easystats,effectsize,2dc75310439673d55bf0b375a37eeef6d0355e6a,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-26T10:23:27Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-26T10:23:27Z,try fixing lazydata,R/data.R;man/hardlyworking.Rd,False,True,True,False,2,2,4,"---FILE: R/data.R---
@@ -2,7 +2,7 @@
 #'
 #' A sample (simulated) dataset, used in tests and some examples.
 #'
-#' @usage hardlyworking
+#' @usage data(hardlyworking)
 #'
 #' @docType data
 #'

---FILE: man/hardlyworking.Rd---
@@ -15,7 +15,7 @@ A data frame with 500 rows and 5 variables:
 }
 }
 \usage{
-hardlyworking
+data(hardlyworking)
 }
 \description{
 A sample (simulated) dataset, used in tests and some examples.",True,False,Documentation / Formatting,6
easystats,effectsize,13803e4bbff10765e9d832f0d193720b9998359a,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-24T13:34:34Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-24T13:34:34Z,fix over senstitive check of between-within variation.,NEWS.md;R/standardize_info.R;R/standardize_parameters.R;man/standardize_parameters.Rd,False,True,True,False,15,4,19,"---FILE: NEWS.md---
@@ -14,6 +14,7 @@
 
 ## Bug fixes
 
+- `standardize_info(include_pseudo = TRUE)` / `standardize_parameters(method = ""pseudo"")` are less sensitive in detecting between-group variation of within-group variables.
 - `interpret_oddsratio()` correctly treats extremely small odds the same as treats extremely large ones.
 
 

---FILE: R/standardize_info.R---
@@ -310,16 +310,24 @@ standardize_info <- function(model, robust = FALSE, include_pseudo = FALSE, ...)
   }
 
   ## test ""within""s are fully ""within""
+  # only relevant to numeric predictors that can have variance
   if (any(check_within <- is_within & types == ""numeric"")) {
-    # only relevant to numeric predictors that can have variance
     p_check_within <- params[check_within]
     temp_d <- data.frame(model_matrix[,p_check_within,drop = FALSE])
     colnames(temp_d) <- paste0(""W"",seq_len(ncol(temp_d))) # overwrite because can't deal with "":""
+
     dm <- parameters::demean(cbind(id,temp_d),
                              select = colnames(temp_d),
                              group = ""id"")
     dm <- dm[,paste0(colnames(temp_d), ""_between""), drop = FALSE]
-    also_between <- p_check_within[sapply(dm, function(x) !isTRUE(all.equal(sd(x),0)))]
+
+    has_lvl2_var <- sapply(seq_along(colnames(temp_d)), function (i) {
+      # If more than 1% of the variance in the within-var is between:
+      var(dm[,i]) /
+         var(temp_d[,i])
+    }) > 0.01
+    also_between <- p_check_within[has_lvl2_var]
+
     if (length(also_between)) {
       warning(
         ""The following within-group terms have between-group variance:\n\t"",

---FILE: R/standardize_parameters.R---
@@ -58,7 +58,8 @@
 #' [parameters::demean()]); The outcome (in linear LMMs) is standardized based
 #' on a fitted random-intercept-model, where `sqrt(random-intercept-variance)`
 #' is used for level 2 predictors, and `sqrt(residual-variance)` is used for
-#' level 1 predictors (Hoffman 2015, page 342).
+#' level 1 predictors (Hoffman 2015, page 342). A warning is given when a
+#' within-group varialbe is found to have access between-group variance.
 #'
 #' ## Transformed Variables
 #' When the model's formula contains transformations (e.g. `y ~ exp(X)`) `method

---FILE: man/standardize_parameters.Rd---
@@ -108,7 +108,8 @@ are standardized based on their SD at level of prediction (see also
 \code{\link[parameters:demean]{parameters::demean()}}); The outcome (in linear LMMs) is standardized based
 on a fitted random-intercept-model, where \code{sqrt(random-intercept-variance)}
 is used for level 2 predictors, and \code{sqrt(residual-variance)} is used for
-level 1 predictors (Hoffman 2015, page 342).
+level 1 predictors (Hoffman 2015, page 342). A warning is given when a
+within-group varialbe is found to have access between-group variance.
 }
 }
 ",True,False,Documentation / Formatting,6
easystats,effectsize,9f58faa8566ad1fcb5c687842881dab74a077bb8,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-24T06:16:26Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-24T06:16:26Z,"fix std_info for ZI

#135",R/standardize_info.R;R/standardize_parameters.R,False,True,True,False,30,17,47,"---FILE: R/standardize_info.R---
@@ -16,6 +16,24 @@ standardize_info <- function(model, robust = FALSE, include_pseudo = FALSE, ...)
   model_matrix <- as.data.frame(stats::model.matrix(model))
   data <- insight::get_data(model)
 
+  # Sanity Check for ZI
+  if (insight::model_info(model)$is_zero_inflated) {
+    warning(""Non-refit parameter standardization is ignoring the zero-inflation component."", call. = FALSE)
+
+    # pzi <- sub(""(count|zero)_"", """", params)
+    # match(pzi, names(model_matrix))
+    #
+    # match(names(model_matrix), pzi)
+    #
+    # pzi %in% names(model_matrix)
+    #
+    #
+    #
+    #
+    # names(model_matrix)
+    # params
+  }
+
   out <- data.frame(
     Parameter = params,
     Type = types$Type,
@@ -37,25 +55,29 @@ standardize_info <- function(model, robust = FALSE, include_pseudo = FALSE, ...)
   # Response - Basic
   out <- merge(
     out,
-    .std_info_response_basic(model, params, robust = robust)
+    .std_info_response_basic(model, params, robust = robust),
+    by = ""Parameter"", all = TRUE
   )
 
   # Response - Smart
   out <- merge(
     out,
-    .std_info_response_smart(model, data, model_matrix, types, robust = robust)
+    .std_info_response_smart(model, data, model_matrix, types, robust = robust),
+    by = ""Parameter"", all = TRUE
   )
 
   # Basic
   out <- merge(
     out,
-    .std_info_predictors_basic(model_matrix, types, robust = robust)
+    .std_info_predictors_basic(model_matrix, types, robust = robust),
+    by = ""Parameter"", all = TRUE
   )
 
   # Smart
   out <- merge(
     out,
-    .std_info_predictors_smart(data, params, types, robust = robust)
+    .std_info_predictors_smart(data, params, types, robust = robust),
+    by = ""Parameter"", all = TRUE
   )
 
   # Pseudo (for LMM)
@@ -70,6 +92,7 @@ standardize_info <- function(model, robust = FALSE, include_pseudo = FALSE, ...)
 
   # Reorder
   out <- out[match(params, out$Parameter), ]
+  out$Parameter <- params
   row.names(out) <- NULL
 
   # Remove all means for now (because it's not used)
@@ -165,7 +188,7 @@ standardize_info <- function(model, robust = FALSE, include_pseudo = FALSE, ...)
   means <- deviations <- rep(NA_real_, length = length(names(model_matrix)))
   for (i in seq_along(names(model_matrix))) {
     var <- names(model_matrix)[i]
-    if (types[types$Parameter == var, ""Type""] == ""intercept"") {
+    if (types[i, ""Type""] == ""intercept"") {
       means[i] <- deviations[i] <- 0
     } else {
       std_info <- .compute_std_info(data = model_matrix, variable = var, robust = robust)
@@ -176,7 +199,7 @@ standardize_info <- function(model, robust = FALSE, include_pseudo = FALSE, ...)
 
   # Out
   data.frame(
-    Parameter = names(model_matrix),
+    Parameter = types$Parameter[seq_along(names(model_matrix))],
     Deviation_Basic = deviations,
     Mean_Basic = means
   )
@@ -215,7 +238,7 @@ standardize_info <- function(model, robust = FALSE, include_pseudo = FALSE, ...)
 
   # Out
   data.frame(
-    Parameter = names(model_matrix),
+    Parameter = types$Parameter[seq_along(names(model_matrix))],
     Deviation_Response_Smart = deviations,
     Mean_Response_Smart = means
   )

---FILE: R/standardize_parameters.R---
@@ -221,11 +221,6 @@ standardize_parameters.parameters_model <- function(model, method = ""refit"", ci
 #' @keywords internal
 #' @importFrom insight model_info find_random
 .standardize_parameters_posthoc <- function(pars, method, model, robust, two_sd, verbose) {
-  # Sanity Check for ZI
-  if (verbose && insight::model_info(model)$is_zero_inflated) {
-    warning(""Non-refit parameter standardization is ignoring the zero-inflation component."", call. = FALSE)
-  }
-
   # Sanity Check for ""pseudo""
   if (method == ""pseudo"" &&
       !(insight::model_info(model)$is_mixed &&
@@ -324,11 +319,6 @@ standardize_posteriors <- function(model, method = ""refit"", robust = FALSE, two_
 #' @keywords internal
 #' @importFrom insight model_info find_random
 .standardize_posteriors_posthoc <- function(pars, method, model, robust, two_sd, verbose) {
-  # Sanity Check for ZI
-  if (verbose && insight::model_info(model)$is_zero_inflated) {
-    warning(""Non-refit parameter standardization is ignoring the zero-inflation component."", call. = FALSE)
-  }
-
   # Sanity Check for ""pseudo""
   if (method == ""pseudo"" &&
       !(insight::model_info(model)$is_mixed &&",True,False,Implementation / Logic,6
easystats,effectsize,acf268068654a441022e31c0c48e06a4ce0879fe,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-24T05:36:26Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-24T05:36:26Z,fix dataset (maybe?),R/data.R;man/hardlyworking.Rd,False,True,True,False,9,1,10,"---FILE: R/data.R---
@@ -2,6 +2,14 @@
 #'
 #' A sample (simulated) dataset, used in tests and some examples.
 #'
+#' @usage hardlyworking
+#'
+#' @docType data
+#'
+#' @name hardlyworking
+#'
+#' @keywords data
+#'
 #' @format A data frame with 500 rows and 5 variables:
 #' \describe{
 #'   \item{salary}{Salary, in Shmekels}

---FILE: man/hardlyworking.Rd---
@@ -20,4 +20,4 @@ hardlyworking
 \description{
 A sample (simulated) dataset, used in tests and some examples.
 }
-\keyword{datasets}
+\keyword{data}",True,False,Documentation / Formatting,6
easystats,effectsize,1d8575cce220388916889cafce0960c88a08b46a,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-23T18:49:58Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-23T18:49:58Z,fix center-testing,R/eta_squared_posterior.R,False,True,True,False,2,2,4,"---FILE: R/eta_squared_posterior.R---
@@ -96,7 +96,7 @@ eta_squared_posterior.stanreg <- function(model,
   resp_name <- insight::find_response(model)
 
   # test centered predictors
-  if (verbose) .all_centered(X)
+  .all_centered(X)
 
   ## 2. get ppd
   ppd <- rstantools::posterior_predict(model,
@@ -135,7 +135,7 @@ eta_squared_posterior.brmsfit <- eta_squared_posterior.stanreg
 #' @keywords internal
 #' @importFrom stats contrasts
 .all_centered <- function(X) {
-  numeric <- sapply(X, is, class2 = ""numeric"")
+  numeric <- sapply(X, inherits, what = c(""numeric"",""integer""))
   numerics <- colnames(X)[numeric]
   factors <- colnames(X)[!numeric]
 ",True,False,Documentation / Formatting,3
easystats,effectsize,abfaa9a88c30587a1a2ca6e173f0fe02618ace32,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-22T06:41:12Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-22T06:41:12Z,fix slight printing problems,R/cohens_d.R;R/print.effectsize_difference.R;R/print.effectsize_table.R;R/print.equivalence_test_effectsize.R,False,True,True,False,5,22,27,"---FILE: R/cohens_d.R---
@@ -195,7 +195,7 @@ glass_delta <- function(x, y = NULL, data = NULL, correction = FALSE, ci = 0.95)
       out[, colnames(out) %in% c(types, ""CI_low"", ""CI_high"")] * correction
   }
 
-  class(out) <- c(""effectsize_difference"",""see_effectsize_table"", class(out))
+  class(out) <- c(""effectsize_difference"", ""effectsize_table"", ""see_effectsize_table"", class(out))
   attr(out, ""correction"") <- correction
   attr(out, ""pooled_sd"") <- pooled_sd
   return(out)

---FILE: R/print.effectsize_difference.R---
@@ -21,7 +21,7 @@ print.effectsize_difference <- function(x, digits = 2, append_CL = FALSE, ...) {
   ## Common lang
   if (append_CL && any(colnames(x) %in% c(""Cohens_d"", ""Hedges_g""))) {
     cl <- d_to_common_language(x[[any(colnames(x) %in% c(""Cohens_d"", ""Hedges_g""))]])
-    cl <- sapply(cl, insight::format_value, digits = digits, as_percent = TRUE)
+    cl <- sapply(cl, function(ff) sprintf(""%g%% CI"", round(ff * 100, digits = digits)))
     cl <- paste(paste0(""* "", names(cl),"": "",cl), collapse = ""\n"")
     cat(""\n"")
     insight::print_color(cl, ""cyan"")

---FILE: R/print.effectsize_table.R---
@@ -14,15 +14,14 @@ print.effectsize_table <- function(x, digits = 2, ...){
                                digits = digits,
                                width = ""auto"")
 
-    colnames(x)[colnames(x) == ""CI""] <-
-      paste0(insight::format_value(ci_level, as_percent = TRUE, digits = 0),
-             "" CI"")
+    colnames(x)[colnames(x) == ""CI""] <- sprintf(""%g%% CI"", round(ci_level * 100, digits = digits))
 
     x$CI_low <- x$CI_high <- NULL
   }
 
   cat(insight::format_table(x, digits = digits))
 
+  ## MSB: Move to own printing function?
   if (!is.null(method <- attr(x_orig, ""std_method""))) {
     method <- paste0(toupper(substr(method, 1L, 1L)), substr(method, 2L, nchar(method)))
     insight::print_color(color = ""blue"", paste0(""\n# Standardization method: "", method, ""\n""))

---FILE: R/print.equivalence_test_effectsize.R---
@@ -18,23 +18,7 @@ print.equivalence_test_effectsize <- function(x, digits = 2, ...) {
   ## ROPE_Equivalence
   colnames(x)[colnames(x) == ""ROPE_Equivalence""] <- ""H0""
 
-  ## CI
-  ci_level <- x$CI[1]
-  x$CI <- insight::format_ci(
-    x$CI_low,
-    x$CI_high,
-    ci = NULL,
-    digits = digits,
-    width = ""auto""
-  )
-  colnames(x)[colnames(x) == ""CI""] <-
-    paste0(insight::format_value(ci_level, as_percent = TRUE, digits = 0),
-           "" CI"")
-  x$CI_low <- x$CI_high <- NULL
-
-  # print
-  cat(insight::format_table(x, digits = digits))
-
+  print.effectsize_table(x)
 
   if (attr(x, ""rule"", exact = TRUE) == ""bayes"") {
     insight::print_color(""\n(Using Bayesian guidlines)\n\n"", ""green"")",True,False,Implementation / Logic,6
easystats,effectsize,646b9340af138ad5bced4a97004bc5d0b49c4e16,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-21T19:58:10Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-21T19:58:10Z,minor fixes,R/eta_squared_posterior.R;R/standardize_parameters.R;man/eta_squared_posterior.Rd,False,True,True,False,27,19,46,"---FILE: R/eta_squared_posterior.R---
@@ -18,7 +18,7 @@
 #' @param draws An integer indicating the number of draws from the posterior
 #'   predictive distribution to return. Larger numbers take longer to run, but
 #'   provide estimates that are more stable.
-#' @param verbose Show messages.
+#' @param verbose Show messages / warning about centering.
 #' @param ... Currently not used.
 #'
 #' @return A data frame containing the ppd of the Eta squared for each fixed
@@ -90,18 +90,18 @@ eta_squared_posterior.stanreg <- function(model,
     # Too hard right now.
   }
 
-  ## 1. get ppd
-  ppd <- rstantools::posterior_predict(model,
-                                       draws = draws, # for rstanreg
-                                       nsamples = draws) # for brms
-
-  ## 2. get model data
+  ## 1. get model data
   f <- insight::find_formula(model)$conditional
   X <- insight::get_predictors(model)
   resp_name <- insight::find_response(model)
 
   # test centered predictors
-  .all_centered(X)
+  if (verbose) .all_centered(X)
+
+  ## 2. get ppd
+  ppd <- rstantools::posterior_predict(model,
+                                       draws = draws, # for rstanreg
+                                       nsamples = draws) # for brms
 
   ## 3. Compute effect size...
   if (verbose) {
@@ -135,26 +135,34 @@ eta_squared_posterior.brmsfit <- eta_squared_posterior.stanreg
 #' @keywords internal
 #' @importFrom stats contrasts
 .all_centered <- function(X) {
-  numeric <- sapply(X, class) == ""numeric""
+  numeric <- sapply(X, is, class2 = ""numeric"")
   numerics <- colnames(X)[numeric]
   factors <- colnames(X)[!numeric]
 
+  numerics_centered <- factors_centered <- logical(0)
+
+  if (length(numerics)) {
+    numerics_centered <- sapply(X[, numerics, drop = FALSE],
+                                function(xi) isTRUE(all.equal(mean(xi),0)))
+  }
+
+  if (length(factors)) {
+    # if a contrast has negative and positive values, it is assumed to be one of:
+    # ""contr.sum"", ""contr.helmert"", ""contr.poly"", ""contr.bayes""
+    factors_centered <- sapply(X[, factors, drop = FALSE],
+                               function (xi) any(contrasts(xi) < 0) & any(contrasts(xi) > 0))
+  }
 
-  numerics_centered <- sapply(X[, numerics, drop = FALSE],
-                              function(xi) isTRUE(all.equal(mean(xi),0)))
 
-  # if a contrast has negative and positive values, it is assumed to be one of:
-  # ""contr.sum"", ""contr.helmert"", ""contr.poly"", ""contr.bayes""
-  factors_centered <- sapply(X[, factors, drop = FALSE],
-                             function (xi) any(contrasts(xi) < 0) & any(contrasts(xi) > 0))
+  if ((length(numerics_centered) && !all(numerics_centered)) ||
+      length(factors_centered) && !all(factors_centered)) {
 
-  if (!all(c(numerics_centered,factors_centered))) {
     non_centered <- !c(numerics_centered,factors_centered)
     non_centered <- names(non_centered)[non_centered]
     warning(
       ""Not all variables are centered:\n "",
       paste(non_centered,collapse = "", ""),
-      ""\n Results might be bogus..."",
+      ""\n Results might be bogus if involved in interactions..."",
       call. = FALSE, immediate. = TRUE
     )
   }

---FILE: R/standardize_parameters.R---
@@ -284,7 +284,7 @@ standardize_parameters.parameters_model <- function(model, method = ""refit"", ci
 }
 
 #' @keywords internal
-.col_2_scale <- c(""Coefficient"",""Median"", ""Mean"", ""SE"", ""CI_low"", ""CI_high"")
+.col_2_scale <- c(""Coefficient"",""Median"", ""Mean"", ""MAP"", ""SE"", ""CI_low"", ""CI_high"")
 
 
 # standardize_posteriors --------------------------------------------------

---FILE: man/eta_squared_posterior.Rd---
@@ -24,7 +24,7 @@ eta_squared_posterior(
 predictive distribution to return. Larger numbers take longer to run, but
 provide estimates that are more stable.}
 
-\item{verbose}{Show messages.}
+\item{verbose}{Show messages / warning about centering.}
 
 \item{...}{Currently not used.}
 }",True,False,Documentation / Formatting,6
easystats,effectsize,9fb3c04cb83bb9b7afbbdfe5e112043ec10a8ec4,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-21T10:29:30Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-21T10:29:30Z,CI fix,NAMESPACE;NEWS.md;R/interpret_oddsratio.R;R/print.rules.R;_pkgdown.yml;man/interpret_oddsratio.Rd;tests/testthat/test-interpret.R,False,True,True,False,9,4,13,"---FILE: NAMESPACE---
@@ -203,3 +203,4 @@ importFrom(stats,update)
 importFrom(stats,var)
 importFrom(utils,capture.output)
 importFrom(utils,head)
+importFrom(utils,tail)

---FILE: NEWS.md---
@@ -13,7 +13,7 @@
 
 ## Bug fixes
 
-- `interpret_odds()` correctly treats extremely small odds the same as treats extremely large ones.
+- `interpret_oddsratio()` correctly treats extremely small odds the same as treats extremely large ones.
 
 
 # effectsize 0.3.3
@@ -26,6 +26,7 @@
 ## Changes
 
 - `r_to_odds()` family is now deprecated in favor of `r_to_oddsratio()`.
+- `interpret_odds()` is now deprecated in favor of `interpret_oddsratio()`
 
 ## Bug fixes
 

---FILE: R/interpret_oddsratio.R---
@@ -23,6 +23,8 @@
 #' interpret_oddsratio(1)
 #' interpret_oddsratio(c(5, 2))
 #'
+#' @aliases interpret_odds
+#'
 #' @references
 #' - Cohen, J. (1988). Statistical power analysis for the behavioural sciences.
 #' - Chen, H., Cohen, P., & Chen, S. (2010). How big is a big odds ratio? Interpreting the magnitudes of odds ratios in epidemiological studies. Communications in StatisticsâSimulation and Computation, 39(4), 860-864.

---FILE: R/print.rules.R---
@@ -1,4 +1,4 @@
-#' @importFrom utils head
+#' @importFrom utils head tail
 #' @export
 print.rules <- function(x, ...){
   orig_x <- x

---FILE: _pkgdown.yml---
@@ -52,7 +52,7 @@ reference:
   - interpret_r
   - interpret_omega_squared
   - interpret_parameters
-  - interpret_odds
+  - interpret_oddsratio
   - interpret_r2
   - interpret_gfi
   - interpret_p

---FILE: man/interpret_oddsratio.Rd---
@@ -2,6 +2,7 @@
 % Please edit documentation in R/interpret_oddsratio.R
 \name{interpret_oddsratio}
 \alias{interpret_oddsratio}
+\alias{interpret_odds}
 \title{Interpret Odds ratio}
 \usage{
 interpret_oddsratio(OR, rules = ""chen2010"", log = FALSE)

---FILE: tests/testthat/test-interpret.R---
@@ -54,7 +54,7 @@ if (require(""testthat"") && require(""effectsize"")) {
   })
 
 
-  test_that(""interpret_odds"", {
+  test_that(""interpret_oddsratio"", {
     testthat::expect_equal(interpret_oddsratio(2), ""small"")
     testthat::expect_equal(interpret_oddsratio(c(1, 3)), c(""very small"", ""small""))
     testthat::expect_equal(interpret_oddsratio(c(1, 3), rules = ""cohen1988""), c(""very small"", ""medium""))",True,False,Documentation / Formatting,6
easystats,effectsize,cfd33377117b3d52ad68a6649f8033734ba12d10,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-18T13:18:56Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-18T13:18:56Z,fix interp_d,R/interpret_d.R;man/interpret_d.Rd;tests/testthat/test-interpret.R,False,True,True,False,7,7,14,"---FILE: R/interpret_d.R---
@@ -29,19 +29,19 @@ interpret_d <- function(d, rules = ""cohen1988"") {
     } else if (rules == ""sawilowsky2009"") {
       return(interpret(abs(d), rules(c(0.1, 0.2, 0.5, 0.8, 1.2, 2), c(""tiny"", ""very small"", ""small"", ""medium"", ""large"", ""very large"", ""huge""))))
     } else {
-      stop(""rules must be 'funder2019', 'gignac2016','cohen1988', 'sawilowsky2009' or an object of type rules."")
+      stop(""rules must be 'gignac2016','cohen1988', 'sawilowsky2009' or an object of type rules."")
     }
   }
 }
 
 #' @rdname interpret_d
 #' @export
-interpret_g <- function(g, rules = ""funder2019"") {
+interpret_g <- function(g, rules = ""cohen1988"") {
   interpret_d(g, rules)
 }
 
 #' @rdname interpret_d
 #' @export
-interpret_delta <- function(delta, rules = ""funder2019"") {
+interpret_delta <- function(delta, rules = ""cohen1988"") {
   interpret_d(delta, rules)
 }

---FILE: man/interpret_d.Rd---
@@ -8,9 +8,9 @@
 \usage{
 interpret_d(d, rules = ""cohen1988"")
 
-interpret_g(g, rules = ""funder2019"")
+interpret_g(g, rules = ""cohen1988"")
 
-interpret_delta(delta, rules = ""funder2019"")
+interpret_delta(delta, rules = ""cohen1988"")
 }
 \arguments{
 \item{d, g, delta}{Value or vector of effect size values.}

---FILE: tests/testthat/test-interpret.R---
@@ -36,9 +36,9 @@ if (require(""testthat"") && require(""effectsize"")) {
 
 
   test_that(""interpret_d"", {
-    testthat::expect_equal(interpret_d(0.021), ""tiny"")
+    testthat::expect_equal(interpret_d(0.021), ""very small"")
     testthat::expect_equal(interpret_d(1.3, rules = ""sawilowsky2009""), ""very large"")
-    testthat::expect_equal(interpret_d(c(0.45, 0.85)), c(""medium"", ""large""), rules = ""cohen1988"")
+    testthat::expect_equal(interpret_d(c(0.45, 0.85), rules = ""cohen1988""), c(""small"", ""large""))
     testthat::expect_equal(interpret_d(0.6, rules = rules(c(0.5), c(""A"", ""B""))), ""B"")
     testthat::expect_error(interpret_d(0.6, rules = ""DUPA""))
   })",True,False,Documentation / Formatting,6
easystats,effectsize,35657233db60abcff69cd04b2436701c9aa7030c,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-18T11:12:59Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-18T11:12:59Z,"Remove Funder (2019) from interpret_d

https://github.com/easystats/report/issues/81",R/interpret_d.R;man/interpret_d.Rd;vignettes/interpret.Rmd,True,True,True,False,12,25,37,"---FILE: R/interpret_d.R---
@@ -4,7 +4,7 @@
 #'
 #'
 #' @param d,g,delta Value or vector of effect size values.
-#' @param rules Can be `""funder2019""` (default), `""gignac2016""`, `""cohen1988""`, `""sawilowsky2009""` or custom set of [rules()].
+#' @param rules Can be `""cohen1988""` (default), `""gignac2016""`, `""sawilowsky2009""` or custom set of [rules()].
 #'
 #'
 #'
@@ -13,19 +13,16 @@
 #' interpret_d(c(.5, .02))
 #'
 #' @references
-#' - Funder, D. C., & Ozer, D. J. (2019). Evaluating effect size in psychological research: sense and nonsense. Advances in Methods and Practices in Psychological Science.
 #' - Gignac, G. E., & Szodorai, E. T. (2016). Effect size guidelines for individual differences researchers. Personality and individual differences, 102, 74-78.
 #' - Cohen, J. (1988). Statistical power analysis for the behavioural sciences.
 #' - Sawilowsky, S. S. (2009). New effect size rules of thumb.
 #'
 #' @export
-interpret_d <- function(d, rules = ""funder2019"") {
+interpret_d <- function(d, rules = ""cohen1988"") {
   if (is.rules(rules)) {
     return(interpret(abs(d), rules))
   } else {
-    if (rules == ""funder2019"") {
-      return(interpret(d_to_r(abs(d)), rules(c(0.05, 0.1, 0.2, 0.3, 0.4), c(""tiny"", ""very small"", ""small"", ""medium"", ""large"", ""very large""))))
-    } else if (rules == ""gignac2016"") {
+    if (rules == ""gignac2016"") {
       return(interpret(abs(d), rules(c(0.2, 0.4, 0.6), c(""very small"", ""small"", ""medium"", ""large""))))
     } else if (rules == ""cohen1988"") {
       return(interpret(abs(d), rules(c(0.2, 0.5, 0.8), c(""very small"", ""small"", ""medium"", ""large""))))

---FILE: man/interpret_d.Rd---
@@ -6,7 +6,7 @@
 \alias{interpret_delta}
 \title{Interpret standardized differences}
 \usage{
-interpret_d(d, rules = ""funder2019"")
+interpret_d(d, rules = ""cohen1988"")
 
 interpret_g(g, rules = ""funder2019"")
 
@@ -15,7 +15,7 @@ interpret_delta(delta, rules = ""funder2019"")
 \arguments{
 \item{d, g, delta}{Value or vector of effect size values.}
 
-\item{rules}{Can be \code{""funder2019""} (default), \code{""gignac2016""}, \code{""cohen1988""}, \code{""sawilowsky2009""} or custom set of \code{\link[=rules]{rules()}}.}
+\item{rules}{Can be \code{""cohen1988""} (default), \code{""gignac2016""}, \code{""sawilowsky2009""} or custom set of \code{\link[=rules]{rules()}}.}
 }
 \description{
 Interpretation of standardized differences using different sets of rules of thumb.
@@ -27,7 +27,6 @@ interpret_d(c(.5, .02))
 }
 \references{
 \itemize{
-\item Funder, D. C., & Ozer, D. J. (2019). Evaluating effect size in psychological research: sense and nonsense. Advances in Methods and Practices in Psychological Science.
 \item Gignac, G. E., & Szodorai, E. T. (2016). Effect size guidelines for individual differences researchers. Personality and individual differences, 102, 74-78.
 \item Cohen, J. (1988). Statistical power analysis for the behavioural sciences.
 \item Sawilowsky, S. S. (2009). New effect size rules of thumb.

---FILE: vignettes/interpret.Rmd---
@@ -159,15 +159,16 @@ interpret_r(x, rules = ""evans1996"")
 
 The sandardized difference can be obtained through the standardization of linear model's parameters or data, in which they can be used as indices of effect size.
 
+#### @cohen1988statistical
+
 ```r
-interpret_d(x, rules = ""funder2019"")
+interpret_d(x, rules = ""cohen1988"")
 ```
 
-- **r = 0 - 0.1**: Very small
-- **r = 0.1 - 0.2**: Small
-- **r = 0.2 - 0.4**: Medium 
-- **r = 0.4 - 0.6**: Large
-- **r > 0.6**: Very large
+- **d = 0 - 0.2**: Very small
+- **d = 0.2 - 0.5**: Small
+- **d = 0.5 - 0.8**: Medium
+- **d > 0.8**: Large
 
 #### @gignac2016effect
 
@@ -183,16 +184,6 @@ interpret_d(x, rules = ""gignac2016"")
 - **d > 0.6**: Large
 
 
-#### @cohen1988statistical
-
-```r
-interpret_d(x, rules = ""cohen1988"")
-```
-
-- **d = 0 - 0.2**: Very small
-- **d = 0.2 - 0.5**: Small
-- **d = 0.5 - 0.8**: Medium
-- **d > 0.8**: Large
 
 #### @sawilowsky2009new
 ",True,True,Documentation / Formatting,6
easystats,effectsize,4b8d8f72aa96fdfc30f9deddec4cee09f9cc031c,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-18T10:52:32Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-18T10:52:32Z,"standardize for model parameters

https://github.com/easystats/effectsize/issues/129

https://github.com/easystats/parameters/issues/301",NAMESPACE;R/standardize_parameters.R;R/utils_standardize_parameters.R;tests/testthat/test-standardize_parameters.R,False,True,True,False,156,59,215,"---FILE: NAMESPACE---
@@ -48,6 +48,8 @@ S3method(standardize,mlm)
 S3method(standardize,numeric)
 S3method(standardize,wbgee)
 S3method(standardize,wbm)
+S3method(standardize_parameters,default)
+S3method(standardize_parameters,parameters_model)
 export(F_to_d)
 export(F_to_epsilon2)
 export(F_to_eta2)

---FILE: R/standardize_parameters.R---
@@ -127,8 +127,6 @@
 #' - Neter, J., Wasserman, W., & Kutner, M. H. (1989). Applied linear regression models.
 #' - Gelman, A. (2008). Scaling regression inputs by dividing by two standard deviations. Statistics in medicine, 27(15), 2865-2873.
 #'
-#' @importFrom parameters model_parameters
-#' @importFrom insight model_info find_random
 #' @export
 standardize_parameters <- function(model, method = ""refit"", ci = 0.95, robust = FALSE, two_sd = FALSE, verbose = TRUE, parameters, ...) {
   if (!missing(parameters)) {
@@ -138,76 +136,70 @@ standardize_parameters <- function(model, method = ""refit"", ci = 0.95, robust =
     )
   }
 
+  UseMethod(""standardize_parameters"")
+}
+
+#' @importFrom parameters model_parameters
+#' @export
+standardize_parameters.default <- function(model, method = ""refit"", ci = 0.95, robust = FALSE, two_sd = FALSE, verbose = TRUE, parameters, ...) {
   object_name <- deparse(substitute(model), width.cutoff = 500)
-  scale_cols <- c(""Coefficient"",""Median"", ""Mean"", ""SE"", ""CI_low"", ""CI_high"")
 
   if (method == ""refit"") {
     model <- standardize(model, robust = robust, two_sd = two_sd, verbose = verbose)
   }
 
   pars <- parameters::model_parameters(model, ci = ci, standardize = NULL, ...)
-  pars$CI <- attr(pars, ""ci"")
-  pars <- pars[,colnames(pars) %in% c(""Parameter"", ""CI"", scale_cols)]
-
 
   if (method %in% c(""posthoc"", ""smart"", ""basic"", ""classic"", ""pseudo"")) {
-    # Sanity Check for ZI
-    if (verbose && insight::model_info(model)$is_zero_inflated) {
-      warning(""Non-refit parameter standardization is ignoring the zero-inflation component."", call. = FALSE)
-    }
+    pars <- .standardize_parameters_posthoc(pars, method, model, robust, two_sd, verbose)
 
-    # Sanity Check for ZI ""pseudo""
-    if (method == ""pseudo"" &&
-        !(insight::model_info(model)$is_mixed &&
-          length(insight::find_random(model)$random) == 1)) {
-      warning(
-        ""'pseudo' method only available for 2-level (G)LMMs.\n"",
-        ""Setting method to 'basic'."",
-        call. = FALSE
-      )
-      method <- ""basic""
-    }
-
-    if (robust && method == ""pseudo"") {
-      warning(""'robust' standardization not available for 'pseudo' method."",
-              call. = FALSE)
-      robust <- FALSE
-    }
+    method <- attr(pars, ""std_method"")
+    robust <- attr(pars, ""robust"")
+  }
 
+  ## clean cols
+  if (!is.null(ci)) pars$CI <- attr(pars, ""ci"")
+  pars <- pars[,colnames(pars) %in% c(""Parameter"", ""CI"", .col_2_scale)]
+  i <- colnames(pars) %in% c(""Coefficient"", ""Median"", ""Mean"", ""MAP"")
+  colnames(pars)[i] <- paste0(""Std_"", colnames(pars)[i])
 
-    ## Get scaling factors
-    deviations <- standardize_info(model, robust = robust, include_pseudo = method == ""pseudo"")
-    i <- match(deviations$Parameter, pars$Parameter)
-    pars <- pars[i,]
+  ## SE attribute?
+  if (""SE"" %in% colnames(pars)) {
+    attr(pars, ""standard_error"") <- pars$SE
+    pars$SE <- NULL
+  }
 
-    if (method == ""basic"") {
-      col_dev_resp <- ""Deviation_Response_Basic""
-      col_dev_pred <- ""Deviation_Basic""
-    } else if (method == ""posthoc"") {
-      col_dev_resp <- ""Deviation_Response_Basic""
-      col_dev_pred <- ""Deviation_Smart""
-    } else if (method == ""smart"") {
-      col_dev_resp <- ""Deviation_Response_Smart""
-      col_dev_pred <- ""Deviation_Smart""
-    } else if (method == ""pseudo"") {
-      col_dev_resp <- ""Deviation_Response_Pseudo""
-      col_dev_pred <- ""Deviation_Pseudo""
-    } else {
-      stop(""'method' must be one of 'basic', 'posthoc', 'smart' or 'pseudo'."")
-    }
+  ## attributes
+  attr(pars, ""std_method"") <- method
+  attr(pars, ""two_sd"") <- two_sd
+  attr(pars, ""robust"") <- robust
+  attr(pars, ""object_name"") <- object_name
+  class(pars) <- c(""effectsize_table"", ""see_effectsize_table"", ""effectsize_std_params"", ""data.frame"")
+  return(pars)
+}
 
-    # Sapply standardization
-    f <- if (two_sd) 2 else 1
+#' @export
+standardize_parameters.parameters_model <- function(model, method = ""refit"", ci = NULL, robust = FALSE, two_sd = FALSE, verbose = TRUE, parameters, ...) {
+  if (method == ""refit"") {
+    stop(""Method 'refit' not supported for 'model_parameters()"", call. = TRUE)
+  }
 
-    pars[,colnames(pars) %in% scale_cols] <- lapply(
-      pars[, colnames(pars) %in% scale_cols, drop = FALSE],
-      function(x) {
-        x * (f * deviations[[col_dev_pred]] / deviations[[col_dev_resp]])
-      }
-    )
+  if (!is.null(ci)) {
+    stop(""Method 'ci' argument not supported for 'model_parameters()"", call. = TRUE)
   }
 
-  ## clean names
+  pars <- model
+  ci <- attr(pars, ""ci"")
+  obj_name <- attr(pars, ""obj_name"")
+  model <- .get_object(model)
+
+  pars <- .standardize_parameters_posthoc(pars, method, model, robust, two_sd, verbose)
+  method <- attr(pars, ""std_method"")
+  robust <- attr(pars, ""robust"")
+
+  ## clean cols
+  if (""CI_low"" %in% colnames(pars)) pars$CI <- ci
+  pars <- pars[,colnames(pars) %in% c(""Parameter"", ""CI"", .col_2_scale)]
   i <- colnames(pars) %in% c(""Coefficient"", ""Median"", ""Mean"", ""MAP"")
   colnames(pars)[i] <- paste0(""Std_"", colnames(pars)[i])
 
@@ -218,14 +210,81 @@ standardize_parameters <- function(model, method = ""refit"", ci = 0.95, robust =
   }
 
   ## attributes
+  attr(pars, ""two_sd"") <- two_sd
   attr(pars, ""std_method"") <- method
   attr(pars, ""two_sd"") <- two_sd
   attr(pars, ""robust"") <- robust
-  attr(pars, ""object_name"") <- object_name
-  class(pars) <- c(""effectsize_table"", ""see_effectsize_table"", class(pars))
+  class(pars) <- c(""effectsize_table"", ""see_effectsize_table"", ""effectsize_std_params"", ""data.frame"")
+  return(pars)
+}
+
+#' @keywords internal
+#' @importFrom insight model_info find_random
+.standardize_parameters_posthoc <- function(pars, method, model, robust, two_sd, verbose) {
+  # Sanity Check for ZI
+  if (verbose && insight::model_info(model)$is_zero_inflated) {
+    warning(""Non-refit parameter standardization is ignoring the zero-inflation component."", call. = FALSE)
+  }
+
+  # Sanity Check for ZI ""pseudo""
+  if (method == ""pseudo"" &&
+      !(insight::model_info(model)$is_mixed &&
+        length(insight::find_random(model)$random) == 1)) {
+    warning(
+      ""'pseudo' method only available for 2-level (G)LMMs.\n"",
+      ""Setting method to 'basic'."",
+      call. = FALSE
+    )
+    method <- ""basic""
+  }
+
+  if (robust && method == ""pseudo"") {
+    warning(""'robust' standardization not available for 'pseudo' method."",
+            call. = FALSE)
+    robust <- FALSE
+  }
+
+
+  ## Get scaling factors
+  deviations <- standardize_info(model, robust = robust, include_pseudo = method == ""pseudo"")
+  i <- match(deviations$Parameter, pars$Parameter)
+  pars <- pars[i,]
+
+  if (method == ""basic"") {
+    col_dev_resp <- ""Deviation_Response_Basic""
+    col_dev_pred <- ""Deviation_Basic""
+  } else if (method == ""posthoc"") {
+    col_dev_resp <- ""Deviation_Response_Basic""
+    col_dev_pred <- ""Deviation_Smart""
+  } else if (method == ""smart"") {
+    col_dev_resp <- ""Deviation_Response_Smart""
+    col_dev_pred <- ""Deviation_Smart""
+  } else if (method == ""pseudo"") {
+    col_dev_resp <- ""Deviation_Response_Pseudo""
+    col_dev_pred <- ""Deviation_Pseudo""
+  } else {
+    stop(""'method' must be one of 'basic', 'posthoc', 'smart' or 'pseudo'."")
+  }
+
+  # Sapply standardization
+  f <- if (two_sd) 2 else 1
+
+  pars[,colnames(pars) %in% .col_2_scale] <- lapply(
+    pars[, colnames(pars) %in% .col_2_scale, drop = FALSE],
+    function(x) {
+      x * (f * deviations[[col_dev_pred]] / deviations[[col_dev_resp]])
+    }
+  )
+
+  attr(pars, ""std_method"") <- method
+  attr(pars, ""two_sd"") <- two_sd
+  attr(pars, ""robust"") <- robust
+
   return(pars)
 }
 
+#' @keywords internal
+.col_2_scale <- c(""Coefficient"",""Median"", ""Mean"", ""SE"", ""CI_low"", ""CI_high"")
 
 
 #' # OLD ---------------------------------------------------------------------

---FILE: R/utils_standardize_parameters.R---
@@ -0,0 +1,22 @@
+#' @keywords internal
+.get_object <- function(x, attribute_name = ""object_name"") {
+  obj_name <- attr(x, attribute_name, exact = TRUE)
+  model <- NULL
+  if (!is.null(obj_name)) {
+    model <- tryCatch({
+      get(obj_name, envir = parent.frame())
+    }, error = function(e) {
+      NULL
+    })
+    if (is.null(model) ||
+        # prevent self reference
+        inherits(model, ""parameters_model"")) {
+      model <- tryCatch({
+        get(obj_name, envir = globalenv())
+      }, error = function(e) {
+        NULL
+      })
+    }
+  }
+  model
+}

---FILE: tests/testthat/test-standardize_parameters.R---
@@ -4,8 +4,22 @@ if (require(""testthat"") && require(""effectsize"")) {
     r <- as.numeric(cor.test(df$Sepal.Length, df$Petal.Length)$estimate)
 
     model <- lm(Sepal.Length ~ Petal.Length, data = df)
-    es <- standardize_parameters(model)[2, 2]
-    testthat::expect_equal(es, r, tol = 0.01)
+    es <- standardize_parameters(model)
+    testthat::expect_equal(es[2,2], r, tol = 0.01)
+  })
+
+
+  test_that(""standardize_parameters (model_parameters)"", {
+    model <- lm(mpg ~ cyl + am, data = mtcars)
+    mp <- parameters::model_parameters(model)
+
+    s1 <- standardize_parameters(model, method = ""basic"")
+    s2 <- standardize_parameters(mp, method = ""basic"")
+
+    testthat::expect_equal(s1$Parameter, s2$Parameter)
+    testthat::expect_equal(s1$Std_Coefficient, s2$Std_Coefficient)
+    testthat::expect_equal(s1$CI_low, s2$CI_low)
+    testthat::expect_equal(s1$CI_high, s2$CI_high)
   })
 
   test_that(""standardize_parameters (lm with ci)"", {",True,False,Dependency / Package,6
easystats,effectsize,74bb2ba646d4d94ed79ac49f12f87ccf735aa862,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-17T07:12:48Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-17T07:12:48Z,fix urls,DESCRIPTION,False,False,False,False,2,2,4,"---FILE: DESCRIPTION---
@@ -26,8 +26,8 @@ Authors@R: c(
 		role = c(""ctb""))
 	)
 Maintainer: Mattan S. Ben-Shachar <matanshm@post.bgu.ac.il>
-URL: https://easystats.github.io/effectsize
-BugReports: https://github.com/easystats/effectsize/issues
+URL: https://easystats.github.io/effectsize/
+BugReports: https://github.com/easystats/effectsize/issues/
 Description: Provide utilities to work with indices of effect size and standardized parameters for a wide variety of models (see support list of insight; LÃ¼decke, Waggoner & Makowski (2019) <doi:10.21105/joss.01412>), allowing computation and conversion of indices such as Cohen's d, r, odds, etc.
 License: GPL-3
 Encoding: UTF-8",False,False,Dependency / Package,6
easystats,effectsize,f9d24f1f11778b0c3563e81e326147fc6505e5b2,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-15T15:21:34Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-15T15:21:34Z,fix #123,NEWS.md;R/convert_odds_to_d.R;R/convert_odds_to_probs.R;tests/testthat/test-convert.R,False,True,True,False,43,50,93,"---FILE: NEWS.md---
@@ -9,6 +9,7 @@
 
 - `phi()` and `cramers_v()` did not respect the CI argument ( #111 ).
 - `standardize()` / `standardize_parameters()` properly deal with transformed data in the model formula ( #113 ).
+- `odds_to_probs()` was mis-treating impossible odds (NEVER TELL ME THE ODDS! #123 )
 
 # effectsize 0.3.2
 

---FILE: R/convert_odds_to_d.R---
@@ -21,7 +21,9 @@ convert_odds_to_d <- odds_to_d
 
 #' @rdname d_to_r
 #' @export
-logodds_to_d <- function(odds, log = TRUE, ...) odds_to_d(odds, log = log, ...)
+logodds_to_d <- function(odds, log = TRUE, ...) {
+  odds_to_d(odds, log = log, ...)
+}
 
 
 
@@ -47,7 +49,7 @@ convert_d_to_odds <- d_to_odds
 #' @rdname d_to_r
 #' @export
 odds_to_r <- function(odds, log = FALSE, ...) {
-  d_to_r(convert_odds_to_d(odds, log = log))
+  d_to_r(odds_to_d(odds, log = log))
 }
 
 #' @rdname d_to_r
@@ -56,14 +58,16 @@ convert_odds_to_r <- odds_to_r
 
 #' @rdname d_to_r
 #' @export
-logodds_to_r <- function(odds, log = TRUE, ...) odds_to_r(odds, log = log, ...)
+logodds_to_r <- function(odds, log = TRUE, ...) {
+  odds_to_r(odds, log = log, ...)
+}
 
 
 
 #' @rdname d_to_r
 #' @export
 r_to_odds <- function(r, log = FALSE, ...) {
-  d_to_odds(convert_r_to_d(r), log = log)
+  d_to_odds(r_to_d(r), log = log)
 }
 
 #' @rdname d_to_r

---FILE: R/convert_odds_to_probs.R---
@@ -5,15 +5,15 @@ odds_to_probs <- function(odds, log = FALSE, ...) {
 }
 
 #' @export
+#' @importFrom stats plogis
 odds_to_probs.numeric <- function(odds, log = FALSE, ...) {
-  .odds_to_probs(odds, log = log)
+  if (log) {
+    stats::plogis(odds)
+  } else {
+    stats::plogis(log(odds))
+  }
 }
 
-#' @export
-odds_to_probs.double <- odds_to_probs.numeric
-
-
-
 
 #' @rdname d_to_r
 #' @export
@@ -29,13 +29,15 @@ probs_to_odds <- function(probs, log = FALSE, ...) {
 }
 
 #' @export
+#' @importFrom stats qlogis
 probs_to_odds.numeric <- function(probs, log = FALSE, ...) {
-  .probs_to_odds(probs, log = log)
+  if (log) {
+    stats::qlogis(probs)
+  } else {
+    exp(stats::qlogis(probs))
+  }
 }
 
-#' @export
-probs_to_odds.double <- probs_to_odds.numeric
-
 #' @export
 probs_to_odds.data.frame <- function(probs, log = FALSE, select = NULL, exclude = NULL, ...) {
   .odds_to_probs_df(probs = probs, log = log, select = select, exclude = exclude, ...)
@@ -108,9 +110,9 @@ convert_probs_to_odds <- probs_to_odds
 
   # Tranform
   if (!is.null(odds)) {
-    dfnum <- .odds_to_probs(dfnum, log = log)
+    dfnum <- data.frame(lapply(dfnum, odds_to_probs.numeric, log = log))
   } else {
-    dfnum <- .probs_to_odds(dfnum, log = log)
+    dfnum <- data.frame(lapply(dfnum, probs_to_odds.numeric, log = log))
   }
 
   # Add non-numerics
@@ -129,23 +131,4 @@ convert_probs_to_odds <- probs_to_odds
   df <- df[var_order]
 
   return(df)
-}
-
-
-#' @keywords internal
-.odds_to_probs <- function(odds, log = TRUE) {
-  if (log == TRUE) {
-    odds <- exp(odds)
-  }
-  probs <- odds / (1 + odds)
-  return(probs)
-}
-
-#' @keywords internal
-.probs_to_odds <- function(probs, log = TRUE) {
-  odds <- probs / (1 - probs)
-  if (log == TRUE) {
-    odds <- log(odds)
-  }
-  return(odds)
-}
+}
\ No newline at end of file

---FILE: tests/testthat/test-convert.R---
@@ -1,22 +1,27 @@
 if (require(""testthat"") && require(""effectsize"")) {
   test_that(""odds_to_probs"", {
-    testthat::expect_equal(odds_to_probs(-1.6), 2.66, tolerance = 0.01)
-    testthat::expect_equal(odds_to_probs(-1.6, log = TRUE), 0.17, tolerance = 0.01)
-    testthat::expect_equal(probs_to_odds(2.66), -1.6, tolerance = 0.01)
-    testthat::expect_equal(probs_to_odds(0.17, log = TRUE), -1.6, tolerance = 0.01)
-    testthat::expect_equal(odds_to_probs(-1.6, log = TRUE), 0.17, tolerance = 0.01)
-
-    testthat::expect_true(
-      ncol(odds_to_probs(
+    testthat::expect_equal(odds_to_probs(3), 0.75, tolerance = 0.01)
+    testthat::expect_equal(probs_to_odds(0.75), 3, tolerance = 0.01)
+    testthat::expect_equal(probs_to_odds(0.75, log = TRUE), 1.098, tolerance = 0.01)
+    testthat::expect_equal(odds_to_probs(1.098, log = TRUE), 0.75, tolerance = 0.01)
+
+
+
+    testthat::expect_equal(
+      ncol(df <- odds_to_probs(
         iris,
         select = c(""Sepal.Length""),
-        exclude = c(""Petal.Length"")
-      )) == ncol(probs_to_odds(
-        iris,
+        exclude = c(""Petal.Length""),
+        log = TRUE
+      )), 5)
+
+    testthat::expect_equal(
+      ncol(probs_to_odds(
+        df,
         select = c(""Sepal.Length""),
-        exclude = c(""Petal.Length"")
-      ))
-    )
+        exclude = c(""Petal.Length""),
+        log = TRUE
+      )), 5)
   })
 
   test_that(""odds_to_d"", {",True,False,Documentation / Formatting,6
easystats,effectsize,74f7f6d298ac3c23aaba0a64a7cfda0c5bac2ebb,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-15T07:44:46Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-15T07:44:46Z,"Update test-standardize_parameters.R

removing this test until #117 is fixed...",tests/testthat/test-standardize_parameters.R,False,True,True,False,4,4,8,"---FILE: tests/testthat/test-standardize_parameters.R---
@@ -79,10 +79,10 @@ if (require(""testthat"") && require(""effectsize"")) {
       standardize_parameters(m1, method = ""basic"")$Std_Coefficient,
       standardize_parameters(m3, method = ""basic"")$Std_Coefficient
     )
-    testthat::expect_equal(
-      standardize_parameters(m1, method = ""basic"")$Std_Coefficient,
-      standardize_parameters(m4, method = ""basic"")$Std_Coefficient
-    )
+    # testthat::expect_equal(
+    #   standardize_parameters(m1, method = ""basic"")$Std_Coefficient,
+    #   standardize_parameters(m4, method = ""basic"")$Std_Coefficient
+    # )
   })
 
   if (require(rstanarm)) {",True,False,Dependency / Package,4
easystats,effectsize,9da56e7978be580ee04ed0f33bf4520226a479d1,Daniel,mail@danielluedecke.de,2020-09-13T10:32:03Z,Daniel,mail@danielluedecke.de,2020-09-13T10:32:03Z,fix,R/standardize_info.R,False,True,True,False,1,1,2,"---FILE: R/standardize_info.R---
@@ -301,7 +301,7 @@ standardize_info <- function(model, robust = FALSE, ...) {
     if (p == ""(Intercept)"") {
       Deviation_Response_Pseudo[p] <- Deviation_Pseudo[p] <- NA
     } else if (p %in% within_vars ||
-               (!is.null(interactions) && p %in% interactions && any(within_vars %in% interactions))) {
+               (!is.null(interactions) && p %in% interactions && any(sapply(within_vars, grepl, interactions)))) {
       ## is within
       # X_fit <- lme4::lmer(model_matrix[[p]] ~ 1 + (1|id))
       # Deviation_Pseudo[p] <- sqrt(insight::get_variance_residual(X_fit))",True,False,Implementation / Logic,6
easystats,effectsize,8c2b725d3d66267fe1daef302e5ead0b6ef4b5c7,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-13T10:15:54Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-09-13T10:15:54Z,"Test for #117

This test will fail until #117 is fixed ^_^",tests/testthat/test-standardize_parameters.R,False,True,True,False,25,1,26,"---FILE: tests/testthat/test-standardize_parameters.R---
@@ -61,6 +61,30 @@ if (require(""testthat"") && require(""effectsize"")) {
     )
   })
 
+  test_that(""standardize_parameters (with dunction interactions)"", {
+    X <- scale(rnorm(100),T,F)
+    Z <- scale(rnorm(100),T,F)
+    Y <- scale(Z + X * Z + rnorm(100),T,F)
+
+    m1 <- lm(Y ~ X * Z)
+    m2 <- lm(Y ~ X * scale(Z))
+    m3 <- lm(Y ~ scale(X) * Z)
+    m4 <- lm(Y ~ scale(X) * scale(Z))
+
+    testthat::expect_equal(
+      standardize_parameters(m1, method = ""basic"")$Std_Coefficient,
+      standardize_parameters(m2, method = ""basic"")$Std_Coefficient
+    )
+    testthat::expect_equal(
+      standardize_parameters(m1, method = ""basic"")$Std_Coefficient,
+      standardize_parameters(m3, method = ""basic"")$Std_Coefficient
+    )
+    testthat::expect_equal(
+      standardize_parameters(m1, method = ""basic"")$Std_Coefficient,
+      standardize_parameters(m4, method = ""basic"")$Std_Coefficient
+    )
+  })
+
   if (require(rstanarm)) {
     test_that(""standardize_parameters (Bayes)"", {
       testthat::skip_on_cran()
@@ -87,7 +111,7 @@ if (require(""testthat"") && require(""effectsize"")) {
   }
 
   if (require(lme4)) {
-    test_that(""Pseudo std"", {
+    test_that(""standardize_parameters (Pseudo - GLMM)"", {
       set.seed(1)
       N <- 10
       k <- 10",True,False,Dependency / Package,3
easystats,effectsize,dfaa133c77e3f8a1f1d544707bdc993c78fd9c83,mattansb,35330040+mattansb@users.noreply.github.com,2020-08-31T05:51:07Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-08-31T05:51:07Z,fix test,tests/testthat/test-standardize.R,False,True,True,False,4,3,7,"---FILE: tests/testthat/test-standardize.R---
@@ -83,10 +83,11 @@ if (require(""testthat"") && require(""effectsize"") && require(""dplyr"") && require(
     testthat::expect_message(standardize(lm(mpg ~ sqrt(cyl), mtcars)))
     testthat::expect_message(standardize(lm(mpg ~ log(hp), mtcars)))
 
-    # difference btween stand-methods:
+    # difference between stand-methods:
+    mtcars$hp_100 <- mtcars$hp/100
     fit_exp <- lm(mpg ~ exp(hp_100), mtcars)
-    fit_scale1 <- lm(scale(mpg) ~ exp(scale(hp/100)), mtcars)
-    fit_scale2 <- lm(scale(mpg) ~ scale(exp(hp/100)), mtcars)
+    fit_scale1 <- lm(scale(mpg) ~ exp(scale(hp_100)), mtcars)
+    fit_scale2 <- lm(scale(mpg) ~ scale(exp(hp_100)), mtcars)
     testthat::expect_equal(standardize_parameters(fit_exp, method = ""refit"")[2,2],
                            unname(coef(fit_scale1)[2]))
 ",True,False,Dependency / Package,3
easystats,effectsize,14f04d479005148b0ea8f3bca1937d8d8ca1ac17,mattansb,35330040+mattansb@users.noreply.github.com,2020-07-14T12:21:19Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-07-14T12:21:19Z,fix #102,NEWS.md;R/effectsize.R;R/phi_cramers_v.R;man/phi.Rd,False,True,True,False,28,13,41,"---FILE: NEWS.md---
@@ -8,6 +8,7 @@
 
 ## Bug fixes
 
+- Fix minor miss-calculation of Chi-squared for 2*2 table with small samples ( #102 ).
 - Fixed miss-calculation of signed rank in `ranktransform()` ( #87 ).
 - Fixed bug in `standardize()` for standard objects with non-standard class-attributes (like vectors of class `haven_labelled` or `vctrs_vctr`).  
 - Fix `effectsize()` for one sample `t.test(...)` ( #95 ; thanks to pull request by @mutlusun )

---FILE: R/effectsize.R---
@@ -47,8 +47,11 @@ effectsize.htest <- function(model, ...) {
     out$CI_high <- model$conf.int[2]
     return(out)
   } else if (grepl(""Chi-squared"", model$method)) {
+    Obs <- model$observed
+    Exp <- model$expected
+
     out <- chisq_to_cramers_v(
-      unname(model$statistic),
+      chisq = .chisq(Obs, Exp),
       n = sum(model$observed),
       nrow = nrow(model$observed),
       ncol = ncol(model$observed),

---FILE: R/phi_cramers_v.R---
@@ -6,7 +6,7 @@
 #' @param y a numeric vector; ignored if x is a matrix. If x is a factor, y should be a factor of the same length.
 #' @param CI Confidence Interval (CI) level
 #' @param adjust Should the effect size be bias-corrected? Defaults to \code{FALSE}.
-#' @param ... Passed to \code{chisq.test()}.
+#' @param ... Ignored.
 #'
 #' @return A data frame with the effect size(s) between 0-1, and confidence interval(s).
 #'
@@ -22,25 +22,36 @@
 #' @importFrom stats chisq.test
 #' @export
 phi <- function(x, y = NULL, CI = 0.95, adjust = FALSE, ...){
-  res <- stats::chisq.test(x, y, ...)
+  res <- stats::chisq.test(x, y)
+  Obs <- res$observed
+  Exp <- res$expected
 
-  chisq_to_phi(unname(res$statistic),
-               n = sum(res$observed),
-               nrow = nrow(res$observed),
-               ncol = ncol(res$observed),
+  chisq_to_phi(chisq = .chisq(Obs, Exp),
+               n = sum(Obs),
+               nrow = nrow(Obs),
+               ncol = ncol(Obs),
                CI = CI,
                adjust = adjust)
 }
 
 #' @rdname phi
+#' @importFrom stats chisq.test
 #' @export
 cramers_v <- function(x, y = NULL, CI = 0.95, adjust = FALSE, ...){
-  res <- stats::chisq.test(x, y, ...)
+  res <- stats::chisq.test(x, y)
+  Obs <- res$observed
+  Exp <- res$expected
 
-  chisq_to_cramers_v(unname(res$statistic),
-                     n = sum(res$observed),
-                     nrow = nrow(res$observed),
-                     ncol = ncol(res$observed),
+  chisq_to_cramers_v(chisq = .chisq(Obs, Exp),
+                     n = sum(Obs),
+                     nrow = nrow(Obs),
+                     ncol = ncol(Obs),
                      CI = CI,
                      adjust = adjust)
+}
+
+
+#' @keywords internal
+.chisq <- function(Obs, Exp) {
+  sum(((Obs - Exp) ^ 2) / Exp)
 }
\ No newline at end of file

---FILE: man/phi.Rd---
@@ -18,7 +18,7 @@ cramers_v(x, y = NULL, CI = 0.95, adjust = FALSE, ...)
 
 \item{adjust}{Should the effect size be bias-corrected? Defaults to \code{FALSE}.}
 
-\item{...}{Passed to \code{chisq.test()}.}
+\item{...}{Ignored.}
 }
 \value{
 A data frame with the effect size(s) between 0-1, and confidence interval(s).",True,False,Documentation / Formatting,6
easystats,effectsize,5fad312305651bb730f25be05014fb24d4029a23,mattansb,35330040+mattansb@users.noreply.github.com,2020-05-24T17:07:25Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-05-24T17:07:25Z,fix examples,R/eta_squared.R;man/eta_squared.Rd,False,True,True,False,0,2,2,"---FILE: R/eta_squared.R---
@@ -99,7 +99,6 @@
 #' }
 #'
 #' if (require(""parameters"")) {
-#'   data(mtcars)
 #'   model <- lm(mpg ~ wt + cyl, data = mtcars)
 #'   mp <- model_parameters(model)
 #'   eta_squared(mp)

---FILE: man/eta_squared.Rd---
@@ -119,7 +119,6 @@ if (require(car, quietly = TRUE)) {
 }
 
 if (require(""parameters"")) {
-  data(mtcars)
   model <- lm(mpg ~ wt + cyl, data = mtcars)
   mp <- model_parameters(model)
   eta_squared(mp)",True,False,Documentation / Formatting,6
easystats,effectsize,23bf80387b8fb516cf18d816279081bef1fd23d8,mattansb,35330040+mattansb@users.noreply.github.com,2020-04-28T14:10:33Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-04-28T14:10:33Z,fix Bayesian parameter standardization,R/standardize_parameters.R,False,True,True,False,11,10,21,"---FILE: R/standardize_parameters.R---
@@ -37,10 +37,6 @@
 #' standardize_parameters(model, robust = TRUE)
 #' standardize_parameters(model, two_sd = TRUE)
 #'
-#' # show CI
-#' library(parameters)
-#' params <- standardize_parameters(model, method = ""smart"", robust = TRUE)
-#' ci(params)
 #'
 #' iris$binary <- ifelse(iris$Sepal.Width > 3, 1, 0)
 #' model <- glm(binary ~ Species * Sepal.Length, data = iris, family = ""binomial"")
@@ -52,7 +48,7 @@
 #'
 #' \donttest{
 #' if (require(""rstanarm"")) {
-#'   model <- stan_glm(Sepal.Length ~ Species * Petal.Width, data = iris, iter = 500, refresh = 0)
+#'   model <- stan_glm(Sepal.Length ~ Species + Petal.Width, data = iris, iter = 500, refresh = 0)
 #'   standardize_posteriors(model, method = ""refit"")
 #'   standardize_posteriors(model, method = ""posthoc"")
 #'   standardize_posteriors(model, method = ""smart"")
@@ -96,9 +92,14 @@ standardize_parameters <- function(model, parameters = NULL, method = ""refit"", c
 
   # Summarise for Bayesian models
   if (insight::model_info(model)$is_bayesian) {
-    std_params <- bayestestR::describe_posterior(std_params, centrality = centrality, dispersion = FALSE, ci = ci, test = NULL, diagnostic = NULL, priors = FALSE)
-    std_params <- std_params[names(std_params) %in% c(""Parameter"", ""Coefficient"", ""Median"", ""Mean"", ""MAP"")]
-    names(std_params)[-1] <- paste0(""Std_"", names(std_params)[-1])
+    std_params <- bayestestR::describe_posterior(
+      std_params, centrality = centrality, dispersion = FALSE,
+      ci = ci, ci_method = ""hdi"",
+      test = NULL, diagnostic = NULL, priors = FALSE
+    )
+    std_params <- std_params[names(std_params) %in% c(""Parameter"", ""Coefficient"", ""Median"", ""Mean"", ""MAP"",""CI"", ""CI_low"", ""CI_high"")]
+    i <- colnames(std_params) %in% c(""Coefficient"", ""Median"", ""Mean"", ""MAP"")
+    colnames(std_params)[i] <- paste0(""Std_"", colnames(std_params)[i])
   }
 
   attr(std_params, ""object_name"") <- deparse(substitute(model), width.cutoff = 500)
@@ -149,7 +150,7 @@ standardize_posteriors <- function(model, method = ""refit"", robust = FALSE, two_
   std_model <- standardize(model, robust = robust, two_sd = two_sd, verbose = verbose, ...)
   std_params <- .extract_parameters(std_model)
 
-  if (!is.null(ci)) {
+  if (!is.null(ci) && !insight::model_info(model)$is_bayesian) {
     CIs <- parameters::ci(std_model, ci = ci)
     std_params$CI <- CIs$CI / 100
     std_params$CI_low <- CIs$CI_low
@@ -257,7 +258,7 @@ standardize_posteriors <- function(model, method = ""refit"", robust = FALSE, two_
   }
 
   attr(std_params, ""object_name"") <- object_name
-  if (!is.null(ci)) {
+  if (!is.null(ci) && !insight::model_info(model)$is_bayesian) {
     CIs <- parameters::ci(std_params, ci = ci)
     if (!is.null(CIs)) {
       std_params$CI <- CIs$CI / 100",True,False,Implementation / Logic,6
easystats,effectsize,a98aabf491f52780c0793b50959172465d3effce,mattansb,35330040+mattansb@users.noreply.github.com,2020-04-26T11:29:53Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-04-26T11:29:53Z,fix refit method #72,R/standardize_parameters.R;man/standardize_parameters.Rd,False,True,True,False,33,18,51,"---FILE: R/standardize_parameters.R---
@@ -80,23 +80,23 @@
 #' @importFrom parameters ci
 #' @export
 standardize_parameters <- function(model, parameters = NULL, method = ""refit"", ci = 0.95, robust = FALSE, two_sd = FALSE, verbose = TRUE, centrality = ""median"", ...) {
-  std_params <- .standardize_parameters(model = model, parameters = parameters, method = method, robust = robust, two_sd = two_sd, verbose = verbose, ...)
+  std_params <-
+    .standardize_parameters(
+      model = model,
+      parameters = parameters,
+      method = method,
+      ci = ci,
+      robust = robust,
+      two_sd = two_sd,
+      verbose = verbose,
+      ...
+    )
 
   # Summarise for Bayesian models
   if (insight::model_info(model)$is_bayesian) {
     std_params <- bayestestR::describe_posterior(std_params, centrality = centrality, dispersion = FALSE, ci = ci, test = NULL, diagnostic = NULL, priors = FALSE)
     std_params <- std_params[names(std_params) %in% c(""Parameter"", ""Coefficient"", ""Median"", ""Mean"", ""MAP"")]
     names(std_params)[-1] <- paste0(""Std_"", names(std_params)[-1])
-  } else if (!is.null(ci)) {
-    CIs <- parameters::ci(std_params, ci = ci)
-    if (!is.null(CIs)) {
-      std_params$CI <- CIs$CI / 100
-      std_params$CI_low <- CIs$CI_low
-      std_params$CI_high <- CIs$CI_high
-    }
-    class(std_params) <- c(""effectsize_table"", ""see_effectsize_table"",class(std_params))
-  } else {
-    class(std_params) <- c(""effectsize_table"", ""see_effectsize_table"",class(std_params))
   }
   std_params
 }
@@ -115,22 +115,23 @@ standardize_posteriors <- function(model, method = ""refit"", robust = FALSE, two_
 # Internal Wrapper -------------------------------------------------------------------
 
 #' @keywords internal
-.standardize_parameters <- function(model, parameters = NULL, method = ""refit"", robust = FALSE, two_sd = FALSE, verbose = TRUE, ...) {
+.standardize_parameters <- function(model, parameters = NULL, method = ""refit"", ci = 0.95, robust = FALSE, two_sd = FALSE, verbose = TRUE, ...) {
   method <- match.arg(method, choices = c(""default"", ""refit"", ""posthoc"", ""smart"", ""partial"", ""basic""))
 
   # Refit
   if (method %in% c(""refit"")) {
-    std_params <- .standardize_parameters_refit(model, robust = robust, verbose = verbose, ...)
+    std_params <- .standardize_parameters_refit(model, ci = ci, robust = robust, verbose = verbose, ...)
 
     # Posthoc
   } else if (method %in% c(""posthoc"", ""smart"", ""basic"", ""classic"")) {
-    std_params <- .standardize_parameters_posthoc(model, parameters = parameters, method = method, robust = robust, two_sd = two_sd, verbose = verbose, ...)
+    std_params <- .standardize_parameters_posthoc(model, parameters = parameters, method = method, ci = ci, robust = robust, two_sd = two_sd, verbose = verbose, ...)
 
     # Partial
   } else if (method == ""partial"") {
     stop(""`method = 'partial'` not implemented yet :("")
   }
 
+  class(std_params) <- c(""effectsize_table"", ""see_effectsize_table"",class(std_params))
   std_params
 }
 
@@ -140,12 +141,18 @@ standardize_posteriors <- function(model, method = ""refit"", robust = FALSE, two_
 # REFIT -------------------------------------------------------------------
 #' @importFrom parameters standard_error ci
 #' @keywords internal
-.standardize_parameters_refit <- function(model, robust = FALSE, two_sd = FALSE, verbose = TRUE, ...) {
+.standardize_parameters_refit <- function(model, ci = 0.95, robust = FALSE, two_sd = FALSE, verbose = TRUE, ...) {
   std_model <- standardize(model, robust = robust, two_sd = two_sd, verbose = verbose, ...)
   std_params <- .extract_parameters(std_model)
 
+  if (!is.null(ci)) {
+    CIs <- parameters::ci(std_model, ci = ci)
+    std_params$CI <- CIs$CI / 100
+    std_params$CI_low <- CIs$CI_low
+    std_params$CI_high <- CIs$CI_high
+  }
+
   attr(std_params, ""standard_error"") <- parameters::standard_error(std_model)
-  attr(std_params, ""ci"") <- parameters::ci(std_model)
 
   std_params
 }
@@ -164,7 +171,7 @@ standardize_posteriors <- function(model, method = ""refit"", robust = FALSE, two_
 #' @importFrom parameters standard_error
 #' @importFrom insight model_info get_data
 #' @keywords internal
-.standardize_parameters_posthoc <- function(model, parameters = NULL, method = ""smart"", robust = FALSE, two_sd = FALSE, verbose = TRUE, ...) {
+.standardize_parameters_posthoc <- function(model, parameters = NULL, method = ""smart"", ci = 0.95, robust = FALSE, two_sd = FALSE, verbose = TRUE, ...) {
 
   # Sanity Checks
   if (verbose && insight::model_info(model)$is_zero_inflated) {
@@ -245,6 +252,14 @@ standardize_posteriors <- function(model, method = ""refit"", robust = FALSE, two_
     class(std_params) <- c(""effectsize_std_params"", class(std_params))
   }
 
+  if (!is.null(ci)) {
+    CIs <- parameters::ci(std_params, ci = ci)
+    if (!is.null(CIs)) {
+      std_params$CI <- CIs$CI / 100
+      std_params$CI_low <- CIs$CI_low
+      std_params$CI_high <- CIs$CI_high
+    }
+  }
   std_params
 }
 

---FILE: man/standardize_parameters.Rd---
@@ -9,7 +9,7 @@ standardize_parameters(
   model,
   parameters = NULL,
   method = ""refit"",
-  ci = NULL,
+  ci = 0.95,
   robust = FALSE,
   two_sd = FALSE,
   verbose = TRUE,",True,False,Documentation / Formatting,6
easystats,effectsize,4edd124181d082f40c9d86818ff4970b82dbe2dc,mattansb,35330040+mattansb@users.noreply.github.com,2020-04-23T14:24:48Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-04-23T14:24:48Z,"#70

Also:
https://github.com/easystats/parameters/issues/12",R/equivalence_test.R;R/print.equivalence_test_effectsize.R;docs/reference/equivalence_test.effectsize_table-1.png;docs/reference/equivalence_test.effectsize_table-2.png;docs/reference/equivalence_test.effectsize_table-3.png;docs/reference/equivalence_test.effectsize_table.html;man/equivalence_test.effectsize_table.Rd,False,True,True,False,161,31,192,"---FILE: R/equivalence_test.R---
@@ -10,15 +10,42 @@ bayestestR::equivalence_test
 #' @param range The range of practical equivalence of an effect. If a single value is provided,
 #'   the test is done against \code{c(-range, range)}. For effect sizes that cannot be negative,
 #'   the lower bound is set to 0. If \code{""default""}, will be set to \code{[-.1, .1]}.
+#' @param rule How should acceptance and rejection be decided? See details.
 #' @param ... Arguments passed to or from other methods.
 #'
+#' @details
+#' The CIs used in the equivalence test are the ones in the provided effect size table.
+#' For results equivalent (ha!) to those that can be obtained using the TOST approach (e.g., Lakens, 2017),
+#' appropriate CIs should be extracted using the function used to make the effect size table
+#' (\code{cohens_d, eta_squared, F_to_r}, etc). See examples.
+#'
+#' \subsection{The Different Rules}{
+#' \code{""classic""} - \strong{the classic method}: \itemize{
+#'     \item If the CI is completely within the ROPE - \emph{Accept H0}
+#'     \item Else, if the CI does not contain 0 - \emph{Reject H0}
+#'     \item Else - \emph{Undecided}
+#' }
+#' \code{""cet""} - \strong{conditional equivalence testing}: \itemize{
+#'     \item If the CI does not contain 0 - \emph{Reject H0}
+#'     \item Else, If the CI is completely within the ROPE - \emph{Accept H0}
+#'     \item Else - \emph{Undecided}
+#' }
+#' \code{""bayes""} - \strong{The Bayesian approach}, as put forth by Kruschke: \itemize{
+#'     \item If the CI does is completely outsie the ROPE - \emph{Reject H0}
+#'     \item Else, If the CI is completely within the ROPE - \emph{Accept H0}
+#'     \item Else - \emph{Undecided}
+#' }
+#' }
+#'
 #' @seealso For more details, see \code{\link[bayestestR:equivalence_test]{equivalence_test}}.
 #'
 #' @return A data frame.
 #'
 #' @references
 #' \itemize{
 #'   \item Campbell, H., & Gustafson, P. (2018). Conditional equivalence testing: An alternative remedy for publication bias. PLOS ONE, 13(4), e0195145. https://doi.org/10.1371/journal.pone.0195145
+#'   \item Kruschke, J. K. (2014). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press
+#'   \item Kruschke, J. K. (2018). Rejecting or accepting parameter values in Bayesian estimation. Advances in Methods and Practices in Psychological Science, 1(2), 270-280. doi: 10.1177/2515245918771304
 #'   \item Lakens, D. (2017). Equivalence Tests: A Practical Primer for t Tests, Correlations, and Meta-Analyses. Social Psychological and Personality Science, 8(4), 355â362. https://doi.org/10.1177/1948550617697177
 #' }
 #'
@@ -29,16 +56,20 @@ bayestestR::equivalence_test
 #' es <- eta_squared(model)
 #' equivalence_test(es, range = 0.15)
 #'
-#' ds <- t_to_d(t = c(0.45, -0.65, -2.2, 2.25),
-#'              df_error = c(675, 525, 900, 1875))
-#' (equi <- equivalence_test(ds, range = 0.2))
+#' ds <- t_to_d(t = c(0.45, -0.65, 7, -2.2, 2.25),
+#'              df_error = c(675, 525, 2000, 900, 1875),
+#'              ci = 0.9) # TOST approach
+#' equivalence_test(ds, range = 0.2)
 #'
 #' # Can also plot
-#' if (require(see)) plot(equi)
+#' if (require(see)) plot(equivalence_test(ds, range = 0.2))
+#' if (require(see)) plot(equivalence_test(ds, range = 0.2, rule = ""cet""))
+#' if (require(see)) plot(equivalence_test(ds, range = 0.2, rule = ""bayes""))
 #' }
 #'
 #' @export
-equivalence_test.effectsize_table <- function(x, range = ""default"", ...) {
+equivalence_test.effectsize_table <- function(x, range = ""default"", rule = c(""classic"",""cet"",""bayes""), ...) {
+  rule <- match.arg(rule)
 
   if (!all(c(""CI"", ""CI_low"", ""CI_high"") %in% colnames(x))) {
     stop(""CI values missing from effect size table."", call. = FALSE)
@@ -63,6 +94,7 @@ equivalence_test.effectsize_table <- function(x, range = ""default"", ...) {
 
     signif <- x$CI_low > 0
     in_rope <- x$CI_high < range
+    out_rope <- range < x$CI_low
 
     range <- c(0,range)
 
@@ -74,13 +106,24 @@ equivalence_test.effectsize_table <- function(x, range = ""default"", ...) {
 
     signif <- x$CI_high < 0 | 0 < x$CI_low
     in_rope <- range[1] < x$CI_low & x$CI_high < range[2]
+    out_rope <- x$CI_high < range[1] | range[2] < x$CI_low
   }
 
   x$ROPE_Equivalence <- ""Undecided""
-  x$ROPE_Equivalence[in_rope] <- ""Accepted""
-  x$ROPE_Equivalence[signif & !in_rope] <- ""Rejected""
+  if (rule == ""classic"") {
+    x$ROPE_Equivalence[in_rope] <- ""Accepted""
+    x$ROPE_Equivalence[signif & !in_rope] <- ""Rejected""
+  } else if (rule == ""cet"") {
+    x$ROPE_Equivalence[signif] <- ""Rejected""
+    x$ROPE_Equivalence[in_rope & !signif] <- ""Accepted""
+  } else {
+    x$ROPE_Equivalence[out_rope] <- ""Rejected""
+    x$ROPE_Equivalence[in_rope] <- ""Accepted""
+  }
+
 
   attr(x, ""rope"") <- range
+  attr(x, ""rule"") <- rule
   class(x) <- c(""equivalence_test_effectsize"", ""see_equivalence_test_effectsize"", ""data.frame"")
   return(x)
 }

---FILE: R/print.equivalence_test_effectsize.R---
@@ -1,21 +1,32 @@
 #' @export
-print.equivalence_test_effectsize <- function(x, digits = 2, ...){
+print.equivalence_test_effectsize <- function(x, digits = 2, ...) {
   x_orig <- x
 
-  insight::print_color(""# Test for Practical Equivalence\n\n"", ""blue"")
+  ## Title
+  if (attr(x, ""rule"", exact = TRUE) == ""cet"") {
+    title <- ""# Conditional Test for Practical Equivalence\n\n""
+  } else {
+    title <- ""# Test for Practical Equivalence\n\n""
+  }
+  insight::print_color(title, ""blue"")
 
+  ## Rope range
   .rope <- attr(x, ""rope"", exact = TRUE)
   cat(sprintf(""  ROPE: [%.*f %.*f]\n\n"", digits, .rope[1], digits, .rope[2]))
 
-  # ROPE_Equivalence
-  x$H0 <- x$ROPE_Equivalence
-  x$ROPE_Equivalence <- NULL
 
-  # CI
+  ## ROPE_Equivalence
+  colnames(x)[colnames(x) == ""ROPE_Equivalence""] <- ""H0""
+
+  ## CI
   ci_level <- x$CI[1]
-  # x$CI <- NULL
-  x$CI <- insight::format_ci(x$CI_low, x$CI_high, ci = NULL,
-                             digits = digits, width = ""auto"")
+  x$CI <- insight::format_ci(
+    x$CI_low,
+    x$CI_high,
+    ci = NULL,
+    digits = digits,
+    width = ""auto""
+  )
   colnames(x)[colnames(x) == ""CI""] <-
     paste0(insight::format_value(ci_level, as_percent = TRUE, digits = 0),
            "" CI"")
@@ -24,5 +35,10 @@ print.equivalence_test_effectsize <- function(x, digits = 2, ...){
   # print
   cat(insight::format_table(x, digits = digits))
 
+
+  if (attr(x, ""rule"", exact = TRUE) == ""bayes"") {
+    insight::print_color(""\n(Using Bayesian guidlines)\n\n"", ""green"")
+  }
+
   invisible(x_orig)
 }
\ No newline at end of file

---FILE: docs/reference/equivalence_test.effectsize_table.html---
@@ -162,7 +162,12 @@ <h1>Test for Practical Equivalence</h1>
     </div>
 
     <pre class=""usage""><span class='co'># S3 method for effectsize_table</span>
-<span class='fu'><a href='https://rdrr.io/pkg/bayestestR/man/equivalence_test.html'>equivalence_test</a></span>(<span class='no'>x</span>, <span class='kw'>range</span> <span class='kw'>=</span> <span class='st'>""default""</span>, <span class='no'>...</span>)</pre>
+<span class='fu'><a href='https://rdrr.io/pkg/bayestestR/man/equivalence_test.html'>equivalence_test</a></span>(
+  <span class='no'>x</span>,
+  <span class='kw'>range</span> <span class='kw'>=</span> <span class='st'>""default""</span>,
+  <span class='kw'>rule</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='st'>""classic""</span>, <span class='st'>""cet""</span>, <span class='st'>""bayes""</span>),
+  <span class='no'>...</span>
+)</pre>
 
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
@@ -177,6 +182,10 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
 the test is done against <code><a href='https://rdrr.io/r/base/c.html'>c(-range, range)</a></code>. For effect sizes that cannot be negative,
 the lower bound is set to 0. If <code>""default""</code>, will be set to <code>[-.1, .1]</code>.</p></td>
     </tr>
+    <tr>
+      <th>rule</th>
+      <td><p>How should acceptance and rejection be decided? See details.</p></td>
+    </tr>
     <tr>
       <th>...</th>
       <td><p>Arguments passed to or from other methods.</p></td>
@@ -186,11 +195,35 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
     <h2 class=""hasAnchor"" id=""value""><a class=""anchor"" href=""#value""></a>Value</h2>
 
     <p>A data frame.</p>
+    <h2 class=""hasAnchor"" id=""details""><a class=""anchor"" href=""#details""></a>Details</h2>
+
+    <p>The CIs used in the equivalence test are the ones in the provided effect size table.
+For results equivalent (ha!) to those that can be obtained using the TOST approach (e.g., Lakens, 2017),
+appropriate CIs should be extracted using the function used to make the effect size table
+(<code>cohens_d, eta_squared, F_to_r</code>, etc). See examples.</p>
+<h3>The Different Rules</h3>
+<p><code>""classic""</code> - <strong>the classic method</strong>:</p><ul>
+<li><p>If the CI is completely within the ROPE - <em>Accept H0</em></p></li>
+<li><p>Else, if the CI does not contain 0 - <em>Reject H0</em></p></li>
+<li><p>Else - <em>Undecided</em></p></li>
+</ul><p><code>""cet""</code> - <strong>conditional equivalence testing</strong>:</p><ul>
+<li><p>If the CI does not contain 0 - <em>Reject H0</em></p></li>
+<li><p>Else, If the CI is completely within the ROPE - <em>Accept H0</em></p></li>
+<li><p>Else - <em>Undecided</em></p></li>
+</ul><p><code>""bayes""</code> - <strong>The Bayesian approach</strong>, as put forth by Kruschke:</p><ul>
+<li><p>If the CI does is completely outsie the ROPE - <em>Reject H0</em></p></li>
+<li><p>Else, If the CI is completely within the ROPE - <em>Accept H0</em></p></li>
+<li><p>Else - <em>Undecided</em></p></li>
+</ul>
+
+
     <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>References</h2>
 
     
 <ul>
 <li><p>Campbell, H., &amp; Gustafson, P. (2018). Conditional equivalence testing: An alternative remedy for publication bias. PLOS ONE, 13(4), e0195145. https://doi.org/10.1371/journal.pone.0195145</p></li>
+<li><p>Kruschke, J. K. (2014). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press</p></li>
+<li><p>Kruschke, J. K. (2018). Rejecting or accepting parameter values in Bayesian estimation. Advances in Methods and Practices in Psychological Science, 1(2), 270-280. doi: 10.1177/2515245918771304</p></li>
 <li><p>Lakens, D. (2017). Equivalence Tests: A Practical Primer for t Tests, Correlations, and Meta-Analyses. Social Psychological and Personality Science, 8(4), 355â362. https://doi.org/10.1177/1948550617697177</p></li>
 </ul>
 
@@ -212,20 +245,22 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
 #&gt; factor(am)             |           0.63 | [0.42, 0.75] |  Rejected
 #&gt; factor(cyl)            |           0.66 | [0.45, 0.77] |  Rejected
 #&gt; factor(am):factor(cyl) |           0.10 | [0.00, 0.27] | Undecided</div><div class='input'>
-<span class='no'>ds</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='t_to_r.html'>t_to_d</a></span>(<span class='kw'>t</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>0.45</span>, -<span class='fl'>0.65</span>, -<span class='fl'>2.2</span>, <span class='fl'>2.25</span>),
-             <span class='kw'>df_error</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>675</span>, <span class='fl'>525</span>, <span class='fl'>900</span>, <span class='fl'>1875</span>))
-(<span class='no'>equi</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/bayestestR/man/equivalence_test.html'>equivalence_test</a></span>(<span class='no'>ds</span>, <span class='kw'>range</span> <span class='kw'>=</span> <span class='fl'>0.2</span>))</div><div class='output co'>#&gt; </span><span style='color: #0000BB;'># Test for Practical Equivalence
+<span class='no'>ds</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='t_to_r.html'>t_to_d</a></span>(<span class='kw'>t</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>0.45</span>, -<span class='fl'>0.65</span>, <span class='fl'>7</span>, -<span class='fl'>2.2</span>, <span class='fl'>2.25</span>),
+             <span class='kw'>df_error</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>675</span>, <span class='fl'>525</span>, <span class='fl'>2000</span>, <span class='fl'>900</span>, <span class='fl'>1875</span>),
+             <span class='kw'>ci</span> <span class='kw'>=</span> <span class='fl'>0.9</span>) <span class='co'># TOST approach</span>
+<span class='fu'><a href='https://rdrr.io/pkg/bayestestR/man/equivalence_test.html'>equivalence_test</a></span>(<span class='no'>ds</span>, <span class='kw'>range</span> <span class='kw'>=</span> <span class='fl'>0.2</span>)</div><div class='output co'>#&gt; </span><span style='color: #0000BB;'># Test for Practical Equivalence
 #&gt; 
 #&gt; </span><span>  ROPE: [-0.20 0.20]
 #&gt; 
-#&gt;     d |         95% CI |        H0
+#&gt;     d |         90% CI |        H0
 #&gt; ----------------------------------
-#&gt;  0.03 | [-0.12,  0.19] |  Accepted
-#&gt; -0.06 | [-0.23,  0.11] | Undecided
-#&gt; -0.15 | [-0.28, -0.02] |  Rejected
-#&gt;  0.10 | [ 0.01,  0.19] |  Accepted</div><div class='input'>
+#&gt;  0.03 | [-0.09,  0.16] |  Accepted
+#&gt; -0.06 | [-0.20,  0.09] | Undecided
+#&gt;  0.31 | [ 0.24,  0.39] |  Rejected
+#&gt; -0.15 | [-0.26, -0.04] |  Rejected
+#&gt;  0.10 | [ 0.03,  0.18] |  Accepted</div><div class='input'>
 <span class='co'># Can also plot</span>
-<span class='kw'>if</span> (<span class='fu'><a href='https://rdrr.io/r/base/library.html'>require</a></span>(<span class='no'>see</span>)) <span class='fu'><a href='https://rdrr.io/r/graphics/plot.html'>plot</a></span>(<span class='no'>equi</span>)</div><div class='output co'>#&gt; <span class='message'>Loading required package: see</span></div><div class='img'><img src='equivalence_test.effectsize_table-1.png' alt='' width='700' height='433' /></div><div class='input'># }
+<span class='kw'>if</span> (<span class='fu'><a href='https://rdrr.io/r/base/library.html'>require</a></span>(<span class='no'>see</span>)) <span class='fu'><a href='https://rdrr.io/r/graphics/plot.html'>plot</a></span>(<span class='fu'><a href='https://rdrr.io/pkg/bayestestR/man/equivalence_test.html'>equivalence_test</a></span>(<span class='no'>ds</span>, <span class='kw'>range</span> <span class='kw'>=</span> <span class='fl'>0.2</span>))</div><div class='img'><img src='equivalence_test.effectsize_table-1.png' alt='' width='700' height='433' /></div><div class='input'><span class='kw'>if</span> (<span class='fu'><a href='https://rdrr.io/r/base/library.html'>require</a></span>(<span class='no'>see</span>)) <span class='fu'><a href='https://rdrr.io/r/graphics/plot.html'>plot</a></span>(<span class='fu'><a href='https://rdrr.io/pkg/bayestestR/man/equivalence_test.html'>equivalence_test</a></span>(<span class='no'>ds</span>, <span class='kw'>range</span> <span class='kw'>=</span> <span class='fl'>0.2</span>, <span class='kw'>rule</span> <span class='kw'>=</span> <span class='st'>""cet""</span>))</div><div class='img'><img src='equivalence_test.effectsize_table-2.png' alt='' width='700' height='433' /></div><div class='input'><span class='kw'>if</span> (<span class='fu'><a href='https://rdrr.io/r/base/library.html'>require</a></span>(<span class='no'>see</span>)) <span class='fu'><a href='https://rdrr.io/r/graphics/plot.html'>plot</a></span>(<span class='fu'><a href='https://rdrr.io/pkg/bayestestR/man/equivalence_test.html'>equivalence_test</a></span>(<span class='no'>ds</span>, <span class='kw'>range</span> <span class='kw'>=</span> <span class='fl'>0.2</span>, <span class='kw'>rule</span> <span class='kw'>=</span> <span class='st'>""bayes""</span>))</div><div class='img'><img src='equivalence_test.effectsize_table-3.png' alt='' width='700' height='433' /></div><div class='input'># }
 
 </div></span></pre>
   </div>

---FILE: man/equivalence_test.effectsize_table.Rd---
@@ -4,7 +4,12 @@
 \alias{equivalence_test.effectsize_table}
 \title{Test for Practical Equivalence}
 \usage{
-\method{equivalence_test}{effectsize_table}(x, range = ""default"", ...)
+\method{equivalence_test}{effectsize_table}(
+  x,
+  range = ""default"",
+  rule = c(""classic"", ""cet"", ""bayes""),
+  ...
+)
 }
 \arguments{
 \item{x}{An effect size table, such as returned by \code{cohens_d, eta_squared, F_to_r}, etc.}
@@ -13,6 +18,8 @@
 the test is done against \code{c(-range, range)}. For effect sizes that cannot be negative,
 the lower bound is set to 0. If \code{""default""}, will be set to \code{[-.1, .1]}.}
 
+\item{rule}{How should acceptance and rejection be decided? See details.}
+
 \item{...}{Arguments passed to or from other methods.}
 }
 \value{
@@ -21,25 +28,54 @@ A data frame.
 \description{
 Perform a \strong{Test for Practical Equivalence} for indices of effect size.
 }
+\details{
+The CIs used in the equivalence test are the ones in the provided effect size table.
+For results equivalent (ha!) to those that can be obtained using the TOST approach (e.g., Lakens, 2017),
+appropriate CIs should be extracted using the function used to make the effect size table
+(\code{cohens_d, eta_squared, F_to_r}, etc). See examples.
+
+\subsection{The Different Rules}{
+\code{""classic""} - \strong{the classic method}: \itemize{
+    \item If the CI is completely within the ROPE - \emph{Accept H0}
+    \item Else, if the CI does not contain 0 - \emph{Reject H0}
+    \item Else - \emph{Undecided}
+}
+\code{""cet""} - \strong{conditional equivalence testing}: \itemize{
+    \item If the CI does not contain 0 - \emph{Reject H0}
+    \item Else, If the CI is completely within the ROPE - \emph{Accept H0}
+    \item Else - \emph{Undecided}
+}
+\code{""bayes""} - \strong{The Bayesian approach}, as put forth by Kruschke: \itemize{
+    \item If the CI does is completely outsie the ROPE - \emph{Reject H0}
+    \item Else, If the CI is completely within the ROPE - \emph{Accept H0}
+    \item Else - \emph{Undecided}
+}
+}
+}
 \examples{
 
 \donttest{
 model <- aov(mpg ~ factor(am) * factor(cyl), data = mtcars)
 es <- eta_squared(model)
 equivalence_test(es, range = 0.15)
 
-ds <- t_to_d(t = c(0.45, -0.65, -2.2, 2.25),
-             df_error = c(675, 525, 900, 1875))
-(equi <- equivalence_test(ds, range = 0.2))
+ds <- t_to_d(t = c(0.45, -0.65, 7, -2.2, 2.25),
+             df_error = c(675, 525, 2000, 900, 1875),
+             ci = 0.9) # TOST approach
+equivalence_test(ds, range = 0.2)
 
 # Can also plot
-if (require(see)) plot(equi)
+if (require(see)) plot(equivalence_test(ds, range = 0.2))
+if (require(see)) plot(equivalence_test(ds, range = 0.2, rule = ""cet""))
+if (require(see)) plot(equivalence_test(ds, range = 0.2, rule = ""bayes""))
 }
 
 }
 \references{
 \itemize{
   \item Campbell, H., & Gustafson, P. (2018). Conditional equivalence testing: An alternative remedy for publication bias. PLOS ONE, 13(4), e0195145. https://doi.org/10.1371/journal.pone.0195145
+  \item Kruschke, J. K. (2014). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press
+  \item Kruschke, J. K. (2018). Rejecting or accepting parameter values in Bayesian estimation. Advances in Methods and Practices in Psychological Science, 1(2), 270-280. doi: 10.1177/2515245918771304
   \item Lakens, D. (2017). Equivalence Tests: A Practical Primer for t Tests, Correlations, and Meta-Analyses. Social Psychological and Personality Science, 8(4), 355â362. https://doi.org/10.1177/1948550617697177
 }
 }",True,False,Documentation / Formatting,6
easystats,effectsize,2e825642f9795b5d15054cfa4748ca8e6770ecd7,mattansb,35330040+mattansb@users.noreply.github.com,2020-04-23T10:01:43Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-04-23T10:01:43Z,fix error in travis,R/equivalence_test.R;docs/reference/equivalence_test.effectsize_table.html;man/equivalence_test.effectsize_table.Rd,False,True,True,False,30,23,53,"---FILE: R/equivalence_test.R---
@@ -24,16 +24,18 @@ bayestestR::equivalence_test
 #'
 #' @examples
 #'
+#' \donttest{
+#' model <- aov(mpg ~ factor(am) * factor(cyl), data = mtcars)
+#' es <- eta_squared(model)
+#' equivalence_test(es, range = 0.15)
+#'
 #' ds <- t_to_d(t = c(0.45, -0.65, -2.2, 2.25),
 #'              df_error = c(675, 525, 900, 1875))
 #' (equi <- equivalence_test(ds, range = 0.2))
-#' if (require(see)) plot(equi)
 #'
-#'
-#' model <- aov(mpg ~ factor(am) * factor(cyl), data = mtcars)
-#' es <- eta_squared(model)
-#' (equi <- equivalence_test(es, range = 0.15))
+#' # Can also plot
 #' if (require(see)) plot(equi)
+#' }
 #'
 #' @export
 equivalence_test.effectsize_table <- function(x, range = ""default"", ...) {

---FILE: docs/reference/equivalence_test.effectsize_table.html---
@@ -200,9 +200,21 @@ <h2 class=""hasAnchor"" id=""see-also""><a class=""anchor"" href=""#see-also""></a>See a
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'>
+<span class='co'># \donttest{</span>
+<span class='no'>model</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/aov.html'>aov</a></span>(<span class='no'>mpg</span> ~ <span class='fu'><a href='https://rdrr.io/r/base/factor.html'>factor</a></span>(<span class='no'>am</span>) * <span class='fu'><a href='https://rdrr.io/r/base/factor.html'>factor</a></span>(<span class='no'>cyl</span>), <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>mtcars</span>)
+<span class='no'>es</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='eta_squared.html'>eta_squared</a></span>(<span class='no'>model</span>)
+<span class='fu'><a href='https://rdrr.io/pkg/bayestestR/man/equivalence_test.html'>equivalence_test</a></span>(<span class='no'>es</span>, <span class='kw'>range</span> <span class='kw'>=</span> <span class='fl'>0.15</span>)</div><div class='output co'>#&gt; <span style='color: #0000BB;'># Test for Practical Equivalence
+#&gt; 
+#&gt; </span><span>  ROPE: [0.00 0.15]
+#&gt; 
+#&gt; Parameter              | Eta_Sq_partial |       90% CI |        H0
+#&gt; ------------------------------------------------------------------
+#&gt; factor(am)             |           0.63 | [0.42, 0.75] |  Rejected
+#&gt; factor(cyl)            |           0.66 | [0.45, 0.77] |  Rejected
+#&gt; factor(am):factor(cyl) |           0.10 | [0.00, 0.27] | Undecided</div><div class='input'>
 <span class='no'>ds</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='t_to_r.html'>t_to_d</a></span>(<span class='kw'>t</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>0.45</span>, -<span class='fl'>0.65</span>, -<span class='fl'>2.2</span>, <span class='fl'>2.25</span>),
              <span class='kw'>df_error</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>675</span>, <span class='fl'>525</span>, <span class='fl'>900</span>, <span class='fl'>1875</span>))
-(<span class='no'>equi</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/bayestestR/man/equivalence_test.html'>equivalence_test</a></span>(<span class='no'>ds</span>, <span class='kw'>range</span> <span class='kw'>=</span> <span class='fl'>0.2</span>))</div><div class='output co'>#&gt; <span style='color: #0000BB;'># Test for Practical Equivalence
+(<span class='no'>equi</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/bayestestR/man/equivalence_test.html'>equivalence_test</a></span>(<span class='no'>ds</span>, <span class='kw'>range</span> <span class='kw'>=</span> <span class='fl'>0.2</span>))</div><div class='output co'>#&gt; </span><span style='color: #0000BB;'># Test for Practical Equivalence
 #&gt; 
 #&gt; </span><span>  ROPE: [-0.20 0.20]
 #&gt; 
@@ -211,19 +223,10 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
 #&gt;  0.03 | [-0.12,  0.19] |  Accepted
 #&gt; -0.06 | [-0.23,  0.11] | Undecided
 #&gt; -0.15 | [-0.28, -0.02] |  Rejected
-#&gt;  0.10 | [ 0.01,  0.19] |  Accepted</div><div class='input'><span class='kw'>if</span> (<span class='fu'><a href='https://rdrr.io/r/base/library.html'>require</a></span>(<span class='no'>see</span>)) <span class='fu'><a href='https://rdrr.io/r/graphics/plot.html'>plot</a></span>(<span class='no'>equi</span>)</div><div class='img'><img src='equivalence_test.effectsize_table-1.png' alt='' width='700' height='433' /></div><div class='input'>
+#&gt;  0.10 | [ 0.01,  0.19] |  Accepted</div><div class='input'>
+<span class='co'># Can also plot</span>
+<span class='kw'>if</span> (<span class='fu'><a href='https://rdrr.io/r/base/library.html'>require</a></span>(<span class='no'>see</span>)) <span class='fu'><a href='https://rdrr.io/r/graphics/plot.html'>plot</a></span>(<span class='no'>equi</span>)</div><div class='output co'>#&gt; <span class='message'>Loading required package: see</span></div><div class='img'><img src='equivalence_test.effectsize_table-1.png' alt='' width='700' height='433' /></div><div class='input'># }
 
-<span class='no'>model</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/aov.html'>aov</a></span>(<span class='no'>mpg</span> ~ <span class='fu'><a href='https://rdrr.io/r/base/factor.html'>factor</a></span>(<span class='no'>am</span>) * <span class='fu'><a href='https://rdrr.io/r/base/factor.html'>factor</a></span>(<span class='no'>cyl</span>), <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>mtcars</span>)
-<span class='no'>es</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='eta_squared.html'>eta_squared</a></span>(<span class='no'>model</span>)
-(<span class='no'>equi</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/bayestestR/man/equivalence_test.html'>equivalence_test</a></span>(<span class='no'>es</span>, <span class='kw'>range</span> <span class='kw'>=</span> <span class='fl'>0.15</span>))</div><div class='output co'>#&gt; </span><span style='color: #0000BB;'># Test for Practical Equivalence
-#&gt; 
-#&gt; </span><span>  ROPE: [0.00 0.15]
-#&gt; 
-#&gt; Parameter              | Eta_Sq_partial |       90% CI |        H0
-#&gt; ------------------------------------------------------------------
-#&gt; factor(am)             |           0.63 | [0.42, 0.75] |  Rejected
-#&gt; factor(cyl)            |           0.66 | [0.45, 0.77] |  Rejected
-#&gt; factor(am):factor(cyl) |           0.10 | [0.00, 0.27] | Undecided</div><div class='input'><span class='kw'>if</span> (<span class='fu'><a href='https://rdrr.io/r/base/library.html'>require</a></span>(<span class='no'>see</span>)) <span class='fu'><a href='https://rdrr.io/r/graphics/plot.html'>plot</a></span>(<span class='no'>equi</span>)</div><div class='img'><img src='equivalence_test.effectsize_table-2.png' alt='' width='700' height='433' /></div><div class='input'>
 </div></span></pre>
   </div>
   <div class=""col-md-3 hidden-xs hidden-sm"" id=""pkgdown-sidebar"">

---FILE: man/equivalence_test.effectsize_table.Rd---
@@ -23,16 +23,18 @@ Perform a \strong{Test for Practical Equivalence} for indices of effect size.
 }
 \examples{
 
+\donttest{
+model <- aov(mpg ~ factor(am) * factor(cyl), data = mtcars)
+es <- eta_squared(model)
+equivalence_test(es, range = 0.15)
+
 ds <- t_to_d(t = c(0.45, -0.65, -2.2, 2.25),
              df_error = c(675, 525, 900, 1875))
 (equi <- equivalence_test(ds, range = 0.2))
-if (require(see)) plot(equi)
 
-
-model <- aov(mpg ~ factor(am) * factor(cyl), data = mtcars)
-es <- eta_squared(model)
-(equi <- equivalence_test(es, range = 0.15))
+# Can also plot
 if (require(see)) plot(equi)
+}
 
 }
 \references{",True,False,Documentation / Formatting,6
easystats,effectsize,1f3e86ce52f004373bd20e034ed67f68e65f63ac,mattansb,35330040+mattansb@users.noreply.github.com,2020-04-20T14:55:19Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-04-20T14:55:19Z,fix error,R/interpret_d.R;R/interpret_r.R,False,True,True,False,2,2,4,"---FILE: R/interpret_d.R---
@@ -33,7 +33,7 @@ interpret_d <- function(d, rules = ""funder2019"") {
     } else if (rules == ""sawilowsky2009"") {
       return(interpret(abs(d), rules(c(0.1, 0.2, 0.5, 0.8, 1.2, 2), c(""tiny"", ""very small"", ""small"", ""medium"", ""large"", ""very large"", ""huge""))))
     } else {
-      stop(""rules must be 'cohen1988', 'sawilowsky2009' or an object of type rules."")
+      stop(""rules must be 'funder2019', 'gignac2016','cohen1988', 'sawilowsky2009' or an object of type rules."")
     }
   }
 }

---FILE: R/interpret_r.R---
@@ -54,7 +54,7 @@ interpret_r <- function(r, rules = ""funder2019"") {
         )
       )
     } else {
-      stop(""rules must be 'gignac2016', 'cohen1988', 'evans1996' or an object of type rules."")
+      stop(""rules must be 'funder2019', 'gignac2016', 'cohen1988', 'evans1996' or an object of type rules."")
     }
   }
 ",True,False,Implementation / Logic,6
easystats,effectsize,9efbeeba0f9834b41be6f66731bce545df5542ea,mattansb,35330040+mattansb@users.noreply.github.com,2020-04-16T12:56:21Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-04-16T12:56:21Z,"print returns original

https://github.com/easystats/easystats/issues/65",R/interpret.R;R/print.effectsize_table.R;R/print.rules.R,False,True,True,False,17,22,39,"---FILE: R/interpret.R---
@@ -61,27 +61,6 @@ is.rules <- function(x) inherits(x, ""rules"")
 
 
 
-#' @importFrom utils head
-#' @export
-print.rules <- function(x, ...){
-
-  if(length(x$values) == length(x$labels)){
-    insight::print_color(""# Reference values\n\n"", ""blue"")
-    df <- data.frame(t(rep(NA, length(x$labels))))
-    names(df) <- x$labels
-    df[1, ] <- x$values
-    cat(insight::format_table(df))
-  } else{
-    insight::print_color(""# Reference thresholds\n\n"", ""blue"")
-    cat(paste0(head(x$labels, -1), "" < "", x$values, "" < "", x$labels[-1], collapse = "" < ""))
-  }
-}
-
-
-
-
-
-
 
 
 # Interpret ---------------------------------------------------------------

---FILE: R/print.effectsize_table.R---
@@ -18,6 +18,6 @@ print.effectsize_table <- function(x, digits = 2, ...){
 
   cat(insight::format_table(x, digits = digits))
 
-  return(invisible(x_orig))
+  invisible(x_orig)
 }
 

---FILE: R/print.rules.R---
@@ -0,0 +1,16 @@
+#' @importFrom utils head
+#' @export
+print.rules <- function(x, ...){
+  orig_x <- x
+  if(length(x$values) == length(x$labels)){
+    insight::print_color(""# Reference values\n\n"", ""blue"")
+    df <- data.frame(t(rep(NA, length(x$labels))))
+    names(df) <- x$labels
+    df[1, ] <- x$values
+    cat(insight::format_table(df))
+  } else{
+    insight::print_color(""# Reference thresholds\n\n"", ""blue"")
+    cat(paste0(head(x$labels, -1), "" < "", x$values, "" < "", x$labels[-1], collapse = "" < ""))
+  }
+  invisible(orig_x)
+}
\ No newline at end of file",True,False,Implementation / Logic,6
easystats,effectsize,f97ef6f500ea80607271099da32c7afba20ef6a7,mattansb,35330040+mattansb@users.noreply.github.com,2020-04-11T12:55:56Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-04-11T12:55:56Z,fix cran warnings,DESCRIPTION;R/print.effectsize_table.R;vignettes/standardize_data.Rmd,True,True,True,False,3,2,5,"---FILE: DESCRIPTION---
@@ -44,6 +44,7 @@ Suggests:
 	afex,
 	brms,
 	boot,
+	car,
 	correlation,
 	covr,
 	dplyr,

---FILE: R/print.effectsize_table.R---
@@ -1,5 +1,5 @@
 #' @export
-print.effectsize_table <- function(x, digits = 2){
+print.effectsize_table <- function(x, digits = 2, ...){
   x_orig <- x
 
   if (""CI"" %in% colnames(x)) {

---FILE: vignettes/standardize_data.Rmd---
@@ -133,7 +133,7 @@ print_summary(Z_Full)
 The **means** and the **SD** appear as fairly similar (0 and 1)...
 
 ##  Distribution
-```{r, fig.width=7, fig.height=4.5, eval = TRUE, results='markup', fig.align='center', comment=NA, message=FALSE, warning=FALSE}
+```{r, fig.width=7, fig.height=4.5, eval = requireNamespace(""KernSmooth"", quietly = TRUE), results='markup', fig.align='center', comment=NA, message=FALSE, warning=FALSE}
 library(bayestestR)
 library(see)
 ",True,True,Dependency / Package,7
easystats,effectsize,272e181aa500813f08e94ae436ad93060d6ef739,Daniel,mail@danielluedecke.de,2020-04-03T13:54:39Z,Daniel,mail@danielluedecke.de,2020-04-03T13:54:39Z,hotfix,R/eta_squared.R,False,True,True,False,1,1,2,"---FILE: R/eta_squared.R---
@@ -303,7 +303,7 @@ cohens_f <- function(model, partial = TRUE, ci = 0.9, ...) {
                                        ...) {
   type <- match.arg(type)
 
-  if (""Group"" %in% colnames(model)) {
+  if (""Group"" %in% colnames(model) && sum(model$Parameter == ""Residuals"") > 1) {
     x <- split(model, model$Group)
     out <- do.call(rbind, lapply(x, function(i) {
       f <- i[[""F""]]",True,False,Implementation / Logic,6
easystats,effectsize,ed5c1d3363840034d56b99f660d894c7f952b1fb,mattansb,35330040+mattansb@users.noreply.github.com,2020-03-30T09:02:10Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-03-30T09:02:10Z,fix unequal group size,R/cohens_d.R;docs/articles/standardize_parameters.html;docs/reference/cohens_d.html;tests/testthat/test_standardized_differences.R,False,True,True,False,20,19,39,"---FILE: R/cohens_d.R---
@@ -122,14 +122,15 @@ glass_delta <- function(x, y = NULL, data = NULL, correction = FALSE, ci = 0.95)
     d <- mean(x - y, na.rm = TRUE)
     s <- stats::sd(x - y, na.rm = TRUE)
     n <- length(x)
-    df <- n - 1
+    hn <- n - 1
     t <- d / (s / sqrt(n))
   } else {
     d <- mean(x, na.rm = TRUE) - mean(y, na.rm = TRUE)
     n1 <- length(x)
     n2 <- length(y)
     n <- n1 + n2
-    df <- n - 2
+    # hn <- n - 2
+    hn <- 4 / (1 / n1 + 1 / n2) # When giving this ti t_to_d it is like using the harmonic mean of n
     if (type == ""d"" | type == ""g"") {
       if (pooled_sd) {
         s <- suppressWarnings(sd_pooled(x, y))
@@ -152,7 +153,7 @@ glass_delta <- function(x, y = NULL, data = NULL, correction = FALSE, ci = 0.95)
   colnames(out) <- types[type]
   out <- cbind(
     out,
-    t_to_d(t, df, ci = ci, paired = paired)[,-1 , drop = FALSE]
+    t_to_d(t, hn, ci = ci, paired = paired)[,-1 , drop = FALSE]
   )
 
   if (type == ""g"") {

---FILE: docs/articles/standardize_parameters.html---
@@ -229,7 +229,7 @@ <h2 class=""hasAnchor"">
 <div class=""sourceCode"" id=""cb10""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb10-1"" title=""1""><span class=""kw""><a href=""../reference/cohens_d.html"">cohens_d</a></span>(Sepal.Length <span class=""op"">~</span><span class=""st""> </span>Species, <span class=""dt"">data =</span> data) </a></code></pre></div>
 <pre><code>&gt; Cohens_d |         95% CI
 &gt; -------------------------
-&gt;    -2.10 | [-2.62, -1.63]</code></pre>
+&gt;    -2.10 | [-2.59, -1.61]</code></pre>
 <p><strong><em>It is very different!</em></strong> Why? How? Both differences should be expressed in units of SD! But which SDs? Different SDs!</p>
 <p>When looking at the difference between groups as a <strong>slope</strong>, the standardized parameter is the difference between the means in <span class=""math inline"">\(SD_{Sepal.Length}\)</span>. That is, the <em>slope</em> between <code>setosa</code> and <code>versicolor</code> is a change of 1.45 <span class=""math inline"">\(SD_{Sepal.Length}\)</span>.</p>
 <p>However, when looking a the difference as a distance between two populations, Cohenâs d is the distance between the means in units of <a href=""https://easystats.github.io/effectsize/reference/sd_pooled.html""><strong>pooled SDs</strong></a>. That is, the <em>distance</em> between <code>setosa</code> and <code>versicolor</code> is of 2.1 SDs of each of the groups (here assumed to be equal).</p>
@@ -267,7 +267,7 @@ <h2 class=""hasAnchor"">
 <a class=""sourceLine"" id=""cb17-2"" title=""2"">            data<span class=""op"">$</span>Sepal.Length[data<span class=""op"">$</span>Species<span class=""op"">==</span><span class=""st"">""setosa""</span>])</a></code></pre></div>
 <pre><code>&gt; Glass_delta |       95% CI
 &gt; --------------------------
-&gt;        2.64 | [2.12, 3.21]</code></pre>
+&gt;        2.64 | [2.10, 3.17]</code></pre>
 <div class=""sourceCode"" id=""cb19""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb19-1"" title=""1""><span class=""co""># glass_delta takes SD from second group</span></a></code></pre></div>
 <p><strong><em>â¦ So note that some standardized differences are difference than others! :)</em></strong></p>
 </div>

---FILE: docs/reference/cohens_d.html---
@@ -240,18 +240,18 @@ <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>R
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='fu'>cohens_d</span>(<span class='no'>iris</span>$<span class='no'>Sepal.Length</span>, <span class='no'>iris</span>$<span class='no'>Sepal.Width</span>)</div><div class='output co'>#&gt; Cohens_d |       95% CI
 #&gt; -----------------------
-#&gt;     4.21 | [3.82, 4.63]</div><div class='input'><span class='fu'>hedges_g</span>(<span class='st'>""Sepal.Length""</span>, <span class='st'>""Sepal.Width""</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>iris</span>)</div><div class='output co'>#&gt; Hedges_g |       95% CI
+#&gt;     4.21 | [3.80, 4.61]</div><div class='input'><span class='fu'>hedges_g</span>(<span class='st'>""Sepal.Length""</span>, <span class='st'>""Sepal.Width""</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>iris</span>)</div><div class='output co'>#&gt; Hedges_g |       95% CI
 #&gt; -----------------------
-#&gt;     4.20 | [3.81, 4.62]</div><div class='input'>
+#&gt;     4.20 | [3.79, 4.60]</div><div class='input'>
 <span class='fu'>cohens_d</span>(<span class='no'>mpg</span> ~ <span class='no'>am</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>mtcars</span>)</div><div class='output co'>#&gt; Cohens_d |         95% CI
 #&gt; -------------------------
-#&gt;    -1.48 | [-2.30, -0.68]</div><div class='input'><span class='fu'>cohens_d</span>(<span class='no'>mpg</span> ~ <span class='no'>am</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>mtcars</span>, <span class='kw'>pooled_sd</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)</div><div class='output co'>#&gt; Cohens_d |         95% CI
+#&gt;    -1.48 | [-2.26, -0.67]</div><div class='input'><span class='fu'>cohens_d</span>(<span class='no'>mpg</span> ~ <span class='no'>am</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>mtcars</span>, <span class='kw'>pooled_sd</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)</div><div class='output co'>#&gt; Cohens_d |         95% CI
 #&gt; -------------------------
-#&gt;    -1.41 | [-2.16, -0.57]</div><div class='input'><span class='fu'>hedges_g</span>(<span class='no'>mpg</span> ~ <span class='no'>am</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>mtcars</span>)</div><div class='output co'>#&gt; Hedges_g |         95% CI
+#&gt;    -1.41 | [-2.13, -0.57]</div><div class='input'><span class='fu'>hedges_g</span>(<span class='no'>mpg</span> ~ <span class='no'>am</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>mtcars</span>)</div><div class='output co'>#&gt; Hedges_g |         95% CI
 #&gt; -------------------------
-#&gt;    -1.44 | [-2.24, -0.66]</div><div class='input'><span class='fu'>glass_delta</span>(<span class='no'>mpg</span> ~ <span class='no'>am</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>mtcars</span>)</div><div class='output co'>#&gt; Glass_delta |         95% CI
+#&gt;    -1.44 | [-2.21, -0.66]</div><div class='input'><span class='fu'>glass_delta</span>(<span class='no'>mpg</span> ~ <span class='no'>am</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>mtcars</span>)</div><div class='output co'>#&gt; Glass_delta |         95% CI
 #&gt; ----------------------------
-#&gt;       -1.17 | [-1.96, -0.41]</div><div class='input'>
+#&gt;       -1.17 | [-1.93, -0.40]</div><div class='input'>
 </div></pre>
   </div>
   <div class=""col-md-3 hidden-xs hidden-sm"" id=""sidebar"">

---FILE: tests/testthat/test_standardized_differences.R---
@@ -37,32 +37,32 @@ if (require(""testthat"") && require(""effectsize"")) {
     x <- cohens_d(wt ~ am, data = mtcars, pooled_sd = TRUE)
     testthat::expect_equal(colnames(x)[1], ""Cohens_d"")
     testthat::expect_equal(x[[1]], 1.892, tol = 0.001)
-    testthat::expect_equal(x$CI_low, 1.044, tol = 0.001)
-    testthat::expect_equal(x$CI_high, 2.772, tol = 0.001)
+    testthat::expect_equal(x$CI_low, 1.033, tol = 0.001)
+    testthat::expect_equal(x$CI_high, 2.729, tol = 0.001)
   })
 
   test_that(""cohens_d - non-pooled"", {
     x <- cohens_d(wt ~ am, data = mtcars, pooled_sd = FALSE)
     testthat::expect_equal(colnames(x)[1], ""Cohens_d"")
     testthat::expect_equal(x[[1]], 1.934, tol = 0.001)
-    testthat::expect_equal(x$CI_low, 1.118, tol = 0.001)
-    testthat::expect_equal(x$CI_high, 2.870, tol = 0.001)
+    testthat::expect_equal(x$CI_low, 1.106, tol = 0.001)
+    testthat::expect_equal(x$CI_high, 2.826, tol = 0.001)
   })
 
   test_that(""hedges_g"", {
     x <- hedges_g(wt ~ am, data = mtcars)
     testthat::expect_equal(colnames(x)[1], ""Hedges_g"")
     testthat::expect_equal(x[[1]], 1.844, tol = 0.001)
-    testthat::expect_equal(x$CI_low, 1.018, tol = 0.001)
-    testthat::expect_equal(x$CI_high, 2.702, tol = 0.001)
+    testthat::expect_equal(x$CI_low, 1.007, tol = 0.001)
+    testthat::expect_equal(x$CI_high, 2.660, tol = 0.001)
   })
 
   test_that(""glass_delta"", {
     x <- glass_delta(wt ~ am, data = mtcars)
     testthat::expect_equal(colnames(x)[1], ""Glass_delta"")
     testthat::expect_equal(x[[1]], 2.200, tol = 0.001)
-    testthat::expect_equal(x$CI_low, 1.310, tol = 0.001)
-    testthat::expect_equal(x$CI_high, 3.131, tol = 0.001)
+    testthat::expect_equal(x$CI_low, 1.297, tol = 0.001)
+    testthat::expect_equal(x$CI_high, 3.081, tol = 0.001)
 
     # must be 2 samples
     testthat::expect_error(glass_delta(1:10))",True,False,Implementation / Logic,6
easystats,effectsize,e89b137f9953c854d05dc6e6cff94af1452b67b7,mattansb,35330040+mattansb@users.noreply.github.com,2020-03-29T12:45:55Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-03-29T12:45:55Z,fix example order,R/convert_tFz_to_r.R;docs/reference/t_to_r.html;man/t_to_r.Rd,False,True,True,False,21,36,57,"---FILE: R/convert_tFz_to_r.R---
@@ -55,14 +55,13 @@
 #' model <- lm(Sepal.Length ~ Sepal.Width + Petal.Length, data = iris)
 #' library(parameters)
 #' (param_tab <- parameters(model))
-#' # > Parameter    | Coefficient |   SE |       95% CI |     t |  df |      p
-#' # > -----------------------------------------------------------------------
-#' # > (Intercept)  |        2.25 | 0.25 | [1.76, 2.74] |  9.07 | 147 | < .001
-#' # > Sepal.Width  |        0.60 | 0.07 | [0.46, 0.73] |  8.59 | 147 | < .001
-#' # > Petal.Length |        0.47 | 0.02 | [0.44, 0.51] | 27.57 | 147 | < .001
 #'
 #' t_to_r(param_tab$t[2:3], param_tab$df_error[2:3])
-#' # > [1] 0.5781005 0.9153894
+#'
+#' # How does this compare to actual partial correlations?
+#' if (require(""ppcor"")) {
+#'   pcor(iris[1:3])$estimate[1, -1]
+#' }
 #'
 #' ## Use with emmeans based contrasts (see also t_to_eta2)
 #' if (require(emmeans) & require(dplyr)) {
@@ -74,10 +73,6 @@
 #'     bind_cols(t_to_d(.$t.ratio, .$df))
 #' }
 #'
-#' # How does this compare to actual partial correlations?
-#' if (require(""ppcor"")) {
-#'   pcor(iris[1:3])$estimate[1, -1]
-#' }
 #' }
 #' @references
 #' \itemize{

---FILE: docs/reference/t_to_r.html---
@@ -278,17 +278,19 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
 #&gt; -----------------------------------------------------------------------
 #&gt; (Intercept)  |        2.25 | 0.25 | [1.76, 2.74] |  9.07 | 147 | &lt; .001
 #&gt; Sepal.Width  |        0.60 | 0.07 | [0.46, 0.73] |  8.59 | 147 | &lt; .001
-#&gt; Petal.Length |        0.47 | 0.02 | [0.44, 0.51] | 27.57 | 147 | &lt; .001</div><div class='input'><span class='co'># &gt; Parameter    | Coefficient |   SE |       95% CI |     t |  df |      p</span>
-<span class='co'># &gt; -----------------------------------------------------------------------</span>
-<span class='co'># &gt; (Intercept)  |        2.25 | 0.25 | [1.76, 2.74] |  9.07 | 147 | &lt; .001</span>
-<span class='co'># &gt; Sepal.Width  |        0.60 | 0.07 | [0.46, 0.73] |  8.59 | 147 | &lt; .001</span>
-<span class='co'># &gt; Petal.Length |        0.47 | 0.02 | [0.44, 0.51] | 27.57 | 147 | &lt; .001</span>
-
+#&gt; Petal.Length |        0.47 | 0.02 | [0.44, 0.51] | 27.57 | 147 | &lt; .001</div><div class='input'>
 <span class='fu'>t_to_r</span>(<span class='no'>param_tab</span>$<span class='no'>t</span>[<span class='fl'>2</span>:<span class='fl'>3</span>], <span class='no'>param_tab</span>$<span class='no'>df_error</span>[<span class='fl'>2</span>:<span class='fl'>3</span>])</div><div class='output co'>#&gt;    r |       95% CI
 #&gt; -------------------
 #&gt; 0.58 | [0.47, 0.66]
-#&gt; 0.92 | [0.89, 0.93]</div><div class='input'><span class='co'># &gt; [1] 0.5781005 0.9153894</span>
-
+#&gt; 0.92 | [0.89, 0.93]</div><div class='input'>
+<span class='co'># How does this compare to actual partial correlations?</span>
+<span class='kw'>if</span> (<span class='fu'><a href='https://rdrr.io/r/base/library.html'>require</a></span>(<span class='st'>""ppcor""</span>)) {
+  <span class='fu'><a href='https://rdrr.io/pkg/ppcor/man/pcor.html'>pcor</a></span>(<span class='no'>iris</span>[<span class='fl'>1</span>:<span class='fl'>3</span>])$<span class='no'>estimate</span>[<span class='fl'>1</span>, -<span class='fl'>1</span>]
+}</div><div class='output co'>#&gt; <span class='message'>Loading required package: ppcor</span></div><div class='output co'>#&gt; <span class='message'>Loading required package: MASS</span></div><div class='output co'>#&gt; <span class='message'></span>
+#&gt; <span class='message'>Attaching package: 'MASS'</span></div><div class='output co'>#&gt; <span class='message'>The following object is masked from 'package:dplyr':</span>
+#&gt; <span class='message'></span>
+#&gt; <span class='message'>    select</span></div><div class='output co'>#&gt;  Sepal.Width Petal.Length 
+#&gt;    0.5781005    0.9153894 </div><div class='input'>
 <span class='co'>## Use with emmeans based contrasts (see also t_to_eta2)</span>
 <span class='kw'>if</span> (<span class='fu'><a href='https://rdrr.io/r/base/library.html'>require</a></span>(<span class='no'>emmeans</span>) <span class='kw'>&amp;</span> <span class='fu'><a href='https://rdrr.io/r/base/library.html'>require</a></span>(<span class='no'>dplyr</span>)) {
   <span class='no'>warp.lm</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/lm.html'>lm</a></span>(<span class='no'>breaks</span> ~ <span class='no'>wool</span> * <span class='no'>tension</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>warpbreaks</span>)
@@ -310,14 +312,7 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
 #&gt;  M - H      10.000 5.16 48  1.939  0.1389   0.5597 0.95 -0.0198   1.134
 #&gt; 
 #&gt; P value adjustment: tukey method for comparing a family of 3 estimates </div><div class='input'>
-<span class='co'># How does this compare to actual partial correlations?</span>
-<span class='kw'>if</span> (<span class='fu'><a href='https://rdrr.io/r/base/library.html'>require</a></span>(<span class='st'>""ppcor""</span>)) {
-  <span class='fu'><a href='https://rdrr.io/pkg/ppcor/man/pcor.html'>pcor</a></span>(<span class='no'>iris</span>[<span class='fl'>1</span>:<span class='fl'>3</span>])$<span class='no'>estimate</span>[<span class='fl'>1</span>, -<span class='fl'>1</span>]
-}</div><div class='output co'>#&gt; <span class='message'>Loading required package: ppcor</span></div><div class='output co'>#&gt; <span class='message'>Loading required package: MASS</span></div><div class='output co'>#&gt; <span class='message'></span>
-#&gt; <span class='message'>Attaching package: 'MASS'</span></div><div class='output co'>#&gt; <span class='message'>The following object is masked from 'package:dplyr':</span>
-#&gt; <span class='message'></span>
-#&gt; <span class='message'>    select</span></div><div class='output co'>#&gt;  Sepal.Width Petal.Length 
-#&gt;    0.5781005    0.9153894 </div><div class='input'># }
+# }
 </div></pre>
   </div>
   <div class=""col-md-3 hidden-xs hidden-sm"" id=""sidebar"">

---FILE: man/t_to_r.Rd---
@@ -101,14 +101,13 @@ t_to_r(t = res$statistic, res$parameter)
 model <- lm(Sepal.Length ~ Sepal.Width + Petal.Length, data = iris)
 library(parameters)
 (param_tab <- parameters(model))
-# > Parameter    | Coefficient |   SE |       95\% CI |     t |  df |      p
-# > -----------------------------------------------------------------------
-# > (Intercept)  |        2.25 | 0.25 | [1.76, 2.74] |  9.07 | 147 | < .001
-# > Sepal.Width  |        0.60 | 0.07 | [0.46, 0.73] |  8.59 | 147 | < .001
-# > Petal.Length |        0.47 | 0.02 | [0.44, 0.51] | 27.57 | 147 | < .001
 
 t_to_r(param_tab$t[2:3], param_tab$df_error[2:3])
-# > [1] 0.5781005 0.9153894
+
+# How does this compare to actual partial correlations?
+if (require(""ppcor"")) {
+  pcor(iris[1:3])$estimate[1, -1]
+}
 
 ## Use with emmeans based contrasts (see also t_to_eta2)
 if (require(emmeans) & require(dplyr)) {
@@ -120,10 +119,6 @@ if (require(emmeans) & require(dplyr)) {
     bind_cols(t_to_d(.$t.ratio, .$df))
 }
 
-# How does this compare to actual partial correlations?
-if (require(""ppcor"")) {
-  pcor(iris[1:3])$estimate[1, -1]
-}
 }
 }
 \references{",True,False,Documentation / Formatting,6
easystats,effectsize,78b1fe4609df67f44899ab2cf617c126696f93e2,mattansb,35330040+mattansb@users.noreply.github.com,2020-03-28T17:50:22Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-03-28T17:50:22Z,fix warnings in tests,tests/testthat/test-standardize.R,False,True,True,False,3,3,6,"---FILE: tests/testthat/test-standardize.R---
@@ -15,12 +15,12 @@ if (require(""testthat"") && require(""effectsize"") && require(""dplyr"") && require(
     x <- standardize(iris)
     testthat::expect_equal(mean(x$Sepal.Length), 0, tol = 0.01)
     testthat::expect_length(levels(x$Species), 3)
-    testthat::expect_equal(mean(dplyr::filter_(x, ""Species == 'virginica'"")$Sepal.Length), 0.89, tol = 0.01)
+    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 0.89, tol = 0.01)
 
-    x <- standardize(dplyr::group_by_(iris, ""Species""))
+    x <- standardize(dplyr::group_by(iris, Species))
     testthat::expect_equal(mean(x$Sepal.Length), 0, tol = 0.01)
     testthat::expect_length(levels(x$Species), 3)
-    testthat::expect_equal(mean(dplyr::filter_(x, ""Species == 'virginica'"")$Sepal.Length), 0, tol = 0.01)
+    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 0, tol = 0.01)
   })
 
 ",True,False,Implementation / Logic,6
easystats,effectsize,28421c82f40db5875b40fab2853c9f64009012e9,mattansb,35330040+mattansb@users.noreply.github.com,2020-03-27T07:21:06Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-03-27T07:21:06Z,example fix,R/sd_pooled.R;man/sd_pooled.Rd,False,True,True,False,2,2,4,"---FILE: R/sd_pooled.R---
@@ -6,7 +6,7 @@
 #'
 #' @return Numeric, the pooled standard deviation.
 #' @examples
-#' sd_pooled(Sepal.Length ~ Petal.Width, data = iris)
+#' sd_pooled(mpg ~ am, data = mtcars)
 #'
 #' @export
 sd_pooled <- function(x, y = NULL, data = NULL) {

---FILE: man/sd_pooled.Rd---
@@ -23,6 +23,6 @@ Numeric, the pooled standard deviation.
 The Pooled Standard Deviation is a weighted average of standard deviations for two or more groups, with more ""weight"" given to larger sample sizes.
 }
 \examples{
-sd_pooled(Sepal.Length ~ Petal.Width, data = iris)
+sd_pooled(mpg ~ am, data = mtcars)
 
 }",True,False,Documentation / Formatting,6
easystats,effectsize,29ad9dcb5d6284256aac137c8571ddc972e8191b,mattansb,35330040+mattansb@users.noreply.github.com,2020-03-26T14:45:40Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-03-26T14:45:40Z,"fix data validation in cohens_d

#44",NEWS.md;R/cohens_d.R;R/sd_pooled.R;man/cohens_d.Rd;man/sd_pooled.Rd;tests/testthat/test_standardized_differences.R,False,True,True,False,107,66,173,"---FILE: NEWS.md---
@@ -11,6 +11,10 @@
 - `standardize()` for model-objects has a default-method, which usually accepts all models. Exception for model-objects that do not work will be added if missing.
 - `standardize.data.frame()` gets `append` and `suffix` arguments, to add (instead of replace) standardized variables to the returned data frame.
 
+## Bug fixes
+
+- Fix `cohens_d()`'s dealing with formula input (#44).
+
 ## Changes
 
 - In `t_to_d()`, argument `pooled` is now `paired`.

---FILE: R/cohens_d.R---
@@ -2,10 +2,10 @@
 #'
 #' Compute different indices of effect size. For very small sample sizes (n < 20) Hedges' g is considered as less biased than Cohen's d. For sample sizes > 20, the results for both statistics are roughly equivalent. The Glassâs delta is appropriate if standard deviations are significantly different between groups, as it uses only the control group's (\code{x}) standard deviation.
 #'
-#' @param x A continuous variable or a formula.
-#' @param y A continuous variable, a factor with two groups or a formula.
+#' @param x A formula, a numeric vector, or a name of one in \code{data}.
+#' @param y A numeric vector, a grouping (character / factor) vector, a or a name of one in \code{data}. Ignored if \code{x} is a formula.
 #' @param data An optional data frame containing the variables.
-#' @param correction If \code{TRUE}, applies a correction to the formula to make it less biased for small samples (McGrath & Meyer, 2006).
+#' @param correction If \code{TRUE}, applies a correction to make it less biased for small samples (McGrath & Meyer, 2006).
 #' @param pooled_sd If \code{FALSE}, the regular SD from both combined groups is used instead of the \code{\link{sd_pooled}}.
 #' @param paired If \code{TRUE}, the values of \code{x} and \code{y} are considered as paired.
 #' @inheritParams chisq_to_phi
@@ -76,16 +76,9 @@ glass_delta <- function(x, y = NULL, data = NULL, correction = FALSE, ci = 0.95)
 
 
 
-
-
-
-
-
-
-
 #' @importFrom stats sd
 #' @keywords internal
-.effect_size_difference <- function(x, y = NULL, data = NULL, type = ""d"", correction = FALSE, pooled_sd = TRUE, paired = FALSE, ci = ci) {
+.effect_size_difference <- function(x, y = NULL, data = NULL, type = ""d"", correction = FALSE, pooled_sd = TRUE, paired = FALSE, ci = 0.95) {
   out <- .deal_with_cohens_d_arguments(x, y, data)
   x <- out$x
   y <- out$y
@@ -106,7 +99,7 @@ glass_delta <- function(x, y = NULL, data = NULL, correction = FALSE, ci = 0.95)
       denominator <- stats::sd(x - y, na.rm = TRUE)
     } else {
       if (pooled_sd) {
-        denominator <- sd_pooled(x, y)
+        denominator <- suppressWarnings(sd_pooled(x, y))
       } else {
         denominator <- stats::sd(c(x, y), na.rm = TRUE)
       }
@@ -150,6 +143,10 @@ glass_delta <- function(x, y = NULL, data = NULL, correction = FALSE, ci = 0.95)
 
 
 
+# Utils -------------------------------------------------------------------
+
+
+
 #' @keywords internal
 .deal_with_cohens_d_arguments <- function(x, y = NULL, data = NULL) {
 
@@ -160,14 +157,24 @@ glass_delta <- function(x, y = NULL, data = NULL, correction = FALSE, ci = 0.95)
     }
   }
 
+  ## Preprocess data
 
-  # Preprocess data
+  # Formula
   if (inherits(x, ""formula"")) {
-    data <- model.frame(x, data = data)
-    x <- names(data)[1]
-    y <- names(data)[2]
+    trms <- terms(x)
+
+    group <- all.vars(delete.response(trms))
+    outcome <- setdiff(all.vars(trms),group)
+
+    if (!(length(outcome) == 1 & length(group) == 1)) {
+      stop(""Formula must have the 'outcome ~ group'."", call. = FALSE)
+    }
+
+    x <- data[[outcome]]
+    y <- as.factor(data[[group]])
   }
 
+
   if (is.character(x)) {
     x <- data[[x]]
   }
@@ -176,20 +183,29 @@ glass_delta <- function(x, y = NULL, data = NULL, correction = FALSE, ci = 0.95)
     y <- data[[y]]
   }
 
+  if (!is.numeric(x)) {
+    stop(""Cannot compute effect size for a non-numeric vector."", call. = FALSE)
+  }
 
   # If y is a factor
   if (!is.null(y)) {
-    if (is.factor(y) | is.character(y)) {
-      if (length(x) != length(y)) {
-        stop(""The length of the group factor must be the same."")
-      }
+    if (!is.numeric(y)) {
       if (length(unique(y)) > 2) {
-        stop(""Cannot compute the difference as a factor with more than 2 levels has been provided."")
-      } else {
-        groups <- as.character(y)
-        y <- x[groups == unique(groups)[2]]
-        x <- x[groups == unique(groups)[1]]
+        stop(""Cannot compute the difference as a factor with more than 2 levels has been provided."",
+             call. = FALSE)
       }
+      if (length(x) != length(y)) {
+        stop(""Grouping variable must be the same length."", call. = FALSE)
+      }
+
+      data <- split(x, y)
+      x <- data[[1]]
+      y <- data[[2]]
+    } else if (length(unique(y)) == 2) {
+      warning(
+        ""'y' is numeric but has only 2 unique values. If this is a grouping variable, convert it to a factor."",
+        call. = FALSE
+      )
     }
   }
 

---FILE: R/sd_pooled.R---
@@ -81,39 +81,34 @@ mad_pooled <- function(x, y = NULL, data = NULL) {
 
 
 
-
-
-
-.evaluate_arguments <- function(x, y, data) {
-  eval_x <- .evaluate_argument(x)
-  if (!is.null(eval_x$variable)) x <- eval_x$variable
-  if (!is.null(eval_x$data) && is.null(data)) data <- get(eval_x$data)
-
-  eval_y <- .evaluate_argument(y)
-  if (!is.null(eval_y$variable)) y <- eval_y$variable
-  if (!is.null(eval_y$data) && is.null(data)) data <- get(eval_y$data)
-
-  list(x = x, y = y, data = data)
-}
-
-
-
-
-.evaluate_argument <- function(arg) {
-  data_frame <- NULL
-  if (!is.null(arg)) {
-    if (is.numeric(arg) && length(arg) > 1) {
-      # do nothiung
-    } else if (arg == ""NULL"") {
-      arg <- NULL
-    } else if (grepl(""~"", arg, fixed = TRUE)) {
-      arg <- stats::as.formula(arg)
-    } else if (grepl(""\"""", arg, fixed = TRUE)) {
-      arg <- gsub(""\"""", """", arg, fixed = TRUE)
-    } else if (grepl(""$"", arg, fixed = TRUE)) {
-      data_frame <- gsub(""(.*)\\$(.*)"", ""\\1"", arg)
-      arg <- gsub(""(.*)\\$(.*)"", ""\\2"", arg)
-    }
-  }
-  list(variable = arg, data = data_frame)
-}
\ No newline at end of file
+# .evaluate_arguments <- function(x, y, data) {
+#   eval_x <- .evaluate_argument(x)
+#   if (!is.null(eval_x$variable)) x <- eval_x$variable
+#   if (!is.null(eval_x$data) && is.null(data)) data <- get(eval_x$data)
+#
+#   eval_y <- .evaluate_argument(y)
+#   if (!is.null(eval_y$variable)) y <- eval_y$variable
+#   if (!is.null(eval_y$data) && is.null(data)) data <- get(eval_y$data)
+#
+#   list(x = x, y = y, data = data)
+# }
+
+
+# .evaluate_argument <- function(arg) {
+#   data_frame <- NULL
+#   if (!is.null(arg)) {
+#     if (is.numeric(arg) && length(arg) > 1) {
+#       # do nothiung
+#     } else if (arg == ""NULL"") {
+#       arg <- NULL
+#     } else if (grepl(""~"", arg, fixed = TRUE)) {
+#       arg <- stats::as.formula(arg)
+#     } else if (grepl(""\"""", arg, fixed = TRUE)) {
+#       arg <- gsub(""\"""", """", arg, fixed = TRUE)
+#     } else if (grepl(""$"", arg, fixed = TRUE)) {
+#       data_frame <- gsub(""(.*)\\$(.*)"", ""\\1"", arg)
+#       arg <- gsub(""(.*)\\$(.*)"", ""\\2"", arg)
+#     }
+#   }
+#   list(variable = arg, data = data_frame)
+# }
\ No newline at end of file

---FILE: man/cohens_d.Rd---
@@ -29,13 +29,13 @@ hedges_g(
 glass_delta(x, y = NULL, data = NULL, correction = FALSE, ci = 0.95)
 }
 \arguments{
-\item{x}{A continuous variable or a formula.}
+\item{x}{A formula, a numeric vector, or a name of one in \code{data}.}
 
-\item{y}{A continuous variable, a factor with two groups or a formula.}
+\item{y}{A numeric vector, a grouping (character / factor) vector, a or a name of one in \code{data}. Ignored if \code{x} is a formula.}
 
 \item{data}{An optional data frame containing the variables.}
 
-\item{correction}{If \code{TRUE}, applies a correction to the formula to make it less biased for small samples (McGrath & Meyer, 2006).}
+\item{correction}{If \code{TRUE}, applies a correction to make it less biased for small samples (McGrath & Meyer, 2006).}
 
 \item{pooled_sd}{If \code{FALSE}, the regular SD from both combined groups is used instead of the \code{\link{sd_pooled}}.}
 

---FILE: man/sd_pooled.Rd---
@@ -10,9 +10,9 @@ sd_pooled(x, y = NULL, data = NULL)
 mad_pooled(x, y = NULL, data = NULL)
 }
 \arguments{
-\item{x}{A continuous variable or a formula.}
+\item{x}{A formula, a numeric vector, or a name of one in \code{data}.}
 
-\item{y}{A continuous variable, a factor with two groups or a formula.}
+\item{y}{A numeric vector, a grouping (character / factor) vector, a or a name of one in \code{data}. Ignored if \code{x} is a formula.}
 
 \item{data}{An optional data frame containing the variables.}
 }

---FILE: tests/testthat/test_standardized_differences.R---
@@ -1,7 +1,33 @@
 if (require(""testthat"") && require(""effectsize"")) {
   test_that(""cohens_d"", {
+
+    # Direction ---------------------------------------------------------------
     rez_t <- t.test(iris$Sepal.Length, iris$Sepal.Width)
     rez_d <- cohens_d(iris$Sepal.Length, iris$Sepal.Width)
     testthat::expect_true(sign(rez_t$statistic) == sign(rez_d$Cohens_d))
+
+
+    # Errors and warnings -----------------------------------------------------
+    df <- data.frame(
+      a = 1:10,
+      b = 2:11,
+      c = rep(letters[1:2], each = 5),
+      d = sample(letters[1:3], 10, replace = T),
+      e = rep(0:1, each = 5)
+    )
+    a2 <- 1:11
+
+    testthat::expect_true({cohens_d(a ~ c, data = df); TRUE})
+    testthat::expect_true({cohens_d(""a"", ""c"", data = df); TRUE})
+    testthat::expect_true({cohens_d(""a"", ""b"", data = df); TRUE})
+    testthat::expect_true({cohens_d(a2, df$b); TRUE})
+
+    testthat::expect_error(cohens_d(a ~ b, data = df))
+    testthat::expect_error(cohens_d(a ~ d, data = df))
+    testthat::expect_error(cohens_d(""a"", ""d"", data = df))
+    testthat::expect_error(cohens_d(""c"", ""c"", data = df))
+    testthat::expect_error(cohens_d(a2, df$c))
+
+    testthat::expect_warning(cohens_d(""b"", ""e"", data = df))
   })
 }
\ No newline at end of file",True,False,Documentation / Formatting,6
easystats,effectsize,597c87657f3f518765d639263140f8799baa15d4,mattansb,35330040+mattansb@users.noreply.github.com,2020-03-26T06:10:01Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-03-26T06:10:01Z,fix test,tests/testthat/test_standardized_differences.R,False,True,True,False,1,1,2,"---FILE: tests/testthat/test_standardized_differences.R---
@@ -2,6 +2,6 @@ if (require(""testthat"") && require(""effectsize"")) {
   test_that(""cohens_d"", {
     rez_t <- t.test(iris$Sepal.Length, iris$Sepal.Width)
     rez_d <- cohens_d(iris$Sepal.Length, iris$Sepal.Width)
-    testthat::expect_true(sign(rez_t$statistic) == sign(rez_d))
+    testthat::expect_true(sign(rez_t$statistic) == sign(rez_d$Cohens_d))
   })
 }
\ No newline at end of file",True,False,Dependency / Package,3
easystats,effectsize,4595b4cfbd408c3d7367d2f0a7caa1a86809065c,mattansb,35330040+mattansb@users.noreply.github.com,2020-03-24T15:54:50Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-03-24T15:54:50Z,fix urls,docs/404.html;docs/articles/convert.html;docs/articles/interpret.html;docs/articles/standardize_data.html;docs/articles/standardize_parameters.html;docs/news/index.html;docs/reference/F_to_eta2.html;docs/reference/adjust.html;docs/reference/change_scale.html;docs/reference/chisq_to_phi.html;docs/reference/cohens_d.html;docs/reference/convert_z_to_percentile.html;docs/reference/d_to_r.html;docs/reference/dot-factor_to_numeric.html;docs/reference/eta_squared.html;docs/reference/format_standardize.html;docs/reference/index.html;docs/reference/interpret.html;docs/reference/interpret_bf.html;docs/reference/interpret_d.html;docs/reference/interpret_direction.html;docs/reference/interpret_ess.html;docs/reference/interpret_gfi.html;docs/reference/interpret_odds.html;docs/reference/interpret_omega_squared.html;docs/reference/interpret_p.html;docs/reference/interpret_parameters.html;docs/reference/interpret_r.html;docs/reference/interpret_r2.html;docs/reference/normalize.html;docs/reference/phi.html;docs/reference/ranktransform.html;docs/reference/rules.html;docs/reference/sd_pooled.html;docs/reference/standardize.html;docs/reference/standardize_info.html;docs/reference/standardize_parameters.html;docs/reference/t_to_r.html,False,False,False,False,38,38,76,"---FILE: docs/404.html---
@@ -120,7 +120,7 @@
       <a href=""articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/articles/convert.html---
@@ -82,7 +82,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/articles/interpret.html---
@@ -82,7 +82,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/articles/standardize_data.html---
@@ -82,7 +82,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/articles/standardize_parameters.html---
@@ -82,7 +82,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/news/index.html---
@@ -120,7 +120,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/F_to_eta2.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/adjust.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/change_scale.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/chisq_to_phi.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/cohens_d.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/convert_z_to_percentile.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/d_to_r.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/dot-factor_to_numeric.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/eta_squared.html---
@@ -122,7 +122,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/format_standardize.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/index.html---
@@ -120,7 +120,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/interpret.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/interpret_bf.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/interpret_d.html---
@@ -122,7 +122,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/interpret_direction.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/interpret_ess.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/interpret_gfi.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/interpret_odds.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/interpret_omega_squared.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/interpret_p.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/interpret_parameters.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/interpret_r.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/interpret_r2.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/normalize.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/phi.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/ranktransform.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/rules.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/sd_pooled.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/standardize.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/standardize_info.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/standardize_parameters.html---
@@ -121,7 +121,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>

---FILE: docs/reference/t_to_r.html---
@@ -123,7 +123,7 @@
       <a href=""../articles/convert.html"">Effect size conversion</a>
     </li>
     <li>
-      <a href=""../articles/from_teststatistics.html"">Effect Size from Test Statistics</a>
+      <a href=""../articles/from_test_statistics.html"">Effect Size from Test Statistics</a>
     </li>
     <li>
       <a href=""../articles/interpret.html"">Interpretation Guidelines</a>",False,False,Implementation / Logic,3
easystats,effectsize,55ac8ddf7771c3461ee9d39ba7f14fe88bca9b08,mattansb,35330040+mattansb@users.noreply.github.com,2020-03-22T21:41:29Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-03-22T21:41:29Z,fix example,R/convert_chisq.R;docs/reference/chisq_to_phi.html;man/chisq_to_phi.Rd,False,True,True,False,19,6,25,"---FILE: R/convert_chisq.R---
@@ -5,7 +5,7 @@
 #' @param chisq The Chi2 statistic.
 #' @param phi The Phi statistic.
 #' @param n Sample size.
-#' @param nrow,ncol The number of rows/columns in the contingency table (ignored for Phi when \code{adjust=FALSE}).
+#' @param nrow,ncol The number of rows/columns in the contingency table (ignored for Phi when \code{adjust=FALSE} and \code{CI=NULL}).
 #' @param CI Confidence Interval (CI) level
 #' @param adjust Should the effect size be bias-corrected? Defaults to \code{FALSE}.
 #' @param ... Arguments passed to or from other methods.
@@ -34,7 +34,11 @@
 #' # data:  ctab
 #' # X-squared = 41.234, df = 4, p-value = 2.405e-08
 #'
-#' chisq_to_phi(41.234, n = sum(contingency_table))
+#' chisq_to_phi(41.234,
+#'   n = sum(contingency_table),
+#'   nrow = nrow(contingency_table),
+#'   ncol = ncol(contingency_table)
+#' )
 #' chisq_to_cramers_v(41.234,
 #'   n = sum(contingency_table),
 #'   nrow = nrow(contingency_table),

---FILE: docs/reference/chisq_to_phi.html---
@@ -188,7 +188,7 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
     </tr>
     <tr>
       <th>nrow, ncol</th>
-      <td><p>The number of rows/columns in the contingency table (ignored for Phi when <code>adjust=FALSE</code>).</p></td>
+      <td><p>The number of rows/columns in the contingency table (ignored for Phi when <code>adjust=FALSE</code> and <code>CI=NULL</code>).</p></td>
     </tr>
     <tr>
       <th>CI</th>
@@ -245,7 +245,12 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
 <span class='co'># data:  ctab</span>
 <span class='co'># X-squared = 41.234, df = 4, p-value = 2.405e-08</span>
 
-<span class='fu'>chisq_to_phi</span>(<span class='fl'>41.234</span>, <span class='kw'>n</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span>(<span class='no'>contingency_table</span>))</div><div class='output co'>#&gt; <span class='error'>Error in mapply(.get_ncp_chi, chisq, (nrow - 1) * (ncol - 1), CI): argument ""nrow"" is missing, with no default</span></div><div class='input'><span class='fu'>chisq_to_cramers_v</span>(<span class='fl'>41.234</span>,
+<span class='fu'>chisq_to_phi</span>(<span class='fl'>41.234</span>,
+  <span class='kw'>n</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span>(<span class='no'>contingency_table</span>),
+  <span class='kw'>nrow</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span>(<span class='no'>contingency_table</span>),
+  <span class='kw'>ncol</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>ncol</a></span>(<span class='no'>contingency_table</span>)
+)</div><div class='output co'>#&gt;        phi   CI     CI_low   CI_high
+#&gt; 1 0.102081 0.95 0.06632831 0.1299439</div><div class='input'><span class='fu'>chisq_to_cramers_v</span>(<span class='fl'>41.234</span>,
   <span class='kw'>n</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span>(<span class='no'>contingency_table</span>),
   <span class='kw'>nrow</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span>(<span class='no'>contingency_table</span>),
   <span class='kw'>ncol</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>ncol</a></span>(<span class='no'>contingency_table</span>)

---FILE: man/chisq_to_phi.Rd---
@@ -34,7 +34,7 @@ convert_phi_to_chisq(phi, n, ...)
 
 \item{n}{Sample size.}
 
-\item{nrow, ncol}{The number of rows/columns in the contingency table (ignored for Phi when \code{adjust=FALSE}).}
+\item{nrow, ncol}{The number of rows/columns in the contingency table (ignored for Phi when \code{adjust=FALSE} and \code{CI=NULL}).}
 
 \item{CI}{Confidence Interval (CI) level}
 
@@ -73,7 +73,11 @@ chisq.test(contingency_table)
 # data:  ctab
 # X-squared = 41.234, df = 4, p-value = 2.405e-08
 
-chisq_to_phi(41.234, n = sum(contingency_table))
+chisq_to_phi(41.234,
+  n = sum(contingency_table),
+  nrow = nrow(contingency_table),
+  ncol = ncol(contingency_table)
+)
 chisq_to_cramers_v(41.234,
   n = sum(contingency_table),
   nrow = nrow(contingency_table),",True,False,Documentation / Formatting,6
easystats,effectsize,2bd3fcbd5035fc072a10a58a9c112288799bf1a8,mattansb,35330040+mattansb@users.noreply.github.com,2020-03-22T20:43:47Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-03-22T20:43:47Z,add and fix tests,tests/testthat/test-datatransform.R;tests/testthat/test-es_from_statistic.R,False,True,True,False,56,10,66,"---FILE: tests/testthat/test-datatransform.R---
@@ -3,12 +3,12 @@ if (require(""testthat"") && require(""effectsize"") && require(""dplyr"")) {
     x <- normalize(iris)
     testthat::expect_equal(mean(x$Sepal.Length), 0.42, tol = 0.01)
     testthat::expect_length(levels(x$Species), 3)
-    testthat::expect_equal(mean(dplyr::filter_(x, ""Species == 'virginica'"")$Sepal.Length), 0.635, tol = 0.01)
+    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 0.635, tol = 0.01)
 
-    x <- normalize(dplyr::group_by_(iris, ""Species""))
+    x <- normalize(dplyr::group_by(iris, .data$Species))
     testthat::expect_equal(mean(x$Sepal.Length), 0.509, tol = 0.01)
     testthat::expect_length(levels(x$Species), 3)
-    testthat::expect_equal(mean(dplyr::filter_(x, ""Species == 'virginica'"")$Sepal.Length), 0.562, tol = 0.01)
+    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 0.562, tol = 0.01)
   })
 
 
@@ -17,12 +17,12 @@ if (require(""testthat"") && require(""effectsize"") && require(""dplyr"")) {
     x <- ranktransform(iris)
     testthat::expect_equal(mean(x$Sepal.Length), 75.5, tol = 0.01)
     testthat::expect_length(levels(x$Species), 3)
-    testthat::expect_equal(mean(dplyr::filter_(x, ""Species == 'virginica'"")$Sepal.Length), 114 , tol = 0.01)
+    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 114 , tol = 0.01)
 
-    x <- ranktransform(dplyr::group_by_(iris, ""Species""))
+    x <- ranktransform(dplyr::group_by(iris, .data$Species))
     testthat::expect_equal(mean(x$Sepal.Length), 25.5, tol = 0.01)
     testthat::expect_length(levels(x$Species), 3)
-    testthat::expect_equal(mean(dplyr::filter_(x, ""Species == 'virginica'"")$Sepal.Length), 25.5, tol = 0.01)
+    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 25.5, tol = 0.01)
   })
 
 
@@ -31,19 +31,19 @@ if (require(""testthat"") && require(""effectsize"") && require(""dplyr"")) {
     x <- change_scale(iris)
     testthat::expect_equal(mean(x$Sepal.Length), 42.9, tol = 0.01)
     testthat::expect_length(levels(x$Species), 3)
-    testthat::expect_equal(mean(dplyr::filter_(x, ""Species == 'virginica'"")$Sepal.Length), 63.6 , tol = 0.01)
+    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 63.6 , tol = 0.01)
 
-    x <- change_scale(dplyr::group_by_(iris, ""Species""))
+    x <- change_scale(dplyr::group_by(iris, .data$Species))
     testthat::expect_equal(mean(x$Sepal.Length), 50.9, tol = 0.01)
     testthat::expect_length(levels(x$Species), 3)
-    testthat::expect_equal(mean(dplyr::filter_(x, ""Species == 'virginica'"")$Sepal.Length), 56.3, tol = 0.01)
+    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 56.3, tol = 0.01)
   })
 
 
   test_that(""adjust"", {
     x <- adjust(iris)
     testthat::expect_equal(mean(x$Sepal.Length), 0, tol = 0.01)
     testthat::expect_length(levels(x$Species), 3)
-    testthat::expect_equal(mean(dplyr::filter_(x, ""Species == 'virginica'"")$Sepal.Length), 0 , tol = 0.01)
+    testthat::expect_equal(mean(dplyr::filter(x, .data$Species == 'virginica')$Sepal.Length), 0 , tol = 0.01)
   })
 }
\ No newline at end of file

---FILE: tests/testthat/test-es_from_statistic.R---
@@ -0,0 +1,46 @@
+test_that(""r"", {
+  res1 <- cor.test(iris[[1]], iris[[2]])
+  res2 <- t_to_r(t = res1$statistic, res1$parameter)
+
+  testthat::expect_equal(unname(res1$estimate), res2$r, tolerance = 0.01)
+  testthat::expect_equal(unname(res1$conf.int[1]), res2$CI_low, tolerance = 0.01)
+  testthat::expect_equal(unname(res1$conf.int[2]), res2$CI_high, tolerance = 0.01)
+})
+
+
+if (require(""DescTools"")) {
+  test_that(""Cramers V"", {
+    contingency_table <- as.table(rbind(c(762, 327, 468),
+                                        c(484, 239, 477),
+                                        c(484, 239, 477)))
+
+    res1 <- DescTools::CramerV(contingency_table, conf.level = 0.95, method = ""ncchisq"")
+    res2 <- effectsize::cramers_v(contingency_table)
+
+    testthat::expect_equal(unname(res1[1]), res2$cramers_v, tolerance = 0.01)
+    testthat::expect_equal(unname(res1[2]), res2$CI_low, tolerance = 0.01)
+    testthat::expect_equal(unname(res1[3]), res2$CI_high, tolerance = 0.01)
+  })
+}
+
+if (require(""MBESS"", quietly = TRUE)) {
+  test_that(""d"", {
+    res1 <- unlist(MBESS::ci.smd(4, n.1 = 40, n.2 = 30))
+    res2 <- t_to_d(4, 68)
+
+    testthat::expect_equal(unname(res1[2]), res2$d, tolerance = 0.01)
+    testthat::expect_equal(unname(res1[1]), res2$CI_low, tolerance = 0.01)
+    testthat::expect_equal(unname(res1[3]), res2$CI_high, tolerance = 0.01)
+  })
+
+
+  test_that(""eta2"", {
+    res1 <- unlist(MBESS::ci.pvaf(4, 3, 123, N = 127, conf.level = 0.9))
+    res2 <- F_to_eta2(4, 3, 123)
+
+    # no equvilant for actual eta2
+    testthat::expect_equal(unname(res1[1]), res2$CI_low, tolerance = 0.01)
+    testthat::expect_equal(unname(res1[3]), res2$CI_high, tolerance = 0.01)
+  })
+}
+",True,False,Implementation / Logic,6
easystats,effectsize,52b64269b20a60b1cc3c5321e70712b24b4e47a1,mattansb,35330040+mattansb@users.noreply.github.com,2020-03-21T06:49:46Z,mattansb,35330040+mattansb@users.noreply.github.com,2020-03-21T06:49:46Z,rebuild site + fix docs,R/convert_tFz_to_r.R;docs/404.html;docs/CODE_OF_CONDUCT.html;docs/CONTRIBUTING.html;docs/LICENSE-text.html;docs/PULL_REQUEST_TEMPLATE.html;docs/articles/convert.html;docs/articles/index.html;docs/articles/interpret.html;docs/articles/standardize_data.html;docs/articles/standardize_parameters.html;docs/authors.html;docs/index.html;docs/news/index.html;docs/pkgdown.yml;docs/reference/F_to_eta2.html;docs/reference/adjust.html;docs/reference/change_scale.html;docs/reference/chisq_to_phi.html;docs/reference/cohens_d.html;docs/reference/convert_z_to_percentile.html;docs/reference/d_to_r.html;docs/reference/dot-factor_to_numeric.html;docs/reference/eta_squared.html;docs/reference/format_standardize.html;docs/reference/index.html;docs/reference/interpret.html;docs/reference/interpret_bf.html;docs/reference/interpret_d.html;docs/reference/interpret_direction.html;docs/reference/interpret_ess.html;docs/reference/interpret_gfi.html;docs/reference/interpret_odds.html;docs/reference/interpret_omega_squared.html;docs/reference/interpret_p.html;docs/reference/interpret_parameters.html;docs/reference/interpret_r.html;docs/reference/interpret_r2.html;docs/reference/normalize.html;docs/reference/phi.html;docs/reference/ranktransform.html;docs/reference/rules.html;docs/reference/sd_pooled.html;docs/reference/standardize.html;docs/reference/standardize_info.html;docs/reference/standardize_parameters.html;docs/reference/t_to_r.html;man/t_to_r.Rd;vignettes/standardize_parameters.Rmd,True,True,True,False,318,391,709,"---FILE: R/convert_tFz_to_r.R---
@@ -14,7 +14,9 @@
 #' @param CI Confidence Interval (CI) level
 #' @param ... Arguments passed to or from other methods.
 #'
-#' #' @return A data frame with the effect size(s) between 0-1, and confidence interval(s)
+#'
+#' @return A data frame with the effect size(s) between 0-1, and confidence interval(s)
+#'
 #'
 #' @details These functions use the following formulae:
 #' \cr\cr
@@ -45,9 +47,6 @@
 #' t_to_d(t = res$statistic, res$parameter, pooled = TRUE)
 #' t_to_r(t = res$statistic, res$parameter)
 #'
-#' res <- cor.test(iris$Sepal.Width, iris$Petal.Width)
-#' t_to_r(t = res$statistic, n = 150)
-#'
 #' \donttest{
 #' ## Linear Regression
 #' model <- lm(Sepal.Length ~ Sepal.Width + Petal.Length, data = iris)

---FILE: docs/404.html---
@@ -117,15 +117,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/CODE_OF_CONDUCT.html---
@@ -117,15 +117,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/CONTRIBUTING.html---
@@ -117,15 +117,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">
@@ -195,9 +192,9 @@ <h2 class=""hasAnchor"">
 <li>
 <code><a href=""https://rdrr.io/pkg/styler/man/style_pkg.html"">styler::style_pkg()</a></code>: Automatic style formatting</li>
 <li>
-<code>lintr::lint_package()</code>: Style checks</li>
+<code><a href=""https://rdrr.io/pkg/lintr/man/lint_package.html"">lintr::lint_package()</a></code>: Style checks</li>
 <li>
-<code><a href=""https://rdrr.io/pkg/devtools/man/check.html"">devtools::check()</a></code>: General checks</li>
+<code><a href=""https://devtools.r-lib.org//reference/check.html"">devtools::check()</a></code>: General checks</li>
 </ul>
 </li>
 </ul>

---FILE: docs/LICENSE-text.html---
@@ -117,15 +117,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/PULL_REQUEST_TEMPLATE.html---
@@ -117,15 +117,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/articles/convert.html---
@@ -79,15 +79,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
 <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
 <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/articles/index.html---
@@ -117,15 +117,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">
@@ -156,7 +153,6 @@ <h3>All vignettes</h3>
       <p class=""section-desc""></p>
 
       <ul>
-        <li><a href=""bayesian_models.html"">Effect sizes for Bayesian models</a></li>
         <li><a href=""convert.html"">Converting between Indices of Effect Size</a></li>
         <li><a href=""interpret.html"">Automated Interpretation of Indices of Effect Size</a></li>
         <li><a href=""standardize_data.html"">Data Standardization</a></li>

---FILE: docs/articles/interpret.html---
@@ -79,15 +79,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
 <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
 <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/articles/standardize_data.html---
@@ -79,15 +79,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
 <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
 <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/articles/standardize_parameters.html---
@@ -79,15 +79,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
 <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
 <ul class=""nav navbar-nav navbar-right"">
@@ -174,8 +171,11 @@ <h2 class=""hasAnchor"">
 <div class=""sourceCode"" id=""cb6""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb6-1"" title=""1"">model &lt;-<span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/stats/lm.html"">lm</a></span>(Sepal.Length <span class=""op"">~</span><span class=""st""> </span>., <span class=""dt"">data =</span> df) </a>
 <a class=""sourceLine"" id=""cb6-2"" title=""2""></a>
 <a class=""sourceLine"" id=""cb6-3"" title=""3"">parameters &lt;-<span class=""st""> </span><span class=""kw"">model_parameters</span>(model)[<span class=""dv"">2</span><span class=""op"">:</span><span class=""dv"">4</span>,]</a>
-<a class=""sourceLine"" id=""cb6-4"" title=""4""><span class=""kw""><a href=""../reference/t_to_r.html"">convert_t_to_r</a></span>(parameters<span class=""op"">$</span>t, parameters<span class=""op"">$</span>df_residual)</a></code></pre></div>
-<pre><code>&gt; numeric(0)</code></pre>
+<a class=""sourceLine"" id=""cb6-4"" title=""4""><span class=""kw""><a href=""../reference/t_to_r.html"">convert_t_to_r</a></span>(parameters<span class=""op"">$</span>t, parameters<span class=""op"">$</span>df_error)</a></code></pre></div>
+<pre><code>&gt;       r   CI CI_low CI_high
+&gt; 1  0.63 0.95   0.53    0.70
+&gt; 2  0.72 0.95   0.64    0.78
+&gt; 3 -0.34 0.95  -0.47   -0.19</code></pre>
 <p>Wow, the retrieved correlations coefficients from the regression model are <strong>exactly</strong> the same as the partial correlations!</p>
 <p>However, note that in multiple regression standardizing the parameters in not quite the same as computing the (partial) correlation, due toâ¦ math :(</p>
 <div class=""sourceCode"" id=""cb8""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb8-1"" title=""1"">model <span class=""op"">%&gt;%</span><span class=""st""> </span></a>

---FILE: docs/authors.html---
@@ -117,15 +117,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/index.html---
@@ -79,15 +79,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
 <li>
-      <a href=""articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
 <ul class=""nav navbar-nav navbar-right"">
@@ -122,7 +119,7 @@ <h2 class=""hasAnchor"">
 <a href=""#installation"" class=""anchor""></a>Installation</h2>
 <p>Run the following:</p>
 <div class=""sourceCode"" id=""cb1""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb1-1"" title=""1""><span class=""kw""><a href=""https://rdrr.io/r/utils/install.packages.html"">install.packages</a></span>(<span class=""st"">""devtools""</span>)</a>
-<a class=""sourceLine"" id=""cb1-2"" title=""2"">devtools<span class=""op"">::</span><span class=""kw""><a href=""https://rdrr.io/pkg/devtools/man/remote-reexports.html"">install_github</a></span>(<span class=""st"">""easystats/effectsize""</span>)</a></code></pre></div>
+<a class=""sourceLine"" id=""cb1-2"" title=""2"">devtools<span class=""op"">::</span><span class=""kw""><a href=""https://devtools.r-lib.org//reference/remote-reexports.html"">install_github</a></span>(<span class=""st"">""easystats/effectsize""</span>)</a></code></pre></div>
 <div class=""sourceCode"" id=""cb2""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb2-1"" title=""1""><span class=""kw""><a href=""https://rdrr.io/r/base/library.html"">library</a></span>(<span class=""st"">""effectsize""</span>)</a></code></pre></div>
 </div>
 <div id=""documentation"" class=""section level2"">

---FILE: docs/news/index.html---
@@ -117,15 +117,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">
@@ -162,6 +159,10 @@ <h2 class=""hasAnchor"">
 <ul>
 <li>New sffect sizes for contingency tables (<code><a href=""../reference/phi.html"">phi()</a></code> and <code><a href=""../reference/phi.html"">cramers_v()</a></code>).</li>
 <li>
+<code><a href=""../reference/F_to_eta2.html"">F_to_eta2()</a></code> family of functions now support CIs (via the ncp method), and return a data frame.</li>
+<li>
+<code><a href=""../reference/t_to_r.html"">t_to_d()</a></code> and <code><a href=""../reference/t_to_r.html"">t_to_r()</a></code> now support CIs (via the ncp method), and return a data frame.</li>
+<li>
 <code><a href=""../reference/standardize.html"">standardize()</a></code> for model-objects has a default-method, which usually accepts all models. Exception for model-objects that do not work will be added if missing.</li>
 <li>
 <code><a href=""../reference/standardize.html"">standardize.data.frame()</a></code> gets <code>append</code> and <code>suffix</code> arguments, to add (instead of replace) standardized variables to the returned data frame.</li>

---FILE: docs/pkgdown.yml---
@@ -2,7 +2,6 @@ pandoc: 2.7.2
 pkgdown: 1.4.1
 pkgdown_sha: ~
 articles:
-  bayesian_models: bayesian_models.html
   convert: convert.html
   interpret: interpret.html
   standardize_data: standardize_data.html

---FILE: docs/reference/F_to_eta2.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">
@@ -158,19 +155,19 @@ <h1>Convert test statistics (F, t) to indices of <strong>partial</strong> varian
     <p>These functions are convenience functions to convert F and t test statistics to <strong>partial</strong> Eta squared, (\(\eta{_p}^2\)), Omega squared (\(\omega{_p}^2\)) and Epsilon squared (\(\epsilon{_p}^2\); an alias for the adjusted Eta squared). These are useful in cases where the various Sum of Squares and Mean Squares are not easily available or their computation is not straightforward (e.g., in liner mixed models, contrasts, etc.). For test statistics derived from <code>lm</code> and <code>aov</code> models, these functions give exact results. For all other cases, they return close approximations.</p>
     </div>
 
-    <pre class=""usage""><span class='fu'>F_to_eta2</span>(<span class='no'>f</span>, <span class='no'>df</span>, <span class='no'>df_error</span>, <span class='no'>...</span>)
+    <pre class=""usage""><span class='fu'>F_to_eta2</span>(<span class='no'>f</span>, <span class='no'>df</span>, <span class='no'>df_error</span>, <span class='kw'>CI</span> <span class='kw'>=</span> <span class='fl'>0.9</span>, <span class='no'>...</span>)
 
 <span class='fu'>t_to_eta2</span>(<span class='no'>t</span>, <span class='no'>df_error</span>, <span class='no'>...</span>)
 
-<span class='fu'>F_to_epsilon2</span>(<span class='no'>f</span>, <span class='no'>df</span>, <span class='no'>df_error</span>, <span class='no'>...</span>)
+<span class='fu'>F_to_epsilon2</span>(<span class='no'>f</span>, <span class='no'>df</span>, <span class='no'>df_error</span>, <span class='kw'>CI</span> <span class='kw'>=</span> <span class='fl'>0.9</span>, <span class='no'>...</span>)
 
 <span class='fu'>t_to_epsilon2</span>(<span class='no'>t</span>, <span class='no'>df_error</span>, <span class='no'>...</span>)
 
-<span class='fu'>F_to_eta2_adj</span>(<span class='no'>f</span>, <span class='no'>df</span>, <span class='no'>df_error</span>, <span class='no'>...</span>)
+<span class='fu'>F_to_eta2_adj</span>(<span class='no'>f</span>, <span class='no'>df</span>, <span class='no'>df_error</span>, <span class='kw'>CI</span> <span class='kw'>=</span> <span class='fl'>0.9</span>, <span class='no'>...</span>)
 
 <span class='fu'>t_to_eta2_adj</span>(<span class='no'>t</span>, <span class='no'>df_error</span>, <span class='no'>...</span>)
 
-<span class='fu'>F_to_omega2</span>(<span class='no'>f</span>, <span class='no'>df</span>, <span class='no'>df_error</span>, <span class='no'>...</span>)
+<span class='fu'>F_to_omega2</span>(<span class='no'>f</span>, <span class='no'>df</span>, <span class='no'>df_error</span>, <span class='kw'>CI</span> <span class='kw'>=</span> <span class='fl'>0.9</span>, <span class='no'>...</span>)
 
 <span class='fu'>t_to_omega2</span>(<span class='no'>t</span>, <span class='no'>df_error</span>, <span class='no'>...</span>)</pre>
 
@@ -181,6 +178,10 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <th>df, df_error</th>
       <td><p>Degrees of freedom of numerator or of the error estimate (i.e., the residuals).</p></td>
     </tr>
+    <tr>
+      <th>CI</th>
+      <td><p>Confidence Interval (CI) level</p></td>
+    </tr>
     <tr>
       <th>...</th>
       <td><p>Arguments passed to or from other methods.</p></td>
@@ -193,7 +194,7 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
 
     <h2 class=""hasAnchor"" id=""value""><a class=""anchor"" href=""#value""></a>Value</h2>
 
-    <p>A numeric value between 0-1 (Note that for \(\omega_p^2\) and \(\epsilon_p^2\)
+    <p>A data frame with the effect size(s) between 0-1, and confidence interval(s) (Note that for \(\omega_p^2\) and \(\epsilon_p^2\)
 it is possible to compute a negative number; even though this doesn't make any practical sense,
 it is recommended to report the negative number and not a 0).</p>
     <h2 class=""hasAnchor"" id=""details""><a class=""anchor"" href=""#details""></a>Details</h2>
@@ -206,7 +207,12 @@ <h2 class=""hasAnchor"" id=""details""><a class=""anchor"" href=""#details""></a>Details
 <br /><br />
 $$\omega_p^2 = \frac{(F - 1) \times df_{num}}{F \times df_{num} + df_{den} + 1}$$
 <br /><br /><br />
-For \(t\), the conversion is based on the equality of \(t^2 = F\) when \(df_{num}=1\).</p>
+For \(t\), the conversion is based on the equality of \(t^2 = F\) when \(df_{num}=1\).</p><h3>Confidence Intervals</h3>
+<p>Confidence intervals are estimated using the Noncentrality parameter method;
+These methods searches for a the best <code>ncp</code> (non-central parameters) for
+of the noncentral F distribution for the desired tail-probabilities,
+and then convert these <code>ncp</code>s to the corresponding effect sizes.</p>
+
     <h2 class=""hasAnchor"" id=""note""><a class=""anchor"" href=""#note""></a>Note</h2>
 
     <p>\(Adj. \eta_p^2\) is an alias for \(\epsilon_p^2\).</p>
@@ -217,6 +223,8 @@ <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>R
 <li><p>Friedman, H. (1982). Simplified determinations of statistical power, magnitude of effect and research sample sizes. Educational and Psychological Measurement, 42(2), 521-526. doi: <a href='https://doi.org/10.1177/001316448204200214'>10.1177/001316448204200214</a></p></li>
 <li><p>Mordkoff, J. T. (2019). A Simple Method for Removing Bias From a Popular Measure of Standardized Effect Size: Adjusted Partial Eta Squared. Advances in Methods and Practices in Psychological Science, 2(3), 228-232. doi: <a href='https://doi.org/10.1177/2515245919855053'>10.1177/2515245919855053</a></p></li>
 <li><p>Albers, C., &amp; Lakens, D. (2018). When power analyses based on pilot data are biased: Inaccurate effect size estimators and follow-up bias. Journal of experimental social psychology, 74, 187-195. doi: <a href='https://doi.org/10.31234/osf.io/b7z4q'>10.31234/osf.io/b7z4q</a></p></li>
+<li><p>Steiger, J. H. (2004). Beyond the F test: Effect size confidence intervals and tests of close fit in the analysis of variance and contrast analysis. Psychological Methods, 9, 164-182.</p></li>
+<li><p>Cumming, G., &amp; Finch, S. (2001). A primer on the understanding, use, and calculation of confidence intervals that are based on central and noncentral distributions. Educational and Psychological Measurement, 61(4), 532-574.</p></li>
 </ul>
 
 
@@ -228,7 +236,7 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <span class='kw'>within</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='st'>""angle""</span>, <span class='st'>""noise""</span>),
     <span class='kw'>anova_table</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span>(<span class='kw'>correction</span> <span class='kw'>=</span> <span class='st'>""none""</span>, <span class='kw'>es</span> <span class='kw'>=</span> <span class='st'>""pes""</span>)
   )
-}</div><div class='output co'>#&gt; <span class='message'>Loading required package: afex</span></div><div class='output co'>#&gt; <span class='warning'>Warning: package 'afex' was built under R version 3.6.3</span></div><div class='output co'>#&gt; <span class='message'>Loading required package: lme4</span></div><div class='output co'>#&gt; <span class='message'>Loading required package: Matrix</span></div><div class='output co'>#&gt; <span class='message'>Registered S3 methods overwritten by 'car':</span>
+}</div><div class='output co'>#&gt; <span class='message'>Loading required package: afex</span></div><div class='output co'>#&gt; <span class='message'>Loading required package: lme4</span></div><div class='output co'>#&gt; <span class='message'>Loading required package: Matrix</span></div><div class='output co'>#&gt; <span class='message'>Registered S3 methods overwritten by 'car':</span>
 #&gt; <span class='message'>  method                          from</span>
 #&gt; <span class='message'>  influence.merMod                lme4</span>
 #&gt; <span class='message'>  cooks.distance.influence.merMod lme4</span>
@@ -253,7 +261,14 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
 #&gt; 3 angle:noise 2, 18 1160.00 45.31 *** .83  &lt;.0001
 #&gt; ---
 #&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1</div><div class='input'><span class='co'># compare to:</span>
-<span class='fu'>F_to_eta2</span>(<span class='fl'>40.72</span>, <span class='fl'>2</span>, <span class='fl'>18</span>)</div><div class='output co'>#&gt; [1] 0.8189863</div><div class='input'><span class='fu'>F_to_eta2</span>(<span class='fl'>33.77</span>, <span class='fl'>1</span>, <span class='fl'>9</span>)</div><div class='output co'>#&gt; [1] 0.7895721</div><div class='input'><span class='fu'>F_to_eta2</span>(<span class='fl'>45.31</span>, <span class='fl'>2</span>, <span class='fl'>18</span>)</div><div class='output co'>#&gt; [1] 0.8342847</div><div class='input'>
+<span class='fu'>F_to_eta2</span>(
+  <span class='kw'>f</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>40.72</span>, <span class='fl'>33.77</span>, <span class='fl'>45.31</span>),
+  <span class='kw'>df</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>2</span>, <span class='fl'>1</span>, <span class='fl'>2</span>),
+  <span class='kw'>df_error</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>18</span>, <span class='fl'>9</span>, <span class='fl'>18</span>)
+)</div><div class='output co'>#&gt;   Eta_Sq_partial  CI    CI_low   CI_high
+#&gt; 1      0.8189863 0.9 0.6604136 0.8865963
+#&gt; 2      0.7895721 0.9 0.4922275 0.8887108
+#&gt; 3      0.8342847 0.9 0.6880421 0.8962630</div><div class='input'>
 
 <span class='kw'>if</span> (<span class='fu'><a href='https://rdrr.io/r/base/library.html'>require</a></span>(<span class='st'>""lmerTest""</span>)) { <span class='co'># for the df_error</span>
   <span class='no'>fit</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/lmerTest/man/lmer.html'>lmer</a></span>(<span class='no'>extra</span> ~ <span class='no'>group</span> + (<span class='fl'>1</span> <span class='kw'>|</span> <span class='no'>ID</span>), <span class='no'>sleep</span>)
@@ -271,7 +286,27 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
 #&gt; <span class='message'></span>
 #&gt; <span class='message'>    lmer</span></div><div class='output co'>#&gt; <span class='message'>The following object is masked from 'package:stats':</span>
 #&gt; <span class='message'></span>
-#&gt; <span class='message'>    step</span></div><div class='output co'>#&gt; [1] 0.6078585</div><div class='input'># }
+#&gt; <span class='message'>    step</span></div><div class='output co'>#&gt;   Epsilon_Sq_partial  CI    CI_low   CI_high
+#&gt; 1          0.6078585 0.9 0.1643059 0.7916289</div><div class='input'>
+<span class='co'>## Use with emmeans based contrasts</span>
+<span class='kw'>if</span> (<span class='fu'><a href='https://rdrr.io/r/base/library.html'>require</a></span>(<span class='no'>emmeans</span>) <span class='kw'>&amp;</span> <span class='fu'><a href='https://rdrr.io/r/base/library.html'>require</a></span>(<span class='no'>dplyr</span>)) {
+  <span class='no'>warp.lm</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/lm.html'>lm</a></span>(<span class='no'>breaks</span> ~ <span class='no'>wool</span> * <span class='no'>tension</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>warpbreaks</span>)
+
+  <span class='fu'><a href='https://rdrr.io/pkg/emmeans/man/joint_tests.html'>joint_tests</a></span>(<span class='no'>warp.lm</span>, <span class='kw'>by</span> <span class='kw'>=</span> <span class='st'>""wool""</span>) <span class='kw'>%&gt;%</span>
+    <span class='fu'><a href='https://dplyr.tidyverse.org/reference/bind.html'>bind_cols</a></span>(<span class='fu'>F_to_eta2</span>(<span class='no'>.</span>$<span class='no'>F.ratio</span>, <span class='no'>.</span>$<span class='no'>df1</span>, <span class='no'>.</span>$<span class='no'>df2</span>))
+}</div><div class='output co'>#&gt; <span class='message'>Loading required package: emmeans</span></div><div class='output co'>#&gt; <span class='message'>Loading required package: dplyr</span></div><div class='output co'>#&gt; <span class='message'></span>
+#&gt; <span class='message'>Attaching package: 'dplyr'</span></div><div class='output co'>#&gt; <span class='message'>The following objects are masked from 'package:stats':</span>
+#&gt; <span class='message'></span>
+#&gt; <span class='message'>    filter, lag</span></div><div class='output co'>#&gt; <span class='message'>The following objects are masked from 'package:base':</span>
+#&gt; <span class='message'></span>
+#&gt; <span class='message'>    intersect, setdiff, setequal, union</span></div><div class='output co'>#&gt; wool = A:
+#&gt;  model term df1 df2 F.ratio p.value Eta_Sq_partial  CI    CI_low   CI_high
+#&gt;  tension      2  48  10.312 0.0002      0.30053626 0.9 0.1196468 0.4479451
+#&gt; 
+#&gt; wool = B:
+#&gt;  model term df1 df2 F.ratio p.value Eta_Sq_partial  CI    CI_low   CI_high
+#&gt;  tension      2  48   2.375 0.1039      0.09004739 0.9 0.0000000 0.2197384
+#&gt; </div><div class='input'># }
 </div></pre>
   </div>
   <div class=""col-md-3 hidden-xs hidden-sm"" id=""sidebar"">

---FILE: docs/reference/adjust.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">
@@ -504,9 +501,7 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
 #&gt; 147  -0.28175619         2.5          5.0         1.9  virginica
 #&gt; 148  -0.08175619         3.0          5.2         2.0  virginica
 #&gt; 149  -0.38175619         3.4          5.4         2.3  virginica
-#&gt; 150  -0.68175619         3.0          5.1         1.8  virginica</div><div class='input'><span class='fu'>adjust</span>(<span class='no'>iris</span>, <span class='kw'>effect</span> <span class='kw'>=</span> <span class='st'>""Species""</span>, <span class='kw'>select</span> <span class='kw'>=</span> <span class='st'>""Sepal.Length""</span>, <span class='kw'>bayesian</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>)</div><div class='output co'>#&gt; <span class='message'>Loading required namespace: rstanarm</span></div><div class='output co'>#&gt; <span class='message'>Registered S3 method overwritten by 'xts':</span>
-#&gt; <span class='message'>  method     from</span>
-#&gt; <span class='message'>  as.zoo.xts zoo </span></div><div class='output co'>#&gt;     Sepal.Length Sepal.Width Petal.Length Petal.Width    Species
+#&gt; 150  -0.68175619         3.0          5.1         1.8  virginica</div><div class='input'><span class='fu'>adjust</span>(<span class='no'>iris</span>, <span class='kw'>effect</span> <span class='kw'>=</span> <span class='st'>""Species""</span>, <span class='kw'>select</span> <span class='kw'>=</span> <span class='st'>""Sepal.Length""</span>, <span class='kw'>bayesian</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>)</div><div class='output co'>#&gt; <span class='message'>Loading required namespace: rstanarm</span></div><div class='output co'>#&gt;     Sepal.Length Sepal.Width Petal.Length Petal.Width    Species
 #&gt; 1    0.091789436         3.5          1.4         0.2     setosa
 #&gt; 2   -0.108210564         3.0          1.4         0.2     setosa
 #&gt; 3   -0.308210564         3.2          1.3         0.2     setosa

---FILE: docs/reference/change_scale.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/chisq_to_phi.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/cohens_d.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/convert_z_to_percentile.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/d_to_r.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/dot-factor_to_numeric.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/eta_squared.html---
@@ -119,15 +119,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/format_standardize.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/index.html---
@@ -117,15 +117,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">
@@ -338,20 +335,14 @@ <h2 id=""section-conversion"" class=""hasAnchor""><a href=""#section-conversion"" clas
         <td><p>Conversion between Effect sizes for Contingency Tables (Chi2, Phi, Cramer's V...)</p></td>
       </tr><tr>
         
-        <td>
-          <p><code><a href=""convert_posteriors_to_r.html"">convert_posteriors_to_r()</a></code> <code><a href=""convert_posteriors_to_r.html"">posteriors_to_r()</a></code> <code><a href=""convert_posteriors_to_r.html"">convert_posteriors_to_t()</a></code> <code><a href=""convert_posteriors_to_r.html"">posteriors_to_t()</a></code> </p>
-        </td>
-        <td><p>Convert posterior distributions from a Bayesian model</p></td>
-      </tr><tr>
-        
         <td>
           <p><code><a href=""convert_z_to_percentile.html"">convert_z_to_percentile()</a></code> <code><a href=""convert_z_to_percentile.html"">convert_percentile_to_z()</a></code> <code><a href=""convert_z_to_percentile.html"">z_to_percentile()</a></code> <code><a href=""convert_z_to_percentile.html"">percentile_to_z()</a></code> </p>
         </td>
         <td><p>Z score to Percentile</p></td>
       </tr><tr>
         
         <td>
-          <p><code><a href=""t_to_r.html"">t_to_d()</a></code> <code><a href=""t_to_r.html"">convert_t_to_d()</a></code> <code><a href=""t_to_r.html"">z_to_d()</a></code> <code><a href=""t_to_r.html"">convert_z_to_d()</a></code> <code><a href=""t_to_r.html"">F_to_d()</a></code> <code><a href=""t_to_r.html"">convert_F_to_d()</a></code> <code><a href=""t_to_r.html"">t_to_r()</a></code> <code><a href=""t_to_r.html"">r_to_t()</a></code> <code><a href=""t_to_r.html"">z_to_r()</a></code> <code><a href=""t_to_r.html"">r_to_z()</a></code> <code><a href=""t_to_r.html"">F_to_r()</a></code> <code><a href=""t_to_r.html"">convert_t_to_r()</a></code> <code><a href=""t_to_r.html"">convert_r_to_t()</a></code> <code><a href=""t_to_r.html"">convert_z_to_r()</a></code> <code><a href=""t_to_r.html"">convert_r_to_z()</a></code> <code><a href=""t_to_r.html"">convert_F_to_r()</a></code> </p>
+          <p><code><a href=""t_to_r.html"">t_to_d()</a></code> <code><a href=""t_to_r.html"">convert_t_to_d()</a></code> <code><a href=""t_to_r.html"">z_to_d()</a></code> <code><a href=""t_to_r.html"">convert_z_to_d()</a></code> <code><a href=""t_to_r.html"">F_to_d()</a></code> <code><a href=""t_to_r.html"">convert_F_to_d()</a></code> <code><a href=""t_to_r.html"">t_to_r()</a></code> <code><a href=""t_to_r.html"">convert_t_to_r()</a></code> <code><a href=""t_to_r.html"">z_to_r()</a></code> <code><a href=""t_to_r.html"">convert_z_to_r()</a></code> <code><a href=""t_to_r.html"">F_to_r()</a></code> <code><a href=""t_to_r.html"">convert_F_to_r()</a></code> </p>
         </td>
         <td><p>Convert test statistics (t, z, F) to effect sizes of differences (Cohen's d) or association (<strong>partial</strong> r)</p></td>
       </tr><tr>

---FILE: docs/reference/interpret.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/interpret_bf.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/interpret_d.html---
@@ -119,15 +119,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/interpret_direction.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/interpret_ess.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/interpret_gfi.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/interpret_odds.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/interpret_omega_squared.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/interpret_p.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/interpret_parameters.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/interpret_r.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/interpret_r2.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/normalize.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/phi.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">
@@ -194,8 +191,7 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <pre class=""examples""><div class='input'><span class='no'>contingency_table</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/table.html'>as.table</a></span>(<span class='fu'><a href='https://rdrr.io/r/base/cbind.html'>rbind</a></span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>762</span>, <span class='fl'>327</span>, <span class='fl'>468</span>), <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>484</span>, <span class='fl'>239</span>, <span class='fl'>477</span>), <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>484</span>, <span class='fl'>239</span>, <span class='fl'>477</span>)))
 
 <span class='fu'>phi</span>(<span class='no'>contingency_table</span>)</div><div class='output co'>#&gt; [1] 0.1020804</div><div class='input'>
-<span class='fu'>cramers_v</span>(<span class='no'>contingency_table</span>)</div><div class='output co'>#&gt; [1] 0.07218172</div><div class='input'>
-</div></pre>
+<span class='fu'>cramers_v</span>(<span class='no'>contingency_table</span>)</div><div class='output co'>#&gt; [1] 0.07218172</div></pre>
   </div>
   <div class=""col-md-3 hidden-xs hidden-sm"" id=""sidebar"">
     <h2>Contents</h2>

---FILE: docs/reference/ranktransform.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/rules.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/sd_pooled.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/standardize.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/standardize_info.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">

---FILE: docs/reference/standardize_parameters.html---
@@ -118,15 +118,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">
@@ -343,9 +340,13 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
   <span class='fu'>standardize_parameters</span>(<span class='no'>model</span>, <span class='kw'>method</span> <span class='kw'>=</span> <span class='st'>""posthoc""</span>)
   <span class='fu'>standardize_parameters</span>(<span class='no'>model</span>, <span class='kw'>method</span> <span class='kw'>=</span> <span class='st'>""smart""</span>)
   <span class='fu'>standardize_parameters</span>(<span class='no'>model</span>, <span class='kw'>method</span> <span class='kw'>=</span> <span class='st'>""basic""</span>)
-}</div><div class='output co'>#&gt; <span class='warning'>Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.</span>
+}</div><div class='output co'>#&gt; <span class='message'>Loading required package: rstanarm</span></div><div class='output co'>#&gt; <span class='message'>Loading required package: Rcpp</span></div><div class='output co'>#&gt; <span class='message'>rstanarm (Version 2.19.3, packaged: 2020-02-11 05:16:41 UTC)</span></div><div class='output co'>#&gt; <span class='message'>- Do not expect the default priors to remain the same in future rstanarm versions.</span></div><div class='output co'>#&gt; <span class='message'>Thus, R scripts should specify priors explicitly, even if they are just the defaults.</span></div><div class='output co'>#&gt; <span class='message'>- For execution on a local, multicore CPU with excess RAM we recommend calling</span></div><div class='output co'>#&gt; <span class='message'>options(mc.cores = parallel::detectCores())</span></div><div class='output co'>#&gt; <span class='message'>- bayesplot theme set to bayesplot::theme_default()</span></div><div class='output co'>#&gt; <span class='message'>   * Does _not_ affect other ggplot2 plots</span></div><div class='output co'>#&gt; <span class='message'>   * See ?bayesplot_theme_set for details on theme setting</span></div><div class='output co'>#&gt; <span class='warning'>Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.</span>
+#&gt; <span class='warning'>Running the chains for more iterations may help. See</span>
+#&gt; <span class='warning'>http://mc-stan.org/misc/warnings.html#bulk-ess</span></div><div class='output co'>#&gt; <span class='warning'>Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.</span>
+#&gt; <span class='warning'>Running the chains for more iterations may help. See</span>
+#&gt; <span class='warning'>http://mc-stan.org/misc/warnings.html#tail-ess</span></div><div class='output co'>#&gt; <span class='warning'>Warning: The largest R-hat is 1.06, indicating chains have not mixed.</span>
 #&gt; <span class='warning'>Running the chains for more iterations may help. See</span>
-#&gt; <span class='warning'>http://mc-stan.org/misc/warnings.html#bulk-ess</span></div><div class='output co'>#&gt; <span class='warning'>Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.</span>
+#&gt; <span class='warning'>http://mc-stan.org/misc/warnings.html#r-hat</span></div><div class='output co'>#&gt; <span class='warning'>Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.</span>
 #&gt; <span class='warning'>Running the chains for more iterations may help. See</span>
 #&gt; <span class='warning'>http://mc-stan.org/misc/warnings.html#bulk-ess</span></div><div class='output co'>#&gt; <span class='warning'>Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.</span>
 #&gt; <span class='warning'>Running the chains for more iterations may help. See</span>

---FILE: docs/reference/t_to_r.html---
@@ -120,15 +120,12 @@
   </a>
   <ul class=""dropdown-menu"" role=""menu"">
     <li>
-      <a href=""../articles/bayesian_models.html"">Bayesian models</a>
+      <a href=""../articles/convert.html"">Effect size conversion</a>
+    </li>
+    <li>
+      <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
     </li>
   </ul>
-</li>
-<li>
-  <a href=""../articles/convert.html"">Effect size conversion</a>
-</li>
-<li>
-  <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
       <ul class=""nav navbar-nav navbar-right"">
@@ -162,37 +159,29 @@ <h1>Convert test statistics (t, z, F) to effect sizes of differences (Cohen's d)
 available or their computation is not straightforward (e.g., in liner mixed models, contrasts, etc.).</p>
     </div>
 
-    <pre class=""usage""><span class='fu'>t_to_d</span>(<span class='no'>t</span>, <span class='no'>df_error</span>, <span class='kw'>pooled</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='no'>...</span>)
-
-<span class='fu'>convert_t_to_d</span>(<span class='no'>t</span>, <span class='no'>df_error</span>, <span class='kw'>pooled</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='no'>...</span>)
+    <pre class=""usage""><span class='fu'>t_to_d</span>(<span class='no'>t</span>, <span class='no'>df_error</span>, <span class='kw'>pooled</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>CI</span> <span class='kw'>=</span> <span class='fl'>0.95</span>, <span class='no'>...</span>)
 
-<span class='fu'>z_to_d</span>(<span class='no'>z</span>, <span class='no'>n</span>, <span class='no'>...</span>)
+<span class='fu'>convert_t_to_d</span>(<span class='no'>t</span>, <span class='no'>df_error</span>, <span class='kw'>pooled</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>CI</span> <span class='kw'>=</span> <span class='fl'>0.95</span>, <span class='no'>...</span>)
 
-<span class='fu'>convert_z_to_d</span>(<span class='no'>z</span>, <span class='no'>n</span>, <span class='no'>...</span>)
+<span class='fu'>z_to_d</span>(<span class='no'>z</span>, <span class='no'>n</span>, <span class='kw'>pooled</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>CI</span> <span class='kw'>=</span> <span class='fl'>0.95</span>, <span class='no'>...</span>)
 
-<span class='fu'>F_to_d</span>(<span class='no'>f</span>, <span class='no'>df</span>, <span class='no'>df_error</span>, <span class='kw'>pooled</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='no'>...</span>)
+<span class='fu'>convert_z_to_d</span>(<span class='no'>z</span>, <span class='no'>n</span>, <span class='kw'>pooled</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>CI</span> <span class='kw'>=</span> <span class='fl'>0.95</span>, <span class='no'>...</span>)
 
-<span class='fu'>convert_F_to_d</span>(<span class='no'>f</span>, <span class='no'>df</span>, <span class='no'>df_error</span>, <span class='kw'>pooled</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='no'>...</span>)
+<span class='fu'>F_to_d</span>(<span class='no'>f</span>, <span class='no'>df</span>, <span class='no'>df_error</span>, <span class='kw'>pooled</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>CI</span> <span class='kw'>=</span> <span class='fl'>0.95</span>, <span class='no'>...</span>)
 
-<span class='fu'>t_to_r</span>(<span class='no'>t</span>, <span class='kw'>n</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>df_error</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='no'>...</span>)
+<span class='fu'>convert_F_to_d</span>(<span class='no'>f</span>, <span class='no'>df</span>, <span class='no'>df_error</span>, <span class='kw'>pooled</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>CI</span> <span class='kw'>=</span> <span class='fl'>0.95</span>, <span class='no'>...</span>)
 
-<span class='fu'>r_to_t</span>(<span class='no'>r</span>, <span class='kw'>n</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>df_error</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='no'>...</span>)
+<span class='fu'>t_to_r</span>(<span class='no'>t</span>, <span class='no'>df_error</span>, <span class='kw'>CI</span> <span class='kw'>=</span> <span class='fl'>0.95</span>, <span class='no'>...</span>)
 
-<span class='fu'>z_to_r</span>(<span class='no'>z</span>, <span class='kw'>n</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>df_error</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='no'>...</span>)
+<span class='fu'>convert_t_to_r</span>(<span class='no'>t</span>, <span class='no'>df_error</span>, <span class='kw'>CI</span> <span class='kw'>=</span> <span class='fl'>0.95</span>, <span class='no'>...</span>)
 
-<span class='fu'>r_to_z</span>(<span class='no'>r</span>, <span class='kw'>n</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>df_error</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='no'>...</span>)
+<span class='fu'>z_to_r</span>(<span class='no'>z</span>, <span class='no'>n</span>, <span class='kw'>CI</span> <span class='kw'>=</span> <span class='fl'>0.95</span>, <span class='no'>...</span>)
 
-<span class='fu'>F_to_r</span>(<span class='no'>f</span>, <span class='no'>df</span>, <span class='kw'>df_error</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>n</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='no'>...</span>)
+<span class='fu'>convert_z_to_r</span>(<span class='no'>z</span>, <span class='no'>n</span>, <span class='kw'>CI</span> <span class='kw'>=</span> <span class='fl'>0.95</span>, <span class='no'>...</span>)
 
-<span class='fu'>convert_t_to_r</span>(<span class='no'>t</span>, <span class='kw'>n</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>df_error</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='no'>...</span>)
+<span class='fu'>F_to_r</span>(<span class='no'>f</span>, <span class='no'>df</span>, <span class='kw'>df_error</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>n</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>CI</span> <span class='kw'>=</span> <span class='fl'>0.95</span>, <span class='no'>...</span>)
 
-<span class='fu'>convert_r_to_t</span>(<span class='no'>r</span>, <span class='kw'>n</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>df_error</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='no'>...</span>)
-
-<span class='fu'>convert_z_to_r</span>(<span class='no'>z</span>, <span class='kw'>n</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>df_error</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='no'>...</span>)
-
-<span class='fu'>convert_r_to_z</span>(<span class='no'>r</span>, <span class='kw'>n</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>df_error</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='no'>...</span>)
-
-<span class='fu'>convert_F_to_r</span>(<span class='no'>f</span>, <span class='no'>df</span>, <span class='kw'>df_error</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>n</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='no'>...</span>)</pre>
+<span class='fu'>convert_F_to_r</span>(<span class='no'>f</span>, <span class='no'>df</span>, <span class='kw'>df_error</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>n</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>CI</span> <span class='kw'>=</span> <span class='fl'>0.95</span>, <span class='no'>...</span>)</pre>
 
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
@@ -205,6 +194,10 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <th>pooled</th>
       <td><p>Should the estimate accout for the t-value being based on a repeated-measures design, or not (default).</p></td>
     </tr>
+    <tr>
+      <th>CI</th>
+      <td><p>Confidence Interval (CI) level</p></td>
+    </tr>
     <tr>
       <th>...</th>
       <td><p>Arguments passed to or from other methods.</p></td>
@@ -225,7 +218,7 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
 
     <h2 class=""hasAnchor"" id=""value""><a class=""anchor"" href=""#value""></a>Value</h2>
 
-    <p>A numeric value of the requested effect size.</p>
+    <p>A data frame with the effect size(s) between 0-1, and confidence interval(s)</p>
     <h2 class=""hasAnchor"" id=""details""><a class=""anchor"" href=""#details""></a>Details</h2>
 
     <p>These functions use the following formulae:
@@ -239,29 +232,34 @@ <h2 class=""hasAnchor"" id=""details""><a class=""anchor"" href=""#details""></a>Details
 $$Cohen's d_z = t / \sqrt{df_{error}}$$
 <br /><br />
 $$Cohen's d = 2 * z / \sqrt{N}$$</p>
+<h3>Confidence Intervals</h3>
+<p>Confidence intervals are estimated using the Noncentrality parameter method;
+These methods searches for a the best <code>ncp</code> (non-central parameters) for
+of the noncentral F distribution for the desired tail-probabilities,
+and then convert these <code>ncp</code>s to the corresponding effect sizes.</p>
+
     <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>References</h2>
 
     
 <ul>
 <li><p>Friedman, H. (1982). Simplified determinations of statistical power, magnitude of effect and research sample sizes. Educational and Psychological Measurement, 42(2), 521-526. doi: <a href='https://doi.org/10.1177/001316448204200214'>10.1177/001316448204200214</a></p></li>
 <li><p>Wolf, F. M. (1986). Meta-analysis: Quantitative methods for research synthesis (Vol. 59). Sage.</p></li>
 <li><p>Rosenthal, R. (1991). Meta-analytic procedures for social research. Newbury Park, CA: SAGE Publications, Incorporated.</p></li>
+<li><p>Steiger, J. H. (2004). Beyond the F test: Effect size confidence intervals and tests of close fit in the analysis of variance and contrast analysis. Psychological Methods, 9, 164-182.</p></li>
+<li><p>Cumming, G., &amp; Finch, S. (2001). A primer on the understanding, use, and calculation of confidence intervals that are based on central and noncentral distributions. Educational and Psychological Measurement, 61(4), 532-574.</p></li>
 </ul>
 
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='co'>## t Tests</span>
 <span class='no'>res</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/t.test.html'>t.test</a></span>(<span class='fl'>1</span>:<span class='fl'>10</span>, <span class='kw'>y</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>7</span>:<span class='fl'>20</span>), <span class='kw'>var.equal</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>)
-<span class='fu'>t_to_d</span>(<span class='kw'>t</span> <span class='kw'>=</span> <span class='no'>res</span>$<span class='no'>statistic</span>, <span class='no'>res</span>$<span class='no'>parameter</span>)</div><div class='output co'>#&gt;         t 
-#&gt; -2.194813 </div><div class='input'><span class='fu'>t_to_r</span>(<span class='kw'>t</span> <span class='kw'>=</span> <span class='no'>res</span>$<span class='no'>statistic</span>, <span class='no'>res</span>$<span class='no'>parameter</span>)</div><div class='output co'>#&gt;          t 
-#&gt; -0.7548793 </div><div class='input'>
+<span class='fu'>t_to_d</span>(<span class='kw'>t</span> <span class='kw'>=</span> <span class='no'>res</span>$<span class='no'>statistic</span>, <span class='no'>res</span>$<span class='no'>parameter</span>)</div><div class='output co'>#&gt;           d   CI    CI_low   CI_high
+#&gt; t -2.194813 0.95 -3.234487 -1.123621</div><div class='input'><span class='fu'>t_to_r</span>(<span class='kw'>t</span> <span class='kw'>=</span> <span class='no'>res</span>$<span class='no'>statistic</span>, <span class='no'>res</span>$<span class='no'>parameter</span>)</div><div class='output co'>#&gt;            r   CI     CI_low    CI_high
+#&gt; t -0.7391491 0.95 -0.8505359 -0.4898045</div><div class='input'>
 <span class='no'>res</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/with.html'>with</a></span>(<span class='no'>sleep</span>, <span class='fu'><a href='https://rdrr.io/r/stats/t.test.html'>t.test</a></span>(<span class='no'>extra</span>[<span class='no'>group</span> <span class='kw'>==</span> <span class='fl'>1</span>], <span class='no'>extra</span>[<span class='no'>group</span> <span class='kw'>==</span> <span class='fl'>2</span>], <span class='kw'>paired</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>))
-<span class='fu'>t_to_d</span>(<span class='kw'>t</span> <span class='kw'>=</span> <span class='no'>res</span>$<span class='no'>statistic</span>, <span class='no'>res</span>$<span class='no'>parameter</span>, <span class='kw'>pooled</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>)</div><div class='output co'>#&gt;         t 
-#&gt; -1.354043 </div><div class='input'><span class='fu'>t_to_r</span>(<span class='kw'>t</span> <span class='kw'>=</span> <span class='no'>res</span>$<span class='no'>statistic</span>, <span class='no'>res</span>$<span class='no'>parameter</span>)</div><div class='output co'>#&gt;          t 
-#&gt; -0.8379372 </div><div class='input'>
-<span class='no'>res</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/cor.test.html'>cor.test</a></span>(<span class='no'>iris</span>$<span class='no'>Sepal.Width</span>, <span class='no'>iris</span>$<span class='no'>Petal.Width</span>)
-<span class='fu'>t_to_r</span>(<span class='kw'>t</span> <span class='kw'>=</span> <span class='no'>res</span>$<span class='no'>statistic</span>, <span class='kw'>n</span> <span class='kw'>=</span> <span class='fl'>150</span>)</div><div class='output co'>#&gt;          t 
-#&gt; -0.3661259 </div><div class='input'>
+<span class='fu'>t_to_d</span>(<span class='kw'>t</span> <span class='kw'>=</span> <span class='no'>res</span>$<span class='no'>statistic</span>, <span class='no'>res</span>$<span class='no'>parameter</span>, <span class='kw'>pooled</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>)</div><div class='output co'>#&gt;           d   CI    CI_low    CI_high
+#&gt; t -1.354043 0.95 -2.232586 -0.4370559</div><div class='input'><span class='fu'>t_to_r</span>(<span class='kw'>t</span> <span class='kw'>=</span> <span class='no'>res</span>$<span class='no'>statistic</span>, <span class='no'>res</span>$<span class='no'>parameter</span>)</div><div class='output co'>#&gt;            r   CI     CI_low    CI_high
+#&gt; t -0.8044072 0.95 -0.9126335 -0.4004773</div><div class='input'>
 <span class='co'># \donttest{</span>
 <span class='co'>## Linear Regression</span>
 <span class='no'>model</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/lm.html'>lm</a></span>(<span class='no'>Sepal.Length</span> ~ <span class='no'>Sepal.Width</span> + <span class='no'>Petal.Length</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>iris</span>)
@@ -276,14 +274,40 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
 <span class='co'># &gt; Sepal.Width  |        0.60 | 0.07 | [0.46, 0.73] |  8.59 | 147 | &lt; .001</span>
 <span class='co'># &gt; Petal.Length |        0.47 | 0.02 | [0.44, 0.51] | 27.57 | 147 | &lt; .001</span>
 
-<span class='fu'>t_to_r</span>(<span class='no'>param_tab</span>$<span class='no'>t</span>[<span class='fl'>2</span>:<span class='fl'>3</span>], <span class='no'>param_tab</span>$<span class='no'>df_error</span>[<span class='fl'>2</span>:<span class='fl'>3</span>])</div><div class='output co'>#&gt; [1] 0.5807367 0.9164002</div><div class='input'><span class='co'># &gt; [1] 0.5781005 0.9153894</span>
-<span class='co'># }</span>
-
+<span class='fu'>t_to_r</span>(<span class='no'>param_tab</span>$<span class='no'>t</span>[<span class='fl'>2</span>:<span class='fl'>3</span>], <span class='no'>param_tab</span>$<span class='no'>df_error</span>[<span class='fl'>2</span>:<span class='fl'>3</span>])</div><div class='output co'>#&gt;           r   CI    CI_low   CI_high
+#&gt; 1 0.5781005 0.95 0.4660381 0.6641125
+#&gt; 2 0.9153894 0.95 0.8913958 0.9323413</div><div class='input'><span class='co'># &gt; [1] 0.5781005 0.9153894</span>
+
+<span class='co'>## Use with emmeans based contrasts (see also t_to_eta2)</span>
+<span class='kw'>if</span> (<span class='fu'><a href='https://rdrr.io/r/base/library.html'>require</a></span>(<span class='no'>emmeans</span>) <span class='kw'>&amp;</span> <span class='fu'><a href='https://rdrr.io/r/base/library.html'>require</a></span>(<span class='no'>dplyr</span>)) {
+  <span class='no'>warp.lm</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/lm.html'>lm</a></span>(<span class='no'>breaks</span> ~ <span class='no'>wool</span> * <span class='no'>tension</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>warpbreaks</span>)
+
+  <span class='fu'><a href='https://rdrr.io/pkg/emmeans/man/emmeans.html'>emmeans</a></span>(<span class='no'>warp.lm</span>,  ~ <span class='no'>tension</span> <span class='kw'>|</span> <span class='no'>wool</span>) <span class='kw'>%&gt;%</span>
+    <span class='fu'><a href='https://rdrr.io/pkg/emmeans/man/contrast.html'>contrast</a></span>(<span class='st'>""pairwise""</span>) <span class='kw'>%&gt;%</span>
+    <span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span>() <span class='kw'>%&gt;%</span>
+    <span class='fu'><a href='https://dplyr.tidyverse.org/reference/bind.html'>bind_cols</a></span>(<span class='fu'>t_to_d</span>(<span class='no'>.</span>$<span class='no'>t.ratio</span>, <span class='no'>.</span>$<span class='no'>df</span>))
+}</div><div class='output co'>#&gt; wool = A:
+#&gt;  contrast estimate   SE df t.ratio p.value       d   CI  CI_low CI_high
+#&gt;  L - M      20.556 5.16 48  3.986  0.0007   1.1506 0.95  0.5348   1.756
+#&gt;  L - H      20.000 5.16 48  3.878  0.0009   1.1195 0.95  0.5061   1.723
+#&gt;  M - H      -0.556 5.16 48 -0.108  0.9936  -0.0311 0.95 -0.5968   0.535
+#&gt; 
+#&gt; wool = B:
+#&gt;  contrast estimate   SE df t.ratio p.value       d   CI  CI_low CI_high
+#&gt;  L - M      -0.556 5.16 48 -0.108  0.9936  -0.0311 0.95 -0.5968   0.535
+#&gt;  L - H       9.444 5.16 48  1.831  0.1704   0.5286 0.95 -0.0496   1.102
+#&gt;  M - H      10.000 5.16 48  1.939  0.1389   0.5597 0.95 -0.0198   1.134
+#&gt; 
+#&gt; P value adjustment: tukey method for comparing a family of 3 estimates </div><div class='input'>
 <span class='co'># How does this compare to actual partial correlations?</span>
 <span class='kw'>if</span> (<span class='fu'><a href='https://rdrr.io/r/base/library.html'>require</a></span>(<span class='st'>""ppcor""</span>)) {
   <span class='fu'><a href='https://rdrr.io/pkg/ppcor/man/pcor.html'>pcor</a></span>(<span class='no'>iris</span>[<span class='fl'>1</span>:<span class='fl'>3</span>])$<span class='no'>estimate</span>[<span class='fl'>1</span>, -<span class='fl'>1</span>]
-}</div><div class='output co'>#&gt; <span class='message'>Loading required package: ppcor</span></div><div class='output co'>#&gt; <span class='message'>Loading required package: MASS</span></div><div class='output co'>#&gt;  Sepal.Width Petal.Length 
-#&gt;    0.5781005    0.9153894 </div></pre>
+}</div><div class='output co'>#&gt; <span class='message'>Loading required package: ppcor</span></div><div class='output co'>#&gt; <span class='message'>Loading required package: MASS</span></div><div class='output co'>#&gt; <span class='message'></span>
+#&gt; <span class='message'>Attaching package: 'MASS'</span></div><div class='output co'>#&gt; <span class='message'>The following object is masked from 'package:dplyr':</span>
+#&gt; <span class='message'></span>
+#&gt; <span class='message'>    select</span></div><div class='output co'>#&gt;  Sepal.Width Petal.Length 
+#&gt;    0.5781005    0.9153894 </div><div class='input'># }
+</div></pre>
   </div>
   <div class=""col-md-3 hidden-xs hidden-sm"" id=""sidebar"">
     <h2>Contents</h2>

---FILE: man/t_to_r.Rd---
@@ -46,16 +46,17 @@ convert_F_to_r(f, df, df_error = NULL, n = NULL, CI = 0.95, ...)
 
 \item{CI}{Confidence Interval (CI) level}
 
-\item{...}{Arguments passed to or from other methods.
-
-#' @return A data frame with the effect size(s) between 0-1, and confidence interval(s)}
+\item{...}{Arguments passed to or from other methods.}
 
 \item{n}{The number of observations (the sample size).}
 
 \item{df, df_error}{Degrees of freedom of numerator or of the error estimate (i.e., the residuals).}
 
 \item{r}{The correlation coefficient r.}
 }
+\value{
+A data frame with the effect size(s) between 0-1, and confidence interval(s)
+}
 \description{
 These functions are convenience functions to convert t, z and F test statistics to Cohen's d and
 \strong{partial} r. These are useful in cases where the data required to compute these are not easily
@@ -91,9 +92,6 @@ res <- with(sleep, t.test(extra[group == 1], extra[group == 2], paired = TRUE))
 t_to_d(t = res$statistic, res$parameter, pooled = TRUE)
 t_to_r(t = res$statistic, res$parameter)
 
-res <- cor.test(iris$Sepal.Width, iris$Petal.Width)
-t_to_r(t = res$statistic, n = 150)
-
 \donttest{
 ## Linear Regression
 model <- lm(Sepal.Length ~ Sepal.Width + Petal.Length, data = iris)

---FILE: vignettes/standardize_parameters.Rmd---
@@ -93,7 +93,7 @@ Now, let's apply another method to obtain effect sizes for frequentist regressio
 model <- lm(Sepal.Length ~ ., data = df) 
 
 parameters <- model_parameters(model)[2:4,]
-convert_t_to_r(parameters$t, parameters$df_residual)
+convert_t_to_r(parameters$t, parameters$df_error)
 ```
 
 Wow, the retrieved correlations coefficients from the regression model are **exactly** the same as the partial correlations!",True,True,Documentation / Formatting,7
easystats,effectsize,b97792ad9b4af79dda3f6d1c143efc5f2e954b23,Daniel,mail@danielluedecke.de,2020-03-01T10:58:13Z,Daniel,mail@danielluedecke.de,2020-03-01T10:58:13Z,minor fixes,NAMESPACE;NEWS.md;R/standardize.models.R;R/standardize_parameters.R;man/standardize.Rd,False,True,True,False,17,226,243,"---FILE: NAMESPACE---
@@ -44,72 +44,21 @@ S3method(ranktransform,factor)
 S3method(ranktransform,grouped_df)
 S3method(ranktransform,numeric)
 S3method(standardize,AsIs)
-S3method(standardize,LORgee)
-S3method(standardize,MixMod)
 S3method(standardize,Surv)
-S3method(standardize,betareg)
-S3method(standardize,biglm)
-S3method(standardize,bracl)
-S3method(standardize,brmsfit)
-S3method(standardize,brmultinom)
-S3method(standardize,censReg)
-S3method(standardize,cgam)
-S3method(standardize,cglm)
+S3method(standardize,bcplm)
 S3method(standardize,character)
-S3method(standardize,clm)
 S3method(standardize,clm2)
-S3method(standardize,complmrob)
 S3method(standardize,coxme)
 S3method(standardize,coxph)
-S3method(standardize,cpglm)
-S3method(standardize,cpglmm)
-S3method(standardize,crch)
-S3method(standardize,crq)
 S3method(standardize,data.frame)
+S3method(standardize,default)
 S3method(standardize,factor)
-S3method(standardize,feis)
-S3method(standardize,fixest)
-S3method(standardize,flexsurvreg)
-S3method(standardize,gee)
-S3method(standardize,geeglm)
-S3method(standardize,glmRob)
-S3method(standardize,glmmTMB)
-S3method(standardize,glmmadmb)
-S3method(standardize,glmrob)
-S3method(standardize,gls)
 S3method(standardize,grouped_df)
-S3method(standardize,hurdle)
-S3method(standardize,iv_robust)
-S3method(standardize,ivreg)
-S3method(standardize,lm)
-S3method(standardize,lmRob)
-S3method(standardize,lm_robust)
-S3method(standardize,lme)
-S3method(standardize,lmrob)
 S3method(standardize,logical)
-S3method(standardize,logistf)
-S3method(standardize,lrm)
-S3method(standardize,merMod)
-S3method(standardize,mixor)
 S3method(standardize,mlm)
-S3method(standardize,negbin)
-S3method(standardize,nlrq)
 S3method(standardize,numeric)
-S3method(standardize,ols)
-S3method(standardize,plm)
-S3method(standardize,psm)
-S3method(standardize,rms)
-S3method(standardize,rq)
-S3method(standardize,speedglm)
-S3method(standardize,speedlm)
-S3method(standardize,stanreg)
-S3method(standardize,tobit)
-S3method(standardize,truncreg)
-S3method(standardize,vglm)
 S3method(standardize,wbgee)
 S3method(standardize,wbm)
-S3method(standardize,zerocount)
-S3method(standardize,zeroinfl)
 export(F_to_d)
 export(F_to_epsilon2)
 export(F_to_eta2)

---FILE: NEWS.md---
@@ -2,12 +2,14 @@
 
 ## Changes
 
+- `standardize()` for model-objects has a default-method, which usually accepts all models. Exception for model-objects that do not work will be added if missing.
 - `standardize.data.frame()` gets `append` and `suffix` arguments, to add (instead of replace) standardized variables to the returned data frame.
 
 ## Bug fixes
 
 - `standardize.data.frame()` did not work when variables had missing values.
 - Fixed wrong computation in `standardize()` when `two_sd = TRUE`.
+- Fixed bug with missing column names in `standardize_parameters()` for models with different components (like count and zero-inflation).
 
 # effectsize 0.2.0
 

---FILE: R/standardize.models.R---
@@ -3,15 +3,15 @@
 #' @importFrom insight get_data model_info find_response get_response find_weights
 #' @importFrom utils capture.output
 #' @export
-standardize.lm <- function(x, robust = FALSE, two_sd = FALSE, include_response = TRUE, verbose = TRUE, ...) {
+standardize.default <- function(x, robust = FALSE, two_sd = FALSE, include_response = TRUE, verbose = TRUE, ...) {
   m_info <- insight::model_info(x)
   data <- insight::get_data(x)
   resp <- NULL
 
   # for models with specific scale of the response value (e.g. count models
   # with positive integers, or beta with ratio between 0 and 1), we need to
   # make sure that the original response value will be restored after
-  # standardizing, as these models also require a non-standardized reponse.
+  # standardizing, as these models also require a non-standardized response.
 
   if (.no_response_standardize(m_info) || !include_response) {
     resp <- unique(c(insight::find_response(x), insight::find_response(x, combine = FALSE)))
@@ -81,161 +81,18 @@ standardize.lm <- function(x, robust = FALSE, two_sd = FALSE, include_response =
 
 
 
-#' @export
-standardize.mlm <- function(x, robust = FALSE, two_sd = FALSE, verbose = TRUE, ...) {
-  standardize.lm(x = x, robust = robust, two_sd = two_sd, include_response = FALSE, verbose = verbose, ...)
-}
-
-#' @export
-standardize.cglm <- standardize.lm
-
-#' @export
-standardize.cpglmm <- standardize.lm
-
-#' @export
-standardize.cpglm <- standardize.lm
-
-#' @export
-standardize.merMod <- standardize.lm
-
-#' @export
-standardize.mixor <- standardize.lm
-
-#' @export
-standardize.glmmadmb <- standardize.lm
-
-#' @export
-standardize.rq <- standardize.lm
-
-#' @export
-standardize.cgam <- standardize.lm
-
-#' @export
-standardize.crq <- standardize.lm
-
-#' @export
-standardize.nlrq <- standardize.lm
-
-#' @export
-standardize.bracl <- standardize.lm
-
-#' @export
-standardize.brmultinom <- standardize.lm
-
-#' @export
-standardize.speedglm <- standardize.lm
 
-#' @export
-standardize.speedlm <- standardize.lm
-
-#' @export
-standardize.iv_robust <- standardize.lm
-
-#' @export
-standardize.lmrob <- standardize.lm
-
-#' @export
-standardize.glmrob <- standardize.lm
+# exceptions, models that cannot use the default-method --------------------
 
-#' @export
-standardize.glmRob <- standardize.lm
 
 #' @export
-standardize.lmRob <- standardize.lm
-
-#' @export
-standardize.MixMod <- standardize.lm
-
-#' @export
-standardize.glmmTMB <- standardize.lm
-
-#' @export
-standardize.stanreg <- standardize.lm
-
-#' @export
-standardize.brmsfit <- standardize.lm
-
-#' @export
-standardize.fixest <- standardize.lm
-
-#' @export
-standardize.complmrob <- standardize.lm
-
-#' @export
-standardize.flexsurvreg <- standardize.lm
-
-#' @export
-standardize.lme <- standardize.lm
-
-#' @export
-standardize.biglm <- standardize.lm
-
-#' @export
-standardize.LORgee <- standardize.lm
-
-#' @export
-standardize.gls <- standardize.lm
-
-#' @export
-standardize.plm <- standardize.lm
-
-#' @export
-standardize.feis <- standardize.lm
-
-#' @export
-standardize.negbin <- standardize.lm
-
-#' @export
-standardize.betareg <- standardize.lm
-
-#' @export
-standardize.ivreg <- standardize.lm
-
-#' @export
-standardize.truncreg <- standardize.lm
-
-#' @export
-standardize.lm_robust <- standardize.lm
-
-#' @export
-standardize.tobit <- standardize.lm
-
-#' @export
-standardize.censReg <- standardize.lm
-
-#' @export
-standardize.crch <- standardize.lm
-
-#' @export
-standardize.lrm <- standardize.lm
-
-#' @export
-standardize.psm <- standardize.lm
-
-#' @export
-standardize.ols <- standardize.lm
-
-#' @export
-standardize.geeglm <- standardize.lm
-
-#' @export
-standardize.gee <- standardize.lm
-
-#' @export
-standardize.rms <- standardize.lm
-
-#' @export
-standardize.logistf <- standardize.lm
-
-#' @export
-standardize.vglm <- standardize.lm
-
-#' @export
-standardize.clm <- standardize.lm
+standardize.mlm <- function(x, robust = FALSE, two_sd = FALSE, verbose = TRUE, ...) {
+  standardize.default(x = x, robust = robust, two_sd = two_sd, include_response = FALSE, verbose = verbose, ...)
+}
 
 #' @export
 standardize.wbm <- function(x, ...) {
-  warning(""Standardization of parameters not possible for models from package 'panelr'."", call. = FALSE)
+  warning(paste0(""Standardization of parameters not possible for models of class '"", class(x)[1], ""'.""), call. = FALSE)
   x
 }
 
@@ -249,27 +106,10 @@ standardize.Surv <- function(x, ...) {
 standardize.clm2 <- standardize.wbm
 
 #' @export
-standardize.wbgee <- standardize.wbm
-
-
-
-
-
-
-# Zero-Inflated models -------------------------------------------------------
-
-
-#' @export
-standardize.zeroinfl <- standardize.lm
-
-#' @export
-standardize.hurdle <- standardize.lm
+standardize.bcplm <- standardize.wbm
 
 #' @export
-standardize.zerocount <- standardize.lm
-
-
-
+standardize.wbgee <- standardize.wbm
 
 
 
@@ -284,7 +124,7 @@ standardize.coxph <- function(x, robust = FALSE, two_sd = FALSE, verbose = TRUE,
   # ""update()"", so we only standardize model predictors
   #
   # survival models have some strange format for the response variable,
-  # so we don't use the default standardize.lm function here, but
+  # so we don't use the default standardize function here, but
   # use a different approach that only retrieves predictors that should
   # be standardized.
 

---FILE: R/standardize_parameters.R---
@@ -245,7 +245,7 @@ standardize_posteriors <- function(model, method = ""refit"", robust = FALSE, two_
     params <- insight::get_parameters(model, ...)
   } else {
     params <- insight::get_parameters(model, ...)
-    names(params) <- c(""Parameter"", ""Std_Coefficient"")
+    names(params)[2] <- ""Std_Coefficient""
   }
   params
 }

---FILE: man/standardize.Rd---
@@ -4,7 +4,7 @@
 \name{standardize}
 \alias{standardize}
 \alias{standardize.data.frame}
-\alias{standardize.lm}
+\alias{standardize.default}
 \title{Standardization (Z-scoring)}
 \usage{
 standardize(x, ...)
@@ -22,7 +22,7 @@ standardize(x, ...)
   ...
 )
 
-\method{standardize}{lm}(
+\method{standardize}{default}(
   x,
   robust = FALSE,
   two_sd = FALSE,",True,False,Documentation / Formatting,6
easystats,effectsize,95c30d4c9e78d8a221d75d9944e404cb710c4a1d,Daniel,mail@danielluedecke.de,2020-02-26T09:25:50Z,Daniel,mail@danielluedecke.de,2020-02-26T09:25:50Z,fix issues in standardize(),DESCRIPTION;NEWS.md;R/standardize.R;R/standardize.data.frame.R;man/format_standardize.Rd;man/standardize.Rd;man/standardize_info.Rd;man/standardize_parameters.Rd;tests/testthat/test-standardize.R,False,True,True,False,73,29,102,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Package: effectsize
 Type: Package
 Title: Indices of Effect Size and Standardized Parameters
-Version: 0.2.0
+Version: 0.2.0.1
 Authors@R: c(
     person(""Dominique"", 
 		""Makowski"", 
@@ -56,6 +56,7 @@ Suggests:
 	MuMIn,
 	performance,
 	ppcor,
+	rlang,
 	rmarkdown,
 	rstan,
 	rstanarm,

---FILE: NEWS.md---
@@ -1,6 +1,17 @@
-# effectsize 0.1.0
+# effectsize 0.2.1
+
+## Bug fixes
+
+- `standadize.data.frame()` did not work when variables had missing values.
+- Fixed wrong computation in `standadize()` when `two_sd = TRUE`.
 
-## Breaking changes
+# effectsize 0.2.0
+
+## Changes
+
+- News are hidden in an air of mystery...
+
+# effectsize 0.1.0
 
 ## New features
 

---FILE: R/standardize.R---
@@ -1,11 +1,11 @@
 #' Standardization (Z-scoring)
 #'
-#' Performs a standardization of data (Z-scoring), i.e., centering and scaling, so that the data is expressed in terms of standard deviation (i.e., mean = 0, SD = 1) or Median Absolute Deviance (median = 0, MAD = 1). When applied to a statistical model, this function extracts the dataset, standardizes it, and refits the model with this standardized version of the dataset. The \code{\link{normalize}} function can also be used to scale all numeric variables within the 0 - 1 range.
+#' Performs a standardization of data (z-scoring), i.e., centering and scaling, so that the data is expressed in terms of standard deviation (i.e., mean = 0, SD = 1) or Median Absolute Deviance (median = 0, MAD = 1). When applied to a statistical model, this function extracts the dataset, standardizes it, and refits the model with this standardized version of the dataset. The \code{\link{normalize}} function can also be used to scale all numeric variables within the 0 - 1 range.
 #'
-#' @param x A dataframe, a vector or a statistical model.
-#' @param robust Logical, if \code{TRUE}, centering is done by substracting the
+#' @param x A data frame, a vector or a statistical model.
+#' @param robust Logical, if \code{TRUE}, centering is done by subtracting the
 #'   median from the variables and dividing it by the median absolute deviation
-#'   (MAD). If \code{FALSE}, variables are standardized by substracting the
+#'   (MAD). If \code{FALSE}, variables are standardized by subtracting the
 #'   mean and dividing it by the standard deviation (SD).
 #' @param two_sd If \code{TRUE}, the variables are scaled by two times the deviation (SD or MAD depending on \code{robust}). This method can be useful to obtain model coefficients of continuous parameters comparable to coefficients related to binary predictors (Gelman, 2008).
 #' @param verbose Toggle warnings on or off.
@@ -21,11 +21,13 @@
 #'   response value will never be standardized, to make re-fitting the model work.
 #' @param ... Arguments passed to or from other methods.
 #'
-#' @return The standardized object (either a standardize dataframe or a statistical model fitted on standardized data).
+#' @return The standardized object (either a standardize data frame or a statistical model fitted on standardized data).
+#'
+#' @note When \code{x} is a data frame or vector, missing values are preserved, so the return value has the same length / number of rows as the original input.
 #'
 #' @seealso \code{\link{normalize}} \code{\link{standardize_parameters}}
 #' @examples
-#' # Dataframes
+#' # Data frames
 #' summary(standardize(iris))
 #'
 #' # Models

---FILE: R/standardize.data.frame.R---
@@ -7,6 +7,8 @@ standardize.numeric <- function(x, robust = FALSE, two_sd = FALSE, verbose = TRU
     return(x)
   }
 
+  valid_x <- !is.na(x)
+  scaled_x <- rep(NA, length(x))
   x <- stats::na.omit(x)
 
   # Sanity checks
@@ -28,14 +30,15 @@ standardize.numeric <- function(x, robust = FALSE, two_sd = FALSE, verbose = TRU
   }
 
   if (two_sd) {
-    x <- as.vector((x - center) / 2 * scale)
+    x <- as.vector((x - center) / (2 * scale))
   } else {
     x <- as.vector((x - center) / scale)
   }
 
-  attr(x, ""center"") <- center
-  attr(x, ""scale"") <- scale
-  x
+  scaled_x[valid_x] <- x
+  attr(scaled_x, ""center"") <- center
+  attr(scaled_x, ""scale"") <- scale
+  scaled_x
 }
 
 
@@ -138,9 +141,9 @@ standardize.data.frame <- function(x, robust = FALSE, two_sd = FALSE, select = N
     select <- setdiff(select, exclude)
   }
 
-  for (i in 1:length(select)) {
-    .check_standardize_numeric(x[[select[i]]], name = select[i], verbose = verbose)
-  }
+  # for (i in 1:length(select)) {
+  #   .check_standardize_numeric(x[[select[i]]], name = select[i], verbose = verbose)
+  # }
 
   x[select] <- lapply(x[select], standardize, robust = robust, two_sd = two_sd, verbose = FALSE, force = force)
 

---FILE: man/format_standardize.Rd---
@@ -11,9 +11,9 @@ format_standardize(x, reference = x, robust = FALSE, digits = NULL, ...)
 
 \item{reference}{The reference vector from which to compute the mean and SD.}
 
-\item{robust}{Logical, if \code{TRUE}, centering is done by substracting the
+\item{robust}{Logical, if \code{TRUE}, centering is done by subtracting the
 median from the variables and dividing it by the median absolute deviation
-(MAD). If \code{FALSE}, variables are standardized by substracting the
+(MAD). If \code{FALSE}, variables are standardized by subtracting the
 mean and dividing it by the standard deviation (SD).}
 
 \item{digits}{Number of significant digits.}

---FILE: man/standardize.Rd---
@@ -30,13 +30,13 @@ standardize(x, ...)
 )
 }
 \arguments{
-\item{x}{A dataframe, a vector or a statistical model.}
+\item{x}{A data frame, a vector or a statistical model.}
 
 \item{...}{Arguments passed to or from other methods.}
 
-\item{robust}{Logical, if \code{TRUE}, centering is done by substracting the
+\item{robust}{Logical, if \code{TRUE}, centering is done by subtracting the
 median from the variables and dividing it by the median absolute deviation
-(MAD). If \code{FALSE}, variables are standardized by substracting the
+(MAD). If \code{FALSE}, variables are standardized by subtracting the
 mean and dividing it by the standard deviation (SD).}
 
 \item{two_sd}{If \code{TRUE}, the variables are scaled by two times the deviation (SD or MAD depending on \code{robust}). This method can be useful to obtain model coefficients of continuous parameters comparable to coefficients related to binary predictors (Gelman, 2008).}
@@ -58,13 +58,16 @@ Note that for certain models (logistic regression, count models, ...), the
 response value will never be standardized, to make re-fitting the model work.}
 }
 \value{
-The standardized object (either a standardize dataframe or a statistical model fitted on standardized data).
+The standardized object (either a standardize data frame or a statistical model fitted on standardized data).
 }
 \description{
-Performs a standardization of data (Z-scoring), i.e., centering and scaling, so that the data is expressed in terms of standard deviation (i.e., mean = 0, SD = 1) or Median Absolute Deviance (median = 0, MAD = 1). When applied to a statistical model, this function extracts the dataset, standardizes it, and refits the model with this standardized version of the dataset. The \code{\link{normalize}} function can also be used to scale all numeric variables within the 0 - 1 range.
+Performs a standardization of data (z-scoring), i.e., centering and scaling, so that the data is expressed in terms of standard deviation (i.e., mean = 0, SD = 1) or Median Absolute Deviance (median = 0, MAD = 1). When applied to a statistical model, this function extracts the dataset, standardizes it, and refits the model with this standardized version of the dataset. The \code{\link{normalize}} function can also be used to scale all numeric variables within the 0 - 1 range.
+}
+\note{
+When \code{x} is a data frame or vector, missing values are preserved, so the return value has the same length / number of rows as the original input.
 }
 \examples{
-# Dataframes
+# Data frames
 summary(standardize(iris))
 
 # Models

---FILE: man/standardize_info.Rd---
@@ -9,9 +9,9 @@ standardize_info(model, robust = FALSE, ...)
 \arguments{
 \item{model}{A statistical model.}
 
-\item{robust}{Logical, if \code{TRUE}, centering is done by substracting the
+\item{robust}{Logical, if \code{TRUE}, centering is done by subtracting the
 median from the variables and dividing it by the median absolute deviation
-(MAD). If \code{FALSE}, variables are standardized by substracting the
+(MAD). If \code{FALSE}, variables are standardized by subtracting the
 mean and dividing it by the standard deviation (SD).}
 
 \item{...}{Arguments passed to or from other methods.}

---FILE: man/standardize_parameters.Rd---
@@ -32,9 +32,9 @@ standardize_posteriors(
 
 \item{method}{The method used for standardizing the parameters. Can be \code{""refit""} (default), \code{""posthoc""}, \code{""smart""} or \code{""basic""}. See 'Details'.}
 
-\item{robust}{Logical, if \code{TRUE}, centering is done by substracting the
+\item{robust}{Logical, if \code{TRUE}, centering is done by subtracting the
 median from the variables and dividing it by the median absolute deviation
-(MAD). If \code{FALSE}, variables are standardized by substracting the
+(MAD). If \code{FALSE}, variables are standardized by subtracting the
 mean and dividing it by the standard deviation (SD).}
 
 \item{two_sd}{If \code{TRUE}, the variables are scaled by two times the deviation (SD or MAD depending on \code{robust}). This method can be useful to obtain model coefficients of continuous parameters comparable to coefficients related to binary predictors (Gelman, 2008).}

---FILE: tests/testthat/test-standardize.R---
@@ -1,4 +1,4 @@
-if (require(""testthat"") && require(""effectsize"") && require(""dplyr"")) {
+if (require(""testthat"") && require(""effectsize"") && require(""dplyr"") && require(""rlang"")) {
   test_that(""standardize.numeric"", {
     x <- standardize(seq(0, 1, length.out = 100))
     testthat::expect_equal(mean(0), 0, tol = 0.01)
@@ -29,4 +29,28 @@ if (require(""testthat"") && require(""effectsize"") && require(""dplyr"")) {
     model <- standardize(lm(Sepal.Length ~ Species * Petal.Width, data = iris))
     testthat::expect_equal(coef(model)[[1]], 0.059, tol = 0.01)
   })
+
+
+
+  test_that(""standardize.data.frame, NAs"", {
+    data(iris)
+    set.seed(123)
+    iris$Sepal.Width[sample(1:150, 10)] <- NA
+    iris$Sepal.Length[sample(1:150, 10)] <- NA
+
+    x <- standardize(iris)
+    testthat::expect_equal(head(x$Sepal.Length), c(-0.9163, -1.1588, -1.4013, -1.5226, -1.0376, -0.5526), tol = 0.01)
+    testthat::expect_equal(head(x$Sepal.Width), c(0.9965, -0.1377, 0.316, 0.0891, 1.2233, 1.9038), tol = 0.01)
+    testthat::expect_equal(mean(x$Sepal.Length), as.numeric(NA))
+
+    x <- standardize(iris, two_sd = TRUE)
+    testthat::expect_equal(head(x$Sepal.Length), c(-0.4582, -0.5794, -0.7007, -0.7613, -0.5188, -0.2763), tol = 0.01)
+    testthat::expect_equal(head(x$Sepal.Width), c(0.4982, -0.0689, 0.158, 0.0446, 0.6116, 0.9519), tol = 0.01)
+    testthat::expect_equal(mean(x$Sepal.Length), as.numeric(NA))
+
+    x <- standardize(dplyr::group_by(iris, .data$Species))
+    testthat::expect_equal(head(x$Sepal.Length), c(0.2086, -0.3681, -0.9447, -1.233, -0.0797, 1.0735), tol = 0.01)
+    testthat::expect_equal(head(x$Sepal.Width), c(0.1441, -1.1586, -0.6375, -0.8981, 0.4047, 1.1863), tol = 0.01)
+    testthat::expect_equal(mean(x$Sepal.Length), as.numeric(NA))
+  })
 }",True,False,Documentation / Formatting,6
easystats,effectsize,be5b424f8c2a1a090f8a53d8e555f82c385a1293,Dominique Makowski,dom.mak19@gmail.com,2020-01-31T05:14:52Z,Dominique Makowski,dom.mak19@gmail.com,2020-01-31T05:14:52Z,fix,DESCRIPTION;R/adjust.R,False,True,True,False,5,5,10,"---FILE: DESCRIPTION---
@@ -1,7 +1,7 @@
 Package: effectsize
 Type: Package
 Title: Indices of Effect Size and Standardized Parameters
-Version: 0.1.1
+Version: 0.1.2
 Authors@R: c(
     person(""Dominique"", 
 		""Makowski"", 
@@ -35,9 +35,9 @@ LazyData: true
 Depends:
 	R (>= 3.2)
 Imports:
-	insight (>= 0.7.0),
-	bayestestR (>= 0.4.0),
-	parameters (>= 0.3.0),
+	insight (>= 0.8.0),
+	bayestestR (>= 0.5.0),
+	parameters (>= 0.4.0),
 	stats,
 	utils
 Suggests:

---FILE: R/adjust.R---
@@ -49,7 +49,7 @@ adjust <- function(data, effect = NULL, select = NULL, exclude = NULL, multileve
   if(is.null(select)){
     select <- names(data[nums])
   }
-  if(is.null(exclude)){
+  if(!is.null(exclude)){
     select <- select[!select %in% c(exclude)]
   }
 ",True,False,Dependency / Package,6
easystats,effectsize,7dec5fad551a57ba768b13234198b16f2b5daa00,Daniel,mail@danielluedecke.de,2020-01-21T11:22:47Z,Daniel,mail@danielluedecke.de,2020-01-21T11:22:47Z,fix vignettes,vignettes/bayesian_models.Rmd;vignettes/standardize_parameters.Rmd,True,False,True,False,37,30,67,"---FILE: vignettes/bayesian_models.Rmd---
@@ -23,8 +23,17 @@ bibliography: bibliography.bib
 ```{r message=FALSE, warning=FALSE, include=FALSE}
 library(knitr)
 options(knitr.kable.NA = '')
-knitr::opts_chunk$set(comment="">"")
-options(digits=2)
+options(digits = 2)
+knitr::opts_chunk$set(comment = "">"")
+
+if (!requireNamespace(""parameters"", quietly = TRUE) ||
+    !requireNamespace(""rstanarm"", quietly = TRUE) ||
+    !requireNamespace(""bayestestR"", quietly = TRUE) ||
+    !requireNamespace(""ppcor"", quietly = TRUE)) {
+  knitr::opts_chunk$set(eval = FALSE)
+}
+
+library(effectsize)
 ```
 
 
@@ -35,10 +44,9 @@ options(digits=2)
 
 ### Overview
 ```{r, warning=FALSE, message=FALSE}
-if (require(""ppcor"")) {
-  df <- iris[, 1:4]  # Remove the Species factor
-  ppcor::pcor(df)$estimate[2:4, 1]  # Select the rows of interest
-}
+library(""ppcor"")
+df <- iris[, 1:4]  # Remove the Species factor
+ppcor::pcor(df)$estimate[2:4, 1]  # Select the rows of interest
 ```
 
 The goal is to retrieve coefficients similar to the above **(partial) correlations** for this multiple regression model: `Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width`. This can easily be achieved for frequentist models by converting the *t* statistic into a correlation:
@@ -64,14 +72,12 @@ standardize_parameters(model)$Std_Coefficient[2:4]
 Let's start by fitting the Bayesian regression:
 
 ```{r, warning=FALSE, message=FALSE, eval = FALSE}
-if (require(""rstanarm"")) {
-  model <- stan_glm(Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width, data = df) 
-}
+library(""rstanarm"")
+model <- stan_glm(Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width, data = df) 
 ```
 ```{r, warning=FALSE, message=FALSE, echo = FALSE}
-if (require(""rstanarm"")) {
-  model <- stan_glm(Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width, data = df, refresh = 0, chains = 2) 
-}
+library(""rstanarm"")
+model <- stan_glm(Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width, data = df, refresh = 0, chains = 2) 
 ```
 
 
@@ -110,24 +116,20 @@ parameters
 And now the Bayesian:
 
 ```{r, warning=FALSE, message=FALSE, eval = FALSE}
-if (require(""rstanarm"")) {
-  model <- stan_glm(vs ~ cyl + disp + drat,, data = mtcars, family = ""binomial"") 
-  parameters <- model_parameters(model)
-  r <- convert_posteriors_to_r(model)
-  parameters$r <- bayestestR::describe_posterior(r)$Median
-  parameters$r_from_odds <- convert_odds_to_r(parameters$Median, log = TRUE)
-  parameters
-}
+model <- stan_glm(vs ~ cyl + disp + drat,, data = mtcars, family = ""binomial"") 
+parameters <- model_parameters(model)
+r <- convert_posteriors_to_r(model)
+parameters$r <- bayestestR::describe_posterior(r)$Median
+parameters$r_from_odds <- convert_odds_to_r(parameters$Median, log = TRUE)
+parameters
 ```
 ```{r, warning=FALSE, message=FALSE, echo = FALSE, eval=FALSE}
-if (require(""rstanarm"")) {
-  model <- stan_glm(vs ~ cyl + disp + drat,, data = mtcars, family = ""binomial"", refresh = 0) 
-  parameters <- model_parameters(model)
-  r <- convert_posteriors_to_r(model)
-  parameters$r <- bayestestR::describe_posterior(r)$Median
-  parameters$r_from_odds <- convert_odds_to_r(parameters$Median, log = TRUE)
-  parameters
-}
+model <- stan_glm(vs ~ cyl + disp + drat,, data = mtcars, family = ""binomial"", refresh = 0) 
+parameters <- model_parameters(model)
+r <- convert_posteriors_to_r(model)
+parameters$r <- bayestestR::describe_posterior(r)$Median
+parameters$r_from_odds <- convert_odds_to_r(parameters$Median, log = TRUE)
+parameters
 ```
 
 

---FILE: vignettes/standardize_parameters.Rmd---
@@ -21,9 +21,14 @@ bibliography: bibliography.bib
 
 ```{r message=FALSE, warning=FALSE, include=FALSE}
 library(knitr)
+knitr::opts_chunk$set(comment = "">"")
+options(digits = 2)
 options(knitr.kable.NA = '')
-knitr::opts_chunk$set(comment="">"")
-options(digits=2)
+
+if (!requireNamespace(""dplyr"", quietly = TRUE) ||
+    !requireNamespace(""parameters"", quietly = TRUE)) {
+  knitr::opts_chunk$set(eval = FALSE)
+}
 
 set.seed(333)
 ```",False,True,Implementation / Logic,6
easystats,effectsize,07f37d6f074861e03578d3aac4de6b423773ba32,Dominique Makowski,dom.mak19@gmail.com,2020-01-05T00:52:06Z,Dominique Makowski,dom.mak19@gmail.com,2020-01-05T00:52:06Z,further fix of adjust,R/adjust.R,False,True,True,False,1,1,2,"---FILE: R/adjust.R---
@@ -64,7 +64,7 @@ adjust <- function(data, effect = NULL, select = NULL, exclude = NULL, multileve
     formula_predictors <- paste(c(""1"", predictors), collapse = "" + "")
     formula <- paste(var, ""~"", formula_predictors)
 
-    x <- .model_adjust_for(data=data[c(var, effect)], formula, multilevel = multilevel, additive = additive, bayesian = bayesian, formula_random = formula_random)
+    x <- .model_adjust_for(data=data[unique(c(var, effect, facs))], formula, multilevel = multilevel, additive = additive, bayesian = bayesian, formula_random = formula_random)
     out[var] <- x
   }
   out[names(data)[!names(data) %in% names(out)]] <- data[names(data)[!names(data) %in% names(out)]]",True,False,Implementation / Logic,6
easystats,effectsize,0ff6cbbfd504ddbfbd66c46110d800da7231327a,Dominique Makowski,dom.mak19@gmail.com,2020-01-04T09:32:21Z,Dominique Makowski,dom.mak19@gmail.com,2020-01-04T09:32:21Z,minor fix to adjust,R/adjust.R,False,True,True,False,1,1,2,"---FILE: R/adjust.R---
@@ -64,7 +64,7 @@ adjust <- function(data, effect = NULL, select = NULL, exclude = NULL, multileve
     formula_predictors <- paste(c(""1"", predictors), collapse = "" + "")
     formula <- paste(var, ""~"", formula_predictors)
 
-    x <- .model_adjust_for(data, formula, multilevel = multilevel, additive = additive, bayesian = bayesian, formula_random = formula_random)
+    x <- .model_adjust_for(data=data[c(var, effect)], formula, multilevel = multilevel, additive = additive, bayesian = bayesian, formula_random = formula_random)
     out[var] <- x
   }
   out[names(data)[!names(data) %in% names(out)]] <- data[names(data)[!names(data) %in% names(out)]]",True,False,Implementation / Logic,6
easystats,effectsize,af3bce565e36ae837850a1bd4c5732fd029bf97e,Dominique Makowski,dom.mak19@gmail.com,2019-12-31T06:09:36Z,Dominique Makowski,dom.mak19@gmail.com,2019-12-31T06:09:36Z,fix 'adjust' for missing data,NAMESPACE;R/adjust.R,False,True,True,False,13,8,21,"---FILE: NAMESPACE---
@@ -229,6 +229,7 @@ importFrom(parameters,standard_error)
 importFrom(stats,anova)
 importFrom(stats,aov)
 importFrom(stats,as.formula)
+importFrom(stats,complete.cases)
 importFrom(stats,cor)
 importFrom(stats,lm)
 importFrom(stats,mad)

---FILE: R/adjust.R---
@@ -74,7 +74,7 @@ adjust <- function(data, effect = NULL, select = NULL, exclude = NULL, multileve
 
 
 
-#' @importFrom stats lm residuals as.formula
+#' @importFrom stats lm residuals as.formula complete.cases
 #' @keywords internal
 .model_adjust_for <- function(data, formula, multilevel = FALSE, additive = FALSE, bayesian = FALSE, formula_random = NULL) {
 
@@ -85,13 +85,13 @@ adjust <- function(data, effect = NULL, select = NULL, exclude = NULL, multileve
       if (!requireNamespace(""rstanarm"")) {
         stop(""This function needs `rstanarm` to be installed. Please install by running `install.packages('rstanarm')`."")
       }
-      out <- rstanarm::stan_gamm4(as.formula(formula), random = formula_random, data = data, refresh = 0)$residuals
+      adjusted <- rstanarm::stan_gamm4(as.formula(formula), random = formula_random, data = data, refresh = 0)$residuals
       # Frequentist
     } else{
       if (!requireNamespace(""gamm4"")) {
         stop(""This function needs `gamm4` to be installed. Please install by running `install.packages('gamm4')`."")
       }
-      out <- gamm4::gamm4(as.formula(formula), random = formula_random, data = data)$gam$residuals
+      adjusted <- gamm4::gamm4(as.formula(formula), random = formula_random, data = data)$gam$residuals
     }
 
   # Linear -------------------------
@@ -102,22 +102,26 @@ adjust <- function(data, effect = NULL, select = NULL, exclude = NULL, multileve
         stop(""This function needs `rstanarm` to be installed. Please install by running `install.packages('rstanarm')`."")
       }
       if (multilevel) {
-        out <- rstanarm::stan_lmer(paste(formula, formula_random), data = data, refresh = 0)$residuals
+        adjusted <- rstanarm::stan_lmer(paste(formula, formula_random), data = data, refresh = 0)$residuals
       } else{
-        out <- rstanarm::stan_glm(formula, data = data, refresh = 0)$residuals
+        adjusted <- rstanarm::stan_glm(formula, data = data, refresh = 0)$residuals
       }
     # Frequentist
     } else{
       if (multilevel) {
         if (!requireNamespace(""lme4"")) {
           stop(""This function needs `lme4` to be installed. Please install by running `install.packages('lme4')`."")
         }
-        out <- residuals(lme4::lmer(paste(formula, formula_random), data = data))
+        adjusted <- residuals(lme4::lmer(paste(formula, formula_random), data = data))
       } else{
-        out <- lm(formula, data = data)$residuals
+        adjusted <- lm(formula, data = data)$residuals
       }
     }
   }
 
-  as.vector(out)
+  # Deal with missing data
+  out <- rep(NA, nrow(data))
+  out[complete.cases(data)] <- as.vector(adjusted)
+
+  out
 }",True,False,Dependency / Package,6
easystats,effectsize,445eb01c776c0ab11a3d2a8baf489365627f00e4,Dominique Makowski,dom.mak19@gmail.com,2019-11-17T09:29:29Z,Dominique Makowski,dom.mak19@gmail.com,2019-11-17T09:29:29Z,fix note and split file,DESCRIPTION;R/convert_tFz_to_d.R;R/convert_tFz_to_r.R;R/omega_squared.R;R/standardize.data.frame.R;R/standardize.models.R;man/adjust.Rd;man/change_scale.Rd;man/cohens_d.Rd;man/d_to_r.Rd;man/format_standardize.Rd;man/interpret_parameters.Rd;man/normalize.Rd;man/ranktransform.Rd;man/standardize.Rd;man/standardize_parameters.Rd;man/t_to_r.Rd,False,True,True,False,198,120,318,"---FILE: DESCRIPTION---
@@ -62,6 +62,6 @@ Suggests:
 	see,
 	testthat,
 	tidyr
-RoxygenNote: 6.1.1
+RoxygenNote: 7.0.0
 Language: en-GB
 VignetteBuilder: knitr

---FILE: R/convert_tFz_to_d.R---
@@ -0,0 +1,50 @@
+#' @rdname t_to_r
+#' @export
+t_to_d <- function(t, df_error, pooled = FALSE, ...) {
+  if (isTRUE(pooled)) {
+    t / sqrt(df_error)
+  } else {
+    2 * t / sqrt(df_error)
+  }
+}
+
+#' @rdname t_to_r
+#' @export
+convert_t_to_d <- t_to_d
+
+
+
+
+# z -----------------------------------------------------------------------
+
+
+
+#' @rdname t_to_r
+#' @export
+z_to_d <- function(z, n, ...) {
+  2 * z / sqrt(n)
+}
+
+#' @rdname t_to_r
+#' @export
+convert_z_to_d <- z_to_d
+
+
+
+# F -----------------------------------------------------------------------
+
+
+
+
+#' @rdname t_to_r
+#' @export
+F_to_d <- function(f, df, df_error, pooled = FALSE, ...) {
+  if (df > 1) {
+    stop(""Cannot convert F with more than 1 df to (partial) r."")
+  }
+  t_to_d(sqrt(f), df_error, pooled)
+}
+
+#' @rdname t_to_r
+#' @export
+convert_F_to_d <- F_to_d

---FILE: R/convert_tFz_to_r.R---
@@ -72,19 +72,6 @@ t_to_r <- function(t, df_error, ...) {
 convert_t_to_r <- t_to_r
 
 
-#' @rdname t_to_r
-#' @export
-t_to_d <- function(t, df_error, pooled = FALSE, ...) {
-  if (isTRUE(pooled)) {
-    t / sqrt(df_error)
-  } else {
-    2 * t / sqrt(df_error)
-  }
-}
-
-#' @rdname t_to_r
-#' @export
-convert_t_to_d <- t_to_d
 
 
 
@@ -105,16 +92,6 @@ z_to_r <- function(z, n, ...) {
 convert_z_to_r <- z_to_r
 
 
-#' @rdname t_to_r
-#' @export
-z_to_d <- function(z, n, ...) {
-  2 * z / sqrt(n)
-}
-
-#' @rdname t_to_r
-#' @export
-convert_z_to_d <- z_to_d
-
 
 
 # F -----------------------------------------------------------------------
@@ -133,18 +110,3 @@ F_to_r <- function(f, df, df_error, ...) {
 #' @rdname t_to_r
 #' @export
 convert_F_to_r <- F_to_r
-
-
-
-#' @rdname t_to_r
-#' @export
-F_to_d <- function(f, df, df_error, pooled = FALSE, ...) {
-  if (df > 1) {
-    stop(""Cannot convert F with more than 1 df to (partial) r."")
-  }
-  t_to_d(sqrt(f), df_error, pooled)
-}
-
-#' @rdname t_to_r
-#' @export
-convert_F_to_d <- F_to_d

---FILE: R/omega_squared.R---
@@ -55,16 +55,17 @@ omega_squared.aovlist <- function(model, partial = TRUE, ci = NULL, iterations =
   .omega_square_from_F(par_table, ci = ci)
 }
 
+
 #' @export
-omega_squared.merMod <- function(model, partial = TRUE, ci = NULL) {
+omega_squared.merMod <- function(model, partial = TRUE, ci = NULL, iterations = 1000) {
   if (!requireNamespace(""lmerTest"", quietly = TRUE)) {
     stop(""Package 'lmerTest' required for this function to work. Please install it by running `install.packages('lmerTest')`."")
   }
 
 
   model <- lmerTest::as_lmerModLmerTest(model)
   model <- stats::anova(model)
-  omega_squared.anova(model, partial = partial, ci = ci)
+  omega_squared.anova(model, partial = partial, ci = ci, iterations = iterations)
 }
 
 
@@ -175,6 +176,7 @@ omega_squared.merMod <- function(model, partial = TRUE, ci = NULL) {
   }
 }
 
+#' @keywords internal
 .omega_square_from_F <- function(.data, ci = NULL) {
   .data$Omega_Sq_partial <- F_to_omega2(.data$`F`, .data$df, .data$df2)
 

---FILE: R/standardize.data.frame.R---
@@ -91,14 +91,6 @@ standardize.character <- standardize.factor
 #' @export
 standardize.logical <- standardize.factor
 
-
-#' @export
-standardize.Surv <- function(x, ...) {
-  insight::print_color(""'Surv' objects cannot be standardized.\n"", ""red"")
-  x
-}
-
-
 #' @export
 standardize.AsIs <- standardize.numeric
 

---FILE: R/standardize.models.R---
@@ -202,6 +202,12 @@ standardize.wbm <- function(x, ...) {
   x
 }
 
+#' @export
+standardize.Surv <- function(x, ...) {
+  insight::print_color(""'Surv' objects cannot be standardized.\n"", ""red"")
+  x
+}
+
 #' @export
 standardize.clm2 <- standardize.wbm
 

---FILE: man/adjust.Rd---
@@ -4,8 +4,15 @@
 \alias{adjust}
 \title{Adjust data for the effect of other variable(s)}
 \usage{
-adjust(data, effect = NULL, select = NULL, exclude = NULL,
-  multilevel = FALSE, additive = FALSE, bayesian = FALSE)
+adjust(
+  data,
+  effect = NULL,
+  select = NULL,
+  exclude = NULL,
+  multilevel = FALSE,
+  additive = FALSE,
+  bayesian = FALSE
+)
 }
 \arguments{
 \item{data}{A dataframe.}

---FILE: man/change_scale.Rd---
@@ -9,14 +9,25 @@
 \usage{
 change_scale(x, ...)
 
-\method{change_scale}{numeric}(x, to = c(0, 100), range = NULL,
-  verbose = TRUE, ...)
-
-\method{change_scale}{grouped_df}(x, select = NULL, exclude = NULL,
-  to = c(0, 100), range = NULL, ...)
-
-\method{change_scale}{data.frame}(x, select = NULL, exclude = NULL,
-  to = c(0, 100), range = NULL, ...)
+\method{change_scale}{numeric}(x, to = c(0, 100), range = NULL, verbose = TRUE, ...)
+
+\method{change_scale}{grouped_df}(
+  x,
+  select = NULL,
+  exclude = NULL,
+  to = c(0, 100),
+  range = NULL,
+  ...
+)
+
+\method{change_scale}{data.frame}(
+  x,
+  select = NULL,
+  exclude = NULL,
+  to = c(0, 100),
+  range = NULL,
+  ...
+)
 }
 \arguments{
 \item{x}{Object.}

---FILE: man/cohens_d.Rd---
@@ -6,11 +6,23 @@
 \alias{glass_delta}
 \title{Effect size for differences}
 \usage{
-cohens_d(x, y = NULL, data = NULL, correction = FALSE,
-  pooled_sd = TRUE, paired = FALSE)
-
-hedges_g(x, y = NULL, data = NULL, correction = FALSE,
-  pooled_sd = TRUE, paired = FALSE)
+cohens_d(
+  x,
+  y = NULL,
+  data = NULL,
+  correction = FALSE,
+  pooled_sd = TRUE,
+  paired = FALSE
+)
+
+hedges_g(
+  x,
+  y = NULL,
+  data = NULL,
+  correction = FALSE,
+  pooled_sd = TRUE,
+  paired = FALSE
+)
 
 glass_delta(x, y = NULL, data = NULL, correction = FALSE)
 }

---FILE: man/d_to_r.Rd---
@@ -59,8 +59,7 @@ convert_odds_to_r(odds, log = FALSE, ...)
 
 odds_to_probs(odds, log = FALSE, ...)
 
-\method{odds_to_probs}{data.frame}(odds, log = FALSE, select = NULL,
-  exclude = NULL, ...)
+\method{odds_to_probs}{data.frame}(odds, log = FALSE, select = NULL, exclude = NULL, ...)
 
 probs_to_odds(probs, log = FALSE, ...)
 

---FILE: man/format_standardize.Rd---
@@ -4,8 +4,7 @@
 \alias{format_standardize}
 \title{Transform a standardized vector into character}
 \usage{
-format_standardize(x, reference = x, robust = FALSE, digits = NULL,
-  ...)
+format_standardize(x, reference = x, robust = FALSE, digits = NULL, ...)
 }
 \arguments{
 \item{x}{A standardized numeric vector.}

---FILE: man/interpret_parameters.Rd---
@@ -7,9 +7,14 @@
 \usage{
 interpret_parameters(model, ...)
 
-\method{interpret_parameters}{lm}(model, parameters = NULL,
-  interpretation = ""funder2019"", standardize_method = ""refit"",
-  standardize_robust = FALSE, ...)
+\method{interpret_parameters}{lm}(
+  model,
+  parameters = NULL,
+  interpretation = ""funder2019"",
+  standardize_method = ""refit"",
+  standardize_robust = FALSE,
+  ...
+)
 }
 \arguments{
 \item{model}{A statistical model.}

---FILE: man/normalize.Rd---
@@ -9,14 +9,11 @@
 \usage{
 normalize(x, ...)
 
-\method{normalize}{numeric}(x, include_bounds = TRUE, verbose = TRUE,
-  ...)
+\method{normalize}{numeric}(x, include_bounds = TRUE, verbose = TRUE, ...)
 
-\method{normalize}{grouped_df}(x, select = NULL, exclude = NULL,
-  include_bounds = TRUE, ...)
+\method{normalize}{grouped_df}(x, select = NULL, exclude = NULL, include_bounds = TRUE, ...)
 
-\method{normalize}{data.frame}(x, select = NULL, exclude = NULL,
-  include_bounds = TRUE, ...)
+\method{normalize}{data.frame}(x, select = NULL, exclude = NULL, include_bounds = TRUE, ...)
 }
 \arguments{
 \item{x}{Object.}

---FILE: man/ranktransform.Rd---
@@ -9,14 +9,25 @@
 \usage{
 ranktransform(x, ...)
 
-\method{ranktransform}{numeric}(x, sign = FALSE, method = ""average"",
-  verbose = TRUE, ...)
-
-\method{ranktransform}{grouped_df}(x, select = NULL, exclude = NULL,
-  sign = FALSE, method = ""average"", ...)
-
-\method{ranktransform}{data.frame}(x, select = NULL, exclude = NULL,
-  sign = FALSE, method = ""average"", ...)
+\method{ranktransform}{numeric}(x, sign = FALSE, method = ""average"", verbose = TRUE, ...)
+
+\method{ranktransform}{grouped_df}(
+  x,
+  select = NULL,
+  exclude = NULL,
+  sign = FALSE,
+  method = ""average"",
+  ...
+)
+
+\method{ranktransform}{data.frame}(
+  x,
+  select = NULL,
+  exclude = NULL,
+  sign = FALSE,
+  method = ""average"",
+  ...
+)
 }
 \arguments{
 \item{x}{Object.}

---FILE: man/standardize.Rd---
@@ -11,17 +11,29 @@
 \usage{
 standardize(x, ...)
 
-\method{standardize}{numeric}(x, robust = FALSE, two_sd = FALSE,
-  verbose = TRUE, ...)
+\method{standardize}{numeric}(x, robust = FALSE, two_sd = FALSE, verbose = TRUE, ...)
 
 \method{standardize}{factor}(x, force = FALSE, ...)
 
-\method{standardize}{data.frame}(x, robust = FALSE, two_sd = FALSE,
-  select = NULL, exclude = NULL, verbose = TRUE, force = FALSE,
-  ...)
+\method{standardize}{data.frame}(
+  x,
+  robust = FALSE,
+  two_sd = FALSE,
+  select = NULL,
+  exclude = NULL,
+  verbose = TRUE,
+  force = FALSE,
+  ...
+)
 
-\method{standardize}{lm}(x, robust = FALSE, two_sd = FALSE,
-  include_response = TRUE, verbose = TRUE, ...)
+\method{standardize}{lm}(
+  x,
+  robust = FALSE,
+  two_sd = FALSE,
+  include_response = TRUE,
+  verbose = TRUE,
+  ...
+)
 }
 \arguments{
 \item{x}{A dataframe, a vector or a statistical model.}

---FILE: man/standardize_parameters.Rd---
@@ -5,12 +5,25 @@
 \alias{standardize_posteriors}
 \title{Parameters standardization}
 \usage{
-standardize_parameters(model, parameters = NULL, method = ""refit"",
-  robust = FALSE, two_sd = FALSE, verbose = TRUE,
-  centrality = ""median"", ...)
+standardize_parameters(
+  model,
+  parameters = NULL,
+  method = ""refit"",
+  robust = FALSE,
+  two_sd = FALSE,
+  verbose = TRUE,
+  centrality = ""median"",
+  ...
+)
 
-standardize_posteriors(model, method = ""refit"", robust = FALSE,
-  two_sd = FALSE, verbose = TRUE, ...)
+standardize_posteriors(
+  model,
+  method = ""refit"",
+  robust = FALSE,
+  two_sd = FALSE,
+  verbose = TRUE,
+  ...
+)
 }
 \arguments{
 \item{model}{A statistical model.}

---FILE: man/t_to_r.Rd---
@@ -1,51 +1,51 @@
 % Generated by roxygen2: do not edit by hand
-% Please edit documentation in R/convert_tFz_to_rd.R
-\name{t_to_r}
-\alias{t_to_r}
-\alias{convert_t_to_r}
+% Please edit documentation in R/convert_tFz_to_d.R, R/convert_tFz_to_r.R
+\name{t_to_d}
 \alias{t_to_d}
 \alias{convert_t_to_d}
-\alias{z_to_r}
-\alias{convert_z_to_r}
 \alias{z_to_d}
 \alias{convert_z_to_d}
-\alias{F_to_r}
-\alias{convert_F_to_r}
 \alias{F_to_d}
 \alias{convert_F_to_d}
+\alias{t_to_r}
+\alias{convert_t_to_r}
+\alias{z_to_r}
+\alias{convert_z_to_r}
+\alias{F_to_r}
+\alias{convert_F_to_r}
 \title{Convert test statistics (t, z, F) to effect sizes of differences (Cohen's d) or association (\strong{partial} r)}
 \usage{
-t_to_r(t, df_error, ...)
-
-convert_t_to_r(t, df_error, ...)
-
 t_to_d(t, df_error, pooled = FALSE, ...)
 
 convert_t_to_d(t, df_error, pooled = FALSE, ...)
 
-z_to_r(z, n, ...)
-
-convert_z_to_r(z, n, ...)
-
 z_to_d(z, n, ...)
 
 convert_z_to_d(z, n, ...)
 
-F_to_r(f, df, df_error, ...)
-
-convert_F_to_r(f, df, df_error, ...)
-
 F_to_d(f, df, df_error, pooled = FALSE, ...)
 
 convert_F_to_d(f, df, df_error, pooled = FALSE, ...)
+
+t_to_r(t, df_error, ...)
+
+convert_t_to_r(t, df_error, ...)
+
+z_to_r(z, n, ...)
+
+convert_z_to_r(z, n, ...)
+
+F_to_r(f, df, df_error, ...)
+
+convert_F_to_r(f, df, df_error, ...)
 }
 \arguments{
 \item{t, f, z}{The t, the F or the z statistics.}
 
-\item{...}{Arguments passed to or from other methods.}
-
 \item{pooled}{Should the estimate accout for the t-value being based on a repeated-measures design, or not (default).}
 
+\item{...}{Arguments passed to or from other methods.}
+
 \item{n}{The number of observations (samples size).}
 
 \item{df, df_error}{Degrees of freedom of numerator or of the error estimate (i.e., the residuals).}
@@ -86,7 +86,7 @@ t_to_r(res$statistic, res$parameter)
 model <- lm(Sepal.Length ~ Sepal.Width + Petal.Length, data = iris)
 library(parameters)
 (param_tab <- parameters(model))
-# > Parameter    | Coefficient |   SE |       95\% CI |     t |  df |      p
+# > Parameter    | Coefficient |   SE |       95% CI |     t |  df |      p
 # > -----------------------------------------------------------------------
 # > (Intercept)  |        2.25 | 0.25 | [1.76, 2.74] |  9.07 | 147 | < .001
 # > Sepal.Width  |        0.60 | 0.07 | [0.46, 0.73] |  8.59 | 147 | < .001",True,False,Documentation / Formatting,6
easystats,effectsize,fbc6f3843c8d9c660ff507654fc071be889671d6,Daniel,mail@danielluedecke.de,2019-11-15T17:13:55Z,Daniel,mail@danielluedecke.de,2019-11-15T17:13:55Z,fix CRAN check issues,DESCRIPTION,False,False,False,False,0,1,1,"---FILE: DESCRIPTION---
@@ -38,7 +38,6 @@ Imports:
 	insight (>= 0.6.0),
 	bayestestR (>= 0.4.0),
 	parameters (>= 0.2.0),
-	methods,
 	stats,
 	utils
 Suggests:",False,False,Dependency / Package,7
easystats,effectsize,18985b339fc068dca7e4bb8f30ede7e586e03f2f,Daniel LÃ¼decke,mail@danielluedecke.de,2019-10-22T09:54:58Z,Daniel LÃ¼decke,mail@danielluedecke.de,2019-10-22T09:54:58Z,fix URLs in vignettes,docs/404.html;docs/CODE_OF_CONDUCT.html;docs/CONTRIBUTING.html;docs/LICENSE-text.html;docs/PULL_REQUEST_TEMPLATE.html;docs/articles/bayesian_models.html;docs/articles/convert.html;docs/articles/index.html;docs/articles/interpret.html;docs/articles/standardize_data.html;docs/articles/standardize_parameters.html;docs/authors.html;docs/index.html;docs/news/index.html;docs/pkgdown.yml;docs/reference/F_to_partial_eta_squared.html;docs/reference/change_scale.html;docs/reference/chisq_to_phi.html;docs/reference/cohens_d.html;docs/reference/convert_posteriors_to_r.html;docs/reference/d_to_r.html;docs/reference/dot-factor_to_numeric.html;docs/reference/eta_squared.html;docs/reference/format_standardize.html;docs/reference/index.html;docs/reference/interpret.html;docs/reference/interpret_bf.html;docs/reference/interpret_d.html;docs/reference/interpret_direction.html;docs/reference/interpret_ess.html;docs/reference/interpret_gfi.html;docs/reference/interpret_odds.html;docs/reference/interpret_omega_squared.html;docs/reference/interpret_p.html;docs/reference/interpret_parameters.html;docs/reference/interpret_r.html;docs/reference/interpret_r2.html;docs/reference/normalize.html;docs/reference/ranktransform.html;docs/reference/rules.html;docs/reference/sd_pooled.html;docs/reference/standardize.html;docs/reference/standardize_info.html;docs/reference/standardize_parameters.html;docs/reference/t_to_r.html;vignettes/interpret.Rmd;vignettes/standardize_parameters.Rmd,True,False,True,False,8566,9327,17893,"---FILE: docs/404.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,13 +41,14 @@
 
 
 
-<meta property=""og:title"" content=""Page not found (404)"" />
 
+<meta property=""og:title"" content=""Page not found (404)"" />
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -125,7 +128,6 @@
   <a href=""articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -163,7 +165,7 @@ <h1>Page not found (404)</h1>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/CODE_OF_CONDUCT.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,13 +41,14 @@
 
 
 
-<meta property=""og:title"" content=""Contributor Covenant Code of Conduct"" />
 
+<meta property=""og:title"" content=""Contributor Covenant Code of Conduct"" />
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -125,7 +128,6 @@
   <a href=""articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -212,7 +214,7 @@ <h2 class=""hasAnchor"">
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/CONTRIBUTING.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,13 +41,14 @@
 
 
 
-<meta property=""og:title"" content=""Contribution Guidelines"" />
 
+<meta property=""og:title"" content=""Contribution Guidelines"" />
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -125,7 +128,6 @@
   <a href=""articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -193,7 +195,7 @@ <h2 class=""hasAnchor"">
 <li>
 <code><a href=""https://rdrr.io/pkg/styler/man/style_pkg.html"">styler::style_pkg()</a></code>: Automatic style formatting</li>
 <li>
-<code>lintr::lint_package()</code>: Style checks</li>
+<code><a href=""https://rdrr.io/pkg/lintr/man/lint_package.html"">lintr::lint_package()</a></code>: Style checks</li>
 <li>
 <code><a href=""https://rdrr.io/pkg/devtools/man/check.html"">devtools::check()</a></code>: General checks</li>
 </ul>
@@ -221,7 +223,7 @@ <h2 class=""hasAnchor"">
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/LICENSE-text.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,13 +41,14 @@
 
 
 
-<meta property=""og:title"" content=""License"" />
 
+<meta property=""og:title"" content=""License"" />
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -125,7 +128,6 @@
   <a href=""articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -837,7 +839,7 @@ <h1>License</h1>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/PULL_REQUEST_TEMPLATE.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,13 +41,14 @@
 
 
 
-<meta property=""og:title"" content=""Description"" />
 
+<meta property=""og:title"" content=""Description"" />
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -125,7 +128,6 @@
   <a href=""articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -173,7 +175,7 @@ <h1 class=""hasAnchor"">
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/articles/bayesian_models.html---
@@ -155,7 +155,6 @@ <h3 class=""hasAnchor"">
 <a class=""sourceLine"" id=""cb8-2"" title=""2""></a>
 <a class=""sourceLine"" id=""cb8-3"" title=""3"">r &lt;-<span class=""st""> </span><span class=""kw""><a href=""../reference/convert_posteriors_to_r.html"">convert_posteriors_to_r</a></span>(model)</a>
 <a class=""sourceLine"" id=""cb8-4"" title=""4"">bayestestR<span class=""op"">::</span><span class=""kw""><a href=""https://rdrr.io/pkg/bayestestR/man/describe_posterior.html"">describe_posterior</a></span>(r)<span class=""op"">$</span>Median[<span class=""dv"">2</span><span class=""op"">:</span><span class=""dv"">4</span>]</a></code></pre></div>
-<pre><code>&gt; [1]  0.63  0.71 -0.33</code></pre>
 </div>
 <div id=""applicability"" class=""section level3"">
 <h3 class=""hasAnchor"">
@@ -165,49 +164,25 @@ <h3 class=""hasAnchor"">
 <h4 class=""hasAnchor"">
 <a href=""#logistic-models"" class=""anchor""></a>Logistic Models</h4>
 <p>Letâs start with the frequentist model:</p>
-<div class=""sourceCode"" id=""cb10""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb10-1"" title=""1"">model &lt;-<span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/stats/glm.html"">glm</a></span>(vs <span class=""op"">~</span><span class=""st""> </span>cyl <span class=""op"">+</span><span class=""st""> </span>disp <span class=""op"">+</span><span class=""st""> </span>drat, <span class=""dt"">data =</span> mtcars, <span class=""dt"">family =</span> <span class=""st"">""binomial""</span>)</a>
-<a class=""sourceLine"" id=""cb10-2"" title=""2""></a>
-<a class=""sourceLine"" id=""cb10-3"" title=""3"">parameters &lt;-<span class=""st""> </span><span class=""kw"">model_parameters</span>(model)</a>
-<a class=""sourceLine"" id=""cb10-4"" title=""4"">parameters<span class=""op"">$</span>r &lt;-<span class=""st""> </span><span class=""kw""><a href=""../reference/t_to_r.html"">convert_z_to_r</a></span>(parameters<span class=""op"">$</span>z, <span class=""dt"">n =</span> insight<span class=""op"">::</span><span class=""kw""><a href=""https://rdrr.io/pkg/insight/man/n_obs.html"">n_obs</a></span>(model))</a>
-<a class=""sourceLine"" id=""cb10-5"" title=""5"">parameters</a></code></pre></div>
-<pre><code>&gt; Parameter   | Coefficient |    SE |         95% CI |     z | df |     p |     r
-&gt; -------------------------------------------------------------------------------
-&gt; (Intercept) |       25.09 | 11.88 | [ 6.43, 56.94] |  2.11 | 28 | &lt; .05 |  0.35
-&gt; cyl         |       -1.99 |  1.05 | [-4.57, -0.13] | -1.89 | 28 | 0.06  | -0.32
-&gt; disp        |       -0.01 |  0.02 | [-0.06,  0.02] | -0.47 | 28 | 0.64  | -0.08
-&gt; drat        |       -3.18 |  2.16 | [-8.70,  0.49] | -1.47 | 28 | 0.14  | -0.25</code></pre>
+<div class=""sourceCode"" id=""cb9""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb9-1"" title=""1"">model &lt;-<span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/stats/glm.html"">glm</a></span>(vs <span class=""op"">~</span><span class=""st""> </span>cyl <span class=""op"">+</span><span class=""st""> </span>disp <span class=""op"">+</span><span class=""st""> </span>drat, <span class=""dt"">data =</span> mtcars, <span class=""dt"">family =</span> <span class=""st"">""binomial""</span>)</a>
+<a class=""sourceLine"" id=""cb9-2"" title=""2""></a>
+<a class=""sourceLine"" id=""cb9-3"" title=""3"">parameters &lt;-<span class=""st""> </span><span class=""kw"">model_parameters</span>(model)</a>
+<a class=""sourceLine"" id=""cb9-4"" title=""4"">parameters<span class=""op"">$</span>r &lt;-<span class=""st""> </span><span class=""kw""><a href=""../reference/t_to_r.html"">convert_z_to_r</a></span>(parameters<span class=""op"">$</span>z, <span class=""dt"">n =</span> insight<span class=""op"">::</span><span class=""kw""><a href=""https://rdrr.io/pkg/insight/man/n_obs.html"">n_obs</a></span>(model))</a>
+<a class=""sourceLine"" id=""cb9-5"" title=""5"">parameters</a></code></pre></div>
 <p>However, as logistic models return log-odds, these can be directly converted to <em>r</em>:</p>
-<div class=""sourceCode"" id=""cb12""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb12-1"" title=""1"">parameters<span class=""op"">$</span>r_from_odds &lt;-<span class=""st""> </span><span class=""kw""><a href=""../reference/d_to_r.html"">convert_odds_to_r</a></span>(parameters<span class=""op"">$</span>Coefficient, <span class=""dt"">log =</span> <span class=""ot"">TRUE</span>)</a>
-<a class=""sourceLine"" id=""cb12-2"" title=""2"">parameters</a></code></pre></div>
-<pre><code>&gt; Parameter   | Coefficient |    SE |         95% CI |     z | df |     p |     r | r_from_odds
-&gt; ---------------------------------------------------------------------------------------------
-&gt; (Intercept) |       25.09 | 11.88 | [ 6.43, 56.94] |  2.11 | 28 | &lt; .05 |  0.35 |        0.99
-&gt; cyl         |       -1.99 |  1.05 | [-4.57, -0.13] | -1.89 | 28 | 0.06  | -0.32 |       -0.48
-&gt; disp        |       -0.01 |  0.02 | [-0.06,  0.02] | -0.47 | 28 | 0.64  | -0.08 |        0.00
-&gt; drat        |       -3.18 |  2.16 | [-8.70,  0.49] | -1.47 | 28 | 0.14  | -0.25 |       -0.66</code></pre>
+<div class=""sourceCode"" id=""cb10""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb10-1"" title=""1"">parameters<span class=""op"">$</span>r_from_odds &lt;-<span class=""st""> </span><span class=""kw""><a href=""../reference/d_to_r.html"">convert_odds_to_r</a></span>(parameters<span class=""op"">$</span>Coefficient, <span class=""dt"">log =</span> <span class=""ot"">TRUE</span>)</a>
+<a class=""sourceLine"" id=""cb10-2"" title=""2"">parameters</a></code></pre></div>
 <p>And now the Bayesian:</p>
-<div class=""sourceCode"" id=""cb14""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb14-1"" title=""1"">model &lt;-<span class=""st""> </span><span class=""kw"">stan_glm</span>(vs <span class=""op"">~</span><span class=""st""> </span>cyl <span class=""op"">+</span><span class=""st""> </span>disp <span class=""op"">+</span><span class=""st""> </span>drat,, <span class=""dt"">data =</span> mtcars, <span class=""dt"">family =</span> <span class=""st"">""binomial""</span>) </a></code></pre></div>
-<div class=""sourceCode"" id=""cb15""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb15-1"" title=""1"">parameters &lt;-<span class=""st""> </span><span class=""kw"">model_parameters</span>(model)</a>
-<a class=""sourceLine"" id=""cb15-2"" title=""2"">r &lt;-<span class=""st""> </span><span class=""kw""><a href=""../reference/convert_posteriors_to_r.html"">convert_posteriors_to_r</a></span>(model)</a>
-<a class=""sourceLine"" id=""cb15-3"" title=""3"">parameters<span class=""op"">$</span>r &lt;-<span class=""st""> </span>bayestestR<span class=""op"">::</span><span class=""kw""><a href=""https://rdrr.io/pkg/bayestestR/man/describe_posterior.html"">describe_posterior</a></span>(r)<span class=""op"">$</span>Median</a>
-<a class=""sourceLine"" id=""cb15-4"" title=""4"">parameters</a></code></pre></div>
-<pre><code>&gt; Parameter   | Median |         89% CI |     pd | % in ROPE |  Rhat |  ESS |               Prior |     r
-&gt; -------------------------------------------------------------------------------------------------------
-&gt; (Intercept) |  21.48 | [ 7.38, 35.03] | 99.80% |     0.02% | 1.001 | 2247 | Normal (0 +- 10.00) |  0.42
-&gt; cyl         |  -1.69 | [-2.84, -0.56] | 99.65% |     1.00% | 1.001 | 2259 |  Normal (0 +- 1.40) | -0.40
-&gt; disp        |  -0.01 | [-0.03,  0.01] | 84.52% |      100% | 1.003 | 2056 |  Normal (0 +- 0.02) | -0.18
-&gt; drat        |  -2.57 | [-5.25,  0.01] | 94.65% |     2.35% | 1.001 | 2286 |  Normal (0 +- 4.68) | -0.28</code></pre>
-<div class=""sourceCode"" id=""cb17""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb17-1"" title=""1"">parameters &lt;-<span class=""st""> </span><span class=""kw"">model_parameters</span>(model)</a>
-<a class=""sourceLine"" id=""cb17-2"" title=""2"">r &lt;-<span class=""st""> </span><span class=""kw""><a href=""../reference/convert_posteriors_to_r.html"">convert_posteriors_to_r</a></span>(model)</a>
-<a class=""sourceLine"" id=""cb17-3"" title=""3"">parameters<span class=""op"">$</span>r &lt;-<span class=""st""> </span>bayestestR<span class=""op"">::</span><span class=""kw""><a href=""https://rdrr.io/pkg/bayestestR/man/describe_posterior.html"">describe_posterior</a></span>(r)<span class=""op"">$</span>Median</a>
-<a class=""sourceLine"" id=""cb17-4"" title=""4"">parameters<span class=""op"">$</span>r_from_odds &lt;-<span class=""st""> </span><span class=""kw""><a href=""../reference/d_to_r.html"">convert_odds_to_r</a></span>(parameters<span class=""op"">$</span>Median, <span class=""dt"">log =</span> <span class=""ot"">TRUE</span>)</a>
-<a class=""sourceLine"" id=""cb17-5"" title=""5"">parameters</a></code></pre></div>
-<pre><code>&gt; Parameter   | Median |         89% CI |     pd | % in ROPE |  Rhat |  ESS |               Prior |     r | r_from_odds
-&gt; ---------------------------------------------------------------------------------------------------------------------
-&gt; (Intercept) |  21.48 | [ 7.38, 35.03] | 99.80% |     0.02% | 1.001 | 2247 | Normal (0 +- 10.00) |  0.42 |        0.99
-&gt; cyl         |  -1.69 | [-2.84, -0.56] | 99.65% |     1.00% | 1.001 | 2259 |  Normal (0 +- 1.40) | -0.40 |       -0.42
-&gt; disp        |  -0.01 | [-0.03,  0.01] | 84.52% |      100% | 1.003 | 2056 |  Normal (0 +- 0.02) | -0.18 |        0.00
-&gt; drat        |  -2.57 | [-5.25,  0.01] | 94.65% |     2.35% | 1.001 | 2286 |  Normal (0 +- 4.68) | -0.28 |       -0.58</code></pre>
+<div class=""sourceCode"" id=""cb11""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb11-1"" title=""1"">model &lt;-<span class=""st""> </span><span class=""kw"">stan_glm</span>(vs <span class=""op"">~</span><span class=""st""> </span>cyl <span class=""op"">+</span><span class=""st""> </span>disp <span class=""op"">+</span><span class=""st""> </span>drat,, <span class=""dt"">data =</span> mtcars, <span class=""dt"">family =</span> <span class=""st"">""binomial""</span>) </a></code></pre></div>
+<div class=""sourceCode"" id=""cb12""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb12-1"" title=""1"">parameters &lt;-<span class=""st""> </span><span class=""kw"">model_parameters</span>(model)</a>
+<a class=""sourceLine"" id=""cb12-2"" title=""2"">r &lt;-<span class=""st""> </span><span class=""kw""><a href=""../reference/convert_posteriors_to_r.html"">convert_posteriors_to_r</a></span>(model)</a>
+<a class=""sourceLine"" id=""cb12-3"" title=""3"">parameters<span class=""op"">$</span>r &lt;-<span class=""st""> </span>bayestestR<span class=""op"">::</span><span class=""kw""><a href=""https://rdrr.io/pkg/bayestestR/man/describe_posterior.html"">describe_posterior</a></span>(r)<span class=""op"">$</span>Median</a>
+<a class=""sourceLine"" id=""cb12-4"" title=""4"">parameters</a></code></pre></div>
+<div class=""sourceCode"" id=""cb13""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb13-1"" title=""1"">parameters &lt;-<span class=""st""> </span><span class=""kw"">model_parameters</span>(model)</a>
+<a class=""sourceLine"" id=""cb13-2"" title=""2"">r &lt;-<span class=""st""> </span><span class=""kw""><a href=""../reference/convert_posteriors_to_r.html"">convert_posteriors_to_r</a></span>(model)</a>
+<a class=""sourceLine"" id=""cb13-3"" title=""3"">parameters<span class=""op"">$</span>r &lt;-<span class=""st""> </span>bayestestR<span class=""op"">::</span><span class=""kw""><a href=""https://rdrr.io/pkg/bayestestR/man/describe_posterior.html"">describe_posterior</a></span>(r)<span class=""op"">$</span>Median</a>
+<a class=""sourceLine"" id=""cb13-4"" title=""4"">parameters<span class=""op"">$</span>r_from_odds &lt;-<span class=""st""> </span><span class=""kw""><a href=""../reference/d_to_r.html"">convert_odds_to_r</a></span>(parameters<span class=""op"">$</span>Median, <span class=""dt"">log =</span> <span class=""ot"">TRUE</span>)</a>
+<a class=""sourceLine"" id=""cb13-5"" title=""5"">parameters</a></code></pre></div>
 </div>
 </div>
 </div>
@@ -218,6 +193,7 @@ <h2 class=""hasAnchor"">
   </div>
 
   <div class=""col-md-3 hidden-xs hidden-sm"" id=""sidebar"">
+
         <div id=""tocnav"">
       <h2 class=""hasAnchor"">
 <a href=""#tocnav"" class=""anchor""></a>Contents</h2>
@@ -237,7 +213,7 @@ <h2 class=""hasAnchor"">
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/articles/convert.html---
@@ -132,6 +132,7 @@ <h2 class=""hasAnchor"">
   </div>
 
   <div class=""col-md-3 hidden-xs hidden-sm"" id=""sidebar"">
+
         <div id=""tocnav"">
       <h2 class=""hasAnchor"">
 <a href=""#tocnav"" class=""anchor""></a>Contents</h2>
@@ -150,7 +151,7 @@ <h2 class=""hasAnchor"">
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/articles/index.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,13 +41,14 @@
 
 
 
-<meta property=""og:title"" content=""Articles"" />
 
+<meta property=""og:title"" content=""Articles"" />
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -125,7 +128,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -171,7 +173,7 @@ <h3>All vignettes</h3>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/articles/interpret.html---
@@ -440,7 +440,7 @@ <h3 class=""hasAnchor"">
 <div id=""other-bayesian-indices-in-rope-pd"" class=""section level3"">
 <h3 class=""hasAnchor"">
 <a href=""#other-bayesian-indices-in-rope-pd"" class=""anchor""></a>Other Bayesian Indices (% in ROPE, <em>pd</em>)</h3>
-<p>The interpretation of Bayesian indices is detailed in <a href=""https://easystats.github.io/bayestestR/articles/4_Guidelines.html"">this article</a>.</p>
+<p>The interpretation of Bayesian indices is detailed in <a href=""https://easystats.github.io/bayestestR/articles/guidelines.html"">this article</a>.</p>
 </div>
 <div id=""references"" class=""section level2 unnumbered"">
 <h2 class=""hasAnchor"">
@@ -500,6 +500,7 @@ <h2 class=""hasAnchor"">
   </div>
 
   <div class=""col-md-3 hidden-xs hidden-sm"" id=""sidebar"">
+
         <div id=""tocnav"">
       <h2 class=""hasAnchor"">
 <a href=""#tocnav"" class=""anchor""></a>Contents</h2>
@@ -523,7 +524,7 @@ <h2 class=""hasAnchor"">
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/articles/standardize_data.html---
@@ -161,6 +161,7 @@ <h1 class=""hasAnchor"">
   </div>
 
   <div class=""col-md-3 hidden-xs hidden-sm"" id=""sidebar"">
+
         <div id=""tocnav"">
       <h2 class=""hasAnchor"">
 <a href=""#tocnav"" class=""anchor""></a>Contents</h2>
@@ -185,7 +186,7 @@ <h2 class=""hasAnchor"">
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/articles/standardize_parameters.html---
@@ -123,7 +123,7 @@ <h1>Parameters Standardization</h1>
 <div id=""introduction"" class=""section level1"">
 <h1 class=""hasAnchor"">
 <a href=""#introduction"" class=""anchor""></a>Introduction</h1>
-<p>Standardising parameters (<em>i.e.</em>, coefficients) can allow for their comparison within and between models, variables and studies. Moreover, as it returns coefficients expressed in terms of <strong>change of variance</strong> (for instance, coefficients expresed in terms of SD of the response variable), it can allow for the usage of <a href=""https://easystats.github.io/easystats/articles/interpret.html"">effect size interpretation guidelines</a>, such as the famous Cohenâs (1988) rules of thumb.</p>
+<p>Standardising parameters (<em>i.e.</em>, coefficients) can allow for their comparison within and between models, variables and studies. Moreover, as it returns coefficients expressed in terms of <strong>change of variance</strong> (for instance, coefficients expresed in terms of SD of the response variable), it can allow for the usage of <a href=""https://easystats.github.io/effectsize/articles/interpret.html"">effect size interpretation guidelines</a>, such as the famous Cohenâs (1988) rules of thumb.</p>
 <p>However, standardizing the modelâs parameters should <em>not</em> be automatically and mindlessly done: for some research fields, particular variables or types of studies (<em>e.g.</em>, replications), it sometimes makes more sense to keep, use and interpret the original parameters, especially if they are well known or easily understood.</p>
 <p>Critically, <strong>parameters standardization is not a trivial process</strong>. Different techniques exist, that can lead to drastically different results. Thus, it is critical that the standardization method is explicitly documented and detailed.</p>
 <p><strong><code>parameters</code> include different techniques of parameters standardization</strong>, described below <span class=""citation"">(Bring 1994; Menard 2004, 2011; Gelman 2008; Schielzeth 2010)</span>.</p>
@@ -257,837 +257,237 @@ <h2 class=""hasAnchor"">
 </tr>
 </tbody>
 </table>
-<p>Not really. Why? Because the actual formula to compute a <strong>Cohenâs <em>d</em></strong> doesnât use the simple SD to scale the effect (as it is done when standardizing the parameters), but computes something called the <a href=""https://easystats.github.io/effectsize/reference/pooled_sd.html""><strong>pooled SD</strong></a>. However, this can be turned off by setting <code>correct = ""raw""</code>.</p>
+<p>Not really. Why? Because the actual formula to compute a <strong>Cohenâs <em>d</em></strong> doesnât use the simple SD to scale the effect (as it is done when standardizing the parameters), but computes something called the <a href=""https://easystats.github.io/effectsize/reference/sd_pooled.html""><strong>pooled SD</strong></a>. However, this can be turned off by setting <code>correct = ""raw""</code>.</p>
 <div class=""sourceCode"" id=""cb13""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb13-1"" title=""1""><span class=""kw""><a href=""../reference/cohens_d.html"">cohens_d</a></span>(Sepal.Length <span class=""op"">~</span><span class=""st""> </span>Species, <span class=""dt"">data =</span> data, <span class=""dt"">pooled_sd =</span> <span class=""ot"">FALSE</span>) </a></code></pre></div>
 <pre><code>&gt; [1] 1.4</code></pre>
 <p><strong><em>And here we are :)</em></strong></p>
-<p>However, it is interesting to note that using the <em>smart</em> method when standardizing parameters will give you indices equivalent to <strong>Glassâ delta</strong>, which difference is expressed in terms of SD of the intercept (the âreferenceâ factor levels).</p>
-<div class=""sourceCode"" id=""cb15""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb15-1"" title=""1""><span class=""kw""><a href=""https://rdrr.io/r/stats/lm.html"">lm</a></span>(Sepal.Length <span class=""op"">~</span><span class=""st""> </span>Species, <span class=""dt"">data =</span> data) <span class=""op"">%&gt;%</span><span class=""st""> </span></a>
-<a class=""sourceLine"" id=""cb15-2"" title=""2""><span class=""st"">  </span><span class=""kw""><a href=""../reference/standardize_parameters.html"">standardize_parameters</a></span>(<span class=""dt"">method =</span> <span class=""st"">""smart""</span>)</a></code></pre></div>
-<table class=""table"">
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""right"">Std_Coefficient</th>
-</tr></thead>
-<tbody>
-<tr class=""odd"">
-<td align=""left"">(Intercept)</td>
-<td align=""right"">0.0</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Speciesversicolor</td>
-<td align=""right"">2.6</td>
-</tr>
-</tbody>
-</table>
-<div class=""sourceCode"" id=""cb16""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb16-1"" title=""1""><span class=""kw""><a href=""../reference/cohens_d.html"">glass_delta</a></span>(Sepal.Length <span class=""op"">~</span><span class=""st""> </span>Species, <span class=""dt"">data =</span> data)</a></code></pre></div>
-<pre><code>&gt; [1] 2.6</code></pre>
-</div>
-<div id=""what-about-standardized-interaction-effects"" class=""section level2"">
-<h2 class=""hasAnchor"">
-<a href=""#what-about-standardized-interaction-effects"" class=""anchor""></a>What about standardized interaction effects?</h2>
-<p>Well, this oneâs a mess (at least for me). Help is required to make sense out of it. Otherwise, <em>NEXT</em>.</p>
-</div>
-</div>
-<div id=""standardization-methods"" class=""section level1"">
-<h1 class=""hasAnchor"">
-<a href=""#standardization-methods"" class=""anchor""></a>Standardization methods</h1>
-<div id=""refit-re-fitting-the-model-with-standardized-data"" class=""section level3"">
-<h3 class=""hasAnchor"">
-<a href=""#refit-re-fitting-the-model-with-standardized-data"" class=""anchor""></a><strong>ârefitâ</strong>: Re-fitting the model with standardized data</h3>
-<p><strong>This method is based on a complete model re-fit with a standardized version of data</strong>. Hence, this method is equal to standardizing the variables before fitting the model. It is the âpurestâ and the most accurate (Neter et al., 1989), but it is also the most computationally costly and long (especially for heavy models such as, for instance, for Bayesian models). This method is particularly recommended for complex models that include interactions or transformations (e.g., polynomial or spline terms).</p>
-<div class=""sourceCode"" id=""cb18""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb18-1"" title=""1""><span class=""kw""><a href=""https://rdrr.io/r/base/library.html"">library</a></span>(effectsize)</a>
-<a class=""sourceLine"" id=""cb18-2"" title=""2""></a>
-<a class=""sourceLine"" id=""cb18-3"" title=""3"">data &lt;-<span class=""st""> </span>iris</a>
-<a class=""sourceLine"" id=""cb18-4"" title=""4"">model &lt;-<span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/stats/lm.html"">lm</a></span>(Sepal.Length <span class=""op"">~</span><span class=""st""> </span>Petal.Width <span class=""op"">+</span><span class=""st""> </span>Sepal.Width, <span class=""dt"">data=</span>data)</a>
-<a class=""sourceLine"" id=""cb18-5"" title=""5""></a>
-<a class=""sourceLine"" id=""cb18-6"" title=""6""><span class=""kw""><a href=""../reference/standardize_parameters.html"">standardize_parameters</a></span>(model, <span class=""dt"">method=</span><span class=""st"">""refit""</span>)</a></code></pre></div>
-<table class=""table"">
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""right"">Std_Coefficient</th>
-</tr></thead>
-<tbody>
-<tr class=""odd"">
-<td align=""left"">(Intercept)</td>
-<td align=""right"">0.00</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Petal.Width</td>
-<td align=""right"">0.89</td>
-</tr>
-<tr class=""odd"">
-<td align=""left"">Sepal.Width</td>
-<td align=""right"">0.21</td>
-</tr>
-</tbody>
-</table>
-<p>The <code>robust</code> (default to <code>FALSE</code>) argument enables a <strong>robust standardization of data</strong>, <em>i.e.</em>, based on the <strong>median</strong> and <strong>MAD</strong> instead of the <strong>mean</strong> and <strong>SD</strong>.</p>
-<div class=""sourceCode"" id=""cb19""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb19-1"" title=""1""><span class=""kw""><a href=""../reference/standardize_parameters.html"">standardize_parameters</a></span>(model, <span class=""dt"">method=</span><span class=""st"">""refit""</span>, <span class=""dt"">robust=</span><span class=""ot"">TRUE</span>)</a></code></pre></div>
-<table class=""table"">
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""right"">Std_Coefficient</th>
-</tr></thead>
-<tbody>
-<tr class=""odd"">
-<td align=""left"">(Intercept)</td>
-<td align=""right"">0.11</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Petal.Width</td>
-<td align=""right"">0.97</td>
-</tr>
-<tr class=""odd"">
-<td align=""left"">Sepal.Width</td>
-<td align=""right"">0.17</td>
-</tr>
-</tbody>
-</table>
-<p>This method is very flexible as it can be applied to all types of models (linear, logisticâ¦).</p>
-<div class=""sourceCode"" id=""cb20""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb20-1"" title=""1"">data<span class=""op"">$</span>binary &lt;-<span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/base/ifelse.html"">ifelse</a></span>(data<span class=""op"">$</span>Sepal.Width <span class=""op"">&gt;</span><span class=""st""> </span><span class=""dv"">3</span>, <span class=""dv"">1</span>, <span class=""dv"">0</span>)</a>
-<a class=""sourceLine"" id=""cb20-2"" title=""2"">model &lt;-<span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/stats/glm.html"">glm</a></span>(binary <span class=""op"">~</span><span class=""st""> </span>Species <span class=""op"">+</span><span class=""st""> </span>Sepal.Length, <span class=""dt"">data =</span> data, <span class=""dt"">family=</span><span class=""st"">""binomial""</span>)</a>
-<a class=""sourceLine"" id=""cb20-3"" title=""3""><span class=""kw""><a href=""../reference/standardize_parameters.html"">standardize_parameters</a></span>(model, <span class=""dt"">method=</span><span class=""st"">""refit""</span>)</a></code></pre></div>
-<table class=""table"">
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""right"">Std_Coefficient</th>
-</tr></thead>
-<tbody>
-<tr class=""odd"">
-<td align=""left"">(Intercept)</td>
-<td align=""right"">3.3</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Speciesversicolor</td>
-<td align=""right"">-5.4</td>
-</tr>
-<tr class=""odd"">
-<td align=""left"">Speciesvirginica</td>
-<td align=""right"">-5.5</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Sepal.Length</td>
-<td align=""right"">1.5</td>
-</tr>
-</tbody>
-</table>
-</div>
-<div id=""posthoc-refit-without-refitting"" class=""section level3"">
-<h3 class=""hasAnchor"">
-<a href=""#posthoc-refit-without-refitting"" class=""anchor""></a><strong>âposthocâ</strong>: Refit without refitting</h3>
-<p>Post-hoc standardization of the parameters, aiming at emulating the results obtained by ârefitâ without refitting the model. The coefficients are divided by the standard deviation (or MAD if <code>robust</code>) of the outcome (which becomes their expression âunitâ). Then, the coefficients related to numeric variables are additionally multiplied by the standard deviation (or MAD if <code>robust</code>) of the related terms, so that they correspond to changes of 1 SD of the predictor (e.g., ""A change in 1 SD of <em>x</em> is related to a change of 0.24 of the SD of <em>y</em>). This does not apply to binary variables or factors, so the coefficients are still related to changes in levels. This method is not accurate and tend to give aberrant results when interactions are specified.</p>
-<div class=""sourceCode"" id=""cb21""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb21-1"" title=""1"">model &lt;-<span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/stats/lm.html"">lm</a></span>(Sepal.Length <span class=""op"">~</span><span class=""st""> </span>Petal.Width <span class=""op"">+</span><span class=""st""> </span>Sepal.Width, <span class=""dt"">data=</span>data)</a>
-<a class=""sourceLine"" id=""cb21-2"" title=""2""><span class=""kw""><a href=""../reference/standardize_parameters.html"">standardize_parameters</a></span>(model, <span class=""dt"">method=</span><span class=""st"">""posthoc""</span>)</a></code></pre></div>
-<table class=""table"">
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""right"">Std_Coefficient</th>
-</tr></thead>
-<tbody>
-<tr class=""odd"">
-<td align=""left"">(Intercept)</td>
-<td align=""right"">0.00</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Petal.Width</td>
-<td align=""right"">0.89</td>
-</tr>
-<tr class=""odd"">
-<td align=""left"">Sepal.Width</td>
-<td align=""right"">0.21</td>
-</tr>
-</tbody>
-</table>
-</div>
-<div id=""smart-standardization-of-models-parameters-with-adjustment-reconnaissance-and-transformation"" class=""section level3"">
-<h3 class=""hasAnchor"">
-<a href=""#smart-standardization-of-models-parameters-with-adjustment-reconnaissance-and-transformation"" class=""anchor""></a><strong>âsmartâ</strong>: Standardization of Modelâs parameters with Adjustment, Reconnaissance and Transformation</h3>
-<p>Similar to <code>method = ""posthoc""</code> in that it does not involve model refitting. The difference is that the SD of the response is computed on the relevant section of the data. For instance, if a factor with 3 levels A (the intercept), B and C is entered as a predictor, the effect corresponding to B vs.Â A will be scaled by the variance of the response at the intercept only. As a results, the coefficients for effects of factors are similar to a Glassâ <em>delta</em>.</p>
-<div class=""sourceCode"" id=""cb22""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb22-1"" title=""1"">model &lt;-<span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/stats/lm.html"">lm</a></span>(Sepal.Length <span class=""op"">~</span><span class=""st""> </span>Petal.Width <span class=""op"">+</span><span class=""st""> </span>Sepal.Width, <span class=""dt"">data=</span>data)</a>
-<a class=""sourceLine"" id=""cb22-2"" title=""2""><span class=""kw""><a href=""../reference/standardize_parameters.html"">standardize_parameters</a></span>(model, <span class=""dt"">method=</span><span class=""st"">""smart""</span>)</a></code></pre></div>
-<table class=""table"">
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""right"">Std_Coefficient</th>
-</tr></thead>
-<tbody>
-<tr class=""odd"">
-<td align=""left"">(Intercept)</td>
-<td align=""right"">0.00</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Petal.Width</td>
-<td align=""right"">0.89</td>
-</tr>
-<tr class=""odd"">
-<td align=""left"">Sepal.Width</td>
-<td align=""right"">0.21</td>
-</tr>
-</tbody>
-</table>
-</div>
-<div id=""basic-raw-scaling-of-the-model-frame"" class=""section level3"">
-<h3 class=""hasAnchor"">
-<a href=""#basic-raw-scaling-of-the-model-frame"" class=""anchor""></a><strong>âbasicâ</strong>: Raw scaling of the model frame</h3>
-<p>This method is similar to <code>method = ""posthoc""</code>, but treats all variables as continuous: it also scales the coefficient by the standard deviation of modelâs matrixâ parameter of factors levels (transformed to integers) or binary predictors. Although being inappropriate for these cases, this method is the one implemented by default in other software packages, such as <code><a href=""https://rdrr.io/pkg/lm.beta/man/lm.beta.html"">lm.beta::lm.beta()</a></code>.</p>
-</div>
-<div id=""methods-comparison"" class=""section level2"">
-<h2 class=""hasAnchor"">
-<a href=""#methods-comparison"" class=""anchor""></a>Methods Comparison</h2>
-<p>We will use the ârefitâ method as the baseline. We will then compute the differences between these standardized parameters and the ones provided by the other functions. The <strong>bigger the (absolute) number, the worse it is</strong>.</p>
-<blockquote>
-<p><strong>SPOILER ALERT: the standardization implemented in <code>effectsize</code> is the most accurate and the most flexible.</strong></p>
-</blockquote>
-<div id=""convenience-function"" class=""section level3"">
-<h3 class=""hasAnchor"">
-<a href=""#convenience-function"" class=""anchor""></a>Convenience function</h3>
-<div class=""sourceCode"" id=""cb23""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb23-1"" title=""1""><span class=""kw""><a href=""https://rdrr.io/r/base/library.html"">library</a></span>(effectsize)</a>
-<a class=""sourceLine"" id=""cb23-2"" title=""2""><span class=""kw""><a href=""https://rdrr.io/r/base/library.html"">library</a></span>(lm.beta)</a>
-<a class=""sourceLine"" id=""cb23-3"" title=""3""><span class=""kw""><a href=""https://rdrr.io/r/base/library.html"">library</a></span>(MuMIn)</a>
-<a class=""sourceLine"" id=""cb23-4"" title=""4""></a>
-<a class=""sourceLine"" id=""cb23-5"" title=""5"">comparison &lt;-<span class=""st""> </span><span class=""cf"">function</span>(model, <span class=""dt"">robust=</span><span class=""ot"">FALSE</span>){</a>
-<a class=""sourceLine"" id=""cb23-6"" title=""6"">  out &lt;-<span class=""st""> </span><span class=""kw""><a href=""../reference/standardize_parameters.html"">standardize_parameters</a></span>(model, <span class=""dt"">method=</span><span class=""st"">""refit""</span>, <span class=""dt"">robust=</span>robust)[<span class=""dv"">1</span><span class=""op"">:</span><span class=""dv"">2</span>]</a>
-<a class=""sourceLine"" id=""cb23-7"" title=""7"">  </a>
-<a class=""sourceLine"" id=""cb23-8"" title=""8"">  out<span class=""op"">$</span>posthoc &lt;-<span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/base/conditions.html"">tryCatch</a></span>({</a>
-<a class=""sourceLine"" id=""cb23-9"" title=""9"">    out[, <span class=""dv"">2</span>] <span class=""op"">-</span><span class=""st""> </span><span class=""kw""><a href=""../reference/standardize_parameters.html"">standardize_parameters</a></span>(model, <span class=""dt"">method=</span><span class=""st"">""posthoc""</span>, <span class=""dt"">robust=</span>robust)[, <span class=""dv"">2</span>]</a>
-<a class=""sourceLine"" id=""cb23-10"" title=""10"">}, <span class=""dt"">error =</span> <span class=""cf"">function</span>(error_condition) {</a>
-<a class=""sourceLine"" id=""cb23-11"" title=""11"">    <span class=""st"">""Error""</span></a>
-<a class=""sourceLine"" id=""cb23-12"" title=""12"">})</a>
-<a class=""sourceLine"" id=""cb23-13"" title=""13"">  out<span class=""op"">$</span>basic &lt;-<span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/base/conditions.html"">tryCatch</a></span>({</a>
-<a class=""sourceLine"" id=""cb23-14"" title=""14"">    out[, <span class=""dv"">2</span>] <span class=""op"">-</span><span class=""st""> </span><span class=""kw""><a href=""../reference/standardize_parameters.html"">standardize_parameters</a></span>(model, <span class=""dt"">method=</span><span class=""st"">""basic""</span>, <span class=""dt"">robust=</span>robust)[, <span class=""dv"">2</span>]</a>
-<a class=""sourceLine"" id=""cb23-15"" title=""15"">}, <span class=""dt"">error =</span> <span class=""cf"">function</span>(error_condition) {</a>
-<a class=""sourceLine"" id=""cb23-16"" title=""16"">    <span class=""st"">""Error""</span></a>
-<a class=""sourceLine"" id=""cb23-17"" title=""17"">})</a>
-<a class=""sourceLine"" id=""cb23-18"" title=""18""></a>
-<a class=""sourceLine"" id=""cb23-19"" title=""19"">  out<span class=""op"">$</span>lm.beta &lt;-<span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/base/conditions.html"">tryCatch</a></span>({</a>
-<a class=""sourceLine"" id=""cb23-20"" title=""20"">    out[, <span class=""dv"">2</span>] <span class=""op"">-</span><span class=""st""> </span>lm.beta<span class=""op"">::</span><span class=""kw"">lm.beta</span>(model)<span class=""op"">$</span>standardized.coefficients</a>
-<a class=""sourceLine"" id=""cb23-21"" title=""21"">}, <span class=""dt"">error =</span> <span class=""cf"">function</span>(error_condition) {</a>
-<a class=""sourceLine"" id=""cb23-22"" title=""22"">    <span class=""st"">""Error""</span></a>
-<a class=""sourceLine"" id=""cb23-23"" title=""23"">}, <span class=""dt"">warning =</span> <span class=""cf"">function</span>(warning_condition) {</a>
-<a class=""sourceLine"" id=""cb23-24"" title=""24"">  <span class=""st"">""Error""</span></a>
-<a class=""sourceLine"" id=""cb23-25"" title=""25"">})</a>
-<a class=""sourceLine"" id=""cb23-26"" title=""26"">  </a>
-<a class=""sourceLine"" id=""cb23-27"" title=""27"">  out<span class=""op"">$</span>MuMIn &lt;-<span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/base/conditions.html"">tryCatch</a></span>({</a>
-<a class=""sourceLine"" id=""cb23-28"" title=""28"">    out[, <span class=""dv"">2</span>] <span class=""op"">-</span><span class=""st""> </span>MuMIn<span class=""op"">::</span><span class=""kw""><a href=""https://rdrr.io/pkg/MuMIn/man/std.coef.html"">std.coef</a></span>(model, <span class=""dt"">partial.sd=</span><span class=""ot"">FALSE</span>)[, <span class=""dv"">1</span>]</a>
-<a class=""sourceLine"" id=""cb23-29"" title=""29"">}, <span class=""dt"">error =</span> <span class=""cf"">function</span>(error_condition) {</a>
-<a class=""sourceLine"" id=""cb23-30"" title=""30"">    <span class=""st"">""Error""</span></a>
-<a class=""sourceLine"" id=""cb23-31"" title=""31"">})</a>
-<a class=""sourceLine"" id=""cb23-32"" title=""32""></a>
-<a class=""sourceLine"" id=""cb23-33"" title=""33"">  out[, <span class=""dv"">2</span>] &lt;-<span class=""st""> </span><span class=""ot"">NULL</span></a>
-<a class=""sourceLine"" id=""cb23-34"" title=""34"">  out</a>
-<a class=""sourceLine"" id=""cb23-35"" title=""35"">}</a></code></pre></div>
-</div>
-<div id=""data"" class=""section level3"">
-<h3 class=""hasAnchor"">
-<a href=""#data"" class=""anchor""></a>Data</h3>
-<div class=""sourceCode"" id=""cb24""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb24-1"" title=""1"">data &lt;-<span class=""st""> </span>iris</a>
-<a class=""sourceLine"" id=""cb24-2"" title=""2"">data<span class=""op"">$</span>Group_Sepal.Width &lt;-<span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/base/factor.html"">as.factor</a></span>(<span class=""kw""><a href=""https://rdrr.io/r/base/ifelse.html"">ifelse</a></span>(data<span class=""op"">$</span>Sepal.Width <span class=""op"">&gt;</span><span class=""st""> </span><span class=""dv"">3</span>, <span class=""st"">""High""</span>, <span class=""st"">""Low""</span>))</a>
-<a class=""sourceLine"" id=""cb24-3"" title=""3"">data<span class=""op"">$</span>Binary_Sepal.Width &lt;-<span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/base/factor.html"">as.factor</a></span>(<span class=""kw""><a href=""https://rdrr.io/r/base/ifelse.html"">ifelse</a></span>(data<span class=""op"">$</span>Sepal.Width <span class=""op"">&gt;</span><span class=""st""> </span><span class=""dv"">3</span>, <span class=""dv"">1</span>, <span class=""dv"">0</span>))</a>
-<a class=""sourceLine"" id=""cb24-4"" title=""4""></a>
-<a class=""sourceLine"" id=""cb24-5"" title=""5""><span class=""kw""><a href=""https://rdrr.io/r/base/summary.html"">summary</a></span>(data)</a></code></pre></div>
-<pre><code>&gt;   Sepal.Length  Sepal.Width   Petal.Length  Petal.Width        Species  
-&gt;  Min.   :4.3   Min.   :2.0   Min.   :1.0   Min.   :0.1   setosa    :50  
-&gt;  1st Qu.:5.1   1st Qu.:2.8   1st Qu.:1.6   1st Qu.:0.3   versicolor:50  
-&gt;  Median :5.8   Median :3.0   Median :4.3   Median :1.3   virginica :50  
-&gt;  Mean   :5.8   Mean   :3.1   Mean   :3.8   Mean   :1.2                  
-&gt;  3rd Qu.:6.4   3rd Qu.:3.3   3rd Qu.:5.1   3rd Qu.:1.8                  
-&gt;  Max.   :7.9   Max.   :4.4   Max.   :6.9   Max.   :2.5                  
-&gt;  Group_Sepal.Width Binary_Sepal.Width
-&gt;  High:67           0:83              
-&gt;  Low :83           1:67              
-&gt;                                      
-&gt;                                      
-&gt;                                      
-&gt; </code></pre>
-</div>
-<div id=""models-with-only-numeric-predictors"" class=""section level3"">
-<h3 class=""hasAnchor"">
-<a href=""#models-with-only-numeric-predictors"" class=""anchor""></a>Models with only numeric predictors</h3>
-<div id=""linear-model"" class=""section level4"">
-<h4 class=""hasAnchor"">
-<a href=""#linear-model"" class=""anchor""></a>Linear Model</h4>
-<div class=""sourceCode"" id=""cb26""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb26-1"" title=""1"">model &lt;-<span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/stats/lm.html"">lm</a></span>(Sepal.Length <span class=""op"">~</span><span class=""st""> </span>Petal.Width <span class=""op"">+</span><span class=""st""> </span>Sepal.Width, <span class=""dt"">data=</span>data) </a>
-<a class=""sourceLine"" id=""cb26-2"" title=""2""><span class=""kw"">comparison</span>(model)</a></code></pre></div>
-<table class=""table"">
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""right"">posthoc</th>
-<th align=""right"">basic</th>
-<th align=""right"">lm.beta</th>
-<th align=""right"">MuMIn</th>
-</tr></thead>
-<tbody>
-<tr class=""odd"">
-<td align=""left"">(Intercept)</td>
-<td align=""right"">0</td>
-<td align=""right"">0</td>
-<td align=""right"">0</td>
-<td align=""right"">0</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Petal.Width</td>
-<td align=""right"">0</td>
-<td align=""right"">0</td>
-<td align=""right"">0</td>
-<td align=""right"">0</td>
-</tr>
-<tr class=""odd"">
-<td align=""left"">Sepal.Width</td>
-<td align=""right"">0</td>
-<td align=""right"">0</td>
-<td align=""right"">0</td>
-<td align=""right"">0</td>
-</tr>
-</tbody>
-</table>
-</div>
-<div id=""logistic-model"" class=""section level4"">
-<h4 class=""hasAnchor"">
-<a href=""#logistic-model"" class=""anchor""></a>Logistic Model</h4>
-<div class=""sourceCode"" id=""cb27""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb27-1"" title=""1"">model &lt;-<span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/stats/glm.html"">glm</a></span>(Binary_Sepal.Width <span class=""op"">~</span><span class=""st""> </span>Petal.Width <span class=""op"">+</span><span class=""st""> </span>Sepal.Length, <span class=""dt"">data=</span>data, <span class=""dt"">family=</span><span class=""st"">""binomial""</span>)</a>
-<a class=""sourceLine"" id=""cb27-2"" title=""2""><span class=""kw"">comparison</span>(model)</a></code></pre></div>
-<table class=""table"">
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""right"">posthoc</th>
-<th align=""right"">basic</th>
-<th align=""left"">lm.beta</th>
-<th align=""left"">MuMIn</th>
-</tr></thead>
-<tbody>
-<tr class=""odd"">
-<td align=""left"">(Intercept)</td>
-<td align=""right"">-0.26</td>
-<td align=""right"">-0.26</td>
-<td align=""left"">Error</td>
-<td align=""left"">Error</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Petal.Width</td>
-<td align=""right"">0.00</td>
-<td align=""right"">0.00</td>
-<td align=""left"">Error</td>
-<td align=""left"">Error</td>
-</tr>
-<tr class=""odd"">
-<td align=""left"">Sepal.Length</td>
-<td align=""right"">0.00</td>
-<td align=""right"">0.00</td>
-<td align=""left"">Error</td>
-<td align=""left"">Error</td>
-</tr>
-</tbody>
-</table>
-</div>
-<div id=""linear-mixed-model"" class=""section level4"">
-<h4 class=""hasAnchor"">
-<a href=""#linear-mixed-model"" class=""anchor""></a>Linear Mixed Model</h4>
-<div class=""sourceCode"" id=""cb28""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb28-1"" title=""1""><span class=""kw""><a href=""https://rdrr.io/r/base/library.html"">library</a></span>(lme4)</a>
-<a class=""sourceLine"" id=""cb28-2"" title=""2""></a>
-<a class=""sourceLine"" id=""cb28-3"" title=""3"">model &lt;-<span class=""st""> </span>lme4<span class=""op"">::</span><span class=""kw""><a href=""https://rdrr.io/pkg/lme4/man/lmer.html"">lmer</a></span>(Sepal.Length <span class=""op"">~</span><span class=""st""> </span>Petal.Width <span class=""op"">+</span><span class=""st""> </span>Sepal.Width <span class=""op"">+</span><span class=""st""> </span>(<span class=""dv"">1</span><span class=""op"">|</span>Species), <span class=""dt"">data=</span>data)</a>
-<a class=""sourceLine"" id=""cb28-4"" title=""4""><span class=""kw"">comparison</span>(model)</a></code></pre></div>
-<table class=""table"">
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""right"">posthoc</th>
-<th align=""right"">basic</th>
-<th align=""left"">lm.beta</th>
-<th align=""right"">MuMIn</th>
-</tr></thead>
-<tbody>
-<tr class=""odd"">
-<td align=""left"">(Intercept)</td>
-<td align=""right"">0</td>
-<td align=""right"">0</td>
-<td align=""left"">Error</td>
-<td align=""right"">0</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Petal.Width</td>
-<td align=""right"">0</td>
-<td align=""right"">0</td>
-<td align=""left"">Error</td>
-<td align=""right"">0</td>
-</tr>
-<tr class=""odd"">
-<td align=""left"">Sepal.Width</td>
-<td align=""right"">0</td>
-<td align=""right"">0</td>
-<td align=""left"">Error</td>
-<td align=""right"">0</td>
-</tr>
-</tbody>
-</table>
-</div>
-<div id=""bayesian-models"" class=""section level4"">
-<h4 class=""hasAnchor"">
-<a href=""#bayesian-models"" class=""anchor""></a>Bayesian Models</h4>
-<div class=""sourceCode"" id=""cb29""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb29-1"" title=""1""><span class=""kw""><a href=""https://rdrr.io/r/base/library.html"">library</a></span>(rstanarm)</a>
-<a class=""sourceLine"" id=""cb29-2"" title=""2""></a>
-<a class=""sourceLine"" id=""cb29-3"" title=""3"">model &lt;-<span class=""st""> </span><span class=""kw"">stan_glm</span>(Sepal.Length <span class=""op"">~</span><span class=""st""> </span>Petal.Width <span class=""op"">+</span><span class=""st""> </span>Sepal.Width, <span class=""dt"">data=</span>data)</a>
-<a class=""sourceLine"" id=""cb29-4"" title=""4""><span class=""kw"">comparison</span>(model)</a></code></pre></div>
-<table class=""table"">
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""right"">posthoc</th>
-<th align=""right"">basic</th>
-<th align=""right"">lm.beta</th>
-<th align=""right"">MuMIn</th>
-</tr></thead>
-<tbody>
-<tr class=""odd"">
-<td align=""left"">(Intercept)</td>
-<td align=""right"">0</td>
-<td align=""right"">0</td>
-<td align=""right"">0</td>
-<td align=""right"">0</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Petal.Width</td>
-<td align=""right"">0</td>
-<td align=""right"">0</td>
-<td align=""right"">0</td>
-<td align=""right"">0</td>
-</tr>
-<tr class=""odd"">
-<td align=""left"">Sepal.Width</td>
-<td align=""right"">0</td>
-<td align=""right"">0</td>
-<td align=""right"">0</td>
-<td align=""right"">0</td>
-</tr>
-</tbody>
-</table>
-<p>For these simple models, <strong>all methods return results equal to the ârefitâ method</strong> (although the other packages fail).</p>
-</div>
-<div id=""transformation"" class=""section level4"">
-<h4 class=""hasAnchor"">
-<a href=""#transformation"" class=""anchor""></a>Transformation</h4>
-<div class=""sourceCode"" id=""cb30""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb30-1"" title=""1"">model &lt;-<span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/stats/lm.html"">lm</a></span>(Sepal.Length <span class=""op"">~</span><span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/stats/poly.html"">poly</a></span>(Petal.Width, <span class=""dv"">2</span>) <span class=""op"">+</span><span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/stats/poly.html"">poly</a></span>(Sepal.Width, <span class=""dv"">2</span>), <span class=""dt"">data=</span>data)</a>
-<a class=""sourceLine"" id=""cb30-2"" title=""2""><span class=""kw"">comparison</span>(model)</a></code></pre></div>
-<table class=""table"">
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""right"">posthoc</th>
-<th align=""right"">basic</th>
-<th align=""right"">lm.beta</th>
-<th align=""right"">MuMIn</th>
-</tr></thead>
-<tbody>
-<tr class=""odd"">
-<td align=""left"">(Intercept)</td>
-<td align=""right"">0</td>
-<td align=""right"">0.00</td>
-<td align=""right"">0.00</td>
-<td align=""right"">0.00</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">poly(Petal.Width, 2)1</td>
-<td align=""right"">0</td>
-<td align=""right"">10.48</td>
-<td align=""right"">10.48</td>
-<td align=""right"">10.48</td>
-</tr>
-<tr class=""odd"">
-<td align=""left"">poly(Petal.Width, 2)2</td>
-<td align=""right"">0</td>
-<td align=""right"">-1.86</td>
-<td align=""right"">-1.86</td>
-<td align=""right"">-1.86</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">poly(Sepal.Width, 2)1</td>
-<td align=""right"">0</td>
-<td align=""right"">3.44</td>
-<td align=""right"">3.44</td>
-<td align=""right"">3.44</td>
-</tr>
-<tr class=""odd"">
-<td align=""left"">poly(Sepal.Width, 2)2</td>
-<td align=""right"">0</td>
-<td align=""right"">0.28</td>
-<td align=""right"">0.28</td>
-<td align=""right"">0.28</td>
-</tr>
-</tbody>
-</table>
-<p>When transformation are involved (e.g., polynomial transformations), <strong>the basic method becomes very unreliable</strong>.</p>
-</div>
-</div>
-<div id=""models-with-factors"" class=""section level3"">
-<h3 class=""hasAnchor"">
-<a href=""#models-with-factors"" class=""anchor""></a>Models with factors</h3>
-<div id=""linear-model-1"" class=""section level4"">
-<h4 class=""hasAnchor"">
-<a href=""#linear-model-1"" class=""anchor""></a>Linear Model</h4>
-<div class=""sourceCode"" id=""cb31""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb31-1"" title=""1"">model &lt;-<span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/stats/lm.html"">lm</a></span>(Sepal.Length <span class=""op"">~</span><span class=""st""> </span>Petal.Width <span class=""op"">+</span><span class=""st""> </span>Group_Sepal.Width, <span class=""dt"">data=</span>data) </a>
-<a class=""sourceLine"" id=""cb31-2"" title=""2""><span class=""kw"">comparison</span>(model)</a></code></pre></div>
-<table class=""table"">
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""right"">posthoc</th>
-<th align=""right"">basic</th>
-<th align=""right"">lm.beta</th>
-<th align=""right"">MuMIn</th>
-</tr></thead>
-<tbody>
-<tr class=""odd"">
-<td align=""left"">(Intercept)</td>
-<td align=""right"">0.14</td>
-<td align=""right"">0.14</td>
-<td align=""right"">0.14</td>
-<td align=""right"">0.14</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Petal.Width</td>
-<td align=""right"">0.00</td>
-<td align=""right"">0.00</td>
-<td align=""right"">0.00</td>
-<td align=""right"">0.00</td>
-</tr>
-<tr class=""odd"">
-<td align=""left"">Group_Sepal.WidthLow</td>
-<td align=""right"">0.00</td>
-<td align=""right"">-0.12</td>
-<td align=""right"">-0.12</td>
-<td align=""right"">-0.12</td>
-</tr>
-</tbody>
-</table>
-</div>
-<div id=""logistic-model-1"" class=""section level4"">
-<h4 class=""hasAnchor"">
-<a href=""#logistic-model-1"" class=""anchor""></a>Logistic Model</h4>
-<div class=""sourceCode"" id=""cb32""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb32-1"" title=""1"">model &lt;-<span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/stats/glm.html"">glm</a></span>(Binary_Sepal.Width <span class=""op"">~</span><span class=""st""> </span>Petal.Width <span class=""op"">+</span><span class=""st""> </span>Species, <span class=""dt"">data=</span>data, <span class=""dt"">family=</span><span class=""st"">""binomial""</span>)</a>
-<a class=""sourceLine"" id=""cb32-2"" title=""2""><span class=""kw"">comparison</span>(model)</a></code></pre></div>
-<table class=""table"">
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""right"">posthoc</th>
-<th align=""right"">basic</th>
-<th align=""left"">lm.beta</th>
-<th align=""left"">MuMIn</th>
-</tr></thead>
-<tbody>
-<tr class=""odd"">
-<td align=""left"">(Intercept)</td>
-<td align=""right"">8</td>
-<td align=""right"">8.0</td>
-<td align=""left"">Error</td>
-<td align=""left"">Error</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Petal.Width</td>
-<td align=""right"">0</td>
-<td align=""right"">0.0</td>
-<td align=""left"">Error</td>
-<td align=""left"">Error</td>
-</tr>
-<tr class=""odd"">
-<td align=""left"">Speciesversicolor</td>
-<td align=""right"">0</td>
-<td align=""right"">-5.8</td>
-<td align=""left"">Error</td>
-<td align=""left"">Error</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Speciesvirginica</td>
-<td align=""right"">0</td>
-<td align=""right"">-7.6</td>
-<td align=""left"">Error</td>
-<td align=""left"">Error</td>
-</tr>
-</tbody>
-</table>
-</div>
-<div id=""linear-mixed-model-1"" class=""section level4"">
-<h4 class=""hasAnchor"">
-<a href=""#linear-mixed-model-1"" class=""anchor""></a>Linear Mixed Model</h4>
-<div class=""sourceCode"" id=""cb33""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb33-1"" title=""1""><span class=""kw""><a href=""https://rdrr.io/r/base/library.html"">library</a></span>(lme4)</a>
-<a class=""sourceLine"" id=""cb33-2"" title=""2""></a>
-<a class=""sourceLine"" id=""cb33-3"" title=""3"">model &lt;-<span class=""st""> </span>lme4<span class=""op"">::</span><span class=""kw""><a href=""https://rdrr.io/pkg/lme4/man/lmer.html"">lmer</a></span>(Sepal.Length <span class=""op"">~</span><span class=""st""> </span>Petal.Length <span class=""op"">+</span><span class=""st""> </span>Group_Sepal.Width <span class=""op"">+</span><span class=""st""> </span>(<span class=""dv"">1</span><span class=""op"">|</span>Species), <span class=""dt"">data=</span>data)</a>
-<a class=""sourceLine"" id=""cb33-4"" title=""4""><span class=""kw"">comparison</span>(model)</a></code></pre></div>
-<table class=""table"">
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""right"">posthoc</th>
-<th align=""right"">basic</th>
-<th align=""left"">lm.beta</th>
-<th align=""right"">MuMIn</th>
-</tr></thead>
-<tbody>
-<tr class=""odd"">
-<td align=""left"">(Intercept)</td>
-<td align=""right"">0.15</td>
-<td align=""right"">0.15</td>
-<td align=""left"">Error</td>
-<td align=""right"">0.15</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Petal.Length</td>
-<td align=""right"">0.00</td>
-<td align=""right"">0.00</td>
-<td align=""left"">Error</td>
-<td align=""right"">0.00</td>
-</tr>
-<tr class=""odd"">
-<td align=""left"">Group_Sepal.WidthLow</td>
-<td align=""right"">0.00</td>
-<td align=""right"">-0.14</td>
-<td align=""left"">Error</td>
-<td align=""right"">-0.14</td>
-</tr>
-</tbody>
-</table>
-</div>
-<div id=""bayesian-models-1"" class=""section level4"">
-<h4 class=""hasAnchor"">
-<a href=""#bayesian-models-1"" class=""anchor""></a>Bayesian Models</h4>
-<div class=""sourceCode"" id=""cb34""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb34-1"" title=""1""><span class=""kw""><a href=""https://rdrr.io/r/base/library.html"">library</a></span>(rstanarm)</a>
-<a class=""sourceLine"" id=""cb34-2"" title=""2""></a>
-<a class=""sourceLine"" id=""cb34-3"" title=""3"">model &lt;-<span class=""st""> </span><span class=""kw"">stan_lmer</span>(Sepal.Length <span class=""op"">~</span><span class=""st""> </span>Petal.Width <span class=""op"">+</span><span class=""st""> </span>Group_Sepal.Width <span class=""op"">+</span><span class=""st""> </span>(<span class=""dv"">1</span><span class=""op"">|</span>Species), <span class=""dt"">data=</span>data)</a>
-<a class=""sourceLine"" id=""cb34-4"" title=""4""><span class=""kw"">comparison</span>(model)</a></code></pre></div>
-<table class=""table"">
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""right"">posthoc</th>
-<th align=""right"">basic</th>
-<th align=""left"">lm.beta</th>
-<th align=""left"">MuMIn</th>
-</tr></thead>
-<tbody>
-<tr class=""odd"">
-<td align=""left"">(Intercept)</td>
-<td align=""right"">0.15</td>
-<td align=""right"">0.15</td>
-<td align=""left"">Error</td>
-<td align=""left"">Error</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Petal.Width</td>
-<td align=""right"">-0.01</td>
-<td align=""right"">-0.01</td>
-<td align=""left"">Error</td>
-<td align=""left"">Error</td>
-</tr>
-<tr class=""odd"">
-<td align=""left"">Group_Sepal.WidthLow</td>
-<td align=""right"">-0.01</td>
-<td align=""right"">-0.15</td>
-<td align=""left"">Error</td>
-<td align=""left"">Error</td>
-</tr>
-</tbody>
-</table>
-<p>When factors are involved, the basic method (that standardizes the numeric transformation of factors) give again different results.</p>
-</div>
-</div>
-<div id=""models-with-interactions"" class=""section level3"">
-<h3 class=""hasAnchor"">
-<a href=""#models-with-interactions"" class=""anchor""></a>Models with interactions</h3>
-<p>Long story short, coeffcient obtained via <strong>posthoc</strong> standardization (without refitting the model) go berserk when interactions are involved. However, <strong>this is ânormalâ</strong>: a regression model estimates coefficient between two variables when the other predictors are at 0 (are <em>fixed</em> at 0, that people interpret as <em>âadjusted forâ</em>). When a standardized data is passed (in the <em>refit</em> method), the effects and interactions are estimated at the <strong>means</strong> of the other predictors (because 0 is the mean for a standardized variable). Whereas in posthoc standardization, this coefficient correspond to something different (because the 0 corresponds to something different in standardzed and non-standardized data). In other words, when it comes to interaction, passing standardized data results in a different model, which coefficient have an intrinsically different meaning from unstandardized data. And as <a href=""https://github.com/easystats/effectsize/issues/6"">for now</a>, we are unable to retrieve one from another.</p>
-<div id=""between-continuous"" class=""section level4"">
-<h4 class=""hasAnchor"">
-<a href=""#between-continuous"" class=""anchor""></a>Between continuous</h4>
-<div class=""sourceCode"" id=""cb35""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb35-1"" title=""1"">model &lt;-<span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/stats/lm.html"">lm</a></span>(Sepal.Length <span class=""op"">~</span><span class=""st""> </span>Petal.Width <span class=""op"">*</span><span class=""st""> </span>Sepal.Width, <span class=""dt"">data=</span>data)</a>
-<a class=""sourceLine"" id=""cb35-2"" title=""2""><span class=""kw"">comparison</span>(model)</a></code></pre></div>
-<table class=""table"">
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""right"">posthoc</th>
-<th align=""right"">basic</th>
-<th align=""right"">lm.beta</th>
-<th align=""right"">MuMIn</th>
-</tr></thead>
-<tbody>
-<tr class=""odd"">
-<td align=""left"">(Intercept)</td>
-<td align=""right"">-0.01</td>
-<td align=""right"">-0.01</td>
-<td align=""right"">-0.01</td>
-<td align=""right"">-0.01</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Petal.Width</td>
-<td align=""right"">-0.28</td>
-<td align=""right"">-0.28</td>
-<td align=""right"">-0.28</td>
-<td align=""right"">-0.28</td>
-</tr>
-<tr class=""odd"">
-<td align=""left"">Sepal.Width</td>
-<td align=""right"">-0.06</td>
-<td align=""right"">-0.06</td>
-<td align=""right"">-0.06</td>
-<td align=""right"">-0.06</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Petal.Width:Sepal.Width</td>
-<td align=""right"">0.01</td>
-<td align=""right"">0.24</td>
-<td align=""right"">0.24</td>
-<td align=""right"">0.24</td>
-</tr>
-</tbody>
-</table>
-</div>
-<div id=""between-factors"" class=""section level4"">
-<h4 class=""hasAnchor"">
-<a href=""#between-factors"" class=""anchor""></a>Between factors</h4>
-<div class=""sourceCode"" id=""cb36""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb36-1"" title=""1"">model &lt;-<span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/stats/lm.html"">lm</a></span>(Sepal.Length <span class=""op"">~</span><span class=""st""> </span>Species <span class=""op"">*</span><span class=""st""> </span>Group_Sepal.Width, <span class=""dt"">data=</span>data)</a>
-<a class=""sourceLine"" id=""cb36-2"" title=""2""><span class=""kw"">comparison</span>(model)</a></code></pre></div>
-<table class=""table"">
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""right"">posthoc</th>
-<th align=""right"">basic</th>
-<th align=""right"">lm.beta</th>
-<th align=""right"">MuMIn</th>
-</tr></thead>
-<tbody>
-<tr class=""odd"">
-<td align=""left"">(Intercept)</td>
-<td align=""right"">-0.93</td>
-<td align=""right"">-0.93</td>
-<td align=""right"">-0.93</td>
-<td align=""right"">-0.93</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Speciesversicolor</td>
-<td align=""right"">0.00</td>
-<td align=""right"">0.90</td>
-<td align=""right"">0.90</td>
-<td align=""right"">0.90</td>
-</tr>
-<tr class=""odd"">
-<td align=""left"">Speciesvirginica</td>
-<td align=""right"">0.00</td>
-<td align=""right"">1.10</td>
-<td align=""right"">1.10</td>
-<td align=""right"">1.10</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Group_Sepal.WidthLow</td>
-<td align=""right"">0.00</td>
-<td align=""right"">-0.27</td>
-<td align=""right"">-0.27</td>
-<td align=""right"">-0.27</td>
-</tr>
-<tr class=""odd"">
-<td align=""left"">Speciesversicolor:Group_Sepal.WidthLow</td>
-<td align=""right"">0.00</td>
-<td align=""right"">-0.14</td>
-<td align=""right"">-0.14</td>
-<td align=""right"">-0.14</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Speciesvirginica:Group_Sepal.WidthLow</td>
-<td align=""right"">0.00</td>
-<td align=""right"">0.08</td>
-<td align=""right"">0.08</td>
-<td align=""right"">0.08</td>
-</tr>
-</tbody>
-</table>
-</div>
-<div id=""between-factors-and-continuous"" class=""section level4"">
-<h4 class=""hasAnchor"">
-<a href=""#between-factors-and-continuous"" class=""anchor""></a>Between factors and continuous</h4>
-<div class=""sourceCode"" id=""cb37""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb37-1"" title=""1"">model &lt;-<span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/stats/lm.html"">lm</a></span>(Sepal.Length <span class=""op"">~</span><span class=""st""> </span>Petal.Width <span class=""op"">*</span><span class=""st""> </span>Group_Sepal.Width, <span class=""dt"">data=</span>data)</a>
-<a class=""sourceLine"" id=""cb37-2"" title=""2""><span class=""kw"">comparison</span>(model)</a></code></pre></div>
-<table class=""table"">
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""right"">posthoc</th>
-<th align=""right"">basic</th>
-<th align=""right"">lm.beta</th>
-<th align=""right"">MuMIn</th>
-</tr></thead>
-<tbody>
-<tr class=""odd"">
-<td align=""left"">(Intercept)</td>
-<td align=""right"">0.12</td>
-<td align=""right"">0.12</td>
-<td align=""right"">0.12</td>
-<td align=""right"">0.12</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Petal.Width</td>
-<td align=""right"">0.00</td>
-<td align=""right"">0.00</td>
-<td align=""right"">0.00</td>
-<td align=""right"">0.00</td>
-</tr>
-<tr class=""odd"">
-<td align=""left"">Group_Sepal.WidthLow</td>
-<td align=""right"">0.27</td>
-<td align=""right"">0.01</td>
-<td align=""right"">0.01</td>
-<td align=""right"">0.01</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Petal.Width:Group_Sepal.WidthLow</td>
-<td align=""right"">-0.05</td>
-<td align=""right"">-0.01</td>
-<td align=""right"">-0.01</td>
-<td align=""right"">-0.01</td>
-</tr>
-</tbody>
-</table>
-<div class=""sourceCode"" id=""cb38""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb38-1"" title=""1"">model &lt;-<span class=""st""> </span><span class=""kw""><a href=""https://rdrr.io/r/stats/lm.html"">lm</a></span>(Sepal.Length <span class=""op"">~</span><span class=""st""> </span>Group_Sepal.Width <span class=""op"">*</span><span class=""st""> </span>Petal.Width, <span class=""dt"">data=</span>data)</a>
-<a class=""sourceLine"" id=""cb38-2"" title=""2""><span class=""kw"">comparison</span>(model)</a></code></pre></div>
-<table class=""table"">
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""right"">posthoc</th>
-<th align=""right"">basic</th>
-<th align=""right"">lm.beta</th>
-<th align=""right"">MuMIn</th>
-</tr></thead>
-<tbody>
-<tr class=""odd"">
-<td align=""left"">(Intercept)</td>
-<td align=""right"">0.12</td>
-<td align=""right"">0.12</td>
-<td align=""right"">0.12</td>
-<td align=""right"">0.12</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Group_Sepal.WidthLow</td>
-<td align=""right"">0.27</td>
-<td align=""right"">0.01</td>
-<td align=""right"">0.01</td>
-<td align=""right"">0.01</td>
-</tr>
-<tr class=""odd"">
-<td align=""left"">Petal.Width</td>
-<td align=""right"">0.00</td>
-<td align=""right"">0.00</td>
-<td align=""right"">0.00</td>
-<td align=""right"">0.00</td>
-</tr>
-<tr class=""even"">
-<td align=""left"">Group_Sepal.WidthLow:Petal.Width</td>
-<td align=""right"">0.00</td>
-<td align=""right"">-0.01</td>
-<td align=""right"">-0.01</td>
-<td align=""right"">-0.01</td>
-</tr>
-</tbody>
-</table>
-</div>
-</div>
-</div>
-<div id=""conclusion"" class=""section level2"">
-<h2 class=""hasAnchor"">
-<a href=""#conclusion"" class=""anchor""></a>Conclusion</h2>
-<p>Use <code>refit</code> if possible, but if no interactions, can use <code>posthoc</code> or <code>smart</code>.</p>
-</div>
-</div>
-<div id=""references"" class=""section level1 unnumbered"">
-<h1 class=""hasAnchor"">
-<a href=""#references"" class=""anchor""></a>References</h1>
+<!-- However, it is interesting to note that using the *smart* method when standardizing parameters will give you indices equivalent to **Glass' delta**, which difference is expressed in terms of SD of the intercept (the ""reference"" factor levels). -->
+<!-- ```{r, warning=FALSE, message=FALSE, eval=FALSE} -->
+<!-- lm(Sepal.Length ~ Species, data = data) %>%  -->
+<!--   standardize_parameters(method = ""smart"") -->
+<!-- ``` -->
+<!-- ```{r, warning=FALSE, message=FALSE, echo = FALSE} -->
+<!-- lm(Sepal.Length ~ Species, data = data) %>%  -->
+<!--   standardize_parameters(method = ""smart"") %>%  -->
+<!--   knitr::kable(digits = 2) -->
+<!-- ``` -->
+<!-- ```{r, warning=FALSE, message=FALSE} -->
+<!-- glass_delta(Sepal.Length ~ Species, data = data) -->
+<!-- ``` -->
+<!-- ## What about standardized interaction effects? -->
+<!-- Well, this one's a mess (at least for me). Help is required to make sense out of it. Otherwise, *NEXT*. -->
+<!-- # Standardization methods -->
+<!-- ### **""refit""**: Re-fitting the model with standardized data -->
+<!-- **This method is based on a complete model re-fit with a standardized version of data**. Hence, this method is equal to standardizing the variables before fitting the model. It is the ""purest"" and the most accurate (Neter et al., 1989), but it is also the most computationally costly and long (especially for heavy models such as, for instance, for Bayesian models). This method is particularly recommended for complex models that include interactions or transformations (e.g., polynomial or spline terms). -->
+<!-- ```{r message=FALSE, warning=FALSE, results='hide'} -->
+<!-- library(effectsize) -->
+<!-- data <- iris -->
+<!-- model <- lm(Sepal.Length ~ Petal.Width + Sepal.Width, data=data) -->
+<!-- standardize_parameters(model, method=""refit"") -->
+<!-- ``` -->
+<!-- ```{r message=FALSE, warning=FALSE, echo=FALSE} -->
+<!-- knitr::kable(standardize_parameters(model, method=""refit""), digits=2) -->
+<!-- ``` -->
+<!-- The `robust` (default to `FALSE`) argument enables a **robust standardization of data**, *i.e.*, based on the **median** and **MAD** instead of the **mean** and **SD**. -->
+<!-- ```{r warning=FALSE, message=FALSE, results='hide'} -->
+<!-- standardize_parameters(model, method=""refit"", robust=TRUE) -->
+<!-- ``` -->
+<!-- ```{r message=FALSE, warning=FALSE, echo=FALSE} -->
+<!-- knitr::kable(standardize_parameters(model, method=""refit"", robust=TRUE), digits=2) -->
+<!-- ``` -->
+<!-- This method is very flexible as it can be applied to all types of models (linear, logistic...). -->
+<!-- ```{r warning=FALSE, message=FALSE, results='hide'} -->
+<!-- data$binary <- ifelse(data$Sepal.Width > 3, 1, 0) -->
+<!-- model <- glm(binary ~ Species + Sepal.Length, data = data, family=""binomial"") -->
+<!-- standardize_parameters(model, method=""refit"") -->
+<!-- ``` -->
+<!-- ```{r message=FALSE, warning=FALSE, echo=FALSE} -->
+<!-- knitr::kable(standardize_parameters(model, method=""refit""), digits=2) -->
+<!-- ``` -->
+<!-- ### **""posthoc""**: Refit without refitting -->
+<!-- Post-hoc standardization of the parameters, aiming at emulating the results obtained by ""refit"" without refitting the model. The coefficients are divided by the standard deviation (or MAD if `robust`) of the outcome (which becomes their expression 'unit'). Then, the coefficients related to numeric variables are additionally multiplied by the standard deviation (or MAD if `robust`) of the related terms, so that they correspond to changes of 1 SD of the predictor (e.g., ""A change in 1 SD of *x* is related to a change of 0.24 of the SD of *y*). This does not apply to binary variables or factors, so the coefficients are still related to changes in levels. This method is not accurate and tend to give aberrant results when interactions are specified. -->
+<!-- ```{r warning=FALSE, message=FALSE, results='hide'} -->
+<!-- model <- lm(Sepal.Length ~ Petal.Width + Sepal.Width, data=data) -->
+<!-- standardize_parameters(model, method=""posthoc"") -->
+<!-- ``` -->
+<!-- ```{r message=FALSE, warning=FALSE, echo=FALSE} -->
+<!-- knitr::kable(standardize_parameters(model, method=""posthoc""), digits=2) -->
+<!-- ``` -->
+<!-- ### **""smart""**: Standardization of Model's parameters with Adjustment, Reconnaissance and Transformation -->
+<!-- Similar to `method = ""posthoc""` in that it does not involve model refitting. The difference is that the SD of the response is computed on the relevant section of the data. For instance, if a factor with 3 levels A (the intercept), B and C is entered as a predictor, the effect corresponding to B vs. A will be scaled by the variance of the response at the intercept only. As a results, the coefficients for effects of factors are similar to a Glass' *delta*. -->
+<!-- ```{r warning=FALSE, message=FALSE, results='hide'} -->
+<!-- model <- lm(Sepal.Length ~ Petal.Width + Sepal.Width, data=data) -->
+<!-- standardize_parameters(model, method=""smart"") -->
+<!-- ``` -->
+<!-- ```{r message=FALSE, warning=FALSE, echo=FALSE} -->
+<!-- knitr::kable(standardize_parameters(model, method=""smart""), digits=2) -->
+<!-- ``` -->
+<!-- ### **""basic""**: Raw scaling of the model frame -->
+<!-- This method is similar to `method = ""posthoc""`, but treats all variables as continuous: it also scales the coefficient by the standard deviation of model's matrix' parameter of factors levels (transformed to integers) or binary predictors. Although being inappropriate for these cases, this method is the one implemented by default in other software packages, such as `lm.beta::lm.beta()`. -->
+<!-- ## Methods Comparison -->
+<!-- We will use the ""refit"" method as the baseline. We will then compute the differences between these standardized parameters and the ones provided by the other functions. The **bigger the (absolute) number, the worse it is**.  -->
+<!-- > **SPOILER ALERT: the standardization implemented in `effectsize` is the most accurate and the most flexible.** -->
+<!-- ### Convenience function -->
+<!-- ```{r message=FALSE, warning=FALSE} -->
+<!-- library(effectsize) -->
+<!-- library(lm.beta) -->
+<!-- library(MuMIn) -->
+<!-- comparison <- function(model, robust=FALSE){ -->
+<!--   out <- standardize_parameters(model, method=""refit"", robust=robust)[1:2] -->
+<!--   out$posthoc <- tryCatch({ -->
+<!--     out[, 2] - standardize_parameters(model, method=""posthoc"", robust=robust)[, 2] -->
+<!-- }, error = function(error_condition) { -->
+<!--     ""Error"" -->
+<!-- }) -->
+<!--   out$basic <- tryCatch({ -->
+<!--     out[, 2] - standardize_parameters(model, method=""basic"", robust=robust)[, 2] -->
+<!-- }, error = function(error_condition) { -->
+<!--     ""Error"" -->
+<!-- }) -->
+<!--   out$lm.beta <- tryCatch({ -->
+<!--     out[, 2] - lm.beta::lm.beta(model)$standardized.coefficients -->
+<!-- }, error = function(error_condition) { -->
+<!--     ""Error"" -->
+<!-- }, warning = function(warning_condition) { -->
+<!--   ""Error"" -->
+<!-- }) -->
+<!--   out$MuMIn <- tryCatch({ -->
+<!--     out[, 2] - MuMIn::std.coef(model, partial.sd=FALSE)[, 1] -->
+<!-- }, error = function(error_condition) { -->
+<!--     ""Error"" -->
+<!-- }) -->
+<!--   out[, 2] <- NULL -->
+<!--   out -->
+<!-- } -->
+<!-- ``` -->
+<!-- ### Data -->
+<!-- ```{r message=FALSE, warning=FALSE} -->
+<!-- data <- iris -->
+<!-- data$Group_Sepal.Width <- as.factor(ifelse(data$Sepal.Width > 3, ""High"", ""Low"")) -->
+<!-- data$Binary_Sepal.Width <- as.factor(ifelse(data$Sepal.Width > 3, 1, 0)) -->
+<!-- summary(data) -->
+<!-- ``` -->
+<!-- ### Models with only numeric predictors -->
+<!-- #### Linear Model -->
+<!-- ```{r message=FALSE, warning=FALSE, results='hide'} -->
+<!-- model <- lm(Sepal.Length ~ Petal.Width + Sepal.Width, data=data)  -->
+<!-- comparison(model) -->
+<!-- ``` -->
+<!-- ```{r message=FALSE, warning=FALSE, echo=FALSE} -->
+<!-- knitr::kable(comparison(model), digits=2, row.names = FALSE) -->
+<!-- ``` -->
+<!-- #### Logistic Model -->
+<!-- ```{r message=FALSE, warning=FALSE, results='hide'} -->
+<!-- model <- glm(Binary_Sepal.Width ~ Petal.Width + Sepal.Length, data=data, family=""binomial"") -->
+<!-- comparison(model) -->
+<!-- ``` -->
+<!-- ```{r message=FALSE, warning=FALSE, echo=FALSE} -->
+<!-- knitr::kable(comparison(model), digits=2, row.names = FALSE) -->
+<!-- ``` -->
+<!-- #### Linear Mixed Model -->
+<!-- ```{r message=FALSE, warning=FALSE, results='hide'} -->
+<!-- library(lme4) -->
+<!-- model <- lme4::lmer(Sepal.Length ~ Petal.Width + Sepal.Width + (1|Species), data=data) -->
+<!-- comparison(model) -->
+<!-- ``` -->
+<!-- ```{r message=FALSE, warning=FALSE, echo=FALSE} -->
+<!-- knitr::kable(comparison(model), digits=2, row.names = FALSE) -->
+<!-- ``` -->
+<!-- #### Bayesian Models -->
+<!-- ```{r message=FALSE, warning=FALSE, eval=FALSE} -->
+<!-- library(rstanarm) -->
+<!-- model <- stan_glm(Sepal.Length ~ Petal.Width + Sepal.Width, data=data) -->
+<!-- comparison(model) -->
+<!-- ``` -->
+<!-- ```{r message=FALSE, warning=FALSE, echo=FALSE} -->
+<!-- library(rstanarm) -->
+<!-- model <- stan_glm(Sepal.Length ~ Petal.Width + Sepal.Width, data=data, refresh = 0) -->
+<!-- knitr::kable(comparison(model), digits=2, row.names = FALSE) -->
+<!-- ``` -->
+<!-- For these simple models, **all methods return results equal to the ""refit"" method** (although the other packages fail). -->
+<!-- #### Transformation -->
+<!-- ```{r message=FALSE, warning=FALSE, results='hide'} -->
+<!-- model <- lm(Sepal.Length ~ poly(Petal.Width, 2) + poly(Sepal.Width, 2), data=data) -->
+<!-- comparison(model) -->
+<!-- ``` -->
+<!-- ```{r message=FALSE, warning=FALSE, echo=FALSE} -->
+<!-- knitr::kable(comparison(model), digits=2, row.names = FALSE) -->
+<!-- ``` -->
+<!-- When transformation are involved (e.g., polynomial transformations), **the basic method becomes very unreliable**. -->
+<!-- ### Models with factors -->
+<!-- #### Linear Model -->
+<!-- ```{r message=FALSE, warning=FALSE, results='hide'} -->
+<!-- model <- lm(Sepal.Length ~ Petal.Width + Group_Sepal.Width, data=data)  -->
+<!-- comparison(model) -->
+<!-- ``` -->
+<!-- ```{r message=FALSE, warning=FALSE, echo=FALSE} -->
+<!-- knitr::kable(comparison(model), digits=2, row.names = FALSE) -->
+<!-- ``` -->
+<!-- #### Logistic Model -->
+<!-- ```{r message=FALSE, warning=FALSE, results='hide'} -->
+<!-- model <- glm(Binary_Sepal.Width ~ Petal.Width + Species, data=data, family=""binomial"") -->
+<!-- comparison(model) -->
+<!-- ``` -->
+<!-- ```{r message=FALSE, warning=FALSE, echo=FALSE} -->
+<!-- knitr::kable(comparison(model), digits=2, row.names = FALSE) -->
+<!-- ``` -->
+<!-- #### Linear Mixed Model -->
+<!-- ```{r message=FALSE, warning=FALSE, results='hide'} -->
+<!-- library(lme4) -->
+<!-- model <- lme4::lmer(Sepal.Length ~ Petal.Length + Group_Sepal.Width + (1|Species), data=data) -->
+<!-- comparison(model) -->
+<!-- ``` -->
+<!-- ```{r message=FALSE, warning=FALSE, echo=FALSE} -->
+<!-- knitr::kable(comparison(model), digits=2, row.names = FALSE) -->
+<!-- ``` -->
+<!-- #### Bayesian Models -->
+<!-- ```{r message=FALSE, warning=FALSE, eval=FALSE} -->
+<!-- library(rstanarm) -->
+<!-- model <- stan_lmer(Sepal.Length ~ Petal.Width + Group_Sepal.Width + (1|Species), data=data) -->
+<!-- comparison(model) -->
+<!-- ``` -->
+<!-- ```{r message=FALSE, warning=FALSE, echo=FALSE} -->
+<!-- library(rstanarm) -->
+<!-- model <- stan_lmer(Sepal.Length ~ Petal.Width + Group_Sepal.Width + (1|Species), data=data, refresh = 0, iter = 500) -->
+<!-- knitr::kable(comparison(model), digits=2, row.names = FALSE) -->
+<!-- ``` -->
+<!-- When factors are involved, the basic method (that standardizes the numeric transformation of factors) give again different results. -->
+<!-- ### Models with interactions -->
+<!-- Long story short, coeffcient obtained via **posthoc** standardization (without refitting the model) go berserk when interactions are involved. However, **this is ""normal""**: a regression model estimates coefficient between two variables when the other predictors are at 0 (are *fixed* at 0, that people interpret as *""adjusted for""*). When a standardized data is passed (in the *refit* method), the effects and interactions are estimated at the **means** of the other predictors (because 0 is the mean for a standardized variable). Whereas in posthoc standardization, this coefficient correspond to something different (because the 0 corresponds to something different in standardzed and non-standardized data). In other words, when it comes to interaction, passing standardized data results in a different model, which coefficient have an intrinsically different meaning from unstandardized data. And as [for now](https://github.com/easystats/effectsize/issues/6), we are unable to retrieve one from another. -->
+<!-- #### Between continuous -->
+<!-- ```{r message=FALSE, warning=FALSE, results='hide'} -->
+<!-- model <- lm(Sepal.Length ~ Petal.Width * Sepal.Width, data=data) -->
+<!-- comparison(model) -->
+<!-- ``` -->
+<!-- ```{r message=FALSE, warning=FALSE, echo=FALSE} -->
+<!-- knitr::kable(comparison(model), digits=2, row.names = FALSE) -->
+<!-- ``` -->
+<!-- #### Between factors -->
+<!-- ```{r message=FALSE, warning=FALSE, results='hide'} -->
+<!-- model <- lm(Sepal.Length ~ Species * Group_Sepal.Width, data=data) -->
+<!-- comparison(model) -->
+<!-- ``` -->
+<!-- ```{r message=FALSE, warning=FALSE, echo=FALSE} -->
+<!-- knitr::kable(comparison(model), digits=2, row.names = FALSE) -->
+<!-- ``` -->
+<!-- #### Between factors and continuous -->
+<!-- ```{r message=FALSE, warning=FALSE, results='hide'} -->
+<!-- model <- lm(Sepal.Length ~ Petal.Width * Group_Sepal.Width, data=data) -->
+<!-- comparison(model) -->
+<!-- ``` -->
+<!-- ```{r message=FALSE, warning=FALSE, echo=FALSE} -->
+<!-- knitr::kable(comparison(model), digits=2, row.names = FALSE) -->
+<!-- ``` -->
+<!-- ```{r message=FALSE, warning=FALSE, results='hide'} -->
+<!-- model <- lm(Sepal.Length ~ Group_Sepal.Width * Petal.Width, data=data) -->
+<!-- comparison(model) -->
+<!-- ``` -->
+<!-- ```{r message=FALSE, warning=FALSE, echo=FALSE} -->
+<!-- knitr::kable(comparison(model), digits=2, row.names = FALSE) -->
+<!-- ``` -->
+<!-- ## Conclusion -->
+<!-- Use `refit` if possible, but if no interactions, can use `posthoc` or `smart`. -->
+<!-- # References -->
 <div id=""refs"" class=""references"">
 <div id=""ref-bring1994standardize"">
 <p>Bring, Johan. 1994. âHow to Standardize Regression Coefficients.â <em>The American Statistician</em> 48 (3): 209â13.</p>
@@ -1105,10 +505,12 @@ <h1 class=""hasAnchor"">
 <p>Schielzeth, Holger. 2010. âSimple Means to Improve the Interpretability of Regression Coefficients.â <em>Methods in Ecology and Evolution</em> 1 (2): 103â13.</p>
 </div>
 </div>
+</div>
 </div>
   </div>
 
   <div class=""col-md-3 hidden-xs hidden-sm"" id=""sidebar"">
+
         <div id=""tocnav"">
       <h2 class=""hasAnchor"">
 <a href=""#tocnav"" class=""anchor""></a>Contents</h2>
@@ -1118,16 +520,8 @@ <h2 class=""hasAnchor"">
 <a href=""#how-to-interpret-standardized-coefficients"">How to interpret standardized coefficients?</a><ul class=""nav nav-pills nav-stacked"">
 <li><a href=""#measure-of-association-correlation-r"">Measure of association (correlation <em>r</em>)</a></li>
       <li><a href=""#standardized-differences"">Standardized differences</a></li>
-      <li><a href=""#what-about-standardized-interaction-effects"">What about standardized interaction effects?</a></li>
-      </ul>
-</li>
-      <li>
-<a href=""#standardization-methods"">Standardization methods</a><ul class=""nav nav-pills nav-stacked"">
-<li><a href=""#methods-comparison"">Methods Comparison</a></li>
-      <li><a href=""#conclusion"">Conclusion</a></li>
       </ul>
 </li>
-      <li><a href=""#references"">References</a></li>
       </ul>
 </div>
       </div>
@@ -1141,7 +535,7 @@ <h2 class=""hasAnchor"">
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/authors.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,13 +41,14 @@
 
 
 
-<meta property=""og:title"" content=""Citation and Authors"" />
 
+<meta property=""og:title"" content=""Citation and Authors"" />
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -125,7 +128,6 @@
   <a href=""articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -163,6 +165,7 @@ <h1>Citation</h1>
   note = {R package},
   url = {https://github.com/easystats/effectsize},
 }</pre>
+
     <div class=""page-header"">
       <h1>Authors</h1>
     </div>
@@ -194,7 +197,7 @@ <h1>Authors</h1>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/index.html---
@@ -122,7 +122,7 @@ <h2 class=""hasAnchor"">
 <a href=""#installation"" class=""anchor""></a>Installation</h2>
 <p>Run the following:</p>
 <div class=""sourceCode"" id=""cb1""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb1-1"" title=""1""><span class=""kw""><a href=""https://rdrr.io/r/utils/install.packages.html"">install.packages</a></span>(<span class=""st"">""devtools""</span>)</a>
-<a class=""sourceLine"" id=""cb1-2"" title=""2"">devtools<span class=""op"">::</span><span class=""kw""><a href=""https://rdrr.io/pkg/devtools/man/reexports.html"">install_github</a></span>(<span class=""st"">""easystats/effectsize""</span>)</a></code></pre></div>
+<a class=""sourceLine"" id=""cb1-2"" title=""2"">devtools<span class=""op"">::</span><span class=""kw""><a href=""https://rdrr.io/pkg/devtools/man/remote-reexports.html"">install_github</a></span>(<span class=""st"">""easystats/effectsize""</span>)</a></code></pre></div>
 <div class=""sourceCode"" id=""cb2""><pre class=""sourceCode r""><code class=""sourceCode r""><a class=""sourceLine"" id=""cb2-1"" title=""1""><span class=""kw""><a href=""https://rdrr.io/r/base/library.html"">library</a></span>(<span class=""st"">""effectsize""</span>)</a></code></pre></div>
 </div>
 <div id=""documentation"" class=""section level2"">
@@ -381,7 +381,7 @@ <h2>Dev status</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/news/index.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,13 +41,14 @@
 
 
 
-<meta property=""og:title"" content=""Changelog"" />
 
+<meta property=""og:title"" content=""Changelog"" />
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -125,7 +128,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -186,7 +188,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/pkgdown.yml---
@@ -1,5 +1,5 @@
-pandoc: 2.7.1
-pkgdown: 1.4.0
+pandoc: 2.7.2
+pkgdown: 1.4.1
 pkgdown_sha: ~
 articles:
   bayesian_models: bayesian_models.html

---FILE: docs/reference/F_to_partial_eta_squared.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""Convert test statistics (F, t) to indices of variance explained (partial Eta / Omega / Epsilon squared) â F_to_partial_eta_squared"" />
 
+<meta property=""og:title"" content=""Convert test statistics (F, t) to indices of variance explained (partial Eta / Omega / Epsilon squared) â F_to_partial_eta_squared"" />
 <meta property=""og:description"" content=""These functions are convenience functions to convert F and t test statistics to partial Eta squared, (\(\eta{_p}^2\)), Omega squared (\(\omega{_p}^2\)) and Epsilon squared (\(\epsilon{_p}^2\); an alias for the adjusted Eta squared). These are useful in cases where the various Sum of Squares and Mean Squares are not easily available or their computation is not straightforward (e.g., in liner mixed models, contrasts, etc.). For test statistics derived from lm and aov models, these functions give exact results. For all other cases, they return close approximations."" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,9 +155,7 @@ <h1>Convert test statistics (F, t) to indices of variance explained (partial Eta
     </div>
 
     <div class=""ref-description"">
-    
     <p>These functions are convenience functions to convert F and t test statistics to partial Eta squared, (\(\eta{_p}^2\)), Omega squared (\(\omega{_p}^2\)) and Epsilon squared (\(\epsilon{_p}^2\); an alias for the adjusted Eta squared). These are useful in cases where the various Sum of Squares and Mean Squares are not easily available or their computation is not straightforward (e.g., in liner mixed models, contrasts, etc.). For test statistics derived from <code>lm</code> and <code>aov</code> models, these functions give exact results. For all other cases, they return close approximations.</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>F_to_partial_eta_squared</span>(<span class='no'>f</span>, <span class='no'>df</span>, <span class='no'>df_error</span>, <span class='no'>...</span>)
@@ -174,7 +173,7 @@ <h1>Convert test statistics (F, t) to indices of variance explained (partial Eta
 <span class='fu'>F_to_partial_omega_squared</span>(<span class='no'>f</span>, <span class='no'>df</span>, <span class='no'>df_error</span>, <span class='no'>...</span>)
 
 <span class='fu'>t_to_partial_omega_squared</span>(<span class='no'>t</span>, <span class='no'>df_error</span>, <span class='no'>...</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -191,13 +190,12 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <td><p>The t, the F or the z statistics.</p></td>
     </tr>
     </table>
-    
+
     <h2 class=""hasAnchor"" id=""value""><a class=""anchor"" href=""#value""></a>Value</h2>
 
     <p>A numeric integer between 0-1 (Note that for \(\omega_p^2\) and \(\epsilon_p^2\)
 it is possible to compute a negative number; even though this doesn't make any practical sense,
 it is recommended to report the negative number and not a 0).</p>
-    
     <h2 class=""hasAnchor"" id=""details""><a class=""anchor"" href=""#details""></a>Details</h2>
 
     <p>These functions use the following formulae:
@@ -209,11 +207,9 @@ <h2 class=""hasAnchor"" id=""details""><a class=""anchor"" href=""#details""></a>Details
 $$\omega_p^2 = \frac{(F - 1) \times df_{num}}{F \times df_{num} + df_{den} + 1}$$
 <br /><br /><br />
 For \(t\), the conversion is based on the equality of \(t^2 = F\) when \(df_{num}=1\).</p>
-    
     <h2 class=""hasAnchor"" id=""note""><a class=""anchor"" href=""#note""></a>Note</h2>
 
     <p>\(Adj. \eta_p^2\) is an alias for \(\epsilon_p^2\).</p>
-    
     <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>References</h2>
 
     
@@ -223,7 +219,6 @@ <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>R
 <li><p>Albers, C., &amp; Lakens, D. (2018). When power analyses based on pilot data are biased: Inaccurate effect size estimators and follow-up bias. Journal of experimental social psychology, 74, 187-195. doi: <a href='https://doi.org/10.31234/osf.io/b7z4q'>10.31234/osf.io/b7z4q</a></p></li>
 </ul>
 
-    
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='kw'>if</span> (<span class='fl'>FALSE</span>) {
@@ -256,15 +251,10 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-      
       <li><a href=""#value"">Value</a></li>
-
       <li><a href=""#details"">Details</a></li>
-
       <li><a href=""#note"">Note</a></li>
-
       <li><a href=""#references"">References</a></li>
-      
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -278,7 +268,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/change_scale.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""Rescale a numeric variable â change_scale"" />
 
+<meta property=""og:title"" content=""Rescale a numeric variable â change_scale"" />
 <meta property=""og:description"" content=""Rescale a numeric variable. This scales all numeric variables in the range 0 - 1."" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,9 +155,7 @@ <h1>Rescale a numeric variable</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>Rescale a numeric variable. This scales all numeric variables in the range 0 - 1.</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>change_scale</span>(<span class='no'>x</span>, <span class='no'>...</span>)
@@ -172,7 +171,7 @@ <h1>Rescale a numeric variable</h1>
 <span class='co'># S3 method for data.frame</span>
 <span class='fu'>change_scale</span>(<span class='no'>x</span>, <span class='kw'>select</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>exclude</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
   <span class='kw'>to</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>0</span>, <span class='fl'>100</span>), <span class='kw'>range</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='no'>...</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -208,15 +207,13 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
 be excluded from standardization.</p></td>
     </tr>
     </table>
-    
+
     <h2 class=""hasAnchor"" id=""value""><a class=""anchor"" href=""#value""></a>Value</h2>
 
     <p>A rescaled object.</p>
-    
     <h2 class=""hasAnchor"" id=""see-also""><a class=""anchor"" href=""#see-also""></a>See also</h2>
 
     <div class='dont-index'><p><code><a href='normalize.html'>normalize</a></code> <code><a href='standardize.html'>standardize</a></code> <code><a href='ranktransform.html'>ranktransform</a></code></p></div>
-    
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='fu'>change_scale</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>0</span>, <span class='fl'>1</span>, <span class='fl'>5</span>, -<span class='fl'>5</span>, -<span class='fl'>2</span>))</div><div class='output co'>#&gt; [1]  50  60 100   0  30</div><div class='input'><span class='fu'>change_scale</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>0</span>, <span class='fl'>1</span>, <span class='fl'>5</span>, -<span class='fl'>5</span>, -<span class='fl'>2</span>), <span class='kw'>to</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(-<span class='fl'>5</span>, <span class='fl'>5</span>))</div><div class='output co'>#&gt; [1]  0  1  5 -5 -2</div><div class='input'>
@@ -232,11 +229,8 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-      
       <li><a href=""#value"">Value</a></li>
-
       <li><a href=""#see-also"">See also</a></li>
-      
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -250,7 +244,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/chisq_to_phi.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""Conversion between Effect sizes for Contingency Tables (Chi2, Phi, Cramer's V...) â chisq_to_phi"" />
 
+<meta property=""og:title"" content=""Conversion between Effect sizes for Contingency Tables (Chi2, Phi, Cramer's V...) â chisq_to_phi"" />
 <meta property=""og:description"" content=""Convert between Chi square, (\(chi^2\)), phi (\(\phi\)) and Cramer's V."" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,9 +155,7 @@ <h1>Conversion between Effect sizes for Contingency Tables (Chi2, Phi, Cramer's
     </div>
 
     <div class=""ref-description"">
-    
     <p>Convert between Chi square, (\(chi^2\)), phi (\(\phi\)) and Cramer's V.</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>chisq_to_phi</span>(<span class='no'>chisq</span>, <span class='no'>n</span>, <span class='no'>...</span>)
@@ -170,7 +169,7 @@ <h1>Conversion between Effect sizes for Contingency Tables (Chi2, Phi, Cramer's
 <span class='fu'>chisq_to_cramers_v</span>(<span class='no'>chisq</span>, <span class='no'>n</span>, <span class='no'>nrow</span>, <span class='no'>ncol</span>, <span class='no'>...</span>)
 
 <span class='fu'>convert_chisq_to_cramers_v</span>(<span class='no'>chisq</span>, <span class='no'>n</span>, <span class='no'>nrow</span>, <span class='no'>ncol</span>, <span class='no'>...</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -199,11 +198,10 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <td><p>The number of columns in the contingency tables.</p></td>
     </tr>
     </table>
-    
+
     <h2 class=""hasAnchor"" id=""value""><a class=""anchor"" href=""#value""></a>Value</h2>
 
     <p>A numeric integer between 0-1.</p>
-    
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='no'>contingency_table</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/table.html'>as.table</a></span>(<span class='fu'><a href='https://rdrr.io/r/base/cbind.html'>rbind</a></span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>762</span>, <span class='fl'>327</span>, <span class='fl'>468</span>), <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>484</span>, <span class='fl'>239</span>, <span class='fl'>477</span>), <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>484</span>, <span class='fl'>239</span>, <span class='fl'>477</span>)))
@@ -229,9 +227,7 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-      
       <li><a href=""#value"">Value</a></li>
-      
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -245,7 +241,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/cohens_d.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""Effect size for differences â cohens_d"" />
 
+<meta property=""og:title"" content=""Effect size for differences â cohens_d"" />
 <meta property=""og:description"" content=""Compute different indices of effect size. For very small sample sizes (n &amp;lt; 20) Hedges' g is considered as less biased than Cohen's d. For sample sizes &amp;gt; 20, the results for both statistics are roughly equivalent. The Glassâs delta is appropriate if standard deviations are significantly different between groups, as it uses only the control group's (x) standard deviation."" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,9 +155,7 @@ <h1>Effect size for differences</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>Compute different indices of effect size. For very small sample sizes (n &lt; 20) Hedges' g is considered as less biased than Cohen's d. For sample sizes &gt; 20, the results for both statistics are roughly equivalent. The Glassâs delta is appropriate if standard deviations are significantly different between groups, as it uses only the control group's (<code>x</code>) standard deviation.</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>cohens_d</span>(<span class='no'>x</span>, <span class='kw'>y</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>correction</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
@@ -166,7 +165,7 @@ <h1>Effect size for differences</h1>
   <span class='kw'>pooled_sd</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='kw'>paired</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)
 
 <span class='fu'>glass_delta</span>(<span class='no'>x</span>, <span class='kw'>y</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>correction</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -195,7 +194,7 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <td><p>If <code>TRUE</code>, the values of <code>x</code> and <code>y</code> are considered as paired.</p></td>
     </tr>
     </table>
-    
+
     <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>References</h2>
 
     
@@ -205,7 +204,6 @@ <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>R
 <li><p>Hedges, L. V. &amp; Olkin, I. (1985). Statistical methods for meta-analysis. Orlando, FL: Academic Press.</p></li>
 </ul>
 
-    
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='fu'>cohens_d</span>(<span class='no'>iris</span>$<span class='no'>Sepal.Length</span>, <span class='no'>iris</span>$<span class='no'>Sepal.Width</span>)</div><div class='output co'>#&gt; [1] -4.210417</div><div class='input'><span class='fu'>hedges_g</span>(<span class='no'>iris</span>$<span class='no'>Sepal.Length</span>, <span class='no'>iris</span>$<span class='no'>Sepal.Width</span>)</div><div class='output co'>#&gt; [1] -4.199812</div><div class='input'><span class='fu'>glass_delta</span>(<span class='no'>iris</span>$<span class='no'>Sepal.Length</span>, <span class='no'>iris</span>$<span class='no'>Sepal.Width</span>)</div><div class='output co'>#&gt; [1] -3.364466</div><div class='input'>
@@ -215,9 +213,7 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-      
       <li><a href=""#references"">References</a></li>
-      
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -231,7 +227,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/convert_posteriors_to_r.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""Convert posterior distributions from a Bayesian model â convert_posteriors_to_r"" />
 
+<meta property=""og:title"" content=""Convert posterior distributions from a Bayesian model â convert_posteriors_to_r"" />
 <meta property=""og:description"" content=""Convert posterior distributions from a Bayesian model to indices of effect size."" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,9 +155,7 @@ <h1>Convert posterior distributions from a Bayesian model</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>Convert posterior distributions from a Bayesian model to indices of effect size.</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>convert_posteriors_to_r</span>(<span class='no'>model</span>, <span class='no'>...</span>)
@@ -166,7 +165,7 @@ <h1>Convert posterior distributions from a Bayesian model</h1>
 <span class='fu'>convert_posteriors_to_t</span>(<span class='no'>model</span>, <span class='no'>...</span>)
 
 <span class='fu'>posteriors_to_t</span>(<span class='no'>model</span>, <span class='no'>...</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -179,18 +178,19 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <td><p>Arguments passed to or from other methods.</p></td>
     </tr>
     </table>
-    
+
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
-    <pre class=""examples""><div class='input'><span class='fu'><a href='https://rdrr.io/r/base/library.html'>library</a></span>(<span class='no'>rstanarm</span>)</div><div class='output co'>#&gt; <span class='warning'>Warning: package 'rstanarm' was built under R version 3.6.1</span></div><div class='output co'>#&gt; <span class='message'>Loading required package: Rcpp</span></div><div class='output co'>#&gt; <span class='warning'>Warning: package 'Rcpp' was built under R version 3.6.1</span></div><div class='output co'>#&gt; <span class='message'>Registered S3 method overwritten by 'xts':</span>
+    <pre class=""examples""><div class='input'><span class='fu'><a href='https://rdrr.io/r/base/library.html'>library</a></span>(<span class='no'>rstanarm</span>)</div><div class='output co'>#&gt; <span class='message'>Loading required package: Rcpp</span></div><div class='output co'>#&gt; <span class='message'>Registered S3 method overwritten by 'xts':</span>
 #&gt; <span class='message'>  method     from</span>
-#&gt; <span class='message'>  as.zoo.xts zoo </span></div><div class='output co'>#&gt; <span class='message'>rstanarm (Version 2.18.2, packaged: 2018-11-08 22:19:38 UTC)</span></div><div class='output co'>#&gt; <span class='message'>- Do not expect the default priors to remain the same in future rstanarm versions.</span></div><div class='output co'>#&gt; <span class='message'>Thus, R scripts should specify priors explicitly, even if they are just the defaults.</span></div><div class='output co'>#&gt; <span class='message'>- For execution on a local, multicore CPU with excess RAM we recommend calling</span></div><div class='output co'>#&gt; <span class='message'>options(mc.cores = parallel::detectCores())</span></div><div class='output co'>#&gt; <span class='message'>- Plotting theme set to bayesplot::theme_default().</span></div><div class='input'><span class='no'>model</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://mc-stan.org/rstanarm/reference/stan_glm.html'>stan_glm</a></span>(<span class='no'>mpg</span> ~ <span class='no'>cyl</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>mtcars</span>, <span class='kw'>refresh</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>chains</span> <span class='kw'>=</span> <span class='fl'>2</span>)</div></pre>
+#&gt; <span class='message'>  as.zoo.xts zoo </span></div><div class='output co'>#&gt; <span class='message'>Registered S3 method overwritten by 'rstanarm':</span>
+#&gt; <span class='message'>  method         from   </span>
+#&gt; <span class='message'>  nobs.stanmvreg insight</span></div><div class='output co'>#&gt; <span class='message'>rstanarm (Version 2.19.2, packaged: 2019-10-01 20:20:33 UTC)</span></div><div class='output co'>#&gt; <span class='message'>- Do not expect the default priors to remain the same in future rstanarm versions.</span></div><div class='output co'>#&gt; <span class='message'>Thus, R scripts should specify priors explicitly, even if they are just the defaults.</span></div><div class='output co'>#&gt; <span class='message'>- For execution on a local, multicore CPU with excess RAM we recommend calling</span></div><div class='output co'>#&gt; <span class='message'>options(mc.cores = parallel::detectCores())</span></div><div class='output co'>#&gt; <span class='message'>- bayesplot theme set to bayesplot::theme_default()</span></div><div class='output co'>#&gt; <span class='message'>   * Does _not_ affect other ggplot2 plots</span></div><div class='output co'>#&gt; <span class='message'>   * See ?bayesplot_theme_set for details on theme setting</span></div><div class='input'><span class='no'>model</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://mc-stan.org/rstanarm/reference/stan_glm.html'>stan_glm</a></span>(<span class='no'>mpg</span> ~ <span class='no'>cyl</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>mtcars</span>, <span class='kw'>refresh</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>chains</span> <span class='kw'>=</span> <span class='fl'>2</span>)</div></pre>
   </div>
   <div class=""col-md-3 hidden-xs hidden-sm"" id=""sidebar"">
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-            
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -204,7 +204,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/d_to_r.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""General effect size conversion â percentage_to_d"" />
 
+<meta property=""og:title"" content=""General effect size conversion â percentage_to_d"" />
 <meta property=""og:description"" content=""Enables a conversion between different indices of effect size, such as standardized difference (Cohen's d), correlation r or (log) odds ratios."" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,9 +155,7 @@ <h1>General effect size conversion</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>Enables a conversion between different indices of effect size, such as standardized difference (Cohen's d), correlation r or (log) odds ratios.</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>percentage_to_d</span>(<span class='no'>percentage</span>, <span class='no'>...</span>)
@@ -202,7 +201,7 @@ <h1>General effect size conversion</h1>
 <span class='fu'>convert_odds_to_probs</span>(<span class='no'>odds</span>, <span class='kw'>log</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='no'>...</span>)
 
 <span class='fu'>convert_probs_to_odds</span>(<span class='no'>probs</span>, <span class='kw'>log</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='no'>...</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -245,11 +244,10 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <td><p>Probability values.</p></td>
     </tr>
     </table>
-    
+
     <h2 class=""hasAnchor"" id=""value""><a class=""anchor"" href=""#value""></a>Value</h2>
 
     <p>Converted index.</p>
-    
     <h2 class=""hasAnchor"" id=""details""><a class=""anchor"" href=""#details""></a>Details</h2>
 
     
@@ -260,7 +258,6 @@ <h2 class=""hasAnchor"" id=""details""><a class=""anchor"" href=""#details""></a>Details
 <li><p><em>d to odds</em>: \(log(odds) = d * \frac{\pi}{\sqrt(3)}\)</p></li>
 </ul>
 
-    
     <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>References</h2>
 
     
@@ -269,7 +266,6 @@ <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>R
 <li><p>Borenstein, M., Hedges, L. V., Higgins, J. P. T., &amp; Rothstein, H. R. (2009). Converting among effect sizes. Introduction to meta-analysis, 45-49.</p></li>
 </ul>
 
-    
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='fu'>r_to_d</span>(<span class='fl'>0.5</span>)</div><div class='output co'>#&gt; [1] 1.154701</div><div class='input'><span class='fu'>d_to_odds</span>(<span class='kw'>d</span> <span class='kw'>=</span> <span class='fl'>1.154701</span>)</div><div class='output co'>#&gt; [1] 8.120534</div><div class='input'><span class='fu'>odds_to_r</span>(<span class='kw'>odds</span> <span class='kw'>=</span> <span class='fl'>8.120534</span>)</div><div class='output co'>#&gt; [1] 0.5000001</div><div class='input'>
@@ -279,13 +275,9 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-      
       <li><a href=""#value"">Value</a></li>
-
       <li><a href=""#details"">Details</a></li>
-
       <li><a href=""#references"">References</a></li>
-      
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -299,7 +291,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/dot-factor_to_numeric.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""Safe transformation from factor/character to numeric â .factor_to_numeric"" />
 
+<meta property=""og:title"" content=""Safe transformation from factor/character to numeric â .factor_to_numeric"" />
 <meta property=""og:description"" content=""Safe transformation from factor/character to numeric"" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,19 +155,18 @@ <h1>Safe transformation from factor/character to numeric</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>Safe transformation from factor/character to numeric</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>.factor_to_numeric</span>(<span class='no'>x</span>)</pre>
-        
+
+
 
   </div>
   <div class=""col-md-3 hidden-xs hidden-sm"" id=""sidebar"">
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
-                </ul>
+    </ul>
 
   </div>
 </div>
@@ -178,7 +178,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/eta_squared.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""Effect size for ANOVA â cohens_f"" />
 
+<meta property=""og:title"" content=""Effect size for ANOVA â cohens_f"" />
 <meta property=""og:description"" content=""Set of functions to compute effect size measures for ANOVAs, such as omega squared, the eta squared or the epsilon squared (Kelly, 1935). They are an estimate of how much variance in the response variables are accounted for by the explanatory variables."" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,9 +155,7 @@ <h1>Effect size for ANOVA</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>Set of functions to compute effect size measures for ANOVAs, such as omega squared, the eta squared or the epsilon squared (Kelly, 1935). They are an estimate of how much variance in the response variables are accounted for by the explanatory variables.</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>cohens_f</span>(<span class='no'>model</span>)
@@ -170,7 +169,7 @@ <h1>Effect size for ANOVA</h1>
   <span class='kw'>iterations</span> <span class='kw'>=</span> <span class='fl'>1000</span>, <span class='no'>...</span>)
 
 <span class='fu'>omega_squared</span>(<span class='no'>model</span>, <span class='kw'>partial</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='kw'>ci</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>iterations</span> <span class='kw'>=</span> <span class='fl'>1000</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -195,11 +194,10 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <td><p>Number of bootstrap iterations.</p></td>
     </tr>
     </table>
-    
+
     <h2 class=""hasAnchor"" id=""value""><a class=""anchor"" href=""#value""></a>Value</h2>
 
     <p>Data.frame containing the effect size values.</p>
-    
     <h2 class=""hasAnchor"" id=""details""><a class=""anchor"" href=""#details""></a>Details</h2>
 
     
@@ -215,7 +213,6 @@ <h3>Omega Squared</h3>
 <p>It is one of the least common measures of effect sizes: omega squared and eta squared are used more frequently. Although having a different name and a formula in appearance different, this index is equivalent to the adjusted R2 (Allen, 2017, p. 382).</p><p></p><h3>Cohen's f</h3>
 <p>Cohen's f statistic is one appropriate effect size index to use for a oneway analysis of variance (ANOVA). Cohen's f can take on values between zero, when the population means are all equal, and an indefinitely large number as standard deviation of means increases relative to the average standard deviation within each group. Cohen has suggested that the values of 0.10, 0.25, and 0.40 represent small, medium, and large effect sizes, respectively.</p>
 
-    
     <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>References</h2>
 
     
@@ -228,7 +225,6 @@ <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>R
 </ul>
 
 <p>The computation of CIs is based on the implementation done by Stanley (2018) in the <code>ApaTables</code> package and Kelley (2007) in the <code>MBESS</code> package. All credits go to them.</p>
-    
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='fu'><a href='https://rdrr.io/r/base/library.html'>library</a></span>(<span class='no'>effectsize</span>)
@@ -274,13 +270,9 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-      
       <li><a href=""#value"">Value</a></li>
-
       <li><a href=""#details"">Details</a></li>
-
       <li><a href=""#references"">References</a></li>
-      
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -294,7 +286,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/format_standardize.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""Transform a standardized vector into character â format_standardize"" />
 
+<meta property=""og:title"" content=""Transform a standardized vector into character â format_standardize"" />
 <meta property=""og:description"" content=""Transform a standardized vector into character, e.g., c(&quot;-1 SD&quot;, &quot;Mean&quot;, &quot;+1 SD&quot;)."" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,14 +155,12 @@ <h1>Transform a standardized vector into character</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>Transform a standardized vector into character, e.g., <code><a href='https://rdrr.io/r/base/c.html'>c(""-1 SD"", ""Mean"", ""+1 SD"")</a></code>.</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>format_standardize</span>(<span class='no'>x</span>, <span class='kw'>reference</span> <span class='kw'>=</span> <span class='no'>x</span>, <span class='kw'>robust</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>digits</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
   <span class='no'>...</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -189,7 +188,7 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <td><p>Arguments passed to or from other methods.</p></td>
     </tr>
     </table>
-    
+
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='fu'>format_standardize</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(-<span class='fl'>1</span>, <span class='fl'>0</span>, <span class='fl'>1</span>))</div><div class='output co'>#&gt; [1] -1 SD Mean  +1 SD
@@ -201,7 +200,6 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-            
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -215,7 +213,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/index.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,13 +41,14 @@
 
 
 
-<meta property=""og:title"" content=""Function reference"" />
 
+<meta property=""og:title"" content=""Function reference"" />
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -125,7 +128,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -388,7 +390,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/interpret.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""Generic function for interpretation â interpret"" />
 
+<meta property=""og:title"" content=""Generic function for interpretation â interpret"" />
 <meta property=""og:description"" content=""Interpret a value based on a set of rules. See rules."" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,13 +155,11 @@ <h1>Generic function for interpretation</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>Interpret a value based on a set of rules. See <a href='rules.html'>rules</a>.</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>interpret</span>(<span class='no'>x</span>, <span class='no'>rules</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -173,7 +172,7 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <td><p>Set of <a href='rules.html'>rules</a>.</p></td>
     </tr>
     </table>
-    
+
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='no'>rules_grid</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='rules.html'>rules</a></span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>0.01</span>, <span class='fl'>0.05</span>), <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='st'>""very significant""</span>, <span class='st'>""significant""</span>, <span class='st'>""not significant""</span>))
@@ -183,7 +182,6 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-            
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -197,7 +195,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/interpret_bf.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""Bayes Factor (BF) Interpretation â interpret_bf"" />
 
+<meta property=""og:title"" content=""Bayes Factor (BF) Interpretation â interpret_bf"" />
 <meta property=""og:description"" content=""Bayes Factor (BF) Interpretation"" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,13 +155,11 @@ <h1>Bayes Factor (BF) Interpretation</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>Bayes Factor (BF) Interpretation</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>interpret_bf</span>(<span class='no'>bf</span>, <span class='kw'>rules</span> <span class='kw'>=</span> <span class='st'>""jeffreys1961""</span>, <span class='kw'>include_value</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -177,7 +176,7 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <td><p>Include the value in the output.</p></td>
     </tr>
     </table>
-    
+
     <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>References</h2>
 
     
@@ -187,7 +186,6 @@ <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>R
 <li><p>Jarosz, A. F., &amp; Wiley, J. (2014). What are the odds? A practical guide to computing and reporting Bayes factors. The Journal of Problem Solving, 7(1), 2.</p></li>
 </ul>
 
-    
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='fu'>interpret_bf</span>(<span class='fl'>1</span>)</div><div class='output co'>#&gt; [1] ""anecdotal evidence in favour of""</div><div class='input'><span class='fu'>interpret_bf</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>5</span>, <span class='fl'>2</span>))</div><div class='output co'>#&gt; [1] ""moderate evidence in favour of""  ""anecdotal evidence in favour of""</div></pre>
@@ -196,9 +194,7 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-      
       <li><a href=""#references"">References</a></li>
-      
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -212,7 +208,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/interpret_d.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,16 +41,16 @@
 
 
 
-<meta property=""og:title"" content=""Standardized difference interpretation â interpret_d"" />
 
+<meta property=""og:title"" content=""Standardized difference interpretation â interpret_d"" />
 <meta property=""og:description"" content=""Interpretation of indices using different sets of rules of thumb.
 Click here for details."" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -128,7 +130,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -155,18 +156,16 @@ <h1>Standardized difference interpretation</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>Interpretation of indices using different sets of rules of thumb.
 <a href='https://easystats.github.io/report/articles/interpret_metrics.html#standardized-difference-d-cohens-d'>Click here</a> for details.</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>interpret_d</span>(<span class='no'>d</span>, <span class='kw'>rules</span> <span class='kw'>=</span> <span class='st'>""funder2019""</span>)
 
 <span class='fu'>interpret_g</span>(<span class='no'>g</span>, <span class='kw'>rules</span> <span class='kw'>=</span> <span class='st'>""funder2019""</span>)
 
 <span class='fu'>interpret_delta</span>(<span class='no'>delta</span>, <span class='kw'>rules</span> <span class='kw'>=</span> <span class='st'>""funder2019""</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -179,7 +178,7 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <td><p>Can be ""funder2019"" (default), ""gignac2016"", ""cohen1988"", ""sawilowsky2009"" or custom set of <code><a href='rules.html'>rules</a></code>.</p></td>
     </tr>
     </table>
-    
+
     <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>References</h2>
 
     
@@ -190,7 +189,6 @@ <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>R
 <li><p>Sawilowsky, S. S. (2009). New effect size rules of thumb.</p></li>
 </ul>
 
-    
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='fu'>interpret_d</span>(<span class='fl'>.02</span>)</div><div class='output co'>#&gt; [1] ""tiny""</div><div class='input'><span class='fu'>interpret_d</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>.5</span>, <span class='fl'>.02</span>))</div><div class='output co'>#&gt; [1] ""medium"" ""tiny""  </div></pre>
@@ -199,9 +197,7 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-      
       <li><a href=""#references"">References</a></li>
-      
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -215,7 +211,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/interpret_direction.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""Direction interpretation â interpret_direction"" />
 
+<meta property=""og:title"" content=""Direction interpretation â interpret_direction"" />
 <meta property=""og:description"" content=""Direction interpretation"" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,13 +155,11 @@ <h1>Direction interpretation</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>Direction interpretation</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>interpret_direction</span>(<span class='no'>x</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -169,7 +168,7 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <td><p>Numeric value.</p></td>
     </tr>
     </table>
-    
+
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='fu'>interpret_direction</span>(<span class='fl'>.02</span>)</div><div class='output co'>#&gt; [1] ""positive""</div><div class='input'><span class='fu'>interpret_direction</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>.5</span>, -<span class='fl'>.02</span>))</div><div class='output co'>#&gt; [1] ""positive"" ""negative""</div><div class='input'>#
@@ -179,7 +178,6 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-            
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -193,7 +191,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/interpret_ess.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""Bayesian indices interpretation â interpret_ess"" />
 
+<meta property=""og:title"" content=""Bayesian indices interpretation â interpret_ess"" />
 <meta property=""og:description"" content=""Interpretation of Bayesian indices, such as Effective Sample Size (ESS), Rhat, or percentage in ROPE."" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,17 +155,15 @@ <h1>Bayesian indices interpretation</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>Interpretation of Bayesian indices, such as Effective Sample Size (ESS), Rhat, or percentage in ROPE.</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>interpret_ess</span>(<span class='no'>ess</span>, <span class='kw'>rules</span> <span class='kw'>=</span> <span class='st'>""burkner2017""</span>)
 
 <span class='fu'>interpret_rhat</span>(<span class='no'>rhat</span>, <span class='kw'>rules</span> <span class='kw'>=</span> <span class='st'>""vehtari2019""</span>)
 
 <span class='fu'>interpret_rope</span>(<span class='no'>rope</span>, <span class='kw'>ci</span> <span class='kw'>=</span> <span class='fl'>0.9</span>, <span class='kw'>rules</span> <span class='kw'>=</span> <span class='st'>""default""</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -189,7 +188,7 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <td><p>The Credible Interval (CI) probability, corresponding to the proportion of HDI, that was used. Can be <code>1</code> in the case of ""full ROPE"".</p></td>
     </tr>
     </table>
-    
+
     <h2 class=""hasAnchor"" id=""details""><a class=""anchor"" href=""#details""></a>Details</h2>
 
     
@@ -202,7 +201,6 @@ <h3>Rules sets:</h3>
 <li><p><strong>ESS</strong>:</p></li>
 </ul>
 
-    
     <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>References</h2>
 
     
@@ -213,7 +211,6 @@ <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>R
 <li><p><a href='https://easystats.github.io/bayestestR/articles/guidelines.html'>BayestestR's reporting guidelines</a></p></li>
 </ul>
 
-    
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='fu'>interpret_ess</span>(<span class='fl'>1001</span>)</div><div class='output co'>#&gt; [1] ""sufficient""</div><div class='input'><span class='fu'>interpret_ess</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>852</span>, <span class='fl'>1200</span>))</div><div class='output co'>#&gt; [1] ""unsufficient"" ""sufficient""  </div><div class='input'>
@@ -224,11 +221,8 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-      
       <li><a href=""#details"">Details</a></li>
-
       <li><a href=""#references"">References</a></li>
-      
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -242,7 +236,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/interpret_gfi.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""Interpretation of indices of fit â interpret_gfi"" />
 
+<meta property=""og:title"" content=""Interpretation of indices of fit â interpret_gfi"" />
 <meta property=""og:description"" content=""Interpretation of indices of fit found in confirmatory analysis or structural equation modelling, such as RMSEA, CFI, NFI, IFI, etc."" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,9 +155,7 @@ <h1>Interpretation of indices of fit</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>Interpretation of indices of fit found in confirmatory analysis or structural equation modelling, such as RMSEA, CFI, NFI, IFI, etc.</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>interpret_gfi</span>(<span class='no'>x</span>, <span class='kw'>rules</span> <span class='kw'>=</span> <span class='st'>""default""</span>)
@@ -178,7 +177,7 @@ <h1>Interpretation of indices of fit</h1>
 <span class='fu'>interpret_ifi</span>(<span class='no'>x</span>, <span class='kw'>rules</span> <span class='kw'>=</span> <span class='st'>""default""</span>)
 
 <span class='fu'>interpret_pnfi</span>(<span class='no'>x</span>, <span class='kw'>rules</span> <span class='kw'>=</span> <span class='st'>""default""</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -191,7 +190,7 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <td><p>Can be ""default"" or custom set of rules.</p></td>
     </tr>
     </table>
-    
+
     <h2 class=""hasAnchor"" id=""details""><a class=""anchor"" href=""#details""></a>Details</h2>
 
     
@@ -213,7 +212,6 @@ <h3>Indices of fit</h3>
 <h3>What to report</h3>
 <p>For structural equation models (SEM), Kline (2015) suggests that at a minimum the following indices should be reported: The model <strong>chi-square</strong>, the <strong>RMSEA</strong>, the <strong>CFI</strong> and the <strong>SRMR</strong>.</p>
 
-    
     <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>References</h2>
 
     
@@ -225,7 +223,6 @@ <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>R
 <li><p>Kline, R. B. (2015). Principles and practice of structural equation modeling. Guilford publications.</p></li>
 </ul>
 
-    
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='fu'>interpret_gfi</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>.5</span>, <span class='fl'>.99</span>))</div><div class='output co'>#&gt; [1] ""poor""         ""satisfactory""</div><div class='input'><span class='fu'>interpret_agfi</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>.5</span>, <span class='fl'>.99</span>))</div><div class='output co'>#&gt; [1] ""poor""         ""satisfactory""</div><div class='input'><span class='fu'>interpret_nfi</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>.5</span>, <span class='fl'>.99</span>))</div><div class='output co'>#&gt; [1] ""poor""         ""satisfactory""</div><div class='input'><span class='fu'>interpret_nnfi</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>.5</span>, <span class='fl'>.99</span>))</div><div class='output co'>#&gt; [1] ""poor""         ""satisfactory""</div><div class='input'><span class='fu'>interpret_cfi</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>.5</span>, <span class='fl'>.99</span>))</div><div class='output co'>#&gt; [1] ""poor""         ""satisfactory""</div><div class='input'><span class='fu'>interpret_rmsea</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>.5</span>, <span class='fl'>.99</span>))</div><div class='output co'>#&gt; [1] ""poor"" ""poor""</div><div class='input'><span class='fu'>interpret_srmr</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>.5</span>, <span class='fl'>.99</span>))</div><div class='output co'>#&gt; [1] ""poor"" ""poor""</div><div class='input'><span class='fu'>interpret_rfi</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>.5</span>, <span class='fl'>.99</span>))</div><div class='output co'>#&gt; [1] ""poor""         ""satisfactory""</div><div class='input'><span class='fu'>interpret_ifi</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>.5</span>, <span class='fl'>.99</span>))</div><div class='output co'>#&gt; [1] ""poor""         ""satisfactory""</div><div class='input'><span class='fu'>interpret_pnfi</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>.5</span>, <span class='fl'>.99</span>))</div><div class='output co'>#&gt; [1] ""satisfactory"" ""satisfactory""</div></pre>
@@ -234,11 +231,8 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-      
       <li><a href=""#details"">Details</a></li>
-
       <li><a href=""#references"">References</a></li>
-      
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -252,7 +246,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/interpret_odds.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""(Log) Odds ratio interpretation â interpret_odds"" />
 
+<meta property=""og:title"" content=""(Log) Odds ratio interpretation â interpret_odds"" />
 <meta property=""og:description"" content=""(Log) Odds ratio interpretation"" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,13 +155,11 @@ <h1>(Log) Odds ratio interpretation</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>(Log) Odds ratio interpretation</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>interpret_odds</span>(<span class='no'>odds</span>, <span class='kw'>rules</span> <span class='kw'>=</span> <span class='st'>""chen2010""</span>, <span class='kw'>log</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -177,7 +176,7 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <td><p>Are the provided values log odds ratio.</p></td>
     </tr>
     </table>
-    
+
     <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>References</h2>
 
     
@@ -187,7 +186,6 @@ <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>R
 <li><p>SÃ¡nchez-Meca, J., MarÃ­n-MartÃ­nez, F., &amp; ChacÃ³n-Moscoso, S. (2003). Effect-size indices for dichotomized outcomes in meta-analysis. Psychological methods, 8(4), 448.</p></li>
 </ul>
 
-    
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='fu'>interpret_odds</span>(<span class='fl'>1</span>)</div><div class='output co'>#&gt; [1] ""very small""</div><div class='input'><span class='fu'>interpret_odds</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>5</span>, <span class='fl'>2</span>))</div><div class='output co'>#&gt; [1] ""medium"" ""small"" </div></pre>
@@ -196,9 +194,7 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-      
       <li><a href=""#references"">References</a></li>
-      
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -212,7 +208,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/interpret_omega_squared.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""ANOVA effect size interpretation â interpret_omega_squared"" />
 
+<meta property=""og:title"" content=""ANOVA effect size interpretation â interpret_omega_squared"" />
 <meta property=""og:description"" content=""ANOVA effect size interpretation"" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,13 +155,11 @@ <h1>ANOVA effect size interpretation</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>ANOVA effect size interpretation</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>interpret_omega_squared</span>(<span class='no'>omega_squared</span>, <span class='kw'>rules</span> <span class='kw'>=</span> <span class='st'>""field2013""</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -173,19 +172,17 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <td><p>Can be ""field2013"" (default) or custom set of rules.</p></td>
     </tr>
     </table>
-    
+
     <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>References</h2>
 
     
 <ul>
 <li><p>Field, A (2013) Discovering statistics using IBM SPSS Statistics. Fourth Edition. Sage:London.</p></li>
 </ul>
 
-    
     <h2 class=""hasAnchor"" id=""see-also""><a class=""anchor"" href=""#see-also""></a>See also</h2>
 
     <div class='dont-index'><p>http://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/effectSize</p></div>
-    
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='fu'>interpret_omega_squared</span>(<span class='fl'>.02</span>)</div><div class='output co'>#&gt; [1] ""small""</div><div class='input'><span class='fu'>interpret_omega_squared</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>.5</span>, <span class='fl'>.02</span>))</div><div class='output co'>#&gt; [1] ""large"" ""small""</div></pre>
@@ -194,11 +191,8 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-      
       <li><a href=""#references"">References</a></li>
-
       <li><a href=""#see-also"">See also</a></li>
-      
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -212,7 +206,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/interpret_p.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""p-values interpretation â interpret_p"" />
 
+<meta property=""og:title"" content=""p-values interpretation â interpret_p"" />
 <meta property=""og:description"" content=""p-values interpretation"" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,13 +155,11 @@ <h1>p-values interpretation</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>p-values interpretation</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>interpret_p</span>(<span class='no'>p</span>, <span class='kw'>rules</span> <span class='kw'>=</span> <span class='st'>""default""</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -173,7 +172,7 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <td><p>Can be ""default"" or custom set of rules.</p></td>
     </tr>
     </table>
-    
+
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='fu'>interpret_p</span>(<span class='fl'>.02</span>)</div><div class='output co'>#&gt; [1] ""significant""</div><div class='input'><span class='fu'>interpret_p</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>.5</span>, <span class='fl'>.02</span>))</div><div class='output co'>#&gt; [1] ""not significant"" ""significant""    </div></pre>
@@ -182,7 +181,6 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-            
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -196,7 +194,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/interpret_parameters.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""Automated Interpretation of Effect Sizes â interpret_parameters"" />
 
+<meta property=""og:title"" content=""Automated Interpretation of Effect Sizes â interpret_parameters"" />
 <meta property=""og:description"" content=""Automated interpretation of effect sizes."" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,9 +155,7 @@ <h1>Automated Interpretation of Effect Sizes</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>Automated interpretation of effect sizes.</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>interpret_parameters</span>(<span class='no'>model</span>, <span class='no'>...</span>)
@@ -165,7 +164,7 @@ <h1>Automated Interpretation of Effect Sizes</h1>
 <span class='fu'>interpret_parameters</span>(<span class='no'>model</span>, <span class='kw'>interpretation</span> <span class='kw'>=</span> <span class='st'>""funder2019""</span>,
   <span class='kw'>parameters</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>standardize_method</span> <span class='kw'>=</span> <span class='st'>""refit""</span>,
   <span class='kw'>standardize_robust</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='no'>...</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -194,23 +193,15 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <td><p>See <code><a href='standardize_parameters.html'>standardize_parameters</a></code>.</p></td>
     </tr>
     </table>
-    
+
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
-    <pre class=""examples""><div class='input'><span class='no'>model</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/lm.html'>lm</a></span>(<span class='no'>Sepal.Length</span> ~ <span class='no'>Species</span> * <span class='no'>Petal.Width</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>iris</span>)
-<span class='fu'>interpret_parameters</span>(<span class='no'>model</span>)</div><div class='output co'>#&gt;                       Parameter Effect_Size Interpretation
-#&gt; 1                   (Intercept)          NA     very large
-#&gt; 2             Speciesversicolor -0.08270276     very small
-#&gt; 3              Speciesvirginica  0.09450438     very small
-#&gt; 4                   Petal.Width  0.85622714     very large
-#&gt; 5 Speciesversicolor:Petal.Width  0.22264112         medium
-#&gt; 6  Speciesvirginica:Petal.Width -0.12751810          small</div></pre>
+    <pre class=""examples""><div class='input'><span class='no'>model</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/lm.html'>lm</a></span>(<span class='no'>Sepal.Length</span> ~ <span class='no'>Species</span> * <span class='no'>Petal.Width</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>iris</span>)</div></pre>
   </div>
   <div class=""col-md-3 hidden-xs hidden-sm"" id=""sidebar"">
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-            
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -224,7 +215,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/interpret_r.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""Correlation interpretation â interpret_r"" />
 
+<meta property=""og:title"" content=""Correlation interpretation â interpret_r"" />
 <meta property=""og:description"" content=""Correlation interpretation"" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,13 +155,11 @@ <h1>Correlation interpretation</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>Correlation interpretation</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>interpret_r</span>(<span class='no'>r</span>, <span class='kw'>rules</span> <span class='kw'>=</span> <span class='st'>""funder2019""</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -173,7 +172,7 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <td><p>Can be ""funder2019"" (default), ""gignac2016"", cohen1988"", ""evans1996"" or custom set of rules.</p></td>
     </tr>
     </table>
-    
+
     <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>References</h2>
 
     
@@ -184,11 +183,9 @@ <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>R
 <li><p>Evans, J. D. (1996). Straightforward statistics for the behavioral sciences. Thomson Brooks/Cole Publishing Co.</p></li>
 </ul>
 
-    
     <h2 class=""hasAnchor"" id=""see-also""><a class=""anchor"" href=""#see-also""></a>See also</h2>
 
     <div class='dont-index'><p>Page 88 of APA's 6th Edition.</p></div>
-    
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='fu'>interpret_r</span>(<span class='kw'>r</span> <span class='kw'>=</span> <span class='fl'>.015</span>)</div><div class='output co'>#&gt; [1] ""tiny""</div><div class='input'><span class='fu'>interpret_r</span>(<span class='kw'>r</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>.5</span>, -<span class='fl'>.02</span>))</div><div class='output co'>#&gt; [1] ""very large"" ""tiny""      </div></pre>
@@ -197,11 +194,8 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-      
       <li><a href=""#references"">References</a></li>
-
       <li><a href=""#see-also"">See also</a></li>
-      
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -215,7 +209,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/interpret_r2.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""Coefficient of determination  (R2) interpretation â interpret_r2"" />
 
+<meta property=""og:title"" content=""Coefficient of determination  (R2) interpretation â interpret_r2"" />
 <meta property=""og:description"" content=""Coefficient of determination  (R2) interpretation"" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,13 +155,11 @@ <h1>Coefficient of determination  (R2) interpretation</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>Coefficient of determination  (R2) interpretation</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>interpret_r2</span>(<span class='no'>r2</span>, <span class='kw'>rules</span> <span class='kw'>=</span> <span class='st'>""cohen1988""</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -173,7 +172,7 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <td><p>Can be ""cohen1988"" (default), ""falk1992"", ""chin1998"", ""hair2011"" or custom set of rules.</p></td>
     </tr>
     </table>
-    
+
     <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>References</h2>
 
     
@@ -184,7 +183,6 @@ <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>R
 <li><p>Hair, J. F., Ringle, C. M., &amp; Sarstedt, M. (2011). PLS-SEM: Indeed a silver bullet. Journal of Marketing theory and Practice, 19(2), 139-152.</p></li>
 </ul>
 
-    
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='fu'>interpret_r2</span>(<span class='fl'>.02</span>)</div><div class='output co'>#&gt; [1] ""weak""</div><div class='input'><span class='fu'>interpret_r2</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>.5</span>, <span class='fl'>.02</span>))</div><div class='output co'>#&gt; [1] ""substantial"" ""weak""       </div></pre>
@@ -193,9 +191,7 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-      
       <li><a href=""#references"">References</a></li>
-      
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -209,7 +205,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/normalize.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""Normalization â normalize"" />
 
+<meta property=""og:title"" content=""Normalization â normalize"" />
 <meta property=""og:description"" content=""Performs a normalization of data, i.e., it scales all numeric variables in the range 0 - 1. This is a special case of change_scale."" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,9 +155,7 @@ <h1>Normalization</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>Performs a normalization of data, i.e., it scales all numeric variables in the range 0 - 1. This is a special case of <code><a href='change_scale.html'>change_scale</a></code>.</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>normalize</span>(<span class='no'>x</span>, <span class='no'>...</span>)
@@ -172,7 +171,7 @@ <h1>Normalization</h1>
 <span class='co'># S3 method for data.frame</span>
 <span class='fu'>normalize</span>(<span class='no'>x</span>, <span class='kw'>select</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>exclude</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
   <span class='kw'>include_bounds</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='no'>...</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -209,19 +208,16 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
 be excluded from standardization.</p></td>
     </tr>
     </table>
-    
+
     <h2 class=""hasAnchor"" id=""value""><a class=""anchor"" href=""#value""></a>Value</h2>
 
     <p>A normalized object.</p>
-    
     <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>References</h2>
 
     <p>Smithson M, Verkuilen J (2006). A Better Lemon Squeezer? Maximum-Likelihood Regression with Beta-Distributed Dependent Variables. Psychological Methods, 11(1), 54â71.</p>
-    
     <h2 class=""hasAnchor"" id=""see-also""><a class=""anchor"" href=""#see-also""></a>See also</h2>
 
     <div class='dont-index'><p><code><a href='ranktransform.html'>ranktransform</a></code> <code><a href='standardize.html'>standardize</a></code> <code><a href='change_scale.html'>change_scale</a></code></p></div>
-    
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='fu'>normalize</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>0</span>, <span class='fl'>1</span>, <span class='fl'>5</span>, -<span class='fl'>5</span>, -<span class='fl'>2</span>))</div><div class='output co'>#&gt; [1] 0.5 0.6 1.0 0.0 0.3</div><div class='input'><span class='fu'>normalize</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>0</span>, <span class='fl'>1</span>, <span class='fl'>5</span>, -<span class='fl'>5</span>, -<span class='fl'>2</span>), <span class='kw'>include_bounds</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)</div><div class='output co'>#&gt; [1] 0.50 0.58 0.90 0.10 0.34</div><div class='input'>
@@ -237,13 +233,9 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-      
       <li><a href=""#value"">Value</a></li>
-
       <li><a href=""#references"">References</a></li>
-
       <li><a href=""#see-also"">See also</a></li>
-      
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -257,7 +249,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/ranktransform.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""(Signed) rank transformation â ranktransform"" />
 
+<meta property=""og:title"" content=""(Signed) rank transformation â ranktransform"" />
 <meta property=""og:description"" content=""Transform numeric values with the integers of their rank (i.e., 1st smallest, 2nd smallest, 3rd smallest, etc.). Setting the sign argument to TRUE will give you signed ranks, where the ranking is done according to absolute size but where the sign is presereved (i.e., 2, 1, -3, 4)."" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,9 +155,7 @@ <h1>(Signed) rank transformation</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>Transform numeric values with the integers of their rank (i.e., 1st smallest, 2nd smallest, 3rd smallest, etc.). Setting the <code>sign</code> argument to <code>TRUE</code> will give you signed ranks, where the ranking is done according to absolute size but where the sign is presereved (i.e., 2, 1, -3, 4).</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>ranktransform</span>(<span class='no'>x</span>, <span class='no'>...</span>)
@@ -172,7 +171,7 @@ <h1>(Signed) rank transformation</h1>
 <span class='co'># S3 method for data.frame</span>
 <span class='fu'>ranktransform</span>(<span class='no'>x</span>, <span class='kw'>select</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>exclude</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
   <span class='kw'>sign</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>method</span> <span class='kw'>=</span> <span class='st'>""average""</span>, <span class='no'>...</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -208,15 +207,13 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
 be excluded from standardization.</p></td>
     </tr>
     </table>
-    
+
     <h2 class=""hasAnchor"" id=""value""><a class=""anchor"" href=""#value""></a>Value</h2>
 
     <p>A rank-transformed object.</p>
-    
     <h2 class=""hasAnchor"" id=""see-also""><a class=""anchor"" href=""#see-also""></a>See also</h2>
 
     <div class='dont-index'><p><code><a href='normalize.html'>normalize</a></code> <code><a href='standardize.html'>standardize</a></code> <code><a href='change_scale.html'>change_scale</a></code></p></div>
-    
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='fu'>ranktransform</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>0</span>, <span class='fl'>1</span>, <span class='fl'>5</span>, -<span class='fl'>5</span>, -<span class='fl'>2</span>))</div><div class='output co'>#&gt; [1] 3 4 5 1 2</div><div class='input'><span class='fu'>ranktransform</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>0</span>, <span class='fl'>1</span>, <span class='fl'>5</span>, -<span class='fl'>5</span>, -<span class='fl'>2</span>), <span class='kw'>sign</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>)</div><div class='output co'>#&gt; [1]  0  4  5 -1 -2</div><div class='input'>
@@ -232,11 +229,8 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-      
       <li><a href=""#value"">Value</a></li>
-
       <li><a href=""#see-also"">See also</a></li>
-      
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -250,7 +244,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/rules.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""Interpretation Grid â rules"" />
 
+<meta property=""og:title"" content=""Interpretation Grid â rules"" />
 <meta property=""og:description"" content=""Create a container for interpretation rules of thumb. See interpret."" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,15 +155,13 @@ <h1>Interpretation Grid</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>Create a container for interpretation rules of thumb. See <a href='interpret.html'>interpret</a>.</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>rules</span>(<span class='no'>breakpoints</span>, <span class='no'>labels</span>, <span class='kw'>if_lower</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>)
 
 <span class='fu'>is.rules</span>(<span class='no'>x</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -183,7 +182,7 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <td><p>An arbitrary R object.</p></td>
     </tr>
     </table>
-    
+
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='fu'>rules</span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>0.05</span>), <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='st'>""significant""</span>, <span class='st'>""not significant""</span>), <span class='kw'>if_lower</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>)</div><div class='output co'>#&gt; $breakpoints
@@ -202,7 +201,6 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-            
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -216,7 +214,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/sd_pooled.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""Pooled Standard Deviation â sd_pooled"" />
 
+<meta property=""og:title"" content=""Pooled Standard Deviation â sd_pooled"" />
 <meta property=""og:description"" content=""The Pooled Standard Deviation is a weighted average of standard deviations for two or more groups, with more &quot;weight&quot; given to larger sample sizes."" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,15 +155,13 @@ <h1>Pooled Standard Deviation</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>The Pooled Standard Deviation is a weighted average of standard deviations for two or more groups, with more ""weight"" given to larger sample sizes.</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>sd_pooled</span>(<span class='no'>x</span>, <span class='kw'>y</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='kw'>NULL</span>)
 
 <span class='fu'>mad_pooled</span>(<span class='no'>x</span>, <span class='kw'>y</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='kw'>NULL</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -179,14 +178,14 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <td><p>An optional data frame containing the variables.</p></td>
     </tr>
     </table>
-    
+
 
   </div>
   <div class=""col-md-3 hidden-xs hidden-sm"" id=""sidebar"">
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-                </ul>
+    </ul>
 
   </div>
 </div>
@@ -198,7 +197,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/standardize.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""Standardization (Z-scoring) â standardize"" />
 
+<meta property=""og:title"" content=""Standardization (Z-scoring) â standardize"" />
 <meta property=""og:description"" content=""Performs a standardization of data (Z-scoring), i.e., centred and scaled, so that the data is expressed in terms of standard deviation (i.e., mean = 0, SD = 1) or Median Absolute Deviance (median = 0, MAD = 1). When applied to a statistical model, this function extracts the dataset, standardizes it, and refits the model with this standardized version of the dataset. The normalize function can also be used to scale all numeric variables within the 0 - 1 range."" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,9 +155,7 @@ <h1>Standardization (Z-scoring)</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>Performs a standardization of data (Z-scoring), i.e., centred and scaled, so that the data is expressed in terms of standard deviation (i.e., mean = 0, SD = 1) or Median Absolute Deviance (median = 0, MAD = 1). When applied to a statistical model, this function extracts the dataset, standardizes it, and refits the model with this standardized version of the dataset. The <code><a href='normalize.html'>normalize</a></code> function can also be used to scale all numeric variables within the 0 - 1 range.</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>standardize</span>(<span class='no'>x</span>, <span class='no'>...</span>)
@@ -176,7 +175,7 @@ <h1>Standardization (Z-scoring)</h1>
 <span class='co'># S3 method for lm</span>
 <span class='fu'>standardize</span>(<span class='no'>x</span>, <span class='kw'>robust</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>two_sd</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
   <span class='kw'>include_response</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='kw'>verbose</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='no'>...</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -229,15 +228,13 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
 response value will never be standardized, to make re-fitting the model work.</p></td>
     </tr>
     </table>
-    
+
     <h2 class=""hasAnchor"" id=""value""><a class=""anchor"" href=""#value""></a>Value</h2>
 
     <p>The standardized object (either a standardize dataframe or a statistical model fitted on standardized data).</p>
-    
     <h2 class=""hasAnchor"" id=""see-also""><a class=""anchor"" href=""#see-also""></a>See also</h2>
 
     <div class='dont-index'><p><code><a href='normalize.html'>normalize</a></code> <code><a href='standardize_parameters.html'>standardize_parameters</a></code></p></div>
-    
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='co'># Dataframes</span>
@@ -268,11 +265,8 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-      
       <li><a href=""#value"">Value</a></li>
-
       <li><a href=""#see-also"">See also</a></li>
-      
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -286,7 +280,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/standardize_info.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,15 +41,15 @@
 
 
 
-<meta property=""og:title"" content=""Get Standardization Information â standardize_info"" />
 
+<meta property=""og:title"" content=""Get Standardization Information â standardize_info"" />
 <meta property=""og:description"" content=""This function extracts information, such as the deviations (SD or MAD) from parent variables, that are necessary for post-hoc standardization of parameters. This function gives a window on how standardized are obtained, i.e., by what they are devided. The &quot;basic&quot; method of standardization uses"" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -127,7 +129,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -154,13 +155,11 @@ <h1>Get Standardization Information</h1>
     </div>
 
     <div class=""ref-description"">
-    
     <p>This function extracts information, such as the deviations (SD or MAD) from parent variables, that are necessary for post-hoc standardization of parameters. This function gives a window on how standardized are obtained, i.e., by what they are devided. The ""basic"" method of standardization uses</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>standardize_info</span>(<span class='no'>model</span>, <span class='kw'>robust</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='no'>...</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -180,37 +179,15 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <td><p>Arguments passed to or from other methods.</p></td>
     </tr>
     </table>
-    
+
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
-    <pre class=""examples""><div class='input'><span class='no'>model</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/lm.html'>lm</a></span>(<span class='no'>Sepal.Width</span> ~ <span class='no'>Sepal.Length</span> * <span class='no'>Species</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>iris</span>)
-<span class='fu'>standardize_info</span>(<span class='no'>model</span>)</div><div class='output co'>#&gt;                        Parameter        Type        Link Secondary_Parameter
-#&gt; 1                    (Intercept)   intercept        Mean                &lt;NA&gt;
-#&gt; 2                   Sepal.Length     numeric Association                &lt;NA&gt;
-#&gt; 3              Speciesversicolor      factor  Difference                &lt;NA&gt;
-#&gt; 4               Speciesvirginica      factor  Difference                &lt;NA&gt;
-#&gt; 5 Sepal.Length:Speciesversicolor interaction  Difference        Sepal.Length
-#&gt; 6  Sepal.Length:Speciesvirginica interaction  Difference        Sepal.Length
-#&gt;   EffectSize_Type Deviation_Response_Basic Deviation_Response_Smart
-#&gt; 1            &lt;NA&gt;                0.4358663                0.4358663
-#&gt; 2               r                0.4358663                0.4358663
-#&gt; 3               d                0.4358663                0.3790644
-#&gt; 4               d                0.4358663                0.3790644
-#&gt; 5     interaction                0.4358663                0.3790644
-#&gt; 6     interaction                0.4358663                0.3790644
-#&gt;   Deviation_Basic Deviation_Smart
-#&gt; 1       0.0000000       0.0000000
-#&gt; 2       0.8280661       0.8280661
-#&gt; 3       0.4729838       1.0000000
-#&gt; 4       0.4729838       1.0000000
-#&gt; 5       2.8231922       1.0000000
-#&gt; 6       3.1372813       1.0000000</div></pre>
+    <pre class=""examples""><div class='input'><span class='no'>model</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/lm.html'>lm</a></span>(<span class='no'>Sepal.Width</span> ~ <span class='no'>Sepal.Length</span> * <span class='no'>Species</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>iris</span>)</div></pre>
   </div>
   <div class=""col-md-3 hidden-xs hidden-sm"" id=""sidebar"">
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-            
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -224,7 +201,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: docs/reference/t_to_r.html---
@@ -15,11 +15,13 @@
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""120x120"" href=""../apple-touch-icon-120x120.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""76x76"" href=""../apple-touch-icon-76x76.png"" />
 <link rel=""apple-touch-icon"" type=""image/png"" sizes=""60x60"" href=""../apple-touch-icon-60x60.png"" />
+
 <!-- jquery -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"" integrity=""sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="" crossorigin=""anonymous""></script>
 <!-- Bootstrap -->
 <link href=""https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css"" rel=""stylesheet"" crossorigin=""anonymous"" />
 
+
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"" integrity=""sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8="" crossorigin=""anonymous""></script>
 
 <!-- Font Awesome icons -->
@@ -39,17 +41,17 @@
 
 
 
-<meta property=""og:title"" content=""Convert test statistics (t, z, F) to effect sizes of differences (Cohen's d) or association (partial r). â t_to_r"" />
 
+<meta property=""og:title"" content=""Convert test statistics (t, z, F) to effect sizes of differences (Cohen's d) or association (partial r). â t_to_r"" />
 <meta property=""og:description"" content=""These functions are convenience functions to convert t, z and F test statistics to Cohen's d and
 (partial) r. These are useful in cases where the data required to compute these are not easily
 available or their computation is not straightforward (e.g., in liner mixed models, contrasts, etc.)."" />
-
 <meta property=""og:image"" content=""/logo.png"" />
 <meta name=""twitter:card"" content=""summary"" />
 
 
 
+
 <!-- mathjax -->
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"" integrity=""sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k="" crossorigin=""anonymous""></script>
 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js"" integrity=""sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA="" crossorigin=""anonymous""></script>
@@ -129,7 +131,6 @@
   <a href=""../articles/interpret.html"">Interpretation Guidelines</a>
 </li>
       </ul>
-      
       <ul class=""nav navbar-nav navbar-right"">
         <li>
   <a href=""https://github.com/easystats/effectsize"">
@@ -156,11 +157,9 @@ <h1>Convert test statistics (t, z, F) to effect sizes of differences (Cohen's d)
     </div>
 
     <div class=""ref-description"">
-    
     <p>These functions are convenience functions to convert t, z and F test statistics to Cohen's d and
 (partial) r. These are useful in cases where the data required to compute these are not easily
 available or their computation is not straightforward (e.g., in liner mixed models, contrasts, etc.).</p>
-    
     </div>
 
     <pre class=""usage""><span class='fu'>t_to_r</span>(<span class='no'>t</span>, <span class='no'>df_error</span>, <span class='no'>...</span>)
@@ -186,7 +185,7 @@ <h1>Convert test statistics (t, z, F) to effect sizes of differences (Cohen's d)
 <span class='fu'>F_to_d</span>(<span class='no'>f</span>, <span class='no'>df</span>, <span class='no'>df_error</span>, <span class='kw'>pooled</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='no'>...</span>)
 
 <span class='fu'>convert_F_to_d</span>(<span class='no'>f</span>, <span class='no'>df</span>, <span class='no'>df_error</span>, <span class='kw'>pooled</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='no'>...</span>)</pre>
-    
+
     <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arguments</h2>
     <table class=""ref-arguments"">
     <colgroup><col class=""name"" /><col class=""desc"" /></colgroup>
@@ -211,11 +210,10 @@ <h2 class=""hasAnchor"" id=""arguments""><a class=""anchor"" href=""#arguments""></a>Arg
       <td><p>Degrees of freedom of numerator or of the error estimate (i.e., the residuals).</p></td>
     </tr>
     </table>
-    
+
     <h2 class=""hasAnchor"" id=""value""><a class=""anchor"" href=""#value""></a>Value</h2>
 
     <p>A numeric integer between of the requested effect size.</p>
-    
     <h2 class=""hasAnchor"" id=""details""><a class=""anchor"" href=""#details""></a>Details</h2>
 
     <p>These functions use the following formulae:
@@ -229,7 +227,6 @@ <h2 class=""hasAnchor"" id=""details""><a class=""anchor"" href=""#details""></a>Details
 $$Cohen's d_z = t / \sqrt{df_{error}}$$
 <br /><br />
 $$Cohen's d = 2 * z / \sqrt{N}$$</p>
-    
     <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>References</h2>
 
     
@@ -239,7 +236,6 @@ <h2 class=""hasAnchor"" id=""references""><a class=""anchor"" href=""#references""></a>R
 <li><p>Rosenthal, R. (1991). Meta-analytic procedures for social research. Newbury Park, CA: SAGE Publications, Incorporated.</p></li>
 </ul>
 
-    
 
     <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examples</h2>
     <pre class=""examples""><div class='input'><span class='kw'>if</span> (<span class='fl'>FALSE</span>) {
@@ -276,13 +272,9 @@ <h2 class=""hasAnchor"" id=""examples""><a class=""anchor"" href=""#examples""></a>Examp
     <h2>Contents</h2>
     <ul class=""nav nav-pills nav-stacked"">
       <li><a href=""#arguments"">Arguments</a></li>
-      
       <li><a href=""#value"">Value</a></li>
-
       <li><a href=""#details"">Details</a></li>
-
       <li><a href=""#references"">References</a></li>
-      
       <li><a href=""#examples"">Examples</a></li>
     </ul>
 
@@ -296,7 +288,7 @@ <h2>Contents</h2>
 </div>
 
 <div class=""pkgdown"">
-  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.0.</p>
+  <p>Site built with <a href=""https://pkgdown.r-lib.org/"">pkgdown</a> 1.4.1.</p>
 </div>
 
       </footer>

---FILE: vignettes/interpret.Rmd---
@@ -295,7 +295,7 @@ Experts have suggested thresholds value to help interpreting and convergence and
 ### Other Bayesian Indices (\% in ROPE, *pd*)
 
 
-The interpretation of Bayesian indices is detailed in [this article](https://easystats.github.io/bayestestR/articles/4_Guidelines.html).
+The interpretation of Bayesian indices is detailed in [this article](https://easystats.github.io/bayestestR/articles/guidelines.html).
 
 
 

---FILE: vignettes/standardize_parameters.Rmd---
@@ -30,7 +30,7 @@ set.seed(333)
 
 # Introduction
 
-Standardising parameters (*i.e.*, coefficients) can allow for their comparison within and between models, variables and studies. Moreover, as it returns coefficients expressed in terms of **change of variance** (for instance, coefficients expresed in terms of SD of the response variable), it can allow for the usage of [effect size interpretation guidelines](https://easystats.github.io/easystats/articles/interpret.html), such as the famous Cohen's (1988) rules of thumb.
+Standardising parameters (*i.e.*, coefficients) can allow for their comparison within and between models, variables and studies. Moreover, as it returns coefficients expressed in terms of **change of variance** (for instance, coefficients expresed in terms of SD of the response variable), it can allow for the usage of [effect size interpretation guidelines](https://easystats.github.io/effectsize/articles/interpret.html), such as the famous Cohen's (1988) rules of thumb.
 
 However, standardizing the model's parameters should *not* be automatically and mindlessly done: for some research fields, particular variables or types of studies (*e.g.*, replications), it sometimes makes more sense to keep, use and interpret the original parameters, especially if they are well known or easily understood.
 
@@ -142,7 +142,7 @@ lm(Sepal.Length ~ Species, data = data) %>%
   knitr::kable(digits = 2)
 ```
 
-Not really. Why? Because the actual formula to compute a **Cohen's *d*** doesn't use the simple SD to scale the effect (as it is done when standardizing the parameters), but computes something called the [**pooled SD**](https://easystats.github.io/effectsize/reference/pooled_sd.html). However, this can be turned off by setting `correct = ""raw""`.
+Not really. Why? Because the actual formula to compute a **Cohen's *d*** doesn't use the simple SD to scale the effect (as it is done when standardizing the parameters), but computes something called the [**pooled SD**](https://easystats.github.io/effectsize/reference/sd_pooled.html). However, this can be turned off by setting `correct = ""raw""`.
 
 ```{r, warning=FALSE, message=FALSE}
 cohens_d(Sepal.Length ~ Species, data = data, pooled_sd = FALSE) ",False,True,Rendering / Conversion,6
easystats,effectsize,efc8016d2ae9e5b32f4a5b2ab7c0d9c00bd8b914,Dominique Makowski,dom.mak19@gmail.com,2019-10-12T16:01:12Z,Dominique Makowski,dom.mak19@gmail.com,2019-10-12T16:01:12Z,minor fixes in docs (for travis),R/convert_chisq.R;R/convert_eta_sq.R;R/convert_t_to_r.R;R/eta_squared.R;R/utils_values_aov.R;man/F_to_partial_eta_squared.Rd;man/chisq_to_phi.Rd,False,True,True,False,52,28,80,"---FILE: R/convert_chisq.R---
@@ -1,9 +1,9 @@
 #' Conversion between Effect sizes for Contingency Tables (Chi2, Phi, Cramer's V...)
 #'
-#' Convert between \eqn{chi^2}, \eqn{\phi} and \eqn{\Cramer's V}.
+#' Convert between Chi square, (\eqn{chi^2}), phi (\eqn{\phi}) and Cramer's V.
 #'
-#' @param chisq The \eqn{chi^2} statistic.
-#' @param phi The \eqn{phi} statistic.
+#' @param chisq The Chi2 statistic.
+#' @param phi The Phi statistic.
 #' @param n Sample size.
 #' @param nrow The number of rows in the contingency table.
 #' @param ncol The number of columns in the contingency tables.

---FILE: R/convert_eta_sq.R---
@@ -1,16 +1,8 @@
 #' Convert test statistics (F, t) to indices of variance explained (partial Eta / Omega / Epsilon squared)
 #'
-#' These functions are convenience functions to convert \eqn{F} and \eqn{t}
-#' test statistics to \eqn{\eta_p^2}, \eqn{\omega_p^2}, \eqn{\epsilon_p^2}, or
-#' \eqn{Adj. \eta_p^2}. These are useful in cases where the various \eqn{SS}s and
-#' \eqn{MS}s are not easily available or their computation is not straightforward
-#' (e.g., in liner mixed models, contrasts, etc.).
-#' \cr\cr
-#' For test statistics derived from \code{lm} and \code{aov} models, these functions
-#' give exact results. For all other cases, these give practically exact results.
+#' These functions are convenience functions to convert F and t test statistics to partial Eta squared, (\eqn{\eta{_p}^2}), Omega squared (\eqn{\omega{_p}^2}) and Epsilon squared (\eqn{\epsilon{_p}^2}; an alias for the adjusted Eta squared). These are useful in cases where the various Sum of Squares and Mean Squares are not easily available or their computation is not straightforward (e.g., in liner mixed models, contrasts, etc.). For test statistics derived from \code{lm} and \code{aov} models, these functions give exact results. For all other cases, they return close approximations.
 #'
-#' @param F_stat The \eqn{F} statistic.
-#' @param t_stat The \eqn{t} statistic.
+#' @param F_stat,t_stat The \eqn{F} or \eqn{t} statistics.
 #' @param df Numerator degrees of freedom for the \eqn{F} statistic.
 #' @param df_error Denominator degrees of freedom for the \eqn{F} and \eqn{t} statistics.
 #'

---FILE: R/convert_t_to_r.R---
@@ -0,0 +1 @@
+# convert_t_to_r <- function()
\ No newline at end of file

---FILE: R/eta_squared.R---
@@ -128,6 +128,10 @@ eta_squared.merMod <- function(model, partial = TRUE, ci = NULL, ...) {
   .eta_square_from_F(par_table, ci = ci)
 }
 
+
+
+
+
 #' @keywords internal
 .eta_squared <- function(model, partial, ci, iterations) {
   params <- as.data.frame(parameters::model_parameters(model))

---FILE: R/utils_values_aov.R---
@@ -0,0 +1,36 @@
+#' @keywords internal
+.values_aov <- function(params) {
+
+  # number of observations
+  if (""Group"" %in% names(params) && (""Within"" %in% params$Group)) {
+    lapply(split(params, params$Group), function(.i) {
+      N <- sum(.i$df) + 1
+      .prepare_values_aov(.i, N)
+    })
+  } else {
+    N <- sum(params$df) + 1
+    .prepare_values_aov(params, N)
+  }
+}
+
+
+#' @keywords internal
+.prepare_values_aov <- function(params, N) {
+  # get mean squared of residuals
+  Mean_Square_residuals <- sum(params[params$Parameter == ""Residuals"", ]$Mean_Square)
+  # get sum of squares of residuals
+  Sum_Squares_residuals <- sum(params[params$Parameter == ""Residuals"", ]$Sum_Squares)
+  # get total sum of squares
+  Sum_Squares_total <- sum(params$Sum_Squares)
+  # number of terms in model
+  N_terms <- nrow(params) - 1
+
+
+  list(
+    ""Mean_Square_residuals"" = Mean_Square_residuals,
+    ""Sum_Squares_residuals"" = Sum_Squares_residuals,
+    ""Sum_Squares_total"" = Sum_Squares_total,
+    ""n_terms"" = N_terms,
+    ""n"" = N
+  )
+}
\ No newline at end of file

---FILE: man/F_to_partial_eta_squared.Rd---
@@ -28,28 +28,19 @@ F_to_partial_omega_squared(F_stat, df, df_error)
 t_to_partial_omega_squared(t_stat, df_error)
 }
 \arguments{
-\item{F_stat}{The \eqn{F} statistic.}
+\item{F_stat, t_stat}{The \eqn{F} or \eqn{t} statistics.}
 
 \item{df}{Numerator degrees of freedom for the \eqn{F} statistic.}
 
 \item{df_error}{Denominator degrees of freedom for the \eqn{F} and \eqn{t} statistics.}
-
-\item{t_stat}{The \eqn{t} statistic.}
 }
 \value{
 A numeric integer between 0-1 (Note that for \eqn{\omega_p^2} and \eqn{\epsilon_p^2}
 it is possible to compute a negative number; even though this doesn't make any practical sense,
 it is recommended to report the negative number and not a 0).
 }
 \description{
-These functions are convenience functions to convert \eqn{F} and \eqn{t}
-test statistics to \eqn{\eta_p^2}, \eqn{\omega_p^2}, \eqn{\epsilon_p^2}, or
-\eqn{Adj. \eta_p^2}. These are useful in cases where the various \eqn{SS}s and
-\eqn{MS}s are not easily available or their computation is not straightforward
-(e.g., in liner mixed models, contrasts, etc.).
-\cr\cr
-For test statistics derived from \code{lm} and \code{aov} models, these functions
-give exact results. For all other cases, these give practically exact results.
+These functions are convenience functions to convert F and t test statistics to partial Eta squared, (\eqn{\eta{_p}^2}), Omega squared (\eqn{\omega{_p}^2}) and Epsilon squared (\eqn{\epsilon{_p}^2}; an alias for the adjusted Eta squared). These are useful in cases where the various Sum of Squares and Mean Squares are not easily available or their computation is not straightforward (e.g., in liner mixed models, contrasts, etc.). For test statistics derived from \code{lm} and \code{aov} models, these functions give exact results. For all other cases, they return close approximations.
 }
 \details{
 These functions use the following formulae:

---FILE: man/chisq_to_phi.Rd---
@@ -1,5 +1,5 @@
 % Generated by roxygen2: do not edit by hand
-% Please edit documentation in R/convert_etasq_to_cramers_v.R
+% Please edit documentation in R/convert_chisq.R
 \name{chisq_to_phi}
 \alias{chisq_to_phi}
 \alias{convert_chisq_to_phi}
@@ -22,11 +22,11 @@ chisq_to_cramers_v(chisq, n, nrow, ncol)
 convert_cchisq_to_cramers_v(chisq, n, nrow, ncol)
 }
 \arguments{
-\item{chisq}{The \eqn{chi^2} statistic.}
+\item{chisq}{The Chi2 statistic.}
 
 \item{n}{Sample size.}
 
-\item{phi}{The \eqn{phi} statistic.}
+\item{phi}{The Phi statistic.}
 
 \item{nrow}{The number of rows in the contingency table.}
 
@@ -36,7 +36,7 @@ convert_cchisq_to_cramers_v(chisq, n, nrow, ncol)
 A numeric integer between 0-1.
 }
 \description{
-Convert between \eqn{chi^2}, \eqn{\phi} and \eqn{\Cramer's V}.
+Convert between Chi square, (\eqn{chi^2}), phi (\eqn{\phi}) and Cramer's V.
 }
 \examples{
 contingency_table <- as.table(rbind(c(762, 327, 468), c(484, 239, 477), c(484, 239, 477)))",True,False,Documentation / Formatting,7
easystats,effectsize,14e17ab2a362977f82d13808193dea3efd458905,mattansb,35330040+mattansb@users.noreply.github.com,2019-10-12T09:45:10Z,mattansb,35330040+mattansb@users.noreply.github.com,2019-10-12T09:45:10Z,"Doc fixed for stat2es

#7",NAMESPACE;R/convert_teststats_to_es.R;man/F_to_partial_eta_squared.Rd;man/chisq_to_phi.Rd,False,True,True,False,47,30,77,"---FILE: NAMESPACE---
@@ -96,6 +96,7 @@ export(.sd_pooled)
 export(F_to_adj_partial_eta_squared)
 export(F_to_partial_epsilon_squared)
 export(F_to_partial_eta_squared)
+export(F_to_partial_omega_squared)
 export(chisq_to_cramers_V)
 export(chisq_to_phi)
 export(cohens_d)
@@ -161,6 +162,7 @@ export(standardize)
 export(standardize_info)
 export(standardize_parameters)
 export(standardize_posteriors)
+export(t_to_adj_partial_eta_squared)
 export(t_to_partial_epsilon_squared)
 export(t_to_partial_eta_squared)
 export(t_to_partial_omega_squared)

---FILE: R/convert_teststats_to_es.R---
@@ -1,10 +1,10 @@
 #' Compute Partial Variance Explained Effect Sizes From Test Statistics
 #'
-#' These functions are conviniance functions to convert \eqn{F} and \eqn{t}
+#' These functions are convenience functions to convert \eqn{F} and \eqn{t}
 #' test statistics to \eqn{\eta_p^2}, \eqn{\omega_p^2}, \eqn{\epsilon_p^2}, or
-#' \eqn{Adj. \eta_p^2}. These are useful in cases where the \eqn{SS}s and
-#' \eqn{MS}s are not easily availbe or their computation is not streight
-#' forward (e.g., in liner mixed models, contrasts, etc.).
+#' \eqn{Adj. \eta_p^2}. These are useful in cases where the various \eqn{SS}s and
+#' \eqn{MS}s are not easily available or their computation is not straightforward
+#' (e.g., in liner mixed models, contrasts, etc.).
 #' \cr\cr
 #' For test statistics derived from \code{lm} and \code{aov} models, these functions
 #' give exact results. For all other cases, these give practically exact results.
@@ -18,15 +18,17 @@
 #' it is possible to compute a negative number; even though this doesn't make any practical sense,
 #' it is recommended to report the negative number and not a 0).
 #'
-#' @details These functions use the following formulea:
+#' @details These functions use the following formulae:
 #' \cr\cr
 #' \deqn{\eta_p^2 = \frac{F \times df_{num}}{F \times df_{num} + df_{den}}}
 #' \cr\cr
 #' \deqn{\epsilon_p^2 = \frac{(F - 1) \times df_{num}}{F \times df_{num} + df_{den}}}
 #' \cr\cr
 #' \deqn{\omega_p^2 = \frac{(F - 1) \times df_{num}}{F \times df_{num} + df_{den} + 1}}
 #' \cr\cr\cr
-#' For \eqn{t}, the conversion is based on the equality of \eqn{t^2 = F} when {df_{num}=1}.
+#' For \eqn{t}, the conversion is based on the equality of \eqn{t^2 = F} when \eqn{df_{num}=1}.
+#'
+#' @note \eqn{Adj. \eta_p^2} is an alias for \eqn{\epsilon_p^2}.
 #'
 #' @examples
 #' \dontrun{
@@ -53,7 +55,7 @@
 #' F_to_partial_epsilon_squared(16.501, 1, 9)
 #' }
 #'
-#'#' @references
+#' @references
 #' \itemize{
 #'   \item Friedman, H. (1982). Simplified determinations of statistical power, magnitude of effect and research sample sizes. Educational and Psychological Measurement, 42(2), 521-526. \doi{10.1177/001316448204200214}
 #'   \item Mordkoff, J. T. (2019). A Simple Method for Removing Bias From a Popular Measure of Standardized Effect Size: Adjusted Partial Eta Squared. Advances in Methods and Practices in Psychological Science, 2(3), 228-232. \doi{10.1177/2515245919855053}
@@ -68,8 +70,8 @@ F_to_partial_eta_squared <- function(F.ratio, df_num, df_den){
 
 #' @rdname F_to_partial_eta_squared
 #' @export
-t_to_partial_eta_squared <- function(t.ratio, df){
-  F_to_partial_eta_squared(t.ratio^2, 1, df)
+t_to_partial_eta_squared <- function(t.ratio, df_den){
+  F_to_partial_eta_squared(t.ratio^2, 1, df_den)
 }
 
 #' @rdname F_to_partial_eta_squared
@@ -81,25 +83,29 @@ F_to_partial_epsilon_squared <- function(F.ratio, df_num, df_den){
 
 #' @rdname F_to_partial_eta_squared
 #' @export
-t_to_partial_epsilon_squared <- function(t.ratio, df){
-  F_to_partial_epsilon_squared(t.ratio^2, 1, df)
+t_to_partial_epsilon_squared <- function(t.ratio, df_den){
+  F_to_partial_epsilon_squared(t.ratio^2, 1, df_den)
 }
 
 #' @rdname F_to_partial_eta_squared
 #' @export
 F_to_adj_partial_eta_squared <- F_to_partial_epsilon_squared
 
+#' @rdname F_to_partial_eta_squared
+#' @export
 t_to_adj_partial_eta_squared <- t_to_partial_epsilon_squared
 
+#' @rdname F_to_partial_eta_squared
+#' @export
 F_to_partial_omega_squared <- function(F.tatio, df_num, df_den){
   ((F.tatio - 1) * df_num) /
     (F.tatio * df_num + df_den + 1)
 }
 
 #' @rdname F_to_partial_eta_squared
 #' @export
-t_to_partial_omega_squared <- function(t.ratio, df){
-  F_to_partial_omega_squared(t.ratio^2, 1, df)
+t_to_partial_omega_squared <- function(t.ratio, df_den){
+  F_to_partial_omega_squared(t.ratio^2, 1, df_den)
 }
 
 
@@ -110,7 +116,7 @@ t_to_partial_omega_squared <- function(t.ratio, df){
 #' @param chisq The \eqn{chi^2} statistic.
 #' @param N The sample size
 #' @param a The number of rows in the contingency table.
-#' @param b The number of colums in the contingency tables.
+#' @param b The number of columns in the contingency tables.
 #'
 #' @return A numeric integer between 0-1.
 #'

---FILE: man/F_to_partial_eta_squared.Rd---
@@ -6,20 +6,26 @@
 \alias{F_to_partial_epsilon_squared}
 \alias{t_to_partial_epsilon_squared}
 \alias{F_to_adj_partial_eta_squared}
+\alias{t_to_adj_partial_eta_squared}
+\alias{F_to_partial_omega_squared}
 \alias{t_to_partial_omega_squared}
 \title{Compute Partial Variance Explained Effect Sizes From Test Statistics}
 \usage{
 F_to_partial_eta_squared(F.ratio, df_num, df_den)
 
-t_to_partial_eta_squared(t.ratio, df)
+t_to_partial_eta_squared(t.ratio, df_den)
 
 F_to_partial_epsilon_squared(F.ratio, df_num, df_den)
 
-t_to_partial_epsilon_squared(t.ratio, df)
+t_to_partial_epsilon_squared(t.ratio, df_den)
 
 F_to_adj_partial_eta_squared(F.ratio, df_num, df_den)
 
-t_to_partial_omega_squared(t.ratio, df)
+t_to_adj_partial_eta_squared(t.ratio, df_den)
+
+F_to_partial_omega_squared(F.tatio, df_num, df_den)
+
+t_to_partial_omega_squared(t.ratio, df_den)
 }
 \arguments{
 \item{F.ratio}{The \eqn{F} statistic.}
@@ -36,25 +42,28 @@ it is possible to compute a negative number; even though this doesn't make any p
 it is recommended to report the negative number and not a 0).
 }
 \description{
-These functions are conviniance functions to convert \eqn{F} and \eqn{t}
+These functions are convenience functions to convert \eqn{F} and \eqn{t}
 test statistics to \eqn{\eta_p^2}, \eqn{\omega_p^2}, \eqn{\epsilon_p^2}, or
-\eqn{Adj. \eta_p^2}. These are useful in cases where the \eqn{SS}s and
-\eqn{MS}s are not easily availbe or their computation is not streight
-forward (e.g., in liner mixed models, contrasts, etc.).
+\eqn{Adj. \eta_p^2}. These are useful in cases where the various \eqn{SS}s and
+\eqn{MS}s are not easily available or their computation is not straightforward
+(e.g., in liner mixed models, contrasts, etc.).
 \cr\cr
 For test statistics derived from \code{lm} and \code{aov} models, these functions
 give exact results. For all other cases, these give practically exact results.
 }
 \details{
-These functions use the following formulea:
+These functions use the following formulae:
 \cr\cr
 \deqn{\eta_p^2 = \frac{F \times df_{num}}{F \times df_{num} + df_{den}}}
 \cr\cr
 \deqn{\epsilon_p^2 = \frac{(F - 1) \times df_{num}}{F \times df_{num} + df_{den}}}
 \cr\cr
 \deqn{\omega_p^2 = \frac{(F - 1) \times df_{num}}{F \times df_{num} + df_{den} + 1}}
 \cr\cr\cr
-For \eqn{t}, the conversion is based on the equality of \eqn{t^2 = F} when {df_{num}=1}.
+For \eqn{t}, the conversion is based on the equality of \eqn{t^2 = F} when \eqn{df_{num}=1}.
+}
+\note{
+\eqn{Adj. \eta_p^2} is an alias for \eqn{\epsilon_p^2}.
 }
 \examples{
 \dontrun{
@@ -81,11 +90,11 @@ F_to_partial_omega_squared(16.501, 1, 9)
 F_to_partial_epsilon_squared(16.501, 1, 9)
 }
 
-#' @references
-\\itemize{
-  \\item Friedman, H. (1982). Simplified determinations of statistical power, magnitude of effect and research sample sizes. Educational and Psychological Measurement, 42(2), 521-526. \\doi{10.1177/001316448204200214}
-  \\item Mordkoff, J. T. (2019). A Simple Method for Removing Bias From a Popular Measure of Standardized Effect Size: Adjusted Partial Eta Squared. Advances in Methods and Practices in Psychological Science, 2(3), 228-232. \\doi{10.1177/2515245919855053}
-  \\item Albers, C., & Lakens, D. (2018). When power analyses based on pilot data are biased: Inaccurate effect size estimators and follow-up bias. Journal of experimental social psychology, 74, 187-195. \\doi{10.31234/osf.io/b7z4q}
 }
-
+\references{
+\itemize{
+  \item Friedman, H. (1982). Simplified determinations of statistical power, magnitude of effect and research sample sizes. Educational and Psychological Measurement, 42(2), 521-526. \doi{10.1177/001316448204200214}
+  \item Mordkoff, J. T. (2019). A Simple Method for Removing Bias From a Popular Measure of Standardized Effect Size: Adjusted Partial Eta Squared. Advances in Methods and Practices in Psychological Science, 2(3), 228-232. \doi{10.1177/2515245919855053}
+  \item Albers, C., & Lakens, D. (2018). When power analyses based on pilot data are biased: Inaccurate effect size estimators and follow-up bias. Journal of experimental social psychology, 74, 187-195. \doi{10.31234/osf.io/b7z4q}
+}
 }

---FILE: man/chisq_to_phi.Rd---
@@ -16,7 +16,7 @@ chisq_to_cramers_V(chisq, N, a, b)
 
 \item{a}{The number of rows in the contingency table.}
 
-\item{b}{The number of colums in the contingency tables.}
+\item{b}{The number of columns in the contingency tables.}
 }
 \value{
 A numeric integer between 0-1.",True,False,Documentation / Formatting,6
easystats,effectsize,02bcd1c4e1053daf95dc821b19592b6c59460419,Dominique Makowski,dom.mak19@gmail.com,2019-10-12T06:20:42Z,Dominique Makowski,dom.mak19@gmail.com,2019-10-12T06:20:42Z,"added glass' delta, hedges'g, fixed vignettes etc.",NAMESPACE;R/cohens_d.R;R/interpret_d.R;R/interpret_parameters.R;R/normalize.R;R/ranktransform.R;R/sd_pooled.R;R/standardize_info.R;R/standardize_parameters.R;README.Rmd;man/cohens_d.Rd;man/interpret_d.Rd;man/interpret_parameters.Rd;man/normalize.Rd;man/ranktransform.Rd;tests/testthat/test-standardize_parameters.R;vignettes/standardize_parameters.Rmd,True,True,True,False,351,235,586,"---FILE: NAMESPACE---
@@ -87,13 +87,17 @@ export(d_to_odds)
 export(d_to_percentage)
 export(d_to_r)
 export(format_standardize)
+export(glass_delta)
+export(hedges_g)
 export(interpret)
 export(interpret_agfi)
 export(interpret_bf)
 export(interpret_cfi)
 export(interpret_d)
+export(interpret_delta)
 export(interpret_direction)
 export(interpret_effective_sample)
+export(interpret_g)
 export(interpret_gfi)
 export(interpret_ifi)
 export(interpret_nfi)

---FILE: R/cohens_d.R---
@@ -1,69 +1,150 @@
-#' Indices of effect size (Cohen's d, Hedges' g, Glass' delta, ...)
+#' Effect sizes for difference between means (Cohen's d, Hedges' g, Glass' delta, ...)
 #'
-#' Compute different indices of effect size.
+#' Compute different indices of effect size. For very small sample sizes (n < 20) Hedges' g is considered as less biased than Cohen's d. For sample sizes > 20, the results for both statistics are roughly equivalent. The Glassâs delta is appropriate if standard deviations are significantly different between groups, as it uses only the control group's (\code{x}) standard deviation.
 #'
 #' @param x A continuous variable or a formula.
 #' @param y A continuous variable, a factor with two groups or a formula.
 #' @param data An optional data frame containing the variables.
-#' @param paired Should the values be considered as paired.
-#' @param correct For Cohen's d, a correction to the formula to make it less biased for small samples (McGrath & Meyer, 2006). Can also be ""raw"", in which case the SD from both combined groups is computed instead of the \code{\link{sd_pooled}}.
+#' @param correction If \code{TRUE}, applies a correction to the formula to make it less biased for small samples (McGrath & Meyer, 2006).
+#' @param pooled_sd If \code{FALSE}, the regular SD from both combined groups is used instead of the \code{\link{sd_pooled}}.
+#' @param paired If \code{TRUE}, the values of \code{x} and \code{y} are considered as paired.
+#'
 #'
 #' @examples
 #' cohens_d(iris$Sepal.Length, iris$Sepal.Width)
+#' hedges_g(iris$Sepal.Length, iris$Sepal.Width)
+#' glass_delta(iris$Sepal.Length, iris$Sepal.Width)
+#'
+#' cohens_d(iris$Sepal.Length, iris$Sepal.Width, correct = TRUE, pooled_sd = FALSE)
 #' cohens_d(Sepal.Length ~ Species, data = iris[iris$Species %in% c(""versicolor"", ""setosa""), ])
 #'
+#'
+#'
 #' @references \itemize{
 #'  \item Cohen, J. (2013). Statistical power analysis for the behavioral sciences. Routledge.
 #'  \item McGrath, R. E., & Meyer, G. J. (2006). When effect sizes disagree: the case of r and d. Psychological methods, 11(4), 386.
+#'  \item Hedges, L. V. & Olkin, I. (1985). Statistical methods for meta-analysis. Orlando, FL: Academic Press.
 #' }
 #' @importFrom stats var model.frame
 #' @export
-cohens_d <- function(x, y = NULL, data = NULL, paired = FALSE, correct = FALSE) {
-  .effect_size_difference(x, y = y, data = data, type = ""d"", paired = paired, correct = correct)
+cohens_d <- function(x, y = NULL, data = NULL, correction = FALSE, pooled_sd = TRUE, paired = FALSE) {
+  .effect_size_difference(x, y = y, data = data, type = ""d"", correction = correction, pooled_sd = pooled_sd, paired = paired)
 }
 
+#' @rdname cohens_d
+#' @export
+hedges_g <- function(x, y = NULL, data = NULL, correction = FALSE, pooled_sd = TRUE, paired = FALSE) {
+  .effect_size_difference(x, y = y, data = data, type = ""g"", correction = correction, pooled_sd = pooled_sd, paired = paired)
+}
 
 #' @rdname cohens_d
-#' @keywords
-glass_delta <- function(x, y = NULL, data = NULL, correct = FALSE) {
-  .effect_size_difference(x, y = y, data = data, type = ""delta"", correct = correct)
+#' @export
+glass_delta <- function(x, y = NULL, data = NULL, correction = FALSE) {
+  .effect_size_difference(x, y = y, data = data, type = ""delta"", correction = correction)
 }
 
 
 
 
+
+
+
+
+
+
 #' @keywords internal
-.effect_size_difference <- function(x, y = NULL, data = NULL, type = ""d"", paired = FALSE, correct = FALSE) {
-  out <- .deal_with_cohensd_arguments(x, y, data)
+.effect_size_difference <- function(x, y = NULL, data = NULL, type = ""d"", correction = FALSE, pooled_sd = TRUE, paired = FALSE) {
+  out <- .deal_with_cohens_d_arguments(x, y, data)
   x <- out$x
   y <- out$y
 
   # Compute index
-  diff_of_means  <- mean(y, na.rm = TRUE) - mean(x, na.rm = TRUE)
+  diff_of_means <- mean(y, na.rm = TRUE) - mean(x, na.rm = TRUE)
 
-
-  if(type == ""d""){
-    if(paired){
-      denominator <- sd(x-y, na.rm = TRUE)
+  if (type == ""d"" | type == ""g"") {
+    if (paired) {
+      denominator <- sd(x - y, na.rm = TRUE)
     } else {
-      denominator <- sd_pooled(x, y)
+      if (pooled_sd) {
+        denominator <- sd_pooled(x, y)
+      } else {
+        denominator <- sd(c(x, y), na.rm = TRUE)
+      }
+    }
+    if (type == ""g"") {
+      if (paired) {
+        J <- 1 - 3 / (4 * (length(x) - 1) - 1)
+      } else {
+        J <- 1 - 3 / (4 * length(c(x, y)) - 9)
+      }
+      diff_of_means <- diff_of_means * J
     }
-  } else if (type == ""delta""){
+  } else if (type == ""delta"") {
     denominator <- sd(x, na.rm = TRUE)
   }
 
 
-
   d <- diff_of_means / denominator
 
 
   # McGrath & Meyer (2006)
-  if(correct == TRUE){
+  if (correction == TRUE) {
     n <- length(c(x, y))
-    d <- d * ((n - 3)/(n-2.25)) * ((n - 2)/n)
-  } else if(correct == ""raw""){
-    d <- diff_of_means / sd(c(x, y), na.rm = TRUE)
+    d <- d * ((n - 3) / (n - 2.25)) * ((n - 2) / n)
   }
 
   d
-}
\ No newline at end of file
+}
+
+
+
+
+
+
+
+
+#' @keywords internal
+.deal_with_cohens_d_arguments <- function(x, y = NULL, data = NULL) {
+
+  # Sanity checks
+  if (inherits(x, ""formula"") | is.character(x) | is.character(y)) {
+    if (is.null(data)) {
+      stop(""Please provide data argument."")
+    }
+  }
+
+
+  # Preprocess data
+  if (inherits(x, ""formula"")) {
+    data <- model.frame(x, data = data)
+    x <- names(data)[1]
+    y <- names(data)[2]
+  }
+
+  if (is.character(x)) {
+    x <- data[[x]]
+  }
+
+  if (is.character(y)) {
+    y <- data[[y]]
+  }
+
+
+  # If y is a factor
+  if (!is.null(y)) {
+    if (is.factor(y) | is.character(y)) {
+      if (length(x) != length(y)) {
+        stop(""The length of the group factor must be the same."")
+      }
+      if (length(unique(y)) > 2) {
+        stop(""Cannot compute the difference as a factor with more than 2 levels has been provided."")
+      } else {
+        groups <- as.character(y)
+        y <- x[groups == unique(groups)[2]]
+        x <- x[groups == unique(groups)[1]]
+      }
+    }
+  }
+
+  list(x = x, y = y)
+}

---FILE: R/interpret_d.R---
@@ -4,7 +4,7 @@
 #' \href{https://easystats.github.io/report/articles/interpret_metrics.html#standardized-difference-d-cohens-d}{Click here} for details.
 #'
 #'
-#' @param d Value or vector of d values.
+#' @param d,g,delta Value or vector of effect size values.
 #' @param rules Can be ""funder2019"" (default), ""gignac2016"", ""cohen1988"", ""sawilowsky2009"" or custom set of \code{\link{rules}}.
 #'
 #'
@@ -37,3 +37,15 @@ interpret_d <- function(d, rules = ""funder2019"") {
     }
   }
 }
+
+#' @rdname interpret_d
+#' @export
+interpret_g <- function(g, rules = ""funder2019""){
+  interpret_d(g, rules)
+}
+
+#' @rdname interpret_d
+#' @export
+interpret_delta <- function(delta, rules = ""funder2019""){
+  interpret_d(delta, rules)
+}
\ No newline at end of file

---FILE: R/interpret_parameters.R---
@@ -11,9 +11,8 @@
 #' @examples
 #' model <- lm(Sepal.Length ~ Species * Petal.Width, data = iris)
 #' interpret_parameters(model)
-#'
 #' @export
-interpret_parameters <- function(model, ...){
+interpret_parameters <- function(model, ...) {
   UseMethod(""interpret_parameters"")
 }
 
@@ -22,7 +21,7 @@ interpret_parameters <- function(model, ...){
 
 #' @rdname interpret_parameters
 #' @export
-interpret_parameters.lm <- function(model, interpretation = ""funder2019"", parameters = NULL, standardize_method = ""refit"", standardize_robust = FALSE, ...){
+interpret_parameters.lm <- function(model, interpretation = ""funder2019"", parameters = NULL, standardize_method = ""refit"", standardize_robust = FALSE, ...) {
   .interpret_parameters_regressions(model, interpretation = interpretation, parameters = parameters, standardize_method = standardize_method, standardize_robust = standardize_robust)
 }
 
@@ -33,14 +32,15 @@ interpret_parameters.lm <- function(model, interpretation = ""funder2019"", parame
 
 
 #' @keywords internal
-.interpret_parameters_regressions <- function(model, interpretation = ""funder2019"", parameters = NULL, standardize_method = ""refit"", standardize_robust = FALSE, ...){
-
+.interpret_parameters_regressions <- function(model, interpretation = ""funder2019"", parameters = NULL, standardize_method = ""refit"", standardize_robust = FALSE, ...) {
   type <- parameters::parameters_type(model)
   std_es <- .standardize_standardized(model, standardize_method = standardize_method, standardize_robust = standardize_robust, type = type, centrality = ""Median"")
 
-  data.frame(Parameter = type$Parameter,
-             Effect_Size = std_es,
-             Interpretation = interpret_r(std_es, rules = interpretation))
+  data.frame(
+    Parameter = type$Parameter,
+    Effect_Size = std_es,
+    Interpretation = interpret_r(std_es, rules = interpretation)
+  )
 }
 
 
@@ -51,14 +51,14 @@ interpret_parameters.lm <- function(model, interpretation = ""funder2019"", parame
 
 
 #' @keywords internal
-.standardize_standardized <- function(model, parameters = NULL, standardize_method = ""refit"", standardize_robust = FALSE, type = NULL, centrality = ""Median"", ...){
+.standardize_standardized <- function(model, parameters = NULL, standardize_method = ""refit"", standardize_robust = FALSE, type = NULL, centrality = ""Median"", ...) {
 
   # Get type of parameters
   info <- standardize_info(model, robust = standardize_robust)
 
   # Compute std parameters
-  if(is.null(parameters)){
-    parameters <- standardize_parameters(model, method = standardize_method, robust = standardize_robust, centrality = centrality,  ...)
+  if (is.null(parameters)) {
+    parameters <- standardize_parameters(model, method = standardize_method, robust = standardize_robust, centrality = centrality, ...)
   }
 
   # Standardize standardized parameters (Correlation r)
@@ -82,25 +82,25 @@ interpret_parameters.lm <- function(model, interpretation = ""funder2019"", parame
 
 
 #' @keywords internal
-.standardize_standardized_interactions <- function(model, info, type, std_es, centrality = ""Median"", method = ""absolute"", ...){
+.standardize_standardized_interactions <- function(model, info, type, std_es, centrality = ""Median"", method = ""absolute"", ...) {
   # Get parameters
   parameters <- insight::get_parameters(model)
   if (insight::model_info(model)$is_bayesian) {
     parameters <- bayestestR::describe_posterior(parameters, centrality = centrality, dispersion = FALSE, ci = NULL, test = NULL, diagnostic = NULL, priors = FALSE, ...)
     parameters <- parameters[names(parameters) %in% c(""Parameter"", ""Coefficient"", ""Median"", ""Mean"", ""MAP"")]
-  } else{
+  } else {
     names(parameters) <- c(""Parameter"", ""Coefficient"")
   }
   params <- parameters[names(parameters) %in% c(""estimate"", ""Coefficient"", ""Median"", ""Mean"", ""MAP"")][[1]]
 
   interactions <- info$Parameter[info$Type == ""interaction""]
-  if(length(interactions) > 0){
+  if (length(interactions) > 0) {
     parent_effect <- type[type$Parameter == interactions, ""Secondary_Term""]
 
-    if(method == ""absolute""){
+    if (method == ""absolute"") {
       # Absolute method
       info[info$Parameter %in% interactions, ""EffectSize_Type""] <- info[info$Parameter %in% parent_effect, ""EffectSize_Type""]
-    } else{
+    } else {
       # Relative method (compute percentage of change based on parent effect)
       parent_effect <- params[parameters$Parameter %in% parent_effect]
       interactions <- params[!is.na(info$EffectSize_Type) & info$EffectSize_Type == ""interaction""]
@@ -110,4 +110,4 @@ interpret_parameters.lm <- function(model, interpretation = ""funder2019"", parame
   }
 
   list(info = info, std_es = std_es)
-}
\ No newline at end of file
+}

---FILE: R/normalize.R---
@@ -18,7 +18,6 @@
 #' normalize(c(0, 1, 5, -5, -2), include_bounds = FALSE)
 #'
 #' head(normalize(iris))
-#'
 #' @references Smithson M, Verkuilen J (2006). A Better Lemon Squeezer? Maximum-Likelihood Regression with Beta-Distributed Dependent Variables. Psychological Methods, 11(1), 54â71.
 #'
 #' @return A normalized object.

---FILE: R/ranktransform.R---
@@ -14,7 +14,6 @@
 #' ranktransform(c(0, 1, 5, -5, -2), sign = TRUE)
 #'
 #' head(ranktransform(iris))
-#'
 #' @return A rank-transformed object.
 #' @export
 ranktransform <- function(x, ...) {
@@ -63,9 +62,9 @@ ranktransform.numeric <- function(x, sign = FALSE, method = ""average"", verbose =
   }
 
 
-  if(sign){
+  if (sign) {
     out <- sign(x) * rank(x, ties.method = method, na.last = ""keep"")
-  } else{
+  } else {
     out <- rank(x, ties.method = method, na.last = ""keep"")
   }
 

---FILE: R/sd_pooled.R---
@@ -27,70 +27,23 @@ mad_pooled <- function(x, y = NULL, data = NULL) {
 #' @importFrom stats mad
 #' @export
 .sd_pooled <- function(x, y = NULL, data = NULL, robust = FALSE) {
-  out <- .deal_with_cohensd_arguments(x, y, data)
+  out <- .deal_with_cohens_d_arguments(x, y, data)
   x <- out$x
   y <- out$y
 
-  if(robust){
+  if (robust) {
     sd1 <- mad(x, na.rm = TRUE)
     sd2 <- mad(y, na.rm = TRUE)
-  } else{
+  } else {
     sd1 <- sd(x, na.rm = TRUE)
     sd2 <- sd(y, na.rm = TRUE)
   }
 
 
-  sqrt((sd1^2 + sd2^2)/2)
+  sqrt((sd1^2 + sd2^2) / 2)
 
   # Cohen's more complicated formula:
   # n1 <- length(x)
   # n2 <- length(y)
   # sqrt( (n1-1) * var(x) + (n2-1) * var(y) / n1 + n2 - 2)
 }
-
-
-#' @keywords internal
-.deal_with_cohensd_arguments <- function(x, y = NULL, data = NULL){
-
-  # Sanity checks
-  if(inherits(x,""formula"") | is.character(x) | is.character(y)){
-    if(is.null(data)){
-      stop(""Please provide data argument."")
-    }
-  }
-
-
-  # Preprocess data
-  if(inherits(x, ""formula"")){
-    data <- model.frame(x, data = data)
-    x <- names(data)[1]
-    y <- names(data)[2]
-  }
-
-  if(is.character(x)){
-    x <- data[[x]]
-  }
-
-  if(is.character(y)){
-    y <- data[[y]]
-  }
-
-
-  # If y is a factor
-  if(!is.null(y)){
-    if(is.factor(y) | is.character(y)){
-      if(length(x) != length(y)){
-        stop(""The length of the group factor must be the same."")
-      }
-      if(length(unique(y)) > 2){
-        stop(""Cannot compute the difference as a factor with more than 2 levels has been provided."")
-      } else{
-        groups <- as.character(y)
-        y <- x[groups == unique(groups)[2]]
-        x <- x[groups == unique(groups)[1]]
-      }
-    }
-  }
-
-  list(x = x, y = y)
-}
\ No newline at end of file

---FILE: R/standardize_info.R---
@@ -24,8 +24,10 @@ standardize_info <- function(model, robust = FALSE, ...) {
 
   # Type of effect size
   out$EffectSize_Type <- ifelse(types$Type == ""interaction"", ""interaction"",
-                                 ifelse(types$Link == ""Association"", ""r"",
-                                        ifelse(types$Link == ""Difference"", ""d"", NA)))
+    ifelse(types$Link == ""Association"", ""r"",
+      ifelse(types$Link == ""Difference"", ""d"", NA)
+    )
+  )
 
 
 
@@ -177,15 +179,14 @@ standardize_info <- function(model, robust = FALSE, ...) {
 
 #' @keywords internal
 .std_info_response_smart <- function(model, data, model_matrix, types, robust = FALSE, ...) {
-
   info <- insight::model_info(model)
 
   if (info$is_linear) {
     response <- insight::get_response(model)
     deviations <- c()
     means <- c()
-    for(var in names(model_matrix)){
-      if(types$Link[types$Parameter == var] == ""Difference""){
+    for (var in names(model_matrix)) {
+      if (types$Link[types$Parameter == var] == ""Difference"") {
         parent_var <- types$Variable[types$Parameter == var]
         intercept <- unique(data[[parent_var]])[1]
         response_at_intercept <- response[data[[parent_var]] == intercept]
@@ -248,8 +249,7 @@ standardize_info <- function(model, robust = FALSE, ...) {
 
 #' @keywords internal
 .compute_std_info <- function(data = NULL, variable = NULL, response = NULL, robust = FALSE) {
-
-  if(is.null(response)){
+  if (is.null(response)) {
     response <- as.numeric(data[, variable])
   }
 
@@ -263,4 +263,3 @@ standardize_info <- function(model, robust = FALSE, ...) {
 
   list(sd = sd_x, mean = mean_x)
 }
-

---FILE: R/standardize_parameters.R---
@@ -146,18 +146,18 @@ standardize_posteriors <- function(model, method = ""refit"", robust = FALSE, two_
   }
 
   # Get parameters
-  if (is.null(parameters)){
+  if (is.null(parameters)) {
     parameters <- .extract_parameters(model)
     if (insight::model_info(model)$is_bayesian) {
       parameters <- as.data.frame(t(parameters))
     }
   }
 
   # Get names of parameters
-  if(""Parameter"" %in% names(parameters)){
+  if (""Parameter"" %in% names(parameters)) {
     param_names <- parameters$Parameter
     parameters$Parameter <- NULL
-  } else{
+  } else {
     param_names <- row.names(parameters)
   }
 
@@ -177,14 +177,14 @@ standardize_posteriors <- function(model, method = ""refit"", robust = FALSE, two_
   } else if (method == ""smart"") {
     col_dev_resp <- ""Deviation_Response_Smart""
     col_dev_pred <- ""Deviation_Smart""
-  } else{
+  } else {
     stop(""'method' must be one of 'basic', 'posthoc' or 'smart'."")
   }
 
   # Sapply standardization
-  if(two_sd){
+  if (two_sd) {
     std_params <- sapply(parameters, function(x) x * (2 * deviations[[col_dev_pred]]) / deviations[[col_dev_resp]])
-  } else{
+  } else {
     std_params <- sapply(parameters, function(x) x * deviations[[col_dev_pred]] / deviations[[col_dev_resp]])
   }
 
@@ -194,9 +194,11 @@ standardize_posteriors <- function(model, method = ""refit"", robust = FALSE, two_
     std_params <- as.data.frame(t(std_params))
     row.names(std_params) <- NULL
     names(std_params) <- param_names
-  } else{
-    std_params <- cbind(data.frame(Parameter = param_names),
-                        as.data.frame(std_params))
+  } else {
+    std_params <- cbind(
+      data.frame(Parameter = param_names),
+      as.data.frame(std_params)
+    )
   }
 
 
@@ -207,7 +209,8 @@ standardize_posteriors <- function(model, method = ""refit"", robust = FALSE, two_
   },
   error = function(e) {
     NULL
-  })
+  }
+  )
 
   # add standardized standard errors as attribute
   if (!is.null(std_error)) {

---FILE: README.Rmd---
@@ -74,85 +74,43 @@ This package is focused on indices of effect size. But **there are hundreds of t
 
 ## Effect Size Computation
 
-### Measure of association (correlation *r*)
+### Basic Indices (Cohen's *d*, Hedges' *g*, Glass' *delta*)
 
-```{r, warning=FALSE, message=FALSE, eval=FALSE}
-library(dplyr)
-
-lm(Sepal.Length ~ Petal.Length, data = iris) %>% 
-  standardize_parameters()
-```
-```{r, warning=FALSE, message=FALSE, echo = FALSE}
-library(dplyr)
-
-lm(Sepal.Length ~ Petal.Length, data = iris) %>% 
-  standardize_parameters() %>% 
-  knitr::kable(digits = 2)
-```
-
-Standardizing the coefficient of this simple linear regression gives a value of `0.87`, but did you know that this is actually the **same as a correlation**? Thus, you can eventually apply some (*in*)famous interpretation guidelines (e.g., Cohen's rules of thumb).
-
-```{r, warning=FALSE, message=FALSE}
-library(parameters)
-
-cor.test(iris$Sepal.Length, iris$Petal.Length) %>% 
-  model_parameters()
-```
-
-
-### Standardized differences
-
-How does it work in the case of differences, when **factors** are entered and differences between a given level and a reference level (the intercept)? You might have heard that it is similar to a **Cohen's *d***. Well, let's see.
+The package provides functions to compute indices of effect size.
 
 ```{r, warning=FALSE, message=FALSE, eval=FALSE}
-lm(Sepal.Length ~ Species, data = iris) %>% 
-  standardize_parameters()
-```
-```{r, warning=FALSE, message=FALSE, echo = FALSE}
-lm(Sepal.Length ~ Species, data = iris) %>% 
-  standardize_parameters() %>% 
-  knitr::kable(digits = 2)
+cohens_d(iris$Sepal.Length, iris$Sepal.Width)
+hedges_g(iris$Sepal.Length, iris$Sepal.Width)
+glass_delta(iris$Sepal.Length, iris$Sepal.Width)
 ```
 
-This linear model suggests that the *standardized* difference between the *versicolor* level of Species and the *setosa* level (the reference level - the intercept) is of 1.12 standard deviation of `Sepal.Length` (because the response variable was standardized, right?). Let's compute the **Cohen's *d*** between these two levels:
+### ANOVAs (Eta$^2$, Omega$^2$, ...)
 
-```{r, warning=FALSE, message=FALSE}
-# Select portion of data containing the two levels of interest
-data <- iris[iris$Species %in% c(""setosa"", ""versicolor""), ]
+Currently implemented in the `parameters` package, will be transfered here in the next update.
 
-cohens_d(Sepal.Length ~ Species, data = data) 
-```
+### Regression Models
 
-***It is very different!*** Why? How? Both differences should be expressed in terms of SD of the response variable. *And there's the trick*. First of all, in the linear model above, the SD by which the difference is scaled is the one of the whole response, which include **all the three levels**, whereas below, we filtered the data to only include the levels of interest. If we recompute the model on this filtered data, it should be better:
+Importantly, `effectsize` also provides [advanced methods](https://easystats.github.io/effectsize/articles/standardize_parameters.html) to compute standardized parameters for regression models.
 
 ```{r, warning=FALSE, message=FALSE, eval=FALSE}
-lm(Sepal.Length ~ Species, data = data) %>% 
+lm(Sepal.Length ~ Species + Sepal.Length, data = iris) %>% 
   standardize_parameters()
 ```
 ```{r, warning=FALSE, message=FALSE, echo = FALSE}
-lm(Sepal.Length ~ Species, data = data) %>% 
+lm(Sepal.Length ~ Species + Sepal.Length, data = iris) %>% 
   standardize_parameters() %>% 
   knitr::kable(digits = 2)
 ```
 
-Not really. Why? Because the actual formula to compute a **Cohen's *d*** doesn't use the simple SD to scale the effect (as it is done when standardizing the parameters), but computes something called the [**pooled SD**](https://easystats.github.io/effectsize/reference/pooled_sd.html). However, this can be turned off by setting `correct = ""raw""`.
+## Effect Size Interpretation
+
+The package allows for an automated interpretation of different indices. 
 
 ```{r, warning=FALSE, message=FALSE}
-cohens_d(Sepal.Length ~ Species, data = data, correct = ""raw"") 
+interpret_r(r = 0.3)
 ```
 
-***And here we are :)***
-
-
-### What about standardized interaction effects?
-
-Well, this one's a mess (at least for me). Help is required to make sense out of it. Otherwise, *NEXT*.
-
-
-
-## Effect Size Interpretation
-
-The [**guidelines are detailed here**](https://easystats.github.io/effectsize/articles/interpret.html).
+Different sets of ""rules of thumb"" are implemented ([**guidelines are detailed here**](https://easystats.github.io/effectsize/articles/interpret.html)) and can be easily changed.
 
 
 ```{r, warning=FALSE, message=FALSE}
@@ -163,6 +121,8 @@ interpret_d(d = 0.45, rules = ""funder2019"")
 
 ## Effect Size Conversion
 
+The package also provides ways of converting between different effect sizes.
+
 ```{r, warning=FALSE, message=FALSE}
 convert_d_to_r(d = 1)
 ```

---FILE: man/cohens_d.Rd---
@@ -2,12 +2,17 @@
 % Please edit documentation in R/cohens_d.R
 \name{cohens_d}
 \alias{cohens_d}
+\alias{hedges_g}
 \alias{glass_delta}
-\title{Indices of effect size (Cohen's d, Hedges' g, ...)}
+\title{Effect sizes for difference between means (Cohen's d, Hedges' g, Glass' delta, ...)}
 \usage{
-cohens_d(x, y = NULL, data = NULL, paired = FALSE, correct = FALSE)
+cohens_d(x, y = NULL, data = NULL, correction = FALSE,
+  pooled_sd = TRUE, paired = FALSE)
 
-glass_delta(x, y = NULL, data = NULL, correct = FALSE)
+hedges_g(x, y = NULL, data = NULL, correction = FALSE,
+  pooled_sd = TRUE, paired = FALSE)
+
+glass_delta(x, y = NULL, data = NULL, correction = FALSE)
 }
 \arguments{
 \item{x}{A continuous variable or a formula.}
@@ -16,21 +21,30 @@ glass_delta(x, y = NULL, data = NULL, correct = FALSE)
 
 \item{data}{An optional data frame containing the variables.}
 
-\item{paired}{Should the values be considered as paired.}
+\item{correction}{If \code{TRUE}, applies a correction to the formula to make it less biased for small samples (McGrath & Meyer, 2006).}
+
+\item{pooled_sd}{If \code{FALSE}, the regular SD from both combined groups is used instead of the \code{\link{sd_pooled}}.}
 
-\item{correct}{For Cohen's d, a correction to the formula to make it less biased for small samples (McGrath & Meyer, 2006). Can also be ""raw"", in which case the SD from both combined groups is computed instead of the \code{\link{sd_pooled}}.}
+\item{paired}{If \code{TRUE}, the values of \code{x} and \code{y} are considered as paired.}
 }
 \description{
-Compute different indices of effect size.
+Compute different indices of effect size. For very small sample sizes (n < 20) Hedges' g is considered as less biased than Cohen's d. For sample sizes > 20, the results for both statistics are roughly equivalent. The Glassâs delta is appropriate if standard deviations are significantly different between groups, as it uses only the control group's (\code{x}) standard deviation.
 }
 \examples{
 cohens_d(iris$Sepal.Length, iris$Sepal.Width)
+hedges_g(iris$Sepal.Length, iris$Sepal.Width)
+glass_delta(iris$Sepal.Length, iris$Sepal.Width)
+
+cohens_d(iris$Sepal.Length, iris$Sepal.Width, correct = TRUE, pooled_sd = FALSE)
 cohens_d(Sepal.Length ~ Species, data = iris[iris$Species \%in\% c(""versicolor"", ""setosa""), ])
 
+
+
 }
 \references{
 \itemize{
  \item Cohen, J. (2013). Statistical power analysis for the behavioral sciences. Routledge.
  \item McGrath, R. E., & Meyer, G. J. (2006). When effect sizes disagree: the case of r and d. Psychological methods, 11(4), 386.
+ \item Hedges, L. V. & Olkin, I. (1985). Statistical methods for meta-analysis. Orlando, FL: Academic Press.
 }
 }

---FILE: man/interpret_d.Rd---
@@ -2,12 +2,18 @@
 % Please edit documentation in R/interpret_d.R
 \name{interpret_d}
 \alias{interpret_d}
+\alias{interpret_g}
+\alias{interpret_delta}
 \title{Standardized Difference (Cohen's d) Interpretation}
 \usage{
 interpret_d(d, rules = ""funder2019"")
+
+interpret_g(g, rules = ""funder2019"")
+
+interpret_delta(delta, rules = ""funder2019"")
 }
 \arguments{
-\item{d}{Value or vector of d values.}
+\item{d, g, delta}{Value or vector of effect size values.}
 
 \item{rules}{Can be ""funder2019"" (default), ""gignac2016"", ""cohen1988"", ""sawilowsky2009"" or custom set of \code{\link{rules}}.}
 }

---FILE: man/interpret_parameters.Rd---
@@ -30,5 +30,4 @@ Automated interpretation of effect sizes.
 \examples{
 model <- lm(Sepal.Length ~ Species * Petal.Width, data = iris)
 interpret_parameters(model)
-
 }

---FILE: man/normalize.Rd---
@@ -50,7 +50,6 @@ normalize(c(0, 1, 5, -5, -2))
 normalize(c(0, 1, 5, -5, -2), include_bounds = FALSE)
 
 head(normalize(iris))
-
 }
 \references{
 Smithson M, Verkuilen J (2006). A Better Lemon Squeezer? Maximum-Likelihood Regression with Beta-Distributed Dependent Variables. Psychological Methods, 11(1), 54â71.

---FILE: man/ranktransform.Rd---
@@ -47,5 +47,4 @@ ranktransform(c(0, 1, 5, -5, -2))
 ranktransform(c(0, 1, 5, -5, -2), sign = TRUE)
 
 head(ranktransform(iris))
-
 }

---FILE: tests/testthat/test-standardize_parameters.R---
@@ -10,4 +10,3 @@ test_that(""standardize_parameters (simple)"", {
   es <- standardize_parameters(model)[2, 2]
   testthat::expect_equal(es, r, tol = 0.01)
 })
-

---FILE: vignettes/standardize_parameters.Rmd---
@@ -40,15 +40,105 @@ Critically, **parameters standardization is not a trivial process**. Different t
 
 # How to interpret standardized coefficients?
 
-Cohen's d? Correlations r?
+
+## Measure of association (correlation *r*)
+
+```{r, warning=FALSE, message=FALSE, eval=FALSE}
+library(effectsize)
+library(dplyr)
+
+lm(Sepal.Length ~ Petal.Length, data = iris) %>% 
+  standardize_parameters()
+```
+```{r, warning=FALSE, message=FALSE, echo = FALSE}
+library(effectsize)
+library(dplyr)
+
+lm(Sepal.Length ~ Petal.Length, data = iris) %>% 
+  standardize_parameters() %>% 
+  knitr::kable(digits = 2)
+```
+
+Standardizing the coefficient of this simple linear regression gives a value of `0.87`, but did you know that this is actually the **same as a correlation**? Thus, you can eventually apply some (*in*)famous interpretation guidelines (e.g., Cohen's rules of thumb).
+
+```{r, warning=FALSE, message=FALSE}
+library(parameters)
+
+cor.test(iris$Sepal.Length, iris$Petal.Length) %>% 
+  model_parameters()
+```
+
+
+## Standardized differences
+
+How does it work in the case of differences, when **factors** are entered and differences between a given level and a reference level (the intercept)? You might have heard that it is similar to a **Cohen's *d***. Well, let's see.
+
+```{r, warning=FALSE, message=FALSE, eval=FALSE}
+lm(Sepal.Length ~ Species, data = iris) %>% 
+  standardize_parameters()
+```
+```{r, warning=FALSE, message=FALSE, echo = FALSE}
+lm(Sepal.Length ~ Species, data = iris) %>% 
+  standardize_parameters() %>% 
+  knitr::kable(digits = 2)
+```
+
+This linear model suggests that the *standardized* difference between the *versicolor* level of Species and the *setosa* level (the reference level - the intercept) is of 1.12 standard deviation of `Sepal.Length` (because the response variable was standardized, right?). Let's compute the **Cohen's *d*** between these two levels:
+
+```{r, warning=FALSE, message=FALSE}
+# Select portion of data containing the two levels of interest
+data <- iris[iris$Species %in% c(""setosa"", ""versicolor""), ]
+
+cohens_d(Sepal.Length ~ Species, data = data) 
+```
+
+***It is very different!*** Why? How? Both differences should be expressed in terms of SD of the response variable. *And there's the trick*. First of all, in the linear model above, the SD by which the difference is scaled is the one of the whole response, which include **all the three levels**, whereas below, we filtered the data to only include the levels of interest. If we recompute the model on this filtered data, it should be better:
+
+```{r, warning=FALSE, message=FALSE, eval=FALSE}
+lm(Sepal.Length ~ Species, data = data) %>% 
+  standardize_parameters()
+```
+```{r, warning=FALSE, message=FALSE, echo = FALSE}
+lm(Sepal.Length ~ Species, data = data) %>% 
+  standardize_parameters() %>% 
+  knitr::kable(digits = 2)
+```
+
+Not really. Why? Because the actual formula to compute a **Cohen's *d*** doesn't use the simple SD to scale the effect (as it is done when standardizing the parameters), but computes something called the [**pooled SD**](https://easystats.github.io/effectsize/reference/pooled_sd.html). However, this can be turned off by setting `correct = ""raw""`.
+
+```{r, warning=FALSE, message=FALSE}
+cohens_d(Sepal.Length ~ Species, data = data, pooled_sd = FALSE) 
+```
+
+***And here we are :)***
+
+However, it is interesting to note that using the *smart* method when standardizing parameters will give you indices equivalent to **Glass' delta**, which difference is expressed in terms of SD of the intercept (the ""reference"" factor levels).
+
+```{r, warning=FALSE, message=FALSE, eval=FALSE}
+lm(Sepal.Length ~ Species, data = data) %>% 
+  standardize_parameters(method = ""smart"")
+```
+```{r, warning=FALSE, message=FALSE, echo = FALSE}
+lm(Sepal.Length ~ Species, data = data) %>% 
+  standardize_parameters(method = ""smart"") %>% 
+  knitr::kable(digits = 2)
+```
+```{r, warning=FALSE, message=FALSE}
+glass_delta(Sepal.Length ~ Species, data = data)
+```
+
+
+## What about standardized interaction effects?
+
+Well, this one's a mess (at least for me). Help is required to make sense out of it. Otherwise, *NEXT*.
 
 
 
 # Standardization methods
 
 ### **""refit""**: Re-fitting the model with standardized data
 
-**This method is based on a complete model re-fit with a standardized version of data**. Hence, this method is equal to standardizing the variables before fitting the model. It is the ""purest"" and the most accurate [@neter1989applied], but it is also the most computationally costly and long (especially for Bayesian models). This method is particularly recommended for complex models that include interactions or transformations (*e.g.*, polynomial or spline terms).
+**This method is based on a complete model re-fit with a standardized version of data**. Hence, this method is equal to standardizing the variables before fitting the model. It is the ""purest"" and the most accurate (Neter et al., 1989), but it is also the most computationally costly and long (especially for heavy models such as, for instance, for Bayesian models). This method is particularly recommended for complex models that include interactions or transformations (e.g., polynomial or spline terms).
 
 
 ```{r message=FALSE, warning=FALSE, results='hide'}
@@ -84,15 +174,21 @@ standardize_parameters(model, method=""refit"")
 knitr::kable(standardize_parameters(model, method=""refit""), digits=2)
 ```
 
-### **""2SD""**: Scaling by two 2 SDs
-
-Same as `method = ""refit""`, however, standardization is done by dividing by two times the `SD` or `MAD` (depending on `robust`). This method is useful to obtain coefficients of continuous parameters comparable to coefficients related to binary predictors [@gelman2008scaling].
+### **""posthoc""**: Refit without refitting
 
+Post-hoc standardization of the parameters, aiming at emulating the results obtained by ""refit"" without refitting the model. The coefficients are divided by the standard deviation (or MAD if `robust`) of the outcome (which becomes their expression 'unit'). Then, the coefficients related to numeric variables are additionally multiplied by the standard deviation (or MAD if `robust`) of the related terms, so that they correspond to changes of 1 SD of the predictor (e.g., ""A change in 1 SD of *x* is related to a change of 0.24 of the SD of *y*). This does not apply to binary variables or factors, so the coefficients are still related to changes in levels. This method is not accurate and tend to give aberrant results when interactions are specified.
 
+```{r warning=FALSE, message=FALSE, results='hide'}
+model <- lm(Sepal.Length ~ Petal.Width + Sepal.Width, data=data)
+standardize_parameters(model, method=""posthoc"")
+```
+```{r message=FALSE, warning=FALSE, echo=FALSE}
+knitr::kable(standardize_parameters(model, method=""posthoc""), digits=2)
+```
 
-### **""smart""**: Scaling by the variances of the response and the predictor
+### **""smart""**: Standardization of Model's parameters with Adjustment, Reconnaissance and Transformation
 
-Post-hoc standardization of the model paramaters. The coefficients are divided by the standard deviation (or MAD if `robust`) of the outcome (which becomes their expression 'unit'). Then, the coefficients related to numeric variables are additionaly multiplied by the standard deviation (or MAD if `robust`) of the related term, so that they correspond to changes of 1 SD of the predictor (e.g., ""A change in 1 SD of `x` is related to a change of 0.24 of the SD of `y`). This does not apply to binary variables or factors, so the coefficients are still related to changes in levels.
+Similar to `method = ""posthoc""` in that it does not involve model refitting. The difference is that the SD of the response is computed on the relevant section of the data. For instance, if a factor with 3 levels A (the intercept), B and C is entered as a predictor, the effect corresponding to B vs. A will be scaled by the variance of the response at the intercept only. As a results, the coefficients for effects of factors are similar to a Glass' *delta*.
 
 
 ```{r warning=FALSE, message=FALSE, results='hide'}
@@ -103,16 +199,18 @@ standardize_parameters(model, method=""smart"")
 knitr::kable(standardize_parameters(model, method=""smart""), digits=2)
 ```
 
-### **""classic""**: Basic scaling of all parameters
+### **""basic""**: Raw scaling of the model frame
 
-This method is similar to `method = ""smart""`, but treats all variables as continuous: it also scales the coefficient by the standard deviation of factors (transformed to integers) or binary predictors. Altough being inapropriate for these cases, this method is the one implemented by default in other softwares, such as `lm.beta::lm.beta()`.
+This method is similar to `method = ""posthoc""`, but treats all variables as continuous: it also scales the coefficient by the standard deviation of model's matrix' parameter of factors levels (transformed to integers) or binary predictors. Although being inappropriate for these cases, this method is the one implemented by default in other software packages, such as `lm.beta::lm.beta()`.
 
 ## Methods Comparison
 
 We will use the ""refit"" method as the baseline. We will then compute the differences between these standardized parameters and the ones provided by the other functions. The **bigger the (absolute) number, the worse it is**. 
 
 > **SPOILER ALERT: the standardization implemented in `effectsize` is the most accurate and the most flexible.**
 
+### Convenience function
+
 ```{r message=FALSE, warning=FALSE}
 library(effectsize)
 library(lm.beta)
@@ -121,13 +219,13 @@ library(MuMIn)
 comparison <- function(model, robust=FALSE){
   out <- standardize_parameters(model, method=""refit"", robust=robust)[1:2]
   
-  out$smart <- tryCatch({
-    out[, 2] - standardize_parameters(model, method=""smart"", robust=robust)[, 2]
+  out$posthoc <- tryCatch({
+    out[, 2] - standardize_parameters(model, method=""posthoc"", robust=robust)[, 2]
 }, error = function(error_condition) {
     ""Error""
 })
-  out$classic <- tryCatch({
-    out[, 2] - standardize_parameters(model, method=""classic"", robust=robust)[, 2]
+  out$basic <- tryCatch({
+    out[, 2] - standardize_parameters(model, method=""basic"", robust=robust)[, 2]
 }, error = function(error_condition) {
     ""Error""
 })
@@ -151,26 +249,29 @@ comparison <- function(model, robust=FALSE){
 }
 ```
 
+### Data
+
+```{r message=FALSE, warning=FALSE}
+data <- iris
+data$Group_Sepal.Width <- as.factor(ifelse(data$Sepal.Width > 3, ""High"", ""Low""))
+data$Binary_Sepal.Width <- as.factor(ifelse(data$Sepal.Width > 3, 1, 0))
+
+summary(data)
+```
 
 ### Models with only numeric predictors
 
 
 #### Linear Model
 
-
 ```{r message=FALSE, warning=FALSE, results='hide'}
-data <- iris
-data$Group_Sepal.Width <- as.factor(ifelse(data$Sepal.Width > 3, ""High"", ""Low""))
-data$Binary_Sepal.Width <- as.factor(ifelse(data$Sepal.Width > 3, 1, 0))
-
 model <- lm(Sepal.Length ~ Petal.Width + Sepal.Width, data=data) 
 comparison(model)
 ```
 ```{r message=FALSE, warning=FALSE, echo=FALSE}
 knitr::kable(comparison(model), digits=2, row.names = FALSE)
 ```
 
-For this simple model, **all methods return results equal to the ""refit"" method**.
 
 #### Logistic Model
 
@@ -183,7 +284,6 @@ comparison(model)
 knitr::kable(comparison(model), digits=2, row.names = FALSE)
 ```
 
-
 #### Linear Mixed Model
 
 
@@ -197,39 +297,36 @@ comparison(model)
 knitr::kable(comparison(model), digits=2, row.names = FALSE)
 ```
 
-For this simple mixed model, **all methods return results equal to the ""refit"" method**.
-
-
-
-When interactions are involved, post-hoc methods return different results. However, methods implemented in other softwares perform arguably worse.
-
+#### Bayesian Models
 
-#### Transformation
+```{r message=FALSE, warning=FALSE, eval=FALSE}
+library(rstanarm)
 
-```{r message=FALSE, warning=FALSE, results='hide'}
-model <- lm(Sepal.Length ~ poly(Petal.Width, 2) + poly(Sepal.Width, 2), data=data)
+model <- stan_glm(Sepal.Length ~ Petal.Width + Sepal.Width, data=data)
 comparison(model)
 ```
 ```{r message=FALSE, warning=FALSE, echo=FALSE}
+library(rstanarm)
+model <- stan_glm(Sepal.Length ~ Petal.Width + Sepal.Width, data=data, refresh = 0)
 knitr::kable(comparison(model), digits=2, row.names = FALSE)
 ```
 
-For polynomial transformations, other software become very unreliable.
 
-#### Bayesian Models
+For these simple models, **all methods return results equal to the ""refit"" method** (although the other packages fail).
 
-```{r message=FALSE, warning=FALSE, eval=FALSE}
-library(rstanarm)
 
-model <- stan_glm(Sepal.Length ~ Petal.Width + Sepal.Width, data=data)
+#### Transformation
+
+```{r message=FALSE, warning=FALSE, results='hide'}
+model <- lm(Sepal.Length ~ poly(Petal.Width, 2) + poly(Sepal.Width, 2), data=data)
 comparison(model)
 ```
 ```{r message=FALSE, warning=FALSE, echo=FALSE}
-library(rstanarm)
-model <- stan_glm(Sepal.Length ~ Petal.Width + Sepal.Width, data=data, refresh = 0)
 knitr::kable(comparison(model), digits=2, row.names = FALSE)
 ```
 
+When transformation are involved (e.g., polynomial transformations), **the basic method becomes very unreliable**.
+
 
 
 ### Models with factors
@@ -245,7 +342,6 @@ comparison(model)
 knitr::kable(comparison(model), digits=2, row.names = FALSE)
 ```
 
-When factors are involved, methods that standardize the numeric transformation of factors give different results.
 
 
 #### Logistic Model
@@ -279,19 +375,6 @@ knitr::kable(comparison(model), digits=2, row.names = FALSE)
 ```{r message=FALSE, warning=FALSE}
 library(rstanarm)
 
-model <- stan_glm(Sepal.Length ~ Petal.Width + Group_Sepal.Width, data=data)
-comparison(model)
-```
-```{r message=FALSE, warning=FALSE, echo=FALSE}
-library(rstanarm)
-
-model <- stan_glm(Sepal.Length ~ Petal.Width + Group_Sepal.Width, data=data, refresh = 0, iter = 500)
-knitr::kable(comparison(model), digits=2, row.names = FALSE)
-```
-
-```{r message=FALSE, warning=FALSE}
-library(rstanarm)
-
 model <- stan_lmer(Sepal.Length ~ Petal.Width + Group_Sepal.Width + (1|Species), data=data)
 comparison(model)
 ```
@@ -301,8 +384,15 @@ model <- stan_lmer(Sepal.Length ~ Petal.Width + Group_Sepal.Width + (1|Species),
 knitr::kable(comparison(model), digits=2, row.names = FALSE)
 ```
 
+When factors are involved, the basic method (that standardizes the numeric transformation of factors) give again different results.
+
+
+
 ### Models with interactions
 
+Long story short, coeffcient obtained via **posthoc** standardization (without refitting the model) go berserk when interactions are involved. However, **this is ""normal""**: a regression model estimates coefficient between two variables when the other predictors are at 0 (are *fixed* at 0, that people interpret as *""adjusted for""*). When a standardized data is passed (in the *refit* method), the effects and interactions are estimated at the **means** of the other predictors (because 0 is the mean for a standardized variable). Whereas in posthoc standardization, this coefficient correspond to something different (because the 0 corresponds to something different in standardzed and non-standardized data). In other words, when it comes to interaction, passing standardized data results in a different model, which coefficient have an intrinsically different meaning from unstandardized data. And as [for now](https://github.com/easystats/effectsize/issues/6), we are unable to retrieve one from another.
+
+
 #### Between continuous
 
 ```{r message=FALSE, warning=FALSE, results='hide'}
@@ -345,7 +435,7 @@ knitr::kable(comparison(model), digits=2, row.names = FALSE)
 
 ## Conclusion
 
-Use `refit` if possible, otherwise `smart`.
+Use `refit` if possible, but if no interactions, can use `posthoc` or `smart`.
 
 
 # References",True,True,Documentation / Formatting,6
