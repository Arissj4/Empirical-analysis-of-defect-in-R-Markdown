repo_owner,repo_name,commit_hash,author,author_email,date,committer_name,committer_email,committer_date,message,filenames,touches_rmd,touches_r,touches_r_or_rmd,is_merge,added,deleted,changed,diff,_touch_r,_touch_rmd,bug_category,category_score
oliviergimenez,banana-book,f588cde4d8c6bdb29f58ff1af6b240b40baa86ad,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2025-11-06T13:06:44Z,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2025-11-06T13:06:44Z,"add book cover, and fix ggtern issue",5-move.Rmd;_bookdown_files/banana-book_files/figure-html/betadistribution-1.png;_bookdown_files/banana-book_files/figure-html/bgr-1.png;_bookdown_files/banana-book_files/figure-html/burnin-1.png;_bookdown_files/banana-book_files/figure-html/chain-1.png;_bookdown_files/banana-book_files/figure-html/dag-survival-1.png;_bookdown_files/banana-book_files/figure-html/diagram-stopover-1.pdf;_bookdown_files/banana-book_files/figure-html/diagram-stopover-1.png;_bookdown_files/banana-book_files/figure-html/dirichletdistribution-1.png;_bookdown_files/banana-book_files/figure-html/fig-arrival-prob-1.png;_bookdown_files/banana-book_files/figure-html/fig-mortality-age-1.png;_bookdown_files/banana-book_files/figure-html/fig-stopover-duration-1.png;_bookdown_files/banana-book_files/figure-html/gammadistribution-1.png;_bookdown_files/banana-book_files/figure-html/longchain-1.png;_bookdown_files/banana-book_files/figure-html/traceown-1.png;_bookdown_files/banana-book_files/figure-html/twochains-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-10-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-10-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-11-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-11-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-112-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-113-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-117-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-117-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-118-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-118-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-12-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-120-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-129-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-13-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-132-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-133-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-134-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-138-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-138-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-139-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-139-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-14-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-15-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-16-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-161-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-17-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-18-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-181-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-181-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-19-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-196-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-197-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-199-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-199-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-20-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-200-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-200-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-21-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-219-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-22-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-220-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-220-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-221-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-221-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-222-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-23-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-24-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-24-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-240-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-241-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-242-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-243-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-244-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-25-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-25-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-256-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-257-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-258-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-26-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-26-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-263-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-263-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-267-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-268-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-269-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-27-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-270-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-271-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-278-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-294-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-296-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-297-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-298-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-299-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-3-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-3-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-30-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-300-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-301-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-302-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-31-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-310-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-312-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-314-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-322-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-324-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-336-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-337-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-338-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-339-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-340-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-341-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-342-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-343-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-345-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-346-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-349-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-350-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-353-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-355-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-359-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-360-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-367-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-369-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-372-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-373-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-374-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-375-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-376-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-377-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-379-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-380-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-384-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-387-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-388-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-389-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-391-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-392-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-395-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-397-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-399-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-4-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-4-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-400-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-400-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-401-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-402-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-402-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-404-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-405-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-406-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-407-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-408-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-418-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-419-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-42-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-421-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-422-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-425-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-43-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-435-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-44-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-442-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-45-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-46-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-47-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-49-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-5-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-5-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-50-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-51-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-52-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-53-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-56-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-6-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-60-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-61-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-63-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-65-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-67-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-7-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-79-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-8-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-81-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-9-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-9-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-90-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-91-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-93-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-94-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-97-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-98-1.png;_bookdown_files/banana-book_files/figure-html/viterbiaveragecompute-1.png;_bookdown_files/banana-book_files/figure-html/viterbicomputeaverage-1.png;_bookdown_files/banana-book_files/figure-latex/betadistribution-1.pdf;_bookdown_files/banana-book_files/figure-latex/bgr-1.pdf;_bookdown_files/banana-book_files/figure-latex/burnin-1.pdf;_bookdown_files/banana-book_files/figure-latex/chain-1.pdf;_bookdown_files/banana-book_files/figure-latex/dag-survival-1.pdf;_bookdown_files/banana-book_files/figure-latex/diagram-stopover-1.pdf;_bookdown_files/banana-book_files/figure-latex/dirichletdistribution-1.pdf;_bookdown_files/banana-book_files/figure-latex/fig-arrival-prob-1.pdf;_bookdown_files/banana-book_files/figure-latex/fig-mortality-age-1.pdf;_bookdown_files/banana-book_files/figure-latex/fig-stopover-duration-1.pdf;_bookdown_files/banana-book_files/figure-latex/gammadistribution-1.pdf;_bookdown_files/banana-book_files/figure-latex/longchain-1.pdf;_bookdown_files/banana-book_files/figure-latex/traceown-1.pdf;_bookdown_files/banana-book_files/figure-latex/twochains-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-101-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-11-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-117-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-118-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-119-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-120-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-13-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-135-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-136-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-138-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-139-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-140-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-141-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-15-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-151-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-155-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-156-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-157-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-16-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-160-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-161-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-17-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-170-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-171-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-18-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-181-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-183-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-187-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-190-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-191-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-192-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-196-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-197-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-198-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-199-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-203-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-214-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-218-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-219-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-22-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-220-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-221-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-222-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-223-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-224-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-237-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-238-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-240-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-241-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-242-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-244-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-246-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-256-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-257-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-258-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-26-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-260-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-262-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-264-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-267-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-268-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-269-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-270-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-271-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-272-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-273-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-274-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-278-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-279-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-285-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-286-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-289-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-29-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-290-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-294-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-296-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-297-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-298-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-299-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-30-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-300-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-301-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-302-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-303-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-31-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-310-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-312-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-314-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-315-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-316-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-319-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-32-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-320-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-321-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-328-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-33-1.pdf,True,False,True,False,69,37,106,"---FILE: 5-move.Rmd---
@@ -537,50 +537,82 @@ The Dirichlet distribution extends the Beta distribution multivariate we have se
 
 (ref:captiondirichlet) The Dirichlet distribution as a prior for $(\psi^{11}, \psi^{12}, \psi^{13})$ with vector of parameters $\alpha$. Here all components of $\alpha$ are equal which makes the distribution symmetric, and its mean is $(1/3, 1/3, 1/3)$. When $\alpha = 1$, the prior for the $\psi$'s is uniform (middle panel), unimodal when $\alpha = 10$ (right panel) and concentrated in the corners (0 and 1) when $\alpha = 0.1$ (left panel).
 
+
 ```{r dirichletdistribution, echo = FALSE, message=FALSE, warning=FALSE, fig.cap='(ref:captiondirichlet)'}
-library(gtools) # to make the rdirichlet() function available
-library(ggtern) # to visually represent multidim prob distribution 
-set.seed(123) # for reproducibility
-n <- 1000 # number of values drawn from Dirichlet distribution
+# --- packages
+library(gtools)   # rdirichlet
+library(dplyr)
+library(tibble)
+library(ggplot2)
+
+# --- data (unchanged)
+set.seed(123)
+n <- 1000
 alpha1 <- c(.1, .1, .1)
-p1 <- rdirichlet(n, alpha1)
 alpha2 <- c(1, 1, 1)
-p2 <- rdirichlet(n, alpha2)
 alpha3 <- c(10, 10, 10)
+
+p1 <- rdirichlet(n, alpha1)
+p2 <- rdirichlet(n, alpha2)
 p3 <- rdirichlet(n, alpha3)
-df <- cbind(rbind(p1, p2, p3), c(rep(""alpha = c(0.1, 0.1, 0.1)"", n),
-                                     rep(""alpha = c(1, 1, 1)"", n),
-                                     rep(""alpha = c(10, 10, 10)"", n))) %>%
-  as_tibble() %>%
-  mutate(x = as.numeric(V1),
-         y = as.numeric(V2),
-         z = as.numeric(V3),
-         alpha = V4)
-
-df %>%
-  ggtern(aes(x = x, y = y, z = z)) +
-  stat_density_tern(aes(fill=..level.., alpha=..level..),
-                    geom = 'polygon',
-                    bdl = 0.005) + # a 2D kernel density estimation of the distribution
-  scale_fill_viridis_b() +
-  geom_point(alpha = 0.3, pch = ""+"") +
-  theme_showarrows() +
-  scale_T_continuous(breaks = seq(0, 1, by = 0.2),
-                     labels = seq(0, 1, by = 0.2)) +
-  scale_L_continuous(breaks = seq(0, 1, by = 0.2),
-                     labels = seq(0, 1, by = 0.2)) +
-  scale_R_continuous(breaks = seq(0, 1, by = 0.2),
-                     labels = seq(0, 1, by = 0.2)) +
-  labs(x = """",
-       y = """",
-       z = """",
-       Tarrow = ""psi11"",
-       Larrow = ""psi12"",
-       Rarrow = ""psi13"") +
-  guides(color = ""none"", fill = ""none"", alpha = ""none"") +
-  facet_wrap(~alpha, ncol = 3)
+
+df <- cbind(rbind(p1, p2, p3),
+            c(rep(""alpha = c(0.1, 0.1, 0.1)"", n),
+              rep(""alpha = c(1, 1, 1)"", n),
+              rep(""alpha = c(10, 10, 10)"", n))) |>
+  as_tibble() |>
+  mutate(
+    psi11 = as.numeric(V1),   # top
+    psi12 = as.numeric(V2),   # left
+    psi13 = as.numeric(V3),   # right
+    alpha = V4
+  )
+
+# --- barycentric (psi11, psi12, psi13) -> Cartesian (X,Y)
+# Vertices: Left=(0,0) [psi12], Right=(1,0) [psi13], Top=(0.5, sqrt(3)/2) [psi11]
+tri_h <- sqrt(3)/2
+df_xy <- df |>
+  mutate(
+    S  = psi11 + psi12 + psi13,         # should be 1, but keep for safety
+    X  = 0.5 * (2*psi13 + psi11) / S,
+    Y  = (tri_h * psi11) / S
+  )
+
+# --- triangle boundary for annotation
+triangle <- tibble(
+  X = c(0, 1, 0.5, 0),
+  Y = c(0, 0, tri_h, 0)
+)
+
+# --- plot: filled density (like stat_density_tern) + points + facets
+ggplot(df_xy, aes(X, Y)) +
+  # density ""polygons"" (2D KDE on projected plane)
+  stat_density_2d_filled(contour = TRUE, bins = 12, alpha = 0.9) +
+  # points overlay (light, like your pch = ""+"")
+  geom_point(alpha = 0.25, shape = 3, size = 0.6) +
+  # triangle outline
+  geom_path(data = triangle, aes(X, Y), inherit.aes = FALSE, linewidth = 0.6) +
+  # vertex labels
+  annotate(""text"", x = 0.5, y = tri_h + 0.04, label = ""psi11"", fontface = ""bold"") +
+  annotate(""text"", x = -0.04, y = -0.02,       label = ""psi12"", fontface = ""bold"", hjust = 1) +
+  annotate(""text"", x = 1.04, y = -0.02,        label = ""psi13"", fontface = ""bold"", hjust = 0) +
+  coord_equal(clip = ""off"") +
+  #scale_fill_viridis_d(name = NULL) +
+  scale_fill_viridis_d(option = ""A"", direction = -1) +
+  guides(fill = ""none"") +
+  labs(x = NULL, y = NULL) +
+  theme_void(base_size = 12) +
+  theme(
+    plot.margin = margin(10, 20, 10, 20),
+    strip.text = element_text(face = ""bold""),
+    panel.background = element_rect(fill = ""white"", colour = NA)
+  ) +
+  facet_wrap(~ alpha, ncol = 3)
+
 ```
 
+
+
 Going back to our example, in NIMBLE, we consider a Dirichlet prior for each triplet of movement parameters, from site 1 ($\psi^{11}$, $\psi^{12}$ and $\psi^{13}$), from site 2 ($\psi^{21}$, $\psi^{22}$ and $\psi^{23}$) and from site 3 ($\psi^{31}$, $\psi^{32}$ and $\psi^{33}$). 
 
 We start by setting the scene with comments:",False,True,Visualization / Plotting,6
oliviergimenez,banana-book,0adf0af540350405dfd43ed79e91335b52636cf6,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2025-09-10T18:13:35Z,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2025-09-10T18:13:35Z,fix issues w/ table and kable,6-covariates.Rmd;7-lackoffit.Rmd;8-lifehistory.Rmd;banana-book.log;banana-book_files/figure-html/diagram-stopover-1.pdf;banana-book_files/figure-html/unnamed-chunk-117-1.pdf;banana-book_files/figure-html/unnamed-chunk-118-1.pdf;banana-book_files/figure-html/unnamed-chunk-138-1.pdf;banana-book_files/figure-html/unnamed-chunk-139-1.pdf;banana-book_files/figure-html/unnamed-chunk-181-1.pdf;banana-book_files/figure-latex/betadistribution-1.pdf;banana-book_files/figure-latex/bgr-1.pdf;banana-book_files/figure-latex/burnin-1.pdf;banana-book_files/figure-latex/chain-1.pdf;banana-book_files/figure-latex/dag-survival-1.pdf;banana-book_files/figure-latex/diagram-stopover-1.pdf;banana-book_files/figure-latex/dirichletdistribution-1.pdf;banana-book_files/figure-latex/fig-arrival-prob-1.pdf;banana-book_files/figure-latex/fig-mortality-age-1.pdf;banana-book_files/figure-latex/fig-stopover-duration-1.pdf;banana-book_files/figure-latex/gammadistribution-1.pdf;banana-book_files/figure-latex/longchain-1.pdf;banana-book_files/figure-latex/traceown-1.pdf;banana-book_files/figure-latex/twochains-1.pdf;banana-book_files/figure-latex/unnamed-chunk-11-1.pdf;banana-book_files/figure-latex/unnamed-chunk-117-1.pdf;banana-book_files/figure-latex/unnamed-chunk-118-1.pdf;banana-book_files/figure-latex/unnamed-chunk-138-1.pdf;banana-book_files/figure-latex/unnamed-chunk-139-1.pdf;banana-book_files/figure-latex/unnamed-chunk-15-1.pdf;banana-book_files/figure-latex/unnamed-chunk-16-1.pdf;banana-book_files/figure-latex/unnamed-chunk-181-1.pdf;banana-book_files/figure-latex/unnamed-chunk-197-1.pdf;banana-book_files/figure-latex/unnamed-chunk-221-1.pdf;banana-book_files/figure-latex/unnamed-chunk-222-1.pdf;banana-book_files/figure-latex/unnamed-chunk-242-1.pdf;banana-book_files/figure-latex/unnamed-chunk-244-1.pdf;banana-book_files/figure-latex/unnamed-chunk-258-1.pdf;banana-book_files/figure-latex/unnamed-chunk-270-1.pdf;banana-book_files/figure-latex/unnamed-chunk-271-1.pdf;banana-book_files/figure-latex/unnamed-chunk-297-1.pdf;banana-book_files/figure-latex/unnamed-chunk-30-1.pdf;banana-book_files/figure-latex/unnamed-chunk-300-1.pdf;banana-book_files/figure-latex/unnamed-chunk-301-1.pdf;banana-book_files/figure-latex/unnamed-chunk-31-1.pdf;banana-book_files/figure-latex/unnamed-chunk-314-1.pdf;banana-book_files/figure-latex/unnamed-chunk-342-1.pdf;banana-book_files/figure-latex/unnamed-chunk-343-1.pdf;banana-book_files/figure-latex/unnamed-chunk-345-1.pdf;banana-book_files/figure-latex/unnamed-chunk-346-1.pdf;banana-book_files/figure-latex/unnamed-chunk-349-1.pdf;banana-book_files/figure-latex/unnamed-chunk-359-1.pdf;banana-book_files/figure-latex/unnamed-chunk-373-1.pdf;banana-book_files/figure-latex/unnamed-chunk-47-1.pdf;banana-book_files/figure-latex/unnamed-chunk-50-1.pdf;banana-book_files/figure-latex/unnamed-chunk-51-1.pdf;banana-book_files/figure-latex/unnamed-chunk-52-1.pdf;banana-book_files/figure-latex/unnamed-chunk-56-1.pdf;banana-book_files/figure-latex/unnamed-chunk-79-1.pdf;banana-book_files/figure-latex/viterbiaveragecompute-1.pdf;banana-book_files/figure-latex/viterbicomputeaverage-1.pdf;docs/404.html;docs/banana-book.pdf;docs/banana-book.tex;docs/conclusion.html;docs/covariateschapter.html;docs/crashcourse.html;docs/dispersal.html;docs/hmmcapturerecapture.html;docs/index.html;docs/introduction-4.html;docs/introduction-7.html;docs/introduction.html;docs/intronimble.html;docs/lackoffit.html;docs/libs/kePrint-0.0.1/kePrint.js;docs/libs/lightable-0.0.1/lightable.css;docs/preface.html;docs/references.html;docs/search.json;docs/survival.html;docs/tradeoffs.html;index.Rmd;latex/preamble.tex,True,False,True,False,2285,1436,3721,"---FILE: 6-covariates.Rmd---
@@ -402,6 +402,7 @@ MCMCsummary(out, round = 2)
 ```
 
 which we can arrange as in Table \@ref(tab:ageuncertaintycompare) to compare them with the results obtained by @Gervasi2017:
+
 ```{r ageuncertaintycompare, results='asis', message=FALSE, echo=FALSE}
 library(MCMCvis)
 library(knitr)
@@ -448,10 +449,10 @@ labels <- c(
   ""phiA[2]""    = ""$\\phi_{A,m}$ (adult male)"",
   ""p""          = ""$p$ (detection)"",
   ""pi""         = ""$\\pi$ (cub at first detection)"",
-  ""betaCCC""    = ""$C_{c,cc}$ (cub by both | cub)"",
-  ""betaCCA""    = ""$C_{c,ca}$ (cub by P1 only | cub)"",
-  ""betaACC""    = ""$C_{a,cc}$ (cub by both | adult)"",
-  ""betaACA""    = ""$C_{a,ca}$ (cub by P1 only | adult)""
+  ""betaCCC""    = ""$C_{c,cc}$ (cub by both given cub)"",
+  ""betaCCA""    = ""$C_{c,ca}$ (cub by P1 only given cub)"",
+  ""betaACC""    = ""$C_{a,cc}$ (cub by both given adult)"",
+  ""betaACA""    = ""$C_{a,ca}$ (cub by P1 only given adult)""
 )
 
 tab <- data.frame(
@@ -461,14 +462,29 @@ tab <- data.frame(
   check.names = FALSE
 )
 
-kable(
+library(kableExtra)
+
+kableExtra::kable(
   tab,
   align = c(""c"",""c"",""c""),
   escape = FALSE,
-  caption = ""Comparison of parameter estimates for the same HMM to account for age uncertainty: our NIMBLE fit vs. Gervasi et al. (2017, Table 3). Intervals are 95% credible intervals for NIMBLE and confidence intervals for Gervasi et al.. Detection in Gervasi et al. varies by design/year; I report their overall average.""
-)
+  booktabs = TRUE,
+  caption = ""Comparison of parameter estimates for the same HMM to account for age uncertainty: our NIMBLE fit vs. Gervasi et al. (2017, Table 3).""#,
+#  format = ""latex"",
+#  longtable = TRUE
+) %>%
+  kableExtra::kable_styling(
+    latex_options = c(""repeat_header"", ""striped""), 
+    position = ""center"", 
+    full_width = FALSE,
+    latex_table_env = ""longtable"") 
+#  kableExtra::footnote(general = ""Intervals are 95% credible intervals for NIMBLE and confidence intervals for Gervasi et al.. Detection in #Gervasi et al. varies by design and year; I report their overall average."")
 ```
 
+\justifying
+
+Intervals in Table \@ref(tab:ageuncertaintycompare) are 95% credible intervals for NIMBLE and confidence intervals for @Gervasi2017. Detection in @Gervasi2017 varies by design and year; I report their overall average.
+
 Our NIMBLE fit reproduces the main biological signals reported for the Apennine brown bear. Survival shows the expected ordering, that cubs << adults, and adult females > adult males -- with estimates that closely match the published analysis. The credible/confidence intervals overlap broadly, indicating good agreement.
 
 Our detection estimate aligns with the study's average detection, even though their analysis lets detection vary by design and year rather than assuming a single constant value.
@@ -759,7 +775,7 @@ pr_m <- c(
   ""m[1]"" = sprintf(""%s"", round2(pr_m_vals[1])),
   ""m[2]"" = sprintf(""%s"", round2(pr_m_vals[2])),
   ""m[3]"" = sprintf(""%s"", round2(pr_m_vals[3])),
-  ""m[4]"" = ""time-varying (see caption)""
+  ""m[4]"" = ""time-varying""
 )
 
 # Error rates (mean with SE) ‚Äî rounded
@@ -801,26 +817,34 @@ tab <- data.frame(
   row.names = NULL
 )
 
+library(kableExtra)
+
 # ---- Build caption with explicit m4(t) values ----
 a <- -7.3979
 b <-  0.6258
 T <- 10                       # years reported for p(t) in RUN 6
 t <- 1:T
 m4_pred <- plogis(a + b * t)  # predicted m4(t)
 m4_str  <- paste(sprintf(""%.3f"", m4_pred), collapse = "", "")
-cap <- paste0(
-  ""Comparison of parameter estimates for the same HMM to account for sex uncertainty: our NIMBLE fit vs. Pradel et al. (2008, Table 5, model B no genetically sexed anchors). Intervals are 95% credible intervals for NIMBLE and confidence intervals for Pradel et al.. Our error rates are 1 ‚àí x[i]. Pradel's m's were provided by the main author of the paper himself. Note that m4 is time-varying; the estimates were for t=1,...,"", T, "": "",
-  m4_str, "".""
-)
 
-kable(
+kableExtra::kable(
   tab,
   align = c(""l"",""c"",""c""),
   escape = FALSE,
-  caption = cap
-)
+  booktabs = TRUE,
+  caption = ""Comparison of parameter estimates for the same HMM to account for sex uncertainty: our NIMBLE fit vs. Pradel et al. (2008, Table 5, model B no genetically sexed anchors).""#,
+#  format = ""latex"",
+#  longtable = TRUE
+) %>%
+ kableExtra::kable_styling(latex_options = c(""repeat_header"", ""striped""), 
+                position = ""center"", 
+                full_width = FALSE)
 ```
 
+\justifying
+
+Intervals in Table \@ref(tab:sexuncertainty) are 95% credible intervals for NIMBLE and confidence intervals for @pradel2008sex. Our error rates are `1 ‚àí x[i]`. Pradel's $m$'s were provided by the main author of the paper himself. Note that `m4` was time-varying; the estimates were for $t=1,\ldots,10$: 0.001, 0.002, 0.004, 0.007, 0.014, 0.026, 0.047, 0.084, 0.146, 0.242.
+
 Our NIMBLE fit recovers the main biological signals reported for the Audouin's gulls analysis. Survival shows the expected ordering -- adult females ‚â• adult males -- with broadly overlapping intervals and means that are close to the published model. In our run, the female--male gap is a bit smaller (0.90 vs 0.89), but the direction matches the paper's message (higher female survival).
 
 We used a single, constant detection probability and obtained $p \approx 0.65$, which sits near the middle of the year‚Äêspecific values obtained by the authors (not shown in the paper).

---FILE: 7-lackoffit.Rmd---
@@ -475,13 +475,26 @@ tab <- pradel_avg |>
   arrange(factor(Transition, levels = c(""MM"",""MC"",""CM"",""CC"")),
           factor(Condition, levels = c(""Equal to t-1"",""Not equal to t-1"")))
 
-kable(
+library(kableExtra)
+
+kableExtra::kable(
   tab,
   align = c(""l"",""l"",""c"",""c""),
-  caption = ""Second-order (memory) estimates of transition probabilities. The first column gives the Transition made in $t$ to $t+1$ where M is for mid--Atlantic and C for Chesapeake. The second column gives the Condition that is whether the location at $t+1$ is Equal or Not equal to the location at $t-1$. The Pradel (2005) time-averaged estimates are given in the third column. Our NIMBLE estimates (mean and 95% credible interval) are given in the fourth column. ""
-)
+  escape = FALSE,
+  booktabs = TRUE,
+  caption = ""Second-order (memory) estimates of transition probabilities.""#,
+#  format = ""latex"",
+#  longtable = TRUE
+) %>%
+  kableExtra::kable_styling(latex_options = c(""repeat_header"", ""striped""), 
+                position = ""center"", 
+                full_width = FALSE)
 ```
 
+\justifying
+
+In Table \@ref(tab:memoryres), the first column gives the Transition made in $t$ to $t+1$ where M is for mid--Atlantic and C for Chesapeake. The second column gives the Condition that is whether the location at $t+1$ is Equal or Not equal to the location at $t-1$. The @pradel_multievent_2005 time-averaged estimates are given in the third column. Our NIMBLE estimates (mean and 95% credible interval) are given in the fourth column.
+
 In both analyses, memory is real: for each transition, the probability is higher when the destination at $t+1$ matches where the bird was at $t‚àí1$ ('Equal to $t-1$' rows) than when it doesn't ('Not equal to $t-1$' rows). That's site fidelity or directional return. Our fit mirrors Pradel's fit especially well for staying in Chesapeake (CC, equal: 0.63 in both) and still shows a clear memory signal for staying in mid-Atlantic (MM, 0.50 vs 0.57 when equal). Moves also carry memory: MC is more likely when the bird was in C two steps back (0.33 vs 0.16), and CM shows a weaker but similar pattern (0.10 vs 0.06).
 
 Where we differ is in the directional balance. Relative to Pradel's averages, our model leans more toward Chesapeake: we estimate higher MC probabilities (both equal and not equal; e.g., 0.33 vs 0.27 and 0.16 vs 0.09) and lower CM (equal) (0.10 vs 0.21). We also find a higher chance of staying in C (CC, not equal: 0.57 vs 0.48). Several of these differences are well outside our 95% credible intervals (e.g., CM equal 0.09-0.11 vs 0.21, MC not equal 0.15-0.17 vs 0.09). These discrepancies are likely explained by the difference in model structures: ours assumes constant parameters, whereas Pradel‚Äôs allows them to vary over time. The big picture remains the same, though: movements are second--order and that memory is asymmetric, being strongest for persistence in Chesapeake and for moves toward it.
@@ -722,13 +735,22 @@ tab$`Abs % error` <- round(abs(tab$mean - tab$truth) / pmax(tab$truth, 1e-8) * 1
 out <- tab[, c(""param"", ""truth"", ""Posterior mean (95% CrI)"")]
 names(out) <- c(""Parameter"", ""True value"", ""Posterior mean (95% credible interval)"")
 
+library(kableExtra)
+
 kable(
   out[match(c(""phi"",""pi"",""pp1"",""pp2""), out$Parameter), ],
   align = c(""l"",""c"",""c"",""r"",""r""),
+  booktabs= TRUE,
   caption = ""Comparison of posterior estimates from NIMBLE with the data-generating values for a finite--mixture HMM.""
-)
+) %>%
+  kable_styling(latex_options = c(""repeat_header"", ""striped""), 
+                position = ""center"", 
+                full_width = FALSE, 
+                latex_table_env = ""longtable"")
 ```
 
+\justifying
+
 Why is that? The first issue is that the classes were permuted. In our model, nothing tells NIMBLE that the highly detectable individuals must belong to class A1 and the less detectable ones to class A2. The labeling of the classes is arbitrary. The interpretation only comes afterwards, by inspecting the parameter estimates. Now if we re-calculate $\pi$ as the proportion of individuals in A1 as follows: 
 ```{r}
 samples <- rbind(mcmc.phipmix[[1]], mcmc.phipmix[[2]])
@@ -767,13 +789,22 @@ tab$`Abs % error` <- round(abs(tab$mean - tab$truth) / pmax(tab$truth, 1e-8) * 1
 out <- tab[, c(""param"", ""truth"", ""Posterior mean (95% CrI)"")]
 names(out) <- c(""Parameter"", ""True value"", ""Posterior mean (95% credible interval)"")
 
+library(kableExtra)
+
 kable(
   out[match(c(""phi"",""pi"",""pp1"",""pp2""), out$Parameter), ],
   align = c(""l"",""c"",""c"",""r"",""r""),
+  booktabs = TRUE,
   caption = ""Comparison of posterior estimates from NIMBLE with the data-generating values for a finite--mixture HMM.""
-)
+) %>%
+  kable_styling(latex_options = c(""repeat_header"", ""striped""), 
+                position = ""center"", 
+                full_width = FALSE, 
+                latex_table_env = ""longtable"")
 ```
 
+\justifying
+
 Still, the detection estimates are off. There's a deeper issue here. The HMM formulation we used for capturing heterogeneity creates a limitation: individuals are not allowed to switch between classes over time (e.g., from A1 to A2), because the transition matrix does not permit it. In other words, any individual seen > 1 time (it's detected after the first observation occasion) can *never* change class assignments away from their initial value class assignment. Why this formulation fails? The problem is subtle but fundamental: in a HMM, transitions between states are governed by a Markov process. If the transition matrix says an individual in A1 must stay in A1 (or die), then the individual is permanently locked in that class. As a result, once an individual is assigned to a class through its initial latent state (e.g., A1), it can never change class during sampling. Even worse, any individual seen on multiple occasions (say, years 1 and 4) must stay alive during those years, the latent state cannot 'jump' between classes without violating the transition constraints, therefore, the initial class assignment is fixed forever, and the MCMC sampler cannot explore the alternative class, no matter how much data supports it.
 
 I must confess, I got stuck in that trap, and it was only because I used simulations that I could identify the problem. I then asked the NIMBLE team for help, and Daniel Turek came up with the explanation -- thanks, Daniel!
@@ -1004,13 +1035,22 @@ tab$`Abs % error` <- round(100 * abs(tab$mean - tab$truth) / pmax(tab$truth, 1e-
 out <- tab[, c(""param"",""truth"",""Posterior mean (95% CrI)"")]
 names(out) <- c(""Parameter"",""True value"",""Posterior mean (95% credible interval)"")
 
+library(kableExtra)
+
 kable(
   out[match(c(""phi"",""pi"",""pp1"",""pp2""), out$Parameter), ],
   align = c(""l"",""c"",""c"",""r"",""r""),
+  booktabs = TRUE,
   caption = ""Posterior estimates vs. data-generating values for a finite--mixture HMM, when a marginalized likelihood is used.""
-)
+) %>%
+  kable_styling(latex_options = c(""repeat_header"", ""striped""), 
+                position = ""center"", 
+                full_width = FALSE, 
+                latex_table_env = ""longtable"")
 ```
 
+\justifying
+
 In summary, when modeling unobservable individual heterogeneity (e.g., detection classes) in an HMM, avoid encoding class identity as a dynamic state. Instead, treat it as a fixed latent variable, or marginalize it out. Otherwise, the model is unable to explore the full posterior and will yield biased or unreliable estimates.
 
 A question that remains is the number of classes we should use. In other words, why 2 classes and not 3 or 4? One option is to fit models with more classes and select among them [e.g., @cubaynes2012]. Alternatively, you can take a non-parametric route and let the data decide how many classes are needed; this is relatively easy in NIMBLE [see @turek_bayesian_2021]. 

---FILE: 8-lifehistory.Rmd---
@@ -825,13 +825,22 @@ tab <- data.frame(
     row.names = NULL   
 )
 
+library(kableExtra)
+
 kable(
   tab,
   align = c(""l"",""c"",""c""),
+  booktabs = TRUE,
   caption = ""Age-specific estimates of breeding probabilities. Comparison of our NIMBLE estimates with Couet et al. (2019). 'NR' denotes quantities not reported in the paper. 'NB' is for non-breeding and 'yoy' for young-of-the-year. Adult female detection on the paper side is a rough time-average read by eye from the authors' Figure 3 (2005‚Äì2016).""
-)
+) %>%
+  kable_styling(latex_options = c(""repeat_header"", ""striped""), 
+                position = ""center"", 
+                full_width = FALSE, 
+                latex_table_env = ""longtable"")
 ```
 
+\justifying
+
 Our NIMBLE estimates track the published values closely. Calf survival shows some discrepancies, but credible and confidence intervals overlap, so I would not worry too much. Note also that our model differs slightly: we held adult female detection constant in time, whereas the paper models it as time‚Äêdependent.
 
 Offspring are often missed even when a female is breeding, especially young of the year, which are harder to see than older calves. Offspring detection is well below 1. Adult detection also depends on the female's state: females with a young of the year or 1-year calf are more detectable than non-breeders or those with older calves.

---FILE: docs/404.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.9.0/transition.js""></script><script src=""libs/bs3compat-0.9.0/tabs.js""></script><script src=""libs/bs3compat-0.9.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -112,7 +113,7 @@ <h1>Page not found<a class=""anchor"" aria-label=""anchor"" href=""#page-not-found""><
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-07.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-10.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/banana-book.tex---
@@ -112,6 +112,10 @@
 \usepackage{longtable}
 \usepackage[bf,singlelinecheck=off]{caption}
 
+\usepackage{threeparttable}
+\usepackage{caption}
+\captionsetup[longtable]{justification=justified,singlelinecheck=false}
+
 \usepackage{Alegreya}
 \usepackage[scale=.7]{sourcecodepro}
 
@@ -201,6 +205,9 @@
 \usepackage{makeidx}
 \makeindex
 
+\usepackage{colortbl}
+\usepackage[table]{xcolor}
+
 \urlstyle{tt}
 
 \usepackage{amsthm}
@@ -220,6 +227,8 @@
 \usepackage{arydshln}
 \newtcolorbox{blackbox}{ colback=white, colframe=purple, coltext=black, boxsep=5pt, arc=4pt}
 \usepackage{subfig}
+\usepackage{ragged2e}
+\usepackage[table]{xcolor}
 \usepackage[]{natbib}
 \bibliographystyle{plainnat}
 \usepackage{bookmark}
@@ -244,7 +253,7 @@
 \makeatother
 \subtitle{Theory and case studies in R and NIMBLE}
 \author{Olivier Gimenez}
-\date{2025-08-17}
+\date{2025-09-10}
 
 \begin{document}
 \maketitle
@@ -267,12 +276,28 @@
 \chapter*{Welcome}\label{welcome}
 
 
-Welcome to the online version of the book \emph{Bayesian analysis of capture-recapture data with hidden Markov models: Theory and case studies in R and NIMBLE}. The book is also available in \href{https://github.com/oliviergimenez/banana-book/blob/master/docs/banana-book.pdf}{PDF format} (I still need to fix a lot of issues). Here, I write about three of my favorite research topics -- capture-recapture, hidden Markov models and Bayesian statistics -- let's enjoy this great m/cocktail together üçπ
+Welcome to the online version of the book \emph{Bayesian analysis of capture-recapture data with hidden Markov models: Theory and case studies in R and NIMBLE}. Here, I write about three of my favorite research topics -- capture-recapture, hidden Markov models and Bayesian statistics -- let's enjoy this great m/cocktail together üçπ
 
-I'm currently writing this book, and I welcome any feedback. You may raise an issue \href{https://github.com/oliviergimenez/banana-book/issues}{here}, amend directly the R Markdown file that generated the page you're reading by clicking on the `Edit this page' icon in the right panel, or \href{mailto:olivier.gimenez@cefe.cnrs.fr}{email me}. Many thanks!
+I welcome any feedback. You may raise an issue \href{https://github.com/oliviergimenez/banana-book/issues}{here}, amend directly the R Markdown file that generated the page you're reading by clicking on the `Edit this page' icon in the right panel, or \href{mailto:olivier.gimenez@cefe.cnrs.fr}{email me}. Many thanks!
 
 Olivier Gimenez. Written in Montpellier, France and Athens, Greece.
-Last updated: August 17, 2025
+Last updated: September 10, 2025
+
+\section*{How to cite}\label{how-to-cite}
+
+
+Gimenez, O. 2026. Bayesian analysis of capture-recapture data with hidden Markov models: Theory and case studies in R and NIMBLE. Chapman \& Hall/CRC Interdisciplinary Statistics series.
+
+\begin{Shaded}
+\begin{Highlighting}[]
+\VariableTok{@book}\NormalTok{\{}\OtherTok{gimenez2026}\NormalTok{,}
+  \DataTypeTok{title}\NormalTok{ = \{Bayesian Analysis of Capture{-}Recapture Data with Hidden \{\{Markov\}\} Models: \{\{Theory\}\} and Case Studies in \{\{R\}\} and \{\{NIMBLE\}\}\},}
+  \DataTypeTok{author}\NormalTok{ = \{Gimenez, Olivier\},}
+  \DataTypeTok{year}\NormalTok{ = \{2026\},}
+  \DataTypeTok{publisher}\NormalTok{ = \{Chapman \& Hall/CRC Interdisciplinary Statistics series\}}
+\NormalTok{\}}
+\end{Highlighting}
+\end{Shaded}
 
 \section*{License}\label{license}
 
@@ -349,7 +374,7 @@ \section*{How this book was written}\label{how-this-book-was-written}
 ggtern & 3.5.0 & CRAN (R 4.5.0) \\
 gtools & 3.9.5 & CRAN (R 4.5.0) \\
 here & 1.0.1 & CRAN (R 4.5.0) \\
-janitor & NA & NA \\
+janitor & 2.2.1 & CRAN (R 4.5.0) \\
 magick & 2.8.7 & CRAN (R 4.5.0) \\
 MCMCvis & 0.16.3 & CRAN (R 4.5.0) \\
 nimble & 1.3.0 & CRAN (R 4.5.0) \\
@@ -415,7 +440,7 @@ \part{Foundations}\label{part-foundations}
 \chapter*{Introduction}\label{introduction}
 
 
-This first part \texttt{Foundations} is aimed at getting you up-to-speed with Bayesian statistics, NIMBLE, and hidden Markov models.
+This first part \texttt{Foundations} is aimed at getting you up-to-speed with Bayesian statistics, NIMBLE, and hidden Markov models. The code is available at \url{https://github.com/oliviergimenez/banana-book/tree/master/appendix}.
 
 \chapter{Bayesian statistics \& MCMC}\label{crashcourse}
 
@@ -501,11 +526,11 @@ \section{Approximating posteriors via numerical integration}\label{numerical-app
 \NormalTok{df }\SpecialCharTok{\%\textgreater{}\%}
   \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+} 
   \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ survival, }\AttributeTok{y =}\NormalTok{ likelihood) }\SpecialCharTok{+} 
-  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{size =} \FloatTok{1.5}\NormalTok{)}
+  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{linewidth =} \FloatTok{1.5}\NormalTok{)}
 \end{Highlighting}
 \end{Shaded}
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-33-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-11-1.pdf}}
 
 This is the binomial likelihood with \(n = 57\) released animals and \(y = 19\) survivors after winter. The value of survival (on the x-axis) that corresponds to the maximum of the likelihood function (on the y-axis) is the MLE, or the proportion of success in this example, close to 0.33.
 
@@ -543,11 +568,11 @@ \section{Approximating posteriors via numerical integration}\label{numerical-app
 \NormalTok{numerical\_posterior }\SpecialCharTok{\%\textgreater{}\%}
   \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
   \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ survival, }\AttributeTok{y =}\NormalTok{ posterior) }\SpecialCharTok{+} 
-  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{size =} \FloatTok{1.5}\NormalTok{)}
+  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{linewidth =} \FloatTok{1.5}\NormalTok{)}
 \end{Highlighting}
 \end{Shaded}
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-37-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-15-1.pdf}}
 
 How good is our numerical approximation of survival posterior distribution? Ideally, we would want to compare the approximation to the true posterior distribution. Although a closed-form expression for the posterior distribution is in general intractable, when you combine a binomial likelihood together with a beta distribution as a prior, then the posterior distribution is also a beta distribution, which makes it amenable to all sorts of exact calculations. We say that the beta distribution is the conjugate prior distribution for the binomial distribution. The beta distribution is continuous between 0 and 1, and extends the uniform distribution to situations where not all outcomes are equally likely. It has two parameters \(a\) and \(b\) that control its shape (Figure \ref{fig:betadistribution}).
 
@@ -579,7 +604,7 @@ \section{Approximating posteriors via numerical integration}\label{numerical-app
 \end{Highlighting}
 \end{Shaded}
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-38-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-16-1.pdf}}
 
 Clearly, the exact (dashed line) vs.~numerical approximation (continuous line) of winter survival posterior distribution are indistinguishable, suggesting that the numerical approximation is more than fine.
 
@@ -611,7 +636,7 @@ \subsection{Monte Carlo integration}\label{monte-carlo-integration}
 \begin{Highlighting}[]
 \NormalTok{sample\_from\_posterior }\OtherTok{\textless{}{-}} \FunctionTok{rbeta}\NormalTok{(}\DecValTok{1000}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{39}\NormalTok{) }\CommentTok{\# draw 1000 values from posterior survival beta(20,39)}
 \FunctionTok{mean}\NormalTok{(sample\_from\_posterior) }\CommentTok{\# compute mean with Monte Carlo integration}
-\DocumentationTok{\#\# [1] 0.3399}
+\DocumentationTok{\#\# [1] 0.3421}
 \end{Highlighting}
 \end{Shaded}
 
@@ -630,7 +655,7 @@ \subsection{Monte Carlo integration}\label{monte-carlo-integration}
 \begin{Highlighting}[]
 \FunctionTok{quantile}\NormalTok{(sample\_from\_posterior, }\AttributeTok{probs =} \FunctionTok{c}\NormalTok{(}\FloatTok{2.5}\SpecialCharTok{/}\DecValTok{100}\NormalTok{, }\FloatTok{97.5}\SpecialCharTok{/}\DecValTok{100}\NormalTok{))}
 \DocumentationTok{\#\#   2.5\%  97.5\% }
-\DocumentationTok{\#\# 0.2230 0.4623}
+\DocumentationTok{\#\# 0.2258 0.4671}
 \end{Highlighting}
 \end{Shaded}
 
@@ -826,7 +851,7 @@ \subsection{Metropolis algorithm}\label{metropolis-algorithm}
 
 In this visualisation, remember that our Markov chain starts at value 0.5. The steps or iterations are on the x-axis, and samples on the y-axis. This graphical representation is called a trace plot.
 
-The acceptance probability is the average number of times we accepted a candidated value, which is 0.44 and almost satisfying.
+The acceptance probability is the average number of times we accepted a candidate value, which is 0.44 and almost satisfying.
 
 To make our life easier and avoid repeating the same lines of code again and again, let's make a function out of the code we have written so far:
 
@@ -990,7 +1015,7 @@ \subsection{Chain length}\label{chain-length}
 \end{Highlighting}
 \end{Shaded}
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-52-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-30-1.pdf}}
 
 Small and big moves in the left and right panels provide high correlations between successive observations of the Markov chain, whereas a standard deviation of 1 in the center panel allows efficient exploration of the parameter space. The movement around the parameter space is referred to as \emph{mixing}. Mixing is bad when the chain makes small and big moves, and good otherwise.
 
@@ -1008,7 +1033,7 @@ \subsection{Chain length}\label{chain-length}
 \end{Highlighting}
 \end{Shaded}
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-53-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-31-1.pdf}}
 
 In the left and right panels, autocorrelation is strong, decreases slowly with increasing lag and mixing is bad. In the center panel, autocorrelation is weak, decreases rapidly with increasing lag and mixing is good.
 
@@ -1324,7 +1349,7 @@ \section{Getting started}\label{start-nimble}
 \end{Highlighting}
 \end{Shaded}
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-69-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-47-1.pdf}}
 
 There are less painful ways of doing posterior inference. In this book, I will use the R package \texttt{MCMCvis} to summarise and visualize MCMC outputs, but there are other perfectly valid options out there like \texttt{ggmcmc}, \texttt{bayesplot} and \texttt{basicMCMCplots}.
 
@@ -1356,7 +1381,7 @@ \section{Getting started}\label{start-nimble}
 \end{Highlighting}
 \end{Shaded}
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-72-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-50-1.pdf}}
 
 The point represents the posterior median, the thick line is the 50\% credible interval and the thin line the 95\% credible interval.
 
@@ -1371,7 +1396,7 @@ \section{Getting started}\label{start-nimble}
 \end{Highlighting}
 \end{Shaded}
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-73-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-51-1.pdf}}
 We use the trace and density plots for assessing convergence and get an idea of whether there may be any estimation issues (see Section \ref{convergence-diag}).
 
 You can also add the diagnostics of convergence we discussed in the previous chapter:
@@ -1387,7 +1412,7 @@ \section{Getting started}\label{start-nimble}
 \end{Highlighting}
 \end{Shaded}
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-74-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-52-1.pdf}}
 
 We calculated lifespan directly in our model with \texttt{lifespan\ \textless{}-\ -1/log(theta)}. But you can also calculate this quantity from outside NIMBLE. This is a nice by-product of using MCMC simulations: You can obtain the posterior distribution of any quantity that is a function of your model parameters by applying this function to samples from the posterior distribution of these parameters. Especially when working with big models/data, it is recommended to keep any calculations that can be made ``post-hoc'' using the posterior samples outside of NIMBLE as this lessens memory load. In our example, all you need is samples from the posterior distribution of \texttt{theta}, which we pool between the three chains with:
 
@@ -1431,7 +1456,7 @@ \section{Getting started}\label{start-nimble}
 \end{Highlighting}
 \end{Shaded}
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-78-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-56-1.pdf}}
 
 Now you're good to go. For convenience I have summarized the steps above in the box below. The NIMBLE workflow provided with \texttt{nimbleMCMC()} allows you to build models and make inference. This is what you can achieve with other software like WinBUGS or JAGS.
 
@@ -1852,7 +1877,7 @@ \section{Under the hood}\label{under-the-hood}
 \end{Highlighting}
 \end{Shaded}
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-101-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-79-1.pdf}}
 
 Second we compile the model with \texttt{compileNimble()}:
 
@@ -2684,11 +2709,11 @@ \subsection{Assumptions}\label{assumptions}
 
 Our Markov process can be represented this way:
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-139-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-117-1.pdf}}
 
 An example of this Markov process is, for example:
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-140-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-118-1.pdf}}
 
 Here the animal remains alive over the first two time intervals \((z_{i,1} = z_{i,2} = z_{i,3} = 1)\) with probability \(\phi\) until it dies over the fourth time interval \((z_{i,4} = 2)\) with probability \(1-\phi\) then remains dead from then onwards \((z_{i,5} = 2)\) with probability 1.
 
@@ -3198,7 +3223,7 @@ \subsection{Hidden Markov model}\label{hidden-markov-model}
 
 Our hidden Markov model can be represented this way:
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-160-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-138-1.pdf}}
 
 States \(z\) are in gray. Observations \(y\) are in white. All individuals are first captured in the first winter \(t = 1\), and are therefore all alive \(z_1 = 1\) and detected \(y_1 = 2\).
 
@@ -3209,7 +3234,7 @@ \subsection{Hidden Markov model}\label{hidden-markov-model}
 
 Have a look to the example below, in which an individual is detected at first sampling occasion, detected again, then missed for the rest of the study. While on occasion \(t=3\) that individual was alive \(z_3=1\) and went undetected \(y_3=1\), on occasions \(t=4\) and \(t=5\) it went undetected \(y_4=y_5=1\) because it was dead \(z_4=z_5=2\). Because we condition on first detection, the link between state and observation at \(t=1\) is deterministic and \(p = 1\).
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-161-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-139-1.pdf}}
 
 \subsection{Likelihood}\label{likelihoodhmm}
 
@@ -3455,7 +3480,7 @@ \section{Fitting HMM with NIMBLE}\label{fittinghmmnimble}
 \end{Shaded}
 
 \begin{verbatim}
-## Time difference of 25.9 secs
+## Time difference of 56.2 secs
 \end{verbatim}
 
 We can have a look to numerical summaries:
@@ -3767,7 +3792,7 @@ \subsubsection{Do it yourself}\label{diymarginalisation}
 \DocumentationTok{\#\# |{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}|}
 \NormalTok{end\_time }\OtherTok{\textless{}{-}} \FunctionTok{Sys.time}\NormalTok{()}
 \NormalTok{end\_time }\SpecialCharTok{{-}}\NormalTok{ start\_time}
-\DocumentationTok{\#\# Time difference of 22.57 secs}
+\DocumentationTok{\#\# Time difference of 1.002 mins}
 \end{Highlighting}
 \end{Shaded}
 
@@ -3872,7 +3897,7 @@ \subsubsection{\texorpdfstring{Do it with \texttt{nimbleEcology}}{Do it with nim
 \DocumentationTok{\#\# |{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}|}
 \NormalTok{end\_time }\OtherTok{\textless{}{-}} \FunctionTok{Sys.time}\NormalTok{()}
 \NormalTok{end\_time }\SpecialCharTok{{-}}\NormalTok{ start\_time}
-\DocumentationTok{\#\# Time difference of 26.19 secs}
+\DocumentationTok{\#\# Time difference of 1.18 mins}
 \end{Highlighting}
 \end{Shaded}
 
@@ -4044,7 +4069,7 @@ \section{Pooled encounter histories}\label{pooled-likelihood}
 \DocumentationTok{\#\# |{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}|}
 \NormalTok{end\_time }\OtherTok{\textless{}{-}} \FunctionTok{Sys.time}\NormalTok{()}
 \NormalTok{end\_time }\SpecialCharTok{{-}}\NormalTok{ start\_time}
-\DocumentationTok{\#\# Time difference of 22.81 secs}
+\DocumentationTok{\#\# Time difference of 1.015 mins}
 \FunctionTok{MCMCsummary}\NormalTok{(mcmc.output, }\AttributeTok{round =} \DecValTok{2}\NormalTok{)}
 \DocumentationTok{\#\#     mean   sd 2.5\%  50\% 97.5\% Rhat n.eff}
 \DocumentationTok{\#\# p   0.61 0.06 0.49 0.61  0.72    1  1455}
@@ -4319,7 +4344,7 @@ \part{Transitions}\label{part-transitions}
 \chapter*{Introduction}\label{introduction-4}
 
 
-This second part \texttt{Transitions} will teach you all about capture-recapture models for open populations, with reproducible R code to ease the learning process.
+This second part \texttt{Transitions} will teach you all about capture-recapture models for open populations, with reproducible R code to ease the learning process. The code and data are available at \url{https://github.com/oliviergimenez/banana-book/tree/master/appendix}.
 
 \chapter{Alive and dead}\label{survival}
 
@@ -4331,7 +4356,7 @@ \section{The Cormack-Jolly-Seber (CJS) model}\label{the-cormack-jolly-seber-cjs-
 
 In Chapter \ref{hmmcapturerecapture}, we introduced a capture-recapture model with constant survival and detection probabilities which we formulated as a HMM and fitted to data in NIMBLE. Historically, however, it was a slightly more complicated model that was first proposed -- the so-called Cormack-Jolly-Seber (CJS) model -- in which survival and recapture probabilities are time-varying. This feature of the CJS model is useful to account for variation due to environmental conditions in survival or to sampling effort in detection. Schematically the CJS model can be represented this way:
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-203-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-181-1.pdf}}
 
 Note that the states (in gray) and the observations (in white) do not change. We still have \(z = 1\) for alive, \(z = 2\) for dead, \(y = 1\) for non-detected, and \(y = 2\) for detected.
 
@@ -4362,27 +4387,30 @@ \section{Capture-recapture data}\label{crdataeg}
 
 \begin{Shaded}
 \begin{Highlighting}[]
-\NormalTok{dipper }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{""dat/dipper.csv""}\NormalTok{)}
+\NormalTok{dipper }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{""dipper.csv""}\NormalTok{)}
 \NormalTok{dipper}
-\DocumentationTok{\#\# \# A tibble: 294 x 9}
-\DocumentationTok{\#\#    year\_1981 year\_1982 year\_1983 year\_1984 year\_1985}
-\DocumentationTok{\#\#        \textless{}dbl\textgreater{}     \textless{}dbl\textgreater{}     \textless{}dbl\textgreater{}     \textless{}dbl\textgreater{}     \textless{}dbl\textgreater{}}
-\DocumentationTok{\#\#  1         1         1         1         1         1}
-\DocumentationTok{\#\#  2         1         1         1         1         1}
-\DocumentationTok{\#\#  3         1         1         1         1         0}
-\DocumentationTok{\#\#  4         1         1         1         1         0}
-\DocumentationTok{\#\#  5         1         1         0         1         1}
-\DocumentationTok{\#\#  6         1         1         0         0         0}
-\DocumentationTok{\#\#  7         1         1         0         0         0}
-\DocumentationTok{\#\#  8         1         1         0         0         0}
-\DocumentationTok{\#\#  9         1         1         0         0         0}
-\DocumentationTok{\#\# 10         1         1         0         0         0}
-\DocumentationTok{\#\# \# i 284 more rows}
-\DocumentationTok{\#\# \# i 4 more variables: year\_1986 \textless{}dbl\textgreater{}, year\_1987 \textless{}dbl\textgreater{},}
-\DocumentationTok{\#\# \#   sex \textless{}chr\textgreater{}, wing\_length \textless{}dbl\textgreater{}}
 \end{Highlighting}
 \end{Shaded}
 
+\begin{verbatim}
+## # A tibble: 294 x 9
+##    year_1981 year_1982 year_1983 year_1984 year_1985
+##        <dbl>     <dbl>     <dbl>     <dbl>     <dbl>
+##  1         1         1         1         1         1
+##  2         1         1         1         1         1
+##  3         1         1         1         1         0
+##  4         1         1         1         1         0
+##  5         1         1         0         1         1
+##  6         1         1         0         0         0
+##  7         1         1         0         0         0
+##  8         1         1         0         0         0
+##  9         1         1         0         0         0
+## 10         1         1         0         0         0
+## # i 284 more rows
+## # i 4 more variables: year_1986 <dbl>, year_1987 <dbl>,
+## #   sex <chr>, wing_length <dbl>
+\end{verbatim}
+
 The first seven columns are years in which Gilbert went on the field and captured the birds. A 0 stands for a non-detection, and a 1 for a detection. The eighth column informs on the sex of the bird, with F for female and M for male. The last column gives a measure wing length the first time a bird was captured.
 
 \section{Fitting the CJS model to the dipper data with NIMBLE}\label{fitting-the-cjs-model-to-the-dipper-data-with-nimble}
@@ -4548,18 +4576,18 @@ \section{Fitting the CJS model to the dipper data with NIMBLE}\label{fitting-the
 \begin{Highlighting}[]
 \FunctionTok{MCMCsummary}\NormalTok{(mcmc.phitpt, }\AttributeTok{params =} \FunctionTok{c}\NormalTok{(}\StringTok{""phi""}\NormalTok{,}\StringTok{""p""}\NormalTok{), }\AttributeTok{round =} \DecValTok{2}\NormalTok{)}
 \DocumentationTok{\#\#        mean   sd 2.5\%  50\% 97.5\% Rhat n.eff}
-\DocumentationTok{\#\# phi[1] 0.73 0.14 0.46 0.72  0.99 1.02   199}
-\DocumentationTok{\#\# phi[2] 0.45 0.07 0.32 0.44  0.59 1.02   410}
-\DocumentationTok{\#\# phi[3] 0.48 0.06 0.35 0.48  0.59 1.01   506}
-\DocumentationTok{\#\# phi[4] 0.63 0.06 0.52 0.63  0.75 1.03   415}
-\DocumentationTok{\#\# phi[5] 0.60 0.06 0.49 0.60  0.72 1.01   365}
-\DocumentationTok{\#\# phi[6] 0.74 0.13 0.51 0.74  0.97 1.10    38}
-\DocumentationTok{\#\# p[1]   0.66 0.14 0.38 0.67  0.89 1.01   344}
-\DocumentationTok{\#\# p[2]   0.87 0.08 0.68 0.89  0.98 1.02   249}
-\DocumentationTok{\#\# p[3]   0.88 0.07 0.73 0.89  0.97 1.02   307}
-\DocumentationTok{\#\# p[4]   0.87 0.06 0.74 0.88  0.96 1.05   333}
-\DocumentationTok{\#\# p[5]   0.90 0.05 0.77 0.91  0.98 1.01   224}
-\DocumentationTok{\#\# p[6]   0.72 0.13 0.50 0.72  0.97 1.08    37}
+\DocumentationTok{\#\# phi[1] 0.72 0.13 0.45 0.72  0.96 1.00   553}
+\DocumentationTok{\#\# phi[2] 0.45 0.07 0.32 0.45  0.60 1.01  1175}
+\DocumentationTok{\#\# phi[3] 0.48 0.06 0.36 0.48  0.60 1.00  1320}
+\DocumentationTok{\#\# phi[4] 0.63 0.06 0.51 0.63  0.75 1.01  1041}
+\DocumentationTok{\#\# phi[5] 0.60 0.06 0.49 0.60  0.71 1.01  1030}
+\DocumentationTok{\#\# phi[6] 0.70 0.14 0.49 0.69  0.97 1.00    86}
+\DocumentationTok{\#\# p[1]   0.67 0.13 0.39 0.67  0.90 1.00   923}
+\DocumentationTok{\#\# p[2]   0.87 0.08 0.68 0.88  0.98 1.00   690}
+\DocumentationTok{\#\# p[3]   0.88 0.06 0.73 0.89  0.97 1.00   840}
+\DocumentationTok{\#\# p[4]   0.88 0.06 0.75 0.89  0.96 1.02   860}
+\DocumentationTok{\#\# p[5]   0.90 0.05 0.79 0.91  0.98 1.01   740}
+\DocumentationTok{\#\# p[6]   0.76 0.14 0.51 0.77  0.98 1.00    95}
 \end{Highlighting}
 \end{Shaded}
 
@@ -4579,7 +4607,7 @@ \section{Fitting the CJS model to the dipper data with NIMBLE}\label{fitting-the
 \end{Highlighting}
 \end{Shaded}
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-218-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-197-1.pdf}}
 
 Clearly mixing (left panel in the plot above) is bad and there is a big overlap between the prior and the posterior for this parameter (right panel) suggesting that its prior was not well updated with the data. What is going on? If you could inspect the likelihood of the CJS model, you would realize that these two parameters \(\phi_6\) and \(p_7\) appear only as the product \(\phi_6 p_7\) and cannot be estimated separately. In other words, one of these parameters is redundant, and you'd need an extra sampling occasion to be able to disentangle them. This is not a big issue as long as you're aware of it and you do not attempt to ecologically interpret these parameters.
 
@@ -4631,7 +4659,7 @@ \section{CJS model derivatives}\label{cjsderivatives}
 \CommentTok{\# parameters to monitor}
 \NormalTok{parameters.to.save }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{""phi""}\NormalTok{, }\StringTok{""p""}\NormalTok{)}
 \CommentTok{\# MCMC details}
-\NormalTok{n.iter }\OtherTok{\textless{}{-}} \DecValTok{2500}
+\NormalTok{n.iter }\OtherTok{\textless{}{-}} \DecValTok{5000}
 \NormalTok{n.burnin }\OtherTok{\textless{}{-}} \DecValTok{1000}
 \NormalTok{n.chains }\OtherTok{\textless{}{-}} \DecValTok{2}
 \CommentTok{\# run NIMBLE}
@@ -4650,8 +4678,8 @@ \section{CJS model derivatives}\label{cjsderivatives}
 \CommentTok{\# numerical summaries}
 \FunctionTok{MCMCsummary}\NormalTok{(mcmc.phip, }\AttributeTok{round =} \DecValTok{2}\NormalTok{)}
 \DocumentationTok{\#\#     mean   sd 2.5\%  50\% 97.5\% Rhat n.eff}
-\DocumentationTok{\#\# p   0.89 0.03 0.83 0.90  0.94 1.02   231}
-\DocumentationTok{\#\# phi 0.56 0.02 0.51 0.56  0.61 1.00   595}
+\DocumentationTok{\#\# p   0.90 0.03 0.83 0.90  0.94 1.00   661}
+\DocumentationTok{\#\# phi 0.56 0.02 0.51 0.56  0.61 1.01  1633}
 \end{Highlighting}
 \end{Shaded}
 
@@ -4690,13 +4718,13 @@ \section{CJS model derivatives}\label{cjsderivatives}
 
 \begin{verbatim}
 ##        mean   sd 2.5%  50% 97.5% Rhat n.eff
-## phi[1] 0.63 0.10 0.42 0.63  0.82 1.04   564
-## phi[2] 0.46 0.06 0.35 0.46  0.59 1.01   629
-## phi[3] 0.48 0.05 0.37 0.48  0.59 1.00   610
-## phi[4] 0.62 0.06 0.51 0.62  0.73 1.00   553
-## phi[5] 0.61 0.05 0.50 0.61  0.72 1.00   568
-## phi[6] 0.59 0.05 0.48 0.59  0.69 1.03   463
-## p      0.89 0.03 0.82 0.89  0.95 1.04   211
+## phi[1] 0.63 0.11 0.41 0.63  0.84    1  1407
+## phi[2] 0.46 0.07 0.33 0.46  0.60    1  1350
+## phi[3] 0.48 0.06 0.37 0.48  0.59    1  1586
+## phi[4] 0.62 0.06 0.51 0.62  0.73    1  1528
+## phi[5] 0.61 0.06 0.50 0.61  0.71    1  1463
+## phi[6] 0.59 0.06 0.48 0.59  0.71    1  1101
+## p      0.89 0.03 0.82 0.89  0.94    1   595
 \end{verbatim}
 
 Now the model with time-varying detection and constant survival, for which the NIMBLE code has a constant over time transition matrix:
@@ -4734,13 +4762,13 @@ \section{CJS model derivatives}\label{cjsderivatives}
 
 \begin{verbatim}
 ##      mean   sd 2.5%  50% 97.5% Rhat n.eff
-## phi  0.56 0.03 0.52 0.56  0.61 1.02   381
-## p[1] 0.75 0.12 0.48 0.77  0.93 1.03   452
-## p[2] 0.85 0.08 0.68 0.86  0.97 1.02   359
-## p[3] 0.85 0.07 0.69 0.85  0.96 1.00   316
-## p[4] 0.89 0.05 0.77 0.89  0.97 1.00   412
-## p[5] 0.91 0.04 0.82 0.92  0.98 1.00   376
-## p[6] 0.90 0.07 0.73 0.91  1.00 1.07   111
+## phi  0.56 0.03 0.51 0.56  0.61 1.00  1296
+## p[1] 0.74 0.12 0.49 0.74  0.93 1.00  1369
+## p[2] 0.84 0.08 0.66 0.85  0.98 1.01   744
+## p[3] 0.84 0.07 0.68 0.85  0.96 1.00   722
+## p[4] 0.89 0.05 0.77 0.89  0.97 1.00   962
+## p[5] 0.92 0.04 0.81 0.92  0.98 1.00  1123
+## p[6] 0.90 0.07 0.74 0.91  1.00 1.01   378
 \end{verbatim}
 
 We note that these two models do no longer have parameter redundancy issues.
@@ -4801,8 +4829,8 @@ \section{CJS model derivatives}\label{cjsderivatives}
 \CommentTok{\# numerical summaries}
 \FunctionTok{MCMCsummary}\NormalTok{(mcmc.phip.nimbleecology, }\AttributeTok{round =} \DecValTok{2}\NormalTok{)}
 \DocumentationTok{\#\#     mean   sd 2.5\%  50\% 97.5\% Rhat n.eff}
-\DocumentationTok{\#\# p   0.89 0.03 0.84 0.90  0.94 1.02   672}
-\DocumentationTok{\#\# phi 0.56 0.02 0.52 0.56  0.61 1.00   716}
+\DocumentationTok{\#\# p   0.90 0.03 0.83 0.90  0.94 1.00   668}
+\DocumentationTok{\#\# phi 0.56 0.02 0.51 0.56  0.61 1.01   723}
 \end{Highlighting}
 \end{Shaded}
 
@@ -4849,10 +4877,10 @@ \section{Model comparison with WAIC}\label{waic}
 
 \begin{verbatim}
 ##                                         model  WAIC
-## 1          both survival & detection constant 265.9
-## 2 time-dependent survival, constant detection 277.6
-## 3 constant survival, time-dependent detection 270.2
-## 4    both survival & detection time-dependent 308.8
+## 1          both survival & detection constant 266.7
+## 2 time-dependent survival, constant detection 273.0
+## 3 constant survival, time-dependent detection 270.9
+## 4    both survival & detection time-dependent 308.9
 \end{verbatim}
 
 Lower values of WAIC imply higher predictive accuracy, thefore we would favor model with constant parameters.
@@ -5047,6 +5075,16 @@ \subsubsection{Discrete}\label{discrete}
 \end{Highlighting}
 \end{Shaded}
 
+The MCMC details:
+
+\begin{Shaded}
+\begin{Highlighting}[]
+\NormalTok{n.iter }\OtherTok{\textless{}{-}} \DecValTok{5000}
+\NormalTok{n.burnin }\OtherTok{\textless{}{-}} \DecValTok{1000}
+\NormalTok{n.chains }\OtherTok{\textless{}{-}} \DecValTok{2}
+\end{Highlighting}
+\end{Shaded}
+
 We're all set, and we run NIMBLE:
 
 \begin{Shaded}
@@ -5115,7 +5153,7 @@ \subsubsection{Discrete}\label{discrete}
 \end{Highlighting}
 \end{Shaded}
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-241-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-221-1.pdf}}
 
 Now if you go for a lower standard deviation for the intercept prior (left figure below), e.g.~1.5, the prior on survival is non-informative, looking like a uniform distribution between 0 and 1 (right figure below):
 
@@ -5139,7 +5177,7 @@ \subsubsection{Discrete}\label{discrete}
 \end{Highlighting}
 \end{Shaded}
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-242-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-222-1.pdf}}
 
 Now let's go back to our model. We first define our flood covariate with 0 if nonflood year, and 1 if flood year:
 
@@ -5402,7 +5440,7 @@ \subsubsection{Continuous}\label{continuous}
 \end{Highlighting}
 \end{Shaded}
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-262-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-242-1.pdf}}
 
 The posterior distribution of the slope (\texttt{beta{[}2{]}}) is centered on negative values, suggesting that as water flow increases, survival decreases.
 
@@ -5414,7 +5452,7 @@ \subsubsection{Continuous}\label{continuous}
 \end{Highlighting}
 \end{Shaded}
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-264-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-244-1.pdf}}
 
 Survival between 1982 and 1983 (\texttt{phi{[}2{]}}) was greatly affected and much lower than on average. This decrease corresponds to the high water flow in 1983 and the flood. These results are in line with our previous findings obtained by considering a discrete covariate for nonflood vs.~flood years.
 
@@ -5613,7 +5651,7 @@ \subsubsection{Continuous}\label{continuous-1}
 \end{Highlighting}
 \end{Shaded}
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-278-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-258-1.pdf}}
 
 The flat relationship between survival and wing length is confirmed.
 
@@ -5690,6 +5728,16 @@ \subsection{Several covariates}\label{several-covariates}
 \end{Highlighting}
 \end{Shaded}
 
+The MCMC details (note that we need to increase the number of iterations to achieve satisfying effective sample sizes):
+
+\begin{Shaded}
+\begin{Highlighting}[]
+\NormalTok{n.iter }\OtherTok{\textless{}{-}} \DecValTok{5000}\SpecialCharTok{*}\DecValTok{4}
+\NormalTok{n.burnin }\OtherTok{\textless{}{-}} \DecValTok{1000}
+\NormalTok{n.chains }\OtherTok{\textless{}{-}} \DecValTok{2}
+\end{Highlighting}
+\end{Shaded}
+
 And now we run NIMBLE:
 
 \begin{Shaded}
@@ -5715,10 +5763,10 @@ \subsection{Several covariates}\label{several-covariates}
 
 \begin{verbatim}
 ##          mean   sd  2.5%   50% 97.5% Rhat n.eff
-## beta[1]  0.47 0.24 -0.02  0.48  0.94 1.01   102
-## beta[2] -0.43 0.43 -1.28 -0.44  0.46 1.01    85
-## beta[3] -0.19 0.20 -0.60 -0.19  0.22 1.00   106
-## p        0.89 0.03  0.83  0.90  0.94 1.01   643
+## beta[1]  0.52 0.24  0.05  0.52  0.99    1   466
+## beta[2] -0.53 0.43 -1.37 -0.53  0.30    1   447
+## beta[3] -0.25 0.21 -0.65 -0.25  0.16    1   530
+## p        0.90 0.03  0.83  0.90  0.95    1  3141
 \end{verbatim}
 
 The slope \texttt{beta{[}3{]}} is the same for both males and females. Although its posterior mean is negative, its crebible interval suggests that its posterior distribution largely encompasses 0, therefore a very weak signal, if any.
@@ -5792,7 +5840,7 @@ \subsection{Several covariates}\label{several-covariates}
 \end{Highlighting}
 \end{Shaded}
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-289-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-270-1.pdf}}
 
 Note that the two curves are not exactly parallel because we back-transformed the linear part of the relationship between survival and wing length. You may check that parallelism occurs on the logit scale:
 
@@ -5823,12 +5871,12 @@ \subsection{Several covariates}\label{several-covariates}
   \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+} 
   \FunctionTok{ylim}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+} 
   \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{""wing length""}\NormalTok{, }
-       \AttributeTok{y =} \StringTok{""estimated survival (on the lgit scale)""}\NormalTok{, }
+       \AttributeTok{y =} \StringTok{""estimated survival (on the logit scale)""}\NormalTok{, }
        \AttributeTok{color =} \StringTok{""""}\NormalTok{)}
 \end{Highlighting}
 \end{Shaded}
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-290-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-271-1.pdf}}
 
 \subsection{Random effects}\label{randomeffects}
 
@@ -6073,9 +6121,9 @@ \subsection{Individual time-varying covariates}\label{agecov}
 
 \begin{verbatim}
 ##          mean   sd 2.5%  50% 97.5% Rhat n.eff
-## p        0.89 0.03 0.83 0.90  0.94 1.00   402
-## phi1     0.56 0.03 0.49 0.55  0.63 1.01   689
-## phi1plus 0.57 0.04 0.50 0.57  0.64 1.00   309
+## p        0.90 0.03 0.83 0.90  0.95 1.00   738
+## phi1     0.56 0.03 0.49 0.56  0.62 1.00  1624
+## phi1plus 0.57 0.04 0.49 0.57  0.64 1.01   506
 \end{verbatim}
 
 Age or time elapsed since first encounter does not seem to have an effect on survival here.
@@ -6180,9 +6228,9 @@ \subsection{Individual time-varying covariates}\label{agecov}
 
 \begin{verbatim}
 ##          mean   sd 2.5%  50% 97.5% Rhat n.eff
-## p        0.90 0.03 0.84 0.90  0.95 1.02   438
-## phi1     0.55 0.03 0.48 0.55  0.62 1.00   878
-## phi1plus 0.57 0.04 0.50 0.57  0.64 1.02  1048
+## p        0.90 0.03 0.84 0.90  0.95 1.01   793
+## phi1     0.55 0.03 0.48 0.55  0.62 1.01  1736
+## phi1plus 0.57 0.04 0.50 0.57  0.64 1.00  2064
 \end{verbatim}
 
 Like I mentioned earlier, age is easy to deal with as it does not contain missing values. Now think of size or body mass for a minute. The problem is that we cannot record size or body mass when an animal is non-detected. The easiest way to cope with individual time-varying covariates is to discretize e.g.~in small, medium and large as in Chapter \ref{dispersal}. Another option is to come up with a model for the covariate and fill in missing values by simulating from this model.
@@ -6201,7 +6249,7 @@ \subsection{Prior elicitation}\label{prior-elicitation}
 
 Now let's assume that we had only the three first years of data, what would have happened? We fit the model with constant parameters with both the non-informative and informative priors to the dataset from which we delete the final 4 years of data. Now the benefit of using the prior information becomes clear as the credible interval when prior information is ignored has a width of 0.53, which is more than twice as much as when prior information is used (0.24), illustrating the increased precision provided by the prior. We may assess visually this gain in precision by comparing the survival posterior distributions with and without informative prior:
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-316-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-297-1.pdf}}
 
 If the aim is to get an estimate of survival, Gilbert did not have to conduct further data collection after 3 years, and he could have reached the same precision as with 7 years of data by using prior information derived from body mass. In brief, the prior information was worth 4 years of field data. Of course, this is assuming that the ecological question remains the same whether you have 3 or 7 years of data, which is unlikely to be the case, as with long-term data, there is so much we can ask, more than ``just'' what annual survival probability is.
 
@@ -6274,11 +6322,11 @@ \subsection{Theory}\label{theory}
 
 Let's assume for now that we have two sites, say 1 and 2. The way we usually think of analyzing the data is to start from the detections and non-detections and infer the transitions between sites and movements. Schematically, when a animal is detected in site 1 or site 2, it obviously means that it is alive in that site, whereas when it is not detected, it may be dead or alive in either site. Schematically, we have:
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-319-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-300-1.pdf}}
 
 Observations and states are indeed closely related, but we do not have a perfect states to observations correspondence, and the HMM framework will help you make the distinction clear, which in turn will make the modelling easier. Usually, we focus our energy on the observations but what we'd really like is to spend time thinking of the ecological processes that we observed imperfectly. In the HMM framework, when we are to build a model, we think of the states and their dynamic over time, and these states emit the observations we're given to make. Going back to the our example, when an animal is alive in either site, it may get detected in that site or go undetected. When an animal is dead, then it goes undetected for sure. Schematically, we obtain:
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-320-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-301-1.pdf}}
 
 We have \(z = 1\) for alive in site 1, \(z = 2\) for alive in site 2 and \(z = 3\) for dead. We will code \(y = 1\) for non-detected, \(y = 2\) for detected in site 1 and \(y = 3\) for detected in site 2. The parameters are:\\
 - \(\pi^r\) is the probability the a newly encountered individual is in state \(r\);\\
@@ -6377,25 +6425,28 @@ \subsection{Geese data}\label{geese-data}
 
 \begin{Shaded}
 \begin{Highlighting}[]
-\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{""dat/geese.csv""}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as.matrix}\NormalTok{()}
+\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{""geese.csv""}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as.matrix}\NormalTok{()}
 \FunctionTok{head}\NormalTok{(y)}
-\DocumentationTok{\#\#      year\_1984 year\_1985 year\_1986 year\_1987 year\_1988}
-\DocumentationTok{\#\# [1,]         0         2         2         0         0}
-\DocumentationTok{\#\# [2,]         0         0         0         0         0}
-\DocumentationTok{\#\# [3,]         0         0         0         1         0}
-\DocumentationTok{\#\# [4,]         0         0         2         0         0}
-\DocumentationTok{\#\# [5,]         0         3         0         0         3}
-\DocumentationTok{\#\# [6,]         0         0         0         2         0}
-\DocumentationTok{\#\#      year\_1989}
-\DocumentationTok{\#\# [1,]         0}
-\DocumentationTok{\#\# [2,]         2}
-\DocumentationTok{\#\# [3,]         0}
-\DocumentationTok{\#\# [4,]         0}
-\DocumentationTok{\#\# [5,]         2}
-\DocumentationTok{\#\# [6,]         0}
 \end{Highlighting}
 \end{Shaded}
 
+\begin{verbatim}
+##      year_1984 year_1985 year_1986 year_1987 year_1988
+## [1,]         0         2         2         0         0
+## [2,]         0         0         0         0         0
+## [3,]         0         0         0         1         0
+## [4,]         0         0         2         0         0
+## [5,]         0         3         0         0         3
+## [6,]         0         0         0         2         0
+##      year_1989
+## [1,]         0
+## [2,]         2
+## [3,]         0
+## [4,]         0
+## [5,]         2
+## [6,]         0
+\end{verbatim}
+
 The six columns are years in which the geese were captured, banded and recapture. A 0 stands for a non-detection, and detections were coded in the 3 wintering sites 1, 2 and 3 for mid--Atlantic, Chesapeake and Carolinas respectively. This is only a subsample of 500 individuals of the whole dataset that I will use for illustration here.
 
 \subsection{NIMBLE implementation}\label{nimble-implementation-1}
@@ -6405,6 +6456,9 @@ \subsection{NIMBLE implementation}\label{nimble-implementation-1}
 \begin{Shaded}
 \begin{Highlighting}[]
 \NormalTok{y[y}\SpecialCharTok{==}\DecValTok{3}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{0}
+\CommentTok{\# remove rows with 0\textquotesingle{}s}
+\NormalTok{mask }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(y, }\DecValTok{1}\NormalTok{, sum)}
+\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ y[mask}\SpecialCharTok{!=}\DecValTok{0}\NormalTok{,]}
 \end{Highlighting}
 \end{Shaded}
 
@@ -6561,7 +6615,7 @@ \subsection{NIMBLE implementation}\label{nimble-implementation-1}
 \CommentTok{\# parameters to monitor}
 \NormalTok{parameters.to.save }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{""phi1""}\NormalTok{, }\StringTok{""phi2""}\NormalTok{,}\StringTok{""psi12""}\NormalTok{, }\StringTok{""psi21""}\NormalTok{, }\StringTok{""p1""}\NormalTok{, }\StringTok{""p2""}\NormalTok{, }\StringTok{""pi1""}\NormalTok{)}
 \CommentTok{\# MCMC details}
-\NormalTok{n.iter }\OtherTok{\textless{}{-}} \DecValTok{5000}
+\NormalTok{n.iter }\OtherTok{\textless{}{-}} \DecValTok{20000}
 \NormalTok{n.burnin }\OtherTok{\textless{}{-}} \DecValTok{1000}
 \NormalTok{n.chains }\OtherTok{\textless{}{-}} \DecValTok{2}
 \end{Highlighting}
@@ -6590,7 +6644,7 @@ \subsection{NIMBLE implementation}\label{nimble-implementation-1}
 \end{Highlighting}
 \end{Shaded}
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-332-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-314-1.pdf}}
 
 Remember mid--Atlantic is site 1, and Chesapeake site 2. Detection in mid--Atlantic (around 0.5) is higher than in Cheasapeake (around 0.4) although it comes with more uncertainty (wider credible interval). Survival in both sites are estimated at around 0.6--0.7. Note that by going multisite, we could make these parameters site-specific and differences might reflect habitat quality for example. Now the novelty lies in our capability to estimate movements from site 1 to site 2 and from site 2 to site 1 from a winter to the next. The annual probability of remaining in the same site for two successive winters, used as a measure of site fidelity, was lower in the mid--Atlantic (\(1-\psi_{12}\) around 0.8) than in the Chesapeake (\(1-\psi_{21}\) around 0.9). The estimated probability of moving to the Chesapeake from the mid--Atlantic was four times as high as the probability of moving in the opposite direction.
 
@@ -6600,13 +6654,12 @@ \subsection{NIMBLE implementation}\label{nimble-implementation-1}
 \begin{Highlighting}[]
 \FunctionTok{MCMCsummary}\NormalTok{(mcmc.multisite, }\AttributeTok{round =} \DecValTok{2}\NormalTok{)}
 \DocumentationTok{\#\#       mean   sd 2.5\%  50\% 97.5\% Rhat n.eff}
-\DocumentationTok{\#\# p1    0.56 0.10 0.37 0.56  0.76 1.00   157}
-\DocumentationTok{\#\# p2    0.40 0.04 0.32 0.39  0.48 1.00   217}
-\DocumentationTok{\#\# phi1  0.56 0.08 0.40 0.56  0.72 1.04   155}
-\DocumentationTok{\#\# phi2  0.72 0.05 0.63 0.72  0.83 1.02   120}
-\DocumentationTok{\#\# pi1   0.37 0.10 0.21 0.36  0.60 1.02    62}
-\DocumentationTok{\#\# psi12 0.23 0.09 0.08 0.22  0.43 1.03   171}
-\DocumentationTok{\#\# psi21 0.06 0.02 0.02 0.05  0.11 1.01   336}
+\DocumentationTok{\#\# p1    0.53 0.09 0.37 0.53  0.71    1  1107}
+\DocumentationTok{\#\# p2    0.40 0.04 0.32 0.39  0.48    1  1080}
+\DocumentationTok{\#\# phi1  0.60 0.05 0.50 0.60  0.71    1  1675}
+\DocumentationTok{\#\# phi2  0.70 0.04 0.63 0.70  0.77    1  1145}
+\DocumentationTok{\#\# psi12 0.27 0.06 0.17 0.27  0.39    1  2001}
+\DocumentationTok{\#\# psi21 0.07 0.02 0.04 0.07  0.11    1  2192}
 \end{Highlighting}
 \end{Shaded}
 
@@ -6746,7 +6799,7 @@ \subsection{NIMBLE implementation}\label{nimble-implementation-1}
 \end{Highlighting}
 \end{Shaded}
 
-There are slight differences in these parameters estimates compared to those we obtained earlier. This is probably due to the effective sample sizes being much bigger here (by a factor 3) with the marginalized likelihood for the same number of MCMC iterations.
+There are no differences whatsoever in these parameters estimates compared to those we obtained earlier.
 
 \subsection{Goodness of fit}\label{gofas}
 
@@ -6756,17 +6809,23 @@ \subsection{Goodness of fit}\label{gofas}
 
 \begin{Shaded}
 \begin{Highlighting}[]
+\CommentTok{\# To install the R2ucare package:}
+\CommentTok{\# if(!require(devtools)) install.packages(""devtools"")}
+\CommentTok{\# devtools::install\_github(""oliviergimenez/R2ucare"")}
 \FunctionTok{library}\NormalTok{(R2ucare)}
-\NormalTok{geese }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv2}\NormalTok{(}\StringTok{""dat/allgeese.csv""}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as.matrix}\NormalTok{()}
+\NormalTok{geese }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv2}\NormalTok{(}\StringTok{""allgeese.csv""}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as.matrix}\NormalTok{()}
 \NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ geese[,}\DecValTok{1}\SpecialCharTok{:}\DecValTok{6}\NormalTok{]}
 \NormalTok{size }\OtherTok{\textless{}{-}}\NormalTok{ geese[,}\DecValTok{7}\NormalTok{]}
 \NormalTok{wbwa }\OtherTok{\textless{}{-}} \FunctionTok{test3Gwbwa}\NormalTok{(y, size)}
 \NormalTok{wbwa}\SpecialCharTok{$}\NormalTok{test3Gwbwa}
-\DocumentationTok{\#\#  stat    df p\_val }
-\DocumentationTok{\#\# 472.9  20.0   0.0}
 \end{Highlighting}
 \end{Shaded}
 
+\begin{verbatim}
+##  stat    df p_val 
+## 472.9  20.0   0.0
+\end{verbatim}
+
 There is clearly a strong (not to say significant) positive relationship judging by the value of the statistic. I will demonstrate how to account for this memory issue in an extension of the AS model in a case study in Section \ref{memorymodel}.
 
 \section{What if more than 2 sites?}\label{what-if-more-than-2-sites}
@@ -6917,21 +6976,21 @@ \subsection{Dirichlet prior}\label{dirichletprior}
 \begin{Highlighting}[]
 \FunctionTok{MCMCsummary}\NormalTok{(mcmc.multisite, }\AttributeTok{round =} \DecValTok{2}\NormalTok{)}
 \DocumentationTok{\#\#         mean   sd 2.5\%  50\% 97.5\% Rhat n.eff}
-\DocumentationTok{\#\# p1      0.51 0.08 0.36 0.51  0.67 1.02   306}
-\DocumentationTok{\#\# p2      0.45 0.05 0.36 0.45  0.55 1.00   217}
-\DocumentationTok{\#\# p3      0.26 0.06 0.15 0.25  0.39 1.01   166}
-\DocumentationTok{\#\# phi1    0.60 0.05 0.51 0.60  0.70 1.01   384}
-\DocumentationTok{\#\# phi2    0.70 0.04 0.63 0.70  0.77 1.00   233}
-\DocumentationTok{\#\# phi3    0.75 0.06 0.62 0.76  0.87 1.03   218}
-\DocumentationTok{\#\# psi1[1] 0.74 0.05 0.63 0.75  0.84 1.01   818}
-\DocumentationTok{\#\# psi1[2] 0.24 0.05 0.14 0.24  0.35 1.02   817}
-\DocumentationTok{\#\# psi1[3] 0.02 0.02 0.00 0.01  0.07 1.05   487}
-\DocumentationTok{\#\# psi2[1] 0.07 0.02 0.04 0.07  0.12 1.00   668}
-\DocumentationTok{\#\# psi2[2] 0.84 0.04 0.75 0.84  0.90 1.00   292}
-\DocumentationTok{\#\# psi2[3] 0.09 0.03 0.04 0.08  0.17 1.00   220}
-\DocumentationTok{\#\# psi3[1] 0.02 0.01 0.00 0.02  0.06 1.00  1022}
-\DocumentationTok{\#\# psi3[2] 0.22 0.05 0.12 0.21  0.33 1.01   525}
-\DocumentationTok{\#\# psi3[3] 0.76 0.06 0.64 0.76  0.86 1.01   506}
+\DocumentationTok{\#\# p1      0.53 0.09 0.36 0.52  0.70 1.01   412}
+\DocumentationTok{\#\# p2      0.46 0.05 0.37 0.45  0.57 1.00   399}
+\DocumentationTok{\#\# p3      0.24 0.06 0.13 0.23  0.38 1.01   248}
+\DocumentationTok{\#\# phi1    0.60 0.05 0.50 0.60  0.70 1.01   564}
+\DocumentationTok{\#\# phi2    0.70 0.04 0.63 0.70  0.77 1.00   547}
+\DocumentationTok{\#\# phi3    0.78 0.07 0.64 0.78  0.91 1.00   258}
+\DocumentationTok{\#\# psi1[1] 0.74 0.06 0.62 0.74  0.84 1.00   798}
+\DocumentationTok{\#\# psi1[2] 0.24 0.05 0.14 0.23  0.36 1.00   853}
+\DocumentationTok{\#\# psi1[3] 0.02 0.03 0.00 0.02  0.10 1.01   401}
+\DocumentationTok{\#\# psi2[1] 0.07 0.02 0.04 0.07  0.12 1.01   687}
+\DocumentationTok{\#\# psi2[2] 0.83 0.04 0.73 0.84  0.90 1.00   363}
+\DocumentationTok{\#\# psi2[3] 0.09 0.04 0.04 0.09  0.18 1.01   361}
+\DocumentationTok{\#\# psi3[1] 0.02 0.02 0.00 0.02  0.06 1.00  1631}
+\DocumentationTok{\#\# psi3[2] 0.21 0.05 0.12 0.20  0.32 1.00   721}
+\DocumentationTok{\#\# psi3[3] 0.77 0.06 0.65 0.78  0.87 1.00   672}
 \end{Highlighting}
 \end{Shaded}
 
@@ -7038,21 +7097,21 @@ \subsection{Multinomial logit}\label{multinomiallogit}
 \begin{Highlighting}[]
 \FunctionTok{MCMCsummary}\NormalTok{(mcmc.multisite, }\AttributeTok{round =} \DecValTok{2}\NormalTok{)}
 \DocumentationTok{\#\#         mean   sd 2.5\%  50\% 97.5\% Rhat n.eff}
-\DocumentationTok{\#\# p1      0.52 0.08 0.37 0.52  0.69 1.01   297}
-\DocumentationTok{\#\# p2      0.46 0.05 0.37 0.45  0.57 1.13   209}
-\DocumentationTok{\#\# p3      0.23 0.06 0.14 0.23  0.36 1.05   137}
-\DocumentationTok{\#\# phi1    0.60 0.05 0.50 0.60  0.70 1.00   403}
-\DocumentationTok{\#\# phi2    0.70 0.04 0.63 0.70  0.77 1.14   281}
-\DocumentationTok{\#\# phi3    0.77 0.06 0.64 0.77  0.89 1.05   199}
-\DocumentationTok{\#\# psi1[1] 0.74 0.06 0.62 0.74  0.83 1.00   727}
-\DocumentationTok{\#\# psi1[2] 0.22 0.05 0.13 0.22  0.33 1.03   795}
-\DocumentationTok{\#\# psi1[3] 0.04 0.03 0.01 0.04  0.12 1.05    88}
-\DocumentationTok{\#\# psi2[1] 0.07 0.02 0.04 0.07  0.11 1.01   655}
-\DocumentationTok{\#\# psi2[2] 0.83 0.04 0.74 0.84  0.90 1.04   153}
-\DocumentationTok{\#\# psi2[3] 0.10 0.04 0.04 0.09  0.19 1.03   122}
-\DocumentationTok{\#\# psi3[1] 0.03 0.02 0.01 0.02  0.07 1.01   794}
-\DocumentationTok{\#\# psi3[2] 0.22 0.05 0.13 0.21  0.32 1.02   477}
-\DocumentationTok{\#\# psi3[3] 0.76 0.05 0.64 0.76  0.85 1.02   444}
+\DocumentationTok{\#\# p1      0.52 0.09 0.36 0.52  0.69 1.02   702}
+\DocumentationTok{\#\# p2      0.46 0.05 0.37 0.46  0.57 1.00   538}
+\DocumentationTok{\#\# p3      0.23 0.06 0.13 0.23  0.36 1.00   404}
+\DocumentationTok{\#\# phi1    0.61 0.05 0.51 0.61  0.71 1.00   893}
+\DocumentationTok{\#\# phi2    0.70 0.04 0.63 0.70  0.77 1.00   879}
+\DocumentationTok{\#\# phi3    0.77 0.07 0.64 0.77  0.91 1.01   462}
+\DocumentationTok{\#\# psi1[1] 0.73 0.06 0.62 0.74  0.83 1.02  1435}
+\DocumentationTok{\#\# psi1[2] 0.22 0.05 0.13 0.22  0.33 1.00  1687}
+\DocumentationTok{\#\# psi1[3] 0.05 0.03 0.01 0.04  0.12 1.03   313}
+\DocumentationTok{\#\# psi2[1] 0.07 0.02 0.04 0.07  0.12 1.00  1318}
+\DocumentationTok{\#\# psi2[2] 0.83 0.04 0.73 0.84  0.90 1.01   466}
+\DocumentationTok{\#\# psi2[3] 0.10 0.04 0.04 0.09  0.18 1.00   325}
+\DocumentationTok{\#\# psi3[1] 0.03 0.02 0.01 0.02  0.07 1.01  2526}
+\DocumentationTok{\#\# psi3[2] 0.21 0.05 0.12 0.21  0.33 1.00  1197}
+\DocumentationTok{\#\# psi3[3] 0.76 0.06 0.64 0.76  0.86 1.00   994}
 \end{Highlighting}
 \end{Shaded}
 
@@ -7099,7 +7158,7 @@ \subsection{Titis data}\label{titis-data}
 
 \begin{Shaded}
 \begin{Highlighting}[]
-\NormalTok{titis }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv2}\NormalTok{(}\StringTok{""dat/titis.csv""}\NormalTok{, }
+\NormalTok{titis }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv2}\NormalTok{(}\StringTok{""titis.csv""}\NormalTok{, }
                    \AttributeTok{col\_names =} \ConstantTok{FALSE}\NormalTok{)}
 \NormalTok{titis }\SpecialCharTok{\%\textgreater{}\%}
   \FunctionTok{rename}\NormalTok{(}\AttributeTok{year\_1942 =}\NormalTok{ X1,}
@@ -7109,24 +7168,27 @@ \subsection{Titis data}\label{titis-data}
          \AttributeTok{year\_1952 =}\NormalTok{ X5,}
          \AttributeTok{year\_1953 =}\NormalTok{ X6,}
          \AttributeTok{year\_1956 =}\NormalTok{ X7)}
-\DocumentationTok{\#\# \# A tibble: 1,013 x 7}
-\DocumentationTok{\#\#    year\_1942 year\_1943 year\_1944 year\_1949 year\_1952}
-\DocumentationTok{\#\#        \textless{}dbl\textgreater{}     \textless{}dbl\textgreater{}     \textless{}dbl\textgreater{}     \textless{}dbl\textgreater{}     \textless{}dbl\textgreater{}}
-\DocumentationTok{\#\#  1         0         0         0         0         0}
-\DocumentationTok{\#\#  2         0         0         0         0         0}
-\DocumentationTok{\#\#  3         0         0         0         0         0}
-\DocumentationTok{\#\#  4         0         0         0         0         0}
-\DocumentationTok{\#\#  5         0         0         0         0         0}
-\DocumentationTok{\#\#  6         0         0         0         0         0}
-\DocumentationTok{\#\#  7         0         0         0         0         0}
-\DocumentationTok{\#\#  8         0         0         0         0         0}
-\DocumentationTok{\#\#  9         0         0         0         0         0}
-\DocumentationTok{\#\# 10         0         0         0         0         0}
-\DocumentationTok{\#\# \# i 1,003 more rows}
-\DocumentationTok{\#\# \# i 2 more variables: year\_1953 \textless{}dbl\textgreater{}, year\_1956 \textless{}dbl\textgreater{}}
 \end{Highlighting}
 \end{Shaded}
 
+\begin{verbatim}
+## # A tibble: 1,013 x 7
+##    year_1942 year_1943 year_1944 year_1949 year_1952
+##        <dbl>     <dbl>     <dbl>     <dbl>     <dbl>
+##  1         0         0         0         0         0
+##  2         0         0         0         0         0
+##  3         0         0         0         0         0
+##  4         0         0         0         0         0
+##  5         0         0         0         0         0
+##  6         0         0         0         0         0
+##  7         0         0         0         0         0
+##  8         0         0         0         0         0
+##  9         0         0         0         0         0
+## 10         0         0         0         0         0
+## # i 1,003 more rows
+## # i 2 more variables: year_1953 <dbl>, year_1956 <dbl>
+\end{verbatim}
+
 In total, 1013 titis were captured, marked and recaptured on a small colony on Whero Island in southern New Zealand. These data were previously analyzed by Richard Scofield who kindly provided us with the data.
 
 Following the way the data were collected, four states were originally considered: Alive breeder; Accompanied by another bird in a burrow; Alone in a burrow; On the surface; Dead. For simplicity, we pooled all alive states (except breeder) together in a non-breeder state (NB) that includes failed breeders (birds that had bred previously -- skip reproduction or divorce) and pre-breeders (birds that had yet to breed). Because burrows were not checked before hatching, some birds in the category NB might have already failed. Therefore birds in the breeder state (B) should be seen as successful breeders, and those in the NB state as nonbreeders plus prebreeders and failed breeders.
@@ -7305,12 +7367,12 @@ \subsection{NIMBLE implementation}\label{nimble-implementation-2}
 \begin{Highlighting}[]
 \FunctionTok{MCMCsummary}\NormalTok{(mcmc.multistate, }\AttributeTok{round =} \DecValTok{2}\NormalTok{)}
 \DocumentationTok{\#\#        mean   sd 2.5\%  50\% 97.5\% Rhat n.eff}
-\DocumentationTok{\#\# pB     0.60 0.03 0.54 0.59  0.66 1.00   202}
-\DocumentationTok{\#\# pNB    0.57 0.03 0.51 0.57  0.62 1.01   281}
-\DocumentationTok{\#\# phiB   0.80 0.02 0.77 0.80  0.83 1.01   313}
-\DocumentationTok{\#\# phiNB  0.85 0.02 0.82 0.85  0.88 1.00   404}
-\DocumentationTok{\#\# psiBNB 0.25 0.02 0.21 0.25  0.30 1.00   434}
-\DocumentationTok{\#\# psiNBB 0.24 0.02 0.20 0.24  0.29 1.03   478}
+\DocumentationTok{\#\# pB     0.60 0.03 0.54 0.60  0.65 1.00   756}
+\DocumentationTok{\#\# pNB    0.56 0.03 0.51 0.56  0.62 1.01   725}
+\DocumentationTok{\#\# phiB   0.80 0.02 0.77 0.80  0.83 1.00  1485}
+\DocumentationTok{\#\# phiNB  0.85 0.02 0.81 0.85  0.88 1.01  1231}
+\DocumentationTok{\#\# psiBNB 0.25 0.02 0.21 0.25  0.30 1.01  1227}
+\DocumentationTok{\#\# psiNBB 0.24 0.02 0.20 0.24  0.28 1.00  1123}
 \end{Highlighting}
 \end{Shaded}
 
@@ -7338,7 +7400,7 @@ \subsection{NIMBLE implementation}\label{nimble-implementation-2}
 \end{Highlighting}
 \end{Shaded}
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-358-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-342-1.pdf}}
 
 There is little overlap between the two distributions, suggesting an actual trade--off. A formal test of the trade-off would consist in fitting the model with survival irrespective of the state, and compare its WAIC value to the model we just fitted.
 
@@ -7360,7 +7422,7 @@ \subsection{NIMBLE implementation}\label{nimble-implementation-2}
 \end{Highlighting}
 \end{Shaded}
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-359-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-343-1.pdf}}
 
 There is no overlap whatsoever, so the two transition probabilities are clearly different. Interestingly, breeder individuals do much better than non-breeder individuals. This failure at detecting a trade-off is probably due to individual heterogeneity that should be accounted for. You could add an individual random effect as in Section \ref{randomeffects} or consider 2 classes of individuals as we will do in a case study at Section \ref{indhet}.
 
@@ -7415,22 +7477,22 @@ \section{Issue of local minima}\label{localminima}
 
 You might argue that this is a problem of the optimization algorithm and therefore inherent to the frequentist approach. Well, it turns out that MCMC algorithms are not immune to the issue. If you fit the AS model with constant parameters to the simulated data, here is the trace for the probability of moving from 2 to 1:
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-361-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-345-1.pdf}}
 
 Clearly, there are two regimes. The chain spends most of its time around high values of \(\psi^{21}\) close to the true value represented by the blue dashed line. But sometimes, the chain jumps to values around 0.3-0.4. This behavior translates into two modes in the posterior distribution for \(\psi^{21}\) where the mode on the right is closer to the truth represented by the dashed blue vertical line:
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-362-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-346-1.pdf}}
 
 The issue of local minima is a difficult problem. How to get out of this problematic situation? In the frequentist approach, the trick is to fit your model several times with different initial values each time, hoping that you'll get to fall in the green area somehow as in Figure \ref{fig:inits}. In the Bayesian approach, the key to handle distributions with multiple modes is to sample the posteriors efficiently. Assuming the chains we run in NIMBLE spend more time in the region of the parameter space corresponding to the global minimum, then I recommend using the median or the mode to summarize the posterior distribution. In the simulated example, we get a median of 0.79 for \(\psi^{21}\), not too bad given that the data were simulated with a value of 0.85 for that parameter:
 
 \begin{Shaded}
 \begin{Highlighting}[]
 \FunctionTok{MCMCsummary}\NormalTok{(mcmc.multisite, }\AttributeTok{round =} \DecValTok{2}\NormalTok{)}
 \DocumentationTok{\#\#       mean   sd 2.5\%  50\% 97.5\% Rhat n.eff}
-\DocumentationTok{\#\# p     0.58 0.03 0.51 0.58  0.65 1.01  1866}
-\DocumentationTok{\#\# phi   0.99 0.01 0.98 1.00  1.00 1.01   691}
-\DocumentationTok{\#\# psi12 0.53 0.14 0.21 0.56  0.72 1.05    69}
-\DocumentationTok{\#\# psi21 0.72 0.18 0.28 0.79  0.92 1.04    37}
+\DocumentationTok{\#\# p     0.58 0.04 0.51 0.58  0.65 1.00  3194}
+\DocumentationTok{\#\# phi   0.99 0.01 0.98 1.00  1.00 1.02  1173}
+\DocumentationTok{\#\# psi12 0.51 0.15 0.19 0.56  0.72 1.10    76}
+\DocumentationTok{\#\# psi21 0.70 0.20 0.27 0.78  0.93 1.12    56}
 \end{Highlighting}
 \end{Shaded}
 
@@ -7446,7 +7508,7 @@ \subsection{Breeding states}\label{breedingmultievent}
 
 How do the states generate the observations?
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-365-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-349-1.pdf}}
 
 Each alive state can generate 3 observations. The only deterministic link is that between the dead state and the observation non-encountered, because if a bird is dead, it cannot be detected for sure.
 
@@ -7705,15 +7767,15 @@ \subsection{Breeding states}\label{breedingmultievent}
 \begin{Highlighting}[]
 \FunctionTok{MCMCsummary}\NormalTok{(mcmc.multievent, }\AttributeTok{round =} \DecValTok{2}\NormalTok{)}
 \DocumentationTok{\#\#        mean   sd 2.5\%  50\% 97.5\% Rhat n.eff}
-\DocumentationTok{\#\# betaB  0.19 0.01 0.16 0.19  0.21 1.01   332}
-\DocumentationTok{\#\# betaNB 0.76 0.05 0.66 0.76  0.86 1.01    65}
-\DocumentationTok{\#\# pB     0.56 0.03 0.51 0.56  0.62 1.06   229}
-\DocumentationTok{\#\# pNB    0.60 0.04 0.53 0.60  0.67 1.03   142}
-\DocumentationTok{\#\# phiB   0.81 0.02 0.78 0.81  0.85 1.01   312}
-\DocumentationTok{\#\# phiNB  0.84 0.02 0.80 0.84  0.87 1.00   354}
-\DocumentationTok{\#\# piB    0.71 0.03 0.66 0.71  0.76 1.02   115}
-\DocumentationTok{\#\# psiBNB 0.23 0.02 0.18 0.22  0.27 1.00   214}
-\DocumentationTok{\#\# psiNBB 0.25 0.04 0.17 0.25  0.34 1.00    95}
+\DocumentationTok{\#\# betaB  0.19 0.01 0.16 0.19  0.22 1.00   583}
+\DocumentationTok{\#\# betaNB 0.74 0.06 0.64 0.73  0.88 1.00   198}
+\DocumentationTok{\#\# pB     0.56 0.03 0.51 0.56  0.62 1.01   801}
+\DocumentationTok{\#\# pNB    0.60 0.04 0.53 0.60  0.67 1.02   757}
+\DocumentationTok{\#\# phiB   0.81 0.02 0.78 0.81  0.85 1.00  1551}
+\DocumentationTok{\#\# phiNB  0.84 0.02 0.80 0.84  0.87 1.00  1610}
+\DocumentationTok{\#\# piB    0.70 0.03 0.64 0.70  0.76 1.00   296}
+\DocumentationTok{\#\# psiBNB 0.22 0.03 0.17 0.22  0.28 1.01   925}
+\DocumentationTok{\#\# psiNBB 0.23 0.05 0.15 0.23  0.35 1.00   250}
 \end{Highlighting}
 \end{Shaded}
 
@@ -7770,7 +7832,7 @@ \subsection{Disease states}\label{diseasemultievent}
 
 How do the states generate observations?
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-375-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-359-1.pdf}}
 
 Clearly, this is the same model as in the previous section on titis, Section \ref{breedingmultievent}, in which loosely speaking we replace breeder by healthy and non-breeder by ill.
 
@@ -7873,18 +7935,18 @@ \subsection{Disease states}\label{diseasemultievent}
 
 \begin{verbatim}
 ##       mean   sd 2.5%  50% 97.5% Rhat n.eff
-## betaH 0.99 0.01 0.97 0.99  1.00 1.01  1421
-## betaI 0.05 0.01 0.03 0.05  0.08 1.00  6477
-## pH    0.17 0.02 0.13 0.17  0.22 1.01   331
-## pI    0.58 0.10 0.41 0.57  0.80 1.04   220
-## phiH  0.88 0.02 0.84 0.88  0.92 1.01   360
-## phiI  0.99 0.01 0.96 0.99  1.00 1.00  1004
-## pi    0.96 0.01 0.93 0.96  0.98 1.00  4190
-## psiHI 0.22 0.04 0.16 0.22  0.32 1.02   311
-## psiIH 0.46 0.08 0.32 0.45  0.63 1.02   392
+## betaH 0.99 0.01 0.97 0.99  1.00 1.01  2118
+## betaI 0.05 0.01 0.02 0.05  0.08 1.01  1810
+## pH    0.71 0.21 0.15 0.75  0.98 1.04   142
+## pI    0.28 0.10 0.21 0.25  0.63 1.00   317
+## phiH  0.70 0.07 0.62 0.69  0.89 1.08   192
+## phiI  0.99 0.01 0.96 0.99  1.00 1.00   832
+## pi    0.96 0.01 0.93 0.96  0.98 1.00  6332
+## psiHI 0.75 0.17 0.19 0.80  0.88 1.02   160
+## psiIH 0.20 0.09 0.12 0.17  0.50 1.05   146
 \end{verbatim}
 
-Healthy individuals are correctly assigned (\(\beta^H\) is almost 1), while infected individuals are difficult to ascertain (\(\beta^I\) is around 0.05). Unexpectedly, ill birds have a better survival than healthy individuals (compare \(\phi^I\) and \(\phi^H\)). Infection rate (\(\psi^{HI}\)) is 22\%, recovery rate is 46\% (\(\psi^{IH}\)).
+Healthy individuals are correctly assigned (\(\beta^H\) is almost 1), while infected individuals are difficult to ascertain (\(\beta^I\) is around 0.05). Unexpectedly, ill birds have a better survival than healthy individuals (compare \(\phi^I\) and \(\phi^H\)). Infection rate (\(\psi^{HI}\)) is 75\%, recovery rate is 20\% (\(\psi^{IH}\)).
 
 \section{Summary}\label{summary-4}
 
@@ -8165,7 +8227,7 @@ \subsection{Results and interpretation}\label{results-and-interpretation}
 
 \FunctionTok{ggplot}\NormalTok{(df\_phi, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \DecValTok{1956}\SpecialCharTok{:}\DecValTok{1970}\NormalTok{, }\AttributeTok{y =}\NormalTok{ mean)) }\SpecialCharTok{+}
   \FunctionTok{geom\_ribbon}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ low, }\AttributeTok{ymax =}\NormalTok{ high), }\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{) }\SpecialCharTok{+}
-  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{size =} \FloatTok{0.9}\NormalTok{) }\SpecialCharTok{+}
+  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{linewidth =} \FloatTok{0.9}\NormalTok{) }\SpecialCharTok{+}
   \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
   \FunctionTok{labs}\NormalTok{(}
     \AttributeTok{x =} \StringTok{""Years (interval start)""}\NormalTok{,}
@@ -8175,7 +8237,7 @@ \subsection{Results and interpretation}\label{results-and-interpretation}
 \end{Highlighting}
 \end{Shaded}
 
-\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-389-1.pdf}}
+\pandocbounded{\includegraphics[keepaspectratio]{banana-book_files/figure-latex/unnamed-chunk-373-1.pdf}}
 
 Shaded ribbons show 95\% credible intervals; the solid line is the posterior mean of survival, which decreases over time, model-averaged over covariate inclusion.
 
@@ -8417,36 +8479,32 @@ \subsection{Results and interpretation}\label{results-and-interpretation-1}
 \end{verbatim}
 
 which we can arrange as in Table \ref{tab:ageuncertaintycompare} to compare them with the results obtained by \citet{Gervasi2017}:
-\textbackslash begin\{table\}
 
-\textbackslash caption\{\label{tab:ageuncertaintycompare}Comparison of parameter estimates for the same HMM to account for age uncertainty: our NIMBLE fit vs.~Gervasi et al.~(2017, Table 3). Intervals are 95\% credible intervals for NIMBLE and confidence intervals for Gervasi et al.. Detection in Gervasi et al.~varies by design/year; I report their overall average.\}
+\begin{table}
 \centering
-
-\begin{tabular}[t]{c|c|c}
-\hline
+\caption{\label{tab:ageuncertaintycompare}Comparison of parameter estimates for the same HMM to account for age uncertainty: our NIMBLE fit vs. Gervasi et al. (2017, Table 3).}
+\centering
+\begin{longtable}{ccc}
+\toprule
 Parameter & NIMBLE & Gervasi et al. (2017)\\
-\hline
-$\phi_C$ (cub survival) & 0.53 (0.28‚Äì0.78) & 0.51 (0.22‚Äì0.79)\\
-\hline
+\midrule
+\cellcolor{gray!10}{$\phi_C$ (cub survival)} & \cellcolor{gray!10}{0.53 (0.28‚Äì0.78)} & \cellcolor{gray!10}{0.51 (0.22‚Äì0.79)}\\
 $\phi_{A,f}$ (adult female) & 0.88 (0.80‚Äì0.94) & 0.92 (0.87‚Äì0.95)\\
-\hline
-$\phi_{A,m}$ (adult male) & 0.82 (0.69‚Äì0.92) & 0.85 (0.76‚Äì0.91)\\
-\hline
+\cellcolor{gray!10}{$\phi_{A,m}$ (adult male)} & \cellcolor{gray!10}{0.82 (0.69‚Äì0.92)} & \cellcolor{gray!10}{0.85 (0.76‚Äì0.91)}\\
 $p$ (detection) & 0.71 (0.63‚Äì0.79) & ‚âà0.71 (0.62‚Äì0.79)\\
-\hline
-$\pi$ (cub at first detection) & 0.27 (0.12‚Äì0.49) & 0.062 (0.007‚Äì0.396)\\
-\hline
-$C_{c,cc}$ (cub by both | cub) & 0.30 (0.13‚Äì0.50) & 0.40 (0.15‚Äì0.72)\\
-\hline
-$C_{c,ca}$ (cub by P1 only | cub) & 0.57 (0.33‚Äì0.79) & 0.60 (0.28‚Äì0.85)\\
-\hline
-$C_{a,cc}$ (cub by both | adult) & 0.02 (0.00‚Äì0.05) & 0.067 (0.024‚Äì0.174)\\
-\hline
-$C_{a,ca}$ (cub by P1 only | adult) & 0.05 (0.02‚Äì0.08) & 0.191 (0.110‚Äì0.309)\\
-\hline
-\end{tabular}
+\cellcolor{gray!10}{$\pi$ (cub at first detection)} & \cellcolor{gray!10}{0.27 (0.12‚Äì0.49)} & \cellcolor{gray!10}{0.062 (0.007‚Äì0.396)}\\
+\addlinespace
+$C_{c,cc}$ (cub by both given cub) & 0.30 (0.13‚Äì0.50) & 0.40 (0.15‚Äì0.72)\\
+\cellcolor{gray!10}{$C_{c,ca}$ (cub by P1 only given cub)} & \cellcolor{gray!10}{0.57 (0.33‚Äì0.79)} & \cellcolor{gray!10}{0.60 (0.28‚Äì0.85)}\\
+$C_{a,cc}$ (cub by both given adult) & 0.02 (0.00‚Äì0.05) & 0.067 (0.024‚Äì0.174)\\
+\cellcolor{gray!10}{$C_{a,ca}$ (cub by P1 only given adult)} & \cellcolor{gray!10}{0.05 (0.02‚Äì0.08)} & \cellcolor{gray!10}{0.191 (0.110‚Äì0.309)}\\
+\bottomrule
+\end{longtable}
+\end{table}
 
-\textbackslash end\{table\}
+\justifying
+
+Intervals in Table \ref{tab:ageuncertaintycompare} are 95\% credible intervals for NIMBLE and confidence intervals for \citet{Gervasi2017}. Detection in \citet{Gervasi2017} varies by design and year; I report their overall average.
 
 Our NIMBLE fit reproduces the main biological signals reported for the Apennine brown bear. Survival shows the expected ordering, that cubs \textless\textless{} adults, and adult females \textgreater{} adult males -- with estimates that closely match the published analysis. The credible/confidence intervals overlap broadly, indicating good agreement.
 
@@ -8677,40 +8735,35 @@ \subsection{Results and interpretation}\label{results-and-interpretation-2}
 \end{verbatim}
 
 which we can arrange in as in Table \ref{tab:sexuncertainty} to compare them with the results obtained by \citet{pradel2008sex}:
-\textbackslash begin\{table\}
 
-\textbackslash caption\{\label{tab:sexuncertainty}Comparison of parameter estimates for the same HMM to account for sex uncertainty: our NIMBLE fit vs.~Pradel et al.~(2008, Table 5, model B no genetically sexed anchors). Intervals are 95\% credible intervals for NIMBLE and confidence intervals for Pradel et al.. Our error rates are 1 ‚àí x{[}i{]}. Pradel's m's were provided by the main author of the paper himself. Note that m4 is time-varying; the estimates were for t=1,\ldots,10: 0.001, 0.002, 0.004, 0.007, 0.014, 0.026, 0.047, 0.084, 0.146, 0.242.\}
+\begin{table}
 \centering
-
-\begin{tabular}[t]{l|c|c}
-\hline
+\caption{\label{tab:sexuncertainty}Comparison of parameter estimates for the same HMM to account for sex uncertainty: our NIMBLE fit vs. Pradel et al. (2008, Table 5, model B no genetically sexed anchors).}
+\centering
+\begin{tabular}[t]{lcc}
+\toprule
 Parameter & NIMBLE & Pradel et al. (2008)\\
-\hline
-$\mu$ (proportion male) & 0.52 (0.50‚Äì0.55) & 0.53 (SE 0.03)\\
-\hline
+\midrule
+\cellcolor{gray!10}{$\mu$ (proportion male)} & \cellcolor{gray!10}{0.52 (0.50‚Äì0.55)} & \cellcolor{gray!10}{0.53 (SE 0.03)}\\
 $\phi_F$ (female survival) & 0.90 (0.89‚Äì0.91) & 0.91 (SE 0.01)\\
-\hline
-$\phi_M$ (male survival) & 0.89 (0.88‚Äì0.90) & 0.86 (SE 0.01)\\
-\hline
+\cellcolor{gray!10}{$\phi_M$ (male survival)} & \cellcolor{gray!10}{0.89 (0.88‚Äì0.90)} & \cellcolor{gray!10}{0.86 (SE 0.01)}\\
 $m_1$ (Copulation) & 0.29 (0.26‚Äì0.32) & 0.29\\
-\hline
-$m_2$ (Begging) & 0.60 (0.56‚Äì0.63) & 0.60\\
-\hline
+\cellcolor{gray!10}{$m_2$ (Begging)} & \cellcolor{gray!10}{0.60 (0.56‚Äì0.63)} & \cellcolor{gray!10}{0.60}\\
+\addlinespace
 $m_3$ (Courtship feeding) & 0.11 (0.09‚Äì0.14) & 0.11\\
-\hline
-$m_4$ (Body size) & 0.17 (0.14‚Äì0.19) & time-varying (see caption)\\
-\hline
+\cellcolor{gray!10}{$m_4$ (Body size)} & \cellcolor{gray!10}{0.17 (0.14‚Äì0.19)} & \cellcolor{gray!10}{time-varying}\\
 Error (Copulation) & 0.48 (0.42‚Äì0.55) & 0.06 (SE 0.04)\\
-\hline
-Error (Begging) & 0.45 (0.40‚Äì0.50) & 0.06 (SE 0.03)\\
-\hline
+\cellcolor{gray!10}{Error (Begging)} & \cellcolor{gray!10}{0.45 (0.40‚Äì0.50)} & \cellcolor{gray!10}{0.06 (SE 0.03)}\\
 Error (Courtship feeding) & 0.46 (0.35‚Äì0.56) & 0.00 (SE 0.16)\\
-\hline
-Error (Body size) & 0.42 (0.33‚Äì0.50) & 0.09 (SE 0.07)\\
-\hline
+\addlinespace
+\cellcolor{gray!10}{Error (Body size)} & \cellcolor{gray!10}{0.42 (0.33‚Äì0.50)} & \cellcolor{gray!10}{0.09 (SE 0.07)}\\
+\bottomrule
 \end{tabular}
+\end{table}
+
+\justifying
 
-\textbackslash end\{table\}
+Intervals in Table \ref{tab:sexuncertainty} are 95\% credible intervals for NIMBLE and confidence intervals for \citet{pradel2008sex}. Our error rates are \texttt{1\ ‚àí\ x{[}i{]}}. Pradel's \(m\)'s were provided by the main author of the paper himself. Note that \texttt{m4} was time-varying; the estimates were for \(t=1,\ldots,10\): 0.001, 0.002, 0.004, 0.007, 0.014, 0.026, 0.047, 0.084, 0.146, 0.242.
 
 Our NIMBLE fit recovers the main biological signals reported for the Audouin's gulls analysis. Survival shows the expected ordering -- adult females ‚â• adult males -- with broadly overlapping intervals and means that are close to the published model. In our run, the female--male gap is a bit smaller (0.90 vs 0.89), but the direction matches the paper's message (higher female survival).
 
@@ -8881,10 +8934,10 @@ \subsection{Results and interpretation}\label{results-and-interpretation-3}
 
 \begin{verbatim}
 ##        mean   sd 2.5%  50% 97.5% Rhat n.eff
-## p      0.45 0.06 0.34 0.45  0.56 1.00   126
-## phi1   0.76 0.02 0.71 0.76  0.80 1.00   395
-## phi2   0.87 0.02 0.84 0.87  0.91 1.01   173
-## pprime 0.79 0.02 0.75 0.79  0.82 1.00   183
+## p      0.46 0.06 0.34 0.46  0.56 1.10   580
+## phi1   0.76 0.02 0.71 0.76  0.80 1.03  1892
+## phi2   0.87 0.02 0.84 0.87  0.90 1.08   940
+## pprime 0.79 0.02 0.75 0.79  0.82 1.06  1154
 \end{verbatim}
 
 The two detection probabilities, depending on whether a bird was previously caught or not, differ clearly, providing evidence of trap-happiness. Our survival estimates are very similar to those obtained by \citet{pradeltrapdep2012} who found \(\phi_1 = 0.77\; (0.70, 0.82)\) and \(\phi_2 = 0.87\; (0.82,0.90)\) (check out their Table 1). Interestingly, when we fit the same model by ignoring trap-dependence, we get the following results:
@@ -9198,51 +9251,48 @@ \subsection{Results and interpretation}\label{results-and-interpretation-4}
 
 \begin{verbatim}
 ##          mean   sd 2.5%  50% 97.5% Rhat n.eff
-## det1     0.45 0.01 0.43 0.45  0.47 1.01   296
-## det2     0.41 0.01 0.39 0.41  0.42 1.05   244
-## phi11[1] 0.50 0.01 0.49 0.50  0.52 1.00   478
-## phi11[2] 0.16 0.01 0.15 0.16  0.17 1.01   834
-## phi11[3] 0.34 0.01 0.32 0.34  0.35 1.00   565
-## phi12[1] 0.10 0.00 0.09 0.10  0.11 1.00   496
-## phi12[2] 0.57 0.01 0.55 0.57  0.59 1.02   382
-## phi12[3] 0.33 0.01 0.32 0.34  0.35 1.02   421
-## phi21[1] 0.36 0.03 0.31 0.36  0.42 1.00   900
-## phi21[2] 0.33 0.03 0.27 0.33  0.38 1.01  1149
-## phi21[3] 0.31 0.03 0.24 0.31  0.37 1.01   932
-## phi22[1] 0.06 0.00 0.05 0.06  0.07 1.00   676
-## phi22[2] 0.63 0.01 0.61 0.63  0.64 1.01  1140
-## phi22[3] 0.31 0.01 0.30 0.31  0.33 1.00   965
+## det1     0.45 0.01 0.43 0.45  0.47 1.01   597
+## det2     0.41 0.01 0.39 0.41  0.42 1.02   613
+## phi11[1] 0.50 0.01 0.49 0.50  0.52 1.01   889
+## phi11[2] 0.16 0.01 0.15 0.16  0.17 1.01  1103
+## phi11[3] 0.34 0.01 0.32 0.34  0.35 1.00  1206
+## phi12[1] 0.10 0.00 0.09 0.10  0.11 1.01   931
+## phi12[2] 0.57 0.01 0.55 0.57  0.59 1.02   838
+## phi12[3] 0.34 0.01 0.32 0.34  0.35 1.01  1007
+## phi21[1] 0.37 0.03 0.31 0.36  0.42 1.00  1784
+## phi21[2] 0.32 0.03 0.27 0.32  0.38 1.00  2196
+## phi21[3] 0.31 0.03 0.25 0.31  0.38 1.00  1634
+## phi22[1] 0.06 0.00 0.05 0.06  0.07 1.00  1424
+## phi22[2] 0.63 0.01 0.61 0.63  0.64 1.00  2356
+## phi22[3] 0.31 0.01 0.30 0.31  0.33 1.00  2067
 \end{verbatim}
 
 which we can reaarange as in Table \ref{tab:memoryres} to the results obtained by \citet{pradel_multievent_2005} in his Table 1:
-\textbackslash begin\{table\}
 
-\textbackslash caption\{\label{tab:memoryres}Second-order (memory) estimates of transition probabilities. The first column gives the Transition made in \(t\) to \(t+1\) where M is for mid--Atlantic and C for Chesapeake. The second column gives the Condition that is whether the location at \(t+1\) is Equal or Not equal to the location at \(t-1\). The Pradel (2005) time-averaged estimates are given in the third column. Our NIMBLE estimates (mean and 95\% credible interval) are given in the fourth column. \}
+\begin{table}
 \centering
-
-\begin{tabular}[t]{l|l|c|c}
-\hline
+\caption{\label{tab:memoryres}Second-order (memory) estimates of transition probabilities.}
+\centering
+\begin{tabular}[t]{llcc}
+\toprule
 Transition & Condition & Pradel (avg 1985‚Äì88) & NIMBLE\\
-\hline
-MM & Equal to t-1 & 0.57 & 0.50 (0.49‚Äì0.52)\\
-\hline
+\midrule
+\cellcolor{gray!10}{MM} & \cellcolor{gray!10}{Equal to t-1} & \cellcolor{gray!10}{0.57} & \cellcolor{gray!10}{0.50 (0.49‚Äì0.52)}\\
 MM & Not equal to t-1 & 0.33 & 0.36 (0.31‚Äì0.42)\\
-\hline
-MC & Equal to t-1 & 0.27 & 0.33 (0.27‚Äì0.38)\\
-\hline
+\cellcolor{gray!10}{MC} & \cellcolor{gray!10}{Equal to t-1} & \cellcolor{gray!10}{0.27} & \cellcolor{gray!10}{0.33 (0.27‚Äì0.38)}\\
 MC & Not equal to t-1 & 0.09 & 0.16 (0.15‚Äì0.17)\\
-\hline
-CM & Equal to t-1 & 0.21 & 0.10 (0.09‚Äì0.11)\\
-\hline
+\cellcolor{gray!10}{CM} & \cellcolor{gray!10}{Equal to t-1} & \cellcolor{gray!10}{0.21} & \cellcolor{gray!10}{0.10 (0.09‚Äì0.11)}\\
+\addlinespace
 CM & Not equal to t-1 & 0.05 & 0.06 (0.05‚Äì0.07)\\
-\hline
-CC & Equal to t-1 & 0.63 & 0.63 (0.61‚Äì0.64)\\
-\hline
+\cellcolor{gray!10}{CC} & \cellcolor{gray!10}{Equal to t-1} & \cellcolor{gray!10}{0.63} & \cellcolor{gray!10}{0.63 (0.61‚Äì0.64)}\\
 CC & Not equal to t-1 & 0.48 & 0.57 (0.55‚Äì0.59)\\
-\hline
+\bottomrule
 \end{tabular}
+\end{table}
+
+\justifying
 
-\textbackslash end\{table\}
+In Table \ref{tab:memoryres}, the first column gives the Transition made in \(t\) to \(t+1\) where M is for mid--Atlantic and C for Chesapeake. The second column gives the Condition that is whether the location at \(t+1\) is Equal or Not equal to the location at \(t-1\). The \citet{pradel_multievent_2005} time-averaged estimates are given in the third column. Our NIMBLE estimates (mean and 95\% credible interval) are given in the fourth column.
 
 In both analyses, memory is real: for each transition, the probability is higher when the destination at \(t+1\) matches where the bird was at \(t‚àí1\) (`Equal to \(t-1\)' rows) than when it doesn't (`Not equal to \(t-1\)' rows). That's site fidelity or directional return. Our fit mirrors Pradel's fit especially well for staying in Chesapeake (CC, equal: 0.63 in both) and still shows a clear memory signal for staying in mid-Atlantic (MM, 0.50 vs 0.57 when equal). Moves also carry memory: MC is more likely when the bird was in C two steps back (0.33 vs 0.16), and CM shows a weaker but similar pattern (0.10 vs 0.06).
 
@@ -9482,68 +9532,66 @@ \subsection{Model and NIMBLE implementation}\label{model-and-nimble-implementati
 
 \begin{verbatim}
 ##     mean   sd 2.5%  50% 97.5% Rhat n.eff
-## phi 0.70 0.01 0.67 0.70  0.73 1.00  1074
-## pi  0.70 0.03 0.63 0.70  0.76 1.01   722
-## pp1 0.45 0.02 0.40 0.45  0.49 1.00   492
-## pp2 0.49 0.03 0.43 0.48  0.55 1.01   632
+## phi 0.70 0.01 0.67 0.70  0.72 1.01  1003
+## pi  0.70 0.03 0.63 0.70  0.76 1.01   631
+## pp1 0.45 0.02 0.40 0.45  0.50 1.02   431
+## pp2 0.48 0.03 0.43 0.48  0.55 1.01   638
 \end{verbatim}
 
 These estimates diverge markedly from the values used to simulate the data, see Table \ref{tab:simpar}:
 
 \begin{table}
-
+\centering
 \caption{\label{tab:simpar}Comparison of posterior estimates from NIMBLE with the data-generating values for a finite--mixture HMM.}
 \centering
-\begin{tabular}[t]{l|c|c}
-\hline
+\begin{longtable}{lcc}
+\toprule
 Parameter & True value & Posterior mean (95\% credible interval)\\
-\hline
-phi & 0.7 & 0.70 (0.67‚Äì0.73)\\
-\hline
+\midrule
+\cellcolor{gray!10}{phi} & \cellcolor{gray!10}{0.7} & \cellcolor{gray!10}{0.70 (0.67‚Äì0.73)}\\
 pi & 0.2 & 0.70 (0.63‚Äì0.76)\\
-\hline
-pp1 & 0.8 & 0.45 (0.40‚Äì0.49)\\
-\hline
+\cellcolor{gray!10}{pp1} & \cellcolor{gray!10}{0.8} & \cellcolor{gray!10}{0.45 (0.40‚Äì0.49)}\\
 pp2 & 0.3 & 0.49 (0.43‚Äì0.55)\\
-\hline
-\end{tabular}
+\bottomrule
+\end{longtable}
 \end{table}
 
+\justifying
+
 Why is that? The first issue is that the classes were permuted. In our model, nothing tells NIMBLE that the highly detectable individuals must belong to class A1 and the less detectable ones to class A2. The labeling of the classes is arbitrary. The interpretation only comes afterwards, by inspecting the parameter estimates. Now if we re-calculate \(\pi\) as the proportion of individuals in A1 as follows:
 
 \begin{Shaded}
 \begin{Highlighting}[]
 \NormalTok{samples }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(mcmc.phipmix[[}\DecValTok{1}\NormalTok{]], mcmc.phipmix[[}\DecValTok{2}\NormalTok{]])}
 \NormalTok{pi }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ samples[,}\StringTok{\textquotesingle{}pi\textquotesingle{}}\NormalTok{]}
 \FunctionTok{mean}\NormalTok{(pi)}
-\DocumentationTok{\#\# [1] 0.305}
+\DocumentationTok{\#\# [1] 0.3041}
 \FunctionTok{quantile}\NormalTok{(pi, }\AttributeTok{probs =} \FunctionTok{c}\NormalTok{(}\FloatTok{2.5}\NormalTok{, }\FloatTok{97.5}\NormalTok{)}\SpecialCharTok{/}\DecValTok{100}\NormalTok{)}
 \DocumentationTok{\#\#   2.5\%  97.5\% }
-\DocumentationTok{\#\# 0.2418 0.3715}
+\DocumentationTok{\#\# 0.2417 0.3727}
 \end{Highlighting}
 \end{Shaded}
 
 we can get a sorted new Table \ref{tab:simpar2}:
 
 \begin{table}
-
+\centering
 \caption{\label{tab:simpar2}Comparison of posterior estimates from NIMBLE with the data-generating values for a finite--mixture HMM.}
 \centering
-\begin{tabular}[t]{l|c|c}
-\hline
+\begin{longtable}{lcc}
+\toprule
 Parameter & True value & Posterior mean (95\% credible interval)\\
-\hline
-phi & 0.7 & 0.70 (0.67‚Äì0.73)\\
-\hline
+\midrule
+\cellcolor{gray!10}{phi} & \cellcolor{gray!10}{0.7} & \cellcolor{gray!10}{0.70 (0.67‚Äì0.73)}\\
 pi & 0.2 & 0.30 (0.24‚Äì0.37)\\
-\hline
-pp1 & 0.8 & 0.49 (0.43‚Äì0.55)\\
-\hline
+\cellcolor{gray!10}{pp1} & \cellcolor{gray!10}{0.8} & \cellcolor{gray!10}{0.49 (0.43‚Äì0.55)}\\
 pp2 & 0.3 & 0.45 (0.40‚Äì0.49)\\
-\hline
-\end{tabular}
+\bottomrule
+\end{longtable}
 \end{table}
 
+\justifying
+
 Still, the detection estimates are off. There's a deeper issue here. The HMM formulation we used for capturing heterogeneity creates a limitation: individuals are not allowed to switch between classes over time (e.g., from A1 to A2), because the transition matrix does not permit it. In other words, any individual seen \textgreater{} 1 time (it's detected after the first observation occasion) can \emph{never} change class assignments away from their initial value class assignment. Why this formulation fails? The problem is subtle but fundamental: in a HMM, transitions between states are governed by a Markov process. If the transition matrix says an individual in A1 must stay in A1 (or die), then the individual is permanently locked in that class. As a result, once an individual is assigned to a class through its initial latent state (e.g., A1), it can never change class during sampling. Even worse, any individual seen on multiple occasions (say, years 1 and 4) must stay alive during those years, the latent state cannot `jump' between classes without violating the transition constraints, therefore, the initial class assignment is fixed forever, and the MCMC sampler cannot explore the alternative class, no matter how much data supports it.
 
 I must confess, I got stuck in that trap, and it was only because I used simulations that I could identify the problem. I then asked the NIMBLE team for help, and Daniel Turek came up with the explanation -- thanks, Daniel!
@@ -9755,24 +9803,23 @@ \subsection{Results and interpretation}\label{results-and-interpretation-5}
 The results in Table \ref{tab:okidh} look fine now:
 
 \begin{table}
-
+\centering
 \caption{\label{tab:okidh}Posterior estimates vs. data-generating values for a finite--mixture HMM, when a marginalized likelihood is used.}
 \centering
-\begin{tabular}[t]{l|c|c}
-\hline
+\begin{longtable}{lcc}
+\toprule
 Parameter & True value & Posterior mean (95\% credible interval)\\
-\hline
-phi & 0.7 & 0.72 (0.69‚Äì0.75)\\
-\hline
-pi & 0.2 & 0.28 (0.10‚Äì0.46)\\
-\hline
-pp1 & 0.8 & 0.79 (0.65‚Äì0.92)\\
-\hline
-pp2 & 0.3 & 0.27 (0.18‚Äì0.35)\\
-\hline
-\end{tabular}
+\midrule
+\cellcolor{gray!10}{phi} & \cellcolor{gray!10}{0.7} & \cellcolor{gray!10}{0.72 (0.69‚Äì0.75)}\\
+pi & 0.2 & 0.27 (0.10‚Äì0.46)\\
+\cellcolor{gray!10}{pp1} & \cellcolor{gray!10}{0.8} & \cellcolor{gray!10}{0.79 (0.65‚Äì0.93)}\\
+pp2 & 0.3 & 0.27 (0.17‚Äì0.35)\\
+\bottomrule
+\end{longtable}
 \end{table}
 
+\justifying
+
 In summary, when modeling unobservable individual heterogeneity (e.g., detection classes) in an HMM, avoid encoding class identity as a dynamic state. Instead, treat it as a fixed latent variable, or marginalize it out. Otherwise, the model is unable to explore the full posterior and will yield biased or unreliable estimates.
 
 A question that remains is the number of classes we should use. In other words, why 2 classes and not 3 or 4? One option is to fit models with more classes and select among them \citep[e.g.,][]{cubaynes2012}. Alternatively, you can take a non-parametric route and let the data decide how many classes are needed; this is relatively easy in NIMBLE \citep[see][]{turek_bayesian_2021}.
@@ -10425,40 +10472,33 @@ \subsection{Results and interpretation}\label{results-and-interpretation-7}
 which we can re-arrange as in Table \ref{tab:dolphin} to compare them to the estimates obtained by \citet{couet2019}:
 
 \begin{table}
-
+\centering
 \caption{\label{tab:dolphin}Age-specific estimates of breeding probabilities. Comparison of our NIMBLE estimates with Couet et al. (2019). 'NR' denotes quantities not reported in the paper. 'NB' is for non-breeding and 'yoy' for young-of-the-year. Adult female detection on the paper side is a rough time-average read by eye from the authors' Figure 3 (2005‚Äì2016).}
 \centering
-\begin{tabular}[t]{l|c|c}
-\hline
+\begin{longtable}{lcc}
+\toprule
 Parameter & NIMBLE & Couet\\
-\hline
-Adult female survival & 0.96 (0.94‚Äì0.98) & 0.97 (0.96-0.98)\\
-\hline
+\midrule
+\cellcolor{gray!10}{Adult female survival} & \cellcolor{gray!10}{0.96 (0.94‚Äì0.98)} & \cellcolor{gray!10}{0.97 (0.96-0.98)}\\
 Calf observation, yoy & 0.59 (0.49‚Äì0.69) & 0.58 (0.46-0.68)\\
-\hline
-Calf observation, 1-3y & 0.80 (0.70‚Äì0.89) & 0.79 (0.59-0.90)\\
-\hline
+\cellcolor{gray!10}{Calf observation, 1-3y} & \cellcolor{gray!10}{0.80 (0.70‚Äì0.89)} & \cellcolor{gray!10}{0.79 (0.59-0.90)}\\
 Calf survival (yoy) & 0.63 (0.55‚Äì0.73) & 0.66 (0.50-0.78)\\
-\hline
-Calf survival (1y) & 0.69 (0.53‚Äì0.83) & 0.45 (0.29-0.61)\\
-\hline
+\cellcolor{gray!10}{Calf survival (1y)} & \cellcolor{gray!10}{0.69 (0.53‚Äì0.83)} & \cellcolor{gray!10}{0.45 (0.29-0.61)}\\
+\addlinespace
 Female detection: NB or calf 2-3y & 0.63 (0.58‚Äì0.69) & ‚âà0.47\\
-\hline
-Female detection: yoy or 1-year calf & 0.79 (0.72‚Äì0.86) & ‚âà0.61\\
-\hline
+\cellcolor{gray!10}{Female detection: yoy or 1-year calf} & \cellcolor{gray!10}{0.79 (0.72‚Äì0.86)} & \cellcolor{gray!10}{‚âà0.61}\\
 Initial state NB & 0.49 (0.37‚Äì0.60) & NR\\
-\hline
-Initial state Byoy & 0.26 (0.17‚Äì0.37) & NR\\
-\hline
+\cellcolor{gray!10}{Initial state Byoy} & \cellcolor{gray!10}{0.26 (0.17‚Äì0.37)} & \cellcolor{gray!10}{NR}\\
 Initial state Bc1 & 0.08 (0.03‚Äì0.16) & NR\\
-\hline
-Initial state Bc2 & 0.14 (0.07‚Äì0.23) & NR\\
-\hline
+\addlinespace
+\cellcolor{gray!10}{Initial state Bc2} & \cellcolor{gray!10}{0.14 (0.07‚Äì0.23)} & \cellcolor{gray!10}{NR}\\
 Initial state Bc3 & 0.03 (0.00‚Äì0.10) & NR\\
-\hline
-\end{tabular}
+\bottomrule
+\end{longtable}
 \end{table}
 
+\justifying
+
 Our NIMBLE estimates track the published values closely. Calf survival shows some discrepancies, but credible and confidence intervals overlap, so I would not worry too much. Note also that our model differs slightly: we held adult female detection constant in time, whereas the paper models it as time‚Äêdependent.
 
 Offspring are often missed even when a female is breeding, especially young of the year, which are harder to see than older calves. Offspring detection is well below 1. Adult detection also depends on the female's state: females with a young of the year or 1-year calf are more detectable than non-breeders or those with older calves.

---FILE: docs/conclusion.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.9.0/transition.js""></script><script src=""libs/bs3compat-0.9.0/tabs.js""></script><script src=""libs/bs3compat-0.9.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -131,7 +132,7 @@ <h1>Conclusion<a class=""anchor"" aria-label=""anchor"" href=""#conclusion""><i class=
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-07.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-10.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/covariateschapter.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.9.0/transition.js""></script><script src=""libs/bs3compat-0.9.0/tabs.js""></script><script src=""libs/bs3compat-0.9.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -503,76 +504,124 @@ <h3>
 ## phiC    0.53 0.13 0.28 0.53  0.78 1.00  3563
 ## pi      0.27 0.09 0.12 0.26  0.49 1.02  1416</code></pre>
 <p>which we can arrange as in Table <a href=""covariateschapter.html#tab:ageuncertaintycompare"">6.1</a> to compare them with the results obtained by <span class=""citation"">Gervasi et al. (<a href=""references.html#ref-Gervasi2017"">2017</a>)</span>:</p>
-<div class=""inline-table""><table class=""table table-sm"">
+<div class=""inline-table""><table class=""table"" style=""width: auto !important; margin-left: auto; margin-right: auto;"">
 <caption>
-<span id=""tab:ageuncertaintycompare"">Table 6.1: </span>Comparison of parameter estimates for the same HMM to account for age uncertainty: our NIMBLE fit vs.¬†Gervasi et al.¬†(2017, Table 3). Intervals are 95% credible intervals for NIMBLE and confidence intervals for Gervasi et al.. Detection in Gervasi et al.¬†varies by design/year; I report their overall average.</caption>
-<colgroup>
-<col width=""50%"">
-<col width=""21%"">
-<col width=""27%"">
-</colgroup>
-<thead><tr class=""header"">
-<th align=""center"">Parameter</th>
-<th align=""center"">NIMBLE</th>
-<th align=""center"">Gervasi et al.¬†(2017)</th>
+<span id=""tab:ageuncertaintycompare"">Table 6.1: </span><span id=""tab:ageuncertaintycompare"">Table 6.2: </span>Comparison of parameter estimates for the same HMM to account for age uncertainty: our NIMBLE fit vs.¬†Gervasi et al.¬†(2017, Table 3).
+</caption>
+<thead><tr>
+<th style=""text-align:center;"">
+Parameter
+</th>
+<th style=""text-align:center;"">
+NIMBLE
+</th>
+<th style=""text-align:center;"">
+Gervasi et al.¬†(2017)
+</th>
 </tr></thead>
 <tbody>
-<tr class=""odd"">
-<td align=""center"">
-<span class=""math inline"">\(\phi_C\)</span> (cub survival)</td>
-<td align=""center"">0.53 (0.28‚Äì0.78)</td>
-<td align=""center"">0.51 (0.22‚Äì0.79)</td>
+<tr>
+<td style=""text-align:center;"">
+<span class=""math inline"">\(\phi_C\)</span> (cub survival)
+</td>
+<td style=""text-align:center;"">
+0.53 (0.28‚Äì0.78)
+</td>
+<td style=""text-align:center;"">
+0.51 (0.22‚Äì0.79)
+</td>
 </tr>
-<tr class=""even"">
-<td align=""center"">
-<span class=""math inline"">\(\phi_{A,f}\)</span> (adult female)</td>
-<td align=""center"">0.88 (0.80‚Äì0.94)</td>
-<td align=""center"">0.92 (0.87‚Äì0.95)</td>
+<tr>
+<td style=""text-align:center;"">
+<span class=""math inline"">\(\phi_{A,f}\)</span> (adult female)
+</td>
+<td style=""text-align:center;"">
+0.88 (0.80‚Äì0.94)
+</td>
+<td style=""text-align:center;"">
+0.92 (0.87‚Äì0.95)
+</td>
 </tr>
-<tr class=""odd"">
-<td align=""center"">
-<span class=""math inline"">\(\phi_{A,m}\)</span> (adult male)</td>
-<td align=""center"">0.82 (0.69‚Äì0.92)</td>
-<td align=""center"">0.85 (0.76‚Äì0.91)</td>
+<tr>
+<td style=""text-align:center;"">
+<span class=""math inline"">\(\phi_{A,m}\)</span> (adult male)
+</td>
+<td style=""text-align:center;"">
+0.82 (0.69‚Äì0.92)
+</td>
+<td style=""text-align:center;"">
+0.85 (0.76‚Äì0.91)
+</td>
 </tr>
-<tr class=""even"">
-<td align=""center"">
-<span class=""math inline"">\(p\)</span> (detection)</td>
-<td align=""center"">0.71 (0.63‚Äì0.79)</td>
-<td align=""center"">‚âà0.71 (0.62‚Äì0.79)</td>
+<tr>
+<td style=""text-align:center;"">
+<span class=""math inline"">\(p\)</span> (detection)
+</td>
+<td style=""text-align:center;"">
+0.71 (0.63‚Äì0.79)
+</td>
+<td style=""text-align:center;"">
+‚âà0.71 (0.62‚Äì0.79)
+</td>
 </tr>
-<tr class=""odd"">
-<td align=""center"">
-<span class=""math inline"">\(\pi\)</span> (cub at first detection)</td>
-<td align=""center"">0.27 (0.12‚Äì0.49)</td>
-<td align=""center"">0.062 (0.007‚Äì0.396)</td>
+<tr>
+<td style=""text-align:center;"">
+<span class=""math inline"">\(\pi\)</span> (cub at first detection)
+</td>
+<td style=""text-align:center;"">
+0.27 (0.12‚Äì0.49)
+</td>
+<td style=""text-align:center;"">
+0.062 (0.007‚Äì0.396)
+</td>
 </tr>
-<tr class=""even"">
-<td align=""center"">
-<span class=""math inline"">\(C_{c,cc}\)</span> (cub by both | cub)</td>
-<td align=""center"">0.30 (0.13‚Äì0.50)</td>
-<td align=""center"">0.40 (0.15‚Äì0.72)</td>
+<tr>
+<td style=""text-align:center;"">
+<span class=""math inline"">\(C_{c,cc}\)</span> (cub by both given cub)
+</td>
+<td style=""text-align:center;"">
+0.30 (0.13‚Äì0.50)
+</td>
+<td style=""text-align:center;"">
+0.40 (0.15‚Äì0.72)
+</td>
 </tr>
-<tr class=""odd"">
-<td align=""center"">
-<span class=""math inline"">\(C_{c,ca}\)</span> (cub by P1 only | cub)</td>
-<td align=""center"">0.57 (0.33‚Äì0.79)</td>
-<td align=""center"">0.60 (0.28‚Äì0.85)</td>
+<tr>
+<td style=""text-align:center;"">
+<span class=""math inline"">\(C_{c,ca}\)</span> (cub by P1 only given cub)
+</td>
+<td style=""text-align:center;"">
+0.57 (0.33‚Äì0.79)
+</td>
+<td style=""text-align:center;"">
+0.60 (0.28‚Äì0.85)
+</td>
 </tr>
-<tr class=""even"">
-<td align=""center"">
-<span class=""math inline"">\(C_{a,cc}\)</span> (cub by both | adult)</td>
-<td align=""center"">0.02 (0.00‚Äì0.05)</td>
-<td align=""center"">0.067 (0.024‚Äì0.174)</td>
+<tr>
+<td style=""text-align:center;"">
+<span class=""math inline"">\(C_{a,cc}\)</span> (cub by both given adult)
+</td>
+<td style=""text-align:center;"">
+0.02 (0.00‚Äì0.05)
+</td>
+<td style=""text-align:center;"">
+0.067 (0.024‚Äì0.174)
+</td>
 </tr>
-<tr class=""odd"">
-<td align=""center"">
-<span class=""math inline"">\(C_{a,ca}\)</span> (cub by P1 only | adult)</td>
-<td align=""center"">0.05 (0.02‚Äì0.08)</td>
-<td align=""center"">0.191 (0.110‚Äì0.309)</td>
+<tr>
+<td style=""text-align:center;"">
+<span class=""math inline"">\(C_{a,ca}\)</span> (cub by P1 only given adult)
+</td>
+<td style=""text-align:center;"">
+0.05 (0.02‚Äì0.08)
+</td>
+<td style=""text-align:center;"">
+0.191 (0.110‚Äì0.309)
+</td>
 </tr>
 </tbody>
 </table></div>
+<p>Intervals in Table <a href=""covariateschapter.html#tab:ageuncertaintycompare"">6.1</a> are 95% credible intervals for NIMBLE and confidence intervals for <span class=""citation"">Gervasi et al. (<a href=""references.html#ref-Gervasi2017"">2017</a>)</span>. Detection in <span class=""citation"">Gervasi et al. (<a href=""references.html#ref-Gervasi2017"">2017</a>)</span> varies by design and year; I report their overall average.</p>
 <p>Our NIMBLE fit reproduces the main biological signals reported for the Apennine brown bear. Survival shows the expected ordering, that cubs &lt;&lt; adults, and adult females &gt; adult males ‚Äì with estimates that closely match the published analysis. The credible/confidence intervals overlap broadly, indicating good agreement.</p>
 <p>Our detection estimate aligns with the study‚Äôs average detection, even though their analysis lets detection vary by design and year rather than assuming a single constant value.</p>
 <p>For age classification (linking the hidden age to P1/P2 outcomes), mapping our parameters to theirs, we found lower adult-as-cub misclassification than the paper (and thus a higher probability that detected adults are correctly called ‚Äòadult by both‚Äô), which still matches their qualitative take: the stricter criterion (P2) performs very well for adults.</p>
@@ -807,85 +856,147 @@ <h3>
 ## x[2] 0.55 0.02 0.50 0.55  0.60 1.01   725
 ## x[3] 0.54 0.05 0.44 0.55  0.65 1.00   927
 ## x[4] 0.58 0.04 0.50 0.58  0.67 1.00   753</code></pre>
-<p>which we can arrange in as in Table <a href=""covariateschapter.html#tab:sexuncertainty"">6.2</a> to compare them with the results obtained by <span class=""citation"">Pradel et al. (<a href=""references.html#ref-pradel2008sex"">2008</a>)</span>:</p>
-<div class=""inline-table""><table class=""table table-sm"">
+which we can arrange in as in Table <a href=""covariateschapter.html#tab:sexuncertainty"">6.3</a> to compare them with the results obtained by <span class=""citation"">Pradel et al. (<a href=""references.html#ref-pradel2008sex"">2008</a>)</span>:
+<div class=""inline-table""><table class=""table"" style=""width: auto !important; margin-left: auto; margin-right: auto;"">
 <caption>
-<span id=""tab:sexuncertainty"">Table 6.2: </span>Comparison of parameter estimates for the same HMM to account for sex uncertainty: our NIMBLE fit vs.¬†Pradel et al.¬†(2008, Table 5, model B no genetically sexed anchors). Intervals are 95% credible intervals for NIMBLE and confidence intervals for Pradel et al.. Our error rates are 1 ‚àí x[i]. Pradel‚Äôs m‚Äôs were provided by the main author of the paper himself. Note that m4 is time-varying; the estimates were for t=1,‚Ä¶,10: 0.001, 0.002, 0.004, 0.007, 0.014, 0.026, 0.047, 0.084, 0.146, 0.242.</caption>
-<colgroup>
-<col width=""36%"">
-<col width=""24%"">
-<col width=""38%"">
-</colgroup>
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""center"">NIMBLE</th>
-<th align=""center"">Pradel et al.¬†(2008)</th>
+<span id=""tab:sexuncertainty"">Table 6.3: </span><span id=""tab:sexuncertainty"">Table 6.4: </span>Comparison of parameter estimates for the same HMM to account for sex uncertainty: our NIMBLE fit vs.¬†Pradel et al.¬†(2008, Table 5, model B no genetically sexed anchors).
+</caption>
+<thead><tr>
+<th style=""text-align:left;"">
+Parameter
+</th>
+<th style=""text-align:center;"">
+NIMBLE
+</th>
+<th style=""text-align:center;"">
+Pradel et al.¬†(2008)
+</th>
 </tr></thead>
 <tbody>
-<tr class=""odd"">
-<td align=""left"">
-<span class=""math inline"">\(\mu\)</span> (proportion male)</td>
-<td align=""center"">0.52 (0.50‚Äì0.55)</td>
-<td align=""center"">0.53 (SE 0.03)</td>
+<tr>
+<td style=""text-align:left;"">
+<span class=""math inline"">\(\mu\)</span> (proportion male)
+</td>
+<td style=""text-align:center;"">
+0.52 (0.50‚Äì0.55)
+</td>
+<td style=""text-align:center;"">
+0.53 (SE 0.03)
+</td>
 </tr>
-<tr class=""even"">
-<td align=""left"">
-<span class=""math inline"">\(\phi_F\)</span> (female survival)</td>
-<td align=""center"">0.90 (0.89‚Äì0.91)</td>
-<td align=""center"">0.91 (SE 0.01)</td>
+<tr>
+<td style=""text-align:left;"">
+<span class=""math inline"">\(\phi_F\)</span> (female survival)
+</td>
+<td style=""text-align:center;"">
+0.90 (0.89‚Äì0.91)
+</td>
+<td style=""text-align:center;"">
+0.91 (SE 0.01)
+</td>
 </tr>
-<tr class=""odd"">
-<td align=""left"">
-<span class=""math inline"">\(\phi_M\)</span> (male survival)</td>
-<td align=""center"">0.89 (0.88‚Äì0.90)</td>
-<td align=""center"">0.86 (SE 0.01)</td>
+<tr>
+<td style=""text-align:left;"">
+<span class=""math inline"">\(\phi_M\)</span> (male survival)
+</td>
+<td style=""text-align:center;"">
+0.89 (0.88‚Äì0.90)
+</td>
+<td style=""text-align:center;"">
+0.86 (SE 0.01)
+</td>
 </tr>
-<tr class=""even"">
-<td align=""left"">
-<span class=""math inline"">\(m_1\)</span> (Copulation)</td>
-<td align=""center"">0.29 (0.26‚Äì0.32)</td>
-<td align=""center"">0.29</td>
+<tr>
+<td style=""text-align:left;"">
+<span class=""math inline"">\(m_1\)</span> (Copulation)
+</td>
+<td style=""text-align:center;"">
+0.29 (0.26‚Äì0.32)
+</td>
+<td style=""text-align:center;"">
+0.29
+</td>
 </tr>
-<tr class=""odd"">
-<td align=""left"">
-<span class=""math inline"">\(m_2\)</span> (Begging)</td>
-<td align=""center"">0.60 (0.56‚Äì0.63)</td>
-<td align=""center"">0.60</td>
+<tr>
+<td style=""text-align:left;"">
+<span class=""math inline"">\(m_2\)</span> (Begging)
+</td>
+<td style=""text-align:center;"">
+0.60 (0.56‚Äì0.63)
+</td>
+<td style=""text-align:center;"">
+0.60
+</td>
 </tr>
-<tr class=""even"">
-<td align=""left"">
-<span class=""math inline"">\(m_3\)</span> (Courtship feeding)</td>
-<td align=""center"">0.11 (0.09‚Äì0.14)</td>
-<td align=""center"">0.11</td>
+<tr>
+<td style=""text-align:left;"">
+<span class=""math inline"">\(m_3\)</span> (Courtship feeding)
+</td>
+<td style=""text-align:center;"">
+0.11 (0.09‚Äì0.14)
+</td>
+<td style=""text-align:center;"">
+0.11
+</td>
 </tr>
-<tr class=""odd"">
-<td align=""left"">
-<span class=""math inline"">\(m_4\)</span> (Body size)</td>
-<td align=""center"">0.17 (0.14‚Äì0.19)</td>
-<td align=""center"">time-varying (see caption)</td>
+<tr>
+<td style=""text-align:left;"">
+<span class=""math inline"">\(m_4\)</span> (Body size)
+</td>
+<td style=""text-align:center;"">
+0.17 (0.14‚Äì0.19)
+</td>
+<td style=""text-align:center;"">
+time-varying
+</td>
 </tr>
-<tr class=""even"">
-<td align=""left"">Error (Copulation)</td>
-<td align=""center"">0.48 (0.42‚Äì0.55)</td>
-<td align=""center"">0.06 (SE 0.04)</td>
+<tr>
+<td style=""text-align:left;"">
+Error (Copulation)
+</td>
+<td style=""text-align:center;"">
+0.48 (0.42‚Äì0.55)
+</td>
+<td style=""text-align:center;"">
+0.06 (SE 0.04)
+</td>
 </tr>
-<tr class=""odd"">
-<td align=""left"">Error (Begging)</td>
-<td align=""center"">0.45 (0.40‚Äì0.50)</td>
-<td align=""center"">0.06 (SE 0.03)</td>
+<tr>
+<td style=""text-align:left;"">
+Error (Begging)
+</td>
+<td style=""text-align:center;"">
+0.45 (0.40‚Äì0.50)
+</td>
+<td style=""text-align:center;"">
+0.06 (SE 0.03)
+</td>
 </tr>
-<tr class=""even"">
-<td align=""left"">Error (Courtship feeding)</td>
-<td align=""center"">0.46 (0.35‚Äì0.56)</td>
-<td align=""center"">0.00 (SE 0.16)</td>
+<tr>
+<td style=""text-align:left;"">
+Error (Courtship feeding)
+</td>
+<td style=""text-align:center;"">
+0.46 (0.35‚Äì0.56)
+</td>
+<td style=""text-align:center;"">
+0.00 (SE 0.16)
+</td>
 </tr>
-<tr class=""odd"">
-<td align=""left"">Error (Body size)</td>
-<td align=""center"">0.42 (0.33‚Äì0.50)</td>
-<td align=""center"">0.09 (SE 0.07)</td>
+<tr>
+<td style=""text-align:left;"">
+Error (Body size)
+</td>
+<td style=""text-align:center;"">
+0.42 (0.33‚Äì0.50)
+</td>
+<td style=""text-align:center;"">
+0.09 (SE 0.07)
+</td>
 </tr>
 </tbody>
 </table></div>
+<p>Intervals in Table <a href=""covariateschapter.html#tab:sexuncertainty"">6.3</a> are 95% credible intervals for NIMBLE and confidence intervals for <span class=""citation"">Pradel et al. (<a href=""references.html#ref-pradel2008sex"">2008</a>)</span>. Our error rates are <code>1 ‚àí x[i]</code>. Pradel‚Äôs <span class=""math inline"">\(m\)</span>‚Äôs were provided by the main author of the paper himself. Note that <code>m4</code> was time-varying; the estimates were for <span class=""math inline"">\(t=1,\ldots,10\)</span>: 0.001, 0.002, 0.004, 0.007, 0.014, 0.026, 0.047, 0.084, 0.146, 0.242.</p>
 <p>Our NIMBLE fit recovers the main biological signals reported for the Audouin‚Äôs gulls analysis. Survival shows the expected ordering ‚Äì adult females ‚â• adult males ‚Äì with broadly overlapping intervals and means that are close to the published model. In our run, the female‚Äìmale gap is a bit smaller (0.90 vs 0.89), but the direction matches the paper‚Äôs message (higher female survival).</p>
 <p>We used a single, constant detection probability and obtained <span class=""math inline"">\(p \approx 0.65\)</span>, which sits near the middle of the year‚Äêspecific values obtained by the authors (not shown in the paper).</p>
 <p>The estimated probabilities of which clue is used align closely with the published analysis for the three ‚Äòbehavioural‚Äô criteria: <span class=""math inline"">\(m_1 \approx 0.29\)</span> (copulation), <span class=""math inline"">\(m_2 \approx 0.60\)</span> (begging), <span class=""math inline"">\(m_3 \approx 0.11\)</span> (courtship feeding). The paper lets body size use vary over time; our constant estimate (<span class=""math inline"">\(m_4 \approx 0.17\)</span>) should be read as a pooled average across years‚Äîconsistent with their finding of a low but increasing use of this criterion.</p>
@@ -961,7 +1072,7 @@ <h3>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-07.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-10.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/crashcourse.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.9.0/transition.js""></script><script src=""libs/bs3compat-0.9.0/tabs.js""></script><script src=""libs/bs3compat-0.9.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -254,7 +255,7 @@ <h3>
 <div class=""sourceCode"" id=""cb9""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""va"">sample_from_posterior</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Beta.html"">rbeta</a></span><span class=""op"">(</span><span class=""fl"">1000</span>, <span class=""fl"">20</span>, <span class=""fl"">39</span><span class=""op"">)</span> <span class=""co""># draw 1000 values from posterior survival beta(20,39)</span></span>
 <span><span class=""fu""><a href=""https://rdrr.io/r/base/mean.html"">mean</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span><span class=""op"">)</span> <span class=""co""># compute mean with Monte Carlo integration</span></span>
-<span><span class=""co"">## [1] 0.3387</span></span></code></pre></div>
+<span><span class=""co"">## [1] 0.3386</span></span></code></pre></div>
 <p>You may check that the mean we have just calculated matches closely the expectation of a beta distribution:</p>
 <div class=""sourceCode"" id=""cb10""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""fl"">20</span><span class=""op"">/</span><span class=""op"">(</span><span class=""fl"">20</span><span class=""op"">+</span><span class=""fl"">39</span><span class=""op"">)</span> <span class=""co""># expectation of beta(20,39)</span></span>
@@ -263,7 +264,7 @@ <h3>
 <div class=""sourceCode"" id=""cb11""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""fu""><a href=""https://rdrr.io/r/stats/quantile.html"">quantile</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span>, probs <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/c.html"">c</a></span><span class=""op"">(</span><span class=""fl"">2.5</span><span class=""op"">/</span><span class=""fl"">100</span>, <span class=""fl"">97.5</span><span class=""op"">/</span><span class=""fl"">100</span><span class=""op"">)</span><span class=""op"">)</span></span>
 <span><span class=""co"">##   2.5%  97.5% </span></span>
-<span><span class=""co"">## 0.2256 0.4655</span></span></code></pre></div>
+<span><span class=""co"">## 0.2223 0.4583</span></span></code></pre></div>
 </div>
 <div id=""markovmodelmcmc"" class=""section level3"" number=""1.5.2"">
 <h3>
@@ -687,7 +688,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-07.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-10.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/dispersal.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.9.0/transition.js""></script><script src=""libs/bs3compat-0.9.0/tabs.js""></script><script src=""libs/bs3compat-0.9.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -1522,7 +1523,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-07.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-10.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/hmmcapturerecapture.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.9.0/transition.js""></script><script src=""libs/bs3compat-0.9.0/tabs.js""></script><script src=""libs/bs3compat-0.9.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -771,7 +772,7 @@ <h2>
 <span>                          nchains <span class=""op"">=</span> <span class=""va"">n.chains</span><span class=""op"">)</span></span>
 <span><span class=""va"">end_time</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/Sys.time.html"">Sys.time</a></span><span class=""op"">(</span><span class=""op"">)</span></span>
 <span><span class=""va"">end_time</span> <span class=""op"">-</span> <span class=""va"">start_time</span></span></code></pre></div>
-<pre><code>## Time difference of 24.87 secs</code></pre>
+<pre><code>## Time difference of 22.68 secs</code></pre>
 <p>We can have a look to numerical summaries:</p>
 <div class=""sourceCode"" id=""cb140""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""fu""><a href=""https://rdrr.io/pkg/MCMCvis/man/MCMCsummary.html"">MCMCsummary</a></span><span class=""op"">(</span><span class=""va"">mcmc.output</span>, round <span class=""op"">=</span> <span class=""fl"">2</span><span class=""op"">)</span></span>
@@ -1022,7 +1023,7 @@ <h4>
 <span><span class=""co"">## |-------------------------------------------------------|</span></span>
 <span><span class=""va"">end_time</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/Sys.time.html"">Sys.time</a></span><span class=""op"">(</span><span class=""op"">)</span></span>
 <span><span class=""va"">end_time</span> <span class=""op"">-</span> <span class=""va"">start_time</span></span>
-<span><span class=""co"">## Time difference of 21.75 secs</span></span></code></pre></div>
+<span><span class=""co"">## Time difference of 20.66 secs</span></span></code></pre></div>
 <p>The numerical summaries are similar to those we obtained with the complete likelihood, and effective samples sizes are larger denoting better mixing:</p>
 <div class=""sourceCode"" id=""cb146""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""fu""><a href=""https://rdrr.io/pkg/MCMCvis/man/MCMCsummary.html"">MCMCsummary</a></span><span class=""op"">(</span><span class=""va"">mcmc.output</span>, round <span class=""op"">=</span> <span class=""fl"">2</span><span class=""op"">)</span></span>
@@ -1102,7 +1103,7 @@ <h4>
 <span><span class=""co"">## |-------------------------------------------------------|</span></span>
 <span><span class=""va"">end_time</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/Sys.time.html"">Sys.time</a></span><span class=""op"">(</span><span class=""op"">)</span></span>
 <span><span class=""va"">end_time</span> <span class=""op"">-</span> <span class=""va"">start_time</span></span>
-<span><span class=""co"">## Time difference of 25.25 secs</span></span></code></pre></div>
+<span><span class=""co"">## Time difference of 23.63 secs</span></span></code></pre></div>
 <p>Now we display the numerical summaries of the posterior distributions:</p>
 <div class=""sourceCode"" id=""cb151""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""fu""><a href=""https://rdrr.io/pkg/MCMCvis/man/MCMCsummary.html"">MCMCsummary</a></span><span class=""op"">(</span><span class=""va"">mcmc.output</span>, round <span class=""op"">=</span> <span class=""fl"">2</span><span class=""op"">)</span></span>
@@ -1240,7 +1241,7 @@ <h2>
 <span><span class=""co"">## |-------------------------------------------------------|</span></span>
 <span><span class=""va"">end_time</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/Sys.time.html"">Sys.time</a></span><span class=""op"">(</span><span class=""op"">)</span></span>
 <span><span class=""va"">end_time</span> <span class=""op"">-</span> <span class=""va"">start_time</span></span>
-<span><span class=""co"">## Time difference of 20.96 secs</span></span>
+<span><span class=""co"">## Time difference of 20.65 secs</span></span>
 <span><span class=""fu""><a href=""https://rdrr.io/pkg/MCMCvis/man/MCMCsummary.html"">MCMCsummary</a></span><span class=""op"">(</span><span class=""va"">mcmc.output</span>, round <span class=""op"">=</span> <span class=""fl"">2</span><span class=""op"">)</span></span>
 <span><span class=""co"">##     mean   sd 2.5%  50% 97.5% Rhat n.eff</span></span>
 <span><span class=""co"">## p   0.61 0.06 0.49 0.61  0.72    1  1455</span></span>
@@ -1756,7 +1757,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-07.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-10.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/index.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.9.0/transition.js""></script><script src=""libs/bs3compat-0.9.0/tabs.js""></script><script src=""libs/bs3compat-0.9.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -102,16 +103,16 @@ <h1>Welcome<a class=""anchor"" aria-label=""anchor"" href=""#welcome""><i class=""fas f
 <!-- The book is also available in [PDF format](https://github.com/oliviergimenez/banana-book/blob/master/docs/banana-book.pdf) (I still need to fix a lot of issues).  -->
 <p>I welcome any feedback. You may raise an issue <a href=""https://github.com/oliviergimenez/banana-book/issues"">here</a>, amend directly the R Markdown file that generated the page you‚Äôre reading by clicking on the ‚ÄòEdit this page‚Äô icon in the right panel, or <a href=""mailto:olivier.gimenez@cefe.cnrs.fr"">email me</a>. Many thanks!</p>
 <p>Olivier Gimenez. Written in Montpellier, France and Athens, Greece.
-Last updated: September 07, 2025</p>
+Last updated: September 10, 2025</p>
 <div id=""how-to-cite"" class=""section level2 unnumbered"">
 <h2>How to cite<a class=""anchor"" aria-label=""anchor"" href=""#how-to-cite""><i class=""fas fa-link""></i></a>
 </h2>
-<p>Gimenez, O. 2026. Bayesian analysis of capture-recapture data with hidden Markov models: Theory and case studies in R and NIMBLE. CRC Press.</p>
+<p>Gimenez, O. 2026. Bayesian analysis of capture-recapture data with hidden Markov models: Theory and case studies in R and NIMBLE. Chapman &amp; Hall/CRC Interdisciplinary Statistics series.</p>
 <div class=""sourceCode"" id=""cb1""><pre class=""sourceCode bibtex""><code class=""sourceCode bibtex""><span id=""cb1-1""><a href=""index.html#cb1-1"" tabindex=""-1""></a><span class=""va"">@book</span>{<span class=""ot"">gimenez2026</span>,</span>
 <span id=""cb1-2""><a href=""index.html#cb1-2"" tabindex=""-1""></a>  <span class=""dt"">title</span> = {Bayesian Analysis of Capture-Recapture Data with Hidden {{Markov}} Models: {{Theory}} and Case Studies in {{R}} and {{NIMBLE}}},</span>
 <span id=""cb1-3""><a href=""index.html#cb1-3"" tabindex=""-1""></a>  <span class=""dt"">author</span> = {Gimenez, Olivier},</span>
 <span id=""cb1-4""><a href=""index.html#cb1-4"" tabindex=""-1""></a>  <span class=""dt"">year</span> = {2026},</span>
-<span id=""cb1-5""><a href=""index.html#cb1-5"" tabindex=""-1""></a>  <span class=""dt"">publisher</span> = {CRC Press}</span>
+<span id=""cb1-5""><a href=""index.html#cb1-5"" tabindex=""-1""></a>  <span class=""dt"">publisher</span> = {Chapman &amp; Hall/CRC Interdisciplinary Statistics series}</span>
 <span id=""cb1-6""><a href=""index.html#cb1-6"" tabindex=""-1""></a>}</span></code></pre></div>
 </div>
 <div id=""license"" class=""section level2 unnumbered"">
@@ -148,7 +149,7 @@ <h2>License<a class=""anchor"" aria-label=""anchor"" href=""#license""><i class=""fas f
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-07.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-10.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/introduction-4.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.9.0/transition.js""></script><script src=""libs/bs3compat-0.9.0/tabs.js""></script><script src=""libs/bs3compat-0.9.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -121,7 +122,7 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-4""><i
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-07.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-10.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/introduction-7.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.9.0/transition.js""></script><script src=""libs/bs3compat-0.9.0/tabs.js""></script><script src=""libs/bs3compat-0.9.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -121,7 +122,7 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-7""><i
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-07.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-10.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/introduction.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.9.0/transition.js""></script><script src=""libs/bs3compat-0.9.0/tabs.js""></script><script src=""libs/bs3compat-0.9.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -121,7 +122,7 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction""><i cl
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-07.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-10.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/intronimble.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.9.0/transition.js""></script><script src=""libs/bs3compat-0.9.0/tabs.js""></script><script src=""libs/bs3compat-0.9.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -1350,7 +1351,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-07.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-10.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/lackoffit.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.9.0/transition.js""></script><script src=""libs/bs3compat-0.9.0/tabs.js""></script><script src=""libs/bs3compat-0.9.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -542,73 +543,141 @@ <h3>
 ## phi22[1] 0.06 0.00 0.05 0.06  0.07 1.00  1424
 ## phi22[2] 0.63 0.01 0.61 0.63  0.64 1.00  2356
 ## phi22[3] 0.31 0.01 0.30 0.31  0.33 1.00  2067</code></pre>
-<p>which we can reaarange as in Table <a href=""lackoffit.html#tab:memoryres"">7.1</a> to the results obtained by <span class=""citation"">Pradel (<a href=""references.html#ref-pradel_multievent_2005"">2005</a>)</span> in his Table 1:</p>
-<div class=""inline-table""><table class=""table table-sm"">
+which we can reaarange as in Table <a href=""lackoffit.html#tab:memoryres"">7.1</a> to the results obtained by <span class=""citation"">Pradel (<a href=""references.html#ref-pradel_multievent_2005"">2005</a>)</span> in his Table 1:
+<div class=""inline-table""><table class=""table"" style=""width: auto !important; margin-left: auto; margin-right: auto;"">
 <caption>
-<span id=""tab:memoryres"">Table 7.1: </span>Second-order (memory) estimates of transition probabilities. The first column gives the Transition made in <span class=""math inline"">\(t\)</span> to <span class=""math inline"">\(t+1\)</span> where M is for mid‚ÄìAtlantic and C for Chesapeake. The second column gives the Condition that is whether the location at <span class=""math inline"">\(t+1\)</span> is Equal or Not equal to the location at <span class=""math inline"">\(t-1\)</span>. The Pradel (2005) time-averaged estimates are given in the third column. Our NIMBLE estimates (mean and 95% credible interval) are given in the fourth column.</caption>
-<colgroup>
-<col width=""16%"">
-<col width=""25%"">
-<col width=""32%"">
-<col width=""26%"">
-</colgroup>
-<thead><tr class=""header"">
-<th align=""left"">Transition</th>
-<th align=""left"">Condition</th>
-<th align=""center"">Pradel (avg 1985‚Äì88)</th>
-<th align=""center"">NIMBLE</th>
+<span id=""tab:memoryres"">Table 7.1: </span><span id=""tab:memoryres"">Table 7.2: </span>Second-order (memory) estimates of transition probabilities.
+</caption>
+<thead><tr>
+<th style=""text-align:left;"">
+Transition
+</th>
+<th style=""text-align:left;"">
+Condition
+</th>
+<th style=""text-align:center;"">
+Pradel (avg 1985‚Äì88)
+</th>
+<th style=""text-align:center;"">
+NIMBLE
+</th>
 </tr></thead>
 <tbody>
-<tr class=""odd"">
-<td align=""left"">MM</td>
-<td align=""left"">Equal to t-1</td>
-<td align=""center"">0.57</td>
-<td align=""center"">0.50 (0.49‚Äì0.52)</td>
+<tr>
+<td style=""text-align:left;"">
+MM
+</td>
+<td style=""text-align:left;"">
+Equal to t-1
+</td>
+<td style=""text-align:center;"">
+0.57
+</td>
+<td style=""text-align:center;"">
+0.50 (0.49‚Äì0.52)
+</td>
 </tr>
-<tr class=""even"">
-<td align=""left"">MM</td>
-<td align=""left"">Not equal to t-1</td>
-<td align=""center"">0.33</td>
-<td align=""center"">0.36 (0.31‚Äì0.42)</td>
+<tr>
+<td style=""text-align:left;"">
+MM
+</td>
+<td style=""text-align:left;"">
+Not equal to t-1
+</td>
+<td style=""text-align:center;"">
+0.33
+</td>
+<td style=""text-align:center;"">
+0.36 (0.31‚Äì0.42)
+</td>
 </tr>
-<tr class=""odd"">
-<td align=""left"">MC</td>
-<td align=""left"">Equal to t-1</td>
-<td align=""center"">0.27</td>
-<td align=""center"">0.33 (0.27‚Äì0.38)</td>
+<tr>
+<td style=""text-align:left;"">
+MC
+</td>
+<td style=""text-align:left;"">
+Equal to t-1
+</td>
+<td style=""text-align:center;"">
+0.27
+</td>
+<td style=""text-align:center;"">
+0.33 (0.27‚Äì0.38)
+</td>
 </tr>
-<tr class=""even"">
-<td align=""left"">MC</td>
-<td align=""left"">Not equal to t-1</td>
-<td align=""center"">0.09</td>
-<td align=""center"">0.16 (0.15‚Äì0.17)</td>
+<tr>
+<td style=""text-align:left;"">
+MC
+</td>
+<td style=""text-align:left;"">
+Not equal to t-1
+</td>
+<td style=""text-align:center;"">
+0.09
+</td>
+<td style=""text-align:center;"">
+0.16 (0.15‚Äì0.17)
+</td>
 </tr>
-<tr class=""odd"">
-<td align=""left"">CM</td>
-<td align=""left"">Equal to t-1</td>
-<td align=""center"">0.21</td>
-<td align=""center"">0.10 (0.09‚Äì0.11)</td>
+<tr>
+<td style=""text-align:left;"">
+CM
+</td>
+<td style=""text-align:left;"">
+Equal to t-1
+</td>
+<td style=""text-align:center;"">
+0.21
+</td>
+<td style=""text-align:center;"">
+0.10 (0.09‚Äì0.11)
+</td>
 </tr>
-<tr class=""even"">
-<td align=""left"">CM</td>
-<td align=""left"">Not equal to t-1</td>
-<td align=""center"">0.05</td>
-<td align=""center"">0.06 (0.05‚Äì0.07)</td>
+<tr>
+<td style=""text-align:left;"">
+CM
+</td>
+<td style=""text-align:left;"">
+Not equal to t-1
+</td>
+<td style=""text-align:center;"">
+0.05
+</td>
+<td style=""text-align:center;"">
+0.06 (0.05‚Äì0.07)
+</td>
 </tr>
-<tr class=""odd"">
-<td align=""left"">CC</td>
-<td align=""left"">Equal to t-1</td>
-<td align=""center"">0.63</td>
-<td align=""center"">0.63 (0.61‚Äì0.64)</td>
+<tr>
+<td style=""text-align:left;"">
+CC
+</td>
+<td style=""text-align:left;"">
+Equal to t-1
+</td>
+<td style=""text-align:center;"">
+0.63
+</td>
+<td style=""text-align:center;"">
+0.63 (0.61‚Äì0.64)
+</td>
 </tr>
-<tr class=""even"">
-<td align=""left"">CC</td>
-<td align=""left"">Not equal to t-1</td>
-<td align=""center"">0.48</td>
-<td align=""center"">0.57 (0.55‚Äì0.59)</td>
+<tr>
+<td style=""text-align:left;"">
+CC
+</td>
+<td style=""text-align:left;"">
+Not equal to t-1
+</td>
+<td style=""text-align:center;"">
+0.48
+</td>
+<td style=""text-align:center;"">
+0.57 (0.55‚Äì0.59)
+</td>
 </tr>
 </tbody>
 </table></div>
+<p>In Table <a href=""lackoffit.html#tab:memoryres"">7.1</a>, the first column gives the Transition made in <span class=""math inline"">\(t\)</span> to <span class=""math inline"">\(t+1\)</span> where M is for mid‚ÄìAtlantic and C for Chesapeake. The second column gives the Condition that is whether the location at <span class=""math inline"">\(t+1\)</span> is Equal or Not equal to the location at <span class=""math inline"">\(t-1\)</span>. The <span class=""citation"">Pradel (<a href=""references.html#ref-pradel_multievent_2005"">2005</a>)</span> time-averaged estimates are given in the third column. Our NIMBLE estimates (mean and 95% credible interval) are given in the fourth column.</p>
 <p>In both analyses, memory is real: for each transition, the probability is higher when the destination at <span class=""math inline"">\(t+1\)</span> matches where the bird was at <span class=""math inline"">\(t‚àí1\)</span> (‚ÄòEqual to <span class=""math inline"">\(t-1\)</span>‚Äô rows) than when it doesn‚Äôt (‚ÄòNot equal to <span class=""math inline"">\(t-1\)</span>‚Äô rows). That‚Äôs site fidelity or directional return. Our fit mirrors Pradel‚Äôs fit especially well for staying in Chesapeake (CC, equal: 0.63 in both) and still shows a clear memory signal for staying in mid-Atlantic (MM, 0.50 vs 0.57 when equal). Moves also carry memory: MC is more likely when the bird was in C two steps back (0.33 vs 0.16), and CM shows a weaker but similar pattern (0.10 vs 0.06).</p>
 <p>Where we differ is in the directional balance. Relative to Pradel‚Äôs averages, our model leans more toward Chesapeake: we estimate higher MC probabilities (both equal and not equal; e.g., 0.33 vs 0.27 and 0.16 vs 0.09) and lower CM (equal) (0.10 vs 0.21). We also find a higher chance of staying in C (CC, not equal: 0.57 vs 0.48). Several of these differences are well outside our 95% credible intervals (e.g., CM equal 0.09-0.11 vs 0.21, MC not equal 0.15-0.17 vs 0.09). These discrepancies are likely explained by the difference in model structures: ours assumes constant parameters, whereas Pradel‚Äôs allows them to vary over time. The big picture remains the same, though: movements are second‚Äìorder and that memory is asymmetric, being strongest for persistence in Chesapeake and for moves toward it.</p>
 </div>
@@ -817,35 +886,66 @@ <h3>
 ## pi  0.70 0.03 0.63 0.70  0.76 1.01   631
 ## pp1 0.45 0.02 0.40 0.45  0.50 1.02   431
 ## pp2 0.48 0.03 0.43 0.48  0.55 1.01   638</code></pre>
-<p>These estimates diverge markedly from the values used to simulate the data, see Table <a href=""lackoffit.html#tab:simpar"">7.2</a>:</p>
-<div class=""inline-table""><table class=""table table-sm"">
+These estimates diverge markedly from the values used to simulate the data, see Table <a href=""lackoffit.html#tab:simpar"">7.3</a>:
+<div class=""inline-table""><table class=""table"" style=""width: auto !important; margin-left: auto; margin-right: auto;"">
 <caption>
-<span id=""tab:simpar"">Table 7.2: </span>Comparison of posterior estimates from NIMBLE with the data-generating values for a finite‚Äìmixture HMM.</caption>
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""center"">True value</th>
-<th align=""center"">Posterior mean (95% credible interval)</th>
+<span id=""tab:simpar"">Table 7.3: </span><span id=""tab:simpar"">Table 7.4: </span>Comparison of posterior estimates from NIMBLE with the data-generating values for a finite‚Äìmixture HMM.
+</caption>
+<thead><tr>
+<th style=""text-align:left;"">
+Parameter
+</th>
+<th style=""text-align:center;"">
+True value
+</th>
+<th style=""text-align:center;"">
+Posterior mean (95% credible interval)
+</th>
 </tr></thead>
 <tbody>
-<tr class=""odd"">
-<td align=""left"">phi</td>
-<td align=""center"">0.7</td>
-<td align=""center"">0.70 (0.67‚Äì0.73)</td>
+<tr>
+<td style=""text-align:left;"">
+phi
+</td>
+<td style=""text-align:center;"">
+0.7
+</td>
+<td style=""text-align:center;"">
+0.70 (0.67‚Äì0.73)
+</td>
 </tr>
-<tr class=""even"">
-<td align=""left"">pi</td>
-<td align=""center"">0.2</td>
-<td align=""center"">0.70 (0.63‚Äì0.76)</td>
+<tr>
+<td style=""text-align:left;"">
+pi
+</td>
+<td style=""text-align:center;"">
+0.2
+</td>
+<td style=""text-align:center;"">
+0.70 (0.63‚Äì0.76)
+</td>
 </tr>
-<tr class=""odd"">
-<td align=""left"">pp1</td>
-<td align=""center"">0.8</td>
-<td align=""center"">0.45 (0.40‚Äì0.49)</td>
+<tr>
+<td style=""text-align:left;"">
+pp1
+</td>
+<td style=""text-align:center;"">
+0.8
+</td>
+<td style=""text-align:center;"">
+0.45 (0.40‚Äì0.49)
+</td>
 </tr>
-<tr class=""even"">
-<td align=""left"">pp2</td>
-<td align=""center"">0.3</td>
-<td align=""center"">0.49 (0.43‚Äì0.55)</td>
+<tr>
+<td style=""text-align:left;"">
+pp2
+</td>
+<td style=""text-align:center;"">
+0.3
+</td>
+<td style=""text-align:center;"">
+0.49 (0.43‚Äì0.55)
+</td>
 </tr>
 </tbody>
 </table></div>
@@ -858,35 +958,66 @@ <h3>
 <span><span class=""fu""><a href=""https://rdrr.io/r/stats/quantile.html"">quantile</a></span><span class=""op"">(</span><span class=""va"">pi</span>, probs <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/c.html"">c</a></span><span class=""op"">(</span><span class=""fl"">2.5</span>, <span class=""fl"">97.5</span><span class=""op"">)</span><span class=""op"">/</span><span class=""fl"">100</span><span class=""op"">)</span></span>
 <span><span class=""co"">##   2.5%  97.5% </span></span>
 <span><span class=""co"">## 0.2417 0.3727</span></span></code></pre></div>
-<p>we can get a sorted new Table <a href=""lackoffit.html#tab:simpar2"">7.3</a>:</p>
-<div class=""inline-table""><table class=""table table-sm"">
+we can get a sorted new Table <a href=""lackoffit.html#tab:simpar2"">7.5</a>:
+<div class=""inline-table""><table class=""table"" style=""width: auto !important; margin-left: auto; margin-right: auto;"">
 <caption>
-<span id=""tab:simpar2"">Table 7.3: </span>Comparison of posterior estimates from NIMBLE with the data-generating values for a finite‚Äìmixture HMM.</caption>
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""center"">True value</th>
-<th align=""center"">Posterior mean (95% credible interval)</th>
+<span id=""tab:simpar2"">Table 7.5: </span><span id=""tab:simpar2"">Table 7.6: </span>Comparison of posterior estimates from NIMBLE with the data-generating values for a finite‚Äìmixture HMM.
+</caption>
+<thead><tr>
+<th style=""text-align:left;"">
+Parameter
+</th>
+<th style=""text-align:center;"">
+True value
+</th>
+<th style=""text-align:center;"">
+Posterior mean (95% credible interval)
+</th>
 </tr></thead>
 <tbody>
-<tr class=""odd"">
-<td align=""left"">phi</td>
-<td align=""center"">0.7</td>
-<td align=""center"">0.70 (0.67‚Äì0.73)</td>
+<tr>
+<td style=""text-align:left;"">
+phi
+</td>
+<td style=""text-align:center;"">
+0.7
+</td>
+<td style=""text-align:center;"">
+0.70 (0.67‚Äì0.73)
+</td>
 </tr>
-<tr class=""even"">
-<td align=""left"">pi</td>
-<td align=""center"">0.2</td>
-<td align=""center"">0.30 (0.24‚Äì0.37)</td>
+<tr>
+<td style=""text-align:left;"">
+pi
+</td>
+<td style=""text-align:center;"">
+0.2
+</td>
+<td style=""text-align:center;"">
+0.30 (0.24‚Äì0.37)
+</td>
 </tr>
-<tr class=""odd"">
-<td align=""left"">pp1</td>
-<td align=""center"">0.8</td>
-<td align=""center"">0.49 (0.43‚Äì0.55)</td>
+<tr>
+<td style=""text-align:left;"">
+pp1
+</td>
+<td style=""text-align:center;"">
+0.8
+</td>
+<td style=""text-align:center;"">
+0.49 (0.43‚Äì0.55)
+</td>
 </tr>
-<tr class=""even"">
-<td align=""left"">pp2</td>
-<td align=""center"">0.3</td>
-<td align=""center"">0.45 (0.40‚Äì0.49)</td>
+<tr>
+<td style=""text-align:left;"">
+pp2
+</td>
+<td style=""text-align:center;"">
+0.3
+</td>
+<td style=""text-align:center;"">
+0.45 (0.40‚Äì0.49)
+</td>
 </tr>
 </tbody>
 </table></div>
@@ -1084,35 +1215,66 @@ <h3>
 <h3>
 <span class=""header-section-number"">7.4.3</span> Results and interpretation<a class=""anchor"" aria-label=""anchor"" href=""#results-and-interpretation-5""><i class=""fas fa-link""></i></a>
 </h3>
-<p>The results in Table <a href=""lackoffit.html#tab:okidh"">7.4</a> look fine now:</p>
-<div class=""inline-table""><table class=""table table-sm"">
+The results in Table <a href=""lackoffit.html#tab:okidh"">7.7</a> look fine now:
+<div class=""inline-table""><table class=""table"" style=""width: auto !important; margin-left: auto; margin-right: auto;"">
 <caption>
-<span id=""tab:okidh"">Table 7.4: </span>Posterior estimates vs.¬†data-generating values for a finite‚Äìmixture HMM, when a marginalized likelihood is used.</caption>
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""center"">True value</th>
-<th align=""center"">Posterior mean (95% credible interval)</th>
+<span id=""tab:okidh"">Table 7.7: </span><span id=""tab:okidh"">Table 7.8: </span>Posterior estimates vs.¬†data-generating values for a finite‚Äìmixture HMM, when a marginalized likelihood is used.
+</caption>
+<thead><tr>
+<th style=""text-align:left;"">
+Parameter
+</th>
+<th style=""text-align:center;"">
+True value
+</th>
+<th style=""text-align:center;"">
+Posterior mean (95% credible interval)
+</th>
 </tr></thead>
 <tbody>
-<tr class=""odd"">
-<td align=""left"">phi</td>
-<td align=""center"">0.7</td>
-<td align=""center"">0.72 (0.69‚Äì0.75)</td>
+<tr>
+<td style=""text-align:left;"">
+phi
+</td>
+<td style=""text-align:center;"">
+0.7
+</td>
+<td style=""text-align:center;"">
+0.72 (0.69‚Äì0.75)
+</td>
 </tr>
-<tr class=""even"">
-<td align=""left"">pi</td>
-<td align=""center"">0.2</td>
-<td align=""center"">0.27 (0.10‚Äì0.46)</td>
+<tr>
+<td style=""text-align:left;"">
+pi
+</td>
+<td style=""text-align:center;"">
+0.2
+</td>
+<td style=""text-align:center;"">
+0.27 (0.10‚Äì0.46)
+</td>
 </tr>
-<tr class=""odd"">
-<td align=""left"">pp1</td>
-<td align=""center"">0.8</td>
-<td align=""center"">0.79 (0.65‚Äì0.93)</td>
+<tr>
+<td style=""text-align:left;"">
+pp1
+</td>
+<td style=""text-align:center;"">
+0.8
+</td>
+<td style=""text-align:center;"">
+0.79 (0.65‚Äì0.93)
+</td>
 </tr>
-<tr class=""even"">
-<td align=""left"">pp2</td>
-<td align=""center"">0.3</td>
-<td align=""center"">0.27 (0.17‚Äì0.35)</td>
+<tr>
+<td style=""text-align:left;"">
+pp2
+</td>
+<td style=""text-align:center;"">
+0.3
+</td>
+<td style=""text-align:center;"">
+0.27 (0.17‚Äì0.35)
+</td>
 </tr>
 </tbody>
 </table></div>
@@ -1215,7 +1377,7 @@ <h3>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-07.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-10.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/libs/kePrint-0.0.1/kePrint.js---
@@ -0,0 +1,8 @@
+$(document).ready(function(){
+    if (typeof $('[data-toggle=""tooltip""]').tooltip === 'function') {
+        $('[data-toggle=""tooltip""]').tooltip();
+    }
+    if ($('[data-toggle=""popover""]').popover === 'function') {
+        $('[data-toggle=""popover""]').popover();
+    }
+});

---FILE: docs/libs/lightable-0.0.1/lightable.css---
@@ -0,0 +1,272 @@
+/*!
+ * lightable v0.0.1
+ * Copyright 2020 Hao Zhu
+ * Licensed under MIT (https://github.com/haozhu233/kableExtra/blob/master/LICENSE)
+ */
+
+.lightable-minimal {
+  border-collapse: separate;
+  border-spacing: 16px 1px;
+  width: 100%;
+  margin-bottom: 10px;
+}
+
+.lightable-minimal td {
+  margin-left: 5px;
+  margin-right: 5px;
+}
+
+.lightable-minimal th {
+  margin-left: 5px;
+  margin-right: 5px;
+}
+
+.lightable-minimal thead tr:last-child th {
+  border-bottom: 2px solid #00000050;
+  empty-cells: hide;
+
+}
+
+.lightable-minimal tbody tr:first-child td {
+  padding-top: 0.5em;
+}
+
+.lightable-minimal.lightable-hover tbody tr:hover {
+  background-color: #f5f5f5;
+}
+
+.lightable-minimal.lightable-striped tbody tr:nth-child(even) {
+  background-color: #f5f5f5;
+}
+
+.lightable-classic {
+  border-top: 0.16em solid #111111;
+  border-bottom: 0.16em solid #111111;
+  width: 100%;
+  margin-bottom: 10px;
+  margin: 10px 5px;
+}
+
+.lightable-classic tfoot tr td {
+  border: 0;
+}
+
+.lightable-classic tfoot tr:first-child td {
+  border-top: 0.14em solid #111111;
+}
+
+.lightable-classic caption {
+  color: #222222;
+}
+
+.lightable-classic td {
+  padding-left: 5px;
+  padding-right: 5px;
+  color: #222222;
+}
+
+.lightable-classic th {
+  padding-left: 5px;
+  padding-right: 5px;
+  font-weight: normal;
+  color: #222222;
+}
+
+.lightable-classic thead tr:last-child th {
+  border-bottom: 0.10em solid #111111;
+}
+
+.lightable-classic.lightable-hover tbody tr:hover {
+  background-color: #F9EEC1;
+}
+
+.lightable-classic.lightable-striped tbody tr:nth-child(even) {
+  background-color: #f5f5f5;
+}
+
+.lightable-classic-2 {
+  border-top: 3px double #111111;
+  border-bottom: 3px double #111111;
+  width: 100%;
+  margin-bottom: 10px;
+}
+
+.lightable-classic-2 tfoot tr td {
+  border: 0;
+}
+
+.lightable-classic-2 tfoot tr:first-child td {
+  border-top: 3px double #111111;
+}
+
+.lightable-classic-2 caption {
+  color: #222222;
+}
+
+.lightable-classic-2 td {
+  padding-left: 5px;
+  padding-right: 5px;
+  color: #222222;
+}
+
+.lightable-classic-2 th {
+  padding-left: 5px;
+  padding-right: 5px;
+  font-weight: normal;
+  color: #222222;
+}
+
+.lightable-classic-2 tbody tr:last-child td {
+  border-bottom: 3px double #111111;
+}
+
+.lightable-classic-2 thead tr:last-child th {
+  border-bottom: 1px solid #111111;
+}
+
+.lightable-classic-2.lightable-hover tbody tr:hover {
+  background-color: #F9EEC1;
+}
+
+.lightable-classic-2.lightable-striped tbody tr:nth-child(even) {
+  background-color: #f5f5f5;
+}
+
+.lightable-material {
+  min-width: 100%;
+  white-space: nowrap;
+  table-layout: fixed;
+  font-family: Roboto, sans-serif;
+  border: 1px solid #EEE;
+  border-collapse: collapse;
+  margin-bottom: 10px;
+}
+
+.lightable-material tfoot tr td {
+  border: 0;
+}
+
+.lightable-material tfoot tr:first-child td {
+  border-top: 1px solid #EEE;
+}
+
+.lightable-material th {
+  height: 56px;
+  padding-left: 16px;
+  padding-right: 16px;
+}
+
+.lightable-material td {
+  height: 52px;
+  padding-left: 16px;
+  padding-right: 16px;
+  border-top: 1px solid #eeeeee;
+}
+
+.lightable-material.lightable-hover tbody tr:hover {
+  background-color: #f5f5f5;
+}
+
+.lightable-material.lightable-striped tbody tr:nth-child(even) {
+  background-color: #f5f5f5;
+}
+
+.lightable-material.lightable-striped tbody td {
+  border: 0;
+}
+
+.lightable-material.lightable-striped thead tr:last-child th {
+  border-bottom: 1px solid #ddd;
+}
+
+.lightable-material-dark {
+  min-width: 100%;
+  white-space: nowrap;
+  table-layout: fixed;
+  font-family: Roboto, sans-serif;
+  border: 1px solid #FFFFFF12;
+  border-collapse: collapse;
+  margin-bottom: 10px;
+  background-color: #363640;
+}
+
+.lightable-material-dark tfoot tr td {
+  border: 0;
+}
+
+.lightable-material-dark tfoot tr:first-child td {
+  border-top: 1px solid #FFFFFF12;
+}
+
+.lightable-material-dark th {
+  height: 56px;
+  padding-left: 16px;
+  padding-right: 16px;
+  color: #FFFFFF60;
+}
+
+.lightable-material-dark td {
+  height: 52px;
+  padding-left: 16px;
+  padding-right: 16px;
+  color: #FFFFFF;
+  border-top: 1px solid #FFFFFF12;
+}
+
+.lightable-material-dark.lightable-hover tbody tr:hover {
+  background-color: #FFFFFF12;
+}
+
+.lightable-material-dark.lightable-striped tbody tr:nth-child(even) {
+  background-color: #FFFFFF12;
+}
+
+.lightable-material-dark.lightable-striped tbody td {
+  border: 0;
+}
+
+.lightable-material-dark.lightable-striped thead tr:last-child th {
+  border-bottom: 1px solid #FFFFFF12;
+}
+
+.lightable-paper {
+  width: 100%;
+  margin-bottom: 10px;
+  color: #444;
+}
+
+.lightable-paper tfoot tr td {
+  border: 0;
+}
+
+.lightable-paper tfoot tr:first-child td {
+  border-top: 1px solid #00000020;
+}
+
+.lightable-paper thead tr:last-child th {
+  color: #666;
+  vertical-align: bottom;
+  border-bottom: 1px solid #00000020;
+  line-height: 1.15em;
+  padding: 10px 5px;
+}
+
+.lightable-paper td {
+  vertical-align: middle;
+  border-bottom: 1px solid #00000010;
+  line-height: 1.15em;
+  padding: 7px 5px;
+}
+
+.lightable-paper.lightable-hover tbody tr:hover {
+  background-color: #F9EEC1;
+}
+
+.lightable-paper.lightable-striped tbody tr:nth-child(even) {
+  background-color: #00000008;
+}
+
+.lightable-paper.lightable-striped tbody td {
+  border: 0;
+}
+

---FILE: docs/preface.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.9.0/transition.js""></script><script src=""libs/bs3compat-0.9.0/tabs.js""></script><script src=""libs/bs3compat-0.9.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -304,7 +305,7 @@ <h2>Acknowledgements<a class=""anchor"" aria-label=""anchor"" href=""#acknowledgement
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-07.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-10.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/references.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.9.0/transition.js""></script><script src=""libs/bs3compat-0.9.0/tabs.js""></script><script src=""libs/bs3compat-0.9.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -368,7 +369,7 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-07.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-10.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/survival.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.9.0/transition.js""></script><script src=""libs/bs3compat-0.9.0/tabs.js""></script><script src=""libs/bs3compat-0.9.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -1595,7 +1596,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-07.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-10.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/tradeoffs.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.9.0/transition.js""></script><script src=""libs/bs3compat-0.9.0/tabs.js""></script><script src=""libs/bs3compat-0.9.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -740,80 +741,154 @@ <h3>
 ## q[2]             0.80 0.05 0.70 0.80  0.89 1.01   818
 ## youngsurvival[1] 0.63 0.05 0.55 0.63  0.73 1.00   808
 ## youngsurvival[2] 0.69 0.08 0.53 0.69  0.83 1.00  1702</code></pre>
-<p>which we can re-arrange as in Table <a href=""tradeoffs.html#tab:dolphin"">8.1</a> to compare them to the estimates obtained by <span class=""citation"">Couet et al. (<a href=""references.html#ref-couet2019"">2019</a>)</span>:</p>
-<div class=""inline-table""><table class=""table table-sm"">
+which we can re-arrange as in Table <a href=""tradeoffs.html#tab:dolphin"">8.1</a> to compare them to the estimates obtained by <span class=""citation"">Couet et al. (<a href=""references.html#ref-couet2019"">2019</a>)</span>:
+<div class=""inline-table""><table class=""table"" style=""width: auto !important; margin-left: auto; margin-right: auto;"">
 <caption>
-<span id=""tab:dolphin"">Table 8.1: </span>Age-specific estimates of breeding probabilities. Comparison of our NIMBLE estimates with Couet et al.¬†(2019). ‚ÄòNR‚Äô denotes quantities not reported in the paper. ‚ÄòNB‚Äô is for non-breeding and ‚Äòyoy‚Äô for young-of-the-year. Adult female detection on the paper side is a rough time-average read by eye from the authors‚Äô Figure 3 (2005‚Äì2016).</caption>
-<colgroup>
-<col width=""50%"">
-<col width=""24%"">
-<col width=""24%"">
-</colgroup>
-<thead><tr class=""header"">
-<th align=""left"">Parameter</th>
-<th align=""center"">NIMBLE</th>
-<th align=""center"">Couet</th>
+<span id=""tab:dolphin"">Table 8.1: </span><span id=""tab:dolphin"">Table 8.2: </span>Age-specific estimates of breeding probabilities. Comparison of our NIMBLE estimates with Couet et al.¬†(2019). ‚ÄòNR‚Äô denotes quantities not reported in the paper. ‚ÄòNB‚Äô is for non-breeding and ‚Äòyoy‚Äô for young-of-the-year. Adult female detection on the paper side is a rough time-average read by eye from the authors‚Äô Figure 3 (2005‚Äì2016).
+</caption>
+<thead><tr>
+<th style=""text-align:left;"">
+Parameter
+</th>
+<th style=""text-align:center;"">
+NIMBLE
+</th>
+<th style=""text-align:center;"">
+Couet
+</th>
 </tr></thead>
 <tbody>
-<tr class=""odd"">
-<td align=""left"">Adult female survival</td>
-<td align=""center"">0.96 (0.94‚Äì0.98)</td>
-<td align=""center"">0.97 (0.96-0.98)</td>
+<tr>
+<td style=""text-align:left;"">
+Adult female survival
+</td>
+<td style=""text-align:center;"">
+0.96 (0.94‚Äì0.98)
+</td>
+<td style=""text-align:center;"">
+0.97 (0.96-0.98)
+</td>
 </tr>
-<tr class=""even"">
-<td align=""left"">Calf observation, yoy</td>
-<td align=""center"">0.59 (0.49‚Äì0.69)</td>
-<td align=""center"">0.58 (0.46-0.68)</td>
+<tr>
+<td style=""text-align:left;"">
+Calf observation, yoy
+</td>
+<td style=""text-align:center;"">
+0.59 (0.49‚Äì0.69)
+</td>
+<td style=""text-align:center;"">
+0.58 (0.46-0.68)
+</td>
 </tr>
-<tr class=""odd"">
-<td align=""left"">Calf observation, 1-3y</td>
-<td align=""center"">0.80 (0.70‚Äì0.89)</td>
-<td align=""center"">0.79 (0.59-0.90)</td>
+<tr>
+<td style=""text-align:left;"">
+Calf observation, 1-3y
+</td>
+<td style=""text-align:center;"">
+0.80 (0.70‚Äì0.89)
+</td>
+<td style=""text-align:center;"">
+0.79 (0.59-0.90)
+</td>
 </tr>
-<tr class=""even"">
-<td align=""left"">Calf survival (yoy)</td>
-<td align=""center"">0.63 (0.55‚Äì0.73)</td>
-<td align=""center"">0.66 (0.50-0.78)</td>
+<tr>
+<td style=""text-align:left;"">
+Calf survival (yoy)
+</td>
+<td style=""text-align:center;"">
+0.63 (0.55‚Äì0.73)
+</td>
+<td style=""text-align:center;"">
+0.66 (0.50-0.78)
+</td>
 </tr>
-<tr class=""odd"">
-<td align=""left"">Calf survival (1y)</td>
-<td align=""center"">0.69 (0.53‚Äì0.83)</td>
-<td align=""center"">0.45 (0.29-0.61)</td>
+<tr>
+<td style=""text-align:left;"">
+Calf survival (1y)
+</td>
+<td style=""text-align:center;"">
+0.69 (0.53‚Äì0.83)
+</td>
+<td style=""text-align:center;"">
+0.45 (0.29-0.61)
+</td>
 </tr>
-<tr class=""even"">
-<td align=""left"">Female detection: NB or calf 2-3y</td>
-<td align=""center"">0.63 (0.58‚Äì0.69)</td>
-<td align=""center"">‚âà0.47</td>
+<tr>
+<td style=""text-align:left;"">
+Female detection: NB or calf 2-3y
+</td>
+<td style=""text-align:center;"">
+0.63 (0.58‚Äì0.69)
+</td>
+<td style=""text-align:center;"">
+‚âà0.47
+</td>
 </tr>
-<tr class=""odd"">
-<td align=""left"">Female detection: yoy or 1-year calf</td>
-<td align=""center"">0.79 (0.72‚Äì0.86)</td>
-<td align=""center"">‚âà0.61</td>
+<tr>
+<td style=""text-align:left;"">
+Female detection: yoy or 1-year calf
+</td>
+<td style=""text-align:center;"">
+0.79 (0.72‚Äì0.86)
+</td>
+<td style=""text-align:center;"">
+‚âà0.61
+</td>
 </tr>
-<tr class=""even"">
-<td align=""left"">Initial state NB</td>
-<td align=""center"">0.49 (0.37‚Äì0.60)</td>
-<td align=""center"">NR</td>
+<tr>
+<td style=""text-align:left;"">
+Initial state NB
+</td>
+<td style=""text-align:center;"">
+0.49 (0.37‚Äì0.60)
+</td>
+<td style=""text-align:center;"">
+NR
+</td>
 </tr>
-<tr class=""odd"">
-<td align=""left"">Initial state Byoy</td>
-<td align=""center"">0.26 (0.17‚Äì0.37)</td>
-<td align=""center"">NR</td>
+<tr>
+<td style=""text-align:left;"">
+Initial state Byoy
+</td>
+<td style=""text-align:center;"">
+0.26 (0.17‚Äì0.37)
+</td>
+<td style=""text-align:center;"">
+NR
+</td>
 </tr>
-<tr class=""even"">
-<td align=""left"">Initial state Bc1</td>
-<td align=""center"">0.08 (0.03‚Äì0.16)</td>
-<td align=""center"">NR</td>
+<tr>
+<td style=""text-align:left;"">
+Initial state Bc1
+</td>
+<td style=""text-align:center;"">
+0.08 (0.03‚Äì0.16)
+</td>
+<td style=""text-align:center;"">
+NR
+</td>
 </tr>
-<tr class=""odd"">
-<td align=""left"">Initial state Bc2</td>
-<td align=""center"">0.14 (0.07‚Äì0.23)</td>
-<td align=""center"">NR</td>
+<tr>
+<td style=""text-align:left;"">
+Initial state Bc2
+</td>
+<td style=""text-align:center;"">
+0.14 (0.07‚Äì0.23)
+</td>
+<td style=""text-align:center;"">
+NR
+</td>
 </tr>
-<tr class=""even"">
-<td align=""left"">Initial state Bc3</td>
-<td align=""center"">0.03 (0.00‚Äì0.10)</td>
-<td align=""center"">NR</td>
+<tr>
+<td style=""text-align:left;"">
+Initial state Bc3
+</td>
+<td style=""text-align:center;"">
+0.03 (0.00‚Äì0.10)
+</td>
+<td style=""text-align:center;"">
+NR
+</td>
 </tr>
 </tbody>
 </table></div>
@@ -1023,7 +1098,7 @@ <h3>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-07.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2025-09-10.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: index.Rmd---
@@ -29,6 +29,8 @@ header-includes:
     boxsep=5pt,
     arc=4pt}
   - \usepackage{subfig}
+  - \usepackage{ragged2e}
+  - \usepackage[table]{xcolor}
 ---
 
 ```{r setup, include=FALSE}
@@ -58,14 +60,14 @@ Last updated: `r Sys.setlocale(""LC_TIME"", ""C""); format(Sys.Date(), ""%B %d, %Y"")`
 
 ## How to cite {-}
 
-Gimenez, O. 2026. Bayesian analysis of capture-recapture data with hidden Markov models: Theory and case studies in R and NIMBLE. CRC Press.
+Gimenez, O. 2026. Bayesian analysis of capture-recapture data with hidden Markov models: Theory and case studies in R and NIMBLE. Chapman & Hall/CRC Interdisciplinary Statistics series.
 
 ```bibtex
 @book{gimenez2026,
   title = {Bayesian Analysis of Capture-Recapture Data with Hidden {{Markov}} Models: {{Theory}} and Case Studies in {{R}} and {{NIMBLE}}},
   author = {Gimenez, Olivier},
   year = {2026},
-  publisher = {CRC Press}
+  publisher = {Chapman & Hall/CRC Interdisciplinary Statistics series}
 }
 ```
 

---FILE: latex/preamble.tex---
@@ -3,6 +3,10 @@
 \usepackage{longtable}
 \usepackage[bf,singlelinecheck=off]{caption}
 
+\usepackage{threeparttable}
+\usepackage{caption}
+\captionsetup[longtable]{justification=justified,singlelinecheck=false}
+
 \usepackage{Alegreya}
 \usepackage[scale=.7]{sourcecodepro}
 
@@ -92,6 +96,9 @@
 \usepackage{makeidx}
 \makeindex
 
+\usepackage{colortbl}
+\usepackage[table]{xcolor}
+
 \urlstyle{tt}
 
 \usepackage{amsthm}",False,True,Rendering / Conversion,6
oliviergimenez,banana-book,89e9ba6b74eb3080f3360123007ded2e090ac8ef,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2023-08-21T16:21:30Z,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2023-08-21T16:21:30Z,Cleaned up chapters 1-2-3. Fixed issue w/ PDF. Incorporated comments by colleagues (closed corresponding issues on GitHub).,DESCRIPTION;_bookdown.yml;_bookdown_files/banana-book_files/figure-html/binlik-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-11-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-11-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-116-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-116-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-117-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-117-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-12-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-137-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-137-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-138-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-138-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-15-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-16-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-18-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-180-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-180-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-181-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-181-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-195-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-196-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-20-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-21-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-216-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-217-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-218-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-22-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-237-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-238-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-239-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-240-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-253-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-254-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-264-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-265-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-266-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-292-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-293-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-294-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-30-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-304-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-305-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-31-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-32-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-325-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-326-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-327-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-328-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-329-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-33-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-330-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-331-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-339-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-345-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-346-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-348-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-349-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-350-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-351-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-352-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-353-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-42-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-46-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-47-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-49-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-50-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-51-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-55-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-78-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-80-1.png;_bookdown_files/banana-book_files/figure-latex/betadistribution-1.pdf;_bookdown_files/banana-book_files/figure-latex/bgr-1.pdf;_bookdown_files/banana-book_files/figure-latex/burnin-1.pdf;_bookdown_files/banana-book_files/figure-latex/chain-1.pdf;_bookdown_files/banana-book_files/figure-latex/dag-survival-1.pdf;_bookdown_files/banana-book_files/figure-latex/dirichletdistribution-1.pdf;_bookdown_files/banana-book_files/figure-latex/longchain-1.pdf;_bookdown_files/banana-book_files/figure-latex/traceown-1.pdf;_bookdown_files/banana-book_files/figure-latex/twochains-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-10-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-11-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-112-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-113-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-116-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-117-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-12-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-133-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-135-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-137-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-138-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-14-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-149-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-15-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-16-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-160-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-161-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-180-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-181-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-188-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-189-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-195-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-196-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-200-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-216-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-217-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-218-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-221-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-222-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-224-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-225-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-226-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-237-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-238-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-239-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-240-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-241-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-242-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-253-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-254-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-264-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-265-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-266-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-292-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-293-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-294-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-30-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-304-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-305-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-31-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-32-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-325-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-326-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-327-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-328-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-329-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-33-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-330-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-331-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-346-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-349-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-351-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-352-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-353-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-46-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-49-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-50-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-51-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-55-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-76-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-77-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-78-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-79-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-80-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-81-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-91-1.pdf;_bookdown_files/banana-book_files/figure-latex/viterbiaveragecompute-1.pdf;_bookdown_files/banana-book_files/figure-latex/viterbicomputeaverage-1.pdf;_output.yml;banana-book.log;bayesmcmc.Rmd;book.bib;covariates.Rmd;dispersal.Rmd;docs/404.html;docs/banana-book.pdf;docs/banana-book.tex;docs/banana-book_files/figure-html/binlik-1.png;docs/banana-book_files/figure-html/unnamed-chunk-11-1.png;docs/banana-book_files/figure-html/unnamed-chunk-116-1.png;docs/banana-book_files/figure-html/unnamed-chunk-117-1.png;docs/banana-book_files/figure-html/unnamed-chunk-137-1.png;docs/banana-book_files/figure-html/unnamed-chunk-138-1.png;docs/banana-book_files/figure-html/unnamed-chunk-15-1.png;docs/banana-book_files/figure-html/unnamed-chunk-16-1.png;docs/banana-book_files/figure-html/unnamed-chunk-18-1.png;docs/banana-book_files/figure-html/unnamed-chunk-180-1.png;docs/banana-book_files/figure-html/unnamed-chunk-181-1.png;docs/banana-book_files/figure-html/unnamed-chunk-195-1.png;docs/banana-book_files/figure-html/unnamed-chunk-196-1.png;docs/banana-book_files/figure-html/unnamed-chunk-20-1.png;docs/banana-book_files/figure-html/unnamed-chunk-21-1.png;docs/banana-book_files/figure-html/unnamed-chunk-216-1.png;docs/banana-book_files/figure-html/unnamed-chunk-217-1.png;docs/banana-book_files/figure-html/unnamed-chunk-218-1.png;docs/banana-book_files/figure-html/unnamed-chunk-22-1.png;docs/banana-book_files/figure-html/unnamed-chunk-237-1.png;docs/banana-book_files/figure-html/unnamed-chunk-238-1.png;docs/banana-book_files/figure-html/unnamed-chunk-239-1.png;docs/banana-book_files/figure-html/unnamed-chunk-240-1.png;docs/banana-book_files/figure-html/unnamed-chunk-253-1.png;docs/banana-book_files/figure-html/unnamed-chunk-254-1.png;docs/banana-book_files/figure-html/unnamed-chunk-264-1.png;docs/banana-book_files/figure-html/unnamed-chunk-265-1.png;docs/banana-book_files/figure-html/unnamed-chunk-266-1.png;docs/banana-book_files/figure-html/unnamed-chunk-292-1.png;docs/banana-book_files/figure-html/unnamed-chunk-293-1.png;docs/banana-book_files/figure-html/unnamed-chunk-294-1.png;docs/banana-book_files/figure-html/unnamed-chunk-30-1.png;docs/banana-book_files/figure-html/unnamed-chunk-304-1.png;docs/banana-book_files/figure-html/unnamed-chunk-305-1.png;docs/banana-book_files/figure-html/unnamed-chunk-31-1.png;docs/banana-book_files/figure-html/unnamed-chunk-325-1.png;docs/banana-book_files/figure-html/unnamed-chunk-326-1.png;docs/banana-book_files/figure-html/unnamed-chunk-327-1.png;docs/banana-book_files/figure-html/unnamed-chunk-328-1.png;docs/banana-book_files/figure-html/unnamed-chunk-329-1.png;docs/banana-book_files/figure-html/unnamed-chunk-330-1.png;docs/banana-book_files/figure-html/unnamed-chunk-331-1.png;docs/banana-book_files/figure-html/unnamed-chunk-339-1.png;docs/banana-book_files/figure-html/unnamed-chunk-345-1.png;docs/banana-book_files/figure-html/unnamed-chunk-346-1.png;docs/banana-book_files/figure-html/unnamed-chunk-348-1.png;docs/banana-book_files/figure-html/unnamed-chunk-349-1.png;docs/banana-book_files/figure-html/unnamed-chunk-350-1.png;docs/banana-book_files/figure-html/unnamed-chunk-351-1.png;docs/banana-book_files/figure-html/unnamed-chunk-352-1.png;docs/banana-book_files/figure-html/unnamed-chunk-353-1.png;docs/banana-book_files/figure-html/unnamed-chunk-42-1.png;docs/banana-book_files/figure-html/unnamed-chunk-46-1.png;docs/banana-book_files/figure-html/unnamed-chunk-47-1.png;docs/banana-book_files/figure-html/unnamed-chunk-49-1.png;docs/banana-book_files/figure-html/unnamed-chunk-50-1.png;docs/banana-book_files/figure-html/unnamed-chunk-51-1.png;docs/banana-book_files/figure-html/unnamed-chunk-55-1.png;docs/banana-book_files/figure-html/unnamed-chunk-78-1.png;docs/banana-book_files/figure-html/unnamed-chunk-80-1.png;docs/covariateschapter.html;docs/crashcourse.html;docs/dispersal.html;docs/hmmcapturerecapture.html;docs/images/bayes_neon.jpeg;docs/images/traceplotMCMC.gif;docs/index.html;docs/introduction-1.html;docs/introduction-2.html;docs/introduction-3.html;docs/introduction-4.html;docs/introduction-7.html;docs/introduction.html;docs/intronimble.html;docs/lackoffit.html;docs/libs/kePrint-0.0.1/kePrint.js;docs/libs/lightable-0.0.1/lightable.css;docs/misc.html;docs/miscelleanous.html;docs/preface.html;docs/reference-keys.txt;docs/references.html;docs/search.json;docs/survival.html;docs/tradeoffs.html;hmm.Rmd;index.Rmd;introductionpartone.Rmd;introductionpartthree.Rmd;introductionparttwo.Rmd;lackoffit.Rmd;lifehistory.Rmd;miscelleanous.Rmd;nimble.Rmd;survival.Rmd,True,False,True,False,15436,49671,65107,"---FILE: DESCRIPTION---
@@ -16,7 +16,9 @@ Imports:
     nimbleEcology,
     bookdown,
     sessioninfo,
-    RColorBrewer
+    RColorBrewer,
+    forecast,
+    coda
 Suggests:
     bslib,
     desc,

---FILE: _bookdown.yml---
@@ -28,5 +28,5 @@ rmd_files:
     ""lackoffit.Rmd"",
     ""miscelleanous.Rmd"",
   #  ""speed.Rmd"",
-    ""references.Rmd"",
+    ""references.Rmd""
   ]

---FILE: _output.yml---
@@ -9,7 +9,6 @@ bookdown::bs4_book:
       collapse: none
       before: |
         <li><a href=""./"">Bayesian HMM Capture-Recapture</a></li>
-    download: [pdf]
     sharing:
       github: yes
       facebook: no

---FILE: bayesmcmc.Rmd---
@@ -8,34 +8,41 @@ In this first chapter, you will learn what the Bayesian theory is, and how you m
 
 Let's not wait any longer and jump into it. Bayesian statistics relies on the Bayes' theorem (or law, or rule, whatever you prefer) named after Reverend Thomas Bayes (Figure \@ref(fig:revbayes)). This theorem was published in 1763 two years after Bayes' death thanks to his friend's efforts Richard Price, and was independently discovered by Pierre-Simon Laplace [@mcgrayne2011]. 
 
-```{r revbayes, echo = FALSE, fig.align=""center"", out.width=""100%"", fig.cap = ""Cartoon of Thomas Bayes with Bayes' theorem in background. Source: [James Kulich](https://www.elmhurst.edu/blog/thomas-bayes/)""}
+```{r revbayes, echo = FALSE, fig.align=""center"", out.width=""100%"", fig.cap = ""Cartoon of Thomas Bayes with Bayes' theorem in background. Source: James Kulich at <https://www.elmhurst.edu/blog/thomas-bayes/>""}
 knitr::include_graphics(""images/amazing-thomas-bayes-illustration.jpg"")
 ```
 
-As we will see in a minute, Bayes' theorem is all about conditional probabilities, which are somehow tricky to understand. Conditional probability of outcome or event A given event B, which we denote $\Pr(A \mid B)$, is the probability that A occurs, revised by considering the additional information that event B has occurred.^[For example, a friend of yours rolls a fair dice and asks you the probability that the outcome was a six (event A). Your answer is 1/6 because each side of the dice is equally likely to come up. Now imagine that you're told the number rolled was even (event B) before you answer your friend's question. Because there are only three even numbers, one of which is six, you may revise your answer for the probability that a six was rolled from 1/6 to $\Pr(A \mid B) = 1/3$.] The order in which A and B appear is important, make sure you do not confuse $\Pr(A \mid B)$ and $\Pr(B \mid A)$.
+As we will see in a minute, Bayes' theorem is all about conditional probabilities, which are somehow tricky to understand. Conditional probability of outcome or event A given event B, which we denote $\Pr(A \mid B)$, is the probability that A occurs, revised by considering the additional information that event B has occurred. For example, a friend of yours rolls a fair dice and asks you the probability that the outcome was a six (event A). Your answer is 1/6 because each side of the dice is equally likely to come up. Now imagine that you're told the number rolled was even (event B) before you answer your friend's question. Because there are only three even numbers, one of which is six, you may revise your answer for the probability that a six was rolled from 1/6 to $\Pr(A \mid B) = 1/3$. The order in which A and B appear is important, make sure you do not confuse $\Pr(A \mid B)$ and $\Pr(B \mid A)$.
+
+Bayes' theorem gives you $\Pr(A \mid B)$ using marginal probabilities $\Pr(A)$ and $\Pr(B)$ and $\Pr(B \mid A)$:
 
-Bayes' theorem (Figure \@ref(fig:bayestheorem)) gives you $\Pr(A \mid B)$ using marginal probabilities $\Pr(A)$ and $\Pr(B)$ and $\Pr(B \mid A)$:
 $$\Pr(A \mid B) = \displaystyle{\frac{ \Pr(B \mid A) \; \Pr(A)}{\Pr(B)}}.$$
-Originally, Bayes' theorem was seen as a way to infer an unkown cause A of a particular effect B, knowing the probability of effect B given cause A. Think for example of a situation where a medical diagnosis is needed, with A an unkown disease and B symptoms, the doctor knows P(symptoms|disease) and wants to derive P(disease|symptoms). This way of reversing $\Pr(B \mid A)$ into $\Pr(A \mid B)$ explains why Bayesian thinking used to be referred to as 'inverse probability'. 
 
-```{r bayestheorem, echo = FALSE, fig.align=""center"", fig.cap = ""Bayes' theorem spelt out in blue neon. Source: [Wikipedia](https://en.wikipedia.org/wiki/Bayes%27_theorem)""}
-knitr::include_graphics(""images/bayes_neon.jpeg"")
-```
+Originally, Bayes' theorem was seen as a way to infer an unkown cause A of a particular effect B, knowing the probability of effect B given cause A. Think for example of a situation where a medical diagnosis is needed, with A an unknown disease and B symptoms, the doctor knows Pr(symptoms|disease) and wants to derive Pr(disease|symptoms). This way of reversing $\Pr(B \mid A)$ into $\Pr(A \mid B)$ explains why Bayesian thinking used to be referred to as 'inverse probability'. 
 
-I don't know about you, but I need to think twice for not messing the letters around. I find it easier to remember Bayes' theorem written like this^[When teaching Bayes' theorem, I am very much inspired by Tristan Mahr's slides from his introduction to Bayesian regression https://www.tjmahr.com/bayes-intro-lecture-slides-2017/]:
 
-$$ \Pr(\text{hypothesis} \mid \text{data}) = \frac{ \Pr(\text{data} \mid \text{hypothesis}) \; \Pr(\text{hypothesis})}{\Pr(\text{data})} $$
-```{block2 bayes, type='rmdnote'}
-The *hypothesis* is a working assumption about which you want to learn using *data*. In capture--recapture analyses, the hypothesis might be a parameter like detection probability, or regression parameters in a relationship between survival probability and a covariate. Bayes' theorem tells us how to obtain the probability of a hypothesis given the data we have. 
-```
+<!-- ```{r bayestheorem, echo = FALSE, fig.align=""center"", fig.cap = ""Bayes' theorem spelt out in blue neon. Source: https://en.wikipedia.org/wiki/Bayes%27_theorem."", out.width=""60%""} -->
+<!-- knitr::include_graphics(""images/bayes_neon.jpeg"") -->
+<!-- ``` -->
+
+I don't know about you, but I need to think twice for not messing the letters around. I find it easier to remember Bayes' theorem written like this:
+
+$$\Pr(\text{hypothesis} \mid \text{data}) = \frac{ \Pr(\text{data} \mid \text{hypothesis}) \; \Pr(\text{hypothesis})}{\Pr(\text{data})}$$
+
+
+:::: {.blackbox data-latex=""""}
+The *hypothesis* is a working assumption about which you want to learn using *data*. In capture--recapture analyses, the hypothesis might be a parameter like detection probability, or regression parameters in a relationship between survival probability and a covariate (see Chapter \@ref(survival)). Bayes' theorem tells us how to obtain the probability of a hypothesis given the data we have. 
+::::
 
 This is great because think about it, this is exactly what the scientific method is! We'd like to know how plausible some hypothesis is based on some data we collected, and possibly compare several hypotheses among them. In that respect, the Bayesian reasoning matches the scientific reasoning, which probably explains why the Bayesian framework is so natural for doing and understanding statistics. 
 
-You might ask then, why is Bayesian statistics not the default in statistics? Clearly, because of futile wars between male statisticians (including Ronald Fisher, Jerzy Neyman and Egon Sharpe Pearson among others), little progress was made for over two centuries. Also, until recently, there were practical problems to implement Bayes' theorem. Recent advances in computational power coupled with the development of new algorithms have led to a great increase in the application of Bayesian methods within the last three decades.
+You might ask then, why is Bayesian statistics not the default in statistics? Until recently, there were practical problems to implement Bayes' theorem. Recent advances in computational power coupled with the development of new algorithms have led to a great increase in the application of Bayesian methods within the last three decades.
+
+<!-- Clearly, because of futile wars between male statisticians (including Ronald Fisher, Jerzy Neyman and Egon Sharpe Pearson among others), little progress was made for over two centuries. Also,  -->
 
 ## What is the Bayesian approach?	
 
-Typical statistical problems involve estimating a parameter (or several parameters) $\theta$ with available data. To do so, you might be more used to the frequentist rather than the Bayesian method. The frequentist approach, and in particular maximum likelihood estimation (MLE), assumes that the parameters are fixed, and have unknown values to be estimated. Therefore classical estimates are generally point estimates of the parameters of interest. In contrast, the Bayesian approach assumes that the parameters are not fixed, and have some unknown distribution^[A probability distribution is a mathematical expression that gives the probability for a random variable to take particular values. A probability distribution may be either discrete (e.g., the Bernoulli, Binomial or Poisson distribution) or continuous (e.g., the Gaussian distribution also known as the normal distribution)].
+Typical statistical problems involve estimating a parameter (or several parameters) $\theta$ with available data. To do so, you might be more used to the frequentist rather than the Bayesian method. The frequentist approach, and in particular maximum likelihood estimation (MLE), assumes that the parameters are fixed, and have unknown values to be estimated. Therefore classical estimates are generally point estimates of the parameters of interest. In contrast, the Bayesian approach assumes that the parameters are not fixed, and have some unknown distribution. A probability distribution is a mathematical expression that gives the probability for a random variable to take particular values. It may be either discrete (e.g., the Bernoulli, Binomial or Poisson distribution) or continuous (e.g., the Gaussian distribution also known as the normal distribution).
 
 The Bayesian approach is based upon the idea that you, as an experimenter, begin with some prior beliefs about the system. Then you collect data and update your prior beliefs on the basis of observations. These observations might arise from field work, lab work or from expertise of your esteemed colleagues. This updating process is based upon Bayes' theorem. Loosely, let's say $A = \theta$ and $B = \text{data}$, then Bayes' theorem gives you a way to estimate parameter $\theta$ given the data you have:
 
@@ -46,26 +53,26 @@ On the left-hand side is the $\color{red}{\text{posterior distribution}}$. It re
 
 On the right-hand side, there is the $\color{blue}{\text{likelihood}}$. This quantity is the same as in the MLE approach. Yes, the Bayesian and frequentist approaches have the same likelihood at their core, which mostly explains why results often do not differ much. The likelihood captures the information you have in your data, given a model parameterized with $\theta$. 
 
-Then we have the $\color{green}{\text{prior distribution}}$. This quantity represents what you know before seeing the data. This is the source of much discussion about the Bayesian approach. It may be vague if you don't know anything about $\theta$. Usually however, you never start from scratch, and you'd like your prior to reflect the information you have^[Shall I include a section on sensitivity analyses in this chapter or later in the book? Cross-reference section in Survival chapter where prior elicitation is covered.].
+Then we have the $\color{green}{\text{prior distribution}}$. This quantity represents what you know before seeing the data. This is the source of much discussion about the Bayesian approach. It may be vague if you don't know anything about $\theta$. Usually however, you never start from scratch, and you'd like your prior to reflect the information you have (see Section \@ref(elicitprior) for how to accomplish that).
 
 Last, we have $\color{orange}{\Pr(\text{data})}$ which is sometimes called the average likelihood because it is obtained by integrating the likelihood with respect to the prior $\color{orange}{\Pr(\text{data}) = \int{L(\text{data} \mid \theta)\Pr(\theta) d\theta}}$ so that the posterior is standardized, that is it integrates to one for the posterior to be a distribution. The average likelihood is an integral with dimension the number of parameters $\theta$ you need to estimate. This quantity is difficult, if not impossible, to calculate in general. This is one of the reasons why the Bayesian method wasn't used until recently, and why we need algorithms to estimate posterior distributions as I illustrate in the next section.
 
 ## Approximating posteriors via numerical integration {#numerical-approx}
 
-Let's take an example to illustrate Bayes' theorem. Say we capture, mark and release $n = 57$ animals at the beginning of a winter, out of which we recapture $y = 19$ animals alive^[We used a similar example in @king_bayesian_2009]. We'd like to estimate winter survival $\theta$.
+Let's take an example to illustrate Bayes' theorem. Say we capture, mark and release $n = 57$ animals at the beginning of a winter, out of which we recapture $y = 19$ animals alive (we used a similar example in @king_bayesian_2009). We'd like to estimate winter survival $\theta$. The data are:
 ```{r}
 y <- 19 # nb of success
 n <- 57 # nb of attempts
 ```
 
-We build our model first. Assuming all animals are independent of each other and have the same survival probability, then $y$ the number of alive animals at the end of the winter is a binomial distribution^[I follow @mcelreathbook and use labels on the right to help remember what each line is about.] with $n$ trials and $\theta$ the probability of success:
+We build our model first. Assuming all animals are independent of each other and have the same survival probability, then $y$ the number of alive animals at the end of the winter is a binomial distribution with $n$ trials and $\theta$ the probability of success:
   
 \begin{align*}
 y &\sim \text{Binomial}(n, \theta) &\text{[likelihood]}
 \end{align*}
 
-This likelihood can be visualised in `R`: 
-```{r binlik, echo = TRUE, fig.cap = ""Binomial likelihood with $n = 57$ released animals and $y = 19$ survivors after winter. The value of survival (on the x-axis) that corresponds to the maximum of the likelihood function (on the y-axis) is the MLE, or the proportion of success in this example, close to 0.33.""}
+Note that I follow @mcelreathbook and use labels on the right to help remember what each line is about. This likelihood can be visualised in `R`: 
+```{r}
 grid <- seq(0, 1, 0.01) # grid of values for survival
 likelihood <- dbinom(y, n, grid) # compute binomial likelihood
 df <- data.frame(survival = grid, likelihood = likelihood) 
@@ -75,6 +82,8 @@ df %>%
   geom_line(size = 1.5)
 ```
 
+This is the binomial likelihood with $n = 57$ released animals and $y = 19$ survivors after winter. The value of survival (on the x-axis) that corresponds to the maximum of the likelihood function (on the y-axis) is the MLE, or the proportion of success in this example, close to 0.33.
+
 Besides the likelihood, priors are another component of the model in the Bayesian approach. For a parameter that is a probability, the one thing we know is that the prior should be a continuous random variable that lies between 0 and 1. To reflect that, we often go for the uniform distribution $U(0,1)$ to imply *vague* priors. Here vague means that survival has, before we see the data, the same probability of falling between 0.1 and 0.2 and between 0.8 and 0.9, for example. 
 
 \begin{align*}
@@ -104,8 +113,8 @@ denominator <- integrate(numerator,0,1)$value
 
 We use the `R` function `integrate` to calculate the integral in the denominator, which implements quadrature techniques to divide in little squares the area underneath the curve delimited by the function to integrate (here the numerator), and count them.
 
-Then we get a numerical approximation of the posterior in Figure \@ref(fig:numapprox) by applying Bayes' theorem. 
-```{r numapprox, echo = TRUE, fig.cap = ""Winter survival posterior distribution obtained by numerical integration.""}
+Then we get a numerical approximation of the posterior of winter survival by applying Bayes' theorem:
+```{r}
 grid <- seq(0, 1, 0.01) # grid of values for theta
 numerical_posterior <- data.frame(survival = grid, 
                                   posterior = numerator(grid)/denominator) # Bayes' theorem
@@ -115,9 +124,9 @@ numerical_posterior %>%
   geom_line(size = 1.5)
 ```
 
-How good is our numerical approximation of survival posterior distribution? Ideally, we would want to compare the approximation to the true posterior distribution. Although a closed-form expression for the posterior distribution is in general intractable, when you combine a binomial likelihood together with a beta distribution as a prior, then the posterior distribution is also a beta distribution, which makes it amenable to all sorts of exact calculations^[We say that the beta distribution is the conjugate prior distribution for the binomial distribution.]. The beta distribution is continuous between 0 and 1, and extends the uniform distribution to situations where not all outcomes are equally likely. It has two parameters $a$ and $b$ that control its shape (Figure \@ref(fig:betadistribution)).
+How good is our numerical approximation of survival posterior distribution? Ideally, we would want to compare the approximation to the true posterior distribution. Although a closed-form expression for the posterior distribution is in general intractable, when you combine a binomial likelihood together with a beta distribution as a prior, then the posterior distribution is also a beta distribution, which makes it amenable to all sorts of exact calculations. We say that the beta distribution is the conjugate prior distribution for the binomial distribution. The beta distribution is continuous between 0 and 1, and extends the uniform distribution to situations where not all outcomes are equally likely. It has two parameters $a$ and $b$ that control its shape (Figure \@ref(fig:betadistribution)).
 
-(ref:captionbeta) The distribution beta($a$,$b$) for different values of $a$ and $b$. Note that for $a = b = 1$, we get the uniform distribution between 0 and 1 in the top left panel. When $a$ and $b$ are equal, the distribution is symmetric, and the bigger $a$ and $b$, the more peaked the distribution around the mean (the smaller the variance). 
+(ref:captionbeta) The distribution beta($a$,$b$) for different values of $a$ and $b$. Note that for $a = b = 1$, we get the uniform distribution between 0 and 1 in the top left panel. When $a$ and $b$ are equal, the distribution is symmetric, and the bigger $a$ and $b$, the more peaked the distribution around the mean (the smaller the variance). The expectation (or mean) of a beta($a$,$b$) is $\displaystyle{\frac{a}{a + b}}$.
 
 ```{r betadistribution, echo = FALSE, fig.cap='(ref:captionbeta)'}
 x <- seq(0, 1, length=200)
@@ -131,8 +140,8 @@ plot(x,dbeta(x, 10, 10),type='l',xlab='',ylab='',main='beta(10,10)',lwd=3,col='b
 plot(x,dbeta(x, 0.8, 0.8),type='l',xlab='',ylab='',main='beta(0.8,0.8)',lwd=3,col='black',ylim=c(0.5,2.5))
 ```
 
-If the likelihood of the data $y$ is binomial with $n$ trials and probability of success $\theta$, and the prior is a beta distribution with parameters $a$ and $b$, then the posterior is a beta distribution with parameters $a + y$ and $b + n - y$^[**provide a sketch of the proof**]. In our example, we have $n = 57$ trials and $y = 19$ animals that survived and a uniform prior between 0 and 1 or a beta distribution with parameters $a = b = 1$, therefore survival has a beta posterior distribution with parameters 20 and 39. In Figure \@ref(fig:compar), we superimpose the exact posterior and the numerical approximation. Clearly, the two distributions are indistinguishable, suggesting that the numerical approximation is more than fine. 
-```{r compar, echo = FALSE, fig.cap = ""Comparison of exact (dashed line) vs. numerical approximation (continuous line) of winter survival posterior distribution.""}
+If the likelihood of the data $y$ is binomial with $n$ trials and probability of success $\theta$, and the prior is a beta distribution with parameters $a$ and $b$, then the posterior is a beta distribution with parameters $a + y$ and $b + n - y$. In our example, we have $n = 57$ trials and $y = 19$ animals that survived and a uniform prior between 0 and 1 or a beta distribution with parameters $a = b = 1$, therefore survival has a beta posterior distribution with parameters 20 and 39. Let's superimpose the exact posterior and the numerical approximation:
+```{r}
 explicit_posterior <- dbeta(grid, y + a, n - y + b)
 dfexpposterior <- data.frame(survival = grid, explicit_posterior = explicit_posterior)
 ggplot() + 
@@ -148,6 +157,8 @@ ggplot() +
             linetype = ""dashed"")
 ```
 
+Clearly, the exact (dashed line) vs. numerical approximation (continuous line) of winter survival posterior distribution are indistinguishable, suggesting that the numerical approximation is more than fine. 
+
 <!-- To finish up, let's add the prior.  -->
 <!-- ```{r, echo = FALSE} -->
 <!-- ggplot() +  -->
@@ -176,7 +187,7 @@ There are two computational challenges with this formula. First, do we really wi
 
 In the early 1990s, statisticians rediscovered work from the 1950's in physics. In a famous paper that would lay the fundations of modern Bayesian statistics (Figure \@ref(fig:mcmcpaper)), the authors use simulations to approximate posterior distributions with some precision by drawing large samples. This is a neat trick to avoid explicit calculation of the multi-dimensional integrals we struggle with when using Bayes' theorem. 
 
-```{r mcmcpaper, echo = FALSE, fig.align='center', fig.cap = ""MCMC article cover. Source: [The Journal of Chemical Physics](https://aip.scitation.org/doi/10.1063/1.1699114)""}
+```{r mcmcpaper, echo = FALSE, fig.align='center', fig.cap = ""MCMC article cover. Source: The Journal of Chemical Physics -- https://aip.scitation.org/doi/10.1063/1.1699114"", out.width=""100%""}
 knitr::include_graphics(""images/metropolis.png"")
 ```
 
@@ -190,7 +201,7 @@ sample_from_posterior <- rbeta(1000, 20, 39) # draw 1000 values from posterior s
 mean(sample_from_posterior) # compute mean with Monte Carlo integration
 ```
 
-You may check that the mean we have just calculated matches closely the expectation of a beta distribution^[If $X$ is a random variable with distribution $\text{beta}(a, b)$, then $E(X) = \displaystyle{\frac{a}{a + b}}$]:
+You may check that the mean we have just calculated matches closely the expectation of a beta distribution:
 ```{r}
 20/(20+39) # expectation of beta(20,39)
 ```
@@ -224,7 +235,7 @@ $$
     \end{matrix}
 \end{matrix}
 $$
-In rows the weather today, and in columns the weather tomorrow. The cells give the probability of a sunny or rainy day tomorrow, given the day is sunny or rainy today. Under certain conditions^[The Markov chain is irreducible and aperiodic.], a Markov chain will converge to a unique stationary distribution. In our weather example, let's run the Markov chain for 20 steps:
+In rows the weather today, and in columns the weather tomorrow. The cells give the probability of a sunny or rainy day tomorrow, given the day is sunny or rainy today. Under certain conditions, a Markov chain will converge to a unique stationary distribution. In our weather example, let's run the Markov chain for 20 steps:
 ```{r}
 weather <- matrix(c(0.8, 0.2, 0.9, 0.1), nrow = 2, byrow = T) # transition matrix
 steps <- 20
@@ -238,15 +249,15 @@ Each row of the transition matrix converges to the same distribution $(0.82, 0.1
 
 Back to MCMC, the core idea is that you can build a Markov chain with a given stationary distribution set to be the desired posterior distribution. 
 
-```{block2 mcmc, type='rmdnote'}
+:::: {.blackbox data-latex=""""}
 Putting Monte Carlo and Markov chains together, MCMC allows us to generate a sample of values (Markov chain) whose distribution converges to the posterior distribution, and we can use this sample of values to calculate any posterior summaries (Monte Carlo), such as posterior means and credible intervals. 
-```
+:::: 
 
 ### Metropolis algorithm {#metropolis-algorithm}
 
-There are several ways of constructing Markov chains for Bayesian inference^[You might have heard about the Metropolis-Hastings or the Gibbs sampler. Have a look to <https://github.com/chi-feng/mcmc-demo> for an interactive gallery of MCMC algorithms.]. Here I illustrate the Metropolis algorithm and how to implement it in practice^[This presentation is largely inspired by @alberthu2019].
+There are several ways of constructing Markov chains for Bayesian inference. You might have heard about the Metropolis-Hastings or the Gibbs sampler. Have a look to <https://chi-feng.github.io/mcmc-demo/> for an interactive gallery of MCMC algorithms. Here I illustrate the Metropolis algorithm and how to implement it in practice.
 
-Let's go back to our example on animal survival estimation. We illustrate sampling from survival posterior distribution. We write functions for likelihood, prior and posterior.
+Let's go back to our example on animal survival estimation. We illustrate sampling from survival posterior distribution. We write functions for likelihood, prior and posterior:
 
 ```{r}
 # 19 animals recaptured alive out of 57 captured, marked and released
@@ -271,7 +282,7 @@ posterior <- function(x, p){
 
 The Metropolis algorithm works as follows: 
   
-1. We pick a value of the parameter to be estimated. This is where we start our Markov chain -- this is a *starting* value. 
+1. We pick a value of the parameter to be estimated. This is where we start our Markov chain -- this is a *starting* value, or a starting location. 
 
 2. To decide where to go next, we propose to move away from the current value of the parameter -- this is a *candidate* value. To do so, we add to the current value some random value from e.g. a normal distribution with some variance -- this is a *proposal* distribution. The Metropolis algorithm is a particular case of the Metropolis-Hastings algorithm with symmetric proposals.
   
@@ -283,22 +294,22 @@ The Metropolis algorithm works as follows:
   
 5. We repeat 2-4 a number of times -- or *steps*.
 
-Enough of the theory, let's implement the Metropolis algorithm in `R`. Let's start by setting the scene. 
+Enough of the theory, let's implement the Metropolis algorithm in `R`. Let's start by setting the scene:
 ```{r}
 steps <- 100 # number of steps
 theta.post <- rep(NA, steps) # vector to store samples
 accept <- rep(NA, steps) # keep track of accept/reject
 set.seed(1234) # for reproducibility
 ```
 
-Now follow the 5 steps we've just described. First, we pick a starting value, and store it (step 1).
+Now follow the 5 steps we've just described. First, we pick a starting value, and store it (step 1):
 ```{r}
 inits <- 0.5
 theta.post[1] <- inits
 accept[1] <- 1
 ```
 
-Then, we need a function to propose a candidate value. We add a value taken from a normal distribution with mean zero and standard deviation we call *away*. We work on the logit scale to make sure the candidate value for survival lies between 0 and 1. 
+Then, we need a function to propose a candidate value: 
 ```{r}
 move <- function(x, away = 1){ # by default, standard deviation of the proposal distribution is 1
   logitx <- log(x / (1 - x)) # apply logit transform (-infinity,+infinity)
@@ -308,7 +319,9 @@ move <- function(x, away = 1){ # by default, standard deviation of the proposal
 }
 ```
 
-Now we're ready for steps 2, 3 and 4. We write a loop to take care of step 5. We start at initial value 0.5 and run the algorithm for 100 steps or iterations. 
+We add a value taken from a normal distribution with mean zero and standard deviation we call *away*. We work on the logit scale to make sure the candidate value for survival lies between 0 and 1.
+
+Now we're ready for steps 2, 3 and 4. We write a loop to take care of step 5. We start at initial value 0.5 and run the algorithm for 100 steps or iterations:
 ```{r}
 for (t in 2:steps){ # repeat steps 2-4 (step 5)
   
@@ -334,14 +347,14 @@ for (t in 2:steps){ # repeat steps 2-4 (step 5)
 }
 ```
 
-We get the following values. 
+We get the following values:
 ```{r}
 head(theta.post) # first values
 tail(theta.post) # last values
 ```
 
-Visually, you may look at the chain in Figure \@ref(fig:chain) called a trace plot.
-```{r chain, echo = FALSE, fig.align='center', fig.cap = ""Visualisation of a Markov chain starting at value 0.5, with steps or iterations on the x-axis, and samples on the y-axis. This graphical representation is called a trace plot.""}
+Visually, you may look at the chain:
+```{r chain}
 df <- data.frame(x = 1:steps, y = theta.post)
 df %>%
   ggplot() +
@@ -350,6 +363,8 @@ df %>%
   ylim(0.1, 0.6)
 ```
 
+In this visualisation, remember that our Markov chain starts at value 0.5. The steps or iterations are on the x-axis, and samples on the y-axis. This graphical representation is called a trace plot.
+
 The acceptance probability is the average number of times we accepted a candidated value, which is `r mean(accept)` and almost satisfying. 
 
 ```{r echo = FALSE}
@@ -375,7 +390,10 @@ move <- function(x, away = .2){
   candidate <- plogis(logit_candidate)
   return(candidate)
 }
+```
 
+To make our life easier and avoid repeating the same lines of code again and again, let's make a function out of the code we have written so far:
+```{r echo = TRUE}
 metropolis <- function(steps = 100, inits = 0.5, away = 1){
   
   # pre-alloc memory
@@ -408,8 +426,8 @@ metropolis <- function(steps = 100, inits = 0.5, away = 1){
 }
 ```
 
-Can we run another chain and start at initial value 0.2 this time? Yes, just go through the same algorithm again, and visualise the results in Figure \@ref(fig:twochains). 
-```{r twochains, echo = FALSE, fig.align='center', fig.cap = ""Trace plot of survival for two chains starting at 0.2 (yellow) and 0.5 (blue) run for 100 steps.""}
+Can we run another chain and start at initial value 0.2 this time? Yes, just go through the same algorithm again, and visualise the results with trace plot of survival for two chains starting at 0.2 (yellow) and 0.5 (blue) run for 100 steps:
+```{r twochains}
 theta.post2 <- metropolis(steps = 100, inits = 0.2)
 df2 <- data.frame(x = 1:steps, y = theta.post2)
 ggplot() +
@@ -419,8 +437,8 @@ ggplot() +
   ylim(0.1, 0.6)
 ```
 
-Notice that we do not get the exact same results because the algorithm is stochastic. The question is to know whether we have reached the stationary distribution. Let's increase the number of steps and run a chain with 5000 iterations as in Figure \@ref(fig:longchain).
-```{r longchain, echo = FALSE, fig.align='center', fig.cap = ""Trace plot of survival for a chain starting at 0.5 and 1000 steps.""}
+Notice that we do not get the exact same results because the algorithm is stochastic. The question is to know whether we have reached the stationary distribution. Let's increase the number of steps, start at 0.5 and run a chain with 5000 iterations:
+```{r longchain}
 steps <- 5000
 set.seed(1234)
 theta.post <- metropolis(steps = steps, inits = 0.5)
@@ -434,77 +452,78 @@ df %>%
   scale_linetype_manual(name = """", values = c(2,2)) 
 ```
 
-This is what we're after, a trace plot that looks like a beautiful lawn, see Section \@ref(convergence-diag). I find it informative to look at the animated version of Figure \@ref(fig:longchain), it helps understanding the stochastic behavior of the algorithm, and also to realise how the chains converge to their stationary distribution, see Figure \@ref(fig:animlongchain).
-
-```{r echo = FALSE, eval = FALSE}
-# load packages
-library(tidyverse)
-theme_set(theme_light(base_size = 16))
-library(gganimate)
-library(magick)
-
-# deer data, 19 ""success"" out of 57 ""attempts""
-survived <- 19
-released <- 57
-
-#---------- apply Metropolis
-
-steps <- 1000
-chain1 <- metropolis(steps = steps, inits = 0.2)
-chain2 <- metropolis(steps = steps, inits = 0.5)
-chain3 <- metropolis(steps = steps, inits = 0.7)
-
-df <- data.frame(iter = rep(1:steps, 3), 
-                 value = c(chain1, chain2, chain3),
-                 chain = c(rep(""chain1"", steps), 
-                           rep(""chain2"", steps), 
-                           rep(""chain3"", steps)))
-
-#---------- time series
-static_tsplot <- df %>%
-  mutate(posterior_mean = mean(value)) %>%
-  ggplot(aes(x = iter, y = value, group = chain, color = chain)) +
-  geom_line(size = 1, alpha = 0.5) + 
-  geom_hline(aes(yintercept = posterior_mean, linetype = ""posterior mean"")) + 
-  scale_linetype_manual(name = """", values = c(2,2)) + 
-  labs(color = """", x = ""iterations"", y = ""survival"")
-static_tsplot  
-  
-# animate
-animated_tsplot <- static_tsplot +
-  transition_reveal(along = iter, 
-                    range = as.integer(c(1, max(df$iter) + 50))) # trick to pause
-animated_tsplot  
-
-# save
-a_gif <- animate(animated_tsplot,
-                 width = 6, 
-                 height = 3,
-                 res = 600,
-                 units = ""in"")
-
-# get file in directory str(a_gif)
-```
-```{r animlongchain, echo = FALSE, out.width=""100%"", fig.align='center', fig.cap = ""Animated trace plot of survival with three chains starting at 0.2, 0.5 and 0.7 run for 1000 steps.""}
-knitr::include_graphics(""images/traceplotMCMC.gif"")
-```
+This is what we're after, a trace plot that looks like a beautiful lawn, see Section \@ref(convergence-diag). 
+
+<!-- I find it informative to look at the animated version of the figure above, it helps understanding the stochastic behavior of the algorithm, and also to realise how the chains converge to their stationary distribution, see Figure \@ref(fig:animlongchain). -->
+
+<!-- ```{r echo = FALSE, eval = FALSE} -->
+<!-- # load packages -->
+<!-- library(tidyverse) -->
+<!-- theme_set(theme_light(base_size = 16)) -->
+<!-- library(gganimate) -->
+<!-- library(magick) -->
+
+<!-- # deer data, 19 ""success"" out of 57 ""attempts"" -->
+<!-- survived <- 19 -->
+<!-- released <- 57 -->
+
+<!-- #---------- apply Metropolis -->
+
+<!-- steps <- 1000 -->
+<!-- chain1 <- metropolis(steps = steps, inits = 0.2) -->
+<!-- chain2 <- metropolis(steps = steps, inits = 0.5) -->
+<!-- chain3 <- metropolis(steps = steps, inits = 0.7) -->
+
+<!-- df <- data.frame(iter = rep(1:steps, 3),  -->
+<!--                  value = c(chain1, chain2, chain3), -->
+<!--                  chain = c(rep(""chain1"", steps),  -->
+<!--                            rep(""chain2"", steps),  -->
+<!--                            rep(""chain3"", steps))) -->
+
+<!-- #---------- time series -->
+<!-- static_tsplot <- df %>% -->
+<!--   mutate(posterior_mean = mean(value)) %>% -->
+<!--   ggplot(aes(x = iter, y = value, group = chain, color = chain)) + -->
+<!--   geom_line(size = 1, alpha = 0.5) +  -->
+<!--   geom_hline(aes(yintercept = posterior_mean, linetype = ""posterior mean"")) +  -->
+<!--   scale_linetype_manual(name = """", values = c(2,2)) +  -->
+<!--   labs(color = """", x = ""iterations"", y = ""survival"") -->
+<!-- static_tsplot   -->
+
+<!-- # animate -->
+<!-- animated_tsplot <- static_tsplot + -->
+<!--   transition_reveal(along = iter,  -->
+<!--                     range = as.integer(c(1, max(df$iter) + 50))) # trick to pause -->
+<!-- animated_tsplot   -->
+
+<!-- # save -->
+<!-- a_gif <- animate(animated_tsplot, -->
+<!--                  width = 6,  -->
+<!--                  height = 3, -->
+<!--                  res = 600, -->
+<!--                  units = ""in"") -->
+
+<!-- # get file in directory str(a_gif) -->
+<!-- ``` -->
+<!-- ```{r animlongchain, echo = FALSE, out.width=""100%"", fig.align='center', fig.cap = ""Animated trace plot of survival with three chains starting at 0.2, 0.5 and 0.7 run for 1000 steps.""} -->
+<!-- knitr::include_graphics(""images/traceplotMCMC.gif"") -->
+<!-- ``` -->
 
 Once the stationary distribution is reached, you may regard the realisations of the Markov chain as a sample from the posterior distribution, and obtain numerical summaries. In the next section, we consider several important implementation issues. 
 
 ## Assessing convergence {#convergence-diag}
 
-```{block2 convergence, type='rmdnote'}
+:::: {.blackbox data-latex=""""}
 When implementing MCMC, we need to determine how long it takes for our Markov chain to converge to the target distribution, and the number of iterations we need after achieving convergence to get reasonable Monte Carlo estimates of numerical summaries (posterior means and credible intervals).
-```
+::::
 
 ### Burn-in
   
 In practice, we discard observations from the start of the Markov chain and just use observations from the chain once it has converged. The initial observations that we discard are usually referred to as the *burn-in*. 
 
-The simplest method to determine the length of the burn-in period is to look at trace plots. Going back to our example, we see from the trace plot in Figure \@ref(fig:burnin) that we need at least 100 iterations to achieve convergence toward an average survival around 0.3. It is always better to be conservative when specifying the length of the burn-in period, and in this example, we would use 250 or even 500 iterations as a burn-in. The length of the burn-in period can be determined by performing preliminary MCMC short runs. 
-
-```{r burnin, echo = FALSE, fig.cap = ""Determining the length of the burn-in period. The chain starts at value 0.99 and rapidly stabilises, with values bouncing back and forth around 0.3 from the 100th iteration onwards. You may choose the shaded area as the burn-in, and discard the corresponding values.""}
+The simplest method to determine the length of the burn-in period is to look at trace plots. Going back to our example, let's have a look to a trace plot of a chain that starts at value 0.99. 
 
+```{r burnin}
 # set up the scene
 steps <- 1000
 theta.post <- metropolis(steps = steps, inits = 0.99)
@@ -523,6 +542,10 @@ df %>%
   scale_y_continuous(expand = c(0,0))
 ```
 
+The chain starts at value 0.99 and rapidly stabilises, with values bouncing back and forth around 0.3 from the 100th iteration onwards. You may choose the shaded area as the burn-in, and discard the first 100th values.
+
+We see from the trace plot below that we need at least 100 iterations to achieve convergence toward an average survival around 0.3. It is always better to be conservative when specifying the length of the burn-in period, and in this example, we would use 250 or even 500 iterations as a burn-in. The length of the burn-in period can be determined by performing preliminary MCMC short runs. 
+
 Inspecting the trace plot for a single run of the Markov chain is useful. However, we usually run the Markov chain several times, starting from different over-dispersed points, to check that all runs achieve the same stationary distribution. This approach is formalised by using the Brooks-Gelman-Rubin (BGR) statistic $\hat{R}$ which measures the ratio of the total variability combining multiple chains (between-chain plus within-chain) to the within-chain variability. The BGR statistic asks whether there is a chain effect, and is very much alike the $F$ test in an analysis of variance. Values below 1.1 indicate likely convergence.
 
 ```{r, echo = FALSE, cache = TRUE}
@@ -562,20 +585,24 @@ for (i in 1:length(steps)){
 df <- data.frame(iterations = steps, bgr = bgr)
 ```
 
-Back to our example, we run two Markov chains with starting values 0.2 and 0.8 using 100 up to 5000 iterations, and calculate the BGR statistic using half the number of iterations as the length of the burn-in. From Figure \@ref(fig:bgr), we get a value of the BGR statistic near 1 by up to 2000 iterations, which suggests that with 2000 iterations as a burn-in, there is no evidence of a lack of convergence. 
+Back to our example, we run two Markov chains with starting values 0.2 and 0.8 using 100 up to 5000 iterations, and calculate the BGR statistic using half the number of iterations as the length of the burn-in (code not shown): 
 
-```{r bgr, echo=FALSE, fig.cap = ""Brooks-Gelman-Rubin statistic as a function of the number of iterations.""}
+```{r bgr, echo=FALSE}
 df %>%
   ggplot() + 
   geom_line(aes(x = iterations, y = bgr), size = 1.2) +
   labs(y = ""BGR statistic"")
 ```
 
-It is important to bear in mind that a value near 1 for the BGR statistic is only a necessary *but not sufficient* condition for convergence. In other words, this diagnostic cannot tell you for sure that the Markov chain has achieved convergence, only that it has not.^[Cross-reference sections on local minima and parameter redundancy for pathological cases.]
+We get a value of the BGR statistic near 1 by up to 2000 iterations, which suggests that with 2000 iterations as a burn-in, there is no evidence of a lack of convergence.
+
+It is important to bear in mind that a value near 1 for the BGR statistic is only a necessary *but not sufficient* condition for convergence. In other words, this diagnostic cannot tell you for sure that the Markov chain has achieved convergence, only that it has not.
 
 ### Chain length
   
-```{r, echo = FALSE}
+How long of a chain is needed to produce reliable parameter estimates? To answer this question, you need to keep in mind that successive steps in a Markov chain are not independent -- this is usually referred to as *autocorrelation*. Ideally, we would like to keep autocorrelation as low as possible. Here again, trace plots are useful to diagnose issues with autocorrelation. Let's get back to our survival example. The figure below shows trace plots for different values of the standard deviation (parameter *away*) of the normal proposal distribution we use to propose a candidate value (Section \@ref(metropolis-algorithm)): 
+
+```{r, echo = TRUE}
 # inspired from https://bookdown.org/content/3686/markov-chain-monte-carlo.html
 
 n_steps <- 10000
@@ -601,48 +628,48 @@ trace <- d %>%
   facet_wrap(~proposal_sd, ncol = 3) +
   theme_light(base_size = 14)
 
-library(forecast)
-plot1 <- ggAcf(x = d$accepted_traj[d$proposal_sd==""Proposal SD = 0.1""]) + ggtitle(""Proposal SD = 0.1"")
-plot2 <- ggAcf(x = d$accepted_traj[d$proposal_sd==""Proposal SD = 1""]) + ggtitle(""Proposal SD = 1"")
-plot3 <- ggAcf(x = d$accepted_traj[d$proposal_sd==""Proposal SD = 10""]) + ggtitle(""Proposal SD = 10"")
+trace
 ```
 
-How long of a chain is needed to produce reliable parameter estimates? To answer this question, you need to keep in mind that successive steps in a Markov chain are not independent -- this is usually referred to as *autocorrelation*. Ideally, we would like to keep autocorrelation as low as possible. Here again, trace plots are useful to diagnose issues with autocorrelation. Let's get back to our survival example. Figure \@ref(fig:tracechainlength) shows trace plots for different values of the standard deviation (parameter *away*) of the (normal) proposal distribution we use to propose a candidate value (Section \@ref(metropolis-algorithm)). Small and big moves provide high correlations between successive observations of the Markov chain, whereas a standard deviation of 1 allows efficient exploration of the parameter space. The movement around the parameter space is referred to as *mixing*. Mixing is bad when the chain makes small and big moves, and good otherwise. 
+Small and big moves in the left and right panels provide high correlations between successive observations of the Markov chain, whereas a standard deviation of 1 in the center panel allows efficient exploration of the parameter space. The movement around the parameter space is referred to as *mixing*. Mixing is bad when the chain makes small and big moves, and good otherwise. 
 
-```{r tracechainlength, echo=FALSE, fig.cap = ""Trace plots for different values of the standard deviation (SD) of the proposal distribution. Left: The chain exhibits small moves and mixing is bad. Right: The chain exhibits big moves and mixing is bad. Middle: The chain exhibits adequate moves and mixing is good. Only the thousand last iterations are shown.""}
-trace
-```
+In addition to trace plots, autocorrelation function (ACF) plots are a convenient way of displaying the strength of autocorrelation in a given sample values. ACF plots provide the autocorrelation between successively sampled values separated by an increasing number of iterations, or *lag*. We obtain the autocorrelation function plots for different values of the standard deviation of the proposal distribution with the R `forecast::ggAcf()` function: 
 
-In addition to trace plots, autocorrelation function (ACF) plots are a convenient way of displaying the strength of autocorrelation in a given sample values. ACF plots provide the autocorrelation between successively sampled values separated by an increasing number of iterations, or *lag* (Figure \@ref(fig:acfchainlength)).
+```{r}
+library(forecast)
+plot1 <- ggAcf(x = d$accepted_traj[d$proposal_sd==""Proposal SD = 0.1""]) + ggtitle(""Proposal SD = 0.1"")
+plot2 <- ggAcf(x = d$accepted_traj[d$proposal_sd==""Proposal SD = 1""]) + ggtitle(""Proposal SD = 1"")
+plot3 <- ggAcf(x = d$accepted_traj[d$proposal_sd==""Proposal SD = 10""]) + ggtitle(""Proposal SD = 10"")
 
-```{r acfchainlength, echo=FALSE, fig.cap = ""Autocorrelation function plots for different values of the standard deviation (SD) of the proposal distribution. Left and right: Autocorrelation is strong, decreases slowly with increasing lag and mixing is bad. Middle: Autocorrelation is weak, decreases rapidly with increasing lag and mixing is good.""}
 library(patchwork)
 (plot1 + plot2 + plot3)
 ```
 
-Autocorrelation is not necessarily a big issue. Strongly correlated observations just require large sample sizes and therefore longer simulations. But how many iterations exactly? The effective sample size (`n.eff`) measures chain length while taking into account chain autocorrelation. You should check the `n.eff` of every parameter of interest, and of any interesting parameter combinations. In general, we need $\text{n.eff} \geq 1000$ independent steps to get reasonable Monte Carlo estimates of model parameters. In the animal survival example, `n.eff` can be calculated with the R `coda::effectiveSize()` function.
-```{r neff, echo = FALSE}
+In the left and right panels, autocorrelation is strong, decreases slowly with increasing lag and mixing is bad. In the center panel, autocorrelation is weak, decreases rapidly with increasing lag and mixing is good.
+
+Autocorrelation is not necessarily a big issue. Strongly correlated observations just require large sample sizes and therefore longer simulations. But how many iterations exactly? The effective sample size (`n.eff`) measures chain length while taking into account chain autocorrelation. You should check the `n.eff` of every parameter of interest, and of any interesting parameter combinations. In general, we need $\text{n.eff} \geq 1000$ independent steps to get reasonable Monte Carlo estimates of model parameters. In the animal survival example, `n.eff` can be calculated with the R `coda::effectiveSize()` function:
+```{r neff, echo = TRUE}
 neff1 <- coda::effectiveSize(d$accepted_traj[d$proposal_sd==""Proposal SD = 0.1""])
 neff2 <- coda::effectiveSize(d$accepted_traj[d$proposal_sd==""Proposal SD = 1""])
 neff3 <- coda::effectiveSize(d$accepted_traj[d$proposal_sd==""Proposal SD = 10""])
 df <- tibble(""Proposal SD"" = c(0.1, 1, 10),
-                 ""n.eff"" = round(c(neff1, neff2, neff3)))
-knitr::kable(df, format = ""markdown"")
+             ""n.eff"" = round(c(neff1, neff2, neff3)))
+df
 ```
 
-As expected, `n.eff` is less than the number of MCMC iterations because of autocorrelation. Only when the standard deviation of the proposal distribution is 1 and mixing is good (Figures \@ref(fig:tracechainlength) and \@ref(fig:acfchainlength)) we get a satisfying effective sample size. 
+As expected, `n.eff` is less than the number of MCMC iterations because of autocorrelation. Only when the standard deviation of the proposal distribution is 1 is the mixing good and we get a satisfying effective sample size. 
 
 ### What if you have issues of convergence?
   
 When diagnosing MCMC convergence, you will (very) often run into troubles. In this section you will find some helpful tips I hope. 
 
 When mixing is bad and effective sample size is small, you may just need to increase burn-in and/or sample more. Using more informative priors might also make Markov chains converge faster by helping your MCMC sampler (e.g. the Metropolis algorithm) navigating more efficiently the parameter space. In the same spirit, picking better initial values for starting the chain does not harm. For doing that, a strategy consists in using estimates from a simpler model for which your MCMC chains do converge. 
 
-If convergence issues persist, often there is a problem with your model^[The quote 'When you have computational problems, often there's a problem with your model' is the folk theorem of statistical computing stated by Andrew Gelman in 2008, see https://statmodeling.stat.columbia.edu/2008/05/13/the_folk_theore/]. A bug in the code? A typo somewhere? A mistake in your maths? As often when coding is involved, the issue can be identified by removing complexities, and start with a simpler model until you find what the problem is. 
+If convergence issues persist, often there is a problem with your model (also known as the folk theorem of statistical computing as stated by Andrew Gelman in 2008, see https://statmodeling.stat.columbia.edu/2008/05/13/the_folk_theore/). A bug in the code? A typo somewhere? A mistake in your maths? As often when coding is involved, the issue can be identified by removing complexities, and start with a simpler model until you find what the problem is. 
 
 A general advice is to see your model as a data generating tool in the first place, simulate data from it using some realistic values for the parameters, and try to recover these parameter values by fitting the model to the simulated data. Simulating from a model will help you understanding how it works, what it does not do, and the data you need to get reasonable parameter estimates. 
 
-We will see other strategies to improve convergence in the next chapters.^[Cross reference relevant chapters. Option 1. Change your sampler. Option 2. Reparameterize (standardize covariates, plus non-centering: $\alpha \sim N(0,\sigma)$ becomes $\alpha = z \sigma$ with $z \sim N(0,1)$).]
+<!-- We will see other strategies to improve convergence in the next chapters. Cross reference relevant chapters. Option 1. Change your sampler. Option 2. Reparameterize (standardize covariates, plus non-centering: $\alpha \sim N(0,\sigma)$ becomes $\alpha = z \sigma$ with $z \sim N(0,1)$). -->
 
 ## Summary
 
@@ -658,6 +685,9 @@ We will see other strategies to improve convergence in the next chapters.^[Cross
 
 ## Suggested reading 
 
-+ I strongly recommend @gelman2020workflow in which the authors offer a workflow for bayesian analyses. They discuss model building, model comparison, model checking, model validation, model understanding and troubleshooting of computational problems.
++ @mccarthy2007 is an excellent introduction to Bayesian statistics for ecologists. 
+
++ For deeper insights, I recommend @gelmanhill2006 which analyse data using the frequentist and Bayesian approaches side-by-side. The book by @mcelreathbook is also an excellent read. The presentation of the Metropolis algorithm in Section \@ref(metropolis-algorithm) was inspired by @alberthu2019. If you'd like to know more about Monte Carlo methods, the book @robert2004montecarlo is a must (see also its R counterpart @robert2004montecarloinr). 
+
++ I also recommend @gelman2020workflow in which the authors offer a workflow for Bayesian analyses. They discuss model building, model comparison, model checking, model validation, model understanding and troubleshooting of computational problems.
 
-+ @gelmanhill2006, @mccarthy2007, @mcelreathbook. **Comment.**

---FILE: book.bib---
@@ -395,6 +395,18 @@ @article{choquet2018modulated
 year = {2018}
 }
 
+@article{cook1967expectancy,
+  title={The Accuracy of a Population Estimation from Multiple Recapture Data},
+  author={Cook, L.M.M and Brower, L. P. and Croze, H. J.},
+  journal={Journal of Animal Ecology},
+  volume={36},
+  number={1},
+  pages={57--60},
+  year={1967},
+  publisher={Wiley Online Library}
+}
+
+
 @article{cooch2012disease,
   title={Disease dynamics in wild populations: modeling and estimation: a review},
   author={Cooch, E.G. and Conn, P.B. and Ellner, S.P. and Dobson, A.P. and Pollock, K.H.},
@@ -623,6 +635,17 @@ @article{felsenstein_hidden_1996
   pages = {93--104},
 }
 
+
+@article{fernandez2016ggmcmc,
+	author = {Fern{\'a}ndez-i-Mar{\'\i}n, X.},
+	journal = {Journal of Statistical Software},
+	number = {9},
+	pages = {1--20},
+	title = {ggmcmc: Analysis of MCMC Samples and Bayesian Inference},
+	volume = {70},
+	year = {2016}}
+
+
 @article{FineEtAl1998,
   title={The hierarchical hidden {M}arkov model: Analysis and applications},
   author={Fine, Shai and Singer, Yoram and Tishby, Naftali},
@@ -666,6 +689,15 @@ @article{frederiksen2014
 	year = {2014}}
 
 
+@Misc{gabry2022bayesplot,
+    title = {bayesplot: Plotting for Bayesian Models},
+    author = {Gabry, J. and Mahr, T.},
+    year = {2022},
+    note = {R package version 1.10.0},
+    url = {https://mc-stan.org/bayesplot/},
+  }
+
+
 @article{GalesYoung2008,
   title={The application of hidden {M}arkov models in speech recognition},
   author={Gales, Mark and Young, Steve},
@@ -877,11 +909,11 @@ @article{glennie2019open
   publisher={Wiley Online Library}
 }
 
-@Manual{GoldsteinEtAl2019,
+@misc{goldstein2019nimbleecology,
     title = {{nimbleEcology}: Distributions for Ecological Models in 'nimble'},
-    author = {B. R. Goldstein and D. Turek and L. Ponisio and P. {de Valpine}},
-    year = {2019},
-    note = {R package version 0.1.0},
+    author = {Goldstein, B.R. and Turek, D. and Ponisio, L. and {de Valpine}, P.},
+    year = {2021},
+    note = {R package version 0.4.1},
     url = {https://CRAN.R-project.org/package=nimbleEcology},
 }
 
@@ -1247,6 +1279,17 @@ @article{LinkEtAl2010
  year                 = {2010},
  }
  
+
+@article{link2012thinning,
+	author = {Link, W. A. and Eaton, M. J.},
+	journal = {Methods in Ecology and Evolution},
+	number = {1},
+	pages = {112-115},
+	title = {On thinning of chains in MCMC},
+	volume = {3},
+	year = {2012}}
+ 
+ 
 @article{LloydEtAl2020,
   title={Trade-offs between age-related breeding improvement and survival senescence in highly polygynous elephant seals: Dominant males always do better},
   author={Lloyd, Kyle J and Oosthuizen, W Chris and Bester, Marth{\'a}n N and de Bruyn, PJ Nico},
@@ -1714,6 +1757,17 @@ @article{Pollock2002
  year                 = {2002},
  }
  
+
+@article{ponisio2020customizing,
+	author = {Ponisio, L. C. and {de Valpine}, P. and Michaud, N. and Turek, D.},
+	journal = {Ecology and Evolution},
+	number = {5},
+	pages = {2385-2416},
+	title = {One size does not fit all: Customizing MCMC methods for hierarchical models using NIMBLE},
+	volume = {10},
+	year = {2020}}
+
+ 
 @article{Pradel1996,
  author               = {Pradel, R.},
  journal              = {Biometrics},
@@ -1773,6 +1827,22 @@ @Manual{RCoreTeam2019
     url = {https://www.R-project.org/},
 }
 
+@book{robert2004montecarlo,
+  title={Monte Carlo Statistical Methods},
+  author={Robert, C.P. and Casella, G.},
+  year={2004},
+  publisher={{Springer}},
+  edition={2nd edition}
+}
+
+@book{robert2004montecarloinr,
+  title={Introducing Monte Carlo Methods with R},
+  author={Robert, C.P. and Casella, G.},
+  year={2010},
+  publisher={{Springer}}
+}
+
+
 
 @article{rose2018,
 	author = {Rose, J. P. and Wylie, G. D. and Casazza, M. L. and Halstead, B. J.},
@@ -2072,6 +2142,14 @@ @article{TurekEtAl2016
   year={2016}
 }
 
+@Misc{turek2022basicmcmcplots,
+    title = {basicMCMCplots: Trace Plots, Density Plots and Chain Comparisons for MCMC Samples},
+    author = {Turek, D.},
+    year = {2022},
+    note = {R package version 0.2.7},
+    url = {https://mc-stan.org/bayesplot/},
+  }
+
 @article{VeranEtAl2015,
   title={Modeling spatiotemporal dynamics of outbreaking species: influence of environment and migration in a locust},
   author={Veran, Sophie and Simpson, Stephen J and Sword, Gregory A and Deveson, Edward and Piry, Sylvain and Hines, James E and Berthier, Karine},
@@ -2155,7 +2233,17 @@ @article{YackulicEtAl2020
   issue={5},
   year={2020}
 }
- 
+
+@article{youngflesh2018mcmcvis,
+  title={{MCMCvis}: Tools to visualize, manipulate, and summarize MCMC output},
+  author={Youngflesh, C.},
+  journal={Journal of Open Source Software},
+  volume={3},
+  number={24},
+  pages={640},
+  year={2018}
+}
+
 @book{ZucchiniEtAl2016,
   title={Hidden {M}arkov models for time series: {A}n introduction using {R}},
   author={Zucchini, W. and MacDonald, I.L. and Langrock, R.},

---FILE: covariates.Rmd---
@@ -12,7 +12,7 @@ Splines √† la @gimenez_semiparametric_2006, possibly w/ jagam <https://rdrr.io/c
 
 RJMCMC in @gimenez2009fitness on Common blackbirds or @gimenez2009winbugs on White stork.
 
-As an illustration, we use data on the white stork {\it Ciconia ciconia} population in Baden W\""{u}rttemberg (Germany), consisting of 321 capture histories of individuals ringed as chicks between 1956 and 1971. From the 60's to the 90's, all Western European stork populations were declining @bair91. This trend was likely the result of reduced food availability @schau05 caused by severe droughts observed in the wintering ground of storks in the Sahel region. This hypothesis has been examined in several studies (@kanya90 and @barb99). 
+As an illustration, we use data on the white stork *Ciconia ciconia* population in Baden Wurttemberg (Germany), consisting of 321 capture histories of individuals ringed as chicks between 1956 and 1971. From the 60's to the 90's, all Western European stork populations were declining @bair91. This trend was likely the result of reduced food availability @schau05 caused by severe droughts observed in the wintering ground of storks in the Sahel region. This hypothesis has been examined in several studies (@kanya90 and @barb99). 
 
 Check out <https://r-nimble.org/nimbleExamples/RJMCMC_example.html> and <https://r-nimble.org/variable-selection-in-nimble-using-reversible-jump-mcmc>.
 
@@ -37,3 +37,17 @@ E.g. @Gervasi2017.
 Not spatial capture-recapture sensu SCR or SECR or oSCR. Refer to book.
 
 3D Splines as in @Peron2011. (I)CAR as in @saracco2010icar (see  (<https://github.com/Andrew9Lawson/Bayesian-DM-code-examples>, <https://github.com/Andrew9Lawson/Bayesian_DM_Nimble_code/tree/ICAR-and-other-code> and <https://r-nimble.org/html_manual/cha-spatial.html> for NIMBLE implementation). Add RSR @khan2022rsr (see Jags code at <https://gist.github.com/oliviergimenez/0d5519654adef09060581eb49e2128ce>). 
+
+## Misc
+
+Somewhere explain how to use if-else in model code to consider alternative models, w/ some covariate in/out. Avoids rewriting all models, we see what's changed, and it avoids errors. Example:
+
+```{r eval = FALSE}
+if(covariate){
+logit(survival[t]) <- beta[1] + beta[2] *x[t]
+}else{
+logit(survival[t]) <- beta[1]
+}#ifelse
+```
+
+then specify ""covariate=TRUE/FALSE"".
\ No newline at end of file

---FILE: dispersal.Rmd---
@@ -80,8 +80,7 @@ We drop the time index.
 
 Vector of initial states. **Explain.**
 
-$$
-\begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\delta} =
     \left ( \vphantom{ \begin{matrix} 12 \end{matrix} } \right .
@@ -97,13 +96,11 @@ $$
 \left . \vphantom{ \begin{matrix} 12 \end{matrix} } \right )
     \begin{matrix}
     \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
 
 Transition matrix. **Explain.**
 
-$$
-\begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\Gamma} =
     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
@@ -122,13 +119,11 @@ $$
     \begin{matrix}
     z_{t-1}=A \\ z_{t-1}=B \\ z_{t-1}=D
     \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
 
 Observation matrix. **Explain.**
 
-$$
-\begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\Omega} =
     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
@@ -147,8 +142,7 @@ $$
     \begin{matrix}
     z_{t}=A \\ z_{t}=B \\ z_{t}=D
     \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
 
 ### Goodness of fit {#gofas}
   
@@ -177,13 +171,11 @@ overall_JMV(geese.hist, geese.freq)
 
 To introduce this chapter, we will use data on the Canada goose (*Cinclus cinclus*; geese hereafter) kindly provided by Jay Hestbeck (**add pix of a goose?**). In total, 21277 geese were captured, marked with coded neck bands and recaptured between 1984 and 1989 in their wintering locations. Specifically, geese were monitored in the Atlantic flyway, in large areas along the East coast of the USA, namely 3 sites in the mid--Atlantic (New York, Pennsylvania, New Jersey), Chesapeake (Delaware, Maryland, Virginia), and Carolinas (North and South Carolina). Birds were adults and sub-adults when banded. 
 
-You may scroll down the data below (**only a subsample**): 
+You may see the data below (**only a subsample**): 
 
 ```{r echo = FALSE}
 geese <- read_csv(here::here(""dat"", ""geese.csv""))
-geese %>%
-  kableExtra::kable() %>%
-  kableExtra::scroll_box(width = ""100%"", height = ""400px"")
+geese
 y <- geese %>%
   as.matrix()
 ```
@@ -546,9 +538,9 @@ In brief, states are individual, time-specific discrete covariates.
 
 ### Titis data 
 
-To illustrate this section, we will consider data collected between 1940 and 1957 by Lance Richdale on the Sooty shearwaters (aka titis). **More details. Plus a picture of titi.**
+To illustrate this section, we will consider data collected between 1940 and 1957 by Lance Richdale on the Sooty shearwaters (aka titis): **More details. Plus a picture of titi.**
 
-```{r echo = FALSE}
+```{r echo = TRUE}
 titis <- read_csv2(here::here(""dat"", ""titis.csv""), col_names = FALSE)
 titis %>%
   rename(year_1942 = X1,
@@ -557,9 +549,7 @@ titis %>%
          year_1949 = X4,
          year_1952 = X5,
          year_1953 = X6,
-         year_1956 = X7) %>%
-  kableExtra::kable() %>%
-  kableExtra::scroll_box(width = ""100%"", height = ""400px"")
+         year_1956 = X7)
 ```
 
 
@@ -581,8 +571,7 @@ Basically, same model as in the geese example with two sites, see Sections \@ref
 
 Transition matrix
 
-$$
-\begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\Gamma} =
     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
@@ -601,15 +590,13 @@ $$
     \begin{matrix}
     z_{t-1}=B \\ z_{t-1}=NB \\ z_{t-1}=D
     \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
 
 The costs or reproduction would reflect in future reproduction if breeders have a lower probability of breed next year than non-breeders $\psi^{BB} = 1 - \psi^{BNB} < \psi^{NBB}$ or in survival if the survival of breeders is lower than that of non-breeders $\phi^B < \phi^{NB}$.
 
 Observation matrix
 
-$$
-\begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\Omega} =
     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
@@ -628,8 +615,7 @@ $$
     \begin{matrix}
     z_{t}=B \\ z_{t}=NB \\ z_{t}=D
     \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
 
 ### NIMBLE implementation
 
@@ -773,13 +759,15 @@ df %>%
 
 ```
 
-Interestingly, breeder individuals do much better than non-breeder individuals. This failure at detecting a trade-off is probably due to individual heterogeneity that should be accounted for. **Case study with simulations as in Oikos paper, see Figure 1 and Table 2. Would be a nice example of the use of simulations. Another example could the statistical power analyses.**
+Interestingly, breeder individuals do much better than non-breeder individuals. This failure at detecting a trade-off is probably due to individual heterogeneity that should be accounted for. **Case study with simulations as in Oikos paper, see Figure 1 and Table 2. Would be a nice example of the use of simulations. Another example could the statistical power analyses.** 
+
+<!-- See M. Paquet suggestion: Pouvoir utiliser le mod√®le √† la fois pour simuler des donn√©es, puis ensuite pour les ajuster au mod√®le (le tout sans avoir √† r√©√©crire le mod√®le!). Exemple: nodesToSim <- model$getDependencies(c(""parameter_name1"",""parameter_name2""), self = F, downstream = T), # compile Cmodel <- compileNimble(model), #simulate Cmodel$simulate(nodesToSim) -->
   
 ## Issue of local minima {#localminima}
 
 In the Frequentist approach, we use the maximum likelihood theory to estimate parameters. The maximum likelihood estimates are the values that get you to the maximum of the model likelihood. To find out the maximum of the likelihood, we use iterative optimization algorithms. However, sometimes, our model likelihood contains several maxima and there is no guarantee that the algorithms will find the global maximum corresponding to the maximum likelihood estimates, and it may get stuck in a local maximum. Let's illustrate this issue with some simulated data that were kindly provided by J√©r√¥me Dupuis. We consider 2 sites or states, say 1 and 2, and 7 sampling occasions. The survival probability is constant $\phi = 1$ as well as the detection probability $p = 0.6$. The probability of moving from 1 to 2 is $\psi^{12} = 0.6$ and $\psi^{21} = 0.85$ in the opposite direction. Here are the encounter histories of the 27 individuals that were simulated: **refer to HMM chapter for simulations?**
 
-```{r echo = FALSE}
+```{r echo = TRUE}
 dat <- matrix(c(2, 0, 2, 1, 2, 0, 2,
                 2, 0, 2, 1, 2, 0, 2,
                 2, 0, 2, 1, 2, 0, 2,
@@ -815,9 +803,7 @@ dat <- matrix(c(2, 0, 2, 1, 2, 0, 2,
               byrow = T,
               ncol = 7)
 dat %>%
-  as_tibble() %>%
-  kableExtra::kable() %>%
-  kableExtra::scroll_box(width = ""100%"", height = ""400px"")
+  as_tibble()
 ```
 
 In Figure \@ref(fig:inits), we provide an illustration of the influence of the choice of initial values when trying to minimize the deviance (which is minus two times the log of the likelihood). The black curve is the what we called the profile deviance for $\psi^{21}$. In brief, the profile deviance consists in taking a slice of the deviance in the direction of a parameter of interest and treating the other parameters as nuisance parameters. In our example, we set $\psi^{21}$ to a value (on the x-axis) an minimize the deviance with respect to the other parameters (on the y-axis). There are two minima, but only the global minimum corresponding to $\psi^{21}$ around 0.8 is of interest to us. The thing is that if you start your optimization algorithm by picking value in the red area, then it will get stuck in the local minimum and tells you the maximum likelihood estimate of $\psi^{21}$ is around 0.35, which is obviously far from the value we used to simulate the data. In contrast, if you pick initial values in the green area, then the algorithm will converge to the global minimum. 
@@ -972,8 +958,7 @@ Each alive state can generate 3 observations. The only deterministic link is tha
 
 Let's specify the model. First thing we need, and it's a big difference with the AS model, we need initial state probabilities because we cannot assign states to individuals with certainty **assumes we got rid of them in the multistate section, is it true?**. We write down the probability for each state at first encounter, or the vector of initial state probabilities:
 
-$$
-\begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\delta} =
     \left ( \vphantom{ \begin{matrix} 12 \end{matrix} } \right .
@@ -989,15 +974,13 @@ $$
 \left . \vphantom{ \begin{matrix} 12 \end{matrix} } \right )
     \begin{matrix}
     \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
 
 where $\pi^B$ is the probability that a newly encountered individual is a breeder, and $\pi^{NB} = 1 - \pi^B$ is the probability that a newly encountered individual is a non-breeder (the complementary probability of $\pi^B$. The probability of being dead at first encounter is 0 (a bird is alive when it is first encountered).
 
 Now the transition matrix, this is the easy part as it doesn't change. We have:
 
-$$
-\begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\Gamma} =
     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
@@ -1016,15 +999,13 @@ $$
     \begin{matrix}
     z_{t-1}=B \\ z_{t-1}=NB \\ z_{t-1}=D
     \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
 
 where $\phi^B$ is the breeder survival, $\phi_ {NB}$ that of non-breeders, $\psi^{BNB}$ is the probability for an individual breeding a year to be a non-breeder the next year, and $\psi^{NBB}$ is the probability for an non-breeder individual to breeder the next year. 
 
 Last, the observation matrix. The main difference between multistate and multievent models is here, in the observation parameters. Besides $p^B$ the detection probability of breeders and $p^{NB}$ that of non-breeders, we introduce two new parameters: $\beta^B$ is the probability to correctly assign an individual that is in state B to state B, and $\beta^{NB}$ is the probability to correctly assign an individual that is in state NB to state NB. We put everything in a matrix, as usual. In rows we have the states: breeding, non-breeding and dead. In columns, at the same occasion, we have the observations: detected and ascertained B, detected and ascertained NB, detected and state unknown, and not detected. 
 
-$$
-\begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\Omega} =
     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right .
@@ -1043,14 +1024,12 @@ $$
     \begin{matrix}
     z_{t}=B \\ z_{t}=NB \\ z_{t}=D
     \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
 For example, the probability of being detected and assigned to state B, given that you're in state B is the product of the detection probability in B and the probability of correctly assigning a breeding individual to state B.
 
 At first encounter, all individuals are captured, but you still need to assign them a state. This means that we should set $p^B = p^{NB} = 1$ and use:
 
-$$
-\begin{matrix}
+$$\begin{matrix}
 & \\
     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right .
 \end{matrix}
@@ -1068,8 +1047,7 @@ $$
     \begin{matrix}
     z_{t = \text{first}}=B \\ z_{t = \text{first}}=NB \\ z_{t = \text{first}}=D
     \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
 **Show how to split into capture then assignment? Matrix product and all.**
 
 ### NIMBLE implementation

---FILE: docs/404.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -70,21 +69,21 @@ <h1>
         <ul class=""book-toc list-unstyled"">
 <li><a class="""" href=""index.html"">Welcome</a></li>
 <li><a class="""" href=""preface.html"">Preface</a></li>
-<li class=""book-part"">I. Foundations</li>
+<li class=""book-part"">Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li class=""book-part"">II. Transitions</li>
+<li class=""book-part"">Transitions</li>
 <li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Alive and dead</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Sites and states</a></li>
-<li class=""book-part"">III. Case studies</li>
+<li class=""book-part"">Case studies</li>
 <li><a class="""" href=""introduction-7.html"">Introduction</a></li>
 <li><a class="""" href=""covariateschapter.html""><span class=""header-section-number"">6</span> Covariates</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">7</span> Life history</a></li>
 <li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">8</span> Lack of fit</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">9</span> Miscelleanous</a></li>
+<li><a class="""" href=""miscelleanous.html""><span class=""header-section-number"">9</span> Miscelleanous</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
 
@@ -112,7 +111,7 @@ <h1>Page not found<a class=""anchor"" aria-label=""anchor"" href=""#page-not-found""><
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-20.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-21.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/covariateschapter.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -70,21 +69,21 @@ <h1>
         <ul class=""book-toc list-unstyled"">
 <li><a class="""" href=""index.html"">Welcome</a></li>
 <li><a class="""" href=""preface.html"">Preface</a></li>
-<li class=""book-part"">I. Foundations</li>
+<li class=""book-part"">Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li class=""book-part"">II. Transitions</li>
+<li class=""book-part"">Transitions</li>
 <li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Alive and dead</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Sites and states</a></li>
-<li class=""book-part"">III. Case studies</li>
+<li class=""book-part"">Case studies</li>
 <li><a class="""" href=""introduction-7.html"">Introduction</a></li>
 <li><a class=""active"" href=""covariateschapter.html""><span class=""header-section-number"">6</span> Covariates</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">7</span> Life history</a></li>
 <li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">8</span> Lack of fit</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">9</span> Miscelleanous</a></li>
+<li><a class="""" href=""miscelleanous.html""><span class=""header-section-number"">9</span> Miscelleanous</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
 
@@ -114,7 +113,7 @@ <h2>
 <span class=""header-section-number"">6.3</span> Covariate selection<a class=""anchor"" aria-label=""anchor"" href=""#covariate-selection""><i class=""fas fa-link""></i></a>
 </h2>
 <p>RJMCMC in <span class=""citation"">Gimenez, Gr√©goire, and Lenormand (<a href=""references.html#ref-gimenez2009fitness"">2009</a>)</span> on Common blackbirds or <span class=""citation"">Gimenez et al. (<a href=""references.html#ref-gimenez2009winbugs"">2009</a>)</span> on White stork.</p>
-<p>As an illustration, we use data on the white stork {} population in Baden W""{u}rttemberg (Germany), consisting of 321 capture histories of individuals ringed as chicks between 1956 and 1971. From the 60‚Äôs to the 90‚Äôs, all Western European stork populations were declining <span class=""citation"">Bairlein (<a href=""references.html#ref-bair91"">1991</a>)</span>. This trend was likely the result of reduced food availability <span class=""citation"">Schaub, Kania, and U. (<a href=""references.html#ref-schau05"">2005</a>)</span> caused by severe droughts observed in the wintering ground of storks in the Sahel region. This hypothesis has been examined in several studies (<span class=""citation"">Kanyamibwa et al. (<a href=""references.html#ref-kanya90"">1990</a>)</span> and <span class=""citation"">Barbraud, Barbraud, and Barbraud (<a href=""references.html#ref-barb99"">1999</a>)</span>).</p>
+<p>As an illustration, we use data on the white stork <em>Ciconia ciconia</em> population in Baden Wurttemberg (Germany), consisting of 321 capture histories of individuals ringed as chicks between 1956 and 1971. From the 60‚Äôs to the 90‚Äôs, all Western European stork populations were declining <span class=""citation"">Bairlein (<a href=""references.html#ref-bair91"">1991</a>)</span>. This trend was likely the result of reduced food availability <span class=""citation"">Schaub, Kania, and U. (<a href=""references.html#ref-schau05"">2005</a>)</span> caused by severe droughts observed in the wintering ground of storks in the Sahel region. This hypothesis has been examined in several studies (<span class=""citation"">Kanyamibwa et al. (<a href=""references.html#ref-kanya90"">1990</a>)</span> and <span class=""citation"">Barbraud, Barbraud, and Barbraud (<a href=""references.html#ref-barb99"">1999</a>)</span>).</p>
 <p>Check out <a href=""https://r-nimble.org/nimbleExamples/RJMCMC_example.html"" class=""uri"">https://r-nimble.org/nimbleExamples/RJMCMC_example.html</a> and <a href=""https://r-nimble.org/variable-selection-in-nimble-using-reversible-jump-mcmc"" class=""uri"">https://r-nimble.org/variable-selection-in-nimble-using-reversible-jump-mcmc</a>.</p>
 </div>
 <div id=""sex-uncertainty"" class=""section level2"" number=""6.4"">
@@ -147,6 +146,19 @@ <h2>
 </h2>
 <p>Not spatial capture-recapture sensu SCR or SECR or oSCR. Refer to book.</p>
 <p>3D Splines as in <span class=""citation"">P√©ron et al. (<a href=""references.html#ref-Peron2011"">2011</a>)</span>. (I)CAR as in <span class=""citation"">Saracco et al. (<a href=""references.html#ref-saracco2010icar"">2010</a>)</span> (see (<a href=""https://github.com/Andrew9Lawson/Bayesian-DM-code-examples"" class=""uri"">https://github.com/Andrew9Lawson/Bayesian-DM-code-examples</a>, <a href=""https://github.com/Andrew9Lawson/Bayesian_DM_Nimble_code/tree/ICAR-and-other-code"" class=""uri"">https://github.com/Andrew9Lawson/Bayesian_DM_Nimble_code/tree/ICAR-and-other-code</a> and <a href=""https://r-nimble.org/html_manual/cha-spatial.html"" class=""uri"">https://r-nimble.org/html_manual/cha-spatial.html</a> for NIMBLE implementation). Add RSR <span class=""citation"">Khan and Calder (<a href=""references.html#ref-khan2022rsr"">2022</a>)</span> (see Jags code at <a href=""https://gist.github.com/oliviergimenez/0d5519654adef09060581eb49e2128ce"" class=""uri"">https://gist.github.com/oliviergimenez/0d5519654adef09060581eb49e2128ce</a>).</p>
+</div>
+<div id=""misc"" class=""section level2"" number=""6.9"">
+<h2>
+<span class=""header-section-number"">6.9</span> Misc<a class=""anchor"" aria-label=""anchor"" href=""#misc""><i class=""fas fa-link""></i></a>
+</h2>
+<p>Somewhere explain how to use if-else in model code to consider alternative models, w/ some covariate in/out. Avoids rewriting all models, we see what‚Äôs changed, and it avoids errors. Example:</p>
+<div class=""sourceCode"" id=""cb306""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""kw"">if</span><span class=""op"">(</span><span class=""va"">covariate</span><span class=""op"">)</span><span class=""op"">{</span></span>
+<span><span class=""fu""><a href=""https://rdrr.io/pkg/gtools/man/logit.html"">logit</a></span><span class=""op"">(</span><span class=""va"">survival</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">]</span><span class=""op"">)</span> <span class=""op"">&lt;-</span> <span class=""va"">beta</span><span class=""op"">[</span><span class=""fl"">1</span><span class=""op"">]</span> <span class=""op"">+</span> <span class=""va"">beta</span><span class=""op"">[</span><span class=""fl"">2</span><span class=""op"">]</span> <span class=""op"">*</span><span class=""va"">x</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">]</span></span>
+<span><span class=""op"">}</span><span class=""kw"">else</span><span class=""op"">{</span></span>
+<span><span class=""fu""><a href=""https://rdrr.io/pkg/gtools/man/logit.html"">logit</a></span><span class=""op"">(</span><span class=""va"">survival</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">]</span><span class=""op"">)</span> <span class=""op"">&lt;-</span> <span class=""va"">beta</span><span class=""op"">[</span><span class=""fl"">1</span><span class=""op"">]</span></span>
+<span><span class=""op"">}</span><span class=""co"">#ifelse</span></span></code></pre></div>
+<p>then specify ‚Äúcovariate=TRUE/FALSE‚Äù.</p>
 
 </div>
 </div>
@@ -165,6 +177,7 @@ <h2>
 <li><a class=""nav-link"" href=""#covariate-on-multinomial-logit-link-or-dirichlet""><span class=""header-section-number"">6.6</span> Covariate on multinomial logit link or Dirichlet</a></li>
 <li><a class=""nav-link"" href=""#uncertainty-in-age""><span class=""header-section-number"">6.7</span> Uncertainty in age</a></li>
 <li><a class=""nav-link"" href=""#spatial""><span class=""header-section-number"">6.8</span> Spatial</a></li>
+<li><a class=""nav-link"" href=""#misc""><span class=""header-section-number"">6.9</span> Misc</a></li>
 </ul>
 
       <div class=""book-extra"">
@@ -182,7 +195,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-20.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-21.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/index.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -70,21 +69,21 @@ <h1>
         <ul class=""book-toc list-unstyled"">
 <li><a class=""active"" href=""index.html"">Welcome</a></li>
 <li><a class="""" href=""preface.html"">Preface</a></li>
-<li class=""book-part"">I. Foundations</li>
+<li class=""book-part"">Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li class=""book-part"">II. Transitions</li>
+<li class=""book-part"">Transitions</li>
 <li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Alive and dead</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Sites and states</a></li>
-<li class=""book-part"">III. Case studies</li>
+<li class=""book-part"">Case studies</li>
 <li><a class="""" href=""introduction-7.html"">Introduction</a></li>
 <li><a class="""" href=""covariateschapter.html""><span class=""header-section-number"">6</span> Covariates</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">7</span> Life history</a></li>
 <li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">8</span> Lack of fit</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">9</span> Miscelleanous</a></li>
+<li><a class="""" href=""miscelleanous.html""><span class=""header-section-number"">9</span> Miscelleanous</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
 
@@ -99,8 +98,9 @@ <h1>Welcome<a class=""anchor"" aria-label=""anchor"" href=""#welcome""><i class=""fas f
 <!-- bookdown::render_book(""index.Rmd"", ""bookdown::pdf_book"") -->
 <p>Welcome to the online version of the book <em>Bayesian analysis of capture-recapture data with hidden Markov models: Theory and case studies in R and NIMBLE</em>. <!-- The book is also available in [PDF format](https://github.com/oliviergimenez/banana-book/raw/master/docs/bayesHMMcapturerecapture.pdf). --> Here, I write about three of my favorite research topics ‚Äì capture-recapture, hidden Markov models and Bayes statistics ‚Äì let‚Äôs enjoy this great cocktail together üçπ</p>
 <p>I‚Äôm currently writing this book, and I welcome any feedback. You may raise an issue <a href=""https://github.com/oliviergimenez/banana-book/issues"">here</a>, amend directly the R Markdown file that generated the page you‚Äôre reading by clicking on the ‚ÄòEdit this page‚Äô icon in the right panel, or <a href=""mailto:olivier.gimenez@cefe.cnrs.fr"">email me</a>. Many thanks!</p>
+<!-- The PDF of the book can be downloaded [here](banana-book.pdf). I still need to fix lots of issues.  -->
 <p>Olivier Gimenez. Written in Montpellier, France and Athens, Greece.
-Last updated: August 20, 2023</p>
+Last updated: August 21, 2023</p>
 <div id=""license"" class=""section level2 unnumbered"">
 <h2>License<a class=""anchor"" aria-label=""anchor"" href=""#license""><i class=""fas fa-link""></i></a>
 </h2>
@@ -134,7 +134,7 @@ <h2>License<a class=""anchor"" aria-label=""anchor"" href=""#license""><i class=""fas f
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-20.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-21.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/introduction-1.html---
@@ -0,0 +1,159 @@
+<!DOCTYPE html>
+<html lang=""en"">
+<head>
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>Introduction | Bayesian analysis of capture-recapture data with hidden Markov models</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""This second part Transitions will teach you all about capture-recapture models for open populations, with reproducible R code to ease the learning process."">
+<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
+<meta property=""og:title"" content=""Introduction | Bayesian analysis of capture-recapture data with hidden Markov models"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/banana-book/introduction-1.html"">
+<meta property=""og:description"" content=""This second part Transitions will teach you all about capture-recapture models for open populations, with reproducible R code to ease the learning process."">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""Introduction | Bayesian analysis of capture-recapture data with hidden Markov models"">
+<meta name=""twitter:description"" content=""This second part Transitions will teach you all about capture-recapture models for open populations, with reproducible R code to ease the learning process."">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+    
+    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
+  </style>
+<style type=""text/css"">
+    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
+    div.csl-bib-body { }
+    div.csl-entry {
+      clear: both;
+        }
+    .hanging div.csl-entry {
+      margin-left:2em;
+      text-indent:-2em;
+    }
+    div.csl-left-margin {
+      min-width:2em;
+      float:left;
+    }
+    div.csl-right-inline {
+      margin-left:2em;
+      padding-left:1em;
+    }
+    div.csl-indent {
+      margin-left: 2em;
+    }
+  </style>
+<link rel=""stylesheet"" href=""bs4_style.css"">
+</head>
+<body data-spy=""scroll"" data-target=""#toc"">
+
+<div class=""container-fluid"">
+<div class=""row"">
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+
+    <div class=""d-flex align-items-start justify-content-between"">
+      <h1>
+        <a href=""index.html"" title=""Theory and case studies in R and NIMBLE"">Bayesian analysis of capture-recapture data with hidden Markov models</a>:
+        <small class=""text-muted"">Theory and case studies in R and NIMBLE</small>
+      </h1>
+      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
+    </div>
+
+    <div id=""main-nav"" class=""collapse-lg"">
+      <form role=""search"">
+        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
+</form>
+
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li class=""book-part"">Foundations</li>
+<li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li class=""book-part"">Transitions</li>
+<li><a class=""active"" href=""introduction-1.html"">Introduction</a></li>
+<li class=""book-part"">Case studies</li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""covariateschapter.html""><span class=""header-section-number"">1</span> Covariates</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">3</span> Lack of fit</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
+
+        <div class=""book-extra"">
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
+        </div>
+      </nav>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""introduction-1"" class=""section level1 unnumbered"">
+<h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-1""><i class=""fas fa-link""></i></a>
+</h1>
+<p>This second part <code>Transitions</code> will teach you all about capture-recapture models for open populations, with reproducible R code to ease the learning process.</p>
+
+</div>
+
+
+
+  <div class=""chapter-nav"">
+<div class=""prev""><a href=""introduction.html"">Introduction</a></div>
+<div class=""next""><a href=""introduction-2.html"">Introduction</a></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
+      <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#introduction-1"">Introduction</a></li></ul>
+
+      <div class=""book-extra"">
+        <ul class=""list-unstyled"">
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionparttwo.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionparttwo.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+        </ul>
+</div>
+    </nav>
+</div>
+
+</div>
+</div> <!-- .container -->
+
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-21.</p>
+  </div>
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
+  </div>
+
+</div></div>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
+</body>
+</html>

---FILE: docs/introduction-2.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -70,17 +69,13 @@ <h1>
         <ul class=""book-toc list-unstyled"">
 <li><a class="""" href=""index.html"">Welcome</a></li>
 <li><a class="""" href=""preface.html"">Preface</a></li>
-<li class=""book-part"">I. Foundations</li>
+<li class=""book-part"">Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">1</span> Hidden Markov models</a></li>
-<li class=""book-part"">II. Transitions</li>
+<li class=""book-part"">Transitions</li>
 <li><a class=""active"" href=""introduction-2.html"">Introduction</a></li>
-<li class=""book-part"">III. Case studies</li>
+<li class=""book-part"">Case studies</li>
 <li><a class="""" href=""introduction-3.html"">Introduction</a></li>
-<li><a class="""" href=""covariateschapter.html""><span class=""header-section-number"">2</span> Covariates</a></li>
-<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">3</span> Life history</a></li>
-<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">4</span> Lack of fit</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">5</span> Miscelleanous</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
 
@@ -120,7 +115,7 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-2""><i
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-20.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-21.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/introduction-3.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -70,17 +69,13 @@ <h1>
         <ul class=""book-toc list-unstyled"">
 <li><a class="""" href=""index.html"">Welcome</a></li>
 <li><a class="""" href=""preface.html"">Preface</a></li>
-<li class=""book-part"">I. Foundations</li>
+<li class=""book-part"">Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">1</span> Hidden Markov models</a></li>
-<li class=""book-part"">II. Transitions</li>
+<li class=""book-part"">Transitions</li>
 <li><a class="""" href=""introduction-2.html"">Introduction</a></li>
-<li class=""book-part"">III. Case studies</li>
+<li class=""book-part"">Case studies</li>
 <li><a class=""active"" href=""introduction-3.html"">Introduction</a></li>
-<li><a class="""" href=""covariateschapter.html""><span class=""header-section-number"">2</span> Covariates</a></li>
-<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">3</span> Life history</a></li>
-<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">4</span> Lack of fit</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">5</span> Miscelleanous</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
 
@@ -93,7 +88,7 @@ <h1>
 <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-3""><i class=""fas fa-link""></i></a>
 </h1>
 <p>This third part <code>Case studies</code> provides real-world case studies from the scientific literature that you can reproduce using material covered in previous chapters. These problems can either i) be used to cement and deepen your understanding of methods and models, ii) be adapted for your own purpose, or iii) serve as teaching projects.</p>
-<p>I have assembled a searchable list at <a href=""https://oliviergimenez.github.io/banana-book/applistHMM.html"" class=""uri"">https://oliviergimenez.github.io/banana-book/applistHMM.html</a> of HMM analyses of capture-recapture data to get inspiration. This list is not exhaustive, please get in touch with us if you‚Äôd like to add a reference.</p>
+<p>I have assembled a searchable list at <a href=""https://oliviergimenez.github.io/curated-list-HMM-apps/"" class=""uri"">https://oliviergimenez.github.io/curated-list-HMM-apps/</a> of HMM analyses of capture-recapture data to get inspiration. This list is not exhaustive, please get in touch with us if you‚Äôd like to add a reference.</p>
 <p>Before we start with case studies, we‚Äôd like to give you a few pieces of advice. This is not rocket science. Just a few things based on our own experience of Bayesian capture-recapture analysis with HMM.</p>
 <ul>
 <li><p>Make your ecological question explicit. First things first. Make sure you‚Äôve spent some to time to make your ecological question explicit. This step will help you to stay on course, and make the right choices. For example, it‚Äôs ok to use subsets of your data to address different questions.</p></li>
@@ -107,7 +102,7 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-3""><i
 </div>
   <div class=""chapter-nav"">
 <div class=""prev""><a href=""introduction-2.html"">Introduction</a></div>
-<div class=""next""><a href=""covariateschapter.html""><span class=""header-section-number"">2</span> Covariates</a></div>
+<div class=""next""><a href=""references.html"">References</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
       <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#introduction-3"">Introduction</a></li></ul>
@@ -127,7 +122,7 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-3""><i
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-20.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-21.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/introduction-4.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -70,21 +69,21 @@ <h1>
         <ul class=""book-toc list-unstyled"">
 <li><a class="""" href=""index.html"">Welcome</a></li>
 <li><a class="""" href=""preface.html"">Preface</a></li>
-<li class=""book-part"">I. Foundations</li>
+<li class=""book-part"">Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li class=""book-part"">II. Transitions</li>
+<li class=""book-part"">Transitions</li>
 <li><a class=""active"" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Alive and dead</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Sites and states</a></li>
-<li class=""book-part"">III. Case studies</li>
+<li class=""book-part"">Case studies</li>
 <li><a class="""" href=""introduction-7.html"">Introduction</a></li>
 <li><a class="""" href=""covariateschapter.html""><span class=""header-section-number"">6</span> Covariates</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">7</span> Life history</a></li>
 <li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">8</span> Lack of fit</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">9</span> Miscelleanous</a></li>
+<li><a class="""" href=""miscelleanous.html""><span class=""header-section-number"">9</span> Miscelleanous</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
 
@@ -121,7 +120,7 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-4""><i
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-20.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-21.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/introduction-7.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -70,21 +69,21 @@ <h1>
         <ul class=""book-toc list-unstyled"">
 <li><a class="""" href=""index.html"">Welcome</a></li>
 <li><a class="""" href=""preface.html"">Preface</a></li>
-<li class=""book-part"">I. Foundations</li>
+<li class=""book-part"">Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li class=""book-part"">II. Transitions</li>
+<li class=""book-part"">Transitions</li>
 <li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Alive and dead</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Sites and states</a></li>
-<li class=""book-part"">III. Case studies</li>
+<li class=""book-part"">Case studies</li>
 <li><a class=""active"" href=""introduction-7.html"">Introduction</a></li>
 <li><a class="""" href=""covariateschapter.html""><span class=""header-section-number"">6</span> Covariates</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">7</span> Life history</a></li>
 <li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">8</span> Lack of fit</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">9</span> Miscelleanous</a></li>
+<li><a class="""" href=""miscelleanous.html""><span class=""header-section-number"">9</span> Miscelleanous</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
 
@@ -131,7 +130,7 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-7""><i
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-20.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-21.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/introduction.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -70,21 +69,21 @@ <h1>
         <ul class=""book-toc list-unstyled"">
 <li><a class="""" href=""index.html"">Welcome</a></li>
 <li><a class="""" href=""preface.html"">Preface</a></li>
-<li class=""book-part"">I. Foundations</li>
+<li class=""book-part"">Foundations</li>
 <li><a class=""active"" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li class=""book-part"">II. Transitions</li>
+<li class=""book-part"">Transitions</li>
 <li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Alive and dead</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Sites and states</a></li>
-<li class=""book-part"">III. Case studies</li>
+<li class=""book-part"">Case studies</li>
 <li><a class="""" href=""introduction-7.html"">Introduction</a></li>
 <li><a class="""" href=""covariateschapter.html""><span class=""header-section-number"">6</span> Covariates</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">7</span> Life history</a></li>
 <li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">8</span> Lack of fit</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">9</span> Miscelleanous</a></li>
+<li><a class="""" href=""miscelleanous.html""><span class=""header-section-number"">9</span> Miscelleanous</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
 
@@ -121,7 +120,7 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction""><i cl
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-20.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-21.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/lackoffit.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -70,21 +69,21 @@ <h1>
         <ul class=""book-toc list-unstyled"">
 <li><a class="""" href=""index.html"">Welcome</a></li>
 <li><a class="""" href=""preface.html"">Preface</a></li>
-<li class=""book-part"">I. Foundations</li>
+<li class=""book-part"">Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li class=""book-part"">II. Transitions</li>
+<li class=""book-part"">Transitions</li>
 <li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Alive and dead</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Sites and states</a></li>
-<li class=""book-part"">III. Case studies</li>
+<li class=""book-part"">Case studies</li>
 <li><a class="""" href=""introduction-7.html"">Introduction</a></li>
 <li><a class="""" href=""covariateschapter.html""><span class=""header-section-number"">6</span> Covariates</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">7</span> Life history</a></li>
 <li><a class=""active"" href=""lackoffit.html""><span class=""header-section-number"">8</span> Lack of fit</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">9</span> Miscelleanous</a></li>
+<li><a class="""" href=""miscelleanous.html""><span class=""header-section-number"">9</span> Miscelleanous</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
 
@@ -121,8 +120,7 @@ <h2>
 <li><p>captured (1)</p></li>
 </ul>
 <p>Vector of initial state probabilities</p>
-<p><span class=""math display"">\[
-  \begin{matrix}
+<p><span class=""math display"">\[\begin{matrix}
 &amp; \\
 \mathbf{\delta} =
   \left ( \vphantom{ \begin{matrix} 12 \end{matrix} } \right .
@@ -138,12 +136,10 @@ <h2>
           \left . \vphantom{ \begin{matrix} 12 \end{matrix} } \right )
 \begin{matrix}
 \end{matrix}
-\end{matrix}
-\]</span></p>
+\end{matrix}\]</span></p>
 <p><span class=""math inline"">\(\pi\)</span> is the probability of being alive in class 1. <span class=""math inline"">\(1 - \pi\)</span> is the probability of being in class 2.</p>
 <p>Transition matrix</p>
-<p><span class=""math display"">\[
-  \begin{matrix}
+<p><span class=""math display"">\[\begin{matrix}
 &amp; \\
 \mathbf{\Gamma} =
   \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
@@ -162,12 +158,10 @@ <h2>
 \begin{matrix}
 z_{t-1}=A1 \\ z_{t-1}=A2 \\ z_{t-1}=D
 \end{matrix}
-\end{matrix}
-\]</span></p>
+\end{matrix}\]</span></p>
 <p><span class=""math inline"">\(\phi\)</span> is the survival probability, which could be made heterogeneous.</p>
 <p>Transition matrix, with change in heterogeneity class</p>
-<p><span class=""math display"">\[
-  \begin{matrix}
+<p><span class=""math display"">\[\begin{matrix}
 &amp; \\
 \mathbf{\Gamma} =
   \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
@@ -186,12 +180,10 @@ <h2>
 \begin{matrix}
 z_{t-1}=A1 \\ z_{t-1}=A2 \\ z_{t-1}=D
 \end{matrix}
-\end{matrix}
-\]</span></p>
+\end{matrix}\]</span></p>
 <p><span class=""math inline"">\(\psi_{12}\)</span> is the probability for an individual to change class of heterogeneity, from 1 to 2. <span class=""math inline"">\(\psi_{21}\)</span> is the probability for an individual to change class of heterogeneity, from 2 to 1.</p>
 <p>Observation matrix</p>
-<p><span class=""math display"">\[
-  \begin{matrix}
+<p><span class=""math display"">\[\begin{matrix}
 &amp; \\
 \mathbf{\Omega} =
   \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right .
@@ -210,8 +202,7 @@ <h2>
 \begin{matrix}
 z_{t}=A1 \\ z_{t}=A2 \\ z_{t}=D
 \end{matrix}
-\end{matrix}
-\]</span></p>
+\end{matrix}\]</span></p>
 <p><span class=""math inline"">\(p_1\)</span> is detection for individuals in class 1, and <span class=""math inline"">\(p_2\)</span> that of individuals in class 2.</p>
 <p>Results</p>
 <pre><code>##     mean   sd 2.5%  50% 97.5% Rhat n.eff
@@ -220,7 +211,7 @@ <h2>
 ## phi 0.81 0.05 0.71 0.81  0.91 1.04   317
 ## pi  0.62 0.12 0.36 0.63  0.83 1.02   164</code></pre>
 <p>We have lowly detectable individuals (class A1 with <span class=""math inline"">\(p_1\)</span>) in proportion 62%. And highly (or so) detectable individuals (class A2 with <span class=""math inline"">\(p_2\)</span>) in proportion 38%. Note that interpretation of classes is made a posteriori. Survival is 81%.</p>
-<div class=""inline-figure""><img src=""banana-book_files/figure-html/unnamed-chunk-339-1.png"" width=""672""></div>
+<div class=""inline-figure""><img src=""banana-book_files/figure-html/unnamed-chunk-346-1.png"" width=""672""></div>
 <p>You may consider more classes, and select among models, see <span class=""citation"">Cubaynes et al. (<a href=""references.html#ref-cubaynes2012"">2012</a>)</span>. You may also go for a non-parametric approach and let the data tell you how many classes you need. This is relatively easy to do in NIMBLE, see <span class=""citation"">Turek, Wehrhahn, and Gimenez (<a href=""references.html#ref-turek_bayesian_2021"">2021</a>)</span>. More about individual heterogeneity in <span class=""citation"">Gimenez, Cam, and Gaillard (<a href=""references.html#ref-gimenez2018ih"">2018</a>)</span>.</p>
 <!-- I'm not an expert on the BNP facilities offered in NIMBLE, but I think I can comment: the stick-breaking representation (as you're using), and the CRP distribution, are modelling the same Dirichlet process.  They differ in the MCMC sampling algorithms which are applied to each, automatically, by NIMBLE's MCMC.  Translating your code between these two (mathematically identical) representations is a relatively small and straight-forward exercise.  The relative performance of the different sampling algorithms, as applied to each representation, could differ, would depend on the model and the data, and is generally difficult to predict. -->
 <!-- Changing between the stick-breaking representation and the CRP representation, the categorical distribution would persist in your model.  And Perry's comments are correct, that (in particular for a large number of categories, e.g. large values of H or HH in your code) the categorical sampler (which is applied to the categorical distribution) would become arbitrarily inefficient, in that it evaluates the posterior density for every category value (H or HH times), then samples directly from that posterior distribution.  And that you could hopefully reduce this inefficiency by writing a customized sampling strategy (a custom-written MCMC sampler), to update your categorical distributions, in a more efficient (less wasteful) manner. -->
@@ -243,8 +234,7 @@ <h2>
 </h2>
 <p>Multistate treatment as in <span class=""citation"">Schaub et al. (<a href=""references.html#ref-schaub2004te"">2004</a>)</span>. See example in <span class=""citation"">B«éncil«é et al. (<a href=""references.html#ref-bancila2018te"">2018</a>)</span>.</p>
 <p>Transition matrix:</p>
-<p><span class=""math display"">\[
-  \begin{matrix}
+<p><span class=""math display"">\[\begin{matrix}
 &amp; \\
 \mathbf{\Gamma} =
   \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
@@ -263,11 +253,9 @@ <h2>
 \begin{matrix}
 z_{t-1}=\text{in} \\ z_{t-1}=\text{out} \\ z_{t-1}=\text{D}
 \end{matrix}
-\end{matrix}
-\]</span></p>
+\end{matrix}\]</span></p>
 <p>Observation matrix:</p>
-<p><span class=""math display"">\[
-  \begin{matrix}
+<p><span class=""math display"">\[\begin{matrix}
 &amp; \\
 \mathbf{\Omega} =
   \left ( \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right .
@@ -286,8 +274,7 @@ <h2>
 \begin{matrix}
 z_{t}=\text{in} \\ z_{t}=\text{out} \\ z_{t}=\text{D}
 \end{matrix}
-\end{matrix}
-\]</span></p>
+\end{matrix}\]</span></p>
 </div>
 <div id=""memory-model"" class=""section level2"" number=""8.5"">
 <h2>
@@ -298,8 +285,7 @@ <h2>
 <p>Memory models were initially proposed by <span class=""citation"">Hestbeck, Nichols, and Malecki (<a href=""references.html#ref-hestbeck1991estimates"">1991</a>)</span> and <span class=""citation"">Brownie et al. (<a href=""references.html#ref-BrownieEtAl1993"">1993</a>)</span>, then formulated as HMMs in <span class=""citation"">Rouan, Choquet, and Pradel (<a href=""references.html#ref-rouan2009memory"">2009</a>)</span>. See also <span class=""citation"">D. J. Cole et al. (<a href=""references.html#ref-cole2014"">2014</a>)</span>.</p>
 <p>Remember HMM model for dispersal between 2 sites</p>
 <p>Transition matrix</p>
-<p><span class=""math display"">\[
-\begin{matrix}
+<p><span class=""math display"">\[\begin{matrix}
 &amp; \\
 \mathbf{\Gamma} =
 \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
@@ -318,11 +304,9 @@ <h2>
 \begin{matrix}
 z_{t-1}=A \\ z_{t-1}=B \\ z_{t-1}=D
 \end{matrix}
-\end{matrix}
-\]</span></p>
+\end{matrix}\]</span></p>
 <p>Observation matrix</p>
-<p><span class=""math display"">\[
-\begin{matrix}
+<p><span class=""math display"">\[\begin{matrix}
 &amp; \\
 \mathbf{\Omega} =
 \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
@@ -341,8 +325,7 @@ <h2>
 \begin{matrix}
 z_{t}=A \\ z_{t}=B \\ z_{t}=D
 \end{matrix}
-\end{matrix}
-\]</span></p>
+\end{matrix}\]</span></p>
 <p>HMM formulation of the memory model</p>
 <p>To keep track of the sites previously visited, the trick is to consider states as being pairs of sites occupied</p>
 <ul>
@@ -358,8 +341,7 @@ <h2>
 <li><p>2 captured at site B</p></li>
 </ul>
 <p>Vector of initial state probabilities</p>
-<p><span class=""math display"">\[
-\begin{matrix}
+<p><span class=""math display"">\[\begin{matrix}
 &amp; \\
 \mathbf{\delta} =
 \left ( \vphantom{ \begin{matrix} 12 \end{matrix} } \right .
@@ -375,12 +357,10 @@ <h2>
 \left . \vphantom{ \begin{matrix} 12 \end{matrix} } \right )
 \begin{matrix}
 \end{matrix}
-\end{matrix}
-\]</span></p>
+\end{matrix}\]</span></p>
 <p>where <span class=""math inline"">\(\pi_{BB} = 1 - (\pi_{AA} + \pi_{AB} + \pi_{BA})\)</span>, and <span class=""math inline"">\(\pi_{ij}\)</span> at site <span class=""math inline"">\(j\)</span> when first captured at <span class=""math inline"">\(t\)</span> and site <span class=""math inline"">\(i\)</span> at <span class=""math inline"">\(t - 1\)</span>.</p>
 <p>Transition matrix</p>
-<p><span class=""math display"">\[
-\begin{matrix}
+<p><span class=""math display"">\[\begin{matrix}
 &amp; \\
 \mathbf{\Gamma} =
 \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12\end{matrix} } \right .
@@ -401,13 +381,11 @@ <h2>
 \begin{matrix}
 z_t=AA \\ z_t=AB \\ z_t=BA \\ z_t=BB \\ z_t=D
 \end{matrix}
-\end{matrix}
-\]</span></p>
+\end{matrix}\]</span></p>
 <p><span class=""math inline"">\(\phi_{ijk}\)</span> is probability to be in site <span class=""math inline"">\(k\)</span> at time <span class=""math inline"">\(t + 1\)</span> for an individual
 present in site <span class=""math inline"">\(j\)</span> at <span class=""math inline"">\(t\)</span> and in site <span class=""math inline"">\(i\)</span> at <span class=""math inline"">\(t - 1\)</span></p>
 <p>Transition matrix, alternate parameterization</p>
-<p><span class=""math display"">\[
-\begin{matrix}
+<p><span class=""math display"">\[\begin{matrix}
 &amp; \\
 \mathbf{\Gamma} =
 \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12\end{matrix} } \right .
@@ -428,12 +406,10 @@ <h2>
 \begin{matrix}
 z_t=AA \\ z_t=AB \\ z_t=BA \\ z_t=BB \\ z_t=D
 \end{matrix}
-\end{matrix}
-\]</span></p>
+\end{matrix}\]</span></p>
 <p><span class=""math inline"">\(\phi\)</span> is the probability of surviving from one occasion to the next. <span class=""math inline"">\(\psi_{ijj}\)</span> is the probability an animal stays at the same site <span class=""math inline"">\(j\)</span> given that it was at site <span class=""math inline"">\(i\)</span> on the previous occasion.</p>
 <p>Observation matrix</p>
-<p><span class=""math display"">\[
-\begin{matrix}
+<p><span class=""math display"">\[\begin{matrix}
 &amp; \\
 \mathbf{\Omega} =
 \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12\end{matrix} } \right .
@@ -454,14 +430,13 @@ <h2>
 \begin{matrix}
 z_t=AA \\ z_t=AB \\ z_t=BA \\ z_t=BB \\ z_t=D
 \end{matrix}
-\end{matrix}
-\]</span></p>
+\end{matrix}\]</span></p>
 
 </div>
 </div>
   <div class=""chapter-nav"">
 <div class=""prev""><a href=""tradeoffs.html""><span class=""header-section-number"">7</span> Life history</a></div>
-<div class=""next""><a href=""misc.html""><span class=""header-section-number"">9</span> Miscelleanous</a></div>
+<div class=""next""><a href=""miscelleanous.html""><span class=""header-section-number"">9</span> Miscelleanous</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
       <ul class=""nav navbar-nav"">
@@ -488,7 +463,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-20.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-21.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/libs/kePrint-0.0.1/kePrint.js---
@@ -1,8 +0,0 @@
-$(document).ready(function(){
-    if (typeof $('[data-toggle=""tooltip""]').tooltip === 'function') {
-        $('[data-toggle=""tooltip""]').tooltip();
-    }
-    if ($('[data-toggle=""popover""]').popover === 'function') {
-        $('[data-toggle=""popover""]').popover();
-    }
-});

---FILE: docs/libs/lightable-0.0.1/lightable.css---
@@ -1,272 +0,0 @@
-/*!
- * lightable v0.0.1
- * Copyright 2020 Hao Zhu
- * Licensed under MIT (https://github.com/haozhu233/kableExtra/blob/master/LICENSE)
- */
-
-.lightable-minimal {
-  border-collapse: separate;
-  border-spacing: 16px 1px;
-  width: 100%;
-  margin-bottom: 10px;
-}
-
-.lightable-minimal td {
-  margin-left: 5px;
-  margin-right: 5px;
-}
-
-.lightable-minimal th {
-  margin-left: 5px;
-  margin-right: 5px;
-}
-
-.lightable-minimal thead tr:last-child th {
-  border-bottom: 2px solid #00000050;
-  empty-cells: hide;
-
-}
-
-.lightable-minimal tbody tr:first-child td {
-  padding-top: 0.5em;
-}
-
-.lightable-minimal.lightable-hover tbody tr:hover {
-  background-color: #f5f5f5;
-}
-
-.lightable-minimal.lightable-striped tbody tr:nth-child(even) {
-  background-color: #f5f5f5;
-}
-
-.lightable-classic {
-  border-top: 0.16em solid #111111;
-  border-bottom: 0.16em solid #111111;
-  width: 100%;
-  margin-bottom: 10px;
-  margin: 10px 5px;
-}
-
-.lightable-classic tfoot tr td {
-  border: 0;
-}
-
-.lightable-classic tfoot tr:first-child td {
-  border-top: 0.14em solid #111111;
-}
-
-.lightable-classic caption {
-  color: #222222;
-}
-
-.lightable-classic td {
-  padding-left: 5px;
-  padding-right: 5px;
-  color: #222222;
-}
-
-.lightable-classic th {
-  padding-left: 5px;
-  padding-right: 5px;
-  font-weight: normal;
-  color: #222222;
-}
-
-.lightable-classic thead tr:last-child th {
-  border-bottom: 0.10em solid #111111;
-}
-
-.lightable-classic.lightable-hover tbody tr:hover {
-  background-color: #F9EEC1;
-}
-
-.lightable-classic.lightable-striped tbody tr:nth-child(even) {
-  background-color: #f5f5f5;
-}
-
-.lightable-classic-2 {
-  border-top: 3px double #111111;
-  border-bottom: 3px double #111111;
-  width: 100%;
-  margin-bottom: 10px;
-}
-
-.lightable-classic-2 tfoot tr td {
-  border: 0;
-}
-
-.lightable-classic-2 tfoot tr:first-child td {
-  border-top: 3px double #111111;
-}
-
-.lightable-classic-2 caption {
-  color: #222222;
-}
-
-.lightable-classic-2 td {
-  padding-left: 5px;
-  padding-right: 5px;
-  color: #222222;
-}
-
-.lightable-classic-2 th {
-  padding-left: 5px;
-  padding-right: 5px;
-  font-weight: normal;
-  color: #222222;
-}
-
-.lightable-classic-2 tbody tr:last-child td {
-  border-bottom: 3px double #111111;
-}
-
-.lightable-classic-2 thead tr:last-child th {
-  border-bottom: 1px solid #111111;
-}
-
-.lightable-classic-2.lightable-hover tbody tr:hover {
-  background-color: #F9EEC1;
-}
-
-.lightable-classic-2.lightable-striped tbody tr:nth-child(even) {
-  background-color: #f5f5f5;
-}
-
-.lightable-material {
-  min-width: 100%;
-  white-space: nowrap;
-  table-layout: fixed;
-  font-family: Roboto, sans-serif;
-  border: 1px solid #EEE;
-  border-collapse: collapse;
-  margin-bottom: 10px;
-}
-
-.lightable-material tfoot tr td {
-  border: 0;
-}
-
-.lightable-material tfoot tr:first-child td {
-  border-top: 1px solid #EEE;
-}
-
-.lightable-material th {
-  height: 56px;
-  padding-left: 16px;
-  padding-right: 16px;
-}
-
-.lightable-material td {
-  height: 52px;
-  padding-left: 16px;
-  padding-right: 16px;
-  border-top: 1px solid #eeeeee;
-}
-
-.lightable-material.lightable-hover tbody tr:hover {
-  background-color: #f5f5f5;
-}
-
-.lightable-material.lightable-striped tbody tr:nth-child(even) {
-  background-color: #f5f5f5;
-}
-
-.lightable-material.lightable-striped tbody td {
-  border: 0;
-}
-
-.lightable-material.lightable-striped thead tr:last-child th {
-  border-bottom: 1px solid #ddd;
-}
-
-.lightable-material-dark {
-  min-width: 100%;
-  white-space: nowrap;
-  table-layout: fixed;
-  font-family: Roboto, sans-serif;
-  border: 1px solid #FFFFFF12;
-  border-collapse: collapse;
-  margin-bottom: 10px;
-  background-color: #363640;
-}
-
-.lightable-material-dark tfoot tr td {
-  border: 0;
-}
-
-.lightable-material-dark tfoot tr:first-child td {
-  border-top: 1px solid #FFFFFF12;
-}
-
-.lightable-material-dark th {
-  height: 56px;
-  padding-left: 16px;
-  padding-right: 16px;
-  color: #FFFFFF60;
-}
-
-.lightable-material-dark td {
-  height: 52px;
-  padding-left: 16px;
-  padding-right: 16px;
-  color: #FFFFFF;
-  border-top: 1px solid #FFFFFF12;
-}
-
-.lightable-material-dark.lightable-hover tbody tr:hover {
-  background-color: #FFFFFF12;
-}
-
-.lightable-material-dark.lightable-striped tbody tr:nth-child(even) {
-  background-color: #FFFFFF12;
-}
-
-.lightable-material-dark.lightable-striped tbody td {
-  border: 0;
-}
-
-.lightable-material-dark.lightable-striped thead tr:last-child th {
-  border-bottom: 1px solid #FFFFFF12;
-}
-
-.lightable-paper {
-  width: 100%;
-  margin-bottom: 10px;
-  color: #444;
-}
-
-.lightable-paper tfoot tr td {
-  border: 0;
-}
-
-.lightable-paper tfoot tr:first-child td {
-  border-top: 1px solid #00000020;
-}
-
-.lightable-paper thead tr:last-child th {
-  color: #666;
-  vertical-align: bottom;
-  border-bottom: 1px solid #00000020;
-  line-height: 1.15em;
-  padding: 10px 5px;
-}
-
-.lightable-paper td {
-  vertical-align: middle;
-  border-bottom: 1px solid #00000010;
-  line-height: 1.15em;
-  padding: 7px 5px;
-}
-
-.lightable-paper.lightable-hover tbody tr:hover {
-  background-color: #F9EEC1;
-}
-
-.lightable-paper.lightable-striped tbody tr:nth-child(even) {
-  background-color: #00000008;
-}
-
-.lightable-paper.lightable-striped tbody td {
-  border: 0;
-}
-

---FILE: docs/misc.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -70,16 +69,16 @@ <h1>
         <ul class=""book-toc list-unstyled"">
 <li><a class="""" href=""index.html"">Welcome</a></li>
 <li><a class="""" href=""preface.html"">Preface</a></li>
-<li class=""book-part"">I. Foundations</li>
+<li class=""book-part"">Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li class=""book-part"">II. Transitions</li>
+<li class=""book-part"">Transitions</li>
 <li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Alive and dead</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Sites and states</a></li>
-<li class=""book-part"">III. Case studies</li>
+<li class=""book-part"">Case studies</li>
 <li><a class="""" href=""introduction-7.html"">Introduction</a></li>
 <li><a class="""" href=""covariateschapter.html""><span class=""header-section-number"">6</span> Covariates</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">7</span> Life history</a></li>
@@ -118,8 +117,7 @@ <h3>
 </h3>
 <p>Combine live recapture w/ dead recoveries by <span class=""citation"">Lebreton, Almeras, and Pradel (<a href=""references.html#ref-lebreton1999"">1999</a>)</span>.</p>
 <p>Transition matrix</p>
-<p><span class=""math display"">\[
-\begin{matrix}
+<p><span class=""math display"">\[\begin{matrix}
 &amp; \\
 \mathbf{\Gamma} =
   \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
@@ -138,11 +136,9 @@ <h3>
 \begin{matrix}
 z_{t-1}=\text{alive} \\ z_{t-1}=\text{just dead} \\ z_{t-1}=\text{dead for good}
 \end{matrix}
-\end{matrix}
-\]</span></p>
+\end{matrix}\]</span></p>
 <p>Observation matrix</p>
-<p><span class=""math display"">\[
-\begin{matrix}
+<p><span class=""math display"">\[\begin{matrix}
 &amp; \\
 \mathbf{\Omega} =
   \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right .
@@ -161,8 +157,7 @@ <h3>
 \begin{matrix}
 z_{t}=A \\ z_{t}=JD \\ z_{t}=D
 \end{matrix}
-\end{matrix}
-\]</span></p>
+\end{matrix}\]</span></p>
 </div>
 <div id=""cause-specific-mortalities"" class=""section level3"" number=""9.2.3"">
 <h3>
@@ -179,7 +174,7 @@ <h2>
 <p>Let‚Äôs have a look to another example. Very similar to the previous example. We consider a system of an emerging pathogen <em>Mycoplasma gallisepticum</em> Edward and Kanarek and its host the house finch, <em>Carpodacus mexicanus</em> M√ºller.</p>
 <div class=""figure"" style=""text-align: center"">
 <span style=""display:block;"" id=""fig:pixfinch""></span>
-<img src=""images/infectedhousefinch.jpg"" alt=""A house finch with a heavy infection (Jim Mondok)."" width=""640""><p class=""caption"">
+<img src=""images/infectedhousefinch.jpg"" alt=""A house finch with a heavy infection (Jim Mondok)."" width=""100%""><p class=""caption"">
 Figure 9.1: A house finch with a heavy infection (Jim Mondok).
 </p>
 </div>
@@ -203,10 +198,9 @@ <h2>
 </li>
 </ul>
 <p>How states generate observations.</p>
-<div class=""inline-figure""><img src=""banana-book_files/figure-html/unnamed-chunk-342-1.png"" width=""672""></div>
+<div class=""inline-figure""><img src=""banana-book_files/figure-html/unnamed-chunk-349-1.png"" width=""672""></div>
 <p>Vector of initial state probabilities</p>
-<p><span class=""math display"">\[
-\begin{matrix}
+<p><span class=""math display"">\[\begin{matrix}
 &amp; \\
 \mathbf{\delta} =
     \left ( \vphantom{ \begin{matrix} 12 \end{matrix} } \right .
@@ -222,12 +216,10 @@ <h2>
 \left . \vphantom{ \begin{matrix} 12 \end{matrix} } \right )
     \begin{matrix}
     \end{matrix}
-\end{matrix}
-\]</span></p>
+\end{matrix}\]</span></p>
 <p><span class=""math inline"">\(\pi_H\)</span> is the probability that a newly encountered individual is healthy. <span class=""math inline"">\(\pi_{I} = 1 - \pi_H\)</span> is the probability that a newly encountered individual is ill.</p>
 <p>Transition matrix</p>
-<p><span class=""math display"">\[
-\begin{matrix}
+<p><span class=""math display"">\[\begin{matrix}
 &amp; \\
 \mathbf{\Gamma} =
     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
@@ -246,12 +238,10 @@ <h2>
     \begin{matrix}
     z_{t-1}=H \\ z_{t-1}=I \\ z_{t-1}=D
     \end{matrix}
-\end{matrix}
-\]</span></p>
+\end{matrix}\]</span></p>
 <p><span class=""math inline"">\(\phi_H\)</span> is the survival probability of healthy individuals, <span class=""math inline"">\(\phi_I\)</span> that of ill individuals. <span class=""math inline"">\(\psi_{HI}\)</span> is the probability of getting sick, <span class=""math inline"">\(\psi_{IH}\)</span> that of recovering from the disease.</p>
 <p>Transition matrix, incurable disease</p>
-<p><span class=""math display"">\[
-\begin{matrix}
+<p><span class=""math display"">\[\begin{matrix}
 &amp; \\
 \mathbf{\Gamma} =
     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
@@ -270,12 +260,10 @@ <h2>
     \begin{matrix}
     z_{t-1}=H \\ z_{t-1}=I \\ z_{t-1}=D
     \end{matrix}
-\end{matrix}
-\]</span></p>
+\end{matrix}\]</span></p>
 <p>No possibility of recovering from the disease, that is <span class=""math inline"">\(\psi_{IH} = 0\)</span>. Once you get sick, you remain sick <span class=""math inline"">\(\psi_{II} = 1 - \psi_{IH} = 1\)</span>. For analysing the house finch data, we allow recovering from the disease, and we will use transition matrix from previous slide.</p>
 <p>Observation matrix</p>
-<p><span class=""math display"">\[
-\begin{matrix}
+<p><span class=""math display"">\[\begin{matrix}
 &amp; \\
 \mathbf{\Omega} =
     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right .
@@ -294,8 +282,7 @@ <h2>
     \begin{matrix}
     z_{t}=H \\ z_{t}=I \\ z_{t}=D
     \end{matrix}
-\end{matrix}
-\]</span></p>
+\end{matrix}\]</span></p>
 <p><span class=""math inline"">\(\beta_H\)</span> is the probability to assign a healthy individual to state H. <span class=""math inline"">\(\beta_{I}\)</span> is the probability to assign a sick individual to state I. <span class=""math inline"">\(p_H\)</span> is the detection probability of healthy individuals, <span class=""math inline"">\(p_I\)</span> that of sick individuals.</p>
 <p>Results</p>
 <pre><code>##       mean   sd 2.5%  50% 97.5% Rhat n.eff
@@ -309,28 +296,28 @@ <h2>
 ## psiHI 0.22 0.04 0.16 0.22  0.32 1.02   311
 ## psiIH 0.46 0.08 0.32 0.45  0.63 1.02   392</code></pre>
 <p>Healthy individuals are correctly assigned, while infected individuals are difficult to ascertain. Sounds like being infected has an effect on detection and survival. Run models without effects and compare with WAIC for formal testing. Infection rate is 22%, recovery rate is 46%.</p>
-<div class=""inline-figure""><img src=""banana-book_files/figure-html/unnamed-chunk-344-1.png"" width=""672""></div>
+<div class=""inline-figure""><img src=""banana-book_files/figure-html/unnamed-chunk-351-1.png"" width=""672""></div>
 </div>
 <div id=""stopover-duration"" class=""section level2"" number=""9.4"">
 <h2>
 <span class=""header-section-number"">9.4</span> Stopover duration<a class=""anchor"" aria-label=""anchor"" href=""#stopover-duration""><i class=""fas fa-link""></i></a>
 </h2>
 <p><span class=""citation"">Gu√©rin et al. (<a href=""references.html#ref-guerin_advances_2017"">2017</a>)</span></p>
 </div>
-<div id=""why-bayes-incorporate-prior-information"" class=""section level2"" number=""9.5"">
+<div id=""elicitprior"" class=""section level2"" number=""9.5"">
 <h2>
-<span class=""header-section-number"">9.5</span> Why Bayes? Incorporate prior information<a class=""anchor"" aria-label=""anchor"" href=""#why-bayes-incorporate-prior-information""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">9.5</span> Why Bayes? Incorporate prior information<a class=""anchor"" aria-label=""anchor"" href=""#elicitprior""><i class=""fas fa-link""></i></a>
 </h2>
 <p>The example on how to incorporate prior information is in <span class=""citation"">McCarthy and Masters (<a href=""references.html#ref-mccarthy2005"">2005</a>)</span>.</p>
 <p>So far, we have assumed a non-informative prior on survival <span class=""math inline"">\(\text{Beta}(1,1) = \text{Uniform}(0,1)\)</span>. With this prior, mean posterior survival is <span class=""math inline"">\(\phi = 0.56\)</span> with credible interval <span class=""math inline"">\([0.52,0.62]\)</span>. Graphically we may represent the posterior distribution of survival obtained with two chains with different colors, and our prior in gray dashed line:</p>
-<div class=""inline-figure""><img src=""banana-book_files/figure-html/unnamed-chunk-345-1.png"" width=""672""></div>
+<div class=""inline-figure""><img src=""banana-book_files/figure-html/unnamed-chunk-352-1.png"" width=""672""></div>
 <div id=""prior-elicitation"" class=""section level3"" number=""9.5.1"">
 <h3>
 <span class=""header-section-number"">9.5.1</span> Prior elicitation<a class=""anchor"" aria-label=""anchor"" href=""#prior-elicitation""><i class=""fas fa-link""></i></a>
 </h3>
 <p>The thing is that we know a lot about passerines and it is a shame not to be able to use this information and act as if we have to start from scratch and know nothing. We illustrate how to incorporate prior information by acknowledging that species with similar body masses have similar survival. By gathering information on several other European passerines than the dipper, let‚Äôs assume we have built a regression of survival vs.¬†body mass ‚Äì allometric relationship. Knowing dippers weigh on average 59.8g, we‚Äôre now in the position to build a prior for dipper survival probability by predicting its value using the regression. We obtain a predicted survival of 0.57 and a standard deviation of 0.075. Using an informative prior <span class=""math inline"">\(\text{Normal}(0.57, sd = 0.073)\)</span> in NIMBLE, we get a mean posterior of <span class=""math inline"">\(0.56\)</span> with credible interval <span class=""math inline"">\([0.52, 0.61]\)</span>. There‚Äôs barely no difference with the non-informative prior, quite a disappointment.</p>
 <p>Now let‚Äôs assume that we had only the three first years of data, what would have happened? We fit the model with constant parameters with both the non-informative and informative priors to the dataset from which we delete the final 4 years of data. Now the benefit of using the prior information becomes clear as the credible interval when prior information is ignored has a width of 0.53, which is more than twice as much as when prior information is used (0.24), illustrating the increased precision provided by the prior. We may assess visually this gain in precision by comparing the survival posterior distributions with and without informative prior:</p>
-<div class=""inline-figure""><img src=""banana-book_files/figure-html/unnamed-chunk-346-1.png"" width=""672""></div>
+<div class=""inline-figure""><img src=""banana-book_files/figure-html/unnamed-chunk-353-1.png"" width=""672""></div>
 <p>In brief, if the aim is to get an estimate of survival, Gilbert did not have to conduct further data collection after 3 years, and he could have reached the same precision as with 7 years of data by using prior information derived from body mass. In brief, the prior information was worth 4 years of field data. Of course, this is assuming that the ecological question remains the same whether you have 3 or 7 years of data, which is unlikely to be the case, as with long-term data, there is so much we can ask, more than ‚Äújust‚Äù what annual survival probability is.</p>
 </div>
 <div id=""moment-matching"" class=""section level3"" number=""9.5.2"">
@@ -343,7 +330,7 @@ <h3>
 <span class=""math display"">\[\alpha = \bigg(\frac{1-\mu}{\sigma^2}- \frac{1}{\mu} \bigg)\mu^2\]</span>
 <span class=""math display"">\[\beta = \alpha \bigg(\frac{1}{\mu}-1\bigg)\]</span>
 For our model, that means:</p>
-<div class=""sourceCode"" id=""cb288""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb309""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""op"">(</span><span class=""va"">alpha</span> <span class=""op"">&lt;-</span> <span class=""op"">(</span> <span class=""op"">(</span><span class=""fl"">1</span> <span class=""op"">-</span> <span class=""fl"">0.57</span><span class=""op"">)</span><span class=""op"">/</span><span class=""op"">(</span><span class=""fl"">0.073</span><span class=""op"">*</span><span class=""fl"">0.073</span><span class=""op"">)</span> <span class=""op"">-</span> <span class=""op"">(</span><span class=""fl"">1</span><span class=""op"">/</span><span class=""fl"">0.57</span><span class=""op"">)</span> <span class=""op"">)</span><span class=""op"">*</span><span class=""fl"">0.57</span><span class=""op"">^</span><span class=""fl"">2</span><span class=""op"">)</span></span>
 <span><span class=""co"">## [1] 25.65</span></span>
 <span><span class=""op"">(</span><span class=""va"">beta</span> <span class=""op"">&lt;-</span> <span class=""va"">alpha</span> <span class=""op"">*</span> <span class=""op"">(</span> <span class=""op"">(</span><span class=""fl"">1</span><span class=""op"">/</span><span class=""fl"">0.57</span><span class=""op"">)</span> <span class=""op"">-</span> <span class=""fl"">1</span><span class=""op"">)</span><span class=""op"">)</span></span>
@@ -385,7 +372,7 @@ <h2>
 <li><a class=""nav-link"" href=""#disease-dynamics""><span class=""header-section-number"">9.3</span> Disease dynamics</a></li>
 <li><a class=""nav-link"" href=""#stopover-duration""><span class=""header-section-number"">9.4</span> Stopover duration</a></li>
 <li>
-<a class=""nav-link"" href=""#why-bayes-incorporate-prior-information""><span class=""header-section-number"">9.5</span> Why Bayes? Incorporate prior information</a><ul class=""nav navbar-nav"">
+<a class=""nav-link"" href=""#elicitprior""><span class=""header-section-number"">9.5</span> Why Bayes? Incorporate prior information</a><ul class=""nav navbar-nav"">
 <li><a class=""nav-link"" href=""#prior-elicitation""><span class=""header-section-number"">9.5.1</span> Prior elicitation</a></li>
 <li><a class=""nav-link"" href=""#moment-matching""><span class=""header-section-number"">9.5.2</span> Moment matching</a></li>
 </ul>
@@ -409,7 +396,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-20.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-21.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/miscelleanous.html---
@@ -0,0 +1,437 @@
+<!DOCTYPE html>
+<html lang=""en"">
+<head>
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>Chapter 9 Miscelleanous | Bayesian analysis of capture-recapture data with hidden Markov models</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""9.1 Dependence among individuals Culina et al. (2013) and Cubaynes et al. (2021)  9.2 Using data on dead recoveries  9.2.1 Ring recovery simple model   9.2.2 Combination of live captures and dead..."">
+<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
+<meta property=""og:title"" content=""Chapter 9 Miscelleanous | Bayesian analysis of capture-recapture data with hidden Markov models"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/banana-book/miscelleanous.html"">
+<meta property=""og:description"" content=""9.1 Dependence among individuals Culina et al. (2013) and Cubaynes et al. (2021)  9.2 Using data on dead recoveries  9.2.1 Ring recovery simple model   9.2.2 Combination of live captures and dead..."">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""Chapter 9 Miscelleanous | Bayesian analysis of capture-recapture data with hidden Markov models"">
+<meta name=""twitter:description"" content=""9.1 Dependence among individuals Culina et al. (2013) and Cubaynes et al. (2021)  9.2 Using data on dead recoveries  9.2.1 Ring recovery simple model   9.2.2 Combination of live captures and dead..."">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+    
+    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
+  </style>
+<style type=""text/css"">
+    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
+    div.csl-bib-body { }
+    div.csl-entry {
+      clear: both;
+        }
+    .hanging div.csl-entry {
+      margin-left:2em;
+      text-indent:-2em;
+    }
+    div.csl-left-margin {
+      min-width:2em;
+      float:left;
+    }
+    div.csl-right-inline {
+      margin-left:2em;
+      padding-left:1em;
+    }
+    div.csl-indent {
+      margin-left: 2em;
+    }
+  </style>
+<link rel=""stylesheet"" href=""bs4_style.css"">
+</head>
+<body data-spy=""scroll"" data-target=""#toc"">
+
+<div class=""container-fluid"">
+<div class=""row"">
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+
+    <div class=""d-flex align-items-start justify-content-between"">
+      <h1>
+        <a href=""index.html"" title=""Theory and case studies in R and NIMBLE"">Bayesian analysis of capture-recapture data with hidden Markov models</a>:
+        <small class=""text-muted"">Theory and case studies in R and NIMBLE</small>
+      </h1>
+      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
+    </div>
+
+    <div id=""main-nav"" class=""collapse-lg"">
+      <form role=""search"">
+        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
+</form>
+
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li class=""book-part"">Foundations</li>
+<li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
+<li class=""book-part"">Transitions</li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Alive and dead</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Sites and states</a></li>
+<li class=""book-part"">Case studies</li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li><a class="""" href=""covariateschapter.html""><span class=""header-section-number"">6</span> Covariates</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">7</span> Life history</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">8</span> Lack of fit</a></li>
+<li><a class=""active"" href=""miscelleanous.html""><span class=""header-section-number"">9</span> Miscelleanous</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
+
+        <div class=""book-extra"">
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
+        </div>
+      </nav>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""miscelleanous"" class=""section level1"" number=""9"">
+<h1>
+<span class=""header-section-number"">9</span> Miscelleanous<a class=""anchor"" aria-label=""anchor"" href=""#miscelleanous""><i class=""fas fa-link""></i></a>
+</h1>
+<div id=""dependence-among-individuals"" class=""section level2"" number=""9.1"">
+<h2>
+<span class=""header-section-number"">9.1</span> Dependence among individuals<a class=""anchor"" aria-label=""anchor"" href=""#dependence-among-individuals""><i class=""fas fa-link""></i></a>
+</h2>
+<p><span class=""citation"">Culina et al. (<a href=""references.html#ref-culina_multievent_2013"">2013</a>)</span> and <span class=""citation"">Cubaynes et al. (<a href=""references.html#ref-cubaynes_modeling_2021"">2021</a>)</span></p>
+</div>
+<div id=""using-data-on-dead-recoveries"" class=""section level2"" number=""9.2"">
+<h2>
+<span class=""header-section-number"">9.2</span> Using data on dead recoveries<a class=""anchor"" aria-label=""anchor"" href=""#using-data-on-dead-recoveries""><i class=""fas fa-link""></i></a>
+</h2>
+<div id=""ring-recovery-simple-model"" class=""section level3"" number=""9.2.1"">
+<h3>
+<span class=""header-section-number"">9.2.1</span> Ring recovery simple model<a class=""anchor"" aria-label=""anchor"" href=""#ring-recovery-simple-model""><i class=""fas fa-link""></i></a>
+</h3>
+</div>
+<div id=""combination-of-live-captures-and-dead-recoveries"" class=""section level3"" number=""9.2.2"">
+<h3>
+<span class=""header-section-number"">9.2.2</span> Combination of live captures and dead recoveries<a class=""anchor"" aria-label=""anchor"" href=""#combination-of-live-captures-and-dead-recoveries""><i class=""fas fa-link""></i></a>
+</h3>
+<p>Combine live recapture w/ dead recoveries by <span class=""citation"">Lebreton, Almeras, and Pradel (<a href=""references.html#ref-lebreton1999"">1999</a>)</span>.</p>
+<p>Transition matrix</p>
+<p><span class=""math display"">\[\begin{matrix}
+&amp; \\
+\mathbf{\Gamma} =
+  \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
+          \end{matrix}
+          \hspace{-1.2em}
+          \begin{matrix}
+          z_t=A &amp; z_t=JD &amp; z_t=D \\ \hdashline
+          s &amp; 1-s &amp; 0\\
+          0 &amp; 0 &amp; 1\\
+          0 &amp; 0 &amp; 1
+          \end{matrix}
+          \hspace{-0.2em}
+          \begin{matrix}
+          &amp; \\
+          \left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
+\begin{matrix}
+z_{t-1}=\text{alive} \\ z_{t-1}=\text{just dead} \\ z_{t-1}=\text{dead for good}
+\end{matrix}
+\end{matrix}\]</span></p>
+<p>Observation matrix</p>
+<p><span class=""math display"">\[\begin{matrix}
+&amp; \\
+\mathbf{\Omega} =
+  \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right .
+          \end{matrix}
+          \hspace{-1.2em}
+          \begin{matrix}
+          y_t=0 &amp; y_t=1 &amp; y_t=2 \\ \hdashline
+          1 - p &amp; 0 &amp; p\\
+          1 - r &amp; r &amp; 0\\
+          1 &amp; 0 &amp; 0
+          \end{matrix}
+          \hspace{-0.2em}
+          \begin{matrix}
+          &amp; \\
+          \left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
+\begin{matrix}
+z_{t}=A \\ z_{t}=JD \\ z_{t}=D
+\end{matrix}
+\end{matrix}\]</span></p>
+</div>
+<div id=""cause-specific-mortalities"" class=""section level3"" number=""9.2.3"">
+<h3>
+<span class=""header-section-number"">9.2.3</span> Cause-specific mortalities<a class=""anchor"" aria-label=""anchor"" href=""#cause-specific-mortalities""><i class=""fas fa-link""></i></a>
+</h3>
+<p><span class=""citation"">Koons et al. (<a href=""references.html#ref-koons2014"">2014</a>)</span>, <span class=""citation"">Fern√°ndez-Chac√≥n et al. (<a href=""references.html#ref-fernandez-chacon_causes_2016"">2016</a>)</span> and <span class=""citation"">Ruette et al. (<a href=""references.html#ref-ruette_comparative_2015"">2015</a>)</span></p>
+</div>
+</div>
+<div id=""disease-dynamics"" class=""section level2"" number=""9.3"">
+<h2>
+<span class=""header-section-number"">9.3</span> Disease dynamics<a class=""anchor"" aria-label=""anchor"" href=""#disease-dynamics""><i class=""fas fa-link""></i></a>
+</h2>
+<p><span class=""citation"">Conn and Cooch (<a href=""references.html#ref-ConnCooch2009"">2009</a>)</span>, <span class=""citation"">Cooch et al. (<a href=""references.html#ref-cooch2012disease"">2012</a>)</span>, <span class=""citation"">Marescot et al. (<a href=""references.html#ref-MarescotEtAl2018"">2018</a>)</span> and <span class=""citation"">Santoro et al. (<a href=""references.html#ref-santoro2014host"">2014</a>)</span>.</p>
+<p>Let‚Äôs have a look to another example. Very similar to the previous example. We consider a system of an emerging pathogen <em>Mycoplasma gallisepticum</em> Edward and Kanarek and its host the house finch, <em>Carpodacus mexicanus</em> M√ºller.</p>
+<div class=""figure"" style=""text-align: center"">
+<span style=""display:block;"" id=""fig:pixfinch""></span>
+<img src=""images/infectedhousefinch.jpg"" alt=""A house finch with a heavy infection (Jim Mondok)."" width=""100%""><p class=""caption"">
+Figure 9.1: A house finch with a heavy infection (Jim Mondok).
+</p>
+</div>
+<p>We consider a system of an emerging pathogen <em>Mycoplasma gallisepticum</em> Edward and Kanarek and its host the house finch, <em>Carpodacus mexicanus</em> M√ºller. <span class=""citation"">Faustino et al. (<a href=""references.html#ref-FaustinoEtAl2004"">2004</a>)</span> and <span class=""citation"">Conn and Cooch (<a href=""references.html#ref-ConnCooch2009"">2009</a>)</span> studied impact of pathogen on host demographic rates (see also <span class=""citation"">Cooch et al. (<a href=""references.html#ref-cooch2012disease"">2012</a>)</span>). Problem is true disease state for some encountered individuals is ambiguous because seen at distance. In this context, how to study the dynamics of the disease?</p>
+<p>States and observations</p>
+<ul>
+<li>3 states
+<ul>
+<li>healthy (H)</li>
+<li>ill (I)</li>
+<li>dead (D)</li>
+</ul>
+</li>
+<li>4 observations
+<ul>
+<li>not seen (0)</li>
+<li>captured healthy (1)</li>
+<li>captured ill (2)</li>
+<li>health status unknown, i.e.¬†seen at distance (3)</li>
+</ul>
+</li>
+</ul>
+<p>How states generate observations.</p>
+<div class=""inline-figure""><img src=""banana-book_files/figure-html/unnamed-chunk-349-1.png"" width=""672""></div>
+<p>Vector of initial state probabilities</p>
+<p><span class=""math display"">\[\begin{matrix}
+&amp; \\
+\mathbf{\delta} =
+    \left ( \vphantom{ \begin{matrix} 12 \end{matrix} } \right .
+\end{matrix}
+\hspace{-1.2em}
+\begin{matrix}
+    z_t=H &amp; z_t=I &amp; z_t=D \\ \hdashline
+\pi_H &amp; 1 - \pi_{H} &amp; 0\\
+\end{matrix}
+\hspace{-0.2em}
+\begin{matrix}
+&amp; \\
+\left . \vphantom{ \begin{matrix} 12 \end{matrix} } \right )
+    \begin{matrix}
+    \end{matrix}
+\end{matrix}\]</span></p>
+<p><span class=""math inline"">\(\pi_H\)</span> is the probability that a newly encountered individual is healthy. <span class=""math inline"">\(\pi_{I} = 1 - \pi_H\)</span> is the probability that a newly encountered individual is ill.</p>
+<p>Transition matrix</p>
+<p><span class=""math display"">\[\begin{matrix}
+&amp; \\
+\mathbf{\Gamma} =
+    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
+\end{matrix}
+\hspace{-1.2em}
+\begin{matrix}
+    z_t=H &amp; z_t=I &amp; z_t=D \\ \hdashline
+\phi_H (1-\psi_{HI}) &amp; \phi_H \psi_{HI} &amp; 1 - \phi_H\\
+\phi_{I} \psi_{IH} &amp; \phi_{I} (1-\psi_{IH}) &amp; 1 - \phi_{I}\\
+0 &amp; 0 &amp; 1
+\end{matrix}
+\hspace{-0.2em}
+\begin{matrix}
+&amp; \\
+\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
+    \begin{matrix}
+    z_{t-1}=H \\ z_{t-1}=I \\ z_{t-1}=D
+    \end{matrix}
+\end{matrix}\]</span></p>
+<p><span class=""math inline"">\(\phi_H\)</span> is the survival probability of healthy individuals, <span class=""math inline"">\(\phi_I\)</span> that of ill individuals. <span class=""math inline"">\(\psi_{HI}\)</span> is the probability of getting sick, <span class=""math inline"">\(\psi_{IH}\)</span> that of recovering from the disease.</p>
+<p>Transition matrix, incurable disease</p>
+<p><span class=""math display"">\[\begin{matrix}
+&amp; \\
+\mathbf{\Gamma} =
+    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
+\end{matrix}
+\hspace{-1.2em}
+\begin{matrix}
+    z_t=H &amp; z_t=I &amp; z_t=D \\ \hdashline
+\phi_H (1-\psi_{HI}) &amp; \phi_H \psi_{HI} &amp; 1 - \phi_H\\
+0 &amp; \phi_{I}  &amp; 1 - \phi_{I}\\
+0 &amp; 0 &amp; 1
+\end{matrix}
+\hspace{-0.2em}
+\begin{matrix}
+&amp; \\
+\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
+    \begin{matrix}
+    z_{t-1}=H \\ z_{t-1}=I \\ z_{t-1}=D
+    \end{matrix}
+\end{matrix}\]</span></p>
+<p>No possibility of recovering from the disease, that is <span class=""math inline"">\(\psi_{IH} = 0\)</span>. Once you get sick, you remain sick <span class=""math inline"">\(\psi_{II} = 1 - \psi_{IH} = 1\)</span>. For analysing the house finch data, we allow recovering from the disease, and we will use transition matrix from previous slide.</p>
+<p>Observation matrix</p>
+<p><span class=""math display"">\[\begin{matrix}
+&amp; \\
+\mathbf{\Omega} =
+    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right .
+\end{matrix}
+\hspace{-1.2em}
+\begin{matrix}
+    y_t=0 &amp; y_t=1 &amp; y_t=2 &amp; y_t=3\\ \hdashline
+1-p_H &amp; p_H \beta_H &amp; 0 &amp; p_H (1-\beta_H)\\
+1-p_I &amp; 0 &amp; p_{I} \beta_{I} &amp; p_{I} (1-\beta_{I})\\
+1 &amp; 0 &amp; 0 &amp; 0
+\end{matrix}
+\hspace{-0.2em}
+\begin{matrix}
+&amp; \\
+\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right )
+    \begin{matrix}
+    z_{t}=H \\ z_{t}=I \\ z_{t}=D
+    \end{matrix}
+\end{matrix}\]</span></p>
+<p><span class=""math inline"">\(\beta_H\)</span> is the probability to assign a healthy individual to state H. <span class=""math inline"">\(\beta_{I}\)</span> is the probability to assign a sick individual to state I. <span class=""math inline"">\(p_H\)</span> is the detection probability of healthy individuals, <span class=""math inline"">\(p_I\)</span> that of sick individuals.</p>
+<p>Results</p>
+<pre><code>##       mean   sd 2.5%  50% 97.5% Rhat n.eff
+## betaH 0.99 0.01 0.97 0.99  1.00 1.01  1421
+## betaI 0.05 0.01 0.03 0.05  0.08 1.00  6477
+## pH    0.17 0.02 0.13 0.17  0.22 1.01   331
+## pI    0.58 0.10 0.41 0.57  0.80 1.04   220
+## phiH  0.88 0.02 0.84 0.88  0.92 1.01   360
+## phiI  0.99 0.01 0.96 0.99  1.00 1.00  1004
+## pi    0.96 0.01 0.93 0.96  0.98 1.00  4190
+## psiHI 0.22 0.04 0.16 0.22  0.32 1.02   311
+## psiIH 0.46 0.08 0.32 0.45  0.63 1.02   392</code></pre>
+<p>Healthy individuals are correctly assigned, while infected individuals are difficult to ascertain. Sounds like being infected has an effect on detection and survival. Run models without effects and compare with WAIC for formal testing. Infection rate is 22%, recovery rate is 46%.</p>
+<div class=""inline-figure""><img src=""banana-book_files/figure-html/unnamed-chunk-351-1.png"" width=""672""></div>
+</div>
+<div id=""stopover-duration"" class=""section level2"" number=""9.4"">
+<h2>
+<span class=""header-section-number"">9.4</span> Stopover duration<a class=""anchor"" aria-label=""anchor"" href=""#stopover-duration""><i class=""fas fa-link""></i></a>
+</h2>
+<p><span class=""citation"">Gu√©rin et al. (<a href=""references.html#ref-guerin_advances_2017"">2017</a>)</span></p>
+</div>
+<div id=""elicitprior"" class=""section level2"" number=""9.5"">
+<h2>
+<span class=""header-section-number"">9.5</span> Why Bayes? Incorporate prior information<a class=""anchor"" aria-label=""anchor"" href=""#elicitprior""><i class=""fas fa-link""></i></a>
+</h2>
+<p>The example on how to incorporate prior information is in <span class=""citation"">McCarthy and Masters (<a href=""references.html#ref-mccarthy2005"">2005</a>)</span>.</p>
+<p>So far, we have assumed a non-informative prior on survival <span class=""math inline"">\(\text{Beta}(1,1) = \text{Uniform}(0,1)\)</span>. With this prior, mean posterior survival is <span class=""math inline"">\(\phi = 0.56\)</span> with credible interval <span class=""math inline"">\([0.52,0.62]\)</span>. Graphically we may represent the posterior distribution of survival obtained with two chains with different colors, and our prior in gray dashed line:</p>
+<div class=""inline-figure""><img src=""banana-book_files/figure-html/unnamed-chunk-352-1.png"" width=""672""></div>
+<div id=""prior-elicitation"" class=""section level3"" number=""9.5.1"">
+<h3>
+<span class=""header-section-number"">9.5.1</span> Prior elicitation<a class=""anchor"" aria-label=""anchor"" href=""#prior-elicitation""><i class=""fas fa-link""></i></a>
+</h3>
+<p>The thing is that we know a lot about passerines and it is a shame not to be able to use this information and act as if we have to start from scratch and know nothing. We illustrate how to incorporate prior information by acknowledging that species with similar body masses have similar survival. By gathering information on several other European passerines than the dipper, let‚Äôs assume we have built a regression of survival vs.¬†body mass ‚Äì allometric relationship. Knowing dippers weigh on average 59.8g, we‚Äôre now in the position to build a prior for dipper survival probability by predicting its value using the regression. We obtain a predicted survival of 0.57 and a standard deviation of 0.075. Using an informative prior <span class=""math inline"">\(\text{Normal}(0.57, sd = 0.073)\)</span> in NIMBLE, we get a mean posterior of <span class=""math inline"">\(0.56\)</span> with credible interval <span class=""math inline"">\([0.52, 0.61]\)</span>. There‚Äôs barely no difference with the non-informative prior, quite a disappointment.</p>
+<p>Now let‚Äôs assume that we had only the three first years of data, what would have happened? We fit the model with constant parameters with both the non-informative and informative priors to the dataset from which we delete the final 4 years of data. Now the benefit of using the prior information becomes clear as the credible interval when prior information is ignored has a width of 0.53, which is more than twice as much as when prior information is used (0.24), illustrating the increased precision provided by the prior. We may assess visually this gain in precision by comparing the survival posterior distributions with and without informative prior:</p>
+<div class=""inline-figure""><img src=""banana-book_files/figure-html/unnamed-chunk-353-1.png"" width=""672""></div>
+<p>In brief, if the aim is to get an estimate of survival, Gilbert did not have to conduct further data collection after 3 years, and he could have reached the same precision as with 7 years of data by using prior information derived from body mass. In brief, the prior information was worth 4 years of field data. Of course, this is assuming that the ecological question remains the same whether you have 3 or 7 years of data, which is unlikely to be the case, as with long-term data, there is so much we can ask, more than ‚Äújust‚Äù what annual survival probability is.</p>
+</div>
+<div id=""moment-matching"" class=""section level3"" number=""9.5.2"">
+<h3>
+<span class=""header-section-number"">9.5.2</span> Moment matching<a class=""anchor"" aria-label=""anchor"" href=""#moment-matching""><i class=""fas fa-link""></i></a>
+</h3>
+<p>The prior <span class=""math inline"">\(\text{Normal}(0.57, sd = 0.073)\)</span> is not entirely satisfying because it is not constrained to be positive or less than one, which is the minimum for a probability (of survival) to be well defined. In our specific example, the prior distribution is centered on positive values far from 0, and the sandard deviation is small enough so that the chances to get values smaller than 0 or higher than 1 are null (to convince yourself, <code>hist(rnorm(1000, mean = 0.57, sd = 0.073))</code>). Can we do better? The answer is yes.</p>
+<p>Remember the Beta distribution? Recall that the Beta distribution is a continuous distribution with values between 0 and 1. It is therefore convenient to specify priors for survival and detection probabilities. Plus we know everything about the Beta distribution, in particular its moments. If <span class=""math inline"">\(X \sim Beta(\alpha,\beta)\)</span>, then the first (mean) and second moments (variance) of <span class=""math inline"">\(X\)</span> are <span class=""math inline"">\(\mu = \text{E}(X) = \frac{\alpha}{\alpha + \beta}\)</span> and <span class=""math inline"">\(\sigma^2 = \text{Var}(X) = \frac{\alpha\beta}{(\alpha + \beta)^2 (\alpha + \beta + 1)}\)</span>.</p>
+<p>In the capture-recapture example, we know a priori that the mean of the probability we‚Äôre interested in is <span class=""math inline"">\(\mu = 0.57\)</span> and its variance is <span class=""math inline"">\(\sigma^2 = 0.073^2\)</span>. Parameters <span class=""math inline"">\(\mu\)</span> and <span class=""math inline"">\(\sigma^2\)</span> are seen as the moments of a <span class=""math inline"">\(Beta(\alpha,\beta)\)</span> distribution. Now we look for values of <span class=""math inline"">\(\alpha\)</span> and <span class=""math inline"">\(\beta\)</span> that match the observed moments of the Beta distribution <span class=""math inline"">\(\mu\)</span> and <span class=""math inline"">\(\sigma^2\)</span>. We need another set of equations:
+<span class=""math display"">\[\alpha = \bigg(\frac{1-\mu}{\sigma^2}- \frac{1}{\mu} \bigg)\mu^2\]</span>
+<span class=""math display"">\[\beta = \alpha \bigg(\frac{1}{\mu}-1\bigg)\]</span>
+For our model, that means:</p>
+<div class=""sourceCode"" id=""cb309""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""op"">(</span><span class=""va"">alpha</span> <span class=""op"">&lt;-</span> <span class=""op"">(</span> <span class=""op"">(</span><span class=""fl"">1</span> <span class=""op"">-</span> <span class=""fl"">0.57</span><span class=""op"">)</span><span class=""op"">/</span><span class=""op"">(</span><span class=""fl"">0.073</span><span class=""op"">*</span><span class=""fl"">0.073</span><span class=""op"">)</span> <span class=""op"">-</span> <span class=""op"">(</span><span class=""fl"">1</span><span class=""op"">/</span><span class=""fl"">0.57</span><span class=""op"">)</span> <span class=""op"">)</span><span class=""op"">*</span><span class=""fl"">0.57</span><span class=""op"">^</span><span class=""fl"">2</span><span class=""op"">)</span></span>
+<span><span class=""co"">## [1] 25.65</span></span>
+<span><span class=""op"">(</span><span class=""va"">beta</span> <span class=""op"">&lt;-</span> <span class=""va"">alpha</span> <span class=""op"">*</span> <span class=""op"">(</span> <span class=""op"">(</span><span class=""fl"">1</span><span class=""op"">/</span><span class=""fl"">0.57</span><span class=""op"">)</span> <span class=""op"">-</span> <span class=""fl"">1</span><span class=""op"">)</span><span class=""op"">)</span></span>
+<span><span class=""co"">## [1] 19.35</span></span></code></pre></div>
+<p>Now we simply have to use <span class=""math inline"">\(\text{Beta}(\alpha = 25.6,\beta = 19.3)\)</span> as a prior instead of our <span class=""math inline"">\(\text{Normal}(0.57, sd = 0.073)\)</span>.</p>
+</div>
+</div>
+<div id=""posterior-predictive-check"" class=""section level2"" number=""9.6"">
+<h2>
+<span class=""header-section-number"">9.6</span> Posterior predictive check<a class=""anchor"" aria-label=""anchor"" href=""#posterior-predictive-check""><i class=""fas fa-link""></i></a>
+</h2>
+<p>Classical m-array (minimal sufficient statistics for CJS model) as in <span class=""citation"">Paganin and de Valpine (<a href=""references.html#ref-paganin2023computational"">2023</a>)</span>. Individual performance in <span class=""citation"">Chambert, Rotella, and Higgs (<a href=""references.html#ref-chambert2014"">2014</a>)</span> and <span class=""citation"">Nater et al. (<a href=""references.html#ref-nater2020trout"">2020</a>)</span>. Sojourn time is geometric assumption in <span class=""citation"">Conn et al. (<a href=""references.html#ref-conn2018"">2018</a>)</span>.</p>
+<!-- This has an m-array structure. The number of individuals released at occasion $i$ ($R_i$) and the number of first recaptures at occasion $j$, given release at occasion $i$ ($m_{ij}$) are provided. For example, 38 birds were released in 1969 among which, 22 were first recaptured in 1970, and 16 (= 38 - 22) were never observed again. -->
+<p>Check out <a href=""https://r-nimble.org/nimbleExamples/posterior_predictive.html"" class=""uri"">https://r-nimble.org/nimbleExamples/posterior_predictive.html</a>.</p>
+</div>
+<div id=""others"" class=""section level2"" number=""9.7"">
+<h2>
+<span class=""header-section-number"">9.7</span> Others<a class=""anchor"" aria-label=""anchor"" href=""#others""><i class=""fas fa-link""></i></a>
+</h2>
+<p>Multispecies? Phylogeny? Social networks? Path analysis? Structural Equation Modelling? Prevalence estimation with hybrid (<span class=""citation"">Santostasi et al. (<a href=""references.html#ref-SantostasiEtAl2019"">2019</a>)</span>) or sex-ratio (<span class=""citation"">Pradel et al. (<a href=""references.html#ref-pradel2008sex"">2008</a>)</span>) example.</p>
+
+</div>
+</div>
+  <div class=""chapter-nav"">
+<div class=""prev""><a href=""lackoffit.html""><span class=""header-section-number"">8</span> Lack of fit</a></div>
+<div class=""next""><a href=""references.html"">References</a></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
+      <ul class=""nav navbar-nav"">
+<li><a class=""nav-link"" href=""#miscelleanous""><span class=""header-section-number"">9</span> Miscelleanous</a></li>
+<li><a class=""nav-link"" href=""#dependence-among-individuals""><span class=""header-section-number"">9.1</span> Dependence among individuals</a></li>
+<li>
+<a class=""nav-link"" href=""#using-data-on-dead-recoveries""><span class=""header-section-number"">9.2</span> Using data on dead recoveries</a><ul class=""nav navbar-nav"">
+<li><a class=""nav-link"" href=""#ring-recovery-simple-model""><span class=""header-section-number"">9.2.1</span> Ring recovery simple model</a></li>
+<li><a class=""nav-link"" href=""#combination-of-live-captures-and-dead-recoveries""><span class=""header-section-number"">9.2.2</span> Combination of live captures and dead recoveries</a></li>
+<li><a class=""nav-link"" href=""#cause-specific-mortalities""><span class=""header-section-number"">9.2.3</span> Cause-specific mortalities</a></li>
+</ul>
+</li>
+<li><a class=""nav-link"" href=""#disease-dynamics""><span class=""header-section-number"">9.3</span> Disease dynamics</a></li>
+<li><a class=""nav-link"" href=""#stopover-duration""><span class=""header-section-number"">9.4</span> Stopover duration</a></li>
+<li>
+<a class=""nav-link"" href=""#elicitprior""><span class=""header-section-number"">9.5</span> Why Bayes? Incorporate prior information</a><ul class=""nav navbar-nav"">
+<li><a class=""nav-link"" href=""#prior-elicitation""><span class=""header-section-number"">9.5.1</span> Prior elicitation</a></li>
+<li><a class=""nav-link"" href=""#moment-matching""><span class=""header-section-number"">9.5.2</span> Moment matching</a></li>
+</ul>
+</li>
+<li><a class=""nav-link"" href=""#posterior-predictive-check""><span class=""header-section-number"">9.6</span> Posterior predictive check</a></li>
+<li><a class=""nav-link"" href=""#others""><span class=""header-section-number"">9.7</span> Others</a></li>
+</ul>
+
+      <div class=""book-extra"">
+        <ul class=""list-unstyled"">
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/miscelleanous.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/miscelleanous.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+        </ul>
+</div>
+    </nav>
+</div>
+
+</div>
+</div> <!-- .container -->
+
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-21.</p>
+  </div>
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
+  </div>
+
+</div></div>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
+</body>
+</html>

---FILE: docs/preface.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -70,21 +69,21 @@ <h1>
         <ul class=""book-toc list-unstyled"">
 <li><a class="""" href=""index.html"">Welcome</a></li>
 <li><a class=""active"" href=""preface.html"">Preface</a></li>
-<li class=""book-part"">I. Foundations</li>
+<li class=""book-part"">Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li class=""book-part"">II. Transitions</li>
+<li class=""book-part"">Transitions</li>
 <li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Alive and dead</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Sites and states</a></li>
-<li class=""book-part"">III. Case studies</li>
+<li class=""book-part"">Case studies</li>
 <li><a class="""" href=""introduction-7.html"">Introduction</a></li>
 <li><a class="""" href=""covariateschapter.html""><span class=""header-section-number"">6</span> Covariates</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">7</span> Life history</a></li>
 <li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">8</span> Lack of fit</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">9</span> Miscelleanous</a></li>
+<li><a class="""" href=""miscelleanous.html""><span class=""header-section-number"">9</span> Miscelleanous</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
 
@@ -126,10 +125,11 @@ <h2>Prerequisites<a class=""anchor"" aria-label=""anchor"" href=""#prerequisites""><i
 <p>This book uses primarily the R package NIMBLE, so you need to install at least R and NIMBLE. A bunch of other R packages are used. You can install them all at once by running:</p>
 <div class=""sourceCode"" id=""cb1""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""fu""><a href=""https://rdrr.io/r/utils/install.packages.html"">install.packages</a></span><span class=""op"">(</span><span class=""fu""><a href=""https://rdrr.io/r/base/c.html"">c</a></span><span class=""op"">(</span></span>
-<span>  <span class=""st"">""bookdown""</span>, <span class=""st"">""ggtern""</span>, <span class=""st"">""gtools""</span>, <span class=""st"">""here""</span>, <span class=""st"">""janitor""</span>, </span>
-<span>  <span class=""st"">""magick""</span>, <span class=""st"">""MCMCvis""</span>, <span class=""st"">""nimble""</span>, <span class=""st"">""nimbleEcology""</span>, </span>
-<span>  <span class=""st"">""patchwork""</span>, <span class=""st"">""pdftools""</span>, <span class=""st"">""RColorBrewer""</span>, </span>
-<span>  <span class=""st"">""sessioninfo""</span>, <span class=""st"">""tidyverse""</span>, <span class=""st"">""wesanderson""</span> </span>
+<span>  <span class=""st"">""bookdown""</span>, <span class=""st"">""coda""</span>, <span class=""st"">""forecast""</span>, <span class=""st"">""ggtern""</span>, <span class=""st"">""gtools""</span>, </span>
+<span>  <span class=""st"">""here""</span>, <span class=""st"">""janitor""</span>, <span class=""st"">""magick""</span>, <span class=""st"">""MCMCvis""</span>, <span class=""st"">""nimble""</span>, </span>
+<span>  <span class=""st"">""nimbleEcology""</span>, <span class=""st"">""patchwork""</span>, <span class=""st"">""pdftools""</span>, </span>
+<span>  <span class=""st"">""RColorBrewer""</span>, <span class=""st"">""sessioninfo""</span>, <span class=""st"">""tidyverse""</span>, </span>
+<span>  <span class=""st"">""wesanderson""</span> </span>
 <span><span class=""op"">)</span><span class=""op"">)</span></span></code></pre></div>
 </div>
 <div id=""how-this-book-was-written"" class=""section level2 unnumbered"">
@@ -150,6 +150,16 @@ <h2>How this book was written<a class=""anchor"" aria-label=""anchor"" href=""#how-th
 <td align=""left"">CRAN (R 4.2.0)</td>
 </tr>
 <tr class=""even"">
+<td align=""left"">coda</td>
+<td align=""left"">0.19-4</td>
+<td align=""left"">CRAN (R 4.2.0)</td>
+</tr>
+<tr class=""odd"">
+<td align=""left"">forecast</td>
+<td align=""left"">8.21</td>
+<td align=""left"">CRAN (R 4.2.0)</td>
+</tr>
+<tr class=""even"">
 <td align=""left"">ggtern</td>
 <td align=""left"">3.4.1</td>
 <td align=""left"">CRAN (R 4.2.0)</td>
@@ -293,7 +303,7 @@ <h2>Acknowledgements<a class=""anchor"" aria-label=""anchor"" href=""#acknowledgement
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-20.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-21.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/reference-keys.txt---
@@ -1,21 +1,8 @@
 fig:revbayes
-fig:bayestheorem
-fig:binlik
-fig:numapprox
 fig:betadistribution
-fig:compar
 fig:mcmcpaper
-fig:chain
-fig:twochains
-fig:longchain
-fig:animlongchain
-fig:burnin
-fig:bgr
-fig:tracechainlength
-fig:acfchainlength
 fig:nimblelogo
 fig:dag-survival
-fig:traceown
 fig:treillis-viterbi
 fig:viterbiaveragecompute
 fig:viterbicomputeaverage
@@ -84,11 +71,9 @@ marginalization
 brute-force-approach
 forward-algorithm
 nimble-implementation-1
-do-it-yourself
+diymarginalisation
 do-it-with-nimbleecology
 pooled-likelihood
-do-it-yourself-1
-do-it-with-nimbleecology-1
 decoding
 viterbi-theory
 implementation
@@ -149,6 +134,7 @@ actuarial-senescence
 covariate-on-multinomial-logit-link-or-dirichlet
 uncertainty-in-age
 spatial
+misc
 tradeoffs
 access-to-reproduction
 tradeoffs-1
@@ -159,15 +145,15 @@ trap-dep
 transience
 temporary-emigration
 memory-model
-misc
+miscelleanous
 dependence-among-individuals
 using-data-on-dead-recoveries
 ring-recovery-simple-model
 combination-of-live-captures-and-dead-recoveries
 cause-specific-mortalities
 disease-dynamics
 stopover-duration
-why-bayes-incorporate-prior-information
+elicitprior
 prior-elicitation
 moment-matching
 posterior-predictive-check

---FILE: docs/references.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -70,21 +69,21 @@ <h1>
         <ul class=""book-toc list-unstyled"">
 <li><a class="""" href=""index.html"">Welcome</a></li>
 <li><a class="""" href=""preface.html"">Preface</a></li>
-<li class=""book-part"">I. Foundations</li>
+<li class=""book-part"">Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li class=""book-part"">II. Transitions</li>
+<li class=""book-part"">Transitions</li>
 <li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Alive and dead</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Sites and states</a></li>
-<li class=""book-part"">III. Case studies</li>
+<li class=""book-part"">Case studies</li>
 <li><a class="""" href=""introduction-7.html"">Introduction</a></li>
 <li><a class="""" href=""covariateschapter.html""><span class=""header-section-number"">6</span> Covariates</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">7</span> Life history</a></li>
 <li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">8</span> Lack of fit</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">9</span> Miscelleanous</a></li>
+<li><a class="""" href=""miscelleanous.html""><span class=""header-section-number"">9</span> Miscelleanous</a></li>
 <li><a class=""active"" href=""references.html"">References</a></li>
 </ul>
 
@@ -149,6 +148,9 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 <div id=""ref-cooch2017intromark"" class=""csl-entry"">
 Cooch, E. G., and G. White. 2017. <em>Progam MARK: A Gentle Introduction</em>. 13th edition. <a href=""http://www.phidot.org/software/mark/docs/book/"">http://www.phidot.org/software/mark/docs/book/</a>.
 </div>
+<div id=""ref-cook1967expectancy"" class=""csl-entry"">
+Cook, L. M. M, L. P. Brower, and H. J. Croze. 1967. <span>‚ÄúThe Accuracy of a Population Estimation from Multiple Recapture Data.‚Äù</span> <em>Journal of Animal Ecology</em> 36 (1): 57‚Äì60.
+</div>
 <div id=""ref-cruz-flores_sex-specific_nodate"" class=""csl-entry"">
 Cruz-Flores, M., R. Pradel, J. Bried, J. Gonz√°lez-Sol√≠s, and R. Ramos. n.d. <span>‚ÄúSex-Specific Costs of Reproduction on Survival in a Long-Lived Seabird.‚Äù</span> <em>Biology Letters</em> 17 (3): 2021.
 </div>
@@ -182,9 +184,15 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 <div id=""ref-fernandez-chacon_causes_2016"" class=""csl-entry"">
 Fern√°ndez-Chac√≥n, A., E. Moland, S. H. Espeland, A. R. Kleiven, and E. M. Olsen. 2016. <span>‚ÄúCauses of Mortality in Depleted Populations of <span>Atlantic</span> Cod Estimated from Multi‚ÄìEvent Modelling of Mark‚Äì-Recapture and Recovery Data.‚Äù</span> <em>Canadian Journal of Fisheries and Aquatic Sciences</em> 74 (1): 116‚Äì26.
 </div>
+<div id=""ref-fernandez2016ggmcmc"" class=""csl-entry"">
+Fern√°ndez-i-Marƒ±ÃÅn, X. 2016. <span>‚ÄúGgmcmc: Analysis of MCMC Samples and Bayesian Inference.‚Äù</span> <em>Journal of Statistical Software</em> 70 (9): 1‚Äì20.
+</div>
 <div id=""ref-frederiksen2014"" class=""csl-entry"">
 Frederiksen, M., J.-D. Lebreton, R. Pradel, R. Choquet, and O. Gimenez. 2014. <span>‚ÄúIdentifying Links Between Vital Rates and Environment: <span>A</span> Toolbox for the Applied Ecologist.‚Äù</span> <em>Journal of Applied Ecology</em> 51 (1): 71‚Äì81.
 </div>
+<div id=""ref-gabry2022bayesplot"" class=""csl-entry"">
+Gabry, J., and T. Mahr. 2022. <span>‚ÄúBayesplot: Plotting for Bayesian Models.‚Äù</span> <a href=""https://mc-stan.org/bayesplot/"">https://mc-stan.org/bayesplot/</a>.
+</div>
 <div id=""ref-gelmanhill2006"" class=""csl-entry"">
 Gelman, A., and J. Hill. 2006. <em>Data Analysis Using Regression and Multilevel/Hierarchical Models.</em> Cambridge University Press.
 </div>
@@ -230,6 +238,9 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 <div id=""ref-gimenez2007"" class=""csl-entry"">
 Gimenez, O., V. Rossi, R. Choquet, C. Dehais, B. Doris, H. Varella, J.-P. Vila, and R. Pradel. 2007. <span>‚ÄúState-Space Modelling of Data on Marked Individuals.‚Äù</span> <em>Ecological Modelling</em> 206 (3): 431‚Äì38.
 </div>
+<div id=""ref-goldstein2019nimbleecology"" class=""csl-entry"">
+Goldstein, B. R., D. Turek, L. Ponisio, and P. de Valpine. 2021. <span>‚Äú<span class=""nocase"">nimbleEcology</span>: Distributions for Ecological Models in ‚ÄôNimble‚Äô.‚Äù</span> <a href=""https://CRAN.R-project.org/package=nimbleEcology"">https://CRAN.R-project.org/package=nimbleEcology</a>.
+</div>
 <div id=""ref-grosbois_assessing_2008"" class=""csl-entry"">
 Grosbois, V., O. Gimenez, J. M. Gaillard, R. Pradel, C. Barbraud, J. Clobert, A. P. M√∏ller, and H. Weimerskirch. 2008. <span>‚ÄúAssessing the Impact of Climate Variation on Survival in Vertebrate Populations.‚Äù</span> <em>Biological Reviews</em> 83 (3): 357‚Äì99.
 </div>
@@ -266,6 +277,9 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 <div id=""ref-LebretonEtAl2009"" class=""csl-entry"">
 Lebreton, J.-D., J. D. Nichols, R. J. Barker, R. Pradel, and J. A. Spendelow. 2009. <span>‚ÄúModeling Individual Animal Histories with Multistate Capture‚ÄìRecapture Models.‚Äù</span> <em>Advances in Ecological Research</em> 41: 87‚Äì173.
 </div>
+<div id=""ref-link2012thinning"" class=""csl-entry"">
+Link, W. A., and M. J. Eaton. 2012. <span>‚ÄúOn Thinning of Chains in MCMC.‚Äù</span> <em>Methods in Ecology and Evolution</em> 3 (1): 112‚Äì15.
+</div>
 <div id=""ref-MarescotEtAl2018"" class=""csl-entry"">
 Marescot, L., S. Benhaiem, O. Gimenez, H. Hofer, J.-D. Lebreton, X. A. Olarte-Castillo, S. Kramer-Schadt, and M. L. East. 2018. <span>‚ÄúSocial Status Mediates the Fitness Costs of Infection with Canine Distemper Virus in <span>Serengeti</span> Spotted Hyenas.‚Äù</span> <em>Functional Ecology</em> 32 (5): 1237‚Äì50.
 </div>
@@ -311,6 +325,9 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 <div id=""ref-peron_evidence_2016"" class=""csl-entry"">
 P√©ron, G., J.-M. Gaillard, C. Barbraud, C. Bonenfant, A. Charmantier, R. Choquet, T. Coulson, et al. 2016. <span>‚ÄúEvidence of Reduced Individual Heterogeneity in Adult Survival of Long-Lived Species.‚Äù</span> <em>Evolution</em> 70 (12): 2909‚Äì14.
 </div>
+<div id=""ref-ponisio2020customizing"" class=""csl-entry"">
+Ponisio, L. C., P. de Valpine, N. Michaud, and D. Turek. 2020. <span>‚ÄúOne Size Does Not Fit All: Customizing MCMC Methods for Hierarchical Models Using NIMBLE.‚Äù</span> <em>Ecology and Evolution</em> 10 (5): 2385‚Äì2416.
+</div>
 <div id=""ref-pradel_multievent_2005"" class=""csl-entry"">
 Pradel, R. 2005. <span>‚ÄúMultievent: <span>An</span> <span>Extension</span> of <span>Multistate</span> <span>Capture</span>‚Äì<span>Recapture</span> <span>Models</span> to <span>Uncertain</span> <span>States</span>.‚Äù</span> <em>Biometrics</em> 61 (2): 442‚Äì47.
 </div>
@@ -332,6 +349,12 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 <div id=""ref-Rabiner1989"" class=""csl-entry"">
 Rabiner, L. R. 1989. <span>‚ÄúA Tutorial on Hidden <span>M</span>arkov Models and Selected Applications in Speech Recognition.‚Äù</span> <em>Proceedings of the IEEE</em> 77 (2): 257‚Äì86.
 </div>
+<div id=""ref-robert2004montecarlo"" class=""csl-entry"">
+Robert, C. P., and G. Casella. 2004. <em>Monte Carlo Statistical Methods</em>. 2nd edition. <span>Springer</span>.
+</div>
+<div id=""ref-robert2004montecarloinr"" class=""csl-entry"">
+‚Äî‚Äî‚Äî. 2010. <em>Introducing Monte Carlo Methods with r</em>. <span>Springer</span>.
+</div>
 <div id=""ref-rose2018"" class=""csl-entry"">
 Rose, J. P., G. D. Wylie, M. L. Casazza, and B. J. Halstead. 2018. <span>‚ÄúIntegrating Growth and Capture‚ÄìMark‚ÄìRecapture Models Reveals Size-Dependent Survival in an Elusive Species.‚Äù</span> <em>Ecosphere</em> 9 (8): e02384.
 </div>
@@ -374,6 +397,12 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 <div id=""ref-shefferson_life_2003"" class=""csl-entry"">
 Shefferson, R. P., J. Proper, S. R. Beissinger, and E. L. Simms. 2003. <span>‚ÄúLife <span>History</span> <span>Trade</span>-<span>Offs</span> in a <span>Rare</span> <span>Orchid</span>: <span>The</span> <span>Costs</span> of <span>Flowering</span>, <span>Dormancy</span>, and <span>Sprouting</span>.‚Äù</span> <em>Ecology</em> 84 (5): 1199‚Äì1206.
 </div>
+<div id=""ref-turek2022basicmcmcplots"" class=""csl-entry"">
+Turek, D. 2022. <span>‚ÄúbasicMCMCplots: Trace Plots, Density Plots and Chain Comparisons for MCMC Samples.‚Äù</span> <a href=""https://mc-stan.org/bayesplot/"">https://mc-stan.org/bayesplot/</a>.
+</div>
+<div id=""ref-TurekEtAl2016"" class=""csl-entry"">
+Turek, D., P. de Valpine, and C. J. Paciorek. 2016. <span>‚ÄúEfficient <span class=""nocase"">Markov chain Monte Carlo</span> Sampling for Hierarchical Hidden <span>M</span>arkov Models.‚Äù</span> <em>Environmental and Ecological Statistics</em> 23 (4): 549‚Äì64.
+</div>
 <div id=""ref-turek_bayesian_2021"" class=""csl-entry"">
 Turek, D., C. Wehrhahn, and O. Gimenez. 2021. <span>‚ÄúBayesian Non-Parametric Detection Heterogeneity in Ecological Models.‚Äù</span> <em>Environmental and Ecological Statistics</em>.
 </div>
@@ -383,6 +412,9 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 <div id=""ref-worthington2015"" class=""csl-entry"">
 Worthington, H., R. King, and S. T. Buckland. 2015. <span>‚ÄúAnalysing Mark‚ÄìRecapture‚ÄìRecovery Data in the Presence of Missing Covariate Data via Multiple Imputation.‚Äù</span> <em>Journal of Agricultural, Biological, and Environmental Statistics</em> 20 (1): 28‚Äì46.
 </div>
+<div id=""ref-youngflesh2018mcmcvis"" class=""csl-entry"">
+Youngflesh, C. 2018. <span>‚Äú<span>MCMCvis</span>: Tools to Visualize, Manipulate, and Summarize MCMC Output.‚Äù</span> <em>Journal of Open Source Software</em> 3 (24): 640.
+</div>
 <div id=""ref-ZucchiniEtAl2016"" class=""csl-entry"">
 Zucchini, W., I. L. MacDonald, and R. Langrock. 2016. <em>Hidden <span>M</span>arkov Models for Time Series: <span>A</span>n Introduction Using <span>R</span></em>. 2nd edition. <span>Chapman and Hall/CRC</span>.
 </div>
@@ -394,37 +426,8 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 
 
 
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
   <div class=""chapter-nav"">
-<div class=""prev""><a href=""misc.html""><span class=""header-section-number"">9</span> Miscelleanous</a></div>
+<div class=""prev""><a href=""miscelleanous.html""><span class=""header-section-number"">9</span> Miscelleanous</a></div>
 <div class=""empty""></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
@@ -445,7 +448,7 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-20.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-21.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/tradeoffs.html---
@@ -6,20 +6,19 @@
 <meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <title>Chapter 7 Life history | Bayesian analysis of capture-recapture data with hidden Markov models</title>
 <meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""7.1 Access to reproduction Pradel et al. (1997) Transition matrix: \[ \begin{matrix} &amp; \\ \mathbf{\Gamma} =  \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12 \end{matrix} } \right .   ..."">
+<meta name=""description"" content=""7.1 Access to reproduction Pradel et al. (1997) Transition matrix: \[\begin{matrix} &amp; \\ \mathbf{\Gamma} =  \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12 \end{matrix} } \right .    ..."">
 <meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
 <meta property=""og:title"" content=""Chapter 7 Life history | Bayesian analysis of capture-recapture data with hidden Markov models"">
 <meta property=""og:type"" content=""book"">
 <meta property=""og:url"" content=""https://oliviergimenez.github.io/banana-book/tradeoffs.html"">
-<meta property=""og:description"" content=""7.1 Access to reproduction Pradel et al. (1997) Transition matrix: \[ \begin{matrix} &amp; \\ \mathbf{\Gamma} =  \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12 \end{matrix} } \right .   ..."">
+<meta property=""og:description"" content=""7.1 Access to reproduction Pradel et al. (1997) Transition matrix: \[\begin{matrix} &amp; \\ \mathbf{\Gamma} =  \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12 \end{matrix} } \right .    ..."">
 <meta name=""twitter:card"" content=""summary"">
 <meta name=""twitter:title"" content=""Chapter 7 Life history | Bayesian analysis of capture-recapture data with hidden Markov models"">
-<meta name=""twitter:description"" content=""7.1 Access to reproduction Pradel et al. (1997) Transition matrix: \[ \begin{matrix} &amp; \\ \mathbf{\Gamma} =  \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12 \end{matrix} } \right .   ..."">
+<meta name=""twitter:description"" content=""7.1 Access to reproduction Pradel et al. (1997) Transition matrix: \[\begin{matrix} &amp; \\ \mathbf{\Gamma} =  \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12 \end{matrix} } \right .    ..."">
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -70,21 +69,21 @@ <h1>
         <ul class=""book-toc list-unstyled"">
 <li><a class="""" href=""index.html"">Welcome</a></li>
 <li><a class="""" href=""preface.html"">Preface</a></li>
-<li class=""book-part"">I. Foundations</li>
+<li class=""book-part"">Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li class=""book-part"">II. Transitions</li>
+<li class=""book-part"">Transitions</li>
 <li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Alive and dead</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Sites and states</a></li>
-<li class=""book-part"">III. Case studies</li>
+<li class=""book-part"">Case studies</li>
 <li><a class="""" href=""introduction-7.html"">Introduction</a></li>
 <li><a class="""" href=""covariateschapter.html""><span class=""header-section-number"">6</span> Covariates</a></li>
 <li><a class=""active"" href=""tradeoffs.html""><span class=""header-section-number"">7</span> Life history</a></li>
 <li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">8</span> Lack of fit</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">9</span> Miscelleanous</a></li>
+<li><a class="""" href=""miscelleanous.html""><span class=""header-section-number"">9</span> Miscelleanous</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
 
@@ -103,8 +102,7 @@ <h2>
 </h2>
 <p><span class=""citation"">Pradel et al. (<a href=""references.html#ref-pradel1997"">1997</a>)</span></p>
 <p>Transition matrix:</p>
-<p><span class=""math display"">\[
-\begin{matrix}
+<p><span class=""math display"">\[\begin{matrix}
 &amp; \\
 \mathbf{\Gamma} =
   \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12 \end{matrix} } \right .
@@ -125,12 +123,10 @@ <h2>
 \begin{matrix}
 z_{t-1} = J \\ z_{t-1} = 1yNB \\ z_{t-1} = 2yNB \\ z_{t-1} = B \\ z_{t-1} = D
 \end{matrix}
-\end{matrix}
-\]</span></p>
+\end{matrix}\]</span></p>
 <p>First-year and second-year individuals breed with probabilities <span class=""math inline"">\(\alpha_1\)</span> and <span class=""math inline"">\(\alpha_2\)</span>. Then, everybody breeds from age 3.</p>
 <p>Observation matrix:</p>
-<p><span class=""math display"">\[
-\begin{matrix}
+<p><span class=""math display"">\[\begin{matrix}
 &amp; \\
 \mathbf{\Omega} =
   \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\12 \end{matrix} } \right .
@@ -151,9 +147,8 @@ <h2>
 \begin{matrix}
 z_t = J \\ z_t = 1yNB \\ z_t = 2yNB \\ z_t = B \\ z_t = D
 \end{matrix}
-\end{matrix}
-\]</span>
-Juveniles are never detected.</p>
+\end{matrix}\]</span></p>
+<p>Juveniles are never detected.</p>
 </div>
 <div id=""tradeoffs-1"" class=""section level2"" number=""7.2"">
 <h2>
@@ -196,7 +191,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-20.</p>
+    <p>""<strong>Bayesian analysis of capture-recapture data with hidden Markov models</strong>: Theory and case studies in R and NIMBLE"" was written by Olivier Gimenez. It was last built on 2023-08-21.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: hmm.Rmd---
@@ -6,7 +6,7 @@ In this third chapter, you will learn the basics on Markov models and how to fit
 
 ## Longitudinal data
 
-Let's get back to our survival example, and denote $z_i$ the state of individual $i$ with $z_i = 1$ if alive and $z_i = 0$ if dead. We have a total of $z = \displaystyle{\sum_{i=1}^{n}{z_i}}$ survivors out of $n$ released animals with winter survival probability $\phi$. Our model so far is a combination of a binomial likelihood and a Beta prior with parameters 1 and 1, which is also a uniform distribution between 0 and 1. It can be written as^[I write models the way Richard McElreath does it in his book and video lectures [Statistical Rethinking](https://xcelab.net/rm/statistical-rethinking/).]:
+Let's get back to our survival example, and denote $z_i$ the state of individual $i$ with $z_i = 1$ if alive and $z_i = 0$ if dead. We have a total of $z = \displaystyle{\sum_{i=1}^{n}{z_i}}$ survivors out of $n$ released animals with winter survival probability $\phi$. Our model so far is a combination of a binomial likelihood and a Beta prior with parameters 1 and 1, which is also a uniform distribution between 0 and 1. It can be written as:
 
 \begin{align*}
    z &\sim \text{Binomial}(n, \phi) &\text{[likelihood]}
@@ -50,16 +50,16 @@ for (i in 1:nind){
 colnames(z) <- paste0(""winter "", 1:nocc)
 z %>%
   as_tibble() %>%
-  add_column(id = 1:nind, .before = ""winter 1"") %>%
-  kableExtra::kable() %>%
-  kableExtra::scroll_box(width = ""100%"", height = ""400px"")
+  add_column(id = 1:nind, .before = ""winter 1"") #%>%
+#  kableExtra::kable() %>%
+#  kableExtra::scroll_box(width = ""100%"", height = ""400px"")
 #  kableExtra::kable_styling(font_size = 8,
 #                            latex_options = ""scale_down"")
 ```
 
 ## A Markov model for longitudinal data
 
-Let's think of a model for these data. The objective remains the same, estimating survival. To build this model, we'll make assumptions, go through its components and write down its likelihood. Note that we already encountered Markov models in Section \@ref(markovmodelmcmc).
+Let's think of a model for these data. The objective remains the same, estimating survival. To build this model, we'll make assumptions, go through its components and write down its likelihood. Note that we have already encountered Markov models in Section \@ref(markovmodelmcmc).
 
 ### Assumptions
 
@@ -127,8 +127,9 @@ We can gather these probabilities of transition between states from one occasion
 
 To try and remember that the states at $t-1$ are in rows, and the states at $t$ are in columns, I will often write:
 
-$$
-\begin{matrix}
+
+
+$$\begin{matrix}
 & \\
 \mathbf{\Gamma} =
     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right .
@@ -146,8 +147,9 @@ $$
     \begin{matrix}
     z_{t-1}=1 \; \mbox{(alive)} \\ z_{t-1}=2 \; \mbox{(dead)}
     \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
+
+
 
 Take the time you need to navigate through this matrix, and get familiar with it. For example, you may start alive at $t$ (first row) then end up dead at $t+1$ (first column) with probability $1-\phi$.
 
@@ -247,12 +249,12 @@ The probability of having the sequence alive, alive and dead is the probability
 
 ## Bayesian formulation
 
-Before implementing this model in NIMBLE, we provide a Bayesian formulation of our model. We first note that the likelihood is a product of conditional probabilities of binary events (alive or dead). Usually binary events are associated with the Bernoulli distribution. Here however,  we will use its extension to several outcomes (from a coin with two sides to a dice with more than two faces) known as the categorical distribution^[The categorical distribution is a multinomial distribution with a single draw.]. To get a better idea of how the categorical distribution works, let's simulate from it with the `rcat()` function. Consider for example a random value drawn from a categorical distribution with probability 0.1, 0.3 and 0.6. Think of a dice with three faces, face 1 has probability 0.1 of occurring, face 2 probability 0.3 and face 3 has probability 0.6, the sum of these probabilities being 1. We expect to get a 3 more often than a 2 and rarely a 1^[Alternatively, you can use the `sample()` function and `sample(x = 1:3, size = 1, replace = FALSE, prob = c(0.1, 0.3, 0.6))`]: 
+Before implementing this model in NIMBLE, we provide a Bayesian formulation of our model. We first note that the likelihood is a product of conditional probabilities of binary events (alive or dead). Usually binary events are associated with the Bernoulli distribution. Here however,  we will use its extension to several outcomes (from a coin with two sides to a dice with more than two faces) known as the categorical distribution. The categorical distribution is a multinomial distribution with a single draw. To get a better idea of how the categorical distribution works, let's simulate from it with the `rcat()` function. Consider for example a random value drawn from a categorical distribution with probability 0.1, 0.3 and 0.6. Think of a dice with three faces, face 1 has probability 0.1 of occurring, face 2 probability 0.3 and face 3 has probability 0.6, the sum of these probabilities being 1. We expect to get a 3 more often than a 2 and rarely a 1: 
 ```{r}
 rcat(n = 1, prob = c(0.1, 0.3, 0.6))
 ```
 
-Here is another example in which we sample 20 times in a categorical distribution with probabilities 0.1, 0.1, 0.4, 0.2 and 0.2, hence a dice with 5 faces:
+Alternatively, you can use the `sample()` function and `sample(x = 1:3, size = 1, replace = FALSE, prob = c(0.1, 0.3, 0.6))`. Here is another example in which we sample 20 times in a categorical distribution with probabilities 0.1, 0.1, 0.4, 0.2 and 0.2, hence a dice with 5 faces:
 ```{r}
 rcat(n = 20, prob = c(0.1, 0.1, 0.4, 0.2, 0.2))
 ```
@@ -455,38 +457,35 @@ for (i in 1:nind){
 head(z) 
 ```
 
-We could replace `dcat()` by `dbern()` everywhere in the code because we have binary events alive/dead. Would it make any difference? Although `dcat()` uses less efficient samplers than `dbern()` (**check w/ Perry/Daniel**), `dcat()` is convenient for model building to accomodate more than two outcomes, a feature that will become handy in the next chapters. 
+We could replace `dcat()` by `dbern()` everywhere in the code because we have binary events alive/dead. Would it make any difference? Although `dcat()` uses less efficient samplers than `dbern()`, `dcat()` is convenient for model building to accomodate more than two outcomes, a feature that will become handy in the next chapters. 
 
 ## Hidden Markov models
 
 ### Capture-recapture data {#capturerecapturedata}
 
-```{block2 hmm-verbal, type='rmdnote', eval = FALSE}
-Unfortunately, the data with alive and dead states is the data we wish we had. In real life, animals cannot be monitored exhaustively, like humans in a medical trial. This is why we use capture-recapture protocols^[Have a look to this enjoyable video on the basics principles of capture-recapture experiments <https://www.youtube.com/embed/tyX79mPm2xY>.], in which animals are captured, individually marked, and released alive. Then, these animals may be detected again, or go undetected. Whenever animals go undetected, it might be that they were alive but missed, or because they were dead and therefore could not be detected. This issue is usually referred to as that of imperfect detection. As a consequence of imperfect detection, the Markov process for survival is only partially observed: You know an animal is alive when you detect it, but when an animal goes undetected, whether it is alive or dead is unknown to you. This is where hidden Markov models (HMMs) come in.
-```
+
+:::: {.blackbox data-latex=""""}
+Unfortunately, the data with alive and dead states is the data we wish we had. In real life, animals cannot be monitored exhaustively, like humans in a medical trial. This is why we use capture-recapture protocols, in which animals are captured, individually marked, and released alive. Then, these animals may be detected again, or go undetected. Whenever animals go undetected, it might be that they were alive but missed, or because they were dead and therefore could not be detected. This issue is usually referred to as that of imperfect detection. As a consequence of imperfect detection, the Markov process for survival is only partially observed: You know an animal is alive when you detect it, but when an animal goes undetected, whether it is alive or dead is unknown to you. This is where hidden Markov models (HMMs) come in.
+::::
 
 Let's get back to the data we had in the previous section. The truth is in $z$ which contains the fate of all individuals with $z = 1$ for alive, and $z = 2$ for dead:
 
 ```{r echo = FALSE}
 colnames(z) <- paste0(""winter "", 1:nocc)
 z %>%
   as_tibble() %>%
-  add_column(id = 1:nind, .before = ""winter 1"") %>%
-  kableExtra::kable() %>%
-  kableExtra::scroll_box(width = ""100%"", height = ""300px"")
+  add_column(id = 1:nind, .before = ""winter 1"")
 ```
 
 Unfortunately, we have only partial access to $z$. What we do observe is $y$ the detections and non-detections. How are $z$ and $y$ connected?
 
-The easiest connection is with dead animals which go undetected for sure. Therefore when an animal is dead i.e. $z = 2$, it cannot be detected, therefore $y = 0$: **why not use 1 for non-detected and 2 for detected from here, and mention somewhere that usually people use 0 and 1?**
+The easiest connection is with dead animals which go undetected for sure. Therefore when an animal is dead i.e. $z = 2$, it cannot be detected, therefore $y = 0$:
 
 ```{r echo = FALSE}
 z %>%
   as_tibble() %>%
   replace(. == 2, 0) %>%
-  add_column(id = 1:nind, .before = ""winter 1"") %>%
-  kableExtra::kable() %>%
-  kableExtra::scroll_box(width = ""100%"", height = ""300px"")
+  add_column(id = 1:nind, .before = ""winter 1"")
 ```
 
 Now alive animals may be detected or not. If an animal is alive $z = 1$, it is detected $y = 1$ with probability $p$ or not $y = 0$ with probability $1-p$. In our example, first detection coincides with first winter for all individuals. 
@@ -524,18 +523,16 @@ nobs <- sum(apply(y,1,sum) != 0)
 y <- y[apply(y,1,sum) !=0, ] # remove rows w/ non-detections only
 y %>%
  as_tibble() %>%
- add_column(id = 1:nobs, .before = ""winter 1"") %>%
- kableExtra::kable() %>%
- kableExtra::scroll_box(width = ""100%"", height = ""300px"")
+ add_column(id = 1:nobs, .before = ""winter 1"")
 ```
 
-Compare with previous table. Some 1's for alive have become 0's for non-detection, other 1's for alive have remained 1's for detection. This table $y$ is what we observe in real life. I hope I have convinced you that to make the connection between observations, the $y$, and true states, the $z$,  we need to describe how observations are made (or emitted in the HMM terminology) from the states.
+Compare with the previous $z$ table. Some 1's for alive have become 0's for non-detection, other 1's for alive have remained 1's for detection. This $y$ table is what we observe in real life. I hope I have convinced you that to make the connection between observations, the $y$, and true states, the $z$,  we need to describe how observations are made (or emitted in the HMM terminology) from the states.
 
 ### Observation matrix
 
 The novelty in HMMs is the link between observations and states. This link is made through observation probabilities. For example, the probability of detecting an animal $i$ at $t$ given it is alive at $t$ is $\Pr(y_{i,t}=2|z_{i,t}=1)=\omega_{1,2}$. It is the detection probability $p$. If individual $i$ is dead at $t$, then it is missed for sure, and  $\Pr(y_{i,t}=1|z_{i,t}=2)=\omega_{2,1}=1$. 
 
-We can gather these observation probabilities into an observation matrix $\mathbf{\Omega}$. In rows we have the states alive $z = 1$ and dead $z = 2$, while in columns we have the observations non-detected $y = 1$ and detected $y = 2$ (previously coded 0 and 1 respectively): **if we go for 1 and 2, do wee need the comment between parentheses?**
+We can gather these observation probabilities into an observation matrix $\mathbf{\Omega}$. In rows we have the states alive $z = 1$ and dead $z = 2$, while in columns we have the observations non-detected $y = 1$ and detected $y = 2$ (previously coded 0 and 1 respectively):
 
 \begin{align*}
 \mathbf{\Omega} =
@@ -549,10 +546,11 @@ We can gather these observation probabilities into an observation matrix $\mathb
 \end{array}\right)
 \end{align*}
 
-Observation matrix:
+In survival models we will use throughout this book, we condition the fate of individuals on first detection, which boils down to set the corresponding detection probability to 1. 
 
-$$
-\begin{matrix}
+The observation matrix is:
+
+$$\begin{matrix}
 & \\
 \mathbf{\Omega} =
     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right .
@@ -571,8 +569,8 @@ $$
     \begin{matrix}
     z_{t}=1 \; \mbox{(alive)}\\ z_{t}=2 \; \mbox{(dead)}
     \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
+
 
 ### Hidden Markov model
 
@@ -606,11 +604,13 @@ Our hidden Markov model can be represented this way:
 
 States $z$ are in gray. Observations $y$ are in white. All individuals are first captured in the first winter $t = 1$, and are therefore all alive $z_1 = 1$ and detected $y_1 = 2$. 
 
-```{block2 hmm-diagram, type='rmdnote', eval = FALSE}
-A hidden Markov model is just two time series running in parallel. One for the states with the Markovian property, and the other of for the observations generated from the states^[HMM are a special case of state-space models in which latent states are discrete.].
-```
 
-Have a look to the example below, in which an individual is detected at first sampling occasion, detected again, then missed for the rest of the study. While on occasion $t=3$ that individual was alive $z_3=1$ and went undetected $y_3=1$, on occasions $t=4$ and $t=5$ it went undetected $y_4=y_5=1$ because it was dead $z_4=z_5=2$.
+:::: {.blackbox data-latex=""""}
+A hidden Markov model is just two time series running in parallel. One for the states with the Markovian property, and the other of for the observations generated from the states. HMM are a special case of state-space models in which latent states are discrete.
+::::
+
+
+Have a look to the example below, in which an individual is detected at first sampling occasion, detected again, then missed for the rest of the study. While on occasion $t=3$ that individual was alive $z_3=1$ and went undetected $y_3=1$, on occasions $t=4$ and $t=5$ it went undetected $y_4=y_5=1$ because it was dead $z_4=z_5=2$. Because we condition on first detection, the link between state and observation at $t=1$ is deterministic and $p = 1$. 
 
 ```{r, engine = 'tikz', echo = FALSE}
 \usetikzlibrary{arrows, fit, positioning, automata}
@@ -717,12 +717,12 @@ The Bayesian approach with MCMC methods allows treating the latent states $z_{i,
 
 ## Fitting HMM with NIMBLE {#fittinghmmnimble}
 
-Our model so far is written as follows:
+If we denote *first* the time of first detection, then our model so far is written as follows:
 
 \begin{align*}
    z_{\text{first}} &\sim \text{Categorical}(1, \delta) &\text{[likelihood]}\\
-   z_t | z_{t-1} &\sim \text{Categorical}(1, \gamma_{z_{t-1},z_{t}}) &\text{[likelihood]}\\
-   y_t | z_{t} &\sim \text{Categorical}(1, \omega_{z_{t}}) &\text{[likelihood]}\\
+   z_t | z_{t-1} &\sim \text{Categorical}(1, \gamma_{z_{t-1},z_{t}}) &\text{[likelihood, t>first]}\\
+   y_t | z_{t} &\sim \text{Categorical}(1, \omega_{z_{t}}) &\text{[likelihood, t>first]}\\
   \phi &\sim \text{Beta}(1, 1) &\text{[prior for }\phi \text{]} \\
   p &\sim \text{Beta}(1, 1) &\text{[prior for }p \text{]} \\
 \end{align*}
@@ -766,8 +766,8 @@ Then we define initial states, transition and observation matrices:
 ```{r eval=FALSE}
 ...
   # parameters
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
+  delta[1] <- 1          # Pr(alive t = first) = 1
+  delta[2] <- 0          # Pr(dead t = first) = 0
   gamma[1,1] <- phi      # Pr(alive t -> alive t+1)
   gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)
   gamma[2,1] <- 0        # Pr(dead t -> alive t+1)
@@ -793,14 +793,16 @@ Then the likelihood:
 })
 ```
 
+The loop over time for each individual `for (j in 2:T){}` starts after the first time individuals are detected (this is time 2 for all of them here), because we work conditional on the first detection. 
+
 Overall, the code looks like:
 ```{r eval = FALSE}
 hmm.survival <- nimbleCode({
   phi ~ dunif(0, 1) # prior survival
   p ~ dunif(0, 1) # prior detection
   # likelihood
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
+  delta[1] <- 1          # Pr(alive t = first) = 1
+  delta[2] <- 0          # Pr(dead t = first) = 0
   gamma[1,1] <- phi      # Pr(alive t -> alive t+1)
   gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)
   gamma[2,1] <- 0        # Pr(dead t -> alive t+1)
@@ -825,11 +827,13 @@ my.constants <- list(N = nrow(y), T = 5)
 my.constants
 ```
 
-The data are made of 0's for non-detections and 1's for detections. To use the categorical distribution, we need to code 1's and 2's. We simply add 1 to get the correct format, that is $y = 1$ for non-detection and $y = 2$ for detection: **Using 1 and 2 would make my life easier... The 0/1 coding is a convention; Using the 1/2 coding would make clear that non-detections are actual data (while the use of 0s for non-detections is sometimes confusing). Also, it might help to replace states 1 and 2 by A and D for dead and alive. Even if not mathematically convenient, I guess it would help the understanding. Do it, do it. We want non-detection first, so always 1's.**
+The data are made of 0's for non-detections and 1's for detections. To use the categorical distribution, we need to code 1's and 2's. We simply add 1 to get the correct format, that is $y = 1$ for non-detection and $y = 2$ for detection: 
 ```{r}
 my.data <- list(y = y + 1)
 ```
 
+<!-- **Using 1 and 2 would make my life easier... The 0/1 coding is a convention; Using the 1/2 coding would make clear that non-detections are actual data (while the use of 0s for non-detections is sometimes confusing). Also, it might help to replace states 1 and 2 by A and D for dead and alive. Even if not mathematically convenient, I guess it would help the understanding. Do it, do it. We want non-detection first, so always 1's.** -->
+
 Now let's write a function for the initial values:
 ```{r}
 zinits <- y + 1 # non-detection -> alive
@@ -839,6 +843,8 @@ initial.values <- function() list(phi = runif(1,0,1),
                                   z = zinits)
 ```
 
+As initial values for the latent states, we assumed that whenever an individual was non-detected, it was alive, with with `zinits <- y + 1`, and we make sure dead individuals are alive with `zinits[zinits == 2] <- 1`.
+
 We specify the parameters we'd like to monitor:
 ```{r}
 parameters.to.save <- c(""phi"", ""p"")
@@ -867,7 +873,7 @@ end_time <- Sys.time()
 end_time - start_time
 ```
 
-```{r, message=FALSE, cache = F, echo = FALSE}
+```{r, message=FALSE, echo = FALSE}
 start_time <- Sys.time()
 mcmc.output <- nimbleMCMC(code = hmm.survival,
                           constants = my.constants,
@@ -912,7 +918,7 @@ Omega[2,2] <- 0          # Pr(dead t -> detected t)
 # Matrix of states
 z <- matrix(NA, nrow = nind, ncol = nocc)
 y <- z
-y[,1] <- 2 # all individuals are detected in first winter
+y[,1] <- 2 # all individuals are detected in first winter, as we condition on first detection
 for (i in 1:nind){
   z[i,1] <- rcat(n = 1, prob = delta) # 1 for sure
   for (t in 2:nocc){
@@ -1002,8 +1008,6 @@ You end up with $\Pr(y_1 = 2, y_2 = 2, y_3 = 1) = \phi p (1 - p\phi)$.
 
 The latent states are no longer involved in the likelihood for this individual. However, even on a rather simple example, the marginal likelihood is quite complex to evaluate because it involves many operations. If $T$ is the length of our encounter histories and $N$ is the number of hidden states (two for alive and dead, but we will deal with more states in some chapters to come), then we need to calculate the sum of $N^T$ terms (the sums in the formula above), each of which has two products of $T$ factors (the products in the formula above), hence $2TN^T$ calculations in total. You can check that in the simple example above, we have $T^N = 2^3 = 8$ terms that are summed, each of which is a product of $2T = 2 \times 3 = 6$ terms. This means that the number of operations increases exponentially as the number of states increases. In most cases, this complexity precludes using this method to get rid of the states. Fortunately, we have another algorithm in the HMM toolbox that is useful to calculate the marginal likelihood efficiently.
 
-**Explain somewhere that we condition on first encounter, therefore p at first encounter is 1! **
-
 ### Forward algorithm {#forward-algorithm}
 
 In the brute-force approach, some products are computed several times to calculate the marginal likelihood. What if we could store these products and use them later while computing the probability of the observation sequence? This is precisely what the forward algorithm does. 
@@ -1101,19 +1105,20 @@ You can check that we did in total $3 \times 2^2 = 12$ operations.
 
 ### NIMBLE implementation
 
-#### Do it yourself
+#### Do it yourself {#diymarginalisation}
 
 In NIMBLE, we use functions to implement the forward algorithm. The only differences with the theory above is that i) we work on the log scale for numerical stability and ii) we use a matrix formulation of the recurrence. 
+
 First we write the density function:
 ```{r}
 dHMM <- nimbleFunction(
   run = function(x = double(1), 
-                 probInit = double(1),
-                 probObs = double(2),
-                 probTrans = double(2),
-                 len = double(0, default = 0),
+                 probInit = double(1), # vector of initial states
+                 probObs = double(2), #observation matrix
+                 probTrans = double(2), # transition matrix
+                 len = double(0, default = 0), # number of sampling occasions
                  log = integer(0, default = 0)) {
-    alpha <- probInit[1:2]
+    alpha <- probInit[1:2] # * probObs[1:2,x[1]] == 1 due to conditioning on first detection
     for (t in 2:len) {
       alpha[1:2] <- (alpha[1:2] %*% probTrans[1:2,1:2]) * probObs[1:2,x[t]]
     }
@@ -1125,7 +1130,7 @@ dHMM <- nimbleFunction(
 )
 ```
 
-In passing, this is the function you would maximize in a Frequentist approach^[I might add that example in a footnote. See also Section \@ref(under-the-hood)]. Then we write a function to simulate values from a HMM:
+In passing, this is the function you would maximize in a frequentist approach (see Section \@ref(under-the-hood)). Then we write a function to simulate values from a HMM:
 ```{r}
 rHMM <- nimbleFunction(
   run = function(n = integer(),
@@ -1262,15 +1267,16 @@ MCMCsummary(mcmc.output, round = 2)
 
 #### Do it with `nimbleEcology`
 
-Writing NIMBLE functions is not easy. Fortunately, the NIMBLE folks got you covered. They developed the package `nimbleEcology` that implements some of the most popular ecological models with latent states. **Develop. Give ref in Suggested reading.**
+Writing NIMBLE functions is not easy. Fortunately, the NIMBLE folks got you covered. They developed the package `nimbleEcology` that implements some of the most popular ecological models with latent states. 
 
-We will use the function `dHMMo` which provides the distribution of a hidden Markov model with time-independent transition matrix and time-dependent observation matrix. Why time-dependent observation matrix? We need to tell NIMBLE that capture at first encounter is 1. **More details.**
+We will use the function `dHMMo` which provides the distribution of a hidden Markov model with time-independent transition matrix and time-dependent observation matrix. Why time-dependent observation matrix? Because we need to tell NIMBLE that detection at first encounter is 1. 
 
+We load the package:
 ```{r}
 library(nimbleEcology)
 ```
 
-NIMBLE code:
+The NIMBLE code is:
 
 ```{r}
 hmm.survival <- nimbleCode({
@@ -1303,7 +1309,9 @@ hmm.survival <- nimbleCode({
 })
 ```
 
-Next steps are similar to the workflow we used before:
+You may see that we no longer have the states in the code as we use the marginalized likelihood. The `dHMMo` takes several arguments, including `init` the vector of initial state probabilities, `probObs` the observation matrix, `probTrans` the transition matrix and `len` the number of sampling occasions. 
+
+Next steps are similar to the workflow we used before. The only difference is that we do not need to specify initial values for the latent states: 
 
 ```{r}
 # constants
@@ -1337,19 +1345,16 @@ end_time <- Sys.time()
 end_time - start_time
 ```
 
-
+Now we display the numerical summaries of the posterior distributions: 
 ```{r}
 MCMCsummary(mcmc.output, round = 2)
 ```
 
-
-
+The results are similar what we obtained previously with our home-made marginalized likelihood (Section \@ref(diymarginalisation)), or with the full likelihood (\@ref(fittinghmmnimble)).
 
 ## Pooled encounter histories {#pooled-likelihood}
 
-### Do it yourself
-
-We can go one step further to make convergence even faster. As mentionned earlier in Section \@ref(likelihoodhmm), the likelihood of an HMM fitted to capture-recapture data often involves individuals that share the same encounter histories. Instead of repeating the same calculations several times, the likelihood contribution that is shared by say $x$ individuals is raised to the power $x$ in the likelihood of the whole dataset, hence making the same operations only once^[This idea is used in routine in capture-recapture software like MARK or E-SURGE. For Bayesian software however, it is only recently that the trick was tested in NIMBLE (in Turek, de Valpine, and Paciorek (2016). Efficient Markov chain Monte Carlo sampling for hierarchical hidden Markov models. *Environmental and Ecological Statistics* 23: 549-564. Many thanks to Chlo√© Nater for showing me how to implement it.].
+We can go one step further to make convergence even faster. As mentionned earlier in Section \@ref(likelihoodhmm), the likelihood of an HMM fitted to capture-recapture data often involves individuals that share the same encounter histories. Instead of repeating the same calculations several times, the likelihood contribution that is shared by say $x$ individuals is raised to the power $x$ in the likelihood of the whole dataset, hence making the same operations only once. This idea is used in routine in capture-recapture software. For Bayesian software however, it is only recently that the trick was tested in NIMBLE by @TurekEtAl2016.
 
 In this section, we amend the NIMBLE functions we wrote for marginalizing latent states in Section \@ref(marginalization) to express the likelihood using pooled encounter histories. We use a vector `size` that contains the number of individuals with the same encounter history. 
 
@@ -1471,231 +1476,217 @@ MCMCsummary(mcmc.output, round = 2)
 
 The results are the same as those obtained previously. The gain in computation times will be bigger for more complex models as we will see in the next chapters. 
 
-<!-- Works preeeeeety well ;-) two small issues though: -->
-
-<!-- 1. I get this warning:  -->
-<!-- Message d'avis : -->
-<!-- Dans model$checkBasics() : -->
-<!--   Possible size/dimension mismatch amongst vectors and matrices  -->
-<!--    in BUGS expression: y[i, 1:5] ~ dHMM(probInit = delta[1:2],  -->
-<!--    probObs = omegat[1:2,     1:2], probTrans = gamma[1:2, 1:2],  -->
-<!--    len = 5, lower_ = -Inf,     upper_ = Inf). Ignore this warning  -->
-<!--    if the user-provided distribution has multivariate parameters  -->
-<!--    with distinct sizes or if size of variable differs from sizes of parameters. -->
-
-### Do it with `nimbleEcology`
-
-**Pooled likelihood not implemented at the moment in nimbleEcology, but you can hack the code for the function dHMMo to implement it yourself. Get functions in nimbleEcology GitHub <https://github.com/nimble-dev/nimbleEcology/blob/master/R/dHMM.R> and add size. That gives**
-
-```{r}
-library(nimble)
-library(MCMCvis)
-library(tidyverse)
-
-dHMMopooled <- nimbleFunction(
-  run = function(x = double(1),    ## Observed capture (state) history
-                 init = double(1),##
-                 probObs = double(3),
-                 probTrans = double(2),
-                 len = double(0, default = 0),## length of x (needed as a separate param for rDHMM)
-                 size = double(0),
-                 checkRowSums = double(0, default = 1),
-                 log = integer(0, default = 0)) {
-    if (length(x) != len) stop(""In dHMMo: Argument len must be length of x or 0."")
-    if (dim(probObs)[1] != dim(probTrans)[1]) stop(""In dHMMo: In dHMM: Length of dimension 1 in probObs must equal length of dimension 1 in probTrans."")
-    if (dim(probTrans)[1] != dim(probTrans)[2]) stop(""In dHMMo: probTrans must be a square matrix."")
-    if (dim(probObs)[3] != len) {
-      if (dim(probObs)[3] == 1) stop(""In dHMMo: Time dimension of probObs must match length of data. Did you mean dHMM?"")
-      stop(""In dHMMo: Length of time dimension of probObs must match length of data."")
-    }
-    if (abs(sum(init) - 1) > 1e-6) stop(""In dHMMo: Initial probabilities must sum to 1."")
-
-    if (checkRowSums) {
-      transCheckPasses <- TRUE
-      for (i in 1:dim(probTrans)[1]) {
-        thisCheckSum <- sum(probTrans[i,])
-        if (abs(thisCheckSum - 1) > 1e-6) {
-          ## Compilation doesn't support more than a simple string for stop()
-          ## so we provide more detail using a print().
-          print(""In dHMMo: Problem with sum(probTrans[i,]) with i = "", i, "". The sum should be 1 but is "", thisCheckSum)
-          transCheckPasses <- FALSE
-        }
-      }
-      obsCheckPasses <- TRUE
-      for (i in 1:dim(probObs)[1]) {
-        for (k in 1:dim(probObs)[3]) {
-          thisCheckSum <- sum(probObs[i,,k])
-          if (abs(thisCheckSum - 1) > 1e-6) {
-            print(""In dHMMo: Problem with sum(probObs[i,,k]) with i = "", i, "" k = "" , k, "". The sum should be 1 but is "", thisCheckSum)
-            obsCheckPasses <- FALSE
-          }
-        }
-      }
-      if(!(transCheckPasses | obsCheckPasses))
-        stop(""In dHMMo: probTrans and probObs were not specified correctly.  Probabilities in each row (second dimension) must sum to 1."")
-      if(!transCheckPasses)
-        stop(""In dHMMo: probTrans was not specified correctly.  Probabilities in each row (second dimension) must sum to 1."")
-      if(!obsCheckPasses)
-        stop(""In dHMMo: probObs was not specified correctly. Probabilities in each row must sum to 1."")
-    }
-    pi <- init # State probabilities at time t=1
-    logL <- 0
-    nObsClasses <- dim(probObs)[2]
-    for (t in 1:len) {
-      if (x[t] > nObsClasses | x[t] < 1) stop(""In dHMMo: Invalid value of x[t]."")
-      Zpi <- probObs[,x[t],t] * pi # Vector of P(state) * P(observation class x[t] | state)
-      sumZpi <- sum(Zpi)    # Total P(observed as class x[t])
-      logL <- logL + log(sumZpi) * size  # Accumulate log probabilities through time√ç
-      if (t != len) pi <- ((Zpi %*% probTrans) / sumZpi)[1, ] # State probabilities at t+1
-    }
-    returnType(double())
-    if (log) return(logL)
-    return(exp(logL))
-  }
-)
-
-rHMMopooled <- nimbleFunction(
-  run = function(n = integer(),    ## Observed capture (state) history
-                 init = double(1),
-                 probObs = double(3),
-                 probTrans = double(2),
-                 len = double(0, default = 0),
-                 size = double(0),
-                 checkRowSums = double(0, default = 1)) {
-  returnType(double(1))
-  if (dim(probObs)[1] != dim(probTrans)[1]) stop(""In rHMMo: Number of cols in probObs must equal number of cols in probTrans."")
-  if (dim(probTrans)[1] != dim(probTrans)[2]) stop(""In rHMMo: probTrans must be a square matrix."")
-  if (dim(probObs)[3] != len) {
-    if (dim(probObs)[3] == 1) stop(""In rHMMo: Time dimension of probObs must match length of data. Did you mean rHMM?"")
-    stop(""In rHMMo: Length of time dimension of probObs must match length of data."")
-  }
-  if (abs(sum(init) - 1) > 1e-6) stop(""In rHMMo: Initial probabilities must sum to 1."")
-
-  if (checkRowSums) {
-    transCheckPasses <- TRUE
-    for (i in 1:dim(probTrans)[1]) {
-      thisCheckSum <- sum(probTrans[i,])
-      if (abs(thisCheckSum - 1) > 1e-6) {
-        ## Compilation doesn't support more than a simple string for stop()
-        ## so we provide more detail using a print().
-        print(""In rHMMo: Problem with sum(probTrans[i,]) with i = "", i, "". The sum should be 1 but is "", thisCheckSum)
-        transCheckPasses <- FALSE
-      }
-    }
-    obsCheckPasses <- TRUE
-    for (i in 1:dim(probObs)[1]) {
-      for (k in 1:dim(probObs)[3]) {
-        thisCheckSum <- sum(probObs[i,,k])
-        if (abs(thisCheckSum - 1) > 1e-6) {
-          print(""In rHMMo: Problem with sum(probObs[i,,k]) with i = "", i, "" k = "", k, "". The sum should be 1 but is "", thisCheckSum)
-          obsCheckPasses <- FALSE
-        }
-      }
-    }
-    if(!(transCheckPasses | obsCheckPasses))
-      stop(""In rHMMo: probTrans and probObs were not specified correctly.  Probabilities in each row (second dimension) must sum to 1."")
-    if(!transCheckPasses)
-      stop(""In rHMMo: probTrans was not specified correctly.  Probabilities in each row (second dimension) must sum to 1."")
-    if(!obsCheckPasses)
-      stop(""In rHMMo: probObs was not specified correctly. Probabilities in each row must sum to 1."")
-  }
-
-  ans <- numeric(len)
-
-  probInit <- init
-  trueInit <- 0
-
-  r <- runif(1, 0, 1)
-  j <- 1
-  while (r > sum(probInit[1:j])) j <- j + 1
-  trueInit <- j
-
-  trueState <- trueInit
-  for (i in 1:len) {
-    # Transition to a new true state
-    r <- runif(1, 0, 1)
-    j <- 1
-    while (r > sum(probTrans[trueState, 1:j])) j <- j + 1
-    trueState <- j
-
-    # Detect based on the true state
-    r <- runif(1, 0, 1)
-    j <- 1
-    while (r > sum(probObs[trueState, 1:j, i])) j <- j + 1
-    ans[i] <- j
-
-  }
-
-  return(ans)
-})
-
-assign('dHMMopooled', dHMMopooled, .GlobalEnv)
-assign('rHMMopooled', rHMMopooled, .GlobalEnv)
-
-# code
-hmm.survival <- nimbleCode({
-  phi ~ dunif(0, 1) # prior survival
-  p ~ dunif(0, 1) # prior detection
-  # likelihood
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)
-  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)
-  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)
-  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)
-  omega[1,1,1] <- 0        # Pr(alive first -> non-detected first)
-  omega[1,2,1] <- 1        # Pr(alive first -> detected first)
-  omega[2,1,1] <- 1        # Pr(dead first -> non-detected first)
-  omega[2,2,1] <- 0        # Pr(dead first -> detected first)
-  for (t in 2:5){
-    omega[1,1,t] <- 1 - p    # Pr(alive t -> non-detected t)
-    omega[1,2,t] <- p        # Pr(alive t -> detected t)
-    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)
-    omega[2,2,t] <- 0        # Pr(dead t -> detected t)
-  }
-  for (i in 1:N){
-    y[i,1:5] ~ dHMMopooled(init = delta[1:2], # vector of initial state probabilities
-                           probObs = omega[1:2,1:2,1:5], # observation matrix
-                           probTrans = gamma[1:2,1:2], # transition matrix
-                           len = 5, # nb of sampling occasions
-                           checkRowSums = 0, # skip validity checks
-                           size = size[i]) # number of individuals with encounter history i
-
-  }
-})
-
-y_pooled <- y %>% 
-  as_tibble() %>% 
-  group_by_all() %>% # group
-  summarise(size = n()) %>% # count
-  relocate(size) %>% # put size in front
-  arrange(-size) %>% # sort along size
-  as.matrix()
-y_pooled
-
-my.constants <- list(N = nrow(y_pooled), T = 5, size = y_pooled[,'size'])
-my.data <- list(y = y_pooled[,-1] + 1) # delete size from dataset
-initial.values <- function() list(phi = runif(1,0,1),
-                                  p = runif(1,0,1))
-parameters.to.save <- c(""phi"", ""p"")
-n.iter <- 5000
-n.burnin <- 1000
-n.chains <- 2
-
-start_time <- Sys.time()
-mcmc.output <- nimbleMCMC(code = hmm.survival,
-                          constants = my.constants,
-                          data = my.data,
-                          inits = initial.values,
-                          monitors = parameters.to.save,
-                          niter = n.iter,
-                          nburnin = n.burnin,
-                          nchains = n.chains)
-end_time <- Sys.time()
-end_time - start_time
-
-MCMCsummary(mcmc.output, round = 2)
-```
+The pooled likelihood is not yet implemented in `nimbleEcology`, but you can hack the code for the function `dHMMo` <https://github.com/nimble-dev/nimbleEcology/blob/master/R/dHMM.R> to implement it yourself by adding a `size` argument. 
+
+<!-- ```{r} -->
+<!-- library(nimble) -->
+<!-- library(MCMCvis) -->
+<!-- library(tidyverse) -->
+
+<!-- dHMMopooled <- nimbleFunction( -->
+<!--   run = function(x = double(1),    ## Observed capture (state) history -->
+<!--                  init = double(1),## -->
+<!--                  probObs = double(3), -->
+<!--                  probTrans = double(2), -->
+<!--                  len = double(0, default = 0),## length of x (needed as a separate param for rDHMM) -->
+<!--                  size = double(0), -->
+<!--                  checkRowSums = double(0, default = 1), -->
+<!--                  log = integer(0, default = 0)) { -->
+<!--     if (length(x) != len) stop(""In dHMMo: Argument len must be length of x or 0."") -->
+<!--     if (dim(probObs)[1] != dim(probTrans)[1]) stop(""In dHMMo: In dHMM: Length of dimension 1 in probObs must equal length of dimension 1 in probTrans."") -->
+<!--     if (dim(probTrans)[1] != dim(probTrans)[2]) stop(""In dHMMo: probTrans must be a square matrix."") -->
+<!--     if (dim(probObs)[3] != len) { -->
+<!--       if (dim(probObs)[3] == 1) stop(""In dHMMo: Time dimension of probObs must match length of data. Did you mean dHMM?"") -->
+<!--       stop(""In dHMMo: Length of time dimension of probObs must match length of data."") -->
+<!--     } -->
+<!--     if (abs(sum(init) - 1) > 1e-6) stop(""In dHMMo: Initial probabilities must sum to 1."") -->
+
+<!--     if (checkRowSums) { -->
+<!--       transCheckPasses <- TRUE -->
+<!--       for (i in 1:dim(probTrans)[1]) { -->
+<!--         thisCheckSum <- sum(probTrans[i,]) -->
+<!--         if (abs(thisCheckSum - 1) > 1e-6) { -->
+<!--           ## Compilation doesn't support more than a simple string for stop() -->
+<!--           ## so we provide more detail using a print(). -->
+<!--           print(""In dHMMo: Problem with sum(probTrans[i,]) with i = "", i, "". The sum should be 1 but is "", thisCheckSum) -->
+<!--           transCheckPasses <- FALSE -->
+<!--         } -->
+<!--       } -->
+<!--       obsCheckPasses <- TRUE -->
+<!--       for (i in 1:dim(probObs)[1]) { -->
+<!--         for (k in 1:dim(probObs)[3]) { -->
+<!--           thisCheckSum <- sum(probObs[i,,k]) -->
+<!--           if (abs(thisCheckSum - 1) > 1e-6) { -->
+<!--             print(""In dHMMo: Problem with sum(probObs[i,,k]) with i = "", i, "" k = "" , k, "". The sum should be 1 but is "", thisCheckSum) -->
+<!--             obsCheckPasses <- FALSE -->
+<!--           } -->
+<!--         } -->
+<!--       } -->
+<!--       if(!(transCheckPasses | obsCheckPasses)) -->
+<!--         stop(""In dHMMo: probTrans and probObs were not specified correctly.  Probabilities in each row (second dimension) must sum to 1."") -->
+<!--       if(!transCheckPasses) -->
+<!--         stop(""In dHMMo: probTrans was not specified correctly.  Probabilities in each row (second dimension) must sum to 1."") -->
+<!--       if(!obsCheckPasses) -->
+<!--         stop(""In dHMMo: probObs was not specified correctly. Probabilities in each row must sum to 1."") -->
+<!--     } -->
+<!--     pi <- init # State probabilities at time t=1 -->
+<!--     logL <- 0 -->
+<!--     nObsClasses <- dim(probObs)[2] -->
+<!--     for (t in 1:len) { -->
+<!--       if (x[t] > nObsClasses | x[t] < 1) stop(""In dHMMo: Invalid value of x[t]."") -->
+<!--       Zpi <- probObs[,x[t],t] * pi # Vector of P(state) * P(observation class x[t] | state) -->
+<!--       sumZpi <- sum(Zpi)    # Total P(observed as class x[t]) -->
+<!--       logL <- logL + log(sumZpi) * size  # Accumulate log probabilities through time√ç -->
+<!--       if (t != len) pi <- ((Zpi %*% probTrans) / sumZpi)[1, ] # State probabilities at t+1 -->
+<!--     } -->
+<!--     returnType(double()) -->
+<!--     if (log) return(logL) -->
+<!--     return(exp(logL)) -->
+<!--   } -->
+<!-- ) -->
+
+<!-- rHMMopooled <- nimbleFunction( -->
+<!--   run = function(n = integer(),    ## Observed capture (state) history -->
+<!--                  init = double(1), -->
+<!--                  probObs = double(3), -->
+<!--                  probTrans = double(2), -->
+<!--                  len = double(0, default = 0), -->
+<!--                  size = double(0), -->
+<!--                  checkRowSums = double(0, default = 1)) { -->
+<!--   returnType(double(1)) -->
+<!--   if (dim(probObs)[1] != dim(probTrans)[1]) stop(""In rHMMo: Number of cols in probObs must equal number of cols in probTrans."") -->
+<!--   if (dim(probTrans)[1] != dim(probTrans)[2]) stop(""In rHMMo: probTrans must be a square matrix."") -->
+<!--   if (dim(probObs)[3] != len) { -->
+<!--     if (dim(probObs)[3] == 1) stop(""In rHMMo: Time dimension of probObs must match length of data. Did you mean rHMM?"") -->
+<!--     stop(""In rHMMo: Length of time dimension of probObs must match length of data."") -->
+<!--   } -->
+<!--   if (abs(sum(init) - 1) > 1e-6) stop(""In rHMMo: Initial probabilities must sum to 1."") -->
+
+<!--   if (checkRowSums) { -->
+<!--     transCheckPasses <- TRUE -->
+<!--     for (i in 1:dim(probTrans)[1]) { -->
+<!--       thisCheckSum <- sum(probTrans[i,]) -->
+<!--       if (abs(thisCheckSum - 1) > 1e-6) { -->
+<!--         ## Compilation doesn't support more than a simple string for stop() -->
+<!--         ## so we provide more detail using a print(). -->
+<!--         print(""In rHMMo: Problem with sum(probTrans[i,]) with i = "", i, "". The sum should be 1 but is "", thisCheckSum) -->
+<!--         transCheckPasses <- FALSE -->
+<!--       } -->
+<!--     } -->
+<!--     obsCheckPasses <- TRUE -->
+<!--     for (i in 1:dim(probObs)[1]) { -->
+<!--       for (k in 1:dim(probObs)[3]) { -->
+<!--         thisCheckSum <- sum(probObs[i,,k]) -->
+<!--         if (abs(thisCheckSum - 1) > 1e-6) { -->
+<!--           print(""In rHMMo: Problem with sum(probObs[i,,k]) with i = "", i, "" k = "", k, "". The sum should be 1 but is "", thisCheckSum) -->
+<!--           obsCheckPasses <- FALSE -->
+<!--         } -->
+<!--       } -->
+<!--     } -->
+<!--     if(!(transCheckPasses | obsCheckPasses)) -->
+<!--       stop(""In rHMMo: probTrans and probObs were not specified correctly.  Probabilities in each row (second dimension) must sum to 1."") -->
+<!--     if(!transCheckPasses) -->
+<!--       stop(""In rHMMo: probTrans was not specified correctly.  Probabilities in each row (second dimension) must sum to 1."") -->
+<!--     if(!obsCheckPasses) -->
+<!--       stop(""In rHMMo: probObs was not specified correctly. Probabilities in each row must sum to 1."") -->
+<!--   } -->
+
+<!--   ans <- numeric(len) -->
+
+<!--   probInit <- init -->
+<!--   trueInit <- 0 -->
+
+<!--   r <- runif(1, 0, 1) -->
+<!--   j <- 1 -->
+<!--   while (r > sum(probInit[1:j])) j <- j + 1 -->
+<!--   trueInit <- j -->
+
+<!--   trueState <- trueInit -->
+<!--   for (i in 1:len) { -->
+<!--     # Transition to a new true state -->
+<!--     r <- runif(1, 0, 1) -->
+<!--     j <- 1 -->
+<!--     while (r > sum(probTrans[trueState, 1:j])) j <- j + 1 -->
+<!--     trueState <- j -->
+
+<!--     # Detect based on the true state -->
+<!--     r <- runif(1, 0, 1) -->
+<!--     j <- 1 -->
+<!--     while (r > sum(probObs[trueState, 1:j, i])) j <- j + 1 -->
+<!--     ans[i] <- j -->
+
+<!--   } -->
+
+<!--   return(ans) -->
+<!-- }) -->
+
+<!-- assign('dHMMopooled', dHMMopooled, .GlobalEnv) -->
+<!-- assign('rHMMopooled', rHMMopooled, .GlobalEnv) -->
+
+<!-- # code -->
+<!-- hmm.survival <- nimbleCode({ -->
+<!--   phi ~ dunif(0, 1) # prior survival -->
+<!--   p ~ dunif(0, 1) # prior detection -->
+<!--   # likelihood -->
+<!--   delta[1] <- 1          # Pr(alive t = 1) = 1 -->
+<!--   delta[2] <- 0          # Pr(dead t = 1) = 0 -->
+<!--   gamma[1,1] <- phi      # Pr(alive t -> alive t+1) -->
+<!--   gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1) -->
+<!--   gamma[2,1] <- 0        # Pr(dead t -> alive t+1) -->
+<!--   gamma[2,2] <- 1        # Pr(dead t -> dead t+1) -->
+<!--   omega[1,1,1] <- 0        # Pr(alive first -> non-detected first) -->
+<!--   omega[1,2,1] <- 1        # Pr(alive first -> detected first) -->
+<!--   omega[2,1,1] <- 1        # Pr(dead first -> non-detected first) -->
+<!--   omega[2,2,1] <- 0        # Pr(dead first -> detected first) -->
+<!--   for (t in 2:5){ -->
+<!--     omega[1,1,t] <- 1 - p    # Pr(alive t -> non-detected t) -->
+<!--     omega[1,2,t] <- p        # Pr(alive t -> detected t) -->
+<!--     omega[2,1,t] <- 1        # Pr(dead t -> non-detected t) -->
+<!--     omega[2,2,t] <- 0        # Pr(dead t -> detected t) -->
+<!--   } -->
+<!--   for (i in 1:N){ -->
+<!--     y[i,1:5] ~ dHMMopooled(init = delta[1:2], # vector of initial state probabilities -->
+<!--                            probObs = omega[1:2,1:2,1:5], # observation matrix -->
+<!--                            probTrans = gamma[1:2,1:2], # transition matrix -->
+<!--                            len = 5, # nb of sampling occasions -->
+<!--                            checkRowSums = 0, # skip validity checks -->
+<!--                            size = size[i]) # number of individuals with encounter history i -->
+
+<!--   } -->
+<!-- }) -->
+
+<!-- y_pooled <- y %>%  -->
+<!--   as_tibble() %>%  -->
+<!--   group_by_all() %>% # group -->
+<!--   summarise(size = n()) %>% # count -->
+<!--   relocate(size) %>% # put size in front -->
+<!--   arrange(-size) %>% # sort along size -->
+<!--   as.matrix() -->
+<!-- y_pooled -->
+
+<!-- my.constants <- list(N = nrow(y_pooled), T = 5, size = y_pooled[,'size']) -->
+<!-- my.data <- list(y = y_pooled[,-1] + 1) # delete size from dataset -->
+<!-- initial.values <- function() list(phi = runif(1,0,1), -->
+<!--                                   p = runif(1,0,1)) -->
+<!-- parameters.to.save <- c(""phi"", ""p"") -->
+<!-- n.iter <- 5000 -->
+<!-- n.burnin <- 1000 -->
+<!-- n.chains <- 2 -->
+
+<!-- start_time <- Sys.time() -->
+<!-- mcmc.output <- nimbleMCMC(code = hmm.survival, -->
+<!--                           constants = my.constants, -->
+<!--                           data = my.data, -->
+<!--                           inits = initial.values, -->
+<!--                           monitors = parameters.to.save, -->
+<!--                           niter = n.iter, -->
+<!--                           nburnin = n.burnin, -->
+<!--                           nchains = n.chains) -->
+<!-- end_time <- Sys.time() -->
+<!-- end_time - start_time -->
+
+<!-- MCMCsummary(mcmc.output, round = 2) -->
+<!-- ``` -->
 
 
 ## Decoding after marginalization {#decoding}
@@ -1746,7 +1737,7 @@ Imagine you do not know the truth. What is the chance that animal #15 was alive
 
 Now what is the chance that animal #15 was alive, then dead for the rest of the study, when observing the encounter history (`r y[15,] + 1`)? And the chance of being alive in first and second winters, then dead after when observing the same encounter history? And so on. You need to enumerate all possible sequences of states and compute the probability for each of them, and choose the most probable sequence, that is with maximum probability. In our example, we would need to compute $2^5 = 32$ of these probabilities, and $N^T$ in general. Needless to say, these calculations quickly become cumbersome, if not impossible, as the number of states and/or the number of sampling occasions increases. 
 
-This is where the Viterbi algorithm comes in. The idea is to decompose this overall complex problem in a sequence of smallers problems that are easier to solve^[If dynamic programming rings a bell, the Viterbi algorithm should look familiar to you.]. The Viterbi algorithm is based on the fact that the optimal path to each winter and each state can be deduced from the optimal path to the previous winter and each state.  
+This is where the Viterbi algorithm comes in. The idea is to decompose this overall complex problem in a sequence of smallers problems that are easier to solve. If dynamic programming rings a bell, the Viterbi algorithm should look familiar to you. The Viterbi algorithm is based on the fact that the optimal path to each winter and each state can be deduced from the optimal path to the previous winter and each state.  
 
 For first winter, the probability of being alive and detected is 1, while the probability of being dead and detected is 0. Now what is the probability of being alive in the second winter and non-detected? If the animal was alive in the first winter, it remains alive and is missed with probability $1 \times \phi (1-p) = 0.32$. If it was dead in the first winter, then this probability is 0. The maximum probability is 0.32 obviously so the most probable scenario to being alive in the second winter is being alive in the first winter. What about being dead in the second winter? If the animal was alive in first winter, then the probability is $1 \times (1-\phi) \times 1 = 0.2$. If dead, then this probability is $0 \times 0 \times (1-p) = 0$. The maximum probability is 0.2 obviously so the most probable scenario to being dead in the second winter is being alive in the first winter. Doing these calculations for third, fourth and fifth winters, we get the probabilities:
 
@@ -1827,7 +1818,7 @@ for (i in 2:T) {
 }
 ```
 
-Note that instead of writing your own R function, you could use a built-in function from an existing R package to implement the Viterbi algorithm^[For example, the `viterbi()` function from the HMM and depmixS4 packages.], and call it from NIMBLE as we have seen in Section \@ref(callrfninnimble). The difficulty is that HMM for capture-recapture data have specific features that make standard functions not adapted and requires coding your own Viterbi function. In particular, we have to deal with detection at first encounter, which is not estimated but is always one because an individual has to be captured to be marked and released for the first time. Also, our transition and observation matrices are not always homogeneous and may depend on time. 
+Note that instead of writing your own R function, you could use a built-in function from an existing R package to implement the Viterbi algorithm (for example, the `viterbi()` function from the `HMM` and `depmixS4` packages), and call it from NIMBLE as we have seen in Section \@ref(callrfninnimble). The difficulty is that HMM for capture-recapture data have specific features that make standard functions not adapted and requires coding your own Viterbi function. In particular, we have to deal with detection at first encounter, which is not estimated but is always one because an individual has to be captured to be marked and released for the first time. Also, our transition and observation matrices are not always homogeneous and may depend on time. 
 
 ```{r echo = FALSE, eval = FALSE}
 library(HMM)
@@ -1977,4 +1968,10 @@ The results are very similar to those we obtained in Section \@ref(compute-avera
 
 ## Suggested reading
 
-+ @JurafskySpeechAL, @mcclintock_uncovering_2020, @Rabiner1989, @ZucchiniEtAl2016. **Comment.**
++ A landmark paper on HMM is @Rabiner1989. 
+
++ Check out @JurafskySpeechAL for a nice introduction to HMM and @ZucchiniEtAl2016 for an excellent book that covers theory and applications. 
+
++ The paper by @mcclintock_uncovering_2020 reviews the applications of HMM in ecology. 
+
++ The package `nimbleEcology` is developed by @goldstein2019nimbleecology and @ponisio2020customizing for application to occupancy and N--mixture models.
\ No newline at end of file

---FILE: index.Rmd---
@@ -19,6 +19,17 @@ header-includes:
   - \usepackage{tikz}
   - \usepackage{pgfplots}
   - \usepackage{blkarray}
+  - \pgfplotsset{compat=1.18} 
+  - \usepackage{tcolorbox}
+  - \usepackage{arydshln}
+  - \newtcolorbox{blackbox}{
+    colback=white,
+    colframe=purple,
+    coltext=black,
+    boxsep=5pt,
+    arc=4pt}
+  - \usepackage{subfig}
+# Warning: Package pgfplots Warning: running in backwards compatibility mode (unsuitable tick labels; missing features). Consider writing \pgfplotsset{compat=1.18} into your preamble.
 ---
 
 ```{r setup, include=FALSE}
@@ -40,6 +51,8 @@ Welcome to the online version of the book *Bayesian analysis of capture-recaptur
 
 I'm currently writing this book, and I welcome any feedback. You may raise an issue [here](https://github.com/oliviergimenez/banana-book/issues), amend directly the R Markdown file that generated the page you're reading by clicking on the 'Edit this page' icon in the right panel, or [email me](mailto:olivier.gimenez@cefe.cnrs.fr). Many thanks!
 
+<!-- The PDF of the book can be downloaded [here](banana-book.pdf). I still need to fix lots of issues.  -->
+
 Olivier Gimenez. Written in Montpellier, France and Athens, Greece. 
 Last updated: `r Sys.setlocale(""LC_TIME"", ""C""); format(Sys.Date(), ""%B %d, %Y"")`
 

---FILE: introductionpartone.Rmd---
@@ -1,6 +1,6 @@
 \mainmatter
 
-# (PART) I. Foundations {-}
+# (PART) Foundations {-}
 
 # Introduction {-}
 

---FILE: introductionpartthree.Rmd---
@@ -1,4 +1,4 @@
-# (PART) III. Case studies {-}
+# (PART) Case studies {-}
 
 # Introduction {-}
 

---FILE: introductionparttwo.Rmd---
@@ -1,4 +1,4 @@
-# (PART) II. Transitions {-}
+# (PART) Transitions {-}
 
 # Introduction {-}
 

---FILE: lackoffit.Rmd---
@@ -25,8 +25,7 @@ Individual heterogeneity
 
 Vector of initial state probabilities
 
-$$
-  \begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\delta} =
   \left ( \vphantom{ \begin{matrix} 12 \end{matrix} } \right .
@@ -42,15 +41,13 @@ $$
           \left . \vphantom{ \begin{matrix} 12 \end{matrix} } \right )
 \begin{matrix}
 \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
   
 $\pi$ is the probability of being alive in class 1. $1 - \pi$ is the probability of being in class 2.
 
 Transition matrix
 
-$$
-  \begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\Gamma} =
   \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
@@ -69,15 +66,13 @@ $$
 \begin{matrix}
 z_{t-1}=A1 \\ z_{t-1}=A2 \\ z_{t-1}=D
 \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
   
 $\phi$ is the survival probability, which could be made heterogeneous.
 
 Transition matrix, with change in heterogeneity class
 
-$$
-  \begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\Gamma} =
   \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
@@ -96,15 +91,13 @@ $$
 \begin{matrix}
 z_{t-1}=A1 \\ z_{t-1}=A2 \\ z_{t-1}=D
 \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
   
 $\psi_{12}$ is the probability for an individual to change class of heterogeneity, from 1 to 2. $\psi_{21}$ is the probability for an individual to change class of heterogeneity, from 2 to 1.
 
 Observation matrix
 
-$$
-  \begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\Omega} =
   \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right .
@@ -123,8 +116,7 @@ $$
 \begin{matrix}
 z_{t}=A1 \\ z_{t}=A2 \\ z_{t}=D
 \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
   
 $p_1$ is detection for individuals in class 1, and $p_2$ that of individuals in class 2.
 
@@ -164,8 +156,7 @@ Multistate treatment as in @schaub2004te. See example in @bancila2018te.
 
 Transition matrix:
   
-$$
-  \begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\Gamma} =
   \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
@@ -184,13 +175,11 @@ $$
 \begin{matrix}
 z_{t-1}=\text{in} \\ z_{t-1}=\text{out} \\ z_{t-1}=\text{D}
 \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
   
 Observation matrix:
   
-$$
-  \begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\Omega} =
   \left ( \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right .
@@ -209,8 +198,7 @@ $$
 \begin{matrix}
 z_{t}=\text{in} \\ z_{t}=\text{out} \\ z_{t}=\text{D}
 \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
 
 
 ## Memory model
@@ -225,8 +213,7 @@ Remember HMM model for dispersal between 2 sites
 
 Transition matrix
 
-$$
-\begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\Gamma} =
 \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
@@ -245,13 +232,11 @@ z_t=A & z_t=B & z_t=D \\ \hdashline
 \begin{matrix}
 z_{t-1}=A \\ z_{t-1}=B \\ z_{t-1}=D
 \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
 
 Observation matrix
 
-$$
-\begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\Omega} =
 \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
@@ -270,8 +255,7 @@ y_t=0 & y_t=1 & y_t=2 \\ \hdashline
 \begin{matrix}
 z_{t}=A \\ z_{t}=B \\ z_{t}=D
 \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
 
 HMM formulation of the memory model
 
@@ -291,8 +275,7 @@ To keep track of the sites previously visited, the trick is to consider states a
 
 Vector of initial state probabilities
 
-$$
-\begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\delta} =
 \left ( \vphantom{ \begin{matrix} 12 \end{matrix} } \right .
@@ -308,15 +291,13 @@ z_t=AA & z_t=AB & z_t=BA & z_t=BB &z_t=D \\ \hdashline
 \left . \vphantom{ \begin{matrix} 12 \end{matrix} } \right )
 \begin{matrix}
 \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
 
 where $\pi_{BB} = 1 - (\pi_{AA} + \pi_{AB} + \pi_{BA})$, and $\pi_{ij}$ at site $j$ when first captured at $t$ and site $i$ at $t - 1$.
 
 Transition matrix
 
-$$
-\begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\Gamma} =
 \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12\end{matrix} } \right .
@@ -337,16 +318,14 @@ z_t=AA & z_t=AB & z_t=BA & z_t=BB & z_t=D \\ \hdashline
 \begin{matrix}
 z_t=AA \\ z_t=AB \\ z_t=BA \\ z_t=BB \\ z_t=D
 \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
 
 $\phi_{ijk}$ is probability to be in site $k$ at time $t + 1$ for an individual
 present in site $j$ at $t$ and in site $i$ at $t - 1$
 
 Transition matrix, alternate parameterization
 
-$$
-\begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\Gamma} =
 \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12\end{matrix} } \right .
@@ -367,15 +346,13 @@ z_t=AA & z_t=AB & z_t=BA & z_t=BB & z_t=D \\ \hdashline
 \begin{matrix}
 z_t=AA \\ z_t=AB \\ z_t=BA \\ z_t=BB \\ z_t=D
 \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
 
 $\phi$ is the probability of surviving from one occasion to the next. $\psi_{ijj}$ is the probability an animal stays at the same site $j$ given that it was at site $i$ on the previous occasion.
 
 Observation matrix
 
-$$
-\begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\Omega} =
 \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12\end{matrix} } \right .
@@ -396,8 +373,7 @@ y_t=0 & y_t=1 & y_t=2 \\ \hdashline
 \begin{matrix}
 z_t=AA \\ z_t=AB \\ z_t=BA \\ z_t=BB \\ z_t=D
 \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
 
 ```{r eval = FALSE, echo = FALSE}
 library(tidyverse)

---FILE: lifehistory.Rmd---
@@ -6,8 +6,7 @@
 
 Transition matrix:
   
-$$
-\begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\Gamma} =
   \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12 \end{matrix} } \right .
@@ -28,15 +27,13 @@ $$
 \begin{matrix}
 z_{t-1} = J \\ z_{t-1} = 1yNB \\ z_{t-1} = 2yNB \\ z_{t-1} = B \\ z_{t-1} = D
 \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
   
 First-year and second-year individuals breed with probabilities $\alpha_1$ and $\alpha_2$. Then, everybody breeds from age 3.
 
 Observation matrix:
   
-$$
-\begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\Omega} =
   \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\12 \end{matrix} } \right .
@@ -57,8 +54,8 @@ $$
 \begin{matrix}
 z_t = J \\ z_t = 1yNB \\ z_t = 2yNB \\ z_t = B \\ z_t = D
 \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
+
 Juveniles are never detected.
 
 ## Tradeoffs

---FILE: miscelleanous.Rmd---
@@ -1,4 +1,4 @@
-# Miscelleanous {#misc}
+# Miscelleanous {#miscelleanous}
 
 ## Dependence among individuals
 
@@ -14,8 +14,8 @@ Combine live recapture w/ dead recoveries by @lebreton1999.
 
 Transition matrix
 
-$$
-\begin{matrix}
+
+$$\begin{matrix}
 & \\
 \mathbf{\Gamma} =
   \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
@@ -34,13 +34,13 @@ $$
 \begin{matrix}
 z_{t-1}=\text{alive} \\ z_{t-1}=\text{just dead} \\ z_{t-1}=\text{dead for good}
 \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
+
+
   
 Observation matrix
 
-$$
-\begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\Omega} =
   \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right .
@@ -59,8 +59,7 @@ $$
 \begin{matrix}
 z_{t}=A \\ z_{t}=JD \\ z_{t}=D
 \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
 
 
 ### Cause-specific mortalities
@@ -73,7 +72,7 @@ $$
 
 Let's have a look to another example. Very similar to the previous example. We consider a system of an emerging pathogen *Mycoplasma gallisepticum* Edward and Kanarek and its host the house finch, *Carpodacus mexicanus* M√ºller.
 
-```{r pixfinch, echo=FALSE, fig.cap=""A house finch with a heavy infection (Jim Mondok)."", fig.align='center'}
+```{r pixfinch, echo=FALSE, fig.cap=""A house finch with a heavy infection (Jim Mondok)."", out.width=""100%"", fig.align='center'}
 knitr::include_graphics(""images/infectedhousefinch.jpg"")
 ```
 
@@ -130,8 +129,7 @@ ggplot() +
 
 Vector of initial state probabilities
 
-$$
-\begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\delta} =
     \left ( \vphantom{ \begin{matrix} 12 \end{matrix} } \right .
@@ -147,15 +145,13 @@ $$
 \left . \vphantom{ \begin{matrix} 12 \end{matrix} } \right )
     \begin{matrix}
     \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
 
 $\pi_H$ is the probability that a newly encountered individual is healthy. $\pi_{I} = 1 - \pi_H$ is the probability that a newly encountered individual is ill.
 
 Transition matrix
 
-$$
-\begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\Gamma} =
     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
@@ -174,15 +170,13 @@ $$
     \begin{matrix}
     z_{t-1}=H \\ z_{t-1}=I \\ z_{t-1}=D
     \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
 
 $\phi_H$ is the survival probability of healthy individuals, $\phi_I$ that of ill individuals. $\psi_{HI}$ is the probability of getting sick, $\psi_{IH}$ that of recovering from the disease.
 
 Transition matrix, incurable disease
 
-$$
-\begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\Gamma} =
     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
@@ -201,15 +195,13 @@ $$
     \begin{matrix}
     z_{t-1}=H \\ z_{t-1}=I \\ z_{t-1}=D
     \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
 
 No possibility of recovering from the disease, that is $\psi_{IH} = 0$. Once you get sick, you remain sick $\psi_{II} = 1 - \psi_{IH} = 1$. For analysing the house finch data, we allow recovering from the disease, and we will use transition matrix from previous slide.
 
 Observation matrix
 
-$$
-\begin{matrix}
+$$\begin{matrix}
 & \\
 \mathbf{\Omega} =
     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right .
@@ -228,8 +220,7 @@ $$
     \begin{matrix}
     z_{t}=H \\ z_{t}=I \\ z_{t}=D
     \end{matrix}
-\end{matrix}
-$$
+\end{matrix}$$
 
 $\beta_H$ is the probability to assign a healthy individual to state H. $\beta_{I}$ is the probability to assign a sick individual to state I. $p_H$ is the detection probability of healthy individuals, $p_I$ that of sick individuals.
 
@@ -254,7 +245,7 @@ MCMCplot(out)
 
 @guerin_advances_2017
 
-## Why Bayes? Incorporate prior information
+## Why Bayes? Incorporate prior information {#elicitprior}
 
 The example on how to incorporate prior information is in @mccarthy2005.
 

---FILE: nimble.Rmd---
@@ -2,30 +2,32 @@
 
 ## Introduction
 
-In this second chapter, you will get familiar with NIMBLE, an R package that implements up-to-date MCMC algorithms for fitting complex models. NIMBLE spares you from coding the MCMC algorithms by hand, and requires only the specification of a likelihood and priors for model parameters. We will illustrate NIMBLE main features with a simple example, but the ideas hold for other problems.
+In this second chapter, you will get familiar with NIMBLE, an R package that implements up-to-date MCMC algorithms for fitting complex models. NIMBLE spares you from coding the MCMC algorithms by hand, and requires only the specification of a likelihood and priors for model parameters. We will illustrate NIMBLE main features with a simple example, but the ideas hold for more complex problems.
 
 ## What is NIMBLE?
 
 NIMBLE stands for **N**umerical **I**nference for statistical **M**odels using **B**ayesian and **L**ikelihood **E**stimation. Briefly speaking, NIMBLE is an R package that implements for you MCMC algorithms to generate samples from the posterior distribution of model parameters. Freed from the burden of coding your own MCMC algorithms, you only have to specify a likelihood and priors to apply the Bayes theorem. To do so, NIMBLE uses a syntax very similar to the R syntax, which should make your life easier. This so-called BUGS language is also used by other programs like WinBUGS, OpenBUGS, and JAGS. 
 
-So why use NIMBLE you may ask? The short answer is that NIMBLE is capable of so much more than just running MCMC algorithms! First, you will work from within R, but in the background NIMBLE will translate your code in C++ for (in general) faster computation. Second, NIMBLE extends the BUGS language for writing new functions and distributions of your own, or borrow those written by others. Third, NIMBLE gives you full control of the MCMC samplers, and you may pick other algorithms than the defaults. Fourth, NIMBLE comes with a library of numerical methods other than MCMC algorithms, including sequential Monte Carlo (for particle filtering) and Monte Carlo Expectation Maximization (for maximum likelihood). Last but not least, the development team is friendly and helpful, and based on users' feedbacks, NIMBLE folks work constantly at improving the package capabilities. 
+So why use NIMBLE you may ask? The short answer is that NIMBLE is capable of so much more than just running MCMC algorithms! First, you will work from within R, but in the background NIMBLE will translate your code in C++ for (in general) faster computation. Second, NIMBLE extends the BUGS language for writing new functions and distributions of your own, or borrow those written by others. Third, NIMBLE gives you full control of the MCMC samplers, and you may pick other algorithms than the defaults. Fourth, NIMBLE comes with a library of numerical methods other than MCMC algorithms, including sequential Monte Carlo (for particle filtering), Monte Carlo Expectation Maximization (for maximum likelihood), Hamiltonian Monte Carlo (like in program Stan), and Laplace approximation (like in program TMB). Last but not least, the development team is friendly and helpful, and based on users' feedbacks, NIMBLE folks work constantly at improving the package capabilities. 
 
-```{r nimblelogo, echo = FALSE, fig.align=""center"", out.width=""50%"", fig.cap = ""Logo of the NIMBLE R package designed by Luke Larson. **Ask Perry for context and meaning.**""}
+```{r nimblelogo, echo = FALSE, fig.align=""center"", out.width=""50%"", fig.cap = ""Logo of the NIMBLE R package designed by Luke Larson.""}
 knitr::include_graphics(""images/nimble-icon.png"")
 ```
 
 <!-- Why NIMBLE over Stan? i) The BUGS language is cool, ii) discrete latent states easier to deal with NIMBLE, no need to marginalise like with Stan (ref forward to relevant section of the book for marginalization in NIMBLE), iii) also HMC is on its way in NIMBLE, so NIMBLE includes STAN and has so much more to offer the users.  -->
 
 ## Getting started {#start-nimble}
 
-```{block2 nimble_workflow, type='rmdnote', eval = FALSE}
+
+:::: {.blackbox data-latex=""""}
 To run NIMBLE, you will need to:  
 1. Build a model consisting of a likelihood and priors.   
 2. Read in some data.   
 3. Specify parameters you want to make inference about.   
 4. Pick initial values for parameters to be estimated (for each chain).   
 5. Provide MCMC details namely the number of chains, the length of the burn-in period and the number of iterations following burn-in.
-```
+::::
+
 
 First things first, let's not forget to load the `nimble` package:
 ```{r}
@@ -51,9 +53,9 @@ You can check that the `model` R object contains your code:
 model
 ```
 
-In the code above, `survived` and `released` are known, only `theta` needs to be estimated. The line `survived ~ dbinom(theta, released)` states that the number of successes or animals that have survived over winter  `survived` is distributed as (that's the `~`) as a binomial with `released` trials and probability of success or survival `theta`. Then the line `theta ~ dunif(0, 1)` assigns a uniform between 0 and 1 as a prior distribution to the survival probability. This is all you need, a likelihood and priors for model parameters, NIMBLE knows the Bayes theorem. The last line `lifespan <- - 1/log(theta)` calculates a quantity derived from `theta`, which is the expected lifespan assuming constant survival^[Cook LM, Brower LP, Croze HJ (1967) The accuracy of a population estimation from multiple recapture data. J Anim Ecol 36:57‚Äì60].
+In the code above, `survived` and `released` are known, only `theta` needs to be estimated. The line `survived ~ dbinom(theta, released)` states that the number of successes or animals that have survived over winter  `survived` is distributed as (that's the `~`) as a binomial with `released` trials and probability of success or survival `theta`. Then the line `theta ~ dunif(0, 1)` assigns a uniform between 0 and 1 as a prior distribution to the survival probability. This is all you need, a likelihood and priors for model parameters, NIMBLE knows the Bayes theorem. The last line `lifespan <- - 1/log(theta)` calculates a quantity derived from `theta`, which is the expected lifespan assuming constant survival. If you'd like to know more about the calculation of life expectancy, check out @cook1967expectancy.
 
-A few comments:    
+A few comments:   
 
 + The most common distributions are available in NIMBLE. Among others, we will use later in the book `dbeta`, `dmultinom` and `dnorm`. If you cannot find what you need in NIMBLE, you can write your own distribution as illustrated in Section \@ref(functions-in-nimble).
 
@@ -152,19 +154,21 @@ initial.values <- list(init1, init2, init3)
 initial.values
 ```
 
-Alternatively, you can write a simple R function that generates random initial values:
+Alternatively, you can write an R function that generates random initial values:
 ```{r}
 initial.values <- function() list(theta = runif(1,0,1))
 initial.values()
 ```
 
-Firth and last step, you need to tell NIMBLE the number of chains to run, say `n.chain`, how long the burn-in period should be, say `n.burnin`, and the number of iterations following the burn-in period to be used for posterior inference. In NIMBLE, you specify the total number of iterations, say `n.iter`, so that the number of posterior samples per chain is `n.iter - n.burnin`. NIMBLE also allows discarding samples after burn-in, a procedure known as thinning, which I will not use in this book^[Link, W.A. and Eaton, M.J. (2012), On thinning of chains in MCMC. Methods in Ecology and Evolution, 3: 112-115.].
+Firth and last step, you need to tell NIMBLE the number of chains to run, say `n.chain`, how long the burn-in period should be, say `n.burnin`, and the number of iterations following the burn-in period to be used for posterior inference:
 ```{r}
 n.iter <- 5000
 n.burnin <- 1000
 n.chains <- 3
 ```
 
+In NIMBLE, you specify the total number of iterations, say `n.iter`, so that the number of posterior samples per chain is `n.iter - n.burnin`. NIMBLE also allows discarding samples after burn-in, a procedure known as thinning. Thinning is fixed to 1 by default in NIMBLE so that all simulations are used to summarise posterior distributions. @link2012thinning offer a discussion of the pros and cons of thinning. 
+
 We now have all the ingredients to run model, that is to sample in the posterior distribution of model parameters using MCMC simulations. This is accomplished using function `nimbleMCMC()`: 
 ```{r, cache = F}
 mcmc.output <- nimbleMCMC(code = model,
@@ -201,14 +205,14 @@ quantile(mcmc.output$chain1[,'theta'], probs = c(2.5, 97.5)/100)
 
 Let's visualise the posterior distribution of `theta` with a histogram: 
 ```{r}
-mcmc.output %>%
+mcmc.output$chain1[,""theta""] %>%
   as_tibble() %>%
   ggplot() +
-  geom_histogram(aes(x = chain1[,""theta""]), color = ""white"") +
+  geom_histogram(aes(x = value), color = ""white"") +
   labs(x = ""survival probability"")
 ```
 
-There are less painful ways of doing posterior inference. In this book, I will use the R package `MCMCvis`^[https://github.com/caseyyoungflesh/MCMCvis] to summarise and visualize MCMC outputs, but there are other perfectly valid options out there like `ggmcmc`^[Fern√°ndez-i-Mar√≠n, X. (2016). ggmcmc: Analysis of MCMC Samples and Bayesian Inference. Journal of Statistical Software, 70(9), 1‚Äì20] and `basicMCMCplots`^[https://cran.r-project.org/web/packages/basicMCMCplots/index.html]. **Shall I demonstrate these other options?**
+There are less painful ways of doing posterior inference. In this book, I will use the R package `MCMCvis` to summarise and visualize MCMC outputs, but there are other perfectly valid options out there like `ggmcmc`, `bayesplot` and `basicMCMCplots`.
 
 <!-- Finally we want to look at our samples. NIMBLE returns samples as a simple matrix with named columns. There are numerous packages for processing MCMC output. If you want to use the coda package, you can convert a matrix to a coda mcmc object like this: -->
 <!-- library(coda) -->
@@ -251,7 +255,7 @@ MCMCtrace(object = mcmc.output,
           params = ""theta"")
 ```
 
-We calculated lifespan directly in our model with `lifespan <- -1/log(theta)`. But you can also calculate this quantity from outside NIMBLE. This is a nice by-product of using MCMC simulations: you can obtain the posterior distribution of any quantity that is function of your model parameters by applying this function to samples from the posterior distribution of these parameters. In our example, all you need is samples from the posterior distribution of `theta`, which we pool between the three chains with:
+We calculated lifespan directly in our model with `lifespan <- -1/log(theta)`. But you can also calculate this quantity from outside NIMBLE. This is a nice by-product of using MCMC simulations: You can obtain the posterior distribution of any quantity that is function of your model parameters by applying this function to samples from the posterior distribution of these parameters. In our example, all you need is samples from the posterior distribution of `theta`, which we pool between the three chains with:
 ```{r}
 theta_samples <- c(mcmc.output$chain1[,'theta'], 
                    mcmc.output$chain2[,'theta'],
@@ -280,7 +284,8 @@ lifespan %>%
 
 Now you're good to go. For convenience I have summarized the steps above in the box below. The NIMBLE workflow provided with `nimbleMCMC()` allows you to build models and make inference. This is what you can achieve with other software like WinBUGS or JAGS. 
 
-::: {.rmdnote}
+
+:::: {.blackbox data-latex=""""}
 **NIMBLE workflow:**
 ```{r, eval = FALSE}
 # model building
@@ -323,6 +328,7 @@ MCMCtrace(object = mcmc.output,
 ```
 :::
 
+
 But NIMBLE is more than just another MCMC engine. It provides a programming environment so that you have full control when building models and estimating parameters. NIMBLE allows you to write your own functions and distributions to build models, and to choose alternative MCMC samplers or code new ones. This flexibility often comes with faster convergence. 
 
 I have to be honest, learning these improvements over other software takes some reading and experimentation, and it might well be that you do not need to use any of these features. And it's fine. In the next sections, I cover some of this advanced material. You may skip these sections and go back to this material later if you need it.
@@ -452,9 +458,9 @@ dmybinom <- nimbleFunction(
                  prob = double(0), 
                  log = integer(0, default = 1)) {
     returnType(double(0))
-    # compute binomial coefficient 
+    # compute binomial coefficient = size! / [x! (n-x)!] and take log
     lchoose <- lfactorial(size) - lfactorial(x) - lfactorial(size - x)
-    # binomial density function
+    # binomial density function = size! / [x! (n-x)!] * prob^x * (1-prob)^(size-x) and take log
     logProb <- lchoose + x * log(prob) + (size - x) * log(1 - prob)
     if(log) return(logProb)
     else return(exp(logProb)) 
@@ -557,7 +563,33 @@ survival$calculate()
 # this is dbinom(x = 19, size = 57, prob = 0.5, log = TRUE)
 ```
 
-The ability in NIMBLE to access the nodes of your model and to evaluate the model likelihood can help you in identifying bugs in your code. **Give example? Provide negative initial value for theta, or released in data < survived.**
+The ability in NIMBLE to access the nodes of your model and to evaluate the model likelihood can help you in identifying bugs in your code. For example, if we provide a negative initial value for `theta`, `survival$calculate()` returns NA:
+```{r}
+survival <- nimbleModel(code = model,
+                        data = my.data,
+                        inits = list(theta = -0.5))
+survival$calculate()
+```
+
+As another example, if we convey in the data the information that more animals survived than were released, we'll get an infinity value for the log-likelihood:
+```{r}
+my.data <- list(survived = 61, released = 57)
+initial.values <- list(theta = 0.5)
+survival <- nimbleModel(code = model,
+                        data = my.data,
+                        inits = initial.values)
+survival$calculate()
+```
+
+As a check that the model is correctly initialized and that your code is without bugs, the call to `model$calculate()` should return a number and not NA or -Inf:
+```{r}
+my.data <- list(survived = 19, released = 57)
+initial.values <- list(theta = 0.5)
+survival <- nimbleModel(code = model,
+                        data = my.data,
+                        inits = initial.values)
+survival$calculate()
+```
 
 You can obtain the graph of the model as in Figure \@ref(fig:dag-survival) with:
 ```{r}
@@ -629,14 +661,15 @@ You can look into `samples` which contains values simulated from the posterior d
 head(samples)
 ```
 
-From here, you can obtain numerical summaries with `samplesSummary()`:
+From here, you can obtain numerical summaries with `samplesSummary()` (or `MCMCvis::MCMCsummary()`):
 ```{r}
 samplesSummary(samples)
 ```
 
 I have summarized the steps above in the box below. 
 
-::: {.rmdnote}
+
+:::: {.blackbox data-latex=""""}
 **Detailed NIMBLE workflow:**
 ```{r, eval = FALSE}
 # model building
@@ -730,7 +763,9 @@ samples2 <- runMCMC(mcmc = CsurvivalMCMC2,
 samplesSummary(samples2)
 ```
 
-NIMBLE implements many samplers, and a list is available with `?samplers`. For example, high correlation in (regression) parameters can make independent samplers inefficient. In that situation, block sampling might help which consists in proposing candidate values from a multivariate distribution that acknowledges correlation between parameters. **Say something on how default samplers are chosen by NIMBLE?**
+NIMBLE implements many samplers, and a list is available with `?samplers`. For example, high correlation in (regression) parameters can make independent samplers inefficient. In that situation, block sampling might help which consists in proposing candidate values from a multivariate distribution that acknowledges correlation between parameters. 
+
+<!-- **Say something on how default samplers are chosen by NIMBLE?** -->
 
 ### User-defined samplers
 
@@ -818,8 +853,9 @@ samples <- runMCMC(mcmc = CsurvivalMCMC,
 samplesSummary(samples)
 ```
 
-You can re-run the analysis by setting the standard deviation of the proposal to different values, say 1 and 10, and compare Figure \@ref(fig:traceown) to traceplots we obtained with our R implementation of the Metropolis algorithm in the previous chapter at Figure \@ref(fig:tracechainlength):
-```{r traceown, echo = FALSE, fig.align=""center"", out.width=""100%"", fig.cap = ""Trace plots for different values of the standard deviation (scale) of the proposal distribution.""}
+You can re-run the analysis by setting the standard deviation of the proposal to different values, say 1 and 10, and compare the results to traceplots we obtained with our R implementation of the Metropolis algorithm in the previous chapter:
+```{r traceown}
+# standard deviation of proposal is 0.1
 scale <- 0.1
 Rmodel <- nimbleModel(code = model, data = my.data, inits = initial.values())
 conf <- configureMCMC(Rmodel, monitors = c('theta'), print = FALSE)
@@ -829,6 +865,7 @@ Rmcmc <- buildMCMC(conf)
 out <- compileNimble(list(model = Rmodel, mcmc = Rmcmc))
 Cmcmc <- out$mcmc
 samples_sd01 <- runMCMC(Cmcmc, niter = 10000, nburnin = 9000, progressBar = FALSE)
+# standard deviation of proposal is 1
 scale <- 1
 Rmodel <- nimbleModel(code = model, data = my.data, inits = initial.values())
 conf <- configureMCMC(Rmodel, monitors = c('theta'), print = FALSE)
@@ -838,6 +875,7 @@ Rmcmc <- buildMCMC(conf)
 out <- compileNimble(list(model = Rmodel, mcmc = Rmcmc))
 Cmcmc <- out$mcmc
 samples_sd1 <- runMCMC(Cmcmc, niter = 10000, nburnin = 9000, progressBar = FALSE)
+# standard deviation of proposal is 10
 scale <- 10
 Rmodel <- nimbleModel(code = model, data = my.data, inits = initial.values())
 conf <- configureMCMC(Rmodel, monitors = c('theta'), print = FALSE)
@@ -847,31 +885,37 @@ Rmcmc <- buildMCMC(conf)
 out <- compileNimble(list(model = Rmodel, mcmc = Rmcmc))
 Cmcmc <- out$mcmc
 samples_sd10 <- runMCMC(Cmcmc, niter = 10000, nburnin = 9000, progressBar = FALSE)
+# trace plot for scenario with standard deviation 0.1
 plot01 <- samples_sd01 %>%
   as_tibble() %>%
   ggplot() + 
   aes(x = 9001:10000, y = theta) +
   geom_line() + 
   labs(x = ""iterations"", title = ""scale = 0.1"")
+# trace plot for scenario with standard deviation 1
 plot1 <- samples_sd1 %>%
   as_tibble() %>%
   ggplot() + 
   aes(x = 9001:10000, y = theta) +
   geom_line() + 
   labs(x = ""iterations"", title = ""scale = 1"")
+# trace plot for scenario with standard deviation 10
 plot10 <- samples_sd10 %>%
   as_tibble() %>%
   ggplot() + 
   aes(x = 9001:10000, y = theta) +
   geom_line() + 
   labs(x = ""iterations"", title = ""scale = 10"")
+# Assemble all three trace plots
 library(patchwork)
 plot01 + plot1 + plot10
 ```
 
 ## Tips and tricks
 
-Before closing this chapter on NIMBLE, I thought it'd be useful to have a section gathering a few tips and tricks that would make your life easier. **These are my tips and tricks, NIMBLE users, I'd be happy to hear yours: [email me](mailto:olivier.gimenez@cefe.cnrs.fr), [edit the chapter](https://github.com/oliviergimenez/banana-book/edit/master/nimble.Rmd) or [file an issue](https://github.com/oliviergimenez/banana-book/issues) on GitHub.**
+Before closing this chapter on NIMBLE, I thought it'd be useful to have a section gathering a few tips and tricks that would make your life easier. 
+
+<!-- **These are my tips and tricks, NIMBLE users, I'd be happy to hear yours: [email me](mailto:olivier.gimenez@cefe.cnrs.fr), [edit the chapter](https://github.com/oliviergimenez/banana-book/edit/master/nimble.Rmd) or [file an issue](https://github.com/oliviergimenez/banana-book/issues) on GitHub.** -->
 
 ### Precision vs standard deviation
 
@@ -1085,7 +1129,7 @@ you would write:
 x[1:n] <- mu + epsilon[1:n]
 ```
 
-Vectorization can make your code more efficient by manipulating one vector node `x[1:n]` instead of `n` nodes `x[1]`, ..., `x[n]`. **Think of an example in relation to animal survival? Illustrate with vectorized Bernoulli or [vectorized Binomial](https://github.com/nimble-dev/nimbleSCR/blob/master/nimbleSCR/R/dbinom_vector.R)?**
+Vectorization can make your code more efficient by manipulating one vector node `x[1:n]` instead of `n` nodes `x[1]`, ..., `x[n]`. As an example, you may have a look to the vectorized flavor of the binomial distribution written by Pierre Dupont at <https://github.com/nimble-dev/nimbleSCR/blob/master/nimbleSCR/R/dbinom_vector.R>.
 
 ## Summary
 
@@ -1111,10 +1155,10 @@ In this chapter, I have only scratched the surface of what NIMBLE is capable of.
 
 - You can keep the NIMBLE cheatsheet [https://r-nimble.org/cheatsheets/NimbleCheatSheet.pdf](https://r-nimble.org/cheatsheets/NimbleCheatSheet.pdf) near you to remind yourself of the workflow, how to write and use models, or which functions and distributions are available.
 
-- The motivation to write this book comes from a workshop I co-teach with colleagues, including Perry de Valpine and Daniel Turek from the NIMBLE development team. The material (slides and videos) is available at [https://github.com/oliviergimenez/bayesian-cr-workshop](https://github.com/oliviergimenez/bayesian-cr-workshop). 
-
 - If you have questions, feel free to get in touch with the community of NIMBLE users by emailing the discussion group [https://groups.google.com/forum/#!forum/nimble-users](https://groups.google.com/forum/#!forum/nimble-users). This is a great place to learn, and folks who take the time to answer questions are kind and provide constructive answers. When possible, make sure to provide a reproducible example illustrating your problem. 
 
-- Last, you can cite the following reference when using NIMBLE in a publication:
+- You can cite the following reference when using NIMBLE in a publication:
+
+> de Valpine, P., D. Turek, C. J. Paciorek, C. Anderson-Bergman, D. Temple Lang, and R. Bodik (2017). Programming With Models: Writing Statistical Algorithms for General Model Structures With NIMBLE. *Journal of Computational and Graphical Statistics* **26** (2): 403‚Äì13.
 
-> de Valpine, P., D. Turek, C. J. Paciorek, C. Anderson-Bergman, D. Temple Lang, and R. Bodik (2017). [Programming With Models: Writing Statistical Algorithms for General Model Structures With NIMBLE](https://arxiv.org/pdf/1505.05093.pdf). *Journal of Computational and Graphical Statistics* **26** (2): 403‚Äì13.
+- Last, the packages to process NIMBLE results are developed by people whose work should be acknowledged: see @youngflesh2018mcmcvis for `MCMCvis`, @turek2022basicmcmcplots for `basicMCMCplots`, @gabry2022bayesplot for `bayesplot` and @fernandez2016ggmcmc for `ggmcmc`.
\ No newline at end of file

---FILE: survival.Rmd---
@@ -63,13 +63,11 @@ Throughout this chapter, we will use data on the White-throated Dipper (*Cinclus
 knitr::include_graphics(""images/Marzo_BaguesMance.jpg"")
 ```
 
-You may scroll down the data below: 
+The data look like: 
 
-```{r echo = FALSE}
+```{r echo = TRUE}
 dipper <- read_csv(here::here(""dat"", ""dipper.csv""))
-dipper %>%
-  kableExtra::kable() %>%
-  kableExtra::scroll_box(width = ""100%"", height = ""400px"")
+dipper
 y <- dipper %>%
   select(year_1981:year_1987) %>%
   as.matrix()",False,True,Rendering / Conversion,7
oliviergimenez,banana-book,b219c43395e37e2c395e92e23dd808697b78c47e,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2023-08-14T06:29:45Z,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2023-08-14T06:29:45Z,"all in again, hopefully bug w/ fig is fixed.",_bookdown.yml;_bookdown_files/banana-book_files/figure-html/dag-survival-1.png;_bookdown_files/banana-book_files/figure-html/traceown-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-110-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-110-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-111-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-111-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-131-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-131-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-132-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-132-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-169-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-169-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-184-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-204-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-205-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-225-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-227-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-241-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-252-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-253-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-281-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-282-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-292-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-293-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-312-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-313-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-314-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-43-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-46-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-47-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-48-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-52-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-72-1.png;_bookdown_files/banana-book_files/figure-html/viterbiaveragecompute-1.png;_bookdown_files/banana-book_files/figure-html/viterbicomputeaverage-1.png;_common.R;docs/404.html;docs/about-the-author.html;docs/banana-book_files/figure-html/dag-survival-1.png;docs/banana-book_files/figure-html/traceown-1.png;docs/banana-book_files/figure-html/unnamed-chunk-110-1.png;docs/banana-book_files/figure-html/unnamed-chunk-111-1.png;docs/banana-book_files/figure-html/unnamed-chunk-131-1.png;docs/banana-book_files/figure-html/unnamed-chunk-132-1.png;docs/banana-book_files/figure-html/unnamed-chunk-169-1.png;docs/banana-book_files/figure-html/unnamed-chunk-184-1.png;docs/banana-book_files/figure-html/unnamed-chunk-204-1.png;docs/banana-book_files/figure-html/unnamed-chunk-205-1.png;docs/banana-book_files/figure-html/unnamed-chunk-225-1.png;docs/banana-book_files/figure-html/unnamed-chunk-227-1.png;docs/banana-book_files/figure-html/unnamed-chunk-241-1.png;docs/banana-book_files/figure-html/unnamed-chunk-252-1.png;docs/banana-book_files/figure-html/unnamed-chunk-253-1.png;docs/banana-book_files/figure-html/unnamed-chunk-281-1.png;docs/banana-book_files/figure-html/unnamed-chunk-282-1.png;docs/banana-book_files/figure-html/unnamed-chunk-292-1.png;docs/banana-book_files/figure-html/unnamed-chunk-293-1.png;docs/banana-book_files/figure-html/unnamed-chunk-312-1.png;docs/banana-book_files/figure-html/unnamed-chunk-313-1.png;docs/banana-book_files/figure-html/unnamed-chunk-314-1.png;docs/banana-book_files/figure-html/unnamed-chunk-46-1.png;docs/banana-book_files/figure-html/unnamed-chunk-47-1.png;docs/banana-book_files/figure-html/unnamed-chunk-48-1.png;docs/banana-book_files/figure-html/unnamed-chunk-52-1.png;docs/banana-book_files/figure-html/unnamed-chunk-72-1.png;docs/banana-book_files/figure-html/viterbiaveragecompute-1.png;docs/banana-book_files/figure-html/viterbicomputeaverage-1.png;docs/covariates.html;docs/crashcourse.html;docs/dispersal.html;docs/hmmcapturerecapture.html;docs/images/Marzo_BaguesMance.jpg;docs/images/bearscat.png;docs/images/bighorn.png;docs/images/gull.jpg;docs/images/lynx.png;docs/images/multistate_local_minimav2_Page_06.png;docs/images/multistate_local_minimav2_Page_07.png;docs/images/nimble-icon.png;docs/images/sooty.jpg;docs/images/treillis-viterbi.png;docs/index.html;docs/introduction-4.html;docs/introduction-7.html;docs/introduction-8.html;docs/introduction.html;docs/intronimble.html;docs/lackoffit.html;docs/libs/kePrint-0.0.1/kePrint.js;docs/libs/lightable-0.0.1/lightable.css;docs/misc.html;docs/preface.html;docs/reference-keys.txt;docs/references.html;docs/search.json;docs/survival.html;docs/take-home-messages.html;docs/tradeoffs.html,True,False,True,False,53617,236,53853,"---FILE: _bookdown.yml---
@@ -18,11 +18,11 @@ rmd_files:
     ""author.Rmd"",
     ""introductionpartone.Rmd"",
     ""bayesmcmc.Rmd"",
-   # ""nimble.Rmd"",
-  #  ""hmm.Rmd"",
+    ""nimble.Rmd"",
+    ""hmm.Rmd"",
     ""introductionparttwo.Rmd"",
-   # ""survival.Rmd"",
-  #  ""dispersal.Rmd"",
+    ""survival.Rmd"",
+    ""dispersal.Rmd"",
     ""introductionpartthree.Rmd"",
     ""lifehistory.Rmd"",
     ""covariates.Rmd"",

---FILE: _common.R---
@@ -8,8 +8,8 @@ library(pdftools)
 library(wesanderson)
 library(RColorBrewer)
 library(patchwork)
-library(nimbleEcology)
-library(basicMCMCplots)
+#library(nimbleEcology)
+#library(basicMCMCplots)
 
 # R options
 options(width = 60)

---FILE: docs/404.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -73,16 +74,20 @@ <h1>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
-<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
-<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
-<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">6</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">7</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">8</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">9</span> Lack of fit</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>

---FILE: docs/about-the-author.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -73,16 +74,20 @@ <h1>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
-<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
-<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
-<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">6</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">7</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">8</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">9</span> Lack of fit</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>

---FILE: docs/covariates.html---
@@ -4,21 +4,22 @@
 <meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
 <meta charset=""utf-8"">
 <meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<title>Chapter 3 Covariates | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<title>Chapter 7 Covariates | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
 <meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""3.1 Missing values NAs reprise du papier de Bonner, ou mod√®le de croissance poisson, ou rien hein‚Ä¶ Work on missing values by Bonner et al.¬†(2006) and Langrock and King (2013) and Worthington et..."">
+<meta name=""description"" content=""7.1 Missing values NAs reprise du papier de Bonner, ou mod√®le de croissance poisson, ou rien hein‚Ä¶ Work on missing values by Bonner et al.¬†(2006) and Langrock and King (2013) and Worthington et..."">
 <meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
-<meta property=""og:title"" content=""Chapter 3 Covariates | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:title"" content=""Chapter 7 Covariates | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
 <meta property=""og:type"" content=""book"">
 <meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/covariates.html"">
-<meta property=""og:description"" content=""3.1 Missing values NAs reprise du papier de Bonner, ou mod√®le de croissance poisson, ou rien hein‚Ä¶ Work on missing values by Bonner et al.¬†(2006) and Langrock and King (2013) and Worthington et..."">
+<meta property=""og:description"" content=""7.1 Missing values NAs reprise du papier de Bonner, ou mod√®le de croissance poisson, ou rien hein‚Ä¶ Work on missing values by Bonner et al.¬†(2006) and Langrock and King (2013) and Worthington et..."">
 <meta name=""twitter:card"" content=""summary"">
-<meta name=""twitter:title"" content=""Chapter 3 Covariates | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta name=""twitter:description"" content=""3.1 Missing values NAs reprise du papier de Bonner, ou mod√®le de croissance poisson, ou rien hein‚Ä¶ Work on missing values by Bonner et al.¬†(2006) and Langrock and King (2013) and Worthington et..."">
+<meta name=""twitter:title"" content=""Chapter 7 Covariates | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""7.1 Missing values NAs reprise du papier de Bonner, ou mod√®le de croissance poisson, ou rien hein‚Ä¶ Work on missing values by Bonner et al.¬†(2006) and Langrock and King (2013) and Worthington et..."">
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -73,16 +74,20 @@ <h1>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
-<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
-<li><a class=""active"" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
-<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">6</span> Life history</a></li>
+<li><a class=""active"" href=""covariates.html""><span class=""header-section-number"">7</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">8</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">9</span> Lack of fit</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
@@ -92,69 +97,69 @@ <h1>
         </div>
       </nav>
 </div>
-  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""covariates"" class=""section level1"" number=""3"">
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""covariates"" class=""section level1"" number=""7"">
 <h1>
-<span class=""header-section-number"">3</span> Covariates<a class=""anchor"" aria-label=""anchor"" href=""#covariates""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">7</span> Covariates<a class=""anchor"" aria-label=""anchor"" href=""#covariates""><i class=""fas fa-link""></i></a>
 </h1>
-<div id=""missing-values"" class=""section level2"" number=""3.1"">
+<div id=""missing-values"" class=""section level2"" number=""7.1"">
 <h2>
-<span class=""header-section-number"">3.1</span> Missing values<a class=""anchor"" aria-label=""anchor"" href=""#missing-values""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">7.1</span> Missing values<a class=""anchor"" aria-label=""anchor"" href=""#missing-values""><i class=""fas fa-link""></i></a>
 </h2>
 <p>NAs reprise du papier de Bonner, ou mod√®le de croissance poisson, ou rien hein‚Ä¶</p>
 <p>Work on missing values by <a href=""https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1541-0420.2005.00399.x"">Bonner et al.¬†(2006)</a> and <a href=""https://projecteuclid.org/journals/annals-of-applied-statistics/volume-7/issue-3/Maximum-likelihood-estimation-of-markrecapturerecovery-models-in-the-presence-of/10.1214/13-AOAS644.full"">Langrock and King (2013)</a> and <a href=""https://link.springer.com/article/10.1007/s13253-014-0184-z"">Worthington et al.¬†(2015)</a>.</p>
 </div>
-<div id=""nonlinearities"" class=""section level2"" number=""3.2"">
+<div id=""nonlinearities"" class=""section level2"" number=""7.2"">
 <h2>
-<span class=""header-section-number"">3.2</span> Nonlinearities<a class=""anchor"" aria-label=""anchor"" href=""#nonlinearities""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">7.2</span> Nonlinearities<a class=""anchor"" aria-label=""anchor"" href=""#nonlinearities""><i class=""fas fa-link""></i></a>
 </h2>
 <p>splines √† la main et avec jagam, ex snow petrels</p>
 </div>
-<div id=""covariate-selection"" class=""section level2"" number=""3.3"">
+<div id=""covariate-selection"" class=""section level2"" number=""7.3"">
 <h2>
-<span class=""header-section-number"">3.3</span> Covariate selection<a class=""anchor"" aria-label=""anchor"" href=""#covariate-selection""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">7.3</span> Covariate selection<a class=""anchor"" aria-label=""anchor"" href=""#covariate-selection""><i class=""fas fa-link""></i></a>
 </h2>
 <p>rjmcmc on turdus merila, papier Evolution Gimenez. Exemple cigognes, papier Gimenez WinBUGS.</p>
 </div>
-<div id=""sex-uncertainty"" class=""section level2"" number=""3.4"">
+<div id=""sex-uncertainty"" class=""section level2"" number=""7.4"">
 <h2>
-<span class=""header-section-number"">3.4</span> Sex uncertainty<a class=""anchor"" aria-label=""anchor"" href=""#sex-uncertainty""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">7.4</span> Sex uncertainty<a class=""anchor"" aria-label=""anchor"" href=""#sex-uncertainty""><i class=""fas fa-link""></i></a>
 </h2>
 <p><span class=""citation"">Pradel et al. (<a href=""references.html#ref-PradelEtAl2008"">2008</a>)</span> and <span class=""citation"">Genovart, Pradel, and Oro (<a href=""references.html#ref-genovart_exploiting_2012"">2012</a>)</span></p>
 </div>
-<div id=""actuarial-senescence"" class=""section level2"" number=""3.5"">
+<div id=""actuarial-senescence"" class=""section level2"" number=""7.5"">
 <h2>
-<span class=""header-section-number"">3.5</span> Actuarial senescence<a class=""anchor"" aria-label=""anchor"" href=""#actuarial-senescence""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">7.5</span> Actuarial senescence<a class=""anchor"" aria-label=""anchor"" href=""#actuarial-senescence""><i class=""fas fa-link""></i></a>
 </h2>
 <p><span class=""citation"">Choquet et al. (<a href=""references.html#ref-choquet_semi-markov_2011"">2011</a>)</span>, <span class=""citation"">P√©ron et al. (<a href=""references.html#ref-peron_evidence_2016"">2016</a>)</span>, Marzolin on dipper in Ecology.</p>
 </div>
-<div id=""covariate-on-multinomial-logit-link"" class=""section level2"" number=""3.6"">
+<div id=""covariate-on-multinomial-logit-link"" class=""section level2"" number=""7.6"">
 <h2>
-<span class=""header-section-number"">3.6</span> Covariate on multinomial logit link<a class=""anchor"" aria-label=""anchor"" href=""#covariate-on-multinomial-logit-link""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">7.6</span> Covariate on multinomial logit link<a class=""anchor"" aria-label=""anchor"" href=""#covariate-on-multinomial-logit-link""><i class=""fas fa-link""></i></a>
 </h2>
 <p>papier Lorele√Ø</p>
 </div>
-<div id=""uncertainty-in-age"" class=""section level2"" number=""3.7"">
+<div id=""uncertainty-in-age"" class=""section level2"" number=""7.7"">
 <h2>
-<span class=""header-section-number"">3.7</span> Uncertainty in age<a class=""anchor"" aria-label=""anchor"" href=""#uncertainty-in-age""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">7.7</span> Uncertainty in age<a class=""anchor"" aria-label=""anchor"" href=""#uncertainty-in-age""><i class=""fas fa-link""></i></a>
 </h2>
 <p>Papier Vincenzo et d‚Äôautre papiers.</p>
 
 </div>
 </div>
   <div class=""chapter-nav"">
-<div class=""prev""><a href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></div>
-<div class=""next""><a href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></div>
+<div class=""prev""><a href=""tradeoffs.html""><span class=""header-section-number"">6</span> Life history</a></div>
+<div class=""next""><a href=""misc.html""><span class=""header-section-number"">8</span> Miscelleanous</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
       <ul class=""nav navbar-nav"">
-<li><a class=""nav-link"" href=""#covariates""><span class=""header-section-number"">3</span> Covariates</a></li>
-<li><a class=""nav-link"" href=""#missing-values""><span class=""header-section-number"">3.1</span> Missing values</a></li>
-<li><a class=""nav-link"" href=""#nonlinearities""><span class=""header-section-number"">3.2</span> Nonlinearities</a></li>
-<li><a class=""nav-link"" href=""#covariate-selection""><span class=""header-section-number"">3.3</span> Covariate selection</a></li>
-<li><a class=""nav-link"" href=""#sex-uncertainty""><span class=""header-section-number"">3.4</span> Sex uncertainty</a></li>
-<li><a class=""nav-link"" href=""#actuarial-senescence""><span class=""header-section-number"">3.5</span> Actuarial senescence</a></li>
-<li><a class=""nav-link"" href=""#covariate-on-multinomial-logit-link""><span class=""header-section-number"">3.6</span> Covariate on multinomial logit link</a></li>
-<li><a class=""nav-link"" href=""#uncertainty-in-age""><span class=""header-section-number"">3.7</span> Uncertainty in age</a></li>
+<li><a class=""nav-link"" href=""#covariates""><span class=""header-section-number"">7</span> Covariates</a></li>
+<li><a class=""nav-link"" href=""#missing-values""><span class=""header-section-number"">7.1</span> Missing values</a></li>
+<li><a class=""nav-link"" href=""#nonlinearities""><span class=""header-section-number"">7.2</span> Nonlinearities</a></li>
+<li><a class=""nav-link"" href=""#covariate-selection""><span class=""header-section-number"">7.3</span> Covariate selection</a></li>
+<li><a class=""nav-link"" href=""#sex-uncertainty""><span class=""header-section-number"">7.4</span> Sex uncertainty</a></li>
+<li><a class=""nav-link"" href=""#actuarial-senescence""><span class=""header-section-number"">7.5</span> Actuarial senescence</a></li>
+<li><a class=""nav-link"" href=""#covariate-on-multinomial-logit-link""><span class=""header-section-number"">7.6</span> Covariate on multinomial logit link</a></li>
+<li><a class=""nav-link"" href=""#uncertainty-in-age""><span class=""header-section-number"">7.7</span> Uncertainty in age</a></li>
 </ul>
 
       <div class=""book-extra"">

---FILE: docs/crashcourse.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -73,16 +74,20 @@ <h1>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class=""active"" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
-<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
-<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
-<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">6</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">7</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">8</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">9</span> Lack of fit</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
@@ -255,7 +260,7 @@ <h3>
 <div class=""sourceCode"" id=""cb7""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""va"">sample_from_posterior</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Beta.html"">rbeta</a></span><span class=""op"">(</span><span class=""fl"">1000</span>, <span class=""fl"">20</span>, <span class=""fl"">39</span><span class=""op"">)</span> <span class=""co""># draw 1000 values from posterior survival beta(20,39)</span></span>
 <span><span class=""fu""><a href=""https://rdrr.io/r/base/mean.html"">mean</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span><span class=""op"">)</span> <span class=""co""># compute mean with Monte Carlo integration</span></span>
-<span><span class=""co"">## [1] 0.3394</span></span></code></pre></div>
+<span><span class=""co"">## [1] 0.3443</span></span></code></pre></div>
 <p>You may check that the mean we have just calculated matches closely the expectation of a beta distribution<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;If &lt;span class=""math inline""&gt;\(X\)&lt;/span&gt; is a random variable with distribution &lt;span class=""math inline""&gt;\(\text{beta}(a, b)\)&lt;/span&gt;, then &lt;span class=""math inline""&gt;\(E(X) = \displaystyle{\frac{a}{a + b}}\)&lt;/span&gt;&lt;/p&gt;'><sup>10</sup></a>:</p>
 <div class=""sourceCode"" id=""cb8""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""fl"">20</span><span class=""op"">/</span><span class=""op"">(</span><span class=""fl"">20</span><span class=""op"">+</span><span class=""fl"">39</span><span class=""op"">)</span> <span class=""co""># expectation of beta(20,39)</span></span>
@@ -264,7 +269,7 @@ <h3>
 <div class=""sourceCode"" id=""cb9""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span><span class=""fu""><a href=""https://rdrr.io/r/stats/quantile.html"">quantile</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span>, probs <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/c.html"">c</a></span><span class=""op"">(</span><span class=""fl"">2.5</span><span class=""op"">/</span><span class=""fl"">100</span>, <span class=""fl"">97.5</span><span class=""op"">/</span><span class=""fl"">100</span><span class=""op"">)</span><span class=""op"">)</span></span>
 <span><span class=""co"">##   2.5%  97.5% </span></span>
-<span><span class=""co"">## 0.2201 0.4670</span></span></code></pre></div>
+<span><span class=""co"">## 0.2253 0.4602</span></span></code></pre></div>
 </div>
 <div id=""markovmodelmcmc"" class=""section level3"" number=""1.5.2"">
 <h3>
@@ -533,12 +538,9 @@ <h2>
 </div>
 </div>
 
-
-
-
   <div class=""chapter-nav"">
 <div class=""prev""><a href=""introduction.html"">Introduction</a></div>
-<div class=""next""><a href=""introduction-2.html"">Introduction</a></div>
+<div class=""next""><a href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
       <ul class=""nav navbar-nav"">

---FILE: docs/index.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -73,16 +74,20 @@ <h1>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
-<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
-<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
-<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">6</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">7</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">8</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">9</span> Lack of fit</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>

---FILE: docs/introduction-4.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -73,16 +74,20 @@ <h1>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class=""active"" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
-<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
-<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
-<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">6</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">7</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">8</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">9</span> Lack of fit</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class=""active"" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
@@ -95,18 +100,19 @@ <h1>
   </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""introduction-4"" class=""section level1 unnumbered"">
 <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-4""><i class=""fas fa-link""></i></a>
 </h1>
+
 </div>
   <div class=""chapter-nav"">
-<div class=""prev""><a href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></div>
-<div class=""next""><a href=""take-home-messages.html"">Take-home messages</a></div>
+<div class=""prev""><a href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></div>
+<div class=""next""><a href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
       <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#introduction-4"">Introduction</a></li></ul>
 
       <div class=""book-extra"">
         <ul class=""list-unstyled"">
-<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionpartfour.Rmd"">View source <i class=""fab fa-github""></i></a></li>
-          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionpartfour.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionparttwo.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionparttwo.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
         </ul>
 </div>
     </nav>

---FILE: docs/introduction-7.html---
@@ -0,0 +1,165 @@
+<!DOCTYPE html>
+<html lang=""en"">
+<head>
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
+<meta property=""og:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/introduction-7.html"">
+<meta property=""og:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+    
+    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
+  </style>
+<style type=""text/css"">
+    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
+    div.csl-bib-body { }
+    div.csl-entry {
+      clear: both;
+        }
+    .hanging div.csl-entry {
+      margin-left:2em;
+      text-indent:-2em;
+    }
+    div.csl-left-margin {
+      min-width:2em;
+      float:left;
+    }
+    div.csl-right-inline {
+      margin-left:2em;
+      padding-left:1em;
+    }
+    div.csl-indent {
+      margin-left: 2em;
+    }
+  </style>
+<link rel=""stylesheet"" href=""bs4_style.css"">
+</head>
+<body data-spy=""scroll"" data-target=""#toc"">
+
+<div class=""container-fluid"">
+<div class=""row"">
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+
+    <div class=""d-flex align-items-start justify-content-between"">
+      <h1>
+        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
+        <small class=""text-muted"">Theory and Case Studies in R</small>
+      </h1>
+      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
+    </div>
+
+    <div id=""main-nav"" class=""collapse-lg"">
+      <form role=""search"">
+        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
+</form>
+
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li><a class="""" href=""about-the-author.html"">About the author</a></li>
+<li class=""book-part"">I. Foundations</li>
+<li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
+<li class=""book-part"">II. Transitions</li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
+<li class=""book-part"">III. Case studies</li>
+<li><a class=""active"" href=""introduction-7.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">6</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">7</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">8</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">9</span> Lack of fit</a></li>
+<li class=""book-part"">IV. Conclusions</li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
+<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
+
+        <div class=""book-extra"">
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
+        </div>
+      </nav>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""introduction-7"" class=""section level1 unnumbered"">
+<h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-7""><i class=""fas fa-link""></i></a>
+</h1>
+
+</div>
+  <div class=""chapter-nav"">
+<div class=""prev""><a href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></div>
+<div class=""next""><a href=""tradeoffs.html""><span class=""header-section-number"">6</span> Life history</a></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
+      <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#introduction-7"">Introduction</a></li></ul>
+
+      <div class=""book-extra"">
+        <ul class=""list-unstyled"">
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionpartthree.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionpartthree.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+        </ul>
+</div>
+    </nav>
+</div>
+
+</div>
+</div> <!-- .container -->
+
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-14.</p>
+  </div>
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
+  </div>
+
+</div></div>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
+</body>
+</html>

---FILE: docs/introduction-8.html---
@@ -0,0 +1,164 @@
+<!DOCTYPE html>
+<html lang=""en"">
+<head>
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
+<meta property=""og:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/introduction-8.html"">
+<meta property=""og:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+    
+    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
+  </style>
+<style type=""text/css"">
+    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
+    div.csl-bib-body { }
+    div.csl-entry {
+      clear: both;
+        }
+    .hanging div.csl-entry {
+      margin-left:2em;
+      text-indent:-2em;
+    }
+    div.csl-left-margin {
+      min-width:2em;
+      float:left;
+    }
+    div.csl-right-inline {
+      margin-left:2em;
+      padding-left:1em;
+    }
+    div.csl-indent {
+      margin-left: 2em;
+    }
+  </style>
+<link rel=""stylesheet"" href=""bs4_style.css"">
+</head>
+<body data-spy=""scroll"" data-target=""#toc"">
+
+<div class=""container-fluid"">
+<div class=""row"">
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+
+    <div class=""d-flex align-items-start justify-content-between"">
+      <h1>
+        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
+        <small class=""text-muted"">Theory and Case Studies in R</small>
+      </h1>
+      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
+    </div>
+
+    <div id=""main-nav"" class=""collapse-lg"">
+      <form role=""search"">
+        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
+</form>
+
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li><a class="""" href=""about-the-author.html"">About the author</a></li>
+<li class=""book-part"">I. Foundations</li>
+<li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
+<li class=""book-part"">II. Transitions</li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
+<li class=""book-part"">III. Case studies</li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">6</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">7</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">8</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">9</span> Lack of fit</a></li>
+<li class=""book-part"">IV. Conclusions</li>
+<li><a class=""active"" href=""introduction-8.html"">Introduction</a></li>
+<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
+
+        <div class=""book-extra"">
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
+        </div>
+      </nav>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""introduction-8"" class=""section level1 unnumbered"">
+<h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-8""><i class=""fas fa-link""></i></a>
+</h1>
+</div>
+  <div class=""chapter-nav"">
+<div class=""prev""><a href=""lackoffit.html""><span class=""header-section-number"">9</span> Lack of fit</a></div>
+<div class=""next""><a href=""take-home-messages.html"">Take-home messages</a></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
+      <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#introduction-8"">Introduction</a></li></ul>
+
+      <div class=""book-extra"">
+        <ul class=""list-unstyled"">
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionpartfour.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionpartfour.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+        </ul>
+</div>
+    </nav>
+</div>
+
+</div>
+</div> <!-- .container -->
+
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-14.</p>
+  </div>
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
+  </div>
+
+</div></div>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
+</body>
+</html>

---FILE: docs/introduction.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -73,16 +74,20 @@ <h1>
 <li class=""book-part"">I. Foundations</li>
 <li><a class=""active"" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
-<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
-<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
-<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">6</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">7</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">8</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">9</span> Lack of fit</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>

---FILE: docs/lackoffit.html---
@@ -4,21 +4,22 @@
 <meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
 <meta charset=""utf-8"">
 <meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<title>Chapter 5 Lack of fit | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<title>Chapter 9 Lack of fit | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
 <meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""5.1 Individual heterogeneity Cubaynes et al. (2010), Gimenez and Choquet (2010), and Turek, Wehrhahn, and Gimenez (2021). Example wolf. Traiter label switching avec constraint dans Nimble. Aussi..."">
+<meta name=""description"" content=""9.1 Individual heterogeneity Cubaynes et al. (2010), Gimenez and Choquet (2010), and Turek, Wehrhahn, and Gimenez (2021). Example wolf. Traiter label switching avec constraint dans Nimble. Aussi..."">
 <meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
-<meta property=""og:title"" content=""Chapter 5 Lack of fit | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:title"" content=""Chapter 9 Lack of fit | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
 <meta property=""og:type"" content=""book"">
 <meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/lackoffit.html"">
-<meta property=""og:description"" content=""5.1 Individual heterogeneity Cubaynes et al. (2010), Gimenez and Choquet (2010), and Turek, Wehrhahn, and Gimenez (2021). Example wolf. Traiter label switching avec constraint dans Nimble. Aussi..."">
+<meta property=""og:description"" content=""9.1 Individual heterogeneity Cubaynes et al. (2010), Gimenez and Choquet (2010), and Turek, Wehrhahn, and Gimenez (2021). Example wolf. Traiter label switching avec constraint dans Nimble. Aussi..."">
 <meta name=""twitter:card"" content=""summary"">
-<meta name=""twitter:title"" content=""Chapter 5 Lack of fit | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta name=""twitter:description"" content=""5.1 Individual heterogeneity Cubaynes et al. (2010), Gimenez and Choquet (2010), and Turek, Wehrhahn, and Gimenez (2021). Example wolf. Traiter label switching avec constraint dans Nimble. Aussi..."">
+<meta name=""twitter:title"" content=""Chapter 9 Lack of fit | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""9.1 Individual heterogeneity Cubaynes et al. (2010), Gimenez and Choquet (2010), and Turek, Wehrhahn, and Gimenez (2021). Example wolf. Traiter label switching avec constraint dans Nimble. Aussi..."">
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -73,16 +74,20 @@ <h1>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
-<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
-<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
-<li><a class=""active"" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">6</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">7</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">8</span> Miscelleanous</a></li>
+<li><a class=""active"" href=""lackoffit.html""><span class=""header-section-number"">9</span> Lack of fit</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
@@ -92,39 +97,39 @@ <h1>
         </div>
       </nav>
 </div>
-  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""lackoffit"" class=""section level1"" number=""5"">
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""lackoffit"" class=""section level1"" number=""9"">
 <h1>
-<span class=""header-section-number"">5</span> Lack of fit<a class=""anchor"" aria-label=""anchor"" href=""#lackoffit""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">9</span> Lack of fit<a class=""anchor"" aria-label=""anchor"" href=""#lackoffit""><i class=""fas fa-link""></i></a>
 </h1>
-<div id=""individual-heterogeneity"" class=""section level2"" number=""5.1"">
+<div id=""individual-heterogeneity"" class=""section level2"" number=""9.1"">
 <h2>
-<span class=""header-section-number"">5.1</span> Individual heterogeneity<a class=""anchor"" aria-label=""anchor"" href=""#individual-heterogeneity""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">9.1</span> Individual heterogeneity<a class=""anchor"" aria-label=""anchor"" href=""#individual-heterogeneity""><i class=""fas fa-link""></i></a>
 </h2>
 <p><span class=""citation"">Cubaynes et al. (<a href=""references.html#ref-cubaynes_importance_2010"">2010</a>)</span>, <span class=""citation"">Gimenez and Choquet (<a href=""references.html#ref-gimenez_individual_2010"">2010</a>)</span>, and <span class=""citation"">Turek, Wehrhahn, and Gimenez (<a href=""references.html#ref-turek_bayesian_2021"">2021</a>)</span>. Example wolf. Traiter label switching avec constraint dans Nimble. Aussi go fully non-parametric, w/ Daniel‚Äôs paper. Ou bien exercice mouettes des workshops E-SURGE?</p>
 </div>
-<div id=""trap-dep"" class=""section level2"" number=""5.2"">
+<div id=""trap-dep"" class=""section level2"" number=""9.2"">
 <h2>
-<span class=""header-section-number"">5.2</span> Trap dep<a class=""anchor"" aria-label=""anchor"" href=""#trap-dep""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">9.2</span> Trap dep<a class=""anchor"" aria-label=""anchor"" href=""#trap-dep""><i class=""fas fa-link""></i></a>
 </h2>
 <p>Papier Roger &amp; Ana. Sur dipper ? Add example for trap-dependence w/ time individual covariate.</p>
 <p><a href=""https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0032666"" class=""uri"">https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0032666</a></p>
 </div>
-<div id=""transience"" class=""section level2"" number=""5.3"">
+<div id=""transience"" class=""section level2"" number=""9.3"">
 <h2>
-<span class=""header-section-number"">5.3</span> Transience<a class=""anchor"" aria-label=""anchor"" href=""#transience""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">9.3</span> Transience<a class=""anchor"" aria-label=""anchor"" href=""#transience""><i class=""fas fa-link""></i></a>
 </h2>
 <p>Multievent treatment.</p>
 <p><a href=""https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0222241"" class=""uri"">https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0222241</a></p>
 </div>
-<div id=""temporary-emigration"" class=""section level2"" number=""5.4"">
+<div id=""temporary-emigration"" class=""section level2"" number=""9.4"">
 <h2>
-<span class=""header-section-number"">5.4</span> Temporary emigration<a class=""anchor"" aria-label=""anchor"" href=""#temporary-emigration""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">9.4</span> Temporary emigration<a class=""anchor"" aria-label=""anchor"" href=""#temporary-emigration""><i class=""fas fa-link""></i></a>
 </h2>
 <p>papier Michael.</p>
 </div>
-<div id=""memory-model"" class=""section level2"" number=""5.5"">
+<div id=""memory-model"" class=""section level2"" number=""9.5"">
 <h2>
-<span class=""header-section-number"">5.5</span> Memory model<a class=""anchor"" aria-label=""anchor"" href=""#memory-model""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">9.5</span> Memory model<a class=""anchor"" aria-label=""anchor"" href=""#memory-model""><i class=""fas fa-link""></i></a>
 </h2>
 
 </div>
@@ -133,17 +138,17 @@ <h2>
 
 
   <div class=""chapter-nav"">
-<div class=""prev""><a href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></div>
-<div class=""next""><a href=""introduction-4.html"">Introduction</a></div>
+<div class=""prev""><a href=""misc.html""><span class=""header-section-number"">8</span> Miscelleanous</a></div>
+<div class=""next""><a href=""introduction-8.html"">Introduction</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
       <ul class=""nav navbar-nav"">
-<li><a class=""nav-link"" href=""#lackoffit""><span class=""header-section-number"">5</span> Lack of fit</a></li>
-<li><a class=""nav-link"" href=""#individual-heterogeneity""><span class=""header-section-number"">5.1</span> Individual heterogeneity</a></li>
-<li><a class=""nav-link"" href=""#trap-dep""><span class=""header-section-number"">5.2</span> Trap dep</a></li>
-<li><a class=""nav-link"" href=""#transience""><span class=""header-section-number"">5.3</span> Transience</a></li>
-<li><a class=""nav-link"" href=""#temporary-emigration""><span class=""header-section-number"">5.4</span> Temporary emigration</a></li>
-<li><a class=""nav-link"" href=""#memory-model""><span class=""header-section-number"">5.5</span> Memory model</a></li>
+<li><a class=""nav-link"" href=""#lackoffit""><span class=""header-section-number"">9</span> Lack of fit</a></li>
+<li><a class=""nav-link"" href=""#individual-heterogeneity""><span class=""header-section-number"">9.1</span> Individual heterogeneity</a></li>
+<li><a class=""nav-link"" href=""#trap-dep""><span class=""header-section-number"">9.2</span> Trap dep</a></li>
+<li><a class=""nav-link"" href=""#transience""><span class=""header-section-number"">9.3</span> Transience</a></li>
+<li><a class=""nav-link"" href=""#temporary-emigration""><span class=""header-section-number"">9.4</span> Temporary emigration</a></li>
+<li><a class=""nav-link"" href=""#memory-model""><span class=""header-section-number"">9.5</span> Memory model</a></li>
 </ul>
 
       <div class=""book-extra"">

---FILE: docs/libs/kePrint-0.0.1/kePrint.js---
@@ -0,0 +1,8 @@
+$(document).ready(function(){
+    if (typeof $('[data-toggle=""tooltip""]').tooltip === 'function') {
+        $('[data-toggle=""tooltip""]').tooltip();
+    }
+    if ($('[data-toggle=""popover""]').popover === 'function') {
+        $('[data-toggle=""popover""]').popover();
+    }
+});

---FILE: docs/libs/lightable-0.0.1/lightable.css---
@@ -0,0 +1,272 @@
+/*!
+ * lightable v0.0.1
+ * Copyright 2020 Hao Zhu
+ * Licensed under MIT (https://github.com/haozhu233/kableExtra/blob/master/LICENSE)
+ */
+
+.lightable-minimal {
+  border-collapse: separate;
+  border-spacing: 16px 1px;
+  width: 100%;
+  margin-bottom: 10px;
+}
+
+.lightable-minimal td {
+  margin-left: 5px;
+  margin-right: 5px;
+}
+
+.lightable-minimal th {
+  margin-left: 5px;
+  margin-right: 5px;
+}
+
+.lightable-minimal thead tr:last-child th {
+  border-bottom: 2px solid #00000050;
+  empty-cells: hide;
+
+}
+
+.lightable-minimal tbody tr:first-child td {
+  padding-top: 0.5em;
+}
+
+.lightable-minimal.lightable-hover tbody tr:hover {
+  background-color: #f5f5f5;
+}
+
+.lightable-minimal.lightable-striped tbody tr:nth-child(even) {
+  background-color: #f5f5f5;
+}
+
+.lightable-classic {
+  border-top: 0.16em solid #111111;
+  border-bottom: 0.16em solid #111111;
+  width: 100%;
+  margin-bottom: 10px;
+  margin: 10px 5px;
+}
+
+.lightable-classic tfoot tr td {
+  border: 0;
+}
+
+.lightable-classic tfoot tr:first-child td {
+  border-top: 0.14em solid #111111;
+}
+
+.lightable-classic caption {
+  color: #222222;
+}
+
+.lightable-classic td {
+  padding-left: 5px;
+  padding-right: 5px;
+  color: #222222;
+}
+
+.lightable-classic th {
+  padding-left: 5px;
+  padding-right: 5px;
+  font-weight: normal;
+  color: #222222;
+}
+
+.lightable-classic thead tr:last-child th {
+  border-bottom: 0.10em solid #111111;
+}
+
+.lightable-classic.lightable-hover tbody tr:hover {
+  background-color: #F9EEC1;
+}
+
+.lightable-classic.lightable-striped tbody tr:nth-child(even) {
+  background-color: #f5f5f5;
+}
+
+.lightable-classic-2 {
+  border-top: 3px double #111111;
+  border-bottom: 3px double #111111;
+  width: 100%;
+  margin-bottom: 10px;
+}
+
+.lightable-classic-2 tfoot tr td {
+  border: 0;
+}
+
+.lightable-classic-2 tfoot tr:first-child td {
+  border-top: 3px double #111111;
+}
+
+.lightable-classic-2 caption {
+  color: #222222;
+}
+
+.lightable-classic-2 td {
+  padding-left: 5px;
+  padding-right: 5px;
+  color: #222222;
+}
+
+.lightable-classic-2 th {
+  padding-left: 5px;
+  padding-right: 5px;
+  font-weight: normal;
+  color: #222222;
+}
+
+.lightable-classic-2 tbody tr:last-child td {
+  border-bottom: 3px double #111111;
+}
+
+.lightable-classic-2 thead tr:last-child th {
+  border-bottom: 1px solid #111111;
+}
+
+.lightable-classic-2.lightable-hover tbody tr:hover {
+  background-color: #F9EEC1;
+}
+
+.lightable-classic-2.lightable-striped tbody tr:nth-child(even) {
+  background-color: #f5f5f5;
+}
+
+.lightable-material {
+  min-width: 100%;
+  white-space: nowrap;
+  table-layout: fixed;
+  font-family: Roboto, sans-serif;
+  border: 1px solid #EEE;
+  border-collapse: collapse;
+  margin-bottom: 10px;
+}
+
+.lightable-material tfoot tr td {
+  border: 0;
+}
+
+.lightable-material tfoot tr:first-child td {
+  border-top: 1px solid #EEE;
+}
+
+.lightable-material th {
+  height: 56px;
+  padding-left: 16px;
+  padding-right: 16px;
+}
+
+.lightable-material td {
+  height: 52px;
+  padding-left: 16px;
+  padding-right: 16px;
+  border-top: 1px solid #eeeeee;
+}
+
+.lightable-material.lightable-hover tbody tr:hover {
+  background-color: #f5f5f5;
+}
+
+.lightable-material.lightable-striped tbody tr:nth-child(even) {
+  background-color: #f5f5f5;
+}
+
+.lightable-material.lightable-striped tbody td {
+  border: 0;
+}
+
+.lightable-material.lightable-striped thead tr:last-child th {
+  border-bottom: 1px solid #ddd;
+}
+
+.lightable-material-dark {
+  min-width: 100%;
+  white-space: nowrap;
+  table-layout: fixed;
+  font-family: Roboto, sans-serif;
+  border: 1px solid #FFFFFF12;
+  border-collapse: collapse;
+  margin-bottom: 10px;
+  background-color: #363640;
+}
+
+.lightable-material-dark tfoot tr td {
+  border: 0;
+}
+
+.lightable-material-dark tfoot tr:first-child td {
+  border-top: 1px solid #FFFFFF12;
+}
+
+.lightable-material-dark th {
+  height: 56px;
+  padding-left: 16px;
+  padding-right: 16px;
+  color: #FFFFFF60;
+}
+
+.lightable-material-dark td {
+  height: 52px;
+  padding-left: 16px;
+  padding-right: 16px;
+  color: #FFFFFF;
+  border-top: 1px solid #FFFFFF12;
+}
+
+.lightable-material-dark.lightable-hover tbody tr:hover {
+  background-color: #FFFFFF12;
+}
+
+.lightable-material-dark.lightable-striped tbody tr:nth-child(even) {
+  background-color: #FFFFFF12;
+}
+
+.lightable-material-dark.lightable-striped tbody td {
+  border: 0;
+}
+
+.lightable-material-dark.lightable-striped thead tr:last-child th {
+  border-bottom: 1px solid #FFFFFF12;
+}
+
+.lightable-paper {
+  width: 100%;
+  margin-bottom: 10px;
+  color: #444;
+}
+
+.lightable-paper tfoot tr td {
+  border: 0;
+}
+
+.lightable-paper tfoot tr:first-child td {
+  border-top: 1px solid #00000020;
+}
+
+.lightable-paper thead tr:last-child th {
+  color: #666;
+  vertical-align: bottom;
+  border-bottom: 1px solid #00000020;
+  line-height: 1.15em;
+  padding: 10px 5px;
+}
+
+.lightable-paper td {
+  vertical-align: middle;
+  border-bottom: 1px solid #00000010;
+  line-height: 1.15em;
+  padding: 7px 5px;
+}
+
+.lightable-paper.lightable-hover tbody tr:hover {
+  background-color: #F9EEC1;
+}
+
+.lightable-paper.lightable-striped tbody tr:nth-child(even) {
+  background-color: #00000008;
+}
+
+.lightable-paper.lightable-striped tbody td {
+  border: 0;
+}
+

---FILE: docs/misc.html---
@@ -4,21 +4,22 @@
 <meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
 <meta charset=""utf-8"">
 <meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<title>Chapter 4 Miscelleanous | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<title>Chapter 8 Miscelleanous | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
 <meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""4.1 Dependence among individuals Culina et al. (2013) and Cubaynes et al. (2021)  4.2 Cause-specific mortalities Fern√°ndez-Chac√≥n et al. (2016) and Ruette et al. (2015)  4.3 Disease dynamics..."">
+<meta name=""description"" content=""8.1 Dependence among individuals Culina et al. (2013) and Cubaynes et al. (2021)  8.2 Cause-specific mortalities Fern√°ndez-Chac√≥n et al. (2016) and Ruette et al. (2015)  8.3 Disease dynamics..."">
 <meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
-<meta property=""og:title"" content=""Chapter 4 Miscelleanous | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:title"" content=""Chapter 8 Miscelleanous | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
 <meta property=""og:type"" content=""book"">
 <meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/misc.html"">
-<meta property=""og:description"" content=""4.1 Dependence among individuals Culina et al. (2013) and Cubaynes et al. (2021)  4.2 Cause-specific mortalities Fern√°ndez-Chac√≥n et al. (2016) and Ruette et al. (2015)  4.3 Disease dynamics..."">
+<meta property=""og:description"" content=""8.1 Dependence among individuals Culina et al. (2013) and Cubaynes et al. (2021)  8.2 Cause-specific mortalities Fern√°ndez-Chac√≥n et al. (2016) and Ruette et al. (2015)  8.3 Disease dynamics..."">
 <meta name=""twitter:card"" content=""summary"">
-<meta name=""twitter:title"" content=""Chapter 4 Miscelleanous | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta name=""twitter:description"" content=""4.1 Dependence among individuals Culina et al. (2013) and Cubaynes et al. (2021)  4.2 Cause-specific mortalities Fern√°ndez-Chac√≥n et al. (2016) and Ruette et al. (2015)  4.3 Disease dynamics..."">
+<meta name=""twitter:title"" content=""Chapter 8 Miscelleanous | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""8.1 Dependence among individuals Culina et al. (2013) and Cubaynes et al. (2021)  8.2 Cause-specific mortalities Fern√°ndez-Chac√≥n et al. (2016) and Ruette et al. (2015)  8.3 Disease dynamics..."">
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -73,16 +74,20 @@ <h1>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
-<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
-<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
-<li><a class=""active"" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
-<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">6</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">7</span> Covariates</a></li>
+<li><a class=""active"" href=""misc.html""><span class=""header-section-number"">8</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">9</span> Lack of fit</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
@@ -92,76 +97,76 @@ <h1>
         </div>
       </nav>
 </div>
-  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""misc"" class=""section level1"" number=""4"">
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""misc"" class=""section level1"" number=""8"">
 <h1>
-<span class=""header-section-number"">4</span> Miscelleanous<a class=""anchor"" aria-label=""anchor"" href=""#misc""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">8</span> Miscelleanous<a class=""anchor"" aria-label=""anchor"" href=""#misc""><i class=""fas fa-link""></i></a>
 </h1>
-<div id=""dependence-among-individuals"" class=""section level2"" number=""4.1"">
+<div id=""dependence-among-individuals"" class=""section level2"" number=""8.1"">
 <h2>
-<span class=""header-section-number"">4.1</span> Dependence among individuals<a class=""anchor"" aria-label=""anchor"" href=""#dependence-among-individuals""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">8.1</span> Dependence among individuals<a class=""anchor"" aria-label=""anchor"" href=""#dependence-among-individuals""><i class=""fas fa-link""></i></a>
 </h2>
 <p><span class=""citation"">Culina et al. (<a href=""references.html#ref-culina_multievent_2013"">2013</a>)</span> and <span class=""citation"">Cubaynes et al. (<a href=""references.html#ref-cubaynes_modeling_2021"">2021</a>)</span></p>
 </div>
-<div id=""cause-specific-mortalities"" class=""section level2"" number=""4.2"">
+<div id=""cause-specific-mortalities"" class=""section level2"" number=""8.2"">
 <h2>
-<span class=""header-section-number"">4.2</span> Cause-specific mortalities<a class=""anchor"" aria-label=""anchor"" href=""#cause-specific-mortalities""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">8.2</span> Cause-specific mortalities<a class=""anchor"" aria-label=""anchor"" href=""#cause-specific-mortalities""><i class=""fas fa-link""></i></a>
 </h2>
 <p><span class=""citation"">Fern√°ndez-Chac√≥n et al. (<a href=""references.html#ref-fernandez-chacon_causes_2016"">2016</a>)</span> and <span class=""citation"">Ruette et al. (<a href=""references.html#ref-ruette_comparative_2015"">2015</a>)</span></p>
 </div>
-<div id=""disease-dynamics"" class=""section level2"" number=""4.3"">
+<div id=""disease-dynamics"" class=""section level2"" number=""8.3"">
 <h2>
-<span class=""header-section-number"">4.3</span> Disease dynamics<a class=""anchor"" aria-label=""anchor"" href=""#disease-dynamics""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">8.3</span> Disease dynamics<a class=""anchor"" aria-label=""anchor"" href=""#disease-dynamics""><i class=""fas fa-link""></i></a>
 </h2>
 <p><span class=""citation"">Marescot et al. (<a href=""references.html#ref-MarescotEtAl2018"">2018</a>)</span> and <span class=""citation"">Santoro et al. (<a href=""references.html#ref-santoro_multi-event_2014"">2014</a>)</span>. House finch as well.</p>
 </div>
-<div id=""combine-live-captures-and-dead-recoveries"" class=""section level2"" number=""4.4"">
+<div id=""combine-live-captures-and-dead-recoveries"" class=""section level2"" number=""8.4"">
 <h2>
-<span class=""header-section-number"">4.4</span> Combine live captures and dead recoveries<a class=""anchor"" aria-label=""anchor"" href=""#combine-live-captures-and-dead-recoveries""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">8.4</span> Combine live captures and dead recoveries<a class=""anchor"" aria-label=""anchor"" href=""#combine-live-captures-and-dead-recoveries""><i class=""fas fa-link""></i></a>
 </h2>
 <p>Combine live recapture w/ dead recoveries by <a href=""https://www.tandfonline.com/doi/pdf/10.1080/00063659909477230"">Lebreton et al.¬†(1999)</a> and go spatial to account for emigration <a href=""https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/12-0124.1"">Gilroy et al.¬†(2012)</a> and <a href=""https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12134"">Schaub &amp; Royle (2014)</a>.</p>
 </div>
-<div id=""stopover-duration"" class=""section level2"" number=""4.5"">
+<div id=""stopover-duration"" class=""section level2"" number=""8.5"">
 <h2>
-<span class=""header-section-number"">4.5</span> Stopover duration<a class=""anchor"" aria-label=""anchor"" href=""#stopover-duration""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">8.5</span> Stopover duration<a class=""anchor"" aria-label=""anchor"" href=""#stopover-duration""><i class=""fas fa-link""></i></a>
 </h2>
 <p>A voir? Papier de Guerin et al.¬†(2017)</p>
 </div>
-<div id=""prior-info"" class=""section level2"" number=""4.6"">
+<div id=""prior-info"" class=""section level2"" number=""8.6"">
 <h2>
-<span class=""header-section-number"">4.6</span> Prior info<a class=""anchor"" aria-label=""anchor"" href=""#prior-info""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">8.6</span> Prior info<a class=""anchor"" aria-label=""anchor"" href=""#prior-info""><i class=""fas fa-link""></i></a>
 </h2>
 <p>Papier McCarthy and Pipper. Cf le code et tout dans le fichier leftover. Ajouter figure avec 3, 4 et 5 ans seulement.</p>
 <p>The example on how to incorporate prior information is in <a href=""https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-2664.2005.01101.x"">McCarthy and Masters (2005)</a>.</p>
 </div>
-<div id=""posterior-predictive-check"" class=""section level2"" number=""4.7"">
+<div id=""posterior-predictive-check"" class=""section level2"" number=""8.7"">
 <h2>
-<span class=""header-section-number"">4.7</span> Posterior predictive check<a class=""anchor"" aria-label=""anchor"" href=""#posterior-predictive-check""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">8.7</span> Posterior predictive check<a class=""anchor"" aria-label=""anchor"" href=""#posterior-predictive-check""><i class=""fas fa-link""></i></a>
 </h2>
 <p>M-array avec Paganin et de Valpine. Puis IH avec Chambert. Et aussi geometric avec Conn et al.¬†</p>
 </div>
-<div id=""others"" class=""section level2"" number=""4.8"">
+<div id=""others"" class=""section level2"" number=""8.8"">
 <h2>
-<span class=""header-section-number"">4.8</span> Others<a class=""anchor"" aria-label=""anchor"" href=""#others""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">8.8</span> Others<a class=""anchor"" aria-label=""anchor"" href=""#others""><i class=""fas fa-link""></i></a>
 </h2>
 <p>Multispecies. Phylogeny. Path analysis, SEM. Exemple Nina loup hybrides, ou pr√©valence disease, ou sex-ratio, ou la LRS comme dans papier TPB. Manque s√ªrement qqch sur l‚Äôint√©r√™t des simulations, en faire un CS? V√©rifier que les posterior predictive checks sont trait√©s quelque part.</p>
 
 </div>
 </div>
   <div class=""chapter-nav"">
-<div class=""prev""><a href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></div>
-<div class=""next""><a href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></div>
+<div class=""prev""><a href=""covariates.html""><span class=""header-section-number"">7</span> Covariates</a></div>
+<div class=""next""><a href=""lackoffit.html""><span class=""header-section-number"">9</span> Lack of fit</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
       <ul class=""nav navbar-nav"">
-<li><a class=""nav-link"" href=""#misc""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
-<li><a class=""nav-link"" href=""#dependence-among-individuals""><span class=""header-section-number"">4.1</span> Dependence among individuals</a></li>
-<li><a class=""nav-link"" href=""#cause-specific-mortalities""><span class=""header-section-number"">4.2</span> Cause-specific mortalities</a></li>
-<li><a class=""nav-link"" href=""#disease-dynamics""><span class=""header-section-number"">4.3</span> Disease dynamics</a></li>
-<li><a class=""nav-link"" href=""#combine-live-captures-and-dead-recoveries""><span class=""header-section-number"">4.4</span> Combine live captures and dead recoveries</a></li>
-<li><a class=""nav-link"" href=""#stopover-duration""><span class=""header-section-number"">4.5</span> Stopover duration</a></li>
-<li><a class=""nav-link"" href=""#prior-info""><span class=""header-section-number"">4.6</span> Prior info</a></li>
-<li><a class=""nav-link"" href=""#posterior-predictive-check""><span class=""header-section-number"">4.7</span> Posterior predictive check</a></li>
-<li><a class=""nav-link"" href=""#others""><span class=""header-section-number"">4.8</span> Others</a></li>
+<li><a class=""nav-link"" href=""#misc""><span class=""header-section-number"">8</span> Miscelleanous</a></li>
+<li><a class=""nav-link"" href=""#dependence-among-individuals""><span class=""header-section-number"">8.1</span> Dependence among individuals</a></li>
+<li><a class=""nav-link"" href=""#cause-specific-mortalities""><span class=""header-section-number"">8.2</span> Cause-specific mortalities</a></li>
+<li><a class=""nav-link"" href=""#disease-dynamics""><span class=""header-section-number"">8.3</span> Disease dynamics</a></li>
+<li><a class=""nav-link"" href=""#combine-live-captures-and-dead-recoveries""><span class=""header-section-number"">8.4</span> Combine live captures and dead recoveries</a></li>
+<li><a class=""nav-link"" href=""#stopover-duration""><span class=""header-section-number"">8.5</span> Stopover duration</a></li>
+<li><a class=""nav-link"" href=""#prior-info""><span class=""header-section-number"">8.6</span> Prior info</a></li>
+<li><a class=""nav-link"" href=""#posterior-predictive-check""><span class=""header-section-number"">8.7</span> Posterior predictive check</a></li>
+<li><a class=""nav-link"" href=""#others""><span class=""header-section-number"">8.8</span> Others</a></li>
 </ul>
 
       <div class=""book-extra"">

---FILE: docs/preface.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -73,16 +74,20 @@ <h1>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
-<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
-<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
-<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">6</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">7</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">8</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">9</span> Lack of fit</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>

---FILE: docs/reference-keys.txt---
@@ -13,6 +13,16 @@ fig:burnin
 fig:bgr
 fig:tracechainlength
 fig:acfchainlength
+fig:nimblelogo
+fig:dag-survival
+fig:traceown
+fig:treillis-viterbi
+fig:viterbiaveragecompute
+fig:viterbicomputeaverage
+fig:marking
+fig:pixdipper
+fig:unnamed-chunk-293
+fig:inits
 crashcourse
 introduction-1
 bayes-theorem
@@ -28,11 +38,106 @@ chain-length
 what-if-you-have-issues-of-convergence
 summary
 suggested-reading
+intronimble
+introduction-2
+what-is-nimble
+start-nimble
+functions-in-nimble
+nimble-functions
+callrfninnimble
+user-defined-distributions
+under-the-hood
+mcmc-samplers
+change-sampler
+user-defined-samplers
+tips-and-tricks
+precision-vs-standard-deviation
+indexing
+faster-compilation
+updating-mcmc-chains
+reproducibility
+parallelization
+incomplete-initialization
+vectorization
+summary-1
+suggested-reading-1
+hmmcapturerecapture
+introduction-3
+longitudinal-data
+a-markov-model-for-longitudinal-data
+assumptions
+transition-matrix
+initial-states
+likelihood
+example
+bayesian-formulation
+nimble-implementation
+hidden-markov-models
+capturerecapturedata
+observation-matrix
+hidden-markov-model
+likelihoodhmm
+fittinghmmnimble
+marginalization
+brute-force-approach
+forward-algorithm
+nimble-implementation-1
+pooled-likelihood
+decoding
+viterbi-theory
+implementation
+compute-average
+average-first-compute-after
+summary-2
+suggested-reading-2
+survival
+introduction-5
+the-cormack-jolly-seber-cjs-model
+capture-recapture-data
+fitting-the-cjs-model-to-the-dipper-data-with-nimble
+cjs-model-derivatives
+waic
+gof
+posterior-predictive-checks
+classical-tests
+design-considerations
+covariates
+temporal-covariates
+discrete
+continuous
+individual-covariates
+discrete-1
+continuous-1
+several-covariates
+random-effects
+individual-time-varying-covariates
+summary-3
+suggested-reading-3
+dispersal
+introduction-6
+the-arnason-schwarz-as-model
+multisite-capture-recapture-data
+biological-inference
+fitting-the-as-model-to-the-geese-data-with-nimble
+what-if-there-are-more-than-2-sites
+dirichlet-prior
+multinomial-logit
+sites-may-be-states
+examples
+sooty-shearwaters
+model
+issue-of-local-minima
+uncertainty
+examples-1
+breeding-status
+model-1
+nimble-implementation-2
+summary-4
+suggested-reading-4
 tradeoffs
 access-to-reproduction
 tradeoffs-1
 breeding-dynamics
-covariates
 missing-values
 nonlinearities
 covariate-selection

---FILE: docs/references.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -73,16 +74,20 @@ <h1>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
-<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
-<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
-<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">6</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">7</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">8</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">9</span> Lack of fit</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class=""active"" href=""references.html"">References</a></li>
 </ul>
@@ -192,6 +197,21 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 
 
 
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
 
 
 

---FILE: docs/take-home-messages.html---
@@ -18,7 +18,8 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -73,16 +74,20 @@ <h1>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
-<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
-<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
-<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">6</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">7</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">8</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">9</span> Lack of fit</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
 <li><a class=""active"" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
@@ -171,7 +176,7 @@ <h1>Take-home messages<a class=""anchor"" aria-label=""anchor"" href=""#take-home-mes
 
 </div>
   <div class=""chapter-nav"">
-<div class=""prev""><a href=""introduction-4.html"">Introduction</a></div>
+<div class=""prev""><a href=""introduction-8.html"">Introduction</a></div>
 <div class=""next""><a href=""references.html"">References</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>

---FILE: docs/tradeoffs.html---
@@ -4,21 +4,22 @@
 <meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
 <meta charset=""utf-8"">
 <meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<title>Chapter 2 Life history | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<title>Chapter 6 Life history | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
 <meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""2.1 Access to reproduction Flamants.  2.2 Tradeoffs Morano et al. (2013), Shefferson et al. (2003), and Cruz-Flores et al. (n.d.)  2.3 Breeding dynamics Pradel, Choquet, and B√©chet (2012), Desprez..."">
+<meta name=""description"" content=""6.1 Access to reproduction Flamants.  6.2 Tradeoffs Morano et al. (2013), Shefferson et al. (2003), and Cruz-Flores et al. (n.d.)  6.3 Breeding dynamics Pradel, Choquet, and B√©chet (2012), Desprez..."">
 <meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
-<meta property=""og:title"" content=""Chapter 2 Life history | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:title"" content=""Chapter 6 Life history | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
 <meta property=""og:type"" content=""book"">
 <meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/tradeoffs.html"">
-<meta property=""og:description"" content=""2.1 Access to reproduction Flamants.  2.2 Tradeoffs Morano et al. (2013), Shefferson et al. (2003), and Cruz-Flores et al. (n.d.)  2.3 Breeding dynamics Pradel, Choquet, and B√©chet (2012), Desprez..."">
+<meta property=""og:description"" content=""6.1 Access to reproduction Flamants.  6.2 Tradeoffs Morano et al. (2013), Shefferson et al. (2003), and Cruz-Flores et al. (n.d.)  6.3 Breeding dynamics Pradel, Choquet, and B√©chet (2012), Desprez..."">
 <meta name=""twitter:card"" content=""summary"">
-<meta name=""twitter:title"" content=""Chapter 2 Life history | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta name=""twitter:description"" content=""2.1 Access to reproduction Flamants.  2.2 Tradeoffs Morano et al. (2013), Shefferson et al. (2003), and Cruz-Flores et al. (n.d.)  2.3 Breeding dynamics Pradel, Choquet, and B√©chet (2012), Desprez..."">
+<meta name=""twitter:title"" content=""Chapter 6 Life history | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""6.1 Access to reproduction Flamants.  6.2 Tradeoffs Morano et al. (2013), Shefferson et al. (2003), and Cruz-Flores et al. (n.d.)  6.3 Breeding dynamics Pradel, Choquet, and B√©chet (2012), Desprez..."">
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
     
     div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
   </style>
@@ -73,16 +74,20 @@ <h1>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
-<li><a class=""active"" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
-<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
-<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
-<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li><a class=""active"" href=""tradeoffs.html""><span class=""header-section-number"">6</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">7</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">8</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">9</span> Lack of fit</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
@@ -92,40 +97,40 @@ <h1>
         </div>
       </nav>
 </div>
-  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""tradeoffs"" class=""section level1"" number=""2"">
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""tradeoffs"" class=""section level1"" number=""6"">
 <h1>
-<span class=""header-section-number"">2</span> Life history<a class=""anchor"" aria-label=""anchor"" href=""#tradeoffs""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">6</span> Life history<a class=""anchor"" aria-label=""anchor"" href=""#tradeoffs""><i class=""fas fa-link""></i></a>
 </h1>
-<div id=""access-to-reproduction"" class=""section level2"" number=""2.1"">
+<div id=""access-to-reproduction"" class=""section level2"" number=""6.1"">
 <h2>
-<span class=""header-section-number"">2.1</span> Access to reproduction<a class=""anchor"" aria-label=""anchor"" href=""#access-to-reproduction""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">6.1</span> Access to reproduction<a class=""anchor"" aria-label=""anchor"" href=""#access-to-reproduction""><i class=""fas fa-link""></i></a>
 </h2>
 <p>Flamants.</p>
 </div>
-<div id=""tradeoffs-1"" class=""section level2"" number=""2.2"">
+<div id=""tradeoffs-1"" class=""section level2"" number=""6.2"">
 <h2>
-<span class=""header-section-number"">2.2</span> Tradeoffs<a class=""anchor"" aria-label=""anchor"" href=""#tradeoffs-1""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">6.2</span> Tradeoffs<a class=""anchor"" aria-label=""anchor"" href=""#tradeoffs-1""><i class=""fas fa-link""></i></a>
 </h2>
 <p><span class=""citation"">Morano et al. (<a href=""references.html#ref-morano_life-history_2013"">2013</a>)</span>, <span class=""citation"">Shefferson et al. (<a href=""references.html#ref-shefferson_life_2003"">2003</a>)</span>, and <span class=""citation"">Cruz-Flores et al. (<a href=""references.html#ref-cruz-flores_sex-specific_nodate"">n.d.</a>)</span></p>
 </div>
-<div id=""breeding-dynamics"" class=""section level2"" number=""2.3"">
+<div id=""breeding-dynamics"" class=""section level2"" number=""6.3"">
 <h2>
-<span class=""header-section-number"">2.3</span> Breeding dynamics<a class=""anchor"" aria-label=""anchor"" href=""#breeding-dynamics""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">6.3</span> Breeding dynamics<a class=""anchor"" aria-label=""anchor"" href=""#breeding-dynamics""><i class=""fas fa-link""></i></a>
 </h2>
 <p><span class=""citation"">Pradel, Choquet, and B√©chet (<a href=""references.html#ref-pradel_breeding_2012"">2012</a>)</span>, <span class=""citation"">Desprez et al. (<a href=""references.html#ref-desprez_now_2011"">2011</a>)</span>, <span class=""citation"">Desprez et al. (<a href=""references.html#ref-desprez_known_2013"">2013</a>)</span>, and <span class=""citation"">Pacoureau et al. (<a href=""references.html#ref-pacoureau_population_2019"">2019</a>)</span></p>
 
 </div>
 </div>
   <div class=""chapter-nav"">
-<div class=""prev""><a href=""introduction-3.html"">Introduction</a></div>
-<div class=""next""><a href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></div>
+<div class=""prev""><a href=""introduction-7.html"">Introduction</a></div>
+<div class=""next""><a href=""covariates.html""><span class=""header-section-number"">7</span> Covariates</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
       <ul class=""nav navbar-nav"">
-<li><a class=""nav-link"" href=""#tradeoffs""><span class=""header-section-number"">2</span> Life history</a></li>
-<li><a class=""nav-link"" href=""#access-to-reproduction""><span class=""header-section-number"">2.1</span> Access to reproduction</a></li>
-<li><a class=""nav-link"" href=""#tradeoffs-1""><span class=""header-section-number"">2.2</span> Tradeoffs</a></li>
-<li><a class=""nav-link"" href=""#breeding-dynamics""><span class=""header-section-number"">2.3</span> Breeding dynamics</a></li>
+<li><a class=""nav-link"" href=""#tradeoffs""><span class=""header-section-number"">6</span> Life history</a></li>
+<li><a class=""nav-link"" href=""#access-to-reproduction""><span class=""header-section-number"">6.1</span> Access to reproduction</a></li>
+<li><a class=""nav-link"" href=""#tradeoffs-1""><span class=""header-section-number"">6.2</span> Tradeoffs</a></li>
+<li><a class=""nav-link"" href=""#breeding-dynamics""><span class=""header-section-number"">6.3</span> Breeding dynamics</a></li>
 </ul>
 
       <div class=""book-extra"">",True,True,Rendering / Conversion,6
oliviergimenez,banana-book,81e7f06837b4162f009f92f1e4338b4331e38f11,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2023-08-14T06:19:47Z,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2023-08-14T06:19:47Z,Debug issue w/ figures (un-ignore docs/).,_bookdown_files/banana-book_files/figure-html/acfchainlength-1.png;_bookdown_files/banana-book_files/figure-html/betadistribution-1.png;_bookdown_files/banana-book_files/figure-html/bgr-1.png;_bookdown_files/banana-book_files/figure-html/binlik-1.png;_bookdown_files/banana-book_files/figure-html/burnin-1.png;_bookdown_files/banana-book_files/figure-html/chain-1.png;_bookdown_files/banana-book_files/figure-html/compar-1.png;_bookdown_files/banana-book_files/figure-html/longchain-1.png;_bookdown_files/banana-book_files/figure-html/numapprox-1.png;_bookdown_files/banana-book_files/figure-html/tracechainlength-1.png;_bookdown_files/banana-book_files/figure-html/twochains-1.png;banana-book.Rmd;docs/404.html;docs/about-the-author.html;docs/banana-book_files/figure-html/acfchainlength-1.png;docs/banana-book_files/figure-html/betadistribution-1.png;docs/banana-book_files/figure-html/bgr-1.png;docs/banana-book_files/figure-html/binlik-1.png;docs/banana-book_files/figure-html/burnin-1.png;docs/banana-book_files/figure-html/chain-1.png;docs/banana-book_files/figure-html/compar-1.png;docs/banana-book_files/figure-html/longchain-1.png;docs/banana-book_files/figure-html/numapprox-1.png;docs/banana-book_files/figure-html/tracechainlength-1.png;docs/banana-book_files/figure-html/twochains-1.png;docs/covariates.html;docs/crashcourse.html;docs/images/amazing-thomas-bayes-illustration.jpg;docs/images/bayes_neon.jpeg;docs/images/metropolis.png;docs/images/traceplotMCMC.gif;docs/index.html;docs/introduction-2.html;docs/introduction-3.html;docs/introduction-4.html;docs/introduction.html;docs/lackoffit.html;docs/libs/bootstrap-4.6.0/bootstrap.bundle.min.js;docs/libs/bootstrap-4.6.0/bootstrap.min.css;docs/libs/bootstrap-4.6.0/fonts/bootstrap/glyphicons-halflings-regular.eot;docs/libs/bootstrap-4.6.0/fonts/bootstrap/glyphicons-halflings-regular.svg;docs/libs/bootstrap-4.6.0/fonts/bootstrap/glyphicons-halflings-regular.ttf;docs/libs/bootstrap-4.6.0/fonts/bootstrap/glyphicons-halflings-regular.woff;docs/libs/bootstrap-4.6.0/fonts/bootstrap/glyphicons-halflings-regular.woff2;docs/libs/bs3compat-0.5.0/bs3compat.js;docs/libs/bs3compat-0.5.0/tabs.js;docs/libs/bs3compat-0.5.0/transition.js;docs/libs/bs4_book-1.0.0/bs4_book.css;docs/libs/bs4_book-1.0.0/bs4_book.js;docs/libs/jquery-3.6.0/jquery-3.6.0.min.js;docs/misc.html;docs/preface.html;docs/reference-keys.txt;docs/references.html;docs/search.json;docs/take-home-messages.html;docs/tradeoffs.html,True,False,True,False,4632,1410,6042,"---FILE: banana-book.Rmd---
@@ -1,1410 +0,0 @@
----
-title: ""Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models""
-subtitle: ""Theory and Case Studies in R""
-author: ""Olivier Gimenez""
-date: ""`r Sys.Date()`""
-documentclass: krantz
-bibliography: [book.bib]
-#biblio-style: apalike
-link-citations: yes
-colorlinks: yes
-lot: yes
-lof: yes
-fontsize: 12pt
-site: bookdown::bookdown_site
-description: ""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R.""
-url: 'https\://oliviergimenez.github.io/bayesian-cr-workshop/'
-github-repo: oliviergimenez/banana-book
-header-includes: 
-  - \usepackage{tikz}
-  - \usepackage{pgfplots}
-  - \usepackage{blkarray}
----
-```{r include=FALSE, cache=FALSE}
-# packages
-library(tidyverse)
-theme_set(theme_light())
-library(nimble)
-library(MCMCvis)
-library(magick)
-library(pdftools)
-library(wesanderson)
-library(RColorBrewer)
-library(patchwork)
-library(nimbleEcology)
-library(basicMCMCplots)
-
-# R options
-options(width = 60)
-
-# chunk options
-knitr::opts_chunk$set(
-  comment = ""##"",
-  collapse = TRUE,
-  warning = FALSE,
-  message = FALSE
-  )
-```
-
-```{r setup, include=FALSE}
-options(
-#  htmltools.dir.version = FALSE, 
-  formatR.indent = 2,
-  width = 55, 
-  digits = 4, 
-  warnPartialMatchAttr = FALSE, 
-  warnPartialMatchDollar = FALSE
-)
-```
-
-# Welcome {-}
-
-<!-- bookdown::render_book(""index.Rmd"", ""bookdown::pdf_book"") -->
-
-Welcome to the online version of the book *Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R*. <!-- The book is also available in [PDF format](https://github.com/oliviergimenez/banana-book/raw/master/docs/bayesHMMcapturerecapture.pdf). -->
-
-The HMM framework has gained much attention in the ecological literature over the last decade, and has been suggested as a general modelling framework for the demography of plant and animal populations. In particular, HMMs are increasingly used to analyse capture-recapture data and estimate key population parameters (e.g., survival, dispersal, recruitment or abundance) with applications in all fields of ecology. 
-
-In parallel, Bayesian statistics is well established and fast growing in ecology and related disciplines, because it resonates with scientific reasoning and allows accommodating uncertainty smoothly. The popularity of Bayesian statistics also comes from the availability of free pieces of software (WinBUGS, OpenBUGS, JAGS, Stan, NIMBLE) that allow practitioners to code their own analyses.
-
-This book offers a Bayesian treatment of HMMs applied to capture-recapture data. You will learn to use the R package NIMBLE which is seen by many as the future of Bayesian statistical ecology to deal with complex models and/or big data. An important part of the book consists in case studies presented in a tutorial style to abide by the ‚Äúlearning by doing‚Äù philosophy.
-
-I'm currently writing this book, and I welcome any feedback. You may raise an issue [here](https://github.com/oliviergimenez/banana-book/issues), amend directly the R Markdown file that generated the page you're reading by clicking on the 'Edit this page' icon in the right panel, or [email me](mailto:olivier.gimenez@cefe.cnrs.fr). Many thanks!
-
-Olivier Gimenez. Written in Montpellier, France and Athens, Greece. 
-Last updated: `r Sys.setlocale(""LC_TIME"", ""C""); format(Sys.Date(), ""%B %d, %Y"")`
-
-## License {-}
-
-The online version of this book is licensed under the [Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License](http://creativecommons.org/licenses/by-nc-nd/4.0/). 
-
-The code is public domain, licensed under [Creative Commons CC0 1.0 Universal (CC0 1.0)](https://creativecommons.org/publicdomain/zero/1.0/).
-
-
-<!--chapter:end:index.Rmd-->
-
-```{r include=FALSE, cache=FALSE}
-# packages
-library(tidyverse)
-theme_set(theme_light())
-library(nimble)
-library(MCMCvis)
-library(magick)
-library(pdftools)
-library(wesanderson)
-library(RColorBrewer)
-library(patchwork)
-library(nimbleEcology)
-library(basicMCMCplots)
-
-# R options
-options(width = 60)
-
-# chunk options
-knitr::opts_chunk$set(
-  comment = ""##"",
-  collapse = TRUE,
-  warning = FALSE,
-  message = FALSE
-  )
-```
-# Preface {-}
-
-## Why this book? {-}
-
-**To be completed.** Why and what of capture-recapture data and models, with fields of application.^[Watch out nice Johnny Ball's video https://www.youtube.com/watch?v=tyX79mPm2xY.] Brief history of capture-recapture, with switch to state-space/hidden Markov model (HMM) formulation. Flexibility of HMM to decompose complex problems in smaller pieces that are easier to understand, model and analyse. From satellite guidance to conservation of endangered species. Why Bayes? Also three of my fav research topics -- capture-recapture, HMM and Bayes statistics -- let's enjoy this great cocktail together. 
-
-## Who should read this book? {-}
-
-This book is aimed at beginners who're comfortable using R and write basic code (including loops), as well as connoisseurs of capture-recapture who'd like to tap into the power of the Bayesian side of statistics. For both audiences, thinking in the HMM framework will help you in confidently building models and make the most of your capture-recapture data. 
-
-## What will you learn? {-}
-
-The book is divided into five parts. The first part is aimed at getting you up-to-speed with Bayesian statistics, NIMBLE, and hidden Markov models. The second part will teach you all about capture-recapture models for open populations, with reproducible R code to ease the learning process. In the third part, we will focus on issues in inferring states (dealing with uncertainty in assignment, modelling waiting time distribution). The fourth part provides real-world case studies from the scientific literature that you can reproduce using material covered in previous chapters. These problems can either i) be used to cement and deepen your understanding of methods and models, ii) be adapted for your own purpose, or iii) serve as teaching projects. The fifth and last chapter closes the book with take-home messages and recommendations, a list of frequently asked questions and references cited in the book. **Likely to be amended after feedbacks.**
-
-## What won't you learn? {-}
-
-There is hardly any maths in this book. The equations I use are either simple enough to be understood without a background in maths, or can be skipped without prejudice. I do not cover Bayesian statistics or even hidden Markov models fully, I provide just what you need to work with capture-recapture data. If you are interested in knowing more about these topics, hopefully the section Suggested reading at the end of each chapter will put you in the right direction. There are also a number of important topics specific to capture-recapture that I do not cover, including closed-population capture-recapture models [@WilliamsEtAl2002], and spatial capture-recapture models [@RoyleEtAl2013book]. These models can be treated as HMMs, but for now the usual formulation is just fine.  **There will be spatial considerations in the Covariates chapter w/ splines and CAR. I'm not sure yet about SCR models (R. Glennie's Biometrics paper on HMMs and open pop SCR will not be easy to Bayes transform and implement in NIMBLE).**
-
-## Prerequisites {-}
-
-This book uses primarily the R package NIMBLE, so you need to install at least R and NIMBLE. A bunch of other R packages are used. You can install them all at once by running:
-
-```{r, echo = FALSE, cache = FALSE}
-deps <- desc::desc_get_deps()
-pkgs <- sort(deps$package[deps$type == ""Imports""])
-pkgs2 <- strwrap(paste(encodeString(pkgs, quote = '""'), collapse = "", ""), exdent = 2)
-install <- paste0(
-  ""install.packages(c(\n  "", 
-  paste(pkgs2, ""\n"", collapse = """"), 
-  ""))""
-)
-```
-
-```{r code = install, eval = FALSE}
-```
-
-## Acknowledgements {-}
-
-**To be completed.**
-
-## How this book was written {-}
-
-I am writing this book in [RStudio](http://www.rstudio.com/ide/) using [bookdown](http://bookdown.org/). The [book website](https://oliviergimenez.github.io/banana-book) is hosted with [GitHub Pages](https://pages.github.com/), and automatically updated after every push by [Github Actions](https://github.com/features/actions). The source is available from [GitHub](https://github.com/oliviergimenez/banana-book).
-
-The version of the book you're reading was built with `r R.version.string` and the following packages:
-
-```{r, echo = FALSE, results=""asis""}
-pkgs <- sessioninfo::package_info(pkgs, dependencies = FALSE)
-df <- tibble(
-  package = pkgs$package,
-  version = pkgs$ondiskversion,
-  source = gsub(""@"", ""\\\\@"", pkgs$source)
-)
-knitr::kable(df, format = ""markdown"")
-```
-
-```{r, echo = FALSE}
-ruler <- function(width = getOption(""width"")) {
-  x <- seq_len(width)
-  y <- dplyr::case_when(
-    x %% 10 == 0 ~ as.character((x %/% 10) %% 10),
-    x %% 5 == 0  ~ ""+"",
-    TRUE         ~ ""-""
-  )
-  cat(y, ""\n"", sep = """")
-  cat(x %% 10, ""\n"", sep = """")
-}
-```
-
-```{r, include = FALSE}
-ruler()
-```
-
-<!--chapter:end:preface.Rmd-->
-
-```{r include=FALSE, cache=FALSE}
-# packages
-library(tidyverse)
-theme_set(theme_light())
-library(nimble)
-library(MCMCvis)
-library(magick)
-library(pdftools)
-library(wesanderson)
-library(RColorBrewer)
-library(patchwork)
-library(nimbleEcology)
-library(basicMCMCplots)
-
-# R options
-options(width = 60)
-
-# chunk options
-knitr::opts_chunk$set(
-  comment = ""##"",
-  collapse = TRUE,
-  warning = FALSE,
-  message = FALSE
-  )
-```
-# About the author {-}
-
-My name is Olivier Gimenez (https://oliviergimenez.github.io/). I am a senior (euphemism for not so young anymore) scientist at the National Centre for Scientific Research (CNRS) in the beautiful city of Montpellier, France. 
-
-I struggled studying maths, obtained a PhD in applied statistics a long time ago in a galaxy of wine and cheese. I was awarded my habilitation (https://en.wikipedia.org/wiki/Habilitation) in ecology and evolution so that I could stop pretending to understand what my colleagues were talking about. More recently I embarked in sociology studies because hey, why not. 
-
-Lost somewhere at the interface of animal ecology, statistical modeling and social sciences, my so-called expertise lies in population dynamics and species distribution modeling to address questions in ecology and conservation biology about the impact of human activities and the management of large carnivores. I would be nothing without the students and colleagues who are kind enough to bear with me.
-
-You may find me on Twitter (https://twitter.com/oaggimenez), GitHub (https://github.com/oliviergimenez), or get in touch [by email](mailto:olivier.gimenez@cefe.cnrs.fr).
-
-<!--chapter:end:author.Rmd-->
-
-```{r include=FALSE, cache=FALSE}
-# packages
-library(tidyverse)
-theme_set(theme_light())
-library(nimble)
-library(MCMCvis)
-library(magick)
-library(pdftools)
-library(wesanderson)
-library(RColorBrewer)
-library(patchwork)
-library(nimbleEcology)
-library(basicMCMCplots)
-
-# R options
-options(width = 60)
-
-# chunk options
-knitr::opts_chunk$set(
-  comment = ""##"",
-  collapse = TRUE,
-  warning = FALSE,
-  message = FALSE
-  )
-```
-\mainmatter
-
-# (PART) I. Foundations {-}
-
-# Introduction {-}
-
-
-<!--chapter:end:introductionpartone.Rmd-->
-
-```{r include=FALSE, cache=FALSE}
-# packages
-library(tidyverse)
-theme_set(theme_light())
-library(nimble)
-library(MCMCvis)
-library(magick)
-library(pdftools)
-library(wesanderson)
-library(RColorBrewer)
-library(patchwork)
-library(nimbleEcology)
-library(basicMCMCplots)
-
-# R options
-options(width = 60)
-
-# chunk options
-knitr::opts_chunk$set(
-  comment = ""##"",
-  collapse = TRUE,
-  warning = FALSE,
-  message = FALSE
-  )
-```
-# Bayesian statistics & MCMC {#crashcourse}
-
-## Introduction
-
-In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to implement the Bayesian method for more complex analyses. This is not an exhaustive treatment of Bayesian statistics, but you should get what you need to navigate through the rest of the book. 
-
-## Bayes' theorem
-
-Let's not wait any longer and jump into it. Bayesian statistics relies on the Bayes' theorem (or law, or rule, whatever you prefer) named after Reverend Thomas Bayes (Figure \@ref(fig:revbayes)). This theorem was published in 1763 two years after Bayes' death thanks to his friend's efforts Richard Price, and was independently discovered by Pierre-Simon Laplace [@mcgrayne2011]. 
-
-```{r revbayes, echo = FALSE, fig.align=""center"", out.width=""100%"", fig.cap = ""Cartoon of Thomas Bayes with Bayes' theorem in background. Source: [James Kulich](https://www.elmhurst.edu/blog/thomas-bayes/)""}
-knitr::include_graphics(""images/amazing-thomas-bayes-illustration.jpg"")
-```
-
-As we will see in a minute, Bayes' theorem is all about conditional probabilities, which are somehow tricky to understand. Conditional probability of outcome or event A given event B, which we denote $\Pr(A \mid B)$, is the probability that A occurs, revised by considering the additional information that event B has occurred.^[For example, a friend of yours rolls a fair dice and asks you the probability that the outcome was a six (event A). Your answer is 1/6 because each side of the dice is equally likely to come up. Now imagine that you're told the number rolled was even (event B) before you answer your friend's question. Because there are only three even numbers, one of which is six, you may revise your answer for the probability that a six was rolled from 1/6 to $\Pr(A \mid B) = 1/3$.] The order in which A and B appear is important, make sure you do not confuse $\Pr(A \mid B)$ and $\Pr(B \mid A)$.
-
-Bayes' theorem (Figure \@ref(fig:bayestheorem)) gives you $\Pr(A \mid B)$ using marginal probabilities $\Pr(A)$ and $\Pr(B)$ and $\Pr(B \mid A)$:
-$$\Pr(A \mid B) = \displaystyle{\frac{ \Pr(B \mid A) \; \Pr(A)}{\Pr(B)}}.$$
-Originally, Bayes' theorem was seen as a way to infer an unkown cause A of a particular effect B, knowing the probability of effect B given cause A. Think for example of a situation where a medical diagnosis is needed, with A an unkown disease and B symptoms, the doctor knows P(symptoms|disease) and wants to derive P(disease|symptoms). This way of reversing $\Pr(B \mid A)$ into $\Pr(A \mid B)$ explains why Bayesian thinking used to be referred to as 'inverse probability'. 
-
-<!-- ```{r bayestheorem, echo = FALSE, fig.align=""center"", fig.cap = ""Bayes' theorem spelt out in blue neon. Source: [Wikipedia](https://en.wikipedia.org/wiki/Bayes%27_theorem)""} -->
-<!-- knitr::include_graphics(""images/bayes_neon.jpeg"") -->
-<!-- ``` -->
-
-I don't know about you, but I need to think twice for not messing the letters around. I find it easier to remember Bayes' theorem written like this^[When teaching Bayes' theorem, I am very much inspired by Tristan Mahr's slides from his introduction to Bayesian regression https://www.tjmahr.com/bayes-intro-lecture-slides-2017/]:
-
-$$ \Pr(\text{hypothesis} \mid \text{data}) = \frac{ \Pr(\text{data} \mid \text{hypothesis}) \; \Pr(\text{hypothesis})}{\Pr(\text{data})} $$
-```{block2 bayes, type='rmdnote'}
-The *hypothesis* is a working assumption about which you want to learn using *data*. In capture--recapture analyses, the hypothesis might be a parameter like detection probability, or regression parameters in a relationship between survival probability and a covariate. Bayes' theorem tells us how to obtain the probability of a hypothesis given the data we have. 
-```
-
-This is great because think about it, this is exactly what the scientific method is! We'd like to know how plausible some hypothesis is based on some data we collected, and possibly compare several hypotheses among them. In that respect, the Bayesian reasoning matches the scientific reasoning, which probably explains why the Bayesian framework is so natural for doing and understanding statistics. 
-
-You might ask then, why is Bayesian statistics not the default in statistics? Clearly, because of futile wars between male statisticians (including Ronald Fisher, Jerzy Neyman and Egon Sharpe Pearson among others), little progress was made for over two centuries. Also, until recently, there were practical problems to implement Bayes' theorem. Recent advances in computational power coupled with the development of new algorithms have led to a great increase in the application of Bayesian methods within the last three decades.
-
-## What is the Bayesian approach?	
-
-Typical statistical problems involve estimating a parameter (or several parameters) $\theta$ with available data. To do so, you might be more used to the frequentist rather than the Bayesian method. The frequentist approach, and in particular maximum likelihood estimation (MLE), assumes that the parameters are fixed, and have unknown values to be estimated. Therefore classical estimates are generally point estimates of the parameters of interest. In contrast, the Bayesian approach assumes that the parameters are not fixed, and have some unknown distribution^[A probability distribution is a mathematical expression that gives the probability for a random variable to take particular values. A probability distribution may be either discrete (e.g., the Bernoulli, Binomial or Poisson distribution) or continuous (e.g., the Gaussian distribution also known as the normal distribution)].
-
-The Bayesian approach is based upon the idea that you, as an experimenter, begin with some prior beliefs about the system. Then you collect data and update your prior beliefs on the basis of observations. These observations might arise from field work, lab work or from expertise of your esteemed colleagues. This updating process is based upon Bayes' theorem. Loosely, let's say $A = \theta$ and $B = \text{data}$, then Bayes' theorem gives you a way to estimate parameter $\theta$ given the data you have:
-
-$${\color{red}{\Pr(\theta \mid \text{data})}} = \frac{\color{blue}{\Pr(\text{data} \mid \theta)} \times \color{green}{\Pr(\theta)}}{\color{orange}{\Pr(\text{data})}}.$$
-Let's spend some time going through each quantity in this formula. 
-
-On the left-hand side is the $\color{red}{\text{posterior distribution}}$. It represents what you know after having seen the data. This is the basis for inference and clearly what you're after, a distribution, possibly multivariate if you have more than one parameter. 
-
-On the right-hand side, there is the $\color{blue}{\text{likelihood}}$. This quantity is the same as in the MLE approach. Yes, the Bayesian and frequentist approaches have the same likelihood at their core, which mostly explains why results often do not differ much. The likelihood captures the information you have in your data, given a model parameterized with $\theta$. 
-
-Then we have the $\color{green}{\text{prior distribution}}$. This quantity represents what you know before seeing the data. This is the source of much discussion about the Bayesian approach. It may be vague if you don't know anything about $\theta$. Usually however, you never start from scratch, and you'd like your prior to reflect the information you have^[Shall I include a section on sensitivity analyses in this chapter or later in the book? Cross-reference section in Survival chapter where prior elicitation is covered.].
-
-Last, we have $\color{orange}{\Pr(\text{data})}$ which is sometimes called the average likelihood because it is obtained by integrating the likelihood with respect to the prior $\color{orange}{\Pr(\text{data}) = \int{L(\text{data} \mid \theta)\Pr(\theta) d\theta}}$ so that the posterior is standardized, that is it integrates to one for the posterior to be a distribution. The average likelihood is an integral with dimension the number of parameters $\theta$ you need to estimate. This quantity is difficult, if not impossible, to calculate in general. This is one of the reasons why the Bayesian method wasn't used until recently, and why we need algorithms to estimate posterior distributions as I illustrate in the next section.
-
-## Approximating posteriors via numerical integration {#numerical-approx}
-
-Let's take an example to illustrate Bayes' theorem. Say we capture, mark and release $n = 57$ animals at the beginning of a winter, out of which we recapture $y = 19$ animals alive^[We used a similar example in @king_bayesian_2009]. We'd like to estimate winter survival $\theta$.
-```{r}
-y <- 19 # nb of success
-n <- 57 # nb of attempts
-```
-
-We build our model first. Assuming all animals are independent of each other and have the same survival probability, then $y$ the number of alive animals at the end of the winter is a binomial distribution^[I follow @mcelreathbook and use labels on the right to help remember what each line is about.] with $n$ trials and $\theta$ the probability of success:
-  
-\begin{align*}
-y &\sim \text{Binomial}(n, \theta) &\text{[likelihood]}
-\end{align*}
-
-This likelihood can be visualised in `R`: 
-```{r binlik, echo = TRUE, fig.cap = ""Binomial likelihood with $n = 57$ released animals and $y = 19$ survivors after winter. The value of survival (on the x-axis) that corresponds to the maximum of the likelihood function (on the y-axis) is the MLE, or the proportion of success in this example, close to 0.33.""}
-grid <- seq(0, 1, 0.01) # grid of values for survival
-likelihood <- dbinom(y, n, grid) # compute binomial likelihood
-df <- data.frame(survival = grid, likelihood = likelihood) 
-df %>%
-  ggplot() + 
-  aes(x = survival, y = likelihood) + 
-  geom_line(size = 1.5)
-```
-
-Besides the likelihood, priors are another component of the model in the Bayesian approach. For a parameter that is a probability, the one thing we know is that the prior should be a continuous random variable that lies between 0 and 1. To reflect that, we often go for the uniform distribution $U(0,1)$ to imply *vague* priors. Here vague means that survival has, before we see the data, the same probability of falling between 0.1 and 0.2 and between 0.8 and 0.9, for example. 
-
-\begin{align*}
-\theta &\sim \text{Uniform}(0, 1) &\text{[prior for }\theta \text{]}
-\end{align*}
-
-```{r, echo = FALSE}
-a <- 1; b <- 1; grid <- seq(0,1,0.01); prior <- dbeta(grid,a,b)
-dfprior <- data.frame(survival = grid, prior = prior) 
-#dfprior %>%
-#  ggplot() + 
-#  geom_line(aes(x = p, y = prior), 
-#            size = 1.5,
-#            color = wesanderson::wes_palettes$Royal1[1])
-#plot(p, dbeta(p,a,b), type='l', lwd=3)
-```
-
-Now we apply Bayes' theorem. We write a `R` function that computes the product of the likelihood times the prior, or the numerator in Bayes' theorem: $\Pr(\text{data} \mid \theta) \times \Pr(\theta)$
-```{r}
-numerator <- function(theta) dbinom(y, n, theta) * dunif(theta, 0, 1)
-```
-
-We write another function that calculates the denominator, the average likelihood: $\Pr(\text{data}) = \int{L(\theta \mid \text{data}) \Pr(\theta) d\theta}$
-```{r}
-denominator <- integrate(numerator,0,1)$value
-```
-
-We use the `R` function `integrate` to calculate the integral in the denominator, which implements quadrature techniques to divide in little squares the area underneath the curve delimited by the function to integrate (here the numerator), and count them.
-
-Then we get a numerical approximation of the posterior in Figure \@ref(fig:numapprox) by applying Bayes' theorem. 
-```{r numapprox, echo = TRUE, fig.cap = ""Winter survival posterior distribution obtained by numerical integration.""}
-grid <- seq(0, 1, 0.01) # grid of values for theta
-numerical_posterior <- data.frame(survival = grid, 
-                                  posterior = numerator(grid)/denominator) # Bayes' theorem
-numerical_posterior %>%
-  ggplot() +
-  aes(x = survival, y = posterior) + 
-  geom_line(size = 1.5)
-```
-
-How good is our numerical approximation of survival posterior distribution? Ideally, we would want to compare the approximation to the true posterior distribution. Although a closed-form expression for the posterior distribution is in general intractable, when you combine a binomial likelihood together with a beta distribution as a prior, then the posterior distribution is also a beta distribution, which makes it amenable to all sorts of exact calculations^[We say that the beta distribution is the conjugate prior distribution for the binomial distribution.]. The beta distribution is continuous between 0 and 1, and extends the uniform distribution to situations where not all outcomes are equally likely. It has two parameters $a$ and $b$ that control its shape (Figure \@ref(fig:betadistribution)).
-
-(ref:captionbeta) The distribution beta($a$,$b$) for different values of $a$ and $b$. Note that for $a = b = 1$, we get the uniform distribution between 0 and 1 in the top left panel. When $a$ and $b$ are equal, the distribution is symmetric, and the bigger $a$ and $b$, the more peaked the distribution or the smaller the variance. 
-
-```{r betadistribution, echo = FALSE, fig.cap='(ref:captionbeta)'}
-x <- seq(0, 1, length=200)
-par(mfrow = c(2,3))
-# distribution a posteriori beta
-plot(x,dbeta(x, 1, 1),type='l',xlab='',ylab='Density',main='beta(1,1)',lwd=3,col='black',ylim=c(0,1.5))
-plot(x,dbeta(x, 2, 1),type='l',xlab='',ylab='',main='beta(2,1)',lwd=3,col='black',ylim=c(0,2))
-plot(x,dbeta(x, 1, 2),type='l',xlab='',ylab='',main='beta(1,2)',lwd=3,col='black',ylim=c(0,2))
-plot(x,dbeta(x, 2, 2),type='l',xlab='',ylab='Density',main='beta(2,2)',lwd=3,col='black',ylim=c(0,1.5))
-plot(x,dbeta(x, 10, 10),type='l',xlab='',ylab='',main='beta(10,10)',lwd=3,col='black',ylim=c(0,3.5))
-plot(x,dbeta(x, 0.8, 0.8),type='l',xlab='',ylab='',main='beta(0.8,0.8)',lwd=3,col='black',ylim=c(0.5,2.5))
-```
-
-If the likelihood of the data $y$ is binomial with $n$ trials and probability of success $\theta$, and the prior is a beta distribution with parameters $a$ and $b$, then the posterior is a beta distribution with parameters $a + y$ and $b + n - y$^[**provide a sketch of the proof**]. In our example, we have $n = 57$ trials and $y = 19$ animals that survived and a uniform prior between 0 and 1 or a beta distribution with parameters $a = b = 1$, therefore survival has a beta posterior distribution with parameters 20 and 39. In Figure \@ref(fig:compar), we superimpose the exact posterior and the numerical approximation. Clearly, the two distributions are indistinguishable, suggesting that the numerical approximation is more than fine. 
-```{r compar, echo = FALSE, fig.cap = ""Comparison of exact (dashed line) vs. numerical approximation (continuous line) of winter survival posterior distribution.""}
-explicit_posterior <- dbeta(grid, y + a, n - y + b)
-dfexpposterior <- data.frame(survival = grid, explicit_posterior = explicit_posterior)
-ggplot() + 
-  geom_line(data = numerical_posterior, 
-            aes(x = survival, y = posterior), 
-            size = 1.5, 
-            col = wesanderson::wes_palettes$Royal1[2],
-            alpha = 0.5) + 
-  geom_line(data = dfexpposterior, 
-            aes(x = survival, y = explicit_posterior),
-            size = 1.5, 
-            col = wesanderson::wes_palettes$Royal1[3], 
-            linetype = ""dashed"")
-```
-
-<!-- To finish up, let's add the prior.  -->
-<!-- ```{r, echo = FALSE} -->
-<!-- ggplot() +  -->
-<!--   geom_line(data = numerical_posterior,  -->
-<!--             aes(x = survival, y = posterior),  -->
-<!--             size = 1.5,  -->
-<!--             col = wesanderson::wes_palettes$Royal1[2],  -->
-<!--             alpha = 0.5) +  -->
-<!--   geom_line(data = dfexpposterior,  -->
-<!--             aes(x = survival, y = explicit_posterior), -->
-<!--             col = wesanderson::wes_palettes$Royal1[3],  -->
-<!--             size = 1.5,  -->
-<!--             linetype = ""dashed"") +  -->
-<!--   geom_line(data = dfprior, -->
-<!--             aes(x = survival, y = prior), -->
-<!--             col = wesanderson::wes_palettes$Royal1[1], -->
-<!--             size = 1.5) -->
-<!-- ``` -->
-
-In our example, we have a single parameter to estimate, winter survival. This means dealing with a one-dimensional integral in the denominator which is pretty easy with quadrature techniques and the `R` function `integrate()`. Now what if we had multiple parameters? For example, imagine you'd like to fit a capture-recapture model with detection probability $p$ and regression parameters $\alpha$ and $\beta$ for the intercept and slope of a relationship between survival probability and a covariate, then Bayes' theorem gives you the posterior distribution of all three parameters together:
-
-$$ \Pr(\alpha, \beta, p \mid \text{data}) = \frac{ \Pr(\text{data} \mid \alpha, \beta, p) \times \Pr(\alpha, \beta, p)}{\iiint \, \Pr(\text{data} \mid \alpha, \beta, p) \Pr(\alpha, \beta, p) d\alpha d\beta dp} $$
-There are two computational challenges with this formula. First, do we really wish to calculate a three-dimensional integral? The answer is no, one-dimensional and two-dimensional integrals are so much further we can go with standard methods. Second, we're more interested in a posterior distribution for each parameter separately than the joint posterior distribution. The so-called marginal distribution of $p$ for example is obtained by integrating over all the other parameters -- a two-dimensional integral in this example. Now imagine with tens or hundreds of parameters to estimate, these integrals become highly multi-dimensional and simply intractable. In the next section, I introduce powerful simulation methods to circumvent this issue. 
-
-## Markov chain Monte Carlo (MCMC)
-
-In the early 1990s, statisticians rediscovered work from the 1950's in physics. In a famous paper that would lay the fundations of modern Bayesian statistics (Figure \@ref(fig:mcmcpaper)), the authors use simulations to approximate posterior distributions with some precision by drawing large samples. This is a neat trick to avoid explicit calculation of the multi-dimensional integrals we struggle with when using Bayes' theorem. 
-
-```{r mcmcpaper, echo = FALSE, fig.align='center', fig.cap = ""MCMC article cover. Source: [The Journal of Chemical Physics](https://aip.scitation.org/doi/10.1063/1.1699114)""}
-knitr::include_graphics(""images/metropolis.png"")
-```
-
-These simulation algorithms are called Markov chain Monte Carlo (MCMC), and they definitely gave a boost to Bayesian statistics. There are two parts in MCMC, Markov chain and Monte Carlo, let's try and make sense of these terms. 
-
-### Monte Carlo integration
-
-What does Monte Carlo stand for? Monte Carlo integration is a simulation technique to calculate integrals of any function $f$ of random variable $X$ with distribution $\Pr(X)$ say $\int f(X) \Pr(X)dX$. You draw values $X_1,\ldots,X_k$ from $\Pr(X)$ the distribution of $X$, apply function $f$ to these values, then calculate the mean of these new values $\displaystyle{\frac{1}{k}}\sum_{i=1}^k{f(X_i)}$ to approximate the integral. How is Monte Carlo integration used in a Bayesian context? The posterior distribution contains all the information we need about the parameter to be estimated. When dealing with many parameters however, you may want to summarise posterior results by calculating numerical summaries. The simplest numerical summary is the mean of the posterior distribution, $E(\theta) = \int \theta \Pr(\theta|\text{data})$, where $X$ is $\theta$ now and $f$ is the identity function. Posterior mean can be calculated with Monte Carlo integration:
-```{r}
-sample_from_posterior <- rbeta(1000, 20, 39) # draw 1000 values from posterior survival beta(20,39)
-mean(sample_from_posterior) # compute mean with Monte Carlo integration
-```
-
-You may check that the mean we have just calculated matches closely the expectation of a beta distribution^[If $X$ is a random variable with distribution $\text{beta}(a, b)$, then $E(X) = \displaystyle{\frac{a}{a + b}}$]:
-```{r}
-20/(20+39) # expectation of beta(20,39)
-```
-
-Another useful numerical summary is the credible interval within which our parameter falls with some probability, usually 0.95 hence a 95$\%$ credible interval. Finding the bounds of a credible interval requires calculating quantiles, which in turn involves integrals and the use of Monte Carlo integration. A 95$\%$ credible interval for winter survival can be obtained in `R` with:
-```{r}
-quantile(sample_from_posterior, probs = c(2.5/100, 97.5/100))
-```
-
-### Markov chains {#markovmodelmcmc}
-
-What is a Markov chain? A Markov chain is a random sequence of numbers, in which each number depends only on the previous number. An example is the weather in my home town in Southern France, Montpellier, in which a sunny day is most likely to be followed by another sunny day, say with probability 0.8, and a rainy day is rarely followed by another rainy day, say with probability 0.1. The dynamic of this Markov chain is captured by the transition matrix $\mathbf{\Gamma}$:
-$$
-\begin{matrix}
-& \\
-\mathbf{\Gamma} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    \text{sunny tomorrow} & \text{rainy tomorrow} \\ 
-0.8 & 0.2 \\ 
-0.9 & 0.1 \\ 
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    \text{sunny today} \\ \text{rainy today}
-    \end{matrix}
-\end{matrix}
-$$
-In rows the weather today, and in columns the weather tomorrow. The cells give the probability of a sunny or rainy day tomorrow, given the day is sunny or rainy today. Under certain conditions^[The Markov chain is irreducible and aperiodic.], a Markov chain will converge to a unique stationary distribution. In our weather example, let's run the Markov chain for 20 steps:
-```{r}
-weather <- matrix(c(0.8, 0.2, 0.9, 0.1), nrow = 2, byrow = T) # transition matrix
-steps <- 20
-for (i in 1:steps){
-  weather <- weather %*% weather # matrix multiplication
-}
-round(weather, 2) # matrix product after 20 steps
-```
-
-Each row of the transition matrix converges to the same distribution $(0.82, 0.18)$ as the number of steps increases. Convergence happens no matter which state you start in, and you always have probability 0.82 of the day being sunny and 0.18 of the day being rainy. 
-
-Back to MCMC, the core idea is that you can build a Markov chain with a given stationary distribution set to be the desired posterior distribution. 
-
-```{block2 mcmc, type='rmdnote'}
-Putting Monte Carlo and Markov chains together, MCMC allows us to generate a sample of values (Markov chain) whose distribution converges to the posterior distribution, and we can use this sample of values to calculate any posterior summaries (Monte Carlo), such as posterior means and credible intervals. 
-```
-
-### Metropolis algorithm {#metropolis-algorithm}
-
-There are several ways of constructing Markov chains for Bayesian inference^[You might have heard about the Metropolis-Hastings or the Gibbs sampler. Have a look to <https://github.com/chi-feng/mcmc-demo> for an interactive gallery of MCMC algorithms.]. Here I illustrate the Metropolis algorithm and how to implement it in practice^[This presentation is largely inspired by @alberthu2019].
-
-Let's go back to our example on animal survival estimation. We illustrate sampling from survival posterior distribution. We write functions for likelihood, prior and posterior.
-
-```{r}
-# 19 animals recaptured alive out of 57 captured, marked and released
-survived <- 19
-released <- 57
-
-# binomial log-likelihood function
-loglikelihood <- function(x, p){
-  dbinom(x = x, size = released, prob = p, log = TRUE)
-}
-
-# uniform prior density
-logprior <- function(p){
-  dunif(x = p, min = 0, max = 1, log = TRUE)
-}
-
-# posterior density function (log scale)
-posterior <- function(x, p){
-  loglikelihood(x, p) + logprior(p) # - log(Pr(data))
-}
-```
-
-The Metropolis algorithm works as follows: 
-  
-1. We pick a value of the parameter to be estimated. This is where we start our Markov chain -- this is a *starting* value. 
-
-2. To decide where to go next, we propose to move away from the current value of the parameter -- this is a *candidate* value. To do so, we add to the current value some random value from e.g. a normal distribution with some variance -- this is a *proposal* distribution. The Metropolis algorithm is a particular case of the Metropolis-Hastings algorithm with symmetric proposals.
-  
-3. We compute the ratio of the probabilities at the candidate and current locations $R=\displaystyle{\frac{{\Pr(\text{candidate}|\text{data})}}{{\Pr(\text{current}|\text{data})}}}$. This is where the magic of MCMC happens, in that $\Pr(\text{data})$, the denominator in the Bayes' theorem, appears in both the numerator and the denominator in $R$ therefore cancels out and does not need to be calculated. 
-
-<!-- -- *the Hastings ratio* -->
-
-4. If the posterior at the candidate location $\Pr(\text{candidate}|\text{data})$ is higher than at the current location $\Pr(\text{current}|\text{data})$, in other words when the candidate value is more plausible than the current value, we definitely accept the candidate value. If not, then we accept the candidate value with probability $R$ and reject with probability $1-R$. For example, if the candidate value is ten times less plausible than the current value, then we accept with probability 0.1 and reject with probability 0.9. How does it work in practice? We use a continuous spinner that lands somewhere between 0 and 1 -- call the random spin $X$. If $X$ is smaller than $R$, we move to the candidate location, otherwise we remain at the current location.  We do not want to accept or reject too often. In practice, the Metropolis algorithm should have an acceptance probability between 0.2 and 0.4, which can be achieved by *tuning* the variance of the normal proposal distribution. 
-  
-5. We repeat 2-4 a number of times -- or *steps*.
-
-Enough of the theory, let's implement the Metropolis algorithm in `R`. Let's start by setting the scene. 
-```{r}
-steps <- 100 # number of steps
-theta.post <- rep(NA, steps) # vector to store samples
-accept <- rep(NA, steps) # keep track of accept/reject
-set.seed(1234) # for reproducibility
-```
-
-Now follow the 5 steps we've just described. First, we pick a starting value, and store it (step 1).
-```{r}
-inits <- 0.5
-theta.post[1] <- inits
-accept[1] <- 1
-```
-
-Then, we need a function to propose a candidate value. We add a value taken from a normal distribution with mean zero and standard deviation we call *away*. We work on the logit scale to make sure the candidate value for survival lies between 0 and 1. 
-```{r}
-move <- function(x, away = 1){ # by default, standard deviation of the proposal distribution is 1
-  logitx <- log(x / (1 - x)) # apply logit transform (-infinity,+infinity)
-  logit_candidate <- logitx + rnorm(1, 0, away) # add a value taken from N(0,sd=away) to current value
-  candidate <- plogis(logit_candidate) # back-transform (0,1)
-  return(candidate)
-}
-```
-
-Now we're ready for steps 2, 3 and 4. We write a loop to take care of step 5. We start at initial value 0.5 and run the algorithm for 100 steps or iterations. 
-```{r}
-for (t in 2:steps){ # repeat steps 2-4 (step 5)
-  
-  # propose candidate value for survival (step 2)
-  theta_star <- move(theta.post[t-1])
-  
-  # calculate ratio R (step 3)
-  pstar <- posterior(survived, p = theta_star)  
-  pprev <- posterior(survived, p = theta.post[t-1])
-  logR <- pstar - pprev # likelihood and prior are on the log scale
-  R <- exp(logR)
-  
-  # accept candidate value or keep current value (step 4)
-  X <- runif(1, 0, 1) # spin continuous spinner
-  if (X < R){
-    theta.post[t] <- theta_star # accept candidate value
-    accept[t] <- 1 # accept
-  }
-  else{
-    theta.post[t] <- theta.post[t-1] # keep current value
-    accept[t] <- 0 # reject
-  }
-}
-```
-
-We get the following values. 
-```{r}
-head(theta.post) # first values
-tail(theta.post) # last values
-```
-
-Visually, you may look at the chain in Figure \@ref(fig:chain) called a trace plot.
-```{r chain, echo = FALSE, fig.align='center', fig.cap = ""Visualisation of a Markov chain starting at value 0.5, with steps or iterations on the x-axis, and samples on the y-axis. This graphical representation is called a trace plot.""}
-df <- data.frame(x = 1:steps, y = theta.post)
-df %>%
-  ggplot() +
-  geom_line(aes(x = x, y = y), size = 1.5, color = wesanderson::wes_palettes$Zissou1[1]) + 
-  labs(x = ""iterations"", y = ""samples"") + 
-  ylim(0.1, 0.6)
-```
-
-The acceptance probability is the average number of times we accepted a candidated value, which is `r mean(accept)` and almost satisfying. 
-
-```{r echo = FALSE}
-# log-likelihood function
-loglikelihood <- function(x, p){
-  dbinom(x = x, size = released, prob = p, log = TRUE)
-}
-
-# prior density
-logprior <- function(p){
-  dunif(x = p, min = 0, max = 1, log = TRUE)
-}
-
-# posterior density function (log scale)
-posterior <- function(x, p){
-  loglikelihood(x, p) + logprior(p) # - log(Pr(data))
-}
-
-# propose candidate value
-move <- function(x, away = .2){ 
-  logitx <- log(x / (1 - x))
-  logit_candidate <- logitx + rnorm(1, 0, away)
-  candidate <- plogis(logit_candidate)
-  return(candidate)
-}
-
-metropolis <- function(steps = 100, inits = 0.5, away = 1){
-  
-  # pre-alloc memory
-  theta.post <- rep(NA, steps)
-  
-  # start
-  theta.post[1] <- inits
-  
-  for (t in 2:steps){
-    
-    # propose candidate value for prob of success
-    theta_star <- move(theta.post[t-1], away = away)
-    
-    # calculate ratio R
-    pstar <- posterior(survived, p = theta_star)  
-    pprev <- posterior(survived, p = theta.post[t-1])
-    logR <- pstar - pprev
-    R <- exp(logR)
-    
-    # accept candidate value or keep current value (step 4)
-    X <- runif(1, 0, 1) # spin continuous spinner
-    if (X < R){
-      theta.post[t] <- theta_star
-    }
-    else{
-      theta.post[t] <- theta.post[t-1]
-    }
-  }
-  theta.post
-}
-```
-
-Can we run another chain and start at initial value 0.2 this time? Yes, just go through the same algorithm again, and visualise the results in Figure \@ref(fig:twochains). 
-```{r twochains, echo = FALSE, fig.align='center', fig.cap = ""Trace plot of survival for two chains starting at 0.2 (yellow) and 0.5 (blue) run for 100 steps.""}
-theta.post2 <- metropolis(steps = 100, inits = 0.2)
-df2 <- data.frame(x = 1:steps, y = theta.post2)
-ggplot() +
-  geom_line(data = df, aes(x = x, y = y), size = 1.5, color = wesanderson::wes_palettes$Zissou1[1]) + 
-  geom_line(data = df2, aes(x = x, y = y), size = 1.5, color = wesanderson::wes_palettes$Zissou1[3]) + 
-  labs(x = ""iterations"", y = ""values from posterior distribution"") + 
-  ylim(0.1, 0.6)
-```
-
-Notice that we do not get the exact same results because the algorithm is stochastic. The question is to know whether we have reached the stationary distribution. Let's increase the number of steps and run a chain with 5000 iterations as in Figure \@ref(fig:longchain).
-```{r longchain, echo = FALSE, fig.align='center', fig.cap = ""Trace plot of survival for a chain starting at 0.5 and 1000 steps.""}
-steps <- 5000
-set.seed(1234)
-theta.post <- metropolis(steps = steps, inits = 0.5)
-df <- data.frame(x = 1:steps, y = theta.post)
-df %>%
-  ggplot() +
-  geom_line(aes(x = x, y = y), size = 1, color = wesanderson::wes_palettes$Zissou1[1]) + 
-  labs(x = ""iterations"", y = ""values from posterior distribution"") + 
-  ylim(0.1, 0.6) + 
-  geom_hline(aes(yintercept = mean(theta.post), linetype = ""posterior mean"")) + 
-  scale_linetype_manual(name = """", values = c(2,2)) 
-```
-
-This is what we're after, a trace plot that looks like a beautiful lawn, see Section \@ref(convergence-diag). I find it informative to look at the animated version of Figure \@ref(fig:longchain), it helps understanding the stochastic behavior of the algorithm, and also to realise how the chains converge to their stationary distribution, see Figure \@ref(fig:animlongchain).
-
-```{r echo = FALSE, eval = FALSE}
-# load packages
-library(tidyverse)
-theme_set(theme_light(base_size = 16))
-library(gganimate)
-library(magick)
-
-# deer data, 19 ""success"" out of 57 ""attempts""
-survived <- 19
-released <- 57
-
-#---------- apply Metropolis
-
-steps <- 1000
-chain1 <- metropolis(steps = steps, inits = 0.2)
-chain2 <- metropolis(steps = steps, inits = 0.5)
-chain3 <- metropolis(steps = steps, inits = 0.7)
-
-df <- data.frame(iter = rep(1:steps, 3), 
-                 value = c(chain1, chain2, chain3),
-                 chain = c(rep(""chain1"", steps), 
-                           rep(""chain2"", steps), 
-                           rep(""chain3"", steps)))
-
-#---------- time series
-static_tsplot <- df %>%
-  mutate(posterior_mean = mean(value)) %>%
-  ggplot(aes(x = iter, y = value, group = chain, color = chain)) +
-  geom_line(size = 1, alpha = 0.5) + 
-  geom_hline(aes(yintercept = posterior_mean, linetype = ""posterior mean"")) + 
-  scale_linetype_manual(name = """", values = c(2,2)) + 
-  labs(color = """", x = ""iterations"", y = ""survival"")
-static_tsplot  
-  
-# animate
-animated_tsplot <- static_tsplot +
-  transition_reveal(along = iter, 
-                    range = as.integer(c(1, max(df$iter) + 50))) # trick to pause
-animated_tsplot  
-
-# save
-a_gif <- animate(animated_tsplot,
-                 width = 6, 
-                 height = 3,
-                 res = 600,
-                 units = ""in"")
-
-# get file in directory str(a_gif)
-```
-```{r animlongchain, echo = FALSE, out.width=""100%"", fig.align='center', fig.cap = ""Animated trace plot of survival with three chains starting at 0.2, 0.5 and 0.7 run for 1000 steps.""}
-knitr::include_graphics(""images/traceplotMCMC.gif"")
-```
-
-Once the stationary distribution is reached, you may regard the realisations of the Markov chain as a sample from the posterior distribution, and obtain numerical summaries. In the next section, we consider several important implementation issues. 
-
-## Assessing convergence {#convergence-diag}
-
-```{block2 convergence, type='rmdnote'}
-When implementing MCMC, we need to determine how long it takes for our Markov chain to converge to the target distribution, and the number of iterations we need after achieving convergence to get reasonable Monte Carlo estimates of numerical summaries (posterior means and credible intervals).
-```
-
-### Burn-in
-  
-In practice, we discard observations from the start of the Markov chain and just use observations from the chain once it has converged. The initial observations that we discard are usually referred to as the *burn-in*. 
-
-The simplest method to determine the length of the burn-in period is to look at trace plots. Going back to our example, we see from the trace plot in Figure \@ref(fig:burnin) that we need at least 100 iterations to achieve convergence toward an average survival around 0.3. It is always better to be conservative when specifying the length of the burn-in period, and in this example, we would use 250 or even 500 iterations as a burn-in. The length of the burn-in period can be determined by performing preliminary MCMC short runs. 
-
-```{r burnin, echo = FALSE, fig.cap = ""Determining the length of the burn-in period. The chain starts at value 0.99 and rapidly stabilises, with values bouncing back and forth around 0.3 from the 100th iteration onwards. You may choose the shaded area as the burn-in, and discard the corresponding values.""}
-
-# set up the scene
-steps <- 1000
-theta.post <- metropolis(steps = steps, inits = 0.99)
-df <- data.frame(x = 1:steps, y = theta.post)
-df %>%
-  ggplot() +
-  geom_line(aes(x = x, y = y), size = 1.2, color = wesanderson::wes_palettes$Zissou1[1]) + 
-  labs(x = ""iterations"", y = ""survival"") + 
-  theme_light(base_size = 14) + 
-  annotate(""rect"", 
-           xmin = 0, 
-           xmax = 100, 
-           ymin = 0.1, 
-           ymax = 1, 
-           alpha = .3) +
-  scale_y_continuous(expand = c(0,0))
-```
-
-Inspecting the trace plot for a single run of the Markov chain is useful. However, we usually run the Markov chain several times, starting from different over-dispersed points, to check that all runs achieve the same stationary distribution. This approach is formalised by using the Brooks-Gelman-Rubin (BGR) statistic $\hat{R}$ which measures the ratio of the total variability combining multiple chains (between-chain plus within-chain) to the within-chain variability. The BGR statistic asks whether there is a chain effect, and is very much alike the $F$ test in an analysis of variance. Values below 1.1 indicate likely convergence.
-
-```{r, echo = FALSE, cache = TRUE}
-simul.bgr <- function(steps, inits){
-  
-  nb.replicates <- length(inits)
-  theta.post <- matrix(NA, nrow = nb.replicates, ncol = steps)
-  for (i in 1:nb.replicates){
-    theta.post[i,1:steps] <- metropolis(steps = steps, inits = inits[i])
-  }
-  
-  df <- data.frame(x = rep(1:steps, nb.replicates), 
-                   y = c(t(theta.post)), 
-                   chain = paste0(""chain "",gl(nb.replicates, steps))) %>%
-    filter(x > round(steps/2)) # apply burnin (half number of iterations)
-
-  # compute BGR (R-hat)
-  num <- quantile(df$y, probs = c(20/100, 80/100))[2] - quantile(df$y, probs = c(20/100, 80/100))[1]
-  den <- df %>%
-    group_by(chain) %>%
-    summarise(ci = quantile(y, probs = c(20/100, 80/100))) %>%
-    mutate(diff = ci - lag(ci, default = ci[1])) %>%
-    filter(diff != 0) %>%
-    pull(diff) %>%
-    mean()
-  
-  bgr <- round(num / den, 3)
-  return(bgr)
-}
-
-set.seed(1234)
-steps <- seq(100, 5000, 100)
-bgr <- rep(NA, length(steps))
-for (i in 1:length(steps)){
-  bgr[i] <- simul.bgr(steps = steps[i], inits = c(0.2, 0.8))
-}
-df <- data.frame(iterations = steps, bgr = bgr)
-```
-
-Back to our example, we run two Markov chains with starting values 0.2 and 0.8 using 100 up to 5000 iterations, and calculate the BGR statistic using half the number of iterations as the length of the burn-in. From Figure \@ref(fig:bgr), we get a value of the BGR statistic near 1 by up to 2000 iterations, which suggests that with 2000 iterations as a burn-in, there is no evidence of a lack of convergence. 
-
-```{r bgr, echo=FALSE, fig.cap = ""Brooks-Gelman-Rubin statistic as a function of the number of iterations.""}
-df %>%
-  ggplot() + 
-  geom_line(aes(x = iterations, y = bgr), size = 1.2) +
-  labs(y = ""BGR statistic"")
-```
-
-It is important to bear in mind that a value near 1 for the BGR statistic is only a necessary *but not sufficient* condition for convergence. In other words, this diagnostic cannot tell you for sure that the Markov chain has achieved convergence, only that it has not.^[Cross-reference sections on local minima and parameter redundancy for pathological cases.]
-
-### Chain length
-  
-```{r, echo = FALSE}
-# inspired from https://bookdown.org/content/3686/markov-chain-monte-carlo.html
-
-n_steps <- 10000
-
-d <-
-  tibble(away = c(0.1, 1, 10)) %>% 
-  mutate(accepted_traj = map(away, metropolis, steps = n_steps, inits = 0.1)) %>% 
-  unnest(accepted_traj)
-
-d <-
-  d %>% 
-  mutate(proposal_sd = str_c(""Proposal SD = "", away),
-         iter        = rep(1:n_steps, times = 3))
-
-trace <- d %>% 
-  ggplot(aes(y = accepted_traj, x = iter)) +
-  geom_path(size = 1/4, color = ""steelblue"") +
-  geom_point(size = 1/2, alpha = 1/2, color = ""steelblue"") +
-  scale_y_continuous(""survival"", breaks = 0:5 * 0.1, limits = c(0.15, 0.5)) +
-  scale_x_continuous(""iterations"", 
-                     breaks = seq(n_steps-n_steps*10/100,n_steps,by = 600), 
-                     limits = c(n_steps-n_steps*10/100, n_steps)) +
-  facet_wrap(~proposal_sd, ncol = 3) +
-  theme_light(base_size = 14)
-
-library(forecast)
-plot1 <- ggAcf(x = d$accepted_traj[d$proposal_sd==""Proposal SD = 0.1""]) + ggtitle(""Proposal SD = 0.1"")
-plot2 <- ggAcf(x = d$accepted_traj[d$proposal_sd==""Proposal SD = 1""]) + ggtitle(""Proposal SD = 1"")
-plot3 <- ggAcf(x = d$accepted_traj[d$proposal_sd==""Proposal SD = 10""]) + ggtitle(""Proposal SD = 10"")
-```
-
-How long of a chain is needed to produce reliable parameter estimates? To answer this question, you need to keep in mind that successive steps in a Markov chain are not independent -- this is usually referred to as *autocorrelation*. Ideally, we would like to keep autocorrelation as low as possible. Here again, trace plots are useful to diagnose issues with autocorrelation. Let's get back to our survival example. Figure \@ref(fig:tracechainlength) shows trace plots for different values of the standard deviation (parameter *away*) of the (normal) proposal distribution we use to propose a candidate value (Section \@ref(metropolis-algorithm)). Small and big moves provide high correlations between successive observations of the Markov chain, whereas a standard deviation of 1 allows efficient exploration of the parameter space. The movement around the parameter space is referred to as *mixing*. Mixing is bad when the chain makes small and big moves, and good otherwise. 
-
-```{r tracechainlength, echo=FALSE, fig.cap = ""Trace plots for different values of the standard deviation (SD) of the proposal distribution. Left: The chain exhibits small moves and mixing is bad. Right: The chain exhibits big moves and mixing is bad. Middle: The chain exhibits adequate moves and mixing is good. Only the thousand last iterations are shown.""}
-trace
-```
-
-In addition to trace plots, autocorrelation function (ACF) plots are a convenient way of displaying the strength of autocorrelation in a given sample values. ACF plots provide the autocorrelation between successively sampled values separated by an increasing number of iterations, or *lag* (Figure \@ref(fig:acfchainlength)).
-
-```{r acfchainlength, echo=FALSE, fig.cap = ""Autocorrelation function plots for different values of the standard deviation (SD) of the proposal distribution. Left and right: Autocorrelation is strong, decreases slowly with increasing lag and mixing is bad. Middle: Autocorrelation is weak, decreases rapidly with increasing lag and mixing is good.""}
-library(patchwork)
-(plot1 + plot2 + plot3)
-```
-
-Autocorrelation is not necessarily a big issue. Strongly correlated observations just require large sample sizes and therefore longer simulations. But how many iterations exactly? The effective sample size (`n.eff`) measures chain length while taking into account chain autocorrelation. You should check the `n.eff` of every parameter of interest, and of any interesting parameter combinations. In general, we need $\text{n.eff} \geq 1000$ independent steps to get reasonable Monte Carlo estimates of model parameters. In the animal survival example, `n.eff` can be calculated with the R `coda::effectiveSize()` function.
-```{r neff, echo = FALSE}
-neff1 <- coda::effectiveSize(d$accepted_traj[d$proposal_sd==""Proposal SD = 0.1""])
-neff2 <- coda::effectiveSize(d$accepted_traj[d$proposal_sd==""Proposal SD = 1""])
-neff3 <- coda::effectiveSize(d$accepted_traj[d$proposal_sd==""Proposal SD = 10""])
-df <- tibble(""Proposal SD"" = c(0.1, 1, 10),
-                 ""n.eff"" = round(c(neff1, neff2, neff3)))
-knitr::kable(df, format = ""markdown"")
-```
-
-As expected, `n.eff` is less than the number of MCMC iterations because of autocorrelation. Only when the standard deviation of the proposal distribution is 1 and mixing is good (Figures \@ref(fig:tracechainlength) and \@ref(fig:acfchainlength)) we get a satisfying effective sample size. 
-
-### What if you have issues of convergence?
-  
-When diagnosing MCMC convergence, you will (very) often run into troubles. In this section you will find some helpful tips I hope. 
-
-When mixing is bad and effective sample size is small, you may just need to increase burn-in and/or sample more. Using more informative priors might also make Markov chains converge faster by helping your MCMC sampler (e.g. the Metropolis algorithm) navigating more efficiently the parameter space. In the same spirit, picking better initial values for starting the chain does not harm. For doing that, a strategy consists in using estimates from a simpler model for which your MCMC chains do converge. 
-
-If convergence issues persist, often there is a problem with your model^[The quote 'When you have computational problems, often there's a problem with your model' is the folk theorem of statistical computing stated by Andrew Gelman in 2008, see https://statmodeling.stat.columbia.edu/2008/05/13/the_folk_theore/]. A bug in the code? A typo somewhere? A mistake in your maths? As often when coding is involved, the issue can be identified by removing complexities, and start with a simpler model until you find what the problem is. 
-
-A general advice is to see your model as a data generating tool in the first place, simulate data from it using some realistic values for the parameters, and try to recover these parameter values by fitting the model to the simulated data. Simulating from a model will help you understanding how it works, what it does not do, and the data you need to get reasonable parameter estimates. 
-
-We will see other strategies to improve convergence in the next chapters.^[Cross reference relevant chapters. Option 1. Change your sampler. Option 2. Reparameterize (standardize covariates, plus non-centering: $\alpha \sim N(0,\sigma)$ becomes $\alpha = z \sigma$ with $z \sim N(0,1)$).]
-
-## Summary
-
-+ With the Bayes' theorem, you update your beliefs (prior) with new data (likelihood) to get posterior beliefs (posterior): posterior $\propto$ likelihood $\times$ prior.
-
-+ The idea of Markov chain Monte Carlo (MCMC) is to simulate values from a Markov chain which has a stationary distribution equal to the posterior distribution you're after. 
-
-+ In practice, you run a Markov chain multiple times starting from over-dispersed initial values. 
-
-+ You discard iterations in an initial burn-in phase and achieve convergence when all chains reach the same regime. 
-
-+ From there, you run the chains long enough and proceed with calculating Monte Carlo estimates of numerical summaries (e.g. posterior means and credible intervals) for parameters.
-
-## Suggested reading
-
-+ Gelman, A. and Hill, J. (2006). [Data Analysis Using Regression and Multilevel/Hierarchical Models (Analytical Methods for Social Research)](https://www.cambridge.org/core/books/data-analysis-using-regression-and-multilevelhierarchical-models/32A29531C7FD730C3A68951A17C9D983). Cambridge: Cambridge University Press.
-
-+ Gelman, A. and colleagues (2020). [Bayesian workflow](https://arxiv.org/pdf/2011.01808.pdf). arXiv preprint. 
-
-+ McCarthy, M. (2007). [Bayesian Methods for Ecology](https://www.cambridge.org/core/books/bayesian-methods-for-ecology/9225F65B8A25D69B0B6C50B5A9A78201). Cambridge: Cambridge University Press.
-
-+ McElreath, R. (2020). [Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2nd ed.)](https://xcelab.net/rm/statistical-rethinking/). CRC Press.
-
-
-<!--chapter:end:bayesmcmc.Rmd-->
-
-```{r include=FALSE, cache=FALSE}
-# packages
-library(tidyverse)
-theme_set(theme_light())
-library(nimble)
-library(MCMCvis)
-library(magick)
-library(pdftools)
-library(wesanderson)
-library(RColorBrewer)
-library(patchwork)
-library(nimbleEcology)
-library(basicMCMCplots)
-
-# R options
-options(width = 60)
-
-# chunk options
-knitr::opts_chunk$set(
-  comment = ""##"",
-  collapse = TRUE,
-  warning = FALSE,
-  message = FALSE
-  )
-```
-# (PART) II. Transitions {-}
-
-# Introduction {-}
-
-
-<!--chapter:end:introductionparttwo.Rmd-->
-
-```{r include=FALSE, cache=FALSE}
-# packages
-library(tidyverse)
-theme_set(theme_light())
-library(nimble)
-library(MCMCvis)
-library(magick)
-library(pdftools)
-library(wesanderson)
-library(RColorBrewer)
-library(patchwork)
-library(nimbleEcology)
-library(basicMCMCplots)
-
-# R options
-options(width = 60)
-
-# chunk options
-knitr::opts_chunk$set(
-  comment = ""##"",
-  collapse = TRUE,
-  warning = FALSE,
-  message = FALSE
-  )
-```
-# (PART) III. Case studies {-}
-
-# Introduction {-}
-
-
-<!--chapter:end:introductionpartthree.Rmd-->
-
-```{r include=FALSE, cache=FALSE}
-# packages
-library(tidyverse)
-theme_set(theme_light())
-library(nimble)
-library(MCMCvis)
-library(magick)
-library(pdftools)
-library(wesanderson)
-library(RColorBrewer)
-library(patchwork)
-library(nimbleEcology)
-library(basicMCMCplots)
-
-# R options
-options(width = 60)
-
-# chunk options
-knitr::opts_chunk$set(
-  comment = ""##"",
-  collapse = TRUE,
-  warning = FALSE,
-  message = FALSE
-  )
-```
-# Life history {#tradeoffs}
-
-## Access to reproduction
-
-Flamants. 
-
-## Tradeoffs
-
-@morano_life-history_2013, @shefferson_life_2003, and @cruz-flores_sex-specific_nodate
-
-## Breeding dynamics
-
-@pradel_breeding_2012, @desprez_now_2011, @desprez_known_2013, and @pacoureau_population_2019
-
-<!--chapter:end:lifehistory.Rmd-->
-
-```{r include=FALSE, cache=FALSE}
-# packages
-library(tidyverse)
-theme_set(theme_light())
-library(nimble)
-library(MCMCvis)
-library(magick)
-library(pdftools)
-library(wesanderson)
-library(RColorBrewer)
-library(patchwork)
-library(nimbleEcology)
-library(basicMCMCplots)
-
-# R options
-options(width = 60)
-
-# chunk options
-knitr::opts_chunk$set(
-  comment = ""##"",
-  collapse = TRUE,
-  warning = FALSE,
-  message = FALSE
-  )
-```
-# Covariates {#covariates}
-
-## Missing values
-
-NAs reprise du papier de Bonner, ou mod√®le de croissance poisson, ou rien hein...
-
-Work on missing values by [Bonner et al. (2006)](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1541-0420.2005.00399.x) and [Langrock and King (2013)](https://projecteuclid.org/journals/annals-of-applied-statistics/volume-7/issue-3/Maximum-likelihood-estimation-of-markrecapturerecovery-models-in-the-presence-of/10.1214/13-AOAS644.full) and [Worthington et al. (2015)](https://link.springer.com/article/10.1007/s13253-014-0184-z).
-
-## Nonlinearities
-
-splines √† la main et avec jagam, ex snow petrels
-
-## Covariate selection
-
-rjmcmc on turdus merila, papier Evolution Gimenez. Exemple cigognes, papier Gimenez WinBUGS.
-
-## Sex uncertainty
-
-@PradelEtAl2008 and @genovart_exploiting_2012
-
-## Actuarial senescence
-
-@choquet_semi-markov_2011, @peron_evidence_2016, Marzolin on dipper in Ecology.
-
-## Covariate on multinomial logit link
-
-papier Lorele√Ø
-
-## Uncertainty in age
-
-Papier Vincenzo et d'autre papiers.
-
-
-<!--chapter:end:covariates.Rmd-->
-
-```{r include=FALSE, cache=FALSE}
-# packages
-library(tidyverse)
-theme_set(theme_light())
-library(nimble)
-library(MCMCvis)
-library(magick)
-library(pdftools)
-library(wesanderson)
-library(RColorBrewer)
-library(patchwork)
-library(nimbleEcology)
-library(basicMCMCplots)
-
-# R options
-options(width = 60)
-
-# chunk options
-knitr::opts_chunk$set(
-  comment = ""##"",
-  collapse = TRUE,
-  warning = FALSE,
-  message = FALSE
-  )
-```
-# Miscelleanous {#misc}
-
-## Dependence among individuals
-
-@culina_multievent_2013 and @cubaynes_modeling_2021
-
-## Cause-specific mortalities
-
-@fernandez-chacon_causes_2016 and @ruette_comparative_2015
-
-## Disease dynamics
-
-@MarescotEtAl2018 and @santoro_multi-event_2014. House finch as well.
-
-## Combine live captures and dead recoveries
-
-Combine live recapture w/ dead recoveries by [Lebreton et al. (1999)](https://www.tandfonline.com/doi/pdf/10.1080/00063659909477230) and go spatial to account for emigration [Gilroy et al. (2012)](https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/12-0124.1) and [Schaub & Royle (2014)](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12134).
-
-##  Stopover duration
-
-A voir? Papier de Guerin et al. (2017)
-
-## Prior info
-
-Papier McCarthy and Pipper. Cf le code et tout dans le fichier leftover. Ajouter figure avec 3, 4 et 5 ans seulement. 
-
-The example on how to incorporate prior information is in [McCarthy and Masters (2005)](https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-2664.2005.01101.x).
-
-## Posterior predictive check
-
-M-array avec Paganin et de Valpine. Puis IH avec Chambert. Et aussi geometric avec Conn et al. 
-
-## Others
-
-Multispecies. Phylogeny. Path analysis, SEM. Exemple Nina loup hybrides, ou pr√©valence disease, ou sex-ratio, ou la LRS comme dans papier TPB. Manque s√ªrement qqch sur l'int√©r√™t des simulations, en faire un CS? V√©rifier que les posterior predictive checks sont trait√©s quelque part.
-
-
-<!--chapter:end:miscelleanous.Rmd-->
-
-```{r include=FALSE, cache=FALSE}
-# packages
-library(tidyverse)
-theme_set(theme_light())
-library(nimble)
-library(MCMCvis)
-library(magick)
-library(pdftools)
-library(wesanderson)
-library(RColorBrewer)
-library(patchwork)
-library(nimbleEcology)
-library(basicMCMCplots)
-
-# R options
-options(width = 60)
-
-# chunk options
-knitr::opts_chunk$set(
-  comment = ""##"",
-  collapse = TRUE,
-  warning = FALSE,
-  message = FALSE
-  )
-```
-# Lack of fit {#lackoffit}
-
-## Individual heterogeneity
-
-@cubaynes_importance_2010, @gimenez_individual_2010, and @turek_bayesian_2021. Example wolf. Traiter label switching avec constraint dans Nimble. Aussi go fully non-parametric, w/ Daniel's paper. Ou bien exercice mouettes des workshops E-SURGE?
-
-## Trap dep
-
-Papier Roger & Ana. Sur dipper ? Add example for trap-dependence w/ time individual covariate. 
-
-https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0032666
-
-## Transience 
-
-Multievent treatment.
-
-https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0222241
-
-## Temporary emigration
-
-papier Michael.
-
-## Memory model
-
-
-<!--chapter:end:lackoffit.Rmd-->
-
-```{r include=FALSE, cache=FALSE}
-# packages
-library(tidyverse)
-theme_set(theme_light())
-library(nimble)
-library(MCMCvis)
-library(magick)
-library(pdftools)
-library(wesanderson)
-library(RColorBrewer)
-library(patchwork)
-library(nimbleEcology)
-library(basicMCMCplots)
-
-# R options
-options(width = 60)
-
-# chunk options
-knitr::opts_chunk$set(
-  comment = ""##"",
-  collapse = TRUE,
-  warning = FALSE,
-  message = FALSE
-  )
-```
-# (PART) IV. Conclusions {-}
-
-# Introduction {-}
-
-# Take-home messages {-}
-
-
-<!-- ## Take-home messages and recommendations -->
-
-<!-- + We'll wrap up the workshop with a few take-home messages  -->
-<!-- + And recommendations for conducting your own analyses. -->
-
-<!-- ## Make the best of your data with HMMs -->
-
-<!-- + Here is [a searchable list](applistHMM.html) of HMM analyses of capture-recapture data. -->
-
-<!-- + We hope to have provided you with a useful overview of how to use hidden Markov models to analyze capture-recapture data.  -->
-<!-- + We have only scratched the surface of what you can do with these models.  -->
-<!-- + We have assembled a searchable list of HMM analyses of capture-recapture data to get inspiration.  -->
-
-<!-- + This list is not exhaustive, please get in touch with us if you'd like to add a reference. -->
-
-<!-- + It is not exhaustive, we'll continue updating it. Feel free to suggest papers to add to the list.  -->
-
-<!-- ## Bayesian capture-recapture analysis with HMMs -->
-
-<!-- + Before we leave, we'd like to give you a few pieces of advice. -->
-<!-- + This is not rocket science. -->
-<!-- + Just a few things based on our own experience of Bayesian capture-recapture analysis with HMMS. -->
-
-<!-- + Make your ecological question explicit.  -->
-
-<!-- + First things first. Make sure you've spent some to time to make your ecological question explicit.  -->
-<!-- + This step will help you to stay on course, and make the right choices.  -->
-<!-- + For example, it's ok to use subsets of your data to address different questions.  -->
-
-<!-- + Think of observations and states first.  -->
-
-<!-- + Now in terms of modeling. Don't jump on your keyboard right away.  -->
-<!-- + Spend some time thinking about your model with pen and paper.  -->
-<!-- + In particular make sure you have the observations and the states of your HMM.  -->
-
-<!-- + Then write down the observation and transition matrices on paper.  -->
-
-<!-- + Then write down the transition matrix. You may act as if you had no imperfect detection. This is really what you're after, the ecological process (survival, dispersal, etc).  -->
-<!-- + Proceed with the observation matrix.  -->
-
-<!-- + Start simple, all parameters constant for example. Make sure convergence is reached. -->
-
-<!-- + When it comes to model fitting with Nimble, start simple.  -->
-<!-- + Consider all parameters constant.  -->
-<!-- + Make sure convergence is reached.  -->
-
-<!-- + Add complexity one step at a time.  -->
-
-<!-- + Then add complexity. Time effect for example. Or random effects. -->
-<!-- + Or uncertainty in the assignment of states.  -->
-
-<!-- ## Bayesian capture-recapture analysis with HMMs -->
-
-<!-- + Use simulations to better understand your model.  -->
-
-<!-- + Nimble models can be used to simulate data, check out [this tutorial](https://r-nimble.org/nimbleExamples/simulation_from_model.html).   -->
-
-<!-- + When it comes to model building, consider simulating data to better understand your model.  -->
-<!-- + You will always learn something on your model by seeing it an engine to generate data, instead of estimating its parameters. -->
-<!-- + The cool thing with nimble is that you can you models to simulate data. There is a tutorial for that.   -->
-
-<!-- + Do not try to optimize your code. Make it work first, then think of optimization.  -->
-
-<!-- > [""Premature optimization is the root of all evil""](https://stackify.com/premature-optimization-evil/) - Donald Knuth (creator of TeX and author of [""The Art of Computer Programming""](https://en.wikipedia.org/wiki/The_Art_of_Computer_Programming)) -->
-
-<!-- + Another advice, quite general in programming, is to not try to optimize your code -->
-<!-- + Or to try to make it elegant right away. Make it work first.  -->
-<!-- + Then think of optimization.  -->
-
-<!-- + Read [Bayesian workflow](https://arxiv.org/abs/2011.01808) by Gelman et al. (2021). -->
-
-<!-- + More recommendations on Bayesian analyses in this recent paper by Gelman and collaborations.  -->
-<!-- + They offer a workflow for bayesian analyses. -->
-<!-- + In which they discuss model building, model comparison, model checking, model validation, model understanding and troubleshooting of computational problems. -->
-
-<!-- <!-- --- --> -->
-<!-- <!-- ## Nimble --> -->
-
-<!-- <!-- + [TO BE COMPLETED BY ALL] --> -->
-
-<!-- <!-- + Go for `nimbleMCMC()` if standard needs.  --> -->
-
-<!-- <!-- + Unleash full `Nimble` potential for improving MCMC or implementing new distributions.  --> -->
-
-<!-- ## Till next time -->
-
-<!-- + The Slack space will remain for some time. Happy to answer questions you might have related to the workshop.  -->
-
-<!-- + The Slack space will remain for some time.  -->
-<!-- + We'll be happy to answer the questions you might have related to the workshop.  -->
-
-<!-- + Website will be updated with -->
-
-<!--     + video recordings -->
-<!--     + your feedbacks -->
-<!--     + a FAQ section based on your questions -->
-
-<!-- + We will update the workshop website in the coming weeks.  -->
-<!-- + With the video recordings of course.  -->
-<!-- + Any feedback you might have. Please get in touch with me if you have any, that would be great.  -->
-<!-- + Our plan is also to gather our exchanges in a Frequently Asked Questions section on the website.  -->
-
-<!-- + A book is on its way. More in 2022 hopefully. -->
-
-<!-- + And last, a book is on its way. Based on the material we used for the workshop and more stuff.  -->
-<!-- + Also half the book will be about case studies reproducing analysis from published papers.  -->
-<!-- + More in 2022 hopefully.  -->
-
-<!-- ## Let's see if I can put to use my own pieces of advice - case studies -->
-
-<!--chapter:end:introductionpartfour.Rmd-->
-
-```{r include=FALSE, cache=FALSE}
-# packages
-library(tidyverse)
-theme_set(theme_light())
-library(nimble)
-library(MCMCvis)
-library(magick)
-library(pdftools)
-library(wesanderson)
-library(RColorBrewer)
-library(patchwork)
-library(nimbleEcology)
-library(basicMCMCplots)
-
-# R options
-options(width = 60)
-
-# chunk options
-knitr::opts_chunk$set(
-  comment = ""##"",
-  collapse = TRUE,
-  warning = FALSE,
-  message = FALSE
-  )
-```
-\backmatter
-
-`r if (knitr:::is_html_output()) '
-# References {-}
-'`
-
-<!--chapter:end:references.Rmd-->
-

---FILE: docs/404.html---
@@ -0,0 +1,152 @@
+<!DOCTYPE html>
+<html lang=""en"">
+<head>
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>Page not found | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are..."">
+<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
+<meta property=""og:title"" content=""Page not found | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/404.html"">
+<meta property=""og:description"" content=""The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are..."">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""Page not found | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are..."">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+    
+    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
+  </style>
+<style type=""text/css"">
+    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
+    div.csl-bib-body { }
+    div.csl-entry {
+      clear: both;
+        }
+    .hanging div.csl-entry {
+      margin-left:2em;
+      text-indent:-2em;
+    }
+    div.csl-left-margin {
+      min-width:2em;
+      float:left;
+    }
+    div.csl-right-inline {
+      margin-left:2em;
+      padding-left:1em;
+    }
+    div.csl-indent {
+      margin-left: 2em;
+    }
+  </style>
+<link rel=""stylesheet"" href=""bs4_style.css"">
+</head>
+<body data-spy=""scroll"" data-target=""#toc"">
+
+<div class=""container-fluid"">
+<div class=""row"">
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+
+    <div class=""d-flex align-items-start justify-content-between"">
+      <h1>
+        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
+        <small class=""text-muted"">Theory and Case Studies in R</small>
+      </h1>
+      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
+    </div>
+
+    <div id=""main-nav"" class=""collapse-lg"">
+      <form role=""search"">
+        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
+</form>
+
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li><a class="""" href=""about-the-author.html"">About the author</a></li>
+<li class=""book-part"">I. Foundations</li>
+<li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li class=""book-part"">II. Transitions</li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li class=""book-part"">III. Case studies</li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li class=""book-part"">IV. Conclusions</li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
+
+        <div class=""book-extra"">
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
+        </div>
+      </nav>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""page-not-found"" class=""section level1"">
+<h1>Page not found<a class=""anchor"" aria-label=""anchor"" href=""#page-not-found""><i class=""fas fa-link""></i></a>
+</h1>
+<p>The page you requested cannot be found (perhaps it was moved or renamed).</p>
+<p>You may want to try searching to find the page's new location, or use
+the table of contents to find the page you are looking for.</p>
+</div>
+  <div class=""chapter-nav"">
+<div class=""empty""></div>
+<div class=""empty""></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    </div>
+
+</div>
+</div> <!-- .container -->
+
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-14.</p>
+  </div>
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
+  </div>
+
+</div></div>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
+</body>
+</html>

---FILE: docs/about-the-author.html---
@@ -0,0 +1,167 @@
+<!DOCTYPE html>
+<html lang=""en"">
+<head>
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>About the author | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""My name is Olivier Gimenez (https://oliviergimenez.github.io/). I am a senior (euphemism for not so young anymore) scientist at the National Centre for Scientific Research (CNRS) in the beautiful..."">
+<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
+<meta property=""og:title"" content=""About the author | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/about-the-author.html"">
+<meta property=""og:description"" content=""My name is Olivier Gimenez (https://oliviergimenez.github.io/). I am a senior (euphemism for not so young anymore) scientist at the National Centre for Scientific Research (CNRS) in the beautiful..."">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""About the author | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""My name is Olivier Gimenez (https://oliviergimenez.github.io/). I am a senior (euphemism for not so young anymore) scientist at the National Centre for Scientific Research (CNRS) in the beautiful..."">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+    
+    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
+  </style>
+<style type=""text/css"">
+    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
+    div.csl-bib-body { }
+    div.csl-entry {
+      clear: both;
+        }
+    .hanging div.csl-entry {
+      margin-left:2em;
+      text-indent:-2em;
+    }
+    div.csl-left-margin {
+      min-width:2em;
+      float:left;
+    }
+    div.csl-right-inline {
+      margin-left:2em;
+      padding-left:1em;
+    }
+    div.csl-indent {
+      margin-left: 2em;
+    }
+  </style>
+<link rel=""stylesheet"" href=""bs4_style.css"">
+</head>
+<body data-spy=""scroll"" data-target=""#toc"">
+
+<div class=""container-fluid"">
+<div class=""row"">
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+
+    <div class=""d-flex align-items-start justify-content-between"">
+      <h1>
+        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
+        <small class=""text-muted"">Theory and Case Studies in R</small>
+      </h1>
+      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
+    </div>
+
+    <div id=""main-nav"" class=""collapse-lg"">
+      <form role=""search"">
+        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
+</form>
+
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li><a class=""active"" href=""about-the-author.html"">About the author</a></li>
+<li class=""book-part"">I. Foundations</li>
+<li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li class=""book-part"">II. Transitions</li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li class=""book-part"">III. Case studies</li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li class=""book-part"">IV. Conclusions</li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
+
+        <div class=""book-extra"">
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
+        </div>
+      </nav>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""about-the-author"" class=""section level1 unnumbered"">
+<h1>About the author<a class=""anchor"" aria-label=""anchor"" href=""#about-the-author""><i class=""fas fa-link""></i></a>
+</h1>
+<p>My name is Olivier Gimenez (<a href=""https://oliviergimenez.github.io/"" class=""uri"">https://oliviergimenez.github.io/</a>). I am a senior (euphemism for not so young anymore) scientist at the National Centre for Scientific Research (CNRS) in the beautiful city of Montpellier, France.</p>
+<p>I struggled studying maths, obtained a PhD in applied statistics a long time ago in a galaxy of wine and cheese. I was awarded my habilitation (<a href=""https://en.wikipedia.org/wiki/Habilitation"" class=""uri"">https://en.wikipedia.org/wiki/Habilitation</a>) in ecology and evolution so that I could stop pretending to understand what my colleagues were talking about. More recently I embarked in sociology studies because hey, why not.</p>
+<p>Lost somewhere at the interface of animal ecology, statistical modeling and social sciences, my so-called expertise lies in population dynamics and species distribution modeling to address questions in ecology and conservation biology about the impact of human activities and the management of large carnivores. I would be nothing without the students and colleagues who are kind enough to bear with me.</p>
+<p>You may find me on Twitter (<a href=""https://twitter.com/oaggimenez"" class=""uri"">https://twitter.com/oaggimenez</a>), GitHub (<a href=""https://github.com/oliviergimenez"" class=""uri"">https://github.com/oliviergimenez</a>), or get in touch <a href=""mailto:olivier.gimenez@cefe.cnrs.fr"">by email</a>.</p>
+
+</div>
+
+
+
+  <div class=""chapter-nav"">
+<div class=""prev""><a href=""preface.html"">Preface</a></div>
+<div class=""next""><a href=""introduction.html"">Introduction</a></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
+      <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#about-the-author"">About the author</a></li></ul>
+
+      <div class=""book-extra"">
+        <ul class=""list-unstyled"">
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/author.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/author.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+        </ul>
+</div>
+    </nav>
+</div>
+
+</div>
+</div> <!-- .container -->
+
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-14.</p>
+  </div>
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
+  </div>
+
+</div></div>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
+</body>
+</html>

---FILE: docs/covariates.html---
@@ -0,0 +1,213 @@
+<!DOCTYPE html>
+<html lang=""en"">
+<head>
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>Chapter 3 Covariates | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""3.1 Missing values NAs reprise du papier de Bonner, ou mod√®le de croissance poisson, ou rien hein‚Ä¶ Work on missing values by Bonner et al.¬†(2006) and Langrock and King (2013) and Worthington et..."">
+<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
+<meta property=""og:title"" content=""Chapter 3 Covariates | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/covariates.html"">
+<meta property=""og:description"" content=""3.1 Missing values NAs reprise du papier de Bonner, ou mod√®le de croissance poisson, ou rien hein‚Ä¶ Work on missing values by Bonner et al.¬†(2006) and Langrock and King (2013) and Worthington et..."">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""Chapter 3 Covariates | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""3.1 Missing values NAs reprise du papier de Bonner, ou mod√®le de croissance poisson, ou rien hein‚Ä¶ Work on missing values by Bonner et al.¬†(2006) and Langrock and King (2013) and Worthington et..."">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+    
+    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
+  </style>
+<style type=""text/css"">
+    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
+    div.csl-bib-body { }
+    div.csl-entry {
+      clear: both;
+        }
+    .hanging div.csl-entry {
+      margin-left:2em;
+      text-indent:-2em;
+    }
+    div.csl-left-margin {
+      min-width:2em;
+      float:left;
+    }
+    div.csl-right-inline {
+      margin-left:2em;
+      padding-left:1em;
+    }
+    div.csl-indent {
+      margin-left: 2em;
+    }
+  </style>
+<link rel=""stylesheet"" href=""bs4_style.css"">
+</head>
+<body data-spy=""scroll"" data-target=""#toc"">
+
+<div class=""container-fluid"">
+<div class=""row"">
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+
+    <div class=""d-flex align-items-start justify-content-between"">
+      <h1>
+        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
+        <small class=""text-muted"">Theory and Case Studies in R</small>
+      </h1>
+      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
+    </div>
+
+    <div id=""main-nav"" class=""collapse-lg"">
+      <form role=""search"">
+        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
+</form>
+
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li><a class="""" href=""about-the-author.html"">About the author</a></li>
+<li class=""book-part"">I. Foundations</li>
+<li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li class=""book-part"">II. Transitions</li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li class=""book-part"">III. Case studies</li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
+<li><a class=""active"" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li class=""book-part"">IV. Conclusions</li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
+
+        <div class=""book-extra"">
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
+        </div>
+      </nav>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""covariates"" class=""section level1"" number=""3"">
+<h1>
+<span class=""header-section-number"">3</span> Covariates<a class=""anchor"" aria-label=""anchor"" href=""#covariates""><i class=""fas fa-link""></i></a>
+</h1>
+<div id=""missing-values"" class=""section level2"" number=""3.1"">
+<h2>
+<span class=""header-section-number"">3.1</span> Missing values<a class=""anchor"" aria-label=""anchor"" href=""#missing-values""><i class=""fas fa-link""></i></a>
+</h2>
+<p>NAs reprise du papier de Bonner, ou mod√®le de croissance poisson, ou rien hein‚Ä¶</p>
+<p>Work on missing values by <a href=""https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1541-0420.2005.00399.x"">Bonner et al.¬†(2006)</a> and <a href=""https://projecteuclid.org/journals/annals-of-applied-statistics/volume-7/issue-3/Maximum-likelihood-estimation-of-markrecapturerecovery-models-in-the-presence-of/10.1214/13-AOAS644.full"">Langrock and King (2013)</a> and <a href=""https://link.springer.com/article/10.1007/s13253-014-0184-z"">Worthington et al.¬†(2015)</a>.</p>
+</div>
+<div id=""nonlinearities"" class=""section level2"" number=""3.2"">
+<h2>
+<span class=""header-section-number"">3.2</span> Nonlinearities<a class=""anchor"" aria-label=""anchor"" href=""#nonlinearities""><i class=""fas fa-link""></i></a>
+</h2>
+<p>splines √† la main et avec jagam, ex snow petrels</p>
+</div>
+<div id=""covariate-selection"" class=""section level2"" number=""3.3"">
+<h2>
+<span class=""header-section-number"">3.3</span> Covariate selection<a class=""anchor"" aria-label=""anchor"" href=""#covariate-selection""><i class=""fas fa-link""></i></a>
+</h2>
+<p>rjmcmc on turdus merila, papier Evolution Gimenez. Exemple cigognes, papier Gimenez WinBUGS.</p>
+</div>
+<div id=""sex-uncertainty"" class=""section level2"" number=""3.4"">
+<h2>
+<span class=""header-section-number"">3.4</span> Sex uncertainty<a class=""anchor"" aria-label=""anchor"" href=""#sex-uncertainty""><i class=""fas fa-link""></i></a>
+</h2>
+<p><span class=""citation"">Pradel et al. (<a href=""references.html#ref-PradelEtAl2008"">2008</a>)</span> and <span class=""citation"">Genovart, Pradel, and Oro (<a href=""references.html#ref-genovart_exploiting_2012"">2012</a>)</span></p>
+</div>
+<div id=""actuarial-senescence"" class=""section level2"" number=""3.5"">
+<h2>
+<span class=""header-section-number"">3.5</span> Actuarial senescence<a class=""anchor"" aria-label=""anchor"" href=""#actuarial-senescence""><i class=""fas fa-link""></i></a>
+</h2>
+<p><span class=""citation"">Choquet et al. (<a href=""references.html#ref-choquet_semi-markov_2011"">2011</a>)</span>, <span class=""citation"">P√©ron et al. (<a href=""references.html#ref-peron_evidence_2016"">2016</a>)</span>, Marzolin on dipper in Ecology.</p>
+</div>
+<div id=""covariate-on-multinomial-logit-link"" class=""section level2"" number=""3.6"">
+<h2>
+<span class=""header-section-number"">3.6</span> Covariate on multinomial logit link<a class=""anchor"" aria-label=""anchor"" href=""#covariate-on-multinomial-logit-link""><i class=""fas fa-link""></i></a>
+</h2>
+<p>papier Lorele√Ø</p>
+</div>
+<div id=""uncertainty-in-age"" class=""section level2"" number=""3.7"">
+<h2>
+<span class=""header-section-number"">3.7</span> Uncertainty in age<a class=""anchor"" aria-label=""anchor"" href=""#uncertainty-in-age""><i class=""fas fa-link""></i></a>
+</h2>
+<p>Papier Vincenzo et d‚Äôautre papiers.</p>
+
+</div>
+</div>
+  <div class=""chapter-nav"">
+<div class=""prev""><a href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></div>
+<div class=""next""><a href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
+      <ul class=""nav navbar-nav"">
+<li><a class=""nav-link"" href=""#covariates""><span class=""header-section-number"">3</span> Covariates</a></li>
+<li><a class=""nav-link"" href=""#missing-values""><span class=""header-section-number"">3.1</span> Missing values</a></li>
+<li><a class=""nav-link"" href=""#nonlinearities""><span class=""header-section-number"">3.2</span> Nonlinearities</a></li>
+<li><a class=""nav-link"" href=""#covariate-selection""><span class=""header-section-number"">3.3</span> Covariate selection</a></li>
+<li><a class=""nav-link"" href=""#sex-uncertainty""><span class=""header-section-number"">3.4</span> Sex uncertainty</a></li>
+<li><a class=""nav-link"" href=""#actuarial-senescence""><span class=""header-section-number"">3.5</span> Actuarial senescence</a></li>
+<li><a class=""nav-link"" href=""#covariate-on-multinomial-logit-link""><span class=""header-section-number"">3.6</span> Covariate on multinomial logit link</a></li>
+<li><a class=""nav-link"" href=""#uncertainty-in-age""><span class=""header-section-number"">3.7</span> Uncertainty in age</a></li>
+</ul>
+
+      <div class=""book-extra"">
+        <ul class=""list-unstyled"">
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/covariates.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/covariates.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+        </ul>
+</div>
+    </nav>
+</div>
+
+</div>
+</div> <!-- .container -->
+
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-14.</p>
+  </div>
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
+  </div>
+
+</div></div>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
+</body>
+</html>

---FILE: docs/crashcourse.html---
@@ -0,0 +1,621 @@
+<!DOCTYPE html>
+<html lang=""en"">
+<head>
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>Chapter 1 Bayesian statistics &amp; MCMC | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""1.1 Introduction In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to..."">
+<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
+<meta property=""og:title"" content=""Chapter 1 Bayesian statistics &amp; MCMC | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/crashcourse.html"">
+<meta property=""og:description"" content=""1.1 Introduction In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to..."">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""Chapter 1 Bayesian statistics &amp; MCMC | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""1.1 Introduction In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to..."">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+    
+    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
+  </style>
+<style type=""text/css"">
+    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
+    div.csl-bib-body { }
+    div.csl-entry {
+      clear: both;
+        }
+    .hanging div.csl-entry {
+      margin-left:2em;
+      text-indent:-2em;
+    }
+    div.csl-left-margin {
+      min-width:2em;
+      float:left;
+    }
+    div.csl-right-inline {
+      margin-left:2em;
+      padding-left:1em;
+    }
+    div.csl-indent {
+      margin-left: 2em;
+    }
+  </style>
+<link rel=""stylesheet"" href=""bs4_style.css"">
+</head>
+<body data-spy=""scroll"" data-target=""#toc"">
+
+<div class=""container-fluid"">
+<div class=""row"">
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+
+    <div class=""d-flex align-items-start justify-content-between"">
+      <h1>
+        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
+        <small class=""text-muted"">Theory and Case Studies in R</small>
+      </h1>
+      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
+    </div>
+
+    <div id=""main-nav"" class=""collapse-lg"">
+      <form role=""search"">
+        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
+</form>
+
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li><a class="""" href=""about-the-author.html"">About the author</a></li>
+<li class=""book-part"">I. Foundations</li>
+<li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class=""active"" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li class=""book-part"">II. Transitions</li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li class=""book-part"">III. Case studies</li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li class=""book-part"">IV. Conclusions</li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
+
+        <div class=""book-extra"">
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
+        </div>
+      </nav>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""crashcourse"" class=""section level1"" number=""1"">
+<h1>
+<span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC<a class=""anchor"" aria-label=""anchor"" href=""#crashcourse""><i class=""fas fa-link""></i></a>
+</h1>
+<div id=""introduction-1"" class=""section level2"" number=""1.1"">
+<h2>
+<span class=""header-section-number"">1.1</span> Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-1""><i class=""fas fa-link""></i></a>
+</h2>
+<p>In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to implement the Bayesian method for more complex analyses. This is not an exhaustive treatment of Bayesian statistics, but you should get what you need to navigate through the rest of the book.</p>
+</div>
+<div id=""bayes-theorem"" class=""section level2"" number=""1.2"">
+<h2>
+<span class=""header-section-number"">1.2</span> Bayes‚Äô theorem<a class=""anchor"" aria-label=""anchor"" href=""#bayes-theorem""><i class=""fas fa-link""></i></a>
+</h2>
+<p>Let‚Äôs not wait any longer and jump into it. Bayesian statistics relies on the Bayes‚Äô theorem (or law, or rule, whatever you prefer) named after Reverend Thomas Bayes (Figure <a href=""crashcourse.html#fig:revbayes"">1.1</a>). This theorem was published in 1763 two years after Bayes‚Äô death thanks to his friend‚Äôs efforts Richard Price, and was independently discovered by Pierre-Simon Laplace <span class=""citation"">(<a href=""references.html#ref-mcgrayne2011"">McGrayne 2011</a>)</span>.</p>
+<div class=""figure"" style=""text-align: center"">
+<span style=""display:block;"" id=""fig:revbayes""></span>
+<img src=""images/amazing-thomas-bayes-illustration.jpg"" alt=""Cartoon of Thomas Bayes with Bayes' theorem in background. Source: [James Kulich](https://www.elmhurst.edu/blog/thomas-bayes/)"" width=""100%""><p class=""caption"">
+Figure 1.1: Cartoon of Thomas Bayes with Bayes‚Äô theorem in background. Source: <a href=""https://www.elmhurst.edu/blog/thomas-bayes/"">James Kulich</a>
+</p>
+</div>
+<p>As we will see in a minute, Bayes‚Äô theorem is all about conditional probabilities, which are somehow tricky to understand. Conditional probability of outcome or event A given event B, which we denote <span class=""math inline"">\(\Pr(A \mid B)\)</span>, is the probability that A occurs, revised by considering the additional information that event B has occurred.<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;For example, a friend of yours rolls a fair dice and asks you the probability that the outcome was a six (event A). Your answer is 1/6 because each side of the dice is equally likely to come up. Now imagine that you‚Äôre told the number rolled was even (event B) before you answer your friend‚Äôs question. Because there are only three even numbers, one of which is six, you may revise your answer for the probability that a six was rolled from 1/6 to &lt;span class=""math inline""&gt;\(\Pr(A \mid B) = 1/3\)&lt;/span&gt;.&lt;/p&gt;'><sup>2</sup></a> The order in which A and B appear is important, make sure you do not confuse <span class=""math inline"">\(\Pr(A \mid B)\)</span> and <span class=""math inline"">\(\Pr(B \mid A)\)</span>.</p>
+<p>Bayes‚Äô theorem (Figure <a href=""crashcourse.html#fig:bayestheorem"">1.2</a>) gives you <span class=""math inline"">\(\Pr(A \mid B)\)</span> using marginal probabilities <span class=""math inline"">\(\Pr(A)\)</span> and <span class=""math inline"">\(\Pr(B)\)</span> and <span class=""math inline"">\(\Pr(B \mid A)\)</span>:
+<span class=""math display"">\[\Pr(A \mid B) = \displaystyle{\frac{ \Pr(B \mid A) \; \Pr(A)}{\Pr(B)}}.\]</span>
+Originally, Bayes‚Äô theorem was seen as a way to infer an unkown cause A of a particular effect B, knowing the probability of effect B given cause A. Think for example of a situation where a medical diagnosis is needed, with A an unkown disease and B symptoms, the doctor knows P(symptoms|disease) and wants to derive P(disease|symptoms). This way of reversing <span class=""math inline"">\(\Pr(B \mid A)\)</span> into <span class=""math inline"">\(\Pr(A \mid B)\)</span> explains why Bayesian thinking used to be referred to as ‚Äòinverse probability‚Äô.</p>
+<div class=""figure"" style=""text-align: center"">
+<span style=""display:block;"" id=""fig:bayestheorem""></span>
+<img src=""images/bayes_neon.jpeg"" alt=""Bayes' theorem spelt out in blue neon. Source: [Wikipedia](https://en.wikipedia.org/wiki/Bayes%27_theorem)"" width=""400""><p class=""caption"">
+Figure 1.2: Bayes‚Äô theorem spelt out in blue neon. Source: <a href=""https://en.wikipedia.org/wiki/Bayes%27_theorem"">Wikipedia</a>
+</p>
+</div>
+<p>I don‚Äôt know about you, but I need to think twice for not messing the letters around. I find it easier to remember Bayes‚Äô theorem written like this<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;When teaching Bayes‚Äô theorem, I am very much inspired by Tristan Mahr‚Äôs slides from his introduction to Bayesian regression &lt;a href=""https://www.tjmahr.com/bayes-intro-lecture-slides-2017/"" class=""uri""&gt;https://www.tjmahr.com/bayes-intro-lecture-slides-2017/&lt;/a&gt;&lt;/p&gt;'><sup>3</sup></a>:</p>
+<span class=""math display"">\[ \Pr(\text{hypothesis} \mid \text{data}) = \frac{ \Pr(\text{data} \mid \text{hypothesis}) \; \Pr(\text{hypothesis})}{\Pr(\text{data})} \]</span>
+
+<div class=""rmdnote"">
+The <em>hypothesis</em> is a working assumption about which you want to learn using <em>data</em>. In capture‚Äìrecapture analyses, the hypothesis might be a parameter like detection probability, or regression parameters in a relationship between survival probability and a covariate. Bayes‚Äô theorem tells us how to obtain the probability of a hypothesis given the data we have.
+</div>
+<p>This is great because think about it, this is exactly what the scientific method is! We‚Äôd like to know how plausible some hypothesis is based on some data we collected, and possibly compare several hypotheses among them. In that respect, the Bayesian reasoning matches the scientific reasoning, which probably explains why the Bayesian framework is so natural for doing and understanding statistics.</p>
+<p>You might ask then, why is Bayesian statistics not the default in statistics? Clearly, because of futile wars between male statisticians (including Ronald Fisher, Jerzy Neyman and Egon Sharpe Pearson among others), little progress was made for over two centuries. Also, until recently, there were practical problems to implement Bayes‚Äô theorem. Recent advances in computational power coupled with the development of new algorithms have led to a great increase in the application of Bayesian methods within the last three decades.</p>
+</div>
+<div id=""what-is-the-bayesian-approach"" class=""section level2"" number=""1.3"">
+<h2>
+<span class=""header-section-number"">1.3</span> What is the Bayesian approach?<a class=""anchor"" aria-label=""anchor"" href=""#what-is-the-bayesian-approach""><i class=""fas fa-link""></i></a>
+</h2>
+<p>Typical statistical problems involve estimating a parameter (or several parameters) <span class=""math inline"">\(\theta\)</span> with available data. To do so, you might be more used to the frequentist rather than the Bayesian method. The frequentist approach, and in particular maximum likelihood estimation (MLE), assumes that the parameters are fixed, and have unknown values to be estimated. Therefore classical estimates are generally point estimates of the parameters of interest. In contrast, the Bayesian approach assumes that the parameters are not fixed, and have some unknown distribution<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;A probability distribution is a mathematical expression that gives the probability for a random variable to take particular values. A probability distribution may be either discrete (e.g., the Bernoulli, Binomial or Poisson distribution) or continuous (e.g., the Gaussian distribution also known as the normal distribution)&lt;/p&gt;""><sup>4</sup></a>.</p>
+<p>The Bayesian approach is based upon the idea that you, as an experimenter, begin with some prior beliefs about the system. Then you collect data and update your prior beliefs on the basis of observations. These observations might arise from field work, lab work or from expertise of your esteemed colleagues. This updating process is based upon Bayes‚Äô theorem. Loosely, let‚Äôs say <span class=""math inline"">\(A = \theta\)</span> and <span class=""math inline"">\(B = \text{data}\)</span>, then Bayes‚Äô theorem gives you a way to estimate parameter <span class=""math inline"">\(\theta\)</span> given the data you have:</p>
+<p><span class=""math display"">\[{\color{red}{\Pr(\theta \mid \text{data})}} = \frac{\color{blue}{\Pr(\text{data} \mid \theta)} \times \color{green}{\Pr(\theta)}}{\color{orange}{\Pr(\text{data})}}.\]</span>
+Let‚Äôs spend some time going through each quantity in this formula.</p>
+<p>On the left-hand side is the <span class=""math inline"">\(\color{red}{\text{posterior distribution}}\)</span>. It represents what you know after having seen the data. This is the basis for inference and clearly what you‚Äôre after, a distribution, possibly multivariate if you have more than one parameter.</p>
+<p>On the right-hand side, there is the <span class=""math inline"">\(\color{blue}{\text{likelihood}}\)</span>. This quantity is the same as in the MLE approach. Yes, the Bayesian and frequentist approaches have the same likelihood at their core, which mostly explains why results often do not differ much. The likelihood captures the information you have in your data, given a model parameterized with <span class=""math inline"">\(\theta\)</span>.</p>
+<p>Then we have the <span class=""math inline"">\(\color{green}{\text{prior distribution}}\)</span>. This quantity represents what you know before seeing the data. This is the source of much discussion about the Bayesian approach. It may be vague if you don‚Äôt know anything about <span class=""math inline"">\(\theta\)</span>. Usually however, you never start from scratch, and you‚Äôd like your prior to reflect the information you have<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;Shall I include a section on sensitivity analyses in this chapter or later in the book? Cross-reference section in Survival chapter where prior elicitation is covered.&lt;/p&gt;""><sup>5</sup></a>.</p>
+<p>Last, we have <span class=""math inline"">\(\color{orange}{\Pr(\text{data})}\)</span> which is sometimes called the average likelihood because it is obtained by integrating the likelihood with respect to the prior <span class=""math inline"">\(\color{orange}{\Pr(\text{data}) = \int{L(\text{data} \mid \theta)\Pr(\theta) d\theta}}\)</span> so that the posterior is standardized, that is it integrates to one for the posterior to be a distribution. The average likelihood is an integral with dimension the number of parameters <span class=""math inline"">\(\theta\)</span> you need to estimate. This quantity is difficult, if not impossible, to calculate in general. This is one of the reasons why the Bayesian method wasn‚Äôt used until recently, and why we need algorithms to estimate posterior distributions as I illustrate in the next section.</p>
+</div>
+<div id=""numerical-approx"" class=""section level2"" number=""1.4"">
+<h2>
+<span class=""header-section-number"">1.4</span> Approximating posteriors via numerical integration<a class=""anchor"" aria-label=""anchor"" href=""#numerical-approx""><i class=""fas fa-link""></i></a>
+</h2>
+<p>Let‚Äôs take an example to illustrate Bayes‚Äô theorem. Say we capture, mark and release <span class=""math inline"">\(n = 57\)</span> animals at the beginning of a winter, out of which we recapture <span class=""math inline"">\(y = 19\)</span> animals alive<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;We used a similar example in &lt;span class=""citation""&gt;King et al. (&lt;a href=""references.html#ref-king_bayesian_2009""&gt;2009&lt;/a&gt;)&lt;/span&gt;&lt;/p&gt;'><sup>6</sup></a>. We‚Äôd like to estimate winter survival <span class=""math inline"">\(\theta\)</span>.</p>
+<div class=""sourceCode"" id=""cb2""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">y</span> <span class=""op"">&lt;-</span> <span class=""fl"">19</span> <span class=""co""># nb of success</span></span>
+<span><span class=""va"">n</span> <span class=""op"">&lt;-</span> <span class=""fl"">57</span> <span class=""co""># nb of attempts</span></span></code></pre></div>
+<p>We build our model first. Assuming all animals are independent of each other and have the same survival probability, then <span class=""math inline"">\(y\)</span> the number of alive animals at the end of the winter is a binomial distribution<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;I follow &lt;span class=""citation""&gt;McElreath (&lt;a href=""references.html#ref-mcelreathbook""&gt;2016&lt;/a&gt;)&lt;/span&gt; and use labels on the right to help remember what each line is about.&lt;/p&gt;'><sup>7</sup></a> with <span class=""math inline"">\(n\)</span> trials and <span class=""math inline"">\(\theta\)</span> the probability of success:</p>
+<p><span class=""math display"">\[\begin{align*}
+y &amp;\sim \text{Binomial}(n, \theta) &amp;\text{[likelihood]}
+\end{align*}\]</span></p>
+<p>This likelihood can be visualised in <code>R</code>:</p>
+<div class=""sourceCode"" id=""cb3""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">grid</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/seq.html"">seq</a></span><span class=""op"">(</span><span class=""fl"">0</span>, <span class=""fl"">1</span>, <span class=""fl"">0.01</span><span class=""op"">)</span> <span class=""co""># grid of values for survival</span></span>
+<span><span class=""va"">likelihood</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Binomial.html"">dbinom</a></span><span class=""op"">(</span><span class=""va"">y</span>, <span class=""va"">n</span>, <span class=""va"">grid</span><span class=""op"">)</span> <span class=""co""># compute binomial likelihood</span></span>
+<span><span class=""va"">df</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/data.frame.html"">data.frame</a></span><span class=""op"">(</span>survival <span class=""op"">=</span> <span class=""va"">grid</span>, likelihood <span class=""op"">=</span> <span class=""va"">likelihood</span><span class=""op"">)</span> </span>
+<span><span class=""va"">df</span> <span class=""op"">%&gt;%</span></span>
+<span>  <span class=""fu"">ggplot</span><span class=""op"">(</span><span class=""op"">)</span> <span class=""op"">+</span> </span>
+<span>  <span class=""fu"">aes</span><span class=""op"">(</span>x <span class=""op"">=</span> <span class=""va"">survival</span>, y <span class=""op"">=</span> <span class=""va"">likelihood</span><span class=""op"">)</span> <span class=""op"">+</span> </span>
+<span>  <span class=""fu"">geom_line</span><span class=""op"">(</span>size <span class=""op"">=</span> <span class=""fl"">1.5</span><span class=""op"">)</span></span></code></pre></div>
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:binlik""></span>
+<img src=""banana-book_files/figure-html/binlik-1.png"" alt=""Binomial likelihood with $n = 57$ released animals and $y = 19$ survivors after winter. The value of survival (on the x-axis) that corresponds to the maximum of the likelihood function (on the y-axis) is the MLE, or the proportion of success in this example, close to 0.33."" width=""672""><p class=""caption"">
+Figure 1.3: Binomial likelihood with <span class=""math inline"">\(n = 57\)</span> released animals and <span class=""math inline"">\(y = 19\)</span> survivors after winter. The value of survival (on the x-axis) that corresponds to the maximum of the likelihood function (on the y-axis) is the MLE, or the proportion of success in this example, close to 0.33.
+</p>
+</div>
+<p>Besides the likelihood, priors are another component of the model in the Bayesian approach. For a parameter that is a probability, the one thing we know is that the prior should be a continuous random variable that lies between 0 and 1. To reflect that, we often go for the uniform distribution <span class=""math inline"">\(U(0,1)\)</span> to imply <em>vague</em> priors. Here vague means that survival has, before we see the data, the same probability of falling between 0.1 and 0.2 and between 0.8 and 0.9, for example.</p>
+<p><span class=""math display"">\[\begin{align*}
+\theta &amp;\sim \text{Uniform}(0, 1) &amp;\text{[prior for }\theta \text{]}
+\end{align*}\]</span></p>
+<p>Now we apply Bayes‚Äô theorem. We write a <code>R</code> function that computes the product of the likelihood times the prior, or the numerator in Bayes‚Äô theorem: <span class=""math inline"">\(\Pr(\text{data} \mid \theta) \times \Pr(\theta)\)</span></p>
+<div class=""sourceCode"" id=""cb4""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">numerator</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">theta</span><span class=""op"">)</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Binomial.html"">dbinom</a></span><span class=""op"">(</span><span class=""va"">y</span>, <span class=""va"">n</span>, <span class=""va"">theta</span><span class=""op"">)</span> <span class=""op"">*</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Uniform.html"">dunif</a></span><span class=""op"">(</span><span class=""va"">theta</span>, <span class=""fl"">0</span>, <span class=""fl"">1</span><span class=""op"">)</span></span></code></pre></div>
+<p>We write another function that calculates the denominator, the average likelihood: <span class=""math inline"">\(\Pr(\text{data}) = \int{L(\theta \mid \text{data}) \Pr(\theta) d\theta}\)</span></p>
+<div class=""sourceCode"" id=""cb5""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">denominator</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/integrate.html"">integrate</a></span><span class=""op"">(</span><span class=""va"">numerator</span>,<span class=""fl"">0</span>,<span class=""fl"">1</span><span class=""op"">)</span><span class=""op"">$</span><span class=""va"">value</span></span></code></pre></div>
+<p>We use the <code>R</code> function <code>integrate</code> to calculate the integral in the denominator, which implements quadrature techniques to divide in little squares the area underneath the curve delimited by the function to integrate (here the numerator), and count them.</p>
+<p>Then we get a numerical approximation of the posterior in Figure <a href=""crashcourse.html#fig:numapprox"">1.4</a> by applying Bayes‚Äô theorem.</p>
+<div class=""sourceCode"" id=""cb6""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">grid</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/seq.html"">seq</a></span><span class=""op"">(</span><span class=""fl"">0</span>, <span class=""fl"">1</span>, <span class=""fl"">0.01</span><span class=""op"">)</span> <span class=""co""># grid of values for theta</span></span>
+<span><span class=""va"">numerical_posterior</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/data.frame.html"">data.frame</a></span><span class=""op"">(</span>survival <span class=""op"">=</span> <span class=""va"">grid</span>, </span>
+<span>                                  posterior <span class=""op"">=</span> <span class=""fu"">numerator</span><span class=""op"">(</span><span class=""va"">grid</span><span class=""op"">)</span><span class=""op"">/</span><span class=""va"">denominator</span><span class=""op"">)</span> <span class=""co""># Bayes' theorem</span></span>
+<span><span class=""va"">numerical_posterior</span> <span class=""op"">%&gt;%</span></span>
+<span>  <span class=""fu"">ggplot</span><span class=""op"">(</span><span class=""op"">)</span> <span class=""op"">+</span></span>
+<span>  <span class=""fu"">aes</span><span class=""op"">(</span>x <span class=""op"">=</span> <span class=""va"">survival</span>, y <span class=""op"">=</span> <span class=""va"">posterior</span><span class=""op"">)</span> <span class=""op"">+</span> </span>
+<span>  <span class=""fu"">geom_line</span><span class=""op"">(</span>size <span class=""op"">=</span> <span class=""fl"">1.5</span><span class=""op"">)</span></span></code></pre></div>
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:numapprox""></span>
+<img src=""banana-book_files/figure-html/numapprox-1.png"" alt=""Winter survival posterior distribution obtained by numerical integration."" width=""672""><p class=""caption"">
+Figure 1.4: Winter survival posterior distribution obtained by numerical integration.
+</p>
+</div>
+<p>How good is our numerical approximation of survival posterior distribution? Ideally, we would want to compare the approximation to the true posterior distribution. Although a closed-form expression for the posterior distribution is in general intractable, when you combine a binomial likelihood together with a beta distribution as a prior, then the posterior distribution is also a beta distribution, which makes it amenable to all sorts of exact calculations<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;We say that the beta distribution is the conjugate prior distribution for the binomial distribution.&lt;/p&gt;""><sup>8</sup></a>. The beta distribution is continuous between 0 and 1, and extends the uniform distribution to situations where not all outcomes are equally likely. It has two parameters <span class=""math inline"">\(a\)</span> and <span class=""math inline"">\(b\)</span> that control its shape (Figure <a href=""crashcourse.html#fig:betadistribution"">1.5</a>).</p>
+
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:betadistribution""></span>
+<img src=""banana-book_files/figure-html/betadistribution-1.png"" alt=""The distribution beta(\(a\),\(b\)) for different values of \(a\) and \(b\). Note that for \(a = b = 1\), we get the uniform distribution between 0 and 1 in the top left panel. When \(a\) and \(b\) are equal, the distribution is symmetric, and the bigger \(a\) and \(b\), the more peaked the distribution or the smaller the variance."" width=""672""><p class=""caption"">
+Figure 1.5: The distribution beta(<span class=""math inline"">\(a\)</span>,<span class=""math inline"">\(b\)</span>) for different values of <span class=""math inline"">\(a\)</span> and <span class=""math inline"">\(b\)</span>. Note that for <span class=""math inline"">\(a = b = 1\)</span>, we get the uniform distribution between 0 and 1 in the top left panel. When <span class=""math inline"">\(a\)</span> and <span class=""math inline"">\(b\)</span> are equal, the distribution is symmetric, and the bigger <span class=""math inline"">\(a\)</span> and <span class=""math inline"">\(b\)</span>, the more peaked the distribution or the smaller the variance.
+</p>
+</div>
+If the likelihood of the data <span class=""math inline"">\(y\)</span> is binomial with <span class=""math inline"">\(n\)</span> trials and probability of success <span class=""math inline"">\(\theta\)</span>, and the prior is a beta distribution with parameters <span class=""math inline"">\(a\)</span> and <span class=""math inline"">\(b\)</span>, then the posterior is a beta distribution with parameters <span class=""math inline"">\(a + y\)</span> and <span class=""math inline"">\(b + n - y\)</span><a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;&lt;strong&gt;provide a sketch of the proof&lt;/strong&gt;&lt;/p&gt;""><sup>9</sup></a>. In our example, we have <span class=""math inline"">\(n = 57\)</span> trials and <span class=""math inline"">\(y = 19\)</span> animals that survived and a uniform prior between 0 and 1 or a beta distribution with parameters <span class=""math inline"">\(a = b = 1\)</span>, therefore survival has a beta posterior distribution with parameters 20 and 39. In Figure <a href=""crashcourse.html#fig:compar"">1.6</a>, we superimpose the exact posterior and the numerical approximation. Clearly, the two distributions are indistinguishable, suggesting that the numerical approximation is more than fine.
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:compar""></span>
+<img src=""banana-book_files/figure-html/compar-1.png"" alt=""Comparison of exact (dashed line) vs. numerical approximation (continuous line) of winter survival posterior distribution."" width=""672""><p class=""caption"">
+Figure 1.6: Comparison of exact (dashed line) vs.¬†numerical approximation (continuous line) of winter survival posterior distribution.
+</p>
+</div>
+<!-- To finish up, let's add the prior.  -->
+<!-- ```{r, echo = FALSE} -->
+<!-- ggplot() +  -->
+<!--   geom_line(data = numerical_posterior,  -->
+<!--             aes(x = survival, y = posterior),  -->
+<!--             size = 1.5,  -->
+<!--             col = wesanderson::wes_palettes$Royal1[2],  -->
+<!--             alpha = 0.5) +  -->
+<!--   geom_line(data = dfexpposterior,  -->
+<!--             aes(x = survival, y = explicit_posterior), -->
+<!--             col = wesanderson::wes_palettes$Royal1[3],  -->
+<!--             size = 1.5,  -->
+<!--             linetype = ""dashed"") +  -->
+<!--   geom_line(data = dfprior, -->
+<!--             aes(x = survival, y = prior), -->
+<!--             col = wesanderson::wes_palettes$Royal1[1], -->
+<!--             size = 1.5) -->
+<!-- ``` -->
+<p>In our example, we have a single parameter to estimate, winter survival. This means dealing with a one-dimensional integral in the denominator which is pretty easy with quadrature techniques and the <code>R</code> function <code><a href=""https://rdrr.io/r/stats/integrate.html"">integrate()</a></code>. Now what if we had multiple parameters? For example, imagine you‚Äôd like to fit a capture-recapture model with detection probability <span class=""math inline"">\(p\)</span> and regression parameters <span class=""math inline"">\(\alpha\)</span> and <span class=""math inline"">\(\beta\)</span> for the intercept and slope of a relationship between survival probability and a covariate, then Bayes‚Äô theorem gives you the posterior distribution of all three parameters together:</p>
+<p><span class=""math display"">\[ \Pr(\alpha, \beta, p \mid \text{data}) = \frac{ \Pr(\text{data} \mid \alpha, \beta, p) \times \Pr(\alpha, \beta, p)}{\iiint \, \Pr(\text{data} \mid \alpha, \beta, p) \Pr(\alpha, \beta, p) d\alpha d\beta dp} \]</span>
+There are two computational challenges with this formula. First, do we really wish to calculate a three-dimensional integral? The answer is no, one-dimensional and two-dimensional integrals are so much further we can go with standard methods. Second, we‚Äôre more interested in a posterior distribution for each parameter separately than the joint posterior distribution. The so-called marginal distribution of <span class=""math inline"">\(p\)</span> for example is obtained by integrating over all the other parameters ‚Äì a two-dimensional integral in this example. Now imagine with tens or hundreds of parameters to estimate, these integrals become highly multi-dimensional and simply intractable. In the next section, I introduce powerful simulation methods to circumvent this issue.</p>
+</div>
+<div id=""markov-chain-monte-carlo-mcmc"" class=""section level2"" number=""1.5"">
+<h2>
+<span class=""header-section-number"">1.5</span> Markov chain Monte Carlo (MCMC)<a class=""anchor"" aria-label=""anchor"" href=""#markov-chain-monte-carlo-mcmc""><i class=""fas fa-link""></i></a>
+</h2>
+<p>In the early 1990s, statisticians rediscovered work from the 1950‚Äôs in physics. In a famous paper that would lay the fundations of modern Bayesian statistics (Figure <a href=""crashcourse.html#fig:mcmcpaper"">1.7</a>), the authors use simulations to approximate posterior distributions with some precision by drawing large samples. This is a neat trick to avoid explicit calculation of the multi-dimensional integrals we struggle with when using Bayes‚Äô theorem.</p>
+<div class=""figure"" style=""text-align: center"">
+<span style=""display:block;"" id=""fig:mcmcpaper""></span>
+<img src=""images/metropolis.png"" alt=""MCMC article cover. Source: [The Journal of Chemical Physics](https://aip.scitation.org/doi/10.1063/1.1699114)"" width=""582""><p class=""caption"">
+Figure 1.7: MCMC article cover. Source: <a href=""https://aip.scitation.org/doi/10.1063/1.1699114"">The Journal of Chemical Physics</a>
+</p>
+</div>
+<p>These simulation algorithms are called Markov chain Monte Carlo (MCMC), and they definitely gave a boost to Bayesian statistics. There are two parts in MCMC, Markov chain and Monte Carlo, let‚Äôs try and make sense of these terms.</p>
+<div id=""monte-carlo-integration"" class=""section level3"" number=""1.5.1"">
+<h3>
+<span class=""header-section-number"">1.5.1</span> Monte Carlo integration<a class=""anchor"" aria-label=""anchor"" href=""#monte-carlo-integration""><i class=""fas fa-link""></i></a>
+</h3>
+<p>What does Monte Carlo stand for? Monte Carlo integration is a simulation technique to calculate integrals of any function <span class=""math inline"">\(f\)</span> of random variable <span class=""math inline"">\(X\)</span> with distribution <span class=""math inline"">\(\Pr(X)\)</span> say <span class=""math inline"">\(\int f(X) \Pr(X)dX\)</span>. You draw values <span class=""math inline"">\(X_1,\ldots,X_k\)</span> from <span class=""math inline"">\(\Pr(X)\)</span> the distribution of <span class=""math inline"">\(X\)</span>, apply function <span class=""math inline"">\(f\)</span> to these values, then calculate the mean of these new values <span class=""math inline"">\(\displaystyle{\frac{1}{k}}\sum_{i=1}^k{f(X_i)}\)</span> to approximate the integral. How is Monte Carlo integration used in a Bayesian context? The posterior distribution contains all the information we need about the parameter to be estimated. When dealing with many parameters however, you may want to summarise posterior results by calculating numerical summaries. The simplest numerical summary is the mean of the posterior distribution, <span class=""math inline"">\(E(\theta) = \int \theta \Pr(\theta|\text{data})\)</span>, where <span class=""math inline"">\(X\)</span> is <span class=""math inline"">\(\theta\)</span> now and <span class=""math inline"">\(f\)</span> is the identity function. Posterior mean can be calculated with Monte Carlo integration:</p>
+<div class=""sourceCode"" id=""cb7""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">sample_from_posterior</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Beta.html"">rbeta</a></span><span class=""op"">(</span><span class=""fl"">1000</span>, <span class=""fl"">20</span>, <span class=""fl"">39</span><span class=""op"">)</span> <span class=""co""># draw 1000 values from posterior survival beta(20,39)</span></span>
+<span><span class=""fu""><a href=""https://rdrr.io/r/base/mean.html"">mean</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span><span class=""op"">)</span> <span class=""co""># compute mean with Monte Carlo integration</span></span>
+<span><span class=""co"">## [1] 0.3394</span></span></code></pre></div>
+<p>You may check that the mean we have just calculated matches closely the expectation of a beta distribution<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;If &lt;span class=""math inline""&gt;\(X\)&lt;/span&gt; is a random variable with distribution &lt;span class=""math inline""&gt;\(\text{beta}(a, b)\)&lt;/span&gt;, then &lt;span class=""math inline""&gt;\(E(X) = \displaystyle{\frac{a}{a + b}}\)&lt;/span&gt;&lt;/p&gt;'><sup>10</sup></a>:</p>
+<div class=""sourceCode"" id=""cb8""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""fl"">20</span><span class=""op"">/</span><span class=""op"">(</span><span class=""fl"">20</span><span class=""op"">+</span><span class=""fl"">39</span><span class=""op"">)</span> <span class=""co""># expectation of beta(20,39)</span></span>
+<span><span class=""co"">## [1] 0.339</span></span></code></pre></div>
+<p>Another useful numerical summary is the credible interval within which our parameter falls with some probability, usually 0.95 hence a 95<span class=""math inline"">\(\%\)</span> credible interval. Finding the bounds of a credible interval requires calculating quantiles, which in turn involves integrals and the use of Monte Carlo integration. A 95<span class=""math inline"">\(\%\)</span> credible interval for winter survival can be obtained in <code>R</code> with:</p>
+<div class=""sourceCode"" id=""cb9""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""fu""><a href=""https://rdrr.io/r/stats/quantile.html"">quantile</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span>, probs <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/c.html"">c</a></span><span class=""op"">(</span><span class=""fl"">2.5</span><span class=""op"">/</span><span class=""fl"">100</span>, <span class=""fl"">97.5</span><span class=""op"">/</span><span class=""fl"">100</span><span class=""op"">)</span><span class=""op"">)</span></span>
+<span><span class=""co"">##   2.5%  97.5% </span></span>
+<span><span class=""co"">## 0.2201 0.4670</span></span></code></pre></div>
+</div>
+<div id=""markovmodelmcmc"" class=""section level3"" number=""1.5.2"">
+<h3>
+<span class=""header-section-number"">1.5.2</span> Markov chains<a class=""anchor"" aria-label=""anchor"" href=""#markovmodelmcmc""><i class=""fas fa-link""></i></a>
+</h3>
+<p>What is a Markov chain? A Markov chain is a random sequence of numbers, in which each number depends only on the previous number. An example is the weather in my home town in Southern France, Montpellier, in which a sunny day is most likely to be followed by another sunny day, say with probability 0.8, and a rainy day is rarely followed by another rainy day, say with probability 0.1. The dynamic of this Markov chain is captured by the transition matrix <span class=""math inline"">\(\mathbf{\Gamma}\)</span>:
+<span class=""math display"">\[
+\begin{matrix}
+&amp; \\
+\mathbf{\Gamma} =
+    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right .
+\end{matrix}
+\hspace{-1.2em}
+\begin{matrix}
+    \text{sunny tomorrow} &amp; \text{rainy tomorrow} \\
+0.8 &amp; 0.2 \\
+0.9 &amp; 0.1 \\
+\end{matrix}
+\hspace{-0.2em}
+\begin{matrix}
+&amp; \\
+\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
+    \begin{matrix}
+    \text{sunny today} \\ \text{rainy today}
+    \end{matrix}
+\end{matrix}
+\]</span>
+In rows the weather today, and in columns the weather tomorrow. The cells give the probability of a sunny or rainy day tomorrow, given the day is sunny or rainy today. Under certain conditions<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;The Markov chain is irreducible and aperiodic.&lt;/p&gt;""><sup>11</sup></a>, a Markov chain will converge to a unique stationary distribution. In our weather example, let‚Äôs run the Markov chain for 20 steps:</p>
+<div class=""sourceCode"" id=""cb10""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">weather</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/matrix.html"">matrix</a></span><span class=""op"">(</span><span class=""fu""><a href=""https://rdrr.io/r/base/c.html"">c</a></span><span class=""op"">(</span><span class=""fl"">0.8</span>, <span class=""fl"">0.2</span>, <span class=""fl"">0.9</span>, <span class=""fl"">0.1</span><span class=""op"">)</span>, nrow <span class=""op"">=</span> <span class=""fl"">2</span>, byrow <span class=""op"">=</span> <span class=""cn"">T</span><span class=""op"">)</span> <span class=""co""># transition matrix</span></span>
+<span><span class=""va"">steps</span> <span class=""op"">&lt;-</span> <span class=""fl"">20</span></span>
+<span><span class=""kw"">for</span> <span class=""op"">(</span><span class=""va"">i</span> <span class=""kw"">in</span> <span class=""fl"">1</span><span class=""op"">:</span><span class=""va"">steps</span><span class=""op"">)</span><span class=""op"">{</span></span>
+<span>  <span class=""va"">weather</span> <span class=""op"">&lt;-</span> <span class=""va"">weather</span> <span class=""op""><a href=""https://rdrr.io/r/base/matmult.html"">%*%</a></span> <span class=""va"">weather</span> <span class=""co""># matrix multiplication</span></span>
+<span><span class=""op"">}</span></span>
+<span><span class=""fu""><a href=""https://rdrr.io/r/base/Round.html"">round</a></span><span class=""op"">(</span><span class=""va"">weather</span>, <span class=""fl"">2</span><span class=""op"">)</span> <span class=""co""># matrix product after 20 steps</span></span>
+<span><span class=""co"">##      [,1] [,2]</span></span>
+<span><span class=""co"">## [1,] 0.82 0.18</span></span>
+<span><span class=""co"">## [2,] 0.82 0.18</span></span></code></pre></div>
+<p>Each row of the transition matrix converges to the same distribution <span class=""math inline"">\((0.82, 0.18)\)</span> as the number of steps increases. Convergence happens no matter which state you start in, and you always have probability 0.82 of the day being sunny and 0.18 of the day being rainy.</p>
+<p>Back to MCMC, the core idea is that you can build a Markov chain with a given stationary distribution set to be the desired posterior distribution.</p>
+
+<div class=""rmdnote"">
+Putting Monte Carlo and Markov chains together, MCMC allows us to generate a sample of values (Markov chain) whose distribution converges to the posterior distribution, and we can use this sample of values to calculate any posterior summaries (Monte Carlo), such as posterior means and credible intervals.
+</div>
+</div>
+<div id=""metropolis-algorithm"" class=""section level3"" number=""1.5.3"">
+<h3>
+<span class=""header-section-number"">1.5.3</span> Metropolis algorithm<a class=""anchor"" aria-label=""anchor"" href=""#metropolis-algorithm""><i class=""fas fa-link""></i></a>
+</h3>
+<p>There are several ways of constructing Markov chains for Bayesian inference<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;You might have heard about the Metropolis-Hastings or the Gibbs sampler. Have a look to &lt;a href=""https://github.com/chi-feng/mcmc-demo"" class=""uri""&gt;https://github.com/chi-feng/mcmc-demo&lt;/a&gt; for an interactive gallery of MCMC algorithms.&lt;/p&gt;'><sup>12</sup></a>. Here I illustrate the Metropolis algorithm and how to implement it in practice<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;This presentation is largely inspired by &lt;span class=""citation""&gt;Albert and Hu (&lt;a href=""references.html#ref-alberthu2019""&gt;2019&lt;/a&gt;)&lt;/span&gt;&lt;/p&gt;'><sup>13</sup></a>.</p>
+<p>Let‚Äôs go back to our example on animal survival estimation. We illustrate sampling from survival posterior distribution. We write functions for likelihood, prior and posterior.</p>
+<div class=""sourceCode"" id=""cb11""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""co""># 19 animals recaptured alive out of 57 captured, marked and released</span></span>
+<span><span class=""va"">survived</span> <span class=""op"">&lt;-</span> <span class=""fl"">19</span></span>
+<span><span class=""va"">released</span> <span class=""op"">&lt;-</span> <span class=""fl"">57</span></span>
+<span></span>
+<span><span class=""co""># binomial log-likelihood function</span></span>
+<span><span class=""va"">loglikelihood</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">x</span>, <span class=""va"">p</span><span class=""op"">)</span><span class=""op"">{</span></span>
+<span>  <span class=""fu""><a href=""https://rdrr.io/r/stats/Binomial.html"">dbinom</a></span><span class=""op"">(</span>x <span class=""op"">=</span> <span class=""va"">x</span>, size <span class=""op"">=</span> <span class=""va"">released</span>, prob <span class=""op"">=</span> <span class=""va"">p</span>, log <span class=""op"">=</span> <span class=""cn"">TRUE</span><span class=""op"">)</span></span>
+<span><span class=""op"">}</span></span>
+<span></span>
+<span><span class=""co""># uniform prior density</span></span>
+<span><span class=""va"">logprior</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">p</span><span class=""op"">)</span><span class=""op"">{</span></span>
+<span>  <span class=""fu""><a href=""https://rdrr.io/r/stats/Uniform.html"">dunif</a></span><span class=""op"">(</span>x <span class=""op"">=</span> <span class=""va"">p</span>, min <span class=""op"">=</span> <span class=""fl"">0</span>, max <span class=""op"">=</span> <span class=""fl"">1</span>, log <span class=""op"">=</span> <span class=""cn"">TRUE</span><span class=""op"">)</span></span>
+<span><span class=""op"">}</span></span>
+<span></span>
+<span><span class=""co""># posterior density function (log scale)</span></span>
+<span><span class=""va"">posterior</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">x</span>, <span class=""va"">p</span><span class=""op"">)</span><span class=""op"">{</span></span>
+<span>  <span class=""fu"">loglikelihood</span><span class=""op"">(</span><span class=""va"">x</span>, <span class=""va"">p</span><span class=""op"">)</span> <span class=""op"">+</span> <span class=""fu"">logprior</span><span class=""op"">(</span><span class=""va"">p</span><span class=""op"">)</span> <span class=""co""># - log(Pr(data))</span></span>
+<span><span class=""op"">}</span></span></code></pre></div>
+<p>The Metropolis algorithm works as follows:</p>
+<ol style=""list-style-type: decimal"">
+<li><p>We pick a value of the parameter to be estimated. This is where we start our Markov chain ‚Äì this is a <em>starting</em> value.</p></li>
+<li><p>To decide where to go next, we propose to move away from the current value of the parameter ‚Äì this is a <em>candidate</em> value. To do so, we add to the current value some random value from e.g.¬†a normal distribution with some variance ‚Äì this is a <em>proposal</em> distribution. The Metropolis algorithm is a particular case of the Metropolis-Hastings algorithm with symmetric proposals.</p></li>
+<li><p>We compute the ratio of the probabilities at the candidate and current locations <span class=""math inline"">\(R=\displaystyle{\frac{{\Pr(\text{candidate}|\text{data})}}{{\Pr(\text{current}|\text{data})}}}\)</span>. This is where the magic of MCMC happens, in that <span class=""math inline"">\(\Pr(\text{data})\)</span>, the denominator in the Bayes‚Äô theorem, appears in both the numerator and the denominator in <span class=""math inline"">\(R\)</span> therefore cancels out and does not need to be calculated.</p></li>
+</ol>
+<!-- -- *the Hastings ratio* --><ol start=""4"" style=""list-style-type: decimal"">
+<li><p>If the posterior at the candidate location <span class=""math inline"">\(\Pr(\text{candidate}|\text{data})\)</span> is higher than at the current location <span class=""math inline"">\(\Pr(\text{current}|\text{data})\)</span>, in other words when the candidate value is more plausible than the current value, we definitely accept the candidate value. If not, then we accept the candidate value with probability <span class=""math inline"">\(R\)</span> and reject with probability <span class=""math inline"">\(1-R\)</span>. For example, if the candidate value is ten times less plausible than the current value, then we accept with probability 0.1 and reject with probability 0.9. How does it work in practice? We use a continuous spinner that lands somewhere between 0 and 1 ‚Äì call the random spin <span class=""math inline"">\(X\)</span>. If <span class=""math inline"">\(X\)</span> is smaller than <span class=""math inline"">\(R\)</span>, we move to the candidate location, otherwise we remain at the current location. We do not want to accept or reject too often. In practice, the Metropolis algorithm should have an acceptance probability between 0.2 and 0.4, which can be achieved by <em>tuning</em> the variance of the normal proposal distribution.</p></li>
+<li><p>We repeat 2-4 a number of times ‚Äì or <em>steps</em>.</p></li>
+</ol>
+<p>Enough of the theory, let‚Äôs implement the Metropolis algorithm in <code>R</code>. Let‚Äôs start by setting the scene.</p>
+<div class=""sourceCode"" id=""cb12""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">steps</span> <span class=""op"">&lt;-</span> <span class=""fl"">100</span> <span class=""co""># number of steps</span></span>
+<span><span class=""va"">theta.post</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/rep.html"">rep</a></span><span class=""op"">(</span><span class=""cn"">NA</span>, <span class=""va"">steps</span><span class=""op"">)</span> <span class=""co""># vector to store samples</span></span>
+<span><span class=""va"">accept</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/rep.html"">rep</a></span><span class=""op"">(</span><span class=""cn"">NA</span>, <span class=""va"">steps</span><span class=""op"">)</span> <span class=""co""># keep track of accept/reject</span></span>
+<span><span class=""fu""><a href=""https://rdrr.io/r/base/Random.html"">set.seed</a></span><span class=""op"">(</span><span class=""fl"">1234</span><span class=""op"">)</span> <span class=""co""># for reproducibility</span></span></code></pre></div>
+<p>Now follow the 5 steps we‚Äôve just described. First, we pick a starting value, and store it (step 1).</p>
+<div class=""sourceCode"" id=""cb13""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">inits</span> <span class=""op"">&lt;-</span> <span class=""fl"">0.5</span></span>
+<span><span class=""va"">theta.post</span><span class=""op"">[</span><span class=""fl"">1</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""va"">inits</span></span>
+<span><span class=""va"">accept</span><span class=""op"">[</span><span class=""fl"">1</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""fl"">1</span></span></code></pre></div>
+<p>Then, we need a function to propose a candidate value. We add a value taken from a normal distribution with mean zero and standard deviation we call <em>away</em>. We work on the logit scale to make sure the candidate value for survival lies between 0 and 1.</p>
+<div class=""sourceCode"" id=""cb14""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">move</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">x</span>, <span class=""va"">away</span> <span class=""op"">=</span> <span class=""fl"">1</span><span class=""op"">)</span><span class=""op"">{</span> <span class=""co""># by default, standard deviation of the proposal distribution is 1</span></span>
+<span>  <span class=""va"">logitx</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/Log.html"">log</a></span><span class=""op"">(</span><span class=""va"">x</span> <span class=""op"">/</span> <span class=""op"">(</span><span class=""fl"">1</span> <span class=""op"">-</span> <span class=""va"">x</span><span class=""op"">)</span><span class=""op"">)</span> <span class=""co""># apply logit transform (-infinity,+infinity)</span></span>
+<span>  <span class=""va"">logit_candidate</span> <span class=""op"">&lt;-</span> <span class=""va"">logitx</span> <span class=""op"">+</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Normal.html"">rnorm</a></span><span class=""op"">(</span><span class=""fl"">1</span>, <span class=""fl"">0</span>, <span class=""va"">away</span><span class=""op"">)</span> <span class=""co""># add a value taken from N(0,sd=away) to current value</span></span>
+<span>  <span class=""va"">candidate</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Logistic.html"">plogis</a></span><span class=""op"">(</span><span class=""va"">logit_candidate</span><span class=""op"">)</span> <span class=""co""># back-transform (0,1)</span></span>
+<span>  <span class=""kw""><a href=""https://rdrr.io/r/base/function.html"">return</a></span><span class=""op"">(</span><span class=""va"">candidate</span><span class=""op"">)</span></span>
+<span><span class=""op"">}</span></span></code></pre></div>
+<p>Now we‚Äôre ready for steps 2, 3 and 4. We write a loop to take care of step 5. We start at initial value 0.5 and run the algorithm for 100 steps or iterations.</p>
+<div class=""sourceCode"" id=""cb15""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""kw"">for</span> <span class=""op"">(</span><span class=""va"">t</span> <span class=""kw"">in</span> <span class=""fl"">2</span><span class=""op"">:</span><span class=""va"">steps</span><span class=""op"">)</span><span class=""op"">{</span> <span class=""co""># repeat steps 2-4 (step 5)</span></span>
+<span>  </span>
+<span>  <span class=""co""># propose candidate value for survival (step 2)</span></span>
+<span>  <span class=""va"">theta_star</span> <span class=""op"">&lt;-</span> <span class=""fu"">move</span><span class=""op"">(</span><span class=""va"">theta.post</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">-</span><span class=""fl"">1</span><span class=""op"">]</span><span class=""op"">)</span></span>
+<span>  </span>
+<span>  <span class=""co""># calculate ratio R (step 3)</span></span>
+<span>  <span class=""va"">pstar</span> <span class=""op"">&lt;-</span> <span class=""fu"">posterior</span><span class=""op"">(</span><span class=""va"">survived</span>, p <span class=""op"">=</span> <span class=""va"">theta_star</span><span class=""op"">)</span>  </span>
+<span>  <span class=""va"">pprev</span> <span class=""op"">&lt;-</span> <span class=""fu"">posterior</span><span class=""op"">(</span><span class=""va"">survived</span>, p <span class=""op"">=</span> <span class=""va"">theta.post</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">-</span><span class=""fl"">1</span><span class=""op"">]</span><span class=""op"">)</span></span>
+<span>  <span class=""va"">logR</span> <span class=""op"">&lt;-</span> <span class=""va"">pstar</span> <span class=""op"">-</span> <span class=""va"">pprev</span> <span class=""co""># likelihood and prior are on the log scale</span></span>
+<span>  <span class=""va"">R</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/Log.html"">exp</a></span><span class=""op"">(</span><span class=""va"">logR</span><span class=""op"">)</span></span>
+<span>  </span>
+<span>  <span class=""co""># accept candidate value or keep current value (step 4)</span></span>
+<span>  <span class=""va"">X</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Uniform.html"">runif</a></span><span class=""op"">(</span><span class=""fl"">1</span>, <span class=""fl"">0</span>, <span class=""fl"">1</span><span class=""op"">)</span> <span class=""co""># spin continuous spinner</span></span>
+<span>  <span class=""kw"">if</span> <span class=""op"">(</span><span class=""va"">X</span> <span class=""op"">&lt;</span> <span class=""va"">R</span><span class=""op"">)</span><span class=""op"">{</span></span>
+<span>    <span class=""va"">theta.post</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""va"">theta_star</span> <span class=""co""># accept candidate value</span></span>
+<span>    <span class=""va"">accept</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""fl"">1</span> <span class=""co""># accept</span></span>
+<span>  <span class=""op"">}</span></span>
+<span>  <span class=""kw"">else</span><span class=""op"">{</span></span>
+<span>    <span class=""va"">theta.post</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""va"">theta.post</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">-</span><span class=""fl"">1</span><span class=""op"">]</span> <span class=""co""># keep current value</span></span>
+<span>    <span class=""va"">accept</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""fl"">0</span> <span class=""co""># reject</span></span>
+<span>  <span class=""op"">}</span></span>
+<span><span class=""op"">}</span></span></code></pre></div>
+<p>We get the following values.</p>
+<div class=""sourceCode"" id=""cb16""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""fu""><a href=""https://rdrr.io/r/utils/head.html"">head</a></span><span class=""op"">(</span><span class=""va"">theta.post</span><span class=""op"">)</span> <span class=""co""># first values</span></span>
+<span><span class=""co"">## [1] 0.5000 0.2302 0.2906 0.2906 0.2980 0.2980</span></span>
+<span><span class=""fu""><a href=""https://rdrr.io/r/utils/head.html"">tail</a></span><span class=""op"">(</span><span class=""va"">theta.post</span><span class=""op"">)</span> <span class=""co""># last values</span></span>
+<span><span class=""co"">## [1] 0.2622 0.2622 0.2622 0.3727 0.3232 0.3862</span></span></code></pre></div>
+Visually, you may look at the chain in Figure <a href=""crashcourse.html#fig:chain"">1.8</a> called a trace plot.
+<div class=""figure"" style=""text-align: center"">
+<span style=""display:block;"" id=""fig:chain""></span>
+<img src=""banana-book_files/figure-html/chain-1.png"" alt=""Visualisation of a Markov chain starting at value 0.5, with steps or iterations on the x-axis, and samples on the y-axis. This graphical representation is called a trace plot."" width=""672""><p class=""caption"">
+Figure 1.8: Visualisation of a Markov chain starting at value 0.5, with steps or iterations on the x-axis, and samples on the y-axis. This graphical representation is called a trace plot.
+</p>
+</div>
+<p>The acceptance probability is the average number of times we accepted a candidated value, which is 0.44 and almost satisfying.</p>
+Can we run another chain and start at initial value 0.2 this time? Yes, just go through the same algorithm again, and visualise the results in Figure <a href=""crashcourse.html#fig:twochains"">1.9</a>.
+<div class=""figure"" style=""text-align: center"">
+<span style=""display:block;"" id=""fig:twochains""></span>
+<img src=""banana-book_files/figure-html/twochains-1.png"" alt=""Trace plot of survival for two chains starting at 0.2 (yellow) and 0.5 (blue) run for 100 steps."" width=""672""><p class=""caption"">
+Figure 1.9: Trace plot of survival for two chains starting at 0.2 (yellow) and 0.5 (blue) run for 100 steps.
+</p>
+</div>
+Notice that we do not get the exact same results because the algorithm is stochastic. The question is to know whether we have reached the stationary distribution. Let‚Äôs increase the number of steps and run a chain with 5000 iterations as in Figure <a href=""crashcourse.html#fig:longchain"">1.10</a>.
+<div class=""figure"" style=""text-align: center"">
+<span style=""display:block;"" id=""fig:longchain""></span>
+<img src=""banana-book_files/figure-html/longchain-1.png"" alt=""Trace plot of survival for a chain starting at 0.5 and 1000 steps."" width=""672""><p class=""caption"">
+Figure 1.10: Trace plot of survival for a chain starting at 0.5 and 1000 steps.
+</p>
+</div>
+<p>This is what we‚Äôre after, a trace plot that looks like a beautiful lawn, see Section <a href=""crashcourse.html#convergence-diag"">1.6</a>. I find it informative to look at the animated version of Figure <a href=""crashcourse.html#fig:longchain"">1.10</a>, it helps understanding the stochastic behavior of the algorithm, and also to realise how the chains converge to their stationary distribution, see Figure <a href=""crashcourse.html#fig:animlongchain"">1.11</a>.</p>
+<div class=""figure"" style=""text-align: center"">
+<span style=""display:block;"" id=""fig:animlongchain""></span>
+<img src=""images/traceplotMCMC.gif"" alt=""Animated trace plot of survival with three chains starting at 0.2, 0.5 and 0.7 run for 1000 steps."" width=""100%""><p class=""caption"">
+Figure 1.11: Animated trace plot of survival with three chains starting at 0.2, 0.5 and 0.7 run for 1000 steps.
+</p>
+</div>
+<p>Once the stationary distribution is reached, you may regard the realisations of the Markov chain as a sample from the posterior distribution, and obtain numerical summaries. In the next section, we consider several important implementation issues.</p>
+</div>
+</div>
+<div id=""convergence-diag"" class=""section level2"" number=""1.6"">
+<h2>
+<span class=""header-section-number"">1.6</span> Assessing convergence<a class=""anchor"" aria-label=""anchor"" href=""#convergence-diag""><i class=""fas fa-link""></i></a>
+</h2>
+
+<div class=""rmdnote"">
+When implementing MCMC, we need to determine how long it takes for our Markov chain to converge to the target distribution, and the number of iterations we need after achieving convergence to get reasonable Monte Carlo estimates of numerical summaries (posterior means and credible intervals).
+</div>
+<div id=""burn-in"" class=""section level3"" number=""1.6.1"">
+<h3>
+<span class=""header-section-number"">1.6.1</span> Burn-in<a class=""anchor"" aria-label=""anchor"" href=""#burn-in""><i class=""fas fa-link""></i></a>
+</h3>
+<p>In practice, we discard observations from the start of the Markov chain and just use observations from the chain once it has converged. The initial observations that we discard are usually referred to as the <em>burn-in</em>.</p>
+<p>The simplest method to determine the length of the burn-in period is to look at trace plots. Going back to our example, we see from the trace plot in Figure <a href=""crashcourse.html#fig:burnin"">1.12</a> that we need at least 100 iterations to achieve convergence toward an average survival around 0.3. It is always better to be conservative when specifying the length of the burn-in period, and in this example, we would use 250 or even 500 iterations as a burn-in. The length of the burn-in period can be determined by performing preliminary MCMC short runs.</p>
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:burnin""></span>
+<img src=""banana-book_files/figure-html/burnin-1.png"" alt=""Determining the length of the burn-in period. The chain starts at value 0.99 and rapidly stabilises, with values bouncing back and forth around 0.3 from the 100th iteration onwards. You may choose the shaded area as the burn-in, and discard the corresponding values."" width=""672""><p class=""caption"">
+Figure 1.12: Determining the length of the burn-in period. The chain starts at value 0.99 and rapidly stabilises, with values bouncing back and forth around 0.3 from the 100th iteration onwards. You may choose the shaded area as the burn-in, and discard the corresponding values.
+</p>
+</div>
+<p>Inspecting the trace plot for a single run of the Markov chain is useful. However, we usually run the Markov chain several times, starting from different over-dispersed points, to check that all runs achieve the same stationary distribution. This approach is formalised by using the Brooks-Gelman-Rubin (BGR) statistic <span class=""math inline"">\(\hat{R}\)</span> which measures the ratio of the total variability combining multiple chains (between-chain plus within-chain) to the within-chain variability. The BGR statistic asks whether there is a chain effect, and is very much alike the <span class=""math inline"">\(F\)</span> test in an analysis of variance. Values below 1.1 indicate likely convergence.</p>
+<p>Back to our example, we run two Markov chains with starting values 0.2 and 0.8 using 100 up to 5000 iterations, and calculate the BGR statistic using half the number of iterations as the length of the burn-in. From Figure <a href=""crashcourse.html#fig:bgr"">1.13</a>, we get a value of the BGR statistic near 1 by up to 2000 iterations, which suggests that with 2000 iterations as a burn-in, there is no evidence of a lack of convergence.</p>
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:bgr""></span>
+<img src=""banana-book_files/figure-html/bgr-1.png"" alt=""Brooks-Gelman-Rubin statistic as a function of the number of iterations."" width=""672""><p class=""caption"">
+Figure 1.13: Brooks-Gelman-Rubin statistic as a function of the number of iterations.
+</p>
+</div>
+<p>It is important to bear in mind that a value near 1 for the BGR statistic is only a necessary <em>but not sufficient</em> condition for convergence. In other words, this diagnostic cannot tell you for sure that the Markov chain has achieved convergence, only that it has not.<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;Cross-reference sections on local minima and parameter redundancy for pathological cases.&lt;/p&gt;""><sup>14</sup></a></p>
+</div>
+<div id=""chain-length"" class=""section level3"" number=""1.6.2"">
+<h3>
+<span class=""header-section-number"">1.6.2</span> Chain length<a class=""anchor"" aria-label=""anchor"" href=""#chain-length""><i class=""fas fa-link""></i></a>
+</h3>
+<p>How long of a chain is needed to produce reliable parameter estimates? To answer this question, you need to keep in mind that successive steps in a Markov chain are not independent ‚Äì this is usually referred to as <em>autocorrelation</em>. Ideally, we would like to keep autocorrelation as low as possible. Here again, trace plots are useful to diagnose issues with autocorrelation. Let‚Äôs get back to our survival example. Figure <a href=""crashcourse.html#fig:tracechainlength"">1.14</a> shows trace plots for different values of the standard deviation (parameter <em>away</em>) of the (normal) proposal distribution we use to propose a candidate value (Section <a href=""crashcourse.html#metropolis-algorithm"">1.5.3</a>). Small and big moves provide high correlations between successive observations of the Markov chain, whereas a standard deviation of 1 allows efficient exploration of the parameter space. The movement around the parameter space is referred to as <em>mixing</em>. Mixing is bad when the chain makes small and big moves, and good otherwise.</p>
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:tracechainlength""></span>
+<img src=""banana-book_files/figure-html/tracechainlength-1.png"" alt=""Trace plots for different values of the standard deviation (SD) of the proposal distribution. Left: The chain exhibits small moves and mixing is bad. Right: The chain exhibits big moves and mixing is bad. Middle: The chain exhibits adequate moves and mixing is good. Only the thousand last iterations are shown."" width=""672""><p class=""caption"">
+Figure 1.14: Trace plots for different values of the standard deviation (SD) of the proposal distribution. Left: The chain exhibits small moves and mixing is bad. Right: The chain exhibits big moves and mixing is bad. Middle: The chain exhibits adequate moves and mixing is good. Only the thousand last iterations are shown.
+</p>
+</div>
+<p>In addition to trace plots, autocorrelation function (ACF) plots are a convenient way of displaying the strength of autocorrelation in a given sample values. ACF plots provide the autocorrelation between successively sampled values separated by an increasing number of iterations, or <em>lag</em> (Figure <a href=""crashcourse.html#fig:acfchainlength"">1.15</a>).</p>
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:acfchainlength""></span>
+<img src=""banana-book_files/figure-html/acfchainlength-1.png"" alt=""Autocorrelation function plots for different values of the standard deviation (SD) of the proposal distribution. Left and right: Autocorrelation is strong, decreases slowly with increasing lag and mixing is bad. Middle: Autocorrelation is weak, decreases rapidly with increasing lag and mixing is good."" width=""672""><p class=""caption"">
+Figure 1.15: Autocorrelation function plots for different values of the standard deviation (SD) of the proposal distribution. Left and right: Autocorrelation is strong, decreases slowly with increasing lag and mixing is bad. Middle: Autocorrelation is weak, decreases rapidly with increasing lag and mixing is good.
+</p>
+</div>
+<p>Autocorrelation is not necessarily a big issue. Strongly correlated observations just require large sample sizes and therefore longer simulations. But how many iterations exactly? The effective sample size (<code>n.eff</code>) measures chain length while taking into account chain autocorrelation. You should check the <code>n.eff</code> of every parameter of interest, and of any interesting parameter combinations. In general, we need <span class=""math inline"">\(\text{n.eff} \geq 1000\)</span> independent steps to get reasonable Monte Carlo estimates of model parameters. In the animal survival example, <code>n.eff</code> can be calculated with the R <code><a href=""https://rdrr.io/pkg/coda/man/effectiveSize.html"">coda::effectiveSize()</a></code> function.</p>
+<div class=""inline-table""><table class=""table table-sm"">
+<thead><tr class=""header"">
+<th align=""right"">Proposal SD</th>
+<th align=""right"">n.eff</th>
+</tr></thead>
+<tbody>
+<tr class=""odd"">
+<td align=""right"">0.1</td>
+<td align=""right"">224</td>
+</tr>
+<tr class=""even"">
+<td align=""right"">1.0</td>
+<td align=""right"">1934</td>
+</tr>
+<tr class=""odd"">
+<td align=""right"">10.0</td>
+<td align=""right"">230</td>
+</tr>
+</tbody>
+</table></div>
+<p>As expected, <code>n.eff</code> is less than the number of MCMC iterations because of autocorrelation. Only when the standard deviation of the proposal distribution is 1 and mixing is good (Figures <a href=""crashcourse.html#fig:tracechainlength"">1.14</a> and <a href=""crashcourse.html#fig:acfchainlength"">1.15</a>) we get a satisfying effective sample size.</p>
+</div>
+<div id=""what-if-you-have-issues-of-convergence"" class=""section level3"" number=""1.6.3"">
+<h3>
+<span class=""header-section-number"">1.6.3</span> What if you have issues of convergence?<a class=""anchor"" aria-label=""anchor"" href=""#what-if-you-have-issues-of-convergence""><i class=""fas fa-link""></i></a>
+</h3>
+<p>When diagnosing MCMC convergence, you will (very) often run into troubles. In this section you will find some helpful tips I hope.</p>
+<p>When mixing is bad and effective sample size is small, you may just need to increase burn-in and/or sample more. Using more informative priors might also make Markov chains converge faster by helping your MCMC sampler (e.g.¬†the Metropolis algorithm) navigating more efficiently the parameter space. In the same spirit, picking better initial values for starting the chain does not harm. For doing that, a strategy consists in using estimates from a simpler model for which your MCMC chains do converge.</p>
+<p>If convergence issues persist, often there is a problem with your model<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;The quote ‚ÄòWhen you have computational problems, often there‚Äôs a problem with your model‚Äô is the folk theorem of statistical computing stated by Andrew Gelman in 2008, see &lt;a href=""https://statmodeling.stat.columbia.edu/2008/05/13/the_folk_theore/"" class=""uri""&gt;https://statmodeling.stat.columbia.edu/2008/05/13/the_folk_theore/&lt;/a&gt;&lt;/p&gt;'><sup>15</sup></a>. A bug in the code? A typo somewhere? A mistake in your maths? As often when coding is involved, the issue can be identified by removing complexities, and start with a simpler model until you find what the problem is.</p>
+<p>A general advice is to see your model as a data generating tool in the first place, simulate data from it using some realistic values for the parameters, and try to recover these parameter values by fitting the model to the simulated data. Simulating from a model will help you understanding how it works, what it does not do, and the data you need to get reasonable parameter estimates.</p>
+<p>We will see other strategies to improve convergence in the next chapters.<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;Cross reference relevant chapters. Option 1. Change your sampler. Option 2. Reparameterize (standardize covariates, plus non-centering: &lt;span class=""math inline""&gt;\(\alpha \sim N(0,\sigma)\)&lt;/span&gt; becomes &lt;span class=""math inline""&gt;\(\alpha = z \sigma\)&lt;/span&gt; with &lt;span class=""math inline""&gt;\(z \sim N(0,1)\)&lt;/span&gt;).&lt;/p&gt;'><sup>16</sup></a></p>
+</div>
+</div>
+<div id=""summary"" class=""section level2"" number=""1.7"">
+<h2>
+<span class=""header-section-number"">1.7</span> Summary<a class=""anchor"" aria-label=""anchor"" href=""#summary""><i class=""fas fa-link""></i></a>
+</h2>
+<ul>
+<li><p>With the Bayes‚Äô theorem, you update your beliefs (prior) with new data (likelihood) to get posterior beliefs (posterior): posterior <span class=""math inline"">\(\propto\)</span> likelihood <span class=""math inline"">\(\times\)</span> prior.</p></li>
+<li><p>The idea of Markov chain Monte Carlo (MCMC) is to simulate values from a Markov chain which has a stationary distribution equal to the posterior distribution you‚Äôre after.</p></li>
+<li><p>In practice, you run a Markov chain multiple times starting from over-dispersed initial values.</p></li>
+<li><p>You discard iterations in an initial burn-in phase and achieve convergence when all chains reach the same regime.</p></li>
+<li><p>From there, you run the chains long enough and proceed with calculating Monte Carlo estimates of numerical summaries (e.g.¬†posterior means and credible intervals) for parameters.</p></li>
+</ul>
+</div>
+<div id=""suggested-reading"" class=""section level2"" number=""1.8"">
+<h2>
+<span class=""header-section-number"">1.8</span> Suggested reading<a class=""anchor"" aria-label=""anchor"" href=""#suggested-reading""><i class=""fas fa-link""></i></a>
+</h2>
+<ul>
+<li><p>Gelman, A. and Hill, J. (2006). <a href=""https://www.cambridge.org/core/books/data-analysis-using-regression-and-multilevelhierarchical-models/32A29531C7FD730C3A68951A17C9D983"">Data Analysis Using Regression and Multilevel/Hierarchical Models (Analytical Methods for Social Research)</a>. Cambridge: Cambridge University Press.</p></li>
+<li><p>Gelman, A. and colleagues (2020). <a href=""https://arxiv.org/pdf/2011.01808.pdf"">Bayesian workflow</a>. arXiv preprint.</p></li>
+<li><p>McCarthy, M. (2007). <a href=""https://www.cambridge.org/core/books/bayesian-methods-for-ecology/9225F65B8A25D69B0B6C50B5A9A78201"">Bayesian Methods for Ecology</a>. Cambridge: Cambridge University Press.</p></li>
+<li><p>McElreath, R. (2020). <a href=""https://xcelab.net/rm/statistical-rethinking/"">Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2nd ed.)</a>. CRC Press.</p></li>
+</ul>
+</div>
+</div>
+
+
+
+
+  <div class=""chapter-nav"">
+<div class=""prev""><a href=""introduction.html"">Introduction</a></div>
+<div class=""next""><a href=""introduction-2.html"">Introduction</a></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
+      <ul class=""nav navbar-nav"">
+<li><a class=""nav-link"" href=""#crashcourse""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class=""nav-link"" href=""#introduction-1""><span class=""header-section-number"">1.1</span> Introduction</a></li>
+<li><a class=""nav-link"" href=""#bayes-theorem""><span class=""header-section-number"">1.2</span> Bayes‚Äô theorem</a></li>
+<li><a class=""nav-link"" href=""#what-is-the-bayesian-approach""><span class=""header-section-number"">1.3</span> What is the Bayesian approach?</a></li>
+<li><a class=""nav-link"" href=""#numerical-approx""><span class=""header-section-number"">1.4</span> Approximating posteriors via numerical integration</a></li>
+<li>
+<a class=""nav-link"" href=""#markov-chain-monte-carlo-mcmc""><span class=""header-section-number"">1.5</span> Markov chain Monte Carlo (MCMC)</a><ul class=""nav navbar-nav"">
+<li><a class=""nav-link"" href=""#monte-carlo-integration""><span class=""header-section-number"">1.5.1</span> Monte Carlo integration</a></li>
+<li><a class=""nav-link"" href=""#markovmodelmcmc""><span class=""header-section-number"">1.5.2</span> Markov chains</a></li>
+<li><a class=""nav-link"" href=""#metropolis-algorithm""><span class=""header-section-number"">1.5.3</span> Metropolis algorithm</a></li>
+</ul>
+</li>
+<li>
+<a class=""nav-link"" href=""#convergence-diag""><span class=""header-section-number"">1.6</span> Assessing convergence</a><ul class=""nav navbar-nav"">
+<li><a class=""nav-link"" href=""#burn-in""><span class=""header-section-number"">1.6.1</span> Burn-in</a></li>
+<li><a class=""nav-link"" href=""#chain-length""><span class=""header-section-number"">1.6.2</span> Chain length</a></li>
+<li><a class=""nav-link"" href=""#what-if-you-have-issues-of-convergence""><span class=""header-section-number"">1.6.3</span> What if you have issues of convergence?</a></li>
+</ul>
+</li>
+<li><a class=""nav-link"" href=""#summary""><span class=""header-section-number"">1.7</span> Summary</a></li>
+<li><a class=""nav-link"" href=""#suggested-reading""><span class=""header-section-number"">1.8</span> Suggested reading</a></li>
+</ul>
+
+      <div class=""book-extra"">
+        <ul class=""list-unstyled"">
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/bayesmcmc.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/bayesmcmc.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+        </ul>
+</div>
+    </nav>
+</div>
+
+</div>
+</div> <!-- .container -->
+
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-14.</p>
+  </div>
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
+  </div>
+
+</div></div>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
+</body>
+</html>

---FILE: docs/index.html---
@@ -0,0 +1,177 @@
+<!DOCTYPE html>
+<html lang=""en"">
+<head>
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>Welcome | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
+<meta property=""og:title"" content=""Welcome | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/"">
+<meta property=""og:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""Welcome | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+    
+    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
+  </style>
+<style type=""text/css"">
+    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
+    div.csl-bib-body { }
+    div.csl-entry {
+      clear: both;
+        }
+    .hanging div.csl-entry {
+      margin-left:2em;
+      text-indent:-2em;
+    }
+    div.csl-left-margin {
+      min-width:2em;
+      float:left;
+    }
+    div.csl-right-inline {
+      margin-left:2em;
+      padding-left:1em;
+    }
+    div.csl-indent {
+      margin-left: 2em;
+    }
+  </style>
+<link rel=""stylesheet"" href=""bs4_style.css"">
+</head>
+<body data-spy=""scroll"" data-target=""#toc"">
+
+<div class=""container-fluid"">
+<div class=""row"">
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+
+    <div class=""d-flex align-items-start justify-content-between"">
+      <h1>
+        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
+        <small class=""text-muted"">Theory and Case Studies in R</small>
+      </h1>
+      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
+    </div>
+
+    <div id=""main-nav"" class=""collapse-lg"">
+      <form role=""search"">
+        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
+</form>
+
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class=""active"" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li><a class="""" href=""about-the-author.html"">About the author</a></li>
+<li class=""book-part"">I. Foundations</li>
+<li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li class=""book-part"">II. Transitions</li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li class=""book-part"">III. Case studies</li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li class=""book-part"">IV. Conclusions</li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
+
+        <div class=""book-extra"">
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
+        </div>
+      </nav>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><!--bookdown:title:end--><!--bookdown:title:start--><div id=""welcome"" class=""section level1 unnumbered"">
+<h1>Welcome<a class=""anchor"" aria-label=""anchor"" href=""#welcome""><i class=""fas fa-link""></i></a>
+</h1>
+<!-- bookdown::render_book(""index.Rmd"", ""bookdown::pdf_book"") -->
+<p>Welcome to the online version of the book <em>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</em>. <!-- The book is also available in [PDF format](https://github.com/oliviergimenez/banana-book/raw/master/docs/bayesHMMcapturerecapture.pdf). --></p>
+<p>The HMM framework has gained much attention in the ecological literature over the last decade, and has been suggested as a general modelling framework for the demography of plant and animal populations. In particular, HMMs are increasingly used to analyse capture-recapture data and estimate key population parameters (e.g., survival, dispersal, recruitment or abundance) with applications in all fields of ecology.</p>
+<p>In parallel, Bayesian statistics is well established and fast growing in ecology and related disciplines, because it resonates with scientific reasoning and allows accommodating uncertainty smoothly. The popularity of Bayesian statistics also comes from the availability of free pieces of software (WinBUGS, OpenBUGS, JAGS, Stan, NIMBLE) that allow practitioners to code their own analyses.</p>
+<p>This book offers a Bayesian treatment of HMMs applied to capture-recapture data. You will learn to use the R package NIMBLE which is seen by many as the future of Bayesian statistical ecology to deal with complex models and/or big data. An important part of the book consists in case studies presented in a tutorial style to abide by the ‚Äúlearning by doing‚Äù philosophy.</p>
+<p>I‚Äôm currently writing this book, and I welcome any feedback. You may raise an issue <a href=""https://github.com/oliviergimenez/banana-book/issues"">here</a>, amend directly the R Markdown file that generated the page you‚Äôre reading by clicking on the ‚ÄòEdit this page‚Äô icon in the right panel, or <a href=""mailto:olivier.gimenez@cefe.cnrs.fr"">email me</a>. Many thanks!</p>
+<p>Olivier Gimenez. Written in Montpellier, France and Athens, Greece.
+Last updated: August 14, 2023</p>
+<div id=""license"" class=""section level2 unnumbered"">
+<h2>License<a class=""anchor"" aria-label=""anchor"" href=""#license""><i class=""fas fa-link""></i></a>
+</h2>
+<p>The online version of this book is licensed under the <a href=""http://creativecommons.org/licenses/by-nc-nd/4.0/"">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License</a>.</p>
+<p>The code is public domain, licensed under <a href=""https://creativecommons.org/publicdomain/zero/1.0/"">Creative Commons CC0 1.0 Universal (CC0 1.0)</a>.</p>
+
+</div>
+</div>
+  <div class=""chapter-nav"">
+<div class=""empty""></div>
+<div class=""next""><a href=""preface.html"">Preface</a></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
+      <ul class=""nav navbar-nav"">
+<li><a class=""nav-link"" href=""#welcome"">Welcome</a></li>
+<li><a class=""nav-link"" href=""#license"">License</a></li>
+</ul>
+
+      <div class=""book-extra"">
+        <ul class=""list-unstyled"">
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/index.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/index.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+        </ul>
+</div>
+    </nav>
+</div>
+
+</div>
+</div> <!-- .container -->
+
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-14.</p>
+  </div>
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
+  </div>
+
+</div></div>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
+</body>
+</html>

---FILE: docs/introduction-2.html---
@@ -0,0 +1,163 @@
+<!DOCTYPE html>
+<html lang=""en"">
+<head>
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
+<meta property=""og:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/introduction-2.html"">
+<meta property=""og:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+    
+    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
+  </style>
+<style type=""text/css"">
+    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
+    div.csl-bib-body { }
+    div.csl-entry {
+      clear: both;
+        }
+    .hanging div.csl-entry {
+      margin-left:2em;
+      text-indent:-2em;
+    }
+    div.csl-left-margin {
+      min-width:2em;
+      float:left;
+    }
+    div.csl-right-inline {
+      margin-left:2em;
+      padding-left:1em;
+    }
+    div.csl-indent {
+      margin-left: 2em;
+    }
+  </style>
+<link rel=""stylesheet"" href=""bs4_style.css"">
+</head>
+<body data-spy=""scroll"" data-target=""#toc"">
+
+<div class=""container-fluid"">
+<div class=""row"">
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+
+    <div class=""d-flex align-items-start justify-content-between"">
+      <h1>
+        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
+        <small class=""text-muted"">Theory and Case Studies in R</small>
+      </h1>
+      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
+    </div>
+
+    <div id=""main-nav"" class=""collapse-lg"">
+      <form role=""search"">
+        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
+</form>
+
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li><a class="""" href=""about-the-author.html"">About the author</a></li>
+<li class=""book-part"">I. Foundations</li>
+<li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li class=""book-part"">II. Transitions</li>
+<li><a class=""active"" href=""introduction-2.html"">Introduction</a></li>
+<li class=""book-part"">III. Case studies</li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li class=""book-part"">IV. Conclusions</li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
+
+        <div class=""book-extra"">
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
+        </div>
+      </nav>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""introduction-2"" class=""section level1 unnumbered"">
+<h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-2""><i class=""fas fa-link""></i></a>
+</h1>
+
+</div>
+
+
+
+  <div class=""chapter-nav"">
+<div class=""prev""><a href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></div>
+<div class=""next""><a href=""introduction-3.html"">Introduction</a></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
+      <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#introduction-2"">Introduction</a></li></ul>
+
+      <div class=""book-extra"">
+        <ul class=""list-unstyled"">
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionparttwo.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionparttwo.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+        </ul>
+</div>
+    </nav>
+</div>
+
+</div>
+</div> <!-- .container -->
+
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-14.</p>
+  </div>
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
+  </div>
+
+</div></div>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
+</body>
+</html>

---FILE: docs/introduction-3.html---
@@ -0,0 +1,160 @@
+<!DOCTYPE html>
+<html lang=""en"">
+<head>
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
+<meta property=""og:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/introduction-3.html"">
+<meta property=""og:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+    
+    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
+  </style>
+<style type=""text/css"">
+    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
+    div.csl-bib-body { }
+    div.csl-entry {
+      clear: both;
+        }
+    .hanging div.csl-entry {
+      margin-left:2em;
+      text-indent:-2em;
+    }
+    div.csl-left-margin {
+      min-width:2em;
+      float:left;
+    }
+    div.csl-right-inline {
+      margin-left:2em;
+      padding-left:1em;
+    }
+    div.csl-indent {
+      margin-left: 2em;
+    }
+  </style>
+<link rel=""stylesheet"" href=""bs4_style.css"">
+</head>
+<body data-spy=""scroll"" data-target=""#toc"">
+
+<div class=""container-fluid"">
+<div class=""row"">
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+
+    <div class=""d-flex align-items-start justify-content-between"">
+      <h1>
+        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
+        <small class=""text-muted"">Theory and Case Studies in R</small>
+      </h1>
+      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
+    </div>
+
+    <div id=""main-nav"" class=""collapse-lg"">
+      <form role=""search"">
+        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
+</form>
+
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li><a class="""" href=""about-the-author.html"">About the author</a></li>
+<li class=""book-part"">I. Foundations</li>
+<li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li class=""book-part"">II. Transitions</li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li class=""book-part"">III. Case studies</li>
+<li><a class=""active"" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li class=""book-part"">IV. Conclusions</li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
+
+        <div class=""book-extra"">
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
+        </div>
+      </nav>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""introduction-3"" class=""section level1 unnumbered"">
+<h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-3""><i class=""fas fa-link""></i></a>
+</h1>
+
+</div>
+  <div class=""chapter-nav"">
+<div class=""prev""><a href=""introduction-2.html"">Introduction</a></div>
+<div class=""next""><a href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
+      <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#introduction-3"">Introduction</a></li></ul>
+
+      <div class=""book-extra"">
+        <ul class=""list-unstyled"">
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionpartthree.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionpartthree.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+        </ul>
+</div>
+    </nav>
+</div>
+
+</div>
+</div> <!-- .container -->
+
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-14.</p>
+  </div>
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
+  </div>
+
+</div></div>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
+</body>
+</html>

---FILE: docs/introduction-4.html---
@@ -0,0 +1,159 @@
+<!DOCTYPE html>
+<html lang=""en"">
+<head>
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
+<meta property=""og:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/introduction-4.html"">
+<meta property=""og:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+    
+    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
+  </style>
+<style type=""text/css"">
+    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
+    div.csl-bib-body { }
+    div.csl-entry {
+      clear: both;
+        }
+    .hanging div.csl-entry {
+      margin-left:2em;
+      text-indent:-2em;
+    }
+    div.csl-left-margin {
+      min-width:2em;
+      float:left;
+    }
+    div.csl-right-inline {
+      margin-left:2em;
+      padding-left:1em;
+    }
+    div.csl-indent {
+      margin-left: 2em;
+    }
+  </style>
+<link rel=""stylesheet"" href=""bs4_style.css"">
+</head>
+<body data-spy=""scroll"" data-target=""#toc"">
+
+<div class=""container-fluid"">
+<div class=""row"">
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+
+    <div class=""d-flex align-items-start justify-content-between"">
+      <h1>
+        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
+        <small class=""text-muted"">Theory and Case Studies in R</small>
+      </h1>
+      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
+    </div>
+
+    <div id=""main-nav"" class=""collapse-lg"">
+      <form role=""search"">
+        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
+</form>
+
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li><a class="""" href=""about-the-author.html"">About the author</a></li>
+<li class=""book-part"">I. Foundations</li>
+<li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li class=""book-part"">II. Transitions</li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li class=""book-part"">III. Case studies</li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li class=""book-part"">IV. Conclusions</li>
+<li><a class=""active"" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
+
+        <div class=""book-extra"">
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
+        </div>
+      </nav>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""introduction-4"" class=""section level1 unnumbered"">
+<h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-4""><i class=""fas fa-link""></i></a>
+</h1>
+</div>
+  <div class=""chapter-nav"">
+<div class=""prev""><a href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></div>
+<div class=""next""><a href=""take-home-messages.html"">Take-home messages</a></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
+      <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#introduction-4"">Introduction</a></li></ul>
+
+      <div class=""book-extra"">
+        <ul class=""list-unstyled"">
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionpartfour.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionpartfour.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+        </ul>
+</div>
+    </nav>
+</div>
+
+</div>
+</div> <!-- .container -->
+
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-14.</p>
+  </div>
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
+  </div>
+
+</div></div>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
+</body>
+</html>

---FILE: docs/introduction.html---
@@ -0,0 +1,160 @@
+<!DOCTYPE html>
+<html lang=""en"">
+<head>
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
+<meta property=""og:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/introduction.html"">
+<meta property=""og:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+    
+    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
+  </style>
+<style type=""text/css"">
+    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
+    div.csl-bib-body { }
+    div.csl-entry {
+      clear: both;
+        }
+    .hanging div.csl-entry {
+      margin-left:2em;
+      text-indent:-2em;
+    }
+    div.csl-left-margin {
+      min-width:2em;
+      float:left;
+    }
+    div.csl-right-inline {
+      margin-left:2em;
+      padding-left:1em;
+    }
+    div.csl-indent {
+      margin-left: 2em;
+    }
+  </style>
+<link rel=""stylesheet"" href=""bs4_style.css"">
+</head>
+<body data-spy=""scroll"" data-target=""#toc"">
+
+<div class=""container-fluid"">
+<div class=""row"">
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+
+    <div class=""d-flex align-items-start justify-content-between"">
+      <h1>
+        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
+        <small class=""text-muted"">Theory and Case Studies in R</small>
+      </h1>
+      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
+    </div>
+
+    <div id=""main-nav"" class=""collapse-lg"">
+      <form role=""search"">
+        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
+</form>
+
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li><a class="""" href=""about-the-author.html"">About the author</a></li>
+<li class=""book-part"">I. Foundations</li>
+<li><a class=""active"" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li class=""book-part"">II. Transitions</li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li class=""book-part"">III. Case studies</li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li class=""book-part"">IV. Conclusions</li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
+
+        <div class=""book-extra"">
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
+        </div>
+      </nav>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""introduction"" class=""section level1 unnumbered"">
+<h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction""><i class=""fas fa-link""></i></a>
+</h1>
+
+</div>
+  <div class=""chapter-nav"">
+<div class=""prev""><a href=""about-the-author.html"">About the author</a></div>
+<div class=""next""><a href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
+      <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#introduction"">Introduction</a></li></ul>
+
+      <div class=""book-extra"">
+        <ul class=""list-unstyled"">
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionpartone.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionpartone.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+        </ul>
+</div>
+    </nav>
+</div>
+
+</div>
+</div> <!-- .container -->
+
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-14.</p>
+  </div>
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
+  </div>
+
+</div></div>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
+</body>
+</html>

---FILE: docs/lackoffit.html---
@@ -0,0 +1,202 @@
+<!DOCTYPE html>
+<html lang=""en"">
+<head>
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>Chapter 5 Lack of fit | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""5.1 Individual heterogeneity Cubaynes et al. (2010), Gimenez and Choquet (2010), and Turek, Wehrhahn, and Gimenez (2021). Example wolf. Traiter label switching avec constraint dans Nimble. Aussi..."">
+<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
+<meta property=""og:title"" content=""Chapter 5 Lack of fit | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/lackoffit.html"">
+<meta property=""og:description"" content=""5.1 Individual heterogeneity Cubaynes et al. (2010), Gimenez and Choquet (2010), and Turek, Wehrhahn, and Gimenez (2021). Example wolf. Traiter label switching avec constraint dans Nimble. Aussi..."">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""Chapter 5 Lack of fit | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""5.1 Individual heterogeneity Cubaynes et al. (2010), Gimenez and Choquet (2010), and Turek, Wehrhahn, and Gimenez (2021). Example wolf. Traiter label switching avec constraint dans Nimble. Aussi..."">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+    
+    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
+  </style>
+<style type=""text/css"">
+    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
+    div.csl-bib-body { }
+    div.csl-entry {
+      clear: both;
+        }
+    .hanging div.csl-entry {
+      margin-left:2em;
+      text-indent:-2em;
+    }
+    div.csl-left-margin {
+      min-width:2em;
+      float:left;
+    }
+    div.csl-right-inline {
+      margin-left:2em;
+      padding-left:1em;
+    }
+    div.csl-indent {
+      margin-left: 2em;
+    }
+  </style>
+<link rel=""stylesheet"" href=""bs4_style.css"">
+</head>
+<body data-spy=""scroll"" data-target=""#toc"">
+
+<div class=""container-fluid"">
+<div class=""row"">
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+
+    <div class=""d-flex align-items-start justify-content-between"">
+      <h1>
+        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
+        <small class=""text-muted"">Theory and Case Studies in R</small>
+      </h1>
+      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
+    </div>
+
+    <div id=""main-nav"" class=""collapse-lg"">
+      <form role=""search"">
+        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
+</form>
+
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li><a class="""" href=""about-the-author.html"">About the author</a></li>
+<li class=""book-part"">I. Foundations</li>
+<li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li class=""book-part"">II. Transitions</li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li class=""book-part"">III. Case studies</li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
+<li><a class=""active"" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li class=""book-part"">IV. Conclusions</li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
+
+        <div class=""book-extra"">
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
+        </div>
+      </nav>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""lackoffit"" class=""section level1"" number=""5"">
+<h1>
+<span class=""header-section-number"">5</span> Lack of fit<a class=""anchor"" aria-label=""anchor"" href=""#lackoffit""><i class=""fas fa-link""></i></a>
+</h1>
+<div id=""individual-heterogeneity"" class=""section level2"" number=""5.1"">
+<h2>
+<span class=""header-section-number"">5.1</span> Individual heterogeneity<a class=""anchor"" aria-label=""anchor"" href=""#individual-heterogeneity""><i class=""fas fa-link""></i></a>
+</h2>
+<p><span class=""citation"">Cubaynes et al. (<a href=""references.html#ref-cubaynes_importance_2010"">2010</a>)</span>, <span class=""citation"">Gimenez and Choquet (<a href=""references.html#ref-gimenez_individual_2010"">2010</a>)</span>, and <span class=""citation"">Turek, Wehrhahn, and Gimenez (<a href=""references.html#ref-turek_bayesian_2021"">2021</a>)</span>. Example wolf. Traiter label switching avec constraint dans Nimble. Aussi go fully non-parametric, w/ Daniel‚Äôs paper. Ou bien exercice mouettes des workshops E-SURGE?</p>
+</div>
+<div id=""trap-dep"" class=""section level2"" number=""5.2"">
+<h2>
+<span class=""header-section-number"">5.2</span> Trap dep<a class=""anchor"" aria-label=""anchor"" href=""#trap-dep""><i class=""fas fa-link""></i></a>
+</h2>
+<p>Papier Roger &amp; Ana. Sur dipper ? Add example for trap-dependence w/ time individual covariate.</p>
+<p><a href=""https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0032666"" class=""uri"">https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0032666</a></p>
+</div>
+<div id=""transience"" class=""section level2"" number=""5.3"">
+<h2>
+<span class=""header-section-number"">5.3</span> Transience<a class=""anchor"" aria-label=""anchor"" href=""#transience""><i class=""fas fa-link""></i></a>
+</h2>
+<p>Multievent treatment.</p>
+<p><a href=""https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0222241"" class=""uri"">https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0222241</a></p>
+</div>
+<div id=""temporary-emigration"" class=""section level2"" number=""5.4"">
+<h2>
+<span class=""header-section-number"">5.4</span> Temporary emigration<a class=""anchor"" aria-label=""anchor"" href=""#temporary-emigration""><i class=""fas fa-link""></i></a>
+</h2>
+<p>papier Michael.</p>
+</div>
+<div id=""memory-model"" class=""section level2"" number=""5.5"">
+<h2>
+<span class=""header-section-number"">5.5</span> Memory model<a class=""anchor"" aria-label=""anchor"" href=""#memory-model""><i class=""fas fa-link""></i></a>
+</h2>
+
+</div>
+</div>
+
+
+
+  <div class=""chapter-nav"">
+<div class=""prev""><a href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></div>
+<div class=""next""><a href=""introduction-4.html"">Introduction</a></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
+      <ul class=""nav navbar-nav"">
+<li><a class=""nav-link"" href=""#lackoffit""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li><a class=""nav-link"" href=""#individual-heterogeneity""><span class=""header-section-number"">5.1</span> Individual heterogeneity</a></li>
+<li><a class=""nav-link"" href=""#trap-dep""><span class=""header-section-number"">5.2</span> Trap dep</a></li>
+<li><a class=""nav-link"" href=""#transience""><span class=""header-section-number"">5.3</span> Transience</a></li>
+<li><a class=""nav-link"" href=""#temporary-emigration""><span class=""header-section-number"">5.4</span> Temporary emigration</a></li>
+<li><a class=""nav-link"" href=""#memory-model""><span class=""header-section-number"">5.5</span> Memory model</a></li>
+</ul>
+
+      <div class=""book-extra"">
+        <ul class=""list-unstyled"">
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/lackoffit.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/lackoffit.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+        </ul>
+</div>
+    </nav>
+</div>
+
+</div>
+</div> <!-- .container -->
+
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-14.</p>
+  </div>
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
+  </div>
+
+</div></div>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
+</body>
+</html>

---FILE: docs/libs/bootstrap-4.6.0/bootstrap.bundle.min.js---
@@ -0,0 +1,7 @@
+/*!
+  * Bootstrap v4.6.0 (https://getbootstrap.com/)
+  * Copyright 2011-2021 The Bootstrap Authors (https://github.com/twbs/bootstrap/graphs/contributors)
+  * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE)
+  */
+!function(t,e){""object""==typeof exports&&""undefined""!=typeof module?e(exports,require(""jquery"")):""function""==typeof define&&define.amd?define([""exports"",""jquery""],e):e((t=""undefined""!=typeof globalThis?globalThis:t||self).bootstrap={},t.jQuery)}(this,(function(t,e){""use strict"";function n(t){return t&&""object""==typeof t&&""default""in t?t:{default:t}}var i=n(e);function o(t,e){for(var n=0;n<e.length;n++){var i=e[n];i.enumerable=i.enumerable||!1,i.configurable=!0,""value""in i&&(i.writable=!0),Object.defineProperty(t,i.key,i)}}function r(t,e,n){return e&&o(t.prototype,e),n&&o(t,n),t}function a(){return(a=Object.assign||function(t){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var i in n)Object.prototype.hasOwnProperty.call(n,i)&&(t[i]=n[i])}return t}).apply(this,arguments)}function s(t){var e=this,n=!1;return i.default(this).one(l.TRANSITION_END,(function(){n=!0})),setTimeout((function(){n||l.triggerTransitionEnd(e)}),t),this}var l={TRANSITION_END:""bsTransitionEnd"",getUID:function(t){do{t+=~~(1e6*Math.random())}while(document.getElementById(t));return t},getSelectorFromElement:function(t){var e=t.getAttribute(""data-target"");if(!e||""#""===e){var n=t.getAttribute(""href"");e=n&&""#""!==n?n.trim():""""}try{return document.querySelector(e)?e:null}catch(t){return null}},getTransitionDurationFromElement:function(t){if(!t)return 0;var e=i.default(t).css(""transition-duration""),n=i.default(t).css(""transition-delay""),o=parseFloat(e),r=parseFloat(n);return o||r?(e=e.split("","")[0],n=n.split("","")[0],1e3*(parseFloat(e)+parseFloat(n))):0},reflow:function(t){return t.offsetHeight},triggerTransitionEnd:function(t){i.default(t).trigger(""transitionend"")},supportsTransitionEnd:function(){return Boolean(""transitionend"")},isElement:function(t){return(t[0]||t).nodeType},typeCheckConfig:function(t,e,n){for(var i in n)if(Object.prototype.hasOwnProperty.call(n,i)){var o=n[i],r=e[i],a=r&&l.isElement(r)?""element"":null===(s=r)||""undefined""==typeof s?""""+s:{}.toString.call(s).match(/\s([a-z]+)/i)[1].toLowerCase();if(!new RegExp(o).test(a))throw new Error(t.toUpperCase()+': Option ""'+i+'"" provided type ""'+a+'"" but expected type ""'+o+'"".')}var s},findShadowRoot:function(t){if(!document.documentElement.attachShadow)return null;if(""function""==typeof t.getRootNode){var e=t.getRootNode();return e instanceof ShadowRoot?e:null}return t instanceof ShadowRoot?t:t.parentNode?l.findShadowRoot(t.parentNode):null},jQueryDetection:function(){if(""undefined""==typeof i.default)throw new TypeError(""Bootstrap's JavaScript requires jQuery. jQuery must be included before Bootstrap's JavaScript."");var t=i.default.fn.jquery.split("" "")[0].split(""."");if(t[0]<2&&t[1]<9||1===t[0]&&9===t[1]&&t[2]<1||t[0]>=4)throw new Error(""Bootstrap's JavaScript requires at least jQuery v1.9.1 but less than v4.0.0"")}};l.jQueryDetection(),i.default.fn.emulateTransitionEnd=s,i.default.event.special[l.TRANSITION_END]={bindType:""transitionend"",delegateType:""transitionend"",handle:function(t){if(i.default(t.target).is(this))return t.handleObj.handler.apply(this,arguments)}};var u=""alert"",f=i.default.fn[u],d=function(){function t(t){this._element=t}var e=t.prototype;return e.close=function(t){var e=this._element;t&&(e=this._getRootElement(t)),this._triggerCloseEvent(e).isDefaultPrevented()||this._removeElement(e)},e.dispose=function(){i.default.removeData(this._element,""bs.alert""),this._element=null},e._getRootElement=function(t){var e=l.getSelectorFromElement(t),n=!1;return e&&(n=document.querySelector(e)),n||(n=i.default(t).closest("".alert"")[0]),n},e._triggerCloseEvent=function(t){var e=i.default.Event(""close.bs.alert"");return i.default(t).trigger(e),e},e._removeElement=function(t){var e=this;if(i.default(t).removeClass(""show""),i.default(t).hasClass(""fade"")){var n=l.getTransitionDurationFromElement(t);i.default(t).one(l.TRANSITION_END,(function(n){return e._destroyElement(t,n)})).emulateTransitionEnd(n)}else this._destroyElement(t)},e._destroyElement=function(t){i.default(t).detach().trigger(""closed.bs.alert"").remove()},t._jQueryInterface=function(e){return this.each((function(){var n=i.default(this),o=n.data(""bs.alert"");o||(o=new t(this),n.data(""bs.alert"",o)),""close""===e&&o[e](this)}))},t._handleDismiss=function(t){return function(e){e&&e.preventDefault(),t.close(this)}},r(t,null,[{key:""VERSION"",get:function(){return""4.6.0""}}]),t}();i.default(document).on(""click.bs.alert.data-api"",'[data-dismiss=""alert""]',d._handleDismiss(new d)),i.default.fn[u]=d._jQueryInterface,i.default.fn[u].Constructor=d,i.default.fn[u].noConflict=function(){return i.default.fn[u]=f,d._jQueryInterface};var c=i.default.fn.button,h=function(){function t(t){this._element=t,this.shouldAvoidTriggerChange=!1}var e=t.prototype;return e.toggle=function(){var t=!0,e=!0,n=i.default(this._element).closest('[data-toggle=""buttons""]')[0];if(n){var o=this._element.querySelector('input:not([type=""hidden""])');if(o){if(""radio""===o.type)if(o.checked&&this._element.classList.contains(""active""))t=!1;else{var r=n.querySelector("".active"");r&&i.default(r).removeClass(""active"")}t&&(""checkbox""!==o.type&&""radio""!==o.type||(o.checked=!this._element.classList.contains(""active"")),this.shouldAvoidTriggerChange||i.default(o).trigger(""change"")),o.focus(),e=!1}}this._element.hasAttribute(""disabled"")||this._element.classList.contains(""disabled"")||(e&&this._element.setAttribute(""aria-pressed"",!this._element.classList.contains(""active"")),t&&i.default(this._element).toggleClass(""active""))},e.dispose=function(){i.default.removeData(this._element,""bs.button""),this._element=null},t._jQueryInterface=function(e,n){return this.each((function(){var o=i.default(this),r=o.data(""bs.button"");r||(r=new t(this),o.data(""bs.button"",r)),r.shouldAvoidTriggerChange=n,""toggle""===e&&r[e]()}))},r(t,null,[{key:""VERSION"",get:function(){return""4.6.0""}}]),t}();i.default(document).on(""click.bs.button.data-api"",'[data-toggle^=""button""]',(function(t){var e=t.target,n=e;if(i.default(e).hasClass(""btn"")||(e=i.default(e).closest("".btn"")[0]),!e||e.hasAttribute(""disabled"")||e.classList.contains(""disabled""))t.preventDefault();else{var o=e.querySelector('input:not([type=""hidden""])');if(o&&(o.hasAttribute(""disabled"")||o.classList.contains(""disabled"")))return void t.preventDefault();""INPUT""!==n.tagName&&""LABEL""===e.tagName||h._jQueryInterface.call(i.default(e),""toggle"",""INPUT""===n.tagName)}})).on(""focus.bs.button.data-api blur.bs.button.data-api"",'[data-toggle^=""button""]',(function(t){var e=i.default(t.target).closest("".btn"")[0];i.default(e).toggleClass(""focus"",/^focus(in)?$/.test(t.type))})),i.default(window).on(""load.bs.button.data-api"",(function(){for(var t=[].slice.call(document.querySelectorAll('[data-toggle=""buttons""] .btn')),e=0,n=t.length;e<n;e++){var i=t[e],o=i.querySelector('input:not([type=""hidden""])');o.checked||o.hasAttribute(""checked"")?i.classList.add(""active""):i.classList.remove(""active"")}for(var r=0,a=(t=[].slice.call(document.querySelectorAll('[data-toggle=""button""]'))).length;r<a;r++){var s=t[r];""true""===s.getAttribute(""aria-pressed"")?s.classList.add(""active""):s.classList.remove(""active"")}})),i.default.fn.button=h._jQueryInterface,i.default.fn.button.Constructor=h,i.default.fn.button.noConflict=function(){return i.default.fn.button=c,h._jQueryInterface};var p=""carousel"",m="".bs.carousel"",g=i.default.fn[p],v={interval:5e3,keyboard:!0,slide:!1,pause:""hover"",wrap:!0,touch:!0},_={interval:""(number|boolean)"",keyboard:""boolean"",slide:""(boolean|string)"",pause:""(string|boolean)"",wrap:""boolean"",touch:""boolean""},b={TOUCH:""touch"",PEN:""pen""},y=function(){function t(t,e){this._items=null,this._interval=null,this._activeElement=null,this._isPaused=!1,this._isSliding=!1,this.touchTimeout=null,this.touchStartX=0,this.touchDeltaX=0,this._config=this._getConfig(e),this._element=t,this._indicatorsElement=this._element.querySelector("".carousel-indicators""),this._touchSupported=""ontouchstart""in document.documentElement||navigator.maxTouchPoints>0,this._pointerEvent=Boolean(window.PointerEvent||window.MSPointerEvent),this._addEventListeners()}var e=t.prototype;return e.next=function(){this._isSliding||this._slide(""next"")},e.nextWhenVisible=function(){var t=i.default(this._element);!document.hidden&&t.is("":visible"")&&""hidden""!==t.css(""visibility"")&&this.next()},e.prev=function(){this._isSliding||this._slide(""prev"")},e.pause=function(t){t||(this._isPaused=!0),this._element.querySelector("".carousel-item-next, .carousel-item-prev"")&&(l.triggerTransitionEnd(this._element),this.cycle(!0)),clearInterval(this._interval),this._interval=null},e.cycle=function(t){t||(this._isPaused=!1),this._interval&&(clearInterval(this._interval),this._interval=null),this._config.interval&&!this._isPaused&&(this._updateInterval(),this._interval=setInterval((document.visibilityState?this.nextWhenVisible:this.next).bind(this),this._config.interval))},e.to=function(t){var e=this;this._activeElement=this._element.querySelector("".active.carousel-item"");var n=this._getItemIndex(this._activeElement);if(!(t>this._items.length-1||t<0))if(this._isSliding)i.default(this._element).one(""slid.bs.carousel"",(function(){return e.to(t)}));else{if(n===t)return this.pause(),void this.cycle();var o=t>n?""next"":""prev"";this._slide(o,this._items[t])}},e.dispose=function(){i.default(this._element).off(m),i.default.removeData(this._element,""bs.carousel""),this._items=null,this._config=null,this._element=null,this._interval=null,this._isPaused=null,this._isSliding=null,this._activeElement=null,this._indicatorsElement=null},e._getConfig=function(t){return t=a({},v,t),l.typeCheckConfig(p,t,_),t},e._handleSwipe=function(){var t=Math.abs(this.touchDeltaX);if(!(t<=40)){var e=t/this.touchDeltaX;this.touchDeltaX=0,e>0&&this.prev(),e<0&&this.next()}},e._addEventListeners=function(){var t=this;this._config.keyboard&&i.default(this._element).on(""keydown.bs.carousel"",(function(e){return t._keydown(e)})),""hover""===this._config.pause&&i.default(this._element).on(""mouseenter.bs.carousel"",(function(e){return t.pause(e)})).on(""mouseleave.bs.carousel"",(function(e){return t.cycle(e)})),this._config.touch&&this._addTouchEventListeners()},e._addTouchEventListeners=function(){var t=this;if(this._touchSupported){var e=function(e){t._pointerEvent&&b[e.originalEvent.pointerType.toUpperCase()]?t.touchStartX=e.originalEvent.clientX:t._pointerEvent||(t.touchStartX=e.originalEvent.touches[0].clientX)},n=function(e){t._pointerEvent&&b[e.originalEvent.pointerType.toUpperCase()]&&(t.touchDeltaX=e.originalEvent.clientX-t.touchStartX),t._handleSwipe(),""hover""===t._config.pause&&(t.pause(),t.touchTimeout&&clearTimeout(t.touchTimeout),t.touchTimeout=setTimeout((function(e){return t.cycle(e)}),500+t._config.interval))};i.default(this._element.querySelectorAll("".carousel-item img"")).on(""dragstart.bs.carousel"",(function(t){return t.preventDefault()})),this._pointerEvent?(i.default(this._element).on(""pointerdown.bs.carousel"",(function(t){return e(t)})),i.default(this._element).on(""pointerup.bs.carousel"",(function(t){return n(t)})),this._element.classList.add(""pointer-event"")):(i.default(this._element).on(""touchstart.bs.carousel"",(function(t){return e(t)})),i.default(this._element).on(""touchmove.bs.carousel"",(function(e){return function(e){e.originalEvent.touches&&e.originalEvent.touches.length>1?t.touchDeltaX=0:t.touchDeltaX=e.originalEvent.touches[0].clientX-t.touchStartX}(e)})),i.default(this._element).on(""touchend.bs.carousel"",(function(t){return n(t)})))}},e._keydown=function(t){if(!/input|textarea/i.test(t.target.tagName))switch(t.which){case 37:t.preventDefault(),this.prev();break;case 39:t.preventDefault(),this.next()}},e._getItemIndex=function(t){return this._items=t&&t.parentNode?[].slice.call(t.parentNode.querySelectorAll("".carousel-item"")):[],this._items.indexOf(t)},e._getItemByDirection=function(t,e){var n=""next""===t,i=""prev""===t,o=this._getItemIndex(e),r=this._items.length-1;if((i&&0===o||n&&o===r)&&!this._config.wrap)return e;var a=(o+(""prev""===t?-1:1))%this._items.length;return-1===a?this._items[this._items.length-1]:this._items[a]},e._triggerSlideEvent=function(t,e){var n=this._getItemIndex(t),o=this._getItemIndex(this._element.querySelector("".active.carousel-item"")),r=i.default.Event(""slide.bs.carousel"",{relatedTarget:t,direction:e,from:o,to:n});return i.default(this._element).trigger(r),r},e._setActiveIndicatorElement=function(t){if(this._indicatorsElement){var e=[].slice.call(this._indicatorsElement.querySelectorAll("".active""));i.default(e).removeClass(""active"");var n=this._indicatorsElement.children[this._getItemIndex(t)];n&&i.default(n).addClass(""active"")}},e._updateInterval=function(){var t=this._activeElement||this._element.querySelector("".active.carousel-item"");if(t){var e=parseInt(t.getAttribute(""data-interval""),10);e?(this._config.defaultInterval=this._config.defaultInterval||this._config.interval,this._config.interval=e):this._config.interval=this._config.defaultInterval||this._config.interval}},e._slide=function(t,e){var n,o,r,a=this,s=this._element.querySelector("".active.carousel-item""),u=this._getItemIndex(s),f=e||s&&this._getItemByDirection(t,s),d=this._getItemIndex(f),c=Boolean(this._interval);if(""next""===t?(n=""carousel-item-left"",o=""carousel-item-next"",r=""left""):(n=""carousel-item-right"",o=""carousel-item-prev"",r=""right""),f&&i.default(f).hasClass(""active""))this._isSliding=!1;else if(!this._triggerSlideEvent(f,r).isDefaultPrevented()&&s&&f){this._isSliding=!0,c&&this.pause(),this._setActiveIndicatorElement(f),this._activeElement=f;var h=i.default.Event(""slid.bs.carousel"",{relatedTarget:f,direction:r,from:u,to:d});if(i.default(this._element).hasClass(""slide"")){i.default(f).addClass(o),l.reflow(f),i.default(s).addClass(n),i.default(f).addClass(n);var p=l.getTransitionDurationFromElement(s);i.default(s).one(l.TRANSITION_END,(function(){i.default(f).removeClass(n+"" ""+o).addClass(""active""),i.default(s).removeClass(""active ""+o+"" ""+n),a._isSliding=!1,setTimeout((function(){return i.default(a._element).trigger(h)}),0)})).emulateTransitionEnd(p)}else i.default(s).removeClass(""active""),i.default(f).addClass(""active""),this._isSliding=!1,i.default(this._element).trigger(h);c&&this.cycle()}},t._jQueryInterface=function(e){return this.each((function(){var n=i.default(this).data(""bs.carousel""),o=a({},v,i.default(this).data());""object""==typeof e&&(o=a({},o,e));var r=""string""==typeof e?e:o.slide;if(n||(n=new t(this,o),i.default(this).data(""bs.carousel"",n)),""number""==typeof e)n.to(e);else if(""string""==typeof r){if(""undefined""==typeof n[r])throw new TypeError('No method named ""'+r+'""');n[r]()}else o.interval&&o.ride&&(n.pause(),n.cycle())}))},t._dataApiClickHandler=function(e){var n=l.getSelectorFromElement(this);if(n){var o=i.default(n)[0];if(o&&i.default(o).hasClass(""carousel"")){var r=a({},i.default(o).data(),i.default(this).data()),s=this.getAttribute(""data-slide-to"");s&&(r.interval=!1),t._jQueryInterface.call(i.default(o),r),s&&i.default(o).data(""bs.carousel"").to(s),e.preventDefault()}}},r(t,null,[{key:""VERSION"",get:function(){return""4.6.0""}},{key:""Default"",get:function(){return v}}]),t}();i.default(document).on(""click.bs.carousel.data-api"",""[data-slide], [data-slide-to]"",y._dataApiClickHandler),i.default(window).on(""load.bs.carousel.data-api"",(function(){for(var t=[].slice.call(document.querySelectorAll('[data-ride=""carousel""]')),e=0,n=t.length;e<n;e++){var o=i.default(t[e]);y._jQueryInterface.call(o,o.data())}})),i.default.fn[p]=y._jQueryInterface,i.default.fn[p].Constructor=y,i.default.fn[p].noConflict=function(){return i.default.fn[p]=g,y._jQueryInterface};var w=""collapse"",E=i.default.fn[w],T={toggle:!0,parent:""""},C={toggle:""boolean"",parent:""(string|element)""},S=function(){function t(t,e){this._isTransitioning=!1,this._element=t,this._config=this._getConfig(e),this._triggerArray=[].slice.call(document.querySelectorAll('[data-toggle=""collapse""][href=""#'+t.id+'""],[data-toggle=""collapse""][data-target=""#'+t.id+'""]'));for(var n=[].slice.call(document.querySelectorAll('[data-toggle=""collapse""]')),i=0,o=n.length;i<o;i++){var r=n[i],a=l.getSelectorFromElement(r),s=[].slice.call(document.querySelectorAll(a)).filter((function(e){return e===t}));null!==a&&s.length>0&&(this._selector=a,this._triggerArray.push(r))}this._parent=this._config.parent?this._getParent():null,this._config.parent||this._addAriaAndCollapsedClass(this._element,this._triggerArray),this._config.toggle&&this.toggle()}var e=t.prototype;return e.toggle=function(){i.default(this._element).hasClass(""show"")?this.hide():this.show()},e.show=function(){var e,n,o=this;if(!this._isTransitioning&&!i.default(this._element).hasClass(""show"")&&(this._parent&&0===(e=[].slice.call(this._parent.querySelectorAll("".show, .collapsing"")).filter((function(t){return""string""==typeof o._config.parent?t.getAttribute(""data-parent"")===o._config.parent:t.classList.contains(""collapse"")}))).length&&(e=null),!(e&&(n=i.default(e).not(this._selector).data(""bs.collapse""))&&n._isTransitioning))){var r=i.default.Event(""show.bs.collapse"");if(i.default(this._element).trigger(r),!r.isDefaultPrevented()){e&&(t._jQueryInterface.call(i.default(e).not(this._selector),""hide""),n||i.default(e).data(""bs.collapse"",null));var a=this._getDimension();i.default(this._element).removeClass(""collapse"").addClass(""collapsing""),this._element.style[a]=0,this._triggerArray.length&&i.default(this._triggerArray).removeClass(""collapsed"").attr(""aria-expanded"",!0),this.setTransitioning(!0);var s=""scroll""+(a[0].toUpperCase()+a.slice(1)),u=l.getTransitionDurationFromElement(this._element);i.default(this._element).one(l.TRANSITION_END,(function(){i.default(o._element).removeClass(""collapsing"").addClass(""collapse show""),o._element.style[a]="""",o.setTransitioning(!1),i.default(o._element).trigger(""shown.bs.collapse"")})).emulateTransitionEnd(u),this._element.style[a]=this._element[s]+""px""}}},e.hide=function(){var t=this;if(!this._isTransitioning&&i.default(this._element).hasClass(""show"")){var e=i.default.Event(""hide.bs.collapse"");if(i.default(this._element).trigger(e),!e.isDefaultPrevented()){var n=this._getDimension();this._element.style[n]=this._element.getBoundingClientRect()[n]+""px"",l.reflow(this._element),i.default(this._element).addClass(""collapsing"").removeClass(""collapse show"");var o=this._triggerArray.length;if(o>0)for(var r=0;r<o;r++){var a=this._triggerArray[r],s=l.getSelectorFromElement(a);if(null!==s)i.default([].slice.call(document.querySelectorAll(s))).hasClass(""show"")||i.default(a).addClass(""collapsed"").attr(""aria-expanded"",!1)}this.setTransitioning(!0);this._element.style[n]="""";var u=l.getTransitionDurationFromElement(this._element);i.default(this._element).one(l.TRANSITION_END,(function(){t.setTransitioning(!1),i.default(t._element).removeClass(""collapsing"").addClass(""collapse"").trigger(""hidden.bs.collapse"")})).emulateTransitionEnd(u)}}},e.setTransitioning=function(t){this._isTransitioning=t},e.dispose=function(){i.default.removeData(this._element,""bs.collapse""),this._config=null,this._parent=null,this._element=null,this._triggerArray=null,this._isTransitioning=null},e._getConfig=function(t){return(t=a({},T,t)).toggle=Boolean(t.toggle),l.typeCheckConfig(w,t,C),t},e._getDimension=function(){return i.default(this._element).hasClass(""width"")?""width"":""height""},e._getParent=function(){var e,n=this;l.isElement(this._config.parent)?(e=this._config.parent,""undefined""!=typeof this._config.parent.jquery&&(e=this._config.parent[0])):e=document.querySelector(this._config.parent);var o='[data-toggle=""collapse""][data-parent=""'+this._config.parent+'""]',r=[].slice.call(e.querySelectorAll(o));return i.default(r).each((function(e,i){n._addAriaAndCollapsedClass(t._getTargetFromElement(i),[i])})),e},e._addAriaAndCollapsedClass=function(t,e){var n=i.default(t).hasClass(""show"");e.length&&i.default(e).toggleClass(""collapsed"",!n).attr(""aria-expanded"",n)},t._getTargetFromElement=function(t){var e=l.getSelectorFromElement(t);return e?document.querySelector(e):null},t._jQueryInterface=function(e){return this.each((function(){var n=i.default(this),o=n.data(""bs.collapse""),r=a({},T,n.data(),""object""==typeof e&&e?e:{});if(!o&&r.toggle&&""string""==typeof e&&/show|hide/.test(e)&&(r.toggle=!1),o||(o=new t(this,r),n.data(""bs.collapse"",o)),""string""==typeof e){if(""undefined""==typeof o[e])throw new TypeError('No method named ""'+e+'""');o[e]()}}))},r(t,null,[{key:""VERSION"",get:function(){return""4.6.0""}},{key:""Default"",get:function(){return T}}]),t}();i.default(document).on(""click.bs.collapse.data-api"",'[data-toggle=""collapse""]',(function(t){""A""===t.currentTarget.tagName&&t.preventDefault();var e=i.default(this),n=l.getSelectorFromElement(this),o=[].slice.call(document.querySelectorAll(n));i.default(o).each((function(){var t=i.default(this),n=t.data(""bs.collapse"")?""toggle"":e.data();S._jQueryInterface.call(t,n)}))})),i.default.fn[w]=S._jQueryInterface,i.default.fn[w].Constructor=S,i.default.fn[w].noConflict=function(){return i.default.fn[w]=E,S._jQueryInterface};var N=""undefined""!=typeof window&&""undefined""!=typeof document&&""undefined""!=typeof navigator,D=function(){for(var t=[""Edge"",""Trident"",""Firefox""],e=0;e<t.length;e+=1)if(N&&navigator.userAgent.indexOf(t[e])>=0)return 1;return 0}();var k=N&&window.Promise?function(t){var e=!1;return function(){e||(e=!0,window.Promise.resolve().then((function(){e=!1,t()})))}}:function(t){var e=!1;return function(){e||(e=!0,setTimeout((function(){e=!1,t()}),D))}};function A(t){return t&&""[object Function]""==={}.toString.call(t)}function I(t,e){if(1!==t.nodeType)return[];var n=t.ownerDocument.defaultView.getComputedStyle(t,null);return e?n[e]:n}function O(t){return""HTML""===t.nodeName?t:t.parentNode||t.host}function x(t){if(!t)return document.body;switch(t.nodeName){case""HTML"":case""BODY"":return t.ownerDocument.body;case""#document"":return t.body}var e=I(t),n=e.overflow,i=e.overflowX,o=e.overflowY;return/(auto|scroll|overlay)/.test(n+o+i)?t:x(O(t))}function j(t){return t&&t.referenceNode?t.referenceNode:t}var L=N&&!(!window.MSInputMethodContext||!document.documentMode),P=N&&/MSIE 10/.test(navigator.userAgent);function F(t){return 11===t?L:10===t?P:L||P}function R(t){if(!t)return document.documentElement;for(var e=F(10)?document.body:null,n=t.offsetParent||null;n===e&&t.nextElementSibling;)n=(t=t.nextElementSibling).offsetParent;var i=n&&n.nodeName;return i&&""BODY""!==i&&""HTML""!==i?-1!==[""TH"",""TD"",""TABLE""].indexOf(n.nodeName)&&""static""===I(n,""position"")?R(n):n:t?t.ownerDocument.documentElement:document.documentElement}function H(t){return null!==t.parentNode?H(t.parentNode):t}function M(t,e){if(!(t&&t.nodeType&&e&&e.nodeType))return document.documentElement;var n=t.compareDocumentPosition(e)&Node.DOCUMENT_POSITION_FOLLOWING,i=n?t:e,o=n?e:t,r=document.createRange();r.setStart(i,0),r.setEnd(o,0);var a,s,l=r.commonAncestorContainer;if(t!==l&&e!==l||i.contains(o))return""BODY""===(s=(a=l).nodeName)||""HTML""!==s&&R(a.firstElementChild)!==a?R(l):l;var u=H(t);return u.host?M(u.host,e):M(t,H(e).host)}function q(t){var e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:""top"",n=""top""===e?""scrollTop"":""scrollLeft"",i=t.nodeName;if(""BODY""===i||""HTML""===i){var o=t.ownerDocument.documentElement,r=t.ownerDocument.scrollingElement||o;return r[n]}return t[n]}function B(t,e){var n=arguments.length>2&&void 0!==arguments[2]&&arguments[2],i=q(e,""top""),o=q(e,""left""),r=n?-1:1;return t.top+=i*r,t.bottom+=i*r,t.left+=o*r,t.right+=o*r,t}function Q(t,e){var n=""x""===e?""Left"":""Top"",i=""Left""===n?""Right"":""Bottom"";return parseFloat(t[""border""+n+""Width""])+parseFloat(t[""border""+i+""Width""])}function W(t,e,n,i){return Math.max(e[""offset""+t],e[""scroll""+t],n[""client""+t],n[""offset""+t],n[""scroll""+t],F(10)?parseInt(n[""offset""+t])+parseInt(i[""margin""+(""Height""===t?""Top"":""Left"")])+parseInt(i[""margin""+(""Height""===t?""Bottom"":""Right"")]):0)}function U(t){var e=t.body,n=t.documentElement,i=F(10)&&getComputedStyle(n);return{height:W(""Height"",e,n,i),width:W(""Width"",e,n,i)}}var V=function(t,e){if(!(t instanceof e))throw new TypeError(""Cannot call a class as a function"")},Y=function(){function t(t,e){for(var n=0;n<e.length;n++){var i=e[n];i.enumerable=i.enumerable||!1,i.configurable=!0,""value""in i&&(i.writable=!0),Object.defineProperty(t,i.key,i)}}return function(e,n,i){return n&&t(e.prototype,n),i&&t(e,i),e}}(),z=function(t,e,n){return e in t?Object.defineProperty(t,e,{value:n,enumerable:!0,configurable:!0,writable:!0}):t[e]=n,t},X=Object.assign||function(t){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var i in n)Object.prototype.hasOwnProperty.call(n,i)&&(t[i]=n[i])}return t};function K(t){return X({},t,{right:t.left+t.width,bottom:t.top+t.height})}function G(t){var e={};try{if(F(10)){e=t.getBoundingClientRect();var n=q(t,""top""),i=q(t,""left"");e.top+=n,e.left+=i,e.bottom+=n,e.right+=i}else e=t.getBoundingClientRect()}catch(t){}var o={left:e.left,top:e.top,width:e.right-e.left,height:e.bottom-e.top},r=""HTML""===t.nodeName?U(t.ownerDocument):{},a=r.width||t.clientWidth||o.width,s=r.height||t.clientHeight||o.height,l=t.offsetWidth-a,u=t.offsetHeight-s;if(l||u){var f=I(t);l-=Q(f,""x""),u-=Q(f,""y""),o.width-=l,o.height-=u}return K(o)}function $(t,e){var n=arguments.length>2&&void 0!==arguments[2]&&arguments[2],i=F(10),o=""HTML""===e.nodeName,r=G(t),a=G(e),s=x(t),l=I(e),u=parseFloat(l.borderTopWidth),f=parseFloat(l.borderLeftWidth);n&&o&&(a.top=Math.max(a.top,0),a.left=Math.max(a.left,0));var d=K({top:r.top-a.top-u,left:r.left-a.left-f,width:r.width,height:r.height});if(d.marginTop=0,d.marginLeft=0,!i&&o){var c=parseFloat(l.marginTop),h=parseFloat(l.marginLeft);d.top-=u-c,d.bottom-=u-c,d.left-=f-h,d.right-=f-h,d.marginTop=c,d.marginLeft=h}return(i&&!n?e.contains(s):e===s&&""BODY""!==s.nodeName)&&(d=B(d,e)),d}function J(t){var e=arguments.length>1&&void 0!==arguments[1]&&arguments[1],n=t.ownerDocument.documentElement,i=$(t,n),o=Math.max(n.clientWidth,window.innerWidth||0),r=Math.max(n.clientHeight,window.innerHeight||0),a=e?0:q(n),s=e?0:q(n,""left""),l={top:a-i.top+i.marginTop,left:s-i.left+i.marginLeft,width:o,height:r};return K(l)}function Z(t){var e=t.nodeName;if(""BODY""===e||""HTML""===e)return!1;if(""fixed""===I(t,""position""))return!0;var n=O(t);return!!n&&Z(n)}function tt(t){if(!t||!t.parentElement||F())return document.documentElement;for(var e=t.parentElement;e&&""none""===I(e,""transform"");)e=e.parentElement;return e||document.documentElement}function et(t,e,n,i){var o=arguments.length>4&&void 0!==arguments[4]&&arguments[4],r={top:0,left:0},a=o?tt(t):M(t,j(e));if(""viewport""===i)r=J(a,o);else{var s=void 0;""scrollParent""===i?""BODY""===(s=x(O(e))).nodeName&&(s=t.ownerDocument.documentElement):s=""window""===i?t.ownerDocument.documentElement:i;var l=$(s,a,o);if(""HTML""!==s.nodeName||Z(a))r=l;else{var u=U(t.ownerDocument),f=u.height,d=u.width;r.top+=l.top-l.marginTop,r.bottom=f+l.top,r.left+=l.left-l.marginLeft,r.right=d+l.left}}var c=""number""==typeof(n=n||0);return r.left+=c?n:n.left||0,r.top+=c?n:n.top||0,r.right-=c?n:n.right||0,r.bottom-=c?n:n.bottom||0,r}function nt(t){return t.width*t.height}function it(t,e,n,i,o){var r=arguments.length>5&&void 0!==arguments[5]?arguments[5]:0;if(-1===t.indexOf(""auto""))return t;var a=et(n,i,r,o),s={top:{width:a.width,height:e.top-a.top},right:{width:a.right-e.right,height:a.height},bottom:{width:a.width,height:a.bottom-e.bottom},left:{width:e.left-a.left,height:a.height}},l=Object.keys(s).map((function(t){return X({key:t},s[t],{area:nt(s[t])})})).sort((function(t,e){return e.area-t.area})),u=l.filter((function(t){var e=t.width,i=t.height;return e>=n.clientWidth&&i>=n.clientHeight})),f=u.length>0?u[0].key:l[0].key,d=t.split(""-"")[1];return f+(d?""-""+d:"""")}function ot(t,e,n){var i=arguments.length>3&&void 0!==arguments[3]?arguments[3]:null,o=i?tt(e):M(e,j(n));return $(n,o,i)}function rt(t){var e=t.ownerDocument.defaultView.getComputedStyle(t),n=parseFloat(e.marginTop||0)+parseFloat(e.marginBottom||0),i=parseFloat(e.marginLeft||0)+parseFloat(e.marginRight||0);return{width:t.offsetWidth+i,height:t.offsetHeight+n}}function at(t){var e={left:""right"",right:""left"",bottom:""top"",top:""bottom""};return t.replace(/left|right|bottom|top/g,(function(t){return e[t]}))}function st(t,e,n){n=n.split(""-"")[0];var i=rt(t),o={width:i.width,height:i.height},r=-1!==[""right"",""left""].indexOf(n),a=r?""top"":""left"",s=r?""left"":""top"",l=r?""height"":""width"",u=r?""width"":""height"";return o[a]=e[a]+e[l]/2-i[l]/2,o[s]=n===s?e[s]-i[u]:e[at(s)],o}function lt(t,e){return Array.prototype.find?t.find(e):t.filter(e)[0]}function ut(t,e,n){return(void 0===n?t:t.slice(0,function(t,e,n){if(Array.prototype.findIndex)return t.findIndex((function(t){return t[e]===n}));var i=lt(t,(function(t){return t[e]===n}));return t.indexOf(i)}(t,""name"",n))).forEach((function(t){t.function&&console.warn(""`modifier.function` is deprecated, use `modifier.fn`!"");var n=t.function||t.fn;t.enabled&&A(n)&&(e.offsets.popper=K(e.offsets.popper),e.offsets.reference=K(e.offsets.reference),e=n(e,t))})),e}function ft(){if(!this.state.isDestroyed){var t={instance:this,styles:{},arrowStyles:{},attributes:{},flipped:!1,offsets:{}};t.offsets.reference=ot(this.state,this.popper,this.reference,this.options.positionFixed),t.placement=it(this.options.placement,t.offsets.reference,this.popper,this.reference,this.options.modifiers.flip.boundariesElement,this.options.modifiers.flip.padding),t.originalPlacement=t.placement,t.positionFixed=this.options.positionFixed,t.offsets.popper=st(this.popper,t.offsets.reference,t.placement),t.offsets.popper.position=this.options.positionFixed?""fixed"":""absolute"",t=ut(this.modifiers,t),this.state.isCreated?this.options.onUpdate(t):(this.state.isCreated=!0,this.options.onCreate(t))}}function dt(t,e){return t.some((function(t){var n=t.name;return t.enabled&&n===e}))}function ct(t){for(var e=[!1,""ms"",""Webkit"",""Moz"",""O""],n=t.charAt(0).toUpperCase()+t.slice(1),i=0;i<e.length;i++){var o=e[i],r=o?""""+o+n:t;if(""undefined""!=typeof document.body.style[r])return r}return null}function ht(){return this.state.isDestroyed=!0,dt(this.modifiers,""applyStyle"")&&(this.popper.removeAttribute(""x-placement""),this.popper.style.position="""",this.popper.style.top="""",this.popper.style.left="""",this.popper.style.right="""",this.popper.style.bottom="""",this.popper.style.willChange="""",this.popper.style[ct(""transform"")]=""""),this.disableEventListeners(),this.options.removeOnDestroy&&this.popper.parentNode.removeChild(this.popper),this}function pt(t){var e=t.ownerDocument;return e?e.defaultView:window}function mt(t,e,n,i){n.updateBound=i,pt(t).addEventListener(""resize"",n.updateBound,{passive:!0});var o=x(t);return function t(e,n,i,o){var r=""BODY""===e.nodeName,a=r?e.ownerDocument.defaultView:e;a.addEventListener(n,i,{passive:!0}),r||t(x(a.parentNode),n,i,o),o.push(a)}(o,""scroll"",n.updateBound,n.scrollParents),n.scrollElement=o,n.eventsEnabled=!0,n}function gt(){this.state.eventsEnabled||(this.state=mt(this.reference,this.options,this.state,this.scheduleUpdate))}function vt(){var t,e;this.state.eventsEnabled&&(cancelAnimationFrame(this.scheduleUpdate),this.state=(t=this.reference,e=this.state,pt(t).removeEventListener(""resize"",e.updateBound),e.scrollParents.forEach((function(t){t.removeEventListener(""scroll"",e.updateBound)})),e.updateBound=null,e.scrollParents=[],e.scrollElement=null,e.eventsEnabled=!1,e))}function _t(t){return""""!==t&&!isNaN(parseFloat(t))&&isFinite(t)}function bt(t,e){Object.keys(e).forEach((function(n){var i="""";-1!==[""width"",""height"",""top"",""right"",""bottom"",""left""].indexOf(n)&&_t(e[n])&&(i=""px""),t.style[n]=e[n]+i}))}var yt=N&&/Firefox/i.test(navigator.userAgent);function wt(t,e,n){var i=lt(t,(function(t){return t.name===e})),o=!!i&&t.some((function(t){return t.name===n&&t.enabled&&t.order<i.order}));if(!o){var r=""`""+e+""`"",a=""`""+n+""`"";console.warn(a+"" modifier is required by ""+r+"" modifier in order to work, be sure to include it before ""+r+""!"")}return o}var Et=[""auto-start"",""auto"",""auto-end"",""top-start"",""top"",""top-end"",""right-start"",""right"",""right-end"",""bottom-end"",""bottom"",""bottom-start"",""left-end"",""left"",""left-start""],Tt=Et.slice(3);function Ct(t){var e=arguments.length>1&&void 0!==arguments[1]&&arguments[1],n=Tt.indexOf(t),i=Tt.slice(n+1).concat(Tt.slice(0,n));return e?i.reverse():i}var St=""flip"",Nt=""clockwise"",Dt=""counterclockwise"";function kt(t,e,n,i){var o=[0,0],r=-1!==[""right"",""left""].indexOf(i),a=t.split(/(\+|\-)/).map((function(t){return t.trim()})),s=a.indexOf(lt(a,(function(t){return-1!==t.search(/,|\s/)})));a[s]&&-1===a[s].indexOf("","")&&console.warn(""Offsets separated by white space(s) are deprecated, use a comma (,) instead."");var l=/\s*,\s*|\s+/,u=-1!==s?[a.slice(0,s).concat([a[s].split(l)[0]]),[a[s].split(l)[1]].concat(a.slice(s+1))]:[a];return(u=u.map((function(t,i){var o=(1===i?!r:r)?""height"":""width"",a=!1;return t.reduce((function(t,e){return""""===t[t.length-1]&&-1!==[""+"",""-""].indexOf(e)?(t[t.length-1]=e,a=!0,t):a?(t[t.length-1]+=e,a=!1,t):t.concat(e)}),[]).map((function(t){return function(t,e,n,i){var o=t.match(/((?:\-|\+)?\d*\.?\d*)(.*)/),r=+o[1],a=o[2];if(!r)return t;if(0===a.indexOf(""%"")){var s=void 0;switch(a){case""%p"":s=n;break;case""%"":case""%r"":default:s=i}return K(s)[e]/100*r}if(""vh""===a||""vw""===a)return(""vh""===a?Math.max(document.documentElement.clientHeight,window.innerHeight||0):Math.max(document.documentElement.clientWidth,window.innerWidth||0))/100*r;return r}(t,o,e,n)}))}))).forEach((function(t,e){t.forEach((function(n,i){_t(n)&&(o[e]+=n*(""-""===t[i-1]?-1:1))}))})),o}var At={placement:""bottom"",positionFixed:!1,eventsEnabled:!0,removeOnDestroy:!1,onCreate:function(){},onUpdate:function(){},modifiers:{shift:{order:100,enabled:!0,fn:function(t){var e=t.placement,n=e.split(""-"")[0],i=e.split(""-"")[1];if(i){var o=t.offsets,r=o.reference,a=o.popper,s=-1!==[""bottom"",""top""].indexOf(n),l=s?""left"":""top"",u=s?""width"":""height"",f={start:z({},l,r[l]),end:z({},l,r[l]+r[u]-a[u])};t.offsets.popper=X({},a,f[i])}return t}},offset:{order:200,enabled:!0,fn:function(t,e){var n=e.offset,i=t.placement,o=t.offsets,r=o.popper,a=o.reference,s=i.split(""-"")[0],l=void 0;return l=_t(+n)?[+n,0]:kt(n,r,a,s),""left""===s?(r.top+=l[0],r.left-=l[1]):""right""===s?(r.top+=l[0],r.left+=l[1]):""top""===s?(r.left+=l[0],r.top-=l[1]):""bottom""===s&&(r.left+=l[0],r.top+=l[1]),t.popper=r,t},offset:0},preventOverflow:{order:300,enabled:!0,fn:function(t,e){var n=e.boundariesElement||R(t.instance.popper);t.instance.reference===n&&(n=R(n));var i=ct(""transform""),o=t.instance.popper.style,r=o.top,a=o.left,s=o[i];o.top="""",o.left="""",o[i]="""";var l=et(t.instance.popper,t.instance.reference,e.padding,n,t.positionFixed);o.top=r,o.left=a,o[i]=s,e.boundaries=l;var u=e.priority,f=t.offsets.popper,d={primary:function(t){var n=f[t];return f[t]<l[t]&&!e.escapeWithReference&&(n=Math.max(f[t],l[t])),z({},t,n)},secondary:function(t){var n=""right""===t?""left"":""top"",i=f[n];return f[t]>l[t]&&!e.escapeWithReference&&(i=Math.min(f[n],l[t]-(""right""===t?f.width:f.height))),z({},n,i)}};return u.forEach((function(t){var e=-1!==[""left"",""top""].indexOf(t)?""primary"":""secondary"";f=X({},f,d[e](t))})),t.offsets.popper=f,t},priority:[""left"",""right"",""top"",""bottom""],padding:5,boundariesElement:""scrollParent""},keepTogether:{order:400,enabled:!0,fn:function(t){var e=t.offsets,n=e.popper,i=e.reference,o=t.placement.split(""-"")[0],r=Math.floor,a=-1!==[""top"",""bottom""].indexOf(o),s=a?""right"":""bottom"",l=a?""left"":""top"",u=a?""width"":""height"";return n[s]<r(i[l])&&(t.offsets.popper[l]=r(i[l])-n[u]),n[l]>r(i[s])&&(t.offsets.popper[l]=r(i[s])),t}},arrow:{order:500,enabled:!0,fn:function(t,e){var n;if(!wt(t.instance.modifiers,""arrow"",""keepTogether""))return t;var i=e.element;if(""string""==typeof i){if(!(i=t.instance.popper.querySelector(i)))return t}else if(!t.instance.popper.contains(i))return console.warn(""WARNING: `arrow.element` must be child of its popper element!""),t;var o=t.placement.split(""-"")[0],r=t.offsets,a=r.popper,s=r.reference,l=-1!==[""left"",""right""].indexOf(o),u=l?""height"":""width"",f=l?""Top"":""Left"",d=f.toLowerCase(),c=l?""left"":""top"",h=l?""bottom"":""right"",p=rt(i)[u];s[h]-p<a[d]&&(t.offsets.popper[d]-=a[d]-(s[h]-p)),s[d]+p>a[h]&&(t.offsets.popper[d]+=s[d]+p-a[h]),t.offsets.popper=K(t.offsets.popper);var m=s[d]+s[u]/2-p/2,g=I(t.instance.popper),v=parseFloat(g[""margin""+f]),_=parseFloat(g[""border""+f+""Width""]),b=m-t.offsets.popper[d]-v-_;return b=Math.max(Math.min(a[u]-p,b),0),t.arrowElement=i,t.offsets.arrow=(z(n={},d,Math.round(b)),z(n,c,""""),n),t},element:""[x-arrow]""},flip:{order:600,enabled:!0,fn:function(t,e){if(dt(t.instance.modifiers,""inner""))return t;if(t.flipped&&t.placement===t.originalPlacement)return t;var n=et(t.instance.popper,t.instance.reference,e.padding,e.boundariesElement,t.positionFixed),i=t.placement.split(""-"")[0],o=at(i),r=t.placement.split(""-"")[1]||"""",a=[];switch(e.behavior){case St:a=[i,o];break;case Nt:a=Ct(i);break;case Dt:a=Ct(i,!0);break;default:a=e.behavior}return a.forEach((function(s,l){if(i!==s||a.length===l+1)return t;i=t.placement.split(""-"")[0],o=at(i);var u=t.offsets.popper,f=t.offsets.reference,d=Math.floor,c=""left""===i&&d(u.right)>d(f.left)||""right""===i&&d(u.left)<d(f.right)||""top""===i&&d(u.bottom)>d(f.top)||""bottom""===i&&d(u.top)<d(f.bottom),h=d(u.left)<d(n.left),p=d(u.right)>d(n.right),m=d(u.top)<d(n.top),g=d(u.bottom)>d(n.bottom),v=""left""===i&&h||""right""===i&&p||""top""===i&&m||""bottom""===i&&g,_=-1!==[""top"",""bottom""].indexOf(i),b=!!e.flipVariations&&(_&&""start""===r&&h||_&&""end""===r&&p||!_&&""start""===r&&m||!_&&""end""===r&&g),y=!!e.flipVariationsByContent&&(_&&""start""===r&&p||_&&""end""===r&&h||!_&&""start""===r&&g||!_&&""end""===r&&m),w=b||y;(c||v||w)&&(t.flipped=!0,(c||v)&&(i=a[l+1]),w&&(r=function(t){return""end""===t?""start"":""start""===t?""end"":t}(r)),t.placement=i+(r?""-""+r:""""),t.offsets.popper=X({},t.offsets.popper,st(t.instance.popper,t.offsets.reference,t.placement)),t=ut(t.instance.modifiers,t,""flip""))})),t},behavior:""flip"",padding:5,boundariesElement:""viewport"",flipVariations:!1,flipVariationsByContent:!1},inner:{order:700,enabled:!1,fn:function(t){var e=t.placement,n=e.split(""-"")[0],i=t.offsets,o=i.popper,r=i.reference,a=-1!==[""left"",""right""].indexOf(n),s=-1===[""top"",""left""].indexOf(n);return o[a?""left"":""top""]=r[n]-(s?o[a?""width"":""height""]:0),t.placement=at(e),t.offsets.popper=K(o),t}},hide:{order:800,enabled:!0,fn:function(t){if(!wt(t.instance.modifiers,""hide"",""preventOverflow""))return t;var e=t.offsets.reference,n=lt(t.instance.modifiers,(function(t){return""preventOverflow""===t.name})).boundaries;if(e.bottom<n.top||e.left>n.right||e.top>n.bottom||e.right<n.left){if(!0===t.hide)return t;t.hide=!0,t.attributes[""x-out-of-boundaries""]=""""}else{if(!1===t.hide)return t;t.hide=!1,t.attributes[""x-out-of-boundaries""]=!1}return t}},computeStyle:{order:850,enabled:!0,fn:function(t,e){var n=e.x,i=e.y,o=t.offsets.popper,r=lt(t.instance.modifiers,(function(t){return""applyStyle""===t.name})).gpuAcceleration;void 0!==r&&console.warn(""WARNING: `gpuAcceleration` option moved to `computeStyle` modifier and will not be supported in future versions of Popper.js!"");var a=void 0!==r?r:e.gpuAcceleration,s=R(t.instance.popper),l=G(s),u={position:o.position},f=function(t,e){var n=t.offsets,i=n.popper,o=n.reference,r=Math.round,a=Math.floor,s=function(t){return t},l=r(o.width),u=r(i.width),f=-1!==[""left"",""right""].indexOf(t.placement),d=-1!==t.placement.indexOf(""-""),c=e?f||d||l%2==u%2?r:a:s,h=e?r:s;return{left:c(l%2==1&&u%2==1&&!d&&e?i.left-1:i.left),top:h(i.top),bottom:h(i.bottom),right:c(i.right)}}(t,window.devicePixelRatio<2||!yt),d=""bottom""===n?""top"":""bottom"",c=""right""===i?""left"":""right"",h=ct(""transform""),p=void 0,m=void 0;if(m=""bottom""===d?""HTML""===s.nodeName?-s.clientHeight+f.bottom:-l.height+f.bottom:f.top,p=""right""===c?""HTML""===s.nodeName?-s.clientWidth+f.right:-l.width+f.right:f.left,a&&h)u[h]=""translate3d(""+p+""px, ""+m+""px, 0)"",u[d]=0,u[c]=0,u.willChange=""transform"";else{var g=""bottom""===d?-1:1,v=""right""===c?-1:1;u[d]=m*g,u[c]=p*v,u.willChange=d+"", ""+c}var _={""x-placement"":t.placement};return t.attributes=X({},_,t.attributes),t.styles=X({},u,t.styles),t.arrowStyles=X({},t.offsets.arrow,t.arrowStyles),t},gpuAcceleration:!0,x:""bottom"",y:""right""},applyStyle:{order:900,enabled:!0,fn:function(t){var e,n;return bt(t.instance.popper,t.styles),e=t.instance.popper,n=t.attributes,Object.keys(n).forEach((function(t){!1!==n[t]?e.setAttribute(t,n[t]):e.removeAttribute(t)})),t.arrowElement&&Object.keys(t.arrowStyles).length&&bt(t.arrowElement,t.arrowStyles),t},onLoad:function(t,e,n,i,o){var r=ot(o,e,t,n.positionFixed),a=it(n.placement,r,e,t,n.modifiers.flip.boundariesElement,n.modifiers.flip.padding);return e.setAttribute(""x-placement"",a),bt(e,{position:n.positionFixed?""fixed"":""absolute""}),n},gpuAcceleration:void 0}}},It=function(){function t(e,n){var i=this,o=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{};V(this,t),this.scheduleUpdate=function(){return requestAnimationFrame(i.update)},this.update=k(this.update.bind(this)),this.options=X({},t.Defaults,o),this.state={isDestroyed:!1,isCreated:!1,scrollParents:[]},this.reference=e&&e.jquery?e[0]:e,this.popper=n&&n.jquery?n[0]:n,this.options.modifiers={},Object.keys(X({},t.Defaults.modifiers,o.modifiers)).forEach((function(e){i.options.modifiers[e]=X({},t.Defaults.modifiers[e]||{},o.modifiers?o.modifiers[e]:{})})),this.modifiers=Object.keys(this.options.modifiers).map((function(t){return X({name:t},i.options.modifiers[t])})).sort((function(t,e){return t.order-e.order})),this.modifiers.forEach((function(t){t.enabled&&A(t.onLoad)&&t.onLoad(i.reference,i.popper,i.options,t,i.state)})),this.update();var r=this.options.eventsEnabled;r&&this.enableEventListeners(),this.state.eventsEnabled=r}return Y(t,[{key:""update"",value:function(){return ft.call(this)}},{key:""destroy"",value:function(){return ht.call(this)}},{key:""enableEventListeners"",value:function(){return gt.call(this)}},{key:""disableEventListeners"",value:function(){return vt.call(this)}}]),t}();It.Utils=(""undefined""!=typeof window?window:global).PopperUtils,It.placements=Et,It.Defaults=At;var Ot=""dropdown"",xt=i.default.fn[Ot],jt=new RegExp(""38|40|27""),Lt={offset:0,flip:!0,boundary:""scrollParent"",reference:""toggle"",display:""dynamic"",popperConfig:null},Pt={offset:""(number|string|function)"",flip:""boolean"",boundary:""(string|element)"",reference:""(string|element)"",display:""string"",popperConfig:""(null|object)""},Ft=function(){function t(t,e){this._element=t,this._popper=null,this._config=this._getConfig(e),this._menu=this._getMenuElement(),this._inNavbar=this._detectNavbar(),this._addEventListeners()}var e=t.prototype;return e.toggle=function(){if(!this._element.disabled&&!i.default(this._element).hasClass(""disabled"")){var e=i.default(this._menu).hasClass(""show"");t._clearMenus(),e||this.show(!0)}},e.show=function(e){if(void 0===e&&(e=!1),!(this._element.disabled||i.default(this._element).hasClass(""disabled"")||i.default(this._menu).hasClass(""show""))){var n={relatedTarget:this._element},o=i.default.Event(""show.bs.dropdown"",n),r=t._getParentFromElement(this._element);if(i.default(r).trigger(o),!o.isDefaultPrevented()){if(!this._inNavbar&&e){if(""undefined""==typeof It)throw new TypeError(""Bootstrap's dropdowns require Popper (https://popper.js.org)"");var a=this._element;""parent""===this._config.reference?a=r:l.isElement(this._config.reference)&&(a=this._config.reference,""undefined""!=typeof this._config.reference.jquery&&(a=this._config.reference[0])),""scrollParent""!==this._config.boundary&&i.default(r).addClass(""position-static""),this._popper=new It(a,this._menu,this._getPopperConfig())}""ontouchstart""in document.documentElement&&0===i.default(r).closest("".navbar-nav"").length&&i.default(document.body).children().on(""mouseover"",null,i.default.noop),this._element.focus(),this._element.setAttribute(""aria-expanded"",!0),i.default(this._menu).toggleClass(""show""),i.default(r).toggleClass(""show"").trigger(i.default.Event(""shown.bs.dropdown"",n))}}},e.hide=function(){if(!this._element.disabled&&!i.default(this._element).hasClass(""disabled"")&&i.default(this._menu).hasClass(""show"")){var e={relatedTarget:this._element},n=i.default.Event(""hide.bs.dropdown"",e),o=t._getParentFromElement(this._element);i.default(o).trigger(n),n.isDefaultPrevented()||(this._popper&&this._popper.destroy(),i.default(this._menu).toggleClass(""show""),i.default(o).toggleClass(""show"").trigger(i.default.Event(""hidden.bs.dropdown"",e)))}},e.dispose=function(){i.default.removeData(this._element,""bs.dropdown""),i.default(this._element).off("".bs.dropdown""),this._element=null,this._menu=null,null!==this._popper&&(this._popper.destroy(),this._popper=null)},e.update=function(){this._inNavbar=this._detectNavbar(),null!==this._popper&&this._popper.scheduleUpdate()},e._addEventListeners=function(){var t=this;i.default(this._element).on(""click.bs.dropdown"",(function(e){e.preventDefault(),e.stopPropagation(),t.toggle()}))},e._getConfig=function(t){return t=a({},this.constructor.Default,i.default(this._element).data(),t),l.typeCheckConfig(Ot,t,this.constructor.DefaultType),t},e._getMenuElement=function(){if(!this._menu){var e=t._getParentFromElement(this._element);e&&(this._menu=e.querySelector("".dropdown-menu""))}return this._menu},e._getPlacement=function(){var t=i.default(this._element.parentNode),e=""bottom-start"";return t.hasClass(""dropup"")?e=i.default(this._menu).hasClass(""dropdown-menu-right"")?""top-end"":""top-start"":t.hasClass(""dropright"")?e=""right-start"":t.hasClass(""dropleft"")?e=""left-start"":i.default(this._menu).hasClass(""dropdown-menu-right"")&&(e=""bottom-end""),e},e._detectNavbar=function(){return i.default(this._element).closest("".navbar"").length>0},e._getOffset=function(){var t=this,e={};return""function""==typeof this._config.offset?e.fn=function(e){return e.offsets=a({},e.offsets,t._config.offset(e.offsets,t._element)||{}),e}:e.offset=this._config.offset,e},e._getPopperConfig=function(){var t={placement:this._getPlacement(),modifiers:{offset:this._getOffset(),flip:{enabled:this._config.flip},preventOverflow:{boundariesElement:this._config.boundary}}};return""static""===this._config.display&&(t.modifiers.applyStyle={enabled:!1}),a({},t,this._config.popperConfig)},t._jQueryInterface=function(e){return this.each((function(){var n=i.default(this).data(""bs.dropdown"");if(n||(n=new t(this,""object""==typeof e?e:null),i.default(this).data(""bs.dropdown"",n)),""string""==typeof e){if(""undefined""==typeof n[e])throw new TypeError('No method named ""'+e+'""');n[e]()}}))},t._clearMenus=function(e){if(!e||3!==e.which&&(""keyup""!==e.type||9===e.which))for(var n=[].slice.call(document.querySelectorAll('[data-toggle=""dropdown""]')),o=0,r=n.length;o<r;o++){var a=t._getParentFromElement(n[o]),s=i.default(n[o]).data(""bs.dropdown""),l={relatedTarget:n[o]};if(e&&""click""===e.type&&(l.clickEvent=e),s){var u=s._menu;if(i.default(a).hasClass(""show"")&&!(e&&(""click""===e.type&&/input|textarea/i.test(e.target.tagName)||""keyup""===e.type&&9===e.which)&&i.default.contains(a,e.target))){var f=i.default.Event(""hide.bs.dropdown"",l);i.default(a).trigger(f),f.isDefaultPrevented()||(""ontouchstart""in document.documentElement&&i.default(document.body).children().off(""mouseover"",null,i.default.noop),n[o].setAttribute(""aria-expanded"",""false""),s._popper&&s._popper.destroy(),i.default(u).removeClass(""show""),i.default(a).removeClass(""show"").trigger(i.default.Event(""hidden.bs.dropdown"",l)))}}}},t._getParentFromElement=function(t){var e,n=l.getSelectorFromElement(t);return n&&(e=document.querySelector(n)),e||t.parentNode},t._dataApiKeydownHandler=function(e){if(!(/input|textarea/i.test(e.target.tagName)?32===e.which||27!==e.which&&(40!==e.which&&38!==e.which||i.default(e.target).closest("".dropdown-menu"").length):!jt.test(e.which))&&!this.disabled&&!i.default(this).hasClass(""disabled"")){var n=t._getParentFromElement(this),o=i.default(n).hasClass(""show"");if(o||27!==e.which){if(e.preventDefault(),e.stopPropagation(),!o||27===e.which||32===e.which)return 27===e.which&&i.default(n.querySelector('[data-toggle=""dropdown""]')).trigger(""focus""),void i.default(this).trigger(""click"");var r=[].slice.call(n.querySelectorAll("".dropdown-menu .dropdown-item:not(.disabled):not(:disabled)"")).filter((function(t){return i.default(t).is("":visible"")}));if(0!==r.length){var a=r.indexOf(e.target);38===e.which&&a>0&&a--,40===e.which&&a<r.length-1&&a++,a<0&&(a=0),r[a].focus()}}}},r(t,null,[{key:""VERSION"",get:function(){return""4.6.0""}},{key:""Default"",get:function(){return Lt}},{key:""DefaultType"",get:function(){return Pt}}]),t}();i.default(document).on(""keydown.bs.dropdown.data-api"",'[data-toggle=""dropdown""]',Ft._dataApiKeydownHandler).on(""keydown.bs.dropdown.data-api"","".dropdown-menu"",Ft._dataApiKeydownHandler).on(""click.bs.dropdown.data-api keyup.bs.dropdown.data-api"",Ft._clearMenus).on(""click.bs.dropdown.data-api"",'[data-toggle=""dropdown""]',(function(t){t.preventDefault(),t.stopPropagation(),Ft._jQueryInterface.call(i.default(this),""toggle"")})).on(""click.bs.dropdown.data-api"","".dropdown form"",(function(t){t.stopPropagation()})),i.default.fn[Ot]=Ft._jQueryInterface,i.default.fn[Ot].Constructor=Ft,i.default.fn[Ot].noConflict=function(){return i.default.fn[Ot]=xt,Ft._jQueryInterface};var Rt=i.default.fn.modal,Ht={backdrop:!0,keyboard:!0,focus:!0,show:!0},Mt={backdrop:""(boolean|string)"",keyboard:""boolean"",focus:""boolean"",show:""boolean""},qt=function(){function t(t,e){this._config=this._getConfig(e),this._element=t,this._dialog=t.querySelector("".modal-dialog""),this._backdrop=null,this._isShown=!1,this._isBodyOverflowing=!1,this._ignoreBackdropClick=!1,this._isTransitioning=!1,this._scrollbarWidth=0}var e=t.prototype;return e.toggle=function(t){return this._isShown?this.hide():this.show(t)},e.show=function(t){var e=this;if(!this._isShown&&!this._isTransitioning){i.default(this._element).hasClass(""fade"")&&(this._isTransitioning=!0);var n=i.default.Event(""show.bs.modal"",{relatedTarget:t});i.default(this._element).trigger(n),this._isShown||n.isDefaultPrevented()||(this._isShown=!0,this._checkScrollbar(),this._setScrollbar(),this._adjustDialog(),this._setEscapeEvent(),this._setResizeEvent(),i.default(this._element).on(""click.dismiss.bs.modal"",'[data-dismiss=""modal""]',(function(t){return e.hide(t)})),i.default(this._dialog).on(""mousedown.dismiss.bs.modal"",(function(){i.default(e._element).one(""mouseup.dismiss.bs.modal"",(function(t){i.default(t.target).is(e._element)&&(e._ignoreBackdropClick=!0)}))})),this._showBackdrop((function(){return e._showElement(t)})))}},e.hide=function(t){var e=this;if(t&&t.preventDefault(),this._isShown&&!this._isTransitioning){var n=i.default.Event(""hide.bs.modal"");if(i.default(this._element).trigger(n),this._isShown&&!n.isDefaultPrevented()){this._isShown=!1;var o=i.default(this._element).hasClass(""fade"");if(o&&(this._isTransitioning=!0),this._setEscapeEvent(),this._setResizeEvent(),i.default(document).off(""focusin.bs.modal""),i.default(this._element).removeClass(""show""),i.default(this._element).off(""click.dismiss.bs.modal""),i.default(this._dialog).off(""mousedown.dismiss.bs.modal""),o){var r=l.getTransitionDurationFromElement(this._element);i.default(this._element).one(l.TRANSITION_END,(function(t){return e._hideModal(t)})).emulateTransitionEnd(r)}else this._hideModal()}}},e.dispose=function(){[window,this._element,this._dialog].forEach((function(t){return i.default(t).off("".bs.modal"")})),i.default(document).off(""focusin.bs.modal""),i.default.removeData(this._element,""bs.modal""),this._config=null,this._element=null,this._dialog=null,this._backdrop=null,this._isShown=null,this._isBodyOverflowing=null,this._ignoreBackdropClick=null,this._isTransitioning=null,this._scrollbarWidth=null},e.handleUpdate=function(){this._adjustDialog()},e._getConfig=function(t){return t=a({},Ht,t),l.typeCheckConfig(""modal"",t,Mt),t},e._triggerBackdropTransition=function(){var t=this,e=i.default.Event(""hidePrevented.bs.modal"");if(i.default(this._element).trigger(e),!e.isDefaultPrevented()){var n=this._element.scrollHeight>document.documentElement.clientHeight;n||(this._element.style.overflowY=""hidden""),this._element.classList.add(""modal-static"");var o=l.getTransitionDurationFromElement(this._dialog);i.default(this._element).off(l.TRANSITION_END),i.default(this._element).one(l.TRANSITION_END,(function(){t._element.classList.remove(""modal-static""),n||i.default(t._element).one(l.TRANSITION_END,(function(){t._element.style.overflowY=""""})).emulateTransitionEnd(t._element,o)})).emulateTransitionEnd(o),this._element.focus()}},e._showElement=function(t){var e=this,n=i.default(this._element).hasClass(""fade""),o=this._dialog?this._dialog.querySelector("".modal-body""):null;this._element.parentNode&&this._element.parentNode.nodeType===Node.ELEMENT_NODE||document.body.appendChild(this._element),this._element.style.display=""block"",this._element.removeAttribute(""aria-hidden""),this._element.setAttribute(""aria-modal"",!0),this._element.setAttribute(""role"",""dialog""),i.default(this._dialog).hasClass(""modal-dialog-scrollable"")&&o?o.scrollTop=0:this._element.scrollTop=0,n&&l.reflow(this._element),i.default(this._element).addClass(""show""),this._config.focus&&this._enforceFocus();var r=i.default.Event(""shown.bs.modal"",{relatedTarget:t}),a=function(){e._config.focus&&e._element.focus(),e._isTransitioning=!1,i.default(e._element).trigger(r)};if(n){var s=l.getTransitionDurationFromElement(this._dialog);i.default(this._dialog).one(l.TRANSITION_END,a).emulateTransitionEnd(s)}else a()},e._enforceFocus=function(){var t=this;i.default(document).off(""focusin.bs.modal"").on(""focusin.bs.modal"",(function(e){document!==e.target&&t._element!==e.target&&0===i.default(t._element).has(e.target).length&&t._element.focus()}))},e._setEscapeEvent=function(){var t=this;this._isShown?i.default(this._element).on(""keydown.dismiss.bs.modal"",(function(e){t._config.keyboard&&27===e.which?(e.preventDefault(),t.hide()):t._config.keyboard||27!==e.which||t._triggerBackdropTransition()})):this._isShown||i.default(this._element).off(""keydown.dismiss.bs.modal"")},e._setResizeEvent=function(){var t=this;this._isShown?i.default(window).on(""resize.bs.modal"",(function(e){return t.handleUpdate(e)})):i.default(window).off(""resize.bs.modal"")},e._hideModal=function(){var t=this;this._element.style.display=""none"",this._element.setAttribute(""aria-hidden"",!0),this._element.removeAttribute(""aria-modal""),this._element.removeAttribute(""role""),this._isTransitioning=!1,this._showBackdrop((function(){i.default(document.body).removeClass(""modal-open""),t._resetAdjustments(),t._resetScrollbar(),i.default(t._element).trigger(""hidden.bs.modal"")}))},e._removeBackdrop=function(){this._backdrop&&(i.default(this._backdrop).remove(),this._backdrop=null)},e._showBackdrop=function(t){var e=this,n=i.default(this._element).hasClass(""fade"")?""fade"":"""";if(this._isShown&&this._config.backdrop){if(this._backdrop=document.createElement(""div""),this._backdrop.className=""modal-backdrop"",n&&this._backdrop.classList.add(n),i.default(this._backdrop).appendTo(document.body),i.default(this._element).on(""click.dismiss.bs.modal"",(function(t){e._ignoreBackdropClick?e._ignoreBackdropClick=!1:t.target===t.currentTarget&&(""static""===e._config.backdrop?e._triggerBackdropTransition():e.hide())})),n&&l.reflow(this._backdrop),i.default(this._backdrop).addClass(""show""),!t)return;if(!n)return void t();var o=l.getTransitionDurationFromElement(this._backdrop);i.default(this._backdrop).one(l.TRANSITION_END,t).emulateTransitionEnd(o)}else if(!this._isShown&&this._backdrop){i.default(this._backdrop).removeClass(""show"");var r=function(){e._removeBackdrop(),t&&t()};if(i.default(this._element).hasClass(""fade"")){var a=l.getTransitionDurationFromElement(this._backdrop);i.default(this._backdrop).one(l.TRANSITION_END,r).emulateTransitionEnd(a)}else r()}else t&&t()},e._adjustDialog=function(){var t=this._element.scrollHeight>document.documentElement.clientHeight;!this._isBodyOverflowing&&t&&(this._element.style.paddingLeft=this._scrollbarWidth+""px""),this._isBodyOverflowing&&!t&&(this._element.style.paddingRight=this._scrollbarWidth+""px"")},e._resetAdjustments=function(){this._element.style.paddingLeft="""",this._element.style.paddingRight=""""},e._checkScrollbar=function(){var t=document.body.getBoundingClientRect();this._isBodyOverflowing=Math.round(t.left+t.right)<window.innerWidth,this._scrollbarWidth=this._getScrollbarWidth()},e._setScrollbar=function(){var t=this;if(this._isBodyOverflowing){var e=[].slice.call(document.querySelectorAll("".fixed-top, .fixed-bottom, .is-fixed, .sticky-top"")),n=[].slice.call(document.querySelectorAll("".sticky-top""));i.default(e).each((function(e,n){var o=n.style.paddingRight,r=i.default(n).css(""padding-right"");i.default(n).data(""padding-right"",o).css(""padding-right"",parseFloat(r)+t._scrollbarWidth+""px"")})),i.default(n).each((function(e,n){var o=n.style.marginRight,r=i.default(n).css(""margin-right"");i.default(n).data(""margin-right"",o).css(""margin-right"",parseFloat(r)-t._scrollbarWidth+""px"")}));var o=document.body.style.paddingRight,r=i.default(document.body).css(""padding-right"");i.default(document.body).data(""padding-right"",o).css(""padding-right"",parseFloat(r)+this._scrollbarWidth+""px"")}i.default(document.body).addClass(""modal-open"")},e._resetScrollbar=function(){var t=[].slice.call(document.querySelectorAll("".fixed-top, .fixed-bottom, .is-fixed, .sticky-top""));i.default(t).each((function(t,e){var n=i.default(e).data(""padding-right"");i.default(e).removeData(""padding-right""),e.style.paddingRight=n||""""}));var e=[].slice.call(document.querySelectorAll("".sticky-top""));i.default(e).each((function(t,e){var n=i.default(e).data(""margin-right"");""undefined""!=typeof n&&i.default(e).css(""margin-right"",n).removeData(""margin-right"")}));var n=i.default(document.body).data(""padding-right"");i.default(document.body).removeData(""padding-right""),document.body.style.paddingRight=n||""""},e._getScrollbarWidth=function(){var t=document.createElement(""div"");t.className=""modal-scrollbar-measure"",document.body.appendChild(t);var e=t.getBoundingClientRect().width-t.clientWidth;return document.body.removeChild(t),e},t._jQueryInterface=function(e,n){return this.each((function(){var o=i.default(this).data(""bs.modal""),r=a({},Ht,i.default(this).data(),""object""==typeof e&&e?e:{});if(o||(o=new t(this,r),i.default(this).data(""bs.modal"",o)),""string""==typeof e){if(""undefined""==typeof o[e])throw new TypeError('No method named ""'+e+'""');o[e](n)}else r.show&&o.show(n)}))},r(t,null,[{key:""VERSION"",get:function(){return""4.6.0""}},{key:""Default"",get:function(){return Ht}}]),t}();i.default(document).on(""click.bs.modal.data-api"",'[data-toggle=""modal""]',(function(t){var e,n=this,o=l.getSelectorFromElement(this);o&&(e=document.querySelector(o));var r=i.default(e).data(""bs.modal"")?""toggle"":a({},i.default(e).data(),i.default(this).data());""A""!==this.tagName&&""AREA""!==this.tagName||t.preventDefault();var s=i.default(e).one(""show.bs.modal"",(function(t){t.isDefaultPrevented()||s.one(""hidden.bs.modal"",(function(){i.default(n).is("":visible"")&&n.focus()}))}));qt._jQueryInterface.call(i.default(e),r,this)})),i.default.fn.modal=qt._jQueryInterface,i.default.fn.modal.Constructor=qt,i.default.fn.modal.noConflict=function(){return i.default.fn.modal=Rt,qt._jQueryInterface};var Bt=[""background"",""cite"",""href"",""itemtype"",""longdesc"",""poster"",""src"",""xlink:href""],Qt={""*"":[""class"",""dir"",""id"",""lang"",""role"",/^aria-[\w-]*$/i],a:[""target"",""href"",""title"",""rel""],area:[],b:[],br:[],col:[],code:[],div:[],em:[],hr:[],h1:[],h2:[],h3:[],h4:[],h5:[],h6:[],i:[],img:[""src"",""srcset"",""alt"",""title"",""width"",""height""],li:[],ol:[],p:[],pre:[],s:[],small:[],span:[],sub:[],sup:[],strong:[],u:[],ul:[]},Wt=/^(?:(?:https?|mailto|ftp|tel|file):|[^#&/:?]*(?:[#/?]|$))/gi,Ut=/^data:(?:image\/(?:bmp|gif|jpeg|jpg|png|tiff|webp)|video\/(?:mpeg|mp4|ogg|webm)|audio\/(?:mp3|oga|ogg|opus));base64,[\d+/a-z]+=*$/i;function Vt(t,e,n){if(0===t.length)return t;if(n&&""function""==typeof n)return n(t);for(var i=(new window.DOMParser).parseFromString(t,""text/html""),o=Object.keys(e),r=[].slice.call(i.body.querySelectorAll(""*"")),a=function(t,n){var i=r[t],a=i.nodeName.toLowerCase();if(-1===o.indexOf(i.nodeName.toLowerCase()))return i.parentNode.removeChild(i),""continue"";var s=[].slice.call(i.attributes),l=[].concat(e[""*""]||[],e[a]||[]);s.forEach((function(t){(function(t,e){var n=t.nodeName.toLowerCase();if(-1!==e.indexOf(n))return-1===Bt.indexOf(n)||Boolean(t.nodeValue.match(Wt)||t.nodeValue.match(Ut));for(var i=e.filter((function(t){return t instanceof RegExp})),o=0,r=i.length;o<r;o++)if(n.match(i[o]))return!0;return!1})(t,l)||i.removeAttribute(t.nodeName)}))},s=0,l=r.length;s<l;s++)a(s);return i.body.innerHTML}var Yt=""tooltip"",zt=i.default.fn[Yt],Xt=new RegExp(""(^|\\s)bs-tooltip\\S+"",""g""),Kt=[""sanitize"",""whiteList"",""sanitizeFn""],Gt={animation:""boolean"",template:""string"",title:""(string|element|function)"",trigger:""string"",delay:""(number|object)"",html:""boolean"",selector:""(string|boolean)"",placement:""(string|function)"",offset:""(number|string|function)"",container:""(string|element|boolean)"",fallbackPlacement:""(string|array)"",boundary:""(string|element)"",customClass:""(string|function)"",sanitize:""boolean"",sanitizeFn:""(null|function)"",whiteList:""object"",popperConfig:""(null|object)""},$t={AUTO:""auto"",TOP:""top"",RIGHT:""right"",BOTTOM:""bottom"",LEFT:""left""},Jt={animation:!0,template:'<div class=""tooltip"" role=""tooltip""><div class=""arrow""></div><div class=""tooltip-inner""></div></div>',trigger:""hover focus"",title:"""",delay:0,html:!1,selector:!1,placement:""top"",offset:0,container:!1,fallbackPlacement:""flip"",boundary:""scrollParent"",customClass:"""",sanitize:!0,sanitizeFn:null,whiteList:Qt,popperConfig:null},Zt={HIDE:""hide.bs.tooltip"",HIDDEN:""hidden.bs.tooltip"",SHOW:""show.bs.tooltip"",SHOWN:""shown.bs.tooltip"",INSERTED:""inserted.bs.tooltip"",CLICK:""click.bs.tooltip"",FOCUSIN:""focusin.bs.tooltip"",FOCUSOUT:""focusout.bs.tooltip"",MOUSEENTER:""mouseenter.bs.tooltip"",MOUSELEAVE:""mouseleave.bs.tooltip""},te=function(){function t(t,e){if(""undefined""==typeof It)throw new TypeError(""Bootstrap's tooltips require Popper (https://popper.js.org)"");this._isEnabled=!0,this._timeout=0,this._hoverState="""",this._activeTrigger={},this._popper=null,this.element=t,this.config=this._getConfig(e),this.tip=null,this._setListeners()}var e=t.prototype;return e.enable=function(){this._isEnabled=!0},e.disable=function(){this._isEnabled=!1},e.toggleEnabled=function(){this._isEnabled=!this._isEnabled},e.toggle=function(t){if(this._isEnabled)if(t){var e=this.constructor.DATA_KEY,n=i.default(t.currentTarget).data(e);n||(n=new this.constructor(t.currentTarget,this._getDelegateConfig()),i.default(t.currentTarget).data(e,n)),n._activeTrigger.click=!n._activeTrigger.click,n._isWithActiveTrigger()?n._enter(null,n):n._leave(null,n)}else{if(i.default(this.getTipElement()).hasClass(""show""))return void this._leave(null,this);this._enter(null,this)}},e.dispose=function(){clearTimeout(this._timeout),i.default.removeData(this.element,this.constructor.DATA_KEY),i.default(this.element).off(this.constructor.EVENT_KEY),i.default(this.element).closest("".modal"").off(""hide.bs.modal"",this._hideModalHandler),this.tip&&i.default(this.tip).remove(),this._isEnabled=null,this._timeout=null,this._hoverState=null,this._activeTrigger=null,this._popper&&this._popper.destroy(),this._popper=null,this.element=null,this.config=null,this.tip=null},e.show=function(){var t=this;if(""none""===i.default(this.element).css(""display""))throw new Error(""Please use show on visible elements"");var e=i.default.Event(this.constructor.Event.SHOW);if(this.isWithContent()&&this._isEnabled){i.default(this.element).trigger(e);var n=l.findShadowRoot(this.element),o=i.default.contains(null!==n?n:this.element.ownerDocument.documentElement,this.element);if(e.isDefaultPrevented()||!o)return;var r=this.getTipElement(),a=l.getUID(this.constructor.NAME);r.setAttribute(""id"",a),this.element.setAttribute(""aria-describedby"",a),this.setContent(),this.config.animation&&i.default(r).addClass(""fade"");var s=""function""==typeof this.config.placement?this.config.placement.call(this,r,this.element):this.config.placement,u=this._getAttachment(s);this.addAttachmentClass(u);var f=this._getContainer();i.default(r).data(this.constructor.DATA_KEY,this),i.default.contains(this.element.ownerDocument.documentElement,this.tip)||i.default(r).appendTo(f),i.default(this.element).trigger(this.constructor.Event.INSERTED),this._popper=new It(this.element,r,this._getPopperConfig(u)),i.default(r).addClass(""show""),i.default(r).addClass(this.config.customClass),""ontouchstart""in document.documentElement&&i.default(document.body).children().on(""mouseover"",null,i.default.noop);var d=function(){t.config.animation&&t._fixTransition();var e=t._hoverState;t._hoverState=null,i.default(t.element).trigger(t.constructor.Event.SHOWN),""out""===e&&t._leave(null,t)};if(i.default(this.tip).hasClass(""fade"")){var c=l.getTransitionDurationFromElement(this.tip);i.default(this.tip).one(l.TRANSITION_END,d).emulateTransitionEnd(c)}else d()}},e.hide=function(t){var e=this,n=this.getTipElement(),o=i.default.Event(this.constructor.Event.HIDE),r=function(){""show""!==e._hoverState&&n.parentNode&&n.parentNode.removeChild(n),e._cleanTipClass(),e.element.removeAttribute(""aria-describedby""),i.default(e.element).trigger(e.constructor.Event.HIDDEN),null!==e._popper&&e._popper.destroy(),t&&t()};if(i.default(this.element).trigger(o),!o.isDefaultPrevented()){if(i.default(n).removeClass(""show""),""ontouchstart""in document.documentElement&&i.default(document.body).children().off(""mouseover"",null,i.default.noop),this._activeTrigger.click=!1,this._activeTrigger.focus=!1,this._activeTrigger.hover=!1,i.default(this.tip).hasClass(""fade"")){var a=l.getTransitionDurationFromElement(n);i.default(n).one(l.TRANSITION_END,r).emulateTransitionEnd(a)}else r();this._hoverState=""""}},e.update=function(){null!==this._popper&&this._popper.scheduleUpdate()},e.isWithContent=function(){return Boolean(this.getTitle())},e.addAttachmentClass=function(t){i.default(this.getTipElement()).addClass(""bs-tooltip-""+t)},e.getTipElement=function(){return this.tip=this.tip||i.default(this.config.template)[0],this.tip},e.setContent=function(){var t=this.getTipElement();this.setElementContent(i.default(t.querySelectorAll("".tooltip-inner"")),this.getTitle()),i.default(t).removeClass(""fade show"")},e.setElementContent=function(t,e){""object""!=typeof e||!e.nodeType&&!e.jquery?this.config.html?(this.config.sanitize&&(e=Vt(e,this.config.whiteList,this.config.sanitizeFn)),t.html(e)):t.text(e):this.config.html?i.default(e).parent().is(t)||t.empty().append(e):t.text(i.default(e).text())},e.getTitle=function(){var t=this.element.getAttribute(""data-original-title"");return t||(t=""function""==typeof this.config.title?this.config.title.call(this.element):this.config.title),t},e._getPopperConfig=function(t){var e=this;return a({},{placement:t,modifiers:{offset:this._getOffset(),flip:{behavior:this.config.fallbackPlacement},arrow:{element:"".arrow""},preventOverflow:{boundariesElement:this.config.boundary}},onCreate:function(t){t.originalPlacement!==t.placement&&e._handlePopperPlacementChange(t)},onUpdate:function(t){return e._handlePopperPlacementChange(t)}},this.config.popperConfig)},e._getOffset=function(){var t=this,e={};return""function""==typeof this.config.offset?e.fn=function(e){return e.offsets=a({},e.offsets,t.config.offset(e.offsets,t.element)||{}),e}:e.offset=this.config.offset,e},e._getContainer=function(){return!1===this.config.container?document.body:l.isElement(this.config.container)?i.default(this.config.container):i.default(document).find(this.config.container)},e._getAttachment=function(t){return $t[t.toUpperCase()]},e._setListeners=function(){var t=this;this.config.trigger.split("" "").forEach((function(e){if(""click""===e)i.default(t.element).on(t.constructor.Event.CLICK,t.config.selector,(function(e){return t.toggle(e)}));else if(""manual""!==e){var n=""hover""===e?t.constructor.Event.MOUSEENTER:t.constructor.Event.FOCUSIN,o=""hover""===e?t.constructor.Event.MOUSELEAVE:t.constructor.Event.FOCUSOUT;i.default(t.element).on(n,t.config.selector,(function(e){return t._enter(e)})).on(o,t.config.selector,(function(e){return t._leave(e)}))}})),this._hideModalHandler=function(){t.element&&t.hide()},i.default(this.element).closest("".modal"").on(""hide.bs.modal"",this._hideModalHandler),this.config.selector?this.config=a({},this.config,{trigger:""manual"",selector:""""}):this._fixTitle()},e._fixTitle=function(){var t=typeof this.element.getAttribute(""data-original-title"");(this.element.getAttribute(""title"")||""string""!==t)&&(this.element.setAttribute(""data-original-title"",this.element.getAttribute(""title"")||""""),this.element.setAttribute(""title"",""""))},e._enter=function(t,e){var n=this.constructor.DATA_KEY;(e=e||i.default(t.currentTarget).data(n))||(e=new this.constructor(t.currentTarget,this._getDelegateConfig()),i.default(t.currentTarget).data(n,e)),t&&(e._activeTrigger[""focusin""===t.type?""focus"":""hover""]=!0),i.default(e.getTipElement()).hasClass(""show"")||""show""===e._hoverState?e._hoverState=""show"":(clearTimeout(e._timeout),e._hoverState=""show"",e.config.delay&&e.config.delay.show?e._timeout=setTimeout((function(){""show""===e._hoverState&&e.show()}),e.config.delay.show):e.show())},e._leave=function(t,e){var n=this.constructor.DATA_KEY;(e=e||i.default(t.currentTarget).data(n))||(e=new this.constructor(t.currentTarget,this._getDelegateConfig()),i.default(t.currentTarget).data(n,e)),t&&(e._activeTrigger[""focusout""===t.type?""focus"":""hover""]=!1),e._isWithActiveTrigger()||(clearTimeout(e._timeout),e._hoverState=""out"",e.config.delay&&e.config.delay.hide?e._timeout=setTimeout((function(){""out""===e._hoverState&&e.hide()}),e.config.delay.hide):e.hide())},e._isWithActiveTrigger=function(){for(var t in this._activeTrigger)if(this._activeTrigger[t])return!0;return!1},e._getConfig=function(t){var e=i.default(this.element).data();return Object.keys(e).forEach((function(t){-1!==Kt.indexOf(t)&&delete e[t]})),""number""==typeof(t=a({},this.constructor.Default,e,""object""==typeof t&&t?t:{})).delay&&(t.delay={show:t.delay,hide:t.delay}),""number""==typeof t.title&&(t.title=t.title.toString()),""number""==typeof t.content&&(t.content=t.content.toString()),l.typeCheckConfig(Yt,t,this.constructor.DefaultType),t.sanitize&&(t.template=Vt(t.template,t.whiteList,t.sanitizeFn)),t},e._getDelegateConfig=function(){var t={};if(this.config)for(var e in this.config)this.constructor.Default[e]!==this.config[e]&&(t[e]=this.config[e]);return t},e._cleanTipClass=function(){var t=i.default(this.getTipElement()),e=t.attr(""class"").match(Xt);null!==e&&e.length&&t.removeClass(e.join(""""))},e._handlePopperPlacementChange=function(t){this.tip=t.instance.popper,this._cleanTipClass(),this.addAttachmentClass(this._getAttachment(t.placement))},e._fixTransition=function(){var t=this.getTipElement(),e=this.config.animation;null===t.getAttribute(""x-placement"")&&(i.default(t).removeClass(""fade""),this.config.animation=!1,this.hide(),this.show(),this.config.animation=e)},t._jQueryInterface=function(e){return this.each((function(){var n=i.default(this),o=n.data(""bs.tooltip""),r=""object""==typeof e&&e;if((o||!/dispose|hide/.test(e))&&(o||(o=new t(this,r),n.data(""bs.tooltip"",o)),""string""==typeof e)){if(""undefined""==typeof o[e])throw new TypeError('No method named ""'+e+'""');o[e]()}}))},r(t,null,[{key:""VERSION"",get:function(){return""4.6.0""}},{key:""Default"",get:function(){return Jt}},{key:""NAME"",get:function(){return Yt}},{key:""DATA_KEY"",get:function(){return""bs.tooltip""}},{key:""Event"",get:function(){return Zt}},{key:""EVENT_KEY"",get:function(){return"".bs.tooltip""}},{key:""DefaultType"",get:function(){return Gt}}]),t}();i.default.fn[Yt]=te._jQueryInterface,i.default.fn[Yt].Constructor=te,i.default.fn[Yt].noConflict=function(){return i.default.fn[Yt]=zt,te._jQueryInterface};var ee=""popover"",ne=i.default.fn[ee],ie=new RegExp(""(^|\\s)bs-popover\\S+"",""g""),oe=a({},te.Default,{placement:""right"",trigger:""click"",content:"""",template:'<div class=""popover"" role=""tooltip""><div class=""arrow""></div><h3 class=""popover-header""></h3><div class=""popover-body""></div></div>'}),re=a({},te.DefaultType,{content:""(string|element|function)""}),ae={HIDE:""hide.bs.popover"",HIDDEN:""hidden.bs.popover"",SHOW:""show.bs.popover"",SHOWN:""shown.bs.popover"",INSERTED:""inserted.bs.popover"",CLICK:""click.bs.popover"",FOCUSIN:""focusin.bs.popover"",FOCUSOUT:""focusout.bs.popover"",MOUSEENTER:""mouseenter.bs.popover"",MOUSELEAVE:""mouseleave.bs.popover""},se=function(t){var e,n;function o(){return t.apply(this,arguments)||this}n=t,(e=o).prototype=Object.create(n.prototype),e.prototype.constructor=e,e.__proto__=n;var a=o.prototype;return a.isWithContent=function(){return this.getTitle()||this._getContent()},a.addAttachmentClass=function(t){i.default(this.getTipElement()).addClass(""bs-popover-""+t)},a.getTipElement=function(){return this.tip=this.tip||i.default(this.config.template)[0],this.tip},a.setContent=function(){var t=i.default(this.getTipElement());this.setElementContent(t.find("".popover-header""),this.getTitle());var e=this._getContent();""function""==typeof e&&(e=e.call(this.element)),this.setElementContent(t.find("".popover-body""),e),t.removeClass(""fade show"")},a._getContent=function(){return this.element.getAttribute(""data-content"")||this.config.content},a._cleanTipClass=function(){var t=i.default(this.getTipElement()),e=t.attr(""class"").match(ie);null!==e&&e.length>0&&t.removeClass(e.join(""""))},o._jQueryInterface=function(t){return this.each((function(){var e=i.default(this).data(""bs.popover""),n=""object""==typeof t?t:null;if((e||!/dispose|hide/.test(t))&&(e||(e=new o(this,n),i.default(this).data(""bs.popover"",e)),""string""==typeof t)){if(""undefined""==typeof e[t])throw new TypeError('No method named ""'+t+'""');e[t]()}}))},r(o,null,[{key:""VERSION"",get:function(){return""4.6.0""}},{key:""Default"",get:function(){return oe}},{key:""NAME"",get:function(){return ee}},{key:""DATA_KEY"",get:function(){return""bs.popover""}},{key:""Event"",get:function(){return ae}},{key:""EVENT_KEY"",get:function(){return"".bs.popover""}},{key:""DefaultType"",get:function(){return re}}]),o}(te);i.default.fn[ee]=se._jQueryInterface,i.default.fn[ee].Constructor=se,i.default.fn[ee].noConflict=function(){return i.default.fn[ee]=ne,se._jQueryInterface};var le=""scrollspy"",ue=i.default.fn[le],fe={offset:10,method:""auto"",target:""""},de={offset:""number"",method:""string"",target:""(string|element)""},ce=function(){function t(t,e){var n=this;this._element=t,this._scrollElement=""BODY""===t.tagName?window:t,this._config=this._getConfig(e),this._selector=this._config.target+"" .nav-link,""+this._config.target+"" .list-group-item,""+this._config.target+"" .dropdown-item"",this._offsets=[],this._targets=[],this._activeTarget=null,this._scrollHeight=0,i.default(this._scrollElement).on(""scroll.bs.scrollspy"",(function(t){return n._process(t)})),this.refresh(),this._process()}var e=t.prototype;return e.refresh=function(){var t=this,e=this._scrollElement===this._scrollElement.window?""offset"":""position"",n=""auto""===this._config.method?e:this._config.method,o=""position""===n?this._getScrollTop():0;this._offsets=[],this._targets=[],this._scrollHeight=this._getScrollHeight(),[].slice.call(document.querySelectorAll(this._selector)).map((function(t){var e,r=l.getSelectorFromElement(t);if(r&&(e=document.querySelector(r)),e){var a=e.getBoundingClientRect();if(a.width||a.height)return[i.default(e)[n]().top+o,r]}return null})).filter((function(t){return t})).sort((function(t,e){return t[0]-e[0]})).forEach((function(e){t._offsets.push(e[0]),t._targets.push(e[1])}))},e.dispose=function(){i.default.removeData(this._element,""bs.scrollspy""),i.default(this._scrollElement).off("".bs.scrollspy""),this._element=null,this._scrollElement=null,this._config=null,this._selector=null,this._offsets=null,this._targets=null,this._activeTarget=null,this._scrollHeight=null},e._getConfig=function(t){if(""string""!=typeof(t=a({},fe,""object""==typeof t&&t?t:{})).target&&l.isElement(t.target)){var e=i.default(t.target).attr(""id"");e||(e=l.getUID(le),i.default(t.target).attr(""id"",e)),t.target=""#""+e}return l.typeCheckConfig(le,t,de),t},e._getScrollTop=function(){return this._scrollElement===window?this._scrollElement.pageYOffset:this._scrollElement.scrollTop},e._getScrollHeight=function(){return this._scrollElement.scrollHeight||Math.max(document.body.scrollHeight,document.documentElement.scrollHeight)},e._getOffsetHeight=function(){return this._scrollElement===window?window.innerHeight:this._scrollElement.getBoundingClientRect().height},e._process=function(){var t=this._getScrollTop()+this._config.offset,e=this._getScrollHeight(),n=this._config.offset+e-this._getOffsetHeight();if(this._scrollHeight!==e&&this.refresh(),t>=n){var i=this._targets[this._targets.length-1];this._activeTarget!==i&&this._activate(i)}else{if(this._activeTarget&&t<this._offsets[0]&&this._offsets[0]>0)return this._activeTarget=null,void this._clear();for(var o=this._offsets.length;o--;){this._activeTarget!==this._targets[o]&&t>=this._offsets[o]&&(""undefined""==typeof this._offsets[o+1]||t<this._offsets[o+1])&&this._activate(this._targets[o])}}},e._activate=function(t){this._activeTarget=t,this._clear();var e=this._selector.split("","").map((function(e){return e+'[data-target=""'+t+'""],'+e+'[href=""'+t+'""]'})),n=i.default([].slice.call(document.querySelectorAll(e.join("",""))));n.hasClass(""dropdown-item"")?(n.closest("".dropdown"").find("".dropdown-toggle"").addClass(""active""),n.addClass(""active"")):(n.addClass(""active""),n.parents("".nav, .list-group"").prev("".nav-link, .list-group-item"").addClass(""active""),n.parents("".nav, .list-group"").prev("".nav-item"").children("".nav-link"").addClass(""active"")),i.default(this._scrollElement).trigger(""activate.bs.scrollspy"",{relatedTarget:t})},e._clear=function(){[].slice.call(document.querySelectorAll(this._selector)).filter((function(t){return t.classList.contains(""active"")})).forEach((function(t){return t.classList.remove(""active"")}))},t._jQueryInterface=function(e){return this.each((function(){var n=i.default(this).data(""bs.scrollspy"");if(n||(n=new t(this,""object""==typeof e&&e),i.default(this).data(""bs.scrollspy"",n)),""string""==typeof e){if(""undefined""==typeof n[e])throw new TypeError('No method named ""'+e+'""');n[e]()}}))},r(t,null,[{key:""VERSION"",get:function(){return""4.6.0""}},{key:""Default"",get:function(){return fe}}]),t}();i.default(window).on(""load.bs.scrollspy.data-api"",(function(){for(var t=[].slice.call(document.querySelectorAll('[data-spy=""scroll""]')),e=t.length;e--;){var n=i.default(t[e]);ce._jQueryInterface.call(n,n.data())}})),i.default.fn[le]=ce._jQueryInterface,i.default.fn[le].Constructor=ce,i.default.fn[le].noConflict=function(){return i.default.fn[le]=ue,ce._jQueryInterface};var he=i.default.fn.tab,pe=function(){function t(t){this._element=t}var e=t.prototype;return e.show=function(){var t=this;if(!(this._element.parentNode&&this._element.parentNode.nodeType===Node.ELEMENT_NODE&&i.default(this._element).hasClass(""active"")||i.default(this._element).hasClass(""disabled""))){var e,n,o=i.default(this._element).closest("".nav, .list-group"")[0],r=l.getSelectorFromElement(this._element);if(o){var a=""UL""===o.nodeName||""OL""===o.nodeName?""> li > .active"":"".active"";n=(n=i.default.makeArray(i.default(o).find(a)))[n.length-1]}var s=i.default.Event(""hide.bs.tab"",{relatedTarget:this._element}),u=i.default.Event(""show.bs.tab"",{relatedTarget:n});if(n&&i.default(n).trigger(s),i.default(this._element).trigger(u),!u.isDefaultPrevented()&&!s.isDefaultPrevented()){r&&(e=document.querySelector(r)),this._activate(this._element,o);var f=function(){var e=i.default.Event(""hidden.bs.tab"",{relatedTarget:t._element}),o=i.default.Event(""shown.bs.tab"",{relatedTarget:n});i.default(n).trigger(e),i.default(t._element).trigger(o)};e?this._activate(e,e.parentNode,f):f()}}},e.dispose=function(){i.default.removeData(this._element,""bs.tab""),this._element=null},e._activate=function(t,e,n){var o=this,r=(!e||""UL""!==e.nodeName&&""OL""!==e.nodeName?i.default(e).children("".active""):i.default(e).find(""> li > .active""))[0],a=n&&r&&i.default(r).hasClass(""fade""),s=function(){return o._transitionComplete(t,r,n)};if(r&&a){var u=l.getTransitionDurationFromElement(r);i.default(r).removeClass(""show"").one(l.TRANSITION_END,s).emulateTransitionEnd(u)}else s()},e._transitionComplete=function(t,e,n){if(e){i.default(e).removeClass(""active"");var o=i.default(e.parentNode).find(""> .dropdown-menu .active"")[0];o&&i.default(o).removeClass(""active""),""tab""===e.getAttribute(""role"")&&e.setAttribute(""aria-selected"",!1)}i.default(t).addClass(""active""),""tab""===t.getAttribute(""role"")&&t.setAttribute(""aria-selected"",!0),l.reflow(t),t.classList.contains(""fade"")&&t.classList.add(""show"");var r=t.parentNode;if(r&&""LI""===r.nodeName&&(r=r.parentNode),r&&i.default(r).hasClass(""dropdown-menu"")){var a=i.default(t).closest("".dropdown"")[0];if(a){var s=[].slice.call(a.querySelectorAll("".dropdown-toggle""));i.default(s).addClass(""active"")}t.setAttribute(""aria-expanded"",!0)}n&&n()},t._jQueryInterface=function(e){return this.each((function(){var n=i.default(this),o=n.data(""bs.tab"");if(o||(o=new t(this),n.data(""bs.tab"",o)),""string""==typeof e){if(""undefined""==typeof o[e])throw new TypeError('No method named ""'+e+'""');o[e]()}}))},r(t,null,[{key:""VERSION"",get:function(){return""4.6.0""}}]),t}();i.default(document).on(""click.bs.tab.data-api"",'[data-toggle=""tab""], [data-toggle=""pill""], [data-toggle=""list""]',(function(t){t.preventDefault(),pe._jQueryInterface.call(i.default(this),""show"")})),i.default.fn.tab=pe._jQueryInterface,i.default.fn.tab.Constructor=pe,i.default.fn.tab.noConflict=function(){return i.default.fn.tab=he,pe._jQueryInterface};var me=i.default.fn.toast,ge={animation:""boolean"",autohide:""boolean"",delay:""number""},ve={animation:!0,autohide:!0,delay:500},_e=function(){function t(t,e){this._element=t,this._config=this._getConfig(e),this._timeout=null,this._setListeners()}var e=t.prototype;return e.show=function(){var t=this,e=i.default.Event(""show.bs.toast"");if(i.default(this._element).trigger(e),!e.isDefaultPrevented()){this._clearTimeout(),this._config.animation&&this._element.classList.add(""fade"");var n=function(){t._element.classList.remove(""showing""),t._element.classList.add(""show""),i.default(t._element).trigger(""shown.bs.toast""),t._config.autohide&&(t._timeout=setTimeout((function(){t.hide()}),t._config.delay))};if(this._element.classList.remove(""hide""),l.reflow(this._element),this._element.classList.add(""showing""),this._config.animation){var o=l.getTransitionDurationFromElement(this._element);i.default(this._element).one(l.TRANSITION_END,n).emulateTransitionEnd(o)}else n()}},e.hide=function(){if(this._element.classList.contains(""show"")){var t=i.default.Event(""hide.bs.toast"");i.default(this._element).trigger(t),t.isDefaultPrevented()||this._close()}},e.dispose=function(){this._clearTimeout(),this._element.classList.contains(""show"")&&this._element.classList.remove(""show""),i.default(this._element).off(""click.dismiss.bs.toast""),i.default.removeData(this._element,""bs.toast""),this._element=null,this._config=null},e._getConfig=function(t){return t=a({},ve,i.default(this._element).data(),""object""==typeof t&&t?t:{}),l.typeCheckConfig(""toast"",t,this.constructor.DefaultType),t},e._setListeners=function(){var t=this;i.default(this._element).on(""click.dismiss.bs.toast"",'[data-dismiss=""toast""]',(function(){return t.hide()}))},e._close=function(){var t=this,e=function(){t._element.classList.add(""hide""),i.default(t._element).trigger(""hidden.bs.toast"")};if(this._element.classList.remove(""show""),this._config.animation){var n=l.getTransitionDurationFromElement(this._element);i.default(this._element).one(l.TRANSITION_END,e).emulateTransitionEnd(n)}else e()},e._clearTimeout=function(){clearTimeout(this._timeout),this._timeout=null},t._jQueryInterface=function(e){return this.each((function(){var n=i.default(this),o=n.data(""bs.toast"");if(o||(o=new t(this,""object""==typeof e&&e),n.data(""bs.toast"",o)),""string""==typeof e){if(""undefined""==typeof o[e])throw new TypeError('No method named ""'+e+'""');o[e](this)}}))},r(t,null,[{key:""VERSION"",get:function(){return""4.6.0""}},{key:""DefaultType"",get:function(){return ge}},{key:""Default"",get:function(){return ve}}]),t}();i.default.fn.toast=_e._jQueryInterface,i.default.fn.toast.Constructor=_e,i.default.fn.toast.noConflict=function(){return i.default.fn.toast=me,_e._jQueryInterface},t.Alert=d,t.Button=h,t.Carousel=y,t.Collapse=S,t.Dropdown=Ft,t.Modal=qt,t.Popover=se,t.Scrollspy=ce,t.Tab=pe,t.Toast=_e,t.Tooltip=te,t.Util=l,Object.defineProperty(t,""__esModule"",{value:!0})}));
+//# sourceMappingURL=bootstrap.bundle.min.js.map
\ No newline at end of file

---FILE: docs/libs/bs3compat-0.5.0/bs3compat.js---
@@ -0,0 +1,48 @@
+// Inform the world that we have the ability to use BS3 nav/navbar markup in BS4
+window.BS3_COMPAT = true;
+
+// This logic needs to execute after both the BS4+ (new) as well as BS3 (legacy)
+// jQuery plugins have been registered. For BS5, plugin registration happens
+// after DOM content is loaded, which is why we do the same here.
+// https://github.com/twbs/bootstrap/blob/08139c22/js/dist/tab.js#L87
+$(function() {
+
+  // The legacy plugin needs to be registered after the new one
+  if (!$.fn.tab.Constructor.VERSION.match(/^3\./)) {
+    (console.warn || console.error || console.log)(""bs3compat.js couldn't find bs3 tab impl; bs3 tabs will not be properly supported"");
+    return;
+  }
+  var legacyTabPlugin = $.fn.tab.noConflict();
+
+  if (!$.fn.tab || !$.fn.tab.Constructor || !$.fn.tab.noConflict) {
+    (console.warn || console.error || console.log)(""bs3compat.js couldn't find a jQuery tab impl; bs3 tabs will not be properly supported"");
+  }
+  var newTabPlugin = $.fn.tab.noConflict();
+
+  // Re-define the tab click event
+  // https://github.com/twbs/bootstrap/blob/08139c2/js/src/tab.js#L33
+  var EVENT_KEY = ""click.bs.tab.data-api"";
+  $(document).off(EVENT_KEY);
+
+  var SELECTOR = '[data-toggle=""tab""], [data-toggle=""pill""], [data-bs-toggle=""tab""], [data-bs-toggle=""pill""]';
+  $(document).on(EVENT_KEY, SELECTOR, function(event) {
+    event.preventDefault();
+    $(this).tab(""show"");
+  });
+
+  function TabPlugin(config) {
+    // Legacy (bs3) tabs: li.active > a
+    // New (bs4+) tabs: li.nav-item > a.active.nav-link
+    var legacy = $(this).closest("".nav"").find(""li:not(.dropdown).active > a"").length > 0;
+    var plugin = legacy ? legacyTabPlugin : newTabPlugin;
+    plugin.call($(this), config);
+  }
+
+  var noconflict = $.fn.tab;
+  $.fn.tab = TabPlugin;
+  $.fn.tab.Constructor = newTabPlugin.Constructor;
+  $.fn.tab.noConflict = function() {
+    $.fn.tab = noconflict;
+    return TabPlugin;
+  };
+});

---FILE: docs/libs/bs3compat-0.5.0/tabs.js---
@@ -0,0 +1,157 @@
+/* ========================================================================
+ * Bootstrap: tab.js v3.4.1
+ * https://getbootstrap.com/docs/3.4/javascript/#tabs
+ * ========================================================================
+ * Copyright 2011-2019 Twitter, Inc.
+ * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
+ * ======================================================================== */
+
+// Register tab plugin after DOM content loaded in order to
+// override BS5's plugin
+// https://github.com/twbs/bootstrap/blob/08139c22/js/dist/tab.js#L87
+$(function() {
+  'use strict';
+
+  // TAB CLASS DEFINITION
+  // ====================
+
+  var Tab = function (element) {
+    // jscs:disable requireDollarBeforejQueryAssignment
+    this.element = $(element)
+    // jscs:enable requireDollarBeforejQueryAssignment
+  }
+
+  Tab.VERSION = '3.4.1'
+
+  Tab.TRANSITION_DURATION = 150
+
+  Tab.prototype.show = function () {
+    var $this    = this.element
+    var $ul      = $this.closest('ul:not(.dropdown-menu)')
+    var selector = $this.data('target')
+
+    if (!selector) {
+      selector = $this.attr('href')
+      selector = selector && selector.replace(/.*(?=#[^\s]*$)/, '') // strip for ie7
+    }
+
+    if ($this.parent('li').hasClass('active')) return
+
+    var $previous = $ul.find('.active:last a')
+    var hideEvent = $.Event('hide.bs.tab', {
+      relatedTarget: $this[0]
+    })
+    var showEvent = $.Event('show.bs.tab', {
+      relatedTarget: $previous[0]
+    })
+
+    $previous.trigger(hideEvent)
+    $this.trigger(showEvent)
+
+    if (showEvent.isDefaultPrevented() || hideEvent.isDefaultPrevented()) return
+
+    var $target = $(document).find(selector)
+
+    this.activate($this.closest('li'), $ul)
+    this.activate($target, $target.parent(), function () {
+      $previous.trigger({
+        type: 'hidden.bs.tab',
+        relatedTarget: $this[0]
+      })
+      $this.trigger({
+        type: 'shown.bs.tab',
+        relatedTarget: $previous[0]
+      })
+    })
+  }
+
+  Tab.prototype.activate = function (element, container, callback) {
+    var $active    = container.find('> .active')
+    var transition = callback
+      && $.support.transition
+      && ($active.length && $active.hasClass('fade') || !!container.find('> .fade').length)
+
+    function next() {
+      $active
+        .removeClass('active')
+        .find('> .dropdown-menu > .active')
+        .removeClass('active')
+        .end()
+        .find('[data-toggle=""tab""]')
+        .attr('aria-expanded', false)
+
+      element
+        .addClass('active')
+        .find('[data-toggle=""tab""]')
+        .attr('aria-expanded', true)
+
+      if (transition) {
+        element[0].offsetWidth // reflow for transition
+        element.addClass('in')
+      } else {
+        element.removeClass('fade')
+      }
+
+      if (element.parent('.dropdown-menu').length) {
+        element
+          .closest('li.dropdown')
+          .addClass('active')
+          .end()
+          .find('[data-toggle=""tab""]')
+          .attr('aria-expanded', true)
+      }
+
+      callback && callback()
+    }
+
+    $active.length && transition ?
+      $active
+        .one('bsTransitionEnd', next)
+        .emulateTransitionEnd(Tab.TRANSITION_DURATION) :
+      next()
+
+    $active.removeClass('in')
+  }
+
+
+  // TAB PLUGIN DEFINITION
+  // =====================
+
+  function Plugin(option) {
+    return this.each(function () {
+      var $this = $(this)
+      var data  = $this.data('bs.tab')
+
+      if (!data) $this.data('bs.tab', (data = new Tab(this)))
+      if (typeof option == 'string') data[option]()
+    })
+  }
+
+  var old = $.fn.tab
+
+  $.fn.tab             = Plugin
+  $.fn.tab.Constructor = Tab
+
+
+  // TAB NO CONFLICT
+  // ===============
+
+  $.fn.tab.noConflict = function () {
+    $.fn.tab = old
+    return this
+  }
+
+
+  // TAB DATA-API
+  // ============
+
+  var clickHandler = function (e) {
+    e.preventDefault()
+    Plugin.call($(this), 'show')
+  }
+
+  $(document)
+    .on('click.bs.tab.data-api', '[data-toggle=""tab""]', clickHandler)
+    .on('click.bs.tab.data-api', '[data-toggle=""pill""]', clickHandler)
+
+});

---FILE: docs/libs/bs3compat-0.5.0/transition.js---
@@ -0,0 +1,59 @@
+/* ========================================================================
+ * Bootstrap: transition.js v3.4.1
+ * https://getbootstrap.com/docs/3.4/javascript/#transitions
+ * ========================================================================
+ * Copyright 2011-2019 Twitter, Inc.
+ * Licensed under MIT (https://github.com/twbs/bootstrap/blob/v3-dev/LICENSE)
+ * ======================================================================== */
+
+
++function ($) {
+  'use strict';
+
+  // CSS TRANSITION SUPPORT (Shoutout: https://modernizr.com/)
+  // ============================================================
+
+  function transitionEnd() {
+    var el = document.createElement('bootstrap')
+
+    var transEndEventNames = {
+      WebkitTransition : 'webkitTransitionEnd',
+      MozTransition    : 'transitionend',
+      OTransition      : 'oTransitionEnd otransitionend',
+      transition       : 'transitionend'
+    }
+
+    for (var name in transEndEventNames) {
+      if (el.style[name] !== undefined) {
+        return { end: transEndEventNames[name] }
+      }
+    }
+
+    return false // explicit for ie8 (  ._.)
+  }
+
+  // https://blog.alexmaccaw.com/css-transitions
+  $.fn.emulateTransitionEnd = function (duration) {
+    var called = false
+    var $el = this
+    $(this).one('bsTransitionEnd', function () { called = true })
+    var callback = function () { if (!called) $($el).trigger($.support.transition.end) }
+    setTimeout(callback, duration)
+    return this
+  }
+
+  $(function () {
+    $.support.transition = transitionEnd()
+
+    if (!$.support.transition) return
+
+    $.event.special.bsTransitionEnd = {
+      bindType: $.support.transition.end,
+      delegateType: $.support.transition.end,
+      handle: function (e) {
+        if ($(e.target).is(this)) return e.handleObj.handler.apply(this, arguments)
+      }
+    }
+  })
+
+}(jQuery);

---FILE: docs/libs/bs4_book-1.0.0/bs4_book.css---
@@ -0,0 +1,555 @@
+/* Page structure ----------------------------------------------------------
+
++-----+-----------------+------+--------------+
+|     | sidebar-chapter | main | sidebar-book |
++=====+=================+======+==============+
+| sml | 12 (collapsed)  | 12   | -            |
+| md  | 12 (collapsed)  | 9    | 3            |
+| lg  | 3               | 7    | 2            |
++-----+-----------------+------+--------------+
+
+Side uses container-fluid so we set up some additional breakpoints, to ensure
+that the columns never get too wide, either individually or collectively.
+
+*/
+
+
+@media (min-width: 1200px) {
+  .container-fluid {
+    max-width: 95rem;
+  }
+  .container-fluid .row {
+    justify-content: space-evenly;
+  }
+  .container-fluid main {
+    max-width: 45rem;
+  }
+  .sidebar {
+    max-width: 15rem;
+  }
+
+  /* Increase font-size for very wide devices */
+  body {
+    font-size: 18px
+  }
+}
+
+main {margin-top: 1rem;}
+
+@media (max-width: 991.98px) {
+  .sidebar {
+    max-width: 100%;
+  }
+
+  .collapse-lg {
+    display: none;
+    padding: 1rem;
+    border-radius: 0.2rem;
+    background: #fafafa;
+    margin-top: 0.5rem;
+    margin-bottom: 1rem;
+    box-shadow: 5px 5px 10px rgba(0.1, 0.1, 0.1, 0.5);
+    border: 1px solid var(--primary);
+  }
+  .book-toc {
+    column-count: 2;
+  }
+  .sidebar-book, main {
+    padding-left: 1rem;
+  }
+  .sidebar-book {
+    margin-top: 1rem;
+  }
+}
+@media (min-width: 992px) {
+  .collapse-lg {
+    display: block !important;
+  }
+}
+.collapse-lg.show {
+  display: block;
+}
+
+@media (min-width: 768px) {
+  .sidebar-chapter {
+    position: sticky;
+    max-height: 100vh;
+    top: 0;
+    overflow-y: auto;
+  }
+}
+
+@media (min-width: 992px) {
+  .sidebar-book {
+    position: sticky;
+    max-height: 100vh;
+    top: 0;
+    overflow-y: auto;
+  }
+}
+
+/* Chapter nav ----------------------------------------- */
+
+.chapter-nav {
+  display: flex;
+  justify-content: space-between;
+  margin-top: 2rem;
+}
+.chapter-nav .prev, .chapter-nav .next {
+  padding: 0.5rem;
+  border: 1px solid #eee;
+  border-radius: 0.2rem;
+  box-shadow: 0 .5rem 1rem rgba(0,0,0,.15);
+}
+.chapter-nav .empty {
+  border: none;
+}
+.chapter-nav .prev a:before {
+  content: ""¬´ "";
+}
+.chapter-nav .next a:after {
+  content: "" ¬ª"";
+}
+
+/* Sidebar ------------------------------------------------------ */
+
+.sidebar h1, .sidebar h2 {
+  margin-top: 1.5rem;
+  margin-bottom: 0.5rem;
+}
+.sidebar h1 {
+  font-size: 1.1rem;
+}
+@media (max-width: 991.98px) {
+  .sidebar h1 {
+    font-size: 1.5rem;
+    margin-top: 0rem;
+  }
+}
+.sidebar h2 {
+  font-size: 0.9rem;
+}
+
+.sidebar hr {
+  margin: 0 0 0.5rem 0;
+}
+
+.sidebar li {
+  margin-bottom: 0.5rem;
+  font-size: 0.9rem;
+  line-height: 1.5;
+}
+
+.sidebar li.book-part {
+  margin-top: 1rem;
+}
+
+.book-toc .active {
+  font-weight: bolder;
+}
+
+.book-extra {
+  border-top: 1px solid #ccc;
+  margin-top: 0.5rem;
+  padding-top: 0.5rem;
+  font-size: 0.9rem;
+}
+
+.book-extra i {
+  font-size: 1.2em;
+}
+
+/* Sticky footer ----------------------------------------- */
+html, body {height: 100%}
+
+body {
+  display: flex;
+  flex-direction: column;
+}
+.container-fluid {
+  flex: 1 0 auto;
+}
+footer {
+  flex-shrink: 0;
+  font-size: 0.9rem;
+
+}
+footer a {
+  text-decoration: underline;
+}
+
+/* Scrollspy --------------------------------------------- */
+
+nav[data-toggle=""toc""] .nav > li {
+  margin-bottom: calc(0.5rem - 3px);
+}
+
+nav[data-toggle=""toc""] .nav > li > a {
+  padding: 3px;
+  display: block;
+}
+
+nav[data-toggle=""toc""] .nav > li > a:hover {
+  text-decoration: underline;
+}
+
+nav[data-toggle=""toc""] .nav a.nav-link.active,
+nav[data-toggle=""toc""] .nav .nav-link.active > li > a {
+  background-color: #eee;
+}
+
+/* Nav: second level (shown on .active) */
+nav[data-toggle=""toc""] .nav-link + ul {
+  display: none;
+}
+nav[data-toggle=""toc""] .nav-link.active + ul {
+  margin-top: 3px;
+  display: block;
+}
+
+nav[data-toggle=""toc""] .nav .nav > li {
+  margin-bottom: 0;
+}
+nav[data-toggle=""toc""] .nav .nav > li > a {
+  margin-left: 10px;
+}
+/* Figures -------------------------------------------- */
+
+.figure, .inline-figure {
+  width: 100%;
+  overflow-x: auto;
+}
+
+.inline-figure {
+  border: solid 2px #f1f1f1;
+  margin-bottom: 1rem; /* to match <p> */
+}
+
+.figure {
+  border-top: 2px solid #eee;
+  border-bottom: 2px solid #eee;
+  margin:  1.5rem -0.5rem 1rem -0.5rem;
+  padding: 1.5rem    0    1rem      1rem;
+}
+
+@media (max-width: 767.98px) {
+  .figure {
+    margin: 1.5rem -1rem 1.5rem -1rem;
+    padding: 1.5rem;
+    width: 100vw;
+  }
+}
+
+caption, p.caption {
+  text-align: left;
+  margin-top: 1rem;
+  margin-bottom: 0;
+  font-size: 0.9rem;
+  color: #777;
+}
+
+/* Headings -------------------------------------------- */
+
+h2 {
+  margin-top: 2rem;
+  margin-bottom: 1rem;
+  font-size: 1.5rem;
+}
+h3 { margin-top: 1.5em; font-size: 1.2rem; }
+h4 { margin-top: 1.5em; font-size: 1.1rem; }
+h5 { margin-top: 1.5em; font-size: 1rem; }
+
+h1, h2, h3, h4, h5 {
+  line-height: 1.3;
+}
+
+.header-section-number {
+  color: #6C6C6C;
+  font-weight: normal;
+}
+
+.dropdown-item .header-section-number {
+  position: absolute;
+  width: 2rem;
+  left: -1rem;
+  display: block;
+  text-align: right;
+}
+
+.anchor {
+  font-size: max(0.5em, 1rem);
+  margin-left: 0.5rem;
+  display: none;
+}
+h1:hover .anchor,
+h2:hover .anchor,
+h3:hover .anchor,
+h4:hover .anchor,
+h5:hover .anchor,
+h6:hover .anchor {
+  display: inline;
+}
+
+/* Tables ---------------------------------------------- */
+
+.inline-table {
+  overflow-x: auto;
+}
+
+table.kable_wrapper td {
+  vertical-align: top;
+}
+
+
+/* Footnotes --------------------------------------------- */
+
+.popover {
+  max-width: min(100vw, 32rem);
+  font-size: 0.9rem;
+  box-shadow: 4px 4px 8px rgba(0, 0, 0, 0.3);
+}
+.popover-body {
+  padding: 0.75rem;
+}
+.popover-body p:last-child {
+  margin-bottom: 0;
+}
+
+a.footnote-ref {
+  cursor: pointer;
+}
+
+/* Search ---------------------------------------------- */
+
+mark {
+  background: linear-gradient(-100deg,
+    hsla(48,92%,75%,.3),
+    hsla(48,92%,75%,.7) 95%,
+    hsla(48,92%,75%,.1)
+  )
+}
+
+.algolia-autocomplete .aa-hint {
+  color: #999;
+}
+.algolia-autocomplete .aa-dropdown-menu {
+  width: min(100%, 20rem);
+  background-color: #fff;
+  border: 1px solid var(--gray);
+  border-radius: 0.2rem;
+  margin-top: 2px;
+
+  max-height: 50vh;
+  overflow-y: auto;
+}
+.algolia-autocomplete .aa-dropdown-menu .aa-suggestion {
+  cursor: pointer;
+  padding: 5px 4px;
+  border-bottom: 1px #ddd solid;
+  font-size: 0.9rem;
+}
+.algolia-autocomplete .aa-dropdown-menu .aa-suggestion.aa-cursor {
+  background-color: #B2D7FF;
+}
+
+/* Code ------------------------------------------------ */
+
+pre {
+  position: relative;
+  overflow: auto;
+  border: 1px solid #eee;
+  padding: 0.5rem;
+  margin: 0 -0.5rem 1rem -0.5rem;
+  background-image: linear-gradient(160deg,#f8f8f8 0,#f1f1f1 100%);
+}
+
+@media (max-width: 767.98px) {
+  /* Make background span full width on mobile */
+  .section > .sourceCode > pre {
+    margin: 0 -1rem 1rem -1rem;
+    padding: 0.5rem 1rem;
+    width: 100vw;
+  }
+}
+
+code {
+  background-color: #f8f8f8;
+}
+
+pre code {
+  background-color: transparent;
+  word-break: normal; /* force wide blocks to scroll, not wrap */
+  word-wrap: normal;
+}
+
+pre, code {
+  border-radius: 0.2rem;
+  color: #212529; /* match text colour */
+}
+code a:any-link {
+  color: inherit; /* use colour from syntax highlighting */
+  text-decoration: underline;
+  text-decoration-color: #ccc;
+}
+
+/* copy button */
+
+div.sourceCode {
+  position: relative;
+}
+
+.btn-copy {
+  position: absolute;
+  top: 0rem;
+  right: -0.5rem; /* coherent with pre margin rule */
+}
+
+div.sourceCode > button {
+  filter: opacity(50%);
+}
+
+div.sourceCode > button:hover {
+  filter: opacity(100%);
+}
+
+div.sourceCode > button > i.bi::before {
+  display: inline-block;
+  height: 1rem;
+  width: 1rem;
+  content: """";
+  vertical-align: -0.125em;
+  background-image: url('data:image/svg+xml,<svg xmlns=""http://www.w3.org/2000/svg"" width=""16"" height=""16"" fill=""currentColor"" viewBox=""0 0 16 16""><path d=""M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z""/><path d=""M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z""/></svg>');
+  background-repeat: no-repeat;
+  background-size: 1rem 1rem;
+}
+
+div.sourceCode > button.btn-copy-checked > .bi::before {
+  background-image: url('data:image/svg+xml,<svg xmlns=""http://www.w3.org/2000/svg"" width=""16"" height=""16"" fill=""currentColor"" viewBox=""0 0 16 16""><path d=""M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z""/></svg>');
+}
+
+/* https://github.com/rstudio/distill/blob/master/inst/rmarkdown/templates/distill_article/resources/a11y.theme + https://gist.github.com/hadley/f53b6e92df20994fdabe6562d284728a */
+code span.ot {color:#007faa}
+code span.at {color:#7d9029}
+code span.ss {color:#bb6688}
+code span.an {color:#545454;}
+code span.fu {color:#4254A7}
+code span.st {color:#008000}
+code span.cf {color:#007faa;}
+code span.op {color:#696969}
+code span.er {color:#ff0000;}
+code span.bn {color:#a1024a}
+code span.al {color:#ff0000;}
+code span.va {color:#19177c}
+code span.bu {color: #007faa;}
+code span.ex {}
+code span.pp {color:#bc7a00}
+code span.in {color:#545454;}
+code span.vs {color:#008000}
+code span.wa {color:#545454; font-style: italic}
+code span.do {color:#ba2121; font-style: italic}
+code span.im {color:#007faa; font-weight: bold;}
+code span.ch {color:#008000}
+code span.dt {color:#aa5d00}
+code span.fl {color:#a1024a}
+code span.co {color:#545454}
+code span.cv {color:#545454; font-style: italic}
+code span.cn {color:#d91e18}
+code span.sc {color:#008000}
+code span.dv {color:#a1024a}
+code span.kw {color:#007faa}
+
+/* Misc typography ---------------------------------------------- */
+
+a {
+  overflow-wrap: break-word;
+  word-wrap: break-word;
+}
+
+blockquote {
+  border-left: 0.5rem solid #eee;
+  padding-left: 0.5rem;
+  margin-left: -0.5rem;
+}
+
+body {
+  line-height: 1.6;
+}
+
+.smallcaps {
+  font-variant: small-caps;
+}
+
+/* special callout blocks */
+
+.rmdnote, .rmdcaution, .rmdimportant, .rmdtip, .rmdwarning {
+  margin: 1rem calc(-2px - 0.5em);
+  padding: 1rem;
+  border: 2px solid #eee;
+}
+
+.rmdnote > *:last-child, .rmdcaution > *:last-child, .rmdimportant > *:last-child, .rmdtip > *:last-child, .rmdwarning > *:last-child {
+  margin-bottom: 0;
+}
+
+@media (max-width: 767.98px) {
+  .rmdnote, .rmdcaution, .rmdimportant, .rmdtip, .rmdwarning {
+    margin: 1rem -1rem;
+    border-width: 4px;
+  }
+}
+
+.rmdnote {
+  border-color: var(--primary);
+}
+.rmdimportant {
+  border-color: var(--success);
+}
+.rmdcaution {
+  border-color: var(--danger);
+}
+.rmdwarning {
+  border-color: var(--warning);
+}
+.rmdtip {
+  border-color: var(--info);
+}
+
+.rmdcaution pre, .rmdimportant pre, .rmdnote pre, .rmdtip pre, .rmdwarning pre {
+  /* Make code blocks full width in rmdnote */
+  margin: 0 -1rem 1rem -1rem;
+  padding: 1rem;
+}
+
+.rmdcaution .btn-copy, .rmdimportant .btn-copy, .rmdnote .btn-copy, .rmdtip .btn-copy, .rmdwarning .btn-copy {
+  /* Needs to be set according to margin in callout pre block */
+  right: -1rem;
+}
+
+main ul {
+ list-style-type: square;
+}
+main ol, main ul {
+  padding-left: 25px;
+  margin-bottom: 0;
+}
+main li {
+  margin-bottom: 0.5rem;
+}
+main ol > li:first-child, main ul > li:first-child {
+  margin-top: 0.5rem;
+}
+
+/* Cover image */
+
+img.cover {
+  float: right;
+  margin: 0 1rem 0 1rem;
+  box-shadow: 0 .5rem 1rem rgba(0,0,0,.15);
+}
+@media (max-width: 767.98px) {
+  img.cover {
+    float: none;
+    display: block;
+    margin: 0 auto 1rem auto;
+  }
+}

---FILE: docs/libs/bs4_book-1.0.0/bs4_book.js---
@@ -0,0 +1,136 @@
+$(function () {
+  var url = new URL(window.location.href);
+  var toMark = url.searchParams.get(""q"");
+  var mark = new Mark(""main"");
+  if (toMark) {
+    mark.mark(toMark, {
+      accuracy: {
+        value: ""complementary"",
+        limiters: ["","", ""."", "":"", ""/""],
+      }
+    });
+  }
+
+  // Activate popovers
+  $('[data-toggle=""popover""]').popover({
+    container: 'body',
+    html: true,
+    trigger: 'focus',
+    placement: ""top"",
+    sanitize: false,
+  });
+  $('[data-toggle=""tooltip""]').tooltip();
+})
+
+// Search ----------------------------------------------------------------------
+
+var fuse;
+
+$(function () {
+  // Initialise search index on focus
+  $(""#search"").focus(async function(e) {
+    if (fuse) {
+      return;
+    }
+
+    $(e.target).addClass(""loading"");
+
+    var response = await fetch('search.json');
+    var data = await response.json();
+
+    var options = {
+      keys: [""heading"", ""text"", ""code""],
+      ignoreLocation: true,
+      threshold: 0.1,
+      includeMatches: true,
+      includeScore: true,
+    };
+    fuse = new Fuse(data, options);
+
+    $(e.target).removeClass(""loading"");
+  });
+
+  // Use algolia autocomplete
+  var options = {
+    autoselect: true,
+    debug: true,
+    hint: false,
+    minLength: 2,
+  };
+
+  $(""#search"").autocomplete(options, [
+    {
+      name: ""content"",
+      source: searchFuse,
+      templates: {
+        suggestion: (s) => {
+          if (s.chapter == s.heading) {
+            return `${s.chapter}`;
+          } else {
+            return `${s.chapter} /<br> ${s.heading}`;
+          }
+        },
+      },
+    },
+  ]).on('autocomplete:selected', function(event, s) {
+    window.location.href = s.path + ""?q="" + q + ""#"" + s.id;
+  });
+});
+
+var q;
+async function searchFuse(query, callback) {
+  await fuse;
+
+  var items;
+  if (!fuse) {
+    items = [];
+  } else {
+    q = query;
+    var results = fuse.search(query, { limit: 20 });
+    items = results
+      .filter((x) => x.score <= 0.75)
+      .map((x) => x.item);
+  }
+
+  callback(items);
+}
+
+// Copy to clipboard -----------------------------------------------------------
+
+function changeTooltipMessage(element, msg) {
+  var tooltipOriginalTitle=element.getAttribute('data-original-title');
+  element.setAttribute('data-original-title', msg);
+  $(element).tooltip('show');
+  element.setAttribute('data-original-title', tooltipOriginalTitle);
+}
+
+$(document).ready(function() {
+  if(ClipboardJS.isSupported()) {
+    // Insert copy buttons
+    var copyButton = ""<button type='button' class='btn btn-copy' title='Copy to clipboard' aria-label='Copy to clipboard' data-toggle='popover' data-placement='top' data-trigger='hover'><i class='bi'></i></button>"";
+    $(copyButton).appendTo(""div.sourceCode"");
+    // Initialize tooltips:
+    $('.btn-copy').tooltip({container: 'body', boundary: 'window'});
+
+    // Initialize clipboard:
+    var clipboard = new ClipboardJS('.btn-copy', {
+      text: function(trigger) {
+        return trigger.parentNode.textContent;
+      }
+    });
+
+    clipboard.on('success', function(e) {
+      const btn = e.trigger;
+      changeTooltipMessage(btn, 'Copied!');
+      btn.classList.add('btn-copy-checked');
+      setTimeout(function() {
+        btn.classList.remove('btn-copy-checked');
+      }, 2000);
+      e.clearSelection();
+    });
+
+    clipboard.on('error', function() {
+      changeTooltipMessage(e.trigger,'Press Ctrl+C or Command+C to copy');
+    });
+  };
+});

---FILE: docs/libs/jquery-3.6.0/jquery-3.6.0.min.js---
@@ -0,0 +1,2 @@
+/*! jQuery v3.6.0 | (c) OpenJS Foundation and other contributors | jquery.org/license */
+!function(e,t){""use strict"";""object""==typeof module&&""object""==typeof module.exports?module.exports=e.document?t(e,!0):function(e){if(!e.document)throw new Error(""jQuery requires a window with a document"");return t(e)}:t(e)}(""undefined""!=typeof window?window:this,function(C,e){""use strict"";var t=[],r=Object.getPrototypeOf,s=t.slice,g=t.flat?function(e){return t.flat.call(e)}:function(e){return t.concat.apply([],e)},u=t.push,i=t.indexOf,n={},o=n.toString,v=n.hasOwnProperty,a=v.toString,l=a.call(Object),y={},m=function(e){return""function""==typeof e&&""number""!=typeof e.nodeType&&""function""!=typeof e.item},x=function(e){return null!=e&&e===e.window},E=C.document,c={type:!0,src:!0,nonce:!0,noModule:!0};function b(e,t,n){var r,i,o=(n=n||E).createElement(""script"");if(o.text=e,t)for(r in c)(i=t[r]||t.getAttribute&&t.getAttribute(r))&&o.setAttribute(r,i);n.head.appendChild(o).parentNode.removeChild(o)}function w(e){return null==e?e+"""":""object""==typeof e||""function""==typeof e?n[o.call(e)]||""object"":typeof e}var f=""3.6.0"",S=function(e,t){return new S.fn.init(e,t)};function p(e){var t=!!e&&""length""in e&&e.length,n=w(e);return!m(e)&&!x(e)&&(""array""===n||0===t||""number""==typeof t&&0<t&&t-1 in e)}S.fn=S.prototype={jquery:f,constructor:S,length:0,toArray:function(){return s.call(this)},get:function(e){return null==e?s.call(this):e<0?this[e+this.length]:this[e]},pushStack:function(e){var t=S.merge(this.constructor(),e);return t.prevObject=this,t},each:function(e){return S.each(this,e)},map:function(n){return this.pushStack(S.map(this,function(e,t){return n.call(e,t,e)}))},slice:function(){return this.pushStack(s.apply(this,arguments))},first:function(){return this.eq(0)},last:function(){return this.eq(-1)},even:function(){return this.pushStack(S.grep(this,function(e,t){return(t+1)%2}))},odd:function(){return this.pushStack(S.grep(this,function(e,t){return t%2}))},eq:function(e){var t=this.length,n=+e+(e<0?t:0);return this.pushStack(0<=n&&n<t?[this[n]]:[])},end:function(){return this.prevObject||this.constructor()},push:u,sort:t.sort,splice:t.splice},S.extend=S.fn.extend=function(){var e,t,n,r,i,o,a=arguments[0]||{},s=1,u=arguments.length,l=!1;for(""boolean""==typeof a&&(l=a,a=arguments[s]||{},s++),""object""==typeof a||m(a)||(a={}),s===u&&(a=this,s--);s<u;s++)if(null!=(e=arguments[s]))for(t in e)r=e[t],""__proto__""!==t&&a!==r&&(l&&r&&(S.isPlainObject(r)||(i=Array.isArray(r)))?(n=a[t],o=i&&!Array.isArray(n)?[]:i||S.isPlainObject(n)?n:{},i=!1,a[t]=S.extend(l,o,r)):void 0!==r&&(a[t]=r));return a},S.extend({expando:""jQuery""+(f+Math.random()).replace(/\D/g,""""),isReady:!0,error:function(e){throw new Error(e)},noop:function(){},isPlainObject:function(e){var t,n;return!(!e||""[object Object]""!==o.call(e))&&(!(t=r(e))||""function""==typeof(n=v.call(t,""constructor"")&&t.constructor)&&a.call(n)===l)},isEmptyObject:function(e){var t;for(t in e)return!1;return!0},globalEval:function(e,t,n){b(e,{nonce:t&&t.nonce},n)},each:function(e,t){var n,r=0;if(p(e)){for(n=e.length;r<n;r++)if(!1===t.call(e[r],r,e[r]))break}else for(r in e)if(!1===t.call(e[r],r,e[r]))break;return e},makeArray:function(e,t){var n=t||[];return null!=e&&(p(Object(e))?S.merge(n,""string""==typeof e?[e]:e):u.call(n,e)),n},inArray:function(e,t,n){return null==t?-1:i.call(t,e,n)},merge:function(e,t){for(var n=+t.length,r=0,i=e.length;r<n;r++)e[i++]=t[r];return e.length=i,e},grep:function(e,t,n){for(var r=[],i=0,o=e.length,a=!n;i<o;i++)!t(e[i],i)!==a&&r.push(e[i]);return r},map:function(e,t,n){var r,i,o=0,a=[];if(p(e))for(r=e.length;o<r;o++)null!=(i=t(e[o],o,n))&&a.push(i);else for(o in e)null!=(i=t(e[o],o,n))&&a.push(i);return g(a)},guid:1,support:y}),""function""==typeof Symbol&&(S.fn[Symbol.iterator]=t[Symbol.iterator]),S.each(""Boolean Number String Function Array Date RegExp Object Error Symbol"".split("" ""),function(e,t){n[""[object ""+t+""]""]=t.toLowerCase()});var d=function(n){var e,d,b,o,i,h,f,g,w,u,l,T,C,a,E,v,s,c,y,S=""sizzle""+1*new Date,p=n.document,k=0,r=0,m=ue(),x=ue(),A=ue(),N=ue(),j=function(e,t){return e===t&&(l=!0),0},D={}.hasOwnProperty,t=[],q=t.pop,L=t.push,H=t.push,O=t.slice,P=function(e,t){for(var n=0,r=e.length;n<r;n++)if(e[n]===t)return n;return-1},R=""checked|selected|async|autofocus|autoplay|controls|defer|disabled|hidden|ismap|loop|multiple|open|readonly|required|scoped"",M=""[\\x20\\t\\r\\n\\f]"",I=""(?:\\\\[\\da-fA-F]{1,6}""+M+""?|\\\\[^\\r\\n\\f]|[\\w-]|[^\0-\\x7f])+"",W=""\\[""+M+""*(""+I+"")(?:""+M+""*([*^$|!~]?=)""+M+""*(?:'((?:\\\\.|[^\\\\'])*)'|\""((?:\\\\.|[^\\\\\""])*)\""|(""+I+""))|)""+M+""*\\]"",F="":(""+I+"")(?:\\((('((?:\\\\.|[^\\\\'])*)'|\""((?:\\\\.|[^\\\\\""])*)\"")|((?:\\\\.|[^\\\\()[\\]]|""+W+"")*)|.*)\\)|)"",B=new RegExp(M+""+"",""g""),$=new RegExp(""^""+M+""+|((?:^|[^\\\\])(?:\\\\.)*)""+M+""+$"",""g""),_=new RegExp(""^""+M+""*,""+M+""*""),z=new RegExp(""^""+M+""*([>+~]|""+M+"")""+M+""*""),U=new RegExp(M+""|>""),X=new RegExp(F),V=new RegExp(""^""+I+""$""),G={ID:new RegExp(""^#(""+I+"")""),CLASS:new RegExp(""^\\.(""+I+"")""),TAG:new RegExp(""^(""+I+""|[*])""),ATTR:new RegExp(""^""+W),PSEUDO:new RegExp(""^""+F),CHILD:new RegExp(""^:(only|first|last|nth|nth-last)-(child|of-type)(?:\\(""+M+""*(even|odd|(([+-]|)(\\d*)n|)""+M+""*(?:([+-]|)""+M+""*(\\d+)|))""+M+""*\\)|)"",""i""),bool:new RegExp(""^(?:""+R+"")$"",""i""),needsContext:new RegExp(""^""+M+""*[>+~]|:(even|odd|eq|gt|lt|nth|first|last)(?:\\(""+M+""*((?:-\\d)?\\d*)""+M+""*\\)|)(?=[^-]|$)"",""i"")},Y=/HTML$/i,Q=/^(?:input|select|textarea|button)$/i,J=/^h\d$/i,K=/^[^{]+\{\s*\[native \w/,Z=/^(?:#([\w-]+)|(\w+)|\.([\w-]+))$/,ee=/[+~]/,te=new RegExp(""\\\\[\\da-fA-F]{1,6}""+M+""?|\\\\([^\\r\\n\\f])"",""g""),ne=function(e,t){var n=""0x""+e.slice(1)-65536;return t||(n<0?String.fromCharCode(n+65536):String.fromCharCode(n>>10|55296,1023&n|56320))},re=/([\0-\x1f\x7f]|^-?\d)|^-$|[^\0-\x1f\x7f-\uFFFF\w-]/g,ie=function(e,t){return t?""\0""===e?""\ufffd"":e.slice(0,-1)+""\\""+e.charCodeAt(e.length-1).toString(16)+"" "":""\\""+e},oe=function(){T()},ae=be(function(e){return!0===e.disabled&&""fieldset""===e.nodeName.toLowerCase()},{dir:""parentNode"",next:""legend""});try{H.apply(t=O.call(p.childNodes),p.childNodes),t[p.childNodes.length].nodeType}catch(e){H={apply:t.length?function(e,t){L.apply(e,O.call(t))}:function(e,t){var n=e.length,r=0;while(e[n++]=t[r++]);e.length=n-1}}}function se(t,e,n,r){var i,o,a,s,u,l,c,f=e&&e.ownerDocument,p=e?e.nodeType:9;if(n=n||[],""string""!=typeof t||!t||1!==p&&9!==p&&11!==p)return n;if(!r&&(T(e),e=e||C,E)){if(11!==p&&(u=Z.exec(t)))if(i=u[1]){if(9===p){if(!(a=e.getElementById(i)))return n;if(a.id===i)return n.push(a),n}else if(f&&(a=f.getElementById(i))&&y(e,a)&&a.id===i)return n.push(a),n}else{if(u[2])return H.apply(n,e.getElementsByTagName(t)),n;if((i=u[3])&&d.getElementsByClassName&&e.getElementsByClassName)return H.apply(n,e.getElementsByClassName(i)),n}if(d.qsa&&!N[t+"" ""]&&(!v||!v.test(t))&&(1!==p||""object""!==e.nodeName.toLowerCase())){if(c=t,f=e,1===p&&(U.test(t)||z.test(t))){(f=ee.test(t)&&ye(e.parentNode)||e)===e&&d.scope||((s=e.getAttribute(""id""))?s=s.replace(re,ie):e.setAttribute(""id"",s=S)),o=(l=h(t)).length;while(o--)l[o]=(s?""#""+s:"":scope"")+"" ""+xe(l[o]);c=l.join("","")}try{return H.apply(n,f.querySelectorAll(c)),n}catch(e){N(t,!0)}finally{s===S&&e.removeAttribute(""id"")}}}return g(t.replace($,""$1""),e,n,r)}function ue(){var r=[];return function e(t,n){return r.push(t+"" "")>b.cacheLength&&delete e[r.shift()],e[t+"" ""]=n}}function le(e){return e[S]=!0,e}function ce(e){var t=C.createElement(""fieldset"");try{return!!e(t)}catch(e){return!1}finally{t.parentNode&&t.parentNode.removeChild(t),t=null}}function fe(e,t){var n=e.split(""|""),r=n.length;while(r--)b.attrHandle[n[r]]=t}function pe(e,t){var n=t&&e,r=n&&1===e.nodeType&&1===t.nodeType&&e.sourceIndex-t.sourceIndex;if(r)return r;if(n)while(n=n.nextSibling)if(n===t)return-1;return e?1:-1}function de(t){return function(e){return""input""===e.nodeName.toLowerCase()&&e.type===t}}function he(n){return function(e){var t=e.nodeName.toLowerCase();return(""input""===t||""button""===t)&&e.type===n}}function ge(t){return function(e){return""form""in e?e.parentNode&&!1===e.disabled?""label""in e?""label""in e.parentNode?e.parentNode.disabled===t:e.disabled===t:e.isDisabled===t||e.isDisabled!==!t&&ae(e)===t:e.disabled===t:""label""in e&&e.disabled===t}}function ve(a){return le(function(o){return o=+o,le(function(e,t){var n,r=a([],e.length,o),i=r.length;while(i--)e[n=r[i]]&&(e[n]=!(t[n]=e[n]))})})}function ye(e){return e&&""undefined""!=typeof e.getElementsByTagName&&e}for(e in d=se.support={},i=se.isXML=function(e){var t=e&&e.namespaceURI,n=e&&(e.ownerDocument||e).documentElement;return!Y.test(t||n&&n.nodeName||""HTML"")},T=se.setDocument=function(e){var t,n,r=e?e.ownerDocument||e:p;return r!=C&&9===r.nodeType&&r.documentElement&&(a=(C=r).documentElement,E=!i(C),p!=C&&(n=C.defaultView)&&n.top!==n&&(n.addEventListener?n.addEventListener(""unload"",oe,!1):n.attachEvent&&n.attachEvent(""onunload"",oe)),d.scope=ce(function(e){return a.appendChild(e).appendChild(C.createElement(""div"")),""undefined""!=typeof e.querySelectorAll&&!e.querySelectorAll("":scope fieldset div"").length}),d.attributes=ce(function(e){return e.className=""i"",!e.getAttribute(""className"")}),d.getElementsByTagName=ce(function(e){return e.appendChild(C.createComment("""")),!e.getElementsByTagName(""*"").length}),d.getElementsByClassName=K.test(C.getElementsByClassName),d.getById=ce(function(e){return a.appendChild(e).id=S,!C.getElementsByName||!C.getElementsByName(S).length}),d.getById?(b.filter.ID=function(e){var t=e.replace(te,ne);return function(e){return e.getAttribute(""id"")===t}},b.find.ID=function(e,t){if(""undefined""!=typeof t.getElementById&&E){var n=t.getElementById(e);return n?[n]:[]}}):(b.filter.ID=function(e){var n=e.replace(te,ne);return function(e){var t=""undefined""!=typeof e.getAttributeNode&&e.getAttributeNode(""id"");return t&&t.value===n}},b.find.ID=function(e,t){if(""undefined""!=typeof t.getElementById&&E){var n,r,i,o=t.getElementById(e);if(o){if((n=o.getAttributeNode(""id""))&&n.value===e)return[o];i=t.getElementsByName(e),r=0;while(o=i[r++])if((n=o.getAttributeNode(""id""))&&n.value===e)return[o]}return[]}}),b.find.TAG=d.getElementsByTagName?function(e,t){return""undefined""!=typeof t.getElementsByTagName?t.getElementsByTagName(e):d.qsa?t.querySelectorAll(e):void 0}:function(e,t){var n,r=[],i=0,o=t.getElementsByTagName(e);if(""*""===e){while(n=o[i++])1===n.nodeType&&r.push(n);return r}return o},b.find.CLASS=d.getElementsByClassName&&function(e,t){if(""undefined""!=typeof t.getElementsByClassName&&E)return t.getElementsByClassName(e)},s=[],v=[],(d.qsa=K.test(C.querySelectorAll))&&(ce(function(e){var t;a.appendChild(e).innerHTML=""<a id='""+S+""'></a><select id='""+S+""-\r\\' msallowcapture=''><option selected=''></option></select>"",e.querySelectorAll(""[msallowcapture^='']"").length&&v.push(""[*^$]=""+M+""*(?:''|\""\"")""),e.querySelectorAll(""[selected]"").length||v.push(""\\[""+M+""*(?:value|""+R+"")""),e.querySelectorAll(""[id~=""+S+""-]"").length||v.push(""~=""),(t=C.createElement(""input"")).setAttribute(""name"",""""),e.appendChild(t),e.querySelectorAll(""[name='']"").length||v.push(""\\[""+M+""*name""+M+""*=""+M+""*(?:''|\""\"")""),e.querySelectorAll("":checked"").length||v.push("":checked""),e.querySelectorAll(""a#""+S+""+*"").length||v.push("".#.+[+~]""),e.querySelectorAll(""\\\f""),v.push(""[\\r\\n\\f]"")}),ce(function(e){e.innerHTML=""<a href='' disabled='disabled'></a><select disabled='disabled'><option/></select>"";var t=C.createElement(""input"");t.setAttribute(""type"",""hidden""),e.appendChild(t).setAttribute(""name"",""D""),e.querySelectorAll(""[name=d]"").length&&v.push(""name""+M+""*[*^$|!~]?=""),2!==e.querySelectorAll("":enabled"").length&&v.push("":enabled"","":disabled""),a.appendChild(e).disabled=!0,2!==e.querySelectorAll("":disabled"").length&&v.push("":enabled"","":disabled""),e.querySelectorAll(""*,:x""),v.push("",.*:"")})),(d.matchesSelector=K.test(c=a.matches||a.webkitMatchesSelector||a.mozMatchesSelector||a.oMatchesSelector||a.msMatchesSelector))&&ce(function(e){d.disconnectedMatch=c.call(e,""*""),c.call(e,""[s!='']:x""),s.push(""!="",F)}),v=v.length&&new RegExp(v.join(""|"")),s=s.length&&new RegExp(s.join(""|"")),t=K.test(a.compareDocumentPosition),y=t||K.test(a.contains)?function(e,t){var n=9===e.nodeType?e.documentElement:e,r=t&&t.parentNode;return e===r||!(!r||1!==r.nodeType||!(n.contains?n.contains(r):e.compareDocumentPosition&&16&e.compareDocumentPosition(r)))}:function(e,t){if(t)while(t=t.parentNode)if(t===e)return!0;return!1},j=t?function(e,t){if(e===t)return l=!0,0;var n=!e.compareDocumentPosition-!t.compareDocumentPosition;return n||(1&(n=(e.ownerDocument||e)==(t.ownerDocument||t)?e.compareDocumentPosition(t):1)||!d.sortDetached&&t.compareDocumentPosition(e)===n?e==C||e.ownerDocument==p&&y(p,e)?-1:t==C||t.ownerDocument==p&&y(p,t)?1:u?P(u,e)-P(u,t):0:4&n?-1:1)}:function(e,t){if(e===t)return l=!0,0;var n,r=0,i=e.parentNode,o=t.parentNode,a=[e],s=[t];if(!i||!o)return e==C?-1:t==C?1:i?-1:o?1:u?P(u,e)-P(u,t):0;if(i===o)return pe(e,t);n=e;while(n=n.parentNode)a.unshift(n);n=t;while(n=n.parentNode)s.unshift(n);while(a[r]===s[r])r++;return r?pe(a[r],s[r]):a[r]==p?-1:s[r]==p?1:0}),C},se.matches=function(e,t){return se(e,null,null,t)},se.matchesSelector=function(e,t){if(T(e),d.matchesSelector&&E&&!N[t+"" ""]&&(!s||!s.test(t))&&(!v||!v.test(t)))try{var n=c.call(e,t);if(n||d.disconnectedMatch||e.document&&11!==e.document.nodeType)return n}catch(e){N(t,!0)}return 0<se(t,C,null,[e]).length},se.contains=function(e,t){return(e.ownerDocument||e)!=C&&T(e),y(e,t)},se.attr=function(e,t){(e.ownerDocument||e)!=C&&T(e);var n=b.attrHandle[t.toLowerCase()],r=n&&D.call(b.attrHandle,t.toLowerCase())?n(e,t,!E):void 0;return void 0!==r?r:d.attributes||!E?e.getAttribute(t):(r=e.getAttributeNode(t))&&r.specified?r.value:null},se.escape=function(e){return(e+"""").replace(re,ie)},se.error=function(e){throw new Error(""Syntax error, unrecognized expression: ""+e)},se.uniqueSort=function(e){var t,n=[],r=0,i=0;if(l=!d.detectDuplicates,u=!d.sortStable&&e.slice(0),e.sort(j),l){while(t=e[i++])t===e[i]&&(r=n.push(i));while(r--)e.splice(n[r],1)}return u=null,e},o=se.getText=function(e){var t,n="""",r=0,i=e.nodeType;if(i){if(1===i||9===i||11===i){if(""string""==typeof e.textContent)return e.textContent;for(e=e.firstChild;e;e=e.nextSibling)n+=o(e)}else if(3===i||4===i)return e.nodeValue}else while(t=e[r++])n+=o(t);return n},(b=se.selectors={cacheLength:50,createPseudo:le,match:G,attrHandle:{},find:{},relative:{"">"":{dir:""parentNode"",first:!0},"" "":{dir:""parentNode""},""+"":{dir:""previousSibling"",first:!0},""~"":{dir:""previousSibling""}},preFilter:{ATTR:function(e){return e[1]=e[1].replace(te,ne),e[3]=(e[3]||e[4]||e[5]||"""").replace(te,ne),""~=""===e[2]&&(e[3]="" ""+e[3]+"" ""),e.slice(0,4)},CHILD:function(e){return e[1]=e[1].toLowerCase(),""nth""===e[1].slice(0,3)?(e[3]||se.error(e[0]),e[4]=+(e[4]?e[5]+(e[6]||1):2*(""even""===e[3]||""odd""===e[3])),e[5]=+(e[7]+e[8]||""odd""===e[3])):e[3]&&se.error(e[0]),e},PSEUDO:function(e){var t,n=!e[6]&&e[2];return G.CHILD.test(e[0])?null:(e[3]?e[2]=e[4]||e[5]||"""":n&&X.test(n)&&(t=h(n,!0))&&(t=n.indexOf("")"",n.length-t)-n.length)&&(e[0]=e[0].slice(0,t),e[2]=n.slice(0,t)),e.slice(0,3))}},filter:{TAG:function(e){var t=e.replace(te,ne).toLowerCase();return""*""===e?function(){return!0}:function(e){return e.nodeName&&e.nodeName.toLowerCase()===t}},CLASS:function(e){var t=m[e+"" ""];return t||(t=new RegExp(""(^|""+M+"")""+e+""(""+M+""|$)""))&&m(e,function(e){return t.test(""string""==typeof e.className&&e.className||""undefined""!=typeof e.getAttribute&&e.getAttribute(""class"")||"""")})},ATTR:function(n,r,i){return function(e){var t=se.attr(e,n);return null==t?""!=""===r:!r||(t+="""",""=""===r?t===i:""!=""===r?t!==i:""^=""===r?i&&0===t.indexOf(i):""*=""===r?i&&-1<t.indexOf(i):""$=""===r?i&&t.slice(-i.length)===i:""~=""===r?-1<("" ""+t.replace(B,"" "")+"" "").indexOf(i):""|=""===r&&(t===i||t.slice(0,i.length+1)===i+""-""))}},CHILD:function(h,e,t,g,v){var y=""nth""!==h.slice(0,3),m=""last""!==h.slice(-4),x=""of-type""===e;return 1===g&&0===v?function(e){return!!e.parentNode}:function(e,t,n){var r,i,o,a,s,u,l=y!==m?""nextSibling"":""previousSibling"",c=e.parentNode,f=x&&e.nodeName.toLowerCase(),p=!n&&!x,d=!1;if(c){if(y){while(l){a=e;while(a=a[l])if(x?a.nodeName.toLowerCase()===f:1===a.nodeType)return!1;u=l=""only""===h&&!u&&""nextSibling""}return!0}if(u=[m?c.firstChild:c.lastChild],m&&p){d=(s=(r=(i=(o=(a=c)[S]||(a[S]={}))[a.uniqueID]||(o[a.uniqueID]={}))[h]||[])[0]===k&&r[1])&&r[2],a=s&&c.childNodes[s];while(a=++s&&a&&a[l]||(d=s=0)||u.pop())if(1===a.nodeType&&++d&&a===e){i[h]=[k,s,d];break}}else if(p&&(d=s=(r=(i=(o=(a=e)[S]||(a[S]={}))[a.uniqueID]||(o[a.uniqueID]={}))[h]||[])[0]===k&&r[1]),!1===d)while(a=++s&&a&&a[l]||(d=s=0)||u.pop())if((x?a.nodeName.toLowerCase()===f:1===a.nodeType)&&++d&&(p&&((i=(o=a[S]||(a[S]={}))[a.uniqueID]||(o[a.uniqueID]={}))[h]=[k,d]),a===e))break;return(d-=v)===g||d%g==0&&0<=d/g}}},PSEUDO:function(e,o){var t,a=b.pseudos[e]||b.setFilters[e.toLowerCase()]||se.error(""unsupported pseudo: ""+e);return a[S]?a(o):1<a.length?(t=[e,e,"""",o],b.setFilters.hasOwnProperty(e.toLowerCase())?le(function(e,t){var n,r=a(e,o),i=r.length;while(i--)e[n=P(e,r[i])]=!(t[n]=r[i])}):function(e){return a(e,0,t)}):a}},pseudos:{not:le(function(e){var r=[],i=[],s=f(e.replace($,""$1""));return s[S]?le(function(e,t,n,r){var i,o=s(e,null,r,[]),a=e.length;while(a--)(i=o[a])&&(e[a]=!(t[a]=i))}):function(e,t,n){return r[0]=e,s(r,null,n,i),r[0]=null,!i.pop()}}),has:le(function(t){return function(e){return 0<se(t,e).length}}),contains:le(function(t){return t=t.replace(te,ne),function(e){return-1<(e.textContent||o(e)).indexOf(t)}}),lang:le(function(n){return V.test(n||"""")||se.error(""unsupported lang: ""+n),n=n.replace(te,ne).toLowerCase(),function(e){var t;do{if(t=E?e.lang:e.getAttribute(""xml:lang"")||e.getAttribute(""lang""))return(t=t.toLowerCase())===n||0===t.indexOf(n+""-"")}while((e=e.parentNode)&&1===e.nodeType);return!1}}),target:function(e){var t=n.location&&n.location.hash;return t&&t.slice(1)===e.id},root:function(e){return e===a},focus:function(e){return e===C.activeElement&&(!C.hasFocus||C.hasFocus())&&!!(e.type||e.href||~e.tabIndex)},enabled:ge(!1),disabled:ge(!0),checked:function(e){var t=e.nodeName.toLowerCase();return""input""===t&&!!e.checked||""option""===t&&!!e.selected},selected:function(e){return e.parentNode&&e.parentNode.selectedIndex,!0===e.selected},empty:function(e){for(e=e.firstChild;e;e=e.nextSibling)if(e.nodeType<6)return!1;return!0},parent:function(e){return!b.pseudos.empty(e)},header:function(e){return J.test(e.nodeName)},input:function(e){return Q.test(e.nodeName)},button:function(e){var t=e.nodeName.toLowerCase();return""input""===t&&""button""===e.type||""button""===t},text:function(e){var t;return""input""===e.nodeName.toLowerCase()&&""text""===e.type&&(null==(t=e.getAttribute(""type""))||""text""===t.toLowerCase())},first:ve(function(){return[0]}),last:ve(function(e,t){return[t-1]}),eq:ve(function(e,t,n){return[n<0?n+t:n]}),even:ve(function(e,t){for(var n=0;n<t;n+=2)e.push(n);return e}),odd:ve(function(e,t){for(var n=1;n<t;n+=2)e.push(n);return e}),lt:ve(function(e,t,n){for(var r=n<0?n+t:t<n?t:n;0<=--r;)e.push(r);return e}),gt:ve(function(e,t,n){for(var r=n<0?n+t:n;++r<t;)e.push(r);return e})}}).pseudos.nth=b.pseudos.eq,{radio:!0,checkbox:!0,file:!0,password:!0,image:!0})b.pseudos[e]=de(e);for(e in{submit:!0,reset:!0})b.pseudos[e]=he(e);function me(){}function xe(e){for(var t=0,n=e.length,r="""";t<n;t++)r+=e[t].value;return r}function be(s,e,t){var u=e.dir,l=e.next,c=l||u,f=t&&""parentNode""===c,p=r++;return e.first?function(e,t,n){while(e=e[u])if(1===e.nodeType||f)return s(e,t,n);return!1}:function(e,t,n){var r,i,o,a=[k,p];if(n){while(e=e[u])if((1===e.nodeType||f)&&s(e,t,n))return!0}else while(e=e[u])if(1===e.nodeType||f)if(i=(o=e[S]||(e[S]={}))[e.uniqueID]||(o[e.uniqueID]={}),l&&l===e.nodeName.toLowerCase())e=e[u]||e;else{if((r=i[c])&&r[0]===k&&r[1]===p)return a[2]=r[2];if((i[c]=a)[2]=s(e,t,n))return!0}return!1}}function we(i){return 1<i.length?function(e,t,n){var r=i.length;while(r--)if(!i[r](e,t,n))return!1;return!0}:i[0]}function Te(e,t,n,r,i){for(var o,a=[],s=0,u=e.length,l=null!=t;s<u;s++)(o=e[s])&&(n&&!n(o,r,i)||(a.push(o),l&&t.push(s)));return a}function Ce(d,h,g,v,y,e){return v&&!v[S]&&(v=Ce(v)),y&&!y[S]&&(y=Ce(y,e)),le(function(e,t,n,r){var i,o,a,s=[],u=[],l=t.length,c=e||function(e,t,n){for(var r=0,i=t.length;r<i;r++)se(e,t[r],n);return n}(h||""*"",n.nodeType?[n]:n,[]),f=!d||!e&&h?c:Te(c,s,d,n,r),p=g?y||(e?d:l||v)?[]:t:f;if(g&&g(f,p,n,r),v){i=Te(p,u),v(i,[],n,r),o=i.length;while(o--)(a=i[o])&&(p[u[o]]=!(f[u[o]]=a))}if(e){if(y||d){if(y){i=[],o=p.length;while(o--)(a=p[o])&&i.push(f[o]=a);y(null,p=[],i,r)}o=p.length;while(o--)(a=p[o])&&-1<(i=y?P(e,a):s[o])&&(e[i]=!(t[i]=a))}}else p=Te(p===t?p.splice(l,p.length):p),y?y(null,t,p,r):H.apply(t,p)})}function Ee(e){for(var i,t,n,r=e.length,o=b.relative[e[0].type],a=o||b.relative["" ""],s=o?1:0,u=be(function(e){return e===i},a,!0),l=be(function(e){return-1<P(i,e)},a,!0),c=[function(e,t,n){var r=!o&&(n||t!==w)||((i=t).nodeType?u(e,t,n):l(e,t,n));return i=null,r}];s<r;s++)if(t=b.relative[e[s].type])c=[be(we(c),t)];else{if((t=b.filter[e[s].type].apply(null,e[s].matches))[S]){for(n=++s;n<r;n++)if(b.relative[e[n].type])break;return Ce(1<s&&we(c),1<s&&xe(e.slice(0,s-1).concat({value:"" ""===e[s-2].type?""*"":""""})).replace($,""$1""),t,s<n&&Ee(e.slice(s,n)),n<r&&Ee(e=e.slice(n)),n<r&&xe(e))}c.push(t)}return we(c)}return me.prototype=b.filters=b.pseudos,b.setFilters=new me,h=se.tokenize=function(e,t){var n,r,i,o,a,s,u,l=x[e+"" ""];if(l)return t?0:l.slice(0);a=e,s=[],u=b.preFilter;while(a){for(o in n&&!(r=_.exec(a))||(r&&(a=a.slice(r[0].length)||a),s.push(i=[])),n=!1,(r=z.exec(a))&&(n=r.shift(),i.push({value:n,type:r[0].replace($,"" "")}),a=a.slice(n.length)),b.filter)!(r=G[o].exec(a))||u[o]&&!(r=u[o](r))||(n=r.shift(),i.push({value:n,type:o,matches:r}),a=a.slice(n.length));if(!n)break}return t?a.length:a?se.error(e):x(e,s).slice(0)},f=se.compile=function(e,t){var n,v,y,m,x,r,i=[],o=[],a=A[e+"" ""];if(!a){t||(t=h(e)),n=t.length;while(n--)(a=Ee(t[n]))[S]?i.push(a):o.push(a);(a=A(e,(v=o,m=0<(y=i).length,x=0<v.length,r=function(e,t,n,r,i){var o,a,s,u=0,l=""0"",c=e&&[],f=[],p=w,d=e||x&&b.find.TAG(""*"",i),h=k+=null==p?1:Math.random()||.1,g=d.length;for(i&&(w=t==C||t||i);l!==g&&null!=(o=d[l]);l++){if(x&&o){a=0,t||o.ownerDocument==C||(T(o),n=!E);while(s=v[a++])if(s(o,t||C,n)){r.push(o);break}i&&(k=h)}m&&((o=!s&&o)&&u--,e&&c.push(o))}if(u+=l,m&&l!==u){a=0;while(s=y[a++])s(c,f,t,n);if(e){if(0<u)while(l--)c[l]||f[l]||(f[l]=q.call(r));f=Te(f)}H.apply(r,f),i&&!e&&0<f.length&&1<u+y.length&&se.uniqueSort(r)}return i&&(k=h,w=p),c},m?le(r):r))).selector=e}return a},g=se.select=function(e,t,n,r){var i,o,a,s,u,l=""function""==typeof e&&e,c=!r&&h(e=l.selector||e);if(n=n||[],1===c.length){if(2<(o=c[0]=c[0].slice(0)).length&&""ID""===(a=o[0]).type&&9===t.nodeType&&E&&b.relative[o[1].type]){if(!(t=(b.find.ID(a.matches[0].replace(te,ne),t)||[])[0]))return n;l&&(t=t.parentNode),e=e.slice(o.shift().value.length)}i=G.needsContext.test(e)?0:o.length;while(i--){if(a=o[i],b.relative[s=a.type])break;if((u=b.find[s])&&(r=u(a.matches[0].replace(te,ne),ee.test(o[0].type)&&ye(t.parentNode)||t))){if(o.splice(i,1),!(e=r.length&&xe(o)))return H.apply(n,r),n;break}}}return(l||f(e,c))(r,t,!E,n,!t||ee.test(e)&&ye(t.parentNode)||t),n},d.sortStable=S.split("""").sort(j).join("""")===S,d.detectDuplicates=!!l,T(),d.sortDetached=ce(function(e){return 1&e.compareDocumentPosition(C.createElement(""fieldset""))}),ce(function(e){return e.innerHTML=""<a href='#'></a>"",""#""===e.firstChild.getAttribute(""href"")})||fe(""type|href|height|width"",function(e,t,n){if(!n)return e.getAttribute(t,""type""===t.toLowerCase()?1:2)}),d.attributes&&ce(function(e){return e.innerHTML=""<input/>"",e.firstChild.setAttribute(""value"",""""),""""===e.firstChild.getAttribute(""value"")})||fe(""value"",function(e,t,n){if(!n&&""input""===e.nodeName.toLowerCase())return e.defaultValue}),ce(function(e){return null==e.getAttribute(""disabled"")})||fe(R,function(e,t,n){var r;if(!n)return!0===e[t]?t.toLowerCase():(r=e.getAttributeNode(t))&&r.specified?r.value:null}),se}(C);S.find=d,S.expr=d.selectors,S.expr["":""]=S.expr.pseudos,S.uniqueSort=S.unique=d.uniqueSort,S.text=d.getText,S.isXMLDoc=d.isXML,S.contains=d.contains,S.escapeSelector=d.escape;var h=function(e,t,n){var r=[],i=void 0!==n;while((e=e[t])&&9!==e.nodeType)if(1===e.nodeType){if(i&&S(e).is(n))break;r.push(e)}return r},T=function(e,t){for(var n=[];e;e=e.nextSibling)1===e.nodeType&&e!==t&&n.push(e);return n},k=S.expr.match.needsContext;function A(e,t){return e.nodeName&&e.nodeName.toLowerCase()===t.toLowerCase()}var N=/^<([a-z][^\/\0>:\x20\t\r\n\f]*)[\x20\t\r\n\f]*\/?>(?:<\/\1>|)$/i;function j(e,n,r){return m(n)?S.grep(e,function(e,t){return!!n.call(e,t,e)!==r}):n.nodeType?S.grep(e,function(e){return e===n!==r}):""string""!=typeof n?S.grep(e,function(e){return-1<i.call(n,e)!==r}):S.filter(n,e,r)}S.filter=function(e,t,n){var r=t[0];return n&&(e="":not(""+e+"")""),1===t.length&&1===r.nodeType?S.find.matchesSelector(r,e)?[r]:[]:S.find.matches(e,S.grep(t,function(e){return 1===e.nodeType}))},S.fn.extend({find:function(e){var t,n,r=this.length,i=this;if(""string""!=typeof e)return this.pushStack(S(e).filter(function(){for(t=0;t<r;t++)if(S.contains(i[t],this))return!0}));for(n=this.pushStack([]),t=0;t<r;t++)S.find(e,i[t],n);return 1<r?S.uniqueSort(n):n},filter:function(e){return this.pushStack(j(this,e||[],!1))},not:function(e){return this.pushStack(j(this,e||[],!0))},is:function(e){return!!j(this,""string""==typeof e&&k.test(e)?S(e):e||[],!1).length}});var D,q=/^(?:\s*(<[\w\W]+>)[^>]*|#([\w-]+))$/;(S.fn.init=function(e,t,n){var r,i;if(!e)return this;if(n=n||D,""string""==typeof e){if(!(r=""<""===e[0]&&"">""===e[e.length-1]&&3<=e.length?[null,e,null]:q.exec(e))||!r[1]&&t)return!t||t.jquery?(t||n).find(e):this.constructor(t).find(e);if(r[1]){if(t=t instanceof S?t[0]:t,S.merge(this,S.parseHTML(r[1],t&&t.nodeType?t.ownerDocument||t:E,!0)),N.test(r[1])&&S.isPlainObject(t))for(r in t)m(this[r])?this[r](t[r]):this.attr(r,t[r]);return this}return(i=E.getElementById(r[2]))&&(this[0]=i,this.length=1),this}return e.nodeType?(this[0]=e,this.length=1,this):m(e)?void 0!==n.ready?n.ready(e):e(S):S.makeArray(e,this)}).prototype=S.fn,D=S(E);var L=/^(?:parents|prev(?:Until|All))/,H={children:!0,contents:!0,next:!0,prev:!0};function O(e,t){while((e=e[t])&&1!==e.nodeType);return e}S.fn.extend({has:function(e){var t=S(e,this),n=t.length;return this.filter(function(){for(var e=0;e<n;e++)if(S.contains(this,t[e]))return!0})},closest:function(e,t){var n,r=0,i=this.length,o=[],a=""string""!=typeof e&&S(e);if(!k.test(e))for(;r<i;r++)for(n=this[r];n&&n!==t;n=n.parentNode)if(n.nodeType<11&&(a?-1<a.index(n):1===n.nodeType&&S.find.matchesSelector(n,e))){o.push(n);break}return this.pushStack(1<o.length?S.uniqueSort(o):o)},index:function(e){return e?""string""==typeof e?i.call(S(e),this[0]):i.call(this,e.jquery?e[0]:e):this[0]&&this[0].parentNode?this.first().prevAll().length:-1},add:function(e,t){return this.pushStack(S.uniqueSort(S.merge(this.get(),S(e,t))))},addBack:function(e){return this.add(null==e?this.prevObject:this.prevObject.filter(e))}}),S.each({parent:function(e){var t=e.parentNode;return t&&11!==t.nodeType?t:null},parents:function(e){return h(e,""parentNode"")},parentsUntil:function(e,t,n){return h(e,""parentNode"",n)},next:function(e){return O(e,""nextSibling"")},prev:function(e){return O(e,""previousSibling"")},nextAll:function(e){return h(e,""nextSibling"")},prevAll:function(e){return h(e,""previousSibling"")},nextUntil:function(e,t,n){return h(e,""nextSibling"",n)},prevUntil:function(e,t,n){return h(e,""previousSibling"",n)},siblings:function(e){return T((e.parentNode||{}).firstChild,e)},children:function(e){return T(e.firstChild)},contents:function(e){return null!=e.contentDocument&&r(e.contentDocument)?e.contentDocument:(A(e,""template"")&&(e=e.content||e),S.merge([],e.childNodes))}},function(r,i){S.fn[r]=function(e,t){var n=S.map(this,i,e);return""Until""!==r.slice(-5)&&(t=e),t&&""string""==typeof t&&(n=S.filter(t,n)),1<this.length&&(H[r]||S.uniqueSort(n),L.test(r)&&n.reverse()),this.pushStack(n)}});var P=/[^\x20\t\r\n\f]+/g;function R(e){return e}function M(e){throw e}function I(e,t,n,r){var i;try{e&&m(i=e.promise)?i.call(e).done(t).fail(n):e&&m(i=e.then)?i.call(e,t,n):t.apply(void 0,[e].slice(r))}catch(e){n.apply(void 0,[e])}}S.Callbacks=function(r){var e,n;r=""string""==typeof r?(e=r,n={},S.each(e.match(P)||[],function(e,t){n[t]=!0}),n):S.extend({},r);var i,t,o,a,s=[],u=[],l=-1,c=function(){for(a=a||r.once,o=i=!0;u.length;l=-1){t=u.shift();while(++l<s.length)!1===s[l].apply(t[0],t[1])&&r.stopOnFalse&&(l=s.length,t=!1)}r.memory||(t=!1),i=!1,a&&(s=t?[]:"""")},f={add:function(){return s&&(t&&!i&&(l=s.length-1,u.push(t)),function n(e){S.each(e,function(e,t){m(t)?r.unique&&f.has(t)||s.push(t):t&&t.length&&""string""!==w(t)&&n(t)})}(arguments),t&&!i&&c()),this},remove:function(){return S.each(arguments,function(e,t){var n;while(-1<(n=S.inArray(t,s,n)))s.splice(n,1),n<=l&&l--}),this},has:function(e){return e?-1<S.inArray(e,s):0<s.length},empty:function(){return s&&(s=[]),this},disable:function(){return a=u=[],s=t="""",this},disabled:function(){return!s},lock:function(){return a=u=[],t||i||(s=t=""""),this},locked:function(){return!!a},fireWith:function(e,t){return a||(t=[e,(t=t||[]).slice?t.slice():t],u.push(t),i||c()),this},fire:function(){return f.fireWith(this,arguments),this},fired:function(){return!!o}};return f},S.extend({Deferred:function(e){var o=[[""notify"",""progress"",S.Callbacks(""memory""),S.Callbacks(""memory""),2],[""resolve"",""done"",S.Callbacks(""once memory""),S.Callbacks(""once memory""),0,""resolved""],[""reject"",""fail"",S.Callbacks(""once memory""),S.Callbacks(""once memory""),1,""rejected""]],i=""pending"",a={state:function(){return i},always:function(){return s.done(arguments).fail(arguments),this},""catch"":function(e){return a.then(null,e)},pipe:function(){var i=arguments;return S.Deferred(function(r){S.each(o,function(e,t){var n=m(i[t[4]])&&i[t[4]];s[t[1]](function(){var e=n&&n.apply(this,arguments);e&&m(e.promise)?e.promise().progress(r.notify).done(r.resolve).fail(r.reject):r[t[0]+""With""](this,n?[e]:arguments)})}),i=null}).promise()},then:function(t,n,r){var u=0;function l(i,o,a,s){return function(){var n=this,r=arguments,e=function(){var e,t;if(!(i<u)){if((e=a.apply(n,r))===o.promise())throw new TypeError(""Thenable self-resolution"");t=e&&(""object""==typeof e||""function""==typeof e)&&e.then,m(t)?s?t.call(e,l(u,o,R,s),l(u,o,M,s)):(u++,t.call(e,l(u,o,R,s),l(u,o,M,s),l(u,o,R,o.notifyWith))):(a!==R&&(n=void 0,r=[e]),(s||o.resolveWith)(n,r))}},t=s?e:function(){try{e()}catch(e){S.Deferred.exceptionHook&&S.Deferred.exceptionHook(e,t.stackTrace),u<=i+1&&(a!==M&&(n=void 0,r=[e]),o.rejectWith(n,r))}};i?t():(S.Deferred.getStackHook&&(t.stackTrace=S.Deferred.getStackHook()),C.setTimeout(t))}}return S.Deferred(function(e){o[0][3].add(l(0,e,m(r)?r:R,e.notifyWith)),o[1][3].add(l(0,e,m(t)?t:R)),o[2][3].add(l(0,e,m(n)?n:M))}).promise()},promise:function(e){return null!=e?S.extend(e,a):a}},s={};return S.each(o,function(e,t){var n=t[2],r=t[5];a[t[1]]=n.add,r&&n.add(function(){i=r},o[3-e][2].disable,o[3-e][3].disable,o[0][2].lock,o[0][3].lock),n.add(t[3].fire),s[t[0]]=function(){return s[t[0]+""With""](this===s?void 0:this,arguments),this},s[t[0]+""With""]=n.fireWith}),a.promise(s),e&&e.call(s,s),s},when:function(e){var n=arguments.length,t=n,r=Array(t),i=s.call(arguments),o=S.Deferred(),a=function(t){return function(e){r[t]=this,i[t]=1<arguments.length?s.call(arguments):e,--n||o.resolveWith(r,i)}};if(n<=1&&(I(e,o.done(a(t)).resolve,o.reject,!n),""pending""===o.state()||m(i[t]&&i[t].then)))return o.then();while(t--)I(i[t],a(t),o.reject);return o.promise()}});var W=/^(Eval|Internal|Range|Reference|Syntax|Type|URI)Error$/;S.Deferred.exceptionHook=function(e,t){C.console&&C.console.warn&&e&&W.test(e.name)&&C.console.warn(""jQuery.Deferred exception: ""+e.message,e.stack,t)},S.readyException=function(e){C.setTimeout(function(){throw e})};var F=S.Deferred();function B(){E.removeEventListener(""DOMContentLoaded"",B),C.removeEventListener(""load"",B),S.ready()}S.fn.ready=function(e){return F.then(e)[""catch""](function(e){S.readyException(e)}),this},S.extend({isReady:!1,readyWait:1,ready:function(e){(!0===e?--S.readyWait:S.isReady)||(S.isReady=!0)!==e&&0<--S.readyWait||F.resolveWith(E,[S])}}),S.ready.then=F.then,""complete""===E.readyState||""loading""!==E.readyState&&!E.documentElement.doScroll?C.setTimeout(S.ready):(E.addEventListener(""DOMContentLoaded"",B),C.addEventListener(""load"",B));var $=function(e,t,n,r,i,o,a){var s=0,u=e.length,l=null==n;if(""object""===w(n))for(s in i=!0,n)$(e,t,s,n[s],!0,o,a);else if(void 0!==r&&(i=!0,m(r)||(a=!0),l&&(a?(t.call(e,r),t=null):(l=t,t=function(e,t,n){return l.call(S(e),n)})),t))for(;s<u;s++)t(e[s],n,a?r:r.call(e[s],s,t(e[s],n)));return i?e:l?t.call(e):u?t(e[0],n):o},_=/^-ms-/,z=/-([a-z])/g;function U(e,t){return t.toUpperCase()}function X(e){return e.replace(_,""ms-"").replace(z,U)}var V=function(e){return 1===e.nodeType||9===e.nodeType||!+e.nodeType};function G(){this.expando=S.expando+G.uid++}G.uid=1,G.prototype={cache:function(e){var t=e[this.expando];return t||(t={},V(e)&&(e.nodeType?e[this.expando]=t:Object.defineProperty(e,this.expando,{value:t,configurable:!0}))),t},set:function(e,t,n){var r,i=this.cache(e);if(""string""==typeof t)i[X(t)]=n;else for(r in t)i[X(r)]=t[r];return i},get:function(e,t){return void 0===t?this.cache(e):e[this.expando]&&e[this.expando][X(t)]},access:function(e,t,n){return void 0===t||t&&""string""==typeof t&&void 0===n?this.get(e,t):(this.set(e,t,n),void 0!==n?n:t)},remove:function(e,t){var n,r=e[this.expando];if(void 0!==r){if(void 0!==t){n=(t=Array.isArray(t)?t.map(X):(t=X(t))in r?[t]:t.match(P)||[]).length;while(n--)delete r[t[n]]}(void 0===t||S.isEmptyObject(r))&&(e.nodeType?e[this.expando]=void 0:delete e[this.expando])}},hasData:function(e){var t=e[this.expando];return void 0!==t&&!S.isEmptyObject(t)}};var Y=new G,Q=new G,J=/^(?:\{[\w\W]*\}|\[[\w\W]*\])$/,K=/[A-Z]/g;function Z(e,t,n){var r,i;if(void 0===n&&1===e.nodeType)if(r=""data-""+t.replace(K,""-$&"").toLowerCase(),""string""==typeof(n=e.getAttribute(r))){try{n=""true""===(i=n)||""false""!==i&&(""null""===i?null:i===+i+""""?+i:J.test(i)?JSON.parse(i):i)}catch(e){}Q.set(e,t,n)}else n=void 0;return n}S.extend({hasData:function(e){return Q.hasData(e)||Y.hasData(e)},data:function(e,t,n){return Q.access(e,t,n)},removeData:function(e,t){Q.remove(e,t)},_data:function(e,t,n){return Y.access(e,t,n)},_removeData:function(e,t){Y.remove(e,t)}}),S.fn.extend({data:function(n,e){var t,r,i,o=this[0],a=o&&o.attributes;if(void 0===n){if(this.length&&(i=Q.get(o),1===o.nodeType&&!Y.get(o,""hasDataAttrs""))){t=a.length;while(t--)a[t]&&0===(r=a[t].name).indexOf(""data-"")&&(r=X(r.slice(5)),Z(o,r,i[r]));Y.set(o,""hasDataAttrs"",!0)}return i}return""object""==typeof n?this.each(function(){Q.set(this,n)}):$(this,function(e){var t;if(o&&void 0===e)return void 0!==(t=Q.get(o,n))?t:void 0!==(t=Z(o,n))?t:void 0;this.each(function(){Q.set(this,n,e)})},null,e,1<arguments.length,null,!0)},removeData:function(e){return this.each(function(){Q.remove(this,e)})}}),S.extend({queue:function(e,t,n){var r;if(e)return t=(t||""fx"")+""queue"",r=Y.get(e,t),n&&(!r||Array.isArray(n)?r=Y.access(e,t,S.makeArray(n)):r.push(n)),r||[]},dequeue:function(e,t){t=t||""fx"";var n=S.queue(e,t),r=n.length,i=n.shift(),o=S._queueHooks(e,t);""inprogress""===i&&(i=n.shift(),r--),i&&(""fx""===t&&n.unshift(""inprogress""),delete o.stop,i.call(e,function(){S.dequeue(e,t)},o)),!r&&o&&o.empty.fire()},_queueHooks:function(e,t){var n=t+""queueHooks"";return Y.get(e,n)||Y.access(e,n,{empty:S.Callbacks(""once memory"").add(function(){Y.remove(e,[t+""queue"",n])})})}}),S.fn.extend({queue:function(t,n){var e=2;return""string""!=typeof t&&(n=t,t=""fx"",e--),arguments.length<e?S.queue(this[0],t):void 0===n?this:this.each(function(){var e=S.queue(this,t,n);S._queueHooks(this,t),""fx""===t&&""inprogress""!==e[0]&&S.dequeue(this,t)})},dequeue:function(e){return this.each(function(){S.dequeue(this,e)})},clearQueue:function(e){return this.queue(e||""fx"",[])},promise:function(e,t){var n,r=1,i=S.Deferred(),o=this,a=this.length,s=function(){--r||i.resolveWith(o,[o])};""string""!=typeof e&&(t=e,e=void 0),e=e||""fx"";while(a--)(n=Y.get(o[a],e+""queueHooks""))&&n.empty&&(r++,n.empty.add(s));return s(),i.promise(t)}});var ee=/[+-]?(?:\d*\.|)\d+(?:[eE][+-]?\d+|)/.source,te=new RegExp(""^(?:([+-])=|)(""+ee+"")([a-z%]*)$"",""i""),ne=[""Top"",""Right"",""Bottom"",""Left""],re=E.documentElement,ie=function(e){return S.contains(e.ownerDocument,e)},oe={composed:!0};re.getRootNode&&(ie=function(e){return S.contains(e.ownerDocument,e)||e.getRootNode(oe)===e.ownerDocument});var ae=function(e,t){return""none""===(e=t||e).style.display||""""===e.style.display&&ie(e)&&""none""===S.css(e,""display"")};function se(e,t,n,r){var i,o,a=20,s=r?function(){return r.cur()}:function(){return S.css(e,t,"""")},u=s(),l=n&&n[3]||(S.cssNumber[t]?"""":""px""),c=e.nodeType&&(S.cssNumber[t]||""px""!==l&&+u)&&te.exec(S.css(e,t));if(c&&c[3]!==l){u/=2,l=l||c[3],c=+u||1;while(a--)S.style(e,t,c+l),(1-o)*(1-(o=s()/u||.5))<=0&&(a=0),c/=o;c*=2,S.style(e,t,c+l),n=n||[]}return n&&(c=+c||+u||0,i=n[1]?c+(n[1]+1)*n[2]:+n[2],r&&(r.unit=l,r.start=c,r.end=i)),i}var ue={};function le(e,t){for(var n,r,i,o,a,s,u,l=[],c=0,f=e.length;c<f;c++)(r=e[c]).style&&(n=r.style.display,t?(""none""===n&&(l[c]=Y.get(r,""display"")||null,l[c]||(r.style.display="""")),""""===r.style.display&&ae(r)&&(l[c]=(u=a=o=void 0,a=(i=r).ownerDocument,s=i.nodeName,(u=ue[s])||(o=a.body.appendChild(a.createElement(s)),u=S.css(o,""display""),o.parentNode.removeChild(o),""none""===u&&(u=""block""),ue[s]=u)))):""none""!==n&&(l[c]=""none"",Y.set(r,""display"",n)));for(c=0;c<f;c++)null!=l[c]&&(e[c].style.display=l[c]);return e}S.fn.extend({show:function(){return le(this,!0)},hide:function(){return le(this)},toggle:function(e){return""boolean""==typeof e?e?this.show():this.hide():this.each(function(){ae(this)?S(this).show():S(this).hide()})}});var ce,fe,pe=/^(?:checkbox|radio)$/i,de=/<([a-z][^\/\0>\x20\t\r\n\f]*)/i,he=/^$|^module$|\/(?:java|ecma)script/i;ce=E.createDocumentFragment().appendChild(E.createElement(""div"")),(fe=E.createElement(""input"")).setAttribute(""type"",""radio""),fe.setAttribute(""checked"",""checked""),fe.setAttribute(""name"",""t""),ce.appendChild(fe),y.checkClone=ce.cloneNode(!0).cloneNode(!0).lastChild.checked,ce.innerHTML=""<textarea>x</textarea>"",y.noCloneChecked=!!ce.cloneNode(!0).lastChild.defaultValue,ce.innerHTML=""<option></option>"",y.option=!!ce.lastChild;var ge={thead:[1,""<table>"",""</table>""],col:[2,""<table><colgroup>"",""</colgroup></table>""],tr:[2,""<table><tbody>"",""</tbody></table>""],td:[3,""<table><tbody><tr>"",""</tr></tbody></table>""],_default:[0,"""",""""]};function ve(e,t){var n;return n=""undefined""!=typeof e.getElementsByTagName?e.getElementsByTagName(t||""*""):""undefined""!=typeof e.querySelectorAll?e.querySelectorAll(t||""*""):[],void 0===t||t&&A(e,t)?S.merge([e],n):n}function ye(e,t){for(var n=0,r=e.length;n<r;n++)Y.set(e[n],""globalEval"",!t||Y.get(t[n],""globalEval""))}ge.tbody=ge.tfoot=ge.colgroup=ge.caption=ge.thead,ge.th=ge.td,y.option||(ge.optgroup=ge.option=[1,""<select multiple='multiple'>"",""</select>""]);var me=/<|&#?\w+;/;function xe(e,t,n,r,i){for(var o,a,s,u,l,c,f=t.createDocumentFragment(),p=[],d=0,h=e.length;d<h;d++)if((o=e[d])||0===o)if(""object""===w(o))S.merge(p,o.nodeType?[o]:o);else if(me.test(o)){a=a||f.appendChild(t.createElement(""div"")),s=(de.exec(o)||["""",""""])[1].toLowerCase(),u=ge[s]||ge._default,a.innerHTML=u[1]+S.htmlPrefilter(o)+u[2],c=u[0];while(c--)a=a.lastChild;S.merge(p,a.childNodes),(a=f.firstChild).textContent=""""}else p.push(t.createTextNode(o));f.textContent="""",d=0;while(o=p[d++])if(r&&-1<S.inArray(o,r))i&&i.push(o);else if(l=ie(o),a=ve(f.appendChild(o),""script""),l&&ye(a),n){c=0;while(o=a[c++])he.test(o.type||"""")&&n.push(o)}return f}var be=/^([^.]*)(?:\.(.+)|)/;function we(){return!0}function Te(){return!1}function Ce(e,t){return e===function(){try{return E.activeElement}catch(e){}}()==(""focus""===t)}function Ee(e,t,n,r,i,o){var a,s;if(""object""==typeof t){for(s in""string""!=typeof n&&(r=r||n,n=void 0),t)Ee(e,s,n,r,t[s],o);return e}if(null==r&&null==i?(i=n,r=n=void 0):null==i&&(""string""==typeof n?(i=r,r=void 0):(i=r,r=n,n=void 0)),!1===i)i=Te;else if(!i)return e;return 1===o&&(a=i,(i=function(e){return S().off(e),a.apply(this,arguments)}).guid=a.guid||(a.guid=S.guid++)),e.each(function(){S.event.add(this,t,i,r,n)})}function Se(e,i,o){o?(Y.set(e,i,!1),S.event.add(e,i,{namespace:!1,handler:function(e){var t,n,r=Y.get(this,i);if(1&e.isTrigger&&this[i]){if(r.length)(S.event.special[i]||{}).delegateType&&e.stopPropagation();else if(r=s.call(arguments),Y.set(this,i,r),t=o(this,i),this[i](),r!==(n=Y.get(this,i))||t?Y.set(this,i,!1):n={},r!==n)return e.stopImmediatePropagation(),e.preventDefault(),n&&n.value}else r.length&&(Y.set(this,i,{value:S.event.trigger(S.extend(r[0],S.Event.prototype),r.slice(1),this)}),e.stopImmediatePropagation())}})):void 0===Y.get(e,i)&&S.event.add(e,i,we)}S.event={global:{},add:function(t,e,n,r,i){var o,a,s,u,l,c,f,p,d,h,g,v=Y.get(t);if(V(t)){n.handler&&(n=(o=n).handler,i=o.selector),i&&S.find.matchesSelector(re,i),n.guid||(n.guid=S.guid++),(u=v.events)||(u=v.events=Object.create(null)),(a=v.handle)||(a=v.handle=function(e){return""undefined""!=typeof S&&S.event.triggered!==e.type?S.event.dispatch.apply(t,arguments):void 0}),l=(e=(e||"""").match(P)||[""""]).length;while(l--)d=g=(s=be.exec(e[l])||[])[1],h=(s[2]||"""").split(""."").sort(),d&&(f=S.event.special[d]||{},d=(i?f.delegateType:f.bindType)||d,f=S.event.special[d]||{},c=S.extend({type:d,origType:g,data:r,handler:n,guid:n.guid,selector:i,needsContext:i&&S.expr.match.needsContext.test(i),namespace:h.join(""."")},o),(p=u[d])||((p=u[d]=[]).delegateCount=0,f.setup&&!1!==f.setup.call(t,r,h,a)||t.addEventListener&&t.addEventListener(d,a)),f.add&&(f.add.call(t,c),c.handler.guid||(c.handler.guid=n.guid)),i?p.splice(p.delegateCount++,0,c):p.push(c),S.event.global[d]=!0)}},remove:function(e,t,n,r,i){var o,a,s,u,l,c,f,p,d,h,g,v=Y.hasData(e)&&Y.get(e);if(v&&(u=v.events)){l=(t=(t||"""").match(P)||[""""]).length;while(l--)if(d=g=(s=be.exec(t[l])||[])[1],h=(s[2]||"""").split(""."").sort(),d){f=S.event.special[d]||{},p=u[d=(r?f.delegateType:f.bindType)||d]||[],s=s[2]&&new RegExp(""(^|\\.)""+h.join(""\\.(?:.*\\.|)"")+""(\\.|$)""),a=o=p.length;while(o--)c=p[o],!i&&g!==c.origType||n&&n.guid!==c.guid||s&&!s.test(c.namespace)||r&&r!==c.selector&&(""**""!==r||!c.selector)||(p.splice(o,1),c.selector&&p.delegateCount--,f.remove&&f.remove.call(e,c));a&&!p.length&&(f.teardown&&!1!==f.teardown.call(e,h,v.handle)||S.removeEvent(e,d,v.handle),delete u[d])}else for(d in u)S.event.remove(e,d+t[l],n,r,!0);S.isEmptyObject(u)&&Y.remove(e,""handle events"")}},dispatch:function(e){var t,n,r,i,o,a,s=new Array(arguments.length),u=S.event.fix(e),l=(Y.get(this,""events"")||Object.create(null))[u.type]||[],c=S.event.special[u.type]||{};for(s[0]=u,t=1;t<arguments.length;t++)s[t]=arguments[t];if(u.delegateTarget=this,!c.preDispatch||!1!==c.preDispatch.call(this,u)){a=S.event.handlers.call(this,u,l),t=0;while((i=a[t++])&&!u.isPropagationStopped()){u.currentTarget=i.elem,n=0;while((o=i.handlers[n++])&&!u.isImmediatePropagationStopped())u.rnamespace&&!1!==o.namespace&&!u.rnamespace.test(o.namespace)||(u.handleObj=o,u.data=o.data,void 0!==(r=((S.event.special[o.origType]||{}).handle||o.handler).apply(i.elem,s))&&!1===(u.result=r)&&(u.preventDefault(),u.stopPropagation()))}return c.postDispatch&&c.postDispatch.call(this,u),u.result}},handlers:function(e,t){var n,r,i,o,a,s=[],u=t.delegateCount,l=e.target;if(u&&l.nodeType&&!(""click""===e.type&&1<=e.button))for(;l!==this;l=l.parentNode||this)if(1===l.nodeType&&(""click""!==e.type||!0!==l.disabled)){for(o=[],a={},n=0;n<u;n++)void 0===a[i=(r=t[n]).selector+"" ""]&&(a[i]=r.needsContext?-1<S(i,this).index(l):S.find(i,this,null,[l]).length),a[i]&&o.push(r);o.length&&s.push({elem:l,handlers:o})}return l=this,u<t.length&&s.push({elem:l,handlers:t.slice(u)}),s},addProp:function(t,e){Object.defineProperty(S.Event.prototype,t,{enumerable:!0,configurable:!0,get:m(e)?function(){if(this.originalEvent)return e(this.originalEvent)}:function(){if(this.originalEvent)return this.originalEvent[t]},set:function(e){Object.defineProperty(this,t,{enumerable:!0,configurable:!0,writable:!0,value:e})}})},fix:function(e){return e[S.expando]?e:new S.Event(e)},special:{load:{noBubble:!0},click:{setup:function(e){var t=this||e;return pe.test(t.type)&&t.click&&A(t,""input"")&&Se(t,""click"",we),!1},trigger:function(e){var t=this||e;return pe.test(t.type)&&t.click&&A(t,""input"")&&Se(t,""click""),!0},_default:function(e){var t=e.target;return pe.test(t.type)&&t.click&&A(t,""input"")&&Y.get(t,""click"")||A(t,""a"")}},beforeunload:{postDispatch:function(e){void 0!==e.result&&e.originalEvent&&(e.originalEvent.returnValue=e.result)}}}},S.removeEvent=function(e,t,n){e.removeEventListener&&e.removeEventListener(t,n)},S.Event=function(e,t){if(!(this instanceof S.Event))return new S.Event(e,t);e&&e.type?(this.originalEvent=e,this.type=e.type,this.isDefaultPrevented=e.defaultPrevented||void 0===e.defaultPrevented&&!1===e.returnValue?we:Te,this.target=e.target&&3===e.target.nodeType?e.target.parentNode:e.target,this.currentTarget=e.currentTarget,this.relatedTarget=e.relatedTarget):this.type=e,t&&S.extend(this,t),this.timeStamp=e&&e.timeStamp||Date.now(),this[S.expando]=!0},S.Event.prototype={constructor:S.Event,isDefaultPrevented:Te,isPropagationStopped:Te,isImmediatePropagationStopped:Te,isSimulated:!1,preventDefault:function(){var e=this.originalEvent;this.isDefaultPrevented=we,e&&!this.isSimulated&&e.preventDefault()},stopPropagation:function(){var e=this.originalEvent;this.isPropagationStopped=we,e&&!this.isSimulated&&e.stopPropagation()},stopImmediatePropagation:function(){var e=this.originalEvent;this.isImmediatePropagationStopped=we,e&&!this.isSimulated&&e.stopImmediatePropagation(),this.stopPropagation()}},S.each({altKey:!0,bubbles:!0,cancelable:!0,changedTouches:!0,ctrlKey:!0,detail:!0,eventPhase:!0,metaKey:!0,pageX:!0,pageY:!0,shiftKey:!0,view:!0,""char"":!0,code:!0,charCode:!0,key:!0,keyCode:!0,button:!0,buttons:!0,clientX:!0,clientY:!0,offsetX:!0,offsetY:!0,pointerId:!0,pointerType:!0,screenX:!0,screenY:!0,targetTouches:!0,toElement:!0,touches:!0,which:!0},S.event.addProp),S.each({focus:""focusin"",blur:""focusout""},function(e,t){S.event.special[e]={setup:function(){return Se(this,e,Ce),!1},trigger:function(){return Se(this,e),!0},_default:function(){return!0},delegateType:t}}),S.each({mouseenter:""mouseover"",mouseleave:""mouseout"",pointerenter:""pointerover"",pointerleave:""pointerout""},function(e,i){S.event.special[e]={delegateType:i,bindType:i,handle:function(e){var t,n=e.relatedTarget,r=e.handleObj;return n&&(n===this||S.contains(this,n))||(e.type=r.origType,t=r.handler.apply(this,arguments),e.type=i),t}}}),S.fn.extend({on:function(e,t,n,r){return Ee(this,e,t,n,r)},one:function(e,t,n,r){return Ee(this,e,t,n,r,1)},off:function(e,t,n){var r,i;if(e&&e.preventDefault&&e.handleObj)return r=e.handleObj,S(e.delegateTarget).off(r.namespace?r.origType+"".""+r.namespace:r.origType,r.selector,r.handler),this;if(""object""==typeof e){for(i in e)this.off(i,t,e[i]);return this}return!1!==t&&""function""!=typeof t||(n=t,t=void 0),!1===n&&(n=Te),this.each(function(){S.event.remove(this,e,n,t)})}});var ke=/<script|<style|<link/i,Ae=/checked\s*(?:[^=]|=\s*.checked.)/i,Ne=/^\s*<!(?:\[CDATA\[|--)|(?:\]\]|--)>\s*$/g;function je(e,t){return A(e,""table"")&&A(11!==t.nodeType?t:t.firstChild,""tr"")&&S(e).children(""tbody"")[0]||e}function De(e){return e.type=(null!==e.getAttribute(""type""))+""/""+e.type,e}function qe(e){return""true/""===(e.type||"""").slice(0,5)?e.type=e.type.slice(5):e.removeAttribute(""type""),e}function Le(e,t){var n,r,i,o,a,s;if(1===t.nodeType){if(Y.hasData(e)&&(s=Y.get(e).events))for(i in Y.remove(t,""handle events""),s)for(n=0,r=s[i].length;n<r;n++)S.event.add(t,i,s[i][n]);Q.hasData(e)&&(o=Q.access(e),a=S.extend({},o),Q.set(t,a))}}function He(n,r,i,o){r=g(r);var e,t,a,s,u,l,c=0,f=n.length,p=f-1,d=r[0],h=m(d);if(h||1<f&&""string""==typeof d&&!y.checkClone&&Ae.test(d))return n.each(function(e){var t=n.eq(e);h&&(r[0]=d.call(this,e,t.html())),He(t,r,i,o)});if(f&&(t=(e=xe(r,n[0].ownerDocument,!1,n,o)).firstChild,1===e.childNodes.length&&(e=t),t||o)){for(s=(a=S.map(ve(e,""script""),De)).length;c<f;c++)u=e,c!==p&&(u=S.clone(u,!0,!0),s&&S.merge(a,ve(u,""script""))),i.call(n[c],u,c);if(s)for(l=a[a.length-1].ownerDocument,S.map(a,qe),c=0;c<s;c++)u=a[c],he.test(u.type||"""")&&!Y.access(u,""globalEval"")&&S.contains(l,u)&&(u.src&&""module""!==(u.type||"""").toLowerCase()?S._evalUrl&&!u.noModule&&S._evalUrl(u.src,{nonce:u.nonce||u.getAttribute(""nonce"")},l):b(u.textContent.replace(Ne,""""),u,l))}return n}function Oe(e,t,n){for(var r,i=t?S.filter(t,e):e,o=0;null!=(r=i[o]);o++)n||1!==r.nodeType||S.cleanData(ve(r)),r.parentNode&&(n&&ie(r)&&ye(ve(r,""script"")),r.parentNode.removeChild(r));return e}S.extend({htmlPrefilter:function(e){return e},clone:function(e,t,n){var r,i,o,a,s,u,l,c=e.cloneNode(!0),f=ie(e);if(!(y.noCloneChecked||1!==e.nodeType&&11!==e.nodeType||S.isXMLDoc(e)))for(a=ve(c),r=0,i=(o=ve(e)).length;r<i;r++)s=o[r],u=a[r],void 0,""input""===(l=u.nodeName.toLowerCase())&&pe.test(s.type)?u.checked=s.checked:""input""!==l&&""textarea""!==l||(u.defaultValue=s.defaultValue);if(t)if(n)for(o=o||ve(e),a=a||ve(c),r=0,i=o.length;r<i;r++)Le(o[r],a[r]);else Le(e,c);return 0<(a=ve(c,""script"")).length&&ye(a,!f&&ve(e,""script"")),c},cleanData:function(e){for(var t,n,r,i=S.event.special,o=0;void 0!==(n=e[o]);o++)if(V(n)){if(t=n[Y.expando]){if(t.events)for(r in t.events)i[r]?S.event.remove(n,r):S.removeEvent(n,r,t.handle);n[Y.expando]=void 0}n[Q.expando]&&(n[Q.expando]=void 0)}}}),S.fn.extend({detach:function(e){return Oe(this,e,!0)},remove:function(e){return Oe(this,e)},text:function(e){return $(this,function(e){return void 0===e?S.text(this):this.empty().each(function(){1!==this.nodeType&&11!==this.nodeType&&9!==this.nodeType||(this.textContent=e)})},null,e,arguments.length)},append:function(){return He(this,arguments,function(e){1!==this.nodeType&&11!==this.nodeType&&9!==this.nodeType||je(this,e).appendChild(e)})},prepend:function(){return He(this,arguments,function(e){if(1===this.nodeType||11===this.nodeType||9===this.nodeType){var t=je(this,e);t.insertBefore(e,t.firstChild)}})},before:function(){return He(this,arguments,function(e){this.parentNode&&this.parentNode.insertBefore(e,this)})},after:function(){return He(this,arguments,function(e){this.parentNode&&this.parentNode.insertBefore(e,this.nextSibling)})},empty:function(){for(var e,t=0;null!=(e=this[t]);t++)1===e.nodeType&&(S.cleanData(ve(e,!1)),e.textContent="""");return this},clone:function(e,t){return e=null!=e&&e,t=null==t?e:t,this.map(function(){return S.clone(this,e,t)})},html:function(e){return $(this,function(e){var t=this[0]||{},n=0,r=this.length;if(void 0===e&&1===t.nodeType)return t.innerHTML;if(""string""==typeof e&&!ke.test(e)&&!ge[(de.exec(e)||["""",""""])[1].toLowerCase()]){e=S.htmlPrefilter(e);try{for(;n<r;n++)1===(t=this[n]||{}).nodeType&&(S.cleanData(ve(t,!1)),t.innerHTML=e);t=0}catch(e){}}t&&this.empty().append(e)},null,e,arguments.length)},replaceWith:function(){var n=[];return He(this,arguments,function(e){var t=this.parentNode;S.inArray(this,n)<0&&(S.cleanData(ve(this)),t&&t.replaceChild(e,this))},n)}}),S.each({appendTo:""append"",prependTo:""prepend"",insertBefore:""before"",insertAfter:""after"",replaceAll:""replaceWith""},function(e,a){S.fn[e]=function(e){for(var t,n=[],r=S(e),i=r.length-1,o=0;o<=i;o++)t=o===i?this:this.clone(!0),S(r[o])[a](t),u.apply(n,t.get());return this.pushStack(n)}});var Pe=new RegExp(""^(""+ee+"")(?!px)[a-z%]+$"",""i""),Re=function(e){var t=e.ownerDocument.defaultView;return t&&t.opener||(t=C),t.getComputedStyle(e)},Me=function(e,t,n){var r,i,o={};for(i in t)o[i]=e.style[i],e.style[i]=t[i];for(i in r=n.call(e),t)e.style[i]=o[i];return r},Ie=new RegExp(ne.join(""|""),""i"");function We(e,t,n){var r,i,o,a,s=e.style;return(n=n||Re(e))&&(""""!==(a=n.getPropertyValue(t)||n[t])||ie(e)||(a=S.style(e,t)),!y.pixelBoxStyles()&&Pe.test(a)&&Ie.test(t)&&(r=s.width,i=s.minWidth,o=s.maxWidth,s.minWidth=s.maxWidth=s.width=a,a=n.width,s.width=r,s.minWidth=i,s.maxWidth=o)),void 0!==a?a+"""":a}function Fe(e,t){return{get:function(){if(!e())return(this.get=t).apply(this,arguments);delete this.get}}}!function(){function e(){if(l){u.style.cssText=""position:absolute;left:-11111px;width:60px;margin-top:1px;padding:0;border:0"",l.style.cssText=""position:relative;display:block;box-sizing:border-box;overflow:scroll;margin:auto;border:1px;padding:1px;width:60%;top:1%"",re.appendChild(u).appendChild(l);var e=C.getComputedStyle(l);n=""1%""!==e.top,s=12===t(e.marginLeft),l.style.right=""60%"",o=36===t(e.right),r=36===t(e.width),l.style.position=""absolute"",i=12===t(l.offsetWidth/3),re.removeChild(u),l=null}}function t(e){return Math.round(parseFloat(e))}var n,r,i,o,a,s,u=E.createElement(""div""),l=E.createElement(""div"");l.style&&(l.style.backgroundClip=""content-box"",l.cloneNode(!0).style.backgroundClip="""",y.clearCloneStyle=""content-box""===l.style.backgroundClip,S.extend(y,{boxSizingReliable:function(){return e(),r},pixelBoxStyles:function(){return e(),o},pixelPosition:function(){return e(),n},reliableMarginLeft:function(){return e(),s},scrollboxSize:function(){return e(),i},reliableTrDimensions:function(){var e,t,n,r;return null==a&&(e=E.createElement(""table""),t=E.createElement(""tr""),n=E.createElement(""div""),e.style.cssText=""position:absolute;left:-11111px;border-collapse:separate"",t.style.cssText=""border:1px solid"",t.style.height=""1px"",n.style.height=""9px"",n.style.display=""block"",re.appendChild(e).appendChild(t).appendChild(n),r=C.getComputedStyle(t),a=parseInt(r.height,10)+parseInt(r.borderTopWidth,10)+parseInt(r.borderBottomWidth,10)===t.offsetHeight,re.removeChild(e)),a}}))}();var Be=[""Webkit"",""Moz"",""ms""],$e=E.createElement(""div"").style,_e={};function ze(e){var t=S.cssProps[e]||_e[e];return t||(e in $e?e:_e[e]=function(e){var t=e[0].toUpperCase()+e.slice(1),n=Be.length;while(n--)if((e=Be[n]+t)in $e)return e}(e)||e)}var Ue=/^(none|table(?!-c[ea]).+)/,Xe=/^--/,Ve={position:""absolute"",visibility:""hidden"",display:""block""},Ge={letterSpacing:""0"",fontWeight:""400""};function Ye(e,t,n){var r=te.exec(t);return r?Math.max(0,r[2]-(n||0))+(r[3]||""px""):t}function Qe(e,t,n,r,i,o){var a=""width""===t?1:0,s=0,u=0;if(n===(r?""border"":""content""))return 0;for(;a<4;a+=2)""margin""===n&&(u+=S.css(e,n+ne[a],!0,i)),r?(""content""===n&&(u-=S.css(e,""padding""+ne[a],!0,i)),""margin""!==n&&(u-=S.css(e,""border""+ne[a]+""Width"",!0,i))):(u+=S.css(e,""padding""+ne[a],!0,i),""padding""!==n?u+=S.css(e,""border""+ne[a]+""Width"",!0,i):s+=S.css(e,""border""+ne[a]+""Width"",!0,i));return!r&&0<=o&&(u+=Math.max(0,Math.ceil(e[""offset""+t[0].toUpperCase()+t.slice(1)]-o-u-s-.5))||0),u}function Je(e,t,n){var r=Re(e),i=(!y.boxSizingReliable()||n)&&""border-box""===S.css(e,""boxSizing"",!1,r),o=i,a=We(e,t,r),s=""offset""+t[0].toUpperCase()+t.slice(1);if(Pe.test(a)){if(!n)return a;a=""auto""}return(!y.boxSizingReliable()&&i||!y.reliableTrDimensions()&&A(e,""tr"")||""auto""===a||!parseFloat(a)&&""inline""===S.css(e,""display"",!1,r))&&e.getClientRects().length&&(i=""border-box""===S.css(e,""boxSizing"",!1,r),(o=s in e)&&(a=e[s])),(a=parseFloat(a)||0)+Qe(e,t,n||(i?""border"":""content""),o,r,a)+""px""}function Ke(e,t,n,r,i){return new Ke.prototype.init(e,t,n,r,i)}S.extend({cssHooks:{opacity:{get:function(e,t){if(t){var n=We(e,""opacity"");return""""===n?""1"":n}}}},cssNumber:{animationIterationCount:!0,columnCount:!0,fillOpacity:!0,flexGrow:!0,flexShrink:!0,fontWeight:!0,gridArea:!0,gridColumn:!0,gridColumnEnd:!0,gridColumnStart:!0,gridRow:!0,gridRowEnd:!0,gridRowStart:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,widows:!0,zIndex:!0,zoom:!0},cssProps:{},style:function(e,t,n,r){if(e&&3!==e.nodeType&&8!==e.nodeType&&e.style){var i,o,a,s=X(t),u=Xe.test(t),l=e.style;if(u||(t=ze(s)),a=S.cssHooks[t]||S.cssHooks[s],void 0===n)return a&&""get""in a&&void 0!==(i=a.get(e,!1,r))?i:l[t];""string""===(o=typeof n)&&(i=te.exec(n))&&i[1]&&(n=se(e,t,i),o=""number""),null!=n&&n==n&&(""number""!==o||u||(n+=i&&i[3]||(S.cssNumber[s]?"""":""px"")),y.clearCloneStyle||""""!==n||0!==t.indexOf(""background"")||(l[t]=""inherit""),a&&""set""in a&&void 0===(n=a.set(e,n,r))||(u?l.setProperty(t,n):l[t]=n))}},css:function(e,t,n,r){var i,o,a,s=X(t);return Xe.test(t)||(t=ze(s)),(a=S.cssHooks[t]||S.cssHooks[s])&&""get""in a&&(i=a.get(e,!0,n)),void 0===i&&(i=We(e,t,r)),""normal""===i&&t in Ge&&(i=Ge[t]),""""===n||n?(o=parseFloat(i),!0===n||isFinite(o)?o||0:i):i}}),S.each([""height"",""width""],function(e,u){S.cssHooks[u]={get:function(e,t,n){if(t)return!Ue.test(S.css(e,""display""))||e.getClientRects().length&&e.getBoundingClientRect().width?Je(e,u,n):Me(e,Ve,function(){return Je(e,u,n)})},set:function(e,t,n){var r,i=Re(e),o=!y.scrollboxSize()&&""absolute""===i.position,a=(o||n)&&""border-box""===S.css(e,""boxSizing"",!1,i),s=n?Qe(e,u,n,a,i):0;return a&&o&&(s-=Math.ceil(e[""offset""+u[0].toUpperCase()+u.slice(1)]-parseFloat(i[u])-Qe(e,u,""border"",!1,i)-.5)),s&&(r=te.exec(t))&&""px""!==(r[3]||""px"")&&(e.style[u]=t,t=S.css(e,u)),Ye(0,t,s)}}}),S.cssHooks.marginLeft=Fe(y.reliableMarginLeft,function(e,t){if(t)return(parseFloat(We(e,""marginLeft""))||e.getBoundingClientRect().left-Me(e,{marginLeft:0},function(){return e.getBoundingClientRect().left}))+""px""}),S.each({margin:"""",padding:"""",border:""Width""},function(i,o){S.cssHooks[i+o]={expand:function(e){for(var t=0,n={},r=""string""==typeof e?e.split("" ""):[e];t<4;t++)n[i+ne[t]+o]=r[t]||r[t-2]||r[0];return n}},""margin""!==i&&(S.cssHooks[i+o].set=Ye)}),S.fn.extend({css:function(e,t){return $(this,function(e,t,n){var r,i,o={},a=0;if(Array.isArray(t)){for(r=Re(e),i=t.length;a<i;a++)o[t[a]]=S.css(e,t[a],!1,r);return o}return void 0!==n?S.style(e,t,n):S.css(e,t)},e,t,1<arguments.length)}}),((S.Tween=Ke).prototype={constructor:Ke,init:function(e,t,n,r,i,o){this.elem=e,this.prop=n,this.easing=i||S.easing._default,this.options=t,this.start=this.now=this.cur(),this.end=r,this.unit=o||(S.cssNumber[n]?"""":""px"")},cur:function(){var e=Ke.propHooks[this.prop];return e&&e.get?e.get(this):Ke.propHooks._default.get(this)},run:function(e){var t,n=Ke.propHooks[this.prop];return this.options.duration?this.pos=t=S.easing[this.easing](e,this.options.duration*e,0,1,this.options.duration):this.pos=t=e,this.now=(this.end-this.start)*t+this.start,this.options.step&&this.options.step.call(this.elem,this.now,this),n&&n.set?n.set(this):Ke.propHooks._default.set(this),this}}).init.prototype=Ke.prototype,(Ke.propHooks={_default:{get:function(e){var t;return 1!==e.elem.nodeType||null!=e.elem[e.prop]&&null==e.elem.style[e.prop]?e.elem[e.prop]:(t=S.css(e.elem,e.prop,""""))&&""auto""!==t?t:0},set:function(e){S.fx.step[e.prop]?S.fx.step[e.prop](e):1!==e.elem.nodeType||!S.cssHooks[e.prop]&&null==e.elem.style[ze(e.prop)]?e.elem[e.prop]=e.now:S.style(e.elem,e.prop,e.now+e.unit)}}}).scrollTop=Ke.propHooks.scrollLeft={set:function(e){e.elem.nodeType&&e.elem.parentNode&&(e.elem[e.prop]=e.now)}},S.easing={linear:function(e){return e},swing:function(e){return.5-Math.cos(e*Math.PI)/2},_default:""swing""},S.fx=Ke.prototype.init,S.fx.step={};var Ze,et,tt,nt,rt=/^(?:toggle|show|hide)$/,it=/queueHooks$/;function ot(){et&&(!1===E.hidden&&C.requestAnimationFrame?C.requestAnimationFrame(ot):C.setTimeout(ot,S.fx.interval),S.fx.tick())}function at(){return C.setTimeout(function(){Ze=void 0}),Ze=Date.now()}function st(e,t){var n,r=0,i={height:e};for(t=t?1:0;r<4;r+=2-t)i[""margin""+(n=ne[r])]=i[""padding""+n]=e;return t&&(i.opacity=i.width=e),i}function ut(e,t,n){for(var r,i=(lt.tweeners[t]||[]).concat(lt.tweeners[""*""]),o=0,a=i.length;o<a;o++)if(r=i[o].call(n,t,e))return r}function lt(o,e,t){var n,a,r=0,i=lt.prefilters.length,s=S.Deferred().always(function(){delete u.elem}),u=function(){if(a)return!1;for(var e=Ze||at(),t=Math.max(0,l.startTime+l.duration-e),n=1-(t/l.duration||0),r=0,i=l.tweens.length;r<i;r++)l.tweens[r].run(n);return s.notifyWith(o,[l,n,t]),n<1&&i?t:(i||s.notifyWith(o,[l,1,0]),s.resolveWith(o,[l]),!1)},l=s.promise({elem:o,props:S.extend({},e),opts:S.extend(!0,{specialEasing:{},easing:S.easing._default},t),originalProperties:e,originalOptions:t,startTime:Ze||at(),duration:t.duration,tweens:[],createTween:function(e,t){var n=S.Tween(o,l.opts,e,t,l.opts.specialEasing[e]||l.opts.easing);return l.tweens.push(n),n},stop:function(e){var t=0,n=e?l.tweens.length:0;if(a)return this;for(a=!0;t<n;t++)l.tweens[t].run(1);return e?(s.notifyWith(o,[l,1,0]),s.resolveWith(o,[l,e])):s.rejectWith(o,[l,e]),this}}),c=l.props;for(!function(e,t){var n,r,i,o,a;for(n in e)if(i=t[r=X(n)],o=e[n],Array.isArray(o)&&(i=o[1],o=e[n]=o[0]),n!==r&&(e[r]=o,delete e[n]),(a=S.cssHooks[r])&&""expand""in a)for(n in o=a.expand(o),delete e[r],o)n in e||(e[n]=o[n],t[n]=i);else t[r]=i}(c,l.opts.specialEasing);r<i;r++)if(n=lt.prefilters[r].call(l,o,c,l.opts))return m(n.stop)&&(S._queueHooks(l.elem,l.opts.queue).stop=n.stop.bind(n)),n;return S.map(c,ut,l),m(l.opts.start)&&l.opts.start.call(o,l),l.progress(l.opts.progress).done(l.opts.done,l.opts.complete).fail(l.opts.fail).always(l.opts.always),S.fx.timer(S.extend(u,{elem:o,anim:l,queue:l.opts.queue})),l}S.Animation=S.extend(lt,{tweeners:{""*"":[function(e,t){var n=this.createTween(e,t);return se(n.elem,e,te.exec(t),n),n}]},tweener:function(e,t){m(e)?(t=e,e=[""*""]):e=e.match(P);for(var n,r=0,i=e.length;r<i;r++)n=e[r],lt.tweeners[n]=lt.tweeners[n]||[],lt.tweeners[n].unshift(t)},prefilters:[function(e,t,n){var r,i,o,a,s,u,l,c,f=""width""in t||""height""in t,p=this,d={},h=e.style,g=e.nodeType&&ae(e),v=Y.get(e,""fxshow"");for(r in n.queue||(null==(a=S._queueHooks(e,""fx"")).unqueued&&(a.unqueued=0,s=a.empty.fire,a.empty.fire=function(){a.unqueued||s()}),a.unqueued++,p.always(function(){p.always(function(){a.unqueued--,S.queue(e,""fx"").length||a.empty.fire()})})),t)if(i=t[r],rt.test(i)){if(delete t[r],o=o||""toggle""===i,i===(g?""hide"":""show"")){if(""show""!==i||!v||void 0===v[r])continue;g=!0}d[r]=v&&v[r]||S.style(e,r)}if((u=!S.isEmptyObject(t))||!S.isEmptyObject(d))for(r in f&&1===e.nodeType&&(n.overflow=[h.overflow,h.overflowX,h.overflowY],null==(l=v&&v.display)&&(l=Y.get(e,""display"")),""none""===(c=S.css(e,""display""))&&(l?c=l:(le([e],!0),l=e.style.display||l,c=S.css(e,""display""),le([e]))),(""inline""===c||""inline-block""===c&&null!=l)&&""none""===S.css(e,""float"")&&(u||(p.done(function(){h.display=l}),null==l&&(c=h.display,l=""none""===c?"""":c)),h.display=""inline-block"")),n.overflow&&(h.overflow=""hidden"",p.always(function(){h.overflow=n.overflow[0],h.overflowX=n.overflow[1],h.overflowY=n.overflow[2]})),u=!1,d)u||(v?""hidden""in v&&(g=v.hidden):v=Y.access(e,""fxshow"",{display:l}),o&&(v.hidden=!g),g&&le([e],!0),p.done(function(){for(r in g||le([e]),Y.remove(e,""fxshow""),d)S.style(e,r,d[r])})),u=ut(g?v[r]:0,r,p),r in v||(v[r]=u.start,g&&(u.end=u.start,u.start=0))}],prefilter:function(e,t){t?lt.prefilters.unshift(e):lt.prefilters.push(e)}}),S.speed=function(e,t,n){var r=e&&""object""==typeof e?S.extend({},e):{complete:n||!n&&t||m(e)&&e,duration:e,easing:n&&t||t&&!m(t)&&t};return S.fx.off?r.duration=0:""number""!=typeof r.duration&&(r.duration in S.fx.speeds?r.duration=S.fx.speeds[r.duration]:r.duration=S.fx.speeds._default),null!=r.queue&&!0!==r.queue||(r.queue=""fx""),r.old=r.complete,r.complete=function(){m(r.old)&&r.old.call(this),r.queue&&S.dequeue(this,r.queue)},r},S.fn.extend({fadeTo:function(e,t,n,r){return this.filter(ae).css(""opacity"",0).show().end().animate({opacity:t},e,n,r)},animate:function(t,e,n,r){var i=S.isEmptyObject(t),o=S.speed(e,n,r),a=function(){var e=lt(this,S.extend({},t),o);(i||Y.get(this,""finish""))&&e.stop(!0)};return a.finish=a,i||!1===o.queue?this.each(a):this.queue(o.queue,a)},stop:function(i,e,o){var a=function(e){var t=e.stop;delete e.stop,t(o)};return""string""!=typeof i&&(o=e,e=i,i=void 0),e&&this.queue(i||""fx"",[]),this.each(function(){var e=!0,t=null!=i&&i+""queueHooks"",n=S.timers,r=Y.get(this);if(t)r[t]&&r[t].stop&&a(r[t]);else for(t in r)r[t]&&r[t].stop&&it.test(t)&&a(r[t]);for(t=n.length;t--;)n[t].elem!==this||null!=i&&n[t].queue!==i||(n[t].anim.stop(o),e=!1,n.splice(t,1));!e&&o||S.dequeue(this,i)})},finish:function(a){return!1!==a&&(a=a||""fx""),this.each(function(){var e,t=Y.get(this),n=t[a+""queue""],r=t[a+""queueHooks""],i=S.timers,o=n?n.length:0;for(t.finish=!0,S.queue(this,a,[]),r&&r.stop&&r.stop.call(this,!0),e=i.length;e--;)i[e].elem===this&&i[e].queue===a&&(i[e].anim.stop(!0),i.splice(e,1));for(e=0;e<o;e++)n[e]&&n[e].finish&&n[e].finish.call(this);delete t.finish})}}),S.each([""toggle"",""show"",""hide""],function(e,r){var i=S.fn[r];S.fn[r]=function(e,t,n){return null==e||""boolean""==typeof e?i.apply(this,arguments):this.animate(st(r,!0),e,t,n)}}),S.each({slideDown:st(""show""),slideUp:st(""hide""),slideToggle:st(""toggle""),fadeIn:{opacity:""show""},fadeOut:{opacity:""hide""},fadeToggle:{opacity:""toggle""}},function(e,r){S.fn[e]=function(e,t,n){return this.animate(r,e,t,n)}}),S.timers=[],S.fx.tick=function(){var e,t=0,n=S.timers;for(Ze=Date.now();t<n.length;t++)(e=n[t])()||n[t]!==e||n.splice(t--,1);n.length||S.fx.stop(),Ze=void 0},S.fx.timer=function(e){S.timers.push(e),S.fx.start()},S.fx.interval=13,S.fx.start=function(){et||(et=!0,ot())},S.fx.stop=function(){et=null},S.fx.speeds={slow:600,fast:200,_default:400},S.fn.delay=function(r,e){return r=S.fx&&S.fx.speeds[r]||r,e=e||""fx"",this.queue(e,function(e,t){var n=C.setTimeout(e,r);t.stop=function(){C.clearTimeout(n)}})},tt=E.createElement(""input""),nt=E.createElement(""select"").appendChild(E.createElement(""option"")),tt.type=""checkbox"",y.checkOn=""""!==tt.value,y.optSelected=nt.selected,(tt=E.createElement(""input"")).value=""t"",tt.type=""radio"",y.radioValue=""t""===tt.value;var ct,ft=S.expr.attrHandle;S.fn.extend({attr:function(e,t){return $(this,S.attr,e,t,1<arguments.length)},removeAttr:function(e){return this.each(function(){S.removeAttr(this,e)})}}),S.extend({attr:function(e,t,n){var r,i,o=e.nodeType;if(3!==o&&8!==o&&2!==o)return""undefined""==typeof e.getAttribute?S.prop(e,t,n):(1===o&&S.isXMLDoc(e)||(i=S.attrHooks[t.toLowerCase()]||(S.expr.match.bool.test(t)?ct:void 0)),void 0!==n?null===n?void S.removeAttr(e,t):i&&""set""in i&&void 0!==(r=i.set(e,n,t))?r:(e.setAttribute(t,n+""""),n):i&&""get""in i&&null!==(r=i.get(e,t))?r:null==(r=S.find.attr(e,t))?void 0:r)},attrHooks:{type:{set:function(e,t){if(!y.radioValue&&""radio""===t&&A(e,""input"")){var n=e.value;return e.setAttribute(""type"",t),n&&(e.value=n),t}}}},removeAttr:function(e,t){var n,r=0,i=t&&t.match(P);if(i&&1===e.nodeType)while(n=i[r++])e.removeAttribute(n)}}),ct={set:function(e,t,n){return!1===t?S.removeAttr(e,n):e.setAttribute(n,n),n}},S.each(S.expr.match.bool.source.match(/\w+/g),function(e,t){var a=ft[t]||S.find.attr;ft[t]=function(e,t,n){var r,i,o=t.toLowerCase();return n||(i=ft[o],ft[o]=r,r=null!=a(e,t,n)?o:null,ft[o]=i),r}});var pt=/^(?:input|select|textarea|button)$/i,dt=/^(?:a|area)$/i;function ht(e){return(e.match(P)||[]).join("" "")}function gt(e){return e.getAttribute&&e.getAttribute(""class"")||""""}function vt(e){return Array.isArray(e)?e:""string""==typeof e&&e.match(P)||[]}S.fn.extend({prop:function(e,t){return $(this,S.prop,e,t,1<arguments.length)},removeProp:function(e){return this.each(function(){delete this[S.propFix[e]||e]})}}),S.extend({prop:function(e,t,n){var r,i,o=e.nodeType;if(3!==o&&8!==o&&2!==o)return 1===o&&S.isXMLDoc(e)||(t=S.propFix[t]||t,i=S.propHooks[t]),void 0!==n?i&&""set""in i&&void 0!==(r=i.set(e,n,t))?r:e[t]=n:i&&""get""in i&&null!==(r=i.get(e,t))?r:e[t]},propHooks:{tabIndex:{get:function(e){var t=S.find.attr(e,""tabindex"");return t?parseInt(t,10):pt.test(e.nodeName)||dt.test(e.nodeName)&&e.href?0:-1}}},propFix:{""for"":""htmlFor"",""class"":""className""}}),y.optSelected||(S.propHooks.selected={get:function(e){var t=e.parentNode;return t&&t.parentNode&&t.parentNode.selectedIndex,null},set:function(e){var t=e.parentNode;t&&(t.selectedIndex,t.parentNode&&t.parentNode.selectedIndex)}}),S.each([""tabIndex"",""readOnly"",""maxLength"",""cellSpacing"",""cellPadding"",""rowSpan"",""colSpan"",""useMap"",""frameBorder"",""contentEditable""],function(){S.propFix[this.toLowerCase()]=this}),S.fn.extend({addClass:function(t){var e,n,r,i,o,a,s,u=0;if(m(t))return this.each(function(e){S(this).addClass(t.call(this,e,gt(this)))});if((e=vt(t)).length)while(n=this[u++])if(i=gt(n),r=1===n.nodeType&&"" ""+ht(i)+"" ""){a=0;while(o=e[a++])r.indexOf("" ""+o+"" "")<0&&(r+=o+"" "");i!==(s=ht(r))&&n.setAttribute(""class"",s)}return this},removeClass:function(t){var e,n,r,i,o,a,s,u=0;if(m(t))return this.each(function(e){S(this).removeClass(t.call(this,e,gt(this)))});if(!arguments.length)return this.attr(""class"","""");if((e=vt(t)).length)while(n=this[u++])if(i=gt(n),r=1===n.nodeType&&"" ""+ht(i)+"" ""){a=0;while(o=e[a++])while(-1<r.indexOf("" ""+o+"" ""))r=r.replace("" ""+o+"" "","" "");i!==(s=ht(r))&&n.setAttribute(""class"",s)}return this},toggleClass:function(i,t){var o=typeof i,a=""string""===o||Array.isArray(i);return""boolean""==typeof t&&a?t?this.addClass(i):this.removeClass(i):m(i)?this.each(function(e){S(this).toggleClass(i.call(this,e,gt(this),t),t)}):this.each(function(){var e,t,n,r;if(a){t=0,n=S(this),r=vt(i);while(e=r[t++])n.hasClass(e)?n.removeClass(e):n.addClass(e)}else void 0!==i&&""boolean""!==o||((e=gt(this))&&Y.set(this,""__className__"",e),this.setAttribute&&this.setAttribute(""class"",e||!1===i?"""":Y.get(this,""__className__"")||""""))})},hasClass:function(e){var t,n,r=0;t="" ""+e+"" "";while(n=this[r++])if(1===n.nodeType&&-1<("" ""+ht(gt(n))+"" "").indexOf(t))return!0;return!1}});var yt=/\r/g;S.fn.extend({val:function(n){var r,e,i,t=this[0];return arguments.length?(i=m(n),this.each(function(e){var t;1===this.nodeType&&(null==(t=i?n.call(this,e,S(this).val()):n)?t="""":""number""==typeof t?t+="""":Array.isArray(t)&&(t=S.map(t,function(e){return null==e?"""":e+""""})),(r=S.valHooks[this.type]||S.valHooks[this.nodeName.toLowerCase()])&&""set""in r&&void 0!==r.set(this,t,""value"")||(this.value=t))})):t?(r=S.valHooks[t.type]||S.valHooks[t.nodeName.toLowerCase()])&&""get""in r&&void 0!==(e=r.get(t,""value""))?e:""string""==typeof(e=t.value)?e.replace(yt,""""):null==e?"""":e:void 0}}),S.extend({valHooks:{option:{get:function(e){var t=S.find.attr(e,""value"");return null!=t?t:ht(S.text(e))}},select:{get:function(e){var t,n,r,i=e.options,o=e.selectedIndex,a=""select-one""===e.type,s=a?null:[],u=a?o+1:i.length;for(r=o<0?u:a?o:0;r<u;r++)if(((n=i[r]).selected||r===o)&&!n.disabled&&(!n.parentNode.disabled||!A(n.parentNode,""optgroup""))){if(t=S(n).val(),a)return t;s.push(t)}return s},set:function(e,t){var n,r,i=e.options,o=S.makeArray(t),a=i.length;while(a--)((r=i[a]).selected=-1<S.inArray(S.valHooks.option.get(r),o))&&(n=!0);return n||(e.selectedIndex=-1),o}}}}),S.each([""radio"",""checkbox""],function(){S.valHooks[this]={set:function(e,t){if(Array.isArray(t))return e.checked=-1<S.inArray(S(e).val(),t)}},y.checkOn||(S.valHooks[this].get=function(e){return null===e.getAttribute(""value"")?""on"":e.value})}),y.focusin=""onfocusin""in C;var mt=/^(?:focusinfocus|focusoutblur)$/,xt=function(e){e.stopPropagation()};S.extend(S.event,{trigger:function(e,t,n,r){var i,o,a,s,u,l,c,f,p=[n||E],d=v.call(e,""type"")?e.type:e,h=v.call(e,""namespace"")?e.namespace.split("".""):[];if(o=f=a=n=n||E,3!==n.nodeType&&8!==n.nodeType&&!mt.test(d+S.event.triggered)&&(-1<d.indexOf(""."")&&(d=(h=d.split(""."")).shift(),h.sort()),u=d.indexOf("":"")<0&&""on""+d,(e=e[S.expando]?e:new S.Event(d,""object""==typeof e&&e)).isTrigger=r?2:3,e.namespace=h.join("".""),e.rnamespace=e.namespace?new RegExp(""(^|\\.)""+h.join(""\\.(?:.*\\.|)"")+""(\\.|$)""):null,e.result=void 0,e.target||(e.target=n),t=null==t?[e]:S.makeArray(t,[e]),c=S.event.special[d]||{},r||!c.trigger||!1!==c.trigger.apply(n,t))){if(!r&&!c.noBubble&&!x(n)){for(s=c.delegateType||d,mt.test(s+d)||(o=o.parentNode);o;o=o.parentNode)p.push(o),a=o;a===(n.ownerDocument||E)&&p.push(a.defaultView||a.parentWindow||C)}i=0;while((o=p[i++])&&!e.isPropagationStopped())f=o,e.type=1<i?s:c.bindType||d,(l=(Y.get(o,""events"")||Object.create(null))[e.type]&&Y.get(o,""handle""))&&l.apply(o,t),(l=u&&o[u])&&l.apply&&V(o)&&(e.result=l.apply(o,t),!1===e.result&&e.preventDefault());return e.type=d,r||e.isDefaultPrevented()||c._default&&!1!==c._default.apply(p.pop(),t)||!V(n)||u&&m(n[d])&&!x(n)&&((a=n[u])&&(n[u]=null),S.event.triggered=d,e.isPropagationStopped()&&f.addEventListener(d,xt),n[d](),e.isPropagationStopped()&&f.removeEventListener(d,xt),S.event.triggered=void 0,a&&(n[u]=a)),e.result}},simulate:function(e,t,n){var r=S.extend(new S.Event,n,{type:e,isSimulated:!0});S.event.trigger(r,null,t)}}),S.fn.extend({trigger:function(e,t){return this.each(function(){S.event.trigger(e,t,this)})},triggerHandler:function(e,t){var n=this[0];if(n)return S.event.trigger(e,t,n,!0)}}),y.focusin||S.each({focus:""focusin"",blur:""focusout""},function(n,r){var i=function(e){S.event.simulate(r,e.target,S.event.fix(e))};S.event.special[r]={setup:function(){var e=this.ownerDocument||this.document||this,t=Y.access(e,r);t||e.addEventListener(n,i,!0),Y.access(e,r,(t||0)+1)},teardown:function(){var e=this.ownerDocument||this.document||this,t=Y.access(e,r)-1;t?Y.access(e,r,t):(e.removeEventListener(n,i,!0),Y.remove(e,r))}}});var bt=C.location,wt={guid:Date.now()},Tt=/\?/;S.parseXML=function(e){var t,n;if(!e||""string""!=typeof e)return null;try{t=(new C.DOMParser).parseFromString(e,""text/xml"")}catch(e){}return n=t&&t.getElementsByTagName(""parsererror"")[0],t&&!n||S.error(""Invalid XML: ""+(n?S.map(n.childNodes,function(e){return e.textContent}).join(""\n""):e)),t};var Ct=/\[\]$/,Et=/\r?\n/g,St=/^(?:submit|button|image|reset|file)$/i,kt=/^(?:input|select|textarea|keygen)/i;function At(n,e,r,i){var t;if(Array.isArray(e))S.each(e,function(e,t){r||Ct.test(n)?i(n,t):At(n+""[""+(""object""==typeof t&&null!=t?e:"""")+""]"",t,r,i)});else if(r||""object""!==w(e))i(n,e);else for(t in e)At(n+""[""+t+""]"",e[t],r,i)}S.param=function(e,t){var n,r=[],i=function(e,t){var n=m(t)?t():t;r[r.length]=encodeURIComponent(e)+""=""+encodeURIComponent(null==n?"""":n)};if(null==e)return"""";if(Array.isArray(e)||e.jquery&&!S.isPlainObject(e))S.each(e,function(){i(this.name,this.value)});else for(n in e)At(n,e[n],t,i);return r.join(""&"")},S.fn.extend({serialize:function(){return S.param(this.serializeArray())},serializeArray:function(){return this.map(function(){var e=S.prop(this,""elements"");return e?S.makeArray(e):this}).filter(function(){var e=this.type;return this.name&&!S(this).is("":disabled"")&&kt.test(this.nodeName)&&!St.test(e)&&(this.checked||!pe.test(e))}).map(function(e,t){var n=S(this).val();return null==n?null:Array.isArray(n)?S.map(n,function(e){return{name:t.name,value:e.replace(Et,""\r\n"")}}):{name:t.name,value:n.replace(Et,""\r\n"")}}).get()}});var Nt=/%20/g,jt=/#.*$/,Dt=/([?&])_=[^&]*/,qt=/^(.*?):[ \t]*([^\r\n]*)$/gm,Lt=/^(?:GET|HEAD)$/,Ht=/^\/\//,Ot={},Pt={},Rt=""*/"".concat(""*""),Mt=E.createElement(""a"");function It(o){return function(e,t){""string""!=typeof e&&(t=e,e=""*"");var n,r=0,i=e.toLowerCase().match(P)||[];if(m(t))while(n=i[r++])""+""===n[0]?(n=n.slice(1)||""*"",(o[n]=o[n]||[]).unshift(t)):(o[n]=o[n]||[]).push(t)}}function Wt(t,i,o,a){var s={},u=t===Pt;function l(e){var r;return s[e]=!0,S.each(t[e]||[],function(e,t){var n=t(i,o,a);return""string""!=typeof n||u||s[n]?u?!(r=n):void 0:(i.dataTypes.unshift(n),l(n),!1)}),r}return l(i.dataTypes[0])||!s[""*""]&&l(""*"")}function Ft(e,t){var n,r,i=S.ajaxSettings.flatOptions||{};for(n in t)void 0!==t[n]&&((i[n]?e:r||(r={}))[n]=t[n]);return r&&S.extend(!0,e,r),e}Mt.href=bt.href,S.extend({active:0,lastModified:{},etag:{},ajaxSettings:{url:bt.href,type:""GET"",isLocal:/^(?:about|app|app-storage|.+-extension|file|res|widget):$/.test(bt.protocol),global:!0,processData:!0,async:!0,contentType:""application/x-www-form-urlencoded; charset=UTF-8"",accepts:{""*"":Rt,text:""text/plain"",html:""text/html"",xml:""application/xml, text/xml"",json:""application/json, text/javascript""},contents:{xml:/\bxml\b/,html:/\bhtml/,json:/\bjson\b/},responseFields:{xml:""responseXML"",text:""responseText"",json:""responseJSON""},converters:{""* text"":String,""text html"":!0,""text json"":JSON.parse,""text xml"":S.parseXML},flatOptions:{url:!0,context:!0}},ajaxSetup:function(e,t){return t?Ft(Ft(e,S.ajaxSettings),t):Ft(S.ajaxSettings,e)},ajaxPrefilter:It(Ot),ajaxTransport:It(Pt),ajax:function(e,t){""object""==typeof e&&(t=e,e=void 0),t=t||{};var c,f,p,n,d,r,h,g,i,o,v=S.ajaxSetup({},t),y=v.context||v,m=v.context&&(y.nodeType||y.jquery)?S(y):S.event,x=S.Deferred(),b=S.Callbacks(""once memory""),w=v.statusCode||{},a={},s={},u=""canceled"",T={readyState:0,getResponseHeader:function(e){var t;if(h){if(!n){n={};while(t=qt.exec(p))n[t[1].toLowerCase()+"" ""]=(n[t[1].toLowerCase()+"" ""]||[]).concat(t[2])}t=n[e.toLowerCase()+"" ""]}return null==t?null:t.join("", "")},getAllResponseHeaders:function(){return h?p:null},setRequestHeader:function(e,t){return null==h&&(e=s[e.toLowerCase()]=s[e.toLowerCase()]||e,a[e]=t),this},overrideMimeType:function(e){return null==h&&(v.mimeType=e),this},statusCode:function(e){var t;if(e)if(h)T.always(e[T.status]);else for(t in e)w[t]=[w[t],e[t]];return this},abort:function(e){var t=e||u;return c&&c.abort(t),l(0,t),this}};if(x.promise(T),v.url=((e||v.url||bt.href)+"""").replace(Ht,bt.protocol+""//""),v.type=t.method||t.type||v.method||v.type,v.dataTypes=(v.dataType||""*"").toLowerCase().match(P)||[""""],null==v.crossDomain){r=E.createElement(""a"");try{r.href=v.url,r.href=r.href,v.crossDomain=Mt.protocol+""//""+Mt.host!=r.protocol+""//""+r.host}catch(e){v.crossDomain=!0}}if(v.data&&v.processData&&""string""!=typeof v.data&&(v.data=S.param(v.data,v.traditional)),Wt(Ot,v,t,T),h)return T;for(i in(g=S.event&&v.global)&&0==S.active++&&S.event.trigger(""ajaxStart""),v.type=v.type.toUpperCase(),v.hasContent=!Lt.test(v.type),f=v.url.replace(jt,""""),v.hasContent?v.data&&v.processData&&0===(v.contentType||"""").indexOf(""application/x-www-form-urlencoded"")&&(v.data=v.data.replace(Nt,""+"")):(o=v.url.slice(f.length),v.data&&(v.processData||""string""==typeof v.data)&&(f+=(Tt.test(f)?""&"":""?"")+v.data,delete v.data),!1===v.cache&&(f=f.replace(Dt,""$1""),o=(Tt.test(f)?""&"":""?"")+""_=""+wt.guid+++o),v.url=f+o),v.ifModified&&(S.lastModified[f]&&T.setRequestHeader(""If-Modified-Since"",S.lastModified[f]),S.etag[f]&&T.setRequestHeader(""If-None-Match"",S.etag[f])),(v.data&&v.hasContent&&!1!==v.contentType||t.contentType)&&T.setRequestHeader(""Content-Type"",v.contentType),T.setRequestHeader(""Accept"",v.dataTypes[0]&&v.accepts[v.dataTypes[0]]?v.accepts[v.dataTypes[0]]+(""*""!==v.dataTypes[0]?"", ""+Rt+""; q=0.01"":""""):v.accepts[""*""]),v.headers)T.setRequestHeader(i,v.headers[i]);if(v.beforeSend&&(!1===v.beforeSend.call(y,T,v)||h))return T.abort();if(u=""abort"",b.add(v.complete),T.done(v.success),T.fail(v.error),c=Wt(Pt,v,t,T)){if(T.readyState=1,g&&m.trigger(""ajaxSend"",[T,v]),h)return T;v.async&&0<v.timeout&&(d=C.setTimeout(function(){T.abort(""timeout"")},v.timeout));try{h=!1,c.send(a,l)}catch(e){if(h)throw e;l(-1,e)}}else l(-1,""No Transport"");function l(e,t,n,r){var i,o,a,s,u,l=t;h||(h=!0,d&&C.clearTimeout(d),c=void 0,p=r||"""",T.readyState=0<e?4:0,i=200<=e&&e<300||304===e,n&&(s=function(e,t,n){var r,i,o,a,s=e.contents,u=e.dataTypes;while(""*""===u[0])u.shift(),void 0===r&&(r=e.mimeType||t.getResponseHeader(""Content-Type""));if(r)for(i in s)if(s[i]&&s[i].test(r)){u.unshift(i);break}if(u[0]in n)o=u[0];else{for(i in n){if(!u[0]||e.converters[i+"" ""+u[0]]){o=i;break}a||(a=i)}o=o||a}if(o)return o!==u[0]&&u.unshift(o),n[o]}(v,T,n)),!i&&-1<S.inArray(""script"",v.dataTypes)&&S.inArray(""json"",v.dataTypes)<0&&(v.converters[""text script""]=function(){}),s=function(e,t,n,r){var i,o,a,s,u,l={},c=e.dataTypes.slice();if(c[1])for(a in e.converters)l[a.toLowerCase()]=e.converters[a];o=c.shift();while(o)if(e.responseFields[o]&&(n[e.responseFields[o]]=t),!u&&r&&e.dataFilter&&(t=e.dataFilter(t,e.dataType)),u=o,o=c.shift())if(""*""===o)o=u;else if(""*""!==u&&u!==o){if(!(a=l[u+"" ""+o]||l[""* ""+o]))for(i in l)if((s=i.split("" ""))[1]===o&&(a=l[u+"" ""+s[0]]||l[""* ""+s[0]])){!0===a?a=l[i]:!0!==l[i]&&(o=s[0],c.unshift(s[1]));break}if(!0!==a)if(a&&e[""throws""])t=a(t);else try{t=a(t)}catch(e){return{state:""parsererror"",error:a?e:""No conversion from ""+u+"" to ""+o}}}return{state:""success"",data:t}}(v,s,T,i),i?(v.ifModified&&((u=T.getResponseHeader(""Last-Modified""))&&(S.lastModified[f]=u),(u=T.getResponseHeader(""etag""))&&(S.etag[f]=u)),204===e||""HEAD""===v.type?l=""nocontent"":304===e?l=""notmodified"":(l=s.state,o=s.data,i=!(a=s.error))):(a=l,!e&&l||(l=""error"",e<0&&(e=0))),T.status=e,T.statusText=(t||l)+"""",i?x.resolveWith(y,[o,l,T]):x.rejectWith(y,[T,l,a]),T.statusCode(w),w=void 0,g&&m.trigger(i?""ajaxSuccess"":""ajaxError"",[T,v,i?o:a]),b.fireWith(y,[T,l]),g&&(m.trigger(""ajaxComplete"",[T,v]),--S.active||S.event.trigger(""ajaxStop"")))}return T},getJSON:function(e,t,n){return S.get(e,t,n,""json"")},getScript:function(e,t){return S.get(e,void 0,t,""script"")}}),S.each([""get"",""post""],function(e,i){S[i]=function(e,t,n,r){return m(t)&&(r=r||n,n=t,t=void 0),S.ajax(S.extend({url:e,type:i,dataType:r,data:t,success:n},S.isPlainObject(e)&&e))}}),S.ajaxPrefilter(function(e){var t;for(t in e.headers)""content-type""===t.toLowerCase()&&(e.contentType=e.headers[t]||"""")}),S._evalUrl=function(e,t,n){return S.ajax({url:e,type:""GET"",dataType:""script"",cache:!0,async:!1,global:!1,converters:{""text script"":function(){}},dataFilter:function(e){S.globalEval(e,t,n)}})},S.fn.extend({wrapAll:function(e){var t;return this[0]&&(m(e)&&(e=e.call(this[0])),t=S(e,this[0].ownerDocument).eq(0).clone(!0),this[0].parentNode&&t.insertBefore(this[0]),t.map(function(){var e=this;while(e.firstElementChild)e=e.firstElementChild;return e}).append(this)),this},wrapInner:function(n){return m(n)?this.each(function(e){S(this).wrapInner(n.call(this,e))}):this.each(function(){var e=S(this),t=e.contents();t.length?t.wrapAll(n):e.append(n)})},wrap:function(t){var n=m(t);return this.each(function(e){S(this).wrapAll(n?t.call(this,e):t)})},unwrap:function(e){return this.parent(e).not(""body"").each(function(){S(this).replaceWith(this.childNodes)}),this}}),S.expr.pseudos.hidden=function(e){return!S.expr.pseudos.visible(e)},S.expr.pseudos.visible=function(e){return!!(e.offsetWidth||e.offsetHeight||e.getClientRects().length)},S.ajaxSettings.xhr=function(){try{return new C.XMLHttpRequest}catch(e){}};var Bt={0:200,1223:204},$t=S.ajaxSettings.xhr();y.cors=!!$t&&""withCredentials""in $t,y.ajax=$t=!!$t,S.ajaxTransport(function(i){var o,a;if(y.cors||$t&&!i.crossDomain)return{send:function(e,t){var n,r=i.xhr();if(r.open(i.type,i.url,i.async,i.username,i.password),i.xhrFields)for(n in i.xhrFields)r[n]=i.xhrFields[n];for(n in i.mimeType&&r.overrideMimeType&&r.overrideMimeType(i.mimeType),i.crossDomain||e[""X-Requested-With""]||(e[""X-Requested-With""]=""XMLHttpRequest""),e)r.setRequestHeader(n,e[n]);o=function(e){return function(){o&&(o=a=r.onload=r.onerror=r.onabort=r.ontimeout=r.onreadystatechange=null,""abort""===e?r.abort():""error""===e?""number""!=typeof r.status?t(0,""error""):t(r.status,r.statusText):t(Bt[r.status]||r.status,r.statusText,""text""!==(r.responseType||""text"")||""string""!=typeof r.responseText?{binary:r.response}:{text:r.responseText},r.getAllResponseHeaders()))}},r.onload=o(),a=r.onerror=r.ontimeout=o(""error""),void 0!==r.onabort?r.onabort=a:r.onreadystatechange=function(){4===r.readyState&&C.setTimeout(function(){o&&a()})},o=o(""abort"");try{r.send(i.hasContent&&i.data||null)}catch(e){if(o)throw e}},abort:function(){o&&o()}}}),S.ajaxPrefilter(function(e){e.crossDomain&&(e.contents.script=!1)}),S.ajaxSetup({accepts:{script:""text/javascript, application/javascript, application/ecmascript, application/x-ecmascript""},contents:{script:/\b(?:java|ecma)script\b/},converters:{""text script"":function(e){return S.globalEval(e),e}}}),S.ajaxPrefilter(""script"",function(e){void 0===e.cache&&(e.cache=!1),e.crossDomain&&(e.type=""GET"")}),S.ajaxTransport(""script"",function(n){var r,i;if(n.crossDomain||n.scriptAttrs)return{send:function(e,t){r=S(""<script>"").attr(n.scriptAttrs||{}).prop({charset:n.scriptCharset,src:n.url}).on(""load error"",i=function(e){r.remove(),i=null,e&&t(""error""===e.type?404:200,e.type)}),E.head.appendChild(r[0])},abort:function(){i&&i()}}});var _t,zt=[],Ut=/(=)\?(?=&|$)|\?\?/;S.ajaxSetup({jsonp:""callback"",jsonpCallback:function(){var e=zt.pop()||S.expando+""_""+wt.guid++;return this[e]=!0,e}}),S.ajaxPrefilter(""json jsonp"",function(e,t,n){var r,i,o,a=!1!==e.jsonp&&(Ut.test(e.url)?""url"":""string""==typeof e.data&&0===(e.contentType||"""").indexOf(""application/x-www-form-urlencoded"")&&Ut.test(e.data)&&""data"");if(a||""jsonp""===e.dataTypes[0])return r=e.jsonpCallback=m(e.jsonpCallback)?e.jsonpCallback():e.jsonpCallback,a?e[a]=e[a].replace(Ut,""$1""+r):!1!==e.jsonp&&(e.url+=(Tt.test(e.url)?""&"":""?"")+e.jsonp+""=""+r),e.converters[""script json""]=function(){return o||S.error(r+"" was not called""),o[0]},e.dataTypes[0]=""json"",i=C[r],C[r]=function(){o=arguments},n.always(function(){void 0===i?S(C).removeProp(r):C[r]=i,e[r]&&(e.jsonpCallback=t.jsonpCallback,zt.push(r)),o&&m(i)&&i(o[0]),o=i=void 0}),""script""}),y.createHTMLDocument=((_t=E.implementation.createHTMLDocument("""").body).innerHTML=""<form></form><form></form>"",2===_t.childNodes.length),S.parseHTML=function(e,t,n){return""string""!=typeof e?[]:(""boolean""==typeof t&&(n=t,t=!1),t||(y.createHTMLDocument?((r=(t=E.implementation.createHTMLDocument("""")).createElement(""base"")).href=E.location.href,t.head.appendChild(r)):t=E),o=!n&&[],(i=N.exec(e))?[t.createElement(i[1])]:(i=xe([e],t,o),o&&o.length&&S(o).remove(),S.merge([],i.childNodes)));var r,i,o},S.fn.load=function(e,t,n){var r,i,o,a=this,s=e.indexOf("" "");return-1<s&&(r=ht(e.slice(s)),e=e.slice(0,s)),m(t)?(n=t,t=void 0):t&&""object""==typeof t&&(i=""POST""),0<a.length&&S.ajax({url:e,type:i||""GET"",dataType:""html"",data:t}).done(function(e){o=arguments,a.html(r?S(""<div>"").append(S.parseHTML(e)).find(r):e)}).always(n&&function(e,t){a.each(function(){n.apply(this,o||[e.responseText,t,e])})}),this},S.expr.pseudos.animated=function(t){return S.grep(S.timers,function(e){return t===e.elem}).length},S.offset={setOffset:function(e,t,n){var r,i,o,a,s,u,l=S.css(e,""position""),c=S(e),f={};""static""===l&&(e.style.position=""relative""),s=c.offset(),o=S.css(e,""top""),u=S.css(e,""left""),(""absolute""===l||""fixed""===l)&&-1<(o+u).indexOf(""auto"")?(a=(r=c.position()).top,i=r.left):(a=parseFloat(o)||0,i=parseFloat(u)||0),m(t)&&(t=t.call(e,n,S.extend({},s))),null!=t.top&&(f.top=t.top-s.top+a),null!=t.left&&(f.left=t.left-s.left+i),""using""in t?t.using.call(e,f):c.css(f)}},S.fn.extend({offset:function(t){if(arguments.length)return void 0===t?this:this.each(function(e){S.offset.setOffset(this,t,e)});var e,n,r=this[0];return r?r.getClientRects().length?(e=r.getBoundingClientRect(),n=r.ownerDocument.defaultView,{top:e.top+n.pageYOffset,left:e.left+n.pageXOffset}):{top:0,left:0}:void 0},position:function(){if(this[0]){var e,t,n,r=this[0],i={top:0,left:0};if(""fixed""===S.css(r,""position""))t=r.getBoundingClientRect();else{t=this.offset(),n=r.ownerDocument,e=r.offsetParent||n.documentElement;while(e&&(e===n.body||e===n.documentElement)&&""static""===S.css(e,""position""))e=e.parentNode;e&&e!==r&&1===e.nodeType&&((i=S(e).offset()).top+=S.css(e,""borderTopWidth"",!0),i.left+=S.css(e,""borderLeftWidth"",!0))}return{top:t.top-i.top-S.css(r,""marginTop"",!0),left:t.left-i.left-S.css(r,""marginLeft"",!0)}}},offsetParent:function(){return this.map(function(){var e=this.offsetParent;while(e&&""static""===S.css(e,""position""))e=e.offsetParent;return e||re})}}),S.each({scrollLeft:""pageXOffset"",scrollTop:""pageYOffset""},function(t,i){var o=""pageYOffset""===i;S.fn[t]=function(e){return $(this,function(e,t,n){var r;if(x(e)?r=e:9===e.nodeType&&(r=e.defaultView),void 0===n)return r?r[i]:e[t];r?r.scrollTo(o?r.pageXOffset:n,o?n:r.pageYOffset):e[t]=n},t,e,arguments.length)}}),S.each([""top"",""left""],function(e,n){S.cssHooks[n]=Fe(y.pixelPosition,function(e,t){if(t)return t=We(e,n),Pe.test(t)?S(e).position()[n]+""px"":t})}),S.each({Height:""height"",Width:""width""},function(a,s){S.each({padding:""inner""+a,content:s,"""":""outer""+a},function(r,o){S.fn[o]=function(e,t){var n=arguments.length&&(r||""boolean""!=typeof e),i=r||(!0===e||!0===t?""margin"":""border"");return $(this,function(e,t,n){var r;return x(e)?0===o.indexOf(""outer"")?e[""inner""+a]:e.document.documentElement[""client""+a]:9===e.nodeType?(r=e.documentElement,Math.max(e.body[""scroll""+a],r[""scroll""+a],e.body[""offset""+a],r[""offset""+a],r[""client""+a])):void 0===n?S.css(e,t,i):S.style(e,t,n,i)},s,n?e:void 0,n)}})}),S.each([""ajaxStart"",""ajaxStop"",""ajaxComplete"",""ajaxError"",""ajaxSuccess"",""ajaxSend""],function(e,t){S.fn[t]=function(e){return this.on(t,e)}}),S.fn.extend({bind:function(e,t,n){return this.on(e,null,t,n)},unbind:function(e,t){return this.off(e,null,t)},delegate:function(e,t,n,r){return this.on(t,e,n,r)},undelegate:function(e,t,n){return 1===arguments.length?this.off(e,""**""):this.off(t,e||""**"",n)},hover:function(e,t){return this.mouseenter(e).mouseleave(t||e)}}),S.each(""blur focus focusin focusout resize scroll click dblclick mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave change select submit keydown keypress keyup contextmenu"".split("" ""),function(e,n){S.fn[n]=function(e,t){return 0<arguments.length?this.on(n,null,e,t):this.trigger(n)}});var Xt=/^[\s\uFEFF\xA0]+|[\s\uFEFF\xA0]+$/g;S.proxy=function(e,t){var n,r,i;if(""string""==typeof t&&(n=e[t],t=e,e=n),m(e))return r=s.call(arguments,2),(i=function(){return e.apply(t||this,r.concat(s.call(arguments)))}).guid=e.guid=e.guid||S.guid++,i},S.holdReady=function(e){e?S.readyWait++:S.ready(!0)},S.isArray=Array.isArray,S.parseJSON=JSON.parse,S.nodeName=A,S.isFunction=m,S.isWindow=x,S.camelCase=X,S.type=w,S.now=Date.now,S.isNumeric=function(e){var t=S.type(e);return(""number""===t||""string""===t)&&!isNaN(e-parseFloat(e))},S.trim=function(e){return null==e?"""":(e+"""").replace(Xt,"""")},""function""==typeof define&&define.amd&&define(""jquery"",[],function(){return S});var Vt=C.jQuery,Gt=C.$;return S.noConflict=function(e){return C.$===S&&(C.$=Gt),e&&C.jQuery===S&&(C.jQuery=Vt),S},""undefined""==typeof e&&(C.jQuery=C.$=S),S});

---FILE: docs/misc.html---
@@ -0,0 +1,220 @@
+<!DOCTYPE html>
+<html lang=""en"">
+<head>
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>Chapter 4 Miscelleanous | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""4.1 Dependence among individuals Culina et al. (2013) and Cubaynes et al. (2021)  4.2 Cause-specific mortalities Fern√°ndez-Chac√≥n et al. (2016) and Ruette et al. (2015)  4.3 Disease dynamics..."">
+<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
+<meta property=""og:title"" content=""Chapter 4 Miscelleanous | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/misc.html"">
+<meta property=""og:description"" content=""4.1 Dependence among individuals Culina et al. (2013) and Cubaynes et al. (2021)  4.2 Cause-specific mortalities Fern√°ndez-Chac√≥n et al. (2016) and Ruette et al. (2015)  4.3 Disease dynamics..."">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""Chapter 4 Miscelleanous | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""4.1 Dependence among individuals Culina et al. (2013) and Cubaynes et al. (2021)  4.2 Cause-specific mortalities Fern√°ndez-Chac√≥n et al. (2016) and Ruette et al. (2015)  4.3 Disease dynamics..."">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+    
+    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
+  </style>
+<style type=""text/css"">
+    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
+    div.csl-bib-body { }
+    div.csl-entry {
+      clear: both;
+        }
+    .hanging div.csl-entry {
+      margin-left:2em;
+      text-indent:-2em;
+    }
+    div.csl-left-margin {
+      min-width:2em;
+      float:left;
+    }
+    div.csl-right-inline {
+      margin-left:2em;
+      padding-left:1em;
+    }
+    div.csl-indent {
+      margin-left: 2em;
+    }
+  </style>
+<link rel=""stylesheet"" href=""bs4_style.css"">
+</head>
+<body data-spy=""scroll"" data-target=""#toc"">
+
+<div class=""container-fluid"">
+<div class=""row"">
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+
+    <div class=""d-flex align-items-start justify-content-between"">
+      <h1>
+        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
+        <small class=""text-muted"">Theory and Case Studies in R</small>
+      </h1>
+      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
+    </div>
+
+    <div id=""main-nav"" class=""collapse-lg"">
+      <form role=""search"">
+        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
+</form>
+
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li><a class="""" href=""about-the-author.html"">About the author</a></li>
+<li class=""book-part"">I. Foundations</li>
+<li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li class=""book-part"">II. Transitions</li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li class=""book-part"">III. Case studies</li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
+<li><a class=""active"" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li class=""book-part"">IV. Conclusions</li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
+
+        <div class=""book-extra"">
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
+        </div>
+      </nav>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""misc"" class=""section level1"" number=""4"">
+<h1>
+<span class=""header-section-number"">4</span> Miscelleanous<a class=""anchor"" aria-label=""anchor"" href=""#misc""><i class=""fas fa-link""></i></a>
+</h1>
+<div id=""dependence-among-individuals"" class=""section level2"" number=""4.1"">
+<h2>
+<span class=""header-section-number"">4.1</span> Dependence among individuals<a class=""anchor"" aria-label=""anchor"" href=""#dependence-among-individuals""><i class=""fas fa-link""></i></a>
+</h2>
+<p><span class=""citation"">Culina et al. (<a href=""references.html#ref-culina_multievent_2013"">2013</a>)</span> and <span class=""citation"">Cubaynes et al. (<a href=""references.html#ref-cubaynes_modeling_2021"">2021</a>)</span></p>
+</div>
+<div id=""cause-specific-mortalities"" class=""section level2"" number=""4.2"">
+<h2>
+<span class=""header-section-number"">4.2</span> Cause-specific mortalities<a class=""anchor"" aria-label=""anchor"" href=""#cause-specific-mortalities""><i class=""fas fa-link""></i></a>
+</h2>
+<p><span class=""citation"">Fern√°ndez-Chac√≥n et al. (<a href=""references.html#ref-fernandez-chacon_causes_2016"">2016</a>)</span> and <span class=""citation"">Ruette et al. (<a href=""references.html#ref-ruette_comparative_2015"">2015</a>)</span></p>
+</div>
+<div id=""disease-dynamics"" class=""section level2"" number=""4.3"">
+<h2>
+<span class=""header-section-number"">4.3</span> Disease dynamics<a class=""anchor"" aria-label=""anchor"" href=""#disease-dynamics""><i class=""fas fa-link""></i></a>
+</h2>
+<p><span class=""citation"">Marescot et al. (<a href=""references.html#ref-MarescotEtAl2018"">2018</a>)</span> and <span class=""citation"">Santoro et al. (<a href=""references.html#ref-santoro_multi-event_2014"">2014</a>)</span>. House finch as well.</p>
+</div>
+<div id=""combine-live-captures-and-dead-recoveries"" class=""section level2"" number=""4.4"">
+<h2>
+<span class=""header-section-number"">4.4</span> Combine live captures and dead recoveries<a class=""anchor"" aria-label=""anchor"" href=""#combine-live-captures-and-dead-recoveries""><i class=""fas fa-link""></i></a>
+</h2>
+<p>Combine live recapture w/ dead recoveries by <a href=""https://www.tandfonline.com/doi/pdf/10.1080/00063659909477230"">Lebreton et al.¬†(1999)</a> and go spatial to account for emigration <a href=""https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/12-0124.1"">Gilroy et al.¬†(2012)</a> and <a href=""https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12134"">Schaub &amp; Royle (2014)</a>.</p>
+</div>
+<div id=""stopover-duration"" class=""section level2"" number=""4.5"">
+<h2>
+<span class=""header-section-number"">4.5</span> Stopover duration<a class=""anchor"" aria-label=""anchor"" href=""#stopover-duration""><i class=""fas fa-link""></i></a>
+</h2>
+<p>A voir? Papier de Guerin et al.¬†(2017)</p>
+</div>
+<div id=""prior-info"" class=""section level2"" number=""4.6"">
+<h2>
+<span class=""header-section-number"">4.6</span> Prior info<a class=""anchor"" aria-label=""anchor"" href=""#prior-info""><i class=""fas fa-link""></i></a>
+</h2>
+<p>Papier McCarthy and Pipper. Cf le code et tout dans le fichier leftover. Ajouter figure avec 3, 4 et 5 ans seulement.</p>
+<p>The example on how to incorporate prior information is in <a href=""https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-2664.2005.01101.x"">McCarthy and Masters (2005)</a>.</p>
+</div>
+<div id=""posterior-predictive-check"" class=""section level2"" number=""4.7"">
+<h2>
+<span class=""header-section-number"">4.7</span> Posterior predictive check<a class=""anchor"" aria-label=""anchor"" href=""#posterior-predictive-check""><i class=""fas fa-link""></i></a>
+</h2>
+<p>M-array avec Paganin et de Valpine. Puis IH avec Chambert. Et aussi geometric avec Conn et al.¬†</p>
+</div>
+<div id=""others"" class=""section level2"" number=""4.8"">
+<h2>
+<span class=""header-section-number"">4.8</span> Others<a class=""anchor"" aria-label=""anchor"" href=""#others""><i class=""fas fa-link""></i></a>
+</h2>
+<p>Multispecies. Phylogeny. Path analysis, SEM. Exemple Nina loup hybrides, ou pr√©valence disease, ou sex-ratio, ou la LRS comme dans papier TPB. Manque s√ªrement qqch sur l‚Äôint√©r√™t des simulations, en faire un CS? V√©rifier que les posterior predictive checks sont trait√©s quelque part.</p>
+
+</div>
+</div>
+  <div class=""chapter-nav"">
+<div class=""prev""><a href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></div>
+<div class=""next""><a href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
+      <ul class=""nav navbar-nav"">
+<li><a class=""nav-link"" href=""#misc""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
+<li><a class=""nav-link"" href=""#dependence-among-individuals""><span class=""header-section-number"">4.1</span> Dependence among individuals</a></li>
+<li><a class=""nav-link"" href=""#cause-specific-mortalities""><span class=""header-section-number"">4.2</span> Cause-specific mortalities</a></li>
+<li><a class=""nav-link"" href=""#disease-dynamics""><span class=""header-section-number"">4.3</span> Disease dynamics</a></li>
+<li><a class=""nav-link"" href=""#combine-live-captures-and-dead-recoveries""><span class=""header-section-number"">4.4</span> Combine live captures and dead recoveries</a></li>
+<li><a class=""nav-link"" href=""#stopover-duration""><span class=""header-section-number"">4.5</span> Stopover duration</a></li>
+<li><a class=""nav-link"" href=""#prior-info""><span class=""header-section-number"">4.6</span> Prior info</a></li>
+<li><a class=""nav-link"" href=""#posterior-predictive-check""><span class=""header-section-number"">4.7</span> Posterior predictive check</a></li>
+<li><a class=""nav-link"" href=""#others""><span class=""header-section-number"">4.8</span> Others</a></li>
+</ul>
+
+      <div class=""book-extra"">
+        <ul class=""list-unstyled"">
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/miscelleanous.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/miscelleanous.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+        </ul>
+</div>
+    </nav>
+</div>
+
+</div>
+</div> <!-- .container -->
+
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-14.</p>
+  </div>
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
+  </div>
+
+</div></div>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
+</body>
+</html>

---FILE: docs/preface.html---
@@ -0,0 +1,249 @@
+<!DOCTYPE html>
+<html lang=""en"">
+<head>
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>Preface | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""Why this book? To be completed. Why and what of capture-recapture data and models, with fields of application.1 Brief history of capture-recapture, with switch to state-space/hidden Markov model..."">
+<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
+<meta property=""og:title"" content=""Preface | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/preface.html"">
+<meta property=""og:description"" content=""Why this book? To be completed. Why and what of capture-recapture data and models, with fields of application.1 Brief history of capture-recapture, with switch to state-space/hidden Markov model..."">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""Preface | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""Why this book? To be completed. Why and what of capture-recapture data and models, with fields of application.1 Brief history of capture-recapture, with switch to state-space/hidden Markov model..."">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+    
+    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
+  </style>
+<style type=""text/css"">
+    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
+    div.csl-bib-body { }
+    div.csl-entry {
+      clear: both;
+        }
+    .hanging div.csl-entry {
+      margin-left:2em;
+      text-indent:-2em;
+    }
+    div.csl-left-margin {
+      min-width:2em;
+      float:left;
+    }
+    div.csl-right-inline {
+      margin-left:2em;
+      padding-left:1em;
+    }
+    div.csl-indent {
+      margin-left: 2em;
+    }
+  </style>
+<link rel=""stylesheet"" href=""bs4_style.css"">
+</head>
+<body data-spy=""scroll"" data-target=""#toc"">
+
+<div class=""container-fluid"">
+<div class=""row"">
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+
+    <div class=""d-flex align-items-start justify-content-between"">
+      <h1>
+        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
+        <small class=""text-muted"">Theory and Case Studies in R</small>
+      </h1>
+      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
+    </div>
+
+    <div id=""main-nav"" class=""collapse-lg"">
+      <form role=""search"">
+        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
+</form>
+
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class=""active"" href=""preface.html"">Preface</a></li>
+<li><a class="""" href=""about-the-author.html"">About the author</a></li>
+<li class=""book-part"">I. Foundations</li>
+<li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li class=""book-part"">II. Transitions</li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li class=""book-part"">III. Case studies</li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li class=""book-part"">IV. Conclusions</li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
+
+        <div class=""book-extra"">
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
+        </div>
+      </nav>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""preface"" class=""section level1 unnumbered"">
+<h1>Preface<a class=""anchor"" aria-label=""anchor"" href=""#preface""><i class=""fas fa-link""></i></a>
+</h1>
+<div id=""why-this-book"" class=""section level2 unnumbered"">
+<h2>Why this book?<a class=""anchor"" aria-label=""anchor"" href=""#why-this-book""><i class=""fas fa-link""></i></a>
+</h2>
+<p><strong>To be completed.</strong> Why and what of capture-recapture data and models, with fields of application.<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;Watch out nice Johnny Ball‚Äôs video &lt;a href=""https://www.youtube.com/watch?v=tyX79mPm2xY"" class=""uri""&gt;https://www.youtube.com/watch?v=tyX79mPm2xY&lt;/a&gt;.&lt;/p&gt;'><sup>1</sup></a> Brief history of capture-recapture, with switch to state-space/hidden Markov model (HMM) formulation. Flexibility of HMM to decompose complex problems in smaller pieces that are easier to understand, model and analyse. From satellite guidance to conservation of endangered species. Why Bayes? Also three of my fav research topics ‚Äì capture-recapture, HMM and Bayes statistics ‚Äì let‚Äôs enjoy this great cocktail together.</p>
+</div>
+<div id=""who-should-read-this-book"" class=""section level2 unnumbered"">
+<h2>Who should read this book?<a class=""anchor"" aria-label=""anchor"" href=""#who-should-read-this-book""><i class=""fas fa-link""></i></a>
+</h2>
+<p>This book is aimed at beginners who‚Äôre comfortable using R and write basic code (including loops), as well as connoisseurs of capture-recapture who‚Äôd like to tap into the power of the Bayesian side of statistics. For both audiences, thinking in the HMM framework will help you in confidently building models and make the most of your capture-recapture data.</p>
+</div>
+<div id=""what-will-you-learn"" class=""section level2 unnumbered"">
+<h2>What will you learn?<a class=""anchor"" aria-label=""anchor"" href=""#what-will-you-learn""><i class=""fas fa-link""></i></a>
+</h2>
+<p>The book is divided into five parts. The first part is aimed at getting you up-to-speed with Bayesian statistics, NIMBLE, and hidden Markov models. The second part will teach you all about capture-recapture models for open populations, with reproducible R code to ease the learning process. In the third part, we will focus on issues in inferring states (dealing with uncertainty in assignment, modelling waiting time distribution). The fourth part provides real-world case studies from the scientific literature that you can reproduce using material covered in previous chapters. These problems can either i) be used to cement and deepen your understanding of methods and models, ii) be adapted for your own purpose, or iii) serve as teaching projects. The fifth and last chapter closes the book with take-home messages and recommendations, a list of frequently asked questions and references cited in the book. <strong>Likely to be amended after feedbacks.</strong></p>
+</div>
+<div id=""what-wont-you-learn"" class=""section level2 unnumbered"">
+<h2>What won‚Äôt you learn?<a class=""anchor"" aria-label=""anchor"" href=""#what-wont-you-learn""><i class=""fas fa-link""></i></a>
+</h2>
+<p>There is hardly any maths in this book. The equations I use are either simple enough to be understood without a background in maths, or can be skipped without prejudice. I do not cover Bayesian statistics or even hidden Markov models fully, I provide just what you need to work with capture-recapture data. If you are interested in knowing more about these topics, hopefully the section Suggested reading at the end of each chapter will put you in the right direction. There are also a number of important topics specific to capture-recapture that I do not cover, including closed-population capture-recapture models <span class=""citation"">(<a href=""references.html#ref-WilliamsEtAl2002"">Williams, Nichols, and Conroy 2002</a>)</span>, and spatial capture-recapture models <span class=""citation"">(<a href=""references.html#ref-RoyleEtAl2013book"">Royle et al. 2013</a>)</span>. These models can be treated as HMMs, but for now the usual formulation is just fine. <strong>There will be spatial considerations in the Covariates chapter w/ splines and CAR. I‚Äôm not sure yet about SCR models (R. Glennie‚Äôs Biometrics paper on HMMs and open pop SCR will not be easy to Bayes transform and implement in NIMBLE).</strong></p>
+</div>
+<div id=""prerequisites"" class=""section level2 unnumbered"">
+<h2>Prerequisites<a class=""anchor"" aria-label=""anchor"" href=""#prerequisites""><i class=""fas fa-link""></i></a>
+</h2>
+<p>This book uses primarily the R package NIMBLE, so you need to install at least R and NIMBLE. A bunch of other R packages are used. You can install them all at once by running:</p>
+<div class=""sourceCode"" id=""cb1""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""fu""><a href=""https://rdrr.io/r/utils/install.packages.html"">install.packages</a></span><span class=""op"">(</span><span class=""fu""><a href=""https://rdrr.io/r/base/c.html"">c</a></span><span class=""op"">(</span></span>
+<span>  <span class=""st"">""magick""</span>, <span class=""st"">""MCMCvis""</span>, <span class=""st"">""nimble""</span>, <span class=""st"">""pdftools""</span>, </span>
+<span>  <span class=""st"">""tidyverse""</span>, <span class=""st"">""wesanderson""</span> </span>
+<span><span class=""op"">)</span><span class=""op"">)</span></span></code></pre></div>
+</div>
+<div id=""acknowledgements"" class=""section level2 unnumbered"">
+<h2>Acknowledgements<a class=""anchor"" aria-label=""anchor"" href=""#acknowledgements""><i class=""fas fa-link""></i></a>
+</h2>
+<p><strong>To be completed.</strong></p>
+</div>
+<div id=""how-this-book-was-written"" class=""section level2 unnumbered"">
+<h2>How this book was written<a class=""anchor"" aria-label=""anchor"" href=""#how-this-book-was-written""><i class=""fas fa-link""></i></a>
+</h2>
+<p>I am writing this book in <a href=""http://www.rstudio.com/ide/"">RStudio</a> using <a href=""http://bookdown.org/"">bookdown</a>. The <a href=""https://oliviergimenez.github.io/banana-book"">book website</a> is hosted with <a href=""https://pages.github.com/"">GitHub Pages</a>, and automatically updated after every push by <a href=""https://github.com/features/actions"">Github Actions</a>. The source is available from <a href=""https://github.com/oliviergimenez/banana-book"">GitHub</a>.</p>
+<p>The version of the book you‚Äôre reading was built with R version 4.2.3 (2023-03-15) and the following packages:</p>
+<div class=""inline-table""><table class=""table table-sm"">
+<thead><tr class=""header"">
+<th align=""left"">package</th>
+<th align=""left"">version</th>
+<th align=""left"">source</th>
+</tr></thead>
+<tbody>
+<tr class=""odd"">
+<td align=""left"">magick</td>
+<td align=""left"">2.7.4</td>
+<td align=""left"">CRAN (R 4.2.0)</td>
+</tr>
+<tr class=""even"">
+<td align=""left"">MCMCvis</td>
+<td align=""left"">0.15.5</td>
+<td align=""left"">CRAN (R 4.2.0)</td>
+</tr>
+<tr class=""odd"">
+<td align=""left"">nimble</td>
+<td align=""left"">0.13.1</td>
+<td align=""left"">CRAN (R 4.2.0)</td>
+</tr>
+<tr class=""even"">
+<td align=""left"">pdftools</td>
+<td align=""left"">3.3.3</td>
+<td align=""left"">CRAN (R 4.2.0)</td>
+</tr>
+<tr class=""odd"">
+<td align=""left"">tidyverse</td>
+<td align=""left"">2.0.0</td>
+<td align=""left"">CRAN (R 4.2.0)</td>
+</tr>
+<tr class=""even"">
+<td align=""left"">wesanderson</td>
+<td align=""left"">0.3.6</td>
+<td align=""left"">CRAN (R 4.2.0)</td>
+</tr>
+</tbody>
+</table></div>
+</div>
+</div>
+
+  <div class=""chapter-nav"">
+<div class=""prev""><a href=""index.html"">Welcome</a></div>
+<div class=""next""><a href=""about-the-author.html"">About the author</a></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
+      <ul class=""nav navbar-nav"">
+<li><a class=""nav-link"" href=""#preface"">Preface</a></li>
+<li><a class=""nav-link"" href=""#why-this-book"">Why this book?</a></li>
+<li><a class=""nav-link"" href=""#who-should-read-this-book"">Who should read this book?</a></li>
+<li><a class=""nav-link"" href=""#what-will-you-learn"">What will you learn?</a></li>
+<li><a class=""nav-link"" href=""#what-wont-you-learn"">What won‚Äôt you learn?</a></li>
+<li><a class=""nav-link"" href=""#prerequisites"">Prerequisites</a></li>
+<li><a class=""nav-link"" href=""#acknowledgements"">Acknowledgements</a></li>
+<li><a class=""nav-link"" href=""#how-this-book-was-written"">How this book was written</a></li>
+</ul>
+
+      <div class=""book-extra"">
+        <ul class=""list-unstyled"">
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/preface.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/preface.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+        </ul>
+</div>
+    </nav>
+</div>
+
+</div>
+</div> <!-- .container -->
+
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-14.</p>
+  </div>
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
+  </div>
+
+</div></div>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
+</body>
+</html>

---FILE: docs/reference-keys.txt---
@@ -0,0 +1,57 @@
+fig:revbayes
+fig:bayestheorem
+fig:binlik
+fig:numapprox
+fig:betadistribution
+fig:compar
+fig:mcmcpaper
+fig:chain
+fig:twochains
+fig:longchain
+fig:animlongchain
+fig:burnin
+fig:bgr
+fig:tracechainlength
+fig:acfchainlength
+crashcourse
+introduction-1
+bayes-theorem
+what-is-the-bayesian-approach
+numerical-approx
+markov-chain-monte-carlo-mcmc
+monte-carlo-integration
+markovmodelmcmc
+metropolis-algorithm
+convergence-diag
+burn-in
+chain-length
+what-if-you-have-issues-of-convergence
+summary
+suggested-reading
+tradeoffs
+access-to-reproduction
+tradeoffs-1
+breeding-dynamics
+covariates
+missing-values
+nonlinearities
+covariate-selection
+sex-uncertainty
+actuarial-senescence
+covariate-on-multinomial-logit-link
+uncertainty-in-age
+misc
+dependence-among-individuals
+cause-specific-mortalities
+disease-dynamics
+combine-live-captures-and-dead-recoveries
+stopover-duration
+prior-info
+posterior-predictive-check
+others
+lackoffit
+individual-heterogeneity
+trap-dep
+transience
+temporary-emigration
+memory-model

---FILE: docs/references.html---
@@ -0,0 +1,261 @@
+<!DOCTYPE html>
+<html lang=""en"">
+<head>
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>References | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""Albert, Jim, and Jingchen Hu. 2019. Probability and Bayesian Modeling. 1st edition. Chapman; Hall/CRC.  Choquet, R√©mi, Anne Viallefont, Lauriane Rouan, Kamel Gaanoun, and Jean-Michel Gaillard...."">
+<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
+<meta property=""og:title"" content=""References | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/references.html"">
+<meta property=""og:description"" content=""Albert, Jim, and Jingchen Hu. 2019. Probability and Bayesian Modeling. 1st edition. Chapman; Hall/CRC.  Choquet, R√©mi, Anne Viallefont, Lauriane Rouan, Kamel Gaanoun, and Jean-Michel Gaillard...."">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""References | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""Albert, Jim, and Jingchen Hu. 2019. Probability and Bayesian Modeling. 1st edition. Chapman; Hall/CRC.  Choquet, R√©mi, Anne Viallefont, Lauriane Rouan, Kamel Gaanoun, and Jean-Michel Gaillard...."">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+    
+    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
+  </style>
+<style type=""text/css"">
+    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
+    div.csl-bib-body { }
+    div.csl-entry {
+      clear: both;
+        }
+    .hanging div.csl-entry {
+      margin-left:2em;
+      text-indent:-2em;
+    }
+    div.csl-left-margin {
+      min-width:2em;
+      float:left;
+    }
+    div.csl-right-inline {
+      margin-left:2em;
+      padding-left:1em;
+    }
+    div.csl-indent {
+      margin-left: 2em;
+    }
+  </style>
+<link rel=""stylesheet"" href=""bs4_style.css"">
+</head>
+<body data-spy=""scroll"" data-target=""#toc"">
+
+<div class=""container-fluid"">
+<div class=""row"">
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+
+    <div class=""d-flex align-items-start justify-content-between"">
+      <h1>
+        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
+        <small class=""text-muted"">Theory and Case Studies in R</small>
+      </h1>
+      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
+    </div>
+
+    <div id=""main-nav"" class=""collapse-lg"">
+      <form role=""search"">
+        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
+</form>
+
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li><a class="""" href=""about-the-author.html"">About the author</a></li>
+<li class=""book-part"">I. Foundations</li>
+<li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li class=""book-part"">II. Transitions</li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li class=""book-part"">III. Case studies</li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li class=""book-part"">IV. Conclusions</li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
+<li><a class=""active"" href=""references.html"">References</a></li>
+</ul>
+
+        <div class=""book-extra"">
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
+        </div>
+      </nav>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""references"" class=""section level1 unnumbered"">
+<h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=""fas fa-link""></i></a>
+</h1>
+
+<div id=""refs"" class=""references csl-bib-body hanging-indent"">
+<div id=""ref-alberthu2019"" class=""csl-entry"">
+Albert, Jim, and Jingchen Hu. 2019. <em>Probability and <span>Bayesian</span> <span>Modeling</span></em>. 1st edition. Chapman; Hall/CRC.
+</div>
+<div id=""ref-choquet_semi-markov_2011"" class=""csl-entry"">
+Choquet, R√©mi, Anne Viallefont, Lauriane Rouan, Kamel Gaanoun, and Jean-Michel Gaillard. 2011. <span>‚ÄúA Semi-<span>Markov</span> Model to Assess Reliably Survival Patterns from Birth to Death in Free-Ranging Populations.‚Äù</span> <em>Methods in Ecology and Evolution</em> 2 (4): 383‚Äì89.
+</div>
+<div id=""ref-cruz-flores_sex-specific_nodate"" class=""csl-entry"">
+Cruz-Flores, Marta, Roger Pradel, Jo√´l Bried, Jacob Gonz√°lez-Sol√≠s, and Ra√ºl Ramos. n.d. <span>‚ÄúSex-Specific Costs of Reproduction on Survival in a Long-Lived Seabird.‚Äù</span> <em>Biology Letters</em> 17 (3): 20200804.
+</div>
+<div id=""ref-cubaynes_modeling_2021"" class=""csl-entry"">
+Cubaynes, Sarah, Jon Aars, Nigel G. Yoccoz, Roger Pradel, √òystein Wiig, Rolf A. Ims, and Olivier Gimenez. 2021. <span>‚ÄúModeling the Demography of Species Providing Extended Parental Care: <span>A</span> Capture‚ÄìRecapture Multievent Model with a Case Study on Polar Bears (<span>Ursus</span> Maritimus).‚Äù</span> <em>Ecology and Evolution</em> 11 (7): 3380‚Äì92.
+</div>
+<div id=""ref-cubaynes_importance_2010"" class=""csl-entry"">
+Cubaynes, Sarah, Roger Pradel, R√©mi Choquet, Christophe Duchamp, Jean-Michel Gaillard, Jean-Dominique Lebreton, Eric Marboutin, et al. 2010. <span>‚ÄúImportance of Accounting for Detection Heterogeneity When Estimating Abundance: The Case of <span>French</span> Wolves.‚Äù</span> <em>Conservation Biology: The Journal of the Society for Conservation Biology</em> 24 (2): 621‚Äì26.
+</div>
+<div id=""ref-culina_multievent_2013"" class=""csl-entry"">
+Culina, Antica, Shelly Lachish, Roger Pradel, Remi Choquet, and Ben C. Sheldon. 2013. <span>‚ÄúA Multievent Approach to Estimating Pair Fidelity and Heterogeneity in State Transitions.‚Äù</span> <em>Ecology and Evolution</em> 3 (13): 4326‚Äì38.
+</div>
+<div id=""ref-desprez_known_2013"" class=""csl-entry"">
+Desprez, Marine, Clive R. McMahon, Mark A. Hindell, Robert Harcourt, and Olivier Gimenez. 2013. <span>‚ÄúKnown Unknowns in an Imperfect World: Incorporating Uncertainty in Recruitment Estimates Using Multi-Event Capture-Recapture Models.‚Äù</span> <em>Ecology and Evolution</em> 3 (14): 4658‚Äì68.
+</div>
+<div id=""ref-desprez_now_2011"" class=""csl-entry"">
+Desprez, Marine, Roger Pradel, Emmanuelle Cam, Jean-Yves Monnat, and Olivier Gimenez. 2011. <span>‚ÄúNow You See Him, Now You Don‚Äôt: Experience, Not Age, Is Related to Reproduction in Kittiwakes.‚Äù</span> <em>Proceedings of the Royal Society B: Biological Sciences</em> 278 (1721): 3060‚Äì66.
+</div>
+<div id=""ref-fernandez-chacon_causes_2016"" class=""csl-entry"">
+Fern√°ndez-Chac√≥n, Albert, Even Moland, Sigurd Heiberg Espeland, Alf Ring Kleiven, and Esben Moland Olsen. 2016. <span>‚ÄúCauses of Mortality in Depleted Populations of <span>Atlantic</span> Cod Estimated from Multi-Event Modelling of Mark‚ÄìRecapture and Recovery Data.‚Äù</span> <em>Canadian Journal of Fisheries and Aquatic Sciences</em>, June.
+</div>
+<div id=""ref-genovart_exploiting_2012"" class=""csl-entry"">
+Genovart, Meritxell, Roger Pradel, and Daniel Oro. 2012. <span>‚ÄúExploiting Uncertain Ecological Fieldwork Data with Multi-Event Capture‚ÄìRecapture Modelling: An Example with Bird Sex Assignment.‚Äù</span> <em>Journal of Animal Ecology</em> 81 (5): 970‚Äì77.
+</div>
+<div id=""ref-gimenez_individual_2010"" class=""csl-entry"">
+Gimenez, O., and R. Choquet. 2010. <span>‚ÄúIndividual Heterogeneity in Studies on Marked Animals Using Numerical Integration: Capture‚ÄìRecapture Mixed Models.‚Äù</span> <em>Ecology</em> 91 (4): 951‚Äì57.
+</div>
+<div id=""ref-king_bayesian_2009"" class=""csl-entry"">
+King, Ruth, B. J. T. Morgan, O. Gimenez, and S. P. Brooks. 2009. <em>Bayesian <span>Analysis</span> for <span>Population</span> <span>Ecology</span></em>. Chapman; Hall/CRC.
+</div>
+<div id=""ref-MarescotEtAl2018"" class=""csl-entry"">
+Marescot, L., S. Benhaiem, O. Gimenez, H. Hofer, J.-D. Lebreton, X. A. Olarte-Castillo, S. Kramer-Schadt, and M. L. East. 2018. <span>‚ÄúSocial Status Mediates the Fitness Costs of Infection with Canine Distemper Virus in <span>Serengeti</span> Spotted Hyenas.‚Äù</span> <em>Functional Ecology</em> 32 (5): 1237‚Äì50.
+</div>
+<div id=""ref-mcelreathbook"" class=""csl-entry"">
+McElreath, Richard. 2016. <em>Statistical <span>Rethinking</span>: <span>A</span> <span>Bayesian</span> <span>Course</span> with <span>Examples</span> in <span>R</span> and <span>Stan</span></em>. 1st edition. Chapman; Hall/CRC.
+</div>
+<div id=""ref-mcgrayne2011"" class=""csl-entry"">
+McGrayne, Sharon Bertsch. 2011. <em>The <span>Theory</span> <span>That</span> <span>Would</span> <span>Not</span> <span>Die</span>: <span>How</span> <span>Bayes</span>‚Äô <span>Rule</span> <span>Cracked</span> the <span>Enigma</span> <span>Code</span>, <span>Hunted</span> <span>Down</span> <span>Russian</span> <span>Submarines</span>, and <span>Emerged</span> <span>Triumphant</span> from <span>Two</span> <span>Centuries</span> of <span>Controversy</span></em>. Yale University Press.
+</div>
+<div id=""ref-morano_life-history_2013"" class=""csl-entry"">
+Morano, Sabrina, Kelley M. Stewart, James S. Sedinger, Christopher A. Nicolai, and Martin Vavra. 2013. <span>‚ÄúLife-History Strategies of <span>North</span> <span>American</span> Elk: Trade-Offs Associated with Reproduction and Survival.‚Äù</span> <em>Journal of Mammalogy</em> 94 (1): 162‚Äì72.
+</div>
+<div id=""ref-pacoureau_population_2019"" class=""csl-entry"">
+Pacoureau, Nathan, Matthieu Authier, Karine Delord, and Christophe Barbraud. 2019. <span>‚ÄúPopulation Response of an Apex <span>Antarctic</span> Consumer to Its Prey and Climate Fluctuations.‚Äù</span> <em>Oecologia</em> 189 (2): 279‚Äì91.
+</div>
+<div id=""ref-peron_evidence_2016"" class=""csl-entry"">
+P√©ron, Guillaume, Jean-Michel Gaillard, Christophe Barbraud, Christophe Bonenfant, Anne Charmantier, R√©mi Choquet, Tim Coulson, et al. 2016. <span>‚ÄúEvidence of Reduced Individual Heterogeneity in Adult Survival of Long-Lived Species.‚Äù</span> <em>Evolution</em> 70 (12): 2909‚Äì14.
+</div>
+<div id=""ref-pradel_breeding_2012"" class=""csl-entry"">
+Pradel, Roger, R√©mi Choquet, and Arnaud B√©chet. 2012. <span>‚ÄúBreeding <span>Experience</span> <span>Might</span> <span>Be</span> a <span>Major</span> <span>Determinant</span> of <span>Breeding</span> <span>Probability</span> in <span>Long</span>-<span>Lived</span> <span>Species</span>: <span>The</span> <span>Case</span> of the <span>Greater</span> <span>Flamingo</span>.‚Äù</span> <em>PLOS ONE</em> 7 (12): e51016.
+</div>
+<div id=""ref-PradelEtAl2008"" class=""csl-entry"">
+Pradel, Roger, Lory Maurin-Bernier, Olivier Gimenez, Meritxell Genovart, R√©mi Choquet, and Daniel Oro. 2008. <span>‚ÄúEstimation of Sex-Specific Survival with Uncertainty in Sex Assessment.‚Äù</span> <em>Canadian Journal of Statistics</em> 36 (1): 29‚Äì42.
+</div>
+<div id=""ref-RoyleEtAl2013book"" class=""csl-entry"">
+Royle, J Andrew, Richard B Chandler, Rahel Sollmann, and Beth Gardner. 2013. <em>Spatial Capture-Recapture</em>. Academic Press.
+</div>
+<div id=""ref-ruette_comparative_2015"" class=""csl-entry"">
+Ruette, S., J.-M. Vandel, M. Albaret, and S. Devillard. 2015. <span>‚ÄúComparative Survival Pattern of the Syntopic Pine and Stone Martens in a Trapped Rural Area in <span>France</span>.‚Äù</span> <em>Journal of Zoology</em> 295 (3): 214‚Äì22.
+</div>
+<div id=""ref-santoro_multi-event_2014"" class=""csl-entry"">
+Santoro, Simone, Isa Pacios, Sacramento Moreno, Alejandro Bert√≥-Moran, and Carlos Rouco. 2014. <span>‚ÄúMulti-Event Capture‚ÄìRecapture Modeling of Host‚ÄìPathogen Dynamics Among <span>European</span> Rabbit Populations Exposed to Myxoma and <span>Rabbit</span> <span>Hemorrhagic</span> <span>Disease</span> <span>Viruses</span>: Common and Heterogeneous Patterns.‚Äù</span> <em>Veterinary Research</em> 45 (1): 39.
+</div>
+<div id=""ref-shefferson_life_2003"" class=""csl-entry"">
+Shefferson, Richard P., Joyce Proper, Steven R. Beissinger, and Ellen L. Simms. 2003. <span>‚ÄúLife <span>History</span> <span>Trade</span>-<span>Offs</span> in a <span>Rare</span> <span>Orchid</span>: <span>The</span> <span>Costs</span> of <span>Flowering</span>, <span>Dormancy</span>, and <span>Sprouting</span>.‚Äù</span> <em>Ecology</em> 84 (5): 1199‚Äì1206.
+</div>
+<div id=""ref-turek_bayesian_2021"" class=""csl-entry"">
+Turek, Daniel, Claudia Wehrhahn, and Olivier Gimenez. 2021. <span>‚ÄúBayesian Non-Parametric Detection Heterogeneity in Ecological Models.‚Äù</span> <em>Environmental and Ecological Statistics</em>.
+</div>
+<div id=""ref-WilliamsEtAl2002"" class=""csl-entry"">
+Williams, B. K., J. D. Nichols, and M. J. Conroy. 2002. <em>Analysis and Management of Animal Populations</em>. San Diego, CA, USA: Academic Press.
+</div>
+</div>
+</div>
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+  <div class=""chapter-nav"">
+<div class=""prev""><a href=""take-home-messages.html"">Take-home messages</a></div>
+<div class=""empty""></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
+      <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#references"">References</a></li></ul>
+
+      <div class=""book-extra"">
+        <ul class=""list-unstyled"">
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/references.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/references.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+        </ul>
+</div>
+    </nav>
+</div>
+
+</div>
+</div> <!-- .container -->
+
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-14.</p>
+  </div>
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
+  </div>
+
+</div></div>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
+</body>
+</html>

---FILE: docs/search.json---
@@ -0,0 +1 @@
+[{""path"":""index.html"",""id"":""welcome"",""chapter"":""Welcome"",""heading"":""Welcome"",""text"":""Welcome online version book Bayesian Analysis Capture-Recapture Data Hidden Markov Models ‚Äì Theory Case Studies R. HMM framework gained much attention ecological literature last decade, suggested general modelling framework demography plant animal populations. particular, HMMs increasingly used analyse capture-recapture data estimate key population parameters (e.g., survival, dispersal, recruitment abundance) applications fields ecology.parallel, Bayesian statistics well established fast growing ecology related disciplines, resonates scientific reasoning allows accommodating uncertainty smoothly. popularity Bayesian statistics also comes availability free pieces software (WinBUGS, OpenBUGS, JAGS, Stan, NIMBLE) allow practitioners code analyses.book offers Bayesian treatment HMMs applied capture-recapture data. learn use R package NIMBLE seen many future Bayesian statistical ecology deal complex models /big data. important part book consists case studies presented tutorial style abide ‚Äúlearning ‚Äù philosophy.‚Äôm currently writing book, welcome feedback. may raise issue , amend directly R Markdown file generated page ‚Äôre reading clicking ‚ÄòEdit page‚Äô icon right panel, email . Many thanks!Olivier Gimenez. Written Montpellier, France Athens, Greece.\nLast updated: August 14, 2023"",""code"":""""},{""path"":""index.html"",""id"":""license"",""chapter"":""Welcome"",""heading"":""License"",""text"":""online version book licensed Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.code public domain, licensed Creative Commons CC0 1.0 Universal (CC0 1.0)."",""code"":""""},{""path"":""preface.html"",""id"":""preface"",""chapter"":""Preface"",""heading"":""Preface"",""text"":"""",""code"":""""},{""path"":""preface.html"",""id"":""why-this-book"",""chapter"":""Preface"",""heading"":""Why this book?"",""text"":""completed. capture-recapture data models, fields application.1 Brief history capture-recapture, switch state-space/hidden Markov model (HMM) formulation. Flexibility HMM decompose complex problems smaller pieces easier understand, model analyse. satellite guidance conservation endangered species. Bayes? Also three fav research topics ‚Äì capture-recapture, HMM Bayes statistics ‚Äì let‚Äôs enjoy great cocktail together."",""code"":""""},{""path"":""preface.html"",""id"":""who-should-read-this-book"",""chapter"":""Preface"",""heading"":""Who should read this book?"",""text"":""book aimed beginners ‚Äôre comfortable using R write basic code (including loops), well connoisseurs capture-recapture ‚Äôd like tap power Bayesian side statistics. audiences, thinking HMM framework help confidently building models make capture-recapture data."",""code"":""""},{""path"":""preface.html"",""id"":""what-will-you-learn"",""chapter"":""Preface"",""heading"":""What will you learn?"",""text"":""book divided five parts. first part aimed getting --speed Bayesian statistics, NIMBLE, hidden Markov models. second part teach capture-recapture models open populations, reproducible R code ease learning process. third part, focus issues inferring states (dealing uncertainty assignment, modelling waiting time distribution). fourth part provides real-world case studies scientific literature can reproduce using material covered previous chapters. problems can either ) used cement deepen understanding methods models, ii) adapted purpose, iii) serve teaching projects. fifth last chapter closes book take-home messages recommendations, list frequently asked questions references cited book. Likely amended feedbacks."",""code"":""""},{""path"":""preface.html"",""id"":""what-wont-you-learn"",""chapter"":""Preface"",""heading"":""What won‚Äôt you learn?"",""text"":""hardly maths book. equations use either simple enough understood without background maths, can skipped without prejudice. cover Bayesian statistics even hidden Markov models fully, provide just need work capture-recapture data. interested knowing topics, hopefully section Suggested reading end chapter put right direction. also number important topics specific capture-recapture cover, including closed-population capture-recapture models (Williams, Nichols, Conroy 2002), spatial capture-recapture models (Royle et al. 2013). models can treated HMMs, now usual formulation just fine. spatial considerations Covariates chapter w/ splines CAR. ‚Äôm sure yet SCR models (R. Glennie‚Äôs Biometrics paper HMMs open pop SCR easy Bayes transform implement NIMBLE)."",""code"":""""},{""path"":""preface.html"",""id"":""prerequisites"",""chapter"":""Preface"",""heading"":""Prerequisites"",""text"":""book uses primarily R package NIMBLE, need install least R NIMBLE. bunch R packages used. can install running:"",""code"":""\ninstall.packages(c(\n  \""magick\"", \""MCMCvis\"", \""nimble\"", \""pdftools\"", \n  \""tidyverse\"", \""wesanderson\"" \n))""},{""path"":""preface.html"",""id"":""acknowledgements"",""chapter"":""Preface"",""heading"":""Acknowledgements"",""text"":""completed."",""code"":""""},{""path"":""preface.html"",""id"":""how-this-book-was-written"",""chapter"":""Preface"",""heading"":""How this book was written"",""text"":""writing book RStudio using bookdown. book website hosted GitHub Pages, automatically updated every push Github Actions. source available GitHub.version book ‚Äôre reading built R version 4.2.3 (2023-03-15) following packages:"",""code"":""""},{""path"":""about-the-author.html"",""id"":""about-the-author"",""chapter"":""About the author"",""heading"":""About the author"",""text"":""name Olivier Gimenez (https://oliviergimenez.github.io/). senior (euphemism young anymore) scientist National Centre Scientific Research (CNRS) beautiful city Montpellier, France.struggled studying maths, obtained PhD applied statistics long time ago galaxy wine cheese. awarded habilitation (https://en.wikipedia.org/wiki/Habilitation) ecology evolution stop pretending understand colleagues talking . recently embarked sociology studies hey, .Lost somewhere interface animal ecology, statistical modeling social sciences, -called expertise lies population dynamics species distribution modeling address questions ecology conservation biology impact human activities management large carnivores. nothing without students colleagues kind enough bear .may find Twitter (https://twitter.com/oaggimenez), GitHub (https://github.com/oliviergimenez), get touch email."",""code"":""""},{""path"":""introduction.html"",""id"":""introduction"",""chapter"":""Introduction"",""heading"":""Introduction"",""text"":"""",""code"":""""},{""path"":""crashcourse.html"",""id"":""crashcourse"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1 Bayesian statistics & MCMC"",""text"":"""",""code"":""""},{""path"":""crashcourse.html"",""id"":""introduction-1"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.1 Introduction"",""text"":""first chapter, learn Bayesian theory , may use simple example. also see implement simulation algorithms implement Bayesian method complex analyses. exhaustive treatment Bayesian statistics, get need navigate rest book."",""code"":""""},{""path"":""crashcourse.html"",""id"":""bayes-theorem"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.2 Bayes‚Äô theorem"",""text"":""Let‚Äôs wait longer jump . Bayesian statistics relies Bayes‚Äô theorem (law, rule, whatever prefer) named Reverend Thomas Bayes (Figure 1.1). theorem published 1763 two years Bayes‚Äô death thanks friend‚Äôs efforts Richard Price, independently discovered Pierre-Simon Laplace (McGrayne 2011).\nFigure 1.1: Cartoon Thomas Bayes Bayes‚Äô theorem background. Source: James Kulich\nsee minute, Bayes‚Äô theorem conditional probabilities, somehow tricky understand. Conditional probability outcome event given event B, denote \\(\\Pr(\\mid B)\\), probability occurs, revised considering additional information event B occurred.2 order B appear important, make sure confuse \\(\\Pr(\\mid B)\\) \\(\\Pr(B \\mid )\\).Bayes‚Äô theorem (Figure 1.2) gives \\(\\Pr(\\mid B)\\) using marginal probabilities \\(\\Pr()\\) \\(\\Pr(B)\\) \\(\\Pr(B \\mid )\\):\n\\[\\Pr(\\mid B) = \\displaystyle{\\frac{ \\Pr(B \\mid ) \\; \\Pr()}{\\Pr(B)}}.\\]\nOriginally, Bayes‚Äô theorem seen way infer unkown cause particular effect B, knowing probability effect B given cause . Think example situation medical diagnosis needed, unkown disease B symptoms, doctor knows P(symptoms|disease) wants derive P(disease|symptoms). way reversing \\(\\Pr(B \\mid )\\) \\(\\Pr(\\mid B)\\) explains Bayesian thinking used referred ‚Äòinverse probability‚Äô.\nFigure 1.2: Bayes‚Äô theorem spelt blue neon. Source: Wikipedia\ndon‚Äôt know , need think twice messing letters around. find easier remember Bayes‚Äô theorem written like this3:great think , exactly scientific method ! ‚Äôd like know plausible hypothesis based data collected, possibly compare several hypotheses among . respect, Bayesian reasoning matches scientific reasoning, probably explains Bayesian framework natural understanding statistics.might ask , Bayesian statistics default statistics? Clearly, futile wars male statisticians (including Ronald Fisher, Jerzy Neyman Egon Sharpe Pearson among others), little progress made two centuries. Also, recently, practical problems implement Bayes‚Äô theorem. Recent advances computational power coupled development new algorithms led great increase application Bayesian methods within last three decades."",""code"":""""},{""path"":""crashcourse.html"",""id"":""what-is-the-bayesian-approach"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.3 What is the Bayesian approach?"",""text"":""Typical statistical problems involve estimating parameter (several parameters) \\(\\theta\\) available data. , might used frequentist rather Bayesian method. frequentist approach, particular maximum likelihood estimation (MLE), assumes parameters fixed, unknown values estimated. Therefore classical estimates generally point estimates parameters interest. contrast, Bayesian approach assumes parameters fixed, unknown distribution4.Bayesian approach based upon idea , experimenter, begin prior beliefs system. collect data update prior beliefs basis observations. observations might arise field work, lab work expertise esteemed colleagues. updating process based upon Bayes‚Äô theorem. Loosely, let‚Äôs say \\(= \\theta\\) \\(B = \\text{data}\\), Bayes‚Äô theorem gives way estimate parameter \\(\\theta\\) given data :\\[{\\color{red}{\\Pr(\\theta \\mid \\text{data})}} = \\frac{\\color{blue}{\\Pr(\\text{data} \\mid \\theta)} \\times \\color{green}{\\Pr(\\theta)}}{\\color{orange}{\\Pr(\\text{data})}}.\\]\nLet‚Äôs spend time going quantity formula.left-hand side \\(\\color{red}{\\text{posterior distribution}}\\). represents know seen data. basis inference clearly ‚Äôre , distribution, possibly multivariate one parameter.right-hand side, \\(\\color{blue}{\\text{likelihood}}\\). quantity MLE approach. Yes, Bayesian frequentist approaches likelihood core, mostly explains results often differ much. likelihood captures information data, given model parameterized \\(\\theta\\).\\(\\color{green}{\\text{prior distribution}}\\). quantity represents know seeing data. source much discussion Bayesian approach. may vague don‚Äôt know anything \\(\\theta\\). Usually however, never start scratch, ‚Äôd like prior reflect information have5.Last, \\(\\color{orange}{\\Pr(\\text{data})}\\) sometimes called average likelihood obtained integrating likelihood respect prior \\(\\color{orange}{\\Pr(\\text{data}) = \\int{L(\\text{data} \\mid \\theta)\\Pr(\\theta) d\\theta}}\\) posterior standardized, integrates one posterior distribution. average likelihood integral dimension number parameters \\(\\theta\\) need estimate. quantity difficult, impossible, calculate general. one reasons Bayesian method wasn‚Äôt used recently, need algorithms estimate posterior distributions illustrate next section."",""code"":""""},{""path"":""crashcourse.html"",""id"":""numerical-approx"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.4 Approximating posteriors via numerical integration"",""text"":""Let‚Äôs take example illustrate Bayes‚Äô theorem. Say capture, mark release \\(n = 57\\) animals beginning winter, recapture \\(y = 19\\) animals alive6. ‚Äôd like estimate winter survival \\(\\theta\\).build model first. Assuming animals independent survival probability, \\(y\\) number alive animals end winter binomial distribution7 \\(n\\) trials \\(\\theta\\) probability success:\\[\\begin{align*}\ny &\\sim \\text{Binomial}(n, \\theta) &\\text{[likelihood]}\n\\end{align*}\\]likelihood can visualised R:\nFigure 1.3: Binomial likelihood \\(n = 57\\) released animals \\(y = 19\\) survivors winter. value survival (x-axis) corresponds maximum likelihood function (y-axis) MLE, proportion success example, close 0.33.\nBesides likelihood, priors another component model Bayesian approach. parameter probability, one thing know prior continuous random variable lies 0 1. reflect , often go uniform distribution \\(U(0,1)\\) imply vague priors. vague means survival , see data, probability falling 0.1 0.2 0.8 0.9, example.\\[\\begin{align*}\n\\theta &\\sim \\text{Uniform}(0, 1) &\\text{[prior }\\theta \\text{]}\n\\end{align*}\\]Now apply Bayes‚Äô theorem. write R function computes product likelihood times prior, numerator Bayes‚Äô theorem: \\(\\Pr(\\text{data} \\mid \\theta) \\times \\Pr(\\theta)\\)write another function calculates denominator, average likelihood: \\(\\Pr(\\text{data}) = \\int{L(\\theta \\mid \\text{data}) \\Pr(\\theta) d\\theta}\\)use R function integrate calculate integral denominator, implements quadrature techniques divide little squares area underneath curve delimited function integrate (numerator), count .get numerical approximation posterior Figure 1.4 applying Bayes‚Äô theorem.\nFigure 1.4: Winter survival posterior distribution obtained numerical integration.\ngood numerical approximation survival posterior distribution? Ideally, want compare approximation true posterior distribution. Although closed-form expression posterior distribution general intractable, combine binomial likelihood together beta distribution prior, posterior distribution also beta distribution, makes amenable sorts exact calculations8. beta distribution continuous 0 1, extends uniform distribution situations outcomes equally likely. two parameters \\(\\) \\(b\\) control shape (Figure 1.5).\nFigure 1.5: distribution beta(\\(\\),\\(b\\)) different values \\(\\) \\(b\\). Note \\(= b = 1\\), get uniform distribution 0 1 top left panel. \\(\\) \\(b\\) equal, distribution symmetric, bigger \\(\\) \\(b\\), peaked distribution smaller variance.\n\nFigure 1.6: Comparison exact (dashed line) vs.¬†numerical approximation (continuous line) winter survival posterior distribution.\nexample, single parameter estimate, winter survival. means dealing one-dimensional integral denominator pretty easy quadrature techniques R function integrate(). Now multiple parameters? example, imagine ‚Äôd like fit capture-recapture model detection probability \\(p\\) regression parameters \\(\\alpha\\) \\(\\beta\\) intercept slope relationship survival probability covariate, Bayes‚Äô theorem gives posterior distribution three parameters together:\\[ \\Pr(\\alpha, \\beta, p \\mid \\text{data}) = \\frac{ \\Pr(\\text{data} \\mid \\alpha, \\beta, p) \\times \\Pr(\\alpha, \\beta, p)}{\\iiint \\, \\Pr(\\text{data} \\mid \\alpha, \\beta, p) \\Pr(\\alpha, \\beta, p) d\\alpha d\\beta dp} \\]\ntwo computational challenges formula. First, really wish calculate three-dimensional integral? answer , one-dimensional two-dimensional integrals much can go standard methods. Second, ‚Äôre interested posterior distribution parameter separately joint posterior distribution. -called marginal distribution \\(p\\) example obtained integrating parameters ‚Äì two-dimensional integral example. Now imagine tens hundreds parameters estimate, integrals become highly multi-dimensional simply intractable. next section, introduce powerful simulation methods circumvent issue."",""code"":""\ny <- 19 # nb of success\nn <- 57 # nb of attempts\ngrid <- seq(0, 1, 0.01) # grid of values for survival\nlikelihood <- dbinom(y, n, grid) # compute binomial likelihood\ndf <- data.frame(survival = grid, likelihood = likelihood) \ndf %>%\n  ggplot() + \n  aes(x = survival, y = likelihood) + \n  geom_line(size = 1.5)\nnumerator <- function(theta) dbinom(y, n, theta) * dunif(theta, 0, 1)\ndenominator <- integrate(numerator,0,1)$value\ngrid <- seq(0, 1, 0.01) # grid of values for theta\nnumerical_posterior <- data.frame(survival = grid, \n                                  posterior = numerator(grid)/denominator) # Bayes' theorem\nnumerical_posterior %>%\n  ggplot() +\n  aes(x = survival, y = posterior) + \n  geom_line(size = 1.5)""},{""path"":""crashcourse.html"",""id"":""markov-chain-monte-carlo-mcmc"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.5 Markov chain Monte Carlo (MCMC)"",""text"":""early 1990s, statisticians rediscovered work 1950‚Äôs physics. famous paper lay fundations modern Bayesian statistics (Figure 1.7), authors use simulations approximate posterior distributions precision drawing large samples. neat trick avoid explicit calculation multi-dimensional integrals struggle using Bayes‚Äô theorem.\nFigure 1.7: MCMC article cover. Source: Journal Chemical Physics\nsimulation algorithms called Markov chain Monte Carlo (MCMC), definitely gave boost Bayesian statistics. two parts MCMC, Markov chain Monte Carlo, let‚Äôs try make sense terms."",""code"":""""},{""path"":""crashcourse.html"",""id"":""monte-carlo-integration"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.5.1 Monte Carlo integration"",""text"":""Monte Carlo stand ? Monte Carlo integration simulation technique calculate integrals function \\(f\\) random variable \\(X\\) distribution \\(\\Pr(X)\\) say \\(\\int f(X) \\Pr(X)dX\\). draw values \\(X_1,\\ldots,X_k\\) \\(\\Pr(X)\\) distribution \\(X\\), apply function \\(f\\) values, calculate mean new values \\(\\displaystyle{\\frac{1}{k}}\\sum_{=1}^k{f(X_i)}\\) approximate integral. Monte Carlo integration used Bayesian context? posterior distribution contains information need parameter estimated. dealing many parameters however, may want summarise posterior results calculating numerical summaries. simplest numerical summary mean posterior distribution, \\(E(\\theta) = \\int \\theta \\Pr(\\theta|\\text{data})\\), \\(X\\) \\(\\theta\\) now \\(f\\) identity function. Posterior mean can calculated Monte Carlo integration:may check mean just calculated matches closely expectation beta distribution10:Another useful numerical summary credible interval within parameter falls probability, usually 0.95 hence 95\\(\\%\\) credible interval. Finding bounds credible interval requires calculating quantiles, turn involves integrals use Monte Carlo integration. 95\\(\\%\\) credible interval winter survival can obtained R :"",""code"":""\nsample_from_posterior <- rbeta(1000, 20, 39) # draw 1000 values from posterior survival beta(20,39)\nmean(sample_from_posterior) # compute mean with Monte Carlo integration\n## [1] 0.3394\n20/(20+39) # expectation of beta(20,39)\n## [1] 0.339\nquantile(sample_from_posterior, probs = c(2.5/100, 97.5/100))\n##   2.5%  97.5% \n## 0.2201 0.4670""},{""path"":""crashcourse.html"",""id"":""markovmodelmcmc"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.5.2 Markov chains"",""text"":""Markov chain? Markov chain random sequence numbers, number depends previous number. example weather home town Southern France, Montpellier, sunny day likely followed another sunny day, say probability 0.8, rainy day rarely followed another rainy day, say probability 0.1. dynamic Markov chain captured transition matrix \\(\\mathbf{\\Gamma}\\):\n\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    \\text{sunny tomorrow} & \\text{rainy tomorrow} \\\\\n0.8 & 0.2 \\\\\n0.9 & 0.1 \\\\\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    \\text{sunny today} \\\\ \\text{rainy today}\n    \\end{matrix}\n\\end{matrix}\n\\]\nrows weather today, columns weather tomorrow. cells give probability sunny rainy day tomorrow, given day sunny rainy today. certain conditions11, Markov chain converge unique stationary distribution. weather example, let‚Äôs run Markov chain 20 steps:row transition matrix converges distribution \\((0.82, 0.18)\\) number steps increases. Convergence happens matter state start , always probability 0.82 day sunny 0.18 day rainy.Back MCMC, core idea can build Markov chain given stationary distribution set desired posterior distribution."",""code"":""\nweather <- matrix(c(0.8, 0.2, 0.9, 0.1), nrow = 2, byrow = T) # transition matrix\nsteps <- 20\nfor (i in 1:steps){\n  weather <- weather %*% weather # matrix multiplication\n}\nround(weather, 2) # matrix product after 20 steps\n##      [,1] [,2]\n## [1,] 0.82 0.18\n## [2,] 0.82 0.18""},{""path"":""crashcourse.html"",""id"":""metropolis-algorithm"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.5.3 Metropolis algorithm"",""text"":""several ways constructing Markov chains Bayesian inference12. illustrate Metropolis algorithm implement practice13.Let‚Äôs go back example animal survival estimation. illustrate sampling survival posterior distribution. write functions likelihood, prior posterior.Metropolis algorithm works follows:pick value parameter estimated. start Markov chain ‚Äì starting value.pick value parameter estimated. start Markov chain ‚Äì starting value.decide go next, propose move away current value parameter ‚Äì candidate value. , add current value random value e.g.¬†normal distribution variance ‚Äì proposal distribution. Metropolis algorithm particular case Metropolis-Hastings algorithm symmetric proposals.decide go next, propose move away current value parameter ‚Äì candidate value. , add current value random value e.g.¬†normal distribution variance ‚Äì proposal distribution. Metropolis algorithm particular case Metropolis-Hastings algorithm symmetric proposals.compute ratio probabilities candidate current locations \\(R=\\displaystyle{\\frac{{\\Pr(\\text{candidate}|\\text{data})}}{{\\Pr(\\text{current}|\\text{data})}}}\\). magic MCMC happens, \\(\\Pr(\\text{data})\\), denominator Bayes‚Äô theorem, appears numerator denominator \\(R\\) therefore cancels need calculated.compute ratio probabilities candidate current locations \\(R=\\displaystyle{\\frac{{\\Pr(\\text{candidate}|\\text{data})}}{{\\Pr(\\text{current}|\\text{data})}}}\\). magic MCMC happens, \\(\\Pr(\\text{data})\\), denominator Bayes‚Äô theorem, appears numerator denominator \\(R\\) therefore cancels need calculated.posterior candidate location \\(\\Pr(\\text{candidate}|\\text{data})\\) higher current location \\(\\Pr(\\text{current}|\\text{data})\\), words candidate value plausible current value, definitely accept candidate value. , accept candidate value probability \\(R\\) reject probability \\(1-R\\). example, candidate value ten times less plausible current value, accept probability 0.1 reject probability 0.9. work practice? use continuous spinner lands somewhere 0 1 ‚Äì call random spin \\(X\\). \\(X\\) smaller \\(R\\), move candidate location, otherwise remain current location. want accept reject often. practice, Metropolis algorithm acceptance probability 0.2 0.4, can achieved tuning variance normal proposal distribution.posterior candidate location \\(\\Pr(\\text{candidate}|\\text{data})\\) higher current location \\(\\Pr(\\text{current}|\\text{data})\\), words candidate value plausible current value, definitely accept candidate value. , accept candidate value probability \\(R\\) reject probability \\(1-R\\). example, candidate value ten times less plausible current value, accept probability 0.1 reject probability 0.9. work practice? use continuous spinner lands somewhere 0 1 ‚Äì call random spin \\(X\\). \\(X\\) smaller \\(R\\), move candidate location, otherwise remain current location. want accept reject often. practice, Metropolis algorithm acceptance probability 0.2 0.4, can achieved tuning variance normal proposal distribution.repeat 2-4 number times ‚Äì steps.repeat 2-4 number times ‚Äì steps.Enough theory, let‚Äôs implement Metropolis algorithm R. Let‚Äôs start setting scene.Now follow 5 steps ‚Äôve just described. First, pick starting value, store (step 1)., need function propose candidate value. add value taken normal distribution mean zero standard deviation call away. work logit scale make sure candidate value survival lies 0 1.Now ‚Äôre ready steps 2, 3 4. write loop take care step 5. start initial value 0.5 run algorithm 100 steps iterations.get following values.\nFigure 1.8: Visualisation Markov chain starting value 0.5, steps iterations x-axis, samples y-axis. graphical representation called trace plot.\nacceptance probability average number times accepted candidated value, 0.44 almost satisfying.\nFigure 1.9: Trace plot survival two chains starting 0.2 (yellow) 0.5 (blue) run 100 steps.\n\nFigure 1.10: Trace plot survival chain starting 0.5 1000 steps.\n‚Äôre , trace plot looks like beautiful lawn, see Section 1.6. find informative look animated version Figure 1.10, helps understanding stochastic behavior algorithm, also realise chains converge stationary distribution, see Figure 1.11.\nFigure 1.11: Animated trace plot survival three chains starting 0.2, 0.5 0.7 run 1000 steps.\nstationary distribution reached, may regard realisations Markov chain sample posterior distribution, obtain numerical summaries. next section, consider several important implementation issues."",""code"":""\n# 19 animals recaptured alive out of 57 captured, marked and released\nsurvived <- 19\nreleased <- 57\n\n# binomial log-likelihood function\nloglikelihood <- function(x, p){\n  dbinom(x = x, size = released, prob = p, log = TRUE)\n}\n\n# uniform prior density\nlogprior <- function(p){\n  dunif(x = p, min = 0, max = 1, log = TRUE)\n}\n\n# posterior density function (log scale)\nposterior <- function(x, p){\n  loglikelihood(x, p) + logprior(p) # - log(Pr(data))\n}\nsteps <- 100 # number of steps\ntheta.post <- rep(NA, steps) # vector to store samples\naccept <- rep(NA, steps) # keep track of accept/reject\nset.seed(1234) # for reproducibility\ninits <- 0.5\ntheta.post[1] <- inits\naccept[1] <- 1\nmove <- function(x, away = 1){ # by default, standard deviation of the proposal distribution is 1\n  logitx <- log(x / (1 - x)) # apply logit transform (-infinity,+infinity)\n  logit_candidate <- logitx + rnorm(1, 0, away) # add a value taken from N(0,sd=away) to current value\n  candidate <- plogis(logit_candidate) # back-transform (0,1)\n  return(candidate)\n}\nfor (t in 2:steps){ # repeat steps 2-4 (step 5)\n  \n  # propose candidate value for survival (step 2)\n  theta_star <- move(theta.post[t-1])\n  \n  # calculate ratio R (step 3)\n  pstar <- posterior(survived, p = theta_star)  \n  pprev <- posterior(survived, p = theta.post[t-1])\n  logR <- pstar - pprev # likelihood and prior are on the log scale\n  R <- exp(logR)\n  \n  # accept candidate value or keep current value (step 4)\n  X <- runif(1, 0, 1) # spin continuous spinner\n  if (X < R){\n    theta.post[t] <- theta_star # accept candidate value\n    accept[t] <- 1 # accept\n  }\n  else{\n    theta.post[t] <- theta.post[t-1] # keep current value\n    accept[t] <- 0 # reject\n  }\n}\nhead(theta.post) # first values\n## [1] 0.5000 0.2302 0.2906 0.2906 0.2980 0.2980\ntail(theta.post) # last values\n## [1] 0.2622 0.2622 0.2622 0.3727 0.3232 0.3862""},{""path"":""crashcourse.html"",""id"":""convergence-diag"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.6 Assessing convergence"",""text"":"""",""code"":""""},{""path"":""crashcourse.html"",""id"":""burn-in"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.6.1 Burn-in"",""text"":""practice, discard observations start Markov chain just use observations chain converged. initial observations discard usually referred burn-.simplest method determine length burn-period look trace plots. Going back example, see trace plot Figure 1.12 need least 100 iterations achieve convergence toward average survival around 0.3. always better conservative specifying length burn-period, example, use 250 even 500 iterations burn-. length burn-period can determined performing preliminary MCMC short runs.\nFigure 1.12: Determining length burn-period. chain starts value 0.99 rapidly stabilises, values bouncing back forth around 0.3 100th iteration onwards. may choose shaded area burn-, discard corresponding values.\nInspecting trace plot single run Markov chain useful. However, usually run Markov chain several times, starting different -dispersed points, check runs achieve stationary distribution. approach formalised using Brooks-Gelman-Rubin (BGR) statistic \\(\\hat{R}\\) measures ratio total variability combining multiple chains (-chain plus within-chain) within-chain variability. BGR statistic asks whether chain effect, much alike \\(F\\) test analysis variance. Values 1.1 indicate likely convergence.Back example, run two Markov chains starting values 0.2 0.8 using 100 5000 iterations, calculate BGR statistic using half number iterations length burn-. Figure 1.13, get value BGR statistic near 1 2000 iterations, suggests 2000 iterations burn-, evidence lack convergence.\nFigure 1.13: Brooks-Gelman-Rubin statistic function number iterations.\nimportant bear mind value near 1 BGR statistic necessary sufficient condition convergence. words, diagnostic tell sure Markov chain achieved convergence, .14"",""code"":""""},{""path"":""crashcourse.html"",""id"":""chain-length"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.6.2 Chain length"",""text"":""long chain needed produce reliable parameter estimates? answer question, need keep mind successive steps Markov chain independent ‚Äì usually referred autocorrelation. Ideally, like keep autocorrelation low possible. , trace plots useful diagnose issues autocorrelation. Let‚Äôs get back survival example. Figure 1.14 shows trace plots different values standard deviation (parameter away) (normal) proposal distribution use propose candidate value (Section 1.5.3). Small big moves provide high correlations successive observations Markov chain, whereas standard deviation 1 allows efficient exploration parameter space. movement around parameter space referred mixing. Mixing bad chain makes small big moves, good otherwise.\nFigure 1.14: Trace plots different values standard deviation (SD) proposal distribution. Left: chain exhibits small moves mixing bad. Right: chain exhibits big moves mixing bad. Middle: chain exhibits adequate moves mixing good. thousand last iterations shown.\naddition trace plots, autocorrelation function (ACF) plots convenient way displaying strength autocorrelation given sample values. ACF plots provide autocorrelation successively sampled values separated increasing number iterations, lag (Figure 1.15).\nFigure 1.15: Autocorrelation function plots different values standard deviation (SD) proposal distribution. Left right: Autocorrelation strong, decreases slowly increasing lag mixing bad. Middle: Autocorrelation weak, decreases rapidly increasing lag mixing good.\nAutocorrelation necessarily big issue. Strongly correlated observations just require large sample sizes therefore longer simulations. many iterations exactly? effective sample size (n.eff) measures chain length taking account chain autocorrelation. check n.eff every parameter interest, interesting parameter combinations. general, need \\(\\text{n.eff} \\geq 1000\\) independent steps get reasonable Monte Carlo estimates model parameters. animal survival example, n.eff can calculated R coda::effectiveSize() function.expected, n.eff less number MCMC iterations autocorrelation. standard deviation proposal distribution 1 mixing good (Figures 1.14 1.15) get satisfying effective sample size."",""code"":""""},{""path"":""crashcourse.html"",""id"":""what-if-you-have-issues-of-convergence"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.6.3 What if you have issues of convergence?"",""text"":""diagnosing MCMC convergence, () often run troubles. section find helpful tips hope.mixing bad effective sample size small, may just need increase burn-/sample . Using informative priors might also make Markov chains converge faster helping MCMC sampler (e.g.¬†Metropolis algorithm) navigating efficiently parameter space. spirit, picking better initial values starting chain harm. , strategy consists using estimates simpler model MCMC chains converge.convergence issues persist, often problem model15. bug code? typo somewhere? mistake maths? often coding involved, issue can identified removing complexities, start simpler model find problem .general advice see model data generating tool first place, simulate data using realistic values parameters, try recover parameter values fitting model simulated data. Simulating model help understanding works, , data need get reasonable parameter estimates.see strategies improve convergence next chapters.16"",""code"":""""},{""path"":""crashcourse.html"",""id"":""summary"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.7 Summary"",""text"":""Bayes‚Äô theorem, update beliefs (prior) new data (likelihood) get posterior beliefs (posterior): posterior \\(\\propto\\) likelihood \\(\\times\\) prior.Bayes‚Äô theorem, update beliefs (prior) new data (likelihood) get posterior beliefs (posterior): posterior \\(\\propto\\) likelihood \\(\\times\\) prior.idea Markov chain Monte Carlo (MCMC) simulate values Markov chain stationary distribution equal posterior distribution ‚Äôre .idea Markov chain Monte Carlo (MCMC) simulate values Markov chain stationary distribution equal posterior distribution ‚Äôre .practice, run Markov chain multiple times starting -dispersed initial values.practice, run Markov chain multiple times starting -dispersed initial values.discard iterations initial burn-phase achieve convergence chains reach regime.discard iterations initial burn-phase achieve convergence chains reach regime., run chains long enough proceed calculating Monte Carlo estimates numerical summaries (e.g.¬†posterior means credible intervals) parameters., run chains long enough proceed calculating Monte Carlo estimates numerical summaries (e.g.¬†posterior means credible intervals) parameters."",""code"":""""},{""path"":""crashcourse.html"",""id"":""suggested-reading"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.8 Suggested reading"",""text"":""Gelman, . Hill, J. (2006). Data Analysis Using Regression Multilevel/Hierarchical Models (Analytical Methods Social Research). Cambridge: Cambridge University Press.Gelman, . Hill, J. (2006). Data Analysis Using Regression Multilevel/Hierarchical Models (Analytical Methods Social Research). Cambridge: Cambridge University Press.Gelman, . colleagues (2020). Bayesian workflow. arXiv preprint.Gelman, . colleagues (2020). Bayesian workflow. arXiv preprint.McCarthy, M. (2007). Bayesian Methods Ecology. Cambridge: Cambridge University Press.McCarthy, M. (2007). Bayesian Methods Ecology. Cambridge: Cambridge University Press.McElreath, R. (2020). Statistical Rethinking: Bayesian Course Examples R Stan (2nd ed.). CRC Press.McElreath, R. (2020). Statistical Rethinking: Bayesian Course Examples R Stan (2nd ed.). CRC Press."",""code"":""""},{""path"":""introduction-2.html"",""id"":""introduction-2"",""chapter"":""Introduction"",""heading"":""Introduction"",""text"":"""",""code"":""""},{""path"":""introduction-3.html"",""id"":""introduction-3"",""chapter"":""Introduction"",""heading"":""Introduction"",""text"":"""",""code"":""""},{""path"":""tradeoffs.html"",""id"":""tradeoffs"",""chapter"":""2 Life history"",""heading"":""2 Life history"",""text"":"""",""code"":""""},{""path"":""tradeoffs.html"",""id"":""access-to-reproduction"",""chapter"":""2 Life history"",""heading"":""2.1 Access to reproduction"",""text"":""Flamants."",""code"":""""},{""path"":""tradeoffs.html"",""id"":""tradeoffs-1"",""chapter"":""2 Life history"",""heading"":""2.2 Tradeoffs"",""text"":""Morano et al. (2013), Shefferson et al. (2003), Cruz-Flores et al. (n.d.)"",""code"":""""},{""path"":""tradeoffs.html"",""id"":""breeding-dynamics"",""chapter"":""2 Life history"",""heading"":""2.3 Breeding dynamics"",""text"":""Pradel, Choquet, B√©chet (2012), Desprez et al. (2011), Desprez et al. (2013), Pacoureau et al. (2019)"",""code"":""""},{""path"":""covariates.html"",""id"":""covariates"",""chapter"":""3 Covariates"",""heading"":""3 Covariates"",""text"":"""",""code"":""""},{""path"":""covariates.html"",""id"":""missing-values"",""chapter"":""3 Covariates"",""heading"":""3.1 Missing values"",""text"":""NAs reprise du papier de Bonner, ou mod√®le de croissance poisson, ou rien hein‚Ä¶Work missing values Bonner et al.¬†(2006) Langrock King (2013) Worthington et al.¬†(2015)."",""code"":""""},{""path"":""covariates.html"",""id"":""nonlinearities"",""chapter"":""3 Covariates"",""heading"":""3.2 Nonlinearities"",""text"":""splines √† la main et avec jagam, ex snow petrels"",""code"":""""},{""path"":""covariates.html"",""id"":""covariate-selection"",""chapter"":""3 Covariates"",""heading"":""3.3 Covariate selection"",""text"":""rjmcmc turdus merila, papier Evolution Gimenez. Exemple cigognes, papier Gimenez WinBUGS."",""code"":""""},{""path"":""covariates.html"",""id"":""sex-uncertainty"",""chapter"":""3 Covariates"",""heading"":""3.4 Sex uncertainty"",""text"":""Pradel et al. (2008) Genovart, Pradel, Oro (2012)"",""code"":""""},{""path"":""covariates.html"",""id"":""actuarial-senescence"",""chapter"":""3 Covariates"",""heading"":""3.5 Actuarial senescence"",""text"":""Choquet et al. (2011), P√©ron et al. (2016), Marzolin dipper Ecology."",""code"":""""},{""path"":""covariates.html"",""id"":""covariate-on-multinomial-logit-link"",""chapter"":""3 Covariates"",""heading"":""3.6 Covariate on multinomial logit link"",""text"":""papier Lorele√Ø"",""code"":""""},{""path"":""covariates.html"",""id"":""uncertainty-in-age"",""chapter"":""3 Covariates"",""heading"":""3.7 Uncertainty in age"",""text"":""Papier Vincenzo et d‚Äôautre papiers."",""code"":""""},{""path"":""misc.html"",""id"":""misc"",""chapter"":""4 Miscelleanous"",""heading"":""4 Miscelleanous"",""text"":"""",""code"":""""},{""path"":""misc.html"",""id"":""dependence-among-individuals"",""chapter"":""4 Miscelleanous"",""heading"":""4.1 Dependence among individuals"",""text"":""Culina et al. (2013) Cubaynes et al. (2021)"",""code"":""""},{""path"":""misc.html"",""id"":""cause-specific-mortalities"",""chapter"":""4 Miscelleanous"",""heading"":""4.2 Cause-specific mortalities"",""text"":""Fern√°ndez-Chac√≥n et al. (2016) Ruette et al. (2015)"",""code"":""""},{""path"":""misc.html"",""id"":""disease-dynamics"",""chapter"":""4 Miscelleanous"",""heading"":""4.3 Disease dynamics"",""text"":""Marescot et al. (2018) Santoro et al. (2014). House finch well."",""code"":""""},{""path"":""misc.html"",""id"":""combine-live-captures-and-dead-recoveries"",""chapter"":""4 Miscelleanous"",""heading"":""4.4 Combine live captures and dead recoveries"",""text"":""Combine live recapture w/ dead recoveries Lebreton et al.¬†(1999) go spatial account emigration Gilroy et al.¬†(2012) Schaub & Royle (2014)."",""code"":""""},{""path"":""misc.html"",""id"":""stopover-duration"",""chapter"":""4 Miscelleanous"",""heading"":""4.5 Stopover duration"",""text"":""voir? Papier de Guerin et al.¬†(2017)"",""code"":""""},{""path"":""misc.html"",""id"":""prior-info"",""chapter"":""4 Miscelleanous"",""heading"":""4.6 Prior info"",""text"":""Papier McCarthy Pipper. Cf le code et tout dans le fichier leftover. Ajouter figure avec 3, 4 et 5 ans seulement.example incorporate prior information McCarthy Masters (2005)."",""code"":""""},{""path"":""misc.html"",""id"":""posterior-predictive-check"",""chapter"":""4 Miscelleanous"",""heading"":""4.7 Posterior predictive check"",""text"":""M-array avec Paganin et de Valpine. Puis IH avec Chambert. Et aussi geometric avec Conn et al.¬†"",""code"":""""},{""path"":""misc.html"",""id"":""others"",""chapter"":""4 Miscelleanous"",""heading"":""4.8 Others"",""text"":""Multispecies. Phylogeny. Path analysis, SEM. Exemple Nina loup hybrides, ou pr√©valence disease, ou sex-ratio, ou la LRS comme dans papier TPB. Manque s√ªrement qqch sur l‚Äôint√©r√™t des simulations, en faire un CS? V√©rifier que les posterior predictive checks sont trait√©s quelque part."",""code"":""""},{""path"":""lackoffit.html"",""id"":""lackoffit"",""chapter"":""5 Lack of fit"",""heading"":""5 Lack of fit"",""text"":"""",""code"":""""},{""path"":""lackoffit.html"",""id"":""individual-heterogeneity"",""chapter"":""5 Lack of fit"",""heading"":""5.1 Individual heterogeneity"",""text"":""Cubaynes et al. (2010), Gimenez Choquet (2010), Turek, Wehrhahn, Gimenez (2021). Example wolf. Traiter label switching avec constraint dans Nimble. Aussi go fully non-parametric, w/ Daniel‚Äôs paper. Ou bien exercice mouettes des workshops E-SURGE?"",""code"":""""},{""path"":""lackoffit.html"",""id"":""trap-dep"",""chapter"":""5 Lack of fit"",""heading"":""5.2 Trap dep"",""text"":""Papier Roger & Ana. Sur dipper ? Add example trap-dependence w/ time individual covariate.https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0032666"",""code"":""""},{""path"":""lackoffit.html"",""id"":""transience"",""chapter"":""5 Lack of fit"",""heading"":""5.3 Transience"",""text"":""Multievent treatment.https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0222241"",""code"":""""},{""path"":""lackoffit.html"",""id"":""temporary-emigration"",""chapter"":""5 Lack of fit"",""heading"":""5.4 Temporary emigration"",""text"":""papier Michael."",""code"":""""},{""path"":""lackoffit.html"",""id"":""memory-model"",""chapter"":""5 Lack of fit"",""heading"":""5.5 Memory model"",""text"":"""",""code"":""""},{""path"":""introduction-4.html"",""id"":""introduction-4"",""chapter"":""Introduction"",""heading"":""Introduction"",""text"":"""",""code"":""""},{""path"":""take-home-messages.html"",""id"":""take-home-messages"",""chapter"":""Take-home messages"",""heading"":""Take-home messages"",""text"":""‚Äì>\n ‚Äì>‚Äì>‚Äì>‚Äì>"",""code"":""""},{""path"":""references.html"",""id"":""references"",""chapter"":""References"",""heading"":""References"",""text"":"""",""code"":""""}]

---FILE: docs/take-home-messages.html---
@@ -0,0 +1,233 @@
+<!DOCTYPE html>
+<html lang=""en"">
+<head>
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>Take-home messages | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""‚Äì&gt; ‚Äì&gt; ‚Äì&gt; ‚Äì&gt; ‚Äì&gt;"">
+<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
+<meta property=""og:title"" content=""Take-home messages | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/take-home-messages.html"">
+<meta property=""og:description"" content=""‚Äì&gt; ‚Äì&gt; ‚Äì&gt; ‚Äì&gt; ‚Äì&gt;"">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""Take-home messages | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""‚Äì&gt; ‚Äì&gt; ‚Äì&gt; ‚Äì&gt; ‚Äì&gt;"">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+    
+    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
+  </style>
+<style type=""text/css"">
+    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
+    div.csl-bib-body { }
+    div.csl-entry {
+      clear: both;
+        }
+    .hanging div.csl-entry {
+      margin-left:2em;
+      text-indent:-2em;
+    }
+    div.csl-left-margin {
+      min-width:2em;
+      float:left;
+    }
+    div.csl-right-inline {
+      margin-left:2em;
+      padding-left:1em;
+    }
+    div.csl-indent {
+      margin-left: 2em;
+    }
+  </style>
+<link rel=""stylesheet"" href=""bs4_style.css"">
+</head>
+<body data-spy=""scroll"" data-target=""#toc"">
+
+<div class=""container-fluid"">
+<div class=""row"">
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+
+    <div class=""d-flex align-items-start justify-content-between"">
+      <h1>
+        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
+        <small class=""text-muted"">Theory and Case Studies in R</small>
+      </h1>
+      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
+    </div>
+
+    <div id=""main-nav"" class=""collapse-lg"">
+      <form role=""search"">
+        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
+</form>
+
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li><a class="""" href=""about-the-author.html"">About the author</a></li>
+<li class=""book-part"">I. Foundations</li>
+<li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li class=""book-part"">II. Transitions</li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li class=""book-part"">III. Case studies</li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li class=""book-part"">IV. Conclusions</li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class=""active"" href=""take-home-messages.html"">Take-home messages</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
+
+        <div class=""book-extra"">
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
+        </div>
+      </nav>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""take-home-messages"" class=""section level1 unnumbered"">
+<h1>Take-home messages<a class=""anchor"" aria-label=""anchor"" href=""#take-home-messages""><i class=""fas fa-link""></i></a>
+</h1>
+<!-- ## Take-home messages and recommendations -->
+<!-- + We'll wrap up the workshop with a few take-home messages  -->
+<!-- + And recommendations for conducting your own analyses. -->
+<!-- ## Make the best of your data with HMMs -->
+<!-- + Here is [a searchable list](applistHMM.html) of HMM analyses of capture-recapture data. -->
+<!-- + We hope to have provided you with a useful overview of how to use hidden Markov models to analyze capture-recapture data.  -->
+<!-- + We have only scratched the surface of what you can do with these models.  -->
+<!-- + We have assembled a searchable list of HMM analyses of capture-recapture data to get inspiration.  -->
+<!-- + This list is not exhaustive, please get in touch with us if you'd like to add a reference. -->
+<!-- + It is not exhaustive, we'll continue updating it. Feel free to suggest papers to add to the list.  -->
+<!-- ## Bayesian capture-recapture analysis with HMMs -->
+<!-- + Before we leave, we'd like to give you a few pieces of advice. -->
+<!-- + This is not rocket science. -->
+<!-- + Just a few things based on our own experience of Bayesian capture-recapture analysis with HMMS. -->
+<!-- + Make your ecological question explicit.  -->
+<!-- + First things first. Make sure you've spent some to time to make your ecological question explicit.  -->
+<!-- + This step will help you to stay on course, and make the right choices.  -->
+<!-- + For example, it's ok to use subsets of your data to address different questions.  -->
+<!-- + Think of observations and states first.  -->
+<!-- + Now in terms of modeling. Don't jump on your keyboard right away.  -->
+<!-- + Spend some time thinking about your model with pen and paper.  -->
+<!-- + In particular make sure you have the observations and the states of your HMM.  -->
+<!-- + Then write down the observation and transition matrices on paper.  -->
+<!-- + Then write down the transition matrix. You may act as if you had no imperfect detection. This is really what you're after, the ecological process (survival, dispersal, etc).  -->
+<!-- + Proceed with the observation matrix.  -->
+<!-- + Start simple, all parameters constant for example. Make sure convergence is reached. -->
+<!-- + When it comes to model fitting with Nimble, start simple.  -->
+<!-- + Consider all parameters constant.  -->
+<!-- + Make sure convergence is reached.  -->
+<!-- + Add complexity one step at a time.  -->
+<!-- + Then add complexity. Time effect for example. Or random effects. -->
+<!-- + Or uncertainty in the assignment of states.  -->
+<!-- ## Bayesian capture-recapture analysis with HMMs -->
+<!-- + Use simulations to better understand your model.  -->
+<!-- + Nimble models can be used to simulate data, check out [this tutorial](https://r-nimble.org/nimbleExamples/simulation_from_model.html).   -->
+<!-- + When it comes to model building, consider simulating data to better understand your model.  -->
+<!-- + You will always learn something on your model by seeing it an engine to generate data, instead of estimating its parameters. -->
+<!-- + The cool thing with nimble is that you can you models to simulate data. There is a tutorial for that.   -->
+<!-- + Do not try to optimize your code. Make it work first, then think of optimization.  -->
+<!-- > [""Premature optimization is the root of all evil""](https://stackify.com/premature-optimization-evil/) - Donald Knuth (creator of TeX and author of [""The Art of Computer Programming""](https://en.wikipedia.org/wiki/The_Art_of_Computer_Programming)) -->
+<!-- + Another advice, quite general in programming, is to not try to optimize your code -->
+<!-- + Or to try to make it elegant right away. Make it work first.  -->
+<!-- + Then think of optimization.  -->
+<!-- + Read [Bayesian workflow](https://arxiv.org/abs/2011.01808) by Gelman et al. (2021). -->
+<!-- + More recommendations on Bayesian analyses in this recent paper by Gelman and collaborations.  -->
+<!-- + They offer a workflow for bayesian analyses. -->
+<!-- + In which they discuss model building, model comparison, model checking, model validation, model understanding and troubleshooting of computational problems. -->
+<!-- <!-- --- -->
+<p>‚Äì&gt;
+<!-- <!-- ## Nimble --> ‚Äì&gt;</p>
+<!-- <!-- + [TO BE COMPLETED BY ALL] -->
+<p>‚Äì&gt;</p>
+<!-- <!-- + Go for `nimbleMCMC()` if standard needs.  -->
+<p>‚Äì&gt;</p>
+<!-- <!-- + Unleash full `Nimble` potential for improving MCMC or implementing new distributions.  -->
+<p>‚Äì&gt;</p>
+<!-- ## Till next time -->
+<!-- + The Slack space will remain for some time. Happy to answer questions you might have related to the workshop.  -->
+<!-- + The Slack space will remain for some time.  -->
+<!-- + We'll be happy to answer the questions you might have related to the workshop.  -->
+<!-- + Website will be updated with -->
+<!--     + video recordings -->
+<!--     + your feedbacks -->
+<!--     + a FAQ section based on your questions -->
+<!-- + We will update the workshop website in the coming weeks.  -->
+<!-- + With the video recordings of course.  -->
+<!-- + Any feedback you might have. Please get in touch with me if you have any, that would be great.  -->
+<!-- + Our plan is also to gather our exchanges in a Frequently Asked Questions section on the website.  -->
+<!-- + A book is on its way. More in 2022 hopefully. -->
+<!-- + And last, a book is on its way. Based on the material we used for the workshop and more stuff.  -->
+<!-- + Also half the book will be about case studies reproducing analysis from published papers.  -->
+<!-- + More in 2022 hopefully.  -->
+<!-- ## Let's see if I can put to use my own pieces of advice - case studies -->
+
+</div>
+  <div class=""chapter-nav"">
+<div class=""prev""><a href=""introduction-4.html"">Introduction</a></div>
+<div class=""next""><a href=""references.html"">References</a></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
+      <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#take-home-messages"">Take-home messages</a></li></ul>
+
+      <div class=""book-extra"">
+        <ul class=""list-unstyled"">
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionpartfour.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionpartfour.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+        </ul>
+</div>
+    </nav>
+</div>
+
+</div>
+</div> <!-- .container -->
+
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-14.</p>
+  </div>
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
+  </div>
+
+</div></div>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
+</body>
+</html>

---FILE: docs/tradeoffs.html---
@@ -0,0 +1,184 @@
+<!DOCTYPE html>
+<html lang=""en"">
+<head>
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>Chapter 2 Life history | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""2.1 Access to reproduction Flamants.  2.2 Tradeoffs Morano et al. (2013), Shefferson et al. (2003), and Cruz-Flores et al. (n.d.)  2.3 Breeding dynamics Pradel, Choquet, and B√©chet (2012), Desprez..."">
+<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
+<meta property=""og:title"" content=""Chapter 2 Life history | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/tradeoffs.html"">
+<meta property=""og:description"" content=""2.1 Access to reproduction Flamants.  2.2 Tradeoffs Morano et al. (2013), Shefferson et al. (2003), and Cruz-Flores et al. (n.d.)  2.3 Breeding dynamics Pradel, Choquet, and B√©chet (2012), Desprez..."">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""Chapter 2 Life history | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""2.1 Access to reproduction Flamants.  2.2 Tradeoffs Morano et al. (2013), Shefferson et al. (2003), and Cruz-Flores et al. (n.d.)  2.3 Breeding dynamics Pradel, Choquet, and B√©chet (2012), Desprez..."">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+    
+    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
+  </style>
+<style type=""text/css"">
+    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
+    div.csl-bib-body { }
+    div.csl-entry {
+      clear: both;
+        }
+    .hanging div.csl-entry {
+      margin-left:2em;
+      text-indent:-2em;
+    }
+    div.csl-left-margin {
+      min-width:2em;
+      float:left;
+    }
+    div.csl-right-inline {
+      margin-left:2em;
+      padding-left:1em;
+    }
+    div.csl-indent {
+      margin-left: 2em;
+    }
+  </style>
+<link rel=""stylesheet"" href=""bs4_style.css"">
+</head>
+<body data-spy=""scroll"" data-target=""#toc"">
+
+<div class=""container-fluid"">
+<div class=""row"">
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+
+    <div class=""d-flex align-items-start justify-content-between"">
+      <h1>
+        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
+        <small class=""text-muted"">Theory and Case Studies in R</small>
+      </h1>
+      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
+    </div>
+
+    <div id=""main-nav"" class=""collapse-lg"">
+      <form role=""search"">
+        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
+</form>
+
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li><a class="""" href=""about-the-author.html"">About the author</a></li>
+<li class=""book-part"">I. Foundations</li>
+<li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li class=""book-part"">II. Transitions</li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li class=""book-part"">III. Case studies</li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class=""active"" href=""tradeoffs.html""><span class=""header-section-number"">2</span> Life history</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></li>
+<li><a class="""" href=""misc.html""><span class=""header-section-number"">4</span> Miscelleanous</a></li>
+<li><a class="""" href=""lackoffit.html""><span class=""header-section-number"">5</span> Lack of fit</a></li>
+<li class=""book-part"">IV. Conclusions</li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
+
+        <div class=""book-extra"">
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
+        </div>
+      </nav>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""tradeoffs"" class=""section level1"" number=""2"">
+<h1>
+<span class=""header-section-number"">2</span> Life history<a class=""anchor"" aria-label=""anchor"" href=""#tradeoffs""><i class=""fas fa-link""></i></a>
+</h1>
+<div id=""access-to-reproduction"" class=""section level2"" number=""2.1"">
+<h2>
+<span class=""header-section-number"">2.1</span> Access to reproduction<a class=""anchor"" aria-label=""anchor"" href=""#access-to-reproduction""><i class=""fas fa-link""></i></a>
+</h2>
+<p>Flamants.</p>
+</div>
+<div id=""tradeoffs-1"" class=""section level2"" number=""2.2"">
+<h2>
+<span class=""header-section-number"">2.2</span> Tradeoffs<a class=""anchor"" aria-label=""anchor"" href=""#tradeoffs-1""><i class=""fas fa-link""></i></a>
+</h2>
+<p><span class=""citation"">Morano et al. (<a href=""references.html#ref-morano_life-history_2013"">2013</a>)</span>, <span class=""citation"">Shefferson et al. (<a href=""references.html#ref-shefferson_life_2003"">2003</a>)</span>, and <span class=""citation"">Cruz-Flores et al. (<a href=""references.html#ref-cruz-flores_sex-specific_nodate"">n.d.</a>)</span></p>
+</div>
+<div id=""breeding-dynamics"" class=""section level2"" number=""2.3"">
+<h2>
+<span class=""header-section-number"">2.3</span> Breeding dynamics<a class=""anchor"" aria-label=""anchor"" href=""#breeding-dynamics""><i class=""fas fa-link""></i></a>
+</h2>
+<p><span class=""citation"">Pradel, Choquet, and B√©chet (<a href=""references.html#ref-pradel_breeding_2012"">2012</a>)</span>, <span class=""citation"">Desprez et al. (<a href=""references.html#ref-desprez_now_2011"">2011</a>)</span>, <span class=""citation"">Desprez et al. (<a href=""references.html#ref-desprez_known_2013"">2013</a>)</span>, and <span class=""citation"">Pacoureau et al. (<a href=""references.html#ref-pacoureau_population_2019"">2019</a>)</span></p>
+
+</div>
+</div>
+  <div class=""chapter-nav"">
+<div class=""prev""><a href=""introduction-3.html"">Introduction</a></div>
+<div class=""next""><a href=""covariates.html""><span class=""header-section-number"">3</span> Covariates</a></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
+      <ul class=""nav navbar-nav"">
+<li><a class=""nav-link"" href=""#tradeoffs""><span class=""header-section-number"">2</span> Life history</a></li>
+<li><a class=""nav-link"" href=""#access-to-reproduction""><span class=""header-section-number"">2.1</span> Access to reproduction</a></li>
+<li><a class=""nav-link"" href=""#tradeoffs-1""><span class=""header-section-number"">2.2</span> Tradeoffs</a></li>
+<li><a class=""nav-link"" href=""#breeding-dynamics""><span class=""header-section-number"">2.3</span> Breeding dynamics</a></li>
+</ul>
+
+      <div class=""book-extra"">
+        <ul class=""list-unstyled"">
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/lifehistory.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/lifehistory.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+        </ul>
+</div>
+    </nav>
+</div>
+
+</div>
+</div> <!-- .container -->
+
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-14.</p>
+  </div>
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
+  </div>
+
+</div></div>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
+</body>
+</html>",False,True,Documentation / Formatting,7
oliviergimenez,banana-book,a0462f4099a2cd51b489f249d1a2b2445457ad35,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2023-08-12T14:52:06Z,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2023-08-12T14:52:06Z,"All in again. I give up finding issue w/ figures in Chapter 4, for now.",_bookdown.yml;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-72-1.png;docs/404.html;docs/about-the-author.html;docs/banana-book_files/figure-html/unnamed-chunk-72-1.png;docs/crashcourse.html;docs/dispersal.html;docs/hmmcapturerecapture.html;docs/images/amazing-thomas-bayes-illustration.jpg;docs/images/arnason1973.png;docs/images/bayes_neon.jpeg;docs/images/deadpool.gif;docs/images/metropolis.png;docs/images/multistate_local_minimav2_Page_05.png;docs/images/multistate_local_minimav2_Page_06.png;docs/images/multistate_local_minimav2_Page_07.png;docs/images/nichols.png;docs/images/nimble-icon.png;docs/images/schwarz1993.png;docs/images/sooty.jpg;docs/images/traceplotMCMC.gif;docs/index.html;docs/introduction-4.html;docs/introduction-7.html;docs/introduction-8.html;docs/introduction.html;docs/intronimble.html;docs/preface.html;docs/reference-keys.txt;docs/references.html;docs/search.json;docs/survival.html;docs/take-home-messages.html,True,False,True,False,44238,329,44567,"---FILE: _bookdown.yml---
@@ -17,12 +17,12 @@ rmd_files:
     ""preface.Rmd"",
     ""author.Rmd"",
     ""introductionpartone.Rmd"",
-   # ""bayesmcmc.Rmd"",
-  #  ""nimble.Rmd"",
-  #  ""hmm.Rmd"",
+    ""bayesmcmc.Rmd"",
+    ""nimble.Rmd"",
+    ""hmm.Rmd"",
     ""introductionparttwo.Rmd"",
     ""survival.Rmd"",
-   # ""dispersal.Rmd"",
+    ""dispersal.Rmd"",
     ""introductionpartthree.Rmd"",
   # ""lht.Rmd"",
   #  ""abundance.Rmd"",

---FILE: docs/404.html---
@@ -73,13 +73,17 @@ <h1>
 <li><a class="""" href=""about-the-author.html"">About the author</a></li>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">1</span> Survival</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>

---FILE: docs/about-the-author.html---
@@ -73,13 +73,17 @@ <h1>
 <li><a class=""active"" href=""about-the-author.html"">About the author</a></li>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">1</span> Survival</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>

---FILE: docs/crashcourse.html---
@@ -0,0 +1,619 @@
+<!DOCTYPE html>
+<html lang=""en"">
+<head>
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>Chapter 1 Bayesian statistics &amp; MCMC | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""1.1 Introduction In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to..."">
+<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
+<meta property=""og:title"" content=""Chapter 1 Bayesian statistics &amp; MCMC | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/crashcourse.html"">
+<meta property=""og:description"" content=""1.1 Introduction In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to..."">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""Chapter 1 Bayesian statistics &amp; MCMC | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""1.1 Introduction In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to..."">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+    
+    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
+  </style>
+<style type=""text/css"">
+    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
+    div.csl-bib-body { }
+    div.csl-entry {
+      clear: both;
+        }
+    .hanging div.csl-entry {
+      margin-left:2em;
+      text-indent:-2em;
+    }
+    div.csl-left-margin {
+      min-width:2em;
+      float:left;
+    }
+    div.csl-right-inline {
+      margin-left:2em;
+      padding-left:1em;
+    }
+    div.csl-indent {
+      margin-left: 2em;
+    }
+  </style>
+<link rel=""stylesheet"" href=""bs4_style.css"">
+</head>
+<body data-spy=""scroll"" data-target=""#toc"">
+
+<div class=""container-fluid"">
+<div class=""row"">
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+
+    <div class=""d-flex align-items-start justify-content-between"">
+      <h1>
+        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
+        <small class=""text-muted"">Theory and Case Studies in R</small>
+      </h1>
+      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
+    </div>
+
+    <div id=""main-nav"" class=""collapse-lg"">
+      <form role=""search"">
+        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
+</form>
+
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li><a class="""" href=""about-the-author.html"">About the author</a></li>
+<li class=""book-part"">I. Foundations</li>
+<li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class=""active"" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
+<li class=""book-part"">II. Transitions</li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
+<li class=""book-part"">III. Case studies</li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li class=""book-part"">IV. Conclusions</li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
+<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
+
+        <div class=""book-extra"">
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
+        </div>
+      </nav>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""crashcourse"" class=""section level1"" number=""1"">
+<h1>
+<span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC<a class=""anchor"" aria-label=""anchor"" href=""#crashcourse""><i class=""fas fa-link""></i></a>
+</h1>
+<div id=""introduction-1"" class=""section level2"" number=""1.1"">
+<h2>
+<span class=""header-section-number"">1.1</span> Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-1""><i class=""fas fa-link""></i></a>
+</h2>
+<p>In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to implement the Bayesian method for more complex analyses. This is not an exhaustive treatment of Bayesian statistics, but you should get what you need to navigate through the rest of the book.</p>
+</div>
+<div id=""bayes-theorem"" class=""section level2"" number=""1.2"">
+<h2>
+<span class=""header-section-number"">1.2</span> Bayes‚Äô theorem<a class=""anchor"" aria-label=""anchor"" href=""#bayes-theorem""><i class=""fas fa-link""></i></a>
+</h2>
+<p>Let‚Äôs not wait any longer and jump into it. Bayesian statistics relies on the Bayes‚Äô theorem (or law, or rule, whatever you prefer) named after Reverend Thomas Bayes (Figure <a href=""crashcourse.html#fig:revbayes"">1.1</a>). This theorem was published in 1763 two years after Bayes‚Äô death thanks to his friend‚Äôs efforts Richard Price, and was independently discovered by Pierre-Simon Laplace <span class=""citation"">(<a href=""references.html#ref-mcgrayne2011"">McGrayne 2011</a>)</span>.</p>
+<div class=""figure"" style=""text-align: center"">
+<span style=""display:block;"" id=""fig:revbayes""></span>
+<img src=""images/amazing-thomas-bayes-illustration.jpg"" alt=""Cartoon of Thomas Bayes with Bayes' theorem in background. Source: [James Kulich](https://www.elmhurst.edu/blog/thomas-bayes/)"" width=""100%""><p class=""caption"">
+Figure 1.1: Cartoon of Thomas Bayes with Bayes‚Äô theorem in background. Source: <a href=""https://www.elmhurst.edu/blog/thomas-bayes/"">James Kulich</a>
+</p>
+</div>
+<p>As we will see in a minute, Bayes‚Äô theorem is all about conditional probabilities, which are somehow tricky to understand. Conditional probability of outcome or event A given event B, which we denote <span class=""math inline"">\(\Pr(A \mid B)\)</span>, is the probability that A occurs, revised by considering the additional information that event B has occurred.<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;For example, a friend of yours rolls a fair dice and asks you the probability that the outcome was a six (event A). Your answer is 1/6 because each side of the dice is equally likely to come up. Now imagine that you‚Äôre told the number rolled was even (event B) before you answer your friend‚Äôs question. Because there are only three even numbers, one of which is six, you may revise your answer for the probability that a six was rolled from 1/6 to &lt;span class=""math inline""&gt;\(\Pr(A \mid B) = 1/3\)&lt;/span&gt;.&lt;/p&gt;'><sup>2</sup></a> The order in which A and B appear is important, make sure you do not confuse <span class=""math inline"">\(\Pr(A \mid B)\)</span> and <span class=""math inline"">\(\Pr(B \mid A)\)</span>.</p>
+<p>Bayes‚Äô theorem (Figure <a href=""crashcourse.html#fig:bayestheorem"">1.2</a>) gives you <span class=""math inline"">\(\Pr(A \mid B)\)</span> using marginal probabilities <span class=""math inline"">\(\Pr(A)\)</span> and <span class=""math inline"">\(\Pr(B)\)</span> and <span class=""math inline"">\(\Pr(B \mid A)\)</span>:
+<span class=""math display"">\[\Pr(A \mid B) = \displaystyle{\frac{ \Pr(B \mid A) \; \Pr(A)}{\Pr(B)}}.\]</span>
+Originally, Bayes‚Äô theorem was seen as a way to infer an unkown cause A of a particular effect B, knowing the probability of effect B given cause A. Think for example of a situation where a medical diagnosis is needed, with A an unkown disease and B symptoms, the doctor knows P(symptoms|disease) and wants to derive P(disease|symptoms). This way of reversing <span class=""math inline"">\(\Pr(B \mid A)\)</span> into <span class=""math inline"">\(\Pr(A \mid B)\)</span> explains why Bayesian thinking used to be referred to as ‚Äòinverse probability‚Äô.</p>
+<div class=""figure"" style=""text-align: center"">
+<span style=""display:block;"" id=""fig:bayestheorem""></span>
+<img src=""images/bayes_neon.jpeg"" alt=""Bayes' theorem spelt out in blue neon. Source: [Wikipedia](https://en.wikipedia.org/wiki/Bayes%27_theorem)"" width=""400""><p class=""caption"">
+Figure 1.2: Bayes‚Äô theorem spelt out in blue neon. Source: <a href=""https://en.wikipedia.org/wiki/Bayes%27_theorem"">Wikipedia</a>
+</p>
+</div>
+<p>I don‚Äôt know about you, but I need to think twice for not messing the letters around. I find it easier to remember Bayes‚Äô theorem written like this<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;When teaching Bayes‚Äô theorem, I am very much inspired by Tristan Mahr‚Äôs slides from his introduction to Bayesian regression &lt;a href=""https://www.tjmahr.com/bayes-intro-lecture-slides-2017/"" class=""uri""&gt;https://www.tjmahr.com/bayes-intro-lecture-slides-2017/&lt;/a&gt;&lt;/p&gt;'><sup>3</sup></a>:</p>
+<span class=""math display"">\[ \Pr(\text{hypothesis} \mid \text{data}) = \frac{ \Pr(\text{data} \mid \text{hypothesis}) \; \Pr(\text{hypothesis})}{\Pr(\text{data})} \]</span>
+
+<div class=""rmdnote"">
+The <em>hypothesis</em> is a working assumption about which you want to learn using <em>data</em>. In capture‚Äìrecapture analyses, the hypothesis might be a parameter like detection probability, or regression parameters in a relationship between survival probability and a covariate. Bayes‚Äô theorem tells us how to obtain the probability of a hypothesis given the data we have.
+</div>
+<p>This is great because think about it, this is exactly what the scientific method is! We‚Äôd like to know how plausible some hypothesis is based on some data we collected, and possibly compare several hypotheses among them. In that respect, the Bayesian reasoning matches the scientific reasoning, which probably explains why the Bayesian framework is so natural for doing and understanding statistics.</p>
+<p>You might ask then, why is Bayesian statistics not the default in statistics? Clearly, because of futile wars between male statisticians (including Ronald Fisher, Jerzy Neyman and Egon Sharpe Pearson among others), little progress was made for over two centuries. Also, until recently, there were practical problems to implement Bayes‚Äô theorem. Recent advances in computational power coupled with the development of new algorithms have led to a great increase in the application of Bayesian methods within the last three decades.</p>
+</div>
+<div id=""what-is-the-bayesian-approach"" class=""section level2"" number=""1.3"">
+<h2>
+<span class=""header-section-number"">1.3</span> What is the Bayesian approach?<a class=""anchor"" aria-label=""anchor"" href=""#what-is-the-bayesian-approach""><i class=""fas fa-link""></i></a>
+</h2>
+<p>Typical statistical problems involve estimating a parameter (or several parameters) <span class=""math inline"">\(\theta\)</span> with available data. To do so, you might be more used to the frequentist rather than the Bayesian method. The frequentist approach, and in particular maximum likelihood estimation (MLE), assumes that the parameters are fixed, and have unknown values to be estimated. Therefore classical estimates are generally point estimates of the parameters of interest. In contrast, the Bayesian approach assumes that the parameters are not fixed, and have some unknown distribution<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;A probability distribution is a mathematical expression that gives the probability for a random variable to take particular values. A probability distribution may be either discrete (e.g., the Bernoulli, Binomial or Poisson distribution) or continuous (e.g., the Gaussian distribution also known as the normal distribution)&lt;/p&gt;""><sup>4</sup></a>.</p>
+<p>The Bayesian approach is based upon the idea that you, as an experimenter, begin with some prior beliefs about the system. Then you collect data and update your prior beliefs on the basis of observations. These observations might arise from field work, lab work or from expertise of your esteemed colleagues. This updating process is based upon Bayes‚Äô theorem. Loosely, let‚Äôs say <span class=""math inline"">\(A = \theta\)</span> and <span class=""math inline"">\(B = \text{data}\)</span>, then Bayes‚Äô theorem gives you a way to estimate parameter <span class=""math inline"">\(\theta\)</span> given the data you have:</p>
+<p><span class=""math display"">\[{\color{red}{\Pr(\theta \mid \text{data})}} = \frac{\color{blue}{\Pr(\text{data} \mid \theta)} \times \color{green}{\Pr(\theta)}}{\color{orange}{\Pr(\text{data})}}.\]</span>
+Let‚Äôs spend some time going through each quantity in this formula.</p>
+<p>On the left-hand side is the <span class=""math inline"">\(\color{red}{\text{posterior distribution}}\)</span>. It represents what you know after having seen the data. This is the basis for inference and clearly what you‚Äôre after, a distribution, possibly multivariate if you have more than one parameter.</p>
+<p>On the right-hand side, there is the <span class=""math inline"">\(\color{blue}{\text{likelihood}}\)</span>. This quantity is the same as in the MLE approach. Yes, the Bayesian and frequentist approaches have the same likelihood at their core, which mostly explains why results often do not differ much. The likelihood captures the information you have in your data, given a model parameterized with <span class=""math inline"">\(\theta\)</span>.</p>
+<p>Then we have the <span class=""math inline"">\(\color{green}{\text{prior distribution}}\)</span>. This quantity represents what you know before seeing the data. This is the source of much discussion about the Bayesian approach. It may be vague if you don‚Äôt know anything about <span class=""math inline"">\(\theta\)</span>. Usually however, you never start from scratch, and you‚Äôd like your prior to reflect the information you have<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;Shall I include a section on sensitivity analyses in this chapter or later in the book? Cross-reference section in Survival chapter where prior elicitation is covered.&lt;/p&gt;""><sup>5</sup></a>.</p>
+<p>Last, we have <span class=""math inline"">\(\color{orange}{\Pr(\text{data})}\)</span> which is sometimes called the average likelihood because it is obtained by integrating the likelihood with respect to the prior <span class=""math inline"">\(\color{orange}{\Pr(\text{data}) = \int{L(\text{data} \mid \theta)\Pr(\theta) d\theta}}\)</span> so that the posterior is standardized, that is it integrates to one for the posterior to be a distribution. The average likelihood is an integral with dimension the number of parameters <span class=""math inline"">\(\theta\)</span> you need to estimate. This quantity is difficult, if not impossible, to calculate in general. This is one of the reasons why the Bayesian method wasn‚Äôt used until recently, and why we need algorithms to estimate posterior distributions as I illustrate in the next section.</p>
+</div>
+<div id=""numerical-approx"" class=""section level2"" number=""1.4"">
+<h2>
+<span class=""header-section-number"">1.4</span> Approximating posteriors via numerical integration<a class=""anchor"" aria-label=""anchor"" href=""#numerical-approx""><i class=""fas fa-link""></i></a>
+</h2>
+<p>Let‚Äôs take an example to illustrate Bayes‚Äô theorem. Say we capture, mark and release <span class=""math inline"">\(n = 57\)</span> animals at the beginning of a winter, out of which we recapture <span class=""math inline"">\(y = 19\)</span> animals alive<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;We used a similar example in &lt;span class=""citation""&gt;King et al. (&lt;a href=""references.html#ref-king_bayesian_2009""&gt;2009&lt;/a&gt;)&lt;/span&gt;&lt;/p&gt;'><sup>6</sup></a>. We‚Äôd like to estimate winter survival <span class=""math inline"">\(\theta\)</span>.</p>
+<div class=""sourceCode"" id=""cb2""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">y</span> <span class=""op"">&lt;-</span> <span class=""fl"">19</span> <span class=""co""># nb of success</span></span>
+<span><span class=""va"">n</span> <span class=""op"">&lt;-</span> <span class=""fl"">57</span> <span class=""co""># nb of attempts</span></span></code></pre></div>
+<p>We build our model first. Assuming all animals are independent of each other and have the same survival probability, then <span class=""math inline"">\(y\)</span> the number of alive animals at the end of the winter is a binomial distribution<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;I follow &lt;span class=""citation""&gt;McElreath (&lt;a href=""references.html#ref-mcelreathbook""&gt;2016&lt;/a&gt;)&lt;/span&gt; and use labels on the right to help remember what each line is about.&lt;/p&gt;'><sup>7</sup></a> with <span class=""math inline"">\(n\)</span> trials and <span class=""math inline"">\(\theta\)</span> the probability of success:</p>
+<p><span class=""math display"">\[\begin{align*}
+y &amp;\sim \text{Binomial}(n, \theta) &amp;\text{[likelihood]}
+\end{align*}\]</span></p>
+<p>This likelihood can be visualised in <code>R</code>:</p>
+<div class=""sourceCode"" id=""cb3""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">grid</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/seq.html"">seq</a></span><span class=""op"">(</span><span class=""fl"">0</span>, <span class=""fl"">1</span>, <span class=""fl"">0.01</span><span class=""op"">)</span> <span class=""co""># grid of values for survival</span></span>
+<span><span class=""va"">likelihood</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Binomial.html"">dbinom</a></span><span class=""op"">(</span><span class=""va"">y</span>, <span class=""va"">n</span>, <span class=""va"">grid</span><span class=""op"">)</span> <span class=""co""># compute binomial likelihood</span></span>
+<span><span class=""va"">df</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/data.frame.html"">data.frame</a></span><span class=""op"">(</span>survival <span class=""op"">=</span> <span class=""va"">grid</span>, likelihood <span class=""op"">=</span> <span class=""va"">likelihood</span><span class=""op"">)</span> </span>
+<span><span class=""va"">df</span> <span class=""op"">%&gt;%</span></span>
+<span>  <span class=""fu"">ggplot</span><span class=""op"">(</span><span class=""op"">)</span> <span class=""op"">+</span> </span>
+<span>  <span class=""fu"">aes</span><span class=""op"">(</span>x <span class=""op"">=</span> <span class=""va"">survival</span>, y <span class=""op"">=</span> <span class=""va"">likelihood</span><span class=""op"">)</span> <span class=""op"">+</span> </span>
+<span>  <span class=""fu"">geom_line</span><span class=""op"">(</span>size <span class=""op"">=</span> <span class=""fl"">1.5</span><span class=""op"">)</span></span></code></pre></div>
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:binlik""></span>
+<img src=""banana-book_files/figure-html/binlik-1.png"" alt=""Binomial likelihood with $n = 57$ released animals and $y = 19$ survivors after winter. The value of survival (on the x-axis) that corresponds to the maximum of the likelihood function (on the y-axis) is the MLE, or the proportion of success in this example, close to 0.33."" width=""672""><p class=""caption"">
+Figure 1.3: Binomial likelihood with <span class=""math inline"">\(n = 57\)</span> released animals and <span class=""math inline"">\(y = 19\)</span> survivors after winter. The value of survival (on the x-axis) that corresponds to the maximum of the likelihood function (on the y-axis) is the MLE, or the proportion of success in this example, close to 0.33.
+</p>
+</div>
+<p>Besides the likelihood, priors are another component of the model in the Bayesian approach. For a parameter that is a probability, the one thing we know is that the prior should be a continuous random variable that lies between 0 and 1. To reflect that, we often go for the uniform distribution <span class=""math inline"">\(U(0,1)\)</span> to imply <em>vague</em> priors. Here vague means that survival has, before we see the data, the same probability of falling between 0.1 and 0.2 and between 0.8 and 0.9, for example.</p>
+<p><span class=""math display"">\[\begin{align*}
+\theta &amp;\sim \text{Uniform}(0, 1) &amp;\text{[prior for }\theta \text{]}
+\end{align*}\]</span></p>
+<p>Now we apply Bayes‚Äô theorem. We write a <code>R</code> function that computes the product of the likelihood times the prior, or the numerator in Bayes‚Äô theorem: <span class=""math inline"">\(\Pr(\text{data} \mid \theta) \times \Pr(\theta)\)</span></p>
+<div class=""sourceCode"" id=""cb4""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">numerator</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">theta</span><span class=""op"">)</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Binomial.html"">dbinom</a></span><span class=""op"">(</span><span class=""va"">y</span>, <span class=""va"">n</span>, <span class=""va"">theta</span><span class=""op"">)</span> <span class=""op"">*</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Uniform.html"">dunif</a></span><span class=""op"">(</span><span class=""va"">theta</span>, <span class=""fl"">0</span>, <span class=""fl"">1</span><span class=""op"">)</span></span></code></pre></div>
+<p>We write another function that calculates the denominator, the average likelihood: <span class=""math inline"">\(\Pr(\text{data}) = \int{L(\theta \mid \text{data}) \Pr(\theta) d\theta}\)</span></p>
+<div class=""sourceCode"" id=""cb5""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">denominator</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/integrate.html"">integrate</a></span><span class=""op"">(</span><span class=""va"">numerator</span>,<span class=""fl"">0</span>,<span class=""fl"">1</span><span class=""op"">)</span><span class=""op"">$</span><span class=""va"">value</span></span></code></pre></div>
+<p>We use the <code>R</code> function <code>integrate</code> to calculate the integral in the denominator, which implements quadrature techniques to divide in little squares the area underneath the curve delimited by the function to integrate (here the numerator), and count them.</p>
+<p>Then we get a numerical approximation of the posterior in Figure <a href=""crashcourse.html#fig:numapprox"">1.4</a> by applying Bayes‚Äô theorem.</p>
+<div class=""sourceCode"" id=""cb6""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">grid</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/seq.html"">seq</a></span><span class=""op"">(</span><span class=""fl"">0</span>, <span class=""fl"">1</span>, <span class=""fl"">0.01</span><span class=""op"">)</span> <span class=""co""># grid of values for theta</span></span>
+<span><span class=""va"">numerical_posterior</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/data.frame.html"">data.frame</a></span><span class=""op"">(</span>survival <span class=""op"">=</span> <span class=""va"">grid</span>, </span>
+<span>                                  posterior <span class=""op"">=</span> <span class=""fu"">numerator</span><span class=""op"">(</span><span class=""va"">grid</span><span class=""op"">)</span><span class=""op"">/</span><span class=""va"">denominator</span><span class=""op"">)</span> <span class=""co""># Bayes' theorem</span></span>
+<span><span class=""va"">numerical_posterior</span> <span class=""op"">%&gt;%</span></span>
+<span>  <span class=""fu"">ggplot</span><span class=""op"">(</span><span class=""op"">)</span> <span class=""op"">+</span></span>
+<span>  <span class=""fu"">aes</span><span class=""op"">(</span>x <span class=""op"">=</span> <span class=""va"">survival</span>, y <span class=""op"">=</span> <span class=""va"">posterior</span><span class=""op"">)</span> <span class=""op"">+</span> </span>
+<span>  <span class=""fu"">geom_line</span><span class=""op"">(</span>size <span class=""op"">=</span> <span class=""fl"">1.5</span><span class=""op"">)</span></span></code></pre></div>
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:numapprox""></span>
+<img src=""banana-book_files/figure-html/numapprox-1.png"" alt=""Winter survival posterior distribution obtained by numerical integration."" width=""672""><p class=""caption"">
+Figure 1.4: Winter survival posterior distribution obtained by numerical integration.
+</p>
+</div>
+<p>How good is our numerical approximation of survival posterior distribution? Ideally, we would want to compare the approximation to the true posterior distribution. Although a closed-form expression for the posterior distribution is in general intractable, when you combine a binomial likelihood together with a beta distribution as a prior, then the posterior distribution is also a beta distribution, which makes it amenable to all sorts of exact calculations<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;We say that the beta distribution is the conjugate prior distribution for the binomial distribution.&lt;/p&gt;""><sup>8</sup></a>. The beta distribution is continuous between 0 and 1, and extends the uniform distribution to situations where not all outcomes are equally likely. It has two parameters <span class=""math inline"">\(a\)</span> and <span class=""math inline"">\(b\)</span> that control its shape (Figure <a href=""crashcourse.html#fig:betadistribution"">1.5</a>).</p>
+
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:betadistribution""></span>
+<img src=""banana-book_files/figure-html/betadistribution-1.png"" alt=""The distribution beta(\(a\),\(b\)) for different values of \(a\) and \(b\). Note that for \(a = b = 1\), we get the uniform distribution between 0 and 1 in the top left panel. When \(a\) and \(b\) are equal, the distribution is symmetric, and the bigger \(a\) and \(b\), the more peaked the distribution or the smaller the variance."" width=""672""><p class=""caption"">
+Figure 1.5: The distribution beta(<span class=""math inline"">\(a\)</span>,<span class=""math inline"">\(b\)</span>) for different values of <span class=""math inline"">\(a\)</span> and <span class=""math inline"">\(b\)</span>. Note that for <span class=""math inline"">\(a = b = 1\)</span>, we get the uniform distribution between 0 and 1 in the top left panel. When <span class=""math inline"">\(a\)</span> and <span class=""math inline"">\(b\)</span> are equal, the distribution is symmetric, and the bigger <span class=""math inline"">\(a\)</span> and <span class=""math inline"">\(b\)</span>, the more peaked the distribution or the smaller the variance.
+</p>
+</div>
+If the likelihood of the data <span class=""math inline"">\(y\)</span> is binomial with <span class=""math inline"">\(n\)</span> trials and probability of success <span class=""math inline"">\(\theta\)</span>, and the prior is a beta distribution with parameters <span class=""math inline"">\(a\)</span> and <span class=""math inline"">\(b\)</span>, then the posterior is a beta distribution with parameters <span class=""math inline"">\(a + y\)</span> and <span class=""math inline"">\(b + n - y\)</span><a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;&lt;strong&gt;provide a sketch of the proof&lt;/strong&gt;&lt;/p&gt;""><sup>9</sup></a>. In our example, we have <span class=""math inline"">\(n = 57\)</span> trials and <span class=""math inline"">\(y = 19\)</span> animals that survived and a uniform prior between 0 and 1 or a beta distribution with parameters <span class=""math inline"">\(a = b = 1\)</span>, therefore survival has a beta posterior distribution with parameters 20 and 39. In Figure <a href=""crashcourse.html#fig:compar"">1.6</a>, we superimpose the exact posterior and the numerical approximation. Clearly, the two distributions are indistinguishable, suggesting that the numerical approximation is more than fine.
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:compar""></span>
+<img src=""banana-book_files/figure-html/compar-1.png"" alt=""Comparison of exact (dashed line) vs. numerical approximation (continuous line) of winter survival posterior distribution."" width=""672""><p class=""caption"">
+Figure 1.6: Comparison of exact (dashed line) vs.¬†numerical approximation (continuous line) of winter survival posterior distribution.
+</p>
+</div>
+<!-- To finish up, let's add the prior.  -->
+<!-- ```{r, echo = FALSE} -->
+<!-- ggplot() +  -->
+<!--   geom_line(data = numerical_posterior,  -->
+<!--             aes(x = survival, y = posterior),  -->
+<!--             size = 1.5,  -->
+<!--             col = wesanderson::wes_palettes$Royal1[2],  -->
+<!--             alpha = 0.5) +  -->
+<!--   geom_line(data = dfexpposterior,  -->
+<!--             aes(x = survival, y = explicit_posterior), -->
+<!--             col = wesanderson::wes_palettes$Royal1[3],  -->
+<!--             size = 1.5,  -->
+<!--             linetype = ""dashed"") +  -->
+<!--   geom_line(data = dfprior, -->
+<!--             aes(x = survival, y = prior), -->
+<!--             col = wesanderson::wes_palettes$Royal1[1], -->
+<!--             size = 1.5) -->
+<!-- ``` -->
+<p>In our example, we have a single parameter to estimate, winter survival. This means dealing with a one-dimensional integral in the denominator which is pretty easy with quadrature techniques and the <code>R</code> function <code><a href=""https://rdrr.io/r/stats/integrate.html"">integrate()</a></code>. Now what if we had multiple parameters? For example, imagine you‚Äôd like to fit a capture-recapture model with detection probability <span class=""math inline"">\(p\)</span> and regression parameters <span class=""math inline"">\(\alpha\)</span> and <span class=""math inline"">\(\beta\)</span> for the intercept and slope of a relationship between survival probability and a covariate, then Bayes‚Äô theorem gives you the posterior distribution of all three parameters together:</p>
+<p><span class=""math display"">\[ \Pr(\alpha, \beta, p \mid \text{data}) = \frac{ \Pr(\text{data} \mid \alpha, \beta, p) \times \Pr(\alpha, \beta, p)}{\iiint \, \Pr(\text{data} \mid \alpha, \beta, p) \Pr(\alpha, \beta, p) d\alpha d\beta dp} \]</span>
+There are two computational challenges with this formula. First, do we really wish to calculate a three-dimensional integral? The answer is no, one-dimensional and two-dimensional integrals are so much further we can go with standard methods. Second, we‚Äôre more interested in a posterior distribution for each parameter separately than the joint posterior distribution. The so-called marginal distribution of <span class=""math inline"">\(p\)</span> for example is obtained by integrating over all the other parameters ‚Äì a two-dimensional integral in this example. Now imagine with tens or hundreds of parameters to estimate, these integrals become highly multi-dimensional and simply intractable. In the next section, I introduce powerful simulation methods to circumvent this issue.</p>
+</div>
+<div id=""markov-chain-monte-carlo-mcmc"" class=""section level2"" number=""1.5"">
+<h2>
+<span class=""header-section-number"">1.5</span> Markov chain Monte Carlo (MCMC)<a class=""anchor"" aria-label=""anchor"" href=""#markov-chain-monte-carlo-mcmc""><i class=""fas fa-link""></i></a>
+</h2>
+<p>In the early 1990s, statisticians rediscovered work from the 1950‚Äôs in physics. In a famous paper that would lay the fundations of modern Bayesian statistics (Figure <a href=""crashcourse.html#fig:mcmcpaper"">1.7</a>), the authors use simulations to approximate posterior distributions with some precision by drawing large samples. This is a neat trick to avoid explicit calculation of the multi-dimensional integrals we struggle with when using Bayes‚Äô theorem.</p>
+<div class=""figure"" style=""text-align: center"">
+<span style=""display:block;"" id=""fig:mcmcpaper""></span>
+<img src=""images/metropolis.png"" alt=""MCMC article cover. Source: [The Journal of Chemical Physics](https://aip.scitation.org/doi/10.1063/1.1699114)"" width=""582""><p class=""caption"">
+Figure 1.7: MCMC article cover. Source: <a href=""https://aip.scitation.org/doi/10.1063/1.1699114"">The Journal of Chemical Physics</a>
+</p>
+</div>
+<p>These simulation algorithms are called Markov chain Monte Carlo (MCMC), and they definitely gave a boost to Bayesian statistics. There are two parts in MCMC, Markov chain and Monte Carlo, let‚Äôs try and make sense of these terms.</p>
+<div id=""monte-carlo-integration"" class=""section level3"" number=""1.5.1"">
+<h3>
+<span class=""header-section-number"">1.5.1</span> Monte Carlo integration<a class=""anchor"" aria-label=""anchor"" href=""#monte-carlo-integration""><i class=""fas fa-link""></i></a>
+</h3>
+<p>What does Monte Carlo stand for? Monte Carlo integration is a simulation technique to calculate integrals of any function <span class=""math inline"">\(f\)</span> of random variable <span class=""math inline"">\(X\)</span> with distribution <span class=""math inline"">\(\Pr(X)\)</span> say <span class=""math inline"">\(\int f(X) \Pr(X)dX\)</span>. You draw values <span class=""math inline"">\(X_1,\ldots,X_k\)</span> from <span class=""math inline"">\(\Pr(X)\)</span> the distribution of <span class=""math inline"">\(X\)</span>, apply function <span class=""math inline"">\(f\)</span> to these values, then calculate the mean of these new values <span class=""math inline"">\(\displaystyle{\frac{1}{k}}\sum_{i=1}^k{f(X_i)}\)</span> to approximate the integral. How is Monte Carlo integration used in a Bayesian context? The posterior distribution contains all the information we need about the parameter to be estimated. When dealing with many parameters however, you may want to summarise posterior results by calculating numerical summaries. The simplest numerical summary is the mean of the posterior distribution, <span class=""math inline"">\(E(\theta) = \int \theta \Pr(\theta|\text{data})\)</span>, where <span class=""math inline"">\(X\)</span> is <span class=""math inline"">\(\theta\)</span> now and <span class=""math inline"">\(f\)</span> is the identity function. Posterior mean can be calculated with Monte Carlo integration:</p>
+<div class=""sourceCode"" id=""cb7""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">sample_from_posterior</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Beta.html"">rbeta</a></span><span class=""op"">(</span><span class=""fl"">1000</span>, <span class=""fl"">20</span>, <span class=""fl"">39</span><span class=""op"">)</span> <span class=""co""># draw 1000 values from posterior survival beta(20,39)</span></span>
+<span><span class=""fu""><a href=""https://rdrr.io/r/base/mean.html"">mean</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span><span class=""op"">)</span> <span class=""co""># compute mean with Monte Carlo integration</span></span>
+<span><span class=""co"">## [1] 0.3382</span></span></code></pre></div>
+<p>You may check that the mean we have just calculated matches closely the expectation of a beta distribution<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;If &lt;span class=""math inline""&gt;\(X\)&lt;/span&gt; is a random variable with distribution &lt;span class=""math inline""&gt;\(\text{beta}(a, b)\)&lt;/span&gt;, then &lt;span class=""math inline""&gt;\(E(X) = \displaystyle{\frac{a}{a + b}}\)&lt;/span&gt;&lt;/p&gt;'><sup>10</sup></a>:</p>
+<div class=""sourceCode"" id=""cb8""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""fl"">20</span><span class=""op"">/</span><span class=""op"">(</span><span class=""fl"">20</span><span class=""op"">+</span><span class=""fl"">39</span><span class=""op"">)</span> <span class=""co""># expectation of beta(20,39)</span></span>
+<span><span class=""co"">## [1] 0.339</span></span></code></pre></div>
+<p>Another useful numerical summary is the credible interval within which our parameter falls with some probability, usually 0.95 hence a 95<span class=""math inline"">\(\%\)</span> credible interval. Finding the bounds of a credible interval requires calculating quantiles, which in turn involves integrals and the use of Monte Carlo integration. A 95<span class=""math inline"">\(\%\)</span> credible interval for winter survival can be obtained in <code>R</code> with:</p>
+<div class=""sourceCode"" id=""cb9""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""fu""><a href=""https://rdrr.io/r/stats/quantile.html"">quantile</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span>, probs <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/c.html"">c</a></span><span class=""op"">(</span><span class=""fl"">2.5</span><span class=""op"">/</span><span class=""fl"">100</span>, <span class=""fl"">97.5</span><span class=""op"">/</span><span class=""fl"">100</span><span class=""op"">)</span><span class=""op"">)</span></span>
+<span><span class=""co"">##   2.5%  97.5% </span></span>
+<span><span class=""co"">## 0.2308 0.4673</span></span></code></pre></div>
+</div>
+<div id=""markovmodelmcmc"" class=""section level3"" number=""1.5.2"">
+<h3>
+<span class=""header-section-number"">1.5.2</span> Markov chains<a class=""anchor"" aria-label=""anchor"" href=""#markovmodelmcmc""><i class=""fas fa-link""></i></a>
+</h3>
+<p>What is a Markov chain? A Markov chain is a random sequence of numbers, in which each number depends only on the previous number. An example is the weather in my home town in Southern France, Montpellier, in which a sunny day is most likely to be followed by another sunny day, say with probability 0.8, and a rainy day is rarely followed by another rainy day, say with probability 0.1. The dynamic of this Markov chain is captured by the transition matrix <span class=""math inline"">\(\mathbf{\Gamma}\)</span>:
+<span class=""math display"">\[
+\begin{matrix}
+&amp; \\
+\mathbf{\Gamma} =
+    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right .
+\end{matrix}
+\hspace{-1.2em}
+\begin{matrix}
+    \text{sunny tomorrow} &amp; \text{rainy tomorrow} \\
+0.8 &amp; 0.2 \\
+0.9 &amp; 0.1 \\
+\end{matrix}
+\hspace{-0.2em}
+\begin{matrix}
+&amp; \\
+\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
+    \begin{matrix}
+    \text{sunny today} \\ \text{rainy today}
+    \end{matrix}
+\end{matrix}
+\]</span>
+In rows the weather today, and in columns the weather tomorrow. The cells give the probability of a sunny or rainy day tomorrow, given the day is sunny or rainy today. Under certain conditions<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;The Markov chain is irreducible and aperiodic.&lt;/p&gt;""><sup>11</sup></a>, a Markov chain will converge to a unique stationary distribution. In our weather example, let‚Äôs run the Markov chain for 20 steps:</p>
+<div class=""sourceCode"" id=""cb10""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">weather</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/matrix.html"">matrix</a></span><span class=""op"">(</span><span class=""fu""><a href=""https://rdrr.io/r/base/c.html"">c</a></span><span class=""op"">(</span><span class=""fl"">0.8</span>, <span class=""fl"">0.2</span>, <span class=""fl"">0.9</span>, <span class=""fl"">0.1</span><span class=""op"">)</span>, nrow <span class=""op"">=</span> <span class=""fl"">2</span>, byrow <span class=""op"">=</span> <span class=""cn"">T</span><span class=""op"">)</span> <span class=""co""># transition matrix</span></span>
+<span><span class=""va"">steps</span> <span class=""op"">&lt;-</span> <span class=""fl"">20</span></span>
+<span><span class=""kw"">for</span> <span class=""op"">(</span><span class=""va"">i</span> <span class=""kw"">in</span> <span class=""fl"">1</span><span class=""op"">:</span><span class=""va"">steps</span><span class=""op"">)</span><span class=""op"">{</span></span>
+<span>  <span class=""va"">weather</span> <span class=""op"">&lt;-</span> <span class=""va"">weather</span> <span class=""op""><a href=""https://rdrr.io/r/base/matmult.html"">%*%</a></span> <span class=""va"">weather</span> <span class=""co""># matrix multiplication</span></span>
+<span><span class=""op"">}</span></span>
+<span><span class=""fu""><a href=""https://rdrr.io/r/base/Round.html"">round</a></span><span class=""op"">(</span><span class=""va"">weather</span>, <span class=""fl"">2</span><span class=""op"">)</span> <span class=""co""># matrix product after 20 steps</span></span>
+<span><span class=""co"">##      [,1] [,2]</span></span>
+<span><span class=""co"">## [1,] 0.82 0.18</span></span>
+<span><span class=""co"">## [2,] 0.82 0.18</span></span></code></pre></div>
+<p>Each row of the transition matrix converges to the same distribution <span class=""math inline"">\((0.82, 0.18)\)</span> as the number of steps increases. Convergence happens no matter which state you start in, and you always have probability 0.82 of the day being sunny and 0.18 of the day being rainy.</p>
+<p>Back to MCMC, the core idea is that you can build a Markov chain with a given stationary distribution set to be the desired posterior distribution.</p>
+
+<div class=""rmdnote"">
+Putting Monte Carlo and Markov chains together, MCMC allows us to generate a sample of values (Markov chain) whose distribution converges to the posterior distribution, and we can use this sample of values to calculate any posterior summaries (Monte Carlo), such as posterior means and credible intervals.
+</div>
+</div>
+<div id=""metropolis-algorithm"" class=""section level3"" number=""1.5.3"">
+<h3>
+<span class=""header-section-number"">1.5.3</span> Metropolis algorithm<a class=""anchor"" aria-label=""anchor"" href=""#metropolis-algorithm""><i class=""fas fa-link""></i></a>
+</h3>
+<p>There are several ways of constructing Markov chains for Bayesian inference<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;You might have heard about the Metropolis-Hastings or the Gibbs sampler. Have a look to &lt;a href=""https://github.com/chi-feng/mcmc-demo"" class=""uri""&gt;https://github.com/chi-feng/mcmc-demo&lt;/a&gt; for an interactive gallery of MCMC algorithms.&lt;/p&gt;'><sup>12</sup></a>. Here I illustrate the Metropolis algorithm and how to implement it in practice<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;This presentation is largely inspired by &lt;span class=""citation""&gt;Albert and Hu (&lt;a href=""references.html#ref-alberthu2019""&gt;2019&lt;/a&gt;)&lt;/span&gt;&lt;/p&gt;'><sup>13</sup></a>.</p>
+<p>Let‚Äôs go back to our example on animal survival estimation. We illustrate sampling from survival posterior distribution. We write functions for likelihood, prior and posterior.</p>
+<div class=""sourceCode"" id=""cb11""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""co""># 19 animals recaptured alive out of 57 captured, marked and released</span></span>
+<span><span class=""va"">survived</span> <span class=""op"">&lt;-</span> <span class=""fl"">19</span></span>
+<span><span class=""va"">released</span> <span class=""op"">&lt;-</span> <span class=""fl"">57</span></span>
+<span></span>
+<span><span class=""co""># binomial log-likelihood function</span></span>
+<span><span class=""va"">loglikelihood</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">x</span>, <span class=""va"">p</span><span class=""op"">)</span><span class=""op"">{</span></span>
+<span>  <span class=""fu""><a href=""https://rdrr.io/r/stats/Binomial.html"">dbinom</a></span><span class=""op"">(</span>x <span class=""op"">=</span> <span class=""va"">x</span>, size <span class=""op"">=</span> <span class=""va"">released</span>, prob <span class=""op"">=</span> <span class=""va"">p</span>, log <span class=""op"">=</span> <span class=""cn"">TRUE</span><span class=""op"">)</span></span>
+<span><span class=""op"">}</span></span>
+<span></span>
+<span><span class=""co""># uniform prior density</span></span>
+<span><span class=""va"">logprior</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">p</span><span class=""op"">)</span><span class=""op"">{</span></span>
+<span>  <span class=""fu""><a href=""https://rdrr.io/r/stats/Uniform.html"">dunif</a></span><span class=""op"">(</span>x <span class=""op"">=</span> <span class=""va"">p</span>, min <span class=""op"">=</span> <span class=""fl"">0</span>, max <span class=""op"">=</span> <span class=""fl"">1</span>, log <span class=""op"">=</span> <span class=""cn"">TRUE</span><span class=""op"">)</span></span>
+<span><span class=""op"">}</span></span>
+<span></span>
+<span><span class=""co""># posterior density function (log scale)</span></span>
+<span><span class=""va"">posterior</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">x</span>, <span class=""va"">p</span><span class=""op"">)</span><span class=""op"">{</span></span>
+<span>  <span class=""fu"">loglikelihood</span><span class=""op"">(</span><span class=""va"">x</span>, <span class=""va"">p</span><span class=""op"">)</span> <span class=""op"">+</span> <span class=""fu"">logprior</span><span class=""op"">(</span><span class=""va"">p</span><span class=""op"">)</span> <span class=""co""># - log(Pr(data))</span></span>
+<span><span class=""op"">}</span></span></code></pre></div>
+<p>The Metropolis algorithm works as follows:</p>
+<ol style=""list-style-type: decimal"">
+<li><p>We pick a value of the parameter to be estimated. This is where we start our Markov chain ‚Äì this is a <em>starting</em> value.</p></li>
+<li><p>To decide where to go next, we propose to move away from the current value of the parameter ‚Äì this is a <em>candidate</em> value. To do so, we add to the current value some random value from e.g.¬†a normal distribution with some variance ‚Äì this is a <em>proposal</em> distribution. The Metropolis algorithm is a particular case of the Metropolis-Hastings algorithm with symmetric proposals.</p></li>
+<li><p>We compute the ratio of the probabilities at the candidate and current locations <span class=""math inline"">\(R=\displaystyle{\frac{{\Pr(\text{candidate}|\text{data})}}{{\Pr(\text{current}|\text{data})}}}\)</span>. This is where the magic of MCMC happens, in that <span class=""math inline"">\(\Pr(\text{data})\)</span>, the denominator in the Bayes‚Äô theorem, appears in both the numerator and the denominator in <span class=""math inline"">\(R\)</span> therefore cancels out and does not need to be calculated.</p></li>
+</ol>
+<!-- -- *the Hastings ratio* --><ol start=""4"" style=""list-style-type: decimal"">
+<li><p>If the posterior at the candidate location <span class=""math inline"">\(\Pr(\text{candidate}|\text{data})\)</span> is higher than at the current location <span class=""math inline"">\(\Pr(\text{current}|\text{data})\)</span>, in other words when the candidate value is more plausible than the current value, we definitely accept the candidate value. If not, then we accept the candidate value with probability <span class=""math inline"">\(R\)</span> and reject with probability <span class=""math inline"">\(1-R\)</span>. For example, if the candidate value is ten times less plausible than the current value, then we accept with probability 0.1 and reject with probability 0.9. How does it work in practice? We use a continuous spinner that lands somewhere between 0 and 1 ‚Äì call the random spin <span class=""math inline"">\(X\)</span>. If <span class=""math inline"">\(X\)</span> is smaller than <span class=""math inline"">\(R\)</span>, we move to the candidate location, otherwise we remain at the current location. We do not want to accept or reject too often. In practice, the Metropolis algorithm should have an acceptance probability between 0.2 and 0.4, which can be achieved by <em>tuning</em> the variance of the normal proposal distribution.</p></li>
+<li><p>We repeat 2-4 a number of times ‚Äì or <em>steps</em>.</p></li>
+</ol>
+<p>Enough of the theory, let‚Äôs implement the Metropolis algorithm in <code>R</code>. Let‚Äôs start by setting the scene.</p>
+<div class=""sourceCode"" id=""cb12""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">steps</span> <span class=""op"">&lt;-</span> <span class=""fl"">100</span> <span class=""co""># number of steps</span></span>
+<span><span class=""va"">theta.post</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/rep.html"">rep</a></span><span class=""op"">(</span><span class=""cn"">NA</span>, <span class=""va"">steps</span><span class=""op"">)</span> <span class=""co""># vector to store samples</span></span>
+<span><span class=""va"">accept</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/rep.html"">rep</a></span><span class=""op"">(</span><span class=""cn"">NA</span>, <span class=""va"">steps</span><span class=""op"">)</span> <span class=""co""># keep track of accept/reject</span></span>
+<span><span class=""fu""><a href=""https://rdrr.io/r/base/Random.html"">set.seed</a></span><span class=""op"">(</span><span class=""fl"">1234</span><span class=""op"">)</span> <span class=""co""># for reproducibility</span></span></code></pre></div>
+<p>Now follow the 5 steps we‚Äôve just described. First, we pick a starting value, and store it (step 1).</p>
+<div class=""sourceCode"" id=""cb13""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">inits</span> <span class=""op"">&lt;-</span> <span class=""fl"">0.5</span></span>
+<span><span class=""va"">theta.post</span><span class=""op"">[</span><span class=""fl"">1</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""va"">inits</span></span>
+<span><span class=""va"">accept</span><span class=""op"">[</span><span class=""fl"">1</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""fl"">1</span></span></code></pre></div>
+<p>Then, we need a function to propose a candidate value. We add a value taken from a normal distribution with mean zero and standard deviation we call <em>away</em>. We work on the logit scale to make sure the candidate value for survival lies between 0 and 1.</p>
+<div class=""sourceCode"" id=""cb14""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""va"">move</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">x</span>, <span class=""va"">away</span> <span class=""op"">=</span> <span class=""fl"">1</span><span class=""op"">)</span><span class=""op"">{</span> <span class=""co""># by default, standard deviation of the proposal distribution is 1</span></span>
+<span>  <span class=""va"">logitx</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/Log.html"">log</a></span><span class=""op"">(</span><span class=""va"">x</span> <span class=""op"">/</span> <span class=""op"">(</span><span class=""fl"">1</span> <span class=""op"">-</span> <span class=""va"">x</span><span class=""op"">)</span><span class=""op"">)</span> <span class=""co""># apply logit transform (-infinity,+infinity)</span></span>
+<span>  <span class=""va"">logit_candidate</span> <span class=""op"">&lt;-</span> <span class=""va"">logitx</span> <span class=""op"">+</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Normal.html"">rnorm</a></span><span class=""op"">(</span><span class=""fl"">1</span>, <span class=""fl"">0</span>, <span class=""va"">away</span><span class=""op"">)</span> <span class=""co""># add a value taken from N(0,sd=away) to current value</span></span>
+<span>  <span class=""va"">candidate</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Logistic.html"">plogis</a></span><span class=""op"">(</span><span class=""va"">logit_candidate</span><span class=""op"">)</span> <span class=""co""># back-transform (0,1)</span></span>
+<span>  <span class=""kw""><a href=""https://rdrr.io/r/base/function.html"">return</a></span><span class=""op"">(</span><span class=""va"">candidate</span><span class=""op"">)</span></span>
+<span><span class=""op"">}</span></span></code></pre></div>
+<p>Now we‚Äôre ready for steps 2, 3 and 4. We write a loop to take care of step 5. We start at initial value 0.5 and run the algorithm for 100 steps or iterations.</p>
+<div class=""sourceCode"" id=""cb15""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""kw"">for</span> <span class=""op"">(</span><span class=""va"">t</span> <span class=""kw"">in</span> <span class=""fl"">2</span><span class=""op"">:</span><span class=""va"">steps</span><span class=""op"">)</span><span class=""op"">{</span> <span class=""co""># repeat steps 2-4 (step 5)</span></span>
+<span>  </span>
+<span>  <span class=""co""># propose candidate value for survival (step 2)</span></span>
+<span>  <span class=""va"">theta_star</span> <span class=""op"">&lt;-</span> <span class=""fu"">move</span><span class=""op"">(</span><span class=""va"">theta.post</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">-</span><span class=""fl"">1</span><span class=""op"">]</span><span class=""op"">)</span></span>
+<span>  </span>
+<span>  <span class=""co""># calculate ratio R (step 3)</span></span>
+<span>  <span class=""va"">pstar</span> <span class=""op"">&lt;-</span> <span class=""fu"">posterior</span><span class=""op"">(</span><span class=""va"">survived</span>, p <span class=""op"">=</span> <span class=""va"">theta_star</span><span class=""op"">)</span>  </span>
+<span>  <span class=""va"">pprev</span> <span class=""op"">&lt;-</span> <span class=""fu"">posterior</span><span class=""op"">(</span><span class=""va"">survived</span>, p <span class=""op"">=</span> <span class=""va"">theta.post</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">-</span><span class=""fl"">1</span><span class=""op"">]</span><span class=""op"">)</span></span>
+<span>  <span class=""va"">logR</span> <span class=""op"">&lt;-</span> <span class=""va"">pstar</span> <span class=""op"">-</span> <span class=""va"">pprev</span> <span class=""co""># likelihood and prior are on the log scale</span></span>
+<span>  <span class=""va"">R</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/Log.html"">exp</a></span><span class=""op"">(</span><span class=""va"">logR</span><span class=""op"">)</span></span>
+<span>  </span>
+<span>  <span class=""co""># accept candidate value or keep current value (step 4)</span></span>
+<span>  <span class=""va"">X</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Uniform.html"">runif</a></span><span class=""op"">(</span><span class=""fl"">1</span>, <span class=""fl"">0</span>, <span class=""fl"">1</span><span class=""op"">)</span> <span class=""co""># spin continuous spinner</span></span>
+<span>  <span class=""kw"">if</span> <span class=""op"">(</span><span class=""va"">X</span> <span class=""op"">&lt;</span> <span class=""va"">R</span><span class=""op"">)</span><span class=""op"">{</span></span>
+<span>    <span class=""va"">theta.post</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""va"">theta_star</span> <span class=""co""># accept candidate value</span></span>
+<span>    <span class=""va"">accept</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""fl"">1</span> <span class=""co""># accept</span></span>
+<span>  <span class=""op"">}</span></span>
+<span>  <span class=""kw"">else</span><span class=""op"">{</span></span>
+<span>    <span class=""va"">theta.post</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""va"">theta.post</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">-</span><span class=""fl"">1</span><span class=""op"">]</span> <span class=""co""># keep current value</span></span>
+<span>    <span class=""va"">accept</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""fl"">0</span> <span class=""co""># reject</span></span>
+<span>  <span class=""op"">}</span></span>
+<span><span class=""op"">}</span></span></code></pre></div>
+<p>We get the following values.</p>
+<div class=""sourceCode"" id=""cb16""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span><span class=""fu""><a href=""https://rdrr.io/r/utils/head.html"">head</a></span><span class=""op"">(</span><span class=""va"">theta.post</span><span class=""op"">)</span> <span class=""co""># first values</span></span>
+<span><span class=""co"">## [1] 0.5000 0.2302 0.2906 0.2906 0.2980 0.2980</span></span>
+<span><span class=""fu""><a href=""https://rdrr.io/r/utils/head.html"">tail</a></span><span class=""op"">(</span><span class=""va"">theta.post</span><span class=""op"">)</span> <span class=""co""># last values</span></span>
+<span><span class=""co"">## [1] 0.2622 0.2622 0.2622 0.3727 0.3232 0.3862</span></span></code></pre></div>
+Visually, you may look at the chain in Figure <a href=""crashcourse.html#fig:chain"">1.8</a> called a trace plot.
+<div class=""figure"" style=""text-align: center"">
+<span style=""display:block;"" id=""fig:chain""></span>
+<img src=""banana-book_files/figure-html/chain-1.png"" alt=""Visualisation of a Markov chain starting at value 0.5, with steps or iterations on the x-axis, and samples on the y-axis. This graphical representation is called a trace plot."" width=""672""><p class=""caption"">
+Figure 1.8: Visualisation of a Markov chain starting at value 0.5, with steps or iterations on the x-axis, and samples on the y-axis. This graphical representation is called a trace plot.
+</p>
+</div>
+<p>The acceptance probability is the average number of times we accepted a candidated value, which is 0.44 and almost satisfying.</p>
+Can we run another chain and start at initial value 0.2 this time? Yes, just go through the same algorithm again, and visualise the results in Figure <a href=""crashcourse.html#fig:twochains"">1.9</a>.
+<div class=""figure"" style=""text-align: center"">
+<span style=""display:block;"" id=""fig:twochains""></span>
+<img src=""banana-book_files/figure-html/twochains-1.png"" alt=""Trace plot of survival for two chains starting at 0.2 (yellow) and 0.5 (blue) run for 100 steps."" width=""672""><p class=""caption"">
+Figure 1.9: Trace plot of survival for two chains starting at 0.2 (yellow) and 0.5 (blue) run for 100 steps.
+</p>
+</div>
+Notice that we do not get the exact same results because the algorithm is stochastic. The question is to know whether we have reached the stationary distribution. Let‚Äôs increase the number of steps and run a chain with 5000 iterations as in Figure <a href=""crashcourse.html#fig:longchain"">1.10</a>.
+<div class=""figure"" style=""text-align: center"">
+<span style=""display:block;"" id=""fig:longchain""></span>
+<img src=""banana-book_files/figure-html/longchain-1.png"" alt=""Trace plot of survival for a chain starting at 0.5 and 1000 steps."" width=""672""><p class=""caption"">
+Figure 1.10: Trace plot of survival for a chain starting at 0.5 and 1000 steps.
+</p>
+</div>
+<p>This is what we‚Äôre after, a trace plot that looks like a beautiful lawn, see Section <a href=""crashcourse.html#convergence-diag"">1.6</a>. I find it informative to look at the animated version of Figure <a href=""crashcourse.html#fig:longchain"">1.10</a>, it helps understanding the stochastic behavior of the algorithm, and also to realise how the chains converge to their stationary distribution, see Figure <a href=""crashcourse.html#fig:animlongchain"">1.11</a>.</p>
+<div class=""figure"" style=""text-align: center"">
+<span style=""display:block;"" id=""fig:animlongchain""></span>
+<img src=""images/traceplotMCMC.gif"" alt=""Animated trace plot of survival with three chains starting at 0.2, 0.5 and 0.7 run for 1000 steps."" width=""100%""><p class=""caption"">
+Figure 1.11: Animated trace plot of survival with three chains starting at 0.2, 0.5 and 0.7 run for 1000 steps.
+</p>
+</div>
+<p>Once the stationary distribution is reached, you may regard the realisations of the Markov chain as a sample from the posterior distribution, and obtain numerical summaries. In the next section, we consider several important implementation issues.</p>
+</div>
+</div>
+<div id=""convergence-diag"" class=""section level2"" number=""1.6"">
+<h2>
+<span class=""header-section-number"">1.6</span> Assessing convergence<a class=""anchor"" aria-label=""anchor"" href=""#convergence-diag""><i class=""fas fa-link""></i></a>
+</h2>
+
+<div class=""rmdnote"">
+When implementing MCMC, we need to determine how long it takes for our Markov chain to converge to the target distribution, and the number of iterations we need after achieving convergence to get reasonable Monte Carlo estimates of numerical summaries (posterior means and credible intervals).
+</div>
+<div id=""burn-in"" class=""section level3"" number=""1.6.1"">
+<h3>
+<span class=""header-section-number"">1.6.1</span> Burn-in<a class=""anchor"" aria-label=""anchor"" href=""#burn-in""><i class=""fas fa-link""></i></a>
+</h3>
+<p>In practice, we discard observations from the start of the Markov chain and just use observations from the chain once it has converged. The initial observations that we discard are usually referred to as the <em>burn-in</em>.</p>
+<p>The simplest method to determine the length of the burn-in period is to look at trace plots. Going back to our example, we see from the trace plot in Figure <a href=""crashcourse.html#fig:burnin"">1.12</a> that we need at least 100 iterations to achieve convergence toward an average survival around 0.3. It is always better to be conservative when specifying the length of the burn-in period, and in this example, we would use 250 or even 500 iterations as a burn-in. The length of the burn-in period can be determined by performing preliminary MCMC short runs.</p>
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:burnin""></span>
+<img src=""banana-book_files/figure-html/burnin-1.png"" alt=""Determining the length of the burn-in period. The chain starts at value 0.99 and rapidly stabilises, with values bouncing back and forth around 0.3 from the 100th iteration onwards. You may choose the shaded area as the burn-in, and discard the corresponding values."" width=""672""><p class=""caption"">
+Figure 1.12: Determining the length of the burn-in period. The chain starts at value 0.99 and rapidly stabilises, with values bouncing back and forth around 0.3 from the 100th iteration onwards. You may choose the shaded area as the burn-in, and discard the corresponding values.
+</p>
+</div>
+<p>Inspecting the trace plot for a single run of the Markov chain is useful. However, we usually run the Markov chain several times, starting from different over-dispersed points, to check that all runs achieve the same stationary distribution. This approach is formalised by using the Brooks-Gelman-Rubin (BGR) statistic <span class=""math inline"">\(\hat{R}\)</span> which measures the ratio of the total variability combining multiple chains (between-chain plus within-chain) to the within-chain variability. The BGR statistic asks whether there is a chain effect, and is very much alike the <span class=""math inline"">\(F\)</span> test in an analysis of variance. Values below 1.1 indicate likely convergence.</p>
+<p>Back to our example, we run two Markov chains with starting values 0.2 and 0.8 using 100 up to 5000 iterations, and calculate the BGR statistic using half the number of iterations as the length of the burn-in. From Figure <a href=""crashcourse.html#fig:bgr"">1.13</a>, we get a value of the BGR statistic near 1 by up to 2000 iterations, which suggests that with 2000 iterations as a burn-in, there is no evidence of a lack of convergence.</p>
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:bgr""></span>
+<img src=""banana-book_files/figure-html/bgr-1.png"" alt=""Brooks-Gelman-Rubin statistic as a function of the number of iterations."" width=""672""><p class=""caption"">
+Figure 1.13: Brooks-Gelman-Rubin statistic as a function of the number of iterations.
+</p>
+</div>
+<p>It is important to bear in mind that a value near 1 for the BGR statistic is only a necessary <em>but not sufficient</em> condition for convergence. In other words, this diagnostic cannot tell you for sure that the Markov chain has achieved convergence, only that it has not.<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;Cross-reference sections on local minima and parameter redundancy for pathological cases.&lt;/p&gt;""><sup>14</sup></a></p>
+</div>
+<div id=""chain-length"" class=""section level3"" number=""1.6.2"">
+<h3>
+<span class=""header-section-number"">1.6.2</span> Chain length<a class=""anchor"" aria-label=""anchor"" href=""#chain-length""><i class=""fas fa-link""></i></a>
+</h3>
+<p>How long of a chain is needed to produce reliable parameter estimates? To answer this question, you need to keep in mind that successive steps in a Markov chain are not independent ‚Äì this is usually referred to as <em>autocorrelation</em>. Ideally, we would like to keep autocorrelation as low as possible. Here again, trace plots are useful to diagnose issues with autocorrelation. Let‚Äôs get back to our survival example. Figure <a href=""crashcourse.html#fig:tracechainlength"">1.14</a> shows trace plots for different values of the standard deviation (parameter <em>away</em>) of the (normal) proposal distribution we use to propose a candidate value (Section <a href=""crashcourse.html#metropolis-algorithm"">1.5.3</a>). Small and big moves provide high correlations between successive observations of the Markov chain, whereas a standard deviation of 1 allows efficient exploration of the parameter space. The movement around the parameter space is referred to as <em>mixing</em>. Mixing is bad when the chain makes small and big moves, and good otherwise.</p>
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:tracechainlength""></span>
+<img src=""banana-book_files/figure-html/tracechainlength-1.png"" alt=""Trace plots for different values of the standard deviation (SD) of the proposal distribution. Left: The chain exhibits small moves and mixing is bad. Right: The chain exhibits big moves and mixing is bad. Middle: The chain exhibits adequate moves and mixing is good. Only the thousand last iterations are shown."" width=""672""><p class=""caption"">
+Figure 1.14: Trace plots for different values of the standard deviation (SD) of the proposal distribution. Left: The chain exhibits small moves and mixing is bad. Right: The chain exhibits big moves and mixing is bad. Middle: The chain exhibits adequate moves and mixing is good. Only the thousand last iterations are shown.
+</p>
+</div>
+<p>In addition to trace plots, autocorrelation function (ACF) plots are a convenient way of displaying the strength of autocorrelation in a given sample values. ACF plots provide the autocorrelation between successively sampled values separated by an increasing number of iterations, or <em>lag</em> (Figure <a href=""crashcourse.html#fig:acfchainlength"">1.15</a>).</p>
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:acfchainlength""></span>
+<img src=""banana-book_files/figure-html/acfchainlength-1.png"" alt=""Autocorrelation function plots for different values of the standard deviation (SD) of the proposal distribution. Left and right: Autocorrelation is strong, decreases slowly with increasing lag and mixing is bad. Middle: Autocorrelation is weak, decreases rapidly with increasing lag and mixing is good."" width=""672""><p class=""caption"">
+Figure 1.15: Autocorrelation function plots for different values of the standard deviation (SD) of the proposal distribution. Left and right: Autocorrelation is strong, decreases slowly with increasing lag and mixing is bad. Middle: Autocorrelation is weak, decreases rapidly with increasing lag and mixing is good.
+</p>
+</div>
+<p>Autocorrelation is not necessarily a big issue. Strongly correlated observations just require large sample sizes and therefore longer simulations. But how many iterations exactly? The effective sample size (<code>n.eff</code>) measures chain length while taking into account chain autocorrelation. You should check the <code>n.eff</code> of every parameter of interest, and of any interesting parameter combinations. In general, we need <span class=""math inline"">\(\text{n.eff} \geq 1000\)</span> independent steps to get reasonable Monte Carlo estimates of model parameters. In the animal survival example, <code>n.eff</code> can be calculated with the R <code><a href=""https://rdrr.io/pkg/coda/man/effectiveSize.html"">coda::effectiveSize()</a></code> function.</p>
+<div class=""inline-table""><table class=""table table-sm"">
+<thead><tr class=""header"">
+<th align=""right"">Proposal SD</th>
+<th align=""right"">n.eff</th>
+</tr></thead>
+<tbody>
+<tr class=""odd"">
+<td align=""right"">0.1</td>
+<td align=""right"">224</td>
+</tr>
+<tr class=""even"">
+<td align=""right"">1.0</td>
+<td align=""right"">1934</td>
+</tr>
+<tr class=""odd"">
+<td align=""right"">10.0</td>
+<td align=""right"">230</td>
+</tr>
+</tbody>
+</table></div>
+<p>As expected, <code>n.eff</code> is less than the number of MCMC iterations because of autocorrelation. Only when the standard deviation of the proposal distribution is 1 and mixing is good (Figures <a href=""crashcourse.html#fig:tracechainlength"">1.14</a> and <a href=""crashcourse.html#fig:acfchainlength"">1.15</a>) we get a satisfying effective sample size.</p>
+</div>
+<div id=""what-if-you-have-issues-of-convergence"" class=""section level3"" number=""1.6.3"">
+<h3>
+<span class=""header-section-number"">1.6.3</span> What if you have issues of convergence?<a class=""anchor"" aria-label=""anchor"" href=""#what-if-you-have-issues-of-convergence""><i class=""fas fa-link""></i></a>
+</h3>
+<p>When diagnosing MCMC convergence, you will (very) often run into troubles. In this section you will find some helpful tips I hope.</p>
+<p>When mixing is bad and effective sample size is small, you may just need to increase burn-in and/or sample more. Using more informative priors might also make Markov chains converge faster by helping your MCMC sampler (e.g.¬†the Metropolis algorithm) navigating more efficiently the parameter space. In the same spirit, picking better initial values for starting the chain does not harm. For doing that, a strategy consists in using estimates from a simpler model for which your MCMC chains do converge.</p>
+<p>If convergence issues persist, often there is a problem with your model<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;The quote ‚ÄòWhen you have computational problems, often there‚Äôs a problem with your model‚Äô is the folk theorem of statistical computing stated by Andrew Gelman in 2008, see &lt;a href=""https://statmodeling.stat.columbia.edu/2008/05/13/the_folk_theore/"" class=""uri""&gt;https://statmodeling.stat.columbia.edu/2008/05/13/the_folk_theore/&lt;/a&gt;&lt;/p&gt;'><sup>15</sup></a>. A bug in the code? A typo somewhere? A mistake in your maths? As often when coding is involved, the issue can be identified by removing complexities, and start with a simpler model until you find what the problem is.</p>
+<p>A general advice is to see your model as a data generating tool in the first place, simulate data from it using some realistic values for the parameters, and try to recover these parameter values by fitting the model to the simulated data. Simulating from a model will help you understanding how it works, what it does not do, and the data you need to get reasonable parameter estimates.</p>
+<p>We will see other strategies to improve convergence in the next chapters.<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;Cross reference relevant chapters. Option 1. Change your sampler. Option 2. Reparameterize (standardize covariates, plus non-centering: &lt;span class=""math inline""&gt;\(\alpha \sim N(0,\sigma)\)&lt;/span&gt; becomes &lt;span class=""math inline""&gt;\(\alpha = z \sigma\)&lt;/span&gt; with &lt;span class=""math inline""&gt;\(z \sim N(0,1)\)&lt;/span&gt;).&lt;/p&gt;'><sup>16</sup></a></p>
+</div>
+</div>
+<div id=""summary"" class=""section level2"" number=""1.7"">
+<h2>
+<span class=""header-section-number"">1.7</span> Summary<a class=""anchor"" aria-label=""anchor"" href=""#summary""><i class=""fas fa-link""></i></a>
+</h2>
+<ul>
+<li><p>With the Bayes‚Äô theorem, you update your beliefs (prior) with new data (likelihood) to get posterior beliefs (posterior): posterior <span class=""math inline"">\(\propto\)</span> likelihood <span class=""math inline"">\(\times\)</span> prior.</p></li>
+<li><p>The idea of Markov chain Monte Carlo (MCMC) is to simulate values from a Markov chain which has a stationary distribution equal to the posterior distribution you‚Äôre after.</p></li>
+<li><p>In practice, you run a Markov chain multiple times starting from over-dispersed initial values.</p></li>
+<li><p>You discard iterations in an initial burn-in phase and achieve convergence when all chains reach the same regime.</p></li>
+<li><p>From there, you run the chains long enough and proceed with calculating Monte Carlo estimates of numerical summaries (e.g.¬†posterior means and credible intervals) for parameters.</p></li>
+</ul>
+</div>
+<div id=""suggested-reading"" class=""section level2"" number=""1.8"">
+<h2>
+<span class=""header-section-number"">1.8</span> Suggested reading<a class=""anchor"" aria-label=""anchor"" href=""#suggested-reading""><i class=""fas fa-link""></i></a>
+</h2>
+<ul>
+<li><p>Gelman, A. and Hill, J. (2006). <a href=""https://www.cambridge.org/core/books/data-analysis-using-regression-and-multilevelhierarchical-models/32A29531C7FD730C3A68951A17C9D983"">Data Analysis Using Regression and Multilevel/Hierarchical Models (Analytical Methods for Social Research)</a>. Cambridge: Cambridge University Press.</p></li>
+<li><p>Gelman, A. and colleagues (2020). <a href=""https://arxiv.org/pdf/2011.01808.pdf"">Bayesian workflow</a>. arXiv preprint.</p></li>
+<li><p>McCarthy, M. (2007). <a href=""https://www.cambridge.org/core/books/bayesian-methods-for-ecology/9225F65B8A25D69B0B6C50B5A9A78201"">Bayesian Methods for Ecology</a>. Cambridge: Cambridge University Press.</p></li>
+<li><p>McElreath, R. (2020). <a href=""https://xcelab.net/rm/statistical-rethinking/"">Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2nd ed.)</a>. CRC Press.</p></li>
+</ul>
+</div>
+</div>
+
+  <div class=""chapter-nav"">
+<div class=""prev""><a href=""introduction.html"">Introduction</a></div>
+<div class=""next""><a href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
+      <ul class=""nav navbar-nav"">
+<li><a class=""nav-link"" href=""#crashcourse""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class=""nav-link"" href=""#introduction-1""><span class=""header-section-number"">1.1</span> Introduction</a></li>
+<li><a class=""nav-link"" href=""#bayes-theorem""><span class=""header-section-number"">1.2</span> Bayes‚Äô theorem</a></li>
+<li><a class=""nav-link"" href=""#what-is-the-bayesian-approach""><span class=""header-section-number"">1.3</span> What is the Bayesian approach?</a></li>
+<li><a class=""nav-link"" href=""#numerical-approx""><span class=""header-section-number"">1.4</span> Approximating posteriors via numerical integration</a></li>
+<li>
+<a class=""nav-link"" href=""#markov-chain-monte-carlo-mcmc""><span class=""header-section-number"">1.5</span> Markov chain Monte Carlo (MCMC)</a><ul class=""nav navbar-nav"">
+<li><a class=""nav-link"" href=""#monte-carlo-integration""><span class=""header-section-number"">1.5.1</span> Monte Carlo integration</a></li>
+<li><a class=""nav-link"" href=""#markovmodelmcmc""><span class=""header-section-number"">1.5.2</span> Markov chains</a></li>
+<li><a class=""nav-link"" href=""#metropolis-algorithm""><span class=""header-section-number"">1.5.3</span> Metropolis algorithm</a></li>
+</ul>
+</li>
+<li>
+<a class=""nav-link"" href=""#convergence-diag""><span class=""header-section-number"">1.6</span> Assessing convergence</a><ul class=""nav navbar-nav"">
+<li><a class=""nav-link"" href=""#burn-in""><span class=""header-section-number"">1.6.1</span> Burn-in</a></li>
+<li><a class=""nav-link"" href=""#chain-length""><span class=""header-section-number"">1.6.2</span> Chain length</a></li>
+<li><a class=""nav-link"" href=""#what-if-you-have-issues-of-convergence""><span class=""header-section-number"">1.6.3</span> What if you have issues of convergence?</a></li>
+</ul>
+</li>
+<li><a class=""nav-link"" href=""#summary""><span class=""header-section-number"">1.7</span> Summary</a></li>
+<li><a class=""nav-link"" href=""#suggested-reading""><span class=""header-section-number"">1.8</span> Suggested reading</a></li>
+</ul>
+
+      <div class=""book-extra"">
+        <ul class=""list-unstyled"">
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/bayesmcmc.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/bayesmcmc.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+        </ul>
+</div>
+    </nav>
+</div>
+
+</div>
+</div> <!-- .container -->
+
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-12.</p>
+  </div>
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
+  </div>
+
+</div></div>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
+</body>
+</html>

---FILE: docs/index.html---
@@ -73,13 +73,17 @@ <h1>
 <li><a class="""" href=""about-the-author.html"">About the author</a></li>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">1</span> Survival</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>

---FILE: docs/introduction-4.html---
@@ -73,13 +73,17 @@ <h1>
 <li><a class="""" href=""about-the-author.html"">About the author</a></li>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">1</span> Survival</a></li>
+<li><a class=""active"" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class=""active"" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
@@ -92,18 +96,19 @@ <h1>
   </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""introduction-4"" class=""section level1 unnumbered"">
 <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-4""><i class=""fas fa-link""></i></a>
 </h1>
+
 </div>
   <div class=""chapter-nav"">
-<div class=""prev""><a href=""introduction-3.html"">Introduction</a></div>
-<div class=""next""><a href=""take-home-messages.html"">Take-home messages</a></div>
+<div class=""prev""><a href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></div>
+<div class=""next""><a href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
       <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#introduction-4"">Introduction</a></li></ul>
 
       <div class=""book-extra"">
         <ul class=""list-unstyled"">
-<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionpartfour.Rmd"">View source <i class=""fab fa-github""></i></a></li>
-          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionpartfour.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionparttwo.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionparttwo.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
         </ul>
 </div>
     </nav>

---FILE: docs/introduction-7.html---
@@ -0,0 +1,164 @@
+<!DOCTYPE html>
+<html lang=""en"">
+<head>
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
+<meta property=""og:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/introduction-7.html"">
+<meta property=""og:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+    
+    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
+  </style>
+<style type=""text/css"">
+    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
+    div.csl-bib-body { }
+    div.csl-entry {
+      clear: both;
+        }
+    .hanging div.csl-entry {
+      margin-left:2em;
+      text-indent:-2em;
+    }
+    div.csl-left-margin {
+      min-width:2em;
+      float:left;
+    }
+    div.csl-right-inline {
+      margin-left:2em;
+      padding-left:1em;
+    }
+    div.csl-indent {
+      margin-left: 2em;
+    }
+  </style>
+<link rel=""stylesheet"" href=""bs4_style.css"">
+</head>
+<body data-spy=""scroll"" data-target=""#toc"">
+
+<div class=""container-fluid"">
+<div class=""row"">
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+
+    <div class=""d-flex align-items-start justify-content-between"">
+      <h1>
+        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
+        <small class=""text-muted"">Theory and Case Studies in R</small>
+      </h1>
+      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
+    </div>
+
+    <div id=""main-nav"" class=""collapse-lg"">
+      <form role=""search"">
+        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
+</form>
+
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li><a class="""" href=""about-the-author.html"">About the author</a></li>
+<li class=""book-part"">I. Foundations</li>
+<li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
+<li class=""book-part"">II. Transitions</li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
+<li class=""book-part"">III. Case studies</li>
+<li><a class=""active"" href=""introduction-7.html"">Introduction</a></li>
+<li class=""book-part"">IV. Conclusions</li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
+<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
+
+        <div class=""book-extra"">
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
+        </div>
+      </nav>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""introduction-7"" class=""section level1 unnumbered"">
+<h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-7""><i class=""fas fa-link""></i></a>
+</h1>
+
+</div>
+
+
+
+  <div class=""chapter-nav"">
+<div class=""prev""><a href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></div>
+<div class=""next""><a href=""introduction-8.html"">Introduction</a></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
+      <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#introduction-7"">Introduction</a></li></ul>
+
+      <div class=""book-extra"">
+        <ul class=""list-unstyled"">
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionpartthree.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionpartthree.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+        </ul>
+</div>
+    </nav>
+</div>
+
+</div>
+</div> <!-- .container -->
+
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-12.</p>
+  </div>
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
+  </div>
+
+</div></div>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
+</body>
+</html>

---FILE: docs/introduction-8.html---
@@ -0,0 +1,160 @@
+<!DOCTYPE html>
+<html lang=""en"">
+<head>
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
+<meta property=""og:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/introduction-8.html"">
+<meta property=""og:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
+<meta name=""twitter:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
+<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
+    
+    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
+  </style>
+<style type=""text/css"">
+    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
+    div.csl-bib-body { }
+    div.csl-entry {
+      clear: both;
+        }
+    .hanging div.csl-entry {
+      margin-left:2em;
+      text-indent:-2em;
+    }
+    div.csl-left-margin {
+      min-width:2em;
+      float:left;
+    }
+    div.csl-right-inline {
+      margin-left:2em;
+      padding-left:1em;
+    }
+    div.csl-indent {
+      margin-left: 2em;
+    }
+  </style>
+<link rel=""stylesheet"" href=""bs4_style.css"">
+</head>
+<body data-spy=""scroll"" data-target=""#toc"">
+
+<div class=""container-fluid"">
+<div class=""row"">
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+
+    <div class=""d-flex align-items-start justify-content-between"">
+      <h1>
+        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
+        <small class=""text-muted"">Theory and Case Studies in R</small>
+      </h1>
+      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
+    </div>
+
+    <div id=""main-nav"" class=""collapse-lg"">
+      <form role=""search"">
+        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
+</form>
+
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li><a class="""" href=""about-the-author.html"">About the author</a></li>
+<li class=""book-part"">I. Foundations</li>
+<li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
+<li class=""book-part"">II. Transitions</li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
+<li class=""book-part"">III. Case studies</li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li class=""book-part"">IV. Conclusions</li>
+<li><a class=""active"" href=""introduction-8.html"">Introduction</a></li>
+<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
+
+        <div class=""book-extra"">
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
+        </div>
+      </nav>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""introduction-8"" class=""section level1 unnumbered"">
+<h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-8""><i class=""fas fa-link""></i></a>
+</h1>
+</div>
+  <div class=""chapter-nav"">
+<div class=""prev""><a href=""introduction-7.html"">Introduction</a></div>
+<div class=""next""><a href=""take-home-messages.html"">Take-home messages</a></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
+      <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#introduction-8"">Introduction</a></li></ul>
+
+      <div class=""book-extra"">
+        <ul class=""list-unstyled"">
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionpartfour.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionpartfour.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+        </ul>
+</div>
+    </nav>
+</div>
+
+</div>
+</div> <!-- .container -->
+
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-12.</p>
+  </div>
+
+  <div class=""col-12 col-md-6 mt-3"">
+    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
+  </div>
+
+</div></div>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
+</body>
+</html>

---FILE: docs/introduction.html---
@@ -73,13 +73,17 @@ <h1>
 <li><a class="""" href=""about-the-author.html"">About the author</a></li>
 <li class=""book-part"">I. Foundations</li>
 <li><a class=""active"" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">1</span> Survival</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
@@ -94,12 +98,9 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction""><i cl
 </h1>
 
 </div>
-
-
-
   <div class=""chapter-nav"">
 <div class=""prev""><a href=""about-the-author.html"">About the author</a></div>
-<div class=""next""><a href=""introduction-1.html"">Introduction</a></div>
+<div class=""next""><a href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
       <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#introduction"">Introduction</a></li></ul>

---FILE: docs/preface.html---
@@ -73,13 +73,17 @@ <h1>
 <li><a class="""" href=""about-the-author.html"">About the author</a></li>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">1</span> Survival</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>

---FILE: docs/reference-keys.txt---
@@ -1,7 +1,97 @@
+fig:revbayes
+fig:bayestheorem
+fig:binlik
+fig:numapprox
+fig:betadistribution
+fig:compar
+fig:mcmcpaper
+fig:chain
+fig:twochains
+fig:longchain
+fig:animlongchain
+fig:burnin
+fig:bgr
+fig:tracechainlength
+fig:acfchainlength
+fig:nimblelogo
+fig:dag-survival
+fig:traceown
+fig:treillis-viterbi
+fig:viterbiaveragecompute
+fig:viterbicomputeaverage
 fig:marking
 fig:pixdipper
-survival
+fig:unnamed-chunk-302
+fig:unnamed-chunk-319
+crashcourse
+introduction-1
+bayes-theorem
+what-is-the-bayesian-approach
+numerical-approx
+markov-chain-monte-carlo-mcmc
+monte-carlo-integration
+markovmodelmcmc
+metropolis-algorithm
+convergence-diag
+burn-in
+chain-length
+what-if-you-have-issues-of-convergence
+summary
+suggested-reading
+intronimble
 introduction-2
+what-is-nimble
+start-nimble
+functions-in-nimble
+nimble-functions
+callrfninnimble
+user-defined-distributions
+under-the-hood
+mcmc-samplers
+change-sampler
+user-defined-samplers
+tips-and-tricks
+precision-vs-standard-deviation
+indexing
+faster-compilation
+updating-mcmc-chains
+reproducibility
+parallelization
+incomplete-initialization
+vectorization
+summary-1
+suggested-reading-1
+hmmcapturerecapture
+introduction-3
+longitudinal-data
+a-markov-model-for-longitudinal-data
+assumptions
+transition-matrix
+initial-states
+likelihood
+example
+bayesian-formulation
+nimble-implementation
+hidden-markov-models
+capturerecapturedata
+observation-matrix
+hidden-markov-model
+likelihoodhmm
+fittinghmmnimble
+marginalization
+brute-force-approach
+forward-algorithm
+nimble-implementation-1
+pooled-likelihood
+decoding
+viterbi-theory
+implementation
+compute-average
+average-first-compute-after
+summary-2
+suggested-reading-2
+survival
+introduction-5
 the-cormack-jolly-seber-cjs-model
 capture-recapture-data
 fitting-the-cjs-model-to-the-dipper-data-with-nimble
@@ -21,5 +111,49 @@ continuous-1
 several-covariates
 random-effects
 individual-time-varying-covariates
-summary
-suggested-reading
+summary-3
+suggested-reading-3
+dispersal
+introduction-6
+wintering-site-fidelity-in-canada-geese
+sites-carolinas-chesapeake-mid-atlantic
+biological-inference
+the-model-construction-how-we-should-think.
+the-model-construction-how-we-should-think.-1
+the-model-construction-how-we-should-think.-2
+the-model-construction-how-we-should-think.-3
+hmm-model-for-dispersal-with-2-sites-drop-carolinas
+hmm-model-for-dispersal-with-2-sites-drop-carolinas-1
+hmm-model-for-dispersal-with-2-sites-drop-carolinas-2
+our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b
+our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-1
+our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-2
+our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-3
+our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-4
+our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-5
+what-if-there-are-three-sites
+nimble-implementation-of-the-dirichlet-prior
+nimble-implementation-of-the-dirichlet-prior-1
+multinomial-logit
+nimble-implementation-of-the-dirichlet-prior-2
+nimble-implementation-of-the-dirichlet-prior-3
+sites-may-be-states.
+examples-of-multistate-models
+sooty-shearwater-david-boyle
+sooty-shearwaters-and-life-history-tradeoffs
+sooty-shearwaters-and-life-history-tradeoffs-1
+hmm-model-for-transition-between-states
+hmm-model-for-transition-between-states-1
+our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b
+our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-1
+our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-2
+our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-3
+our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-4
+issue-of-local-minima
+data
+uncertainty
+uncertainty-in-breeding-status-sooty-shearwater-david-boyle
+hmm-model-for-breeding-states-with-uncertainty
+results
+summary-4
+suggested-reading-4

---FILE: docs/references.html---
@@ -6,15 +6,15 @@
 <meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <title>References | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
 <meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""Royle, J Andrew, Richard B Chandler, Rahel Sollmann, and Beth Gardner. 2013. Spatial Capture-Recapture. Academic Press.  Williams, B. K., J. D. Nichols, and M. J. Conroy. 2002. Analysis and..."">
+<meta name=""description"" content=""Albert, Jim, and Jingchen Hu. 2019. Probability and Bayesian Modeling. 1st edition. Chapman; Hall/CRC.  King, Ruth, B. J. T. Morgan, O. Gimenez, and S. P. Brooks. 2009. Bayesian Analysis for..."">
 <meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
 <meta property=""og:title"" content=""References | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
 <meta property=""og:type"" content=""book"">
 <meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/references.html"">
-<meta property=""og:description"" content=""Royle, J Andrew, Richard B Chandler, Rahel Sollmann, and Beth Gardner. 2013. Spatial Capture-Recapture. Academic Press.  Williams, B. K., J. D. Nichols, and M. J. Conroy. 2002. Analysis and..."">
+<meta property=""og:description"" content=""Albert, Jim, and Jingchen Hu. 2019. Probability and Bayesian Modeling. 1st edition. Chapman; Hall/CRC.  King, Ruth, B. J. T. Morgan, O. Gimenez, and S. P. Brooks. 2009. Bayesian Analysis for..."">
 <meta name=""twitter:card"" content=""summary"">
 <meta name=""twitter:title"" content=""References | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta name=""twitter:description"" content=""Royle, J Andrew, Richard B Chandler, Rahel Sollmann, and Beth Gardner. 2013. Spatial Capture-Recapture. Academic Press.  Williams, B. K., J. D. Nichols, and M. J. Conroy. 2002. Analysis and..."">
+<meta name=""twitter:description"" content=""Albert, Jim, and Jingchen Hu. 2019. Probability and Bayesian Modeling. 1st edition. Chapman; Hall/CRC.  King, Ruth, B. J. T. Morgan, O. Gimenez, and S. P. Brooks. 2009. Bayesian Analysis for..."">
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
@@ -73,13 +73,17 @@ <h1>
 <li><a class="""" href=""about-the-author.html"">About the author</a></li>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">1</span> Survival</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class=""active"" href=""references.html"">References</a></li>
 </ul>
@@ -94,6 +98,18 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 </h1>
 
 <div id=""refs"" class=""references csl-bib-body hanging-indent"">
+<div id=""ref-alberthu2019"" class=""csl-entry"">
+Albert, Jim, and Jingchen Hu. 2019. <em>Probability and <span>Bayesian</span> <span>Modeling</span></em>. 1st edition. Chapman; Hall/CRC.
+</div>
+<div id=""ref-king_bayesian_2009"" class=""csl-entry"">
+King, Ruth, B. J. T. Morgan, O. Gimenez, and S. P. Brooks. 2009. <em>Bayesian <span>Analysis</span> for <span>Population</span> <span>Ecology</span></em>. Chapman; Hall/CRC.
+</div>
+<div id=""ref-mcelreathbook"" class=""csl-entry"">
+McElreath, Richard. 2016. <em>Statistical <span>Rethinking</span>: <span>A</span> <span>Bayesian</span> <span>Course</span> with <span>Examples</span> in <span>R</span> and <span>Stan</span></em>. 1st edition. Chapman; Hall/CRC.
+</div>
+<div id=""ref-mcgrayne2011"" class=""csl-entry"">
+McGrayne, Sharon Bertsch. 2011. <em>The <span>Theory</span> <span>That</span> <span>Would</span> <span>Not</span> <span>Die</span>: <span>How</span> <span>Bayes</span>‚Äô <span>Rule</span> <span>Cracked</span> the <span>Enigma</span> <span>Code</span>, <span>Hunted</span> <span>Down</span> <span>Russian</span> <span>Submarines</span>, and <span>Emerged</span> <span>Triumphant</span> from <span>Two</span> <span>Centuries</span> of <span>Controversy</span></em>. Yale University Press.
+</div>
 <div id=""ref-RoyleEtAl2013book"" class=""csl-entry"">
 Royle, J Andrew, Richard B Chandler, Rahel Sollmann, and Beth Gardner. 2013. <em>Spatial Capture-Recapture</em>. Academic Press.
 </div>
@@ -108,6 +124,36 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 
 
 
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
   <div class=""chapter-nav"">
 <div class=""prev""><a href=""take-home-messages.html"">Take-home messages</a></div>
 <div class=""empty""></div>

---FILE: docs/take-home-messages.html---
@@ -73,13 +73,17 @@ <h1>
 <li><a class="""" href=""about-the-author.html"">About the author</a></li>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">1</span> Survival</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
 <li><a class=""active"" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
@@ -168,7 +172,7 @@ <h1>Take-home messages<a class=""anchor"" aria-label=""anchor"" href=""#take-home-mes
 
 </div>
   <div class=""chapter-nav"">
-<div class=""prev""><a href=""introduction-4.html"">Introduction</a></div>
+<div class=""prev""><a href=""introduction-8.html"">Introduction</a></div>
 <div class=""next""><a href=""references.html"">References</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>",False,True,Rendering / Conversion,6
oliviergimenez,banana-book,955123c3936cf3159d750e7cdcd25ac513387a82,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2023-08-12T14:27:44Z,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2023-08-12T14:27:44Z,Try to fix issue w/ figures not showing in survival chapter.,_bookdown.yml;_bookdown_files/banana-book.aux;_bookdown_files/banana-book.idx;_bookdown_files/banana-book.lof;_bookdown_files/banana-book.log;_bookdown_files/banana-book.lot;_bookdown_files/banana-book.pdf;_bookdown_files/banana-book.synctex(busy);_bookdown_files/banana-book.synctex.gz;_bookdown_files/banana-book.tex;_bookdown_files/banana-book.toc;_bookdown_files/banana-book_cache/html/__packages;_bookdown_files/banana-book_cache/html/unnamed-chunk-27_e639ee4bcbace813a16a85eab2880552.RData;_bookdown_files/banana-book_cache/html/unnamed-chunk-27_e639ee4bcbace813a16a85eab2880552.rdb;_bookdown_files/banana-book_cache/html/unnamed-chunk-27_e639ee4bcbace813a16a85eab2880552.rdx;_bookdown_files/banana-book_cache/latex/__packages;_bookdown_files/banana-book_files/figure-html/acfchainlength-1.png;_bookdown_files/banana-book_files/figure-html/betadistribution-1.png;_bookdown_files/banana-book_files/figure-html/bgr-1.png;_bookdown_files/banana-book_files/figure-html/binlik-1.png;_bookdown_files/banana-book_files/figure-html/burnin-1.png;_bookdown_files/banana-book_files/figure-html/chain-1.png;_bookdown_files/banana-book_files/figure-html/compar-1.png;_bookdown_files/banana-book_files/figure-html/dag-survival-1.png;_bookdown_files/banana-book_files/figure-html/longchain-1.png;_bookdown_files/banana-book_files/figure-html/numapprox-1.png;_bookdown_files/banana-book_files/figure-html/tracechainlength-1.png;_bookdown_files/banana-book_files/figure-html/traceown-1.png;_bookdown_files/banana-book_files/figure-html/twochains-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-110-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-110-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-111-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-111-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-131-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-131-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-132-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-132-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-173-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-173-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-174-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-174-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-194-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-195-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-197-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-198-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-199-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-200-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-201-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-202-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-203-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-204-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-205-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-43-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-46-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-47-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-48-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-52-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-72-1.png;_bookdown_files/banana-book_files/figure-html/viterbiaveragecompute-1.png;_bookdown_files/banana-book_files/figure-html/viterbicomputeaverage-1.png;_bookdown_files/banana-book_files/figure-latex/acfchainlength-1.pdf;_bookdown_files/banana-book_files/figure-latex/betadistribution-1.pdf;_bookdown_files/banana-book_files/figure-latex/bgr-1.pdf;_bookdown_files/banana-book_files/figure-latex/binlik-1.pdf;_bookdown_files/banana-book_files/figure-latex/burnin-1.pdf;_bookdown_files/banana-book_files/figure-latex/chain-1.pdf;_bookdown_files/banana-book_files/figure-latex/compar-1.pdf;_bookdown_files/banana-book_files/figure-latex/dag-survival-1.pdf;_bookdown_files/banana-book_files/figure-latex/longchain-1.pdf;_bookdown_files/banana-book_files/figure-latex/numapprox-1.pdf;_bookdown_files/banana-book_files/figure-latex/tracechainlength-1.pdf;_bookdown_files/banana-book_files/figure-latex/traceown-1.pdf;_bookdown_files/banana-book_files/figure-latex/twochains-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-110-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-111-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-131-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-132-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-197-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-199-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-200-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-201-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-202-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-203-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-204-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-205-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-43-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-46-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-47-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-48-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-52-1.pdf;_bookdown_files/banana-book_files/figure-latex/unnamed-chunk-72-1.pdf;_bookdown_files/images/002d7e638fb463fb7a266f5ffc7ac47d.gif;_bookdown_files/images/112546886-56862f00-8dba-11eb-81a0-465434672bdd.gif;_bookdown_files/images/19IP.gif;_bookdown_files/images/4FOU.gif;_bookdown_files/images/4Vg4.gif;_bookdown_files/images/84.gif;_bookdown_files/images/Do-Not-Google-That-Phrase-Parks-Recreation.gif;_bookdown_files/images/GaseousHappyBigmouthbass-size_restricted.gif;_bookdown_files/images/I1bIY06.gif;_bookdown_files/images/MarzoCin502728Sauvoy.jpg;_bookdown_files/images/Marzo_BaguesMance.jpg;_bookdown_files/images/Marzocuissardes.jpg;_bookdown_files/images/RgS.gif;_bookdown_files/images/RobRob_Comment_edited.png;_bookdown_files/images/ToddStudents_Meme.jpg;_bookdown_files/images/amazing-thomas-bayes-illustration.jpg;_bookdown_files/images/archer.png;_bookdown_files/images/arnason1973.png;_bookdown_files/images/arnason_small.png;_bookdown_files/images/b31cc5e589e3f2d1796cafcca73deb84.gif;_bookdown_files/images/b5b086f9cc403008ba7be5dd508cfed2.gif;_bookdown_files/images/bayes_neon.jpeg;_bookdown_files/images/bearscat.png;_bookdown_files/images/bighorn.png;_bookdown_files/images/burnin.png;_bookdown_files/images/by-nc-sa.png;_bookdown_files/images/chloe.jpg;_bookdown_files/images/cormack-left.png;_bookdown_files/images/cormack-right.png;_bookdown_files/images/create-gif.gif;_bookdown_files/images/deadpool.gif;_bookdown_files/images/galery.png;_bookdown_files/images/geese.png;_bookdown_files/images/googleform.png;_bookdown_files/images/gull.jpg;_bookdown_files/images/histMCMC.gif;_bookdown_files/images/infectedhousefinch.jpg;_bookdown_files/images/king.png;_bookdown_files/images/lebreton.png;_bookdown_files/images/lynx.png;_bookdown_files/images/maniac.png;_bookdown_files/images/maniac1.png;_bookdown_files/images/maniac2.png;_bookdown_files/images/maud.png;_bookdown_files/images/metropolis.png;_bookdown_files/images/mindblow.gif;_bookdown_files/images/mixing.png;_bookdown_files/images/montpellier.png;_bookdown_files/images/more_than_2_states.png;_bookdown_files/images/multistate_local_minimav2_Page_05.png;_bookdown_files/images/multistate_local_minimav2_Page_06.png;_bookdown_files/images/multistate_local_minimav2_Page_07.png;_bookdown_files/images/nichols.png;_bookdown_files/images/nichols1992.png;_bookdown_files/images/nichols1994.png;_bookdown_files/images/nimble-icon.png;_bookdown_files/images/nimble_workflow.png;_bookdown_files/images/nimble_workflow_sofar.png;_bookdown_files/images/olivier.jpg;_bookdown_files/images/perry.jpg;_bookdown_files/images/r_1051694_ifmHZ.gif;_bookdown_files/images/sarah.jpg;_bookdown_files/images/satellite 2.png;_bookdown_files/images/satellite.png;_bookdown_files/images/schwarz1993.png;_bookdown_files/images/schwarz_small.png;_bookdown_files/images/sooty.jpg;_bookdown_files/images/traceplotMCMC.gif;_bookdown_files/images/treillis-viterbi.png;_bookdown_files/images/wolfdominance.jpg;_bookdown_files/images/zoom-covid.png;_bookdown_files/krantz.cls;docs/404.html;docs/about-the-author.html;docs/abundance.html;docs/banana-book.pdf;docs/banana-book.tex;docs/banana-book_files/figure-html/acfchainlength-1.png;docs/banana-book_files/figure-html/betadistribution-1.png;docs/banana-book_files/figure-html/bgr-1.png;docs/banana-book_files/figure-html/binlik-1.png;docs/banana-book_files/figure-html/burnin-1.png;docs/banana-book_files/figure-html/chain-1.png;docs/banana-book_files/figure-html/compar-1.png;docs/banana-book_files/figure-html/dag-survival-1.png;docs/banana-book_files/figure-html/longchain-1.png;docs/banana-book_files/figure-html/numapprox-1.png;docs/banana-book_files/figure-html/tracechainlength-1.png;docs/banana-book_files/figure-html/traceown-1.png;docs/banana-book_files/figure-html/twochains-1.png;docs/banana-book_files/figure-html/unnamed-chunk-110-1.png;docs/banana-book_files/figure-html/unnamed-chunk-111-1.png;docs/banana-book_files/figure-html/unnamed-chunk-131-1.png;docs/banana-book_files/figure-html/unnamed-chunk-132-1.png;docs/banana-book_files/figure-html/unnamed-chunk-173-1.png;docs/banana-book_files/figure-html/unnamed-chunk-174-1.png;docs/banana-book_files/figure-html/unnamed-chunk-194-1.png;docs/banana-book_files/figure-html/unnamed-chunk-195-1.png;docs/banana-book_files/figure-html/unnamed-chunk-197-1.png;docs/banana-book_files/figure-html/unnamed-chunk-198-1.png;docs/banana-book_files/figure-html/unnamed-chunk-199-1.png;docs/banana-book_files/figure-html/unnamed-chunk-200-1.png;docs/banana-book_files/figure-html/unnamed-chunk-201-1.png;docs/banana-book_files/figure-html/unnamed-chunk-202-1.png;docs/banana-book_files/figure-html/unnamed-chunk-203-1.png;docs/banana-book_files/figure-html/unnamed-chunk-204-1.png;docs/banana-book_files/figure-html/unnamed-chunk-205-1.png;docs/banana-book_files/figure-html/unnamed-chunk-43-1.png;docs/banana-book_files/figure-html/unnamed-chunk-46-1.png;docs/banana-book_files/figure-html/unnamed-chunk-47-1.png;docs/banana-book_files/figure-html/unnamed-chunk-48-1.png;docs/banana-book_files/figure-html/unnamed-chunk-52-1.png;docs/banana-book_files/figure-html/unnamed-chunk-72-1.png;docs/banana-book_files/figure-html/viterbiaveragecompute-1.png;docs/banana-book_files/figure-html/viterbicomputeaverage-1.png;docs/crashcourse.html;docs/dispersal.html;docs/faq.html;docs/hmmcapturerecapture.html;docs/images/Marzocuissardes.jpg;docs/images/amazing-thomas-bayes-illustration.jpg;docs/images/arnason1973.png;docs/images/bayes_neon.jpeg;docs/images/cormack-left.png;docs/images/cormack-right.png;docs/images/deadpool.gif;docs/images/king.png;docs/images/lebreton.png;docs/images/metropolis.png;docs/images/multistate_local_minimav2_Page_05.png;docs/images/multistate_local_minimav2_Page_06.png;docs/images/multistate_local_minimav2_Page_07.png;docs/images/nichols.png;docs/images/nimble-icon.png;docs/images/schwarz1993.png;docs/images/sooty.jpg;docs/images/traceplotMCMC.gif;docs/images/treillis-viterbi.png;docs/index.html;docs/individual-dependence.html;docs/introduction-2.html;docs/introduction-4.html;docs/introduction-5.html;docs/introduction-6.html;docs/introduction-7.html;docs/introduction-8.html;docs/introduction.html;docs/intronimble.html;docs/libs/bs3compat-0.4.2/bs3compat.js;docs/libs/bs3compat-0.4.2/tabs.js;docs/libs/bs3compat-0.4.2/transition.js;docs/model-selection.html;docs/preface.html;docs/reference-keys.txt;docs/references.html;docs/search.json;docs/stopover.html;docs/survival.html;docs/take-home-messages.html;docs/tradeoffs.html;docs/uncertainty.html;survival.Rmd,True,False,True,False,346,57137,57483,"---FILE: _bookdown.yml---
@@ -17,12 +17,12 @@ rmd_files:
     ""preface.Rmd"",
     ""author.Rmd"",
     ""introductionpartone.Rmd"",
-    ""bayesmcmc.Rmd"",
-    ""nimble.Rmd"",
-    ""hmm.Rmd"",
+   # ""bayesmcmc.Rmd"",
+  #  ""nimble.Rmd"",
+  #  ""hmm.Rmd"",
     ""introductionparttwo.Rmd"",
     ""survival.Rmd"",
-    ""dispersal.Rmd"",
+   # ""dispersal.Rmd"",
     ""introductionpartthree.Rmd"",
   # ""lht.Rmd"",
   #  ""abundance.Rmd"",

---FILE: _bookdown_files/banana-book.aux---
@@ -1,98 +0,0 @@
-\relax 
-\providecommand\hyper@newdestlabel[2]{}
-\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
-\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
-\global\let\oldnewlabel\newlabel
-\gdef\newlabel#1#2{\newlabelxx{#1}#2}
-\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
-\AtEndDocument{\ifx\hyper@anchor\@undefined
-\let\newlabel\oldnewlabel
-\fi}
-\fi}
-\global\let\hyper@last\relax 
-\gdef\HyperFirstAtBeginDocument#1{#1}
-\providecommand*\HyPL@Entry[1]{}
-\bibstyle{plainnat}
-\HyPL@Entry{0<</S/r>>}
-\@writefile{toc}{\contentsline {fm}{List of Figures}{v}{chapter*.1}\protected@file@percent }
-\@writefile{toc}{\contentsline {fm}{List of Tables}{vii}{chapter*.2}\protected@file@percent }
-\@writefile{toc}{\contentsline {fm}{Welcome}{ix}{chapter*.3}\protected@file@percent }
-\newlabel{welcome}{{}{ix}{Welcome}{chapter*.3}{}}
-\newlabel{license}{{}{x}{License}{section*.4}{}}
-\@writefile{toc}{\contentsline {fm}{Preface}{xi}{chapter*.5}\protected@file@percent }
-\newlabel{preface}{{}{xi}{Preface}{chapter*.5}{}}
-\newlabel{why-this-book}{{}{xi}{Why this book?}{section*.6}{}}
-\newlabel{who-should-read-this-book}{{}{xi}{Who should read this book?}{section*.7}{}}
-\citation{WilliamsEtAl2002}
-\citation{RoyleEtAl2013book}
-\newlabel{what-will-you-learn}{{}{xii}{What will you learn?}{section*.8}{}}
-\newlabel{what-wont-you-learn}{{}{xii}{What won't you learn?}{section*.9}{}}
-\newlabel{prerequisites}{{}{xiii}{Prerequisites}{section*.10}{}}
-\newlabel{acknowledgements}{{}{xiii}{Acknowledgements}{section*.11}{}}
-\newlabel{how-this-book-was-written}{{}{xiii}{How this book was written}{section*.12}{}}
-\gdef \LT@i {\LT@entry 
-    {2}{69.42802pt}\LT@entry 
-    {1}{45.88002pt}\LT@entry 
-    {2}{78.92003pt}}
-\@writefile{toc}{\contentsline {fm}{About the author}{xv}{chapter*.13}\protected@file@percent }
-\newlabel{about-the-author}{{}{xv}{About the author}{chapter*.13}{}}
-\HyPL@Entry{16<</S/D>>}
-\@writefile{toc}{\contentsline {part}{I\hspace  {1em}I. Foundations}{1}{part.1}\protected@file@percent }
-\newlabel{part-i.-foundations}{{I}{3}{I. Foundations}{part.1}{}}
-\@writefile{toc}{\contentsline {fm}{Introduction}{3}{chapter*.14}\protected@file@percent }
-\newlabel{introduction}{{I}{3}{Introduction}{chapter*.14}{}}
-\@writefile{toc}{\contentsline {chapter}{\numberline {1}NIMBLE tutorial}{5}{chapter.1}\protected@file@percent }
-\@writefile{lof}{\addvspace {10\p@ }}
-\@writefile{lot}{\addvspace {10\p@ }}
-\newlabel{intronimble}{{1}{5}{NIMBLE tutorial}{chapter.1}{}}
-\@writefile{toc}{\contentsline {section}{\numberline {1.1}Introduction}{5}{section.1.1}\protected@file@percent }
-\newlabel{introduction-1}{{1.1}{5}{Introduction}{section.1.1}{}}
-\@writefile{toc}{\contentsline {section}{\numberline {1.2}What is NIMBLE?}{5}{section.1.2}\protected@file@percent }
-\newlabel{what-is-nimble}{{1.2}{5}{What is NIMBLE?}{section.1.2}{}}
-\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Logo of the NIMBLE R package designed by Luke Larson. **Ask Perry for context and meaning.**\relax }}{6}{figure.caption.15}\protected@file@percent }
-\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
-\newlabel{fig:nimblelogo}{{1.1}{6}{Logo of the NIMBLE R package designed by Luke Larson. **Ask Perry for context and meaning.**\relax }{figure.caption.15}{}}
-\@writefile{toc}{\contentsline {section}{\numberline {1.3}Getting started}{6}{section.1.3}\protected@file@percent }
-\newlabel{start-nimble}{{1.3}{6}{Getting started}{section.1.3}{}}
-\@writefile{toc}{\contentsline {section}{\numberline {1.4}Programming}{20}{section.1.4}\protected@file@percent }
-\newlabel{functions-in-nimble}{{1.4}{20}{Programming}{section.1.4}{}}
-\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}NIMBLE functions}{20}{subsection.1.4.1}\protected@file@percent }
-\newlabel{nimble-functions}{{1.4.1}{20}{NIMBLE functions}{subsection.1.4.1}{}}
-\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}Calling R/C++ functions}{23}{subsection.1.4.2}\protected@file@percent }
-\newlabel{callrfninnimble}{{1.4.2}{23}{Calling R/C++ functions}{subsection.1.4.2}{}}
-\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.3}User-defined distributions}{25}{subsection.1.4.3}\protected@file@percent }
-\newlabel{user-defined-distributions}{{1.4.3}{25}{User-defined distributions}{subsection.1.4.3}{}}
-\@writefile{toc}{\contentsline {section}{\numberline {1.5}Under the hood}{27}{section.1.5}\protected@file@percent }
-\newlabel{under-the-hood}{{1.5}{27}{Under the hood}{section.1.5}{}}
-\@writefile{toc}{\contentsline {section}{\numberline {1.6}MCMC samplers}{34}{section.1.6}\protected@file@percent }
-\newlabel{mcmc-samplers}{{1.6}{34}{MCMC samplers}{section.1.6}{}}
-\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.1}Default samplers}{34}{subsection.1.6.1}\protected@file@percent }
-\newlabel{change-sampler}{{1.6.1}{34}{Default samplers}{subsection.1.6.1}{}}
-\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.2}User-defined samplers}{35}{subsection.1.6.2}\protected@file@percent }
-\newlabel{user-defined-samplers}{{1.6.2}{35}{User-defined samplers}{subsection.1.6.2}{}}
-\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Trace plots for different values of the standard deviation (scale) of the proposal distribution.\relax }}{39}{figure.caption.16}\protected@file@percent }
-\newlabel{fig:traceown}{{1.2}{39}{Trace plots for different values of the standard deviation (scale) of the proposal distribution.\relax }{figure.caption.16}{}}
-\@writefile{toc}{\contentsline {section}{\numberline {1.7}Tips and tricks}{39}{section.1.7}\protected@file@percent }
-\newlabel{tips-and-tricks}{{1.7}{39}{Tips and tricks}{section.1.7}{}}
-\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.1}Precision vs standard deviation}{39}{subsection.1.7.1}\protected@file@percent }
-\newlabel{precision-vs-standard-deviation}{{1.7.1}{39}{Precision vs standard deviation}{subsection.1.7.1}{}}
-\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.2}Indexing}{40}{subsection.1.7.2}\protected@file@percent }
-\newlabel{indexing}{{1.7.2}{40}{Indexing}{subsection.1.7.2}{}}
-\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.3}Faster compilation}{40}{subsection.1.7.3}\protected@file@percent }
-\newlabel{faster-compilation}{{1.7.3}{40}{Faster compilation}{subsection.1.7.3}{}}
-\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.4}Updating MCMC chains}{41}{subsection.1.7.4}\protected@file@percent }
-\newlabel{updating-mcmc-chains}{{1.7.4}{41}{Updating MCMC chains}{subsection.1.7.4}{}}
-\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.5}Reproducibility}{42}{subsection.1.7.5}\protected@file@percent }
-\newlabel{reproducibility}{{1.7.5}{42}{Reproducibility}{subsection.1.7.5}{}}
-\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.6}Parallelization}{43}{subsection.1.7.6}\protected@file@percent }
-\newlabel{parallelization}{{1.7.6}{43}{Parallelization}{subsection.1.7.6}{}}
-\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.7}Incomplete initialization}{46}{subsection.1.7.7}\protected@file@percent }
-\newlabel{incomplete-initialization}{{1.7.7}{46}{Incomplete initialization}{subsection.1.7.7}{}}
-\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.8}Vectorization}{47}{subsection.1.7.8}\protected@file@percent }
-\newlabel{vectorization}{{1.7.8}{47}{Vectorization}{subsection.1.7.8}{}}
-\@writefile{toc}{\contentsline {section}{\numberline {1.8}Summary}{48}{section.1.8}\protected@file@percent }
-\newlabel{summary}{{1.8}{48}{Summary}{section.1.8}{}}
-\@writefile{toc}{\contentsline {section}{\numberline {1.9}Suggested reading}{48}{section.1.9}\protected@file@percent }
-\newlabel{suggested-reading}{{1.9}{48}{Suggested reading}{section.1.9}{}}
-\bibdata{book.bib}
-\gdef \@abspage@last{66}

---FILE: _bookdown_files/banana-book.lof---
@@ -1,3 +0,0 @@
-\addvspace {10\p@ }
-\contentsline {figure}{\numberline {1.1}{\ignorespaces Logo of the NIMBLE R package designed by Luke Larson. **Ask Perry for context and meaning.**\relax }}{6}{figure.caption.15}%
-\contentsline {figure}{\numberline {1.2}{\ignorespaces Trace plots for different values of the standard deviation (scale) of the proposal distribution.\relax }}{39}{figure.caption.16}%

---FILE: _bookdown_files/banana-book.log---
@@ -1,1762 +0,0 @@
-This is XeTeX, Version 3.141592653-2.6-0.999993 (MiKTeX 22.1) (preloaded format=xelatex 2023.4.26)  26 APR 2023 13:25
-entering extended mode
- restricted \write18 enabled.
- %&-line parsing enabled.
-**./banana-book.tex
-(banana-book.tex
-LaTeX2e <2022-11-01> patch level 1
-L3 programming layer <2023-03-30> (krantz.cls
-Document Class: krantz 2005/09/16 v1.4f Standard LaTeX document class
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/base/bk12.clo
-File: bk12.clo 2022/07/02 v1.4n Standard LaTeX file (size option)
-)
-\trimheight=\dimen140
-\trimwidth=\dimen141
-\normaltextheight=\dimen142
-\tempa=\dimen143
-\tempdimen=\dimen144
-\htrim=\dimen145
-\vtrimtop=\dimen146
-\vtrimbot=\dimen147
-\ul@box=\box51
-\ur@box=\box52
-\ll@box=\box53
-\lr@box=\box54
-\@cipboxa=\box55
-\@cipboxb=\box56
-\@ciprulewidth=\dimen148
-\c@part=\count181
-\c@chapter=\count182
-\c@section=\count183
-\c@subsection=\count184
-\c@subsubsection=\count185
-\c@paragraph=\count186
-\c@subparagraph=\count187
-\secwd=\dimen149
-\subsecwd=\dimen150
-\subsubsecwd=\dimen151
-\c@figure=\count188
-\c@table=\count189
-\abovecaptionskip=\skip48
-\belowcaptionskip=\skip49
-\c@numauthors=\count190
-\section@toc@skip=\skip50
-\SectionTOCWidth=\skip51
-\subsection@toc@skip=\skip52
-\SubSectionTOCWidth=\skip53
-\subsubsection@toc@skip=\skip54
-\SubSubSectionTOCWidth=\skip55
-\paragraph@toc@skip=\skip56
-\ParagraphTOCWidth=\skip57
-\subparagraph@toc@skip=\skip58
-\@AUonebox=\box57
-\@AUtwobox=\box58
-\@AUthreebox=\box59
-\@AUfourbox=\box60
-\@AUaffonebox=\box61
-\@AUafftwobox=\box62
-\@AUaffthreebox=\box63
-\@AUafffourbox=\box64
-\@finalAUboxfromone=\box65
-\@finalAUboxfromtwo=\box66
-\@finalAUboxfromthree=\box67
-\@finalAUboxfromfour=\box68
-\c@chaptocdepth=\count191
-\bibindent=\dimen152
-\tempbox=\box69
-\nomenwidth=\dimen153
-\@tablebox=\box70
-\@tabletitlebox=\box71
-\@tablewidth=\dimen154
-\@tabletitlewidth=\dimen155
-\max@tablewidth=\dimen156
-\tempbox=\box72
-\tempdimen=\dimen157
-\tempbox=\box73
-\notewidth=\dimen158
-\wherebox=\box74
-\wherewidth=\dimen159
-\listtextleftmargin=\skip59
-\listtextleftmarginii=\skip60
-\listtextleftmarginiii=\skip61
-\listtextrightmargin=\skip62
-\listlabelleftskip=\skip63
-\listlabelleftskipii=\skip64
-\listlabelleftskipiii=\skip65
-\abovelistskipi=\skip66
-\belowlistskipi=\skip67
-\abovelistskipii=\skip68
-\belowlistskipii=\skip69
-\abovelistskipiii=\skip70
-\belowlistskipiii=\skip71
-\labelsepi=\skip72
-\labelsepii=\skip73
-\labelsepiii=\skip74
-\itemsepi=\skip75
-\itemsepii=\skip76
-\itemsepiii=\skip77
-\enumdimwd=\dimen160
-\enumdim=\dimen161
-\concolwidth=\dimen162
-\stempbox=\box75
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/amsmath/amsmath.sty
-Package: amsmath 2022/04/08 v2.17n AMS math features
-\@mathmargin=\skip78
-
-For additional information on amsmath, use the `?' option.
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/amsmath/amstext.sty
-Package: amstext 2021/08/26 v2.01 AMS text
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/amsmath/amsgen.sty
-File: amsgen.sty 1999/11/30 v2.0 generic functions
-\@emptytoks=\toks16
-\ex@=\dimen163
-))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/amsmath/amsbsy.sty
-Package: amsbsy 1999/11/29 v1.2d Bold Symbols
-\pmbraise@=\dimen164
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/amsmath/amsopn.sty
-Package: amsopn 2022/04/08 v2.04 operator names
-)
-\inf@bad=\count192
-LaTeX Info: Redefining \frac on input line 234.
-\uproot@=\count193
-\leftroot@=\count194
-LaTeX Info: Redefining \overline on input line 399.
-LaTeX Info: Redefining \colon on input line 410.
-\classnum@=\count195
-\DOTSCASE@=\count196
-LaTeX Info: Redefining \ldots on input line 496.
-LaTeX Info: Redefining \dots on input line 499.
-LaTeX Info: Redefining \cdots on input line 620.
-\Mathstrutbox@=\box76
-\strutbox@=\box77
-LaTeX Info: Redefining \big on input line 722.
-LaTeX Info: Redefining \Big on input line 723.
-LaTeX Info: Redefining \bigg on input line 724.
-LaTeX Info: Redefining \Bigg on input line 725.
-\big@size=\dimen165
-LaTeX Font Info:    Redeclaring font encoding OML on input line 743.
-LaTeX Font Info:    Redeclaring font encoding OMS on input line 744.
-\macc@depth=\count197
-LaTeX Info: Redefining \bmod on input line 905.
-LaTeX Info: Redefining \pmod on input line 910.
-LaTeX Info: Redefining \smash on input line 940.
-LaTeX Info: Redefining \relbar on input line 970.
-LaTeX Info: Redefining \Relbar on input line 971.
-\c@MaxMatrixCols=\count198
-\dotsspace@=\muskip16
-\c@parentequation=\count199
-\dspbrk@lvl=\count266
-\tag@help=\toks17
-\row@=\count267
-\column@=\count268
-\maxfields@=\count269
-\andhelp@=\toks18
-\eqnshift@=\dimen166
-\alignsep@=\dimen167
-\tagshift@=\dimen168
-\tagwidth@=\dimen169
-\totwidth@=\dimen170
-\lineht@=\dimen171
-\@envbody=\toks19
-\multlinegap=\skip79
-\multlinetaggap=\skip80
-\mathdisplay@stack=\toks20
-LaTeX Info: Redefining \[ on input line 2953.
-LaTeX Info: Redefining \] on input line 2954.
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/amsfonts/amssymb.sty
-Package: amssymb 2013/01/14 v3.01 AMS font symbols
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/amsfonts/amsfonts.sty
-Package: amsfonts 2013/01/14 v3.01 Basic AMSFonts support
-\symAMSa=\mathgroup4
-\symAMSb=\mathgroup5
-LaTeX Font Info:    Redeclaring math symbol \hbar on input line 98.
-LaTeX Font Info:    Overwriting math alphabet `\mathfrak' in version `bold'
-(Font)                  U/euf/m/n --> U/euf/b/n on input line 106.
-))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/lm/lmodern.sty
-Package: lmodern 2015/05/01 v1.6.1 Latin Modern Fonts
-LaTeX Font Info:    Overwriting symbol font `operators' in version `normal'
-(Font)                  OT1/cmr/m/n --> OT1/lmr/m/n on input line 22.
-LaTeX Font Info:    Overwriting symbol font `letters' in version `normal'
-(Font)                  OML/cmm/m/it --> OML/lmm/m/it on input line 23.
-LaTeX Font Info:    Overwriting symbol font `symbols' in version `normal'
-(Font)                  OMS/cmsy/m/n --> OMS/lmsy/m/n on input line 24.
-LaTeX Font Info:    Overwriting symbol font `largesymbols' in version `normal'
-(Font)                  OMX/cmex/m/n --> OMX/lmex/m/n on input line 25.
-LaTeX Font Info:    Overwriting symbol font `operators' in version `bold'
-(Font)                  OT1/cmr/bx/n --> OT1/lmr/bx/n on input line 26.
-LaTeX Font Info:    Overwriting symbol font `letters' in version `bold'
-(Font)                  OML/cmm/b/it --> OML/lmm/b/it on input line 27.
-LaTeX Font Info:    Overwriting symbol font `symbols' in version `bold'
-(Font)                  OMS/cmsy/b/n --> OMS/lmsy/b/n on input line 28.
-LaTeX Font Info:    Overwriting symbol font `largesymbols' in version `bold'
-(Font)                  OMX/cmex/m/n --> OMX/lmex/m/n on input line 29.
-LaTeX Font Info:    Overwriting math alphabet `\mathbf' in version `normal'
-(Font)                  OT1/cmr/bx/n --> OT1/lmr/bx/n on input line 31.
-LaTeX Font Info:    Overwriting math alphabet `\mathsf' in version `normal'
-(Font)                  OT1/cmss/m/n --> OT1/lmss/m/n on input line 32.
-LaTeX Font Info:    Overwriting math alphabet `\mathit' in version `normal'
-(Font)                  OT1/cmr/m/it --> OT1/lmr/m/it on input line 33.
-LaTeX Font Info:    Overwriting math alphabet `\mathtt' in version `normal'
-(Font)                  OT1/cmtt/m/n --> OT1/lmtt/m/n on input line 34.
-LaTeX Font Info:    Overwriting math alphabet `\mathbf' in version `bold'
-(Font)                  OT1/cmr/bx/n --> OT1/lmr/bx/n on input line 35.
-LaTeX Font Info:    Overwriting math alphabet `\mathsf' in version `bold'
-(Font)                  OT1/cmss/bx/n --> OT1/lmss/bx/n on input line 36.
-LaTeX Font Info:    Overwriting math alphabet `\mathit' in version `bold'
-(Font)                  OT1/cmr/bx/it --> OT1/lmr/bx/it on input line 37.
-LaTeX Font Info:    Overwriting math alphabet `\mathtt' in version `bold'
-(Font)                  OT1/cmtt/m/n --> OT1/lmtt/m/n on input line 38.
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/iftex/iftex.sty
-Package: iftex 2022/02/03 v1.0f TeX engine tests
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/unicode-math/unicode-math.sty
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/l3kernel/expl3.sty
-Package: expl3 2023-03-30 L3 programming layer (loader) 
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/l3backend/l3backend-xetex.def
-File: l3backend-xetex.def 2023-03-30 L3 backend support: XeTeX
-\g__graphics_track_int=\count270
-\l__pdf_internal_box=\box78
-\g__pdf_backend_object_int=\count271
-\g__pdf_backend_annotation_int=\count272
-\g__pdf_backend_link_int=\count273
-))
-Package: unicode-math 2020/01/31 v0.8q Unicode maths in XeLaTeX and LuaLaTeX
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/unicode-math/unicode-math-xetex.sty
-Package: unicode-math-xetex 2020/01/31 v0.8q Unicode maths in XeLaTeX and LuaLa
-TeX
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/l3packages/xparse/xparse.sty
-Package: xparse 2023-02-02 L3 Experimental document command parser
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/l3packages/l3keys2e/l3keys2e.sty
-Package: l3keys2e 2023-02-02 LaTeX2e option processing using LaTeX3 keys
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/fontspec/fontspec.sty
-Package: fontspec 2022/01/15 v2.8a Font selection for XeLaTeX and LuaLaTeX
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/fontspec/fontspec-xetex.sty
-Package: fontspec-xetex 2022/01/15 v2.8a Font selection for XeLaTeX and LuaLaTe
-X
-\l__fontspec_script_int=\count274
-\l__fontspec_language_int=\count275
-\l__fontspec_strnum_int=\count276
-\l__fontspec_tmp_int=\count277
-\l__fontspec_tmpa_int=\count278
-\l__fontspec_tmpb_int=\count279
-\l__fontspec_tmpc_int=\count280
-\l__fontspec_em_int=\count281
-\l__fontspec_emdef_int=\count282
-\l__fontspec_strong_int=\count283
-\l__fontspec_strongdef_int=\count284
-\l__fontspec_tmpa_dim=\dimen172
-\l__fontspec_tmpb_dim=\dimen173
-\l__fontspec_tmpc_dim=\dimen174
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/base/fontenc.sty
-Package: fontenc 2021/04/29 v2.0v Standard LaTeX package
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/fontspec/fontspec.cfg)))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/base/fix-cm.sty
-Package: fix-cm 2020/11/24 v1.1t fixes to LaTeX
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/base/ts1enc.def
-File: ts1enc.def 2001/06/05 v3.0e (jk/car/fm) Standard LaTeX file
-LaTeX Font Info:    Redeclaring font encoding TS1 on input line 47.
-))
-\g__um_fam_int=\count285
-\g__um_fonts_used_int=\count286
-\l__um_primecount_int=\count287
-\g__um_primekern_muskip=\muskip17
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/unicode-math/unicode-math-table.tex)))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/upquote/upquote.sty
-Package: upquote 2012/04/19 v1.3 upright-quote and grave-accent glyphs in verba
-tim
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/base/textcomp.sty
-Package: textcomp 2020/02/02 v2.0n Standard LaTeX package
-))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/microtype/microtype.sty
-Package: microtype 2023/03/13 v3.1a Micro-typographical refinements (RS)
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/graphics/keyval.sty
-Package: keyval 2022/05/29 v1.15 key=value parser (DPC)
-\KV@toks@=\toks21
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/etoolbox/etoolbox.sty
-Package: etoolbox 2020/10/05 v2.5k e-TeX tools for LaTeX (JAW)
-\etb@tempcnta=\count288
-)
-\MT@toks=\toks22
-\MT@tempbox=\box79
-\MT@count=\count289
-LaTeX Info: Redefining \noprotrusionifhmode on input line 1059.
-LaTeX Info: Redefining \leftprotrusion on input line 1060.
-\MT@prot@toks=\toks23
-LaTeX Info: Redefining \rightprotrusion on input line 1078.
-LaTeX Info: Redefining \textls on input line 1368.
-\MT@outer@kern=\dimen175
-LaTeX Info: Redefining \textmicrotypecontext on input line 1988.
-\MT@listname@count=\count290
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/microtype/microtype-xetex.def
-File: microtype-xetex.def 2023/03/13 v3.1a Definitions specific to xetex (RS)
-LaTeX Info: Redefining \lsstyle on input line 238.
-)
-Package microtype Info: Loading configuration file microtype.cfg.
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/microtype/microtype.cfg
-File: microtype.cfg 2023/03/13 v3.1a microtype main configuration file (RS)
-))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/parskip/parskip.sty
-Package: parskip 2021-03-14 v2.0h non-zero parskip adjustments
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/kvoptions/kvoptions.sty
-Package: kvoptions 2022-06-15 v3.15 Key value format for package options (HO)
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/ltxcmds/ltxcmds.sty
-Package: ltxcmds 2020-05-10 v1.25 LaTeX kernel commands for general use (HO)
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/kvsetkeys/kvsetkeys.sty
-Package: kvsetkeys 2022-10-05 v1.19 Key value parser (HO)
-)))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/xcolor/xcolor.sty
-Package: xcolor 2022/06/12 v2.14 LaTeX color extensions (UK)
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/graphics-cfg/color.cfg
-File: color.cfg 2016/01/02 v1.6 sample color configuration
-)
-Package xcolor Info: Driver file: xetex.def on input line 227.
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/graphics-def/xetex.def
-File: xetex.def 2022/09/22 v5.0n Graphics/color driver for xetex
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/graphics/mathcolor.ltx)
-Package xcolor Info: Model `cmy' substituted by `cmy0' on input line 1353.
-Package xcolor Info: Model `RGB' extended on input line 1369.
-Package xcolor Info: Model `HTML' substituted by `rgb' on input line 1371.
-Package xcolor Info: Model `Hsb' substituted by `hsb' on input line 1372.
-Package xcolor Info: Model `tHsb' substituted by `hsb' on input line 1373.
-Package xcolor Info: Model `HSB' substituted by `hsb' on input line 1374.
-Package xcolor Info: Model `Gray' substituted by `gray' on input line 1375.
-Package xcolor Info: Model `wave' substituted by `hsb' on input line 1376.
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/graphics/dvipsnam.def
-File: dvipsnam.def 2016/06/17 v3.0m Driver-dependent file (DPC,SPQR)
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/xcolor/svgnam.def
-File: svgnam.def 2022/06/12 v2.14 Predefined colors according to SVG 1.1 (UK)
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/xcolor/x11nam.def
-File: x11nam.def 2022/06/12 v2.14 Predefined colors according to Unix/X11 (UK)
-))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/fancyvrb/fancyvrb.sty
-Package: fancyvrb 2023/01/19 4.5a verbatim text (tvz,hv)
-\FV@CodeLineNo=\count291
-\FV@InFile=\read2
-\FV@TabBox=\box80
-\c@FancyVerbLine=\count292
-\FV@StepNumber=\count293
-\FV@OutFile=\write3
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/framed/framed.sty
-Package: framed 2011/10/22 v 0.96: framed or shaded text with page breaks
-\OuterFrameSep=\skip81
-\fb@frw=\dimen176
-\fb@frh=\dimen177
-\FrameRule=\dimen178
-\FrameSep=\dimen179
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/tools/longtable.sty
-Package: longtable 2021-09-01 v4.17 Multi-page Table package (DPC)
-\LTleft=\skip82
-\LTright=\skip83
-\LTpre=\skip84
-\LTpost=\skip85
-\LTchunksize=\count294
-\LTcapwidth=\dimen180
-\LT@head=\box81
-\LT@firsthead=\box82
-\LT@foot=\box83
-\LT@lastfoot=\box84
-\LT@gbox=\box85
-\LT@cols=\count295
-\LT@rows=\count296
-\c@LT@tables=\count297
-\c@LT@chunks=\count298
-\LT@p@ftn=\toks24
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/booktabs/booktabs.sty
-Package: booktabs 2020/01/12 v1.61803398 Publication quality tables
-\heavyrulewidth=\dimen181
-\lightrulewidth=\dimen182
-\cmidrulewidth=\dimen183
-\belowrulesep=\dimen184
-\belowbottomsep=\dimen185
-\aboverulesep=\dimen186
-\abovetopsep=\dimen187
-\cmidrulesep=\dimen188
-\cmidrulekern=\dimen189
-\defaultaddspace=\dimen190
-\@cmidla=\count299
-\@cmidlb=\count300
-\@aboverulesep=\dimen191
-\@belowrulesep=\dimen192
-\@thisruleclass=\count301
-\@lastruleclass=\count302
-\@thisrulewidth=\dimen193
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/tools/array.sty
-Package: array 2022/09/04 v2.5g Tabular extension package (FMi)
-\col@sep=\dimen194
-\ar@mcellbox=\box86
-\extrarowheight=\dimen195
-\NC@list=\toks25
-\extratabsurround=\skip86
-\backup@length=\skip87
-\ar@cellbox=\box87
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/tools/calc.sty
-Package: calc 2017/05/25 v4.3 Infix arithmetic (KKT,FJ)
-\calc@Acount=\count303
-\calc@Bcount=\count304
-\calc@Adimen=\dimen196
-\calc@Bdimen=\dimen197
-\calc@Askip=\skip88
-\calc@Bskip=\skip89
-LaTeX Info: Redefining \setlength on input line 80.
-LaTeX Info: Redefining \addtolength on input line 81.
-\calc@Ccount=\count305
-\calc@Cskip=\skip90
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/footnotehyper/footnotehyper.sty
-Package: footnotehyper 2021/08/13 v1.1e hyperref aware footnote.sty (JFB)
-\FNH@notes=\box88
-\FNH@width=\dimen198
-\FNH@toks=\toks26
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/graphics/graphicx.sty
-Package: graphicx 2021/09/16 v1.2d Enhanced LaTeX Graphics (DPC,SPQR)
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/graphics/graphics.sty
-Package: graphics 2022/03/10 v1.4e Standard LaTeX Graphics (DPC,SPQR)
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/graphics/trig.sty
-Package: trig 2021/08/11 v1.11 sin cos tan (DPC)
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/graphics-cfg/graphics.cfg
-File: graphics.cfg 2016/06/04 v1.11 sample graphics configuration
-)
-Package graphics Info: Driver file: xetex.def on input line 107.
-)
-\Gin@req@height=\dimen199
-\Gin@req@width=\dimen256
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/hyperref/hyperref.sty
-Package: hyperref 2023-02-07 v7.00v Hypertext links for LaTeX
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pdftexcmds/pdftexcmds.sty
-Package: pdftexcmds 2020-06-27 v0.33 Utility functions of pdfTeX for LuaTeX (HO
-)
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/infwarerr/infwarerr.sty
-Package: infwarerr 2019/12/03 v1.5 Providing info/warning/error messages (HO)
-)
-Package pdftexcmds Info: \pdf@primitive is available.
-Package pdftexcmds Info: \pdf@ifprimitive is available.
-Package pdftexcmds Info: \pdfdraftmode not found.
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/kvdefinekeys/kvdefinekeys.sty
-Package: kvdefinekeys 2019-12-19 v1.6 Define keys (HO)
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pdfescape/pdfescape.sty
-Package: pdfescape 2019/12/09 v1.15 Implements pdfTeX's escape features (HO)
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/hycolor/hycolor.sty
-Package: hycolor 2020-01-27 v1.10 Color options for hyperref/bookmark (HO)
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/letltxmacro/letltxmacro.sty
-Package: letltxmacro 2019/12/03 v1.6 Let assignment for LaTeX macros (HO)
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/auxhook/auxhook.sty
-Package: auxhook 2019-12-17 v1.6 Hooks for auxiliary files (HO)
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/hyperref/nameref.sty
-Package: nameref 2022-05-17 v2.50 Cross-referencing by name of section
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/refcount/refcount.sty
-Package: refcount 2019/12/15 v3.6 Data extraction from label references (HO)
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/gettitlestring/gettitlestring.sty
-Package: gettitlestring 2019/12/15 v1.6 Cleanup title references (HO)
-)
-\c@section@level=\count306
-)
-\@linkdim=\dimen257
-\Hy@linkcounter=\count307
-\Hy@pagecounter=\count308
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/hyperref/pd1enc.def
-File: pd1enc.def 2023-02-07 v7.00v Hyperref: PDFDocEncoding definition (HO)
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/intcalc/intcalc.sty
-Package: intcalc 2019/12/15 v1.3 Expandable calculations with integers (HO)
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/etexcmds/etexcmds.sty
-Package: etexcmds 2019/12/15 v1.7 Avoid name clashes with e-TeX commands (HO)
-)
-\Hy@SavedSpaceFactor=\count309
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/hyperref/puenc.def
-File: puenc.def 2023-02-07 v7.00v Hyperref: PDF Unicode definition (HO)
-)
-Package hyperref Info: Option `unicode' set `true' on input line 4060.
-Package hyperref Info: Hyper figures OFF on input line 4177.
-Package hyperref Info: Link nesting OFF on input line 4182.
-Package hyperref Info: Hyper index ON on input line 4185.
-Package hyperref Info: Plain pages OFF on input line 4192.
-Package hyperref Info: Backreferencing OFF on input line 4197.
-Package hyperref Info: Implicit mode ON; LaTeX internals redefined.
-Package hyperref Info: Bookmarks ON on input line 4425.
-\c@Hy@tempcnt=\count310
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/url/url.sty
-\Urlmuskip=\muskip18
-Package: url 2013/09/16  ver 3.4  Verb mode for urls, etc.
-)
-LaTeX Info: Redefining \url on input line 4763.
-\XeTeXLinkMargin=\dimen258
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/bitset/bitset.sty
-Package: bitset 2019/12/09 v1.3 Handle bit-vector datatype (HO)
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/bigintcalc/bigintcalc.sty
-Package: bigintcalc 2019/12/15 v1.5 Expandable calculations on big integers (HO
-)
-))
-\Fld@menulength=\count311
-\Field@Width=\dimen259
-\Fld@charsize=\dimen260
-Package hyperref Info: Hyper figures OFF on input line 6042.
-Package hyperref Info: Link nesting OFF on input line 6047.
-Package hyperref Info: Hyper index ON on input line 6050.
-Package hyperref Info: backreferencing OFF on input line 6057.
-Package hyperref Info: Link coloring OFF on input line 6062.
-Package hyperref Info: Link coloring with OCG OFF on input line 6067.
-Package hyperref Info: PDF/A mode OFF on input line 6072.
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/base/atbegshi-ltx.sty
-Package: atbegshi-ltx 2021/01/10 v1.0c Emulation of the original atbegshi
-package with kernel methods
-)
-\Hy@abspage=\count312
-\c@Item=\count313
-\c@Hfootnote=\count314
-)
-Package hyperref Info: Driver (autodetected): hxetex.
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/hyperref/hxetex.def
-File: hxetex.def 2023-02-07 v7.00v Hyperref driver for XeTeX
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/stringenc/stringenc.sty
-Package: stringenc 2019/11/29 v1.12 Convert strings between diff. encodings (HO
-)
-)
-\pdfm@box=\box89
-\c@Hy@AnnotLevel=\count315
-\HyField@AnnotCount=\count316
-\Fld@listcount=\count317
-\c@bookmark@seq@number=\count318
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/rerunfilecheck/rerunfilecheck.sty
-Package: rerunfilecheck 2022-07-10 v1.10 Rerun checks for auxiliary files (HO)
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/base/atveryend-ltx.sty
-Package: atveryend-ltx 2020/08/19 v1.0a Emulation of the original atveryend pac
-kage
-with kernel methods
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/uniquecounter/uniquecounter.sty
-Package: uniquecounter 2019/12/15 v1.4 Provide unlimited unique counter (HO)
-)
-Package uniquecounter Info: New unique counter `rerunfilecheck' on input line 2
-85.
-)
-\Hy@SectionHShift=\skip91
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/caption/caption.sty
-Package: caption 2023/03/12 v3.6j Customizing captions (AR)
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/caption/caption3.sty
-Package: caption3 2023/03/12 v2.4 caption3 kernel (AR)
-\caption@tempdima=\dimen261
-\captionmargin=\dimen262
-\caption@leftmargin=\dimen263
-\caption@rightmargin=\dimen264
-\caption@width=\dimen265
-\caption@indent=\dimen266
-\caption@parindent=\dimen267
-\caption@hangindent=\dimen268
-Package caption Info: Unknown document class (or package),
-(caption)             standard defaults will be used.
-Package caption Info: \@makecaption = \long macro:#1#2->\vskip \abovecaptionski
-p \sbox \@tempboxa {#1: #2}\ifdim \wd \@tempboxa >\hsize {\FigCapFont #1} #2\pa
-r \else \global \@minipagefalse {\FigCapFont #1} #2\par \fi \vskip \belowcaptio
-nskip  on input line 1176.
-)
-
-Package caption Warning: Unknown document class (or package),
-(caption)                standard defaults will be used.
-See the caption package documentation for explanation.
-
-\c@caption@flags=\count319
-\c@continuedfloat=\count320
-Package caption Info: hyperref package is loaded.
-Package caption Info: longtable package is loaded.
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/caption/ltcaption.sty
-Package: ltcaption 2021/01/08 v1.4c longtable captions (AR)
-))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/alegreya/Alegreya.sty
-Package: Alegreya 2022/09/14 (Bob Tennent) Supports Alegreya and AlegreyaSC fon
-ts for all LaTeX engines. 
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/iftex/ifxetex.sty
-Package: ifxetex 2019/10/25 v0.7 ifxetex legacy package. Use iftex instead.
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/iftex/ifluatex.sty
-Package: ifluatex 2019/10/25 v1.5 ifluatex legacy package. Use iftex instead.
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/xkeyval/xkeyval.sty
-Package: xkeyval 2022/06/16 v2.9 package option processing (HA)
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/xkeyval/xkeyval.tex
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/xkeyval/xkvutils.tex
-\XKV@toks=\toks27
-\XKV@tempa@toks=\toks28
-)
-\XKV@depth=\count321
-File: xkeyval.tex 2014/12/03 v2.7a key=value parser (HA)
-))
-
-Package fontspec Info: Font family 'Alegreya(0)' created for font 'Alegreya'
-(fontspec)             with options [Ligatures = TeX,Extension = .otf,Scale =
-(fontspec)             1,Ligatures=TeX,Scale=1,Numbers =
-(fontspec)             {Proportional,Lining},UprightFont =
-(fontspec)             *-Regular,ItalicFont = *-Italic,BoldFont =
-(fontspec)             *-Bold,BoldItalicFont = *-BoldItalic].
-(fontspec)              
-(fontspec)              This font family consists of the following NFSS
-(fontspec)             series/shapes:
-(fontspec)              
-(fontspec)             - 'normal' (m/n) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Regular.otf]/OT:script=latn;language=
-dflt;+pnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'small caps'  (m/sc) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Regular.otf]/OT:script=latn;language=
-dflt;+pnum;+lnum;+smcp;mapping=tex-text;""
-(fontspec)             - 'bold' (b/n) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Bold.otf]/OT:script=latn;language=dfl
-t;+pnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'bold small caps'  (b/sc) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Bold.otf]/OT:script=latn;language=dfl
-t;+pnum;+lnum;+smcp;mapping=tex-text;""
-(fontspec)             - 'italic' (m/it) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Italic.otf]/OT:script=latn;language=d
-flt;+pnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'italic small caps'  (m/scit) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Italic.otf]/OT:script=latn;language=d
-flt;+pnum;+lnum;+smcp;mapping=tex-text;""
-(fontspec)             - 'bold italic' (b/it) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-BoldItalic.otf]/OT:script=latn;langua
-ge=dflt;+pnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'bold italic small caps'  (b/scit) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-BoldItalic.otf]/OT:script=latn;langua
-ge=dflt;+pnum;+lnum;+smcp;mapping=tex-text;""
-
-
-Package fontspec Info: Font family 'Alegreya(1)' created for font 'Alegreya'
-(fontspec)             with options [Ligatures = TeX,Extension = .otf,Scale =
-(fontspec)             1,Numbers = {Proportional,Lining},UprightFont =
-(fontspec)             *-Regular,ItalicFont = *-Italic,BoldFont =
-(fontspec)             *-Bold,BoldItalicFont = *-BoldItalic].
-(fontspec)              
-(fontspec)              This font family consists of the following NFSS
-(fontspec)             series/shapes:
-(fontspec)              
-(fontspec)             - 'normal' (m/n) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Regular.otf]/OT:script=latn;language=
-dflt;+pnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'small caps'  (m/sc) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Regular.otf]/OT:script=latn;language=
-dflt;+pnum;+lnum;+smcp;mapping=tex-text;""
-(fontspec)             - 'bold' (b/n) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Bold.otf]/OT:script=latn;language=dfl
-t;+pnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'bold small caps'  (b/sc) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Bold.otf]/OT:script=latn;language=dfl
-t;+pnum;+lnum;+smcp;mapping=tex-text;""
-(fontspec)             - 'italic' (m/it) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Italic.otf]/OT:script=latn;language=d
-flt;+pnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'italic small caps'  (m/scit) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Italic.otf]/OT:script=latn;language=d
-flt;+pnum;+lnum;+smcp;mapping=tex-text;""
-(fontspec)             - 'bold italic' (b/it) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-BoldItalic.otf]/OT:script=latn;langua
-ge=dflt;+pnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'bold italic small caps'  (b/scit) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-BoldItalic.otf]/OT:script=latn;langua
-ge=dflt;+pnum;+lnum;+smcp;mapping=tex-text;""
-
-LaTeX Font Info:    Overwriting math alphabet `\mathrm' in version `normal'
-(Font)                  OT1/lmr/m/n --> TU/Alegreya(1)/m/n on input line 168.
-LaTeX Font Info:    Overwriting math alphabet `\mathit' in version `normal'
-(Font)                  OT1/lmr/m/it --> TU/Alegreya(1)/m/it on input line 168.
-
-LaTeX Font Info:    Overwriting math alphabet `\mathbf' in version `normal'
-(Font)                  OT1/lmr/bx/n --> TU/Alegreya(1)/b/n on input line 168.
-LaTeX Font Info:    Font shape `TU/Alegreya(0)/m/n' will be
-(Font)              scaled to size 12.0pt on input line 168.
-
-Package fontspec Info: Font family 'Alegreya(2)' created for font 'Alegreya'
-(fontspec)             with options [Ligatures = TeX,Extension = .otf,Scale =
-(fontspec)             1,Numbers = {Proportional,OldStyle},UprightFont =
-(fontspec)             *-Regular,ItalicFont = *-Italic,BoldFont =
-(fontspec)             *-Bold,BoldItalicFont = *-BoldItalic].
-(fontspec)              
-(fontspec)              This font family consists of the following NFSS
-(fontspec)             series/shapes:
-(fontspec)              
-(fontspec)             - 'normal' (m/n) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Regular.otf]/OT:script=latn;language=
-dflt;+pnum;+onum;mapping=tex-text;""
-(fontspec)             - 'small caps'  (m/sc) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Regular.otf]/OT:script=latn;language=
-dflt;+pnum;+onum;+smcp;mapping=tex-text;""
-(fontspec)             - 'bold' (b/n) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Bold.otf]/OT:script=latn;language=dfl
-t;+pnum;+onum;mapping=tex-text;""
-(fontspec)             - 'bold small caps'  (b/sc) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Bold.otf]/OT:script=latn;language=dfl
-t;+pnum;+onum;+smcp;mapping=tex-text;""
-(fontspec)             - 'italic' (m/it) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Italic.otf]/OT:script=latn;language=d
-flt;+pnum;+onum;mapping=tex-text;""
-(fontspec)             - 'italic small caps'  (m/scit) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Italic.otf]/OT:script=latn;language=d
-flt;+pnum;+onum;+smcp;mapping=tex-text;""
-(fontspec)             - 'bold italic' (b/it) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-BoldItalic.otf]/OT:script=latn;langua
-ge=dflt;+pnum;+onum;mapping=tex-text;""
-(fontspec)             - 'bold italic small caps'  (b/scit) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-BoldItalic.otf]/OT:script=latn;langua
-ge=dflt;+pnum;+onum;+smcp;mapping=tex-text;""
-
-
-Package fontspec Info: Font family 'Alegreya(3)' created for font 'Alegreya'
-(fontspec)             with options [Ligatures = TeX,Extension = .otf,Scale =
-(fontspec)             1,Numbers = {Monospaced,OldStyle},UprightFont =
-(fontspec)             *-Regular,ItalicFont = *-Italic,BoldFont =
-(fontspec)             *-Bold,BoldItalicFont = *-BoldItalic].
-(fontspec)              
-(fontspec)              This font family consists of the following NFSS
-(fontspec)             series/shapes:
-(fontspec)              
-(fontspec)             - 'normal' (m/n) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Regular.otf]/OT:script=latn;language=
-dflt;+tnum;+onum;mapping=tex-text;""
-(fontspec)             - 'small caps'  (m/sc) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Regular.otf]/OT:script=latn;language=
-dflt;+tnum;+onum;+smcp;mapping=tex-text;""
-(fontspec)             - 'bold' (b/n) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Bold.otf]/OT:script=latn;language=dfl
-t;+tnum;+onum;mapping=tex-text;""
-(fontspec)             - 'bold small caps'  (b/sc) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Bold.otf]/OT:script=latn;language=dfl
-t;+tnum;+onum;+smcp;mapping=tex-text;""
-(fontspec)             - 'italic' (m/it) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Italic.otf]/OT:script=latn;language=d
-flt;+tnum;+onum;mapping=tex-text;""
-(fontspec)             - 'italic small caps'  (m/scit) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Italic.otf]/OT:script=latn;language=d
-flt;+tnum;+onum;+smcp;mapping=tex-text;""
-(fontspec)             - 'bold italic' (b/it) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-BoldItalic.otf]/OT:script=latn;langua
-ge=dflt;+tnum;+onum;mapping=tex-text;""
-(fontspec)             - 'bold italic small caps'  (b/scit) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-BoldItalic.otf]/OT:script=latn;langua
-ge=dflt;+tnum;+onum;+smcp;mapping=tex-text;""
-
-
-Package fontspec Info: Font family 'Alegreya(4)' created for font 'Alegreya'
-(fontspec)             with options [Ligatures = TeX,Extension = .otf,Scale =
-(fontspec)             1,Numbers = {Proportional, OldStyle},UprightFont =
-(fontspec)             *-Regular,ItalicFont = *-Italic,BoldFont =
-(fontspec)             *-Bold,BoldItalicFont = *-BoldItalic].
-(fontspec)              
-(fontspec)              This font family consists of the following NFSS
-(fontspec)             series/shapes:
-(fontspec)              
-(fontspec)             - 'normal' (m/n) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Regular.otf]/OT:script=latn;language=
-dflt;+pnum;+onum;mapping=tex-text;""
-(fontspec)             - 'small caps'  (m/sc) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Regular.otf]/OT:script=latn;language=
-dflt;+pnum;+onum;+smcp;mapping=tex-text;""
-(fontspec)             - 'bold' (b/n) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Bold.otf]/OT:script=latn;language=dfl
-t;+pnum;+onum;mapping=tex-text;""
-(fontspec)             - 'bold small caps'  (b/sc) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Bold.otf]/OT:script=latn;language=dfl
-t;+pnum;+onum;+smcp;mapping=tex-text;""
-(fontspec)             - 'italic' (m/it) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Italic.otf]/OT:script=latn;language=d
-flt;+pnum;+onum;mapping=tex-text;""
-(fontspec)             - 'italic small caps'  (m/scit) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Italic.otf]/OT:script=latn;language=d
-flt;+pnum;+onum;+smcp;mapping=tex-text;""
-(fontspec)             - 'bold italic' (b/it) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-BoldItalic.otf]/OT:script=latn;langua
-ge=dflt;+pnum;+onum;mapping=tex-text;""
-(fontspec)             - 'bold italic small caps'  (b/scit) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-BoldItalic.otf]/OT:script=latn;langua
-ge=dflt;+pnum;+onum;+smcp;mapping=tex-text;""
-
-
-Package fontspec Info: Font family 'Alegreya(5)' created for font 'Alegreya'
-(fontspec)             with options [Ligatures = TeX,Extension = .otf,Scale =
-(fontspec)             1,Numbers = {Monospaced,Lining},UprightFont =
-(fontspec)             *-Regular,ItalicFont = *-Italic,BoldFont =
-(fontspec)             *-Bold,BoldItalicFont = *-BoldItalic].
-(fontspec)              
-(fontspec)              This font family consists of the following NFSS
-(fontspec)             series/shapes:
-(fontspec)              
-(fontspec)             - 'normal' (m/n) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Regular.otf]/OT:script=latn;language=
-dflt;+tnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'small caps'  (m/sc) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Regular.otf]/OT:script=latn;language=
-dflt;+tnum;+lnum;+smcp;mapping=tex-text;""
-(fontspec)             - 'bold' (b/n) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Bold.otf]/OT:script=latn;language=dfl
-t;+tnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'bold small caps'  (b/sc) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Bold.otf]/OT:script=latn;language=dfl
-t;+tnum;+lnum;+smcp;mapping=tex-text;""
-(fontspec)             - 'italic' (m/it) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Italic.otf]/OT:script=latn;language=d
-flt;+tnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'italic small caps'  (m/scit) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Italic.otf]/OT:script=latn;language=d
-flt;+tnum;+lnum;+smcp;mapping=tex-text;""
-(fontspec)             - 'bold italic' (b/it) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-BoldItalic.otf]/OT:script=latn;langua
-ge=dflt;+tnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'bold italic small caps'  (b/scit) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-BoldItalic.otf]/OT:script=latn;langua
-ge=dflt;+tnum;+lnum;+smcp;mapping=tex-text;""
-
-
-Package fontspec Info: Font family 'Alegreya(6)' created for font 'Alegreya'
-(fontspec)             with options [Ligatures = TeX,Extension = .otf,Scale =
-(fontspec)             1,Numbers = {Proportional,Lining},UprightFont =
-(fontspec)             *-ExtraBold,ItalicFont = *-ExtraBoldItalic,BoldFont =
-(fontspec)             *-ExtraBold,BoldItalicFont = *-ExtraBoldItalic].
-(fontspec)              
-(fontspec)              This font family consists of the following NFSS
-(fontspec)             series/shapes:
-(fontspec)              
-(fontspec)             - 'normal' (m/n) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-ExtraBold.otf]/OT:script=latn;languag
-e=dflt;+pnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'small caps'  (m/sc) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-ExtraBold.otf]/OT:script=latn;languag
-e=dflt;+pnum;+lnum;+smcp;mapping=tex-text;""
-(fontspec)             - 'bold' (b/n) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-ExtraBold.otf]/OT:script=latn;languag
-e=dflt;+pnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'bold small caps'  (b/sc) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-ExtraBold.otf]/OT:script=latn;languag
-e=dflt;+pnum;+lnum;+smcp;mapping=tex-text;""
-(fontspec)             - 'italic' (m/it) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-ExtraBoldItalic.otf]/OT:script=latn;l
-anguage=dflt;+pnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'italic small caps'  (m/scit) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-ExtraBoldItalic.otf]/OT:script=latn;l
-anguage=dflt;+pnum;+lnum;+smcp;mapping=tex-text;""
-(fontspec)             - 'bold italic' (b/it) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-ExtraBoldItalic.otf]/OT:script=latn;l
-anguage=dflt;+pnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'bold italic small caps'  (b/scit) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-ExtraBoldItalic.otf]/OT:script=latn;l
-anguage=dflt;+pnum;+lnum;+smcp;mapping=tex-text;""
-
-
-Package fontspec Info: Font family 'Alegreya(7)' created for font 'Alegreya'
-(fontspec)             with options [Ligatures = TeX,Extension = .otf,Scale =
-(fontspec)             1,Numbers = {Proportional,Lining},UprightFont =
-(fontspec)             *-Black,ItalicFont = *-BlackItalic,BoldFont =
-(fontspec)             *-Black,BoldItalicFont = *-BlackItalic].
-(fontspec)              
-(fontspec)              This font family consists of the following NFSS
-(fontspec)             series/shapes:
-(fontspec)              
-(fontspec)             - 'normal' (m/n) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Black.otf]/OT:script=latn;language=df
-lt;+pnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'small caps'  (m/sc) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Black.otf]/OT:script=latn;language=df
-lt;+pnum;+lnum;+smcp;mapping=tex-text;""
-(fontspec)             - 'bold' (b/n) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Black.otf]/OT:script=latn;language=df
-lt;+pnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'bold small caps'  (b/sc) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Black.otf]/OT:script=latn;language=df
-lt;+pnum;+lnum;+smcp;mapping=tex-text;""
-(fontspec)             - 'italic' (m/it) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-BlackItalic.otf]/OT:script=latn;langu
-age=dflt;+pnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'italic small caps'  (m/scit) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-BlackItalic.otf]/OT:script=latn;langu
-age=dflt;+pnum;+lnum;+smcp;mapping=tex-text;""
-(fontspec)             - 'bold italic' (b/it) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-BlackItalic.otf]/OT:script=latn;langu
-age=dflt;+pnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'bold italic small caps'  (b/scit) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-BlackItalic.otf]/OT:script=latn;langu
-age=dflt;+pnum;+lnum;+smcp;mapping=tex-text;""
-
-
-Package fontspec Info: Font family 'Alegreya(8)' created for font 'Alegreya'
-(fontspec)             with options [Ligatures = TeX,Extension = .otf,Scale =
-(fontspec)             1,Numbers = {Proportional,Lining},UprightFont =
-(fontspec)             *-Medium,ItalicFont = *-MediumItalic,BoldFont =
-(fontspec)             *-Medium,BoldItalicFont = *-MediumItalic].
-(fontspec)              
-(fontspec)              This font family consists of the following NFSS
-(fontspec)             series/shapes:
-(fontspec)              
-(fontspec)             - 'normal' (m/n) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Medium.otf]/OT:script=latn;language=d
-flt;+pnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'small caps'  (m/sc) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Medium.otf]/OT:script=latn;language=d
-flt;+pnum;+lnum;+smcp;mapping=tex-text;""
-(fontspec)             - 'bold' (b/n) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Medium.otf]/OT:script=latn;language=d
-flt;+pnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'bold small caps'  (b/sc) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-Medium.otf]/OT:script=latn;language=d
-flt;+pnum;+lnum;+smcp;mapping=tex-text;""
-(fontspec)             - 'italic' (m/it) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-MediumItalic.otf]/OT:script=latn;lang
-uage=dflt;+pnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'italic small caps'  (m/scit) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-MediumItalic.otf]/OT:script=latn;lang
-uage=dflt;+pnum;+lnum;+smcp;mapping=tex-text;""
-(fontspec)             - 'bold italic' (b/it) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-MediumItalic.otf]/OT:script=latn;lang
-uage=dflt;+pnum;+lnum;mapping=tex-text;""
-(fontspec)             - 'bold italic small caps'  (b/scit) with NFSS spec.:
-(fontspec)             <->s*[1]""[Alegreya-MediumItalic.otf]/OT:script=latn;lang
-uage=dflt;+pnum;+lnum;+smcp;mapping=tex-text;""
-
-LaTeX Info: Redefining \textin on input line 293.
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/sourcecodepro/sourcecodepro.sty
-Package: sourcecodepro 2018/01/13 v2.7 Adobe's Source Code Pro typeface
-
-Package fontspec Info: Font family 'SourceCodePro(0)' created for font
-(fontspec)             'SourceCodePro' with options [Ligatures =,Numbers
-(fontspec)             =,Scale = .7,Extension =
-(fontspec)             .otf,WordSpace={1,0,0},HyphenChar=None,PunctuationSpace=
-WordSpace,UprightFont
-(fontspec)             = *-Regular,ItalicFont = *-RegularIt,BoldFont =
-(fontspec)             *-Bold,BoldItalicFont = *-BoldIt].
-(fontspec)              
-(fontspec)              This font family consists of the following NFSS
-(fontspec)             series/shapes:
-(fontspec)              
-(fontspec)             - 'normal' (m/n) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-Regular.otf]/OT:script=latn;lan
-guage=dflt;""
-(fontspec)             - 'small caps'  (m/sc) with NFSS spec.: 
-(fontspec)             and font adjustment code:
-(fontspec)             \fontdimen 2\font =1\fontdimen 2\font \fontdimen 3\font
-(fontspec)             =0\fontdimen 3\font \fontdimen 4\font =0\fontdimen
-(fontspec)             4\font \fontdimen 7\font =0\fontdimen 2\font
-(fontspec)             \tex_hyphenchar:D \font =-1\scan_stop: 
-(fontspec)             - 'bold' (b/n) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-Bold.otf]/OT:script=latn;langua
-ge=dflt;""
-(fontspec)             - 'bold small caps'  (b/sc) with NFSS spec.: 
-(fontspec)             and font adjustment code:
-(fontspec)             \fontdimen 2\font =1\fontdimen 2\font \fontdimen 3\font
-(fontspec)             =0\fontdimen 3\font \fontdimen 4\font =0\fontdimen
-(fontspec)             4\font \fontdimen 7\font =0\fontdimen 2\font
-(fontspec)             \tex_hyphenchar:D \font =-1\scan_stop: 
-(fontspec)             - 'italic' (m/it) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-RegularIt.otf]/OT:script=latn;l
-anguage=dflt;""
-(fontspec)             - 'italic small caps'  (m/scit) with NFSS spec.: 
-(fontspec)             and font adjustment code:
-(fontspec)             \fontdimen 2\font =1\fontdimen 2\font \fontdimen 3\font
-(fontspec)             =0\fontdimen 3\font \fontdimen 4\font =0\fontdimen
-(fontspec)             4\font \fontdimen 7\font =0\fontdimen 2\font
-(fontspec)             \tex_hyphenchar:D \font =-1\scan_stop: 
-(fontspec)             - 'bold italic' (b/it) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-BoldIt.otf]/OT:script=latn;lang
-uage=dflt;""
-(fontspec)             - 'bold italic small caps'  (b/scit) with NFSS spec.: 
-(fontspec)             and font adjustment code:
-(fontspec)             \fontdimen 2\font =1\fontdimen 2\font \fontdimen 3\font
-(fontspec)             =0\fontdimen 3\font \fontdimen 4\font =0\fontdimen
-(fontspec)             4\font \fontdimen 7\font =0\fontdimen 2\font
-(fontspec)             \tex_hyphenchar:D \font =-1\scan_stop: 
-
-
-Package fontspec Info: Font family 'SourceCodePro(1)' created for font
-(fontspec)             'SourceCodePro' with options [Ligatures =,Numbers
-(fontspec)             =,Scale = .7,Extension = .otf,UprightFont =
-(fontspec)             *-Regular,ItalicFont = *-RegularIt,BoldFont =
-(fontspec)             *-Bold,BoldItalicFont = *-BoldIt].
-(fontspec)              
-(fontspec)              This font family consists of the following NFSS
-(fontspec)             series/shapes:
-(fontspec)              
-(fontspec)             - 'normal' (m/n) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-Regular.otf]/OT:script=latn;lan
-guage=dflt;""
-(fontspec)             - 'small caps'  (m/sc) with NFSS spec.: 
-(fontspec)             - 'bold' (b/n) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-Bold.otf]/OT:script=latn;langua
-ge=dflt;""
-(fontspec)             - 'bold small caps'  (b/sc) with NFSS spec.: 
-(fontspec)             - 'italic' (m/it) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-RegularIt.otf]/OT:script=latn;l
-anguage=dflt;""
-(fontspec)             - 'italic small caps'  (m/scit) with NFSS spec.: 
-(fontspec)             - 'bold italic' (b/it) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-BoldIt.otf]/OT:script=latn;lang
-uage=dflt;""
-(fontspec)             - 'bold italic small caps'  (b/scit) with NFSS spec.: 
-
-LaTeX Font Info:    Overwriting math alphabet `\mathtt' in version `normal'
-(Font)                  OT1/lmtt/m/n --> TU/SourceCodePro(1)/m/n on input line 
-121.
-LaTeX Font Info:    Overwriting math alphabet `\mathtt' in version `bold'
-(Font)                  OT1/lmtt/m/n --> TU/SourceCodePro(1)/b/n on input line 
-121.
-
-Package fontspec Info: Font family 'SourceCodePro(2)' created for font
-(fontspec)             'SourceCodePro' with options [Ligatures =,Numbers
-(fontspec)             =,Scale = .7,Extension = .otf,UprightFont =
-(fontspec)             *-Medium,ItalicFont = *-MediumIt,BoldFont =
-(fontspec)             *-Bold,BoldItalicFont = *-BoldIt].
-(fontspec)              
-(fontspec)              This font family consists of the following NFSS
-(fontspec)             series/shapes:
-(fontspec)              
-(fontspec)             - 'normal' (m/n) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-Medium.otf]/OT:script=latn;lang
-uage=dflt;""
-(fontspec)             - 'small caps'  (m/sc) with NFSS spec.: 
-(fontspec)             - 'bold' (b/n) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-Bold.otf]/OT:script=latn;langua
-ge=dflt;""
-(fontspec)             - 'bold small caps'  (b/sc) with NFSS spec.: 
-(fontspec)             - 'italic' (m/it) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-MediumIt.otf]/OT:script=latn;la
-nguage=dflt;""
-(fontspec)             - 'italic small caps'  (m/scit) with NFSS spec.: 
-(fontspec)             - 'bold italic' (b/it) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-BoldIt.otf]/OT:script=latn;lang
-uage=dflt;""
-(fontspec)             - 'bold italic small caps'  (b/scit) with NFSS spec.: 
-
-
-Package fontspec Info: Font family 'SourceCodePro(3)' created for font
-(fontspec)             'SourceCodePro' with options [Ligatures =,Numbers
-(fontspec)             =,Scale = .7,Extension = .otf,UprightFont =
-(fontspec)             *-Light,ItalicFont = *-LightIt,BoldFont =
-(fontspec)             *-Semibold,BoldItalicFont = *-SemiboldIt].
-(fontspec)              
-(fontspec)              This font family consists of the following NFSS
-(fontspec)             series/shapes:
-(fontspec)              
-(fontspec)             - 'normal' (m/n) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-Light.otf]/OT:script=latn;langu
-age=dflt;""
-(fontspec)             - 'small caps'  (m/sc) with NFSS spec.: 
-(fontspec)             - 'bold' (b/n) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-Semibold.otf]/OT:script=latn;la
-nguage=dflt;""
-(fontspec)             - 'bold small caps'  (b/sc) with NFSS spec.: 
-(fontspec)             - 'italic' (m/it) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-LightIt.otf]/OT:script=latn;lan
-guage=dflt;""
-(fontspec)             - 'italic small caps'  (m/scit) with NFSS spec.: 
-(fontspec)             - 'bold italic' (b/it) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-SemiboldIt.otf]/OT:script=latn;
-language=dflt;""
-(fontspec)             - 'bold italic small caps'  (b/scit) with NFSS spec.: 
-
-
-Package fontspec Info: Font family 'SourceCodePro(4)' created for font
-(fontspec)             'SourceCodePro' with options [Ligatures =,Numbers
-(fontspec)             =,Scale = .7,Extension = .otf,UprightFont =
-(fontspec)             *-ExtraLight,ItalicFont = *-ExtraLightIt,BoldFont =
-(fontspec)             *-Black,BoldItalicFont = *-BlackIt].
-(fontspec)              
-(fontspec)              This font family consists of the following NFSS
-(fontspec)             series/shapes:
-(fontspec)              
-(fontspec)             - 'normal' (m/n) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-ExtraLight.otf]/OT:script=latn;
-language=dflt;""
-(fontspec)             - 'small caps'  (m/sc) with NFSS spec.: 
-(fontspec)             - 'bold' (b/n) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-Black.otf]/OT:script=latn;langu
-age=dflt;""
-(fontspec)             - 'bold small caps'  (b/sc) with NFSS spec.: 
-(fontspec)             - 'italic' (m/it) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-ExtraLightIt.otf]/OT:script=lat
-n;language=dflt;""
-(fontspec)             - 'italic small caps'  (m/scit) with NFSS spec.: 
-(fontspec)             - 'bold italic' (b/it) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-BlackIt.otf]/OT:script=latn;lan
-guage=dflt;""
-(fontspec)             - 'bold italic small caps'  (b/scit) with NFSS spec.: 
-
-
-Package fontspec Info: Font family 'SourceCodePro(5)' created for font
-(fontspec)             'SourceCodePro' with options [Ligatures =,Numbers
-(fontspec)             =,Scale = .7,Extension = .otf,Numbers =,UprightFont =
-(fontspec)             *-Regular,ItalicFont = *-RegularIt,BoldFont =
-(fontspec)             *-Bold,BoldItalicFont = *-BoldIt].
-(fontspec)              
-(fontspec)              This font family consists of the following NFSS
-(fontspec)             series/shapes:
-(fontspec)              
-(fontspec)             - 'normal' (m/n) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-Regular.otf]/OT:script=latn;lan
-guage=dflt;""
-(fontspec)             - 'small caps'  (m/sc) with NFSS spec.: 
-(fontspec)             - 'bold' (b/n) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-Bold.otf]/OT:script=latn;langua
-ge=dflt;""
-(fontspec)             - 'bold small caps'  (b/sc) with NFSS spec.: 
-(fontspec)             - 'italic' (m/it) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-RegularIt.otf]/OT:script=latn;l
-anguage=dflt;""
-(fontspec)             - 'italic small caps'  (m/scit) with NFSS spec.: 
-(fontspec)             - 'bold italic' (b/it) with NFSS spec.:
-(fontspec)             <->s*[.7]""[SourceCodePro-BoldIt.otf]/OT:script=latn;lang
-uage=dflt;""
-(fontspec)             - 'bold italic small caps'  (b/scit) with NFSS spec.: 
-
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/base/makeidx.sty
-Package: makeidx 2021/10/04 v1.0m Standard LaTeX package
-)
-\@indexfile=\write4
-\openout4 = `banana-book.idx'.
-
-
-Writing index file banana-book.idx
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/amscls/amsthm.sty
-Package: amsthm 2020/05/29 v2.20.6
-\thm@style=\toks29
-\thm@bodyfont=\toks30
-\thm@headfont=\toks31
-\thm@notefont=\toks32
-\thm@headpunct=\toks33
-\thm@preskip=\skip92
-\thm@postskip=\skip93
-\thm@headsep=\skip94
-\dth@everypar=\toks34
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/pgf/frontendlayer/tikz.sty
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/pgf/basiclayer/pgf.sty
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/pgf/utilities/pgfrcs.sty
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/utilities/pgfutil-common.tex
-\pgfutil@everybye=\toks35
-\pgfutil@tempdima=\dimen269
-\pgfutil@tempdimb=\dimen270
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/utilities/pgfutil-latex.def
-\pgfutil@abb=\box90
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/utilities/pgfrcs.code.tex
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/pgf.revision.tex)
-Package: pgfrcs 2023-01-15 v3.1.10 (3.1.10)
-))
-Package: pgf 2023-01-15 v3.1.10 (3.1.10)
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/pgf/basiclayer/pgfcore.sty
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/pgf/systemlayer/pgfsys.sty
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/systemlayer/pgfsys.code.tex
-Package: pgfsys 2023-01-15 v3.1.10 (3.1.10)
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/utilities/pgfkeys.code.tex
-\pgfkeys@pathtoks=\toks36
-\pgfkeys@temptoks=\toks37
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/utilities/pgfkeyslibraryfiltered.code.tex
-\pgfkeys@tmptoks=\toks38
-))
-\pgf@x=\dimen271
-\pgf@y=\dimen272
-\pgf@xa=\dimen273
-\pgf@ya=\dimen274
-\pgf@xb=\dimen275
-\pgf@yb=\dimen276
-\pgf@xc=\dimen277
-\pgf@yc=\dimen278
-\pgf@xd=\dimen279
-\pgf@yd=\dimen280
-\w@pgf@writea=\write5
-\r@pgf@reada=\read3
-\c@pgf@counta=\count322
-\c@pgf@countb=\count323
-\c@pgf@countc=\count324
-\c@pgf@countd=\count325
-\t@pgf@toka=\toks39
-\t@pgf@tokb=\toks40
-\t@pgf@tokc=\toks41
-\pgf@sys@id@count=\count326
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/systemlayer/pgf.cfg
-File: pgf.cfg 2023-01-15 v3.1.10 (3.1.10)
-)
-Driver file for pgf: pgfsys-xetex.def
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/systemlayer/pgfsys-xetex.def
-File: pgfsys-xetex.def 2023-01-15 v3.1.10 (3.1.10)
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/systemlayer/pgfsys-dvipdfmx.def
-File: pgfsys-dvipdfmx.def 2023-01-15 v3.1.10 (3.1.10)
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/systemlayer/pgfsys-common-pdf.def
-File: pgfsys-common-pdf.def 2023-01-15 v3.1.10 (3.1.10)
-)
-\pgfsys@objnum=\count327
-)))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/systemlayer/pgfsyssoftpath.code.tex
-File: pgfsyssoftpath.code.tex 2023-01-15 v3.1.10 (3.1.10)
-\pgfsyssoftpath@smallbuffer@items=\count328
-\pgfsyssoftpath@bigbuffer@items=\count329
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/systemlayer/pgfsysprotocol.code.tex
-File: pgfsysprotocol.code.tex 2023-01-15 v3.1.10 (3.1.10)
-))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/basiclayer/pgfcore.code.tex
-Package: pgfcore 2023-01-15 v3.1.10 (3.1.10)
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/math/pgfmath.code.tex
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/math/pgfmathutil.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/math/pgfmathparser.code.tex
-\pgfmath@dimen=\dimen281
-\pgfmath@count=\count330
-\pgfmath@box=\box91
-\pgfmath@toks=\toks42
-\pgfmath@stack@operand=\toks43
-\pgfmath@stack@operation=\toks44
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/math/pgfmathfunctions.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/math/pgfmathfunctions.basic.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/math/pgfmathfunctions.trigonometric.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/math/pgfmathfunctions.random.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/math/pgfmathfunctions.comparison.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/math/pgfmathfunctions.base.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/math/pgfmathfunctions.round.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/math/pgfmathfunctions.misc.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/math/pgfmathfunctions.integerarithmetics.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/math/pgfmathcalc.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/math/pgfmathfloat.code.tex
-\c@pgfmathroundto@lastzeros=\count331
-))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/math/pgfint.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/basiclayer/pgfcorepoints.code.tex
-File: pgfcorepoints.code.tex 2023-01-15 v3.1.10 (3.1.10)
-\pgf@picminx=\dimen282
-\pgf@picmaxx=\dimen283
-\pgf@picminy=\dimen284
-\pgf@picmaxy=\dimen285
-\pgf@pathminx=\dimen286
-\pgf@pathmaxx=\dimen287
-\pgf@pathminy=\dimen288
-\pgf@pathmaxy=\dimen289
-\pgf@xx=\dimen290
-\pgf@xy=\dimen291
-\pgf@yx=\dimen292
-\pgf@yy=\dimen293
-\pgf@zx=\dimen294
-\pgf@zy=\dimen295
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/basiclayer/pgfcorepathconstruct.code.tex
-File: pgfcorepathconstruct.code.tex 2023-01-15 v3.1.10 (3.1.10)
-\pgf@path@lastx=\dimen296
-\pgf@path@lasty=\dimen297
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/basiclayer/pgfcorepathusage.code.tex
-File: pgfcorepathusage.code.tex 2023-01-15 v3.1.10 (3.1.10)
-\pgf@shorten@end@additional=\dimen298
-\pgf@shorten@start@additional=\dimen299
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/basiclayer/pgfcorescopes.code.tex
-File: pgfcorescopes.code.tex 2023-01-15 v3.1.10 (3.1.10)
-\pgfpic=\box92
-\pgf@hbox=\box93
-\pgf@layerbox@main=\box94
-\pgf@picture@serial@count=\count332
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/basiclayer/pgfcoregraphicstate.code.tex
-File: pgfcoregraphicstate.code.tex 2023-01-15 v3.1.10 (3.1.10)
-\pgflinewidth=\dimen300
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/basiclayer/pgfcoretransformations.code.tex
-File: pgfcoretransformations.code.tex 2023-01-15 v3.1.10 (3.1.10)
-\pgf@pt@x=\dimen301
-\pgf@pt@y=\dimen302
-\pgf@pt@temp=\dimen303
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/basiclayer/pgfcorequick.code.tex
-File: pgfcorequick.code.tex 2023-01-15 v3.1.10 (3.1.10)
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/basiclayer/pgfcoreobjects.code.tex
-File: pgfcoreobjects.code.tex 2023-01-15 v3.1.10 (3.1.10)
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/basiclayer/pgfcorepathprocessing.code.tex
-File: pgfcorepathprocessing.code.tex 2023-01-15 v3.1.10 (3.1.10)
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/basiclayer/pgfcorearrows.code.tex
-File: pgfcorearrows.code.tex 2023-01-15 v3.1.10 (3.1.10)
-\pgfarrowsep=\dimen304
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/basiclayer/pgfcoreshade.code.tex
-File: pgfcoreshade.code.tex 2023-01-15 v3.1.10 (3.1.10)
-\pgf@max=\dimen305
-\pgf@sys@shading@range@num=\count333
-\pgf@shadingcount=\count334
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/basiclayer/pgfcoreimage.code.tex
-File: pgfcoreimage.code.tex 2023-01-15 v3.1.10 (3.1.10)
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/basiclayer/pgfcoreexternal.code.tex
-File: pgfcoreexternal.code.tex 2023-01-15 v3.1.10 (3.1.10)
-\pgfexternal@startupbox=\box95
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/basiclayer/pgfcorelayers.code.tex
-File: pgfcorelayers.code.tex 2023-01-15 v3.1.10 (3.1.10)
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/basiclayer/pgfcoretransparency.code.tex
-File: pgfcoretransparency.code.tex 2023-01-15 v3.1.10 (3.1.10)
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/basiclayer/pgfcorepatterns.code.tex
-File: pgfcorepatterns.code.tex 2023-01-15 v3.1.10 (3.1.10)
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/basiclayer/pgfcorerdf.code.tex
-File: pgfcorerdf.code.tex 2023-01-15 v3.1.10 (3.1.10)
-)))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/modules/pgfmoduleshapes.code.tex
-File: pgfmoduleshapes.code.tex 2023-01-15 v3.1.10 (3.1.10)
-\pgfnodeparttextbox=\box96
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/modules/pgfmoduleplot.code.tex
-File: pgfmoduleplot.code.tex 2023-01-15 v3.1.10 (3.1.10)
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/pgf/compatibility/pgfcomp-version-0-65.sty
-Package: pgfcomp-version-0-65 2023-01-15 v3.1.10 (3.1.10)
-\pgf@nodesepstart=\dimen306
-\pgf@nodesepend=\dimen307
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/pgf/compatibility/pgfcomp-version-1-18.sty
-Package: pgfcomp-version-1-18 2023-01-15 v3.1.10 (3.1.10)
-))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/pgf/utilities/pgffor.sty
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/pgf/utilities/pgfkeys.sty
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/utilities/pgfkeys.code.tex))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/pgf/math/pgfmath.sty
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/math/pgfmath.code.tex))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/utilities/pgffor.code.tex
-Package: pgffor 2023-01-15 v3.1.10 (3.1.10)
-\pgffor@iter=\dimen308
-\pgffor@skip=\dimen309
-\pgffor@stack=\toks45
-\pgffor@toks=\toks46
-))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/frontendlayer/tikz/tikz.code.tex
-Package: tikz 2023-01-15 v3.1.10 (3.1.10)
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/libraries/pgflibraryplothandlers.code.tex
-File: pgflibraryplothandlers.code.tex 2023-01-15 v3.1.10 (3.1.10)
-\pgf@plot@mark@count=\count335
-\pgfplotmarksize=\dimen310
-)
-\tikz@lastx=\dimen311
-\tikz@lasty=\dimen312
-\tikz@lastxsaved=\dimen313
-\tikz@lastysaved=\dimen314
-\tikz@lastmovetox=\dimen315
-\tikz@lastmovetoy=\dimen316
-\tikzleveldistance=\dimen317
-\tikzsiblingdistance=\dimen318
-\tikz@figbox=\box97
-\tikz@figbox@bg=\box98
-\tikz@tempbox=\box99
-\tikz@tempbox@bg=\box100
-\tikztreelevel=\count336
-\tikznumberofchildren=\count337
-\tikznumberofcurrentchild=\count338
-\tikz@fig@count=\count339
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/modules/pgfmodulematrix.code.tex
-File: pgfmodulematrix.code.tex 2023-01-15 v3.1.10 (3.1.10)
-\pgfmatrixcurrentrow=\count340
-\pgfmatrixcurrentcolumn=\count341
-\pgf@matrix@numberofcolumns=\count342
-)
-\tikz@expandcount=\count343
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/frontendlayer/tikz/libraries/tikzlibrarytopaths.code.tex
-File: tikzlibrarytopaths.code.tex 2023-01-15 v3.1.10 (3.1.10)
-)))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/pgfplots/pgfplots.sty
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/pgfplots.revision.tex)
-Package: pgfplots 2021/05/15 v1.18.1 Data Visualization (1.18.1)
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/pgfplots.code.tex
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/pgfplotscore.code.tex
-\t@pgfplots@toka=\toks47
-\t@pgfplots@tokb=\toks48
-\t@pgfplots@tokc=\toks49
-\pgfplots@tmpa=\dimen319
-\c@pgfplots@coordindex=\count344
-\c@pgfplots@scanlineindex=\count345
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/sys/pgfplotssysgeneric.code.tex))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/libs/pgfplotslibrary.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/oldpgfcompatib/pgfplotsoldpgfsupp_loader.code.tex
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/libraries/pgflibraryfpu.code.tex)
-Package pgfplots: loading complementary utilities for your pgf version...
-\t@pgf@toka=\toks50
-\t@pgf@tokb=\toks51
-\t@pgf@tokc=\toks52
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/oldpgfcompatib/pgfplotsoldpgfsupp_pgfutil-common-lists.tex))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/util/pgfplotsutil.code.tex
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/liststructure/pgfplotsliststructure.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/liststructure/pgfplotsliststructureext.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/liststructure/pgfplotsarray.code.tex
-\c@pgfplotsarray@tmp=\count346
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/liststructure/pgfplotsmatrix.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/numtable/pgfplotstableshared.code.tex
-\c@pgfplotstable@counta=\count347
-\t@pgfplotstable@a=\toks53
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/liststructure/pgfplotsdeque.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/util/pgfplotsbinary.code.tex
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/util/pgfplotsbinary.data.code.tex))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/util/pgfplotsutil.verb.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/libs/pgflibrarypgfplots.surfshading.code.tex
-\c@pgfplotslibrarysurf@no=\count348
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/sys/pgflibrarypgfplots.surfshading.pgfsys-xetex.def
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/sys/pgflibrarypgfplots.surfshading.pgfsys-dvipdfmx.def
-\c@pgfplotslibrarysurf@streamlen=\count349
-))))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/util/pgfplotscolormap.code.tex
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/util/pgfplotscolor.code.tex))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/pgfplotsstackedplots.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/pgfplotsplothandlers.code.tex
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/pgfplotsmeshplothandler.code.tex
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/pgfplotsmeshplotimage.code.tex)))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/pgfplots.scaling.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/pgfplotscoordprocessing.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/pgfplots.errorbars.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/pgfplots.markers.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/pgfplotsticks.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/pgfplots.paths.code.tex)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/frontendlayer/tikz/libraries/tikzlibrarydecorations.code.tex
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/modules/pgfmoduledecorations.code.tex
-\pgfdecoratedcompleteddistance=\dimen320
-\pgfdecoratedremainingdistance=\dimen321
-\pgfdecoratedinputsegmentcompleteddistance=\dimen322
-\pgfdecoratedinputsegmentremainingdistance=\dimen323
-\pgf@decorate@distancetomove=\dimen324
-\pgf@decorate@repeatstate=\count350
-\pgfdecorationsegmentamplitude=\dimen325
-\pgfdecorationsegmentlength=\dimen326
-)
-\tikz@lib@dec@box=\box101
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/frontendlayer/tikz/libraries/tikzlibrarydecorations.pathmorphing.code
-.tex
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/libraries/decorations/pgflibrarydecorations.pathmorphing.code.tex))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/frontendlayer/tikz/libraries/tikzlibrarydecorations.pathreplacing.cod
-e.tex
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/libraries/decorations/pgflibrarydecorations.pathreplacing.code.tex))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgfplots/libs/tikzlibrarypgfplots.contourlua.code.tex)
-\pgfplots@numplots=\count351
-\pgfplots@xmin@reg=\dimen327
-\pgfplots@xmax@reg=\dimen328
-\pgfplots@ymin@reg=\dimen329
-\pgfplots@ymax@reg=\dimen330
-\pgfplots@zmin@reg=\dimen331
-\pgfplots@zmax@reg=\dimen332
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/frontendlayer/tikz/libraries/tikzlibraryplotmarks.code.tex
-File: tikzlibraryplotmarks.code.tex 2023-01-15 v3.1.10 (3.1.10)
-
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/ge
-neric/pgf/libraries/pgflibraryplotmarks.code.tex
-File: pgflibraryplotmarks.code.tex 2023-01-15 v3.1.10 (3.1.10)
-)))
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/blkarray/blkarray.sty
-Package: blkarray 2015/02/27 v0.07 Block array (dpc)
-\c@BAenumi=\count352
-\BA@col=\count353
-\BA@block@cnt=\count354
-\BA@final@box=\box102
-\BA@first@box=\box103
-\BA@colsep=\dimen333
-\BA@ftn=\toks54
-\BAextrarowheight=\dimen334
-\BAextraheightafterhline=\dimen335
-\BAarrayrulewidth=\dimen336
-\BAdoublerulesep=\dimen337
-\BAfootskip=\dimen338
-\BA@dashbox=\box104
-\BA@ddashbox=\box105
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/multirow/multirow.sty
-Package: multirow 2021/03/15 v2.8 Span multiple rows of a table
-\multirow@colwidth=\skip95
-\multirow@cntb=\count355
-\multirow@dima=\skip96
-\bigstrutjot=\dimen339
-)
-(/Users/oliviergimenez/Library/Application Support/MiKTeX/texmfs/install/tex/la
-tex/wrapfig/wrapfig.sty
-\wrapoverhang=\dimen340
-\WF@size=\dimen341
-\c@WF@wrappedlines=\count356
-\WF@box=\box106
-\WF@everypar=\toks55
-Package: wrapfig 2003/01/31  v 3.6
-)
-(/Users/oliviergimenez/Library/Appli
\ No newline at end of file

---FILE: _bookdown_files/banana-book.lot---
@@ -1 +0,0 @@
-\addvspace {10\p@ }

---FILE: _bookdown_files/banana-book.toc---
@@ -1,30 +0,0 @@
-\contentsline {fm}{List of Figures}{v}{chapter*.1}%
-\contentsline {fm}{List of Tables}{vii}{chapter*.2}%
-\contentsline {fm}{Welcome}{ix}{chapter*.3}%
-\contentsline {fm}{Preface}{xi}{chapter*.5}%
-\contentsline {fm}{About the author}{xv}{chapter*.13}%
-\contentsline {part}{I\hspace {1em}I. Foundations}{1}{part.1}%
-\contentsline {fm}{Introduction}{3}{chapter*.14}%
-\contentsline {chapter}{\numberline {1}NIMBLE tutorial}{5}{chapter.1}%
-\contentsline {section}{\numberline {1.1}Introduction}{5}{section.1.1}%
-\contentsline {section}{\numberline {1.2}What is NIMBLE?}{5}{section.1.2}%
-\contentsline {section}{\numberline {1.3}Getting started}{6}{section.1.3}%
-\contentsline {section}{\numberline {1.4}Programming}{20}{section.1.4}%
-\contentsline {subsection}{\numberline {1.4.1}NIMBLE functions}{20}{subsection.1.4.1}%
-\contentsline {subsection}{\numberline {1.4.2}Calling R/C++ functions}{23}{subsection.1.4.2}%
-\contentsline {subsection}{\numberline {1.4.3}User-defined distributions}{25}{subsection.1.4.3}%
-\contentsline {section}{\numberline {1.5}Under the hood}{27}{section.1.5}%
-\contentsline {section}{\numberline {1.6}MCMC samplers}{34}{section.1.6}%
-\contentsline {subsection}{\numberline {1.6.1}Default samplers}{34}{subsection.1.6.1}%
-\contentsline {subsection}{\numberline {1.6.2}User-defined samplers}{35}{subsection.1.6.2}%
-\contentsline {section}{\numberline {1.7}Tips and tricks}{39}{section.1.7}%
-\contentsline {subsection}{\numberline {1.7.1}Precision vs standard deviation}{39}{subsection.1.7.1}%
-\contentsline {subsection}{\numberline {1.7.2}Indexing}{40}{subsection.1.7.2}%
-\contentsline {subsection}{\numberline {1.7.3}Faster compilation}{40}{subsection.1.7.3}%
-\contentsline {subsection}{\numberline {1.7.4}Updating MCMC chains}{41}{subsection.1.7.4}%
-\contentsline {subsection}{\numberline {1.7.5}Reproducibility}{42}{subsection.1.7.5}%
-\contentsline {subsection}{\numberline {1.7.6}Parallelization}{43}{subsection.1.7.6}%
-\contentsline {subsection}{\numberline {1.7.7}Incomplete initialization}{46}{subsection.1.7.7}%
-\contentsline {subsection}{\numberline {1.7.8}Vectorization}{47}{subsection.1.7.8}%
-\contentsline {section}{\numberline {1.8}Summary}{48}{section.1.8}%
-\contentsline {section}{\numberline {1.9}Suggested reading}{48}{section.1.9}%

---FILE: _bookdown_files/banana-book_cache/html/__packages---
@@ -1,23 +0,0 @@
-base
-methods
-datasets
-utils
-grDevices
-graphics
-stats
-tidyverse
-ggplot2
-tibble
-tidyr
-readr
-purrr
-dplyr
-stringr
-forcats
-lubridate
-nimble
-MCMCvis
-magick
-pdftools
-wesanderson
-RColorBrewer

---FILE: _bookdown_files/banana-book_cache/latex/__packages---
@@ -1,16 +0,0 @@
-tidyverse
-ggplot2
-tibble
-tidyr
-readr
-purrr
-dplyr
-stringr
-forcats
-nimble
-MCMCvis
-magick
-pdftools
-wesanderson
-RColorBrewer
-lubridate

---FILE: _bookdown_files/krantz.cls---
@@ -1,1946 +0,0 @@
-%% This is file `Krantz.cls'
-%%% Created by Shashi Kumar / ITC [August 2008]
-
-
-\NeedsTeXFormat{LaTeX2e}[1995/12/01]
-\ProvidesClass{krantz}
-              [2005/09/16 v1.4f
- Standard LaTeX document class]
-\newcommand\@ptsize{}
-\newif\if@restonecol
-\newif\if@titlepage
-\@titlepagetrue
-\newif\if@openright
-\newif\if@mainmatter \@mainmattertrue
-\if@compatibility\else
-\DeclareOption{a4paper}
-   {\setlength\paperheight {297mm}%
-    \setlength\paperwidth  {210mm}}
-\DeclareOption{a5paper}
-   {\setlength\paperheight {210mm}%
-    \setlength\paperwidth  {148mm}}
-\DeclareOption{b5paper}
-   {\setlength\paperheight {250mm}%
-    \setlength\paperwidth  {176mm}}
-\DeclareOption{letterpaper}
-   {\setlength\paperheight {11in}%
-    \setlength\paperwidth  {8.5in}}
-\DeclareOption{legalpaper}
-   {\setlength\paperheight {14in}%
-    \setlength\paperwidth  {8.5in}}
-\DeclareOption{executivepaper}
-   {\setlength\paperheight {10.5in}%
-    \setlength\paperwidth  {7.25in}}
-\DeclareOption{landscape}
-   {\setlength\@tempdima   {\paperheight}%
-    \setlength\paperheight {\paperwidth}%
-    \setlength\paperwidth  {\@tempdima}}
-\fi
-\if@compatibility
-  \renewcommand\@ptsize{0}
-\else
-\DeclareOption{10pt}{\renewcommand\@ptsize{0}}
-\fi
-\DeclareOption{11pt}{\renewcommand\@ptsize{1}}
-\DeclareOption{12pt}{\renewcommand\@ptsize{2}}
-\if@compatibility\else
-\DeclareOption{oneside}{\@twosidefalse \@mparswitchfalse}
-\fi
-\DeclareOption{twoside}{\@twosidetrue  \@mparswitchtrue}
-\DeclareOption{draft}{\setlength\overfullrule{5pt}}
-\if@compatibility\else
-\DeclareOption{final}{\setlength\overfullrule{0pt}}
-\fi
-\DeclareOption{titlepage}{\@titlepagetrue}
-\if@compatibility\else
-\DeclareOption{notitlepage}{\@titlepagefalse}
-\fi
-\if@compatibility
-\@openrighttrue
-\else
-\DeclareOption{openright}{\@openrighttrue}
-\DeclareOption{openany}{\@openrightfalse}
-\fi
-\if@compatibility\else
-\DeclareOption{onecolumn}{\@twocolumnfalse}
-\fi
-\DeclareOption{twocolumn}{\@twocolumntrue}
-\DeclareOption{leqno}{\input{leqno.clo}}
-\DeclareOption{fleqn}{\input{fleqn.clo}}
-\DeclareOption{openbib}{%
-  \AtEndOfPackage{%
-   \renewcommand\@openbib@code{%
-      \advance\leftmargin\bibindent
-      \itemindent -\bibindent
-      \listparindent \itemindent
-      \parsep \z@
-      }%
-   \renewcommand\newblock{\par}}%
-}
-%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
-\newif\if@numbysec
-\DeclareOption{numbysec}{\@numbysectrue}
-\newif\if@numberinsequence
-\DeclareOption{numberinsequence}{\@numberinsequencetrue}
-\newif\if@nocaptionbreak
-\DeclareOption{NoCaptionBreak}{\@nocaptionbreaktrue}
-\newif\if@sevenbyten
-\DeclareOption{sevenbyten}{\@sevenbytentrue}
-\newif\if@cip
-\DeclareOption{cip}{\@ciptrue}
-\newif\if@times
-\DeclareOption{times}{\@timestrue}
-\newif\if@chapnumonly
-\DeclareOption{chapnumonly}{\@chapnumonlytrue}
-\newif\if@ChapterResetsPage
-\DeclareOption{ChapterResetsPage}{\@ChapterResetsPagetrue}
-\newif\if@ChapterTOCs
-\DeclareOption{ChapterTOCs}{\@ChapterTOCstrue}
-\newif\if@EOCRefs
-\DeclareOption{EOCRefs}{\@EOCRefstrue}%
-\newif\if@SuperscriptCites
-\DeclareOption{SuperscriptCites}{\@SuperscriptCitestrue}%
-\newif\if@UnnumberedReferences
-\DeclareOption{UnnumberedReferences}{\@UnnumberedReferencestrue}%
-\newif\if@pdf
-\DeclareOption{pdf}{\@pdftrue}
-\DeclareOption{krantz1}{\@krantzatrue}
-\newif\if@krantza
-\DeclareOption{krantz2}{\@krantzbtrue}
-\newif\if@krantzb
-%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
-
-
-\ExecuteOptions{letterpaper,10pt,twoside,onecolumn,final,openright}
-\ProcessOptions
-
-%%%%%%%%%%%%%%%%%%%
-
-\def\helv@scale{.82}
-%
-\DeclareFontFamily{T1}{helvetica}{}%
-\DeclareFontShape{T1}{helvetica}{m}{n}{<->s*[\helv@scale]phvr8t}{}%
-\DeclareFontShape{T1}{helvetica}{m}{it}{<->s*[\helv@scale]phvro8t}{}%
-\DeclareFontShape{T1}{helvetica}{m}{sc}{<->s*[\helv@scale]phvrc8t}{}%
-\DeclareFontShape{T1}{helvetica}{b}{n}{<->s*[\helv@scale]phvb8t}{}%
-\DeclareFontShape{T1}{helvetica}{b}{it}{<->s*[\helv@scale]phvbo8t}{}%
-\DeclareFontShape{T1}{helvetica}{m}{sl}{<->s*[\helv@scale]phvro8t}{}%
-\DeclareFontShape{T1}{helvetica}{b}{sc}{<->s*[\helv@scale]phvbc8t}{}%
-\DeclareFontShape{T1}{helvetica}{b}{sl}{<->s*[\helv@scale]phvbo8t}{}%
-\DeclareFontShape{T1}{helvetica}{bx}{n}{<->s*[\helv@scale]phvb8t}{}%
-\DeclareFontShape{T1}{helvetica}{bx}{it}{<->s*[\helv@scale]phvbo8t}{}%
-\DeclareFontShape{T1}{helvetica}{bx}{sc}{<->s*[\helv@scale]phvbc8t}{}%
-\DeclareFontShape{T1}{helvetica}{bx}{sl}{<->ssub * helvetica/b/it}{}%
-
-\DeclareFontFamily{OT1}{helvetica}{}%
-\DeclareFontShape{OT1}{helvetica}{m}{n}{<->s*[\helv@scale]phvr7t}{}%
-\DeclareFontShape{OT1}{helvetica}{m}{it}{<->s*[\helv@scale]phvro7t}{}%
-\DeclareFontShape{OT1}{helvetica}{m}{sc}{<->s*[\helv@scale]phvrc7t}{}%
-\DeclareFontShape{OT1}{helvetica}{b}{n}{<->s*[\helv@scale]phvb7t}{}%
-\DeclareFontShape{OT1}{helvetica}{b}{it}{<->s*[\helv@scale]phvbo7t}{}%
-\DeclareFontShape{OT1}{helvetica}{m}{sl}{<->s*[\helv@scale]phvro7t}{}%
-\DeclareFontShape{OT1}{helvetica}{b}{sc}{<->s*[\helv@scale]phvbc8t}{}%
-\DeclareFontShape{OT1}{helvetica}{b}{sl}{<->s*[\helv@scale]phvbo7t}{}%
-\DeclareFontShape{OT1}{helvetica}{bx}{n}{<->s*[\helv@scale]phvb7t}{}%
-\DeclareFontShape{OT1}{helvetica}{bx}{it}{<->s*[\helv@scale]phvbo7t}{}%
-\DeclareFontShape{OT1}{helvetica}{bx}{sc}{<->s*[\helv@scale]phvbc8t}{}%
-\DeclareFontShape{OT1}{helvetica}{bx}{sl}{<->s*[\helv@scale]phvbo7t}{}%
-
-%%%%%%%%%%%%%%%%%%%%%
-
-%%%%%%%%%%%%%% Font Defined %%%%%%%%%%%%%%%%%
-
- \def\@xipt{11}
-  \def\@xviiipt{18}
- \def\@xxivpt{24}
-
-
-\newcommand\ContributorAffiliationFont{\reset@font\fontsize{10}{12}\raggedright\selectfont}
-\newcommand\ContributorNameFont{\reset@font\fontsize{10}{12}\bfseries\raggedright\selectfont}
-
-\newcommand\TitlePageTitleFont{\fontsize{24}{28}\slshape\bfseries\selectfont}
-\newcommand\PageNumFont{\reset@font\fontsize{10}{12}\selectfont}
-\newcommand\ChapNumFont{\reset@font\fontsize{24}{24}\bfseries\selectfont}
-\newcommand\ChapTitleFont{\reset@font\fontsize{18}{20}\slshape\selectfont}
-\newcommand\SectionHeadFont{\fontsize{12}{14}\bfseries\selectfont}
-\newcommand\SubsectionHeadFont{\fontsize{11}{13}\bfseries\selectfont}
-\newcommand\SubsubsectionHeadFont{\fontsize{10}{12}\bfseries\selectfont}
-\newcommand\ParagraphHeadFont{\fontsize{10}{12}\itshape\selectfont}
-\newcommand\SubParagraphHeadFont{\fontsize{10}{12}\itshape\selectfont}
-\newcommand\FMHeadFont{\reset@font\fontsize{18}{20}\slshape\bfseries\selectfont}
-\newcommand\RunningHeadFont{\fontsize{10}{12}\itshape\selectfont}
-\newcommand\NameFont{\fontsize{10}{12}\itshape\selectfont}
-\newcommand\AffiliationFont{\fontsize{8}{10}\selectfont}
-\newcommand\FigCapFont{\fontsize{10}{12}\bfseries\selectfont}
-\newcommand\FigCapBIFont{\fontsize{10}{12}\bfseries\itshape\selectfont}
-\newcommand\TableColHeadFont{\fontsize{10}{12}\bfseries\selectfont}
-\newcommand\TableTitleFont{\fontsize{10}{12}\selectfont}
-\newcommand\TableNumberFont{\fontsize{11}{13}\bfseries\selectfont}
-\newcommand\TableBodyFont{\reset@font\fontsize{9}{11}\selectfont}
-\newcommand\TableSubheadFont{\reset@font\fontsize{9}{11}\selectfont}
-\newcommand\TableFootnoteFont{\reset@font\fontsize{8}{10}\selectfont}
-\newcommand\CAPlusOneFont{\fontsize{10}{12}\bfseries\selectfont}
-\newcommand\CAAPlusOneFont{\fontsize{10}{12}\itshape\selectfont}
-\newcommand\tocfont{\fontsize{10}{12}\selectfont}
-\newcommand\extraFont{\fontsize{24}{28}\selectfont}
-\newcommand\VfFont{\fontsize{10}{12}\selectfont}
-
-%%%%%%%%%%%%%%%%%
-
-\input{bk1\@ptsize.clo}
-\setlength\lineskip{1\p@}
-\setlength\normallineskip{1\p@}
-\renewcommand\baselinestretch{}
-\setlength\parskip{0\p@ \@plus \p@}
-\@lowpenalty   51
-\@medpenalty  151
-\@highpenalty 301
-\@beginparpenalty -\@lowpenalty
-\@endparpenalty   -\@lowpenalty
-\@itempenalty     -\@lowpenalty
-%
-\clubpenalty=0         % 'Club line'  at bottom of page.
-\widowpenalty=10000    % 'Widow line' at top of page.
-\setcounter{topnumber}{2}
-\renewcommand\topfraction{.7}
-\setcounter{bottomnumber}{1}
-\renewcommand\bottomfraction{.3}
-\setcounter{totalnumber}{3}
-\renewcommand\textfraction{.2}
-\renewcommand\floatpagefraction{.5}
-\setcounter{dbltopnumber}{2}
-\renewcommand\dbltopfraction{.7}
-\renewcommand\dblfloatpagefraction{.5}
-
-%  ****************************************
-%  *            PAGE LAYOUT               *
-%  ****************************************
-%
-% All margin dimensions measured from a point one inch from top and side
-% of page.
-%
-% SIDE MARGINS:
-%
-\oddsidemargin  6pc %5pc
-\evensidemargin 5.7pc %5pc
-\marginparwidth 4pc
-\marginparsep   1pc
-\topmargin  12pt %0pt
-\headheight 12pt
-\headsep    12pt
-\footskip   2pc
-%
-% DIMENSION OF TEXT:
-\newdimen\trimheight
-\newdimen\trimwidth
-\newdimen\normaltextheight
-\newdimen\tempa
-\newdimen\tempdimen
-%
-%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  Parameter Initializaton %%%%%%%%%%%%%%%%%%%%%%%%%%
-%
-\newdimen\htrim
-\newdimen\vtrimtop
-\newdimen\vtrimbot
-
-\setlength\trimheight{9in}
-\setlength\trimwidth{6in}
-%
-%
-\if@krantza
-\textheight = 45pc
-  %\advance\textheight by \topskip
-\addtolength\textheight{3pt}
-  \textwidth 28pc
-\addtolength\textwidth{.5pt}
-  \topmargin0in
-  \oddsidemargin1.1875in
-  \evensidemargin1.1875in
-  \htrim.7365in
-  \vtrimtop1.068in
-  \vtrimbot1.068in
-  \hoffset-15pt
-  \voffset39pt
-\let\normaltextheight\textheight
-\else\if@krantzb
-  \textheight = 51pc
-%  \advance\textheight by \topskip
-  \textwidth 33pc
-  \topmargin0in
-  \oddsidemargin.5in
-  \evensidemargin.5in
-  \htrim.75in
-  \vtrimtop.8607in
-  \vtrimbot1.027in
-  \hoffset-.1in
-  \voffset-.15in%.04in
-\let\normaltextheight\textheight
-\else
-%%%Uncomment to get 6x9 trim
-%%%%\textheight = 43pc
-%%%%  %\advance\textheight by \topskip
-%%%%\addtolength\textheight{3pt}
-%%%%  \textwidth 26pc
-%%%%\addtolength\textwidth{.5pt}
-%%%% \topmargin0in
-%%%%  \oddsidemargin1.1875in
-%%%%  \evensidemargin1.1875in
-%%%%  \htrim5.05pc
-%%%%  \vtrimtop7.7pc
-%%%%  \vtrimbot5.44pc
-%%%%%  \hoffset-5pt
-%%%%  \voffset45pt
-%%%%\let\normaltextheight\textheight
-\textheight = 45pc
-  %\advance\textheight by \topskip
-\addtolength\textheight{3pt}
-  \textwidth 28pc
-\addtolength\textwidth{.5pt}
-  \topmargin0in
-  \oddsidemargin1.1875in
-  \evensidemargin1.1875in
-  \htrim.7365in
-  \vtrimtop1.068in
-  \vtrimbot1.068in
-  \hoffset-15pt
-  \voffset39pt
-\let\normaltextheight\textheight
-
-  \fi
-\fi
-%
-\columnsep 1pc
-\columnseprule 0pt
-%
-% FOOTNOTES
-%
-\footnotesep 6.65pt
-\skip\footins 12pt plus 3pt minus 1.5pt
-%
-
-%%%%  Trim marks %%%%%%%%%%%
-\newsavebox\ul@box
-\newsavebox\ur@box
-\newsavebox\ll@box
-\newsavebox\lr@box
-\def\top@cornermarks{%
-  \hskip-\htrim
-  \vbox to 0\p@{\vskip-\vtrimtop\llap{\copy\ul@box}\vss}%
-  \vbox to 0\p@{\vskip-\vtrimtop\rlap{\hskip\textwidth\hskip2\htrim\copy\ur@box}\vss}%
-  \vbox to 0\p@{\vskip\textheight\vskip\vtrimbot\llap{\copy\ll@box}\vss}%
-  \vbox to 0\p@{\vskip\textheight\vskip\vtrimbot\rlap{\hskip\textwidth\hskip2\htrim\copy\lr@box}\vss}%
-  \hskip\htrim}
-\def\make@cornermarks{%
-  \sbox\ul@box{\rule{18\p@}{.25\p@}\hskip8\p@\hbox to.25\p@{\vbox to26\p@{\noindent\rule{.25\p@}{18\p@}}}}%
-  \sbox\ur@box{\hbox to.25\p@{\vbox to26\p@{\noindent\rule{.25\p@}{18\p@}}}\hskip8\p@\rule{18\p@}{.25\p@}}%
-  \sbox\ll@box{\rule{18\p@}{.25\p@}\hskip8\p@\lower34\p@\hbox to.25\p@{\vbox to26\p@{\noindent\rule{.25\p@}{18\p@}}}}%
-  \sbox\lr@box{\lower34\p@\hbox to.25\p@{\vbox to26\p@{\noindent\rule{.25\p@}{18\p@}}}\hskip8\p@\rule{18\p@}{.25\p@}}}
-
-%%%%%%%%%%%%%%%%%%%%  End Trim Marks %%%%%%%%%%%%
-
-
-\def\ps@plain{\let\@mkboth\@gobbletwo
-     \let\@oddhead\top@cornermarks%\@empty
-     \def\@oddfoot{\reset@font\hfil\thepage
-     \hfil}\let\@evenhead\@empty\let\@evenfoot\@oddfoot}
-
-
-
-\def\even@head{%
-\top@cornermarks
-  {\@the@page\RunningHeadFont
-    \hfill
-\if@mainmatter\ifnum\value{chapter}>0 \thechapter\enspace\fi\fi\leftmark
-    }}
-\def\odd@head{%
-\top@cornermarks
-  \hfil{\RunningHeadFont
-\if@mainmatter\ifnum\value{section}>0 \thesection\enspace\fi\fi\rightmark
-    }
-\hfill
-    \@the@page
-  }
-\def\@the@page{{\PageNumFont\thepage}}
-
-
-\if@twoside
-\def\ps@headings{%
-  \let\@mkboth\@gobbletwo
-  \if@pdf
-    \let\@evenhead\@empty
-    \let\@oddhead\@empty
-    \def\@oddfoot{\@cip\hfil}%
-    \def\@evenfoot{\@cip\hfil}%
-  \else
-\let\@oddfoot\@empty
-\let\@evenfoot\@empty
-    \let\@evenhead\even@head
-    \let\@oddhead\odd@head
-  \fi
-  }
-\else
-  \def\ps@headings{\let\@mkboth\@gobbletwo%
-\if@pdf
-    \let\@evenhead\@empty
-    \let\@oddhead\@empty
-    \def\@oddfoot{\@cip\hfil}%
-    \def\@evenfoot{\@cip\hfil}%
-  \else
-\let\@oddfoot\@empty
-\let\@evenfoot\@empty
-    \let\@evenhead\even@head
-    \let\@oddhead\odd@head
-  \fi
-}
-\fi
-\def\ps@myheadings{%
-    \let\@oddfoot\@empty\let\@evenfoot\@empty
-    \def\@evenhead{\thepage\hfil\slshape\leftmark}%
-    \def\@oddhead{{\slshape\rightmark}\hfil\thepage}%
-    \let\@mkboth\@gobbletwo
-    \let\chaptermark\@gobble
-    \let\sectionmark\@gobble
-    }
-\def\ps@empty{%
-  \let\@mkboth\@gobbletwo
-  \if@pdf
-    \let\@evenhead\@empty
-    \let\@oddhead\@empty
-    \def\@oddfoot{\@cip\hfil}%
-    \def\@evenfoot{\@cip\hfil}%
-  \else
-    \make@cornermarks
-    \let\@oddhead\top@cornermarks
-    \let\@evenhead\top@cornermarks
-    \let\@oddfoot\@empty
-    \let\@evenfoot\@empty
-  \fi
-  }
-\def\ps@folio{%
-  \let\@mkboth\@gobbletwo
-  \if@pdf
-    \let\@evenhead\@empty
-    \let\@oddhead\@empty
-    \def\@oddfoot{\@cip\hfil}%
-    \def\@evenfoot{\@cip\hfil}%
-  \else
-\let\@oddhead\top@cornermarks
-    \def\@oddfoot{%
-      \parindent\z@
-      \baselineskip7\p@
-      \hbox{%
-        \textwidth\@ciprulewidth
-        \vbox{%
-          \if@cip\rule{\@ciprulewidth}{.25pt}\par
-            \hbox{\vbox{\noindent\copy\@cipboxa\par\noindent\copy\@cipboxb}}\fi}}
-      \hfill\@the@page}
-    \let\@evenhead\top@cornermarks%\odd@head
-    \let\@evenfoot\@oddfoot
-  \fi
-  }
-\newcommand\HeadingsBookChapter{%
-  \def\chaptermark##1{%
-    \markboth{\@title}{%
-      ##1}}%
-  \def\sectionmark##1{}}
-\def\HeadingsChapterSection{%
-  \def\chaptermark##1{%
-    \markboth{%
-      ##1}{}}%
-  \def\sectionmark##1{%
-    \markright{%
-      ##1}}}
-\def\pdfon{\@pdftrue}
-\def\pdfoff{\@pdffalse}
-\if@pdf
-  \def\@cip{{\fontsize{6\p@}{8\p@}\selectfont\copyright 2001 by CRC Press LLC}}
-\else
-  \newsavebox\@cipboxa
-  \newsavebox\@cipboxb
-  \newdimen\@ciprulewidth
-  \def\@cip#1#2{%
-    \sbox\@cipboxa{\fontsize{6\p@}{8\p@}\selectfont #1}%
-    \sbox\@cipboxb{\fontsize{6\p@}{8\p@}\selectfont #2}%
-    \@ciprulewidth\wd\@cipboxa
-    \ifnum\@ciprulewidth<\wd\@cipboxb\@ciprulewidth\wd\@cipboxb\fi}%
-\fi
-\if@pdf
-\else
-  \AtBeginDocument{%
-    \@cip{\rule{0pt}{9pt}0-8493-0052-5/00/\$0.00+\$.50}%
-      {\copyright\ \ 2001 by CRC Press LLC}}%
-\fi
-  \if@titlepage
-  \newcommand\maketitle{\begin{titlepage}%
-  \let\footnotesize\small
-  \let\footnoterule\relax
-  \let \footnote \thanks
-{\parindent \z@ \raggedright \baselineskip \z@ \lineskip \z@ \parskip \z@
-    \vbox{
-    \vskip -7bp
-    {\baselineskip 10bp\lineskip 10bp\NameFont\uppercase{\@author}\par}
-    \vskip 6bp
-    \AffiliationFont \@affiliation
-    \vskip -2bp
-    \crcrule
-    \vskip 22bp
-    {\baselineskip 24bp\lineskip 24bp\TitlePageTitleFont\@title\par}}}
-  \@thanks
-  \vfil\null
-  \end{titlepage}%
-  \setcounter{footnote}{0}%
-  \global\let\thanks\relax
-  \global\let\maketitle\relax
-  \global\let\@thanks\@empty
-  \global\let\@author\@empty
-  \global\let\@date\@empty
-%  \global\let\@title\@empty
-  \global\let\title\relax
-  \global\let\author\relax
-  \global\let\date\relax
-  \global\let\and\relax
-}
-\else
-\newcommand\maketitle{\par
-  \begingroup
-    \renewcommand\thefootnote{\@fnsymbol\c@footnote}%
-    \def\@makefnmark{\rlap{\@textsuperscript{\normalfont\@thefnmark}}}%
-    \long\def\@makefntext##1{\parindent 1em\noindent
-            \hb@xt@1.8em{%
-                \hss\@textsuperscript{\normalfont\@thefnmark}}##1}%
-    \if@twocolumn
-      \ifnum \col@number=\@ne
-        \@maketitle
-      \else
-        \twocolumn[\@maketitle]%
-      \fi
-    \else
-      \newpage
-      \global\@topnum\z@   % Prevents figures from going at top of page.
-      \@maketitle
-    \fi
-    \thispagestyle{empty}\@thanks
-  \endgroup
-  \setcounter{footnote}{0}%
-  \global\let\thanks\relax
-  \global\let\maketitle\relax
-  \global\let\@maketitle\relax
-  \global\let\@thanks\@empty
-  \global\let\@author\@empty
-  \global\let\@date\@empty
-  \global\let\@title\@empty
-  \global\let\title\relax
-  \global\let\author\relax
-  \global\let\date\relax
-  \global\let\and\relax
-}
-\def\@maketitle{%
-  \newpage
-  \null
-  \vskip 2em%
-{\parindent \z@ \raggedright \baselineskip \z@ \lineskip \z@ \parskip \z@
-    \vbox{
-    \vskip -7bp
-    {\baselineskip 10bp\lineskip 10bp\NameFont\uppercase{\@author}\par}
-    \vskip 6bp
-    \AffiliationFont \@affiliation
-    \vskip 10bp
-    \crcrule
-    \vskip 26bp
-    {\baselineskip 24bp\lineskip 24bp\TitlePageTitleFont\@title\par}}}
-  \par
-  \vskip 1.5em}
-\fi
-
-
-%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
-
-
-\newcommand*\chaptermark[1]{}
-\setcounter{secnumdepth}{3}
-\newcounter {part}
-\newcounter {chapter}
-\newcounter {section}[chapter]
-\newcounter {subsection}[section]
-\newcounter {subsubsection}[subsection]
-\newcounter {paragraph}[subsubsection]
-\newcounter {subparagraph}[paragraph]
-\renewcommand \thepart {\@Roman\c@part}
-\renewcommand \thechapter {\@arabic\c@chapter}
-\renewcommand \thesection {\thechapter.\@arabic\c@section}
-\renewcommand\thesubsection   {\thesection.\@arabic\c@subsection}
-\renewcommand\thesubsubsection{\thesubsection .\@arabic\c@subsubsection}
-\renewcommand\theparagraph    {\thesubsubsection.\@arabic\c@paragraph}
-\renewcommand\thesubparagraph {\theparagraph.\@arabic\c@subparagraph}
-\newcommand\@chapapp{\chaptername}
-\newcommand\frontmatter{%
-    \cleardoublepage
-  \@mainmatterfalse
-  \pagenumbering{roman}}
-\newcommand\mainmatter{%
-    \cleardoublepage
-  \@mainmattertrue
-  \pagenumbering{arabic}}
-\newcommand\backmatter{%
-  \if@openright
-    \cleardoublepage
-  \else
-    \clearpage
-  \fi
-  \@mainmatterfalse}
-\newcommand\part{\make@cornermarks%
-  \if@openright
-    \cleardoublepage
-  \else
-    \clearpage
-  \fi
-  \thispagestyle{empty}%
-  \if@twocolumn
-    \onecolumn
-    \@tempswatrue
-  \else
-    \@tempswafalse
-  \fi
-  \null\vfil
-  \secdef\@part\@spart}
-
-\def\@part[#1]#2{%
-    \ifnum \c@secnumdepth >-2\relax
-      \refstepcounter{part}%
-      \addcontentsline{toc}{part}{\thepart\hspace{1em}#1}%
-    \else
-      \addcontentsline{toc}{part}{#1}%
-    \fi
-    \markboth{}{}%
-    {\centering
-     \interlinepenalty \@M
-     \normalfont
-     \ifnum \c@secnumdepth >-2\relax
-       \huge\bfseries \partname\nobreakspace\thepart
-       \par
-       \vskip 20\p@
-     \fi
-     \Huge \bfseries #2\par}%
-    \@endpart}
-\def\@spart#1{%
-    {\centering
-     \interlinepenalty \@M
-     \normalfont
-     \Huge \bfseries #1\par}%
-    \@endpart}
-\def\@endpart{\vfil\newpage
-              \if@twoside
-               \if@openright
-                \null
-                \thispagestyle{empty}%
-                \newpage
-               \fi
-              \fi
-              \if@tempswa
-                \twocolumn
-              \fi}
-
-\if@ChapterTOCs
-  \newwrite\@chaptoc
-   \def\secnumwidth{21pt}\def\subsecnumwidth{30pt}\def\ssubsecnumwidth{36pt}\def\subsubsecnumwidth{66pt}\fi
-\long\def\@trplarg#1{\@ifnextchar[{\@xtrplarg{#1}}{\@ztrplarg{#1}}}
-\long\def\@xtrplarg#1[#2]{\@ifnextchar[{#1[#2]}{\@ytrplarg{#1}[{#2}]}}
-\long\def\@ytrplarg#1[#2]#3{#1[{#2}][{#2}]{#3}}
-\long\def\@ztrplarg#1#2{#1[{#2}][{#2}]{#2}}
-
-
-\newcommand\chapter{\if@openright\cleardoublepage\else\clearpage\fi
-  \make@cornermarks
-  \cleardoublepage
-  \if@ChapterTOCs\if@filesw\immediate\closeout\@chaptoc\fi\fi
-  \pagestyle{headings}%
-  \thispagestyle{folio}%
-\if@ChapterResetsPage\global\c@page\@ne\fi
-                    \global\@topnum\z@
-                      \gdef\chapterauthor{\@ca}%
-  \gdef\endchapterauthors{\end@cas}%
-                    \@afterindentfalse
-                    \secdef\@chapter\@schapter
-%%%                     \@ifstar{\@schapter}{\@trplarg{\@chapter}}
-                     }
-
-
-\def\@chapter[#1]#2{%
-  \ifnum\c@secnumdepth>\m@ne
-    \if@mainmatter
-      \refstepcounter{chapter}%
-      \typeout{\@chapapp\space\thechapter.}%
-      \addcontentsline{toc}{chapter}{\protect\numberline{\thechapter}#1}%
-    \else
-      \addcontentsline{toc}{chapter}{#1}\fi
-  \else
-    \addcontentsline{toc}{chapter}{#1}\fi
-  \chaptermark{%
-    #2}%
-  \addtocontents{lof}{\protect\addvspace{10\p@}}%
-  \addtocontents{lot}{\protect\addvspace{10\p@}}%
-  \if@twocolumn
-    \@topnewpage[\@makechapterhead{#2}]%
-  \else
-    \@makechapterhead{#2}%
-    \@afterheading\fi
-  \if@ChapterTOCs\if@filesw\immediate\openout\@chaptoc\thechapter.toc\fi\fi
-}
-\def\@makechapterhead#1{%
-  {\parindent \z@ \raggedright \baselineskip \z@ \lineskip \z@ \parskip \z@
-    \vbox{
-    \vskip -2\p@
-    \ChapNumFont
-%Remove comment if ""Chapter""  word required before Number
-%\if@chapnumonly\else
-%    \@chapapp\
-%\fi
-    \thechapter
-    \vskip -15\p@
-    \chap@rule
-    \vskip 6\p@
-    {\baselineskip 20\p@\lineskip 20\p@\ChapTitleFont #1\par\vskip-15pt}%
-    \noindent\hbox{\vrule height.5pt width84pt}
-    \vskip28\p@}
-            \if@ChapterTOCs
-      \make@chaptoc
-    \else
-\fi
-    \vskip 19.3\p@}
-    \def\theequation{\thechapter.\arabic{equation}}}%
-
-
-\def\@schapter#1{\if@twocolumn
-                   \@topnewpage[\@makeschapterhead{#1}]%
-                 \else
-                   \@makeschapterhead{#1}%
-                   \addcontentsline{toc}{fm}{#1}
-                   \markboth{#1}{#1}
-                   \@afterheading
-                 \fi}
-
-\def\@makeschapterhead#1{%
-  {\parindent \z@ \raggedright \baselineskip 6\p@ \lineskip \z@ \parskip \z@
-    \vbox{
-    \vskip 22\p@
-    \unnumchap@rule
-    \vskip 5\p@
-    \FMHeadFont #1\par\vskip-12pt
-    \noindent\hbox{\vrule height.5pt width84pt}
-    \vskip 41\p@}}%
-  \def\theequation{\thechapter.\arabic{equation}}}
-
-%%%\def\@startsection#1#2#3#4#5#6{%
-%%%  \if@noskipsec\leavevmode\fi
-%%%  \par
-%%%  \@tempskipa #4\relax
-%%%  \@afterindenttrue
-%%%  \ifdim \@tempskipa <\z@
-%%%    \@tempskipa -\@tempskipa \@afterindentfalse
-%%%  \fi
-%%%  \if@nobreak
-%%%    \everypar{}%
-%%%  \else
-%%%    \addpenalty\@secpenalty\addvspace\@tempskipa
-%%%  \fi
-%%%  \@ifstar
-%%%    {\@ssect{#1}{#3}{#4}{#5}{#6}}%
-%%%    {\@trplarg{\@sect{#1}{#2}{#3}{#4}{#5}{#6}}}}
-%%%\def\@ssect#1#2#3#4#5#6{%
-%%%  \@tempskipa #4\relax
-%%%  \ifdim \@tempskipa>\z@
-%%%    \begingroup
-%%%      #5{%
-%%%        \@hangfrom{\hskip #2}%
-%%%          \interlinepenalty \@M #6\@@par}%
-%%%    \endgroup
-%%%    \csname #1mark\endcsname{#6}%
-%%%  \else
-%%%    \def\@svsechd{#5{\hskip #2\relax #6}\csname #1mark\endcsname{#6}}%
-%%%  \fi
-%%%  \@xsect{#4}}
-%%%\def\@sect#1#2#3#4#5#6[#7][#8]#9{%
-%%%  \ifnum #2>\c@secnumdepth
-%%%    \let\@svsec\@empty
-%%%  \else
-%%%    \refstepcounter{#1}%
-%%%\protected@edef\@svsec{\@seccntformat{#1}\relax}%
-%%%  \fi
-%%%  \@tempskipa #5\relax
-%%%  \ifdim \@tempskipa>\z@
-%%%    \begingroup
-%%%      #6{%
-%%%\@hangfrom{\hskip #3\relax\@svsec}\interlinepenalty \@M %
-%%%          #9\@@par}%
-%%%    \endgroup
-%%%    \csname #1mark\endcsname{%
-%%%      #8}%
-%%%    \addcontentsline{toc}{#1}{%
-%%%      \ifnum #2>\c@secnumdepth \else
-%%%        \protect\numberline{\csname the#1\endcsname}%
-%%%      \fi
-%%%      #7}%
-%%%  \else
-%%%    \def\@svsechd{%
-%%%      #6{\hskip #3\relax
-%%%      \@svsec #9}%
-%%%      \csname #1mark\endcsname{%
-%%%        #8}%
-%%%      \addcontentsline{toc}{#1}{%
-%%%        \ifnum #2>\c@secnumdepth \else
-%%%          \protect\numberline{\csname the#1\endcsname}%
-%%%        \fi
-%%%        #7}}%
-%%%  \fi
-%%%  \@xsect{#5}}
-
-%%Change mydotted also
-\newdimen\secwd
-\newdimen\subsecwd
-\newdimen\subsubsecwd
-
-\def\secwd{31pt}
-\def\subsecwd{36pt}
-\def\subsubsecwd{46pt}
-
-
-\def\ssubnumberline#1{\@hangfrom{\hbox to \secwd{#1\hfill}}}
-\def\subnumberline#1{\@hangfrom{\hskip\subsecnumwidth\hbox to \subsecwd{#1\hfill}}}
-\def\subsubnumberline#1{\@hangfrom{\hskip\subsubsecnumwidth\hbox to \subsubsecwd{#1\hfill}}}
-
-
-\newcommand\section{%
-  \gdef\chapterauthor{\@caplusone}%
-  \gdef\endchapterauthors{\end@casplusone}%
-  \@ifstar{\@ssection}{\@trplarg{\@section}}}
-\def\@ssection#1{%
-  \if@ChapterTOCs
-    \myaddcontentsline{\@chaptoc}{chapsection}{\string\makebox[\secnumwidth][l]{}#1}\fi
-  \@startsection{section}{1}{\z@}{-30\p@}{6\p@}{\sec@rule\nopagebreak\vskip9.5\p@\nopagebreak\SectionHeadFont}*{#1}}
-\def\@section[#1][#2]#3{%
-  \if@ChapterTOCs
-    \addtocounter{section}{1}%
-        \myaddcontentsline{\@chaptoc}{chapsection}{\protect\ssubnumberline{\thesection}#1}%
-    \addtocounter{section}{-1}\fi
-  \@startsection{section}{1}{\z@}{-30\p@}{6\p@}{\sec@rule\nopagebreak\vskip9.5\p@\nopagebreak\SectionHeadFont}[#2]{#3}}
-\def\sectionauthor#1{\hfill{\ChapTOCAuthorFont #1}}
-
-\newcommand\subsection{\@ifstar{\@ssubsection}{\@trplarg{\@subsection}}}
-\def\@ssubsection#1{%
-  \if@ChapterTOCs
-    \myaddcontentsline{\@chaptoc}{chapsubsection}{\string\makebox[\subsecnumwidth][l]{}#1}\fi
-  \@startsection{subsection}{2}{\z@}{-18\p@}{6\p@}{%
-    \SubsectionHeadFont}*{#1}}
-\def\@subsection[#1][#2]#3{%
-  \if@ChapterTOCs
-    \addtocounter{subsection}{1}%
-        \myaddcontentsline{\@chaptoc}{chapsubsection}{\protect\subnumberline{\thesubsection}#1}%
-    \addtocounter{subsection}{-1}\fi
-  \@startsection{subsection}{2}{\z@}{-18\p@}{6\p@}{%
-    \SubsectionHeadFont}[#2]{#3}}
-
-\newcommand\subsubsection{\@ifstar{\@ssubsubsection}{\@trplarg{\@subsubsection}}}
-\def\@ssubsubsection#1{%
-  \if@ChapterTOCs
-    \myaddcontentsline{\@chaptoc}{chapsubsubsection}{\string\makebox[\subsecnumwidth][l]{}#1}\fi
-  \@startsection{subsubsection}{3}{\z@}{-12\p@}{6\p@}{%
-    \SubsubsectionHeadFont}*{#1}}
-\def\@subsubsection[#1][#2]#3{%
-  \if@ChapterTOCs
-    \addtocounter{subsubsection}{1}%
-        \myaddcontentsline{\@chaptoc}{chapsubsubsection}{\protect\subsubnumberline{\thesubsubsection}#1}%
-    \addtocounter{subsubsection}{-1}\fi
-  \@startsection{subsubsection}{3}{\z@}{-12\p@}{6\p@}{%
-    \SubsubsectionHeadFont}[#2]{#3}}
-
-\newcommand\paragraph{\@startsection{paragraph}{4}{\z@}%
-{-12\p@}{6\p@}{\ParagraphHeadFont}}
-
-\newcommand\subparagraph{\@startsection{subparagraph}{5}{\parindent}%
-{-12\p@}{6\p@}{\SubParagraphHeadFont}}
-
-
-\if@twocolumn
-  \setlength\leftmargini  {2em}
-\else
-  \setlength\leftmargini  {2.5em}
-\fi
-\leftmargin  \leftmargini
-\setlength\leftmarginii  {2.2em}
-\setlength\leftmarginiii {1.87em}
-\setlength\leftmarginiv  {1.7em}
-\if@twocolumn
-  \setlength\leftmarginv  {.5em}
-  \setlength\leftmarginvi {.5em}
-\else
-  \setlength\leftmarginv  {1em}
-  \setlength\leftmarginvi {1em}
-\fi
-\setlength  \labelsep  {.5em}
-\setlength  \labelwidth{\leftmargini}
-\addtolength\labelwidth{-\labelsep}
-\@beginparpenalty -\@lowpenalty
-\@endparpenalty   -\@lowpenalty
-\@itempenalty     -\@lowpenalty
-\renewcommand\theenumi{\@arabic\c@enumi}
-\renewcommand\theenumii{\@alph\c@enumii}
-\renewcommand\theenumiii{\@roman\c@enumiii}
-\renewcommand\theenumiv{\@Alph\c@enumiv}
-\newcommand\labelenumi{\theenumi.}
-\newcommand\labelenumii{(\theenumii)}
-\newcommand\labelenumiii{\theenumiii.}
-\newcommand\labelenumiv{\theenumiv.}
-\renewcommand\p@enumii{\theenumi}
-\renewcommand\p@enumiii{\theenumi(\theenumii)}
-\renewcommand\p@enumiv{\p@enumiii\theenumiii}
-\newcommand\labelitemi{\textbullet}
-\newcommand\labelitemii{\normalfont\bfseries \textendash}
-\newcommand\labelitemiii{\textasteriskcentered}
-\newcommand\labelitemiv{\textperiodcentered}
-\newenvironment{description}
-               {\list{}{\labelwidth\z@ \itemindent-\leftmargin
-                        \let\makelabel\descriptionlabel}}
-               {\endlist}
-\newcommand*\descriptionlabel[1]{\hspace\labelsep
-                                \normalfont\bfseries #1}
-\newenvironment{verse}
-               {\let\\\@centercr
-                \list{}{\itemsep      \z@
-                        \itemindent   -1.5em%
-                        \listparindent\itemindent
-                        \rightmargin  \leftmargin
-                        \advance\leftmargin 1.5em}%
-                \item\relax}
-               {\endlist}
-\newenvironment{quotation}
-               {\list{}{\listparindent 1.5em%
-                        \itemindent    \listparindent
-                        \rightmargin   \leftmargin
-                        \parsep        \z@ \@plus\p@}%
-                \item\relax}
-               {\endlist}
-\newenvironment{quote}
-               {\list{}{\rightmargin\leftmargin}%
-                \item\relax}
-               {\endlist}
-\if@compatibility
-\newenvironment{titlepage}
-    {%
-      \cleardoublepage
-      \if@twocolumn
-        \@restonecoltrue\onecolumn
-      \else
-        \@restonecolfalse\newpage
-      \fi
-      \thispagestyle{empty}%
-      \setcounter{page}\z@
-    }%
-    {\if@restonecol\twocolumn \else \newpage \fi
-    }
-\else
-\newenvironment{titlepage}
-    {%
-      \cleardoublepage
-      \if@twocolumn
-        \@restonecoltrue\onecolumn
-      \else
-        \@restonecolfalse\newpage
-      \fi
-      \thispagestyle{empty}%
-      \setcounter{page}\@ne
-    }%
-    {\if@restonecol\twocolumn \else \newpage \fi
-     \if@twoside\else
-        \setcounter{page}\@ne
-     \fi
-    }
-\fi
-\newcommand\appendix{\par
-  \setcounter{chapter}{0}%
-  \setcounter{section}{0}%
-  \gdef\@chapapp{\appendixname}%
-  \gdef\thechapter{\@Alph\c@chapter}}
-\setlength\arraycolsep{5\p@}
-\setlength\tabcolsep{6\p@}
-\setlength\arrayrulewidth{.4\p@}
-\setlength\doublerulesep{2\p@}
-\setlength\tabbingsep{\labelsep}
-\skip\@mpfootins = \skip\footins
-\setlength\fboxsep{3\p@}
-\setlength\fboxrule{.4\p@}
-\@addtoreset {equation}{chapter}
-\renewcommand\theequation
-  {\ifnum \c@chapter>\z@ \thechapter.\fi \@arabic\c@equation}
-\newcounter{figure}[chapter]
-\renewcommand \thefigure
-     {\ifnum \c@chapter>\z@ \thechapter.\fi \@arabic\c@figure}
-\def\fps@figure{tbp}
-\def\ftype@figure{1}
-\def\ext@figure{lof}
-\def\fnum@figure{\figurename\nobreakspace\thefigure}
-\newenvironment{figure}
-               {\@float{figure}}
-               {\end@float}
-\newenvironment{figure*}
-               {\@dblfloat{figure}}
-               {\end@dblfloat}
-\newcounter{table}[chapter]
-\renewcommand \thetable
-     {\ifnum \c@chapter>\z@ \thechapter.\fi \@arabic\c@table}
-\def\fps@table{tbp}
-\def\ftype@table{2}
-\def\ext@table{lot}
-\def\fnum@table{\tablename\nobreakspace\thetable}
-\newenvironment{table}
-               {\@float{table}}
-               {\end@float}
-\newenvironment{table*}
-               {\@dblfloat{table}}
-               {\end@dblfloat}
-\newlength\abovecaptionskip
-\newlength\belowcaptionskip
-\setlength\abovecaptionskip{10\p@}
-\setlength\belowcaptionskip{0\p@}
-\long\def\@makecaption#1#2{%
-  \vskip\abovecaptionskip
-  \sbox\@tempboxa{#1: #2}%
-  \ifdim \wd\@tempboxa >\hsize
-    {\FigCapFont #1} #2\par
-  \else
-    \global \@minipagefalse
-%    \hb@xt@\hsize{\hfil\box\@tempboxa\hfil}%
-    {\FigCapFont #1} #2\par
-  \fi
-  \vskip\belowcaptionskip}
-\DeclareOldFontCommand{\rm}{\normalfont\rmfamily}{\mathrm}
-\DeclareOldFontCommand{\sf}{\normalfont\sffamily}{\mathsf}
-\DeclareOldFontCommand{\tt}{\normalfont\ttfamily}{\mathtt}
-\DeclareOldFontCommand{\bf}{\normalfont\bfseries}{\mathbf}
-\DeclareOldFontCommand{\it}{\normalfont\itshape}{\mathit}
-\DeclareOldFontCommand{\sl}{\normalfont\slshape}{\@nomath\sl}
-\DeclareOldFontCommand{\sc}{\normalfont\scshape}{\@nomath\sc}
-\DeclareRobustCommand*\cal{\@fontswitch\relax\mathcal}
-\DeclareRobustCommand*\mit{\@fontswitch\relax\mathnormal}
-\newcommand\@pnumwidth{1.55em}
-\newcommand\@tocrmarg{2.55em}
-\newcommand\@dotsep{4.5}
-\setcounter{tocdepth}{3}
-
-
-\newcounter{numauthors}
-\newif\if@break
-\newif\if@firstauthor
-
-\newcommand\tableofcontents{\cleardoublepage\markboth{Contents}{Contents}%
-  \make@cornermarks
-    \gdef\chapterauthor{\@caplusone}%
-  \gdef\endchapterauthors{\end@casplusone}%
-    \if@twocolumn
-      \@restonecoltrue\onecolumn
-    \else
-      \@restonecolfalse
-    \fi
-      {\parindent \z@ \raggedright \baselineskip 6\p@ \lineskip \z@ \parskip \z@
-    \vbox{
-    \vskip 22\p@
-    \unnumchap@rule
-    \vskip 5\p@
-    \FMHeadFont \contentsname\par\vskip-12pt
-    \noindent\hbox{\vrule height.5pt width84pt}
-    \vskip 41\p@}}
-%%%    \chapter*{\contentsname
-%%%        \@mkboth{%
-%%%           \MakeUppercase\contentsname}{\MakeUppercase\contentsname}}%
-           \pagestyle{headings}\thispagestyle{folio}
-             {\let\break\space
-    \let\author\toc@author
-    \reset@authors
-    \let\toc@draw\relax
-    \@starttoc{toc}
-%%    \toc@draw
-    }
-    \if@restonecol\twocolumn\fi
-    }
-
-
-\def\draw@part#1#2{%
-  \addpenalty{-\@highpenalty}%
-  \vskip1em plus\p@
-  \@tempdima1.5em
-  \begingroup
-    \parindent\z@\rightskip\@pnumwidth
-    \parfillskip-\rightskip
-    \bfseries
-    \leavevmode
-    \advance\leftskip\@tempdima
-    \hskip-\leftskip
-    {#1\hfil}\nobreak
-      \if@pdf
-      \else
-        \hfil\nobreak\hb@xt@\@pnumwidth{\hss #2}%
-\fi
-    \par
-    \penalty\@highpenalty\endgroup}
-
-\let\toc@draw\relax
-%
-\def\l@part#1#2{%
-\toc@draw
- \gdef\toc@draw{\draw@part{\large #1}{\large #2}}}
-
-\def\l@fm#1#2{%
-  \toc@draw
-  \gdef\toc@draw{\draw@fm{#1}{#2}}}
-\def\@pnumwidth{1.8em}
-\def\draw@fm#1#2{%
-  \addpenalty{-\@highpenalty}%
-  \vskip1em plus\p@
-  \@tempdima1.5em
-  \begingroup
-    \parindent\z@\rightskip\@pnumwidth
-    \parfillskip-\rightskip
-    \bfseries
-    \leavevmode
-    \advance\leftskip\@tempdima
-    \hskip-\leftskip
-    {#1\hfil}\nobreak
-      \if@pdf
-      \else
-        \hfil\nobreak\hb@xt@\@pnumwidth{\hss #2}%
-\fi
-    \par
-    \penalty\@highpenalty\endgroup}
-
-
-
-  \def\l@chapter#1#2{%
-  \toc@draw
-  \gdef\toc@draw{\draw@chapter{#1}{#2}}}
-\def\@pnumwidth{1.8em}
-\def\draw@chapter#1#2{%
-  \addpenalty{-\@highpenalty}%
-  \vskip1em plus\p@
-  \@tempdima1.5em
-  \begingroup
-    \parindent\z@\rightskip\@pnumwidth
-    \parfillskip-\rightskip
-    \bfseries
-    \leavevmode
-    \advance\leftskip\@tempdima
-    \hskip-\leftskip
-    {#1\hfil}\nobreak
-      \if@pdf
-      \else
-        \hfil\nobreak\hb@xt@\@pnumwidth{\hss #2}%
-\fi
-    \par
-    {\it\draw@authors}%
-    \penalty\@highpenalty\endgroup}
-\def\toc@author#1#2{%
-  \if@firstauthor
-    \@firstauthorfalse
-  \else
-    \ifx\@authors\@empty
-      \xdef\@authors{\last@author}%
-    \else
-      \@cons{\@authors}{, \last@author}\fi\fi
-  \stepcounter{numauthors}%
-%%%%%%% commented and deleted below the second part to aviod inaccessible error % shashi % September-2008
-%%  \gdef\last@author{#1 {\rm\fontsize{9\p@}{11\p@}\selectfont #2}}
-\gdef\last@author{#1}
-}
-\def\draw@authors{%
-  \let\@t\@authors
-  \ifx\@t\@empty
-    \let\@t\last@author\fi
-  \ifx\@t\@empty\else
-    \hskip\leftskip
-    \ifx\@authors\@empty
-    \else
-      \@authors
-      \ifnum\c@numauthors>2,\fi
-      \if@break\break\fi
-      \ and \fi
-    \last@author\break\fi
-  \reset@authors}
-\def\reset@authors{%
-  \gdef\@authors{}%
-  \gdef\last@author{}%
-  \@firstauthortrue
-  \setcounter{numauthors}{0}}
-\newlength\section@toc@skip
-\section@toc@skip1.5em
-\newlength\SectionTOCWidth
-\SectionTOCWidth2.3em
-\def\l@section#1#2{%
-  \toc@draw
-  \gdef\toc@draw{\draw@section{#1}{#2}}}
-\def\draw@section#1#2{%
-  \@dottedtocline{1}{\section@toc@skip}{\SectionTOCWidth}{#1 }{{
-\tocfont #2}}}
-\newlength\subsection@toc@skip
-\subsection@toc@skip\section@toc@skip
-\advance\subsection@toc@skip\SectionTOCWidth
-\newlength\SubSectionTOCWidth
-\SubSectionTOCWidth3.2em
-\def\l@subsection#1#2{%
-  \toc@draw
-  \gdef\toc@draw{\draw@subsection{#1}{#2}}}
-\def\draw@subsection#1#2{%
-  \@dottedtocline{2}{\subsection@toc@skip}{\SubSectionTOCWidth}{#1}{{
-\tocfont #2}}}
-\newlength\subsubsection@toc@skip
-\subsubsection@toc@skip\subsection@toc@skip
-\advance\subsubsection@toc@skip\SubSectionTOCWidth
-\newlength\SubSubSectionTOCWidth
-\SubSubSectionTOCWidth4.1em
-\def\l@subsubsection#1#2{%
-  \toc@draw
-  \gdef\toc@draw{\draw@subsubsection{#1}{#2}}}
-\def\draw@subsubsection#1#2{%
-  \@dottedtocline{3}{\subsubsection@toc@skip}{\SubSubSectionTOCWidth}{#1}{{
-\tocfont #2}}}
-\newlength\paragraph@toc@skip
-\paragraph@toc@skip\subsubsection@toc@skip
-\advance\paragraph@toc@skip\SubSubSectionTOCWidth
-\newlength\ParagraphTOCWidth
-\ParagraphTOCWidth4.1em
-\def\l@paragraph#1#2{%
-  \toc@draw
-  \gdef\toc@draw{\draw@paragraph{#1}{#2}}}
-\def\draw@paragraph#1#2{%
-  \@dottedtocline{4}{\paragraph@toc@skip}{\ParagraphTOCWidth}{#1}{{
-\tocfont #2}}}
-\newlength\subparagraph@toc@skip
-\subparagraph@toc@skip\paragraph@toc@skip
-\advance\subparagraph@toc@skip\ParagraphTOCWidth
-\def\l@subparagraph#1#2{%
-  \toc@draw
-  \gdef\toc@draw{\draw@subparagraph{#1}{#2}}}
-\def\draw@subparagraph#1#2{%
-  \@dottedtocline{5}{\subparagraph@toc@skip}{6em}{#1}{{
-\tocfont #2}}}
-
-\def\@dottedtocline#1#2#3#4#5{%
-  \ifnum #1>\c@tocdepth
-  \else
-    \vskip \z@ \@plus.2\p@
-    {\leftskip #2\relax\rightskip\@tocrmarg\parfillskip-\rightskip
-      \parindent #2\relax\@afterindenttrue
-      \interlinepenalty\@M
-      \leavevmode
-      \@tempdima #3\relax
-      \advance\leftskip\@tempdima\null\hskip-\leftskip
-      {#4\hfil}\nobreak
-      \if@pdf
-      \else
-        \leaders\hbox{$\m@th\mkern\@dotsep mu\hbox{.}\mkern\@dotsep mu$}\hfill
-        \nobreak
-        \hb@xt@\@pnumwidth{\hfil\normalfont\normalcolor #5}%
-\fi
-      \par}\fi}
-
-\newcommand\chapterauthors{%
-  \def\break{\string\break\ }%
-  \def\protect##1{\string ##1 }}
-\def\end@cas{}
-\def\end@casplusone{\vskip4pt\@doendpe}
-
-%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
-\def\make@chaptoc{% chapter author
-  {\parindent\z@
-  \newcommand\FolioBoldFont{}%
-  \let\@b\bullet
-  \def\bullet{\raisebox{2pt}{$\scriptscriptstyle\@b$}}%
-  \let\SubsectionItalicFont\it
-%\ifx\chapter@author\@empty\else
-{\rm\fontsize{10\p@}{10\p@}\bfseries\selectfont
-%\the\c@numauthors
-    \ifnum\c@numauthors=1
-        \chapter@authorone\vskip6\p@
-        {\it\fontsize{10\p@}{10\p@}\selectfont\chapter@affiliationone}\vskip12\p@
-            \fi
-        \ifnum\c@numauthors=2
-                    \chapter@authorone\vskip6\p@
-        {\it\fontsize{10\p@}{10\p@}\selectfont\chapter@affiliationone}\vskip12\p@
-                        \chapter@authortwo\vskip6\p@
-        {\it\fontsize{10\p@}{10\p@}\selectfont\chapter@affiliationtwo}
-                            \fi
-                                \ifnum\c@numauthors=3
-                                    \chapter@authorone\vskip6\p@
-        {\it\fontsize{10\p@}{10\p@}\selectfont\chapter@affiliationone}\vskip12\p@
-                                        \chapter@authortwo\vskip6\p@
-        {\it\fontsize{10\p@}{10\p@}\selectfont\chapter@affiliationtwo}\vskip12\p@
-                                            \chapter@authorthree\vskip6\p@
-        {\it\fontsize{10\p@}{10\p@}\selectfont\chapter@affiliationthree}
-                                                \fi
-                                                    \ifnum\c@numauthors=4
-                                                        \chapter@authorone\vskip6\p@
-        {\it\fontsize{10\p@}{10\p@}\selectfont\chapter@affiliationone}\vskip12\p@
-                                                            \chapter@authortwo\vskip6\p@
-        {\it\fontsize{10\p@}{10\p@}\selectfont\chapter@affiliationtwo}\vskip12\p@
-                                                                \chapter@authorthree\vskip6\p@
-        {\it\fontsize{10\p@}{10\p@}\selectfont\chapter@affiliationthree}\vskip12\p@
-                                                                    \chapter@authorfour\vskip6\p@
-        {\it\fontsize{10\p@}{10\p@}\selectfont\chapter@affiliationfour}
-                                                                        \fi
-}
- \gdef\chapter@authorone{}\gdef\chapter@affiliationone{}%
- \gdef\chapter@authortwo{}\gdef\chapter@affiliationtwo{}%
- \gdef\chapter@authorthree{}\gdef\chapter@affiliationthree{}%
- \gdef\chapter@authorfour{}\gdef\chapter@affiliationfour{}%
-  \vskip 14.6\p@
-{\leftskip\secnumwidth\def\author##1##2{}\vskip14pt\hbox{\leftskip0pt\SubsectionHeadFont CONTENTS}\vskip6pt\par\@input{\thechapter.toc}\par}%
-  }
-\reset@authors}
-%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
-\newif\iffinishedfromone
-\global\finishedfromonefalse
-%
-\newif\iffinishedfromtwo
-\global\finishedfromtwofalse
-%
-\newif\iffinishedfromthree
-\global\finishedfromthreefalse
-%
-\newif\iffinishedfromfour
-\global\finishedfromfourfalse
-%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
-%
-\newcommand\singleauthorchapter{\finishedfromonetrue}
-\newcommand\twoauthorchapter{\finishedfromtwotrue}
-\newcommand\threeauthorchapter{\finishedfromthreetrue}
-\newcommand\fourauthorchapter{\finishedfromfourtrue}
-%
-%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
-\newif\iffinish
-\global\finishfalse
-%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
-\newsavebox\@AUonebox
-\newsavebox\@AUtwobox
-\newsavebox\@AUthreebox
-\newsavebox\@AUfourbox
-%
-\newsavebox\@AUaffonebox
-\newsavebox\@AUafftwobox
-\newsavebox\@AUaffthreebox
-\newsavebox\@AUafffourbox
-%
-\newsavebox\@finalAUboxfromone
-\newsavebox\@finalAUboxfromtwo
-\newsavebox\@finalAUboxfromthree
-\newsavebox\@finalAUboxfromfour
-%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
-
-\def\@ca#1#2{%
-%  \def\chapter@author{#1}%
-%  \def\chapter@affiliation{#2}%
-  \if@filesw%
-    \write\@auxout{%
-\string\@writefile{toc}{\string\author{#1}{}}%
-}%
-  \fi
-%%%%%%%%%%%%%%%
-
-\ifnum\c@numauthors>4
-    \resetcounter{numauthors}
-\fi
-\stepcounter{numauthors}
-%%\the\c@numauthors
-\ifnum\c@numauthors=1 %
-    \sbox\@AUonebox{\CAPlusOneFont#1}
-    \sbox\@AUaffonebox{\vbox{\hsize\textwidth\CAAPlusOneFont\noindent #2\par}}
-    \sbox\@finalAUboxfromone{\copy\@AUonebox}
-    \def\chapter@authorone{\copy\@finalAUboxfromone}
-    \def\chapter@affiliationone{\copy\@AUaffonebox}
-\fi \ifnum\c@numauthors=2
-    \sbox\@AUtwobox{\CAPlusOneFont#1}
-    \sbox\@AUafftwobox{\vbox{\hsize\textwidth\CAAPlusOneFont\noindent #2\par}}
-    \sbox\@finalAUboxfromtwo{\copy\@AUtwobox}
-    \def\chapter@authortwo{\copy\@finalAUboxfromtwo}
-    \def\chapter@affiliationtwo{\copy\@AUafftwobox}
-\fi \ifnum\c@numauthors=3
-    \sbox\@AUthreebox{\CAPlusOneFont#1}
-    \sbox\@AUaffthreebox{\vbox{\hsize\textwidth\CAAPlusOneFont\noindent #2\par}}
-    \sbox\@finalAUboxfromthree{\copy\@AUthreebox}
-    \def\chapter@authorthree{\copy\@finalAUboxfromthree}
-    \def\chapter@affiliationthree{\copy\@AUaffthreebox}
-\fi \ifnum\c@numauthors=4
-    \sbox\@AUfourbox{\CAPlusOneFont#1}
-    \sbox\@AUafffourbox{\vbox{\hsize\textwidth\CAAPlusOneFont\noindent #2\par}}
-    \sbox\@finalAUboxfromfour{\copy\@AUfourbox}
-    \def\chapter@authorfour{\copy\@finalAUboxfromfour}
-    \def\chapter@affiliationfour{\copy\@AUafffourbox}
-\fi}
-
-
-\def\@caplusone{\@ifstar{\@scaplusone}{\@ifnextchar[{\@xcaplusone}{\@xcaplusone[]}}}
-\def\@xcaplusone[#1]#2#3{%
-  \def\@@empty{#1}\ifx\@empty\@@empty\@ca{#2}{#3}\else\@ca{#2}{#1}\fi\@scaplusone{#2}{#3}}
-\def\@scaplusone#1#2{%
-  \ifhmode\vskip-12pt\fi
-%%Shashi Commented
-%%%  \noindent\hskip3pc{\CAPlusOneFont\baselineskip14pt #1\def\@t{#2}\ifx\@t\@empty\else,\fi}\hskip6pt{\CAAPlusOneFont #2}\par
-}
-
-\def\chapterauthoronly#1#2{\@ca{#1}{}\@scaplusone{#1}{#2}}
-\def\myaddcontentsline#1#2#3{%
-  \if@filesw
-    \begingroup
-    \let\label\@gobble\let\index\@gobble\let\glossary\@gobble
-    \def\break{\ }%
-    \def\protect##1{\string ##1 }%
-    \@temptokena{\thepage}%
-    \edef\@tempa{\write#1{\string\chapcontentsline{#2}{\string\raggedright\space #3}{\the\@temptokena}}}\@tempa
-    \if@nobreak\ifvmode\nobreak\fi\fi
-    \endgroup
-  \fi}
-\def\chapcontentsline#1{\csname l@#1\endcsname}
-\def\l@chapsection{\@mydottedtocline{1}{\z@}{6pt}}
-\def\l@chapsubsection{\@mydottedtocline{2}{\secnumwidth}{6pt}}
-\def\l@chapsubsubsection{\@mydottedtocline{3}{\subsecnumwidth}{36pt}}
-\newcount\c@chaptocdepth
-\setcounter{chaptocdepth}{3}
-\def\@mytocline#1#2#3#4#5{%
-  \ifnum #1>\c@chaptocdepth
-  \else
-    \vskip 2pt plus.2\p@
-    \ifnum #1=1\ifnum\c@chaptocdepth>1\addvspace{12pt}\fi\fi
-    {\leftskip #2\relax% \rightskip \@tocrmarg \parfillskip -\rightskip
-      \interlinepenalty\@M
-      \leavevmode
-      \@tempdima #3\relax
-      \rightskip\z@
-      \vbox{\ChapTOCFont #4\nobreak}%
-      \par}\fi}
-\def\@mydottedtocline#1#2#3#4#5{%
-  \ifnum #1>\c@chaptocdepth
-  \else
-\fontsize{10}{12}\selectfont
-{\leftskip #2\relax \rightskip \@tocrmarg \parfillskip -\rightskip
-     % \parindent #2\relax\@afterindenttrue
-      \interlinepenalty\@M
-      \leavevmode
-      \def\@dotsep{1.2}%
-      \@tempdima #3\relax
-      \rightskip\z@
-%      \advance\hsize-\secnumwidth
-%      \hskip-\secnumwidth
-\if@sevenbyten
-\hangindent\secnumwidth\hsize372pt\else\hangindent\secnumwidth\hsize312pt\fi
-#4
-        \if@pdf
-          \hfill
-        \else
-          \nobreak\leaders\hbox{$\m@th\mkern\@dotsep mu.\mkern\@dotsep mu$}\hfill\nobreak
-          \hbox to24\p@{\hfil #5}\fi
-      \par}\fi}
-
-\newcommand\listoffigures{%
-    \if@twocolumn
-      \@restonecoltrue\onecolumn
-    \else
-      \@restonecolfalse
-    \fi
-    \chapter*{\listfigurename}%
-      \@mkboth{\MakeUppercase\listfigurename}%
-              {\MakeUppercase\listfigurename}%
-    \@starttoc{lof}%
-    \if@restonecol\twocolumn\fi
-    }
-\newcommand*\l@figure{\@dottedtocline{1}{1.5em}{2.3em}}
-\newcommand\listoftables{%
-    \if@twocolumn
-      \@restonecoltrue\onecolumn
-    \else
-      \@restonecolfalse
-    \fi
-    \chapter*{\listtablename}%
-      \@mkboth{%
-          \MakeUppercase\listtablename}%
-         {\MakeUppercase\listtablename}%
-    \@starttoc{lot}%
-    \if@restonecol\twocolumn\fi
-    }
-\let\l@table\l@figure
-\newdimen\bibindent
-\setlength\bibindent{1.5em}
-\newenvironment{thebibliography}[1]
-     {\chapter*{\bibname}%
-      \@mkboth{\MakeUppercase\bibname}{\MakeUppercase\bibname}%
-%       \addcontentsline{toc}{chapter}{\bibname}
-      \list{\@biblabel{\@arabic\c@enumiv}}%
-           {\settowidth\labelwidth{\@biblabel{#1}}%
-            \leftmargin\labelwidth
-            \advance\leftmargin\labelsep
-            \@openbib@code
-            \usecounter{enumiv}%
-            \let\p@enumiv\@empty
-            \renewcommand\theenumiv{\@arabic\c@enumiv}}%
-      \sloppy
-      \clubpenalty4000
-      \@clubpenalty \clubpenalty
-      \widowpenalty4000%
-      \sfcode`\.\@m}
-     {\def\@noitemerr
-       {\@latex@warning{Empty `thebibliography' environment}}%
-      \endlist}
-\newcommand\newblock{\hskip .11em\@plus.33em\@minus.07em}
-\let\@openbib@code\@empty
-\newcommand\indexname{Index}
-\newenvironment{theindex}
-               {\cleardoublepage\if@twocolumn
-                  \@restonecolfalse
-                \else
-                  \@restonecoltrue
-                \fi
-                \twocolumn[\@makeschapterhead{\indexname}]%
-                \@mkboth{\MakeUppercase\indexname}%
-                        {\MakeUppercase\indexname}%
-                        \pagestyle{headings}
-                        \addcontentsline{toc}{chapter}{\indexname}
-% there seems to be a weird bug in krantz.cls that prevents the very _last_ item
-% of \addcontentsline from being added to TOC, so I have to add an empty entry
-\addcontentsline{toc}{section}{}
-                \thispagestyle{folio}\parindent\z@\markboth{\indexname}{\indexname}
-                \parskip\z@ \@plus .3\p@\relax\raggedright
-                \columnseprule \z@
-                \columnsep 35\p@
-                \let\item\@idxitem}
-               {\if@restonecol\onecolumn\else\clearpage\fi}
-\newcommand\@idxitem{\par\hangindent 40\p@}
-\newcommand\subitem{\@idxitem \hspace*{20\p@}}
-\newcommand\subsubitem{\@idxitem \hspace*{30\p@}}
-\newcommand\indexspace{\par \vskip 10\p@ \@plus5\p@ \@minus3\p@\relax}
-\renewcommand\footnoterule{%
-  \kern-3\p@
-  \hrule\@width.4\columnwidth
-  \kern2.6\p@}
-\@addtoreset{footnote}{chapter}
-\newcommand\@makefntext[1]{%
-    \parindent 1em%
-    \noindent
-    \hb@xt@1.8em{\hss\@makefnmark}#1}
-\newcommand\contentsname{Contents}
-\newcommand\listfigurename{List of Figures}
-\newcommand\listtablename{List of Tables}
-\newcommand\bibname{Bibliography}
-\newcommand\figurename{FIGURE}
-\newcommand\tablename{TABLE}
-\newcommand\partname{Part}
-\newcommand\chaptername{Chapter}
-\newcommand\appendixname{Appendix}
-\def\today{\ifcase\month\or
-  January\or February\or March\or April\or May\or June\or
-  July\or August\or September\or October\or November\or December\fi
-  \space\number\day, \number\year}
-\setlength\columnsep{10\p@}
-\setlength\columnseprule{0\p@}
-\pagestyle{headings}
-\pagenumbering{arabic}
-\if@twoside
-\else
-  \raggedbottom
-\fi
-\if@twocolumn
-  \twocolumn
-  \sloppy
-  \flushbottom
-\else
-  \onecolumn
-\fi
-\newcommand\unnumcrcrule{\hbox to\textwidth{\rlap{\rule[-3.5\p@]{84\p@}{4\p@}}}}
-\newcommand\unnumchap@rule{\unnumcrcrule}
-\newcommand\crcrule{\hbox to\textwidth{\rlap{\rule[-3.5\p@]{84\p@}{4\p@}}\rule{\textwidth}{.5\p@}}}
-\newcommand\chap@rule{\crcrule}
-\newcommand\sec@rule{\crcrule}
-\def\@affiliate[#1]{\gdef\@affiliation{#1}}
-\def\@affiliation{}
-
-\def\def@theequation{%
-  \if@numberinsequence
-    \def\theequation{%
-\if@numbysec\thesection\else\thechapter\fi.%
-\@arabic\c@shared}%
-  \else
-    \def\theequation{%
-\if@numbysec\thesection\else\thechapter\fi.%
-\@arabic\c@equation}\fi}
-
-\def\affiliation#1{{\AffiliationFont\noindent #1\vskip 36bp}}
-\newbox\tempbox
-
-\newdimen\nomenwidth
-
-\newenvironment{symbollist}[1]{%
-\addvspace{12pt}
-			\setbox\tempbox\hbox{#1\hskip1em}%
-   \global\nomenwidth\wd\tempbox
-   %\section*{Sumbol Description}
-\noindent{\SectionHeadFont Symbol Description}\vskip6pt
-\begin{multicols}{2}}{%
-		\end{multicols}\par\addvspace{12pt}}
-\def\symbolentry#1#2{\par\noindent\@hangfrom{\hbox to \nomenwidth{#1\hss}}#2\par}
-
-
-\tabcolsep 5pt
-\arrayrulewidth .5pt
-\doublerulesep 1pt
-%\newcounter{subtable}[table]
-\newif\if@tablerules\@tablerulestrue
-\newif\if@centertable\@centertabletrue
-\newif\if@centertabletitle\@centertabletitletrue
-\newbox\@tablebox
-\newbox\@tabletitlebox
-\newdimen\@tablewidth
-\newdimen\@tabletitlewidth
-\newdimen\max@tablewidth
-\newcommand\automaticrules{\@tablerulestrue}
-\newcommand\noautomaticrules{\@tablerulesfalse}
-\def\thetable{%
-\thechapter.%
-\@arabic\c@table}
-\def\thesubtable{%
-\thechapter.%
-\@arabic\c@table\alph{subtable}}
-\def\resettableletter{\setcounter{subtable}{0}}
-\def\@Tabletitle{}
-\newcommand\tabletitle{\@ifnextchar[{\@xtabletitle}{\@tabletitlewidth\z@\@ytabletitle}}
-\def\@@tabletitle{}
-\newif\ifshorttabletitle
-\global\shorttabletitlefalse
-%\def\@xtabletitle#1{\@tabletitlewidth#1\@ytabletitle}
-%
-\def\@xtabletitle[#1]#2{%
-  \gdef\@@tabletitle{#1}%
-  \gdef\@tabletitle{#2}%
-  \let\@Tabletitle\@TableTitle
-  \refstepcounter{table}%
-  {\let\footnotemark\@empty
-    \let\footnote\@gobble
-    \addcontentsline{\ext@table}{table}{\protect\numberline{\thetable}{\@@tabletitle}}}}
-%%%%
-%\long\def\@xtabletitle[#1]#2{%
-%  \setbox\@ttbox\hbox{#1}\global\shorttabletitletrue
-%  \def\@@tabletitle{\ifx\@ttbox\@empty\else#1\fi}%
-%  \def\@tabletitle{#2}%
-%  \let\@Tabletitle\@TableTitle
-%  \refstepcounter{table}%
-%  {\let\footnotemark\@empty
-%    \let\footnote\@gobble
-%    \addcontentsline{\ext@table}{table}{\protect\numberline{\thetable}{%
-%\ifshorttabletitle\@@tabletitle\else\@tabletitle\fi}}}}
-
-%%%
-%
-\long\def\@ytabletitle#1{%
-  \def\@tabletitle{#1}%
-  \let\@Tabletitle\@TableTitle
-  \refstepcounter{table}%
-  {\let\footnotemark\@empty
-    \let\footnote\@gobble
-    \addcontentsline{\ext@table}{table}{\protect\numberline{\thetable}{\@tabletitle}}}}
-\def\tabletitlelet{\@ifnextchar[{\@xtabletitlelet}{\@tabletitlewidth\z@\@ytabletitlelet}}
-\def\@xtabletitlelet[#1]{\@tabletitlewidth#1\@ytabletitlelet}
-\long\def\@ytabletitlelet#1{%
-  \def\@tabletitle{#1}%
-  \let\@Tabletitle\@TableTitle
-  \ifnum\c@subtable=0\stepcounter{table}\fi
-  \let\@currentlabel\thesubtable
-  {\let\footnotemark\@empty
-    \let\footnote\@gobble
-    \addcontentsline{\ext@table}{table}{\protect\numberline{\thetable}{\@tabletitle}}}}
-\def\@TableTitle{%
-  \noindent
-  {%
-    \vbox{{\TableNumberFont TABLE\ \thetable}}\par\TableTitleFont\@tabletitle}}
-\def\table{%
-  %\long\def\caption##1{\tabletitle{##1}\@TableTitle\par}%
-  \@float{table}}
-\@namedef{table*}{%
-  \long\def\caption##1{\tabletitle{##1}\@TableTitle\par}%
-  \@dblfloat{table}}
-
-\def\endtabular{\crcr\egroup\egroup $\egroup}
-\expandafter \let \csname endtabular*\endcsname = \endtabular
-\def\tabular{\let\@halignto\@empty\@tabular}
-\@namedef{tabular*}#1{%
- \setlength\dimen@{#1}%
-   \edef\@halignto{to\the\dimen@}\@tabular}
-
-
-\def\tch#1{\TableColHeadFont #1\llstrut\hfill}
-\def\tsh#1{\TableSubheadFont #1\hfill}
-\newcommand\llstrut{\rule[-6pt]{0pt}{14pt}}
-\newcommand\flstrut{\rule{0pt}{10pt}}
-\newcommand\tabletitlestrut{\rule{0pt}{20pt}}
-
-\def\Boxhead#1{\par\addvspace{3pt plus2pt}\noindent{\centering\bfseries#1\par}\vskip3pt}
-
-
-\newbox\tempbox%
-\newdimen\tempdimen%
-%
-\newenvironment{shortbox}{\par\addvspace{12pt plus2pt}%
-\if@krantza
-\setbox\tempbox\vbox\bgroup\hsize27pc%
-\else\if@krantzb
-\setbox\tempbox\vbox\bgroup\hsize32pc%
-\else
-\setbox\tempbox\vbox\bgroup\hsize25pc%
-\fi\fi
-}{%
-\egroup%
-\noindent\fboxsep6pt\fboxrule.5pt\hspace*{0pt}\fbox{\box\tempbox}
-\par\addvspace{12pt plus2pt}}%
-%
-
-
-\def\grayink{\special{color cmyk 0 0 0 0.2}}
-\def\blackink{\special{color cmyk 0 0 0 1.0}} %
-\def\whiteink{\special{color cmyk 0 0 0 0}} % 0%
-
-\newenvironment{shadebox}{%
-\setbox\tempbox\hbox\bgroup\vbox\bgroup\leftskip12pt\rightskip\leftskip\vspace*{12pt}}{\par\addvspace{-6pt}
-\egroup\egroup\par\addvspace{15pt}
-\tempdimen\ht\tempbox
-\advance\tempdimen by 1pc
-\noindent{\hbox to \wd\tempbox{\vbox to \ht\tempbox{\hsize\textwidth{\special{color push}\grayink\noindent\vrule height\tempdimen width\textwidth
-\special{color pop}\blackink}}}}%
-\llap{\unhbox\tempbox}\par\addvspace{20pt}}
-
-%%%%%%%%%% Note %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
-\newbox\tempbox
-\newdimen\notewidth
-\newenvironment{notelist}[1]{%
-\addvspace{6pt}
-			\setbox\tempbox\hbox{#1\hskip.57em}%
-   \global\notewidth\wd\tempbox
-}{%
-		\par\addvspace{6pt}}
-
-\def\notes#1#2{\par\noindent\@hangfrom{\hbox to \notewidth{\bf #1\hss}}#2\par}
-%%%%%%%%%%%%%%%% wherelist %%%%%%%%%%%%%%%%
-\newbox\wherebox
-\newdimen\wherewidth
-\newenvironment{wherelist}[1]{\leftskip10pt%
-\addvspace{6pt}
-			\setbox\wherebox\hbox{#1\hskip1em}%
-   \global\wherewidth\wd\wherebox
-\noindent\hspace*{-14pt} where
-}{%
-\par\addvspace{6pt}}
-\def\whereentry#1#2#3{\par\noindent\@hangfrom{\hbox to \wherewidth{#1\hss}#2\hskip6pt}#3\par}
-%%%%%%%%%%%%
-\newenvironment{unnumlist}{%
-  \ifnum \@enumdepth >3 \@toodeep\else
-    \advance\@enumdepth\@ne
-    \list{}{%
-\leftmargini27.5pt \leftmarginii17.5pt\leftmarginiv17.5pt
-%    \leftmargin\parindent
-    \advance\leftmargin-.2em
-    \advance\leftmarginii.2em
-    \advance\leftmarginiii.1em
-    \advance\leftmarginiv.2em
-    \def\makelabel##1{\hss\llap{##1}}}
-    \fi%
-}{%
-  \endlist}
-  %
-\newenvironment{extract}{%
-		\par\addvspace{11.5pt minus2pt}%
-  \leftskip2em\rightskip\leftskip
- \noindent\ignorespaces
-}{%
-		\par\addvspace{11.5pt minus2pt}%
-  \@endparenv}
-%
-%
-\def\VA#1#2{\addvspace{12pt}\raggedleft #1\rightskip3em\par #2\rightskip3em}
-%
-\newenvironment{VF}{\VfFont%
-		\par\addvspace{12pt minus2pt}%
-\noindent{\vrule height2pt width\textwidth}\par\vskip7.3pt
-  \leftskip3em\rightskip\leftskip
- \noindent\ignorespaces
-}{%
-\par\vskip6pt\leftskip0pt\noindent{{\vrule height2pt width\textwidth}}\par\addvspace{12pt minus2pt}%
-  \@endparenv}
-%
-\def\VTA#1#2{\addvspace{12pt}\raggedleft #1\rightskip3em\par {\it #2}\rightskip3em}
-%
-%
-\def\VT{\par\addvspace{3.5pt}\noindent}
-
-\def\VH#1{{\normalfont\fontsize{12.5}{14.5}\itshape\centering\selectfont #1\par}\addvspace{5.5pt}}
-%
-\newenvironment{VT1}{\VfFont%
-		\par\addvspace{12pt minus2pt}%
-\noindent{\vrule height2pt width\textwidth}\par\vskip7.5pt
-  \leftskip3em\rightskip\leftskip
-%\@afterheading
-\parindent0pt
- \noindent\ignorespaces
-}{%
-\par\vskip6pt\leftskip0pt\noindent{{\vrule height2pt width\textwidth}}\par\addvspace{10pt minus2pt}%
-  \@endparenv}
-%
-%%%%%%%%%%%% Glossary %%%%%%%%%%%%%%%%%%%%%%%
-\newenvironment{Glossary}
-               {\list{}{\labelwidth\z@\leftmargin18pt \itemindent-18pt
-                        \let\makelabel\glosslabel}}
-               {\endlist}
-\newcommand\glosslabel[1]{\hspace\labelsep\normalfont\bfseries #1:}
-
-%%%%%%%%%%%%
-\newif\iffnalpha
-\global\fnalphafalse
-
-\newskip\listtextleftmargin\listtextleftmargin 20pt%24pt
-\newskip\listtextleftmarginii\listtextleftmarginii0pt% 24pt
-\newskip\listtextleftmarginiii\listtextleftmarginiii0pt% 24pt
-
-\newskip\listtextrightmargin\listtextrightmargin12pt%.5pc
-\newskip\listlabelleftskip \listlabelleftskip4pt%3.3pt
-\newskip\listlabelleftskipii \listlabelleftskipii0pt%3.3pt
-\newskip\listlabelleftskipiii \listlabelleftskipiii0pt%3.3pt
-
-\newskip\abovelistskipi\abovelistskipi6pt plus2pt
-\newskip\belowlistskipi\belowlistskipi6pt plus2pt
-\newskip\abovelistskipii\abovelistskipii0pt plus2pt
-\newskip\belowlistskipii\belowlistskipii0pt plus2pt
-\newskip\abovelistskipiii\abovelistskipiii0pt plus2pt
-\newskip\belowlistskipiii\belowlistskipiii0pt plus2pt
-
-\newskip\labelsepi \labelsepi6pt
-\newskip\labelsepii \labelsepii6pt
-\newskip\labelsepiii \labelsepiii6pt%\z@
-
-\newskip\itemsepi \itemsepi0pt%10pt
-\newskip\itemsepii \itemsepii0pt
-\newskip\itemsepiii \itemsepiii0pt
-
-
-\newdimen\enumdimwd
-\newif\iflabelrightalign\labelrightaligntrue
-\newdimen\enumdim%
-%
-\def\enummax#1{%
-  \labelsep\csname labelsep\romannumeral\the\@enumdepth\endcsname
-  \ifdim\listtextleftmargin>\z@\labelsepi0pt\fi
-  \ifdim\listtextleftmarginii>\z@\labelsepii0pt\fi
-  \ifdim\listtextleftmarginiii>\z@\labelsepiii0pt\fi
-  \setbox\tempbox\hbox{\csname listdevicefont\romannumeral\the\@enumdepth\endcsname#1\hskip\labelsep}%
-  \enumdim\wd\tempbox
-  \setbox\tempbox\hbox{\csname listdevicefont\romannumeral\the\@enumdepth\endcsname#1}%
-  \enumdimwd\wd\tempbox
-  \expandafter\global\csname leftmargin\romannumeral\the\@enumdepth\endcsname\enumdim
-  \ifdim\listtextleftmargin>\z@
-     \leftmargini\listtextleftmargin
-     \ifdim\listlabelleftskip>\z@
-        \advance\leftmargini-\listlabelleftskip
-     \fi
-  \fi
-  \ifdim\listtextleftmarginii>\z@
-     \leftmarginii\listtextleftmarginii
-     \ifdim\listlabelleftskipii>\z@
-        \advance\leftmarginii-\listlabelleftskipii
-     \fi
-  \fi
-  \ifdim\listtextleftmarginiii>\z@
-     \leftmarginiii\listtextleftmarginiii
-     \ifdim\listlabelleftskipiii>\z@
-        \advance\leftmarginiii-\listlabelleftskipiii
-     \fi
-  \fi
-}
-%
-\enummax{1.}
-%
-\def\enumerate{\@ifnextchar[{\@enumerate}{\@enumerate[\csname label\@enumctr\endcsname]}}%%
-%
-
-\def\@enumerate[#1]{\par
-      \ifnum \@enumdepth >3 \@toodeep
-      \else
-         \advance\@enumdepth\@ne
-         \edef\@enumctr{enum\romannumeral\the\@enumdepth}%
-         \setcounter{\@enumctr}{1}\enummax{#1}%
-         \list
-            {\csname label\@enumctr\endcsname}{\usecounter{\@enumctr}%
-         \topsep\csname abovelistskip\romannumeral\the\@enumdepth\endcsname
-         \itemsep\csname itemsep\romannumeral\the\@enumdepth\endcsname
-%         \listfont %\listparindent18.25pt
-         \ifnum \@enumdepth=1 \leftmargin32.7pt
-            \rightmargin\listtextrightmargin
-            \advance\rightmargin\rightskip
-            \advance\leftmargin\leftskip
-            \tempdimen\leftmargini
-            \advance\tempdimen-\labelsep
-           %%%%%%%%%%%
-           \iffnalpha
-            \def\makelabel##1{{\hskip\listlabelleftskip{\csname listdevicefont\romannumeral\the\@enumdepth\endcsname{\iflabelrightalign\hss\fi\textlistlabel##1}}}}%
-            \global\fnalphafalse
-           \else
-            \def\makelabel##1{\hbox to \tempdimen{\hskip\listlabelleftskip{\csname listdevicefont\romannumeral\the\@enumdepth\endcsname\hbox to \enumdimwd{\iflabelrightalign\hss\fi\textlistlabel##1}}\blackink}}%
-           \fi
-           %%%%%%%%%%%%%%%%%%%%%%%%%%%
-         \else
-            \ifnum \@enumdepth=2
-               \tempdimen\leftmarginii
-               \advance\tempdimen-\labelsep
-               \def\makelabel##1{\hbox to \tempdimen{\hskip\listlabelleftskipii{\csname listdevicefont\romannumeral\the\@enumdepth\endcsname\hbox to \enumdimwd{\iflabelrightalign\hss\fi##1}\blackink}}}%
-            \else
-               \ifnum \@enumdepth=3
-                  \tempdimen\leftmarginiii
-                  \advance\tempdimen-\labelsep
-                  \def\makelabel##1{\hbox to \tempdimen{\hskip\listlabelleftskipiii{\csname listdevicefont\romannumeral\the\@enumdepth\endcsname\hbox to \enumdimwd{\iflabelrightalign\hss\fi##1}\blackink}}}%
-              \else
-                                       \def\makelabel##1{\hss\llap{\csname listdevicefont\romannumeral\the\@enumdepth\endcsname##1}}%
-                                    \fi
-                                 \fi
-         \fi}
-      \fi}
-%
-\def\endenumerate{\@topsepadd\csname belowlistskip\romannumeral\the\@enumdepth\endcsname\endlist}%
-%
-
-\def\textlistlabel{}
-
-%%%%%%%%%%%%%%%%%%%%%%%%%%%
-\newdimen\concolwidth
-\newbox\stempbox
-\def\contributor#1#2#3{\addvspace{10pt}{%
-\setbox\stempbox\hbox{\ContributorAffiliationFont #2}
-\concolwidth\wd\stempbox
-  \noindent{\ContributorNameFont #1}\par
-  \ifdim\concolwidth>\columnwidth \vspace*{3pt} \else \fi
-  \noindent{\vbox{\hangindent12pt\ContributorAffiliationFont #2}}\vskip-1\p@
-  \noindent{\vbox{\hangindent12pt\ContributorAffiliationFont #3}}}}
-
-%%\def\contributors{%
-%%  \twocolumn[\contributorshead]
-%%  \pagestyle{empty}
-%%  \leftskip1pc
-%%  \parindent-1pc}
-%%\def\contributorshead{%
-%%  \vbox{}\vskip2pc
-%%  {\centering\HeadFont CONTRIBUTORS\vskip2\p@}
-%%  \noindent\rule{\textwidth}{1\p@}\vskip25\p@}
-
-%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
-\def\cleardoublepage{\clearpage\if@twoside \ifodd\c@page\else
-    \hbox{}\thispagestyle{empty}\newpage\if@twocolumn\hbox{}\newpage\fi\fi\fi}
-
-\frenchspacing
-\tolerance=5000
-\raggedbottom
-
-%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
-
-\@centertabletitlefalse
-%\HeadingsBookChapter
-\HeadingsChapterSection
-\endinput
-%%
-%% End of file `krantz.cls'.

---FILE: docs/404.html---
@@ -73,17 +73,13 @@ <h1>
 <li><a class="""" href=""about-the-author.html"">About the author</a></li>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
-<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
-<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
-<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
-<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
+<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">1</span> Survival</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>

---FILE: docs/about-the-author.html---
@@ -73,17 +73,13 @@ <h1>
 <li><a class=""active"" href=""about-the-author.html"">About the author</a></li>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
-<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
-<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
-<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
-<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
+<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">1</span> Survival</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>

---FILE: docs/abundance.html---
@@ -1,205 +0,0 @@
-<!DOCTYPE html>
-<html lang=""en"">
-<head>
-<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
-<meta charset=""utf-8"">
-<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<title>Chapter 2 Abundance | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
-<meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""2.1 HMM and closed population   2.2 Horvitz-Thompson Viterbi √† la Rouan and complete likelihood √† la Gimenez for calculating LRS Santostasi et al. (2019) Cubaynes et al on wolves. Infering the..."">
-<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
-<meta property=""og:title"" content=""Chapter 2 Abundance | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta property=""og:type"" content=""book"">
-<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/abundance.html"">
-<meta property=""og:description"" content=""2.1 HMM and closed population   2.2 Horvitz-Thompson Viterbi √† la Rouan and complete likelihood √† la Gimenez for calculating LRS Santostasi et al. (2019) Cubaynes et al on wolves. Infering the..."">
-<meta name=""twitter:card"" content=""summary"">
-<meta name=""twitter:title"" content=""Chapter 2 Abundance | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta name=""twitter:description"" content=""2.1 HMM and closed population   2.2 Horvitz-Thompson Viterbi √† la Rouan and complete likelihood √† la Gimenez for calculating LRS Santostasi et al. (2019) Cubaynes et al on wolves. Infering the..."">
-<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
-<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
-    
-    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
-  </style>
-<style type=""text/css"">
-    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
-    div.csl-bib-body { }
-    div.csl-entry {
-      clear: both;
-        }
-    .hanging div.csl-entry {
-      margin-left:2em;
-      text-indent:-2em;
-    }
-    div.csl-left-margin {
-      min-width:2em;
-      float:left;
-    }
-    div.csl-right-inline {
-      margin-left:2em;
-      padding-left:1em;
-    }
-    div.csl-indent {
-      margin-left: 2em;
-    }
-  </style>
-<link rel=""stylesheet"" href=""bs4_style.css"">
-</head>
-<body data-spy=""scroll"" data-target=""#toc"">
-
-<div class=""container-fluid"">
-<div class=""row"">
-  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
-
-    <div class=""d-flex align-items-start justify-content-between"">
-      <h1>
-        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
-        <small class=""text-muted"">Theory and Case Studies in R</small>
-      </h1>
-      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
-    </div>
-
-    <div id=""main-nav"" class=""collapse-lg"">
-      <form role=""search"">
-        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
-</form>
-
-      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
-        <ul class=""book-toc list-unstyled"">
-<li><a class="""" href=""index.html"">Welcome</a></li>
-<li><a class="""" href=""preface.html"">Preface</a></li>
-<li><a class="""" href=""about-the-author.html"">About the author</a></li>
-<li class=""book-part"">I. Foundations</li>
-<li><a class="""" href=""introduction.html"">Introduction</a></li>
-<li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
-<li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
-<li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
-<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">1</span> Life history theory</a></li>
-<li><a class=""active"" href=""abundance.html""><span class=""header-section-number"">2</span> Abundance</a></li>
-<li><a class="""" href=""stopover.html""><span class=""header-section-number"">3</span> Stopover duration</a></li>
-<li><a class="""" href=""individual-dependence.html""><span class=""header-section-number"">4</span> Individual dependence</a></li>
-<li class=""book-part"">V. Conclusion</li>
-<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
-<li><a class="""" href=""references.html"">References</a></li>
-</ul>
-
-        <div class=""book-extra"">
-          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
-        </div>
-      </nav>
-</div>
-  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""abundance"" class=""section level1"" number=""2"">
-<h1>
-<span class=""header-section-number"">2</span> Abundance<a class=""anchor"" aria-label=""anchor"" href=""#abundance""><i class=""fas fa-link""></i></a>
-</h1>
-<div id=""hmm-and-closed-population"" class=""section level2"" number=""2.1"">
-<h2>
-<span class=""header-section-number"">2.1</span> HMM and closed population<a class=""anchor"" aria-label=""anchor"" href=""#hmm-and-closed-population""><i class=""fas fa-link""></i></a>
-</h2>
-</div>
-<div id=""horvitz-thompson"" class=""section level2"" number=""2.2"">
-<h2>
-<span class=""header-section-number"">2.2</span> Horvitz-Thompson<a class=""anchor"" aria-label=""anchor"" href=""#horvitz-thompson""><i class=""fas fa-link""></i></a>
-</h2>
-<p>Viterbi √† la Rouan and complete likelihood √† la Gimenez for calculating LRS</p>
-<p><span class=""citation"">Santostasi et al. (<a href=""references.html#ref-santostasi_use_2019"">2019</a>)</span></p>
-<p>Cubaynes et al on wolves.</p>
-<p>Infering the latent states <span class=""math inline"">\(z\)</span> can be useful to estimate prevalence, e.g.¬†in animal epidemiology with <a href=""https://veterinaryresearch.biomedcentral.com/articles/10.1186/1297-9716-45-39"">prevalence of a disease</a>, in evolutionary ecology with <a href=""https://onlinelibrary.wiley.com/doi/abs/10.1002/cjs.5550360105"">sex ratio</a> or in conservation biology with <a href=""https://onlinelibrary.wiley.com/doi/full/10.1002/ece3.4819?af=R"">prevalence of hybrids</a>.</p>
-</div>
-<div id=""jolly-seber"" class=""section level2"" number=""2.3"">
-<h2>
-<span class=""header-section-number"">2.3</span> Jolly-Seber<a class=""anchor"" aria-label=""anchor"" href=""#jolly-seber""><i class=""fas fa-link""></i></a>
-</h2>
-</div>
-<div id=""robust-design"" class=""section level2"" number=""2.4"">
-<h2>
-<span class=""header-section-number"">2.4</span> Robust design<a class=""anchor"" aria-label=""anchor"" href=""#robust-design""><i class=""fas fa-link""></i></a>
-</h2>
-<p><span class=""citation"">Karamanlidis et al. (<a href=""references.html#ref-karamanlidis_evidence_2015"">2015</a>)</span>, <span class=""citation"">Santostasi et al. (<a href=""references.html#ref-santostasi_robust_2016"">2016</a>)</span>, <span class=""citation"">Gibson et al. (<a href=""references.html#ref-gibson_application_2018"">2018</a>)</span>, and <span class=""citation"">Rankin et al. (<a href=""references.html#ref-rankin_full-capture_2016"">2016</a>)</span></p>
-</div>
-<div id=""hmm-and-scr-models-closed-and-open-√†-la-glennie"" class=""section level2"" number=""2.5"">
-<h2>
-<span class=""header-section-number"">2.5</span> HMM and SCR models (closed and open √† la Glennie)<a class=""anchor"" aria-label=""anchor"" href=""#hmm-and-scr-models-closed-and-open-%C3%A0-la-glennie""><i class=""fas fa-link""></i></a>
-</h2>
-</div>
-<div id=""hmm-and-ipms"" class=""section level2"" number=""2.6"">
-<h2>
-<span class=""header-section-number"">2.6</span> HMM and IPMs<a class=""anchor"" aria-label=""anchor"" href=""#hmm-and-ipms""><i class=""fas fa-link""></i></a>
-</h2>
-<p>Besbeas and Morgan.</p>
-
-</div>
-</div>
-  <div class=""chapter-nav"">
-<div class=""prev""><a href=""tradeoffs.html""><span class=""header-section-number"">1</span> Life history theory</a></div>
-<div class=""next""><a href=""stopover.html""><span class=""header-section-number"">3</span> Stopover duration</a></div>
-</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
-    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
-      <ul class=""nav navbar-nav"">
-<li><a class=""nav-link"" href=""#abundance""><span class=""header-section-number"">2</span> Abundance</a></li>
-<li><a class=""nav-link"" href=""#hmm-and-closed-population""><span class=""header-section-number"">2.1</span> HMM and closed population</a></li>
-<li><a class=""nav-link"" href=""#horvitz-thompson""><span class=""header-section-number"">2.2</span> Horvitz-Thompson</a></li>
-<li><a class=""nav-link"" href=""#jolly-seber""><span class=""header-section-number"">2.3</span> Jolly-Seber</a></li>
-<li><a class=""nav-link"" href=""#robust-design""><span class=""header-section-number"">2.4</span> Robust design</a></li>
-<li><a class=""nav-link"" href=""#hmm-and-scr-models-closed-and-open-%C3%A0-la-glennie""><span class=""header-section-number"">2.5</span> HMM and SCR models (closed and open √† la Glennie)</a></li>
-<li><a class=""nav-link"" href=""#hmm-and-ipms""><span class=""header-section-number"">2.6</span> HMM and IPMs</a></li>
-</ul>
-
-      <div class=""book-extra"">
-        <ul class=""list-unstyled"">
-<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/abundance.Rmd"">View source <i class=""fab fa-github""></i></a></li>
-          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/abundance.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
-        </ul>
-</div>
-    </nav>
-</div>
-
-</div>
-</div> <!-- .container -->
-
-<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-08.</p>
-  </div>
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
-  </div>
-
-</div></div>
-</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
-  (function () {
-    var script = document.createElement(""script"");
-    script.type = ""text/javascript"";
-    var src = ""true"";
-    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
-    if (location.protocol !== ""file:"")
-      if (/^https?:/.test(src))
-        src = src.replace(/^https?:/, '');
-    script.src = src;
-    document.getElementsByTagName(""head"")[0].appendChild(script);
-  })();
-</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
-for (let popover of popovers) {
-  const div = document.createElement('div');
-  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
-  div.innerHTML = popover.getAttribute('data-content');
-
-  var has_math = div.querySelector(""span.math"");
-  if (has_math) {
-    document.body.appendChild(div);
-    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
-    MathJax.Hub.Queue(function() {
-      popover.setAttribute('data-content', div.innerHTML);
-      document.body.removeChild(div);
-    })
-  }
-}
-</script>
-</body>
-</html>

---FILE: docs/banana-book.tex---
@@ -1,370 +0,0 @@
-% Options for packages loaded elsewhere
-\PassOptionsToPackage{unicode}{hyperref}
-\PassOptionsToPackage{hyphens}{url}
-\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
-%
-\documentclass[
-  12pt,
-]{krantz}
-\usepackage{amsmath,amssymb}
-\usepackage{lmodern}
-\usepackage{iftex}
-\ifPDFTeX
-  \usepackage[T1]{fontenc}
-  \usepackage[utf8]{inputenc}
-  \usepackage{textcomp} % provide euro and other symbols
-\else % if luatex or xetex
-  \usepackage{unicode-math}
-  \defaultfontfeatures{Scale=MatchLowercase}
-  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
-\fi
-% Use upquote if available, for straight quotes in verbatim environments
-\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
-\IfFileExists{microtype.sty}{% use microtype if available
-  \usepackage[]{microtype}
-  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
-}{}
-\makeatletter
-\@ifundefined{KOMAClassName}{% if non-KOMA class
-  \IfFileExists{parskip.sty}{%
-    \usepackage{parskip}
-  }{% else
-    \setlength{\parindent}{0pt}
-    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
-}{% if KOMA class
-  \KOMAoptions{parskip=half}}
-\makeatother
-\usepackage{xcolor}
-\usepackage{color}
-\usepackage{fancyvrb}
-\newcommand{\VerbBar}{|}
-\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
-\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
-% Add ',fontsize=\small' for more characters per line
-\usepackage{framed}
-\definecolor{shadecolor}{RGB}{248,248,248}
-\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
-\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
-\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
-\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
-\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
-\newcommand{\BuiltInTok}[1]{#1}
-\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
-\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
-\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
-\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
-\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
-\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
-\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
-\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
-\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
-\newcommand{\ExtensionTok}[1]{#1}
-\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
-\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
-\newcommand{\ImportTok}[1]{#1}
-\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
-\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
-\newcommand{\NormalTok}[1]{#1}
-\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
-\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
-\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
-\newcommand{\RegionMarkerTok}[1]{#1}
-\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
-\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
-\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
-\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
-\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
-\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
-\usepackage{longtable,booktabs,array}
-\usepackage{calc} % for calculating minipage widths
-% Correct order of tables after \paragraph or \subparagraph
-\usepackage{etoolbox}
-\makeatletter
-\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
-\makeatother
-% Allow footnotes in longtable head/foot
-\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
-\makesavenoteenv{longtable}
-\setlength{\emergencystretch}{3em} % prevent overfull lines
-\providecommand{\tightlist}{%
-  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
-\setcounter{secnumdepth}{5}
-\usepackage{hyperref}
-\usepackage{booktabs}
-\usepackage{longtable}
-\usepackage[bf,singlelinecheck=off]{caption}
-
-\usepackage{Alegreya}
-\usepackage[scale=.7]{sourcecodepro}
-
-\usepackage{framed,color}
-\definecolor{shadecolor}{RGB}{248,248,248}
-
-\renewcommand{\textfraction}{0.05}
-\renewcommand{\topfraction}{0.8}
-\renewcommand{\bottomfraction}{0.8}
-\renewcommand{\floatpagefraction}{0.75}
-
-\renewenvironment{quote}{\begin{VF}}{\end{VF}}
-\let\oldhref\href
-\renewcommand{\href}[2]{#2\footnote{\url{#1}}}
-
-\ifxetex
-  \usepackage{letltxmacro}
-  \setlength{\XeTeXLinkMargin}{1pt}
-  \LetLtxMacro\SavedIncludeGraphics\includegraphics
-  \def\includegraphics#1#{% #1 catches optional stuff (star/opt. arg.)
-    \IncludeGraphicsAux{#1}%
-  }%
-  \newcommand*{\IncludeGraphicsAux}[2]{%
-    \XeTeXLinkBox{%
-      \SavedIncludeGraphics#1{#2}%
-    }%
-  }%
-\fi
-
-\makeatletter
-\newenvironment{kframe}{%
-\medskip{}
-\setlength{\fboxsep}{.8em}
- \def\at@end@of@kframe{}%
- \ifinner\ifhmode%
-  \def\at@end@of@kframe{\end{minipage}}%
-  \begin{minipage}{\columnwidth}%
- \fi\fi%
- \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
- \colorbox{shadecolor}{##1}\hskip-\fboxsep
-     % There is no \\@totalrightmargin, so:
-     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
- \MakeFramed {\advance\hsize-\width
-   \@totalleftmargin\z@ \linewidth\hsize
-   \@setminipage}}%
- {\par\unskip\endMakeFramed%
- \at@end@of@kframe}
-\makeatother
-
-\makeatletter
-\@ifundefined{Shaded}{
-}{\renewenvironment{Shaded}{\begin{kframe}}{\end{kframe}}}
-\makeatother
-
-\newenvironment{rmdblock}[1]
-  {
-  \begin{itemize}
-  \renewcommand{\labelitemi}{
-    \raisebox{-.7\height}[0pt][0pt]{
-      {\setkeys{Gin}{width=3em,keepaspectratio}\includegraphics{images/#1}}
-    }
-  }
-  \setlength{\fboxsep}{1em}
-  \begin{kframe}
-  \item
-  }
-  {
-  \end{kframe}
-  \end{itemize}
-  }
-\newenvironment{rmdnote}
-  {\begin{rmdblock}{note}}
-  {\end{rmdblock}}
-\newenvironment{rmdcaution}
-  {\begin{rmdblock}{caution}}
-  {\end{rmdblock}}
-\newenvironment{rmdimportant}
-  {\begin{rmdblock}{important}}
-  {\end{rmdblock}}
-\newenvironment{rmdtip}
-  {\begin{rmdblock}{tip}}
-  {\end{rmdblock}}
-\newenvironment{rmdwarning}
-  {\begin{rmdblock}{warning}}
-  {\end{rmdblock}}
-
-\usepackage{makeidx}
-\makeindex
-
-\urlstyle{tt}
-
-\usepackage{amsthm}
-\makeatletter
-\def\thm@space@setup{%
-  \thm@preskip=8pt plus 2pt minus 4pt
-  \thm@postskip=\thm@preskip
-}
-\makeatother
-
-\frontmatter
-\usepackage{tikz}
-\usepackage{pgfplots}
-\usepackage{blkarray}
-\ifLuaTeX
-  \usepackage{selnolig}  % disable illegal ligatures
-\fi
-\usepackage[]{natbib}
-\bibliographystyle{plainnat}
-\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
-\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
-\urlstyle{same} % disable monospaced font for URLs
-\hypersetup{
-  pdftitle={Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models},
-  pdfauthor={Olivier Gimenez},
-  colorlinks=true,
-  linkcolor={Maroon},
-  filecolor={Maroon},
-  citecolor={Blue},
-  urlcolor={Blue},
-  pdfcreator={LaTeX via pandoc}}
-
-\title{Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models}
-\usepackage{etoolbox}
-\makeatletter
-\providecommand{\subtitle}[1]{% add subtitle to \maketitle
-  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
-}
-\makeatother
-\subtitle{Theory and Case Studies in R}
-\author{Olivier Gimenez}
-\date{2023-04-26}
-
-\begin{document}
-\maketitle
-
-%\cleardoublepage\newpage\thispagestyle{empty}\null
-%\cleardoublepage\newpage\thispagestyle{empty}\null
-%\cleardoublepage\newpage
-\thispagestyle{empty}
-
-\setlength{\abovedisplayskip}{-5pt}
-\setlength{\abovedisplayshortskip}{-5pt}
-
-{
-\hypersetup{linkcolor=}
-\setcounter{tocdepth}{2}
-\tableofcontents
-}
-\listoffigures
-\listoftables
-\hypertarget{welcome}{%
-\chapter*{Welcome}\label{welcome}}
-
-
-Welcome to the online version of the book \emph{Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models -- Theory and Case Studies in R}.
-
-The HMM framework has gained much attention in the ecological literature over the last decade, and has been suggested as a general modelling framework for the demography of plant and animal populations. In particular, HMMs are increasingly used to analyse capture-recapture data and estimate key population parameters (e.g., survival, dispersal, recruitment or abundance) with applications in all fields of ecology.
-
-In parallel, Bayesian statistics is well established and fast growing in ecology and related disciplines, because it resonates with scientific reasoning and allows accommodating uncertainty smoothly. The popularity of Bayesian statistics also comes from the availability of free pieces of software (WinBUGS, OpenBUGS, JAGS, Stan, NIMBLE) that allow practitioners to code their own analyses.
-
-This book offers a Bayesian treatment of HMMs applied to capture-recapture data. You will learn to use the R package NIMBLE which is seen by many as the future of Bayesian statistical ecology to deal with complex models and/or big data. An important part of the book consists in case studies presented in a tutorial style to abide by the ``learning by doing'' philosophy.
-
-I'm currently writing this book, and I welcome any feedback. You may raise an issue \href{https://github.com/oliviergimenez/banana-book/issues}{here}, amend directly the R Markdown file that generated the page you're reading by clicking on the `Edit this page' icon in the right panel, or \href{mailto:olivier.gimenez@cefe.cnrs.fr}{email me}. Many thanks!
-
-Olivier Gimenez, Montpellier, France\\
-Last updated: April 26, 2023
-
-\hypertarget{license}{%
-\section*{License}\label{license}}
-
-
-The online version of this book is licensed under the \href{http://creativecommons.org/licenses/by-nc-nd/4.0/}{Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License}.
-
-The code is public domain, licensed under \href{https://creativecommons.org/publicdomain/zero/1.0/}{Creative Commons CC0 1.0 Universal (CC0 1.0)}.
-
-\hypertarget{preface}{%
-\chapter*{Preface}\label{preface}}
-
-
-\hypertarget{why-this-book}{%
-\section*{Why this book?}\label{why-this-book}}
-
-
-\textbf{To be completed.} Why and what of capture-recapture data and models, with fields of application.\footnote{Watch out nice Johnny Ball's video \url{https://www.youtube.com/watch?v=tyX79mPm2xY}.} Brief history of capture-recapture, with switch to state-space/hidden Markov model (HMM) formulation. Flexibility of HMM to decompose complex problems in smaller pieces that are easier to understand, model and analyse. From satellite guidance to conservation of endangered species. Why Bayes? Also three of my fav research topics -- capture-recapture, HMM and Bayes statistics -- let's enjoy this great cocktail together.
-
-\hypertarget{who-should-read-this-book}{%
-\section*{Who should read this book?}\label{who-should-read-this-book}}
-
-
-This book is aimed at beginners who're comfortable using R and write basic code (including loops), as well as connoisseurs of capture-recapture who'd like to tap into the power of the Bayesian side of statistics. For both audiences, thinking in the HMM framework will help you in confidently building models and make the most of your capture-recapture data.
-
-\hypertarget{what-will-you-learn}{%
-\section*{What will you learn?}\label{what-will-you-learn}}
-
-
-The book is divided into five parts. The first part is aimed at getting you up-to-speed with Bayesian statistics, NIMBLE, and hidden Markov models. The second part will teach you all about capture-recapture models for open populations, with reproducible R code to ease the learning process. In the third part, we will focus on issues in inferring states (dealing with uncertainty in assignment, modelling waiting time distribution). The fourth part provides real-world case studies from the scientific literature that you can reproduce using material covered in previous chapters. These problems can either i) be used to cement and deepen your understanding of methods and models, ii) be adapted for your own purpose, or iii) serve as teaching projects. The fifth and last chapter closes the book with take-home messages and recommendations, a list of frequently asked questions and references cited in the book. \textbf{Likely to be amended after feedbacks.}
-
-\hypertarget{what-wont-you-learn}{%
-\section*{What won't you learn?}\label{what-wont-you-learn}}
-
-
-There is hardly any maths in this book. The equations I use are either simple enough to be understood without a background in maths, or can be skipped without prejudice. I do not cover Bayesian statistics or even hidden Markov models fully, I provide just what you need to work with capture-recapture data. If you are interested in knowing more about these topics, hopefully the section Suggested reading at the end of each chapter will put you in the right direction. There are also a number of important topics specific to capture-recapture that I do not cover, including closed-population capture-recapture models \citep{WilliamsEtAl2002}, and spatial capture-recapture models \citep{RoyleEtAl2013book}. These models can be treated as HMMs, but for now the usual formulation is just fine. \textbf{There will be spatial considerations in the Covariates chapter w/ splines and CAR. I'm not sure yet about SCR models (R. Glennie's Biometrics paper on HMMs and open pop SCR will not be easy to Bayes transform and implement in NIMBLE).}
-
-\hypertarget{prerequisites}{%
-\section*{Prerequisites}\label{prerequisites}}
-
-
-This book uses primarily the R package NIMBLE, so you need to install at least R and NIMBLE. A bunch of other R packages are used. You can install them all at once by running:
-
-\begin{Shaded}
-\begin{Highlighting}[]
-\FunctionTok{install.packages}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
-  \StringTok{""magick""}\NormalTok{, }\StringTok{""MCMCvis""}\NormalTok{, }\StringTok{""nimble""}\NormalTok{, }\StringTok{""pdftools""}\NormalTok{, }
-  \StringTok{""tidyverse""}\NormalTok{, }\StringTok{""wesanderson""} 
-\NormalTok{))}
-\end{Highlighting}
-\end{Shaded}
-
-\hypertarget{acknowledgements}{%
-\section*{Acknowledgements}\label{acknowledgements}}
-
-
-\textbf{To be completed.}
-
-\hypertarget{how-this-book-was-written}{%
-\section*{How this book was written}\label{how-this-book-was-written}}
-
-
-I am writing this book in \href{http://www.rstudio.com/ide/}{RStudio} using \href{http://bookdown.org/}{bookdown}. The \href{https://oliviergimenez.github.io/banana-book}{book website} is hosted with \href{https://pages.github.com/}{GitHub Pages}, and automatically updated after every push by \href{https://github.com/features/actions}{Github Actions}. The source is available from \href{https://github.com/oliviergimenez/banana-book}{GitHub}.
-
-The version of the book you're reading was built with R version 4.2.3 (2023-03-15) and the following packages:
-
-\begin{longtable}[]{@{}
-  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.1348}}
-  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.0899}}
-  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.7753}}@{}}
-\toprule()
-\begin{minipage}[b]{\linewidth}\raggedright
-package
-\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
-version
-\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
-source
-\end{minipage} \\
-\midrule()
-\endhead
-magick & 2.7.3 & CRAN (R 4.2.0) \\
-MCMCvis & 0.15.5 & CRAN (R 4.2.0) \\
-nimble & 0.12.3 & Github (nimble-dev/nimble@6992a0db8d4dca99b85fb6865094c6ac38ff3160) \\
-pdftools & 3.3.2 & CRAN (R 4.2.0) \\
-tidyverse & 1.3.2 & CRAN (R 4.2.0) \\
-wesanderson & 0.3.6 & CRAN (R 4.2.0) \\
-\bottomrule()
-\end{longtable}
-
-\hypertarget{about-the-author}{%
-\chapter*{About the author}\label{about-the-author}}
-
-
-My name is Olivier Gimenez (\url{https://oliviergimenez.github.io/}). I am a senior (euphemism for not so young anymore) scientist at the National Centre for Scientific Research (CNRS) in the beautiful city of Montpellier, France.
-
-I struggled studying maths, obtained a PhD in applied statistics a long time ago in a galaxy of wine and cheese. I was awarded my habilitation (\url{https://en.wikipedia.org/wiki/Habilitation}) in ecology and evolution so that I could stop pretending to understand what my colleagues were talking about. More recently I embarked in sociology studies because hey, why not.
-
-Lost somewhere at the interface of animal ecology, statistical modeling and social sciences, my so-called expertise lies in population dynamics and species distribution modeling to address questions in ecology and conservation biology about the impact of human activities and the management of large carnivores. I would be nothing without the students and colleagues who are kind enough to bear with me.
-
-You may find me on Twitter (\url{https://twitter.com/oaggimenez}), GitHub (\url{https://github.com/oliviergimenez}), or get in touch \href{mailto:olivier.gimenez@cefe.cnrs.fr}{by email}.
-
-\backmatter
-
-  \bibliography{book.bib}
-
-\printindex
-
-\end{document}

---FILE: docs/crashcourse.html---
@@ -1,619 +0,0 @@
-<!DOCTYPE html>
-<html lang=""en"">
-<head>
-<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
-<meta charset=""utf-8"">
-<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<title>Chapter 1 Bayesian statistics &amp; MCMC | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
-<meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""1.1 Introduction In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to..."">
-<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
-<meta property=""og:title"" content=""Chapter 1 Bayesian statistics &amp; MCMC | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta property=""og:type"" content=""book"">
-<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/crashcourse.html"">
-<meta property=""og:description"" content=""1.1 Introduction In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to..."">
-<meta name=""twitter:card"" content=""summary"">
-<meta name=""twitter:title"" content=""Chapter 1 Bayesian statistics &amp; MCMC | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta name=""twitter:description"" content=""1.1 Introduction In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to..."">
-<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
-<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
-    
-    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
-  </style>
-<style type=""text/css"">
-    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
-    div.csl-bib-body { }
-    div.csl-entry {
-      clear: both;
-        }
-    .hanging div.csl-entry {
-      margin-left:2em;
-      text-indent:-2em;
-    }
-    div.csl-left-margin {
-      min-width:2em;
-      float:left;
-    }
-    div.csl-right-inline {
-      margin-left:2em;
-      padding-left:1em;
-    }
-    div.csl-indent {
-      margin-left: 2em;
-    }
-  </style>
-<link rel=""stylesheet"" href=""bs4_style.css"">
-</head>
-<body data-spy=""scroll"" data-target=""#toc"">
-
-<div class=""container-fluid"">
-<div class=""row"">
-  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
-
-    <div class=""d-flex align-items-start justify-content-between"">
-      <h1>
-        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
-        <small class=""text-muted"">Theory and Case Studies in R</small>
-      </h1>
-      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
-    </div>
-
-    <div id=""main-nav"" class=""collapse-lg"">
-      <form role=""search"">
-        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
-</form>
-
-      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
-        <ul class=""book-toc list-unstyled"">
-<li><a class="""" href=""index.html"">Welcome</a></li>
-<li><a class="""" href=""preface.html"">Preface</a></li>
-<li><a class="""" href=""about-the-author.html"">About the author</a></li>
-<li class=""book-part"">I. Foundations</li>
-<li><a class="""" href=""introduction.html"">Introduction</a></li>
-<li><a class=""active"" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
-<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
-<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
-<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
-<li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
-<li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
-<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
-<li><a class="""" href=""references.html"">References</a></li>
-</ul>
-
-        <div class=""book-extra"">
-          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
-        </div>
-      </nav>
-</div>
-  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""crashcourse"" class=""section level1"" number=""1"">
-<h1>
-<span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC<a class=""anchor"" aria-label=""anchor"" href=""#crashcourse""><i class=""fas fa-link""></i></a>
-</h1>
-<div id=""introduction-1"" class=""section level2"" number=""1.1"">
-<h2>
-<span class=""header-section-number"">1.1</span> Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-1""><i class=""fas fa-link""></i></a>
-</h2>
-<p>In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to implement the Bayesian method for more complex analyses. This is not an exhaustive treatment of Bayesian statistics, but you should get what you need to navigate through the rest of the book.</p>
-</div>
-<div id=""bayes-theorem"" class=""section level2"" number=""1.2"">
-<h2>
-<span class=""header-section-number"">1.2</span> Bayes‚Äô theorem<a class=""anchor"" aria-label=""anchor"" href=""#bayes-theorem""><i class=""fas fa-link""></i></a>
-</h2>
-<p>Let‚Äôs not wait any longer and jump into it. Bayesian statistics relies on the Bayes‚Äô theorem (or law, or rule, whatever you prefer) named after Reverend Thomas Bayes (Figure <a href=""crashcourse.html#fig:revbayes"">1.1</a>). This theorem was published in 1763 two years after Bayes‚Äô death thanks to his friend‚Äôs efforts Richard Price, and was independently discovered by Pierre-Simon Laplace <span class=""citation"">(<a href=""references.html#ref-mcgrayne2011"">McGrayne 2011</a>)</span>.</p>
-<div class=""figure"" style=""text-align: center"">
-<span style=""display:block;"" id=""fig:revbayes""></span>
-<img src=""images/amazing-thomas-bayes-illustration.jpg"" alt=""Cartoon of Thomas Bayes with Bayes' theorem in background. Source: [James Kulich](https://www.elmhurst.edu/blog/thomas-bayes/)"" width=""100%""><p class=""caption"">
-Figure 1.1: Cartoon of Thomas Bayes with Bayes‚Äô theorem in background. Source: <a href=""https://www.elmhurst.edu/blog/thomas-bayes/"">James Kulich</a>
-</p>
-</div>
-<p>As we will see in a minute, Bayes‚Äô theorem is all about conditional probabilities, which are somehow tricky to understand. Conditional probability of outcome or event A given event B, which we denote <span class=""math inline"">\(\Pr(A \mid B)\)</span>, is the probability that A occurs, revised by considering the additional information that event B has occurred.<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;For example, a friend of yours rolls a fair dice and asks you the probability that the outcome was a six (event A). Your answer is 1/6 because each side of the dice is equally likely to come up. Now imagine that you‚Äôre told the number rolled was even (event B) before you answer your friend‚Äôs question. Because there are only three even numbers, one of which is six, you may revise your answer for the probability that a six was rolled from 1/6 to &lt;span class=""math inline""&gt;\(\Pr(A \mid B) = 1/3\)&lt;/span&gt;.&lt;/p&gt;'><sup>2</sup></a> The order in which A and B appear is important, make sure you do not confuse <span class=""math inline"">\(\Pr(A \mid B)\)</span> and <span class=""math inline"">\(\Pr(B \mid A)\)</span>.</p>
-<p>Bayes‚Äô theorem (Figure <a href=""crashcourse.html#fig:bayestheorem"">1.2</a>) gives you <span class=""math inline"">\(\Pr(A \mid B)\)</span> using marginal probabilities <span class=""math inline"">\(\Pr(A)\)</span> and <span class=""math inline"">\(\Pr(B)\)</span> and <span class=""math inline"">\(\Pr(B \mid A)\)</span>:
-<span class=""math display"">\[\Pr(A \mid B) = \displaystyle{\frac{ \Pr(B \mid A) \; \Pr(A)}{\Pr(B)}}.\]</span>
-Originally, Bayes‚Äô theorem was seen as a way to infer an unkown cause A of a particular effect B, knowing the probability of effect B given cause A. Think for example of a situation where a medical diagnosis is needed, with A an unkown disease and B symptoms, the doctor knows P(symptoms|disease) and wants to derive P(disease|symptoms). This way of reversing <span class=""math inline"">\(\Pr(B \mid A)\)</span> into <span class=""math inline"">\(\Pr(A \mid B)\)</span> explains why Bayesian thinking used to be referred to as ‚Äòinverse probability‚Äô.</p>
-<div class=""figure"" style=""text-align: center"">
-<span style=""display:block;"" id=""fig:bayestheorem""></span>
-<img src=""images/bayes_neon.jpeg"" alt=""Bayes' theorem spelt out in blue neon. Source: [Wikipedia](https://en.wikipedia.org/wiki/Bayes%27_theorem)"" width=""400""><p class=""caption"">
-Figure 1.2: Bayes‚Äô theorem spelt out in blue neon. Source: <a href=""https://en.wikipedia.org/wiki/Bayes%27_theorem"">Wikipedia</a>
-</p>
-</div>
-<p>I don‚Äôt know about you, but I need to think twice for not messing the letters around. I find it easier to remember Bayes‚Äô theorem written like this<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;When teaching Bayes‚Äô theorem, I am very much inspired by Tristan Mahr‚Äôs slides from his introduction to Bayesian regression &lt;a href=""https://www.tjmahr.com/bayes-intro-lecture-slides-2017/"" class=""uri""&gt;https://www.tjmahr.com/bayes-intro-lecture-slides-2017/&lt;/a&gt;&lt;/p&gt;'><sup>3</sup></a>:</p>
-<span class=""math display"">\[ \Pr(\text{hypothesis} \mid \text{data}) = \frac{ \Pr(\text{data} \mid \text{hypothesis}) \; \Pr(\text{hypothesis})}{\Pr(\text{data})} \]</span>
-
-<div class=""rmdnote"">
-The <em>hypothesis</em> is a working assumption about which you want to learn using <em>data</em>. In capture‚Äìrecapture analyses, the hypothesis might be a parameter like detection probability, or regression parameters in a relationship between survival probability and a covariate. Bayes‚Äô theorem tells us how to obtain the probability of a hypothesis given the data we have.
-</div>
-<p>This is great because think about it, this is exactly what the scientific method is! We‚Äôd like to know how plausible some hypothesis is based on some data we collected, and possibly compare several hypotheses among them. In that respect, the Bayesian reasoning matches the scientific reasoning, which probably explains why the Bayesian framework is so natural for doing and understanding statistics.</p>
-<p>You might ask then, why is Bayesian statistics not the default in statistics? Clearly, because of futile wars between male statisticians (including Ronald Fisher, Jerzy Neyman and Egon Sharpe Pearson among others), little progress was made for over two centuries. Also, until recently, there were practical problems to implement Bayes‚Äô theorem. Recent advances in computational power coupled with the development of new algorithms have led to a great increase in the application of Bayesian methods within the last three decades.</p>
-</div>
-<div id=""what-is-the-bayesian-approach"" class=""section level2"" number=""1.3"">
-<h2>
-<span class=""header-section-number"">1.3</span> What is the Bayesian approach?<a class=""anchor"" aria-label=""anchor"" href=""#what-is-the-bayesian-approach""><i class=""fas fa-link""></i></a>
-</h2>
-<p>Typical statistical problems involve estimating a parameter (or several parameters) <span class=""math inline"">\(\theta\)</span> with available data. To do so, you might be more used to the frequentist rather than the Bayesian method. The frequentist approach, and in particular maximum likelihood estimation (MLE), assumes that the parameters are fixed, and have unknown values to be estimated. Therefore classical estimates are generally point estimates of the parameters of interest. In contrast, the Bayesian approach assumes that the parameters are not fixed, and have some unknown distribution<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;A probability distribution is a mathematical expression that gives the probability for a random variable to take particular values. A probability distribution may be either discrete (e.g., the Bernoulli, Binomial or Poisson distribution) or continuous (e.g., the Gaussian distribution also known as the normal distribution)&lt;/p&gt;""><sup>4</sup></a>.</p>
-<p>The Bayesian approach is based upon the idea that you, as an experimenter, begin with some prior beliefs about the system. Then you collect data and update your prior beliefs on the basis of observations. These observations might arise from field work, lab work or from expertise of your esteemed colleagues. This updating process is based upon Bayes‚Äô theorem. Loosely, let‚Äôs say <span class=""math inline"">\(A = \theta\)</span> and <span class=""math inline"">\(B = \text{data}\)</span>, then Bayes‚Äô theorem gives you a way to estimate parameter <span class=""math inline"">\(\theta\)</span> given the data you have:</p>
-<p><span class=""math display"">\[{\color{red}{\Pr(\theta \mid \text{data})}} = \frac{\color{blue}{\Pr(\text{data} \mid \theta)} \times \color{green}{\Pr(\theta)}}{\color{orange}{\Pr(\text{data})}}.\]</span>
-Let‚Äôs spend some time going through each quantity in this formula.</p>
-<p>On the left-hand side is the <span class=""math inline"">\(\color{red}{\text{posterior distribution}}\)</span>. It represents what you know after having seen the data. This is the basis for inference and clearly what you‚Äôre after, a distribution, possibly multivariate if you have more than one parameter.</p>
-<p>On the right-hand side, there is the <span class=""math inline"">\(\color{blue}{\text{likelihood}}\)</span>. This quantity is the same as in the MLE approach. Yes, the Bayesian and frequentist approaches have the same likelihood at their core, which mostly explains why results often do not differ much. The likelihood captures the information you have in your data, given a model parameterized with <span class=""math inline"">\(\theta\)</span>.</p>
-<p>Then we have the <span class=""math inline"">\(\color{green}{\text{prior distribution}}\)</span>. This quantity represents what you know before seeing the data. This is the source of much discussion about the Bayesian approach. It may be vague if you don‚Äôt know anything about <span class=""math inline"">\(\theta\)</span>. Usually however, you never start from scratch, and you‚Äôd like your prior to reflect the information you have<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;Shall I include a section on sensitivity analyses in this chapter or later in the book? Cross-reference section in Survival chapter where prior elicitation is covered.&lt;/p&gt;""><sup>5</sup></a>.</p>
-<p>Last, we have <span class=""math inline"">\(\color{orange}{\Pr(\text{data})}\)</span> which is sometimes called the average likelihood because it is obtained by integrating the likelihood with respect to the prior <span class=""math inline"">\(\color{orange}{\Pr(\text{data}) = \int{L(\text{data} \mid \theta)\Pr(\theta) d\theta}}\)</span> so that the posterior is standardized, that is it integrates to one for the posterior to be a distribution. The average likelihood is an integral with dimension the number of parameters <span class=""math inline"">\(\theta\)</span> you need to estimate. This quantity is difficult, if not impossible, to calculate in general. This is one of the reasons why the Bayesian method wasn‚Äôt used until recently, and why we need algorithms to estimate posterior distributions as I illustrate in the next section.</p>
-</div>
-<div id=""numerical-approx"" class=""section level2"" number=""1.4"">
-<h2>
-<span class=""header-section-number"">1.4</span> Approximating posteriors via numerical integration<a class=""anchor"" aria-label=""anchor"" href=""#numerical-approx""><i class=""fas fa-link""></i></a>
-</h2>
-<p>Let‚Äôs take an example to illustrate Bayes‚Äô theorem. Say we capture, mark and release <span class=""math inline"">\(n = 57\)</span> animals at the beginning of a winter, out of which we recapture <span class=""math inline"">\(y = 19\)</span> animals alive<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;We used a similar example in &lt;span class=""citation""&gt;King et al. (&lt;a href=""references.html#ref-king_bayesian_2009""&gt;2009&lt;/a&gt;)&lt;/span&gt;&lt;/p&gt;'><sup>6</sup></a>. We‚Äôd like to estimate winter survival <span class=""math inline"">\(\theta\)</span>.</p>
-<div class=""sourceCode"" id=""cb2""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span><span class=""va"">y</span> <span class=""op"">&lt;-</span> <span class=""fl"">19</span> <span class=""co""># nb of success</span></span>
-<span><span class=""va"">n</span> <span class=""op"">&lt;-</span> <span class=""fl"">57</span> <span class=""co""># nb of attempts</span></span></code></pre></div>
-<p>We build our model first. Assuming all animals are independent of each other and have the same survival probability, then <span class=""math inline"">\(y\)</span> the number of alive animals at the end of the winter is a binomial distribution<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;I follow &lt;span class=""citation""&gt;McElreath (&lt;a href=""references.html#ref-mcelreathbook""&gt;2016&lt;/a&gt;)&lt;/span&gt; and use labels on the right to help remember what each line is about.&lt;/p&gt;'><sup>7</sup></a> with <span class=""math inline"">\(n\)</span> trials and <span class=""math inline"">\(\theta\)</span> the probability of success:</p>
-<p><span class=""math display"">\[\begin{align*}
-y &amp;\sim \text{Binomial}(n, \theta) &amp;\text{[likelihood]}
-\end{align*}\]</span></p>
-<p>This likelihood can be visualised in <code>R</code>:</p>
-<div class=""sourceCode"" id=""cb3""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span><span class=""va"">grid</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/seq.html"">seq</a></span><span class=""op"">(</span><span class=""fl"">0</span>, <span class=""fl"">1</span>, <span class=""fl"">0.01</span><span class=""op"">)</span> <span class=""co""># grid of values for survival</span></span>
-<span><span class=""va"">likelihood</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Binomial.html"">dbinom</a></span><span class=""op"">(</span><span class=""va"">y</span>, <span class=""va"">n</span>, <span class=""va"">grid</span><span class=""op"">)</span> <span class=""co""># compute binomial likelihood</span></span>
-<span><span class=""va"">df</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/data.frame.html"">data.frame</a></span><span class=""op"">(</span>survival <span class=""op"">=</span> <span class=""va"">grid</span>, likelihood <span class=""op"">=</span> <span class=""va"">likelihood</span><span class=""op"">)</span> </span>
-<span><span class=""va"">df</span> <span class=""op"">%&gt;%</span></span>
-<span>  <span class=""fu"">ggplot</span><span class=""op"">(</span><span class=""op"">)</span> <span class=""op"">+</span> </span>
-<span>  <span class=""fu"">aes</span><span class=""op"">(</span>x <span class=""op"">=</span> <span class=""va"">survival</span>, y <span class=""op"">=</span> <span class=""va"">likelihood</span><span class=""op"">)</span> <span class=""op"">+</span> </span>
-<span>  <span class=""fu"">geom_line</span><span class=""op"">(</span>size <span class=""op"">=</span> <span class=""fl"">1.5</span><span class=""op"">)</span></span></code></pre></div>
-<div class=""figure"">
-<span style=""display:block;"" id=""fig:binlik""></span>
-<img src=""banana-book_files/figure-html/binlik-1.png"" alt=""Binomial likelihood with $n = 57$ released animals and $y = 19$ survivors after winter. The value of survival (on the x-axis) that corresponds to the maximum of the likelihood function (on the y-axis) is the MLE, or the proportion of success in this example, close to 0.33."" width=""672""><p class=""caption"">
-Figure 1.3: Binomial likelihood with <span class=""math inline"">\(n = 57\)</span> released animals and <span class=""math inline"">\(y = 19\)</span> survivors after winter. The value of survival (on the x-axis) that corresponds to the maximum of the likelihood function (on the y-axis) is the MLE, or the proportion of success in this example, close to 0.33.
-</p>
-</div>
-<p>Besides the likelihood, priors are another component of the model in the Bayesian approach. For a parameter that is a probability, the one thing we know is that the prior should be a continuous random variable that lies between 0 and 1. To reflect that, we often go for the uniform distribution <span class=""math inline"">\(U(0,1)\)</span> to imply <em>vague</em> priors. Here vague means that survival has, before we see the data, the same probability of falling between 0.1 and 0.2 and between 0.8 and 0.9, for example.</p>
-<p><span class=""math display"">\[\begin{align*}
-\theta &amp;\sim \text{Uniform}(0, 1) &amp;\text{[prior for }\theta \text{]}
-\end{align*}\]</span></p>
-<p>Now we apply Bayes‚Äô theorem. We write a <code>R</code> function that computes the product of the likelihood times the prior, or the numerator in Bayes‚Äô theorem: <span class=""math inline"">\(\Pr(\text{data} \mid \theta) \times \Pr(\theta)\)</span></p>
-<div class=""sourceCode"" id=""cb4""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span><span class=""va"">numerator</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">theta</span><span class=""op"">)</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Binomial.html"">dbinom</a></span><span class=""op"">(</span><span class=""va"">y</span>, <span class=""va"">n</span>, <span class=""va"">theta</span><span class=""op"">)</span> <span class=""op"">*</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Uniform.html"">dunif</a></span><span class=""op"">(</span><span class=""va"">theta</span>, <span class=""fl"">0</span>, <span class=""fl"">1</span><span class=""op"">)</span></span></code></pre></div>
-<p>We write another function that calculates the denominator, the average likelihood: <span class=""math inline"">\(\Pr(\text{data}) = \int{L(\theta \mid \text{data}) \Pr(\theta) d\theta}\)</span></p>
-<div class=""sourceCode"" id=""cb5""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span><span class=""va"">denominator</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/integrate.html"">integrate</a></span><span class=""op"">(</span><span class=""va"">numerator</span>,<span class=""fl"">0</span>,<span class=""fl"">1</span><span class=""op"">)</span><span class=""op"">$</span><span class=""va"">value</span></span></code></pre></div>
-<p>We use the <code>R</code> function <code>integrate</code> to calculate the integral in the denominator, which implements quadrature techniques to divide in little squares the area underneath the curve delimited by the function to integrate (here the numerator), and count them.</p>
-<p>Then we get a numerical approximation of the posterior in Figure <a href=""crashcourse.html#fig:numapprox"">1.4</a> by applying Bayes‚Äô theorem.</p>
-<div class=""sourceCode"" id=""cb6""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span><span class=""va"">grid</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/seq.html"">seq</a></span><span class=""op"">(</span><span class=""fl"">0</span>, <span class=""fl"">1</span>, <span class=""fl"">0.01</span><span class=""op"">)</span> <span class=""co""># grid of values for theta</span></span>
-<span><span class=""va"">numerical_posterior</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/data.frame.html"">data.frame</a></span><span class=""op"">(</span>survival <span class=""op"">=</span> <span class=""va"">grid</span>, </span>
-<span>                                  posterior <span class=""op"">=</span> <span class=""fu"">numerator</span><span class=""op"">(</span><span class=""va"">grid</span><span class=""op"">)</span><span class=""op"">/</span><span class=""va"">denominator</span><span class=""op"">)</span> <span class=""co""># Bayes' theorem</span></span>
-<span><span class=""va"">numerical_posterior</span> <span class=""op"">%&gt;%</span></span>
-<span>  <span class=""fu"">ggplot</span><span class=""op"">(</span><span class=""op"">)</span> <span class=""op"">+</span></span>
-<span>  <span class=""fu"">aes</span><span class=""op"">(</span>x <span class=""op"">=</span> <span class=""va"">survival</span>, y <span class=""op"">=</span> <span class=""va"">posterior</span><span class=""op"">)</span> <span class=""op"">+</span> </span>
-<span>  <span class=""fu"">geom_line</span><span class=""op"">(</span>size <span class=""op"">=</span> <span class=""fl"">1.5</span><span class=""op"">)</span></span></code></pre></div>
-<div class=""figure"">
-<span style=""display:block;"" id=""fig:numapprox""></span>
-<img src=""banana-book_files/figure-html/numapprox-1.png"" alt=""Winter survival posterior distribution obtained by numerical integration."" width=""672""><p class=""caption"">
-Figure 1.4: Winter survival posterior distribution obtained by numerical integration.
-</p>
-</div>
-<p>How good is our numerical approximation of survival posterior distribution? Ideally, we would want to compare the approximation to the true posterior distribution. Although a closed-form expression for the posterior distribution is in general intractable, when you combine a binomial likelihood together with a beta distribution as a prior, then the posterior distribution is also a beta distribution, which makes it amenable to all sorts of exact calculations<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;We say that the beta distribution is the conjugate prior distribution for the binomial distribution.&lt;/p&gt;""><sup>8</sup></a>. The beta distribution is continuous between 0 and 1, and extends the uniform distribution to situations where not all outcomes are equally likely. It has two parameters <span class=""math inline"">\(a\)</span> and <span class=""math inline"">\(b\)</span> that control its shape (Figure <a href=""crashcourse.html#fig:betadistribution"">1.5</a>).</p>
-
-<div class=""figure"">
-<span style=""display:block;"" id=""fig:betadistribution""></span>
-<img src=""banana-book_files/figure-html/betadistribution-1.png"" alt=""The distribution beta(\(a\),\(b\)) for different values of \(a\) and \(b\). Note that for \(a = b = 1\), we get the uniform distribution between 0 and 1 in the top left panel. When \(a\) and \(b\) are equal, the distribution is symmetric, and the bigger \(a\) and \(b\), the more peaked the distribution or the smaller the variance."" width=""672""><p class=""caption"">
-Figure 1.5: The distribution beta(<span class=""math inline"">\(a\)</span>,<span class=""math inline"">\(b\)</span>) for different values of <span class=""math inline"">\(a\)</span> and <span class=""math inline"">\(b\)</span>. Note that for <span class=""math inline"">\(a = b = 1\)</span>, we get the uniform distribution between 0 and 1 in the top left panel. When <span class=""math inline"">\(a\)</span> and <span class=""math inline"">\(b\)</span> are equal, the distribution is symmetric, and the bigger <span class=""math inline"">\(a\)</span> and <span class=""math inline"">\(b\)</span>, the more peaked the distribution or the smaller the variance.
-</p>
-</div>
-If the likelihood of the data <span class=""math inline"">\(y\)</span> is binomial with <span class=""math inline"">\(n\)</span> trials and probability of success <span class=""math inline"">\(\theta\)</span>, and the prior is a beta distribution with parameters <span class=""math inline"">\(a\)</span> and <span class=""math inline"">\(b\)</span>, then the posterior is a beta distribution with parameters <span class=""math inline"">\(a + y\)</span> and <span class=""math inline"">\(b + n - y\)</span><a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;&lt;strong&gt;provide a sketch of the proof&lt;/strong&gt;&lt;/p&gt;""><sup>9</sup></a>. In our example, we have <span class=""math inline"">\(n = 57\)</span> trials and <span class=""math inline"">\(y = 19\)</span> animals that survived and a uniform prior between 0 and 1 or a beta distribution with parameters <span class=""math inline"">\(a = b = 1\)</span>, therefore survival has a beta posterior distribution with parameters 20 and 39. In Figure <a href=""crashcourse.html#fig:compar"">1.6</a>, we superimpose the exact posterior and the numerical approximation. Clearly, the two distributions are indistinguishable, suggesting that the numerical approximation is more than fine.
-<div class=""figure"">
-<span style=""display:block;"" id=""fig:compar""></span>
-<img src=""banana-book_files/figure-html/compar-1.png"" alt=""Comparison of exact (dashed line) vs. numerical approximation (continuous line) of winter survival posterior distribution."" width=""672""><p class=""caption"">
-Figure 1.6: Comparison of exact (dashed line) vs.¬†numerical approximation (continuous line) of winter survival posterior distribution.
-</p>
-</div>
-<!-- To finish up, let's add the prior.  -->
-<!-- ```{r, echo = FALSE} -->
-<!-- ggplot() +  -->
-<!--   geom_line(data = numerical_posterior,  -->
-<!--             aes(x = survival, y = posterior),  -->
-<!--             size = 1.5,  -->
-<!--             col = wesanderson::wes_palettes$Royal1[2],  -->
-<!--             alpha = 0.5) +  -->
-<!--   geom_line(data = dfexpposterior,  -->
-<!--             aes(x = survival, y = explicit_posterior), -->
-<!--             col = wesanderson::wes_palettes$Royal1[3],  -->
-<!--             size = 1.5,  -->
-<!--             linetype = ""dashed"") +  -->
-<!--   geom_line(data = dfprior, -->
-<!--             aes(x = survival, y = prior), -->
-<!--             col = wesanderson::wes_palettes$Royal1[1], -->
-<!--             size = 1.5) -->
-<!-- ``` -->
-<p>In our example, we have a single parameter to estimate, winter survival. This means dealing with a one-dimensional integral in the denominator which is pretty easy with quadrature techniques and the <code>R</code> function <code><a href=""https://rdrr.io/r/stats/integrate.html"">integrate()</a></code>. Now what if we had multiple parameters? For example, imagine you‚Äôd like to fit a capture-recapture model with detection probability <span class=""math inline"">\(p\)</span> and regression parameters <span class=""math inline"">\(\alpha\)</span> and <span class=""math inline"">\(\beta\)</span> for the intercept and slope of a relationship between survival probability and a covariate, then Bayes‚Äô theorem gives you the posterior distribution of all three parameters together:</p>
-<p><span class=""math display"">\[ \Pr(\alpha, \beta, p \mid \text{data}) = \frac{ \Pr(\text{data} \mid \alpha, \beta, p) \times \Pr(\alpha, \beta, p)}{\iiint \, \Pr(\text{data} \mid \alpha, \beta, p) \Pr(\alpha, \beta, p) d\alpha d\beta dp} \]</span>
-There are two computational challenges with this formula. First, do we really wish to calculate a three-dimensional integral? The answer is no, one-dimensional and two-dimensional integrals are so much further we can go with standard methods. Second, we‚Äôre more interested in a posterior distribution for each parameter separately than the joint posterior distribution. The so-called marginal distribution of <span class=""math inline"">\(p\)</span> for example is obtained by integrating over all the other parameters ‚Äì a two-dimensional integral in this example. Now imagine with tens or hundreds of parameters to estimate, these integrals become highly multi-dimensional and simply intractable. In the next section, I introduce powerful simulation methods to circumvent this issue.</p>
-</div>
-<div id=""markov-chain-monte-carlo-mcmc"" class=""section level2"" number=""1.5"">
-<h2>
-<span class=""header-section-number"">1.5</span> Markov chain Monte Carlo (MCMC)<a class=""anchor"" aria-label=""anchor"" href=""#markov-chain-monte-carlo-mcmc""><i class=""fas fa-link""></i></a>
-</h2>
-<p>In the early 1990s, statisticians rediscovered work from the 1950‚Äôs in physics. In a famous paper that would lay the fundations of modern Bayesian statistics (Figure <a href=""crashcourse.html#fig:mcmcpaper"">1.7</a>), the authors use simulations to approximate posterior distributions with some precision by drawing large samples. This is a neat trick to avoid explicit calculation of the multi-dimensional integrals we struggle with when using Bayes‚Äô theorem.</p>
-<div class=""figure"" style=""text-align: center"">
-<span style=""display:block;"" id=""fig:mcmcpaper""></span>
-<img src=""images/metropolis.png"" alt=""MCMC article cover. Source: [The Journal of Chemical Physics](https://aip.scitation.org/doi/10.1063/1.1699114)"" width=""582""><p class=""caption"">
-Figure 1.7: MCMC article cover. Source: <a href=""https://aip.scitation.org/doi/10.1063/1.1699114"">The Journal of Chemical Physics</a>
-</p>
-</div>
-<p>These simulation algorithms are called Markov chain Monte Carlo (MCMC), and they definitely gave a boost to Bayesian statistics. There are two parts in MCMC, Markov chain and Monte Carlo, let‚Äôs try and make sense of these terms.</p>
-<div id=""monte-carlo-integration"" class=""section level3"" number=""1.5.1"">
-<h3>
-<span class=""header-section-number"">1.5.1</span> Monte Carlo integration<a class=""anchor"" aria-label=""anchor"" href=""#monte-carlo-integration""><i class=""fas fa-link""></i></a>
-</h3>
-<p>What does Monte Carlo stand for? Monte Carlo integration is a simulation technique to calculate integrals of any function <span class=""math inline"">\(f\)</span> of random variable <span class=""math inline"">\(X\)</span> with distribution <span class=""math inline"">\(\Pr(X)\)</span> say <span class=""math inline"">\(\int f(X) \Pr(X)dX\)</span>. You draw values <span class=""math inline"">\(X_1,\ldots,X_k\)</span> from <span class=""math inline"">\(\Pr(X)\)</span> the distribution of <span class=""math inline"">\(X\)</span>, apply function <span class=""math inline"">\(f\)</span> to these values, then calculate the mean of these new values <span class=""math inline"">\(\displaystyle{\frac{1}{k}}\sum_{i=1}^k{f(X_i)}\)</span> to approximate the integral. How is Monte Carlo integration used in a Bayesian context? The posterior distribution contains all the information we need about the parameter to be estimated. When dealing with many parameters however, you may want to summarise posterior results by calculating numerical summaries. The simplest numerical summary is the mean of the posterior distribution, <span class=""math inline"">\(E(\theta) = \int \theta \Pr(\theta|\text{data})\)</span>, where <span class=""math inline"">\(X\)</span> is <span class=""math inline"">\(\theta\)</span> now and <span class=""math inline"">\(f\)</span> is the identity function. Posterior mean can be calculated with Monte Carlo integration:</p>
-<div class=""sourceCode"" id=""cb7""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span><span class=""va"">sample_from_posterior</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Beta.html"">rbeta</a></span><span class=""op"">(</span><span class=""fl"">1000</span>, <span class=""fl"">20</span>, <span class=""fl"">39</span><span class=""op"">)</span> <span class=""co""># draw 1000 values from posterior survival beta(20,39)</span></span>
-<span><span class=""fu""><a href=""https://rdrr.io/r/base/mean.html"">mean</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span><span class=""op"">)</span> <span class=""co""># compute mean with Monte Carlo integration</span></span>
-<span><span class=""co"">## [1] 0.3398</span></span></code></pre></div>
-<p>You may check that the mean we have just calculated matches closely the expectation of a beta distribution<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;If &lt;span class=""math inline""&gt;\(X\)&lt;/span&gt; is a random variable with distribution &lt;span class=""math inline""&gt;\(\text{beta}(a, b)\)&lt;/span&gt;, then &lt;span class=""math inline""&gt;\(E(X) = \displaystyle{\frac{a}{a + b}}\)&lt;/span&gt;&lt;/p&gt;'><sup>10</sup></a>:</p>
-<div class=""sourceCode"" id=""cb8""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span><span class=""fl"">20</span><span class=""op"">/</span><span class=""op"">(</span><span class=""fl"">20</span><span class=""op"">+</span><span class=""fl"">39</span><span class=""op"">)</span> <span class=""co""># expectation of beta(20,39)</span></span>
-<span><span class=""co"">## [1] 0.339</span></span></code></pre></div>
-<p>Another useful numerical summary is the credible interval within which our parameter falls with some probability, usually 0.95 hence a 95<span class=""math inline"">\(\%\)</span> credible interval. Finding the bounds of a credible interval requires calculating quantiles, which in turn involves integrals and the use of Monte Carlo integration. A 95<span class=""math inline"">\(\%\)</span> credible interval for winter survival can be obtained in <code>R</code> with:</p>
-<div class=""sourceCode"" id=""cb9""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span><span class=""fu""><a href=""https://rdrr.io/r/stats/quantile.html"">quantile</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span>, probs <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/c.html"">c</a></span><span class=""op"">(</span><span class=""fl"">2.5</span><span class=""op"">/</span><span class=""fl"">100</span>, <span class=""fl"">97.5</span><span class=""op"">/</span><span class=""fl"">100</span><span class=""op"">)</span><span class=""op"">)</span></span>
-<span><span class=""co"">##   2.5%  97.5% </span></span>
-<span><span class=""co"">## 0.2319 0.4583</span></span></code></pre></div>
-</div>
-<div id=""markovmodelmcmc"" class=""section level3"" number=""1.5.2"">
-<h3>
-<span class=""header-section-number"">1.5.2</span> Markov chains<a class=""anchor"" aria-label=""anchor"" href=""#markovmodelmcmc""><i class=""fas fa-link""></i></a>
-</h3>
-<p>What is a Markov chain? A Markov chain is a random sequence of numbers, in which each number depends only on the previous number. An example is the weather in my home town in Southern France, Montpellier, in which a sunny day is most likely to be followed by another sunny day, say with probability 0.8, and a rainy day is rarely followed by another rainy day, say with probability 0.1. The dynamic of this Markov chain is captured by the transition matrix <span class=""math inline"">\(\mathbf{\Gamma}\)</span>:
-<span class=""math display"">\[
-\begin{matrix}
-&amp; \\
-\mathbf{\Gamma} =
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    \text{sunny tomorrow} &amp; \text{rainy tomorrow} \\
-0.8 &amp; 0.2 \\
-0.9 &amp; 0.1 \\
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-&amp; \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    \text{sunny today} \\ \text{rainy today}
-    \end{matrix}
-\end{matrix}
-\]</span>
-In rows the weather today, and in columns the weather tomorrow. The cells give the probability of a sunny or rainy day tomorrow, given the day is sunny or rainy today. Under certain conditions<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;The Markov chain is irreducible and aperiodic.&lt;/p&gt;""><sup>11</sup></a>, a Markov chain will converge to a unique stationary distribution. In our weather example, let‚Äôs run the Markov chain for 20 steps:</p>
-<div class=""sourceCode"" id=""cb10""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span><span class=""va"">weather</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/matrix.html"">matrix</a></span><span class=""op"">(</span><span class=""fu""><a href=""https://rdrr.io/r/base/c.html"">c</a></span><span class=""op"">(</span><span class=""fl"">0.8</span>, <span class=""fl"">0.2</span>, <span class=""fl"">0.9</span>, <span class=""fl"">0.1</span><span class=""op"">)</span>, nrow <span class=""op"">=</span> <span class=""fl"">2</span>, byrow <span class=""op"">=</span> <span class=""cn"">T</span><span class=""op"">)</span> <span class=""co""># transition matrix</span></span>
-<span><span class=""va"">steps</span> <span class=""op"">&lt;-</span> <span class=""fl"">20</span></span>
-<span><span class=""kw"">for</span> <span class=""op"">(</span><span class=""va"">i</span> <span class=""kw"">in</span> <span class=""fl"">1</span><span class=""op"">:</span><span class=""va"">steps</span><span class=""op"">)</span><span class=""op"">{</span></span>
-<span>  <span class=""va"">weather</span> <span class=""op"">&lt;-</span> <span class=""va"">weather</span> <span class=""op""><a href=""https://rdrr.io/r/base/matmult.html"">%*%</a></span> <span class=""va"">weather</span> <span class=""co""># matrix multiplication</span></span>
-<span><span class=""op"">}</span></span>
-<span><span class=""fu""><a href=""https://rdrr.io/r/base/Round.html"">round</a></span><span class=""op"">(</span><span class=""va"">weather</span>, <span class=""fl"">2</span><span class=""op"">)</span> <span class=""co""># matrix product after 20 steps</span></span>
-<span><span class=""co"">##      [,1] [,2]</span></span>
-<span><span class=""co"">## [1,] 0.82 0.18</span></span>
-<span><span class=""co"">## [2,] 0.82 0.18</span></span></code></pre></div>
-<p>Each row of the transition matrix converges to the same distribution <span class=""math inline"">\((0.82, 0.18)\)</span> as the number of steps increases. Convergence happens no matter which state you start in, and you always have probability 0.82 of the day being sunny and 0.18 of the day being rainy.</p>
-<p>Back to MCMC, the core idea is that you can build a Markov chain with a given stationary distribution set to be the desired posterior distribution.</p>
-
-<div class=""rmdnote"">
-Putting Monte Carlo and Markov chains together, MCMC allows us to generate a sample of values (Markov chain) whose distribution converges to the posterior distribution, and we can use this sample of values to calculate any posterior summaries (Monte Carlo), such as posterior means and credible intervals.
-</div>
-</div>
-<div id=""metropolis-algorithm"" class=""section level3"" number=""1.5.3"">
-<h3>
-<span class=""header-section-number"">1.5.3</span> Metropolis algorithm<a class=""anchor"" aria-label=""anchor"" href=""#metropolis-algorithm""><i class=""fas fa-link""></i></a>
-</h3>
-<p>There are several ways of constructing Markov chains for Bayesian inference<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;You might have heard about the Metropolis-Hastings or the Gibbs sampler. Have a look to &lt;a href=""https://github.com/chi-feng/mcmc-demo"" class=""uri""&gt;https://github.com/chi-feng/mcmc-demo&lt;/a&gt; for an interactive gallery of MCMC algorithms.&lt;/p&gt;'><sup>12</sup></a>. Here I illustrate the Metropolis algorithm and how to implement it in practice<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;This presentation is largely inspired by &lt;span class=""citation""&gt;Albert and Hu (&lt;a href=""references.html#ref-alberthu2019""&gt;2019&lt;/a&gt;)&lt;/span&gt;&lt;/p&gt;'><sup>13</sup></a>.</p>
-<p>Let‚Äôs go back to our example on animal survival estimation. We illustrate sampling from survival posterior distribution. We write functions for likelihood, prior and posterior.</p>
-<div class=""sourceCode"" id=""cb11""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span><span class=""co""># 19 animals recaptured alive out of 57 captured, marked and released</span></span>
-<span><span class=""va"">survived</span> <span class=""op"">&lt;-</span> <span class=""fl"">19</span></span>
-<span><span class=""va"">released</span> <span class=""op"">&lt;-</span> <span class=""fl"">57</span></span>
-<span></span>
-<span><span class=""co""># binomial log-likelihood function</span></span>
-<span><span class=""va"">loglikelihood</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">x</span>, <span class=""va"">p</span><span class=""op"">)</span><span class=""op"">{</span></span>
-<span>  <span class=""fu""><a href=""https://rdrr.io/r/stats/Binomial.html"">dbinom</a></span><span class=""op"">(</span>x <span class=""op"">=</span> <span class=""va"">x</span>, size <span class=""op"">=</span> <span class=""va"">released</span>, prob <span class=""op"">=</span> <span class=""va"">p</span>, log <span class=""op"">=</span> <span class=""cn"">TRUE</span><span class=""op"">)</span></span>
-<span><span class=""op"">}</span></span>
-<span></span>
-<span><span class=""co""># uniform prior density</span></span>
-<span><span class=""va"">logprior</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">p</span><span class=""op"">)</span><span class=""op"">{</span></span>
-<span>  <span class=""fu""><a href=""https://rdrr.io/r/stats/Uniform.html"">dunif</a></span><span class=""op"">(</span>x <span class=""op"">=</span> <span class=""va"">p</span>, min <span class=""op"">=</span> <span class=""fl"">0</span>, max <span class=""op"">=</span> <span class=""fl"">1</span>, log <span class=""op"">=</span> <span class=""cn"">TRUE</span><span class=""op"">)</span></span>
-<span><span class=""op"">}</span></span>
-<span></span>
-<span><span class=""co""># posterior density function (log scale)</span></span>
-<span><span class=""va"">posterior</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">x</span>, <span class=""va"">p</span><span class=""op"">)</span><span class=""op"">{</span></span>
-<span>  <span class=""fu"">loglikelihood</span><span class=""op"">(</span><span class=""va"">x</span>, <span class=""va"">p</span><span class=""op"">)</span> <span class=""op"">+</span> <span class=""fu"">logprior</span><span class=""op"">(</span><span class=""va"">p</span><span class=""op"">)</span> <span class=""co""># - log(Pr(data))</span></span>
-<span><span class=""op"">}</span></span></code></pre></div>
-<p>The Metropolis algorithm works as follows:</p>
-<ol style=""list-style-type: decimal"">
-<li><p>We pick a value of the parameter to be estimated. This is where we start our Markov chain ‚Äì this is a <em>starting</em> value.</p></li>
-<li><p>To decide where to go next, we propose to move away from the current value of the parameter ‚Äì this is a <em>candidate</em> value. To do so, we add to the current value some random value from e.g.¬†a normal distribution with some variance ‚Äì this is a <em>proposal</em> distribution. The Metropolis algorithm is a particular case of the Metropolis-Hastings algorithm with symmetric proposals.</p></li>
-<li><p>We compute the ratio of the probabilities at the candidate and current locations <span class=""math inline"">\(R=\displaystyle{\frac{{\Pr(\text{candidate}|\text{data})}}{{\Pr(\text{current}|\text{data})}}}\)</span>. This is where the magic of MCMC happens, in that <span class=""math inline"">\(\Pr(\text{data})\)</span>, the denominator in the Bayes‚Äô theorem, appears in both the numerator and the denominator in <span class=""math inline"">\(R\)</span> therefore cancels out and does not need to be calculated.</p></li>
-</ol>
-<!-- -- *the Hastings ratio* --><ol start=""4"" style=""list-style-type: decimal"">
-<li><p>If the posterior at the candidate location <span class=""math inline"">\(\Pr(\text{candidate}|\text{data})\)</span> is higher than at the current location <span class=""math inline"">\(\Pr(\text{current}|\text{data})\)</span>, in other words when the candidate value is more plausible than the current value, we definitely accept the candidate value. If not, then we accept the candidate value with probability <span class=""math inline"">\(R\)</span> and reject with probability <span class=""math inline"">\(1-R\)</span>. For example, if the candidate value is ten times less plausible than the current value, then we accept with probability 0.1 and reject with probability 0.9. How does it work in practice? We use a continuous spinner that lands somewhere between 0 and 1 ‚Äì call the random spin <span class=""math inline"">\(X\)</span>. If <span class=""math inline"">\(X\)</span> is smaller than <span class=""math inline"">\(R\)</span>, we move to the candidate location, otherwise we remain at the current location. We do not want to accept or reject too often. In practice, the Metropolis algorithm should have an acceptance probability between 0.2 and 0.4, which can be achieved by <em>tuning</em> the variance of the normal proposal distribution.</p></li>
-<li><p>We repeat 2-4 a number of times ‚Äì or <em>steps</em>.</p></li>
-</ol>
-<p>Enough of the theory, let‚Äôs implement the Metropolis algorithm in <code>R</code>. Let‚Äôs start by setting the scene.</p>
-<div class=""sourceCode"" id=""cb12""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span><span class=""va"">steps</span> <span class=""op"">&lt;-</span> <span class=""fl"">100</span> <span class=""co""># number of steps</span></span>
-<span><span class=""va"">theta.post</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/rep.html"">rep</a></span><span class=""op"">(</span><span class=""cn"">NA</span>, <span class=""va"">steps</span><span class=""op"">)</span> <span class=""co""># vector to store samples</span></span>
-<span><span class=""va"">accept</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/rep.html"">rep</a></span><span class=""op"">(</span><span class=""cn"">NA</span>, <span class=""va"">steps</span><span class=""op"">)</span> <span class=""co""># keep track of accept/reject</span></span>
-<span><span class=""fu""><a href=""https://rdrr.io/r/base/Random.html"">set.seed</a></span><span class=""op"">(</span><span class=""fl"">1234</span><span class=""op"">)</span> <span class=""co""># for reproducibility</span></span></code></pre></div>
-<p>Now follow the 5 steps we‚Äôve just described. First, we pick a starting value, and store it (step 1).</p>
-<div class=""sourceCode"" id=""cb13""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span><span class=""va"">inits</span> <span class=""op"">&lt;-</span> <span class=""fl"">0.5</span></span>
-<span><span class=""va"">theta.post</span><span class=""op"">[</span><span class=""fl"">1</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""va"">inits</span></span>
-<span><span class=""va"">accept</span><span class=""op"">[</span><span class=""fl"">1</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""fl"">1</span></span></code></pre></div>
-<p>Then, we need a function to propose a candidate value. We add a value taken from a normal distribution with mean zero and standard deviation we call <em>away</em>. We work on the logit scale to make sure the candidate value for survival lies between 0 and 1.</p>
-<div class=""sourceCode"" id=""cb14""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span><span class=""va"">move</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">x</span>, <span class=""va"">away</span> <span class=""op"">=</span> <span class=""fl"">1</span><span class=""op"">)</span><span class=""op"">{</span> <span class=""co""># by default, standard deviation of the proposal distribution is 1</span></span>
-<span>  <span class=""va"">logitx</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/Log.html"">log</a></span><span class=""op"">(</span><span class=""va"">x</span> <span class=""op"">/</span> <span class=""op"">(</span><span class=""fl"">1</span> <span class=""op"">-</span> <span class=""va"">x</span><span class=""op"">)</span><span class=""op"">)</span> <span class=""co""># apply logit transform (-infinity,+infinity)</span></span>
-<span>  <span class=""va"">logit_candidate</span> <span class=""op"">&lt;-</span> <span class=""va"">logitx</span> <span class=""op"">+</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Normal.html"">rnorm</a></span><span class=""op"">(</span><span class=""fl"">1</span>, <span class=""fl"">0</span>, <span class=""va"">away</span><span class=""op"">)</span> <span class=""co""># add a value taken from N(0,sd=away) to current value</span></span>
-<span>  <span class=""va"">candidate</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Logistic.html"">plogis</a></span><span class=""op"">(</span><span class=""va"">logit_candidate</span><span class=""op"">)</span> <span class=""co""># back-transform (0,1)</span></span>
-<span>  <span class=""kw""><a href=""https://rdrr.io/r/base/function.html"">return</a></span><span class=""op"">(</span><span class=""va"">candidate</span><span class=""op"">)</span></span>
-<span><span class=""op"">}</span></span></code></pre></div>
-<p>Now we‚Äôre ready for steps 2, 3 and 4. We write a loop to take care of step 5. We start at initial value 0.5 and run the algorithm for 100 steps or iterations.</p>
-<div class=""sourceCode"" id=""cb15""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span><span class=""kw"">for</span> <span class=""op"">(</span><span class=""va"">t</span> <span class=""kw"">in</span> <span class=""fl"">2</span><span class=""op"">:</span><span class=""va"">steps</span><span class=""op"">)</span><span class=""op"">{</span> <span class=""co""># repeat steps 2-4 (step 5)</span></span>
-<span>  </span>
-<span>  <span class=""co""># propose candidate value for survival (step 2)</span></span>
-<span>  <span class=""va"">theta_star</span> <span class=""op"">&lt;-</span> <span class=""fu"">move</span><span class=""op"">(</span><span class=""va"">theta.post</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">-</span><span class=""fl"">1</span><span class=""op"">]</span><span class=""op"">)</span></span>
-<span>  </span>
-<span>  <span class=""co""># calculate ratio R (step 3)</span></span>
-<span>  <span class=""va"">pstar</span> <span class=""op"">&lt;-</span> <span class=""fu"">posterior</span><span class=""op"">(</span><span class=""va"">survived</span>, p <span class=""op"">=</span> <span class=""va"">theta_star</span><span class=""op"">)</span>  </span>
-<span>  <span class=""va"">pprev</span> <span class=""op"">&lt;-</span> <span class=""fu"">posterior</span><span class=""op"">(</span><span class=""va"">survived</span>, p <span class=""op"">=</span> <span class=""va"">theta.post</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">-</span><span class=""fl"">1</span><span class=""op"">]</span><span class=""op"">)</span></span>
-<span>  <span class=""va"">logR</span> <span class=""op"">&lt;-</span> <span class=""va"">pstar</span> <span class=""op"">-</span> <span class=""va"">pprev</span> <span class=""co""># likelihood and prior are on the log scale</span></span>
-<span>  <span class=""va"">R</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/Log.html"">exp</a></span><span class=""op"">(</span><span class=""va"">logR</span><span class=""op"">)</span></span>
-<span>  </span>
-<span>  <span class=""co""># accept candidate value or keep current value (step 4)</span></span>
-<span>  <span class=""va"">X</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Uniform.html"">runif</a></span><span class=""op"">(</span><span class=""fl"">1</span>, <span class=""fl"">0</span>, <span class=""fl"">1</span><span class=""op"">)</span> <span class=""co""># spin continuous spinner</span></span>
-<span>  <span class=""kw"">if</span> <span class=""op"">(</span><span class=""va"">X</span> <span class=""op"">&lt;</span> <span class=""va"">R</span><span class=""op"">)</span><span class=""op"">{</span></span>
-<span>    <span class=""va"">theta.post</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""va"">theta_star</span> <span class=""co""># accept candidate value</span></span>
-<span>    <span class=""va"">accept</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""fl"">1</span> <span class=""co""># accept</span></span>
-<span>  <span class=""op"">}</span></span>
-<span>  <span class=""kw"">else</span><span class=""op"">{</span></span>
-<span>    <span class=""va"">theta.post</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""va"">theta.post</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">-</span><span class=""fl"">1</span><span class=""op"">]</span> <span class=""co""># keep current value</span></span>
-<span>    <span class=""va"">accept</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""fl"">0</span> <span class=""co""># reject</span></span>
-<span>  <span class=""op"">}</span></span>
-<span><span class=""op"">}</span></span></code></pre></div>
-<p>We get the following values.</p>
-<div class=""sourceCode"" id=""cb16""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span><span class=""fu""><a href=""https://rdrr.io/r/utils/head.html"">head</a></span><span class=""op"">(</span><span class=""va"">theta.post</span><span class=""op"">)</span> <span class=""co""># first values</span></span>
-<span><span class=""co"">## [1] 0.5000 0.2302 0.2906 0.2906 0.2980 0.2980</span></span>
-<span><span class=""fu""><a href=""https://rdrr.io/r/utils/head.html"">tail</a></span><span class=""op"">(</span><span class=""va"">theta.post</span><span class=""op"">)</span> <span class=""co""># last values</span></span>
-<span><span class=""co"">## [1] 0.2622 0.2622 0.2622 0.3727 0.3232 0.3862</span></span></code></pre></div>
-Visually, you may look at the chain in Figure <a href=""crashcourse.html#fig:chain"">1.8</a> called a trace plot.
-<div class=""figure"" style=""text-align: center"">
-<span style=""display:block;"" id=""fig:chain""></span>
-<img src=""banana-book_files/figure-html/chain-1.png"" alt=""Visualisation of a Markov chain starting at value 0.5, with steps or iterations on the x-axis, and samples on the y-axis. This graphical representation is called a trace plot."" width=""672""><p class=""caption"">
-Figure 1.8: Visualisation of a Markov chain starting at value 0.5, with steps or iterations on the x-axis, and samples on the y-axis. This graphical representation is called a trace plot.
-</p>
-</div>
-<p>The acceptance probability is the average number of times we accepted a candidated value, which is 0.44 and almost satisfying.</p>
-Can we run another chain and start at initial value 0.2 this time? Yes, just go through the same algorithm again, and visualise the results in Figure <a href=""crashcourse.html#fig:twochains"">1.9</a>.
-<div class=""figure"" style=""text-align: center"">
-<span style=""display:block;"" id=""fig:twochains""></span>
-<img src=""banana-book_files/figure-html/twochains-1.png"" alt=""Trace plot of survival for two chains starting at 0.2 (yellow) and 0.5 (blue) run for 100 steps."" width=""672""><p class=""caption"">
-Figure 1.9: Trace plot of survival for two chains starting at 0.2 (yellow) and 0.5 (blue) run for 100 steps.
-</p>
-</div>
-Notice that we do not get the exact same results because the algorithm is stochastic. The question is to know whether we have reached the stationary distribution. Let‚Äôs increase the number of steps and run a chain with 5000 iterations as in Figure <a href=""crashcourse.html#fig:longchain"">1.10</a>.
-<div class=""figure"" style=""text-align: center"">
-<span style=""display:block;"" id=""fig:longchain""></span>
-<img src=""banana-book_files/figure-html/longchain-1.png"" alt=""Trace plot of survival for a chain starting at 0.5 and 1000 steps."" width=""672""><p class=""caption"">
-Figure 1.10: Trace plot of survival for a chain starting at 0.5 and 1000 steps.
-</p>
-</div>
-<p>This is what we‚Äôre after, a trace plot that looks like a beautiful lawn, see Section <a href=""crashcourse.html#convergence-diag"">1.6</a>. I find it informative to look at the animated version of Figure <a href=""crashcourse.html#fig:longchain"">1.10</a>, it helps understanding the stochastic behavior of the algorithm, and also to realise how the chains converge to their stationary distribution, see Figure <a href=""crashcourse.html#fig:animlongchain"">1.11</a>.</p>
-<div class=""figure"" style=""text-align: center"">
-<span style=""display:block;"" id=""fig:animlongchain""></span>
-<img src=""images/traceplotMCMC.gif"" alt=""Animated trace plot of survival with three chains starting at 0.2, 0.5 and 0.7 run for 1000 steps."" width=""100%""><p class=""caption"">
-Figure 1.11: Animated trace plot of survival with three chains starting at 0.2, 0.5 and 0.7 run for 1000 steps.
-</p>
-</div>
-<p>Once the stationary distribution is reached, you may regard the realisations of the Markov chain as a sample from the posterior distribution, and obtain numerical summaries. In the next section, we consider several important implementation issues.</p>
-</div>
-</div>
-<div id=""convergence-diag"" class=""section level2"" number=""1.6"">
-<h2>
-<span class=""header-section-number"">1.6</span> Assessing convergence<a class=""anchor"" aria-label=""anchor"" href=""#convergence-diag""><i class=""fas fa-link""></i></a>
-</h2>
-
-<div class=""rmdnote"">
-When implementing MCMC, we need to determine how long it takes for our Markov chain to converge to the target distribution, and the number of iterations we need after achieving convergence to get reasonable Monte Carlo estimates of numerical summaries (posterior means and credible intervals).
-</div>
-<div id=""burn-in"" class=""section level3"" number=""1.6.1"">
-<h3>
-<span class=""header-section-number"">1.6.1</span> Burn-in<a class=""anchor"" aria-label=""anchor"" href=""#burn-in""><i class=""fas fa-link""></i></a>
-</h3>
-<p>In practice, we discard observations from the start of the Markov chain and just use observations from the chain once it has converged. The initial observations that we discard are usually referred to as the <em>burn-in</em>.</p>
-<p>The simplest method to determine the length of the burn-in period is to look at trace plots. Going back to our example, we see from the trace plot in Figure <a href=""crashcourse.html#fig:burnin"">1.12</a> that we need at least 100 iterations to achieve convergence toward an average survival around 0.3. It is always better to be conservative when specifying the length of the burn-in period, and in this example, we would use 250 or even 500 iterations as a burn-in. The length of the burn-in period can be determined by performing preliminary MCMC short runs.</p>
-<div class=""figure"">
-<span style=""display:block;"" id=""fig:burnin""></span>
-<img src=""banana-book_files/figure-html/burnin-1.png"" alt=""Determining the length of the burn-in period. The chain starts at value 0.99 and rapidly stabilises, with values bouncing back and forth around 0.3 from the 100th iteration onwards. You may choose the shaded area as the burn-in, and discard the corresponding values."" width=""672""><p class=""caption"">
-Figure 1.12: Determining the length of the burn-in period. The chain starts at value 0.99 and rapidly stabilises, with values bouncing back and forth around 0.3 from the 100th iteration onwards. You may choose the shaded area as the burn-in, and discard the corresponding values.
-</p>
-</div>
-<p>Inspecting the trace plot for a single run of the Markov chain is useful. However, we usually run the Markov chain several times, starting from different over-dispersed points, to check that all runs achieve the same stationary distribution. This approach is formalised by using the Brooks-Gelman-Rubin (BGR) statistic <span class=""math inline"">\(\hat{R}\)</span> which measures the ratio of the total variability combining multiple chains (between-chain plus within-chain) to the within-chain variability. The BGR statistic asks whether there is a chain effect, and is very much alike the <span class=""math inline"">\(F\)</span> test in an analysis of variance. Values below 1.1 indicate likely convergence.</p>
-<p>Back to our example, we run two Markov chains with starting values 0.2 and 0.8 using 100 up to 5000 iterations, and calculate the BGR statistic using half the number of iterations as the length of the burn-in. From Figure <a href=""crashcourse.html#fig:bgr"">1.13</a>, we get a value of the BGR statistic near 1 by up to 2000 iterations, which suggests that with 2000 iterations as a burn-in, there is no evidence of a lack of convergence.</p>
-<div class=""figure"">
-<span style=""display:block;"" id=""fig:bgr""></span>
-<img src=""banana-book_files/figure-html/bgr-1.png"" alt=""Brooks-Gelman-Rubin statistic as a function of the number of iterations."" width=""672""><p class=""caption"">
-Figure 1.13: Brooks-Gelman-Rubin statistic as a function of the number of iterations.
-</p>
-</div>
-<p>It is important to bear in mind that a value near 1 for the BGR statistic is only a necessary <em>but not sufficient</em> condition for convergence. In other words, this diagnostic cannot tell you for sure that the Markov chain has achieved convergence, only that it has not.<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;Cross-reference sections on local minima and parameter redundancy for pathological cases.&lt;/p&gt;""><sup>14</sup></a></p>
-</div>
-<div id=""chain-length"" class=""section level3"" number=""1.6.2"">
-<h3>
-<span class=""header-section-number"">1.6.2</span> Chain length<a class=""anchor"" aria-label=""anchor"" href=""#chain-length""><i class=""fas fa-link""></i></a>
-</h3>
-<p>How long of a chain is needed to produce reliable parameter estimates? To answer this question, you need to keep in mind that successive steps in a Markov chain are not independent ‚Äì this is usually referred to as <em>autocorrelation</em>. Ideally, we would like to keep autocorrelation as low as possible. Here again, trace plots are useful to diagnose issues with autocorrelation. Let‚Äôs get back to our survival example. Figure <a href=""crashcourse.html#fig:tracechainlength"">1.14</a> shows trace plots for different values of the standard deviation (parameter <em>away</em>) of the (normal) proposal distribution we use to propose a candidate value (Section <a href=""crashcourse.html#metropolis-algorithm"">1.5.3</a>). Small and big moves provide high correlations between successive observations of the Markov chain, whereas a standard deviation of 1 allows efficient exploration of the parameter space. The movement around the parameter space is referred to as <em>mixing</em>. Mixing is bad when the chain makes small and big moves, and good otherwise.</p>
-<div class=""figure"">
-<span style=""display:block;"" id=""fig:tracechainlength""></span>
-<img src=""banana-book_files/figure-html/tracechainlength-1.png"" alt=""Trace plots for different values of the standard deviation (SD) of the proposal distribution. Left: The chain exhibits small moves and mixing is bad. Right: The chain exhibits big moves and mixing is bad. Middle: The chain exhibits adequate moves and mixing is good. Only the thousand last iterations are shown."" width=""672""><p class=""caption"">
-Figure 1.14: Trace plots for different values of the standard deviation (SD) of the proposal distribution. Left: The chain exhibits small moves and mixing is bad. Right: The chain exhibits big moves and mixing is bad. Middle: The chain exhibits adequate moves and mixing is good. Only the thousand last iterations are shown.
-</p>
-</div>
-<p>In addition to trace plots, autocorrelation function (ACF) plots are a convenient way of displaying the strength of autocorrelation in a given sample values. ACF plots provide the autocorrelation between successively sampled values separated by an increasing number of iterations, or <em>lag</em> (Figure <a href=""crashcourse.html#fig:acfchainlength"">1.15</a>).</p>
-<div class=""figure"">
-<span style=""display:block;"" id=""fig:acfchainlength""></span>
-<img src=""banana-book_files/figure-html/acfchainlength-1.png"" alt=""Autocorrelation function plots for different values of the standard deviation (SD) of the proposal distribution. Left and right: Autocorrelation is strong, decreases slowly with increasing lag and mixing is bad. Middle: Autocorrelation is weak, decreases rapidly with increasing lag and mixing is good."" width=""672""><p class=""caption"">
-Figure 1.15: Autocorrelation function plots for different values of the standard deviation (SD) of the proposal distribution. Left and right: Autocorrelation is strong, decreases slowly with increasing lag and mixing is bad. Middle: Autocorrelation is weak, decreases rapidly with increasing lag and mixing is good.
-</p>
-</div>
-<p>Autocorrelation is not necessarily a big issue. Strongly correlated observations just require large sample sizes and therefore longer simulations. But how many iterations exactly? The effective sample size (<code>n.eff</code>) measures chain length while taking into account chain autocorrelation. You should check the <code>n.eff</code> of every parameter of interest, and of any interesting parameter combinations. In general, we need <span class=""math inline"">\(\text{n.eff} \geq 1000\)</span> independent steps to get reasonable Monte Carlo estimates of model parameters. In the animal survival example, <code>n.eff</code> can be calculated with the R <code><a href=""https://rdrr.io/pkg/coda/man/effectiveSize.html"">coda::effectiveSize()</a></code> function.</p>
-<div class=""inline-table""><table class=""table table-sm"">
-<thead><tr class=""header"">
-<th align=""right"">Proposal SD</th>
-<th align=""right"">n.eff</th>
-</tr></thead>
-<tbody>
-<tr class=""odd"">
-<td align=""right"">0.1</td>
-<td align=""right"">224</td>
-</tr>
-<tr class=""even"">
-<td align=""right"">1.0</td>
-<td align=""right"">1934</td>
-</tr>
-<tr class=""odd"">
-<td align=""right"">10.0</td>
-<td align=""right"">230</td>
-</tr>
-</tbody>
-</table></div>
-<p>As expected, <code>n.eff</code> is less than the number of MCMC iterations because of autocorrelation. Only when the standard deviation of the proposal distribution is 1 and mixing is good (Figures <a href=""crashcourse.html#fig:tracechainlength"">1.14</a> and <a href=""crashcourse.html#fig:acfchainlength"">1.15</a>) we get a satisfying effective sample size.</p>
-</div>
-<div id=""what-if-you-have-issues-of-convergence"" class=""section level3"" number=""1.6.3"">
-<h3>
-<span class=""header-section-number"">1.6.3</span> What if you have issues of convergence?<a class=""anchor"" aria-label=""anchor"" href=""#what-if-you-have-issues-of-convergence""><i class=""fas fa-link""></i></a>
-</h3>
-<p>When diagnosing MCMC convergence, you will (very) often run into troubles. In this section you will find some helpful tips I hope.</p>
-<p>When mixing is bad and effective sample size is small, you may just need to increase burn-in and/or sample more. Using more informative priors might also make Markov chains converge faster by helping your MCMC sampler (e.g.¬†the Metropolis algorithm) navigating more efficiently the parameter space. In the same spirit, picking better initial values for starting the chain does not harm. For doing that, a strategy consists in using estimates from a simpler model for which your MCMC chains do converge.</p>
-<p>If convergence issues persist, often there is a problem with your model<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;The quote ‚ÄòWhen you have computational problems, often there‚Äôs a problem with your model‚Äô is the folk theorem of statistical computing stated by Andrew Gelman in 2008, see &lt;a href=""https://statmodeling.stat.columbia.edu/2008/05/13/the_folk_theore/"" class=""uri""&gt;https://statmodeling.stat.columbia.edu/2008/05/13/the_folk_theore/&lt;/a&gt;&lt;/p&gt;'><sup>15</sup></a>. A bug in the code? A typo somewhere? A mistake in your maths? As often when coding is involved, the issue can be identified by removing complexities, and start with a simpler model until you find what the problem is.</p>
-<p>A general advice is to see your model as a data generating tool in the first place, simulate data from it using some realistic values for the parameters, and try to recover these parameter values by fitting the model to the simulated data. Simulating from a model will help you understanding how it works, what it does not do, and the data you need to get reasonable parameter estimates.</p>
-<p>We will see other strategies to improve convergence in the next chapters.<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;Cross reference relevant chapters. Option 1. Change your sampler. Option 2. Reparameterize (standardize covariates, plus non-centering: &lt;span class=""math inline""&gt;\(\alpha \sim N(0,\sigma)\)&lt;/span&gt; becomes &lt;span class=""math inline""&gt;\(\alpha = z \sigma\)&lt;/span&gt; with &lt;span class=""math inline""&gt;\(z \sim N(0,1)\)&lt;/span&gt;).&lt;/p&gt;'><sup>16</sup></a></p>
-</div>
-</div>
-<div id=""summary"" class=""section level2"" number=""1.7"">
-<h2>
-<span class=""header-section-number"">1.7</span> Summary<a class=""anchor"" aria-label=""anchor"" href=""#summary""><i class=""fas fa-link""></i></a>
-</h2>
-<ul>
-<li><p>With the Bayes‚Äô theorem, you update your beliefs (prior) with new data (likelihood) to get posterior beliefs (posterior): posterior <span class=""math inline"">\(\propto\)</span> likelihood <span class=""math inline"">\(\times\)</span> prior.</p></li>
-<li><p>The idea of Markov chain Monte Carlo (MCMC) is to simulate values from a Markov chain which has a stationary distribution equal to the posterior distribution you‚Äôre after.</p></li>
-<li><p>In practice, you run a Markov chain multiple times starting from over-dispersed initial values.</p></li>
-<li><p>You discard iterations in an initial burn-in phase and achieve convergence when all chains reach the same regime.</p></li>
-<li><p>From there, you run the chains long enough and proceed with calculating Monte Carlo estimates of numerical summaries (e.g.¬†posterior means and credible intervals) for parameters.</p></li>
-</ul>
-</div>
-<div id=""suggested-reading"" class=""section level2"" number=""1.8"">
-<h2>
-<span class=""header-section-number"">1.8</span> Suggested reading<a class=""anchor"" aria-label=""anchor"" href=""#suggested-reading""><i class=""fas fa-link""></i></a>
-</h2>
-<ul>
-<li><p>Gelman, A. and Hill, J. (2006). <a href=""https://www.cambridge.org/core/books/data-analysis-using-regression-and-multilevelhierarchical-models/32A29531C7FD730C3A68951A17C9D983"">Data Analysis Using Regression and Multilevel/Hierarchical Models (Analytical Methods for Social Research)</a>. Cambridge: Cambridge University Press.</p></li>
-<li><p>Gelman, A. and colleagues (2020). <a href=""https://arxiv.org/pdf/2011.01808.pdf"">Bayesian workflow</a>. arXiv preprint.</p></li>
-<li><p>McCarthy, M. (2007). <a href=""https://www.cambridge.org/core/books/bayesian-methods-for-ecology/9225F65B8A25D69B0B6C50B5A9A78201"">Bayesian Methods for Ecology</a>. Cambridge: Cambridge University Press.</p></li>
-<li><p>McElreath, R. (2020). <a href=""https://xcelab.net/rm/statistical-rethinking/"">Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2nd ed.)</a>. CRC Press.</p></li>
-</ul>
-</div>
-</div>
-
-  <div class=""chapter-nav"">
-<div class=""prev""><a href=""introduction.html"">Introduction</a></div>
-<div class=""next""><a href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></div>
-</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
-    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
-      <ul class=""nav navbar-nav"">
-<li><a class=""nav-link"" href=""#crashcourse""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
-<li><a class=""nav-link"" href=""#introduction-1""><span class=""header-section-number"">1.1</span> Introduction</a></li>
-<li><a class=""nav-link"" href=""#bayes-theorem""><span class=""header-section-number"">1.2</span> Bayes‚Äô theorem</a></li>
-<li><a class=""nav-link"" href=""#what-is-the-bayesian-approach""><span class=""header-section-number"">1.3</span> What is the Bayesian approach?</a></li>
-<li><a class=""nav-link"" href=""#numerical-approx""><span class=""header-section-number"">1.4</span> Approximating posteriors via numerical integration</a></li>
-<li>
-<a class=""nav-link"" href=""#markov-chain-monte-carlo-mcmc""><span class=""header-section-number"">1.5</span> Markov chain Monte Carlo (MCMC)</a><ul class=""nav navbar-nav"">
-<li><a class=""nav-link"" href=""#monte-carlo-integration""><span class=""header-section-number"">1.5.1</span> Monte Carlo integration</a></li>
-<li><a class=""nav-link"" href=""#markovmodelmcmc""><span class=""header-section-number"">1.5.2</span> Markov chains</a></li>
-<li><a class=""nav-link"" href=""#metropolis-algorithm""><span class=""header-section-number"">1.5.3</span> Metropolis algorithm</a></li>
-</ul>
-</li>
-<li>
-<a class=""nav-link"" href=""#convergence-diag""><span class=""header-section-number"">1.6</span> Assessing convergence</a><ul class=""nav navbar-nav"">
-<li><a class=""nav-link"" href=""#burn-in""><span class=""header-section-number"">1.6.1</span> Burn-in</a></li>
-<li><a class=""nav-link"" href=""#chain-length""><span class=""header-section-number"">1.6.2</span> Chain length</a></li>
-<li><a class=""nav-link"" href=""#what-if-you-have-issues-of-convergence""><span class=""header-section-number"">1.6.3</span> What if you have issues of convergence?</a></li>
-</ul>
-</li>
-<li><a class=""nav-link"" href=""#summary""><span class=""header-section-number"">1.7</span> Summary</a></li>
-<li><a class=""nav-link"" href=""#suggested-reading""><span class=""header-section-number"">1.8</span> Suggested reading</a></li>
-</ul>
-
-      <div class=""book-extra"">
-        <ul class=""list-unstyled"">
-<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/bayesmcmc.Rmd"">View source <i class=""fab fa-github""></i></a></li>
-          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/bayesmcmc.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
-        </ul>
-</div>
-    </nav>
-</div>
-
-</div>
-</div> <!-- .container -->
-
-<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-12.</p>
-  </div>
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
-  </div>
-
-</div></div>
-</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
-  (function () {
-    var script = document.createElement(""script"");
-    script.type = ""text/javascript"";
-    var src = ""true"";
-    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
-    if (location.protocol !== ""file:"")
-      if (/^https?:/.test(src))
-        src = src.replace(/^https?:/, '');
-    script.src = src;
-    document.getElementsByTagName(""head"")[0].appendChild(script);
-  })();
-</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
-for (let popover of popovers) {
-  const div = document.createElement('div');
-  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
-  div.innerHTML = popover.getAttribute('data-content');
-
-  var has_math = div.querySelector(""span.math"");
-  if (has_math) {
-    document.body.appendChild(div);
-    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
-    MathJax.Hub.Queue(function() {
-      popover.setAttribute('data-content', div.innerHTML);
-      document.body.removeChild(div);
-    })
-  }
-}
-</script>
-</body>
-</html>

---FILE: docs/faq.html---
@@ -1,168 +0,0 @@
-<!DOCTYPE html>
-<html lang=""en"">
-<head>
-<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
-<meta charset=""utf-8"">
-<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<title>FAQ | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
-<meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
-<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
-<meta property=""og:title"" content=""FAQ | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta property=""og:type"" content=""book"">
-<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/faq.html"">
-<meta property=""og:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
-<meta name=""twitter:card"" content=""summary"">
-<meta name=""twitter:title"" content=""FAQ | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta name=""twitter:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
-<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
-<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
-    
-    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
-  </style>
-<style type=""text/css"">
-    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
-    div.csl-bib-body { }
-    div.csl-entry {
-      clear: both;
-        }
-    .hanging div.csl-entry {
-      margin-left:2em;
-      text-indent:-2em;
-    }
-    div.csl-left-margin {
-      min-width:2em;
-      float:left;
-    }
-    div.csl-right-inline {
-      margin-left:2em;
-      padding-left:1em;
-    }
-    div.csl-indent {
-      margin-left: 2em;
-    }
-  </style>
-<link rel=""stylesheet"" href=""bs4_style.css"">
-</head>
-<body data-spy=""scroll"" data-target=""#toc"">
-
-<div class=""container-fluid"">
-<div class=""row"">
-  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
-
-    <div class=""d-flex align-items-start justify-content-between"">
-      <h1>
-        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
-        <small class=""text-muted"">Theory and Case Studies in R</small>
-      </h1>
-      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
-    </div>
-
-    <div id=""main-nav"" class=""collapse-lg"">
-      <form role=""search"">
-        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
-</form>
-
-      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
-        <ul class=""book-toc list-unstyled"">
-<li><a class="""" href=""index.html"">Welcome</a></li>
-<li><a class="""" href=""preface.html"">Preface</a></li>
-<li><a class="""" href=""about-the-author.html"">About the author</a></li>
-<li class=""book-part"">I. Foundations</li>
-<li><a class="""" href=""introduction.html"">Introduction</a></li>
-<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
-<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
-<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
-<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Dispersal</a></li>
-<li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">6</span> State uncertainty</a></li>
-<li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-6.html"">Introduction</a></li>
-<li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
-<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
-<li><a class=""active"" href=""faq.html"">FAQ</a></li>
-<li><a class="""" href=""references.html"">References</a></li>
-</ul>
-
-        <div class=""book-extra"">
-          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
-        </div>
-      </nav>
-</div>
-  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""faq"" class=""section level1 unnumbered"">
-<h1>FAQ<a class=""anchor"" aria-label=""anchor"" href=""#faq""><i class=""fas fa-link""></i></a>
-</h1>
-<!-- Below is the _complete_ list of frequently asked questions (FAQ). Yes, there is only one question here. Personally I do not like FAQs. They often mean surprises, and surprises are not good for software users. -->
-<!-- 1. Q: Will **bookdown** have the features X, Y, and Z? -->
-<!--     A: The short answer is no, but if you have asked yourself three times ""do I really need them"" and the answer is still ""yes"", please feel free to file a feature request to https://github.com/rstudio/bookdown/issues. -->
-<!--     Users asking for more features often come from the LaTeX world. If that is the case for you, the answer to this question is yes, because Pandoc's Markdown supports raw LaTeX code. Whenever you feel Markdown cannot do the job for you, you always have the option to apply some raw LaTeX code in your Markdown document. For example, you can create glossaries using the **glossaries** package, or embed a complicated LaTeX table, as long as you know the LaTeX syntax. However, please keep in mind that the LaTeX content is not portable. It will only work for LaTeX/PDF output, and will be ignored in other types of output. Depending on the request, we may port a few more LaTeX features into **bookdown** in the future, but our general philosophy is that Markdown should be kept as simple as possible. -->
-<!-- The most challenging thing in the world is not to learn fancy technologies, but control your own wild heart. -->
-
-</div>
-  <div class=""chapter-nav"">
-<div class=""prev""><a href=""take-home-messages.html"">Take-home messages</a></div>
-<div class=""next""><a href=""references.html"">References</a></div>
-</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
-    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
-      <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#faq"">FAQ</a></li></ul>
-
-      <div class=""book-extra"">
-        <ul class=""list-unstyled"">
-<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/faq.Rmd"">View source <i class=""fab fa-github""></i></a></li>
-          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/faq.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
-        </ul>
-</div>
-    </nav>
-</div>
-
-</div>
-</div> <!-- .container -->
-
-<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-11.</p>
-  </div>
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
-  </div>
-
-</div></div>
-</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
-  (function () {
-    var script = document.createElement(""script"");
-    script.type = ""text/javascript"";
-    var src = ""true"";
-    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
-    if (location.protocol !== ""file:"")
-      if (/^https?:/.test(src))
-        src = src.replace(/^https?:/, '');
-    script.src = src;
-    document.getElementsByTagName(""head"")[0].appendChild(script);
-  })();
-</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
-for (let popover of popovers) {
-  const div = document.createElement('div');
-  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
-  div.innerHTML = popover.getAttribute('data-content');
-
-  var has_math = div.querySelector(""span.math"");
-  if (has_math) {
-    document.body.appendChild(div);
-    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
-    MathJax.Hub.Queue(function() {
-      popover.setAttribute('data-content', div.innerHTML);
-      document.body.removeChild(div);
-    })
-  }
-}
-</script>
-</body>
-</html>

---FILE: docs/index.html---
@@ -73,17 +73,13 @@ <h1>
 <li><a class="""" href=""about-the-author.html"">About the author</a></li>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
-<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
-<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
-<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
-<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
+<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">1</span> Survival</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>

---FILE: docs/individual-dependence.html---
@@ -1,180 +0,0 @@
-<!DOCTYPE html>
-<html lang=""en"">
-<head>
-<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
-<meta charset=""utf-8"">
-<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<title>Chapter 4 Individual dependence | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
-<meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""4.1 Dependence among individuals Culina et al. (2013) and Cubaynes et al. (2021)  4.2 Individual heterogeneity Cubaynes et al. (2010), Gimenez and Choquet (2010), and Turek, Wehrhahn, and Gimenez..."">
-<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
-<meta property=""og:title"" content=""Chapter 4 Individual dependence | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta property=""og:type"" content=""book"">
-<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/individual-dependence.html"">
-<meta property=""og:description"" content=""4.1 Dependence among individuals Culina et al. (2013) and Cubaynes et al. (2021)  4.2 Individual heterogeneity Cubaynes et al. (2010), Gimenez and Choquet (2010), and Turek, Wehrhahn, and Gimenez..."">
-<meta name=""twitter:card"" content=""summary"">
-<meta name=""twitter:title"" content=""Chapter 4 Individual dependence | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta name=""twitter:description"" content=""4.1 Dependence among individuals Culina et al. (2013) and Cubaynes et al. (2021)  4.2 Individual heterogeneity Cubaynes et al. (2010), Gimenez and Choquet (2010), and Turek, Wehrhahn, and Gimenez..."">
-<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
-<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
-    
-    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
-  </style>
-<style type=""text/css"">
-    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
-    div.csl-bib-body { }
-    div.csl-entry {
-      clear: both;
-        }
-    .hanging div.csl-entry {
-      margin-left:2em;
-      text-indent:-2em;
-    }
-    div.csl-left-margin {
-      min-width:2em;
-      float:left;
-    }
-    div.csl-right-inline {
-      margin-left:2em;
-      padding-left:1em;
-    }
-    div.csl-indent {
-      margin-left: 2em;
-    }
-  </style>
-<link rel=""stylesheet"" href=""bs4_style.css"">
-</head>
-<body data-spy=""scroll"" data-target=""#toc"">
-
-<div class=""container-fluid"">
-<div class=""row"">
-  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
-
-    <div class=""d-flex align-items-start justify-content-between"">
-      <h1>
-        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
-        <small class=""text-muted"">Theory and Case Studies in R</small>
-      </h1>
-      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
-    </div>
-
-    <div id=""main-nav"" class=""collapse-lg"">
-      <form role=""search"">
-        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
-</form>
-
-      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
-        <ul class=""book-toc list-unstyled"">
-<li><a class="""" href=""index.html"">Welcome</a></li>
-<li><a class="""" href=""preface.html"">Preface</a></li>
-<li><a class="""" href=""about-the-author.html"">About the author</a></li>
-<li class=""book-part"">I. Foundations</li>
-<li><a class="""" href=""introduction.html"">Introduction</a></li>
-<li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
-<li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
-<li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
-<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">1</span> Life history theory</a></li>
-<li><a class="""" href=""abundance.html""><span class=""header-section-number"">2</span> Abundance</a></li>
-<li><a class="""" href=""stopover.html""><span class=""header-section-number"">3</span> Stopover duration</a></li>
-<li><a class=""active"" href=""individual-dependence.html""><span class=""header-section-number"">4</span> Individual dependence</a></li>
-<li class=""book-part"">V. Conclusion</li>
-<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
-<li><a class="""" href=""references.html"">References</a></li>
-</ul>
-
-        <div class=""book-extra"">
-          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
-        </div>
-      </nav>
-</div>
-  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""individual-dependence"" class=""section level1"" number=""4"">
-<h1>
-<span class=""header-section-number"">4</span> Individual dependence<a class=""anchor"" aria-label=""anchor"" href=""#individual-dependence""><i class=""fas fa-link""></i></a>
-</h1>
-<div id=""dependence-among-individuals"" class=""section level2"" number=""4.1"">
-<h2>
-<span class=""header-section-number"">4.1</span> Dependence among individuals<a class=""anchor"" aria-label=""anchor"" href=""#dependence-among-individuals""><i class=""fas fa-link""></i></a>
-</h2>
-<p><span class=""citation"">Culina et al. (<a href=""references.html#ref-culina_multievent_2013"">2013</a>)</span> and <span class=""citation"">Cubaynes et al. (<a href=""references.html#ref-cubaynes_modeling_2021"">2021</a>)</span></p>
-</div>
-<div id=""individual-heterogeneity"" class=""section level2"" number=""4.2"">
-<h2>
-<span class=""header-section-number"">4.2</span> Individual heterogeneity<a class=""anchor"" aria-label=""anchor"" href=""#individual-heterogeneity""><i class=""fas fa-link""></i></a>
-</h2>
-<p><span class=""citation"">Cubaynes et al. (<a href=""references.html#ref-cubaynes_importance_2010"">2010</a>)</span>, <span class=""citation"">Gimenez and Choquet (<a href=""references.html#ref-gimenez_individual_2010"">2010</a>)</span>, and <span class=""citation"">Turek, Wehrhahn, and Gimenez (<a href=""references.html#ref-turek_bayesian_2021"">2021</a>)</span></p>
-
-</div>
-</div>
-
-
-
-  <div class=""chapter-nav"">
-<div class=""prev""><a href=""stopover.html""><span class=""header-section-number"">3</span> Stopover duration</a></div>
-<div class=""next""><a href=""take-home-messages.html"">Take-home messages</a></div>
-</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
-    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
-      <ul class=""nav navbar-nav"">
-<li><a class=""nav-link"" href=""#individual-dependence""><span class=""header-section-number"">4</span> Individual dependence</a></li>
-<li><a class=""nav-link"" href=""#dependence-among-individuals""><span class=""header-section-number"">4.1</span> Dependence among individuals</a></li>
-<li><a class=""nav-link"" href=""#individual-heterogeneity""><span class=""header-section-number"">4.2</span> Individual heterogeneity</a></li>
-</ul>
-
-      <div class=""book-extra"">
-        <ul class=""list-unstyled"">
-<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/dependence.Rmd"">View source <i class=""fab fa-github""></i></a></li>
-          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/dependence.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
-        </ul>
-</div>
-    </nav>
-</div>
-
-</div>
-</div> <!-- .container -->
-
-<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-08.</p>
-  </div>
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
-  </div>
-
-</div></div>
-</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
-  (function () {
-    var script = document.createElement(""script"");
-    script.type = ""text/javascript"";
-    var src = ""true"";
-    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
-    if (location.protocol !== ""file:"")
-      if (/^https?:/.test(src))
-        src = src.replace(/^https?:/, '');
-    script.src = src;
-    document.getElementsByTagName(""head"")[0].appendChild(script);
-  })();
-</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
-for (let popover of popovers) {
-  const div = document.createElement('div');
-  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
-  div.innerHTML = popover.getAttribute('data-content');
-
-  var has_math = div.querySelector(""span.math"");
-  if (has_math) {
-    document.body.appendChild(div);
-    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
-    MathJax.Hub.Queue(function() {
-      popover.setAttribute('data-content', div.innerHTML);
-      document.body.removeChild(div);
-    })
-  }
-}
-</script>
-</body>
-</html>

---FILE: docs/introduction-2.html---
@@ -1,158 +0,0 @@
-<!DOCTYPE html>
-<html lang=""en"">
-<head>
-<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
-<meta charset=""utf-8"">
-<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<title>Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
-<meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
-<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
-<meta property=""og:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta property=""og:type"" content=""book"">
-<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/introduction-2.html"">
-<meta property=""og:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
-<meta name=""twitter:card"" content=""summary"">
-<meta name=""twitter:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta name=""twitter:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
-<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
-<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
-    
-    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
-  </style>
-<style type=""text/css"">
-    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
-    div.csl-bib-body { }
-    div.csl-entry {
-      clear: both;
-        }
-    .hanging div.csl-entry {
-      margin-left:2em;
-      text-indent:-2em;
-    }
-    div.csl-left-margin {
-      min-width:2em;
-      float:left;
-    }
-    div.csl-right-inline {
-      margin-left:2em;
-      padding-left:1em;
-    }
-    div.csl-indent {
-      margin-left: 2em;
-    }
-  </style>
-<link rel=""stylesheet"" href=""bs4_style.css"">
-</head>
-<body data-spy=""scroll"" data-target=""#toc"">
-
-<div class=""container-fluid"">
-<div class=""row"">
-  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
-
-    <div class=""d-flex align-items-start justify-content-between"">
-      <h1>
-        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
-        <small class=""text-muted"">Theory and Case Studies in R</small>
-      </h1>
-      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
-    </div>
-
-    <div id=""main-nav"" class=""collapse-lg"">
-      <form role=""search"">
-        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
-</form>
-
-      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
-        <ul class=""book-toc list-unstyled"">
-<li><a class="""" href=""index.html"">Welcome</a></li>
-<li><a class="""" href=""preface.html"">Preface</a></li>
-<li><a class="""" href=""about-the-author.html"">About the author</a></li>
-<li class=""book-part"">I. Foundations</li>
-<li><a class="""" href=""introduction.html"">Introduction</a></li>
-<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">1</span> Hidden Markov models</a></li>
-<li class=""book-part"">II. Transitions</li>
-<li><a class=""active"" href=""introduction-2.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">2</span> Survival</a></li>
-<li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
-<li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-5.html"">Introduction</a></li>
-<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
-<li><a class="""" href=""references.html"">References</a></li>
-</ul>
-
-        <div class=""book-extra"">
-          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
-        </div>
-      </nav>
-</div>
-  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""introduction-2"" class=""section level1 unnumbered"">
-<h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-2""><i class=""fas fa-link""></i></a>
-</h1>
-
-</div>
-  <div class=""chapter-nav"">
-<div class=""prev""><a href=""hmmcapturerecapture.html""><span class=""header-section-number"">1</span> Hidden Markov models</a></div>
-<div class=""next""><a href=""survival.html""><span class=""header-section-number"">2</span> Survival</a></div>
-</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
-    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
-      <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#introduction-2"">Introduction</a></li></ul>
-
-      <div class=""book-extra"">
-        <ul class=""list-unstyled"">
-<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionparttwo.Rmd"">View source <i class=""fab fa-github""></i></a></li>
-          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionparttwo.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
-        </ul>
-</div>
-    </nav>
-</div>
-
-</div>
-</div> <!-- .container -->
-
-<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-11.</p>
-  </div>
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
-  </div>
-
-</div></div>
-</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
-  (function () {
-    var script = document.createElement(""script"");
-    script.type = ""text/javascript"";
-    var src = ""true"";
-    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
-    if (location.protocol !== ""file:"")
-      if (/^https?:/.test(src))
-        src = src.replace(/^https?:/, '');
-    script.src = src;
-    document.getElementsByTagName(""head"")[0].appendChild(script);
-  })();
-</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
-for (let popover of popovers) {
-  const div = document.createElement('div');
-  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
-  div.innerHTML = popover.getAttribute('data-content');
-
-  var has_math = div.querySelector(""span.math"");
-  if (has_math) {
-    document.body.appendChild(div);
-    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
-    MathJax.Hub.Queue(function() {
-      popover.setAttribute('data-content', div.innerHTML);
-      document.body.removeChild(div);
-    })
-  }
-}
-</script>
-</body>
-</html>

---FILE: docs/introduction-4.html---
@@ -73,17 +73,13 @@ <h1>
 <li><a class="""" href=""about-the-author.html"">About the author</a></li>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
-<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
-<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
-<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class=""active"" href=""introduction-4.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
-<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
+<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">1</span> Survival</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
+<li><a class=""active"" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
@@ -96,19 +92,18 @@ <h1>
   </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""introduction-4"" class=""section level1 unnumbered"">
 <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-4""><i class=""fas fa-link""></i></a>
 </h1>
-
 </div>
   <div class=""chapter-nav"">
-<div class=""prev""><a href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></div>
-<div class=""next""><a href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></div>
+<div class=""prev""><a href=""introduction-3.html"">Introduction</a></div>
+<div class=""next""><a href=""take-home-messages.html"">Take-home messages</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
       <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#introduction-4"">Introduction</a></li></ul>
 
       <div class=""book-extra"">
         <ul class=""list-unstyled"">
-<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionparttwo.Rmd"">View source <i class=""fab fa-github""></i></a></li>
-          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionparttwo.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionpartfour.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionpartfour.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
         </ul>
 </div>
     </nav>

---FILE: docs/introduction-5.html---
@@ -1,157 +0,0 @@
-<!DOCTYPE html>
-<html lang=""en"">
-<head>
-<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
-<meta charset=""utf-8"">
-<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<title>Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
-<meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
-<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
-<meta property=""og:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta property=""og:type"" content=""book"">
-<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/introduction-5.html"">
-<meta property=""og:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
-<meta name=""twitter:card"" content=""summary"">
-<meta name=""twitter:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta name=""twitter:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
-<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
-<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
-    
-    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
-  </style>
-<style type=""text/css"">
-    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
-    div.csl-bib-body { }
-    div.csl-entry {
-      clear: both;
-        }
-    .hanging div.csl-entry {
-      margin-left:2em;
-      text-indent:-2em;
-    }
-    div.csl-left-margin {
-      min-width:2em;
-      float:left;
-    }
-    div.csl-right-inline {
-      margin-left:2em;
-      padding-left:1em;
-    }
-    div.csl-indent {
-      margin-left: 2em;
-    }
-  </style>
-<link rel=""stylesheet"" href=""bs4_style.css"">
-</head>
-<body data-spy=""scroll"" data-target=""#toc"">
-
-<div class=""container-fluid"">
-<div class=""row"">
-  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
-
-    <div class=""d-flex align-items-start justify-content-between"">
-      <h1>
-        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
-        <small class=""text-muted"">Theory and Case Studies in R</small>
-      </h1>
-      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
-    </div>
-
-    <div id=""main-nav"" class=""collapse-lg"">
-      <form role=""search"">
-        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
-</form>
-
-      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
-        <ul class=""book-toc list-unstyled"">
-<li><a class="""" href=""index.html"">Welcome</a></li>
-<li><a class="""" href=""preface.html"">Preface</a></li>
-<li><a class="""" href=""about-the-author.html"">About the author</a></li>
-<li class=""book-part"">I. Foundations</li>
-<li><a class="""" href=""introduction.html"">Introduction</a></li>
-<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">1</span> Hidden Markov models</a></li>
-<li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">2</span> Survival</a></li>
-<li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
-<li class=""book-part"">IV. Conclusions</li>
-<li><a class=""active"" href=""introduction-5.html"">Introduction</a></li>
-<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
-<li><a class="""" href=""references.html"">References</a></li>
-</ul>
-
-        <div class=""book-extra"">
-          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
-        </div>
-      </nav>
-</div>
-  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""introduction-5"" class=""section level1 unnumbered"">
-<h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-5""><i class=""fas fa-link""></i></a>
-</h1>
-</div>
-  <div class=""chapter-nav"">
-<div class=""prev""><a href=""introduction-4.html"">Introduction</a></div>
-<div class=""next""><a href=""take-home-messages.html"">Take-home messages</a></div>
-</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
-    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
-      <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#introduction-5"">Introduction</a></li></ul>
-
-      <div class=""book-extra"">
-        <ul class=""list-unstyled"">
-<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionpartfour.Rmd"">View source <i class=""fab fa-github""></i></a></li>
-          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionpartfour.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
-        </ul>
-</div>
-    </nav>
-</div>
-
-</div>
-</div> <!-- .container -->
-
-<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-11.</p>
-  </div>
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
-  </div>
-
-</div></div>
-</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
-  (function () {
-    var script = document.createElement(""script"");
-    script.type = ""text/javascript"";
-    var src = ""true"";
-    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
-    if (location.protocol !== ""file:"")
-      if (/^https?:/.test(src))
-        src = src.replace(/^https?:/, '');
-    script.src = src;
-    document.getElementsByTagName(""head"")[0].appendChild(script);
-  })();
-</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
-for (let popover of popovers) {
-  const div = document.createElement('div');
-  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
-  div.innerHTML = popover.getAttribute('data-content');
-
-  var has_math = div.querySelector(""span.math"");
-  if (has_math) {
-    document.body.appendChild(div);
-    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
-    MathJax.Hub.Queue(function() {
-      popover.setAttribute('data-content', div.innerHTML);
-      document.body.removeChild(div);
-    })
-  }
-}
-</script>
-</body>
-</html>

---FILE: docs/introduction-6.html---
@@ -1,163 +0,0 @@
-<!DOCTYPE html>
-<html lang=""en"">
-<head>
-<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
-<meta charset=""utf-8"">
-<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<title>Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
-<meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
-<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
-<meta property=""og:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta property=""og:type"" content=""book"">
-<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/introduction-6.html"">
-<meta property=""og:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
-<meta name=""twitter:card"" content=""summary"">
-<meta name=""twitter:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta name=""twitter:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
-<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
-<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
-    
-    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
-  </style>
-<style type=""text/css"">
-    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
-    div.csl-bib-body { }
-    div.csl-entry {
-      clear: both;
-        }
-    .hanging div.csl-entry {
-      margin-left:2em;
-      text-indent:-2em;
-    }
-    div.csl-left-margin {
-      min-width:2em;
-      float:left;
-    }
-    div.csl-right-inline {
-      margin-left:2em;
-      padding-left:1em;
-    }
-    div.csl-indent {
-      margin-left: 2em;
-    }
-  </style>
-<link rel=""stylesheet"" href=""bs4_style.css"">
-</head>
-<body data-spy=""scroll"" data-target=""#toc"">
-
-<div class=""container-fluid"">
-<div class=""row"">
-  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
-
-    <div class=""d-flex align-items-start justify-content-between"">
-      <h1>
-        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
-        <small class=""text-muted"">Theory and Case Studies in R</small>
-      </h1>
-      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
-    </div>
-
-    <div id=""main-nav"" class=""collapse-lg"">
-      <form role=""search"">
-        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
-</form>
-
-      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
-        <ul class=""book-toc list-unstyled"">
-<li><a class="""" href=""index.html"">Welcome</a></li>
-<li><a class="""" href=""preface.html"">Preface</a></li>
-<li><a class="""" href=""about-the-author.html"">About the author</a></li>
-<li class=""book-part"">I. Foundations</li>
-<li><a class="""" href=""introduction.html"">Introduction</a></li>
-<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
-<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
-<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
-<li class=""book-part"">III. Case studies</li>
-<li><a class=""active"" href=""introduction-6.html"">Introduction</a></li>
-<li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
-<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
-<li><a class="""" href=""references.html"">References</a></li>
-</ul>
-
-        <div class=""book-extra"">
-          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
-        </div>
-      </nav>
-</div>
-  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""introduction-6"" class=""section level1 unnumbered"">
-<h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-6""><i class=""fas fa-link""></i></a>
-</h1>
-
-</div>
-
-
-
-  <div class=""chapter-nav"">
-<div class=""prev""><a href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></div>
-<div class=""next""><a href=""introduction-7.html"">Introduction</a></div>
-</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
-    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
-      <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#introduction-6"">Introduction</a></li></ul>
-
-      <div class=""book-extra"">
-        <ul class=""list-unstyled"">
-<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionpartthree.Rmd"">View source <i class=""fab fa-github""></i></a></li>
-          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionpartthree.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
-        </ul>
-</div>
-    </nav>
-</div>
-
-</div>
-</div> <!-- .container -->
-
-<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-12.</p>
-  </div>
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
-  </div>
-
-</div></div>
-</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
-  (function () {
-    var script = document.createElement(""script"");
-    script.type = ""text/javascript"";
-    var src = ""true"";
-    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
-    if (location.protocol !== ""file:"")
-      if (/^https?:/.test(src))
-        src = src.replace(/^https?:/, '');
-    script.src = src;
-    document.getElementsByTagName(""head"")[0].appendChild(script);
-  })();
-</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
-for (let popover of popovers) {
-  const div = document.createElement('div');
-  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
-  div.innerHTML = popover.getAttribute('data-content');
-
-  var has_math = div.querySelector(""span.math"");
-  if (has_math) {
-    document.body.appendChild(div);
-    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
-    MathJax.Hub.Queue(function() {
-      popover.setAttribute('data-content', div.innerHTML);
-      document.body.removeChild(div);
-    })
-  }
-}
-</script>
-</body>
-</html>

---FILE: docs/introduction-7.html---
@@ -1,164 +0,0 @@
-<!DOCTYPE html>
-<html lang=""en"">
-<head>
-<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
-<meta charset=""utf-8"">
-<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<title>Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
-<meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
-<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
-<meta property=""og:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta property=""og:type"" content=""book"">
-<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/introduction-7.html"">
-<meta property=""og:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
-<meta name=""twitter:card"" content=""summary"">
-<meta name=""twitter:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta name=""twitter:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
-<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
-<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
-    
-    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
-  </style>
-<style type=""text/css"">
-    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
-    div.csl-bib-body { }
-    div.csl-entry {
-      clear: both;
-        }
-    .hanging div.csl-entry {
-      margin-left:2em;
-      text-indent:-2em;
-    }
-    div.csl-left-margin {
-      min-width:2em;
-      float:left;
-    }
-    div.csl-right-inline {
-      margin-left:2em;
-      padding-left:1em;
-    }
-    div.csl-indent {
-      margin-left: 2em;
-    }
-  </style>
-<link rel=""stylesheet"" href=""bs4_style.css"">
-</head>
-<body data-spy=""scroll"" data-target=""#toc"">
-
-<div class=""container-fluid"">
-<div class=""row"">
-  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
-
-    <div class=""d-flex align-items-start justify-content-between"">
-      <h1>
-        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
-        <small class=""text-muted"">Theory and Case Studies in R</small>
-      </h1>
-      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
-    </div>
-
-    <div id=""main-nav"" class=""collapse-lg"">
-      <form role=""search"">
-        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
-</form>
-
-      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
-        <ul class=""book-toc list-unstyled"">
-<li><a class="""" href=""index.html"">Welcome</a></li>
-<li><a class="""" href=""preface.html"">Preface</a></li>
-<li><a class="""" href=""about-the-author.html"">About the author</a></li>
-<li class=""book-part"">I. Foundations</li>
-<li><a class="""" href=""introduction.html"">Introduction</a></li>
-<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
-<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
-<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
-<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
-<li class=""book-part"">III. Case studies</li>
-<li><a class=""active"" href=""introduction-7.html"">Introduction</a></li>
-<li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
-<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
-<li><a class="""" href=""references.html"">References</a></li>
-</ul>
-
-        <div class=""book-extra"">
-          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
-        </div>
-      </nav>
-</div>
-  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""introduction-7"" class=""section level1 unnumbered"">
-<h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-7""><i class=""fas fa-link""></i></a>
-</h1>
-
-</div>
-
-
-
-  <div class=""chapter-nav"">
-<div class=""prev""><a href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></div>
-<div class=""next""><a href=""introduction-8.html"">Introduction</a></div>
-</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
-    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
-      <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#introduction-7"">Introduction</a></li></ul>
-
-      <div class=""book-extra"">
-        <ul class=""list-unstyled"">
-<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionpartthree.Rmd"">View source <i class=""fab fa-github""></i></a></li>
-          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionpartthree.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
-        </ul>
-</div>
-    </nav>
-</div>
-
-</div>
-</div> <!-- .container -->
-
-<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-12.</p>
-  </div>
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
-  </div>
-
-</div></div>
-</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
-  (function () {
-    var script = document.createElement(""script"");
-    script.type = ""text/javascript"";
-    var src = ""true"";
-    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
-    if (location.protocol !== ""file:"")
-      if (/^https?:/.test(src))
-        src = src.replace(/^https?:/, '');
-    script.src = src;
-    document.getElementsByTagName(""head"")[0].appendChild(script);
-  })();
-</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
-for (let popover of popovers) {
-  const div = document.createElement('div');
-  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
-  div.innerHTML = popover.getAttribute('data-content');
-
-  var has_math = div.querySelector(""span.math"");
-  if (has_math) {
-    document.body.appendChild(div);
-    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
-    MathJax.Hub.Queue(function() {
-      popover.setAttribute('data-content', div.innerHTML);
-      document.body.removeChild(div);
-    })
-  }
-}
-</script>
-</body>
-</html>

---FILE: docs/introduction-8.html---
@@ -1,160 +0,0 @@
-<!DOCTYPE html>
-<html lang=""en"">
-<head>
-<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
-<meta charset=""utf-8"">
-<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<title>Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
-<meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
-<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
-<meta property=""og:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta property=""og:type"" content=""book"">
-<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/introduction-8.html"">
-<meta property=""og:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
-<meta name=""twitter:card"" content=""summary"">
-<meta name=""twitter:title"" content=""Introduction | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta name=""twitter:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
-<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
-<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
-    
-    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
-  </style>
-<style type=""text/css"">
-    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
-    div.csl-bib-body { }
-    div.csl-entry {
-      clear: both;
-        }
-    .hanging div.csl-entry {
-      margin-left:2em;
-      text-indent:-2em;
-    }
-    div.csl-left-margin {
-      min-width:2em;
-      float:left;
-    }
-    div.csl-right-inline {
-      margin-left:2em;
-      padding-left:1em;
-    }
-    div.csl-indent {
-      margin-left: 2em;
-    }
-  </style>
-<link rel=""stylesheet"" href=""bs4_style.css"">
-</head>
-<body data-spy=""scroll"" data-target=""#toc"">
-
-<div class=""container-fluid"">
-<div class=""row"">
-  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
-
-    <div class=""d-flex align-items-start justify-content-between"">
-      <h1>
-        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
-        <small class=""text-muted"">Theory and Case Studies in R</small>
-      </h1>
-      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
-    </div>
-
-    <div id=""main-nav"" class=""collapse-lg"">
-      <form role=""search"">
-        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
-</form>
-
-      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
-        <ul class=""book-toc list-unstyled"">
-<li><a class="""" href=""index.html"">Welcome</a></li>
-<li><a class="""" href=""preface.html"">Preface</a></li>
-<li><a class="""" href=""about-the-author.html"">About the author</a></li>
-<li class=""book-part"">I. Foundations</li>
-<li><a class="""" href=""introduction.html"">Introduction</a></li>
-<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
-<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
-<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
-<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
-<li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
-<li class=""book-part"">IV. Conclusions</li>
-<li><a class=""active"" href=""introduction-8.html"">Introduction</a></li>
-<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
-<li><a class="""" href=""references.html"">References</a></li>
-</ul>
-
-        <div class=""book-extra"">
-          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
-        </div>
-      </nav>
-</div>
-  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""introduction-8"" class=""section level1 unnumbered"">
-<h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-8""><i class=""fas fa-link""></i></a>
-</h1>
-</div>
-  <div class=""chapter-nav"">
-<div class=""prev""><a href=""introduction-7.html"">Introduction</a></div>
-<div class=""next""><a href=""take-home-messages.html"">Take-home messages</a></div>
-</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
-    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
-      <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#introduction-8"">Introduction</a></li></ul>
-
-      <div class=""book-extra"">
-        <ul class=""list-unstyled"">
-<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionpartfour.Rmd"">View source <i class=""fab fa-github""></i></a></li>
-          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionpartfour.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
-        </ul>
-</div>
-    </nav>
-</div>
-
-</div>
-</div> <!-- .container -->
-
-<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-12.</p>
-  </div>
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
-  </div>
-
-</div></div>
-</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
-  (function () {
-    var script = document.createElement(""script"");
-    script.type = ""text/javascript"";
-    var src = ""true"";
-    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
-    if (location.protocol !== ""file:"")
-      if (/^https?:/.test(src))
-        src = src.replace(/^https?:/, '');
-    script.src = src;
-    document.getElementsByTagName(""head"")[0].appendChild(script);
-  })();
-</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
-for (let popover of popovers) {
-  const div = document.createElement('div');
-  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
-  div.innerHTML = popover.getAttribute('data-content');
-
-  var has_math = div.querySelector(""span.math"");
-  if (has_math) {
-    document.body.appendChild(div);
-    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
-    MathJax.Hub.Queue(function() {
-      popover.setAttribute('data-content', div.innerHTML);
-      document.body.removeChild(div);
-    })
-  }
-}
-</script>
-</body>
-</html>

---FILE: docs/introduction.html---
@@ -73,17 +73,13 @@ <h1>
 <li><a class="""" href=""about-the-author.html"">About the author</a></li>
 <li class=""book-part"">I. Foundations</li>
 <li><a class=""active"" href=""introduction.html"">Introduction</a></li>
-<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
-<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
-<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
-<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
+<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">1</span> Survival</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
@@ -98,9 +94,12 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction""><i cl
 </h1>
 
 </div>
+
+
+
   <div class=""chapter-nav"">
 <div class=""prev""><a href=""about-the-author.html"">About the author</a></div>
-<div class=""next""><a href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></div>
+<div class=""next""><a href=""introduction-1.html"">Introduction</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
       <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#introduction"">Introduction</a></li></ul>

---FILE: docs/libs/bs3compat-0.4.2/bs3compat.js---
@@ -1,48 +0,0 @@
-// Inform the world that we have the ability to use BS3 nav/navbar markup in BS4
-window.BS3_COMPAT = true;
-
-// This logic needs to execute after both the BS4+ (new) as well as BS3 (legacy)
-// jQuery plugins have been registered. For BS5, plugin registration happens
-// after DOM content is loaded, which is why we do the same here.
-// https://github.com/twbs/bootstrap/blob/08139c22/js/dist/tab.js#L87
-$(function() {
-
-  // The legacy plugin needs to be registered after the new one
-  if (!$.fn.tab.Constructor.VERSION.match(/^3\./)) {
-    (console.warn || console.error || console.log)(""bs3compat.js couldn't find bs3 tab impl; bs3 tabs will not be properly supported"");
-    return;
-  }
-  var legacyTabPlugin = $.fn.tab.noConflict();
-
-  if (!$.fn.tab || !$.fn.tab.Constructor || !$.fn.tab.noConflict) {
-    (console.warn || console.error || console.log)(""bs3compat.js couldn't find a jQuery tab impl; bs3 tabs will not be properly supported"");
-  }
-  var newTabPlugin = $.fn.tab.noConflict();
-
-  // Re-define the tab click event
-  // https://github.com/twbs/bootstrap/blob/08139c2/js/src/tab.js#L33
-  var EVENT_KEY = ""click.bs.tab.data-api"";
-  $(document).off(EVENT_KEY);
-
-  var SELECTOR = '[data-toggle=""tab""], [data-toggle=""pill""], [data-bs-toggle=""tab""], [data-bs-toggle=""pill""]';
-  $(document).on(EVENT_KEY, SELECTOR, function(event) {
-    event.preventDefault();
-    $(this).tab(""show"");
-  });
-
-  function TabPlugin(config) {
-    // Legacy (bs3) tabs: li.active > a
-    // New (bs4+) tabs: li.nav-item > a.active.nav-link
-    var legacy = $(this).closest("".nav"").find(""li:not(.dropdown).active > a"").length > 0;
-    var plugin = legacy ? legacyTabPlugin : newTabPlugin;
-    plugin.call($(this), config);
-  }
-
-  var noconflict = $.fn.tab;
-  $.fn.tab = TabPlugin;
-  $.fn.tab.Constructor = newTabPlugin.Constructor;
-  $.fn.tab.noConflict = function() {
-    $.fn.tab = noconflict;
-    return TabPlugin;
-  };
-});

---FILE: docs/libs/bs3compat-0.4.2/tabs.js---
@@ -1,157 +0,0 @@
-/* ========================================================================
- * Bootstrap: tab.js v3.4.1
- * https://getbootstrap.com/docs/3.4/javascript/#tabs
- * ========================================================================
- * Copyright 2011-2019 Twitter, Inc.
- * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
- * ======================================================================== */
-
-// Register tab plugin after DOM content loaded in order to
-// override BS5's plugin
-// https://github.com/twbs/bootstrap/blob/08139c22/js/dist/tab.js#L87
-$(function() {
-  'use strict';
-
-  // TAB CLASS DEFINITION
-  // ====================
-
-  var Tab = function (element) {
-    // jscs:disable requireDollarBeforejQueryAssignment
-    this.element = $(element)
-    // jscs:enable requireDollarBeforejQueryAssignment
-  }
-
-  Tab.VERSION = '3.4.1'
-
-  Tab.TRANSITION_DURATION = 150
-
-  Tab.prototype.show = function () {
-    var $this    = this.element
-    var $ul      = $this.closest('ul:not(.dropdown-menu)')
-    var selector = $this.data('target')
-
-    if (!selector) {
-      selector = $this.attr('href')
-      selector = selector && selector.replace(/.*(?=#[^\s]*$)/, '') // strip for ie7
-    }
-
-    if ($this.parent('li').hasClass('active')) return
-
-    var $previous = $ul.find('.active:last a')
-    var hideEvent = $.Event('hide.bs.tab', {
-      relatedTarget: $this[0]
-    })
-    var showEvent = $.Event('show.bs.tab', {
-      relatedTarget: $previous[0]
-    })
-
-    $previous.trigger(hideEvent)
-    $this.trigger(showEvent)
-
-    if (showEvent.isDefaultPrevented() || hideEvent.isDefaultPrevented()) return
-
-    var $target = $(document).find(selector)
-
-    this.activate($this.closest('li'), $ul)
-    this.activate($target, $target.parent(), function () {
-      $previous.trigger({
-        type: 'hidden.bs.tab',
-        relatedTarget: $this[0]
-      })
-      $this.trigger({
-        type: 'shown.bs.tab',
-        relatedTarget: $previous[0]
-      })
-    })
-  }
-
-  Tab.prototype.activate = function (element, container, callback) {
-    var $active    = container.find('> .active')
-    var transition = callback
-      && $.support.transition
-      && ($active.length && $active.hasClass('fade') || !!container.find('> .fade').length)
-
-    function next() {
-      $active
-        .removeClass('active')
-        .find('> .dropdown-menu > .active')
-        .removeClass('active')
-        .end()
-        .find('[data-toggle=""tab""]')
-        .attr('aria-expanded', false)
-
-      element
-        .addClass('active')
-        .find('[data-toggle=""tab""]')
-        .attr('aria-expanded', true)
-
-      if (transition) {
-        element[0].offsetWidth // reflow for transition
-        element.addClass('in')
-      } else {
-        element.removeClass('fade')
-      }
-
-      if (element.parent('.dropdown-menu').length) {
-        element
-          .closest('li.dropdown')
-          .addClass('active')
-          .end()
-          .find('[data-toggle=""tab""]')
-          .attr('aria-expanded', true)
-      }
-
-      callback && callback()
-    }
-
-    $active.length && transition ?
-      $active
-        .one('bsTransitionEnd', next)
-        .emulateTransitionEnd(Tab.TRANSITION_DURATION) :
-      next()
-
-    $active.removeClass('in')
-  }
-
-
-  // TAB PLUGIN DEFINITION
-  // =====================
-
-  function Plugin(option) {
-    return this.each(function () {
-      var $this = $(this)
-      var data  = $this.data('bs.tab')
-
-      if (!data) $this.data('bs.tab', (data = new Tab(this)))
-      if (typeof option == 'string') data[option]()
-    })
-  }
-
-  var old = $.fn.tab
-
-  $.fn.tab             = Plugin
-  $.fn.tab.Constructor = Tab
-
-
-  // TAB NO CONFLICT
-  // ===============
-
-  $.fn.tab.noConflict = function () {
-    $.fn.tab = old
-    return this
-  }
-
-
-  // TAB DATA-API
-  // ============
-
-  var clickHandler = function (e) {
-    e.preventDefault()
-    Plugin.call($(this), 'show')
-  }
-
-  $(document)
-    .on('click.bs.tab.data-api', '[data-toggle=""tab""]', clickHandler)
-    .on('click.bs.tab.data-api', '[data-toggle=""pill""]', clickHandler)
-
-});

---FILE: docs/libs/bs3compat-0.4.2/transition.js---
@@ -1,59 +0,0 @@
-/* ========================================================================
- * Bootstrap: transition.js v3.4.1
- * https://getbootstrap.com/docs/3.4/javascript/#transitions
- * ========================================================================
- * Copyright 2011-2019 Twitter, Inc.
- * Licensed under MIT (https://github.com/twbs/bootstrap/blob/v3-dev/LICENSE)
- * ======================================================================== */
-
-
-+function ($) {
-  'use strict';
-
-  // CSS TRANSITION SUPPORT (Shoutout: https://modernizr.com/)
-  // ============================================================
-
-  function transitionEnd() {
-    var el = document.createElement('bootstrap')
-
-    var transEndEventNames = {
-      WebkitTransition : 'webkitTransitionEnd',
-      MozTransition    : 'transitionend',
-      OTransition      : 'oTransitionEnd otransitionend',
-      transition       : 'transitionend'
-    }
-
-    for (var name in transEndEventNames) {
-      if (el.style[name] !== undefined) {
-        return { end: transEndEventNames[name] }
-      }
-    }
-
-    return false // explicit for ie8 (  ._.)
-  }
-
-  // https://blog.alexmaccaw.com/css-transitions
-  $.fn.emulateTransitionEnd = function (duration) {
-    var called = false
-    var $el = this
-    $(this).one('bsTransitionEnd', function () { called = true })
-    var callback = function () { if (!called) $($el).trigger($.support.transition.end) }
-    setTimeout(callback, duration)
-    return this
-  }
-
-  $(function () {
-    $.support.transition = transitionEnd()
-
-    if (!$.support.transition) return
-
-    $.event.special.bsTransitionEnd = {
-      bindType: $.support.transition.end,
-      delegateType: $.support.transition.end,
-      handle: function (e) {
-        if ($(e.target).is(this)) return e.handleObj.handler.apply(this, arguments)
-      }
-    }
-  })
-
-}(jQuery);

---FILE: docs/model-selection.html---
@@ -1,254 +0,0 @@
-<!DOCTYPE html>
-<html lang=""en"">
-<head>
-<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
-<meta charset=""utf-8"">
-<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<title>Chapter 5 Model selection and validation | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
-<meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""WAIC. RJMCMC for covariate selection, Lasso via Laplace prior. Papers by Conn, Hooten, etc sur model selection Ajouter section sur GOF avec R2ucare, derniers travaux de la th√©sarde de Roger Anita..."">
-<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
-<meta property=""og:title"" content=""Chapter 5 Model selection and validation | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta property=""og:type"" content=""book"">
-<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/model-selection.html"">
-<meta property=""og:description"" content=""WAIC. RJMCMC for covariate selection, Lasso via Laplace prior. Papers by Conn, Hooten, etc sur model selection Ajouter section sur GOF avec R2ucare, derniers travaux de la th√©sarde de Roger Anita..."">
-<meta name=""twitter:card"" content=""summary"">
-<meta name=""twitter:title"" content=""Chapter 5 Model selection and validation | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta name=""twitter:description"" content=""WAIC. RJMCMC for covariate selection, Lasso via Laplace prior. Papers by Conn, Hooten, etc sur model selection Ajouter section sur GOF avec R2ucare, derniers travaux de la th√©sarde de Roger Anita..."">
-<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
-<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
-    
-    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
-  </style>
-<style type=""text/css"">
-    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
-    div.csl-bib-body { }
-    div.csl-entry {
-      clear: both;
-        }
-    .hanging div.csl-entry {
-      margin-left:2em;
-      text-indent:-2em;
-    }
-    div.csl-left-margin {
-      min-width:2em;
-      float:left;
-    }
-    div.csl-right-inline {
-      margin-left:2em;
-      padding-left:1em;
-    }
-    div.csl-indent {
-      margin-left: 2em;
-    }
-  </style>
-<link rel=""stylesheet"" href=""bs4_style.css"">
-</head>
-<body data-spy=""scroll"" data-target=""#toc"">
-
-<div class=""container-fluid"">
-<div class=""row"">
-  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
-
-    <div class=""d-flex align-items-start justify-content-between"">
-      <h1>
-        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
-        <small class=""text-muted"">Theory and Case Studies in R</small>
-      </h1>
-      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
-    </div>
-
-    <div id=""main-nav"" class=""collapse-lg"">
-      <form role=""search"">
-        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
-</form>
-
-      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
-        <ul class=""book-toc list-unstyled"">
-<li><a class="""" href=""index.html"">Welcome</a></li>
-<li><a class="""" href=""preface.html"">Preface</a></li>
-<li><a class="""" href=""about-the-author.html"">About the author</a></li>
-<li class=""book-part"">I. Foundations</li>
-<li><a class="""" href=""introduction.html"">Introduction</a></li>
-<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
-<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
-<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
-<li><a class=""active"" href=""model-selection.html""><span class=""header-section-number"">5</span> Model selection and validation</a></li>
-<li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-6.html"">Introduction</a></li>
-<li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
-<li class=""book-part"">V. Conclusion</li>
-<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
-<li><a class="""" href=""references.html"">References</a></li>
-</ul>
-
-        <div class=""book-extra"">
-          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
-        </div>
-      </nav>
-</div>
-  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""model-selection"" class=""section level1"" number=""5"">
-<h1>
-<span class=""header-section-number"">5</span> Model selection and validation<a class=""anchor"" aria-label=""anchor"" href=""#model-selection""><i class=""fas fa-link""></i></a>
-</h1>
-<p>WAIC. RJMCMC for covariate selection, Lasso via Laplace prior. Papers by Conn, Hooten, etc sur model selection</p>
-<p>Ajouter section sur GOF avec R2ucare, derniers travaux de la th√©sarde de Roger Anita Jeyam. Posterior predictive checks.</p>
-<p>Ajouter trap-dependence √† la Pradel et Sanz quelque part. Et memory model.</p>
-<div id=""how-to-select-a-best-model-model-selection"" class=""section level2"" number=""5.1"">
-<h2>
-<span class=""header-section-number"">5.1</span> How to select a best model? Model selection<a class=""anchor"" aria-label=""anchor"" href=""#how-to-select-a-best-model-model-selection""><i class=""fas fa-link""></i></a>
-</h2>
-<ul>
-<li><p>Which of the four models above is best supported by the data?</p></li>
-<li><p>The proportion of explained variance <span class=""math inline"">\(R^2\)</span> is problematic, because the more variables you have, the bigger <span class=""math inline"">\(R^2\)</span> is.</p></li>
-<li><p>The idea is to penalize models with too many parameters.</p></li>
-</ul>
-</div>
-<div id=""akaike-information-criterion-aic"" class=""section level2"" number=""5.2"">
-<h2>
-<span class=""header-section-number"">5.2</span> Akaike information criterion (AIC)<a class=""anchor"" aria-label=""anchor"" href=""#akaike-information-criterion-aic""><i class=""fas fa-link""></i></a>
-</h2>
-<p><span class=""math display"">\[AIC = - 2 \log(L(\hat{\theta}_1,\ldots,\hat{\theta}_K)) + 2 K\]</span></p>
-<p>with <span class=""math inline"">\(L\)</span> the likelihood and <span class=""math inline"">\(K\)</span> the number of parameters <span class=""math inline"">\(\theta_i\)</span>.</p>
-<p><span class=""math display"">\[\text{AIC} = {\color{purple}{- 2 \log(L(\hat{\theta}_1,\ldots,\hat{\theta}_K))}} + 2 K\]</span></p>
-<p><span style=""color: purple;"">A measure of goodness-of-fit of the model to the data</span>: the more parameters you have, the smaller the deviance is (or the bigger the likelihood is).</p>
-<p><span class=""math display"">\[\text{AIC} = - 2 \log(L(\hat{\theta}_1,\ldots,\hat{\theta}_K)) + {\color{purple}{2 K}}\]</span></p>
-<p><span style=""color: purple;"">A penalty</span>: twice the number of parameters <span class=""math inline"">\(K\)</span></p>
-<ul>
-<li><p>AIC makes the balance between <em>quality of fit</em> and <em>complexity</em> of a model.</p></li>
-<li><p>Best model is the one with lowest AIC value.</p></li>
-<li><p>Two models are difficult to distinguish if <span class=""math inline"">\(\Delta \text{AIC} &lt; 2\)</span>.</p></li>
-</ul>
-</div>
-<div id=""bayesian-version"" class=""section level2"" number=""5.3"">
-<h2>
-<span class=""header-section-number"">5.3</span> Bayesian version<a class=""anchor"" aria-label=""anchor"" href=""#bayesian-version""><i class=""fas fa-link""></i></a>
-</h2>
-<ul>
-<li>Watanabe-Akaike (Widely-Applicable) Information Criteria or WAIC:</li>
-</ul>
-<p><span class=""math display"">\[\textrm{WAIC} = -2 \sum_{i = 1}^n \log E[\Pr(y_i \mid \theta)] +
-                  2 p_\text{WAIC}\]</span></p>
-<ul>
-<li><p>where <span class=""math inline"">\(E[p(y_i \mid \theta)]\)</span> is the posterior mean of the likelihood evaluated pointwise at each <span class=""math inline"">\(i\)</span>th observation.</p></li>
-<li><p><span class=""math inline"">\(p_\text{WAIC}\)</span> is a penalty computed using the posterior variance of the likelihood.</p></li>
-<li><p>More in this video <a href=""https://www.youtube.com/watch?v=vSjL2Zc-gEQ"" class=""uri"">https://www.youtube.com/watch?v=vSjL2Zc-gEQ</a> by R. McElreath.</p></li>
-<li><p>Nimble provides the conditional WAIC, where all parameters directly involved in the likelihood are considered. If you would want to calculate the marginal WAIC, integrating over latent variables, you could monitor the relevant nodes and carry out the calculations yourself based on the MCMC output.</p></li>
-</ul>
-</div>
-<div id=""how-to-compute-waic-in-nimble"" class=""section level2"" number=""5.4"">
-<h2>
-<span class=""header-section-number"">5.4</span> How to compute WAIC in Nimble?<a class=""anchor"" aria-label=""anchor"" href=""#how-to-compute-waic-in-nimble""><i class=""fas fa-link""></i></a>
-</h2>
-<div class=""sourceCode"" id=""cb153""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span><span class=""va"">parameters.to.save</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/c.html"">c</a></span><span class=""op"">(</span><span class=""st"">""phi""</span>, <span class=""st"">""p""</span><span class=""op"">)</span></span>
-<span><span class=""va"">mcmc.phitpt</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/pkg/nimble/man/nimbleMCMC.html"">nimbleMCMC</a></span><span class=""op"">(</span>code <span class=""op"">=</span> <span class=""va"">hmm.phitpt</span>,</span>
-<span>                          constants <span class=""op"">=</span> <span class=""va"">my.constants</span>,</span>
-<span>                          data <span class=""op"">=</span> <span class=""va"">my.data</span>,</span>
-<span>                          inits <span class=""op"">=</span> <span class=""va"">initial.values</span>,</span>
-<span>                          monitors <span class=""op"">=</span> <span class=""va"">parameters.to.save</span>,</span>
-<span>                          niter <span class=""op"">=</span> <span class=""va"">n.iter</span>,</span>
-<span>                          nburnin <span class=""op"">=</span> <span class=""va"">n.burnin</span>,</span>
-<span>                          nchains <span class=""op"">=</span> <span class=""va"">n.chains</span><span class=""op"">)</span></span></code></pre></div>
-<div class=""sourceCode"" id=""cb154""><pre class=""downlit sourceCode r"">
-<code class=""sourceCode R""><span><span class=""va"">parameters.to.save</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/c.html"">c</a></span><span class=""op"">(</span><span class=""st"">""phi""</span>, <span class=""st"">""p""</span>, <span class=""st"">""z""</span><span class=""op"">)</span> <span class=""co"">#&lt;&lt;</span></span>
-<span><span class=""va"">mcmc.phitpt</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/pkg/nimble/man/nimbleMCMC.html"">nimbleMCMC</a></span><span class=""op"">(</span>code <span class=""op"">=</span> <span class=""va"">hmm.phitpt</span>,</span>
-<span>                          constants <span class=""op"">=</span> <span class=""va"">my.constants</span>,</span>
-<span>                          data <span class=""op"">=</span> <span class=""va"">my.data</span>,</span>
-<span>                          inits <span class=""op"">=</span> <span class=""va"">initial.values</span>,</span>
-<span>                          monitors <span class=""op"">=</span> <span class=""va"">parameters.to.save</span>,</span>
-<span>                          niter <span class=""op"">=</span> <span class=""va"">n.iter</span>,</span>
-<span>                          nburnin <span class=""op"">=</span> <span class=""va"">n.burnin</span>,</span>
-<span>                          nchains <span class=""op"">=</span> <span class=""va"">n.chains</span>,</span>
-<span>                          WAIC <span class=""op"">=</span> <span class=""cn"">TRUE</span><span class=""op"">)</span> <span class=""co"">#&lt;&lt;</span></span></code></pre></div>
-</div>
-<div id=""dipper-example---continued"" class=""section level2"" number=""5.5"">
-<h2>
-<span class=""header-section-number"">5.5</span> Dipper example - continued<a class=""anchor"" aria-label=""anchor"" href=""#dipper-example---continued""><i class=""fas fa-link""></i></a>
-</h2>
-<pre><code>##       model  WAIC
-## 1   (phi,p) 265.9
-## 2  (phit,p) 277.6
-## 3  (phi,pt) 270.2
-## 4 (phit,pt) 308.8</code></pre>
-
-</div>
-</div>
-
-
-
-  <div class=""chapter-nav"">
-<div class=""prev""><a href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></div>
-<div class=""next""><a href=""introduction-6.html"">Introduction</a></div>
-</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
-    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
-      <ul class=""nav navbar-nav"">
-<li><a class=""nav-link"" href=""#model-selection""><span class=""header-section-number"">5</span> Model selection and validation</a></li>
-<li><a class=""nav-link"" href=""#how-to-select-a-best-model-model-selection""><span class=""header-section-number"">5.1</span> How to select a best model? Model selection</a></li>
-<li><a class=""nav-link"" href=""#akaike-information-criterion-aic""><span class=""header-section-number"">5.2</span> Akaike information criterion (AIC)</a></li>
-<li><a class=""nav-link"" href=""#bayesian-version""><span class=""header-section-number"">5.3</span> Bayesian version</a></li>
-<li><a class=""nav-link"" href=""#how-to-compute-waic-in-nimble""><span class=""header-section-number"">5.4</span> How to compute WAIC in Nimble?</a></li>
-<li><a class=""nav-link"" href=""#dipper-example---continued""><span class=""header-section-number"">5.5</span> Dipper example - continued</a></li>
-</ul>
-
-      <div class=""book-extra"">
-        <ul class=""list-unstyled"">
-<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/modelselectiongof.Rmd"">View source <i class=""fab fa-github""></i></a></li>
-          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/modelselectiongof.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
-        </ul>
-</div>
-    </nav>
-</div>
-
-</div>
-</div> <!-- .container -->
-
-<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-07.</p>
-  </div>
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
-  </div>
-
-</div></div>
-</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
-  (function () {
-    var script = document.createElement(""script"");
-    script.type = ""text/javascript"";
-    var src = ""true"";
-    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
-    if (location.protocol !== ""file:"")
-      if (/^https?:/.test(src))
-        src = src.replace(/^https?:/, '');
-    script.src = src;
-    document.getElementsByTagName(""head"")[0].appendChild(script);
-  })();
-</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
-for (let popover of popovers) {
-  const div = document.createElement('div');
-  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
-  div.innerHTML = popover.getAttribute('data-content');
-
-  var has_math = div.querySelector(""span.math"");
-  if (has_math) {
-    document.body.appendChild(div);
-    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
-    MathJax.Hub.Queue(function() {
-      popover.setAttribute('data-content', div.innerHTML);
-      document.body.removeChild(div);
-    })
-  }
-}
-</script>
-</body>
-</html>

---FILE: docs/preface.html---
@@ -73,17 +73,13 @@ <h1>
 <li><a class="""" href=""about-the-author.html"">About the author</a></li>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
-<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
-<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
-<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
-<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
+<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">1</span> Survival</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>

---FILE: docs/reference-keys.txt---
@@ -1,97 +1,7 @@
-fig:revbayes
-fig:bayestheorem
-fig:binlik
-fig:numapprox
-fig:betadistribution
-fig:compar
-fig:mcmcpaper
-fig:chain
-fig:twochains
-fig:longchain
-fig:animlongchain
-fig:burnin
-fig:bgr
-fig:tracechainlength
-fig:acfchainlength
-fig:nimblelogo
-fig:dag-survival
-fig:traceown
-fig:treillis-viterbi
-fig:viterbiaveragecompute
-fig:viterbicomputeaverage
 fig:marking
 fig:pixdipper
-fig:unnamed-chunk-302
-fig:unnamed-chunk-319
-crashcourse
-introduction-1
-bayes-theorem
-what-is-the-bayesian-approach
-numerical-approx
-markov-chain-monte-carlo-mcmc
-monte-carlo-integration
-markovmodelmcmc
-metropolis-algorithm
-convergence-diag
-burn-in
-chain-length
-what-if-you-have-issues-of-convergence
-summary
-suggested-reading
-intronimble
-introduction-2
-what-is-nimble
-start-nimble
-functions-in-nimble
-nimble-functions
-callrfninnimble
-user-defined-distributions
-under-the-hood
-mcmc-samplers
-change-sampler
-user-defined-samplers
-tips-and-tricks
-precision-vs-standard-deviation
-indexing
-faster-compilation
-updating-mcmc-chains
-reproducibility
-parallelization
-incomplete-initialization
-vectorization
-summary-1
-suggested-reading-1
-hmmcapturerecapture
-introduction-3
-longitudinal-data
-a-markov-model-for-longitudinal-data
-assumptions
-transition-matrix
-initial-states
-likelihood
-example
-bayesian-formulation
-nimble-implementation
-hidden-markov-models
-capturerecapturedata
-observation-matrix
-hidden-markov-model
-likelihoodhmm
-fittinghmmnimble
-marginalization
-brute-force-approach
-forward-algorithm
-nimble-implementation-1
-pooled-likelihood
-decoding
-viterbi-theory
-implementation
-compute-average
-average-first-compute-after
-summary-2
-suggested-reading-2
 survival
-introduction-5
+introduction-2
 the-cormack-jolly-seber-cjs-model
 capture-recapture-data
 fitting-the-cjs-model-to-the-dipper-data-with-nimble
@@ -111,49 +21,5 @@ continuous-1
 several-covariates
 random-effects
 individual-time-varying-covariates
-summary-3
-suggested-reading-3
-dispersal
-introduction-6
-wintering-site-fidelity-in-canada-geese
-sites-carolinas-chesapeake-mid-atlantic
-biological-inference
-the-model-construction-how-we-should-think.
-the-model-construction-how-we-should-think.-1
-the-model-construction-how-we-should-think.-2
-the-model-construction-how-we-should-think.-3
-hmm-model-for-dispersal-with-2-sites-drop-carolinas
-hmm-model-for-dispersal-with-2-sites-drop-carolinas-1
-hmm-model-for-dispersal-with-2-sites-drop-carolinas-2
-our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b
-our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-1
-our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-2
-our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-3
-our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-4
-our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-5
-what-if-there-are-three-sites
-nimble-implementation-of-the-dirichlet-prior
-nimble-implementation-of-the-dirichlet-prior-1
-multinomial-logit
-nimble-implementation-of-the-dirichlet-prior-2
-nimble-implementation-of-the-dirichlet-prior-3
-sites-may-be-states.
-examples-of-multistate-models
-sooty-shearwater-david-boyle
-sooty-shearwaters-and-life-history-tradeoffs
-sooty-shearwaters-and-life-history-tradeoffs-1
-hmm-model-for-transition-between-states
-hmm-model-for-transition-between-states-1
-our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b
-our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-1
-our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-2
-our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-3
-our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-4
-issue-of-local-minima
-data
-uncertainty
-uncertainty-in-breeding-status-sooty-shearwater-david-boyle
-hmm-model-for-breeding-states-with-uncertainty
-results
-summary-4
-suggested-reading-4
+summary
+suggested-reading

---FILE: docs/references.html---
@@ -6,15 +6,15 @@
 <meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <title>References | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
 <meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""Albert, Jim, and Jingchen Hu. 2019. Probability and Bayesian Modeling. 1st edition. Chapman; Hall/CRC.  King, Ruth, B. J. T. Morgan, O. Gimenez, and S. P. Brooks. 2009. Bayesian Analysis for..."">
+<meta name=""description"" content=""Royle, J Andrew, Richard B Chandler, Rahel Sollmann, and Beth Gardner. 2013. Spatial Capture-Recapture. Academic Press.  Williams, B. K., J. D. Nichols, and M. J. Conroy. 2002. Analysis and..."">
 <meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
 <meta property=""og:title"" content=""References | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
 <meta property=""og:type"" content=""book"">
 <meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/references.html"">
-<meta property=""og:description"" content=""Albert, Jim, and Jingchen Hu. 2019. Probability and Bayesian Modeling. 1st edition. Chapman; Hall/CRC.  King, Ruth, B. J. T. Morgan, O. Gimenez, and S. P. Brooks. 2009. Bayesian Analysis for..."">
+<meta property=""og:description"" content=""Royle, J Andrew, Richard B Chandler, Rahel Sollmann, and Beth Gardner. 2013. Spatial Capture-Recapture. Academic Press.  Williams, B. K., J. D. Nichols, and M. J. Conroy. 2002. Analysis and..."">
 <meta name=""twitter:card"" content=""summary"">
 <meta name=""twitter:title"" content=""References | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta name=""twitter:description"" content=""Albert, Jim, and Jingchen Hu. 2019. Probability and Bayesian Modeling. 1st edition. Chapman; Hall/CRC.  King, Ruth, B. J. T. Morgan, O. Gimenez, and S. P. Brooks. 2009. Bayesian Analysis for..."">
+<meta name=""twitter:description"" content=""Royle, J Andrew, Richard B Chandler, Rahel Sollmann, and Beth Gardner. 2013. Spatial Capture-Recapture. Academic Press.  Williams, B. K., J. D. Nichols, and M. J. Conroy. 2002. Analysis and..."">
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
@@ -73,17 +73,13 @@ <h1>
 <li><a class="""" href=""about-the-author.html"">About the author</a></li>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
-<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
-<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
-<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
-<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
+<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">1</span> Survival</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class=""active"" href=""references.html"">References</a></li>
 </ul>
@@ -98,18 +94,6 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 </h1>
 
 <div id=""refs"" class=""references csl-bib-body hanging-indent"">
-<div id=""ref-alberthu2019"" class=""csl-entry"">
-Albert, Jim, and Jingchen Hu. 2019. <em>Probability and <span>Bayesian</span> <span>Modeling</span></em>. 1st edition. Chapman; Hall/CRC.
-</div>
-<div id=""ref-king_bayesian_2009"" class=""csl-entry"">
-King, Ruth, B. J. T. Morgan, O. Gimenez, and S. P. Brooks. 2009. <em>Bayesian <span>Analysis</span> for <span>Population</span> <span>Ecology</span></em>. Chapman; Hall/CRC.
-</div>
-<div id=""ref-mcelreathbook"" class=""csl-entry"">
-McElreath, Richard. 2016. <em>Statistical <span>Rethinking</span>: <span>A</span> <span>Bayesian</span> <span>Course</span> with <span>Examples</span> in <span>R</span> and <span>Stan</span></em>. 1st edition. Chapman; Hall/CRC.
-</div>
-<div id=""ref-mcgrayne2011"" class=""csl-entry"">
-McGrayne, Sharon Bertsch. 2011. <em>The <span>Theory</span> <span>That</span> <span>Would</span> <span>Not</span> <span>Die</span>: <span>How</span> <span>Bayes</span>‚Äô <span>Rule</span> <span>Cracked</span> the <span>Enigma</span> <span>Code</span>, <span>Hunted</span> <span>Down</span> <span>Russian</span> <span>Submarines</span>, and <span>Emerged</span> <span>Triumphant</span> from <span>Two</span> <span>Centuries</span> of <span>Controversy</span></em>. Yale University Press.
-</div>
 <div id=""ref-RoyleEtAl2013book"" class=""csl-entry"">
 Royle, J Andrew, Richard B Chandler, Rahel Sollmann, and Beth Gardner. 2013. <em>Spatial Capture-Recapture</em>. Academic Press.
 </div>
@@ -124,36 +108,6 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 
 
 
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
   <div class=""chapter-nav"">
 <div class=""prev""><a href=""take-home-messages.html"">Take-home messages</a></div>
 <div class=""empty""></div>

---FILE: docs/stopover.html---
@@ -1,162 +0,0 @@
-<!DOCTYPE html>
-<html lang=""en"">
-<head>
-<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
-<meta charset=""utf-8"">
-<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<title>Chapter 3 Stopover duration | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
-<meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""Paper by Gu√©rin et al. (2017)"">
-<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
-<meta property=""og:title"" content=""Chapter 3 Stopover duration | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta property=""og:type"" content=""book"">
-<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/stopover.html"">
-<meta property=""og:description"" content=""Paper by Gu√©rin et al. (2017)"">
-<meta name=""twitter:card"" content=""summary"">
-<meta name=""twitter:title"" content=""Chapter 3 Stopover duration | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta name=""twitter:description"" content=""Paper by Gu√©rin et al. (2017)"">
-<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
-<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
-    
-    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
-  </style>
-<style type=""text/css"">
-    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
-    div.csl-bib-body { }
-    div.csl-entry {
-      clear: both;
-        }
-    .hanging div.csl-entry {
-      margin-left:2em;
-      text-indent:-2em;
-    }
-    div.csl-left-margin {
-      min-width:2em;
-      float:left;
-    }
-    div.csl-right-inline {
-      margin-left:2em;
-      padding-left:1em;
-    }
-    div.csl-indent {
-      margin-left: 2em;
-    }
-  </style>
-<link rel=""stylesheet"" href=""bs4_style.css"">
-</head>
-<body data-spy=""scroll"" data-target=""#toc"">
-
-<div class=""container-fluid"">
-<div class=""row"">
-  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
-
-    <div class=""d-flex align-items-start justify-content-between"">
-      <h1>
-        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
-        <small class=""text-muted"">Theory and Case Studies in R</small>
-      </h1>
-      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
-    </div>
-
-    <div id=""main-nav"" class=""collapse-lg"">
-      <form role=""search"">
-        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
-</form>
-
-      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
-        <ul class=""book-toc list-unstyled"">
-<li><a class="""" href=""index.html"">Welcome</a></li>
-<li><a class="""" href=""preface.html"">Preface</a></li>
-<li><a class="""" href=""about-the-author.html"">About the author</a></li>
-<li class=""book-part"">I. Foundations</li>
-<li><a class="""" href=""introduction.html"">Introduction</a></li>
-<li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
-<li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
-<li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
-<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">1</span> Life history theory</a></li>
-<li><a class="""" href=""abundance.html""><span class=""header-section-number"">2</span> Abundance</a></li>
-<li><a class=""active"" href=""stopover.html""><span class=""header-section-number"">3</span> Stopover duration</a></li>
-<li><a class="""" href=""individual-dependence.html""><span class=""header-section-number"">4</span> Individual dependence</a></li>
-<li class=""book-part"">V. Conclusion</li>
-<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
-<li><a class="""" href=""references.html"">References</a></li>
-</ul>
-
-        <div class=""book-extra"">
-          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
-        </div>
-      </nav>
-</div>
-  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""stopover"" class=""section level1"" number=""3"">
-<h1>
-<span class=""header-section-number"">3</span> Stopover duration<a class=""anchor"" aria-label=""anchor"" href=""#stopover""><i class=""fas fa-link""></i></a>
-</h1>
-<p>Paper by <span class=""citation"">Gu√©rin et al. (<a href=""references.html#ref-guerin_advances_2017"">2017</a>)</span></p>
-
-</div>
-  <div class=""chapter-nav"">
-<div class=""prev""><a href=""abundance.html""><span class=""header-section-number"">2</span> Abundance</a></div>
-<div class=""next""><a href=""individual-dependence.html""><span class=""header-section-number"">4</span> Individual dependence</a></div>
-</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
-    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
-      <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#stopover""><span class=""header-section-number"">3</span> Stopover duration</a></li></ul>
-
-      <div class=""book-extra"">
-        <ul class=""list-unstyled"">
-<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/stopover.Rmd"">View source <i class=""fab fa-github""></i></a></li>
-          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/stopover.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
-        </ul>
-</div>
-    </nav>
-</div>
-
-</div>
-</div> <!-- .container -->
-
-<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-08.</p>
-  </div>
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
-  </div>
-
-</div></div>
-</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
-  (function () {
-    var script = document.createElement(""script"");
-    script.type = ""text/javascript"";
-    var src = ""true"";
-    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
-    if (location.protocol !== ""file:"")
-      if (/^https?:/.test(src))
-        src = src.replace(/^https?:/, '');
-    script.src = src;
-    document.getElementsByTagName(""head"")[0].appendChild(script);
-  })();
-</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
-for (let popover of popovers) {
-  const div = document.createElement('div');
-  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
-  div.innerHTML = popover.getAttribute('data-content');
-
-  var has_math = div.querySelector(""span.math"");
-  if (has_math) {
-    document.body.appendChild(div);
-    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
-    MathJax.Hub.Queue(function() {
-      popover.setAttribute('data-content', div.innerHTML);
-      document.body.removeChild(div);
-    })
-  }
-}
-</script>
-</body>
-</html>

---FILE: docs/take-home-messages.html---
@@ -73,17 +73,13 @@ <h1>
 <li><a class="""" href=""about-the-author.html"">About the author</a></li>
 <li class=""book-part"">I. Foundations</li>
 <li><a class="""" href=""introduction.html"">Introduction</a></li>
-<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
-<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
-<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
-<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Movements between sites, and states</a></li>
+<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">1</span> Survival</a></li>
 <li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-8.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class=""active"" href=""take-home-messages.html"">Take-home messages</a></li>
 <li><a class="""" href=""references.html"">References</a></li>
 </ul>
@@ -172,7 +168,7 @@ <h1>Take-home messages<a class=""anchor"" aria-label=""anchor"" href=""#take-home-mes
 
 </div>
   <div class=""chapter-nav"">
-<div class=""prev""><a href=""introduction-8.html"">Introduction</a></div>
+<div class=""prev""><a href=""introduction-4.html"">Introduction</a></div>
 <div class=""next""><a href=""references.html"">References</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>

---FILE: docs/tradeoffs.html---
@@ -1,205 +0,0 @@
-<!DOCTYPE html>
-<html lang=""en"">
-<head>
-<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
-<meta charset=""utf-8"">
-<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<title>Chapter 1 Life history theory | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
-<meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""1.1 Tradeoffs Morano et al. (2013), Shefferson et al. (2003), and Cruz-Flores et al. (n.d.)  1.2 Breeding dynamics Pradel, Choquet, and B√©chet (2012), Desprez et al. (2011), Desprez et al. (2013),..."">
-<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
-<meta property=""og:title"" content=""Chapter 1 Life history theory | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta property=""og:type"" content=""book"">
-<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/tradeoffs.html"">
-<meta property=""og:description"" content=""1.1 Tradeoffs Morano et al. (2013), Shefferson et al. (2003), and Cruz-Flores et al. (n.d.)  1.2 Breeding dynamics Pradel, Choquet, and B√©chet (2012), Desprez et al. (2011), Desprez et al. (2013),..."">
-<meta name=""twitter:card"" content=""summary"">
-<meta name=""twitter:title"" content=""Chapter 1 Life history theory | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta name=""twitter:description"" content=""1.1 Tradeoffs Morano et al. (2013), Shefferson et al. (2003), and Cruz-Flores et al. (n.d.)  1.2 Breeding dynamics Pradel, Choquet, and B√©chet (2012), Desprez et al. (2011), Desprez et al. (2013),..."">
-<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
-<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
-    
-    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
-  </style>
-<style type=""text/css"">
-    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
-    div.csl-bib-body { }
-    div.csl-entry {
-      clear: both;
-        }
-    .hanging div.csl-entry {
-      margin-left:2em;
-      text-indent:-2em;
-    }
-    div.csl-left-margin {
-      min-width:2em;
-      float:left;
-    }
-    div.csl-right-inline {
-      margin-left:2em;
-      padding-left:1em;
-    }
-    div.csl-indent {
-      margin-left: 2em;
-    }
-  </style>
-<link rel=""stylesheet"" href=""bs4_style.css"">
-</head>
-<body data-spy=""scroll"" data-target=""#toc"">
-
-<div class=""container-fluid"">
-<div class=""row"">
-  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
-
-    <div class=""d-flex align-items-start justify-content-between"">
-      <h1>
-        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
-        <small class=""text-muted"">Theory and Case Studies in R</small>
-      </h1>
-      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
-    </div>
-
-    <div id=""main-nav"" class=""collapse-lg"">
-      <form role=""search"">
-        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
-</form>
-
-      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
-        <ul class=""book-toc list-unstyled"">
-<li><a class="""" href=""index.html"">Welcome</a></li>
-<li><a class="""" href=""preface.html"">Preface</a></li>
-<li><a class="""" href=""about-the-author.html"">About the author</a></li>
-<li class=""book-part"">I. Foundations</li>
-<li><a class="""" href=""introduction.html"">Introduction</a></li>
-<li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
-<li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
-<li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
-<li><a class=""active"" href=""tradeoffs.html""><span class=""header-section-number"">1</span> Life history theory</a></li>
-<li><a class="""" href=""abundance.html""><span class=""header-section-number"">2</span> Abundance</a></li>
-<li><a class="""" href=""stopover.html""><span class=""header-section-number"">3</span> Stopover duration</a></li>
-<li><a class="""" href=""individual-dependence.html""><span class=""header-section-number"">4</span> Individual dependence</a></li>
-<li class=""book-part"">V. Conclusion</li>
-<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
-<li><a class="""" href=""references.html"">References</a></li>
-</ul>
-
-        <div class=""book-extra"">
-          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
-        </div>
-      </nav>
-</div>
-  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""tradeoffs"" class=""section level1"" number=""1"">
-<h1>
-<span class=""header-section-number"">1</span> Life history theory<a class=""anchor"" aria-label=""anchor"" href=""#tradeoffs""><i class=""fas fa-link""></i></a>
-</h1>
-<div id=""tradeoffs-1"" class=""section level2"" number=""1.1"">
-<h2>
-<span class=""header-section-number"">1.1</span> Tradeoffs<a class=""anchor"" aria-label=""anchor"" href=""#tradeoffs-1""><i class=""fas fa-link""></i></a>
-</h2>
-<p><span class=""citation"">Morano et al. (<a href=""references.html#ref-morano_life-history_2013"">2013</a>)</span>, <span class=""citation"">Shefferson et al. (<a href=""references.html#ref-shefferson_life_2003"">2003</a>)</span>, and <span class=""citation"">Cruz-Flores et al. (<a href=""references.html#ref-cruz-flores_sex-specific_nodate"">n.d.</a>)</span></p>
-</div>
-<div id=""breeding-dynamics"" class=""section level2"" number=""1.2"">
-<h2>
-<span class=""header-section-number"">1.2</span> Breeding dynamics<a class=""anchor"" aria-label=""anchor"" href=""#breeding-dynamics""><i class=""fas fa-link""></i></a>
-</h2>
-<p><span class=""citation"">Pradel, Choquet, and B√©chet (<a href=""references.html#ref-pradel_breeding_2012"">2012</a>)</span>, <span class=""citation"">Desprez et al. (<a href=""references.html#ref-desprez_now_2011"">2011</a>)</span>, <span class=""citation"">Desprez et al. (<a href=""references.html#ref-desprez_known_2013"">2013</a>)</span>, and <span class=""citation"">Pacoureau et al. (<a href=""references.html#ref-pacoureau_population_2019"">2019</a>)</span></p>
-</div>
-<div id=""actuarial-senescence"" class=""section level2"" number=""1.3"">
-<h2>
-<span class=""header-section-number"">1.3</span> Actuarial senescence<a class=""anchor"" aria-label=""anchor"" href=""#actuarial-senescence""><i class=""fas fa-link""></i></a>
-</h2>
-<p><span class=""citation"">Choquet et al. (<a href=""references.html#ref-choquet_semi-markov_2011"">2011</a>)</span>, <span class=""citation"">P√©ron et al. (<a href=""references.html#ref-peron_evidence_2016"">2016</a>)</span></p>
-</div>
-<div id=""cause-specific-mortalities"" class=""section level2"" number=""1.4"">
-<h2>
-<span class=""header-section-number"">1.4</span> Cause-specific mortalities<a class=""anchor"" aria-label=""anchor"" href=""#cause-specific-mortalities""><i class=""fas fa-link""></i></a>
-</h2>
-<p><span class=""citation"">Fern√°ndez-Chac√≥n et al. (<a href=""references.html#ref-fernandez-chacon_causes_2016"">2016</a>)</span> and <span class=""citation"">Ruette et al. (<a href=""references.html#ref-ruette_comparative_2015"">2015</a>)</span></p>
-</div>
-<div id=""disease-dynamics"" class=""section level2"" number=""1.5"">
-<h2>
-<span class=""header-section-number"">1.5</span> Disease dynamics<a class=""anchor"" aria-label=""anchor"" href=""#disease-dynamics""><i class=""fas fa-link""></i></a>
-</h2>
-<p><span class=""citation"">Marescot et al. (<a href=""references.html#ref-MarescotEtAl2018"">2018</a>)</span> and <span class=""citation"">Santoro et al. (<a href=""references.html#ref-santoro_multi-event_2014"">2014</a>)</span></p>
-</div>
-<div id=""sex-uncertainty"" class=""section level2"" number=""1.6"">
-<h2>
-<span class=""header-section-number"">1.6</span> Sex uncertainty<a class=""anchor"" aria-label=""anchor"" href=""#sex-uncertainty""><i class=""fas fa-link""></i></a>
-</h2>
-<p><span class=""citation"">Pradel et al. (<a href=""references.html#ref-PradelEtAl2008"">2008</a>)</span> and <span class=""citation"">Genovart, Pradel, and Oro (<a href=""references.html#ref-genovart_exploiting_2012"">2012</a>)</span></p>
-
-</div>
-</div>
-  <div class=""chapter-nav"">
-<div class=""prev""><a href=""introduction-3.html"">Introduction</a></div>
-<div class=""next""><a href=""abundance.html""><span class=""header-section-number"">2</span> Abundance</a></div>
-</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
-    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
-      <ul class=""nav navbar-nav"">
-<li><a class=""nav-link"" href=""#tradeoffs""><span class=""header-section-number"">1</span> Life history theory</a></li>
-<li><a class=""nav-link"" href=""#tradeoffs-1""><span class=""header-section-number"">1.1</span> Tradeoffs</a></li>
-<li><a class=""nav-link"" href=""#breeding-dynamics""><span class=""header-section-number"">1.2</span> Breeding dynamics</a></li>
-<li><a class=""nav-link"" href=""#actuarial-senescence""><span class=""header-section-number"">1.3</span> Actuarial senescence</a></li>
-<li><a class=""nav-link"" href=""#cause-specific-mortalities""><span class=""header-section-number"">1.4</span> Cause-specific mortalities</a></li>
-<li><a class=""nav-link"" href=""#disease-dynamics""><span class=""header-section-number"">1.5</span> Disease dynamics</a></li>
-<li><a class=""nav-link"" href=""#sex-uncertainty""><span class=""header-section-number"">1.6</span> Sex uncertainty</a></li>
-</ul>
-
-      <div class=""book-extra"">
-        <ul class=""list-unstyled"">
-<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/lht.Rmd"">View source <i class=""fab fa-github""></i></a></li>
-          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/lht.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
-        </ul>
-</div>
-    </nav>
-</div>
-
-</div>
-</div> <!-- .container -->
-
-<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-08.</p>
-  </div>
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
-  </div>
-
-</div></div>
-</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
-  (function () {
-    var script = document.createElement(""script"");
-    script.type = ""text/javascript"";
-    var src = ""true"";
-    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
-    if (location.protocol !== ""file:"")
-      if (/^https?:/.test(src))
-        src = src.replace(/^https?:/, '');
-    script.src = src;
-    document.getElementsByTagName(""head"")[0].appendChild(script);
-  })();
-</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
-for (let popover of popovers) {
-  const div = document.createElement('div');
-  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
-  div.innerHTML = popover.getAttribute('data-content');
-
-  var has_math = div.querySelector(""span.math"");
-  if (has_math) {
-    document.body.appendChild(div);
-    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
-    MathJax.Hub.Queue(function() {
-      popover.setAttribute('data-content', div.innerHTML);
-      document.body.removeChild(div);
-    })
-  }
-}
-</script>
-</body>
-</html>

---FILE: docs/uncertainty.html---
@@ -1,1102 +0,0 @@
-<!DOCTYPE html>
-<html lang=""en"">
-<head>
-<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
-<meta charset=""utf-8"">
-<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<title>Chapter 6 State uncertainty | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>
-<meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""WORK IN PROGRESS."">
-<meta name=""generator"" content=""bookdown 0.33 with bs4_book()"">
-<meta property=""og:title"" content=""Chapter 6 State uncertainty | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta property=""og:type"" content=""book"">
-<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/uncertainty.html"">
-<meta property=""og:description"" content=""WORK IN PROGRESS."">
-<meta name=""twitter:card"" content=""summary"">
-<meta name=""twitter:title"" content=""Chapter 6 State uncertainty | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models"">
-<meta name=""twitter:description"" content=""WORK IN PROGRESS."">
-<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
-<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.5.0/transition.js""></script><script src=""libs/bs3compat-0.5.0/tabs.js""></script><script src=""libs/bs3compat-0.5.0/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><style type=""text/css"">
-    
-    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
-  </style>
-<style type=""text/css"">
-    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
-    div.csl-bib-body { }
-    div.csl-entry {
-      clear: both;
-        }
-    .hanging div.csl-entry {
-      margin-left:2em;
-      text-indent:-2em;
-    }
-    div.csl-left-margin {
-      min-width:2em;
-      float:left;
-    }
-    div.csl-right-inline {
-      margin-left:2em;
-      padding-left:1em;
-    }
-    div.csl-indent {
-      margin-left: 2em;
-    }
-  </style>
-<link rel=""stylesheet"" href=""bs4_style.css"">
-</head>
-<body data-spy=""scroll"" data-target=""#toc"">
-
-<div class=""container-fluid"">
-<div class=""row"">
-  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
-
-    <div class=""d-flex align-items-start justify-content-between"">
-      <h1>
-        <a href=""index.html"" title=""Theory and Case Studies in R"">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</a>:
-        <small class=""text-muted"">Theory and Case Studies in R</small>
-      </h1>
-      <button class=""btn btn-outline-primary d-lg-none ml-2 mt-1"" type=""button"" data-toggle=""collapse"" data-target=""#main-nav"" aria-expanded=""true"" aria-controls=""main-nav""><i class=""fas fa-bars""></i><span class=""sr-only"">Show table of contents</span></button>
-    </div>
-
-    <div id=""main-nav"" class=""collapse-lg"">
-      <form role=""search"">
-        <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
-</form>
-
-      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
-        <ul class=""book-toc list-unstyled"">
-<li><a class="""" href=""index.html"">Welcome</a></li>
-<li><a class="""" href=""preface.html"">Preface</a></li>
-<li><a class="""" href=""about-the-author.html"">About the author</a></li>
-<li class=""book-part"">I. Foundations</li>
-<li><a class="""" href=""introduction.html"">Introduction</a></li>
-<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
-<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE tutorial</a></li>
-<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
-<li><a class="""" href=""dispersal.html""><span class=""header-section-number"">5</span> Dispersal</a></li>
-<li><a class=""active"" href=""uncertainty.html""><span class=""header-section-number"">6</span> State uncertainty</a></li>
-<li class=""book-part"">III. Case studies</li>
-<li><a class="""" href=""introduction-6.html"">Introduction</a></li>
-<li class=""book-part"">IV. Conclusions</li>
-<li><a class="""" href=""introduction-7.html"">Introduction</a></li>
-<li><a class="""" href=""take-home-messages.html"">Take-home messages</a></li>
-<li><a class="""" href=""faq.html"">FAQ</a></li>
-<li><a class="""" href=""references.html"">References</a></li>
-</ul>
-
-        <div class=""book-extra"">
-          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
-        </div>
-      </nav>
-</div>
-  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""uncertainty"" class=""section level1"" number=""6"">
-<h1>
-<span class=""header-section-number"">6</span> State uncertainty<a class=""anchor"" aria-label=""anchor"" href=""#uncertainty""><i class=""fas fa-link""></i></a>
-</h1>
-<p>WORK IN PROGRESS.</p>
-<!-- ## Introduction -->
-<!-- In this module, we're going to talk about multievent models. Multievent models extend multistate models with uncertainty in state assignment. Let's see some examples to fix ideas. These examples are from published papers which used multievent models. -->
-<!-- + Breeding status in female roe deer is ascertained based on fawn detection -->
-<!-- + Sex status is ascertained based on morphological criteria in Audouin's gulls -->
-<!-- + Disease status in house finches is ascertained based on birds' eyes examination -->
-<!-- + Hybrid status in wolves is ascertained based on genetics -->
-<!-- + Dominance status in wolves is ascertained based on heterogeneity in detection -->
-<!-- The common thing to all these examples is that. We need to explicitly consider state assignment in a model. HMMs to the rescue! And to do that, we'll use HMMs again! -->
-<!-- Examples -->
-<!-- + Testing life-history trade-offs while accounting for uncertainty in breeding status -->
-<!-- + Quantifying disease dynamics while accounting for uncertainty in disease status -->
-<!-- + Estimating survival while accounting for individual heterogeneity in detection -->
-<!-- + In this module, I'll go through 3 examples. -->
-<!-- + Testing life-history trade-offs while accounting for uncertainty in breeding status. -->
-<!-- + Quantifying disease dynamics while accounting for uncertainty in disease status. -->
-<!-- + Estimating survival while accounting for individual heterogeneity in detection. -->
-<!-- + **Testing life-history trade-offs while accounting for uncertainty in breeding status** -->
-<!-- + Quantifying disease dynamics while accounting for uncertainty in disease status -->
-<!-- + Estimating survival while accounting for individual heterogeneity in detection -->
-<!-- ```{r} -->
-<!-- knitr::include_graphics(""images/sooty.jpg"") -->
-<!-- ``` -->
-<!-- ## Uncertainty in breeding status: Sooty shearwater (David Boyle) -->
-<!-- ### Ingredients -->
-<!-- + 3 states -->
-<!--     + breeding (B) -->
-<!--     + non-breeding (NB) -->
-<!--     + dead (D) -->
-<!-- + 4 observations -->
-<!--     + not encountered (0) -->
-<!--     + found, ascertained as breeder (1) -->
-<!--     + found, ascertained as non-breeder (2) -->
-<!--     + found, status unknown (3) -->
-<!-- + We still have 3 states, breeding, non-breeding and dead. -->
-<!-- + With regard to observations, a bird may be not encountered. -->
-<!-- + It may also be encountered, but in contrast with multistate CR data, we don't know its state for sure. -->
-<!-- + It may be found and ascertained or classified as breeder. -->
-<!-- + It may be found and ascertained or classified as non-breeder. -->
-<!-- + It may be found be we are unable to determine whether it's breeding or non-breeding. -->
-<!-- ### How states generate observations -->
-<!-- ```{r, echo = FALSE} -->
-<!-- ggplot() + -->
-<!--   geom_point(aes(1, 1), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1, 2), size = 2.5, alpha = .7) + -->
-<!--   geom_text(aes(1.5, 2, label = 'not encountered (0)'), nudge_x = 1, size = 7) + -->
-<!--   geom_text(aes(1.5, 1.5, label = 'found, ascertained as breeder (1)'), nudge_x = 1.5, size = 7) + -->
-<!--   geom_text(aes(1.5, 1, label = 'found, ascertained as non-breeder (2)'), nudge_x = 1.7, size = 7) + -->
-<!--   geom_text(aes(1.5, 0.5, label = 'found, status unknown (3)'), nudge_x = 1.2, size = 7) + -->
-<!--   geom_point(aes(1.5, 0.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1.5, 1), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1.5, 1.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1.5, 2), size = 2.5, alpha = .7) + -->
-<!--   geom_text(aes(.5, 2, label = 'breeding'), nudge_x = 0, size = 7) + -->
-<!--   geom_text(aes(.5, 1.5, label = 'non-breeding'), nudge_x = -0.2, size = 7) + -->
-<!--   geom_text(aes(.5, 1, label = 'dead'), nudge_x = 0.1, size = 7) + -->
-<!--   xlim(0, 4.5) + -->
-<!--   ylim(0.5, 3) + -->
-<!--   annotate('text', x = .5, y = 2.6, label = 'States', size = 10) + -->
-<!--   annotate('text', x = 2.5, y = 2.6, label = 'Observations', size = 10) + -->
-<!--   theme_void() -->
-<!-- ``` -->
-<!-- Now how do the states generate the observations? -->
-<!-- ```{r, echo = FALSE} -->
-<!-- ggplot() + -->
-<!--   geom_point(aes(1, 1), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1, 2), size = 2.5, alpha = .7) + -->
-<!--   geom_text(aes(1.5, 2, label = 'not encountered (0)'), nudge_x = 1, size = 7) + -->
-<!--   geom_text(aes(1.5, 1.5, label = 'found, ascertained as breeder (1)'), nudge_x = 1.5, size = 7) + -->
-<!--   geom_text(aes(1.5, 1, label = 'found, ascertained as non-breeder (2)'), nudge_x = 1.7, size = 7) + -->
-<!--   geom_text(aes(1.5, 0.5, label = 'found, status unknown (3)'), nudge_x = 1.2, size = 7) + -->
-<!--   geom_point(aes(1.5, 0.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1.5, 1), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1.5, 1.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1.5, 2), size = 2.5, alpha = .7) + -->
-<!--   geom_text(aes(.5, 2, label = 'breeding'), nudge_x = 0, size = 7) + -->
-<!--   geom_text(aes(.5, 1.5, label = 'non-breeding'), nudge_x = -0.2, size = 7) + -->
-<!--   geom_text(aes(.5, 1, label = 'dead'), nudge_x = 0.1, size = 7) + -->
-<!--   xlim(0, 4.5) + -->
-<!--   ylim(0.5, 3) + -->
-<!--   annotate('text', x = .5, y = 2.6, label = 'States', size = 10) + -->
-<!--   annotate('text', x = 2.5, y = 2.6, label = 'Observations', size = 10) + -->
-<!--   geom_segment(aes(x = 1, y = 1, xend = 1.5, yend = 2), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   theme_void() -->
-<!-- ``` -->
-<!-- ```{r, echo = FALSE} -->
-<!-- ggplot() + -->
-<!--   geom_point(aes(1, 1), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1, 2), size = 2.5, alpha = .7) + -->
-<!--   geom_text(aes(1.5, 2, label = 'not encountered (0)'), nudge_x = 1, size = 7) + -->
-<!--   geom_text(aes(1.5, 1.5, label = 'found, ascertained as breeder (1)'), nudge_x = 1.5, size = 7) + -->
-<!--   geom_text(aes(1.5, 1, label = 'found, ascertained as non-breeder (2)'), nudge_x = 1.7, size = 7) + -->
-<!--   geom_text(aes(1.5, 0.5, label = 'found, status unknown (3)'), nudge_x = 1.2, size = 7) + -->
-<!--   geom_point(aes(1.5, 0.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1.5, 1), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1.5, 1.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1.5, 2), size = 2.5, alpha = .7) + -->
-<!--   geom_text(aes(.5, 2, label = 'breeding'), nudge_x = 0, size = 7) + -->
-<!--   geom_text(aes(.5, 1.5, label = 'non-breeding'), nudge_x = -0.2, size = 7) + -->
-<!--   geom_text(aes(.5, 1, label = 'dead'), nudge_x = 0.1, size = 7) + -->
-<!--   xlim(0, 4.5) + -->
-<!--   ylim(0.5, 3) + -->
-<!--   annotate('text', x = .5, y = 2.6, label = 'States', size = 10) + -->
-<!--   annotate('text', x = 2.5, y = 2.6, label = 'Observations', size = 10) + -->
-<!--   geom_segment(aes(x = 1, y = 2, xend = 1.5, yend = .5), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   geom_segment(aes(x = 1, y = 2, xend = 1.5, yend = 1.5), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   geom_segment(aes(x = 1, y = 2, xend = 1.5, yend = 2), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   theme_void() -->
-<!-- ``` -->
-<!-- ```{r, echo = FALSE} -->
-<!-- ggplot() + -->
-<!--   geom_point(aes(1, 1), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1, 2), size = 2.5, alpha = .7) + -->
-<!--   geom_text(aes(1.5, 2, label = 'not encountered (0)'), nudge_x = 1, size = 7) + -->
-<!--   geom_text(aes(1.5, 1.5, label = 'found, ascertained as breeder (1)'), nudge_x = 1.5, size = 7) + -->
-<!--   geom_text(aes(1.5, 1, label = 'found, ascertained as non-breeder (2)'), nudge_x = 1.7, size = 7) + -->
-<!--   geom_text(aes(1.5, 0.5, label = 'found, status unknown (3)'), nudge_x = 1.2, size = 7) + -->
-<!--   geom_point(aes(1.5, 0.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1.5, 1), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1.5, 1.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1.5, 2), size = 2.5, alpha = .7) + -->
-<!--   geom_text(aes(.5, 2, label = 'breeding'), nudge_x = 0, size = 7) + -->
-<!--   geom_text(aes(.5, 1.5, label = 'non-breeding'), nudge_x = -0.2, size = 7) + -->
-<!--   geom_text(aes(.5, 1, label = 'dead'), nudge_x = 0.1, size = 7) + -->
-<!--   xlim(0, 4.5) + -->
-<!--   ylim(0.5, 3) + -->
-<!--   annotate('text', x = .5, y = 2.6, label = 'States', size = 10) + -->
-<!--   annotate('text', x = 2.5, y = 2.6, label = 'Observations', size = 10) + -->
-<!--   geom_segment(aes(x = 1, y = 1.5, xend = 1.5, yend = 1), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   geom_segment(aes(x = 1, y = 1.5, xend = 1.5, yend = 2), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   geom_segment(aes(x = 1, y = 1.5, xend = 1.5, yend = .5), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   theme_void() -->
-<!-- ``` -->
-<!-- ```{r, echo = FALSE} -->
-<!-- ggplot() + -->
-<!--   geom_point(aes(1, 1), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1, 2), size = 2.5, alpha = .7) + -->
-<!--   geom_text(aes(1.5, 2, label = 'not encountered (0)'), nudge_x = 1, size = 7) + -->
-<!--   geom_text(aes(1.5, 1.5, label = 'found, ascertained as breeder (1)'), nudge_x = 1.5, size = 7) + -->
-<!--   geom_text(aes(1.5, 1, label = 'found, ascertained as non-breeder (2)'), nudge_x = 1.7, size = 7) + -->
-<!--   geom_text(aes(1.5, 0.5, label = 'found, status unknown (3)'), nudge_x = 1.2, size = 7) + -->
-<!--   geom_point(aes(1.5, 0.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1.5, 1), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1.5, 1.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1.5, 2), size = 2.5, alpha = .7) + -->
-<!--   geom_text(aes(.5, 2, label = 'breeding'), nudge_x = 0, size = 7) + -->
-<!--   geom_text(aes(.5, 1.5, label = 'non-breeding'), nudge_x = -0.2, size = 7) + -->
-<!--   geom_text(aes(.5, 1, label = 'dead'), nudge_x = 0.1, size = 7) + -->
-<!--   xlim(0, 4.5) + -->
-<!--   ylim(0.5, 3) + -->
-<!--   annotate('text', x = .5, y = 2.6, label = 'States', size = 10) + -->
-<!--   annotate('text', x = 2.5, y = 2.6, label = 'Observations', size = 10) + -->
-<!--   geom_segment(aes(x = 1, y = 1, xend = 1.5, yend = 2), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   geom_segment(aes(x = 1, y = 1.5, xend = 1.5, yend = 1), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   geom_segment(aes(x = 1, y = 1.5, xend = 1.5, yend = 2), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   geom_segment(aes(x = 1, y = 1.5, xend = 1.5, yend = .5), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   geom_segment(aes(x = 1, y = 2, xend = 1.5, yend = .5), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   geom_segment(aes(x = 1, y = 2, xend = 1.5, yend = 1.5), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   geom_segment(aes(x = 1, y = 2, xend = 1.5, yend = 2), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   theme_void() -->
-<!-- ``` -->
-<!-- To wrap up each live state can generate 3 observations. The only deterministic link is that between the dead state and the observation non-encountered. Cause if you're dead, you cannot be detected for sure. -->
-<!-- ### HMM model for breeding states with uncertainty -->
-<!-- Vector of initial state probabilities -->
-<!-- $$ -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \mathbf{\delta} = -->
-<!--     \left ( \vphantom{ \begin{matrix} 12 \end{matrix} } \right . -->
-<!-- \end{matrix} -->
-<!-- \hspace{-1.2em} -->
-<!-- \begin{matrix} -->
-<!--     z_t=B & z_t=NB & z_t=D \\ \hdashline -->
-<!-- \pi_B & 1 - \pi_{B} & 0\\ -->
-<!-- \end{matrix} -->
-<!-- \hspace{-0.2em} -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \left . \vphantom{ \begin{matrix} 12 \end{matrix} } \right ) -->
-<!--     \begin{matrix} -->
-<!--     \end{matrix} -->
-<!-- \end{matrix} -->
-<!-- $$ -->
-<!-- $\pi_B$ is the probability that a newly encountered individual is a breeder. $\pi_{NB} = 1 - \pi_B$ is the probability that a newly encountered individual is a non-breeder -->
-<!-- OK now let‚Äôs specify the model. First thing we need, and it‚Äôs a big difference with multistate models, we need initial state probabilities cause we cannot assign states to individuals w/ certainty. Let's define pi_B the prob that a newly encountered individual is a breeding individual. We write down the prob for each state at first encounter. We have pi_B, then the prob of being a NB is the complementary. And the prob of being dead at first encounter is 0 of course. -->
-<!-- Transition matrix -->
-<!-- $$ -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \mathbf{\Gamma} = -->
-<!--     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right . -->
-<!-- \end{matrix} -->
-<!-- \hspace{-1.2em} -->
-<!-- \begin{matrix} -->
-<!--     z_t=B & z_t=NB & z_t=D \\ \hdashline -->
-<!-- \phi_B (1-\psi_{BNB}) & \phi_B \psi_{BNB} & 1 - \phi_B\\ -->
-<!-- \phi_{NB} \psi_{NBB} & \phi_{NB} (1-\psi_{NBB}) & 1 - \phi_{NB}\\ -->
-<!-- 0 & 0 & 1 -->
-<!-- \end{matrix} -->
-<!-- \hspace{-0.2em} -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right ) -->
-<!--     \begin{matrix} -->
-<!--     z_{t-1}=B \\ z_{t-1}=NB \\ z_{t-1}=D -->
-<!--     \end{matrix} -->
-<!-- \end{matrix} -->
-<!-- $$ -->
-<!-- $\phi_B$ is breeder survival, $\phi_{NB}$ that of non-breeders. $\psi_{BNB}$ is the probability for an individual breeding a year to be a non-breeder the next year. $\psi_{NBB}$ is the probability for an non-breeder individual to breeder the next year. The transition parameters are in a matrix similar to the one we used for multistate models. -->
-<!-- Observation matrix -->
-<!-- $$ -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \mathbf{\Omega} = -->
-<!--     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right . -->
-<!-- \end{matrix} -->
-<!-- \hspace{-1.2em} -->
-<!-- \begin{matrix} -->
-<!--     y_t=0 & y_t=1 & y_t=2 & y_t=3\\ \hdashline -->
-<!-- 1 - p_B & p_B \beta_B & 0 & p_B (1-\beta_B) \\ -->
-<!-- 1-p_{NB} & 0 & p_{NB} \beta_{NB} & p_{NB} (1-\beta_{NB})\\ -->
-<!-- 1 & 0 & 0 & 0 -->
-<!-- \end{matrix} -->
-<!-- \hspace{-0.2em} -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right ) -->
-<!--     \begin{matrix} -->
-<!--     z_{t}=B \\ z_{t}=NB \\ z_{t}=D -->
-<!--     \end{matrix} -->
-<!-- \end{matrix} -->
-<!-- $$ -->
-<!-- $\beta_B$ is the probability to assign an individual in state B to state B. $\beta_{NB}$ is the probability to assign an individual in state NB to state NB. $p_B$ is the detection probability of breeders, $p_{NB}$ that of non-breeders. -->
-<!-- The main difference between multistate and multievent models is here, in the observation parameters. We introduce two new parameters. $\delta_B$: prob. to correctly assign an indiv. that is in state B to state B, $\delta_{NB}$: prob. to correctly assign an indiv. that is in state NB to state NB. We put everything in a matrix, as usual. The observation matrix. In rows we have the states, breeding, non-breeding and dead. In columns, at the same occasion, we have the observation, detected and ascertained B, -->
-<!-- detected and ascertained NB, detected and state unknown, and not detected. For example, the prob of being detected and assigned to the state B, given that you‚Äôre in state B is the product of the detection prob in B and delta the prob of correctly assigning a B individual to state B. -->
-<!-- Because animals are all captured, $p_B = p_{NB} = 1$ at first encounter: -->
-<!-- $$ -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!--     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right . -->
-<!-- \end{matrix} -->
-<!-- \hspace{-1.2em} -->
-<!-- \begin{matrix} -->
-<!--     y_t=0 & y_t=1 & y_t=2 & y_t=3\\ \hdashline -->
-<!--  0 & \beta_B & 0 & (1-\beta_B)\\ -->
-<!-- 0 & 0 & \beta_{NB} & (1-\beta_{NB})\\ -->
-<!-- 1 & 0 & 0 & 0 -->
-<!-- \end{matrix} -->
-<!-- \hspace{-0.2em} -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right ) -->
-<!--     \begin{matrix} -->
-<!--     z_{t}=B \\ z_{t}=NB \\ z_{t}=D -->
-<!--     \end{matrix} -->
-<!-- \end{matrix} -->
-<!-- $$ -->
-<!-- Note: Breeding assessment is unaffected. Then at first encounter, what happens is that step 1 of encounter is degenerate because individuals are all captured. Just set all the p‚Äôs to 1 in the encounter matrix. The breeding assessment matrix remains unchanged. -->
-<!-- ### Our model $(\phi_B, \phi_{NB}, \psi_{BNB}, \psi_{NBB}, p_B, p_{NB}, \beta_B, \beta_{NB}, \pi)$ -->
-<!-- ```{r eval = FALSE} -->
-<!-- multievent <- nimbleCode({ -->
-<!--   # ------------------------------------------------- -->
-<!--   # Parameters: -->
-<!--   # phiB: survival probability state B -->
-<!--   # phiNB: survival probability state NB -->
-<!--   # psiBNB: transition probability from B to NB -->
-<!--   # psiNBB: transition probability from NB to B -->
-<!--   # pB: recapture probability B -->
-<!--   # pNB: recapture probability NB -->
-<!--   # piB prob. of being in initial state breeder -->
-<!--   # betaNB prob to ascertain the breeding status of an individual encountered as non-breeder -->
-<!--   # betaB prob to ascertain the breeding status of an individual encountered as breeder -->
-<!--   # ------------------------------------------------- -->
-<!--   # States (z): -->
-<!--   # 1 alive B -->
-<!--   # 2 alive NB -->
-<!--   # 3 dead -->
-<!--   # Observations (y): -->
-<!--   # 1 = non-detected -->
-<!--   # 2 = seen and ascertained as breeder -->
-<!--   # 3 = seen and ascertained as non-breeder -->
-<!--   # 4 = not ascertained -->
-<!--   # ------------------------------------------------- -->
-<!-- ... -->
-<!-- ``` -->
-<!-- ```{r eval = FALSE} -->
-<!-- multievent <- nimbleCode({ -->
-<!-- ... -->
-<!--   # Priors -->
-<!--   phiB ~ dunif(0, 1) -->
-<!--   phiNB ~ dunif(0, 1) -->
-<!--   psiBNB ~ dunif(0, 1) -->
-<!--   psiNBB ~ dunif(0, 1) -->
-<!--   pB ~ dunif(0, 1) -->
-<!--   pNB ~ dunif(0, 1) -->
-<!--   piB ~ dunif(0, 1) -->
-<!--   betaNB ~ dunif(0, 1) -->
-<!--   betaB ~ dunif(0, 1) -->
-<!-- ... -->
-<!-- ``` -->
-<!-- ] -->
-<!-- ```{r eval = FALSE} -->
-<!-- multievent <- nimbleCode({ -->
-<!-- ... -->
-<!--   # vector of initial stats probs -->
-<!--   delta[1] <- piB # prob. of being in initial state B -->
-<!--   delta[2] <- 1 - piB # prob. of being in initial state NB -->
-<!--   delta[3] <- 0 # prob. of being in initial state dead -->
-<!-- ... -->
-<!-- ``` -->
-<!-- ```{r eval = FALSE} -->
-<!-- multievent <- nimbleCode({ -->
-<!-- ... -->
-<!--   # probabilities of state z(t+1) given z(t) -->
-<!--   gamma[1,1] <- phiB * (1 - psiBNB) -->
-<!--   gamma[1,2] <- phiB * psiBNB -->
-<!--   gamma[1,3] <- 1 - phiB -->
-<!--   gamma[2,1] <- phiNB * psiNBB -->
-<!--   gamma[2,2] <- phiNB * (1 - psiNBB) -->
-<!--   gamma[2,3] <- 1 - phiNB -->
-<!--   gamma[3,1] <- 0 -->
-<!--   gamma[3,2] <- 0 -->
-<!--   gamma[3,3] <- 1 -->
-<!-- ... -->
-<!-- ``` -->
-<!-- ```{r eval = FALSE} -->
-<!-- multievent <- nimbleCode({ -->
-<!-- ... -->
-<!--   # probabilities of y(t) given z(t) -->
-<!--   omega[1,1] <- 1 - pB             # Pr(alive B t -> non-detected t) -->
-<!--   omega[1,2] <- pB * betaB         # Pr(alive B t -> detected B t) -->
-<!--   omega[1,3] <- 0                  # Pr(alive B t -> detected NB t) -->
-<!--   omega[1,4] <- pB * (1 - betaB)   # Pr(alive B t -> detected U t) -->
-<!--   omega[2,1] <- 1 - pNB            # Pr(alive NB t -> non-detected t) -->
-<!--   omega[2,2] <- 0                  # Pr(alive NB t -> detected B t) -->
-<!--   omega[2,3] <- pNB * betaNB       # Pr(alive NB t -> detected NB t) -->
-<!--   omega[2,4] <- pNB * (1 - betaNB) # Pr(alive NB t -> detected U t) -->
-<!--   omega[3,1] <- 1                  # Pr(dead t -> non-detected t) -->
-<!--   omega[3,2] <- 0                  # Pr(dead t -> detected N t) -->
-<!--   omega[3,3] <- 0                  # Pr(dead t -> detected NB t) -->
-<!--   omega[3,4] <- 0                  # Pr(dead t -> detected U t) -->
-<!-- ... -->
-<!-- ``` -->
-<!-- ```{r eval = FALSE} -->
-<!-- multievent <- nimbleCode({ -->
-<!-- ... -->
-<!--   # probabilities of y(first) given z(first) -->
-<!--   omega.init[1,1] <- 0          # Pr(alive B t = 1 -> non-detected t = 1) -->
-<!--   omega.init[1,2] <- betaB      # Pr(alive B t = 1 -> detected B t = 1) -->
-<!--   omega.init[1,3] <- 0          # Pr(alive B t = 1 -> detected NB t = 1) -->
-<!--   omega.init[1,4] <- 1 - betaB  # Pr(alive B t = 1 -> detected U t = 1) -->
-<!--   omega.init[2,1] <- 0          # Pr(alive NB t = 1 -> non-detected t = 1) -->
-<!--   omega.init[2,2] <- 0          # Pr(alive NB t = 1 -> detected B t = 1) -->
-<!--   omega.init[2,3] <- betaNB     # Pr(alive NB t = 1 -> detected NB t = 1) -->
-<!--   omega.init[2,4] <- 1 - betaNB # Pr(alive NB t = 1 -> detected U t = 1) -->
-<!--   omega.init[3,1] <- 1          # Pr(dead t = 1 -> non-detected t = 1) -->
-<!--   omega.init[3,2] <- 0          # Pr(dead t = 1 -> detected N t = 1) -->
-<!--   omega.init[3,3] <- 0          # Pr(dead t = 1 -> detected NB t = 1) -->
-<!--   omega.init[3,4] <- 0          # Pr(dead t = 1 -> detected U t = 1) -->
-<!-- ... -->
-<!-- ``` -->
-<!-- ```{r eval = FALSE} -->
-<!-- multievent <- nimbleCode({ -->
-<!-- ... -->
-<!--   # likelihood -->
-<!--   for (i in 1:N){ -->
-<!--     # latent state at first capture -->
-<!--     z[i,first[i]] ~ dcat(delta[1:3]) -->
-<!--     y[i,first[i]] ~ dcat(omega.init[z[i,first[i]],1:4]) -->
-<!--     for (t in (first[i]+1):K){ -->
-<!--       # z(t) given z(t-1) -->
-<!--       z[i,t] ~ dcat(gamma[z[i,t-1],1:3]) -->
-<!--       # y(t) given z(t) -->
-<!--       y[i,t] ~ dcat(omega[z[i,t],1:4]) -->
-<!--     } -->
-<!--   } -->
-<!-- }) -->
-<!-- ``` -->
-<!-- ### Results -->
-<!-- ```{r echo = FALSE} -->
-<!-- library(MCMCvis) -->
-<!-- load(here::here(""dat"",""titisuncertain.RData"")) -->
-<!-- MCMCsummary(mcmc.multievent, round = 2) -->
-<!-- ``` -->
-<!-- Breeders are difficult to assigned to the correct state. Non-breeders are relatively well classified as non-breeders. No cost of breeding, neither on survival, nor on future reproduction. -->
-<!-- ```{r, echo = FALSE} -->
-<!-- library(MCMCvis) -->
-<!-- load(here::here(""dat"",""titisuncertain.RData"")) -->
-<!-- MCMCplot(mcmc.multievent) -->
-<!-- ``` -->
-<!-- ## Animal epidemiology with uncertain disease states -->
-<!-- Let's have a look to another example. Very similar to the previous example. We consider a system of an emerging pathogen *Mycoplasma gallisepticum* Edward and Kanarek and its host the house finch, *Carpodacus mexicanus* M√ºller. -->
-<!-- ```{r} -->
-<!-- knitr::include_graphics(""images/infectedhousefinch.jpg"") -->
-<!-- ``` -->
-<!-- A house finch with a heavy infection (Jim Mondok). -->
-<!-- We consider a system of an emerging pathogen *Mycoplasma gallisepticum* Edward and Kanarek and its host the house finch, *Carpodacus mexicanus* M√ºller. [Faustino et al. (2004)](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/j.0021-8790.2004.00840.x) and [Conn & Cooch (2009)](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/j.1365-2664.2008.01597.x) studied impact of pathogen on host demographic rates. Problem is true disease state for some encountered individuals is ambiguous because seen at distance. In this context, how to study the dynamics of the disease? -->
-<!-- ### States and observations -->
-<!-- + 3 states -->
-<!--     + healthy (H) -->
-<!--     + ill (I) -->
-<!--     + dead (D) -->
-<!-- + 4 observations -->
-<!--     + not seen (0) -->
-<!--     + captured healthy (1) -->
-<!--     + captured ill (2) -->
-<!--     + health status unknown, i.e. seen at distance (3) -->
-<!-- ### How states generate observations. -->
-<!-- ```{r, echo = FALSE} -->
-<!-- ggplot() + -->
-<!--   geom_point(aes(1, 1), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1, 2), size = 2.5, alpha = .7) + -->
-<!--   geom_text(aes(1.5, 2, label = 'not seen (0)'), nudge_x = 1.2, size = 7) + -->
-<!--   geom_text(aes(1.5, 1.5, label = 'captured healthy (1)'), nudge_x = 1.5, size = 7) + -->
-<!--   geom_text(aes(1.5, 1, label = 'captured ill (2)'), nudge_x = 1.3, size = 7) + -->
-<!--   geom_text(aes(1.5, 0.5, label = 'status unknown (3)'), nudge_x = 1.5, size = 7) + -->
-<!--   geom_point(aes(2, 0.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(2, 1), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(2, 1.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(2, 2), size = 2.5, alpha = .7) + -->
-<!--   geom_text(aes(.5, 2, label = 'healthy'), nudge_x = 0, size = 7) + -->
-<!--   geom_text(aes(.5, 1.5, label = 'ill'), nudge_x = 0.2, size = 7) + -->
-<!--   geom_text(aes(.5, 1, label = 'dead'), nudge_x = 0.1, size = 7) + -->
-<!--   xlim(0, 4.5) + -->
-<!--   ylim(0.5, 3) + -->
-<!--   annotate('text', x = .5, y = 2.6, label = 'States', size = 10) + -->
-<!--   annotate('text', x = 2.7, y = 2.6, label = 'Observations', size = 10) + -->
-<!--   theme_void() -->
-<!-- ``` -->
-<!-- ```{r, echo = FALSE} -->
-<!-- ggplot() + -->
-<!--   geom_point(aes(1, 1), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1, 2), size = 2.5, alpha = .7) + -->
-<!--   geom_text(aes(1.5, 2, label = 'not seen (0)'), nudge_x = 1.2, size = 7) + -->
-<!--   geom_text(aes(1.5, 1.5, label = 'captured healthy (1)'), nudge_x = 1.5, size = 7) + -->
-<!--   geom_text(aes(1.5, 1, label = 'captured ill (2)'), nudge_x = 1.3, size = 7) + -->
-<!--   geom_text(aes(1.5, 0.5, label = 'status unknown (3)'), nudge_x = 1.5, size = 7) + -->
-<!--   geom_point(aes(2, 0.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(2, 1), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(2, 1.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(2, 2), size = 2.5, alpha = .7) + -->
-<!--   geom_text(aes(.5, 2, label = 'healthy'), nudge_x = 0, size = 7) + -->
-<!--   geom_text(aes(.5, 1.5, label = 'ill'), nudge_x = 0.2, size = 7) + -->
-<!--   geom_text(aes(.5, 1, label = 'dead'), nudge_x = 0.1, size = 7) + -->
-<!--   xlim(0, 4.5) + -->
-<!--   ylim(0.5, 3) + -->
-<!--   annotate('text', x = .5, y = 2.6, label = 'States', size = 10) + -->
-<!--   annotate('text', x = 2.7, y = 2.6, label = 'Observations', size = 10) + -->
-<!--   geom_segment(aes(x = 1, y = 1, xend = 2, yend = 2), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   theme_void() -->
-<!-- ``` -->
-<!-- ```{r, echo = FALSE} -->
-<!-- ggplot() + -->
-<!--   geom_point(aes(1, 1), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1, 2), size = 2.5, alpha = .7) + -->
-<!--   geom_text(aes(1.5, 2, label = 'not seen (0)'), nudge_x = 1.2, size = 7) + -->
-<!--   geom_text(aes(1.5, 1.5, label = 'captured healthy (1)'), nudge_x = 1.5, size = 7) + -->
-<!--   geom_text(aes(1.5, 1, label = 'captured ill (2)'), nudge_x = 1.3, size = 7) + -->
-<!--   geom_text(aes(1.5, 0.5, label = 'status unknown (3)'), nudge_x = 1.5, size = 7) + -->
-<!--   geom_point(aes(2, 0.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(2, 1), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(2, 1.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(2, 2), size = 2.5, alpha = .7) + -->
-<!--   geom_text(aes(.5, 2, label = 'healthy'), nudge_x = 0, size = 7) + -->
-<!--   geom_text(aes(.5, 1.5, label = 'ill'), nudge_x = 0.2, size = 7) + -->
-<!--   geom_text(aes(.5, 1, label = 'dead'), nudge_x = 0.1, size = 7) + -->
-<!--   xlim(0, 4.5) + -->
-<!--   ylim(0.5, 3) + -->
-<!--   annotate('text', x = .5, y = 2.6, label = 'States', size = 10) + -->
-<!--   annotate('text', x = 2.7, y = 2.6, label = 'Observations', size = 10) + -->
-<!--   geom_segment(aes(x = 1, y = 1.5, xend = 2, yend = 1), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   geom_segment(aes(x = 1, y = 1.5, xend = 2, yend = 2), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   geom_segment(aes(x = 1, y = 1.5, xend = 2, yend = .5), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   theme_void() -->
-<!-- ``` -->
-<!-- ```{r, echo = FALSE} -->
-<!-- ggplot() + -->
-<!--   geom_point(aes(1, 1), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1, 2), size = 2.5, alpha = .7) + -->
-<!--   geom_text(aes(1.5, 2, label = 'not seen (0)'), nudge_x = 1.2, size = 7) + -->
-<!--   geom_text(aes(1.5, 1.5, label = 'captured healthy (1)'), nudge_x = 1.5, size = 7) + -->
-<!--   geom_text(aes(1.5, 1, label = 'captured ill (2)'), nudge_x = 1.3, size = 7) + -->
-<!--   geom_text(aes(1.5, 0.5, label = 'status unknown (3)'), nudge_x = 1.5, size = 7) + -->
-<!--   geom_point(aes(2, 0.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(2, 1), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(2, 1.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(2, 2), size = 2.5, alpha = .7) + -->
-<!--   geom_text(aes(.5, 2, label = 'healthy'), nudge_x = 0, size = 7) + -->
-<!--   geom_text(aes(.5, 1.5, label = 'ill'), nudge_x = 0.2, size = 7) + -->
-<!--   geom_text(aes(.5, 1, label = 'dead'), nudge_x = 0.1, size = 7) + -->
-<!--   xlim(0, 4.5) + -->
-<!--   ylim(0.5, 3) + -->
-<!--   annotate('text', x = .5, y = 2.6, label = 'States', size = 10) + -->
-<!--   annotate('text', x = 2.7, y = 2.6, label = 'Observations', size = 10) + -->
-<!--   geom_segment(aes(x = 1, y = 2, xend = 2, yend = .5), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   geom_segment(aes(x = 1, y = 2, xend = 2, yend = 1.5), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   geom_segment(aes(x = 1, y = 2, xend = 2, yend = 2), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   theme_void() -->
-<!-- ``` -->
-<!-- ```{r, echo = FALSE} -->
-<!-- ggplot() + -->
-<!--   geom_point(aes(1, 1), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(1, 2), size = 2.5, alpha = .7) + -->
-<!--   geom_text(aes(1.5, 2, label = 'not seen (0)'), nudge_x = 1.2, size = 7) + -->
-<!--   geom_text(aes(1.5, 1.5, label = 'captured healthy (1)'), nudge_x = 1.5, size = 7) + -->
-<!--   geom_text(aes(1.5, 1, label = 'captured ill (2)'), nudge_x = 1.3, size = 7) + -->
-<!--   geom_text(aes(1.5, 0.5, label = 'status unknown (3)'), nudge_x = 1.5, size = 7) + -->
-<!--   geom_point(aes(2, 0.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(2, 1), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(2, 1.5), size = 2.5, alpha = .7) + -->
-<!--   geom_point(aes(2, 2), size = 2.5, alpha = .7) + -->
-<!--   geom_text(aes(.5, 2, label = 'healthy'), nudge_x = 0, size = 7) + -->
-<!--   geom_text(aes(.5, 1.5, label = 'ill'), nudge_x = 0.2, size = 7) + -->
-<!--   geom_text(aes(.5, 1, label = 'dead'), nudge_x = 0.1, size = 7) + -->
-<!--   xlim(0, 4.5) + -->
-<!--   ylim(0.5, 3) + -->
-<!--   annotate('text', x = .5, y = 2.6, label = 'States', size = 10) + -->
-<!--   annotate('text', x = 2.7, y = 2.6, label = 'Observations', size = 10) + -->
-<!--   geom_segment(aes(x = 1, y = 1, xend = 2, yend = 2), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   geom_segment(aes(x = 1, y = 1.5, xend = 2, yend = 1), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   geom_segment(aes(x = 1, y = 1.5, xend = 2, yend = 2), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   geom_segment(aes(x = 1, y = 1.5, xend = 2, yend = .5), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   geom_segment(aes(x = 1, y = 2, xend = 2, yend = .5), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   geom_segment(aes(x = 1, y = 2, xend = 2, yend = 1.5), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   geom_segment(aes(x = 1, y = 2, xend = 2, yend = 2), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + -->
-<!--   theme_void() -->
-<!-- ``` -->
-<!-- Vector of initial state probabilities -->
-<!-- $$ -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \mathbf{\delta} = -->
-<!--     \left ( \vphantom{ \begin{matrix} 12 \end{matrix} } \right . -->
-<!-- \end{matrix} -->
-<!-- \hspace{-1.2em} -->
-<!-- \begin{matrix} -->
-<!--     z_t=H & z_t=I & z_t=D \\ \hdashline -->
-<!-- \pi_H & 1 - \pi_{H} & 0\\ -->
-<!-- \end{matrix} -->
-<!-- \hspace{-0.2em} -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \left . \vphantom{ \begin{matrix} 12 \end{matrix} } \right ) -->
-<!--     \begin{matrix} -->
-<!--     \end{matrix} -->
-<!-- \end{matrix} -->
-<!-- $$ -->
-<!-- $\pi_H$ is the probability that a newly encountered individual is healthy. $\pi_{I} = 1 - \pi_H$ is the probability that a newly encountered individual is ill. -->
-<!-- ### HMM model for disease states with uncertainty -->
-<!-- Transition matrix -->
-<!-- $$ -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \mathbf{\Gamma} = -->
-<!--     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right . -->
-<!-- \end{matrix} -->
-<!-- \hspace{-1.2em} -->
-<!-- \begin{matrix} -->
-<!--     z_t=H & z_t=I & z_t=D \\ \hdashline -->
-<!-- \phi_H (1-\psi_{HI}) & \phi_H \psi_{HI} & 1 - \phi_H\\ -->
-<!-- \phi_{I} \psi_{IH} & \phi_{I} (1-\psi_{IH}) & 1 - \phi_{I}\\ -->
-<!-- 0 & 0 & 1 -->
-<!-- \end{matrix} -->
-<!-- \hspace{-0.2em} -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right ) -->
-<!--     \begin{matrix} -->
-<!--     z_{t-1}=H \\ z_{t-1}=I \\ z_{t-1}=D -->
-<!--     \end{matrix} -->
-<!-- \end{matrix} -->
-<!-- $$ -->
-<!-- $\phi_H$ is the survival probability of healthy individuals, $\phi_I$ that of ill individuals. $\psi_{HI}$ is the probability of getting sick, $\psi_{IH}$ that of recovering from the disease. -->
-<!-- Transition matrix, incurable disease -->
-<!-- $$ -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \mathbf{\Gamma} = -->
-<!--     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right . -->
-<!-- \end{matrix} -->
-<!-- \hspace{-1.2em} -->
-<!-- \begin{matrix} -->
-<!--     z_t=H & z_t=I & z_t=D \\ \hdashline -->
-<!-- \phi_H (1-\psi_{HI}) & \phi_H \psi_{HI} & 1 - \phi_H\\ -->
-<!-- 0 & \phi_{I}  & 1 - \phi_{I}\\ -->
-<!-- 0 & 0 & 1 -->
-<!-- \end{matrix} -->
-<!-- \hspace{-0.2em} -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right ) -->
-<!--     \begin{matrix} -->
-<!--     z_{t-1}=H \\ z_{t-1}=I \\ z_{t-1}=D -->
-<!--     \end{matrix} -->
-<!-- \end{matrix} -->
-<!-- $$ -->
-<!-- No possibility of recovering from the disease, that is $\psi_{IH} = 0$. Once you get sick, you remain sick $\psi_{II} = 1 - \psi_{IH} = 1$. For analysing the house finch data, we allow recovering from the disease, and we will use transition matrix from previous slide. -->
-<!-- Observation matrix -->
-<!-- $$ -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \mathbf{\Omega} = -->
-<!--     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right . -->
-<!-- \end{matrix} -->
-<!-- \hspace{-1.2em} -->
-<!-- \begin{matrix} -->
-<!--     y_t=0 & y_t=1 & y_t=2 & y_t=3\\ \hdashline -->
-<!-- 1-p_H & p_H \beta_H & 0 & p_H (1-\beta_H)\\ -->
-<!-- 1-p_I & 0 & p_{I} \beta_{I} & p_{I} (1-\beta_{I})\\ -->
-<!-- 1 & 0 & 0 & 0 -->
-<!-- \end{matrix} -->
-<!-- \hspace{-0.2em} -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right ) -->
-<!--     \begin{matrix} -->
-<!--     z_{t}=H \\ z_{t}=I \\ z_{t}=D -->
-<!--     \end{matrix} -->
-<!-- \end{matrix} -->
-<!-- $$ -->
-<!-- $\beta_H$ is the probability to assign a healthy individual to state H. $\beta_{I}$ is the probability to assign a sick individual to state I. $p_H$ is the detection probability of healthy individuals, $p_I$ that of sick individuals. -->
-<!-- ### Results -->
-<!-- ```{r echo = FALSE} -->
-<!-- library(MCMCvis) -->
-<!-- load(here::here(""dat"",""disease.RData"")) -->
-<!-- MCMCsummary(out, round = 2) -->
-<!-- ``` -->
-<!-- Healthy individuals are correctly assigned, while infected individuals are difficult to ascertain. Sounds like being infected has an effect on detection and survival. Run models without effects and compare with WAIC for formal testing. Infection rate is 22%, recovery rate is 46%. -->
-<!-- ```{r, echo = FALSE} -->
-<!-- library(MCMCvis) -->
-<!-- load(here::here(""dat"",""disease.RData"")) -->
-<!-- MCMCplot(out) -->
-<!-- ``` -->
-<!-- ## Individual heterogeneity with finite mixtures. -->
-<!-- Our last example is about individual heterogeneity and how to account for it with HMMs. Gray wolf is a social species with hierarchy in packs which may reflect in species demography. As an example, we'll work with gray wolves. -->
-<!-- ```{r} -->
-<!-- knitr::include_graphics(""images/wolfdominance.jpg"") -->
-<!-- ``` -->
-<!-- Gray wolf is a social species with hierarchy in packs which may reflect in demography. Shirley Pledger in a series of papers developed heterogeneity models in which individuals are assigned in two or more classes with class-specific survival/detection probabilities. [Cubaynes et al. (2010)](https://conbio.onlinelibrary.wiley.com/doi/abs/10.1111/j.1523-1739.2009.01431.x) used HMMs to account for heterogeneity in the detection process due to social status, see also [Pradel et al. (2009)](https://link.springer.com/chapter/10.1007%2F978-0-387-78151-8_36). Dominant individuals tend to use path more often than others, and these paths are where we look for scats. -->
-<!-- ### Individual heterogeneity -->
-<!-- + 3 states -->
-<!--     + alive in class 1 (A1) -->
-<!--     + alive in class 2 (A2) -->
-<!--     + dead (D) -->
-<!-- + 4 observations -->
-<!--     + not captured (0) -->
-<!--     + captured (1) -->
-<!-- ### HMM model for individual heterogeneity -->
-<!-- Vector of initial state probabilities -->
-<!-- $$ -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \mathbf{\delta} = -->
-<!--     \left ( \vphantom{ \begin{matrix} 12 \end{matrix} } \right . -->
-<!-- \end{matrix} -->
-<!-- \hspace{-1.2em} -->
-<!-- \begin{matrix} -->
-<!--     z_t=A1 & z_t=A2 & z_t=D \\ \hdashline -->
-<!-- \pi & 1 - \pi & 0\\ -->
-<!-- \end{matrix} -->
-<!-- \hspace{-0.2em} -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \left . \vphantom{ \begin{matrix} 12 \end{matrix} } \right ) -->
-<!--     \begin{matrix} -->
-<!--     \end{matrix} -->
-<!-- \end{matrix} -->
-<!-- $$ -->
-<!-- $\pi$ is the probability of being alive in class 1. $1 - \pi$ is the probability of being in class 2. -->
-<!-- ### HMM model for individual heterogeneity -->
-<!-- Transition matrix -->
-<!-- $$ -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \mathbf{\Gamma} = -->
-<!--     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right . -->
-<!-- \end{matrix} -->
-<!-- \hspace{-1.2em} -->
-<!-- \begin{matrix} -->
-<!--     z_t=A1 & z_t=A2 & z_t=D \\ \hdashline -->
-<!-- \phi  & 0 & 1 - \phi\\ -->
-<!-- 0 & \phi & 1 - \phi\\ -->
-<!-- 0 & 0 & 1 -->
-<!-- \end{matrix} -->
-<!-- \hspace{-0.2em} -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right ) -->
-<!--     \begin{matrix} -->
-<!--     z_{t-1}=A1 \\ z_{t-1}=A2 \\ z_{t-1}=D -->
-<!--     \end{matrix} -->
-<!-- \end{matrix} -->
-<!-- $$ -->
-<!-- $\phi$ is the survival probability, which could be made heterogeneous. -->
-<!-- Transition matrix, with change in heterogeneity class -->
-<!-- $$ -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \mathbf{\Gamma} = -->
-<!--     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right . -->
-<!-- \end{matrix} -->
-<!-- \hspace{-1.2em} -->
-<!-- \begin{matrix} -->
-<!--     z_t=A1 & z_t=A2 & z_t=D \\ \hdashline -->
-<!-- \phi (1-\psi_{12}) & \phi \psi_{12} & 1 - \phi\\ -->
-<!-- \phi \psi_{21} & \phi (1-\psi_{21}) & 1 - \phi\\ -->
-<!-- 0 & 0 & 1 -->
-<!-- \end{matrix} -->
-<!-- \hspace{-0.2em} -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right ) -->
-<!--     \begin{matrix} -->
-<!--     z_{t-1}=A1 \\ z_{t-1}=A2 \\ z_{t-1}=D -->
-<!--     \end{matrix} -->
-<!-- \end{matrix} -->
-<!-- $$ -->
-<!-- $\psi_{12}$ is the probability for an individual to change class of heterogeneity, from 1 to 2. $\psi_{21}$ is the probability for an individual to change class of heterogeneity, from 2 to 1. -->
-<!-- Observation matrix -->
-<!-- $$ -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \mathbf{\Omega} = -->
-<!--     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right . -->
-<!-- \end{matrix} -->
-<!-- \hspace{-1.2em} -->
-<!-- \begin{matrix} -->
-<!--     y_t=0 & y_t=1\\ \hdashline -->
-<!-- 1 - p_1 & p_1\\ -->
-<!-- 1 - p_2 & p_2\\ -->
-<!-- 1 & 0 -->
-<!-- \end{matrix} -->
-<!-- \hspace{-0.2em} -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right ) -->
-<!--     \begin{matrix} -->
-<!--     z_{t}=A1 \\ z_{t}=A2 \\ z_{t}=D -->
-<!--     \end{matrix} -->
-<!-- \end{matrix} -->
-<!-- $$ -->
-<!-- $p_1$ is detection for individuals in class 1, and $p_2$ that of individuals in class 2. -->
-<!-- ### Results -->
-<!-- ```{r echo = FALSE} -->
-<!-- library(MCMCvis) -->
-<!-- load(here::here(""dat"",""wolf_het.RData"")) -->
-<!-- MCMCsummary(mcmc.phipmix, round = 2) -->
-<!-- ``` -->
-<!-- We have lowly detectable individuals (class A1 with $p_1$) in proportion 62%. And highly (or so) detectable individuals (class A2 with $p_2$) in proportion 38%. Note that interpretation of classes is made a posteriori. Survival is 81%. -->
-<!-- ```{r, echo = FALSE} -->
-<!-- library(MCMCvis) -->
-<!-- load(here::here(""dat"",""wolf_het.RData"")) -->
-<!-- MCMCplot(mcmc.phipmix) -->
-<!-- ``` -->
-<!-- You may consider more classes, and select among models, see [Cubaynes et al. (2012)](https://oliviergimenez.github.io/pubs/Cubaynesetal2011MEE.pdf). You may also go for a non-parametric approach and let the data tell you how many classes you need. This is relatively easy to do in Nimble, see [Turek et al. (2021)](https://arxiv.org/abs/2007.10163). More about individual heterogeneity in [Gimenez et al. (2018)](https://oliviergimenez.github.io/pubs/GimenezCamGaillard2017Oikos.pdf). -->
-<!-- ## HMMs to analyse capture-recapture data -->
-<!-- With the same data, ask further questions, just consider different states. -->
-<!-- ### How to make our models remember? -->
-<!-- So far, the dynamics of the states are first-order Makovian. The site where you will be depends only on the site where you are, and not on the sites you were previously. How to relax this assumption, and go second-order Markovian? -->
-<!-- Memory models were initially proposed by [Hestbeck et al. (1991)](https://esajournals.onlinelibrary.wiley.com/doi/abs/10.2307/2937193) and [Brownie et al. (1993)](https://www.jstor.org/stable/2532259?origin=crossref&seq=1#metadata_info_tab_contents), then formulated as HMMs in [Rouan et al. (2009)](https://link.springer.com/article/10.1198/jabes.2009.06108). See also [Cole et al. (2014)](https://onlinelibrary.wiley.com/doi/10.1002/ece3.1037). -->
-<!-- ### Remember HMM model for dispersal between 2 sites -->
-<!-- Transition matrix -->
-<!-- $$ -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \mathbf{\Gamma} = -->
-<!--     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right . -->
-<!-- \end{matrix} -->
-<!-- \hspace{-1.2em} -->
-<!-- \begin{matrix} -->
-<!--     z_t=A & z_t=B & z_t=D \\ \hdashline -->
-<!-- \phi_A (1-\psi_{AB}) & \phi_A \psi_{AB} & 1 - \phi_A\\ -->
-<!-- \phi_B \psi_{BA} & \phi_B (1-\psi_{BA}) & 1 - \phi_B\\ -->
-<!-- 0 & 0 & 1 -->
-<!-- \end{matrix} -->
-<!-- \hspace{-0.2em} -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right ) -->
-<!--     \begin{matrix} -->
-<!--     z_{t-1}=A \\ z_{t-1}=B \\ z_{t-1}=D -->
-<!--     \end{matrix} -->
-<!-- \end{matrix} -->
-<!-- $$ -->
-<!-- Observation matrix -->
-<!-- $$ -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \mathbf{\Omega} = -->
-<!--     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right . -->
-<!-- \end{matrix} -->
-<!-- \hspace{-1.2em} -->
-<!-- \begin{matrix} -->
-<!--     y_t=0 & y_t=1 & y_t=2 \\ \hdashline -->
-<!-- 1 - p_A & p_A & 0\\ -->
-<!-- 1 - p_B & 0 & p_B\\ -->
-<!-- 1 & 0 & 0 -->
-<!-- \end{matrix} -->
-<!-- \hspace{-0.2em} -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right ) -->
-<!--     \begin{matrix} -->
-<!--     z_{t}=A \\ z_{t}=B \\ z_{t}=D -->
-<!--     \end{matrix} -->
-<!-- \end{matrix} -->
-<!-- $$ -->
-<!-- ### HMM formulation of the memory model -->
-<!-- To keep track of the sites previously visited, the trick is to consider states as being pairs of sites occupied -->
-<!-- + States -->
-<!--      + AA is for alive in site A at $t$ and alive in site A at $t-1$ -->
-<!--      + AB is for alive in site A at $t$ and alive in site B at $t-1$ -->
-<!--      + BA is for alive in site B at $t$ and alive in site A at $t-1$ -->
-<!--      + BB is for alive in site B at $t$ and alive in site B at $t-1$ -->
-<!--      + D is for dead -->
-<!-- + Observations -->
-<!--      + 0 not captured -->
-<!--      + 1 captured at site A -->
-<!--      + 2 captured at site B -->
-<!-- Vector of initial state probabilities -->
-<!-- $$ -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \mathbf{\delta} = -->
-<!--     \left ( \vphantom{ \begin{matrix} 12 \end{matrix} } \right . -->
-<!-- \end{matrix} -->
-<!-- \hspace{-1.2em} -->
-<!-- \begin{matrix} -->
-<!--     z_t=AA & z_t=AB & z_t=BA & z_t=BB &z_t=D \\ \hdashline -->
-<!-- \pi_{AA} & \pi_{AB} & \pi_{BA} & \pi_{BB} & 0\\ -->
-<!-- \end{matrix} -->
-<!-- \hspace{-0.2em} -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \left . \vphantom{ \begin{matrix} 12 \end{matrix} } \right ) -->
-<!--     \begin{matrix} -->
-<!--     \end{matrix} -->
-<!-- \end{matrix} -->
-<!-- $$ -->
-<!-- where $\pi_{BB} = 1 - (\pi_{AA} + \pi_{AB} + \pi_{BA})$, and $\pi_{ij}$ at site $j$ when first captured at $t$ and site $i$ at $t - 1$. -->
-<!-- Transition matrix -->
-<!-- $$ -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \mathbf{\Gamma} = -->
-<!--     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12\end{matrix} } \right . -->
-<!-- \end{matrix} -->
-<!-- \hspace{-1.2em} -->
-<!-- \begin{matrix} -->
-<!--     z_t=AA & z_t=AB & z_t=BA & z_t=BB & z_t=D \\ \hdashline -->
-<!-- \phi_{AAA} & \phi_{AAB} & 0 & 0 & 1 - \phi_{AAA} - \phi_{AAB}\\ -->
-<!-- 0 & 0 & \phi_{ABA} & \phi_{ABB} & 1 - \phi_{ABA} - \phi_{ABB}\\ -->
-<!-- \phi_{BAA} & \phi_{BAB} & 0 & 0 & 1 - \phi_{BAA} - \phi_{BAB}\\ -->
-<!-- 0 & 0 & \phi_{BBA} & \phi_{BBB} & 1 - \phi_{BBA} - \phi_{BBB}\\ -->
-<!-- 0 & 0 & 0 & 0 & 1 -->
-<!-- \end{matrix} -->
-<!-- \hspace{-0.2em} -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12\end{matrix} } \right ) -->
-<!--     \begin{matrix} -->
-<!--     z_t=AA \\ z_t=AB \\ z_t=BA \\ z_t=BB \\ z_t=D -->
-<!--     \end{matrix} -->
-<!-- \end{matrix} -->
-<!-- $$ -->
-<!-- $\phi_{ijk}$ is probability to be in site $k$ at time $t + 1$ for an individual -->
-<!-- present in site $j$ at $t$ and in site $i$ at $t - 1$ -->
-<!-- Transition matrix, alternate parameterization -->
-<!-- $$ -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \mathbf{\Gamma} = -->
-<!--     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12\end{matrix} } \right . -->
-<!-- \end{matrix} -->
-<!-- \hspace{-1.2em} -->
-<!-- \begin{matrix} -->
-<!--     z_t=AA & z_t=AB & z_t=BA & z_t=BB & z_t=D \\ \hdashline -->
-<!-- \phi \psi_{AAA} & \phi (1 - \psi_{AAA}) & 0 & 0 & 1 - \phi\\ -->
-<!-- 0 & 0 & \phi (1 - \psi_{ABB}) & \phi \psi_{ABB} & 1 - \phi\\ -->
-<!-- \phi \psi_{BAA} & \phi (1 - \psi_{BAA}) & 0 & 0 & 1 - \phi\\ -->
-<!-- 0 & 0 & \phi (1-\psi_{BBB}) & \phi \psi_{BBB} & 1 - \phi\\ -->
-<!-- 0 & 0 & 0 & 0 & 1 -->
-<!-- \end{matrix} -->
-<!-- \hspace{-0.2em} -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12\end{matrix} } \right ) -->
-<!--     \begin{matrix} -->
-<!--     z_t=AA \\ z_t=AB \\ z_t=BA \\ z_t=BB \\ z_t=D -->
-<!--     \end{matrix} -->
-<!-- \end{matrix} -->
-<!-- $$ -->
-<!-- $\phi$ is the probability of surviving from one occasion to the next. $\psi_{ijj}$ is the probability an animal stays at the same site $j$ given that it was at site $i$ on the previous occasion. -->
-<!-- Observation matrix -->
-<!-- $$ -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \mathbf{\Omega} = -->
-<!--     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12\end{matrix} } \right . -->
-<!-- \end{matrix} -->
-<!-- \hspace{-1.2em} -->
-<!-- \begin{matrix} -->
-<!--     y_t=0 & y_t=1 & y_t=2 \\ \hdashline -->
-<!-- 1 - p_A & p_A & 0\\ -->
-<!-- 1 - p_B & 0 & p_B\\ -->
-<!-- 1 - p_A & p_A & 0\\ -->
-<!-- 1 - p_B & 0 & p_B\\ -->
-<!-- 1 & 0 & 0 -->
-<!-- \end{matrix} -->
-<!-- \hspace{-0.2em} -->
-<!-- \begin{matrix} -->
-<!-- & \\ -->
-<!-- \left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12\end{matrix} } \right ) -->
-<!--     \begin{matrix} -->
-<!--     z_t=AA \\ z_t=AB \\ z_t=BA \\ z_t=BB \\ z_t=D -->
-<!--     \end{matrix} -->
-<!-- \end{matrix} -->
-<!-- $$ -->
-<!-- ## Summary -->
-<!-- + Blabla. -->
-<!-- + Blabla. -->
-<!-- ## Suggested reading -->
-<!-- + Seminal paper by Pradel (2005) [Multievent: An Extension of Multistate Capture‚ÄìRecapture Models to Uncertain States](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1541-0420.2005.00318.x). Biometrics, 61: 442-447. -->
-<!-- + Dupuis (1995) had a similar idea for the Arnason-Schwarz model: Dupuis, J. (1995) [Bayesian estimation of movement and survival probabilities from capture-recapture data](https://academic.oup.com/biomet/article-abstract/82/4/761/252161). Biometrika. Vol. 82, pp 761-772. -->
-<!-- + See also for a review Gimenez et al. (2012) [Estimating demographic parameters using hidden process dynamic models](https://oliviergimenez.github.io/pubs/Gimenezetal2012TPB.pdf). Theoretical Population Biology 82: 307-316. -->
-
-</div>
-
-
-
-  <div class=""chapter-nav"">
-<div class=""prev""><a href=""dispersal.html""><span class=""header-section-number"">5</span> Dispersal</a></div>
-<div class=""next""><a href=""introduction-6.html"">Introduction</a></div>
-</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
-    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
-      <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#uncertainty""><span class=""header-section-number"">6</span> State uncertainty</a></li></ul>
-
-      <div class=""book-extra"">
-        <ul class=""list-unstyled"">
-<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/uncertainty.Rmd"">View source <i class=""fab fa-github""></i></a></li>
-          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/uncertainty.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
-        </ul>
-</div>
-    </nav>
-</div>
-
-</div>
-</div> <!-- .container -->
-
-<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2023-08-11.</p>
-  </div>
-
-  <div class=""col-12 col-md-6 mt-3"">
-    <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
-  </div>
-
-</div></div>
-</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
-  (function () {
-    var script = document.createElement(""script"");
-    script.type = ""text/javascript"";
-    var src = ""true"";
-    if (src === """" || src === ""true"") src = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML"";
-    if (location.protocol !== ""file:"")
-      if (/^https?:/.test(src))
-        src = src.replace(/^https?:/, '');
-    script.src = src;
-    document.getElementsByTagName(""head"")[0].appendChild(script);
-  })();
-</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
-for (let popover of popovers) {
-  const div = document.createElement('div');
-  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
-  div.innerHTML = popover.getAttribute('data-content');
-
-  var has_math = div.querySelector(""span.math"");
-  if (has_math) {
-    document.body.appendChild(div);
-    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
-    MathJax.Hub.Queue(function() {
-      popover.setAttribute('data-content', div.innerHTML);
-      document.body.removeChild(div);
-    })
-  }
-}
-</script>
-</body>
-</html>

---FILE: survival.Rmd---
@@ -8,6 +8,22 @@ In this fourth chapter, you will learn about the Cormack-Jolly-Seber model that
 
 In chapter \@ref(hmmcapturerecapture), we introduced a capture-recapture model with constant survival and detection probabilities which we formulated as a HMM and fitted to data in NIMBLE. Historically, however, it was a slightly more complicated model that was first proposed -- the so-called Cormack-Jolly-Seber (CJS) model -- in which survival and recapture probabilities are time-varying. This feature of the CJS model is useful to account for variation due to environmental conditions in survival or to sampling effort in detection. Schematically the CJS model can be represented this way:
 
+```{r, engine = 'tikz', echo = FALSE}
+\usetikzlibrary{arrows, fit, positioning, automata}
+\begin{tikzpicture}[node distance = 2cm]
+\tikzset{state/.style = {circle, draw, minimum size = 30pt, scale = 3, line width=1pt}}
+\node [state,fill=lightgray!75] (6) [] {$1$};
+\node [state,fill=lightgray!75] (5) [left = 20mm of 6] {$1$};
+\node [state,fill=lightgray!75] (4) [left = 20mm of 5] {$1$};
+\node [state,fill=lightgray!75] (7) [right = 20mm of 6] {$2$};
+\node [state,fill=lightgray!75] (8) [right = 20mm of 7] {$2$};
+\draw[->,black, line width=0.25mm,-latex] (4) -- node[above=3mm, align=center] {\huge $\phi$} (5);
+\draw[->,black, line width=0.25mm,-latex] (5) -- node[above=3mm, align=center] {\huge $\phi$} (6);
+\draw[->,black, line width=0.25mm,-latex] (6) -- node[above=3mm, align=center] {\huge $1 - \phi$} (7);
+\draw[->,black, line width=0.25mm,-latex] (7) -- node[above=3mm, align=center] {\huge 1} (8);
+\end{tikzpicture}
+```
+
 ```{r, engine = 'tikz', echo = FALSE}
 \usetikzlibrary{arrows, fit, positioning, automata}
 \begin{tikzpicture}[node distance = 2cm]",False,True,Rendering / Conversion,6
oliviergimenez,banana-book,052adefcc9acebe59b16bc2168e271a364b62d99,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2022-03-17T10:42:31Z,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2022-03-17T10:42:31Z,Fixed typos in HMM chapter.,_bookdown_files/banana-book_files/figure-html/unnamed-chunk-110-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-111-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-131-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-132-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-173-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-174-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-26-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-27-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-5-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-6-1.pdf;docs/404.html;docs/about-the-author.html;docs/abundance.html;docs/covariates.html;docs/crashcourse.html;docs/dispersal.html;docs/faq.html;docs/hmmcapturerecapture.html;docs/hsmm.html;docs/index.html;docs/individual-dependence.html;docs/introduction-4.html;docs/introduction-7.html;docs/introduction-9.html;docs/introduction.html;docs/intronimble.html;docs/model-selection.html;docs/preface.html;docs/references.html;docs/search.json;docs/stopover.html;docs/survival.html;docs/take-home-messages.html;docs/tradeoffs.html;docs/uncertainty.html;hmm.Rmd,True,False,True,False,39,39,78,"---FILE: docs/404.html---
@@ -96,7 +96,7 @@ <h1>Page not found<a class=""anchor"" aria-label=""anchor"" href=""#page-not-found""><
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/about-the-author.html---
@@ -111,7 +111,7 @@ <h1>About the author<a class=""anchor"" aria-label=""anchor"" href=""#about-the-autho
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/abundance.html---
@@ -117,7 +117,7 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/covariates.html---
@@ -297,7 +297,7 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/crashcourse.html---
@@ -240,7 +240,7 @@ <h3>
 <div class=""sourceCode"" id=""cb7""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">sample_from_posterior</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Beta.html"">rbeta</a></span><span class=""op"">(</span><span class=""fl"">1000</span>, <span class=""fl"">20</span>, <span class=""fl"">39</span><span class=""op"">)</span> <span class=""co""># draw 1000 values from posterior survival beta(20,39)</span>
 <span class=""fu""><a href=""https://rdrr.io/r/base/mean.html"">mean</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span><span class=""op"">)</span> <span class=""co""># compute mean with Monte Carlo integration</span>
-<span class=""co"">## [1] 0.341</span></code></pre></div>
+<span class=""co"">## [1] 0.3372</span></code></pre></div>
 <p>You may check that the mean we have just calculated matches closely the expectation of a beta distribution<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;If &lt;span class=""math inline""&gt;\(X\)&lt;/span&gt; is a random variable with distribution &lt;span class=""math inline""&gt;\(\text{beta}(a, b)\)&lt;/span&gt;, then &lt;span class=""math inline""&gt;\(E(X) = \displaystyle{\frac{a}{a + b}}\)&lt;/span&gt;&lt;/p&gt;'><sup>10</sup></a>:</p>
 <div class=""sourceCode"" id=""cb8""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fl"">20</span><span class=""op"">/</span><span class=""op"">(</span><span class=""fl"">20</span><span class=""op"">+</span><span class=""fl"">39</span><span class=""op"">)</span> <span class=""co""># expectation of beta(20,39)</span>
@@ -249,7 +249,7 @@ <h3>
 <div class=""sourceCode"" id=""cb9""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/r/stats/quantile.html"">quantile</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span>, probs <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/c.html"">c</a></span><span class=""op"">(</span><span class=""fl"">2.5</span><span class=""op"">/</span><span class=""fl"">100</span>, <span class=""fl"">97.5</span><span class=""op"">/</span><span class=""fl"">100</span><span class=""op"">)</span><span class=""op"">)</span>
 <span class=""co"">##   2.5%  97.5% </span>
-<span class=""co"">## 0.2210 0.4705</span></code></pre></div>
+<span class=""co"">## 0.2309 0.4601</span></code></pre></div>
 </div>
 <div id=""markovmodelmcmc"" class=""section level3"" number=""1.5.2"">
 <h3>
@@ -562,7 +562,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/dispersal.html---
@@ -35138,7 +35138,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/faq.html---
@@ -109,7 +109,7 @@ <h1>FAQ<a class=""anchor"" aria-label=""anchor"" href=""#faq""><i class=""fas fa-link"">
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/hmmcapturerecapture.html---
@@ -1584,7 +1584,7 @@ <h2>
 <span class=""co"">## [4,]    1    1    1    1    2</span>
 <span class=""co"">## [5,]    1    1    1    1    1</span>
 <span class=""co"">## [6,]    1    1    2    2    2</span></code></pre></div>
-<p>We could <code><a href=""https://rdrr.io/pkg/nimble/man/Categorical.html"">dcat()</a></code> by <code>dbern()</code> everywhere in the code because we have binary events alive/dead. Would it make any difference? Although <code><a href=""https://rdrr.io/pkg/nimble/man/Categorical.html"">dcat()</a></code> uses less efficient samplers than <code>dbern()</code> (<strong>check w/ Perry/Daniel</strong>), <code><a href=""https://rdrr.io/pkg/nimble/man/Categorical.html"">dcat()</a></code> is convenient for model building to accomodate more than two outcomes, a feature that will become handy in the next chapters.</p>
+<p>We could replace <code><a href=""https://rdrr.io/pkg/nimble/man/Categorical.html"">dcat()</a></code> by <code>dbern()</code> everywhere in the code because we have binary events alive/dead. Would it make any difference? Although <code><a href=""https://rdrr.io/pkg/nimble/man/Categorical.html"">dcat()</a></code> uses less efficient samplers than <code>dbern()</code> (<strong>check w/ Perry/Daniel</strong>), <code><a href=""https://rdrr.io/pkg/nimble/man/Categorical.html"">dcat()</a></code> is convenient for model building to accomodate more than two outcomes, a feature that will become handy in the next chapters.</p>
 </div>
 <div id=""hidden-markov-models"" class=""section level2"" number=""3.6"">
 <h2>
@@ -5167,18 +5167,18 @@ <h3>
 \end{align*}\]</span></p>
 <p>Using the definition of a conditional probability, we have:</p>
 <p><span class=""math display"">\[\begin{align*}
-\Pr(\mathbf{y}_i) &amp;= \Pr(y_{i,1}, y_{i,2}, \ldots, y_{i,T})\\
+\Pr(\mathbf{y}_i, \mathbf{z}_i) &amp;= \Pr(y_{i,1}, y_{i,2}, \ldots, y_{i,T}, z_{i,1}, z_{i,2}, \ldots, z_{i,T})\\
                   &amp;= \color{blue}{\Pr(y_{i,1}, y_{i,2}, \ldots, y_{i,T} | z_{i,1}, z_{i,2}, \ldots, z_{i,T}) \Pr(z_{i,1}, z_{i,2}, \ldots, z_{i,T})}\\
 \end{align*}\]</span></p>
 <p>Then by using the independence of the <span class=""math inline"">\(y\)</span> conditional on the <span class=""math inline"">\(z\)</span>, and the likelihood of a Markov chain, we get that:</p>
 <p><span class=""math display"">\[\begin{align*}
-\Pr(\mathbf{y}_i) &amp;= \Pr(y_{i,1}, y_{i,2}, \ldots, y_{i,T})\\
+\Pr(\mathbf{y}_i, \mathbf{z}_i) &amp;= \Pr(y_{i,1}, y_{i,2}, \ldots, y_{i,T}, z_{i,1}, z_{i,2}, \ldots, z_{i,T})\\
                   &amp;= \Pr(y_{i,1}, y_{i,2}, \ldots, y_{i,T} | z_{i,1}, z_{i,2}, \ldots, z_{i,T}) \Pr(z_{i,1}, z_{i,2}, \ldots, z_{i,T})\\
                 &amp;= \color{blue}{\left(\prod_{t=1}^T{\Pr{(y_{i,t} | z_{i,t})}}\right) \left(\Pr(z_{i,1}) \prod_{t=2}^T{\Pr{(z_{i,t} | z_{i,t-1})}}\right)}\\
 \end{align*}\]</span></p>
 <p>Finally, by recognizing the observation and transition probabilities, we have that the complete likelihood for individual <span class=""math inline"">\(i\)</span> is:</p>
 <p><span class=""math display"">\[\begin{align*}
-\Pr(\mathbf{y}_i) &amp;= \Pr(y_{i,1}, y_{i,2}, \ldots, y_{i,T})\\
+\Pr(\mathbf{y}_i, \mathbf{z}_i) &amp;= \Pr(y_{i,1}, y_{i,2}, \ldots, y_{i,T}, z_{i,1}, z_{i,2}, \ldots, z_{i,T})\\
                   &amp;= \Pr(y_{i,1}, y_{i,2}, \ldots, y_{i,T} | z_{i,1}, z_{i,2}, \ldots, z_{i,T}) \Pr(z_{i,1}, z_{i,2}, \ldots, z_{i,T})\\
                 &amp;= \color{blue}{\left(\prod_{t=1}^T{\omega_{z_{i,t}, y_{i,t}}}\right) \left(\Pr(z_{i,1}) \prod_{t=2}^T{\gamma_{z_{i,t-1},z_{i,t}}}\right)}\\
 \end{align*}\]</span></p>
@@ -5325,7 +5325,7 @@ <h2>
                           nchains <span class=""op"">=</span> <span class=""va"">n.chains</span><span class=""op"">)</span>
 <span class=""va"">end_time</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/Sys.time.html"">Sys.time</a></span><span class=""op"">(</span><span class=""op"">)</span>
 <span class=""va"">end_time</span> <span class=""op"">-</span> <span class=""va"">start_time</span></code></pre></div>
-<pre><code>## Time difference of 28.84 secs</code></pre>
+<pre><code>## Time difference of 28.35 secs</code></pre>
 <p>We can have a look to numerical summaries:</p>
 <div class=""sourceCode"" id=""cb120""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/pkg/MCMCvis/man/MCMCsummary.html"">MCMCsummary</a></span><span class=""op"">(</span><span class=""va"">mcmc.output</span>, round <span class=""op"">=</span> <span class=""fl"">2</span><span class=""op"">)</span>
@@ -5609,7 +5609,7 @@ <h3>
 <span class=""co"">## |-------------------------------------------------------|</span>
 <span class=""va"">end_time</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/Sys.time.html"">Sys.time</a></span><span class=""op"">(</span><span class=""op"">)</span>
 <span class=""va"">end_time</span> <span class=""op"">-</span> <span class=""va"">start_time</span>
-<span class=""co"">## Time difference of 25.45 secs</span></code></pre></div>
+<span class=""co"">## Time difference of 26.15 secs</span></code></pre></div>
 <p>The numerical summaries are similar to those we obtained with the complete likelihood, and effective samples sizes are larger denoting better mixing:</p>
 <div class=""sourceCode"" id=""cb127""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/pkg/MCMCvis/man/MCMCsummary.html"">MCMCsummary</a></span><span class=""op"">(</span><span class=""va"">mcmc.output</span>, round <span class=""op"">=</span> <span class=""fl"">2</span><span class=""op"">)</span>
@@ -5747,7 +5747,7 @@ <h2>
 <span class=""co"">## |-------------------------------------------------------|</span>
 <span class=""va"">end_time</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/Sys.time.html"">Sys.time</a></span><span class=""op"">(</span><span class=""op"">)</span>
 <span class=""va"">end_time</span> <span class=""op"">-</span> <span class=""va"">start_time</span>
-<span class=""co"">## Time difference of 24.55 secs</span>
+<span class=""co"">## Time difference of 26.14 secs</span>
 <span class=""fu""><a href=""https://rdrr.io/pkg/MCMCvis/man/MCMCsummary.html"">MCMCsummary</a></span><span class=""op"">(</span><span class=""va"">mcmc.output</span>, round <span class=""op"">=</span> <span class=""fl"">2</span><span class=""op"">)</span>
 <span class=""co"">##     mean   sd 2.5%  50% 97.5% Rhat n.eff</span>
 <span class=""co"">## p   0.61 0.06 0.49 0.61  0.72    1  1453</span>
@@ -6085,7 +6085,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/hsmm.html---
@@ -108,7 +108,7 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/index.html---
@@ -86,7 +86,7 @@ <h1>Welcome<a class=""anchor"" aria-label=""anchor"" href=""#welcome""><i class=""fas f
 <p>This book offers a Bayesian treatment of HMMs applied to capture-recapture data. You will learn to use the R package NIMBLE which is seen by many as the future of Bayesian statistical ecology to deal with complex models and/or big data. An important part of the book consists in case studies presented in a tutorial style to abide by the ‚Äúlearning by doing‚Äù philosophy.</p>
 <p>I‚Äôm currently writing this book, and I welcome any feedback. You may raise an issue <a href=""https://github.com/oliviergimenez/banana-book/issues"">here</a>, amend directly the R Markdown file that generated the page you‚Äôre reading by clicking on the ‚ÄòEdit this page‚Äô icon in the right panel, or <a href=""mailto:olivier.gimenez@cefe.cnrs.fr"">email me</a>. Many thanks!</p>
 <p>Olivier Gimenez, Montpellier, France<br>
-Last updated: March 07, 2022</p>
+Last updated: March 17, 2022</p>
 <div id=""license"" class=""section level2 unnumbered"">
 <h2>License<a class=""anchor"" aria-label=""anchor"" href=""#license""><i class=""fas fa-link""></i></a>
 </h2>
@@ -120,7 +120,7 @@ <h2>License<a class=""anchor"" aria-label=""anchor"" href=""#license""><i class=""fas f
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/individual-dependence.html---
@@ -124,7 +124,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/introduction-4.html---
@@ -104,7 +104,7 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-4""><i
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/introduction-7.html---
@@ -104,7 +104,7 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-7""><i
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/introduction-9.html---
@@ -104,7 +104,7 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-9""><i
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/introduction.html---
@@ -104,7 +104,7 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction""><i cl
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/intronimble.html---
@@ -1250,7 +1250,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/model-selection.html---
@@ -169,7 +169,7 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/preface.html---
@@ -193,7 +193,7 @@ <h2>How this book was written<a class=""anchor"" aria-label=""anchor"" href=""#how-th
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/references.html---
@@ -223,7 +223,7 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/stopover.html---
@@ -106,7 +106,7 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/survival.html---
@@ -9244,7 +9244,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/take-home-messages.html---
@@ -177,7 +177,7 @@ <h1>Take-home messages<a class=""anchor"" aria-label=""anchor"" href=""#take-home-mes
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/tradeoffs.html---
@@ -149,7 +149,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/uncertainty.html---
@@ -959,7 +959,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-07.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-03-17.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: hmm.Rmd---
@@ -455,7 +455,7 @@ for (i in 1:nind){
 head(z) 
 ```
 
-We could `dcat()` by `dbern()` everywhere in the code because we have binary events alive/dead. Would it make any difference? Although `dcat()` uses less efficient samplers than `dbern()` (**check w/ Perry/Daniel**), `dcat()` is convenient for model building to accomodate more than two outcomes, a feature that will become handy in the next chapters. 
+We could replace `dcat()` by `dbern()` everywhere in the code because we have binary events alive/dead. Would it make any difference? Although `dcat()` uses less efficient samplers than `dbern()` (**check w/ Perry/Daniel**), `dcat()` is convenient for model building to accomodate more than two outcomes, a feature that will become handy in the next chapters. 
 
 ## Hidden Markov models
 
@@ -648,22 +648,22 @@ In the Bayesian framework, we usually work with the so-called complete likelihoo
 Using the definition of a conditional probability, we have:
 
 \begin{align*}
-\Pr(\mathbf{y}_i) &= \Pr(y_{i,1}, y_{i,2}, \ldots, y_{i,T})\\
+\Pr(\mathbf{y}_i, \mathbf{z}_i) &= \Pr(y_{i,1}, y_{i,2}, \ldots, y_{i,T}, z_{i,1}, z_{i,2}, \ldots, z_{i,T})\\
                   &= \color{blue}{\Pr(y_{i,1}, y_{i,2}, \ldots, y_{i,T} | z_{i,1}, z_{i,2}, \ldots, z_{i,T}) \Pr(z_{i,1}, z_{i,2}, \ldots, z_{i,T})}\\
 \end{align*}
 
 Then by using the independence of the $y$ conditional on the $z$, and the likelihood of a Markov chain, we get that:
 
 \begin{align*}
-\Pr(\mathbf{y}_i) &= \Pr(y_{i,1}, y_{i,2}, \ldots, y_{i,T})\\
+\Pr(\mathbf{y}_i, \mathbf{z}_i) &= \Pr(y_{i,1}, y_{i,2}, \ldots, y_{i,T}, z_{i,1}, z_{i,2}, \ldots, z_{i,T})\\
                   &= \Pr(y_{i,1}, y_{i,2}, \ldots, y_{i,T} | z_{i,1}, z_{i,2}, \ldots, z_{i,T}) \Pr(z_{i,1}, z_{i,2}, \ldots, z_{i,T})\\
                 &= \color{blue}{\left(\prod_{t=1}^T{\Pr{(y_{i,t} | z_{i,t})}}\right) \left(\Pr(z_{i,1}) \prod_{t=2}^T{\Pr{(z_{i,t} | z_{i,t-1})}}\right)}\\
 \end{align*}
 
 Finally, by recognizing the observation and transition probabilities, we have that the complete likelihood for individual $i$ is:
 
 \begin{align*}
-\Pr(\mathbf{y}_i) &= \Pr(y_{i,1}, y_{i,2}, \ldots, y_{i,T})\\
+\Pr(\mathbf{y}_i, \mathbf{z}_i) &= \Pr(y_{i,1}, y_{i,2}, \ldots, y_{i,T}, z_{i,1}, z_{i,2}, \ldots, z_{i,T})\\
                   &= \Pr(y_{i,1}, y_{i,2}, \ldots, y_{i,T} | z_{i,1}, z_{i,2}, \ldots, z_{i,T}) \Pr(z_{i,1}, z_{i,2}, \ldots, z_{i,T})\\
                 &= \color{blue}{\left(\prod_{t=1}^T{\omega_{z_{i,t}, y_{i,t}}}\right) \left(\Pr(z_{i,1}) \prod_{t=2}^T{\gamma_{z_{i,t-1},z_{i,t}}}\right)}\\
 \end{align*}",False,True,Implementation / Logic,6
oliviergimenez,banana-book,2d5008362c1cbec34b00d6795984ba7e544c32ca,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2022-02-12T10:14:44Z,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2022-02-12T10:14:44Z,Sort out nimbleEcology issue?,_bookdown_files/banana-book_files/figure-html/unnamed-chunk-107-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-108-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-123-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-124-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-125-1.pdf;_common.R;docs/404.html;docs/about-the-author.html;docs/abundance.html;docs/covariates.html;docs/crashcourse.html;docs/dispersal.html;docs/faq.html;docs/hmmcapturerecapture.html;docs/hsmm.html;docs/index.html;docs/individual-dependence.html;docs/introduction-4.html;docs/introduction-5.html;docs/introduction-6.html;docs/introduction.html;docs/intronimble.html;docs/model-selection.html;docs/preface.html;docs/references.html;docs/search.json;docs/stopover.html;docs/survival.html;docs/take-home-messages.html;docs/tradeoffs.html;docs/uncertainty.html,False,True,True,False,29,29,58,"---FILE: _common.R---
@@ -6,7 +6,7 @@ library(MCMCvis)
 library(magick)
 library(pdftools)
 library(wesanderson)
-library(nimbleEcology)
+#library(nimbleEcology)
 #library(basicMCMCplots)
 
 # R options

---FILE: docs/404.html---
@@ -96,7 +96,7 @@ <h1>Page not found<a class=""anchor"" aria-label=""anchor"" href=""#page-not-found""><
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/about-the-author.html---
@@ -111,7 +111,7 @@ <h1>About the author<a class=""anchor"" aria-label=""anchor"" href=""#about-the-autho
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/abundance.html---
@@ -127,7 +127,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/covariates.html---
@@ -105,7 +105,7 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/crashcourse.html---
@@ -240,7 +240,7 @@ <h3>
 <div class=""sourceCode"" id=""cb7""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">sample_from_posterior</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Beta.html"">rbeta</a></span><span class=""op"">(</span><span class=""fl"">1000</span>, <span class=""fl"">20</span>, <span class=""fl"">39</span><span class=""op"">)</span> <span class=""co""># draw 1000 values from posterior survival beta(20,39)</span>
 <span class=""fu""><a href=""https://rdrr.io/r/base/mean.html"">mean</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span><span class=""op"">)</span> <span class=""co""># compute mean with Monte Carlo integration</span>
-<span class=""co"">## [1] 0.3407</span></code></pre></div>
+<span class=""co"">## [1] 0.3374</span></code></pre></div>
 <p>You may check that the mean we have just calculated matches closely the expectation of a beta distribution<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;If &lt;span class=""math inline""&gt;\(X\)&lt;/span&gt; is a random variable with distribution &lt;span class=""math inline""&gt;\(\text{beta}(a, b)\)&lt;/span&gt;, then &lt;span class=""math inline""&gt;\(E(X) = \displaystyle{\frac{a}{a + b}}\)&lt;/span&gt;&lt;/p&gt;'><sup>10</sup></a>:</p>
 <div class=""sourceCode"" id=""cb8""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fl"">20</span><span class=""op"">/</span><span class=""op"">(</span><span class=""fl"">20</span><span class=""op"">+</span><span class=""fl"">39</span><span class=""op"">)</span> <span class=""co""># expectation of beta(20,39)</span>
@@ -249,7 +249,7 @@ <h3>
 <div class=""sourceCode"" id=""cb9""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/r/stats/quantile.html"">quantile</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span>, probs <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/c.html"">c</a></span><span class=""op"">(</span><span class=""fl"">2.5</span><span class=""op"">/</span><span class=""fl"">100</span>, <span class=""fl"">97.5</span><span class=""op"">/</span><span class=""fl"">100</span><span class=""op"">)</span><span class=""op"">)</span>
 <span class=""co"">##   2.5%  97.5% </span>
-<span class=""co"">## 0.2308 0.4598</span></code></pre></div>
+<span class=""co"">## 0.2253 0.4603</span></code></pre></div>
 </div>
 <div id=""markov-chains"" class=""section level3"" number=""1.5.2"">
 <h3>
@@ -562,7 +562,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/dispersal.html---
@@ -1123,7 +1123,7 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/faq.html---
@@ -109,7 +109,7 @@ <h1>FAQ<a class=""anchor"" aria-label=""anchor"" href=""#faq""><i class=""fas fa-link"">
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/hmmcapturerecapture.html---
@@ -5527,7 +5527,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/hsmm.html---
@@ -108,7 +108,7 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/index.html---
@@ -86,7 +86,7 @@ <h1>Welcome<a class=""anchor"" aria-label=""anchor"" href=""#welcome""><i class=""fas f
 <p>This book offers a Bayesian treatment of HMMs applied to capture-recapture data. You will learn to use the R package NIMBLE which is seen by many as the future of Bayesian statistical ecology to deal with complex models and/or big data. An important part of the book consists in case studies presented in a tutorial style to abide by the ‚Äúlearning by doing‚Äù philosophy.</p>
 <p>I‚Äôm currently writing this book, and I welcome any feedback. You may raise an issue <a href=""https://github.com/oliviergimenez/banana-book/issues"">here</a>, amend directly the R Markdown file that generated the page you‚Äôre reading by clicking on the ‚ÄòEdit this page‚Äô icon in the right panel, or <a href=""mailto:olivier.gimenez@cefe.cnrs.fr"">email me</a>. Many thanks!</p>
 <p>Olivier Gimenez, Montpellier, France<br>
-Last updated: February 11, 2022</p>
+Last updated: February 12, 2022</p>
 <div id=""license"" class=""section level2 unnumbered"">
 <h2>License<a class=""anchor"" aria-label=""anchor"" href=""#license""><i class=""fas fa-link""></i></a>
 </h2>
@@ -120,7 +120,7 @@ <h2>License<a class=""anchor"" aria-label=""anchor"" href=""#license""><i class=""fas f
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/individual-dependence.html---
@@ -124,7 +124,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/introduction-4.html---
@@ -104,7 +104,7 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-4""><i
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/introduction-5.html---
@@ -104,7 +104,7 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-5""><i
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/introduction-6.html---
@@ -104,7 +104,7 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-6""><i
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/introduction.html---
@@ -104,7 +104,7 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction""><i cl
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/intronimble.html---
@@ -1145,7 +1145,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/model-selection.html---
@@ -108,7 +108,7 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/preface.html---
@@ -193,7 +193,7 @@ <h2>How this book was written<a class=""anchor"" aria-label=""anchor"" href=""#how-th
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/references.html---
@@ -230,7 +230,7 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/stopover.html---
@@ -106,7 +106,7 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/survival.html---
@@ -992,7 +992,7 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/take-home-messages.html---
@@ -177,7 +177,7 @@ <h1>Take-home messages<a class=""anchor"" aria-label=""anchor"" href=""#take-home-mes
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/tradeoffs.html---
@@ -149,7 +149,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/uncertainty.html---
@@ -1131,7 +1131,7 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-11.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-02-12.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">",True,False,Implementation / Logic,6
oliviergimenez,banana-book,ac8d14d27bcdff067672d4045823dee805d77303,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2022-01-31T17:47:50Z,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2022-01-31T17:47:50Z,Issue w/ MCMC chapter.,bayesmcmc.Rmd,True,False,True,False,0,2,2,"---FILE: bayesmcmc.Rmd---
@@ -1,7 +1,5 @@
 # Bayesian statistics & MCMC {#crashcourse}
 
-**Add visual explanation of credible intervals, plus histogram and density plot for posterior distribution**
-
 ## Introduction
 
 In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to implement the Bayesian method for more complex analyses. This is not an exhaustive treatment of Bayesian statistics, but you should get what you need to navigate through the rest of the book. ",False,True,Rendering / Conversion,3
oliviergimenez,banana-book,99f39b17d61b26988c1c4802d819db6b4c627cd4,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2022-01-27T18:21:25Z,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2022-01-27T18:21:25Z,wo hmm chapter for now (issue w GH action and emo package),_bookdown_files/banana-book_cache/html/unnamed-chunk-117_6dd9006e0721756439e1e9ef3d7e9e03.RData;_bookdown_files/banana-book_cache/html/unnamed-chunk-117_6dd9006e0721756439e1e9ef3d7e9e03.rdb;_bookdown_files/banana-book_cache/html/unnamed-chunk-117_6dd9006e0721756439e1e9ef3d7e9e03.rdx;_bookdown_files/banana-book_cache/html/unnamed-chunk-98_4b46fafd620d4e60c9dec2394ed6ac35.RData;_bookdown_files/banana-book_cache/html/unnamed-chunk-98_4b46fafd620d4e60c9dec2394ed6ac35.rdb;_bookdown_files/banana-book_cache/html/unnamed-chunk-98_4b46fafd620d4e60c9dec2394ed6ac35.rdx;_bookdown_files/banana-book_cache/html/unnamed-chunk-99_f89d847bda038ab1b8cdfbb733d66c94.RData;_bookdown_files/banana-book_cache/html/unnamed-chunk-99_f89d847bda038ab1b8cdfbb733d66c94.rdb;_bookdown_files/banana-book_cache/html/unnamed-chunk-99_f89d847bda038ab1b8cdfbb733d66c94.rdx;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-104-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-104-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-105-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-105-1.png;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-106-1.pdf;_bookdown_files/banana-book_files/figure-html/unnamed-chunk-106-1.png;docs/404.html;docs/about-the-author.html;docs/abundance.html;docs/covariates.html;docs/crashcourse.html;docs/dispersal.html;docs/faq.html;docs/hmmcapturerecapture.html;docs/hsmm.html;docs/index.html;docs/individual-dependence.html;docs/introduction-3.html;docs/introduction-4.html;docs/introduction-5.html;docs/introduction.html;docs/intronimble.html;docs/model-selection.html;docs/preface.html;docs/reference-keys.txt;docs/references.html;docs/search.json;docs/stopover.html;docs/survival.html;docs/take-home-messages.html;docs/tradeoffs.html;docs/uncertainty.html;hmm.Rmd,True,False,True,False,2101,6757,8858,"---FILE: docs/404.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.11/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.3.1/transition.js""></script><script src=""libs/bs3compat-0.3.1/tabs.js""></script><script src=""libs/bs3compat-0.3.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 

---FILE: docs/about-the-author.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.11/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.3.1/transition.js""></script><script src=""libs/bs3compat-0.3.1/tabs.js""></script><script src=""libs/bs3compat-0.3.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 

---FILE: docs/abundance.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.11/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.3.1/transition.js""></script><script src=""libs/bs3compat-0.3.1/tabs.js""></script><script src=""libs/bs3compat-0.3.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 

---FILE: docs/covariates.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.11/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.3.1/transition.js""></script><script src=""libs/bs3compat-0.3.1/tabs.js""></script><script src=""libs/bs3compat-0.3.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 

---FILE: docs/crashcourse.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.11/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.3.1/transition.js""></script><script src=""libs/bs3compat-0.3.1/tabs.js""></script><script src=""libs/bs3compat-0.3.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 
@@ -240,7 +239,7 @@ <h3>
 <div class=""sourceCode"" id=""cb7""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">sample_from_posterior</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Beta.html"">rbeta</a></span><span class=""op"">(</span><span class=""fl"">1000</span>, <span class=""fl"">20</span>, <span class=""fl"">39</span><span class=""op"">)</span> <span class=""co""># draw 1000 values from posterior survival beta(20,39)</span>
 <span class=""fu""><a href=""https://rdrr.io/r/base/mean.html"">mean</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span><span class=""op"">)</span> <span class=""co""># compute mean with Monte Carlo integration</span>
-<span class=""co"">## [1] 0.3409</span></code></pre></div>
+<span class=""co"">## [1] 0.336</span></code></pre></div>
 <p>You may check that the mean we have just calculated matches closely the expectation of a beta distribution<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;If &lt;span class=""math inline""&gt;\(X\)&lt;/span&gt; is a random variable with distribution &lt;span class=""math inline""&gt;\(\text{beta}(a, b)\)&lt;/span&gt;, then &lt;span class=""math inline""&gt;\(E(X) = \displaystyle{\frac{a}{a + b}}\)&lt;/span&gt;&lt;/p&gt;'><sup>10</sup></a>:</p>
 <div class=""sourceCode"" id=""cb8""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fl"">20</span><span class=""op"">/</span><span class=""op"">(</span><span class=""fl"">20</span><span class=""op"">+</span><span class=""fl"">39</span><span class=""op"">)</span> <span class=""co""># expectation of beta(20,39)</span>
@@ -249,7 +248,7 @@ <h3>
 <div class=""sourceCode"" id=""cb9""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/r/stats/quantile.html"">quantile</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span>, probs <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/c.html"">c</a></span><span class=""op"">(</span><span class=""fl"">2.5</span><span class=""op"">/</span><span class=""fl"">100</span>, <span class=""fl"">97.5</span><span class=""op"">/</span><span class=""fl"">100</span><span class=""op"">)</span><span class=""op"">)</span>
 <span class=""co"">##   2.5%  97.5% </span>
-<span class=""co"">## 0.2202 0.4705</span></code></pre></div>
+<span class=""co"">## 0.2226 0.4575</span></code></pre></div>
 </div>
 <div id=""markov-chains"" class=""section level3"" number=""1.5.2"">
 <h3>

---FILE: docs/dispersal.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.11/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.3.1/transition.js""></script><script src=""libs/bs3compat-0.3.1/tabs.js""></script><script src=""libs/bs3compat-0.3.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 

---FILE: docs/faq.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.11/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.3.1/transition.js""></script><script src=""libs/bs3compat-0.3.1/tabs.js""></script><script src=""libs/bs3compat-0.3.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 

---FILE: docs/hsmm.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.11/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.3.1/transition.js""></script><script src=""libs/bs3compat-0.3.1/tabs.js""></script><script src=""libs/bs3compat-0.3.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 

---FILE: docs/index.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.11/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.3.1/transition.js""></script><script src=""libs/bs3compat-0.3.1/tabs.js""></script><script src=""libs/bs3compat-0.3.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 

---FILE: docs/individual-dependence.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.11/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.3.1/transition.js""></script><script src=""libs/bs3compat-0.3.1/tabs.js""></script><script src=""libs/bs3compat-0.3.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 

---FILE: docs/introduction-3.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.11/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.3.1/transition.js""></script><script src=""libs/bs3compat-0.3.1/tabs.js""></script><script src=""libs/bs3compat-0.3.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 

---FILE: docs/introduction-4.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.11/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.3.1/transition.js""></script><script src=""libs/bs3compat-0.3.1/tabs.js""></script><script src=""libs/bs3compat-0.3.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 

---FILE: docs/introduction-5.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.11/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.3.1/transition.js""></script><script src=""libs/bs3compat-0.3.1/tabs.js""></script><script src=""libs/bs3compat-0.3.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 

---FILE: docs/introduction.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.11/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.3.1/transition.js""></script><script src=""libs/bs3compat-0.3.1/tabs.js""></script><script src=""libs/bs3compat-0.3.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 

---FILE: docs/intronimble.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.11/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.3.1/transition.js""></script><script src=""libs/bs3compat-0.3.1/tabs.js""></script><script src=""libs/bs3compat-0.3.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 

---FILE: docs/model-selection.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.11/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.3.1/transition.js""></script><script src=""libs/bs3compat-0.3.1/tabs.js""></script><script src=""libs/bs3compat-0.3.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 

---FILE: docs/preface.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.11/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.3.1/transition.js""></script><script src=""libs/bs3compat-0.3.1/tabs.js""></script><script src=""libs/bs3compat-0.3.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 

---FILE: docs/reference-keys.txt---
@@ -48,53 +48,6 @@ running-nimble-a-little-bit-longer
 summary-1
 suggested-reading-1
 hmmcapturerecapture
-back-to-our-survival-example
-longitudinal-data
-a-model-for-longitudinal-survival-data
-markov-process
-transition-matrix
-initial-states
-likelihood
-example
-our-model
-our-model-1
-nimble-implementation
-nimble-code
-note
-nimble-awesomness
-converting-to-nimble-from-jags-openbugs-or-winbugs
-constants-and-data
-initial-values
-parameters-to-monitor
-mcmc-details
-run-nimble
-posterior-distribution-of-survival
-unfortunately-this-is-the-data-we-wish-we-had.
-in-real-life
-the-truth-is-in-z
-dead-animals-go-undetected
-alive-animals-may-be-detected-or-not
-observation-matrix
-markov-model
-hidden-markov-model
-hidden-markov-model-for-survival
-hmm-likelihood
-example-1
-example-2
-estimating-the-latent-states-z-or-not
-our-model-2
-nimble-implementation-1
-priors
-hmm-ingredients
-likelihood-1
-constants
-data
-initial-values-1
-parameters-to-monitor-1
-mcmc-details-1
-run-nimble-1
-posterior-distribution-of-survival-1
-further-reading
 survival
 covariates
 dispersal

---FILE: docs/references.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.11/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.3.1/transition.js""></script><script src=""libs/bs3compat-0.3.1/tabs.js""></script><script src=""libs/bs3compat-0.3.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 
@@ -121,9 +120,6 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 <div id=""ref-guerin_advances_2017"" class=""csl-entry"">
 Gu√©rin, S., D. Picard, R. Choquet, and A. Besnard. 2017. <span>‚ÄúAdvances in Methods for Estimating Stopover Duration for Migratory Species Using Capture-Recapture Data.‚Äù</span> <em>Ecological Applications: A Publication of the Ecological Society of America</em> 27 (5): 1594‚Äì604.
 </div>
-<div id=""ref-heller_novel_2021"" class=""csl-entry"">
-Heller, Philip, and Pratyusha Pogaru. 2021. <span>‚ÄúA Novel Approach to Teaching <span>Hidden</span> <span>Markov</span> <span>Models</span> to a Diverse Undergraduate Population.‚Äù</span> <em>Heliyon</em> 7 (3).
-</div>
 <div id=""ref-karamanlidis_evidence_2015"" class=""csl-entry"">
 Karamanlidis, Alexandros A., Miguel de Gabriel Hernando, Lambros Krambokoukis, and Olivier Gimenez. 2015. <span>‚ÄúEvidence of a Large Carnivore Population Recovery: <span>Counting</span> Bears in <span>Greece</span>.‚Äù</span> <em>Journal for Nature Conservation</em> 27: 10‚Äì17.
 </div>

---FILE: docs/stopover.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.11/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.3.1/transition.js""></script><script src=""libs/bs3compat-0.3.1/tabs.js""></script><script src=""libs/bs3compat-0.3.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 

---FILE: docs/survival.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.11/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.3.1/transition.js""></script><script src=""libs/bs3compat-0.3.1/tabs.js""></script><script src=""libs/bs3compat-0.3.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 

---FILE: docs/take-home-messages.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.11/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.3.1/transition.js""></script><script src=""libs/bs3compat-0.3.1/tabs.js""></script><script src=""libs/bs3compat-0.3.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 

---FILE: docs/tradeoffs.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.11/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.3.1/transition.js""></script><script src=""libs/bs3compat-0.3.1/tabs.js""></script><script src=""libs/bs3compat-0.3.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 

---FILE: docs/uncertainty.html---
@@ -18,8 +18,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.11/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.3.1/transition.js""></script><script src=""libs/bs3compat-0.3.1/tabs.js""></script><script src=""libs/bs3compat-0.3.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""libs/kePrint-0.0.1/kePrint.js""></script><link href=""libs/lightable-0.0.1/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 

---FILE: hmm.Rmd---
@@ -1,1211 +1,1210 @@
 # Hidden Markov models {#hmmcapturerecapture}
 
-## Back to our survival example
+<!-- ## Back to our survival example -->
 
-+ We have $z$ survivors out of $n$ released animals with winter survival probability $\phi$
+<!-- + We have $z$ survivors out of $n$ released animals with winter survival probability $\phi$ -->
 
-+ Let's get back to our survival example.
+<!-- + Let's get back to our survival example. -->
 
-+ Our model so far:
+<!-- + Our model so far: -->
 
-\begin{align*}
-   z &\sim \text{Binomial}(n, \phi) &\text{[likelihood]}
-   \\
-  \phi &\sim \text{Beta}(1, 1) &\text{[prior for }\phi \text{]} \\
-\end{align*}
+<!-- \begin{align*} -->
+<!--    z &\sim \text{Binomial}(n, \phi) &\text{[likelihood]} -->
+<!--    \\ -->
+<!--   \phi &\sim \text{Beta}(1, 1) &\text{[prior for }\phi \text{]} \\ -->
+<!-- \end{align*} -->
+
+<!-- + Our model so far has been a combination -->
+<!-- + Of a binomial likelihood -->
+<!-- + And a Beta prior with param 1 and 1, which is a uniform between 0 and 1. -->
+
+<!-- + This is also: -->
+
+<!-- \begin{align*} -->
+<!--    z_i &\sim \text{Bernoulli}(\phi), \; i = 1, \ldots, N &\text{[likelihood]} -->
+<!--    \\ -->
+<!--   \phi &\sim \text{Beta}(1, 1) &\text{[prior for }\phi \text{]} \\ -->
+<!-- \end{align*} -->
+
+<!-- + The binomial is just a sum of Bernoulli outcomes -->
+<!-- + Like flipping a coin for each individual and get a survivor with prob phi. -->
+
+<!-- + What if we had several winters? Say $T = 5$ winters. -->
+
+<!-- + In this design, we have a single winter. -->
+<!-- But for many species, we'll need to collect data on the long term to get a representative estimate of survival. -->
+<!-- + Therefore what if we had say big T five winters? -->
+
+<!-- ## Longitudinal data -->
+
+<!-- + $z_{i,t} = 1$ if individual $i$ alive at winter $t$, and $z_{i,t} = 2$ if dead. -->
+
+<!-- ```{r echo = FALSE} -->
+<!-- library(tidyverse) -->
+<!-- nind <- 57 -->
+<!-- nocc <- 5 -->
+<!-- first <- rep(1, nind) # single cohort -->
+<!-- z <- matrix(NA, nrow = nind, ncol = nocc) -->
+<!-- phi <- 0.8 -->
+<!-- for (i in 1:nind){ -->
+<!--   z[i,first[i]] <- 1 -->
+<!--   for (t in (first[i]+1):nocc){ -->
+<!--     z[i,t] <- rbinom(1, 1, phi * z[i,t-1]) # once you're dead z = 0, you remain dead -->
+<!--   } -->
+<!-- } -->
+<!-- z[z==0] <- 2 # 2 = dead, 1 = alive -->
+<!-- colnames(z) <- paste0(""winter "", 1:nocc) -->
+<!-- z %>% -->
+<!--   as_tibble() %>% -->
+<!--   add_column(id = 1:nind, .before = ""winter 1"") %>% -->
+<!--   kableExtra::kable() %>% -->
+<!--   kableExtra::scroll_box(width = ""100%"", height = ""400px"") -->
+<!-- #  kableExtra::kable_styling(font_size = 8, -->
+<!-- #                            latex_options = ""scale_down"") -->
+<!-- ``` -->
+
+<!-- + This is what we call longitudinal data. -->
+<!-- + Each row is an individual i, and columns are for winters t, or sampling occasions. -->
+<!-- + z is indexed by both i and t, and takes value 1 if ind i is alive in winter t, and 2 otherwise. -->
+
+<!-- ## A model for longitudinal survival data -->
 
-+ Our model so far has been a combination
-+ Of a binomial likelihood
-+ And a Beta prior with param 1 and 1, which is a uniform between 0 and 1.
+<!-- + A model relies on assumptions. -->
 
-+ This is also:
+<!-- + Let's think of a model for these data. -->
+<!-- + The objective remains the same, estimating survival. -->
+<!-- + To build this model, we'll make assumptions. -->
 
-\begin{align*}
-   z_i &\sim \text{Bernoulli}(\phi), \; i = 1, \ldots, N &\text{[likelihood]}
-   \\
-  \phi &\sim \text{Beta}(1, 1) &\text{[prior for }\phi \text{]} \\
-\end{align*}
+<!-- + The state of an animal at a given winter, alive or dead, is only dependent on its state the winter before. -->
 
-+ The binomial is just a sum of Bernoulli outcomes
-+ Like flipping a coin for each individual and get a survivor with prob phi.
-
-+ What if we had several winters? Say $T = 5$ winters.
-
-+ In this design, we have a single winter.
-But for many species, we'll need to collect data on the long term to get a representative estimate of survival.
-+ Therefore what if we had say big T five winters?
-
-## Longitudinal data
-
-+ $z_{i,t} = 1$ if individual $i$ alive at winter $t$, and $z_{i,t} = 2$ if dead.
-
-```{r echo = FALSE}
-library(tidyverse)
-nind <- 57
-nocc <- 5
-first <- rep(1, nind) # single cohort
-z <- matrix(NA, nrow = nind, ncol = nocc)
-phi <- 0.8
-for (i in 1:nind){
-  z[i,first[i]] <- 1
-  for (t in (first[i]+1):nocc){
-    z[i,t] <- rbinom(1, 1, phi * z[i,t-1]) # once you're dead z = 0, you remain dead
-  }
-}
-z[z==0] <- 2 # 2 = dead, 1 = alive
-colnames(z) <- paste0(""winter "", 1:nocc)
-z %>%
-  as_tibble() %>%
-  add_column(id = 1:nind, .before = ""winter 1"") %>%
-  kableExtra::kable() %>%
-  kableExtra::scroll_box(width = ""100%"", height = ""400px"")
-#  kableExtra::kable_styling(font_size = 8,
-#                            latex_options = ""scale_down"")
-```
+<!-- + First, we assume that the state of an animal in a given winter, alive or dead, is only dependent on its state the winter before. -->
 
-+ This is what we call longitudinal data.
-+ Each row is an individual i, and columns are for winters t, or sampling occasions.
-+ z is indexed by both i and t, and takes value 1 if ind i is alive in winter t, and 2 otherwise.
+<!-- + The future depends only on the present, not the past: Markov process. -->
 
-## A model for longitudinal survival data
+<!-- + In others words, he future depends only on the present, not the past -->
+<!-- + This is a Markov process. -->
 
-+ A model relies on assumptions.
+<!-- + If an animal is alive in a given winter, the probability it survives to the next winter is $\phi$. -->
 
-+ Let's think of a model for these data.
-+ The objective remains the same, estimating survival.
-+ To build this model, we'll make assumptions.
+<!-- + If an animal is alive in a given winter, the probability it survives to the next winter is $\phi$. -->
 
-+ The state of an animal at a given winter, alive or dead, is only dependent on its state the winter before.
+<!-- + The probability it dies is $1 - \phi$. -->
 
-+ First, we assume that the state of an animal in a given winter, alive or dead, is only dependent on its state the winter before.
+<!-- + The probability it dies is $1 - \phi$. -->
 
-+ The future depends only on the present, not the past: Markov process.
+<!-- + If an animal is dead a winter, it remains dead, unless you believe in zombies. -->
 
-+ In others words, he future depends only on the present, not the past
-+ This is a Markov process.
+<!-- + If an animal is dead a winter, it remains dead, unless you believe in zombies. -->
 
-+ If an animal is alive in a given winter, the probability it survives to the next winter is $\phi$.
+<!-- ## Markov process -->
 
-+ If an animal is alive in a given winter, the probability it survives to the next winter is $\phi$.
+<!-- ```{r, engine = 'tikz', echo = FALSE} -->
+<!-- \usetikzlibrary{arrows, fit, positioning, automata} -->
+<!-- \begin{tikzpicture}[node distance = 2cm] -->
+<!-- \tikzset{state/.style = {circle, draw, minimum size = 30pt, scale = 3, line width=1pt}} -->
+<!-- \node [state,fill=lightgray!75] (6) [] {$z_{t}$}; -->
+<!-- \node [state,fill=lightgray!75] (5) [left = 20mm of 6] {$z_{t-1}$}; -->
+<!-- \node [state,fill=lightgray!75] (4) [left = 20mm of 5] {$z_{t-2}$}; -->
+<!-- \node [state,fill=lightgray!75] (3) [left = 20mm of 4] {$\cdots$}; -->
+<!-- \node [state,fill=lightgray!75] (7) [right = 20mm of 6] {$z_{t+1}$}; -->
+<!-- \node [state,fill=lightgray!75] (8) [right = 20mm of 7] {$z_{t+2}$}; -->
+<!-- \node [state,fill=lightgray!75] (9) [right = 20mm of 8] {$\cdots$}; -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (3) to (4); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (4) to (5); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (5) to (6); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (6) to (7); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (7) to (8); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (8) to (9); -->
+<!-- \end{tikzpicture} -->
+<!-- ``` -->
 
-+ The probability it dies is $1 - \phi$.
+<!-- + A markov process can be represented this way. -->
+<!-- + The state at t+1 only depends on the state at t. -->
 
-+ The probability it dies is $1 - \phi$.
-
-+ If an animal is dead a winter, it remains dead, unless you believe in zombies.
-
-+ If an animal is dead a winter, it remains dead, unless you believe in zombies.
-
-## Markov process
-
-```{r, engine = 'tikz', echo = FALSE}
-\usetikzlibrary{arrows, fit, positioning, automata}
-\begin{tikzpicture}[node distance = 2cm]
-\tikzset{state/.style = {circle, draw, minimum size = 30pt, scale = 3, line width=1pt}}
-\node [state,fill=lightgray!75] (6) [] {$z_{t}$};
-\node [state,fill=lightgray!75] (5) [left = 20mm of 6] {$z_{t-1}$};
-\node [state,fill=lightgray!75] (4) [left = 20mm of 5] {$z_{t-2}$};
-\node [state,fill=lightgray!75] (3) [left = 20mm of 4] {$\cdots$};
-\node [state,fill=lightgray!75] (7) [right = 20mm of 6] {$z_{t+1}$};
-\node [state,fill=lightgray!75] (8) [right = 20mm of 7] {$z_{t+2}$};
-\node [state,fill=lightgray!75] (9) [right = 20mm of 8] {$\cdots$};
-\draw[->,black, line width=0.25mm,-latex] (3) to (4);
-\draw[->,black, line width=0.25mm,-latex] (4) to (5);
-\draw[->,black, line width=0.25mm,-latex] (5) to (6);
-\draw[->,black, line width=0.25mm,-latex] (6) to (7);
-\draw[->,black, line width=0.25mm,-latex] (7) to (8);
-\draw[->,black, line width=0.25mm,-latex] (8) to (9);
-\end{tikzpicture}
-```
-
-+ A markov process can be represented this way.
-+ The state at t+1 only depends on the state at t.
-
-```{r, engine = 'tikz', echo = FALSE}
-\usetikzlibrary{arrows, fit, positioning, automata}
-\begin{tikzpicture}[node distance = 2cm]
-\tikzset{state/.style = {circle, draw, minimum size = 30pt, scale = 3, line width=1pt}}
-\node [state,fill=lightgray!75] (6) [] {$1$};
-\node [state,fill=lightgray!75] (5) [left = 20mm of 6] {$1$};
-\node [state,fill=lightgray!75] (4) [left = 20mm of 5] {$1$};
-\node [state,fill=lightgray!75] (3) [left = 20mm of 4] {$1$};
-\node [state,fill=lightgray!75] (7) [right = 20mm of 6] {$2$};
-\node [state,fill=lightgray!75] (8) [right = 20mm of 7] {$2$};
-\node [state,fill=lightgray!75] (9) [right = 20mm of 8] {$\cdots$};
-\draw[->,black, line width=0.25mm,-latex] (3) -- node[above=3mm, align=center] {\huge $\varphi$} (4);
-\draw[->,black, line width=0.25mm,-latex] (4) -- node[above=3mm, align=center] {\huge $\varphi$} (5);
-\draw[->,black, line width=0.25mm,-latex] (5) -- node[above=3mm, align=center] {\huge $\varphi$} (6);
-\draw[->,black, line width=0.25mm,-latex] (6) -- node[above=3mm, align=center] {\huge $1 - \varphi$} (7);
-\draw[->,black, line width=0.25mm,-latex] (7) -- node[above=3mm, align=center] {\huge 1} (8);
-\draw[->,black, line width=0.25mm,-latex] (8) -- node[above=3mm, align=center] {\huge 1} (9);
-\end{tikzpicture}
-```
-
-+ In our model, going from a winter to the next is driven by survival and mortality processes.
-+ The probability of going from alive or 1 to alive or 1 is phi.
-+ Then from alive 1 to dead 2 is 1 - phi.
-+ And the probability to remain dead is 1, that is to go from state 2 dead to state 2 for dead.
-
-## Transition matrix
-
-+ The core of the Markov process is made of the transition probabilities.
-
-+ The engine of a Markov model is the transition matrix.
-+ This matrix or table gathers the probabilities of transition between states from one occasion to the next.
-
-+ For example, the probability of transitioning from state alive at $t-1$ to state alive at $t$ is $\Pr(z_t = 1 | z_{t-1} = 1) = \gamma_{1,1}$. It is the survival probability $\phi$.
+<!-- ```{r, engine = 'tikz', echo = FALSE} -->
+<!-- \usetikzlibrary{arrows, fit, positioning, automata} -->
+<!-- \begin{tikzpicture}[node distance = 2cm] -->
+<!-- \tikzset{state/.style = {circle, draw, minimum size = 30pt, scale = 3, line width=1pt}} -->
+<!-- \node [state,fill=lightgray!75] (6) [] {$1$}; -->
+<!-- \node [state,fill=lightgray!75] (5) [left = 20mm of 6] {$1$}; -->
+<!-- \node [state,fill=lightgray!75] (4) [left = 20mm of 5] {$1$}; -->
+<!-- \node [state,fill=lightgray!75] (3) [left = 20mm of 4] {$1$}; -->
+<!-- \node [state,fill=lightgray!75] (7) [right = 20mm of 6] {$2$}; -->
+<!-- \node [state,fill=lightgray!75] (8) [right = 20mm of 7] {$2$}; -->
+<!-- \node [state,fill=lightgray!75] (9) [right = 20mm of 8] {$\cdots$}; -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (3) -- node[above=3mm, align=center] {\huge $\varphi$} (4); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (4) -- node[above=3mm, align=center] {\huge $\varphi$} (5); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (5) -- node[above=3mm, align=center] {\huge $\varphi$} (6); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (6) -- node[above=3mm, align=center] {\huge $1 - \varphi$} (7); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (7) -- node[above=3mm, align=center] {\huge 1} (8); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (8) -- node[above=3mm, align=center] {\huge 1} (9); -->
+<!-- \end{tikzpicture} -->
+<!-- ``` -->
+
+<!-- + In our model, going from a winter to the next is driven by survival and mortality processes. -->
+<!-- + The probability of going from alive or 1 to alive or 1 is phi. -->
+<!-- + Then from alive 1 to dead 2 is 1 - phi. -->
+<!-- + And the probability to remain dead is 1, that is to go from state 2 dead to state 2 for dead. -->
 
-+ For example, the probability of transitioning from state alive at $t-1$ to state alive at $t$ is $\Pr(z_t = 1 | z_{t-1} = 1) = \gamma_{1,1}$. It is the survival probability $\phi$.
+<!-- ## Transition matrix -->
 
-+ The probability of dying over the interval $(t-1, t)$ is $\Pr(z_t = 2 | z_{t-1} = 1) = \gamma_{1,2} = 1 - \phi$.
+<!-- + The core of the Markov process is made of the transition probabilities. -->
 
-+ The probability of dying over the interval $(t-1, t)$ is $\Pr(z_t = 2 | z_{t-1} = 1) = \gamma_{1,2} = 1 - \phi$.
+<!-- + The engine of a Markov model is the transition matrix. -->
+<!-- + This matrix or table gathers the probabilities of transition between states from one occasion to the next. -->
 
-+ Now if an animal is dead at $t-1$, then $\Pr(z_t = 1 | z_{t-1} = 2) = 0$ and $\Pr(z_t = 2 | z_{t-1} = 2) = 1$.
+<!-- + For example, the probability of transitioning from state alive at $t-1$ to state alive at $t$ is $\Pr(z_t = 1 | z_{t-1} = 1) = \gamma_{1,1}$. It is the survival probability $\phi$. -->
 
-+ Now if an animal is dead at $t-1$, then $\Pr(z_t = 1 | z_{t-1} = 2) = 0$ and $\Pr(z_t = 2 | z_{t-1} = 2) = 1$.
+<!-- + For example, the probability of transitioning from state alive at $t-1$ to state alive at $t$ is $\Pr(z_t = 1 | z_{t-1} = 1) = \gamma_{1,1}$. It is the survival probability $\phi$. -->
 
+<!-- + The probability of dying over the interval $(t-1, t)$ is $\Pr(z_t = 2 | z_{t-1} = 1) = \gamma_{1,2} = 1 - \phi$. -->
 
-+ These probabilities can be packed in a transition matrix $\mathbf{\Gamma}$:
+<!-- + The probability of dying over the interval $(t-1, t)$ is $\Pr(z_t = 2 | z_{t-1} = 1) = \gamma_{1,2} = 1 - \phi$. -->
 
-\begin{align*}
-\mathbf{\Gamma} =
-\left(\begin{array}{cc}
-\gamma_{1,1} & \gamma_{1,2}\\
-\gamma_{2,1} & \gamma_{2,2}
-\end{array}\right) =
-\left(\begin{array}{cc}
-\phi & 1 - \phi\\
-0 & 1
-\end{array}\right)
-\end{align*}
-
-+ These probabilities can be packed in a transition matrix $\mathbf{\Gamma}$:
-
-Transition matrix:
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Gamma} =
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    z_t=A & z_t=D \\ \hdashline
-\phi & 1-\phi \\
-0 & 1
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    z_{t-1}=A \\ z_{t-1}=D
-    \end{matrix}
-\end{matrix}
-$$
-+ Take some time to navigate through this matrix.
-+ From in rows, the origin, to in columns, the destination.
-+ For example...
-
-## Initial states
-
-+ A Markov process has to start somewhere.
-
-+ We need the probabilities of initial states, i.e. states at $t = 1$.
-
-+ In other words, we need the probabilities of initial states
-+ i.e. states at $t = 1$.
-
-+ We will use $\mathbf{\delta} = \left(\Pr(z_1 = 1), \Pr(z_1 = 2)\right)$.
-
-+ We will denote delta this vector.
-+ It gathers the probability of being in each initial states.
-+ Here alive 1 and dead 2.
-
-+ Here we assume that all animals are alive at first winter, i.e. $\Pr(z_1 = 1) = 1$ and $\Pr(z_1 = 2) = 0$.
-
-+ All individuals are marked and release in first winter.
-+ Therefore alive when first captured.
-+ Which means that they are all in state 1 alive for sure.
-
-## Likelihood
-
-\begin{align*}
-\Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)} \\
-\end{align*}
-
-+ OK now that we've defined a Markov model, we need its likelihood to apply the Bayes theorem.
-+ The likelihood is the probability of the data, given the model. Here the data are the z.
-
-\begin{align*}
-\Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\
-                &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-\end{align*}
-
-+ We're gonna work backward, starting from the last sampling occasion.
-+ Now the likelihood can be written as the product of the probability of zT ie you're alive or not on the last occasion given your past history, that is the states at previous occasions, times the prob of your past history, y definition of cond prob.
-
-\begin{align*}
-\Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\
-                &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-\end{align*}
-
-+ Then because we have a Markov model, we're memory less, that is prob of next state, here zT, depends only on the current state, that is zT-1, and not the previous states.
-
-\begin{align*}
-\Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\
-                &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}, \ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)\\
-\end{align*}
-
-+ You can apply the same reasoning to T-1.
-+ First conditional prob.
-
-\begin{align*}
-\Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\
-                &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}, \ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)\\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \Pr(z_{T-2}, \ldots, z_1)\\
-\end{align*}
-
-+ Then markovian property.
-
-\begin{align*}
-\Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\
-                &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}, \ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)\\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \Pr(z_{T-2}, \ldots, z_1)\\
-                &= \ldots \\
-\end{align*}
-
-+ And so on.
-
-\begin{align*}
-\Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\
-                &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}, \ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)\\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \Pr(z_{T-2}, \ldots, z_1)\\
-                &= \ldots \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \ldots \Pr(z_{2} | z_{1}) \Pr(z_{1})\\
-\end{align*}
-
-+ You end up with this expression for the likelihood.
-
-
-\begin{align*}
-\Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\
-                &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}, \ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)\\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \Pr(z_{T-2}, \ldots, z_1)\\
-                &= \ldots \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \ldots \Pr(z_{2} | z_{1}) \Pr(z_{1})\\
-                &= \Pr(z_{1}) \prod_{t=2}^T{\Pr(z_{t} | z_{t-1})}\\
-\end{align*}
+<!-- + Now if an animal is dead at $t-1$, then $\Pr(z_t = 1 | z_{t-1} = 2) = 0$ and $\Pr(z_t = 2 | z_{t-1} = 2) = 1$. -->
 
-+ A product of cond probabilities. And the prob of initial states Pr(z1).
-
-\begin{align*}
-\Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\
-                &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}, \ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)\\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \Pr(z_{T-2}, \ldots, z_1)\\
-                &= \ldots \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \ldots \Pr(z_{2} | z_{1}) \Pr(z_{1})\\
-                &= \Pr(z_{1}) \prod_{t=2}^T{\Pr(z_{t} | z_{t-1})}\\
-                &= \Pr(z_{1}) \prod_{t=2}^T{\gamma_{z_{t-1},z_{t}}}\\
-\end{align*}
-
-+ We recognize the gammas we defined earlier.
-+ The transition probabilities.
-
-
-<!-- --- -->
-<!-- # Matrix formulation of the likelihood -->
+<!-- + Now if an animal is dead at $t-1$, then $\Pr(z_t = 1 | z_{t-1} = 2) = 0$ and $\Pr(z_t = 2 | z_{t-1} = 2) = 1$. -->
+
+
+<!-- + These probabilities can be packed in a transition matrix $\mathbf{\Gamma}$: -->
+
+<!-- \begin{align*} -->
+<!-- \mathbf{\Gamma} = -->
+<!-- \left(\begin{array}{cc} -->
+<!-- \gamma_{1,1} & \gamma_{1,2}\\ -->
+<!-- \gamma_{2,1} & \gamma_{2,2} -->
+<!-- \end{array}\right) = -->
+<!-- \left(\begin{array}{cc} -->
+<!-- \phi & 1 - \phi\\ -->
+<!-- 0 & 1 -->
+<!-- \end{array}\right) -->
+<!-- \end{align*} -->
+
+<!-- + These probabilities can be packed in a transition matrix $\mathbf{\Gamma}$: -->
+
+<!-- Transition matrix: -->
+
+<!-- $$ -->
+<!-- \begin{matrix} -->
+<!-- & \\ -->
+<!-- \mathbf{\Gamma} = -->
+<!--     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right . -->
+<!-- \end{matrix} -->
+<!-- \hspace{-1.2em} -->
+<!-- \begin{matrix} -->
+<!--     z_t=A & z_t=D \\ \hdashline -->
+<!-- \phi & 1-\phi \\ -->
+<!-- 0 & 1 -->
+<!-- \end{matrix} -->
+<!-- \hspace{-0.2em} -->
+<!-- \begin{matrix} -->
+<!-- & \\ -->
+<!-- \left . \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right ) -->
+<!--     \begin{matrix} -->
+<!--     z_{t-1}=A \\ z_{t-1}=D -->
+<!--     \end{matrix} -->
+<!-- \end{matrix} -->
+<!-- $$ -->
+<!-- + Take some time to navigate through this matrix. -->
+<!-- + From in rows, the origin, to in columns, the destination. -->
+<!-- + For example... -->
+
+<!-- ## Initial states -->
+
+<!-- + A Markov process has to start somewhere. -->
+
+<!-- + We need the probabilities of initial states, i.e. states at $t = 1$. -->
+
+<!-- + In other words, we need the probabilities of initial states -->
+<!-- + i.e. states at $t = 1$. -->
+
+<!-- + We will use $\mathbf{\delta} = \left(\Pr(z_1 = 1), \Pr(z_1 = 2)\right)$. -->
+
+<!-- + We will denote delta this vector. -->
+<!-- + It gathers the probability of being in each initial states. -->
+<!-- + Here alive 1 and dead 2. -->
+
+<!-- + Here we assume that all animals are alive at first winter, i.e. $\Pr(z_1 = 1) = 1$ and $\Pr(z_1 = 2) = 0$. -->
+
+<!-- + All individuals are marked and release in first winter. -->
+<!-- + Therefore alive when first captured. -->
+<!-- + Which means that they are all in state 1 alive for sure. -->
+
+<!-- ## Likelihood -->
+
+<!-- \begin{align*} -->
+<!-- \Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)} \\ -->
+<!-- \end{align*} -->
+
+<!-- + OK now that we've defined a Markov model, we need its likelihood to apply the Bayes theorem. -->
+<!-- + The likelihood is the probability of the data, given the model. Here the data are the z. -->
 
 <!-- \begin{align*} -->
 <!-- \Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\ -->
+<!--                 &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\ -->
+<!-- \end{align*} -->
+
+<!-- + We're gonna work backward, starting from the last sampling occasion. -->
+<!-- + Now the likelihood can be written as the product of the probability of zT ie you're alive or not on the last occasion given your past history, that is the states at previous occasions, times the prob of your past history, y definition of cond prob. -->
+
+<!-- \begin{align*} -->
+<!-- \Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\ -->
+<!--                 &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\ -->
+<!--                 &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\ -->
+<!-- \end{align*} -->
+
+<!-- + Then because we have a Markov model, we're memory less, that is prob of next state, here zT, depends only on the current state, that is zT-1, and not the previous states. -->
+
+<!-- \begin{align*} -->
+<!-- \Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\ -->
+<!--                 &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\ -->
+<!--                 &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\ -->
+<!--                 &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}, \ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)\\ -->
+<!-- \end{align*} -->
+
+<!-- + You can apply the same reasoning to T-1. -->
+<!-- + First conditional prob. -->
+
+<!-- \begin{align*} -->
+<!-- \Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\ -->
+<!--                 &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\ -->
+<!--                 &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\ -->
+<!--                 &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}, \ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)\\ -->
+<!--                 &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \Pr(z_{T-2}, \ldots, z_1)\\ -->
+<!-- \end{align*} -->
+
+<!-- + Then markovian property. -->
+
+<!-- \begin{align*} -->
+<!-- \Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\ -->
+<!--                 &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\ -->
+<!--                 &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\ -->
+<!--                 &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}, \ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)\\ -->
+<!--                 &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \Pr(z_{T-2}, \ldots, z_1)\\ -->
+<!--                 &= \ldots \\ -->
+<!-- \end{align*} -->
+
+<!-- + And so on. -->
+
+<!-- \begin{align*} -->
+<!-- \Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\ -->
+<!--                 &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\ -->
+<!--                 &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\ -->
+<!--                 &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}, \ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)\\ -->
+<!--                 &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \Pr(z_{T-2}, \ldots, z_1)\\ -->
+<!--                 &= \ldots \\ -->
+<!--                 &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \ldots \Pr(z_{2} | z_{1}) \Pr(z_{1})\\ -->
+<!-- \end{align*} -->
+
+<!-- + You end up with this expression for the likelihood. -->
+
+
+<!-- \begin{align*} -->
+<!-- \Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\ -->
+<!--                 &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\ -->
+<!--                 &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\ -->
+<!--                 &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}, \ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)\\ -->
+<!--                 &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \Pr(z_{T-2}, \ldots, z_1)\\ -->
+<!--                 &= \ldots \\ -->
+<!--                 &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \ldots \Pr(z_{2} | z_{1}) \Pr(z_{1})\\ -->
+<!--                 &= \Pr(z_{1}) \prod_{t=2}^T{\Pr(z_{t} | z_{t-1})}\\ -->
+<!-- \end{align*} -->
+
+<!-- + A product of cond probabilities. And the prob of initial states Pr(z1). -->
+
+<!-- \begin{align*} -->
+<!-- \Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\ -->
+<!--                 &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\ -->
+<!--                 &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\ -->
+<!--                 &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}, \ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)\\ -->
+<!--                 &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \Pr(z_{T-2}, \ldots, z_1)\\ -->
+<!--                 &= \ldots \\ -->
+<!--                 &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \ldots \Pr(z_{2} | z_{1}) \Pr(z_{1})\\ -->
+<!--                 &= \Pr(z_{1}) \prod_{t=2}^T{\Pr(z_{t} | z_{t-1})}\\ -->
 <!--                 &= \Pr(z_{1}) \prod_{t=2}^T{\gamma_{z_{t-1},z_{t}}}\\ -->
-<!--                 &= \mathbf{\delta} \; \mathbf{\Gamma} \cdots \mathbf{\Gamma} -->
 <!-- \end{align*} -->
 
+<!-- + We recognize the gammas we defined earlier. -->
+<!-- + The transition probabilities. -->
 
-## Example
 
-+ Let's assume an animal is alive, alive then dies.
+<!-- <!-- --- --> -->
+<!-- <!-- # Matrix formulation of the likelihood --> -->
 
-+ I realise these calculations are a bit difficult to follow.
-+ Let's take an example.
+<!-- <!-- \begin{align*} --> -->
+<!-- <!-- \Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\ --> -->
+<!-- <!--                 &= \Pr(z_{1}) \prod_{t=2}^T{\gamma_{z_{t-1},z_{t}}}\\ --> -->
+<!-- <!--                 &= \mathbf{\delta} \; \mathbf{\Gamma} \cdots \mathbf{\Gamma} --> -->
+<!-- <!-- \end{align*} --> -->
 
-+ We have $\mathbf{z} = (1, 1, 2)$. What is the contribution of this animal to the likelihood?
 
-+ We have $\mathbf{z} = (1, 1, 2)$. What is the contribution of this animal to the likelihood?
-+ Let's apply the formula we have just derived.
+<!-- ## Example -->
 
-\begin{align*}
-\Pr(\mathbf{z} = (1, 1, 2)) &= \Pr(z_1 = 1) \; \gamma_{z_{1} = 1, z_{2} = 1} \; \gamma_{z_{2} = 1, z_{3} = 2}\\
-                            &= 1 \; \phi \; (1 - \phi).
-\end{align*}
+<!-- + Let's assume an animal is alive, alive then dies. -->
 
-+ The prob of having the sequence alive, alive and dead is
-+ The prob of being alive first, the to stay alive, then to die.
-+ The prob of being alive at first occasion being 1, we have that the contribution of this individual to the likelihood is phi times 1 - phi.
+<!-- + I realise these calculations are a bit difficult to follow. -->
+<!-- + Let's take an example. -->
 
-+ Remember:
+<!-- + We have $\mathbf{z} = (1, 1, 2)$. What is the contribution of this animal to the likelihood? -->
 
-\begin{align*}
-\mathbf{\Gamma} =
-\left(\begin{array}{cc}
-\gamma_{1,1} & \gamma_{1,2}\\
-\gamma_{2,1} & \gamma_{2,2}
-\end{array}\right) =
-\left(\begin{array}{cc}
-\phi & 1 - \phi\\
-0 & 1
-\end{array}\right)
-\end{align*}
+<!-- + We have $\mathbf{z} = (1, 1, 2)$. What is the contribution of this animal to the likelihood? -->
+<!-- + Let's apply the formula we have just derived. -->
 
-## Our model
+<!-- \begin{align*} -->
+<!-- \Pr(\mathbf{z} = (1, 1, 2)) &= \Pr(z_1 = 1) \; \gamma_{z_{1} = 1, z_{2} = 1} \; \gamma_{z_{2} = 1, z_{3} = 2}\\ -->
+<!--                             &= 1 \; \phi \; (1 - \phi). -->
+<!-- \end{align*} -->
 
-\begin{align*}
-   z_1 &\sim \text{Multinomial}(1, \delta) &\text{[likelihood, }t = 1 \text{]}\\
-   \color{white}{z_t | z_{t-1}} & \color{white}{\sim} \color{white}{\text{Multinomial}(1, \gamma_{z_{t-1},z_{t}})} & \color{white}{\text{[likelihood, }t > 1 \text{]}}\\
-  \color{white}{\phi} & \color{white}{\sim} \color{white}{\text{Beta}(1, 1)} & \color{white}{\text{[prior for }\phi \text{]}} \\
-\end{align*}
+<!-- + The prob of having the sequence alive, alive and dead is -->
+<!-- + The prob of being alive first, the to stay alive, then to die. -->
+<!-- + The prob of being alive at first occasion being 1, we have that the contribution of this individual to the likelihood is phi times 1 - phi. -->
 
-+ OK let's wrap it up.
-+ Our model so far is that one.
+<!-- + Remember: -->
 
-+ Initial state is multinomial with one trial, and probability delta.
-+ That is you have a dice with two faces, a coin, and you have some prob to be alive, and 1 - that prob to be dead. + Of course, it you want your Markov chain to start, you'd better say it's alive so that delta is just (1,0).
+<!-- \begin{align*} -->
+<!-- \mathbf{\Gamma} = -->
+<!-- \left(\begin{array}{cc} -->
+<!-- \gamma_{1,1} & \gamma_{1,2}\\ -->
+<!-- \gamma_{2,1} & \gamma_{2,2} -->
+<!-- \end{array}\right) = -->
+<!-- \left(\begin{array}{cc} -->
+<!-- \phi & 1 - \phi\\ -->
+<!-- 0 & 1 -->
+<!-- \end{array}\right) -->
+<!-- \end{align*} -->
 
-## Our model
+<!-- ## Our model -->
 
-\begin{align*}
-   z_1 &\sim \text{Multinomial}(1, \delta) &\text{[likelihood, }t = 1 \text{]}\\
-   \color{white}{z_t | z_{t-1}} & \color{white}{\sim} \color{white}{\text{Multinomial}(1, \gamma_{z_{t-1},z_{t}})} & \color{white}{\text{[likelihood, }t > 1 \text{]}}\\
-  \phi &\sim \text{Beta}(1, 1) &\text{[prior for }\phi \text{]} \\
-\end{align*}
+<!-- \begin{align*} -->
+<!--    z_1 &\sim \text{Multinomial}(1, \delta) &\text{[likelihood, }t = 1 \text{]}\\ -->
+<!--    \color{white}{z_t | z_{t-1}} & \color{white}{\sim} \color{white}{\text{Multinomial}(1, \gamma_{z_{t-1},z_{t}})} & \color{white}{\text{[likelihood, }t > 1 \text{]}}\\ -->
+<!--   \color{white}{\phi} & \color{white}{\sim} \color{white}{\text{Beta}(1, 1)} & \color{white}{\text{[prior for }\phi \text{]}} \\ -->
+<!-- \end{align*} -->
 
-+ We also need a prior on survival.
-+ As usual we take a uniform distribution between 0 and 1, or a beta with parameters 1 and 1.
-
-\begin{align*}
-   z_1 &\sim \text{Multinomial}(1, \delta) &\text{[likelihood, }t = 1 \text{]}\\
-   z_t | z_{t-1} &\sim \text{Multinomial}(1, \gamma_{z_{t-1},z_{t}}) &\text{[likelihood, }t > 1 \text{]}\\
-  \phi &\sim \text{Beta}(1, 1) &\text{[prior for }\phi \text{]} \\
-\end{align*}
-
-
-+ Now the main part is the dynamic of the states.
-+ Our state at t depends only on your state at t-1, and it is a multinomial random variable, with one trial.
-+ And the probabilities are given by the rows of the transition matrix.
-
-\begin{align*}
-   z_1 &\sim \text{Multinomial}(1, \delta) &\text{[likelihood, }t = 1 \text{]}\\
-   z_t | z_{t-1} &\sim \text{Multinomial}(1, \gamma_{z_{t-1},z_{t}}) &\text{[likelihood, }t > 1 \text{]}\\
-  \phi &\sim \text{Beta}(1, 1) &\text{[prior for }\phi \text{]} \\
-\end{align*}
-
-\begin{align*}
-\mathbf{\Gamma} =
-\left(\begin{array}{cc}
-\color{blue}{\phi} & \color{blue}{1 - \phi}\\
-0 & 1
-\end{array}\right)
-\end{align*}
-
-$$\color{blue}{\gamma_{z_{t-1} = 1,z_{t}} = (\phi, 1-\phi)}$$
-
-+ If z at t-1 is alive, it is the first row, that is phi and 1-phi.
-
-\begin{align*}
-   z_1 &\sim \text{Multinomial}(1, \delta) &\text{[likelihood, }t = 1 \text{]}\\
-   z_t | z_{t-1} &\sim \text{Multinomial}(1, \gamma_{z_{t-1},z_{t}}) &\text{[likelihood, }t > 1 \text{]}\\
-  \phi &\sim \text{Beta}(1, 1) &\text{[prior for }\phi \text{]} \\
-\end{align*}
-
-\begin{align*}
-\mathbf{\Gamma} =
-\left(\begin{array}{cc}
-\phi & 1 - \phi\\
-\color{blue}{0} & \color{blue}{1}
-\end{array}\right)
-\end{align*}
-
-$$\color{blue}{\gamma_{z_{t-1} = 2,z_{t}} = (0, 1)}$$
-
-+ Otherwise, if z at t-1 is dead that is 2, then it is the second row of gamma, 0 and 1.
-+ If dead you remain dead.
-
-## Nimble implementation
-
-+ In Nimble, we will use the categorical distribution `dcat()`.
-
-+ The categorical distribution is a multinomial distribution with a single draw.
-
-
-```{r}
-nimble::rcat(n = 20, prob = c(0.1, 0.3, 0.6))
-```
-
-```{r}
-nimble::rcat(n = 20, prob = c(0.1, 0.1, 0.4, 0.2, 0.2))
-```
-
-https://en.wikipedia.org/wiki/Categorical_distribution
-
-The categorical distribution is the generalization of the Bernoulli distribution for a categorical random variable, i.e. for a discrete variable with more than two possible outcomes, such as the roll of a dice. On the other hand, the categorical distribution is a special case of the multinomial distribution, in that it gives the probabilities of potential outcomes of a single drawing rather than multiple drawings.
-
-## Nimble code
-
-```{r}
-markov.survival <- nimbleCode({
-  phi ~ dunif(0, 1) # prior
-  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)
-  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)
-  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)
-  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  # likelihood
-  for (i in 1:N){
-    z[i,1] ~ dcat(delta[1:2])
-    for (j in 2:T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])
-    }
-  }})
-```
-
-```{r}
-markov.survival <- nimbleCode({
-  phi ~ dunif(0, 1) # prior #<<
-  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)
-  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)
-  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)
-  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  # likelihood
-  for (i in 1:N){
-    z[i,1] ~ dcat(delta[1:2])
-    for (j in 2:T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])
-    }
-  }})
-```
-
-```{r}
-markov.survival <- nimbleCode({
-  phi ~ dunif(0, 1) # prior
-  gamma[1,1] <- phi      # Pr(alive t -> alive t+1) #<<
-  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1) #<<
-  gamma[2,1] <- 0        # Pr(dead t -> alive t+1) #<<
-  gamma[2,2] <- 1        # Pr(dead t -> dead t+1) #<<
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  # likelihood
-  for (i in 1:N){
-    z[i,1] ~ dcat(delta[1:2])
-    for (j in 2:T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])
-    }
-  }})
-```
-]
-
-
-```{r}
-markov.survival <- nimbleCode({
-  phi ~ dunif(0, 1) # prior
-  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)
-  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)
-  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)
-  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)
-  delta[1] <- 1          # Pr(alive t = 1) = 1 #<<
-  delta[2] <- 0          # Pr(dead t = 1) = 0 #<<
-  # likelihood
-  for (i in 1:N){
-    z[i,1] ~ dcat(delta[1:2])
-    for (j in 2:T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])
-    }
-  }})
-```
-
-
-```{r}
-markov.survival <- nimbleCode({
-  phi ~ dunif(0, 1) # prior
-  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)
-  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)
-  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)
-  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  # likelihood
-  for (i in 1:N){ #<<
-    z[i,1] ~ dcat(delta[1:2])
-    for (j in 2:T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])
-    }
-  } #<<
-  })
-```
-
-
-```{r}
-markov.survival <- nimbleCode({
-  phi ~ dunif(0, 1) # prior
-  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)
-  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)
-  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)
-  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  # likelihood
-  for (i in 1:N){
-    z[i,1] ~ dcat(delta[1:2]) #<<
-    for (j in 2:T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])
-    }
-  }})
-```
-
-```{r}
-markov.survival <- nimbleCode({
-  phi ~ dunif(0, 1) # prior
-  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)
-  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)
-  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)
-  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  # likelihood
-  for (i in 1:N){
-    z[i,1] ~ dcat(delta[1:2])
-    for (j in 2:T){ #<<
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])
-    } #<<
-  }})
-```
-
-```{r}
-markov.survival <- nimbleCode({
-  phi ~ dunif(0, 1) # prior
-  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)
-  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)
-  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)
-  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  # likelihood
-  for (i in 1:N){
-    z[i,1] ~ dcat(delta[1:2])
-    for (j in 2:T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2]) #<<
-    }
-  }})
-```
-
-## Note
-
-+ Vector $\delta$ is used as a placeholder for more complex models to come in Class 7.
-
-+ Here, you could write `z[i,1] <- 1`.
-
-## Nimble awesomness
-
-You should be able to define vectors and matrices like you do in `R`.
-
-```{r, eval = FALSE}
-markov.survival <- nimbleCode({
-  phi ~ dunif(0, 1) # prior
-  gamma[1:2,1:2] <- matrix( c(phi, 0, 1 - phi, 1), nrow = 2) #<<
-  delta[1:2] <- c(1, 0) #<<
-  # likelihood
-  for (i in 1:N){
-    z[i,1] ~ dcat(delta[1:2])
-    for (j in 2:T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])
-    }
-  }})
-```
-
-## Converting to Nimble from Jags, OpenBUGS or WinBUGS
-
-+ Main difference is that Nimble does not guess.
-
-+ We need to specify dimensions of vectors and matrices.
-
-+ You cannot write `x[]` or `x[i,]`. Just provide index ranges `x[1:n]` or `x[i,1:m]`.
-
-+ More tips [here](https://r-nimble.org/quick-guide-for-converting-from-jags-or-bugs-to-nimble).
-
-## Constants and data
-
-```{r}
-my.constants <- list(N = 57, T = 5)
-my.constants
-
-my.data <- list(z = z)
-```
-
-## Initial values
-
-```{r}
-initial.values <- function() list(phi = runif(1,0,1))
-initial.values()
-```
-
-## Parameters to monitor
-
-```{r}
-parameters.to.save <- c(""phi"")
-parameters.to.save
-```
-
-## MCMC details
-
-```{r}
-n.iter <- 5000
-n.burnin <- 1000
-n.chains <- 2
-```
-
-## Run Nimble
-```{r, message=FALSE, cache = TRUE}
-mcmc.output <- nimbleMCMC(code = markov.survival,
-                          constants = my.constants,
-                          data = my.data,
-                          inits = initial.values,
-                          monitors = parameters.to.save,
-                          niter = n.iter,
-                          nburnin = n.burnin,
-                          nchains = n.chains)
-```
+<!-- + OK let's wrap it up. -->
+<!-- + Our model so far is that one. -->
 
-```{r, message=FALSE, echo = FALSE, cache = TRUE}
-mcmc.output <- nimbleMCMC(code = markov.survival,
-                          constants = my.constants,
-                          data = my.data,
-                          inits = initial.values,
-                          monitors = parameters.to.save,
-                          niter = n.iter,
-                          nburnin = n.burnin,
-                          nchains = n.chains,
-                          progressBar = FALSE)
-```
+<!-- + Initial state is multinomial with one trial, and probability delta. -->
+<!-- + That is you have a dice with two faces, a coin, and you have some prob to be alive, and 1 - that prob to be dead. + Of course, it you want your Markov chain to start, you'd better say it's alive so that delta is just (1,0). -->
 
-## Posterior distribution of survival
+<!-- ## Our model -->
 
-```{r}
-library(MCMCvis)
-MCMCsummary(mcmc.output, round = 2)
-```
+<!-- \begin{align*} -->
+<!--    z_1 &\sim \text{Multinomial}(1, \delta) &\text{[likelihood, }t = 1 \text{]}\\ -->
+<!--    \color{white}{z_t | z_{t-1}} & \color{white}{\sim} \color{white}{\text{Multinomial}(1, \gamma_{z_{t-1},z_{t}})} & \color{white}{\text{[likelihood, }t > 1 \text{]}}\\ -->
+<!--   \phi &\sim \text{Beta}(1, 1) &\text{[prior for }\phi \text{]} \\ -->
+<!-- \end{align*} -->
 
-+ Posterior mean and median are close to $0.8$.
+<!-- + We also need a prior on survival. -->
+<!-- + As usual we take a uniform distribution between 0 and 1, or a beta with parameters 1 and 1. -->
 
-+ Cool! The data was simulated, with (true) survival $\phi = 0.8$.
+<!-- \begin{align*} -->
+<!--    z_1 &\sim \text{Multinomial}(1, \delta) &\text{[likelihood, }t = 1 \text{]}\\ -->
+<!--    z_t | z_{t-1} &\sim \text{Multinomial}(1, \gamma_{z_{t-1},z_{t}}) &\text{[likelihood, }t > 1 \text{]}\\ -->
+<!--   \phi &\sim \text{Beta}(1, 1) &\text{[prior for }\phi \text{]} \\ -->
+<!-- \end{align*} -->
 
-## Unfortunately, this is the data we wish we had.
 
-## In real life
+<!-- + Now the main part is the dynamic of the states. -->
+<!-- + Our state at t depends only on your state at t-1, and it is a multinomial random variable, with one trial. -->
+<!-- + And the probabilities are given by the rows of the transition matrix. -->
 
-+ Animals cannot be monitored exhaustively, like humans in a medical trial.
+<!-- \begin{align*} -->
+<!--    z_1 &\sim \text{Multinomial}(1, \delta) &\text{[likelihood, }t = 1 \text{]}\\ -->
+<!--    z_t | z_{t-1} &\sim \text{Multinomial}(1, \gamma_{z_{t-1},z_{t}}) &\text{[likelihood, }t > 1 \text{]}\\ -->
+<!--   \phi &\sim \text{Beta}(1, 1) &\text{[prior for }\phi \text{]} \\ -->
+<!-- \end{align*} -->
+
+<!-- \begin{align*} -->
+<!-- \mathbf{\Gamma} = -->
+<!-- \left(\begin{array}{cc} -->
+<!-- \color{blue}{\phi} & \color{blue}{1 - \phi}\\ -->
+<!-- 0 & 1 -->
+<!-- \end{array}\right) -->
+<!-- \end{align*} -->
+
+<!-- $$\color{blue}{\gamma_{z_{t-1} = 1,z_{t}} = (\phi, 1-\phi)}$$ -->
+
+<!-- + If z at t-1 is alive, it is the first row, that is phi and 1-phi. -->
+
+<!-- \begin{align*} -->
+<!--    z_1 &\sim \text{Multinomial}(1, \delta) &\text{[likelihood, }t = 1 \text{]}\\ -->
+<!--    z_t | z_{t-1} &\sim \text{Multinomial}(1, \gamma_{z_{t-1},z_{t}}) &\text{[likelihood, }t > 1 \text{]}\\ -->
+<!--   \phi &\sim \text{Beta}(1, 1) &\text{[prior for }\phi \text{]} \\ -->
+<!-- \end{align*} -->
+
+<!-- \begin{align*} -->
+<!-- \mathbf{\Gamma} = -->
+<!-- \left(\begin{array}{cc} -->
+<!-- \phi & 1 - \phi\\ -->
+<!-- \color{blue}{0} & \color{blue}{1} -->
+<!-- \end{array}\right) -->
+<!-- \end{align*} -->
+
+<!-- $$\color{blue}{\gamma_{z_{t-1} = 2,z_{t}} = (0, 1)}$$ -->
+
+<!-- + Otherwise, if z at t-1 is dead that is 2, then it is the second row of gamma, 0 and 1. -->
+<!-- + If dead you remain dead. -->
+
+<!-- ## Nimble implementation -->
+
+<!-- + In Nimble, we will use the categorical distribution `dcat()`. -->
+
+<!-- + The categorical distribution is a multinomial distribution with a single draw. -->
+
+
+<!-- ```{r} -->
+<!-- nimble::rcat(n = 20, prob = c(0.1, 0.3, 0.6)) -->
+<!-- ``` -->
+
+<!-- ```{r} -->
+<!-- nimble::rcat(n = 20, prob = c(0.1, 0.1, 0.4, 0.2, 0.2)) -->
+<!-- ``` -->
+
+<!-- https://en.wikipedia.org/wiki/Categorical_distribution -->
+
+<!-- The categorical distribution is the generalization of the Bernoulli distribution for a categorical random variable, i.e. for a discrete variable with more than two possible outcomes, such as the roll of a dice. On the other hand, the categorical distribution is a special case of the multinomial distribution, in that it gives the probabilities of potential outcomes of a single drawing rather than multiple drawings. -->
+
+<!-- ## Nimble code -->
+
+<!-- ```{r} -->
+<!-- markov.survival <- nimbleCode({ -->
+<!--   phi ~ dunif(0, 1) # prior -->
+<!--   gamma[1,1] <- phi      # Pr(alive t -> alive t+1) -->
+<!--   gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1) -->
+<!--   gamma[2,1] <- 0        # Pr(dead t -> alive t+1) -->
+<!--   gamma[2,2] <- 1        # Pr(dead t -> dead t+1) -->
+<!--   delta[1] <- 1          # Pr(alive t = 1) = 1 -->
+<!--   delta[2] <- 0          # Pr(dead t = 1) = 0 -->
+<!--   # likelihood -->
+<!--   for (i in 1:N){ -->
+<!--     z[i,1] ~ dcat(delta[1:2]) -->
+<!--     for (j in 2:T){ -->
+<!--       z[i,j] ~ dcat(gamma[z[i,j-1], 1:2]) -->
+<!--     } -->
+<!--   }}) -->
+<!-- ``` -->
+
+<!-- ```{r} -->
+<!-- markov.survival <- nimbleCode({ -->
+<!--   phi ~ dunif(0, 1) # prior #<< -->
+<!--   gamma[1,1] <- phi      # Pr(alive t -> alive t+1) -->
+<!--   gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1) -->
+<!--   gamma[2,1] <- 0        # Pr(dead t -> alive t+1) -->
+<!--   gamma[2,2] <- 1        # Pr(dead t -> dead t+1) -->
+<!--   delta[1] <- 1          # Pr(alive t = 1) = 1 -->
+<!--   delta[2] <- 0          # Pr(dead t = 1) = 0 -->
+<!--   # likelihood -->
+<!--   for (i in 1:N){ -->
+<!--     z[i,1] ~ dcat(delta[1:2]) -->
+<!--     for (j in 2:T){ -->
+<!--       z[i,j] ~ dcat(gamma[z[i,j-1], 1:2]) -->
+<!--     } -->
+<!--   }}) -->
+<!-- ``` -->
+
+<!-- ```{r} -->
+<!-- markov.survival <- nimbleCode({ -->
+<!--   phi ~ dunif(0, 1) # prior -->
+<!--   gamma[1,1] <- phi      # Pr(alive t -> alive t+1) #<< -->
+<!--   gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1) #<< -->
+<!--   gamma[2,1] <- 0        # Pr(dead t -> alive t+1) #<< -->
+<!--   gamma[2,2] <- 1        # Pr(dead t -> dead t+1) #<< -->
+<!--   delta[1] <- 1          # Pr(alive t = 1) = 1 -->
+<!--   delta[2] <- 0          # Pr(dead t = 1) = 0 -->
+<!--   # likelihood -->
+<!--   for (i in 1:N){ -->
+<!--     z[i,1] ~ dcat(delta[1:2]) -->
+<!--     for (j in 2:T){ -->
+<!--       z[i,j] ~ dcat(gamma[z[i,j-1], 1:2]) -->
+<!--     } -->
+<!--   }}) -->
+<!-- ``` -->
+<!-- ] -->
+
+
+<!-- ```{r} -->
+<!-- markov.survival <- nimbleCode({ -->
+<!--   phi ~ dunif(0, 1) # prior -->
+<!--   gamma[1,1] <- phi      # Pr(alive t -> alive t+1) -->
+<!--   gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1) -->
+<!--   gamma[2,1] <- 0        # Pr(dead t -> alive t+1) -->
+<!--   gamma[2,2] <- 1        # Pr(dead t -> dead t+1) -->
+<!--   delta[1] <- 1          # Pr(alive t = 1) = 1 #<< -->
+<!--   delta[2] <- 0          # Pr(dead t = 1) = 0 #<< -->
+<!--   # likelihood -->
+<!--   for (i in 1:N){ -->
+<!--     z[i,1] ~ dcat(delta[1:2]) -->
+<!--     for (j in 2:T){ -->
+<!--       z[i,j] ~ dcat(gamma[z[i,j-1], 1:2]) -->
+<!--     } -->
+<!--   }}) -->
+<!-- ``` -->
+
+
+<!-- ```{r} -->
+<!-- markov.survival <- nimbleCode({ -->
+<!--   phi ~ dunif(0, 1) # prior -->
+<!--   gamma[1,1] <- phi      # Pr(alive t -> alive t+1) -->
+<!--   gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1) -->
+<!--   gamma[2,1] <- 0        # Pr(dead t -> alive t+1) -->
+<!--   gamma[2,2] <- 1        # Pr(dead t -> dead t+1) -->
+<!--   delta[1] <- 1          # Pr(alive t = 1) = 1 -->
+<!--   delta[2] <- 0          # Pr(dead t = 1) = 0 -->
+<!--   # likelihood -->
+<!--   for (i in 1:N){ #<< -->
+<!--     z[i,1] ~ dcat(delta[1:2]) -->
+<!--     for (j in 2:T){ -->
+<!--       z[i,j] ~ dcat(gamma[z[i,j-1], 1:2]) -->
+<!--     } -->
+<!--   } #<< -->
+<!--   }) -->
+<!-- ``` -->
+
+
+<!-- ```{r} -->
+<!-- markov.survival <- nimbleCode({ -->
+<!--   phi ~ dunif(0, 1) # prior -->
+<!--   gamma[1,1] <- phi      # Pr(alive t -> alive t+1) -->
+<!--   gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1) -->
+<!--   gamma[2,1] <- 0        # Pr(dead t -> alive t+1) -->
+<!--   gamma[2,2] <- 1        # Pr(dead t -> dead t+1) -->
+<!--   delta[1] <- 1          # Pr(alive t = 1) = 1 -->
+<!--   delta[2] <- 0          # Pr(dead t = 1) = 0 -->
+<!--   # likelihood -->
+<!--   for (i in 1:N){ -->
+<!--     z[i,1] ~ dcat(delta[1:2]) #<< -->
+<!--     for (j in 2:T){ -->
+<!--       z[i,j] ~ dcat(gamma[z[i,j-1], 1:2]) -->
+<!--     } -->
+<!--   }}) -->
+<!-- ``` -->
+
+<!-- ```{r} -->
+<!-- markov.survival <- nimbleCode({ -->
+<!--   phi ~ dunif(0, 1) # prior -->
+<!--   gamma[1,1] <- phi      # Pr(alive t -> alive t+1) -->
+<!--   gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1) -->
+<!--   gamma[2,1] <- 0        # Pr(dead t -> alive t+1) -->
+<!--   gamma[2,2] <- 1        # Pr(dead t -> dead t+1) -->
+<!--   delta[1] <- 1          # Pr(alive t = 1) = 1 -->
+<!--   delta[2] <- 0          # Pr(dead t = 1) = 0 -->
+<!--   # likelihood -->
+<!--   for (i in 1:N){ -->
+<!--     z[i,1] ~ dcat(delta[1:2]) -->
+<!--     for (j in 2:T){ #<< -->
+<!--       z[i,j] ~ dcat(gamma[z[i,j-1], 1:2]) -->
+<!--     } #<< -->
+<!--   }}) -->
+<!-- ``` -->
+
+<!-- ```{r} -->
+<!-- markov.survival <- nimbleCode({ -->
+<!--   phi ~ dunif(0, 1) # prior -->
+<!--   gamma[1,1] <- phi      # Pr(alive t -> alive t+1) -->
+<!--   gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1) -->
+<!--   gamma[2,1] <- 0        # Pr(dead t -> alive t+1) -->
+<!--   gamma[2,2] <- 1        # Pr(dead t -> dead t+1) -->
+<!--   delta[1] <- 1          # Pr(alive t = 1) = 1 -->
+<!--   delta[2] <- 0          # Pr(dead t = 1) = 0 -->
+<!--   # likelihood -->
+<!--   for (i in 1:N){ -->
+<!--     z[i,1] ~ dcat(delta[1:2]) -->
+<!--     for (j in 2:T){ -->
+<!--       z[i,j] ~ dcat(gamma[z[i,j-1], 1:2]) #<< -->
+<!--     } -->
+<!--   }}) -->
+<!-- ``` -->
+
+<!-- ## Note -->
+
+<!-- + Vector $\delta$ is used as a placeholder for more complex models to come in Class 7. -->
+
+<!-- + Here, you could write `z[i,1] <- 1`. -->
+
+<!-- ## Nimble awesomness -->
+
+<!-- You should be able to define vectors and matrices like you do in `R`. -->
+
+<!-- ```{r, eval = FALSE} -->
+<!-- markov.survival <- nimbleCode({ -->
+<!--   phi ~ dunif(0, 1) # prior -->
+<!--   gamma[1:2,1:2] <- matrix( c(phi, 0, 1 - phi, 1), nrow = 2) #<< -->
+<!--   delta[1:2] <- c(1, 0) #<< -->
+<!--   # likelihood -->
+<!--   for (i in 1:N){ -->
+<!--     z[i,1] ~ dcat(delta[1:2]) -->
+<!--     for (j in 2:T){ -->
+<!--       z[i,j] ~ dcat(gamma[z[i,j-1], 1:2]) -->
+<!--     } -->
+<!--   }}) -->
+<!-- ``` -->
+
+<!-- ## Converting to Nimble from Jags, OpenBUGS or WinBUGS -->
+
+<!-- + Main difference is that Nimble does not guess. -->
+
+<!-- + We need to specify dimensions of vectors and matrices. -->
+
+<!-- + You cannot write `x[]` or `x[i,]`. Just provide index ranges `x[1:n]` or `x[i,1:m]`. -->
+
+<!-- + More tips [here](https://r-nimble.org/quick-guide-for-converting-from-jags-or-bugs-to-nimble). -->
+
+<!-- ## Constants and data -->
+
+<!-- ```{r} -->
+<!-- my.constants <- list(N = 57, T = 5) -->
+<!-- my.constants -->
+
+<!-- my.data <- list(z = z) -->
+<!-- ``` -->
+
+<!-- ## Initial values -->
+
+<!-- ```{r} -->
+<!-- initial.values <- function() list(phi = runif(1,0,1)) -->
+<!-- initial.values() -->
+<!-- ``` -->
+
+<!-- ## Parameters to monitor -->
+
+<!-- ```{r} -->
+<!-- parameters.to.save <- c(""phi"") -->
+<!-- parameters.to.save -->
+<!-- ``` -->
+
+<!-- ## MCMC details -->
+
+<!-- ```{r} -->
+<!-- n.iter <- 5000 -->
+<!-- n.burnin <- 1000 -->
+<!-- n.chains <- 2 -->
+<!-- ``` -->
+
+<!-- ## Run Nimble -->
+<!-- ```{r, message=FALSE, cache = TRUE} -->
+<!-- mcmc.output <- nimbleMCMC(code = markov.survival, -->
+<!--                           constants = my.constants, -->
+<!--                           data = my.data, -->
+<!--                           inits = initial.values, -->
+<!--                           monitors = parameters.to.save, -->
+<!--                           niter = n.iter, -->
+<!--                           nburnin = n.burnin, -->
+<!--                           nchains = n.chains) -->
+<!-- ``` -->
+
+<!-- ```{r, message=FALSE, echo = FALSE, cache = TRUE} -->
+<!-- mcmc.output <- nimbleMCMC(code = markov.survival, -->
+<!--                           constants = my.constants, -->
+<!--                           data = my.data, -->
+<!--                           inits = initial.values, -->
+<!--                           monitors = parameters.to.save, -->
+<!--                           niter = n.iter, -->
+<!--                           nburnin = n.burnin, -->
+<!--                           nchains = n.chains, -->
+<!--                           progressBar = FALSE) -->
+<!-- ``` -->
+
+<!-- ## Posterior distribution of survival -->
+
+<!-- ```{r} -->
+<!-- library(MCMCvis) -->
+<!-- MCMCsummary(mcmc.output, round = 2) -->
+<!-- ``` -->
+
+<!-- + Posterior mean and median are close to $0.8$. -->
+
+<!-- + Cool! The data was simulated, with (true) survival $\phi = 0.8$. -->
+
+<!-- ## Unfortunately, this is the data we wish we had. -->
+
+<!-- ## In real life -->
+
+<!-- + Animals cannot be monitored exhaustively, like humans in a medical trial. -->
+
+<!-- + Animals are captured, marked or identified then released alive. -->
+
+<!-- + Then, these animals may be detected again, or go undetected <span>&#8212;</span> **capture-recapture** -->
+
+<!-- + Whenever animals go undetected, it might be that they were alive but missed, or because they were dead and therefore could not be detected <span>&#8212;</span> **imperfect detection**. -->
+
+<!-- <https://www.youtube.com/embed/tyX79mPm2xY> -->
+
+<!-- + Whenever animals go undetected, it might be that they were alive but missed, or because they were dead and therefore could not be detected <span>&#8212;</span> **imperfect detection**. -->
+
+<!-- + The Markov process for survival is only partially observed <span>&#8212;</span> **hidden Markov models**. -->
+
+<!-- ## The truth is in $z$ -->
+
+<!-- ```{r echo = FALSE} -->
+<!-- z %>% -->
+<!--   as_tibble() %>% -->
+<!--   add_column(id = 1:nind, .before = ""winter 1"") %>% -->
+<!--   kableExtra::kable() %>% -->
+<!--   kableExtra::scroll_box(width = ""100%"", height = ""300px"") -->
+<!-- ``` -->
+
+<!-- + Unfortunately, we have only partial access to $z$. -->
+
+<!-- + We do observe $y$ the detections and non-detections. -->
+
+<!-- + How are $z$ and $y$ connected? -->
+
+<!-- ## Dead animals go undetected -->
+
+<!-- + When an animal is dead i.e. $z = 2$, it cannot be detected, therefore $y = 0$. -->
+
+<!-- ```{r echo = FALSE} -->
+<!-- z %>% -->
+<!--   as_tibble() %>% -->
+<!--   replace(. == 2, 0) %>% -->
+<!--   add_column(id = 1:nind, .before = ""winter 1"") %>% -->
+<!--   kableExtra::kable() %>% -->
+<!--   kableExtra::scroll_box(width = ""100%"", height = ""300px"") -->
+<!-- ``` -->
+
+<!-- ## Alive animals may be detected or not -->
+
+<!-- + If animal is alive $z = 1$, it is detected $y = 1$ w/ prob $p$ or not $y = 0$ w/ prob $1-p$. -->
 
-+ Animals are captured, marked or identified then released alive.
+<!-- + Before **first** detection, we know nothing, and we proceed conditional on it. -->
 
-+ Then, these animals may be detected again, or go undetected <span>&#8212;</span> **capture-recapture**
+<!-- ```{r echo = FALSE} -->
+<!-- p <- 0.6 -->
+<!-- y <- z -->
+<!-- y[z==2] <- 0 -->
+<!-- y[y==1] <- rbinom(n = sum(y==1), 1, p) -->
+<!-- nobs <- sum(apply(y,1,sum) != 0) -->
+<!-- y <- y[apply(y,1,sum) !=0, ] -->
+<!-- first <- apply(y, 1, function(x) min(which(x !=0))) -->
+<!-- for (i in 1:nobs){ -->
+<!--   if(first[i] > 1) y[i, 1:(first[i]-1)] <- NA -->
+<!-- } -->
+<!-- y %>% -->
+<!--   as_tibble() %>% -->
+<!--   add_column(id = 1:nobs, .before = ""winter 1"") %>% -->
+<!--   kableExtra::kable() %>% -->
+<!--   kableExtra::scroll_box(width = ""100%"", height = ""300px"") -->
+<!-- ``` -->
 
-+ Whenever animals go undetected, it might be that they were alive but missed, or because they were dead and therefore could not be detected <span>&#8212;</span> **imperfect detection**.
+<!-- + Compare with previous table -->
+<!-- + Some 1s have become 0s. -->
 
-<https://www.youtube.com/embed/tyX79mPm2xY>
+<!-- + This table $y$ is what we observe in real life. -->
 
-+ Whenever animals go undetected, it might be that they were alive but missed, or because they were dead and therefore could not be detected <span>&#8212;</span> **imperfect detection**.
+<!-- + To make the connection between the observations, the y, and the true states, the z -->
+<!-- + We need to describe how observations are made from the states -->
 
-+ The Markov process for survival is only partially observed <span>&#8212;</span> **hidden Markov models**.
+<!-- ## Observation matrix -->
 
-## The truth is in $z$
+<!-- + The observation probabilities can be packed in an observation matrix $\mathbf{\Omega}$. -->
 
-```{r echo = FALSE}
-z %>%
-  as_tibble() %>%
-  add_column(id = 1:nind, .before = ""winter 1"") %>%
-  kableExtra::kable() %>%
-  kableExtra::scroll_box(width = ""100%"", height = ""300px"")
-```
+<!-- + In rows: the states alive $z = 1$ and dead $z = 2$. -->
 
-+ Unfortunately, we have only partial access to $z$.
+<!-- + In columns: the observations non-detected $y = 1$ and detected $y = 2$ (previously coded 0 and 1 respectively). -->
 
-+ We do observe $y$ the detections and non-detections.
-
-+ How are $z$ and $y$ connected?
-
-## Dead animals go undetected
-
-+ When an animal is dead i.e. $z = 2$, it cannot be detected, therefore $y = 0$.
-
-```{r echo = FALSE}
-z %>%
-  as_tibble() %>%
-  replace(. == 2, 0) %>%
-  add_column(id = 1:nind, .before = ""winter 1"") %>%
-  kableExtra::kable() %>%
-  kableExtra::scroll_box(width = ""100%"", height = ""300px"")
-```
-
-## Alive animals may be detected or not
-
-+ If animal is alive $z = 1$, it is detected $y = 1$ w/ prob $p$ or not $y = 0$ w/ prob $1-p$.
-
-+ Before **first** detection, we know nothing, and we proceed conditional on it.
-
-```{r echo = FALSE}
-p <- 0.6
-y <- z
-y[z==2] <- 0
-y[y==1] <- rbinom(n = sum(y==1), 1, p)
-nobs <- sum(apply(y,1,sum) != 0)
-y <- y[apply(y,1,sum) !=0, ]
-first <- apply(y, 1, function(x) min(which(x !=0)))
-for (i in 1:nobs){
-  if(first[i] > 1) y[i, 1:(first[i]-1)] <- NA
-}
-y %>%
-  as_tibble() %>%
-  add_column(id = 1:nobs, .before = ""winter 1"") %>%
-  kableExtra::kable() %>%
-  kableExtra::scroll_box(width = ""100%"", height = ""300px"")
-```
-
-+ Compare with previous table
-+ Some 1s have become 0s.
-
-+ This table $y$ is what we observe in real life.
-
-+ To make the connection between the observations, the y, and the true states, the z
-+ We need to describe how observations are made from the states
-
-## Observation matrix
-
-+ The observation probabilities can be packed in an observation matrix $\mathbf{\Omega}$.
-
-+ In rows: the states alive $z = 1$ and dead $z = 2$.
-
-+ In columns: the observations non-detected $y = 1$ and detected $y = 2$ (previously coded 0 and 1 respectively).
-
-\begin{align*}
-\mathbf{\Omega} =
-\left(\begin{array}{cc}
-\omega_{1,1} & \omega_{1,2}\\
-\omega_{2,1} & \omega_{2,2}
-\end{array}\right) =
-\left(\begin{array}{cc}
-1 - p & p\\
-1 & 0
-\end{array}\right)
-\end{align*}
-
-Observation matrix:
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Omega} =
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    y_t=1 & y_t=2 \\ \hdashline
-1 - p & p\\
-1 & 0\\
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    z_{t}=A \\ z_{t}=D
-    \end{matrix}
-\end{matrix}
-$$
-
-## Markov model
-
-```{r, engine = 'tikz', echo = FALSE}
-\usetikzlibrary{arrows, fit, positioning, automata}
-\begin{tikzpicture}[node distance = 2cm]
-\tikzset{state/.style = {circle, draw, minimum size = 30pt, scale = 3, line width=1pt}}
-\node [state,fill=lightgray!75] (6) [] {$z_{t}$};
-\node [state,fill=lightgray!75] (5) [left = 20mm of 6] {$z_{t-1}$};
-\node [state,fill=lightgray!75] (4) [left = 20mm of 5] {$z_{t-2}$};
-\node [state,fill=lightgray!75] (3) [left = 20mm of 4] {$\cdots$};
-\node [state,fill=lightgray!75] (7) [right = 20mm of 6] {$z_{t+1}$};
-\node [state,fill=lightgray!75] (8) [right = 20mm of 7] {$z_{t+2}$};
-\node [state,fill=lightgray!75] (9) [right = 20mm of 8] {$\cdots$};
-\draw[->,black, line width=0.25mm,-latex] (3) to (4);
-\draw[->,black, line width=0.25mm,-latex] (4) to (5);
-\draw[->,black, line width=0.25mm,-latex] (5) to (6);
-\draw[->,black, line width=0.25mm,-latex] (6) to (7);
-\draw[->,black, line width=0.25mm,-latex] (7) to (8);
-\draw[->,black, line width=0.25mm,-latex] (8) to (9);
-\end{tikzpicture}
-```
-
-+ States $z$ are in gray.
-
-+ Remember the graphical repres of a Markov model.
-
-## Hidden Markov model
-
-```{r, engine = 'tikz', echo = FALSE}
-\usetikzlibrary{arrows, fit, positioning, automata}
-\begin{tikzpicture}[node distance = 2cm]
-\tikzset{state/.style = {circle, draw, minimum size = 30pt, scale = 3, line width=1pt}}
-\node [state,fill=lightgray!75] (6) [] {$z_{t}$};
-\node [state,fill=lightgray!75] (5) [left = 20mm of 6] {$z_{t-1}$};
-\node [state,fill=lightgray!75] (4) [left = 20mm of 5] {$z_{t-2}$};
-\node [state,fill=lightgray!75] (3) [left = 20mm of 4] {$\cdots$};
-\node [state,fill=lightgray!75] (7) [right = 20mm of 6] {$z_{t+1}$};
-\node [state,fill=lightgray!75] (8) [right = 20mm of 7] {$z_{t+2}$};
-\node [state,fill=lightgray!75] (9) [right = 20mm of 8] {$\cdots$};
-\node [state,fill=white] (16) [above = 20mm of 6] {$y_{t}$};
-\node [state,fill=white] (15) [above = 20mm of 5] {$y_{t-1}$};
-\node [state,fill=white] (14) [above = 20mm of 4] {$y_{t-2}$};
-\node [state,fill=white] (17) [above = 20mm of 7] {$y_{t+1}$};
-\node [state,fill=white] (18) [above = 20mm of 8] {$y_{t+2}$};
-\draw[->,black, line width=0.25mm,-latex] (3) to (4);
-\draw[->,black, line width=0.25mm,-latex] (4) to (5);
-\draw[->,black, line width=0.25mm,-latex] (5) to (6);
-\draw[->,black, line width=0.25mm,-latex] (6) to (7);
-\draw[->,black, line width=0.25mm,-latex] (7) to (8);
-\draw[->,black, line width=0.25mm,-latex] (8) to (9);
-\draw[->,black, line width=0.25mm,-latex] (4) to (14);
-\draw[->,black, line width=0.25mm,-latex] (5) to (15);
-\draw[->,black, line width=0.25mm,-latex] (6) to (16);
-\draw[->,black, line width=0.25mm,-latex] (7) to (17);
-\draw[->,black, line width=0.25mm,-latex] (8) to (18);
-\end{tikzpicture}
-```
-
-+ States $z$ are in gray.
-
-+ Observations $y$ are in white.
-
-+ A hidden Markov model is just two time series.
-+ One for the states with a Markovian property.
-+ The other of observations generated from the states.
-+ Run in parallel.
-
-## Hidden Markov model for survival
-
-```{r, engine = 'tikz', echo = FALSE}
-\usetikzlibrary{arrows, fit, positioning, automata}
-\begin{tikzpicture}[node distance = 2cm]
-\tikzset{state/.style = {circle, draw, minimum size = 30pt, scale = 3, line width=1pt}}
-\node [state,fill=lightgray!75] (6) [] {$1$};
-\node [state,fill=lightgray!75] (5) [left = 20mm of 6] {$1$};
-\node [state,fill=lightgray!75] (4) [left = 20mm of 5] {$1$};
-\node [state,fill=lightgray!75] (3) [left = 20mm of 4] {$1$};
-\node [state,fill=lightgray!75] (7) [right = 20mm of 6] {$2$};
-\node [state,fill=lightgray!75] (8) [right = 20mm of 7] {$2$};
-\node [state,fill=lightgray!75] (9) [right = 20mm of 8] {$\cdots$};
-\node [state,fill=white] (16) [above = 20mm of 6] {$1$};
-\node [state,fill=white] (15) [above = 20mm of 5] {$2$};
-\node [state,fill=white] (14) [above = 20mm of 4] {$1$};
-\node [state,fill=white] (17) [above = 20mm of 7] {$1$};
-\node [state,fill=white] (18) [above = 20mm of 8] {$1$};
-\draw[->,black, line width=0.25mm,-latex] (3) -- node[above=3mm, align=center] {\huge $\varphi$} (4);
-\draw[->,black, line width=0.25mm,-latex] (4) -- node[above=3mm, align=center] {\huge $\varphi$} (5);
-\draw[->,black, line width=0.25mm,-latex] (5) -- node[above=3mm, align=center] {\huge $\varphi$} (6);
-\draw[->,black, line width=0.25mm,-latex] (6) -- node[above=3mm, align=center] {\huge $1 - \varphi$} (7);
-\draw[->,black, line width=0.25mm,-latex] (7) -- node[above=3mm, align=center] {\huge $1$} (8);
-\draw[->,black, line width=0.25mm,-latex] (8) -- node[above=3mm, align=center] {\huge $1$} (9);
-\draw[->,black, line width=0.25mm,-latex] (4) -- node[left=3mm, align=center] {\huge $1 - p$} (14);
-\draw[->,black, line width=0.25mm,-latex] (5) -- node[left=3mm, align=center] {\huge $p$} (15);
-\draw[->,black, line width=0.25mm,-latex] (6) -- node[left=3mm, align=center] {\huge $1 - p$} (16);
-\draw[->,black, line width=0.25mm,-latex] (7) -- node[left=3mm, align=center] {\huge $1$} (17);
-\draw[->,black, line width=0.25mm,-latex] (8) -- node[left=3mm, align=center] {\huge $1$} (18);
-\end{tikzpicture}
-```
-
-+ For states (in gray), $z = 1$ is alive, $z = 2$ is dead.
-
-+ For observations (in white), $y = 1$ is non-detected, $y = 2$ is detected
-
-+ Now add the states alive and dead, 1 and 2s.
-+ The observations, non-detected and detected, 1 and 2s.
-+ And the parameters, phi for transition from 1 to 1.
-+ And p for prob of y being 2 detected given z is 1 alive.
-
-## HMM likelihood
-
-+ Using the formula of total probability, then the likelihood of a Markov chain:
-
-\begin{align*}
-\Pr(\mathbf{y}) &= \Pr(y_1, y_{2}, \ldots, y_T)\\
-                &= \sum_{z_1} \cdots \sum_{z_T} \Pr(y_1, y_{2}, \ldots, y_T | z_1, z_{2}, \ldots, z_T) \Pr(z_1, z_{2}, \ldots, z_T)\\
-                &= \sum_{z_1} \cdots \sum_{z_T} \left(\prod_{t=1}^T{\omega_{z_{t}, y_t}}\right) \left(\Pr(z_{1}) \prod_{t=2}^T{\gamma_{z_{t-1},z_{t}}}\right)\\
-\end{align*}
-
-+ What is the likelihood of a HMM.
-+ The thing here is that we don't know the states.
-+ So we have to go through all possibilities, and sum over the possible states.
-+ Hence these sums here.
-+ Then this term is the likelihood of a Markov chain, we saw that before.
-+ And this component are the elements of the observation matrix.
-+ The likelihood has a matrix formulation that can be useful.
-+ It is delta, initial states, then observation, then transitions, and so on. There is a vector of ones at the end to get the sum all the terms.
-
-+ It has a matrix formulation:
-\begin{align*}
-\Pr(\mathbf{y}) &= \mathbf{\delta} \; \mathbf{\Omega} \; \mathbf{\Gamma} \cdots \mathbf{\Omega} \; \mathbf{\Gamma} \; \mathbf{\Omega} \; \mathbb{1}
-\end{align*}
-
-## Example
-
-+ Let assume an animal is detected, then missed.
-
-+ We have $\mathbf{y} = (2, 1)$. What is the contribution of this animal to the likelihood?
-
-\begin{align*}
-\Pr(\mathbf{y} = (2, 1)) &= \sum_{z_1 = 1}^2 \; \sum_{z_2 = 1}^2 w_{z_1, y_1 = 2} w_{z_2, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2} \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1, z_1, z_1, z_1)}\\
-\end{align*}
-
-## Example
-
-+ Let assume an animal is detected, then missed.
-
-+ We have $\mathbf{y} = (2, 1)$. What is the contribution of this animal to the likelihood?
-
-\begin{align*}
-\Pr(\mathbf{y} = (2, 1)) &= \sum_{z_1 = 1}^2 \; \sum_{z_2 = 1}^2 w_{z_1, y_1 = 2} w_{z_2, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2} \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1, z_1, z_1, z_1)}\\
-&= \sum_{z_1 = 1}^2 \left( w_{z_1, y_1 = 2} w_{z_2 = 1, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2 = 1} + w_{z_1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2 = 2} \right) \\
-\end{align*}
-
-+ Let assume an animal is detected, then missed.
-
-+ We have $\mathbf{y} = (2, 1)$. What is the contribution of this animal to the likelihood?
-
-\begin{align*}
-\Pr(\mathbf{y} = (2, 1)) &= \sum_{z_1 = 1}^2 \; \sum_{z_2 = 1}^2 w_{z_1, y_1 = 2} w_{z_2, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2} \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1, z_1, z_1, z_1)}\\
-&= \sum_{z_1 = 1}^2 \left( w_{z_1, y_1 = 2} w_{z_2 = 1, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2 = 1} + w_{z_1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2 = 2} \right) \\
-&= w_{z_1 = 1, y_1 = 2} w_{z_2 = 1, y_2 = 1}\delta_1 \gamma_{z_1 = 1, z_2 = 1} + w_{z_1 = 1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \delta_1 \gamma_{z_1 = 1, z_2 = 2}
-\end{align*}
-
-Note: $\Pr(z_1 = 1) = \delta_1 = 1$ and $\Pr(z_1 = 2) = 0$.
-
-+ Let assume an animal is detected, then missed.
-
-+ We have $\mathbf{y} = (2, 1)$. What is the contribution of this animal to the likelihood?
-
-\begin{align*}
-\Pr(\mathbf{y} = (2, 1)) &= \sum_{z_1 = 1}^2 \; \sum_{z_2 = 1}^2 w_{z_1, y_1 = 2} w_{z_2, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2} \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1, z_1, z_1, z_1)}\\
-&= \sum_{z_1 = 1}^2 \left( w_{z_1, y_1 = 2} w_{z_2 = 1, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2 = 1} + w_{z_1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2 = 2} \right) \\
-&= w_{z_1 = 1, y_1 = 2} w_{z_2 = 1, y_2 = 1} \delta_1 \gamma_{z_1 = 1, z_2 = 1} + w_{z_1 = 1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \delta_1 \gamma_{z_1 = 1, z_2 = 2}\\
-&= (1 - p) \phi + (1-\phi)
-\end{align*}
-
-Note: $w_{z_1 = 1, y_1 = 2} = \Pr(y_1 = 2 | z_1 = 1) = 1$ because we condition on first capture.
-
-## Estimating the latent states $z$ or not?
-
-+ Next question is, shall we estimate the latent states or not?
-
-+ In previous example, we got rid of the states, so that likelihood was a function of $\phi$ and $p$ only. This is the function we would maximize in a Frequentist approach.
-
-+ The Bayesian approach with MCMC methods allows treating the latent states as if they were parameters, and to be estimated as such.
-
-+ Infering the latent states $z$ can be useful to estimate prevalence, e.g. in animal epidemiology with [prevalence of a disease](https://veterinaryresearch.biomedcentral.com/articles/10.1186/1297-9716-45-39), in evolutionary ecology with [sex ratio](https://onlinelibrary.wiley.com/doi/abs/10.1002/cjs.5550360105) or in conservation biology with [prevalence of hybrids](https://onlinelibrary.wiley.com/doi/full/10.1002/ece3.4819?af=R).
-
-+ Estimating the latent states is costly though, and if not required, marginalisation may speed up computations. Actually, you can estimate the states afterwards (Viterbi).
-
-+ More about so-called marginalisation in [Yackulic et al. (2020)](https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1002/eap.2112).
+<!-- \begin{align*} -->
+<!-- \mathbf{\Omega} = -->
+<!-- \left(\begin{array}{cc} -->
+<!-- \omega_{1,1} & \omega_{1,2}\\ -->
+<!-- \omega_{2,1} & \omega_{2,2} -->
+<!-- \end{array}\right) = -->
+<!-- \left(\begin{array}{cc} -->
+<!-- 1 - p & p\\ -->
+<!-- 1 & 0 -->
+<!-- \end{array}\right) -->
+<!-- \end{align*} -->
+
+<!-- Observation matrix: -->
+
+<!-- $$ -->
+<!-- \begin{matrix} -->
+<!-- & \\ -->
+<!-- \mathbf{\Omega} = -->
+<!--     \left ( \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right . -->
+<!-- \end{matrix} -->
+<!-- \hspace{-1.2em} -->
+<!-- \begin{matrix} -->
+<!--     y_t=1 & y_t=2 \\ \hdashline -->
+<!-- 1 - p & p\\ -->
+<!-- 1 & 0\\ -->
+<!-- \end{matrix} -->
+<!-- \hspace{-0.2em} -->
+<!-- \begin{matrix} -->
+<!-- & \\ -->
+<!-- \left . \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right ) -->
+<!--     \begin{matrix} -->
+<!--     z_{t}=A \\ z_{t}=D -->
+<!--     \end{matrix} -->
+<!-- \end{matrix} -->
+<!-- $$ -->
+
+<!-- ## Markov model -->
+
+<!-- ```{r, engine = 'tikz', echo = FALSE} -->
+<!-- \usetikzlibrary{arrows, fit, positioning, automata} -->
+<!-- \begin{tikzpicture}[node distance = 2cm] -->
+<!-- \tikzset{state/.style = {circle, draw, minimum size = 30pt, scale = 3, line width=1pt}} -->
+<!-- \node [state,fill=lightgray!75] (6) [] {$z_{t}$}; -->
+<!-- \node [state,fill=lightgray!75] (5) [left = 20mm of 6] {$z_{t-1}$}; -->
+<!-- \node [state,fill=lightgray!75] (4) [left = 20mm of 5] {$z_{t-2}$}; -->
+<!-- \node [state,fill=lightgray!75] (3) [left = 20mm of 4] {$\cdots$}; -->
+<!-- \node [state,fill=lightgray!75] (7) [right = 20mm of 6] {$z_{t+1}$}; -->
+<!-- \node [state,fill=lightgray!75] (8) [right = 20mm of 7] {$z_{t+2}$}; -->
+<!-- \node [state,fill=lightgray!75] (9) [right = 20mm of 8] {$\cdots$}; -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (3) to (4); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (4) to (5); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (5) to (6); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (6) to (7); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (7) to (8); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (8) to (9); -->
+<!-- \end{tikzpicture} -->
+<!-- ``` -->
+
+<!-- + States $z$ are in gray. -->
+
+<!-- + Remember the graphical repres of a Markov model. -->
+
+<!-- ## Hidden Markov model -->
+
+<!-- ```{r, engine = 'tikz', echo = FALSE} -->
+<!-- \usetikzlibrary{arrows, fit, positioning, automata} -->
+<!-- \begin{tikzpicture}[node distance = 2cm] -->
+<!-- \tikzset{state/.style = {circle, draw, minimum size = 30pt, scale = 3, line width=1pt}} -->
+<!-- \node [state,fill=lightgray!75] (6) [] {$z_{t}$}; -->
+<!-- \node [state,fill=lightgray!75] (5) [left = 20mm of 6] {$z_{t-1}$}; -->
+<!-- \node [state,fill=lightgray!75] (4) [left = 20mm of 5] {$z_{t-2}$}; -->
+<!-- \node [state,fill=lightgray!75] (3) [left = 20mm of 4] {$\cdots$}; -->
+<!-- \node [state,fill=lightgray!75] (7) [right = 20mm of 6] {$z_{t+1}$}; -->
+<!-- \node [state,fill=lightgray!75] (8) [right = 20mm of 7] {$z_{t+2}$}; -->
+<!-- \node [state,fill=lightgray!75] (9) [right = 20mm of 8] {$\cdots$}; -->
+<!-- \node [state,fill=white] (16) [above = 20mm of 6] {$y_{t}$}; -->
+<!-- \node [state,fill=white] (15) [above = 20mm of 5] {$y_{t-1}$}; -->
+<!-- \node [state,fill=white] (14) [above = 20mm of 4] {$y_{t-2}$}; -->
+<!-- \node [state,fill=white] (17) [above = 20mm of 7] {$y_{t+1}$}; -->
+<!-- \node [state,fill=white] (18) [above = 20mm of 8] {$y_{t+2}$}; -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (3) to (4); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (4) to (5); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (5) to (6); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (6) to (7); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (7) to (8); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (8) to (9); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (4) to (14); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (5) to (15); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (6) to (16); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (7) to (17); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (8) to (18); -->
+<!-- \end{tikzpicture} -->
+<!-- ``` -->
+
+<!-- + States $z$ are in gray. -->
+
+<!-- + Observations $y$ are in white. -->
+
+<!-- + A hidden Markov model is just two time series. -->
+<!-- + One for the states with a Markovian property. -->
+<!-- + The other of observations generated from the states. -->
+<!-- + Run in parallel. -->
+
+<!-- ## Hidden Markov model for survival -->
+
+<!-- ```{r, engine = 'tikz', echo = FALSE} -->
+<!-- \usetikzlibrary{arrows, fit, positioning, automata} -->
+<!-- \begin{tikzpicture}[node distance = 2cm] -->
+<!-- \tikzset{state/.style = {circle, draw, minimum size = 30pt, scale = 3, line width=1pt}} -->
+<!-- \node [state,fill=lightgray!75] (6) [] {$1$}; -->
+<!-- \node [state,fill=lightgray!75] (5) [left = 20mm of 6] {$1$}; -->
+<!-- \node [state,fill=lightgray!75] (4) [left = 20mm of 5] {$1$}; -->
+<!-- \node [state,fill=lightgray!75] (3) [left = 20mm of 4] {$1$}; -->
+<!-- \node [state,fill=lightgray!75] (7) [right = 20mm of 6] {$2$}; -->
+<!-- \node [state,fill=lightgray!75] (8) [right = 20mm of 7] {$2$}; -->
+<!-- \node [state,fill=lightgray!75] (9) [right = 20mm of 8] {$\cdots$}; -->
+<!-- \node [state,fill=white] (16) [above = 20mm of 6] {$1$}; -->
+<!-- \node [state,fill=white] (15) [above = 20mm of 5] {$2$}; -->
+<!-- \node [state,fill=white] (14) [above = 20mm of 4] {$1$}; -->
+<!-- \node [state,fill=white] (17) [above = 20mm of 7] {$1$}; -->
+<!-- \node [state,fill=white] (18) [above = 20mm of 8] {$1$}; -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (3) -- node[above=3mm, align=center] {\huge $\varphi$} (4); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (4) -- node[above=3mm, align=center] {\huge $\varphi$} (5); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (5) -- node[above=3mm, align=center] {\huge $\varphi$} (6); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (6) -- node[above=3mm, align=center] {\huge $1 - \varphi$} (7); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (7) -- node[above=3mm, align=center] {\huge $1$} (8); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (8) -- node[above=3mm, align=center] {\huge $1$} (9); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (4) -- node[left=3mm, align=center] {\huge $1 - p$} (14); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (5) -- node[left=3mm, align=center] {\huge $p$} (15); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (6) -- node[left=3mm, align=center] {\huge $1 - p$} (16); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (7) -- node[left=3mm, align=center] {\huge $1$} (17); -->
+<!-- \draw[->,black, line width=0.25mm,-latex] (8) -- node[left=3mm, align=center] {\huge $1$} (18); -->
+<!-- \end{tikzpicture} -->
+<!-- ``` -->
+
+<!-- + For states (in gray), $z = 1$ is alive, $z = 2$ is dead. -->
+
+<!-- + For observations (in white), $y = 1$ is non-detected, $y = 2$ is detected -->
+
+<!-- + Now add the states alive and dead, 1 and 2s. -->
+<!-- + The observations, non-detected and detected, 1 and 2s. -->
+<!-- + And the parameters, phi for transition from 1 to 1. -->
+<!-- + And p for prob of y being 2 detected given z is 1 alive. -->
+
+<!-- ## HMM likelihood -->
+
+<!-- + Using the formula of total probability, then the likelihood of a Markov chain: -->
+
+<!-- \begin{align*} -->
+<!-- \Pr(\mathbf{y}) &= \Pr(y_1, y_{2}, \ldots, y_T)\\ -->
+<!--                 &= \sum_{z_1} \cdots \sum_{z_T} \Pr(y_1, y_{2}, \ldots, y_T | z_1, z_{2}, \ldots, z_T) \Pr(z_1, z_{2}, \ldots, z_T)\\ -->
+<!--                 &= \sum_{z_1} \cdots \sum_{z_T} \left(\prod_{t=1}^T{\omega_{z_{t}, y_t}}\right) \left(\Pr(z_{1}) \prod_{t=2}^T{\gamma_{z_{t-1},z_{t}}}\right)\\ -->
+<!-- \end{align*} -->
+
+<!-- + What is the likelihood of a HMM. -->
+<!-- + The thing here is that we don't know the states. -->
+<!-- + So we have to go through all possibilities, and sum over the possible states. -->
+<!-- + Hence these sums here. -->
+<!-- + Then this term is the likelihood of a Markov chain, we saw that before. -->
+<!-- + And this component are the elements of the observation matrix. -->
+<!-- + The likelihood has a matrix formulation that can be useful. -->
+<!-- + It is delta, initial states, then observation, then transitions, and so on. There is a vector of ones at the end to get the sum all the terms. -->
+
+<!-- + It has a matrix formulation: -->
+<!-- \begin{align*} -->
+<!-- \Pr(\mathbf{y}) &= \mathbf{\delta} \; \mathbf{\Omega} \; \mathbf{\Gamma} \cdots \mathbf{\Omega} \; \mathbf{\Gamma} \; \mathbf{\Omega} \; \mathbb{1} -->
+<!-- \end{align*} -->
+
+<!-- ## Example -->
+
+<!-- + Let assume an animal is detected, then missed. -->
+
+<!-- + We have $\mathbf{y} = (2, 1)$. What is the contribution of this animal to the likelihood? -->
+
+<!-- \begin{align*} -->
+<!-- \Pr(\mathbf{y} = (2, 1)) &= \sum_{z_1 = 1}^2 \; \sum_{z_2 = 1}^2 w_{z_1, y_1 = 2} w_{z_2, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2} \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1, z_1, z_1, z_1)}\\ -->
+<!-- \end{align*} -->
+
+<!-- ## Example -->
+
+<!-- + Let assume an animal is detected, then missed. -->
+
+<!-- + We have $\mathbf{y} = (2, 1)$. What is the contribution of this animal to the likelihood? -->
 
-+ The neat thing with Nimble is that it provides marginalised models through nimbleEcology, we'll get back to it in Class 8.
+<!-- \begin{align*} -->
+<!-- \Pr(\mathbf{y} = (2, 1)) &= \sum_{z_1 = 1}^2 \; \sum_{z_2 = 1}^2 w_{z_1, y_1 = 2} w_{z_2, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2} \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1, z_1, z_1, z_1)}\\ -->
+<!-- &= \sum_{z_1 = 1}^2 \left( w_{z_1, y_1 = 2} w_{z_2 = 1, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2 = 1} + w_{z_1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2 = 2} \right) \\ -->
+<!-- \end{align*} -->
+
+<!-- + Let assume an animal is detected, then missed. -->
+
+<!-- + We have $\mathbf{y} = (2, 1)$. What is the contribution of this animal to the likelihood? -->
+
+<!-- \begin{align*} -->
+<!-- \Pr(\mathbf{y} = (2, 1)) &= \sum_{z_1 = 1}^2 \; \sum_{z_2 = 1}^2 w_{z_1, y_1 = 2} w_{z_2, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2} \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1, z_1, z_1, z_1)}\\ -->
+<!-- &= \sum_{z_1 = 1}^2 \left( w_{z_1, y_1 = 2} w_{z_2 = 1, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2 = 1} + w_{z_1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2 = 2} \right) \\ -->
+<!-- &= w_{z_1 = 1, y_1 = 2} w_{z_2 = 1, y_2 = 1}\delta_1 \gamma_{z_1 = 1, z_2 = 1} + w_{z_1 = 1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \delta_1 \gamma_{z_1 = 1, z_2 = 2} -->
+<!-- \end{align*} -->
+
+<!-- Note: $\Pr(z_1 = 1) = \delta_1 = 1$ and $\Pr(z_1 = 2) = 0$. -->
 
-## Our model
+<!-- + Let assume an animal is detected, then missed. -->
 
-\begin{align*}
-   z_{\text{first}} &\sim \text{Multinomial}(1, \delta) &\text{[likelihood]}\\
-   z_t | z_{t-1} &\sim \text{Multinomial}(1, \gamma_{z_{t-1},z_{t}}) &\text{[likelihood]}\\
-   y_t | z_{t} &\sim \text{Multinomial}(1, \omega_{z_{t}}) &\text{[likelihood]}\\
-  \phi &\sim \text{Beta}(1, 1) &\text{[prior for }\phi \text{]} \\
-  p &\sim \text{Beta}(1, 1) &\text{[prior for }p \text{]} \\
-\end{align*}
+<!-- + We have $\mathbf{y} = (2, 1)$. What is the contribution of this animal to the likelihood? -->
 
-+ Now our model has an observation layer for the ys, conditional on the z.
-+ And we need a prior for the detection probability.
+<!-- \begin{align*} -->
+<!-- \Pr(\mathbf{y} = (2, 1)) &= \sum_{z_1 = 1}^2 \; \sum_{z_2 = 1}^2 w_{z_1, y_1 = 2} w_{z_2, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2} \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1, z_1, z_1, z_1)}\\ -->
+<!-- &= \sum_{z_1 = 1}^2 \left( w_{z_1, y_1 = 2} w_{z_2 = 1, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2 = 1} + w_{z_1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2 = 2} \right) \\ -->
+<!-- &= w_{z_1 = 1, y_1 = 2} w_{z_2 = 1, y_2 = 1} \delta_1 \gamma_{z_1 = 1, z_2 = 1} + w_{z_1 = 1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \delta_1 \gamma_{z_1 = 1, z_2 = 2}\\ -->
+<!-- &= (1 - p) \phi + (1-\phi) -->
+<!-- \end{align*} -->
 
-## Nimble implementation
+<!-- Note: $w_{z_1 = 1, y_1 = 2} = \Pr(y_1 = 2 | z_1 = 1) = 1$ because we condition on first capture. -->
 
-+ How to implement this model in Nimble?
+<!-- ## Estimating the latent states $z$ or not? -->
 
-## Priors
-
-```{r, echo=FALSE}
-hmm.survival <- nimbleCode({
-  phi ~ dunif(0, 1) # prior survival
-  p ~ dunif(0, 1) # prior detection
-  # likelihood
-  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)
-  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)
-  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)
-  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)
-  omega[1,2] <- p        # Pr(alive t -> detected t)
-  omega[2,1] <- 1        # Pr(dead t -> non-detected t)
-  omega[2,2] <- 0        # Pr(dead t -> detected t)
-  for (i in 1:N){
-    z[i,first[i]] ~ dcat(delta[1:2])
-    for (j in (first[i]+1):T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])
-      y[i,j] ~ dcat(omega[z[i,j], 1:2])
-    }
-  }
-})
-```
-
-```{r eval=FALSE}
-hmm.survival <- nimbleCode({
-  phi ~ dunif(0, 1) # prior survival
-  p ~ dunif(0, 1) # prior detection
-...
-```
-
-## HMM ingredients
-
-```{r eval=FALSE}
-...
-  # parameters
-  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)
-  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)
-  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)
-  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)
-  omega[1,2] <- p        # Pr(alive t -> detected t)
-  omega[2,1] <- 1        # Pr(dead t -> non-detected t)
-  omega[2,2] <- 0        # Pr(dead t -> detected t)
-...
-```
-
-## Likelihood
-
-```{r eval=FALSE}
-...
-    # likelihood
-    for (i in 1:N){
-    z[i,first[i]] ~ dcat(delta[1:2])
-    for (j in (first[i]+1):T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])
-      y[i,j] ~ dcat(omega[z[i,j], 1:2])
-    }
-  }
-})
-```
-
-## Constants
-
-```{r}
-first <- apply(y, 1, function(x) min(which(x !=0)))
-my.constants <- list(N = nrow(y), T = 5, first = first)
-my.constants
-```
-
-## Data
-
-+ The data are made of 0s for non-detections and 1s for detections.
-
-+ To use the categorical distribution, we need to code 1, 2, etc. Value 0 is not accepted.
-
-+ Add 1 to get the correct format $y=1$ for non-detection and $y = 2$ for detection.
-
-```{r}
-my.data <- list(y = y + 1)
-```
-
-## Initial values
-
-```{r}
-zinits <- y + 1 # non-detection -> alive
-zinits[zinits == 2] <- 1 # dead -> alive
-initial.values <- function() list(phi = runif(1,0,1),
-                                  p = runif(1,0,1),
-                                  z = zinits)
-```
-
-## Parameters to monitor
-
-```{r}
-parameters.to.save <- c(""phi"", ""p"")
-parameters.to.save
-```
-
-## MCMC details
-
-```{r}
-n.iter <- 5000
-n.burnin <- 1000
-n.chains <- 2
-```
-
-## Run Nimble
-```{r, message=FALSE}
-mcmc.output <- nimbleMCMC(code = hmm.survival,
-                          constants = my.constants,
-                          data = my.data,
-                          inits = initial.values,
-                          monitors = parameters.to.save,
-                          niter = n.iter,
-                          nburnin = n.burnin,
-                          nchains = n.chains)
-```
-
-```{r, message=FALSE, cache = TRUE}
-mcmc.output <- nimbleMCMC(code = hmm.survival,
-                          constants = my.constants,
-                          data = my.data,
-                          inits = initial.values,
-                          monitors = parameters.to.save,
-                          niter = n.iter,
-                          nburnin = n.burnin,
-                          nchains = n.chains,
-                          progressBar = FALSE)
-```
-
-## Posterior distribution of survival
-
-```{r}
-library(MCMCvis)
-MCMCsummary(mcmc.output, round = 2)
-```
-
-The data is simulated, with true survival $\phi = 0.8$ and detection $p = 0.6$.
+<!-- + Next question is, shall we estimate the latent states or not? -->
 
+<!-- + In previous example, we got rid of the states, so that likelihood was a function of $\phi$ and $p$ only. This is the function we would maximize in a Frequentist approach. -->
+
+<!-- + The Bayesian approach with MCMC methods allows treating the latent states as if they were parameters, and to be estimated as such. -->
+
+<!-- + Infering the latent states $z$ can be useful to estimate prevalence, e.g. in animal epidemiology with [prevalence of a disease](https://veterinaryresearch.biomedcentral.com/articles/10.1186/1297-9716-45-39), in evolutionary ecology with [sex ratio](https://onlinelibrary.wiley.com/doi/abs/10.1002/cjs.5550360105) or in conservation biology with [prevalence of hybrids](https://onlinelibrary.wiley.com/doi/full/10.1002/ece3.4819?af=R). -->
+
+<!-- + Estimating the latent states is costly though, and if not required, marginalisation may speed up computations. Actually, you can estimate the states afterwards (Viterbi). -->
+
+<!-- + More about so-called marginalisation in [Yackulic et al. (2020)](https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1002/eap.2112). -->
+
+<!-- + The neat thing with Nimble is that it provides marginalised models through nimbleEcology, we'll get back to it in Class 8. -->
+
+<!-- ## Our model -->
+
+<!-- \begin{align*} -->
+<!--    z_{\text{first}} &\sim \text{Multinomial}(1, \delta) &\text{[likelihood]}\\ -->
+<!--    z_t | z_{t-1} &\sim \text{Multinomial}(1, \gamma_{z_{t-1},z_{t}}) &\text{[likelihood]}\\ -->
+<!--    y_t | z_{t} &\sim \text{Multinomial}(1, \omega_{z_{t}}) &\text{[likelihood]}\\ -->
+<!--   \phi &\sim \text{Beta}(1, 1) &\text{[prior for }\phi \text{]} \\ -->
+<!--   p &\sim \text{Beta}(1, 1) &\text{[prior for }p \text{]} \\ -->
+<!-- \end{align*} -->
 
-## Further reading
+<!-- + Now our model has an observation layer for the ys, conditional on the z. -->
+<!-- + And we need a prior for the detection probability. -->
+
+<!-- ## Nimble implementation -->
+
+<!-- + How to implement this model in Nimble? -->
+
+<!-- ## Priors -->
+
+<!-- ```{r, echo=FALSE} -->
+<!-- hmm.survival <- nimbleCode({ -->
+<!--   phi ~ dunif(0, 1) # prior survival -->
+<!--   p ~ dunif(0, 1) # prior detection -->
+<!--   # likelihood -->
+<!--   gamma[1,1] <- phi      # Pr(alive t -> alive t+1) -->
+<!--   gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1) -->
+<!--   gamma[2,1] <- 0        # Pr(dead t -> alive t+1) -->
+<!--   gamma[2,2] <- 1        # Pr(dead t -> dead t+1) -->
+<!--   delta[1] <- 1          # Pr(alive t = 1) = 1 -->
+<!--   delta[2] <- 0          # Pr(dead t = 1) = 0 -->
+<!--   omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t) -->
+<!--   omega[1,2] <- p        # Pr(alive t -> detected t) -->
+<!--   omega[2,1] <- 1        # Pr(dead t -> non-detected t) -->
+<!--   omega[2,2] <- 0        # Pr(dead t -> detected t) -->
+<!--   for (i in 1:N){ -->
+<!--     z[i,first[i]] ~ dcat(delta[1:2]) -->
+<!--     for (j in (first[i]+1):T){ -->
+<!--       z[i,j] ~ dcat(gamma[z[i,j-1], 1:2]) -->
+<!--       y[i,j] ~ dcat(omega[z[i,j], 1:2]) -->
+<!--     } -->
+<!--   } -->
+<!-- }) -->
+<!-- ``` -->
+
+<!-- ```{r eval=FALSE} -->
+<!-- hmm.survival <- nimbleCode({ -->
+<!--   phi ~ dunif(0, 1) # prior survival -->
+<!--   p ~ dunif(0, 1) # prior detection -->
+<!-- ... -->
+<!-- ``` -->
+
+<!-- ## HMM ingredients -->
+
+<!-- ```{r eval=FALSE} -->
+<!-- ... -->
+<!--   # parameters -->
+<!--   gamma[1,1] <- phi      # Pr(alive t -> alive t+1) -->
+<!--   gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1) -->
+<!--   gamma[2,1] <- 0        # Pr(dead t -> alive t+1) -->
+<!--   gamma[2,2] <- 1        # Pr(dead t -> dead t+1) -->
+<!--   delta[1] <- 1          # Pr(alive t = 1) = 1 -->
+<!--   delta[2] <- 0          # Pr(dead t = 1) = 0 -->
+<!--   omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t) -->
+<!--   omega[1,2] <- p        # Pr(alive t -> detected t) -->
+<!--   omega[2,1] <- 1        # Pr(dead t -> non-detected t) -->
+<!--   omega[2,2] <- 0        # Pr(dead t -> detected t) -->
+<!-- ... -->
+<!-- ``` -->
+
+<!-- ## Likelihood -->
+
+<!-- ```{r eval=FALSE} -->
+<!-- ... -->
+<!--     # likelihood -->
+<!--     for (i in 1:N){ -->
+<!--     z[i,first[i]] ~ dcat(delta[1:2]) -->
+<!--     for (j in (first[i]+1):T){ -->
+<!--       z[i,j] ~ dcat(gamma[z[i,j-1], 1:2]) -->
+<!--       y[i,j] ~ dcat(omega[z[i,j], 1:2]) -->
+<!--     } -->
+<!--   } -->
+<!-- }) -->
+<!-- ``` -->
+
+<!-- ## Constants -->
+
+<!-- ```{r} -->
+<!-- first <- apply(y, 1, function(x) min(which(x !=0))) -->
+<!-- my.constants <- list(N = nrow(y), T = 5, first = first) -->
+<!-- my.constants -->
+<!-- ``` -->
+
+<!-- ## Data -->
+
+<!-- + The data are made of 0s for non-detections and 1s for detections. -->
+
+<!-- + To use the categorical distribution, we need to code 1, 2, etc. Value 0 is not accepted. -->
+
+<!-- + Add 1 to get the correct format $y=1$ for non-detection and $y = 2$ for detection. -->
+
+<!-- ```{r} -->
+<!-- my.data <- list(y = y + 1) -->
+<!-- ``` -->
+
+<!-- ## Initial values -->
+
+<!-- ```{r} -->
+<!-- zinits <- y + 1 # non-detection -> alive -->
+<!-- zinits[zinits == 2] <- 1 # dead -> alive -->
+<!-- initial.values <- function() list(phi = runif(1,0,1), -->
+<!--                                   p = runif(1,0,1), -->
+<!--                                   z = zinits) -->
+<!-- ``` -->
+
+<!-- ## Parameters to monitor -->
+
+<!-- ```{r} -->
+<!-- parameters.to.save <- c(""phi"", ""p"") -->
+<!-- parameters.to.save -->
+<!-- ``` -->
+
+<!-- ## MCMC details -->
+
+<!-- ```{r} -->
+<!-- n.iter <- 5000 -->
+<!-- n.burnin <- 1000 -->
+<!-- n.chains <- 2 -->
+<!-- ``` -->
+
+<!-- ## Run Nimble -->
+<!-- ```{r, message=FALSE} -->
+<!-- mcmc.output <- nimbleMCMC(code = hmm.survival, -->
+<!--                           constants = my.constants, -->
+<!--                           data = my.data, -->
+<!--                           inits = initial.values, -->
+<!--                           monitors = parameters.to.save, -->
+<!--                           niter = n.iter, -->
+<!--                           nburnin = n.burnin, -->
+<!--                           nchains = n.chains) -->
+<!-- ``` -->
+
+<!-- ```{r, message=FALSE, cache = TRUE} -->
+<!-- mcmc.output <- nimbleMCMC(code = hmm.survival, -->
+<!--                           constants = my.constants, -->
+<!--                           data = my.data, -->
+<!--                           inits = initial.values, -->
+<!--                           monitors = parameters.to.save, -->
+<!--                           niter = n.iter, -->
+<!--                           nburnin = n.burnin, -->
+<!--                           nchains = n.chains, -->
+<!--                           progressBar = FALSE) -->
+<!-- ``` -->
+
+<!-- ## Posterior distribution of survival -->
+
+<!-- ```{r} -->
+<!-- library(MCMCvis) -->
+<!-- MCMCsummary(mcmc.output, round = 2) -->
+<!-- ``` -->
+
+<!-- The data is simulated, with true survival $\phi = 0.8$ and detection $p = 0.6$. -->
+
+<!-- <!-- heller_novel_2021 --> -->
 
-+ Zucchini, MacDonald and Langrock (2016) [Hidden Markov Models for Time Series: An Introduction Using R (2nd ed)](https://www.routledge.com/Hidden-Markov-Models-for-Time-Series-An-Introduction-Using-R-Second-Edition/Zucchini-MacDonald-Langrock/p/book/9781482253832). Chapman and Hall/CRC.
+<!-- ## Further reading -->
 
-+ McClintock, B.T., Langrock, R., Gimenez, O., Cam, E., Borchers, D.L., Glennie, R. and Patterson, T.A. (2020), [Uncovering ecological state dynamics with hidden Markov models](https://onlinelibrary.wiley.com/doi/full/10.1111/ele.13610). Ecology Letters, 23: 1878-1903.
+<!-- + Zucchini, MacDonald and Langrock (2016) [Hidden Markov Models for Time Series: An Introduction Using R (2nd ed)](https://www.routledge.com/Hidden-Markov-Models-for-Time-Series-An-Introduction-Using-R-Second-Edition/Zucchini-MacDonald-Langrock/p/book/9781482253832). Chapman and Hall/CRC. -->
 
-+  Yackulic, C. B. Dodrill, M., Dzul, M., Sanderlin, J. S., and Reid, J. A.. (2020). [A need for speed in Bayesian population models: a practical guide to marginalizing and recovering discrete latent states](https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1002/eap.2112). Ecological Applications 30:e02112.
+<!-- + McClintock, B.T., Langrock, R., Gimenez, O., Cam, E., Borchers, D.L., Glennie, R. and Patterson, T.A. (2020), [Uncovering ecological state dynamics with hidden Markov models](https://onlinelibrary.wiley.com/doi/full/10.1111/ele.13610). Ecology Letters, 23: 1878-1903. -->
 
-+ L. R. Rabiner (1989). [A tutorial on hidden Markov models and selected applications in speech recognition](https://web.ece.ucsb.edu/Faculty/Rabiner/ece259/Reprints/tutorial%20on%20hmm%20and%20applications.pdf). Proceedings of the IEEE, 77:257-286.
+<!-- +  Yackulic, C. B. Dodrill, M., Dzul, M., Sanderlin, J. S., and Reid, J. A.. (2020). [A need for speed in Bayesian population models: a practical guide to marginalizing and recovering discrete latent states](https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1002/eap.2112). Ecological Applications 30:e02112. -->
 
+<!-- + L. R. Rabiner (1989). [A tutorial on hidden Markov models and selected applications in speech recognition](https://web.ece.ucsb.edu/Faculty/Rabiner/ece259/Reprints/tutorial%20on%20hmm%20and%20applications.pdf). Proceedings of the IEEE, 77:257-286. -->
 
-@heller_novel_2021
 ",False,True,Rendering / Conversion,6
oliviergimenez,banana-book,8f4b384402650b880b3e0d3ddd66981df1137912,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2022-01-24T23:33:26Z,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2022-01-24T23:33:26Z,Issue w/ GH actions again.,docs/404.html;docs/about-the-author.html;docs/abundance.html;docs/covariates.html;docs/crashcourse.html;docs/dispersal.html;docs/faq.html;docs/hmmcapturerecapture.html;docs/hsmm.html;docs/index.html;docs/individual-dependence.html;docs/introduction-3.html;docs/introduction-4.html;docs/introduction-5.html;docs/introduction.html;docs/intronimble.html;docs/model-selection.html;docs/preface.html;docs/references.html;docs/search.json;docs/stopover.html;docs/survival.html;docs/take-home-messages.html;docs/tradeoffs.html;docs/uncertainty.html;nimble.Rmd,True,False,True,False,30,30,60,"---FILE: docs/404.html---
@@ -95,7 +95,7 @@ <h1>Page not found<a class=""anchor"" aria-label=""anchor"" href=""#page-not-found""><
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/about-the-author.html---
@@ -110,7 +110,7 @@ <h1>About the author<a class=""anchor"" aria-label=""anchor"" href=""#about-the-autho
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/abundance.html---
@@ -126,7 +126,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/covariates.html---
@@ -104,7 +104,7 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/crashcourse.html---
@@ -239,7 +239,7 @@ <h3>
 <div class=""sourceCode"" id=""cb7""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">sample_from_posterior</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Beta.html"">rbeta</a></span><span class=""op"">(</span><span class=""fl"">1000</span>, <span class=""fl"">20</span>, <span class=""fl"">39</span><span class=""op"">)</span> <span class=""co""># draw 1000 values from posterior survival beta(20,39)</span>
 <span class=""fu""><a href=""https://rdrr.io/r/base/mean.html"">mean</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span><span class=""op"">)</span> <span class=""co""># compute mean with Monte Carlo integration</span>
-<span class=""co"">## [1] 0.3405</span></code></pre></div>
+<span class=""co"">## [1] 0.3378</span></code></pre></div>
 <p>You may check that the mean we have just calculated matches closely the expectation of a beta distribution<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;If &lt;span class=""math inline""&gt;\(X\)&lt;/span&gt; is a random variable with distribution &lt;span class=""math inline""&gt;\(\text{beta}(a, b)\)&lt;/span&gt;, then &lt;span class=""math inline""&gt;\(E(X) = \displaystyle{\frac{a}{a + b}}\)&lt;/span&gt;&lt;/p&gt;'><sup>10</sup></a>:</p>
 <div class=""sourceCode"" id=""cb8""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fl"">20</span><span class=""op"">/</span><span class=""op"">(</span><span class=""fl"">20</span><span class=""op"">+</span><span class=""fl"">39</span><span class=""op"">)</span> <span class=""co""># expectation of beta(20,39)</span>
@@ -248,7 +248,7 @@ <h3>
 <div class=""sourceCode"" id=""cb9""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/r/stats/quantile.html"">quantile</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span>, probs <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/c.html"">c</a></span><span class=""op"">(</span><span class=""fl"">2.5</span><span class=""op"">/</span><span class=""fl"">100</span>, <span class=""fl"">97.5</span><span class=""op"">/</span><span class=""fl"">100</span><span class=""op"">)</span><span class=""op"">)</span>
 <span class=""co"">##   2.5%  97.5% </span>
-<span class=""co"">## 0.2296 0.4662</span></code></pre></div>
+<span class=""co"">## 0.2206 0.4549</span></code></pre></div>
 </div>
 <div id=""markov-chains"" class=""section level3"" number=""1.5.2"">
 <h3>
@@ -561,7 +561,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/dispersal.html---
@@ -1122,7 +1122,7 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/faq.html---
@@ -108,7 +108,7 @@ <h1>FAQ<a class=""anchor"" aria-label=""anchor"" href=""#faq""><i class=""fas fa-link"">
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/hmmcapturerecapture.html---
@@ -1053,7 +1053,7 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/hsmm.html---
@@ -107,7 +107,7 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/index.html---
@@ -85,7 +85,7 @@ <h1>Welcome<a class=""anchor"" aria-label=""anchor"" href=""#welcome""><i class=""fas f
 <p>This book offers a Bayesian treatment of HMMs applied to capture-recapture data. You will learn to use the R package NIMBLE which is seen by many as the future of Bayesian statistical ecology to deal with complex models and/or big data. An important part of the book consists in case studies presented in a tutorial style to abide by the ‚Äúlearning by doing‚Äù philosophy.</p>
 <p>I‚Äôm currently writing this book, and I welcome any feedback. You may raise an issue <a href=""https://github.com/oliviergimenez/banana-book/issues"">here</a>, amend directly the R Markdown file that generated the page you‚Äôre reading by clicking on the ‚ÄòEdit this page‚Äô icon in the right panel, or <a href=""mailto:olivier.gimenez@cefe.cnrs.fr"">email me</a>. Many thanks!</p>
 <p>Olivier Gimenez, Montpellier, France<br>
-Last updated: January 24, 2022</p>
+Last updated: January 25, 2022</p>
 <div id=""license"" class=""section level2 unnumbered"">
 <h2>License<a class=""anchor"" aria-label=""anchor"" href=""#license""><i class=""fas fa-link""></i></a>
 </h2>
@@ -119,7 +119,7 @@ <h2>License<a class=""anchor"" aria-label=""anchor"" href=""#license""><i class=""fas f
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/individual-dependence.html---
@@ -123,7 +123,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/introduction-3.html---
@@ -103,7 +103,7 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-3""><i
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/introduction-4.html---
@@ -103,7 +103,7 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-4""><i
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/introduction-5.html---
@@ -103,7 +103,7 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-5""><i
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/introduction.html---
@@ -103,7 +103,7 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction""><i cl
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/intronimble.html---
@@ -174,7 +174,7 @@ <h3>
 <span class=""fu"">initial.values</span><span class=""op"">(</span><span class=""op"">)</span>
 <span class=""co"">## $theta</span>
 <span class=""co"">## [1] 0.2046</span></code></pre></div>
-<p>Firth and last step, you need to tell NIMBLE the number of chains to run <code>n.chain</code>, how long the burn-in period should be <code>n.burnin</code> and the number of iterations to be used for posterior inference, that is following the burn-in period. In NIMBLE, you specify the total number of iterations <code>n.iter</code>, so that the number of posterior samples per chain is <code>n.iter - n.burnin</code>. <strong>To be smoothed: these are R objects, not nimbleMCMC() arguments; also thinning in the formula, but by default is 1 and we do not use it, so just ignore.</strong></p>
+<p>Firth and last step, you need to tell NIMBLE the number of chains to run <code>n.chain</code>, how long the burn-in period should be <code>n.burnin</code> and the number of iterations to be used for posterior inference, that is following the burn-in period. In NIMBLE, you specify the total number of iterations <code>n.iter</code>, so that the number of posterior samples per chain is <code>n.iter - n.burnin</code>. <strong>To be smoothed, these are R objects, not nimbleMCMC() arguments; also thinning in the formula, but by default is 1 and we do not use it, so just ignore.</strong></p>
 <div class=""sourceCode"" id=""cb24""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">n.iter</span> <span class=""op"">&lt;-</span> <span class=""fl"">5000</span>
 <span class=""va"">n.burnin</span> <span class=""op"">&lt;-</span> <span class=""fl"">1000</span>
@@ -717,7 +717,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/model-selection.html---
@@ -107,7 +107,7 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/preface.html---
@@ -192,7 +192,7 @@ <h2>How this book was written<a class=""anchor"" aria-label=""anchor"" href=""#how-th
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/references.html---
@@ -222,7 +222,7 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/stopover.html---
@@ -105,7 +105,7 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/survival.html---
@@ -991,7 +991,7 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/take-home-messages.html---
@@ -176,7 +176,7 @@ <h1>Take-home messages<a class=""anchor"" aria-label=""anchor"" href=""#take-home-mes
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/tradeoffs.html---
@@ -148,7 +148,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/uncertainty.html---
@@ -1130,7 +1130,7 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-24.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</strong>: Theory and Case Studies in R"" was written by Olivier Gimenez. It was last built on 2022-01-25.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: nimble.Rmd---
@@ -88,7 +88,7 @@ initial.values <- function() list(theta = runif(1,0,1))
 initial.values()
 ```
 
-Firth and last step, you need to tell NIMBLE the number of chains to run `n.chain`, how long the burn-in period should be `n.burnin` and the number of iterations to be used for posterior inference, that is following the burn-in period. In NIMBLE, you specify the total number of iterations `n.iter`, so that the number of posterior samples per chain is `n.iter - n.burnin`. **To be smoothed: these are R objects, not nimbleMCMC() arguments; also thinning in the formula, but by default is 1 and we do not use it, so just ignore.**
+Firth and last step, you need to tell NIMBLE the number of chains to run `n.chain`, how long the burn-in period should be `n.burnin` and the number of iterations to be used for posterior inference, that is following the burn-in period. In NIMBLE, you specify the total number of iterations `n.iter`, so that the number of posterior samples per chain is `n.iter - n.burnin`. **To be smoothed, these are R objects, not nimbleMCMC() arguments; also thinning in the formula, but by default is 1 and we do not use it, so just ignore.**
 ```{r}
 n.iter <- 5000
 n.burnin <- 1000",False,True,Implementation / Logic,6
oliviergimenez,banana-book,61b5e06881c0abd837e0f3b135db73beddba6c61,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2022-01-24T20:09:46Z,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2022-01-24T20:09:46Z,Sort out issue w/ GH action.,_common.R;docs/crashcourse.html;docs/intronimble.html;docs/search.json;nimble.Rmd,True,True,True,False,8,7,15,"---FILE: _common.R---
@@ -6,6 +6,7 @@ library(MCMCvis)
 library(magick)
 library(pdftools)
 library(wesanderson)
+library(basicMCMCplots)
 
 # R options
 options(width = 60)

---FILE: docs/crashcourse.html---
@@ -239,7 +239,7 @@ <h3>
 <div class=""sourceCode"" id=""cb7""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">sample_from_posterior</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Beta.html"">rbeta</a></span><span class=""op"">(</span><span class=""fl"">1000</span>, <span class=""fl"">20</span>, <span class=""fl"">39</span><span class=""op"">)</span> <span class=""co""># draw 1000 values from posterior survival beta(20,39)</span>
 <span class=""fu""><a href=""https://rdrr.io/r/base/mean.html"">mean</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span><span class=""op"">)</span> <span class=""co""># compute mean with Monte Carlo integration</span>
-<span class=""co"">## [1] 0.3389</span></code></pre></div>
+<span class=""co"">## [1] 0.3394</span></code></pre></div>
 <p>You may check that the mean we have just calculated matches closely the expectation of a beta distribution<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;If &lt;span class=""math inline""&gt;\(X\)&lt;/span&gt; is a random variable with distribution &lt;span class=""math inline""&gt;\(\text{beta}(a, b)\)&lt;/span&gt;, then &lt;span class=""math inline""&gt;\(E(X) = \displaystyle{\frac{a}{a + b}}\)&lt;/span&gt;&lt;/p&gt;'><sup>10</sup></a>:</p>
 <div class=""sourceCode"" id=""cb8""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fl"">20</span><span class=""op"">/</span><span class=""op"">(</span><span class=""fl"">20</span><span class=""op"">+</span><span class=""fl"">39</span><span class=""op"">)</span> <span class=""co""># expectation of beta(20,39)</span>
@@ -248,7 +248,7 @@ <h3>
 <div class=""sourceCode"" id=""cb9""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/r/stats/quantile.html"">quantile</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span>, probs <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/c.html"">c</a></span><span class=""op"">(</span><span class=""fl"">2.5</span><span class=""op"">/</span><span class=""fl"">100</span>, <span class=""fl"">97.5</span><span class=""op"">/</span><span class=""fl"">100</span><span class=""op"">)</span><span class=""op"">)</span>
 <span class=""co"">##   2.5%  97.5% </span>
-<span class=""co"">## 0.2161 0.4625</span></code></pre></div>
+<span class=""co"">## 0.2293 0.4585</span></code></pre></div>
 </div>
 <div id=""markov-chains"" class=""section level3"" number=""1.5.2"">
 <h3>

---FILE: docs/intronimble.html---
@@ -571,7 +571,7 @@ <h3>
 <span class=""fu""><a href=""https://rdrr.io/pkg/nimble/man/nimble-internal.html"">samplesSummary</a></span><span class=""op"">(</span><span class=""va"">samples</span><span class=""op"">)</span>
 <span class=""co"">##         Mean Median St.Dev. 95%CI_low 95%CI_upp</span>
 <span class=""co"">## theta 0.3309 0.3306 0.05987    0.2149    0.4549</span>
-<span class=""fu"">basicMCMCplots</span><span class=""fu"">::</span><span class=""fu""><a href=""https://rdrr.io/pkg/basicMCMCplots/man/chainsPlot.html"">chainsPlot</a></span><span class=""op"">(</span><span class=""va"">samples</span><span class=""op"">)</span></code></pre></div>
+<span class=""fu"">chainsPlot</span><span class=""op"">(</span><span class=""va"">samples</span><span class=""op"">)</span></code></pre></div>
 <div class=""inline-figure""><img src=""banana-book_files/figure-html/unnamed-chunk-67-1.png"" width=""672""></div>
 <p>Change parameter to tune.</p>
 <div class=""sourceCode"" id=""cb54""><pre class=""downlit sourceCode r"">
@@ -603,7 +603,7 @@ <h3>
 <span class=""fu""><a href=""https://rdrr.io/pkg/nimble/man/nimble-internal.html"">samplesSummary</a></span><span class=""op"">(</span><span class=""va"">samples</span><span class=""op"">)</span>
 <span class=""co"">##         Mean Median St.Dev. 95%CI_low 95%CI_upp</span>
 <span class=""co"">## theta 0.3287 0.3248 0.05794    0.2282    0.4475</span>
-<span class=""fu"">basicMCMCplots</span><span class=""fu"">::</span><span class=""fu""><a href=""https://rdrr.io/pkg/basicMCMCplots/man/chainsPlot.html"">chainsPlot</a></span><span class=""op"">(</span><span class=""va"">samples</span><span class=""op"">)</span></code></pre></div>
+<span class=""fu"">chainsPlot</span><span class=""op"">(</span><span class=""va"">samples</span><span class=""op"">)</span></code></pre></div>
 <div class=""inline-figure""><img src=""banana-book_files/figure-html/unnamed-chunk-68-1.png"" width=""672""></div>
 <p>Draw parallel with previous chapter.</p>
 </div>

---FILE: nimble.Rmd---
@@ -458,7 +458,7 @@ out <- compileNimble(list(model = Rmodel, mcmc = Rmcmc))
 Cmcmc <- out$mcmc
 samples <- runMCMC(Cmcmc, niter = 5000, nburnin = 1000)
 samplesSummary(samples)
-basicMCMCplots::chainsPlot(samples)
+chainsPlot(samples)
 ```
 
 Change parameter to tune.
@@ -477,7 +477,7 @@ out <- compileNimble(list(model = Rmodel, mcmc = Rmcmc))
 Cmcmc <- out$mcmc
 samples <- runMCMC(Cmcmc, niter = 5000, nburnin = 1000)
 samplesSummary(samples)
-basicMCMCplots::chainsPlot(samples)
+chainsPlot(samples)
 ```
 
 Draw parallel with previous chapter. ",True,True,Rendering / Conversion,3
oliviergimenez,banana-book,096f7954d9ee8c4f752090971cb3f297516b3d9a,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2021-09-20T12:13:23Z,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2021-09-20T12:13:23Z,Bayes & MCMC chapter back in. Some typos fixed.,_bookdown_files/banana-book_files/figure-html/burnin-1.png;_bookdown_files/banana-book_files/figure-html/chain-1.png;bayesmcmc-draft.Rmd;bayesmcmc.Rmd;bayesmcmcdraft.Rmd;docs/404.html;docs/about-the-author.html;docs/abundance.html;docs/banana-book_files/figure-html/burnin-1.png;docs/banana-book_files/figure-html/chain-1.png;docs/covariates.html;docs/crashcourse.html;docs/dispersal.html;docs/faq.html;docs/hmmcapturerecapture.html;docs/hsmm.html;docs/index.html;docs/individual-dependence.html;docs/introduction-2.html;docs/introduction-3.html;docs/introduction-4.html;docs/introduction.html;docs/intronimble.html;docs/model-selection.html;docs/preface.html;docs/reference-keys.txt;docs/references.html;docs/search.json;docs/stopover.html;docs/survival.html;docs/take-home-messages.html;docs/tradeoffs.html;docs/uncertainty.html,True,False,True,False,1965,799,2764,"---FILE: bayesmcmc-draft.Rmd---
@@ -1,660 +0,0 @@
-# Bayesian statistics & MCMC {#crashcourse}
-
-## Introduction
-
-In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to implement the Bayesian method for more complex analyses. This is not an exhaustive treatment of Bayesian statistics, but you should get what you need to navigate through the rest of the book. 
-
-## Bayes' theorem
-
-Let's not wait any longer and jump into it. Bayesian statistics relies on the Bayes' theorem (or law, or rule, whatever you prefer) named after Reverend Thomas Bayes (Figure \@ref(fig:revbayes)). This theorem was published in 1763 two years after Bayes' death thanks to his friend's efforts Richard Price, and was independently discovered by Pierre-Simon Laplace [@mcgrayne2011]. 
-
-```{r revbayes, echo = FALSE, fig.align=""center"", out.width=""100%"", fig.cap = ""Cartoon of Thomas Bayes with Bayes' theorem in background. Source: [James Kulich](https://www.elmhurst.edu/blog/thomas-bayes/)""}
-knitr::include_graphics(""images/amazing-thomas-bayes-illustration.jpg"")
-```
-
-As we will see in a minute, Bayes' theorem is all about conditional probabilities, which are somehow tricky to understand. Conditional probability of outcome or event A given event B, which we denote $\Pr(A \mid B)$, is the probability that A occurs, revised by considering the additional information that event B has definitely occurred.^[For example, a friend of yours rolls a fair dice and asks you the probability that the outcome was a six (event A). Your answer is 1/6 because each side of the dice is equally likely to come up. Now imagine that you're told the number rolled was even (event B) before you answer your friend's question. Because there are only three even numbers, one of which is six, you may revise your answer for the probability that a six was rolled from 1/6 to $\Pr(A \mid B) = 1/3$.] The order in which A and B appear is important, make sure you do not confuse $\Pr(A \mid B)$ and $\Pr(B \mid A)$.
-
-Bayes' theorem (Figure \@ref(fig:bayestheorem)) gives you $\Pr(A \mid B)$ using marginal probabilities $\Pr(A)$ and $\Pr(B)$ and $\Pr(B \mid A)$:
-$$\Pr(A \mid B) = \displaystyle{\frac{ \Pr(B \mid A) \; \Pr(A)}{\Pr(B)}}.$$
-Originally, Bayes' theorem was seen as a way to infer an unkown cause A of a particular effect B, knowing the probability of effect B given cause A. Think for example of a situation where a medical diagnosis is needed, with A an unkown disease and B symptoms, the doctor knows P(symptoms|disease) and wants to derive P(disease|symptoms). This way of reversing $\Pr(B \mid A)$ into $\Pr(A \mid B)$ explains why Bayesian thinking used to be referred to as 'inverse probability'. 
-
-```{r bayestheorem, echo = FALSE, fig.align=""center"", fig.cap = ""Bayes' theorem spelt out in blue neon at the offices of Autonomy in Cambridge. Source: [Wikipedia](https://en.wikipedia.org/wiki/Bayes%27_theorem)""}
-knitr::include_graphics(""images/bayes_neon.jpeg"")
-```
-
-I don't know about you, but I need to think twice for not messing the letters around. I find it easier to remember Bayes' theorem written like this^[When teaching Bayes' theorem, I am very much inspired by Tristan Mahr's slides from his introduction to Bayesian regression https://www.tjmahr.com/bayes-intro-lecture-slides-2017/]:
-
-$$ \Pr(\text{hypothesis} \mid \text{data}) = \frac{ \Pr(\text{data} \mid \text{hypothesis}) \; \Pr(\text{hypothesis})}{\Pr(\text{data})} $$
-The *hypothesis* is a working assumption about which you want to learn using *data*. In capture-recapture analyses, the hypothesis might be a parameter like detection probability, or regression parameters in a relationship between survival probability and a covariate. Bayes' theorem tells us how to obtain the probability of a hypothesis given the data we have. This is great because think about it, this is exactly what the scientific method is! We'd like to know how plausible some hypothesis is based on some data we collected, and possibly compare several hypotheses among them. In that respect, the Bayesian reasoning matches the scientific reasoning, which probably explains why the Bayesian framework is so natural for doing and understanding statistics. 
-
-You might ask then, why is Bayesian statistics not the default in statistics? Clearly, because of futile wars between male statisticians (including Ronald Fisher, Jerzy Neyman and Egon Sharpe Pearson among others), little progress was made for over two centuries. Also, until recently, there were practical problems to implement Bayes' theorem. Recent advances in computational power coupled with the development of new algorithms have led to a great increase in the application of Bayesian methods within the last three decades.
-
-## What is the Bayesian approach?	
-
-Typical statistical problems involve estimating a parameter (or several parameters) $\theta$ with available data. To do so, you might be more used to the frequentist rather than the Bayesian method. The frequentist approach, and in particular maximum likelihood estimation (MLE), assumes that the parameters are fixed, and have unknown values to be estimated. Therefore classical estimates are generally point estimates of the parameters of interest. In contrast, the Bayesian approach assumes that the parameters are not fixed but have some fixed unknown distribution^[A probability distribution is a mathematical expression that gives the probability for a random variable to take particular values. A probability distribution may be either discrete (e.g., the Bernoulli, Binomial or Poisson distribution) or continuous (e.g., the Gaussian distribution also known as the normal distribution)] -- a distribution for the parameter.
-
-The Bayesian approach is based upon the idea that you, the experimenter, begin with some prior beliefs about the system. Then you collect data and update your prior beliefs on the basis of observations. These observations might arise from field work, lab work or from expertise of your esteemed colleagues. This updating process is based upon Bayes' theorem which we've seen earlier. Loosely, let's say $A = \theta$ and $B = \text{data}$, then Bayes' theorem gives you a way to estimate parameter $\theta$ given the data you have:
-
-$${\color{red}{\Pr(\theta \mid \text{data})}} = \frac{\color{blue}{\Pr(\text{data} \mid \theta)} \times \color{green}{\Pr(\theta)}}{\color{orange}{\Pr(\text{data})}}.$$
-Let's spend some time going through each quantity in this formula. 
-
-On the left-hand side is the $\color{red}{\text{posterior distribution}}$. It represents what you know after having seen the data. This is the basis for inference and clearly what you're after, a distribution, possibly multivariate if you have more than one parameter. 
-
-On the right-hand side, there is the $\color{blue}{\text{likelihood}}$. This quantity is the same as in the MLE approach. Yes, the Bayesian and frequentist approaches have the same likelihood at their core, which mostly explains why results often do not differ much. The likelihood captures the information you have in your data, given a model parameterized with $\theta$. 
-
-Then we have the $\color{green}{\text{prior distribution}}$. This quantity represents what you know before seeing the data. This is the source of much discussion about the Bayesian approach. It may be vague if you don't know anything about $\theta$. Usually however, you never start from scratch, and you'd like your prior to reflect some information you have^[Shall I include a section on sensitivity analyses in this chapter or later in the book? Cross-reference section in Survival chapter where prior elicitation is covered.].
-
-Last, we have $\color{orange}{\Pr(\text{data})}$ which is sometimes called the average likelihood because it is obtained by integrating the likelihood with respect to the prior $\color{orange}{\Pr(\text{data}) = \int{L(\text{data} \mid \theta)\Pr(\theta) d\theta}}$ so that the posterior is standardized, that is it integrates to one for the posterior to be a distribution. The average likelihood is an integral with dimension the number of parameters $\theta$ you need to estimate. This quantity is difficult, if not impossible, to calculate in general. This is one of the reasons why the Bayesian method wasn't used until recently, and why we need algorithms to estimate posterior distributions as I illustrate in the next section.
-
-## Approximating posteriors via numerical integration {#numerical-approx}
-
-Let's take an example to illustrate Bayes' theorem. Say we capture, mark and release $n = 57$ animals at the beginning of a winter, out of which we recapture $y = 19$ animals alive^[We used a similar example in @king_bayesian_2009]. We'd like to estimate winter survival $\theta$.
-```{r}
-y <- 19 # nb of success
-n <- 57 # nb of attempts
-```
-
-We build our model first. Assuming all animals are independent of each other and have the same survival probability, then $y$ the number of alive animals at the end of the winter is a binomial distribution^[I follow @mcelreathbook and use labels on the right to help remember what each line is about.] with $n$ trials and $\theta$ the probability of success:
-  
-\begin{align*}
-y &\sim \text{Binomial}(n, \theta) &\text{[likelihood]}
-\end{align*}
-
-This likelihood can be visualised in `R`: 
-```{r binlik, echo = TRUE, fig.cap = ""Binomial likelihood with $n = 57$ released animals and $y = 19$ survivors after winter. The value of survival (on the x-axis) that corresponds to the maximum of the likelihood function (on the y-axis) is the MLE, or the proportion of success in this example, close to 0.33.""}
-grid <- seq(0, 1, 0.01) # grid of values for survival
-likelihood <- dbinom(y, n, grid) # compute binomial likelihood
-df <- data.frame(survival = grid, likelihood = likelihood) 
-df %>%
-  ggplot() + 
-  aes(x = survival, y = likelihood) + 
-  geom_line(size = 1.5)
-```
-
-Besides the likelihood, priors are another component of the model in the Bayesian approach. For a parameter that is a probability, the one thing we know is that the prior should be a continuous random variable that lies between 0 and 1. To reflect that, we often go for the uniform distribution $U(0,1)$ to imply *vague* priors. Here vague means that survival has, before we see the data, the same probability of falling between 0.1 and 0.2 and between 0.8 and 0.9, for example. 
-
-\begin{align*}
-\theta &\sim \text{Uniform}(0, 1) &\text{[prior for }\theta \text{]}
-\end{align*}
-
-```{r, echo = FALSE}
-a <- 1; b <- 1; grid <- seq(0,1,0.01); prior <- dbeta(grid,a,b)
-dfprior <- data.frame(survival = grid, prior = prior) 
-#dfprior %>%
-#  ggplot() + 
-#  geom_line(aes(x = p, y = prior), 
-#            size = 1.5,
-#            color = wesanderson::wes_palettes$Royal1[1])
-#plot(p, dbeta(p,a,b), type='l', lwd=3)
-```
-
-Now we apply Bayes' theorem. We write a `R` function that computes the product of the likelihood times the prior, or the numerator in Bayes' theorem: $\Pr(\text{data} \mid \theta) \times \Pr(\theta)$
-```{r}
-numerator <- function(theta) dbinom(y, n, theta) * dunif(theta, 0, 1)
-```
-
-We write another function that calculates the denominator, the average likelihood: $\Pr(\text{data}) = \int{L(\theta \mid \text{data}) \Pr(\theta) d\theta}$
-```{r}
-denominator <- integrate(numerator,0,1)$value
-```
-
-We use the `R` function `integrate` to calculate the integral in the denominator, which implements quadrature techniques to divide in little squares the area underneath the curve delimited by the function to integrate (here the numerator), and count them.
-
-Then we get a numerical approximation of the posterior in Figure \@ref(fig:numapprox) by applying Bayes' theorem. 
-```{r numapprox, echo = TRUE, fig.cap = ""Winter survival posterior distribution obtained by numerical integration.""}
-grid <- seq(0, 1, 0.01) # grid of values for theta
-numerical_posterior <- data.frame(survival = grid, 
-                                  posterior = numerator(grid)/denominator) # Bayes' theorem
-numerical_posterior %>%
-  ggplot() +
-  aes(x = survival, y = posterior) + 
-  geom_line(size = 1.5)
-```
-
-How good is our numerical approximation of survival posterior distribution? Ideally, we would want to compare the approximation to the true posterior distribution. Although a closed-form expression for the posterior distribution is in general intractable, when you combine a binomial likelihood together with a beta distribution as a prior, then the posterior distribution is also a beta distribution, which makes it amenable to all sorts of exact calculations^[We say that the beta distribution is the conjugate prior distribution for the binomial distribution.]. The beta distribution is continuous between 0 and 1, and extends the uniform distribution to situations where not all outcomes are equally likely. It has two parameters $a$ and $b$ that control its shape (Figure \@ref(fig:betadistribution)).
-
-(ref:captionbeta) The distribution beta($a$,$b$) for different values of $a$ and $b$. Note that for $a = b = 1$, we get the uniform distribution between 0 and 1, see top left panel. When $a$ and $b$ are equal, the distribution is symmetric, and the bigger $a$ and $b$, the more peaked the distribution or the smaller the variance. 
-
-```{r betadistribution, echo = FALSE, fig.cap='(ref:captionbeta)'}
-x <- seq(0, 1, length=200)
-par(mfrow = c(2,3))
-# distribution a posteriori beta
-plot(x,dbeta(x, 1, 1),type='l',xlab='',ylab='Density',main='beta(1,1)',lwd=3,col='black',ylim=c(0,1.5))
-plot(x,dbeta(x, 2, 1),type='l',xlab='',ylab='',main='beta(2,1)',lwd=3,col='black',ylim=c(0,2))
-plot(x,dbeta(x, 1, 2),type='l',xlab='',ylab='',main='beta(1,2)',lwd=3,col='black',ylim=c(0,2))
-plot(x,dbeta(x, 2, 2),type='l',xlab='',ylab='Density',main='beta(2,2)',lwd=3,col='black',ylim=c(0,1.5))
-plot(x,dbeta(x, 10, 10),type='l',xlab='',ylab='',main='beta(10,10)',lwd=3,col='black',ylim=c(0,3.5))
-plot(x,dbeta(x, 0.8, 0.8),type='l',xlab='',ylab='',main='beta(0.8,0.8)',lwd=3,col='black',ylim=c(0.5,2.5))
-```
-
-If the likelihood of the data $y$ is binomial with $n$ trials and probability of success $\theta$, and the prior is a beta distribution with parameters $a$ and $b$, then the posterior is a beta distribution with parameters $a + y$ and $b + n - y$^[**provide a sketch of the proof**]. In our example, we have $n = 57$ trials and $y = 19$ animals that survived and a uniform prior between 0 and 1 or a beta distribution with parameters $a = b = 1$, therefore survival has a beta posterior distribution with parameters 20 and 39. In Figure \@ref(fig:compar), we superimpose the exact posterior and the numerical approximation. Clearly, the two distributions are indistinguishable, suggesting that the numerical approximation is more than fine. 
-```{r compar, echo = FALSE, fig.cap = ""Comparison of exact (dashed line) vs. numerical approximation (continuous line) of winter survival posterior distribution.""}
-explicit_posterior <- dbeta(grid, y + a, n - y + b)
-dfexpposterior <- data.frame(survival = grid, explicit_posterior = explicit_posterior)
-ggplot() + 
-  geom_line(data = numerical_posterior, 
-            aes(x = survival, y = posterior), 
-            size = 1.5, 
-            col = wesanderson::wes_palettes$Royal1[2],
-            alpha = 0.5) + 
-  geom_line(data = dfexpposterior, 
-            aes(x = survival, y = explicit_posterior),
-            size = 1.5, 
-            col = wesanderson::wes_palettes$Royal1[3], 
-            linetype = ""dashed"")
-```
-
-<!-- To finish up, let's add the prior.  -->
-<!-- ```{r, echo = FALSE} -->
-<!-- ggplot() +  -->
-<!--   geom_line(data = numerical_posterior,  -->
-<!--             aes(x = survival, y = posterior),  -->
-<!--             size = 1.5,  -->
-<!--             col = wesanderson::wes_palettes$Royal1[2],  -->
-<!--             alpha = 0.5) +  -->
-<!--   geom_line(data = dfexpposterior,  -->
-<!--             aes(x = survival, y = explicit_posterior), -->
-<!--             col = wesanderson::wes_palettes$Royal1[3],  -->
-<!--             size = 1.5,  -->
-<!--             linetype = ""dashed"") +  -->
-<!--   geom_line(data = dfprior, -->
-<!--             aes(x = survival, y = prior), -->
-<!--             col = wesanderson::wes_palettes$Royal1[1], -->
-<!--             size = 1.5) -->
-<!-- ``` -->
-
-In our example, we have a single parameter to estimate, winter survival. This means dealing with a one-dimensional integral in the denominator which is pretty easy with quadrature techniques and the `R` function `integrate()`. Now what if we had multiple parameters? For example, let's imagine you'd like to fit a capture-recapture model with detection probability $p$ and regression parameters $\alpha$ and $\beta$ for the intercept and slope of a relationship between survival probability and a covariate, then Bayes' theorem gives you the posterior distribution of all three parameters together:
-
-$$ \Pr(\alpha, \beta, p \mid \text{data}) = \frac{ \Pr(\text{data} \mid \alpha, \beta, p) \times \Pr(\alpha, \beta, p)}{\iiint \, \Pr(\text{data} \mid \alpha, \beta, p) \Pr(\alpha, \beta, p) d\alpha d\beta dp} $$
-There are two computational challenges with this formula. First, do we really wish to calculate a three-dimensional integral? The answer is no, one-dimensional and two-dimensional integrals are so much further we can go with standard methods. Second, we're more interested in a posterior distribution for each parameter separately than the joint posterior distribution. The so-called marginal distribution of $p$ for example is obtained by integrating over all the other parameters -- a two-dimensional integral in this example. Now imagine with tens or hundreds of parameters to estimate, these integrals become highly multi-dimensional and simply intractable. In the next section, I introduce powerful simulation methods to circumvent this issue. 
-
-## Markov chain Monte Carlo (MCMC)
-
-In the early 1990s, statisticians rediscovered work from the 1950's in physics. In a famous paper that would lay the fundations of modern Bayesian statistics (see Figure \@ref(fig:mcmcpaper)), the authors use simulations to approximate posterior distributions with some precision by drawing large samples. This is a neat trick to avoid explicit calculation of the multi-dimensional integrals we struggle with when using Bayes' theorem. 
-
-```{r mcmcpaper, echo = FALSE, fig.align='center', fig.cap = ""MCMC article cover. Source: [The Journal of Chemical Physics](https://aip.scitation.org/doi/10.1063/1.1699114)""}
-knitr::include_graphics(""images/metropolis.png"")
-```
-
-These simulation algorithms are called Markov chain Monte Carlo (MCMC), and they definitely gave a boost to Bayesian statistics. There are two parts in MCMC, Markov chain and Monte Carlo, let's try and make sense of these terms. 
-
-### Monte Carlo integration
-
-What does Monte Carlo stand for? Monte Carlo integration is a simulation technique to calculate integrals of any function $f$ of random variable $X$ with distribution $\Pr(X)$, say $\int f(X) \Pr(X)dX$. You draw values $X_1,\ldots,X_k$ from $\Pr(X)$ the distribution of $X$, apply function $f$ to these values, then calculate the mean of these new values $\displaystyle{\frac{1}{k}}\sum_{i=1}^k{f(X_i)}$ to approximate the integral. How is Monte Carlo integration used in a Bayesian context? The posterior distribution contains all the information we need about the parameter to be estimated. When dealing with many parameters however, you may want to summarise posterior results by calculating numerical summaries. The simplest numerical summary is the mean of the posterior distribution, $E(\theta) = \int \theta \Pr(\theta|\text{data})$, where $X$ is $\theta$ now and $f$ is the identity function, which can be calculated with Monte Carlo integration:
-```{r}
-sample_from_posterior <- rbeta(1000, 20, 39) # draw 1000 values from posterior survival beta(20,39)
-mean(sample_from_posterior) # compute mean with Monte Carlo integration
-```
-
-You may check that the mean we have just calculated matches the expectation of a beta distribution^[If $X$ is a random variable with distribution $\text{beta}(a, b)$, then $E(X) = \displaystyle{\frac{a}{a + b}}$]:
-```{r}
-20/(20+39) # expectation of beta(20,39)
-```
-
-Another useful numerical summary is the credible interval within which our parameter falls with some probability, usually 0.95 hence a 95$\%$ credible interval. Finding the bounds of a credible interval requires calculating quantiles, which in turn involves integrals and the use of Monte Carlo integration. A 95$\%$ credible interval for winter survival can be obtained in `R` with:
-```{r}
-quantile(sample_from_posterior, probs = c(2.5/100, 97.5/100))
-```
-
-### Markov chains
-
-What is a Markov chain? A Markov chain is a random sequence of numbers, in which each number depends only on the previous number. An example is the weather in my home town in Southern France, Montpellier, in which a sunny day is most likely to be followed by another sunny day, say with probability 0.8, and a rainy day is rarely followed by another rainy day, say with probability 0.1. The dynamic of this Markov chain is captured by the transition matrix $\mathbf{\Gamma}$:
-$$
-\begin{matrix}
-& \\
-\mathbf{\Gamma} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    \text{sunny tomorrow} & \text{rainy tomorrow} \\ 
-0.8 & 0.2 \\ 
-0.9 & 0.1 \\ 
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    \text{sunny today} \\ \text{rainy today}
-    \end{matrix}
-\end{matrix}
-$$
-Under certain conditions^[The Markov chain is irreducible and aperiodic.], a Markov chain will converge to a unique stationary distribution. In our weather example, let's run the Markov chain for 20 steps:
-```{r}
-weather <- matrix(c(0.8, 0.2, 0.9, 0.1), nrow = 2, byrow = T) # transition matrix
-steps <- 20
-for (i in 1:steps){
-  weather <- weather %*% weather # matrix multiplication
-}
-round(weather, 2) # matrix product after 20 steps
-```
-
-Each row of the transition matrix converges to the same distribution $(0.82, 0.18)$ as the number of steps increases. Convergence happens no matter which state you start in, and you always have probability 0.82 of the day being sunny and 0.18 of the day being rainy. 
-
-Back to MCMC, the core idea is that you can build a Markov chain with a given stationary distribution set to be the desired posterior distribution. 
-
-Putting Monte Carlo and Markov chains together, MCMC allows us to generate a sample of values whose distribution converges to the posterior distribution (Markov chain), and we can use this sample of values to calculate any posterior summaries (Monte Carlo), such as posterior means and credible intervals. 
- 
-### Metropolis algorithm {#metropolis-algorithm}
-
-There are several ways of constructing Markov chains for Bayesian inference^[You might have heard about the Metropolis-Hastings or the Gibbs sampler. Have a look to <https://github.com/chi-feng/mcmc-demo> for an interactive gallery of MCMC algorithms.]. Here I illustrate the Metropolis algorithm and how to implement it in practice^[This presentation is largely inspired by @alberthu2019].
-
-Let's go back to our example on animal survival estimation. We illustrate sampling from survival posterior distribution. We write functions for likelihood, prior and posterior.
-
-```{r}
-# 19 animals recaptured alive out of 57 captured, marked and released
-survived <- 19
-released <- 57
-
-# binomial log-likelihood function
-loglikelihood <- function(x, p){
-  dbinom(x = x, size = released, prob = p, log = TRUE)
-}
-
-# uniform prior density
-logprior <- function(p){
-  dunif(x = p, min = 0, max = 1, log = TRUE)
-}
-
-# posterior density function (log scale)
-posterior <- function(x, p){
-  loglikelihood(x, p) + logprior(p) # - log(Pr(data))
-}
-```
-
-The Metropolis algorithm works as follows: 
-  
-1. We pick a value of the parameter to be estimated. This is where we start our Markov chain -- this is a *starting* value. 
-
-2. To decide where to go next, we propose to move away from the current value of the parameter -- this is a *candidate* value. To do so, we add to the current value some random value from e.g. a normal distribution with some variance -- this is a *proposal* distribution. The Metropolis algorithm is a particular case of the Metropolis-Hastings algorithm with symmetric proposals.
-  
-3. We compute the ratio of the probabilities at the candidate and current locations $R=\displaystyle{\frac{{\Pr(\text{candidate}|\text{data})}}{{\Pr(\text{current}|\text{data})}}}$ -- *the Hastings ratio*. This is where the magic of MCMC happens, in that $\Pr(\text{data})$, the denominator in the Bayes' theorem, appears in both the numerator and the denominator in $R$ therefore cancels out and does not need to be calculated. 
-
-4. If the posterior at the candidate location $\Pr(\text{candidate}|\text{data})$ is higher than at the current location $\Pr(\text{current}|\text{data})$, or when the candidate value is more plausible than the current value, we will definitely accept the candidate value. If not, then we will accept the candidate value with probability $R$ and reject with probability $1-R$. For example, if the candidate value is ten times less plausible than the current value, then we accept with probability 0.1 and reject with probability 0.9. How does it work in practice? We use a continuous spinner that lands somewhere between 0 and 1 -- call the random spin $X$. If $X$ is smaller than $R$, we move to the candidate location, otherwise we remain at the current location.  We do not want to accept or reject too often. In practice, the Metropolis algorithm should have an acceptance probability between 0.2 and 0.4, which can be achieved by *tuning* the variance of the normal proposal distribution. 
-  
-5. We repeat 2-4 a number of times -- or *steps*.
-
-Enough of the theory, let's implement the Metropolis algorithm in `R`. Let's start by setting the scene. 
-```{r}
-steps <- 100 # number of steps
-theta.post <- rep(NA, steps) # vector to store samples
-accept <- rep(NA, steps) # keep track of accept/reject
-set.seed(1234) # for reproducibility
-```
-
-Now follow the 5 steps we've just described. First, we pick a starting value, and store it (step 1).
-```{r}
-inits <- 0.5
-theta.post[1] <- inits
-accept[1] <- 1
-```
-
-Then, we will need a function to propose a candidate value. We add a value taken from a normal distribution with mean zero and standard deviation we call *away*. We work on the logit scale to make sure the candidate value for survival lies between 0 and 1. 
-```{r}
-move <- function(x, away = 1){ # by default, standard deviation of the proposal distribution is 1
-  logitx <- log(x / (1 - x)) # apply logit transform (-infinity,+infinity)
-  logit_candidate <- logitx + rnorm(1, 0, away) # add a value taken from N(0,sd=away) to current value
-  candidate <- plogis(logit_candidate) # back-transform (0,1)
-  return(candidate)
-}
-```
-
-Now we're ready for steps 2, 3 and 4. We write a loop to take care of step 5. Remember we start at initial value 0.5 and run the algorithm for 100 steps or iterations. 
-```{r}
-for (t in 2:steps){ # repeat steps 2-4 (step 5)
-  
-  # propose candidate value for survival (step 2)
-  theta_star <- move(theta.post[t-1])
-  
-  # calculate ratio R (step 3)
-  pstar <- posterior(survived, p = theta_star)  
-  pprev <- posterior(survived, p = theta.post[t-1])
-  logR <- pstar - pprev # likelihod and prior are on the log scale
-  R <- exp(logR)
-  
-  # accept candidate value or keep current value (step 4)
-  X <- runif(1, 0, 1) # spin continuous spinner
-  if (X < R){
-    theta.post[t] <- theta_star # accept candidate value
-    accept[t] <- 1 # reject
-  }
-  else{
-    theta.post[t] <- theta.post[t-1] # keep current value
-    accept[t] <- 0 # reject
-  }
-}
-```
-
-We get the following values. 
-```{r}
-head(theta.post) # first values
-tail(theta.post) # last values
-```
-
-Visually, you may look at the chain in Figure \@ref(fig:chain) called a trace plot.
-```{r chain, echo = FALSE, fig.align='center', fig.cap = ""Visualisation of a Markov chain starting at value 0.5, with steps or iterations on the x-axis, and generated values on the y-axis. This graphical representation is called a trace plot.""}
-df <- data.frame(x = 1:steps, y = theta.post)
-df %>%
-  ggplot() +
-  geom_line(aes(x = x, y = y), size = 1.5, color = wesanderson::wes_palettes$Zissou1[1]) + 
-  labs(x = ""iterations"", y = ""values from posterior distribution"") + 
-  ylim(0.1, 0.6)
-```
-
-The acceptance probability is `r mean(accept)` and almost satisfying. 
-
-```{r echo = FALSE}
-# log-likelihood function
-loglikelihood <- function(x, p){
-  dbinom(x = x, size = released, prob = p, log = TRUE)
-}
-
-# prior density
-logprior <- function(p){
-  dunif(x = p, min = 0, max = 1, log = TRUE)
-}
-
-# posterior density function (log scale)
-posterior <- function(x, p){
-  loglikelihood(x, p) + logprior(p) # - log(Pr(data))
-}
-
-# propose candidate value
-move <- function(x, away = .2){ 
-  logitx <- log(x / (1 - x))
-  logit_candidate <- logitx + rnorm(1, 0, away)
-  candidate <- plogis(logit_candidate)
-  return(candidate)
-}
-
-metropolis <- function(steps = 100, inits = 0.5, away = 1){
-  
-  # pre-alloc memory
-  theta.post <- rep(NA, steps)
-  
-  # start
-  theta.post[1] <- inits
-  
-  for (t in 2:steps){
-    
-    # propose candidate value for prob of success
-    theta_star <- move(theta.post[t-1], away = away)
-    
-    # calculate ratio R
-    pstar <- posterior(survived, p = theta_star)  
-    pprev <- posterior(survived, p = theta.post[t-1])
-    logR <- pstar - pprev
-    R <- exp(logR)
-    
-    # accept candidate value or keep current value (step 4)
-    X <- runif(1, 0, 1) # spin continuous spinner
-    if (X < R){
-      theta.post[t] <- theta_star
-    }
-    else{
-      theta.post[t] <- theta.post[t-1]
-    }
-  }
-  theta.post
-}
-
-```
-
-
-Can we run another chain and start at initial value 0.2 this time? Yes, just go through the same algorithm again, and visualise the results in Figure \@ref(fig:twochains). 
-```{r twochains, echo = FALSE, fig.align='center', fig.cap = ""Trace plot of survival for two chains starting at 0.2 (yellow) and 0.5 (blue) run for 100 steps.""}
-theta.post2 <- metropolis(steps = 100, inits = 0.2)
-df2 <- data.frame(x = 1:steps, y = theta.post2)
-ggplot() +
-  geom_line(data = df, aes(x = x, y = y), size = 1.5, color = wesanderson::wes_palettes$Zissou1[1]) + 
-  geom_line(data = df2, aes(x = x, y = y), size = 1.5, color = wesanderson::wes_palettes$Zissou1[3]) + 
-  labs(x = ""iterations"", y = ""values from posterior distribution"") + 
-  ylim(0.1, 0.6)
-```
-
-Notice that we do not get the exact same results because the algorithm is stochastic. The question is to know whether we have reached the stationary distribution. Let's increase the number of steps and run a chain with 5000 iterations as in Figure \@ref(fig:longchain).
-```{r longchain, echo = FALSE, fig.align='center', fig.cap = ""Trace plot of survival for a chains starting at 0.5 and 1000 steps.""}
-steps <- 5000
-set.seed(1234)
-theta.post <- metropolis(steps = steps, inits = 0.5)
-df <- data.frame(x = 1:steps, y = theta.post)
-df %>%
-  ggplot() +
-  geom_line(aes(x = x, y = y), size = 1, color = wesanderson::wes_palettes$Zissou1[1]) + 
-  labs(x = ""iterations"", y = ""values from posterior distribution"") + 
-  ylim(0.1, 0.6) + 
-  geom_hline(aes(yintercept = mean(theta.post), linetype = ""posterior mean"")) + 
-  scale_linetype_manual(name = """", values = c(2,2)) 
-```
-
-This is what we're after, a trace plot that looks like a beautiful lawn, see Section \@ref(convergence-diag). I find it informative to look at the animated version of Figure \@ref(fig:longchain), it helps understanding the stochastic behavior of the algorithm, and also to realise how the chains converge to their stationary distribution, see Figure \@ref(fig:animlongchain).
-
-```{r echo = FALSE, eval = FALSE}
-# load packages
-library(tidyverse)
-theme_set(theme_light(base_size = 16))
-library(gganimate)
-library(magick)
-
-# deer data, 19 ""success"" out of 57 ""attempts""
-survived <- 19
-released <- 57
-
-#---------- apply Metropolis
-
-steps <- 1000
-chain1 <- metropolis(steps = steps, inits = 0.2)
-chain2 <- metropolis(steps = steps, inits = 0.5)
-chain3 <- metropolis(steps = steps, inits = 0.7)
-
-df <- data.frame(iter = rep(1:steps, 3), 
-                 value = c(chain1, chain2, chain3),
-                 chain = c(rep(""chain1"", steps), 
-                           rep(""chain2"", steps), 
-                           rep(""chain3"", steps)))
-
-#---------- time series
-static_tsplot <- df %>%
-  mutate(posterior_mean = mean(value)) %>%
-  ggplot(aes(x = iter, y = value, group = chain, color = chain)) +
-  geom_line(size = 1, alpha = 0.5) + 
-  geom_hline(aes(yintercept = posterior_mean, linetype = ""posterior mean"")) + 
-  scale_linetype_manual(name = """", values = c(2,2)) + 
-  labs(color = """", x = ""iterations"", y = ""survival"")
-static_tsplot  
-  
-# animate
-animated_tsplot <- static_tsplot +
-  transition_reveal(along = iter, 
-                    range = as.integer(c(1, max(df$iter) + 50))) # trick to pause
-animated_tsplot  
-
-# save
-a_gif <- animate(animated_tsplot,
-                 width = 6, 
-                 height = 3,
-                 res = 600,
-                 units = ""in"")
-
-# get file in directory str(a_gif)
-```
-```{r animlongchain, echo = FALSE, out.width=""100%"", fig.align='center', fig.cap = ""Animated trace plot of survival with three chains starting at 0.2, 0.5 and 0.7 run for 1000 steps.""}
-knitr::include_graphics(""images/traceplotMCMC.gif"")
-```
-
-Once the stationary distribution is reached, you may regard the realisations of the Markov chain as a sample from the posterior distribution, and obtain numerical summaries. In the next section, we consider several important implementation issues. 
-
-## Assessing convergence {#convergence-diag}
-
-When implementing MCMC, we need to determine how long it takes for our Markov chain to converge to the target distribution, and the number of iterations we need after achieving convergence to get reasonable Monte Carlo estimates of numerical summaries (posterior means and credible intervals).
-
-### Burn-in
-  
-In practice, we discard observations from the start of the Markov chain and just use observations from the chain once it has converged. The initial observations that we discard are usually referred to as the *burn-in*. 
-
-The simplest method to determine the length of the burn-in period is to look at trace plots. Going back to our example, we see from the trace plot in Figure \@ref(fig:burnin) that we need at least 500 iterations to achieve convergence toward an average survival around 0.3. It is always better to be conservative when specifying the length of the burn-in period, and in this example, we would use 750 or even 1000 iterations as a burn-in. The length of the burn-in period can be determined by performing preliminary MCMC short runs. 
-
-```{r burnin, echo = FALSE, fig.cap = ""Determining the length of the burn-in period. The chain starts at value 0.99 and rapidly stabilises, with values bouncing back and forth around 0.3 from the 500th iteration onwards. You may choose the shaded area as the burn-in, and discard the corresponding values.""}
-
-# set up the scene
-steps <- 1000
-theta.post <- metropolis(steps = steps, inits = 0.99)
-df <- data.frame(x = 1:steps, y = theta.post)
-df %>%
-  ggplot() +
-  geom_line(aes(x = x, y = y), size = 1.2, color = wesanderson::wes_palettes$Zissou1[1]) + 
-  labs(x = ""iterations"", y = ""survival"") + 
-  theme_light(base_size = 14) + 
-  annotate(""rect"", 
-           xmin = 0, 
-           xmax = 500, 
-           ymin = 0.1, 
-           ymax = 1, 
-           alpha = .3) +
-  scale_y_continuous(expand = c(0,0))
-```
-
-Inspecting the trace plot for a single run of the Markov chain is useful. However, we usually run the Markov chain several times, starting from different over-dispersed points, to check that all replicates achieve the same target distribution. This approach is formalised by using the Brooks-Gelman-Rubin (BGR) statistic $\hat{R}$ which measures the ratio of the total variability combining multiple chains (between-chain plus within-chain) to the within-chain variability. The BGR statistic asks whether there is a chain effect, and is very much alike the $F$ test in an analysis of variance. Values below 1.1 indicate likely convergence.
-
-```{r, echo = FALSE, cache = TRUE}
-simul.bgr <- function(steps, inits){
-  
-  nb.replicates <- length(inits)
-  theta.post <- matrix(NA, nrow = nb.replicates, ncol = steps)
-  for (i in 1:nb.replicates){
-    theta.post[i,1:steps] <- metropolis(steps = steps, inits = inits[i])
-  }
-  
-  df <- data.frame(x = rep(1:steps, nb.replicates), 
-                   y = c(t(theta.post)), 
-                   chain = paste0(""chain "",gl(nb.replicates, steps))) %>%
-    filter(x > round(steps/2)) # apply burnin (half number of iterations)
-
-  # compute BGR (R-hat)
-  num <- quantile(df$y, probs = c(20/100, 80/100))[2] - quantile(df$y, probs = c(20/100, 80/100))[1]
-  den <- df %>%
-    group_by(chain) %>%
-    summarise(ci = quantile(y, probs = c(20/100, 80/100))) %>%
-    mutate(diff = ci - lag(ci, default = ci[1])) %>%
-    filter(diff != 0) %>%
-    pull(diff) %>%
-    mean()
-  
-  bgr <- round(num / den, 3)
-  return(bgr)
-}
-
-set.seed(1234)
-steps <- seq(100, 5000, 100)
-bgr <- rep(NA, length(steps))
-for (i in 1:length(steps)){
-  bgr[i] <- simul.bgr(steps = steps[i], inits = c(0.2, 0.8))
-}
-df <- data.frame(iterations = steps, bgr = bgr)
-```
-
-Back to our example, we run two Markov chains with starting values 0.2 and 0.8 using 100 up to 5000 iterations, and calculate the BGR statistic using half the number of iterations as the length of the burn-in. From Figure \@ref(fig:bgr), we get a value of the BGR statistic near 1 by up to 2000 iterations, which suggests that with 2000 iterations as a burn-in, there is no evidence of a lack of convergence. 
-
-```{r bgr, echo=FALSE, fig.cap = ""Brooks-Gelman-Rubin statistic as a function of the number of iterations.""}
-df %>%
-  ggplot() + 
-  geom_line(aes(x = iterations, y = bgr), size = 1.2) +
-  labs(y = ""BGR statistic"")
-```
-
-It is important to bear in mind that a value near 1 for the BGR statistic is only a necessary *but not sufficient* condition for convergence. In other words, this diagnostic cannot tell you for sure that the Markov chain has achieved convergence, only that it has not.^[Cross-reference sections on local minima and parameter redundancy for pathological cases.]
-
-### Chain length
-  
-```{r, echo = FALSE}
-# inspired from https://bookdown.org/content/3686/markov-chain-monte-carlo.html
-
-n_steps <- 10000
-
-d <-
-  tibble(away = c(0.1, 1, 10)) %>% 
-  mutate(accepted_traj = map(away, metropolis, steps = n_steps, inits = 0.1)) %>% 
-  unnest(accepted_traj)
-
-d <-
-  d %>% 
-  mutate(proposal_sd = str_c(""Proposal SD = "", away),
-         iter        = rep(1:n_steps, times = 3))
-
-trace <- d %>% 
-  ggplot(aes(y = accepted_traj, x = iter)) +
-  geom_path(size = 1/4, color = ""steelblue"") +
-  geom_point(size = 1/2, alpha = 1/2, color = ""steelblue"") +
-  scale_y_continuous(""survival"", breaks = 0:5 * 0.1, limits = c(0.15, 0.5)) +
-  scale_x_continuous(""iterations"", 
-                     breaks = seq(n_steps-n_steps*10/100,n_steps,by = 600), 
-                     limits = c(n_steps-n_steps*10/100, n_steps)) +
-  facet_wrap(~proposal_sd, ncol = 3) +
-  theme_light(base_size = 14)
-
-library(forecast)
-plot1 <- ggAcf(x = d$accepted_traj[d$proposal_sd==""Proposal SD = 0.1""]) + ggtitle(""Proposal SD = 0.1"")
-plot2 <- ggAcf(x = d$accepted_traj[d$proposal_sd==""Proposal SD = 1""]) + ggtitle(""Proposal SD = 1"")
-plot3 <- ggAcf(x = d$accepted_traj[d$proposal_sd==""Proposal SD = 10""]) + ggtitle(""Proposal SD = 10"")
-```
-
-How long of a chain is needed to produce reliable parameter estimates? To answer this question, you need to keep in mind that successive steps in a Markov chain are near each other, and are not independent -- this is usually referred to as *autocorrelation*. Ideally, we would like to keep autocorrelation as low as possible. Here again, trace plots are useful to diagnose issues with autocorrelation. Let's get back to our survival example. Figure \@ref(fig:tracechainlength) shows trace plots for different values of the standard deviation (parameter *away*) of the (normal) proposal distribution we use to propose a candidate value (Section \@ref(metropolis-algorithm)). Small and big moves provide high correlations between successive observations of the Markov chain, whereas a standard deviation of 1 allows efficient exploration of the parameter space. The movement around the parameter space is referred to as *mixing*. Mixing is bad when the chain makes small and big moves, and good otherwise. 
-
-```{r tracechainlength, echo=FALSE, fig.cap = ""Trace plots for different values of the standard deviation (SD) of the proposal distribution. Left: The chain exhibits small moves and mixing is bad. Right: The chain exhibits big moves and mixing is bad. Middle: The chain exhibits adequate moves and mixing is good. Only the thousand last iterations are shown.""}
-trace
-```
-
-In addition to trace plots, autocorrelation function (ACF) plots are a convenient way of displaying the strength of autocorrelation in a given sample values. ACF plots provide the autocorrelation between successively sampled values separated by $k$ iterations, or *lag*, for increasing values of $k$ (Figure \@ref(fig:acfchainlength)).
-
-```{r acfchainlength, echo=FALSE, fig.cap = ""Autocorrelation function plots for different values of the standard deviation (SD) of the proposal distribution. Left and right: Autocorrelation is strong, decreases slowly with increasing lag and mixing is bad. Middle: Autocorrelation is weak, decreases rapidly with increasing lag and mixing is good.""}
-library(patchwork)
-(plot1 + plot2 + plot3)
-```
-
-Autocorrelation is not necessarily a big issue. Strongly correlated observations just require large sample sizes and therefore longer simulations. But how many iterations exactly? The effective sample size (`n.eff`) measures chain length while taking into account chain autocorrelation. You should check the `n.eff` of every parameter of interest, and of any interesting parameter combinations. In general, we need $\text{n.eff} \geq 1000$ independent steps to get reasonable Monte Carlo estimates of model parameters. In the animal survival example, `n.eff` can be calculated with the R `coda::effectiveSize()` function:
-```{r neff, echo = FALSE}
-neff1 <- coda::effectiveSize(d$accepted_traj[d$proposal_sd==""Proposal SD = 0.1""])
-neff2 <- coda::effectiveSize(d$accepted_traj[d$proposal_sd==""Proposal SD = 1""])
-neff3 <- coda::effectiveSize(d$accepted_traj[d$proposal_sd==""Proposal SD = 10""])
-df <- tibble(""Proposal SD"" = c(0.1, 1, 10),
-                 ""n.eff"" = round(c(neff1, neff2, neff3)))
-knitr::kable(df, format = ""markdown"")
-```
-
-As expected, `n.eff` is less than the number of MCMC iterations because of autocorrelation. Only when the standard deviation of the proposal distribution is 1 and mixing is good (Figures \@ref(fig:tracechainlength) and \@ref(fig:acfchainlength)) we get a satisfying effective sample size. 
-
-### What if you have issues of convergence?
-  
-When diagnosing MCMC convergence, you will (very) often run into troubles. In this section I provide some tips learnt from experience. 
-
-When mixing is bad and effective sample size is small, you may just need to increase burn-in and/or sample more. Using more informative priors might also make Markov chains converge faster by helping your MCMC sampler (e.g. the Metropolis algorithm) navigating more efficiently the parameter space. In the same spirit, picking better initial values for starting the chain does not harm. For doing that, a strategy consists in using estimates from a simpler model for which your MCMC chains do converge. 
-
-If convergence issues persist, often there is a problem with your model^[The quote 'When you have computational problems, often there's a problem with your model' is the folk theorem of statistical computing stated by Andrew Gelman in 2008, see https://statmodeling.stat.columbia.edu/2008/05/13/the_folk_theore/]. A bug in the code? A typo somewhere? A mistake in your maths? As often when coding is involved, the issue can be identified by removing complexities, and start with a simpler model until you find what the problem is. 
-
-A general advice is to see your model as a data generating tool in the first place, simulate data from it using some realistic values for the parameters, and try to recover these parameter values by fitting the model to the simulated data. Simulating from a model will help you understanding how it works, what it does not do, and the data you need to get reasonable parameter estimates. 
-
-We will see other strategies to improve convergence in the next chapters.^[Cross reference relevant chapters. Option 1. Change your sampler. Option 2. Reparameterize (standardize covariates, plus non-centering: $\alpha \sim N(0,\sigma)$ becomes $\alpha = z \sigma$ with $z \sim N(0,1)$).]
-
-## Summary
-
-+ With the Bayes' theorem, you may update your beliefs (*prior*) with new data (*likelihood*) to get posterior beliefs (*posterior*): $\text{posterior} \propto \text{likelihood} \times \text{prior}$
-
-+ The idea of Markov chain Monte Carlo (MCMC) is to simulate values from a Markov chain which has a stationary distribution equal to the posterior distribution you're after. 
-
-+ In practice, you run a Markov chain multiple times starting from over-dispersed initial values. 
-
-+ You discard iterations in an initial burn-in phase and achieve convergence when all replicates reach the same regime. 
-
-+ From there, you run the chain long enough and proceed with calculating Monte Carlo estimates of numerical summaries (e.g. posterior means and credible intervals) for parameters.
-
-## Suggested reading
-
-+ Gelman, A. and Hill, J. (2006). [Data Analysis Using Regression and Multilevel/Hierarchical Models (Analytical Methods for Social Research)](https://www.cambridge.org/core/books/data-analysis-using-regression-and-multilevelhierarchical-models/32A29531C7FD730C3A68951A17C9D983). Cambridge: Cambridge University Press.
-
-+ Gelman, A. and colleagues (2020). [Bayesian workflow](https://arxiv.org/pdf/2011.01808.pdf). arXiv preprint. 
-
-+ McCarthy, M. (2007). [Bayesian Methods for Ecology](https://www.cambridge.org/core/books/bayesian-methods-for-ecology/9225F65B8A25D69B0B6C50B5A9A78201). Cambridge: Cambridge University Press.
-
-+ McElreath, R. (2020). [Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2nd ed.)](https://xcelab.net/rm/statistical-rethinking/). CRC Press.
-

---FILE: bayesmcmc.Rmd---
@@ -1,2 +1,669 @@
 # Bayesian statistics & MCMC {#crashcourse}
 
+## Introduction
+
+In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to implement the Bayesian method for more complex analyses. This is not an exhaustive treatment of Bayesian statistics, but you should get what you need to navigate through the rest of the book. 
+
+## Bayes' theorem
+
+Let's not wait any longer and jump into it. Bayesian statistics relies on the Bayes' theorem (or law, or rule, whatever you prefer) named after Reverend Thomas Bayes (Figure \@ref(fig:revbayes)). This theorem was published in 1763 two years after Bayes' death thanks to his friend's efforts Richard Price, and was independently discovered by Pierre-Simon Laplace [@mcgrayne2011]. 
+
+```{r revbayes, echo = FALSE, fig.align=""center"", out.width=""100%"", fig.cap = ""Cartoon of Thomas Bayes with Bayes' theorem in background. Source: [James Kulich](https://www.elmhurst.edu/blog/thomas-bayes/)""}
+knitr::include_graphics(""images/amazing-thomas-bayes-illustration.jpg"")
+```
+
+As we will see in a minute, Bayes' theorem is all about conditional probabilities, which are somehow tricky to understand. Conditional probability of outcome or event A given event B, which we denote $\Pr(A \mid B)$, is the probability that A occurs, revised by considering the additional information that event B has occurred.^[For example, a friend of yours rolls a fair dice and asks you the probability that the outcome was a six (event A). Your answer is 1/6 because each side of the dice is equally likely to come up. Now imagine that you're told the number rolled was even (event B) before you answer your friend's question. Because there are only three even numbers, one of which is six, you may revise your answer for the probability that a six was rolled from 1/6 to $\Pr(A \mid B) = 1/3$.] The order in which A and B appear is important, make sure you do not confuse $\Pr(A \mid B)$ and $\Pr(B \mid A)$.
+
+Bayes' theorem (Figure \@ref(fig:bayestheorem)) gives you $\Pr(A \mid B)$ using marginal probabilities $\Pr(A)$ and $\Pr(B)$ and $\Pr(B \mid A)$:
+$$\Pr(A \mid B) = \displaystyle{\frac{ \Pr(B \mid A) \; \Pr(A)}{\Pr(B)}}.$$
+Originally, Bayes' theorem was seen as a way to infer an unkown cause A of a particular effect B, knowing the probability of effect B given cause A. Think for example of a situation where a medical diagnosis is needed, with A an unkown disease and B symptoms, the doctor knows P(symptoms|disease) and wants to derive P(disease|symptoms). This way of reversing $\Pr(B \mid A)$ into $\Pr(A \mid B)$ explains why Bayesian thinking used to be referred to as 'inverse probability'. 
+
+```{r bayestheorem, echo = FALSE, fig.align=""center"", fig.cap = ""Bayes' theorem spelt out in blue neon. Source: [Wikipedia](https://en.wikipedia.org/wiki/Bayes%27_theorem)""}
+knitr::include_graphics(""images/bayes_neon.jpeg"")
+```
+
+I don't know about you, but I need to think twice for not messing the letters around. I find it easier to remember Bayes' theorem written like this^[When teaching Bayes' theorem, I am very much inspired by Tristan Mahr's slides from his introduction to Bayesian regression https://www.tjmahr.com/bayes-intro-lecture-slides-2017/]:
+
+$$ \Pr(\text{hypothesis} \mid \text{data}) = \frac{ \Pr(\text{data} \mid \text{hypothesis}) \; \Pr(\text{hypothesis})}{\Pr(\text{data})} $$
+```{block2 bayes, type='rmdnote'}
+The *hypothesis* is a working assumption about which you want to learn using *data*. In capture--recapture analyses, the hypothesis might be a parameter like detection probability, or regression parameters in a relationship between survival probability and a covariate. Bayes' theorem tells us how to obtain the probability of a hypothesis given the data we have. 
+```
+
+This is great because think about it, this is exactly what the scientific method is! We'd like to know how plausible some hypothesis is based on some data we collected, and possibly compare several hypotheses among them. In that respect, the Bayesian reasoning matches the scientific reasoning, which probably explains why the Bayesian framework is so natural for doing and understanding statistics. 
+
+You might ask then, why is Bayesian statistics not the default in statistics? Clearly, because of futile wars between male statisticians (including Ronald Fisher, Jerzy Neyman and Egon Sharpe Pearson among others), little progress was made for over two centuries. Also, until recently, there were practical problems to implement Bayes' theorem. Recent advances in computational power coupled with the development of new algorithms have led to a great increase in the application of Bayesian methods within the last three decades.
+
+## What is the Bayesian approach?	
+
+Typical statistical problems involve estimating a parameter (or several parameters) $\theta$ with available data. To do so, you might be more used to the frequentist rather than the Bayesian method. The frequentist approach, and in particular maximum likelihood estimation (MLE), assumes that the parameters are fixed, and have unknown values to be estimated. Therefore classical estimates are generally point estimates of the parameters of interest. In contrast, the Bayesian approach assumes that the parameters are not fixed, and have some unknown distribution^[A probability distribution is a mathematical expression that gives the probability for a random variable to take particular values. A probability distribution may be either discrete (e.g., the Bernoulli, Binomial or Poisson distribution) or continuous (e.g., the Gaussian distribution also known as the normal distribution)].
+
+The Bayesian approach is based upon the idea that you, as an experimenter, begin with some prior beliefs about the system. Then you collect data and update your prior beliefs on the basis of observations. These observations might arise from field work, lab work or from expertise of your esteemed colleagues. This updating process is based upon Bayes' theorem. Loosely, let's say $A = \theta$ and $B = \text{data}$, then Bayes' theorem gives you a way to estimate parameter $\theta$ given the data you have:
+
+$${\color{red}{\Pr(\theta \mid \text{data})}} = \frac{\color{blue}{\Pr(\text{data} \mid \theta)} \times \color{green}{\Pr(\theta)}}{\color{orange}{\Pr(\text{data})}}.$$
+Let's spend some time going through each quantity in this formula. 
+
+On the left-hand side is the $\color{red}{\text{posterior distribution}}$. It represents what you know after having seen the data. This is the basis for inference and clearly what you're after, a distribution, possibly multivariate if you have more than one parameter. 
+
+On the right-hand side, there is the $\color{blue}{\text{likelihood}}$. This quantity is the same as in the MLE approach. Yes, the Bayesian and frequentist approaches have the same likelihood at their core, which mostly explains why results often do not differ much. The likelihood captures the information you have in your data, given a model parameterized with $\theta$. 
+
+Then we have the $\color{green}{\text{prior distribution}}$. This quantity represents what you know before seeing the data. This is the source of much discussion about the Bayesian approach. It may be vague if you don't know anything about $\theta$. Usually however, you never start from scratch, and you'd like your prior to reflect the information you have^[Shall I include a section on sensitivity analyses in this chapter or later in the book? Cross-reference section in Survival chapter where prior elicitation is covered.].
+
+Last, we have $\color{orange}{\Pr(\text{data})}$ which is sometimes called the average likelihood because it is obtained by integrating the likelihood with respect to the prior $\color{orange}{\Pr(\text{data}) = \int{L(\text{data} \mid \theta)\Pr(\theta) d\theta}}$ so that the posterior is standardized, that is it integrates to one for the posterior to be a distribution. The average likelihood is an integral with dimension the number of parameters $\theta$ you need to estimate. This quantity is difficult, if not impossible, to calculate in general. This is one of the reasons why the Bayesian method wasn't used until recently, and why we need algorithms to estimate posterior distributions as I illustrate in the next section.
+
+## Approximating posteriors via numerical integration {#numerical-approx}
+
+Let's take an example to illustrate Bayes' theorem. Say we capture, mark and release $n = 57$ animals at the beginning of a winter, out of which we recapture $y = 19$ animals alive^[We used a similar example in @king_bayesian_2009]. We'd like to estimate winter survival $\theta$.
+```{r}
+y <- 19 # nb of success
+n <- 57 # nb of attempts
+```
+
+We build our model first. Assuming all animals are independent of each other and have the same survival probability, then $y$ the number of alive animals at the end of the winter is a binomial distribution^[I follow @mcelreathbook and use labels on the right to help remember what each line is about.] with $n$ trials and $\theta$ the probability of success:
+  
+\begin{align*}
+y &\sim \text{Binomial}(n, \theta) &\text{[likelihood]}
+\end{align*}
+
+This likelihood can be visualised in `R`: 
+```{r binlik, echo = TRUE, fig.cap = ""Binomial likelihood with $n = 57$ released animals and $y = 19$ survivors after winter. The value of survival (on the x-axis) that corresponds to the maximum of the likelihood function (on the y-axis) is the MLE, or the proportion of success in this example, close to 0.33.""}
+grid <- seq(0, 1, 0.01) # grid of values for survival
+likelihood <- dbinom(y, n, grid) # compute binomial likelihood
+df <- data.frame(survival = grid, likelihood = likelihood) 
+df %>%
+  ggplot() + 
+  aes(x = survival, y = likelihood) + 
+  geom_line(size = 1.5)
+```
+
+Besides the likelihood, priors are another component of the model in the Bayesian approach. For a parameter that is a probability, the one thing we know is that the prior should be a continuous random variable that lies between 0 and 1. To reflect that, we often go for the uniform distribution $U(0,1)$ to imply *vague* priors. Here vague means that survival has, before we see the data, the same probability of falling between 0.1 and 0.2 and between 0.8 and 0.9, for example. 
+
+\begin{align*}
+\theta &\sim \text{Uniform}(0, 1) &\text{[prior for }\theta \text{]}
+\end{align*}
+
+```{r, echo = FALSE}
+a <- 1; b <- 1; grid <- seq(0,1,0.01); prior <- dbeta(grid,a,b)
+dfprior <- data.frame(survival = grid, prior = prior) 
+#dfprior %>%
+#  ggplot() + 
+#  geom_line(aes(x = p, y = prior), 
+#            size = 1.5,
+#            color = wesanderson::wes_palettes$Royal1[1])
+#plot(p, dbeta(p,a,b), type='l', lwd=3)
+```
+
+Now we apply Bayes' theorem. We write a `R` function that computes the product of the likelihood times the prior, or the numerator in Bayes' theorem: $\Pr(\text{data} \mid \theta) \times \Pr(\theta)$
+```{r}
+numerator <- function(theta) dbinom(y, n, theta) * dunif(theta, 0, 1)
+```
+
+We write another function that calculates the denominator, the average likelihood: $\Pr(\text{data}) = \int{L(\theta \mid \text{data}) \Pr(\theta) d\theta}$
+```{r}
+denominator <- integrate(numerator,0,1)$value
+```
+
+We use the `R` function `integrate` to calculate the integral in the denominator, which implements quadrature techniques to divide in little squares the area underneath the curve delimited by the function to integrate (here the numerator), and count them.
+
+Then we get a numerical approximation of the posterior in Figure \@ref(fig:numapprox) by applying Bayes' theorem. 
+```{r numapprox, echo = TRUE, fig.cap = ""Winter survival posterior distribution obtained by numerical integration.""}
+grid <- seq(0, 1, 0.01) # grid of values for theta
+numerical_posterior <- data.frame(survival = grid, 
+                                  posterior = numerator(grid)/denominator) # Bayes' theorem
+numerical_posterior %>%
+  ggplot() +
+  aes(x = survival, y = posterior) + 
+  geom_line(size = 1.5)
+```
+
+How good is our numerical approximation of survival posterior distribution? Ideally, we would want to compare the approximation to the true posterior distribution. Although a closed-form expression for the posterior distribution is in general intractable, when you combine a binomial likelihood together with a beta distribution as a prior, then the posterior distribution is also a beta distribution, which makes it amenable to all sorts of exact calculations^[We say that the beta distribution is the conjugate prior distribution for the binomial distribution.]. The beta distribution is continuous between 0 and 1, and extends the uniform distribution to situations where not all outcomes are equally likely. It has two parameters $a$ and $b$ that control its shape (Figure \@ref(fig:betadistribution)).
+
+(ref:captionbeta) The distribution beta($a$,$b$) for different values of $a$ and $b$. Note that for $a = b = 1$, we get the uniform distribution between 0 and 1 in the top left panel. When $a$ and $b$ are equal, the distribution is symmetric, and the bigger $a$ and $b$, the more peaked the distribution or the smaller the variance. 
+
+```{r betadistribution, echo = FALSE, fig.cap='(ref:captionbeta)'}
+x <- seq(0, 1, length=200)
+par(mfrow = c(2,3))
+# distribution a posteriori beta
+plot(x,dbeta(x, 1, 1),type='l',xlab='',ylab='Density',main='beta(1,1)',lwd=3,col='black',ylim=c(0,1.5))
+plot(x,dbeta(x, 2, 1),type='l',xlab='',ylab='',main='beta(2,1)',lwd=3,col='black',ylim=c(0,2))
+plot(x,dbeta(x, 1, 2),type='l',xlab='',ylab='',main='beta(1,2)',lwd=3,col='black',ylim=c(0,2))
+plot(x,dbeta(x, 2, 2),type='l',xlab='',ylab='Density',main='beta(2,2)',lwd=3,col='black',ylim=c(0,1.5))
+plot(x,dbeta(x, 10, 10),type='l',xlab='',ylab='',main='beta(10,10)',lwd=3,col='black',ylim=c(0,3.5))
+plot(x,dbeta(x, 0.8, 0.8),type='l',xlab='',ylab='',main='beta(0.8,0.8)',lwd=3,col='black',ylim=c(0.5,2.5))
+```
+
+If the likelihood of the data $y$ is binomial with $n$ trials and probability of success $\theta$, and the prior is a beta distribution with parameters $a$ and $b$, then the posterior is a beta distribution with parameters $a + y$ and $b + n - y$^[**provide a sketch of the proof**]. In our example, we have $n = 57$ trials and $y = 19$ animals that survived and a uniform prior between 0 and 1 or a beta distribution with parameters $a = b = 1$, therefore survival has a beta posterior distribution with parameters 20 and 39. In Figure \@ref(fig:compar), we superimpose the exact posterior and the numerical approximation. Clearly, the two distributions are indistinguishable, suggesting that the numerical approximation is more than fine. 
+```{r compar, echo = FALSE, fig.cap = ""Comparison of exact (dashed line) vs. numerical approximation (continuous line) of winter survival posterior distribution.""}
+explicit_posterior <- dbeta(grid, y + a, n - y + b)
+dfexpposterior <- data.frame(survival = grid, explicit_posterior = explicit_posterior)
+ggplot() + 
+  geom_line(data = numerical_posterior, 
+            aes(x = survival, y = posterior), 
+            size = 1.5, 
+            col = wesanderson::wes_palettes$Royal1[2],
+            alpha = 0.5) + 
+  geom_line(data = dfexpposterior, 
+            aes(x = survival, y = explicit_posterior),
+            size = 1.5, 
+            col = wesanderson::wes_palettes$Royal1[3], 
+            linetype = ""dashed"")
+```
+
+<!-- To finish up, let's add the prior.  -->
+<!-- ```{r, echo = FALSE} -->
+<!-- ggplot() +  -->
+<!--   geom_line(data = numerical_posterior,  -->
+<!--             aes(x = survival, y = posterior),  -->
+<!--             size = 1.5,  -->
+<!--             col = wesanderson::wes_palettes$Royal1[2],  -->
+<!--             alpha = 0.5) +  -->
+<!--   geom_line(data = dfexpposterior,  -->
+<!--             aes(x = survival, y = explicit_posterior), -->
+<!--             col = wesanderson::wes_palettes$Royal1[3],  -->
+<!--             size = 1.5,  -->
+<!--             linetype = ""dashed"") +  -->
+<!--   geom_line(data = dfprior, -->
+<!--             aes(x = survival, y = prior), -->
+<!--             col = wesanderson::wes_palettes$Royal1[1], -->
+<!--             size = 1.5) -->
+<!-- ``` -->
+
+In our example, we have a single parameter to estimate, winter survival. This means dealing with a one-dimensional integral in the denominator which is pretty easy with quadrature techniques and the `R` function `integrate()`. Now what if we had multiple parameters? For example, imagine you'd like to fit a capture-recapture model with detection probability $p$ and regression parameters $\alpha$ and $\beta$ for the intercept and slope of a relationship between survival probability and a covariate, then Bayes' theorem gives you the posterior distribution of all three parameters together:
+
+$$ \Pr(\alpha, \beta, p \mid \text{data}) = \frac{ \Pr(\text{data} \mid \alpha, \beta, p) \times \Pr(\alpha, \beta, p)}{\iiint \, \Pr(\text{data} \mid \alpha, \beta, p) \Pr(\alpha, \beta, p) d\alpha d\beta dp} $$
+There are two computational challenges with this formula. First, do we really wish to calculate a three-dimensional integral? The answer is no, one-dimensional and two-dimensional integrals are so much further we can go with standard methods. Second, we're more interested in a posterior distribution for each parameter separately than the joint posterior distribution. The so-called marginal distribution of $p$ for example is obtained by integrating over all the other parameters -- a two-dimensional integral in this example. Now imagine with tens or hundreds of parameters to estimate, these integrals become highly multi-dimensional and simply intractable. In the next section, I introduce powerful simulation methods to circumvent this issue. 
+
+## Markov chain Monte Carlo (MCMC)
+
+In the early 1990s, statisticians rediscovered work from the 1950's in physics. In a famous paper that would lay the fundations of modern Bayesian statistics (Figure \@ref(fig:mcmcpaper)), the authors use simulations to approximate posterior distributions with some precision by drawing large samples. This is a neat trick to avoid explicit calculation of the multi-dimensional integrals we struggle with when using Bayes' theorem. 
+
+```{r mcmcpaper, echo = FALSE, fig.align='center', fig.cap = ""MCMC article cover. Source: [The Journal of Chemical Physics](https://aip.scitation.org/doi/10.1063/1.1699114)""}
+knitr::include_graphics(""images/metropolis.png"")
+```
+
+These simulation algorithms are called Markov chain Monte Carlo (MCMC), and they definitely gave a boost to Bayesian statistics. There are two parts in MCMC, Markov chain and Monte Carlo, let's try and make sense of these terms. 
+
+### Monte Carlo integration
+
+What does Monte Carlo stand for? Monte Carlo integration is a simulation technique to calculate integrals of any function $f$ of random variable $X$ with distribution $\Pr(X)$ say $\int f(X) \Pr(X)dX$. You draw values $X_1,\ldots,X_k$ from $\Pr(X)$ the distribution of $X$, apply function $f$ to these values, then calculate the mean of these new values $\displaystyle{\frac{1}{k}}\sum_{i=1}^k{f(X_i)}$ to approximate the integral. How is Monte Carlo integration used in a Bayesian context? The posterior distribution contains all the information we need about the parameter to be estimated. When dealing with many parameters however, you may want to summarise posterior results by calculating numerical summaries. The simplest numerical summary is the mean of the posterior distribution, $E(\theta) = \int \theta \Pr(\theta|\text{data})$, where $X$ is $\theta$ now and $f$ is the identity function. Posterior mean can be calculated with Monte Carlo integration:
+```{r}
+sample_from_posterior <- rbeta(1000, 20, 39) # draw 1000 values from posterior survival beta(20,39)
+mean(sample_from_posterior) # compute mean with Monte Carlo integration
+```
+
+You may check that the mean we have just calculated matches closely the expectation of a beta distribution^[If $X$ is a random variable with distribution $\text{beta}(a, b)$, then $E(X) = \displaystyle{\frac{a}{a + b}}$]:
+```{r}
+20/(20+39) # expectation of beta(20,39)
+```
+
+Another useful numerical summary is the credible interval within which our parameter falls with some probability, usually 0.95 hence a 95$\%$ credible interval. Finding the bounds of a credible interval requires calculating quantiles, which in turn involves integrals and the use of Monte Carlo integration. A 95$\%$ credible interval for winter survival can be obtained in `R` with:
+```{r}
+quantile(sample_from_posterior, probs = c(2.5/100, 97.5/100))
+```
+
+### Markov chains
+
+What is a Markov chain? A Markov chain is a random sequence of numbers, in which each number depends only on the previous number. An example is the weather in my home town in Southern France, Montpellier, in which a sunny day is most likely to be followed by another sunny day, say with probability 0.8, and a rainy day is rarely followed by another rainy day, say with probability 0.1. The dynamic of this Markov chain is captured by the transition matrix $\mathbf{\Gamma}$:
+$$
+\begin{matrix}
+& \\
+\mathbf{\Gamma} = 
+    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right .
+\end{matrix}
+\hspace{-1.2em}
+\begin{matrix}
+    \text{sunny tomorrow} & \text{rainy tomorrow} \\ 
+0.8 & 0.2 \\ 
+0.9 & 0.1 \\ 
+\end{matrix}
+\hspace{-0.2em}
+\begin{matrix}
+& \\
+\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
+    \begin{matrix}
+    \text{sunny today} \\ \text{rainy today}
+    \end{matrix}
+\end{matrix}
+$$
+In rows the weather today, and in columns the weather tomorrow. The cells give the probability of a sunny or rainy day tomorrow, given the day is sunny or rainy today. Under certain conditions^[The Markov chain is irreducible and aperiodic.], a Markov chain will converge to a unique stationary distribution. In our weather example, let's run the Markov chain for 20 steps:
+```{r}
+weather <- matrix(c(0.8, 0.2, 0.9, 0.1), nrow = 2, byrow = T) # transition matrix
+steps <- 20
+for (i in 1:steps){
+  weather <- weather %*% weather # matrix multiplication
+}
+round(weather, 2) # matrix product after 20 steps
+```
+
+Each row of the transition matrix converges to the same distribution $(0.82, 0.18)$ as the number of steps increases. Convergence happens no matter which state you start in, and you always have probability 0.82 of the day being sunny and 0.18 of the day being rainy. 
+
+Back to MCMC, the core idea is that you can build a Markov chain with a given stationary distribution set to be the desired posterior distribution. 
+
+```{block2 mcmc, type='rmdnote'}
+Putting Monte Carlo and Markov chains together, MCMC allows us to generate a sample of values (Markov chain) whose distribution converges to the posterior distribution, and we can use this sample of values to calculate any posterior summaries (Monte Carlo), such as posterior means and credible intervals. 
+```
+
+### Metropolis algorithm {#metropolis-algorithm}
+
+There are several ways of constructing Markov chains for Bayesian inference^[You might have heard about the Metropolis-Hastings or the Gibbs sampler. Have a look to <https://github.com/chi-feng/mcmc-demo> for an interactive gallery of MCMC algorithms.]. Here I illustrate the Metropolis algorithm and how to implement it in practice^[This presentation is largely inspired by @alberthu2019].
+
+Let's go back to our example on animal survival estimation. We illustrate sampling from survival posterior distribution. We write functions for likelihood, prior and posterior.
+
+```{r}
+# 19 animals recaptured alive out of 57 captured, marked and released
+survived <- 19
+released <- 57
+
+# binomial log-likelihood function
+loglikelihood <- function(x, p){
+  dbinom(x = x, size = released, prob = p, log = TRUE)
+}
+
+# uniform prior density
+logprior <- function(p){
+  dunif(x = p, min = 0, max = 1, log = TRUE)
+}
+
+# posterior density function (log scale)
+posterior <- function(x, p){
+  loglikelihood(x, p) + logprior(p) # - log(Pr(data))
+}
+```
+
+The Metropolis algorithm works as follows: 
+  
+1. We pick a value of the parameter to be estimated. This is where we start our Markov chain -- this is a *starting* value. 
+
+2. To decide where to go next, we propose to move away from the current value of the parameter -- this is a *candidate* value. To do so, we add to the current value some random value from e.g. a normal distribution with some variance -- this is a *proposal* distribution. The Metropolis algorithm is a particular case of the Metropolis-Hastings algorithm with symmetric proposals.
+  
+3. We compute the ratio of the probabilities at the candidate and current locations $R=\displaystyle{\frac{{\Pr(\text{candidate}|\text{data})}}{{\Pr(\text{current}|\text{data})}}}$. This is where the magic of MCMC happens, in that $\Pr(\text{data})$, the denominator in the Bayes' theorem, appears in both the numerator and the denominator in $R$ therefore cancels out and does not need to be calculated. 
+
+<!-- -- *the Hastings ratio* -->
+
+4. If the posterior at the candidate location $\Pr(\text{candidate}|\text{data})$ is higher than at the current location $\Pr(\text{current}|\text{data})$, in other words when the candidate value is more plausible than the current value, we definitely accept the candidate value. If not, then we accept the candidate value with probability $R$ and reject with probability $1-R$. For example, if the candidate value is ten times less plausible than the current value, then we accept with probability 0.1 and reject with probability 0.9. How does it work in practice? We use a continuous spinner that lands somewhere between 0 and 1 -- call the random spin $X$. If $X$ is smaller than $R$, we move to the candidate location, otherwise we remain at the current location.  We do not want to accept or reject too often. In practice, the Metropolis algorithm should have an acceptance probability between 0.2 and 0.4, which can be achieved by *tuning* the variance of the normal proposal distribution. 
+  
+5. We repeat 2-4 a number of times -- or *steps*.
+
+Enough of the theory, let's implement the Metropolis algorithm in `R`. Let's start by setting the scene. 
+```{r}
+steps <- 100 # number of steps
+theta.post <- rep(NA, steps) # vector to store samples
+accept <- rep(NA, steps) # keep track of accept/reject
+set.seed(1234) # for reproducibility
+```
+
+Now follow the 5 steps we've just described. First, we pick a starting value, and store it (step 1).
+```{r}
+inits <- 0.5
+theta.post[1] <- inits
+accept[1] <- 1
+```
+
+Then, we need a function to propose a candidate value. We add a value taken from a normal distribution with mean zero and standard deviation we call *away*. We work on the logit scale to make sure the candidate value for survival lies between 0 and 1. 
+```{r}
+move <- function(x, away = 1){ # by default, standard deviation of the proposal distribution is 1
+  logitx <- log(x / (1 - x)) # apply logit transform (-infinity,+infinity)
+  logit_candidate <- logitx + rnorm(1, 0, away) # add a value taken from N(0,sd=away) to current value
+  candidate <- plogis(logit_candidate) # back-transform (0,1)
+  return(candidate)
+}
+```
+
+Now we're ready for steps 2, 3 and 4. We write a loop to take care of step 5. We start at initial value 0.5 and run the algorithm for 100 steps or iterations. 
+```{r}
+for (t in 2:steps){ # repeat steps 2-4 (step 5)
+  
+  # propose candidate value for survival (step 2)
+  theta_star <- move(theta.post[t-1])
+  
+  # calculate ratio R (step 3)
+  pstar <- posterior(survived, p = theta_star)  
+  pprev <- posterior(survived, p = theta.post[t-1])
+  logR <- pstar - pprev # likelihood and prior are on the log scale
+  R <- exp(logR)
+  
+  # accept candidate value or keep current value (step 4)
+  X <- runif(1, 0, 1) # spin continuous spinner
+  if (X < R){
+    theta.post[t] <- theta_star # accept candidate value
+    accept[t] <- 1 # accept
+  }
+  else{
+    theta.post[t] <- theta.post[t-1] # keep current value
+    accept[t] <- 0 # reject
+  }
+}
+```
+
+We get the following values. 
+```{r}
+head(theta.post) # first values
+tail(theta.post) # last values
+```
+
+Visually, you may look at the chain in Figure \@ref(fig:chain) called a trace plot.
+```{r chain, echo = FALSE, fig.align='center', fig.cap = ""Visualisation of a Markov chain starting at value 0.5, with steps or iterations on the x-axis, and samples on the y-axis. This graphical representation is called a trace plot.""}
+df <- data.frame(x = 1:steps, y = theta.post)
+df %>%
+  ggplot() +
+  geom_line(aes(x = x, y = y), size = 1.5, color = wesanderson::wes_palettes$Zissou1[1]) + 
+  labs(x = ""iterations"", y = ""samples"") + 
+  ylim(0.1, 0.6)
+```
+
+The acceptance probability is the average number of times we accepted a candidated value, which is `r mean(accept)` and almost satisfying. 
+
+```{r echo = FALSE}
+# log-likelihood function
+loglikelihood <- function(x, p){
+  dbinom(x = x, size = released, prob = p, log = TRUE)
+}
+
+# prior density
+logprior <- function(p){
+  dunif(x = p, min = 0, max = 1, log = TRUE)
+}
+
+# posterior density function (log scale)
+posterior <- function(x, p){
+  loglikelihood(x, p) + logprior(p) # - log(Pr(data))
+}
+
+# propose candidate value
+move <- function(x, away = .2){ 
+  logitx <- log(x / (1 - x))
+  logit_candidate <- logitx + rnorm(1, 0, away)
+  candidate <- plogis(logit_candidate)
+  return(candidate)
+}
+
+metropolis <- function(steps = 100, inits = 0.5, away = 1){
+  
+  # pre-alloc memory
+  theta.post <- rep(NA, steps)
+  
+  # start
+  theta.post[1] <- inits
+  
+  for (t in 2:steps){
+    
+    # propose candidate value for prob of success
+    theta_star <- move(theta.post[t-1], away = away)
+    
+    # calculate ratio R
+    pstar <- posterior(survived, p = theta_star)  
+    pprev <- posterior(survived, p = theta.post[t-1])
+    logR <- pstar - pprev
+    R <- exp(logR)
+    
+    # accept candidate value or keep current value (step 4)
+    X <- runif(1, 0, 1) # spin continuous spinner
+    if (X < R){
+      theta.post[t] <- theta_star
+    }
+    else{
+      theta.post[t] <- theta.post[t-1]
+    }
+  }
+  theta.post
+}
+
+```
+
+
+Can we run another chain and start at initial value 0.2 this time? Yes, just go through the same algorithm again, and visualise the results in Figure \@ref(fig:twochains). 
+```{r twochains, echo = FALSE, fig.align='center', fig.cap = ""Trace plot of survival for two chains starting at 0.2 (yellow) and 0.5 (blue) run for 100 steps.""}
+theta.post2 <- metropolis(steps = 100, inits = 0.2)
+df2 <- data.frame(x = 1:steps, y = theta.post2)
+ggplot() +
+  geom_line(data = df, aes(x = x, y = y), size = 1.5, color = wesanderson::wes_palettes$Zissou1[1]) + 
+  geom_line(data = df2, aes(x = x, y = y), size = 1.5, color = wesanderson::wes_palettes$Zissou1[3]) + 
+  labs(x = ""iterations"", y = ""values from posterior distribution"") + 
+  ylim(0.1, 0.6)
+```
+
+Notice that we do not get the exact same results because the algorithm is stochastic. The question is to know whether we have reached the stationary distribution. Let's increase the number of steps and run a chain with 5000 iterations as in Figure \@ref(fig:longchain).
+```{r longchain, echo = FALSE, fig.align='center', fig.cap = ""Trace plot of survival for a chain starting at 0.5 and 1000 steps.""}
+steps <- 5000
+set.seed(1234)
+theta.post <- metropolis(steps = steps, inits = 0.5)
+df <- data.frame(x = 1:steps, y = theta.post)
+df %>%
+  ggplot() +
+  geom_line(aes(x = x, y = y), size = 1, color = wesanderson::wes_palettes$Zissou1[1]) + 
+  labs(x = ""iterations"", y = ""values from posterior distribution"") + 
+  ylim(0.1, 0.6) + 
+  geom_hline(aes(yintercept = mean(theta.post), linetype = ""posterior mean"")) + 
+  scale_linetype_manual(name = """", values = c(2,2)) 
+```
+
+This is what we're after, a trace plot that looks like a beautiful lawn, see Section \@ref(convergence-diag). I find it informative to look at the animated version of Figure \@ref(fig:longchain), it helps understanding the stochastic behavior of the algorithm, and also to realise how the chains converge to their stationary distribution, see Figure \@ref(fig:animlongchain).
+
+```{r echo = FALSE, eval = FALSE}
+# load packages
+library(tidyverse)
+theme_set(theme_light(base_size = 16))
+library(gganimate)
+library(magick)
+
+# deer data, 19 ""success"" out of 57 ""attempts""
+survived <- 19
+released <- 57
+
+#---------- apply Metropolis
+
+steps <- 1000
+chain1 <- metropolis(steps = steps, inits = 0.2)
+chain2 <- metropolis(steps = steps, inits = 0.5)
+chain3 <- metropolis(steps = steps, inits = 0.7)
+
+df <- data.frame(iter = rep(1:steps, 3), 
+                 value = c(chain1, chain2, chain3),
+                 chain = c(rep(""chain1"", steps), 
+                           rep(""chain2"", steps), 
+                           rep(""chain3"", steps)))
+
+#---------- time series
+static_tsplot <- df %>%
+  mutate(posterior_mean = mean(value)) %>%
+  ggplot(aes(x = iter, y = value, group = chain, color = chain)) +
+  geom_line(size = 1, alpha = 0.5) + 
+  geom_hline(aes(yintercept = posterior_mean, linetype = ""posterior mean"")) + 
+  scale_linetype_manual(name = """", values = c(2,2)) + 
+  labs(color = """", x = ""iterations"", y = ""survival"")
+static_tsplot  
+  
+# animate
+animated_tsplot <- static_tsplot +
+  transition_reveal(along = iter, 
+                    range = as.integer(c(1, max(df$iter) + 50))) # trick to pause
+animated_tsplot  
+
+# save
+a_gif <- animate(animated_tsplot,
+                 width = 6, 
+                 height = 3,
+                 res = 600,
+                 units = ""in"")
+
+# get file in directory str(a_gif)
+```
+```{r animlongchain, echo = FALSE, out.width=""100%"", fig.align='center', fig.cap = ""Animated trace plot of survival with three chains starting at 0.2, 0.5 and 0.7 run for 1000 steps.""}
+knitr::include_graphics(""images/traceplotMCMC.gif"")
+```
+
+Once the stationary distribution is reached, you may regard the realisations of the Markov chain as a sample from the posterior distribution, and obtain numerical summaries. In the next section, we consider several important implementation issues. 
+
+## Assessing convergence {#convergence-diag}
+
+```{block2 convergence, type='rmdnote'}
+When implementing MCMC, we need to determine how long it takes for our Markov chain to converge to the target distribution, and the number of iterations we need after achieving convergence to get reasonable Monte Carlo estimates of numerical summaries (posterior means and credible intervals).
+```
+
+### Burn-in
+  
+In practice, we discard observations from the start of the Markov chain and just use observations from the chain once it has converged. The initial observations that we discard are usually referred to as the *burn-in*. 
+
+The simplest method to determine the length of the burn-in period is to look at trace plots. Going back to our example, we see from the trace plot in Figure \@ref(fig:burnin) that we need at least 100 iterations to achieve convergence toward an average survival around 0.3. It is always better to be conservative when specifying the length of the burn-in period, and in this example, we would use 250 or even 500 iterations as a burn-in. The length of the burn-in period can be determined by performing preliminary MCMC short runs. 
+
+```{r burnin, echo = FALSE, fig.cap = ""Determining the length of the burn-in period. The chain starts at value 0.99 and rapidly stabilises, with values bouncing back and forth around 0.3 from the 100th iteration onwards. You may choose the shaded area as the burn-in, and discard the corresponding values.""}
+
+# set up the scene
+steps <- 1000
+theta.post <- metropolis(steps = steps, inits = 0.99)
+df <- data.frame(x = 1:steps, y = theta.post)
+df %>%
+  ggplot() +
+  geom_line(aes(x = x, y = y), size = 1.2, color = wesanderson::wes_palettes$Zissou1[1]) + 
+  labs(x = ""iterations"", y = ""survival"") + 
+  theme_light(base_size = 14) + 
+  annotate(""rect"", 
+           xmin = 0, 
+           xmax = 100, 
+           ymin = 0.1, 
+           ymax = 1, 
+           alpha = .3) +
+  scale_y_continuous(expand = c(0,0))
+```
+
+Inspecting the trace plot for a single run of the Markov chain is useful. However, we usually run the Markov chain several times, starting from different over-dispersed points, to check that all runs achieve the same stationary distribution. This approach is formalised by using the Brooks-Gelman-Rubin (BGR) statistic $\hat{R}$ which measures the ratio of the total variability combining multiple chains (between-chain plus within-chain) to the within-chain variability. The BGR statistic asks whether there is a chain effect, and is very much alike the $F$ test in an analysis of variance. Values below 1.1 indicate likely convergence.
+
+```{r, echo = FALSE, cache = TRUE}
+simul.bgr <- function(steps, inits){
+  
+  nb.replicates <- length(inits)
+  theta.post <- matrix(NA, nrow = nb.replicates, ncol = steps)
+  for (i in 1:nb.replicates){
+    theta.post[i,1:steps] <- metropolis(steps = steps, inits = inits[i])
+  }
+  
+  df <- data.frame(x = rep(1:steps, nb.replicates), 
+                   y = c(t(theta.post)), 
+                   chain = paste0(""chain "",gl(nb.replicates, steps))) %>%
+    filter(x > round(steps/2)) # apply burnin (half number of iterations)
+
+  # compute BGR (R-hat)
+  num <- quantile(df$y, probs = c(20/100, 80/100))[2] - quantile(df$y, probs = c(20/100, 80/100))[1]
+  den <- df %>%
+    group_by(chain) %>%
+    summarise(ci = quantile(y, probs = c(20/100, 80/100))) %>%
+    mutate(diff = ci - lag(ci, default = ci[1])) %>%
+    filter(diff != 0) %>%
+    pull(diff) %>%
+    mean()
+  
+  bgr <- round(num / den, 3)
+  return(bgr)
+}
+
+set.seed(1234)
+steps <- seq(100, 5000, 100)
+bgr <- rep(NA, length(steps))
+for (i in 1:length(steps)){
+  bgr[i] <- simul.bgr(steps = steps[i], inits = c(0.2, 0.8))
+}
+df <- data.frame(iterations = steps, bgr = bgr)
+```
+
+Back to our example, we run two Markov chains with starting values 0.2 and 0.8 using 100 up to 5000 iterations, and calculate the BGR statistic using half the number of iterations as the length of the burn-in. From Figure \@ref(fig:bgr), we get a value of the BGR statistic near 1 by up to 2000 iterations, which suggests that with 2000 iterations as a burn-in, there is no evidence of a lack of convergence. 
+
+```{r bgr, echo=FALSE, fig.cap = ""Brooks-Gelman-Rubin statistic as a function of the number of iterations.""}
+df %>%
+  ggplot() + 
+  geom_line(aes(x = iterations, y = bgr), size = 1.2) +
+  labs(y = ""BGR statistic"")
+```
+
+It is important to bear in mind that a value near 1 for the BGR statistic is only a necessary *but not sufficient* condition for convergence. In other words, this diagnostic cannot tell you for sure that the Markov chain has achieved convergence, only that it has not.^[Cross-reference sections on local minima and parameter redundancy for pathological cases.]
+
+### Chain length
+  
+```{r, echo = FALSE}
+# inspired from https://bookdown.org/content/3686/markov-chain-monte-carlo.html
+
+n_steps <- 10000
+
+d <-
+  tibble(away = c(0.1, 1, 10)) %>% 
+  mutate(accepted_traj = map(away, metropolis, steps = n_steps, inits = 0.1)) %>% 
+  unnest(accepted_traj)
+
+d <-
+  d %>% 
+  mutate(proposal_sd = str_c(""Proposal SD = "", away),
+         iter        = rep(1:n_steps, times = 3))
+
+trace <- d %>% 
+  ggplot(aes(y = accepted_traj, x = iter)) +
+  geom_path(size = 1/4, color = ""steelblue"") +
+  geom_point(size = 1/2, alpha = 1/2, color = ""steelblue"") +
+  scale_y_continuous(""survival"", breaks = 0:5 * 0.1, limits = c(0.15, 0.5)) +
+  scale_x_continuous(""iterations"", 
+                     breaks = seq(n_steps-n_steps*10/100,n_steps,by = 600), 
+                     limits = c(n_steps-n_steps*10/100, n_steps)) +
+  facet_wrap(~proposal_sd, ncol = 3) +
+  theme_light(base_size = 14)
+
+library(forecast)
+plot1 <- ggAcf(x = d$accepted_traj[d$proposal_sd==""Proposal SD = 0.1""]) + ggtitle(""Proposal SD = 0.1"")
+plot2 <- ggAcf(x = d$accepted_traj[d$proposal_sd==""Proposal SD = 1""]) + ggtitle(""Proposal SD = 1"")
+plot3 <- ggAcf(x = d$accepted_traj[d$proposal_sd==""Proposal SD = 10""]) + ggtitle(""Proposal SD = 10"")
+```
+
+How long of a chain is needed to produce reliable parameter estimates? To answer this question, you need to keep in mind that successive steps in a Markov chain are not independent -- this is usually referred to as *autocorrelation*. Ideally, we would like to keep autocorrelation as low as possible. Here again, trace plots are useful to diagnose issues with autocorrelation. Let's get back to our survival example. Figure \@ref(fig:tracechainlength) shows trace plots for different values of the standard deviation (parameter *away*) of the (normal) proposal distribution we use to propose a candidate value (Section \@ref(metropolis-algorithm)). Small and big moves provide high correlations between successive observations of the Markov chain, whereas a standard deviation of 1 allows efficient exploration of the parameter space. The movement around the parameter space is referred to as *mixing*. Mixing is bad when the chain makes small and big moves, and good otherwise. 
+
+```{r tracechainlength, echo=FALSE, fig.cap = ""Trace plots for different values of the standard deviation (SD) of the proposal distribution. Left: The chain exhibits small moves and mixing is bad. Right: The chain exhibits big moves and mixing is bad. Middle: The chain exhibits adequate moves and mixing is good. Only the thousand last iterations are shown.""}
+trace
+```
+
+In addition to trace plots, autocorrelation function (ACF) plots are a convenient way of displaying the strength of autocorrelation in a given sample values. ACF plots provide the autocorrelation between successively sampled values separated by an increasing number of iterations, or *lag* (Figure \@ref(fig:acfchainlength)).
+
+```{r acfchainlength, echo=FALSE, fig.cap = ""Autocorrelation function plots for different values of the standard deviation (SD) of the proposal distribution. Left and right: Autocorrelation is strong, decreases slowly with increasing lag and mixing is bad. Middle: Autocorrelation is weak, decreases rapidly with increasing lag and mixing is good.""}
+library(patchwork)
+(plot1 + plot2 + plot3)
+```
+
+Autocorrelation is not necessarily a big issue. Strongly correlated observations just require large sample sizes and therefore longer simulations. But how many iterations exactly? The effective sample size (`n.eff`) measures chain length while taking into account chain autocorrelation. You should check the `n.eff` of every parameter of interest, and of any interesting parameter combinations. In general, we need $\text{n.eff} \geq 1000$ independent steps to get reasonable Monte Carlo estimates of model parameters. In the animal survival example, `n.eff` can be calculated with the R `coda::effectiveSize()` function.
+```{r neff, echo = FALSE}
+neff1 <- coda::effectiveSize(d$accepted_traj[d$proposal_sd==""Proposal SD = 0.1""])
+neff2 <- coda::effectiveSize(d$accepted_traj[d$proposal_sd==""Proposal SD = 1""])
+neff3 <- coda::effectiveSize(d$accepted_traj[d$proposal_sd==""Proposal SD = 10""])
+df <- tibble(""Proposal SD"" = c(0.1, 1, 10),
+                 ""n.eff"" = round(c(neff1, neff2, neff3)))
+knitr::kable(df, format = ""markdown"")
+```
+
+As expected, `n.eff` is less than the number of MCMC iterations because of autocorrelation. Only when the standard deviation of the proposal distribution is 1 and mixing is good (Figures \@ref(fig:tracechainlength) and \@ref(fig:acfchainlength)) we get a satisfying effective sample size. 
+
+### What if you have issues of convergence?
+  
+When diagnosing MCMC convergence, you will (very) often run into troubles. In this section you will find some helpful tips I hope. 
+
+When mixing is bad and effective sample size is small, you may just need to increase burn-in and/or sample more. Using more informative priors might also make Markov chains converge faster by helping your MCMC sampler (e.g. the Metropolis algorithm) navigating more efficiently the parameter space. In the same spirit, picking better initial values for starting the chain does not harm. For doing that, a strategy consists in using estimates from a simpler model for which your MCMC chains do converge. 
+
+If convergence issues persist, often there is a problem with your model^[The quote 'When you have computational problems, often there's a problem with your model' is the folk theorem of statistical computing stated by Andrew Gelman in 2008, see https://statmodeling.stat.columbia.edu/2008/05/13/the_folk_theore/]. A bug in the code? A typo somewhere? A mistake in your maths? As often when coding is involved, the issue can be identified by removing complexities, and start with a simpler model until you find what the problem is. 
+
+A general advice is to see your model as a data generating tool in the first place, simulate data from it using some realistic values for the parameters, and try to recover these parameter values by fitting the model to the simulated data. Simulating from a model will help you understanding how it works, what it does not do, and the data you need to get reasonable parameter estimates. 
+
+We will see other strategies to improve convergence in the next chapters.^[Cross reference relevant chapters. Option 1. Change your sampler. Option 2. Reparameterize (standardize covariates, plus non-centering: $\alpha \sim N(0,\sigma)$ becomes $\alpha = z \sigma$ with $z \sim N(0,1)$).]
+
+## Summary
+
++ With the Bayes' theorem, you update your beliefs (prior) with new data (likelihood) to get posterior beliefs (posterior): posterior $\propto$ likelihood $\times$ prior.
+
++ The idea of Markov chain Monte Carlo (MCMC) is to simulate values from a Markov chain which has a stationary distribution equal to the posterior distribution you're after. 
+
++ In practice, you run a Markov chain multiple times starting from over-dispersed initial values. 
+
++ You discard iterations in an initial burn-in phase and achieve convergence when all chains reach the same regime. 
+
++ From there, you run the chains long enough and proceed with calculating Monte Carlo estimates of numerical summaries (e.g. posterior means and credible intervals) for parameters.
+
+## Suggested reading
+
++ Gelman, A. and Hill, J. (2006). [Data Analysis Using Regression and Multilevel/Hierarchical Models (Analytical Methods for Social Research)](https://www.cambridge.org/core/books/data-analysis-using-regression-and-multilevelhierarchical-models/32A29531C7FD730C3A68951A17C9D983). Cambridge: Cambridge University Press.
+
++ Gelman, A. and colleagues (2020). [Bayesian workflow](https://arxiv.org/pdf/2011.01808.pdf). arXiv preprint. 
++ McCarthy, M. (2007). [Bayesian Methods for Ecology](https://www.cambridge.org/core/books/bayesian-methods-for-ecology/9225F65B8A25D69B0B6C50B5A9A78201). Cambridge: Cambridge University Press.
+
++ McElreath, R. (2020). [Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2nd ed.)](https://xcelab.net/rm/statistical-rethinking/). CRC Press.
+

---FILE: bayesmcmcdraft.Rmd---
@@ -0,0 +1,2 @@
+# Bayesian statistics & MCMC {#crashcourse}
+

---FILE: docs/404.html---
@@ -49,17 +49,17 @@ <h1>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
 <li><a class="""" href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></li>
 <li><a class="""" href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></li>
 <li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></li>
 <li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
 <li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></li>
 <li><a class="""" href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></li>
 <li><a class="""" href=""stopover.html""><span class=""header-section-number"">12</span> Stopover duration</a></li>
@@ -94,14 +94,42 @@ <h1>Page not found<a class=""anchor"" aria-label=""anchor"" href=""#page-not-found""><
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
 </body>
 </html>

---FILE: docs/about-the-author.html---
@@ -49,17 +49,17 @@ <h1>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
 <li><a class="""" href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></li>
 <li><a class="""" href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></li>
 <li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></li>
 <li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
 <li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></li>
 <li><a class="""" href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></li>
 <li><a class="""" href=""stopover.html""><span class=""header-section-number"">12</span> Stopover duration</a></li>
@@ -109,14 +109,42 @@ <h1>About the author<a class=""anchor"" aria-label=""anchor"" href=""#about-the-autho
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
 </body>
 </html>

---FILE: docs/abundance.html---
@@ -49,17 +49,17 @@ <h1>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
 <li><a class="""" href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></li>
 <li><a class="""" href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></li>
 <li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></li>
 <li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
 <li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></li>
 <li><a class=""active"" href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></li>
 <li><a class="""" href=""stopover.html""><span class=""header-section-number"">12</span> Stopover duration</a></li>
@@ -125,14 +125,42 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
 </body>
 </html>

---FILE: docs/covariates.html---
@@ -49,17 +49,17 @@ <h1>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
 <li><a class=""active"" href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></li>
 <li><a class="""" href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></li>
 <li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></li>
 <li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
 <li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></li>
 <li><a class="""" href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></li>
 <li><a class="""" href=""stopover.html""><span class=""header-section-number"">12</span> Stopover duration</a></li>
@@ -103,14 +103,42 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
 </body>
 </html>

---FILE: docs/crashcourse.html---
@@ -6,15 +6,15 @@
 <meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <title>Chapter 1 Bayesian statistics &amp; MCMC | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</title>
 <meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<meta name=""description"" content=""1.1 Introduction In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to..."">
 <meta name=""generator"" content=""bookdown 0.23 with bs4_book()"">
 <meta property=""og:title"" content=""Chapter 1 Bayesian statistics &amp; MCMC | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R"">
 <meta property=""og:type"" content=""book"">
 <meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/crashcourse.html"">
-<meta property=""og:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<meta property=""og:description"" content=""1.1 Introduction In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to..."">
 <meta name=""twitter:card"" content=""summary"">
 <meta name=""twitter:title"" content=""Chapter 1 Bayesian statistics &amp; MCMC | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R"">
-<meta name=""twitter:description"" content=""This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."">
+<meta name=""twitter:description"" content=""1.1 Introduction In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to..."">
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.10/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.2.5.1/tabs.js""></script><script src=""libs/bs3compat-0.2.5.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
@@ -49,17 +49,17 @@ <h1>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
 <li><a class="""" href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></li>
 <li><a class="""" href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></li>
 <li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></li>
 <li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
 <li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></li>
 <li><a class="""" href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></li>
 <li><a class="""" href=""stopover.html""><span class=""header-section-number"">12</span> Stopover duration</a></li>
@@ -79,14 +79,471 @@ <h1>
 <h1>
 <span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC<a class=""anchor"" aria-label=""anchor"" href=""#crashcourse""><i class=""fas fa-link""></i></a>
 </h1>
+<div id=""introduction-1"" class=""section level2"" number=""1.1"">
+<h2>
+<span class=""header-section-number"">1.1</span> Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-1""><i class=""fas fa-link""></i></a>
+</h2>
+<p>In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to implement the Bayesian method for more complex analyses. This is not an exhaustive treatment of Bayesian statistics, but you should get what you need to navigate through the rest of the book.</p>
+</div>
+<div id=""bayes-theorem"" class=""section level2"" number=""1.2"">
+<h2>
+<span class=""header-section-number"">1.2</span> Bayes‚Äô theorem<a class=""anchor"" aria-label=""anchor"" href=""#bayes-theorem""><i class=""fas fa-link""></i></a>
+</h2>
+<p>Let‚Äôs not wait any longer and jump into it. Bayesian statistics relies on the Bayes‚Äô theorem (or law, or rule, whatever you prefer) named after Reverend Thomas Bayes (Figure <a href=""crashcourse.html#fig:revbayes"">1.1</a>). This theorem was published in 1763 two years after Bayes‚Äô death thanks to his friend‚Äôs efforts Richard Price, and was independently discovered by Pierre-Simon Laplace <span class=""citation"">(<a href=""references.html#ref-mcgrayne2011"" role=""doc-biblioref"">McGrayne 2011</a>)</span>.</p>
+<div class=""figure"" style=""text-align: center"">
+<span style=""display:block;"" id=""fig:revbayes""></span>
+<img src=""images/amazing-thomas-bayes-illustration.jpg"" alt=""Cartoon of Thomas Bayes with Bayes' theorem in background. Source: [James Kulich](https://www.elmhurst.edu/blog/thomas-bayes/)"" width=""100%""><p class=""caption"">
+Figure 1.1: Cartoon of Thomas Bayes with Bayes‚Äô theorem in background. Source: <a href=""https://www.elmhurst.edu/blog/thomas-bayes/"">James Kulich</a>
+</p>
+</div>
+<p>As we will see in a minute, Bayes‚Äô theorem is all about conditional probabilities, which are somehow tricky to understand. Conditional probability of outcome or event A given event B, which we denote <span class=""math inline"">\(\Pr(A \mid B)\)</span>, is the probability that A occurs, revised by considering the additional information that event B has occurred.<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;For example, a friend of yours rolls a fair dice and asks you the probability that the outcome was a six (event A). Your answer is 1/6 because each side of the dice is equally likely to come up. Now imagine that you‚Äôre told the number rolled was even (event B) before you answer your friend‚Äôs question. Because there are only three even numbers, one of which is six, you may revise your answer for the probability that a six was rolled from 1/6 to &lt;span class=""math inline""&gt;\(\Pr(A \mid B) = 1/3\)&lt;/span&gt;.&lt;/p&gt;'><sup>2</sup></a> The order in which A and B appear is important, make sure you do not confuse <span class=""math inline"">\(\Pr(A \mid B)\)</span> and <span class=""math inline"">\(\Pr(B \mid A)\)</span>.</p>
+<p>Bayes‚Äô theorem (Figure <a href=""crashcourse.html#fig:bayestheorem"">1.2</a>) gives you <span class=""math inline"">\(\Pr(A \mid B)\)</span> using marginal probabilities <span class=""math inline"">\(\Pr(A)\)</span> and <span class=""math inline"">\(\Pr(B)\)</span> and <span class=""math inline"">\(\Pr(B \mid A)\)</span>:
+<span class=""math display"">\[\Pr(A \mid B) = \displaystyle{\frac{ \Pr(B \mid A) \; \Pr(A)}{\Pr(B)}}.\]</span>
+Originally, Bayes‚Äô theorem was seen as a way to infer an unkown cause A of a particular effect B, knowing the probability of effect B given cause A. Think for example of a situation where a medical diagnosis is needed, with A an unkown disease and B symptoms, the doctor knows P(symptoms|disease) and wants to derive P(disease|symptoms). This way of reversing <span class=""math inline"">\(\Pr(B \mid A)\)</span> into <span class=""math inline"">\(\Pr(A \mid B)\)</span> explains why Bayesian thinking used to be referred to as ‚Äòinverse probability.‚Äô</p>
+<div class=""figure"" style=""text-align: center"">
+<span style=""display:block;"" id=""fig:bayestheorem""></span>
+<img src=""images/bayes_neon.jpeg"" alt=""Bayes' theorem spelt out in blue neon. Source: [Wikipedia](https://en.wikipedia.org/wiki/Bayes%27_theorem)"" width=""400""><p class=""caption"">
+Figure 1.2: Bayes‚Äô theorem spelt out in blue neon. Source: <a href=""https://en.wikipedia.org/wiki/Bayes%27_theorem"">Wikipedia</a>
+</p>
+</div>
+<p>I don‚Äôt know about you, but I need to think twice for not messing the letters around. I find it easier to remember Bayes‚Äô theorem written like this<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;When teaching Bayes‚Äô theorem, I am very much inspired by Tristan Mahr‚Äôs slides from his introduction to Bayesian regression &lt;a href=""https://www.tjmahr.com/bayes-intro-lecture-slides-2017/"" class=""uri""&gt;https://www.tjmahr.com/bayes-intro-lecture-slides-2017/&lt;/a&gt;&lt;/p&gt;'><sup>3</sup></a>:</p>
+<span class=""math display"">\[ \Pr(\text{hypothesis} \mid \text{data}) = \frac{ \Pr(\text{data} \mid \text{hypothesis}) \; \Pr(\text{hypothesis})}{\Pr(\text{data})} \]</span>
+
+<div class=""rmdnote"">
+The <em>hypothesis</em> is a working assumption about which you want to learn using <em>data</em>. In capture‚Äìrecapture analyses, the hypothesis might be a parameter like detection probability, or regression parameters in a relationship between survival probability and a covariate. Bayes‚Äô theorem tells us how to obtain the probability of a hypothesis given the data we have.
+</div>
+<p>This is great because think about it, this is exactly what the scientific method is! We‚Äôd like to know how plausible some hypothesis is based on some data we collected, and possibly compare several hypotheses among them. In that respect, the Bayesian reasoning matches the scientific reasoning, which probably explains why the Bayesian framework is so natural for doing and understanding statistics.</p>
+<p>You might ask then, why is Bayesian statistics not the default in statistics? Clearly, because of futile wars between male statisticians (including Ronald Fisher, Jerzy Neyman and Egon Sharpe Pearson among others), little progress was made for over two centuries. Also, until recently, there were practical problems to implement Bayes‚Äô theorem. Recent advances in computational power coupled with the development of new algorithms have led to a great increase in the application of Bayesian methods within the last three decades.</p>
+</div>
+<div id=""what-is-the-bayesian-approach"" class=""section level2"" number=""1.3"">
+<h2>
+<span class=""header-section-number"">1.3</span> What is the Bayesian approach?<a class=""anchor"" aria-label=""anchor"" href=""#what-is-the-bayesian-approach""><i class=""fas fa-link""></i></a>
+</h2>
+<p>Typical statistical problems involve estimating a parameter (or several parameters) <span class=""math inline"">\(\theta\)</span> with available data. To do so, you might be more used to the frequentist rather than the Bayesian method. The frequentist approach, and in particular maximum likelihood estimation (MLE), assumes that the parameters are fixed, and have unknown values to be estimated. Therefore classical estimates are generally point estimates of the parameters of interest. In contrast, the Bayesian approach assumes that the parameters are not fixed, and have some unknown distribution<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;A probability distribution is a mathematical expression that gives the probability for a random variable to take particular values. A probability distribution may be either discrete (e.g., the Bernoulli, Binomial or Poisson distribution) or continuous (e.g., the Gaussian distribution also known as the normal distribution)&lt;/p&gt;""><sup>4</sup></a>.</p>
+<p>The Bayesian approach is based upon the idea that you, as an experimenter, begin with some prior beliefs about the system. Then you collect data and update your prior beliefs on the basis of observations. These observations might arise from field work, lab work or from expertise of your esteemed colleagues. This updating process is based upon Bayes‚Äô theorem. Loosely, let‚Äôs say <span class=""math inline"">\(A = \theta\)</span> and <span class=""math inline"">\(B = \text{data}\)</span>, then Bayes‚Äô theorem gives you a way to estimate parameter <span class=""math inline"">\(\theta\)</span> given the data you have:</p>
+<p><span class=""math display"">\[{\color{red}{\Pr(\theta \mid \text{data})}} = \frac{\color{blue}{\Pr(\text{data} \mid \theta)} \times \color{green}{\Pr(\theta)}}{\color{orange}{\Pr(\text{data})}}.\]</span>
+Let‚Äôs spend some time going through each quantity in this formula.</p>
+<p>On the left-hand side is the <span class=""math inline"">\(\color{red}{\text{posterior distribution}}\)</span>. It represents what you know after having seen the data. This is the basis for inference and clearly what you‚Äôre after, a distribution, possibly multivariate if you have more than one parameter.</p>
+<p>On the right-hand side, there is the <span class=""math inline"">\(\color{blue}{\text{likelihood}}\)</span>. This quantity is the same as in the MLE approach. Yes, the Bayesian and frequentist approaches have the same likelihood at their core, which mostly explains why results often do not differ much. The likelihood captures the information you have in your data, given a model parameterized with <span class=""math inline"">\(\theta\)</span>.</p>
+<p>Then we have the <span class=""math inline"">\(\color{green}{\text{prior distribution}}\)</span>. This quantity represents what you know before seeing the data. This is the source of much discussion about the Bayesian approach. It may be vague if you don‚Äôt know anything about <span class=""math inline"">\(\theta\)</span>. Usually however, you never start from scratch, and you‚Äôd like your prior to reflect the information you have<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;Shall I include a section on sensitivity analyses in this chapter or later in the book? Cross-reference section in Survival chapter where prior elicitation is covered.&lt;/p&gt;""><sup>5</sup></a>.</p>
+<p>Last, we have <span class=""math inline"">\(\color{orange}{\Pr(\text{data})}\)</span> which is sometimes called the average likelihood because it is obtained by integrating the likelihood with respect to the prior <span class=""math inline"">\(\color{orange}{\Pr(\text{data}) = \int{L(\text{data} \mid \theta)\Pr(\theta) d\theta}}\)</span> so that the posterior is standardized, that is it integrates to one for the posterior to be a distribution. The average likelihood is an integral with dimension the number of parameters <span class=""math inline"">\(\theta\)</span> you need to estimate. This quantity is difficult, if not impossible, to calculate in general. This is one of the reasons why the Bayesian method wasn‚Äôt used until recently, and why we need algorithms to estimate posterior distributions as I illustrate in the next section.</p>
+</div>
+<div id=""numerical-approx"" class=""section level2"" number=""1.4"">
+<h2>
+<span class=""header-section-number"">1.4</span> Approximating posteriors via numerical integration<a class=""anchor"" aria-label=""anchor"" href=""#numerical-approx""><i class=""fas fa-link""></i></a>
+</h2>
+<p>Let‚Äôs take an example to illustrate Bayes‚Äô theorem. Say we capture, mark and release <span class=""math inline"">\(n = 57\)</span> animals at the beginning of a winter, out of which we recapture <span class=""math inline"">\(y = 19\)</span> animals alive<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;We used a similar example in &lt;span class=""citation""&gt;&lt;a href=""references.html#ref-king_bayesian_2009"" role=""doc-biblioref""&gt;King et al.&lt;/a&gt; (&lt;a href=""references.html#ref-king_bayesian_2009"" role=""doc-biblioref""&gt;2009&lt;/a&gt;)&lt;/span&gt;&lt;/p&gt;'><sup>6</sup></a>. We‚Äôd like to estimate winter survival <span class=""math inline"">\(\theta\)</span>.</p>
+<div class=""sourceCode"" id=""cb2""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""va"">y</span> <span class=""op"">&lt;-</span> <span class=""fl"">19</span> <span class=""co""># nb of success</span>
+<span class=""va"">n</span> <span class=""op"">&lt;-</span> <span class=""fl"">57</span> <span class=""co""># nb of attempts</span></code></pre></div>
+<p>We build our model first. Assuming all animals are independent of each other and have the same survival probability, then <span class=""math inline"">\(y\)</span> the number of alive animals at the end of the winter is a binomial distribution<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;I follow &lt;span class=""citation""&gt;&lt;a href=""references.html#ref-mcelreathbook"" role=""doc-biblioref""&gt;McElreath&lt;/a&gt; (&lt;a href=""references.html#ref-mcelreathbook"" role=""doc-biblioref""&gt;2016&lt;/a&gt;)&lt;/span&gt; and use labels on the right to help remember what each line is about.&lt;/p&gt;'><sup>7</sup></a> with <span class=""math inline"">\(n\)</span> trials and <span class=""math inline"">\(\theta\)</span> the probability of success:</p>
+<p><span class=""math display"">\[\begin{align*}
+y &amp;\sim \text{Binomial}(n, \theta) &amp;\text{[likelihood]}
+\end{align*}\]</span></p>
+<p>This likelihood can be visualised in <code>R</code>:</p>
+<div class=""sourceCode"" id=""cb3""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""va"">grid</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/seq.html"">seq</a></span><span class=""op"">(</span><span class=""fl"">0</span>, <span class=""fl"">1</span>, <span class=""fl"">0.01</span><span class=""op"">)</span> <span class=""co""># grid of values for survival</span>
+<span class=""va"">likelihood</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Binomial.html"">dbinom</a></span><span class=""op"">(</span><span class=""va"">y</span>, <span class=""va"">n</span>, <span class=""va"">grid</span><span class=""op"">)</span> <span class=""co""># compute binomial likelihood</span>
+<span class=""va"">df</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/data.frame.html"">data.frame</a></span><span class=""op"">(</span>survival <span class=""op"">=</span> <span class=""va"">grid</span>, likelihood <span class=""op"">=</span> <span class=""va"">likelihood</span><span class=""op"">)</span> 
+<span class=""va"">df</span> <span class=""op"">%&gt;%</span>
+  <span class=""fu"">ggplot</span><span class=""op"">(</span><span class=""op"">)</span> <span class=""op"">+</span> 
+  <span class=""fu"">aes</span><span class=""op"">(</span>x <span class=""op"">=</span> <span class=""va"">survival</span>, y <span class=""op"">=</span> <span class=""va"">likelihood</span><span class=""op"">)</span> <span class=""op"">+</span> 
+  <span class=""fu"">geom_line</span><span class=""op"">(</span>size <span class=""op"">=</span> <span class=""fl"">1.5</span><span class=""op"">)</span></code></pre></div>
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:binlik""></span>
+<img src=""banana-book_files/figure-html/binlik-1.png"" alt=""Binomial likelihood with $n = 57$ released animals and $y = 19$ survivors after winter. The value of survival (on the x-axis) that corresponds to the maximum of the likelihood function (on the y-axis) is the MLE, or the proportion of success in this example, close to 0.33."" width=""672""><p class=""caption"">
+Figure 1.3: Binomial likelihood with <span class=""math inline"">\(n = 57\)</span> released animals and <span class=""math inline"">\(y = 19\)</span> survivors after winter. The value of survival (on the x-axis) that corresponds to the maximum of the likelihood function (on the y-axis) is the MLE, or the proportion of success in this example, close to 0.33.
+</p>
+</div>
+<p>Besides the likelihood, priors are another component of the model in the Bayesian approach. For a parameter that is a probability, the one thing we know is that the prior should be a continuous random variable that lies between 0 and 1. To reflect that, we often go for the uniform distribution <span class=""math inline"">\(U(0,1)\)</span> to imply <em>vague</em> priors. Here vague means that survival has, before we see the data, the same probability of falling between 0.1 and 0.2 and between 0.8 and 0.9, for example.</p>
+<p><span class=""math display"">\[\begin{align*}
+\theta &amp;\sim \text{Uniform}(0, 1) &amp;\text{[prior for }\theta \text{]}
+\end{align*}\]</span></p>
+<p>Now we apply Bayes‚Äô theorem. We write a <code>R</code> function that computes the product of the likelihood times the prior, or the numerator in Bayes‚Äô theorem: <span class=""math inline"">\(\Pr(\text{data} \mid \theta) \times \Pr(\theta)\)</span></p>
+<div class=""sourceCode"" id=""cb4""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""va"">numerator</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">theta</span><span class=""op"">)</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Binomial.html"">dbinom</a></span><span class=""op"">(</span><span class=""va"">y</span>, <span class=""va"">n</span>, <span class=""va"">theta</span><span class=""op"">)</span> <span class=""op"">*</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Uniform.html"">dunif</a></span><span class=""op"">(</span><span class=""va"">theta</span>, <span class=""fl"">0</span>, <span class=""fl"">1</span><span class=""op"">)</span></code></pre></div>
+<p>We write another function that calculates the denominator, the average likelihood: <span class=""math inline"">\(\Pr(\text{data}) = \int{L(\theta \mid \text{data}) \Pr(\theta) d\theta}\)</span></p>
+<div class=""sourceCode"" id=""cb5""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""va"">denominator</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/integrate.html"">integrate</a></span><span class=""op"">(</span><span class=""va"">numerator</span>,<span class=""fl"">0</span>,<span class=""fl"">1</span><span class=""op"">)</span><span class=""op"">$</span><span class=""va"">value</span></code></pre></div>
+<p>We use the <code>R</code> function <code>integrate</code> to calculate the integral in the denominator, which implements quadrature techniques to divide in little squares the area underneath the curve delimited by the function to integrate (here the numerator), and count them.</p>
+<p>Then we get a numerical approximation of the posterior in Figure <a href=""crashcourse.html#fig:numapprox"">1.4</a> by applying Bayes‚Äô theorem.</p>
+<div class=""sourceCode"" id=""cb6""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""va"">grid</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/seq.html"">seq</a></span><span class=""op"">(</span><span class=""fl"">0</span>, <span class=""fl"">1</span>, <span class=""fl"">0.01</span><span class=""op"">)</span> <span class=""co""># grid of values for theta</span>
+<span class=""va"">numerical_posterior</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/data.frame.html"">data.frame</a></span><span class=""op"">(</span>survival <span class=""op"">=</span> <span class=""va"">grid</span>, 
+                                  posterior <span class=""op"">=</span> <span class=""fu"">numerator</span><span class=""op"">(</span><span class=""va"">grid</span><span class=""op"">)</span><span class=""op"">/</span><span class=""va"">denominator</span><span class=""op"">)</span> <span class=""co""># Bayes' theorem</span>
+<span class=""va"">numerical_posterior</span> <span class=""op"">%&gt;%</span>
+  <span class=""fu"">ggplot</span><span class=""op"">(</span><span class=""op"">)</span> <span class=""op"">+</span>
+  <span class=""fu"">aes</span><span class=""op"">(</span>x <span class=""op"">=</span> <span class=""va"">survival</span>, y <span class=""op"">=</span> <span class=""va"">posterior</span><span class=""op"">)</span> <span class=""op"">+</span> 
+  <span class=""fu"">geom_line</span><span class=""op"">(</span>size <span class=""op"">=</span> <span class=""fl"">1.5</span><span class=""op"">)</span></code></pre></div>
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:numapprox""></span>
+<img src=""banana-book_files/figure-html/numapprox-1.png"" alt=""Winter survival posterior distribution obtained by numerical integration."" width=""672""><p class=""caption"">
+Figure 1.4: Winter survival posterior distribution obtained by numerical integration.
+</p>
+</div>
+<p>How good is our numerical approximation of survival posterior distribution? Ideally, we would want to compare the approximation to the true posterior distribution. Although a closed-form expression for the posterior distribution is in general intractable, when you combine a binomial likelihood together with a beta distribution as a prior, then the posterior distribution is also a beta distribution, which makes it amenable to all sorts of exact calculations<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;We say that the beta distribution is the conjugate prior distribution for the binomial distribution.&lt;/p&gt;""><sup>8</sup></a>. The beta distribution is continuous between 0 and 1, and extends the uniform distribution to situations where not all outcomes are equally likely. It has two parameters <span class=""math inline"">\(a\)</span> and <span class=""math inline"">\(b\)</span> that control its shape (Figure <a href=""crashcourse.html#fig:betadistribution"">1.5</a>).</p>
 
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:betadistribution""></span>
+<img src=""banana-book_files/figure-html/betadistribution-1.png"" alt=""The distribution beta(\(a\),\(b\)) for different values of \(a\) and \(b\). Note that for \(a = b = 1\), we get the uniform distribution between 0 and 1 in the top left panel. When \(a\) and \(b\) are equal, the distribution is symmetric, and the bigger \(a\) and \(b\), the more peaked the distribution or the smaller the variance."" width=""672""><p class=""caption"">
+Figure 1.5: The distribution beta(<span class=""math inline"">\(a\)</span>,<span class=""math inline"">\(b\)</span>) for different values of <span class=""math inline"">\(a\)</span> and <span class=""math inline"">\(b\)</span>. Note that for <span class=""math inline"">\(a = b = 1\)</span>, we get the uniform distribution between 0 and 1 in the top left panel. When <span class=""math inline"">\(a\)</span> and <span class=""math inline"">\(b\)</span> are equal, the distribution is symmetric, and the bigger <span class=""math inline"">\(a\)</span> and <span class=""math inline"">\(b\)</span>, the more peaked the distribution or the smaller the variance.
+</p>
+</div>
+If the likelihood of the data <span class=""math inline"">\(y\)</span> is binomial with <span class=""math inline"">\(n\)</span> trials and probability of success <span class=""math inline"">\(\theta\)</span>, and the prior is a beta distribution with parameters <span class=""math inline"">\(a\)</span> and <span class=""math inline"">\(b\)</span>, then the posterior is a beta distribution with parameters <span class=""math inline"">\(a + y\)</span> and <span class=""math inline"">\(b + n - y\)</span><a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;&lt;strong&gt;provide a sketch of the proof&lt;/strong&gt;&lt;/p&gt;""><sup>9</sup></a>. In our example, we have <span class=""math inline"">\(n = 57\)</span> trials and <span class=""math inline"">\(y = 19\)</span> animals that survived and a uniform prior between 0 and 1 or a beta distribution with parameters <span class=""math inline"">\(a = b = 1\)</span>, therefore survival has a beta posterior distribution with parameters 20 and 39. In Figure <a href=""crashcourse.html#fig:compar"">1.6</a>, we superimpose the exact posterior and the numerical approximation. Clearly, the two distributions are indistinguishable, suggesting that the numerical approximation is more than fine.
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:compar""></span>
+<img src=""banana-book_files/figure-html/compar-1.png"" alt=""Comparison of exact (dashed line) vs. numerical approximation (continuous line) of winter survival posterior distribution."" width=""672""><p class=""caption"">
+Figure 1.6: Comparison of exact (dashed line) vs.¬†numerical approximation (continuous line) of winter survival posterior distribution.
+</p>
+</div>
+<!-- To finish up, let's add the prior.  -->
+<!-- ```{r, echo = FALSE} -->
+<!-- ggplot() +  -->
+<!--   geom_line(data = numerical_posterior,  -->
+<!--             aes(x = survival, y = posterior),  -->
+<!--             size = 1.5,  -->
+<!--             col = wesanderson::wes_palettes$Royal1[2],  -->
+<!--             alpha = 0.5) +  -->
+<!--   geom_line(data = dfexpposterior,  -->
+<!--             aes(x = survival, y = explicit_posterior), -->
+<!--             col = wesanderson::wes_palettes$Royal1[3],  -->
+<!--             size = 1.5,  -->
+<!--             linetype = ""dashed"") +  -->
+<!--   geom_line(data = dfprior, -->
+<!--             aes(x = survival, y = prior), -->
+<!--             col = wesanderson::wes_palettes$Royal1[1], -->
+<!--             size = 1.5) -->
+<!-- ``` -->
+<p>In our example, we have a single parameter to estimate, winter survival. This means dealing with a one-dimensional integral in the denominator which is pretty easy with quadrature techniques and the <code>R</code> function <code><a href=""https://rdrr.io/r/stats/integrate.html"">integrate()</a></code>. Now what if we had multiple parameters? For example, imagine you‚Äôd like to fit a capture-recapture model with detection probability <span class=""math inline"">\(p\)</span> and regression parameters <span class=""math inline"">\(\alpha\)</span> and <span class=""math inline"">\(\beta\)</span> for the intercept and slope of a relationship between survival probability and a covariate, then Bayes‚Äô theorem gives you the posterior distribution of all three parameters together:</p>
+<p><span class=""math display"">\[ \Pr(\alpha, \beta, p \mid \text{data}) = \frac{ \Pr(\text{data} \mid \alpha, \beta, p) \times \Pr(\alpha, \beta, p)}{\iiint \, \Pr(\text{data} \mid \alpha, \beta, p) \Pr(\alpha, \beta, p) d\alpha d\beta dp} \]</span>
+There are two computational challenges with this formula. First, do we really wish to calculate a three-dimensional integral? The answer is no, one-dimensional and two-dimensional integrals are so much further we can go with standard methods. Second, we‚Äôre more interested in a posterior distribution for each parameter separately than the joint posterior distribution. The so-called marginal distribution of <span class=""math inline"">\(p\)</span> for example is obtained by integrating over all the other parameters ‚Äì a two-dimensional integral in this example. Now imagine with tens or hundreds of parameters to estimate, these integrals become highly multi-dimensional and simply intractable. In the next section, I introduce powerful simulation methods to circumvent this issue.</p>
+</div>
+<div id=""markov-chain-monte-carlo-mcmc"" class=""section level2"" number=""1.5"">
+<h2>
+<span class=""header-section-number"">1.5</span> Markov chain Monte Carlo (MCMC)<a class=""anchor"" aria-label=""anchor"" href=""#markov-chain-monte-carlo-mcmc""><i class=""fas fa-link""></i></a>
+</h2>
+<p>In the early 1990s, statisticians rediscovered work from the 1950‚Äôs in physics. In a famous paper that would lay the fundations of modern Bayesian statistics (Figure <a href=""crashcourse.html#fig:mcmcpaper"">1.7</a>), the authors use simulations to approximate posterior distributions with some precision by drawing large samples. This is a neat trick to avoid explicit calculation of the multi-dimensional integrals we struggle with when using Bayes‚Äô theorem.</p>
+<div class=""figure"" style=""text-align: center"">
+<span style=""display:block;"" id=""fig:mcmcpaper""></span>
+<img src=""images/metropolis.png"" alt=""MCMC article cover. Source: [The Journal of Chemical Physics](https://aip.scitation.org/doi/10.1063/1.1699114)"" width=""582""><p class=""caption"">
+Figure 1.7: MCMC article cover. Source: <a href=""https://aip.scitation.org/doi/10.1063/1.1699114"">The Journal of Chemical Physics</a>
+</p>
+</div>
+<p>These simulation algorithms are called Markov chain Monte Carlo (MCMC), and they definitely gave a boost to Bayesian statistics. There are two parts in MCMC, Markov chain and Monte Carlo, let‚Äôs try and make sense of these terms.</p>
+<div id=""monte-carlo-integration"" class=""section level3"" number=""1.5.1"">
+<h3>
+<span class=""header-section-number"">1.5.1</span> Monte Carlo integration<a class=""anchor"" aria-label=""anchor"" href=""#monte-carlo-integration""><i class=""fas fa-link""></i></a>
+</h3>
+<p>What does Monte Carlo stand for? Monte Carlo integration is a simulation technique to calculate integrals of any function <span class=""math inline"">\(f\)</span> of random variable <span class=""math inline"">\(X\)</span> with distribution <span class=""math inline"">\(\Pr(X)\)</span> say <span class=""math inline"">\(\int f(X) \Pr(X)dX\)</span>. You draw values <span class=""math inline"">\(X_1,\ldots,X_k\)</span> from <span class=""math inline"">\(\Pr(X)\)</span> the distribution of <span class=""math inline"">\(X\)</span>, apply function <span class=""math inline"">\(f\)</span> to these values, then calculate the mean of these new values <span class=""math inline"">\(\displaystyle{\frac{1}{k}}\sum_{i=1}^k{f(X_i)}\)</span> to approximate the integral. How is Monte Carlo integration used in a Bayesian context? The posterior distribution contains all the information we need about the parameter to be estimated. When dealing with many parameters however, you may want to summarise posterior results by calculating numerical summaries. The simplest numerical summary is the mean of the posterior distribution, <span class=""math inline"">\(E(\theta) = \int \theta \Pr(\theta|\text{data})\)</span>, where <span class=""math inline"">\(X\)</span> is <span class=""math inline"">\(\theta\)</span> now and <span class=""math inline"">\(f\)</span> is the identity function. Posterior mean can be calculated with Monte Carlo integration:</p>
+<div class=""sourceCode"" id=""cb7""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""va"">sample_from_posterior</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Beta.html"">rbeta</a></span><span class=""op"">(</span><span class=""fl"">1000</span>, <span class=""fl"">20</span>, <span class=""fl"">39</span><span class=""op"">)</span> <span class=""co""># draw 1000 values from posterior survival beta(20,39)</span>
+<span class=""fu""><a href=""https://rdrr.io/r/base/mean.html"">mean</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span><span class=""op"">)</span> <span class=""co""># compute mean with Monte Carlo integration</span>
+<span class=""co"">## [1] 0.3376</span></code></pre></div>
+<p>You may check that the mean we have just calculated matches closely the expectation of a beta distribution<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;If &lt;span class=""math inline""&gt;\(X\)&lt;/span&gt; is a random variable with distribution &lt;span class=""math inline""&gt;\(\text{beta}(a, b)\)&lt;/span&gt;, then &lt;span class=""math inline""&gt;\(E(X) = \displaystyle{\frac{a}{a + b}}\)&lt;/span&gt;&lt;/p&gt;'><sup>10</sup></a>:</p>
+<div class=""sourceCode"" id=""cb8""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""fl"">20</span><span class=""op"">/</span><span class=""op"">(</span><span class=""fl"">20</span><span class=""op"">+</span><span class=""fl"">39</span><span class=""op"">)</span> <span class=""co""># expectation of beta(20,39)</span>
+<span class=""co"">## [1] 0.339</span></code></pre></div>
+<p>Another useful numerical summary is the credible interval within which our parameter falls with some probability, usually 0.95 hence a 95<span class=""math inline"">\(\%\)</span> credible interval. Finding the bounds of a credible interval requires calculating quantiles, which in turn involves integrals and the use of Monte Carlo integration. A 95<span class=""math inline"">\(\%\)</span> credible interval for winter survival can be obtained in <code>R</code> with:</p>
+<div class=""sourceCode"" id=""cb9""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/r/stats/quantile.html"">quantile</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span>, probs <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/c.html"">c</a></span><span class=""op"">(</span><span class=""fl"">2.5</span><span class=""op"">/</span><span class=""fl"">100</span>, <span class=""fl"">97.5</span><span class=""op"">/</span><span class=""fl"">100</span><span class=""op"">)</span><span class=""op"">)</span>
+<span class=""co"">##   2.5%  97.5% </span>
+<span class=""co"">## 0.2309 0.4629</span></code></pre></div>
+</div>
+<div id=""markov-chains"" class=""section level3"" number=""1.5.2"">
+<h3>
+<span class=""header-section-number"">1.5.2</span> Markov chains<a class=""anchor"" aria-label=""anchor"" href=""#markov-chains""><i class=""fas fa-link""></i></a>
+</h3>
+<p>What is a Markov chain? A Markov chain is a random sequence of numbers, in which each number depends only on the previous number. An example is the weather in my home town in Southern France, Montpellier, in which a sunny day is most likely to be followed by another sunny day, say with probability 0.8, and a rainy day is rarely followed by another rainy day, say with probability 0.1. The dynamic of this Markov chain is captured by the transition matrix <span class=""math inline"">\(\mathbf{\Gamma}\)</span>:
+<span class=""math display"">\[
+\begin{matrix}
+&amp; \\
+\mathbf{\Gamma} = 
+    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right .
+\end{matrix}
+\hspace{-1.2em}
+\begin{matrix}
+    \text{sunny tomorrow} &amp; \text{rainy tomorrow} \\ 
+0.8 &amp; 0.2 \\ 
+0.9 &amp; 0.1 \\ 
+\end{matrix}
+\hspace{-0.2em}
+\begin{matrix}
+&amp; \\
+\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
+    \begin{matrix}
+    \text{sunny today} \\ \text{rainy today}
+    \end{matrix}
+\end{matrix}
+\]</span>
+In rows the weather today, and in columns the weather tomorrow. The cells give the probability of a sunny or rainy day tomorrow, given the day is sunny or rainy today. Under certain conditions<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;The Markov chain is irreducible and aperiodic.&lt;/p&gt;""><sup>11</sup></a>, a Markov chain will converge to a unique stationary distribution. In our weather example, let‚Äôs run the Markov chain for 20 steps:</p>
+<div class=""sourceCode"" id=""cb10""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""va"">weather</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/matrix.html"">matrix</a></span><span class=""op"">(</span><span class=""fu""><a href=""https://rdrr.io/r/base/c.html"">c</a></span><span class=""op"">(</span><span class=""fl"">0.8</span>, <span class=""fl"">0.2</span>, <span class=""fl"">0.9</span>, <span class=""fl"">0.1</span><span class=""op"">)</span>, nrow <span class=""op"">=</span> <span class=""fl"">2</span>, byrow <span class=""op"">=</span> <span class=""cn"">T</span><span class=""op"">)</span> <span class=""co""># transition matrix</span>
+<span class=""va"">steps</span> <span class=""op"">&lt;-</span> <span class=""fl"">20</span>
+<span class=""kw"">for</span> <span class=""op"">(</span><span class=""va"">i</span> <span class=""kw"">in</span> <span class=""fl"">1</span><span class=""op"">:</span><span class=""va"">steps</span><span class=""op"">)</span><span class=""op"">{</span>
+  <span class=""va"">weather</span> <span class=""op"">&lt;-</span> <span class=""va"">weather</span> <span class=""op"">%*%</span> <span class=""va"">weather</span> <span class=""co""># matrix multiplication</span>
+<span class=""op"">}</span>
+<span class=""fu""><a href=""https://rdrr.io/r/base/Round.html"">round</a></span><span class=""op"">(</span><span class=""va"">weather</span>, <span class=""fl"">2</span><span class=""op"">)</span> <span class=""co""># matrix product after 20 steps</span>
+<span class=""co"">##      [,1] [,2]</span>
+<span class=""co"">## [1,] 0.82 0.18</span>
+<span class=""co"">## [2,] 0.82 0.18</span></code></pre></div>
+<p>Each row of the transition matrix converges to the same distribution <span class=""math inline"">\((0.82, 0.18)\)</span> as the number of steps increases. Convergence happens no matter which state you start in, and you always have probability 0.82 of the day being sunny and 0.18 of the day being rainy.</p>
+<p>Back to MCMC, the core idea is that you can build a Markov chain with a given stationary distribution set to be the desired posterior distribution.</p>
+
+<div class=""rmdnote"">
+Putting Monte Carlo and Markov chains together, MCMC allows us to generate a sample of values (Markov chain) whose distribution converges to the posterior distribution, and we can use this sample of values to calculate any posterior summaries (Monte Carlo), such as posterior means and credible intervals.
+</div>
+</div>
+<div id=""metropolis-algorithm"" class=""section level3"" number=""1.5.3"">
+<h3>
+<span class=""header-section-number"">1.5.3</span> Metropolis algorithm<a class=""anchor"" aria-label=""anchor"" href=""#metropolis-algorithm""><i class=""fas fa-link""></i></a>
+</h3>
+<p>There are several ways of constructing Markov chains for Bayesian inference<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;You might have heard about the Metropolis-Hastings or the Gibbs sampler. Have a look to &lt;a href=""https://github.com/chi-feng/mcmc-demo"" class=""uri""&gt;https://github.com/chi-feng/mcmc-demo&lt;/a&gt; for an interactive gallery of MCMC algorithms.&lt;/p&gt;'><sup>12</sup></a>. Here I illustrate the Metropolis algorithm and how to implement it in practice<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;This presentation is largely inspired by &lt;span class=""citation""&gt;&lt;a href=""references.html#ref-alberthu2019"" role=""doc-biblioref""&gt;Albert and Hu&lt;/a&gt; (&lt;a href=""references.html#ref-alberthu2019"" role=""doc-biblioref""&gt;2019&lt;/a&gt;)&lt;/span&gt;&lt;/p&gt;'><sup>13</sup></a>.</p>
+<p>Let‚Äôs go back to our example on animal survival estimation. We illustrate sampling from survival posterior distribution. We write functions for likelihood, prior and posterior.</p>
+<div class=""sourceCode"" id=""cb11""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""co""># 19 animals recaptured alive out of 57 captured, marked and released</span>
+<span class=""va"">survived</span> <span class=""op"">&lt;-</span> <span class=""fl"">19</span>
+<span class=""va"">released</span> <span class=""op"">&lt;-</span> <span class=""fl"">57</span>
+
+<span class=""co""># binomial log-likelihood function</span>
+<span class=""va"">loglikelihood</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">x</span>, <span class=""va"">p</span><span class=""op"">)</span><span class=""op"">{</span>
+  <span class=""fu""><a href=""https://rdrr.io/r/stats/Binomial.html"">dbinom</a></span><span class=""op"">(</span>x <span class=""op"">=</span> <span class=""va"">x</span>, size <span class=""op"">=</span> <span class=""va"">released</span>, prob <span class=""op"">=</span> <span class=""va"">p</span>, log <span class=""op"">=</span> <span class=""cn"">TRUE</span><span class=""op"">)</span>
+<span class=""op"">}</span>
+
+<span class=""co""># uniform prior density</span>
+<span class=""va"">logprior</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">p</span><span class=""op"">)</span><span class=""op"">{</span>
+  <span class=""fu""><a href=""https://rdrr.io/r/stats/Uniform.html"">dunif</a></span><span class=""op"">(</span>x <span class=""op"">=</span> <span class=""va"">p</span>, min <span class=""op"">=</span> <span class=""fl"">0</span>, max <span class=""op"">=</span> <span class=""fl"">1</span>, log <span class=""op"">=</span> <span class=""cn"">TRUE</span><span class=""op"">)</span>
+<span class=""op"">}</span>
+
+<span class=""co""># posterior density function (log scale)</span>
+<span class=""va"">posterior</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">x</span>, <span class=""va"">p</span><span class=""op"">)</span><span class=""op"">{</span>
+  <span class=""fu"">loglikelihood</span><span class=""op"">(</span><span class=""va"">x</span>, <span class=""va"">p</span><span class=""op"">)</span> <span class=""op"">+</span> <span class=""fu"">logprior</span><span class=""op"">(</span><span class=""va"">p</span><span class=""op"">)</span> <span class=""co""># - log(Pr(data))</span>
+<span class=""op"">}</span></code></pre></div>
+<p>The Metropolis algorithm works as follows:</p>
+<ol style=""list-style-type: decimal"">
+<li><p>We pick a value of the parameter to be estimated. This is where we start our Markov chain ‚Äì this is a <em>starting</em> value.</p></li>
+<li><p>To decide where to go next, we propose to move away from the current value of the parameter ‚Äì this is a <em>candidate</em> value. To do so, we add to the current value some random value from e.g.¬†a normal distribution with some variance ‚Äì this is a <em>proposal</em> distribution. The Metropolis algorithm is a particular case of the Metropolis-Hastings algorithm with symmetric proposals.</p></li>
+<li><p>We compute the ratio of the probabilities at the candidate and current locations <span class=""math inline"">\(R=\displaystyle{\frac{{\Pr(\text{candidate}|\text{data})}}{{\Pr(\text{current}|\text{data})}}}\)</span>. This is where the magic of MCMC happens, in that <span class=""math inline"">\(\Pr(\text{data})\)</span>, the denominator in the Bayes‚Äô theorem, appears in both the numerator and the denominator in <span class=""math inline"">\(R\)</span> therefore cancels out and does not need to be calculated.</p></li>
+</ol>
+<!-- -- *the Hastings ratio* --><ol start=""4"" style=""list-style-type: decimal"">
+<li><p>If the posterior at the candidate location <span class=""math inline"">\(\Pr(\text{candidate}|\text{data})\)</span> is higher than at the current location <span class=""math inline"">\(\Pr(\text{current}|\text{data})\)</span>, in other words when the candidate value is more plausible than the current value, we definitely accept the candidate value. If not, then we accept the candidate value with probability <span class=""math inline"">\(R\)</span> and reject with probability <span class=""math inline"">\(1-R\)</span>. For example, if the candidate value is ten times less plausible than the current value, then we accept with probability 0.1 and reject with probability 0.9. How does it work in practice? We use a continuous spinner that lands somewhere between 0 and 1 ‚Äì call the random spin <span class=""math inline"">\(X\)</span>. If <span class=""math inline"">\(X\)</span> is smaller than <span class=""math inline"">\(R\)</span>, we move to the candidate location, otherwise we remain at the current location. We do not want to accept or reject too often. In practice, the Metropolis algorithm should have an acceptance probability between 0.2 and 0.4, which can be achieved by <em>tuning</em> the variance of the normal proposal distribution.</p></li>
+<li><p>We repeat 2-4 a number of times ‚Äì or <em>steps</em>.</p></li>
+</ol>
+<p>Enough of the theory, let‚Äôs implement the Metropolis algorithm in <code>R</code>. Let‚Äôs start by setting the scene.</p>
+<div class=""sourceCode"" id=""cb12""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""va"">steps</span> <span class=""op"">&lt;-</span> <span class=""fl"">100</span> <span class=""co""># number of steps</span>
+<span class=""va"">theta.post</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/rep.html"">rep</a></span><span class=""op"">(</span><span class=""cn"">NA</span>, <span class=""va"">steps</span><span class=""op"">)</span> <span class=""co""># vector to store samples</span>
+<span class=""va"">accept</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/rep.html"">rep</a></span><span class=""op"">(</span><span class=""cn"">NA</span>, <span class=""va"">steps</span><span class=""op"">)</span> <span class=""co""># keep track of accept/reject</span>
+<span class=""fu""><a href=""https://rdrr.io/r/base/Random.html"">set.seed</a></span><span class=""op"">(</span><span class=""fl"">1234</span><span class=""op"">)</span> <span class=""co""># for reproducibility</span></code></pre></div>
+<p>Now follow the 5 steps we‚Äôve just described. First, we pick a starting value, and store it (step 1).</p>
+<div class=""sourceCode"" id=""cb13""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""va"">inits</span> <span class=""op"">&lt;-</span> <span class=""fl"">0.5</span>
+<span class=""va"">theta.post</span><span class=""op"">[</span><span class=""fl"">1</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""va"">inits</span>
+<span class=""va"">accept</span><span class=""op"">[</span><span class=""fl"">1</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""fl"">1</span></code></pre></div>
+<p>Then, we need a function to propose a candidate value. We add a value taken from a normal distribution with mean zero and standard deviation we call <em>away</em>. We work on the logit scale to make sure the candidate value for survival lies between 0 and 1.</p>
+<div class=""sourceCode"" id=""cb14""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""va"">move</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">x</span>, <span class=""va"">away</span> <span class=""op"">=</span> <span class=""fl"">1</span><span class=""op"">)</span><span class=""op"">{</span> <span class=""co""># by default, standard deviation of the proposal distribution is 1</span>
+  <span class=""va"">logitx</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/Log.html"">log</a></span><span class=""op"">(</span><span class=""va"">x</span> <span class=""op"">/</span> <span class=""op"">(</span><span class=""fl"">1</span> <span class=""op"">-</span> <span class=""va"">x</span><span class=""op"">)</span><span class=""op"">)</span> <span class=""co""># apply logit transform (-infinity,+infinity)</span>
+  <span class=""va"">logit_candidate</span> <span class=""op"">&lt;-</span> <span class=""va"">logitx</span> <span class=""op"">+</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Normal.html"">rnorm</a></span><span class=""op"">(</span><span class=""fl"">1</span>, <span class=""fl"">0</span>, <span class=""va"">away</span><span class=""op"">)</span> <span class=""co""># add a value taken from N(0,sd=away) to current value</span>
+  <span class=""va"">candidate</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Logistic.html"">plogis</a></span><span class=""op"">(</span><span class=""va"">logit_candidate</span><span class=""op"">)</span> <span class=""co""># back-transform (0,1)</span>
+  <span class=""kw""><a href=""https://rdrr.io/r/base/function.html"">return</a></span><span class=""op"">(</span><span class=""va"">candidate</span><span class=""op"">)</span>
+<span class=""op"">}</span></code></pre></div>
+<p>Now we‚Äôre ready for steps 2, 3 and 4. We write a loop to take care of step 5. We start at initial value 0.5 and run the algorithm for 100 steps or iterations.</p>
+<div class=""sourceCode"" id=""cb15""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""kw"">for</span> <span class=""op"">(</span><span class=""va"">t</span> <span class=""kw"">in</span> <span class=""fl"">2</span><span class=""op"">:</span><span class=""va"">steps</span><span class=""op"">)</span><span class=""op"">{</span> <span class=""co""># repeat steps 2-4 (step 5)</span>
+  
+  <span class=""co""># propose candidate value for survival (step 2)</span>
+  <span class=""va"">theta_star</span> <span class=""op"">&lt;-</span> <span class=""fu"">move</span><span class=""op"">(</span><span class=""va"">theta.post</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">-</span><span class=""fl"">1</span><span class=""op"">]</span><span class=""op"">)</span>
+  
+  <span class=""co""># calculate ratio R (step 3)</span>
+  <span class=""va"">pstar</span> <span class=""op"">&lt;-</span> <span class=""fu"">posterior</span><span class=""op"">(</span><span class=""va"">survived</span>, p <span class=""op"">=</span> <span class=""va"">theta_star</span><span class=""op"">)</span>  
+  <span class=""va"">pprev</span> <span class=""op"">&lt;-</span> <span class=""fu"">posterior</span><span class=""op"">(</span><span class=""va"">survived</span>, p <span class=""op"">=</span> <span class=""va"">theta.post</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">-</span><span class=""fl"">1</span><span class=""op"">]</span><span class=""op"">)</span>
+  <span class=""va"">logR</span> <span class=""op"">&lt;-</span> <span class=""va"">pstar</span> <span class=""op"">-</span> <span class=""va"">pprev</span> <span class=""co""># likelihood and prior are on the log scale</span>
+  <span class=""va"">R</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/Log.html"">exp</a></span><span class=""op"">(</span><span class=""va"">logR</span><span class=""op"">)</span>
+  
+  <span class=""co""># accept candidate value or keep current value (step 4)</span>
+  <span class=""va"">X</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Uniform.html"">runif</a></span><span class=""op"">(</span><span class=""fl"">1</span>, <span class=""fl"">0</span>, <span class=""fl"">1</span><span class=""op"">)</span> <span class=""co""># spin continuous spinner</span>
+  <span class=""kw"">if</span> <span class=""op"">(</span><span class=""va"">X</span> <span class=""op"">&lt;</span> <span class=""va"">R</span><span class=""op"">)</span><span class=""op"">{</span>
+    <span class=""va"">theta.post</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""va"">theta_star</span> <span class=""co""># accept candidate value</span>
+    <span class=""va"">accept</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""fl"">1</span> <span class=""co""># accept</span>
+  <span class=""op"">}</span>
+  <span class=""kw"">else</span><span class=""op"">{</span>
+    <span class=""va"">theta.post</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""va"">theta.post</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">-</span><span class=""fl"">1</span><span class=""op"">]</span> <span class=""co""># keep current value</span>
+    <span class=""va"">accept</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""fl"">0</span> <span class=""co""># reject</span>
+  <span class=""op"">}</span>
+<span class=""op"">}</span></code></pre></div>
+<p>We get the following values.</p>
+<div class=""sourceCode"" id=""cb16""><pre class=""downlit sourceCode r"">
+<code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/r/utils/head.html"">head</a></span><span class=""op"">(</span><span class=""va"">theta.post</span><span class=""op"">)</span> <span class=""co""># first values</span>
+<span class=""co"">## [1] 0.5000 0.2302 0.2906 0.2906 0.2980 0.2980</span>
+<span class=""fu""><a href=""https://rdrr.io/r/utils/head.html"">tail</a></span><span class=""op"">(</span><span class=""va"">theta.post</span><span class=""op"">)</span> <span class=""co""># last values</span>
+<span class=""co"">## [1] 0.2622 0.2622 0.2622 0.3727 0.3232 0.3862</span></code></pre></div>
+Visually, you may look at the chain in Figure <a href=""crashcourse.html#fig:chain"">1.8</a> called a trace plot.
+<div class=""figure"" style=""text-align: center"">
+<span style=""display:block;"" id=""fig:chain""></span>
+<img src=""banana-book_files/figure-html/chain-1.png"" alt=""Visualisation of a Markov chain starting at value 0.5, with steps or iterations on the x-axis, and samples on the y-axis. This graphical representation is called a trace plot."" width=""672""><p class=""caption"">
+Figure 1.8: Visualisation of a Markov chain starting at value 0.5, with steps or iterations on the x-axis, and samples on the y-axis. This graphical representation is called a trace plot.
+</p>
+</div>
+<p>The acceptance probability is the average number of times we accepted a candidated value, which is 0.44 and almost satisfying.</p>
+Can we run another chain and start at initial value 0.2 this time? Yes, just go through the same algorithm again, and visualise the results in Figure <a href=""crashcourse.html#fig:twochains"">1.9</a>.
+<div class=""figure"" style=""text-align: center"">
+<span style=""display:block;"" id=""fig:twochains""></span>
+<img src=""banana-book_files/figure-html/twochains-1.png"" alt=""Trace plot of survival for two chains starting at 0.2 (yellow) and 0.5 (blue) run for 100 steps."" width=""672""><p class=""caption"">
+Figure 1.9: Trace plot of survival for two chains starting at 0.2 (yellow) and 0.5 (blue) run for 100 steps.
+</p>
 </div>
+Notice that we do not get the exact same results because the algorithm is stochastic. The question is to know whether we have reached the stationary distribution. Let‚Äôs increase the number of steps and run a chain with 5000 iterations as in Figure <a href=""crashcourse.html#fig:longchain"">1.10</a>.
+<div class=""figure"" style=""text-align: center"">
+<span style=""display:block;"" id=""fig:longchain""></span>
+<img src=""banana-book_files/figure-html/longchain-1.png"" alt=""Trace plot of survival for a chain starting at 0.5 and 1000 steps."" width=""672""><p class=""caption"">
+Figure 1.10: Trace plot of survival for a chain starting at 0.5 and 1000 steps.
+</p>
+</div>
+<p>This is what we‚Äôre after, a trace plot that looks like a beautiful lawn, see Section <a href=""crashcourse.html#convergence-diag"">1.6</a>. I find it informative to look at the animated version of Figure <a href=""crashcourse.html#fig:longchain"">1.10</a>, it helps understanding the stochastic behavior of the algorithm, and also to realise how the chains converge to their stationary distribution, see Figure <a href=""crashcourse.html#fig:animlongchain"">1.11</a>.</p>
+<div class=""figure"" style=""text-align: center"">
+<span style=""display:block;"" id=""fig:animlongchain""></span>
+<img src=""images/traceplotMCMC.gif"" alt=""Animated trace plot of survival with three chains starting at 0.2, 0.5 and 0.7 run for 1000 steps."" width=""100%""><p class=""caption"">
+Figure 1.11: Animated trace plot of survival with three chains starting at 0.2, 0.5 and 0.7 run for 1000 steps.
+</p>
+</div>
+<p>Once the stationary distribution is reached, you may regard the realisations of the Markov chain as a sample from the posterior distribution, and obtain numerical summaries. In the next section, we consider several important implementation issues.</p>
+</div>
+</div>
+<div id=""convergence-diag"" class=""section level2"" number=""1.6"">
+<h2>
+<span class=""header-section-number"">1.6</span> Assessing convergence<a class=""anchor"" aria-label=""anchor"" href=""#convergence-diag""><i class=""fas fa-link""></i></a>
+</h2>
+
+<div class=""rmdnote"">
+When implementing MCMC, we need to determine how long it takes for our Markov chain to converge to the target distribution, and the number of iterations we need after achieving convergence to get reasonable Monte Carlo estimates of numerical summaries (posterior means and credible intervals).
+</div>
+<div id=""burn-in"" class=""section level3"" number=""1.6.1"">
+<h3>
+<span class=""header-section-number"">1.6.1</span> Burn-in<a class=""anchor"" aria-label=""anchor"" href=""#burn-in""><i class=""fas fa-link""></i></a>
+</h3>
+<p>In practice, we discard observations from the start of the Markov chain and just use observations from the chain once it has converged. The initial observations that we discard are usually referred to as the <em>burn-in</em>.</p>
+<p>The simplest method to determine the length of the burn-in period is to look at trace plots. Going back to our example, we see from the trace plot in Figure <a href=""crashcourse.html#fig:burnin"">1.12</a> that we need at least 100 iterations to achieve convergence toward an average survival around 0.3. It is always better to be conservative when specifying the length of the burn-in period, and in this example, we would use 250 or even 500 iterations as a burn-in. The length of the burn-in period can be determined by performing preliminary MCMC short runs.</p>
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:burnin""></span>
+<img src=""banana-book_files/figure-html/burnin-1.png"" alt=""Determining the length of the burn-in period. The chain starts at value 0.99 and rapidly stabilises, with values bouncing back and forth around 0.3 from the 100th iteration onwards. You may choose the shaded area as the burn-in, and discard the corresponding values."" width=""672""><p class=""caption"">
+Figure 1.12: Determining the length of the burn-in period. The chain starts at value 0.99 and rapidly stabilises, with values bouncing back and forth around 0.3 from the 100th iteration onwards. You may choose the shaded area as the burn-in, and discard the corresponding values.
+</p>
+</div>
+<p>Inspecting the trace plot for a single run of the Markov chain is useful. However, we usually run the Markov chain several times, starting from different over-dispersed points, to check that all runs achieve the same stationary distribution. This approach is formalised by using the Brooks-Gelman-Rubin (BGR) statistic <span class=""math inline"">\(\hat{R}\)</span> which measures the ratio of the total variability combining multiple chains (between-chain plus within-chain) to the within-chain variability. The BGR statistic asks whether there is a chain effect, and is very much alike the <span class=""math inline"">\(F\)</span> test in an analysis of variance. Values below 1.1 indicate likely convergence.</p>
+<p>Back to our example, we run two Markov chains with starting values 0.2 and 0.8 using 100 up to 5000 iterations, and calculate the BGR statistic using half the number of iterations as the length of the burn-in. From Figure <a href=""crashcourse.html#fig:bgr"">1.13</a>, we get a value of the BGR statistic near 1 by up to 2000 iterations, which suggests that with 2000 iterations as a burn-in, there is no evidence of a lack of convergence.</p>
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:bgr""></span>
+<img src=""banana-book_files/figure-html/bgr-1.png"" alt=""Brooks-Gelman-Rubin statistic as a function of the number of iterations."" width=""672""><p class=""caption"">
+Figure 1.13: Brooks-Gelman-Rubin statistic as a function of the number of iterations.
+</p>
+</div>
+<p>It is important to bear in mind that a value near 1 for the BGR statistic is only a necessary <em>but not sufficient</em> condition for convergence. In other words, this diagnostic cannot tell you for sure that the Markov chain has achieved convergence, only that it has not.<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;Cross-reference sections on local minima and parameter redundancy for pathological cases.&lt;/p&gt;""><sup>14</sup></a></p>
+</div>
+<div id=""chain-length"" class=""section level3"" number=""1.6.2"">
+<h3>
+<span class=""header-section-number"">1.6.2</span> Chain length<a class=""anchor"" aria-label=""anchor"" href=""#chain-length""><i class=""fas fa-link""></i></a>
+</h3>
+<p>How long of a chain is needed to produce reliable parameter estimates? To answer this question, you need to keep in mind that successive steps in a Markov chain are not independent ‚Äì this is usually referred to as <em>autocorrelation</em>. Ideally, we would like to keep autocorrelation as low as possible. Here again, trace plots are useful to diagnose issues with autocorrelation. Let‚Äôs get back to our survival example. Figure <a href=""crashcourse.html#fig:tracechainlength"">1.14</a> shows trace plots for different values of the standard deviation (parameter <em>away</em>) of the (normal) proposal distribution we use to propose a candidate value (Section <a href=""crashcourse.html#metropolis-algorithm"">1.5.3</a>). Small and big moves provide high correlations between successive observations of the Markov chain, whereas a standard deviation of 1 allows efficient exploration of the parameter space. The movement around the parameter space is referred to as <em>mixing</em>. Mixing is bad when the chain makes small and big moves, and good otherwise.</p>
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:tracechainlength""></span>
+<img src=""banana-book_files/figure-html/tracechainlength-1.png"" alt=""Trace plots for different values of the standard deviation (SD) of the proposal distribution. Left: The chain exhibits small moves and mixing is bad. Right: The chain exhibits big moves and mixing is bad. Middle: The chain exhibits adequate moves and mixing is good. Only the thousand last iterations are shown."" width=""672""><p class=""caption"">
+Figure 1.14: Trace plots for different values of the standard deviation (SD) of the proposal distribution. Left: The chain exhibits small moves and mixing is bad. Right: The chain exhibits big moves and mixing is bad. Middle: The chain exhibits adequate moves and mixing is good. Only the thousand last iterations are shown.
+</p>
+</div>
+<p>In addition to trace plots, autocorrelation function (ACF) plots are a convenient way of displaying the strength of autocorrelation in a given sample values. ACF plots provide the autocorrelation between successively sampled values separated by an increasing number of iterations, or <em>lag</em> (Figure <a href=""crashcourse.html#fig:acfchainlength"">1.15</a>).</p>
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:acfchainlength""></span>
+<img src=""banana-book_files/figure-html/acfchainlength-1.png"" alt=""Autocorrelation function plots for different values of the standard deviation (SD) of the proposal distribution. Left and right: Autocorrelation is strong, decreases slowly with increasing lag and mixing is bad. Middle: Autocorrelation is weak, decreases rapidly with increasing lag and mixing is good."" width=""672""><p class=""caption"">
+Figure 1.15: Autocorrelation function plots for different values of the standard deviation (SD) of the proposal distribution. Left and right: Autocorrelation is strong, decreases slowly with increasing lag and mixing is bad. Middle: Autocorrelation is weak, decreases rapidly with increasing lag and mixing is good.
+</p>
+</div>
+<p>Autocorrelation is not necessarily a big issue. Strongly correlated observations just require large sample sizes and therefore longer simulations. But how many iterations exactly? The effective sample size (<code>n.eff</code>) measures chain length while taking into account chain autocorrelation. You should check the <code>n.eff</code> of every parameter of interest, and of any interesting parameter combinations. In general, we need <span class=""math inline"">\(\text{n.eff} \geq 1000\)</span> independent steps to get reasonable Monte Carlo estimates of model parameters. In the animal survival example, <code>n.eff</code> can be calculated with the R <code><a href=""https://rdrr.io/pkg/coda/man/effectiveSize.html"">coda::effectiveSize()</a></code> function.</p>
+<div class=""inline-table""><table class=""table table-sm"">
+<thead><tr class=""header"">
+<th align=""right"">Proposal SD</th>
+<th align=""right"">n.eff</th>
+</tr></thead>
+<tbody>
+<tr class=""odd"">
+<td align=""right"">0.1</td>
+<td align=""right"">224</td>
+</tr>
+<tr class=""even"">
+<td align=""right"">1.0</td>
+<td align=""right"">1934</td>
+</tr>
+<tr class=""odd"">
+<td align=""right"">10.0</td>
+<td align=""right"">230</td>
+</tr>
+</tbody>
+</table></div>
+<p>As expected, <code>n.eff</code> is less than the number of MCMC iterations because of autocorrelation. Only when the standard deviation of the proposal distribution is 1 and mixing is good (Figures <a href=""crashcourse.html#fig:tracechainlength"">1.14</a> and <a href=""crashcourse.html#fig:acfchainlength"">1.15</a>) we get a satisfying effective sample size.</p>
+</div>
+<div id=""what-if-you-have-issues-of-convergence"" class=""section level3"" number=""1.6.3"">
+<h3>
+<span class=""header-section-number"">1.6.3</span> What if you have issues of convergence?<a class=""anchor"" aria-label=""anchor"" href=""#what-if-you-have-issues-of-convergence""><i class=""fas fa-link""></i></a>
+</h3>
+<p>When diagnosing MCMC convergence, you will (very) often run into troubles. In this section you will find some helpful tips I hope.</p>
+<p>When mixing is bad and effective sample size is small, you may just need to increase burn-in and/or sample more. Using more informative priors might also make Markov chains converge faster by helping your MCMC sampler (e.g.¬†the Metropolis algorithm) navigating more efficiently the parameter space. In the same spirit, picking better initial values for starting the chain does not harm. For doing that, a strategy consists in using estimates from a simpler model for which your MCMC chains do converge.</p>
+<p>If convergence issues persist, often there is a problem with your model<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;The quote ‚ÄòWhen you have computational problems, often there‚Äôs a problem with your model‚Äô is the folk theorem of statistical computing stated by Andrew Gelman in 2008, see &lt;a href=""https://statmodeling.stat.columbia.edu/2008/05/13/the_folk_theore/"" class=""uri""&gt;https://statmodeling.stat.columbia.edu/2008/05/13/the_folk_theore/&lt;/a&gt;&lt;/p&gt;'><sup>15</sup></a>. A bug in the code? A typo somewhere? A mistake in your maths? As often when coding is involved, the issue can be identified by removing complexities, and start with a simpler model until you find what the problem is.</p>
+<p>A general advice is to see your model as a data generating tool in the first place, simulate data from it using some realistic values for the parameters, and try to recover these parameter values by fitting the model to the simulated data. Simulating from a model will help you understanding how it works, what it does not do, and the data you need to get reasonable parameter estimates.</p>
+<p>We will see other strategies to improve convergence in the next chapters.<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;Cross reference relevant chapters. Option 1. Change your sampler. Option 2. Reparameterize (standardize covariates, plus non-centering: &lt;span class=""math inline""&gt;\(\alpha \sim N(0,\sigma)\)&lt;/span&gt; becomes &lt;span class=""math inline""&gt;\(\alpha = z \sigma\)&lt;/span&gt; with &lt;span class=""math inline""&gt;\(z \sim N(0,1)\)&lt;/span&gt;).&lt;/p&gt;'><sup>16</sup></a></p>
+</div>
+</div>
+<div id=""summary"" class=""section level2"" number=""1.7"">
+<h2>
+<span class=""header-section-number"">1.7</span> Summary<a class=""anchor"" aria-label=""anchor"" href=""#summary""><i class=""fas fa-link""></i></a>
+</h2>
+<ul>
+<li><p>With the Bayes‚Äô theorem, you update your beliefs (prior) with new data (likelihood) to get posterior beliefs (posterior): posterior <span class=""math inline"">\(\propto\)</span> likelihood <span class=""math inline"">\(\times\)</span> prior.</p></li>
+<li><p>The idea of Markov chain Monte Carlo (MCMC) is to simulate values from a Markov chain which has a stationary distribution equal to the posterior distribution you‚Äôre after.</p></li>
+<li><p>In practice, you run a Markov chain multiple times starting from over-dispersed initial values.</p></li>
+<li><p>You discard iterations in an initial burn-in phase and achieve convergence when all chains reach the same regime.</p></li>
+<li><p>From there, you run the chains long enough and proceed with calculating Monte Carlo estimates of numerical summaries (e.g.¬†posterior means and credible intervals) for parameters.</p></li>
+</ul>
+</div>
+<div id=""suggested-reading"" class=""section level2"" number=""1.8"">
+<h2>
+<span class=""header-section-number"">1.8</span> Suggested reading<a class=""anchor"" aria-label=""anchor"" href=""#suggested-reading""><i class=""fas fa-link""></i></a>
+</h2>
+<ul>
+<li><p>Gelman, A. and Hill, J. (2006). <a href=""https://www.cambridge.org/core/books/data-analysis-using-regression-and-multilevelhierarchical-models/32A29531C7FD730C3A68951A17C9D983"">Data Analysis Using Regression and Multilevel/Hierarchical Models (Analytical Methods for Social Research)</a>. Cambridge: Cambridge University Press.</p></li>
+<li><p>Gelman, A. and colleagues (2020). <a href=""https://arxiv.org/pdf/2011.01808.pdf"">Bayesian workflow</a>. arXiv preprint.</p></li>
+<li><p>McCarthy, M. (2007). <a href=""https://www.cambridge.org/core/books/bayesian-methods-for-ecology/9225F65B8A25D69B0B6C50B5A9A78201"">Bayesian Methods for Ecology</a>. Cambridge: Cambridge University Press.</p></li>
+<li><p>McElreath, R. (2020). <a href=""https://xcelab.net/rm/statistical-rethinking/"">Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2nd ed.)</a>. CRC Press.</p></li>
+</ul>
+</div>
+</div>
+
   <div class=""chapter-nav"">
 <div class=""prev""><a href=""introduction.html"">Introduction</a></div>
 <div class=""next""><a href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
-      <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#crashcourse""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li></ul>
+      <ul class=""nav navbar-nav"">
+<li><a class=""nav-link"" href=""#crashcourse""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class=""nav-link"" href=""#introduction-1""><span class=""header-section-number"">1.1</span> Introduction</a></li>
+<li><a class=""nav-link"" href=""#bayes-theorem""><span class=""header-section-number"">1.2</span> Bayes‚Äô theorem</a></li>
+<li><a class=""nav-link"" href=""#what-is-the-bayesian-approach""><span class=""header-section-number"">1.3</span> What is the Bayesian approach?</a></li>
+<li><a class=""nav-link"" href=""#numerical-approx""><span class=""header-section-number"">1.4</span> Approximating posteriors via numerical integration</a></li>
+<li>
+<a class=""nav-link"" href=""#markov-chain-monte-carlo-mcmc""><span class=""header-section-number"">1.5</span> Markov chain Monte Carlo (MCMC)</a><ul class=""nav navbar-nav"">
+<li><a class=""nav-link"" href=""#monte-carlo-integration""><span class=""header-section-number"">1.5.1</span> Monte Carlo integration</a></li>
+<li><a class=""nav-link"" href=""#markov-chains""><span class=""header-section-number"">1.5.2</span> Markov chains</a></li>
+<li><a class=""nav-link"" href=""#metropolis-algorithm""><span class=""header-section-number"">1.5.3</span> Metropolis algorithm</a></li>
+</ul>
+</li>
+<li>
+<a class=""nav-link"" href=""#convergence-diag""><span class=""header-section-number"">1.6</span> Assessing convergence</a><ul class=""nav navbar-nav"">
+<li><a class=""nav-link"" href=""#burn-in""><span class=""header-section-number"">1.6.1</span> Burn-in</a></li>
+<li><a class=""nav-link"" href=""#chain-length""><span class=""header-section-number"">1.6.2</span> Chain length</a></li>
+<li><a class=""nav-link"" href=""#what-if-you-have-issues-of-convergence""><span class=""header-section-number"">1.6.3</span> What if you have issues of convergence?</a></li>
+</ul>
+</li>
+<li><a class=""nav-link"" href=""#summary""><span class=""header-section-number"">1.7</span> Summary</a></li>
+<li><a class=""nav-link"" href=""#suggested-reading""><span class=""header-section-number"">1.8</span> Suggested reading</a></li>
+</ul>
 
       <div class=""book-extra"">
         <ul class=""list-unstyled"">
@@ -103,14 +560,42 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
 </body>
 </html>

---FILE: docs/dispersal.html---
@@ -49,17 +49,17 @@ <h1>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
 <li><a class="""" href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></li>
 <li><a class=""active"" href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></li>
 <li><a class="""" href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></li>
 <li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></li>
 <li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
 <li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></li>
 <li><a class="""" href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></li>
 <li><a class="""" href=""stopover.html""><span class=""header-section-number"">12</span> Stopover duration</a></li>
@@ -1121,14 +1121,42 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
 </body>
 </html>

---FILE: docs/faq.html---
@@ -49,17 +49,17 @@ <h1>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
 <li><a class="""" href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></li>
 <li><a class="""" href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></li>
 <li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></li>
 <li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
 <li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></li>
 <li><a class="""" href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></li>
 <li><a class="""" href=""stopover.html""><span class=""header-section-number"">12</span> Stopover duration</a></li>
@@ -107,14 +107,42 @@ <h1>FAQ<a class=""anchor"" aria-label=""anchor"" href=""#faq""><i class=""fas fa-link"">
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
 </body>
 </html>

---FILE: docs/hmmcapturerecapture.html---
@@ -49,17 +49,17 @@ <h1>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></li>
 <li><a class=""active"" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
 <li><a class="""" href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></li>
 <li><a class="""" href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></li>
 <li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></li>
 <li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
 <li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></li>
 <li><a class="""" href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></li>
 <li><a class="""" href=""stopover.html""><span class=""header-section-number"">12</span> Stopover duration</a></li>
@@ -1032,7 +1032,7 @@ <h1>
 
   <div class=""chapter-nav"">
 <div class=""prev""><a href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></div>
-<div class=""next""><a href=""introduction-1.html"">Introduction</a></div>
+<div class=""next""><a href=""introduction-2.html"">Introduction</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
       <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#hmmcapturerecapture""><span class=""header-section-number"">3</span> Hidden Markov models</a></li></ul>
@@ -1052,14 +1052,42 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
 </body>
 </html>

---FILE: docs/hsmm.html---
@@ -49,17 +49,17 @@ <h1>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
 <li><a class="""" href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></li>
 <li><a class="""" href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></li>
 <li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></li>
 <li><a class=""active"" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
 <li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></li>
 <li><a class="""" href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></li>
 <li><a class="""" href=""stopover.html""><span class=""header-section-number"">12</span> Stopover duration</a></li>
@@ -86,7 +86,7 @@ <h1>
 
   <div class=""chapter-nav"">
 <div class=""prev""><a href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></div>
-<div class=""next""><a href=""introduction-3.html"">Introduction</a></div>
+<div class=""next""><a href=""introduction-4.html"">Introduction</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
       <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#hsmm""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li></ul>
@@ -106,14 +106,42 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
 </body>
 </html>

---FILE: docs/index.html---
@@ -49,17 +49,17 @@ <h1>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
 <li><a class="""" href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></li>
 <li><a class="""" href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></li>
 <li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></li>
 <li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
 <li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></li>
 <li><a class="""" href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></li>
 <li><a class="""" href=""stopover.html""><span class=""header-section-number"">12</span> Stopover duration</a></li>
@@ -84,7 +84,7 @@ <h1>Welcome<a class=""anchor"" aria-label=""anchor"" href=""#welcome""><i class=""fas f
 <p>This book offers a Bayesian treatment of HMMs applied to capture-recapture data. You will learn to use the R package NIMBLE which is seen by many as the future of Bayesian statistical ecology to deal with complex models and/or big data. An important part of the book consists in case studies presented in a tutorial style to abide by the ‚Äúlearning by doing‚Äù philosophy.</p>
 <p>I‚Äôm currently writing this book, and I welcome any feedback. You may raise an issue <a href=""https://github.com/oliviergimenez/banana-book/issues"">here</a>, amend directly the R Markdown file that generated the page you‚Äôre reading by clicking on the ‚ÄòEdit this page‚Äô icon in the right panel, or <a href=""mailto:olivier.gimenez@cefe.cnrs.fr"">email me</a>. Many thanks!</p>
 <p>Olivier Gimenez, Montpellier, France<br>
-Last updated: September 19, 2021</p>
+Last updated: September 20, 2021</p>
 <div id=""license"" class=""section level2 unnumbered"">
 <h2>License<a class=""anchor"" aria-label=""anchor"" href=""#license""><i class=""fas fa-link""></i></a>
 </h2>
@@ -118,14 +118,42 @@ <h2>License<a class=""anchor"" aria-label=""anchor"" href=""#license""><i class=""fas f
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
 </body>
 </html>

---FILE: docs/individual-dependence.html---
@@ -49,17 +49,17 @@ <h1>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
 <li><a class="""" href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></li>
 <li><a class="""" href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></li>
 <li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></li>
 <li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
 <li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></li>
 <li><a class="""" href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></li>
 <li><a class="""" href=""stopover.html""><span class=""header-section-number"">12</span> Stopover duration</a></li>
@@ -122,14 +122,42 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
 </body>
 </html>

---FILE: docs/introduction-2.html---
@@ -49,17 +49,17 @@ <h1>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class=""active"" href=""introduction-2.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
 <li><a class="""" href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></li>
 <li><a class="""" href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></li>
 <li class=""book-part"">III. States</li>
-<li><a class=""active"" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></li>
 <li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
 <li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></li>
 <li><a class="""" href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></li>
 <li><a class="""" href=""stopover.html""><span class=""header-section-number"">12</span> Stopover duration</a></li>
@@ -81,16 +81,16 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-2""><i
 
 </div>
   <div class=""chapter-nav"">
-<div class=""prev""><a href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></div>
-<div class=""next""><a href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></div>
+<div class=""prev""><a href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></div>
+<div class=""next""><a href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
       <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#introduction-2"">Introduction</a></li></ul>
 
       <div class=""book-extra"">
         <ul class=""list-unstyled"">
-<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionpartthree.Rmd"">View source <i class=""fab fa-github""></i></a></li>
-          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionpartthree.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionparttwo.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionparttwo.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
         </ul>
 </div>
     </nav>
@@ -102,14 +102,42 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-2""><i
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
 </body>
 </html>

---FILE: docs/introduction-3.html---
@@ -49,17 +49,17 @@ <h1>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
 <li><a class="""" href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></li>
 <li><a class="""" href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></li>
 <li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class=""active"" href=""introduction-3.html"">Introduction</a></li>
 <li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></li>
 <li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
 <li class=""book-part"">IV. Case studies</li>
-<li><a class=""active"" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></li>
 <li><a class="""" href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></li>
 <li><a class="""" href=""stopover.html""><span class=""header-section-number"">12</span> Stopover duration</a></li>
@@ -81,16 +81,16 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-3""><i
 
 </div>
   <div class=""chapter-nav"">
-<div class=""prev""><a href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></div>
-<div class=""next""><a href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></div>
+<div class=""prev""><a href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></div>
+<div class=""next""><a href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
       <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#introduction-3"">Introduction</a></li></ul>
 
       <div class=""book-extra"">
         <ul class=""list-unstyled"">
-<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionpartfour.Rmd"">View source <i class=""fab fa-github""></i></a></li>
-          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionpartfour.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/introductionpartthree.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/introductionpartthree.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
         </ul>
 </div>
     </nav>
@@ -102,14 +102,42 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-3""><i
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
 </body>
 </html>

---FILE: docs/introduction-4.html---
@@ -102,7 +102,7 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction-4""><i
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/introduction.html---
@@ -49,17 +49,17 @@ <h1>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
 <li><a class="""" href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></li>
 <li><a class="""" href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></li>
 <li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></li>
 <li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
 <li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></li>
 <li><a class="""" href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></li>
 <li><a class="""" href=""stopover.html""><span class=""header-section-number"">12</span> Stopover duration</a></li>
@@ -102,14 +102,42 @@ <h1>Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction""><i cl
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
 </body>
 </html>

---FILE: docs/intronimble.html---
@@ -49,17 +49,17 @@ <h1>
 <li><a class=""active"" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
 <li><a class="""" href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></li>
 <li><a class="""" href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></li>
 <li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></li>
 <li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
 <li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></li>
 <li><a class="""" href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></li>
 <li><a class="""" href=""stopover.html""><span class=""header-section-number"">12</span> Stopover duration</a></li>
@@ -298,14 +298,42 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
 </body>
 </html>

---FILE: docs/model-selection.html---
@@ -49,17 +49,17 @@ <h1>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
 <li><a class="""" href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></li>
 <li><a class=""active"" href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></li>
 <li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></li>
 <li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
 <li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></li>
 <li><a class="""" href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></li>
 <li><a class="""" href=""stopover.html""><span class=""header-section-number"">12</span> Stopover duration</a></li>
@@ -86,7 +86,7 @@ <h1>
 
   <div class=""chapter-nav"">
 <div class=""prev""><a href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></div>
-<div class=""next""><a href=""introduction-2.html"">Introduction</a></div>
+<div class=""next""><a href=""introduction-3.html"">Introduction</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
       <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#model-selection""><span class=""header-section-number"">7</span> Model selection and validation</a></li></ul>
@@ -106,14 +106,42 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
 </body>
 </html>

---FILE: docs/preface.html---
@@ -49,17 +49,17 @@ <h1>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
 <li><a class="""" href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></li>
 <li><a class="""" href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></li>
 <li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></li>
 <li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
 <li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></li>
 <li><a class="""" href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></li>
 <li><a class="""" href=""stopover.html""><span class=""header-section-number"">12</span> Stopover duration</a></li>
@@ -191,14 +191,42 @@ <h2>How this book was written<a class=""anchor"" aria-label=""anchor"" href=""#how-th
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
 </body>
 </html>

---FILE: docs/reference-keys.txt---
@@ -1,4 +1,33 @@
+fig:revbayes
+fig:bayestheorem
+fig:binlik
+fig:numapprox
+fig:betadistribution
+fig:compar
+fig:mcmcpaper
+fig:chain
+fig:twochains
+fig:longchain
+fig:animlongchain
+fig:burnin
+fig:bgr
+fig:tracechainlength
+fig:acfchainlength
 crashcourse
+introduction-1
+bayes-theorem
+what-is-the-bayesian-approach
+numerical-approx
+markov-chain-monte-carlo-mcmc
+monte-carlo-integration
+markov-chains
+metropolis-algorithm
+convergence-diag
+burn-in
+chain-length
+what-if-you-have-issues-of-convergence
+summary
+suggested-reading
 intronimble
 hmmcapturerecapture
 survival

---FILE: docs/references.html---
@@ -6,15 +6,15 @@
 <meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <title>References | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</title>
 <meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""Choquet, R√©mi, Anne Viallefont, Lauriane Rouan, Kamel Gaanoun, and Jean-Michel Gaillard. 2011. ‚ÄúA Semi-Markov Model to Assess Reliably Survival Patterns from Birth to Death in Free-Ranging..."">
+<meta name=""description"" content=""Albert, Jim, and Jingchen Hu. 2019. Probability and Bayesian Modeling. 1st edition. Chapman; Hall/CRC.  Choquet, R√©mi, Anne Viallefont, Lauriane Rouan, Kamel Gaanoun, and Jean-Michel Gaillard...."">
 <meta name=""generator"" content=""bookdown 0.23 with bs4_book()"">
 <meta property=""og:title"" content=""References | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R"">
 <meta property=""og:type"" content=""book"">
 <meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/references.html"">
-<meta property=""og:description"" content=""Choquet, R√©mi, Anne Viallefont, Lauriane Rouan, Kamel Gaanoun, and Jean-Michel Gaillard. 2011. ‚ÄúA Semi-Markov Model to Assess Reliably Survival Patterns from Birth to Death in Free-Ranging..."">
+<meta property=""og:description"" content=""Albert, Jim, and Jingchen Hu. 2019. Probability and Bayesian Modeling. 1st edition. Chapman; Hall/CRC.  Choquet, R√©mi, Anne Viallefont, Lauriane Rouan, Kamel Gaanoun, and Jean-Michel Gaillard...."">
 <meta name=""twitter:card"" content=""summary"">
 <meta name=""twitter:title"" content=""References | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R"">
-<meta name=""twitter:description"" content=""Choquet, R√©mi, Anne Viallefont, Lauriane Rouan, Kamel Gaanoun, and Jean-Michel Gaillard. 2011. ‚ÄúA Semi-Markov Model to Assess Reliably Survival Patterns from Birth to Death in Free-Ranging..."">
+<meta name=""twitter:description"" content=""Albert, Jim, and Jingchen Hu. 2019. Probability and Bayesian Modeling. 1st edition. Chapman; Hall/CRC.  Choquet, R√©mi, Anne Viallefont, Lauriane Rouan, Kamel Gaanoun, and Jean-Michel Gaillard...."">
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.10/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.2.5.1/tabs.js""></script><script src=""libs/bs3compat-0.2.5.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
@@ -49,17 +49,17 @@ <h1>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
 <li><a class="""" href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></li>
 <li><a class="""" href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></li>
 <li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></li>
 <li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
 <li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></li>
 <li><a class="""" href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></li>
 <li><a class="""" href=""stopover.html""><span class=""header-section-number"">12</span> Stopover duration</a></li>
@@ -80,6 +80,9 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 </h1>
 
 <div id=""refs"" class=""references csl-bib-body hanging-indent"">
+<div id=""ref-alberthu2019"" class=""csl-entry"">
+Albert, Jim, and Jingchen Hu. 2019. <em>Probability and <span>Bayesian</span> <span>Modeling</span></em>. 1st edition. Chapman; Hall/CRC.
+</div>
 <div id=""ref-choquet_semi-markov_2011"" class=""csl-entry"">
 Choquet, R√©mi, Anne Viallefont, Lauriane Rouan, Kamel Gaanoun, and Jean-Michel Gaillard. 2011. <span>‚ÄúA Semi-<span>Markov</span> Model to Assess Reliably Survival Patterns from Birth to Death in Free-Ranging Populations.‚Äù</span> <em>Methods in Ecology and Evolution</em> 2 (4): 383‚Äì89.
 </div>
@@ -119,9 +122,18 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 <div id=""ref-karamanlidis_evidence_2015"" class=""csl-entry"">
 Karamanlidis, Alexandros A., Miguel de Gabriel Hernando, Lambros Krambokoukis, and Olivier Gimenez. 2015. <span>‚ÄúEvidence of a Large Carnivore Population Recovery: <span>Counting</span> Bears in <span>Greece</span>.‚Äù</span> <em>Journal for Nature Conservation</em> 27: 10‚Äì17.
 </div>
+<div id=""ref-king_bayesian_2009"" class=""csl-entry"">
+King, Ruth, B. J. T. Morgan, O. Gimenez, and S. P. Brooks. 2009. <em>Bayesian <span>Analysis</span> for <span>Population</span> <span>Ecology</span></em>. Chapman; Hall/CRC.
+</div>
 <div id=""ref-MarescotEtAl2018"" class=""csl-entry"">
 Marescot, L., S. Benhaiem, O. Gimenez, H. Hofer, J.-D. Lebreton, X. A. Olarte-Castillo, S. Kramer-Schadt, and M. L. East. 2018. <span>‚ÄúSocial Status Mediates the Fitness Costs of Infection with Canine Distemper Virus in <span>Serengeti</span> Spotted Hyenas.‚Äù</span> <em>Functional Ecology</em> 32 (5): 1237‚Äì50.
 </div>
+<div id=""ref-mcelreathbook"" class=""csl-entry"">
+McElreath, Richard. 2016. <em>Statistical <span>Rethinking</span>: <span>A</span> <span>Bayesian</span> <span>Course</span> with <span>Examples</span> in <span>R</span> and <span>Stan</span></em>. 1st edition. Chapman; Hall/CRC.
+</div>
+<div id=""ref-mcgrayne2011"" class=""csl-entry"">
+McGrayne, Sharon Bertsch. 2011. <em>The <span>Theory</span> <span>That</span> <span>Would</span> <span>Not</span> <span>Die</span>: <span>How</span> <span>Bayes</span>‚Äô <span>Rule</span> <span>Cracked</span> the <span>Enigma</span> <span>Code</span>, <span>Hunted</span> <span>Down</span> <span>Russian</span> <span>Submarines</span>, and <span>Emerged</span> <span>Triumphant</span> from <span>Two</span> <span>Centuries</span> of <span>Controversy</span></em>. Yale University Press.
+</div>
 <div id=""ref-morano_life-history_2013"" class=""csl-entry"">
 Morano, Sabrina, Kelley M. Stewart, James S. Sedinger, Christopher A. Nicolai, and Martin Vavra. 2013. <span>‚ÄúLife-History Strategies of <span>North</span> <span>American</span> Elk: Trade-Offs Associated with Reproduction and Survival.‚Äù</span> <em>Journal of Mammalogy</em> 94 (1): 162‚Äì72.
 </div>
@@ -166,6 +178,21 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 </div>
 </div>
 </div>
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
 
 
 
@@ -194,14 +221,42 @@ <h1>References<a class=""anchor"" aria-label=""anchor"" href=""#references""><i class=
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
 </body>
 </html>

---FILE: docs/search.json---
@@ -1 +1 @@
-[{""path"":""index.html"",""id"":""welcome"",""chapter"":""Welcome"",""heading"":""Welcome"",""text"":""Welcome online version book Bayesian Analysis Capture-Recapture Data Hidden Markov Models ‚Äì Theory Case Studies R. HMM framework gained much attention ecological literature last decade, suggested general modelling framework demography plant animal populations. particular, HMMs increasingly used analyse capture-recapture data estimate key population parameters (e.g., survival, dispersal, recruitment abundance) applications fields ecology.parallel, Bayesian statistics well established fast growing ecology related disciplines, resonates scientific reasoning allows accommodating uncertainty smoothly. popularity Bayesian statistics also comes availability free pieces software (WinBUGS, OpenBUGS, JAGS, Stan, NIMBLE) allow practitioners code analyses.book offers Bayesian treatment HMMs applied capture-recapture data. learn use R package NIMBLE seen many future Bayesian statistical ecology deal complex models /big data. important part book consists case studies presented tutorial style abide ‚Äúlearning ‚Äù philosophy.‚Äôm currently writing book, welcome feedback. may raise issue , amend directly R Markdown file generated page ‚Äôre reading clicking ‚ÄòEdit page‚Äô icon right panel, email . Many thanks!Olivier Gimenez, Montpellier, France\nLast updated: September 19, 2021"",""code"":""""},{""path"":""index.html"",""id"":""license"",""chapter"":""Welcome"",""heading"":""License"",""text"":""online version book licensed Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.code public domain, licensed Creative Commons CC0 1.0 Universal (CC0 1.0)."",""code"":""""},{""path"":""preface.html"",""id"":""preface"",""chapter"":""Preface"",""heading"":""Preface"",""text"":"""",""code"":""""},{""path"":""preface.html"",""id"":""why-this-book"",""chapter"":""Preface"",""heading"":""Why this book?"",""text"":""completed. capture-recapture data models, fields application.1 Brief history capture-recapture, switch state-space/hidden Markov model (HMM) formulation. Flexibility HMM decompose complex problems smaller pieces easier understand, model analyse. satellite guidance conservation endangered species. Bayes? Also three fav research topics ‚Äì capture-recapture, HMM Bayes statistics ‚Äì let‚Äôs enjoy great cocktail together."",""code"":""""},{""path"":""preface.html"",""id"":""who-should-read-this-book"",""chapter"":""Preface"",""heading"":""Who should read this book?"",""text"":""book aimed beginners ‚Äôre comfortable using R write basic code (including loops), well connoisseurs capture-recapture ‚Äôd like tap power Bayesian side statistics. audiences, thinking HMM framework help confidently building models make capture-recapture data."",""code"":""""},{""path"":""preface.html"",""id"":""what-will-you-learn"",""chapter"":""Preface"",""heading"":""What will you learn?"",""text"":""book divided five parts. first part aimed getting --speed Bayesian statistics, NIMBLE, hidden Markov models. second part teach capture-recapture models open populations, reproducible R code ease learning process. third part, focus issues inferring states (dealing uncertainty assignment, modelling waiting time distribution). fourth part provides real-world case studies scientific literature can reproduce using material covered previous chapters. problems can either ) used cement deepen understanding methods models, ii) adapted purpose, iii) serve teaching projects. fifth last chapter closes book take-home messages recommendations, list frequently asked questions references cited book. Likely amended feedbacks."",""code"":""""},{""path"":""preface.html"",""id"":""what-wont-you-learn"",""chapter"":""Preface"",""heading"":""What won‚Äôt you learn?"",""text"":""hardly maths book. equations use either simple enough understood without background maths, can skipped without prejudice. cover Bayesian statistics even hidden Markov models fully, provide just need work capture-recapture data. interested knowing topics, hopefully section Suggested reading end chapter put right direction. also number important topics specific capture-recapture cover, including closed-population capture-recapture models (Williams, Nichols, Conroy 2002), spatial capture-recapture models (Royle et al. 2013). models can treated HMMs, now usual formulation just fine. spatial considerations Covariates chapter w/ splines CAR. ‚Äôm sure yet SCR models (R. Glennie‚Äôs Biometrics paper HMMs open pop SCR easy Bayes transform implement NIMBLE)."",""code"":""""},{""path"":""preface.html"",""id"":""prerequisites"",""chapter"":""Preface"",""heading"":""Prerequisites"",""text"":""book uses primarily R package NIMBLE, need install least R NIMBLE. bunch R packages used. can install running:"",""code"":""\ninstall.packages(c(\n  \""magick\"", \""MCMCvis\"", \""nimble\"", \""pdftools\"", \n  \""tidyverse\"", \""wesanderson\"" \n))""},{""path"":""preface.html"",""id"":""acknowledgements"",""chapter"":""Preface"",""heading"":""Acknowledgements"",""text"":""completed."",""code"":""""},{""path"":""preface.html"",""id"":""how-this-book-was-written"",""chapter"":""Preface"",""heading"":""How this book was written"",""text"":""writing book RStudio using bookdown. book website hosted GitHub Pages, automatically updated every push Github Actions. source available GitHub.version book ‚Äôre reading built R version 4.1.0 (2021-05-18) following packages:"",""code"":""""},{""path"":""about-the-author.html"",""id"":""about-the-author"",""chapter"":""About the author"",""heading"":""About the author"",""text"":""name Olivier Gimenez (https://oliviergimenez.github.io/). senior (euphemism young anymore) scientist National Centre Scientific Research (CNRS) beautiful city Montpellier, France.struggled studying maths, obtained PhD applied statistics long time ago galaxy wine cheese. awarded habilitation (https://en.wikipedia.org/wiki/Habilitation) ecology evolution stop pretending understand colleagues talking . recently embarked sociology studies hey, .Lost somewhere interface animal ecology, statistical modeling social sciences, -called expertise lies population dynamics species distribution modeling address questions ecology conservation biology impact human activities management large carnivores. nothing without students colleagues kind enough bear .may find Twitter (https://twitter.com/oaggimenez), GitHub (https://github.com/oliviergimenez), get touch email."",""code"":""""},{""path"":""introduction.html"",""id"":""introduction"",""chapter"":""Introduction"",""heading"":""Introduction"",""text"":"""",""code"":""""},{""path"":""crashcourse.html"",""id"":""crashcourse"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1 Bayesian statistics & MCMC"",""text"":"""",""code"":""""},{""path"":""intronimble.html"",""id"":""intronimble"",""chapter"":""2 NIMBLE"",""heading"":""2 NIMBLE"",""text"":"""",""code"":""""},{""path"":""hmmcapturerecapture.html"",""id"":""hmmcapturerecapture"",""chapter"":""3 Hidden Markov models"",""heading"":""3 Hidden Markov models"",""text"":""‚Äì>\n ‚Äì>‚Äì>\n ‚Äì>\n ‚Äì>\n ‚Äì>\n ‚Äì>"",""code"":""""},{""path"":""introduction-1.html"",""id"":""introduction-1"",""chapter"":""Introduction"",""heading"":""Introduction"",""text"":"""",""code"":""""},{""path"":""survival.html"",""id"":""survival"",""chapter"":""4 Survival"",""heading"":""4 Survival"",""text"":""‚Äì>\n ‚Äì>‚Äì>‚Äì>‚Äì>‚Äì>\n ‚Äì>\n ‚Äì>‚Äì>‚Äì>\n ‚Äì>\n ‚Äì>\n ‚Äì>"",""code"":""""},{""path"":""covariates.html"",""id"":""covariates"",""chapter"":""5 Covariates"",""heading"":""5 Covariates"",""text"":"""",""code"":""""},{""path"":""dispersal.html"",""id"":""dispersal"",""chapter"":""6 Dispersal"",""heading"":""6 Dispersal"",""text"":"""",""code"":""""},{""path"":""model-selection.html"",""id"":""model-selection"",""chapter"":""7 Model selection and validation"",""heading"":""7 Model selection and validation"",""text"":"""",""code"":""""},{""path"":""introduction-2.html"",""id"":""introduction-2"",""chapter"":""Introduction"",""heading"":""Introduction"",""text"":"""",""code"":""""},{""path"":""uncertainty.html"",""id"":""uncertainty"",""chapter"":""8 State uncertainty"",""heading"":""8 State uncertainty"",""text"":"""",""code"":""""},{""path"":""hsmm.html"",""id"":""hsmm"",""chapter"":""9 Hidden semi-Markov models"",""heading"":""9 Hidden semi-Markov models"",""text"":"""",""code"":""""},{""path"":""introduction-3.html"",""id"":""introduction-3"",""chapter"":""Introduction"",""heading"":""Introduction"",""text"":"""",""code"":""""},{""path"":""tradeoffs.html"",""id"":""tradeoffs"",""chapter"":""10 Life history theory"",""heading"":""10 Life history theory"",""text"":"""",""code"":""""},{""path"":""tradeoffs.html"",""id"":""tradeoffs-1"",""chapter"":""10 Life history theory"",""heading"":""10.1 Tradeoffs"",""text"":""Morano et al. (2013), Shefferson et al. (2003), Cruz-Flores et al. (n.d.)"",""code"":""""},{""path"":""tradeoffs.html"",""id"":""breeding-dynamics"",""chapter"":""10 Life history theory"",""heading"":""10.2 Breeding dynamics"",""text"":""Pradel, Choquet, B√©chet (2012), Desprez et al. (2011), Desprez et al. (2013), Pacoureau et al. (2019)"",""code"":""""},{""path"":""tradeoffs.html"",""id"":""actuarial-senescence"",""chapter"":""10 Life history theory"",""heading"":""10.3 Actuarial senescence"",""text"":""Choquet et al. (2011), P√©ron et al. (2016)"",""code"":""""},{""path"":""tradeoffs.html"",""id"":""cause-specific-mortalities"",""chapter"":""10 Life history theory"",""heading"":""10.4 Cause-specific mortalities"",""text"":""Fern√°ndez-Chac√≥n et al. (2016) Ruette et al. (2015)"",""code"":""""},{""path"":""tradeoffs.html"",""id"":""disease-dynamics"",""chapter"":""10 Life history theory"",""heading"":""10.5 Disease dynamics"",""text"":""Marescot et al. (2018) Santoro et al. (2014)"",""code"":""""},{""path"":""tradeoffs.html"",""id"":""sex-uncertainty"",""chapter"":""10 Life history theory"",""heading"":""10.6 Sex uncertainty"",""text"":""Pradel et al. (2008) Genovart, Pradel, Oro (2012)"",""code"":""""},{""path"":""abundance.html"",""id"":""abundance"",""chapter"":""11 Abundance"",""heading"":""11 Abundance"",""text"":"""",""code"":""""},{""path"":""abundance.html"",""id"":""horvitz-thompson"",""chapter"":""11 Abundance"",""heading"":""11.1 Horvitz-Thompson"",""text"":""Santostasi et al. (2019)"",""code"":""""},{""path"":""abundance.html"",""id"":""jolly-seber"",""chapter"":""11 Abundance"",""heading"":""11.2 Jolly-Seber"",""text"":"""",""code"":""""},{""path"":""abundance.html"",""id"":""robust-design"",""chapter"":""11 Abundance"",""heading"":""11.3 Robust design"",""text"":""Karamanlidis et al. (2015), Santostasi et al. (2016), Gibson et al. (2018), Rankin et al. (2016)"",""code"":""""},{""path"":""stopover.html"",""id"":""stopover"",""chapter"":""12 Stopover duration"",""heading"":""12 Stopover duration"",""text"":""Gu√©rin et al. (2017)"",""code"":""""},{""path"":""individual-dependence.html"",""id"":""individual-dependence"",""chapter"":""13 Individual dependence"",""heading"":""13 Individual dependence"",""text"":"""",""code"":""""},{""path"":""individual-dependence.html"",""id"":""dependence-among-individuals"",""chapter"":""13 Individual dependence"",""heading"":""13.1 Dependence among individuals"",""text"":""Culina et al. (2013) Cubaynes et al. (2021)"",""code"":""""},{""path"":""individual-dependence.html"",""id"":""individual-heterogeneity"",""chapter"":""13 Individual dependence"",""heading"":""13.2 Individual heterogeneity"",""text"":""Cubaynes et al. (2010), Gimenez Choquet (2010), Turek, Wehrhahn, Gimenez (2021)"",""code"":""""},{""path"":""take-home-messages.html"",""id"":""take-home-messages"",""chapter"":""Take-home messages"",""heading"":""Take-home messages"",""text"":""‚Äì>\n ‚Äì>‚Äì>‚Äì>‚Äì>"",""code"":""""},{""path"":""faq.html"",""id"":""faq"",""chapter"":""FAQ"",""heading"":""FAQ"",""text"":"""",""code"":""""},{""path"":""references.html"",""id"":""references"",""chapter"":""References"",""heading"":""References"",""text"":"""",""code"":""""}]
+[{""path"":""index.html"",""id"":""welcome"",""chapter"":""Welcome"",""heading"":""Welcome"",""text"":""Welcome online version book Bayesian Analysis Capture-Recapture Data Hidden Markov Models ‚Äì Theory Case Studies R. HMM framework gained much attention ecological literature last decade, suggested general modelling framework demography plant animal populations. particular, HMMs increasingly used analyse capture-recapture data estimate key population parameters (e.g., survival, dispersal, recruitment abundance) applications fields ecology.parallel, Bayesian statistics well established fast growing ecology related disciplines, resonates scientific reasoning allows accommodating uncertainty smoothly. popularity Bayesian statistics also comes availability free pieces software (WinBUGS, OpenBUGS, JAGS, Stan, NIMBLE) allow practitioners code analyses.book offers Bayesian treatment HMMs applied capture-recapture data. learn use R package NIMBLE seen many future Bayesian statistical ecology deal complex models /big data. important part book consists case studies presented tutorial style abide ‚Äúlearning ‚Äù philosophy.‚Äôm currently writing book, welcome feedback. may raise issue , amend directly R Markdown file generated page ‚Äôre reading clicking ‚ÄòEdit page‚Äô icon right panel, email . Many thanks!Olivier Gimenez, Montpellier, France\nLast updated: September 20, 2021"",""code"":""""},{""path"":""index.html"",""id"":""license"",""chapter"":""Welcome"",""heading"":""License"",""text"":""online version book licensed Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.code public domain, licensed Creative Commons CC0 1.0 Universal (CC0 1.0)."",""code"":""""},{""path"":""preface.html"",""id"":""preface"",""chapter"":""Preface"",""heading"":""Preface"",""text"":"""",""code"":""""},{""path"":""preface.html"",""id"":""why-this-book"",""chapter"":""Preface"",""heading"":""Why this book?"",""text"":""completed. capture-recapture data models, fields application.1 Brief history capture-recapture, switch state-space/hidden Markov model (HMM) formulation. Flexibility HMM decompose complex problems smaller pieces easier understand, model analyse. satellite guidance conservation endangered species. Bayes? Also three fav research topics ‚Äì capture-recapture, HMM Bayes statistics ‚Äì let‚Äôs enjoy great cocktail together."",""code"":""""},{""path"":""preface.html"",""id"":""who-should-read-this-book"",""chapter"":""Preface"",""heading"":""Who should read this book?"",""text"":""book aimed beginners ‚Äôre comfortable using R write basic code (including loops), well connoisseurs capture-recapture ‚Äôd like tap power Bayesian side statistics. audiences, thinking HMM framework help confidently building models make capture-recapture data."",""code"":""""},{""path"":""preface.html"",""id"":""what-will-you-learn"",""chapter"":""Preface"",""heading"":""What will you learn?"",""text"":""book divided five parts. first part aimed getting --speed Bayesian statistics, NIMBLE, hidden Markov models. second part teach capture-recapture models open populations, reproducible R code ease learning process. third part, focus issues inferring states (dealing uncertainty assignment, modelling waiting time distribution). fourth part provides real-world case studies scientific literature can reproduce using material covered previous chapters. problems can either ) used cement deepen understanding methods models, ii) adapted purpose, iii) serve teaching projects. fifth last chapter closes book take-home messages recommendations, list frequently asked questions references cited book. Likely amended feedbacks."",""code"":""""},{""path"":""preface.html"",""id"":""what-wont-you-learn"",""chapter"":""Preface"",""heading"":""What won‚Äôt you learn?"",""text"":""hardly maths book. equations use either simple enough understood without background maths, can skipped without prejudice. cover Bayesian statistics even hidden Markov models fully, provide just need work capture-recapture data. interested knowing topics, hopefully section Suggested reading end chapter put right direction. also number important topics specific capture-recapture cover, including closed-population capture-recapture models (Williams, Nichols, Conroy 2002), spatial capture-recapture models (Royle et al. 2013). models can treated HMMs, now usual formulation just fine. spatial considerations Covariates chapter w/ splines CAR. ‚Äôm sure yet SCR models (R. Glennie‚Äôs Biometrics paper HMMs open pop SCR easy Bayes transform implement NIMBLE)."",""code"":""""},{""path"":""preface.html"",""id"":""prerequisites"",""chapter"":""Preface"",""heading"":""Prerequisites"",""text"":""book uses primarily R package NIMBLE, need install least R NIMBLE. bunch R packages used. can install running:"",""code"":""\ninstall.packages(c(\n  \""magick\"", \""MCMCvis\"", \""nimble\"", \""pdftools\"", \n  \""tidyverse\"", \""wesanderson\"" \n))""},{""path"":""preface.html"",""id"":""acknowledgements"",""chapter"":""Preface"",""heading"":""Acknowledgements"",""text"":""completed."",""code"":""""},{""path"":""preface.html"",""id"":""how-this-book-was-written"",""chapter"":""Preface"",""heading"":""How this book was written"",""text"":""writing book RStudio using bookdown. book website hosted GitHub Pages, automatically updated every push Github Actions. source available GitHub.version book ‚Äôre reading built R version 4.1.0 (2021-05-18) following packages:"",""code"":""""},{""path"":""about-the-author.html"",""id"":""about-the-author"",""chapter"":""About the author"",""heading"":""About the author"",""text"":""name Olivier Gimenez (https://oliviergimenez.github.io/). senior (euphemism young anymore) scientist National Centre Scientific Research (CNRS) beautiful city Montpellier, France.struggled studying maths, obtained PhD applied statistics long time ago galaxy wine cheese. awarded habilitation (https://en.wikipedia.org/wiki/Habilitation) ecology evolution stop pretending understand colleagues talking . recently embarked sociology studies hey, .Lost somewhere interface animal ecology, statistical modeling social sciences, -called expertise lies population dynamics species distribution modeling address questions ecology conservation biology impact human activities management large carnivores. nothing without students colleagues kind enough bear .may find Twitter (https://twitter.com/oaggimenez), GitHub (https://github.com/oliviergimenez), get touch email."",""code"":""""},{""path"":""introduction.html"",""id"":""introduction"",""chapter"":""Introduction"",""heading"":""Introduction"",""text"":"""",""code"":""""},{""path"":""crashcourse.html"",""id"":""crashcourse"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1 Bayesian statistics & MCMC"",""text"":"""",""code"":""""},{""path"":""crashcourse.html"",""id"":""introduction-1"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.1 Introduction"",""text"":""first chapter, learn Bayesian theory , may use simple example. also see implement simulation algorithms implement Bayesian method complex analyses. exhaustive treatment Bayesian statistics, get need navigate rest book."",""code"":""""},{""path"":""crashcourse.html"",""id"":""bayes-theorem"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.2 Bayes‚Äô theorem"",""text"":""Let‚Äôs wait longer jump . Bayesian statistics relies Bayes‚Äô theorem (law, rule, whatever prefer) named Reverend Thomas Bayes (Figure 1.1). theorem published 1763 two years Bayes‚Äô death thanks friend‚Äôs efforts Richard Price, independently discovered Pierre-Simon Laplace (McGrayne 2011).\nFigure 1.1: Cartoon Thomas Bayes Bayes‚Äô theorem background. Source: James Kulich\nsee minute, Bayes‚Äô theorem conditional probabilities, somehow tricky understand. Conditional probability outcome event given event B, denote \\(\\Pr(\\mid B)\\), probability occurs, revised considering additional information event B occurred.2 order B appear important, make sure confuse \\(\\Pr(\\mid B)\\) \\(\\Pr(B \\mid )\\).Bayes‚Äô theorem (Figure 1.2) gives \\(\\Pr(\\mid B)\\) using marginal probabilities \\(\\Pr()\\) \\(\\Pr(B)\\) \\(\\Pr(B \\mid )\\):\n\\[\\Pr(\\mid B) = \\displaystyle{\\frac{ \\Pr(B \\mid ) \\; \\Pr()}{\\Pr(B)}}.\\]\nOriginally, Bayes‚Äô theorem seen way infer unkown cause particular effect B, knowing probability effect B given cause . Think example situation medical diagnosis needed, unkown disease B symptoms, doctor knows P(symptoms|disease) wants derive P(disease|symptoms). way reversing \\(\\Pr(B \\mid )\\) \\(\\Pr(\\mid B)\\) explains Bayesian thinking used referred ‚Äòinverse probability.‚Äô\nFigure 1.2: Bayes‚Äô theorem spelt blue neon. Source: Wikipedia\ndon‚Äôt know , need think twice messing letters around. find easier remember Bayes‚Äô theorem written like this3:great think , exactly scientific method ! ‚Äôd like know plausible hypothesis based data collected, possibly compare several hypotheses among . respect, Bayesian reasoning matches scientific reasoning, probably explains Bayesian framework natural understanding statistics.might ask , Bayesian statistics default statistics? Clearly, futile wars male statisticians (including Ronald Fisher, Jerzy Neyman Egon Sharpe Pearson among others), little progress made two centuries. Also, recently, practical problems implement Bayes‚Äô theorem. Recent advances computational power coupled development new algorithms led great increase application Bayesian methods within last three decades."",""code"":""""},{""path"":""crashcourse.html"",""id"":""what-is-the-bayesian-approach"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.3 What is the Bayesian approach?"",""text"":""Typical statistical problems involve estimating parameter (several parameters) \\(\\theta\\) available data. , might used frequentist rather Bayesian method. frequentist approach, particular maximum likelihood estimation (MLE), assumes parameters fixed, unknown values estimated. Therefore classical estimates generally point estimates parameters interest. contrast, Bayesian approach assumes parameters fixed, unknown distribution4.Bayesian approach based upon idea , experimenter, begin prior beliefs system. collect data update prior beliefs basis observations. observations might arise field work, lab work expertise esteemed colleagues. updating process based upon Bayes‚Äô theorem. Loosely, let‚Äôs say \\(= \\theta\\) \\(B = \\text{data}\\), Bayes‚Äô theorem gives way estimate parameter \\(\\theta\\) given data :\\[{\\color{red}{\\Pr(\\theta \\mid \\text{data})}} = \\frac{\\color{blue}{\\Pr(\\text{data} \\mid \\theta)} \\times \\color{green}{\\Pr(\\theta)}}{\\color{orange}{\\Pr(\\text{data})}}.\\]\nLet‚Äôs spend time going quantity formula.left-hand side \\(\\color{red}{\\text{posterior distribution}}\\). represents know seen data. basis inference clearly ‚Äôre , distribution, possibly multivariate one parameter.right-hand side, \\(\\color{blue}{\\text{likelihood}}\\). quantity MLE approach. Yes, Bayesian frequentist approaches likelihood core, mostly explains results often differ much. likelihood captures information data, given model parameterized \\(\\theta\\).\\(\\color{green}{\\text{prior distribution}}\\). quantity represents know seeing data. source much discussion Bayesian approach. may vague don‚Äôt know anything \\(\\theta\\). Usually however, never start scratch, ‚Äôd like prior reflect information have5.Last, \\(\\color{orange}{\\Pr(\\text{data})}\\) sometimes called average likelihood obtained integrating likelihood respect prior \\(\\color{orange}{\\Pr(\\text{data}) = \\int{L(\\text{data} \\mid \\theta)\\Pr(\\theta) d\\theta}}\\) posterior standardized, integrates one posterior distribution. average likelihood integral dimension number parameters \\(\\theta\\) need estimate. quantity difficult, impossible, calculate general. one reasons Bayesian method wasn‚Äôt used recently, need algorithms estimate posterior distributions illustrate next section."",""code"":""""},{""path"":""crashcourse.html"",""id"":""numerical-approx"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.4 Approximating posteriors via numerical integration"",""text"":""Let‚Äôs take example illustrate Bayes‚Äô theorem. Say capture, mark release \\(n = 57\\) animals beginning winter, recapture \\(y = 19\\) animals alive6. ‚Äôd like estimate winter survival \\(\\theta\\).build model first. Assuming animals independent survival probability, \\(y\\) number alive animals end winter binomial distribution7 \\(n\\) trials \\(\\theta\\) probability success:\\[\\begin{align*}\ny &\\sim \\text{Binomial}(n, \\theta) &\\text{[likelihood]}\n\\end{align*}\\]likelihood can visualised R:\nFigure 1.3: Binomial likelihood \\(n = 57\\) released animals \\(y = 19\\) survivors winter. value survival (x-axis) corresponds maximum likelihood function (y-axis) MLE, proportion success example, close 0.33.\nBesides likelihood, priors another component model Bayesian approach. parameter probability, one thing know prior continuous random variable lies 0 1. reflect , often go uniform distribution \\(U(0,1)\\) imply vague priors. vague means survival , see data, probability falling 0.1 0.2 0.8 0.9, example.\\[\\begin{align*}\n\\theta &\\sim \\text{Uniform}(0, 1) &\\text{[prior }\\theta \\text{]}\n\\end{align*}\\]Now apply Bayes‚Äô theorem. write R function computes product likelihood times prior, numerator Bayes‚Äô theorem: \\(\\Pr(\\text{data} \\mid \\theta) \\times \\Pr(\\theta)\\)write another function calculates denominator, average likelihood: \\(\\Pr(\\text{data}) = \\int{L(\\theta \\mid \\text{data}) \\Pr(\\theta) d\\theta}\\)use R function integrate calculate integral denominator, implements quadrature techniques divide little squares area underneath curve delimited function integrate (numerator), count .get numerical approximation posterior Figure 1.4 applying Bayes‚Äô theorem.\nFigure 1.4: Winter survival posterior distribution obtained numerical integration.\ngood numerical approximation survival posterior distribution? Ideally, want compare approximation true posterior distribution. Although closed-form expression posterior distribution general intractable, combine binomial likelihood together beta distribution prior, posterior distribution also beta distribution, makes amenable sorts exact calculations8. beta distribution continuous 0 1, extends uniform distribution situations outcomes equally likely. two parameters \\(\\) \\(b\\) control shape (Figure 1.5).\nFigure 1.5: distribution beta(\\(\\),\\(b\\)) different values \\(\\) \\(b\\). Note \\(= b = 1\\), get uniform distribution 0 1 top left panel. \\(\\) \\(b\\) equal, distribution symmetric, bigger \\(\\) \\(b\\), peaked distribution smaller variance.\n\nFigure 1.6: Comparison exact (dashed line) vs.¬†numerical approximation (continuous line) winter survival posterior distribution.\nexample, single parameter estimate, winter survival. means dealing one-dimensional integral denominator pretty easy quadrature techniques R function integrate(). Now multiple parameters? example, imagine ‚Äôd like fit capture-recapture model detection probability \\(p\\) regression parameters \\(\\alpha\\) \\(\\beta\\) intercept slope relationship survival probability covariate, Bayes‚Äô theorem gives posterior distribution three parameters together:\\[ \\Pr(\\alpha, \\beta, p \\mid \\text{data}) = \\frac{ \\Pr(\\text{data} \\mid \\alpha, \\beta, p) \\times \\Pr(\\alpha, \\beta, p)}{\\iiint \\, \\Pr(\\text{data} \\mid \\alpha, \\beta, p) \\Pr(\\alpha, \\beta, p) d\\alpha d\\beta dp} \\]\ntwo computational challenges formula. First, really wish calculate three-dimensional integral? answer , one-dimensional two-dimensional integrals much can go standard methods. Second, ‚Äôre interested posterior distribution parameter separately joint posterior distribution. -called marginal distribution \\(p\\) example obtained integrating parameters ‚Äì two-dimensional integral example. Now imagine tens hundreds parameters estimate, integrals become highly multi-dimensional simply intractable. next section, introduce powerful simulation methods circumvent issue."",""code"":""\ny <- 19 # nb of success\nn <- 57 # nb of attempts\ngrid <- seq(0, 1, 0.01) # grid of values for survival\nlikelihood <- dbinom(y, n, grid) # compute binomial likelihood\ndf <- data.frame(survival = grid, likelihood = likelihood) \ndf %>%\n  ggplot() + \n  aes(x = survival, y = likelihood) + \n  geom_line(size = 1.5)\nnumerator <- function(theta) dbinom(y, n, theta) * dunif(theta, 0, 1)\ndenominator <- integrate(numerator,0,1)$value\ngrid <- seq(0, 1, 0.01) # grid of values for theta\nnumerical_posterior <- data.frame(survival = grid, \n                                  posterior = numerator(grid)/denominator) # Bayes' theorem\nnumerical_posterior %>%\n  ggplot() +\n  aes(x = survival, y = posterior) + \n  geom_line(size = 1.5)""},{""path"":""crashcourse.html"",""id"":""markov-chain-monte-carlo-mcmc"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.5 Markov chain Monte Carlo (MCMC)"",""text"":""early 1990s, statisticians rediscovered work 1950‚Äôs physics. famous paper lay fundations modern Bayesian statistics (Figure 1.7), authors use simulations approximate posterior distributions precision drawing large samples. neat trick avoid explicit calculation multi-dimensional integrals struggle using Bayes‚Äô theorem.\nFigure 1.7: MCMC article cover. Source: Journal Chemical Physics\nsimulation algorithms called Markov chain Monte Carlo (MCMC), definitely gave boost Bayesian statistics. two parts MCMC, Markov chain Monte Carlo, let‚Äôs try make sense terms."",""code"":""""},{""path"":""crashcourse.html"",""id"":""monte-carlo-integration"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.5.1 Monte Carlo integration"",""text"":""Monte Carlo stand ? Monte Carlo integration simulation technique calculate integrals function \\(f\\) random variable \\(X\\) distribution \\(\\Pr(X)\\) say \\(\\int f(X) \\Pr(X)dX\\). draw values \\(X_1,\\ldots,X_k\\) \\(\\Pr(X)\\) distribution \\(X\\), apply function \\(f\\) values, calculate mean new values \\(\\displaystyle{\\frac{1}{k}}\\sum_{=1}^k{f(X_i)}\\) approximate integral. Monte Carlo integration used Bayesian context? posterior distribution contains information need parameter estimated. dealing many parameters however, may want summarise posterior results calculating numerical summaries. simplest numerical summary mean posterior distribution, \\(E(\\theta) = \\int \\theta \\Pr(\\theta|\\text{data})\\), \\(X\\) \\(\\theta\\) now \\(f\\) identity function. Posterior mean can calculated Monte Carlo integration:may check mean just calculated matches closely expectation beta distribution10:Another useful numerical summary credible interval within parameter falls probability, usually 0.95 hence 95\\(\\%\\) credible interval. Finding bounds credible interval requires calculating quantiles, turn involves integrals use Monte Carlo integration. 95\\(\\%\\) credible interval winter survival can obtained R :"",""code"":""\nsample_from_posterior <- rbeta(1000, 20, 39) # draw 1000 values from posterior survival beta(20,39)\nmean(sample_from_posterior) # compute mean with Monte Carlo integration\n## [1] 0.3376\n20/(20+39) # expectation of beta(20,39)\n## [1] 0.339\nquantile(sample_from_posterior, probs = c(2.5/100, 97.5/100))\n##   2.5%  97.5% \n## 0.2309 0.4629""},{""path"":""crashcourse.html"",""id"":""markov-chains"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.5.2 Markov chains"",""text"":""Markov chain? Markov chain random sequence numbers, number depends previous number. example weather home town Southern France, Montpellier, sunny day likely followed another sunny day, say probability 0.8, rainy day rarely followed another rainy day, say probability 0.1. dynamic Markov chain captured transition matrix \\(\\mathbf{\\Gamma}\\):\n\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    \\text{sunny tomorrow} & \\text{rainy tomorrow} \\\\ \n0.8 & 0.2 \\\\ \n0.9 & 0.1 \\\\ \n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    \\text{sunny today} \\\\ \\text{rainy today}\n    \\end{matrix}\n\\end{matrix}\n\\]\nrows weather today, columns weather tomorrow. cells give probability sunny rainy day tomorrow, given day sunny rainy today. certain conditions11, Markov chain converge unique stationary distribution. weather example, let‚Äôs run Markov chain 20 steps:row transition matrix converges distribution \\((0.82, 0.18)\\) number steps increases. Convergence happens matter state start , always probability 0.82 day sunny 0.18 day rainy.Back MCMC, core idea can build Markov chain given stationary distribution set desired posterior distribution."",""code"":""\nweather <- matrix(c(0.8, 0.2, 0.9, 0.1), nrow = 2, byrow = T) # transition matrix\nsteps <- 20\nfor (i in 1:steps){\n  weather <- weather %*% weather # matrix multiplication\n}\nround(weather, 2) # matrix product after 20 steps\n##      [,1] [,2]\n## [1,] 0.82 0.18\n## [2,] 0.82 0.18""},{""path"":""crashcourse.html"",""id"":""metropolis-algorithm"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.5.3 Metropolis algorithm"",""text"":""several ways constructing Markov chains Bayesian inference12. illustrate Metropolis algorithm implement practice13.Let‚Äôs go back example animal survival estimation. illustrate sampling survival posterior distribution. write functions likelihood, prior posterior.Metropolis algorithm works follows:pick value parameter estimated. start Markov chain ‚Äì starting value.pick value parameter estimated. start Markov chain ‚Äì starting value.decide go next, propose move away current value parameter ‚Äì candidate value. , add current value random value e.g.¬†normal distribution variance ‚Äì proposal distribution. Metropolis algorithm particular case Metropolis-Hastings algorithm symmetric proposals.decide go next, propose move away current value parameter ‚Äì candidate value. , add current value random value e.g.¬†normal distribution variance ‚Äì proposal distribution. Metropolis algorithm particular case Metropolis-Hastings algorithm symmetric proposals.compute ratio probabilities candidate current locations \\(R=\\displaystyle{\\frac{{\\Pr(\\text{candidate}|\\text{data})}}{{\\Pr(\\text{current}|\\text{data})}}}\\). magic MCMC happens, \\(\\Pr(\\text{data})\\), denominator Bayes‚Äô theorem, appears numerator denominator \\(R\\) therefore cancels need calculated.compute ratio probabilities candidate current locations \\(R=\\displaystyle{\\frac{{\\Pr(\\text{candidate}|\\text{data})}}{{\\Pr(\\text{current}|\\text{data})}}}\\). magic MCMC happens, \\(\\Pr(\\text{data})\\), denominator Bayes‚Äô theorem, appears numerator denominator \\(R\\) therefore cancels need calculated.posterior candidate location \\(\\Pr(\\text{candidate}|\\text{data})\\) higher current location \\(\\Pr(\\text{current}|\\text{data})\\), words candidate value plausible current value, definitely accept candidate value. , accept candidate value probability \\(R\\) reject probability \\(1-R\\). example, candidate value ten times less plausible current value, accept probability 0.1 reject probability 0.9. work practice? use continuous spinner lands somewhere 0 1 ‚Äì call random spin \\(X\\). \\(X\\) smaller \\(R\\), move candidate location, otherwise remain current location. want accept reject often. practice, Metropolis algorithm acceptance probability 0.2 0.4, can achieved tuning variance normal proposal distribution.posterior candidate location \\(\\Pr(\\text{candidate}|\\text{data})\\) higher current location \\(\\Pr(\\text{current}|\\text{data})\\), words candidate value plausible current value, definitely accept candidate value. , accept candidate value probability \\(R\\) reject probability \\(1-R\\). example, candidate value ten times less plausible current value, accept probability 0.1 reject probability 0.9. work practice? use continuous spinner lands somewhere 0 1 ‚Äì call random spin \\(X\\). \\(X\\) smaller \\(R\\), move candidate location, otherwise remain current location. want accept reject often. practice, Metropolis algorithm acceptance probability 0.2 0.4, can achieved tuning variance normal proposal distribution.repeat 2-4 number times ‚Äì steps.repeat 2-4 number times ‚Äì steps.Enough theory, let‚Äôs implement Metropolis algorithm R. Let‚Äôs start setting scene.Now follow 5 steps ‚Äôve just described. First, pick starting value, store (step 1)., need function propose candidate value. add value taken normal distribution mean zero standard deviation call away. work logit scale make sure candidate value survival lies 0 1.Now ‚Äôre ready steps 2, 3 4. write loop take care step 5. start initial value 0.5 run algorithm 100 steps iterations.get following values.\nFigure 1.8: Visualisation Markov chain starting value 0.5, steps iterations x-axis, samples y-axis. graphical representation called trace plot.\nacceptance probability average number times accepted candidated value, 0.44 almost satisfying.\nFigure 1.9: Trace plot survival two chains starting 0.2 (yellow) 0.5 (blue) run 100 steps.\n\nFigure 1.10: Trace plot survival chain starting 0.5 1000 steps.\n‚Äôre , trace plot looks like beautiful lawn, see Section 1.6. find informative look animated version Figure 1.10, helps understanding stochastic behavior algorithm, also realise chains converge stationary distribution, see Figure 1.11.\nFigure 1.11: Animated trace plot survival three chains starting 0.2, 0.5 0.7 run 1000 steps.\nstationary distribution reached, may regard realisations Markov chain sample posterior distribution, obtain numerical summaries. next section, consider several important implementation issues."",""code"":""\n# 19 animals recaptured alive out of 57 captured, marked and released\nsurvived <- 19\nreleased <- 57\n\n# binomial log-likelihood function\nloglikelihood <- function(x, p){\n  dbinom(x = x, size = released, prob = p, log = TRUE)\n}\n\n# uniform prior density\nlogprior <- function(p){\n  dunif(x = p, min = 0, max = 1, log = TRUE)\n}\n\n# posterior density function (log scale)\nposterior <- function(x, p){\n  loglikelihood(x, p) + logprior(p) # - log(Pr(data))\n}\nsteps <- 100 # number of steps\ntheta.post <- rep(NA, steps) # vector to store samples\naccept <- rep(NA, steps) # keep track of accept/reject\nset.seed(1234) # for reproducibility\ninits <- 0.5\ntheta.post[1] <- inits\naccept[1] <- 1\nmove <- function(x, away = 1){ # by default, standard deviation of the proposal distribution is 1\n  logitx <- log(x / (1 - x)) # apply logit transform (-infinity,+infinity)\n  logit_candidate <- logitx + rnorm(1, 0, away) # add a value taken from N(0,sd=away) to current value\n  candidate <- plogis(logit_candidate) # back-transform (0,1)\n  return(candidate)\n}\nfor (t in 2:steps){ # repeat steps 2-4 (step 5)\n  \n  # propose candidate value for survival (step 2)\n  theta_star <- move(theta.post[t-1])\n  \n  # calculate ratio R (step 3)\n  pstar <- posterior(survived, p = theta_star)  \n  pprev <- posterior(survived, p = theta.post[t-1])\n  logR <- pstar - pprev # likelihood and prior are on the log scale\n  R <- exp(logR)\n  \n  # accept candidate value or keep current value (step 4)\n  X <- runif(1, 0, 1) # spin continuous spinner\n  if (X < R){\n    theta.post[t] <- theta_star # accept candidate value\n    accept[t] <- 1 # accept\n  }\n  else{\n    theta.post[t] <- theta.post[t-1] # keep current value\n    accept[t] <- 0 # reject\n  }\n}\nhead(theta.post) # first values\n## [1] 0.5000 0.2302 0.2906 0.2906 0.2980 0.2980\ntail(theta.post) # last values\n## [1] 0.2622 0.2622 0.2622 0.3727 0.3232 0.3862""},{""path"":""crashcourse.html"",""id"":""convergence-diag"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.6 Assessing convergence"",""text"":"""",""code"":""""},{""path"":""crashcourse.html"",""id"":""burn-in"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.6.1 Burn-in"",""text"":""practice, discard observations start Markov chain just use observations chain converged. initial observations discard usually referred burn-.simplest method determine length burn-period look trace plots. Going back example, see trace plot Figure 1.12 need least 100 iterations achieve convergence toward average survival around 0.3. always better conservative specifying length burn-period, example, use 250 even 500 iterations burn-. length burn-period can determined performing preliminary MCMC short runs.\nFigure 1.12: Determining length burn-period. chain starts value 0.99 rapidly stabilises, values bouncing back forth around 0.3 100th iteration onwards. may choose shaded area burn-, discard corresponding values.\nInspecting trace plot single run Markov chain useful. However, usually run Markov chain several times, starting different -dispersed points, check runs achieve stationary distribution. approach formalised using Brooks-Gelman-Rubin (BGR) statistic \\(\\hat{R}\\) measures ratio total variability combining multiple chains (-chain plus within-chain) within-chain variability. BGR statistic asks whether chain effect, much alike \\(F\\) test analysis variance. Values 1.1 indicate likely convergence.Back example, run two Markov chains starting values 0.2 0.8 using 100 5000 iterations, calculate BGR statistic using half number iterations length burn-. Figure 1.13, get value BGR statistic near 1 2000 iterations, suggests 2000 iterations burn-, evidence lack convergence.\nFigure 1.13: Brooks-Gelman-Rubin statistic function number iterations.\nimportant bear mind value near 1 BGR statistic necessary sufficient condition convergence. words, diagnostic tell sure Markov chain achieved convergence, .14"",""code"":""""},{""path"":""crashcourse.html"",""id"":""chain-length"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.6.2 Chain length"",""text"":""long chain needed produce reliable parameter estimates? answer question, need keep mind successive steps Markov chain independent ‚Äì usually referred autocorrelation. Ideally, like keep autocorrelation low possible. , trace plots useful diagnose issues autocorrelation. Let‚Äôs get back survival example. Figure 1.14 shows trace plots different values standard deviation (parameter away) (normal) proposal distribution use propose candidate value (Section 1.5.3). Small big moves provide high correlations successive observations Markov chain, whereas standard deviation 1 allows efficient exploration parameter space. movement around parameter space referred mixing. Mixing bad chain makes small big moves, good otherwise.\nFigure 1.14: Trace plots different values standard deviation (SD) proposal distribution. Left: chain exhibits small moves mixing bad. Right: chain exhibits big moves mixing bad. Middle: chain exhibits adequate moves mixing good. thousand last iterations shown.\naddition trace plots, autocorrelation function (ACF) plots convenient way displaying strength autocorrelation given sample values. ACF plots provide autocorrelation successively sampled values separated increasing number iterations, lag (Figure 1.15).\nFigure 1.15: Autocorrelation function plots different values standard deviation (SD) proposal distribution. Left right: Autocorrelation strong, decreases slowly increasing lag mixing bad. Middle: Autocorrelation weak, decreases rapidly increasing lag mixing good.\nAutocorrelation necessarily big issue. Strongly correlated observations just require large sample sizes therefore longer simulations. many iterations exactly? effective sample size (n.eff) measures chain length taking account chain autocorrelation. check n.eff every parameter interest, interesting parameter combinations. general, need \\(\\text{n.eff} \\geq 1000\\) independent steps get reasonable Monte Carlo estimates model parameters. animal survival example, n.eff can calculated R coda::effectiveSize() function.expected, n.eff less number MCMC iterations autocorrelation. standard deviation proposal distribution 1 mixing good (Figures 1.14 1.15) get satisfying effective sample size."",""code"":""""},{""path"":""crashcourse.html"",""id"":""what-if-you-have-issues-of-convergence"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.6.3 What if you have issues of convergence?"",""text"":""diagnosing MCMC convergence, () often run troubles. section find helpful tips hope.mixing bad effective sample size small, may just need increase burn-/sample . Using informative priors might also make Markov chains converge faster helping MCMC sampler (e.g.¬†Metropolis algorithm) navigating efficiently parameter space. spirit, picking better initial values starting chain harm. , strategy consists using estimates simpler model MCMC chains converge.convergence issues persist, often problem model15. bug code? typo somewhere? mistake maths? often coding involved, issue can identified removing complexities, start simpler model find problem .general advice see model data generating tool first place, simulate data using realistic values parameters, try recover parameter values fitting model simulated data. Simulating model help understanding works, , data need get reasonable parameter estimates.see strategies improve convergence next chapters.16"",""code"":""""},{""path"":""crashcourse.html"",""id"":""summary"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.7 Summary"",""text"":""Bayes‚Äô theorem, update beliefs (prior) new data (likelihood) get posterior beliefs (posterior): posterior \\(\\propto\\) likelihood \\(\\times\\) prior.Bayes‚Äô theorem, update beliefs (prior) new data (likelihood) get posterior beliefs (posterior): posterior \\(\\propto\\) likelihood \\(\\times\\) prior.idea Markov chain Monte Carlo (MCMC) simulate values Markov chain stationary distribution equal posterior distribution ‚Äôre .idea Markov chain Monte Carlo (MCMC) simulate values Markov chain stationary distribution equal posterior distribution ‚Äôre .practice, run Markov chain multiple times starting -dispersed initial values.practice, run Markov chain multiple times starting -dispersed initial values.discard iterations initial burn-phase achieve convergence chains reach regime.discard iterations initial burn-phase achieve convergence chains reach regime., run chains long enough proceed calculating Monte Carlo estimates numerical summaries (e.g.¬†posterior means credible intervals) parameters., run chains long enough proceed calculating Monte Carlo estimates numerical summaries (e.g.¬†posterior means credible intervals) parameters."",""code"":""""},{""path"":""crashcourse.html"",""id"":""suggested-reading"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.8 Suggested reading"",""text"":""Gelman, . Hill, J. (2006). Data Analysis Using Regression Multilevel/Hierarchical Models (Analytical Methods Social Research). Cambridge: Cambridge University Press.Gelman, . Hill, J. (2006). Data Analysis Using Regression Multilevel/Hierarchical Models (Analytical Methods Social Research). Cambridge: Cambridge University Press.Gelman, . colleagues (2020). Bayesian workflow. arXiv preprint.Gelman, . colleagues (2020). Bayesian workflow. arXiv preprint.McCarthy, M. (2007). Bayesian Methods Ecology. Cambridge: Cambridge University Press.McCarthy, M. (2007). Bayesian Methods Ecology. Cambridge: Cambridge University Press.McElreath, R. (2020). Statistical Rethinking: Bayesian Course Examples R Stan (2nd ed.). CRC Press.McElreath, R. (2020). Statistical Rethinking: Bayesian Course Examples R Stan (2nd ed.). CRC Press."",""code"":""""},{""path"":""intronimble.html"",""id"":""intronimble"",""chapter"":""2 NIMBLE"",""heading"":""2 NIMBLE"",""text"":"""",""code"":""""},{""path"":""hmmcapturerecapture.html"",""id"":""hmmcapturerecapture"",""chapter"":""3 Hidden Markov models"",""heading"":""3 Hidden Markov models"",""text"":""‚Äì>\n ‚Äì>‚Äì>\n ‚Äì>\n ‚Äì>\n ‚Äì>\n ‚Äì>"",""code"":""""},{""path"":""introduction-2.html"",""id"":""introduction-2"",""chapter"":""Introduction"",""heading"":""Introduction"",""text"":"""",""code"":""""},{""path"":""survival.html"",""id"":""survival"",""chapter"":""4 Survival"",""heading"":""4 Survival"",""text"":""‚Äì>\n ‚Äì>‚Äì>‚Äì>‚Äì>‚Äì>\n ‚Äì>\n ‚Äì>‚Äì>‚Äì>\n ‚Äì>\n ‚Äì>\n ‚Äì>"",""code"":""""},{""path"":""covariates.html"",""id"":""covariates"",""chapter"":""5 Covariates"",""heading"":""5 Covariates"",""text"":"""",""code"":""""},{""path"":""dispersal.html"",""id"":""dispersal"",""chapter"":""6 Dispersal"",""heading"":""6 Dispersal"",""text"":"""",""code"":""""},{""path"":""model-selection.html"",""id"":""model-selection"",""chapter"":""7 Model selection and validation"",""heading"":""7 Model selection and validation"",""text"":"""",""code"":""""},{""path"":""introduction-3.html"",""id"":""introduction-3"",""chapter"":""Introduction"",""heading"":""Introduction"",""text"":"""",""code"":""""},{""path"":""uncertainty.html"",""id"":""uncertainty"",""chapter"":""8 State uncertainty"",""heading"":""8 State uncertainty"",""text"":"""",""code"":""""},{""path"":""hsmm.html"",""id"":""hsmm"",""chapter"":""9 Hidden semi-Markov models"",""heading"":""9 Hidden semi-Markov models"",""text"":"""",""code"":""""},{""path"":""introduction-4.html"",""id"":""introduction-4"",""chapter"":""Introduction"",""heading"":""Introduction"",""text"":"""",""code"":""""},{""path"":""tradeoffs.html"",""id"":""tradeoffs"",""chapter"":""10 Life history theory"",""heading"":""10 Life history theory"",""text"":"""",""code"":""""},{""path"":""tradeoffs.html"",""id"":""tradeoffs-1"",""chapter"":""10 Life history theory"",""heading"":""10.1 Tradeoffs"",""text"":""Morano et al. (2013), Shefferson et al. (2003), Cruz-Flores et al. (n.d.)"",""code"":""""},{""path"":""tradeoffs.html"",""id"":""breeding-dynamics"",""chapter"":""10 Life history theory"",""heading"":""10.2 Breeding dynamics"",""text"":""Pradel, Choquet, B√©chet (2012), Desprez et al. (2011), Desprez et al. (2013), Pacoureau et al. (2019)"",""code"":""""},{""path"":""tradeoffs.html"",""id"":""actuarial-senescence"",""chapter"":""10 Life history theory"",""heading"":""10.3 Actuarial senescence"",""text"":""Choquet et al. (2011), P√©ron et al. (2016)"",""code"":""""},{""path"":""tradeoffs.html"",""id"":""cause-specific-mortalities"",""chapter"":""10 Life history theory"",""heading"":""10.4 Cause-specific mortalities"",""text"":""Fern√°ndez-Chac√≥n et al. (2016) Ruette et al. (2015)"",""code"":""""},{""path"":""tradeoffs.html"",""id"":""disease-dynamics"",""chapter"":""10 Life history theory"",""heading"":""10.5 Disease dynamics"",""text"":""Marescot et al. (2018) Santoro et al. (2014)"",""code"":""""},{""path"":""tradeoffs.html"",""id"":""sex-uncertainty"",""chapter"":""10 Life history theory"",""heading"":""10.6 Sex uncertainty"",""text"":""Pradel et al. (2008) Genovart, Pradel, Oro (2012)"",""code"":""""},{""path"":""abundance.html"",""id"":""abundance"",""chapter"":""11 Abundance"",""heading"":""11 Abundance"",""text"":"""",""code"":""""},{""path"":""abundance.html"",""id"":""horvitz-thompson"",""chapter"":""11 Abundance"",""heading"":""11.1 Horvitz-Thompson"",""text"":""Santostasi et al. (2019)"",""code"":""""},{""path"":""abundance.html"",""id"":""jolly-seber"",""chapter"":""11 Abundance"",""heading"":""11.2 Jolly-Seber"",""text"":"""",""code"":""""},{""path"":""abundance.html"",""id"":""robust-design"",""chapter"":""11 Abundance"",""heading"":""11.3 Robust design"",""text"":""Karamanlidis et al. (2015), Santostasi et al. (2016), Gibson et al. (2018), Rankin et al. (2016)"",""code"":""""},{""path"":""stopover.html"",""id"":""stopover"",""chapter"":""12 Stopover duration"",""heading"":""12 Stopover duration"",""text"":""Gu√©rin et al. (2017)"",""code"":""""},{""path"":""individual-dependence.html"",""id"":""individual-dependence"",""chapter"":""13 Individual dependence"",""heading"":""13 Individual dependence"",""text"":"""",""code"":""""},{""path"":""individual-dependence.html"",""id"":""dependence-among-individuals"",""chapter"":""13 Individual dependence"",""heading"":""13.1 Dependence among individuals"",""text"":""Culina et al. (2013) Cubaynes et al. (2021)"",""code"":""""},{""path"":""individual-dependence.html"",""id"":""individual-heterogeneity"",""chapter"":""13 Individual dependence"",""heading"":""13.2 Individual heterogeneity"",""text"":""Cubaynes et al. (2010), Gimenez Choquet (2010), Turek, Wehrhahn, Gimenez (2021)"",""code"":""""},{""path"":""take-home-messages.html"",""id"":""take-home-messages"",""chapter"":""Take-home messages"",""heading"":""Take-home messages"",""text"":""‚Äì>\n ‚Äì>‚Äì>‚Äì>‚Äì>"",""code"":""""},{""path"":""faq.html"",""id"":""faq"",""chapter"":""FAQ"",""heading"":""FAQ"",""text"":"""",""code"":""""},{""path"":""references.html"",""id"":""references"",""chapter"":""References"",""heading"":""References"",""text"":"""",""code"":""""}]

---FILE: docs/stopover.html---
@@ -49,17 +49,17 @@ <h1>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
 <li><a class="""" href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></li>
 <li><a class="""" href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></li>
 <li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></li>
 <li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
 <li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></li>
 <li><a class="""" href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></li>
 <li><a class=""active"" href=""stopover.html""><span class=""header-section-number"">12</span> Stopover duration</a></li>
@@ -104,14 +104,42 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
 </body>
 </html>

---FILE: docs/survival.html---
@@ -49,17 +49,17 @@ <h1>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
 <li><a class=""active"" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
 <li><a class="""" href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></li>
 <li><a class="""" href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></li>
 <li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></li>
 <li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
 <li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></li>
 <li><a class="""" href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></li>
 <li><a class="""" href=""stopover.html""><span class=""header-section-number"">12</span> Stopover duration</a></li>
@@ -969,7 +969,7 @@ <h1>
 
 </div>
   <div class=""chapter-nav"">
-<div class=""prev""><a href=""introduction-1.html"">Introduction</a></div>
+<div class=""prev""><a href=""introduction-2.html"">Introduction</a></div>
 <div class=""next""><a href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
@@ -990,14 +990,42 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
 </body>
 </html>

---FILE: docs/take-home-messages.html---
@@ -49,17 +49,17 @@ <h1>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
 <li><a class="""" href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></li>
 <li><a class="""" href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></li>
 <li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></li>
 <li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
 <li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></li>
 <li><a class="""" href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></li>
 <li><a class="""" href=""stopover.html""><span class=""header-section-number"">12</span> Stopover duration</a></li>
@@ -175,14 +175,42 @@ <h1>Take-home messages<a class=""anchor"" aria-label=""anchor"" href=""#take-home-mes
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
 </body>
 </html>

---FILE: docs/tradeoffs.html---
@@ -49,17 +49,17 @@ <h1>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
 <li><a class="""" href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></li>
 <li><a class="""" href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></li>
 <li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></li>
 <li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
 <li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class=""active"" href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></li>
 <li><a class="""" href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></li>
 <li><a class="""" href=""stopover.html""><span class=""header-section-number"">12</span> Stopover duration</a></li>
@@ -118,7 +118,7 @@ <h2>
 </div>
 </div>
   <div class=""chapter-nav"">
-<div class=""prev""><a href=""introduction-3.html"">Introduction</a></div>
+<div class=""prev""><a href=""introduction-4.html"">Introduction</a></div>
 <div class=""next""><a href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
@@ -147,14 +147,42 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
 </body>
 </html>

---FILE: docs/uncertainty.html---
@@ -49,17 +49,17 @@ <h1>
 <li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> NIMBLE</a></li>
 <li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
 <li class=""book-part"">II. Transitions</li>
-<li><a class="""" href=""introduction-1.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
 <li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
 <li><a class="""" href=""covariates.html""><span class=""header-section-number"">5</span> Covariates</a></li>
 <li><a class="""" href=""dispersal.html""><span class=""header-section-number"">6</span> Dispersal</a></li>
 <li><a class="""" href=""model-selection.html""><span class=""header-section-number"">7</span> Model selection and validation</a></li>
 <li class=""book-part"">III. States</li>
-<li><a class="""" href=""introduction-2.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
 <li><a class=""active"" href=""uncertainty.html""><span class=""header-section-number"">8</span> State uncertainty</a></li>
 <li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
 <li class=""book-part"">IV. Case studies</li>
-<li><a class="""" href=""introduction-3.html"">Introduction</a></li>
+<li><a class="""" href=""introduction-4.html"">Introduction</a></li>
 <li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">10</span> Life history theory</a></li>
 <li><a class="""" href=""abundance.html""><span class=""header-section-number"">11</span> Abundance</a></li>
 <li><a class="""" href=""stopover.html""><span class=""header-section-number"">12</span> Stopover duration</a></li>
@@ -1108,7 +1108,7 @@ <h1>
 
 </div>
   <div class=""chapter-nav"">
-<div class=""prev""><a href=""introduction-2.html"">Introduction</a></div>
+<div class=""prev""><a href=""introduction-3.html"">Introduction</a></div>
 <div class=""next""><a href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
@@ -1129,14 +1129,42 @@ <h1>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-19.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-20.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+  (function () {
+    var script = document.createElement(""script"");
+    script.type = ""text/javascript"";
+    var src = ""true"";
+    if (src === """" || src === ""true"") src = ""https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"";
+    if (location.protocol !== ""file:"")
+      if (/^https?:/.test(src))
+        src = src.replace(/^https?:/, '');
+    script.src = src;
+    document.getElementsByTagName(""head"")[0].appendChild(script);
+  })();
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+for (let popover of popovers) {
+  const div = document.createElement('div');
+  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
+  div.innerHTML = popover.getAttribute('data-content');
+
+  var has_math = div.querySelector(""span.math"");
+  if (has_math) {
+    document.body.appendChild(div);
+    MathJax.Hub.Queue([""Typeset"", MathJax.Hub, div]);
+    MathJax.Hub.Queue(function() {
+      popover.setAttribute('data-content', div.innerHTML);
+      document.body.removeChild(div);
+    })
+  }
+}
+</script>
 </body>
 </html>",False,True,Documentation / Formatting,6
oliviergimenez,banana-book,6fec473e97f93a94ff85abeef8a879a3d0b61be1,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2021-09-15T09:40:14Z,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2021-09-15T09:40:14Z,Debug issue w/ plots.,.Rbuildignore;02-introNimble.Rmd;03-hmm.Rmd;04-survival.Rmd;05-transition.Rmd;06-covariates.Rmd;07-uncertainty.Rmd;08-abundance.Rmd;09-semiMarkov.Rmd;10-states.Rmd;11-speed.Rmd;11-xx-conclusions.Rmd;12-senescence.Rmd;13-heterogeneity.Rmd;14-tradeoffs.Rmd;15-breeding.Rmd;16-robustdesign.Rmd;17-stopover.Rmd;18-disease.Rmd;19-sex.Rmd;20-dependence.Rmd;21-selection.Rmd;22-mortalities.Rmd;23-prevalence.Rmd;24-faq.Rmd;25-references.Rmd;docs/404.html;docs/about-the-author.html;docs/crashcourse.html;docs/index.html;docs/preface.html;docs/reference-keys.txt;docs/search.json,True,False,True,False,88,6246,6334,"---FILE: .Rbuildignore---
@@ -0,0 +1,2 @@
+^.*\.Rproj$
+^\.Rproj\.user$

---FILE: 02-introNimble.Rmd---
@@ -1,273 +0,0 @@
-# Introduction to Nimble {#intronimble}
-
-## What is Nimble?
-
-```{r pressure, echo=FALSE, fig.cap=""(Meme created by Todd Arnold's wonderful students)"", out.width = c('24%', '60%')}
-knitr::include_graphics(c(""images/ToddStudents_Meme.jpg"",""images/RobRob_Comment_edited.png""))
-```
-
-+ **N**umerical **I**nference for statistical **M**odels using **B**ayesian and **L**ikelihood **E**stimation.
-
-+ A framework for hierarchical statistical models and algorithms. 
-
-+ Uses almost the same model code as WinBUGS, OpenBUGS, and JAGS. 
-
-+ An extension of the BUGS language: additional syntax, custom functions and distributions.
-
-+ A configurable system for MCMC.
-
-+ A library of other methods (SMC, MCEM).
-
-+ Sequential Monte Carlo (particle filtering)
-+ Monte Carlo Expectation Maximization (maximum likelihood)
-
-+ A model-generic programming system to write new analysis methods.
-
-+ because it extends the BUGS language for writing new functions and distributions, 
-
-+ and provides samplers that can deal with discrete latent states
-
-
-## Load `nimble` package
-
-```{r}
-library(nimble)
-```
-
-## Build model, made of likelihood and priors
-
-```{r}
-naive.survival.model <- nimbleCode({
-  # prior
-  phi ~ dunif(0, 1)
-  # likelihood
-  y ~ dbinom(phi, n)
-})
-```
-
-## Syntax: what's new/better/different?
-
-+ Vectorization
-```{r, eval = FALSE}
-# JAGS (& Nimble)
-for(t in 1:Tmax){
-  x[t] <- Mu.x + epsilon[t]
-}
-
-# Nimble
-x[1:Tmax] <- Mu.x + epsilon[1:Tmax]
-```
-
-+ More flexible specification of distributions
-```{r, eval = FALSE}
-# JAGS (& Nimble)
-for(t in 1:Tmax){
-  epsilon[t] ~ dnorm(0, tau)
-}
-tau <- pow(sigma, -2)
-sigma ~ dunif(0, 5)
-
-# Nimble
-for(t in 1:Tmax){
-  epsilon[t] ~ dnorm(0, sd = sigma)
-}
-sigma ~ dunif(0, 5)
-```
-
-+ Your own functions and distributions
-```{r, eval = FALSE}
-x[1:Tmax] <- myNimbleFunction(a = Mu.x, b = epsilon[1:Tmax])
-```
-
-```{r, eval = FALSE}
-sigma ~ dCustomDistr(c = 0.5, z = 10)
-```
-
-+ The end of empty indices
-```{r, eval = FALSE}
-# JAGS
-sum.x <- sum(x[])
-
-# Nimble
-sum.x <- sum(x[1:Tmax])
-```
-
-+ & more...
-
-
-## Read in data
-
-Back to our naive survival model:
-
-```{r}
-naive.survival.model <- nimbleCode({
-  # prior
-  phi ~ dunif(0, 1)
-  # likelihood
-  y ~ dbinom(phi, n)
-})
-```
-
-```{r}
-my.data <- list(n = 57, y = 19)
-```
-
-
-## Distinguish constants and data
-
-To Nimble, not all ""data"" is data...
-```{r}
-my.constants <- list(n = 57)
-my.data <- list(y = 19)
-```
-
-**Constants**:
-+ Can never be changed 
-+ Must be provided when a model is defined (part of the model structure)
-+ E.g. vector of known index values, variables used to define for-loops, etc. 
-
-
-To Nimble, not all ""data"" is data...
-```{r}
-my.constants <- list(n = 57)
-my.data <- list(y = 19)
-```
-
-**Data**:
-+ Can be changed without re-building the model 
-+ Can be (re-)simulated within a model
-+ E.g. stuff that *only* appears to the left of a ""~"" 
-
-For computational efficiency, better to specify as much as possible as constants.
-
-Nimble will help you with this!
-
-## Specify initial values
-
-```{r}
-initial.values <- function() list(phi = runif(1,0,1))
-```
-
-```{r}
-initial.values()
-```
-
-
-## Which parameters to save?
-
-```{r}
-parameters.to.save <- c(""phi"")
-```
-
-## MCMC details
-
-```{r}
-n.iter <- 5000
-n.burnin <- 1000
-n.chains <- 2
-n.thin <- 1
-```
-
-Number of posterior samples per chain: 
-
-$$n.posterior = \frac{n.iter - n.burnin}{n.thin}$$
-
-## Run model, tadaa!
-
-```{r, eval = FALSE}
-mcmc.output <- nimbleMCMC(code = naive.survival.model,     
-                          data = my.data,  
-                          constants = my.constants,
-                          inits = initial.values,
-                          monitors = parameters.to.save,
-                          thin = n.thin,
-                          niter = n.iter, 
-                          nburnin = n.burnin, 
-                          nchains = n.chains)
-```
-
-```{r, cache = TRUE, echo = FALSE}
-mcmc.output <- nimbleMCMC(code = naive.survival.model,     
-                          data = my.data,              
-                          constants = my.constants,
-                          inits = initial.values,
-                          monitors = parameters.to.save,
-                          niter = n.iter, 
-                          nburnin = n.burnin, 
-                          nchains = n.chains,
-                          progressBar = FALSE)
-```
-
-## Explore MCMC outputs
-
-```{r}
-str(mcmc.output)
-```
-
-```{r}
-head(mcmc.output$chain1)
-```
-
-
-```{r, echo = FALSE}
-mcmc.output %>%
-  as_tibble() %>%
-  janitor::clean_names() %>%
-  ggplot() + 
-  geom_histogram(aes(x = chain1[,""phi""]), color = ""white"") + 
-  labs(x = ""survival probability"")
-```
-
-## Numerical summaries
-
-```{r}
-library(MCMCvis)
-MCMCsummary(mcmc.output, round = 2)
-```
-
-## Trace and posterior density
-
-```{r eval = FALSE}
-MCMCtrace(mcmc.output,
-          pdf = FALSE) 
-```
-
-```{r eval = FALSE}
-MCMCtrace(mcmc.output,
-          pdf = FALSE,
-          ind = TRUE,
-          Rhat = TRUE,
-          n.eff = TRUE) 
-```
-
-## Our `nimble` workflow so far
-
-```{r}
-knitr::include_graphics(""images/nimble_workflow_sofar.png"")
-```
-
-
-## But `nimble` gives full access to the MCMC engine
-
-
-```{r}
-knitr::include_graphics(""images/nimble_workflow.png"")
-```
-
-```{r}
-knitr::include_graphics(""images/I1bIY06.gif"")
-```
-
-## Useful resources
-
-+ Official website [https://r-nimble.org](https://r-nimble.org)
-
-+ User Manual [https://r-nimble.org/html_manual/cha-welcome-nimble.html](https://r-nimble.org/html_manual/cha-welcome-nimble.html) and [cheatsheet](https://r-nimble.org/cheatsheets/NimbleCheatSheet.pdf).
-
-+ Users mailing list [https://groups.google.com/forum/#!forum/nimble-users](https://groups.google.com/forum/#!forum/nimble-users)
-
-+ Training material [https://github.com/nimble-training](https://github.com/nimble-training)
-
-+ Reference to cite when using nimble in a publication:
-
-> de Valpine, P., D. Turek, C. J. Paciorek, C. Anderson-Bergman, D. Temple Lang, and R. Bodik (2017). [Programming With Models: Writing Statistical Algorithms for General Model Structures With NIMBLE](https://arxiv.org/pdf/1505.05093.pdf). *Journal of Computational and Graphical Statistics* **26** (2): 403‚Äì13.

---FILE: 03-hmm.Rmd---
@@ -1,1211 +0,0 @@
-# Hidden Markov models {#hmmcapturerecapture}
-
-## Back to our survival example
-
-+ We have $z$ survivors out of $n$ released animals with winter survival probability $\phi$
-
-+ Let's get back to our survival example. 
-
-+ Our model so far:
-
-\begin{align*}
-   z &\sim \text{Binomial}(n, \phi) &\text{[likelihood]}
-   \\
-  \phi &\sim \text{Beta}(1, 1) &\text{[prior for }\phi \text{]} \\ 
-\end{align*}
-
-+ Our model so far has been a combination
-+ Of a binomial likelihood
-+ And a Beta prior with param 1 and 1, which is a uniform between 0 and 1. 
-
-+ This is also:
-
-\begin{align*}
-   z_i &\sim \text{Bernoulli}(\phi), \; i = 1, \ldots, N &\text{[likelihood]}
-   \\
-  \phi &\sim \text{Beta}(1, 1) &\text{[prior for }\phi \text{]} \\ 
-\end{align*}
-
-+ The binomial is just a sum of Bernoulli outcomes
-+ Like flipping a coin for each individual and get a survivor with prob phi. 
-
-+ What if we had several winters? Say $T = 5$ winters.
-
-+ In this design, we have a single winter. 
-But for many species, we'll need to collect data on the long term to get a representative estimate of survival. 
-+ Therefore what if we had say big T five winters? 
-
-## Longitudinal data
-
-+ $z_{i,t} = 1$ if individual $i$ alive at winter $t$, and $z_{i,t} = 2$ if dead.
-
-```{r echo = FALSE}
-library(tidyverse)
-nind <- 57
-nocc <- 5
-first <- rep(1, nind) # single cohort
-z <- matrix(NA, nrow = nind, ncol = nocc)
-phi <- 0.8
-for (i in 1:nind){
-  z[i,first[i]] <- 1
-  for (t in (first[i]+1):nocc){
-    z[i,t] <- rbinom(1, 1, phi * z[i,t-1]) # once you're dead z = 0, you remain dead
-  }
-}
-z[z==0] <- 2 # 2 = dead, 1 = alive
-colnames(z) <- paste0(""winter "", 1:nocc)
-z %>% 
-  as_tibble() %>% 
-  add_column(id = 1:nind, .before = ""winter 1"") %>%
-  kableExtra::kable() %>%
-  kableExtra::scroll_box(width = ""100%"", height = ""400px"")
-#  kableExtra::kable_styling(font_size = 8, 
-#                            latex_options = ""scale_down"")
-```
-
-+ This is what we call longitudinal data. 
-+ Each row is an individual i, and columns are for winters t, or sampling occasions. 
-+ z is indexed by both i and t, and takes value 1 if ind i is alive in winter t, and 2 otherwise. 
-
-## A model for longitudinal survival data
-
-+ A model relies on assumptions.
-
-+ Let's think of a model for these data. 
-+ The objective remains the same, estimating survival. 
-+ To build this model, we'll make assumptions. 
-
-+ The state of an animal at a given winter, alive or dead, is only dependent on its state the winter before. 
-
-+ First, we assume that the state of an animal in a given winter, alive or dead, is only dependent on its state the winter before. 
-
-+ The future depends only on the present, not the past: Markov process.
-
-+ In others words, he future depends only on the present, not the past
-+ This is a Markov process.
-
-+ If an animal is alive in a given winter, the probability it survives to the next winter is $\phi$. 
-
-+ If an animal is alive in a given winter, the probability it survives to the next winter is $\phi$. 
-
-+ The probability it dies is $1 - \phi$.
-
-+ The probability it dies is $1 - \phi$.
-
-+ If an animal is dead a winter, it remains dead, unless you believe in zombies. 
-
-+ If an animal is dead a winter, it remains dead, unless you believe in zombies. 
-
-## Markov process
-
-```{r, engine = 'tikz', echo = FALSE}
-\usetikzlibrary{arrows, fit, positioning, automata}
-\begin{tikzpicture}[node distance = 2cm]
-\tikzset{state/.style = {circle, draw, minimum size = 30pt, scale = 3, line width=1pt}}
-\node [state,fill=lightgray!75] (6) [] {$z_{t}$};
-\node [state,fill=lightgray!75] (5) [left = 20mm of 6] {$z_{t-1}$};
-\node [state,fill=lightgray!75] (4) [left = 20mm of 5] {$z_{t-2}$};
-\node [state,fill=lightgray!75] (3) [left = 20mm of 4] {$\cdots$};
-\node [state,fill=lightgray!75] (7) [right = 20mm of 6] {$z_{t+1}$};
-\node [state,fill=lightgray!75] (8) [right = 20mm of 7] {$z_{t+2}$};
-\node [state,fill=lightgray!75] (9) [right = 20mm of 8] {$\cdots$};
-\draw[->,black, line width=0.25mm,-latex] (3) to (4);
-\draw[->,black, line width=0.25mm,-latex] (4) to (5);
-\draw[->,black, line width=0.25mm,-latex] (5) to (6);
-\draw[->,black, line width=0.25mm,-latex] (6) to (7);
-\draw[->,black, line width=0.25mm,-latex] (7) to (8);
-\draw[->,black, line width=0.25mm,-latex] (8) to (9);
-\end{tikzpicture}
-```
-
-+ A markov process can be represented this way. 
-+ The state at t+1 only depends on the state at t. 
-
-```{r, engine = 'tikz', echo = FALSE}
-\usetikzlibrary{arrows, fit, positioning, automata}
-\begin{tikzpicture}[node distance = 2cm]
-\tikzset{state/.style = {circle, draw, minimum size = 30pt, scale = 3, line width=1pt}}
-\node [state,fill=lightgray!75] (6) [] {$1$};
-\node [state,fill=lightgray!75] (5) [left = 20mm of 6] {$1$};
-\node [state,fill=lightgray!75] (4) [left = 20mm of 5] {$1$};
-\node [state,fill=lightgray!75] (3) [left = 20mm of 4] {$1$};
-\node [state,fill=lightgray!75] (7) [right = 20mm of 6] {$2$};
-\node [state,fill=lightgray!75] (8) [right = 20mm of 7] {$2$};
-\node [state,fill=lightgray!75] (9) [right = 20mm of 8] {$\cdots$};
-\draw[->,black, line width=0.25mm,-latex] (3) -- node[above=3mm, align=center] {\huge $\varphi$} (4);
-\draw[->,black, line width=0.25mm,-latex] (4) -- node[above=3mm, align=center] {\huge $\varphi$} (5);
-\draw[->,black, line width=0.25mm,-latex] (5) -- node[above=3mm, align=center] {\huge $\varphi$} (6);
-\draw[->,black, line width=0.25mm,-latex] (6) -- node[above=3mm, align=center] {\huge $1 - \varphi$} (7);
-\draw[->,black, line width=0.25mm,-latex] (7) -- node[above=3mm, align=center] {\huge 1} (8);
-\draw[->,black, line width=0.25mm,-latex] (8) -- node[above=3mm, align=center] {\huge 1} (9);
-\end{tikzpicture}
-```
-
-+ In our model, going from a winter to the next is driven by survival and mortality processes. 
-+ The probability of going from alive or 1 to alive or 1 is phi. 
-+ Then from alive 1 to dead 2 is 1 - phi.
-+ And the probability to remain dead is 1, that is to go from state 2 dead to state 2 for dead. 
-
-## Transition matrix
-
-+ The core of the Markov process is made of the transition probabilities.
-
-+ The engine of a Markov model is the transition matrix. 
-+ This matrix or table gathers the probabilities of transition between states from one occasion to the next. 
-
-+ For example, the probability of transitioning from state alive at $t-1$ to state alive at $t$ is $\Pr(z_t = 1 | z_{t-1} = 1) = \gamma_{1,1}$. It is the survival probability $\phi$. 
-
-+ For example, the probability of transitioning from state alive at $t-1$ to state alive at $t$ is $\Pr(z_t = 1 | z_{t-1} = 1) = \gamma_{1,1}$. It is the survival probability $\phi$. 
-
-+ The probability of dying over the interval $(t-1, t)$ is $\Pr(z_t = 2 | z_{t-1} = 1) = \gamma_{1,2} = 1 - \phi$.
-
-+ The probability of dying over the interval $(t-1, t)$ is $\Pr(z_t = 2 | z_{t-1} = 1) = \gamma_{1,2} = 1 - \phi$.
-
-+ Now if an animal is dead at $t-1$, then $\Pr(z_t = 1 | z_{t-1} = 2) = 0$ and $\Pr(z_t = 2 | z_{t-1} = 2) = 1$.
-
-+ Now if an animal is dead at $t-1$, then $\Pr(z_t = 1 | z_{t-1} = 2) = 0$ and $\Pr(z_t = 2 | z_{t-1} = 2) = 1$.
-
-
-+ These probabilities can be packed in a transition matrix $\mathbf{\Gamma}$:
-
-\begin{align*}
-\mathbf{\Gamma} = 
-\left(\begin{array}{cc} 
-\gamma_{1,1} & \gamma_{1,2}\\ 
-\gamma_{2,1} & \gamma_{2,2}
-\end{array}\right) =
-\left(\begin{array}{cc} 
-\phi & 1 - \phi\\ 
-0 & 1
-\end{array}\right)
-\end{align*}
-
-+ These probabilities can be packed in a transition matrix $\mathbf{\Gamma}$:
-
-Transition matrix:
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Gamma} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    z_t=A & z_t=D \\ \hdashline
-\phi & 1-\phi \\
-0 & 1
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    z_{t-1}=A \\ z_{t-1}=D
-    \end{matrix}
-\end{matrix}
-$$
-+ Take some time to navigate through this matrix. 
-+ From in rows, the origin, to in columns, the destination. 
-+ For example...
-
-## Initial states
-
-+ A Markov process has to start somewhere. 
-
-+ We need the probabilities of initial states, i.e. states at $t = 1$. 
-
-+ In other words, we need the probabilities of initial states
-+ i.e. states at $t = 1$. 
-
-+ We will use $\mathbf{\delta} = \left(\Pr(z_1 = 1), \Pr(z_1 = 2)\right)$.
-
-+ We will denote delta this vector. 
-+ It gathers the probability of being in each initial states.
-+ Here alive 1 and dead 2.
-
-+ Here we assume that all animals are alive at first winter, i.e. $\Pr(z_1 = 1) = 1$ and $\Pr(z_1 = 2) = 0$. 
-
-+ All individuals are marked and release in first winter.
-+ Therefore alive when first captured.
-+ Which means that they are all in state 1 alive for sure. 
-
-## Likelihood 
-
-\begin{align*}
-\Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)} \\
-\end{align*}
-
-+ OK now that we've defined a Markov model, we need its likelihood to apply the Bayes theorem. 
-+ The likelihood is the probability of the data, given the model. Here the data are the z. 
-
-\begin{align*}
-\Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\
-                &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-\end{align*}
-
-+ We're gonna work backward, starting from the last sampling occasion. 
-+ Now the likelihood can be written as the product of the probability of zT ie you're alive or not on the last occasion given your past history, that is the states at previous occasions, times the prob of your past history, y definition of cond prob. 
-
-\begin{align*}
-\Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\
-                &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-\end{align*}
-
-+ Then because we have a Markov model, we're memory less, that is prob of next state, here zT, depends only on the current state, that is zT-1, and not the previous states. 
-
-\begin{align*}
-\Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\
-                &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}, \ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)\\
-\end{align*}
-
-+ You can apply the same reasoning to T-1. 
-+ First conditional prob.
-
-\begin{align*}
-\Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\
-                &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}, \ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)\\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \Pr(z_{T-2}, \ldots, z_1)\\
-\end{align*}
-
-+ Then markovian property.
-
-\begin{align*}
-\Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\
-                &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}, \ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)\\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \Pr(z_{T-2}, \ldots, z_1)\\
-                &= \ldots \\
-\end{align*}
-
-+ And so on.
-
-\begin{align*}
-\Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\
-                &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}, \ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)\\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \Pr(z_{T-2}, \ldots, z_1)\\
-                &= \ldots \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \ldots \Pr(z_{2} | z_{1}) \Pr(z_{1})\\
-\end{align*}
-
-+ You end up with this expression for the likelihood. 
-
-
-\begin{align*}
-\Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\
-                &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}, \ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)\\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \Pr(z_{T-2}, \ldots, z_1)\\
-                &= \ldots \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \ldots \Pr(z_{2} | z_{1}) \Pr(z_{1})\\
-                &= \Pr(z_{1}) \prod_{t=2}^T{\Pr(z_{t} | z_{t-1})}\\
-\end{align*}
-
-+ A product of cond probabilities. And the prob of initial states Pr(z1). 
-
-\begin{align*}
-\Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\
-                &= \Pr(z_T | z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1}, z_{T-2},\ldots, z_1) \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}, \ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)\\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \Pr(z_{T-2}, \ldots, z_1)\\
-                &= \ldots \\
-                &= \Pr(z_T | z_{T-1}) \Pr(z_{T-1} | z_{T-2}) \ldots \Pr(z_{2} | z_{1}) \Pr(z_{1})\\
-                &= \Pr(z_{1}) \prod_{t=2}^T{\Pr(z_{t} | z_{t-1})}\\
-                &= \Pr(z_{1}) \prod_{t=2}^T{\gamma_{z_{t-1},z_{t}}}\\
-\end{align*}
-
-+ We recognize the gammas we defined earlier. 
-+ The transition probabilities. 
-
-
-<!-- --- -->
-<!-- # Matrix formulation of the likelihood -->
-
-<!-- \begin{align*} -->
-<!-- \Pr(\mathbf{z}) &= \Pr(z_T, z_{T-1}, z_{T-2}, \ldots, z_1) \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1) \Pr(z_{T-2}, \ldots, z_1)}\\ -->
-<!--                 &= \Pr(z_{1}) \prod_{t=2}^T{\gamma_{z_{t-1},z_{t}}}\\ -->
-<!--                 &= \mathbf{\delta} \; \mathbf{\Gamma} \cdots \mathbf{\Gamma} -->
-<!-- \end{align*} -->
-
-
-## Example
-
-+ Let's assume an animal is alive, alive then dies. 
-
-+ I realise these calculations are a bit difficult to follow. 
-+ Let's take an example. 
-
-+ We have $\mathbf{z} = (1, 1, 2)$. What is the contribution of this animal to the likelihood?
-
-+ We have $\mathbf{z} = (1, 1, 2)$. What is the contribution of this animal to the likelihood?
-+ Let's apply the formula we have just derived. 
-
-\begin{align*}
-\Pr(\mathbf{z} = (1, 1, 2)) &= \Pr(z_1 = 1) \; \gamma_{z_{1} = 1, z_{2} = 1} \; \gamma_{z_{2} = 1, z_{3} = 2}\\
-                            &= 1 \; \phi \; (1 - \phi).
-\end{align*}
-
-+ The prob of having the sequence alive, alive and dead is
-+ The prob of being alive first, the to stay alive, then to die. 
-+ The prob of being alive at first occasion being 1, we have that the contribution of this individual to the likelihood is phi times 1 - phi. 
-
-+ Remember: 
-
-\begin{align*}
-\mathbf{\Gamma} = 
-\left(\begin{array}{cc} 
-\gamma_{1,1} & \gamma_{1,2}\\ 
-\gamma_{2,1} & \gamma_{2,2}
-\end{array}\right) =
-\left(\begin{array}{cc} 
-\phi & 1 - \phi\\ 
-0 & 1
-\end{array}\right)
-\end{align*}
-
-## Our model
-
-\begin{align*}
-   z_1 &\sim \text{Multinomial}(1, \delta) &\text{[likelihood, }t = 1 \text{]}\\
-   \color{white}{z_t | z_{t-1}} & \color{white}{\sim} \color{white}{\text{Multinomial}(1, \gamma_{z_{t-1},z_{t}})} & \color{white}{\text{[likelihood, }t > 1 \text{]}}\\
-  \color{white}{\phi} & \color{white}{\sim} \color{white}{\text{Beta}(1, 1)} & \color{white}{\text{[prior for }\phi \text{]}} \\ 
-\end{align*}
-
-+ OK let's wrap it up. 
-+ Our model so far is that one. 
-
-+ Initial state is multinomial with one trial, and probability delta. 
-+ That is you have a dice with two faces, a coin, and you have some prob to be alive, and 1 - that prob to be dead. + Of course, it you want your Markov chain to start, you'd better say it's alive so that delta is just (1,0). 
-
-## Our model
-
-\begin{align*}
-   z_1 &\sim \text{Multinomial}(1, \delta) &\text{[likelihood, }t = 1 \text{]}\\
-   \color{white}{z_t | z_{t-1}} & \color{white}{\sim} \color{white}{\text{Multinomial}(1, \gamma_{z_{t-1},z_{t}})} & \color{white}{\text{[likelihood, }t > 1 \text{]}}\\
-  \phi &\sim \text{Beta}(1, 1) &\text{[prior for }\phi \text{]} \\ 
-\end{align*}
-
-+ We also need a prior on survival.
-+ As usual we take a uniform distribution between 0 and 1, or a beta with parameters 1 and 1.
-
-\begin{align*}
-   z_1 &\sim \text{Multinomial}(1, \delta) &\text{[likelihood, }t = 1 \text{]}\\
-   z_t | z_{t-1} &\sim \text{Multinomial}(1, \gamma_{z_{t-1},z_{t}}) &\text{[likelihood, }t > 1 \text{]}\\
-  \phi &\sim \text{Beta}(1, 1) &\text{[prior for }\phi \text{]} \\ 
-\end{align*}
-
-
-+ Now the main part is the dynamic of the states.
-+ Our state at t depends only on your state at t-1, and it is a multinomial random variable, with one trial. 
-+ And the probabilities are given by the rows of the transition matrix.
-
-\begin{align*}
-   z_1 &\sim \text{Multinomial}(1, \delta) &\text{[likelihood, }t = 1 \text{]}\\
-   z_t | z_{t-1} &\sim \text{Multinomial}(1, \gamma_{z_{t-1},z_{t}}) &\text{[likelihood, }t > 1 \text{]}\\
-  \phi &\sim \text{Beta}(1, 1) &\text{[prior for }\phi \text{]} \\ 
-\end{align*}
-
-\begin{align*}
-\mathbf{\Gamma} = 
-\left(\begin{array}{cc} 
-\color{blue}{\phi} & \color{blue}{1 - \phi}\\ 
-0 & 1
-\end{array}\right)
-\end{align*}
-
-$$\color{blue}{\gamma_{z_{t-1} = 1,z_{t}} = (\phi, 1-\phi)}$$
-
-+ If z at t-1 is alive, it is the first row, that is phi and 1-phi. 
-
-\begin{align*}
-   z_1 &\sim \text{Multinomial}(1, \delta) &\text{[likelihood, }t = 1 \text{]}\\
-   z_t | z_{t-1} &\sim \text{Multinomial}(1, \gamma_{z_{t-1},z_{t}}) &\text{[likelihood, }t > 1 \text{]}\\
-  \phi &\sim \text{Beta}(1, 1) &\text{[prior for }\phi \text{]} \\ 
-\end{align*}
-
-\begin{align*}
-\mathbf{\Gamma} = 
-\left(\begin{array}{cc} 
-\phi & 1 - \phi\\ 
-\color{blue}{0} & \color{blue}{1}
-\end{array}\right)
-\end{align*}
-
-$$\color{blue}{\gamma_{z_{t-1} = 2,z_{t}} = (0, 1)}$$
-
-+ Otherwise, if z at t-1 is dead that is 2, then it is the second row of gamma, 0 and 1. 
-+ If dead you remain dead. 
-
-## Nimble implementation
-
-+ In Nimble, we will use the categorical distribution `dcat()`.
-
-+ The categorical distribution is a multinomial distribution with a single draw. 
-
-
-```{r}
-nimble::rcat(n = 20, prob = c(0.1, 0.3, 0.6))
-```
-
-```{r}
-nimble::rcat(n = 20, prob = c(0.1, 0.1, 0.4, 0.2, 0.2))
-```
-
-https://en.wikipedia.org/wiki/Categorical_distribution
-
-The categorical distribution is the generalization of the Bernoulli distribution for a categorical random variable, i.e. for a discrete variable with more than two possible outcomes, such as the roll of a dice. On the other hand, the categorical distribution is a special case of the multinomial distribution, in that it gives the probabilities of potential outcomes of a single drawing rather than multiple drawings. 
-
-## Nimble code
-
-```{r}
-markov.survival <- nimbleCode({
-  phi ~ dunif(0, 1) # prior
-  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)
-  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)
-  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)
-  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  # likelihood
-  for (i in 1:N){
-    z[i,1] ~ dcat(delta[1:2])
-    for (j in 2:T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])
-    }
-  }})
-```
-
-```{r}
-markov.survival <- nimbleCode({
-  phi ~ dunif(0, 1) # prior #<<
-  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)
-  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)
-  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)
-  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  # likelihood
-  for (i in 1:N){
-    z[i,1] ~ dcat(delta[1:2])
-    for (j in 2:T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])
-    }
-  }})
-```
-
-```{r}
-markov.survival <- nimbleCode({
-  phi ~ dunif(0, 1) # prior
-  gamma[1,1] <- phi      # Pr(alive t -> alive t+1) #<<
-  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1) #<<
-  gamma[2,1] <- 0        # Pr(dead t -> alive t+1) #<<
-  gamma[2,2] <- 1        # Pr(dead t -> dead t+1) #<<
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  # likelihood
-  for (i in 1:N){
-    z[i,1] ~ dcat(delta[1:2])
-    for (j in 2:T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])
-    }
-  }})
-```
-]
-
-
-```{r}
-markov.survival <- nimbleCode({
-  phi ~ dunif(0, 1) # prior
-  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)
-  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)
-  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)
-  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)
-  delta[1] <- 1          # Pr(alive t = 1) = 1 #<<
-  delta[2] <- 0          # Pr(dead t = 1) = 0 #<<
-  # likelihood
-  for (i in 1:N){
-    z[i,1] ~ dcat(delta[1:2])
-    for (j in 2:T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])
-    }
-  }})
-```
-
-
-```{r}
-markov.survival <- nimbleCode({
-  phi ~ dunif(0, 1) # prior
-  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)
-  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)
-  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)
-  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  # likelihood
-  for (i in 1:N){ #<<
-    z[i,1] ~ dcat(delta[1:2]) 
-    for (j in 2:T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])
-    } 
-  } #<<
-  })
-```
-
-
-```{r}
-markov.survival <- nimbleCode({
-  phi ~ dunif(0, 1) # prior
-  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)
-  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)
-  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)
-  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  # likelihood
-  for (i in 1:N){
-    z[i,1] ~ dcat(delta[1:2]) #<<
-    for (j in 2:T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])
-    }
-  }})
-```
-
-```{r}
-markov.survival <- nimbleCode({
-  phi ~ dunif(0, 1) # prior
-  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)
-  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)
-  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)
-  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  # likelihood
-  for (i in 1:N){
-    z[i,1] ~ dcat(delta[1:2])
-    for (j in 2:T){ #<<
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])
-    } #<<
-  }})
-```
-
-```{r}
-markov.survival <- nimbleCode({
-  phi ~ dunif(0, 1) # prior
-  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)
-  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)
-  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)
-  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  # likelihood
-  for (i in 1:N){
-    z[i,1] ~ dcat(delta[1:2])
-    for (j in 2:T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2]) #<<
-    }
-  }})
-```
-
-## Note
-
-+ Vector $\delta$ is used as a placeholder for more complex models to come in Class 7.
-
-+ Here, you could write `z[i,1] <- 1`. 
-
-## Nimble awesomness
-
-You should be able to define vectors and matrices like you do in `R`.  
-
-```{r, eval = FALSE}
-markov.survival <- nimbleCode({
-  phi ~ dunif(0, 1) # prior
-  gamma[1:2,1:2] <- matrix( c(phi, 0, 1 - phi, 1), nrow = 2) #<<
-  delta[1:2] <- c(1, 0) #<<
-  # likelihood
-  for (i in 1:N){
-    z[i,1] ~ dcat(delta[1:2])
-    for (j in 2:T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])
-    }
-  }})
-```
-
-## Converting to Nimble from Jags, OpenBUGS or WinBUGS
-
-+ Main difference is that Nimble does not guess. 
-
-+ We need to specify dimensions of vectors and matrices. 
-
-+ You cannot write `x[]` or `x[i,]`. Just provide index ranges `x[1:n]` or `x[i,1:m]`.
-
-+ More tips [here](https://r-nimble.org/quick-guide-for-converting-from-jags-or-bugs-to-nimble).
-
-## Constants and data
-
-```{r}
-my.constants <- list(N = 57, T = 5)
-my.constants
-
-my.data <- list(z = z)
-```
-
-## Initial values
-
-```{r}
-initial.values <- function() list(phi = runif(1,0,1))
-initial.values()
-```
-
-## Parameters to monitor
-
-```{r}
-parameters.to.save <- c(""phi"")
-parameters.to.save
-```
-
-## MCMC details
-
-```{r}
-n.iter <- 5000
-n.burnin <- 1000
-n.chains <- 2
-```
-
-## Run Nimble
-```{r, message=FALSE, cache = TRUE}
-mcmc.output <- nimbleMCMC(code = markov.survival, 
-                          constants = my.constants,
-                          data = my.data,              
-                          inits = initial.values,
-                          monitors = parameters.to.save,
-                          niter = n.iter, 
-                          nburnin = n.burnin, 
-                          nchains = n.chains)
-```
-
-```{r, message=FALSE, echo = FALSE, cache = TRUE}
-mcmc.output <- nimbleMCMC(code = markov.survival, 
-                          constants = my.constants,
-                          data = my.data,              
-                          inits = initial.values,
-                          monitors = parameters.to.save,
-                          niter = n.iter, 
-                          nburnin = n.burnin, 
-                          nchains = n.chains,
-                          progressBar = FALSE)
-```
-
-## Posterior distribution of survival
-
-```{r}
-library(MCMCvis)
-MCMCsummary(mcmc.output, round = 2)
-```
-
-+ Posterior mean and median are close to $0.8$. 
-
-+ Cool! The data was simulated, with (true) survival $\phi = 0.8$. 
-
-## Unfortunately, this is the data we wish we had. 
-
-## In real life
-
-+ Animals cannot be monitored exhaustively, like humans in a medical trial.
-
-+ Animals are captured, marked or identified then released alive. 
-
-+ Then, these animals may be detected again, or go undetected <span>&#8212;</span> **capture-recapture** 
-
-+ Whenever animals go undetected, it might be that they were alive but missed, or because they were dead and therefore could not be detected <span>&#8212;</span> **imperfect detection**. 
-
-<https://www.youtube.com/embed/tyX79mPm2xY>
-
-+ Whenever animals go undetected, it might be that they were alive but missed, or because they were dead and therefore could not be detected <span>&#8212;</span> **imperfect detection**. 
-
-+ The Markov process for survival is only partially observed <span>&#8212;</span> **hidden Markov models**.  
-
-## The truth is in $z$
-
-```{r echo = FALSE}
-z %>% 
-  as_tibble() %>% 
-  add_column(id = 1:nind, .before = ""winter 1"") %>%
-  kableExtra::kable() %>%
-  kableExtra::scroll_box(width = ""100%"", height = ""300px"")
-```
-
-+ Unfortunately, we have only partial access to $z$. 
-
-+ We do observe $y$ the detections and non-detections.
-
-+ How are $z$ and $y$ connected?  
-
-## Dead animals go undetected
-
-+ When an animal is dead i.e. $z = 2$, it cannot be detected, therefore $y = 0$. 
-
-```{r echo = FALSE}
-z %>% 
-  as_tibble() %>% 
-  replace(. == 2, 0) %>%
-  add_column(id = 1:nind, .before = ""winter 1"") %>%
-  kableExtra::kable() %>%
-  kableExtra::scroll_box(width = ""100%"", height = ""300px"")
-```
-
-## Alive animals may be detected or not
-
-+ If animal is alive $z = 1$, it is detected $y = 1$ w/ prob $p$ or not $y = 0$ w/ prob $1-p$. 
-
-+ Before **first** detection, we know nothing, and we proceed conditional on it.
-
-```{r echo = FALSE}
-p <- 0.6
-y <- z
-y[z==2] <- 0
-y[y==1] <- rbinom(n = sum(y==1), 1, p)
-nobs <- sum(apply(y,1,sum) != 0)
-y <- y[apply(y,1,sum) !=0, ]
-first <- apply(y, 1, function(x) min(which(x !=0)))
-for (i in 1:nobs){
-  if(first[i] > 1) y[i, 1:(first[i]-1)] <- NA
-}
-y %>%
-  as_tibble() %>%
-  add_column(id = 1:nobs, .before = ""winter 1"") %>%
-  kableExtra::kable() %>%
-  kableExtra::scroll_box(width = ""100%"", height = ""300px"")
-```
-
-+ Compare with previous table
-+ Some 1s have become 0s. 
-
-+ This table $y$ is what we observe in real life.
-
-+ To make the connection between the observations, the y, and the true states, the z
-+ We need to describe how observations are made from the states
-
-## Observation matrix
-
-+ The observation probabilities can be packed in an observation matrix $\mathbf{\Omega}$.
-
-+ In rows: the states alive $z = 1$ and dead $z = 2$. 
-
-+ In columns: the observations non-detected $y = 1$ and detected $y = 2$ (previously coded 0 and 1 respectively). 
-
-\begin{align*}
-\mathbf{\Omega} = 
-\left(\begin{array}{cc} 
-\omega_{1,1} & \omega_{1,2}\\ 
-\omega_{2,1} & \omega_{2,2}
-\end{array}\right) =
-\left(\begin{array}{cc} 
-1 - p & p\\ 
-1 & 0
-\end{array}\right)
-\end{align*}
-
-Observation matrix:
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Omega} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    y_t=1 & y_t=2 \\ \hdashline
-1 - p & p\\ 
-1 & 0\\
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    z_{t}=A \\ z_{t}=D
-    \end{matrix}
-\end{matrix}
-$$
-
-## Markov model
-
-```{r, engine = 'tikz', echo = FALSE}
-\usetikzlibrary{arrows, fit, positioning, automata}
-\begin{tikzpicture}[node distance = 2cm]
-\tikzset{state/.style = {circle, draw, minimum size = 30pt, scale = 3, line width=1pt}}
-\node [state,fill=lightgray!75] (6) [] {$z_{t}$};
-\node [state,fill=lightgray!75] (5) [left = 20mm of 6] {$z_{t-1}$};
-\node [state,fill=lightgray!75] (4) [left = 20mm of 5] {$z_{t-2}$};
-\node [state,fill=lightgray!75] (3) [left = 20mm of 4] {$\cdots$};
-\node [state,fill=lightgray!75] (7) [right = 20mm of 6] {$z_{t+1}$};
-\node [state,fill=lightgray!75] (8) [right = 20mm of 7] {$z_{t+2}$};
-\node [state,fill=lightgray!75] (9) [right = 20mm of 8] {$\cdots$};
-\draw[->,black, line width=0.25mm,-latex] (3) to (4);
-\draw[->,black, line width=0.25mm,-latex] (4) to (5);
-\draw[->,black, line width=0.25mm,-latex] (5) to (6);
-\draw[->,black, line width=0.25mm,-latex] (6) to (7);
-\draw[->,black, line width=0.25mm,-latex] (7) to (8);
-\draw[->,black, line width=0.25mm,-latex] (8) to (9);
-\end{tikzpicture}
-```
-
-+ States $z$ are in gray.
-
-+ Remember the graphical repres of a Markov model.
-
-## Hidden Markov model
-
-```{r, engine = 'tikz', echo = FALSE}
-\usetikzlibrary{arrows, fit, positioning, automata}
-\begin{tikzpicture}[node distance = 2cm]
-\tikzset{state/.style = {circle, draw, minimum size = 30pt, scale = 3, line width=1pt}}
-\node [state,fill=lightgray!75] (6) [] {$z_{t}$};
-\node [state,fill=lightgray!75] (5) [left = 20mm of 6] {$z_{t-1}$};
-\node [state,fill=lightgray!75] (4) [left = 20mm of 5] {$z_{t-2}$};
-\node [state,fill=lightgray!75] (3) [left = 20mm of 4] {$\cdots$};
-\node [state,fill=lightgray!75] (7) [right = 20mm of 6] {$z_{t+1}$};
-\node [state,fill=lightgray!75] (8) [right = 20mm of 7] {$z_{t+2}$};
-\node [state,fill=lightgray!75] (9) [right = 20mm of 8] {$\cdots$};
-\node [state,fill=white] (16) [above = 20mm of 6] {$y_{t}$};
-\node [state,fill=white] (15) [above = 20mm of 5] {$y_{t-1}$};
-\node [state,fill=white] (14) [above = 20mm of 4] {$y_{t-2}$};
-\node [state,fill=white] (17) [above = 20mm of 7] {$y_{t+1}$};
-\node [state,fill=white] (18) [above = 20mm of 8] {$y_{t+2}$};
-\draw[->,black, line width=0.25mm,-latex] (3) to (4);
-\draw[->,black, line width=0.25mm,-latex] (4) to (5);
-\draw[->,black, line width=0.25mm,-latex] (5) to (6);
-\draw[->,black, line width=0.25mm,-latex] (6) to (7);
-\draw[->,black, line width=0.25mm,-latex] (7) to (8);
-\draw[->,black, line width=0.25mm,-latex] (8) to (9);
-\draw[->,black, line width=0.25mm,-latex] (4) to (14);
-\draw[->,black, line width=0.25mm,-latex] (5) to (15);
-\draw[->,black, line width=0.25mm,-latex] (6) to (16);
-\draw[->,black, line width=0.25mm,-latex] (7) to (17);
-\draw[->,black, line width=0.25mm,-latex] (8) to (18);
-\end{tikzpicture}
-```
-
-+ States $z$ are in gray.
-
-+ Observations $y$ are in white.
-
-+ A hidden Markov model is just two time series. 
-+ One for the states with a Markovian property.
-+ The other of observations generated from the states. 
-+ Run in parallel. 
-
-## Hidden Markov model for survival
-
-```{r, engine = 'tikz', echo = FALSE}
-\usetikzlibrary{arrows, fit, positioning, automata}
-\begin{tikzpicture}[node distance = 2cm]
-\tikzset{state/.style = {circle, draw, minimum size = 30pt, scale = 3, line width=1pt}}
-\node [state,fill=lightgray!75] (6) [] {$1$};
-\node [state,fill=lightgray!75] (5) [left = 20mm of 6] {$1$};
-\node [state,fill=lightgray!75] (4) [left = 20mm of 5] {$1$};
-\node [state,fill=lightgray!75] (3) [left = 20mm of 4] {$1$};
-\node [state,fill=lightgray!75] (7) [right = 20mm of 6] {$2$};
-\node [state,fill=lightgray!75] (8) [right = 20mm of 7] {$2$};
-\node [state,fill=lightgray!75] (9) [right = 20mm of 8] {$\cdots$};
-\node [state,fill=white] (16) [above = 20mm of 6] {$1$};
-\node [state,fill=white] (15) [above = 20mm of 5] {$2$};
-\node [state,fill=white] (14) [above = 20mm of 4] {$1$};
-\node [state,fill=white] (17) [above = 20mm of 7] {$1$};
-\node [state,fill=white] (18) [above = 20mm of 8] {$1$};
-\draw[->,black, line width=0.25mm,-latex] (3) -- node[above=3mm, align=center] {\huge $\varphi$} (4);
-\draw[->,black, line width=0.25mm,-latex] (4) -- node[above=3mm, align=center] {\huge $\varphi$} (5);
-\draw[->,black, line width=0.25mm,-latex] (5) -- node[above=3mm, align=center] {\huge $\varphi$} (6);
-\draw[->,black, line width=0.25mm,-latex] (6) -- node[above=3mm, align=center] {\huge $1 - \varphi$} (7);
-\draw[->,black, line width=0.25mm,-latex] (7) -- node[above=3mm, align=center] {\huge $1$} (8);
-\draw[->,black, line width=0.25mm,-latex] (8) -- node[above=3mm, align=center] {\huge $1$} (9);
-\draw[->,black, line width=0.25mm,-latex] (4) -- node[left=3mm, align=center] {\huge $1 - p$} (14);
-\draw[->,black, line width=0.25mm,-latex] (5) -- node[left=3mm, align=center] {\huge $p$} (15);
-\draw[->,black, line width=0.25mm,-latex] (6) -- node[left=3mm, align=center] {\huge $1 - p$} (16);
-\draw[->,black, line width=0.25mm,-latex] (7) -- node[left=3mm, align=center] {\huge $1$} (17);
-\draw[->,black, line width=0.25mm,-latex] (8) -- node[left=3mm, align=center] {\huge $1$} (18);
-\end{tikzpicture}
-```
-
-+ For states (in gray), $z = 1$ is alive, $z = 2$ is dead.
-
-+ For observations (in white), $y = 1$ is non-detected, $y = 2$ is detected
-
-+ Now add the states alive and dead, 1 and 2s. 
-+ The observations, non-detected and detected, 1 and 2s. 
-+ And the parameters, phi for transition from 1 to 1.
-+ And p for prob of y being 2 detected given z is 1 alive. 
-
-## HMM likelihood 
-
-+ Using the formula of total probability, then the likelihood of a Markov chain: 
-
-\begin{align*}
-\Pr(\mathbf{y}) &= \Pr(y_1, y_{2}, \ldots, y_T)\\
-                &= \sum_{z_1} \cdots \sum_{z_T} \Pr(y_1, y_{2}, \ldots, y_T | z_1, z_{2}, \ldots, z_T) \Pr(z_1, z_{2}, \ldots, z_T)\\
-                &= \sum_{z_1} \cdots \sum_{z_T} \left(\prod_{t=1}^T{\omega_{z_{t}, y_t}}\right) \left(\Pr(z_{1}) \prod_{t=2}^T{\gamma_{z_{t-1},z_{t}}}\right)\\
-\end{align*}
-
-+ What is the likelihood of a HMM.
-+ The thing here is that we don't know the states. 
-+ So we have to go through all possibilities, and sum over the possible states. 
-+ Hence these sums here. 
-+ Then this term is the likelihood of a Markov chain, we saw that before. 
-+ And this component are the elements of the observation matrix.
-+ The likelihood has a matrix formulation that can be useful. 
-+ It is delta, initial states, then observation, then transitions, and so on. There is a vector of ones at the end to get the sum all the terms.  
-
-+ It has a matrix formulation:
-\begin{align*}
-\Pr(\mathbf{y}) &= \mathbf{\delta} \; \mathbf{\Omega} \; \mathbf{\Gamma} \cdots \mathbf{\Omega} \; \mathbf{\Gamma} \; \mathbf{\Omega} \; \mathbb{1}
-\end{align*}
-
-## Example 
-
-+ Let assume an animal is detected, then missed. 
-
-+ We have $\mathbf{y} = (2, 1)$. What is the contribution of this animal to the likelihood?
-
-\begin{align*}
-\Pr(\mathbf{y} = (2, 1)) &= \sum_{z_1 = 1}^2 \; \sum_{z_2 = 1}^2 w_{z_1, y_1 = 2} w_{z_2, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2} \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1, z_1, z_1, z_1)}\\
-\end{align*}
-
-## Example 
-
-+ Let assume an animal is detected, then missed. 
-
-+ We have $\mathbf{y} = (2, 1)$. What is the contribution of this animal to the likelihood?
-
-\begin{align*}
-\Pr(\mathbf{y} = (2, 1)) &= \sum_{z_1 = 1}^2 \; \sum_{z_2 = 1}^2 w_{z_1, y_1 = 2} w_{z_2, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2} \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1, z_1, z_1, z_1)}\\
-&= \sum_{z_1 = 1}^2 \left( w_{z_1, y_1 = 2} w_{z_2 = 1, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2 = 1} + w_{z_1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2 = 2} \right) \\
-\end{align*}
-
-+ Let assume an animal is detected, then missed. 
-
-+ We have $\mathbf{y} = (2, 1)$. What is the contribution of this animal to the likelihood?
-
-\begin{align*}
-\Pr(\mathbf{y} = (2, 1)) &= \sum_{z_1 = 1}^2 \; \sum_{z_2 = 1}^2 w_{z_1, y_1 = 2} w_{z_2, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2} \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1, z_1, z_1, z_1)}\\
-&= \sum_{z_1 = 1}^2 \left( w_{z_1, y_1 = 2} w_{z_2 = 1, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2 = 1} + w_{z_1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2 = 2} \right) \\
-&= w_{z_1 = 1, y_1 = 2} w_{z_2 = 1, y_2 = 1}\delta_1 \gamma_{z_1 = 1, z_2 = 1} + w_{z_1 = 1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \delta_1 \gamma_{z_1 = 1, z_2 = 2}
-\end{align*}
-
-Note: $\Pr(z_1 = 1) = \delta_1 = 1$ and $\Pr(z_1 = 2) = 0$. 
-
-+ Let assume an animal is detected, then missed. 
-
-+ We have $\mathbf{y} = (2, 1)$. What is the contribution of this animal to the likelihood?
-
-\begin{align*}
-\Pr(\mathbf{y} = (2, 1)) &= \sum_{z_1 = 1}^2 \; \sum_{z_2 = 1}^2 w_{z_1, y_1 = 2} w_{z_2, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2} \color{white}{\Pr(z_{T-1}, z_{T-2},\ldots, z_1, z_1, z_1, z_1)}\\
-&= \sum_{z_1 = 1}^2 \left( w_{z_1, y_1 = 2} w_{z_2 = 1, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2 = 1} + w_{z_1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \Pr(z_1) \gamma_{z_1, z_2 = 2} \right) \\
-&= w_{z_1 = 1, y_1 = 2} w_{z_2 = 1, y_2 = 1} \delta_1 \gamma_{z_1 = 1, z_2 = 1} + w_{z_1 = 1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \delta_1 \gamma_{z_1 = 1, z_2 = 2}\\
-&= (1 - p) \phi + (1-\phi)
-\end{align*}
-
-Note: $w_{z_1 = 1, y_1 = 2} = \Pr(y_1 = 2 | z_1 = 1) = 1$ because we condition on first capture. 
-
-## Estimating the latent states $z$ or not?
-
-+ Next question is, shall we estimate the latent states or not? 
-
-+ In previous example, we got rid of the states, so that likelihood was a function of $\phi$ and $p$ only. This is the function we would maximize in a Frequentist approach. 
-
-+ The Bayesian approach with MCMC methods allows treating the latent states as if they were parameters, and to be estimated as such. 
-
-+ Infering the latent states $z$ can be useful to estimate prevalence, e.g. in animal epidemiology with [prevalence of a disease](https://veterinaryresearch.biomedcentral.com/articles/10.1186/1297-9716-45-39), in evolutionary ecology with [sex ratio](https://onlinelibrary.wiley.com/doi/abs/10.1002/cjs.5550360105) or in conservation biology with [prevalence of hybrids](https://onlinelibrary.wiley.com/doi/full/10.1002/ece3.4819?af=R).  
-
-+ Estimating the latent states is costly though, and if not required, marginalisation may speed up computations. Actually, you can estimate the states afterwards (Viterbi). 
-
-+ More about so-called marginalisation in [Yackulic et al. (2020)](https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1002/eap.2112). 
-
-+ The neat thing with Nimble is that it provides marginalised models through nimbleEcology, we'll get back to it in Class 8.
-
-## Our model
-
-\begin{align*}
-   z_{\text{first}} &\sim \text{Multinomial}(1, \delta) &\text{[likelihood]}\\
-   z_t | z_{t-1} &\sim \text{Multinomial}(1, \gamma_{z_{t-1},z_{t}}) &\text{[likelihood]}\\
-   y_t | z_{t} &\sim \text{Multinomial}(1, \omega_{z_{t}}) &\text{[likelihood]}\\
-  \phi &\sim \text{Beta}(1, 1) &\text{[prior for }\phi \text{]} \\ 
-  p &\sim \text{Beta}(1, 1) &\text{[prior for }p \text{]} \\ 
-\end{align*}
-
-+ Now our model has an observation layer for the ys, conditional on the z. 
-+ And we need a prior for the detection probability. 
-
-## Nimble implementation
-
-+ How to implement this model in Nimble? 
-
-## Priors
-
-```{r, echo=FALSE}
-hmm.survival <- nimbleCode({
-  phi ~ dunif(0, 1) # prior survival
-  p ~ dunif(0, 1) # prior detection
-  # likelihood
-  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)
-  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)
-  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)
-  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)
-  omega[1,2] <- p        # Pr(alive t -> detected t)
-  omega[2,1] <- 1        # Pr(dead t -> non-detected t)
-  omega[2,2] <- 0        # Pr(dead t -> detected t)
-  for (i in 1:N){
-    z[i,first[i]] ~ dcat(delta[1:2])
-    for (j in (first[i]+1):T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])
-      y[i,j] ~ dcat(omega[z[i,j], 1:2])
-    }
-  }
-})
-```
-
-```{r eval=FALSE}
-hmm.survival <- nimbleCode({
-  phi ~ dunif(0, 1) # prior survival
-  p ~ dunif(0, 1) # prior detection
-...
-```
-
-## HMM ingredients
-
-```{r eval=FALSE}
-...
-  # parameters
-  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)
-  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)
-  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)
-  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)
-  omega[1,2] <- p        # Pr(alive t -> detected t)
-  omega[2,1] <- 1        # Pr(dead t -> non-detected t)
-  omega[2,2] <- 0        # Pr(dead t -> detected t)
-...
-```
-
-## Likelihood
-
-```{r eval=FALSE}
-...
-    # likelihood
-    for (i in 1:N){
-    z[i,first[i]] ~ dcat(delta[1:2])
-    for (j in (first[i]+1):T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])
-      y[i,j] ~ dcat(omega[z[i,j], 1:2])
-    }
-  }
-})
-```
-
-## Constants
-
-```{r}
-first <- apply(y, 1, function(x) min(which(x !=0)))
-my.constants <- list(N = nrow(y), T = 5, first = first)
-my.constants
-```
-
-## Data
-
-+ The data are made of 0s for non-detections and 1s for detections.
-
-+ To use the categorical distribution, we need to code 1, 2, etc. Value 0 is not accepted. 
-
-+ Add 1 to get the correct format $y=1$ for non-detection and $y = 2$ for detection.
-
-```{r}
-my.data <- list(y = y + 1)
-```
-
-## Initial values
-
-```{r}
-zinits <- y + 1 # non-detection -> alive
-zinits[zinits == 2] <- 1 # dead -> alive
-initial.values <- function() list(phi = runif(1,0,1),
-                                  p = runif(1,0,1),
-                                  z = zinits)
-```
-
-## Parameters to monitor
-
-```{r}
-parameters.to.save <- c(""phi"", ""p"")
-parameters.to.save
-```
-
-## MCMC details
-
-```{r}
-n.iter <- 5000
-n.burnin <- 1000
-n.chains <- 2
-```
-
-## Run Nimble
-```{r, message=FALSE}
-mcmc.output <- nimbleMCMC(code = hmm.survival, 
-                          constants = my.constants,
-                          data = my.data,              
-                          inits = initial.values,
-                          monitors = parameters.to.save,
-                          niter = n.iter, 
-                          nburnin = n.burnin, 
-                          nchains = n.chains)
-```
-
-```{r, message=FALSE, cache = TRUE}
-mcmc.output <- nimbleMCMC(code = hmm.survival, 
-                          constants = my.constants,
-                          data = my.data,              
-                          inits = initial.values,
-                          monitors = parameters.to.save,
-                          niter = n.iter, 
-                          nburnin = n.burnin, 
-                          nchains = n.chains,
-                          progressBar = FALSE)
-```
-
-## Posterior distribution of survival
-
-```{r}
-library(MCMCvis)
-MCMCsummary(mcmc.output, round = 2)
-```
-
-The data is simulated, with true survival $\phi = 0.8$ and detection $p = 0.6$.
-
-
-## Further reading
-
-+ Zucchini, MacDonald and Langrock (2016) [Hidden Markov Models for Time Series: An Introduction Using R (2nd ed)](https://www.routledge.com/Hidden-Markov-Models-for-Time-Series-An-Introduction-Using-R-Second-Edition/Zucchini-MacDonald-Langrock/p/book/9781482253832). Chapman and Hall/CRC. 
-
-+ McClintock, B.T., Langrock, R., Gimenez, O., Cam, E., Borchers, D.L., Glennie, R. and Patterson, T.A. (2020), [Uncovering ecological state dynamics with hidden Markov models](https://onlinelibrary.wiley.com/doi/full/10.1111/ele.13610). Ecology Letters, 23: 1878-1903. 
-
-+  Yackulic, C. B. Dodrill, M., Dzul, M., Sanderlin, J. S., and Reid, J. A.. (2020). [A need for speed in Bayesian population models: a practical guide to marginalizing and recovering discrete latent states](https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1002/eap.2112). Ecological Applications 30:e02112.
-
-+ L. R. Rabiner (1989). [A tutorial on hidden Markov models and selected applications in speech recognition](https://web.ece.ucsb.edu/Faculty/Rabiner/ece259/Reprints/tutorial%20on%20hmm%20and%20applications.pdf). Proceedings of the IEEE, 77:257-286.
-
-
-@heller_novel_2021
-

---FILE: 04-survival.Rmd---
@@ -1,1102 +0,0 @@
-# Survival {#survival}
-
-```{r}
-knitr::include_graphics(""images/lebreton.png"")
-```
-
-## History of the Cormack-Jolly-Seber (CJS) model
-
-S.T. Buckland (2016). A Conversation with Richard M. Cormack. Statistical Science 31: 142-150.
-
-```{r, echo=FALSE, out.width=""80%""}
-knitr::include_graphics(""images/cormack-left.png"")
-
-```{r, echo=FALSE, out.width=""80%""}
-knitr::include_graphics(""images/cormack-right.png"")
-```
-
-```{r, echo=FALSE, out.width=""70%""}
-knitr::include_graphics(""images/king.png"")
-```
-
-Bayesian uptake
-
-## What we've seen so far 
-
-```{r, engine = 'tikz', echo = FALSE}
-\usetikzlibrary{arrows, fit, positioning, automata}
-\begin{tikzpicture}[node distance = 2cm]
-\tikzset{state/.style = {circle, draw, minimum size = 30pt, scale = 3, line width=1pt}}
-\node [state,fill=lightgray!75] (6) [] {$1$};
-\node [state,fill=lightgray!75] (5) [left = 20mm of 6] {$1$};
-\node [state,fill=lightgray!75] (4) [left = 20mm of 5] {$1$};
-\node [state,fill=lightgray!75] (3) [left = 20mm of 4] {$1$};
-\node [state,fill=lightgray!75] (7) [right = 20mm of 6] {$2$};
-\node [state,fill=lightgray!75] (8) [right = 20mm of 7] {$2$};
-\node [state,fill=lightgray!75] (9) [right = 20mm of 8] {$\cdots$};
-\node [state,fill=white] (16) [above = 20mm of 6] {$1$};
-\node [state,fill=white] (15) [above = 20mm of 5] {$2$};
-\node [state,fill=white] (14) [above = 20mm of 4] {$1$};
-\node [state,fill=white] (17) [above = 20mm of 7] {$1$};
-\node [state,fill=white] (18) [above = 20mm of 8] {$1$};
-\draw[->,black, line width=0.25mm,-latex] (3) -- node[above=3mm, align=center] {\huge $\varphi$} (4);
-\draw[->,black, line width=0.25mm,-latex] (4) -- node[above=3mm, align=center] {\huge $\varphi$} (5);
-\draw[->,black, line width=0.25mm,-latex] (5) -- node[above=3mm, align=center] {\huge $\varphi$} (6);
-\draw[->,black, line width=0.25mm,-latex] (6) -- node[above=3mm, align=center] {\huge $1 - \varphi$} (7);
-\draw[->,black, line width=0.25mm,-latex] (7) -- node[above=3mm, align=center] {\huge $1$} (8);
-\draw[->,black, line width=0.25mm,-latex] (8) -- node[above=3mm, align=center] {\huge $1$} (9);
-\draw[->,black, line width=0.25mm,-latex] (4) -- node[left=3mm, align=center] {\huge $1 - p$} (14);
-\draw[->,black, line width=0.25mm,-latex] (5) -- node[left=3mm, align=center] {\huge $p$} (15);
-\draw[->,black, line width=0.25mm,-latex] (6) -- node[left=3mm, align=center] {\huge $1 - p$} (16);
-\draw[->,black, line width=0.25mm,-latex] (7) -- node[left=3mm, align=center] {\huge $1$} (17);
-\draw[->,black, line width=0.25mm,-latex] (8) -- node[left=3mm, align=center] {\huge $1$} (18);
-\end{tikzpicture}
-```
-
-+ For states (in gray), $z = 1$ is alive, $z = 2$ is dead.
-
-+ For observations (in white), $y = 1$ is non-detected, $y = 2$ is detected
-
-## In the CJS model, survival and recapture are time-varying
-
-```{r, engine = 'tikz', echo = FALSE}
-\usetikzlibrary{arrows, fit, positioning, automata}
-\begin{tikzpicture}[node distance = 2cm]
-\tikzset{state/.style = {circle, draw, minimum size = 30pt, scale = 3, line width=1pt}}
-\node [state,fill=lightgray!75] (6) [] {$1$};
-\node [state,fill=lightgray!75] (5) [left = 20mm of 6] {$1$};
-\node [state,fill=lightgray!75] (4) [left = 20mm of 5] {$1$};
-\node [state,fill=lightgray!75] (3) [left = 20mm of 4] {$1$};
-\node [state,fill=lightgray!75] (7) [right = 20mm of 6] {$2$};
-\node [state,fill=lightgray!75] (8) [right = 20mm of 7] {$2$};
-\node [state,fill=lightgray!75] (9) [right = 20mm of 8] {$\cdots$};
-\node [state,fill=white] (16) [above = 20mm of 6] {$1$};
-\node [state,fill=white] (15) [above = 20mm of 5] {$2$};
-\node [state,fill=white] (14) [above = 20mm of 4] {$1$};
-\node [state,fill=white] (17) [above = 20mm of 7] {$1$};
-\node [state,fill=white] (18) [above = 20mm of 8] {$1$};
-\draw[->,black, line width=0.25mm,-latex] (3) -- node[above=3mm, align=center] {\huge $\varphi_1$} (4);
-\draw[->,black, line width=0.25mm,-latex] (4) -- node[above=3mm, align=center] {\huge $\varphi_2$} (5);
-\draw[->,black, line width=0.25mm,-latex] (5) -- node[above=3mm, align=center] {\huge $\varphi_3$} (6);
-\draw[->,black, line width=0.25mm,-latex] (6) -- node[above=3mm, align=center] {\huge $1 - \varphi_4$} (7);
-\draw[->,black, line width=0.25mm,-latex] (7) -- node[above=3mm, align=center] {\huge $1$} (8);
-\draw[->,black, line width=0.25mm,-latex] (8) -- node[above=3mm, align=center] {\huge $1$} (9);
-\draw[->,black, line width=0.25mm,-latex] (4) -- node[left=3mm, align=center] {\huge $1 - p_2$} (14);
-\draw[->,black, line width=0.25mm,-latex] (5) -- node[left=3mm, align=center] {\huge $p_3$} (15);
-\draw[->,black, line width=0.25mm,-latex] (6) -- node[left=3mm, align=center] {\huge $1 - p_4$} (16);
-\draw[->,black, line width=0.25mm,-latex] (7) -- node[left=3mm, align=center] {\huge $1$} (17);
-\draw[->,black, line width=0.25mm,-latex] (8) -- node[left=3mm, align=center] {\huge $1$} (18);
-\end{tikzpicture}
-```
-
-+ Survival probability is $\phi_t = \Pr(z_{t+1} = 1 | z_t = 1)$.
-
-+ Recapture (detection) probability is $p_t = \Pr(y_{t} = 1 | z_t = 1)$.
-
-+ Accounts for variation in e.g. environmental conditions (survival) or sampling effort (detection). 
-
-## Capture, mark and recapture
-
-```{r, echo=FALSE, out.width=""90%""}
-knitr::include_graphics(""images/gull.jpg"")
-```
-
-```{r, echo=FALSE, out.width=""110%""}
-knitr::include_graphics(""images/bighorn.png"")
-```
-
-Artificial marks
-
-## Capture, mark and recapture
-
-```{r, echo=FALSE, out.width=""90%""}
-knitr::include_graphics(""images/lynx.png"")
-```
-
-```{r, echo=FALSE, out.width=""120%""}
-knitr::include_graphics(""images/bearscat.png"")
-```
-
-Natural marks
-
-## The famous Dipper example
-
-```{r, echo=FALSE, out.width=""60%"", fig.cap=""White-throated Dipper (Cinclus cinclus)""}
-knitr::include_graphics(""images/Marzo_BaguesMance.jpg"")
-```
-
-```{r, echo=FALSE, fig.cap=""Gilbert Marzolin"", out.width=""60%""}
-knitr::include_graphics(""images/Marzocuissardes.jpg"")
-```
-
-## 294 dippers captured and recaptured between 1981 and 1987 with known sex and wing length
-
-```{r echo = FALSE}
-dipper <- read_csv(here::here(""dat"", ""dipper.csv""))
-dipper %>%  
-  kableExtra::kable() %>%
-  kableExtra::scroll_box(width = ""100%"", height = ""400px"")
-y <- dipper %>%
-  select(year_1981:year_1987) %>%
-  as.matrix()
-```
-
-## Back to Nimble. 
-
-### Our model so far $(\phi, p)$
-
-```{r eval = FALSE}
-hmm.phip <- nimbleCode({
-  phi ~ dunif(0, 1) # prior survival
-  p ~ dunif(0, 1) # prior detection
-  # likelihood
-  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)
-  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)
-  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)
-  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)
-  omega[1,2] <- p        # Pr(alive t -> detected t)
-  omega[2,1] <- 1        # Pr(dead t -> non-detected t)
-  omega[2,2] <- 0        # Pr(dead t -> detected t)
-  for (i in 1:N){
-    z[i,first[i]] ~ dcat(delta[1:2])
-    for (j in (first[i]+1):T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])
-      y[i,j] ~ dcat(omega[z[i,j], 1:2])
-    }
-  }
-})
-```
-
-### Our model so far $(\phi, p)$
-
-```{r echo = FALSE}
-load(here::here(""dat"",""dipper.RData""))
-MCMCsummary(object = mcmc.phip, params = c(""phi"",""p""), round = 2)
-```
-
-### The CJS model $(\phi_t, p_t)$
-
-```{r eval=FALSE}
-hmm.phitpt <- nimbleCode({
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  for (t in 1:(T-1)){
-    phi[t] ~ dunif(0, 1) # prior survival #<<
-    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)
-    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)
-    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)
-    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)
-    p[t] ~ dunif(0, 1) # prior detection #<<
-    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)
-    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)
-    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)
-    omega[2,2,t] <- 0        # Pr(dead t -> detected t)
-  }
-  # likelihood
-  for (i in 1:N){
-    z[i,first[i]] ~ dcat(delta[1:2])
-    for (j in (first[i]+1):T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])
-      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])
-    }
-  }
-})
-```
-
-### The CJS model $(\phi_t, p_t)$
-
-
-```{r eval=FALSE}
-hmm.phitpt <- nimbleCode({
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  for (t in 1:(T-1)){ #<<
-    phi[t] ~ dunif(0, 1) # prior survival
-    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)
-    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)
-    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)
-    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)
-    p[t] ~ dunif(0, 1) # prior detection
-    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)
-    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)
-    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)
-    omega[2,2,t] <- 0        # Pr(dead t -> detected t)
-  } #<<
-  # likelihood
-  for (i in 1:N){
-    z[i,first[i]] ~ dcat(delta[1:2])
-    for (j in (first[i]+1):T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])
-      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])
-    }
-  }
-})
-```
-
-### The CJS model $(\phi_t, p_t)$
-
-```{r eval=FALSE}
-hmm.phitpt <- nimbleCode({
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  for (t in 1:(T-1)){
-    phi[t] ~ dunif(0, 1) # prior survival
-    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1) #<<
-    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1) #<<
-    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1) #<<
-    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1) #<<
-    p[t] ~ dunif(0, 1) # prior detection
-    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)
-    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)
-    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)
-    omega[2,2,t] <- 0        # Pr(dead t -> detected t)
-  }
-  # likelihood
-  for (i in 1:N){
-    z[i,first[i]] ~ dcat(delta[1:2])
-    for (j in (first[i]+1):T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])
-      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])
-    }
-  }
-})
-```
-
-### The CJS model $(\phi_t, p_t)$
-
-```{r eval=FALSE}
-hmm.phitpt <- nimbleCode({
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  for (t in 1:(T-1)){
-    phi[t] ~ dunif(0, 1) # prior survival
-    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)
-    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)
-    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)
-    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1) 
-    p[t] ~ dunif(0, 1) # prior detection
-    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t) #<<
-    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t) #<<
-    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t) #<<
-    omega[2,2,t] <- 0        # Pr(dead t -> detected t) #<<
-  }
-  # likelihood
-  for (i in 1:N){
-    z[i,first[i]] ~ dcat(delta[1:2])
-    for (j in (first[i]+1):T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])
-      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])
-    }
-  }
-})
-```
-
-### The CJS model $(\phi_t, p_t)$
-
-```{r eval=FALSE}
-hmm.phitpt <- nimbleCode({
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  for (t in 1:(T-1)){
-    phi[t] ~ dunif(0, 1) # prior survival
-    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)
-    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)
-    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)
-    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1) 
-    p[t] ~ dunif(0, 1) # prior detection
-    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)
-    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)
-    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)
-    omega[2,2,t] <- 0        # Pr(dead t -> detected t)
-  }
-  # likelihood
-  for (i in 1:N){
-    z[i,first[i]] ~ dcat(delta[1:2])
-    for (j in (first[i]+1):T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1]) #<<
-      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1]) #<<
-    }
-  }
-})
-```
-
-### The CJS model $(\phi_t, p_t)$
-
-```{r echo = FALSE}
-load(here::here(""dat"",""dipper.RData""))
-MCMCsummary(object = mcmc.phitpt, params = c(""phi"",""p""), round = 2)
-```
-
-### Time-varying survival $(\phi_t, p)$
-
-```{r eval=FALSE}
-hmm.phitp <- nimbleCode({
-  for (t in 1:(T-1)){
-    phi[t] ~ dunif(0, 1) # prior survival
-    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)
-    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)
-    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)
-    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)
-  }
-  p ~ dunif(0, 1) # prior detection
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)
-  omega[1,2] <- p        # Pr(alive t -> detected t)
-  omega[2,1] <- 1        # Pr(dead t -> non-detected t)
-  omega[2,2] <- 0        # Pr(dead t -> detected t)
-  # likelihood
-  for (i in 1:N){
-    z[i,first[i]] ~ dcat(delta[1:2])
-    for (j in (first[i]+1):T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])
-      y[i,j] ~ dcat(omega[z[i,j], 1:2])
-    }
-  }
-})
-```
-]
-
-### Time-varying survival $(\phi_t, p)$
-
-```{r echo = FALSE}
-load(here::here(""dat"",""dipper.RData""))
-MCMCsummary(object = mcmc.phitp, params = c(""phi"",""p""), round = 2)
-```
-
-### Time-varying detection $(\phi, p_t)$
-
-```{r eval=FALSE}
-hmm.phipt <- nimbleCode({
-  phi ~ dunif(0, 1) # prior survival
-  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)
-  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)
-  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)
-  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  for (t in 1:(T-1)){
-    p[t] ~ dunif(0, 1) # prior detection
-    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)
-    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)
-    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)
-    omega[2,2,t] <- 0        # Pr(dead t -> detected t)
-  }
-  # likelihood
-  for (i in 1:N){
-    z[i,first[i]] ~ dcat(delta[1:2])
-    for (j in (first[i]+1):T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])
-      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])
-    }
-  }
-})
-```
-
-### Time-varying detection $(\phi, p_t)$
-
-```{r echo = FALSE}
-load(here::here(""dat"",""dipper.RData""))
-MCMCsummary(object = mcmc.phipt, params = c(""phi"",""p""), round = 2)
-```
-
-## How to select a best model? Model selection
-
-+ Which of the four models above is best supported by the data?
-
-+ The proportion of explained variance $R^2$ is problematic, because the more variables you have, the bigger $R^2$ is.
-
-+ The idea is to penalize models with too many parameters.
-
-## Akaike information criterion (AIC)
-
-$$AIC = - 2 \log(L(\hat{\theta}_1,\ldots,\hat{\theta}_K)) + 2 K$$
-
-with $L$ the likelihood and $K$ the number of parameters $\theta_i$.
-
-$$\text{AIC} = {\color{purple}{- 2 \log(L(\hat{\theta}_1,\ldots,\hat{\theta}_K))}} + 2 K$$
-
-<span style=""color: purple;"">A measure of goodness-of-fit of the model to the data</span>: the more parameters you have, the smaller the deviance is (or the bigger the likelihood is).
-
-$$\text{AIC} = - 2 \log(L(\hat{\theta}_1,\ldots,\hat{\theta}_K)) + {\color{purple}{2 K}}$$
-
-<span style=""color: purple;"">A penalty</span>: twice the number of parameters $K$
-
-+ AIC makes the balance between *quality of fit* and *complexity* of a model.
-
-+ Best model is the one with lowest AIC value.
-
-+ Two models are difficult to distinguish if $\Delta \text{AIC} < 2$.
-
-## Bayesian version
-
-+ Watanabe-Akaike (Widely-Applicable) Information Criteria or WAIC:
-
-$$\textrm{WAIC} = -2 \sum_{i = 1}^n \log E[\Pr(y_i \mid \theta)] + 
-                  2 p_\text{WAIC}$$
-
-+ where $E[p(y_i \mid \theta)]$ is the posterior mean of the likelihood evaluated pointwise at each $i$th observation.
-
-+ $p_\text{WAIC}$ is a penalty computed using the posterior variance of the likelihood. 
-
-+ More in this video <https://www.youtube.com/watch?v=vSjL2Zc-gEQ> by R. McElreath.
-
-+ Nimble provides the conditional WAIC, where all parameters directly involved in the likelihood are considered. If you would want to calculate the marginal WAIC, integrating over latent variables, you could monitor the relevant nodes and carry out the calculations yourself based on the MCMC output.
-
-## How to compute WAIC in Nimble?
-
-```{r eval = FALSE}
-parameters.to.save <- c(""phi"", ""p"")
-mcmc.phitpt <- nimbleMCMC(code = hmm.phitpt, 
-                          constants = my.constants,
-                          data = my.data,              
-                          inits = initial.values,
-                          monitors = parameters.to.save,
-                          niter = n.iter,
-                          nburnin = n.burnin, 
-                          nchains = n.chains)
-```
-
-```{r eval = FALSE}
-parameters.to.save <- c(""phi"", ""p"", ""z"") #<<
-mcmc.phitpt <- nimbleMCMC(code = hmm.phitpt, 
-                          constants = my.constants,
-                          data = my.data,              
-                          inits = initial.values,
-                          monitors = parameters.to.save,
-                          niter = n.iter,
-                          nburnin = n.burnin, 
-                          nchains = n.chains,
-                          WAIC = TRUE) #<<
-```
-
-## Dipper example - continued
-
-```{r echo = FALSE}
-load(here::here(""dat"",""dipper_waic.RData""))
-data.frame(model = c(""(phi,p)"",
-                     ""(phit,p)"",
-                     ""(phi,pt)"",
-                     ""(phit,pt)""),
-           WAIC = c(mcmc.phip$WAIC, 
-             mcmc.phitp$WAIC, 
-             mcmc.phipt$WAIC, 
-             mcmc.phitpt$WAIC))
-```
-
-## Can we explain time variation? Embrace heterogeneity
-
-+ Include temporal covariates, say $x_t$.
-
-+ $\text{logit}(\phi_t) = \beta_1 + \beta_2 x_t$.
-
-+ Let's investigate the effect of water flow on dipper survival ([Marzolin 2002](https://doi.org/10.2307/3802934)).
-
-```{r eval = FALSE}
-hmm.phiflowp <- nimbleCode({
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  for (t in 1:(T-1)){
-    logit(phi[t]) <- beta[1] + beta[2] * flow[t] #<<
-    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)
-    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)
-    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)
-    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)
-  }
-  p ~ dunif(0, 1) # prior detection
-  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)
-  omega[1,2] <- p        # Pr(alive t -> detected t)
-  omega[2,1] <- 1        # Pr(dead t -> non-detected t)
-  omega[2,2] <- 0        # Pr(dead t -> detected t)
-  beta[1] ~ dnorm(0, 1.5) # prior intercept #<<
-  beta[2] ~ dnorm(0, 1.5) # prior slope #<<
-  # likelihood
-  for (i in 1:N){
-    z[i,first[i]] ~ dcat(delta[1:2])
-    for (j in (first[i]+1):T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])
-      y[i,j] ~ dcat(omega[z[i,j], 1:2])
-    }
-  }
-})
-```
-
-```{r eval = FALSE}
-# water flow in L/s
-water_flow <- c(443, 1114, 529, 434, 627, 466) # 1981, 1982, ..., 1987
-water_flow_st <- (water_flow - mean(water_flow))/sd(water_flow) #<<
-```
-]
-
-```{r eval = FALSE}
-my.constants <- list(N = nrow(y), 
-                     T = ncol(y), 
-                     first = first, 
-                     flow = water_flow_st) #<<
-
-initial.values <- function() list(beta = rnorm(2,0,1),
-                                  p = runif(1,0,1),
-                                  z = zinits)
-
-parameters.to.save <- c(""beta"", ""p"", ""phi"")
-```
-
-### Regression intercept and slope
-
-```{r, echo = FALSE}
-load(here::here(""dat/dipperflow.RData""))
-MCMCplot(object = mcmc.phiflowp, params = ""beta"", ISB = TRUE)
-```
-
-### Time-dependent (covariate constrained) survival probability estimates
-
-```{r, echo = FALSE}
-load(here::here(""dat/dipperflow.RData""))
-MCMCplot(object = mcmc.phiflowp, params = ""phi"", ISB = TRUE)
-```
-
-## Embrace heterogeneity
-
-+ Include temporal covariates, say $x_t$
-
-+ $\text{logit}(\phi_t) = \beta_1 + \beta_2 x_t$
-
-+ If temporal variation not fully explained by covariates, add random effects
-
-+ $\text{logit}(\phi_t) = \beta_1 + \beta_2 x_t + \varepsilon_t, \; \varepsilon_t \sim N(0,\sigma^2)$
-
-```{r eval = FALSE}
-hmm.phiflowREp <- nimbleCode({
-  for (t in 1:(T-1)){
-    logit(phi[t]) <- beta[1] + beta[2] * flow[t] + eps[t] 
-    eps[t] ~ dnorm(0, sd = sdeps) 
-    ...  
-  }
-  sdeps ~ dunif(0,10) 
-  ...
-```
-
-## What about individual heterogeneity?
-
-+ Discrete covariate like, e.g., sex
-
-+ Continuous covariate like, e.g., mass or size
-
-## Sex and wing length in Dipper
-
-```{r echo = FALSE}
-dipper %>%  
-  kableExtra::kable() %>%
-  kableExtra::scroll_box(width = ""100%"", height = ""400px"")
-```
-
-## Sex effect
-
-+ Let's use a covariate $\text{sex}$ that takes value 0 if male, and 1 if female
-
-+ And write $\text{logit}(\phi_i) = \beta_1 + \beta_2 \; \text{sex}_i$ for bird $i$
-
-+ Then male survival is 
-
-$$\text{logit}(\phi_i) = \beta_1$$
-
-+ And female survival is 
-
-$$\text{logit}(\phi_i) = \beta_1 + \beta_2$$
-
-### Nimble implementation with sex as a covariate
-
-```{r eval = FALSE}
-hmm.phisexp <- nimbleCode({
-...
-  for (i in 1:N){ #<<
-    logit(phi[i]) <- beta[1] + beta[2] * sex[i] #<<
-    gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)
-    gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)
-    gamma[2,1,i] <- 0        # Pr(dead t -> alive t+1)
-    gamma[2,2,i] <- 1        # Pr(dead t -> dead t+1)
-  } #<<
-  beta[1] ~ dnorm(mean = 0, sd = 1.5) #<<
-  beta[2] ~ dnorm(mean = 0, sd = 1.5) #<<
-  phi_male <- 1/(1+exp(-beta[1])) #<<
-  phi_female <- 1/(1+exp(-(beta[1]+beta[2]))) #<<
-...
-  # likelihood
-  for (i in 1:N){
-    z[i,first[i]] ~ dcat(delta[1:2])
-    for (j in (first[i]+1):T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, i]) #<<
-      y[i,j] ~ dcat(omega[z[i,j], 1:2])
-    }
-  }
-})
-```
-
-```{r echo = FALSE}
-load(here::here(""dat/phisexp.RData""))
-MCMCsummary(object = mcmc.phisexp, round = 2)
-```
-
-
-### Nimble implementation with nested indexing
-
-+ Let's use a covariate $\text{sex}$ that contains 1s and 2s, indicating the sex of each individual: 1 if male, and 2 if female
-
-```{r eval = FALSE}
-...
-for (i in 1:N){
-  phi[i] <- beta[sex[i]] #<<
-  gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)
-  gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)
-  gamma[2,1,i] <- 0           # Pr(dead t -> alive t+1)
-  gamma[2,2,i] <- 1           # Pr(dead t -> dead t+1)
-}
-beta[1] ~ dunif(0,1) # male survival #<<
-beta[2] ~ dunif(0,1) # female survival #<<
-...
-```
-
-+ E.g. for individual $i = 2$, `beta[sex[i]]` gives `beta[sex[2]]` which will be `beta[1]` or `beta[2]` depending on whether sex[2] is 1 or 2.
-
-```{r echo = FALSE}
-load(here::here(""dat/phisexpni.RData""))
-MCMCsummary(object = mcmc.phisexp.ni, round = 2)
-```
-
-### What about wing length?
-
-```{r eval = FALSE}
-...  
-  for (i in 1:N){ #<<
-    logit(phi[i]) <- beta[1] + beta[2] * winglength[i] #<<
-    gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)
-    gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)
-    gamma[2,1,i] <- 0        # Pr(dead t -> alive t+1)
-    gamma[2,2,i] <- 1        # Pr(dead t -> dead t+1)
-  }
-  beta[1] ~ dnorm(mean = 0, sd = 1.5) # intercept #<<
-  beta[2] ~ dnorm(mean = 0, sd = 1.5) # slope #<<
-...
-```
-
-### Wing length
-
-```{r, echo = FALSE}
-load(here::here(""dat/phiwingp.RData""))
-beta1 <- c(mcmc.phiwlp$chain1[,'beta[1]'], mcmc.phiwlp$chain2[,'beta[1]'])
-beta2 <- c(mcmc.phiwlp$chain1[,'beta[2]'], mcmc.phiwlp$chain2[,'beta[2]'])
-wing.length.st <- as.vector(scale(dipper$wing_length))
-predicted_survival <- matrix(NA, 
-                             nrow = length(beta1), 
-                             ncol = length(wing.length.st))
-for (i in 1:length(beta1)){
-  for (j in 1:length(wing.length.st)){
-    predicted_survival[i,j] <- plogis(beta1[i] + beta2[i] * wing.length.st[j])
-  }
-}
-mean_survival <- apply(predicted_survival, 2, mean)
-lci <- apply(predicted_survival, 2, quantile, prob = 2.5/100)
-uci <- apply(predicted_survival, 2, quantile, prob = 97.5/100)
-ord <- order(wing.length.st)
-df <- data.frame(wing_length = wing.length.st[ord],
-                 survival = mean_survival[ord],
-                 lci = lci[ord],
-                 uci = uci[ord])
-df %>%
-  ggplot() + 
-  aes(x = wing_length, y = survival) + 
-  geom_line() + 
-  geom_ribbon(aes(ymin = lci, ymax = uci), fill = ""grey70"", alpha = 0.5) + 
-  ylim(0,1) + 
-  labs(x = ""wing length"", y = ""estimated survival"")
-```
-
-+ You may test an effect of both sex and wing length, see exercise in Worksheets. 
-
-## What if covariates vary with individual and time?
-
-+ Think of age for example (see exercises in Worksheets); covariate or nested indexing works fine.
-
-+ Now, think of body size across life.
-
-+ Problem is we cannot record size when animal is non-detected.
-
-+ Discretize in small, medium and large and treat as a state <span>&#8212;</span> more later.
-
-+ Assume a model for covariate and fill in missing values (imputation).
-
-
-## Why Bayes? Incorporate prior information.
-
-## Vague prior
-
-+ So far, we have assumed a vague prior:
-
-$$\phi_{prior} \sim \text{Beta}(1,1) = \text{Uniform}(0,1)$$
-
-+ With a vague prior, mean posterior survival is $\phi_{posterior} = 0.56$ 
-
-+ With credible interval $[0.52,0.62]$
-
-```{r, echo = FALSE}
-load(here::here(""dat"",""dipper.RData""))
-PR <- runif(1500, 0, 1)
-MCMCtrace(mcmc.phip, 
-          params = c('phi'),
-          ISB = FALSE,
-          exact = TRUE,
-          priors = PR,
-          pdf = FALSE,
-          Rhat = FALSE,
-          n.eff = FALSE,
-#          post_zm = TRUE,
-          sz_txt = NULL,
-          ind = TRUE,
-          type = ""density"",
-          lwd_den = 3,
-          lwd_pr = 3,
-          col_pr = ""gray70"",
-          lty_pr = 2,
-          main_den = """",
-          xlab_den = ""survival"")
-```
-
-Posterior distribution of survival in color (two chains), prior in gray dashed line.
-
-## How to incorporate prior information?
-
-+ Using information on body mass and annual survival of 27 European passerines, we can predict survival of European dippers using only body mass.
-
-+ For dippers, body mass is 59.8g, therefore $\phi = 0.57$ with $\text{sd} = 0.073$.
-
-+ Assuming an informative prior $\phi_{prior} \sim \text{Normal}(0.57,0.073^2)$.
-
-+ Mean posterior $\phi_{posterior} = 0.56$ with credible interval $[0.52, 0.61]$.
-
-+ No increase of precision in posterior inference.
-
-## How to incorporate prior information?
-
-+ Now if you had only the three first years of data, what would have happened?
-
-+ Width of credible interval is 0.53 (vague prior) vs. 0.24 (informative prior).
-
-+ Huge increase of precision in posterior inference, a $120\%$ gain!
-
-### Compare survival posterior with and without informative prior
-
-```{r, echo = FALSE}
-load(here::here(""dat"",""phip3y.RData""))
-phinoprior <- c(mcmc.phip$chain1[,""phi""], mcmc.phip$chain2[,""phi""])
-load(here::here(""dat"",""phipriorp3y.RData""))
-phiprior <- c(mcmc.phip$chain1[,""phi""], mcmc.phip$chain2[,""phi""])
-df <- data.frame(posterior = c(phinoprior, phiprior),
-                 type = c(rep(""w/ vague prior"", length(phinoprior)),
-                          rep(""w/ informative prior"", length(phiprior))))
-df %>%
-  ggplot() + 
-  aes(x = posterior, fill = type) + 
-  geom_density(aes(y = ..density..), 
-               bins = 40, 
-               color = ""white"", 
-               alpha = 0.6) + 
-  labs(x = ""survival"", fill = """") +
-  scale_fill_manual(values = wesanderson::wes_palette(""Royal1"")[2:1])
-```
-
-## Prior elicitation via moment matching
-
-
-+ The prior $\phi_{prior} \sim \text{Normal}(0.57,0.073^2)$ is not entirely satisfying
-
-+ Remember the Beta distribution
-
-+ Recall that the Beta distribution is a continuous distribution with values between 0 and 1. Useful for modelling survival or detection probabilities. 
-
-+ If $X \sim Beta(\alpha,\beta)$, then the first and second moments of $X$ are:
-
-$$\mu = \text{E}(X) = \frac{\alpha}{\alpha + \beta}$$
-
-$$\sigma^2 = \text{Var}(X) = \frac{\alpha\beta}{(\alpha + \beta)^2 (\alpha + \beta + 1)}$$
-
-## Moment matching
-
-+ In the capture-recapture example, we know a priori that the mean of the probability we're interested in is $\mu = 0.57$ and its variance is $\sigma^2 = 0.073^2$.
-
-+ Parameters $\mu$ and $\sigma^2$ are seen as the moments of a $Beta(\alpha,\beta)$ distribution.
-
-+ Now we look for values of $\alpha$ and $\beta$ that match the observed moments of the Beta distribution $\mu$ and $\sigma^2$.
-
-+ We need another set of equations:
-
-$$\alpha = \bigg(\frac{1-\mu}{\sigma^2}- \frac{1}{\mu} \bigg)\mu^2$$
-
-$$\beta = \alpha \bigg(\frac{1}{\mu}-1\bigg)$$
-
-+ For our model, that means:
-
-```{r echo = TRUE}
-(alpha <- ( (1 - 0.57)/(0.073*0.073) - (1/0.57) )*0.57^2)
-(beta <- alpha * ( (1/0.57) - 1))
-```
-
-+ Now use $\phi_{prior} \sim \text{Beta}(\alpha = 25.6,\beta = 19.3)$ instead of $\phi_{prior} \sim \text{Normal}(0.57,0.073^2)$
-
-## Prior predictive checks
-
-## Linear regression
-
-Unreasonable prior $\beta \sim N(0, 1000^2)$
-
-```{r, echo = FALSE}
-df <- rnorm(1000, 0, 1000)
-df %>%
-  as_tibble() %>%
-  ggplot(aes(x = value)) + 
-  geom_density(size = 2) + 
-  labs(x = ""Height (m)"") +
-  theme_light(base_size = 20)
-```
-
-Reasonable prior $\beta \sim N(2, 0.5^2)$
-
-```{r, echo = FALSE}
-df <- rnorm(1000, 2, 0.5)
-df %>%
-  as_tibble() %>%
-  ggplot(aes(x = value)) + 
-  geom_density(size = 2) + 
-  labs(x = ""Height (m)"") +
-  theme_light(base_size = 20)
-```
-
-## Logistic regression
-
-Unreasonable prior $\text{logit}(\phi) = \beta \sim N(0, 10^2)$
-
-```{r, echo = FALSE}
-df <- plogis(rnorm(1000, 0, 10)) 
-df %>%
-  as_tibble() %>%
-  ggplot(aes(x = value)) + 
-  geom_density(size = 2) + 
-  labs(x = ""survival"") +
-  theme_light(base_size = 20)
-```
-
-Reasonable prior $\text{logit}(\phi) = \beta \sim N(0, 1.5^2)$
-
-```{r, echo = FALSE}
-df <- plogis(rnorm(1000, 0, 1.5)) 
-df %>%
-  as_tibble() %>%
-  ggplot(aes(x = value)) + 
-  geom_density(size = 2) + 
-  labs(x = ""survival"") +
-  theme_light(base_size = 20)
-```
-
-## Capture-recapture models rely on assumptions
-
-+ Design
-    + No mark lost
-    + Identity of individuals recorded without error (no false positives)
-    + Captured individuals are a random sample
-
-+ Model
-    + Homogeneity of survival and recapture probabilities
-    + Independence between individuals (overdispersion)
-
-+ Test validity of assumptions
-    + These assumptions should be valid, whatever inferential framework
-    + Use goodness-of-fit tests <span>&#8212;</span> Pradel et al. (2005)
-    + `R` implementation with [package `R2ucare`](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13014)
-    + Posterior predictive checks can also be used (not covered; [Gelman et al. 2020](https://arxiv.org/pdf/2011.01808.pdf))
-
-### Parameter-redundancy issue
-
-```{r, echo = FALSE}
-load(here::here(""dat"", ""profiledeviance.RData""))
-df <- data.frame(last_survival = grid_lastphi, 
-                 max_dev = devmax)
-mytable <- df %>% slice(c(20, 27, 38, 44)) %>% round(2)
-ggplot() + 
-  geom_line(data = df, 
-            aes(x = last_survival, y = max_dev),
-            size = 1.5,
-            color = ""gray70"") + 
-  geom_point(data = df %>% slice(c(20, 27, 38, 44)), 
-             aes(x = last_survival, y = max_dev), 
-             size = 3.5, 
-             pch = 16,
-             color = ""darkblue"") +
-  labs(x = ""survival over last time interval"", y = ""-log-likelihood"") + 
-  theme_light(base_size = 14) + 
-  annotation_custom(gridExtra::tableGrob(mytable, rows=NULL), xmin=0.4, xmax=0.9, ymin=350, ymax=380)
-```
-
-+ Last survival and recapture probabilities cannot be estimated separately.
-
-+ Poor mixing of the chains.
-
-<!-- --- -->
-<!-- ## Parameter redundancy -->
-
-<!-- -- -->
-
-<!-- + Two issues -->
-
-<!-- -- -->
-
-<!-- + Intrinsic redundancy -->
-<!--     + Likelihood can be expressed by a smaller number of parameters -->
-<!--     + Feature of the model -->
-
-<!-- -- -->
-
-<!-- + Extrinsic redundancy -->
-<!--     + Model structure is fine -->
-<!--     + But lack of data makes a parameter non-estimable -->
-<!--     + Feature of the data -->
-
-## Prior-posterior overlap for $\phi_4$ and $\phi_6$
-
-```{r, echo = FALSE}
-load(here::here(""dat"",""dipper.RData""))
-PR <- runif(1500, 0, 1)
-MCMCtrace(mcmc.phitpt, 
-          params = c('phi[4]'),
-          ISB = FALSE,
-          exact = TRUE,
-          priors = PR,
-          pdf = FALSE,
-          Rhat = FALSE,
-          n.eff = FALSE,
-          ind = FALSE,
-          type = ""density"",
-          lwd_den = 3,
-          lwd_pr = 3,
-          col_pr = ""gray70"",
-          lty_pr = 2,
-          main_den = """",
-          xlab_den = ""survival prob. between years 1984 and 1985"",
-          sz_txt = 1.8,
-          sz_ax = 1.8,
-          sz_ax_txt = 1.8,
-          sz_tick_txt = 1.8,
-          sz_main_txt = 1.8)
-```
-
-
-```{r, echo = FALSE}
-load(here::here(""dat"",""dipper.RData""))
-PR <- runif(1500, 0, 1)
-MCMCtrace(mcmc.phitpt, 
-          params = c('phi[6]'),
-          ISB = FALSE,
-          exact = TRUE,
-          priors = PR,
-          pdf = FALSE,
-          Rhat = FALSE,
-          n.eff = FALSE,
-          ind = FALSE,
-          type = ""density"",
-          lwd_den = 3,
-          lwd_pr = 3,
-          col_pr = ""gray70"",
-          lty_pr = 2,
-          main_den = """",
-          xlab_den = ""survival prob. between years 1986 and 1987"",
-          sz_txt = 1.8,
-          sz_ax = 1.8,
-          sz_ax_txt = 1.8,
-          sz_tick_txt = 1.8,
-          sz_main_txt = 1.8)
-
-```
-
-## Prior-posterior overlap for $p_3$ and $p_7$
-
-```{r, echo = FALSE}
-load(here::here(""dat"",""dipper.RData""))
-PR <- runif(1500, 0, 1)
-MCMCtrace(mcmc.phitpt, 
-          params = c('p[2]'),
-          ISB = FALSE,
-          exact = TRUE,
-          priors = PR,
-          pdf = FALSE,
-          Rhat = FALSE,
-          n.eff = FALSE,
-          ind = FALSE,
-          type = ""density"",
-          lwd_den = 3,
-          lwd_pr = 3,
-          col_pr = ""gray70"",
-          lty_pr = 2,
-          main_den = """",
-          xlab_den = ""recapture prob. at year 1983"",
-          sz_txt = 1.8,
-          sz_ax = 1.8,
-          sz_ax_txt = 1.8,
-          sz_tick_txt = 1.8,
-          sz_main_txt = 1.8)
-
-```
-
-```{r, echo = FALSE}
-load(here::here(""dat"",""dipper.RData""))
-PR <- runif(1500, 0, 1)
-MCMCtrace(mcmc.phitpt, 
-          params = c('p[6]'),
-          ISB = FALSE,
-          exact = TRUE,
-          priors = PR,
-          pdf = FALSE,
-          Rhat = FALSE,
-          n.eff = FALSE,
-          ind = FALSE,
-          type = ""density"",
-          lwd_den = 3,
-          lwd_pr = 3,
-          col_pr = ""gray70"",
-          lty_pr = 2,
-          main_den = """",
-          xlab_den = ""recapture prob. at year 1987"",
-          sz_txt = 1.8,
-          sz_ax = 1.8,
-          sz_ax_txt = 1.8,
-          sz_tick_txt = 1.8,
-          sz_main_txt = 1.8)
-
-```
-
-## What does survival actually mean in capture-recapture ?
-
-+ Survival refers to the study area.
-
-+ Mortality and permanent emigration are confounded.
-
-+ Therefore we estimate apparent survival, not true survival.
-
-+ Apparent survival probability = true survival √ó study area fidelity.
-
-+ Consequently, apparent survival < true survival unless study area fidelity = 1.
-
-+ Use caution with interpretation. If possible, combine with ring-recovery data, or go spatial to get closer to true survival.
-
-
-## Further reading
-
-+ CJS state-space formulation [Gimenez et al. (2007)](https://oliviergimenez.github.io/pubs/Gimenezetal2007EcologicalModelling.pdf) and [Royle (2008)](https://onlinelibrary.wiley.com/doi/10.1111/j.1541-0420.2007.00891.x).
-
-+ Work on missing values by [Bonner et al. (2006)](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1541-0420.2005.00399.x) and [Langrock and King (2013)](https://projecteuclid.org/journals/annals-of-applied-statistics/volume-7/issue-3/Maximum-likelihood-estimation-of-markrecapturerecovery-models-in-the-presence-of/10.1214/13-AOAS644.full) and [Worthington et al. (2015)](https://link.springer.com/article/10.1007/s13253-014-0184-z).
-
-+ The example on how to incorporate prior information is in [McCarthy and Masters (2005)](https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-2664.2005.01101.x).
-
-+ Combine live recapture w/ dead recoveries by [Lebreton et al. (1999)](https://www.tandfonline.com/doi/pdf/10.1080/00063659909477230) and go spatial to account for emigration [Gilroy et al. (2012)](https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/12-0124.1) and [Schaub & Royle (2014)](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12134).
-
-+ Non-identifiability in a Bayesian framework, see [Gimenez et al. (2009)](https://oliviergimenez.github.io/pubs/Gimenezetal2009-weakidentifiability.pdf) and [book by Cole (2020)](https://www.routledge.com/Parameter-Redundancy-and-Identifiability/Cole/p/book/9781498720878).
\ No newline at end of file

---FILE: 05-transition.Rmd---
@@ -1,1206 +0,0 @@
-# Transition {#transition}
-
-```{r}
-knitr::include_graphics(""images/arnason1973.png"")
-```
-
-
-```{r}
-knitr::include_graphics(""images/schwarz1993.png"")
-```
-
-```{r}
-knitr::include_graphics(""images/deadpool.gif"")
-```
-
-Thank you Canada!
-
-
-```{r}
-knitr::include_graphics(""images/nichols.png"")
-```
-
-
-## Wintering site fidelity in Canada Geese
-
-### 3 sites Carolinas, Chesapeake, Mid-Atlantic, 
-
-with 21277 banded geese, data kindly provided by Jay Hestbeck ([Hestbeck et al. 1991](https://esajournals.onlinelibrary.wiley.com/doi/10.2307/2937193))
-
-```{r echo = FALSE}
-geese <- read_csv(here::here(""dat"", ""geese.csv""))
-geese %>%  
-  kableExtra::kable() %>%
-  kableExtra::scroll_box(width = ""100%"", height = ""400px"")
-y <- geese %>%
-  as.matrix()
-```
-
-(large areas along East coast of US)
-
-### Biological inference
-
-```{r, echo = FALSE}
-ggplot() + 
-  geom_point(aes(1, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(1, 2, label = 'non-detection'), nudge_x = -0.6, size = 7) + 
-  geom_text(aes(1, 1.5, label = 'detection in site A'), nudge_x = -0.6, size = 7) + 
-  geom_text(aes(1, 1, label = 'detection in site B'), nudge_x = -0.6, size = 7) +
-  geom_point(aes(2, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(2, 2, label = 'alive in site A'), nudge_x = 0.5, size = 7) + 
-  geom_text(aes(2, 1.5, label = 'alive in site B'), nudge_x = 0.5, size = 7) + 
-  geom_text(aes(2, 1, label = 'dead'), nudge_x = 0.5, size = 7) + 
-  xlim(0, 3) + 
-  ylim(0.5, 3) + 
-  annotate('text', x = 1, y = 2.6, label = 'Observations', size = 10) + 
-  annotate('text', x = 2, y = 2.6, label = 'States', size = 10) +
-  theme_void()
-```
-
-+ Observations and states are closely related, but not entirely.
-
-
-```{r, echo = FALSE}
-ggplot() + 
-  geom_point(aes(1, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(1, 2, label = 'non-detection'), nudge_x = -0.6, size = 7) + 
-  geom_text(aes(1, 1.5, label = 'detection in site A'), nudge_x = -0.6, size = 7) + 
-  geom_text(aes(1, 1, label = 'detection in site B'), nudge_x = -0.6, size = 7) +
-  geom_point(aes(2, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(2, 2, label = 'alive in site A'), nudge_x = 0.5, size = 7) + 
-  geom_text(aes(2, 1.5, label = 'alive in site B'), nudge_x = 0.5, size = 7) + 
-  geom_text(aes(2, 1, label = 'dead'), nudge_x = 0.5, size = 7) + 
-  xlim(0, 3) + 
-  ylim(0.5, 3) + 
-  annotate('text', x = 1, y = 2.6, label = 'Observations', size = 10) + 
-  annotate('text', x = 2, y = 2.6, label = 'States', size = 10) +
-  geom_segment(aes(x = 1, y = 1.5, xend = 2, yend = 2), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  theme_void()
-```
-
-```{r, echo = FALSE}
-ggplot() + 
-  geom_point(aes(1, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(1, 2, label = 'non-detection'), nudge_x = -0.6, size = 7) + 
-  geom_text(aes(1, 1.5, label = 'detection in site A'), nudge_x = -0.6, size = 7) + 
-  geom_text(aes(1, 1, label = 'detection in site B'), nudge_x = -0.6, size = 7) +
-  geom_point(aes(2, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(2, 2, label = 'alive in site A'), nudge_x = 0.5, size = 7) + 
-  geom_text(aes(2, 1.5, label = 'alive in site B'), nudge_x = 0.5, size = 7) + 
-  geom_text(aes(2, 1, label = 'dead'), nudge_x = 0.5, size = 7) + 
-  xlim(0, 3) + 
-  ylim(0.5, 3) + 
-  annotate('text', x = 1, y = 2.6, label = 'Observations', size = 10) + 
-  annotate('text', x = 2, y = 2.6, label = 'States', size = 10) +
-  geom_segment(aes(x = 1, y = 1.5, xend = 2, yend = 2), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 1, xend = 2, yend = 1.5), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  theme_void()
-```
-
-```{r, echo = FALSE}
-ggplot() + 
-  geom_point(aes(1, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(1, 2, label = 'non-detection'), nudge_x = -0.6, size = 7) + 
-  geom_text(aes(1, 1.5, label = 'detection in site A'), nudge_x = -0.6, size = 7) + 
-  geom_text(aes(1, 1, label = 'detection in site B'), nudge_x = -0.6, size = 7) +
-  geom_point(aes(2, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(2, 2, label = 'alive in site A'), nudge_x = 0.5, size = 7) + 
-  geom_text(aes(2, 1.5, label = 'alive in site B'), nudge_x = 0.5, size = 7) + 
-  geom_text(aes(2, 1, label = 'dead'), nudge_x = 0.5, size = 7) + 
-  xlim(0, 3) + 
-  ylim(0.5, 3) + 
-  annotate('text', x = 1, y = 2.6, label = 'Observations', size = 10) + 
-  annotate('text', x = 2, y = 2.6, label = 'States', size = 10) +
-  geom_segment(aes(x = 1, y = 2, xend = 2, yend = 2), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 2, xend = 2, yend = 1.5), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 2, xend = 2, yend = 1), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 1.5, xend = 2, yend = 2), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 1, xend = 2, yend = 1.5), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  theme_void()
-```
-
-
-### The model construction: How we should think. 
-
-```{r, echo = FALSE}
-ggplot() + 
-  geom_point(aes(1, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(2, 2, label = 'non-detection'), nudge_x = 0.5, size = 7) + 
-  geom_text(aes(2, 1.5, label = 'detection in site A'), nudge_x = 0.6, size = 7) + 
-  geom_text(aes(2, 1, label = 'detection in site B'), nudge_x = 0.6, size = 7) +
-  geom_point(aes(2, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(1, 2, label = 'alive in site A'), nudge_x = -0.6, size = 7) + 
-  geom_text(aes(1, 1.5, label = 'alive in site B'), nudge_x = -0.6, size = 7) + 
-  geom_text(aes(1, 1, label = 'dead'), nudge_x = -0.6, size = 7) + 
-  xlim(0, 3) + 
-  ylim(0.5, 3) + 
-  annotate('text', x = 1, y = 2.6, label = 'States', size = 10) + 
-  annotate('text', x = 2, y = 2.6, label = 'Observations', size = 10) + 
-  theme_void()
-```
-
-Generative model. States generate observations. 
-
-
-### The model construction: How we should think. 
-
-```{r, echo = FALSE}
-ggplot() + 
-  geom_point(aes(1, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(2, 2, label = 'non-detection'), nudge_x = 0.5, size = 7) + 
-  geom_text(aes(2, 1.5, label = 'detection in site A'), nudge_x = 0.6, size = 7) + 
-  geom_text(aes(2, 1, label = 'detection in site B'), nudge_x = 0.6, size = 7) +
-  geom_point(aes(2, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(1, 2, label = 'alive in site A'), nudge_x = -0.6, size = 7) + 
-  geom_text(aes(1, 1.5, label = 'alive in site B'), nudge_x = -0.6, size = 7) + 
-  geom_text(aes(1, 1, label = 'dead'), nudge_x = -0.6, size = 7) + 
-  xlim(0, 3) + 
-  ylim(0.5, 3) + 
-  annotate('text', x = 1, y = 2.6, label = 'States', size = 10) + 
-  annotate('text', x = 2, y = 2.6, label = 'Observations', size = 10) + 
-    geom_segment(aes(x = 1, y = 1, xend = 2, yend = 2), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  theme_void()
-```
-
-### The model construction: How we should think. 
-
-```{r, echo = FALSE}
-ggplot() + 
-  geom_point(aes(1, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(2, 2, label = 'non-detection'), nudge_x = 0.5, size = 7) + 
-  geom_text(aes(2, 1.5, label = 'detection in site A'), nudge_x = 0.6, size = 7) + 
-  geom_text(aes(2, 1, label = 'detection in site B'), nudge_x = 0.6, size = 7) +
-  geom_point(aes(2, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(1, 2, label = 'alive in site A'), nudge_x = -0.6, size = 7) + 
-  geom_text(aes(1, 1.5, label = 'alive in site B'), nudge_x = -0.6, size = 7) + 
-  geom_text(aes(1, 1, label = 'dead'), nudge_x = -0.6, size = 7) + 
-  xlim(0, 3) + 
-  ylim(0.5, 3) + 
-  annotate('text', x = 1, y = 2.6, label = 'States', size = 10) + 
-  annotate('text', x = 2, y = 2.6, label = 'Observations', size = 10) + 
-    geom_segment(aes(x = 1, y = 2, xend = 2, yend = 2), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 2, xend = 2, yend = 1.5), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 1, xend = 2, yend = 2), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  theme_void()
-```
-
-### The model construction: How we should think. 
-
-```{r, echo = FALSE}
-ggplot() + 
-  geom_point(aes(1, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(2, 2, label = 'non-detection'), nudge_x = 0.5, size = 7) + 
-  geom_text(aes(2, 1.5, label = 'detection in site A'), nudge_x = 0.6, size = 7) + 
-  geom_text(aes(2, 1, label = 'detection in site B'), nudge_x = 0.6, size = 7) +
-  geom_point(aes(2, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(1, 2, label = 'alive in site A'), nudge_x = -0.6, size = 7) + 
-  geom_text(aes(1, 1.5, label = 'alive in site B'), nudge_x = -0.6, size = 7) + 
-  geom_text(aes(1, 1, label = 'dead'), nudge_x = -0.6, size = 7) + 
-  xlim(0, 3) + 
-  ylim(0.5, 3) + 
-  annotate('text', x = 1, y = 2.6, label = 'States', size = 10) + 
-  annotate('text', x = 2, y = 2.6, label = 'Observations', size = 10) + 
-    geom_segment(aes(x = 1, y = 2, xend = 2, yend = 2), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 2, xend = 2, yend = 1.5), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 1.5, xend = 2, yend = 2), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 1.5, xend = 2, yend = 1), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 1, xend = 2, yend = 2), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  theme_void()
-```
-
-### HMM model for dispersal with 2 sites (drop Carolinas)
-
-Transition matrix
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Gamma} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    z_{t}=A & z_{t}=B & z_{t}=D \\ \hdashline
-\phi_A (1-\psi_{AB}) & \phi_A \psi_{AB} & 1 - \phi_A\\ 
-\phi_B \psi_{BA} & \phi_B (1-\psi_{BA}) & 1 - \phi_B\\ 
-0 & 0 & 1
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    z_{t-1}=A \\ z_{t-1}=B \\ z_{t-1}=D
-    \end{matrix}
-\end{matrix}
-$$
-
-### HMM model for dispersal with 2 sites (drop Carolinas)
-
-Observation matrix
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Omega} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    y_t=0 & y_t=1 & y_t=2 \\ \hdashline
-1 - p_A & p_A & 0\\ 
-1 - p_B & 0 & p_B\\ 
-1 & 0 & 0
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    z_{t}=A \\ z_{t}=B \\ z_{t}=D
-    \end{matrix}
-\end{matrix}
-$$
-
-### HMM model for dispersal with 2 sites (drop Carolinas)
-
-Observation matrix
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Omega} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    y_t=0 & y_t=1 & y_t=2 \\ \hdashline
-1 - p_A & p_A & 0\\ 
-1 - p_B & 0 & p_B\\ 
-1 & 0 & 0
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    z_{t}=A \\ z_{t}=B \\ z_{t}=D
-    \end{matrix}
-\end{matrix}
-$$
-
-Note: You may code non-detections as $y_t = 2$, and the first column in the observation matrix should go last.
-
-Quick answer about the -1 and the important issue of coding states and obs. I did this on purpose, to have folks think about the difference between observations and states (non-detection obs should not be confused with state for dead). This becomes even more crucial when we get to multievent models where several observations may be generated by a single state. I get the intuition argument perfectly, but I‚Äôd like them to fight against it at first, then once they‚Äôre comfortable with the difference, they may code obs/states as they see fit. Let‚Äôs see how it goes. I agree that we should mention that during the multistate lecture, in the spirit of ¬´ you‚Äôre free to code states and jobs the way you like ¬ª. I‚Äôll add something. 
-
-### Our model $(\phi_A, \phi_B, \psi_{AB}, \psi_{BA}, p_A, p_B)$
-
-```{r eval = FALSE}
-multisite <- nimbleCode({
-  # -------------------------------------------------
-  # Parameters:
-  # phiA: survival probability site A
-  # phiB: survival probability site B
-  # psiAB: movement probability from site A to site B
-  # psiBA: movement probability from site B to site A
-  # pA: recapture probability site A
-  # pB: recapture probability site B
-  # -------------------------------------------------
-  # States (z):
-  # 1 alive at A
-  # 2 alive at B
-  # 3 dead
-  # Observations (y):  
-  # 1 not seen
-  # 2 seen at A 
-  # 3 seen at B
-  # -------------------------------------------------
-...
-```
-
-### Our model $(\phi_A, \phi_B, \psi_{AB}, \psi_{BA}, p_A, p_B)$
-
-```{r eval = FALSE}
-multisite <- nimbleCode({
-...
-  # Priors
-  phiA ~ dunif(0, 1)
-  phiB ~ dunif(0, 1)
-  psiAB ~ dunif(0, 1)
-  psiBA ~ dunif(0, 1)
-  pA ~ dunif(0, 1)
-  pB ~ dunif(0, 1)
-...
-```
-
-### Our model $(\phi_A, \phi_B, \psi_{AB}, \psi_{BA}, p_A, p_B)$
-
-```{r eval = FALSE}
-multisite <- nimbleCode({
-...  
-  # initial state probabilities
-  delta[1] <- piA          # Pr(alive in A t = 1)
-  delta[2] <- 1 - piA      # Pr(alive in B t = 1)
-  delta[3] <- 0            # Pr(dead t = 1) = 0
-...  
-```
-
-+ Actually, initial state is known exactly. It is alive at site of initial capture, and $\pi_A$ is just the proportion of individuals first captured in site A, no need to estimate it. 
-
-+ Instead of `z[i,first[i]] ~ dcat(delta[1:3])`, use `z[i,first[i]] <- y[i,first[i]]-1` instead in the likelihood. 
-
-+ Same trick applies to CJS models. 
-
-### Our model $(\phi_A, \phi_B, \psi_{AB}, \psi_{BA}, p_A, p_B)$
-
-```{r eval = FALSE}
-multisite <- nimbleCode({
-...  
-  # probabilities of state z(t+1) given z(t)
-  # (read as gamma[z(t),z(t+1)] = gamma[fromState,toState])
-  
-  gamma[1,1] <- phiA * (1 - psiAB)
-  gamma[1,2] <- phiA * psiAB
-  gamma[1,3] <- 1 - phiA
-  gamma[2,1] <- phiB * psiBA
-  gamma[2,2] <- phiB * (1 - psiBA)
-  gamma[2,3] <- 1 - phiB
-  gamma[3,1] <- 0
-  gamma[3,2] <- 0
-  gamma[3,3] <- 1
-...  
-```
-
-### Our model $(\phi_A, \phi_B, \psi_{AB}, \psi_{BA}, p_A, p_B)$
-
-```{r eval = FALSE}
-multisite <- nimbleCode({
-...  
-  # probabilities of y(t) given z(t)
-  # (read as omega[y(t),z(t)] = omega[Observation,State])
-
-  omega[1,1] <- 1 - pA     # Pr(alive A t -> non-detected t)
-  omega[1,2] <- pA         # Pr(alive A t -> detected A t)
-  omega[1,3] <- 0          # Pr(alive A t -> detected B t)
-  omega[2,1] <- 1 - pB     # Pr(alive B t -> non-detected t)
-  omega[2,2] <- 0          # Pr(alive B t -> detected A t)
-  omega[2,3] <- pB         # Pr(alive B t -> detected B t)
-  omega[3,1] <- 1          # Pr(dead t -> non-detected t)
-  omega[3,2] <- 0          # Pr(dead t -> detected A t)
-  omega[3,3] <- 0          # Pr(dead t -> detected B t)
-...
-```
-
-### Our model $(\phi_A, \phi_B, \psi_{AB}, \psi_{BA}, p_A, p_B)$
-
-```{r eval = FALSE}
-multisite <- nimbleCode({
-...
-  # likelihood 
-  for (i in 1:N){
-    # latent state at first capture
-    z[i,first[i]] <- y[i,first[i]] - 1
-    for (t in (first[i]+1):K){
-      # z(t) given z(t-1)
-      z[i,t] ~ dcat(gamma[z[i,t-1],1:3])
-      # y(t) given z(t)
-      y[i,t] ~ dcat(omega[z[i,t],1:3])
-    }
-  }
-})
-```
-
-
-```{r echo = FALSE}
-library(MCMCvis)
-load(here::here(""dat"",""geese_2sites.RData""))
-MCMCsummary(mcmc.multisite, round = 2)
-```
-
-```{r, echo = FALSE}
-library(MCMCvis)
-load(here::here(""dat"",""geese_2sites.RData""))
-MCMCplot(mcmc.multisite)
-```
-
-
-## What if there are three sites?
-
-+ The transition probabilities still need to be between 0 and 1.
-
-+ Another constraint is that the sum of three probabilities of departure from a given site should be one. 
-
-+ Two methods to fulfill both constraints. 
-    + Dirichlet prior
-    + Multinomial logit link
-
-Dirichlet prior with parameter alpha
-
-```{r, echo = FALSE, fig.cap = ""Dirichlet prior with parameter alpha""}
-library(gtools)
-library(ggtern)
-set.seed(123)
-n <- 500
-alpha1 <- c(1, 1, 1)
-p1 <- rdirichlet(n, alpha1) 
-alpha2 <- c(5, 5, 5)
-p2 <- rdirichlet(n, alpha2) 
-alpha3 <- c(1, 2, 2)
-p3 <- rdirichlet(n, alpha3) 
-alpha4 <- c(2, 4, 8)
-p4 <- rdirichlet(n, alpha4) 
-df <- cbind(rbind(p1, p2, p3, p4), c(rep(""alpha = c(1, 1, 1)"", n),
-                                     rep(""alpha = c(5, 5, 5)"", n),
-                                     rep(""alpha = c(1, 2, 2)"", n),
-                                     rep(""alpha = c(2, 4, 8)"", n))) %>%
-  as_tibble() %>%
-  mutate(x = as.numeric(V1),
-         y = as.numeric(V2),
-         z = as.numeric(V3),
-         alpha = V4)
-  
-df %>% 
-  ggtern(aes(x = x, y = y, z = z)) + 
-  stat_density_tern(aes(fill=..level.., alpha=..level..), 
-                    geom = 'polygon', 
-                    bdl = 0.005) +
-#  scale_fill_gradient2(high = ""blue"") + 
-  scale_fill_viridis_b() +  
-  geom_point(alpha = 0.3, pch = ""+"") +
-  theme_light(base_size = 14) + 
-  theme_showarrows() +
-  scale_T_continuous(breaks = seq(0, 1, by = 0.2), 
-                     labels = seq(0, 1, by = 0.2)) +
-  scale_L_continuous(breaks = seq(0, 1, by = 0.2), 
-                     labels = seq(0, 1, by = 0.2)) +
-  scale_R_continuous(breaks = seq(0, 1, by = 0.2), 
-                     labels = seq(0, 1, by = 0.2)) +
-  labs(x = """",
-       y = """",
-       z = """",
-       Tarrow = ""psiAA"",
-       Larrow = ""psiAB"",
-       Rarrow = ""psiAC"") +
-  guides(color = ""none"", fill = ""none"", alpha = ""none"") + 
-  facet_wrap(~alpha)
-```
-
-
-### Nimble implementation of the Dirichlet prior
-
-```{r eval = FALSE}
-multisite <- nimbleCode({
-...
-  # transitions: Dirichlet priors
-  psiA[1:3] ~ ddirch(alpha[1:3]) # psiAA, psiAB, psiAC
-  psiB[1:3] ~ ddirch(alpha[1:3]) # psiBA, psiBB, psiCC
-  psiC[1:3] ~ ddirch(alpha[1:3]) # psiCA, psiCB, psiCC
-...
-```
-
-### Nimble implementation of the Dirichlet prior
-
-```{r eval = FALSE}
-multisite <- nimbleCode({
-...
-  # probabilities of state z(t+1) given z(t)
-  gamma[1,1] <- phiA * psiA[1]
-  gamma[1,2] <- phiA * psiA[2]
-  gamma[1,3] <- phiA * psiA[3]
-  gamma[1,4] <- 1 - phiA
-  gamma[2,1] <- phiB * psiB[1]
-  gamma[2,2] <- phiB * psiB[2]
-  gamma[2,3] <- phiB * psiB[3]
-  gamma[2,4] <- 1 - phiB
-  gamma[3,1] <- phiC * psiC[1]
-  gamma[3,2] <- phiC * psiC[2]
-  gamma[3,3] <- phiC * psiC[3]
-  gamma[3,4] <- 1 - phiC
-  gamma[4,1] <- 0
-  gamma[4,2] <- 0
-  gamma[4,3] <- 0
-  gamma[4,4] <- 1
-...
-```
-
-```{r echo = FALSE}
-library(MCMCvis)
-load(here::here(""dat"",""geese_3sites_dirichlet.RData""))
-MCMCsummary(mcmc.multisite, round = 2)
-```
-
-```{r, echo = FALSE}
-library(MCMCvis)
-load(here::here(""dat"",""geese_3sites_dirichlet.RData""))
-MCMCplot(mcmc.multisite)
-```
-
-
-### Multinomial logit
-
-+ Say we have $P$ sites or states.
-
-+ Specify a normal prior distribution for $P-1$ transition parameters $\alpha_j$. These probabilities are on the multinomial logit scale, possibly function of covariates.
-
-+ To back-transform these parameters, we use:
-
-$$\beta_j = \displaystyle{\frac{\exp(\alpha_j)}{1+\displaystyle{\sum_{p=1}^P{\exp(\alpha_p)}}}}, j = 1,\ldots,P-1$$
-
-+ This ensures that all $\beta_j$ are between 0 and 1, and their sum is 1.
-
-+ Last parameter is calculated as the complement $\beta_P = 1 - \displaystyle{\sum_{j=1}^{P-1}{\exp(\beta_j)}}$
-
-### Nimble implementation of the Dirichlet prior
-
-```{r eval = FALSE}
-multisite <- nimbleCode({
-...
-  # transitions: multinomial logit
-  # normal priors on logit of all but one transition probs
-  for (i in 1:2){
-    lpsiA[i] ~ dnorm(0, sd = 1000)
-    lpsiB[i] ~ dnorm(0, sd = 1000)
-    lpsiC[i] ~ dnorm(0, sd = 1000)
-  }
-  # constrain the transitions such that their sum is < 1
-  for (i in 1:2){
-    psiA[i] <- exp(lpsiA[i]) / (1 + exp(lpsiA[1]) + exp(lpsiA[2]))
-    psiB[i] <- exp(lpsiB[i]) / (1 + exp(lpsiB[1]) + exp(lpsiB[2]))
-    psiC[i] <- exp(lpsiC[i]) / (1 + exp(lpsiC[1]) + exp(lpsiC[2]))
-  }
-  # last transition probability
-  psiA[3] <- 1 - psiA[1] - psiA[2]
-  psiB[3] <- 1 - psiB[1] - psiB[2]
-  psiC[3] <- 1 - psiC[1] - psiC[2]
-...
-```
-
-### Nimble implementation of the Dirichlet prior
-
-```{r eval = FALSE}
-multisite <- nimbleCode({
-...
-  # probabilities of state z(t+1) given z(t)
-  gamma[1,1] <- phiA * psiA[1]
-  gamma[1,2] <- phiA * psiA[2]
-  gamma[1,3] <- phiA * psiA[3]
-  gamma[1,4] <- 1 - phiA
-  gamma[2,1] <- phiB * psiB[1]
-  gamma[2,2] <- phiB * psiB[2]
-  gamma[2,3] <- phiB * psiB[3]
-  gamma[2,4] <- 1 - phiB
-  gamma[3,1] <- phiC * psiC[1]
-  gamma[3,2] <- phiC * psiC[2]
-  gamma[3,3] <- phiC * psiC[3]
-  gamma[3,4] <- 1 - phiC
-  gamma[4,1] <- 0
-  gamma[4,2] <- 0
-  gamma[4,3] <- 0
-  gamma[4,4] <- 1
-...
-```
-
-```{r echo = FALSE}
-library(MCMCvis)
-load(here::here(""dat"",""geese_3sites_logit.RData""))
-MCMCsummary(mcmc.multisite, round = 2)
-```
-
-```{r, echo = FALSE}
-library(MCMCvis)
-load(here::here(""dat"",""geese_3sites_logit.RData""))
-MCMCplot(mcmc.multisite)
-```
-
-
-## Sites may be states.
-
-## Examples of multistate models
-
-+ *Epidemiological or disease states*: sick/healthy, uninfected/infected/recovered.
-
-+ *Morphological states*: small/medium/big,  light/medium/heavy.
-
-+ *Breeding states*: e.g. breeder/non-breeder,  failed breeder, first-time breeder. 
-
-+ *Developmental or life-history states*: e.g. juvenile/subadult/adult.
-
-+ *Social states*: e.g. solitary/group-living,  subordinate/dominant.
-
-+ *Death states*: e.g. alive, dead from harvest, dead from natural causes. 
-
-**States = individual, time-specific categorical covariates.**
-
-```{r}
-knitr::include_graphics(""images/sooty.jpg"")
-```
-
-### Sooty shearwater (David Boyle)
-
-## Sooty shearwaters and life-history tradeoffs
-
-+ We consider data collected between 1940 and 1957 by Lance Richdale on Sooty shearwaters (aka titis). 
-
-+ These data were reanalyzed with multistate models by [Scofield et al. (2001)](https://link.springer.com/article/10.1198/108571101750524607) who kindly provided us with the data. 
-
-+ Following the way the data were collected, four states were originally considered:
-    + Alive breeder;
-    + Accompanied by another bird in a burrow;
-    + Alone in a burrow;
-    + On the surface;
-    + Dead.
-    
-## Sooty shearwaters and life-history tradeoffs
-
-+ Because of numerical issues, we pooled all alive states but breeder together in a non-breeder state (NB) that includes:
-
-    + failed breeders (birds that had bred previously ‚Äì skip reproduction or divorce) and pre-breeders (birds that had yet to breed). 
-    
-    + Note that because burrows were not checked before hatching, some birds in the category NB might have already failed. 
-    
-    + We therefore regard those birds in the B state as successful breeders, and those in the NB state as nonbreeders plus prebreeders and failed breeders.
-
-+ Observations are non-detections, and detections as breeder and non-breeder
-
-+ Does breeding affect survival? Does breeding in current year affect breeding next year?
-
-
-```{r echo = FALSE}
-titis <- read_csv2(here::here(""dat"", ""titis.csv""), col_names = FALSE)
-titis %>%
-  rename(year_1942 = X1,
-         year_1943 = X2,
-         year_1944 = X3,
-         year_1949 = X4,
-         year_1952 = X5,
-         year_1953 = X6,
-         year_1956 = X7) %>%
-  kableExtra::kable() %>%
-  kableExtra::scroll_box(width = ""100%"", height = ""400px"")
-```
-
-### HMM model for transition between states
-
-Transition matrix
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Gamma} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    z_t=B & z_t=NB & z_t=D \\ \hdashline
-\phi_B (1-\psi_{BNB}) & \phi_B \psi_{BNB} & 1 - \phi_B\\ 
-\phi_{NB} \psi_{NBB} & \phi_{NB} (1-\psi_{NBB}) & 1 - \phi_{NB}\\ 
-0 & 0 & 1
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    z_{t-1}=B \\ z_{t-1}=NB \\ z_{t-1}=D
-    \end{matrix}
-\end{matrix}
-$$
-
-+ Costs or reproduction would reflect in future reproduction $\psi_{BB} = 1 - \psi_{BNB} < \psi_{NBB}$ or survival $\phi_B < \phi_{NB}$.
-
-### HMM model for transition between states
-
-Observation matrix
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Omega} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    y_t=0 & y_t=1 & y_t=2 \\ \hdashline
-1 - p_B & p_B & 0\\ 
-1 - p_{NB} & 0 & p_{NB}\\ 
-1 & 0 & 0
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    z_{t}=B \\ z_{t}=NB \\ z_{t}=D
-    \end{matrix}
-\end{matrix}
-$$
-
-### Our model $(\phi_{NB}, \phi_B, \psi_{NBB}, \psi_{BNB}, p_{NB}, p_B)$
-
-```{r eval = FALSE}
-multistate <- nimbleCode({
-  # -------------------------------------------------
-  # Parameters:
-  # phiB: survival probability state B
-  # phiNB: survival probability state NB
-  # psiBNB: transition probability from B to NB
-  # psiNBB: transition probability from NB to B
-  # pB: recapture probability B
-  # pNB: recapture probability NB
-  # -------------------------------------------------
-  # States (z):
-  # 1 alive B
-  # 2 alive NB
-  # 3 dead
-  # Observations (y):  
-  # 1 not seen
-  # 2 seen as B 
-  # 3 seen as NB
-  # -------------------------------------------------
-...
-```
-
-### Our model $(\phi_{NB}, \phi_B, \psi_{NBB}, \psi_{BNB}, p_{NB}, p_B)$
-
-```{r eval = FALSE}
-multistate <- nimbleCode({
-...
-  # Priors
-  phiB ~ dunif(0, 1)
-  phiNB ~ dunif(0, 1)
-  psiBNB ~ dunif(0, 1)
-  psiNBB ~ dunif(0, 1)
-  pB ~ dunif(0, 1)
-  pNB ~ dunif(0, 1)
-...
-```
-
-### Our model $(\phi_{NB}, \phi_B, \psi_{NBB}, \psi_{BNB}, p_{NB}, p_B)$
-
-```{r eval = FALSE}
-multistate <- nimbleCode({
-...  
-  # probabilities of state z(t+1) given z(t)
-  gamma[1,1] <- phiB * (1 - psiBNB)
-  gamma[1,2] <- phiB * psiBNB
-  gamma[1,3] <- 1 - phiB
-  gamma[2,1] <- phiNB * psiNBB
-  gamma[2,2] <- phiNB * (1 - psiNBB)
-  gamma[2,3] <- 1 - phiNB
-  gamma[3,1] <- 0
-  gamma[3,2] <- 0
-  gamma[3,3] <- 1
-...  
-```
-
-### Our model $(\phi_{NB}, \phi_B, \psi_{NBB}, \psi_{BNB}, p_{NB}, p_B)$
-
-```{r eval = FALSE}
-multistate <- nimbleCode({
-...  
-  # probabilities of y(t) given z(t)
-  omega[1,1] <- 1 - pB    # Pr(alive B t -> non-detected t)
-  omega[1,2] <- pB        # Pr(alive B t -> detected B t)
-  omega[1,3] <- 0         # Pr(alive B t -> detected NB t)
-  omega[2,1] <- 1 - pNB   # Pr(alive NB t -> non-detected t)
-  omega[2,2] <- 0         # Pr(alive NB t -> detected B t)
-  omega[2,3] <- pNB       # Pr(alive NB t -> detected NB t)
-  omega[3,1] <- 1         # Pr(dead t -> non-detected t)
-  omega[3,2] <- 0         # Pr(dead t -> detected N t)
-  omega[3,3] <- 0         # Pr(dead t -> detected NB t)
-...
-```
-
-### Our model $(\phi_{NB}, \phi_B, \psi_{NBB}, \psi_{BNB}, p_{NB}, p_B)$
-
-```{r eval = FALSE}
-multistate <- nimbleCode({
-...
-  # likelihood 
-  for (i in 1:N){
-    # latent state at first capture
-    z[i,first[i]] <- y[i,first[i]] - 1
-    for (t in (first[i]+1):K){
-      # z(t) given z(t-1)
-      z[i,t] ~ dcat(gamma[z[i,t-1],1:3])
-      # y(t) given z(t)
-      y[i,t] ~ dcat(omega[z[i,t],1:3])
-    }
-  }
-})
-```
-
-```{r echo = FALSE}
-library(MCMCvis)
-load(here::here(""dat"",""titis.RData""))
-MCMCsummary(mcmc.multistate, round = 2)
-```
-
-
-```{r, echo = FALSE, fig.cap = ""Dirichlet prior with parameter alpha""}
-library(MCMCvis)
-load(here::here(""dat"",""titis.RData""))
-MCMCplot(mcmc.multistate)
-```
-
-## Multistate models are very flexible
-
-+ Access to reproduction
-
-+ Temporary emigration
-
-+ Combination of life and dead encounters
-
-### Access to reproduction
-
-Transition matrix:
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Gamma} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    z_t=J & z_t=1yNB & z_t=2yNB & z_t=B & z_t=D \\ \hdashline
-0 & \phi_1 (1-\alpha_1) & 0 & \phi_1 \alpha_1 & 1 - \phi_1\\ 
-0 & 0 & \phi_2 (1-\alpha_2) & \phi_2 \alpha_2 & 1 - \phi_2\\ 
-0 & 0 & 0 & \phi_3 & 1 - \phi_3\\ 
-0 & 0 & 0 & \phi_B & 1 - \phi_B\\ 
-0 & 0 & 0 & 0 & 1
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    z_{t-1} = J \\ z_{t-1} = 1yNB \\ z_{t-1} = 2yNB \\ z_{t-1} = B \\ z_{t-1} = D
-    \end{matrix}
-\end{matrix}
-$$
-
-+ First-year and second-year individuals breed with probabilities $\alpha_1$ and $\alpha_2$.
-
-+ Then, everybody breeds from age 3.
-
-### Access to reproduction
-
-Observation matrix:
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Omega} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-y_t = 0 & y_t = 1 & y_t = 2 & y_t = 3\\ \hdashline
-1 & 0 & 0 & 0\\
-1 - p_1 & p_1 & 0 & 0\\ 
-1 - p_2 & 0 & p_2 & 0\\ 
-1 - p_3 & 0 & 0 & p_3\\ 
-1 & 0 & 0 & 0
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\12 \end{matrix} } \right )
-    \begin{matrix}
-    z_t = J \\ z_t = 1yNB \\ z_t = 2yNB \\ z_t = B \\ z_t = D
-    \end{matrix}
-\end{matrix}
-$$
-
-+ Juveniles are never detected. 
-
-## Temporary emigration
-
-Transition matrix:
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Gamma} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    z_t=\text{in} & z_t=\text{out} & z_t=\text{D} \\ \hdashline
-\phi (1-\psi_{\text{in} \rightarrow \text{out}}) & \phi \psi_{\text{in} \rightarrow \text{out}} & 1 - \phi\\ 
-\phi \psi_{\text{out} \rightarrow \text{in}} & \phi (1-\psi_{\text{out} \rightarrow \text{in}}) & 1 - \phi\\ 
-0 & 0 & 1
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    z_{t-1}=\text{in} \\ z_{t-1}=\text{out} \\ z_{t-1}=\text{D}
-    \end{matrix}
-\end{matrix}
-$$
-
-Observation matrix:
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Omega} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    y_t=0 & y_t=1 \\ \hdashline
-1 - p & p\\ 
-1 & 0\\
-1 & 0
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    z_{t}=\text{in} \\ z_{t}=\text{out} \\ z_{t}=\text{D}
-    \end{matrix}
-\end{matrix}
-$$
-
-### Combination of life and dead encounters
-
-Transition matrix
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Gamma} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    z_t=A & z_t=JD & z_t=D \\ \hdashline
-s & 1-s & 0\\ 
-0 & 0 & 1\\
-0 & 0 & 1
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    z_{t-1}=\text{alive} \\ z_{t-1}=\text{just dead} \\ z_{t-1}=\text{dead for good}
-    \end{matrix}
-\end{matrix}
-$$
-
-Observation matrix
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Omega} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    y_t=0 & y_t=1 & y_t=2 \\ \hdashline
-1 - p & 0 & p\\ 
-1 - r & r & 0\\ 
-1 & 0 & 0
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    z_{t}=A \\ z_{t}=JD \\ z_{t}=D
-    \end{matrix}
-\end{matrix}
-$$
-
-## Issue of local minima
-
-+ Simulated data
-    + 2 sites or states, and 7 occasions
-    + Survival $\phi = 1$, detection $p = 0.6$
-    + Transition $\psi_{12} = 0.6$
-    + Transition $\psi_{21} = 0.85$
-
-+ Courtesy of J√©r√¥me Dupuis, used in [Gimenez et al. (2005)](https://oliviergimenez.github.io/pubs/Gimenezetal2005JABES.pdf).
-
-### Data
-
-```{r echo = FALSE}
-dat <- matrix(c(2, 0, 2, 1, 2, 0, 2, 
-                2, 0, 2, 1, 2, 0, 2,
-                2, 0, 2, 1, 2, 0, 2,
-                2, 0, 2, 1, 2, 0, 2,
-                1, 1, 1, 0, 1, 0, 1,
-                1, 1, 1, 0, 1, 0, 1,
-                1, 1, 1, 0, 1, 0, 1,
-                1, 1, 1, 0, 1, 0, 1,
-                2, 0, 2, 0, 2, 0, 1,
-                2, 0, 2, 0, 2, 0, 1,
-                2, 0, 2, 0, 2, 0, 1,
-                2, 0, 2, 0, 2, 0, 1,
-                1, 0, 1, 0, 1, 0, 1,
-                1, 0, 1, 0, 1, 0, 1,
-                1, 0, 1, 0, 1, 0, 1,
-                1, 0, 1, 0, 1, 0, 1,
-                2, 0, 2, 0, 2, 0, 2,
-                2, 0, 2, 0, 2, 0, 2,
-                2, 0, 2, 0, 2, 0, 2,
-                2, 0, 2, 0, 2, 0, 2,
-                1, 0, 1, 0, 1, 0, 2,
-                1, 0, 1, 0, 1, 0, 2,
-                1, 0, 1, 0, 1, 0, 2,
-                1, 0, 1, 0, 1, 0, 2,
-                2, 2, 0, 1, 0, 2, 1,
-                2, 2, 0, 1, 0, 2, 1,
-                2, 2, 0, 1, 0, 2, 1,
-                2, 2, 0, 1, 0, 2, 1,
-                2, 1, 0, 2, 0, 1, 1,
-                2, 1, 0, 2, 0, 1, 1,
-                2, 1, 0, 2, 0, 1, 1,
-                2, 1, 0, 2, 0, 1, 1),
-              byrow = T,
-              ncol = 7)
-dat %>%  
-  as_tibble() %>%
-  kableExtra::kable() %>%
-  kableExtra::scroll_box(width = ""100%"", height = ""400px"")
-```
-
-```{r}
-knitr::include_graphics(""images/multistate_local_minimav2_Page_05.png"")
-```
-
-
-```{r}
-knitr::include_graphics(""images/multistate_local_minimav2_Page_06.png"")
-```
-
-```{r}
-knitr::include_graphics(""images/multistate_local_minimav2_Page_07.png"")
-```
-
-
-```{r, echo = FALSE}
-load(here::here(""dat"",""localminima.RData""))
-psiBA <- c(mcmc.multistate$chain1[,""psiBA""], mcmc.multistate$chain2[,""psiBA""])
-plotpsiBA <- psiBA %>%
-  as_tibble() %>%
-  ggplot() + 
-  aes(x = 1:length(value), y = value) + 
-  geom_line(color = ""gray70"") +
-  labs(y = ""psi21"", x = ""iterations"") +
-  theme_light(base_size = 14) +
-  geom_hline(yintercept = 0.85, lty = 2, color = ""blue"")
-
-psiAB <- c(mcmc.multistate$chain1[,""psiAB""],mcmc.multistate$chain2[,""psiAB""])
-plotpsiAB <- psiAB %>%
-  as_tibble() %>%
-  ggplot() + 
-  aes(x = 1:length(value), y = value) + 
-  geom_line(color = ""gray70"") +
-  labs(y = ""psi12"", x = ""iterations"") +
-  theme_light(base_size = 14) +
-  geom_hline(yintercept = 0.6, lty = 2, color = ""blue"")
-
-det <- c(mcmc.multistate$chain1[,""p""], mcmc.multistate$chain2[,""p""])
-plotdet <- det %>%
-  as_tibble() %>%
-  ggplot() + 
-  aes(x = 1:length(value), y = value) + 
-  geom_line(color = ""gray70"") +
-  labs(y = ""detection"", x = ""iterations"") +
-  theme_light(base_size = 14) +
-  geom_hline(yintercept = 0.6, lty = 2, color = ""blue"")
-
-
-library(patchwork)
-
-plotdet / (plotpsiAB + plotpsiBA)
-```
-
-
-```{r, echo = FALSE}
-load(here::here(""dat"",""localminima.RData""))
-psiBA <- c(mcmc.multistate$chain1[,""psiBA""], mcmc.multistate$chain2[,""psiBA""])
-plotpsiBA <- psiBA %>%
-  as_tibble() %>%
-  ggplot() + 
-  aes(x = value) + 
-  geom_histogram(color = ""white"", binwidth = .03, fill = ""gray70"") + 
-  geom_density(aes(y = .03 * ..count..)) +
-  labs(x = ""psi21"", y = """") +
-  theme_light(base_size = 14) +
-  geom_vline(xintercept = 0.85, lty = 2, color = ""blue"")
-
-psiAB <- c(mcmc.multistate$chain1[,""psiAB""],mcmc.multistate$chain2[,""psiAB""])
-plotpsiAB <- psiAB %>%
-  as_tibble() %>%
-  ggplot() + 
-  aes(x = value) + 
-  geom_histogram(color = ""white"", binwidth = .03, fill = ""gray70"") + 
-  geom_density(aes(y = .03 * ..count..)) +
-  labs(x = ""psi12"", y = """") +
-  theme_light(base_size = 14) + 
-  geom_vline(xintercept = 0.6, lty = 2, color = ""blue"")
-
-
-det <- c(mcmc.multistate$chain1[,""p""], mcmc.multistate$chain2[,""p""])
-plotdet <- det %>%
-  as_tibble() %>%
-  ggplot() + 
-  aes(x = value) + 
-  geom_histogram(color = ""white"", binwidth = .03, fill = ""gray70"") + 
-  geom_density(aes(y = .03 * ..count..)) + 
-  labs(x = ""detection"", y = """") +
-  theme_light(base_size = 14) + 
-  geom_vline(xintercept = 0.6, lty = 2, color = ""blue"")
-
-
-library(patchwork)
-
-plotdet / (plotpsiAB + plotpsiBA)
-```
-
-
-## Further reading
-
-+ Lebreton, J.-D., J. D. Nichols, R. J. Barker, R. Pradel and J. A. Spendelow (2009). [Modeling Individual Animal Histories with Multistate Capture‚ÄìRecapture Models](https://multievent.sciencesconf.org/conference/multievent/pages/Lebretonetal2009AER.pdf). Advances in Ecological Research, 41:87-173.
-

---FILE: 06-covariates.Rmd---
@@ -1,2 +0,0 @@
-# Covariates {#covariates}
-

---FILE: 07-uncertainty.Rmd---
@@ -1,1271 +0,0 @@
-# Uncertainty in state assignment {#uncertainty}
-
-
-Multievent models extend multistate models with uncertainty in state assignment
-
-+ In this module, we're going to talk about multievent models.
-+ Multievent models extend multistate models with uncertainty in state assignment.
-+ Let's see some examples to fix ideas. 
-+ These examples are from published papers which used multievent models. 
-
-
-+ Breeding status in female roe deer is ascertained based on fawn detection
-
-+ Sex status is ascertained based on morphological criteria in Audouin's gulls
-
-+ Disease status in house finches is ascertained based on birds' eyes examination
-
-+ Hybrid status in wolves is ascertained based on genetics
-
-+ Dominance status in wolves is ascertained based on heterogeneity in detection
-
-We need to explicitly consider state assignment in a model
-
-+ The common thing to all these examples is that.
-+ We need to explicitly consider state assignment in a model.
-
-HMMs to the rescue!
-
-+ And to do that, we'll use HMMs again! 
-
-## Examples
-
-+ Testing life-history trade-offs while accounting for uncertainty in breeding status
-
-+ Quantifying disease dynamics while accounting for uncertainty in disease status
-
-+ Estimating survival while accounting for individual heterogeneity in detection
-
-+ In this module, I'll go through 3 examples. 
-+ Testing life-history trade-offs while accounting for uncertainty in breeding status.
-+ Quantifying disease dynamics while accounting for uncertainty in disease status.
-+ Estimating survival while accounting for individual heterogeneity in detection.
-
-## Examples
-
-+ **Testing life-history trade-offs while accounting for uncertainty in breeding status**
-
-+ Quantifying disease dynamics while accounting for uncertainty in disease status
-
-+ Estimating survival while accounting for individual heterogeneity in detection
-
-
-```{r}
-knitr::include_graphics(""images/sooty.jpg"")
-```
-
-### Sooty shearwater (David Boyle)
-
-## Uncertainty in breeding status
-
-+ 3 states
-    + breeding (B)
-    + non-breeding (NB)
-    + dead (D)
-
-+ 4 observations
-    + not encountered (0)
-    + found, ascertained as breeder (1)
-    + found, ascertained as non-breeder (2)
-    + found, status unknown (3)
-
-+ We still have 3 states, breeding, non-breeding and dead.
-+ With regard to observations, a bird may be not encountered.
-+ It may also be encountered, but in contrast with multistate CR data, we don't know its state for sure. 
-+ It may be found and ascertained or classified as breeder. 
-+ It may be found and ascertained or classified as non-breeder. 
-+ It may be found be we are unable to determine whether it's breeding or non-breeding.  
-
-### How states generate observations
-
-```{r, echo = FALSE}
-ggplot() + 
-  geom_point(aes(1, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(1.5, 2, label = 'not encountered (0)'), nudge_x = 1, size = 7) + 
-  geom_text(aes(1.5, 1.5, label = 'found, ascertained as breeder (1)'), nudge_x = 1.5, size = 7) + 
-  geom_text(aes(1.5, 1, label = 'found, ascertained as non-breeder (2)'), nudge_x = 1.7, size = 7) +
-  geom_text(aes(1.5, 0.5, label = 'found, status unknown (3)'), nudge_x = 1.2, size = 7) +
-  geom_point(aes(1.5, 0.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1.5, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(1.5, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1.5, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(.5, 2, label = 'breeding'), nudge_x = 0, size = 7) + 
-  geom_text(aes(.5, 1.5, label = 'non-breeding'), nudge_x = -0.2, size = 7) + 
-  geom_text(aes(.5, 1, label = 'dead'), nudge_x = 0.1, size = 7) + 
-  xlim(0, 4.5) + 
-  ylim(0.5, 3) + 
-  annotate('text', x = .5, y = 2.6, label = 'States', size = 10) + 
-  annotate('text', x = 2.5, y = 2.6, label = 'Observations', size = 10) + 
-  theme_void()
-```
-
-+ Now how do the states generate the observations?
-
-### How states generate observations
-
-```{r, echo = FALSE}
-ggplot() + 
-  geom_point(aes(1, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(1.5, 2, label = 'not encountered (0)'), nudge_x = 1, size = 7) + 
-  geom_text(aes(1.5, 1.5, label = 'found, ascertained as breeder (1)'), nudge_x = 1.5, size = 7) + 
-  geom_text(aes(1.5, 1, label = 'found, ascertained as non-breeder (2)'), nudge_x = 1.7, size = 7) +
-  geom_text(aes(1.5, 0.5, label = 'found, status unknown (3)'), nudge_x = 1.2, size = 7) +
-  geom_point(aes(1.5, 0.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1.5, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(1.5, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1.5, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(.5, 2, label = 'breeding'), nudge_x = 0, size = 7) + 
-  geom_text(aes(.5, 1.5, label = 'non-breeding'), nudge_x = -0.2, size = 7) + 
-  geom_text(aes(.5, 1, label = 'dead'), nudge_x = 0.1, size = 7) + 
-  xlim(0, 4.5) + 
-  ylim(0.5, 3) + 
-  annotate('text', x = .5, y = 2.6, label = 'States', size = 10) + 
-  annotate('text', x = 2.5, y = 2.6, label = 'Observations', size = 10) + 
-  geom_segment(aes(x = 1, y = 1, xend = 1.5, yend = 2), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  theme_void()
-```
-
-### How states generate observations
-
-```{r, echo = FALSE}
-ggplot() + 
-  geom_point(aes(1, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(1.5, 2, label = 'not encountered (0)'), nudge_x = 1, size = 7) + 
-  geom_text(aes(1.5, 1.5, label = 'found, ascertained as breeder (1)'), nudge_x = 1.5, size = 7) + 
-  geom_text(aes(1.5, 1, label = 'found, ascertained as non-breeder (2)'), nudge_x = 1.7, size = 7) +
-  geom_text(aes(1.5, 0.5, label = 'found, status unknown (3)'), nudge_x = 1.2, size = 7) +
-  geom_point(aes(1.5, 0.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1.5, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(1.5, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1.5, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(.5, 2, label = 'breeding'), nudge_x = 0, size = 7) + 
-  geom_text(aes(.5, 1.5, label = 'non-breeding'), nudge_x = -0.2, size = 7) + 
-  geom_text(aes(.5, 1, label = 'dead'), nudge_x = 0.1, size = 7) + 
-  xlim(0, 4.5) + 
-  ylim(0.5, 3) + 
-  annotate('text', x = .5, y = 2.6, label = 'States', size = 10) + 
-  annotate('text', x = 2.5, y = 2.6, label = 'Observations', size = 10) + 
-  geom_segment(aes(x = 1, y = 2, xend = 1.5, yend = .5), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 2, xend = 1.5, yend = 1.5), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 2, xend = 1.5, yend = 2), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-
-  theme_void()
-```
-
-### How states generate observations
-
-```{r, echo = FALSE}
-ggplot() + 
-  geom_point(aes(1, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(1.5, 2, label = 'not encountered (0)'), nudge_x = 1, size = 7) + 
-  geom_text(aes(1.5, 1.5, label = 'found, ascertained as breeder (1)'), nudge_x = 1.5, size = 7) + 
-  geom_text(aes(1.5, 1, label = 'found, ascertained as non-breeder (2)'), nudge_x = 1.7, size = 7) +
-  geom_text(aes(1.5, 0.5, label = 'found, status unknown (3)'), nudge_x = 1.2, size = 7) +
-  geom_point(aes(1.5, 0.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1.5, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(1.5, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1.5, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(.5, 2, label = 'breeding'), nudge_x = 0, size = 7) + 
-  geom_text(aes(.5, 1.5, label = 'non-breeding'), nudge_x = -0.2, size = 7) + 
-  geom_text(aes(.5, 1, label = 'dead'), nudge_x = 0.1, size = 7) + 
-  xlim(0, 4.5) + 
-  ylim(0.5, 3) + 
-  annotate('text', x = .5, y = 2.6, label = 'States', size = 10) + 
-  annotate('text', x = 2.5, y = 2.6, label = 'Observations', size = 10) + 
-  geom_segment(aes(x = 1, y = 1.5, xend = 1.5, yend = 1), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 1.5, xend = 1.5, yend = 2), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 1.5, xend = 1.5, yend = .5), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  theme_void()
-```
-
-### How states generate observations
-
-```{r, echo = FALSE}
-ggplot() + 
-  geom_point(aes(1, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(1.5, 2, label = 'not encountered (0)'), nudge_x = 1, size = 7) + 
-  geom_text(aes(1.5, 1.5, label = 'found, ascertained as breeder (1)'), nudge_x = 1.5, size = 7) + 
-  geom_text(aes(1.5, 1, label = 'found, ascertained as non-breeder (2)'), nudge_x = 1.7, size = 7) +
-  geom_text(aes(1.5, 0.5, label = 'found, status unknown (3)'), nudge_x = 1.2, size = 7) +
-  geom_point(aes(1.5, 0.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1.5, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(1.5, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1.5, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(.5, 2, label = 'breeding'), nudge_x = 0, size = 7) + 
-  geom_text(aes(.5, 1.5, label = 'non-breeding'), nudge_x = -0.2, size = 7) + 
-  geom_text(aes(.5, 1, label = 'dead'), nudge_x = 0.1, size = 7) + 
-  xlim(0, 4.5) + 
-  ylim(0.5, 3) + 
-  annotate('text', x = .5, y = 2.6, label = 'States', size = 10) + 
-  annotate('text', x = 2.5, y = 2.6, label = 'Observations', size = 10) + 
-  
-  geom_segment(aes(x = 1, y = 1, xend = 1.5, yend = 2), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  
-  geom_segment(aes(x = 1, y = 1.5, xend = 1.5, yend = 1), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 1.5, xend = 1.5, yend = 2), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 1.5, xend = 1.5, yend = .5), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  
-  geom_segment(aes(x = 1, y = 2, xend = 1.5, yend = .5), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 2, xend = 1.5, yend = 1.5), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 2, xend = 1.5, yend = 2), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-
-  theme_void()
-```
-
-+ To wrap up each live state can generate 3 observations. 
-+ The only deterministic link is that between the dead state and the observation non-encountered.
-+ Cause if you're dead, you cannot be detected for sure. 
-
-### HMM model for breeding states with uncertainty
-
-Vector of initial state probabilities
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\delta} = 
-    \left ( \vphantom{ \begin{matrix} 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    z_t=B & z_t=NB & z_t=D \\ \hdashline
-\pi_B & 1 - \pi_{B} & 0\\ 
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \end{matrix} } \right )
-    \begin{matrix}
-    \end{matrix}
-\end{matrix}
-$$
-+ $\pi_B$ is the probability that a newly encountered individual is a breeder
-
-+ $\pi_{NB} = 1 - \pi_B$ is the probability that a newly encountered individual is a non-breeder
-
-
-+ OK now let‚Äôs specify the model. 
-+ First thing we need, and it‚Äôs a big difference with multistate models, we need initial state probabilities cause we cannot assign states to individuals w/ certainty. 
-+ Let's define pi_B the prob that a newly encountered individual is a breeding individual.
-+ We write down the prob for each state at first encounter. We have pi_B, then the prob of being a NB is the complementary. And the prob of being dead at first encounter is 0 of course. 
-
-
-### HMM model for breeding states with uncertainty
-
-Transition matrix
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Gamma} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    z_t=B & z_t=NB & z_t=D \\ \hdashline
-\phi_B (1-\psi_{BNB}) & \phi_B \psi_{BNB} & 1 - \phi_B\\ 
-\phi_{NB} \psi_{NBB} & \phi_{NB} (1-\psi_{NBB}) & 1 - \phi_{NB}\\ 
-0 & 0 & 1
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    z_{t-1}=B \\ z_{t-1}=NB \\ z_{t-1}=D
-    \end{matrix}
-\end{matrix}
-$$
-
-+ $\phi_B$ is breeder survival, $\phi_{NB}$ that of non-breeders.
-
-+ $\psi_{BNB}$ is the probability for an individual breeding a year to be a non-breeder the next year.
-
-+ $\psi_{NBB}$ is the probability for an non-breeder individual to breeder the next year.
-
-+ The transition parameters are in a matrix similar to the one we used for multistate models.  
-
-### HMM model for breeding states with uncertainty
-
-Observation matrix
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Omega} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    y_t=0 & y_t=1 & y_t=2 & y_t=3\\ \hdashline
-1 - p_B & p_B \beta_B & 0 & p_B (1-\beta_B) \\ 
-1-p_{NB} & 0 & p_{NB} \beta_{NB} & p_{NB} (1-\beta_{NB})\\ 
-1 & 0 & 0 & 0
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right )
-    \begin{matrix}
-    z_{t}=B \\ z_{t}=NB \\ z_{t}=D
-    \end{matrix}
-\end{matrix}
-$$
-
-+ $\beta_B$ is the probability to assign an individual in state B to state B.
-
-+ $\beta_{NB}$ is the probability to assign an individual in state NB to state NB.
-
-+ $p_B$ is the detection probability of breeders, $p_{NB}$ that of non-breeders.
-
-+ The main difference between multistate and multievent models is here, in the observation parameters. 
-+ We introduce two new parameters. 
-+ deltaB: prob. to correctly assign an indiv. that is in state B to state B
-+ deltaNB: prob. to correctly assign an indiv. that is in state NB to state NB
-
-+ We put everything in a matrix, as usual. The observation matrix. 
-
-+ In rows we have the states, breeding, non-breeding and dead. 
-+ In columns, at the same occasion, we have the observation, detected and ascertained B, 
-detected and ascertained NB, detected and state unknown, and not detected. 
-+ For example, the prob of being detected and assigned to the state B, given that you‚Äôre in state B is the product of the detection prob in B and delta the prob of correctly assigning a B individual to state B. 
-
-### HMM model for breeding states with uncertainty
-
-Because animals are all captured, $p_B = p_{NB} = 1$ at first encounter:
-
-$$
-\begin{matrix}
-& \\
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    y_t=0 & y_t=1 & y_t=2 & y_t=3\\ \hdashline
- 0 & \beta_B & 0 & (1-\beta_B)\\ 
-0 & 0 & \beta_{NB} & (1-\beta_{NB})\\ 
-1 & 0 & 0 & 0
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right )
-    \begin{matrix}
-    z_{t}=B \\ z_{t}=NB \\ z_{t}=D
-    \end{matrix}
-\end{matrix}
-$$
-
-Note: Breeding assessment is unaffected.
-
-+ Then at first encounter, what happens is that step 1 of encounter is degenerate because individuals are all captured. Just set all the p‚Äôs to 1 in the encounter matrix. 
-
-+ The breeding assessment matrix remains unchanged. 
-
-### Our model $(\phi_B, \phi_{NB}, \psi_{BNB}, \psi_{NBB}, p_B, p_{NB}, \beta_B, \beta_{NB}, \pi)$
-
-```{r eval = FALSE}
-multievent <- nimbleCode({
-  # -------------------------------------------------
-  # Parameters:
-  # phiB: survival probability state B
-  # phiNB: survival probability state NB
-  # psiBNB: transition probability from B to NB
-  # psiNBB: transition probability from NB to B
-  # pB: recapture probability B
-  # pNB: recapture probability NB
-  # piB prob. of being in initial state breeder
-  # betaNB prob to ascertain the breeding status of an individual encountered as non-breeder
-  # betaB prob to ascertain the breeding status of an individual encountered as breeder
-  # -------------------------------------------------
-  # States (z):
-  # 1 alive B
-  # 2 alive NB
-  # 3 dead
-  # Observations (y):  
-  # 1 = non-detected
-  # 2 = seen and ascertained as breeder
-  # 3 = seen and ascertained as non-breeder
-  # 4 = not ascertained
-  # -------------------------------------------------
-...
-```
-
-### Our model $(\phi_B, \phi_{NB}, \psi_{BNB}, \psi_{NBB}, p_B, p_{NB}, \beta_B, \beta_{NB}, \pi)$
-
-```{r eval = FALSE}
-multievent <- nimbleCode({
-...
-  # Priors
-  phiB ~ dunif(0, 1)
-  phiNB ~ dunif(0, 1)
-  psiBNB ~ dunif(0, 1)
-  psiNBB ~ dunif(0, 1)
-  pB ~ dunif(0, 1)
-  pNB ~ dunif(0, 1)
-  piB ~ dunif(0, 1)
-  betaNB ~ dunif(0, 1)
-  betaB ~ dunif(0, 1)
-...
-```
-]
-
-### Our model $(\phi_B, \phi_{NB}, \psi_{BNB}, \psi_{NBB}, p_B, p_{NB}, \beta_B, \beta_{NB}, \pi)$
-
-```{r eval = FALSE}
-multievent <- nimbleCode({
-...  
-  # vector of initial stats probs
-  delta[1] <- piB # prob. of being in initial state B
-  delta[2] <- 1 - piB # prob. of being in initial state NB
-  delta[3] <- 0 # prob. of being in initial state dead
-...  
-```
-
-### Our model $(\phi_B, \phi_{NB}, \psi_{BNB}, \psi_{NBB}, p_B, p_{NB}, \beta_B, \beta_{NB}, \pi)$
-
-```{r eval = FALSE}
-multievent <- nimbleCode({
-...  
-  # probabilities of state z(t+1) given z(t)
-  gamma[1,1] <- phiB * (1 - psiBNB)
-  gamma[1,2] <- phiB * psiBNB
-  gamma[1,3] <- 1 - phiB
-  gamma[2,1] <- phiNB * psiNBB
-  gamma[2,2] <- phiNB * (1 - psiNBB)
-  gamma[2,3] <- 1 - phiNB
-  gamma[3,1] <- 0
-  gamma[3,2] <- 0
-  gamma[3,3] <- 1
-...
-```
-
-### Our model $(\phi_B, \phi_{NB}, \psi_{BNB}, \psi_{NBB}, p_B, p_{NB}, \beta_B, \beta_{NB}, \pi)$
-
-```{r eval = FALSE}
-multievent <- nimbleCode({
-...  
-  # probabilities of y(t) given z(t)
-  omega[1,1] <- 1 - pB             # Pr(alive B t -> non-detected t)
-  omega[1,2] <- pB * betaB         # Pr(alive B t -> detected B t)
-  omega[1,3] <- 0                  # Pr(alive B t -> detected NB t)
-  omega[1,4] <- pB * (1 - betaB)   # Pr(alive B t -> detected U t)
-  omega[2,1] <- 1 - pNB            # Pr(alive NB t -> non-detected t)
-  omega[2,2] <- 0                  # Pr(alive NB t -> detected B t)
-  omega[2,3] <- pNB * betaNB       # Pr(alive NB t -> detected NB t)
-  omega[2,4] <- pNB * (1 - betaNB) # Pr(alive NB t -> detected U t)
-  omega[3,1] <- 1                  # Pr(dead t -> non-detected t)
-  omega[3,2] <- 0                  # Pr(dead t -> detected N t)
-  omega[3,3] <- 0                  # Pr(dead t -> detected NB t)
-  omega[3,4] <- 0                  # Pr(dead t -> detected U t)
-...
-```
-
-### Our model $(\phi_B, \phi_{NB}, \psi_{BNB}, \psi_{NBB}, p_B, p_{NB}, \beta_B, \beta_{NB}, \pi)$
-
-```{r eval = FALSE}
-multievent <- nimbleCode({
-...  
-  # probabilities of y(first) given z(first)
-  omega.init[1,1] <- 0          # Pr(alive B t = 1 -> non-detected t = 1)
-  omega.init[1,2] <- betaB      # Pr(alive B t = 1 -> detected B t = 1)
-  omega.init[1,3] <- 0          # Pr(alive B t = 1 -> detected NB t = 1)
-  omega.init[1,4] <- 1 - betaB  # Pr(alive B t = 1 -> detected U t = 1)
-  omega.init[2,1] <- 0          # Pr(alive NB t = 1 -> non-detected t = 1)
-  omega.init[2,2] <- 0          # Pr(alive NB t = 1 -> detected B t = 1)
-  omega.init[2,3] <- betaNB     # Pr(alive NB t = 1 -> detected NB t = 1)
-  omega.init[2,4] <- 1 - betaNB # Pr(alive NB t = 1 -> detected U t = 1)
-  omega.init[3,1] <- 1          # Pr(dead t = 1 -> non-detected t = 1)
-  omega.init[3,2] <- 0          # Pr(dead t = 1 -> detected N t = 1)
-  omega.init[3,3] <- 0          # Pr(dead t = 1 -> detected NB t = 1)
-  omega.init[3,4] <- 0          # Pr(dead t = 1 -> detected U t = 1)
-...
-```
-
-### Our model $(\phi_B, \phi_{NB}, \psi_{BNB}, \psi_{NBB}, p_B, p_{NB}, \beta_B, \beta_{NB}, \pi)$
-
-```{r eval = FALSE}
-multievent <- nimbleCode({
-...
-  # likelihood 
-  for (i in 1:N){
-    # latent state at first capture
-    z[i,first[i]] ~ dcat(delta[1:3])
-    y[i,first[i]] ~ dcat(omega.init[z[i,first[i]],1:4])
-    for (t in (first[i]+1):K){
-      # z(t) given z(t-1)
-      z[i,t] ~ dcat(gamma[z[i,t-1],1:3])
-      # y(t) given z(t)
-      y[i,t] ~ dcat(omega[z[i,t],1:4])
-    }
-  }
-})
-```
-
-## Results
-
-```{r echo = FALSE}
-library(MCMCvis)
-load(here::here(""dat"",""titisuncertain.RData""))
-MCMCsummary(mcmc.multievent, round = 2)
-```
-
-+ Breeders are difficult to assigned to the correct state.
-+ Non-breeders are relatively well classified as non-breeders. 
-+ No cost of breeding, neither on survival, nor on future reproduction.
-
-
-```{r, echo = FALSE}
-library(MCMCvis)
-load(here::here(""dat"",""titisuncertain.RData""))
-MCMCplot(mcmc.multievent)
-```
-
-
-## Examples
-
-+ Testing life-history trade-offs while accounting for uncertainty in breeding status
-
-+ **Quantifying disease dynamics while accounting for uncertainty in disease status**
-
-+ Estimating survival while accounting for individual heterogeneity in detection
-
-+ Let's have a look to another example. 
-+ Very similar to the previous example. 
-
-## Animal epidemiology with uncertain disease states
-
-+ We consider a system of an emerging pathogen *Mycoplasma gallisepticum* Edward and Kanarek and its host the house finch, *Carpodacus mexicanus* M√ºller. 
-
-```{r}
-knitr::include_graphics(""images/infectedhousefinch.jpg"")
-```
-
-### A house finch with a heavy infection (Jim Mondok).
-
-## Animal epidemiology with uncertain disease states
-
-+ We consider a system of an emerging pathogen *Mycoplasma gallisepticum* Edward and Kanarek and its host the house finch, *Carpodacus mexicanus* M√ºller. 
-
-+ [Faustino et al. (2004)](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/j.0021-8790.2004.00840.x) and [Conn & Cooch (2009)](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/j.1365-2664.2008.01597.x) studied impact of pathogen on host demographic rates.
-
-+ Problem is true disease state for some encountered individuals is ambiguous because seen at distance.
-
-+ In this context, how to study the dynamics of the disease?
-
-## States and observations
-
-+ 3 states
-    + healthy (H)
-    + ill (I)
-    + dead (D)
-    
-+ 4 observations
-    + not seen (0)
-    + captured healthy (1)
-    + captured ill (2)
-    + health status unknown, i.e. seen at distance (3)
-
-
-### How states generate observations.
-
-```{r, echo = FALSE}
-ggplot() + 
-  geom_point(aes(1, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(1.5, 2, label = 'not seen (0)'), nudge_x = 1.2, size = 7) + 
-  geom_text(aes(1.5, 1.5, label = 'captured healthy (1)'), nudge_x = 1.5, size = 7) + 
-  geom_text(aes(1.5, 1, label = 'captured ill (2)'), nudge_x = 1.3, size = 7) +
-  geom_text(aes(1.5, 0.5, label = 'status unknown (3)'), nudge_x = 1.5, size = 7) +
-  geom_point(aes(2, 0.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(.5, 2, label = 'healthy'), nudge_x = 0, size = 7) + 
-  geom_text(aes(.5, 1.5, label = 'ill'), nudge_x = 0.2, size = 7) + 
-  geom_text(aes(.5, 1, label = 'dead'), nudge_x = 0.1, size = 7) + 
-  xlim(0, 4.5) + 
-  ylim(0.5, 3) + 
-  annotate('text', x = .5, y = 2.6, label = 'States', size = 10) + 
-  annotate('text', x = 2.7, y = 2.6, label = 'Observations', size = 10) + 
-  
-  theme_void()
-```
-
-### How states generate observations.
-
-```{r, echo = FALSE}
-ggplot() + 
-  geom_point(aes(1, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(1.5, 2, label = 'not seen (0)'), nudge_x = 1.2, size = 7) + 
-  geom_text(aes(1.5, 1.5, label = 'captured healthy (1)'), nudge_x = 1.5, size = 7) + 
-  geom_text(aes(1.5, 1, label = 'captured ill (2)'), nudge_x = 1.3, size = 7) +
-  geom_text(aes(1.5, 0.5, label = 'status unknown (3)'), nudge_x = 1.5, size = 7) +
-  geom_point(aes(2, 0.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(.5, 2, label = 'healthy'), nudge_x = 0, size = 7) + 
-  geom_text(aes(.5, 1.5, label = 'ill'), nudge_x = 0.2, size = 7) + 
-  geom_text(aes(.5, 1, label = 'dead'), nudge_x = 0.1, size = 7) + 
-  xlim(0, 4.5) + 
-  ylim(0.5, 3) + 
-  annotate('text', x = .5, y = 2.6, label = 'States', size = 10) + 
-  annotate('text', x = 2.7, y = 2.6, label = 'Observations', size = 10) + 
-  
-  geom_segment(aes(x = 1, y = 1, xend = 2, yend = 2), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  
-  theme_void()
-```
-
-### How states generate observations.
-
-```{r, echo = FALSE}
-ggplot() + 
-  geom_point(aes(1, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(1.5, 2, label = 'not seen (0)'), nudge_x = 1.2, size = 7) + 
-  geom_text(aes(1.5, 1.5, label = 'captured healthy (1)'), nudge_x = 1.5, size = 7) + 
-  geom_text(aes(1.5, 1, label = 'captured ill (2)'), nudge_x = 1.3, size = 7) +
-  geom_text(aes(1.5, 0.5, label = 'status unknown (3)'), nudge_x = 1.5, size = 7) +
-  geom_point(aes(2, 0.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(.5, 2, label = 'healthy'), nudge_x = 0, size = 7) + 
-  geom_text(aes(.5, 1.5, label = 'ill'), nudge_x = 0.2, size = 7) + 
-  geom_text(aes(.5, 1, label = 'dead'), nudge_x = 0.1, size = 7) + 
-  xlim(0, 4.5) + 
-  ylim(0.5, 3) + 
-  annotate('text', x = .5, y = 2.6, label = 'States', size = 10) + 
-  annotate('text', x = 2.7, y = 2.6, label = 'Observations', size = 10) + 
-  
-
-  geom_segment(aes(x = 1, y = 1.5, xend = 2, yend = 1), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 1.5, xend = 2, yend = 2), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 1.5, xend = 2, yend = .5), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  
-  theme_void()
-```
-
-### How states generate observations.
-
-```{r, echo = FALSE}
-ggplot() + 
-  geom_point(aes(1, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(1.5, 2, label = 'not seen (0)'), nudge_x = 1.2, size = 7) + 
-  geom_text(aes(1.5, 1.5, label = 'captured healthy (1)'), nudge_x = 1.5, size = 7) + 
-  geom_text(aes(1.5, 1, label = 'captured ill (2)'), nudge_x = 1.3, size = 7) +
-  geom_text(aes(1.5, 0.5, label = 'status unknown (3)'), nudge_x = 1.5, size = 7) +
-  geom_point(aes(2, 0.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(.5, 2, label = 'healthy'), nudge_x = 0, size = 7) + 
-  geom_text(aes(.5, 1.5, label = 'ill'), nudge_x = 0.2, size = 7) + 
-  geom_text(aes(.5, 1, label = 'dead'), nudge_x = 0.1, size = 7) + 
-  xlim(0, 4.5) + 
-  ylim(0.5, 3) + 
-  annotate('text', x = .5, y = 2.6, label = 'States', size = 10) + 
-  annotate('text', x = 2.7, y = 2.6, label = 'Observations', size = 10) + 
-  
-
-  geom_segment(aes(x = 1, y = 2, xend = 2, yend = .5), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 2, xend = 2, yend = 1.5), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 2, xend = 2, yend = 2), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-
-  theme_void()
-```
-
-### How states generate observations.
-
-```{r, echo = FALSE}
-ggplot() + 
-  geom_point(aes(1, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(1, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(1.5, 2, label = 'not seen (0)'), nudge_x = 1.2, size = 7) + 
-  geom_text(aes(1.5, 1.5, label = 'captured healthy (1)'), nudge_x = 1.5, size = 7) + 
-  geom_text(aes(1.5, 1, label = 'captured ill (2)'), nudge_x = 1.3, size = 7) +
-  geom_text(aes(1.5, 0.5, label = 'status unknown (3)'), nudge_x = 1.5, size = 7) +
-  geom_point(aes(2, 0.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 1), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 1.5), size = 2.5, alpha = .7) + 
-  geom_point(aes(2, 2), size = 2.5, alpha = .7) + 
-  geom_text(aes(.5, 2, label = 'healthy'), nudge_x = 0, size = 7) + 
-  geom_text(aes(.5, 1.5, label = 'ill'), nudge_x = 0.2, size = 7) + 
-  geom_text(aes(.5, 1, label = 'dead'), nudge_x = 0.1, size = 7) + 
-  xlim(0, 4.5) + 
-  ylim(0.5, 3) + 
-  annotate('text', x = .5, y = 2.6, label = 'States', size = 10) + 
-  annotate('text', x = 2.7, y = 2.6, label = 'Observations', size = 10) + 
-  
-  geom_segment(aes(x = 1, y = 1, xend = 2, yend = 2), alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  
-  geom_segment(aes(x = 1, y = 1.5, xend = 2, yend = 1), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 1.5, xend = 2, yend = 2), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 1.5, xend = 2, yend = .5), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  
-  geom_segment(aes(x = 1, y = 2, xend = 2, yend = .5), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 2, xend = 2, yend = 1.5), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-  geom_segment(aes(x = 1, y = 2, xend = 2, yend = 2), lty = 2, alpha = 0.7, arrow = arrow(length = unit(0.02, ""npc""))) + 
-
-  theme_void()
-```
-
-### HMM model for disease states with uncertainty
-
-Vector of initial state probabilities
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\delta} = 
-    \left ( \vphantom{ \begin{matrix} 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    z_t=H & z_t=I & z_t=D \\ \hdashline
-\pi_H & 1 - \pi_{H} & 0\\ 
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \end{matrix} } \right )
-    \begin{matrix}
-    \end{matrix}
-\end{matrix}
-$$
-
-+ $\pi_H$ is the probability that a newly encountered individual is healthy.
-
-+ $\pi_{I} = 1 - \pi_H$ is the probability that a newly encountered individual is ill.
-
-### HMM model for disease states with uncertainty
-
-Transition matrix
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Gamma} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    z_t=H & z_t=I & z_t=D \\ \hdashline
-\phi_H (1-\psi_{HI}) & \phi_H \psi_{HI} & 1 - \phi_H\\ 
-\phi_{I} \psi_{IH} & \phi_{I} (1-\psi_{IH}) & 1 - \phi_{I}\\ 
-0 & 0 & 1
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    z_{t-1}=H \\ z_{t-1}=I \\ z_{t-1}=D
-    \end{matrix}
-\end{matrix}
-$$
-
-+ $\phi_H$ is the survival probability of healthy individuals, $\phi_I$ that of ill individuals.
-
-+ $\psi_{HI}$ is the probability of getting sick, $\psi_{IH}$ that of recovering from the disease.
-
-### HMM model for disease states with uncertainty
-
-Transition matrix, incurable disease
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Gamma} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    z_t=H & z_t=I & z_t=D \\ \hdashline
-\phi_H (1-\psi_{HI}) & \phi_H \psi_{HI} & 1 - \phi_H\\ 
-0 & \phi_{I}  & 1 - \phi_{I}\\ 
-0 & 0 & 1
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    z_{t-1}=H \\ z_{t-1}=I \\ z_{t-1}=D
-    \end{matrix}
-\end{matrix}
-$$
-
-+ No possibility of recovering from the disease, that is $\psi_{IH} = 0$. Once you get sick, you remain sick $\psi_{II} = 1 - \psi_{IH} = 1$.
-
-+ For analysing the house finch data, we allow recovering from the disease, and we will use transition matrix from previous slide. 
-
-### HMM model for disease states with uncertainty
-
-Observation matrix
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Omega} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    y_t=0 & y_t=1 & y_t=2 & y_t=3\\ \hdashline
-1-p_H & p_H \beta_H & 0 & p_H (1-\beta_H)\\ 
-1-p_I & 0 & p_{I} \beta_{I} & p_{I} (1-\beta_{I})\\ 
-1 & 0 & 0 & 0
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right )
-    \begin{matrix}
-    z_{t}=H \\ z_{t}=I \\ z_{t}=D
-    \end{matrix}
-\end{matrix}
-$$
-
-+ $\beta_H$ is the probability to assign a healthy individual to state H.
-
-+ $\beta_{I}$ is the probability to assign a sick individual to state I.
-
-+ $p_H$ is the detection probability of healthy individuals, $p_I$ that of sick individuals.
-
-### Results
-
-```{r echo = FALSE}
-library(MCMCvis)
-load(here::here(""dat"",""disease.RData""))
-MCMCsummary(out, round = 2)
-```
-
-+ Healthy individuals are correctly assigned, while infected individuals are difficult to ascertain. 
-+ Sounds like being infected has an effect on detection and survival. Run models without effects and compare with WAIC for formal testing. 
-+ Infection rate is 22%, recovery rate is 46%.
-
-```{r, echo = FALSE}
-library(MCMCvis)
-load(here::here(""dat"",""disease.RData""))
-MCMCplot(out)
-```
-
-## Examples
-
-+ Testing life-history trade-offs while accounting for uncertainty in breeding status
-
-+ Quantifying disease dynamics while accounting for uncertainty in disease status
-
-+ **Estimating survival while accounting for individual heterogeneity in detection**
-
-+ Our last example is about individual heterogeneity and how to account for it with HMMs. 
-
-## Individual heterogeneity with finite mixtures. 
-
-+ Gray wolf is a social species with hierarchy in packs which may reflect in species demography.
-
-+ As an example, we'll work with gray wolves. 
-
-```{r}
-knitr::include_graphics(""images/wolfdominance.jpg"")
-```
-
-## Individual heterogeneity with finite mixtures. 
-
-+ Gray wolf is a social species with hierarchy in packs which may reflect in demography.
-
-+ Shirley Pledger in a series of papers developed heterogeneity models in which individuals are assigned in two or more classes with class-specific survival/detection probabilities. 
-
-+ [Cubaynes et al. (2010)](https://conbio.onlinelibrary.wiley.com/doi/abs/10.1111/j.1523-1739.2009.01431.x) used HMMs to account for heterogeneity in the detection process due to social status, see also [Pradel et al. (2009)](https://link.springer.com/chapter/10.1007%2F978-0-387-78151-8_36).
-
-Dominant individuals tend to use path more often than others, and these paths are where we look for scats. 
-
-## Individual heterogeneity
-
-+ 3 states
-    + alive in class 1 (A1)
-    + alive in class 2 (A2)
-    + dead (D)
-    
-+ 4 observations
-    + not captured (0)
-    + captured (1)
-
-### HMM model for individual heterogeneity
-
-Vector of initial state probabilities
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\delta} = 
-    \left ( \vphantom{ \begin{matrix} 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    z_t=A1 & z_t=A2 & z_t=D \\ \hdashline
-\pi & 1 - \pi & 0\\ 
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \end{matrix} } \right )
-    \begin{matrix}
-    \end{matrix}
-\end{matrix}
-$$
-
-+ $\pi$ is the probability of being alive in class 1.
-
-+ $1 - \pi$ is the probability of being in class 2.
-
-
-### HMM model for individual heterogeneity
-
-Transition matrix
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Gamma} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    z_t=A1 & z_t=A2 & z_t=D \\ \hdashline
-\phi  & 0 & 1 - \phi\\ 
-0 & \phi & 1 - \phi\\ 
-0 & 0 & 1
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    z_{t-1}=A1 \\ z_{t-1}=A2 \\ z_{t-1}=D
-    \end{matrix}
-\end{matrix}
-$$
-
-+ $\phi$ is the survival probability, which could be made heterogeneous. 
-
-### HMM model for individual heterogeneity
-
-Transition matrix, with change in heterogeneity class
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Gamma} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    z_t=A1 & z_t=A2 & z_t=D \\ \hdashline
-\phi (1-\psi_{12}) & \phi \psi_{12} & 1 - \phi\\ 
-\phi \psi_{21} & \phi (1-\psi_{21}) & 1 - \phi\\ 
-0 & 0 & 1
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    z_{t-1}=A1 \\ z_{t-1}=A2 \\ z_{t-1}=D
-    \end{matrix}
-\end{matrix}
-$$
-
-+ $\psi_{12}$ is the probability for an individual to change class of heterogeneity, from 1 to 2. 
-
-+ $\psi_{21}$ is the probability for an individual to change class of heterogeneity, from 2 to 1. 
-
-### HMM model for individual heterogeneity
-
-Observation matrix
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Omega} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    y_t=0 & y_t=1\\ \hdashline
-1 - p_1 & p_1\\ 
-1 - p_2 & p_2\\ 
-1 & 0
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right )
-    \begin{matrix}
-    z_{t}=A1 \\ z_{t}=A2 \\ z_{t}=D
-    \end{matrix}
-\end{matrix}
-$$
-
-+ $p_1$ is detection for individuals in class 1, and $p_2$ that of individuals in class 2. 
-
-## Results
-
-```{r echo = FALSE}
-library(MCMCvis)
-load(here::here(""dat"",""wolf_het.RData""))
-MCMCsummary(mcmc.phipmix, round = 2)
-```
-
-+ We have lowly detectable individuals (class A1 with $p_1$) in proportion 62%.
-
-+ And highly (or so) detectable individuals (class A2 with $p_2$) in proportion 38%.
-
-+ Note that interpretation of classes is made a posteriori. 
-
-+ Survival is 81%. 
-
-```{r, echo = FALSE}
-library(MCMCvis)
-load(here::here(""dat"",""wolf_het.RData""))
-MCMCplot(mcmc.phipmix)
-```
-
-### HMM model for individual heterogeneity
-
-+ You may consider more classes, and select among models, see [Cubaynes et al. (2012)](https://oliviergimenez.github.io/pubs/Cubaynesetal2011MEE.pdf).
-
-+ You may also go for a non-parametric approach and let the data tell you how many classes you need. This is relatively easy to do in Nimble, see [Turek et al. (2021)](https://arxiv.org/abs/2007.10163). 
-
-+ More about individual heterogeneity in [Gimenez et al. (2018)](https://oliviergimenez.github.io/pubs/GimenezCamGaillard2017Oikos.pdf).
-
-
-## HMMs to analyse capture-recapture data
-
-With the same data, ask further questions, just consider different states.
-
-### How to make our models remember?
-
-+ So far, the dynamics of the states are first-order Makovian.
-
-+ The site where you will be depends only on the site where you are, and not on the sites you were previously. 
-
-+ How to relax this assumption, and go second-order Markovian?
-
-+ Memory models were initially proposed by [Hestbeck et al. (1991)](https://esajournals.onlinelibrary.wiley.com/doi/abs/10.2307/2937193) and [Brownie et al. (1993)](https://www.jstor.org/stable/2532259?origin=crossref&seq=1#metadata_info_tab_contents), then formulated as HMMs in [Rouan et al. (2009)](https://link.springer.com/article/10.1198/jabes.2009.06108). See also [Cole et al. (2014)](https://onlinelibrary.wiley.com/doi/10.1002/ece3.1037). 
-
-### Remember HMM model for dispersal between 2 sites
-
-Transition matrix
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Gamma} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    z_t=A & z_t=B & z_t=D \\ \hdashline
-\phi_A (1-\psi_{AB}) & \phi_A \psi_{AB} & 1 - \phi_A\\ 
-\phi_B \psi_{BA} & \phi_B (1-\psi_{BA}) & 1 - \phi_B\\ 
-0 & 0 & 1
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    z_{t-1}=A \\ z_{t-1}=B \\ z_{t-1}=D
-    \end{matrix}
-\end{matrix}
-$$
-
-Observation matrix
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Omega} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    y_t=0 & y_t=1 & y_t=2 \\ \hdashline
-1 - p_A & p_A & 0\\ 
-1 - p_B & 0 & p_B\\ 
-1 & 0 & 0
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
-    \begin{matrix}
-    z_{t}=A \\ z_{t}=B \\ z_{t}=D
-    \end{matrix}
-\end{matrix}
-$$
-
-## HMM formulation of the memory model
-
-+ To keep track of the sites previously visited, the trick is to consider states as being pairs of sites occupied
-
-+ States
-     + AA is for alive in site A at $t$ and alive in site A at $t-1$
-     + AB is for alive in site A at $t$ and alive in site B at $t-1$
-     + BA is for alive in site B at $t$ and alive in site A at $t-1$
-     + BB is for alive in site B at $t$ and alive in site B at $t-1$
-     + D is for dead
-
-+ Observations
-     + 0 not captured
-     + 1 captured at site A
-     + 2 captured at site B
-
-## HMM formulation of the memory model
-
-Vector of initial state probabilities
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\delta} = 
-    \left ( \vphantom{ \begin{matrix} 12 \end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    z_t=AA & z_t=AB & z_t=BA & z_t=BB &z_t=D \\ \hdashline
-\pi_{AA} & \pi_{AB} & \pi_{BA} & \pi_{BB} & 0\\ 
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \end{matrix} } \right )
-    \begin{matrix}
-    \end{matrix}
-\end{matrix}
-$$
-+ where $\pi_{BB} = 1 - (\pi_{AA} + \pi_{AB} + \pi_{BA})$,
-
-+ and $\pi_{ij}$ at site $j$ when first captured at $t$ and site $i$ at $t - 1$.
-
-## HMM formulation of the memory model
-
-Transition matrix
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Gamma} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12\end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    z_t=AA & z_t=AB & z_t=BA & z_t=BB & z_t=D \\ \hdashline
-\phi_{AAA} & \phi_{AAB} & 0 & 0 & 1 - \phi_{AAA} - \phi_{AAB}\\ 
-0 & 0 & \phi_{ABA} & \phi_{ABB} & 1 - \phi_{ABA} - \phi_{ABB}\\ 
-\phi_{BAA} & \phi_{BAB} & 0 & 0 & 1 - \phi_{BAA} - \phi_{BAB}\\ 
-0 & 0 & \phi_{BBA} & \phi_{BBB} & 1 - \phi_{BBA} - \phi_{BBB}\\ 
-0 & 0 & 0 & 0 & 1
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12\end{matrix} } \right )
-    \begin{matrix}
-    z_t=AA \\ z_t=AB \\ z_t=BA \\ z_t=BB \\ z_t=D
-    \end{matrix}
-\end{matrix}
-$$
-+ $\phi_{ijk}$ is probability to be in site $k$ at time $t + 1$ for an individual
-present in site $j$ at $t$ and in site $i$ at $t - 1$
-
-## HMM formulation of the memory model
-
-Transition matrix, alternate parameterization
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Gamma} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12\end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    z_t=AA & z_t=AB & z_t=BA & z_t=BB & z_t=D \\ \hdashline
-\phi \psi_{AAA} & \phi (1 - \psi_{AAA}) & 0 & 0 & 1 - \phi\\ 
-0 & 0 & \phi (1 - \psi_{ABB}) & \phi \psi_{ABB} & 1 - \phi\\ 
-\phi \psi_{BAA} & \phi (1 - \psi_{BAA}) & 0 & 0 & 1 - \phi\\ 
-0 & 0 & \phi (1-\psi_{BBB}) & \phi \psi_{BBB} & 1 - \phi\\ 
-0 & 0 & 0 & 0 & 1
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12\end{matrix} } \right )
-    \begin{matrix}
-    z_t=AA \\ z_t=AB \\ z_t=BA \\ z_t=BB \\ z_t=D
-    \end{matrix}
-\end{matrix}
-$$
-+ $\phi$ is the probability of surviving from one occasion to the next. 
-
-+ $\psi_{ijj}$ is the probability an animal stays at the same site $j$ given that it was at site $i$ on the previous occasion.
-
-## HMM formulation of the memory model
-
-Observation matrix
-
-$$
-\begin{matrix}
-& \\
-\mathbf{\Omega} = 
-    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12\end{matrix} } \right .
-\end{matrix}
-\hspace{-1.2em}
-\begin{matrix}
-    y_t=0 & y_t=1 & y_t=2 \\ \hdashline
-1 - p_A & p_A & 0\\ 
-1 - p_B & 0 & p_B\\ 
-1 - p_A & p_A & 0\\ 
-1 - p_B & 0 & p_B\\ 
-1 & 0 & 0
-\end{matrix}
-\hspace{-0.2em}
-\begin{matrix}
-& \\
-\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12\end{matrix} } \right )
-    \begin{matrix}
-    z_t=AA \\ z_t=AB \\ z_t=BA \\ z_t=BB \\ z_t=D
-    \end{matrix}
-\end{matrix}
-$$
-
-## Further reading
-
-+ Seminal paper by Pradel (2005) [Multievent: An Extension of Multistate Capture‚ÄìRecapture Models to Uncertain States](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1541-0420.2005.00318.x). Biometrics, 61: 442-447.
-
-+ Dupuis (1995) had a similar idea for the Arnason-Schwarz model: Dupuis, J. (1995) [Bayesian estimation of movement and survival probabilities from capture-recapture data](https://academic.oup.com/biomet/article-abstract/82/4/761/252161). Biometrika. Vol. 82, pp 761-772.
-
-+ See also for a review Gimenez et al. (2012) [Estimating demographic parameters using hidden process dynamic models](https://oliviergimenez.github.io/pubs/Gimenezetal2012TPB.pdf). Theoretical Population Biology 82: 307-316.
-

---FILE: 08-abundance.Rmd---
@@ -1,2 +0,0 @@
-# Abundance {#abundance}
-

---FILE: 09-semiMarkov.Rmd---
@@ -1,2 +0,0 @@
-# Hidden semi-Markov models {#hsmm}
-

---FILE: 10-states.Rmd---
@@ -1,2 +0,0 @@
-# Hidden states {#states}
-

---FILE: 11-speed.Rmd---
@@ -1,511 +0,0 @@
-# Speed up MCMC {#speed}
-
-
-## Our `nimble` workflow so far
-
-```{r}
-knitr::include_graphics(""images/nimble_workflow_sofar.png"")
-```
-
-## But `nimble` gives full access to the MCMC engine
-
-```{r}
-knitr::include_graphics(""images/nimble_workflow.png"")
-```
-
-## Steps to use NIMBLE at full capacity
-
-1. Build the model. It is an R object.
-2. Build the MCMC.
-3. Compile the model and MCMC.
-4. Run the MCMC.
-5. Extract the samples.
-
-- `nimbleMCMC` does all of this at once.
-
-## Back to CJS models with Dipper data. 
-
-### Define model
-
-```{r echo = FALSE}
-dipper <- read_csv(here::here(""dat"", ""dipper.csv""))
-y <- dipper %>%
-  select(year_1981:year_1987) %>%
-  as.matrix()
-first <- apply(y, 1, function(x) min(which(x !=0)))
-my.constants <- list(N = nrow(y), T = ncol(y), first = first)
-my.data <- list(y = y + 1)
-zinits <- y + 1 # non-detection -> alive
-zinits[zinits == 2] <- 1 # dead -> alive
-initial.values <- function() list(phi = runif(1,0,1),
-                                  p = runif(1,0,1),
-                                  z = zinits)
-parameters.to.save <- c(""phi"", ""p"")
-n.iter <- 2500
-n.burnin <- 1000
-n.chains <- 2
-```
-
-```{r, eval = TRUE, echo = TRUE}
-hmm.phip <- nimbleCode({
-  delta[1] <- 1              # Pr(alive t = 1) = 1
-  delta[2] <- 0              # Pr(dead t = 1) = 0
-    phi ~ dunif(0, 1)     # prior survival
-    gamma[1,1] <- phi        # Pr(alive t -> alive t+1)
-    gamma[1,2] <- 1 - phi    # Pr(alive t -> dead t+1)
-    gamma[2,1] <- 0          # Pr(dead t -> alive t+1)
-    gamma[2,2] <- 1          # Pr(dead t -> dead t+1)
-    p ~ dunif(0, 1)       # prior detection
-    omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)
-    omega[1,2] <- p        # Pr(alive t -> detected t)
-    omega[2,1] <- 1        # Pr(dead t -> non-detected t)
-    omega[2,2] <- 0        # Pr(dead t -> detected t)
-  # likelihood
-  for (i in 1:N){
-    z[i,first[i]] ~ dcat(delta[1:2])
-    for (j in (first[i]+1):T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])
-      y[i,j] ~ dcat(omega[z[i,j], 1:2])
-    }
-  }
-})
-```
-
-### Run and summarise
-
-```{r, eval = TRUE, echo = TRUE, cache = TRUE, message = TRUE}
-mcmc.phip <- nimbleMCMC(code = hmm.phip, 
-                         constants = my.constants,
-                         data = my.data,              
-                         inits = initial.values,
-                         monitors = parameters.to.save,
-                         niter = n.iter,
-                         nburnin = n.burnin, 
-                         nchains = n.chains)
-```
-
-```{r, eval = TRUE, echo=TRUE, message = TRUE}
-MCMCsummary(object = mcmc.phip, round = 2)
-```
-
-## Detailed Nimble workflow
-
-## 1. Build the model (R object)
-
-```{r, eval = TRUE, echo = TRUE, message = TRUE}
-hmm.phip <- nimbleModel(code = hmm.phip,
-                        constants = my.constants,
-                        data = my.data,
-                        inits = initial.values())
-```
-
-## 2. Build the MCMC
-
-```{r, eval = TRUE, echo = TRUE, message = TRUE}
-phip.mcmc.configuration <- configureMCMC(hmm.phip)
-phip.mcmc <- buildMCMC(phip.mcmc.configuration)
-```
-
-## 3. Compile the model and MCMC
-
-```{r, eval = TRUE, echo = TRUE, message = TRUE}
-phip.model <- compileNimble(hmm.phip) 
-c.phip.mcmc <- compileNimble(phip.mcmc, project = phip.model)
-```
-
-## 4. Run the MCMC
-
-
-```{r, eval = TRUE, echo = TRUE, message = TRUE}
-samples <- runMCMC(c.phip.mcmc, niter = 1000)
-# Alternative:
-# c.phip.mcmc$run(1000)
-# samples <- as.matrix(c.phip.mcmc$mvSamples)
-```
-
-## 5. Look at results
-
-```{r, eval = TRUE, echo = TRUE, message = TRUE}
-summary(samples[,""phi""])
-summary(samples[,""p""])
-```
-
-## Why is it useful? 
-
-## Use and debug model in `R`
-
-+ Makes your life easier when it comes to debugging
-
-+ Inspect variables
-
-```{r}
-hmm.phip$gamma
-```
-
-+ Calculate likelihood
-
-```{r}
-hmm.phip$calculate()
-```
-
-## Example of debugging a model in `R`
-
-+ Pretend an impossible state was given in inits, making a dead bird alive again.
-
-```{r echo=FALSE}
-# Pretend that inits for the 6th bird are invalid, going from dead to alive.
-saved_z_6 <- phip.model$z[6,]
-phip.model$z[6,] <- c(1, 1, 2, 1, 2, 2, 2)
-```
-
-```{r, eval = TRUE, echo = TRUE, message = TRUE}
-phip.model$calculate(""z"")        # We can see there is a problem in z (states).
-c(phip.model$calculate(""z[5,]""), # Bird 5 is valid.
-  phip.model$calculate(""z[6,]"")) # Bird 6 isn't.
-phip.model$z[6,]                 # We have found the problem
-```
-
-```{r echo=FALSE}
-# Restore to valid valies
-phip.model$z[6,] <- saved_z_6
-```
-
-## Open the hood, and change/modify/write samplers
-
-+ Slice samplers instead of Metropolis-Hastings.
-
-+ Samplers on a log scale, especially for a variance, standard deviation, or precision parameter.
-
-+ Blocking correlated parameters.
-
-+ To know all samplers available in Nimble, type in `help(samplers)`.
-
-+ Source code for samplers and distributions is **in R** and can be copied and modified.
-
-+ Use [`compareMCMCs` package](https://github.com/nimble-dev/compareMCMCs) to compare options (including Stan and Jags!). 
-
-## Consider a model with wing length and individual random effect on survival.  
-
-```{r echo = FALSE}
-dipper <- read_csv(here::here(""dat"", ""dipper.csv""))
-y <- dipper %>%
-  select(year_1981:year_1987) %>%
-  as.matrix()
-first <- apply(y, 1, function(x) min(which(x !=0)))
-wing.length.st <- as.vector(scale(dipper$wing_length))
-my.constants <- list(N = nrow(y), 
-                     T = ncol(y), 
-                     first = first,
-                     winglength = wing.length.st)
-zinits <- y + 1 # non-detection -> alive
-zinits[zinits == 2] <- 1 # dead -> alive
-initial.values <- function() list(beta = rnorm(2,0,1.5),
-                                  sdeps = runif(1,0,3),
-                                  p = runif(1,0,1),
-                                  z = zinits)
-parameters.to.save <- c(""beta"", ""sdeps"", ""p"")
-n.iter <- 10000
-n.burnin <- 2500
-n.chains <- 2
-```
-
-```{r}
-hmm.phiwlrep <- nimbleCode({
-    p ~ dunif(0, 1) # prior detection
-    omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)
-    omega[1,2] <- p        # Pr(alive t -> detected t)
-    omega[2,1] <- 1        # Pr(dead t -> non-detected t)
-    omega[2,2] <- 0        # Pr(dead t -> detected t)
-  for (i in 1:N){
-    logit(phi[i]) <- beta[1] + beta[2] * winglength[i] + eps[i] #<<
-    eps[i] ~ dnorm(mean = 0, sd = sdeps) #<<
-    gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)
-    gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)
-    gamma[2,1,i] <- 0           # Pr(dead t -> alive t+1)
-    gamma[2,2,i] <- 1           # Pr(dead t -> dead t+1)
-  }
-  beta[1] ~ dnorm(mean = 0, sd = 1.5)
-  beta[2] ~ dnorm(mean = 0, sd = 1.5)
-  sdeps ~ dunif(0, 10)
-  delta[1] <- 1          # Pr(alive t = 1) = 1
-  delta[2] <- 0          # Pr(dead t = 1) = 0
-  # likelihood
-  for (i in 1:N){
-    z[i,first[i]] ~ dcat(delta[1:2])
-    for (j in (first[i]+1):T){
-      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, i]) #<<
-      y[i,j] ~ dcat(omega[z[i,j], 1:2])
-    }
-  }
-})
-```
-
-```{r echo = FALSE, eval = FALSE}
-# mcmc.phiwlrep <- nimbleMCMC(code = hmm.phiwlrep, 
-#                             constants = my.constants,
-#                             data = my.data,              
-#                             inits = initial.values,
-#                             monitors = parameters.to.save,
-#                             niter = n.iter,
-#                             nburnin = n.burnin, 
-#                             nchains = n.chains)
-hmm.phiwlrep.m <- nimbleModel(code = hmm.phiwlrep,
-                              constants = my.constants,
-                              data = my.data,
-                              inits = initial.values())
-Rmcmc <- buildMCMC(hmm.phiwlrep.m)
-Cmodel <- compileNimble(hmm.phiwlrep.m)
-Cmcmc <- compileNimble(Rmcmc, project=hmm.phiwlrep.m)
-times.phiwlrep <- system.time( mcmc.phiwlrep <- runMCMC(Cmcmc, niter = 10000, nchains = 2) )
-# Alternative:
-# Cmcmc$run(10000)
-# samples1 <- as.matrix(Cmcmc$mvSamples)
-# Cmcmc$run(10000)
-# samples2 <- as.matrix(Cmcmc$mvSamples)
-save(times.phiwlrep, mcmc.phiwlrep, file = here::here(""dat"", ""wl.RData""))
-```
-
-## Trace plot for standard deviation of the random effect (default sampler)
-
-```{r echo = FALSE, message=FALSE, warning=FALSE} 
-load(here::here(""dat"", ""wl.RData""))
-```
-
-```{r, echo = FALSE}
-MCMCtrace(mcmc.phiwlrep, params = ""sdeps"", pdf = FALSE)
-```
-
-## Change samplers
-
-+ Good sampling strategies depend on the model and data.  What are the samplers used by default?
-
-```{r echo = FALSE}
-hmm.phiwlrep.m <- nimbleModel(code = hmm.phiwlrep,
-                              constants = my.constants,
-                              data = my.data,
-                              inits = initial.values())
-```
-
-
-```{r}
-mcmcConf <- configureMCMC(hmm.phiwlrep.m)
-```
-
-## Remove default sampler, and use slice sampler
-
-```{r}
-mcmcConf$removeSamplers('sdeps')
-mcmcConf$addSampler(target = 'sdeps',
-                    type = ""slice"") #<<
-mcmcConf
-```
-
-```{r, echo = FALSE}
-Rmcmc <- buildMCMC(mcmcConf)
-Cmodel <- compileNimble(hmm.phiwlrep.m)
-Cmcmc <- compileNimble(Rmcmc, project=hmm.phiwlrep.m)
-times.phiwlrep.with.slice <- system.time( mcmc.phiwlrep.with.slice <- runMCMC(Cmcmc, niter = 10000, nchains = 2))
-samples1 <- mcmc.phiwlrep.with.slice[[1]]
-samples2 <- mcmc.phiwlrep.with.slice[[2]]
-iUse <- 2501:10000
-ESS.with.slice <- coda::effectiveSize(list(coda::as.mcmc(samples1[iUse, 'sdeps']),
-                                           coda::as.mcmc(samples2[iUse, 'sdeps'])))
-# Cmcmc$run(10000)
-# samples1 <- as.matrix(Cmcmc$mvSamples)
-# Cmcmc$run(10000)
-# samples2 <- as.matrix(Cmcmc$mvSamples)
-df <- data.frame(iter = c(2501:10000, 2501:10000),
-                 samples = c(samples1[2501:10000,""sdeps""], samples2[2501:10000,""sdeps""]),
-                 chain = c(rep(""chain 1"", length(samples1[2501:10000,""sdeps""])),
-                           rep(""chain 2"", length(samples2[2501:10000,""sdeps""]))))
-df.beta <- data.frame(iter = c(2501:10000, 2501:10000),
-                 beta1 = c(samples1[2501:10000,""beta[1]""], samples2[2501:10000,""beta[1]""]),
-                 beta2 = c(samples1[2501:10000,""beta[2]""], samples2[2501:10000,""beta[2]""]),
-                 chain = c(rep(""chain 1"", length(samples1[2501:10000,""sdeps""])),
-                           rep(""chain 2"", length(samples2[2501:10000,""sdeps""]))))
-```
-
-## Trace plot for standard deviation of the random effect (slice sampler)
-
-```{r, echo = FALSE}
-MCMCtrace(mcmc.phiwlrep.with.slice, params = ""sdeps"", pdf = FALSE)
-```
-
-```{r, echo = FALSE}
-# df %>%
-#   ggplot() + 
-#   aes(x = iter, y = samples, group = chain, color = chain) + 
-#   geom_line() + 
-#   labs(x = ""iterations"", y = ""random effect standard deviation"", color = """")
-```
-
-## Which is better?
-
-+ MCMC efficiency depends on both mixing and computation time.
-
-+ MCMC efficiency = Effective Sample Size (ESS) / computation time.
-
-+ MCMC efficiency is the number of effectively independent posterior samples generated per second.
-
-+ ESS is different for each parameter.  (Computation time is the same for each parameter.)
-
-+ ESS can be estimated from packages `coda` or `mcmcse`. These give statistical estimates, so different runs will give different estimates.
-
-```{r echo = FALSE}
-iUse <- 2501:10000
-time_frac <- 0.75 # Include 75% of the time to count sampling of recorded sampled, which is not the only valid option.
-ESS <- coda::effectiveSize(list(coda::as.mcmc(mcmc.phiwlrep[[1]][iUse, 'sdeps']),
-                                        coda::as.mcmc(mcmc.phiwlrep[[2]][iUse, 'sdeps'])))
-t1 <- (time_frac * times.phiwlrep[3])
-efficiency <- ESS / t1
-t.with.slice <- (time_frac * times.phiwlrep.with.slice[3])
-efficiency.with.slice <- ESS.with.slice / t.with.slice
-rd2 <- function(x) round(x, digits = 2)
-```
-
-+ Efficiency with default sampler = `r rd2(ESS)` / `r rd2(t1)` = `r rd2(efficiency)`.
-
-+ Efficiency with slice sampler = `r rd2(ESS.with.slice)` / `r rd2(t.with.slice)` = `r rd2(efficiency.with.slice)`.
-
-## Block sampling
-
-+ High correlation in (regression) parameters may make independent samplers inefficient.
-
-```{r, echo = FALSE}
-df.beta %>%
-  ggplot() + 
-  aes(x = beta1, y = beta2, group = chain, color = chain) +
-  geom_point(alpha = .05) + 
-  labs(x = ""beta1"", y = ""beta2"", color = """")
-```
-
-+ Block sampling (propose candidate values from multivariate distribution) might help.
-
-## Block sampling
-
-+ Remove and replace independent RW samples by block sampling. Then proceed as usual.
-
-```{r message = FALSE, warning=FALSE}
-mcmcConf$removeSamplers(c('beta[1]','beta[2]'))
-mcmcConf$addSampler(target = c('beta[1]','beta[2]'),
-                    type = ""RW_block"") #<<
-```
-
-## Block sampling
-
-```{r message = FALSE, warning=FALSE}
-mcmcConf
-```
-
-## Summary of strategies for improving MCMC 
-
-
-+ Choose better initial values.
-
-+ Customize sampler choice (more in [Chapter 7 of the User's manual](https://r-nimble.org/html_manual/cha-mcmc.html)).
-
-+ Reparameterize, e.g. standardize covariates, deal with parameter redundancy.
-
-+ Rewrite the model.
-
-    + Vectorize to improve computational efficiency (not covered).
-    + Avoid long chains of deterministic dependencies.
-    + Marginalize to remove parameters
-    + Use new functions and new distributions written as nimbleFunctions.
-
-+ Write new samplers that take advantage of particular model structures (not covered).
-
-+ Using multiple cores with parallelization: see how-to at <https://r-nimble.org/nimbleExamples/parallelizing_NIMBLE.html>
-
-## Marginalization
-
-+ User-defined distributions is another neat feature of Nimble.
-
-+ Integrate over latent states if those are not the focus of ecological inference (marginalization).
-
-+ Marginalization often (but not always) improves MCMC. See [Ponisio et al. 2020](https://onlinelibrary.wiley.com/doi/full/10.1002/ece3.6053) for examples.
-
-+ The [nimbleEcology](https://cran.r-project.org/web/packages/nimbleEcology/vignettes/Introduction_to_nimbleEcology.html) package implements capture-recapture models and HMMs with marginalization. 
-
-### Our model $(\phi_A, \phi_B, \psi_{AB}, \psi_{BA}, p_A, p_B)$
-
-```{r eval = FALSE}
-multisite <- nimbleCode({
-...
-  # Likelihood 
-  for (i in 1:N){
-    # Define latent state at first capture
-    z[i,first[i]] <- y[i,first[i]] - 1
-    for (t in (first[i]+1):K){
-      # State process: draw S(t) given S(t-1)
-      z[i,t] ~ dcat(gamma[z[i,t-1],1:3])
-      # Observation process: draw O(t) given S(t)
-      y[i,t] ~ dcat(omega[z[i,t],1:3])
-    }
-  }
-})
-```
-
-### Same model with nimbleEcology
-
-```{r eval = FALSE}
-multisite <- nimbleCode({
-...
-# initial state probs
-for(i in 1:N) {
-  init[i, 1:4] <- gamma[ y[i, first[i] ] - 1, 1:4 ] # first state propagation
-}
-    
-# likelihood 
-for (i in 1:N){
-  y[i,(first[i]+1):K] ~ dHMM(init = init[i,1:4],           # count data from first[i] + 1
-                             probObs = omega[1:4,1:4],     # observation matrix
-                             probTrans = gamma[1:4,1:4],   # transition matrix
-                             len = K - first[i],           # nb of occasions
-                             checkRowSums = 0)             # do not check whether elements in a row sum tp 1
-}
-...
-```
-
-+ This runs twice as fast as the standard formulation with explicit latent states.
-
-+ Marginalizing typically gives better mixing.
-
-### Reducing redundant calculations
-
-+ So far, a row of the dataset is an individual. However, several individuals may share the same encounter history. 
-
-+ The contribution of $M$ individuals with the same encounter history is the likelihood of this particular encounter history raised to the power $M$.
-
-+ Using this so-called **weighted likelihood** greatly decreases the computational burden.
-
-+ This idea is used in most computer programs that implement maximum likelihood. In the Bayesian framework, the same idea was proposed in [Turek et al. (2016)](https://doi.org/10.1007/s10651-016-0353-z). 
-
-+ Cannot be done in Jags. Can be done in nimble thanks to nimble functions! 
-
-+ The run is *much* faster. Also allows fitting models to big datasets. More details in dedicated Worksheet.
-
-## No live demo, but there is a worksheet.
-
-
-## Future directions for NIMBLE
-
-+ NIMBLE is under active development.  Contributors are welcome, including those who want to get involved but don't know where.
-
-+ Faster building of models and algorithms.  Ability to save and re-load compiled work.
-
-+ Automatic differentiation of model calculations, enabling Hamiltonian Monte Carlo, other sampling strategies, and Laplace approximation.
-
-+ Tools for building packages that use NIMBLE ""under the hood"".
-
-## Further reading
-
-+ Turek, D., de Valpine, P. & Paciorek, C.J. [Efficient Markov chain Monte Carlo sampling for hierarchical hidden Markov models](https://doi.org/10.1007/s10651-016-0353-z) *Environ Ecol Stat* 23: 549‚Äì564 (2016).
-
-+ Ponisio, L.C., de Valpine, P., Michaud, N., and Turek, D. [One size does not fit all: Customizing MCMC methods for hierarchical models using NIMBLE](https://doi.org/10.1002/ece3.6053) *Ecol Evol.* 10: 2385‚Äì2416 (2020).
-
-+ Nimble workshop to come 26-28 May, check out [here](https://r-nimble.org/nimble-virtual-short-course-may-26-28).
-
-+ Nimble workshop material online available [here](https://github.com/nimble-training).
-
-+ Nimble [manual](https://r-nimble.org/html_manual/cha-welcome-nimble.html) and [cheatsheet](https://r-nimble.org/cheatsheets/NimbleCheatSheet.pdf). 
\ No newline at end of file

---FILE: 11-xx-conclusions.Rmd---
@@ -1,112 +0,0 @@
-# Conclusions {#conclusions}
-
-
-## Take-home messages and recommendations
-
-+ We'll wrap up the workshop with a few take-home messages 
-+ And recommendations for conducting your own analyses.
-
-## Make the best of your data with HMMs
-
-+ Here is [a searchable list](applistHMM.html) of HMM analyses of capture-recapture data.
-
-+ We hope to have provided you with a useful overview of how to use hidden Markov models to analyze capture-recapture data. 
-+ We have only scratched the surface of what you can do with these models. 
-+ We have assembled a searchable list of HMM analyses of capture-recapture data to get inspiration. 
-
-+ This list is not exhaustive, please get in touch with us if you'd like to add a reference.
-
-+ It is not exhaustive, we'll continue updating it. Feel free to suggest papers to add to the list. 
-
-## Bayesian capture-recapture analysis with HMMs
-
-+ Before we leave, we'd like to give you a few pieces of advice.
-+ This is not rocket science.
-+ Just a few things based on our own experience of Bayesian capture-recapture analysis with HMMS.
-
-+ Make your ecological question explicit. 
-
-+ First things first. Make sure you've spent some to time to make your ecological question explicit. 
-+ This step will help you to stay on course, and make the right choices. 
-+ For example, it's ok to use subsets of your data to address different questions. 
-
-+ Think of observations and states first. 
-
-+ Now in terms of modeling. Don't jump on your keyboard right away. 
-+ Spend some time thinking about your model with pen and paper. 
-+ In particular make sure you have the observations and the states of your HMM. 
-
-+ Then write down the observation and transition matrices on paper. 
-
-+ Then write down the transition matrix. You may act as if you had no imperfect detection. This is really what you're after, the ecological process (survival, dispersal, etc). 
-+ Proceed with the observation matrix. 
-
-+ Start simple, all parameters constant for example. Make sure convergence is reached.
-
-+ When it comes to model fitting with Nimble, start simple. 
-+ Consider all parameters constant. 
-+ Make sure convergence is reached. 
-
-+ Add complexity one step at a time. 
-
-+ Then add complexity. Time effect for example. Or random effects.
-+ Or uncertainty in the assignment of states. 
-
-## Bayesian capture-recapture analysis with HMMs
-
-+ Use simulations to better understand your model. 
-
-+ Nimble models can be used to simulate data, check out [this tutorial](https://r-nimble.org/nimbleExamples/simulation_from_model.html).  
-
-+ When it comes to model building, consider simulating data to better understand your model. 
-+ You will always learn something on your model by seeing it an engine to generate data, instead of estimating its parameters.
-+ The cool thing with nimble is that you can you models to simulate data. There is a tutorial for that.  
-
-+ Do not try to optimize your code. Make it work first, then think of optimization. 
-
-> [""Premature optimization is the root of all evil""](https://stackify.com/premature-optimization-evil/) - Donald Knuth (creator of TeX and author of [""The Art of Computer Programming""](https://en.wikipedia.org/wiki/The_Art_of_Computer_Programming))
-
-+ Another advice, quite general in programming, is to not try to optimize your code
-+ Or to try to make it elegant right away. Make it work first. 
-+ Then think of optimization. 
-
-+ Read [Bayesian workflow](https://arxiv.org/abs/2011.01808) by Gelman et al. (2021).
-
-+ More recommendations on Bayesian analyses in this recent paper by Gelman and collaborations. 
-+ They offer a workflow for bayesian analyses.
-+ In which they discuss model building, model comparison, model checking, model validation, model understanding and troubleshooting of computational problems.
-
-<!-- --- -->
-<!-- ## Nimble -->
-
-<!-- + [TO BE COMPLETED BY ALL] -->
-
-<!-- + Go for `nimbleMCMC()` if standard needs.  -->
-
-<!-- + Unleash full `Nimble` potential for improving MCMC or implementing new distributions.  -->
-
-## Till next time
-
-+ The Slack space will remain for some time. Happy to answer questions you might have related to the workshop. 
-
-+ The Slack space will remain for some time. 
-+ We'll be happy to answer the questions you might have related to the workshop. 
-
-+ Website will be updated with
-
-    + video recordings
-    + your feedbacks
-    + a FAQ section based on your questions
-
-+ We will update the workshop website in the coming weeks. 
-+ With the video recordings of course. 
-+ Any feedback you might have. Please get in touch with me if you have any, that would be great. 
-+ Our plan is also to gather our exchanges in a Frequently Asked Questions section on the website. 
-
-+ A book is on its way. More in 2022 hopefully.
-
-+ And last, a book is on its way. Based on the material we used for the workshop and more stuff. 
-+ Also half the book will be about case studies reproducing analysis from published papers. 
-+ More in 2022 hopefully. 
-
-## Let's see if I can put to use my own pieces of advice - case studies

---FILE: 12-senescence.Rmd---
@@ -1,5 +0,0 @@
-# (PART) Case studies {-}
-
-# Actuarial senescence {#senescence}
-
-@choquet_semi-markov_2011, @peron_evidence_2016

---FILE: 13-heterogeneity.Rmd---
@@ -1,4 +0,0 @@
-# Individual heterogeneity  {#heterogeneity}
-
-@cubaynes_importance_2010, @gimenez_individual_2010, and @turek_bayesian_2021
-

---FILE: 14-tradeoffs.Rmd---
@@ -1,4 +0,0 @@
-# Life-history tradeoffs  {#tradeoffs}
-
-@morano_life-history_2013, @shefferson_life_2003, and @cruz-flores_sex-specific_nodate
-

---FILE: 15-breeding.Rmd---
@@ -1,4 +0,0 @@
-# Breeding dynamics  {#breeding}
-
-@pradel_breeding_2012, @desprez_now_2011, @desprez_known_2013, and @pacoureau_population_2019
-

---FILE: 16-robustdesign.Rmd---
@@ -1,4 +0,0 @@
-# Robust design  {#rd}
-
-@karamanlidis_evidence_2015, @santostasi_robust_2016, @gibson_application_2018, and @rankin_full-capture_2016
-

---FILE: 17-stopover.Rmd---
@@ -1,4 +0,0 @@
-# Stopover duration  {#stopover}
-
-@guerin_advances_2017
-

---FILE: 18-disease.Rmd---
@@ -1,4 +0,0 @@
-# Disease dynamics  {#disease}
-
-@MarescotEtAl2018 and @santoro_multi-event_2014
-

---FILE: 19-sex.Rmd---
@@ -1,4 +0,0 @@
-# Sex uncertainty {#sex}
-
-@PradelEtAl2008 and @genovart_exploiting_2012
-

---FILE: 20-dependence.Rmd---
@@ -1,4 +0,0 @@
-# Dependence among individuals {#dependence}
-
-@culina_multievent_2013 and @cubaynes_modeling_2021
-

---FILE: 21-selection.Rmd---
@@ -1,4 +0,0 @@
-# Individual and temporal variability  {#covariateselection}
-
-@grosbois_assessing_2008, @cubaynes_testing_2012, @gimenez_semiparametric_2006, and @bonner_continuous_2010
-

---FILE: 22-mortalities.Rmd---
@@ -1,4 +0,0 @@
-# Cause-specific mortalities  {#mortalities}
-
-@fernandez-chacon_causes_2016 and @ruette_comparative_2015
-

---FILE: 23-prevalence.Rmd---
@@ -1,4 +0,0 @@
-# Prevalence {#prevalence}
-
-[@santostasi_use_2019]
-

---FILE: 24-faq.Rmd---
@@ -1,11 +0,0 @@
-# FAQ {-}
-
-Below is the _complete_ list of frequently asked questions (FAQ). Yes, there is only one question here. Personally I do not like FAQs. They often mean surprises, and surprises are not good for software users.
-
-1. Q: Will **bookdown** have the features X, Y, and Z?
-
-    A: The short answer is no, but if you have asked yourself three times ""do I really need them"" and the answer is still ""yes"", please feel free to file a feature request to https://github.com/rstudio/bookdown/issues.
-
-    Users asking for more features often come from the LaTeX world. If that is the case for you, the answer to this question is yes, because Pandoc's Markdown supports raw LaTeX code. Whenever you feel Markdown cannot do the job for you, you always have the option to apply some raw LaTeX code in your Markdown document. For example, you can create glossaries using the **glossaries** package, or embed a complicated LaTeX table, as long as you know the LaTeX syntax. However, please keep in mind that the LaTeX content is not portable. It will only work for LaTeX/PDF output, and will be ignored in other types of output. Depending on the request, we may port a few more LaTeX features into **bookdown** in the future, but our general philosophy is that Markdown should be kept as simple as possible.
-
-The most challenging thing in the world is not to learn fancy technologies, but control your own wild heart.

---FILE: 25-references.Rmd---
@@ -1,5 +0,0 @@
-\backmatter
-
-`r if (knitr:::is_html_output()) '
-# References {-}
-'`

---FILE: docs/404.html---
@@ -1,53 +1,32 @@
-<!doctype html>
+<!DOCTYPE html>
 <html lang=""en"">
 <head>
-  <meta charset=""utf-8"" />
-  <meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-
-  <title>Page not found | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</title>
-
-    <meta name=""author"" content=""Olivier Gimenez"" />
-  
-   <meta name=""description"" content=""This is a comprehensive and applied textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."" />
-   <meta name=""generator"" content=""placeholder"" />
-  <meta property=""og:title"" content=""Page not found | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R"" />
-  <meta property=""og:type"" content=""book"" />
-  <meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/"" />
-  <meta property=""og:image"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop//images/satellite.png"" />
-  <meta property=""og:description"" content=""This is a comprehensive and applied textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."" />
-
-  <meta name=""twitter:card"" content=""summary"" />
-  <meta name=""twitter:title"" content=""Page not found | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R"" />
-  
-  <meta name=""twitter:description"" content=""This is a comprehensive and applied textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."" />
-  <meta name=""twitter:image"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop//images/satellite.png"" />
-  <!-- JS -->
-  <script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script>
-  <script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script>
-  <script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script>
-    <script src=""libs/header-attrs-2.10/header-attrs.js""></script>
-    <script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script>
-    <meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"" />
-    <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"" />
-    <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script>
-    <script src=""libs/bs3compat-0.2.5.1/tabs.js""></script>
-    <script src=""libs/bs3compat-0.2.5.1/bs3compat.js""></script>
-    <link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"" />
-    <script src=""libs/bs4_book-1.0.0/bs4_book.js""></script>
-    <script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script>
-  <script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script>
-
-  <!-- CSS -->
-    <link rel=""stylesheet"" href=""bs4_style.css"" />
-  
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>Page not found | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are..."">
+<meta name=""generator"" content=""bookdown 0.23 with bs4_book()"">
+<meta property=""og:title"" content=""Page not found | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/404.html"">
+<meta property=""og:image"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop//images/satellite.png"">
+<meta property=""og:description"" content=""The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are..."">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""Page not found | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R"">
+<meta name=""twitter:description"" content=""The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are..."">
+<meta name=""twitter:image"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop//images/satellite.png"">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs/header-attrs.js""></script><script src=""libs/jquery/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat/tabs.js""></script><script src=""libs/bs3compat/bs3compat.js""></script><link href=""libs/bs4_book/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
-
 <body data-spy=""scroll"" data-target=""#toc"">
 
 <div class=""container-fluid"">
 <div class=""row"">
-  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book"">
-    <a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
 
     <div class=""d-flex align-items-start justify-content-between"">
       <h1>
@@ -59,62 +38,50 @@ <h1>
     <div id=""main-nav"" class=""collapse-lg"">
       <form role=""search"">
         <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
-      </form>
+</form>
 
-      <nav aria-label=""Table of contents"">
-        <h2>Table of contents</h2>
-        <div id=""book-toc""></div>
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li><a class="""" href=""about-the-author.html"">About the Author</a></li>
+<li class=""book-part"">Theory</li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+</ul>
 
         <div class=""book-extra"">
-          <p><a id=""book-repo"" href=""#"">View book source <i class=""fab fa-github""></i></a></li></p>
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
         </div>
       </nav>
-    </div>
-  </header>
-
-  <main class=""col-sm-12 col-md-9 col-lg-7"" id=""content"">
-<div id=""page-not-found"" class=""section level1"">
-<h1>Page not found</h1>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""page-not-found"" class=""section level1"">
+<h1>Page not found<a class=""anchor"" aria-label=""anchor"" href=""#page-not-found""><i class=""fas fa-link""></i></a>
+</h1>
 <p>The page you requested cannot be found (perhaps it was moved or renamed).</p>
 <p>You may want to try searching to find the page's new location, or use
 the table of contents to find the page you are looking for.</p>
 </div>
-  </main>
-
-  <div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
-    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page"">
-      <h2>On this page</h2>
-      <div id=""book-on-this-page""></div>
-
-      <div class=""book-extra"">
-        <ul class=""list-unstyled"">
-          <li><a id=""book-source"" href=""#"">View source <i class=""fab fa-github""></i></a></li>
-          <li><a id=""book-edit"" href=""#"">Edit this page <i class=""fab fa-github""></i></a></li>
-        </ul>
-      </div>
-    </nav>
-  </div>
+  <div class=""chapter-nav"">
+<div class=""empty""></div>
+<div class=""empty""></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    </div>
 
 </div>
 </div> <!-- .container -->
 
-<footer class=""bg-primary text-light mt-5"">
-  <div class=""container""><div class=""row"">
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-14.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-15.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer>
-
-
-<!-- dynamically load mathjax for compatibility with self-contained -->
-<script>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
   (function () {
     var script = document.createElement(""script"");
     script.type = ""text/javascript"";
@@ -126,8 +93,7 @@ <h2>On this page</h2>
     script.src = src;
     document.getElementsByTagName(""head"")[0].appendChild(script);
   })();
-</script>
-<script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
 for (let popover of popovers) {
   const div = document.createElement('div');
   div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
@@ -145,5 +111,4 @@ <h2>On this page</h2>
 }
 </script>
 </body>
-
 </html>

---FILE: docs/about-the-author.html---
@@ -20,8 +20,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs/header-attrs.js""></script><script src=""libs/jquery/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat/tabs.js""></script><script src=""libs/bs3compat/bs3compat.js""></script><link href=""libs/bs4_book/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book/bs4_book.js""></script><script src=""libs/kePrint/kePrint.js""></script><link href=""libs/lightable/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 
@@ -48,32 +47,6 @@ <h1>
 <li><a class=""active"" href=""about-the-author.html"">About the Author</a></li>
 <li class=""book-part"">Theory</li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
-<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> Introduction to Nimble</a></li>
-<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
-<li><a class="""" href=""transition.html""><span class=""header-section-number"">5</span> Transition</a></li>
-<li><a class="""" href=""covariates.html""><span class=""header-section-number"">6</span> Covariates</a></li>
-<li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">7</span> Uncertainty in state assignment</a></li>
-<li><a class="""" href=""abundance.html""><span class=""header-section-number"">8</span> Abundance</a></li>
-<li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
-<li><a class="""" href=""states.html""><span class=""header-section-number"">10</span> Hidden states</a></li>
-<li><a class="""" href=""speed.html""><span class=""header-section-number"">11</span> Speed up MCMC</a></li>
-<li><a class="""" href=""conclusions.html""><span class=""header-section-number"">12</span> Conclusions</a></li>
-<li class=""book-part"">Case studies</li>
-<li><a class="""" href=""senescence.html""><span class=""header-section-number"">13</span> Actuarial senescence</a></li>
-<li><a class="""" href=""heterogeneity.html""><span class=""header-section-number"">14</span> Individual heterogeneity</a></li>
-<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">15</span> Life-history tradeoffs</a></li>
-<li><a class="""" href=""breeding.html""><span class=""header-section-number"">16</span> Breeding dynamics</a></li>
-<li><a class="""" href=""rd.html""><span class=""header-section-number"">17</span> Robust design</a></li>
-<li><a class="""" href=""stopover.html""><span class=""header-section-number"">18</span> Stopover duration</a></li>
-<li><a class="""" href=""disease.html""><span class=""header-section-number"">19</span> Disease dynamics</a></li>
-<li><a class="""" href=""sex.html""><span class=""header-section-number"">20</span> Sex uncertainty</a></li>
-<li><a class="""" href=""dependence.html""><span class=""header-section-number"">21</span> Dependence among individuals</a></li>
-<li><a class="""" href=""covariateselection.html""><span class=""header-section-number"">22</span> Individual and temporal variability</a></li>
-<li><a class="""" href=""mortalities.html""><span class=""header-section-number"">23</span> Cause-specific mortalities</a></li>
-<li><a class="""" href=""prevalence.html""><span class=""header-section-number"">24</span> Prevalence</a></li>
-<li><a class="""" href=""faq.html"">FAQ</a></li>
-<li><a class="""" href=""references.html"">References</a></li>
 </ul>
 
         <div class=""book-extra"">
@@ -114,7 +87,7 @@ <h1>About the Author<a class=""anchor"" aria-label=""anchor"" href=""#about-the-autho
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-14.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-15.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/crashcourse.html---
@@ -20,8 +20,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs/header-attrs.js""></script><script src=""libs/jquery/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat/tabs.js""></script><script src=""libs/bs3compat/bs3compat.js""></script><link href=""libs/bs4_book/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book/bs4_book.js""></script><script src=""libs/kePrint/kePrint.js""></script><link href=""libs/lightable/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 
@@ -48,32 +47,6 @@ <h1>
 <li><a class="""" href=""about-the-author.html"">About the Author</a></li>
 <li class=""book-part"">Theory</li>
 <li><a class=""active"" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
-<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> Introduction to Nimble</a></li>
-<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
-<li><a class="""" href=""transition.html""><span class=""header-section-number"">5</span> Transition</a></li>
-<li><a class="""" href=""covariates.html""><span class=""header-section-number"">6</span> Covariates</a></li>
-<li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">7</span> Uncertainty in state assignment</a></li>
-<li><a class="""" href=""abundance.html""><span class=""header-section-number"">8</span> Abundance</a></li>
-<li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
-<li><a class="""" href=""states.html""><span class=""header-section-number"">10</span> Hidden states</a></li>
-<li><a class="""" href=""speed.html""><span class=""header-section-number"">11</span> Speed up MCMC</a></li>
-<li><a class="""" href=""conclusions.html""><span class=""header-section-number"">12</span> Conclusions</a></li>
-<li class=""book-part"">Case studies</li>
-<li><a class="""" href=""senescence.html""><span class=""header-section-number"">13</span> Actuarial senescence</a></li>
-<li><a class="""" href=""heterogeneity.html""><span class=""header-section-number"">14</span> Individual heterogeneity</a></li>
-<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">15</span> Life-history tradeoffs</a></li>
-<li><a class="""" href=""breeding.html""><span class=""header-section-number"">16</span> Breeding dynamics</a></li>
-<li><a class="""" href=""rd.html""><span class=""header-section-number"">17</span> Robust design</a></li>
-<li><a class="""" href=""stopover.html""><span class=""header-section-number"">18</span> Stopover duration</a></li>
-<li><a class="""" href=""disease.html""><span class=""header-section-number"">19</span> Disease dynamics</a></li>
-<li><a class="""" href=""sex.html""><span class=""header-section-number"">20</span> Sex uncertainty</a></li>
-<li><a class="""" href=""dependence.html""><span class=""header-section-number"">21</span> Dependence among individuals</a></li>
-<li><a class="""" href=""covariateselection.html""><span class=""header-section-number"">22</span> Individual and temporal variability</a></li>
-<li><a class="""" href=""mortalities.html""><span class=""header-section-number"">23</span> Cause-specific mortalities</a></li>
-<li><a class="""" href=""prevalence.html""><span class=""header-section-number"">24</span> Prevalence</a></li>
-<li><a class="""" href=""faq.html"">FAQ</a></li>
-<li><a class="""" href=""references.html"">References</a></li>
 </ul>
 
         <div class=""book-extra"">
@@ -95,7 +68,7 @@ <h2>
 <h2>
 <span class=""header-section-number"">1.2</span> Bayes‚Äô theorem<a class=""anchor"" aria-label=""anchor"" href=""#bayes-theorem""><i class=""fas fa-link""></i></a>
 </h2>
-<p>Let‚Äôs not wait any longer and jump into it. Bayesian statistics relies on the Bayes‚Äô theorem (or law, or rule, whatever you prefer) named after Reverend Thomas Bayes (Figure <a href=""crashcourse.html#fig:revbayes"">1.1</a>). This theorem was published in 1763 two years after Bayes‚Äô death thanks to his friend‚Äôs efforts Richard Price, and was independently rediscovered by Pierre-Simon Laplace <span class=""citation"">(<a href=""references.html#ref-mcgrayne2011"" role=""doc-biblioref"">McGrayne 2011</a>)</span>.</p>
+<p>Let‚Äôs not wait any longer and jump into it. Bayesian statistics relies on the Bayes‚Äô theorem (or law, or rule, whatever you prefer) named after Reverend Thomas Bayes (Figure <a href=""crashcourse.html#fig:revbayes"">1.1</a>). This theorem was published in 1763 two years after Bayes‚Äô death thanks to his friend‚Äôs efforts Richard Price, and was independently rediscovered by Pierre-Simon Laplace <span class=""citation"">(<a href=""crashcourse.html#ref-mcgrayne2011"" role=""doc-biblioref"">McGrayne 2011</a>)</span>.</p>
 <div class=""figure"" style=""text-align: center"">
 <span style=""display:block;"" id=""fig:revbayes""></span>
 <img src=""images/amazing-thomas-bayes-illustration.jpg"" alt=""Cartoon of Thomas Bayes with Bayes' theorem in background. Source: [James Kulich](https://www.elmhurst.edu/blog/thomas-bayes/)"" width=""70%""><p class=""caption"">
@@ -134,11 +107,11 @@ <h2>
 <h2>
 <span class=""header-section-number"">1.4</span> Approximating posterior distributions via numerical integration<a class=""anchor"" aria-label=""anchor"" href=""#numerical-approx""><i class=""fas fa-link""></i></a>
 </h2>
-<p>Let‚Äôs take an example. Say we capture, mark and release <span class=""math inline"">\(n = 57\)</span> animals at the beginning of a winter, out of which we recapture <span class=""math inline"">\(y = 19\)</span> animals alive<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;We used a similar example in &lt;span class=""citation""&gt;&lt;a href=""references.html#ref-king_bayesian_2009"" role=""doc-biblioref""&gt;King et al.&lt;/a&gt; (&lt;a href=""references.html#ref-king_bayesian_2009"" role=""doc-biblioref""&gt;2009&lt;/a&gt;)&lt;/span&gt;&lt;/p&gt;'><sup>4</sup></a>. We‚Äôd like to estimate winter survival <span class=""math inline"">\(\theta\)</span>.</p>
+<p>Let‚Äôs take an example. Say we capture, mark and release <span class=""math inline"">\(n = 57\)</span> animals at the beginning of a winter, out of which we recapture <span class=""math inline"">\(y = 19\)</span> animals alive<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;We used a similar example in &lt;span class=""citation""&gt;&lt;a href=""crashcourse.html#ref-king_bayesian_2009"" role=""doc-biblioref""&gt;King et al.&lt;/a&gt; (&lt;a href=""crashcourse.html#ref-king_bayesian_2009"" role=""doc-biblioref""&gt;2009&lt;/a&gt;)&lt;/span&gt;&lt;/p&gt;'><sup>4</sup></a>. We‚Äôd like to estimate winter survival <span class=""math inline"">\(\theta\)</span>.</p>
 <div class=""sourceCode"" id=""cb2""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">y</span> <span class=""op"">&lt;-</span> <span class=""fl"">19</span> <span class=""co""># nb of success</span>
 <span class=""va"">n</span> <span class=""op"">&lt;-</span> <span class=""fl"">57</span> <span class=""co""># nb of attempts</span></code></pre></div>
-<p>We build our model first. Assuming all animals are independent of each other and have the same survival probability, then the number of alive animals at the end of the winter is a binomial distribution<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;I follow &lt;span class=""citation""&gt;&lt;a href=""references.html#ref-mcelreathbook"" role=""doc-biblioref""&gt;McElreath&lt;/a&gt; (&lt;a href=""references.html#ref-mcelreathbook"" role=""doc-biblioref""&gt;2016&lt;/a&gt;)&lt;/span&gt; and use labels on the right to help remember what each line is about.&lt;/p&gt;'><sup>5</sup></a>:</p>
+<p>We build our model first. Assuming all animals are independent of each other and have the same survival probability, then the number of alive animals at the end of the winter is a binomial distribution<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;I follow &lt;span class=""citation""&gt;&lt;a href=""crashcourse.html#ref-mcelreathbook"" role=""doc-biblioref""&gt;McElreath&lt;/a&gt; (&lt;a href=""crashcourse.html#ref-mcelreathbook"" role=""doc-biblioref""&gt;2016&lt;/a&gt;)&lt;/span&gt; and use labels on the right to help remember what each line is about.&lt;/p&gt;'><sup>5</sup></a>:</p>
 <p><span class=""math display"">\[\begin{align*}
 y &amp;\sim \text{Binomial}(n, \theta) &amp;\text{[likelihood]}
 \end{align*}\]</span></p>
@@ -205,7 +178,7 @@ <h2>
 <span class=""fu""><a href=""https://rdrr.io/r/base/mean.html"">mean</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span><span class=""op"">)</span> <span class=""co""># compute mean</span>
 <span class=""co"">## [1] 0.3398</span>
 <span class=""fu""><a href=""https://rdrr.io/r/stats/median.html"">median</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span><span class=""op"">)</span> <span class=""co""># compute median</span>
-<span class=""co"">## [1] 0.3379</span></code></pre></div>
+<span class=""co"">## [1] 0.3377</span></code></pre></div>
 <p>Because the posterior distribution is rather symetric, mean and median are very similar but this is not necessarily the case. We may also check that the mean we calculate empirically matches the expectation of a beta distribution<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content='&lt;p&gt;&lt;span class=""math inline""&gt;\(E(\text{beta}(\alpha, \beta)) = \displaystyle{\frac{\alpha}{\alpha + \beta}}\)&lt;/span&gt;&lt;/p&gt;'><sup>7</sup></a>:</p>
 <div class=""sourceCode"" id=""cb7""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/r/base/mean.html"">mean</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span><span class=""op"">)</span> <span class=""co""># compute mean</span>
@@ -216,7 +189,7 @@ <h2>
 <div class=""sourceCode"" id=""cb8""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/r/stats/quantile.html"">quantile</a></span><span class=""op"">(</span><span class=""va"">sample_from_posterior</span>, probs <span class=""op"">=</span> <span class=""fu""><a href=""https://rdrr.io/r/base/c.html"">c</a></span><span class=""op"">(</span><span class=""fl"">2.5</span><span class=""op"">/</span><span class=""fl"">100</span>, <span class=""fl"">97.5</span><span class=""op"">/</span><span class=""fl"">100</span><span class=""op"">)</span><span class=""op"">)</span>
 <span class=""co"">##   2.5%  97.5% </span>
-<span class=""co"">## 0.2205 0.4576</span></code></pre></div>
+<span class=""co"">## 0.2242 0.4636</span></code></pre></div>
 <p>In our example, we have a single parameter to estimate, winter survival. This means dealing with a one-dimensional integral in the denominator which is pretty easy with a quadrature scheme and the <code>R</code> function <code><a href=""https://rdrr.io/r/stats/integrate.html"">integrate()</a></code>. Now what if we had multiple parameters? For example, let‚Äôs imagine you‚Äôd like to fit a capture-recapture model with detection probability <span class=""math inline"">\(p\)</span> and regression parameters <span class=""math inline"">\(\alpha\)</span> and <span class=""math inline"">\(\beta\)</span> for the intercept and slope of a relationship between survival probability and a covariate, then Bayes‚Äô theorem gives you the posterior distribution of all three parameters together:</p>
 <p><span class=""math display"">\[ P(\alpha, \beta, p \mid \text{data}) = \frac{ P(\text{data} \mid \alpha, \beta, p) \times P(\alpha, \beta, p)}{\iiint \, P(\text{data} \mid \alpha, \beta, p) P(\alpha, \beta, p) d\alpha d\beta dp} \]</span>
 There are two computational challenges with this formula. First, do we really wish to calculate a three-dimensional integral? The answer is no, one-dimensional and two-dimensional integrals are so much further we can go with standard methods. Second, we‚Äôre more interested in a posterior distribution for each parameter separately than the joint posterior distribution. The so-called marginal distribution of <span class=""math inline"">\(p\)</span> for example is obtained by integrating over all the other parameters ‚Äì a two-dimensional integral in this example. Now imagine with tens or hundreds of parameters to estimate, these integrals become highly multi-dimensional and simply intractable. In the next section, I introduce powerful simulation methods to circumvent this issue.</p>
@@ -435,12 +408,36 @@ <h2>
 <li><p>McCarthy, M. (2007). <a href=""https://www.cambridge.org/core/books/bayesian-methods-for-ecology/9225F65B8A25D69B0B6C50B5A9A78201"">Bayesian Methods for Ecology</a>. Cambridge: Cambridge University Press.</p></li>
 <li><p>McElreath, R. (2020). <a href=""https://xcelab.net/rm/statistical-rethinking/"">Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2nd ed.)</a>. CRC Press.</p></li>
 </ul>
+<div id=""refs"" class=""references csl-bib-body hanging-indent"">
+<div id=""ref-king_bayesian_2009"" class=""csl-entry"">
+King, Ruth, B. J. T. Morgan, O. Gimenez, and S. P. Brooks. 2009. <em>Bayesian <span>Analysis</span> for <span>Population</span> <span>Ecology</span></em>. Chapman; Hall/CRC.
 </div>
+<div id=""ref-mcelreathbook"" class=""csl-entry"">
+McElreath, Richard. 2016. <em>Statistical <span>Rethinking</span>: <span>A</span> <span>Bayesian</span> <span>Course</span> with <span>Examples</span> in <span>R</span> and <span>Stan</span></em>. 1st edition. Chapman; Hall/CRC.
 </div>
+<div id=""ref-mcgrayne2011"" class=""csl-entry"">
+McGrayne, Sharon Bertsch. 2011. <em>The <span>Theory</span> <span>That</span> <span>Would</span> <span>Not</span> <span>Die</span>: <span>How</span> <span>Bayes</span>‚Äô <span>Rule</span> <span>Cracked</span> the <span>Enigma</span> <span>Code</span>, <span>Hunted</span> <span>Down</span> <span>Russian</span> <span>Submarines</span>, and <span>Emerged</span> <span>Triumphant</span> from <span>Two</span> <span>Centuries</span> of <span>Controversy</span></em>. Yale University Press.
+</div>
+</div>
+</div>
+</div>
+
+
+
+
+
+
+
+
+
+
+
+
+
 
   <div class=""chapter-nav"">
 <div class=""prev""><a href=""about-the-author.html"">About the Author</a></div>
-<div class=""next""><a href=""intronimble.html""><span class=""header-section-number"">2</span> Introduction to Nimble</a></div>
+<div class=""empty""></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
       <ul class=""nav navbar-nav"">
@@ -476,7 +473,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-14.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-15.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/index.html---
@@ -20,8 +20,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs/header-attrs.js""></script><script src=""libs/jquery/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat/tabs.js""></script><script src=""libs/bs3compat/bs3compat.js""></script><link href=""libs/bs4_book/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book/bs4_book.js""></script><script src=""libs/kePrint/kePrint.js""></script><link href=""libs/lightable/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 
@@ -48,32 +47,6 @@ <h1>
 <li><a class="""" href=""about-the-author.html"">About the Author</a></li>
 <li class=""book-part"">Theory</li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
-<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> Introduction to Nimble</a></li>
-<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
-<li><a class="""" href=""transition.html""><span class=""header-section-number"">5</span> Transition</a></li>
-<li><a class="""" href=""covariates.html""><span class=""header-section-number"">6</span> Covariates</a></li>
-<li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">7</span> Uncertainty in state assignment</a></li>
-<li><a class="""" href=""abundance.html""><span class=""header-section-number"">8</span> Abundance</a></li>
-<li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
-<li><a class="""" href=""states.html""><span class=""header-section-number"">10</span> Hidden states</a></li>
-<li><a class="""" href=""speed.html""><span class=""header-section-number"">11</span> Speed up MCMC</a></li>
-<li><a class="""" href=""conclusions.html""><span class=""header-section-number"">12</span> Conclusions</a></li>
-<li class=""book-part"">Case studies</li>
-<li><a class="""" href=""senescence.html""><span class=""header-section-number"">13</span> Actuarial senescence</a></li>
-<li><a class="""" href=""heterogeneity.html""><span class=""header-section-number"">14</span> Individual heterogeneity</a></li>
-<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">15</span> Life-history tradeoffs</a></li>
-<li><a class="""" href=""breeding.html""><span class=""header-section-number"">16</span> Breeding dynamics</a></li>
-<li><a class="""" href=""rd.html""><span class=""header-section-number"">17</span> Robust design</a></li>
-<li><a class="""" href=""stopover.html""><span class=""header-section-number"">18</span> Stopover duration</a></li>
-<li><a class="""" href=""disease.html""><span class=""header-section-number"">19</span> Disease dynamics</a></li>
-<li><a class="""" href=""sex.html""><span class=""header-section-number"">20</span> Sex uncertainty</a></li>
-<li><a class="""" href=""dependence.html""><span class=""header-section-number"">21</span> Dependence among individuals</a></li>
-<li><a class="""" href=""covariateselection.html""><span class=""header-section-number"">22</span> Individual and temporal variability</a></li>
-<li><a class="""" href=""mortalities.html""><span class=""header-section-number"">23</span> Cause-specific mortalities</a></li>
-<li><a class="""" href=""prevalence.html""><span class=""header-section-number"">24</span> Prevalence</a></li>
-<li><a class="""" href=""faq.html"">FAQ</a></li>
-<li><a class="""" href=""references.html"">References</a></li>
 </ul>
 
         <div class=""book-extra"">
@@ -87,7 +60,7 @@ <h1>Welcome<a class=""anchor"" aria-label=""anchor"" href=""#welcome""><i class=""fas f
 <p>Welcome to the online version of the book <em>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</em>. <!-- The book is also available in [PDF format](https://github.com/oliviergimenez/banana-book/raw/master/docs/bayesHMMcapturerecapture.pdf). --></p>
 <p>I‚Äôm currently writing this book, and I welcome any feedback <a href=""https://github.com/oliviergimenez/banana-book/issues"">here</a> or via <a href=""mailto:olivier.gimenez@cefe.cnrs.fr"">email</a>.<br>
 Many thanks!</p>
-<p>Olivier Gimenez, Montpellier, France<br><em>Last updated: September 14, 2021</em></p>
+<p>Olivier Gimenez, Montpellier, France<br><em>Last updated: September 15, 2021</em></p>
 </div>
   <div class=""chapter-nav"">
 <div class=""empty""></div>
@@ -111,7 +84,7 @@ <h1>Welcome<a class=""anchor"" aria-label=""anchor"" href=""#welcome""><i class=""fas f
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-14.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-15.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/preface.html---
@@ -20,8 +20,7 @@
 <!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs/header-attrs.js""></script><script src=""libs/jquery/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
 <link href=""libs/bootstrap/bootstrap.min.css"" rel=""stylesheet"">
 <script src=""libs/bootstrap/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat/tabs.js""></script><script src=""libs/bs3compat/bs3compat.js""></script><link href=""libs/bs4_book/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book/bs4_book.js""></script><script src=""libs/kePrint/kePrint.js""></script><link href=""libs/lightable/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<script src=""libs/bs4_book/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 
@@ -48,32 +47,6 @@ <h1>
 <li><a class="""" href=""about-the-author.html"">About the Author</a></li>
 <li class=""book-part"">Theory</li>
 <li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
-<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> Introduction to Nimble</a></li>
-<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
-<li><a class="""" href=""transition.html""><span class=""header-section-number"">5</span> Transition</a></li>
-<li><a class="""" href=""covariates.html""><span class=""header-section-number"">6</span> Covariates</a></li>
-<li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">7</span> Uncertainty in state assignment</a></li>
-<li><a class="""" href=""abundance.html""><span class=""header-section-number"">8</span> Abundance</a></li>
-<li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
-<li><a class="""" href=""states.html""><span class=""header-section-number"">10</span> Hidden states</a></li>
-<li><a class="""" href=""speed.html""><span class=""header-section-number"">11</span> Speed up MCMC</a></li>
-<li><a class="""" href=""conclusions.html""><span class=""header-section-number"">12</span> Conclusions</a></li>
-<li class=""book-part"">Case studies</li>
-<li><a class="""" href=""senescence.html""><span class=""header-section-number"">13</span> Actuarial senescence</a></li>
-<li><a class="""" href=""heterogeneity.html""><span class=""header-section-number"">14</span> Individual heterogeneity</a></li>
-<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">15</span> Life-history tradeoffs</a></li>
-<li><a class="""" href=""breeding.html""><span class=""header-section-number"">16</span> Breeding dynamics</a></li>
-<li><a class="""" href=""rd.html""><span class=""header-section-number"">17</span> Robust design</a></li>
-<li><a class="""" href=""stopover.html""><span class=""header-section-number"">18</span> Stopover duration</a></li>
-<li><a class="""" href=""disease.html""><span class=""header-section-number"">19</span> Disease dynamics</a></li>
-<li><a class="""" href=""sex.html""><span class=""header-section-number"">20</span> Sex uncertainty</a></li>
-<li><a class="""" href=""dependence.html""><span class=""header-section-number"">21</span> Dependence among individuals</a></li>
-<li><a class="""" href=""covariateselection.html""><span class=""header-section-number"">22</span> Individual and temporal variability</a></li>
-<li><a class="""" href=""mortalities.html""><span class=""header-section-number"">23</span> Cause-specific mortalities</a></li>
-<li><a class="""" href=""prevalence.html""><span class=""header-section-number"">24</span> Prevalence</a></li>
-<li><a class="""" href=""faq.html"">FAQ</a></li>
-<li><a class="""" href=""references.html"">References</a></li>
 </ul>
 
         <div class=""book-extra"">
@@ -102,7 +75,7 @@ <h2>Software information<a class=""anchor"" aria-label=""anchor"" href=""#software-in
 ## Running under: macOS Catalina 10.15.7
 ## 
 ## Matrix products: default
-## BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
+## BLAS:   /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.dylib
 ## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib
 ## 
 ## locale:
@@ -148,7 +121,7 @@ <h2>Software information<a class=""anchor"" aria-label=""anchor"" href=""#software-in
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-14.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-15.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/reference-keys.txt---
@@ -12,12 +12,6 @@ fig:burnin
 fig:bgr
 fig:tracechainlength
 fig:acfchainlength
-fig:pressure-1
-fig:pressure-2
-fig:unnamed-chunk-100
-fig:unnamed-chunk-101
-fig:unnamed-chunk-165
-fig:unnamed-chunk-182
 crashcourse
 introduction
 bayes-theorem
@@ -30,279 +24,3 @@ chain-length
 what-if-you-have-issues-of-convergence
 summary
 further-reading
-intronimble
-what-is-nimble
-load-nimble-package
-build-model-made-of-likelihood-and-priors
-syntax-whats-newbetterdifferent
-read-in-data
-distinguish-constants-and-data
-specify-initial-values
-which-parameters-to-save
-mcmc-details
-run-model-tadaa
-explore-mcmc-outputs
-numerical-summaries
-trace-and-posterior-density
-our-nimble-workflow-so-far
-but-nimble-gives-full-access-to-the-mcmc-engine
-useful-resources
-hmmcapturerecapture
-back-to-our-survival-example
-longitudinal-data
-a-model-for-longitudinal-survival-data
-markov-process
-transition-matrix
-initial-states
-likelihood
-example
-our-model
-our-model-1
-nimble-implementation
-nimble-code
-note
-nimble-awesomness
-converting-to-nimble-from-jags-openbugs-or-winbugs
-constants-and-data
-initial-values
-parameters-to-monitor
-mcmc-details-1
-run-nimble
-posterior-distribution-of-survival
-unfortunately-this-is-the-data-we-wish-we-had.
-in-real-life
-the-truth-is-in-z
-dead-animals-go-undetected
-alive-animals-may-be-detected-or-not
-observation-matrix
-markov-model
-hidden-markov-model
-hidden-markov-model-for-survival
-hmm-likelihood
-example-1
-example-2
-estimating-the-latent-states-z-or-not
-our-model-2
-nimble-implementation-1
-priors
-hmm-ingredients
-likelihood-1
-constants
-data
-initial-values-1
-parameters-to-monitor-1
-mcmc-details-2
-run-nimble-1
-posterior-distribution-of-survival-1
-further-reading-1
-survival
-history-of-the-cormack-jolly-seber-cjs-model
-what-weve-seen-so-far
-in-the-cjs-model-survival-and-recapture-are-time-varying
-capture-mark-and-recapture
-capture-mark-and-recapture-1
-the-famous-dipper-example
-dippers-captured-and-recaptured-between-1981-and-1987-with-known-sex-and-wing-length
-back-to-nimble.
-our-model-so-far-phi-p
-our-model-so-far-phi-p-1
-the-cjs-model-phi_t-p_t
-the-cjs-model-phi_t-p_t-1
-the-cjs-model-phi_t-p_t-2
-the-cjs-model-phi_t-p_t-3
-the-cjs-model-phi_t-p_t-4
-the-cjs-model-phi_t-p_t-5
-time-varying-survival-phi_t-p
-time-varying-survival-phi_t-p-1
-time-varying-detection-phi-p_t
-time-varying-detection-phi-p_t-1
-how-to-select-a-best-model-model-selection
-akaike-information-criterion-aic
-bayesian-version
-how-to-compute-waic-in-nimble
-dipper-example---continued
-can-we-explain-time-variation-embrace-heterogeneity
-regression-intercept-and-slope
-time-dependent-covariate-constrained-survival-probability-estimates
-embrace-heterogeneity
-what-about-individual-heterogeneity
-sex-and-wing-length-in-dipper
-sex-effect
-nimble-implementation-with-sex-as-a-covariate
-nimble-implementation-with-nested-indexing
-what-about-wing-length
-wing-length
-what-if-covariates-vary-with-individual-and-time
-why-bayes-incorporate-prior-information.
-vague-prior
-how-to-incorporate-prior-information
-how-to-incorporate-prior-information-1
-compare-survival-posterior-with-and-without-informative-prior
-prior-elicitation-via-moment-matching
-moment-matching
-prior-predictive-checks
-linear-regression
-logistic-regression
-capture-recapture-models-rely-on-assumptions
-parameter-redundancy-issue
-prior-posterior-overlap-for-phi_4-and-phi_6
-prior-posterior-overlap-for-p_3-and-p_7
-what-does-survival-actually-mean-in-capture-recapture
-further-reading-2
-transition
-wintering-site-fidelity-in-canada-geese
-sites-carolinas-chesapeake-mid-atlantic
-biological-inference
-the-model-construction-how-we-should-think.
-the-model-construction-how-we-should-think.-1
-the-model-construction-how-we-should-think.-2
-the-model-construction-how-we-should-think.-3
-hmm-model-for-dispersal-with-2-sites-drop-carolinas
-hmm-model-for-dispersal-with-2-sites-drop-carolinas-1
-hmm-model-for-dispersal-with-2-sites-drop-carolinas-2
-our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b
-our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-1
-our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-2
-our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-3
-our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-4
-our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-5
-what-if-there-are-three-sites
-nimble-implementation-of-the-dirichlet-prior
-nimble-implementation-of-the-dirichlet-prior-1
-multinomial-logit
-nimble-implementation-of-the-dirichlet-prior-2
-nimble-implementation-of-the-dirichlet-prior-3
-sites-may-be-states.
-examples-of-multistate-models
-sooty-shearwater-david-boyle
-sooty-shearwaters-and-life-history-tradeoffs
-sooty-shearwaters-and-life-history-tradeoffs-1
-hmm-model-for-transition-between-states
-hmm-model-for-transition-between-states-1
-our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b
-our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-1
-our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-2
-our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-3
-our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-4
-multistate-models-are-very-flexible
-access-to-reproduction
-access-to-reproduction-1
-temporary-emigration
-combination-of-life-and-dead-encounters
-issue-of-local-minima
-data-1
-further-reading-3
-covariates
-uncertainty
-examples
-examples-1
-sooty-shearwater-david-boyle-1
-uncertainty-in-breeding-status
-how-states-generate-observations
-how-states-generate-observations-1
-how-states-generate-observations-2
-how-states-generate-observations-3
-how-states-generate-observations-4
-hmm-model-for-breeding-states-with-uncertainty
-hmm-model-for-breeding-states-with-uncertainty-1
-hmm-model-for-breeding-states-with-uncertainty-2
-hmm-model-for-breeding-states-with-uncertainty-3
-our-model-phi_b-phi_nb-psi_bnb-psi_nbb-p_b-p_nb-beta_b-beta_nb-pi
-our-model-phi_b-phi_nb-psi_bnb-psi_nbb-p_b-p_nb-beta_b-beta_nb-pi-1
-our-model-phi_b-phi_nb-psi_bnb-psi_nbb-p_b-p_nb-beta_b-beta_nb-pi-2
-our-model-phi_b-phi_nb-psi_bnb-psi_nbb-p_b-p_nb-beta_b-beta_nb-pi-3
-our-model-phi_b-phi_nb-psi_bnb-psi_nbb-p_b-p_nb-beta_b-beta_nb-pi-4
-our-model-phi_b-phi_nb-psi_bnb-psi_nbb-p_b-p_nb-beta_b-beta_nb-pi-5
-our-model-phi_b-phi_nb-psi_bnb-psi_nbb-p_b-p_nb-beta_b-beta_nb-pi-6
-results
-examples-2
-animal-epidemiology-with-uncertain-disease-states
-a-house-finch-with-a-heavy-infection-jim-mondok.
-animal-epidemiology-with-uncertain-disease-states-1
-states-and-observations
-how-states-generate-observations.
-how-states-generate-observations.-1
-how-states-generate-observations.-2
-how-states-generate-observations.-3
-how-states-generate-observations.-4
-hmm-model-for-disease-states-with-uncertainty
-hmm-model-for-disease-states-with-uncertainty-1
-hmm-model-for-disease-states-with-uncertainty-2
-hmm-model-for-disease-states-with-uncertainty-3
-results-1
-examples-3
-individual-heterogeneity-with-finite-mixtures.
-individual-heterogeneity-with-finite-mixtures.-1
-individual-heterogeneity
-hmm-model-for-individual-heterogeneity
-hmm-model-for-individual-heterogeneity-1
-hmm-model-for-individual-heterogeneity-2
-hmm-model-for-individual-heterogeneity-3
-results-2
-hmm-model-for-individual-heterogeneity-4
-hmms-to-analyse-capture-recapture-data
-how-to-make-our-models-remember
-remember-hmm-model-for-dispersal-between-2-sites
-hmm-formulation-of-the-memory-model
-hmm-formulation-of-the-memory-model-1
-hmm-formulation-of-the-memory-model-2
-hmm-formulation-of-the-memory-model-3
-hmm-formulation-of-the-memory-model-4
-further-reading-4
-abundance
-hsmm
-states
-speed
-our-nimble-workflow-so-far-1
-but-nimble-gives-full-access-to-the-mcmc-engine-1
-steps-to-use-nimble-at-full-capacity
-back-to-cjs-models-with-dipper-data.
-define-model
-run-and-summarise
-detailed-nimble-workflow
-build-the-model-r-object
-build-the-mcmc
-compile-the-model-and-mcmc
-run-the-mcmc
-look-at-results
-why-is-it-useful
-use-and-debug-model-in-r
-example-of-debugging-a-model-in-r
-open-the-hood-and-changemodifywrite-samplers
-consider-a-model-with-wing-length-and-individual-random-effect-on-survival.
-trace-plot-for-standard-deviation-of-the-random-effect-default-sampler
-change-samplers
-remove-default-sampler-and-use-slice-sampler
-trace-plot-for-standard-deviation-of-the-random-effect-slice-sampler
-which-is-better
-block-sampling
-block-sampling-1
-block-sampling-2
-summary-of-strategies-for-improving-mcmc
-marginalization
-our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-6
-same-model-with-nimbleecology
-reducing-redundant-calculations
-no-live-demo-but-there-is-a-worksheet.
-future-directions-for-nimble
-further-reading-5
-conclusions
-take-home-messages-and-recommendations
-make-the-best-of-your-data-with-hmms
-bayesian-capture-recapture-analysis-with-hmms
-bayesian-capture-recapture-analysis-with-hmms-1
-till-next-time
-lets-see-if-i-can-put-to-use-my-own-pieces-of-advice---case-studies
-senescence
-heterogeneity
-tradeoffs
-breeding
-rd
-stopover
-disease
-sex
-dependence
-covariateselection
-mortalities
-prevalence
-rmarkdownrender_siteoutput_format-bookdownpdf_book-encoding-utf-8",False,True,Rendering / Conversion,6
oliviergimenez,banana-book,cea95b9cd53d503fd3e33780eaf6ccc8c5704218,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2021-09-14T21:04:16Z,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2021-09-14T21:04:16Z,Indentation error.,.github/workflows/build-book.yaml,False,False,False,False,2,2,4,"---FILE: .github/workflows/build-book.yaml---
@@ -33,8 +33,8 @@ jobs:
       - name : Install tinytex
       - uses: r-lib/actions/setup-tinytex@v1
         run: tlmgr --version
-         
-     - name: Install pak and query dependencies
+
+      - name: Install pak and query dependencies
         run: |
           install.packages(""pak"", repos = ""https://r-lib.github.io/p/pak/dev/"")
           saveRDS(pak::local_dev_deps_tree(), "".github/r-depends.rds"")",False,False,Rendering / Conversion,3
oliviergimenez,banana-book,01585b4c64ded21257cd99e238f01e51b77e5c80,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2021-09-14T19:40:30Z,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2021-09-14T19:40:30Z,Error in build-book.yaml.,.github/workflows/build-book.yaml;hist.png;tikz1ce27c690ba7.aux;tikz1ce27c690ba7.log;tikz1ce27c690ba7.pdf;tikz1ce27c690ba7.tex,False,False,False,False,5,41,46,"---FILE: .github/workflows/build-book.yaml---
@@ -30,11 +30,11 @@ jobs:
       - name: Setup pandoc
         uses: r-lib/actions/setup-pandoc@master
 
-      - name: Install pak and query dependencies
-        run: |
-          install.packages(""pak"", repos = ""https://r-lib.github.io/p/pak/dev/"")
-          saveRDS(pak::local_dev_deps_tree(), "".github/r-depends.rds"")
-        shell: Rscript {0}
+      # - name: Install pak and query dependencies
+      #   run: |
+      #     install.packages(""pak"", repos = ""https://r-lib.github.io/p/pak/dev/"")
+      #     saveRDS(pak::local_dev_deps_tree(), "".github/r-depends.rds"")
+      #   shell: Rscript {0}
 
       - name: Cache R packages
         uses: actions/cache@v2

---FILE: tikz1ce27c690ba7.aux---
@@ -1,2 +0,0 @@
-\relax 
-\gdef \@abspage@last{1}

---FILE: tikz1ce27c690ba7.tex---
@@ -1,34 +0,0 @@
-\documentclass[tikz]{standalone}
-\usepackage{amsmath}
-\usetikzlibrary{matrix}
-%% EXTRA_TIKZ_PREAMBLE_CODE %%
-\begin{document}
-%% TIKZ_CODE %%
-\usetikzlibrary{arrows, fit, positioning, automata}
-\begin{tikzpicture}[node distance = 2cm]
-\tikzset{state/.style = {circle, draw, minimum size = 30pt, scale = 3, line width=1pt}}
-\node [state,fill=lightgray!75] (6) [] {$z_{t}$};
-\node [state,fill=lightgray!75] (5) [left = 20mm of 6] {$z_{t-1}$};
-\node [state,fill=lightgray!75] (4) [left = 20mm of 5] {$z_{t-2}$};
-\node [state,fill=lightgray!75] (3) [left = 20mm of 4] {$\cdots$};
-\node [state,fill=lightgray!75] (7) [right = 20mm of 6] {$z_{t+1}$};
-\node [state,fill=lightgray!75] (8) [right = 20mm of 7] {$z_{t+2}$};
-\node [state,fill=lightgray!75] (9) [right = 20mm of 8] {$\cdots$};
-\node [state,fill=white] (16) [above = 20mm of 6] {$y_{t}$};
-\node [state,fill=white] (15) [above = 20mm of 5] {$y_{t-1}$};
-\node [state,fill=white] (14) [above = 20mm of 4] {$y_{t-2}$};
-\node [state,fill=white] (17) [above = 20mm of 7] {$y_{t+1}$};
-\node [state,fill=white] (18) [above = 20mm of 8] {$y_{t+2}$};
-\draw[->,black, line width=0.25mm,-latex] (3) to (4);
-\draw[->,black, line width=0.25mm,-latex] (4) to (5);
-\draw[->,black, line width=0.25mm,-latex] (5) to (6);
-\draw[->,black, line width=0.25mm,-latex] (6) to (7);
-\draw[->,black, line width=0.25mm,-latex] (7) to (8);
-\draw[->,black, line width=0.25mm,-latex] (8) to (9);
-\draw[->,black, line width=0.25mm,-latex] (4) to (14);
-\draw[->,black, line width=0.25mm,-latex] (5) to (15);
-\draw[->,black, line width=0.25mm,-latex] (6) to (16);
-\draw[->,black, line width=0.25mm,-latex] (7) to (17);
-\draw[->,black, line width=0.25mm,-latex] (8) to (18);
-\end{tikzpicture}
-\end{document}",False,False,Environment / Configuration,4
oliviergimenez,banana-book,69814ee6a66f30338f14fa9d429b621724e8db78,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2021-09-10T10:37:34Z,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2021-09-10T10:37:34Z,"Draft of Bayes/MCMC chapter, focus on convergence issues.",01-bayesMCMC.Rmd;docs/404.html;docs/crashcourse.html;docs/reference-keys.txt;hist.png,True,False,True,False,338,313,651,"---FILE: 01-bayesMCMC.Rmd---
@@ -148,16 +148,16 @@ There are two computational challenges with this formula. First, do we really wi
 
 ## Bayesian computation with Markov chain Monte Carlo (MCMC)
 
-In the early 1990s, statisticians rediscovered work from the 1950's in physics. In a famous paper that would lay the fundations of algorithms for implementing Bayes' theorem, the authors use simulations to approximate posterior distributions with some precision by drawing large samples. This is a neat trick to avoid explicit calculation of multi-dimensional integrals we struggle with when using Bayes' theorem. These simulation algorithms are called Markov chain Monte Carlo (MCMC), and they definitely gave a boost to Bayesian statistics. **simulation algorithm ou stochastic algorithms. Expliquer.**
+In the early 1990s, statisticians rediscovered work from the 1950's in physics. In a famous paper that would lay the fundations of modern Bayesian statistics, the authors use simulations to approximate posterior distributions with some precision by drawing large samples. This is a neat trick to avoid explicit calculation of multi-dimensional integrals we struggle with when using Bayes' theorem. These simulation algorithms are called Markov chain Monte Carlo (MCMC), and they definitely gave a boost to Bayesian statistics. **simulation algorithm ou stochastic algorithms. Expliquer.**
 
 ```{r, echo = FALSE, fig.align='center', fig.cap = ""MCMC article cover. Source: [The Journal of Chemical Physics](https://aip.scitation.org/doi/10.1063/1.1699114)""}
 knitr::include_graphics(""images/metropolis.png"")
 ```
 
-Why are MCMC methods so useful? Well to understand *why*, we need to better explain the *what*. MCMC are stochastic algorithms to produce sequence of dependent random numbers from a Markov chain. What is a Markov chain? A Markov chain is a discrete sequence of states, in which the probability of an event depends only on the state in the previous event. **donner example de la m√©t√©o?** By construction, a Markov chain has an equilibrium (also know as stationary) distribution. **expliquer** The cool thing is that the equilibrium distribution is the desired posterior distribution. Yes, MCMC algorithms are used to construct a Markov chain with a given stationary distribution set to be the posterior distribution. This summarizes the core spirit of MCMC algorithms. 
+Why are MCMC methods so useful? Well to understand *why*, we need to better explain the *what*. MCMC are stochastic algorithms to produce sequence of dependent random numbers from a Markov chain. What is a Markov chain? A Markov chain is a discrete sequence of states, in which the probability of an event depends only on the state in the previous event. **donner example de la m√©t√©o?** By construction, a Markov chain has an equilibrium (also know as stationary) distribution. **expliquer** The cool thing is that the equilibrium distribution is the desired posterior distribution. **Expliquer Monte Carlo avec exemple simple, idem pour Markov chain** Yes, MCMC algorithms are used to construct a Markov chain with a given stationary distribution set to be the posterior distribution. This summarizes the core spirit of MCMC algorithms. 
 **why is it so cool? plut√¥t que de simuler comme des dingues dans tous les snes, il suffit de tirer dans Markov chain, et eventuellement, on converge vers distribution statitionnaire qui est l'a posteriori! Also For the MCMC algorithm, the posterior distribution is only needed to be known up to proportionality.**
 
-There are several ways of constructing these chains: e.g., Metropolis-Hastings, Gibbs sampler. Here I will illustrate the Metropolis algorithm and how to implement it in practice.
+There are several ways of constructing these chains: e.g., Metropolis-Hastings, Gibbs sampler. Here I will illustrate the Metropolis algorithm and how to implement it in practice. **Diff√©rence entre Metropolis et MH**
 
 Let's go back to our example on animal survival estimation. We illustrate sampling from survival posterior distribution. We write functions for likelihood, prior and posterior.
 
@@ -467,11 +467,141 @@ knitr::include_graphics(""images/traceplotMCMC.gif"")
 knitr::include_graphics(""images/histMCMC.gif"")
 ```
 
-**Introduire l'id√©e de grass, note de bas de page vers Steve Brooks comm pers, et transition vers next section avec l'id√©e de comment on regarde la convergence** Once the stationary distribution is reached, we can regard the realisations of the chain as a (dependent) sample from the posterior distribution (and obtain Monte Carlo estimates). In the next section, we consider several important implementation issues. **coder Metropolis d'au-dessus dans Nimble**
+**Introduire l'id√©e de grass, note de bas de page vers Steve Brooks comm pers, et transition vers next section avec l'id√©e de comment on regarde la convergence** We discard some realisations of the Markov chain before convergence is achieved. Once the stationary distribution is reached **use stationary or target or limiting**, we can regard the realisations of the chain as a (dependent) sample from the posterior distribution, and obtain Monte Carlo estimates of parameters. In the next section, we consider several important implementation issues. **coder Metropolis d'au-dessus dans Nimble**
 
 ## Assessing convergence
 
-**Les principales questions on doit r√©pondre pour check convergence. Noter qu'en freq c'est plus ou moins fait en backstage. En MCMC pas grand chose pour automatiser.**
+How do good chains behave? When implementing MCMC, we need to i) ensure that our Markov chain explores efficiently the parameter space, i) determine how long it takes and whether our Markov chain converges to the target distribution, and the same target distribution if we run several Markov chains, and iii) the number of iterations post-convergence to get reasonable Monte Carlo estimates (numerical summaries). 
+
+### Burn-in
+  
+In practice, we discard observations from the start of the Markov chain and just use observations from the chain once it has converged. The initial observations that we discard are usually referred to as the **burn-in**. The simplest method to determine the length of the burn-in period is to look at trace plots. Going back to our example, we see from the trace plot in Figure \@ref(fig:burnin) that we need at least 500 iterations to achieve convergence toward an average survival around 0.3. It is always better to be conservative when specifying the length of the burn-in period, and in this example, we would use 750 or even 1000 iterations as a burn-in. **pr√©ciser qu'il faut faire qqs runs pr√©liminaires pour d√©terminer le burn-in; ajouter des cas pathologiques ou faire des renvois aux sections suiantes, en particuier les minimal locaux ou par redundancy?**
+
+```{r burnin, echo = FALSE, fig.cap = ""Determining the length of the burn-in period.""}
+
+# set up the scene
+steps <- 1000
+theta.post <- rep(NA, steps)
+set.seed(1234)
+
+# pick starting value (step 1)
+inits <- 0.99
+theta.post[1] <- inits
+
+for (t in 2:steps){ # repeat steps 2-4 (step 5)
+  
+  # propose candidate value for prob of success (step 2)
+  theta_star <- move(theta.post[t-1], away = 0.1)
+  
+  # calculate ratio R (step 3)
+  pstar <- posterior(survived, p = theta_star)  
+  pprev <- posterior(survived, p = theta.post[t-1])
+  logR <- pstar - pprev
+  R <- exp(logR)
+  
+  # decide to accept candidate value or to keep current value (step 4)
+  accept <- rbinom(1, 1, prob = min(R, 1))
+  theta.post[t] <- ifelse(accept == 1, theta_star, theta.post[t-1])
+}
+
+df <- data.frame(x = 1:steps, y = theta.post)
+df %>%
+  ggplot() +
+  geom_line(aes(x = x, y = y), size = 1.2, color = wesanderson::wes_palettes$Zissou1[1]) + 
+  labs(x = ""iterations"", y = ""survival"") + 
+  theme_light(base_size = 14) + 
+  annotate(""rect"", 
+           xmin = 0, 
+           xmax = 500, 
+           ymin = 0.1, 
+           ymax = 1, 
+           alpha = .3) +
+  scale_y_continuous(expand = c(0,0))
+```
+
+### Potential scale reduction factor
+
+Inspecting the trace plot for a single run of the Markov chain is useful. We usually run the Markov chain several times, starting from different over-dispersed points, to check that all replicates achieve the same target distribution. This approach is formalised by using the Brooks-Gelman-Rubin statistic $\hat{R}$ which measures the ratio of the total variability combining multiple chains (between-chain plus within-chain) to the within-chain variability. The BGR statistic asks whether there is a chain effect, and is very much alike the $F$ test in an analysis of variance. Values below $1.2$ indicate likely convergence. **check 1.1 or 1.2** 
+
+```{r, echo=FALSE}
+
+# function to simulate
+simul.bgr <- function(steps, inits){
+  
+  nb.replicates <- length(inits)
+  theta.post <- matrix(NA, nrow = nb.replicates, ncol = steps)
+  
+  for (i in 1:nb.replicates){
+    theta.post[i,1] <- inits[i]
+    for (t in 2:steps){ # repeat steps 2-4 (step 5)
+      
+      # propose candidate value for prob of success (step 2)
+      theta_star <- move(theta.post[i,t-1], away = 0.1)
+      
+      # calculate ratio R (step 3)
+      pstar <- posterior(survived, p = theta_star)  
+      pprev <- posterior(survived, p = theta.post[i,t-1])
+      logR <- pstar - pprev
+      R <- exp(logR)
+      
+      # decide to accept candidate value or to keep current value (step 4)
+      accept <- rbinom(1, 1, prob = min(R, 1))
+      theta.post[i,t] <- ifelse(accept == 1, theta_star, theta.post[i,t-1])
+    }
+  }
+  
+  df <- data.frame(x = rep(1:steps, nb.replicates), 
+                   y = c(t(theta.post)), 
+                   chain = paste0(""chain "",gl(nb.replicates, steps))) %>%
+    filter(x > round(steps/2)) # apply burnin (half number of iterations)
+  
+  # df %>%
+  #   ggplot() +
+  #   geom_line(aes(x = x, y = y, group = chain, color = chain), size = 1.2) + 
+  #   scale_colour_manual(values = wesanderson::wes_palettes$Zissou1[2:(nb.replicates+1)])+
+  #   labs(x = ""iterations"", y = ""survival"", color = NULL) + 
+  #   theme_light(base_size = 14) + 
+  #   annotate(""rect"", 
+  #            xmin = 0, 
+  #            xmax = 750, 
+  #            ymin = 0.1, 
+  #            ymax = 1, 
+  #            alpha = .1) +
+  #   scale_y_continuous(expand = c(0,0))
+  
+  # compute BGR (R-hat)
+  num <- quantile(df$y, probs = c(20/100, 80/100))[2] - quantile(df$y, probs = c(20/100, 80/100))[1]
+  den <- df %>%
+    group_by(chain) %>%
+    summarise(ci = quantile(y, probs = c(20/100, 80/100))) %>%
+    mutate(diff = ci - lag(ci, default = ci[1])) %>%
+    filter(diff != 0) %>%
+    pull(diff) %>%
+    mean()
+  
+  bgr <- round(num / den, 3)
+  return(bgr)
+}
+
+set.seed(1234)
+steps <- seq(100, 5000, 100)
+bgr <- rep(NA, length(steps))
+for (i in 1:length(steps)){
+  bgr[i] <- simul.bgr(steps = steps[i], inits = c(0.2, 0.8))
+}
+df <- data.frame(iterations = steps, bgr = bgr)
+```
+
+Back to our example, we run two replicates of the Markov chain with starting values 0.2 and 0.8 using 100 up to 5000 iterations. 
+
+```{r bgr, echo=FALSE, fig.cap = ""Brooks-Gelman-Rubin statistic.""}
+df %>%
+  ggplot() + 
+  geom_line(aes(x = iterations, y = bgr), size = 1.2) +
+  labs(y = ""BGR statistic"")
+```
+
+It is important to bear in mind that a value near 1 for the BGR statistic is only a necessary *but not sufficient* condition for convergence. In other words, this diagnostic cannot tell you for sure that the Markov chain has achieved convergence, only that it has not.
 
 ### Mixing and autocorrelation
   
@@ -614,65 +744,7 @@ trace / (plot1 + plot2 + plot3)
 
 + ACF plots provide the autocorrelation between successively sampled values separated by $k$ iterations, referred to as lag, (i.e. $\text{cor}(\theta_t, \theta_{t+k})$) for increasing values of $k$.
 
-### How do good chains behave? 
-  
-+ Converge to same target distribution; discard some realisations of Markov chain before convergence is achieved.
-
-+ Once there, explore efficiently: The post-convergence sample size required for suitable numerical summaries.
-
-+ Therefore, we are looking to determine how long it takes for the Markov chain to converge to the stationary distribution.
-
-+ In practice, we must discard observations from the start of the chain and just use observations from the chain once it has converged.
-
-+ The initial observations that we discard are referred to as the **burn-in**.
-
-+ Simplest method to determine length of burn-in period is to look at trace plots.
-
-### Burn-in
-  
-```{r, echo = FALSE}
-
-# set up the scene
-steps <- 1000
-theta.post <- rep(NA, steps)
-set.seed(1234)
-
-# pick starting value (step 1)
-inits <- 0.99
-theta.post[1] <- inits
-
-for (t in 2:steps){ # repeat steps 2-4 (step 5)
-  
-  # propose candidate value for prob of success (step 2)
-  theta_star <- move(theta.post[t-1], away = 0.1)
-  
-  # calculate ratio R (step 3)
-  pstar <- posterior(survived, p = theta_star)  
-  pprev <- posterior(survived, p = theta.post[t-1])
-  logR <- pstar - pprev
-  R <- exp(logR)
-  
-  # decide to accept candidate value or to keep current value (step 4)
-  accept <- rbinom(1, 1, prob = min(R, 1))
-  theta.post[t] <- ifelse(accept == 1, theta_star, theta.post[t-1])
-}
-
-df <- data.frame(x = 1:steps, y = theta.post)
-df %>%
-  ggplot() +
-  geom_line(aes(x = x, y = y), size = 1.2, color = wesanderson::wes_palettes$Zissou1[1]) + 
-  labs(x = ""iterations"", y = ""values from posterior distribution"") + 
-  theme_light(base_size = 14) + 
-  annotate(""rect"", 
-           xmin = 0, 
-           xmax = 500, 
-           ymin = 0.1, 
-           ymax = 1, 
-           alpha = .3) +
-  scale_y_continuous(expand = c(0,0))
-```
 
-If simulations cheap, be conservative.
 
 ### Effective sample size `n.eff`
   
@@ -685,14 +757,6 @@ If simulations cheap, be conservative.
 * Check the `n.eff` of any interesting parameter combinations.
 * We need $\text{n.eff} \geq 100$ independent steps. 
 
-### Potential scale reduction factor
-  
-+ Gelman-Rubin statistic $\hat{R}$
-+ Measures the ratio of the total variability combining multiple chains (between-chain plus within-chain) to the within-chain variability. 
-+ Asks the question is there a chain effect? Very much alike the $F$ test in an ANOVA. 
-+ Values near $1$ indicates likely convergence, a value of $\leq 1.1$ is considered acceptable.
-+ Necessary condition, not sufficient; In other words, these diagnostics cannot tell you that you have converged for sure, only that you have not. 
-
 ### What if you have issues of convergence?
   
 + Increase burn-in, sample more.

---FILE: docs/404.html---
@@ -1,33 +1,53 @@
-<!DOCTYPE html>
+<!doctype html>
 <html lang=""en"">
 <head>
-<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
-<meta charset=""utf-8"">
-<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<title>Page not found | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</title>
-<meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are..."">
-<meta name=""generator"" content=""bookdown 0.23 with bs4_book()"">
-<meta property=""og:title"" content=""Page not found | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R"">
-<meta property=""og:type"" content=""book"">
-<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/404.html"">
-<meta property=""og:image"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop//images/satellite.png"">
-<meta property=""og:description"" content=""The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are..."">
-<meta name=""twitter:card"" content=""summary"">
-<meta name=""twitter:title"" content=""Page not found | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R"">
-<meta name=""twitter:description"" content=""The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are..."">
-<meta name=""twitter:image"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop//images/satellite.png"">
-<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs/header-attrs.js""></script><script src=""libs/jquery/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<link href=""libs/bootstrap/bootstrap.min.css"" rel=""stylesheet"">
-<script src=""libs/bootstrap/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat/tabs.js""></script><script src=""libs/bs3compat/bs3compat.js""></script><link href=""libs/bs4_book/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book/bs4_book.js""></script><script src=""libs/kePrint/kePrint.js""></script><link href=""libs/lightable/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+  <meta charset=""utf-8"" />
+  <meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+
+  <title>Page not found | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</title>
+
+    <meta name=""author"" content=""Olivier Gimenez"" />
+  
+   <meta name=""description"" content=""This is a comprehensive and applied textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."" />
+   <meta name=""generator"" content=""placeholder"" />
+  <meta property=""og:title"" content=""Page not found | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R"" />
+  <meta property=""og:type"" content=""book"" />
+  <meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/"" />
+  <meta property=""og:image"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop//images/satellite.png"" />
+  <meta property=""og:description"" content=""This is a comprehensive and applied textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."" />
+
+  <meta name=""twitter:card"" content=""summary"" />
+  <meta name=""twitter:title"" content=""Page not found | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R"" />
+  
+  <meta name=""twitter:description"" content=""This is a comprehensive and applied textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."" />
+  <meta name=""twitter:image"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop//images/satellite.png"" />
+  <!-- JS -->
+  <script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script>
+  <script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script>
+  <script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script>
+    <script src=""libs/header-attrs-2.10/header-attrs.js""></script>
+    <script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script>
+    <meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"" />
+    <link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"" />
+    <script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script>
+    <script src=""libs/bs3compat-0.2.5.1/tabs.js""></script>
+    <script src=""libs/bs3compat-0.2.5.1/bs3compat.js""></script>
+    <link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"" />
+    <script src=""libs/bs4_book-1.0.0/bs4_book.js""></script>
+    <script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script>
+  <script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script>
+
+  <!-- CSS -->
+    <link rel=""stylesheet"" href=""bs4_style.css"" />
+  
 </head>
+
 <body data-spy=""scroll"" data-target=""#toc"">
 
 <div class=""container-fluid"">
 <div class=""row"">
-  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book"">
+    <a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
 
     <div class=""d-flex align-items-start justify-content-between"">
       <h1>
@@ -39,76 +59,62 @@ <h1>
     <div id=""main-nav"" class=""collapse-lg"">
       <form role=""search"">
         <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
-</form>
-
-      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
-        <ul class=""book-toc list-unstyled"">
-<li><a class="""" href=""index.html"">Welcome</a></li>
-<li><a class="""" href=""preface.html"">Preface</a></li>
-<li><a class="""" href=""about-the-author.html"">About the Author</a></li>
-<li class=""book-part"">Theory</li>
-<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
-<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> Introduction to Nimble</a></li>
-<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
-<li><a class="""" href=""transition.html""><span class=""header-section-number"">5</span> Transition</a></li>
-<li><a class="""" href=""covariates.html""><span class=""header-section-number"">6</span> Covariates</a></li>
-<li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">7</span> Uncertainty in state assignment</a></li>
-<li><a class="""" href=""abundance.html""><span class=""header-section-number"">8</span> Abundance</a></li>
-<li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
-<li><a class="""" href=""states.html""><span class=""header-section-number"">10</span> Hidden states</a></li>
-<li><a class="""" href=""speed.html""><span class=""header-section-number"">11</span> Speed up MCMC</a></li>
-<li><a class="""" href=""conclusions.html""><span class=""header-section-number"">12</span> Conclusions</a></li>
-<li class=""book-part"">Case studies</li>
-<li><a class="""" href=""senescence.html""><span class=""header-section-number"">13</span> Actuarial senescence</a></li>
-<li><a class="""" href=""heterogeneity.html""><span class=""header-section-number"">14</span> Individual heterogeneity</a></li>
-<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">15</span> Life-history tradeoffs</a></li>
-<li><a class="""" href=""breeding.html""><span class=""header-section-number"">16</span> Breeding dynamics</a></li>
-<li><a class="""" href=""rd.html""><span class=""header-section-number"">17</span> Robust design</a></li>
-<li><a class="""" href=""stopover.html""><span class=""header-section-number"">18</span> Stopover duration</a></li>
-<li><a class="""" href=""disease.html""><span class=""header-section-number"">19</span> Disease dynamics</a></li>
-<li><a class="""" href=""sex.html""><span class=""header-section-number"">20</span> Sex uncertainty</a></li>
-<li><a class="""" href=""dependence.html""><span class=""header-section-number"">21</span> Dependence among individuals</a></li>
-<li><a class="""" href=""covariateselection.html""><span class=""header-section-number"">22</span> Individual and temporal variability</a></li>
-<li><a class="""" href=""mortalities.html""><span class=""header-section-number"">23</span> Cause-specific mortalities</a></li>
-<li><a class="""" href=""prevalence.html""><span class=""header-section-number"">24</span> Prevalence</a></li>
-<li><a class="""" href=""faq.html"">FAQ</a></li>
-<li><a class="""" href=""references.html"">References</a></li>
-</ul>
+      </form>
+
+      <nav aria-label=""Table of contents"">
+        <h2>Table of contents</h2>
+        <div id=""book-toc""></div>
 
         <div class=""book-extra"">
-          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
+          <p><a id=""book-repo"" href=""#"">View book source <i class=""fab fa-github""></i></a></li></p>
         </div>
       </nav>
-</div>
-  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""page-not-found"" class=""section level1"">
-<h1>Page not found<a class=""anchor"" aria-label=""anchor"" href=""#page-not-found""><i class=""fas fa-link""></i></a>
-</h1>
+    </div>
+  </header>
+
+  <main class=""col-sm-12 col-md-9 col-lg-7"" id=""content"">
+<div id=""page-not-found"" class=""section level1"">
+<h1>Page not found</h1>
 <p>The page you requested cannot be found (perhaps it was moved or renamed).</p>
 <p>You may want to try searching to find the page's new location, or use
 the table of contents to find the page you are looking for.</p>
 </div>
-  <div class=""chapter-nav"">
-<div class=""empty""></div>
-<div class=""empty""></div>
-</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
-    </div>
+  </main>
+
+  <div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page"">
+      <h2>On this page</h2>
+      <div id=""book-on-this-page""></div>
+
+      <div class=""book-extra"">
+        <ul class=""list-unstyled"">
+          <li><a id=""book-source"" href=""#"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""#"">Edit this page <i class=""fab fa-github""></i></a></li>
+        </ul>
+      </div>
+    </nav>
+  </div>
 
 </div>
 </div> <!-- .container -->
 
-<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
+<footer class=""bg-primary text-light mt-5"">
+  <div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-09.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-10.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>This book was built by the <a class=""text-light"" href=""https://bookdown.org"">bookdown</a> R package.</p>
   </div>
 
 </div></div>
-</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
+</footer>
+
+
+<!-- dynamically load mathjax for compatibility with self-contained -->
+<script>
   (function () {
     var script = document.createElement(""script"");
     script.type = ""text/javascript"";
@@ -120,7 +126,8 @@ <h1>Page not found<a class=""anchor"" aria-label=""anchor"" href=""#page-not-found""><
     script.src = src;
     document.getElementsByTagName(""head"")[0].appendChild(script);
   })();
-</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+</script>
+<script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
 for (let popover of popovers) {
   const div = document.createElement('div');
   div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
@@ -138,4 +145,5 @@ <h1>Page not found<a class=""anchor"" aria-label=""anchor"" href=""#page-not-found""><
 }
 </script>
 </body>
+
 </html>

---FILE: docs/crashcourse.html---
@@ -4,24 +4,23 @@
 <meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
 <meta charset=""utf-8"">
 <meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<title>Chapter 1 Bayesian statistics &amp; MCMC | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</title>
+<title>Chapter 2 Bayesian statistics &amp; MCMC | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</title>
 <meta name=""author"" content=""Olivier Gimenez"">
-<meta name=""description"" content=""1.1 Introduction In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to..."">
+<meta name=""description"" content=""2.1 Introduction In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to..."">
 <meta name=""generator"" content=""bookdown 0.23 with bs4_book()"">
-<meta property=""og:title"" content=""Chapter 1 Bayesian statistics &amp; MCMC | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R"">
+<meta property=""og:title"" content=""Chapter 2 Bayesian statistics &amp; MCMC | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R"">
 <meta property=""og:type"" content=""book"">
 <meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/crashcourse.html"">
 <meta property=""og:image"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop//images/satellite.png"">
-<meta property=""og:description"" content=""1.1 Introduction In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to..."">
+<meta property=""og:description"" content=""2.1 Introduction In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to..."">
 <meta name=""twitter:card"" content=""summary"">
-<meta name=""twitter:title"" content=""Chapter 1 Bayesian statistics &amp; MCMC | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R"">
-<meta name=""twitter:description"" content=""1.1 Introduction In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to..."">
+<meta name=""twitter:title"" content=""Chapter 2 Bayesian statistics &amp; MCMC | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R"">
+<meta name=""twitter:description"" content=""2.1 Introduction In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to..."">
 <meta name=""twitter:image"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop//images/satellite.png"">
-<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs/header-attrs.js""></script><script src=""libs/jquery/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<link href=""libs/bootstrap/bootstrap.min.css"" rel=""stylesheet"">
-<script src=""libs/bootstrap/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat/tabs.js""></script><script src=""libs/bs3compat/bs3compat.js""></script><link href=""libs/bs4_book/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book/bs4_book.js""></script><script src=""libs/kePrint/kePrint.js""></script><link href=""libs/lightable/lightable.css"" rel=""stylesheet"">
-<script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.10/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.2.5.1/tabs.js""></script><script src=""libs/bs3compat-0.2.5.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 
@@ -42,83 +41,51 @@ <h1>
 </form>
 
       <nav aria-label=""Table of contents""><h2>Table of contents</h2>
-        <ul class=""book-toc list-unstyled"">
-<li><a class="""" href=""index.html"">Welcome</a></li>
-<li><a class="""" href=""preface.html"">Preface</a></li>
-<li><a class="""" href=""about-the-author.html"">About the Author</a></li>
-<li class=""book-part"">Theory</li>
-<li><a class=""active"" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
-<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> Introduction to Nimble</a></li>
-<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
-<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
-<li><a class="""" href=""transition.html""><span class=""header-section-number"">5</span> Transition</a></li>
-<li><a class="""" href=""covariates.html""><span class=""header-section-number"">6</span> Covariates</a></li>
-<li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">7</span> Uncertainty in state assignment</a></li>
-<li><a class="""" href=""abundance.html""><span class=""header-section-number"">8</span> Abundance</a></li>
-<li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
-<li><a class="""" href=""states.html""><span class=""header-section-number"">10</span> Hidden states</a></li>
-<li><a class="""" href=""speed.html""><span class=""header-section-number"">11</span> Speed up MCMC</a></li>
-<li><a class="""" href=""conclusions.html""><span class=""header-section-number"">12</span> Conclusions</a></li>
-<li class=""book-part"">Case studies</li>
-<li><a class="""" href=""senescence.html""><span class=""header-section-number"">13</span> Actuarial senescence</a></li>
-<li><a class="""" href=""heterogeneity.html""><span class=""header-section-number"">14</span> Individual heterogeneity</a></li>
-<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">15</span> Life-history tradeoffs</a></li>
-<li><a class="""" href=""breeding.html""><span class=""header-section-number"">16</span> Breeding dynamics</a></li>
-<li><a class="""" href=""rd.html""><span class=""header-section-number"">17</span> Robust design</a></li>
-<li><a class="""" href=""stopover.html""><span class=""header-section-number"">18</span> Stopover duration</a></li>
-<li><a class="""" href=""disease.html""><span class=""header-section-number"">19</span> Disease dynamics</a></li>
-<li><a class="""" href=""sex.html""><span class=""header-section-number"">20</span> Sex uncertainty</a></li>
-<li><a class="""" href=""dependence.html""><span class=""header-section-number"">21</span> Dependence among individuals</a></li>
-<li><a class="""" href=""covariateselection.html""><span class=""header-section-number"">22</span> Individual and temporal variability</a></li>
-<li><a class="""" href=""mortalities.html""><span class=""header-section-number"">23</span> Cause-specific mortalities</a></li>
-<li><a class="""" href=""prevalence.html""><span class=""header-section-number"">24</span> Prevalence</a></li>
-<li><a class="""" href=""faq.html"">FAQ</a></li>
-<li><a class="""" href=""references.html"">References</a></li>
-</ul>
+        <ul class=""book-toc list-unstyled""><li><a class="""" href=""index.html""><span class=""header-section-number"">Chapter 2</span> Bayesian statistics &amp; MCMC</a></li></ul>
 
         <div class=""book-extra"">
           <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
         </div>
       </nav>
 </div>
-  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""crashcourse"" class=""section level1"" number=""1"">
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""crashcourse"" class=""section level1"" number=""2"">
 <h1>
-<span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC<a class=""anchor"" aria-label=""anchor"" href=""#crashcourse""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">2</span> Bayesian statistics &amp; MCMC<a class=""anchor"" aria-label=""anchor"" href=""#crashcourse""><i class=""fas fa-link""></i></a>
 </h1>
-<div id=""introduction"" class=""section level2"" number=""1.1"">
+<div id=""introduction"" class=""section level2"" number=""2.1"">
 <h2>
-<span class=""header-section-number"">1.1</span> Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">2.1</span> Introduction<a class=""anchor"" aria-label=""anchor"" href=""#introduction""><i class=""fas fa-link""></i></a>
 </h2>
 <p>In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to implement the Bayesian method for more complex analyses. This is not an exhaustive treatment of Bayesian statistics, but you should get what you need to navigate through the rest of the book.</p>
 </div>
-<div id=""bayes-theorem"" class=""section level2"" number=""1.2"">
+<div id=""bayes-theorem"" class=""section level2"" number=""2.2"">
 <h2>
-<span class=""header-section-number"">1.2</span> Bayes‚Äô theorem<a class=""anchor"" aria-label=""anchor"" href=""#bayes-theorem""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">2.2</span> Bayes‚Äô theorem<a class=""anchor"" aria-label=""anchor"" href=""#bayes-theorem""><i class=""fas fa-link""></i></a>
 </h2>
 <p><strong>Ajouter quelque chose sur la d√©marche scientifique?</strong></p>
 <p>Let‚Äôs not wait any longer and jump into it. Bayesian statistics relies on the Bayes‚Äô theorem named after Reverend Bayes. <strong>expliquer avec des mots ce que fait ce th√©or√®me, puis donner la formule math√©matique</strong></p>
 <div class=""figure"" style=""text-align: center"">
-<span style=""display:block;"" id=""fig:unnamed-chunk-6""></span>
+<span style=""display:block;"" id=""fig:unnamed-chunk-3""></span>
 <img src=""images/amazing-thomas-bayes-illustration.jpg"" alt=""Cartoon of Thomas Bayes with Bayes' theorem in background. Source: [James Kulich](https://www.elmhurst.edu/blog/thomas-bayes/)"" width=""70%""><p class=""caption"">
-Figure 1.1: Cartoon of Thomas Bayes with Bayes‚Äô theorem in background. Source: <a href=""https://www.elmhurst.edu/blog/thomas-bayes/"">James Kulich</a>
+Figure 2.1: Cartoon of Thomas Bayes with Bayes‚Äô theorem in background. Source: <a href=""https://www.elmhurst.edu/blog/thomas-bayes/"">James Kulich</a>
 </p>
 </div>
 <p>The Bayes‚Äô theorem states that for events <span class=""math inline"">\(A\)</span> and <span class=""math inline"">\(B\)</span>, we have:
 <span class=""math display"">\[\Pr(A \mid B) = \displaystyle{\frac{ \Pr(B \mid A) \; \Pr(A)}{\Pr(B)}}\]</span>
 It is all about conditional probabilities, which are not that easy to understand. <strong>What are conditional probabilities? Link towards nice videos</strong>.</p>
 <div class=""figure"" style=""text-align: center"">
-<span style=""display:block;"" id=""fig:unnamed-chunk-7""></span>
+<span style=""display:block;"" id=""fig:unnamed-chunk-4""></span>
 <img src=""images/bayes_neon.jpeg"" alt=""Bayes' theorem spelt out in blue neon at the offices of Autonomy in Cambridge. Source: [Wikipedia](https://en.wikipedia.org/wiki/Bayes%27_theorem)"" width=""400""><p class=""caption"">
-Figure 1.2: Bayes‚Äô theorem spelt out in blue neon at the offices of Autonomy in Cambridge. Source: <a href=""https://en.wikipedia.org/wiki/Bayes%27_theorem"">Wikipedia</a>
+Figure 2.2: Bayes‚Äô theorem spelt out in blue neon at the offices of Autonomy in Cambridge. Source: <a href=""https://en.wikipedia.org/wiki/Bayes%27_theorem"">Wikipedia</a>
 </p>
 </div>
 <p>I don‚Äôt know about you, but I have a hard time not messing the letters around. It is easier to remember Bayes‚Äô theorem written like this:</p>
 <p><span class=""math display"">\[ \Pr(\text{hypothesis} \mid \text{data}) = \frac{ \Pr(\text{data} \mid \text{hypothesis}) \; \Pr(\text{hypothesis})}{\Pr(\text{data})} \]</span>
 The <em>hypothesis</em> is what you want to learn about using the data. For capture-recapture models, the <em>hypothesis</em> is a parameter like detection probability, or regression parameters in a relationship between survival probability and a covariate. <strong>Citer Taj Mahr comme source</strong>. Bayes‚Äô theorem tells you the probability of the hypothesis given the data. This is great because think about it, what is doing science after all? We‚Äôd like to know how plausible is some hypothesis given the data? <strong>dire des trucs sur les termes de droite</strong> In that respect, the Bayesian reasoning matches the scientific reasoning. You might ask then, why is Bayesian statistics not the default in statistics? Clearly, until recently, there were practical problems to implement the Bayesian approach. Recent advances in computational power coupled with the development of new methodology have led to a great increase in the application of Bayesian methods within the last three decades. Also, because of futile wars between (male) statisticians, little progress was made for over two centuries. <strong>en dire un peu plus sur ces guerres</strong></p>
 </div>
-<div id=""what-is-the-bayesian-approach"" class=""section level2"" number=""1.3"">
+<div id=""what-is-the-bayesian-approach"" class=""section level2"" number=""2.3"">
 <h2>
-<span class=""header-section-number"">1.3</span> What is the Bayesian approach?<a class=""anchor"" aria-label=""anchor"" href=""#what-is-the-bayesian-approach""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">2.3</span> What is the Bayesian approach?<a class=""anchor"" aria-label=""anchor"" href=""#what-is-the-bayesian-approach""><i class=""fas fa-link""></i></a>
 </h2>
 <p>Typical statistical problems involve estimating parameter(s) <span class=""math inline"">\(\theta\)</span> with available data. To do so, you might be more used to the frequentist rather than the Bayesian method. The frequentist approach, and in particular maximum likelihood estimation (MLE), assumes that the parameters are fixed, and have unknown values to be estimated. Therefore classical estimates are generally point estimates of the parameters of interest. In contrast, the Bayesian approach assumes that the parameters are not fixed but have some fixed unknown distribution ‚Äì a distribution for the parameter. <strong>qu‚Äôentend-on par distribution?</strong></p>
 <p>The Bayesian approach is based upon the idea that you, the experimenter, begin with some prior beliefs about the system. In other words, you never start from scratch. Then you collect data and update your prior beliefs on the basis of observations. These observations might arise from field or lab work. This updating process is based upon the Bayes‚Äô theorem which we‚Äôve seen earlier:</p>
@@ -131,12 +98,12 @@ <h2>
 <p>Then we have the <span class=""math inline"">\(\color{green}{\text{prior distribution}}\)</span>. This quantity represents what you know before seeing the data. This is the source of much discussion about the Bayesian approach. We‚Äôll get back to it at length.</p>
 <p>Last, we have <span class=""math inline"">\(\color{orange}{\Pr(\text{data}) = \int{L(\text{data} \mid \theta)\Pr(\theta) d\theta}}\)</span> which is a <span class=""math inline"">\(N\)</span>-dimensional integral if <span class=""math inline"">\(\theta = \theta_1, \ldots, \theta_N\)</span>. This quantity is difficult, if not impossible, to calculate. This is one of the reasons why the Bayesian method wasn‚Äôt used until recently. And this is the reason why we need simulation algorithms to estimate posterior distributions. <strong>simulation ou stochastic algorithms? si stochastic, expliquer</strong></p>
 </div>
-<div id=""approximating-posterior-distributions-via-numerical-integration"" class=""section level2"" number=""1.4"">
+<div id=""approximating-posterior-distributions-via-numerical-integration"" class=""section level2"" number=""2.4"">
 <h2>
-<span class=""header-section-number"">1.4</span> Approximating posterior distributions via numerical integration<a class=""anchor"" aria-label=""anchor"" href=""#approximating-posterior-distributions-via-numerical-integration""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">2.4</span> Approximating posterior distributions via numerical integration<a class=""anchor"" aria-label=""anchor"" href=""#approximating-posterior-distributions-via-numerical-integration""><i class=""fas fa-link""></i></a>
 </h2>
 <p>Let‚Äôs take an example. Say we capture, mark and release <span class=""math inline"">\(n = 57\)</span> animals at the beginning of a winter, out of which we recapture <span class=""math inline"">\(y = 19\)</span> animals alive<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;We used this example in King et al.¬†2009&lt;/p&gt;""><sup>1</sup></a>. We‚Äôd like to estimate winter survival <span class=""math inline"">\(\theta\)</span>.</p>
-<div class=""sourceCode"" id=""cb2""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb1""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">y</span> <span class=""op"">&lt;-</span> <span class=""fl"">19</span> <span class=""co""># nb of success</span>
 <span class=""va"">n</span> <span class=""op"">&lt;-</span> <span class=""fl"">57</span> <span class=""co""># nb of attempts</span></code></pre></div>
 <p><strong>Pr√©ciser quelque part qu‚Äôon prend formalisme McElreath pour pr√©senter les mod√®les</strong>. We build our model first. Assuming all animals are independent of each other and have the same survival probability, then the number of alive animals at the end of the winter is a binomial distribution:</p>
@@ -148,13 +115,13 @@ <h2>
 \theta &amp;\sim \text{Beta}(1, 1) &amp;\text{[prior for }\theta \text{]}
 \end{align*}\]</span></p>
 <p>Now we apply the Bayes‚Äô theorem. We write a function that computes the product of the likelihood times the prior, or the numerator in the formula of the Bayes‚Äô theorem: <span class=""math inline"">\(\Pr(\text{data} \mid \theta) \; \Pr(\theta)\)</span></p>
-<div class=""sourceCode"" id=""cb3""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb2""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">numerator</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">p</span><span class=""op"">)</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Binomial.html"">dbinom</a></span><span class=""op"">(</span><span class=""va"">y</span>,<span class=""va"">n</span>,<span class=""va"">p</span><span class=""op"">)</span> <span class=""op"">*</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Beta.html"">dbeta</a></span><span class=""op"">(</span><span class=""va"">p</span>,<span class=""va"">a</span>,<span class=""va"">b</span><span class=""op"">)</span></code></pre></div>
 <p>We write another function that calculates the denominator, which we sometimes call the averaged likelihood: <span class=""math inline"">\(\Pr(\text{data}) = \int{L(\theta \mid \text{data}) \; \Pr(\theta) d\theta}\)</span></p>
-<div class=""sourceCode"" id=""cb4""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb3""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">denominator</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/integrate.html"">integrate</a></span><span class=""op"">(</span><span class=""va"">numerator</span>,<span class=""fl"">0</span>,<span class=""fl"">1</span><span class=""op"">)</span><span class=""op"">$</span><span class=""va"">value</span></code></pre></div>
 <p>Then we get the posterior via numerical integration.</p>
-<div class=""sourceCode"" id=""cb5""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb4""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">grid</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/seq.html"">seq</a></span><span class=""op"">(</span><span class=""fl"">0</span>, <span class=""fl"">1</span>, <span class=""fl"">0.01</span><span class=""op"">)</span>
 <span class=""va"">numerical_posterior</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/data.frame.html"">data.frame</a></span><span class=""op"">(</span>survival <span class=""op"">=</span> <span class=""va"">grid</span>, 
                                   posterior <span class=""op"">=</span> <span class=""fu"">numerator</span><span class=""op"">(</span><span class=""va"">grid</span><span class=""op"">)</span><span class=""op"">/</span><span class=""va"">denominator</span><span class=""op"">)</span> 
@@ -165,16 +132,16 @@ <h2>
             col <span class=""op"">=</span> <span class=""va"">wes_palettes</span><span class=""op"">$</span><span class=""va"">Royal1</span><span class=""op"">[</span><span class=""fl"">2</span><span class=""op"">]</span>, 
             alpha <span class=""op"">=</span> <span class=""fl"">0.5</span><span class=""op"">)</span></code></pre></div>
 <div class=""figure"">
-<span style=""display:block;"" id=""fig:unnamed-chunk-12""></span>
-<img src=""bayesHMMcapturerecapture_files/figure-html/unnamed-chunk-12-1.png"" alt=""Numerical approximation of winter survival posterior distribution."" width=""672""><p class=""caption"">
-Figure 1.3: Numerical approximation of winter survival posterior distribution.
+<span style=""display:block;"" id=""fig:unnamed-chunk-9""></span>
+<img src=""bayesHMMcapturerecapture_files/figure-html/unnamed-chunk-9-1.png"" alt=""Numerical approximation of winter survival posterior distribution."" width=""672""><p class=""caption"">
+Figure 2.3: Numerical approximation of winter survival posterior distribution.
 </p>
 </div>
 When we use a binomial likelihood together with a uniform prior, the posterior distribution has an explicit form that we can calculate by hand<a class=""footnote-ref"" tabindex=""0"" data-toggle=""popover"" data-content=""&lt;p&gt;&lt;strong&gt;faire qqch sur conjugacy?&lt;/strong&gt;&lt;/p&gt;""><sup>2</sup></a>. We superimpose the exact posterior and its numerical approximation to realise that the two distributions are indistinguishable, suggestion that the numerical approximation is more than fine.
 <div class=""figure"">
-<span style=""display:block;"" id=""fig:unnamed-chunk-13""></span>
-<img src=""bayesHMMcapturerecapture_files/figure-html/unnamed-chunk-13-1.png"" alt=""Comparison of exact (dashed line) vs. numerical approximation (continuous line) of winter survival posterior distribution."" width=""672""><p class=""caption"">
-Figure 1.4: Comparison of exact (dashed line) vs.¬†numerical approximation (continuous line) of winter survival posterior distribution.
+<span style=""display:block;"" id=""fig:unnamed-chunk-10""></span>
+<img src=""bayesHMMcapturerecapture_files/figure-html/unnamed-chunk-10-1.png"" alt=""Comparison of exact (dashed line) vs. numerical approximation (continuous line) of winter survival posterior distribution."" width=""672""><p class=""caption"">
+Figure 2.4: Comparison of exact (dashed line) vs.¬†numerical approximation (continuous line) of winter survival posterior distribution.
 </p>
 </div>
 <!-- To finish up, let's add the prior.  -->
@@ -199,22 +166,22 @@ <h2>
 <p><span class=""math display"">\[ P(\alpha, \beta, p \mid \text{data}) = \frac{ P(\text{data} \mid \alpha, \beta, p) \, P(\alpha, \beta, p)}{\iiint \, P(\text{data} \mid \alpha, \beta, p) \, P(\alpha, \beta, p) \,d\alpha \,d\beta \,dp} \]</span>
 There are two computational challenges with this formula. First, do we really wish to calculate a three-dimensional integral? The answer is no <strong>dire pourquoi, et qu‚Äôon a rien dans R pour faire √ßa</strong>. Second, we‚Äôre more interested in a posterior distribution for each parameter separately than the joint posterior distribution. The so-called marginal distribution of <span class=""math inline"">\(p\)</span> for example is obtained by integrating over all the other parameters ‚Äì a two-dimensional integral in this example. Now imagine with tens or hundreds of parameters to estimate, these integrals become highly multi-dimensional and simply too difficult to calculate. In the next section, we introduce powerful simulation methods to circumvent this issue.</p>
 </div>
-<div id=""bayesian-computation-with-markov-chain-monte-carlo-mcmc"" class=""section level2"" number=""1.5"">
+<div id=""bayesian-computation-with-markov-chain-monte-carlo-mcmc"" class=""section level2"" number=""2.5"">
 <h2>
-<span class=""header-section-number"">1.5</span> Bayesian computation with Markov chain Monte Carlo (MCMC)<a class=""anchor"" aria-label=""anchor"" href=""#bayesian-computation-with-markov-chain-monte-carlo-mcmc""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">2.5</span> Bayesian computation with Markov chain Monte Carlo (MCMC)<a class=""anchor"" aria-label=""anchor"" href=""#bayesian-computation-with-markov-chain-monte-carlo-mcmc""><i class=""fas fa-link""></i></a>
 </h2>
-<p>In the early 1990s, statisticians rediscovered work from the 1950‚Äôs in physics. In a famous paper that would lay the fundations of algorithms for implementing Bayes‚Äô theorem, the authors use simulations to approximate posterior distributions with some precision by drawing large samples. This is a neat trick to avoid explicit calculation of multi-dimensional integrals we struggle with when using Bayes‚Äô theorem. These simulation algorithms are called Markov chain Monte Carlo (MCMC), and they definitely gave a boost to Bayesian statistics. <strong>simulation algorithm ou stochastic algorithms. Expliquer.</strong></p>
+<p>In the early 1990s, statisticians rediscovered work from the 1950‚Äôs in physics. In a famous paper that would lay the fundations of modern Bayesian statistics, the authors use simulations to approximate posterior distributions with some precision by drawing large samples. This is a neat trick to avoid explicit calculation of multi-dimensional integrals we struggle with when using Bayes‚Äô theorem. These simulation algorithms are called Markov chain Monte Carlo (MCMC), and they definitely gave a boost to Bayesian statistics. <strong>simulation algorithm ou stochastic algorithms. Expliquer.</strong></p>
 <div class=""figure"" style=""text-align: center"">
-<span style=""display:block;"" id=""fig:unnamed-chunk-14""></span>
+<span style=""display:block;"" id=""fig:unnamed-chunk-11""></span>
 <img src=""images/metropolis.png"" alt=""MCMC article cover. Source: [The Journal of Chemical Physics](https://aip.scitation.org/doi/10.1063/1.1699114)"" width=""582""><p class=""caption"">
-Figure 1.5: MCMC article cover. Source: <a href=""https://aip.scitation.org/doi/10.1063/1.1699114"">The Journal of Chemical Physics</a>
+Figure 2.5: MCMC article cover. Source: <a href=""https://aip.scitation.org/doi/10.1063/1.1699114"">The Journal of Chemical Physics</a>
 </p>
 </div>
-<p>Why are MCMC methods so useful? Well to understand <em>why</em>, we need to better explain the <em>what</em>. MCMC are stochastic algorithms to produce sequence of dependent random numbers from a Markov chain. What is a Markov chain? A Markov chain is a discrete sequence of states, in which the probability of an event depends only on the state in the previous event. <strong>donner example de la m√©t√©o?</strong> By construction, a Markov chain has an equilibrium (also know as stationary) distribution. <strong>expliquer</strong> The cool thing is that the equilibrium distribution is the desired posterior distribution. Yes, MCMC algorithms are used to construct a Markov chain with a given stationary distribution set to be the posterior distribution. This summarizes the core spirit of MCMC algorithms.
+<p>Why are MCMC methods so useful? Well to understand <em>why</em>, we need to better explain the <em>what</em>. MCMC are stochastic algorithms to produce sequence of dependent random numbers from a Markov chain. What is a Markov chain? A Markov chain is a discrete sequence of states, in which the probability of an event depends only on the state in the previous event. <strong>donner example de la m√©t√©o?</strong> By construction, a Markov chain has an equilibrium (also know as stationary) distribution. <strong>expliquer</strong> The cool thing is that the equilibrium distribution is the desired posterior distribution. <strong>Expliquer Monte Carlo avec exemple simple, idem pour Markov chain</strong> Yes, MCMC algorithms are used to construct a Markov chain with a given stationary distribution set to be the posterior distribution. This summarizes the core spirit of MCMC algorithms.
 <strong>why is it so cool? plut√¥t que de simuler comme des dingues dans tous les snes, il suffit de tirer dans Markov chain, et eventuellement, on converge vers distribution statitionnaire qui est l‚Äôa posteriori! Also For the MCMC algorithm, the posterior distribution is only needed to be known up to proportionality.</strong></p>
-<p>There are several ways of constructing these chains: e.g., Metropolis-Hastings, Gibbs sampler. Here I will illustrate the Metropolis algorithm and how to implement it in practice.</p>
+<p>There are several ways of constructing these chains: e.g., Metropolis-Hastings, Gibbs sampler. Here I will illustrate the Metropolis algorithm and how to implement it in practice. <strong>Diff√©rence entre Metropolis et MH</strong></p>
 <p>Let‚Äôs go back to our example on animal survival estimation. We illustrate sampling from survival posterior distribution. We write functions for likelihood, prior and posterior.</p>
-<div class=""sourceCode"" id=""cb6""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb5""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""co""># 19 animals recaptured alive out of 57 captured, marked and released</span>
 <span class=""va"">survived</span> <span class=""op"">&lt;-</span> <span class=""fl"">19</span>
 <span class=""va"">released</span> <span class=""op"">&lt;-</span> <span class=""fl"">57</span>
@@ -242,24 +209,24 @@ <h2>
 <li><p>We repeat 2-4 a number of times ‚Äì or <em>steps</em> (many steps).</p></li>
 </ol>
 <p>Enough of the theory, let‚Äôs implement the Metropolis algorithm in <code>R</code>. Let‚Äôs start by setting the scene.</p>
-<div class=""sourceCode"" id=""cb7""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb6""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">steps</span> <span class=""op"">&lt;-</span> <span class=""fl"">100</span> <span class=""co""># number of steps</span>
 <span class=""va"">theta.post</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/rep.html"">rep</a></span><span class=""op"">(</span><span class=""cn"">NA</span>, <span class=""va"">steps</span><span class=""op"">)</span> <span class=""co""># vector to store samples</span>
 <span class=""fu""><a href=""https://rdrr.io/r/base/Random.html"">set.seed</a></span><span class=""op"">(</span><span class=""fl"">1234</span><span class=""op"">)</span> <span class=""co""># for reproducibility</span></code></pre></div>
 <p>Now we follow the 5 steps we‚Äôve just described. First, we pick a starting value, and store it (step 1).</p>
-<div class=""sourceCode"" id=""cb8""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb7""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">inits</span> <span class=""op"">&lt;-</span> <span class=""fl"">0.5</span>
 <span class=""va"">theta.post</span><span class=""op"">[</span><span class=""fl"">1</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""va"">inits</span></code></pre></div>
 <p>To go to the next steps, we‚Äôll need a function to propose a candidate value.</p>
-<div class=""sourceCode"" id=""cb9""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb8""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">move</span> <span class=""op"">&lt;-</span> <span class=""kw"">function</span><span class=""op"">(</span><span class=""va"">x</span>, <span class=""va"">away</span> <span class=""op"">=</span> <span class=""fl"">.2</span><span class=""op"">)</span><span class=""op"">{</span> 
   <span class=""va"">logitx</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/Log.html"">log</a></span><span class=""op"">(</span><span class=""va"">x</span> <span class=""op"">/</span> <span class=""op"">(</span><span class=""fl"">1</span> <span class=""op"">-</span> <span class=""va"">x</span><span class=""op"">)</span><span class=""op"">)</span>
   <span class=""va"">logit_candidate</span> <span class=""op"">&lt;-</span> <span class=""va"">logitx</span> <span class=""op"">+</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Normal.html"">rnorm</a></span><span class=""op"">(</span><span class=""fl"">1</span>, <span class=""fl"">0</span>, <span class=""va"">away</span><span class=""op"">)</span>
   <span class=""va"">candidate</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/stats/Logistic.html"">plogis</a></span><span class=""op"">(</span><span class=""va"">logit_candidate</span><span class=""op"">)</span>
   <span class=""kw""><a href=""https://rdrr.io/r/base/function.html"">return</a></span><span class=""op"">(</span><span class=""va"">candidate</span><span class=""op"">)</span>
 <span class=""op"">}</span></code></pre></div>
 <p>Now we‚Äôre ready for steps 2, 3 and 4. Actually, we will write a look to take care of step 5 as well. Remember we start at initial value 0.5 and run the algorithm for <span class=""math inline"">\(100\)</span> iterations.</p>
-<div class=""sourceCode"" id=""cb10""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb9""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""kw"">for</span> <span class=""op"">(</span><span class=""va"">t</span> <span class=""kw"">in</span> <span class=""fl"">2</span><span class=""op"">:</span><span class=""va"">steps</span><span class=""op"">)</span><span class=""op"">{</span> <span class=""co""># repeat steps 2-4 (step 5)</span>
   
   <span class=""co""># propose candidate value for prob of success (step 2)</span>
@@ -276,52 +243,80 @@ <h2>
   <span class=""va"">theta.post</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">]</span> <span class=""op"">&lt;-</span> <span class=""fu""><a href=""https://rdrr.io/r/base/ifelse.html"">ifelse</a></span><span class=""op"">(</span><span class=""va"">accept</span> <span class=""op"">==</span> <span class=""fl"">1</span>, <span class=""va"">theta_star</span>, <span class=""va"">theta.post</span><span class=""op"">[</span><span class=""va"">t</span><span class=""op"">-</span><span class=""fl"">1</span><span class=""op"">]</span><span class=""op"">)</span>
 <span class=""op"">}</span></code></pre></div>
 <p>We get the following values.</p>
-<div class=""sourceCode"" id=""cb11""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb10""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu""><a href=""https://rdrr.io/r/utils/head.html"">head</a></span><span class=""op"">(</span><span class=""va"">theta.post</span><span class=""op"">)</span> <span class=""co""># first values</span>
-<span class=""co"">## [1] 0.5000 0.4399 0.4399 0.4577 0.4577 0.4577</span>
+<span class=""co"">## [1] 0.5000000 0.4399381 0.4399381 0.4577124 0.4577124</span>
+<span class=""co"">## [6] 0.4577124</span>
 <span class=""fu""><a href=""https://rdrr.io/r/utils/head.html"">tail</a></span><span class=""op"">(</span><span class=""va"">theta.post</span><span class=""op"">)</span> <span class=""co""># last values</span>
-<span class=""co"">## [1] 0.4146 0.3772 0.3772 0.3861 0.3899 0.3624</span></code></pre></div>
+<span class=""co"">## [1] 0.4145878 0.3772087 0.3772087 0.3860516 0.3898536</span>
+<span class=""co"">## [6] 0.3624450</span></code></pre></div>
 Visually, the chain looks like that. <strong>introduire traceplot?</strong>
 <div class=""figure"" style=""text-align: center"">
-<span style=""display:block;"" id=""fig:unnamed-chunk-21""></span>
-<img src=""bayesHMMcapturerecapture_files/figure-html/unnamed-chunk-21-1.png"" alt=""Visualisation of a Markov chain, often called traceplot. Starting value is 0.5."" width=""672""><p class=""caption"">
-Figure 1.6: Visualisation of a Markov chain, often called traceplot. Starting value is 0.5.
+<span style=""display:block;"" id=""fig:unnamed-chunk-18""></span>
+<img src=""bayesHMMcapturerecapture_files/figure-html/unnamed-chunk-18-1.png"" alt=""Visualisation of a Markov chain, often called traceplot. Starting value is 0.5."" width=""672""><p class=""caption"">
+Figure 2.6: Visualisation of a Markov chain, often called traceplot. Starting value is 0.5.
 </p>
 </div>
 Can we run another chain and start at initial value 0.2 this time? Yes, just go through the same algorithm again.
 <div class=""figure"" style=""text-align: center"">
-<span style=""display:block;"" id=""fig:unnamed-chunk-22""></span>
-<img src=""bayesHMMcapturerecapture_files/figure-html/unnamed-chunk-22-1.png"" alt=""Visualisation of two Markov chains with starting values 0.2 (yellow) and 0.5 (blue)."" width=""672""><p class=""caption"">
-Figure 1.7: Visualisation of two Markov chains with starting values 0.2 (yellow) and 0.5 (blue).
+<span style=""display:block;"" id=""fig:unnamed-chunk-19""></span>
+<img src=""bayesHMMcapturerecapture_files/figure-html/unnamed-chunk-19-1.png"" alt=""Visualisation of two Markov chains with starting values 0.2 (yellow) and 0.5 (blue)."" width=""672""><p class=""caption"">
+Figure 2.7: Visualisation of two Markov chains with starting values 0.2 (yellow) and 0.5 (blue).
 </p>
 </div>
 Notice that we do not get the same exact results. <strong>Stochasticity, mais on average, seems to reach same value and vary aournd it ‚Äì equilibrium? Stationary? posterior of winter survival</strong> Now let‚Äôs increase the number of steps and run a chain with 5000 iterations.
 <div class=""figure"" style=""text-align: center"">
-<span style=""display:block;"" id=""fig:unnamed-chunk-23""></span>
-<img src=""bayesHMMcapturerecapture_files/figure-html/unnamed-chunk-23-1.png"" alt=""Visualisation of a Markov chains with 5000 iterations."" width=""672""><p class=""caption"">
-Figure 1.8: Visualisation of a Markov chains with 5000 iterations.
+<span style=""display:block;"" id=""fig:unnamed-chunk-20""></span>
+<img src=""bayesHMMcapturerecapture_files/figure-html/unnamed-chunk-20-1.png"" alt=""Visualisation of a Markov chains with 5000 iterations."" width=""672""><p class=""caption"">
+Figure 2.8: Visualisation of a Markov chains with 5000 iterations.
 </p>
 </div>
 <p>We also add two straight lines, one in yellow for the mean of the posterior distribution <strong>dire comment c‚Äôest calcul√©</strong>, and the other in red for the maximum likelihood estimate <strong>c‚Äôest quoi ici?</strong>. <strong>expliquer pourquoi, et noter que √ßa donne la m√™me chose</strong>.</p>
 <p>I find it informative to look at the animated version of this figure, it helps understanding the iterative nature of the algorithm, and also to realise how the chains converge to their stationary distribution.</p>
 <img src=""images/traceplotMCMC.gif"" width=""100%"" style=""display: block; margin: auto;""><div class=""figure"" style=""text-align: center"">
-<span style=""display:block;"" id=""fig:unnamed-chunk-26""></span>
+<span style=""display:block;"" id=""fig:unnamed-chunk-23""></span>
 <img src=""images/histMCMC.gif"" alt=""Sampling values in survival posterior distribution with a MCMC algorithm. Top panel: traceplot. Bottom panel: histogram."" width=""100%""><p class=""caption"">
-Figure 1.9: Sampling values in survival posterior distribution with a MCMC algorithm. Top panel: traceplot. Bottom panel: histogram.
+Figure 2.9: Sampling values in survival posterior distribution with a MCMC algorithm. Top panel: traceplot. Bottom panel: histogram.
 </p>
 </div>
-<p><strong>Introduire l‚Äôid√©e de grass, note de bas de page vers Steve Brooks comm pers, et transition vers next section avec l‚Äôid√©e de comment on regarde la convergence</strong> Once the stationary distribution is reached, we can regard the realisations of the chain as a (dependent) sample from the posterior distribution (and obtain Monte Carlo estimates). In the next section, we consider several important implementation issues.</p>
+<p><strong>Introduire l‚Äôid√©e de grass, note de bas de page vers Steve Brooks comm pers, et transition vers next section avec l‚Äôid√©e de comment on regarde la convergence</strong> We discard some realisations of the Markov chain before convergence is achieved. Once the stationary distribution is reached <strong>use stationary or target or limiting</strong>, we can regard the realisations of the chain as a (dependent) sample from the posterior distribution, and obtain Monte Carlo estimates of parameters. In the next section, we consider several important implementation issues. <strong>coder Metropolis d‚Äôau-dessus dans Nimble</strong></p>
 </div>
-<div id=""assessing-convergence"" class=""section level2"" number=""1.6"">
+<div id=""assessing-convergence"" class=""section level2"" number=""2.6"">
 <h2>
-<span class=""header-section-number"">1.6</span> Assessing convergence<a class=""anchor"" aria-label=""anchor"" href=""#assessing-convergence""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">2.6</span> Assessing convergence<a class=""anchor"" aria-label=""anchor"" href=""#assessing-convergence""><i class=""fas fa-link""></i></a>
 </h2>
-<p><strong>Les principales questions on doit r√©pondre pour check convergence. Noter qu‚Äôen freq c‚Äôest plus ou moins fait en backstage. En MCMC pas grand chose pour automatiser.</strong></p>
-<div id=""mixing-and-autocorrelation"" class=""section level3"" number=""1.6.1"">
+<p>How do good chains behave? When implementing MCMC, we need to i) ensure that our Markov chain explores efficiently the parameter space, i) determine how long it takes and whether our Markov chain converges to the target distribution, and the same target distribution if we run several Markov chains, and iii) the number of iterations post-convergence to get reasonable Monte Carlo estimates (numerical summaries).</p>
+<div id=""burn-in"" class=""section level3"" number=""2.6.1"">
 <h3>
-<span class=""header-section-number"">1.6.1</span> Mixing and autocorrelation<a class=""anchor"" aria-label=""anchor"" href=""#mixing-and-autocorrelation""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">2.6.1</span> Burn-in<a class=""anchor"" aria-label=""anchor"" href=""#burn-in""><i class=""fas fa-link""></i></a>
 </h3>
-<div class=""inline-figure""><img src=""bayesHMMcapturerecapture_files/figure-html/unnamed-chunk-27-1.png"" width=""672""></div>
+<p>In practice, we discard observations from the start of the Markov chain and just use observations from the chain once it has converged. The initial observations that we discard are usually referred to as the <strong>burn-in</strong>. The simplest method to determine the length of the burn-in period is to look at trace plots. Going back to our example, we see from the trace plot in Figure <a href=""crashcourse.html#fig:burnin"">2.10</a> that we need at least 500 iterations to achieve convergence toward an average survival around 0.3. It is always better to be conservative when specifying the length of the burn-in period, and in this example, we would use 750 or even 1000 iterations as a burn-in. <strong>pr√©ciser qu‚Äôil faut faire qqs runs pr√©liminaires pour d√©terminer le burn-in; ajouter des cas pathologiques ou faire des renvois aux sections suiantes, en particuier les minimal locaux ou par redundancy?</strong></p>
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:burnin""></span>
+<img src=""bayesHMMcapturerecapture_files/figure-html/burnin-1.png"" alt=""Determining the length of the burn-in period."" width=""672""><p class=""caption"">
+Figure 2.10: Determining the length of the burn-in period.
+</p>
+</div>
+</div>
+<div id=""potential-scale-reduction-factor"" class=""section level3"" number=""2.6.2"">
+<h3>
+<span class=""header-section-number"">2.6.2</span> Potential scale reduction factor<a class=""anchor"" aria-label=""anchor"" href=""#potential-scale-reduction-factor""><i class=""fas fa-link""></i></a>
+</h3>
+<p>Inspecting the trace plot for a single run of the Markov chain is useful. We usually run the Markov chain several times, starting from different over-dispersed points, to check that all replicates achieve the same target distribution. This approach is formalised by using the Brooks-Gelman-Rubin statistic <span class=""math inline"">\(\hat{R}\)</span> which measures the ratio of the total variability combining multiple chains (between-chain plus within-chain) to the within-chain variability. The BGR statistic asks whether there is a chain effect, and is very much alike the <span class=""math inline"">\(F\)</span> test in an analysis of variance. Values below <span class=""math inline"">\(1.2\)</span> indicate likely convergence. <strong>check 1.1 or 1.2</strong></p>
+<p>Back to our example, we run two replicates of the Markov chain with starting values 0.2 and 0.8 using 100 up to 5000 iterations.</p>
+<div class=""figure"">
+<span style=""display:block;"" id=""fig:bgr""></span>
+<img src=""bayesHMMcapturerecapture_files/figure-html/bgr-1.png"" alt=""Brooks-Gelman-Rubin statistic."" width=""672""><p class=""caption"">
+Figure 2.11: Brooks-Gelman-Rubin statistic.
+</p>
+</div>
+<p>It is important to bear in mind that a value near 1 for the BGR statistic is only a necessary <em>but not sufficient</em> condition for convergence. In other words, this diagnostic cannot tell you for sure that the Markov chain has achieved convergence, only that it has not.</p>
+</div>
+<div id=""mixing-and-autocorrelation"" class=""section level3"" number=""2.6.3"">
+<h3>
+<span class=""header-section-number"">2.6.3</span> Mixing and autocorrelation<a class=""anchor"" aria-label=""anchor"" href=""#mixing-and-autocorrelation""><i class=""fas fa-link""></i></a>
+</h3>
+<div class=""inline-figure""><img src=""bayesHMMcapturerecapture_files/figure-html/unnamed-chunk-25-1.png"" width=""672""></div>
 <ul>
 <li><p>The movement around the parameter space is often referred to as <strong>mixing</strong>.</p></li>
 <li><p>Traceplots of for small and big moves provide (relatively) high correlations (known as autocorrelations) between successive observations of the Markov chain.</p></li>
@@ -330,29 +325,9 @@ <h3>
 <li><p>ACF plots provide the autocorrelation between successively sampled values separated by <span class=""math inline"">\(k\)</span> iterations, referred to as lag, (i.e.¬†<span class=""math inline"">\(\text{cor}(\theta_t, \theta_{t+k})\)</span>) for increasing values of <span class=""math inline"">\(k\)</span>.</p></li>
 </ul>
 </div>
-<div id=""how-do-good-chains-behave"" class=""section level3"" number=""1.6.2"">
-<h3>
-<span class=""header-section-number"">1.6.2</span> How do good chains behave?<a class=""anchor"" aria-label=""anchor"" href=""#how-do-good-chains-behave""><i class=""fas fa-link""></i></a>
-</h3>
-<ul>
-<li><p>Converge to same target distribution; discard some realisations of Markov chain before convergence is achieved.</p></li>
-<li><p>Once there, explore efficiently: The post-convergence sample size required for suitable numerical summaries.</p></li>
-<li><p>Therefore, we are looking to determine how long it takes for the Markov chain to converge to the stationary distribution.</p></li>
-<li><p>In practice, we must discard observations from the start of the chain and just use observations from the chain once it has converged.</p></li>
-<li><p>The initial observations that we discard are referred to as the <strong>burn-in</strong>.</p></li>
-<li><p>Simplest method to determine length of burn-in period is to look at trace plots.</p></li>
-</ul>
-</div>
-<div id=""burn-in"" class=""section level3"" number=""1.6.3"">
-<h3>
-<span class=""header-section-number"">1.6.3</span> Burn-in<a class=""anchor"" aria-label=""anchor"" href=""#burn-in""><i class=""fas fa-link""></i></a>
-</h3>
-<div class=""inline-figure""><img src=""bayesHMMcapturerecapture_files/figure-html/unnamed-chunk-28-1.png"" width=""672""></div>
-<p>If simulations cheap, be conservative.</p>
-</div>
-<div id=""effective-sample-size-n.eff"" class=""section level3"" number=""1.6.4"">
+<div id=""effective-sample-size-n.eff"" class=""section level3"" number=""2.6.4"">
 <h3>
-<span class=""header-section-number"">1.6.4</span> Effective sample size <code>n.eff</code><a class=""anchor"" aria-label=""anchor"" href=""#effective-sample-size-n.eff""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">2.6.4</span> Effective sample size <code>n.eff</code><a class=""anchor"" aria-label=""anchor"" href=""#effective-sample-size-n.eff""><i class=""fas fa-link""></i></a>
 </h3>
 <ul>
 <li>How long of a chain is needed to produce stable estimates ?</li>
@@ -366,22 +341,9 @@ <h3>
 <li>We need <span class=""math inline"">\(\text{n.eff} \geq 100\)</span> independent steps.</li>
 </ul>
 </div>
-<div id=""potential-scale-reduction-factor"" class=""section level3"" number=""1.6.5"">
-<h3>
-<span class=""header-section-number"">1.6.5</span> Potential scale reduction factor<a class=""anchor"" aria-label=""anchor"" href=""#potential-scale-reduction-factor""><i class=""fas fa-link""></i></a>
-</h3>
-<ul>
-<li>Gelman-Rubin statistic <span class=""math inline"">\(\hat{R}\)</span>
-</li>
-<li>Measures the ratio of the total variability combining multiple chains (between-chain plus within-chain) to the within-chain variability.</li>
-<li>Asks the question is there a chain effect? Very much alike the <span class=""math inline"">\(F\)</span> test in an ANOVA.</li>
-<li>Values near <span class=""math inline"">\(1\)</span> indicates likely convergence, a value of <span class=""math inline"">\(\leq 1.1\)</span> is considered acceptable.</li>
-<li>Necessary condition, not sufficient; In other words, these diagnostics cannot tell you that you have converged for sure, only that you have not.</li>
-</ul>
-</div>
-<div id=""what-if-you-have-issues-of-convergence"" class=""section level3"" number=""1.6.6"">
+<div id=""what-if-you-have-issues-of-convergence"" class=""section level3"" number=""2.6.5"">
 <h3>
-<span class=""header-section-number"">1.6.6</span> What if you have issues of convergence?<a class=""anchor"" aria-label=""anchor"" href=""#what-if-you-have-issues-of-convergence""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">2.6.5</span> What if you have issues of convergence?<a class=""anchor"" aria-label=""anchor"" href=""#what-if-you-have-issues-of-convergence""><i class=""fas fa-link""></i></a>
 </h3>
 <ul>
 <li>Increase burn-in, sample more.</li>
@@ -397,9 +359,9 @@ <h3>
 </ul>
 </div>
 </div>
-<div id=""summary"" class=""section level2"" number=""1.7"">
+<div id=""summary"" class=""section level2"" number=""2.7"">
 <h2>
-<span class=""header-section-number"">1.7</span> Summary<a class=""anchor"" aria-label=""anchor"" href=""#summary""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">2.7</span> Summary<a class=""anchor"" aria-label=""anchor"" href=""#summary""><i class=""fas fa-link""></i></a>
 </h2>
 <ul>
 <li>Run multiple chains from arbitrary starting places (initial values).</li>
@@ -410,61 +372,41 @@ <h2>
 </ul>
 <p><strong>Takes some trainig</strong></p>
 </div>
-<div id=""further-reading"" class=""section level2"" number=""1.8"">
+<div id=""further-reading"" class=""section level2"" number=""2.8"">
 <h2>
-<span class=""header-section-number"">1.8</span> Further reading<a class=""anchor"" aria-label=""anchor"" href=""#further-reading""><i class=""fas fa-link""></i></a>
+<span class=""header-section-number"">2.8</span> Further reading<a class=""anchor"" aria-label=""anchor"" href=""#further-reading""><i class=""fas fa-link""></i></a>
 </h2>
 <ul>
 <li><p>McCarthy, M. (2007). <a href=""https://www.cambridge.org/core/books/bayesian-methods-for-ecology/9225F65B8A25D69B0B6C50B5A9A78201"">Bayesian Methods for Ecology</a>. Cambridge: Cambridge University Press.</p></li>
 <li><p>McElreath, R. (2020). <a href=""https://xcelab.net/rm/statistical-rethinking/"">Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2nd ed.)</a>. CRC Press.</p></li>
 <li><p>Gelman, A. and Hill, J. (2006). <a href=""https://www.cambridge.org/core/books/data-analysis-using-regression-and-multilevelhierarchical-models/32A29531C7FD730C3A68951A17C9D983"">Data Analysis Using Regression and Multilevel/Hierarchical Models (Analytical Methods for Social Research)</a>. Cambridge: Cambridge University Press.</p></li>
 <li><p>Animating MCMC - 2D example; Code <a href=""https://mbjoseph.github.io/posts/2018-12-25-animating-the-metropolis-algorithm/"">here</a>.</p></li>
 </ul>
-<div class=""sourceCode"" id=""cb12""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb11""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu"">knitr</span><span class=""fu"">::</span><span class=""fu""><a href=""https://rdrr.io/pkg/knitr/man/include_graphics.html"">include_graphics</a></span><span class=""op"">(</span><span class=""st"">""images/create-gif.gif""</span><span class=""op"">)</span></code></pre></div>
 <div class=""inline-figure"">
 <img src=""images/create-gif.gif""><!-- -->
 </div>
 <ul>
 <li>The MCMC Interactive Gallery (more <a href=""https://chi-feng.github.io/mcmc-demo/"">here</a>)</li>
 </ul>
-<div class=""sourceCode"" id=""cb13""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb12""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""fu"">knitr</span><span class=""fu"">::</span><span class=""fu""><a href=""https://rdrr.io/pkg/knitr/man/include_graphics.html"">include_graphics</a></span><span class=""op"">(</span><span class=""st"">""images/galery.png""</span><span class=""op"">)</span></code></pre></div>
 <div class=""inline-figure""><img src=""images/galery.png"" width=""992""></div>
 
 </div>
 </div>
 
   <div class=""chapter-nav"">
-<div class=""prev""><a href=""about-the-author.html"">About the Author</a></div>
-<div class=""next""><a href=""intronimble.html""><span class=""header-section-number"">2</span> Introduction to Nimble</a></div>
+<div class=""empty""></div>
+<div class=""empty""></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
-      <ul class=""nav navbar-nav"">
-<li><a class=""nav-link"" href=""#crashcourse""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
-<li><a class=""nav-link"" href=""#introduction""><span class=""header-section-number"">1.1</span> Introduction</a></li>
-<li><a class=""nav-link"" href=""#bayes-theorem""><span class=""header-section-number"">1.2</span> Bayes‚Äô theorem</a></li>
-<li><a class=""nav-link"" href=""#what-is-the-bayesian-approach""><span class=""header-section-number"">1.3</span> What is the Bayesian approach?</a></li>
-<li><a class=""nav-link"" href=""#approximating-posterior-distributions-via-numerical-integration""><span class=""header-section-number"">1.4</span> Approximating posterior distributions via numerical integration</a></li>
-<li><a class=""nav-link"" href=""#bayesian-computation-with-markov-chain-monte-carlo-mcmc""><span class=""header-section-number"">1.5</span> Bayesian computation with Markov chain Monte Carlo (MCMC)</a></li>
-<li>
-<a class=""nav-link"" href=""#assessing-convergence""><span class=""header-section-number"">1.6</span> Assessing convergence</a><ul class=""nav navbar-nav"">
-<li><a class=""nav-link"" href=""#mixing-and-autocorrelation""><span class=""header-section-number"">1.6.1</span> Mixing and autocorrelation</a></li>
-<li><a class=""nav-link"" href=""#how-do-good-chains-behave""><span class=""header-section-number"">1.6.2</span> How do good chains behave?</a></li>
-<li><a class=""nav-link"" href=""#burn-in""><span class=""header-section-number"">1.6.3</span> Burn-in</a></li>
-<li><a class=""nav-link"" href=""#effective-sample-size-n.eff""><span class=""header-section-number"">1.6.4</span> Effective sample size n.eff</a></li>
-<li><a class=""nav-link"" href=""#potential-scale-reduction-factor""><span class=""header-section-number"">1.6.5</span> Potential scale reduction factor</a></li>
-<li><a class=""nav-link"" href=""#what-if-you-have-issues-of-convergence""><span class=""header-section-number"">1.6.6</span> What if you have issues of convergence?</a></li>
-</ul>
-</li>
-<li><a class=""nav-link"" href=""#summary""><span class=""header-section-number"">1.7</span> Summary</a></li>
-<li><a class=""nav-link"" href=""#further-reading""><span class=""header-section-number"">1.8</span> Further reading</a></li>
-</ul>
+      <div id=""book-on-this-page""></div>
 
       <div class=""book-extra"">
         <ul class=""list-unstyled"">
-<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/01-bayesMCMC.Rmd"">View source <i class=""fab fa-github""></i></a></li>
-          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/01-bayesMCMC.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
+          
         </ul>
 </div>
     </nav>
@@ -476,7 +418,7 @@ <h2>
 <footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
-    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-09.</p>
+    <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-09-10.</p>
   </div>
 
   <div class=""col-12 col-md-6 mt-3"">

---FILE: docs/reference-keys.txt---
@@ -303,3 +303,14 @@ dependence
 covariateselection
 mortalities
 prevalence
+fig:unnamed-chunk-3
+fig:unnamed-chunk-4
+fig:unnamed-chunk-9
+fig:unnamed-chunk-10
+fig:unnamed-chunk-11
+fig:unnamed-chunk-18
+fig:unnamed-chunk-19
+fig:unnamed-chunk-20
+rmarkdownrender_siteoutput_format-bookdownpdf_book-encoding-utf-8
+fig:burnin
+fig:bgr",False,True,Implementation / Logic,6
oliviergimenez,banana-book,de3148a2ee9e48a21ddd0407646501dd3b58c057,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2021-08-26T10:18:37Z,oliviergimenez,olivier.gimenez@cefe.cnrs.fr,2021-08-26T10:18:37Z,Fix previous/next buttons.,docs/404.html;docs/crashcourse.html;docs/intronimble.html;docs/preface.html;docs/reference-keys.txt;docs/search.json;docs/search_index.json,False,False,False,False,181,115,296,"---FILE: docs/404.html---
@@ -1,53 +1,32 @@
-<!doctype html>
+<!DOCTYPE html>
 <html lang=""en"">
 <head>
-  <meta charset=""utf-8"" />
-  <meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-
-  <title>Page not found | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</title>
-
-    <meta name=""author"" content=""Olivier Gimenez"" />
-  
-   <meta name=""description"" content=""This is a comprehensive and applied textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."" />
-   <meta name=""generator"" content=""placeholder"" />
-  <meta property=""og:title"" content=""Page not found | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R"" />
-  <meta property=""og:type"" content=""book"" />
-  <meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/"" />
-  <meta property=""og:image"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop//images/satellite.png"" />
-  <meta property=""og:description"" content=""This is a comprehensive and applied textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."" />
-
-  <meta name=""twitter:card"" content=""summary"" />
-  <meta name=""twitter:title"" content=""Page not found | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R"" />
-  
-  <meta name=""twitter:description"" content=""This is a comprehensive and applied textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R."" />
-  <meta name=""twitter:image"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop//images/satellite.png"" />
-  <!-- JS -->
-  <script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script>
-  <script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script>
-  <script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script>
-    <script src=""libs/header-attrs/header-attrs.js""></script>
-    <script src=""libs/jquery/jquery-3.6.0.min.js""></script>
-    <meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"" />
-    <link href=""libs/bootstrap/bootstrap.min.css"" rel=""stylesheet"" />
-    <script src=""libs/bootstrap/bootstrap.bundle.min.js""></script>
-    <script src=""libs/bs3compat/tabs.js""></script>
-    <script src=""libs/bs3compat/bs3compat.js""></script>
-    <link href=""libs/bs4_book/bs4_book.css"" rel=""stylesheet"" />
-    <script src=""libs/bs4_book/bs4_book.js""></script>
-    <script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script>
-  <script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script>
-
-  <!-- CSS -->
-    <link rel=""stylesheet"" href=""bs4_style.css"" />
-  
+<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
+<meta charset=""utf-8"">
+<meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<title>Page not found | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</title>
+<meta name=""author"" content=""Olivier Gimenez"">
+<meta name=""description"" content=""The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are..."">
+<meta name=""generator"" content=""bookdown 0.23 with bs4_book()"">
+<meta property=""og:title"" content=""Page not found | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R"">
+<meta property=""og:type"" content=""book"">
+<meta property=""og:url"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop/404.html"">
+<meta property=""og:image"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop//images/satellite.png"">
+<meta property=""og:description"" content=""The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are..."">
+<meta name=""twitter:card"" content=""summary"">
+<meta name=""twitter:title"" content=""Page not found | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R"">
+<meta name=""twitter:description"" content=""The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are..."">
+<meta name=""twitter:image"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop//images/satellite.png"">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs/header-attrs.js""></script><script src=""libs/jquery/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat/tabs.js""></script><script src=""libs/bs3compat/bs3compat.js""></script><link href=""libs/bs4_book/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
-
 <body data-spy=""scroll"" data-target=""#toc"">
 
 <div class=""container-fluid"">
 <div class=""row"">
-  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book"">
-    <a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
+  <header class=""col-sm-12 col-lg-3 sidebar sidebar-book""><a class=""sr-only sr-only-focusable"" href=""#content"">Skip to main content</a>
 
     <div class=""d-flex align-items-start justify-content-between"">
       <h1>
@@ -59,47 +38,64 @@ <h1>
     <div id=""main-nav"" class=""collapse-lg"">
       <form role=""search"">
         <input id=""search"" class=""form-control"" type=""search"" placeholder=""Search"" aria-label=""Search"">
-      </form>
-
-      <nav aria-label=""Table of contents"">
-        <h2>Table of contents</h2>
-        <div id=""book-toc""></div>
+</form>
+
+      <nav aria-label=""Table of contents""><h2>Table of contents</h2>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li><a class="""" href=""about-the-author.html"">About the Author</a></li>
+<li class=""book-part"">Theory</li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> Introduction to Nimble</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""transition.html""><span class=""header-section-number"">5</span> Transition</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">6</span> Covariates</a></li>
+<li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">7</span> Uncertainty in state assignment</a></li>
+<li><a class="""" href=""abundance.html""><span class=""header-section-number"">8</span> Abundance</a></li>
+<li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
+<li><a class="""" href=""states.html""><span class=""header-section-number"">10</span> Hidden states</a></li>
+<li><a class="""" href=""speed.html""><span class=""header-section-number"">11</span> Speed up MCMC</a></li>
+<li class=""book-part"">Case studies</li>
+<li><a class="""" href=""senescence.html""><span class=""header-section-number"">12</span> Actuarial senescence</a></li>
+<li><a class="""" href=""heterogeneity.html""><span class=""header-section-number"">13</span> Individual heterogeneity</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">14</span> Life-history tradeoffs</a></li>
+<li><a class="""" href=""breeding.html""><span class=""header-section-number"">15</span> Breeding dynamics</a></li>
+<li><a class="""" href=""rd.html""><span class=""header-section-number"">16</span> Robust design</a></li>
+<li><a class="""" href=""stopover.html""><span class=""header-section-number"">17</span> Stopover duration</a></li>
+<li><a class="""" href=""disease.html""><span class=""header-section-number"">18</span> Disease dynamics</a></li>
+<li><a class="""" href=""sex.html""><span class=""header-section-number"">19</span> Sex uncertainty</a></li>
+<li><a class="""" href=""dependence.html""><span class=""header-section-number"">20</span> Dependence among individuals</a></li>
+<li><a class="""" href=""covariateselection.html""><span class=""header-section-number"">21</span> Individual and temporal variability</a></li>
+<li><a class="""" href=""mortalities.html""><span class=""header-section-number"">22</span> Cause-specific mortalities</a></li>
+<li><a class="""" href=""prevalence.html""><span class=""header-section-number"">23</span> Prevalence</a></li>
+<li><a class="""" href=""faq.html"">FAQ</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
 
         <div class=""book-extra"">
-          <p><a id=""book-repo"" href=""#"">View book source <i class=""fab fa-github""></i></a></li></p>
+          <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
         </div>
       </nav>
-    </div>
-  </header>
-
-  <main class=""col-sm-12 col-md-9 col-lg-7"" id=""content"">
-<div id=""page-not-found"" class=""section level1"">
-<h1>Page not found</h1>
+</div>
+  </header><main class=""col-sm-12 col-md-9 col-lg-7"" id=""content""><div id=""page-not-found"" class=""section level1"">
+<h1>Page not found<a class=""anchor"" aria-label=""anchor"" href=""#page-not-found""><i class=""fas fa-link""></i></a>
+</h1>
 <p>The page you requested cannot be found (perhaps it was moved or renamed).</p>
 <p>You may want to try searching to find the page's new location, or use
 the table of contents to find the page you are looking for.</p>
 </div>
-  </main>
-
-  <div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
-    <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page"">
-      <h2>On this page</h2>
-      <div id=""book-on-this-page""></div>
-
-      <div class=""book-extra"">
-        <ul class=""list-unstyled"">
-          <li><a id=""book-source"" href=""#"">View source <i class=""fab fa-github""></i></a></li>
-          <li><a id=""book-edit"" href=""#"">Edit this page <i class=""fab fa-github""></i></a></li>
-        </ul>
-      </div>
-    </nav>
-  </div>
+  <div class=""chapter-nav"">
+<div class=""empty""></div>
+<div class=""empty""></div>
+</div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
+    </div>
 
 </div>
 </div> <!-- .container -->
 
-<footer class=""bg-primary text-light mt-5"">
-  <div class=""container""><div class=""row"">
+<footer class=""bg-primary text-light mt-5""><div class=""container""><div class=""row"">
 
   <div class=""col-12 col-md-6 mt-3"">
     <p>""<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R</strong>"" was written by Olivier Gimenez. It was last built on 2021-08-26.</p>
@@ -110,11 +106,7 @@ <h2>On this page</h2>
   </div>
 
 </div></div>
-</footer>
-
-
-<!-- dynamically load mathjax for compatibility with self-contained -->
-<script>
+</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
   (function () {
     var script = document.createElement(""script"");
     script.type = ""text/javascript"";
@@ -126,8 +118,7 @@ <h2>On this page</h2>
     script.src = src;
     document.getElementsByTagName(""head"")[0].appendChild(script);
   })();
-</script>
-<script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
+</script><script type=""text/x-mathjax-config"">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle=""popover""]');
 for (let popover of popovers) {
   const div = document.createElement('div');
   div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
@@ -145,5 +136,4 @@ <h2>On this page</h2>
 }
 </script>
 </body>
-
 </html>

---FILE: docs/crashcourse.html---
@@ -17,10 +17,10 @@
 <meta name=""twitter:title"" content=""Chapter 1 Bayesian statistics &amp; MCMC | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R"">
 <meta name=""twitter:description"" content=""1.1 Bayes‚Äô theorem A theorem about conditional probabilities. \(\Pr(B \mid A) = \displaystyle{\frac{ \Pr(A \mid B) \; \Pr(B)}{\Pr(A)}}\)  Figure 1.1: Bayes‚Äô theorem spelt out in blue neon at the..."">
 <meta name=""twitter:image"" content=""https://oliviergimenez.github.io/bayesian-cr-workshop//images/satellite.png"">
-<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs-2.10/header-attrs.js""></script><script src=""libs/jquery-3.6.0/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
-<link href=""libs/bootstrap-4.6.0/bootstrap.min.css"" rel=""stylesheet"">
-<script src=""libs/bootstrap-4.6.0/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat-0.2.5.1/tabs.js""></script><script src=""libs/bs3compat-0.2.5.1/bs3compat.js""></script><link href=""libs/bs4_book-1.0.0/bs4_book.css"" rel=""stylesheet"">
-<script src=""libs/bs4_book-1.0.0/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
+<!-- JS --><script src=""https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js"" integrity=""sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js"" integrity=""sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A=="" crossorigin=""anonymous""></script><script src=""https://kit.fontawesome.com/6ecbd6c532.js"" crossorigin=""anonymous""></script><script src=""libs/header-attrs/header-attrs.js""></script><script src=""libs/jquery/jquery-3.6.0.min.js""></script><meta name=""viewport"" content=""width=device-width, initial-scale=1, shrink-to-fit=no"">
+<link href=""libs/bootstrap/bootstrap.min.css"" rel=""stylesheet"">
+<script src=""libs/bootstrap/bootstrap.bundle.min.js""></script><script src=""libs/bs3compat/tabs.js""></script><script src=""libs/bs3compat/bs3compat.js""></script><link href=""libs/bs4_book/bs4_book.css"" rel=""stylesheet"">
+<script src=""libs/bs4_book/bs4_book.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js"" integrity=""sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg=="" crossorigin=""anonymous""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js"" integrity=""sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww=="" crossorigin=""anonymous""></script><!-- CSS --><link rel=""stylesheet"" href=""bs4_style.css"">
 </head>
 <body data-spy=""scroll"" data-target=""#toc"">
 
@@ -41,7 +41,38 @@ <h1>
 </form>
 
       <nav aria-label=""Table of contents""><h2>Table of contents</h2>
-        <ul class=""book-toc list-unstyled""><li><a class="""" href=""index.html""><span class=""header-section-number"">Chapter 1</span> Bayesian statistics &amp; MCMC</a></li></ul>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li><a class="""" href=""about-the-author.html"">About the Author</a></li>
+<li class=""book-part"">Theory</li>
+<li><a class=""active"" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class="""" href=""intronimble.html""><span class=""header-section-number"">2</span> Introduction to Nimble</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""transition.html""><span class=""header-section-number"">5</span> Transition</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">6</span> Covariates</a></li>
+<li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">7</span> Uncertainty in state assignment</a></li>
+<li><a class="""" href=""abundance.html""><span class=""header-section-number"">8</span> Abundance</a></li>
+<li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
+<li><a class="""" href=""states.html""><span class=""header-section-number"">10</span> Hidden states</a></li>
+<li><a class="""" href=""speed.html""><span class=""header-section-number"">11</span> Speed up MCMC</a></li>
+<li class=""book-part"">Case studies</li>
+<li><a class="""" href=""senescence.html""><span class=""header-section-number"">12</span> Actuarial senescence</a></li>
+<li><a class="""" href=""heterogeneity.html""><span class=""header-section-number"">13</span> Individual heterogeneity</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">14</span> Life-history tradeoffs</a></li>
+<li><a class="""" href=""breeding.html""><span class=""header-section-number"">15</span> Breeding dynamics</a></li>
+<li><a class="""" href=""rd.html""><span class=""header-section-number"">16</span> Robust design</a></li>
+<li><a class="""" href=""stopover.html""><span class=""header-section-number"">17</span> Stopover duration</a></li>
+<li><a class="""" href=""disease.html""><span class=""header-section-number"">18</span> Disease dynamics</a></li>
+<li><a class="""" href=""sex.html""><span class=""header-section-number"">19</span> Sex uncertainty</a></li>
+<li><a class="""" href=""dependence.html""><span class=""header-section-number"">20</span> Dependence among individuals</a></li>
+<li><a class="""" href=""covariateselection.html""><span class=""header-section-number"">21</span> Individual and temporal variability</a></li>
+<li><a class="""" href=""mortalities.html""><span class=""header-section-number"">22</span> Cause-specific mortalities</a></li>
+<li><a class="""" href=""prevalence.html""><span class=""header-section-number"">23</span> Prevalence</a></li>
+<li><a class="""" href=""faq.html"">FAQ</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
 
         <div class=""book-extra"">
           <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
@@ -59,7 +90,7 @@ <h2>
 <p>A theorem about conditional probabilities.</p>
 <p><span class=""math inline"">\(\Pr(B \mid A) = \displaystyle{\frac{ \Pr(A \mid B) \; \Pr(B)}{\Pr(A)}}\)</span></p>
 <div class=""figure"">
-<span style=""display:block;"" id=""fig:unnamed-chunk-3""></span>
+<span style=""display:block;"" id=""fig:unnamed-chunk-6""></span>
 <img src=""images/bayes_neon.jpeg"" alt=""Bayes' theorem spelt out in blue neon at the offices of Autonomy in Cambridge. Source: Wikipedia"" width=""400""><p class=""caption"">
 Figure 1.1: Bayes‚Äô theorem spelt out in blue neon at the offices of Autonomy in Cambridge. Source: Wikipedia
 </p>
@@ -118,7 +149,7 @@ <h2>
 <span class=""header-section-number"">1.5</span> Brute force via numerical integration<a class=""anchor"" aria-label=""anchor"" href=""#brute-force-via-numerical-integration""><i class=""fas fa-link""></i></a>
 </h2>
 <p>Say we release <span class=""math inline"">\(n\)</span> animals at the beginning of the winter, out of which <span class=""math inline"">\(y\)</span> survive, and we‚Äôd like to estimate winter survival <span class=""math inline"">\(\theta\)</span>.</p>
-<div class=""sourceCode"" id=""cb1""><pre class=""downlit sourceCode r"">
+<div class=""sourceCode"" id=""cb2""><pre class=""downlit sourceCode r"">
 <code class=""sourceCode R""><span class=""va"">y</span> <span class=""op"">&lt;-</span> <span class=""fl"">19</span> <span class=""co""># nb of success</span>
 <span class=""va"">n</span> <span class=""op"">&lt;-</span> <span class=""fl"">57</span> <span class=""co""># nb of attempts</span></code></pre></div>
 </div>
@@ -134,15 +165,24 @@ <h2>
 </div>
 </div>
   <div class=""chapter-nav"">
-<div class=""empty""></div>
-<div class=""empty""></div>
+<div class=""prev""><a href=""about-the-author.html"">About the Author</a></div>
+<div class=""next""><a href=""intronimble.html""><span class=""header-section-number"">2</span> Introduction to Nimble</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
-      <div id=""book-on-this-page""></div>
+      <ul class=""nav navbar-nav"">
+<li><a class=""nav-link"" href=""#crashcourse""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class=""nav-link"" href=""#bayes-theorem""><span class=""header-section-number"">1.1</span> Bayes‚Äô theorem</a></li>
+<li><a class=""nav-link"" href=""#frequentist-versus-bayesian""><span class=""header-section-number"">1.2</span> Frequentist versus Bayesian</a></li>
+<li><a class=""nav-link"" href=""#what-is-the-bayesian-approach""><span class=""header-section-number"">1.3</span> What is the Bayesian approach?</a></li>
+<li><a class=""nav-link"" href=""#bayes-theorem-1""><span class=""header-section-number"">1.4</span> Bayes‚Äô theorem</a></li>
+<li><a class=""nav-link"" href=""#brute-force-via-numerical-integration""><span class=""header-section-number"">1.5</span> Brute force via numerical integration</a></li>
+<li><a class=""nav-link"" href=""#further-reading""><span class=""header-section-number"">1.6</span> Further reading</a></li>
+</ul>
 
       <div class=""book-extra"">
         <ul class=""list-unstyled"">
-          
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/01-bayesMCMC.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/01-bayesMCMC.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
         </ul>
 </div>
     </nav>

---FILE: docs/intronimble.html---
@@ -41,7 +41,38 @@ <h1>
 </form>
 
       <nav aria-label=""Table of contents""><h2>Table of contents</h2>
-        <ul class=""book-toc list-unstyled""><li><a class="""" href=""index.html""><span class=""header-section-number"">Chapter 2</span> Introduction to Nimble</a></li></ul>
+        <ul class=""book-toc list-unstyled"">
+<li><a class="""" href=""index.html"">Welcome</a></li>
+<li><a class="""" href=""preface.html"">Preface</a></li>
+<li><a class="""" href=""about-the-author.html"">About the Author</a></li>
+<li class=""book-part"">Theory</li>
+<li><a class="""" href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></li>
+<li><a class=""active"" href=""intronimble.html""><span class=""header-section-number"">2</span> Introduction to Nimble</a></li>
+<li><a class="""" href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></li>
+<li><a class="""" href=""survival.html""><span class=""header-section-number"">4</span> Survival</a></li>
+<li><a class="""" href=""transition.html""><span class=""header-section-number"">5</span> Transition</a></li>
+<li><a class="""" href=""covariates.html""><span class=""header-section-number"">6</span> Covariates</a></li>
+<li><a class="""" href=""uncertainty.html""><span class=""header-section-number"">7</span> Uncertainty in state assignment</a></li>
+<li><a class="""" href=""abundance.html""><span class=""header-section-number"">8</span> Abundance</a></li>
+<li><a class="""" href=""hsmm.html""><span class=""header-section-number"">9</span> Hidden semi-Markov models</a></li>
+<li><a class="""" href=""states.html""><span class=""header-section-number"">10</span> Hidden states</a></li>
+<li><a class="""" href=""speed.html""><span class=""header-section-number"">11</span> Speed up MCMC</a></li>
+<li class=""book-part"">Case studies</li>
+<li><a class="""" href=""senescence.html""><span class=""header-section-number"">12</span> Actuarial senescence</a></li>
+<li><a class="""" href=""heterogeneity.html""><span class=""header-section-number"">13</span> Individual heterogeneity</a></li>
+<li><a class="""" href=""tradeoffs.html""><span class=""header-section-number"">14</span> Life-history tradeoffs</a></li>
+<li><a class="""" href=""breeding.html""><span class=""header-section-number"">15</span> Breeding dynamics</a></li>
+<li><a class="""" href=""rd.html""><span class=""header-section-number"">16</span> Robust design</a></li>
+<li><a class="""" href=""stopover.html""><span class=""header-section-number"">17</span> Stopover duration</a></li>
+<li><a class="""" href=""disease.html""><span class=""header-section-number"">18</span> Disease dynamics</a></li>
+<li><a class="""" href=""sex.html""><span class=""header-section-number"">19</span> Sex uncertainty</a></li>
+<li><a class="""" href=""dependence.html""><span class=""header-section-number"">20</span> Dependence among individuals</a></li>
+<li><a class="""" href=""covariateselection.html""><span class=""header-section-number"">21</span> Individual and temporal variability</a></li>
+<li><a class="""" href=""mortalities.html""><span class=""header-section-number"">22</span> Cause-specific mortalities</a></li>
+<li><a class="""" href=""prevalence.html""><span class=""header-section-number"">23</span> Prevalence</a></li>
+<li><a class="""" href=""faq.html"">FAQ</a></li>
+<li><a class="""" href=""references.html"">References</a></li>
+</ul>
 
         <div class=""book-extra"">
           <p><a id=""book-repo"" href=""https://github.com/oliviergimenez/banana-book"">View book source <i class=""fab fa-github""></i></a></p>
@@ -57,15 +88,16 @@ <h1>
 
 </div>
   <div class=""chapter-nav"">
-<div class=""empty""></div>
-<div class=""empty""></div>
+<div class=""prev""><a href=""crashcourse.html""><span class=""header-section-number"">1</span> Bayesian statistics &amp; MCMC</a></div>
+<div class=""next""><a href=""hmmcapturerecapture.html""><span class=""header-section-number"">3</span> Hidden Markov models</a></div>
 </div></main><div class=""col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter"">
     <nav id=""toc"" data-toggle=""toc"" aria-label=""On this page""><h2>On this page</h2>
-      <div id=""book-on-this-page""></div>
+      <ul class=""nav navbar-nav""><li><a class=""nav-link"" href=""#intronimble""><span class=""header-section-number"">2</span> Introduction to Nimble</a></li></ul>
 
       <div class=""book-extra"">
         <ul class=""list-unstyled"">
-          
+<li><a id=""book-source"" href=""https://github.com/oliviergimenez/banana-book/blob/master/02-introNimble.Rmd"">View source <i class=""fab fa-github""></i></a></li>
+          <li><a id=""book-edit"" href=""https://github.com/oliviergimenez/banana-book/edit/master/02-introNimble.Rmd"">Edit this page <i class=""fab fa-github""></i></a></li>
         </ul>
 </div>
     </nav>

---FILE: docs/preface.html---
@@ -123,22 +123,26 @@ <h2>Software information and conventions<a class=""anchor"" aria-label=""anchor"" hr
 <span class=""co"">## [6] methods   base     </span>
 <span class=""co"">## </span>
 <span class=""co"">## loaded via a namespace (and not attached):</span>
-<span class=""co"">##  [1] rstudioapi_0.13   knitr_1.33       </span>
-<span class=""co"">##  [3] xml2_1.3.2        magrittr_2.0.1   </span>
-<span class=""co"">##  [5] downlit_0.2.1     R6_2.5.0         </span>
-<span class=""co"">##  [7] rlang_0.4.11      fansi_0.5.0      </span>
-<span class=""co"">##  [9] stringr_1.4.0     tools_4.1.0      </span>
-<span class=""co"">## [11] xfun_0.25         utf8_1.2.2       </span>
-<span class=""co"">## [13] jquerylib_0.1.4   htmltools_0.5.1.1</span>
-<span class=""co"">## [15] ellipsis_0.3.2    yaml_2.2.1       </span>
-<span class=""co"">## [17] digest_0.6.27     tibble_3.1.3     </span>
-<span class=""co"">## [19] lifecycle_1.0.0   crayon_1.4.1     </span>
-<span class=""co"">## [21] bookdown_0.23     vctrs_0.3.8      </span>
-<span class=""co"">## [23] sass_0.4.0        fs_1.5.0         </span>
-<span class=""co"">## [25] evaluate_0.14     rmarkdown_2.10   </span>
-<span class=""co"">## [27] stringi_1.7.3     compiler_4.1.0   </span>
-<span class=""co"">## [29] bslib_0.2.5.1     pillar_1.6.2     </span>
-<span class=""co"">## [31] jsonlite_1.7.2    pkgconfig_2.0.3</span></code></pre></div>
+<span class=""co"">##  [1] Rcpp_1.0.7        rstudioapi_0.13  </span>
+<span class=""co"">##  [3] servr_0.23        knitr_1.33       </span>
+<span class=""co"">##  [5] xml2_1.3.2        magrittr_2.0.1   </span>
+<span class=""co"">##  [7] downlit_0.2.1     R6_2.5.0         </span>
+<span class=""co"">##  [9] jpeg_0.1-9        rlang_0.4.11     </span>
+<span class=""co"">## [11] fansi_0.5.0       highr_0.9        </span>
+<span class=""co"">## [13] stringr_1.4.0     tools_4.1.0      </span>
+<span class=""co"">## [15] xfun_0.25         utf8_1.2.2       </span>
+<span class=""co"">## [17] jquerylib_0.1.4   htmltools_0.5.1.1</span>
+<span class=""co"">## [19] ellipsis_0.3.2    yaml_2.2.1       </span>
+<span class=""co"">## [21] digest_0.6.27     tibble_3.1.3     </span>
+<span class=""co"">## [23] lifecycle_1.0.0   crayon_1.4.1     </span>
+<span class=""co"">## [25] bookdown_0.23     later_1.2.0      </span>
+<span class=""co"">## [27] promises_1.2.0.1  vctrs_0.3.8      </span>
+<span class=""co"">## [29] sass_0.4.0        fs_1.5.0         </span>
+<span class=""co"">## [31] mime_0.11         evaluate_0.14    </span>
+<span class=""co"">## [33] rmarkdown_2.10    stringi_1.7.3    </span>
+<span class=""co"">## [35] compiler_4.1.0    bslib_0.2.5.1    </span>
+<span class=""co"">## [37] pillar_1.6.2      jsonlite_1.7.2   </span>
+<span class=""co"">## [39] httpuv_1.6.1      pkgconfig_2.0.3</span></code></pre></div>
 <p>We do not add prompts (<code><a href=""https://rdrr.io/r/base/Comparison.html"">&gt;</a></code> and <code><a href=""https://rdrr.io/r/base/Arithmetic.html"">+</a></code>) to R source code in this book, and we comment out the text output with two hashes <code>##</code> by default, as you can see from the R session information above. This is for your convenience when you want to copy and run the code (the text output will be ignored since it is commented out). Package names are in bold text (e.g., <strong>nimble</strong>), and inline code and filenames are formatted in a typewriter font (e.g., <code><a href=""https://rdrr.io/pkg/knitr/man/knit.html"">knitr::knit('foo.Rmd')</a></code>). Function names are followed by parentheses (e.g., <code><a href=""https://rdrr.io/pkg/nimble/man/nimbleCode.html"">nimble::nimbleCode()</a></code>). The double-colon operator <code><a href=""https://rdrr.io/r/base/ns-dblcolon.html"">::</a></code> means accessing an object from a package.</p>
 </div>
 <div id=""acknowledgments"" class=""section level2 unnumbered"">

---FILE: docs/reference-keys.txt---
@@ -1,3 +1,4 @@
+fig:unnamed-chunk-6
 crashcourse
 bayes-theorem
 frequentist-versus-bayesian
@@ -27,4 +28,3 @@ dependence
 covariateselection
 mortalities
 prevalence
-fig:unnamed-chunk-3

---FILE: docs/search.json---
@@ -1 +1 @@
-[{""path"":""index.html"",""id"":""welcome"",""chapter"":""Welcome"",""heading"":""Welcome"",""text"":""Welcome website book Bayesian Analysis Capture-Recapture Data Hidden Markov Models ‚Äì Theory Case Studies R Olivier Gimenez. Note book also available PDF format.‚Äôm currently writing book, welcome feedback requests content .Many thanks!Last updated: August 26, 2021"",""code"":""""},{""path"":""preface.html"",""id"":""preface"",""chapter"":""Preface"",""heading"":""Preface"",""text"":""HMM framework gained much attention ecological literature last decade, suggested general modelling framework demography plant animal populations. particular, HMMs increasingly used analyse capture-recapture data estimate key population parameters (e.g., survival, dispersal, recruitment abundance) applications fields ecology. parallel, Bayesian statistics relatively well established fast growing ecology related disciplines, resonates scientific reasoning allows accommodating uncertainty smoothly. popularity Bayesian statistics also comes availability free pieces software (WinBUGS, OpenBUGS, JAGS, Stan, nimble) allow practitioners code analyses.However, knowledge, full Bayesian treatment HMMs applied capture-recapture data yet proposed book. propose book. Besides, popular software solutions come computational limitations ecologists deal complex models /big data. use Nimble seen many future ecological data modelling extends BUGS language writing new functions distributions, provides samplers can deal discrete latent states contrast Stan.book, cover theory HMMs capture-recapture data, applications models empower practitioners fit models confidence. important part book consist case studies presented tutorial style abide ‚Äúlearning ‚Äù philosophy.\nonline version book licensed Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "",""code"":""""},{""path"":""preface.html"",""id"":""why-read-this-book"",""chapter"":""Preface"",""heading"":""Why read this book"",""text"":"""",""code"":""""},{""path"":""preface.html"",""id"":""structure-of-the-book"",""chapter"":""Preface"",""heading"":""Structure of the book"",""text"":""Blabla."",""code"":""""},{""path"":""preface.html"",""id"":""software-information-and-conventions"",""chapter"":""Preface"",""heading"":""Software information and conventions"",""text"":""book uses primarily R package nimble, need least install R nimble package.R session information compiling book shown :add prompts (> +) R source code book, comment text output two hashes ## default, can see R session information . convenience want copy run code (text output ignored since commented ). Package names bold text (e.g., nimble), inline code filenames formatted typewriter font (e.g., knitr::knit('foo.Rmd')). Function names followed parentheses (e.g., nimble::nimbleCode()). double-colon operator :: means accessing object package."",""code"":""\nsessionInfo()\n## R version 4.1.0 (2021-05-18)\n## Platform: x86_64-apple-darwin17.0 (64-bit)\n## Running under: macOS Catalina 10.15.7\n## \n## Matrix products: default\n## BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib\n## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib\n## \n## locale:\n## [1] fr_FR.UTF-8/fr_FR.UTF-8/fr_FR.UTF-8/C/C/fr_FR.UTF-8\n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets \n## [6] methods   base     \n## \n## loaded via a namespace (and not attached):\n##  [1] rstudioapi_0.13   knitr_1.33       \n##  [3] xml2_1.3.2        magrittr_2.0.1   \n##  [5] downlit_0.2.1     R6_2.5.0         \n##  [7] rlang_0.4.11      fansi_0.5.0      \n##  [9] stringr_1.4.0     tools_4.1.0      \n## [11] xfun_0.25         utf8_1.2.2       \n## [13] jquerylib_0.1.4   htmltools_0.5.1.1\n## [15] ellipsis_0.3.2    yaml_2.2.1       \n## [17] digest_0.6.27     tibble_3.1.3     \n## [19] lifecycle_1.0.0   crayon_1.4.1     \n## [21] bookdown_0.23     vctrs_0.3.8      \n## [23] sass_0.4.0        fs_1.5.0         \n## [25] evaluate_0.14     rmarkdown_2.10   \n## [27] stringi_1.7.3     compiler_4.1.0   \n## [29] bslib_0.2.5.1     pillar_1.6.2     \n## [31] jsonlite_1.7.2    pkgconfig_2.0.3""},{""path"":""preface.html"",""id"":""acknowledgments"",""chapter"":""Preface"",""heading"":""Acknowledgments"",""text"":""CNRS. Jean-. Roger. R√©mi. students. Chlo√©, Sarah, Perry, Daniel. Rob Chapman & Hall/CRC. Workshop attendees. Feedback . FIP radio. Marc K√©ry support advice write book. Proofreading . family.\nOlivier Gimenez\nMontpellier, France\n"",""code"":""""},{""path"":""about-the-author.html"",""id"":""about-the-author"",""chapter"":""About the Author"",""heading"":""About the Author"",""text"":""Je m‚Äôappelle Olivier Gimenez (https://oliviergimenez.github.io/). Je suis directeur de recherche au CNRS. Apr√®s des √©tudes universitaires en math√©matiques, j‚Äôai fait une th√®se en statistiques pour l‚Äô√©cologie. J‚Äôai pass√© mon Habilitation √† Diriger des Recherches en √©cologie et √©volution. R√©cemment, je suis retourn√© sur les bancs de l‚Äôuniversit√© pour m‚Äôinitier √† la sociologie.J‚Äôai √©crit des articles scientifiques faisant appel √† la statistique bay√©sienne, et co-√©crit avec des coll√®gues britanniques un livre sur les analyses bay√©siennes pour l‚Äô√©cologie des populations.Vous pouvez retrouver sur Twitter (https://twitter.com/oaggimenez), ou bien contacter via mon adresse email qui s‚Äô√©crit olivier suivi d‚Äôun point puis gimenez, ensuite arobase, puis cefe, suivi d‚Äôun point, puis cnrs, suivi d‚Äôun point et pour terminer fr.Tomb√© dedans quand j‚Äô√©tais petit. Ob√©lix Roger et Ast√©rix JD."",""code"":""""},{""path"":""crashcourse.html"",""id"":""crashcourse"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1 Bayesian statistics & MCMC"",""text"":"""",""code"":""""},{""path"":""crashcourse.html"",""id"":""bayes-theorem"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.1 Bayes‚Äô theorem"",""text"":""theorem conditional probabilities.theorem conditional probabilities.\\(\\Pr(B \\mid ) = \\displaystyle{\\frac{ \\Pr(\\mid B) \\; \\Pr(B)}{\\Pr()}}\\)\\(\\Pr(B \\mid ) = \\displaystyle{\\frac{ \\Pr(\\mid B) \\; \\Pr(B)}{\\Pr()}}\\)always forget letters mean.always forget letters mean.Might easier remember written like :Might easier remember written like :\\[ \\Pr(\\text{hypothesis} \\mid \\text{data}) = \\frac{ \\Pr(\\text{data} \\mid \\text{hypothesis}) \\; \\Pr(\\text{hypothesis})}{\\Pr(\\text{data})} \\]‚Äúhypothesis‚Äù typically something unobserved unknown. ‚Äôs want learn using data.‚Äúhypothesis‚Äù typically something unobserved unknown. ‚Äôs want learn using data.regression models, ‚Äúhypothesis‚Äù parameter (intercept, slopes error terms).regression models, ‚Äúhypothesis‚Äù parameter (intercept, slopes error terms).Bayes theorem tells probability hypothesis given data.Bayes theorem tells probability hypothesis given data.Cool science ?Cool science ?plausible hypothesis given data?\\[ \\Pr(\\text{hypothesis} \\mid \\text{data}) = \\frac{ \\Pr(\\text{data} \\mid \\text{hypothesis}) \\; \\Pr(\\text{hypothesis})}{\\Pr(\\text{data})} \\]\n???Bayesian reasoning echoes scientific reasoning.might ask , Bayesian statistics default?may ask: Bayesian statistics default?Due practical problems implementing Bayesian approach, futile wars (male) statisticians, little progress made two centuries.Due practical problems implementing Bayesian approach, futile wars (male) statisticians, little progress made two centuries.Recent advances computational power coupled development new methodology led great increase application Bayesian methods within last two decades.Recent advances computational power coupled development new methodology led great increase application Bayesian methods within last two decades."",""code"":""\nknitr::include_graphics(\""images/bayes_neon.jpeg\"")""},{""path"":""crashcourse.html"",""id"":""frequentist-versus-bayesian"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.2 Frequentist versus Bayesian"",""text"":""Typical stats problems involve estimating parameter \\(\\theta\\) available data.Typical stats problems involve estimating parameter \\(\\theta\\) available data.frequentist approach (maximum likelihood estimation ‚Äì MLE) assumes parameters fixed, unknown values estimated.frequentist approach (maximum likelihood estimation ‚Äì MLE) assumes parameters fixed, unknown values estimated.Classical estimates generally point estimates parameters interest.Classical estimates generally point estimates parameters interest.Bayesian approach assumes parameters fixed fixed unknown distribution - distribution parameter.Bayesian approach assumes parameters fixed fixed unknown distribution - distribution parameter."",""code"":""""},{""path"":""crashcourse.html"",""id"":""what-is-the-bayesian-approach"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.3 What is the Bayesian approach?"",""text"":""approach based upon idea experimenter begins prior beliefs system.approach based upon idea experimenter begins prior beliefs system.never start scratch.never start scratch.updates beliefs basis observed data.updates beliefs basis observed data.updating procedure based upon Bayes‚Äô Theorem:updating procedure based upon Bayes‚Äô Theorem:\\[\\Pr(\\mid B) = \\frac{\\Pr(B \\mid ) \\; \\Pr()}{\\Pr(B)}\\]Schematically \\(= \\theta\\) \\(B = \\text{data}\\), thenSchematically \\(= \\theta\\) \\(B = \\text{data}\\), thenThe Bayes‚Äô theoremThe Bayes‚Äô theorem\\[\\Pr(\\mid B) = \\frac{\\Pr(B \\mid ) \\; \\Pr()}{\\Pr(B)}\\]Translates :\\[\\Pr(\\theta \\mid \\text{data}) = \\frac{\\Pr(\\text{data} \\mid \\theta) \\; \\Pr(\\theta)}{\\Pr(\\text{data})}\\]"",""code"":""""},{""path"":""crashcourse.html"",""id"":""bayes-theorem-1"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.4 Bayes‚Äô theorem"",""text"":""\\[{\\color{red}{\\Pr(\\theta \\mid \\text{data})}} = \\frac{\\color{blue}{\\Pr(\\text{data} \\mid \\theta)} \\; \\color{green}{\\Pr(\\theta)}}{\\color{orange}{\\Pr(\\text{data})}}\\]\\(\\color{red}{\\text{Posterior distribution}}\\): Represents know seen data. basis inference, distribution, possibly multivariate one parameter.\\(\\color{red}{\\text{Posterior distribution}}\\): Represents know seen data. basis inference, distribution, possibly multivariate one parameter.\\(\\color{blue}{\\text{Likelihood}}\\): quantity MLE approach.\\(\\color{blue}{\\text{Likelihood}}\\): quantity MLE approach.\\(\\color{green}{\\text{Prior distribution}}\\): Represents know seeing data. source much discussion Bayesian approach.\\(\\color{green}{\\text{Prior distribution}}\\): Represents know seeing data. source much discussion Bayesian approach.\\(\\color{orange}{\\Pr(\\text{data}) = \\int{L(\\text{data} \\mid \\theta)\\Pr(\\theta) d\\theta}}\\) \\(N\\)-dimensional integral \\(\\theta = \\theta_1, \\ldots, \\theta_N\\).\\(\\color{orange}{\\Pr(\\text{data}) = \\int{L(\\text{data} \\mid \\theta)\\Pr(\\theta) d\\theta}}\\) \\(N\\)-dimensional integral \\(\\theta = \\theta_1, \\ldots, \\theta_N\\).Difficult impossible calculate. one reasons need simulation (MCMC) methods.Difficult impossible calculate. one reasons need simulation (MCMC) methods."",""code"":""""},{""path"":""crashcourse.html"",""id"":""brute-force-via-numerical-integration"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.5 Brute force via numerical integration"",""text"":""Say release \\(n\\) animals beginning winter, \\(y\\) survive, ‚Äôd like estimate winter survival \\(\\theta\\)."",""code"":""\ny <- 19 # nb of success\nn <- 57 # nb of attempts""},{""path"":""crashcourse.html"",""id"":""further-reading"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.6 Further reading"",""text"":""McCarthy, M. (2007). Bayesian Methods Ecology. Cambridge: Cambridge University Press.McCarthy, M. (2007). Bayesian Methods Ecology. Cambridge: Cambridge University Press.McElreath, R. (2020). Statistical Rethinking: Bayesian Course Examples R Stan (2nd ed.). CRC Press.McElreath, R. (2020). Statistical Rethinking: Bayesian Course Examples R Stan (2nd ed.). CRC Press.Gelman, . Hill, J. (2006). Data Analysis Using Regression Multilevel/Hierarchical Models (Analytical Methods Social Research). Cambridge: Cambridge University Press.Gelman, . Hill, J. (2006). Data Analysis Using Regression Multilevel/Hierarchical Models (Analytical Methods Social Research). Cambridge: Cambridge University Press."",""code"":""""},{""path"":""intronimble.html"",""id"":""intronimble"",""chapter"":""2 Introduction to Nimble"",""heading"":""2 Introduction to Nimble"",""text"":"""",""code"":""""},{""path"":""hmmcapturerecapture.html"",""id"":""hmmcapturerecapture"",""chapter"":""3 Hidden Markov models"",""heading"":""3 Hidden Markov models"",""text"":""Heller Pogaru (2021)"",""code"":""""},{""path"":""survival.html"",""id"":""survival"",""chapter"":""4 Survival"",""heading"":""4 Survival"",""text"":"""",""code"":""""},{""path"":""transition.html"",""id"":""transition"",""chapter"":""5 Transition"",""heading"":""5 Transition"",""text"":"""",""code"":""""},{""path"":""covariates.html"",""id"":""covariates"",""chapter"":""6 Covariates"",""heading"":""6 Covariates"",""text"":"""",""code"":""""},{""path"":""uncertainty.html"",""id"":""uncertainty"",""chapter"":""7 Uncertainty in state assignment"",""heading"":""7 Uncertainty in state assignment"",""text"":"""",""code"":""""},{""path"":""abundance.html"",""id"":""abundance"",""chapter"":""8 Abundance"",""heading"":""8 Abundance"",""text"":"""",""code"":""""},{""path"":""hsmm.html"",""id"":""hsmm"",""chapter"":""9 Hidden semi-Markov models"",""heading"":""9 Hidden semi-Markov models"",""text"":"""",""code"":""""},{""path"":""states.html"",""id"":""states"",""chapter"":""10 Hidden states"",""heading"":""10 Hidden states"",""text"":"""",""code"":""""},{""path"":""speed.html"",""id"":""speed"",""chapter"":""11 Speed up MCMC"",""heading"":""11 Speed up MCMC"",""text"":"""",""code"":""""},{""path"":""senescence.html"",""id"":""senescence"",""chapter"":""12 Actuarial senescence"",""heading"":""12 Actuarial senescence"",""text"":""Choquet et al. (2011), P√©ron et al. (2016)"",""code"":""""},{""path"":""heterogeneity.html"",""id"":""heterogeneity"",""chapter"":""13 Individual heterogeneity"",""heading"":""13 Individual heterogeneity"",""text"":""Cubaynes et al. (2010), Gimenez Choquet (2010), Turek, Wehrhahn, Gimenez (2021)"",""code"":""""},{""path"":""tradeoffs.html"",""id"":""tradeoffs"",""chapter"":""14 Life-history tradeoffs"",""heading"":""14 Life-history tradeoffs"",""text"":""Morano et al. (2013), Shefferson et al. (2003), Cruz-Flores et al. (n.d.)"",""code"":""""},{""path"":""breeding.html"",""id"":""breeding"",""chapter"":""15 Breeding dynamics"",""heading"":""15 Breeding dynamics"",""text"":""Pradel, Choquet, B√©chet (2012), Desprez et al. (2011), Desprez et al. (2013), Pacoureau et al. (2019)"",""code"":""""},{""path"":""rd.html"",""id"":""rd"",""chapter"":""16 Robust design"",""heading"":""16 Robust design"",""text"":""Karamanlidis et al. (2015), Santostasi et al. (2016), Gibson et al. (2018), Rankin et al. (2016)"",""code"":""""},{""path"":""stopover.html"",""id"":""stopover"",""chapter"":""17 Stopover duration"",""heading"":""17 Stopover duration"",""text"":""Gu√©rin et al. (2017)"",""code"":""""},{""path"":""disease.html"",""id"":""disease"",""chapter"":""18 Disease dynamics"",""heading"":""18 Disease dynamics"",""text"":""Marescot et al. (2018) Santoro et al. (2014)"",""code"":""""},{""path"":""sex.html"",""id"":""sex"",""chapter"":""19 Sex uncertainty"",""heading"":""19 Sex uncertainty"",""text"":""Pradel et al. (2008) Genovart, Pradel, Oro (2012)"",""code"":""""},{""path"":""dependence.html"",""id"":""dependence"",""chapter"":""20 Dependence among individuals"",""heading"":""20 Dependence among individuals"",""text"":""Culina et al. (2013) Cubaynes et al. (2021)"",""code"":""""},{""path"":""covariateselection.html"",""id"":""covariateselection"",""chapter"":""21 Individual and temporal variability"",""heading"":""21 Individual and temporal variability"",""text"":""Grosbois et al. (2008), Cubaynes et al. (2012), Gimenez et al. (2006), Bonner, Morgan, King (2010)"",""code"":""""},{""path"":""mortalities.html"",""id"":""mortalities"",""chapter"":""22 Cause-specific mortalities"",""heading"":""22 Cause-specific mortalities"",""text"":""Fern√°ndez-Chac√≥n et al. (2016) Ruette et al. (2015)"",""code"":""""},{""path"":""prevalence.html"",""id"":""prevalence"",""chapter"":""23 Prevalence"",""heading"":""23 Prevalence"",""text"":""(Santostasi et al. 2019)"",""code"":""""},{""path"":""faq.html"",""id"":""faq"",""chapter"":""FAQ"",""heading"":""FAQ"",""text"":""complete list frequently asked questions (FAQ). Yes, one question . Personally like FAQs. often mean surprises, surprises good software users.Q: bookdown features X, Y, Z?\n: short answer , asked three times ‚Äúreally need ‚Äù answer still ‚Äúyes,‚Äù please feel free file feature request https://github.com/rstudio/bookdown/issues.\nUsers asking features often come LaTeX world. case , answer question yes, Pandoc‚Äôs Markdown supports raw LaTeX code. Whenever feel Markdown job , always option apply raw LaTeX code Markdown document. example, can create glossaries using glossaries package, embed complicated LaTeX table, long know LaTeX syntax. However, please keep mind LaTeX content portable. work LaTeX/PDF output, ignored types output. Depending request, may port LaTeX features bookdown future, general philosophy Markdown kept simple possible.Q: bookdown features X, Y, Z?: short answer , asked three times ‚Äúreally need ‚Äù answer still ‚Äúyes,‚Äù please feel free file feature request https://github.com/rstudio/bookdown/issues.Users asking features often come LaTeX world. case , answer question yes, Pandoc‚Äôs Markdown supports raw LaTeX code. Whenever feel Markdown job , always option apply raw LaTeX code Markdown document. example, can create glossaries using glossaries package, embed complicated LaTeX table, long know LaTeX syntax. However, please keep mind LaTeX content portable. work LaTeX/PDF output, ignored types output. Depending request, may port LaTeX features bookdown future, general philosophy Markdown kept simple possible.challenging thing world learn fancy technologies, control wild heart."",""code"":""""},{""path"":""references.html"",""id"":""references"",""chapter"":""References"",""heading"":""References"",""text"":"""",""code"":""""}]
+[{""path"":""index.html"",""id"":""welcome"",""chapter"":""Welcome"",""heading"":""Welcome"",""text"":""Welcome website book Bayesian Analysis Capture-Recapture Data Hidden Markov Models ‚Äì Theory Case Studies R Olivier Gimenez. Note book also available PDF format.‚Äôm currently writing book, welcome feedback requests content .Many thanks!Last updated: August 26, 2021"",""code"":""""},{""path"":""preface.html"",""id"":""preface"",""chapter"":""Preface"",""heading"":""Preface"",""text"":""HMM framework gained much attention ecological literature last decade, suggested general modelling framework demography plant animal populations. particular, HMMs increasingly used analyse capture-recapture data estimate key population parameters (e.g., survival, dispersal, recruitment abundance) applications fields ecology. parallel, Bayesian statistics relatively well established fast growing ecology related disciplines, resonates scientific reasoning allows accommodating uncertainty smoothly. popularity Bayesian statistics also comes availability free pieces software (WinBUGS, OpenBUGS, JAGS, Stan, nimble) allow practitioners code analyses.However, knowledge, full Bayesian treatment HMMs applied capture-recapture data yet proposed book. propose book. Besides, popular software solutions come computational limitations ecologists deal complex models /big data. use Nimble seen many future ecological data modelling extends BUGS language writing new functions distributions, provides samplers can deal discrete latent states contrast Stan.book, cover theory HMMs capture-recapture data, applications models empower practitioners fit models confidence. important part book consist case studies presented tutorial style abide ‚Äúlearning ‚Äù philosophy.\nonline version book licensed Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "",""code"":""""},{""path"":""preface.html"",""id"":""why-read-this-book"",""chapter"":""Preface"",""heading"":""Why read this book"",""text"":"""",""code"":""""},{""path"":""preface.html"",""id"":""structure-of-the-book"",""chapter"":""Preface"",""heading"":""Structure of the book"",""text"":""Blabla."",""code"":""""},{""path"":""preface.html"",""id"":""software-information-and-conventions"",""chapter"":""Preface"",""heading"":""Software information and conventions"",""text"":""book uses primarily R package nimble, need least install R nimble package.R session information compiling book shown :add prompts (> +) R source code book, comment text output two hashes ## default, can see R session information . convenience want copy run code (text output ignored since commented ). Package names bold text (e.g., nimble), inline code filenames formatted typewriter font (e.g., knitr::knit('foo.Rmd')). Function names followed parentheses (e.g., nimble::nimbleCode()). double-colon operator :: means accessing object package."",""code"":""\nsessionInfo()\n## R version 4.1.0 (2021-05-18)\n## Platform: x86_64-apple-darwin17.0 (64-bit)\n## Running under: macOS Catalina 10.15.7\n## \n## Matrix products: default\n## BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib\n## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib\n## \n## locale:\n## [1] fr_FR.UTF-8/fr_FR.UTF-8/fr_FR.UTF-8/C/C/fr_FR.UTF-8\n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets \n## [6] methods   base     \n## \n## loaded via a namespace (and not attached):\n##  [1] Rcpp_1.0.7        rstudioapi_0.13  \n##  [3] servr_0.23        knitr_1.33       \n##  [5] xml2_1.3.2        magrittr_2.0.1   \n##  [7] downlit_0.2.1     R6_2.5.0         \n##  [9] jpeg_0.1-9        rlang_0.4.11     \n## [11] fansi_0.5.0       highr_0.9        \n## [13] stringr_1.4.0     tools_4.1.0      \n## [15] xfun_0.25         utf8_1.2.2       \n## [17] jquerylib_0.1.4   htmltools_0.5.1.1\n## [19] ellipsis_0.3.2    yaml_2.2.1       \n## [21] digest_0.6.27     tibble_3.1.3     \n## [23] lifecycle_1.0.0   crayon_1.4.1     \n## [25] bookdown_0.23     later_1.2.0      \n## [27] promises_1.2.0.1  vctrs_0.3.8      \n## [29] sass_0.4.0        fs_1.5.0         \n## [31] mime_0.11         evaluate_0.14    \n## [33] rmarkdown_2.10    stringi_1.7.3    \n## [35] compiler_4.1.0    bslib_0.2.5.1    \n## [37] pillar_1.6.2      jsonlite_1.7.2   \n## [39] httpuv_1.6.1      pkgconfig_2.0.3""},{""path"":""preface.html"",""id"":""acknowledgments"",""chapter"":""Preface"",""heading"":""Acknowledgments"",""text"":""CNRS. Jean-. Roger. R√©mi. students. Chlo√©, Sarah, Perry, Daniel. Rob Chapman & Hall/CRC. Workshop attendees. Feedback . FIP radio. Marc K√©ry support advice write book. Proofreading . family.\nOlivier Gimenez\nMontpellier, France\n"",""code"":""""},{""path"":""about-the-author.html"",""id"":""about-the-author"",""chapter"":""About the Author"",""heading"":""About the Author"",""text"":""Je m‚Äôappelle Olivier Gimenez (https://oliviergimenez.github.io/). Je suis directeur de recherche au CNRS. Apr√®s des √©tudes universitaires en math√©matiques, j‚Äôai fait une th√®se en statistiques pour l‚Äô√©cologie. J‚Äôai pass√© mon Habilitation √† Diriger des Recherches en √©cologie et √©volution. R√©cemment, je suis retourn√© sur les bancs de l‚Äôuniversit√© pour m‚Äôinitier √† la sociologie.J‚Äôai √©crit des articles scientifiques faisant appel √† la statistique bay√©sienne, et co-√©crit avec des coll√®gues britanniques un livre sur les analyses bay√©siennes pour l‚Äô√©cologie des populations.Vous pouvez retrouver sur Twitter (https://twitter.com/oaggimenez), ou bien contacter via mon adresse email qui s‚Äô√©crit olivier suivi d‚Äôun point puis gimenez, ensuite arobase, puis cefe, suivi d‚Äôun point, puis cnrs, suivi d‚Äôun point et pour terminer fr.Tomb√© dedans quand j‚Äô√©tais petit. Ob√©lix Roger et Ast√©rix JD."",""code"":""""},{""path"":""crashcourse.html"",""id"":""crashcourse"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1 Bayesian statistics & MCMC"",""text"":"""",""code"":""""},{""path"":""crashcourse.html"",""id"":""bayes-theorem"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.1 Bayes‚Äô theorem"",""text"":""theorem conditional probabilities.\\(\\Pr(B \\mid ) = \\displaystyle{\\frac{ \\Pr(\\mid B) \\; \\Pr(B)}{\\Pr()}}\\)\nFigure 1.1: Bayes‚Äô theorem spelt blue neon offices Autonomy Cambridge. Source: Wikipedia\nalways forget letters mean.Might easier remember written like :\\[ \\Pr(\\text{hypothesis} \\mid \\text{data}) = \\frac{ \\Pr(\\text{data} \\mid \\text{hypothesis}) \\; \\Pr(\\text{hypothesis})}{\\Pr(\\text{data})} \\]‚Äúhypothesis‚Äù typically something unobserved unknown. ‚Äôs want learn using data.regression models, ‚Äúhypothesis‚Äù parameter (intercept, slopes error terms).Bayes theorem tells probability hypothesis given data.Cool science ?plausible hypothesis given data?\\[ \\Pr(\\text{hypothesis} \\mid \\text{data}) = \\frac{ \\Pr(\\text{data} \\mid \\text{hypothesis}) \\; \\Pr(\\text{hypothesis})}{\\Pr(\\text{data})} \\]Bayesian reasoning echoes scientific reasoning. might ask , Bayesian statistics default?may ask: Bayesian statistics default?Due practical problems implementing Bayesian approach, futile wars (male) statisticians, little progress made two centuries.Recent advances computational power coupled development new methodology led great increase application Bayesian methods within last two decades."",""code"":""""},{""path"":""crashcourse.html"",""id"":""frequentist-versus-bayesian"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.2 Frequentist versus Bayesian"",""text"":""Typical stats problems involve estimating parameter \\(\\theta\\) available data.frequentist approach (maximum likelihood estimation ‚Äì MLE) assumes parameters fixed, unknown values estimated.Classical estimates generally point estimates parameters interest.Bayesian approach assumes parameters fixed fixed unknown distribution - distribution parameter."",""code"":""""},{""path"":""crashcourse.html"",""id"":""what-is-the-bayesian-approach"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.3 What is the Bayesian approach?"",""text"":""approach based upon idea experimenter begins prior beliefs system.never start scratch.updates beliefs basis observed data.updating procedure based upon Bayes‚Äô Theorem:\\[\\Pr(\\mid B) = \\frac{\\Pr(B \\mid ) \\; \\Pr()}{\\Pr(B)}\\]Schematically \\(= \\theta\\) \\(B = \\text{data}\\), thenThe Bayes‚Äô theorem\\[\\Pr(\\mid B) = \\frac{\\Pr(B \\mid ) \\; \\Pr()}{\\Pr(B)}\\]Translates :\\[\\Pr(\\theta \\mid \\text{data}) = \\frac{\\Pr(\\text{data} \\mid \\theta) \\; \\Pr(\\theta)}{\\Pr(\\text{data})}\\]"",""code"":""""},{""path"":""crashcourse.html"",""id"":""bayes-theorem-1"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.4 Bayes‚Äô theorem"",""text"":""\\[{\\color{red}{\\Pr(\\theta \\mid \\text{data})}} = \\frac{\\color{blue}{\\Pr(\\text{data} \\mid \\theta)} \\; \\color{green}{\\Pr(\\theta)}}{\\color{orange}{\\Pr(\\text{data})}}\\]\\(\\color{red}{\\text{Posterior distribution}}\\): Represents know seen data. basis inference, distribution, possibly multivariate one parameter.\\(\\color{blue}{\\text{Likelihood}}\\): quantity MLE approach.\\(\\color{green}{\\text{Prior distribution}}\\): Represents know seeing data. source much discussion Bayesian approach.\\(\\color{orange}{\\Pr(\\text{data}) = \\int{L(\\text{data} \\mid \\theta)\\Pr(\\theta) d\\theta}}\\) \\(N\\)-dimensional integral \\(\\theta = \\theta_1, \\ldots, \\theta_N\\).Difficult impossible calculate. one reasons need simulation (MCMC) methods."",""code"":""""},{""path"":""crashcourse.html"",""id"":""brute-force-via-numerical-integration"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.5 Brute force via numerical integration"",""text"":""Say release \\(n\\) animals beginning winter, \\(y\\) survive, ‚Äôd like estimate winter survival \\(\\theta\\)."",""code"":""\ny <- 19 # nb of success\nn <- 57 # nb of attempts""},{""path"":""crashcourse.html"",""id"":""further-reading"",""chapter"":""1 Bayesian statistics & MCMC"",""heading"":""1.6 Further reading"",""text"":""McCarthy, M. (2007). Bayesian Methods Ecology. Cambridge: Cambridge University Press.McCarthy, M. (2007). Bayesian Methods Ecology. Cambridge: Cambridge University Press.McElreath, R. (2020). Statistical Rethinking: Bayesian Course Examples R Stan (2nd ed.). CRC Press.McElreath, R. (2020). Statistical Rethinking: Bayesian Course Examples R Stan (2nd ed.). CRC Press.Gelman, . Hill, J. (2006). Data Analysis Using Regression Multilevel/Hierarchical Models (Analytical Methods Social Research). Cambridge: Cambridge University Press.Gelman, . Hill, J. (2006). Data Analysis Using Regression Multilevel/Hierarchical Models (Analytical Methods Social Research). Cambridge: Cambridge University Press."",""code"":""""},{""path"":""intronimble.html"",""id"":""intronimble"",""chapter"":""2 Introduction to Nimble"",""heading"":""2 Introduction to Nimble"",""text"":""Blabla.\\(x + 2 = 5\\)"",""code"":""""},{""path"":""hmmcapturerecapture.html"",""id"":""hmmcapturerecapture"",""chapter"":""3 Hidden Markov models"",""heading"":""3 Hidden Markov models"",""text"":""Heller Pogaru (2021)"",""code"":""""},{""path"":""survival.html"",""id"":""survival"",""chapter"":""4 Survival"",""heading"":""4 Survival"",""text"":"""",""code"":""""},{""path"":""transition.html"",""id"":""transition"",""chapter"":""5 Transition"",""heading"":""5 Transition"",""text"":"""",""code"":""""},{""path"":""covariates.html"",""id"":""covariates"",""chapter"":""6 Covariates"",""heading"":""6 Covariates"",""text"":"""",""code"":""""},{""path"":""uncertainty.html"",""id"":""uncertainty"",""chapter"":""7 Uncertainty in state assignment"",""heading"":""7 Uncertainty in state assignment"",""text"":"""",""code"":""""},{""path"":""abundance.html"",""id"":""abundance"",""chapter"":""8 Abundance"",""heading"":""8 Abundance"",""text"":"""",""code"":""""},{""path"":""hsmm.html"",""id"":""hsmm"",""chapter"":""9 Hidden semi-Markov models"",""heading"":""9 Hidden semi-Markov models"",""text"":"""",""code"":""""},{""path"":""states.html"",""id"":""states"",""chapter"":""10 Hidden states"",""heading"":""10 Hidden states"",""text"":"""",""code"":""""},{""path"":""speed.html"",""id"":""speed"",""chapter"":""11 Speed up MCMC"",""heading"":""11 Speed up MCMC"",""text"":"""",""code"":""""},{""path"":""senescence.html"",""id"":""senescence"",""chapter"":""12 Actuarial senescence"",""heading"":""12 Actuarial senescence"",""text"":""Choquet et al. (2011), P√©ron et al. (2016)"",""code"":""""},{""path"":""heterogeneity.html"",""id"":""heterogeneity"",""chapter"":""13 Individual heterogeneity"",""heading"":""13 Individual heterogeneity"",""text"":""Cubaynes et al. (2010), Gimenez Choquet (2010), Turek, Wehrhahn, Gimenez (2021)"",""code"":""""},{""path"":""tradeoffs.html"",""id"":""tradeoffs"",""chapter"":""14 Life-history tradeoffs"",""heading"":""14 Life-history tradeoffs"",""text"":""Morano et al. (2013), Shefferson et al. (2003), Cruz-Flores et al. (n.d.)"",""code"":""""},{""path"":""breeding.html"",""id"":""breeding"",""chapter"":""15 Breeding dynamics"",""heading"":""15 Breeding dynamics"",""text"":""Pradel, Choquet, B√©chet (2012), Desprez et al. (2011), Desprez et al. (2013), Pacoureau et al. (2019)"",""code"":""""},{""path"":""rd.html"",""id"":""rd"",""chapter"":""16 Robust design"",""heading"":""16 Robust design"",""text"":""Karamanlidis et al. (2015), Santostasi et al. (2016), Gibson et al. (2018), Rankin et al. (2016)"",""code"":""""},{""path"":""stopover.html"",""id"":""stopover"",""chapter"":""17 Stopover duration"",""heading"":""17 Stopover duration"",""text"":""Gu√©rin et al. (2017)"",""code"":""""},{""path"":""disease.html"",""id"":""disease"",""chapter"":""18 Disease dynamics"",""heading"":""18 Disease dynamics"",""text"":""Marescot et al. (2018) Santoro et al. (2014)"",""code"":""""},{""path"":""sex.html"",""id"":""sex"",""chapter"":""19 Sex uncertainty"",""heading"":""19 Sex uncertainty"",""text"":""Pradel et al. (2008) Genovart, Pradel, Oro (2012)"",""code"":""""},{""path"":""dependence.html"",""id"":""dependence"",""chapter"":""20 Dependence among individuals"",""heading"":""20 Dependence among individuals"",""text"":""Culina et al. (2013) Cubaynes et al. (2021)"",""code"":""""},{""path"":""covariateselection.html"",""id"":""covariateselection"",""chapter"":""21 Individual and temporal variability"",""heading"":""21 Individual and temporal variability"",""text"":""Grosbois et al. (2008), Cubaynes et al. (2012), Gimenez et al. (2006), Bonner, Morgan, King (2010)"",""code"":""""},{""path"":""mortalities.html"",""id"":""mortalities"",""chapter"":""22 Cause-specific mortalities"",""heading"":""22 Cause-specific mortalities"",""text"":""Fern√°ndez-Chac√≥n et al. (2016) Ruette et al. (2015)"",""code"":""""},{""path"":""prevalence.html"",""id"":""prevalence"",""chapter"":""23 Prevalence"",""heading"":""23 Prevalence"",""text"":""(Santostasi et al. 2019)"",""code"":""""},{""path"":""faq.html"",""id"":""faq"",""chapter"":""FAQ"",""heading"":""FAQ"",""text"":""complete list frequently asked questions (FAQ). Yes, one question . Personally like FAQs. often mean surprises, surprises good software users.Q: bookdown features X, Y, Z?\n: short answer , asked three times ‚Äúreally need ‚Äù answer still ‚Äúyes,‚Äù please feel free file feature request https://github.com/rstudio/bookdown/issues.\nUsers asking features often come LaTeX world. case , answer question yes, Pandoc‚Äôs Markdown supports raw LaTeX code. Whenever feel Markdown job , always option apply raw LaTeX code Markdown document. example, can create glossaries using glossaries package, embed complicated LaTeX table, long know LaTeX syntax. However, please keep mind LaTeX content portable. work LaTeX/PDF output, ignored types output. Depending request, may port LaTeX features bookdown future, general philosophy Markdown kept simple possible.Q: bookdown features X, Y, Z?: short answer , asked three times ‚Äúreally need ‚Äù answer still ‚Äúyes,‚Äù please feel free file feature request https://github.com/rstudio/bookdown/issues.Users asking features often come LaTeX world. case , answer question yes, Pandoc‚Äôs Markdown supports raw LaTeX code. Whenever feel Markdown job , always option apply raw LaTeX code Markdown document. example, can create glossaries using glossaries package, embed complicated LaTeX table, long know LaTeX syntax. However, please keep mind LaTeX content portable. work LaTeX/PDF output, ignored types output. Depending request, may port LaTeX features bookdown future, general philosophy Markdown kept simple possible.challenging thing world learn fancy technologies, control wild heart."",""code"":""""},{""path"":""references.html"",""id"":""references"",""chapter"":""References"",""heading"":""References"",""text"":"""",""code"":""""}]

---FILE: docs/search_index.json---
@@ -1 +1 @@
-[[""index.html"", ""Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R Welcome"", "" Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R Olivier Gimenez 2021-08-26 Welcome Welcome to the website of the book Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R by Olivier Gimenez. Note that the book is also available in PDF format. I‚Äôm currently writing this book, and I welcome any feedback or requests for content here. Many thanks! Last updated: August 26, 2021 ""],[""preface.html"", ""Preface Why read this book Structure of the book Software information and conventions Acknowledgments"", "" Preface The HMM framework has gained much attention in the ecological literature over the last decade, and has been suggested as a general modelling framework for the demography of plant and animal populations. In particular, HMMs are increasingly used to analyse capture-recapture data and estimate key population parameters (e.g., survival, dispersal, recruitment or abundance) with applications all fields of ecology. In parallel, Bayesian statistics is relatively well established and fast growing in ecology and related disciplines, because it resonates with scientific reasoning and allows accommodating uncertainty smoothly. The popularity of Bayesian statistics also comes from the availability of free pieces of software (WinBUGS, OpenBUGS, JAGS, Stan, nimble) that allow practitioners to code their own analyses. However, to my knowledge, a full Bayesian treatment of HMMs applied to capture-recapture data is yet to be proposed in a book. This is what I propose with this book. Besides, the popular software solutions come with computational limitations when ecologists have to deal with complex models and/or big data. I will use Nimble that is seen by many as the future of ecological data modelling because it extends the BUGS language for writing new functions and distributions, and provides samplers that can deal with discrete latent states in contrast with Stan. In this book, I will cover both the theory of HMMs for capture-recapture data, and the applications of these models to empower practitioners to fit their models with confidence. An important part of the book will consist in case studies presented in a tutorial style to abide by the ‚Äúlearning by doing‚Äù philosophy. The online version of this book is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. Why read this book Structure of the book Blabla. Software information and conventions This book uses primarily the R package nimble, so you need to at least install R and the nimble package. The R session information when compiling this book is shown below: sessionInfo() ## R version 4.1.0 (2021-05-18) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Catalina 10.15.7 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib ## ## locale: ## [1] fr_FR.UTF-8/fr_FR.UTF-8/fr_FR.UTF-8/C/C/fr_FR.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets ## [6] methods base ## ## loaded via a namespace (and not attached): ## [1] bookdown_0.23 digest_0.6.27 ## [3] R6_2.5.0 jsonlite_1.7.2 ## [5] magrittr_2.0.1 evaluate_0.14 ## [7] stringi_1.7.3 rlang_0.4.11 ## [9] rstudioapi_0.13 jquerylib_0.1.4 ## [11] bslib_0.2.5.1 rmarkdown_2.10 ## [13] tools_4.1.0 stringr_1.4.0 ## [15] xfun_0.25 yaml_2.2.1 ## [17] compiler_4.1.0 htmltools_0.5.1.1 ## [19] knitr_1.33 sass_0.4.0 We do not add prompts (&gt; and +) to R source code in this book, and we comment out the text output with two hashes ## by default, as you can see from the R session information above. This is for your convenience when you want to copy and run the code (the text output will be ignored since it is commented out). Package names are in bold text (e.g., nimble), and inline code and filenames are formatted in a typewriter font (e.g., knitr::knit('foo.Rmd')). Function names are followed by parentheses (e.g., nimble::nimbleCode()). The double-colon operator :: means accessing an object from a package. Acknowledgments CNRS. Jean-Do. Roger. R√©mi. My students. Chlo√©, Sarah, Perry, Daniel. Rob Chapman &amp; Hall/CRC. Workshop attendees. Feedback from. FIP radio. Marc K√©ry for his support and advice on how to write a book. Proofreading by. My family. Olivier Gimenez Montpellier, France ""],[""about-the-author.html"", ""About the Author"", "" About the Author Je m‚Äôappelle Olivier Gimenez (https://oliviergimenez.github.io/). Je suis directeur de recherche au CNRS. Apr√®s des √©tudes universitaires en math√©matiques, j‚Äôai fait une th√®se en statistiques pour l‚Äô√©cologie. J‚Äôai pass√© mon Habilitation √† Diriger des Recherches en √©cologie et √©volution. R√©cemment, je suis retourn√© sur les bancs de l‚Äôuniversit√© pour m‚Äôinitier √† la sociologie. J‚Äôai √©crit des articles scientifiques faisant appel √† la statistique bay√©sienne, et co-√©crit avec des coll√®gues britanniques un livre sur les analyses bay√©siennes pour l‚Äô√©cologie des populations. Vous pouvez me retrouver sur Twitter (https://twitter.com/oaggimenez), ou bien me contacter via mon adresse email qui s‚Äô√©crit olivier suivi d‚Äôun point puis gimenez, ensuite arobase, puis cefe, suivi d‚Äôun point, puis cnrs, suivi d‚Äôun point et pour terminer fr. Tomb√© dedans quand j‚Äô√©tais petit. Ob√©lix Roger et Ast√©rix JD. ""],[""crashcourse.html"", ""Chapter 1 Bayesian statistics &amp; MCMC 1.1 Bayes‚Äô theorem 1.2 Frequentist versus Bayesian 1.3 What is the Bayesian approach? 1.4 Bayes‚Äô theorem 1.5 Brute force via numerical integration 1.6 Further reading"", "" Chapter 1 Bayesian statistics &amp; MCMC 1.1 Bayes‚Äô theorem A theorem about conditional probabilities. \\(\\Pr(B \\mid A) = \\displaystyle{\\frac{ \\Pr(A \\mid B) \\; \\Pr(B)}{\\Pr(A)}}\\) knitr::include_graphics(&quot;images/bayes_neon.jpeg&quot;) I always forget what the letters mean. Might be easier to remember when written like this: \\[ \\Pr(\\text{hypothesis} \\mid \\text{data}) = \\frac{ \\Pr(\\text{data} \\mid \\text{hypothesis}) \\; \\Pr(\\text{hypothesis})}{\\Pr(\\text{data})} \\] The ‚Äúhypothesis‚Äù is typically something unobserved or unknown. It‚Äôs what you want to learn about using the data. For regression models, the ‚Äúhypothesis‚Äù is a parameter (intercept, slopes or error terms). Bayes theorem tells you the probability of the hypothesis given the data. Cool because what is doing science after all? How plausible is some hypothesis given the data? \\[ \\Pr(\\text{hypothesis} \\mid \\text{data}) = \\frac{ \\Pr(\\text{data} \\mid \\text{hypothesis}) \\; \\Pr(\\text{hypothesis})}{\\Pr(\\text{data})} \\] ??? The Bayesian reasoning echoes the scientific reasoning. You might ask then, why is Bayesian statistics not the default? You may ask: Why is Bayesian statistics not the default? Due to practical problems of implementing the Bayesian approach, and futile wars between (male) statisticians, little progress was made for over two centuries. Recent advances in computational power coupled with the development of new methodology have led to a great increase in the application of Bayesian methods within the last two decades. 1.2 Frequentist versus Bayesian Typical stats problems involve estimating parameter \\(\\theta\\) with available data. The frequentist approach (maximum likelihood estimation ‚Äì MLE) assumes that the parameters are fixed, but have unknown values to be estimated. Classical estimates are generally point estimates of the parameters of interest. The Bayesian approach assumes that the parameters are not fixed but have some fixed unknown distribution - a distribution for the parameter. 1.3 What is the Bayesian approach? The approach is based upon the idea that the experimenter begins with some prior beliefs about the system. You never start from scratch. And then updates these beliefs on the basis of observed data. This updating procedure is based upon the Bayes‚Äô Theorem: \\[\\Pr(A \\mid B) = \\frac{\\Pr(B \\mid A) \\; \\Pr(A)}{\\Pr(B)}\\] Schematically if \\(A = \\theta\\) and \\(B = \\text{data}\\), then The Bayes‚Äô theorem \\[\\Pr(A \\mid B) = \\frac{\\Pr(B \\mid A) \\; \\Pr(A)}{\\Pr(B)}\\] Translates into: \\[\\Pr(\\theta \\mid \\text{data}) = \\frac{\\Pr(\\text{data} \\mid \\theta) \\; \\Pr(\\theta)}{\\Pr(\\text{data})}\\] 1.4 Bayes‚Äô theorem \\[{\\color{red}{\\Pr(\\theta \\mid \\text{data})}} = \\frac{\\color{blue}{\\Pr(\\text{data} \\mid \\theta)} \\; \\color{green}{\\Pr(\\theta)}}{\\color{orange}{\\Pr(\\text{data})}}\\] \\(\\color{red}{\\text{Posterior distribution}}\\): Represents what you know after having seen the data. The basis for inference, a distribution, possibly multivariate if more than one parameter. \\(\\color{blue}{\\text{Likelihood}}\\): This quantity is the same as in the MLE approach. \\(\\color{green}{\\text{Prior distribution}}\\): Represents what you know before seeing the data. The source of much discussion about the Bayesian approach. \\(\\color{orange}{\\Pr(\\text{data}) = \\int{L(\\text{data} \\mid \\theta)\\Pr(\\theta) d\\theta}}\\) is a \\(N\\)-dimensional integral if \\(\\theta = \\theta_1, \\ldots, \\theta_N\\). Difficult if not impossible to calculate. This is one of the reasons why we need simulation (MCMC) methods. 1.5 Brute force via numerical integration Say we release \\(n\\) animals at the beginning of the winter, out of which \\(y\\) survive, and we‚Äôd like to estimate winter survival \\(\\theta\\). y &lt;- 19 # nb of success n &lt;- 57 # nb of attempts 1.6 Further reading McCarthy, M. (2007). Bayesian Methods for Ecology. Cambridge: Cambridge University Press. McElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2nd ed.). CRC Press. Gelman, A. and Hill, J. (2006). Data Analysis Using Regression and Multilevel/Hierarchical Models (Analytical Methods for Social Research). Cambridge: Cambridge University Press. ""],[""intronimble.html"", ""Chapter 2 Introduction to Nimble"", "" Chapter 2 Introduction to Nimble ""],[""hmmcapturerecapture.html"", ""Chapter 3 Hidden Markov models"", "" Chapter 3 Hidden Markov models Heller and Pogaru (2021) References ""],[""survival.html"", ""Chapter 4 Survival"", "" Chapter 4 Survival ""],[""transition.html"", ""Chapter 5 Transition"", "" Chapter 5 Transition ""],[""covariates.html"", ""Chapter 6 Covariates"", "" Chapter 6 Covariates ""],[""uncertainty.html"", ""Chapter 7 Uncertainty in state assignment"", "" Chapter 7 Uncertainty in state assignment ""],[""abundance.html"", ""Chapter 8 Abundance"", "" Chapter 8 Abundance ""],[""hsmm.html"", ""Chapter 9 Hidden semi-Markov models"", "" Chapter 9 Hidden semi-Markov models ""],[""states.html"", ""Chapter 10 Hidden states"", "" Chapter 10 Hidden states ""],[""speed.html"", ""Chapter 11 Speed up MCMC"", "" Chapter 11 Speed up MCMC ""],[""senescence.html"", ""Chapter 12 Actuarial senescence"", "" Chapter 12 Actuarial senescence Choquet et al. (2011), P√©ron et al. (2016) References ""],[""heterogeneity.html"", ""Chapter 13 Individual heterogeneity"", "" Chapter 13 Individual heterogeneity Cubaynes et al. (2010), Gimenez and Choquet (2010), and Turek, Wehrhahn, and Gimenez (2021) References ""],[""tradeoffs.html"", ""Chapter 14 Life-history tradeoffs"", "" Chapter 14 Life-history tradeoffs Morano et al. (2013), Shefferson et al. (2003), and Cruz-Flores et al. (n.d.) References ""],[""breeding.html"", ""Chapter 15 Breeding dynamics"", "" Chapter 15 Breeding dynamics Pradel, Choquet, and B√©chet (2012), Desprez et al. (2011), Desprez et al. (2013), and Pacoureau et al. (2019) References ""],[""rd.html"", ""Chapter 16 Robust design"", "" Chapter 16 Robust design Karamanlidis et al. (2015), Santostasi et al. (2016), Gibson et al. (2018), and Rankin et al. (2016) References ""],[""stopover.html"", ""Chapter 17 Stopover duration"", "" Chapter 17 Stopover duration Gu√©rin et al. (2017) References ""],[""disease.html"", ""Chapter 18 Disease dynamics"", "" Chapter 18 Disease dynamics Marescot et al. (2018) and Santoro et al. (2014) References ""],[""sex.html"", ""Chapter 19 Sex uncertainty"", "" Chapter 19 Sex uncertainty Pradel et al. (2008) and Genovart, Pradel, and Oro (2012) References ""],[""dependence.html"", ""Chapter 20 Dependence among individuals"", "" Chapter 20 Dependence among individuals Culina et al. (2013) and Cubaynes et al. (2021) References ""],[""covariateselection.html"", ""Chapter 21 Individual and temporal variability"", "" Chapter 21 Individual and temporal variability Grosbois et al. (2008), Cubaynes et al. (2012), Gimenez et al. (2006), and Bonner, Morgan, and King (2010) References ""],[""mortalities.html"", ""Chapter 22 Cause-specific mortalities"", "" Chapter 22 Cause-specific mortalities Fern√°ndez-Chac√≥n et al. (2016) and Ruette et al. (2015) References ""],[""prevalence.html"", ""Chapter 23 Prevalence"", "" Chapter 23 Prevalence (Santostasi et al. 2019) References ""],[""faq.html"", ""FAQ"", "" FAQ Below is the complete list of frequently asked questions (FAQ). Yes, there is only one question here. Personally I do not like FAQs. They often mean surprises, and surprises are not good for software users. Q: Will bookdown have the features X, Y, and Z? A: The short answer is no, but if you have asked yourself three times ‚Äúdo I really need them‚Äù and the answer is still ‚Äúyes,‚Äù please feel free to file a feature request to https://github.com/rstudio/bookdown/issues. Users asking for more features often come from the LaTeX world. If that is the case for you, the answer to this question is yes, because Pandoc‚Äôs Markdown supports raw LaTeX code. Whenever you feel Markdown cannot do the job for you, you always have the option to apply some raw LaTeX code in your Markdown document. For example, you can create glossaries using the glossaries package, or embed a complicated LaTeX table, as long as you know the LaTeX syntax. However, please keep in mind that the LaTeX content is not portable. It will only work for LaTeX/PDF output, and will be ignored in other types of output. Depending on the request, we may port a few more LaTeX features into bookdown in the future, but our general philosophy is that Markdown should be kept as simple as possible. The most challenging thing in the world is not to learn fancy technologies, but control your own wild heart. ""],[""references.html"", ""References"", "" References ""],[""404.html"", ""Page not found"", "" Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. ""]]
+[[""index.html"", ""Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R Welcome"", "" Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R Olivier Gimenez 2021-08-26 Welcome Welcome to the website of the book Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models ‚Äì Theory and Case Studies in R by Olivier Gimenez. Note that the book is also available in PDF format. I‚Äôm currently writing this book, and I welcome any feedback or requests for content here. Many thanks! Last updated: August 26, 2021 ""],[""preface.html"", ""Preface Why read this book Structure of the book Software information and conventions Acknowledgments"", "" Preface The HMM framework has gained much attention in the ecological literature over the last decade, and has been suggested as a general modelling framework for the demography of plant and animal populations. In particular, HMMs are increasingly used to analyse capture-recapture data and estimate key population parameters (e.g., survival, dispersal, recruitment or abundance) with applications all fields of ecology. In parallel, Bayesian statistics is relatively well established and fast growing in ecology and related disciplines, because it resonates with scientific reasoning and allows accommodating uncertainty smoothly. The popularity of Bayesian statistics also comes from the availability of free pieces of software (WinBUGS, OpenBUGS, JAGS, Stan, nimble) that allow practitioners to code their own analyses. However, to my knowledge, a full Bayesian treatment of HMMs applied to capture-recapture data is yet to be proposed in a book. This is what I propose with this book. Besides, the popular software solutions come with computational limitations when ecologists have to deal with complex models and/or big data. I will use Nimble that is seen by many as the future of ecological data modelling because it extends the BUGS language for writing new functions and distributions, and provides samplers that can deal with discrete latent states in contrast with Stan. In this book, I will cover both the theory of HMMs for capture-recapture data, and the applications of these models to empower practitioners to fit their models with confidence. An important part of the book will consist in case studies presented in a tutorial style to abide by the ‚Äúlearning by doing‚Äù philosophy. The online version of this book is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. Why read this book Structure of the book Blabla. Software information and conventions This book uses primarily the R package nimble, so you need to at least install R and the nimble package. The R session information when compiling this book is shown below: sessionInfo() ## R version 4.1.0 (2021-05-18) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Catalina 10.15.7 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib ## ## locale: ## [1] fr_FR.UTF-8/fr_FR.UTF-8/fr_FR.UTF-8/C/C/fr_FR.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets ## [6] methods base ## ## loaded via a namespace (and not attached): ## [1] bookdown_0.23 digest_0.6.27 ## [3] R6_2.5.0 jsonlite_1.7.2 ## [5] magrittr_2.0.1 evaluate_0.14 ## [7] stringi_1.7.3 rlang_0.4.11 ## [9] rstudioapi_0.13 jquerylib_0.1.4 ## [11] bslib_0.2.5.1 rmarkdown_2.10 ## [13] tools_4.1.0 stringr_1.4.0 ## [15] xfun_0.25 yaml_2.2.1 ## [17] compiler_4.1.0 htmltools_0.5.1.1 ## [19] knitr_1.33 sass_0.4.0 We do not add prompts (&gt; and +) to R source code in this book, and we comment out the text output with two hashes ## by default, as you can see from the R session information above. This is for your convenience when you want to copy and run the code (the text output will be ignored since it is commented out). Package names are in bold text (e.g., nimble), and inline code and filenames are formatted in a typewriter font (e.g., knitr::knit('foo.Rmd')). Function names are followed by parentheses (e.g., nimble::nimbleCode()). The double-colon operator :: means accessing an object from a package. Acknowledgments CNRS. Jean-Do. Roger. R√©mi. My students. Chlo√©, Sarah, Perry, Daniel. Rob Chapman &amp; Hall/CRC. Workshop attendees. Feedback from. FIP radio. Marc K√©ry for his support and advice on how to write a book. Proofreading by. My family. Olivier Gimenez Montpellier, France ""],[""about-the-author.html"", ""About the Author"", "" About the Author Je m‚Äôappelle Olivier Gimenez (https://oliviergimenez.github.io/). Je suis directeur de recherche au CNRS. Apr√®s des √©tudes universitaires en math√©matiques, j‚Äôai fait une th√®se en statistiques pour l‚Äô√©cologie. J‚Äôai pass√© mon Habilitation √† Diriger des Recherches en √©cologie et √©volution. R√©cemment, je suis retourn√© sur les bancs de l‚Äôuniversit√© pour m‚Äôinitier √† la sociologie. J‚Äôai √©crit des articles scientifiques faisant appel √† la statistique bay√©sienne, et co-√©crit avec des coll√®gues britanniques un livre sur les analyses bay√©siennes pour l‚Äô√©cologie des populations. Vous pouvez me retrouver sur Twitter (https://twitter.com/oaggimenez), ou bien me contacter via mon adresse email qui s‚Äô√©crit olivier suivi d‚Äôun point puis gimenez, ensuite arobase, puis cefe, suivi d‚Äôun point, puis cnrs, suivi d‚Äôun point et pour terminer fr. Tomb√© dedans quand j‚Äô√©tais petit. Ob√©lix Roger et Ast√©rix JD. ""],[""crashcourse.html"", ""Chapter 1 Bayesian statistics &amp; MCMC 1.1 Bayes‚Äô theorem 1.2 Frequentist versus Bayesian 1.3 What is the Bayesian approach? 1.4 Bayes‚Äô theorem 1.5 Brute force via numerical integration 1.6 Further reading"", "" Chapter 1 Bayesian statistics &amp; MCMC 1.1 Bayes‚Äô theorem A theorem about conditional probabilities. \\(\\Pr(B \\mid A) = \\displaystyle{\\frac{ \\Pr(A \\mid B) \\; \\Pr(B)}{\\Pr(A)}}\\) Figure 1.1: Bayes‚Äô theorem spelt out in blue neon at the offices of Autonomy in Cambridge. Source: Wikipedia I always forget what the letters mean. Might be easier to remember when written like this: \\[ \\Pr(\\text{hypothesis} \\mid \\text{data}) = \\frac{ \\Pr(\\text{data} \\mid \\text{hypothesis}) \\; \\Pr(\\text{hypothesis})}{\\Pr(\\text{data})} \\] The ‚Äúhypothesis‚Äù is typically something unobserved or unknown. It‚Äôs what you want to learn about using the data. For regression models, the ‚Äúhypothesis‚Äù is a parameter (intercept, slopes or error terms). Bayes theorem tells you the probability of the hypothesis given the data. Cool because what is doing science after all? How plausible is some hypothesis given the data? \\[ \\Pr(\\text{hypothesis} \\mid \\text{data}) = \\frac{ \\Pr(\\text{data} \\mid \\text{hypothesis}) \\; \\Pr(\\text{hypothesis})}{\\Pr(\\text{data})} \\] The Bayesian reasoning echoes the scientific reasoning. You might ask then, why is Bayesian statistics not the default? You may ask: Why is Bayesian statistics not the default? Due to practical problems of implementing the Bayesian approach, and futile wars between (male) statisticians, little progress was made for over two centuries. Recent advances in computational power coupled with the development of new methodology have led to a great increase in the application of Bayesian methods within the last two decades. 1.2 Frequentist versus Bayesian Typical stats problems involve estimating parameter \\(\\theta\\) with available data. The frequentist approach (maximum likelihood estimation ‚Äì MLE) assumes that the parameters are fixed, but have unknown values to be estimated. Classical estimates are generally point estimates of the parameters of interest. The Bayesian approach assumes that the parameters are not fixed but have some fixed unknown distribution - a distribution for the parameter. 1.3 What is the Bayesian approach? The approach is based upon the idea that the experimenter begins with some prior beliefs about the system. You never start from scratch. And then updates these beliefs on the basis of observed data. This updating procedure is based upon the Bayes‚Äô Theorem: \\[\\Pr(A \\mid B) = \\frac{\\Pr(B \\mid A) \\; \\Pr(A)}{\\Pr(B)}\\] Schematically if \\(A = \\theta\\) and \\(B = \\text{data}\\), then The Bayes‚Äô theorem \\[\\Pr(A \\mid B) = \\frac{\\Pr(B \\mid A) \\; \\Pr(A)}{\\Pr(B)}\\] Translates into: \\[\\Pr(\\theta \\mid \\text{data}) = \\frac{\\Pr(\\text{data} \\mid \\theta) \\; \\Pr(\\theta)}{\\Pr(\\text{data})}\\] 1.4 Bayes‚Äô theorem \\[{\\color{red}{\\Pr(\\theta \\mid \\text{data})}} = \\frac{\\color{blue}{\\Pr(\\text{data} \\mid \\theta)} \\; \\color{green}{\\Pr(\\theta)}}{\\color{orange}{\\Pr(\\text{data})}}\\] \\(\\color{red}{\\text{Posterior distribution}}\\): Represents what you know after having seen the data. The basis for inference, a distribution, possibly multivariate if more than one parameter. \\(\\color{blue}{\\text{Likelihood}}\\): This quantity is the same as in the MLE approach. \\(\\color{green}{\\text{Prior distribution}}\\): Represents what you know before seeing the data. The source of much discussion about the Bayesian approach. \\(\\color{orange}{\\Pr(\\text{data}) = \\int{L(\\text{data} \\mid \\theta)\\Pr(\\theta) d\\theta}}\\) is a \\(N\\)-dimensional integral if \\(\\theta = \\theta_1, \\ldots, \\theta_N\\). Difficult if not impossible to calculate. This is one of the reasons why we need simulation (MCMC) methods. 1.5 Brute force via numerical integration Say we release \\(n\\) animals at the beginning of the winter, out of which \\(y\\) survive, and we‚Äôd like to estimate winter survival \\(\\theta\\). y &lt;- 19 # nb of success n &lt;- 57 # nb of attempts 1.6 Further reading McCarthy, M. (2007). Bayesian Methods for Ecology. Cambridge: Cambridge University Press. McElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2nd ed.). CRC Press. Gelman, A. and Hill, J. (2006). Data Analysis Using Regression and Multilevel/Hierarchical Models (Analytical Methods for Social Research). Cambridge: Cambridge University Press. ""],[""intronimble.html"", ""Chapter 2 Introduction to Nimble"", "" Chapter 2 Introduction to Nimble Blabla. \\(x + 2 = 5\\) ""],[""hmmcapturerecapture.html"", ""Chapter 3 Hidden Markov models"", "" Chapter 3 Hidden Markov models Heller and Pogaru (2021) References ""],[""survival.html"", ""Chapter 4 Survival"", "" Chapter 4 Survival ""],[""transition.html"", ""Chapter 5 Transition"", "" Chapter 5 Transition ""],[""covariates.html"", ""Chapter 6 Covariates"", "" Chapter 6 Covariates ""],[""uncertainty.html"", ""Chapter 7 Uncertainty in state assignment"", "" Chapter 7 Uncertainty in state assignment ""],[""abundance.html"", ""Chapter 8 Abundance"", "" Chapter 8 Abundance ""],[""hsmm.html"", ""Chapter 9 Hidden semi-Markov models"", "" Chapter 9 Hidden semi-Markov models ""],[""states.html"", ""Chapter 10 Hidden states"", "" Chapter 10 Hidden states ""],[""speed.html"", ""Chapter 11 Speed up MCMC"", "" Chapter 11 Speed up MCMC ""],[""senescence.html"", ""Chapter 12 Actuarial senescence"", "" Chapter 12 Actuarial senescence Choquet et al. (2011), P√©ron et al. (2016) References ""],[""heterogeneity.html"", ""Chapter 13 Individual heterogeneity"", "" Chapter 13 Individual heterogeneity Cubaynes et al. (2010), Gimenez and Choquet (2010), and Turek, Wehrhahn, and Gimenez (2021) References ""],[""tradeoffs.html"", ""Chapter 14 Life-history tradeoffs"", "" Chapter 14 Life-history tradeoffs Morano et al. (2013), Shefferson et al. (2003), and Cruz-Flores et al. (n.d.) References ""],[""breeding.html"", ""Chapter 15 Breeding dynamics"", "" Chapter 15 Breeding dynamics Pradel, Choquet, and B√©chet (2012), Desprez et al. (2011), Desprez et al. (2013), and Pacoureau et al. (2019) References ""],[""rd.html"", ""Chapter 16 Robust design"", "" Chapter 16 Robust design Karamanlidis et al. (2015), Santostasi et al. (2016), Gibson et al. (2018), and Rankin et al. (2016) References ""],[""stopover.html"", ""Chapter 17 Stopover duration"", "" Chapter 17 Stopover duration Gu√©rin et al. (2017) References ""],[""disease.html"", ""Chapter 18 Disease dynamics"", "" Chapter 18 Disease dynamics Marescot et al. (2018) and Santoro et al. (2014) References ""],[""sex.html"", ""Chapter 19 Sex uncertainty"", "" Chapter 19 Sex uncertainty Pradel et al. (2008) and Genovart, Pradel, and Oro (2012) References ""],[""dependence.html"", ""Chapter 20 Dependence among individuals"", "" Chapter 20 Dependence among individuals Culina et al. (2013) and Cubaynes et al. (2021) References ""],[""covariateselection.html"", ""Chapter 21 Individual and temporal variability"", "" Chapter 21 Individual and temporal variability Grosbois et al. (2008), Cubaynes et al. (2012), Gimenez et al. (2006), and Bonner, Morgan, and King (2010) References ""],[""mortalities.html"", ""Chapter 22 Cause-specific mortalities"", "" Chapter 22 Cause-specific mortalities Fern√°ndez-Chac√≥n et al. (2016) and Ruette et al. (2015) References ""],[""prevalence.html"", ""Chapter 23 Prevalence"", "" Chapter 23 Prevalence (Santostasi et al. 2019) References ""],[""faq.html"", ""FAQ"", "" FAQ Below is the complete list of frequently asked questions (FAQ). Yes, there is only one question here. Personally I do not like FAQs. They often mean surprises, and surprises are not good for software users. Q: Will bookdown have the features X, Y, and Z? A: The short answer is no, but if you have asked yourself three times ‚Äúdo I really need them‚Äù and the answer is still ‚Äúyes,‚Äù please feel free to file a feature request to https://github.com/rstudio/bookdown/issues. Users asking for more features often come from the LaTeX world. If that is the case for you, the answer to this question is yes, because Pandoc‚Äôs Markdown supports raw LaTeX code. Whenever you feel Markdown cannot do the job for you, you always have the option to apply some raw LaTeX code in your Markdown document. For example, you can create glossaries using the glossaries package, or embed a complicated LaTeX table, as long as you know the LaTeX syntax. However, please keep in mind that the LaTeX content is not portable. It will only work for LaTeX/PDF output, and will be ignored in other types of output. Depending on the request, we may port a few more LaTeX features into bookdown in the future, but our general philosophy is that Markdown should be kept as simple as possible. The most challenging thing in the world is not to learn fancy technologies, but control your own wild heart. ""],[""references.html"", ""References"", "" References ""],[""404.html"", ""Page not found"", "" Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. ""]]",False,False,Rendering / Conversion,3
